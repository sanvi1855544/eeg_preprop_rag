[
  {
    "query_id": "pyprep_prep_pipeline.py___init___doc",
    "prompt": "How do I initialize the PREP class?",
    "data": {
      "docs": [
        {
          "text": "def __init__(self, raw, prep_params, montage, ransac=True, channel_wise=False, max_chunk_size=None, random_state=None, filter_kwargs=None, matlab_strict=False):\n    \"\"\"Initialize PREP class.\"\"\"\n    raw.load_data()\n    self.raw_eeg = raw.copy()\n    self.ch_names_all = raw.ch_names.copy()\n    self.ch_types_all = raw.get_channel_types()\n    self.ch_names_eeg = [self.ch_names_all[i] for i in range(len(self.ch_names_all)) if self.ch_types_all[i] == 'eeg']\n    self.ch_names_non_eeg = list(set(self.ch_names_all) - set(self.ch_names_eeg))\n    self.raw_eeg.pick(self.ch_names_eeg)\n    if self.ch_names_non_eeg == []:\n        self.raw_non_eeg = None\n    else:\n        self.raw_non_eeg = raw.copy()\n        self.raw_non_eeg.pick(self.ch_names_non_eeg)\n    self.raw_eeg.set_montage(montage)\n    self.EEG_raw = self.raw_eeg.get_data()\n    self.prep_params = prep_params\n    if self.prep_params['ref_chs'] == 'eeg':\n        self.prep_params['ref_chs'] = self.ch_names_eeg\n    if self.prep_params['reref_chs'] == 'eeg':\n        self.prep_params['reref_chs'] = self.ch_names_eeg\n    if 'max_iterations' not in prep_params.keys():\n        self.prep_params['max_iterations'] = 4\n    self.sfreq = self.raw_eeg.info['sfreq']\n    self.ransac_settings = {'ransac': ransac, 'channel_wise': channel_wise, 'max_chunk_size': max_chunk_size}\n    self.random_state = check_random_state(random_state)\n    self.filter_kwargs = filter_kwargs\n    self.matlab_strict = matlab_strict"
        },
        {
          "text": "def __init__(self, raw, params, ransac=True, channel_wise=False, max_chunk_size=None, random_state=None, matlab_strict=False):\n    \"\"\"Initialize the class.\"\"\"\n    raw.load_data()\n    self.raw = raw.copy()\n    self.ch_names = self.raw.ch_names\n    self.raw.pick('eeg', exclude=[])\n    self.bads_manual = raw.info['bads']\n    self.ch_names_eeg = self.raw.ch_names\n    self.EEG = self.raw.get_data()\n    self.reference_channels = params['ref_chs']\n    self.rereferenced_channels = params['reref_chs']\n    self.sfreq = self.raw.info['sfreq']\n    self.ransac_settings = {'ransac': ransac, 'channel_wise': channel_wise, 'max_chunk_size': max_chunk_size}\n    self.random_state = check_random_state(random_state)\n    self._extra_info = {}\n    self.matlab_strict = matlab_strict"
        },
        {
          "text": "@property\ndef raw(self):\n    \"\"\"Return a version of self.raw_eeg that includes the non-eeg channels.\"\"\"\n    full_raw = self.raw_eeg.copy()\n    if self.raw_non_eeg is None:\n        return full_raw\n    else:\n        return full_raw.add_channels([self.raw_non_eeg], force_update_info=True)"
        },
        {
          "text": "def perform_reference(self, max_iterations=4):\n    \"\"\"Estimate the true signal mean and interpolate bad channels.\n\n        Parameters\n        ----------\n        max_iterations : int, optional\n            The maximum number of iterations of noisy channel removal to perform\n            during robust referencing. Defaults to ``4``.\n\n        This function implements the functionality of the `performReference` function\n        as part of the PREP pipeline on mne raw object.\n\n        Notes\n        -----\n        This function calls ``robust_reference`` first.\n        Currently this function only implements the functionality of default\n        settings, i.e., ``doRobustPost``.\n\n        \"\"\"\n    self.robust_reference(max_iterations)\n    dummy = self.raw.copy()\n    dummy.info['bads'] = self.noisy_channels['bad_all']\n    if self.matlab_strict:\n        _eeglab_interpolate_bads(dummy)\n    else:\n        dummy.interpolate_bads()\n    self.reference_signal = np.nanmean(dummy.get_data(picks=self.reference_channels), axis=0)\n    del dummy\n    rereferenced_index = [self.ch_names_eeg.index(ch) for ch in self.rereferenced_channels]\n    self.EEG = self.remove_reference(self.EEG, self.reference_signal, rereferenced_index)\n    self.raw._data = self.EEG\n    noisy_detector = NoisyChannels(self.raw, random_state=self.random_state, matlab_strict=self.matlab_strict)\n    noisy_detector.find_all_bads(**self.ransac_settings)\n    self.bad_before_interpolation = noisy_detector.get_bads(verbose=True)\n    self.EEG_before_interpolation = self.EEG.copy()\n    self.noisy_channels_before_interpolation = noisy_detector.get_bads(as_dict=True)\n    self.noisy_channels_before_interpolation['bad_by_manual'] = self.bads_manual\n    self._extra_info['interpolated'] = noisy_detector._extra_info\n    bad_channels = _union(self.bad_before_interpolation, self.unusable_channels)\n    self.raw.info['bads'] = bad_channels\n    if self.matlab_strict:\n        _eeglab_interpolate_bads(self.raw)\n    else:\n        self.raw.interpolate_bads()\n    reference_correct = np.nanmean(self.raw.get_data(picks=self.reference_channels), axis=0)\n    self.EEG = self.raw.get_data()\n    self.EEG = self.remove_reference(self.EEG, reference_correct, rereferenced_index)\n    self.reference_signal_new = self.reference_signal + reference_correct\n    self.raw._data = self.EEG\n    self.interpolated_channels = bad_channels\n    noisy_detector = NoisyChannels(self.raw, random_state=self.random_state, matlab_strict=self.matlab_strict)\n    noisy_detector.find_all_bads(**self.ransac_settings)\n    self.still_noisy_channels = noisy_detector.get_bads()\n    self.raw.info['bads'] = self.still_noisy_channels\n    self.noisy_channels_after_interpolation = noisy_detector.get_bads(as_dict=True)\n    self._extra_info['remaining_bad'] = noisy_detector._extra_info\n    return self"
        },
        {
          "text": "def _predict_median_signals(window, interpolation_mats, matlab_strict=False):\n    \"\"\"Calculate the median RANSAC-predicted signal for a given window of data.\n\n    Parameters\n    ----------\n    window : np.ndarray\n        A 2-D window of EEG data with the shape `[channels, samples]`.\n    interpolation_mats : list of np.ndarray\n        A set of channel interpolation matrices, one for each RANSAC sample of\n        channels.\n    matlab_strict : bool\n        Whether or not RANSAC should strictly follow MATLAB PREP's internal\n        math, ignoring any improvements made in PyPREP over the original code.\n\n    Returns\n    -------\n    predicted : np.ndarray\n        The median RANSAC-predicted EEG signal for the given window of data.\n\n    Notes\n    -----\n    In MATLAB PREP, the median signal is calculated by sorting the different\n    predictions for each EEG sample/channel from low to high and then taking the value\n    at the middle index (as calculated by ``int(n_ransac_samples / 2.0)``) for each.\n    Because this logic only returns the correct result for odd numbers of samples, the\n    current function will instead return the true median signal across predictions\n    unless strict MATLAB equivalence is requested.\n\n    \"\"\"\n    ransac_samples = len(interpolation_mats)\n    merged_mats = np.concatenate(interpolation_mats, axis=0)\n    predictions_per_sample = np.reshape(np.matmul(merged_mats, window), (ransac_samples, window.shape[0], window.shape[1]))\n    if matlab_strict:\n        median_idx = int(_mat_round(ransac_samples / 2.0) - 1)\n        predictions_per_sample.sort(axis=0)\n        return predictions_per_sample[median_idx, :, :]\n    else:\n        return np.median(predictions_per_sample, axis=0)"
        }
      ]
    }
  },
  {
    "query_id": "pyprep_prep_pipeline.py_raw_doc",
    "prompt": "How can I get a version of the EEG data that includes the non-EEG channels?",
    "data": {
      "docs": [
        {
          "text": "@property\ndef raw(self):\n    \"\"\"Return a version of self.raw_eeg that includes the non-eeg channels.\"\"\"\n    full_raw = self.raw_eeg.copy()\n    if self.raw_non_eeg is None:\n        return full_raw\n    else:\n        return full_raw.add_channels([self.raw_non_eeg], force_update_info=True)"
        },
        {
          "text": "def find_bad_by_ransac(data, sample_rate, complete_chn_labs, chn_pos, exclude, n_samples=50, sample_prop=0.25, corr_thresh=0.75, frac_bad=0.4, corr_window_secs=5.0, channel_wise=False, max_chunk_size=None, random_state=None, matlab_strict=False):\n    \"\"\"Detect channels that are not predicted well by other channels.\n\n    Here, a RANSAC approach (see [1]_, and a short discussion in [2]_) is\n    adopted to predict a \"clean EEG\" dataset. After identifying clean EEG\n    channels through the other methods, the clean EEG dataset is\n    constructed by repeatedly sampling a small subset of clean EEG channels\n    and interpolation the complete data. The median of all those\n    repetitions forms the clean EEG dataset. In a second step, the original\n    and the RANSAC-predicted data are correlated and channels, which do not\n    correlate well with themselves across the two datasets are considered\n    `bad_by_ransac`.\n\n    Parameters\n    ----------\n    data : np.ndarray\n        A 2-D array of detrended EEG data, with bad-by-flat and bad-by-NaN\n        channels removed.\n    sample_rate : float\n        The sample rate (in Hz) of the EEG data.\n    complete_chn_labs : array_like\n        Labels for all channels in `data`, in the same order as they appear\n        in `data`.\n    chn_pos : np.ndarray\n        3-D electrode coordinates for all channels in `data`, in the same order\n        as they appear in `data`.\n    exclude : list\n        Labels of channels to exclude as signal predictors during RANSAC\n        (i.e., channels already flagged as bad by metrics other than HF noise).\n    n_samples : int, optional\n        Number of random channel samples to use for RANSAC. Defaults to ``50``.\n    sample_prop : float, optional\n        Proportion of total channels to use for signal prediction per RANSAC\n        sample. This needs to be in the range [0, 1], where 0 would mean no\n        channels would be used and 1 would mean all channels would be used\n        (neither of which would be useful values). Defaults to ``0.25`` (e.g.,\n        16 channels per sample for a 64-channel dataset).\n    corr_thresh : float, optional\n        The minimum predicted vs. actual signal correlation for a channel to\n        be considered good within a given RANSAC window. Defaults to ``0.75``.\n    frac_bad : float, optional\n        The minimum fraction of bad (i.e., below-threshold) RANSAC windows for a\n        channel to be considered bad-by-RANSAC. Defaults to ``0.4``.\n    corr_window_secs : float, optional\n        The duration (in seconds) of each RANSAC correlation window. Defaults to\n        5 seconds.\n    channel_wise : bool, optional\n        Whether RANSAC should predict signals for chunks of channels over the\n        entire signal length (\"channel-wise RANSAC\", see `max_chunk_size`\n        parameter). If ``False``, RANSAC will instead predict signals for all\n        channels at once but over a number of smaller time windows instead of\n        over the entire signal length (\"window-wise RANSAC\"). Channel-wise\n        RANSAC generally has higher RAM demands than window-wise RANSAC\n        (especially if `max_chunk_size` is ``None``), but can be faster on\n        systems with lots of RAM to spare. Defaults to ``False``.\n    max_chunk_size : {int, None}, optional\n        The maximum number of channels to predict at once during channel-wise\n        RANSAC. If ``None``, RANSAC will use the largest chunk size that will\n        fit into the available RAM, which may slow down other programs on the\n        host system. If using window-wise RANSAC (the default), this parameter\n        has no effect. Defaults to ``None``.\n    random_state : {int, None, np.random.RandomState}, optional\n        The random seed with which to generate random samples of channels during\n        RANSAC. If random_state is an int, it will be used as a seed for RandomState.\n        If ``None``, the seed will be obtained from the operating system\n        (see RandomState for details). Defaults to ``None``.\n    matlab_strict : bool, optional\n        Whether or not RANSAC should strictly follow MATLAB PREP's internal\n        math, ignoring any improvements made in PyPREP over the original code\n        (see :ref:`matlab-diffs` for more details). Defaults to ``False``.\n\n    Returns\n    -------\n    bad_by_ransac : list\n        List containing the labels of all channels flagged as bad by RANSAC.\n    channel_correlations : np.ndarray\n        Array of shape (windows, channels) containing the correlations of\n        the channels with their predicted RANSAC values for each window.\n\n    References\n    ----------\n    .. [1] Fischler, M.A., Bolles, R.C. (1981). Random sample consensus: A\n        Paradigm for Model Fitting with Applications to Image Analysis and\n        Automated Cartography. Communications of the ACM, 24, 381-395\n    .. [2] Jas, M., Engemann, D.A., Bekhti, Y., Raimondo, F., Gramfort, A.\n        (2017). Autoreject: Automated Artifact Rejection for MEG and EEG\n        Data. NeuroImage, 159, 417-429\n\n    \"\"\"\n    if np.isnan(chn_pos).any():\n        raise ValueError('Found NaN in channel positions. Did you supply a montage for the raw data?')\n    if not isinstance(n_samples, int):\n        raise TypeError(f\"Argument 'n_samples' must be an int (got {type(n_samples).__name__})\")\n    complete_chn_labs = np.asarray(complete_chn_labs)\n    good_idx = np.array([idx for (idx, ch) in enumerate(complete_chn_labs) if ch not in exclude])\n    n_chans_good = good_idx.shape[0]\n    chn_pos_good = chn_pos[good_idx, :]\n    n_chans = data.shape[0]\n    n_pred_chns = int(np.around(sample_prop * n_chans))\n    if n_pred_chns <= 3:\n        sample_pct = int(sample_prop * 100)\n        raise OSError(f'Too few channels in the original data to reliably perform RANSAC(minimum {int(np.floor(4.0 / sample_prop))} for a sample size of {sample_pct}%).')\n    elif n_chans_good < n_pred_chns + 1:\n        raise OSError(f'Too many noisy channels in the data to reliably perform RANSAC (only {n_chans_good} good channels remaining, need at least {n_pred_chns + 1}).')\n    if channel_wise:\n        _verify_free_ram(data, n_samples, 1)\n    else:\n        window_size = int(sample_rate * corr_window_secs)\n        _verify_free_ram(data[:, :window_size], n_samples, n_chans_good)\n    random_ch_picks = []\n    good_chans = np.arange(chn_pos_good.shape[0])\n    rng = check_random_state(random_state)\n    for i in range(n_samples):\n        picks = _get_random_subset(good_chans, n_pred_chns, rng)\n        random_ch_picks.append(picks)\n    interp_mats = _make_interpolation_matrices(random_ch_picks, chn_pos_good)\n    correlation_frames = corr_window_secs * sample_rate\n    signal_frames = data.shape[1]\n    correlation_offsets = np.arange(0, signal_frames - correlation_frames, correlation_frames)\n    win_size = int(correlation_frames)\n    win_count = correlation_offsets.shape[0]\n    n_chans_complete = len(complete_chn_labs)\n    channel_correlations = np.ones((win_count, n_chans_complete))\n    logger.info('Executing RANSAC\\nThis may take a while, so be patient...')\n    if not channel_wise:\n        channel_correlations[:, good_idx] = _ransac_by_window(data[good_idx, :], interp_mats, win_size, win_count, matlab_strict)\n    chunk_sizes = []\n    chunk_count = 0\n    for i in range(1, n_chans_good + 1):\n        n_chunks = int(np.ceil(n_chans_good / i))\n        if n_chunks != chunk_count:\n            chunk_count = n_chunks\n            if not max_chunk_size or i <= max_chunk_size:\n                chunk_sizes.append(i)\n    chunk_size = chunk_sizes.pop()\n    mem_error = True\n    job = list(range(n_chans_good))\n    while mem_error and channel_wise:\n        try:\n            channel_chunks = _split_list(job, chunk_size)\n            total_chunks = len(channel_chunks)\n            current = 1\n            for chunk in channel_chunks:\n                interp_mats_for_chunk = [mat[chunk, :] for mat in interp_mats]\n                channel_correlations[:, good_idx[chunk]] = _ransac_by_channel(data[good_idx, :], interp_mats_for_chunk, win_size, win_count, chunk, random_ch_picks, matlab_strict)\n                if chunk == channel_chunks[0]:\n                    logger.info('Finding optimal chunk size : %s', chunk_size)\n                    logger.info('Total # of chunks: %s', total_chunks)\n                    logger.info('Current chunk:')\n                logger.info(current)\n                current = current + 1\n            mem_error = False\n            del current\n        except MemoryError:\n            if len(chunk_sizes):\n                chunk_size = chunk_sizes.pop()\n            else:\n                raise MemoryError('Not even doing 1 channel at a time the data fits in ram...You could downsample the data or reduce the number of requested samples.')\n    thresholded_correlations = channel_correlations < corr_thresh\n    frac_bad_corr_windows = np.mean(thresholded_correlations, axis=0)\n    bad_ransac_channels_idx = np.argwhere(frac_bad_corr_windows > frac_bad)\n    bad_ransac_channels_name = complete_chn_labs[bad_ransac_channels_idx.astype(int)]\n    bad_by_ransac = [i[0] for i in bad_ransac_channels_name]\n    logger.info('\\nRANSAC done!')\n    return (bad_by_ransac, channel_correlations)"
        },
        {
          "text": "def __init__(self, raw, prep_params, montage, ransac=True, channel_wise=False, max_chunk_size=None, random_state=None, filter_kwargs=None, matlab_strict=False):\n    \"\"\"Initialize PREP class.\"\"\"\n    raw.load_data()\n    self.raw_eeg = raw.copy()\n    self.ch_names_all = raw.ch_names.copy()\n    self.ch_types_all = raw.get_channel_types()\n    self.ch_names_eeg = [self.ch_names_all[i] for i in range(len(self.ch_names_all)) if self.ch_types_all[i] == 'eeg']\n    self.ch_names_non_eeg = list(set(self.ch_names_all) - set(self.ch_names_eeg))\n    self.raw_eeg.pick(self.ch_names_eeg)\n    if self.ch_names_non_eeg == []:\n        self.raw_non_eeg = None\n    else:\n        self.raw_non_eeg = raw.copy()\n        self.raw_non_eeg.pick(self.ch_names_non_eeg)\n    self.raw_eeg.set_montage(montage)\n    self.EEG_raw = self.raw_eeg.get_data()\n    self.prep_params = prep_params\n    if self.prep_params['ref_chs'] == 'eeg':\n        self.prep_params['ref_chs'] = self.ch_names_eeg\n    if self.prep_params['reref_chs'] == 'eeg':\n        self.prep_params['reref_chs'] = self.ch_names_eeg\n    if 'max_iterations' not in prep_params.keys():\n        self.prep_params['max_iterations'] = 4\n    self.sfreq = self.raw_eeg.info['sfreq']\n    self.ransac_settings = {'ransac': ransac, 'channel_wise': channel_wise, 'max_chunk_size': max_chunk_size}\n    self.random_state = check_random_state(random_state)\n    self.filter_kwargs = filter_kwargs\n    self.matlab_strict = matlab_strict"
        },
        {
          "text": "def _get_filtered_data(self):\n    \"\"\"Apply a [1 Hz - 50 Hz] bandpass filter to the EEG signal.\n\n        Only applied if the sample rate is above 100 Hz to avoid violating the\n        Nyquist theorem.\n\n        \"\"\"\n    if self.sample_rate <= 100:\n        return self.EEGData.copy()\n    bandpass_filter = _filter_design(N_order=100, amp=np.array([1, 1, 0, 0]), freq=np.array([0, 90 / self.sample_rate, 100 / self.sample_rate, 1]))\n    EEG_filt = np.zeros_like(self.EEGData)\n    for i in range(EEG_filt.shape[0]):\n        EEG_filt[i, :] = signal.filtfilt(bandpass_filter, 1, self.EEGData[i, :])\n    return EEG_filt"
        },
        {
          "text": "def find_bad_by_nan_flat(self, flat_threshold=1e-15):\n    \"\"\"Detect channels than contain NaN values or have near-flat signals.\n\n        A channel is considered flat if its standard deviation or its median\n        absolute deviation from the median (MAD) are below the provided flat\n        threshold (default: ``1e-15`` volts).\n\n        This method is run automatically when a ``NoisyChannels`` object is\n        initialized, preventing flat or NaN-containing channels from interfering\n        with the detection of other types of bad channels.\n\n        Parameters\n        ----------\n        flat_threshold : float, optional\n            The lowest standard deviation or MAD value for a channel to be\n            considered bad-by-flat. Defaults to ``1e-15`` volts (corresponds to\n            10e-10 \u00b5V in MATLAB PREP).\n        \"\"\"\n    EEGData = self.raw_mne.get_data()\n    nan_channel_mask = np.isnan(np.sum(EEGData, axis=1))\n    nan_channels = self.ch_names_original[nan_channel_mask]\n    flat_by_mad = median_abs_deviation(EEGData, axis=1) < flat_threshold\n    flat_by_stdev = np.std(EEGData, axis=1) < flat_threshold\n    flat_channel_mask = flat_by_mad | flat_by_stdev\n    flat_channels = self.ch_names_original[flat_channel_mask]\n    self.bad_by_nan = nan_channels.tolist()\n    self.bad_by_flat = flat_channels.tolist()"
        }
      ]
    }
  },
  {
    "query_id": "pyprep_prep_pipeline.py_fit_doc",
    "prompt": "How do I run the full PREP pipeline on EEG data?",
    "data": {
      "docs": [
        {
          "text": "def __init__(self, raw, prep_params, montage, ransac=True, channel_wise=False, max_chunk_size=None, random_state=None, filter_kwargs=None, matlab_strict=False):\n    \"\"\"Initialize PREP class.\"\"\"\n    raw.load_data()\n    self.raw_eeg = raw.copy()\n    self.ch_names_all = raw.ch_names.copy()\n    self.ch_types_all = raw.get_channel_types()\n    self.ch_names_eeg = [self.ch_names_all[i] for i in range(len(self.ch_names_all)) if self.ch_types_all[i] == 'eeg']\n    self.ch_names_non_eeg = list(set(self.ch_names_all) - set(self.ch_names_eeg))\n    self.raw_eeg.pick(self.ch_names_eeg)\n    if self.ch_names_non_eeg == []:\n        self.raw_non_eeg = None\n    else:\n        self.raw_non_eeg = raw.copy()\n        self.raw_non_eeg.pick(self.ch_names_non_eeg)\n    self.raw_eeg.set_montage(montage)\n    self.EEG_raw = self.raw_eeg.get_data()\n    self.prep_params = prep_params\n    if self.prep_params['ref_chs'] == 'eeg':\n        self.prep_params['ref_chs'] = self.ch_names_eeg\n    if self.prep_params['reref_chs'] == 'eeg':\n        self.prep_params['reref_chs'] = self.ch_names_eeg\n    if 'max_iterations' not in prep_params.keys():\n        self.prep_params['max_iterations'] = 4\n    self.sfreq = self.raw_eeg.info['sfreq']\n    self.ransac_settings = {'ransac': ransac, 'channel_wise': channel_wise, 'max_chunk_size': max_chunk_size}\n    self.random_state = check_random_state(random_state)\n    self.filter_kwargs = filter_kwargs\n    self.matlab_strict = matlab_strict"
        },
        {
          "text": "def fit(self):\n    \"\"\"Run the whole PREP pipeline.\"\"\"\n    if len(self.prep_params['line_freqs']) != 0:\n        self.EEG_new = removeTrend(self.EEG_raw, self.sfreq, matlab_strict=self.matlab_strict)\n        linenoise = self.prep_params['line_freqs']\n        if self.filter_kwargs is None:\n            self.EEG_clean = mne.filter.notch_filter(self.EEG_new, Fs=self.sfreq, freqs=linenoise, method='spectrum_fit', mt_bandwidth=2, p_value=0.01, filter_length='10s')\n        else:\n            self.EEG_clean = mne.filter.notch_filter(self.EEG_new, Fs=self.sfreq, freqs=linenoise, **self.filter_kwargs)\n        self.EEG = self.EEG_raw - self.EEG_new + self.EEG_clean\n        self.raw_eeg._data = self.EEG\n    reference = Reference(self.raw_eeg, self.prep_params, random_state=self.random_state, matlab_strict=self.matlab_strict, **self.ransac_settings)\n    reference.perform_reference(self.prep_params['max_iterations'])\n    self.raw_eeg = reference.raw\n    self.noisy_channels_original = reference.noisy_channels_original\n    self.noisy_channels_before_interpolation = reference.noisy_channels_before_interpolation\n    self.noisy_channels_after_interpolation = reference.noisy_channels_after_interpolation\n    self.bad_before_interpolation = reference.bad_before_interpolation\n    self.EEG_before_interpolation = reference.EEG_before_interpolation\n    self.reference_before_interpolation = reference.reference_signal\n    self.reference_after_interpolation = reference.reference_signal_new\n    self.interpolated_channels = reference.interpolated_channels\n    self.still_noisy_channels = reference.still_noisy_channels\n    return self"
        },
        {
          "text": "@property\ndef raw(self):\n    \"\"\"Return a version of self.raw_eeg that includes the non-eeg channels.\"\"\"\n    full_raw = self.raw_eeg.copy()\n    if self.raw_non_eeg is None:\n        return full_raw\n    else:\n        return full_raw.add_channels([self.raw_non_eeg], force_update_info=True)"
        },
        {
          "text": "def _eeglab_fir_filter(data, filt):\n    \"\"\"Apply an FIR filter to a 2-D array of EEG data.\n\n    Parameters\n    ----------\n    data : np.ndarray\n        A 2-D array of EEG data to filter.\n    filt : np.ndarray\n        A 1-D array of FIR filter coefficients.\n\n    Returns\n    -------\n    filtered : np.ndarray\n        A 2-D array of FIR-filtered EEG data.\n\n    Notes\n    -----\n    Produces identical output to EEGLAB's ``firfilt`` function (for non-epoched\n    data). For internal use within :mod:`pyprep.removeTrend`.\n\n    \"\"\"\n    frames_per_window = 2000\n    group_delay = int((len(filt) - 1) / 2)\n    n_samples = data.shape[1]\n    n_windows = int(np.ceil((n_samples - group_delay) / frames_per_window))\n    pad_len = min(group_delay, n_samples)\n    start_pad_idx = np.zeros(pad_len, dtype=np.uint)\n    start_padded = np.concatenate((data[:, start_pad_idx], data[:, :pad_len]), axis=1)\n    zi_init = lfilter_zi(filt, 1) * np.take(start_padded, [0], axis=0)\n    (_, zi) = lfilter(filt, 1, start_padded, axis=1, zi=zi_init)\n    out = np.zeros_like(data)\n    for w in range(n_windows):\n        start = group_delay + w * frames_per_window\n        end = min(start + frames_per_window, n_samples)\n        start_out = start - group_delay\n        end_out = end - group_delay\n        (out[:, start_out:end_out], zi) = lfilter(filt, 1, data[:, start:end], axis=1, zi=zi)\n    end_pad_idx = np.zeros(pad_len, dtype=np.uint) + (n_samples - 1)\n    (end, _) = lfilter(filt, 1, data[:, end_pad_idx], axis=1, zi=zi)\n    out[:, n_samples - pad_len:] = end[:, group_delay - pad_len:]\n    return out"
        },
        {
          "text": "def runline(y, n, dn):\n    \"\"\"Perform local linear regression on a channel of EEG data.\n\n    A re-implementation of the ``runline`` function from the Chronux package\n    for MATLAB [1]_.\n\n    Parameters\n    ----------\n    y : np.ndarray\n        A 1-D array of data from a single EEG channel.\n    n : int\n        Length of the detrending window.\n    dn : int\n        Length of the window step size.\n\n    Returns\n    -------\n    y: np.ndarray\n       The detrended signal for the given EEG channel.\n\n    References\n    ----------\n    .. [1] http://chronux.org/\n\n    \"\"\"\n    nt = y.shape[0]\n    y_line = np.zeros((nt, 1))\n    norm = np.zeros((nt, 1))\n    nwin = int(np.ceil((nt - n) / dn))\n    yfit = np.zeros((nwin, n))\n    xwt = (np.arange(1, n + 1) - n / 2) / (n / 2)\n    wt = np.power(1 - np.power(np.absolute(xwt), 3), 3)\n    for j in range(0, nwin):\n        tseg = y[dn * j:dn * j + n]\n        y1 = np.mean(tseg)\n        y2 = np.mean(np.multiply(np.arange(1, n + 1), tseg)) * (2 / (n + 1))\n        a = np.multiply(np.subtract(y2, y1), 6 / (n - 1))\n        b = np.subtract(y1, a * (n + 1) / 2)\n        yfit[j, :] = np.multiply(np.arange(1, n + 1), a) + b\n        y_line[j * dn:j * dn + n] = y_line[j * dn:j * dn + n] + np.reshape(np.multiply(yfit[j, :], wt), (n, 1))\n        norm[j * dn:j * dn + n] = norm[j * dn:j * dn + n] + np.reshape(wt, (n, 1))\n    for i in range(0, len(norm)):\n        if norm[i] > 0:\n            y_line[i] = y_line[i] / norm[i]\n    indx = (nwin - 1) * dn + n - 1\n    npts = len(y) - indx + 1\n    y_line[indx - 1:] = np.reshape(np.multiply(np.arange(n + 1, n + npts + 1), a) + b, (npts, 1))\n    for i in range(0, len(y_line)):\n        y[i] = y[i] - y_line[i, 0]\n    return y"
        }
      ]
    }
  },
  {
    "query_id": "pyprep_removeTrend.py_removeTrend_doc",
    "prompt": "How do I remove slow drifts or trends from EEG data using PyPREP?",
    "data": {
      "docs": [
        {
          "text": "def removeTrend(EEG, sample_rate, detrendType='high pass', detrendCutoff=1.0, detrendChannels=None, matlab_strict=False):\n    \"\"\"Remove trends (i.e., slow drifts in baseline) from an array of EEG data.\n\n    Parameters\n    ----------\n    EEG : np.ndarray\n        A 2-D array of EEG data to detrend.\n    sample_rate : float\n        The sample rate (in Hz) of the input EEG data.\n    detrendType : str, optional\n        Type of detrending to be performed: must be one of 'high pass',\n        'high pass sinc, or 'local detrend'. Defaults to 'high pass'.\n    detrendCutoff : float, optional\n        The high-pass cutoff frequency (in Hz) to use for detrending. Defaults\n        to 1.0 Hz.\n    detrendChannels : {list, None}, optional\n        List of the indices of all channels that require detrending/filtering.\n        If ``None``, all channels are used (default).\n    matlab_strict : bool, optional\n        Whether or not detrending should strictly follow MATLAB PREP's internal\n        math, ignoring any improvements made in PyPREP over the original code\n        (see :ref:`matlab-diffs` for more details). Defaults to ``False``.\n\n    Returns\n    -------\n    EEG : np.ndarray\n        A 2-D array containing the filtered/detrended EEG data.\n\n    Notes\n    -----\n    High-pass filtering is implemented using the MNE filter function\n    :func:``mne.filter.filter_data`` unless `matlab_strict` is ``True``, in\n    which case it is performed using a minimal re-implementation of EEGLAB's\n    ``pop_eegfiltnew``. Local detrending is performed using a Python\n    re-implementation of the ``runline`` function from the Chronux package for\n    MATLAB [1]_.\n\n    References\n    ----------\n    .. [1] http://chronux.org/\n\n    \"\"\"\n    if len(EEG.shape) == 1:\n        EEG = np.reshape(EEG, (1, EEG.shape[0]))\n    if detrendType.lower() == 'high pass':\n        if matlab_strict:\n            picks = detrendChannels if detrendChannels else range(EEG.shape[0])\n            filt = _eeglab_create_highpass(detrendCutoff, sample_rate)\n            EEG[picks, :] = _eeglab_fir_filter(EEG[picks, :], filt)\n        else:\n            EEG = mne.filter.filter_data(EEG, sfreq=sample_rate, l_freq=detrendCutoff, h_freq=None, picks=detrendChannels)\n    elif detrendType.lower() == 'high pass sinc':\n        fOrder = np.round(14080 * sample_rate / 512)\n        fOrder = int(fOrder + fOrder % 2)\n        EEG = mne.filter.filter_data(data=EEG, sfreq=sample_rate, l_freq=1, h_freq=None, picks=detrendChannels, filter_length=fOrder, fir_window='blackman')\n    elif detrendType.lower() == 'local detrend':\n        if detrendChannels is None:\n            detrendChannels = np.arange(0, EEG.shape[0])\n        windowSize = 1.5 / detrendCutoff\n        windowSize = np.minimum(windowSize, EEG.shape[1])\n        stepSize = 0.02\n        EEG = np.transpose(EEG)\n        n = np.round(sample_rate * windowSize)\n        dn = np.round(sample_rate * stepSize)\n        if dn > n or dn < 1:\n            logging.error('Step size should be less than the window size and contain at least 1 sample')\n        if n == EEG.shape[0]:\n            pass\n        else:\n            for ch in detrendChannels:\n                EEG[:, ch] = runline(EEG[:, ch], int(n), int(dn))\n        EEG = np.transpose(EEG)\n    else:\n        logging.warning('No filtering/detreding performed since the detrend type did not match')\n    return EEG"
        },
        {
          "text": "def _get_filtered_data(self):\n    \"\"\"Apply a [1 Hz - 50 Hz] bandpass filter to the EEG signal.\n\n        Only applied if the sample rate is above 100 Hz to avoid violating the\n        Nyquist theorem.\n\n        \"\"\"\n    if self.sample_rate <= 100:\n        return self.EEGData.copy()\n    bandpass_filter = _filter_design(N_order=100, amp=np.array([1, 1, 0, 0]), freq=np.array([0, 90 / self.sample_rate, 100 / self.sample_rate, 1]))\n    EEG_filt = np.zeros_like(self.EEGData)\n    for i in range(EEG_filt.shape[0]):\n        EEG_filt[i, :] = signal.filtfilt(bandpass_filter, 1, self.EEGData[i, :])\n    return EEG_filt"
        },
        {
          "text": "def __init__(self, raw, do_detrend=True, random_state=None, matlab_strict=False):\n    assert isinstance(raw, mne.io.BaseRaw)\n    raw.load_data()\n    self.raw_mne = raw.copy()\n    self.bad_by_manual = raw.info['bads']\n    self.raw_mne.pick('eeg')\n    self.sample_rate = raw.info['sfreq']\n    if do_detrend:\n        self.raw_mne._data = removeTrend(self.raw_mne.get_data(), self.sample_rate, matlab_strict=matlab_strict)\n    self.matlab_strict = matlab_strict\n    self._extra_info = {'bad_by_deviation': {}, 'bad_by_hf_noise': {}, 'bad_by_correlation': {}, 'bad_by_dropout': {}, 'bad_by_ransac': {}}\n    self.random_state = check_random_state(random_state)\n    self.bad_by_nan = []\n    self.bad_by_flat = []\n    self.bad_by_deviation = []\n    self.bad_by_hf_noise = []\n    self.bad_by_correlation = []\n    self.bad_by_SNR = []\n    self.bad_by_dropout = []\n    self.bad_by_ransac = []\n    ch_names = np.asarray(self.raw_mne.info['ch_names'])\n    self.ch_names_original = ch_names\n    self.n_chans_original = len(ch_names)\n    self.n_samples = raw.get_data().shape[1]\n    self.find_bad_by_nan_flat()\n    bads_by_nan_flat = self.bad_by_nan + self.bad_by_flat\n    self.usable_idx = np.isin(ch_names, bads_by_nan_flat, invert=True)\n    self.EEGData = self.raw_mne.get_data(picks=ch_names[self.usable_idx])\n    self.EEGFiltered = None\n    self.ch_names_new = np.asarray(ch_names[self.usable_idx])\n    self.n_chans_new = len(self.ch_names_new)"
        },
        {
          "text": "def _eeglab_fir_filter(data, filt):\n    \"\"\"Apply an FIR filter to a 2-D array of EEG data.\n\n    Parameters\n    ----------\n    data : np.ndarray\n        A 2-D array of EEG data to filter.\n    filt : np.ndarray\n        A 1-D array of FIR filter coefficients.\n\n    Returns\n    -------\n    filtered : np.ndarray\n        A 2-D array of FIR-filtered EEG data.\n\n    Notes\n    -----\n    Produces identical output to EEGLAB's ``firfilt`` function (for non-epoched\n    data). For internal use within :mod:`pyprep.removeTrend`.\n\n    \"\"\"\n    frames_per_window = 2000\n    group_delay = int((len(filt) - 1) / 2)\n    n_samples = data.shape[1]\n    n_windows = int(np.ceil((n_samples - group_delay) / frames_per_window))\n    pad_len = min(group_delay, n_samples)\n    start_pad_idx = np.zeros(pad_len, dtype=np.uint)\n    start_padded = np.concatenate((data[:, start_pad_idx], data[:, :pad_len]), axis=1)\n    zi_init = lfilter_zi(filt, 1) * np.take(start_padded, [0], axis=0)\n    (_, zi) = lfilter(filt, 1, start_padded, axis=1, zi=zi_init)\n    out = np.zeros_like(data)\n    for w in range(n_windows):\n        start = group_delay + w * frames_per_window\n        end = min(start + frames_per_window, n_samples)\n        start_out = start - group_delay\n        end_out = end - group_delay\n        (out[:, start_out:end_out], zi) = lfilter(filt, 1, data[:, start:end], axis=1, zi=zi)\n    end_pad_idx = np.zeros(pad_len, dtype=np.uint) + (n_samples - 1)\n    (end, _) = lfilter(filt, 1, data[:, end_pad_idx], axis=1, zi=zi)\n    out[:, n_samples - pad_len:] = end[:, group_delay - pad_len:]\n    return out"
        },
        {
          "text": "def fit(self):\n    \"\"\"Run the whole PREP pipeline.\"\"\"\n    if len(self.prep_params['line_freqs']) != 0:\n        self.EEG_new = removeTrend(self.EEG_raw, self.sfreq, matlab_strict=self.matlab_strict)\n        linenoise = self.prep_params['line_freqs']\n        if self.filter_kwargs is None:\n            self.EEG_clean = mne.filter.notch_filter(self.EEG_new, Fs=self.sfreq, freqs=linenoise, method='spectrum_fit', mt_bandwidth=2, p_value=0.01, filter_length='10s')\n        else:\n            self.EEG_clean = mne.filter.notch_filter(self.EEG_new, Fs=self.sfreq, freqs=linenoise, **self.filter_kwargs)\n        self.EEG = self.EEG_raw - self.EEG_new + self.EEG_clean\n        self.raw_eeg._data = self.EEG\n    reference = Reference(self.raw_eeg, self.prep_params, random_state=self.random_state, matlab_strict=self.matlab_strict, **self.ransac_settings)\n    reference.perform_reference(self.prep_params['max_iterations'])\n    self.raw_eeg = reference.raw\n    self.noisy_channels_original = reference.noisy_channels_original\n    self.noisy_channels_before_interpolation = reference.noisy_channels_before_interpolation\n    self.noisy_channels_after_interpolation = reference.noisy_channels_after_interpolation\n    self.bad_before_interpolation = reference.bad_before_interpolation\n    self.EEG_before_interpolation = reference.EEG_before_interpolation\n    self.reference_before_interpolation = reference.reference_signal\n    self.reference_after_interpolation = reference.reference_signal_new\n    self.interpolated_channels = reference.interpolated_channels\n    self.still_noisy_channels = reference.still_noisy_channels\n    return self"
        }
      ]
    }
  },
  {
    "query_id": "pyprep_removeTrend.py_runline_doc",
    "prompt": "How can I perform local linear detrending using the runline method?",
    "data": {
      "docs": [
        {
          "text": "def runline(y, n, dn):\n    \"\"\"Perform local linear regression on a channel of EEG data.\n\n    A re-implementation of the ``runline`` function from the Chronux package\n    for MATLAB [1]_.\n\n    Parameters\n    ----------\n    y : np.ndarray\n        A 1-D array of data from a single EEG channel.\n    n : int\n        Length of the detrending window.\n    dn : int\n        Length of the window step size.\n\n    Returns\n    -------\n    y: np.ndarray\n       The detrended signal for the given EEG channel.\n\n    References\n    ----------\n    .. [1] http://chronux.org/\n\n    \"\"\"\n    nt = y.shape[0]\n    y_line = np.zeros((nt, 1))\n    norm = np.zeros((nt, 1))\n    nwin = int(np.ceil((nt - n) / dn))\n    yfit = np.zeros((nwin, n))\n    xwt = (np.arange(1, n + 1) - n / 2) / (n / 2)\n    wt = np.power(1 - np.power(np.absolute(xwt), 3), 3)\n    for j in range(0, nwin):\n        tseg = y[dn * j:dn * j + n]\n        y1 = np.mean(tseg)\n        y2 = np.mean(np.multiply(np.arange(1, n + 1), tseg)) * (2 / (n + 1))\n        a = np.multiply(np.subtract(y2, y1), 6 / (n - 1))\n        b = np.subtract(y1, a * (n + 1) / 2)\n        yfit[j, :] = np.multiply(np.arange(1, n + 1), a) + b\n        y_line[j * dn:j * dn + n] = y_line[j * dn:j * dn + n] + np.reshape(np.multiply(yfit[j, :], wt), (n, 1))\n        norm[j * dn:j * dn + n] = norm[j * dn:j * dn + n] + np.reshape(wt, (n, 1))\n    for i in range(0, len(norm)):\n        if norm[i] > 0:\n            y_line[i] = y_line[i] / norm[i]\n    indx = (nwin - 1) * dn + n - 1\n    npts = len(y) - indx + 1\n    y_line[indx - 1:] = np.reshape(np.multiply(np.arange(n + 1, n + npts + 1), a) + b, (npts, 1))\n    for i in range(0, len(y_line)):\n        y[i] = y[i] - y_line[i, 0]\n    return y"
        },
        {
          "text": "def removeTrend(EEG, sample_rate, detrendType='high pass', detrendCutoff=1.0, detrendChannels=None, matlab_strict=False):\n    \"\"\"Remove trends (i.e., slow drifts in baseline) from an array of EEG data.\n\n    Parameters\n    ----------\n    EEG : np.ndarray\n        A 2-D array of EEG data to detrend.\n    sample_rate : float\n        The sample rate (in Hz) of the input EEG data.\n    detrendType : str, optional\n        Type of detrending to be performed: must be one of 'high pass',\n        'high pass sinc, or 'local detrend'. Defaults to 'high pass'.\n    detrendCutoff : float, optional\n        The high-pass cutoff frequency (in Hz) to use for detrending. Defaults\n        to 1.0 Hz.\n    detrendChannels : {list, None}, optional\n        List of the indices of all channels that require detrending/filtering.\n        If ``None``, all channels are used (default).\n    matlab_strict : bool, optional\n        Whether or not detrending should strictly follow MATLAB PREP's internal\n        math, ignoring any improvements made in PyPREP over the original code\n        (see :ref:`matlab-diffs` for more details). Defaults to ``False``.\n\n    Returns\n    -------\n    EEG : np.ndarray\n        A 2-D array containing the filtered/detrended EEG data.\n\n    Notes\n    -----\n    High-pass filtering is implemented using the MNE filter function\n    :func:``mne.filter.filter_data`` unless `matlab_strict` is ``True``, in\n    which case it is performed using a minimal re-implementation of EEGLAB's\n    ``pop_eegfiltnew``. Local detrending is performed using a Python\n    re-implementation of the ``runline`` function from the Chronux package for\n    MATLAB [1]_.\n\n    References\n    ----------\n    .. [1] http://chronux.org/\n\n    \"\"\"\n    if len(EEG.shape) == 1:\n        EEG = np.reshape(EEG, (1, EEG.shape[0]))\n    if detrendType.lower() == 'high pass':\n        if matlab_strict:\n            picks = detrendChannels if detrendChannels else range(EEG.shape[0])\n            filt = _eeglab_create_highpass(detrendCutoff, sample_rate)\n            EEG[picks, :] = _eeglab_fir_filter(EEG[picks, :], filt)\n        else:\n            EEG = mne.filter.filter_data(EEG, sfreq=sample_rate, l_freq=detrendCutoff, h_freq=None, picks=detrendChannels)\n    elif detrendType.lower() == 'high pass sinc':\n        fOrder = np.round(14080 * sample_rate / 512)\n        fOrder = int(fOrder + fOrder % 2)\n        EEG = mne.filter.filter_data(data=EEG, sfreq=sample_rate, l_freq=1, h_freq=None, picks=detrendChannels, filter_length=fOrder, fir_window='blackman')\n    elif detrendType.lower() == 'local detrend':\n        if detrendChannels is None:\n            detrendChannels = np.arange(0, EEG.shape[0])\n        windowSize = 1.5 / detrendCutoff\n        windowSize = np.minimum(windowSize, EEG.shape[1])\n        stepSize = 0.02\n        EEG = np.transpose(EEG)\n        n = np.round(sample_rate * windowSize)\n        dn = np.round(sample_rate * stepSize)\n        if dn > n or dn < 1:\n            logging.error('Step size should be less than the window size and contain at least 1 sample')\n        if n == EEG.shape[0]:\n            pass\n        else:\n            for ch in detrendChannels:\n                EEG[:, ch] = runline(EEG[:, ch], int(n), int(dn))\n        EEG = np.transpose(EEG)\n    else:\n        logging.warning('No filtering/detreding performed since the detrend type did not match')\n    return EEG"
        },
        {
          "text": "def __init__(self, raw, do_detrend=True, random_state=None, matlab_strict=False):\n    assert isinstance(raw, mne.io.BaseRaw)\n    raw.load_data()\n    self.raw_mne = raw.copy()\n    self.bad_by_manual = raw.info['bads']\n    self.raw_mne.pick('eeg')\n    self.sample_rate = raw.info['sfreq']\n    if do_detrend:\n        self.raw_mne._data = removeTrend(self.raw_mne.get_data(), self.sample_rate, matlab_strict=matlab_strict)\n    self.matlab_strict = matlab_strict\n    self._extra_info = {'bad_by_deviation': {}, 'bad_by_hf_noise': {}, 'bad_by_correlation': {}, 'bad_by_dropout': {}, 'bad_by_ransac': {}}\n    self.random_state = check_random_state(random_state)\n    self.bad_by_nan = []\n    self.bad_by_flat = []\n    self.bad_by_deviation = []\n    self.bad_by_hf_noise = []\n    self.bad_by_correlation = []\n    self.bad_by_SNR = []\n    self.bad_by_dropout = []\n    self.bad_by_ransac = []\n    ch_names = np.asarray(self.raw_mne.info['ch_names'])\n    self.ch_names_original = ch_names\n    self.n_chans_original = len(ch_names)\n    self.n_samples = raw.get_data().shape[1]\n    self.find_bad_by_nan_flat()\n    bads_by_nan_flat = self.bad_by_nan + self.bad_by_flat\n    self.usable_idx = np.isin(ch_names, bads_by_nan_flat, invert=True)\n    self.EEGData = self.raw_mne.get_data(picks=ch_names[self.usable_idx])\n    self.EEGFiltered = None\n    self.ch_names_new = np.asarray(ch_names[self.usable_idx])\n    self.n_chans_new = len(self.ch_names_new)"
        },
        {
          "text": "def __init__(self, raw, prep_params, montage, ransac=True, channel_wise=False, max_chunk_size=None, random_state=None, filter_kwargs=None, matlab_strict=False):\n    \"\"\"Initialize PREP class.\"\"\"\n    raw.load_data()\n    self.raw_eeg = raw.copy()\n    self.ch_names_all = raw.ch_names.copy()\n    self.ch_types_all = raw.get_channel_types()\n    self.ch_names_eeg = [self.ch_names_all[i] for i in range(len(self.ch_names_all)) if self.ch_types_all[i] == 'eeg']\n    self.ch_names_non_eeg = list(set(self.ch_names_all) - set(self.ch_names_eeg))\n    self.raw_eeg.pick(self.ch_names_eeg)\n    if self.ch_names_non_eeg == []:\n        self.raw_non_eeg = None\n    else:\n        self.raw_non_eeg = raw.copy()\n        self.raw_non_eeg.pick(self.ch_names_non_eeg)\n    self.raw_eeg.set_montage(montage)\n    self.EEG_raw = self.raw_eeg.get_data()\n    self.prep_params = prep_params\n    if self.prep_params['ref_chs'] == 'eeg':\n        self.prep_params['ref_chs'] = self.ch_names_eeg\n    if self.prep_params['reref_chs'] == 'eeg':\n        self.prep_params['reref_chs'] = self.ch_names_eeg\n    if 'max_iterations' not in prep_params.keys():\n        self.prep_params['max_iterations'] = 4\n    self.sfreq = self.raw_eeg.info['sfreq']\n    self.ransac_settings = {'ransac': ransac, 'channel_wise': channel_wise, 'max_chunk_size': max_chunk_size}\n    self.random_state = check_random_state(random_state)\n    self.filter_kwargs = filter_kwargs\n    self.matlab_strict = matlab_strict"
        },
        {
          "text": "def _ransac_by_window(data, interpolation_mats, win_size, win_count, matlab_strict):\n    \"\"\"Calculate correlations of channels with their RANSAC-predicted values.\n\n    This function calculates RANSAC correlations for each RANSAC window\n    individually, requiring RAM equivalent to [channels * sample rate * seconds\n    per RANSAC window] to run. Generally, this method will use less RAM than\n    :func:`_ransac_by_channel`, with the exception of short recordings with high\n    electrode counts.\n\n    Parameters\n    ----------\n    data : np.ndarray\n        A 2-D array containing the EEG signals from all currently-good channels.\n    interpolation_mats : list of np.ndarray\n        A list of interpolation matrices, one for each RANSAC sample of channels.\n    win_size : int\n        Number of frames/samples of EEG data in each RANSAC correlation window.\n    win_count: int\n        Number of RANSAC correlation windows.\n    matlab_strict : bool\n        Whether or not RANSAC should strictly follow MATLAB PREP's internal\n        math, ignoring any improvements made in PyPREP over the original code.\n\n    Returns\n    -------\n    correlations : np.ndarray\n        Correlations of the given channels to their predicted values within each\n        RANSAC window.\n\n    \"\"\"\n    ch_count = data.shape[0]\n    correlations = np.ones((win_count, ch_count))\n    pb = ProgressBar(range(win_count))\n    for window in pb:\n        start = window * win_size\n        end = (window + 1) * win_size\n        actual = data[:, start:end]\n        predicted = _predict_median_signals(actual, interpolation_mats, matlab_strict)\n        correlations[window, :] = _correlate_arrays(actual, predicted, matlab_strict)\n    return correlations"
        }
      ]
    }
  },
  {
    "query_id": "pyprep_reference.py___init___doc",
    "prompt": "How do I initialize the referencing class in PyPREP?",
    "data": {
      "docs": [
        {
          "text": "def perform_reference(self, max_iterations=4):\n    \"\"\"Estimate the true signal mean and interpolate bad channels.\n\n        Parameters\n        ----------\n        max_iterations : int, optional\n            The maximum number of iterations of noisy channel removal to perform\n            during robust referencing. Defaults to ``4``.\n\n        This function implements the functionality of the `performReference` function\n        as part of the PREP pipeline on mne raw object.\n\n        Notes\n        -----\n        This function calls ``robust_reference`` first.\n        Currently this function only implements the functionality of default\n        settings, i.e., ``doRobustPost``.\n\n        \"\"\"\n    self.robust_reference(max_iterations)\n    dummy = self.raw.copy()\n    dummy.info['bads'] = self.noisy_channels['bad_all']\n    if self.matlab_strict:\n        _eeglab_interpolate_bads(dummy)\n    else:\n        dummy.interpolate_bads()\n    self.reference_signal = np.nanmean(dummy.get_data(picks=self.reference_channels), axis=0)\n    del dummy\n    rereferenced_index = [self.ch_names_eeg.index(ch) for ch in self.rereferenced_channels]\n    self.EEG = self.remove_reference(self.EEG, self.reference_signal, rereferenced_index)\n    self.raw._data = self.EEG\n    noisy_detector = NoisyChannels(self.raw, random_state=self.random_state, matlab_strict=self.matlab_strict)\n    noisy_detector.find_all_bads(**self.ransac_settings)\n    self.bad_before_interpolation = noisy_detector.get_bads(verbose=True)\n    self.EEG_before_interpolation = self.EEG.copy()\n    self.noisy_channels_before_interpolation = noisy_detector.get_bads(as_dict=True)\n    self.noisy_channels_before_interpolation['bad_by_manual'] = self.bads_manual\n    self._extra_info['interpolated'] = noisy_detector._extra_info\n    bad_channels = _union(self.bad_before_interpolation, self.unusable_channels)\n    self.raw.info['bads'] = bad_channels\n    if self.matlab_strict:\n        _eeglab_interpolate_bads(self.raw)\n    else:\n        self.raw.interpolate_bads()\n    reference_correct = np.nanmean(self.raw.get_data(picks=self.reference_channels), axis=0)\n    self.EEG = self.raw.get_data()\n    self.EEG = self.remove_reference(self.EEG, reference_correct, rereferenced_index)\n    self.reference_signal_new = self.reference_signal + reference_correct\n    self.raw._data = self.EEG\n    self.interpolated_channels = bad_channels\n    noisy_detector = NoisyChannels(self.raw, random_state=self.random_state, matlab_strict=self.matlab_strict)\n    noisy_detector.find_all_bads(**self.ransac_settings)\n    self.still_noisy_channels = noisy_detector.get_bads()\n    self.raw.info['bads'] = self.still_noisy_channels\n    self.noisy_channels_after_interpolation = noisy_detector.get_bads(as_dict=True)\n    self._extra_info['remaining_bad'] = noisy_detector._extra_info\n    return self"
        },
        {
          "text": "def __init__(self, raw, params, ransac=True, channel_wise=False, max_chunk_size=None, random_state=None, matlab_strict=False):\n    \"\"\"Initialize the class.\"\"\"\n    raw.load_data()\n    self.raw = raw.copy()\n    self.ch_names = self.raw.ch_names\n    self.raw.pick('eeg', exclude=[])\n    self.bads_manual = raw.info['bads']\n    self.ch_names_eeg = self.raw.ch_names\n    self.EEG = self.raw.get_data()\n    self.reference_channels = params['ref_chs']\n    self.rereferenced_channels = params['reref_chs']\n    self.sfreq = self.raw.info['sfreq']\n    self.ransac_settings = {'ransac': ransac, 'channel_wise': channel_wise, 'max_chunk_size': max_chunk_size}\n    self.random_state = check_random_state(random_state)\n    self._extra_info = {}\n    self.matlab_strict = matlab_strict"
        },
        {
          "text": "def robust_reference(self, max_iterations=4):\n    \"\"\"Detect bad channels and estimate the robust reference signal.\n\n        This function implements the functionality of the `robustReference` function\n        as part of the PREP pipeline on mne raw object.\n\n        Parameters\n        ----------\n        max_iterations : int, optional\n            The maximum number of iterations of noisy channel removal to perform\n            during robust referencing. Defaults to ``4``.\n\n        Returns\n        -------\n        noisy_channels: dict\n            A dictionary of names of noisy channels detected from all methods\n            after referencing.\n        reference_signal: np.ndarray, shape(n, )\n            Estimation of the 'true' signal mean\n\n        \"\"\"\n    raw = self.raw.copy()\n    raw._data = removeTrend(raw.get_data(), self.sfreq, matlab_strict=self.matlab_strict)\n    noisy_detector = NoisyChannels(raw, do_detrend=False, random_state=self.random_state, matlab_strict=self.matlab_strict)\n    noisy_detector.find_all_bads(**self.ransac_settings)\n    self.noisy_channels_original = noisy_detector.get_bads(as_dict=True)\n    self._extra_info['initial_bad'] = noisy_detector._extra_info\n    logger.info(f'Bad channels: {self.noisy_channels_original}')\n    self.unusable_channels = _union(noisy_detector.bad_by_nan + noisy_detector.bad_by_flat, noisy_detector.bad_by_SNR + self.bads_manual)\n    reference_channels = _set_diff(self.reference_channels, self.unusable_channels)\n    noisy = {'bad_by_nan': noisy_detector.bad_by_nan, 'bad_by_flat': noisy_detector.bad_by_flat, 'bad_by_deviation': [], 'bad_by_hf_noise': [], 'bad_by_correlation': [], 'bad_by_SNR': [], 'bad_by_dropout': [], 'bad_by_ransac': [], 'bad_by_manual': self.bads_manual, 'bad_all': []}\n    signal = raw.get_data()\n    self.reference_signal = np.nanmedian(raw.get_data(picks=reference_channels), axis=0)\n    reference_index = [self.ch_names_eeg.index(ch) for ch in reference_channels]\n    signal_tmp = self.remove_reference(signal, self.reference_signal, reference_index)\n    raw_tmp = raw.copy()\n    iterations = 0\n    previous_bads = set()\n    while True:\n        raw_tmp._data = signal_tmp\n        noisy_detector = NoisyChannels(raw_tmp, do_detrend=False, random_state=self.random_state, matlab_strict=self.matlab_strict)\n        noisy_detector.find_all_bads(**self.ransac_settings)\n        noisy_new = noisy_detector.get_bads(as_dict=True)\n        ignore = ['bad_by_SNR', 'bad_all']\n        if self.matlab_strict:\n            ignore += ['bad_by_dropout']\n        bad_chans = set()\n        for bad_type in noisy_new.keys():\n            noisy[bad_type] = _union(noisy[bad_type], noisy_new[bad_type])\n            if bad_type not in ignore:\n                bad_chans.update(noisy[bad_type])\n        noisy['bad_by_manual'] = self.bads_manual\n        noisy['bad_all'] = list(bad_chans) + self.bads_manual\n        logger.info(f'Bad channels: {noisy}')\n        if iterations > 1 and (len(bad_chans) == 0 or bad_chans == previous_bads) or iterations > max_iterations:\n            logger.info('Robust reference done')\n            self.noisy_channels = noisy\n            break\n        previous_bads = bad_chans.copy()\n        if raw_tmp.info['nchan'] - len(bad_chans) < 2:\n            raise ValueError('RobustReference:TooManyBad Could not perform a robust reference -- not enough good channels')\n        if len(bad_chans) > 0:\n            raw_tmp._data = signal.copy()\n            raw_tmp.info['bads'] = list(bad_chans)\n            if self.matlab_strict:\n                _eeglab_interpolate_bads(raw_tmp)\n            else:\n                raw_tmp.interpolate_bads()\n        self.reference_signal = np.nanmean(raw_tmp.get_data(picks=reference_channels), axis=0)\n        signal_tmp = self.remove_reference(signal, self.reference_signal, reference_index)\n        iterations = iterations + 1\n        logger.info(f'Iterations: {iterations}')\n    return (self.noisy_channels, self.reference_signal)"
        },
        {
          "text": "def _predict_median_signals(window, interpolation_mats, matlab_strict=False):\n    \"\"\"Calculate the median RANSAC-predicted signal for a given window of data.\n\n    Parameters\n    ----------\n    window : np.ndarray\n        A 2-D window of EEG data with the shape `[channels, samples]`.\n    interpolation_mats : list of np.ndarray\n        A set of channel interpolation matrices, one for each RANSAC sample of\n        channels.\n    matlab_strict : bool\n        Whether or not RANSAC should strictly follow MATLAB PREP's internal\n        math, ignoring any improvements made in PyPREP over the original code.\n\n    Returns\n    -------\n    predicted : np.ndarray\n        The median RANSAC-predicted EEG signal for the given window of data.\n\n    Notes\n    -----\n    In MATLAB PREP, the median signal is calculated by sorting the different\n    predictions for each EEG sample/channel from low to high and then taking the value\n    at the middle index (as calculated by ``int(n_ransac_samples / 2.0)``) for each.\n    Because this logic only returns the correct result for odd numbers of samples, the\n    current function will instead return the true median signal across predictions\n    unless strict MATLAB equivalence is requested.\n\n    \"\"\"\n    ransac_samples = len(interpolation_mats)\n    merged_mats = np.concatenate(interpolation_mats, axis=0)\n    predictions_per_sample = np.reshape(np.matmul(merged_mats, window), (ransac_samples, window.shape[0], window.shape[1]))\n    if matlab_strict:\n        median_idx = int(_mat_round(ransac_samples / 2.0) - 1)\n        predictions_per_sample.sort(axis=0)\n        return predictions_per_sample[median_idx, :, :]\n    else:\n        return np.median(predictions_per_sample, axis=0)"
        },
        {
          "text": "@staticmethod\ndef remove_reference(signal, reference, index=None):\n    \"\"\"Remove the reference signal from the original EEG signal.\n\n        This function implements the functionality of the `removeReference` function\n        as part of the PREP pipeline on mne raw object.\n\n        Parameters\n        ----------\n        signal : np.ndarray, shape(channels, times)\n            The original EEG signal.\n        reference : np.ndarray, shape(times,)\n            The reference signal.\n        index : {list, None}, optional\n            A list of channel indices from which the reference signal should be\n            subtracted. Defaults to all channels in `signal`.\n\n        Returns\n        -------\n        np.ndarray, shape(channels, times)\n            The referenced EEG signal.\n\n        \"\"\"\n    if np.ndim(signal) != 2:\n        raise ValueError('RemoveReference: EEG signal must be 2D array (channels * times)')\n    if np.ndim(reference) != 1:\n        raise ValueError('RemoveReference: Reference signal must be 1D array')\n    if np.shape(signal)[1] != np.shape(reference)[0]:\n        raise ValueError('RemoveReference: The second dimension of EEG signal must be the same with the length of reference signal')\n    if index is None:\n        signal_referenced = signal - reference\n    else:\n        if not isinstance(index, list):\n            raise TypeError(f'RemoveReference: Expected type list, got {type(index)} instead')\n        signal_referenced = signal.copy()\n        signal_referenced[np.asarray(index), :] = signal[np.asarray(index), :] - reference\n    return signal_referenced"
        }
      ]
    }
  },
  {
    "query_id": "pyprep_reference.py_perform_reference_doc",
    "prompt": "How does the perform_reference function estimate the EEG signal mean and handle bad channels?",
    "data": {
      "docs": [
        {
          "text": "def find_bad_by_ransac(data, sample_rate, complete_chn_labs, chn_pos, exclude, n_samples=50, sample_prop=0.25, corr_thresh=0.75, frac_bad=0.4, corr_window_secs=5.0, channel_wise=False, max_chunk_size=None, random_state=None, matlab_strict=False):\n    \"\"\"Detect channels that are not predicted well by other channels.\n\n    Here, a RANSAC approach (see [1]_, and a short discussion in [2]_) is\n    adopted to predict a \"clean EEG\" dataset. After identifying clean EEG\n    channels through the other methods, the clean EEG dataset is\n    constructed by repeatedly sampling a small subset of clean EEG channels\n    and interpolation the complete data. The median of all those\n    repetitions forms the clean EEG dataset. In a second step, the original\n    and the RANSAC-predicted data are correlated and channels, which do not\n    correlate well with themselves across the two datasets are considered\n    `bad_by_ransac`.\n\n    Parameters\n    ----------\n    data : np.ndarray\n        A 2-D array of detrended EEG data, with bad-by-flat and bad-by-NaN\n        channels removed.\n    sample_rate : float\n        The sample rate (in Hz) of the EEG data.\n    complete_chn_labs : array_like\n        Labels for all channels in `data`, in the same order as they appear\n        in `data`.\n    chn_pos : np.ndarray\n        3-D electrode coordinates for all channels in `data`, in the same order\n        as they appear in `data`.\n    exclude : list\n        Labels of channels to exclude as signal predictors during RANSAC\n        (i.e., channels already flagged as bad by metrics other than HF noise).\n    n_samples : int, optional\n        Number of random channel samples to use for RANSAC. Defaults to ``50``.\n    sample_prop : float, optional\n        Proportion of total channels to use for signal prediction per RANSAC\n        sample. This needs to be in the range [0, 1], where 0 would mean no\n        channels would be used and 1 would mean all channels would be used\n        (neither of which would be useful values). Defaults to ``0.25`` (e.g.,\n        16 channels per sample for a 64-channel dataset).\n    corr_thresh : float, optional\n        The minimum predicted vs. actual signal correlation for a channel to\n        be considered good within a given RANSAC window. Defaults to ``0.75``.\n    frac_bad : float, optional\n        The minimum fraction of bad (i.e., below-threshold) RANSAC windows for a\n        channel to be considered bad-by-RANSAC. Defaults to ``0.4``.\n    corr_window_secs : float, optional\n        The duration (in seconds) of each RANSAC correlation window. Defaults to\n        5 seconds.\n    channel_wise : bool, optional\n        Whether RANSAC should predict signals for chunks of channels over the\n        entire signal length (\"channel-wise RANSAC\", see `max_chunk_size`\n        parameter). If ``False``, RANSAC will instead predict signals for all\n        channels at once but over a number of smaller time windows instead of\n        over the entire signal length (\"window-wise RANSAC\"). Channel-wise\n        RANSAC generally has higher RAM demands than window-wise RANSAC\n        (especially if `max_chunk_size` is ``None``), but can be faster on\n        systems with lots of RAM to spare. Defaults to ``False``.\n    max_chunk_size : {int, None}, optional\n        The maximum number of channels to predict at once during channel-wise\n        RANSAC. If ``None``, RANSAC will use the largest chunk size that will\n        fit into the available RAM, which may slow down other programs on the\n        host system. If using window-wise RANSAC (the default), this parameter\n        has no effect. Defaults to ``None``.\n    random_state : {int, None, np.random.RandomState}, optional\n        The random seed with which to generate random samples of channels during\n        RANSAC. If random_state is an int, it will be used as a seed for RandomState.\n        If ``None``, the seed will be obtained from the operating system\n        (see RandomState for details). Defaults to ``None``.\n    matlab_strict : bool, optional\n        Whether or not RANSAC should strictly follow MATLAB PREP's internal\n        math, ignoring any improvements made in PyPREP over the original code\n        (see :ref:`matlab-diffs` for more details). Defaults to ``False``.\n\n    Returns\n    -------\n    bad_by_ransac : list\n        List containing the labels of all channels flagged as bad by RANSAC.\n    channel_correlations : np.ndarray\n        Array of shape (windows, channels) containing the correlations of\n        the channels with their predicted RANSAC values for each window.\n\n    References\n    ----------\n    .. [1] Fischler, M.A., Bolles, R.C. (1981). Random sample consensus: A\n        Paradigm for Model Fitting with Applications to Image Analysis and\n        Automated Cartography. Communications of the ACM, 24, 381-395\n    .. [2] Jas, M., Engemann, D.A., Bekhti, Y., Raimondo, F., Gramfort, A.\n        (2017). Autoreject: Automated Artifact Rejection for MEG and EEG\n        Data. NeuroImage, 159, 417-429\n\n    \"\"\"\n    if np.isnan(chn_pos).any():\n        raise ValueError('Found NaN in channel positions. Did you supply a montage for the raw data?')\n    if not isinstance(n_samples, int):\n        raise TypeError(f\"Argument 'n_samples' must be an int (got {type(n_samples).__name__})\")\n    complete_chn_labs = np.asarray(complete_chn_labs)\n    good_idx = np.array([idx for (idx, ch) in enumerate(complete_chn_labs) if ch not in exclude])\n    n_chans_good = good_idx.shape[0]\n    chn_pos_good = chn_pos[good_idx, :]\n    n_chans = data.shape[0]\n    n_pred_chns = int(np.around(sample_prop * n_chans))\n    if n_pred_chns <= 3:\n        sample_pct = int(sample_prop * 100)\n        raise OSError(f'Too few channels in the original data to reliably perform RANSAC(minimum {int(np.floor(4.0 / sample_prop))} for a sample size of {sample_pct}%).')\n    elif n_chans_good < n_pred_chns + 1:\n        raise OSError(f'Too many noisy channels in the data to reliably perform RANSAC (only {n_chans_good} good channels remaining, need at least {n_pred_chns + 1}).')\n    if channel_wise:\n        _verify_free_ram(data, n_samples, 1)\n    else:\n        window_size = int(sample_rate * corr_window_secs)\n        _verify_free_ram(data[:, :window_size], n_samples, n_chans_good)\n    random_ch_picks = []\n    good_chans = np.arange(chn_pos_good.shape[0])\n    rng = check_random_state(random_state)\n    for i in range(n_samples):\n        picks = _get_random_subset(good_chans, n_pred_chns, rng)\n        random_ch_picks.append(picks)\n    interp_mats = _make_interpolation_matrices(random_ch_picks, chn_pos_good)\n    correlation_frames = corr_window_secs * sample_rate\n    signal_frames = data.shape[1]\n    correlation_offsets = np.arange(0, signal_frames - correlation_frames, correlation_frames)\n    win_size = int(correlation_frames)\n    win_count = correlation_offsets.shape[0]\n    n_chans_complete = len(complete_chn_labs)\n    channel_correlations = np.ones((win_count, n_chans_complete))\n    logger.info('Executing RANSAC\\nThis may take a while, so be patient...')\n    if not channel_wise:\n        channel_correlations[:, good_idx] = _ransac_by_window(data[good_idx, :], interp_mats, win_size, win_count, matlab_strict)\n    chunk_sizes = []\n    chunk_count = 0\n    for i in range(1, n_chans_good + 1):\n        n_chunks = int(np.ceil(n_chans_good / i))\n        if n_chunks != chunk_count:\n            chunk_count = n_chunks\n            if not max_chunk_size or i <= max_chunk_size:\n                chunk_sizes.append(i)\n    chunk_size = chunk_sizes.pop()\n    mem_error = True\n    job = list(range(n_chans_good))\n    while mem_error and channel_wise:\n        try:\n            channel_chunks = _split_list(job, chunk_size)\n            total_chunks = len(channel_chunks)\n            current = 1\n            for chunk in channel_chunks:\n                interp_mats_for_chunk = [mat[chunk, :] for mat in interp_mats]\n                channel_correlations[:, good_idx[chunk]] = _ransac_by_channel(data[good_idx, :], interp_mats_for_chunk, win_size, win_count, chunk, random_ch_picks, matlab_strict)\n                if chunk == channel_chunks[0]:\n                    logger.info('Finding optimal chunk size : %s', chunk_size)\n                    logger.info('Total # of chunks: %s', total_chunks)\n                    logger.info('Current chunk:')\n                logger.info(current)\n                current = current + 1\n            mem_error = False\n            del current\n        except MemoryError:\n            if len(chunk_sizes):\n                chunk_size = chunk_sizes.pop()\n            else:\n                raise MemoryError('Not even doing 1 channel at a time the data fits in ram...You could downsample the data or reduce the number of requested samples.')\n    thresholded_correlations = channel_correlations < corr_thresh\n    frac_bad_corr_windows = np.mean(thresholded_correlations, axis=0)\n    bad_ransac_channels_idx = np.argwhere(frac_bad_corr_windows > frac_bad)\n    bad_ransac_channels_name = complete_chn_labs[bad_ransac_channels_idx.astype(int)]\n    bad_by_ransac = [i[0] for i in bad_ransac_channels_name]\n    logger.info('\\nRANSAC done!')\n    return (bad_by_ransac, channel_correlations)"
        },
        {
          "text": "def perform_reference(self, max_iterations=4):\n    \"\"\"Estimate the true signal mean and interpolate bad channels.\n\n        Parameters\n        ----------\n        max_iterations : int, optional\n            The maximum number of iterations of noisy channel removal to perform\n            during robust referencing. Defaults to ``4``.\n\n        This function implements the functionality of the `performReference` function\n        as part of the PREP pipeline on mne raw object.\n\n        Notes\n        -----\n        This function calls ``robust_reference`` first.\n        Currently this function only implements the functionality of default\n        settings, i.e., ``doRobustPost``.\n\n        \"\"\"\n    self.robust_reference(max_iterations)\n    dummy = self.raw.copy()\n    dummy.info['bads'] = self.noisy_channels['bad_all']\n    if self.matlab_strict:\n        _eeglab_interpolate_bads(dummy)\n    else:\n        dummy.interpolate_bads()\n    self.reference_signal = np.nanmean(dummy.get_data(picks=self.reference_channels), axis=0)\n    del dummy\n    rereferenced_index = [self.ch_names_eeg.index(ch) for ch in self.rereferenced_channels]\n    self.EEG = self.remove_reference(self.EEG, self.reference_signal, rereferenced_index)\n    self.raw._data = self.EEG\n    noisy_detector = NoisyChannels(self.raw, random_state=self.random_state, matlab_strict=self.matlab_strict)\n    noisy_detector.find_all_bads(**self.ransac_settings)\n    self.bad_before_interpolation = noisy_detector.get_bads(verbose=True)\n    self.EEG_before_interpolation = self.EEG.copy()\n    self.noisy_channels_before_interpolation = noisy_detector.get_bads(as_dict=True)\n    self.noisy_channels_before_interpolation['bad_by_manual'] = self.bads_manual\n    self._extra_info['interpolated'] = noisy_detector._extra_info\n    bad_channels = _union(self.bad_before_interpolation, self.unusable_channels)\n    self.raw.info['bads'] = bad_channels\n    if self.matlab_strict:\n        _eeglab_interpolate_bads(self.raw)\n    else:\n        self.raw.interpolate_bads()\n    reference_correct = np.nanmean(self.raw.get_data(picks=self.reference_channels), axis=0)\n    self.EEG = self.raw.get_data()\n    self.EEG = self.remove_reference(self.EEG, reference_correct, rereferenced_index)\n    self.reference_signal_new = self.reference_signal + reference_correct\n    self.raw._data = self.EEG\n    self.interpolated_channels = bad_channels\n    noisy_detector = NoisyChannels(self.raw, random_state=self.random_state, matlab_strict=self.matlab_strict)\n    noisy_detector.find_all_bads(**self.ransac_settings)\n    self.still_noisy_channels = noisy_detector.get_bads()\n    self.raw.info['bads'] = self.still_noisy_channels\n    self.noisy_channels_after_interpolation = noisy_detector.get_bads(as_dict=True)\n    self._extra_info['remaining_bad'] = noisy_detector._extra_info\n    return self"
        },
        {
          "text": "def _predict_median_signals_channelwise(data, interpolation_mats, random_ch_picks, chunk_size, matlab_strict):\n    \"\"\"Calculate the median RANSAC-predicted signal for a given chunk of channels.\n\n    Parameters\n    ----------\n    data : np.ndarray\n        A 2-D array containing the EEG signals from all currently-good channels.\n    interpolation_mats : list of np.ndarray\n        A set of channel interpolation matrices, one for each RANSAC sample of\n        channels.\n    random_ch_picks : list of list of int\n        A list containing multiple random subsets of currently-good channels.\n    chunk_size : int\n        The number of channels to predict in the current chunk.\n    matlab_strict : bool\n        Whether or not RANSAC should strictly follow MATLAB PREP's internal\n        math, ignoring any improvements made in PyPREP over the original code.\n\n    Returns\n    -------\n    predicted_chans : np.ndarray\n        The median RANSAC-predicted EEG signals for the given chunk of channels.\n\n    \"\"\"\n    ransac_samples = len(interpolation_mats)\n    n_timepts = data.shape[1]\n    _verify_free_ram(data, ransac_samples, chunk_size)\n    eeg_predictions = np.zeros((chunk_size, n_timepts, ransac_samples))\n    for sample in range(ransac_samples):\n        reconstr_idx = random_ch_picks[sample]\n        interp_mat = interpolation_mats[sample][:, reconstr_idx]\n        eeg_predictions[..., sample] = np.matmul(interp_mat, data[reconstr_idx, :])\n    if matlab_strict:\n        median_idx = int(_mat_round(ransac_samples / 2.0) - 1)\n        eeg_predictions.sort(axis=-1)\n        return eeg_predictions[:, :, median_idx]\n    else:\n        return np.median(eeg_predictions, axis=-1, overwrite_input=True)"
        },
        {
          "text": "def _ransac_by_channel(data, interpolation_mats, win_size, win_count, chans_to_predict, random_ch_picks, matlab_strict):\n    \"\"\"Calculate correlations of channels with their RANSAC-predicted values.\n\n    This function calculates RANSAC correlations on one (or more) full channels\n    at once, requiring RAM equivalent to [channels per chunk * sample rate *\n    length of recording in seconds] to run. Generally, this method will use\n    more RAM than :func:`_ransac_by_window`, but may be faster for systems with\n    large amounts of RAM.\n\n    Parameters\n    ----------\n    data : np.ndarray\n        A 2-D array containing the EEG signals from all currently-good channels.\n    interpolation_mats : list of np.ndarray\n        A set of channel interpolation matrices, one for each RANSAC sample of\n        channels.\n    win_size : int\n        Number of frames/samples of EEG data in each RANSAC correlation window.\n    win_count: int\n        Number of RANSAC correlation windows.\n    chans_to_predict : list of int\n        Indices of the channels to predict (as they appear in `data`) within the\n        current chunk.\n    random_ch_picks : list of list of int\n        A list containing multiple random subsets of currently-good channels.\n    matlab_strict : bool\n        Whether or not RANSAC should strictly follow MATLAB PREP's internal\n        math, ignoring any improvements made in PyPREP over the original code.\n\n    Returns\n    -------\n    correlations : np.ndarray\n        Correlations of the given channels to their predicted values within each\n        RANSAC window.\n\n    \"\"\"\n    chunk_size = len(chans_to_predict)\n    correlations = np.ones((win_count, chunk_size))\n    predicted_chans = _predict_median_signals_channelwise(data=data, interpolation_mats=interpolation_mats, random_ch_picks=random_ch_picks, chunk_size=len(chans_to_predict), matlab_strict=matlab_strict)\n    data_window = data[chans_to_predict, :win_size * win_count]\n    data_window = data_window.reshape(chunk_size, win_count, win_size)\n    data_window = data_window.swapaxes(1, 0)\n    pred_window = predicted_chans[:chunk_size, :win_size * win_count]\n    pred_window = pred_window.reshape(chunk_size, win_count, win_size)\n    pred_window = pred_window.swapaxes(1, 0)\n    for k in range(win_count):\n        data_portion = data_window[k, :, :]\n        pred_portion = pred_window[k, :, :]\n        R = _correlate_arrays(data_portion, pred_portion, matlab_strict)\n        correlations[k, :] = R\n    return correlations"
        },
        {
          "text": "def _ransac_by_window(data, interpolation_mats, win_size, win_count, matlab_strict):\n    \"\"\"Calculate correlations of channels with their RANSAC-predicted values.\n\n    This function calculates RANSAC correlations for each RANSAC window\n    individually, requiring RAM equivalent to [channels * sample rate * seconds\n    per RANSAC window] to run. Generally, this method will use less RAM than\n    :func:`_ransac_by_channel`, with the exception of short recordings with high\n    electrode counts.\n\n    Parameters\n    ----------\n    data : np.ndarray\n        A 2-D array containing the EEG signals from all currently-good channels.\n    interpolation_mats : list of np.ndarray\n        A list of interpolation matrices, one for each RANSAC sample of channels.\n    win_size : int\n        Number of frames/samples of EEG data in each RANSAC correlation window.\n    win_count: int\n        Number of RANSAC correlation windows.\n    matlab_strict : bool\n        Whether or not RANSAC should strictly follow MATLAB PREP's internal\n        math, ignoring any improvements made in PyPREP over the original code.\n\n    Returns\n    -------\n    correlations : np.ndarray\n        Correlations of the given channels to their predicted values within each\n        RANSAC window.\n\n    \"\"\"\n    ch_count = data.shape[0]\n    correlations = np.ones((win_count, ch_count))\n    pb = ProgressBar(range(win_count))\n    for window in pb:\n        start = window * win_size\n        end = (window + 1) * win_size\n        actual = data[:, start:end]\n        predicted = _predict_median_signals(actual, interpolation_mats, matlab_strict)\n        correlations[window, :] = _correlate_arrays(actual, predicted, matlab_strict)\n    return correlations"
        }
      ]
    }
  },
  {
    "query_id": "pyprep_reference.py_robust_reference_doc",
    "prompt": "How does the robust_reference function detect noisy channels and compute the robust reference signal?",
    "data": {
      "docs": [
        {
          "text": "def robust_reference(self, max_iterations=4):\n    \"\"\"Detect bad channels and estimate the robust reference signal.\n\n        This function implements the functionality of the `robustReference` function\n        as part of the PREP pipeline on mne raw object.\n\n        Parameters\n        ----------\n        max_iterations : int, optional\n            The maximum number of iterations of noisy channel removal to perform\n            during robust referencing. Defaults to ``4``.\n\n        Returns\n        -------\n        noisy_channels: dict\n            A dictionary of names of noisy channels detected from all methods\n            after referencing.\n        reference_signal: np.ndarray, shape(n, )\n            Estimation of the 'true' signal mean\n\n        \"\"\"\n    raw = self.raw.copy()\n    raw._data = removeTrend(raw.get_data(), self.sfreq, matlab_strict=self.matlab_strict)\n    noisy_detector = NoisyChannels(raw, do_detrend=False, random_state=self.random_state, matlab_strict=self.matlab_strict)\n    noisy_detector.find_all_bads(**self.ransac_settings)\n    self.noisy_channels_original = noisy_detector.get_bads(as_dict=True)\n    self._extra_info['initial_bad'] = noisy_detector._extra_info\n    logger.info(f'Bad channels: {self.noisy_channels_original}')\n    self.unusable_channels = _union(noisy_detector.bad_by_nan + noisy_detector.bad_by_flat, noisy_detector.bad_by_SNR + self.bads_manual)\n    reference_channels = _set_diff(self.reference_channels, self.unusable_channels)\n    noisy = {'bad_by_nan': noisy_detector.bad_by_nan, 'bad_by_flat': noisy_detector.bad_by_flat, 'bad_by_deviation': [], 'bad_by_hf_noise': [], 'bad_by_correlation': [], 'bad_by_SNR': [], 'bad_by_dropout': [], 'bad_by_ransac': [], 'bad_by_manual': self.bads_manual, 'bad_all': []}\n    signal = raw.get_data()\n    self.reference_signal = np.nanmedian(raw.get_data(picks=reference_channels), axis=0)\n    reference_index = [self.ch_names_eeg.index(ch) for ch in reference_channels]\n    signal_tmp = self.remove_reference(signal, self.reference_signal, reference_index)\n    raw_tmp = raw.copy()\n    iterations = 0\n    previous_bads = set()\n    while True:\n        raw_tmp._data = signal_tmp\n        noisy_detector = NoisyChannels(raw_tmp, do_detrend=False, random_state=self.random_state, matlab_strict=self.matlab_strict)\n        noisy_detector.find_all_bads(**self.ransac_settings)\n        noisy_new = noisy_detector.get_bads(as_dict=True)\n        ignore = ['bad_by_SNR', 'bad_all']\n        if self.matlab_strict:\n            ignore += ['bad_by_dropout']\n        bad_chans = set()\n        for bad_type in noisy_new.keys():\n            noisy[bad_type] = _union(noisy[bad_type], noisy_new[bad_type])\n            if bad_type not in ignore:\n                bad_chans.update(noisy[bad_type])\n        noisy['bad_by_manual'] = self.bads_manual\n        noisy['bad_all'] = list(bad_chans) + self.bads_manual\n        logger.info(f'Bad channels: {noisy}')\n        if iterations > 1 and (len(bad_chans) == 0 or bad_chans == previous_bads) or iterations > max_iterations:\n            logger.info('Robust reference done')\n            self.noisy_channels = noisy\n            break\n        previous_bads = bad_chans.copy()\n        if raw_tmp.info['nchan'] - len(bad_chans) < 2:\n            raise ValueError('RobustReference:TooManyBad Could not perform a robust reference -- not enough good channels')\n        if len(bad_chans) > 0:\n            raw_tmp._data = signal.copy()\n            raw_tmp.info['bads'] = list(bad_chans)\n            if self.matlab_strict:\n                _eeglab_interpolate_bads(raw_tmp)\n            else:\n                raw_tmp.interpolate_bads()\n        self.reference_signal = np.nanmean(raw_tmp.get_data(picks=reference_channels), axis=0)\n        signal_tmp = self.remove_reference(signal, self.reference_signal, reference_index)\n        iterations = iterations + 1\n        logger.info(f'Iterations: {iterations}')\n    return (self.noisy_channels, self.reference_signal)"
        },
        {
          "text": "def perform_reference(self, max_iterations=4):\n    \"\"\"Estimate the true signal mean and interpolate bad channels.\n\n        Parameters\n        ----------\n        max_iterations : int, optional\n            The maximum number of iterations of noisy channel removal to perform\n            during robust referencing. Defaults to ``4``.\n\n        This function implements the functionality of the `performReference` function\n        as part of the PREP pipeline on mne raw object.\n\n        Notes\n        -----\n        This function calls ``robust_reference`` first.\n        Currently this function only implements the functionality of default\n        settings, i.e., ``doRobustPost``.\n\n        \"\"\"\n    self.robust_reference(max_iterations)\n    dummy = self.raw.copy()\n    dummy.info['bads'] = self.noisy_channels['bad_all']\n    if self.matlab_strict:\n        _eeglab_interpolate_bads(dummy)\n    else:\n        dummy.interpolate_bads()\n    self.reference_signal = np.nanmean(dummy.get_data(picks=self.reference_channels), axis=0)\n    del dummy\n    rereferenced_index = [self.ch_names_eeg.index(ch) for ch in self.rereferenced_channels]\n    self.EEG = self.remove_reference(self.EEG, self.reference_signal, rereferenced_index)\n    self.raw._data = self.EEG\n    noisy_detector = NoisyChannels(self.raw, random_state=self.random_state, matlab_strict=self.matlab_strict)\n    noisy_detector.find_all_bads(**self.ransac_settings)\n    self.bad_before_interpolation = noisy_detector.get_bads(verbose=True)\n    self.EEG_before_interpolation = self.EEG.copy()\n    self.noisy_channels_before_interpolation = noisy_detector.get_bads(as_dict=True)\n    self.noisy_channels_before_interpolation['bad_by_manual'] = self.bads_manual\n    self._extra_info['interpolated'] = noisy_detector._extra_info\n    bad_channels = _union(self.bad_before_interpolation, self.unusable_channels)\n    self.raw.info['bads'] = bad_channels\n    if self.matlab_strict:\n        _eeglab_interpolate_bads(self.raw)\n    else:\n        self.raw.interpolate_bads()\n    reference_correct = np.nanmean(self.raw.get_data(picks=self.reference_channels), axis=0)\n    self.EEG = self.raw.get_data()\n    self.EEG = self.remove_reference(self.EEG, reference_correct, rereferenced_index)\n    self.reference_signal_new = self.reference_signal + reference_correct\n    self.raw._data = self.EEG\n    self.interpolated_channels = bad_channels\n    noisy_detector = NoisyChannels(self.raw, random_state=self.random_state, matlab_strict=self.matlab_strict)\n    noisy_detector.find_all_bads(**self.ransac_settings)\n    self.still_noisy_channels = noisy_detector.get_bads()\n    self.raw.info['bads'] = self.still_noisy_channels\n    self.noisy_channels_after_interpolation = noisy_detector.get_bads(as_dict=True)\n    self._extra_info['remaining_bad'] = noisy_detector._extra_info\n    return self"
        },
        {
          "text": "def find_bad_by_SNR(self):\n    \"\"\"Detect channels that have a low signal-to-noise ratio.\n\n        Channels are considered \"bad-by-SNR\" if they are bad by both high-frequency\n        noise and bad by low correlation.\n\n        \"\"\"\n    if not len(self._extra_info['bad_by_hf_noise']) > 1:\n        self.find_bad_by_hfnoise()\n    if not len(self._extra_info['bad_by_correlation']):\n        self.find_bad_by_correlation()\n    bad_by_hf = set(self.bad_by_hf_noise)\n    bad_by_corr = set(self.bad_by_correlation)\n    self.bad_by_SNR = list(bad_by_corr.intersection(bad_by_hf))"
        },
        {
          "text": "def find_bad_by_ransac(self, n_samples=50, sample_prop=0.25, corr_thresh=0.75, frac_bad=0.4, corr_window_secs=5.0, channel_wise=False, max_chunk_size=None):\n    \"\"\"Detect channels that are predicted poorly by other channels.\n\n        This method uses a random sample consensus approach (RANSAC, see [1]_,\n        and a short discussion in [2]_) to try and predict what the signal should\n        be for each channel based on the signals and spatial locations of other\n        currently-good channels. RANSAC correlations are calculated by splitting\n        the recording into non-overlapping windows of time (default: 5 seconds)\n        and correlating each channel's RANSAC-predicted signal with its actual\n        signal within each window.\n\n        A RANSAC window is considered \"bad\" for a channel if its predicted signal\n        vs. actual signal correlation falls below the given correlation threshold\n        (default: ``0.75``). A channel is considered \"bad-by-RANSAC\" if its fraction\n        of bad RANSAC windows is above the given threshold (default: ``0.4``).\n\n        Due to its random sampling component, the channels identified as\n        \"bad-by-RANSAC\" may vary slightly between calls of this method.\n        Additionally, bad channels may vary between different montages given that\n        RANSAC's signal predictions are based on the spatial coordinates of each\n        electrode.\n\n        This method is a wrapper for the :func:`~ransac.find_bad_by_ransac`\n        function.\n\n        .. warning:: For optimal performance, RANSAC requires that channels bad by\n                     deviation, correlation, and/or dropout have already been\n                     flagged. Otherwise RANSAC will attempt to use those channels\n                     when making signal predictions, decreasing accuracy and thus\n                     increasing the likelihood of false positives.\n\n        Parameters\n        ----------\n        n_samples : int, optional\n            Number of random channel samples to use for RANSAC. Defaults\n            to ``50``.\n        sample_prop : float, optional\n            Proportion of total channels to use for signal prediction per RANSAC\n            sample. This needs to be in the range [0, 1], where 0 would mean no\n            channels would be used and 1 would mean all channels would be used\n            (neither of which would be useful values). Defaults to ``0.25``\n            (e.g., 16 channels per sample for a 64-channel dataset).\n        corr_thresh : float, optional\n            The minimum predicted vs. actual signal correlation for a channel to\n            be considered good within a given RANSAC window. Defaults\n            to ``0.75``.\n        frac_bad : float, optional\n            The minimum fraction of bad (i.e., below-threshold) RANSAC windows\n            for a channel to be considered bad-by-RANSAC. Defaults to ``0.4``.\n        corr_window_secs : float, optional\n            The duration (in seconds) of each RANSAC correlation window. Defaults\n            to 5 seconds.\n        channel_wise : bool, optional\n            Whether RANSAC should predict signals for chunks of channels over the\n            entire signal length (\"channel-wise RANSAC\", see `max_chunk_size`\n            parameter). If ``False``, RANSAC will instead predict signals for all\n            channels at once but over a number of smaller time windows instead of\n            over the entire signal length (\"window-wise RANSAC\"). Channel-wise\n            RANSAC generally has higher RAM demands than window-wise RANSAC\n            (especially if `max_chunk_size` is ``None``), but can be faster on\n            systems with lots of RAM to spare. Defaults to ``False``.\n        max_chunk_size : {int, None}, optional\n            The maximum number of channels to predict at once during\n            channel-wise RANSAC. If ``None``, RANSAC will use the largest chunk\n            size that will fit into the available RAM, which may slow down\n            other programs on the host system. If using window-wise RANSAC\n            (the default), this parameter has no effect. Defaults to ``None``.\n\n        References\n        ----------\n        .. [1] Fischler, M.A., Bolles, R.C. (1981). Random sample consensus: A\n            Paradigm for Model Fitting with Applications to Image Analysis and\n            Automated Cartography. Communications of the ACM, 24, 381-395\n        .. [2] Jas, M., Engemann, D.A., Bekhti, Y., Raimondo, F., Gramfort, A.\n            (2017). Autoreject: Automated Artifact Rejection for MEG and EEG\n            Data. NeuroImage, 159, 417-429\n\n        \"\"\"\n    if self.EEGFiltered is None:\n        self.EEGFiltered = self._get_filtered_data()\n    exclude_from_ransac = self.bad_by_correlation + self.bad_by_deviation + self.bad_by_dropout\n    if self.matlab_strict:\n        random_state = self.random_state.get_state()\n        rng = np.random.RandomState()\n        rng.set_state(random_state)\n    else:\n        rng = self.random_state\n    (self.bad_by_ransac, ch_correlations_usable) = find_bad_by_ransac(self.EEGFiltered, self.sample_rate, self.ch_names_new, self.raw_mne._get_channel_positions()[self.usable_idx, :], exclude_from_ransac, n_samples, sample_prop, corr_thresh, frac_bad, corr_window_secs, channel_wise, max_chunk_size, rng, self.matlab_strict)\n    n_ransac_windows = ch_correlations_usable.shape[0]\n    ch_correlations = np.ones((n_ransac_windows, self.n_chans_original))\n    ch_correlations[:, self.usable_idx] = ch_correlations_usable\n    self._extra_info['bad_by_ransac'] = {'ransac_correlations': ch_correlations, 'bad_window_fractions': np.mean(ch_correlations < corr_thresh, axis=0)}"
        },
        {
          "text": "def find_bad_by_deviation(self, deviation_threshold=5.0):\n    \"\"\"Detect channels with abnormally high or low overall amplitudes.\n\n        A channel is considered \"bad-by-deviation\" if its amplitude deviates\n        considerably from the median channel amplitude, as calculated using a\n        robust Z-scoring method and the given deviation threshold.\n\n        Amplitude Z-scores are calculated using the formula\n        ``(channel_amplitude - median_amplitude) / amplitude_sd``, where\n        channel amplitudes are calculated using a robust outlier-resistant estimate\n        of the signals' standard deviations (IQR scaled to units of SD), and the\n        amplitude SD is the IQR-based SD of those amplitudes.\n\n        Parameters\n        ----------\n        deviation_threshold : float, optional\n            The minimum absolute z-score of a channel for it to be considered\n            bad-by-deviation. Defaults to ``5.0``.\n\n        \"\"\"\n    IQR_TO_SD = 0.7413\n    chan_amplitudes = _mat_iqr(self.EEGData, axis=1) * IQR_TO_SD\n    amp_sd = _mat_iqr(chan_amplitudes) * IQR_TO_SD\n    amp_median = np.nanmedian(chan_amplitudes)\n    amplitude_zscore = np.zeros(self.n_chans_original)\n    amplitude_zscore[self.usable_idx] = (chan_amplitudes - amp_median) / amp_sd\n    abnormal_amplitude = np.abs(amplitude_zscore) > deviation_threshold\n    deviation_channel_mask = np.isnan(amplitude_zscore) | abnormal_amplitude\n    deviation_channels = self.ch_names_original[deviation_channel_mask]\n    self.bad_by_deviation = deviation_channels.tolist()\n    self._extra_info['bad_by_deviation'].update({'median_channel_amplitude': amp_median, 'channel_amplitude_sd': amp_sd, 'robust_channel_deviations': amplitude_zscore})"
        }
      ]
    }
  },
  {
    "query_id": "pyprep_reference.py_remove_reference_doc",
    "prompt": "How do I remove a reference signal from EEG data using PyPREP?",
    "data": {
      "docs": [
        {
          "text": "@staticmethod\ndef remove_reference(signal, reference, index=None):\n    \"\"\"Remove the reference signal from the original EEG signal.\n\n        This function implements the functionality of the `removeReference` function\n        as part of the PREP pipeline on mne raw object.\n\n        Parameters\n        ----------\n        signal : np.ndarray, shape(channels, times)\n            The original EEG signal.\n        reference : np.ndarray, shape(times,)\n            The reference signal.\n        index : {list, None}, optional\n            A list of channel indices from which the reference signal should be\n            subtracted. Defaults to all channels in `signal`.\n\n        Returns\n        -------\n        np.ndarray, shape(channels, times)\n            The referenced EEG signal.\n\n        \"\"\"\n    if np.ndim(signal) != 2:\n        raise ValueError('RemoveReference: EEG signal must be 2D array (channels * times)')\n    if np.ndim(reference) != 1:\n        raise ValueError('RemoveReference: Reference signal must be 1D array')\n    if np.shape(signal)[1] != np.shape(reference)[0]:\n        raise ValueError('RemoveReference: The second dimension of EEG signal must be the same with the length of reference signal')\n    if index is None:\n        signal_referenced = signal - reference\n    else:\n        if not isinstance(index, list):\n            raise TypeError(f'RemoveReference: Expected type list, got {type(index)} instead')\n        signal_referenced = signal.copy()\n        signal_referenced[np.asarray(index), :] = signal[np.asarray(index), :] - reference\n    return signal_referenced"
        },
        {
          "text": "def removeTrend(EEG, sample_rate, detrendType='high pass', detrendCutoff=1.0, detrendChannels=None, matlab_strict=False):\n    \"\"\"Remove trends (i.e., slow drifts in baseline) from an array of EEG data.\n\n    Parameters\n    ----------\n    EEG : np.ndarray\n        A 2-D array of EEG data to detrend.\n    sample_rate : float\n        The sample rate (in Hz) of the input EEG data.\n    detrendType : str, optional\n        Type of detrending to be performed: must be one of 'high pass',\n        'high pass sinc, or 'local detrend'. Defaults to 'high pass'.\n    detrendCutoff : float, optional\n        The high-pass cutoff frequency (in Hz) to use for detrending. Defaults\n        to 1.0 Hz.\n    detrendChannels : {list, None}, optional\n        List of the indices of all channels that require detrending/filtering.\n        If ``None``, all channels are used (default).\n    matlab_strict : bool, optional\n        Whether or not detrending should strictly follow MATLAB PREP's internal\n        math, ignoring any improvements made in PyPREP over the original code\n        (see :ref:`matlab-diffs` for more details). Defaults to ``False``.\n\n    Returns\n    -------\n    EEG : np.ndarray\n        A 2-D array containing the filtered/detrended EEG data.\n\n    Notes\n    -----\n    High-pass filtering is implemented using the MNE filter function\n    :func:``mne.filter.filter_data`` unless `matlab_strict` is ``True``, in\n    which case it is performed using a minimal re-implementation of EEGLAB's\n    ``pop_eegfiltnew``. Local detrending is performed using a Python\n    re-implementation of the ``runline`` function from the Chronux package for\n    MATLAB [1]_.\n\n    References\n    ----------\n    .. [1] http://chronux.org/\n\n    \"\"\"\n    if len(EEG.shape) == 1:\n        EEG = np.reshape(EEG, (1, EEG.shape[0]))\n    if detrendType.lower() == 'high pass':\n        if matlab_strict:\n            picks = detrendChannels if detrendChannels else range(EEG.shape[0])\n            filt = _eeglab_create_highpass(detrendCutoff, sample_rate)\n            EEG[picks, :] = _eeglab_fir_filter(EEG[picks, :], filt)\n        else:\n            EEG = mne.filter.filter_data(EEG, sfreq=sample_rate, l_freq=detrendCutoff, h_freq=None, picks=detrendChannels)\n    elif detrendType.lower() == 'high pass sinc':\n        fOrder = np.round(14080 * sample_rate / 512)\n        fOrder = int(fOrder + fOrder % 2)\n        EEG = mne.filter.filter_data(data=EEG, sfreq=sample_rate, l_freq=1, h_freq=None, picks=detrendChannels, filter_length=fOrder, fir_window='blackman')\n    elif detrendType.lower() == 'local detrend':\n        if detrendChannels is None:\n            detrendChannels = np.arange(0, EEG.shape[0])\n        windowSize = 1.5 / detrendCutoff\n        windowSize = np.minimum(windowSize, EEG.shape[1])\n        stepSize = 0.02\n        EEG = np.transpose(EEG)\n        n = np.round(sample_rate * windowSize)\n        dn = np.round(sample_rate * stepSize)\n        if dn > n or dn < 1:\n            logging.error('Step size should be less than the window size and contain at least 1 sample')\n        if n == EEG.shape[0]:\n            pass\n        else:\n            for ch in detrendChannels:\n                EEG[:, ch] = runline(EEG[:, ch], int(n), int(dn))\n        EEG = np.transpose(EEG)\n    else:\n        logging.warning('No filtering/detreding performed since the detrend type did not match')\n    return EEG"
        },
        {
          "text": "def __init__(self, raw, do_detrend=True, random_state=None, matlab_strict=False):\n    assert isinstance(raw, mne.io.BaseRaw)\n    raw.load_data()\n    self.raw_mne = raw.copy()\n    self.bad_by_manual = raw.info['bads']\n    self.raw_mne.pick('eeg')\n    self.sample_rate = raw.info['sfreq']\n    if do_detrend:\n        self.raw_mne._data = removeTrend(self.raw_mne.get_data(), self.sample_rate, matlab_strict=matlab_strict)\n    self.matlab_strict = matlab_strict\n    self._extra_info = {'bad_by_deviation': {}, 'bad_by_hf_noise': {}, 'bad_by_correlation': {}, 'bad_by_dropout': {}, 'bad_by_ransac': {}}\n    self.random_state = check_random_state(random_state)\n    self.bad_by_nan = []\n    self.bad_by_flat = []\n    self.bad_by_deviation = []\n    self.bad_by_hf_noise = []\n    self.bad_by_correlation = []\n    self.bad_by_SNR = []\n    self.bad_by_dropout = []\n    self.bad_by_ransac = []\n    ch_names = np.asarray(self.raw_mne.info['ch_names'])\n    self.ch_names_original = ch_names\n    self.n_chans_original = len(ch_names)\n    self.n_samples = raw.get_data().shape[1]\n    self.find_bad_by_nan_flat()\n    bads_by_nan_flat = self.bad_by_nan + self.bad_by_flat\n    self.usable_idx = np.isin(ch_names, bads_by_nan_flat, invert=True)\n    self.EEGData = self.raw_mne.get_data(picks=ch_names[self.usable_idx])\n    self.EEGFiltered = None\n    self.ch_names_new = np.asarray(ch_names[self.usable_idx])\n    self.n_chans_new = len(self.ch_names_new)"
        },
        {
          "text": "def _get_filtered_data(self):\n    \"\"\"Apply a [1 Hz - 50 Hz] bandpass filter to the EEG signal.\n\n        Only applied if the sample rate is above 100 Hz to avoid violating the\n        Nyquist theorem.\n\n        \"\"\"\n    if self.sample_rate <= 100:\n        return self.EEGData.copy()\n    bandpass_filter = _filter_design(N_order=100, amp=np.array([1, 1, 0, 0]), freq=np.array([0, 90 / self.sample_rate, 100 / self.sample_rate, 1]))\n    EEG_filt = np.zeros_like(self.EEGData)\n    for i in range(EEG_filt.shape[0]):\n        EEG_filt[i, :] = signal.filtfilt(bandpass_filter, 1, self.EEGData[i, :])\n    return EEG_filt"
        },
        {
          "text": "def fit(self):\n    \"\"\"Run the whole PREP pipeline.\"\"\"\n    if len(self.prep_params['line_freqs']) != 0:\n        self.EEG_new = removeTrend(self.EEG_raw, self.sfreq, matlab_strict=self.matlab_strict)\n        linenoise = self.prep_params['line_freqs']\n        if self.filter_kwargs is None:\n            self.EEG_clean = mne.filter.notch_filter(self.EEG_new, Fs=self.sfreq, freqs=linenoise, method='spectrum_fit', mt_bandwidth=2, p_value=0.01, filter_length='10s')\n        else:\n            self.EEG_clean = mne.filter.notch_filter(self.EEG_new, Fs=self.sfreq, freqs=linenoise, **self.filter_kwargs)\n        self.EEG = self.EEG_raw - self.EEG_new + self.EEG_clean\n        self.raw_eeg._data = self.EEG\n    reference = Reference(self.raw_eeg, self.prep_params, random_state=self.random_state, matlab_strict=self.matlab_strict, **self.ransac_settings)\n    reference.perform_reference(self.prep_params['max_iterations'])\n    self.raw_eeg = reference.raw\n    self.noisy_channels_original = reference.noisy_channels_original\n    self.noisy_channels_before_interpolation = reference.noisy_channels_before_interpolation\n    self.noisy_channels_after_interpolation = reference.noisy_channels_after_interpolation\n    self.bad_before_interpolation = reference.bad_before_interpolation\n    self.EEG_before_interpolation = reference.EEG_before_interpolation\n    self.reference_before_interpolation = reference.reference_signal\n    self.reference_after_interpolation = reference.reference_signal_new\n    self.interpolated_channels = reference.interpolated_channels\n    self.still_noisy_channels = reference.still_noisy_channels\n    return self"
        }
      ]
    }
  },
  {
    "query_id": "pyprep_utils.py__union_doc",
    "prompt": "What does the union function in pyprep_utils.py do?",
    "data": {
      "docs": [
        {
          "text": "def _union(list1, list2):\n    return list(set(list1 + list2))"
        },
        {
          "text": "def _get_random_subset(x, size, rand_state):\n    \"\"\"Get a random subset of items from a list or array, without replacement.\n\n    Parameters\n    ----------\n    x : list or np.ndarray\n        One-dimensional array of items to sample from.\n    size : int\n        The number of items to sample. Must be less than the number of input\n        items.\n    rand_state : np.random.RandomState\n        A random state object to use for random number generation.\n\n    Returns\n    -------\n    sample : list\n        A random subset of the input items.\n\n    Notes\n    -----\n    This function generates random subsets identical to the internal\n    ``randsample`` function in MATLAB PREP's ``findNoisyChannels.m``, allowing\n    the same random seed to produce identical results across both PyPREP and\n    MATLAB PREP.\n\n    \"\"\"\n    sample = []\n    remaining = list(x)\n    for val in rand_state.rand(size):\n        index = round(1 + (len(remaining) - 1) * val) - 1\n        pick = remaining.pop(index)\n        sample.append(pick)\n    return sample"
        },
        {
          "text": "def _split_list(mylist, chunk_size):\n    \"\"\"Split list in chunks.\n\n    Parameters\n    ----------\n    my_list: list\n        list to split.\n    chunk_size: int\n        size of the lists returned.\n\n    Returns\n    -------\n    list\n        list of the chunked lists.\n\n    See: https://stackoverflow.com/a/312466/5201771\n    \"\"\"\n    return [mylist[offs:offs + chunk_size] for offs in range(0, len(mylist), chunk_size)]"
        },
        {
          "text": "def _predict_median_signals(window, interpolation_mats, matlab_strict=False):\n    \"\"\"Calculate the median RANSAC-predicted signal for a given window of data.\n\n    Parameters\n    ----------\n    window : np.ndarray\n        A 2-D window of EEG data with the shape `[channels, samples]`.\n    interpolation_mats : list of np.ndarray\n        A set of channel interpolation matrices, one for each RANSAC sample of\n        channels.\n    matlab_strict : bool\n        Whether or not RANSAC should strictly follow MATLAB PREP's internal\n        math, ignoring any improvements made in PyPREP over the original code.\n\n    Returns\n    -------\n    predicted : np.ndarray\n        The median RANSAC-predicted EEG signal for the given window of data.\n\n    Notes\n    -----\n    In MATLAB PREP, the median signal is calculated by sorting the different\n    predictions for each EEG sample/channel from low to high and then taking the value\n    at the middle index (as calculated by ``int(n_ransac_samples / 2.0)``) for each.\n    Because this logic only returns the correct result for odd numbers of samples, the\n    current function will instead return the true median signal across predictions\n    unless strict MATLAB equivalence is requested.\n\n    \"\"\"\n    ransac_samples = len(interpolation_mats)\n    merged_mats = np.concatenate(interpolation_mats, axis=0)\n    predictions_per_sample = np.reshape(np.matmul(merged_mats, window), (ransac_samples, window.shape[0], window.shape[1]))\n    if matlab_strict:\n        median_idx = int(_mat_round(ransac_samples / 2.0) - 1)\n        predictions_per_sample.sort(axis=0)\n        return predictions_per_sample[median_idx, :, :]\n    else:\n        return np.median(predictions_per_sample, axis=0)"
        },
        {
          "text": "def get_bads(self, verbose=False, as_dict=False):\n    \"\"\"Get the names of all channels currently flagged as bad.\n\n        Note that this method does not perform any bad channel detection itself,\n        and only reports channels already detected as bad by other methods.\n\n        Parameters\n        ----------\n        verbose : bool, optional\n            If ``True``, a summary of the channels currently flagged as by bad per\n            category is printed. Defaults to ``False``.\n        as_dict: bool, optional\n            If ``True``, this method will return a dict of the channels currently\n            flagged as bad by each individual bad channel type. If ``False``, this\n            method will return a list of all unique bad channels detected so far.\n            Defaults to ``False``.\n\n        Returns\n        -------\n        bads : list or dict\n            The names of all bad channels detected so far, either as a combined\n            list or a dict indicating the channels flagged bad by each type.\n\n        \"\"\"\n    bads = {'bad_by_nan': self.bad_by_nan, 'bad_by_flat': self.bad_by_flat, 'bad_by_deviation': self.bad_by_deviation, 'bad_by_hf_noise': self.bad_by_hf_noise, 'bad_by_correlation': self.bad_by_correlation, 'bad_by_SNR': self.bad_by_SNR, 'bad_by_dropout': self.bad_by_dropout, 'bad_by_ransac': self.bad_by_ransac, 'bad_by_manual': self.bad_by_manual}\n    all_bads = set()\n    for bad_chs in bads.values():\n        all_bads.update(bad_chs)\n    name_map = {'nan': 'NaN', 'hf_noise': 'HF noise', 'ransac': 'RANSAC'}\n    if verbose:\n        out = f'Found {len(all_bads)} uniquely bad channels:\\n'\n        for (bad_type, bad_chs) in bads.items():\n            bad_type = bad_type.replace('bad_by_', '')\n            if bad_type in name_map.keys():\n                bad_type = name_map[bad_type]\n            out += f'\\n{len(bad_chs)} by {bad_type}: {bad_chs}\\n'\n        logger.info(out)\n    if as_dict:\n        bads['bad_all'] = list(all_bads)\n    else:\n        bads = list(all_bads)\n    return bads"
        }
      ]
    }
  },
  {
    "query_id": "pyprep_utils.py__set_diff_doc",
    "prompt": "How do I find the difference between two sets in PyPREP?",
    "data": {
      "docs": [
        {
          "text": "def _set_diff(list1, list2):\n    return list(set(list1) - set(list2))"
        },
        {
          "text": "def find_bad_by_SNR(self):\n    \"\"\"Detect channels that have a low signal-to-noise ratio.\n\n        Channels are considered \"bad-by-SNR\" if they are bad by both high-frequency\n        noise and bad by low correlation.\n\n        \"\"\"\n    if not len(self._extra_info['bad_by_hf_noise']) > 1:\n        self.find_bad_by_hfnoise()\n    if not len(self._extra_info['bad_by_correlation']):\n        self.find_bad_by_correlation()\n    bad_by_hf = set(self.bad_by_hf_noise)\n    bad_by_corr = set(self.bad_by_correlation)\n    self.bad_by_SNR = list(bad_by_corr.intersection(bad_by_hf))"
        },
        {
          "text": "def _union(list1, list2):\n    return list(set(list1 + list2))"
        },
        {
          "text": "def _get_random_subset(x, size, rand_state):\n    \"\"\"Get a random subset of items from a list or array, without replacement.\n\n    Parameters\n    ----------\n    x : list or np.ndarray\n        One-dimensional array of items to sample from.\n    size : int\n        The number of items to sample. Must be less than the number of input\n        items.\n    rand_state : np.random.RandomState\n        A random state object to use for random number generation.\n\n    Returns\n    -------\n    sample : list\n        A random subset of the input items.\n\n    Notes\n    -----\n    This function generates random subsets identical to the internal\n    ``randsample`` function in MATLAB PREP's ``findNoisyChannels.m``, allowing\n    the same random seed to produce identical results across both PyPREP and\n    MATLAB PREP.\n\n    \"\"\"\n    sample = []\n    remaining = list(x)\n    for val in rand_state.rand(size):\n        index = round(1 + (len(remaining) - 1) * val) - 1\n        pick = remaining.pop(index)\n        sample.append(pick)\n    return sample"
        },
        {
          "text": "def _predict_median_signals(window, interpolation_mats, matlab_strict=False):\n    \"\"\"Calculate the median RANSAC-predicted signal for a given window of data.\n\n    Parameters\n    ----------\n    window : np.ndarray\n        A 2-D window of EEG data with the shape `[channels, samples]`.\n    interpolation_mats : list of np.ndarray\n        A set of channel interpolation matrices, one for each RANSAC sample of\n        channels.\n    matlab_strict : bool\n        Whether or not RANSAC should strictly follow MATLAB PREP's internal\n        math, ignoring any improvements made in PyPREP over the original code.\n\n    Returns\n    -------\n    predicted : np.ndarray\n        The median RANSAC-predicted EEG signal for the given window of data.\n\n    Notes\n    -----\n    In MATLAB PREP, the median signal is calculated by sorting the different\n    predictions for each EEG sample/channel from low to high and then taking the value\n    at the middle index (as calculated by ``int(n_ransac_samples / 2.0)``) for each.\n    Because this logic only returns the correct result for odd numbers of samples, the\n    current function will instead return the true median signal across predictions\n    unless strict MATLAB equivalence is requested.\n\n    \"\"\"\n    ransac_samples = len(interpolation_mats)\n    merged_mats = np.concatenate(interpolation_mats, axis=0)\n    predictions_per_sample = np.reshape(np.matmul(merged_mats, window), (ransac_samples, window.shape[0], window.shape[1]))\n    if matlab_strict:\n        median_idx = int(_mat_round(ransac_samples / 2.0) - 1)\n        predictions_per_sample.sort(axis=0)\n        return predictions_per_sample[median_idx, :, :]\n    else:\n        return np.median(predictions_per_sample, axis=0)"
        }
      ]
    }
  },
  {
    "query_id": "pyprep_utils.py__mat_round_doc",
    "prompt": "How can I round a number like MATLAB does, with .5 always rounding up?",
    "data": {
      "docs": [
        {
          "text": "def _mat_round(x):\n    \"\"\"Round a number to the nearest whole number.\n\n    Parameters\n    ----------\n    x : float\n        The number to round.\n\n    Returns\n    -------\n    rounded : float\n        The input value, rounded to the nearest whole number.\n\n    Notes\n    -----\n    MATLAB rounds all numbers ending in .5 up to the nearest integer, whereas\n    Python (and Numpy) rounds them to the nearest even number. This function\n    mimics MATLAB's behaviour.\n    \"\"\"\n    return np.ceil(x) if x % 1 >= 0.5 else np.floor(x)"
        },
        {
          "text": "def _mat_quantile(arr, q, axis=None):\n    \"\"\"Calculate the numeric value at quantile (`q`) for a given distribution.\n\n    Parameters\n    ----------\n    arr : np.ndarray\n        Input array containing samples from the distribution to summarize. Must\n        be either a 1-D or 2-D array.\n    q : float\n        The quantile to calculate for the input data. Must be between 0 and 1,\n        inclusive.\n    axis : {int, tuple of int, None}, optional\n        Axis along which quantile values should be calculated. Defaults to\n        calculating the value at the given quantile for the entire array.\n\n    Returns\n    -------\n    quantile : scalar or np.ndarray\n        If no axis is specified, returns the value at quantile (q) for the full\n        input array as a single numeric value. Otherwise, returns an\n        ``np.ndarray`` containing the values at quantile (q) for each row along\n        the specified axis.\n\n    Notes\n    -----\n    MATLAB calculates quantiles using different logic than Numpy: Numpy treats\n    the provided values as a whole population, whereas MATLAB treats them as a\n    sample from a population of unknown size and adjusts quantiles accordingly.\n    This function mimics MATLAB's logic to produce identical results.\n\n    \"\"\"\n    if len(arr) == 0:\n        return np.nan\n    arr_sorted = np.sort(arr, axis=axis)\n    if arr_sorted.ndim > 2:\n        raise ValueError(f'Only 1D and 2D arrays are supported (input has {arr_sorted.ndim} dimensions)')\n    if axis is None:\n        arr_sorted = arr_sorted.reshape(-1, 1)\n    else:\n        arr_sorted = np.moveaxis(arr_sorted, axis, 0)\n    quantiles = arr_sorted[0, :]\n    n = np.sum(np.isfinite(arr_sorted), axis=0)\n    n_usable = n[n > 1]\n    if np.any(n > 1):\n        q = np.asarray(q, dtype=np.float64)\n        q_adj = (q - 0.5) * n_usable / (n_usable - 1) + 0.5\n        exact_idx = (n_usable - 1) * np.clip(q_adj, 0, 1)\n        pre_idx = np.floor(exact_idx).astype(np.int32)\n        post_idx = np.ceil(exact_idx).astype(np.int32)\n        axis_idx = np.arange(len(n))[n > 1]\n        pre = arr_sorted[pre_idx, axis_idx]\n        post = arr_sorted[post_idx, axis_idx]\n        quantiles[n > 1] = pre + (post - pre) * (exact_idx - pre_idx)\n    return quantiles[0] if quantiles.size == 1 else quantiles"
        },
        {
          "text": "def _mat_iqr(arr, axis=None):\n    \"\"\"Calculate the inter-quartile range (IQR) for a given distribution.\n\n    Parameters\n    ----------\n    arr : np.ndarray\n        Input array containing samples from the distribution to summarize.\n    axis : {int, tuple of int, None}, optional\n        Axis along which IQRs should be calculated. Defaults to calculating the\n        IQR for the entire array.\n\n    Returns\n    -------\n    iqr : scalar or np.ndarray\n        If no axis is specified, returns the IQR for the full input array as a\n        single numeric value. Otherwise, returns an ``np.ndarray`` containing\n        the IQRs for each row along the specified axis.\n\n    Notes\n    -----\n    See notes for :func:`utils._mat_quantile`.\n\n    \"\"\"\n    return _mat_quantile(arr, 0.75, axis) - _mat_quantile(arr, 0.25, axis)"
        },
        {
          "text": "def _filter_design(N_order, amp, freq):\n    \"\"\"Create FIR low-pass filter for EEG data using frequency sampling method.\n\n    Parameters\n    ----------\n    N_order : int\n        Order of the filter.\n    amp : list of int\n        Amplitude vector for the frequencies.\n    freq : list of int\n        Frequency vector for which amplitude can be either 0 or 1.\n\n    Returns\n    -------\n    kernel : np.ndarray\n        Filter kernel.\n\n    \"\"\"\n    nfft = np.maximum(512, 2 ** np.ceil(math.log(100) / math.log(2)))\n    hamming_window = np.subtract(0.54, np.multiply(0.46, np.cos(np.divide(np.multiply(2 * math.pi, np.arange(N_order + 1)), N_order))))\n    pchip_interpolate = scipy.interpolate.PchipInterpolator(np.round(np.multiply(nfft, freq)), amp)\n    freq = pchip_interpolate(np.arange(nfft + 1))\n    freq = np.multiply(freq, np.exp(np.divide(np.multiply(-(0.5 * N_order) * sqrt(-1) * math.pi, np.arange(nfft + 1)), nfft)))\n    kernel = np.real(np.fft.ifft(np.concatenate([freq, np.conj(freq[len(freq) - 2:0:-1])])))\n    kernel = np.multiply(kernel[0:N_order + 1], np.transpose(hamming_window[:]))\n    return kernel"
        },
        {
          "text": "def find_bad_by_nan_flat(self, flat_threshold=1e-15):\n    \"\"\"Detect channels than contain NaN values or have near-flat signals.\n\n        A channel is considered flat if its standard deviation or its median\n        absolute deviation from the median (MAD) are below the provided flat\n        threshold (default: ``1e-15`` volts).\n\n        This method is run automatically when a ``NoisyChannels`` object is\n        initialized, preventing flat or NaN-containing channels from interfering\n        with the detection of other types of bad channels.\n\n        Parameters\n        ----------\n        flat_threshold : float, optional\n            The lowest standard deviation or MAD value for a channel to be\n            considered bad-by-flat. Defaults to ``1e-15`` volts (corresponds to\n            10e-10 \u00b5V in MATLAB PREP).\n        \"\"\"\n    EEGData = self.raw_mne.get_data()\n    nan_channel_mask = np.isnan(np.sum(EEGData, axis=1))\n    nan_channels = self.ch_names_original[nan_channel_mask]\n    flat_by_mad = median_abs_deviation(EEGData, axis=1) < flat_threshold\n    flat_by_stdev = np.std(EEGData, axis=1) < flat_threshold\n    flat_channel_mask = flat_by_mad | flat_by_stdev\n    flat_channels = self.ch_names_original[flat_channel_mask]\n    self.bad_by_nan = nan_channels.tolist()\n    self.bad_by_flat = flat_channels.tolist()"
        }
      ]
    }
  },
  {
    "query_id": "pyprep_utils.py__mat_quantile_doc",
    "prompt": "How do I calculate MATLAB-style quantiles for an array in PyPREP?",
    "data": {
      "docs": [
        {
          "text": "def _mat_quantile(arr, q, axis=None):\n    \"\"\"Calculate the numeric value at quantile (`q`) for a given distribution.\n\n    Parameters\n    ----------\n    arr : np.ndarray\n        Input array containing samples from the distribution to summarize. Must\n        be either a 1-D or 2-D array.\n    q : float\n        The quantile to calculate for the input data. Must be between 0 and 1,\n        inclusive.\n    axis : {int, tuple of int, None}, optional\n        Axis along which quantile values should be calculated. Defaults to\n        calculating the value at the given quantile for the entire array.\n\n    Returns\n    -------\n    quantile : scalar or np.ndarray\n        If no axis is specified, returns the value at quantile (q) for the full\n        input array as a single numeric value. Otherwise, returns an\n        ``np.ndarray`` containing the values at quantile (q) for each row along\n        the specified axis.\n\n    Notes\n    -----\n    MATLAB calculates quantiles using different logic than Numpy: Numpy treats\n    the provided values as a whole population, whereas MATLAB treats them as a\n    sample from a population of unknown size and adjusts quantiles accordingly.\n    This function mimics MATLAB's logic to produce identical results.\n\n    \"\"\"\n    if len(arr) == 0:\n        return np.nan\n    arr_sorted = np.sort(arr, axis=axis)\n    if arr_sorted.ndim > 2:\n        raise ValueError(f'Only 1D and 2D arrays are supported (input has {arr_sorted.ndim} dimensions)')\n    if axis is None:\n        arr_sorted = arr_sorted.reshape(-1, 1)\n    else:\n        arr_sorted = np.moveaxis(arr_sorted, axis, 0)\n    quantiles = arr_sorted[0, :]\n    n = np.sum(np.isfinite(arr_sorted), axis=0)\n    n_usable = n[n > 1]\n    if np.any(n > 1):\n        q = np.asarray(q, dtype=np.float64)\n        q_adj = (q - 0.5) * n_usable / (n_usable - 1) + 0.5\n        exact_idx = (n_usable - 1) * np.clip(q_adj, 0, 1)\n        pre_idx = np.floor(exact_idx).astype(np.int32)\n        post_idx = np.ceil(exact_idx).astype(np.int32)\n        axis_idx = np.arange(len(n))[n > 1]\n        pre = arr_sorted[pre_idx, axis_idx]\n        post = arr_sorted[post_idx, axis_idx]\n        quantiles[n > 1] = pre + (post - pre) * (exact_idx - pre_idx)\n    return quantiles[0] if quantiles.size == 1 else quantiles"
        },
        {
          "text": "def _mat_iqr(arr, axis=None):\n    \"\"\"Calculate the inter-quartile range (IQR) for a given distribution.\n\n    Parameters\n    ----------\n    arr : np.ndarray\n        Input array containing samples from the distribution to summarize.\n    axis : {int, tuple of int, None}, optional\n        Axis along which IQRs should be calculated. Defaults to calculating the\n        IQR for the entire array.\n\n    Returns\n    -------\n    iqr : scalar or np.ndarray\n        If no axis is specified, returns the IQR for the full input array as a\n        single numeric value. Otherwise, returns an ``np.ndarray`` containing\n        the IQRs for each row along the specified axis.\n\n    Notes\n    -----\n    See notes for :func:`utils._mat_quantile`.\n\n    \"\"\"\n    return _mat_quantile(arr, 0.75, axis) - _mat_quantile(arr, 0.25, axis)"
        },
        {
          "text": "def _predict_median_signals(window, interpolation_mats, matlab_strict=False):\n    \"\"\"Calculate the median RANSAC-predicted signal for a given window of data.\n\n    Parameters\n    ----------\n    window : np.ndarray\n        A 2-D window of EEG data with the shape `[channels, samples]`.\n    interpolation_mats : list of np.ndarray\n        A set of channel interpolation matrices, one for each RANSAC sample of\n        channels.\n    matlab_strict : bool\n        Whether or not RANSAC should strictly follow MATLAB PREP's internal\n        math, ignoring any improvements made in PyPREP over the original code.\n\n    Returns\n    -------\n    predicted : np.ndarray\n        The median RANSAC-predicted EEG signal for the given window of data.\n\n    Notes\n    -----\n    In MATLAB PREP, the median signal is calculated by sorting the different\n    predictions for each EEG sample/channel from low to high and then taking the value\n    at the middle index (as calculated by ``int(n_ransac_samples / 2.0)``) for each.\n    Because this logic only returns the correct result for odd numbers of samples, the\n    current function will instead return the true median signal across predictions\n    unless strict MATLAB equivalence is requested.\n\n    \"\"\"\n    ransac_samples = len(interpolation_mats)\n    merged_mats = np.concatenate(interpolation_mats, axis=0)\n    predictions_per_sample = np.reshape(np.matmul(merged_mats, window), (ransac_samples, window.shape[0], window.shape[1]))\n    if matlab_strict:\n        median_idx = int(_mat_round(ransac_samples / 2.0) - 1)\n        predictions_per_sample.sort(axis=0)\n        return predictions_per_sample[median_idx, :, :]\n    else:\n        return np.median(predictions_per_sample, axis=0)"
        },
        {
          "text": "def _predict_median_signals_channelwise(data, interpolation_mats, random_ch_picks, chunk_size, matlab_strict):\n    \"\"\"Calculate the median RANSAC-predicted signal for a given chunk of channels.\n\n    Parameters\n    ----------\n    data : np.ndarray\n        A 2-D array containing the EEG signals from all currently-good channels.\n    interpolation_mats : list of np.ndarray\n        A set of channel interpolation matrices, one for each RANSAC sample of\n        channels.\n    random_ch_picks : list of list of int\n        A list containing multiple random subsets of currently-good channels.\n    chunk_size : int\n        The number of channels to predict in the current chunk.\n    matlab_strict : bool\n        Whether or not RANSAC should strictly follow MATLAB PREP's internal\n        math, ignoring any improvements made in PyPREP over the original code.\n\n    Returns\n    -------\n    predicted_chans : np.ndarray\n        The median RANSAC-predicted EEG signals for the given chunk of channels.\n\n    \"\"\"\n    ransac_samples = len(interpolation_mats)\n    n_timepts = data.shape[1]\n    _verify_free_ram(data, ransac_samples, chunk_size)\n    eeg_predictions = np.zeros((chunk_size, n_timepts, ransac_samples))\n    for sample in range(ransac_samples):\n        reconstr_idx = random_ch_picks[sample]\n        interp_mat = interpolation_mats[sample][:, reconstr_idx]\n        eeg_predictions[..., sample] = np.matmul(interp_mat, data[reconstr_idx, :])\n    if matlab_strict:\n        median_idx = int(_mat_round(ransac_samples / 2.0) - 1)\n        eeg_predictions.sort(axis=-1)\n        return eeg_predictions[:, :, median_idx]\n    else:\n        return np.median(eeg_predictions, axis=-1, overwrite_input=True)"
        },
        {
          "text": "def _get_random_subset(x, size, rand_state):\n    \"\"\"Get a random subset of items from a list or array, without replacement.\n\n    Parameters\n    ----------\n    x : list or np.ndarray\n        One-dimensional array of items to sample from.\n    size : int\n        The number of items to sample. Must be less than the number of input\n        items.\n    rand_state : np.random.RandomState\n        A random state object to use for random number generation.\n\n    Returns\n    -------\n    sample : list\n        A random subset of the input items.\n\n    Notes\n    -----\n    This function generates random subsets identical to the internal\n    ``randsample`` function in MATLAB PREP's ``findNoisyChannels.m``, allowing\n    the same random seed to produce identical results across both PyPREP and\n    MATLAB PREP.\n\n    \"\"\"\n    sample = []\n    remaining = list(x)\n    for val in rand_state.rand(size):\n        index = round(1 + (len(remaining) - 1) * val) - 1\n        pick = remaining.pop(index)\n        sample.append(pick)\n    return sample"
        }
      ]
    }
  },
  {
    "query_id": "pyprep_utils.py__mat_iqr_doc",
    "prompt": "How can I calculate the inter-quartile range (IQR) like MATLAB does?",
    "data": {
      "docs": [
        {
          "text": "def _mat_iqr(arr, axis=None):\n    \"\"\"Calculate the inter-quartile range (IQR) for a given distribution.\n\n    Parameters\n    ----------\n    arr : np.ndarray\n        Input array containing samples from the distribution to summarize.\n    axis : {int, tuple of int, None}, optional\n        Axis along which IQRs should be calculated. Defaults to calculating the\n        IQR for the entire array.\n\n    Returns\n    -------\n    iqr : scalar or np.ndarray\n        If no axis is specified, returns the IQR for the full input array as a\n        single numeric value. Otherwise, returns an ``np.ndarray`` containing\n        the IQRs for each row along the specified axis.\n\n    Notes\n    -----\n    See notes for :func:`utils._mat_quantile`.\n\n    \"\"\"\n    return _mat_quantile(arr, 0.75, axis) - _mat_quantile(arr, 0.25, axis)"
        },
        {
          "text": "def _mat_quantile(arr, q, axis=None):\n    \"\"\"Calculate the numeric value at quantile (`q`) for a given distribution.\n\n    Parameters\n    ----------\n    arr : np.ndarray\n        Input array containing samples from the distribution to summarize. Must\n        be either a 1-D or 2-D array.\n    q : float\n        The quantile to calculate for the input data. Must be between 0 and 1,\n        inclusive.\n    axis : {int, tuple of int, None}, optional\n        Axis along which quantile values should be calculated. Defaults to\n        calculating the value at the given quantile for the entire array.\n\n    Returns\n    -------\n    quantile : scalar or np.ndarray\n        If no axis is specified, returns the value at quantile (q) for the full\n        input array as a single numeric value. Otherwise, returns an\n        ``np.ndarray`` containing the values at quantile (q) for each row along\n        the specified axis.\n\n    Notes\n    -----\n    MATLAB calculates quantiles using different logic than Numpy: Numpy treats\n    the provided values as a whole population, whereas MATLAB treats them as a\n    sample from a population of unknown size and adjusts quantiles accordingly.\n    This function mimics MATLAB's logic to produce identical results.\n\n    \"\"\"\n    if len(arr) == 0:\n        return np.nan\n    arr_sorted = np.sort(arr, axis=axis)\n    if arr_sorted.ndim > 2:\n        raise ValueError(f'Only 1D and 2D arrays are supported (input has {arr_sorted.ndim} dimensions)')\n    if axis is None:\n        arr_sorted = arr_sorted.reshape(-1, 1)\n    else:\n        arr_sorted = np.moveaxis(arr_sorted, axis, 0)\n    quantiles = arr_sorted[0, :]\n    n = np.sum(np.isfinite(arr_sorted), axis=0)\n    n_usable = n[n > 1]\n    if np.any(n > 1):\n        q = np.asarray(q, dtype=np.float64)\n        q_adj = (q - 0.5) * n_usable / (n_usable - 1) + 0.5\n        exact_idx = (n_usable - 1) * np.clip(q_adj, 0, 1)\n        pre_idx = np.floor(exact_idx).astype(np.int32)\n        post_idx = np.ceil(exact_idx).astype(np.int32)\n        axis_idx = np.arange(len(n))[n > 1]\n        pre = arr_sorted[pre_idx, axis_idx]\n        post = arr_sorted[post_idx, axis_idx]\n        quantiles[n > 1] = pre + (post - pre) * (exact_idx - pre_idx)\n    return quantiles[0] if quantiles.size == 1 else quantiles"
        },
        {
          "text": "def find_bad_by_deviation(self, deviation_threshold=5.0):\n    \"\"\"Detect channels with abnormally high or low overall amplitudes.\n\n        A channel is considered \"bad-by-deviation\" if its amplitude deviates\n        considerably from the median channel amplitude, as calculated using a\n        robust Z-scoring method and the given deviation threshold.\n\n        Amplitude Z-scores are calculated using the formula\n        ``(channel_amplitude - median_amplitude) / amplitude_sd``, where\n        channel amplitudes are calculated using a robust outlier-resistant estimate\n        of the signals' standard deviations (IQR scaled to units of SD), and the\n        amplitude SD is the IQR-based SD of those amplitudes.\n\n        Parameters\n        ----------\n        deviation_threshold : float, optional\n            The minimum absolute z-score of a channel for it to be considered\n            bad-by-deviation. Defaults to ``5.0``.\n\n        \"\"\"\n    IQR_TO_SD = 0.7413\n    chan_amplitudes = _mat_iqr(self.EEGData, axis=1) * IQR_TO_SD\n    amp_sd = _mat_iqr(chan_amplitudes) * IQR_TO_SD\n    amp_median = np.nanmedian(chan_amplitudes)\n    amplitude_zscore = np.zeros(self.n_chans_original)\n    amplitude_zscore[self.usable_idx] = (chan_amplitudes - amp_median) / amp_sd\n    abnormal_amplitude = np.abs(amplitude_zscore) > deviation_threshold\n    deviation_channel_mask = np.isnan(amplitude_zscore) | abnormal_amplitude\n    deviation_channels = self.ch_names_original[deviation_channel_mask]\n    self.bad_by_deviation = deviation_channels.tolist()\n    self._extra_info['bad_by_deviation'].update({'median_channel_amplitude': amp_median, 'channel_amplitude_sd': amp_sd, 'robust_channel_deviations': amplitude_zscore})"
        },
        {
          "text": "def _predict_median_signals(window, interpolation_mats, matlab_strict=False):\n    \"\"\"Calculate the median RANSAC-predicted signal for a given window of data.\n\n    Parameters\n    ----------\n    window : np.ndarray\n        A 2-D window of EEG data with the shape `[channels, samples]`.\n    interpolation_mats : list of np.ndarray\n        A set of channel interpolation matrices, one for each RANSAC sample of\n        channels.\n    matlab_strict : bool\n        Whether or not RANSAC should strictly follow MATLAB PREP's internal\n        math, ignoring any improvements made in PyPREP over the original code.\n\n    Returns\n    -------\n    predicted : np.ndarray\n        The median RANSAC-predicted EEG signal for the given window of data.\n\n    Notes\n    -----\n    In MATLAB PREP, the median signal is calculated by sorting the different\n    predictions for each EEG sample/channel from low to high and then taking the value\n    at the middle index (as calculated by ``int(n_ransac_samples / 2.0)``) for each.\n    Because this logic only returns the correct result for odd numbers of samples, the\n    current function will instead return the true median signal across predictions\n    unless strict MATLAB equivalence is requested.\n\n    \"\"\"\n    ransac_samples = len(interpolation_mats)\n    merged_mats = np.concatenate(interpolation_mats, axis=0)\n    predictions_per_sample = np.reshape(np.matmul(merged_mats, window), (ransac_samples, window.shape[0], window.shape[1]))\n    if matlab_strict:\n        median_idx = int(_mat_round(ransac_samples / 2.0) - 1)\n        predictions_per_sample.sort(axis=0)\n        return predictions_per_sample[median_idx, :, :]\n    else:\n        return np.median(predictions_per_sample, axis=0)"
        },
        {
          "text": "def _mat_round(x):\n    \"\"\"Round a number to the nearest whole number.\n\n    Parameters\n    ----------\n    x : float\n        The number to round.\n\n    Returns\n    -------\n    rounded : float\n        The input value, rounded to the nearest whole number.\n\n    Notes\n    -----\n    MATLAB rounds all numbers ending in .5 up to the nearest integer, whereas\n    Python (and Numpy) rounds them to the nearest even number. This function\n    mimics MATLAB's behaviour.\n    \"\"\"\n    return np.ceil(x) if x % 1 >= 0.5 else np.floor(x)"
        }
      ]
    }
  },
  {
    "query_id": "pyprep_utils.py__eeglab_create_highpass_doc",
    "prompt": "How do I create a high-pass FIR filter that mimics EEGLAB in MATLAB?",
    "data": {
      "docs": [
        {
          "text": "def _eeglab_create_highpass(cutoff, srate):\n    \"\"\"Create a high-pass FIR filter using Hamming windows.\n\n    Parameters\n    ----------\n    cutoff : float\n        The lower pass-band edge of the filter, in Hz.\n    srate : float\n        The sampling rate of the EEG signal, in Hz.\n\n    Returns\n    -------\n    filter : np.ndarray\n        A 1-dimensional array of FIR filter coefficients.\n\n    Notes\n    -----\n    In MATLAB PREP, the internal ``removeTrend`` function uses EEGLAB's\n    ``pop_eegfiltnew`` to high-pass the EEG data to remove slow drifts.\n    Because MNE's ``mne.filter.filter_data`` and EEGLAB's ``pop_eegfiltnew``\n    calculate filter parameters slightly differently, this function is\n    used to precisely match EEGLAB & MATLAB PREP's filtering method.\n\n    \"\"\"\n    TRANSITION_WIDTH_RATIO = 0.25\n    HAMMING_CONSTANT = 3.3\n    trans_bandwidth = cutoff if cutoff < 2 else cutoff * TRANSITION_WIDTH_RATIO\n    order = HAMMING_CONSTANT / (trans_bandwidth / srate)\n    order = int(np.ceil(order / 2) * 2)\n    stop = cutoff - trans_bandwidth\n    transition = (stop + cutoff) / srate\n    N = order + 1\n    filt = np.zeros(N)\n    filt[N // 2] = 1\n    filt -= firwin(N, transition, window='hamming')\n    return filt"
        },
        {
          "text": "def _eeglab_fir_filter(data, filt):\n    \"\"\"Apply an FIR filter to a 2-D array of EEG data.\n\n    Parameters\n    ----------\n    data : np.ndarray\n        A 2-D array of EEG data to filter.\n    filt : np.ndarray\n        A 1-D array of FIR filter coefficients.\n\n    Returns\n    -------\n    filtered : np.ndarray\n        A 2-D array of FIR-filtered EEG data.\n\n    Notes\n    -----\n    Produces identical output to EEGLAB's ``firfilt`` function (for non-epoched\n    data). For internal use within :mod:`pyprep.removeTrend`.\n\n    \"\"\"\n    frames_per_window = 2000\n    group_delay = int((len(filt) - 1) / 2)\n    n_samples = data.shape[1]\n    n_windows = int(np.ceil((n_samples - group_delay) / frames_per_window))\n    pad_len = min(group_delay, n_samples)\n    start_pad_idx = np.zeros(pad_len, dtype=np.uint)\n    start_padded = np.concatenate((data[:, start_pad_idx], data[:, :pad_len]), axis=1)\n    zi_init = lfilter_zi(filt, 1) * np.take(start_padded, [0], axis=0)\n    (_, zi) = lfilter(filt, 1, start_padded, axis=1, zi=zi_init)\n    out = np.zeros_like(data)\n    for w in range(n_windows):\n        start = group_delay + w * frames_per_window\n        end = min(start + frames_per_window, n_samples)\n        start_out = start - group_delay\n        end_out = end - group_delay\n        (out[:, start_out:end_out], zi) = lfilter(filt, 1, data[:, start:end], axis=1, zi=zi)\n    end_pad_idx = np.zeros(pad_len, dtype=np.uint) + (n_samples - 1)\n    (end, _) = lfilter(filt, 1, data[:, end_pad_idx], axis=1, zi=zi)\n    out[:, n_samples - pad_len:] = end[:, group_delay - pad_len:]\n    return out"
        },
        {
          "text": "def _filter_design(N_order, amp, freq):\n    \"\"\"Create FIR low-pass filter for EEG data using frequency sampling method.\n\n    Parameters\n    ----------\n    N_order : int\n        Order of the filter.\n    amp : list of int\n        Amplitude vector for the frequencies.\n    freq : list of int\n        Frequency vector for which amplitude can be either 0 or 1.\n\n    Returns\n    -------\n    kernel : np.ndarray\n        Filter kernel.\n\n    \"\"\"\n    nfft = np.maximum(512, 2 ** np.ceil(math.log(100) / math.log(2)))\n    hamming_window = np.subtract(0.54, np.multiply(0.46, np.cos(np.divide(np.multiply(2 * math.pi, np.arange(N_order + 1)), N_order))))\n    pchip_interpolate = scipy.interpolate.PchipInterpolator(np.round(np.multiply(nfft, freq)), amp)\n    freq = pchip_interpolate(np.arange(nfft + 1))\n    freq = np.multiply(freq, np.exp(np.divide(np.multiply(-(0.5 * N_order) * sqrt(-1) * math.pi, np.arange(nfft + 1)), nfft)))\n    kernel = np.real(np.fft.ifft(np.concatenate([freq, np.conj(freq[len(freq) - 2:0:-1])])))\n    kernel = np.multiply(kernel[0:N_order + 1], np.transpose(hamming_window[:]))\n    return kernel"
        },
        {
          "text": "def _get_filtered_data(self):\n    \"\"\"Apply a [1 Hz - 50 Hz] bandpass filter to the EEG signal.\n\n        Only applied if the sample rate is above 100 Hz to avoid violating the\n        Nyquist theorem.\n\n        \"\"\"\n    if self.sample_rate <= 100:\n        return self.EEGData.copy()\n    bandpass_filter = _filter_design(N_order=100, amp=np.array([1, 1, 0, 0]), freq=np.array([0, 90 / self.sample_rate, 100 / self.sample_rate, 1]))\n    EEG_filt = np.zeros_like(self.EEGData)\n    for i in range(EEG_filt.shape[0]):\n        EEG_filt[i, :] = signal.filtfilt(bandpass_filter, 1, self.EEGData[i, :])\n    return EEG_filt"
        },
        {
          "text": "def fit(self):\n    \"\"\"Run the whole PREP pipeline.\"\"\"\n    if len(self.prep_params['line_freqs']) != 0:\n        self.EEG_new = removeTrend(self.EEG_raw, self.sfreq, matlab_strict=self.matlab_strict)\n        linenoise = self.prep_params['line_freqs']\n        if self.filter_kwargs is None:\n            self.EEG_clean = mne.filter.notch_filter(self.EEG_new, Fs=self.sfreq, freqs=linenoise, method='spectrum_fit', mt_bandwidth=2, p_value=0.01, filter_length='10s')\n        else:\n            self.EEG_clean = mne.filter.notch_filter(self.EEG_new, Fs=self.sfreq, freqs=linenoise, **self.filter_kwargs)\n        self.EEG = self.EEG_raw - self.EEG_new + self.EEG_clean\n        self.raw_eeg._data = self.EEG\n    reference = Reference(self.raw_eeg, self.prep_params, random_state=self.random_state, matlab_strict=self.matlab_strict, **self.ransac_settings)\n    reference.perform_reference(self.prep_params['max_iterations'])\n    self.raw_eeg = reference.raw\n    self.noisy_channels_original = reference.noisy_channels_original\n    self.noisy_channels_before_interpolation = reference.noisy_channels_before_interpolation\n    self.noisy_channels_after_interpolation = reference.noisy_channels_after_interpolation\n    self.bad_before_interpolation = reference.bad_before_interpolation\n    self.EEG_before_interpolation = reference.EEG_before_interpolation\n    self.reference_before_interpolation = reference.reference_signal\n    self.reference_after_interpolation = reference.reference_signal_new\n    self.interpolated_channels = reference.interpolated_channels\n    self.still_noisy_channels = reference.still_noisy_channels\n    return self"
        }
      ]
    }
  },
  {
    "query_id": "pyprep_utils.py__eeglab_fir_filter_doc",
    "prompt": "How do I apply an FIR filter to EEG data using EEGLAB\u2019s method?",
    "data": {
      "docs": [
        {
          "text": "def _eeglab_fir_filter(data, filt):\n    \"\"\"Apply an FIR filter to a 2-D array of EEG data.\n\n    Parameters\n    ----------\n    data : np.ndarray\n        A 2-D array of EEG data to filter.\n    filt : np.ndarray\n        A 1-D array of FIR filter coefficients.\n\n    Returns\n    -------\n    filtered : np.ndarray\n        A 2-D array of FIR-filtered EEG data.\n\n    Notes\n    -----\n    Produces identical output to EEGLAB's ``firfilt`` function (for non-epoched\n    data). For internal use within :mod:`pyprep.removeTrend`.\n\n    \"\"\"\n    frames_per_window = 2000\n    group_delay = int((len(filt) - 1) / 2)\n    n_samples = data.shape[1]\n    n_windows = int(np.ceil((n_samples - group_delay) / frames_per_window))\n    pad_len = min(group_delay, n_samples)\n    start_pad_idx = np.zeros(pad_len, dtype=np.uint)\n    start_padded = np.concatenate((data[:, start_pad_idx], data[:, :pad_len]), axis=1)\n    zi_init = lfilter_zi(filt, 1) * np.take(start_padded, [0], axis=0)\n    (_, zi) = lfilter(filt, 1, start_padded, axis=1, zi=zi_init)\n    out = np.zeros_like(data)\n    for w in range(n_windows):\n        start = group_delay + w * frames_per_window\n        end = min(start + frames_per_window, n_samples)\n        start_out = start - group_delay\n        end_out = end - group_delay\n        (out[:, start_out:end_out], zi) = lfilter(filt, 1, data[:, start:end], axis=1, zi=zi)\n    end_pad_idx = np.zeros(pad_len, dtype=np.uint) + (n_samples - 1)\n    (end, _) = lfilter(filt, 1, data[:, end_pad_idx], axis=1, zi=zi)\n    out[:, n_samples - pad_len:] = end[:, group_delay - pad_len:]\n    return out"
        },
        {
          "text": "def _eeglab_create_highpass(cutoff, srate):\n    \"\"\"Create a high-pass FIR filter using Hamming windows.\n\n    Parameters\n    ----------\n    cutoff : float\n        The lower pass-band edge of the filter, in Hz.\n    srate : float\n        The sampling rate of the EEG signal, in Hz.\n\n    Returns\n    -------\n    filter : np.ndarray\n        A 1-dimensional array of FIR filter coefficients.\n\n    Notes\n    -----\n    In MATLAB PREP, the internal ``removeTrend`` function uses EEGLAB's\n    ``pop_eegfiltnew`` to high-pass the EEG data to remove slow drifts.\n    Because MNE's ``mne.filter.filter_data`` and EEGLAB's ``pop_eegfiltnew``\n    calculate filter parameters slightly differently, this function is\n    used to precisely match EEGLAB & MATLAB PREP's filtering method.\n\n    \"\"\"\n    TRANSITION_WIDTH_RATIO = 0.25\n    HAMMING_CONSTANT = 3.3\n    trans_bandwidth = cutoff if cutoff < 2 else cutoff * TRANSITION_WIDTH_RATIO\n    order = HAMMING_CONSTANT / (trans_bandwidth / srate)\n    order = int(np.ceil(order / 2) * 2)\n    stop = cutoff - trans_bandwidth\n    transition = (stop + cutoff) / srate\n    N = order + 1\n    filt = np.zeros(N)\n    filt[N // 2] = 1\n    filt -= firwin(N, transition, window='hamming')\n    return filt"
        },
        {
          "text": "def _get_filtered_data(self):\n    \"\"\"Apply a [1 Hz - 50 Hz] bandpass filter to the EEG signal.\n\n        Only applied if the sample rate is above 100 Hz to avoid violating the\n        Nyquist theorem.\n\n        \"\"\"\n    if self.sample_rate <= 100:\n        return self.EEGData.copy()\n    bandpass_filter = _filter_design(N_order=100, amp=np.array([1, 1, 0, 0]), freq=np.array([0, 90 / self.sample_rate, 100 / self.sample_rate, 1]))\n    EEG_filt = np.zeros_like(self.EEGData)\n    for i in range(EEG_filt.shape[0]):\n        EEG_filt[i, :] = signal.filtfilt(bandpass_filter, 1, self.EEGData[i, :])\n    return EEG_filt"
        },
        {
          "text": "def _filter_design(N_order, amp, freq):\n    \"\"\"Create FIR low-pass filter for EEG data using frequency sampling method.\n\n    Parameters\n    ----------\n    N_order : int\n        Order of the filter.\n    amp : list of int\n        Amplitude vector for the frequencies.\n    freq : list of int\n        Frequency vector for which amplitude can be either 0 or 1.\n\n    Returns\n    -------\n    kernel : np.ndarray\n        Filter kernel.\n\n    \"\"\"\n    nfft = np.maximum(512, 2 ** np.ceil(math.log(100) / math.log(2)))\n    hamming_window = np.subtract(0.54, np.multiply(0.46, np.cos(np.divide(np.multiply(2 * math.pi, np.arange(N_order + 1)), N_order))))\n    pchip_interpolate = scipy.interpolate.PchipInterpolator(np.round(np.multiply(nfft, freq)), amp)\n    freq = pchip_interpolate(np.arange(nfft + 1))\n    freq = np.multiply(freq, np.exp(np.divide(np.multiply(-(0.5 * N_order) * sqrt(-1) * math.pi, np.arange(nfft + 1)), nfft)))\n    kernel = np.real(np.fft.ifft(np.concatenate([freq, np.conj(freq[len(freq) - 2:0:-1])])))\n    kernel = np.multiply(kernel[0:N_order + 1], np.transpose(hamming_window[:]))\n    return kernel"
        },
        {
          "text": "def fit(self):\n    \"\"\"Run the whole PREP pipeline.\"\"\"\n    if len(self.prep_params['line_freqs']) != 0:\n        self.EEG_new = removeTrend(self.EEG_raw, self.sfreq, matlab_strict=self.matlab_strict)\n        linenoise = self.prep_params['line_freqs']\n        if self.filter_kwargs is None:\n            self.EEG_clean = mne.filter.notch_filter(self.EEG_new, Fs=self.sfreq, freqs=linenoise, method='spectrum_fit', mt_bandwidth=2, p_value=0.01, filter_length='10s')\n        else:\n            self.EEG_clean = mne.filter.notch_filter(self.EEG_new, Fs=self.sfreq, freqs=linenoise, **self.filter_kwargs)\n        self.EEG = self.EEG_raw - self.EEG_new + self.EEG_clean\n        self.raw_eeg._data = self.EEG\n    reference = Reference(self.raw_eeg, self.prep_params, random_state=self.random_state, matlab_strict=self.matlab_strict, **self.ransac_settings)\n    reference.perform_reference(self.prep_params['max_iterations'])\n    self.raw_eeg = reference.raw\n    self.noisy_channels_original = reference.noisy_channels_original\n    self.noisy_channels_before_interpolation = reference.noisy_channels_before_interpolation\n    self.noisy_channels_after_interpolation = reference.noisy_channels_after_interpolation\n    self.bad_before_interpolation = reference.bad_before_interpolation\n    self.EEG_before_interpolation = reference.EEG_before_interpolation\n    self.reference_before_interpolation = reference.reference_signal\n    self.reference_after_interpolation = reference.reference_signal_new\n    self.interpolated_channels = reference.interpolated_channels\n    self.still_noisy_channels = reference.still_noisy_channels\n    return self"
        }
      ]
    }
  },
  {
    "query_id": "pyprep_utils.py__eeglab_calc_g_doc",
    "prompt": "How can I calculate the spherical spline G matrix for EEG interpolation?",
    "data": {
      "docs": [
        {
          "text": "def _eeglab_calc_g(pos_from, pos_to, stiffness=4, num_lterms=7):\n    \"\"\"Calculate spherical spline g function between points on a sphere.\n\n    Parameters\n    ----------\n    pos_from : np.ndarray of float, shape(n_good_sensors, 3)\n        The electrode positions to interpolate from.\n    pos_to : np.ndarray of float, shape(n_bad_sensors, 3)\n        The electrode positions to interpolate.\n    stiffness : float\n        Stiffness of the spline.\n    num_lterms : int\n        Number of Legendre terms to evaluate.\n\n    Returns\n    -------\n    G : np.ndarray of float, shape(n_channels, n_channels)\n        The G matrix.\n\n    Notes\n    -----\n    Produces identical output to the private ``computeg`` function in EEGLAB's\n    ``eeg_interp.m``.\n\n    \"\"\"\n    n_to = pos_to.shape[0]\n    n_from = pos_from.shape[0]\n    dxyz = []\n    for i in range(0, 3):\n        d1 = np.repeat(pos_to[:, i], n_from).reshape((n_to, n_from))\n        d2 = np.repeat(pos_from[:, i], n_to).reshape((n_from, n_to)).T\n        dxyz.append((d1 - d2) ** 2)\n    elec_dists = np.sqrt(sum(dxyz))\n    EI = np.ones([n_to, n_from]) - elec_dists\n    factors = [0]\n    for n in range(1, num_lterms + 1):\n        f = (2 * n + 1) / (n ** stiffness * (n + 1) ** stiffness * 4 * np.pi)\n        factors.append(f)\n    return legval(EI, factors)"
        },
        {
          "text": "def _eeglab_interpolate(data, pos_from, pos_to):\n    \"\"\"Interpolate bad channels using EEGLAB's custom method.\n\n    Parameters\n    ----------\n    data : np.ndarray\n        A 2-D array containing signals from currently-good EEG channels with\n        which to interpolate signals for bad channels.\n    pos_from : np.ndarray of float, shape(n_good_sensors, 3)\n        The electrode positions to interpolate from.\n    pos_to : np.ndarray of float, shape(n_bad_sensors, 3)\n        The electrode positions to interpolate.\n\n    Returns\n    -------\n    interpolated : np.ndarray\n        The interpolated signals for all bad channels.\n\n    Notes\n    -----\n    Produces identical output to the private ``spheric_spline`` function in\n    EEGLAB's ``eeg_interp.m`` (with minor rounding errors).\n\n    \"\"\"\n    G_from = _eeglab_calc_g(pos_from, pos_from)\n    G_to_from = _eeglab_calc_g(pos_from, pos_to)\n    avg_ref = np.mean(data, axis=0)\n    data_tmp = data - avg_ref\n    pad_ones = np.ones((1, pos_from.shape[0]))\n    C_inv = linalg.pinv(np.vstack([G_from, pad_ones]))\n    interp_mat = np.matmul(G_to_from, C_inv[:, :-1])\n    interpolated = np.matmul(interp_mat, data_tmp) + avg_ref\n    return interpolated"
        },
        {
          "text": "def _eeglab_interpolate_bads(raw):\n    \"\"\"Interpolate bad channels using EEGLAB's custom method.\n\n    This method modifies the provided Raw object in place.\n\n    Parameters\n    ----------\n    raw : mne.io.Raw\n        An MNE Raw object for which channels marked as \"bad\" should be\n        interpolated.\n\n    Notes\n    -----\n    Produces identical results as EEGLAB's ``eeg_interp`` function when using\n    the default spheric spline method (with minor rounding errors). This method\n    appears to be loosely based on the same general Perrin et al. (1989) method\n    as MNE's interpolation, but there are several quirks with the implementation\n    that cause it to produce fairly different numbers.\n\n    \"\"\"\n    eeg_chans = np.array([idx for (idx, typ) in enumerate(raw.get_channel_types()) if typ == 'eeg'])\n    good_idx = np.array([idx for (idx, (ch, typ)) in enumerate(zip(raw.ch_names, raw.get_channel_types())) if typ == 'eeg' and ch not in raw.info['bads']])\n    bad_idx = sorted(_set_diff(eeg_chans, good_idx))\n    elec_pos = raw._get_channel_positions(picks=eeg_chans)\n    pos_good = elec_pos[good_idx, :].copy()\n    pos_bad = elec_pos[bad_idx, :].copy()\n    _normalize_vectors(pos_good)\n    _normalize_vectors(pos_bad)\n    interp = _eeglab_interpolate(raw.get_data()[good_idx, :], pos_good, pos_bad)\n    raw._data[bad_idx, :] = interp\n    eeg_bad_names = [raw.info['ch_names'][i] for i in bad_idx]\n    bads_non_eeg = _set_diff(raw.info['bads'], eeg_bad_names)\n    raw.info['bads'] = bads_non_eeg"
        },
        {
          "text": "def runline(y, n, dn):\n    \"\"\"Perform local linear regression on a channel of EEG data.\n\n    A re-implementation of the ``runline`` function from the Chronux package\n    for MATLAB [1]_.\n\n    Parameters\n    ----------\n    y : np.ndarray\n        A 1-D array of data from a single EEG channel.\n    n : int\n        Length of the detrending window.\n    dn : int\n        Length of the window step size.\n\n    Returns\n    -------\n    y: np.ndarray\n       The detrended signal for the given EEG channel.\n\n    References\n    ----------\n    .. [1] http://chronux.org/\n\n    \"\"\"\n    nt = y.shape[0]\n    y_line = np.zeros((nt, 1))\n    norm = np.zeros((nt, 1))\n    nwin = int(np.ceil((nt - n) / dn))\n    yfit = np.zeros((nwin, n))\n    xwt = (np.arange(1, n + 1) - n / 2) / (n / 2)\n    wt = np.power(1 - np.power(np.absolute(xwt), 3), 3)\n    for j in range(0, nwin):\n        tseg = y[dn * j:dn * j + n]\n        y1 = np.mean(tseg)\n        y2 = np.mean(np.multiply(np.arange(1, n + 1), tseg)) * (2 / (n + 1))\n        a = np.multiply(np.subtract(y2, y1), 6 / (n - 1))\n        b = np.subtract(y1, a * (n + 1) / 2)\n        yfit[j, :] = np.multiply(np.arange(1, n + 1), a) + b\n        y_line[j * dn:j * dn + n] = y_line[j * dn:j * dn + n] + np.reshape(np.multiply(yfit[j, :], wt), (n, 1))\n        norm[j * dn:j * dn + n] = norm[j * dn:j * dn + n] + np.reshape(wt, (n, 1))\n    for i in range(0, len(norm)):\n        if norm[i] > 0:\n            y_line[i] = y_line[i] / norm[i]\n    indx = (nwin - 1) * dn + n - 1\n    npts = len(y) - indx + 1\n    y_line[indx - 1:] = np.reshape(np.multiply(np.arange(n + 1, n + npts + 1), a) + b, (npts, 1))\n    for i in range(0, len(y_line)):\n        y[i] = y[i] - y_line[i, 0]\n    return y"
        },
        {
          "text": "def _make_interpolation_matrices(random_ch_picks, chn_pos_good):\n    \"\"\"Create an interpolation matrix for each RANSAC sample of channels.\n\n    This function takes the spatial coordinates of random subsets of currently-good\n    channels and uses them to predict what the signal will be at the spatial\n    coordinates of all other currently-good channels. The results of this process are\n    returned as matrices that can be multiplied with EEG data to generate predicted\n    signals.\n\n    Parameters\n    ----------\n    random_ch_picks : list of list of int\n        A list containing multiple random subsets of currently-good channels.\n    chn_pos_good : np.ndarray\n        3-D spatial coordinates of all currently-good channels.\n\n    Returns\n    -------\n    interpolation_mats : list of np.ndarray\n        A list of interpolation matrices, one for each random subset of channels.\n        Each matrix has the shape `[num_good_channels, num_good_channels]`, with the\n        number of good channels being inferred from the size of `ch_pos_good`.\n\n    Notes\n    -----\n    This function currently makes use of a private MNE function,\n    ``mne.channels.interpolation._make_interpolation_matrix``, to generate matrices.\n\n    \"\"\"\n    n_chans_good = chn_pos_good.shape[0]\n    interpolation_mats = []\n    for sample in random_ch_picks:\n        mat = np.zeros((n_chans_good, n_chans_good))\n        subset_pos = chn_pos_good[sample, :]\n        mat[:, sample] = _make_interpolation_matrix(subset_pos, chn_pos_good)\n        interpolation_mats.append(mat)\n    return interpolation_mats"
        }
      ]
    }
  },
  {
    "query_id": "pyprep_utils.py__eeglab_interpolate_doc",
    "prompt": "How do I interpolate bad EEG channels using electrode positions in PyPREP?",
    "data": {
      "docs": [
        {
          "text": "def _eeglab_interpolate(data, pos_from, pos_to):\n    \"\"\"Interpolate bad channels using EEGLAB's custom method.\n\n    Parameters\n    ----------\n    data : np.ndarray\n        A 2-D array containing signals from currently-good EEG channels with\n        which to interpolate signals for bad channels.\n    pos_from : np.ndarray of float, shape(n_good_sensors, 3)\n        The electrode positions to interpolate from.\n    pos_to : np.ndarray of float, shape(n_bad_sensors, 3)\n        The electrode positions to interpolate.\n\n    Returns\n    -------\n    interpolated : np.ndarray\n        The interpolated signals for all bad channels.\n\n    Notes\n    -----\n    Produces identical output to the private ``spheric_spline`` function in\n    EEGLAB's ``eeg_interp.m`` (with minor rounding errors).\n\n    \"\"\"\n    G_from = _eeglab_calc_g(pos_from, pos_from)\n    G_to_from = _eeglab_calc_g(pos_from, pos_to)\n    avg_ref = np.mean(data, axis=0)\n    data_tmp = data - avg_ref\n    pad_ones = np.ones((1, pos_from.shape[0]))\n    C_inv = linalg.pinv(np.vstack([G_from, pad_ones]))\n    interp_mat = np.matmul(G_to_from, C_inv[:, :-1])\n    interpolated = np.matmul(interp_mat, data_tmp) + avg_ref\n    return interpolated"
        },
        {
          "text": "def _eeglab_interpolate_bads(raw):\n    \"\"\"Interpolate bad channels using EEGLAB's custom method.\n\n    This method modifies the provided Raw object in place.\n\n    Parameters\n    ----------\n    raw : mne.io.Raw\n        An MNE Raw object for which channels marked as \"bad\" should be\n        interpolated.\n\n    Notes\n    -----\n    Produces identical results as EEGLAB's ``eeg_interp`` function when using\n    the default spheric spline method (with minor rounding errors). This method\n    appears to be loosely based on the same general Perrin et al. (1989) method\n    as MNE's interpolation, but there are several quirks with the implementation\n    that cause it to produce fairly different numbers.\n\n    \"\"\"\n    eeg_chans = np.array([idx for (idx, typ) in enumerate(raw.get_channel_types()) if typ == 'eeg'])\n    good_idx = np.array([idx for (idx, (ch, typ)) in enumerate(zip(raw.ch_names, raw.get_channel_types())) if typ == 'eeg' and ch not in raw.info['bads']])\n    bad_idx = sorted(_set_diff(eeg_chans, good_idx))\n    elec_pos = raw._get_channel_positions(picks=eeg_chans)\n    pos_good = elec_pos[good_idx, :].copy()\n    pos_bad = elec_pos[bad_idx, :].copy()\n    _normalize_vectors(pos_good)\n    _normalize_vectors(pos_bad)\n    interp = _eeglab_interpolate(raw.get_data()[good_idx, :], pos_good, pos_bad)\n    raw._data[bad_idx, :] = interp\n    eeg_bad_names = [raw.info['ch_names'][i] for i in bad_idx]\n    bads_non_eeg = _set_diff(raw.info['bads'], eeg_bad_names)\n    raw.info['bads'] = bads_non_eeg"
        },
        {
          "text": "def _predict_median_signals(window, interpolation_mats, matlab_strict=False):\n    \"\"\"Calculate the median RANSAC-predicted signal for a given window of data.\n\n    Parameters\n    ----------\n    window : np.ndarray\n        A 2-D window of EEG data with the shape `[channels, samples]`.\n    interpolation_mats : list of np.ndarray\n        A set of channel interpolation matrices, one for each RANSAC sample of\n        channels.\n    matlab_strict : bool\n        Whether or not RANSAC should strictly follow MATLAB PREP's internal\n        math, ignoring any improvements made in PyPREP over the original code.\n\n    Returns\n    -------\n    predicted : np.ndarray\n        The median RANSAC-predicted EEG signal for the given window of data.\n\n    Notes\n    -----\n    In MATLAB PREP, the median signal is calculated by sorting the different\n    predictions for each EEG sample/channel from low to high and then taking the value\n    at the middle index (as calculated by ``int(n_ransac_samples / 2.0)``) for each.\n    Because this logic only returns the correct result for odd numbers of samples, the\n    current function will instead return the true median signal across predictions\n    unless strict MATLAB equivalence is requested.\n\n    \"\"\"\n    ransac_samples = len(interpolation_mats)\n    merged_mats = np.concatenate(interpolation_mats, axis=0)\n    predictions_per_sample = np.reshape(np.matmul(merged_mats, window), (ransac_samples, window.shape[0], window.shape[1]))\n    if matlab_strict:\n        median_idx = int(_mat_round(ransac_samples / 2.0) - 1)\n        predictions_per_sample.sort(axis=0)\n        return predictions_per_sample[median_idx, :, :]\n    else:\n        return np.median(predictions_per_sample, axis=0)"
        },
        {
          "text": "def _predict_median_signals_channelwise(data, interpolation_mats, random_ch_picks, chunk_size, matlab_strict):\n    \"\"\"Calculate the median RANSAC-predicted signal for a given chunk of channels.\n\n    Parameters\n    ----------\n    data : np.ndarray\n        A 2-D array containing the EEG signals from all currently-good channels.\n    interpolation_mats : list of np.ndarray\n        A set of channel interpolation matrices, one for each RANSAC sample of\n        channels.\n    random_ch_picks : list of list of int\n        A list containing multiple random subsets of currently-good channels.\n    chunk_size : int\n        The number of channels to predict in the current chunk.\n    matlab_strict : bool\n        Whether or not RANSAC should strictly follow MATLAB PREP's internal\n        math, ignoring any improvements made in PyPREP over the original code.\n\n    Returns\n    -------\n    predicted_chans : np.ndarray\n        The median RANSAC-predicted EEG signals for the given chunk of channels.\n\n    \"\"\"\n    ransac_samples = len(interpolation_mats)\n    n_timepts = data.shape[1]\n    _verify_free_ram(data, ransac_samples, chunk_size)\n    eeg_predictions = np.zeros((chunk_size, n_timepts, ransac_samples))\n    for sample in range(ransac_samples):\n        reconstr_idx = random_ch_picks[sample]\n        interp_mat = interpolation_mats[sample][:, reconstr_idx]\n        eeg_predictions[..., sample] = np.matmul(interp_mat, data[reconstr_idx, :])\n    if matlab_strict:\n        median_idx = int(_mat_round(ransac_samples / 2.0) - 1)\n        eeg_predictions.sort(axis=-1)\n        return eeg_predictions[:, :, median_idx]\n    else:\n        return np.median(eeg_predictions, axis=-1, overwrite_input=True)"
        },
        {
          "text": "def removeTrend(EEG, sample_rate, detrendType='high pass', detrendCutoff=1.0, detrendChannels=None, matlab_strict=False):\n    \"\"\"Remove trends (i.e., slow drifts in baseline) from an array of EEG data.\n\n    Parameters\n    ----------\n    EEG : np.ndarray\n        A 2-D array of EEG data to detrend.\n    sample_rate : float\n        The sample rate (in Hz) of the input EEG data.\n    detrendType : str, optional\n        Type of detrending to be performed: must be one of 'high pass',\n        'high pass sinc, or 'local detrend'. Defaults to 'high pass'.\n    detrendCutoff : float, optional\n        The high-pass cutoff frequency (in Hz) to use for detrending. Defaults\n        to 1.0 Hz.\n    detrendChannels : {list, None}, optional\n        List of the indices of all channels that require detrending/filtering.\n        If ``None``, all channels are used (default).\n    matlab_strict : bool, optional\n        Whether or not detrending should strictly follow MATLAB PREP's internal\n        math, ignoring any improvements made in PyPREP over the original code\n        (see :ref:`matlab-diffs` for more details). Defaults to ``False``.\n\n    Returns\n    -------\n    EEG : np.ndarray\n        A 2-D array containing the filtered/detrended EEG data.\n\n    Notes\n    -----\n    High-pass filtering is implemented using the MNE filter function\n    :func:``mne.filter.filter_data`` unless `matlab_strict` is ``True``, in\n    which case it is performed using a minimal re-implementation of EEGLAB's\n    ``pop_eegfiltnew``. Local detrending is performed using a Python\n    re-implementation of the ``runline`` function from the Chronux package for\n    MATLAB [1]_.\n\n    References\n    ----------\n    .. [1] http://chronux.org/\n\n    \"\"\"\n    if len(EEG.shape) == 1:\n        EEG = np.reshape(EEG, (1, EEG.shape[0]))\n    if detrendType.lower() == 'high pass':\n        if matlab_strict:\n            picks = detrendChannels if detrendChannels else range(EEG.shape[0])\n            filt = _eeglab_create_highpass(detrendCutoff, sample_rate)\n            EEG[picks, :] = _eeglab_fir_filter(EEG[picks, :], filt)\n        else:\n            EEG = mne.filter.filter_data(EEG, sfreq=sample_rate, l_freq=detrendCutoff, h_freq=None, picks=detrendChannels)\n    elif detrendType.lower() == 'high pass sinc':\n        fOrder = np.round(14080 * sample_rate / 512)\n        fOrder = int(fOrder + fOrder % 2)\n        EEG = mne.filter.filter_data(data=EEG, sfreq=sample_rate, l_freq=1, h_freq=None, picks=detrendChannels, filter_length=fOrder, fir_window='blackman')\n    elif detrendType.lower() == 'local detrend':\n        if detrendChannels is None:\n            detrendChannels = np.arange(0, EEG.shape[0])\n        windowSize = 1.5 / detrendCutoff\n        windowSize = np.minimum(windowSize, EEG.shape[1])\n        stepSize = 0.02\n        EEG = np.transpose(EEG)\n        n = np.round(sample_rate * windowSize)\n        dn = np.round(sample_rate * stepSize)\n        if dn > n or dn < 1:\n            logging.error('Step size should be less than the window size and contain at least 1 sample')\n        if n == EEG.shape[0]:\n            pass\n        else:\n            for ch in detrendChannels:\n                EEG[:, ch] = runline(EEG[:, ch], int(n), int(dn))\n        EEG = np.transpose(EEG)\n    else:\n        logging.warning('No filtering/detreding performed since the detrend type did not match')\n    return EEG"
        }
      ]
    }
  },
  {
    "query_id": "pyprep_utils.py__eeglab_interpolate_bads_doc",
    "prompt": "How do I interpolate bad channels in an MNE Raw object using EEGLAB's method?",
    "data": {
      "docs": [
        {
          "text": "def _eeglab_interpolate_bads(raw):\n    \"\"\"Interpolate bad channels using EEGLAB's custom method.\n\n    This method modifies the provided Raw object in place.\n\n    Parameters\n    ----------\n    raw : mne.io.Raw\n        An MNE Raw object for which channels marked as \"bad\" should be\n        interpolated.\n\n    Notes\n    -----\n    Produces identical results as EEGLAB's ``eeg_interp`` function when using\n    the default spheric spline method (with minor rounding errors). This method\n    appears to be loosely based on the same general Perrin et al. (1989) method\n    as MNE's interpolation, but there are several quirks with the implementation\n    that cause it to produce fairly different numbers.\n\n    \"\"\"\n    eeg_chans = np.array([idx for (idx, typ) in enumerate(raw.get_channel_types()) if typ == 'eeg'])\n    good_idx = np.array([idx for (idx, (ch, typ)) in enumerate(zip(raw.ch_names, raw.get_channel_types())) if typ == 'eeg' and ch not in raw.info['bads']])\n    bad_idx = sorted(_set_diff(eeg_chans, good_idx))\n    elec_pos = raw._get_channel_positions(picks=eeg_chans)\n    pos_good = elec_pos[good_idx, :].copy()\n    pos_bad = elec_pos[bad_idx, :].copy()\n    _normalize_vectors(pos_good)\n    _normalize_vectors(pos_bad)\n    interp = _eeglab_interpolate(raw.get_data()[good_idx, :], pos_good, pos_bad)\n    raw._data[bad_idx, :] = interp\n    eeg_bad_names = [raw.info['ch_names'][i] for i in bad_idx]\n    bads_non_eeg = _set_diff(raw.info['bads'], eeg_bad_names)\n    raw.info['bads'] = bads_non_eeg"
        },
        {
          "text": "def _eeglab_interpolate(data, pos_from, pos_to):\n    \"\"\"Interpolate bad channels using EEGLAB's custom method.\n\n    Parameters\n    ----------\n    data : np.ndarray\n        A 2-D array containing signals from currently-good EEG channels with\n        which to interpolate signals for bad channels.\n    pos_from : np.ndarray of float, shape(n_good_sensors, 3)\n        The electrode positions to interpolate from.\n    pos_to : np.ndarray of float, shape(n_bad_sensors, 3)\n        The electrode positions to interpolate.\n\n    Returns\n    -------\n    interpolated : np.ndarray\n        The interpolated signals for all bad channels.\n\n    Notes\n    -----\n    Produces identical output to the private ``spheric_spline`` function in\n    EEGLAB's ``eeg_interp.m`` (with minor rounding errors).\n\n    \"\"\"\n    G_from = _eeglab_calc_g(pos_from, pos_from)\n    G_to_from = _eeglab_calc_g(pos_from, pos_to)\n    avg_ref = np.mean(data, axis=0)\n    data_tmp = data - avg_ref\n    pad_ones = np.ones((1, pos_from.shape[0]))\n    C_inv = linalg.pinv(np.vstack([G_from, pad_ones]))\n    interp_mat = np.matmul(G_to_from, C_inv[:, :-1])\n    interpolated = np.matmul(interp_mat, data_tmp) + avg_ref\n    return interpolated"
        },
        {
          "text": "def perform_reference(self, max_iterations=4):\n    \"\"\"Estimate the true signal mean and interpolate bad channels.\n\n        Parameters\n        ----------\n        max_iterations : int, optional\n            The maximum number of iterations of noisy channel removal to perform\n            during robust referencing. Defaults to ``4``.\n\n        This function implements the functionality of the `performReference` function\n        as part of the PREP pipeline on mne raw object.\n\n        Notes\n        -----\n        This function calls ``robust_reference`` first.\n        Currently this function only implements the functionality of default\n        settings, i.e., ``doRobustPost``.\n\n        \"\"\"\n    self.robust_reference(max_iterations)\n    dummy = self.raw.copy()\n    dummy.info['bads'] = self.noisy_channels['bad_all']\n    if self.matlab_strict:\n        _eeglab_interpolate_bads(dummy)\n    else:\n        dummy.interpolate_bads()\n    self.reference_signal = np.nanmean(dummy.get_data(picks=self.reference_channels), axis=0)\n    del dummy\n    rereferenced_index = [self.ch_names_eeg.index(ch) for ch in self.rereferenced_channels]\n    self.EEG = self.remove_reference(self.EEG, self.reference_signal, rereferenced_index)\n    self.raw._data = self.EEG\n    noisy_detector = NoisyChannels(self.raw, random_state=self.random_state, matlab_strict=self.matlab_strict)\n    noisy_detector.find_all_bads(**self.ransac_settings)\n    self.bad_before_interpolation = noisy_detector.get_bads(verbose=True)\n    self.EEG_before_interpolation = self.EEG.copy()\n    self.noisy_channels_before_interpolation = noisy_detector.get_bads(as_dict=True)\n    self.noisy_channels_before_interpolation['bad_by_manual'] = self.bads_manual\n    self._extra_info['interpolated'] = noisy_detector._extra_info\n    bad_channels = _union(self.bad_before_interpolation, self.unusable_channels)\n    self.raw.info['bads'] = bad_channels\n    if self.matlab_strict:\n        _eeglab_interpolate_bads(self.raw)\n    else:\n        self.raw.interpolate_bads()\n    reference_correct = np.nanmean(self.raw.get_data(picks=self.reference_channels), axis=0)\n    self.EEG = self.raw.get_data()\n    self.EEG = self.remove_reference(self.EEG, reference_correct, rereferenced_index)\n    self.reference_signal_new = self.reference_signal + reference_correct\n    self.raw._data = self.EEG\n    self.interpolated_channels = bad_channels\n    noisy_detector = NoisyChannels(self.raw, random_state=self.random_state, matlab_strict=self.matlab_strict)\n    noisy_detector.find_all_bads(**self.ransac_settings)\n    self.still_noisy_channels = noisy_detector.get_bads()\n    self.raw.info['bads'] = self.still_noisy_channels\n    self.noisy_channels_after_interpolation = noisy_detector.get_bads(as_dict=True)\n    self._extra_info['remaining_bad'] = noisy_detector._extra_info\n    return self"
        },
        {
          "text": "def _eeglab_create_highpass(cutoff, srate):\n    \"\"\"Create a high-pass FIR filter using Hamming windows.\n\n    Parameters\n    ----------\n    cutoff : float\n        The lower pass-band edge of the filter, in Hz.\n    srate : float\n        The sampling rate of the EEG signal, in Hz.\n\n    Returns\n    -------\n    filter : np.ndarray\n        A 1-dimensional array of FIR filter coefficients.\n\n    Notes\n    -----\n    In MATLAB PREP, the internal ``removeTrend`` function uses EEGLAB's\n    ``pop_eegfiltnew`` to high-pass the EEG data to remove slow drifts.\n    Because MNE's ``mne.filter.filter_data`` and EEGLAB's ``pop_eegfiltnew``\n    calculate filter parameters slightly differently, this function is\n    used to precisely match EEGLAB & MATLAB PREP's filtering method.\n\n    \"\"\"\n    TRANSITION_WIDTH_RATIO = 0.25\n    HAMMING_CONSTANT = 3.3\n    trans_bandwidth = cutoff if cutoff < 2 else cutoff * TRANSITION_WIDTH_RATIO\n    order = HAMMING_CONSTANT / (trans_bandwidth / srate)\n    order = int(np.ceil(order / 2) * 2)\n    stop = cutoff - trans_bandwidth\n    transition = (stop + cutoff) / srate\n    N = order + 1\n    filt = np.zeros(N)\n    filt[N // 2] = 1\n    filt -= firwin(N, transition, window='hamming')\n    return filt"
        },
        {
          "text": "def find_bad_by_deviation(self, deviation_threshold=5.0):\n    \"\"\"Detect channels with abnormally high or low overall amplitudes.\n\n        A channel is considered \"bad-by-deviation\" if its amplitude deviates\n        considerably from the median channel amplitude, as calculated using a\n        robust Z-scoring method and the given deviation threshold.\n\n        Amplitude Z-scores are calculated using the formula\n        ``(channel_amplitude - median_amplitude) / amplitude_sd``, where\n        channel amplitudes are calculated using a robust outlier-resistant estimate\n        of the signals' standard deviations (IQR scaled to units of SD), and the\n        amplitude SD is the IQR-based SD of those amplitudes.\n\n        Parameters\n        ----------\n        deviation_threshold : float, optional\n            The minimum absolute z-score of a channel for it to be considered\n            bad-by-deviation. Defaults to ``5.0``.\n\n        \"\"\"\n    IQR_TO_SD = 0.7413\n    chan_amplitudes = _mat_iqr(self.EEGData, axis=1) * IQR_TO_SD\n    amp_sd = _mat_iqr(chan_amplitudes) * IQR_TO_SD\n    amp_median = np.nanmedian(chan_amplitudes)\n    amplitude_zscore = np.zeros(self.n_chans_original)\n    amplitude_zscore[self.usable_idx] = (chan_amplitudes - amp_median) / amp_sd\n    abnormal_amplitude = np.abs(amplitude_zscore) > deviation_threshold\n    deviation_channel_mask = np.isnan(amplitude_zscore) | abnormal_amplitude\n    deviation_channels = self.ch_names_original[deviation_channel_mask]\n    self.bad_by_deviation = deviation_channels.tolist()\n    self._extra_info['bad_by_deviation'].update({'median_channel_amplitude': amp_median, 'channel_amplitude_sd': amp_sd, 'robust_channel_deviations': amplitude_zscore})"
        }
      ]
    }
  },
  {
    "query_id": "pyprep_utils.py__get_random_subset_doc",
    "prompt": "How do I randomly sample a subset from a list or array without replacement?",
    "data": {
      "docs": [
        {
          "text": "def _get_random_subset(x, size, rand_state):\n    \"\"\"Get a random subset of items from a list or array, without replacement.\n\n    Parameters\n    ----------\n    x : list or np.ndarray\n        One-dimensional array of items to sample from.\n    size : int\n        The number of items to sample. Must be less than the number of input\n        items.\n    rand_state : np.random.RandomState\n        A random state object to use for random number generation.\n\n    Returns\n    -------\n    sample : list\n        A random subset of the input items.\n\n    Notes\n    -----\n    This function generates random subsets identical to the internal\n    ``randsample`` function in MATLAB PREP's ``findNoisyChannels.m``, allowing\n    the same random seed to produce identical results across both PyPREP and\n    MATLAB PREP.\n\n    \"\"\"\n    sample = []\n    remaining = list(x)\n    for val in rand_state.rand(size):\n        index = round(1 + (len(remaining) - 1) * val) - 1\n        pick = remaining.pop(index)\n        sample.append(pick)\n    return sample"
        },
        {
          "text": "def _make_interpolation_matrices(random_ch_picks, chn_pos_good):\n    \"\"\"Create an interpolation matrix for each RANSAC sample of channels.\n\n    This function takes the spatial coordinates of random subsets of currently-good\n    channels and uses them to predict what the signal will be at the spatial\n    coordinates of all other currently-good channels. The results of this process are\n    returned as matrices that can be multiplied with EEG data to generate predicted\n    signals.\n\n    Parameters\n    ----------\n    random_ch_picks : list of list of int\n        A list containing multiple random subsets of currently-good channels.\n    chn_pos_good : np.ndarray\n        3-D spatial coordinates of all currently-good channels.\n\n    Returns\n    -------\n    interpolation_mats : list of np.ndarray\n        A list of interpolation matrices, one for each random subset of channels.\n        Each matrix has the shape `[num_good_channels, num_good_channels]`, with the\n        number of good channels being inferred from the size of `ch_pos_good`.\n\n    Notes\n    -----\n    This function currently makes use of a private MNE function,\n    ``mne.channels.interpolation._make_interpolation_matrix``, to generate matrices.\n\n    \"\"\"\n    n_chans_good = chn_pos_good.shape[0]\n    interpolation_mats = []\n    for sample in random_ch_picks:\n        mat = np.zeros((n_chans_good, n_chans_good))\n        subset_pos = chn_pos_good[sample, :]\n        mat[:, sample] = _make_interpolation_matrix(subset_pos, chn_pos_good)\n        interpolation_mats.append(mat)\n    return interpolation_mats"
        },
        {
          "text": "def __init__(self, raw, prep_params, montage, ransac=True, channel_wise=False, max_chunk_size=None, random_state=None, filter_kwargs=None, matlab_strict=False):\n    \"\"\"Initialize PREP class.\"\"\"\n    raw.load_data()\n    self.raw_eeg = raw.copy()\n    self.ch_names_all = raw.ch_names.copy()\n    self.ch_types_all = raw.get_channel_types()\n    self.ch_names_eeg = [self.ch_names_all[i] for i in range(len(self.ch_names_all)) if self.ch_types_all[i] == 'eeg']\n    self.ch_names_non_eeg = list(set(self.ch_names_all) - set(self.ch_names_eeg))\n    self.raw_eeg.pick(self.ch_names_eeg)\n    if self.ch_names_non_eeg == []:\n        self.raw_non_eeg = None\n    else:\n        self.raw_non_eeg = raw.copy()\n        self.raw_non_eeg.pick(self.ch_names_non_eeg)\n    self.raw_eeg.set_montage(montage)\n    self.EEG_raw = self.raw_eeg.get_data()\n    self.prep_params = prep_params\n    if self.prep_params['ref_chs'] == 'eeg':\n        self.prep_params['ref_chs'] = self.ch_names_eeg\n    if self.prep_params['reref_chs'] == 'eeg':\n        self.prep_params['reref_chs'] = self.ch_names_eeg\n    if 'max_iterations' not in prep_params.keys():\n        self.prep_params['max_iterations'] = 4\n    self.sfreq = self.raw_eeg.info['sfreq']\n    self.ransac_settings = {'ransac': ransac, 'channel_wise': channel_wise, 'max_chunk_size': max_chunk_size}\n    self.random_state = check_random_state(random_state)\n    self.filter_kwargs = filter_kwargs\n    self.matlab_strict = matlab_strict"
        },
        {
          "text": "def __init__(self, raw, do_detrend=True, random_state=None, matlab_strict=False):\n    assert isinstance(raw, mne.io.BaseRaw)\n    raw.load_data()\n    self.raw_mne = raw.copy()\n    self.bad_by_manual = raw.info['bads']\n    self.raw_mne.pick('eeg')\n    self.sample_rate = raw.info['sfreq']\n    if do_detrend:\n        self.raw_mne._data = removeTrend(self.raw_mne.get_data(), self.sample_rate, matlab_strict=matlab_strict)\n    self.matlab_strict = matlab_strict\n    self._extra_info = {'bad_by_deviation': {}, 'bad_by_hf_noise': {}, 'bad_by_correlation': {}, 'bad_by_dropout': {}, 'bad_by_ransac': {}}\n    self.random_state = check_random_state(random_state)\n    self.bad_by_nan = []\n    self.bad_by_flat = []\n    self.bad_by_deviation = []\n    self.bad_by_hf_noise = []\n    self.bad_by_correlation = []\n    self.bad_by_SNR = []\n    self.bad_by_dropout = []\n    self.bad_by_ransac = []\n    ch_names = np.asarray(self.raw_mne.info['ch_names'])\n    self.ch_names_original = ch_names\n    self.n_chans_original = len(ch_names)\n    self.n_samples = raw.get_data().shape[1]\n    self.find_bad_by_nan_flat()\n    bads_by_nan_flat = self.bad_by_nan + self.bad_by_flat\n    self.usable_idx = np.isin(ch_names, bads_by_nan_flat, invert=True)\n    self.EEGData = self.raw_mne.get_data(picks=ch_names[self.usable_idx])\n    self.EEGFiltered = None\n    self.ch_names_new = np.asarray(ch_names[self.usable_idx])\n    self.n_chans_new = len(self.ch_names_new)"
        },
        {
          "text": "def _set_diff(list1, list2):\n    return list(set(list1) - set(list2))"
        }
      ]
    }
  },
  {
    "query_id": "pyprep_utils.py__correlate_arrays_doc",
    "prompt": "How can I calculate correlations between two 2D EEG arrays, with optional MATLAB-style behavior?",
    "data": {
      "docs": [
        {
          "text": "def _correlate_arrays(a, b, matlab_strict=False):\n    \"\"\"Calculate correlations between two equally-sized 2-D arrays of EEG data.\n\n    Both input arrays must be in the shape (channels, samples).\n\n    Parameters\n    ----------\n    a : np.ndarray\n        A 2-D array to correlate with `a`.\n    b : np.ndarray\n        A 2-D array to correlate with `b`.\n    matlab_strict : bool, optional\n        Whether or not correlations should be calculated identically to MATLAB\n        PREP (i.e., without mean subtraction) instead of by traditional Pearson\n        product-moment correlation (see Notes for details). Defaults to\n        ``False`` (Pearson correlation).\n\n    Returns\n    -------\n    correlations : np.ndarray\n        A one-dimensional array containing the correlations of the two input arrays\n        along the second axis.\n\n    Notes\n    -----\n    In MATLAB PREP, RANSAC channel predictions are correlated with actual data\n    using a non-standard method: essentially, it uses the standard Pearson\n    correlation formula but without subtracting the channel means from each channel\n    before calculating sums of squares, i.e.,::\n\n       SSa = np.sum(a ** 2)\n       SSb = np.sum(b ** 2)\n       correlation = np.sum(a * b) / (np.sqrt(SSa) * np.sqrt(SSb))\n\n    Because EEG data is roughly mean-centered to begin with, this produces similar\n    values to normal Pearson correlation. However, to avoid making any assumptions\n    about the signal for any given channel/window, PyPREP defaults to normal\n    Pearson correlation unless strict MATLAB equivalence is requested.\n\n    \"\"\"\n    if matlab_strict:\n        SSa = np.sum(a ** 2, axis=1)\n        SSb = np.sum(b ** 2, axis=1)\n        SSab = np.sum(a * b, axis=1)\n        return SSab / (np.sqrt(SSa) * np.sqrt(SSb))\n    else:\n        n_chan = a.shape[0]\n        return np.diag(np.corrcoef(a, b)[:n_chan, n_chan:])"
        },
        {
          "text": "def _ransac_by_window(data, interpolation_mats, win_size, win_count, matlab_strict):\n    \"\"\"Calculate correlations of channels with their RANSAC-predicted values.\n\n    This function calculates RANSAC correlations for each RANSAC window\n    individually, requiring RAM equivalent to [channels * sample rate * seconds\n    per RANSAC window] to run. Generally, this method will use less RAM than\n    :func:`_ransac_by_channel`, with the exception of short recordings with high\n    electrode counts.\n\n    Parameters\n    ----------\n    data : np.ndarray\n        A 2-D array containing the EEG signals from all currently-good channels.\n    interpolation_mats : list of np.ndarray\n        A list of interpolation matrices, one for each RANSAC sample of channels.\n    win_size : int\n        Number of frames/samples of EEG data in each RANSAC correlation window.\n    win_count: int\n        Number of RANSAC correlation windows.\n    matlab_strict : bool\n        Whether or not RANSAC should strictly follow MATLAB PREP's internal\n        math, ignoring any improvements made in PyPREP over the original code.\n\n    Returns\n    -------\n    correlations : np.ndarray\n        Correlations of the given channels to their predicted values within each\n        RANSAC window.\n\n    \"\"\"\n    ch_count = data.shape[0]\n    correlations = np.ones((win_count, ch_count))\n    pb = ProgressBar(range(win_count))\n    for window in pb:\n        start = window * win_size\n        end = (window + 1) * win_size\n        actual = data[:, start:end]\n        predicted = _predict_median_signals(actual, interpolation_mats, matlab_strict)\n        correlations[window, :] = _correlate_arrays(actual, predicted, matlab_strict)\n    return correlations"
        },
        {
          "text": "def runline(y, n, dn):\n    \"\"\"Perform local linear regression on a channel of EEG data.\n\n    A re-implementation of the ``runline`` function from the Chronux package\n    for MATLAB [1]_.\n\n    Parameters\n    ----------\n    y : np.ndarray\n        A 1-D array of data from a single EEG channel.\n    n : int\n        Length of the detrending window.\n    dn : int\n        Length of the window step size.\n\n    Returns\n    -------\n    y: np.ndarray\n       The detrended signal for the given EEG channel.\n\n    References\n    ----------\n    .. [1] http://chronux.org/\n\n    \"\"\"\n    nt = y.shape[0]\n    y_line = np.zeros((nt, 1))\n    norm = np.zeros((nt, 1))\n    nwin = int(np.ceil((nt - n) / dn))\n    yfit = np.zeros((nwin, n))\n    xwt = (np.arange(1, n + 1) - n / 2) / (n / 2)\n    wt = np.power(1 - np.power(np.absolute(xwt), 3), 3)\n    for j in range(0, nwin):\n        tseg = y[dn * j:dn * j + n]\n        y1 = np.mean(tseg)\n        y2 = np.mean(np.multiply(np.arange(1, n + 1), tseg)) * (2 / (n + 1))\n        a = np.multiply(np.subtract(y2, y1), 6 / (n - 1))\n        b = np.subtract(y1, a * (n + 1) / 2)\n        yfit[j, :] = np.multiply(np.arange(1, n + 1), a) + b\n        y_line[j * dn:j * dn + n] = y_line[j * dn:j * dn + n] + np.reshape(np.multiply(yfit[j, :], wt), (n, 1))\n        norm[j * dn:j * dn + n] = norm[j * dn:j * dn + n] + np.reshape(wt, (n, 1))\n    for i in range(0, len(norm)):\n        if norm[i] > 0:\n            y_line[i] = y_line[i] / norm[i]\n    indx = (nwin - 1) * dn + n - 1\n    npts = len(y) - indx + 1\n    y_line[indx - 1:] = np.reshape(np.multiply(np.arange(n + 1, n + npts + 1), a) + b, (npts, 1))\n    for i in range(0, len(y_line)):\n        y[i] = y[i] - y_line[i, 0]\n    return y"
        },
        {
          "text": "def _eeglab_interpolate(data, pos_from, pos_to):\n    \"\"\"Interpolate bad channels using EEGLAB's custom method.\n\n    Parameters\n    ----------\n    data : np.ndarray\n        A 2-D array containing signals from currently-good EEG channels with\n        which to interpolate signals for bad channels.\n    pos_from : np.ndarray of float, shape(n_good_sensors, 3)\n        The electrode positions to interpolate from.\n    pos_to : np.ndarray of float, shape(n_bad_sensors, 3)\n        The electrode positions to interpolate.\n\n    Returns\n    -------\n    interpolated : np.ndarray\n        The interpolated signals for all bad channels.\n\n    Notes\n    -----\n    Produces identical output to the private ``spheric_spline`` function in\n    EEGLAB's ``eeg_interp.m`` (with minor rounding errors).\n\n    \"\"\"\n    G_from = _eeglab_calc_g(pos_from, pos_from)\n    G_to_from = _eeglab_calc_g(pos_from, pos_to)\n    avg_ref = np.mean(data, axis=0)\n    data_tmp = data - avg_ref\n    pad_ones = np.ones((1, pos_from.shape[0]))\n    C_inv = linalg.pinv(np.vstack([G_from, pad_ones]))\n    interp_mat = np.matmul(G_to_from, C_inv[:, :-1])\n    interpolated = np.matmul(interp_mat, data_tmp) + avg_ref\n    return interpolated"
        },
        {
          "text": "def _ransac_by_channel(data, interpolation_mats, win_size, win_count, chans_to_predict, random_ch_picks, matlab_strict):\n    \"\"\"Calculate correlations of channels with their RANSAC-predicted values.\n\n    This function calculates RANSAC correlations on one (or more) full channels\n    at once, requiring RAM equivalent to [channels per chunk * sample rate *\n    length of recording in seconds] to run. Generally, this method will use\n    more RAM than :func:`_ransac_by_window`, but may be faster for systems with\n    large amounts of RAM.\n\n    Parameters\n    ----------\n    data : np.ndarray\n        A 2-D array containing the EEG signals from all currently-good channels.\n    interpolation_mats : list of np.ndarray\n        A set of channel interpolation matrices, one for each RANSAC sample of\n        channels.\n    win_size : int\n        Number of frames/samples of EEG data in each RANSAC correlation window.\n    win_count: int\n        Number of RANSAC correlation windows.\n    chans_to_predict : list of int\n        Indices of the channels to predict (as they appear in `data`) within the\n        current chunk.\n    random_ch_picks : list of list of int\n        A list containing multiple random subsets of currently-good channels.\n    matlab_strict : bool\n        Whether or not RANSAC should strictly follow MATLAB PREP's internal\n        math, ignoring any improvements made in PyPREP over the original code.\n\n    Returns\n    -------\n    correlations : np.ndarray\n        Correlations of the given channels to their predicted values within each\n        RANSAC window.\n\n    \"\"\"\n    chunk_size = len(chans_to_predict)\n    correlations = np.ones((win_count, chunk_size))\n    predicted_chans = _predict_median_signals_channelwise(data=data, interpolation_mats=interpolation_mats, random_ch_picks=random_ch_picks, chunk_size=len(chans_to_predict), matlab_strict=matlab_strict)\n    data_window = data[chans_to_predict, :win_size * win_count]\n    data_window = data_window.reshape(chunk_size, win_count, win_size)\n    data_window = data_window.swapaxes(1, 0)\n    pred_window = predicted_chans[:chunk_size, :win_size * win_count]\n    pred_window = pred_window.reshape(chunk_size, win_count, win_size)\n    pred_window = pred_window.swapaxes(1, 0)\n    for k in range(win_count):\n        data_portion = data_window[k, :, :]\n        pred_portion = pred_window[k, :, :]\n        R = _correlate_arrays(data_portion, pred_portion, matlab_strict)\n        correlations[k, :] = R\n    return correlations"
        }
      ]
    }
  },
  {
    "query_id": "pyprep_utils.py__filter_design_doc",
    "prompt": "How do I create a FIR low-pass filter for EEG data using the frequency sampling method?",
    "data": {
      "docs": [
        {
          "text": "def _get_filtered_data(self):\n    \"\"\"Apply a [1 Hz - 50 Hz] bandpass filter to the EEG signal.\n\n        Only applied if the sample rate is above 100 Hz to avoid violating the\n        Nyquist theorem.\n\n        \"\"\"\n    if self.sample_rate <= 100:\n        return self.EEGData.copy()\n    bandpass_filter = _filter_design(N_order=100, amp=np.array([1, 1, 0, 0]), freq=np.array([0, 90 / self.sample_rate, 100 / self.sample_rate, 1]))\n    EEG_filt = np.zeros_like(self.EEGData)\n    for i in range(EEG_filt.shape[0]):\n        EEG_filt[i, :] = signal.filtfilt(bandpass_filter, 1, self.EEGData[i, :])\n    return EEG_filt"
        },
        {
          "text": "def _eeglab_fir_filter(data, filt):\n    \"\"\"Apply an FIR filter to a 2-D array of EEG data.\n\n    Parameters\n    ----------\n    data : np.ndarray\n        A 2-D array of EEG data to filter.\n    filt : np.ndarray\n        A 1-D array of FIR filter coefficients.\n\n    Returns\n    -------\n    filtered : np.ndarray\n        A 2-D array of FIR-filtered EEG data.\n\n    Notes\n    -----\n    Produces identical output to EEGLAB's ``firfilt`` function (for non-epoched\n    data). For internal use within :mod:`pyprep.removeTrend`.\n\n    \"\"\"\n    frames_per_window = 2000\n    group_delay = int((len(filt) - 1) / 2)\n    n_samples = data.shape[1]\n    n_windows = int(np.ceil((n_samples - group_delay) / frames_per_window))\n    pad_len = min(group_delay, n_samples)\n    start_pad_idx = np.zeros(pad_len, dtype=np.uint)\n    start_padded = np.concatenate((data[:, start_pad_idx], data[:, :pad_len]), axis=1)\n    zi_init = lfilter_zi(filt, 1) * np.take(start_padded, [0], axis=0)\n    (_, zi) = lfilter(filt, 1, start_padded, axis=1, zi=zi_init)\n    out = np.zeros_like(data)\n    for w in range(n_windows):\n        start = group_delay + w * frames_per_window\n        end = min(start + frames_per_window, n_samples)\n        start_out = start - group_delay\n        end_out = end - group_delay\n        (out[:, start_out:end_out], zi) = lfilter(filt, 1, data[:, start:end], axis=1, zi=zi)\n    end_pad_idx = np.zeros(pad_len, dtype=np.uint) + (n_samples - 1)\n    (end, _) = lfilter(filt, 1, data[:, end_pad_idx], axis=1, zi=zi)\n    out[:, n_samples - pad_len:] = end[:, group_delay - pad_len:]\n    return out"
        },
        {
          "text": "def _eeglab_create_highpass(cutoff, srate):\n    \"\"\"Create a high-pass FIR filter using Hamming windows.\n\n    Parameters\n    ----------\n    cutoff : float\n        The lower pass-band edge of the filter, in Hz.\n    srate : float\n        The sampling rate of the EEG signal, in Hz.\n\n    Returns\n    -------\n    filter : np.ndarray\n        A 1-dimensional array of FIR filter coefficients.\n\n    Notes\n    -----\n    In MATLAB PREP, the internal ``removeTrend`` function uses EEGLAB's\n    ``pop_eegfiltnew`` to high-pass the EEG data to remove slow drifts.\n    Because MNE's ``mne.filter.filter_data`` and EEGLAB's ``pop_eegfiltnew``\n    calculate filter parameters slightly differently, this function is\n    used to precisely match EEGLAB & MATLAB PREP's filtering method.\n\n    \"\"\"\n    TRANSITION_WIDTH_RATIO = 0.25\n    HAMMING_CONSTANT = 3.3\n    trans_bandwidth = cutoff if cutoff < 2 else cutoff * TRANSITION_WIDTH_RATIO\n    order = HAMMING_CONSTANT / (trans_bandwidth / srate)\n    order = int(np.ceil(order / 2) * 2)\n    stop = cutoff - trans_bandwidth\n    transition = (stop + cutoff) / srate\n    N = order + 1\n    filt = np.zeros(N)\n    filt[N // 2] = 1\n    filt -= firwin(N, transition, window='hamming')\n    return filt"
        },
        {
          "text": "def _filter_design(N_order, amp, freq):\n    \"\"\"Create FIR low-pass filter for EEG data using frequency sampling method.\n\n    Parameters\n    ----------\n    N_order : int\n        Order of the filter.\n    amp : list of int\n        Amplitude vector for the frequencies.\n    freq : list of int\n        Frequency vector for which amplitude can be either 0 or 1.\n\n    Returns\n    -------\n    kernel : np.ndarray\n        Filter kernel.\n\n    \"\"\"\n    nfft = np.maximum(512, 2 ** np.ceil(math.log(100) / math.log(2)))\n    hamming_window = np.subtract(0.54, np.multiply(0.46, np.cos(np.divide(np.multiply(2 * math.pi, np.arange(N_order + 1)), N_order))))\n    pchip_interpolate = scipy.interpolate.PchipInterpolator(np.round(np.multiply(nfft, freq)), amp)\n    freq = pchip_interpolate(np.arange(nfft + 1))\n    freq = np.multiply(freq, np.exp(np.divide(np.multiply(-(0.5 * N_order) * sqrt(-1) * math.pi, np.arange(nfft + 1)), nfft)))\n    kernel = np.real(np.fft.ifft(np.concatenate([freq, np.conj(freq[len(freq) - 2:0:-1])])))\n    kernel = np.multiply(kernel[0:N_order + 1], np.transpose(hamming_window[:]))\n    return kernel"
        },
        {
          "text": "def removeTrend(EEG, sample_rate, detrendType='high pass', detrendCutoff=1.0, detrendChannels=None, matlab_strict=False):\n    \"\"\"Remove trends (i.e., slow drifts in baseline) from an array of EEG data.\n\n    Parameters\n    ----------\n    EEG : np.ndarray\n        A 2-D array of EEG data to detrend.\n    sample_rate : float\n        The sample rate (in Hz) of the input EEG data.\n    detrendType : str, optional\n        Type of detrending to be performed: must be one of 'high pass',\n        'high pass sinc, or 'local detrend'. Defaults to 'high pass'.\n    detrendCutoff : float, optional\n        The high-pass cutoff frequency (in Hz) to use for detrending. Defaults\n        to 1.0 Hz.\n    detrendChannels : {list, None}, optional\n        List of the indices of all channels that require detrending/filtering.\n        If ``None``, all channels are used (default).\n    matlab_strict : bool, optional\n        Whether or not detrending should strictly follow MATLAB PREP's internal\n        math, ignoring any improvements made in PyPREP over the original code\n        (see :ref:`matlab-diffs` for more details). Defaults to ``False``.\n\n    Returns\n    -------\n    EEG : np.ndarray\n        A 2-D array containing the filtered/detrended EEG data.\n\n    Notes\n    -----\n    High-pass filtering is implemented using the MNE filter function\n    :func:``mne.filter.filter_data`` unless `matlab_strict` is ``True``, in\n    which case it is performed using a minimal re-implementation of EEGLAB's\n    ``pop_eegfiltnew``. Local detrending is performed using a Python\n    re-implementation of the ``runline`` function from the Chronux package for\n    MATLAB [1]_.\n\n    References\n    ----------\n    .. [1] http://chronux.org/\n\n    \"\"\"\n    if len(EEG.shape) == 1:\n        EEG = np.reshape(EEG, (1, EEG.shape[0]))\n    if detrendType.lower() == 'high pass':\n        if matlab_strict:\n            picks = detrendChannels if detrendChannels else range(EEG.shape[0])\n            filt = _eeglab_create_highpass(detrendCutoff, sample_rate)\n            EEG[picks, :] = _eeglab_fir_filter(EEG[picks, :], filt)\n        else:\n            EEG = mne.filter.filter_data(EEG, sfreq=sample_rate, l_freq=detrendCutoff, h_freq=None, picks=detrendChannels)\n    elif detrendType.lower() == 'high pass sinc':\n        fOrder = np.round(14080 * sample_rate / 512)\n        fOrder = int(fOrder + fOrder % 2)\n        EEG = mne.filter.filter_data(data=EEG, sfreq=sample_rate, l_freq=1, h_freq=None, picks=detrendChannels, filter_length=fOrder, fir_window='blackman')\n    elif detrendType.lower() == 'local detrend':\n        if detrendChannels is None:\n            detrendChannels = np.arange(0, EEG.shape[0])\n        windowSize = 1.5 / detrendCutoff\n        windowSize = np.minimum(windowSize, EEG.shape[1])\n        stepSize = 0.02\n        EEG = np.transpose(EEG)\n        n = np.round(sample_rate * windowSize)\n        dn = np.round(sample_rate * stepSize)\n        if dn > n or dn < 1:\n            logging.error('Step size should be less than the window size and contain at least 1 sample')\n        if n == EEG.shape[0]:\n            pass\n        else:\n            for ch in detrendChannels:\n                EEG[:, ch] = runline(EEG[:, ch], int(n), int(dn))\n        EEG = np.transpose(EEG)\n    else:\n        logging.warning('No filtering/detreding performed since the detrend type did not match')\n    return EEG"
        }
      ]
    }
  },
  {
    "query_id": "pyprep_utils.py__split_list_doc",
    "prompt": "How can I split a list into chunks of a specified size in Python?",
    "data": {
      "docs": [
        {
          "text": "def _split_list(mylist, chunk_size):\n    \"\"\"Split list in chunks.\n\n    Parameters\n    ----------\n    my_list: list\n        list to split.\n    chunk_size: int\n        size of the lists returned.\n\n    Returns\n    -------\n    list\n        list of the chunked lists.\n\n    See: https://stackoverflow.com/a/312466/5201771\n    \"\"\"\n    return [mylist[offs:offs + chunk_size] for offs in range(0, len(mylist), chunk_size)]"
        },
        {
          "text": "def _union(list1, list2):\n    return list(set(list1 + list2))"
        },
        {
          "text": "def _get_random_subset(x, size, rand_state):\n    \"\"\"Get a random subset of items from a list or array, without replacement.\n\n    Parameters\n    ----------\n    x : list or np.ndarray\n        One-dimensional array of items to sample from.\n    size : int\n        The number of items to sample. Must be less than the number of input\n        items.\n    rand_state : np.random.RandomState\n        A random state object to use for random number generation.\n\n    Returns\n    -------\n    sample : list\n        A random subset of the input items.\n\n    Notes\n    -----\n    This function generates random subsets identical to the internal\n    ``randsample`` function in MATLAB PREP's ``findNoisyChannels.m``, allowing\n    the same random seed to produce identical results across both PyPREP and\n    MATLAB PREP.\n\n    \"\"\"\n    sample = []\n    remaining = list(x)\n    for val in rand_state.rand(size):\n        index = round(1 + (len(remaining) - 1) * val) - 1\n        pick = remaining.pop(index)\n        sample.append(pick)\n    return sample"
        },
        {
          "text": "def __init__(self, raw, prep_params, montage, ransac=True, channel_wise=False, max_chunk_size=None, random_state=None, filter_kwargs=None, matlab_strict=False):\n    \"\"\"Initialize PREP class.\"\"\"\n    raw.load_data()\n    self.raw_eeg = raw.copy()\n    self.ch_names_all = raw.ch_names.copy()\n    self.ch_types_all = raw.get_channel_types()\n    self.ch_names_eeg = [self.ch_names_all[i] for i in range(len(self.ch_names_all)) if self.ch_types_all[i] == 'eeg']\n    self.ch_names_non_eeg = list(set(self.ch_names_all) - set(self.ch_names_eeg))\n    self.raw_eeg.pick(self.ch_names_eeg)\n    if self.ch_names_non_eeg == []:\n        self.raw_non_eeg = None\n    else:\n        self.raw_non_eeg = raw.copy()\n        self.raw_non_eeg.pick(self.ch_names_non_eeg)\n    self.raw_eeg.set_montage(montage)\n    self.EEG_raw = self.raw_eeg.get_data()\n    self.prep_params = prep_params\n    if self.prep_params['ref_chs'] == 'eeg':\n        self.prep_params['ref_chs'] = self.ch_names_eeg\n    if self.prep_params['reref_chs'] == 'eeg':\n        self.prep_params['reref_chs'] = self.ch_names_eeg\n    if 'max_iterations' not in prep_params.keys():\n        self.prep_params['max_iterations'] = 4\n    self.sfreq = self.raw_eeg.info['sfreq']\n    self.ransac_settings = {'ransac': ransac, 'channel_wise': channel_wise, 'max_chunk_size': max_chunk_size}\n    self.random_state = check_random_state(random_state)\n    self.filter_kwargs = filter_kwargs\n    self.matlab_strict = matlab_strict"
        },
        {
          "text": "def _set_diff(list1, list2):\n    return list(set(list1) - set(list2))"
        }
      ]
    }
  },
  {
    "query_id": "pyprep_utils.py__verify_free_ram_doc",
    "prompt": "How do I check if there is enough free RAM to safely run RANSAC on EEG data?",
    "data": {
      "docs": [
        {
          "text": "def _verify_free_ram(data, n_samples, n_channels, max_prop=0.95):\n    \"\"\"Check if enough memory is free to run RANSAC with the given parameters.\n\n    Parameters\n    ----------\n    data : np.ndarray\n        2-D EEG data\n    n_samples : int\n        Number of samples to use for computation of RANSAC.\n    n_channels : int\n        Number of channels to process per chunk.\n    max_prop : float\n        The maximum proportion of available memory that RANSAC is allowed to\n        use.\n\n    Raises\n    ------\n    MemoryError\n        If insufficient free memory to perform RANSAC with the given data and\n        parameters.\n\n    \"\"\"\n    available_gb = virtual_memory().available * 1e-09 * max_prop\n    needed_gb = data[0, :].nbytes * 1e-09 * n_samples * n_channels\n    if available_gb < needed_gb:\n        ram_diff = needed_gb - available_gb\n        raise MemoryError(f'For given data of shape {data.shape} and the requested number of {n_samples} samples, {ram_diff} GB of additional memory would be needed. You could close other programs, downsample the data, or reduce the number of requested samples.')"
        },
        {
          "text": "def _ransac_by_channel(data, interpolation_mats, win_size, win_count, chans_to_predict, random_ch_picks, matlab_strict):\n    \"\"\"Calculate correlations of channels with their RANSAC-predicted values.\n\n    This function calculates RANSAC correlations on one (or more) full channels\n    at once, requiring RAM equivalent to [channels per chunk * sample rate *\n    length of recording in seconds] to run. Generally, this method will use\n    more RAM than :func:`_ransac_by_window`, but may be faster for systems with\n    large amounts of RAM.\n\n    Parameters\n    ----------\n    data : np.ndarray\n        A 2-D array containing the EEG signals from all currently-good channels.\n    interpolation_mats : list of np.ndarray\n        A set of channel interpolation matrices, one for each RANSAC sample of\n        channels.\n    win_size : int\n        Number of frames/samples of EEG data in each RANSAC correlation window.\n    win_count: int\n        Number of RANSAC correlation windows.\n    chans_to_predict : list of int\n        Indices of the channels to predict (as they appear in `data`) within the\n        current chunk.\n    random_ch_picks : list of list of int\n        A list containing multiple random subsets of currently-good channels.\n    matlab_strict : bool\n        Whether or not RANSAC should strictly follow MATLAB PREP's internal\n        math, ignoring any improvements made in PyPREP over the original code.\n\n    Returns\n    -------\n    correlations : np.ndarray\n        Correlations of the given channels to their predicted values within each\n        RANSAC window.\n\n    \"\"\"\n    chunk_size = len(chans_to_predict)\n    correlations = np.ones((win_count, chunk_size))\n    predicted_chans = _predict_median_signals_channelwise(data=data, interpolation_mats=interpolation_mats, random_ch_picks=random_ch_picks, chunk_size=len(chans_to_predict), matlab_strict=matlab_strict)\n    data_window = data[chans_to_predict, :win_size * win_count]\n    data_window = data_window.reshape(chunk_size, win_count, win_size)\n    data_window = data_window.swapaxes(1, 0)\n    pred_window = predicted_chans[:chunk_size, :win_size * win_count]\n    pred_window = pred_window.reshape(chunk_size, win_count, win_size)\n    pred_window = pred_window.swapaxes(1, 0)\n    for k in range(win_count):\n        data_portion = data_window[k, :, :]\n        pred_portion = pred_window[k, :, :]\n        R = _correlate_arrays(data_portion, pred_portion, matlab_strict)\n        correlations[k, :] = R\n    return correlations"
        },
        {
          "text": "def _ransac_by_window(data, interpolation_mats, win_size, win_count, matlab_strict):\n    \"\"\"Calculate correlations of channels with their RANSAC-predicted values.\n\n    This function calculates RANSAC correlations for each RANSAC window\n    individually, requiring RAM equivalent to [channels * sample rate * seconds\n    per RANSAC window] to run. Generally, this method will use less RAM than\n    :func:`_ransac_by_channel`, with the exception of short recordings with high\n    electrode counts.\n\n    Parameters\n    ----------\n    data : np.ndarray\n        A 2-D array containing the EEG signals from all currently-good channels.\n    interpolation_mats : list of np.ndarray\n        A list of interpolation matrices, one for each RANSAC sample of channels.\n    win_size : int\n        Number of frames/samples of EEG data in each RANSAC correlation window.\n    win_count: int\n        Number of RANSAC correlation windows.\n    matlab_strict : bool\n        Whether or not RANSAC should strictly follow MATLAB PREP's internal\n        math, ignoring any improvements made in PyPREP over the original code.\n\n    Returns\n    -------\n    correlations : np.ndarray\n        Correlations of the given channels to their predicted values within each\n        RANSAC window.\n\n    \"\"\"\n    ch_count = data.shape[0]\n    correlations = np.ones((win_count, ch_count))\n    pb = ProgressBar(range(win_count))\n    for window in pb:\n        start = window * win_size\n        end = (window + 1) * win_size\n        actual = data[:, start:end]\n        predicted = _predict_median_signals(actual, interpolation_mats, matlab_strict)\n        correlations[window, :] = _correlate_arrays(actual, predicted, matlab_strict)\n    return correlations"
        },
        {
          "text": "def find_bad_by_ransac(data, sample_rate, complete_chn_labs, chn_pos, exclude, n_samples=50, sample_prop=0.25, corr_thresh=0.75, frac_bad=0.4, corr_window_secs=5.0, channel_wise=False, max_chunk_size=None, random_state=None, matlab_strict=False):\n    \"\"\"Detect channels that are not predicted well by other channels.\n\n    Here, a RANSAC approach (see [1]_, and a short discussion in [2]_) is\n    adopted to predict a \"clean EEG\" dataset. After identifying clean EEG\n    channels through the other methods, the clean EEG dataset is\n    constructed by repeatedly sampling a small subset of clean EEG channels\n    and interpolation the complete data. The median of all those\n    repetitions forms the clean EEG dataset. In a second step, the original\n    and the RANSAC-predicted data are correlated and channels, which do not\n    correlate well with themselves across the two datasets are considered\n    `bad_by_ransac`.\n\n    Parameters\n    ----------\n    data : np.ndarray\n        A 2-D array of detrended EEG data, with bad-by-flat and bad-by-NaN\n        channels removed.\n    sample_rate : float\n        The sample rate (in Hz) of the EEG data.\n    complete_chn_labs : array_like\n        Labels for all channels in `data`, in the same order as they appear\n        in `data`.\n    chn_pos : np.ndarray\n        3-D electrode coordinates for all channels in `data`, in the same order\n        as they appear in `data`.\n    exclude : list\n        Labels of channels to exclude as signal predictors during RANSAC\n        (i.e., channels already flagged as bad by metrics other than HF noise).\n    n_samples : int, optional\n        Number of random channel samples to use for RANSAC. Defaults to ``50``.\n    sample_prop : float, optional\n        Proportion of total channels to use for signal prediction per RANSAC\n        sample. This needs to be in the range [0, 1], where 0 would mean no\n        channels would be used and 1 would mean all channels would be used\n        (neither of which would be useful values). Defaults to ``0.25`` (e.g.,\n        16 channels per sample for a 64-channel dataset).\n    corr_thresh : float, optional\n        The minimum predicted vs. actual signal correlation for a channel to\n        be considered good within a given RANSAC window. Defaults to ``0.75``.\n    frac_bad : float, optional\n        The minimum fraction of bad (i.e., below-threshold) RANSAC windows for a\n        channel to be considered bad-by-RANSAC. Defaults to ``0.4``.\n    corr_window_secs : float, optional\n        The duration (in seconds) of each RANSAC correlation window. Defaults to\n        5 seconds.\n    channel_wise : bool, optional\n        Whether RANSAC should predict signals for chunks of channels over the\n        entire signal length (\"channel-wise RANSAC\", see `max_chunk_size`\n        parameter). If ``False``, RANSAC will instead predict signals for all\n        channels at once but over a number of smaller time windows instead of\n        over the entire signal length (\"window-wise RANSAC\"). Channel-wise\n        RANSAC generally has higher RAM demands than window-wise RANSAC\n        (especially if `max_chunk_size` is ``None``), but can be faster on\n        systems with lots of RAM to spare. Defaults to ``False``.\n    max_chunk_size : {int, None}, optional\n        The maximum number of channels to predict at once during channel-wise\n        RANSAC. If ``None``, RANSAC will use the largest chunk size that will\n        fit into the available RAM, which may slow down other programs on the\n        host system. If using window-wise RANSAC (the default), this parameter\n        has no effect. Defaults to ``None``.\n    random_state : {int, None, np.random.RandomState}, optional\n        The random seed with which to generate random samples of channels during\n        RANSAC. If random_state is an int, it will be used as a seed for RandomState.\n        If ``None``, the seed will be obtained from the operating system\n        (see RandomState for details). Defaults to ``None``.\n    matlab_strict : bool, optional\n        Whether or not RANSAC should strictly follow MATLAB PREP's internal\n        math, ignoring any improvements made in PyPREP over the original code\n        (see :ref:`matlab-diffs` for more details). Defaults to ``False``.\n\n    Returns\n    -------\n    bad_by_ransac : list\n        List containing the labels of all channels flagged as bad by RANSAC.\n    channel_correlations : np.ndarray\n        Array of shape (windows, channels) containing the correlations of\n        the channels with their predicted RANSAC values for each window.\n\n    References\n    ----------\n    .. [1] Fischler, M.A., Bolles, R.C. (1981). Random sample consensus: A\n        Paradigm for Model Fitting with Applications to Image Analysis and\n        Automated Cartography. Communications of the ACM, 24, 381-395\n    .. [2] Jas, M., Engemann, D.A., Bekhti, Y., Raimondo, F., Gramfort, A.\n        (2017). Autoreject: Automated Artifact Rejection for MEG and EEG\n        Data. NeuroImage, 159, 417-429\n\n    \"\"\"\n    if np.isnan(chn_pos).any():\n        raise ValueError('Found NaN in channel positions. Did you supply a montage for the raw data?')\n    if not isinstance(n_samples, int):\n        raise TypeError(f\"Argument 'n_samples' must be an int (got {type(n_samples).__name__})\")\n    complete_chn_labs = np.asarray(complete_chn_labs)\n    good_idx = np.array([idx for (idx, ch) in enumerate(complete_chn_labs) if ch not in exclude])\n    n_chans_good = good_idx.shape[0]\n    chn_pos_good = chn_pos[good_idx, :]\n    n_chans = data.shape[0]\n    n_pred_chns = int(np.around(sample_prop * n_chans))\n    if n_pred_chns <= 3:\n        sample_pct = int(sample_prop * 100)\n        raise OSError(f'Too few channels in the original data to reliably perform RANSAC(minimum {int(np.floor(4.0 / sample_prop))} for a sample size of {sample_pct}%).')\n    elif n_chans_good < n_pred_chns + 1:\n        raise OSError(f'Too many noisy channels in the data to reliably perform RANSAC (only {n_chans_good} good channels remaining, need at least {n_pred_chns + 1}).')\n    if channel_wise:\n        _verify_free_ram(data, n_samples, 1)\n    else:\n        window_size = int(sample_rate * corr_window_secs)\n        _verify_free_ram(data[:, :window_size], n_samples, n_chans_good)\n    random_ch_picks = []\n    good_chans = np.arange(chn_pos_good.shape[0])\n    rng = check_random_state(random_state)\n    for i in range(n_samples):\n        picks = _get_random_subset(good_chans, n_pred_chns, rng)\n        random_ch_picks.append(picks)\n    interp_mats = _make_interpolation_matrices(random_ch_picks, chn_pos_good)\n    correlation_frames = corr_window_secs * sample_rate\n    signal_frames = data.shape[1]\n    correlation_offsets = np.arange(0, signal_frames - correlation_frames, correlation_frames)\n    win_size = int(correlation_frames)\n    win_count = correlation_offsets.shape[0]\n    n_chans_complete = len(complete_chn_labs)\n    channel_correlations = np.ones((win_count, n_chans_complete))\n    logger.info('Executing RANSAC\\nThis may take a while, so be patient...')\n    if not channel_wise:\n        channel_correlations[:, good_idx] = _ransac_by_window(data[good_idx, :], interp_mats, win_size, win_count, matlab_strict)\n    chunk_sizes = []\n    chunk_count = 0\n    for i in range(1, n_chans_good + 1):\n        n_chunks = int(np.ceil(n_chans_good / i))\n        if n_chunks != chunk_count:\n            chunk_count = n_chunks\n            if not max_chunk_size or i <= max_chunk_size:\n                chunk_sizes.append(i)\n    chunk_size = chunk_sizes.pop()\n    mem_error = True\n    job = list(range(n_chans_good))\n    while mem_error and channel_wise:\n        try:\n            channel_chunks = _split_list(job, chunk_size)\n            total_chunks = len(channel_chunks)\n            current = 1\n            for chunk in channel_chunks:\n                interp_mats_for_chunk = [mat[chunk, :] for mat in interp_mats]\n                channel_correlations[:, good_idx[chunk]] = _ransac_by_channel(data[good_idx, :], interp_mats_for_chunk, win_size, win_count, chunk, random_ch_picks, matlab_strict)\n                if chunk == channel_chunks[0]:\n                    logger.info('Finding optimal chunk size : %s', chunk_size)\n                    logger.info('Total # of chunks: %s', total_chunks)\n                    logger.info('Current chunk:')\n                logger.info(current)\n                current = current + 1\n            mem_error = False\n            del current\n        except MemoryError:\n            if len(chunk_sizes):\n                chunk_size = chunk_sizes.pop()\n            else:\n                raise MemoryError('Not even doing 1 channel at a time the data fits in ram...You could downsample the data or reduce the number of requested samples.')\n    thresholded_correlations = channel_correlations < corr_thresh\n    frac_bad_corr_windows = np.mean(thresholded_correlations, axis=0)\n    bad_ransac_channels_idx = np.argwhere(frac_bad_corr_windows > frac_bad)\n    bad_ransac_channels_name = complete_chn_labs[bad_ransac_channels_idx.astype(int)]\n    bad_by_ransac = [i[0] for i in bad_ransac_channels_name]\n    logger.info('\\nRANSAC done!')\n    return (bad_by_ransac, channel_correlations)"
        },
        {
          "text": "def find_all_bads(self, ransac=True, channel_wise=False, max_chunk_size=None):\n    \"\"\"Call all the functions to detect bad channels.\n\n        This function calls all the bad-channel detecting functions.\n\n        Parameters\n        ----------\n        ransac : bool, optional\n            Whether RANSAC should be used for bad channel detection, in addition\n            to the other methods. RANSAC can detect bad channels that other\n            methods are unable to catch, but also slows down noisy channel\n            detection considerably. Defaults to ``True``.\n        channel_wise : bool, optional\n            Whether RANSAC should predict signals for chunks of channels over the\n            entire signal length (\"channel-wise RANSAC\", see `max_chunk_size`\n            parameter). If ``False``, RANSAC will instead predict signals for all\n            channels at once but over a number of smaller time windows instead of\n            over the entire signal length (\"window-wise RANSAC\"). Channel-wise\n            RANSAC generally has higher RAM demands than window-wise RANSAC\n            (especially if `max_chunk_size` is ``None``), but can be faster on\n            systems with lots of RAM to spare. Has no effect if not using RANSAC.\n            Defaults to ``False``.\n        max_chunk_size : {int, None}, optional\n            The maximum number of channels to predict at once during\n            channel-wise RANSAC. If ``None``, RANSAC will use the largest chunk\n            size that will fit into the available RAM, which may slow down\n            other programs on the host system. If using window-wise RANSAC\n            (the default) or not using RANSAC at all, this parameter has no\n            effect. Defaults to ``None``.\n\n        \"\"\"\n    self.find_bad_by_deviation()\n    self.find_bad_by_hfnoise()\n    self.find_bad_by_correlation()\n    self.find_bad_by_SNR()\n    if ransac:\n        self.find_bad_by_ransac(channel_wise=channel_wise, max_chunk_size=max_chunk_size)"
        }
      ]
    }
  },
  {
    "query_id": "pyprep_ransac.py_find_bad_by_ransac_doc",
    "prompt": "How can I use RANSAC to detect bad EEG channels that aren't predicted well by others?",
    "data": {
      "docs": [
        {
          "text": "def find_bad_by_ransac(data, sample_rate, complete_chn_labs, chn_pos, exclude, n_samples=50, sample_prop=0.25, corr_thresh=0.75, frac_bad=0.4, corr_window_secs=5.0, channel_wise=False, max_chunk_size=None, random_state=None, matlab_strict=False):\n    \"\"\"Detect channels that are not predicted well by other channels.\n\n    Here, a RANSAC approach (see [1]_, and a short discussion in [2]_) is\n    adopted to predict a \"clean EEG\" dataset. After identifying clean EEG\n    channels through the other methods, the clean EEG dataset is\n    constructed by repeatedly sampling a small subset of clean EEG channels\n    and interpolation the complete data. The median of all those\n    repetitions forms the clean EEG dataset. In a second step, the original\n    and the RANSAC-predicted data are correlated and channels, which do not\n    correlate well with themselves across the two datasets are considered\n    `bad_by_ransac`.\n\n    Parameters\n    ----------\n    data : np.ndarray\n        A 2-D array of detrended EEG data, with bad-by-flat and bad-by-NaN\n        channels removed.\n    sample_rate : float\n        The sample rate (in Hz) of the EEG data.\n    complete_chn_labs : array_like\n        Labels for all channels in `data`, in the same order as they appear\n        in `data`.\n    chn_pos : np.ndarray\n        3-D electrode coordinates for all channels in `data`, in the same order\n        as they appear in `data`.\n    exclude : list\n        Labels of channels to exclude as signal predictors during RANSAC\n        (i.e., channels already flagged as bad by metrics other than HF noise).\n    n_samples : int, optional\n        Number of random channel samples to use for RANSAC. Defaults to ``50``.\n    sample_prop : float, optional\n        Proportion of total channels to use for signal prediction per RANSAC\n        sample. This needs to be in the range [0, 1], where 0 would mean no\n        channels would be used and 1 would mean all channels would be used\n        (neither of which would be useful values). Defaults to ``0.25`` (e.g.,\n        16 channels per sample for a 64-channel dataset).\n    corr_thresh : float, optional\n        The minimum predicted vs. actual signal correlation for a channel to\n        be considered good within a given RANSAC window. Defaults to ``0.75``.\n    frac_bad : float, optional\n        The minimum fraction of bad (i.e., below-threshold) RANSAC windows for a\n        channel to be considered bad-by-RANSAC. Defaults to ``0.4``.\n    corr_window_secs : float, optional\n        The duration (in seconds) of each RANSAC correlation window. Defaults to\n        5 seconds.\n    channel_wise : bool, optional\n        Whether RANSAC should predict signals for chunks of channels over the\n        entire signal length (\"channel-wise RANSAC\", see `max_chunk_size`\n        parameter). If ``False``, RANSAC will instead predict signals for all\n        channels at once but over a number of smaller time windows instead of\n        over the entire signal length (\"window-wise RANSAC\"). Channel-wise\n        RANSAC generally has higher RAM demands than window-wise RANSAC\n        (especially if `max_chunk_size` is ``None``), but can be faster on\n        systems with lots of RAM to spare. Defaults to ``False``.\n    max_chunk_size : {int, None}, optional\n        The maximum number of channels to predict at once during channel-wise\n        RANSAC. If ``None``, RANSAC will use the largest chunk size that will\n        fit into the available RAM, which may slow down other programs on the\n        host system. If using window-wise RANSAC (the default), this parameter\n        has no effect. Defaults to ``None``.\n    random_state : {int, None, np.random.RandomState}, optional\n        The random seed with which to generate random samples of channels during\n        RANSAC. If random_state is an int, it will be used as a seed for RandomState.\n        If ``None``, the seed will be obtained from the operating system\n        (see RandomState for details). Defaults to ``None``.\n    matlab_strict : bool, optional\n        Whether or not RANSAC should strictly follow MATLAB PREP's internal\n        math, ignoring any improvements made in PyPREP over the original code\n        (see :ref:`matlab-diffs` for more details). Defaults to ``False``.\n\n    Returns\n    -------\n    bad_by_ransac : list\n        List containing the labels of all channels flagged as bad by RANSAC.\n    channel_correlations : np.ndarray\n        Array of shape (windows, channels) containing the correlations of\n        the channels with their predicted RANSAC values for each window.\n\n    References\n    ----------\n    .. [1] Fischler, M.A., Bolles, R.C. (1981). Random sample consensus: A\n        Paradigm for Model Fitting with Applications to Image Analysis and\n        Automated Cartography. Communications of the ACM, 24, 381-395\n    .. [2] Jas, M., Engemann, D.A., Bekhti, Y., Raimondo, F., Gramfort, A.\n        (2017). Autoreject: Automated Artifact Rejection for MEG and EEG\n        Data. NeuroImage, 159, 417-429\n\n    \"\"\"\n    if np.isnan(chn_pos).any():\n        raise ValueError('Found NaN in channel positions. Did you supply a montage for the raw data?')\n    if not isinstance(n_samples, int):\n        raise TypeError(f\"Argument 'n_samples' must be an int (got {type(n_samples).__name__})\")\n    complete_chn_labs = np.asarray(complete_chn_labs)\n    good_idx = np.array([idx for (idx, ch) in enumerate(complete_chn_labs) if ch not in exclude])\n    n_chans_good = good_idx.shape[0]\n    chn_pos_good = chn_pos[good_idx, :]\n    n_chans = data.shape[0]\n    n_pred_chns = int(np.around(sample_prop * n_chans))\n    if n_pred_chns <= 3:\n        sample_pct = int(sample_prop * 100)\n        raise OSError(f'Too few channels in the original data to reliably perform RANSAC(minimum {int(np.floor(4.0 / sample_prop))} for a sample size of {sample_pct}%).')\n    elif n_chans_good < n_pred_chns + 1:\n        raise OSError(f'Too many noisy channels in the data to reliably perform RANSAC (only {n_chans_good} good channels remaining, need at least {n_pred_chns + 1}).')\n    if channel_wise:\n        _verify_free_ram(data, n_samples, 1)\n    else:\n        window_size = int(sample_rate * corr_window_secs)\n        _verify_free_ram(data[:, :window_size], n_samples, n_chans_good)\n    random_ch_picks = []\n    good_chans = np.arange(chn_pos_good.shape[0])\n    rng = check_random_state(random_state)\n    for i in range(n_samples):\n        picks = _get_random_subset(good_chans, n_pred_chns, rng)\n        random_ch_picks.append(picks)\n    interp_mats = _make_interpolation_matrices(random_ch_picks, chn_pos_good)\n    correlation_frames = corr_window_secs * sample_rate\n    signal_frames = data.shape[1]\n    correlation_offsets = np.arange(0, signal_frames - correlation_frames, correlation_frames)\n    win_size = int(correlation_frames)\n    win_count = correlation_offsets.shape[0]\n    n_chans_complete = len(complete_chn_labs)\n    channel_correlations = np.ones((win_count, n_chans_complete))\n    logger.info('Executing RANSAC\\nThis may take a while, so be patient...')\n    if not channel_wise:\n        channel_correlations[:, good_idx] = _ransac_by_window(data[good_idx, :], interp_mats, win_size, win_count, matlab_strict)\n    chunk_sizes = []\n    chunk_count = 0\n    for i in range(1, n_chans_good + 1):\n        n_chunks = int(np.ceil(n_chans_good / i))\n        if n_chunks != chunk_count:\n            chunk_count = n_chunks\n            if not max_chunk_size or i <= max_chunk_size:\n                chunk_sizes.append(i)\n    chunk_size = chunk_sizes.pop()\n    mem_error = True\n    job = list(range(n_chans_good))\n    while mem_error and channel_wise:\n        try:\n            channel_chunks = _split_list(job, chunk_size)\n            total_chunks = len(channel_chunks)\n            current = 1\n            for chunk in channel_chunks:\n                interp_mats_for_chunk = [mat[chunk, :] for mat in interp_mats]\n                channel_correlations[:, good_idx[chunk]] = _ransac_by_channel(data[good_idx, :], interp_mats_for_chunk, win_size, win_count, chunk, random_ch_picks, matlab_strict)\n                if chunk == channel_chunks[0]:\n                    logger.info('Finding optimal chunk size : %s', chunk_size)\n                    logger.info('Total # of chunks: %s', total_chunks)\n                    logger.info('Current chunk:')\n                logger.info(current)\n                current = current + 1\n            mem_error = False\n            del current\n        except MemoryError:\n            if len(chunk_sizes):\n                chunk_size = chunk_sizes.pop()\n            else:\n                raise MemoryError('Not even doing 1 channel at a time the data fits in ram...You could downsample the data or reduce the number of requested samples.')\n    thresholded_correlations = channel_correlations < corr_thresh\n    frac_bad_corr_windows = np.mean(thresholded_correlations, axis=0)\n    bad_ransac_channels_idx = np.argwhere(frac_bad_corr_windows > frac_bad)\n    bad_ransac_channels_name = complete_chn_labs[bad_ransac_channels_idx.astype(int)]\n    bad_by_ransac = [i[0] for i in bad_ransac_channels_name]\n    logger.info('\\nRANSAC done!')\n    return (bad_by_ransac, channel_correlations)"
        },
        {
          "text": "def find_bad_by_ransac(self, n_samples=50, sample_prop=0.25, corr_thresh=0.75, frac_bad=0.4, corr_window_secs=5.0, channel_wise=False, max_chunk_size=None):\n    \"\"\"Detect channels that are predicted poorly by other channels.\n\n        This method uses a random sample consensus approach (RANSAC, see [1]_,\n        and a short discussion in [2]_) to try and predict what the signal should\n        be for each channel based on the signals and spatial locations of other\n        currently-good channels. RANSAC correlations are calculated by splitting\n        the recording into non-overlapping windows of time (default: 5 seconds)\n        and correlating each channel's RANSAC-predicted signal with its actual\n        signal within each window.\n\n        A RANSAC window is considered \"bad\" for a channel if its predicted signal\n        vs. actual signal correlation falls below the given correlation threshold\n        (default: ``0.75``). A channel is considered \"bad-by-RANSAC\" if its fraction\n        of bad RANSAC windows is above the given threshold (default: ``0.4``).\n\n        Due to its random sampling component, the channels identified as\n        \"bad-by-RANSAC\" may vary slightly between calls of this method.\n        Additionally, bad channels may vary between different montages given that\n        RANSAC's signal predictions are based on the spatial coordinates of each\n        electrode.\n\n        This method is a wrapper for the :func:`~ransac.find_bad_by_ransac`\n        function.\n\n        .. warning:: For optimal performance, RANSAC requires that channels bad by\n                     deviation, correlation, and/or dropout have already been\n                     flagged. Otherwise RANSAC will attempt to use those channels\n                     when making signal predictions, decreasing accuracy and thus\n                     increasing the likelihood of false positives.\n\n        Parameters\n        ----------\n        n_samples : int, optional\n            Number of random channel samples to use for RANSAC. Defaults\n            to ``50``.\n        sample_prop : float, optional\n            Proportion of total channels to use for signal prediction per RANSAC\n            sample. This needs to be in the range [0, 1], where 0 would mean no\n            channels would be used and 1 would mean all channels would be used\n            (neither of which would be useful values). Defaults to ``0.25``\n            (e.g., 16 channels per sample for a 64-channel dataset).\n        corr_thresh : float, optional\n            The minimum predicted vs. actual signal correlation for a channel to\n            be considered good within a given RANSAC window. Defaults\n            to ``0.75``.\n        frac_bad : float, optional\n            The minimum fraction of bad (i.e., below-threshold) RANSAC windows\n            for a channel to be considered bad-by-RANSAC. Defaults to ``0.4``.\n        corr_window_secs : float, optional\n            The duration (in seconds) of each RANSAC correlation window. Defaults\n            to 5 seconds.\n        channel_wise : bool, optional\n            Whether RANSAC should predict signals for chunks of channels over the\n            entire signal length (\"channel-wise RANSAC\", see `max_chunk_size`\n            parameter). If ``False``, RANSAC will instead predict signals for all\n            channels at once but over a number of smaller time windows instead of\n            over the entire signal length (\"window-wise RANSAC\"). Channel-wise\n            RANSAC generally has higher RAM demands than window-wise RANSAC\n            (especially if `max_chunk_size` is ``None``), but can be faster on\n            systems with lots of RAM to spare. Defaults to ``False``.\n        max_chunk_size : {int, None}, optional\n            The maximum number of channels to predict at once during\n            channel-wise RANSAC. If ``None``, RANSAC will use the largest chunk\n            size that will fit into the available RAM, which may slow down\n            other programs on the host system. If using window-wise RANSAC\n            (the default), this parameter has no effect. Defaults to ``None``.\n\n        References\n        ----------\n        .. [1] Fischler, M.A., Bolles, R.C. (1981). Random sample consensus: A\n            Paradigm for Model Fitting with Applications to Image Analysis and\n            Automated Cartography. Communications of the ACM, 24, 381-395\n        .. [2] Jas, M., Engemann, D.A., Bekhti, Y., Raimondo, F., Gramfort, A.\n            (2017). Autoreject: Automated Artifact Rejection for MEG and EEG\n            Data. NeuroImage, 159, 417-429\n\n        \"\"\"\n    if self.EEGFiltered is None:\n        self.EEGFiltered = self._get_filtered_data()\n    exclude_from_ransac = self.bad_by_correlation + self.bad_by_deviation + self.bad_by_dropout\n    if self.matlab_strict:\n        random_state = self.random_state.get_state()\n        rng = np.random.RandomState()\n        rng.set_state(random_state)\n    else:\n        rng = self.random_state\n    (self.bad_by_ransac, ch_correlations_usable) = find_bad_by_ransac(self.EEGFiltered, self.sample_rate, self.ch_names_new, self.raw_mne._get_channel_positions()[self.usable_idx, :], exclude_from_ransac, n_samples, sample_prop, corr_thresh, frac_bad, corr_window_secs, channel_wise, max_chunk_size, rng, self.matlab_strict)\n    n_ransac_windows = ch_correlations_usable.shape[0]\n    ch_correlations = np.ones((n_ransac_windows, self.n_chans_original))\n    ch_correlations[:, self.usable_idx] = ch_correlations_usable\n    self._extra_info['bad_by_ransac'] = {'ransac_correlations': ch_correlations, 'bad_window_fractions': np.mean(ch_correlations < corr_thresh, axis=0)}"
        },
        {
          "text": "def _ransac_by_channel(data, interpolation_mats, win_size, win_count, chans_to_predict, random_ch_picks, matlab_strict):\n    \"\"\"Calculate correlations of channels with their RANSAC-predicted values.\n\n    This function calculates RANSAC correlations on one (or more) full channels\n    at once, requiring RAM equivalent to [channels per chunk * sample rate *\n    length of recording in seconds] to run. Generally, this method will use\n    more RAM than :func:`_ransac_by_window`, but may be faster for systems with\n    large amounts of RAM.\n\n    Parameters\n    ----------\n    data : np.ndarray\n        A 2-D array containing the EEG signals from all currently-good channels.\n    interpolation_mats : list of np.ndarray\n        A set of channel interpolation matrices, one for each RANSAC sample of\n        channels.\n    win_size : int\n        Number of frames/samples of EEG data in each RANSAC correlation window.\n    win_count: int\n        Number of RANSAC correlation windows.\n    chans_to_predict : list of int\n        Indices of the channels to predict (as they appear in `data`) within the\n        current chunk.\n    random_ch_picks : list of list of int\n        A list containing multiple random subsets of currently-good channels.\n    matlab_strict : bool\n        Whether or not RANSAC should strictly follow MATLAB PREP's internal\n        math, ignoring any improvements made in PyPREP over the original code.\n\n    Returns\n    -------\n    correlations : np.ndarray\n        Correlations of the given channels to their predicted values within each\n        RANSAC window.\n\n    \"\"\"\n    chunk_size = len(chans_to_predict)\n    correlations = np.ones((win_count, chunk_size))\n    predicted_chans = _predict_median_signals_channelwise(data=data, interpolation_mats=interpolation_mats, random_ch_picks=random_ch_picks, chunk_size=len(chans_to_predict), matlab_strict=matlab_strict)\n    data_window = data[chans_to_predict, :win_size * win_count]\n    data_window = data_window.reshape(chunk_size, win_count, win_size)\n    data_window = data_window.swapaxes(1, 0)\n    pred_window = predicted_chans[:chunk_size, :win_size * win_count]\n    pred_window = pred_window.reshape(chunk_size, win_count, win_size)\n    pred_window = pred_window.swapaxes(1, 0)\n    for k in range(win_count):\n        data_portion = data_window[k, :, :]\n        pred_portion = pred_window[k, :, :]\n        R = _correlate_arrays(data_portion, pred_portion, matlab_strict)\n        correlations[k, :] = R\n    return correlations"
        },
        {
          "text": "def find_all_bads(self, ransac=True, channel_wise=False, max_chunk_size=None):\n    \"\"\"Call all the functions to detect bad channels.\n\n        This function calls all the bad-channel detecting functions.\n\n        Parameters\n        ----------\n        ransac : bool, optional\n            Whether RANSAC should be used for bad channel detection, in addition\n            to the other methods. RANSAC can detect bad channels that other\n            methods are unable to catch, but also slows down noisy channel\n            detection considerably. Defaults to ``True``.\n        channel_wise : bool, optional\n            Whether RANSAC should predict signals for chunks of channels over the\n            entire signal length (\"channel-wise RANSAC\", see `max_chunk_size`\n            parameter). If ``False``, RANSAC will instead predict signals for all\n            channels at once but over a number of smaller time windows instead of\n            over the entire signal length (\"window-wise RANSAC\"). Channel-wise\n            RANSAC generally has higher RAM demands than window-wise RANSAC\n            (especially if `max_chunk_size` is ``None``), but can be faster on\n            systems with lots of RAM to spare. Has no effect if not using RANSAC.\n            Defaults to ``False``.\n        max_chunk_size : {int, None}, optional\n            The maximum number of channels to predict at once during\n            channel-wise RANSAC. If ``None``, RANSAC will use the largest chunk\n            size that will fit into the available RAM, which may slow down\n            other programs on the host system. If using window-wise RANSAC\n            (the default) or not using RANSAC at all, this parameter has no\n            effect. Defaults to ``None``.\n\n        \"\"\"\n    self.find_bad_by_deviation()\n    self.find_bad_by_hfnoise()\n    self.find_bad_by_correlation()\n    self.find_bad_by_SNR()\n    if ransac:\n        self.find_bad_by_ransac(channel_wise=channel_wise, max_chunk_size=max_chunk_size)"
        },
        {
          "text": "def _ransac_by_window(data, interpolation_mats, win_size, win_count, matlab_strict):\n    \"\"\"Calculate correlations of channels with their RANSAC-predicted values.\n\n    This function calculates RANSAC correlations for each RANSAC window\n    individually, requiring RAM equivalent to [channels * sample rate * seconds\n    per RANSAC window] to run. Generally, this method will use less RAM than\n    :func:`_ransac_by_channel`, with the exception of short recordings with high\n    electrode counts.\n\n    Parameters\n    ----------\n    data : np.ndarray\n        A 2-D array containing the EEG signals from all currently-good channels.\n    interpolation_mats : list of np.ndarray\n        A list of interpolation matrices, one for each RANSAC sample of channels.\n    win_size : int\n        Number of frames/samples of EEG data in each RANSAC correlation window.\n    win_count: int\n        Number of RANSAC correlation windows.\n    matlab_strict : bool\n        Whether or not RANSAC should strictly follow MATLAB PREP's internal\n        math, ignoring any improvements made in PyPREP over the original code.\n\n    Returns\n    -------\n    correlations : np.ndarray\n        Correlations of the given channels to their predicted values within each\n        RANSAC window.\n\n    \"\"\"\n    ch_count = data.shape[0]\n    correlations = np.ones((win_count, ch_count))\n    pb = ProgressBar(range(win_count))\n    for window in pb:\n        start = window * win_size\n        end = (window + 1) * win_size\n        actual = data[:, start:end]\n        predicted = _predict_median_signals(actual, interpolation_mats, matlab_strict)\n        correlations[window, :] = _correlate_arrays(actual, predicted, matlab_strict)\n    return correlations"
        }
      ]
    }
  },
  {
    "query_id": "pyprep_ransac.py__make_interpolation_matrices_doc",
    "prompt": "How do I create interpolation matrices from spatial coordinates of EEG channels for RANSAC?",
    "data": {
      "docs": [
        {
          "text": "def _make_interpolation_matrices(random_ch_picks, chn_pos_good):\n    \"\"\"Create an interpolation matrix for each RANSAC sample of channels.\n\n    This function takes the spatial coordinates of random subsets of currently-good\n    channels and uses them to predict what the signal will be at the spatial\n    coordinates of all other currently-good channels. The results of this process are\n    returned as matrices that can be multiplied with EEG data to generate predicted\n    signals.\n\n    Parameters\n    ----------\n    random_ch_picks : list of list of int\n        A list containing multiple random subsets of currently-good channels.\n    chn_pos_good : np.ndarray\n        3-D spatial coordinates of all currently-good channels.\n\n    Returns\n    -------\n    interpolation_mats : list of np.ndarray\n        A list of interpolation matrices, one for each random subset of channels.\n        Each matrix has the shape `[num_good_channels, num_good_channels]`, with the\n        number of good channels being inferred from the size of `ch_pos_good`.\n\n    Notes\n    -----\n    This function currently makes use of a private MNE function,\n    ``mne.channels.interpolation._make_interpolation_matrix``, to generate matrices.\n\n    \"\"\"\n    n_chans_good = chn_pos_good.shape[0]\n    interpolation_mats = []\n    for sample in random_ch_picks:\n        mat = np.zeros((n_chans_good, n_chans_good))\n        subset_pos = chn_pos_good[sample, :]\n        mat[:, sample] = _make_interpolation_matrix(subset_pos, chn_pos_good)\n        interpolation_mats.append(mat)\n    return interpolation_mats"
        },
        {
          "text": "def _ransac_by_channel(data, interpolation_mats, win_size, win_count, chans_to_predict, random_ch_picks, matlab_strict):\n    \"\"\"Calculate correlations of channels with their RANSAC-predicted values.\n\n    This function calculates RANSAC correlations on one (or more) full channels\n    at once, requiring RAM equivalent to [channels per chunk * sample rate *\n    length of recording in seconds] to run. Generally, this method will use\n    more RAM than :func:`_ransac_by_window`, but may be faster for systems with\n    large amounts of RAM.\n\n    Parameters\n    ----------\n    data : np.ndarray\n        A 2-D array containing the EEG signals from all currently-good channels.\n    interpolation_mats : list of np.ndarray\n        A set of channel interpolation matrices, one for each RANSAC sample of\n        channels.\n    win_size : int\n        Number of frames/samples of EEG data in each RANSAC correlation window.\n    win_count: int\n        Number of RANSAC correlation windows.\n    chans_to_predict : list of int\n        Indices of the channels to predict (as they appear in `data`) within the\n        current chunk.\n    random_ch_picks : list of list of int\n        A list containing multiple random subsets of currently-good channels.\n    matlab_strict : bool\n        Whether or not RANSAC should strictly follow MATLAB PREP's internal\n        math, ignoring any improvements made in PyPREP over the original code.\n\n    Returns\n    -------\n    correlations : np.ndarray\n        Correlations of the given channels to their predicted values within each\n        RANSAC window.\n\n    \"\"\"\n    chunk_size = len(chans_to_predict)\n    correlations = np.ones((win_count, chunk_size))\n    predicted_chans = _predict_median_signals_channelwise(data=data, interpolation_mats=interpolation_mats, random_ch_picks=random_ch_picks, chunk_size=len(chans_to_predict), matlab_strict=matlab_strict)\n    data_window = data[chans_to_predict, :win_size * win_count]\n    data_window = data_window.reshape(chunk_size, win_count, win_size)\n    data_window = data_window.swapaxes(1, 0)\n    pred_window = predicted_chans[:chunk_size, :win_size * win_count]\n    pred_window = pred_window.reshape(chunk_size, win_count, win_size)\n    pred_window = pred_window.swapaxes(1, 0)\n    for k in range(win_count):\n        data_portion = data_window[k, :, :]\n        pred_portion = pred_window[k, :, :]\n        R = _correlate_arrays(data_portion, pred_portion, matlab_strict)\n        correlations[k, :] = R\n    return correlations"
        },
        {
          "text": "def _ransac_by_window(data, interpolation_mats, win_size, win_count, matlab_strict):\n    \"\"\"Calculate correlations of channels with their RANSAC-predicted values.\n\n    This function calculates RANSAC correlations for each RANSAC window\n    individually, requiring RAM equivalent to [channels * sample rate * seconds\n    per RANSAC window] to run. Generally, this method will use less RAM than\n    :func:`_ransac_by_channel`, with the exception of short recordings with high\n    electrode counts.\n\n    Parameters\n    ----------\n    data : np.ndarray\n        A 2-D array containing the EEG signals from all currently-good channels.\n    interpolation_mats : list of np.ndarray\n        A list of interpolation matrices, one for each RANSAC sample of channels.\n    win_size : int\n        Number of frames/samples of EEG data in each RANSAC correlation window.\n    win_count: int\n        Number of RANSAC correlation windows.\n    matlab_strict : bool\n        Whether or not RANSAC should strictly follow MATLAB PREP's internal\n        math, ignoring any improvements made in PyPREP over the original code.\n\n    Returns\n    -------\n    correlations : np.ndarray\n        Correlations of the given channels to their predicted values within each\n        RANSAC window.\n\n    \"\"\"\n    ch_count = data.shape[0]\n    correlations = np.ones((win_count, ch_count))\n    pb = ProgressBar(range(win_count))\n    for window in pb:\n        start = window * win_size\n        end = (window + 1) * win_size\n        actual = data[:, start:end]\n        predicted = _predict_median_signals(actual, interpolation_mats, matlab_strict)\n        correlations[window, :] = _correlate_arrays(actual, predicted, matlab_strict)\n    return correlations"
        },
        {
          "text": "def _eeglab_interpolate(data, pos_from, pos_to):\n    \"\"\"Interpolate bad channels using EEGLAB's custom method.\n\n    Parameters\n    ----------\n    data : np.ndarray\n        A 2-D array containing signals from currently-good EEG channels with\n        which to interpolate signals for bad channels.\n    pos_from : np.ndarray of float, shape(n_good_sensors, 3)\n        The electrode positions to interpolate from.\n    pos_to : np.ndarray of float, shape(n_bad_sensors, 3)\n        The electrode positions to interpolate.\n\n    Returns\n    -------\n    interpolated : np.ndarray\n        The interpolated signals for all bad channels.\n\n    Notes\n    -----\n    Produces identical output to the private ``spheric_spline`` function in\n    EEGLAB's ``eeg_interp.m`` (with minor rounding errors).\n\n    \"\"\"\n    G_from = _eeglab_calc_g(pos_from, pos_from)\n    G_to_from = _eeglab_calc_g(pos_from, pos_to)\n    avg_ref = np.mean(data, axis=0)\n    data_tmp = data - avg_ref\n    pad_ones = np.ones((1, pos_from.shape[0]))\n    C_inv = linalg.pinv(np.vstack([G_from, pad_ones]))\n    interp_mat = np.matmul(G_to_from, C_inv[:, :-1])\n    interpolated = np.matmul(interp_mat, data_tmp) + avg_ref\n    return interpolated"
        },
        {
          "text": "def _predict_median_signals_channelwise(data, interpolation_mats, random_ch_picks, chunk_size, matlab_strict):\n    \"\"\"Calculate the median RANSAC-predicted signal for a given chunk of channels.\n\n    Parameters\n    ----------\n    data : np.ndarray\n        A 2-D array containing the EEG signals from all currently-good channels.\n    interpolation_mats : list of np.ndarray\n        A set of channel interpolation matrices, one for each RANSAC sample of\n        channels.\n    random_ch_picks : list of list of int\n        A list containing multiple random subsets of currently-good channels.\n    chunk_size : int\n        The number of channels to predict in the current chunk.\n    matlab_strict : bool\n        Whether or not RANSAC should strictly follow MATLAB PREP's internal\n        math, ignoring any improvements made in PyPREP over the original code.\n\n    Returns\n    -------\n    predicted_chans : np.ndarray\n        The median RANSAC-predicted EEG signals for the given chunk of channels.\n\n    \"\"\"\n    ransac_samples = len(interpolation_mats)\n    n_timepts = data.shape[1]\n    _verify_free_ram(data, ransac_samples, chunk_size)\n    eeg_predictions = np.zeros((chunk_size, n_timepts, ransac_samples))\n    for sample in range(ransac_samples):\n        reconstr_idx = random_ch_picks[sample]\n        interp_mat = interpolation_mats[sample][:, reconstr_idx]\n        eeg_predictions[..., sample] = np.matmul(interp_mat, data[reconstr_idx, :])\n    if matlab_strict:\n        median_idx = int(_mat_round(ransac_samples / 2.0) - 1)\n        eeg_predictions.sort(axis=-1)\n        return eeg_predictions[:, :, median_idx]\n    else:\n        return np.median(eeg_predictions, axis=-1, overwrite_input=True)"
        }
      ]
    }
  },
  {
    "query_id": "pyprep_ransac.py__ransac_by_window_doc",
    "prompt": "How can I compute window-wise RANSAC correlations between EEG channels and their predictions?",
    "data": {
      "docs": [
        {
          "text": "def _ransac_by_channel(data, interpolation_mats, win_size, win_count, chans_to_predict, random_ch_picks, matlab_strict):\n    \"\"\"Calculate correlations of channels with their RANSAC-predicted values.\n\n    This function calculates RANSAC correlations on one (or more) full channels\n    at once, requiring RAM equivalent to [channels per chunk * sample rate *\n    length of recording in seconds] to run. Generally, this method will use\n    more RAM than :func:`_ransac_by_window`, but may be faster for systems with\n    large amounts of RAM.\n\n    Parameters\n    ----------\n    data : np.ndarray\n        A 2-D array containing the EEG signals from all currently-good channels.\n    interpolation_mats : list of np.ndarray\n        A set of channel interpolation matrices, one for each RANSAC sample of\n        channels.\n    win_size : int\n        Number of frames/samples of EEG data in each RANSAC correlation window.\n    win_count: int\n        Number of RANSAC correlation windows.\n    chans_to_predict : list of int\n        Indices of the channels to predict (as they appear in `data`) within the\n        current chunk.\n    random_ch_picks : list of list of int\n        A list containing multiple random subsets of currently-good channels.\n    matlab_strict : bool\n        Whether or not RANSAC should strictly follow MATLAB PREP's internal\n        math, ignoring any improvements made in PyPREP over the original code.\n\n    Returns\n    -------\n    correlations : np.ndarray\n        Correlations of the given channels to their predicted values within each\n        RANSAC window.\n\n    \"\"\"\n    chunk_size = len(chans_to_predict)\n    correlations = np.ones((win_count, chunk_size))\n    predicted_chans = _predict_median_signals_channelwise(data=data, interpolation_mats=interpolation_mats, random_ch_picks=random_ch_picks, chunk_size=len(chans_to_predict), matlab_strict=matlab_strict)\n    data_window = data[chans_to_predict, :win_size * win_count]\n    data_window = data_window.reshape(chunk_size, win_count, win_size)\n    data_window = data_window.swapaxes(1, 0)\n    pred_window = predicted_chans[:chunk_size, :win_size * win_count]\n    pred_window = pred_window.reshape(chunk_size, win_count, win_size)\n    pred_window = pred_window.swapaxes(1, 0)\n    for k in range(win_count):\n        data_portion = data_window[k, :, :]\n        pred_portion = pred_window[k, :, :]\n        R = _correlate_arrays(data_portion, pred_portion, matlab_strict)\n        correlations[k, :] = R\n    return correlations"
        },
        {
          "text": "def _ransac_by_window(data, interpolation_mats, win_size, win_count, matlab_strict):\n    \"\"\"Calculate correlations of channels with their RANSAC-predicted values.\n\n    This function calculates RANSAC correlations for each RANSAC window\n    individually, requiring RAM equivalent to [channels * sample rate * seconds\n    per RANSAC window] to run. Generally, this method will use less RAM than\n    :func:`_ransac_by_channel`, with the exception of short recordings with high\n    electrode counts.\n\n    Parameters\n    ----------\n    data : np.ndarray\n        A 2-D array containing the EEG signals from all currently-good channels.\n    interpolation_mats : list of np.ndarray\n        A list of interpolation matrices, one for each RANSAC sample of channels.\n    win_size : int\n        Number of frames/samples of EEG data in each RANSAC correlation window.\n    win_count: int\n        Number of RANSAC correlation windows.\n    matlab_strict : bool\n        Whether or not RANSAC should strictly follow MATLAB PREP's internal\n        math, ignoring any improvements made in PyPREP over the original code.\n\n    Returns\n    -------\n    correlations : np.ndarray\n        Correlations of the given channels to their predicted values within each\n        RANSAC window.\n\n    \"\"\"\n    ch_count = data.shape[0]\n    correlations = np.ones((win_count, ch_count))\n    pb = ProgressBar(range(win_count))\n    for window in pb:\n        start = window * win_size\n        end = (window + 1) * win_size\n        actual = data[:, start:end]\n        predicted = _predict_median_signals(actual, interpolation_mats, matlab_strict)\n        correlations[window, :] = _correlate_arrays(actual, predicted, matlab_strict)\n    return correlations"
        },
        {
          "text": "def find_bad_by_ransac(data, sample_rate, complete_chn_labs, chn_pos, exclude, n_samples=50, sample_prop=0.25, corr_thresh=0.75, frac_bad=0.4, corr_window_secs=5.0, channel_wise=False, max_chunk_size=None, random_state=None, matlab_strict=False):\n    \"\"\"Detect channels that are not predicted well by other channels.\n\n    Here, a RANSAC approach (see [1]_, and a short discussion in [2]_) is\n    adopted to predict a \"clean EEG\" dataset. After identifying clean EEG\n    channels through the other methods, the clean EEG dataset is\n    constructed by repeatedly sampling a small subset of clean EEG channels\n    and interpolation the complete data. The median of all those\n    repetitions forms the clean EEG dataset. In a second step, the original\n    and the RANSAC-predicted data are correlated and channels, which do not\n    correlate well with themselves across the two datasets are considered\n    `bad_by_ransac`.\n\n    Parameters\n    ----------\n    data : np.ndarray\n        A 2-D array of detrended EEG data, with bad-by-flat and bad-by-NaN\n        channels removed.\n    sample_rate : float\n        The sample rate (in Hz) of the EEG data.\n    complete_chn_labs : array_like\n        Labels for all channels in `data`, in the same order as they appear\n        in `data`.\n    chn_pos : np.ndarray\n        3-D electrode coordinates for all channels in `data`, in the same order\n        as they appear in `data`.\n    exclude : list\n        Labels of channels to exclude as signal predictors during RANSAC\n        (i.e., channels already flagged as bad by metrics other than HF noise).\n    n_samples : int, optional\n        Number of random channel samples to use for RANSAC. Defaults to ``50``.\n    sample_prop : float, optional\n        Proportion of total channels to use for signal prediction per RANSAC\n        sample. This needs to be in the range [0, 1], where 0 would mean no\n        channels would be used and 1 would mean all channels would be used\n        (neither of which would be useful values). Defaults to ``0.25`` (e.g.,\n        16 channels per sample for a 64-channel dataset).\n    corr_thresh : float, optional\n        The minimum predicted vs. actual signal correlation for a channel to\n        be considered good within a given RANSAC window. Defaults to ``0.75``.\n    frac_bad : float, optional\n        The minimum fraction of bad (i.e., below-threshold) RANSAC windows for a\n        channel to be considered bad-by-RANSAC. Defaults to ``0.4``.\n    corr_window_secs : float, optional\n        The duration (in seconds) of each RANSAC correlation window. Defaults to\n        5 seconds.\n    channel_wise : bool, optional\n        Whether RANSAC should predict signals for chunks of channels over the\n        entire signal length (\"channel-wise RANSAC\", see `max_chunk_size`\n        parameter). If ``False``, RANSAC will instead predict signals for all\n        channels at once but over a number of smaller time windows instead of\n        over the entire signal length (\"window-wise RANSAC\"). Channel-wise\n        RANSAC generally has higher RAM demands than window-wise RANSAC\n        (especially if `max_chunk_size` is ``None``), but can be faster on\n        systems with lots of RAM to spare. Defaults to ``False``.\n    max_chunk_size : {int, None}, optional\n        The maximum number of channels to predict at once during channel-wise\n        RANSAC. If ``None``, RANSAC will use the largest chunk size that will\n        fit into the available RAM, which may slow down other programs on the\n        host system. If using window-wise RANSAC (the default), this parameter\n        has no effect. Defaults to ``None``.\n    random_state : {int, None, np.random.RandomState}, optional\n        The random seed with which to generate random samples of channels during\n        RANSAC. If random_state is an int, it will be used as a seed for RandomState.\n        If ``None``, the seed will be obtained from the operating system\n        (see RandomState for details). Defaults to ``None``.\n    matlab_strict : bool, optional\n        Whether or not RANSAC should strictly follow MATLAB PREP's internal\n        math, ignoring any improvements made in PyPREP over the original code\n        (see :ref:`matlab-diffs` for more details). Defaults to ``False``.\n\n    Returns\n    -------\n    bad_by_ransac : list\n        List containing the labels of all channels flagged as bad by RANSAC.\n    channel_correlations : np.ndarray\n        Array of shape (windows, channels) containing the correlations of\n        the channels with their predicted RANSAC values for each window.\n\n    References\n    ----------\n    .. [1] Fischler, M.A., Bolles, R.C. (1981). Random sample consensus: A\n        Paradigm for Model Fitting with Applications to Image Analysis and\n        Automated Cartography. Communications of the ACM, 24, 381-395\n    .. [2] Jas, M., Engemann, D.A., Bekhti, Y., Raimondo, F., Gramfort, A.\n        (2017). Autoreject: Automated Artifact Rejection for MEG and EEG\n        Data. NeuroImage, 159, 417-429\n\n    \"\"\"\n    if np.isnan(chn_pos).any():\n        raise ValueError('Found NaN in channel positions. Did you supply a montage for the raw data?')\n    if not isinstance(n_samples, int):\n        raise TypeError(f\"Argument 'n_samples' must be an int (got {type(n_samples).__name__})\")\n    complete_chn_labs = np.asarray(complete_chn_labs)\n    good_idx = np.array([idx for (idx, ch) in enumerate(complete_chn_labs) if ch not in exclude])\n    n_chans_good = good_idx.shape[0]\n    chn_pos_good = chn_pos[good_idx, :]\n    n_chans = data.shape[0]\n    n_pred_chns = int(np.around(sample_prop * n_chans))\n    if n_pred_chns <= 3:\n        sample_pct = int(sample_prop * 100)\n        raise OSError(f'Too few channels in the original data to reliably perform RANSAC(minimum {int(np.floor(4.0 / sample_prop))} for a sample size of {sample_pct}%).')\n    elif n_chans_good < n_pred_chns + 1:\n        raise OSError(f'Too many noisy channels in the data to reliably perform RANSAC (only {n_chans_good} good channels remaining, need at least {n_pred_chns + 1}).')\n    if channel_wise:\n        _verify_free_ram(data, n_samples, 1)\n    else:\n        window_size = int(sample_rate * corr_window_secs)\n        _verify_free_ram(data[:, :window_size], n_samples, n_chans_good)\n    random_ch_picks = []\n    good_chans = np.arange(chn_pos_good.shape[0])\n    rng = check_random_state(random_state)\n    for i in range(n_samples):\n        picks = _get_random_subset(good_chans, n_pred_chns, rng)\n        random_ch_picks.append(picks)\n    interp_mats = _make_interpolation_matrices(random_ch_picks, chn_pos_good)\n    correlation_frames = corr_window_secs * sample_rate\n    signal_frames = data.shape[1]\n    correlation_offsets = np.arange(0, signal_frames - correlation_frames, correlation_frames)\n    win_size = int(correlation_frames)\n    win_count = correlation_offsets.shape[0]\n    n_chans_complete = len(complete_chn_labs)\n    channel_correlations = np.ones((win_count, n_chans_complete))\n    logger.info('Executing RANSAC\\nThis may take a while, so be patient...')\n    if not channel_wise:\n        channel_correlations[:, good_idx] = _ransac_by_window(data[good_idx, :], interp_mats, win_size, win_count, matlab_strict)\n    chunk_sizes = []\n    chunk_count = 0\n    for i in range(1, n_chans_good + 1):\n        n_chunks = int(np.ceil(n_chans_good / i))\n        if n_chunks != chunk_count:\n            chunk_count = n_chunks\n            if not max_chunk_size or i <= max_chunk_size:\n                chunk_sizes.append(i)\n    chunk_size = chunk_sizes.pop()\n    mem_error = True\n    job = list(range(n_chans_good))\n    while mem_error and channel_wise:\n        try:\n            channel_chunks = _split_list(job, chunk_size)\n            total_chunks = len(channel_chunks)\n            current = 1\n            for chunk in channel_chunks:\n                interp_mats_for_chunk = [mat[chunk, :] for mat in interp_mats]\n                channel_correlations[:, good_idx[chunk]] = _ransac_by_channel(data[good_idx, :], interp_mats_for_chunk, win_size, win_count, chunk, random_ch_picks, matlab_strict)\n                if chunk == channel_chunks[0]:\n                    logger.info('Finding optimal chunk size : %s', chunk_size)\n                    logger.info('Total # of chunks: %s', total_chunks)\n                    logger.info('Current chunk:')\n                logger.info(current)\n                current = current + 1\n            mem_error = False\n            del current\n        except MemoryError:\n            if len(chunk_sizes):\n                chunk_size = chunk_sizes.pop()\n            else:\n                raise MemoryError('Not even doing 1 channel at a time the data fits in ram...You could downsample the data or reduce the number of requested samples.')\n    thresholded_correlations = channel_correlations < corr_thresh\n    frac_bad_corr_windows = np.mean(thresholded_correlations, axis=0)\n    bad_ransac_channels_idx = np.argwhere(frac_bad_corr_windows > frac_bad)\n    bad_ransac_channels_name = complete_chn_labs[bad_ransac_channels_idx.astype(int)]\n    bad_by_ransac = [i[0] for i in bad_ransac_channels_name]\n    logger.info('\\nRANSAC done!')\n    return (bad_by_ransac, channel_correlations)"
        },
        {
          "text": "def find_bad_by_ransac(self, n_samples=50, sample_prop=0.25, corr_thresh=0.75, frac_bad=0.4, corr_window_secs=5.0, channel_wise=False, max_chunk_size=None):\n    \"\"\"Detect channels that are predicted poorly by other channels.\n\n        This method uses a random sample consensus approach (RANSAC, see [1]_,\n        and a short discussion in [2]_) to try and predict what the signal should\n        be for each channel based on the signals and spatial locations of other\n        currently-good channels. RANSAC correlations are calculated by splitting\n        the recording into non-overlapping windows of time (default: 5 seconds)\n        and correlating each channel's RANSAC-predicted signal with its actual\n        signal within each window.\n\n        A RANSAC window is considered \"bad\" for a channel if its predicted signal\n        vs. actual signal correlation falls below the given correlation threshold\n        (default: ``0.75``). A channel is considered \"bad-by-RANSAC\" if its fraction\n        of bad RANSAC windows is above the given threshold (default: ``0.4``).\n\n        Due to its random sampling component, the channels identified as\n        \"bad-by-RANSAC\" may vary slightly between calls of this method.\n        Additionally, bad channels may vary between different montages given that\n        RANSAC's signal predictions are based on the spatial coordinates of each\n        electrode.\n\n        This method is a wrapper for the :func:`~ransac.find_bad_by_ransac`\n        function.\n\n        .. warning:: For optimal performance, RANSAC requires that channels bad by\n                     deviation, correlation, and/or dropout have already been\n                     flagged. Otherwise RANSAC will attempt to use those channels\n                     when making signal predictions, decreasing accuracy and thus\n                     increasing the likelihood of false positives.\n\n        Parameters\n        ----------\n        n_samples : int, optional\n            Number of random channel samples to use for RANSAC. Defaults\n            to ``50``.\n        sample_prop : float, optional\n            Proportion of total channels to use for signal prediction per RANSAC\n            sample. This needs to be in the range [0, 1], where 0 would mean no\n            channels would be used and 1 would mean all channels would be used\n            (neither of which would be useful values). Defaults to ``0.25``\n            (e.g., 16 channels per sample for a 64-channel dataset).\n        corr_thresh : float, optional\n            The minimum predicted vs. actual signal correlation for a channel to\n            be considered good within a given RANSAC window. Defaults\n            to ``0.75``.\n        frac_bad : float, optional\n            The minimum fraction of bad (i.e., below-threshold) RANSAC windows\n            for a channel to be considered bad-by-RANSAC. Defaults to ``0.4``.\n        corr_window_secs : float, optional\n            The duration (in seconds) of each RANSAC correlation window. Defaults\n            to 5 seconds.\n        channel_wise : bool, optional\n            Whether RANSAC should predict signals for chunks of channels over the\n            entire signal length (\"channel-wise RANSAC\", see `max_chunk_size`\n            parameter). If ``False``, RANSAC will instead predict signals for all\n            channels at once but over a number of smaller time windows instead of\n            over the entire signal length (\"window-wise RANSAC\"). Channel-wise\n            RANSAC generally has higher RAM demands than window-wise RANSAC\n            (especially if `max_chunk_size` is ``None``), but can be faster on\n            systems with lots of RAM to spare. Defaults to ``False``.\n        max_chunk_size : {int, None}, optional\n            The maximum number of channels to predict at once during\n            channel-wise RANSAC. If ``None``, RANSAC will use the largest chunk\n            size that will fit into the available RAM, which may slow down\n            other programs on the host system. If using window-wise RANSAC\n            (the default), this parameter has no effect. Defaults to ``None``.\n\n        References\n        ----------\n        .. [1] Fischler, M.A., Bolles, R.C. (1981). Random sample consensus: A\n            Paradigm for Model Fitting with Applications to Image Analysis and\n            Automated Cartography. Communications of the ACM, 24, 381-395\n        .. [2] Jas, M., Engemann, D.A., Bekhti, Y., Raimondo, F., Gramfort, A.\n            (2017). Autoreject: Automated Artifact Rejection for MEG and EEG\n            Data. NeuroImage, 159, 417-429\n\n        \"\"\"\n    if self.EEGFiltered is None:\n        self.EEGFiltered = self._get_filtered_data()\n    exclude_from_ransac = self.bad_by_correlation + self.bad_by_deviation + self.bad_by_dropout\n    if self.matlab_strict:\n        random_state = self.random_state.get_state()\n        rng = np.random.RandomState()\n        rng.set_state(random_state)\n    else:\n        rng = self.random_state\n    (self.bad_by_ransac, ch_correlations_usable) = find_bad_by_ransac(self.EEGFiltered, self.sample_rate, self.ch_names_new, self.raw_mne._get_channel_positions()[self.usable_idx, :], exclude_from_ransac, n_samples, sample_prop, corr_thresh, frac_bad, corr_window_secs, channel_wise, max_chunk_size, rng, self.matlab_strict)\n    n_ransac_windows = ch_correlations_usable.shape[0]\n    ch_correlations = np.ones((n_ransac_windows, self.n_chans_original))\n    ch_correlations[:, self.usable_idx] = ch_correlations_usable\n    self._extra_info['bad_by_ransac'] = {'ransac_correlations': ch_correlations, 'bad_window_fractions': np.mean(ch_correlations < corr_thresh, axis=0)}"
        },
        {
          "text": "def _predict_median_signals_channelwise(data, interpolation_mats, random_ch_picks, chunk_size, matlab_strict):\n    \"\"\"Calculate the median RANSAC-predicted signal for a given chunk of channels.\n\n    Parameters\n    ----------\n    data : np.ndarray\n        A 2-D array containing the EEG signals from all currently-good channels.\n    interpolation_mats : list of np.ndarray\n        A set of channel interpolation matrices, one for each RANSAC sample of\n        channels.\n    random_ch_picks : list of list of int\n        A list containing multiple random subsets of currently-good channels.\n    chunk_size : int\n        The number of channels to predict in the current chunk.\n    matlab_strict : bool\n        Whether or not RANSAC should strictly follow MATLAB PREP's internal\n        math, ignoring any improvements made in PyPREP over the original code.\n\n    Returns\n    -------\n    predicted_chans : np.ndarray\n        The median RANSAC-predicted EEG signals for the given chunk of channels.\n\n    \"\"\"\n    ransac_samples = len(interpolation_mats)\n    n_timepts = data.shape[1]\n    _verify_free_ram(data, ransac_samples, chunk_size)\n    eeg_predictions = np.zeros((chunk_size, n_timepts, ransac_samples))\n    for sample in range(ransac_samples):\n        reconstr_idx = random_ch_picks[sample]\n        interp_mat = interpolation_mats[sample][:, reconstr_idx]\n        eeg_predictions[..., sample] = np.matmul(interp_mat, data[reconstr_idx, :])\n    if matlab_strict:\n        median_idx = int(_mat_round(ransac_samples / 2.0) - 1)\n        eeg_predictions.sort(axis=-1)\n        return eeg_predictions[:, :, median_idx]\n    else:\n        return np.median(eeg_predictions, axis=-1, overwrite_input=True)"
        }
      ]
    }
  },
  {
    "query_id": "pyprep_ransac.py__predict_median_signals_doc",
    "prompt": "How do I compute the median RANSAC-predicted signal for a given EEG time window?",
    "data": {
      "docs": [
        {
          "text": "def _predict_median_signals(window, interpolation_mats, matlab_strict=False):\n    \"\"\"Calculate the median RANSAC-predicted signal for a given window of data.\n\n    Parameters\n    ----------\n    window : np.ndarray\n        A 2-D window of EEG data with the shape `[channels, samples]`.\n    interpolation_mats : list of np.ndarray\n        A set of channel interpolation matrices, one for each RANSAC sample of\n        channels.\n    matlab_strict : bool\n        Whether or not RANSAC should strictly follow MATLAB PREP's internal\n        math, ignoring any improvements made in PyPREP over the original code.\n\n    Returns\n    -------\n    predicted : np.ndarray\n        The median RANSAC-predicted EEG signal for the given window of data.\n\n    Notes\n    -----\n    In MATLAB PREP, the median signal is calculated by sorting the different\n    predictions for each EEG sample/channel from low to high and then taking the value\n    at the middle index (as calculated by ``int(n_ransac_samples / 2.0)``) for each.\n    Because this logic only returns the correct result for odd numbers of samples, the\n    current function will instead return the true median signal across predictions\n    unless strict MATLAB equivalence is requested.\n\n    \"\"\"\n    ransac_samples = len(interpolation_mats)\n    merged_mats = np.concatenate(interpolation_mats, axis=0)\n    predictions_per_sample = np.reshape(np.matmul(merged_mats, window), (ransac_samples, window.shape[0], window.shape[1]))\n    if matlab_strict:\n        median_idx = int(_mat_round(ransac_samples / 2.0) - 1)\n        predictions_per_sample.sort(axis=0)\n        return predictions_per_sample[median_idx, :, :]\n    else:\n        return np.median(predictions_per_sample, axis=0)"
        },
        {
          "text": "def _predict_median_signals_channelwise(data, interpolation_mats, random_ch_picks, chunk_size, matlab_strict):\n    \"\"\"Calculate the median RANSAC-predicted signal for a given chunk of channels.\n\n    Parameters\n    ----------\n    data : np.ndarray\n        A 2-D array containing the EEG signals from all currently-good channels.\n    interpolation_mats : list of np.ndarray\n        A set of channel interpolation matrices, one for each RANSAC sample of\n        channels.\n    random_ch_picks : list of list of int\n        A list containing multiple random subsets of currently-good channels.\n    chunk_size : int\n        The number of channels to predict in the current chunk.\n    matlab_strict : bool\n        Whether or not RANSAC should strictly follow MATLAB PREP's internal\n        math, ignoring any improvements made in PyPREP over the original code.\n\n    Returns\n    -------\n    predicted_chans : np.ndarray\n        The median RANSAC-predicted EEG signals for the given chunk of channels.\n\n    \"\"\"\n    ransac_samples = len(interpolation_mats)\n    n_timepts = data.shape[1]\n    _verify_free_ram(data, ransac_samples, chunk_size)\n    eeg_predictions = np.zeros((chunk_size, n_timepts, ransac_samples))\n    for sample in range(ransac_samples):\n        reconstr_idx = random_ch_picks[sample]\n        interp_mat = interpolation_mats[sample][:, reconstr_idx]\n        eeg_predictions[..., sample] = np.matmul(interp_mat, data[reconstr_idx, :])\n    if matlab_strict:\n        median_idx = int(_mat_round(ransac_samples / 2.0) - 1)\n        eeg_predictions.sort(axis=-1)\n        return eeg_predictions[:, :, median_idx]\n    else:\n        return np.median(eeg_predictions, axis=-1, overwrite_input=True)"
        },
        {
          "text": "def find_bad_by_ransac(data, sample_rate, complete_chn_labs, chn_pos, exclude, n_samples=50, sample_prop=0.25, corr_thresh=0.75, frac_bad=0.4, corr_window_secs=5.0, channel_wise=False, max_chunk_size=None, random_state=None, matlab_strict=False):\n    \"\"\"Detect channels that are not predicted well by other channels.\n\n    Here, a RANSAC approach (see [1]_, and a short discussion in [2]_) is\n    adopted to predict a \"clean EEG\" dataset. After identifying clean EEG\n    channels through the other methods, the clean EEG dataset is\n    constructed by repeatedly sampling a small subset of clean EEG channels\n    and interpolation the complete data. The median of all those\n    repetitions forms the clean EEG dataset. In a second step, the original\n    and the RANSAC-predicted data are correlated and channels, which do not\n    correlate well with themselves across the two datasets are considered\n    `bad_by_ransac`.\n\n    Parameters\n    ----------\n    data : np.ndarray\n        A 2-D array of detrended EEG data, with bad-by-flat and bad-by-NaN\n        channels removed.\n    sample_rate : float\n        The sample rate (in Hz) of the EEG data.\n    complete_chn_labs : array_like\n        Labels for all channels in `data`, in the same order as they appear\n        in `data`.\n    chn_pos : np.ndarray\n        3-D electrode coordinates for all channels in `data`, in the same order\n        as they appear in `data`.\n    exclude : list\n        Labels of channels to exclude as signal predictors during RANSAC\n        (i.e., channels already flagged as bad by metrics other than HF noise).\n    n_samples : int, optional\n        Number of random channel samples to use for RANSAC. Defaults to ``50``.\n    sample_prop : float, optional\n        Proportion of total channels to use for signal prediction per RANSAC\n        sample. This needs to be in the range [0, 1], where 0 would mean no\n        channels would be used and 1 would mean all channels would be used\n        (neither of which would be useful values). Defaults to ``0.25`` (e.g.,\n        16 channels per sample for a 64-channel dataset).\n    corr_thresh : float, optional\n        The minimum predicted vs. actual signal correlation for a channel to\n        be considered good within a given RANSAC window. Defaults to ``0.75``.\n    frac_bad : float, optional\n        The minimum fraction of bad (i.e., below-threshold) RANSAC windows for a\n        channel to be considered bad-by-RANSAC. Defaults to ``0.4``.\n    corr_window_secs : float, optional\n        The duration (in seconds) of each RANSAC correlation window. Defaults to\n        5 seconds.\n    channel_wise : bool, optional\n        Whether RANSAC should predict signals for chunks of channels over the\n        entire signal length (\"channel-wise RANSAC\", see `max_chunk_size`\n        parameter). If ``False``, RANSAC will instead predict signals for all\n        channels at once but over a number of smaller time windows instead of\n        over the entire signal length (\"window-wise RANSAC\"). Channel-wise\n        RANSAC generally has higher RAM demands than window-wise RANSAC\n        (especially if `max_chunk_size` is ``None``), but can be faster on\n        systems with lots of RAM to spare. Defaults to ``False``.\n    max_chunk_size : {int, None}, optional\n        The maximum number of channels to predict at once during channel-wise\n        RANSAC. If ``None``, RANSAC will use the largest chunk size that will\n        fit into the available RAM, which may slow down other programs on the\n        host system. If using window-wise RANSAC (the default), this parameter\n        has no effect. Defaults to ``None``.\n    random_state : {int, None, np.random.RandomState}, optional\n        The random seed with which to generate random samples of channels during\n        RANSAC. If random_state is an int, it will be used as a seed for RandomState.\n        If ``None``, the seed will be obtained from the operating system\n        (see RandomState for details). Defaults to ``None``.\n    matlab_strict : bool, optional\n        Whether or not RANSAC should strictly follow MATLAB PREP's internal\n        math, ignoring any improvements made in PyPREP over the original code\n        (see :ref:`matlab-diffs` for more details). Defaults to ``False``.\n\n    Returns\n    -------\n    bad_by_ransac : list\n        List containing the labels of all channels flagged as bad by RANSAC.\n    channel_correlations : np.ndarray\n        Array of shape (windows, channels) containing the correlations of\n        the channels with their predicted RANSAC values for each window.\n\n    References\n    ----------\n    .. [1] Fischler, M.A., Bolles, R.C. (1981). Random sample consensus: A\n        Paradigm for Model Fitting with Applications to Image Analysis and\n        Automated Cartography. Communications of the ACM, 24, 381-395\n    .. [2] Jas, M., Engemann, D.A., Bekhti, Y., Raimondo, F., Gramfort, A.\n        (2017). Autoreject: Automated Artifact Rejection for MEG and EEG\n        Data. NeuroImage, 159, 417-429\n\n    \"\"\"\n    if np.isnan(chn_pos).any():\n        raise ValueError('Found NaN in channel positions. Did you supply a montage for the raw data?')\n    if not isinstance(n_samples, int):\n        raise TypeError(f\"Argument 'n_samples' must be an int (got {type(n_samples).__name__})\")\n    complete_chn_labs = np.asarray(complete_chn_labs)\n    good_idx = np.array([idx for (idx, ch) in enumerate(complete_chn_labs) if ch not in exclude])\n    n_chans_good = good_idx.shape[0]\n    chn_pos_good = chn_pos[good_idx, :]\n    n_chans = data.shape[0]\n    n_pred_chns = int(np.around(sample_prop * n_chans))\n    if n_pred_chns <= 3:\n        sample_pct = int(sample_prop * 100)\n        raise OSError(f'Too few channels in the original data to reliably perform RANSAC(minimum {int(np.floor(4.0 / sample_prop))} for a sample size of {sample_pct}%).')\n    elif n_chans_good < n_pred_chns + 1:\n        raise OSError(f'Too many noisy channels in the data to reliably perform RANSAC (only {n_chans_good} good channels remaining, need at least {n_pred_chns + 1}).')\n    if channel_wise:\n        _verify_free_ram(data, n_samples, 1)\n    else:\n        window_size = int(sample_rate * corr_window_secs)\n        _verify_free_ram(data[:, :window_size], n_samples, n_chans_good)\n    random_ch_picks = []\n    good_chans = np.arange(chn_pos_good.shape[0])\n    rng = check_random_state(random_state)\n    for i in range(n_samples):\n        picks = _get_random_subset(good_chans, n_pred_chns, rng)\n        random_ch_picks.append(picks)\n    interp_mats = _make_interpolation_matrices(random_ch_picks, chn_pos_good)\n    correlation_frames = corr_window_secs * sample_rate\n    signal_frames = data.shape[1]\n    correlation_offsets = np.arange(0, signal_frames - correlation_frames, correlation_frames)\n    win_size = int(correlation_frames)\n    win_count = correlation_offsets.shape[0]\n    n_chans_complete = len(complete_chn_labs)\n    channel_correlations = np.ones((win_count, n_chans_complete))\n    logger.info('Executing RANSAC\\nThis may take a while, so be patient...')\n    if not channel_wise:\n        channel_correlations[:, good_idx] = _ransac_by_window(data[good_idx, :], interp_mats, win_size, win_count, matlab_strict)\n    chunk_sizes = []\n    chunk_count = 0\n    for i in range(1, n_chans_good + 1):\n        n_chunks = int(np.ceil(n_chans_good / i))\n        if n_chunks != chunk_count:\n            chunk_count = n_chunks\n            if not max_chunk_size or i <= max_chunk_size:\n                chunk_sizes.append(i)\n    chunk_size = chunk_sizes.pop()\n    mem_error = True\n    job = list(range(n_chans_good))\n    while mem_error and channel_wise:\n        try:\n            channel_chunks = _split_list(job, chunk_size)\n            total_chunks = len(channel_chunks)\n            current = 1\n            for chunk in channel_chunks:\n                interp_mats_for_chunk = [mat[chunk, :] for mat in interp_mats]\n                channel_correlations[:, good_idx[chunk]] = _ransac_by_channel(data[good_idx, :], interp_mats_for_chunk, win_size, win_count, chunk, random_ch_picks, matlab_strict)\n                if chunk == channel_chunks[0]:\n                    logger.info('Finding optimal chunk size : %s', chunk_size)\n                    logger.info('Total # of chunks: %s', total_chunks)\n                    logger.info('Current chunk:')\n                logger.info(current)\n                current = current + 1\n            mem_error = False\n            del current\n        except MemoryError:\n            if len(chunk_sizes):\n                chunk_size = chunk_sizes.pop()\n            else:\n                raise MemoryError('Not even doing 1 channel at a time the data fits in ram...You could downsample the data or reduce the number of requested samples.')\n    thresholded_correlations = channel_correlations < corr_thresh\n    frac_bad_corr_windows = np.mean(thresholded_correlations, axis=0)\n    bad_ransac_channels_idx = np.argwhere(frac_bad_corr_windows > frac_bad)\n    bad_ransac_channels_name = complete_chn_labs[bad_ransac_channels_idx.astype(int)]\n    bad_by_ransac = [i[0] for i in bad_ransac_channels_name]\n    logger.info('\\nRANSAC done!')\n    return (bad_by_ransac, channel_correlations)"
        },
        {
          "text": "def _ransac_by_window(data, interpolation_mats, win_size, win_count, matlab_strict):\n    \"\"\"Calculate correlations of channels with their RANSAC-predicted values.\n\n    This function calculates RANSAC correlations for each RANSAC window\n    individually, requiring RAM equivalent to [channels * sample rate * seconds\n    per RANSAC window] to run. Generally, this method will use less RAM than\n    :func:`_ransac_by_channel`, with the exception of short recordings with high\n    electrode counts.\n\n    Parameters\n    ----------\n    data : np.ndarray\n        A 2-D array containing the EEG signals from all currently-good channels.\n    interpolation_mats : list of np.ndarray\n        A list of interpolation matrices, one for each RANSAC sample of channels.\n    win_size : int\n        Number of frames/samples of EEG data in each RANSAC correlation window.\n    win_count: int\n        Number of RANSAC correlation windows.\n    matlab_strict : bool\n        Whether or not RANSAC should strictly follow MATLAB PREP's internal\n        math, ignoring any improvements made in PyPREP over the original code.\n\n    Returns\n    -------\n    correlations : np.ndarray\n        Correlations of the given channels to their predicted values within each\n        RANSAC window.\n\n    \"\"\"\n    ch_count = data.shape[0]\n    correlations = np.ones((win_count, ch_count))\n    pb = ProgressBar(range(win_count))\n    for window in pb:\n        start = window * win_size\n        end = (window + 1) * win_size\n        actual = data[:, start:end]\n        predicted = _predict_median_signals(actual, interpolation_mats, matlab_strict)\n        correlations[window, :] = _correlate_arrays(actual, predicted, matlab_strict)\n    return correlations"
        },
        {
          "text": "def _ransac_by_channel(data, interpolation_mats, win_size, win_count, chans_to_predict, random_ch_picks, matlab_strict):\n    \"\"\"Calculate correlations of channels with their RANSAC-predicted values.\n\n    This function calculates RANSAC correlations on one (or more) full channels\n    at once, requiring RAM equivalent to [channels per chunk * sample rate *\n    length of recording in seconds] to run. Generally, this method will use\n    more RAM than :func:`_ransac_by_window`, but may be faster for systems with\n    large amounts of RAM.\n\n    Parameters\n    ----------\n    data : np.ndarray\n        A 2-D array containing the EEG signals from all currently-good channels.\n    interpolation_mats : list of np.ndarray\n        A set of channel interpolation matrices, one for each RANSAC sample of\n        channels.\n    win_size : int\n        Number of frames/samples of EEG data in each RANSAC correlation window.\n    win_count: int\n        Number of RANSAC correlation windows.\n    chans_to_predict : list of int\n        Indices of the channels to predict (as they appear in `data`) within the\n        current chunk.\n    random_ch_picks : list of list of int\n        A list containing multiple random subsets of currently-good channels.\n    matlab_strict : bool\n        Whether or not RANSAC should strictly follow MATLAB PREP's internal\n        math, ignoring any improvements made in PyPREP over the original code.\n\n    Returns\n    -------\n    correlations : np.ndarray\n        Correlations of the given channels to their predicted values within each\n        RANSAC window.\n\n    \"\"\"\n    chunk_size = len(chans_to_predict)\n    correlations = np.ones((win_count, chunk_size))\n    predicted_chans = _predict_median_signals_channelwise(data=data, interpolation_mats=interpolation_mats, random_ch_picks=random_ch_picks, chunk_size=len(chans_to_predict), matlab_strict=matlab_strict)\n    data_window = data[chans_to_predict, :win_size * win_count]\n    data_window = data_window.reshape(chunk_size, win_count, win_size)\n    data_window = data_window.swapaxes(1, 0)\n    pred_window = predicted_chans[:chunk_size, :win_size * win_count]\n    pred_window = pred_window.reshape(chunk_size, win_count, win_size)\n    pred_window = pred_window.swapaxes(1, 0)\n    for k in range(win_count):\n        data_portion = data_window[k, :, :]\n        pred_portion = pred_window[k, :, :]\n        R = _correlate_arrays(data_portion, pred_portion, matlab_strict)\n        correlations[k, :] = R\n    return correlations"
        }
      ]
    }
  },
  {
    "query_id": "pyprep_ransac.py__ransac_by_channel_doc",
    "prompt": "How can I compute RANSAC correlations by channel for a chunk of EEG data?",
    "data": {
      "docs": [
        {
          "text": "def _ransac_by_channel(data, interpolation_mats, win_size, win_count, chans_to_predict, random_ch_picks, matlab_strict):\n    \"\"\"Calculate correlations of channels with their RANSAC-predicted values.\n\n    This function calculates RANSAC correlations on one (or more) full channels\n    at once, requiring RAM equivalent to [channels per chunk * sample rate *\n    length of recording in seconds] to run. Generally, this method will use\n    more RAM than :func:`_ransac_by_window`, but may be faster for systems with\n    large amounts of RAM.\n\n    Parameters\n    ----------\n    data : np.ndarray\n        A 2-D array containing the EEG signals from all currently-good channels.\n    interpolation_mats : list of np.ndarray\n        A set of channel interpolation matrices, one for each RANSAC sample of\n        channels.\n    win_size : int\n        Number of frames/samples of EEG data in each RANSAC correlation window.\n    win_count: int\n        Number of RANSAC correlation windows.\n    chans_to_predict : list of int\n        Indices of the channels to predict (as they appear in `data`) within the\n        current chunk.\n    random_ch_picks : list of list of int\n        A list containing multiple random subsets of currently-good channels.\n    matlab_strict : bool\n        Whether or not RANSAC should strictly follow MATLAB PREP's internal\n        math, ignoring any improvements made in PyPREP over the original code.\n\n    Returns\n    -------\n    correlations : np.ndarray\n        Correlations of the given channels to their predicted values within each\n        RANSAC window.\n\n    \"\"\"\n    chunk_size = len(chans_to_predict)\n    correlations = np.ones((win_count, chunk_size))\n    predicted_chans = _predict_median_signals_channelwise(data=data, interpolation_mats=interpolation_mats, random_ch_picks=random_ch_picks, chunk_size=len(chans_to_predict), matlab_strict=matlab_strict)\n    data_window = data[chans_to_predict, :win_size * win_count]\n    data_window = data_window.reshape(chunk_size, win_count, win_size)\n    data_window = data_window.swapaxes(1, 0)\n    pred_window = predicted_chans[:chunk_size, :win_size * win_count]\n    pred_window = pred_window.reshape(chunk_size, win_count, win_size)\n    pred_window = pred_window.swapaxes(1, 0)\n    for k in range(win_count):\n        data_portion = data_window[k, :, :]\n        pred_portion = pred_window[k, :, :]\n        R = _correlate_arrays(data_portion, pred_portion, matlab_strict)\n        correlations[k, :] = R\n    return correlations"
        },
        {
          "text": "def _ransac_by_window(data, interpolation_mats, win_size, win_count, matlab_strict):\n    \"\"\"Calculate correlations of channels with their RANSAC-predicted values.\n\n    This function calculates RANSAC correlations for each RANSAC window\n    individually, requiring RAM equivalent to [channels * sample rate * seconds\n    per RANSAC window] to run. Generally, this method will use less RAM than\n    :func:`_ransac_by_channel`, with the exception of short recordings with high\n    electrode counts.\n\n    Parameters\n    ----------\n    data : np.ndarray\n        A 2-D array containing the EEG signals from all currently-good channels.\n    interpolation_mats : list of np.ndarray\n        A list of interpolation matrices, one for each RANSAC sample of channels.\n    win_size : int\n        Number of frames/samples of EEG data in each RANSAC correlation window.\n    win_count: int\n        Number of RANSAC correlation windows.\n    matlab_strict : bool\n        Whether or not RANSAC should strictly follow MATLAB PREP's internal\n        math, ignoring any improvements made in PyPREP over the original code.\n\n    Returns\n    -------\n    correlations : np.ndarray\n        Correlations of the given channels to their predicted values within each\n        RANSAC window.\n\n    \"\"\"\n    ch_count = data.shape[0]\n    correlations = np.ones((win_count, ch_count))\n    pb = ProgressBar(range(win_count))\n    for window in pb:\n        start = window * win_size\n        end = (window + 1) * win_size\n        actual = data[:, start:end]\n        predicted = _predict_median_signals(actual, interpolation_mats, matlab_strict)\n        correlations[window, :] = _correlate_arrays(actual, predicted, matlab_strict)\n    return correlations"
        },
        {
          "text": "def find_bad_by_ransac(data, sample_rate, complete_chn_labs, chn_pos, exclude, n_samples=50, sample_prop=0.25, corr_thresh=0.75, frac_bad=0.4, corr_window_secs=5.0, channel_wise=False, max_chunk_size=None, random_state=None, matlab_strict=False):\n    \"\"\"Detect channels that are not predicted well by other channels.\n\n    Here, a RANSAC approach (see [1]_, and a short discussion in [2]_) is\n    adopted to predict a \"clean EEG\" dataset. After identifying clean EEG\n    channels through the other methods, the clean EEG dataset is\n    constructed by repeatedly sampling a small subset of clean EEG channels\n    and interpolation the complete data. The median of all those\n    repetitions forms the clean EEG dataset. In a second step, the original\n    and the RANSAC-predicted data are correlated and channels, which do not\n    correlate well with themselves across the two datasets are considered\n    `bad_by_ransac`.\n\n    Parameters\n    ----------\n    data : np.ndarray\n        A 2-D array of detrended EEG data, with bad-by-flat and bad-by-NaN\n        channels removed.\n    sample_rate : float\n        The sample rate (in Hz) of the EEG data.\n    complete_chn_labs : array_like\n        Labels for all channels in `data`, in the same order as they appear\n        in `data`.\n    chn_pos : np.ndarray\n        3-D electrode coordinates for all channels in `data`, in the same order\n        as they appear in `data`.\n    exclude : list\n        Labels of channels to exclude as signal predictors during RANSAC\n        (i.e., channels already flagged as bad by metrics other than HF noise).\n    n_samples : int, optional\n        Number of random channel samples to use for RANSAC. Defaults to ``50``.\n    sample_prop : float, optional\n        Proportion of total channels to use for signal prediction per RANSAC\n        sample. This needs to be in the range [0, 1], where 0 would mean no\n        channels would be used and 1 would mean all channels would be used\n        (neither of which would be useful values). Defaults to ``0.25`` (e.g.,\n        16 channels per sample for a 64-channel dataset).\n    corr_thresh : float, optional\n        The minimum predicted vs. actual signal correlation for a channel to\n        be considered good within a given RANSAC window. Defaults to ``0.75``.\n    frac_bad : float, optional\n        The minimum fraction of bad (i.e., below-threshold) RANSAC windows for a\n        channel to be considered bad-by-RANSAC. Defaults to ``0.4``.\n    corr_window_secs : float, optional\n        The duration (in seconds) of each RANSAC correlation window. Defaults to\n        5 seconds.\n    channel_wise : bool, optional\n        Whether RANSAC should predict signals for chunks of channels over the\n        entire signal length (\"channel-wise RANSAC\", see `max_chunk_size`\n        parameter). If ``False``, RANSAC will instead predict signals for all\n        channels at once but over a number of smaller time windows instead of\n        over the entire signal length (\"window-wise RANSAC\"). Channel-wise\n        RANSAC generally has higher RAM demands than window-wise RANSAC\n        (especially if `max_chunk_size` is ``None``), but can be faster on\n        systems with lots of RAM to spare. Defaults to ``False``.\n    max_chunk_size : {int, None}, optional\n        The maximum number of channels to predict at once during channel-wise\n        RANSAC. If ``None``, RANSAC will use the largest chunk size that will\n        fit into the available RAM, which may slow down other programs on the\n        host system. If using window-wise RANSAC (the default), this parameter\n        has no effect. Defaults to ``None``.\n    random_state : {int, None, np.random.RandomState}, optional\n        The random seed with which to generate random samples of channels during\n        RANSAC. If random_state is an int, it will be used as a seed for RandomState.\n        If ``None``, the seed will be obtained from the operating system\n        (see RandomState for details). Defaults to ``None``.\n    matlab_strict : bool, optional\n        Whether or not RANSAC should strictly follow MATLAB PREP's internal\n        math, ignoring any improvements made in PyPREP over the original code\n        (see :ref:`matlab-diffs` for more details). Defaults to ``False``.\n\n    Returns\n    -------\n    bad_by_ransac : list\n        List containing the labels of all channels flagged as bad by RANSAC.\n    channel_correlations : np.ndarray\n        Array of shape (windows, channels) containing the correlations of\n        the channels with their predicted RANSAC values for each window.\n\n    References\n    ----------\n    .. [1] Fischler, M.A., Bolles, R.C. (1981). Random sample consensus: A\n        Paradigm for Model Fitting with Applications to Image Analysis and\n        Automated Cartography. Communications of the ACM, 24, 381-395\n    .. [2] Jas, M., Engemann, D.A., Bekhti, Y., Raimondo, F., Gramfort, A.\n        (2017). Autoreject: Automated Artifact Rejection for MEG and EEG\n        Data. NeuroImage, 159, 417-429\n\n    \"\"\"\n    if np.isnan(chn_pos).any():\n        raise ValueError('Found NaN in channel positions. Did you supply a montage for the raw data?')\n    if not isinstance(n_samples, int):\n        raise TypeError(f\"Argument 'n_samples' must be an int (got {type(n_samples).__name__})\")\n    complete_chn_labs = np.asarray(complete_chn_labs)\n    good_idx = np.array([idx for (idx, ch) in enumerate(complete_chn_labs) if ch not in exclude])\n    n_chans_good = good_idx.shape[0]\n    chn_pos_good = chn_pos[good_idx, :]\n    n_chans = data.shape[0]\n    n_pred_chns = int(np.around(sample_prop * n_chans))\n    if n_pred_chns <= 3:\n        sample_pct = int(sample_prop * 100)\n        raise OSError(f'Too few channels in the original data to reliably perform RANSAC(minimum {int(np.floor(4.0 / sample_prop))} for a sample size of {sample_pct}%).')\n    elif n_chans_good < n_pred_chns + 1:\n        raise OSError(f'Too many noisy channels in the data to reliably perform RANSAC (only {n_chans_good} good channels remaining, need at least {n_pred_chns + 1}).')\n    if channel_wise:\n        _verify_free_ram(data, n_samples, 1)\n    else:\n        window_size = int(sample_rate * corr_window_secs)\n        _verify_free_ram(data[:, :window_size], n_samples, n_chans_good)\n    random_ch_picks = []\n    good_chans = np.arange(chn_pos_good.shape[0])\n    rng = check_random_state(random_state)\n    for i in range(n_samples):\n        picks = _get_random_subset(good_chans, n_pred_chns, rng)\n        random_ch_picks.append(picks)\n    interp_mats = _make_interpolation_matrices(random_ch_picks, chn_pos_good)\n    correlation_frames = corr_window_secs * sample_rate\n    signal_frames = data.shape[1]\n    correlation_offsets = np.arange(0, signal_frames - correlation_frames, correlation_frames)\n    win_size = int(correlation_frames)\n    win_count = correlation_offsets.shape[0]\n    n_chans_complete = len(complete_chn_labs)\n    channel_correlations = np.ones((win_count, n_chans_complete))\n    logger.info('Executing RANSAC\\nThis may take a while, so be patient...')\n    if not channel_wise:\n        channel_correlations[:, good_idx] = _ransac_by_window(data[good_idx, :], interp_mats, win_size, win_count, matlab_strict)\n    chunk_sizes = []\n    chunk_count = 0\n    for i in range(1, n_chans_good + 1):\n        n_chunks = int(np.ceil(n_chans_good / i))\n        if n_chunks != chunk_count:\n            chunk_count = n_chunks\n            if not max_chunk_size or i <= max_chunk_size:\n                chunk_sizes.append(i)\n    chunk_size = chunk_sizes.pop()\n    mem_error = True\n    job = list(range(n_chans_good))\n    while mem_error and channel_wise:\n        try:\n            channel_chunks = _split_list(job, chunk_size)\n            total_chunks = len(channel_chunks)\n            current = 1\n            for chunk in channel_chunks:\n                interp_mats_for_chunk = [mat[chunk, :] for mat in interp_mats]\n                channel_correlations[:, good_idx[chunk]] = _ransac_by_channel(data[good_idx, :], interp_mats_for_chunk, win_size, win_count, chunk, random_ch_picks, matlab_strict)\n                if chunk == channel_chunks[0]:\n                    logger.info('Finding optimal chunk size : %s', chunk_size)\n                    logger.info('Total # of chunks: %s', total_chunks)\n                    logger.info('Current chunk:')\n                logger.info(current)\n                current = current + 1\n            mem_error = False\n            del current\n        except MemoryError:\n            if len(chunk_sizes):\n                chunk_size = chunk_sizes.pop()\n            else:\n                raise MemoryError('Not even doing 1 channel at a time the data fits in ram...You could downsample the data or reduce the number of requested samples.')\n    thresholded_correlations = channel_correlations < corr_thresh\n    frac_bad_corr_windows = np.mean(thresholded_correlations, axis=0)\n    bad_ransac_channels_idx = np.argwhere(frac_bad_corr_windows > frac_bad)\n    bad_ransac_channels_name = complete_chn_labs[bad_ransac_channels_idx.astype(int)]\n    bad_by_ransac = [i[0] for i in bad_ransac_channels_name]\n    logger.info('\\nRANSAC done!')\n    return (bad_by_ransac, channel_correlations)"
        },
        {
          "text": "def find_bad_by_ransac(self, n_samples=50, sample_prop=0.25, corr_thresh=0.75, frac_bad=0.4, corr_window_secs=5.0, channel_wise=False, max_chunk_size=None):\n    \"\"\"Detect channels that are predicted poorly by other channels.\n\n        This method uses a random sample consensus approach (RANSAC, see [1]_,\n        and a short discussion in [2]_) to try and predict what the signal should\n        be for each channel based on the signals and spatial locations of other\n        currently-good channels. RANSAC correlations are calculated by splitting\n        the recording into non-overlapping windows of time (default: 5 seconds)\n        and correlating each channel's RANSAC-predicted signal with its actual\n        signal within each window.\n\n        A RANSAC window is considered \"bad\" for a channel if its predicted signal\n        vs. actual signal correlation falls below the given correlation threshold\n        (default: ``0.75``). A channel is considered \"bad-by-RANSAC\" if its fraction\n        of bad RANSAC windows is above the given threshold (default: ``0.4``).\n\n        Due to its random sampling component, the channels identified as\n        \"bad-by-RANSAC\" may vary slightly between calls of this method.\n        Additionally, bad channels may vary between different montages given that\n        RANSAC's signal predictions are based on the spatial coordinates of each\n        electrode.\n\n        This method is a wrapper for the :func:`~ransac.find_bad_by_ransac`\n        function.\n\n        .. warning:: For optimal performance, RANSAC requires that channels bad by\n                     deviation, correlation, and/or dropout have already been\n                     flagged. Otherwise RANSAC will attempt to use those channels\n                     when making signal predictions, decreasing accuracy and thus\n                     increasing the likelihood of false positives.\n\n        Parameters\n        ----------\n        n_samples : int, optional\n            Number of random channel samples to use for RANSAC. Defaults\n            to ``50``.\n        sample_prop : float, optional\n            Proportion of total channels to use for signal prediction per RANSAC\n            sample. This needs to be in the range [0, 1], where 0 would mean no\n            channels would be used and 1 would mean all channels would be used\n            (neither of which would be useful values). Defaults to ``0.25``\n            (e.g., 16 channels per sample for a 64-channel dataset).\n        corr_thresh : float, optional\n            The minimum predicted vs. actual signal correlation for a channel to\n            be considered good within a given RANSAC window. Defaults\n            to ``0.75``.\n        frac_bad : float, optional\n            The minimum fraction of bad (i.e., below-threshold) RANSAC windows\n            for a channel to be considered bad-by-RANSAC. Defaults to ``0.4``.\n        corr_window_secs : float, optional\n            The duration (in seconds) of each RANSAC correlation window. Defaults\n            to 5 seconds.\n        channel_wise : bool, optional\n            Whether RANSAC should predict signals for chunks of channels over the\n            entire signal length (\"channel-wise RANSAC\", see `max_chunk_size`\n            parameter). If ``False``, RANSAC will instead predict signals for all\n            channels at once but over a number of smaller time windows instead of\n            over the entire signal length (\"window-wise RANSAC\"). Channel-wise\n            RANSAC generally has higher RAM demands than window-wise RANSAC\n            (especially if `max_chunk_size` is ``None``), but can be faster on\n            systems with lots of RAM to spare. Defaults to ``False``.\n        max_chunk_size : {int, None}, optional\n            The maximum number of channels to predict at once during\n            channel-wise RANSAC. If ``None``, RANSAC will use the largest chunk\n            size that will fit into the available RAM, which may slow down\n            other programs on the host system. If using window-wise RANSAC\n            (the default), this parameter has no effect. Defaults to ``None``.\n\n        References\n        ----------\n        .. [1] Fischler, M.A., Bolles, R.C. (1981). Random sample consensus: A\n            Paradigm for Model Fitting with Applications to Image Analysis and\n            Automated Cartography. Communications of the ACM, 24, 381-395\n        .. [2] Jas, M., Engemann, D.A., Bekhti, Y., Raimondo, F., Gramfort, A.\n            (2017). Autoreject: Automated Artifact Rejection for MEG and EEG\n            Data. NeuroImage, 159, 417-429\n\n        \"\"\"\n    if self.EEGFiltered is None:\n        self.EEGFiltered = self._get_filtered_data()\n    exclude_from_ransac = self.bad_by_correlation + self.bad_by_deviation + self.bad_by_dropout\n    if self.matlab_strict:\n        random_state = self.random_state.get_state()\n        rng = np.random.RandomState()\n        rng.set_state(random_state)\n    else:\n        rng = self.random_state\n    (self.bad_by_ransac, ch_correlations_usable) = find_bad_by_ransac(self.EEGFiltered, self.sample_rate, self.ch_names_new, self.raw_mne._get_channel_positions()[self.usable_idx, :], exclude_from_ransac, n_samples, sample_prop, corr_thresh, frac_bad, corr_window_secs, channel_wise, max_chunk_size, rng, self.matlab_strict)\n    n_ransac_windows = ch_correlations_usable.shape[0]\n    ch_correlations = np.ones((n_ransac_windows, self.n_chans_original))\n    ch_correlations[:, self.usable_idx] = ch_correlations_usable\n    self._extra_info['bad_by_ransac'] = {'ransac_correlations': ch_correlations, 'bad_window_fractions': np.mean(ch_correlations < corr_thresh, axis=0)}"
        },
        {
          "text": "def _correlate_arrays(a, b, matlab_strict=False):\n    \"\"\"Calculate correlations between two equally-sized 2-D arrays of EEG data.\n\n    Both input arrays must be in the shape (channels, samples).\n\n    Parameters\n    ----------\n    a : np.ndarray\n        A 2-D array to correlate with `a`.\n    b : np.ndarray\n        A 2-D array to correlate with `b`.\n    matlab_strict : bool, optional\n        Whether or not correlations should be calculated identically to MATLAB\n        PREP (i.e., without mean subtraction) instead of by traditional Pearson\n        product-moment correlation (see Notes for details). Defaults to\n        ``False`` (Pearson correlation).\n\n    Returns\n    -------\n    correlations : np.ndarray\n        A one-dimensional array containing the correlations of the two input arrays\n        along the second axis.\n\n    Notes\n    -----\n    In MATLAB PREP, RANSAC channel predictions are correlated with actual data\n    using a non-standard method: essentially, it uses the standard Pearson\n    correlation formula but without subtracting the channel means from each channel\n    before calculating sums of squares, i.e.,::\n\n       SSa = np.sum(a ** 2)\n       SSb = np.sum(b ** 2)\n       correlation = np.sum(a * b) / (np.sqrt(SSa) * np.sqrt(SSb))\n\n    Because EEG data is roughly mean-centered to begin with, this produces similar\n    values to normal Pearson correlation. However, to avoid making any assumptions\n    about the signal for any given channel/window, PyPREP defaults to normal\n    Pearson correlation unless strict MATLAB equivalence is requested.\n\n    \"\"\"\n    if matlab_strict:\n        SSa = np.sum(a ** 2, axis=1)\n        SSb = np.sum(b ** 2, axis=1)\n        SSab = np.sum(a * b, axis=1)\n        return SSab / (np.sqrt(SSa) * np.sqrt(SSb))\n    else:\n        n_chan = a.shape[0]\n        return np.diag(np.corrcoef(a, b)[:n_chan, n_chan:])"
        }
      ]
    }
  },
  {
    "query_id": "pyprep_ransac.py__predict_median_signals_channelwise_doc",
    "prompt": "How do I calculate the median RANSAC-predicted EEG signals for a chunk of channels?",
    "data": {
      "docs": [
        {
          "text": "def _predict_median_signals_channelwise(data, interpolation_mats, random_ch_picks, chunk_size, matlab_strict):\n    \"\"\"Calculate the median RANSAC-predicted signal for a given chunk of channels.\n\n    Parameters\n    ----------\n    data : np.ndarray\n        A 2-D array containing the EEG signals from all currently-good channels.\n    interpolation_mats : list of np.ndarray\n        A set of channel interpolation matrices, one for each RANSAC sample of\n        channels.\n    random_ch_picks : list of list of int\n        A list containing multiple random subsets of currently-good channels.\n    chunk_size : int\n        The number of channels to predict in the current chunk.\n    matlab_strict : bool\n        Whether or not RANSAC should strictly follow MATLAB PREP's internal\n        math, ignoring any improvements made in PyPREP over the original code.\n\n    Returns\n    -------\n    predicted_chans : np.ndarray\n        The median RANSAC-predicted EEG signals for the given chunk of channels.\n\n    \"\"\"\n    ransac_samples = len(interpolation_mats)\n    n_timepts = data.shape[1]\n    _verify_free_ram(data, ransac_samples, chunk_size)\n    eeg_predictions = np.zeros((chunk_size, n_timepts, ransac_samples))\n    for sample in range(ransac_samples):\n        reconstr_idx = random_ch_picks[sample]\n        interp_mat = interpolation_mats[sample][:, reconstr_idx]\n        eeg_predictions[..., sample] = np.matmul(interp_mat, data[reconstr_idx, :])\n    if matlab_strict:\n        median_idx = int(_mat_round(ransac_samples / 2.0) - 1)\n        eeg_predictions.sort(axis=-1)\n        return eeg_predictions[:, :, median_idx]\n    else:\n        return np.median(eeg_predictions, axis=-1, overwrite_input=True)"
        },
        {
          "text": "def _predict_median_signals(window, interpolation_mats, matlab_strict=False):\n    \"\"\"Calculate the median RANSAC-predicted signal for a given window of data.\n\n    Parameters\n    ----------\n    window : np.ndarray\n        A 2-D window of EEG data with the shape `[channels, samples]`.\n    interpolation_mats : list of np.ndarray\n        A set of channel interpolation matrices, one for each RANSAC sample of\n        channels.\n    matlab_strict : bool\n        Whether or not RANSAC should strictly follow MATLAB PREP's internal\n        math, ignoring any improvements made in PyPREP over the original code.\n\n    Returns\n    -------\n    predicted : np.ndarray\n        The median RANSAC-predicted EEG signal for the given window of data.\n\n    Notes\n    -----\n    In MATLAB PREP, the median signal is calculated by sorting the different\n    predictions for each EEG sample/channel from low to high and then taking the value\n    at the middle index (as calculated by ``int(n_ransac_samples / 2.0)``) for each.\n    Because this logic only returns the correct result for odd numbers of samples, the\n    current function will instead return the true median signal across predictions\n    unless strict MATLAB equivalence is requested.\n\n    \"\"\"\n    ransac_samples = len(interpolation_mats)\n    merged_mats = np.concatenate(interpolation_mats, axis=0)\n    predictions_per_sample = np.reshape(np.matmul(merged_mats, window), (ransac_samples, window.shape[0], window.shape[1]))\n    if matlab_strict:\n        median_idx = int(_mat_round(ransac_samples / 2.0) - 1)\n        predictions_per_sample.sort(axis=0)\n        return predictions_per_sample[median_idx, :, :]\n    else:\n        return np.median(predictions_per_sample, axis=0)"
        },
        {
          "text": "def find_bad_by_ransac(data, sample_rate, complete_chn_labs, chn_pos, exclude, n_samples=50, sample_prop=0.25, corr_thresh=0.75, frac_bad=0.4, corr_window_secs=5.0, channel_wise=False, max_chunk_size=None, random_state=None, matlab_strict=False):\n    \"\"\"Detect channels that are not predicted well by other channels.\n\n    Here, a RANSAC approach (see [1]_, and a short discussion in [2]_) is\n    adopted to predict a \"clean EEG\" dataset. After identifying clean EEG\n    channels through the other methods, the clean EEG dataset is\n    constructed by repeatedly sampling a small subset of clean EEG channels\n    and interpolation the complete data. The median of all those\n    repetitions forms the clean EEG dataset. In a second step, the original\n    and the RANSAC-predicted data are correlated and channels, which do not\n    correlate well with themselves across the two datasets are considered\n    `bad_by_ransac`.\n\n    Parameters\n    ----------\n    data : np.ndarray\n        A 2-D array of detrended EEG data, with bad-by-flat and bad-by-NaN\n        channels removed.\n    sample_rate : float\n        The sample rate (in Hz) of the EEG data.\n    complete_chn_labs : array_like\n        Labels for all channels in `data`, in the same order as they appear\n        in `data`.\n    chn_pos : np.ndarray\n        3-D electrode coordinates for all channels in `data`, in the same order\n        as they appear in `data`.\n    exclude : list\n        Labels of channels to exclude as signal predictors during RANSAC\n        (i.e., channels already flagged as bad by metrics other than HF noise).\n    n_samples : int, optional\n        Number of random channel samples to use for RANSAC. Defaults to ``50``.\n    sample_prop : float, optional\n        Proportion of total channels to use for signal prediction per RANSAC\n        sample. This needs to be in the range [0, 1], where 0 would mean no\n        channels would be used and 1 would mean all channels would be used\n        (neither of which would be useful values). Defaults to ``0.25`` (e.g.,\n        16 channels per sample for a 64-channel dataset).\n    corr_thresh : float, optional\n        The minimum predicted vs. actual signal correlation for a channel to\n        be considered good within a given RANSAC window. Defaults to ``0.75``.\n    frac_bad : float, optional\n        The minimum fraction of bad (i.e., below-threshold) RANSAC windows for a\n        channel to be considered bad-by-RANSAC. Defaults to ``0.4``.\n    corr_window_secs : float, optional\n        The duration (in seconds) of each RANSAC correlation window. Defaults to\n        5 seconds.\n    channel_wise : bool, optional\n        Whether RANSAC should predict signals for chunks of channels over the\n        entire signal length (\"channel-wise RANSAC\", see `max_chunk_size`\n        parameter). If ``False``, RANSAC will instead predict signals for all\n        channels at once but over a number of smaller time windows instead of\n        over the entire signal length (\"window-wise RANSAC\"). Channel-wise\n        RANSAC generally has higher RAM demands than window-wise RANSAC\n        (especially if `max_chunk_size` is ``None``), but can be faster on\n        systems with lots of RAM to spare. Defaults to ``False``.\n    max_chunk_size : {int, None}, optional\n        The maximum number of channels to predict at once during channel-wise\n        RANSAC. If ``None``, RANSAC will use the largest chunk size that will\n        fit into the available RAM, which may slow down other programs on the\n        host system. If using window-wise RANSAC (the default), this parameter\n        has no effect. Defaults to ``None``.\n    random_state : {int, None, np.random.RandomState}, optional\n        The random seed with which to generate random samples of channels during\n        RANSAC. If random_state is an int, it will be used as a seed for RandomState.\n        If ``None``, the seed will be obtained from the operating system\n        (see RandomState for details). Defaults to ``None``.\n    matlab_strict : bool, optional\n        Whether or not RANSAC should strictly follow MATLAB PREP's internal\n        math, ignoring any improvements made in PyPREP over the original code\n        (see :ref:`matlab-diffs` for more details). Defaults to ``False``.\n\n    Returns\n    -------\n    bad_by_ransac : list\n        List containing the labels of all channels flagged as bad by RANSAC.\n    channel_correlations : np.ndarray\n        Array of shape (windows, channels) containing the correlations of\n        the channels with their predicted RANSAC values for each window.\n\n    References\n    ----------\n    .. [1] Fischler, M.A., Bolles, R.C. (1981). Random sample consensus: A\n        Paradigm for Model Fitting with Applications to Image Analysis and\n        Automated Cartography. Communications of the ACM, 24, 381-395\n    .. [2] Jas, M., Engemann, D.A., Bekhti, Y., Raimondo, F., Gramfort, A.\n        (2017). Autoreject: Automated Artifact Rejection for MEG and EEG\n        Data. NeuroImage, 159, 417-429\n\n    \"\"\"\n    if np.isnan(chn_pos).any():\n        raise ValueError('Found NaN in channel positions. Did you supply a montage for the raw data?')\n    if not isinstance(n_samples, int):\n        raise TypeError(f\"Argument 'n_samples' must be an int (got {type(n_samples).__name__})\")\n    complete_chn_labs = np.asarray(complete_chn_labs)\n    good_idx = np.array([idx for (idx, ch) in enumerate(complete_chn_labs) if ch not in exclude])\n    n_chans_good = good_idx.shape[0]\n    chn_pos_good = chn_pos[good_idx, :]\n    n_chans = data.shape[0]\n    n_pred_chns = int(np.around(sample_prop * n_chans))\n    if n_pred_chns <= 3:\n        sample_pct = int(sample_prop * 100)\n        raise OSError(f'Too few channels in the original data to reliably perform RANSAC(minimum {int(np.floor(4.0 / sample_prop))} for a sample size of {sample_pct}%).')\n    elif n_chans_good < n_pred_chns + 1:\n        raise OSError(f'Too many noisy channels in the data to reliably perform RANSAC (only {n_chans_good} good channels remaining, need at least {n_pred_chns + 1}).')\n    if channel_wise:\n        _verify_free_ram(data, n_samples, 1)\n    else:\n        window_size = int(sample_rate * corr_window_secs)\n        _verify_free_ram(data[:, :window_size], n_samples, n_chans_good)\n    random_ch_picks = []\n    good_chans = np.arange(chn_pos_good.shape[0])\n    rng = check_random_state(random_state)\n    for i in range(n_samples):\n        picks = _get_random_subset(good_chans, n_pred_chns, rng)\n        random_ch_picks.append(picks)\n    interp_mats = _make_interpolation_matrices(random_ch_picks, chn_pos_good)\n    correlation_frames = corr_window_secs * sample_rate\n    signal_frames = data.shape[1]\n    correlation_offsets = np.arange(0, signal_frames - correlation_frames, correlation_frames)\n    win_size = int(correlation_frames)\n    win_count = correlation_offsets.shape[0]\n    n_chans_complete = len(complete_chn_labs)\n    channel_correlations = np.ones((win_count, n_chans_complete))\n    logger.info('Executing RANSAC\\nThis may take a while, so be patient...')\n    if not channel_wise:\n        channel_correlations[:, good_idx] = _ransac_by_window(data[good_idx, :], interp_mats, win_size, win_count, matlab_strict)\n    chunk_sizes = []\n    chunk_count = 0\n    for i in range(1, n_chans_good + 1):\n        n_chunks = int(np.ceil(n_chans_good / i))\n        if n_chunks != chunk_count:\n            chunk_count = n_chunks\n            if not max_chunk_size or i <= max_chunk_size:\n                chunk_sizes.append(i)\n    chunk_size = chunk_sizes.pop()\n    mem_error = True\n    job = list(range(n_chans_good))\n    while mem_error and channel_wise:\n        try:\n            channel_chunks = _split_list(job, chunk_size)\n            total_chunks = len(channel_chunks)\n            current = 1\n            for chunk in channel_chunks:\n                interp_mats_for_chunk = [mat[chunk, :] for mat in interp_mats]\n                channel_correlations[:, good_idx[chunk]] = _ransac_by_channel(data[good_idx, :], interp_mats_for_chunk, win_size, win_count, chunk, random_ch_picks, matlab_strict)\n                if chunk == channel_chunks[0]:\n                    logger.info('Finding optimal chunk size : %s', chunk_size)\n                    logger.info('Total # of chunks: %s', total_chunks)\n                    logger.info('Current chunk:')\n                logger.info(current)\n                current = current + 1\n            mem_error = False\n            del current\n        except MemoryError:\n            if len(chunk_sizes):\n                chunk_size = chunk_sizes.pop()\n            else:\n                raise MemoryError('Not even doing 1 channel at a time the data fits in ram...You could downsample the data or reduce the number of requested samples.')\n    thresholded_correlations = channel_correlations < corr_thresh\n    frac_bad_corr_windows = np.mean(thresholded_correlations, axis=0)\n    bad_ransac_channels_idx = np.argwhere(frac_bad_corr_windows > frac_bad)\n    bad_ransac_channels_name = complete_chn_labs[bad_ransac_channels_idx.astype(int)]\n    bad_by_ransac = [i[0] for i in bad_ransac_channels_name]\n    logger.info('\\nRANSAC done!')\n    return (bad_by_ransac, channel_correlations)"
        },
        {
          "text": "def _ransac_by_channel(data, interpolation_mats, win_size, win_count, chans_to_predict, random_ch_picks, matlab_strict):\n    \"\"\"Calculate correlations of channels with their RANSAC-predicted values.\n\n    This function calculates RANSAC correlations on one (or more) full channels\n    at once, requiring RAM equivalent to [channels per chunk * sample rate *\n    length of recording in seconds] to run. Generally, this method will use\n    more RAM than :func:`_ransac_by_window`, but may be faster for systems with\n    large amounts of RAM.\n\n    Parameters\n    ----------\n    data : np.ndarray\n        A 2-D array containing the EEG signals from all currently-good channels.\n    interpolation_mats : list of np.ndarray\n        A set of channel interpolation matrices, one for each RANSAC sample of\n        channels.\n    win_size : int\n        Number of frames/samples of EEG data in each RANSAC correlation window.\n    win_count: int\n        Number of RANSAC correlation windows.\n    chans_to_predict : list of int\n        Indices of the channels to predict (as they appear in `data`) within the\n        current chunk.\n    random_ch_picks : list of list of int\n        A list containing multiple random subsets of currently-good channels.\n    matlab_strict : bool\n        Whether or not RANSAC should strictly follow MATLAB PREP's internal\n        math, ignoring any improvements made in PyPREP over the original code.\n\n    Returns\n    -------\n    correlations : np.ndarray\n        Correlations of the given channels to their predicted values within each\n        RANSAC window.\n\n    \"\"\"\n    chunk_size = len(chans_to_predict)\n    correlations = np.ones((win_count, chunk_size))\n    predicted_chans = _predict_median_signals_channelwise(data=data, interpolation_mats=interpolation_mats, random_ch_picks=random_ch_picks, chunk_size=len(chans_to_predict), matlab_strict=matlab_strict)\n    data_window = data[chans_to_predict, :win_size * win_count]\n    data_window = data_window.reshape(chunk_size, win_count, win_size)\n    data_window = data_window.swapaxes(1, 0)\n    pred_window = predicted_chans[:chunk_size, :win_size * win_count]\n    pred_window = pred_window.reshape(chunk_size, win_count, win_size)\n    pred_window = pred_window.swapaxes(1, 0)\n    for k in range(win_count):\n        data_portion = data_window[k, :, :]\n        pred_portion = pred_window[k, :, :]\n        R = _correlate_arrays(data_portion, pred_portion, matlab_strict)\n        correlations[k, :] = R\n    return correlations"
        },
        {
          "text": "def _ransac_by_window(data, interpolation_mats, win_size, win_count, matlab_strict):\n    \"\"\"Calculate correlations of channels with their RANSAC-predicted values.\n\n    This function calculates RANSAC correlations for each RANSAC window\n    individually, requiring RAM equivalent to [channels * sample rate * seconds\n    per RANSAC window] to run. Generally, this method will use less RAM than\n    :func:`_ransac_by_channel`, with the exception of short recordings with high\n    electrode counts.\n\n    Parameters\n    ----------\n    data : np.ndarray\n        A 2-D array containing the EEG signals from all currently-good channels.\n    interpolation_mats : list of np.ndarray\n        A list of interpolation matrices, one for each RANSAC sample of channels.\n    win_size : int\n        Number of frames/samples of EEG data in each RANSAC correlation window.\n    win_count: int\n        Number of RANSAC correlation windows.\n    matlab_strict : bool\n        Whether or not RANSAC should strictly follow MATLAB PREP's internal\n        math, ignoring any improvements made in PyPREP over the original code.\n\n    Returns\n    -------\n    correlations : np.ndarray\n        Correlations of the given channels to their predicted values within each\n        RANSAC window.\n\n    \"\"\"\n    ch_count = data.shape[0]\n    correlations = np.ones((win_count, ch_count))\n    pb = ProgressBar(range(win_count))\n    for window in pb:\n        start = window * win_size\n        end = (window + 1) * win_size\n        actual = data[:, start:end]\n        predicted = _predict_median_signals(actual, interpolation_mats, matlab_strict)\n        correlations[window, :] = _correlate_arrays(actual, predicted, matlab_strict)\n    return correlations"
        }
      ]
    }
  },
  {
    "query_id": "pyprep_find_noisy_channels.py___init___doc",
    "prompt": "How do I initialize the NoisyChannels class?",
    "data": {
      "docs": [
        {
          "text": "def robust_reference(self, max_iterations=4):\n    \"\"\"Detect bad channels and estimate the robust reference signal.\n\n        This function implements the functionality of the `robustReference` function\n        as part of the PREP pipeline on mne raw object.\n\n        Parameters\n        ----------\n        max_iterations : int, optional\n            The maximum number of iterations of noisy channel removal to perform\n            during robust referencing. Defaults to ``4``.\n\n        Returns\n        -------\n        noisy_channels: dict\n            A dictionary of names of noisy channels detected from all methods\n            after referencing.\n        reference_signal: np.ndarray, shape(n, )\n            Estimation of the 'true' signal mean\n\n        \"\"\"\n    raw = self.raw.copy()\n    raw._data = removeTrend(raw.get_data(), self.sfreq, matlab_strict=self.matlab_strict)\n    noisy_detector = NoisyChannels(raw, do_detrend=False, random_state=self.random_state, matlab_strict=self.matlab_strict)\n    noisy_detector.find_all_bads(**self.ransac_settings)\n    self.noisy_channels_original = noisy_detector.get_bads(as_dict=True)\n    self._extra_info['initial_bad'] = noisy_detector._extra_info\n    logger.info(f'Bad channels: {self.noisy_channels_original}')\n    self.unusable_channels = _union(noisy_detector.bad_by_nan + noisy_detector.bad_by_flat, noisy_detector.bad_by_SNR + self.bads_manual)\n    reference_channels = _set_diff(self.reference_channels, self.unusable_channels)\n    noisy = {'bad_by_nan': noisy_detector.bad_by_nan, 'bad_by_flat': noisy_detector.bad_by_flat, 'bad_by_deviation': [], 'bad_by_hf_noise': [], 'bad_by_correlation': [], 'bad_by_SNR': [], 'bad_by_dropout': [], 'bad_by_ransac': [], 'bad_by_manual': self.bads_manual, 'bad_all': []}\n    signal = raw.get_data()\n    self.reference_signal = np.nanmedian(raw.get_data(picks=reference_channels), axis=0)\n    reference_index = [self.ch_names_eeg.index(ch) for ch in reference_channels]\n    signal_tmp = self.remove_reference(signal, self.reference_signal, reference_index)\n    raw_tmp = raw.copy()\n    iterations = 0\n    previous_bads = set()\n    while True:\n        raw_tmp._data = signal_tmp\n        noisy_detector = NoisyChannels(raw_tmp, do_detrend=False, random_state=self.random_state, matlab_strict=self.matlab_strict)\n        noisy_detector.find_all_bads(**self.ransac_settings)\n        noisy_new = noisy_detector.get_bads(as_dict=True)\n        ignore = ['bad_by_SNR', 'bad_all']\n        if self.matlab_strict:\n            ignore += ['bad_by_dropout']\n        bad_chans = set()\n        for bad_type in noisy_new.keys():\n            noisy[bad_type] = _union(noisy[bad_type], noisy_new[bad_type])\n            if bad_type not in ignore:\n                bad_chans.update(noisy[bad_type])\n        noisy['bad_by_manual'] = self.bads_manual\n        noisy['bad_all'] = list(bad_chans) + self.bads_manual\n        logger.info(f'Bad channels: {noisy}')\n        if iterations > 1 and (len(bad_chans) == 0 or bad_chans == previous_bads) or iterations > max_iterations:\n            logger.info('Robust reference done')\n            self.noisy_channels = noisy\n            break\n        previous_bads = bad_chans.copy()\n        if raw_tmp.info['nchan'] - len(bad_chans) < 2:\n            raise ValueError('RobustReference:TooManyBad Could not perform a robust reference -- not enough good channels')\n        if len(bad_chans) > 0:\n            raw_tmp._data = signal.copy()\n            raw_tmp.info['bads'] = list(bad_chans)\n            if self.matlab_strict:\n                _eeglab_interpolate_bads(raw_tmp)\n            else:\n                raw_tmp.interpolate_bads()\n        self.reference_signal = np.nanmean(raw_tmp.get_data(picks=reference_channels), axis=0)\n        signal_tmp = self.remove_reference(signal, self.reference_signal, reference_index)\n        iterations = iterations + 1\n        logger.info(f'Iterations: {iterations}')\n    return (self.noisy_channels, self.reference_signal)"
        },
        {
          "text": "def find_bad_by_SNR(self):\n    \"\"\"Detect channels that have a low signal-to-noise ratio.\n\n        Channels are considered \"bad-by-SNR\" if they are bad by both high-frequency\n        noise and bad by low correlation.\n\n        \"\"\"\n    if not len(self._extra_info['bad_by_hf_noise']) > 1:\n        self.find_bad_by_hfnoise()\n    if not len(self._extra_info['bad_by_correlation']):\n        self.find_bad_by_correlation()\n    bad_by_hf = set(self.bad_by_hf_noise)\n    bad_by_corr = set(self.bad_by_correlation)\n    self.bad_by_SNR = list(bad_by_corr.intersection(bad_by_hf))"
        },
        {
          "text": "def find_bad_by_hfnoise(self, HF_zscore_threshold=5.0):\n    \"\"\"Detect channels with abnormally high amounts of high-frequency noise.\n\n        The noisiness of a channel is defined as the amplitude of its\n        high-frequency (>50 Hz) components divided by its overall amplitude.\n        A channel is considered \"bad-by-high-frequency-noise\" if its noisiness\n        is considerably higher than the median channel noisiness, as determined\n        by a robust Z-scoring method and the given Z-score threshold.\n\n        Due to the Nyquist theorem, this method will only attempt bad channel\n        detection if the sample rate of the given signal is above 100 Hz.\n\n        Parameters\n        ----------\n        HF_zscore_threshold : float, optional\n            The minimum noisiness z-score of a channel for it to be considered\n            bad-by-high-frequency-noise. Defaults to ``5.0``.\n\n        \"\"\"\n    MAD_TO_SD = 1.4826\n    if self.EEGFiltered is None:\n        self.EEGFiltered = self._get_filtered_data()\n    (noise_median, noise_sd) = (0, 1)\n    noise_zscore = np.zeros(self.n_chans_original)\n    if self.sample_rate > 100:\n        noisiness = np.divide(median_abs_deviation(self.EEGData - self.EEGFiltered, axis=1), median_abs_deviation(self.EEGFiltered, axis=1))\n        noise_median = np.nanmedian(noisiness)\n        noise_sd = np.median(np.abs(noisiness - noise_median)) * MAD_TO_SD\n        noise_zscore[self.usable_idx] = (noisiness - noise_median) / noise_sd\n    hf_mask = np.isnan(noise_zscore) | (noise_zscore > HF_zscore_threshold)\n    hf_noise_channels = self.ch_names_original[hf_mask]\n    self.bad_by_hf_noise = hf_noise_channels.tolist()\n    self._extra_info['bad_by_hf_noise'].update({'median_channel_noisiness': noise_median, 'channel_noisiness_sd': noise_sd, 'hf_noise_zscores': noise_zscore})"
        },
        {
          "text": "def find_bad_by_nan_flat(self, flat_threshold=1e-15):\n    \"\"\"Detect channels than contain NaN values or have near-flat signals.\n\n        A channel is considered flat if its standard deviation or its median\n        absolute deviation from the median (MAD) are below the provided flat\n        threshold (default: ``1e-15`` volts).\n\n        This method is run automatically when a ``NoisyChannels`` object is\n        initialized, preventing flat or NaN-containing channels from interfering\n        with the detection of other types of bad channels.\n\n        Parameters\n        ----------\n        flat_threshold : float, optional\n            The lowest standard deviation or MAD value for a channel to be\n            considered bad-by-flat. Defaults to ``1e-15`` volts (corresponds to\n            10e-10 \u00b5V in MATLAB PREP).\n        \"\"\"\n    EEGData = self.raw_mne.get_data()\n    nan_channel_mask = np.isnan(np.sum(EEGData, axis=1))\n    nan_channels = self.ch_names_original[nan_channel_mask]\n    flat_by_mad = median_abs_deviation(EEGData, axis=1) < flat_threshold\n    flat_by_stdev = np.std(EEGData, axis=1) < flat_threshold\n    flat_channel_mask = flat_by_mad | flat_by_stdev\n    flat_channels = self.ch_names_original[flat_channel_mask]\n    self.bad_by_nan = nan_channels.tolist()\n    self.bad_by_flat = flat_channels.tolist()"
        },
        {
          "text": "def __init__(self, raw, params, ransac=True, channel_wise=False, max_chunk_size=None, random_state=None, matlab_strict=False):\n    \"\"\"Initialize the class.\"\"\"\n    raw.load_data()\n    self.raw = raw.copy()\n    self.ch_names = self.raw.ch_names\n    self.raw.pick('eeg', exclude=[])\n    self.bads_manual = raw.info['bads']\n    self.ch_names_eeg = self.raw.ch_names\n    self.EEG = self.raw.get_data()\n    self.reference_channels = params['ref_chs']\n    self.rereferenced_channels = params['reref_chs']\n    self.sfreq = self.raw.info['sfreq']\n    self.ransac_settings = {'ransac': ransac, 'channel_wise': channel_wise, 'max_chunk_size': max_chunk_size}\n    self.random_state = check_random_state(random_state)\n    self._extra_info = {}\n    self.matlab_strict = matlab_strict"
        }
      ]
    }
  },
  {
    "query_id": "pyprep_find_noisy_channels.py__get_filtered_data_doc",
    "prompt": "How can I apply a [1 Hz - 50 Hz] bandpass filter to the EEG signal?",
    "data": {
      "docs": [
        {
          "text": "def _get_filtered_data(self):\n    \"\"\"Apply a [1 Hz - 50 Hz] bandpass filter to the EEG signal.\n\n        Only applied if the sample rate is above 100 Hz to avoid violating the\n        Nyquist theorem.\n\n        \"\"\"\n    if self.sample_rate <= 100:\n        return self.EEGData.copy()\n    bandpass_filter = _filter_design(N_order=100, amp=np.array([1, 1, 0, 0]), freq=np.array([0, 90 / self.sample_rate, 100 / self.sample_rate, 1]))\n    EEG_filt = np.zeros_like(self.EEGData)\n    for i in range(EEG_filt.shape[0]):\n        EEG_filt[i, :] = signal.filtfilt(bandpass_filter, 1, self.EEGData[i, :])\n    return EEG_filt"
        },
        {
          "text": "def _eeglab_create_highpass(cutoff, srate):\n    \"\"\"Create a high-pass FIR filter using Hamming windows.\n\n    Parameters\n    ----------\n    cutoff : float\n        The lower pass-band edge of the filter, in Hz.\n    srate : float\n        The sampling rate of the EEG signal, in Hz.\n\n    Returns\n    -------\n    filter : np.ndarray\n        A 1-dimensional array of FIR filter coefficients.\n\n    Notes\n    -----\n    In MATLAB PREP, the internal ``removeTrend`` function uses EEGLAB's\n    ``pop_eegfiltnew`` to high-pass the EEG data to remove slow drifts.\n    Because MNE's ``mne.filter.filter_data`` and EEGLAB's ``pop_eegfiltnew``\n    calculate filter parameters slightly differently, this function is\n    used to precisely match EEGLAB & MATLAB PREP's filtering method.\n\n    \"\"\"\n    TRANSITION_WIDTH_RATIO = 0.25\n    HAMMING_CONSTANT = 3.3\n    trans_bandwidth = cutoff if cutoff < 2 else cutoff * TRANSITION_WIDTH_RATIO\n    order = HAMMING_CONSTANT / (trans_bandwidth / srate)\n    order = int(np.ceil(order / 2) * 2)\n    stop = cutoff - trans_bandwidth\n    transition = (stop + cutoff) / srate\n    N = order + 1\n    filt = np.zeros(N)\n    filt[N // 2] = 1\n    filt -= firwin(N, transition, window='hamming')\n    return filt"
        },
        {
          "text": "def fit(self):\n    \"\"\"Run the whole PREP pipeline.\"\"\"\n    if len(self.prep_params['line_freqs']) != 0:\n        self.EEG_new = removeTrend(self.EEG_raw, self.sfreq, matlab_strict=self.matlab_strict)\n        linenoise = self.prep_params['line_freqs']\n        if self.filter_kwargs is None:\n            self.EEG_clean = mne.filter.notch_filter(self.EEG_new, Fs=self.sfreq, freqs=linenoise, method='spectrum_fit', mt_bandwidth=2, p_value=0.01, filter_length='10s')\n        else:\n            self.EEG_clean = mne.filter.notch_filter(self.EEG_new, Fs=self.sfreq, freqs=linenoise, **self.filter_kwargs)\n        self.EEG = self.EEG_raw - self.EEG_new + self.EEG_clean\n        self.raw_eeg._data = self.EEG\n    reference = Reference(self.raw_eeg, self.prep_params, random_state=self.random_state, matlab_strict=self.matlab_strict, **self.ransac_settings)\n    reference.perform_reference(self.prep_params['max_iterations'])\n    self.raw_eeg = reference.raw\n    self.noisy_channels_original = reference.noisy_channels_original\n    self.noisy_channels_before_interpolation = reference.noisy_channels_before_interpolation\n    self.noisy_channels_after_interpolation = reference.noisy_channels_after_interpolation\n    self.bad_before_interpolation = reference.bad_before_interpolation\n    self.EEG_before_interpolation = reference.EEG_before_interpolation\n    self.reference_before_interpolation = reference.reference_signal\n    self.reference_after_interpolation = reference.reference_signal_new\n    self.interpolated_channels = reference.interpolated_channels\n    self.still_noisy_channels = reference.still_noisy_channels\n    return self"
        },
        {
          "text": "def _eeglab_fir_filter(data, filt):\n    \"\"\"Apply an FIR filter to a 2-D array of EEG data.\n\n    Parameters\n    ----------\n    data : np.ndarray\n        A 2-D array of EEG data to filter.\n    filt : np.ndarray\n        A 1-D array of FIR filter coefficients.\n\n    Returns\n    -------\n    filtered : np.ndarray\n        A 2-D array of FIR-filtered EEG data.\n\n    Notes\n    -----\n    Produces identical output to EEGLAB's ``firfilt`` function (for non-epoched\n    data). For internal use within :mod:`pyprep.removeTrend`.\n\n    \"\"\"\n    frames_per_window = 2000\n    group_delay = int((len(filt) - 1) / 2)\n    n_samples = data.shape[1]\n    n_windows = int(np.ceil((n_samples - group_delay) / frames_per_window))\n    pad_len = min(group_delay, n_samples)\n    start_pad_idx = np.zeros(pad_len, dtype=np.uint)\n    start_padded = np.concatenate((data[:, start_pad_idx], data[:, :pad_len]), axis=1)\n    zi_init = lfilter_zi(filt, 1) * np.take(start_padded, [0], axis=0)\n    (_, zi) = lfilter(filt, 1, start_padded, axis=1, zi=zi_init)\n    out = np.zeros_like(data)\n    for w in range(n_windows):\n        start = group_delay + w * frames_per_window\n        end = min(start + frames_per_window, n_samples)\n        start_out = start - group_delay\n        end_out = end - group_delay\n        (out[:, start_out:end_out], zi) = lfilter(filt, 1, data[:, start:end], axis=1, zi=zi)\n    end_pad_idx = np.zeros(pad_len, dtype=np.uint) + (n_samples - 1)\n    (end, _) = lfilter(filt, 1, data[:, end_pad_idx], axis=1, zi=zi)\n    out[:, n_samples - pad_len:] = end[:, group_delay - pad_len:]\n    return out"
        },
        {
          "text": "def _filter_design(N_order, amp, freq):\n    \"\"\"Create FIR low-pass filter for EEG data using frequency sampling method.\n\n    Parameters\n    ----------\n    N_order : int\n        Order of the filter.\n    amp : list of int\n        Amplitude vector for the frequencies.\n    freq : list of int\n        Frequency vector for which amplitude can be either 0 or 1.\n\n    Returns\n    -------\n    kernel : np.ndarray\n        Filter kernel.\n\n    \"\"\"\n    nfft = np.maximum(512, 2 ** np.ceil(math.log(100) / math.log(2)))\n    hamming_window = np.subtract(0.54, np.multiply(0.46, np.cos(np.divide(np.multiply(2 * math.pi, np.arange(N_order + 1)), N_order))))\n    pchip_interpolate = scipy.interpolate.PchipInterpolator(np.round(np.multiply(nfft, freq)), amp)\n    freq = pchip_interpolate(np.arange(nfft + 1))\n    freq = np.multiply(freq, np.exp(np.divide(np.multiply(-(0.5 * N_order) * sqrt(-1) * math.pi, np.arange(nfft + 1)), nfft)))\n    kernel = np.real(np.fft.ifft(np.concatenate([freq, np.conj(freq[len(freq) - 2:0:-1])])))\n    kernel = np.multiply(kernel[0:N_order + 1], np.transpose(hamming_window[:]))\n    return kernel"
        }
      ]
    }
  },
  {
    "query_id": "pyprep_find_noisy_channels.py_get_bads_doc",
    "prompt": "How do I get the names of all EEG channels currently flagged as bad?",
    "data": {
      "docs": [
        {
          "text": "def get_bads(self, verbose=False, as_dict=False):\n    \"\"\"Get the names of all channels currently flagged as bad.\n\n        Note that this method does not perform any bad channel detection itself,\n        and only reports channels already detected as bad by other methods.\n\n        Parameters\n        ----------\n        verbose : bool, optional\n            If ``True``, a summary of the channels currently flagged as by bad per\n            category is printed. Defaults to ``False``.\n        as_dict: bool, optional\n            If ``True``, this method will return a dict of the channels currently\n            flagged as bad by each individual bad channel type. If ``False``, this\n            method will return a list of all unique bad channels detected so far.\n            Defaults to ``False``.\n\n        Returns\n        -------\n        bads : list or dict\n            The names of all bad channels detected so far, either as a combined\n            list or a dict indicating the channels flagged bad by each type.\n\n        \"\"\"\n    bads = {'bad_by_nan': self.bad_by_nan, 'bad_by_flat': self.bad_by_flat, 'bad_by_deviation': self.bad_by_deviation, 'bad_by_hf_noise': self.bad_by_hf_noise, 'bad_by_correlation': self.bad_by_correlation, 'bad_by_SNR': self.bad_by_SNR, 'bad_by_dropout': self.bad_by_dropout, 'bad_by_ransac': self.bad_by_ransac, 'bad_by_manual': self.bad_by_manual}\n    all_bads = set()\n    for bad_chs in bads.values():\n        all_bads.update(bad_chs)\n    name_map = {'nan': 'NaN', 'hf_noise': 'HF noise', 'ransac': 'RANSAC'}\n    if verbose:\n        out = f'Found {len(all_bads)} uniquely bad channels:\\n'\n        for (bad_type, bad_chs) in bads.items():\n            bad_type = bad_type.replace('bad_by_', '')\n            if bad_type in name_map.keys():\n                bad_type = name_map[bad_type]\n            out += f'\\n{len(bad_chs)} by {bad_type}: {bad_chs}\\n'\n        logger.info(out)\n    if as_dict:\n        bads['bad_all'] = list(all_bads)\n    else:\n        bads = list(all_bads)\n    return bads"
        },
        {
          "text": "def find_bad_by_ransac(data, sample_rate, complete_chn_labs, chn_pos, exclude, n_samples=50, sample_prop=0.25, corr_thresh=0.75, frac_bad=0.4, corr_window_secs=5.0, channel_wise=False, max_chunk_size=None, random_state=None, matlab_strict=False):\n    \"\"\"Detect channels that are not predicted well by other channels.\n\n    Here, a RANSAC approach (see [1]_, and a short discussion in [2]_) is\n    adopted to predict a \"clean EEG\" dataset. After identifying clean EEG\n    channels through the other methods, the clean EEG dataset is\n    constructed by repeatedly sampling a small subset of clean EEG channels\n    and interpolation the complete data. The median of all those\n    repetitions forms the clean EEG dataset. In a second step, the original\n    and the RANSAC-predicted data are correlated and channels, which do not\n    correlate well with themselves across the two datasets are considered\n    `bad_by_ransac`.\n\n    Parameters\n    ----------\n    data : np.ndarray\n        A 2-D array of detrended EEG data, with bad-by-flat and bad-by-NaN\n        channels removed.\n    sample_rate : float\n        The sample rate (in Hz) of the EEG data.\n    complete_chn_labs : array_like\n        Labels for all channels in `data`, in the same order as they appear\n        in `data`.\n    chn_pos : np.ndarray\n        3-D electrode coordinates for all channels in `data`, in the same order\n        as they appear in `data`.\n    exclude : list\n        Labels of channels to exclude as signal predictors during RANSAC\n        (i.e., channels already flagged as bad by metrics other than HF noise).\n    n_samples : int, optional\n        Number of random channel samples to use for RANSAC. Defaults to ``50``.\n    sample_prop : float, optional\n        Proportion of total channels to use for signal prediction per RANSAC\n        sample. This needs to be in the range [0, 1], where 0 would mean no\n        channels would be used and 1 would mean all channels would be used\n        (neither of which would be useful values). Defaults to ``0.25`` (e.g.,\n        16 channels per sample for a 64-channel dataset).\n    corr_thresh : float, optional\n        The minimum predicted vs. actual signal correlation for a channel to\n        be considered good within a given RANSAC window. Defaults to ``0.75``.\n    frac_bad : float, optional\n        The minimum fraction of bad (i.e., below-threshold) RANSAC windows for a\n        channel to be considered bad-by-RANSAC. Defaults to ``0.4``.\n    corr_window_secs : float, optional\n        The duration (in seconds) of each RANSAC correlation window. Defaults to\n        5 seconds.\n    channel_wise : bool, optional\n        Whether RANSAC should predict signals for chunks of channels over the\n        entire signal length (\"channel-wise RANSAC\", see `max_chunk_size`\n        parameter). If ``False``, RANSAC will instead predict signals for all\n        channels at once but over a number of smaller time windows instead of\n        over the entire signal length (\"window-wise RANSAC\"). Channel-wise\n        RANSAC generally has higher RAM demands than window-wise RANSAC\n        (especially if `max_chunk_size` is ``None``), but can be faster on\n        systems with lots of RAM to spare. Defaults to ``False``.\n    max_chunk_size : {int, None}, optional\n        The maximum number of channels to predict at once during channel-wise\n        RANSAC. If ``None``, RANSAC will use the largest chunk size that will\n        fit into the available RAM, which may slow down other programs on the\n        host system. If using window-wise RANSAC (the default), this parameter\n        has no effect. Defaults to ``None``.\n    random_state : {int, None, np.random.RandomState}, optional\n        The random seed with which to generate random samples of channels during\n        RANSAC. If random_state is an int, it will be used as a seed for RandomState.\n        If ``None``, the seed will be obtained from the operating system\n        (see RandomState for details). Defaults to ``None``.\n    matlab_strict : bool, optional\n        Whether or not RANSAC should strictly follow MATLAB PREP's internal\n        math, ignoring any improvements made in PyPREP over the original code\n        (see :ref:`matlab-diffs` for more details). Defaults to ``False``.\n\n    Returns\n    -------\n    bad_by_ransac : list\n        List containing the labels of all channels flagged as bad by RANSAC.\n    channel_correlations : np.ndarray\n        Array of shape (windows, channels) containing the correlations of\n        the channels with their predicted RANSAC values for each window.\n\n    References\n    ----------\n    .. [1] Fischler, M.A., Bolles, R.C. (1981). Random sample consensus: A\n        Paradigm for Model Fitting with Applications to Image Analysis and\n        Automated Cartography. Communications of the ACM, 24, 381-395\n    .. [2] Jas, M., Engemann, D.A., Bekhti, Y., Raimondo, F., Gramfort, A.\n        (2017). Autoreject: Automated Artifact Rejection for MEG and EEG\n        Data. NeuroImage, 159, 417-429\n\n    \"\"\"\n    if np.isnan(chn_pos).any():\n        raise ValueError('Found NaN in channel positions. Did you supply a montage for the raw data?')\n    if not isinstance(n_samples, int):\n        raise TypeError(f\"Argument 'n_samples' must be an int (got {type(n_samples).__name__})\")\n    complete_chn_labs = np.asarray(complete_chn_labs)\n    good_idx = np.array([idx for (idx, ch) in enumerate(complete_chn_labs) if ch not in exclude])\n    n_chans_good = good_idx.shape[0]\n    chn_pos_good = chn_pos[good_idx, :]\n    n_chans = data.shape[0]\n    n_pred_chns = int(np.around(sample_prop * n_chans))\n    if n_pred_chns <= 3:\n        sample_pct = int(sample_prop * 100)\n        raise OSError(f'Too few channels in the original data to reliably perform RANSAC(minimum {int(np.floor(4.0 / sample_prop))} for a sample size of {sample_pct}%).')\n    elif n_chans_good < n_pred_chns + 1:\n        raise OSError(f'Too many noisy channels in the data to reliably perform RANSAC (only {n_chans_good} good channels remaining, need at least {n_pred_chns + 1}).')\n    if channel_wise:\n        _verify_free_ram(data, n_samples, 1)\n    else:\n        window_size = int(sample_rate * corr_window_secs)\n        _verify_free_ram(data[:, :window_size], n_samples, n_chans_good)\n    random_ch_picks = []\n    good_chans = np.arange(chn_pos_good.shape[0])\n    rng = check_random_state(random_state)\n    for i in range(n_samples):\n        picks = _get_random_subset(good_chans, n_pred_chns, rng)\n        random_ch_picks.append(picks)\n    interp_mats = _make_interpolation_matrices(random_ch_picks, chn_pos_good)\n    correlation_frames = corr_window_secs * sample_rate\n    signal_frames = data.shape[1]\n    correlation_offsets = np.arange(0, signal_frames - correlation_frames, correlation_frames)\n    win_size = int(correlation_frames)\n    win_count = correlation_offsets.shape[0]\n    n_chans_complete = len(complete_chn_labs)\n    channel_correlations = np.ones((win_count, n_chans_complete))\n    logger.info('Executing RANSAC\\nThis may take a while, so be patient...')\n    if not channel_wise:\n        channel_correlations[:, good_idx] = _ransac_by_window(data[good_idx, :], interp_mats, win_size, win_count, matlab_strict)\n    chunk_sizes = []\n    chunk_count = 0\n    for i in range(1, n_chans_good + 1):\n        n_chunks = int(np.ceil(n_chans_good / i))\n        if n_chunks != chunk_count:\n            chunk_count = n_chunks\n            if not max_chunk_size or i <= max_chunk_size:\n                chunk_sizes.append(i)\n    chunk_size = chunk_sizes.pop()\n    mem_error = True\n    job = list(range(n_chans_good))\n    while mem_error and channel_wise:\n        try:\n            channel_chunks = _split_list(job, chunk_size)\n            total_chunks = len(channel_chunks)\n            current = 1\n            for chunk in channel_chunks:\n                interp_mats_for_chunk = [mat[chunk, :] for mat in interp_mats]\n                channel_correlations[:, good_idx[chunk]] = _ransac_by_channel(data[good_idx, :], interp_mats_for_chunk, win_size, win_count, chunk, random_ch_picks, matlab_strict)\n                if chunk == channel_chunks[0]:\n                    logger.info('Finding optimal chunk size : %s', chunk_size)\n                    logger.info('Total # of chunks: %s', total_chunks)\n                    logger.info('Current chunk:')\n                logger.info(current)\n                current = current + 1\n            mem_error = False\n            del current\n        except MemoryError:\n            if len(chunk_sizes):\n                chunk_size = chunk_sizes.pop()\n            else:\n                raise MemoryError('Not even doing 1 channel at a time the data fits in ram...You could downsample the data or reduce the number of requested samples.')\n    thresholded_correlations = channel_correlations < corr_thresh\n    frac_bad_corr_windows = np.mean(thresholded_correlations, axis=0)\n    bad_ransac_channels_idx = np.argwhere(frac_bad_corr_windows > frac_bad)\n    bad_ransac_channels_name = complete_chn_labs[bad_ransac_channels_idx.astype(int)]\n    bad_by_ransac = [i[0] for i in bad_ransac_channels_name]\n    logger.info('\\nRANSAC done!')\n    return (bad_by_ransac, channel_correlations)"
        },
        {
          "text": "@property\ndef raw(self):\n    \"\"\"Return a version of self.raw_eeg that includes the non-eeg channels.\"\"\"\n    full_raw = self.raw_eeg.copy()\n    if self.raw_non_eeg is None:\n        return full_raw\n    else:\n        return full_raw.add_channels([self.raw_non_eeg], force_update_info=True)"
        },
        {
          "text": "def find_bad_by_nan_flat(self, flat_threshold=1e-15):\n    \"\"\"Detect channels than contain NaN values or have near-flat signals.\n\n        A channel is considered flat if its standard deviation or its median\n        absolute deviation from the median (MAD) are below the provided flat\n        threshold (default: ``1e-15`` volts).\n\n        This method is run automatically when a ``NoisyChannels`` object is\n        initialized, preventing flat or NaN-containing channels from interfering\n        with the detection of other types of bad channels.\n\n        Parameters\n        ----------\n        flat_threshold : float, optional\n            The lowest standard deviation or MAD value for a channel to be\n            considered bad-by-flat. Defaults to ``1e-15`` volts (corresponds to\n            10e-10 \u00b5V in MATLAB PREP).\n        \"\"\"\n    EEGData = self.raw_mne.get_data()\n    nan_channel_mask = np.isnan(np.sum(EEGData, axis=1))\n    nan_channels = self.ch_names_original[nan_channel_mask]\n    flat_by_mad = median_abs_deviation(EEGData, axis=1) < flat_threshold\n    flat_by_stdev = np.std(EEGData, axis=1) < flat_threshold\n    flat_channel_mask = flat_by_mad | flat_by_stdev\n    flat_channels = self.ch_names_original[flat_channel_mask]\n    self.bad_by_nan = nan_channels.tolist()\n    self.bad_by_flat = flat_channels.tolist()"
        },
        {
          "text": "def find_bad_by_deviation(self, deviation_threshold=5.0):\n    \"\"\"Detect channels with abnormally high or low overall amplitudes.\n\n        A channel is considered \"bad-by-deviation\" if its amplitude deviates\n        considerably from the median channel amplitude, as calculated using a\n        robust Z-scoring method and the given deviation threshold.\n\n        Amplitude Z-scores are calculated using the formula\n        ``(channel_amplitude - median_amplitude) / amplitude_sd``, where\n        channel amplitudes are calculated using a robust outlier-resistant estimate\n        of the signals' standard deviations (IQR scaled to units of SD), and the\n        amplitude SD is the IQR-based SD of those amplitudes.\n\n        Parameters\n        ----------\n        deviation_threshold : float, optional\n            The minimum absolute z-score of a channel for it to be considered\n            bad-by-deviation. Defaults to ``5.0``.\n\n        \"\"\"\n    IQR_TO_SD = 0.7413\n    chan_amplitudes = _mat_iqr(self.EEGData, axis=1) * IQR_TO_SD\n    amp_sd = _mat_iqr(chan_amplitudes) * IQR_TO_SD\n    amp_median = np.nanmedian(chan_amplitudes)\n    amplitude_zscore = np.zeros(self.n_chans_original)\n    amplitude_zscore[self.usable_idx] = (chan_amplitudes - amp_median) / amp_sd\n    abnormal_amplitude = np.abs(amplitude_zscore) > deviation_threshold\n    deviation_channel_mask = np.isnan(amplitude_zscore) | abnormal_amplitude\n    deviation_channels = self.ch_names_original[deviation_channel_mask]\n    self.bad_by_deviation = deviation_channels.tolist()\n    self._extra_info['bad_by_deviation'].update({'median_channel_amplitude': amp_median, 'channel_amplitude_sd': amp_sd, 'robust_channel_deviations': amplitude_zscore})"
        }
      ]
    }
  },
  {
    "query_id": "pyprep_find_noisy_channels.py_find_all_bads_doc",
    "prompt": "How can I run all the bad channel detection functions, including optional RANSAC?",
    "data": {
      "docs": [
        {
          "text": "def find_all_bads(self, ransac=True, channel_wise=False, max_chunk_size=None):\n    \"\"\"Call all the functions to detect bad channels.\n\n        This function calls all the bad-channel detecting functions.\n\n        Parameters\n        ----------\n        ransac : bool, optional\n            Whether RANSAC should be used for bad channel detection, in addition\n            to the other methods. RANSAC can detect bad channels that other\n            methods are unable to catch, but also slows down noisy channel\n            detection considerably. Defaults to ``True``.\n        channel_wise : bool, optional\n            Whether RANSAC should predict signals for chunks of channels over the\n            entire signal length (\"channel-wise RANSAC\", see `max_chunk_size`\n            parameter). If ``False``, RANSAC will instead predict signals for all\n            channels at once but over a number of smaller time windows instead of\n            over the entire signal length (\"window-wise RANSAC\"). Channel-wise\n            RANSAC generally has higher RAM demands than window-wise RANSAC\n            (especially if `max_chunk_size` is ``None``), but can be faster on\n            systems with lots of RAM to spare. Has no effect if not using RANSAC.\n            Defaults to ``False``.\n        max_chunk_size : {int, None}, optional\n            The maximum number of channels to predict at once during\n            channel-wise RANSAC. If ``None``, RANSAC will use the largest chunk\n            size that will fit into the available RAM, which may slow down\n            other programs on the host system. If using window-wise RANSAC\n            (the default) or not using RANSAC at all, this parameter has no\n            effect. Defaults to ``None``.\n\n        \"\"\"\n    self.find_bad_by_deviation()\n    self.find_bad_by_hfnoise()\n    self.find_bad_by_correlation()\n    self.find_bad_by_SNR()\n    if ransac:\n        self.find_bad_by_ransac(channel_wise=channel_wise, max_chunk_size=max_chunk_size)"
        },
        {
          "text": "def find_bad_by_ransac(self, n_samples=50, sample_prop=0.25, corr_thresh=0.75, frac_bad=0.4, corr_window_secs=5.0, channel_wise=False, max_chunk_size=None):\n    \"\"\"Detect channels that are predicted poorly by other channels.\n\n        This method uses a random sample consensus approach (RANSAC, see [1]_,\n        and a short discussion in [2]_) to try and predict what the signal should\n        be for each channel based on the signals and spatial locations of other\n        currently-good channels. RANSAC correlations are calculated by splitting\n        the recording into non-overlapping windows of time (default: 5 seconds)\n        and correlating each channel's RANSAC-predicted signal with its actual\n        signal within each window.\n\n        A RANSAC window is considered \"bad\" for a channel if its predicted signal\n        vs. actual signal correlation falls below the given correlation threshold\n        (default: ``0.75``). A channel is considered \"bad-by-RANSAC\" if its fraction\n        of bad RANSAC windows is above the given threshold (default: ``0.4``).\n\n        Due to its random sampling component, the channels identified as\n        \"bad-by-RANSAC\" may vary slightly between calls of this method.\n        Additionally, bad channels may vary between different montages given that\n        RANSAC's signal predictions are based on the spatial coordinates of each\n        electrode.\n\n        This method is a wrapper for the :func:`~ransac.find_bad_by_ransac`\n        function.\n\n        .. warning:: For optimal performance, RANSAC requires that channels bad by\n                     deviation, correlation, and/or dropout have already been\n                     flagged. Otherwise RANSAC will attempt to use those channels\n                     when making signal predictions, decreasing accuracy and thus\n                     increasing the likelihood of false positives.\n\n        Parameters\n        ----------\n        n_samples : int, optional\n            Number of random channel samples to use for RANSAC. Defaults\n            to ``50``.\n        sample_prop : float, optional\n            Proportion of total channels to use for signal prediction per RANSAC\n            sample. This needs to be in the range [0, 1], where 0 would mean no\n            channels would be used and 1 would mean all channels would be used\n            (neither of which would be useful values). Defaults to ``0.25``\n            (e.g., 16 channels per sample for a 64-channel dataset).\n        corr_thresh : float, optional\n            The minimum predicted vs. actual signal correlation for a channel to\n            be considered good within a given RANSAC window. Defaults\n            to ``0.75``.\n        frac_bad : float, optional\n            The minimum fraction of bad (i.e., below-threshold) RANSAC windows\n            for a channel to be considered bad-by-RANSAC. Defaults to ``0.4``.\n        corr_window_secs : float, optional\n            The duration (in seconds) of each RANSAC correlation window. Defaults\n            to 5 seconds.\n        channel_wise : bool, optional\n            Whether RANSAC should predict signals for chunks of channels over the\n            entire signal length (\"channel-wise RANSAC\", see `max_chunk_size`\n            parameter). If ``False``, RANSAC will instead predict signals for all\n            channels at once but over a number of smaller time windows instead of\n            over the entire signal length (\"window-wise RANSAC\"). Channel-wise\n            RANSAC generally has higher RAM demands than window-wise RANSAC\n            (especially if `max_chunk_size` is ``None``), but can be faster on\n            systems with lots of RAM to spare. Defaults to ``False``.\n        max_chunk_size : {int, None}, optional\n            The maximum number of channels to predict at once during\n            channel-wise RANSAC. If ``None``, RANSAC will use the largest chunk\n            size that will fit into the available RAM, which may slow down\n            other programs on the host system. If using window-wise RANSAC\n            (the default), this parameter has no effect. Defaults to ``None``.\n\n        References\n        ----------\n        .. [1] Fischler, M.A., Bolles, R.C. (1981). Random sample consensus: A\n            Paradigm for Model Fitting with Applications to Image Analysis and\n            Automated Cartography. Communications of the ACM, 24, 381-395\n        .. [2] Jas, M., Engemann, D.A., Bekhti, Y., Raimondo, F., Gramfort, A.\n            (2017). Autoreject: Automated Artifact Rejection for MEG and EEG\n            Data. NeuroImage, 159, 417-429\n\n        \"\"\"\n    if self.EEGFiltered is None:\n        self.EEGFiltered = self._get_filtered_data()\n    exclude_from_ransac = self.bad_by_correlation + self.bad_by_deviation + self.bad_by_dropout\n    if self.matlab_strict:\n        random_state = self.random_state.get_state()\n        rng = np.random.RandomState()\n        rng.set_state(random_state)\n    else:\n        rng = self.random_state\n    (self.bad_by_ransac, ch_correlations_usable) = find_bad_by_ransac(self.EEGFiltered, self.sample_rate, self.ch_names_new, self.raw_mne._get_channel_positions()[self.usable_idx, :], exclude_from_ransac, n_samples, sample_prop, corr_thresh, frac_bad, corr_window_secs, channel_wise, max_chunk_size, rng, self.matlab_strict)\n    n_ransac_windows = ch_correlations_usable.shape[0]\n    ch_correlations = np.ones((n_ransac_windows, self.n_chans_original))\n    ch_correlations[:, self.usable_idx] = ch_correlations_usable\n    self._extra_info['bad_by_ransac'] = {'ransac_correlations': ch_correlations, 'bad_window_fractions': np.mean(ch_correlations < corr_thresh, axis=0)}"
        },
        {
          "text": "def find_bad_by_ransac(data, sample_rate, complete_chn_labs, chn_pos, exclude, n_samples=50, sample_prop=0.25, corr_thresh=0.75, frac_bad=0.4, corr_window_secs=5.0, channel_wise=False, max_chunk_size=None, random_state=None, matlab_strict=False):\n    \"\"\"Detect channels that are not predicted well by other channels.\n\n    Here, a RANSAC approach (see [1]_, and a short discussion in [2]_) is\n    adopted to predict a \"clean EEG\" dataset. After identifying clean EEG\n    channels through the other methods, the clean EEG dataset is\n    constructed by repeatedly sampling a small subset of clean EEG channels\n    and interpolation the complete data. The median of all those\n    repetitions forms the clean EEG dataset. In a second step, the original\n    and the RANSAC-predicted data are correlated and channels, which do not\n    correlate well with themselves across the two datasets are considered\n    `bad_by_ransac`.\n\n    Parameters\n    ----------\n    data : np.ndarray\n        A 2-D array of detrended EEG data, with bad-by-flat and bad-by-NaN\n        channels removed.\n    sample_rate : float\n        The sample rate (in Hz) of the EEG data.\n    complete_chn_labs : array_like\n        Labels for all channels in `data`, in the same order as they appear\n        in `data`.\n    chn_pos : np.ndarray\n        3-D electrode coordinates for all channels in `data`, in the same order\n        as they appear in `data`.\n    exclude : list\n        Labels of channels to exclude as signal predictors during RANSAC\n        (i.e., channels already flagged as bad by metrics other than HF noise).\n    n_samples : int, optional\n        Number of random channel samples to use for RANSAC. Defaults to ``50``.\n    sample_prop : float, optional\n        Proportion of total channels to use for signal prediction per RANSAC\n        sample. This needs to be in the range [0, 1], where 0 would mean no\n        channels would be used and 1 would mean all channels would be used\n        (neither of which would be useful values). Defaults to ``0.25`` (e.g.,\n        16 channels per sample for a 64-channel dataset).\n    corr_thresh : float, optional\n        The minimum predicted vs. actual signal correlation for a channel to\n        be considered good within a given RANSAC window. Defaults to ``0.75``.\n    frac_bad : float, optional\n        The minimum fraction of bad (i.e., below-threshold) RANSAC windows for a\n        channel to be considered bad-by-RANSAC. Defaults to ``0.4``.\n    corr_window_secs : float, optional\n        The duration (in seconds) of each RANSAC correlation window. Defaults to\n        5 seconds.\n    channel_wise : bool, optional\n        Whether RANSAC should predict signals for chunks of channels over the\n        entire signal length (\"channel-wise RANSAC\", see `max_chunk_size`\n        parameter). If ``False``, RANSAC will instead predict signals for all\n        channels at once but over a number of smaller time windows instead of\n        over the entire signal length (\"window-wise RANSAC\"). Channel-wise\n        RANSAC generally has higher RAM demands than window-wise RANSAC\n        (especially if `max_chunk_size` is ``None``), but can be faster on\n        systems with lots of RAM to spare. Defaults to ``False``.\n    max_chunk_size : {int, None}, optional\n        The maximum number of channels to predict at once during channel-wise\n        RANSAC. If ``None``, RANSAC will use the largest chunk size that will\n        fit into the available RAM, which may slow down other programs on the\n        host system. If using window-wise RANSAC (the default), this parameter\n        has no effect. Defaults to ``None``.\n    random_state : {int, None, np.random.RandomState}, optional\n        The random seed with which to generate random samples of channels during\n        RANSAC. If random_state is an int, it will be used as a seed for RandomState.\n        If ``None``, the seed will be obtained from the operating system\n        (see RandomState for details). Defaults to ``None``.\n    matlab_strict : bool, optional\n        Whether or not RANSAC should strictly follow MATLAB PREP's internal\n        math, ignoring any improvements made in PyPREP over the original code\n        (see :ref:`matlab-diffs` for more details). Defaults to ``False``.\n\n    Returns\n    -------\n    bad_by_ransac : list\n        List containing the labels of all channels flagged as bad by RANSAC.\n    channel_correlations : np.ndarray\n        Array of shape (windows, channels) containing the correlations of\n        the channels with their predicted RANSAC values for each window.\n\n    References\n    ----------\n    .. [1] Fischler, M.A., Bolles, R.C. (1981). Random sample consensus: A\n        Paradigm for Model Fitting with Applications to Image Analysis and\n        Automated Cartography. Communications of the ACM, 24, 381-395\n    .. [2] Jas, M., Engemann, D.A., Bekhti, Y., Raimondo, F., Gramfort, A.\n        (2017). Autoreject: Automated Artifact Rejection for MEG and EEG\n        Data. NeuroImage, 159, 417-429\n\n    \"\"\"\n    if np.isnan(chn_pos).any():\n        raise ValueError('Found NaN in channel positions. Did you supply a montage for the raw data?')\n    if not isinstance(n_samples, int):\n        raise TypeError(f\"Argument 'n_samples' must be an int (got {type(n_samples).__name__})\")\n    complete_chn_labs = np.asarray(complete_chn_labs)\n    good_idx = np.array([idx for (idx, ch) in enumerate(complete_chn_labs) if ch not in exclude])\n    n_chans_good = good_idx.shape[0]\n    chn_pos_good = chn_pos[good_idx, :]\n    n_chans = data.shape[0]\n    n_pred_chns = int(np.around(sample_prop * n_chans))\n    if n_pred_chns <= 3:\n        sample_pct = int(sample_prop * 100)\n        raise OSError(f'Too few channels in the original data to reliably perform RANSAC(minimum {int(np.floor(4.0 / sample_prop))} for a sample size of {sample_pct}%).')\n    elif n_chans_good < n_pred_chns + 1:\n        raise OSError(f'Too many noisy channels in the data to reliably perform RANSAC (only {n_chans_good} good channels remaining, need at least {n_pred_chns + 1}).')\n    if channel_wise:\n        _verify_free_ram(data, n_samples, 1)\n    else:\n        window_size = int(sample_rate * corr_window_secs)\n        _verify_free_ram(data[:, :window_size], n_samples, n_chans_good)\n    random_ch_picks = []\n    good_chans = np.arange(chn_pos_good.shape[0])\n    rng = check_random_state(random_state)\n    for i in range(n_samples):\n        picks = _get_random_subset(good_chans, n_pred_chns, rng)\n        random_ch_picks.append(picks)\n    interp_mats = _make_interpolation_matrices(random_ch_picks, chn_pos_good)\n    correlation_frames = corr_window_secs * sample_rate\n    signal_frames = data.shape[1]\n    correlation_offsets = np.arange(0, signal_frames - correlation_frames, correlation_frames)\n    win_size = int(correlation_frames)\n    win_count = correlation_offsets.shape[0]\n    n_chans_complete = len(complete_chn_labs)\n    channel_correlations = np.ones((win_count, n_chans_complete))\n    logger.info('Executing RANSAC\\nThis may take a while, so be patient...')\n    if not channel_wise:\n        channel_correlations[:, good_idx] = _ransac_by_window(data[good_idx, :], interp_mats, win_size, win_count, matlab_strict)\n    chunk_sizes = []\n    chunk_count = 0\n    for i in range(1, n_chans_good + 1):\n        n_chunks = int(np.ceil(n_chans_good / i))\n        if n_chunks != chunk_count:\n            chunk_count = n_chunks\n            if not max_chunk_size or i <= max_chunk_size:\n                chunk_sizes.append(i)\n    chunk_size = chunk_sizes.pop()\n    mem_error = True\n    job = list(range(n_chans_good))\n    while mem_error and channel_wise:\n        try:\n            channel_chunks = _split_list(job, chunk_size)\n            total_chunks = len(channel_chunks)\n            current = 1\n            for chunk in channel_chunks:\n                interp_mats_for_chunk = [mat[chunk, :] for mat in interp_mats]\n                channel_correlations[:, good_idx[chunk]] = _ransac_by_channel(data[good_idx, :], interp_mats_for_chunk, win_size, win_count, chunk, random_ch_picks, matlab_strict)\n                if chunk == channel_chunks[0]:\n                    logger.info('Finding optimal chunk size : %s', chunk_size)\n                    logger.info('Total # of chunks: %s', total_chunks)\n                    logger.info('Current chunk:')\n                logger.info(current)\n                current = current + 1\n            mem_error = False\n            del current\n        except MemoryError:\n            if len(chunk_sizes):\n                chunk_size = chunk_sizes.pop()\n            else:\n                raise MemoryError('Not even doing 1 channel at a time the data fits in ram...You could downsample the data or reduce the number of requested samples.')\n    thresholded_correlations = channel_correlations < corr_thresh\n    frac_bad_corr_windows = np.mean(thresholded_correlations, axis=0)\n    bad_ransac_channels_idx = np.argwhere(frac_bad_corr_windows > frac_bad)\n    bad_ransac_channels_name = complete_chn_labs[bad_ransac_channels_idx.astype(int)]\n    bad_by_ransac = [i[0] for i in bad_ransac_channels_name]\n    logger.info('\\nRANSAC done!')\n    return (bad_by_ransac, channel_correlations)"
        },
        {
          "text": "def _ransac_by_channel(data, interpolation_mats, win_size, win_count, chans_to_predict, random_ch_picks, matlab_strict):\n    \"\"\"Calculate correlations of channels with their RANSAC-predicted values.\n\n    This function calculates RANSAC correlations on one (or more) full channels\n    at once, requiring RAM equivalent to [channels per chunk * sample rate *\n    length of recording in seconds] to run. Generally, this method will use\n    more RAM than :func:`_ransac_by_window`, but may be faster for systems with\n    large amounts of RAM.\n\n    Parameters\n    ----------\n    data : np.ndarray\n        A 2-D array containing the EEG signals from all currently-good channels.\n    interpolation_mats : list of np.ndarray\n        A set of channel interpolation matrices, one for each RANSAC sample of\n        channels.\n    win_size : int\n        Number of frames/samples of EEG data in each RANSAC correlation window.\n    win_count: int\n        Number of RANSAC correlation windows.\n    chans_to_predict : list of int\n        Indices of the channels to predict (as they appear in `data`) within the\n        current chunk.\n    random_ch_picks : list of list of int\n        A list containing multiple random subsets of currently-good channels.\n    matlab_strict : bool\n        Whether or not RANSAC should strictly follow MATLAB PREP's internal\n        math, ignoring any improvements made in PyPREP over the original code.\n\n    Returns\n    -------\n    correlations : np.ndarray\n        Correlations of the given channels to their predicted values within each\n        RANSAC window.\n\n    \"\"\"\n    chunk_size = len(chans_to_predict)\n    correlations = np.ones((win_count, chunk_size))\n    predicted_chans = _predict_median_signals_channelwise(data=data, interpolation_mats=interpolation_mats, random_ch_picks=random_ch_picks, chunk_size=len(chans_to_predict), matlab_strict=matlab_strict)\n    data_window = data[chans_to_predict, :win_size * win_count]\n    data_window = data_window.reshape(chunk_size, win_count, win_size)\n    data_window = data_window.swapaxes(1, 0)\n    pred_window = predicted_chans[:chunk_size, :win_size * win_count]\n    pred_window = pred_window.reshape(chunk_size, win_count, win_size)\n    pred_window = pred_window.swapaxes(1, 0)\n    for k in range(win_count):\n        data_portion = data_window[k, :, :]\n        pred_portion = pred_window[k, :, :]\n        R = _correlate_arrays(data_portion, pred_portion, matlab_strict)\n        correlations[k, :] = R\n    return correlations"
        },
        {
          "text": "def _ransac_by_window(data, interpolation_mats, win_size, win_count, matlab_strict):\n    \"\"\"Calculate correlations of channels with their RANSAC-predicted values.\n\n    This function calculates RANSAC correlations for each RANSAC window\n    individually, requiring RAM equivalent to [channels * sample rate * seconds\n    per RANSAC window] to run. Generally, this method will use less RAM than\n    :func:`_ransac_by_channel`, with the exception of short recordings with high\n    electrode counts.\n\n    Parameters\n    ----------\n    data : np.ndarray\n        A 2-D array containing the EEG signals from all currently-good channels.\n    interpolation_mats : list of np.ndarray\n        A list of interpolation matrices, one for each RANSAC sample of channels.\n    win_size : int\n        Number of frames/samples of EEG data in each RANSAC correlation window.\n    win_count: int\n        Number of RANSAC correlation windows.\n    matlab_strict : bool\n        Whether or not RANSAC should strictly follow MATLAB PREP's internal\n        math, ignoring any improvements made in PyPREP over the original code.\n\n    Returns\n    -------\n    correlations : np.ndarray\n        Correlations of the given channels to their predicted values within each\n        RANSAC window.\n\n    \"\"\"\n    ch_count = data.shape[0]\n    correlations = np.ones((win_count, ch_count))\n    pb = ProgressBar(range(win_count))\n    for window in pb:\n        start = window * win_size\n        end = (window + 1) * win_size\n        actual = data[:, start:end]\n        predicted = _predict_median_signals(actual, interpolation_mats, matlab_strict)\n        correlations[window, :] = _correlate_arrays(actual, predicted, matlab_strict)\n    return correlations"
        }
      ]
    }
  },
  {
    "query_id": "pyprep_find_noisy_channels.py_find_bad_by_nan_flat_doc",
    "prompt": "How do I detect EEG channels that contain NaN values or have flat signals?",
    "data": {
      "docs": [
        {
          "text": "def find_bad_by_nan_flat(self, flat_threshold=1e-15):\n    \"\"\"Detect channels than contain NaN values or have near-flat signals.\n\n        A channel is considered flat if its standard deviation or its median\n        absolute deviation from the median (MAD) are below the provided flat\n        threshold (default: ``1e-15`` volts).\n\n        This method is run automatically when a ``NoisyChannels`` object is\n        initialized, preventing flat or NaN-containing channels from interfering\n        with the detection of other types of bad channels.\n\n        Parameters\n        ----------\n        flat_threshold : float, optional\n            The lowest standard deviation or MAD value for a channel to be\n            considered bad-by-flat. Defaults to ``1e-15`` volts (corresponds to\n            10e-10 \u00b5V in MATLAB PREP).\n        \"\"\"\n    EEGData = self.raw_mne.get_data()\n    nan_channel_mask = np.isnan(np.sum(EEGData, axis=1))\n    nan_channels = self.ch_names_original[nan_channel_mask]\n    flat_by_mad = median_abs_deviation(EEGData, axis=1) < flat_threshold\n    flat_by_stdev = np.std(EEGData, axis=1) < flat_threshold\n    flat_channel_mask = flat_by_mad | flat_by_stdev\n    flat_channels = self.ch_names_original[flat_channel_mask]\n    self.bad_by_nan = nan_channels.tolist()\n    self.bad_by_flat = flat_channels.tolist()"
        },
        {
          "text": "def find_bad_by_ransac(data, sample_rate, complete_chn_labs, chn_pos, exclude, n_samples=50, sample_prop=0.25, corr_thresh=0.75, frac_bad=0.4, corr_window_secs=5.0, channel_wise=False, max_chunk_size=None, random_state=None, matlab_strict=False):\n    \"\"\"Detect channels that are not predicted well by other channels.\n\n    Here, a RANSAC approach (see [1]_, and a short discussion in [2]_) is\n    adopted to predict a \"clean EEG\" dataset. After identifying clean EEG\n    channels through the other methods, the clean EEG dataset is\n    constructed by repeatedly sampling a small subset of clean EEG channels\n    and interpolation the complete data. The median of all those\n    repetitions forms the clean EEG dataset. In a second step, the original\n    and the RANSAC-predicted data are correlated and channels, which do not\n    correlate well with themselves across the two datasets are considered\n    `bad_by_ransac`.\n\n    Parameters\n    ----------\n    data : np.ndarray\n        A 2-D array of detrended EEG data, with bad-by-flat and bad-by-NaN\n        channels removed.\n    sample_rate : float\n        The sample rate (in Hz) of the EEG data.\n    complete_chn_labs : array_like\n        Labels for all channels in `data`, in the same order as they appear\n        in `data`.\n    chn_pos : np.ndarray\n        3-D electrode coordinates for all channels in `data`, in the same order\n        as they appear in `data`.\n    exclude : list\n        Labels of channels to exclude as signal predictors during RANSAC\n        (i.e., channels already flagged as bad by metrics other than HF noise).\n    n_samples : int, optional\n        Number of random channel samples to use for RANSAC. Defaults to ``50``.\n    sample_prop : float, optional\n        Proportion of total channels to use for signal prediction per RANSAC\n        sample. This needs to be in the range [0, 1], where 0 would mean no\n        channels would be used and 1 would mean all channels would be used\n        (neither of which would be useful values). Defaults to ``0.25`` (e.g.,\n        16 channels per sample for a 64-channel dataset).\n    corr_thresh : float, optional\n        The minimum predicted vs. actual signal correlation for a channel to\n        be considered good within a given RANSAC window. Defaults to ``0.75``.\n    frac_bad : float, optional\n        The minimum fraction of bad (i.e., below-threshold) RANSAC windows for a\n        channel to be considered bad-by-RANSAC. Defaults to ``0.4``.\n    corr_window_secs : float, optional\n        The duration (in seconds) of each RANSAC correlation window. Defaults to\n        5 seconds.\n    channel_wise : bool, optional\n        Whether RANSAC should predict signals for chunks of channels over the\n        entire signal length (\"channel-wise RANSAC\", see `max_chunk_size`\n        parameter). If ``False``, RANSAC will instead predict signals for all\n        channels at once but over a number of smaller time windows instead of\n        over the entire signal length (\"window-wise RANSAC\"). Channel-wise\n        RANSAC generally has higher RAM demands than window-wise RANSAC\n        (especially if `max_chunk_size` is ``None``), but can be faster on\n        systems with lots of RAM to spare. Defaults to ``False``.\n    max_chunk_size : {int, None}, optional\n        The maximum number of channels to predict at once during channel-wise\n        RANSAC. If ``None``, RANSAC will use the largest chunk size that will\n        fit into the available RAM, which may slow down other programs on the\n        host system. If using window-wise RANSAC (the default), this parameter\n        has no effect. Defaults to ``None``.\n    random_state : {int, None, np.random.RandomState}, optional\n        The random seed with which to generate random samples of channels during\n        RANSAC. If random_state is an int, it will be used as a seed for RandomState.\n        If ``None``, the seed will be obtained from the operating system\n        (see RandomState for details). Defaults to ``None``.\n    matlab_strict : bool, optional\n        Whether or not RANSAC should strictly follow MATLAB PREP's internal\n        math, ignoring any improvements made in PyPREP over the original code\n        (see :ref:`matlab-diffs` for more details). Defaults to ``False``.\n\n    Returns\n    -------\n    bad_by_ransac : list\n        List containing the labels of all channels flagged as bad by RANSAC.\n    channel_correlations : np.ndarray\n        Array of shape (windows, channels) containing the correlations of\n        the channels with their predicted RANSAC values for each window.\n\n    References\n    ----------\n    .. [1] Fischler, M.A., Bolles, R.C. (1981). Random sample consensus: A\n        Paradigm for Model Fitting with Applications to Image Analysis and\n        Automated Cartography. Communications of the ACM, 24, 381-395\n    .. [2] Jas, M., Engemann, D.A., Bekhti, Y., Raimondo, F., Gramfort, A.\n        (2017). Autoreject: Automated Artifact Rejection for MEG and EEG\n        Data. NeuroImage, 159, 417-429\n\n    \"\"\"\n    if np.isnan(chn_pos).any():\n        raise ValueError('Found NaN in channel positions. Did you supply a montage for the raw data?')\n    if not isinstance(n_samples, int):\n        raise TypeError(f\"Argument 'n_samples' must be an int (got {type(n_samples).__name__})\")\n    complete_chn_labs = np.asarray(complete_chn_labs)\n    good_idx = np.array([idx for (idx, ch) in enumerate(complete_chn_labs) if ch not in exclude])\n    n_chans_good = good_idx.shape[0]\n    chn_pos_good = chn_pos[good_idx, :]\n    n_chans = data.shape[0]\n    n_pred_chns = int(np.around(sample_prop * n_chans))\n    if n_pred_chns <= 3:\n        sample_pct = int(sample_prop * 100)\n        raise OSError(f'Too few channels in the original data to reliably perform RANSAC(minimum {int(np.floor(4.0 / sample_prop))} for a sample size of {sample_pct}%).')\n    elif n_chans_good < n_pred_chns + 1:\n        raise OSError(f'Too many noisy channels in the data to reliably perform RANSAC (only {n_chans_good} good channels remaining, need at least {n_pred_chns + 1}).')\n    if channel_wise:\n        _verify_free_ram(data, n_samples, 1)\n    else:\n        window_size = int(sample_rate * corr_window_secs)\n        _verify_free_ram(data[:, :window_size], n_samples, n_chans_good)\n    random_ch_picks = []\n    good_chans = np.arange(chn_pos_good.shape[0])\n    rng = check_random_state(random_state)\n    for i in range(n_samples):\n        picks = _get_random_subset(good_chans, n_pred_chns, rng)\n        random_ch_picks.append(picks)\n    interp_mats = _make_interpolation_matrices(random_ch_picks, chn_pos_good)\n    correlation_frames = corr_window_secs * sample_rate\n    signal_frames = data.shape[1]\n    correlation_offsets = np.arange(0, signal_frames - correlation_frames, correlation_frames)\n    win_size = int(correlation_frames)\n    win_count = correlation_offsets.shape[0]\n    n_chans_complete = len(complete_chn_labs)\n    channel_correlations = np.ones((win_count, n_chans_complete))\n    logger.info('Executing RANSAC\\nThis may take a while, so be patient...')\n    if not channel_wise:\n        channel_correlations[:, good_idx] = _ransac_by_window(data[good_idx, :], interp_mats, win_size, win_count, matlab_strict)\n    chunk_sizes = []\n    chunk_count = 0\n    for i in range(1, n_chans_good + 1):\n        n_chunks = int(np.ceil(n_chans_good / i))\n        if n_chunks != chunk_count:\n            chunk_count = n_chunks\n            if not max_chunk_size or i <= max_chunk_size:\n                chunk_sizes.append(i)\n    chunk_size = chunk_sizes.pop()\n    mem_error = True\n    job = list(range(n_chans_good))\n    while mem_error and channel_wise:\n        try:\n            channel_chunks = _split_list(job, chunk_size)\n            total_chunks = len(channel_chunks)\n            current = 1\n            for chunk in channel_chunks:\n                interp_mats_for_chunk = [mat[chunk, :] for mat in interp_mats]\n                channel_correlations[:, good_idx[chunk]] = _ransac_by_channel(data[good_idx, :], interp_mats_for_chunk, win_size, win_count, chunk, random_ch_picks, matlab_strict)\n                if chunk == channel_chunks[0]:\n                    logger.info('Finding optimal chunk size : %s', chunk_size)\n                    logger.info('Total # of chunks: %s', total_chunks)\n                    logger.info('Current chunk:')\n                logger.info(current)\n                current = current + 1\n            mem_error = False\n            del current\n        except MemoryError:\n            if len(chunk_sizes):\n                chunk_size = chunk_sizes.pop()\n            else:\n                raise MemoryError('Not even doing 1 channel at a time the data fits in ram...You could downsample the data or reduce the number of requested samples.')\n    thresholded_correlations = channel_correlations < corr_thresh\n    frac_bad_corr_windows = np.mean(thresholded_correlations, axis=0)\n    bad_ransac_channels_idx = np.argwhere(frac_bad_corr_windows > frac_bad)\n    bad_ransac_channels_name = complete_chn_labs[bad_ransac_channels_idx.astype(int)]\n    bad_by_ransac = [i[0] for i in bad_ransac_channels_name]\n    logger.info('\\nRANSAC done!')\n    return (bad_by_ransac, channel_correlations)"
        },
        {
          "text": "@property\ndef raw(self):\n    \"\"\"Return a version of self.raw_eeg that includes the non-eeg channels.\"\"\"\n    full_raw = self.raw_eeg.copy()\n    if self.raw_non_eeg is None:\n        return full_raw\n    else:\n        return full_raw.add_channels([self.raw_non_eeg], force_update_info=True)"
        },
        {
          "text": "def find_bad_by_deviation(self, deviation_threshold=5.0):\n    \"\"\"Detect channels with abnormally high or low overall amplitudes.\n\n        A channel is considered \"bad-by-deviation\" if its amplitude deviates\n        considerably from the median channel amplitude, as calculated using a\n        robust Z-scoring method and the given deviation threshold.\n\n        Amplitude Z-scores are calculated using the formula\n        ``(channel_amplitude - median_amplitude) / amplitude_sd``, where\n        channel amplitudes are calculated using a robust outlier-resistant estimate\n        of the signals' standard deviations (IQR scaled to units of SD), and the\n        amplitude SD is the IQR-based SD of those amplitudes.\n\n        Parameters\n        ----------\n        deviation_threshold : float, optional\n            The minimum absolute z-score of a channel for it to be considered\n            bad-by-deviation. Defaults to ``5.0``.\n\n        \"\"\"\n    IQR_TO_SD = 0.7413\n    chan_amplitudes = _mat_iqr(self.EEGData, axis=1) * IQR_TO_SD\n    amp_sd = _mat_iqr(chan_amplitudes) * IQR_TO_SD\n    amp_median = np.nanmedian(chan_amplitudes)\n    amplitude_zscore = np.zeros(self.n_chans_original)\n    amplitude_zscore[self.usable_idx] = (chan_amplitudes - amp_median) / amp_sd\n    abnormal_amplitude = np.abs(amplitude_zscore) > deviation_threshold\n    deviation_channel_mask = np.isnan(amplitude_zscore) | abnormal_amplitude\n    deviation_channels = self.ch_names_original[deviation_channel_mask]\n    self.bad_by_deviation = deviation_channels.tolist()\n    self._extra_info['bad_by_deviation'].update({'median_channel_amplitude': amp_median, 'channel_amplitude_sd': amp_sd, 'robust_channel_deviations': amplitude_zscore})"
        },
        {
          "text": "def find_bad_by_hfnoise(self, HF_zscore_threshold=5.0):\n    \"\"\"Detect channels with abnormally high amounts of high-frequency noise.\n\n        The noisiness of a channel is defined as the amplitude of its\n        high-frequency (>50 Hz) components divided by its overall amplitude.\n        A channel is considered \"bad-by-high-frequency-noise\" if its noisiness\n        is considerably higher than the median channel noisiness, as determined\n        by a robust Z-scoring method and the given Z-score threshold.\n\n        Due to the Nyquist theorem, this method will only attempt bad channel\n        detection if the sample rate of the given signal is above 100 Hz.\n\n        Parameters\n        ----------\n        HF_zscore_threshold : float, optional\n            The minimum noisiness z-score of a channel for it to be considered\n            bad-by-high-frequency-noise. Defaults to ``5.0``.\n\n        \"\"\"\n    MAD_TO_SD = 1.4826\n    if self.EEGFiltered is None:\n        self.EEGFiltered = self._get_filtered_data()\n    (noise_median, noise_sd) = (0, 1)\n    noise_zscore = np.zeros(self.n_chans_original)\n    if self.sample_rate > 100:\n        noisiness = np.divide(median_abs_deviation(self.EEGData - self.EEGFiltered, axis=1), median_abs_deviation(self.EEGFiltered, axis=1))\n        noise_median = np.nanmedian(noisiness)\n        noise_sd = np.median(np.abs(noisiness - noise_median)) * MAD_TO_SD\n        noise_zscore[self.usable_idx] = (noisiness - noise_median) / noise_sd\n    hf_mask = np.isnan(noise_zscore) | (noise_zscore > HF_zscore_threshold)\n    hf_noise_channels = self.ch_names_original[hf_mask]\n    self.bad_by_hf_noise = hf_noise_channels.tolist()\n    self._extra_info['bad_by_hf_noise'].update({'median_channel_noisiness': noise_median, 'channel_noisiness_sd': noise_sd, 'hf_noise_zscores': noise_zscore})"
        }
      ]
    }
  },
  {
    "query_id": "pyprep_find_noisy_channels.py_find_bad_by_deviation_doc",
    "prompt": "How do I identify EEG channels with unusually high or low amplitudes?",
    "data": {
      "docs": [
        {
          "text": "def find_bad_by_ransac(data, sample_rate, complete_chn_labs, chn_pos, exclude, n_samples=50, sample_prop=0.25, corr_thresh=0.75, frac_bad=0.4, corr_window_secs=5.0, channel_wise=False, max_chunk_size=None, random_state=None, matlab_strict=False):\n    \"\"\"Detect channels that are not predicted well by other channels.\n\n    Here, a RANSAC approach (see [1]_, and a short discussion in [2]_) is\n    adopted to predict a \"clean EEG\" dataset. After identifying clean EEG\n    channels through the other methods, the clean EEG dataset is\n    constructed by repeatedly sampling a small subset of clean EEG channels\n    and interpolation the complete data. The median of all those\n    repetitions forms the clean EEG dataset. In a second step, the original\n    and the RANSAC-predicted data are correlated and channels, which do not\n    correlate well with themselves across the two datasets are considered\n    `bad_by_ransac`.\n\n    Parameters\n    ----------\n    data : np.ndarray\n        A 2-D array of detrended EEG data, with bad-by-flat and bad-by-NaN\n        channels removed.\n    sample_rate : float\n        The sample rate (in Hz) of the EEG data.\n    complete_chn_labs : array_like\n        Labels for all channels in `data`, in the same order as they appear\n        in `data`.\n    chn_pos : np.ndarray\n        3-D electrode coordinates for all channels in `data`, in the same order\n        as they appear in `data`.\n    exclude : list\n        Labels of channels to exclude as signal predictors during RANSAC\n        (i.e., channels already flagged as bad by metrics other than HF noise).\n    n_samples : int, optional\n        Number of random channel samples to use for RANSAC. Defaults to ``50``.\n    sample_prop : float, optional\n        Proportion of total channels to use for signal prediction per RANSAC\n        sample. This needs to be in the range [0, 1], where 0 would mean no\n        channels would be used and 1 would mean all channels would be used\n        (neither of which would be useful values). Defaults to ``0.25`` (e.g.,\n        16 channels per sample for a 64-channel dataset).\n    corr_thresh : float, optional\n        The minimum predicted vs. actual signal correlation for a channel to\n        be considered good within a given RANSAC window. Defaults to ``0.75``.\n    frac_bad : float, optional\n        The minimum fraction of bad (i.e., below-threshold) RANSAC windows for a\n        channel to be considered bad-by-RANSAC. Defaults to ``0.4``.\n    corr_window_secs : float, optional\n        The duration (in seconds) of each RANSAC correlation window. Defaults to\n        5 seconds.\n    channel_wise : bool, optional\n        Whether RANSAC should predict signals for chunks of channels over the\n        entire signal length (\"channel-wise RANSAC\", see `max_chunk_size`\n        parameter). If ``False``, RANSAC will instead predict signals for all\n        channels at once but over a number of smaller time windows instead of\n        over the entire signal length (\"window-wise RANSAC\"). Channel-wise\n        RANSAC generally has higher RAM demands than window-wise RANSAC\n        (especially if `max_chunk_size` is ``None``), but can be faster on\n        systems with lots of RAM to spare. Defaults to ``False``.\n    max_chunk_size : {int, None}, optional\n        The maximum number of channels to predict at once during channel-wise\n        RANSAC. If ``None``, RANSAC will use the largest chunk size that will\n        fit into the available RAM, which may slow down other programs on the\n        host system. If using window-wise RANSAC (the default), this parameter\n        has no effect. Defaults to ``None``.\n    random_state : {int, None, np.random.RandomState}, optional\n        The random seed with which to generate random samples of channels during\n        RANSAC. If random_state is an int, it will be used as a seed for RandomState.\n        If ``None``, the seed will be obtained from the operating system\n        (see RandomState for details). Defaults to ``None``.\n    matlab_strict : bool, optional\n        Whether or not RANSAC should strictly follow MATLAB PREP's internal\n        math, ignoring any improvements made in PyPREP over the original code\n        (see :ref:`matlab-diffs` for more details). Defaults to ``False``.\n\n    Returns\n    -------\n    bad_by_ransac : list\n        List containing the labels of all channels flagged as bad by RANSAC.\n    channel_correlations : np.ndarray\n        Array of shape (windows, channels) containing the correlations of\n        the channels with their predicted RANSAC values for each window.\n\n    References\n    ----------\n    .. [1] Fischler, M.A., Bolles, R.C. (1981). Random sample consensus: A\n        Paradigm for Model Fitting with Applications to Image Analysis and\n        Automated Cartography. Communications of the ACM, 24, 381-395\n    .. [2] Jas, M., Engemann, D.A., Bekhti, Y., Raimondo, F., Gramfort, A.\n        (2017). Autoreject: Automated Artifact Rejection for MEG and EEG\n        Data. NeuroImage, 159, 417-429\n\n    \"\"\"\n    if np.isnan(chn_pos).any():\n        raise ValueError('Found NaN in channel positions. Did you supply a montage for the raw data?')\n    if not isinstance(n_samples, int):\n        raise TypeError(f\"Argument 'n_samples' must be an int (got {type(n_samples).__name__})\")\n    complete_chn_labs = np.asarray(complete_chn_labs)\n    good_idx = np.array([idx for (idx, ch) in enumerate(complete_chn_labs) if ch not in exclude])\n    n_chans_good = good_idx.shape[0]\n    chn_pos_good = chn_pos[good_idx, :]\n    n_chans = data.shape[0]\n    n_pred_chns = int(np.around(sample_prop * n_chans))\n    if n_pred_chns <= 3:\n        sample_pct = int(sample_prop * 100)\n        raise OSError(f'Too few channels in the original data to reliably perform RANSAC(minimum {int(np.floor(4.0 / sample_prop))} for a sample size of {sample_pct}%).')\n    elif n_chans_good < n_pred_chns + 1:\n        raise OSError(f'Too many noisy channels in the data to reliably perform RANSAC (only {n_chans_good} good channels remaining, need at least {n_pred_chns + 1}).')\n    if channel_wise:\n        _verify_free_ram(data, n_samples, 1)\n    else:\n        window_size = int(sample_rate * corr_window_secs)\n        _verify_free_ram(data[:, :window_size], n_samples, n_chans_good)\n    random_ch_picks = []\n    good_chans = np.arange(chn_pos_good.shape[0])\n    rng = check_random_state(random_state)\n    for i in range(n_samples):\n        picks = _get_random_subset(good_chans, n_pred_chns, rng)\n        random_ch_picks.append(picks)\n    interp_mats = _make_interpolation_matrices(random_ch_picks, chn_pos_good)\n    correlation_frames = corr_window_secs * sample_rate\n    signal_frames = data.shape[1]\n    correlation_offsets = np.arange(0, signal_frames - correlation_frames, correlation_frames)\n    win_size = int(correlation_frames)\n    win_count = correlation_offsets.shape[0]\n    n_chans_complete = len(complete_chn_labs)\n    channel_correlations = np.ones((win_count, n_chans_complete))\n    logger.info('Executing RANSAC\\nThis may take a while, so be patient...')\n    if not channel_wise:\n        channel_correlations[:, good_idx] = _ransac_by_window(data[good_idx, :], interp_mats, win_size, win_count, matlab_strict)\n    chunk_sizes = []\n    chunk_count = 0\n    for i in range(1, n_chans_good + 1):\n        n_chunks = int(np.ceil(n_chans_good / i))\n        if n_chunks != chunk_count:\n            chunk_count = n_chunks\n            if not max_chunk_size or i <= max_chunk_size:\n                chunk_sizes.append(i)\n    chunk_size = chunk_sizes.pop()\n    mem_error = True\n    job = list(range(n_chans_good))\n    while mem_error and channel_wise:\n        try:\n            channel_chunks = _split_list(job, chunk_size)\n            total_chunks = len(channel_chunks)\n            current = 1\n            for chunk in channel_chunks:\n                interp_mats_for_chunk = [mat[chunk, :] for mat in interp_mats]\n                channel_correlations[:, good_idx[chunk]] = _ransac_by_channel(data[good_idx, :], interp_mats_for_chunk, win_size, win_count, chunk, random_ch_picks, matlab_strict)\n                if chunk == channel_chunks[0]:\n                    logger.info('Finding optimal chunk size : %s', chunk_size)\n                    logger.info('Total # of chunks: %s', total_chunks)\n                    logger.info('Current chunk:')\n                logger.info(current)\n                current = current + 1\n            mem_error = False\n            del current\n        except MemoryError:\n            if len(chunk_sizes):\n                chunk_size = chunk_sizes.pop()\n            else:\n                raise MemoryError('Not even doing 1 channel at a time the data fits in ram...You could downsample the data or reduce the number of requested samples.')\n    thresholded_correlations = channel_correlations < corr_thresh\n    frac_bad_corr_windows = np.mean(thresholded_correlations, axis=0)\n    bad_ransac_channels_idx = np.argwhere(frac_bad_corr_windows > frac_bad)\n    bad_ransac_channels_name = complete_chn_labs[bad_ransac_channels_idx.astype(int)]\n    bad_by_ransac = [i[0] for i in bad_ransac_channels_name]\n    logger.info('\\nRANSAC done!')\n    return (bad_by_ransac, channel_correlations)"
        },
        {
          "text": "def find_bad_by_deviation(self, deviation_threshold=5.0):\n    \"\"\"Detect channels with abnormally high or low overall amplitudes.\n\n        A channel is considered \"bad-by-deviation\" if its amplitude deviates\n        considerably from the median channel amplitude, as calculated using a\n        robust Z-scoring method and the given deviation threshold.\n\n        Amplitude Z-scores are calculated using the formula\n        ``(channel_amplitude - median_amplitude) / amplitude_sd``, where\n        channel amplitudes are calculated using a robust outlier-resistant estimate\n        of the signals' standard deviations (IQR scaled to units of SD), and the\n        amplitude SD is the IQR-based SD of those amplitudes.\n\n        Parameters\n        ----------\n        deviation_threshold : float, optional\n            The minimum absolute z-score of a channel for it to be considered\n            bad-by-deviation. Defaults to ``5.0``.\n\n        \"\"\"\n    IQR_TO_SD = 0.7413\n    chan_amplitudes = _mat_iqr(self.EEGData, axis=1) * IQR_TO_SD\n    amp_sd = _mat_iqr(chan_amplitudes) * IQR_TO_SD\n    amp_median = np.nanmedian(chan_amplitudes)\n    amplitude_zscore = np.zeros(self.n_chans_original)\n    amplitude_zscore[self.usable_idx] = (chan_amplitudes - amp_median) / amp_sd\n    abnormal_amplitude = np.abs(amplitude_zscore) > deviation_threshold\n    deviation_channel_mask = np.isnan(amplitude_zscore) | abnormal_amplitude\n    deviation_channels = self.ch_names_original[deviation_channel_mask]\n    self.bad_by_deviation = deviation_channels.tolist()\n    self._extra_info['bad_by_deviation'].update({'median_channel_amplitude': amp_median, 'channel_amplitude_sd': amp_sd, 'robust_channel_deviations': amplitude_zscore})"
        },
        {
          "text": "def find_bad_by_hfnoise(self, HF_zscore_threshold=5.0):\n    \"\"\"Detect channels with abnormally high amounts of high-frequency noise.\n\n        The noisiness of a channel is defined as the amplitude of its\n        high-frequency (>50 Hz) components divided by its overall amplitude.\n        A channel is considered \"bad-by-high-frequency-noise\" if its noisiness\n        is considerably higher than the median channel noisiness, as determined\n        by a robust Z-scoring method and the given Z-score threshold.\n\n        Due to the Nyquist theorem, this method will only attempt bad channel\n        detection if the sample rate of the given signal is above 100 Hz.\n\n        Parameters\n        ----------\n        HF_zscore_threshold : float, optional\n            The minimum noisiness z-score of a channel for it to be considered\n            bad-by-high-frequency-noise. Defaults to ``5.0``.\n\n        \"\"\"\n    MAD_TO_SD = 1.4826\n    if self.EEGFiltered is None:\n        self.EEGFiltered = self._get_filtered_data()\n    (noise_median, noise_sd) = (0, 1)\n    noise_zscore = np.zeros(self.n_chans_original)\n    if self.sample_rate > 100:\n        noisiness = np.divide(median_abs_deviation(self.EEGData - self.EEGFiltered, axis=1), median_abs_deviation(self.EEGFiltered, axis=1))\n        noise_median = np.nanmedian(noisiness)\n        noise_sd = np.median(np.abs(noisiness - noise_median)) * MAD_TO_SD\n        noise_zscore[self.usable_idx] = (noisiness - noise_median) / noise_sd\n    hf_mask = np.isnan(noise_zscore) | (noise_zscore > HF_zscore_threshold)\n    hf_noise_channels = self.ch_names_original[hf_mask]\n    self.bad_by_hf_noise = hf_noise_channels.tolist()\n    self._extra_info['bad_by_hf_noise'].update({'median_channel_noisiness': noise_median, 'channel_noisiness_sd': noise_sd, 'hf_noise_zscores': noise_zscore})"
        },
        {
          "text": "def find_bad_by_nan_flat(self, flat_threshold=1e-15):\n    \"\"\"Detect channels than contain NaN values or have near-flat signals.\n\n        A channel is considered flat if its standard deviation or its median\n        absolute deviation from the median (MAD) are below the provided flat\n        threshold (default: ``1e-15`` volts).\n\n        This method is run automatically when a ``NoisyChannels`` object is\n        initialized, preventing flat or NaN-containing channels from interfering\n        with the detection of other types of bad channels.\n\n        Parameters\n        ----------\n        flat_threshold : float, optional\n            The lowest standard deviation or MAD value for a channel to be\n            considered bad-by-flat. Defaults to ``1e-15`` volts (corresponds to\n            10e-10 \u00b5V in MATLAB PREP).\n        \"\"\"\n    EEGData = self.raw_mne.get_data()\n    nan_channel_mask = np.isnan(np.sum(EEGData, axis=1))\n    nan_channels = self.ch_names_original[nan_channel_mask]\n    flat_by_mad = median_abs_deviation(EEGData, axis=1) < flat_threshold\n    flat_by_stdev = np.std(EEGData, axis=1) < flat_threshold\n    flat_channel_mask = flat_by_mad | flat_by_stdev\n    flat_channels = self.ch_names_original[flat_channel_mask]\n    self.bad_by_nan = nan_channels.tolist()\n    self.bad_by_flat = flat_channels.tolist()"
        },
        {
          "text": "@property\ndef raw(self):\n    \"\"\"Return a version of self.raw_eeg that includes the non-eeg channels.\"\"\"\n    full_raw = self.raw_eeg.copy()\n    if self.raw_non_eeg is None:\n        return full_raw\n    else:\n        return full_raw.add_channels([self.raw_non_eeg], force_update_info=True)"
        }
      ]
    }
  },
  {
    "query_id": "pyprep_find_noisy_channels.py_find_bad_by_hfnoise_doc",
    "prompt": "How can I detect EEG channels with high-frequency noise above 50 Hz?",
    "data": {
      "docs": [
        {
          "text": "def find_bad_by_hfnoise(self, HF_zscore_threshold=5.0):\n    \"\"\"Detect channels with abnormally high amounts of high-frequency noise.\n\n        The noisiness of a channel is defined as the amplitude of its\n        high-frequency (>50 Hz) components divided by its overall amplitude.\n        A channel is considered \"bad-by-high-frequency-noise\" if its noisiness\n        is considerably higher than the median channel noisiness, as determined\n        by a robust Z-scoring method and the given Z-score threshold.\n\n        Due to the Nyquist theorem, this method will only attempt bad channel\n        detection if the sample rate of the given signal is above 100 Hz.\n\n        Parameters\n        ----------\n        HF_zscore_threshold : float, optional\n            The minimum noisiness z-score of a channel for it to be considered\n            bad-by-high-frequency-noise. Defaults to ``5.0``.\n\n        \"\"\"\n    MAD_TO_SD = 1.4826\n    if self.EEGFiltered is None:\n        self.EEGFiltered = self._get_filtered_data()\n    (noise_median, noise_sd) = (0, 1)\n    noise_zscore = np.zeros(self.n_chans_original)\n    if self.sample_rate > 100:\n        noisiness = np.divide(median_abs_deviation(self.EEGData - self.EEGFiltered, axis=1), median_abs_deviation(self.EEGFiltered, axis=1))\n        noise_median = np.nanmedian(noisiness)\n        noise_sd = np.median(np.abs(noisiness - noise_median)) * MAD_TO_SD\n        noise_zscore[self.usable_idx] = (noisiness - noise_median) / noise_sd\n    hf_mask = np.isnan(noise_zscore) | (noise_zscore > HF_zscore_threshold)\n    hf_noise_channels = self.ch_names_original[hf_mask]\n    self.bad_by_hf_noise = hf_noise_channels.tolist()\n    self._extra_info['bad_by_hf_noise'].update({'median_channel_noisiness': noise_median, 'channel_noisiness_sd': noise_sd, 'hf_noise_zscores': noise_zscore})"
        },
        {
          "text": "def find_bad_by_ransac(data, sample_rate, complete_chn_labs, chn_pos, exclude, n_samples=50, sample_prop=0.25, corr_thresh=0.75, frac_bad=0.4, corr_window_secs=5.0, channel_wise=False, max_chunk_size=None, random_state=None, matlab_strict=False):\n    \"\"\"Detect channels that are not predicted well by other channels.\n\n    Here, a RANSAC approach (see [1]_, and a short discussion in [2]_) is\n    adopted to predict a \"clean EEG\" dataset. After identifying clean EEG\n    channels through the other methods, the clean EEG dataset is\n    constructed by repeatedly sampling a small subset of clean EEG channels\n    and interpolation the complete data. The median of all those\n    repetitions forms the clean EEG dataset. In a second step, the original\n    and the RANSAC-predicted data are correlated and channels, which do not\n    correlate well with themselves across the two datasets are considered\n    `bad_by_ransac`.\n\n    Parameters\n    ----------\n    data : np.ndarray\n        A 2-D array of detrended EEG data, with bad-by-flat and bad-by-NaN\n        channels removed.\n    sample_rate : float\n        The sample rate (in Hz) of the EEG data.\n    complete_chn_labs : array_like\n        Labels for all channels in `data`, in the same order as they appear\n        in `data`.\n    chn_pos : np.ndarray\n        3-D electrode coordinates for all channels in `data`, in the same order\n        as they appear in `data`.\n    exclude : list\n        Labels of channels to exclude as signal predictors during RANSAC\n        (i.e., channels already flagged as bad by metrics other than HF noise).\n    n_samples : int, optional\n        Number of random channel samples to use for RANSAC. Defaults to ``50``.\n    sample_prop : float, optional\n        Proportion of total channels to use for signal prediction per RANSAC\n        sample. This needs to be in the range [0, 1], where 0 would mean no\n        channels would be used and 1 would mean all channels would be used\n        (neither of which would be useful values). Defaults to ``0.25`` (e.g.,\n        16 channels per sample for a 64-channel dataset).\n    corr_thresh : float, optional\n        The minimum predicted vs. actual signal correlation for a channel to\n        be considered good within a given RANSAC window. Defaults to ``0.75``.\n    frac_bad : float, optional\n        The minimum fraction of bad (i.e., below-threshold) RANSAC windows for a\n        channel to be considered bad-by-RANSAC. Defaults to ``0.4``.\n    corr_window_secs : float, optional\n        The duration (in seconds) of each RANSAC correlation window. Defaults to\n        5 seconds.\n    channel_wise : bool, optional\n        Whether RANSAC should predict signals for chunks of channels over the\n        entire signal length (\"channel-wise RANSAC\", see `max_chunk_size`\n        parameter). If ``False``, RANSAC will instead predict signals for all\n        channels at once but over a number of smaller time windows instead of\n        over the entire signal length (\"window-wise RANSAC\"). Channel-wise\n        RANSAC generally has higher RAM demands than window-wise RANSAC\n        (especially if `max_chunk_size` is ``None``), but can be faster on\n        systems with lots of RAM to spare. Defaults to ``False``.\n    max_chunk_size : {int, None}, optional\n        The maximum number of channels to predict at once during channel-wise\n        RANSAC. If ``None``, RANSAC will use the largest chunk size that will\n        fit into the available RAM, which may slow down other programs on the\n        host system. If using window-wise RANSAC (the default), this parameter\n        has no effect. Defaults to ``None``.\n    random_state : {int, None, np.random.RandomState}, optional\n        The random seed with which to generate random samples of channels during\n        RANSAC. If random_state is an int, it will be used as a seed for RandomState.\n        If ``None``, the seed will be obtained from the operating system\n        (see RandomState for details). Defaults to ``None``.\n    matlab_strict : bool, optional\n        Whether or not RANSAC should strictly follow MATLAB PREP's internal\n        math, ignoring any improvements made in PyPREP over the original code\n        (see :ref:`matlab-diffs` for more details). Defaults to ``False``.\n\n    Returns\n    -------\n    bad_by_ransac : list\n        List containing the labels of all channels flagged as bad by RANSAC.\n    channel_correlations : np.ndarray\n        Array of shape (windows, channels) containing the correlations of\n        the channels with their predicted RANSAC values for each window.\n\n    References\n    ----------\n    .. [1] Fischler, M.A., Bolles, R.C. (1981). Random sample consensus: A\n        Paradigm for Model Fitting with Applications to Image Analysis and\n        Automated Cartography. Communications of the ACM, 24, 381-395\n    .. [2] Jas, M., Engemann, D.A., Bekhti, Y., Raimondo, F., Gramfort, A.\n        (2017). Autoreject: Automated Artifact Rejection for MEG and EEG\n        Data. NeuroImage, 159, 417-429\n\n    \"\"\"\n    if np.isnan(chn_pos).any():\n        raise ValueError('Found NaN in channel positions. Did you supply a montage for the raw data?')\n    if not isinstance(n_samples, int):\n        raise TypeError(f\"Argument 'n_samples' must be an int (got {type(n_samples).__name__})\")\n    complete_chn_labs = np.asarray(complete_chn_labs)\n    good_idx = np.array([idx for (idx, ch) in enumerate(complete_chn_labs) if ch not in exclude])\n    n_chans_good = good_idx.shape[0]\n    chn_pos_good = chn_pos[good_idx, :]\n    n_chans = data.shape[0]\n    n_pred_chns = int(np.around(sample_prop * n_chans))\n    if n_pred_chns <= 3:\n        sample_pct = int(sample_prop * 100)\n        raise OSError(f'Too few channels in the original data to reliably perform RANSAC(minimum {int(np.floor(4.0 / sample_prop))} for a sample size of {sample_pct}%).')\n    elif n_chans_good < n_pred_chns + 1:\n        raise OSError(f'Too many noisy channels in the data to reliably perform RANSAC (only {n_chans_good} good channels remaining, need at least {n_pred_chns + 1}).')\n    if channel_wise:\n        _verify_free_ram(data, n_samples, 1)\n    else:\n        window_size = int(sample_rate * corr_window_secs)\n        _verify_free_ram(data[:, :window_size], n_samples, n_chans_good)\n    random_ch_picks = []\n    good_chans = np.arange(chn_pos_good.shape[0])\n    rng = check_random_state(random_state)\n    for i in range(n_samples):\n        picks = _get_random_subset(good_chans, n_pred_chns, rng)\n        random_ch_picks.append(picks)\n    interp_mats = _make_interpolation_matrices(random_ch_picks, chn_pos_good)\n    correlation_frames = corr_window_secs * sample_rate\n    signal_frames = data.shape[1]\n    correlation_offsets = np.arange(0, signal_frames - correlation_frames, correlation_frames)\n    win_size = int(correlation_frames)\n    win_count = correlation_offsets.shape[0]\n    n_chans_complete = len(complete_chn_labs)\n    channel_correlations = np.ones((win_count, n_chans_complete))\n    logger.info('Executing RANSAC\\nThis may take a while, so be patient...')\n    if not channel_wise:\n        channel_correlations[:, good_idx] = _ransac_by_window(data[good_idx, :], interp_mats, win_size, win_count, matlab_strict)\n    chunk_sizes = []\n    chunk_count = 0\n    for i in range(1, n_chans_good + 1):\n        n_chunks = int(np.ceil(n_chans_good / i))\n        if n_chunks != chunk_count:\n            chunk_count = n_chunks\n            if not max_chunk_size or i <= max_chunk_size:\n                chunk_sizes.append(i)\n    chunk_size = chunk_sizes.pop()\n    mem_error = True\n    job = list(range(n_chans_good))\n    while mem_error and channel_wise:\n        try:\n            channel_chunks = _split_list(job, chunk_size)\n            total_chunks = len(channel_chunks)\n            current = 1\n            for chunk in channel_chunks:\n                interp_mats_for_chunk = [mat[chunk, :] for mat in interp_mats]\n                channel_correlations[:, good_idx[chunk]] = _ransac_by_channel(data[good_idx, :], interp_mats_for_chunk, win_size, win_count, chunk, random_ch_picks, matlab_strict)\n                if chunk == channel_chunks[0]:\n                    logger.info('Finding optimal chunk size : %s', chunk_size)\n                    logger.info('Total # of chunks: %s', total_chunks)\n                    logger.info('Current chunk:')\n                logger.info(current)\n                current = current + 1\n            mem_error = False\n            del current\n        except MemoryError:\n            if len(chunk_sizes):\n                chunk_size = chunk_sizes.pop()\n            else:\n                raise MemoryError('Not even doing 1 channel at a time the data fits in ram...You could downsample the data or reduce the number of requested samples.')\n    thresholded_correlations = channel_correlations < corr_thresh\n    frac_bad_corr_windows = np.mean(thresholded_correlations, axis=0)\n    bad_ransac_channels_idx = np.argwhere(frac_bad_corr_windows > frac_bad)\n    bad_ransac_channels_name = complete_chn_labs[bad_ransac_channels_idx.astype(int)]\n    bad_by_ransac = [i[0] for i in bad_ransac_channels_name]\n    logger.info('\\nRANSAC done!')\n    return (bad_by_ransac, channel_correlations)"
        },
        {
          "text": "def find_bad_by_nan_flat(self, flat_threshold=1e-15):\n    \"\"\"Detect channels than contain NaN values or have near-flat signals.\n\n        A channel is considered flat if its standard deviation or its median\n        absolute deviation from the median (MAD) are below the provided flat\n        threshold (default: ``1e-15`` volts).\n\n        This method is run automatically when a ``NoisyChannels`` object is\n        initialized, preventing flat or NaN-containing channels from interfering\n        with the detection of other types of bad channels.\n\n        Parameters\n        ----------\n        flat_threshold : float, optional\n            The lowest standard deviation or MAD value for a channel to be\n            considered bad-by-flat. Defaults to ``1e-15`` volts (corresponds to\n            10e-10 \u00b5V in MATLAB PREP).\n        \"\"\"\n    EEGData = self.raw_mne.get_data()\n    nan_channel_mask = np.isnan(np.sum(EEGData, axis=1))\n    nan_channels = self.ch_names_original[nan_channel_mask]\n    flat_by_mad = median_abs_deviation(EEGData, axis=1) < flat_threshold\n    flat_by_stdev = np.std(EEGData, axis=1) < flat_threshold\n    flat_channel_mask = flat_by_mad | flat_by_stdev\n    flat_channels = self.ch_names_original[flat_channel_mask]\n    self.bad_by_nan = nan_channels.tolist()\n    self.bad_by_flat = flat_channels.tolist()"
        },
        {
          "text": "@property\ndef raw(self):\n    \"\"\"Return a version of self.raw_eeg that includes the non-eeg channels.\"\"\"\n    full_raw = self.raw_eeg.copy()\n    if self.raw_non_eeg is None:\n        return full_raw\n    else:\n        return full_raw.add_channels([self.raw_non_eeg], force_update_info=True)"
        },
        {
          "text": "def _get_filtered_data(self):\n    \"\"\"Apply a [1 Hz - 50 Hz] bandpass filter to the EEG signal.\n\n        Only applied if the sample rate is above 100 Hz to avoid violating the\n        Nyquist theorem.\n\n        \"\"\"\n    if self.sample_rate <= 100:\n        return self.EEGData.copy()\n    bandpass_filter = _filter_design(N_order=100, amp=np.array([1, 1, 0, 0]), freq=np.array([0, 90 / self.sample_rate, 100 / self.sample_rate, 1]))\n    EEG_filt = np.zeros_like(self.EEGData)\n    for i in range(EEG_filt.shape[0]):\n        EEG_filt[i, :] = signal.filtfilt(bandpass_filter, 1, self.EEGData[i, :])\n    return EEG_filt"
        }
      ]
    }
  },
  {
    "query_id": "pyprep_find_noisy_channels.py_find_bad_by_correlation_doc",
    "prompt": "How do I find EEG channels that don't correlate well with others or have intermittent dropouts?",
    "data": {
      "docs": [
        {
          "text": "def find_bad_by_ransac(data, sample_rate, complete_chn_labs, chn_pos, exclude, n_samples=50, sample_prop=0.25, corr_thresh=0.75, frac_bad=0.4, corr_window_secs=5.0, channel_wise=False, max_chunk_size=None, random_state=None, matlab_strict=False):\n    \"\"\"Detect channels that are not predicted well by other channels.\n\n    Here, a RANSAC approach (see [1]_, and a short discussion in [2]_) is\n    adopted to predict a \"clean EEG\" dataset. After identifying clean EEG\n    channels through the other methods, the clean EEG dataset is\n    constructed by repeatedly sampling a small subset of clean EEG channels\n    and interpolation the complete data. The median of all those\n    repetitions forms the clean EEG dataset. In a second step, the original\n    and the RANSAC-predicted data are correlated and channels, which do not\n    correlate well with themselves across the two datasets are considered\n    `bad_by_ransac`.\n\n    Parameters\n    ----------\n    data : np.ndarray\n        A 2-D array of detrended EEG data, with bad-by-flat and bad-by-NaN\n        channels removed.\n    sample_rate : float\n        The sample rate (in Hz) of the EEG data.\n    complete_chn_labs : array_like\n        Labels for all channels in `data`, in the same order as they appear\n        in `data`.\n    chn_pos : np.ndarray\n        3-D electrode coordinates for all channels in `data`, in the same order\n        as they appear in `data`.\n    exclude : list\n        Labels of channels to exclude as signal predictors during RANSAC\n        (i.e., channels already flagged as bad by metrics other than HF noise).\n    n_samples : int, optional\n        Number of random channel samples to use for RANSAC. Defaults to ``50``.\n    sample_prop : float, optional\n        Proportion of total channels to use for signal prediction per RANSAC\n        sample. This needs to be in the range [0, 1], where 0 would mean no\n        channels would be used and 1 would mean all channels would be used\n        (neither of which would be useful values). Defaults to ``0.25`` (e.g.,\n        16 channels per sample for a 64-channel dataset).\n    corr_thresh : float, optional\n        The minimum predicted vs. actual signal correlation for a channel to\n        be considered good within a given RANSAC window. Defaults to ``0.75``.\n    frac_bad : float, optional\n        The minimum fraction of bad (i.e., below-threshold) RANSAC windows for a\n        channel to be considered bad-by-RANSAC. Defaults to ``0.4``.\n    corr_window_secs : float, optional\n        The duration (in seconds) of each RANSAC correlation window. Defaults to\n        5 seconds.\n    channel_wise : bool, optional\n        Whether RANSAC should predict signals for chunks of channels over the\n        entire signal length (\"channel-wise RANSAC\", see `max_chunk_size`\n        parameter). If ``False``, RANSAC will instead predict signals for all\n        channels at once but over a number of smaller time windows instead of\n        over the entire signal length (\"window-wise RANSAC\"). Channel-wise\n        RANSAC generally has higher RAM demands than window-wise RANSAC\n        (especially if `max_chunk_size` is ``None``), but can be faster on\n        systems with lots of RAM to spare. Defaults to ``False``.\n    max_chunk_size : {int, None}, optional\n        The maximum number of channels to predict at once during channel-wise\n        RANSAC. If ``None``, RANSAC will use the largest chunk size that will\n        fit into the available RAM, which may slow down other programs on the\n        host system. If using window-wise RANSAC (the default), this parameter\n        has no effect. Defaults to ``None``.\n    random_state : {int, None, np.random.RandomState}, optional\n        The random seed with which to generate random samples of channels during\n        RANSAC. If random_state is an int, it will be used as a seed for RandomState.\n        If ``None``, the seed will be obtained from the operating system\n        (see RandomState for details). Defaults to ``None``.\n    matlab_strict : bool, optional\n        Whether or not RANSAC should strictly follow MATLAB PREP's internal\n        math, ignoring any improvements made in PyPREP over the original code\n        (see :ref:`matlab-diffs` for more details). Defaults to ``False``.\n\n    Returns\n    -------\n    bad_by_ransac : list\n        List containing the labels of all channels flagged as bad by RANSAC.\n    channel_correlations : np.ndarray\n        Array of shape (windows, channels) containing the correlations of\n        the channels with their predicted RANSAC values for each window.\n\n    References\n    ----------\n    .. [1] Fischler, M.A., Bolles, R.C. (1981). Random sample consensus: A\n        Paradigm for Model Fitting with Applications to Image Analysis and\n        Automated Cartography. Communications of the ACM, 24, 381-395\n    .. [2] Jas, M., Engemann, D.A., Bekhti, Y., Raimondo, F., Gramfort, A.\n        (2017). Autoreject: Automated Artifact Rejection for MEG and EEG\n        Data. NeuroImage, 159, 417-429\n\n    \"\"\"\n    if np.isnan(chn_pos).any():\n        raise ValueError('Found NaN in channel positions. Did you supply a montage for the raw data?')\n    if not isinstance(n_samples, int):\n        raise TypeError(f\"Argument 'n_samples' must be an int (got {type(n_samples).__name__})\")\n    complete_chn_labs = np.asarray(complete_chn_labs)\n    good_idx = np.array([idx for (idx, ch) in enumerate(complete_chn_labs) if ch not in exclude])\n    n_chans_good = good_idx.shape[0]\n    chn_pos_good = chn_pos[good_idx, :]\n    n_chans = data.shape[0]\n    n_pred_chns = int(np.around(sample_prop * n_chans))\n    if n_pred_chns <= 3:\n        sample_pct = int(sample_prop * 100)\n        raise OSError(f'Too few channels in the original data to reliably perform RANSAC(minimum {int(np.floor(4.0 / sample_prop))} for a sample size of {sample_pct}%).')\n    elif n_chans_good < n_pred_chns + 1:\n        raise OSError(f'Too many noisy channels in the data to reliably perform RANSAC (only {n_chans_good} good channels remaining, need at least {n_pred_chns + 1}).')\n    if channel_wise:\n        _verify_free_ram(data, n_samples, 1)\n    else:\n        window_size = int(sample_rate * corr_window_secs)\n        _verify_free_ram(data[:, :window_size], n_samples, n_chans_good)\n    random_ch_picks = []\n    good_chans = np.arange(chn_pos_good.shape[0])\n    rng = check_random_state(random_state)\n    for i in range(n_samples):\n        picks = _get_random_subset(good_chans, n_pred_chns, rng)\n        random_ch_picks.append(picks)\n    interp_mats = _make_interpolation_matrices(random_ch_picks, chn_pos_good)\n    correlation_frames = corr_window_secs * sample_rate\n    signal_frames = data.shape[1]\n    correlation_offsets = np.arange(0, signal_frames - correlation_frames, correlation_frames)\n    win_size = int(correlation_frames)\n    win_count = correlation_offsets.shape[0]\n    n_chans_complete = len(complete_chn_labs)\n    channel_correlations = np.ones((win_count, n_chans_complete))\n    logger.info('Executing RANSAC\\nThis may take a while, so be patient...')\n    if not channel_wise:\n        channel_correlations[:, good_idx] = _ransac_by_window(data[good_idx, :], interp_mats, win_size, win_count, matlab_strict)\n    chunk_sizes = []\n    chunk_count = 0\n    for i in range(1, n_chans_good + 1):\n        n_chunks = int(np.ceil(n_chans_good / i))\n        if n_chunks != chunk_count:\n            chunk_count = n_chunks\n            if not max_chunk_size or i <= max_chunk_size:\n                chunk_sizes.append(i)\n    chunk_size = chunk_sizes.pop()\n    mem_error = True\n    job = list(range(n_chans_good))\n    while mem_error and channel_wise:\n        try:\n            channel_chunks = _split_list(job, chunk_size)\n            total_chunks = len(channel_chunks)\n            current = 1\n            for chunk in channel_chunks:\n                interp_mats_for_chunk = [mat[chunk, :] for mat in interp_mats]\n                channel_correlations[:, good_idx[chunk]] = _ransac_by_channel(data[good_idx, :], interp_mats_for_chunk, win_size, win_count, chunk, random_ch_picks, matlab_strict)\n                if chunk == channel_chunks[0]:\n                    logger.info('Finding optimal chunk size : %s', chunk_size)\n                    logger.info('Total # of chunks: %s', total_chunks)\n                    logger.info('Current chunk:')\n                logger.info(current)\n                current = current + 1\n            mem_error = False\n            del current\n        except MemoryError:\n            if len(chunk_sizes):\n                chunk_size = chunk_sizes.pop()\n            else:\n                raise MemoryError('Not even doing 1 channel at a time the data fits in ram...You could downsample the data or reduce the number of requested samples.')\n    thresholded_correlations = channel_correlations < corr_thresh\n    frac_bad_corr_windows = np.mean(thresholded_correlations, axis=0)\n    bad_ransac_channels_idx = np.argwhere(frac_bad_corr_windows > frac_bad)\n    bad_ransac_channels_name = complete_chn_labs[bad_ransac_channels_idx.astype(int)]\n    bad_by_ransac = [i[0] for i in bad_ransac_channels_name]\n    logger.info('\\nRANSAC done!')\n    return (bad_by_ransac, channel_correlations)"
        },
        {
          "text": "def find_bad_by_correlation(self, correlation_secs=1.0, correlation_threshold=0.4, frac_bad=0.01):\n    \"\"\"Detect channels that sometimes don't correlate with any other channels.\n\n        Channel correlations are calculated by splitting the recording into\n        non-overlapping windows of time (default: 1 second), getting the absolute\n        correlations of each usable channel with every other usable channel for\n        each window, and then finding the highest correlation each channel has\n        with another channel for each window (by taking the 98th percentile of\n        the absolute correlations).\n\n        A correlation window is considered \"bad\" for a channel if its maximum\n        correlation with another channel is below the provided correlation\n        threshold (default: ``0.4``). A channel is considered \"bad-by-correlation\"\n        if its fraction of bad correlation windows is above the bad fraction\n        threshold (default: ``0.01``).\n\n        This method also detects channels with intermittent dropouts (i.e.,\n        regions of flat signal). A channel is considered \"bad-by-dropout\" if\n        its fraction of correlation windows with a completely flat signal is\n        above the bad fraction threshold (default: ``0.01``).\n\n        Parameters\n        ----------\n        correlation_secs : float, optional\n            The length (in seconds) of each correlation window. Defaults to ``1.0``.\n        correlation_threshold : float, optional\n            The lowest maximum inter-channel correlation for a channel to be\n            considered \"bad\" within a given window. Defaults to ``0.4``.\n        frac_bad : float, optional\n            The minimum proportion of bad windows for a channel to be considered\n            \"bad-by-correlation\" or \"bad-by-dropout\". Defaults to ``0.01`` (1% of\n            all windows).\n\n        \"\"\"\n    IQR_TO_SD = 0.7413\n    if self.EEGFiltered is None:\n        self.EEGFiltered = self._get_filtered_data()\n    win_size = int(correlation_secs * self.sample_rate)\n    win_offsets = np.arange(1, self.n_samples - win_size, win_size)\n    win_count = len(win_offsets)\n    max_correlations = np.ones((win_count, self.n_chans_original))\n    dropout = np.zeros((win_count, self.n_chans_original), dtype=bool)\n    noiselevels = np.zeros((win_count, self.n_chans_original))\n    channel_amplitudes = np.zeros((win_count, self.n_chans_original))\n    for w in range(win_count):\n        (start, end) = (w * win_size, (w + 1) * win_size)\n        eeg_filtered = self.EEGFiltered[:, start:end]\n        eeg_raw = self.EEGData[:, start:end]\n        usable = self.usable_idx.copy()\n        channel_amplitudes[w, usable] = _mat_iqr(eeg_raw, axis=1) * IQR_TO_SD\n        eeg_amplitude = median_abs_deviation(eeg_filtered, axis=1)\n        dropout[w, usable] = eeg_amplitude == 0\n        usable[usable] = eeg_amplitude > 0\n        eeg_raw = eeg_raw[eeg_amplitude > 0, :]\n        eeg_filtered = eeg_filtered[eeg_amplitude > 0, :]\n        eeg_amplitude = eeg_amplitude[eeg_amplitude > 0]\n        high_freq_amplitude = median_abs_deviation(eeg_raw - eeg_filtered, axis=1)\n        noiselevels[w, usable] = high_freq_amplitude / eeg_amplitude\n        win_correlations = np.corrcoef(eeg_filtered)\n        abs_corr = np.abs(win_correlations - np.diag(np.diag(win_correlations)))\n        max_correlations[w, usable] = _mat_quantile(abs_corr, 0.98, axis=0)\n        max_correlations[w, dropout[w, :]] = 0\n    thresholded_correlations = max_correlations < correlation_threshold\n    fraction_bad_corr_windows = np.mean(thresholded_correlations, axis=0)\n    bad_correlation_mask = fraction_bad_corr_windows > frac_bad\n    bad_correlation_channels = self.ch_names_original[bad_correlation_mask]\n    fraction_dropout_windows = np.mean(dropout, axis=0)\n    dropout_mask = fraction_dropout_windows > frac_bad\n    dropout_channels = self.ch_names_original[dropout_mask]\n    self.bad_by_correlation = bad_correlation_channels.tolist()\n    self.bad_by_dropout = dropout_channels.tolist()\n    self._extra_info['bad_by_correlation'] = {'max_correlations': np.transpose(max_correlations), 'median_max_correlations': np.median(max_correlations, axis=0), 'bad_window_fractions': fraction_bad_corr_windows}\n    self._extra_info['bad_by_dropout'] = {'dropouts': np.transpose(dropout.astype(np.int8)), 'bad_window_fractions': fraction_dropout_windows}\n    self._extra_info['bad_by_deviation']['channel_amplitudes'] = channel_amplitudes\n    self._extra_info['bad_by_hf_noise']['noise_levels'] = noiselevels"
        },
        {
          "text": "def find_bad_by_ransac(self, n_samples=50, sample_prop=0.25, corr_thresh=0.75, frac_bad=0.4, corr_window_secs=5.0, channel_wise=False, max_chunk_size=None):\n    \"\"\"Detect channels that are predicted poorly by other channels.\n\n        This method uses a random sample consensus approach (RANSAC, see [1]_,\n        and a short discussion in [2]_) to try and predict what the signal should\n        be for each channel based on the signals and spatial locations of other\n        currently-good channels. RANSAC correlations are calculated by splitting\n        the recording into non-overlapping windows of time (default: 5 seconds)\n        and correlating each channel's RANSAC-predicted signal with its actual\n        signal within each window.\n\n        A RANSAC window is considered \"bad\" for a channel if its predicted signal\n        vs. actual signal correlation falls below the given correlation threshold\n        (default: ``0.75``). A channel is considered \"bad-by-RANSAC\" if its fraction\n        of bad RANSAC windows is above the given threshold (default: ``0.4``).\n\n        Due to its random sampling component, the channels identified as\n        \"bad-by-RANSAC\" may vary slightly between calls of this method.\n        Additionally, bad channels may vary between different montages given that\n        RANSAC's signal predictions are based on the spatial coordinates of each\n        electrode.\n\n        This method is a wrapper for the :func:`~ransac.find_bad_by_ransac`\n        function.\n\n        .. warning:: For optimal performance, RANSAC requires that channels bad by\n                     deviation, correlation, and/or dropout have already been\n                     flagged. Otherwise RANSAC will attempt to use those channels\n                     when making signal predictions, decreasing accuracy and thus\n                     increasing the likelihood of false positives.\n\n        Parameters\n        ----------\n        n_samples : int, optional\n            Number of random channel samples to use for RANSAC. Defaults\n            to ``50``.\n        sample_prop : float, optional\n            Proportion of total channels to use for signal prediction per RANSAC\n            sample. This needs to be in the range [0, 1], where 0 would mean no\n            channels would be used and 1 would mean all channels would be used\n            (neither of which would be useful values). Defaults to ``0.25``\n            (e.g., 16 channels per sample for a 64-channel dataset).\n        corr_thresh : float, optional\n            The minimum predicted vs. actual signal correlation for a channel to\n            be considered good within a given RANSAC window. Defaults\n            to ``0.75``.\n        frac_bad : float, optional\n            The minimum fraction of bad (i.e., below-threshold) RANSAC windows\n            for a channel to be considered bad-by-RANSAC. Defaults to ``0.4``.\n        corr_window_secs : float, optional\n            The duration (in seconds) of each RANSAC correlation window. Defaults\n            to 5 seconds.\n        channel_wise : bool, optional\n            Whether RANSAC should predict signals for chunks of channels over the\n            entire signal length (\"channel-wise RANSAC\", see `max_chunk_size`\n            parameter). If ``False``, RANSAC will instead predict signals for all\n            channels at once but over a number of smaller time windows instead of\n            over the entire signal length (\"window-wise RANSAC\"). Channel-wise\n            RANSAC generally has higher RAM demands than window-wise RANSAC\n            (especially if `max_chunk_size` is ``None``), but can be faster on\n            systems with lots of RAM to spare. Defaults to ``False``.\n        max_chunk_size : {int, None}, optional\n            The maximum number of channels to predict at once during\n            channel-wise RANSAC. If ``None``, RANSAC will use the largest chunk\n            size that will fit into the available RAM, which may slow down\n            other programs on the host system. If using window-wise RANSAC\n            (the default), this parameter has no effect. Defaults to ``None``.\n\n        References\n        ----------\n        .. [1] Fischler, M.A., Bolles, R.C. (1981). Random sample consensus: A\n            Paradigm for Model Fitting with Applications to Image Analysis and\n            Automated Cartography. Communications of the ACM, 24, 381-395\n        .. [2] Jas, M., Engemann, D.A., Bekhti, Y., Raimondo, F., Gramfort, A.\n            (2017). Autoreject: Automated Artifact Rejection for MEG and EEG\n            Data. NeuroImage, 159, 417-429\n\n        \"\"\"\n    if self.EEGFiltered is None:\n        self.EEGFiltered = self._get_filtered_data()\n    exclude_from_ransac = self.bad_by_correlation + self.bad_by_deviation + self.bad_by_dropout\n    if self.matlab_strict:\n        random_state = self.random_state.get_state()\n        rng = np.random.RandomState()\n        rng.set_state(random_state)\n    else:\n        rng = self.random_state\n    (self.bad_by_ransac, ch_correlations_usable) = find_bad_by_ransac(self.EEGFiltered, self.sample_rate, self.ch_names_new, self.raw_mne._get_channel_positions()[self.usable_idx, :], exclude_from_ransac, n_samples, sample_prop, corr_thresh, frac_bad, corr_window_secs, channel_wise, max_chunk_size, rng, self.matlab_strict)\n    n_ransac_windows = ch_correlations_usable.shape[0]\n    ch_correlations = np.ones((n_ransac_windows, self.n_chans_original))\n    ch_correlations[:, self.usable_idx] = ch_correlations_usable\n    self._extra_info['bad_by_ransac'] = {'ransac_correlations': ch_correlations, 'bad_window_fractions': np.mean(ch_correlations < corr_thresh, axis=0)}"
        },
        {
          "text": "def find_bad_by_nan_flat(self, flat_threshold=1e-15):\n    \"\"\"Detect channels than contain NaN values or have near-flat signals.\n\n        A channel is considered flat if its standard deviation or its median\n        absolute deviation from the median (MAD) are below the provided flat\n        threshold (default: ``1e-15`` volts).\n\n        This method is run automatically when a ``NoisyChannels`` object is\n        initialized, preventing flat or NaN-containing channels from interfering\n        with the detection of other types of bad channels.\n\n        Parameters\n        ----------\n        flat_threshold : float, optional\n            The lowest standard deviation or MAD value for a channel to be\n            considered bad-by-flat. Defaults to ``1e-15`` volts (corresponds to\n            10e-10 \u00b5V in MATLAB PREP).\n        \"\"\"\n    EEGData = self.raw_mne.get_data()\n    nan_channel_mask = np.isnan(np.sum(EEGData, axis=1))\n    nan_channels = self.ch_names_original[nan_channel_mask]\n    flat_by_mad = median_abs_deviation(EEGData, axis=1) < flat_threshold\n    flat_by_stdev = np.std(EEGData, axis=1) < flat_threshold\n    flat_channel_mask = flat_by_mad | flat_by_stdev\n    flat_channels = self.ch_names_original[flat_channel_mask]\n    self.bad_by_nan = nan_channels.tolist()\n    self.bad_by_flat = flat_channels.tolist()"
        },
        {
          "text": "def find_bad_by_SNR(self):\n    \"\"\"Detect channels that have a low signal-to-noise ratio.\n\n        Channels are considered \"bad-by-SNR\" if they are bad by both high-frequency\n        noise and bad by low correlation.\n\n        \"\"\"\n    if not len(self._extra_info['bad_by_hf_noise']) > 1:\n        self.find_bad_by_hfnoise()\n    if not len(self._extra_info['bad_by_correlation']):\n        self.find_bad_by_correlation()\n    bad_by_hf = set(self.bad_by_hf_noise)\n    bad_by_corr = set(self.bad_by_correlation)\n    self.bad_by_SNR = list(bad_by_corr.intersection(bad_by_hf))"
        }
      ]
    }
  },
  {
    "query_id": "pyprep_find_noisy_channels.py_find_bad_by_SNR_doc",
    "prompt": "How can I identify channels with a low signal-to-noise ratio (SNR)?",
    "data": {
      "docs": [
        {
          "text": "def find_bad_by_SNR(self):\n    \"\"\"Detect channels that have a low signal-to-noise ratio.\n\n        Channels are considered \"bad-by-SNR\" if they are bad by both high-frequency\n        noise and bad by low correlation.\n\n        \"\"\"\n    if not len(self._extra_info['bad_by_hf_noise']) > 1:\n        self.find_bad_by_hfnoise()\n    if not len(self._extra_info['bad_by_correlation']):\n        self.find_bad_by_correlation()\n    bad_by_hf = set(self.bad_by_hf_noise)\n    bad_by_corr = set(self.bad_by_correlation)\n    self.bad_by_SNR = list(bad_by_corr.intersection(bad_by_hf))"
        },
        {
          "text": "def find_bad_by_ransac(self, n_samples=50, sample_prop=0.25, corr_thresh=0.75, frac_bad=0.4, corr_window_secs=5.0, channel_wise=False, max_chunk_size=None):\n    \"\"\"Detect channels that are predicted poorly by other channels.\n\n        This method uses a random sample consensus approach (RANSAC, see [1]_,\n        and a short discussion in [2]_) to try and predict what the signal should\n        be for each channel based on the signals and spatial locations of other\n        currently-good channels. RANSAC correlations are calculated by splitting\n        the recording into non-overlapping windows of time (default: 5 seconds)\n        and correlating each channel's RANSAC-predicted signal with its actual\n        signal within each window.\n\n        A RANSAC window is considered \"bad\" for a channel if its predicted signal\n        vs. actual signal correlation falls below the given correlation threshold\n        (default: ``0.75``). A channel is considered \"bad-by-RANSAC\" if its fraction\n        of bad RANSAC windows is above the given threshold (default: ``0.4``).\n\n        Due to its random sampling component, the channels identified as\n        \"bad-by-RANSAC\" may vary slightly between calls of this method.\n        Additionally, bad channels may vary between different montages given that\n        RANSAC's signal predictions are based on the spatial coordinates of each\n        electrode.\n\n        This method is a wrapper for the :func:`~ransac.find_bad_by_ransac`\n        function.\n\n        .. warning:: For optimal performance, RANSAC requires that channels bad by\n                     deviation, correlation, and/or dropout have already been\n                     flagged. Otherwise RANSAC will attempt to use those channels\n                     when making signal predictions, decreasing accuracy and thus\n                     increasing the likelihood of false positives.\n\n        Parameters\n        ----------\n        n_samples : int, optional\n            Number of random channel samples to use for RANSAC. Defaults\n            to ``50``.\n        sample_prop : float, optional\n            Proportion of total channels to use for signal prediction per RANSAC\n            sample. This needs to be in the range [0, 1], where 0 would mean no\n            channels would be used and 1 would mean all channels would be used\n            (neither of which would be useful values). Defaults to ``0.25``\n            (e.g., 16 channels per sample for a 64-channel dataset).\n        corr_thresh : float, optional\n            The minimum predicted vs. actual signal correlation for a channel to\n            be considered good within a given RANSAC window. Defaults\n            to ``0.75``.\n        frac_bad : float, optional\n            The minimum fraction of bad (i.e., below-threshold) RANSAC windows\n            for a channel to be considered bad-by-RANSAC. Defaults to ``0.4``.\n        corr_window_secs : float, optional\n            The duration (in seconds) of each RANSAC correlation window. Defaults\n            to 5 seconds.\n        channel_wise : bool, optional\n            Whether RANSAC should predict signals for chunks of channels over the\n            entire signal length (\"channel-wise RANSAC\", see `max_chunk_size`\n            parameter). If ``False``, RANSAC will instead predict signals for all\n            channels at once but over a number of smaller time windows instead of\n            over the entire signal length (\"window-wise RANSAC\"). Channel-wise\n            RANSAC generally has higher RAM demands than window-wise RANSAC\n            (especially if `max_chunk_size` is ``None``), but can be faster on\n            systems with lots of RAM to spare. Defaults to ``False``.\n        max_chunk_size : {int, None}, optional\n            The maximum number of channels to predict at once during\n            channel-wise RANSAC. If ``None``, RANSAC will use the largest chunk\n            size that will fit into the available RAM, which may slow down\n            other programs on the host system. If using window-wise RANSAC\n            (the default), this parameter has no effect. Defaults to ``None``.\n\n        References\n        ----------\n        .. [1] Fischler, M.A., Bolles, R.C. (1981). Random sample consensus: A\n            Paradigm for Model Fitting with Applications to Image Analysis and\n            Automated Cartography. Communications of the ACM, 24, 381-395\n        .. [2] Jas, M., Engemann, D.A., Bekhti, Y., Raimondo, F., Gramfort, A.\n            (2017). Autoreject: Automated Artifact Rejection for MEG and EEG\n            Data. NeuroImage, 159, 417-429\n\n        \"\"\"\n    if self.EEGFiltered is None:\n        self.EEGFiltered = self._get_filtered_data()\n    exclude_from_ransac = self.bad_by_correlation + self.bad_by_deviation + self.bad_by_dropout\n    if self.matlab_strict:\n        random_state = self.random_state.get_state()\n        rng = np.random.RandomState()\n        rng.set_state(random_state)\n    else:\n        rng = self.random_state\n    (self.bad_by_ransac, ch_correlations_usable) = find_bad_by_ransac(self.EEGFiltered, self.sample_rate, self.ch_names_new, self.raw_mne._get_channel_positions()[self.usable_idx, :], exclude_from_ransac, n_samples, sample_prop, corr_thresh, frac_bad, corr_window_secs, channel_wise, max_chunk_size, rng, self.matlab_strict)\n    n_ransac_windows = ch_correlations_usable.shape[0]\n    ch_correlations = np.ones((n_ransac_windows, self.n_chans_original))\n    ch_correlations[:, self.usable_idx] = ch_correlations_usable\n    self._extra_info['bad_by_ransac'] = {'ransac_correlations': ch_correlations, 'bad_window_fractions': np.mean(ch_correlations < corr_thresh, axis=0)}"
        },
        {
          "text": "def find_bad_by_correlation(self, correlation_secs=1.0, correlation_threshold=0.4, frac_bad=0.01):\n    \"\"\"Detect channels that sometimes don't correlate with any other channels.\n\n        Channel correlations are calculated by splitting the recording into\n        non-overlapping windows of time (default: 1 second), getting the absolute\n        correlations of each usable channel with every other usable channel for\n        each window, and then finding the highest correlation each channel has\n        with another channel for each window (by taking the 98th percentile of\n        the absolute correlations).\n\n        A correlation window is considered \"bad\" for a channel if its maximum\n        correlation with another channel is below the provided correlation\n        threshold (default: ``0.4``). A channel is considered \"bad-by-correlation\"\n        if its fraction of bad correlation windows is above the bad fraction\n        threshold (default: ``0.01``).\n\n        This method also detects channels with intermittent dropouts (i.e.,\n        regions of flat signal). A channel is considered \"bad-by-dropout\" if\n        its fraction of correlation windows with a completely flat signal is\n        above the bad fraction threshold (default: ``0.01``).\n\n        Parameters\n        ----------\n        correlation_secs : float, optional\n            The length (in seconds) of each correlation window. Defaults to ``1.0``.\n        correlation_threshold : float, optional\n            The lowest maximum inter-channel correlation for a channel to be\n            considered \"bad\" within a given window. Defaults to ``0.4``.\n        frac_bad : float, optional\n            The minimum proportion of bad windows for a channel to be considered\n            \"bad-by-correlation\" or \"bad-by-dropout\". Defaults to ``0.01`` (1% of\n            all windows).\n\n        \"\"\"\n    IQR_TO_SD = 0.7413\n    if self.EEGFiltered is None:\n        self.EEGFiltered = self._get_filtered_data()\n    win_size = int(correlation_secs * self.sample_rate)\n    win_offsets = np.arange(1, self.n_samples - win_size, win_size)\n    win_count = len(win_offsets)\n    max_correlations = np.ones((win_count, self.n_chans_original))\n    dropout = np.zeros((win_count, self.n_chans_original), dtype=bool)\n    noiselevels = np.zeros((win_count, self.n_chans_original))\n    channel_amplitudes = np.zeros((win_count, self.n_chans_original))\n    for w in range(win_count):\n        (start, end) = (w * win_size, (w + 1) * win_size)\n        eeg_filtered = self.EEGFiltered[:, start:end]\n        eeg_raw = self.EEGData[:, start:end]\n        usable = self.usable_idx.copy()\n        channel_amplitudes[w, usable] = _mat_iqr(eeg_raw, axis=1) * IQR_TO_SD\n        eeg_amplitude = median_abs_deviation(eeg_filtered, axis=1)\n        dropout[w, usable] = eeg_amplitude == 0\n        usable[usable] = eeg_amplitude > 0\n        eeg_raw = eeg_raw[eeg_amplitude > 0, :]\n        eeg_filtered = eeg_filtered[eeg_amplitude > 0, :]\n        eeg_amplitude = eeg_amplitude[eeg_amplitude > 0]\n        high_freq_amplitude = median_abs_deviation(eeg_raw - eeg_filtered, axis=1)\n        noiselevels[w, usable] = high_freq_amplitude / eeg_amplitude\n        win_correlations = np.corrcoef(eeg_filtered)\n        abs_corr = np.abs(win_correlations - np.diag(np.diag(win_correlations)))\n        max_correlations[w, usable] = _mat_quantile(abs_corr, 0.98, axis=0)\n        max_correlations[w, dropout[w, :]] = 0\n    thresholded_correlations = max_correlations < correlation_threshold\n    fraction_bad_corr_windows = np.mean(thresholded_correlations, axis=0)\n    bad_correlation_mask = fraction_bad_corr_windows > frac_bad\n    bad_correlation_channels = self.ch_names_original[bad_correlation_mask]\n    fraction_dropout_windows = np.mean(dropout, axis=0)\n    dropout_mask = fraction_dropout_windows > frac_bad\n    dropout_channels = self.ch_names_original[dropout_mask]\n    self.bad_by_correlation = bad_correlation_channels.tolist()\n    self.bad_by_dropout = dropout_channels.tolist()\n    self._extra_info['bad_by_correlation'] = {'max_correlations': np.transpose(max_correlations), 'median_max_correlations': np.median(max_correlations, axis=0), 'bad_window_fractions': fraction_bad_corr_windows}\n    self._extra_info['bad_by_dropout'] = {'dropouts': np.transpose(dropout.astype(np.int8)), 'bad_window_fractions': fraction_dropout_windows}\n    self._extra_info['bad_by_deviation']['channel_amplitudes'] = channel_amplitudes\n    self._extra_info['bad_by_hf_noise']['noise_levels'] = noiselevels"
        },
        {
          "text": "def find_bad_by_deviation(self, deviation_threshold=5.0):\n    \"\"\"Detect channels with abnormally high or low overall amplitudes.\n\n        A channel is considered \"bad-by-deviation\" if its amplitude deviates\n        considerably from the median channel amplitude, as calculated using a\n        robust Z-scoring method and the given deviation threshold.\n\n        Amplitude Z-scores are calculated using the formula\n        ``(channel_amplitude - median_amplitude) / amplitude_sd``, where\n        channel amplitudes are calculated using a robust outlier-resistant estimate\n        of the signals' standard deviations (IQR scaled to units of SD), and the\n        amplitude SD is the IQR-based SD of those amplitudes.\n\n        Parameters\n        ----------\n        deviation_threshold : float, optional\n            The minimum absolute z-score of a channel for it to be considered\n            bad-by-deviation. Defaults to ``5.0``.\n\n        \"\"\"\n    IQR_TO_SD = 0.7413\n    chan_amplitudes = _mat_iqr(self.EEGData, axis=1) * IQR_TO_SD\n    amp_sd = _mat_iqr(chan_amplitudes) * IQR_TO_SD\n    amp_median = np.nanmedian(chan_amplitudes)\n    amplitude_zscore = np.zeros(self.n_chans_original)\n    amplitude_zscore[self.usable_idx] = (chan_amplitudes - amp_median) / amp_sd\n    abnormal_amplitude = np.abs(amplitude_zscore) > deviation_threshold\n    deviation_channel_mask = np.isnan(amplitude_zscore) | abnormal_amplitude\n    deviation_channels = self.ch_names_original[deviation_channel_mask]\n    self.bad_by_deviation = deviation_channels.tolist()\n    self._extra_info['bad_by_deviation'].update({'median_channel_amplitude': amp_median, 'channel_amplitude_sd': amp_sd, 'robust_channel_deviations': amplitude_zscore})"
        },
        {
          "text": "def find_bad_by_hfnoise(self, HF_zscore_threshold=5.0):\n    \"\"\"Detect channels with abnormally high amounts of high-frequency noise.\n\n        The noisiness of a channel is defined as the amplitude of its\n        high-frequency (>50 Hz) components divided by its overall amplitude.\n        A channel is considered \"bad-by-high-frequency-noise\" if its noisiness\n        is considerably higher than the median channel noisiness, as determined\n        by a robust Z-scoring method and the given Z-score threshold.\n\n        Due to the Nyquist theorem, this method will only attempt bad channel\n        detection if the sample rate of the given signal is above 100 Hz.\n\n        Parameters\n        ----------\n        HF_zscore_threshold : float, optional\n            The minimum noisiness z-score of a channel for it to be considered\n            bad-by-high-frequency-noise. Defaults to ``5.0``.\n\n        \"\"\"\n    MAD_TO_SD = 1.4826\n    if self.EEGFiltered is None:\n        self.EEGFiltered = self._get_filtered_data()\n    (noise_median, noise_sd) = (0, 1)\n    noise_zscore = np.zeros(self.n_chans_original)\n    if self.sample_rate > 100:\n        noisiness = np.divide(median_abs_deviation(self.EEGData - self.EEGFiltered, axis=1), median_abs_deviation(self.EEGFiltered, axis=1))\n        noise_median = np.nanmedian(noisiness)\n        noise_sd = np.median(np.abs(noisiness - noise_median)) * MAD_TO_SD\n        noise_zscore[self.usable_idx] = (noisiness - noise_median) / noise_sd\n    hf_mask = np.isnan(noise_zscore) | (noise_zscore > HF_zscore_threshold)\n    hf_noise_channels = self.ch_names_original[hf_mask]\n    self.bad_by_hf_noise = hf_noise_channels.tolist()\n    self._extra_info['bad_by_hf_noise'].update({'median_channel_noisiness': noise_median, 'channel_noisiness_sd': noise_sd, 'hf_noise_zscores': noise_zscore})"
        }
      ]
    }
  },
  {
    "query_id": "pyprep_find_noisy_channels.py_find_bad_by_ransac_doc",
    "prompt": "How do I use RANSAC to detect EEG channels that are poorly predicted by other channels?",
    "data": {
      "docs": [
        {
          "text": "def find_bad_by_ransac(data, sample_rate, complete_chn_labs, chn_pos, exclude, n_samples=50, sample_prop=0.25, corr_thresh=0.75, frac_bad=0.4, corr_window_secs=5.0, channel_wise=False, max_chunk_size=None, random_state=None, matlab_strict=False):\n    \"\"\"Detect channels that are not predicted well by other channels.\n\n    Here, a RANSAC approach (see [1]_, and a short discussion in [2]_) is\n    adopted to predict a \"clean EEG\" dataset. After identifying clean EEG\n    channels through the other methods, the clean EEG dataset is\n    constructed by repeatedly sampling a small subset of clean EEG channels\n    and interpolation the complete data. The median of all those\n    repetitions forms the clean EEG dataset. In a second step, the original\n    and the RANSAC-predicted data are correlated and channels, which do not\n    correlate well with themselves across the two datasets are considered\n    `bad_by_ransac`.\n\n    Parameters\n    ----------\n    data : np.ndarray\n        A 2-D array of detrended EEG data, with bad-by-flat and bad-by-NaN\n        channels removed.\n    sample_rate : float\n        The sample rate (in Hz) of the EEG data.\n    complete_chn_labs : array_like\n        Labels for all channels in `data`, in the same order as they appear\n        in `data`.\n    chn_pos : np.ndarray\n        3-D electrode coordinates for all channels in `data`, in the same order\n        as they appear in `data`.\n    exclude : list\n        Labels of channels to exclude as signal predictors during RANSAC\n        (i.e., channels already flagged as bad by metrics other than HF noise).\n    n_samples : int, optional\n        Number of random channel samples to use for RANSAC. Defaults to ``50``.\n    sample_prop : float, optional\n        Proportion of total channels to use for signal prediction per RANSAC\n        sample. This needs to be in the range [0, 1], where 0 would mean no\n        channels would be used and 1 would mean all channels would be used\n        (neither of which would be useful values). Defaults to ``0.25`` (e.g.,\n        16 channels per sample for a 64-channel dataset).\n    corr_thresh : float, optional\n        The minimum predicted vs. actual signal correlation for a channel to\n        be considered good within a given RANSAC window. Defaults to ``0.75``.\n    frac_bad : float, optional\n        The minimum fraction of bad (i.e., below-threshold) RANSAC windows for a\n        channel to be considered bad-by-RANSAC. Defaults to ``0.4``.\n    corr_window_secs : float, optional\n        The duration (in seconds) of each RANSAC correlation window. Defaults to\n        5 seconds.\n    channel_wise : bool, optional\n        Whether RANSAC should predict signals for chunks of channels over the\n        entire signal length (\"channel-wise RANSAC\", see `max_chunk_size`\n        parameter). If ``False``, RANSAC will instead predict signals for all\n        channels at once but over a number of smaller time windows instead of\n        over the entire signal length (\"window-wise RANSAC\"). Channel-wise\n        RANSAC generally has higher RAM demands than window-wise RANSAC\n        (especially if `max_chunk_size` is ``None``), but can be faster on\n        systems with lots of RAM to spare. Defaults to ``False``.\n    max_chunk_size : {int, None}, optional\n        The maximum number of channels to predict at once during channel-wise\n        RANSAC. If ``None``, RANSAC will use the largest chunk size that will\n        fit into the available RAM, which may slow down other programs on the\n        host system. If using window-wise RANSAC (the default), this parameter\n        has no effect. Defaults to ``None``.\n    random_state : {int, None, np.random.RandomState}, optional\n        The random seed with which to generate random samples of channels during\n        RANSAC. If random_state is an int, it will be used as a seed for RandomState.\n        If ``None``, the seed will be obtained from the operating system\n        (see RandomState for details). Defaults to ``None``.\n    matlab_strict : bool, optional\n        Whether or not RANSAC should strictly follow MATLAB PREP's internal\n        math, ignoring any improvements made in PyPREP over the original code\n        (see :ref:`matlab-diffs` for more details). Defaults to ``False``.\n\n    Returns\n    -------\n    bad_by_ransac : list\n        List containing the labels of all channels flagged as bad by RANSAC.\n    channel_correlations : np.ndarray\n        Array of shape (windows, channels) containing the correlations of\n        the channels with their predicted RANSAC values for each window.\n\n    References\n    ----------\n    .. [1] Fischler, M.A., Bolles, R.C. (1981). Random sample consensus: A\n        Paradigm for Model Fitting with Applications to Image Analysis and\n        Automated Cartography. Communications of the ACM, 24, 381-395\n    .. [2] Jas, M., Engemann, D.A., Bekhti, Y., Raimondo, F., Gramfort, A.\n        (2017). Autoreject: Automated Artifact Rejection for MEG and EEG\n        Data. NeuroImage, 159, 417-429\n\n    \"\"\"\n    if np.isnan(chn_pos).any():\n        raise ValueError('Found NaN in channel positions. Did you supply a montage for the raw data?')\n    if not isinstance(n_samples, int):\n        raise TypeError(f\"Argument 'n_samples' must be an int (got {type(n_samples).__name__})\")\n    complete_chn_labs = np.asarray(complete_chn_labs)\n    good_idx = np.array([idx for (idx, ch) in enumerate(complete_chn_labs) if ch not in exclude])\n    n_chans_good = good_idx.shape[0]\n    chn_pos_good = chn_pos[good_idx, :]\n    n_chans = data.shape[0]\n    n_pred_chns = int(np.around(sample_prop * n_chans))\n    if n_pred_chns <= 3:\n        sample_pct = int(sample_prop * 100)\n        raise OSError(f'Too few channels in the original data to reliably perform RANSAC(minimum {int(np.floor(4.0 / sample_prop))} for a sample size of {sample_pct}%).')\n    elif n_chans_good < n_pred_chns + 1:\n        raise OSError(f'Too many noisy channels in the data to reliably perform RANSAC (only {n_chans_good} good channels remaining, need at least {n_pred_chns + 1}).')\n    if channel_wise:\n        _verify_free_ram(data, n_samples, 1)\n    else:\n        window_size = int(sample_rate * corr_window_secs)\n        _verify_free_ram(data[:, :window_size], n_samples, n_chans_good)\n    random_ch_picks = []\n    good_chans = np.arange(chn_pos_good.shape[0])\n    rng = check_random_state(random_state)\n    for i in range(n_samples):\n        picks = _get_random_subset(good_chans, n_pred_chns, rng)\n        random_ch_picks.append(picks)\n    interp_mats = _make_interpolation_matrices(random_ch_picks, chn_pos_good)\n    correlation_frames = corr_window_secs * sample_rate\n    signal_frames = data.shape[1]\n    correlation_offsets = np.arange(0, signal_frames - correlation_frames, correlation_frames)\n    win_size = int(correlation_frames)\n    win_count = correlation_offsets.shape[0]\n    n_chans_complete = len(complete_chn_labs)\n    channel_correlations = np.ones((win_count, n_chans_complete))\n    logger.info('Executing RANSAC\\nThis may take a while, so be patient...')\n    if not channel_wise:\n        channel_correlations[:, good_idx] = _ransac_by_window(data[good_idx, :], interp_mats, win_size, win_count, matlab_strict)\n    chunk_sizes = []\n    chunk_count = 0\n    for i in range(1, n_chans_good + 1):\n        n_chunks = int(np.ceil(n_chans_good / i))\n        if n_chunks != chunk_count:\n            chunk_count = n_chunks\n            if not max_chunk_size or i <= max_chunk_size:\n                chunk_sizes.append(i)\n    chunk_size = chunk_sizes.pop()\n    mem_error = True\n    job = list(range(n_chans_good))\n    while mem_error and channel_wise:\n        try:\n            channel_chunks = _split_list(job, chunk_size)\n            total_chunks = len(channel_chunks)\n            current = 1\n            for chunk in channel_chunks:\n                interp_mats_for_chunk = [mat[chunk, :] for mat in interp_mats]\n                channel_correlations[:, good_idx[chunk]] = _ransac_by_channel(data[good_idx, :], interp_mats_for_chunk, win_size, win_count, chunk, random_ch_picks, matlab_strict)\n                if chunk == channel_chunks[0]:\n                    logger.info('Finding optimal chunk size : %s', chunk_size)\n                    logger.info('Total # of chunks: %s', total_chunks)\n                    logger.info('Current chunk:')\n                logger.info(current)\n                current = current + 1\n            mem_error = False\n            del current\n        except MemoryError:\n            if len(chunk_sizes):\n                chunk_size = chunk_sizes.pop()\n            else:\n                raise MemoryError('Not even doing 1 channel at a time the data fits in ram...You could downsample the data or reduce the number of requested samples.')\n    thresholded_correlations = channel_correlations < corr_thresh\n    frac_bad_corr_windows = np.mean(thresholded_correlations, axis=0)\n    bad_ransac_channels_idx = np.argwhere(frac_bad_corr_windows > frac_bad)\n    bad_ransac_channels_name = complete_chn_labs[bad_ransac_channels_idx.astype(int)]\n    bad_by_ransac = [i[0] for i in bad_ransac_channels_name]\n    logger.info('\\nRANSAC done!')\n    return (bad_by_ransac, channel_correlations)"
        },
        {
          "text": "def find_bad_by_ransac(self, n_samples=50, sample_prop=0.25, corr_thresh=0.75, frac_bad=0.4, corr_window_secs=5.0, channel_wise=False, max_chunk_size=None):\n    \"\"\"Detect channels that are predicted poorly by other channels.\n\n        This method uses a random sample consensus approach (RANSAC, see [1]_,\n        and a short discussion in [2]_) to try and predict what the signal should\n        be for each channel based on the signals and spatial locations of other\n        currently-good channels. RANSAC correlations are calculated by splitting\n        the recording into non-overlapping windows of time (default: 5 seconds)\n        and correlating each channel's RANSAC-predicted signal with its actual\n        signal within each window.\n\n        A RANSAC window is considered \"bad\" for a channel if its predicted signal\n        vs. actual signal correlation falls below the given correlation threshold\n        (default: ``0.75``). A channel is considered \"bad-by-RANSAC\" if its fraction\n        of bad RANSAC windows is above the given threshold (default: ``0.4``).\n\n        Due to its random sampling component, the channels identified as\n        \"bad-by-RANSAC\" may vary slightly between calls of this method.\n        Additionally, bad channels may vary between different montages given that\n        RANSAC's signal predictions are based on the spatial coordinates of each\n        electrode.\n\n        This method is a wrapper for the :func:`~ransac.find_bad_by_ransac`\n        function.\n\n        .. warning:: For optimal performance, RANSAC requires that channels bad by\n                     deviation, correlation, and/or dropout have already been\n                     flagged. Otherwise RANSAC will attempt to use those channels\n                     when making signal predictions, decreasing accuracy and thus\n                     increasing the likelihood of false positives.\n\n        Parameters\n        ----------\n        n_samples : int, optional\n            Number of random channel samples to use for RANSAC. Defaults\n            to ``50``.\n        sample_prop : float, optional\n            Proportion of total channels to use for signal prediction per RANSAC\n            sample. This needs to be in the range [0, 1], where 0 would mean no\n            channels would be used and 1 would mean all channels would be used\n            (neither of which would be useful values). Defaults to ``0.25``\n            (e.g., 16 channels per sample for a 64-channel dataset).\n        corr_thresh : float, optional\n            The minimum predicted vs. actual signal correlation for a channel to\n            be considered good within a given RANSAC window. Defaults\n            to ``0.75``.\n        frac_bad : float, optional\n            The minimum fraction of bad (i.e., below-threshold) RANSAC windows\n            for a channel to be considered bad-by-RANSAC. Defaults to ``0.4``.\n        corr_window_secs : float, optional\n            The duration (in seconds) of each RANSAC correlation window. Defaults\n            to 5 seconds.\n        channel_wise : bool, optional\n            Whether RANSAC should predict signals for chunks of channels over the\n            entire signal length (\"channel-wise RANSAC\", see `max_chunk_size`\n            parameter). If ``False``, RANSAC will instead predict signals for all\n            channels at once but over a number of smaller time windows instead of\n            over the entire signal length (\"window-wise RANSAC\"). Channel-wise\n            RANSAC generally has higher RAM demands than window-wise RANSAC\n            (especially if `max_chunk_size` is ``None``), but can be faster on\n            systems with lots of RAM to spare. Defaults to ``False``.\n        max_chunk_size : {int, None}, optional\n            The maximum number of channels to predict at once during\n            channel-wise RANSAC. If ``None``, RANSAC will use the largest chunk\n            size that will fit into the available RAM, which may slow down\n            other programs on the host system. If using window-wise RANSAC\n            (the default), this parameter has no effect. Defaults to ``None``.\n\n        References\n        ----------\n        .. [1] Fischler, M.A., Bolles, R.C. (1981). Random sample consensus: A\n            Paradigm for Model Fitting with Applications to Image Analysis and\n            Automated Cartography. Communications of the ACM, 24, 381-395\n        .. [2] Jas, M., Engemann, D.A., Bekhti, Y., Raimondo, F., Gramfort, A.\n            (2017). Autoreject: Automated Artifact Rejection for MEG and EEG\n            Data. NeuroImage, 159, 417-429\n\n        \"\"\"\n    if self.EEGFiltered is None:\n        self.EEGFiltered = self._get_filtered_data()\n    exclude_from_ransac = self.bad_by_correlation + self.bad_by_deviation + self.bad_by_dropout\n    if self.matlab_strict:\n        random_state = self.random_state.get_state()\n        rng = np.random.RandomState()\n        rng.set_state(random_state)\n    else:\n        rng = self.random_state\n    (self.bad_by_ransac, ch_correlations_usable) = find_bad_by_ransac(self.EEGFiltered, self.sample_rate, self.ch_names_new, self.raw_mne._get_channel_positions()[self.usable_idx, :], exclude_from_ransac, n_samples, sample_prop, corr_thresh, frac_bad, corr_window_secs, channel_wise, max_chunk_size, rng, self.matlab_strict)\n    n_ransac_windows = ch_correlations_usable.shape[0]\n    ch_correlations = np.ones((n_ransac_windows, self.n_chans_original))\n    ch_correlations[:, self.usable_idx] = ch_correlations_usable\n    self._extra_info['bad_by_ransac'] = {'ransac_correlations': ch_correlations, 'bad_window_fractions': np.mean(ch_correlations < corr_thresh, axis=0)}"
        },
        {
          "text": "def _ransac_by_channel(data, interpolation_mats, win_size, win_count, chans_to_predict, random_ch_picks, matlab_strict):\n    \"\"\"Calculate correlations of channels with their RANSAC-predicted values.\n\n    This function calculates RANSAC correlations on one (or more) full channels\n    at once, requiring RAM equivalent to [channels per chunk * sample rate *\n    length of recording in seconds] to run. Generally, this method will use\n    more RAM than :func:`_ransac_by_window`, but may be faster for systems with\n    large amounts of RAM.\n\n    Parameters\n    ----------\n    data : np.ndarray\n        A 2-D array containing the EEG signals from all currently-good channels.\n    interpolation_mats : list of np.ndarray\n        A set of channel interpolation matrices, one for each RANSAC sample of\n        channels.\n    win_size : int\n        Number of frames/samples of EEG data in each RANSAC correlation window.\n    win_count: int\n        Number of RANSAC correlation windows.\n    chans_to_predict : list of int\n        Indices of the channels to predict (as they appear in `data`) within the\n        current chunk.\n    random_ch_picks : list of list of int\n        A list containing multiple random subsets of currently-good channels.\n    matlab_strict : bool\n        Whether or not RANSAC should strictly follow MATLAB PREP's internal\n        math, ignoring any improvements made in PyPREP over the original code.\n\n    Returns\n    -------\n    correlations : np.ndarray\n        Correlations of the given channels to their predicted values within each\n        RANSAC window.\n\n    \"\"\"\n    chunk_size = len(chans_to_predict)\n    correlations = np.ones((win_count, chunk_size))\n    predicted_chans = _predict_median_signals_channelwise(data=data, interpolation_mats=interpolation_mats, random_ch_picks=random_ch_picks, chunk_size=len(chans_to_predict), matlab_strict=matlab_strict)\n    data_window = data[chans_to_predict, :win_size * win_count]\n    data_window = data_window.reshape(chunk_size, win_count, win_size)\n    data_window = data_window.swapaxes(1, 0)\n    pred_window = predicted_chans[:chunk_size, :win_size * win_count]\n    pred_window = pred_window.reshape(chunk_size, win_count, win_size)\n    pred_window = pred_window.swapaxes(1, 0)\n    for k in range(win_count):\n        data_portion = data_window[k, :, :]\n        pred_portion = pred_window[k, :, :]\n        R = _correlate_arrays(data_portion, pred_portion, matlab_strict)\n        correlations[k, :] = R\n    return correlations"
        },
        {
          "text": "def find_all_bads(self, ransac=True, channel_wise=False, max_chunk_size=None):\n    \"\"\"Call all the functions to detect bad channels.\n\n        This function calls all the bad-channel detecting functions.\n\n        Parameters\n        ----------\n        ransac : bool, optional\n            Whether RANSAC should be used for bad channel detection, in addition\n            to the other methods. RANSAC can detect bad channels that other\n            methods are unable to catch, but also slows down noisy channel\n            detection considerably. Defaults to ``True``.\n        channel_wise : bool, optional\n            Whether RANSAC should predict signals for chunks of channels over the\n            entire signal length (\"channel-wise RANSAC\", see `max_chunk_size`\n            parameter). If ``False``, RANSAC will instead predict signals for all\n            channels at once but over a number of smaller time windows instead of\n            over the entire signal length (\"window-wise RANSAC\"). Channel-wise\n            RANSAC generally has higher RAM demands than window-wise RANSAC\n            (especially if `max_chunk_size` is ``None``), but can be faster on\n            systems with lots of RAM to spare. Has no effect if not using RANSAC.\n            Defaults to ``False``.\n        max_chunk_size : {int, None}, optional\n            The maximum number of channels to predict at once during\n            channel-wise RANSAC. If ``None``, RANSAC will use the largest chunk\n            size that will fit into the available RAM, which may slow down\n            other programs on the host system. If using window-wise RANSAC\n            (the default) or not using RANSAC at all, this parameter has no\n            effect. Defaults to ``None``.\n\n        \"\"\"\n    self.find_bad_by_deviation()\n    self.find_bad_by_hfnoise()\n    self.find_bad_by_correlation()\n    self.find_bad_by_SNR()\n    if ransac:\n        self.find_bad_by_ransac(channel_wise=channel_wise, max_chunk_size=max_chunk_size)"
        },
        {
          "text": "def _ransac_by_window(data, interpolation_mats, win_size, win_count, matlab_strict):\n    \"\"\"Calculate correlations of channels with their RANSAC-predicted values.\n\n    This function calculates RANSAC correlations for each RANSAC window\n    individually, requiring RAM equivalent to [channels * sample rate * seconds\n    per RANSAC window] to run. Generally, this method will use less RAM than\n    :func:`_ransac_by_channel`, with the exception of short recordings with high\n    electrode counts.\n\n    Parameters\n    ----------\n    data : np.ndarray\n        A 2-D array containing the EEG signals from all currently-good channels.\n    interpolation_mats : list of np.ndarray\n        A list of interpolation matrices, one for each RANSAC sample of channels.\n    win_size : int\n        Number of frames/samples of EEG data in each RANSAC correlation window.\n    win_count: int\n        Number of RANSAC correlation windows.\n    matlab_strict : bool\n        Whether or not RANSAC should strictly follow MATLAB PREP's internal\n        math, ignoring any improvements made in PyPREP over the original code.\n\n    Returns\n    -------\n    correlations : np.ndarray\n        Correlations of the given channels to their predicted values within each\n        RANSAC window.\n\n    \"\"\"\n    ch_count = data.shape[0]\n    correlations = np.ones((win_count, ch_count))\n    pb = ProgressBar(range(win_count))\n    for window in pb:\n        start = window * win_size\n        end = (window + 1) * win_size\n        actual = data[:, start:end]\n        predicted = _predict_median_signals(actual, interpolation_mats, matlab_strict)\n        correlations[window, :] = _correlate_arrays(actual, predicted, matlab_strict)\n    return correlations"
        }
      ]
    }
  }
]