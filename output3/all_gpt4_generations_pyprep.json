[["import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nfrom .cbramod import CBraMod\n\nclass Model(nn.Module):\n    def __init__(self, param):\n        super().__init__()\n        self.backbone = CBraMod(\n            in_dim=200, out_dim=200, d_model=200,\n            dim_feedforward=800, seq_len=30,\n            n_layer=12, nhead=8\n        )\n        if param.use_pretrained_weights:\n            map_location = torch.device(f'cuda:{param.cuda}')\n            self.backbone.load_state_dict(torch.load(param.foundation_dir, map_location=map_location))\n        self.backbone.proj_out = nn.Identity()\n\n        self.head = nn.Sequential(\n            nn.Linear(6*30*200, 512),\n            nn.GELU(),\n        )\n\n        encoder_layer = nn.TransformerEncoderLayer(\n            d_model=512, nhead=4, dim_feedforward=2048, batch_first=True, activation=F.gelu, norm_first=True\n        )\n        self.sequence_encoder = nn.TransformerEncoder(encoder_layer, num_layers=1, enable_nested_tensor=False)\n        self.classifier = nn.Linear(512, param.num)\n\n    def forward(self, x):\n        x = self.backbone(x)\n        x = x.view(x.size(0), -1)\n        x = self.head(x)\n        x = x.unsqueeze(1)\n        x = self.sequence_encoder(x)\n        x = x.squeeze(1)\n        x = self.classifier(x)\n        return x\n\n# Instantiate the Model class\nparam = {\n    'use_pretrained_weights': True,\n    'cuda': 0,\n    'foundation_dir': 'pretrained_weights/pretrained_weights.pth',\n    'num': 4\n}\nmodel = Model(param).to(device)\n\n# mock_eeg.shape = (batch_size, num_of_channels, time_segments, points_per_patch)\nmock_eeg = torch.randn((8, 22, 4, 200)).to(device)\n\n# logits.shape = (batch_size, num_of_classes)\nlogits = model(mock_eeg)\n\nprint(logits.shape)"]]