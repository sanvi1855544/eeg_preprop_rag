{"_id": "mne_mne_parallel.py_parallel_func_doc", "text": "Return parallel instance with delayed function.\n\nUtil function to use joblib only if available\n\nParameters\n----------\nfunc : callable\n    A function.\n%(n_jobs)s\nmax_nbytes : int | str | None\n    Threshold on the minimum size of arrays passed to the workers that\n    triggers automated memory mapping. Can be an int in Bytes,\n    or a human-readable string, e.g., '1M' for 1 megabyte.\n    Use None to disable memmaping of large arrays. Use 'auto' to\n    use the value set using :func:`mne.set_memmap_min_size`.\npre_dispatch : int | str\n    See :class:`joblib.Parallel`.\ntotal : int | None\n    If int, use a progress bar to display the progress of dispatched\n    jobs. This should only be used when directly iterating, not when\n    using ``split_list`` or :func:`np.array_split`.\n    If None (default), do not add a progress bar.\nprefer : str | None\n    If str, can be ``\"processes\"`` or ``\"threads\"``.\n    See :class:`joblib.Parallel`.\n\n    .. versionadded:: 0.18\nmax_jobs : int | None\n    The upper limit of jobs to use. This is useful when you know ahead\n    of a the maximum number of calls into :class:`joblib.Parallel` that\n    you will possibly want or need, and the returned ``n_jobs`` should not\n    exceed this value regardless of how many jobs the user requests.\n%(verbose)s INFO or DEBUG\n    will print parallel status, others will not.\n\nReturns\n-------\nparallel: instance of joblib.Parallel or list\n    The parallel object.\nmy_func: callable\n    ``func`` if not parallel or delayed(func).\nn_jobs: int\n    Number of jobs >= 1.", "metadata": {}}
{"_id": "mne_mne_cov.py_read_cov_doc", "text": "Read a noise covariance from a FIF file.\n\nParameters\n----------\nfname : path-like\n    The path-like of file containing the covariance matrix. It should end\n    with ``-cov.fif`` or ``-cov.fif.gz``.\n%(verbose)s\n\nReturns\n-------\ncov : Covariance\n    The noise covariance matrix.\n\nSee Also\n--------\nwrite_cov, compute_covariance, compute_raw_covariance", "metadata": {}}
{"_id": "mne_mne_cov.py_make_ad_hoc_cov_doc", "text": "Create an ad hoc noise covariance.\n\nParameters\n----------\n%(info_not_none)s\nstd : dict of float | None\n    Standard_deviation of the diagonal elements. If dict, keys should be\n    ``'grad'`` for gradiometers, ``'mag'`` for magnetometers and ``'eeg'``\n    for EEG channels. If None, default values will be used (see Notes).\n%(verbose)s\n\nReturns\n-------\ncov : instance of Covariance\n    The ad hoc diagonal noise covariance for the M/EEG data channels.\n\nNotes\n-----\nThe default noise values are 5 fT/cm, 20 fT, and 0.2 \u00b5V for gradiometers,\nmagnetometers, and EEG channels respectively.\n\n.. versionadded:: 0.9.0", "metadata": {}}
{"_id": "mne_mne_cov.py_compute_raw_covariance_doc", "text": "Estimate noise covariance matrix from a continuous segment of raw data.\n\nIt is typically useful to estimate a noise covariance from empty room\ndata or time intervals before starting the stimulation.\n\n.. note:: To estimate the noise covariance from epoched data, use\n          :func:`mne.compute_covariance` instead.\n\nParameters\n----------\nraw : instance of Raw\n    Raw data.\ntmin : float\n    Beginning of time interval in seconds. Defaults to 0.\ntmax : float | None (default None)\n    End of time interval in seconds. If None (default), use the end of the\n    recording.\ntstep : float (default 0.2)\n    Length of data chunks for artifact rejection in seconds.\n    Can also be None to use a single epoch of (tmax - tmin)\n    duration. This can use a lot of memory for large ``Raw``\n    instances.\nreject : dict | None (default None)\n    Rejection parameters based on peak-to-peak amplitude.\n    Valid keys are 'grad' | 'mag' | 'eeg' | 'eog' | 'ecg'.\n    If reject is None then no rejection is done. Example::\n\n        reject = dict(grad=4000e-13, # T / m (gradiometers)\n                      mag=4e-12, # T (magnetometers)\n                      eeg=40e-6, # V (EEG channels)\n                      eog=250e-6 # V (EOG channels)\n                      )\n\nflat : dict | None (default None)\n    Rejection parameters based on flatness of signal.\n    Valid keys are 'grad' | 'mag' | 'eeg' | 'eog' | 'ecg', and values\n    are floats that set the minimum acceptable peak-to-peak amplitude.\n    If flat is None then no rejection is done.\n%(picks_good_data_noref)s\nmethod : str | list | None (default 'empirical')\n    The method used for covariance estimation.\n    See :func:`mne.compute_covariance`.\n\n    .. versionadded:: 0.12\nmethod_params : dict | None (default None)\n    Additional parameters to the estimation procedure.\n    See :func:`mne.compute_covariance`.\n\n    .. versionadded:: 0.12\ncv : int | sklearn.model_selection object (default 3)\n    The cross validation method. Defaults to 3, which will\n    internally trigger by default :class:`sklearn.model_selection.KFold`\n    with 3 splits.\n\n    .. versionadded:: 0.12\nscalings : dict | None (default None)\n    Defaults to ``dict(mag=1e15, grad=1e13, eeg=1e6)``.\n    These defaults will scale magnetometers and gradiometers\n    at the same unit.\n\n    .. versionadded:: 0.12\n%(n_jobs)s\n\n    .. versionadded:: 0.12\nreturn_estimators : bool (default False)\n    Whether to return all estimators or the best. Only considered if\n    method equals 'auto' or is a list of str. Defaults to False.\n\n    .. versionadded:: 0.12\n%(reject_by_annotation_epochs)s\n\n    .. versionadded:: 0.14\n%(rank_none)s\n\n    .. versionadded:: 0.17\n\n    .. versionadded:: 0.18\n       Support for 'info' mode.\n%(verbose)s\n\nReturns\n-------\ncov : instance of Covariance | list\n    The computed covariance. If method equals 'auto' or is a list of str\n    and return_estimators equals True, a list of covariance estimators is\n    returned (sorted by log-likelihood, from high to low, i.e. from best\n    to worst).\n\nSee Also\n--------\ncompute_covariance : Estimate noise covariance matrix from epoched data.\n\nNotes\n-----\nThis function will:\n\n1. Partition the data into evenly spaced, equal-length epochs.\n2. Load them into memory.\n3. Subtract the mean across all time points and epochs for each channel.\n4. Process the :class:`Epochs` by :func:`compute_covariance`.\n\nThis will produce a slightly different result compared to using\n:func:`make_fixed_length_events`, :class:`Epochs`, and\n:func:`compute_covariance` directly, since that would (with the recommended\nbaseline correction) subtract the mean across time *for each epoch*\n(instead of across epochs) for each channel.", "metadata": {}}
{"_id": "mne_mne_cov.py_compute_covariance_doc", "text": "Estimate noise covariance matrix from epochs.\n\nThe noise covariance is typically estimated on pre-stimulus periods\nwhen the stimulus onset is defined from events.\n\nIf the covariance is computed for multiple event types (events\nwith different IDs), the following two options can be used and combined:\n\n    1. either an Epochs object for each event type is created and\n       a list of Epochs is passed to this function.\n    2. an Epochs object is created for multiple events and passed\n       to this function.\n\n.. note:: To estimate the noise covariance from non-epoched raw data, such\n          as an empty-room recording, use\n          :func:`mne.compute_raw_covariance` instead.\n\nParameters\n----------\nepochs : instance of Epochs, or list of Epochs\n    The epochs.\nkeep_sample_mean : bool (default True)\n    If False, the average response over epochs is computed for\n    each event type and subtracted during the covariance\n    computation. This is useful if the evoked response from a\n    previous stimulus extends into the baseline period of the next.\n    Note. This option is only implemented for method='empirical'.\ntmin : float | None (default None)\n    Start time for baseline. If None start at first sample.\ntmax : float | None (default None)\n    End time for baseline. If None end at last sample.\nprojs : list of Projection | None (default None)\n    List of projectors to use in covariance calculation, or None\n    to indicate that the projectors from the epochs should be\n    inherited. If None, then projectors from all epochs must match.\nmethod : str | list | None (default 'empirical')\n    The method used for covariance estimation. If 'empirical' (default),\n    the sample covariance will be computed. A list can be passed to\n    perform estimates using multiple methods.\n    If 'auto' or a list of methods, the best estimator will be determined\n    based on log-likelihood and cross-validation on unseen data as\n    described in :footcite:`EngemannGramfort2015`. Valid methods are\n    'empirical', 'diagonal_fixed', 'shrunk', 'oas', 'ledoit_wolf',\n    'factor_analysis', 'shrinkage', and 'pca' (see Notes). If ``'auto'``,\n    it expands to::\n\n         ['shrunk', 'diagonal_fixed', 'empirical', 'factor_analysis']\n\n    ``'factor_analysis'`` is removed when ``rank`` is not 'full'.\n    The ``'auto'`` mode is not recommended if there are many\n    segments of data, since computation can take a long time.\n\n    .. versionadded:: 0.9.0\nmethod_params : dict | None (default None)\n    Additional parameters to the estimation procedure. Only considered if\n    method is not None. Keys must correspond to the value(s) of ``method``.\n    If None (default), expands to the following (with the addition of\n    ``{'store_precision': False, 'assume_centered': True} for all methods\n    except ``'factor_analysis'`` and ``'pca'``)::\n\n        {'diagonal_fixed': {'grad': 0.1, 'mag': 0.1, 'eeg': 0.1, ...},\n         'shrinkage': {'shrinkage': 0.1},\n         'shrunk': {'shrinkage': np.logspace(-4, 0, 30)},\n         'pca': {'iter_n_components': None},\n         'factor_analysis': {'iter_n_components': None}}\n\ncv : int | sklearn.model_selection object (default 3)\n    The cross validation method. Defaults to 3, which will\n    internally trigger by default :class:`sklearn.model_selection.KFold`\n    with 3 splits.\nscalings : dict | None (default None)\n    Defaults to ``dict(mag=1e15, grad=1e13, eeg=1e6)``.\n    These defaults will scale data to roughly the same order of\n    magnitude.\n%(n_jobs)s\nreturn_estimators : bool (default False)\n    Whether to return all estimators or the best. Only considered if\n    method equals 'auto' or is a list of str. Defaults to False.\non_mismatch : str\n    What to do when the MEG<->Head transformations do not match between\n    epochs. If \"raise\" (default) an error is raised, if \"warn\" then a\n    warning is emitted, if \"ignore\" then nothing is printed. Having\n    mismatched transforms can in some cases lead to unexpected or\n    unstable results in covariance calculation, e.g. when data\n    have been processed with Maxwell filtering but not transformed\n    to the same head position.\n%(rank_none)s\n\n    .. versionadded:: 0.17\n\n    .. versionadded:: 0.18\n       Support for 'info' mode.\n%(verbose)s\n\nReturns\n-------\ncov : instance of Covariance | list\n    The computed covariance. If method equals ``'auto'`` or is a list of str\n    and ``return_estimators=True``, a list of covariance estimators is\n    returned (sorted by log-likelihood, from high to low, i.e. from best\n    to worst).\n\nSee Also\n--------\ncompute_raw_covariance : Estimate noise covariance from raw data, such as\n    empty-room recordings.\n\nNotes\n-----\nBaseline correction or sufficient high-passing should be used\nwhen creating the :class:`Epochs` to ensure that the data are zero mean,\notherwise the computed covariance matrix will be inaccurate.\n\nValid ``method`` strings are:\n\n* ``'empirical'``\n    The empirical or sample covariance (default)\n* ``'diagonal_fixed'``\n    A diagonal regularization based on channel types as in\n    :func:`mne.cov.regularize`.\n* ``'shrinkage'``\n    Fixed shrinkage.\n\n  .. versionadded:: 0.16\n* ``'ledoit_wolf'``\n    The Ledoit-Wolf estimator, which uses an\n    empirical formula for the optimal shrinkage value :footcite:`LedoitWolf2004`.\n* ``'oas'``\n    The OAS estimator :footcite:`ChenEtAl2010`, which uses a different\n    empricial formula for the optimal shrinkage value.\n\n  .. versionadded:: 0.16\n* ``'shrunk'``\n    Like 'ledoit_wolf', but with cross-validation for optimal alpha.\n* ``'pca'``\n    Probabilistic PCA with low rank :footcite:`TippingBishop1999`.\n* ``'factor_analysis'``\n    Factor analysis with low rank :footcite:`Barber2012`.\n\n``'ledoit_wolf'`` and ``'pca'`` are similar to ``'shrunk'`` and\n``'factor_analysis'``, respectively, except that they use\ncross validation (which is useful when samples are correlated, which\nis often the case for M/EEG data). The former two are not included in\nthe ``'auto'`` mode to avoid redundancy.\n\nFor multiple event types, it is also possible to create a\nsingle :class:`Epochs` object with events obtained using\n:func:`mne.merge_events`. However, the resulting covariance matrix\nwill only be correct if ``keep_sample_mean is True``.\n\nThe covariance can be unstable if the number of samples is small.\nIn that case it is common to regularize the covariance estimate.\nThe ``method`` parameter allows to regularize the covariance in an\nautomated way. It also allows to select between different alternative\nestimation algorithms which themselves achieve regularization.\nDetails are described in :footcite:t:`EngemannGramfort2015`.\n\nFor more information on the advanced estimation methods, see\n:ref:`the sklearn manual <sklearn:covariance>`.\n\nReferences\n----------\n.. footbibliography::", "metadata": {}}
{"_id": "mne_mne_cov.py_write_cov_doc", "text": "Write a noise covariance matrix.\n\nParameters\n----------\nfname : path-like\n    The name of the file. It should end with ``-cov.fif`` or\n    ``-cov.fif.gz``.\ncov : Covariance\n    The noise covariance matrix.\n%(overwrite)s\n\n    .. versionadded:: 1.0\n%(verbose)s\n\nSee Also\n--------\nread_cov", "metadata": {}}
{"_id": "mne_mne_cov.py_prepare_noise_cov_doc", "text": "Prepare noise covariance matrix.\n\nParameters\n----------\nnoise_cov : instance of Covariance\n    The noise covariance to process.\n%(info_not_none)s (Used to get channel types and bad channels).\nch_names : list | None\n    The channel names to be considered. Can be None to use\n    ``info['ch_names']``.\n%(rank_none)s\n\n    .. versionadded:: 0.18\n       Support for 'info' mode.\nscalings : dict | None\n    Data will be rescaled before rank estimation to improve accuracy.\n    If dict, it will override the following dict (default if None)::\n\n        dict(mag=1e12, grad=1e11, eeg=1e5)\n%(on_rank_mismatch)s\n%(verbose)s\n\nReturns\n-------\ncov : instance of Covariance\n    A copy of the covariance with the good channels subselected\n    and parameters updated.", "metadata": {}}
{"_id": "mne_mne_cov.py_regularize_doc", "text": "Regularize noise covariance matrix.\n\nThis method works by adding a constant to the diagonal for each\nchannel type separately. Special care is taken to keep the\nrank of the data constant.\n\n.. note:: This function is kept for reasons of backward-compatibility.\n          Please consider explicitly using the ``method`` parameter in\n          :func:`mne.compute_covariance` to directly combine estimation\n          with regularization in a data-driven fashion. See the\n          :ref:`FAQ <faq_how_should_i_regularize>` for more information.\n\nParameters\n----------\ncov : Covariance\n    The noise covariance matrix.\n%(info_not_none)s (Used to get channel types and bad channels).\nmag : float (default 0.1)\n    Regularization factor for MEG magnetometers.\ngrad : float (default 0.1)\n    Regularization factor for MEG gradiometers. Must be the same as\n    ``mag`` if data have been processed with SSS.\neeg : float (default 0.1)\n    Regularization factor for EEG.\nexclude : list | 'bads' (default 'bads')\n    List of channels to mark as bad. If 'bads', bads channels\n    are extracted from both info['bads'] and cov['bads'].\nproj : bool (default True)\n    Apply projections to keep rank of data.\nseeg : float (default 0.1)\n    Regularization factor for sEEG signals.\necog : float (default 0.1)\n    Regularization factor for ECoG signals.\nhbo : float (default 0.1)\n    Regularization factor for HBO signals.\nhbr : float (default 0.1)\n    Regularization factor for HBR signals.\nfnirs_cw_amplitude : float (default 0.1)\n    Regularization factor for fNIRS CW raw signals.\nfnirs_fd_ac_amplitude : float (default 0.1)\n    Regularization factor for fNIRS FD AC raw signals.\nfnirs_fd_phase : float (default 0.1)\n    Regularization factor for fNIRS raw phase signals.\nfnirs_od : float (default 0.1)\n    Regularization factor for fNIRS optical density signals.\ncsd : float (default 0.1)\n    Regularization factor for EEG-CSD signals.\ndbs : float (default 0.1)\n    Regularization factor for DBS signals.\n%(rank_none)s\n\n    .. versionadded:: 0.17\n\n    .. versionadded:: 0.18\n       Support for 'info' mode.\nscalings : dict | None\n    Data will be rescaled before rank estimation to improve accuracy.\n    See :func:`mne.compute_covariance`.\n\n    .. versionadded:: 0.17\n%(verbose)s\n\nReturns\n-------\nreg_cov : Covariance\n    The regularized covariance matrix.\n\nSee Also\n--------\nmne.compute_covariance", "metadata": {}}
{"_id": "mne_mne_cov.py_compute_whitener_doc", "text": "Compute whitening matrix.\n\nParameters\n----------\nnoise_cov : Covariance\n    The noise covariance.\n%(info)s Can be None if ``noise_cov`` has already been\n    prepared with :func:`prepare_noise_cov`.\n%(picks_good_data_noref)s\n%(rank_none)s\n\n    .. versionadded:: 0.18\n       Support for 'info' mode.\nscalings : dict | None\n    The rescaling method to be applied. See documentation of\n    ``prepare_noise_cov`` for details.\nreturn_rank : bool\n    If True, return the rank used to compute the whitener.\n\n    .. versionadded:: 0.15\npca : bool | str\n    Space to project the data into. Options:\n\n    :data:`python:True`\n        Whitener will be shape (n_nonzero, n_channels).\n    ``'white'``\n        Whitener will be shape (n_channels, n_channels), potentially rank\n        deficient, and have the first ``n_channels - n_nonzero`` rows and\n        columns set to zero.\n    :data:`python:False` (default)\n        Whitener will be shape (n_channels, n_channels), potentially rank\n        deficient, and rotated back to the space of the original data.\n\n    .. versionadded:: 0.18\nreturn_colorer : bool\n    If True, return the colorer as well.\n%(on_rank_mismatch)s\n%(verbose)s\n\nReturns\n-------\nW : ndarray, shape (n_channels, n_channels) or (n_nonzero, n_channels)\n    The whitening matrix.\nch_names : list\n    The channel names.\nrank : int\n    Rank reduction of the whitener. Returned only if return_rank is True.\ncolorer : ndarray, shape (n_channels, n_channels) or (n_channels, n_nonzero)\n    The coloring matrix.", "metadata": {}}
{"_id": "mne_mne_cov.py_whiten_evoked_doc", "text": "Whiten evoked data using given noise covariance.\n\nParameters\n----------\nevoked : instance of Evoked\n    The evoked data.\nnoise_cov : instance of Covariance\n    The noise covariance.\n%(picks_good_data)s\ndiag : bool (default False)\n    If True, whiten using only the diagonal of the covariance.\n%(rank_none)s\n\n    .. versionadded:: 0.18\n       Support for 'info' mode.\nscalings : dict | None (default None)\n    To achieve reliable rank estimation on multiple sensors,\n    sensors have to be rescaled. This parameter controls the\n    rescaling. If dict, it will override the\n    following default dict (default if None):\n\n        dict(mag=1e12, grad=1e11, eeg=1e5)\n%(verbose)s\n\nReturns\n-------\nevoked_white : instance of Evoked\n    The whitened evoked data.", "metadata": {}}
{"_id": "mne_mne_cov.py_data_doc", "text": "Numpy array of Noise covariance matrix.", "metadata": {}}
{"_id": "mne_mne_cov.py_ch_names_doc", "text": "Channel names.", "metadata": {}}
{"_id": "mne_mne_cov.py_nfree_doc", "text": "Number of degrees of freedom.", "metadata": {}}
{"_id": "mne_mne_cov.py_save_doc", "text": "Save covariance matrix in a FIF file.\n\nParameters\n----------\nfname : path-like\n    Output filename.\n%(overwrite)s\n\n    .. versionadded:: 1.0\n%(verbose)s", "metadata": {}}
{"_id": "mne_mne_cov.py_copy_doc", "text": "Copy the Covariance object.\n\nReturns\n-------\ncov : instance of Covariance\n    The copied object.", "metadata": {}}
{"_id": "mne_mne_cov.py_as_diag_doc", "text": "Set covariance to be processed as being diagonal.\n\nReturns\n-------\ncov : dict\n    The covariance.\n\nNotes\n-----\nThis function allows creation of inverse operators\nequivalent to using the old \"--diagnoise\" mne option.\n\nThis function operates in place.", "metadata": {}}
{"_id": "mne_mne_cov.py_plot_topomap_doc", "text": "Plot a topomap of the covariance diagonal.\n\nParameters\n----------\n%(info_not_none)s\n%(ch_type_topomap)s\n\n    .. versionadded:: 0.21\n%(scalings_topomap)s\n%(proj_plot)s\nnoise_cov : instance of Covariance | None\n    If not None, whiten the instance with ``noise_cov`` before\n    plotting.\n%(sensors_topomap)s\n%(show_names_topomap)s\n%(mask_topomap)s\n%(mask_params_topomap)s\n%(contours_topomap)s\n%(outlines_topomap)s\n%(sphere_topomap_auto)s\n%(image_interp_topomap)s\n%(extrapolate_topomap)s\n\n    .. versionchanged:: 0.21\n\n       - The default was changed to ``'local'`` for MEG sensors.\n       - ``'local'`` was changed to use a convex hull mask\n       - ``'head'`` was changed to extrapolate out to the clipping circle.\n%(border_topomap)s\n\n    .. versionadded:: 0.20\n%(res_topomap)s\n%(size_topomap)s\n%(cmap_topomap)s\n%(vlim_plot_topomap)s\n\n    .. versionadded:: 1.2\n%(cnorm)s\n\n    .. versionadded:: 1.2\n%(colorbar_topomap)s\n%(cbar_fmt_topomap)s\n%(units_topomap_evoked)s\n%(axes_cov_plot_topomap)s\n%(show)s\n%(verbose)s\n\nReturns\n-------\nfig : instance of Figure\n    The matplotlib figure.\n\nNotes\n-----\n.. versionadded:: 0.21", "metadata": {}}
{"_id": "mne_mne_cov.py_pick_channels_doc", "text": "Pick channels from this covariance matrix.\n\nParameters\n----------\nch_names : list of str\n    List of channels to keep. All other channels are dropped.\n%(ordered)s\n%(verbose)s\n\nReturns\n-------\ncov : instance of Covariance.\n    The modified covariance matrix.\n\nNotes\n-----\nOperates in-place.\n\n.. versionadded:: 0.20.0", "metadata": {}}
{"_id": "mne_mne_cov.py_fit_doc", "text": "Fit covariance model with classical diagonal regularization.", "metadata": {}}
{"_id": "mne_mne_cov.py_score_doc", "text": "Delegate call to modified EmpiricalCovariance instance.", "metadata": {}}
{"_id": "mne_mne_cov.py_get_precision_doc", "text": "Delegate call to modified EmpiricalCovariance instance.", "metadata": {}}
{"_id": "mne_mne_cov.py_fit_doc", "text": "Fit covariance model with oracle shrinkage regularization.", "metadata": {}}
{"_id": "mne_mne_cov.py_score_doc", "text": "Delegate to modified EmpiricalCovariance instance.", "metadata": {}}
{"_id": "mne_mne_cov.py_get_precision_doc", "text": "Delegate to modified EmpiricalCovariance instance.", "metadata": {}}
{"_id": "mne_mne_label.py_read_label_doc", "text": "Read FreeSurfer Label file.\n\nParameters\n----------\nfilename : str\n    Path to label file.\n%(subject_label)s\n    It is good practice to set this attribute to avoid combining\n    incompatible labels and SourceEstimates (e.g., ones from other\n    subjects). Note that due to file specification limitations, the\n    subject name isn't saved to or loaded from files written to disk.\ncolor : None | matplotlib color\n    Default label color and alpha (e.g., ``(1., 0., 0., 1.)`` for red).\n    Note that due to file specification limitations, the color isn't saved\n    to or loaded from files written to disk.\n%(verbose)s\n\nReturns\n-------\nlabel : Label\n    Instance of Label object with attributes:\n\n        - ``comment``: comment from the first line of the label file\n        - ``vertices``: vertex indices (0 based, column 1)\n        - ``pos``: locations in meters (columns 2 - 4 divided by 1000)\n        - ``values``: values at the vertices (column 5)\n\nSee Also\n--------\nread_labels_from_annot\nwrite_labels_to_annot", "metadata": {}}
{"_id": "mne_mne_label.py_write_label_doc", "text": "Write a FreeSurfer label.\n\nParameters\n----------\nfilename : str\n    Path to label file to produce.\nlabel : Label\n    The label object to save.\n%(verbose)s\n\nSee Also\n--------\nwrite_labels_to_annot\n\nNotes\n-----\nNote that due to file specification limitations, the Label's subject and\ncolor attributes are not saved to disk.", "metadata": {}}
{"_id": "mne_mne_label.py_split_label_doc", "text": "Split a Label into two or more parts.\n\nParameters\n----------\nlabel : Label | str\n    Label which is to be split (Label object or path to a label file).\nparts : int >= 2 | tuple of str\n    A sequence of strings specifying label names for the new labels (from\n    posterior to anterior), or the number of new labels to create (default\n    is 2). If a number is specified, names of the new labels will be the\n    input label's name with div1, div2 etc. appended.\n%(subject_label)s\n%(subjects_dir)s\nfreesurfer : bool\n    By default (``False``) ``split_label`` uses an algorithm that is\n    slightly optimized for performance and numerical precision. Set\n    ``freesurfer`` to ``True`` in order to replicate label splits from\n    FreeSurfer's ``mris_divide_parcellation``.\n\nReturns\n-------\nlabels : list of Label, shape (n_parts,)\n    The labels, starting from the lowest to the highest end of the\n    projection axis.\n\nNotes\n-----\nWorks by finding the label's principal eigen-axis on the spherical surface,\nprojecting all label vertex coordinates onto this axis and dividing them at\nregular spatial intervals.", "metadata": {}}
{"_id": "mne_mne_label.py_label_sign_flip_doc", "text": "Compute sign for label averaging.\n\nParameters\n----------\nlabel : Label | BiHemiLabel\n    A label.\nsrc : SourceSpaces\n    The source space over which the label is defined.\n\nReturns\n-------\nflip : array\n    Sign flip vector (contains 1 or -1).", "metadata": {}}
{"_id": "mne_mne_label.py_stc_to_label_doc", "text": "Compute a label from the non-zero sources in an stc object.\n\nParameters\n----------\nstc : SourceEstimate\n    The source estimates.\nsrc : SourceSpaces | str | None\n    The source space over which the source estimates are defined.\n    If it's a string it should the subject name (e.g. fsaverage).\n    Can be None if stc.subject is not None.\nsmooth : bool\n    Fill in vertices on the cortical surface that are not in the source\n    space based on the closest source space vertex (requires\n    src to be a SourceSpace).\nconnected : bool\n    If True a list of connected labels will be returned in each\n    hemisphere. The labels are ordered in decreasing order depending\n    of the maximum value in the stc.\n%(subjects_dir)s\n%(verbose)s\n\nReturns\n-------\nlabels : list of Label | list of list of Label\n    The generated labels. If connected is False, it returns\n    a list of Labels (one per hemisphere). If no Label is available\n    in a hemisphere, None is returned. If connected is True,\n    it returns for each hemisphere a list of connected labels\n    ordered in decreasing order depending of the maximum value in the stc.\n    If no Label is available in an hemisphere, an empty list is returned.", "metadata": {}}
{"_id": "mne_mne_label.py_grow_labels_doc", "text": "Generate circular labels in source space with region growing.\n\nThis function generates a number of labels in source space by growing\nregions starting from the vertices defined in \"seeds\". For each seed, a\nlabel is generated containing all vertices within a maximum geodesic\ndistance on the white matter surface from the seed.\n\nParameters\n----------\n%(subject)s\nseeds : int | list\n    Seed, or list of seeds. Each seed can be either a vertex number or\n    a list of vertex numbers.\nextents : array | float\n    Extents (radius in mm) of the labels.\nhemis : array | int\n    Hemispheres to use for the labels (0: left, 1: right).\n%(subjects_dir)s\n%(n_jobs)s\n    Likely only useful if tens or hundreds of labels are being expanded\n    simultaneously. Does not apply with ``overlap=False``.\noverlap : bool\n    Produce overlapping labels. If True (default), the resulting labels\n    can be overlapping. If False, each label will be grown one step at a\n    time, and occupied territory will not be invaded.\nnames : None | list of str\n    Assign names to the new labels (list needs to have the same length as\n    seeds).\n%(surface)s\ncolors : array, shape (n, 4) or (, 4) | None\n    How to assign colors to each label. If None then unique colors will be\n    chosen automatically (default), otherwise colors will be broadcast\n    from the array. The first three values will be interpreted as RGB\n    colors and the fourth column as the alpha value (commonly 1).\n\nReturns\n-------\nlabels : list of Label\n    The labels' ``comment`` attribute contains information on the seed\n    vertex and extent; the ``values``  attribute contains distance from the\n    seed in millimeters.\n\nNotes\n-----\n\"extents\" and \"hemis\" can either be arrays with the same length as\nseeds, which allows using a different extent and hemisphere for\nlabel, or integers, in which case the same extent and hemisphere is\nused for each label.", "metadata": {}}
{"_id": "mne_mne_label.py_random_parcellation_doc", "text": "Generate random cortex parcellation by growing labels.\n\nThis function generates a number of labels which don't intersect and\ncover the whole surface. Regions are growing around randomly chosen\nseeds.\n\nParameters\n----------\n%(subject)s\nn_parcel : int\n    Total number of cortical parcels.\nhemi : str\n    Hemisphere id (ie ``'lh'``, ``'rh'``, ``'both'``). In the case\n    of ``'both'``, both hemispheres are processed with ``(n_parcel // 2)``\n    parcels per hemisphere.\n%(subjects_dir)s\n%(surface)s\n%(random_state)s\n\nReturns\n-------\nlabels : list of Label\n    Random cortex parcellation.", "metadata": {}}
{"_id": "mne_mne_label.py_read_labels_from_annot_doc", "text": "Read labels from a FreeSurfer annotation file.\n\nNote: Only cortical labels will be returned.\n\nParameters\n----------\n%(subject)s\nparc : str\n    The parcellation to use, e.g., ``'aparc'`` or ``'aparc.a2009s'``.\nhemi : str\n    The hemisphere from which to read the parcellation, can be ``'lh'``,\n    ``'rh'``, or ``'both'``.\nsurf_name : str\n    Surface used to obtain vertex locations, e.g., ``'white'``, ``'pial'``.\nannot_fname : path-like | None\n    Filename of the ``.annot`` file. If not None, only this file is read\n    and the arguments ``parc`` and ``hemi`` are ignored.\nregexp : str\n    Regular expression or substring to select particular labels from the\n    parcellation. E.g. ``'superior'`` will return all labels in which this\n    substring is contained.\n%(subjects_dir)s\nsort : bool\n    If true, labels will be sorted by name before being returned.\n\n    .. versionadded:: 0.21.0\n%(verbose)s\n\nReturns\n-------\nlabels : list of Label\n    The labels, sorted by label name (ascending).\n\nSee Also\n--------\nwrite_labels_to_annot\nmorph_labels", "metadata": {}}
{"_id": "mne_mne_label.py_morph_labels_doc", "text": "Morph a set of labels.\n\nThis is useful when morphing a set of non-overlapping labels (such as those\nobtained with :func:`read_labels_from_annot`) from one subject to\nanother.\n\nParameters\n----------\nlabels : list\n    The labels to morph.\nsubject_to : str\n    The subject to morph labels to.\nsubject_from : str | None\n    The subject to morph labels from. Can be None if the labels\n    have the ``.subject`` property defined.\n%(subjects_dir)s\nsurf_name : str\n    Surface used to obtain vertex locations, e.g., ``'white'``, ``'pial'``.\n%(verbose)s\n\nReturns\n-------\nlabels : list\n    The morphed labels.\n\nSee Also\n--------\nread_labels_from_annot\nmne.Label.morph\n\nNotes\n-----\nThis does not use the same algorithm as Freesurfer, so the results\nmorphing (e.g., from ``'fsaverage'`` to your subject) might not match\nwhat Freesurfer produces during ``recon-all``.\n\n.. versionadded:: 0.18", "metadata": {}}
{"_id": "mne_mne_label.py_labels_to_stc_doc", "text": "Convert a set of labels and values to a STC.\n\nThis function is meant to work like the opposite of\n`extract_label_time_course`.\n\nParameters\n----------\n%(labels_eltc)s\nvalues : ndarray, shape (n_labels, ...)\n    The values in each label. Can be 1D or 2D.\ntmin : float\n    The tmin to use for the STC.\ntstep : float\n    The tstep to use for the STC.\n%(subject)s\n%(src_eltc)s\n    Can be omitted if using a surface source space, in which case\n    the label vertices will determine the output STC vertices.\n    Required if using a volumetric source space.\n\n    .. versionadded:: 0.22\n%(verbose)s\n\nReturns\n-------\nstc : instance of SourceEstimate | instance of VolSourceEstimate\n    The values-in-labels converted to a STC.\n\nSee Also\n--------\nextract_label_time_course\n\nNotes\n-----\nVertices that appear in more than one label will be averaged.\n\n.. versionadded:: 0.18", "metadata": {}}
{"_id": "mne_mne_label.py_write_labels_to_annot_doc", "text": "Create a FreeSurfer annotation from a list of labels.\n\nParameters\n----------\nlabels : list with instances of mne.Label\n    The labels to create a parcellation from.\n%(subject)s\nparc : str | None\n    The parcellation name to use.\noverwrite : bool\n    Overwrite files if they already exist.\n%(subjects_dir)s\nannot_fname : str | None\n    Filename of the ``.annot file``. If not None, only this file is written\n    and the arguments ``parc`` and ``subject`` are ignored.\ncolormap : str\n    Colormap to use to generate label colors for labels that do not\n    have a color specified.\nhemi : ``'both'`` | ``'lh'`` | ``'rh'``\n    The hemisphere(s) for which to write \\*.annot files (only applies if\n    annot_fname is not specified; default is 'both').\nsort : bool\n    If True (default), labels will be sorted by name before writing.\n\n    .. versionadded:: 0.21.0\ntable_name : str\n    The table name to use for the colortable.\n\n    .. versionadded:: 0.21.0\n%(verbose)s\n\nSee Also\n--------\nread_labels_from_annot\n\nNotes\n-----\nVertices that are not covered by any of the labels are assigned to a label\nnamed ``\"unknown\"``.", "metadata": {}}
{"_id": "mne_mne_label.py_select_sources_doc", "text": "Select sources from a label.\n\nParameters\n----------\n%(subject)s\nlabel : instance of Label | str\n    Define where the seed will be chosen. If str, can be 'lh' or 'rh',\n    which correspond to left or right hemisphere, respectively.\nlocation : 'random' | 'center' | int\n    Location to grow label from. If the location is an int, it represents\n    the vertex number in the corresponding label. If it is a str, it can be\n    either 'random' or 'center'.\nextent : float\n    Extents (radius in mm) of the labels, i.e. maximum geodesic distance\n    on the white matter surface from the seed. If 0, the resulting label\n    will contain only one vertex.\ngrow_outside : bool\n    Let the region grow outside the original label where location was\n    defined.\n%(subjects_dir)s\nname : None | str\n    Assign name to the new label.\n%(random_state)s\nsurf : str\n    The surface used to simulated the label, defaults to the white surface.\n\nReturns\n-------\nlabel : instance of Label\n    The label that contains the selected sources.\n\nNotes\n-----\nThis function selects a region of interest on the cortical surface based\non a label (or a hemisphere). The sources are selected by growing a region\naround a seed which is selected randomly, is the center of the label, or\nis a specific vertex. The selected vertices can extend beyond the initial\nprovided label. This can be prevented by setting grow_outside to False.\n\nThe selected sources are returned in the form of a new Label object. The\nvalues of the label contain the distance from the seed in millimeters.\n\n.. versionadded:: 0.18", "metadata": {}}
{"_id": "mne_mne_label.py_save_doc", "text": "Write to disk as FreeSurfer \\*.label file.\n\nParameters\n----------\nfilename : path-like\n    Path to label file to produce.\n\nNotes\n-----\nNote that due to file specification limitations, the Label's subject\nand color attributes are not saved to disk.", "metadata": {}}
{"_id": "mne_mne_label.py_copy_doc", "text": "Copy the label instance.\n\nReturns\n-------\nlabel : instance of Label\n    The copied label.", "metadata": {}}
{"_id": "mne_mne_label.py_fill_doc", "text": "Fill the surface between sources for a source space label.\n\nParameters\n----------\nsrc : SourceSpaces\n    Source space in which the label was defined. If a source space is\n    provided, the label is expanded to fill in surface vertices that\n    lie between the vertices included in the source space. For the\n    added vertices, ``pos`` is filled in with positions from the\n    source space, and ``values`` is filled in from the closest source\n    space vertex.\nname : None | str\n    Name for the new Label (default is self.name).\n\nReturns\n-------\nlabel : Label\n    The label covering the same vertices in source space but also\n    including intermediate surface vertices.\n\nSee Also\n--------\nLabel.restrict\nLabel.smooth", "metadata": {}}
{"_id": "mne_mne_label.py_restrict_doc", "text": "Restrict a label to a source space.\n\nParameters\n----------\nsrc : instance of SourceSpaces\n    The source spaces to use to restrict the label.\nname : None | str\n    Name for the new Label (default is self.name).\n\nReturns\n-------\nlabel : instance of Label\n    The Label restricted to the set of source space vertices.\n\nSee Also\n--------\nLabel.fill\n\nNotes\n-----\n.. versionadded:: 0.20", "metadata": {}}
{"_id": "mne_mne_label.py_smooth_doc", "text": "Smooth the label.\n\nUseful for filling in labels made in a\ndecimated source space for display.\n\nParameters\n----------\n%(subject_label)s\nsmooth : int\n    Number of iterations for the smoothing of the surface data.\n    Cannot be None here since not all vertices are used. For a\n    grade of 5 (e.g., fsaverage), a smoothing of 2 will fill a\n    label.\ngrade : int, list of shape (2,), array, or None\n    Resolution of the icosahedral mesh (typically 5). If None, all\n    vertices will be used (potentially filling the surface). If a list,\n    values will be morphed to the set of vertices specified in grade[0]\n    and grade[1], assuming that these are vertices for the left and\n    right hemispheres. Note that specifying the vertices (e.g.,\n    grade=[np.arange(10242), np.arange(10242)] for fsaverage on a\n    standard grade 5 source space) can be substantially faster than\n    computing vertex locations. If one array is used, it is assumed\n    that all vertices belong to the hemisphere of the label. To create\n    a label filling the surface, use None.\n%(subjects_dir)s\n%(n_jobs)s\n%(verbose)s\n\nReturns\n-------\nlabel : instance of Label\n    The smoothed label.\n\nNotes\n-----\nThis function will set label.pos to be all zeros. If the positions\non the new surface are required, consider using mne.read_surface\nwith ``label.vertices``.", "metadata": {}}
{"_id": "mne_mne_label.py_morph_doc", "text": "Morph the label.\n\nUseful for transforming a label from one subject to another.\n\nParameters\n----------\nsubject_from : str | None\n    The name of the subject of the current label. If None, the\n    initial subject will be taken from self.subject.\nsubject_to : str\n    The name of the subject to morph the label to. This will\n    be put in label.subject of the output label file.\nsmooth : int\n    Number of iterations for the smoothing of the surface data.\n    Cannot be None here since not all vertices are used.\ngrade : int, list of shape (2,), array, or None\n    Resolution of the icosahedral mesh (typically 5). If None, all\n    vertices will be used (potentially filling the surface). If a list,\n    values will be morphed to the set of vertices specified in grade[0]\n    and grade[1], assuming that these are vertices for the left and\n    right hemispheres. Note that specifying the vertices (e.g.,\n    ``grade=[np.arange(10242), np.arange(10242)]`` for fsaverage on a\n    standard grade 5 source space) can be substantially faster than\n    computing vertex locations. If one array is used, it is assumed\n    that all vertices belong to the hemisphere of the label. To create\n    a label filling the surface, use None.\n%(subjects_dir)s\n%(n_jobs)s\n%(verbose)s\n\nReturns\n-------\nlabel : instance of Label\n    The morphed label.\n\nSee Also\n--------\nmne.morph_labels : Morph a set of labels.\n\nNotes\n-----\nThis function will set label.pos to be all zeros. If the positions\non the new surface are required, consider using `mne.read_surface`\nwith ``label.vertices``.", "metadata": {}}
{"_id": "mne_mne_label.py_split_doc", "text": "Split the Label into two or more parts.\n\nParameters\n----------\nparts : int >= 2 | tuple of str | str\n    Number of labels to create (default is 2), or tuple of strings\n    specifying label names for new labels (from posterior to anterior),\n    or 'contiguous' to split the label into connected components.\n    If a number or 'contiguous' is specified, names of the new labels\n    will be the input label's name with div1, div2 etc. appended.\n%(subject_label)s\n%(subjects_dir)s\nfreesurfer : bool\n    By default (``False``) ``split_label`` uses an algorithm that is\n    slightly optimized for performance and numerical precision. Set\n    ``freesurfer`` to ``True`` in order to replicate label splits from\n    FreeSurfer's ``mris_divide_parcellation``.\n\nReturns\n-------\nlabels : list of Label, shape (n_parts,)\n    The labels, starting from the lowest to the highest end of the\n    projection axis.\n\nNotes\n-----\nIf using 'contiguous' split, you must ensure that the label being split\nuses the same triangular resolution as the surface mesh files in\n``subjects_dir`` Also, some small fringe labels may be returned that\nare close (but not connected) to the large components.\n\nThe spatial split finds the label's principal eigen-axis on the\nspherical surface, projects all label vertex coordinates onto this\naxis, and divides them at regular spatial intervals.", "metadata": {}}
{"_id": "mne_mne_label.py_get_vertices_used_doc", "text": "Get the source space's vertices inside the label.\n\nParameters\n----------\nvertices : ndarray of int, shape (n_vertices,) | None\n    The set of vertices to compare the label to. If None, equals to\n    ``np.arange(10242)``. Defaults to None.\n\nReturns\n-------\nlabel_verts : ndarray of in, shape (n_label_vertices,)\n    The vertices of the label corresponding used by the data.", "metadata": {}}
{"_id": "mne_mne_label.py_get_tris_doc", "text": "Get the source space's triangles inside the label.\n\nParameters\n----------\ntris : ndarray of int, shape (n_tris, 3)\n    The set of triangles corresponding to the vertices in a\n    source space.\nvertices : ndarray of int, shape (n_vertices,) | None\n    The set of vertices to compare the label to. If None, equals to\n    ``np.arange(10242)``. Defaults to None.\n\nReturns\n-------\nlabel_tris : ndarray of int, shape (n_tris, 3)\n    The subset of tris used by the label.", "metadata": {}}
{"_id": "mne_mne_label.py_center_of_mass_doc", "text": "Compute the center of mass of the label.\n\nThis function computes the spatial center of mass on the surface\nas in :footcite:`LarsonLee2013`.\n\nParameters\n----------\n%(subject_label)s\nrestrict_vertices : bool | array of int | instance of SourceSpaces\n    If True, returned vertex will be one from the label. Otherwise,\n    it could be any vertex from surf. If an array of int, the\n    returned vertex will come from that array. If instance of\n    SourceSpaces (as of 0.13), the returned vertex will be from\n    the given source space. For most accuruate estimates, do not\n    restrict vertices.\n%(subjects_dir)s\nsurf : str\n    The surface to use for Euclidean distance center of mass\n    finding. The default here is \"sphere\", which finds the center\n    of mass on the spherical surface to help avoid potential issues\n    with cortical folding.\n\nReturns\n-------\nvertex : int\n    Vertex of the spatial center of mass for the inferred hemisphere,\n    with each vertex weighted by its label value.\n\nSee Also\n--------\nSourceEstimate.center_of_mass\nvertex_to_mni\n\nNotes\n-----\n.. versionadded:: 0.13\n\nReferences\n----------\n.. footbibliography::", "metadata": {}}
{"_id": "mne_mne_label.py_distances_to_outside_doc", "text": "Compute the distance from each vertex to outside the label.\n\nParameters\n----------\n%(subject_label)s\n%(subjects_dir)s\n%(surface)s\n%(verbose)s\n\nReturns\n-------\ndist : ndarray, shape (n_vertices,)\n    The distance from each vertex in ``self.vertices`` to exit the\n    label.\noutside_vertices : ndarray, shape (n_vertices,)\n    For each vertex in the label, the nearest vertex outside the\n    label.\n\nNotes\n-----\nDistances are computed along the cortical surface.\n\n.. versionadded:: 0.24", "metadata": {}}
{"_id": "mne_mne_label.py_compute_area_doc", "text": "Compute the surface area of a label.\n\nParameters\n----------\n%(subject_label)s\n%(subjects_dir)s\n%(surface)s\n%(verbose)s\n\nReturns\n-------\narea : float\n    The area (in m\u00b2) of the label.\n\nNotes\n-----\n..versionadded:: 0.24", "metadata": {}}
{"_id": "mne_mne_cuda.py_get_cuda_memory_doc", "text": "Get the amount of free memory for CUDA operations.\n\nParameters\n----------\nkind : str\n    Can be ``\"available\"`` or ``\"total\"``.\n\nReturns\n-------\nmemory : str\n    The amount of available or total memory as a human-readable string.", "metadata": {}}
{"_id": "mne_mne_cuda.py_init_cuda_doc", "text": "Initialize CUDA functionality.\n\nThis function attempts to load the necessary interfaces\n(hardware connectivity) to run CUDA-based filtering. This\nfunction should only need to be run once per session.\n\nIf the config var (set via mne.set_config or in ENV)\nMNE_USE_CUDA == 'true', this function will be executed when\nthe first CUDA setup is performed. If this variable is not\nset, this function can be manually executed.\n\nParameters\n----------\nignore_config : bool\n    If True, ignore the config value MNE_USE_CUDA and force init.\n%(verbose)s", "metadata": {}}
{"_id": "mne_mne_cuda.py_set_cuda_device_doc", "text": "Set the CUDA device temporarily for the current session.\n\nParameters\n----------\ndevice_id : int\n    Numeric ID of the CUDA-capable device you want MNE-Python to use.\n%(verbose)s", "metadata": {}}
{"_id": "mne_mne_annotations.py_read_annotations_doc", "text": "Read annotations from a file.\n\nThis function reads a ``.fif``, ``.fif.gz``, ``.vmrk``, ``.amrk``,\n``.edf``, ``.bdf``, ``.gdf``, ``.txt``, ``.csv``, ``.cnt``, ``.cef``, or\n``.set`` file and makes an :class:`mne.Annotations` object.\n\nParameters\n----------\nfname : path-like\n    The filename.\nsfreq : float | ``'auto'``\n    The sampling frequency in the file. This parameter is necessary for\n    \\*.vmrk, \\*.amrk, and \\*.cef files as Annotations are expressed in\n    seconds and \\*.vmrk/\\*.amrk/\\*.cef files are in samples. For any other\n    file format, ``sfreq`` is omitted. If set to 'auto' then the ``sfreq``\n    is taken from the respective info file of the same name with according\n    file extension (\\*.vhdr/\\*.ahdr for brainvision; \\*.dap for Curry 7;\n    \\*.cdt.dpa for Curry 8). So data.vmrk/amrk looks for sfreq in\n    data.vhdr/ahdr, data.cef looks in data.dap and data.cdt.cef looks in\n    data.cdt.dpa.\nuint16_codec : str | None\n    This parameter is only used in EEGLAB (\\*.set) and omitted otherwise.\n    If your \\*.set file contains non-ascii characters, sometimes reading\n    it may fail and give rise to error message stating that \"buffer is\n    too small\". ``uint16_codec`` allows to specify what codec (for example:\n    ``'latin1'`` or ``'utf-8'``) should be used when reading character\n    arrays and can therefore help you solve this problem.\n%(encoding_edf)s\n    Only used when reading EDF annotations.\nignore_marker_types : bool\n    If ``True``, ignore marker types in BrainVision files (and only use their\n    descriptions). Defaults to ``False``.\n\nReturns\n-------\nannot : instance of Annotations\n    The annotations.\n\nNotes\n-----\nThe annotations stored in a ``.csv`` require the onset columns to be\ntimestamps. If you have onsets as floats (in seconds), you should use the\n``.txt`` extension.", "metadata": {}}
{"_id": "mne_mne_annotations.py_events_from_annotations_doc", "text": "Get :term:`events` and ``event_id`` from an Annotations object.\n\nParameters\n----------\nraw : instance of Raw\n    The raw data for which Annotations are defined.\nevent_id : dict | callable | None | ``'auto'``\n    Can be:\n\n    - **dict**: map descriptions (keys) to integer event codes (values).\n      Only the descriptions present will be mapped, others will be ignored.\n    - **callable**: must take a string input and return an integer event\n      code, or return ``None`` to ignore the event.\n    - **None**: Map descriptions to unique integer values based on their\n      ``sorted`` order.\n    - **'auto' (default)**: prefer a raw-format-specific parser:\n\n      - Brainvision: map stimulus events to their integer part; response\n        events to integer part + 1000; optic events to integer part + 2000;\n        'SyncStatus/Sync On' to 99998; 'New Segment/' to 99999;\n        all others like ``None`` with an offset of 10000.\n      - Other raw formats: Behaves like None.\n\n      .. versionadded:: 0.18\nregexp : str | None\n    Regular expression used to filter the annotations whose\n    descriptions is a match. The default ignores descriptions beginning\n    ``'bad'`` or ``'edge'`` (case-insensitive).\n\n    .. versionchanged:: 0.18\n       Default ignores bad and edge descriptions.\nuse_rounding : bool\n    If True, use rounding (instead of truncation) when converting\n    times to indices. This can help avoid non-unique indices.\nchunk_duration : float | None\n    Chunk duration in seconds. If ``chunk_duration`` is set to None\n    (default), generated events correspond to the annotation onsets.\n    If not, :func:`mne.events_from_annotations` returns as many events as\n    they fit within the annotation duration spaced according to\n    ``chunk_duration``. As a consequence annotations with duration shorter\n    than ``chunk_duration`` will not contribute events.\ntol : float\n    The tolerance used to check if a chunk fits within an annotation when\n    ``chunk_duration`` is not ``None``. If the duration from a computed\n    chunk onset to the end of the annotation is smaller than\n    ``chunk_duration`` minus ``tol``, the onset will be discarded.\n%(verbose)s\n\nReturns\n-------\n%(events)s\nevent_id : dict\n    The event_id variable that can be passed to :class:`~mne.Epochs`.\n\nSee Also\n--------\nmne.annotations_from_events\n\nNotes\n-----\nFor data formats that store integer events as strings (e.g., NeuroScan\n``.cnt`` files), passing the Python built-in function :class:`int` as the\n``event_id`` parameter will do what most users probably want in those\ncircumstances: return an ``event_id`` dictionary that maps event ``'1'`` to\ninteger event code ``1``, ``'2'`` to ``2``, etc.", "metadata": {}}
{"_id": "mne_mne_annotations.py_annotations_from_events_doc", "text": "Convert an event array to an Annotations object.\n\nParameters\n----------\nevents : ndarray, shape (n_events, 3)\n    The events.\nsfreq : float\n    Sampling frequency.\nevent_desc : dict | array-like | callable | None\n    Events description. Can be:\n\n    - **dict**: map integer event codes (keys) to descriptions (values).\n      Only the descriptions present will be mapped, others will be ignored.\n    - **array-like**: list, or 1d array of integers event codes to include.\n      Only the event codes present will be mapped, others will be ignored.\n      Event codes will be passed as string descriptions.\n    - **callable**: must take a integer event code as input and return a\n      string description or None to ignore it.\n    - **None**: Use integer event codes as descriptions.\nfirst_samp : int\n    The first data sample (default=0). See :attr:`mne.io.Raw.first_samp`\n    docstring.\norig_time : float | str | datetime | tuple of int | None\n    Determines the starting time of annotation acquisition. If None\n    (default), starting time is determined from beginning of raw data\n    acquisition. For details, see :meth:`mne.Annotations` docstring.\n%(verbose)s\n\nReturns\n-------\nannot : instance of Annotations\n    The annotations.\n\nSee Also\n--------\nmne.events_from_annotations\n\nNotes\n-----\nAnnotations returned by this function will all have zero (null) duration.\n\nCreating events from annotations via the function\n`mne.events_from_annotations` takes in event mappings with\nkey\u2192value pairs as description\u2192ID, whereas `mne.annotations_from_events`\ntakes in event mappings with key\u2192value pairs as ID\u2192description.\nIf you need to use these together, you can invert the mapping by doing::\n\n    event_desc = {v: k for k, v in event_id.items()}", "metadata": {}}
{"_id": "mne_mne_annotations.py_count_annotations_doc", "text": "Count annotations.\n\nParameters\n----------\nannotations : mne.Annotations\n    The annotations instance.\n\nReturns\n-------\ncounts : dict\n    A dictionary containing unique annotation descriptions as keys with their\n    counts as values.\n\nExamples\n--------\n    >>> annotations = mne.Annotations([0, 1, 2], [1, 2, 1], [\"T0\", \"T1\", \"T0\"])\n    >>> count_annotations(annotations)\n    {'T0': 2, 'T1': 1}", "metadata": {}}
{"_id": "mne_mne_annotations.py_orig_time_doc", "text": "The time base of the Annotations.", "metadata": {}}
{"_id": "mne_mne_annotations.py_append_doc", "text": "Add an annotated segment. Operates inplace.\n\nParameters\n----------\nonset : float | array-like\n    Annotation time onset from the beginning of the recording in\n    seconds.\nduration : float | array-like\n    Duration of the annotation in seconds.\ndescription : str | array-like\n    Description for the annotation. To reject epochs, use description\n    starting with keyword 'bad'.\n%(ch_names_annot)s\n\n    .. versionadded:: 0.23\n\nReturns\n-------\nself : mne.Annotations\n    The modified Annotations object.\n\nNotes\n-----\nThe array-like support for arguments allows this to be used similarly\nto not only ``list.append``, but also\n`list.extend <https://docs.python.org/3/library/stdtypes.html#mutable-sequence-types>`__.", "metadata": {}}
{"_id": "mne_mne_annotations.py_copy_doc", "text": "Return a copy of the Annotations.\n\nReturns\n-------\ninst : instance of Annotations\n    A copy of the object.", "metadata": {}}
{"_id": "mne_mne_annotations.py_delete_doc", "text": "Remove an annotation. Operates inplace.\n\nParameters\n----------\nidx : int | array-like of int\n    Index of the annotation to remove. Can be array-like to\n    remove multiple indices.", "metadata": {}}
{"_id": "mne_mne_annotations.py_to_data_frame_doc", "text": "Export annotations in tabular structure as a pandas DataFrame.\n\nParameters\n----------\n%(time_format_df_raw)s\n\n    .. versionadded:: 1.7\n\nReturns\n-------\nresult : pandas.DataFrame\n    Returns a pandas DataFrame with onset, duration, and\n    description columns. A column named ch_names is added if any\n    annotations are channel-specific.", "metadata": {}}
{"_id": "mne_mne_annotations.py_count_doc", "text": "Count annotations.\n\nReturns\n-------\ncounts : dict\n    A dictionary containing unique annotation descriptions as keys with their\n    counts as values.", "metadata": {}}
{"_id": "mne_mne_annotations.py_save_doc", "text": "Save annotations to FIF, CSV or TXT.\n\nTypically annotations get saved in the FIF file for raw data\n(e.g., as ``raw.annotations``), but this offers the possibility\nto also save them to disk separately in different file formats\nwhich are easier to share between packages.\n\nParameters\n----------\nfname : path-like\n    The filename to use.\n%(overwrite)s\n\n    .. versionadded:: 0.23\n%(verbose)s\n\nNotes\n-----\nThe format of the information stored in the saved annotation objects\ndepends on the chosen file format. :file:`.csv` files store the onset\nas timestamps (e.g., ``2002-12-03 19:01:56.676071``),\nwhereas :file:`.txt` files store onset as seconds since start of the\nrecording (e.g., ``45.95597082905339``).", "metadata": {}}
{"_id": "mne_mne_annotations.py_crop_doc", "text": "Remove all annotation that are outside of [tmin, tmax].\n\nThe method operates inplace.\n\nParameters\n----------\ntmin : float | datetime | None\n    Start time of selection in seconds.\ntmax : float | datetime | None\n    End time of selection in seconds.\nemit_warning : bool\n    Whether to emit warnings when limiting or omitting annotations.\n    Defaults to False.\nuse_orig_time : bool\n    Whether to use orig_time as an offset.\n    Defaults to True.\n%(verbose)s\n\nReturns\n-------\nself : instance of Annotations\n    The cropped Annotations object.", "metadata": {}}
{"_id": "mne_mne_annotations.py_set_durations_doc", "text": "Set annotation duration(s). Operates inplace.\n\nParameters\n----------\nmapping : dict | float\n    A dictionary mapping the annotation description to a duration in\n    seconds e.g. ``{'ShortStimulus' : 3, 'LongStimulus' : 12}``.\n    Alternatively, if a number is provided, then all annotations\n    durations are set to the single provided value.\n%(verbose)s\n\nReturns\n-------\nself : mne.Annotations\n    The modified Annotations object.\n\nNotes\n-----\n.. versionadded:: 0.24.0", "metadata": {}}
{"_id": "mne_mne_annotations.py_rename_doc", "text": "Rename annotation description(s). Operates inplace.\n\nParameters\n----------\nmapping : dict\n    A dictionary mapping the old description to a new description,\n    e.g. {'1.0' : 'Control', '2.0' : 'Stimulus'}.\n%(verbose)s\n\nReturns\n-------\nself : mne.Annotations\n    The modified Annotations object.\n\nNotes\n-----\n.. versionadded:: 0.24.0", "metadata": {}}
{"_id": "mne_mne_annotations.py_set_annotations_doc", "text": "Setter for Epoch annotations from Raw.\n\nThis method does not handle offsetting the times based\non first_samp or measurement dates, since that is expected\nto occur in Raw.set_annotations().\n\nParameters\n----------\nannotations : instance of mne.Annotations | None\n    Annotations to set.\n%(on_missing_ch_names)s\n%(verbose)s\n\nReturns\n-------\nself : instance of Epochs\n    The epochs object with annotations.\n\nNotes\n-----\nAnnotation onsets and offsets are stored as time in seconds (not as\nsample numbers).\n\nIf you have an ``-epo.fif`` file saved to disk created before 1.0,\nannotations can be added correctly only if no decimation or\nresampling was performed. We thus suggest to regenerate your\n:class:`mne.Epochs` from raw and re-save to disk with 1.0+ if you\nwant to safely work with :class:`~mne.Annotations` in epochs.\n\nSince this method does not handle offsetting the times based\non first_samp or measurement dates, the recommended way to add\nAnnotations is::\n\n    raw.set_annotations(annotations)\n    annotations = raw.annotations\n    epochs.set_annotations(annotations)\n\n.. versionadded:: 1.0", "metadata": {}}
{"_id": "mne_mne_annotations.py_get_annotations_per_epoch_doc", "text": "Get a list of annotations that occur during each epoch.\n\nReturns\n-------\nepoch_annots : list\n    A list of lists (with length equal to number of epochs) where each\n    inner list contains any annotations that overlap the corresponding\n    epoch. Annotations are stored as a :class:`tuple` of onset,\n    duration, description (not as a :class:`~mne.Annotations` object),\n    where the onset is now relative to time=0 of the epoch, rather than\n    time=0 of the original continuous (raw) data.", "metadata": {}}
{"_id": "mne_mne_annotations.py_add_annotations_to_metadata_doc", "text": "Add raw annotations into the Epochs metadata data frame.\n\nAdds three columns to the ``metadata`` consisting of a list\nin each row:\n- ``annot_onset``: the onset of each Annotation within\nthe Epoch relative to the start time of the Epoch (in seconds).\n- ``annot_duration``: the duration of each Annotation\nwithin the Epoch in seconds.\n- ``annot_description``: the free-form text description of each\nAnnotation.\n\nParameters\n----------\noverwrite : bool\n    Whether to overwrite existing columns in metadata or not.\n    Default is False.\n\nReturns\n-------\nself : instance of Epochs\n    The modified instance (instance is also modified inplace).\n\nNotes\n-----\n.. versionadded:: 1.0", "metadata": {}}
{"_id": "mne_mne_conftest.py_pytest_configure_doc", "text": "Configure pytest options.", "metadata": {}}
{"_id": "mne_mne_conftest.py_check_verbose_doc", "text": "Set to the default logging level to ensure it's tested properly.", "metadata": {}}
{"_id": "mne_mne_conftest.py_close_all_doc", "text": "Close all matplotlib plots, regardless of test status.", "metadata": {}}
{"_id": "mne_mne_conftest.py_add_mne_doc", "text": "Add mne to the namespace.", "metadata": {}}
{"_id": "mne_mne_conftest.py_verbose_debug_doc", "text": "Run a test with debug verbosity.", "metadata": {}}
{"_id": "mne_mne_conftest.py_qt_config_doc", "text": "Configure the Qt backend for viz tests.", "metadata": {}}
{"_id": "mne_mne_conftest.py_matplotlib_config_doc", "text": "Configure matplotlib for viz tests.", "metadata": {}}
{"_id": "mne_mne_conftest.py_azure_windows_doc", "text": "Determine if running on Azure Windows.", "metadata": {}}
{"_id": "mne_mne_conftest.py_raw_orig_doc", "text": "Get raw data without any change to it from mne.io.tests.data.", "metadata": {}}
{"_id": "mne_mne_conftest.py_raw_doc", "text": "Get raw data and pick channels to reduce load for testing.\n\n(from mne.io.tests.data)", "metadata": {}}
{"_id": "mne_mne_conftest.py_raw_ctf_doc", "text": "Get ctf raw data from mne.io.tests.data.", "metadata": {}}
{"_id": "mne_mne_conftest.py_raw_spectrum_doc", "text": "Get raw with power spectral density computed from mne.io.tests.data.", "metadata": {}}
{"_id": "mne_mne_conftest.py_events_doc", "text": "Get events from mne.io.tests.data.", "metadata": {}}
{"_id": "mne_mne_conftest.py_epochs_doc", "text": "Get minimal, pre-loaded epochs data suitable for most tests.\n\n(from mne.io.tests.data)", "metadata": {}}
{"_id": "mne_mne_conftest.py_epochs_unloaded_doc", "text": "Get minimal, unloaded epochs data from mne.io.tests.data.", "metadata": {}}
{"_id": "mne_mne_conftest.py_epochs_full_doc", "text": "Get full, preloaded epochs from mne.io.tests.data.", "metadata": {}}
{"_id": "mne_mne_conftest.py_epochs_spectrum_doc", "text": "Get epochs with power spectral density computed from mne.io.tests.data.", "metadata": {}}
{"_id": "mne_mne_conftest.py_epochs_tfr_doc", "text": "Get an EpochsTFR computed from mne.io.tests.data.", "metadata": {}}
{"_id": "mne_mne_conftest.py_average_tfr_doc", "text": "Get an AverageTFR computed by averaging an EpochsTFR (this is small & fast).", "metadata": {}}
{"_id": "mne_mne_conftest.py_full_average_tfr_doc", "text": "Get an AverageTFR computed from Evoked.\n\nThis is slower than the `average_tfr` fixture, but a few TFR.plot_* tests need it.", "metadata": {}}
{"_id": "mne_mne_conftest.py_raw_tfr_doc", "text": "Get a RawTFR computed from mne.io.tests.data.", "metadata": {}}
{"_id": "mne_mne_conftest.py_epochs_empty_doc", "text": "Get empty epochs from mne.io.tests.data.", "metadata": {}}
{"_id": "mne_mne_conftest.py_evoked_doc", "text": "Get truncated evoked data.", "metadata": {}}
{"_id": "mne_mne_conftest.py_full_evoked_doc", "text": "Get full-duration evoked data (needed for, e.g., testing TFR).", "metadata": {}}
{"_id": "mne_mne_conftest.py_noise_cov_doc", "text": "Get a noise cov from the testing dataset.", "metadata": {}}
{"_id": "mne_mne_conftest.py_noise_cov_io_doc", "text": "Get noise-covariance (from mne.io.tests.data).", "metadata": {}}
{"_id": "mne_mne_conftest.py_bias_params_free_doc", "text": "Provide inputs for free bias functions.", "metadata": {}}
{"_id": "mne_mne_conftest.py_bias_params_fixed_doc", "text": "Provide inputs for fixed bias functions.", "metadata": {}}
{"_id": "mne_mne_conftest.py_garbage_collect_doc", "text": "Garbage collect on exit.", "metadata": {}}
{"_id": "mne_mne_conftest.py_mpl_backend_doc", "text": "Use for epochs/ica when not implemented with pyqtgraph yet.", "metadata": {}}
{"_id": "mne_mne_conftest.py_pg_backend_doc", "text": "Use for pyqtgraph-specific test-functions.", "metadata": {}}
{"_id": "mne_mne_conftest.py_browser_backend_doc", "text": "Parametrizes the name of the browser backend.", "metadata": {}}
{"_id": "mne_mne_conftest.py_renderer_doc", "text": "Yield the 3D backends.", "metadata": {}}
{"_id": "mne_mne_conftest.py_renderer_pyvistaqt_doc", "text": "Yield the PyVista backend.", "metadata": {}}
{"_id": "mne_mne_conftest.py_renderer_notebook_doc", "text": "Yield the 3D notebook renderer.", "metadata": {}}
{"_id": "mne_mne_conftest.py_renderer_interactive_pyvistaqt_doc", "text": "Yield the interactive PyVista backend.", "metadata": {}}
{"_id": "mne_mne_conftest.py_renderer_interactive_doc", "text": "Yield the interactive 3D backends.", "metadata": {}}
{"_id": "mne_mne_conftest.py_pixel_ratio_doc", "text": "Get the pixel ratio.", "metadata": {}}
{"_id": "mne_mne_conftest.py_subjects_dir_tmp_doc", "text": "Copy MNE-testing-data subjects_dir to a temp dir for manipulation.", "metadata": {}}
{"_id": "mne_mne_conftest.py_subjects_dir_tmp_few_doc", "text": "Copy fewer files to a tmp_path.", "metadata": {}}
{"_id": "mne_mne_conftest.py_fwd_volume_small_doc", "text": "Provide a small volumetric source space.", "metadata": {}}
{"_id": "mne_mne_conftest.py_all_src_types_inv_evoked_doc", "text": "All source types of inverses, allowing for possible modification.", "metadata": {}}
{"_id": "mne_mne_conftest.py_mixed_fwd_cov_evoked_doc", "text": "Compute inverses for all source types.", "metadata": {}}
{"_id": "mne_mne_conftest.py_src_volume_labels_doc", "text": "Create a 7mm source space with labels.", "metadata": {}}
{"_id": "mne_mne_conftest.py_download_is_error_doc", "text": "Prevent downloading by raising an error when it's attempted.", "metadata": {}}
{"_id": "mne_mne_conftest.py_fake_retrieve_doc", "text": "Monkeypatch pooch.retrieve to avoid downloading (just touch files).", "metadata": {}}
{"_id": "mne_mne_conftest.py_options_3d_doc", "text": "Disable advanced 3d rendering.", "metadata": {}}
{"_id": "mne_mne_conftest.py_protect_config_doc", "text": "Protect ~/.mne.", "metadata": {}}
{"_id": "mne_mne_conftest.py_brain_gc_doc", "text": "Ensure that brain can be properly garbage collected.", "metadata": {}}
{"_id": "mne_mne_conftest.py_pytest_sessionfinish_doc", "text": "Handle the end of the session.", "metadata": {}}
{"_id": "mne_mne_conftest.py_pytest_terminal_summary_doc", "text": "Print the module-level timings.", "metadata": {}}
{"_id": "mne_mne_conftest.py_pytest_report_header_doc", "text": "Add information to the pytest run header.", "metadata": {}}
{"_id": "mne_mne_conftest.py_numba_conditional_doc", "text": "Test both code paths on machines that have Numba.", "metadata": {}}
{"_id": "mne_mne_conftest.py_nbexec_doc", "text": "Execute Python code in a notebook.", "metadata": {}}
{"_id": "mne_mne_conftest.py_pytest_runtest_call_doc", "text": "Run notebook code written in Python.", "metadata": {}}
{"_id": "mne_mne_conftest.py_nirx_snirf_doc", "text": "Return a (raw_nirx, raw_snirf) matched pair.", "metadata": {}}
{"_id": "mne_mne_conftest.py_qt_windows_closed_doc", "text": "Ensure that no new Qt windows are open after a test.", "metadata": {}}
{"_id": "mne_mne_conftest.py_pytest_runtest_makereport_doc", "text": "Stash the status of each item and turn unexpected skips into errors.", "metadata": {}}
{"_id": "mne_mne_conftest.py_pytest_make_collect_report_doc", "text": "Turn unexpected skips during collection (e.g., module-level) into errors.", "metadata": {}}
{"_id": "mne_mne_conftest.py_eyetrack_cal_doc", "text": "Create a toy calibration instance.", "metadata": {}}
{"_id": "mne_mne_conftest.py_eyetrack_raw_doc", "text": "Create a toy raw instance with eyetracking channels.", "metadata": {}}
{"_id": "mne_mne_baseline.py_rescale_doc", "text": "Rescale (baseline correct) data.\n\nParameters\n----------\ndata : array\n    It can be of any shape. The only constraint is that the last\n    dimension should be time.\ntimes : 1D array\n    Time instants is seconds.\n%(baseline_rescale)s\nmode : 'mean' | 'ratio' | 'logratio' | 'percent' | 'zscore' | 'zlogratio'\n    Perform baseline correction by\n\n    - subtracting the mean of baseline values ('mean')\n    - dividing by the mean of baseline values ('ratio')\n    - dividing by the mean of baseline values and taking the log\n      ('logratio')\n    - subtracting the mean of baseline values followed by dividing by\n      the mean of baseline values ('percent')\n    - subtracting the mean of baseline values and dividing by the\n      standard deviation of baseline values ('zscore')\n    - dividing by the mean of baseline values, taking the log, and\n      dividing by the standard deviation of log baseline values\n      ('zlogratio')\n\ncopy : bool\n    Whether to return a new instance or modify in place.\npicks : list of int | None\n    Data to process along the axis=-2 (None, default, processes all).\n%(verbose)s\n\nReturns\n-------\ndata_scaled: array\n    Array of same shape as data after rescaling.", "metadata": {}}
{"_id": "mne_mne_surface.py_get_head_surf_doc", "text": "Load the subject head surface.\n\nParameters\n----------\nsubject : str\n    Subject name.\nsource : str | list of str\n    Type to load. Common choices would be ``'bem'`` or ``'head'``. We first\n    try loading ``'$SUBJECTS_DIR/$SUBJECT/bem/$SUBJECT-$SOURCE.fif'``, and\n    then look for ``'$SUBJECT*$SOURCE.fif'`` in the same directory by going\n    through all files matching the pattern. The head surface will be read\n    from the first file containing a head surface. Can also be a list\n    to try multiple strings.\nsubjects_dir : path-like | None\n    Path to the ``SUBJECTS_DIR``. If None, the path is obtained by using\n    the environment variable ``SUBJECTS_DIR``.\n%(on_defects)s\n\n    .. versionadded:: 1.0\n%(verbose)s\n\nReturns\n-------\nsurf : dict\n    The head surface.", "metadata": {}}
{"_id": "mne_mne_surface.py_get_meg_helmet_surf_doc", "text": "Load the MEG helmet associated with the MEG sensors.\n\nParameters\n----------\n%(info_not_none)s\ntrans : dict\n    The head<->MRI transformation, usually obtained using\n    read_trans(). Can be None, in which case the surface will\n    be in head coordinates instead of MRI coordinates.\n%(helmet_upsampling)s\n%(verbose)s\n\nReturns\n-------\nsurf : dict\n    The MEG helmet as a surface.\n\nNotes\n-----\nA built-in helmet is loaded if possible. If not, a helmet surface\nwill be approximated based on the sensor locations.", "metadata": {}}
{"_id": "mne_mne_surface.py_fast_cross_3d_doc", "text": "Compute cross product between list of 3D vectors.\n\nMuch faster than np.cross() when the number of cross products\nbecomes large (>= 500). This is because np.cross() methods become\nless memory efficient at this stage.\n\nParameters\n----------\nx : array\n    Input array 1, shape (..., 3).\ny : array\n    Input array 2, shape (..., 3).\n\nReturns\n-------\nz : array, shape (..., 3)\n    Cross product of x and y along the last dimension.\n\nNotes\n-----\nx and y must broadcast against each other.", "metadata": {}}
{"_id": "mne_mne_surface.py_complete_surface_info_doc", "text": "Complete surface information.\n\nParameters\n----------\nsurf : dict\n    The surface.\ndo_neighbor_vert : bool\n    If True (default False), add neighbor vertex information.\ncopy : bool\n    If True (default), make a copy. If False, operate in-place.\ndo_neighbor_tri : bool\n    If True (default), compute triangle neighbors.\n%(verbose)s\n\nReturns\n-------\nsurf : dict\n    The transformed surface.", "metadata": {}}
{"_id": "mne_mne_surface.py_read_curvature_doc", "text": "Load in curvature values from the ?h.curv file.\n\nParameters\n----------\nfilepath : path-like\n    Input path to the ``.curv`` file.\nbinary : bool\n    Specify if the output array is to hold binary values. Defaults to True.\n\nReturns\n-------\ncurv : array of shape (n_vertices,)\n    The curvature values loaded from the user given file.", "metadata": {}}
{"_id": "mne_mne_surface.py_read_surface_doc", "text": "Load a Freesurfer surface mesh in triangular format.\n\nParameters\n----------\nfname : path-like\n    The name of the file containing the surface.\nread_metadata : bool\n    Read metadata as key-value pairs. Only works when reading a FreeSurfer\n    surface file. For .obj files this dictionary will be empty.\n\n    Valid keys:\n\n        * 'head' : array of int\n        * 'valid' : str\n        * 'filename' : str\n        * 'volume' : array of int, shape (3,)\n        * 'voxelsize' : array of float, shape (3,)\n        * 'xras' : array of float, shape (3,)\n        * 'yras' : array of float, shape (3,)\n        * 'zras' : array of float, shape (3,)\n        * 'cras' : array of float, shape (3,)\n\n    .. versionadded:: 0.13.0\n\nreturn_dict : bool\n    If True, a dictionary with surface parameters is returned.\nfile_format : 'auto' | 'freesurfer' | 'obj'\n    File format to use. Can be 'freesurfer' to read a FreeSurfer surface\n    file, or 'obj' to read a Wavefront .obj file (common format for\n    importing in other software), or 'auto' to attempt to infer from the\n    file name. Defaults to 'auto'.\n\n    .. versionadded:: 0.21.0\n%(verbose)s\n\nReturns\n-------\nrr : array, shape=(n_vertices, 3)\n    Coordinate points.\ntris : int array, shape=(n_faces, 3)\n    Triangulation (each line contains indices for three points which\n    together form a face).\nvolume_info : dict-like\n    If read_metadata is true, key-value pairs found in the geometry file.\nsurf : dict\n    The surface parameters. Only returned if ``return_dict`` is True.\n\nSee Also\n--------\nwrite_surface\nread_tri", "metadata": {}}
{"_id": "mne_mne_surface.py_write_surface_doc", "text": "Write a triangular Freesurfer surface mesh.\n\nAccepts the same data format as is returned by read_surface().\n\nParameters\n----------\nfname : path-like\n    File to write.\ncoords : array, shape=(n_vertices, 3)\n    Coordinate points.\nfaces : int array, shape=(n_faces, 3)\n    Triangulation (each line contains indices for three points which\n    together form a face).\ncreate_stamp : str\n    Comment that is written to the beginning of the file. Can not contain\n    line breaks.\nvolume_info : dict-like or None\n    Key-value pairs to encode at the end of the file.\n    Valid keys:\n\n        * 'head' : array of int\n        * 'valid' : str\n        * 'filename' : str\n        * 'volume' : array of int, shape (3,)\n        * 'voxelsize' : array of float, shape (3,)\n        * 'xras' : array of float, shape (3,)\n        * 'yras' : array of float, shape (3,)\n        * 'zras' : array of float, shape (3,)\n        * 'cras' : array of float, shape (3,)\n\n    .. versionadded:: 0.13.0\nfile_format : 'auto' | 'freesurfer' | 'obj'\n    File format to use. Can be 'freesurfer' to write a FreeSurfer surface\n    file, or 'obj' to write a Wavefront .obj file (common format for\n    importing in other software), or 'auto' to attempt to infer from the\n    file name. Defaults to 'auto'.\n\n    .. versionadded:: 0.21.0\n%(overwrite)s\n%(verbose)s\n\nSee Also\n--------\nread_surface\nread_tri", "metadata": {}}
{"_id": "mne_mne_surface.py_decimate_surface_doc", "text": "Decimate surface data.\n\nParameters\n----------\npoints : ndarray\n    The surface to be decimated, a 3 x number of points array.\ntriangles : ndarray\n    The surface to be decimated, a 3 x number of triangles array.\nn_triangles : int\n    The desired number of triangles.\nmethod : str\n    Can be \"quadric\" or \"sphere\". \"sphere\" will inflate the surface to a\n    sphere using Freesurfer and downsample to an icosahedral or\n    octahedral mesh.\n\n    .. versionadded:: 0.20\n%(verbose)s\n\nReturns\n-------\npoints : ndarray\n    The decimated points.\ntriangles : ndarray\n    The decimated triangles.\n\nNotes\n-----\n**\"quadric\" mode**\n\nThis requires VTK. If an odd target number was requested,\nthe ``'decimation'`` algorithm used results in the\nnext even number of triangles. For example a reduction request\nto 30001 triangles may result in 30000 triangles.\n\n**\"sphere\" mode**\n\nThis requires Freesurfer to be installed and available in the\nenvironment. The destination number of triangles must be one of\n``[20, 80, 320, 1280, 5120, 20480]`` for ico (0-5) downsampling or one of\n``[8, 32, 128, 512, 2048, 8192, 32768]`` for oct (1-7) downsampling.\n\nThis mode is slower, but could be more suitable for decimating meshes for\nBEM creation (recommended ``n_triangles=5120``) due to better topological\nproperty preservation.", "metadata": {}}
{"_id": "mne_mne_surface.py_mesh_edges_doc", "text": "Return sparse matrix with edges as an adjacency matrix.\n\nParameters\n----------\ntris : array of shape [n_triangles x 3]\n    The triangles.\n\nReturns\n-------\nedges : scipy.sparse.spmatrix\n    The adjacency matrix.", "metadata": {}}
{"_id": "mne_mne_surface.py_mesh_dist_doc", "text": "Compute adjacency matrix weighted by distances.\n\nIt generates an adjacency matrix where the entries are the distances\nbetween neighboring vertices.\n\nParameters\n----------\ntris : array (n_tris x 3)\n    Mesh triangulation.\nvert : array (n_vert x 3)\n    Vertex locations.\n\nReturns\n-------\ndist_matrix : scipy.sparse.csr_array\n    Sparse matrix with distances between adjacent vertices.", "metadata": {}}
{"_id": "mne_mne_surface.py_read_tri_doc", "text": "Read triangle definitions from an ascii file.\n\nParameters\n----------\nfname_in : path-like\n    Path to surface ASCII file (ending with ``'.tri'``).\nswap : bool\n    Assume the ASCII file vertex ordering is clockwise instead of\n    counterclockwise.\n%(verbose)s\n\nReturns\n-------\nrr : array, shape=(n_vertices, 3)\n    Coordinate points.\ntris : int array, shape=(n_faces, 3)\n    Triangulation (each line contains indices for three points which\n    together form a face).\n\nSee Also\n--------\nread_surface\nwrite_surface\n\nNotes\n-----\n.. versionadded:: 0.13.0", "metadata": {}}
{"_id": "mne_mne_surface.py_dig_mri_distances_doc", "text": "Compute distances between head shape points and the scalp surface.\n\nThis function is useful to check that coregistration is correct.\nUnless outliers are present in the head shape points,\none can assume an average distance around 2-3 mm.\n\nParameters\n----------\n%(info_not_none)s Must contain the head shape points in ``info['dig']``.\ntrans : str | instance of Transform\n    The head<->MRI transform. If str is passed it is the\n    path to file on disk.\nsubject : str\n    The name of the subject.\nsubjects_dir : str | None\n    Directory containing subjects data. If None use\n    the Freesurfer SUBJECTS_DIR environment variable.\n%(dig_kinds)s\n%(exclude_frontal)s\n    Default is False.\n%(on_defects)s\n\n    .. versionadded:: 1.0\n%(verbose)s\n\nReturns\n-------\ndists : array, shape (n_points,)\n    The distances.\n\nSee Also\n--------\nmne.bem.get_fitting_dig\n\nNotes\n-----\n.. versionadded:: 0.19", "metadata": {}}
{"_id": "mne_mne_surface.py_get_montage_volume_labels_doc", "text": "Get regions of interest near channels from a Freesurfer parcellation.\n\n.. note:: This is applicable for channels inside the brain\n          (intracranial electrodes).\n\nParameters\n----------\n%(montage)s\n%(subject)s\n%(subjects_dir)s\n%(aseg)s\ndist : float\n    The distance in mm to use for identifying regions of interest.\n\nReturns\n-------\nlabels : dict\n    The regions of interest labels within ``dist`` of each channel.\ncolors : dict\n    The Freesurfer lookup table colors for the labels.", "metadata": {}}
{"_id": "mne_mne_transforms.py_apply_trans_doc", "text": "Apply a transform matrix to an array of points.\n\nParameters\n----------\ntrans : array, shape = (4, 4) | instance of Transform\n    Transform matrix.\npts : array, shape = (3,) | (n, 3)\n    Array with coordinates for one or n points.\nmove : bool\n    If True (default), apply translation.\n\nReturns\n-------\ntransformed_pts : shape = (3,) | (n, 3)\n    Transformed point(s).", "metadata": {}}
{"_id": "mne_mne_transforms.py_rotation_doc", "text": "Create an array with a 4 dimensional rotation matrix.\n\nParameters\n----------\nx, y, z : scalar\n    Rotation around the origin (in rad).\n\nReturns\n-------\nr : array, shape = (4, 4)\n    The rotation matrix.", "metadata": {}}
{"_id": "mne_mne_transforms.py_rotation3d_doc", "text": "Create an array with a 3 dimensional rotation matrix.\n\nParameters\n----------\nx, y, z : scalar\n    Rotation around the origin (in rad).\n\nReturns\n-------\nr : array, shape = (3, 3)\n    The rotation matrix.", "metadata": {}}
{"_id": "mne_mne_transforms.py_rotation3d_align_z_axis_doc", "text": "Compute a rotation matrix to align [ 0 0 1] with supplied target z axis.\n\nParameters\n----------\ntarget_z_axis : array, shape (1, 3)\n    z axis. computed matrix (r) will map [0 0 1] to target_z_axis\n\nReturns\n-------\nr : array, shape (3, 3)\n    The rotation matrix.", "metadata": {}}
{"_id": "mne_mne_transforms.py_rotation_angles_doc", "text": "Find rotation angles from a transformation matrix.\n\nParameters\n----------\nm : array, shape >= (3, 3)\n    Rotation matrix. Only the top left 3 x 3 partition is accessed.\n\nReturns\n-------\nx, y, z : float\n    Rotation around x, y and z axes.", "metadata": {}}
{"_id": "mne_mne_transforms.py_scaling_doc", "text": "Create an array with a scaling matrix.\n\nParameters\n----------\nx, y, z : scalar\n    Scaling factors.\n\nReturns\n-------\ns : array, shape = (4, 4)\n    The scaling matrix.", "metadata": {}}
{"_id": "mne_mne_transforms.py_translation_doc", "text": "Create an array with a translation matrix.\n\nParameters\n----------\nx, y, z : scalar\n    Translation parameters.\n\nReturns\n-------\nm : array, shape = (4, 4)\n    The translation matrix.", "metadata": {}}
{"_id": "mne_mne_transforms.py_combine_transforms_doc", "text": "Combine two transforms.\n\nParameters\n----------\nt_first : dict\n    First transform.\nt_second : dict\n    Second transform.\nfro : int\n    From coordinate frame.\nto : int\n    To coordinate frame.\n\nReturns\n-------\ntrans : dict\n    Combined transformation.", "metadata": {}}
{"_id": "mne_mne_transforms.py_read_trans_doc", "text": "Read a ``-trans.fif`` file.\n\nParameters\n----------\nfname : path-like\n    The name of the file.\nreturn_all : bool\n    If True, return all transformations in the file.\n    False (default) will only return the first.\n\n    .. versionadded:: 0.15\n%(verbose)s\n\nReturns\n-------\ntrans : dict | list of dict\n    The transformation dictionary from the fif file.\n\nSee Also\n--------\nwrite_trans\nmne.transforms.Transform", "metadata": {}}
{"_id": "mne_mne_transforms.py_write_trans_doc", "text": "Write a transformation FIF file.\n\nParameters\n----------\nfname : path-like\n    The name of the file, which should end in ``-trans.fif``.\ntrans : dict\n    Trans file data, as returned by `~mne.read_trans`.\n%(overwrite)s\n%(verbose)s\n\nSee Also\n--------\nread_trans", "metadata": {}}
{"_id": "mne_mne_transforms.py_invert_transform_doc", "text": "Invert a transformation between coordinate systems.\n\nParameters\n----------\ntrans : dict\n    Transform to invert.\n\nReturns\n-------\ninv_trans : dict\n    Inverse transform.", "metadata": {}}
{"_id": "mne_mne_transforms.py_transform_surface_to_doc", "text": "Transform surface to the desired coordinate system.\n\nParameters\n----------\nsurf : dict\n    Surface.\ndest : 'meg' | 'mri' | 'head' | int\n    Destination coordinate system. Can be an integer for using\n    FIFF types.\ntrans : dict | list of dict\n    Transformation to use (or a list of possible transformations to\n    check).\ncopy : bool\n    If False (default), operate in-place.\n\nReturns\n-------\nres : dict\n    Transformed source space.", "metadata": {}}
{"_id": "mne_mne_transforms.py_get_ras_to_neuromag_trans_doc", "text": "Construct a transformation matrix to the MNE head coordinate system.\n\nConstruct a transformation matrix from an arbitrary RAS coordinate system\nto the MNE head coordinate system, in which the x axis passes through the\ntwo preauricular points, and the y axis passes through the nasion and is\nnormal to the x axis. (see mne manual, pg. 97)\n\nParameters\n----------\nnasion : array_like, shape (3,)\n    Nasion point coordinate.\nlpa : array_like, shape (3,)\n    Left peri-auricular point coordinate.\nrpa : array_like, shape (3,)\n    Right peri-auricular point coordinate.\n\nReturns\n-------\ntrans : numpy.array, shape = (4, 4)\n    Transformation matrix to MNE head space.", "metadata": {}}
{"_id": "mne_mne_transforms.py_quat_to_rot_doc", "text": "Convert a set of quaternions to rotations.\n\nParameters\n----------\nquat : array, shape (..., 3)\n    The q1, q2, and q3 (x, y, z) parameters of a unit quaternion.\n\nReturns\n-------\nrot : array, shape (..., 3, 3)\n    The corresponding rotation matrices.\n\nSee Also\n--------\nrot_to_quat", "metadata": {}}
{"_id": "mne_mne_transforms.py_rot_to_quat_doc", "text": "Convert a set of rotations to quaternions.\n\nParameters\n----------\nrot : array, shape (..., 3, 3)\n    The rotation matrices to convert.\n\nReturns\n-------\nquat : array, shape (..., 3)\n    The q1, q2, and q3 (x, y, z) parameters of the corresponding\n    unit quaternions.\n\nSee Also\n--------\nquat_to_rot", "metadata": {}}
{"_id": "mne_mne_transforms.py_read_ras_mni_t_doc", "text": "Read a subject's RAS to MNI transform.\n\nParameters\n----------\nsubject : str\n    The subject.\n%(subjects_dir)s\n\nReturns\n-------\nras_mni_t : instance of Transform\n    The transform from RAS to MNI (in mm).", "metadata": {}}
{"_id": "mne_mne_transforms.py_compute_volume_registration_doc", "text": "Align two volumes using an affine and, optionally, SDR.\n\nParameters\n----------\n%(moving)s\n%(static)s\n%(pipeline)s\nzooms : float | tuple | dict | None\n    The voxel size of volume for each spatial dimension in mm.\n    If None (default), MRIs won't be resliced (slow, but most accurate).\n    Can be a tuple to provide separate zooms for each dimension (X/Y/Z),\n    or a dict with keys ``['translation', 'rigid', 'affine', 'sdr']``\n    (each with values that are float`, tuple, or None) to provide separate\n    reslicing/accuracy for the steps.\n%(niter)s\nstarting_affine : ndarray\n    The affine to initialize the registration with.\n\n    .. versionadded:: 1.2\n%(verbose)s\n\nReturns\n-------\n%(reg_affine)s\n%(sdr_morph)s\n\nNotes\n-----\nThis function is heavily inspired by and extends\n:func:`dipy.align.affine_registration\n<dipy.align._public.affine_registration>`.\n\n.. versionadded:: 0.24", "metadata": {}}
{"_id": "mne_mne_transforms.py_apply_volume_registration_doc", "text": "Apply volume registration.\n\nUses registration parameters computed by\n:func:`~mne.transforms.compute_volume_registration`.\n\nParameters\n----------\n%(moving)s\n%(static)s\n%(reg_affine)s\n%(sdr_morph)s\ninterpolation : str\n    Interpolation to be used during the interpolation.\n    Can be ``\"linear\"`` (default) or ``\"nearest\"``.\ncval : float | str\n    The constant value to assume exists outside the bounds of the\n    ``moving`` image domain. Can be a string percentage like ``'1%%'``\n    to use the given percentile of image data as the constant value.\n%(verbose)s\n\nReturns\n-------\nreg_img : instance of SpatialImage\n    The image after affine (and SDR, if provided) registration.\n\nNotes\n-----\n.. versionadded:: 0.24", "metadata": {}}
{"_id": "mne_mne_transforms.py_apply_volume_registration_points_doc", "text": "Apply volume registration.\n\nUses registration parameters computed by\n:func:`~mne.transforms.compute_volume_registration`.\n\nParameters\n----------\n%(info_not_none)s\n%(trans_not_none)s\n%(moving)s\n%(static)s\n%(reg_affine)s\n%(sdr_morph)s\n%(verbose)s\n\nReturns\n-------\n%(info_not_none)s\ntrans2 : instance of Transform\n    The head->mri (surface RAS) transform for the static image.\n\nNotes\n-----\n.. versionadded:: 1.4.0", "metadata": {}}
{"_id": "mne_mne_transforms.py_from_str_doc", "text": "The \"from\" frame as a string.", "metadata": {}}
{"_id": "mne_mne_transforms.py_to_str_doc", "text": "The \"to\" frame as a string.", "metadata": {}}
{"_id": "mne_mne_transforms.py_save_doc", "text": "Save the transform as -trans.fif file.\n\nParameters\n----------\nfname : path-like\n    The name of the file, which should end in ``-trans.fif``.\n%(overwrite)s\n%(verbose)s", "metadata": {}}
{"_id": "mne_mne_transforms.py_copy_doc", "text": "Make a copy of the transform.", "metadata": {}}
{"_id": "mne_mne_transforms.py_transform_doc", "text": "Apply the warp.\n\nParameters\n----------\npts : shape (n_transform, 3)\n    Source points to warp to the destination.\n\nReturns\n-------\ndest : shape (n_transform, 3)\n    The transformed points.", "metadata": {}}
{"_id": "mne_mne_transforms.py_fit_doc", "text": "Fit the warp from source points to destination points.\n\nParameters\n----------\nsource : array, shape (n_src, 3)\n    The source points.\ndestination : array, shape (n_dest, 3)\n    The destination points.\norder : int\n    Order of the spherical harmonic fit.\nreg : float\n    Regularization of the TPS warp.\ncenter : bool\n    If True, center the points by fitting a sphere to points\n    that are in a reasonable region for head digitization.\nmatch : str\n    The uniformly-spaced points to match on the two surfaces.\n    Can be \"ico#\" or \"oct#\" where \"#\" is an integer.\n    The default is \"oct5\".\n%(verbose)s\n\nReturns\n-------\ninst : instance of SphericalSurfaceWarp\n    The warping object (for chaining).", "metadata": {}}
{"_id": "mne_mne_transforms.py_transform_doc", "text": "Transform arbitrary source points to the destination.\n\nParameters\n----------\nsource : ndarray, shape (n_pts, 3)\n    Source points to transform. They do not need to be the same\n    points that were used to generate the model, although ideally\n    they will be inside the convex hull formed by the original\n    source points.\n%(verbose)s\n\nReturns\n-------\ndestination : ndarray, shape (n_pts, 3)\n    The points transformed to the destination space.", "metadata": {}}
{"_id": "mne_mne_epochs.py_make_metadata_doc", "text": "Automatically generate metadata for use with `mne.Epochs` from events.\n\nThis function mimics the epoching process (it constructs time windows\naround time-locked \"events of interest\") and collates information about\nany other events that occurred within those time windows. The information\nis returned as a :class:`pandas.DataFrame`, suitable for use as\n`~mne.Epochs` metadata: one row per time-locked event, and columns\nindicating presence or absence and latency of each ancillary event type.\n\nThe function will also return a new ``events`` array and ``event_id``\ndictionary that correspond to the generated metadata, which together can then be\nreadily fed into `~mne.Epochs`.\n\nParameters\n----------\nevents : array, shape (m, 3)\n    The :term:`events array <events>`. By default, the returned metadata\n    :class:`~pandas.DataFrame` will have as many rows as the events array.\n    To create rows for only a subset of events, pass the ``row_events``\n    parameter.\nevent_id : dict\n    A mapping from event names (keys) to event IDs (values). The event\n    names will be incorporated as columns of the returned metadata\n    :class:`~pandas.DataFrame`.\ntmin, tmax : float | str | list of str | None\n    If float, start and end of the time interval for metadata generation in seconds,\n    relative to the time-locked event of the respective time window (the \"row\n    events\").\n\n    .. note::\n       If you are planning to attach the generated metadata to\n       `~mne.Epochs` and intend to include only events that fall inside\n       your epoch's time interval, pass the same ``tmin`` and ``tmax``\n       values here as you use for your epochs.\n\n    If ``None``, the time window used for metadata generation is bounded by the\n    ``row_events``. This is can be particularly practical if trial duration varies\n    greatly, but each trial starts with a known event (e.g., a visual cue or\n    fixation).\n\n    .. note::\n       If ``tmin=None``, the first time window for metadata generation starts with\n       the first row event. If ``tmax=None``, the last time window for metadata\n       generation ends with the last event in ``events``.\n\n    If a string or a list of strings, the events bounding the metadata around each\n    \"row event\". For ``tmin``, the events are assumed to occur **before** the row\n    event, and for ``tmax``, the events are assumed to occur **after** \u2013 unless\n    ``tmin`` or ``tmax`` are equal to a row event, in which case the row event\n    serves as the bound.\n\n    .. versionchanged:: 1.6.0\n       Added support for ``None``.\n\n    .. versionadded:: 1.7.0\n       Added support for strings.\nsfreq : float\n    The sampling frequency of the data from which the events array was\n    extracted.\nrow_events : list of str | str | None\n    Event types around which to create the time windows. For each of these\n    time-locked events, we will create a **row** in the returned metadata\n    :class:`pandas.DataFrame`. If provided, the string(s) must be keys of\n    ``event_id``. If ``None`` (default), rows are created for **all** event types\n    present in ``event_id``.\nkeep_first : str | list of str | None\n    Specify subsets of :term:`hierarchical event descriptors` (HEDs,\n    inspired by :footcite:`BigdelyShamloEtAl2013`) matching events of which\n    the **first occurrence** within each time window shall be stored in\n    addition to the original events.\n\n    .. note::\n       There is currently no way to retain **all** occurrences of a\n       repeated event. The ``keep_first`` parameter can be used to specify\n       subsets of HEDs, effectively creating a new event type that is the\n       union of all events types described by the matching HED pattern.\n       Only the very first event of this set will be kept.\n\n    For example, you might have two response events types,\n    ``response/left`` and ``response/right``; and in trials with both\n    responses occurring, you want to keep only the first response. In this\n    case, you can pass ``keep_first='response'``. This will add two new\n    columns to the metadata: ``response``, indicating at what **time** the\n    event  occurred, relative to the time-locked event; and\n    ``first_response``, stating which **type** (``'left'`` or ``'right'``)\n    of event occurred.\n    To match specific subsets of HEDs describing different sets of events,\n    pass a list of these subsets, e.g.\n    ``keep_first=['response', 'stimulus']``. If ``None`` (default), no\n    event aggregation will take place and no new columns will be created.\n\n    .. note::\n       By default, this function will always retain  the first instance\n       of any event in each time window. For example, if a time window\n       contains two ``'response'`` events, the generated ``response``\n       column will automatically refer to the first of the two events. In\n       this specific case, it is therefore **not** necessary to make use of\n       the ``keep_first`` parameter \u2013 unless you need to differentiate\n       between two types of responses, like in the example above.\n\nkeep_last : list of str | None\n    Same as ``keep_first``, but for keeping only the **last**  occurrence\n    of matching events. The column indicating the **type** of an event\n    ``myevent`` will be named ``last_myevent``.\n\nReturns\n-------\nmetadata : pandas.DataFrame\n    Metadata for each row event, with the following columns:\n\n    - ``event_name``, with strings indicating the name of the time-locked\n      event (\"row event\") for that specific time window\n\n    - one column per event type in ``event_id``, with the same name; floats\n      indicating the latency of the event in seconds, relative to the\n      time-locked event\n\n    - if applicable, additional columns named after the ``keep_first`` and\n      ``keep_last`` event types; floats indicating the latency  of the\n      event in seconds, relative to the time-locked event\n\n    - if applicable, additional columns ``first_{event_type}`` and\n      ``last_{event_type}`` for ``keep_first`` and ``keep_last`` event\n      types, respetively; the values will be strings indicating which event\n      types were matched by the provided HED patterns\n\nevents : array, shape (n, 3)\n    The events corresponding to the generated metadata, i.e. one\n    time-locked event per row.\nevent_id : dict\n    The event dictionary corresponding to the new events array. This will\n    be identical to the input dictionary unless ``row_events`` is supplied,\n    in which case it will only contain the events provided there.\n\nNotes\n-----\nThe time window used for metadata generation need not correspond to the\ntime window used to create the `~mne.Epochs`, to which the metadata will\nbe attached; it may well be much shorter or longer, or not overlap at all,\nif desired. This can be useful, for example, to include events that\noccurred before or after an epoch, e.g. during the inter-trial interval.\nIf either ``tmin``, ``tmax``, or both are ``None``, or a string referring e.g. to a\nresponse event, the time window will typically vary, too.\n\n.. versionadded:: 0.23\n\nReferences\n----------\n.. footbibliography::", "metadata": {}}
{"_id": "mne_mne_epochs.py_combine_event_ids_doc", "text": "Collapse event_ids from an epochs instance into a new event_id.\n\nParameters\n----------\nepochs : instance of Epochs\n    The epochs to operate on.\nold_event_ids : str, or list\n    Conditions to collapse together.\nnew_event_id : dict, or int\n    A one-element dict (or a single integer) for the new\n    condition. Note that for safety, this cannot be any\n    existing id (in epochs.event_id.values()).\ncopy : bool\n    Whether to return a new instance or modify in place.\n\nReturns\n-------\nepochs : instance of Epochs\n    The modified epochs.\n\nNotes\n-----\nThis For example (if epochs.event_id was ``{'Left': 1, 'Right': 2}``::\n\n    combine_event_ids(epochs, ['Left', 'Right'], {'Directional': 12})\n\nwould create a 'Directional' entry in epochs.event_id replacing\n'Left' and 'Right' (combining their trials).", "metadata": {}}
{"_id": "mne_mne_epochs.py_equalize_epoch_counts_doc", "text": "Equalize the number of trials in multiple Epochs or EpochsTFR instances.\n\nParameters\n----------\nepochs_list : list of Epochs instances\n    The Epochs instances to equalize trial counts for.\n%(equalize_events_method)s\n%(random_state)s Used only if ``method='random'``.\n\nNotes\n-----\nThe method ``'mintime'`` tries to make the remaining epochs occurring as close as\npossible in time. This method is motivated by the possibility that if there happened\nto be some time-varying (like on the scale of minutes) noise characteristics during\na recording, they could be compensated for (to some extent) in the\nequalization process. This method thus seeks to reduce any of those effects\nby minimizing the differences in the times of the events in the two sets of\nepochs. For example, if one had event times [1, 2, 3, 4, 120, 121] and the\nother one had [3.5, 4.5, 120.5, 121.5], it would remove events at times\n[1, 2] in the first epochs and not [120, 121].\n\nExamples\n--------\n>>> equalize_epoch_counts([epochs1, epochs2])  # doctest: +SKIP", "metadata": {}}
{"_id": "mne_mne_epochs.py_read_epochs_doc", "text": "Read epochs from a fif file.\n\nParameters\n----------\n%(fname_epochs)s\n%(proj_epochs)s\npreload : bool\n    If True, read all epochs from disk immediately. If ``False``, epochs\n    will be read on demand.\n%(verbose)s\n\nReturns\n-------\nepochs : instance of Epochs\n    The epochs.", "metadata": {}}
{"_id": "mne_mne_epochs.py_bootstrap_doc", "text": "Compute epochs selected by bootstrapping.\n\nParameters\n----------\nepochs : Epochs instance\n    epochs data to be bootstrapped\n%(random_state)s\n\nReturns\n-------\nepochs : Epochs instance\n    The bootstrap samples", "metadata": {}}
{"_id": "mne_mne_epochs.py_concatenate_epochs_doc", "text": "Concatenate a list of `~mne.Epochs` into one `~mne.Epochs` object.\n\n.. note:: Unlike `~mne.concatenate_raws`, this function does **not**\n          modify any of the input data.\n\nParameters\n----------\nepochs_list : list\n    List of `~mne.Epochs` instances to concatenate (in that order).\nadd_offset : bool\n    If True, a fixed offset is added to the event times from different\n    Epochs sets, such that they are easy to distinguish after the\n    concatenation.\n    If False, the event times are unaltered during the concatenation.\n%(on_mismatch_info)s\n%(verbose)s\n\n    .. versionadded:: 0.24\n\nReturns\n-------\nepochs : instance of EpochsArray\n    The result of the concatenation. All data will be loaded into memory.\n\nNotes\n-----\n.. versionadded:: 0.9.0", "metadata": {}}
{"_id": "mne_mne_epochs.py_average_movements_doc", "text": "Average data using Maxwell filtering, transforming using head positions.\n\nParameters\n----------\nepochs : instance of Epochs\n    The epochs to operate on.\n%(head_pos_maxwell)s\norig_sfreq : float | None\n    The original sample frequency of the data (that matches the\n    event sample numbers in ``epochs.events``). Can be ``None``\n    if data have not been decimated or resampled.\n%(picks_all_data)s\n%(origin_maxwell)s\nweight_all : bool\n    If True, all channels are weighted by the SSS basis weights.\n    If False, only MEG channels are weighted, other channels\n    receive uniform weight per epoch.\n%(int_order_maxwell)s\n%(ext_order_maxwell)s\n%(destination_maxwell_dest)s\n%(ignore_ref_maxwell)s\nreturn_mapping : bool\n    If True, return the mapping matrix.\n%(mag_scale_maxwell)s\n\n    .. versionadded:: 0.13\n%(verbose)s\n\nReturns\n-------\nevoked : instance of Evoked\n    The averaged epochs.\n\nSee Also\n--------\nmne.preprocessing.maxwell_filter\nmne.chpi.read_head_pos\n\nNotes\n-----\nThe Maxwell filtering version of this algorithm is described in [1]_,\nin section V.B \"Virtual signals and movement correction\", equations\n40-44. For additional validation, see [2]_.\n\nRegularization has not been added because in testing it appears to\ndecrease dipole localization accuracy relative to using all components.\nFine calibration and cross-talk cancellation, however, could be added\nto this algorithm based on user demand.\n\n.. versionadded:: 0.11\n\nReferences\n----------\n.. [1] Taulu S. and Kajola M. \"Presentation of electromagnetic\n       multichannel data: The signal space separation method,\"\n       Journal of Applied Physics, vol. 97, pp. 124905 1-10, 2005.\n.. [2] Wehner DT, H\u00e4m\u00e4l\u00e4inen MS, Mody M, Ahlfors SP. \"Head movements\n       of children in MEG: Quantification, effects on source\n       estimation, and compensation. NeuroImage 40:541\u2013550, 2008.", "metadata": {}}
{"_id": "mne_mne_epochs.py_make_fixed_length_epochs_doc", "text": "Divide continuous raw data into equal-sized consecutive epochs.\n\nParameters\n----------\nraw : instance of Raw\n    Raw data to divide into segments.\nduration : float\n    Duration of each epoch in seconds. Defaults to 1.\n%(preload)s\n%(reject_by_annotation_epochs)s\n\n    .. versionadded:: 0.21.0\n%(proj_epochs)s\n\n    .. versionadded:: 0.22.0\noverlap : float\n    The overlap between epochs, in seconds. Must be\n    ``0 <= overlap < duration``. Default is 0, i.e., no overlap.\n\n    .. versionadded:: 0.23.0\nid : int\n    The id to use (default 1).\n\n    .. versionadded:: 0.24.0\n%(verbose)s\n\nReturns\n-------\nepochs : instance of Epochs\n    Segmented data.\n\nNotes\n-----\n.. versionadded:: 0.20", "metadata": {}}
{"_id": "mne_mne_epochs.py_reset_drop_log_selection_doc", "text": "Reset the drop_log and selection entries.\n\nThis method will simplify ``self.drop_log`` and ``self.selection``\nso that they are meaningless (tuple of empty tuples and increasing\nintegers, respectively). This can be useful when concatenating\nmany Epochs instances, as ``drop_log`` can accumulate many entries\nwhich can become problematic when saving.", "metadata": {}}
{"_id": "mne_mne_epochs.py_load_data_doc", "text": "Load the data if not already preloaded.\n\nReturns\n-------\nepochs : instance of Epochs\n    The epochs object.\n\nNotes\n-----\nThis function operates in-place.\n\n.. versionadded:: 0.10.0", "metadata": {}}
{"_id": "mne_mne_epochs.py_apply_baseline_doc", "text": "Baseline correct epochs.\n\nParameters\n----------\n%(baseline_epochs)s\n    Defaults to ``(None, 0)``, i.e. beginning of the the data until\n    time point zero.\n%(verbose)s\n\nReturns\n-------\nepochs : instance of Epochs\n    The baseline-corrected Epochs object.\n\nNotes\n-----\nBaseline correction can be done multiple times, but can never be\nreverted once the data has been loaded.\n\n.. versionadded:: 0.10.0", "metadata": {}}
{"_id": "mne_mne_epochs.py_iter_evoked_doc", "text": "Iterate over epochs as a sequence of Evoked objects.\n\nThe Evoked objects yielded will each contain a single epoch (i.e., no\naveraging is performed).\n\nThis method resets the object iteration state to the first epoch.\n\nParameters\n----------\ncopy : bool\n    If False copies of data and measurement info will be omitted\n    to save time.", "metadata": {}}
{"_id": "mne_mne_epochs.py_subtract_evoked_doc", "text": "Subtract an evoked response from each epoch.\n\nCan be used to exclude the evoked response when analyzing induced\nactivity, see e.g. [1]_.\n\nParameters\n----------\nevoked : instance of Evoked | None\n    The evoked response to subtract. If None, the evoked response\n    is computed from Epochs itself.\n\nReturns\n-------\nself : instance of Epochs\n    The modified instance (instance is also modified inplace).\n\nReferences\n----------\n.. [1] David et al. \"Mechanisms of evoked and induced responses in\n       MEG/EEG\", NeuroImage, vol. 31, no. 4, pp. 1580-1591, July 2006.", "metadata": {}}
{"_id": "mne_mne_epochs.py_average_doc", "text": "Compute an average over epochs.\n\nParameters\n----------\n%(picks_all_data)s\nmethod : str | callable\n    How to combine the data. If \"mean\"/\"median\", the mean/median\n    are returned.\n    Otherwise, must be a callable which, when passed an array of shape\n    (n_epochs, n_channels, n_time) returns an array of shape\n    (n_channels, n_time).\n    Note that due to file type limitations, the kind for all\n    these will be \"average\".\n%(by_event_type)s\n\nReturns\n-------\n%(evoked_by_event_type_returns)s\n\nNotes\n-----\nComputes an average of all epochs in the instance, even if\nthey correspond to different conditions. To average by condition,\ndo ``epochs[condition].average()`` for each condition separately.\n\nWhen picks is None and epochs contain only ICA channels, no channels\nare selected, resulting in an error. This is because ICA channels\nare not considered data channels (they are of misc type) and only data\nchannels are selected when picks is None.\n\nThe ``method`` parameter allows e.g. robust averaging.\nFor example, one could do:\n\n    >>> from scipy.stats import trim_mean  # doctest:+SKIP\n    >>> trim = lambda x: trim_mean(x, 0.1, axis=0)  # doctest:+SKIP\n    >>> epochs.average(method=trim)  # doctest:+SKIP\n\nThis would compute the trimmed mean.", "metadata": {}}
{"_id": "mne_mne_epochs.py_standard_error_doc", "text": "Compute standard error over epochs.\n\nParameters\n----------\n%(picks_all_data)s\n%(by_event_type)s\n\nReturns\n-------\n%(std_err_by_event_type_returns)s", "metadata": {}}
{"_id": "mne_mne_epochs.py_ch_names_doc", "text": "Channel names.", "metadata": {}}
{"_id": "mne_mne_epochs.py_drop_bad_doc", "text": "Drop bad epochs without retaining the epochs data.\n\nShould be used before slicing operations.\n\n.. warning:: This operation is slow since all epochs have to be read\n             from disk. To avoid reading epochs from disk multiple\n             times, use :meth:`mne.Epochs.load_data()`.\n\n.. note:: To constrain the time period used for estimation of signal\n          quality, set ``epochs.reject_tmin`` and\n          ``epochs.reject_tmax``, respectively.\n\nParameters\n----------\n%(reject_drop_bad)s\n%(flat_drop_bad)s\n%(verbose)s\n\nReturns\n-------\nepochs : instance of Epochs\n    The epochs with bad epochs dropped. Operates in-place.\n\nNotes\n-----\nDropping bad epochs can be done multiple times with different\n``reject`` and ``flat`` parameters. However, once an epoch is\ndropped, it is dropped forever, so if more lenient thresholds may\nsubsequently be applied, :meth:`epochs.copy <mne.Epochs.copy>` should be\nused.", "metadata": {}}
{"_id": "mne_mne_epochs.py_drop_log_stats_doc", "text": "Compute the channel stats based on a drop_log from Epochs.\n\nParameters\n----------\nignore : list\n    The drop reasons to ignore.\n\nReturns\n-------\nperc : float\n    Total percentage of epochs dropped.\n\nSee Also\n--------\nplot_drop_log", "metadata": {}}
{"_id": "mne_mne_epochs.py_drop_doc", "text": "Drop epochs based on indices or boolean mask.\n\n.. note:: The indices refer to the current set of undropped epochs\n          rather than the complete set of dropped and undropped epochs.\n          They are therefore not necessarily consistent with any\n          external indices (e.g., behavioral logs). To drop epochs\n          based on external criteria, do not use the ``preload=True``\n          flag when constructing an Epochs object, and call this\n          method before calling the :meth:`mne.Epochs.drop_bad` or\n          :meth:`mne.Epochs.load_data` methods.\n\nParameters\n----------\nindices : array of int or bool\n    Set epochs to remove by specifying indices to remove or a boolean\n    mask to apply (where True values get removed). Events are\n    correspondingly modified.\nreason : list | tuple | str\n    Reason(s) for dropping the epochs ('ECG', 'timeout', 'blink' etc).\n    Reason(s) are applied to all indices specified.\n    Default: 'USER'.\n%(verbose)s\n\nReturns\n-------\nepochs : instance of Epochs\n    The epochs with indices dropped. Operates in-place.", "metadata": {}}
{"_id": "mne_mne_epochs.py_get_data_doc", "text": "Get all epochs as a 3D array.\n\nParameters\n----------\n%(picks_all)s\nitem : slice | array-like | str | list | None\n    The items to get. See :meth:`mne.Epochs.__getitem__` for\n    a description of valid options. This can be substantially faster\n    for obtaining an ndarray than :meth:`~mne.Epochs.__getitem__`\n    for repeated access on large Epochs objects.\n    None (default) is an alias for ``slice(None)``.\n\n    .. versionadded:: 0.20\n%(units)s\n\n    .. versionadded:: 0.24\ntmin : int | float | None\n    Start time of data to get in seconds.\n\n    .. versionadded:: 0.24.0\ntmax : int | float | None\n    End time of data to get in seconds.\n\n    .. versionadded:: 0.24.0\ncopy : bool\n    Whether to return a copy of the object's data, or (if possible) a view.\n    See :ref:`the NumPy docs <numpy:basics.copies-and-views>` for an\n    explanation. Default is ``False`` in 1.6 but will change to ``True`` in 1.7,\n    set it explicitly to avoid a warning in some cases. A view is only possible\n    when ``item is None``, ``picks is None``, ``units is None``, and data are\n    preloaded.\n\n    .. warning::\n       Using ``copy=False`` and then modifying the returned ``data`` will in\n       turn modify the Epochs object. Use with caution!\n\n    .. versionchanged:: 1.7\n       The default changed from ``False`` to ``True``.\n\n    .. versionadded:: 1.6\n%(verbose)s\n\nReturns\n-------\ndata : array of shape (n_epochs, n_channels, n_times)\n    The epochs data. Will be a copy when ``copy=True`` and will be a view\n    when possible when ``copy=False``.", "metadata": {}}
{"_id": "mne_mne_epochs.py_apply_function_doc", "text": "Apply a function to a subset of channels.\n\n%(applyfun_summary_epochs)s\n\nParameters\n----------\n%(fun_applyfun)s\n%(picks_all_data_noref)s\n%(dtype_applyfun)s\n%(n_jobs)s Ignored if ``channel_wise=False`` as the workload\n    is split across channels.\n%(channel_wise_applyfun_epo)s\n%(verbose)s\n%(kwargs_fun)s\n\nReturns\n-------\nself : instance of Epochs\n    The epochs object with transformed data.", "metadata": {}}
{"_id": "mne_mne_epochs.py_filename_doc", "text": "The filename if the epochs are loaded from disk.\n\n:type: :class:`pathlib.Path` | ``None``", "metadata": {}}
{"_id": "mne_mne_epochs.py_crop_doc", "text": "Crop a time interval from the epochs.\n\nParameters\n----------\ntmin : float | None\n    Start time of selection in seconds.\ntmax : float | None\n    End time of selection in seconds.\n%(include_tmax)s\n%(verbose)s\n\nReturns\n-------\nepochs : instance of Epochs\n    The cropped epochs object, modified in-place.\n\nNotes\n-----\n%(notes_tmax_included_by_default)s", "metadata": {}}
{"_id": "mne_mne_epochs.py_copy_doc", "text": "Return copy of Epochs instance.\n\nReturns\n-------\nepochs : instance of Epochs\n    A copy of the object.", "metadata": {}}
{"_id": "mne_mne_epochs.py_save_doc", "text": "Save epochs in a fif file.\n\nParameters\n----------\nfname : path-like\n    The name of the file, which should end with ``-epo.fif`` or\n    ``-epo.fif.gz``.\nsplit_size : str | int\n    Large raw files are automatically split into multiple pieces. This\n    parameter specifies the maximum size of each piece. If the\n    parameter is an integer, it specifies the size in Bytes. It is\n    also possible to pass a human-readable string, e.g., 100MB.\n    Note: Due to FIFF file limitations, the maximum split size is 2GB.\n\n    .. versionadded:: 0.10.0\nfmt : str\n    Format to save data. Valid options are 'double' or\n    'single' for 64- or 32-bit float, or for 128- or\n    64-bit complex numbers respectively. Note: Data are processed with\n    double precision. Choosing single-precision, the saved data\n    will slightly differ due to the reduction in precision.\n\n    .. versionadded:: 0.17\n%(overwrite)s\n    To overwrite original file (the same one that was loaded),\n    data must be preloaded upon reading. This defaults to True in 0.18\n    but will change to False in 0.19.\n\n    .. versionadded:: 0.18\n%(split_naming)s\n\n    .. versionadded:: 0.24\n%(verbose)s\n\nReturns\n-------\nfnames : List of path-like\n    List of path-like objects containing the path to each file split.\n    .. versionadded:: 1.9\n\nNotes\n-----\nBad epochs will be dropped before saving the epochs to disk.", "metadata": {}}
{"_id": "mne_mne_epochs.py_export_doc", "text": "Export Epochs to external formats.\n\n%(export_fmt_support_epochs)s\n\n%(export_warning)s\n\nParameters\n----------\n%(fname_export_params)s\n%(export_fmt_params_epochs)s\n%(overwrite)s\n\n    .. versionadded:: 0.24.1\n%(verbose)s\n\nNotes\n-----\n.. versionadded:: 0.24\n\n%(export_warning_note_epochs)s\n%(export_eeglab_note)s", "metadata": {}}
{"_id": "mne_mne_epochs.py_equalize_event_counts_doc", "text": "Equalize the number of trials in each condition.\n\nIt tries to make the remaining epochs occurring as close as possible in\ntime. This method works based on the idea that if there happened to be\nsome time-varying (like on the scale of minutes) noise characteristics\nduring a recording, they could be compensated for (to some extent) in\nthe equalization process. This method thus seeks to reduce any of\nthose effects by minimizing the differences in the times of the events\nwithin a `~mne.Epochs` instance. For example, if one event type\noccurred at time points ``[1, 2, 3, 4, 120, 121]`` and the another one\nat ``[3.5, 4.5, 120.5, 121.5]``, this method would remove the events at\ntimes ``[1, 2]`` for the first event type \u2013 and not the events at times\n``[120, 121]``.\n\nParameters\n----------\nevent_ids : None | list | dict\n    The event types to equalize.\n\n    If ``None`` (default), equalize the counts of **all** event types\n    present in the `~mne.Epochs` instance.\n\n    If a list, each element can either be a string (event name) or a\n    list of strings. In the case where one of the entries is a list of\n    strings, event types in that list will be grouped together before\n    equalizing trial counts across conditions.\n\n    If a dictionary, the keys are considered as the event names whose\n    counts to equalize, i.e., passing ``dict(A=1, B=2)`` will have the\n    same effect as passing ``['A', 'B']``. This is useful if you intend\n    to pass an ``event_id`` dictionary that was used when creating\n    `~mne.Epochs`.\n\n    In the case where partial matching is used (using ``/`` in\n    the event names), the event types will be matched according to the\n    provided tags, that is, processing works as if the ``event_ids``\n    matched by the provided tags had been supplied instead.\n    The ``event_ids`` must identify non-overlapping subsets of the\n    epochs.\n%(equalize_events_method)s\n%(random_state)s Used only if ``method='random'``.\n\nReturns\n-------\nepochs : instance of Epochs\n    The modified instance. It is modified in-place.\nindices : array of int\n    Indices from the original events list that were dropped.\n\nNotes\n-----\nFor example (if ``epochs.event_id`` was ``{'Left': 1, 'Right': 2,\n'Nonspatial':3}``:\n\n    epochs.equalize_event_counts([['Left', 'Right'], 'Nonspatial'])\n\nwould equalize the number of trials in the ``'Nonspatial'`` condition\nwith the total number of trials in the ``'Left'`` and ``'Right'``\nconditions combined.\n\nIf multiple indices are provided (e.g. ``'Left'`` and ``'Right'`` in\nthe example above), it is not guaranteed that after equalization the\nconditions will contribute equally. E.g., it is possible to end up\nwith 70 ``'Nonspatial'`` epochs, 69 ``'Left'`` and 1 ``'Right'``.\n\n.. versionchanged:: 0.23\n    Default to equalizing all events in the passed instance if no\n    event names were specified explicitly.", "metadata": {}}
{"_id": "mne_mne_epochs.py_compute_psd_doc", "text": "Perform spectral analysis on sensor data.\n\nParameters\n----------\n%(method_psd)s\n    Default is ``'multitaper'``.\n%(fmin_fmax_psd)s\n%(tmin_tmax_psd)s\n%(picks_good_data_noref)s\n%(proj_psd)s\n%(remove_dc)s\n%(exclude_psd)s\n%(n_jobs)s\n%(verbose)s\n%(method_kw_psd)s\n\nReturns\n-------\nspectrum : instance of EpochsSpectrum\n    The spectral representation of each epoch.\n\nNotes\n-----\n.. versionadded:: 1.2\n\nReferences\n----------\n.. footbibliography::", "metadata": {}}
{"_id": "mne_mne_epochs.py_compute_tfr_doc", "text": "Compute a time-frequency representation of epoched data.\n\nParameters\n----------\n%(method_tfr_epochs)s\n%(freqs_tfr_epochs)s\n%(tmin_tmax_psd)s\n%(picks_good_data_noref)s\n%(proj_psd)s\n%(output_compute_tfr)s\naverage : bool\n    Whether to return average power across epochs (instead of single-trial\n    power). ``average=True`` is not compatible with ``output=\"complex\"`` or\n    ``output=\"phase\"``. Ignored if ``method=\"stockwell\"`` (Stockwell method\n    *requires* averaging). Default is ``False``.\nreturn_itc : bool\n    Whether to return inter-trial coherence (ITC) as well as power estimates.\n    If ``True`` then must specify ``average=True`` (or ``method=\"stockwell\",\n    average=\"auto\"``). Default is ``False``.\n%(decim_tfr)s\n%(n_jobs)s\n%(verbose)s\n%(method_kw_epochs_tfr)s\n\nReturns\n-------\ntfr : instance of EpochsTFR or AverageTFR\n    The time-frequency-resolved power estimates.\nitc : instance of AverageTFR\n    The inter-trial coherence (ITC). Only returned if ``return_itc=True``.\n\nNotes\n-----\nIf ``average=True`` (or ``method=\"stockwell\", average=\"auto\"``) the result will\nbe an :class:`~mne.time_frequency.AverageTFR` instead of an\n:class:`~mne.time_frequency.EpochsTFR`.\n\n.. versionadded:: 1.7\n\nReferences\n----------\n.. footbibliography::", "metadata": {}}
{"_id": "mne_mne_epochs.py_plot_psd_doc", "text": "%(plot_psd_doc)s.\n\nParameters\n----------\n%(fmin_fmax_psd)s\n%(tmin_tmax_psd)s\n%(picks_good_data_noref)s\n%(proj_psd)s\n%(method_plot_psd_auto)s\n%(average_plot_psd)s\n%(dB_plot_psd)s\n%(estimate_plot_psd)s\n%(xscale_plot_psd)s\n%(area_mode_plot_psd)s\n%(area_alpha_plot_psd)s\n%(color_plot_psd)s\n%(line_alpha_plot_psd)s\n%(spatial_colors_psd)s\n%(sphere_topomap_auto)s\n\n    .. versionadded:: 0.22.0\nexclude : list of str | 'bads'\n    Channels names to exclude from being shown. If 'bads', the bad\n    channels are excluded. Pass an empty list to plot all channels\n    (including channels marked \"bad\", if any).\n\n    .. versionadded:: 0.24.0\n%(ax_plot_psd)s\n%(show)s\n%(n_jobs)s\n%(verbose)s\n%(method_kw_psd)s\n\nReturns\n-------\nfig : instance of Figure\n    Figure with frequency spectra of the data channels.\n\nNotes\n-----\n%(notes_plot_psd_meth)s", "metadata": {}}
{"_id": "mne_mne_epochs.py_to_data_frame_doc", "text": "Export data in tabular structure as a pandas DataFrame.\n\nChannels are converted to columns in the DataFrame. By default,\nadditional columns \"time\", \"epoch\" (epoch number), and \"condition\"\n(epoch event description) are added, unless ``index`` is not ``None``\n(in which case the columns specified in ``index`` will be used to form\nthe DataFrame's index instead).\n\nParameters\n----------\n%(picks_all)s\n%(index_df_epo)s\n    Valid string values are 'time', 'epoch', and 'condition'.\n    Defaults to ``None``.\n%(scalings_df)s\n%(copy_df)s\n%(long_format_df_epo)s\n%(time_format_df)s\n\n    .. versionadded:: 0.20\n%(verbose)s\n\nReturns\n-------\n%(df_return)s", "metadata": {}}
{"_id": "mne_mne_epochs.py_as_type_doc", "text": "Compute virtual epochs using interpolated fields.\n\n.. Warning:: Using virtual epochs to compute inverse can yield\n    unexpected results. The virtual channels have ``'_v'`` appended\n    at the end of the names to emphasize that the data contained in\n    them are interpolated.\n\nParameters\n----------\nch_type : str\n    The destination channel type. It can be 'mag' or 'grad'.\nmode : str\n    Either ``'accurate'`` or ``'fast'``, determines the quality of the\n    Legendre polynomial expansion used. ``'fast'`` should be sufficient\n    for most applications.\n\nReturns\n-------\nepochs : instance of mne.EpochsArray\n    The transformed epochs object containing only virtual channels.\n\nNotes\n-----\nThis method returns a copy and does not modify the data it\noperates on. It also returns an EpochsArray instance.\n\n.. versionadded:: 0.20.0", "metadata": {}}
{"_id": "mne_mne_evoked.py_combine_evoked_doc", "text": "Merge evoked data by weighted addition or subtraction.\n\nEach `~mne.Evoked` in ``all_evoked`` should have the same channels and the\nsame time instants. Subtraction can be performed by passing\n``weights=[1, -1]``.\n\n.. Warning::\n    Other than cases like simple subtraction mentioned above (where all\n    weights are ``-1`` or ``1``), if you provide numeric weights instead of using\n    ``'equal'`` or ``'nave'``, the resulting `~mne.Evoked` object's\n    ``.nave`` attribute (which is used to scale noise covariance when\n    applying the inverse operator) may not be suitable for inverse imaging.\n\nParameters\n----------\nall_evoked : list of Evoked\n    The evoked datasets.\nweights : list of float | ``'equal'`` | ``'nave'``\n    The weights to apply to the data of each evoked instance, or a string\n    describing the weighting strategy to apply: ``'nave'`` computes\n    sum-to-one weights proportional to each object's ``nave`` attribute;\n    ``'equal'`` weights each `~mne.Evoked` by ``1 / len(all_evoked)``.\n\nReturns\n-------\nevoked : Evoked\n    The new evoked data.\n\nNotes\n-----\n.. versionadded:: 0.9.0", "metadata": {}}
{"_id": "mne_mne_evoked.py_read_evokeds_doc", "text": "Read evoked dataset(s).\n\nParameters\n----------\nfname : path-like\n    The filename, which should end with ``-ave.fif`` or ``-ave.fif.gz``.\ncondition : int or str | list of int or str | None\n    The index or list of indices of the evoked dataset to read. FIF files\n    can contain multiple datasets. If None, all datasets are returned as a\n    list.\n%(baseline_evoked)s\n    If ``None`` (default), do not apply baseline correction.\n\n    .. note:: Note that if the read  `~mne.Evoked` objects have already\n              been baseline-corrected, the data retrieved from disk will\n              **always** be baseline-corrected (in fact, only the\n              baseline-corrected version of the data will be saved, so\n              there is no way to undo this procedure). Only **after** the\n              data has been loaded, a custom (additional) baseline\n              correction **may** be optionally applied by passing a tuple\n              here. Passing ``None`` will **not** remove an existing\n              baseline correction, but merely omit the optional, additional\n              baseline correction.\nkind : str\n    Either ``'average'`` or ``'standard_error'``, the type of data to read.\nproj : bool\n    If False, available projectors won't be applied to the data.\nallow_maxshield : bool | str (default False)\n    If True, allow loading of data that has been recorded with internal\n    active compensation (MaxShield). Data recorded with MaxShield should\n    generally not be loaded directly, but should first be processed using\n    SSS/tSSS to remove the compensation signals that may also affect brain\n    activity. Can also be ``\"yes\"`` to load without eliciting a warning.\n%(verbose)s\n\nReturns\n-------\nevoked : Evoked or list of Evoked\n    The evoked dataset(s); one `~mne.Evoked` if ``condition`` is an\n    integer or string; or a list of `~mne.Evoked` if ``condition`` is\n    ``None`` or a list.\n\nSee Also\n--------\nwrite_evokeds\n\nNotes\n-----\n.. versionchanged:: 0.23\n    If the read `~mne.Evoked` objects had been baseline-corrected before\n    saving, this will be reflected in their ``baseline`` attribute after\n    reading.", "metadata": {}}
{"_id": "mne_mne_evoked.py_write_evokeds_doc", "text": "Write an evoked dataset to a file.\n\nParameters\n----------\nfname : path-like\n    The file name, which should end with ``-ave.fif`` or ``-ave.fif.gz``.\nevoked : Evoked instance, or list of Evoked instances\n    The evoked dataset, or list of evoked datasets, to save in one file.\n    Note that the measurement info from the first evoked instance is used,\n    so be sure that information matches.\n%(on_mismatch_info)s\n%(overwrite)s\n\n    .. versionadded:: 1.0\n%(verbose)s\n\n    .. versionadded:: 0.24\n\nSee Also\n--------\nread_evokeds\n\nNotes\n-----\n.. versionchanged:: 0.23\n    Information on baseline correction will be stored with each individual\n    `~mne.Evoked` object, and will be restored when reading the data again\n    via `mne.read_evokeds`.", "metadata": {}}
{"_id": "mne_mne_evoked.py_filename_doc", "text": "The filename of the evoked object, if it exists.\n\n:type: :class:`~pathlib.Path` | None", "metadata": {}}
{"_id": "mne_mne_evoked.py_kind_doc", "text": "The data kind.", "metadata": {}}
{"_id": "mne_mne_evoked.py_data_doc", "text": "The data matrix.", "metadata": {}}
{"_id": "mne_mne_evoked.py_data_doc", "text": "Set the data matrix.", "metadata": {}}
{"_id": "mne_mne_evoked.py_get_data_doc", "text": "Get evoked data as 2D array.\n\nParameters\n----------\n%(picks_all)s\n%(units)s\ntmin : float | None\n    Start time of data to get in seconds.\ntmax : float | None\n    End time of data to get in seconds.\n\nReturns\n-------\ndata : ndarray, shape (n_channels, n_times)\n    A view on evoked data.\n\nNotes\n-----\n.. versionadded:: 0.24", "metadata": {}}
{"_id": "mne_mne_evoked.py_apply_function_doc", "text": "Apply a function to a subset of channels.\n\n%(applyfun_summary_evoked)s\n\nParameters\n----------\n%(fun_applyfun_evoked)s\n%(picks_all_data_noref)s\n%(dtype_applyfun)s\n%(n_jobs)s Ignored if ``channel_wise=False`` as the workload\n    is split across channels.\n%(channel_wise_applyfun)s\n\n    .. versionadded:: 1.6\n%(verbose)s\n%(kwargs_fun)s\n\nReturns\n-------\nself : instance of Evoked\n    The evoked object with transformed data.", "metadata": {}}
{"_id": "mne_mne_evoked.py_apply_baseline_doc", "text": "Baseline correct evoked data.\n\nParameters\n----------\n%(baseline_evoked)s\n    Defaults to ``(None, 0)``, i.e. beginning of the the data until\n    time point zero.\n%(verbose)s\n\nReturns\n-------\nevoked : instance of Evoked\n    The baseline-corrected Evoked object.\n\nNotes\n-----\nBaseline correction can be done multiple times.\n\n.. versionadded:: 0.13.0", "metadata": {}}
{"_id": "mne_mne_evoked.py_save_doc", "text": "Save evoked data to a file.\n\nParameters\n----------\nfname : path-like\n    The name of the file, which should end with ``-ave.fif(.gz)`` or\n    ``_ave.fif(.gz)``.\n%(overwrite)s\n%(verbose)s\n\nNotes\n-----\nTo write multiple conditions into a single file, use\n`mne.write_evokeds`.\n\n.. versionchanged:: 0.23\n    Information on baseline correction will be stored with the data,\n    and will be restored when reading again via `mne.read_evokeds`.", "metadata": {}}
{"_id": "mne_mne_evoked.py_export_doc", "text": "Export Evoked to external formats.\n\n%(export_fmt_support_evoked)s\n\n%(export_warning)s\n\nParameters\n----------\n%(fname_export_params)s\n%(export_fmt_params_evoked)s\n%(overwrite)s\n%(verbose)s\n\nNotes\n-----\n.. versionadded:: 1.1\n\n%(export_warning_note_evoked)s", "metadata": {}}
{"_id": "mne_mne_evoked.py_ch_names_doc", "text": "Channel names.", "metadata": {}}
{"_id": "mne_mne_evoked.py_plot_topo_doc", "text": ".\n\nNotes\n-----\n.. versionadded:: 0.10.0", "metadata": {}}
{"_id": "mne_mne_evoked.py_animate_topomap_doc", "text": "Make animation of evoked data as topomap timeseries.\n\nThe animation can be paused/resumed with left mouse button.\nLeft and right arrow keys can be used to move backward or forward\nin time.\n\nParameters\n----------\nch_type : str | None\n    Channel type to plot. Accepted data types: 'mag', 'grad', 'eeg',\n    'hbo', 'hbr', 'fnirs_cw_amplitude',\n    'fnirs_fd_ac_amplitude', 'fnirs_fd_phase', and 'fnirs_od'.\n    If None, first available channel type from the above list is used.\n    Defaults to None.\ntimes : array of float | None\n    The time points to plot. If None, 10 evenly spaced samples are\n    calculated over the evoked time series. Defaults to None.\nframe_rate : int | None\n    Frame rate for the animation in Hz. If None,\n    frame rate = sfreq / 10. Defaults to None.\nbutterfly : bool\n    Whether to plot the data as butterfly plot under the topomap.\n    Defaults to False.\nblit : bool\n    Whether to use blit to optimize drawing. In general, it is\n    recommended to use blit in combination with ``show=True``. If you\n    intend to save the animation it is better to disable blit.\n    Defaults to True.\nshow : bool\n    Whether to show the animation. Defaults to True.\ntime_unit : str\n    The units for the time axis, can be \"ms\" (default in 0.16)\n    or \"s\" (will become the default in 0.17).\n\n    .. versionadded:: 0.16\n%(sphere_topomap_auto)s\n%(image_interp_topomap)s\n%(extrapolate_topomap)s\n\n    .. versionadded:: 0.22\n%(vmin_vmax_topomap)s\n\n    .. versionadded:: 1.1.0\n%(verbose)s\n\nReturns\n-------\nfig : instance of matplotlib.figure.Figure\n    The figure.\nanim : instance of matplotlib.animation.FuncAnimation\n    Animation of the topomap.\n\nNotes\n-----\n.. versionadded:: 0.12.0", "metadata": {}}
{"_id": "mne_mne_evoked.py_as_type_doc", "text": "Compute virtual evoked using interpolated fields.\n\n.. Warning:: Using virtual evoked to compute inverse can yield\n    unexpected results. The virtual channels have ``'_v'`` appended\n    at the end of the names to emphasize that the data contained in\n    them are interpolated.\n\nParameters\n----------\nch_type : str\n    The destination channel type. It can be 'mag' or 'grad'.\nmode : str\n    Either ``'accurate'`` or ``'fast'``, determines the quality of the\n    Legendre polynomial expansion used. ``'fast'`` should be sufficient\n    for most applications.\n\nReturns\n-------\nevoked : instance of mne.Evoked\n    The transformed evoked object containing only virtual channels.\n\nNotes\n-----\nThis method returns a copy and does not modify the data it\noperates on. It also returns an EvokedArray instance.\n\n.. versionadded:: 0.9.0", "metadata": {}}
{"_id": "mne_mne_evoked.py_detrend_doc", "text": "Detrend data.\n\nThis function operates in-place.\n\nParameters\n----------\norder : int\n    Either 0 or 1, the order of the detrending. 0 is a constant\n    (DC) detrend, 1 is a linear detrend.\n%(picks_good_data)s\n\nReturns\n-------\nevoked : instance of Evoked\n    The detrended evoked object.", "metadata": {}}
{"_id": "mne_mne_evoked.py_copy_doc", "text": "Copy the instance of evoked.\n\nReturns\n-------\nevoked : instance of Evoked\n    A copy of the object.", "metadata": {}}
{"_id": "mne_mne_evoked.py_get_peak_doc", "text": "Get location and latency of peak amplitude.\n\nParameters\n----------\nch_type : str | None\n    The channel type to use. Defaults to None. If more than one channel\n    type is present in the data, this value **must** be provided.\ntmin : float | None\n    The minimum point in time to be considered for peak getting.\n    If None (default), the beginning of the data is used.\ntmax : float | None\n    The maximum point in time to be considered for peak getting.\n    If None (default), the end of the data is used.\nmode : 'pos' | 'neg' | 'abs'\n    How to deal with the sign of the data. If 'pos' only positive\n    values will be considered. If 'neg' only negative values will\n    be considered. If 'abs' absolute values will be considered.\n    Defaults to 'abs'.\ntime_as_index : bool\n    Whether to return the time index instead of the latency in seconds.\nmerge_grads : bool\n    If True, compute peak from merged gradiometer data.\nreturn_amplitude : bool\n    If True, return also the amplitude at the maximum response.\n\n    .. versionadded:: 0.16\nstrict : bool\n    If True, raise an error if values are all positive when detecting\n    a minimum (mode='neg'), or all negative when detecting a maximum\n    (mode='pos'). Defaults to True.\n\n    .. versionadded:: 1.7\n\nReturns\n-------\nch_name : str\n    The channel exhibiting the maximum response.\nlatency : float | int\n    The time point of the maximum response, either latency in seconds\n    or index.\namplitude : float\n    The amplitude of the maximum response. Only returned if\n    return_amplitude is True.\n\n    .. versionadded:: 0.16", "metadata": {}}
{"_id": "mne_mne_evoked.py_compute_psd_doc", "text": "Perform spectral analysis on sensor data.\n\nParameters\n----------\n%(method_psd)s\n    Default is ``'multitaper'``.\n%(fmin_fmax_psd)s\n%(tmin_tmax_psd)s\n%(picks_good_data_noref)s\n%(proj_psd)s\n%(remove_dc)s\n%(exclude_psd)s\n%(n_jobs)s\n%(verbose)s\n%(method_kw_psd)s\n\nReturns\n-------\nspectrum : instance of Spectrum\n    The spectral representation of the data.\n\nNotes\n-----\n.. versionadded:: 1.2\n\nReferences\n----------\n.. footbibliography::", "metadata": {}}
{"_id": "mne_mne_evoked.py_compute_tfr_doc", "text": "Compute a time-frequency representation of evoked data.\n\nParameters\n----------\n%(method_tfr)s\n%(freqs_tfr)s\n%(tmin_tmax_psd)s\n%(picks_good_data_noref)s\n%(proj_psd)s\n%(output_compute_tfr)s\n%(decim_tfr)s\n%(n_jobs)s\n%(verbose)s\n%(method_kw_tfr)s\n\nReturns\n-------\ntfr : instance of AverageTFR\n    The time-frequency-resolved power estimates of the data.\n\nNotes\n-----\n.. versionadded:: 1.7\n\nReferences\n----------\n.. footbibliography::", "metadata": {}}
{"_id": "mne_mne_evoked.py_plot_psd_doc", "text": "%(plot_psd_doc)s.\n\nParameters\n----------\n%(fmin_fmax_psd)s\n%(tmin_tmax_psd)s\n%(picks_good_data_noref)s\n%(proj_psd)s\n%(method_plot_psd_auto)s\n%(average_plot_psd)s\n%(dB_plot_psd)s\n%(estimate_plot_psd)s\n%(xscale_plot_psd)s\n%(area_mode_plot_psd)s\n%(area_alpha_plot_psd)s\n%(color_plot_psd)s\n%(line_alpha_plot_psd)s\n%(spatial_colors_psd)s\n%(sphere_topomap_auto)s\n\n    .. versionadded:: 0.22.0\nexclude : list of str | 'bads'\n    Channels names to exclude from being shown. If 'bads', the bad\n    channels are excluded. Pass an empty list to plot all channels\n    (including channels marked \"bad\", if any).\n\n    .. versionadded:: 0.24.0\n%(ax_plot_psd)s\n%(show)s\n%(n_jobs)s\n%(verbose)s\n%(method_kw_psd)s\n\nReturns\n-------\nfig : instance of Figure\n    Figure with frequency spectra of the data channels.\n\nNotes\n-----\n%(notes_plot_psd_meth)s", "metadata": {}}
{"_id": "mne_mne_evoked.py_to_data_frame_doc", "text": "Export data in tabular structure as a pandas DataFrame.\n\nChannels are converted to columns in the DataFrame. By default,\nan additional column \"time\" is added, unless ``index='time'``\n(in which case time values form the DataFrame's index).\n\nParameters\n----------\n%(picks_all)s\n%(index_df_evk)s\n    Defaults to ``None``.\n%(scalings_df)s\n%(copy_df)s\n%(long_format_df_raw)s\n%(time_format_df)s\n\n    .. versionadded:: 0.20\n%(verbose)s\n\nReturns\n-------\n%(df_return)s", "metadata": {}}
{"_id": "mne_mne_proj.py_read_proj_doc", "text": "Read projections from a FIF file.\n\nParameters\n----------\nfname : path-like\n    The name of file containing the projections vectors. It should end with\n    ``-proj.fif`` or ``-proj.fif.gz``.\n%(verbose)s\n\nReturns\n-------\nprojs : list of Projection\n    The list of projection vectors.\n\nSee Also\n--------\nwrite_proj", "metadata": {}}
{"_id": "mne_mne_proj.py_write_proj_doc", "text": "Write projections to a FIF file.\n\nParameters\n----------\nfname : path-like\n    The name of file containing the projections vectors. It should end with\n    ``-proj.fif`` or ``-proj.fif.gz``.\nprojs : list of Projection\n    The list of projection vectors.\n%(overwrite)s\n\n    .. versionadded:: 1.0\n%(verbose)s\n\n    .. versionadded:: 1.0\n\nSee Also\n--------\nread_proj", "metadata": {}}
{"_id": "mne_mne_proj.py_compute_proj_epochs_doc", "text": "Compute SSP (signal-space projection) vectors on epoched data.\n\n%(compute_ssp)s\n\nParameters\n----------\nepochs : instance of Epochs\n    The epochs containing the artifact.\n%(n_proj_vectors)s\n%(n_jobs)s\n    Number of jobs to use to compute covariance.\ndesc_prefix : str | None\n    The description prefix to use. If None, one will be created based on\n    the event_id, tmin, and tmax.\nmeg : str\n    Can be ``'separate'`` (default) or ``'combined'`` to compute projectors\n    for magnetometers and gradiometers separately or jointly.\n    If ``'combined'``, ``n_mag == n_grad`` is required and the number of\n    projectors computed for MEG will be ``n_mag``.\n\n    .. versionadded:: 0.18\n%(verbose)s\n\nReturns\n-------\nprojs: list of Projection\n    List of projection vectors.\n\nSee Also\n--------\ncompute_proj_raw, compute_proj_evoked", "metadata": {}}
{"_id": "mne_mne_proj.py_compute_proj_evoked_doc", "text": "Compute SSP (signal-space projection) vectors on evoked data.\n\n%(compute_ssp)s\n\nParameters\n----------\nevoked : instance of Evoked\n    The Evoked obtained by averaging the artifact.\n%(n_proj_vectors)s\ndesc_prefix : str | None\n    The description prefix to use. If None, one will be created based on\n    tmin and tmax.\n\n    .. versionadded:: 0.17\nmeg : str\n    Can be ``'separate'`` (default) or ``'combined'`` to compute projectors\n    for magnetometers and gradiometers separately or jointly.\n    If ``'combined'``, ``n_mag == n_grad`` is required and the number of\n    projectors computed for MEG will be ``n_mag``.\n\n    .. versionadded:: 0.18\n%(verbose)s\n\nReturns\n-------\nprojs : list of Projection\n    List of projection vectors.\n\nSee Also\n--------\ncompute_proj_raw, compute_proj_epochs", "metadata": {}}
{"_id": "mne_mne_proj.py_compute_proj_raw_doc", "text": "Compute SSP (signal-space projection) vectors on continuous data.\n\n%(compute_ssp)s\n\nParameters\n----------\nraw : instance of Raw\n    A raw object to use the data from.\nstart : float\n    Time (in seconds) to start computing SSP.\nstop : float | None\n    Time (in seconds) to stop computing SSP. None will go to the end of the file.\nduration : float | None\n    Duration (in seconds) to chunk data into for SSP\n    If duration is ``None``, data will not be chunked.\n%(n_proj_vectors)s\nreject : dict | None\n    Epoch PTP rejection threshold used if ``duration != None``. See `~mne.Epochs`.\nflat : dict | None\n    Epoch flatness rejection threshold used if ``duration != None``. See\n    `~mne.Epochs`.\n%(n_jobs)s\n    Number of jobs to use to compute covariance.\nmeg : str\n    Can be ``'separate'`` (default) or ``'combined'`` to compute projectors\n    for magnetometers and gradiometers separately or jointly.\n    If ``'combined'``, ``n_mag == n_grad`` is required and the number of\n    projectors computed for MEG will be ``n_mag``.\n\n    .. versionadded:: 0.18\n%(verbose)s\n\nReturns\n-------\nprojs: list of Projection\n    List of projection vectors.\n\nSee Also\n--------\ncompute_proj_epochs, compute_proj_evoked", "metadata": {}}
{"_id": "mne_mne_proj.py_sensitivity_map_doc", "text": "Compute sensitivity map.\n\nSuch maps are used to know how much sources are visible by a type\nof sensor, and how much projections shadow some sources.\n\nParameters\n----------\nfwd : Forward\n    The forward operator.\nprojs : list\n    List of projection vectors.\nch_type : ``'grad'`` | ``'mag'`` | ``'eeg'``\n    The type of sensors to use.\nmode : str\n    The type of sensitivity map computed. See manual. Should be ``'free'``,\n    ``'fixed'``, ``'ratio'``, ``'radiality'``, ``'angle'``,\n    ``'remaining'``, or ``'dampening'`` corresponding to the argument\n    ``--map 1, 2, 3, 4, 5, 6, 7`` of the command ``mne_sensitivity_map``.\nexclude : list of str | str\n    List of channels to exclude. If empty do not exclude any (default).\n    If ``'bads'``, exclude channels in ``fwd['info']['bads']``.\n%(verbose)s\n\nReturns\n-------\nstc : SourceEstimate | VolSourceEstimate\n    The sensitivity map as a SourceEstimate or VolSourceEstimate instance\n    for visualization.\n\nNotes\n-----\nWhen mode is ``'fixed'`` or ``'free'``, the sensitivity map is normalized\nby its maximum value.", "metadata": {}}
{"_id": "mne_mne_misc.py_parse_config_doc", "text": "Parse a config file (like .ave and .cov files).\n\nParameters\n----------\nfname : path-like\n    Config file name.\n\nReturns\n-------\nconditions : list of dict\n    Each condition is indexed by the event type.\n    A condition contains as keys::\n\n        tmin, tmax, name, grad_reject, mag_reject,\n        eeg_reject, eog_reject", "metadata": {}}
{"_id": "mne_mne_misc.py_read_reject_parameters_doc", "text": "Read rejection parameters from .cov or .ave config file.\n\nParameters\n----------\nfname : path-like\n    Filename to read.\n\nReturns\n-------\nparams : dict\n    The rejection parameters.", "metadata": {}}
{"_id": "mne_mne_fixes.py_rng_uniform_doc", "text": "Get the uniform/randint from the rng.", "metadata": {}}
{"_id": "mne_mne_fixes.py_empirical_covariance_doc", "text": "Compute the Maximum likelihood covariance estimator.\n\nParameters\n----------\nX : ndarray, shape (n_samples, n_features)\n    Data from which to compute the covariance estimate\n\nassume_centered : Boolean\n    If True, data are not centered before computation.\n    Useful when working with data whose mean is almost, but not exactly\n    zero.\n    If False, data are centered before computation.\n\nReturns\n-------\ncovariance : 2D ndarray, shape (n_features, n_features)\n    Empirical covariance (Maximum Likelihood Estimator).", "metadata": {}}
{"_id": "mne_mne_fixes.py_log_likelihood_doc", "text": "Compute the sample mean of the log_likelihood under a covariance model.\n\ncomputes the empirical expected log-likelihood (accounting for the\nnormalization terms and scaling), allowing for universal comparison (beyond\nthis software package)\n\nParameters\n----------\nemp_cov : 2D ndarray (n_features, n_features)\n    Maximum Likelihood Estimator of covariance\n\nprecision : 2D ndarray (n_features, n_features)\n    The precision matrix of the covariance model to be tested\n\nReturns\n-------\nsample mean of the log-likelihood", "metadata": {}}
{"_id": "mne_mne_fixes.py_stable_cumsum_doc", "text": "Use high precision for cumsum and check that final value matches sum.\n\nParameters\n----------\narr : array-like\n    To be cumulatively summed as flat\naxis : int, optional\n    Axis along which the cumulative sum is computed.\n    The default (None) is to compute the cumsum over the flattened array.\nrtol : float\n    Relative tolerance, see ``np.allclose``\natol : float\n    Absolute tolerance, see ``np.allclose``", "metadata": {}}
{"_id": "mne_mne_fixes.py_minimum_phase_doc", "text": "Wrap scipy.signal.minimum_phase with half option.", "metadata": {}}
{"_id": "mne_mne_fixes.py_sph_harm_y_doc", "text": "Wrap scipy.special.sph_harm for sph_harm_y.", "metadata": {}}
{"_id": "mne_mne_fixes.py_get_params_doc", "text": "Get parameters for this estimator.\n\nParameters\n----------\ndeep : bool, default=True\n    If True, will return the parameters for this estimator and\n    contained subobjects that are estimators.\n\nReturns\n-------\nparams : dict\n    Parameter names mapped to their values.", "metadata": {}}
{"_id": "mne_mne_fixes.py_set_params_doc", "text": "Set the parameters of this estimator.\n\nThe method works on simple estimators as well as on nested objects\n(such as pipelines). The latter have parameters of the form\n``<component>__<parameter>`` so that it's possible to update each\ncomponent of a nested object.\n\nParameters\n----------\n**params : dict\n    Estimator parameters.\n\nReturns\n-------\nself : object\n    Estimator instance.", "metadata": {}}
{"_id": "mne_mne_fixes.py_get_precision_doc", "text": "Getter for the precision matrix.\n\nReturns\n-------\nprecision_ : array-like,\n    The precision matrix associated to the current covariance object.", "metadata": {}}
{"_id": "mne_mne_fixes.py_fit_doc", "text": "Fit the Maximum Likelihood Estimator covariance model.\n\nParameters\n----------\nX : array-like, shape = [n_samples, n_features]\n  Training data, where n_samples is the number of samples and\n  n_features is the number of features.\ny : ndarray | None\n    Not used, present for API consistency.\n\nReturns\n-------\nself : object\n    Returns self.", "metadata": {}}
{"_id": "mne_mne_fixes.py_score_doc", "text": "Compute the log-likelihood of a Gaussian dataset.\n\nUses ``self.covariance_`` as an estimator of its covariance matrix.\n\nParameters\n----------\nX_test : array-like, shape = [n_samples, n_features]\n    Test data of which we compute the likelihood, where n_samples is\n    the number of samples and n_features is the number of features.\n    X_test is assumed to be drawn from the same distribution than\n    the data used in fit (including centering).\ny : ndarray | None\n    Not used, present for API consistency.\n\nReturns\n-------\nres : float\n    The likelihood of the data set with `self.covariance_` as an\n    estimator of its covariance matrix.", "metadata": {}}
{"_id": "mne_mne_fixes.py_error_norm_doc", "text": "Compute the Mean Squared Error between two covariance estimators.\n\nParameters\n----------\ncomp_cov : array-like, shape = [n_features, n_features]\n    The covariance to compare with.\nnorm : str\n    The type of norm used to compute the error. Available error types:\n    - 'frobenius' (default): sqrt(tr(A^t.A))\n    - 'spectral': sqrt(max(eigenvalues(A^t.A))\n    where A is the error ``(comp_cov - self.covariance_)``.\nscaling : bool\n    If True (default), the squared error norm is divided by n_features.\n    If False, the squared error norm is not rescaled.\nsquared : bool\n    Whether to compute the squared error norm or the error norm.\n    If True (default), the squared error norm is returned.\n    If False, the error norm is returned.\n\nReturns\n-------\nThe Mean Squared Error (in the sense of the Frobenius norm) between\n`self` and `comp_cov` covariance estimators.", "metadata": {}}
{"_id": "mne_mne_fixes.py_mahalanobis_doc", "text": "Compute the squared Mahalanobis distances of given observations.\n\nParameters\n----------\nobservations : array-like, shape = [n_observations, n_features]\n    The observations, the Mahalanobis distances of the which we\n    compute. Observations are assumed to be drawn from the same\n    distribution than the data used in fit.\n\nReturns\n-------\nmahalanobis_distance : array, shape = [n_observations,]\n    Squared Mahalanobis distances of the observations.", "metadata": {}}
{"_id": "mne_mne__freesurfer.py_get_volume_labels_from_aseg_doc", "text": "Return a list of names and colors of segmented volumes.\n\nParameters\n----------\nmgz_fname : path-like\n    Filename to read. Typically ``aseg.mgz`` or some variant in the\n    freesurfer pipeline.\nreturn_colors : bool\n    If True returns also the labels colors.\natlas_ids : dict | None\n    A lookup table providing a mapping from region names (str) to ID values\n    (int). Can be None to use the standard Freesurfer LUT.\n\n    .. versionadded:: 0.21.0\n\nReturns\n-------\nlabel_names : list of str\n    The names of segmented volumes included in this mgz file.\nlabel_colors : list of str\n    The RGB colors of the labels included in this mgz file.\n\nSee Also\n--------\nread_freesurfer_lut\n\nNotes\n-----\n.. versionchanged:: 0.21.0\n   The label names are now sorted in the same order as their corresponding\n   values in the MRI file.\n\n.. versionadded:: 0.9.0", "metadata": {}}
{"_id": "mne_mne__freesurfer.py_head_to_mri_doc", "text": "Convert pos from head coordinate system to MRI ones.\n\nParameters\n----------\npos : array, shape (n_pos, 3)\n    The coordinates (in m) in head coordinate system.\n%(subject)s\nmri_head_t : instance of Transform\n    MRI<->Head coordinate transformation.\n%(subjects_dir)s\nkind : str\n    The  MRI coordinate frame kind, can be ``'mri'`` (default) for\n    FreeSurfer surface RAS or ``'ras'`` (default in 1.2) to use MRI RAS\n    (scanner RAS).\n\n    .. versionadded:: 1.2\nunscale : bool\n    For surrogate MRIs (e.g., scaled using ``mne coreg``), if True\n    (default False), use the MRI scaling parameters to obtain points in\n    the original/surrogate subject's MRI space.\n\n    .. versionadded:: 1.2\n%(verbose)s\n\nReturns\n-------\ncoordinates : array, shape (n_pos, 3)\n    The MRI RAS coordinates (in mm) of pos.\n\nNotes\n-----\nThis function requires nibabel.", "metadata": {}}
{"_id": "mne_mne__freesurfer.py_vertex_to_mni_doc", "text": "Convert the array of vertices for a hemisphere to MNI coordinates.\n\nParameters\n----------\nvertices : int, or list of int\n    Vertex number(s) to convert.\nhemis : int, or list of int\n    Hemisphere(s) the vertices belong to.\n%(subject)s\nsubjects_dir : str, or None\n    Path to ``SUBJECTS_DIR`` if it is not set in the environment.\n%(verbose)s\n\nReturns\n-------\ncoordinates : array, shape (n_vertices, 3)\n    The MNI coordinates (in mm) of the vertices.", "metadata": {}}
{"_id": "mne_mne__freesurfer.py_head_to_mni_doc", "text": "Convert pos from head coordinate system to MNI ones.\n\nParameters\n----------\npos : array, shape (n_pos, 3)\n    The coordinates (in m) in head coordinate system.\n%(subject)s\nmri_head_t : instance of Transform\n    MRI<->Head coordinate transformation.\n%(subjects_dir)s\n%(verbose)s\n\nReturns\n-------\ncoordinates : array, shape (n_pos, 3)\n    The MNI coordinates (in mm) of pos.\n\nNotes\n-----\nThis function requires either nibabel.", "metadata": {}}
{"_id": "mne_mne__freesurfer.py_get_mni_fiducials_doc", "text": "Estimate fiducials for a subject.\n\nParameters\n----------\n%(subject)s\n%(subjects_dir)s\n%(verbose)s\n\nReturns\n-------\nfids_mri : list\n    List of estimated fiducials (each point in a dict), in the order\n    LPA, nasion, RPA.\n\nNotes\n-----\nThis takes the ``fsaverage-fiducials.fif`` file included with MNE\u2014which\ncontain the LPA, nasion, and RPA for the ``fsaverage`` subject\u2014and\ntransforms them to the given FreeSurfer subject's MRI space.\nThe MRI of ``fsaverage`` is already in MNI Talairach space, so applying\nthe inverse of the given subject's MNI Talairach affine transformation\n(``$SUBJECTS_DIR/$SUBJECT/mri/transforms/talairach.xfm``) is used\nto estimate the subject's fiducial locations.\n\nFor more details about the coordinate systems and transformations involved,\nsee https://surfer.nmr.mgh.harvard.edu/fswiki/CoordinateSystems and\n:ref:`tut-source-alignment`.", "metadata": {}}
{"_id": "mne_mne__freesurfer.py_estimate_head_mri_t_doc", "text": "Estimate the head->mri transform from fsaverage fiducials.\n\nA subject's fiducials can be estimated given a Freesurfer ``recon-all``\nby transforming ``fsaverage`` fiducials using the inverse Talairach\ntransform, see :func:`mne.coreg.get_mni_fiducials`.\n\nParameters\n----------\n%(subject)s\n%(subjects_dir)s\n%(verbose)s\n\nReturns\n-------\n%(trans_not_none)s", "metadata": {}}
{"_id": "mne_mne__freesurfer.py_read_lta_doc", "text": "Read a Freesurfer linear transform array file.\n\nParameters\n----------\nfname : path-like\n    The transform filename.\n%(verbose)s\n\nReturns\n-------\naffine : ndarray\n    The affine transformation described by the lta file.", "metadata": {}}
{"_id": "mne_mne__freesurfer.py_read_talxfm_doc", "text": "Compute MRI-to-MNI transform from FreeSurfer talairach.xfm file.\n\nParameters\n----------\n%(subject)s\n%(subjects_dir)s\n%(verbose)s\n\nReturns\n-------\nmri_mni_t : instance of Transform\n    The affine transformation from MRI to MNI space for the subject.", "metadata": {}}
{"_id": "mne_mne__freesurfer.py_read_freesurfer_lut_doc", "text": "Read a Freesurfer-formatted LUT.\n\nParameters\n----------\nfname : path-like | None\n    The filename. Can be None to read the standard Freesurfer LUT.\n\nReturns\n-------\natlas_ids : dict\n    Mapping from label names to IDs.\ncolors : dict\n    Mapping from label names to colors.", "metadata": {}}
{"_id": "mne_mne_morph_map.py_read_morph_map_doc", "text": "Read morph map.\n\nMorph maps can be generated with mne_make_morph_maps. If one isn't\navailable, it will be generated automatically and saved to the\n``subjects_dir/morph_maps`` directory.\n\nParameters\n----------\nsubject_from : str\n    Name of the original subject as named in the ``SUBJECTS_DIR``.\nsubject_to : str\n    Name of the subject on which to morph as named in the ``SUBJECTS_DIR``.\nsubjects_dir : path-like\n    Path to ``SUBJECTS_DIR`` is not set in the environment.\nxhemi : bool\n    Morph across hemisphere. Currently only implemented for\n    ``subject_to == subject_from``. See notes of\n    :func:`mne.compute_source_morph`.\n%(verbose)s\n\nReturns\n-------\nleft_map, right_map : ~scipy.sparse.csr_array\n    The morph maps for the 2 hemispheres.", "metadata": {}}
{"_id": "mne_mne_event.py_pick_events_doc", "text": "Select some :term:`events`.\n\nParameters\n----------\n%(events)s\ninclude : int | list | None\n    A event id to include or a list of them.\n    If None all events are included.\nexclude : int | list | None\n    A event id to exclude or a list of them.\n    If None no event is excluded. If include is not None\n    the exclude parameter is ignored.\nstep : bool\n    If True (default is False), events have a step format according\n    to the argument output='step' in the function find_events().\n    In this case, the two last columns are considered in inclusion/\n    exclusion criteria.\n\nReturns\n-------\nevents : array, shape (n_events, 3)\n    The list of events.", "metadata": {}}
{"_id": "mne_mne_event.py_define_target_events_doc", "text": "Define new events by co-occurrence of existing events.\n\nThis function can be used to evaluate events depending on the\ntemporal lag to another event. For example, this can be used to\nanalyze evoked responses which were followed by a button press within\na defined time window.\n\nParameters\n----------\nevents : ndarray\n    Array as returned by mne.find_events.\nreference_id : int\n    The reference event. The event defining the epoch of interest.\ntarget_id : int\n    The target event. The event co-occurring in within a certain time\n    window around the reference event.\nsfreq : float\n    The sampling frequency of the data.\ntmin : float\n    The lower limit in seconds from the target event.\ntmax : float\n    The upper limit border in seconds from the target event.\nnew_id : int\n    New ID for the new event.\nfill_na : int | None\n    Fill event to be inserted if target is not available within the time\n    window specified. If None, the 'null' events will be dropped.\n\nReturns\n-------\nnew_events : ndarray\n    The new defined events.\nlag : ndarray\n    Time lag between reference and target in milliseconds.", "metadata": {}}
{"_id": "mne_mne_event.py_read_events_doc", "text": "Read :term:`events` from fif or text file.\n\nSee :ref:`tut-events-vs-annotations` and :ref:`tut-event-arrays`\nfor more information about events.\n\nParameters\n----------\nfilename : path-like\n    Name of the input file.\n    If the extension is ``.fif``, events are read assuming\n    the file is in FIF format, otherwise (e.g., ``.eve``,\n    ``.lst``, ``.txt``) events are read as coming from text.\n    Note that new format event files do not contain\n    the ``\"time\"`` column (used to be the second column).\ninclude : int | list | None\n    A event id to include or a list of them.\n    If None all events are included.\nexclude : int | list | None\n    A event id to exclude or a list of them.\n    If None no event is excluded. If include is not None\n    the exclude parameter is ignored.\nmask : int | None\n    The value of the digital mask to apply to the stim channel values.\n    If None (default), no masking is performed.\nmask_type : ``'and'`` | ``'not_and'``\n    The type of operation between the mask and the trigger.\n    Choose 'and' (default) for MNE-C masking behavior.\n\n    .. versionadded:: 0.13\nreturn_event_id : bool\n    If True, ``event_id`` will be returned. This is only possible for\n    ``-annot.fif`` files produced with MNE-C ``mne_browse_raw``.\n\n    .. versionadded:: 0.20\n%(verbose)s\n\nReturns\n-------\n%(events)s\nevent_id : dict\n    Dictionary of ``{str: int}`` mappings of event IDs.\n\nSee Also\n--------\nfind_events, write_events\n\nNotes\n-----\nThis function will discard the offset line (i.e., first line with zero\nevent number) if it is present in a text file.\n\nFor more information on ``mask`` and ``mask_type``, see\n:func:`mne.find_events`.", "metadata": {}}
{"_id": "mne_mne_event.py_write_events_doc", "text": "Write :term:`events` to file.\n\nParameters\n----------\nfilename : path-like\n    Name of the output file.\n    If the extension is ``.fif``, events are written in\n    binary FIF format, otherwise (e.g., ``.eve``,\n    ``.lst``, ``.txt``) events are written as plain text.\n    Note that new format event files do not contain\n    the ``\"time\"`` column (used to be the second column).\n%(events)s\n%(overwrite)s\n%(verbose)s\n\nSee Also\n--------\nread_events", "metadata": {}}
{"_id": "mne_mne_event.py_find_stim_steps_doc", "text": "Find all steps in data from a stim channel.\n\nParameters\n----------\nraw : Raw object\n    The raw data.\npad_start : None | int\n    Values to assume outside of the stim channel (e.g., if pad_start=0 and\n    the stim channel starts with value 5, an event of [0, 0, 5] will be\n    inserted at the beginning). With None, no steps will be inserted.\npad_stop : None | int\n    Values to assume outside of the stim channel, see ``pad_start``.\nmerge : int\n    Merge steps occurring in neighboring samples. The integer value\n    indicates over how many samples events should be merged, and the sign\n    indicates in which direction they should be merged (negative means\n    towards the earlier event, positive towards the later event).\nstim_channel : None | str | list of str\n    Name of the stim channel or all the stim channels\n    affected by the trigger. If None, the config variables\n    'MNE_STIM_CHANNEL', 'MNE_STIM_CHANNEL_1', 'MNE_STIM_CHANNEL_2',\n    etc. are read. If these are not found, it will default to\n    'STI101' or 'STI 014', whichever is present.\n\nReturns\n-------\nsteps : array, shape = (n_samples, 3)\n    For each step in the stim channel the values [sample, v_from, v_to].\n    The first column contains the event time in samples (the first sample\n    with the new value). The second column contains the stim channel value\n    before the step, and the third column contains value after the step.\n\nSee Also\n--------\nfind_events : More sophisticated options for finding events in a Raw file.", "metadata": {}}
{"_id": "mne_mne_event.py_find_events_doc", "text": "Find :term:`events` from raw file.\n\nSee :ref:`tut-events-vs-annotations` and :ref:`tut-event-arrays`\nfor more information about events.\n\nParameters\n----------\nraw : Raw object\n    The raw data.\nstim_channel : None | str | list of str\n    Name of the stim channel or all the stim channels\n    affected by triggers. If None, the config variables\n    'MNE_STIM_CHANNEL', 'MNE_STIM_CHANNEL_1', 'MNE_STIM_CHANNEL_2',\n    etc. are read. If these are not found, it will fall back to\n    'STI 014' if present, then fall back to the first channel of type\n    'stim', if present. If multiple channels are provided\n    then the returned events are the union of all the events\n    extracted from individual stim channels.\noutput : 'onset' | 'offset' | 'step'\n    Whether to report when events start, when events end, or both.\nconsecutive : bool | 'increasing'\n    If True, consider instances where the value of the events\n    channel changes without first returning to zero as multiple\n    events. If False, report only instances where the value of the\n    events channel changes from/to zero. If 'increasing', report\n    adjacent events only when the second event code is greater than\n    the first.\nmin_duration : float\n    The minimum duration of a change in the events channel required\n    to consider it as an event (in seconds).\nshortest_event : int\n    Minimum number of samples an event must last (default is 2). If the\n    duration is less than this an exception will be raised.\nmask : int | None\n    The value of the digital mask to apply to the stim channel values.\n    If None (default), no masking is performed.\nuint_cast : bool\n    If True (default False), do a cast to ``uint16`` on the channel\n    data. This can be used to fix a bug with STI101 and STI014 in\n    Neuromag acquisition setups that use channel STI016 (channel 16\n    turns data into e.g. -32768), similar to ``mne_fix_stim14 --32``\n    in MNE-C.\n\n    .. versionadded:: 0.12\nmask_type : 'and' | 'not_and'\n    The type of operation between the mask and the trigger.\n    Choose 'and' (default) for MNE-C masking behavior.\n\n    .. versionadded:: 0.13\ninitial_event : bool\n    If True (default False), an event is created if the stim channel has a\n    value different from 0 as its first sample. This is useful if an event\n    at t=0s is present.\n\n    .. versionadded:: 0.16\n%(verbose)s\n\nReturns\n-------\n%(events)s\n\nSee Also\n--------\nfind_stim_steps : Find all the steps in the stim channel.\nread_events : Read events from disk.\nwrite_events : Write events to disk.\n\nNotes\n-----\n.. warning:: If you are working with downsampled data, events computed\n             before decimation are no longer valid. Please recompute\n             your events after decimation, but note this reduces the\n             precision of event timing.\n\nExamples\n--------\nConsider data with a stim channel that looks like::\n\n    [0, 32, 32, 33, 32, 0]\n\nBy default, find_events returns all samples at which the value of the\nstim channel increases::\n\n    >>> print(find_events(raw)) # doctest: +SKIP\n    [[ 1  0 32]\n     [ 3 32 33]]\n\nIf consecutive is False, find_events only returns the samples at which\nthe stim channel changes from zero to a non-zero value::\n\n    >>> print(find_events(raw, consecutive=False)) # doctest: +SKIP\n    [[ 1  0 32]]\n\nIf consecutive is True, find_events returns samples at which the\nevent changes, regardless of whether it first returns to zero::\n\n    >>> print(find_events(raw, consecutive=True)) # doctest: +SKIP\n    [[ 1  0 32]\n     [ 3 32 33]\n     [ 4 33 32]]\n\nIf output is 'offset', find_events returns the last sample of each event\ninstead of the first one::\n\n    >>> print(find_events(raw, consecutive=True, # doctest: +SKIP\n    ...                   output='offset'))\n    [[ 2 33 32]\n     [ 3 32 33]\n     [ 4  0 32]]\n\nIf output is 'step', find_events returns the samples at which an event\nstarts or ends::\n\n    >>> print(find_events(raw, consecutive=True, # doctest: +SKIP\n    ...                   output='step'))\n    [[ 1  0 32]\n     [ 3 32 33]\n     [ 4 33 32]\n     [ 5 32  0]]\n\nTo ignore spurious events, it is also possible to specify a minimum\nevent duration. Assuming our events channel has a sample rate of\n1000 Hz::\n\n    >>> print(find_events(raw, consecutive=True, # doctest: +SKIP\n    ...                   min_duration=0.002))\n    [[ 1  0 32]]\n\nFor the digital mask, if mask_type is set to 'and' it will take the\nbinary representation of the digital mask, e.g. 5 -> '00000101', and will\nallow the values to pass where mask is one, e.g.::\n\n          7 '0000111' <- trigger value\n         37 '0100101' <- mask\n     ----------------\n          5 '0000101'\n\nFor the digital mask, if mask_type is set to 'not_and' it will take the\nbinary representation of the digital mask, e.g. 5 -> '00000101', and will\nblock the values where mask is one, e.g.::\n\n          7 '0000111' <- trigger value\n         37 '0100101' <- mask\n     ----------------\n          2 '0000010'", "metadata": {}}
{"_id": "mne_mne_event.py_merge_events_doc", "text": "Merge a set of :term:`events`.\n\nParameters\n----------\nevents : array, shape (n_events_in, 3)\n    Events.\nids : array of int\n    The ids of events to merge.\nnew_id : int\n    The new id.\nreplace_events : bool\n    If True (default), old event ids are replaced. Otherwise,\n    new events will be added to the old event list.\n\nReturns\n-------\nnew_events : array, shape (n_events_out, 3)\n    The new events.\n\nNotes\n-----\nRather than merging events you can use hierarchical event_id\nin Epochs. For example, here::\n\n    >>> event_id = {'auditory/left': 1, 'auditory/right': 2}\n\nAnd the condition 'auditory' would correspond to either 1 or 2.\n\nExamples\n--------\nHere is quick example of the behavior::\n\n    >>> events = [[134, 0, 1], [341, 0, 2], [502, 0, 3]]\n    >>> merge_events(events, [1, 2], 12, replace_events=True)\n    array([[134,   0,  12],\n           [341,   0,  12],\n           [502,   0,   3]])\n    >>> merge_events(events, [1, 2], 12, replace_events=False)\n    array([[134,   0,   1],\n           [134,   0,  12],\n           [341,   0,   2],\n           [341,   0,  12],\n           [502,   0,   3]])", "metadata": {}}
{"_id": "mne_mne_event.py_shift_time_events_doc", "text": "Shift a set of :term:`events`.\n\nParameters\n----------\n%(events)s\nids : ndarray of int | None\n    The ids of events to shift.\ntshift : float\n    Time-shift event. Use positive value tshift for forward shifting\n    the event and negative value for backward shift.\nsfreq : float\n    The sampling frequency of the data.\n\nReturns\n-------\nnew_events : array of int, shape (n_new_events, 3)\n    The new events.", "metadata": {}}
{"_id": "mne_mne_event.py_make_fixed_length_events_doc", "text": "Make a set of :term:`events` separated by a fixed duration.\n\nParameters\n----------\nraw : instance of Raw\n    A raw object to use the data from.\nid : int\n    The id to use (default 1).\nstart : float\n    Time of first event (in seconds).\nstop : float | None\n    Maximum time of last event (in seconds). If None, events extend to the\n    end of the recording.\nduration : float\n    The duration to separate events by (in seconds).\nfirst_samp : bool\n    If True (default), times will have :term:`first_samp` added to them, as\n    in :func:`mne.find_events`. This behavior is not desirable if the\n    returned events will be combined with event times that already\n    have :term:`first_samp` added to them, e.g. event times that come\n    from :func:`mne.find_events`.\noverlap : float\n    The overlap between events (in seconds).\n    Must be ``0 <= overlap < duration``.\n\n    .. versionadded:: 0.18\n\nReturns\n-------\n%(events)s", "metadata": {}}
{"_id": "mne_mne_event.py_concatenate_events_doc", "text": "Concatenate event lists to be compatible with concatenate_raws.\n\nThis is useful, for example, if you processed and/or changed\nevents in raw files separately before combining them using\n:func:`mne.concatenate_raws`.\n\nParameters\n----------\nevents : list of array\n    List of :term:`events` arrays, typically each extracted from a\n    corresponding raw file that is being concatenated.\nfirst_samps : list or array of int\n    First sample numbers of the raw files concatenated.\nlast_samps : list or array of int\n    Last sample numbers of the raw files concatenated.\n\nReturns\n-------\nevents : array\n    The concatenated events.\n\nSee Also\n--------\nmne.concatenate_raws", "metadata": {}}
{"_id": "mne_mne_event.py_match_event_names_doc", "text": "Search a collection of event names for matching (sub-)groups of events.\n\nThis function is particularly helpful when using grouped event names\n(i.e., event names containing forward slashes ``/``). Please see the\nExamples section below for a working example.\n\nParameters\n----------\nevent_names : array-like of str | dict\n    Either a collection of event names, or the ``event_id`` dictionary\n    mapping event names to event codes.\nkeys : array-like of str | str\n    One or multiple event names or groups to search for in ``event_names``.\non_missing : 'raise' | 'warn' | 'ignore'\n    How to handle situations when none of the ``keys`` can be found in\n    ``event_names``. If ``'warn'`` or ``'ignore'``, an empty list will be\n    returned.\n\nReturns\n-------\nmatches : list of str\n    All event names that match any of the ``keys`` provided.\n\nNotes\n-----\n.. versionadded:: 1.0\n\nExamples\n--------\nAssuming the following grouped event names in the data, you could easily\nquery for all ``auditory`` and ``left`` event names::\n\n    >>> event_names = [\n    ...     'auditory/left',\n    ...     'auditory/right',\n    ...     'visual/left',\n    ...     'visual/right'\n    ... ]\n    >>> match_event_names(\n    ...     event_names=event_names,\n    ...     keys=['auditory', 'left']\n    ... )\n    ['auditory/left', 'auditory/right', 'visual/left']", "metadata": {}}
{"_id": "mne_mne_event.py_count_events_doc", "text": "Count events.\n\nParameters\n----------\nevents : ndarray, shape (N, 3)\n    The events array (consisting of N events).\nids : array-like of int | None\n    If ``None``, count all event types present in the input. If array-like\n    of int, count only those event types given by ``ids``.\n\nReturns\n-------\ncounts : dict\n    A dictionary containing the event types as keys with their counts as\n    values.\n\nExamples\n--------\n    >>> events = np.array([[0, 0, 1], [0, 0, 1], [0, 0, 5]])\n    >>> count_events(events)\n    {1: 2, 5: 1}\n    >>> count_events(events, ids=[1, 5])\n    {1: 2, 5: 1}\n    >>> count_events(events, ids=[1, 11])\n    {1: 2, 11: 0}", "metadata": {}}
{"_id": "mne_mne_event.py_categories_doc", "text": "Return list of averaging categories ordered by DACQ index.\n\nOnly returns categories marked active in DACQ.", "metadata": {}}
{"_id": "mne_mne_event.py_events_doc", "text": "Return events ordered by DACQ index.\n\nOnly returns events that are in use (referred to by a category).", "metadata": {}}
{"_id": "mne_mne_event.py_get_condition_doc", "text": "Get averaging parameters for a condition (averaging category).\n\nOutput is designed to be used with the Epochs class to extract the\ncorresponding epochs.\n\nParameters\n----------\nraw : Raw object\n    An instance of Raw.\ncondition : None | str | dict | list of dict\n    Condition or a list of conditions. Conditions can be strings\n    (DACQ comment field, e.g. 'Auditory left') or category dicts\n    (e.g. acqp['Auditory left'], where acqp is an instance of\n    AcqParserFIF). If None, get all conditions marked active in\n    DACQ.\nstim_channel : None | str | list of str\n    Name of the stim channel or all the stim channels\n    affected by the trigger. If None, the config variables\n    'MNE_STIM_CHANNEL', 'MNE_STIM_CHANNEL_1', 'MNE_STIM_CHANNEL_2',\n    etc. are read. If these are not found, it will fall back to\n    'STI101' or 'STI 014' if present, then fall back to the first\n    channel of type 'stim', if present.\nmask : int | None\n    The value of the digital mask to apply to the stim channel values.\n    If None (default), no masking is performed.\nuint_cast : bool\n    If True (default False), do a cast to ``uint16`` on the channel\n    data. This can be used to fix a bug with STI101 and STI014 in\n    Neuromag acquisition setups that use channel STI016 (channel 16\n    turns data into e.g. -32768), similar to ``mne_fix_stim14 --32``\n    in MNE-C.\nmask_type : 'and' | 'not_and'\n    The type of operation between the mask and the trigger.\n    Choose 'and' for MNE-C masking behavior.\ndelayed_lookup : bool\n    If True, use the 'delayed lookup' procedure implemented in Elekta\n    software. When a trigger transition occurs, the lookup of\n    the new trigger value will not happen immediately at the following\n    sample, but with a 1-sample delay. This allows a slight\n    asynchrony between trigger onsets, when they are intended to be\n    synchronous. If you have accurate hardware and want to detect\n    transitions with a resolution of one sample, use\n    delayed_lookup=False.\n\nReturns\n-------\nconds_data : dict or list of dict\n    Each dict has the following keys:\n\n    events : array, shape (n_epochs_out, 3)\n        List of zero time points (t0) for the epochs matching the\n        condition. Use as the ``events`` parameter to Epochs. Note\n        that these are not (necessarily) actual events.\n    event_id : dict\n        Name of condition and index compatible with ``events``.\n        Should be passed as the ``event_id`` parameter to Epochs.\n    tmin : float\n        Epoch starting time relative to t0. Use as the ``tmin``\n        parameter to Epochs.\n    tmax : float\n        Epoch ending time relative to t0. Use as the ``tmax``\n        parameter to Epochs.", "metadata": {}}
{"_id": "mne_mne_morph.py_compute_source_morph_doc", "text": "Create a SourceMorph from one subject to another.\n\nMethod is based on spherical morphing by FreeSurfer for surface\ncortical estimates :footcite:`GreveEtAl2013` and\nSymmetric Diffeomorphic Registration for volumic data\n:footcite:`AvantsEtAl2008`.\n\nParameters\n----------\nsrc : instance of SourceSpaces | instance of SourceEstimate\n    The SourceSpaces of subject_from (can be a\n    SourceEstimate if only using a surface source space).\nsubject_from : str | None\n    Name of the original subject as named in the SUBJECTS_DIR.\n    If None (default), then ``src[0]['subject_his_id]'`` will be used.\nsubject_to : str | None\n    Name of the subject to which to morph as named in the SUBJECTS_DIR.\n    Default is ``'fsaverage'``. If None, ``src_to[0]['subject_his_id']``\n    will be used.\n\n    .. versionchanged:: 0.20\n       Support for subject_to=None.\n%(subjects_dir)s\nzooms : float | tuple | str | None\n    The voxel size of volume for each spatial dimension in mm.\n    If spacing is None, MRIs won't be resliced, and both volumes\n    must have the same number of spatial dimensions.\n    Can also be ``'auto'`` to use ``5.`` if ``src_to is None`` and\n    the zooms from ``src_to`` otherwise.\n\n    .. versionchanged:: 0.20\n       Support for 'auto' mode.\nniter_affine : tuple of int\n    Number of levels (``len(niter_affine)``) and number of\n    iterations per level - for each successive stage of iterative\n    refinement - to perform the affine transform.\n    Default is niter_affine=(100, 100, 10).\nniter_sdr : tuple of int\n    Number of levels (``len(niter_sdr)``) and number of\n    iterations per level - for each successive stage of iterative\n    refinement - to perform the Symmetric Diffeomorphic Registration (sdr)\n    transform. Default is niter_sdr=(5, 5, 3).\nspacing : int | list | None\n    The resolution of the icosahedral mesh (typically 5).\n    If None, all vertices will be used (potentially filling the\n    surface). If a list, then values will be morphed to the set of\n    vertices specified in in ``spacing[0]`` and ``spacing[1]``.\n    This will be ignored if ``src_to`` is supplied.\n\n    .. versionchanged:: 0.21\n       src_to, if provided, takes precedence.\nsmooth : int | str | None\n    Number of iterations for the smoothing of the surface data.\n    If None, smooth is automatically defined to fill the surface\n    with non-zero values. Can also be ``'nearest'`` to use the nearest\n    vertices on the surface.\n\n    .. versionchanged:: 0.20\n       Added support for 'nearest'.\nwarn : bool\n    If True, warn if not all vertices were used. The default is warn=True.\nxhemi : bool\n    Morph across hemisphere. Currently only implemented for\n    ``subject_to == subject_from``. See notes below.\n    The default is xhemi=False.\nsparse : bool\n    Morph as a sparse source estimate. Works only with (Vector)\n    SourceEstimate. If True the only parameters used are subject_to and\n    subject_from, and spacing has to be None. Default is sparse=False.\nsrc_to : instance of SourceSpaces | None\n    The destination source space.\n\n    - For surface-based morphing, this is the preferred over ``spacing``\n      for providing the vertices.\n    - For volumetric morphing, this should be passed so that 1) the\n      resultingmorph volume is properly constrained to the brain volume,\n      and 2) STCs from multiple subjects morphed to the same destination\n      subject/source space have the vertices.\n    - For mixed (surface + volume) morphing, this is required.\n\n    .. versionadded:: 0.20\nprecompute : bool\n    If True (default False), compute the sparse matrix representation of\n    the volumetric morph (if present). This takes a long time to\n    compute, but can make morphs faster when thousands of points are used.\n    See :meth:`mne.SourceMorph.compute_vol_morph_mat` (which can be called\n    later if desired) for more information.\n\n    .. versionadded:: 0.22\n%(verbose)s\n\nReturns\n-------\nmorph : instance of SourceMorph\n    The :class:`mne.SourceMorph` object.\n\nNotes\n-----\nThis function can be used to morph surface data between hemispheres by\nsetting ``xhemi=True``. The full cross-hemisphere morph matrix maps left\nto right and right to left. A matrix for cross-mapping only one hemisphere\ncan be constructed by specifying the appropriate vertices, for example, to\nmap the right hemisphere to the left::\n\n    vertices_from=[[], vert_rh], vertices_to=[vert_lh, []]\n\nCross-hemisphere mapping requires appropriate ``sphere.left_right``\nmorph-maps in the subject's directory. These morph maps are included\nwith the ``fsaverage_sym`` FreeSurfer subject, and can be created for other\nsubjects with the ``mris_left_right_register`` FreeSurfer command. The\n``fsaverage_sym`` subject is included with FreeSurfer > 5.1 and can be\nobtained as described `here\n<https://surfer.nmr.mgh.harvard.edu/fswiki/Xhemi>`_. For statistical\ncomparisons between hemispheres, use of the symmetric ``fsaverage_sym``\nmodel is recommended to minimize bias :footcite:`GreveEtAl2013`.\n\n.. versionadded:: 0.17.0\n\n.. versionadded:: 0.21.0\n   Support for morphing mixed source estimates.\n\nReferences\n----------\n.. footbibliography::", "metadata": {}}
{"_id": "mne_mne_morph.py_read_source_morph_doc", "text": "Load the morph for source estimates from a file.\n\nParameters\n----------\nfname : path-like\n    Path to the file containing the morph source estimates.\n\nReturns\n-------\nsource_morph : instance of SourceMorph\n    The loaded morph.", "metadata": {}}
{"_id": "mne_mne_morph.py_grade_to_vertices_doc", "text": "Convert a grade to source space vertices for a given subject.\n\nParameters\n----------\nsubject : str\n    Name of the subject.\ngrade : int | list\n    Resolution of the icosahedral mesh (typically 5). If None, all\n    vertices will be used (potentially filling the surface). If a list,\n    then values will be morphed to the set of vertices specified in\n    in grade[0] and grade[1]. Note that specifying the vertices (e.g.,\n    grade=[np.arange(10242), np.arange(10242)] for fsaverage on a\n    standard grade 5 source space) can be substantially faster than\n    computing vertex locations. Note that if subject='fsaverage'\n    and 'grade=5', this set of vertices will automatically be used\n    (instead of computed) for speed, since this is a common morph.\n%(subjects_dir)s\n%(n_jobs)s\n%(verbose)s\n\nReturns\n-------\nvertices : list of array of int\n    Vertex numbers for LH and RH.", "metadata": {}}
{"_id": "mne_mne_morph.py_apply_doc", "text": "Morph source space data.\n\nParameters\n----------\nstc_from : VolSourceEstimate | VolVectorSourceEstimate | SourceEstimate | VectorSourceEstimate\n    The source estimate to morph.\noutput : str\n    Can be ``'stc'`` (default) or possibly ``'nifti1'``, or\n    ``'nifti2'`` when working with a volume source space defined on a\n    regular grid.\nmri_resolution : bool | tuple | int | float\n    If True the image is saved in MRI resolution. Default False.\n\n    .. warning: If you have many time points the file produced can be\n                huge. The default is ``mri_resolution=False``.\nmri_space : bool | None\n    Whether the image to world registration should be in mri space. The\n    default (None) is mri_space=mri_resolution.\n%(verbose)s\n\nReturns\n-------\nstc_to : VolSourceEstimate | SourceEstimate | VectorSourceEstimate | Nifti1Image | Nifti2Image\n    The morphed source estimates.", "metadata": {}}
{"_id": "mne_mne_morph.py_compute_vol_morph_mat_doc", "text": "Compute the sparse matrix representation of the volumetric morph.\n\nParameters\n----------\n%(verbose)s\n\nReturns\n-------\nmorph : instance of SourceMorph\n    The instance (modified in-place).\n\nNotes\n-----\nFor a volumetric morph, this will compute the morph for an identity\nsource volume, i.e., with one source vertex active at a time, and store\nthe result as a :class:`sparse <scipy.sparse.csr_array>`\nmorphing matrix. This takes a long time (minutes) to compute initially,\nbut drastically speeds up :meth:`apply` for STCs, so it can be\nbeneficial when many time points or many morphs (i.e., greater than\nthe number of volumetric ``src_from`` vertices) will be performed.\n\nWhen calling :meth:`save`, this sparse morphing matrix is saved with\nthe instance, so this only needs to be called once. This function does\nnothing if the morph matrix has already been computed, or if there is\nno volume morphing necessary.\n\n.. versionadded:: 0.22", "metadata": {}}
{"_id": "mne_mne_morph.py_save_doc", "text": "Save the morph for source estimates to a file.\n\nParameters\n----------\nfname : path-like\n    The path to the file. ``'-morph.h5'`` will be added if fname does\n    not end with ``'.h5'``.\n%(overwrite)s\n%(verbose)s", "metadata": {}}
{"_id": "mne_mne_chpi.py_read_head_pos_doc", "text": "Read MaxFilter-formatted head position parameters.\n\nParameters\n----------\nfname : path-like\n    The filename to read. This can be produced by e.g.,\n    ``maxfilter -headpos <name>.pos``.\n\nReturns\n-------\npos : array, shape (N, 10)\n    The position and quaternion parameters from cHPI fitting.\n\nSee Also\n--------\nwrite_head_pos\nhead_pos_to_trans_rot_t\n\nNotes\n-----\n.. versionadded:: 0.12", "metadata": {}}
{"_id": "mne_mne_chpi.py_write_head_pos_doc", "text": "Write MaxFilter-formatted head position parameters.\n\nParameters\n----------\nfname : path-like\n    The filename to write.\npos : array, shape (N, 10)\n    The position and quaternion parameters from cHPI fitting.\n\nSee Also\n--------\nread_head_pos\nhead_pos_to_trans_rot_t\n\nNotes\n-----\n.. versionadded:: 0.12", "metadata": {}}
{"_id": "mne_mne_chpi.py_head_pos_to_trans_rot_t_doc", "text": "Convert Maxfilter-formatted head position quaternions.\n\nParameters\n----------\nquats : ndarray, shape (N, 10)\n    MaxFilter-formatted position and quaternion parameters.\n\nReturns\n-------\ntranslation : ndarray, shape (N, 3)\n    Translations at each time point.\nrotation : ndarray, shape (N, 3, 3)\n    Rotations at each time point.\nt : ndarray, shape (N,)\n    The time points.\n\nSee Also\n--------\nread_head_pos\nwrite_head_pos", "metadata": {}}
{"_id": "mne_mne_chpi.py_extract_chpi_locs_ctf_doc", "text": "Extract cHPI locations from CTF data.\n\nParameters\n----------\nraw : instance of Raw\n    Raw data with CTF cHPI information.\n%(verbose)s\n\nReturns\n-------\n%(chpi_locs)s\n\nNotes\n-----\nCTF continuous head monitoring stores the x,y,z location (m) of each chpi\ncoil as separate channels in the dataset:\n\n- ``HLC001[123]\\\\*`` - nasion\n- ``HLC002[123]\\\\*`` - lpa\n- ``HLC003[123]\\\\*`` - rpa\n\nThis extracts these positions for use with\n:func:`~mne.chpi.compute_head_pos`.\n\n.. versionadded:: 0.20", "metadata": {}}
{"_id": "mne_mne_chpi.py_extract_chpi_locs_kit_doc", "text": "Extract cHPI locations from KIT data.\n\nParameters\n----------\nraw : instance of RawKIT\n    Raw data with KIT cHPI information.\nstim_channel : str\n    The stimulus channel that encodes HPI measurement intervals.\n%(verbose)s\n\nReturns\n-------\n%(chpi_locs)s\n\nNotes\n-----\n.. versionadded:: 0.23", "metadata": {}}
{"_id": "mne_mne_chpi.py_get_chpi_info_doc", "text": "Retrieve cHPI information from the data.\n\nParameters\n----------\n%(info_not_none)s\n%(on_missing_chpi)s\n%(verbose)s\n\nReturns\n-------\nhpi_freqs : array, shape (n_coils,)\n    The frequency used for each individual cHPI coil.\nhpi_pick : int | None\n    The index of the ``STIM`` channel containing information about when\n    which cHPI coils were switched on.\nhpi_on : array, shape (n_coils,)\n    The values coding for the \"on\" state of each individual cHPI coil.\n\nNotes\n-----\n.. versionadded:: 0.24", "metadata": {}}
{"_id": "mne_mne_chpi.py_compute_head_pos_doc", "text": "Compute time-varying head positions.\n\nParameters\n----------\n%(info_not_none)s\n%(chpi_locs)s\n    Typically obtained by :func:`~mne.chpi.compute_chpi_locs` or\n    :func:`~mne.chpi.extract_chpi_locs_ctf`.\ndist_limit : float\n    Minimum distance (m) to accept for coil position fitting.\ngof_limit : float\n    Minimum goodness of fit to accept for each coil.\n%(adjust_dig_chpi)s\n%(verbose)s\n\nReturns\n-------\nquats : ndarray, shape (n_pos, 10)\n    The ``[t, q1, q2, q3, x, y, z, gof, err, v]`` for each fit.\n\nSee Also\n--------\ncompute_chpi_locs\nextract_chpi_locs_ctf\nread_head_pos\nwrite_head_pos\n\nNotes\n-----\n.. versionadded:: 0.20", "metadata": {}}
{"_id": "mne_mne_chpi.py_compute_chpi_snr_doc", "text": "Compute time-varying estimates of cHPI SNR.\n\nParameters\n----------\nraw : instance of Raw\n    Raw data with cHPI information.\nt_step_min : float\n    Minimum time step to use.\n%(t_window_chpi_t)s\n%(ext_order_chpi)s\n%(tmin_raw)s\n%(tmax_raw)s\n%(verbose)s\n\nReturns\n-------\nchpi_snrs : dict\n    The time-varying cHPI SNR estimates, with entries \"times\", \"freqs\",\n    \"snr_mag\", \"power_mag\", and \"resid_mag\" (and/or \"snr_grad\",\n    \"power_grad\", and \"resid_grad\", depending on which channel types are\n    present in ``raw``).\n\nSee Also\n--------\nmne.chpi.compute_chpi_locs, mne.chpi.compute_chpi_amplitudes\n\nNotes\n-----\n.. versionadded:: 0.24", "metadata": {}}
{"_id": "mne_mne_chpi.py_compute_chpi_amplitudes_doc", "text": "Compute time-varying cHPI amplitudes.\n\nParameters\n----------\nraw : instance of Raw\n    Raw data with cHPI information.\nt_step_min : float\n    Minimum time step to use.\n%(t_window_chpi_t)s\n%(ext_order_chpi)s\n%(tmin_raw)s\n%(tmax_raw)s\n%(verbose)s\n\nReturns\n-------\n%(chpi_amplitudes)s\n\nSee Also\n--------\nmne.chpi.compute_chpi_locs, mne.chpi.compute_chpi_snr\n\nNotes\n-----\nThis function will:\n\n1. Get HPI frequencies,  HPI status channel, HPI status bits,\n   and digitization order using ``_setup_hpi_amplitude_fitting``.\n2. Window data using ``t_window`` (half before and half after ``t``) and\n   ``t_step_min``.\n3. Use a linear model (DC + linear slope + sin + cos terms) to fit\n   sinusoidal amplitudes to MEG channels.\n   It uses SVD to determine the phase/amplitude of the sinusoids.\n\nIn \"auto\" mode, ``t_window`` will be set to the longer of:\n\n1. Five cycles of the lowest HPI or line frequency.\n      Ensures that the frequency estimate is stable.\n2. The reciprocal of the smallest difference between HPI and line freqs.\n      Ensures that neighboring frequencies can be disambiguated.\n\nThe output is meant to be used with :func:`~mne.chpi.compute_chpi_locs`.\n\n.. versionadded:: 0.20", "metadata": {}}
{"_id": "mne_mne_chpi.py_compute_chpi_locs_doc", "text": "Compute locations of each cHPI coils over time.\n\nParameters\n----------\n%(info_not_none)s\n%(chpi_amplitudes)s\n    Typically obtained by :func:`mne.chpi.compute_chpi_amplitudes`.\nt_step_max : float\n    Maximum time step to use.\ntoo_close : str\n    How to handle HPI positions too close to the sensors,\n    can be ``'raise'`` (default), ``'warning'``, or ``'info'``.\n%(adjust_dig_chpi)s\n%(verbose)s\n\nReturns\n-------\n%(chpi_locs)s\n\nSee Also\n--------\ncompute_chpi_amplitudes\ncompute_head_pos\nread_head_pos\nwrite_head_pos\nextract_chpi_locs_ctf\n\nNotes\n-----\nThis function is designed to take the output of\n:func:`mne.chpi.compute_chpi_amplitudes` and:\n\n1. Get HPI coil locations (as digitized in ``info['dig']``) in head coords.\n2. If the amplitudes are 98%% correlated with last position\n   (and \u0394t < t_step_max), skip fitting.\n3. Fit magnetic dipoles using the amplitudes for each coil frequency.\n\nThe number of fitted points ``n_pos`` will depend on the velocity of head\nmovements as well as ``t_step_max`` (and ``t_step_min`` from\n:func:`mne.chpi.compute_chpi_amplitudes`).\n\n.. versionadded:: 0.20", "metadata": {}}
{"_id": "mne_mne_chpi.py_filter_chpi_doc", "text": "Remove cHPI and line noise from data.\n\n.. note:: This function will only work properly if cHPI was on\n          during the recording.\n\nParameters\n----------\nraw : instance of Raw\n    Raw data with cHPI information. Must be preloaded. Operates in-place.\ninclude_line : bool\n    If True, also filter line noise.\nt_step : float\n    Time step to use for estimation, default is 0.01 (10 ms).\n%(t_window_chpi_t)s\n%(ext_order_chpi)s\nallow_line_only : bool\n    If True, allow filtering line noise only. The default is False,\n    which only allows the function to run when cHPI information is present.\n\n    .. versionadded:: 0.20\n%(verbose)s\n\nReturns\n-------\nraw : instance of Raw\n    The raw data.\n\nNotes\n-----\ncHPI signals are in general not stationary, because head movements act\nlike amplitude modulators on cHPI signals. Thus it is recommended to\nuse this procedure, which uses an iterative fitting method, to\nremove cHPI signals, as opposed to notch filtering.\n\n.. versionadded:: 0.12", "metadata": {}}
{"_id": "mne_mne_chpi.py_get_active_chpi_doc", "text": "Determine how many HPI coils were active for a time point.\n\nParameters\n----------\nraw : instance of Raw\n    Raw data with cHPI information.\n%(on_missing_chpi)s\n%(verbose)s\n\nReturns\n-------\nn_active : array, shape (n_times)\n    The number of active cHPIs for every timepoint in raw.\n\nNotes\n-----\n.. versionadded:: 1.2", "metadata": {}}
{"_id": "mne_mne_source_estimate.py_read_source_estimate_doc", "text": "Read a source estimate object.\n\nParameters\n----------\nfname : path-like\n    Path to (a) source-estimate file(s).\nsubject : str | None\n    Name of the subject the source estimate(s) is (are) from.\n    It is good practice to set this attribute to avoid combining\n    incompatible labels and SourceEstimates (e.g., ones from other\n    subjects). Note that due to file specification limitations, the\n    subject name isn't saved to or loaded from files written to disk.\n\nReturns\n-------\nstc : SourceEstimate | VectorSourceEstimate | VolSourceEstimate | MixedSourceEstimate\n    The source estimate object loaded from file.\n\nNotes\n-----\n - for volume source estimates, ``fname`` should provide the path to a\n   single file named ``'*-vl.stc``` or ``'*-vol.stc'``\n - for surface source estimates, ``fname`` should either provide the\n   path to the file corresponding to a single hemisphere (``'*-lh.stc'``,\n   ``'*-rh.stc'``) or only specify the asterisk part in these patterns. In\n   any case, the function expects files for both hemisphere with names\n   following this pattern.\n - for vector surface source estimates, only HDF5 files are supported.\n - for mixed source estimates, only HDF5 files are supported.\n - for single time point ``.w`` files, ``fname`` should follow the same\n   pattern as for surface estimates, except that files are named\n   ``'*-lh.w'`` and ``'*-rh.w'``.", "metadata": {}}
{"_id": "mne_mne_source_estimate.py_spatio_temporal_src_adjacency_doc", "text": "Compute adjacency for a source space activation over time.\n\nParameters\n----------\nsrc : instance of SourceSpaces\n    The source space. It can be a surface source space or a\n    volume source space.\nn_times : int\n    Number of time instants.\ndist : float, or None\n    Maximal geodesic distance (in m) between vertices in the\n    source space to consider neighbors. If None, immediate neighbors\n    are extracted from an ico surface.\n%(verbose)s\n\nReturns\n-------\nadjacency : ~scipy.sparse.coo_array\n    The adjacency matrix describing the spatio-temporal\n    graph structure. If N is the number of vertices in the\n    source space, the N first nodes in the graph are the\n    vertices are time 1, the nodes from 2 to 2N are the vertices\n    during time 2, etc.", "metadata": {}}
{"_id": "mne_mne_source_estimate.py_grade_to_tris_doc", "text": "Get tris defined for a certain grade.\n\nParameters\n----------\ngrade : int\n    Grade of an icosahedral mesh.\n%(verbose)s\n\nReturns\n-------\ntris : list\n    2-element list containing Nx3 arrays of tris, suitable for use in\n    spatio_temporal_tris_adjacency.", "metadata": {}}
{"_id": "mne_mne_source_estimate.py_spatio_temporal_tris_adjacency_doc", "text": "Compute adjacency from triangles and time instants.\n\nParameters\n----------\ntris : array\n    N x 3 array defining triangles.\nn_times : int\n    Number of time points.\nremap_vertices : bool\n    Reassign vertex indices based on unique values. Useful\n    to process a subset of triangles. Defaults to False.\n%(verbose)s\n\nReturns\n-------\nadjacency : ~scipy.sparse.coo_array\n    The adjacency matrix describing the spatio-temporal\n    graph structure. If N is the number of vertices in the\n    source space, the N first nodes in the graph are the\n    vertices are time 1, the nodes from 2 to 2N are the vertices\n    during time 2, etc.", "metadata": {}}
{"_id": "mne_mne_source_estimate.py_spatio_temporal_dist_adjacency_doc", "text": "Compute adjacency from distances in a source space and time instants.\n\nParameters\n----------\nsrc : instance of SourceSpaces\n    The source space must have distances between vertices computed, such\n    that src['dist'] exists and is useful. This can be obtained\n    with a call to :func:`mne.setup_source_space` with the\n    ``add_dist=True`` option.\nn_times : int\n    Number of time points.\ndist : float\n    Maximal geodesic distance (in m) between vertices in the\n    source space to consider neighbors.\n%(verbose)s\n\nReturns\n-------\nadjacency : ~scipy.sparse.coo_array\n    The adjacency matrix describing the spatio-temporal\n    graph structure. If N is the number of vertices in the\n    source space, the N first nodes in the graph are the\n    vertices are time 1, the nodes from 2 to 2N are the vertices\n    during time 2, etc.", "metadata": {}}
{"_id": "mne_mne_source_estimate.py_spatial_src_adjacency_doc", "text": "Compute adjacency for a source space activation.\n\nParameters\n----------\nsrc : instance of SourceSpaces\n    The source space. It can be a surface source space or a\n    volume source space.\ndist : float, or None\n    Maximal geodesic distance (in m) between vertices in the\n    source space to consider neighbors. If None, immediate neighbors\n    are extracted from an ico surface.\n%(verbose)s\n\nReturns\n-------\nadjacency : ~scipy.sparse.coo_array\n    The adjacency matrix describing the spatial graph structure.", "metadata": {}}
{"_id": "mne_mne_source_estimate.py_spatial_tris_adjacency_doc", "text": "Compute adjacency from triangles.\n\nParameters\n----------\ntris : array\n    N x 3 array defining triangles.\nremap_vertices : bool\n    Reassign vertex indices based on unique values. Useful\n    to process a subset of triangles. Defaults to False.\n%(verbose)s\n\nReturns\n-------\nadjacency : ~scipy.sparse.coo_array\n    The adjacency matrix describing the spatial graph structure.", "metadata": {}}
{"_id": "mne_mne_source_estimate.py_spatial_dist_adjacency_doc", "text": "Compute adjacency from distances in a source space.\n\nParameters\n----------\nsrc : instance of SourceSpaces\n    The source space must have distances between vertices computed, such\n    that src['dist'] exists and is useful. This can be obtained\n    with a call to :func:`mne.setup_source_space` with the\n    ``add_dist=True`` option.\ndist : float\n    Maximal geodesic distance (in m) between vertices in the\n    source space to consider neighbors.\n%(verbose)s\n\nReturns\n-------\nadjacency : ~scipy.sparse.coo_array\n    The adjacency matrix describing the spatial graph structure.", "metadata": {}}
{"_id": "mne_mne_source_estimate.py_spatial_inter_hemi_adjacency_doc", "text": "Get vertices on each hemisphere that are close to the other hemisphere.\n\nParameters\n----------\nsrc : instance of SourceSpaces\n    The source space. Must be surface type.\ndist : float\n    Maximal Euclidean distance (in m) between vertices in one hemisphere\n    compared to the other to consider neighbors.\n%(verbose)s\n\nReturns\n-------\nadjacency : ~scipy.sparse.coo_array\n    The adjacency matrix describing the spatial graph structure.\n    Typically this should be combined (addititively) with another\n    existing intra-hemispheric adjacency matrix, e.g. computed\n    using geodesic distances.", "metadata": {}}
{"_id": "mne_mne_source_estimate.py_extract_label_time_course_doc", "text": "Extract label time course for lists of labels and source estimates.\n\nThis function will extract one time course for each label and source\nestimate. The way the time courses are extracted depends on the mode\nparameter (see Notes).\n\nParameters\n----------\nstcs : SourceEstimate | list (or generator) of SourceEstimate\n    The source estimates from which to extract the time course.\n%(labels_eltc)s\n%(src_eltc)s\n%(mode_eltc)s\n%(allow_empty_eltc)s\nreturn_generator : bool\n    If True, a generator instead of a list is returned.\n%(mri_resolution_eltc)s\n%(verbose)s\n\nReturns\n-------\n%(label_tc_el_returns)s\n\nNotes\n-----\n%(eltc_mode_notes)s\n\nIf encountering a ``ValueError`` due to mismatch between number of\nsource points in the subject source space and computed ``stc`` object set\n``src`` argument to ``fwd['src']`` or ``inv['src']`` to ensure the source\nspace is the one actually used by the inverse to compute the source\ntime courses.", "metadata": {}}
{"_id": "mne_mne_source_estimate.py_stc_near_sensors_doc", "text": "Create a STC from ECoG, sEEG and DBS sensor data.\n\nParameters\n----------\nevoked : instance of Evoked\n    The evoked data. Must contain ECoG, sEEG or DBS channels.\n%(trans)s\n\n    .. versionchanged:: 0.19\n        Support for 'fsaverage' argument.\nsubject : str\n    The subject name.\ndistance : float\n    Distance (m) defining the activation \"ball\" of the sensor.\nmode : str\n    Can be ``\"sum\"`` to do a linear sum of weights, ``\"weighted\"`` to make\n    this a weighted sum, ``\"nearest\"`` to use only the weight of the\n    nearest sensor, or ``\"single\"`` to do a distance-weight of the nearest\n    sensor. Default is ``\"sum\"``. See Notes.\n\n    .. versionchanged:: 0.24\n       Added \"weighted\" option.\nproject : bool\n    If True, project the sensors to the nearest ``'pial`` surface\n    vertex before computing distances. Only used when doing a\n    surface projection.\n%(subjects_dir)s\nsrc : instance of SourceSpaces\n    The source space.\n\n    .. warning:: If a surface source space is used, make sure that\n                 ``surface='pial'`` was used during construction,\n                 or that you set ``surface='pial'`` here.\n%(picks_base)s good sEEG, ECoG, and DBS channels.\n\n    .. versionadded:: 0.24\nsurface : str | None\n    The surface to use. If ``src=None``, defaults to the pial surface.\n    Otherwise, the source space surface will be used.\n\n    .. versionadded:: 0.24.1\n%(verbose)s\n\nReturns\n-------\nstc : instance of SourceEstimate\n    The surface source estimate. If src is None, a surface source\n    estimate will be produced, and the number of vertices will equal\n    the number of pial-surface vertices that were close enough to\n    the sensors to take on a non-zero volue. If src is not None,\n    a surface, volume, or mixed source estimate will be produced\n    (depending on the kind of source space passed) and the\n    vertices will match those of src (i.e., there may be me\n    many all-zero values in stc.data).\n\nNotes\n-----\nFor surface projections, this function projects the ECoG sensors to\nthe pial surface (if ``project``), then the activation at each pial\nsurface vertex is given by the mode:\n\n- ``'sum'``\n    Activation is the sum across each sensor weighted by the fractional\n    ``distance`` from each sensor. A sensor with zero distance gets weight\n    1 and a sensor at ``distance`` meters away (or larger) gets weight 0.\n    If ``distance`` is less than half the distance between any two\n    sensors, this will be the same as ``'single'``.\n- ``'single'``\n    Same as ``'sum'`` except that only the nearest sensor is used,\n    rather than summing across sensors within the ``distance`` radius.\n    As ``'nearest'`` for vertices with distance zero to the projected\n    sensor.\n- ``'nearest'``\n    The value is given by the value of the nearest sensor, up to a\n    ``distance`` (beyond which it is zero).\n- ``'weighted'``\n    The value is given by the same as ``sum`` but the total weight for\n    each vertex is 1. (i.e., it's a weighted sum based on proximity).\n\nIf creating a Volume STC, ``src`` must be passed in, and this\nfunction will project sEEG and DBS sensors to nearby surrounding vertices.\nThen the activation at each volume vertex is given by the mode\nin the same way as ECoG surface projections.\n\n.. versionadded:: 0.22", "metadata": {}}
{"_id": "mne_mne_source_estimate.py_get_peak_doc", "text": "Get location and latency of peak amplitude.\n\nParameters\n----------\n%(get_peak_parameters)s\n\nReturns\n-------\npos : int\n    The vertex exhibiting the maximum response, either ID or index.\nlatency : float\n    The latency in seconds.", "metadata": {}}
{"_id": "mne_mne_source_estimate.py_extract_label_time_course_doc", "text": "Extract label time courses for lists of labels.\n\nThis function will extract one time course for each label. The way the\ntime courses are extracted depends on the mode parameter.\n\nParameters\n----------\n%(labels_eltc)s\n%(src_eltc)s\n%(mode_eltc)s\n%(allow_empty_eltc)s\n%(verbose)s\n\nReturns\n-------\n%(label_tc_el_returns)s\n\nSee Also\n--------\nextract_label_time_course : Extract time courses for multiple STCs.\n\nNotes\n-----\n%(eltc_mode_notes)s", "metadata": {}}
{"_id": "mne_mne_source_estimate.py_apply_function_doc", "text": "Apply a function to a subset of vertices.\n\n%(applyfun_summary_stc)s\n\nParameters\n----------\n%(fun_applyfun_stc)s\n%(picks_all)s\n%(dtype_applyfun)s\n%(n_jobs)s Ignored if ``vertice_wise=False`` as the workload\n    is split across vertices.\n%(verbose)s\n%(kwargs_fun)s\n\nReturns\n-------\nself : instance of SourceEstimate\n    The SourceEstimate object with transformed data.", "metadata": {}}
{"_id": "mne_mne_source_estimate.py_apply_baseline_doc", "text": "Baseline correct source estimate data.\n\nParameters\n----------\n%(baseline_stc)s\n    Defaults to ``(None, 0)``, i.e. beginning of the the data until\n    time point zero.\n%(verbose)s\n\nReturns\n-------\nstc : instance of SourceEstimate\n    The baseline-corrected source estimate object.\n\nNotes\n-----\nBaseline correction can be done multiple times.", "metadata": {}}
{"_id": "mne_mne_source_estimate.py_save_doc", "text": "Save the full source estimate to an HDF5 file.\n\nParameters\n----------\nfname : path-like\n    The file name to write the source estimate to, should end in\n    ``'-stc.h5'``.\nftype : str\n    File format to use. Currently, the only allowed values is ``\"h5\"``.\n%(overwrite)s\n\n    .. versionadded:: 1.0\n%(verbose)s", "metadata": {}}
{"_id": "mne_mne_source_estimate.py_sfreq_doc", "text": "Sample rate of the data.", "metadata": {}}
{"_id": "mne_mne_source_estimate.py_crop_doc", "text": "Restrict SourceEstimate to a time interval.\n\nParameters\n----------\ntmin : float | None\n    The first time point in seconds. If None the first present is used.\ntmax : float | None\n    The last time point in seconds. If None the last present is used.\n%(include_tmax)s\n\nReturns\n-------\nstc : instance of SourceEstimate\n    The cropped source estimate.", "metadata": {}}
{"_id": "mne_mne_source_estimate.py_resample_doc", "text": "Resample data.\n\nIf appropriate, an anti-aliasing filter is applied before resampling.\nSee :ref:`resampling-and-decimating` for more information.\n\nParameters\n----------\nsfreq : float\n    New sample rate to use.\nnpad : int | str\n    Amount to pad the start and end of the data.\n    Can also be \"auto\" to use a padding that will result in\n    a power-of-two size (can be much faster).\n%(method_resample)s\n\n    .. versionadded:: 1.7\n%(window_resample)s\n\n    .. versionadded:: 1.7\n%(pad_resample_auto)s\n\n    .. versionadded:: 1.7\n%(n_jobs)s\n%(verbose)s\n\nReturns\n-------\nstc : instance of SourceEstimate\n    The resampled source estimate.\n\nNotes\n-----\nFor some data, it may be more accurate to use npad=0 to reduce\nartifacts. This is dataset dependent -- check your data!\n\nNote that the sample rate of the original data is inferred from tstep.", "metadata": {}}
{"_id": "mne_mne_source_estimate.py_data_doc", "text": "Numpy array of source estimate data.", "metadata": {}}
{"_id": "mne_mne_source_estimate.py_shape_doc", "text": "Shape of the data.", "metadata": {}}
{"_id": "mne_mne_source_estimate.py_tmin_doc", "text": "The first timestamp.", "metadata": {}}
{"_id": "mne_mne_source_estimate.py_tstep_doc", "text": "The change in time between two consecutive samples (1 / sfreq).", "metadata": {}}
{"_id": "mne_mne_source_estimate.py_times_doc", "text": "A timestamp for each sample.", "metadata": {}}
{"_id": "mne_mne_source_estimate.py_mean_doc", "text": "Make a summary stc file with mean over time points.\n\nReturns\n-------\nstc : SourceEstimate | VectorSourceEstimate\n    The modified stc.", "metadata": {}}
{"_id": "mne_mne_source_estimate.py_sum_doc", "text": "Make a summary stc file with sum over time points.\n\nReturns\n-------\nstc : SourceEstimate | VectorSourceEstimate\n    The modified stc.", "metadata": {}}
{"_id": "mne_mne_source_estimate.py_sqrt_doc", "text": "Take the square root.\n\nReturns\n-------\nstc : instance of SourceEstimate\n    A copy of the SourceEstimate with sqrt(data).", "metadata": {}}
{"_id": "mne_mne_source_estimate.py_copy_doc", "text": "Return copy of source estimate instance.\n\nReturns\n-------\nstc : instance of SourceEstimate\n    A copy of the source estimate.", "metadata": {}}
{"_id": "mne_mne_source_estimate.py_bin_doc", "text": "Return a source estimate object with data summarized over time bins.\n\nTime bins of ``width`` seconds. This method is intended for\nvisualization only. No filter is applied to the data before binning,\nmaking the method inappropriate as a tool for downsampling data.\n\nParameters\n----------\nwidth : scalar\n    Width of the individual bins in seconds.\ntstart : scalar | None\n    Time point where the first bin starts. The default is the first\n    time point of the stc.\ntstop : scalar | None\n    Last possible time point contained in a bin (if the last bin would\n    be shorter than width it is dropped). The default is the last time\n    point of the stc.\nfunc : callable\n    Function that is applied to summarize the data. Needs to accept a\n    numpy.array as first input and an ``axis`` keyword argument.\n\nReturns\n-------\nstc : SourceEstimate | VectorSourceEstimate\n    The binned source estimate.", "metadata": {}}
{"_id": "mne_mne_source_estimate.py_transform_data_doc", "text": "Get data after a linear (time) transform has been applied.\n\nThe transform is applied to each source time course independently.\n\nParameters\n----------\nfunc : callable\n    The transform to be applied, including parameters (see, e.g.,\n    :func:`functools.partial`). The first parameter of the function is\n    the input data. The first return value is the transformed data,\n    remaining outputs are ignored. The first dimension of the\n    transformed data has to be the same as the first dimension of the\n    input data.\nidx : array | None\n    Indicices of source time courses for which to compute transform.\n    If None, all time courses are used.\ntmin_idx : int | None\n    Index of first time point to include. If None, the index of the\n    first time point is used.\ntmax_idx : int | None\n    Index of the first time point not to include. If None, time points\n    up to (and including) the last time point are included.\n\nReturns\n-------\ndata_t : ndarray\n    The transformed data.\n\nNotes\n-----\nApplying transforms can be significantly faster if the\nSourceEstimate object was created using \"(kernel, sens_data)\", for\nthe \"data\" parameter as the transform is applied in sensor space.\nInverse methods, e.g., \"apply_inverse_epochs\", or \"apply_lcmv_epochs\"\ndo this automatically (if possible).", "metadata": {}}
{"_id": "mne_mne_source_estimate.py_transform_doc", "text": "Apply linear transform.\n\nThe transform is applied to each source time course independently.\n\nParameters\n----------\nfunc : callable\n    The transform to be applied, including parameters (see, e.g.,\n    :func:`functools.partial`). The first parameter of the function is\n    the input data. The first two dimensions of the transformed data\n    should be (i) vertices and (ii) time.  See Notes for details.\nidx : array | None\n    Indices of source time courses for which to compute transform.\n    If None, all time courses are used.\ntmin : float | int | None\n    First time point to include (ms). If None, self.tmin is used.\ntmax : float | int | None\n    Last time point to include (ms). If None, self.tmax is used.\ncopy : bool\n    If True, return a new instance of SourceEstimate instead of\n    modifying the input inplace.\n\nReturns\n-------\nstcs : SourceEstimate | VectorSourceEstimate | list\n    The transformed stc or, in the case of transforms which yield\n    N-dimensional output (where N > 2), a list of stcs. For a list,\n    copy must be True.\n\nNotes\n-----\nTransforms which yield 3D\noutput (e.g. time-frequency transforms) are valid, so long as the\nfirst two dimensions are vertices and time.  In this case, the\ncopy parameter must be True and a list of\nSourceEstimates, rather than a single instance of SourceEstimate,\nwill be returned, one for each index of the 3rd dimension of the\ntransformed data.  In the case of transforms yielding 2D output\n(e.g. filtering), the user has the option of modifying the input\ninplace (copy = False) or returning a new instance of\nSourceEstimate (copy = True) with the transformed data.\n\nApplying transforms can be significantly faster if the\nSourceEstimate object was created using \"(kernel, sens_data)\", for\nthe \"data\" parameter as the transform is applied in sensor space.\nInverse methods, e.g., \"apply_inverse_epochs\", or \"apply_lcmv_epochs\"\ndo this automatically (if possible).", "metadata": {}}
{"_id": "mne_mne_source_estimate.py_to_data_frame_doc", "text": "Export data in tabular structure as a pandas DataFrame.\n\nVertices are converted to columns in the DataFrame. By default,\nan additional column \"time\" is added, unless ``index='time'``\n(in which case time values form the DataFrame's index).\n\nParameters\n----------\n%(index_df_evk)s\n    Defaults to ``None``.\n%(scalings_df)s\n%(long_format_df_stc)s\n%(time_format_df)s\n\n    .. versionadded:: 0.20\n%(verbose)s\n\nReturns\n-------\n%(df_return)s", "metadata": {}}
{"_id": "mne_mne_source_estimate.py_lh_data_doc", "text": "Left hemisphere data.", "metadata": {}}
{"_id": "mne_mne_source_estimate.py_rh_data_doc", "text": "Right hemisphere data.", "metadata": {}}
{"_id": "mne_mne_source_estimate.py_lh_vertno_doc", "text": "Left hemisphere vertno.", "metadata": {}}
{"_id": "mne_mne_source_estimate.py_rh_vertno_doc", "text": "Right hemisphere vertno.", "metadata": {}}
{"_id": "mne_mne_source_estimate.py_in_label_doc", "text": "Get a source estimate object restricted to a label.\n\nSourceEstimate contains the time course of\nactivation of all sources inside the label.\n\nParameters\n----------\nlabel : Label | BiHemiLabel\n    The label (as created for example by mne.read_label). If the label\n    does not match any sources in the SourceEstimate, a ValueError is\n    raised.\n\nReturns\n-------\nstc : SourceEstimate | VectorSourceEstimate\n    The source estimate restricted to the given label.", "metadata": {}}
{"_id": "mne_mne_source_estimate.py_save_as_surface_doc", "text": "Save a surface source estimate (stc) as a GIFTI file.\n\nParameters\n----------\nfname : path-like\n    Filename basename to save files as.\n    Will write anatomical GIFTI plus time series GIFTI for both lh/rh,\n    for example ``\"basename\"`` will write ``\"basename.lh.gii\"``,\n    ``\"basename.lh.time.gii\"``, ``\"basename.rh.gii\"``, and\n    ``\"basename.rh.time.gii\"``.\nsrc : instance of SourceSpaces\n    The source space of the forward solution.\nscale : float\n    Scale factor to apply to the data (functional) values.\nscale_rr : float\n    Scale factor for the source vertex positions. The default (1e3) will\n    scale from meters to millimeters, which is more standard for GIFTI files.\n\nNotes\n-----\n.. versionadded:: 1.7", "metadata": {}}
{"_id": "mne_mne_source_estimate.py_expand_doc", "text": "Expand SourceEstimate to include more vertices.\n\nThis will add rows to stc.data (zero-filled) and modify stc.vertices\nto include all vertices in stc.vertices and the input vertices.\n\nParameters\n----------\nvertices : list of array\n    New vertices to add. Can also contain old values.\n\nReturns\n-------\nstc : SourceEstimate | VectorSourceEstimate\n    The modified stc (note: method operates inplace).", "metadata": {}}
{"_id": "mne_mne_source_estimate.py_to_original_src_doc", "text": "Get a source estimate from morphed source to the original subject.\n\nParameters\n----------\nsrc_orig : instance of SourceSpaces\n    The original source spaces that were morphed to the current\n    subject.\nsubject_orig : str | None\n    The original subject. For most source spaces this shouldn't need\n    to be provided, since it is stored in the source space itself.\n%(subjects_dir)s\n%(verbose)s\n\nReturns\n-------\nstc : SourceEstimate | VectorSourceEstimate\n    The transformed source estimate.\n\nSee Also\n--------\nmorph_source_spaces\n\nNotes\n-----\n.. versionadded:: 0.10.0", "metadata": {}}
{"_id": "mne_mne_source_estimate.py_get_peak_doc", "text": "Get location and latency of peak amplitude.\n\nParameters\n----------\nhemi : {'lh', 'rh', None}\n    The hemi to be considered. If None, the entire source space is\n    considered.\n%(get_peak_parameters)s\n\nReturns\n-------\npos : int\n    The vertex exhibiting the maximum response, either ID or index.\nlatency : float | int\n    The time point of the maximum response, either latency in seconds\n    or index.", "metadata": {}}
{"_id": "mne_mne_source_estimate.py_save_doc", "text": "Save the source estimates to a file.\n\nParameters\n----------\nfname : path-like\n    The stem of the file name. The file names used for surface source\n    spaces are obtained by adding ``\"-lh.stc\"`` and ``\"-rh.stc\"`` (or\n    ``\"-lh.w\"`` and ``\"-rh.w\"``) to the stem provided, for the left and\n    the right hemisphere, respectively.\nftype : str\n    File format to use. Allowed values are ``\"stc\"`` (default),\n    ``\"w\"``, and ``\"h5\"``. The ``\"w\"`` format only supports a single\n    time point.\n%(overwrite)s\n\n    .. versionadded:: 1.0\n%(verbose)s", "metadata": {}}
{"_id": "mne_mne_source_estimate.py_estimate_snr_doc", "text": "Compute time-varying SNR in the source space.\n\nThis function should only be used with source estimates with units\nnanoAmperes (i.e., MNE-like solutions, *not* dSPM or sLORETA).\nSee also :footcite:`GoldenholzEtAl2009`.\n\n.. warning:: This function currently only works properly for fixed\n             orientation.\n\nParameters\n----------\n%(info_not_none)s\nfwd : instance of Forward\n    The forward solution used to create the source estimate.\ncov : instance of Covariance\n    The noise covariance used to estimate the resting cortical\n    activations. Should be an evoked covariance, not empty room.\n%(verbose)s\n\nReturns\n-------\nsnr_stc : instance of SourceEstimate\n    The source estimate with the SNR computed.\n\nNotes\n-----\nWe define the SNR in decibels for each source location at each\ntime point as:\n\n.. math::\n\n    {\\rm SNR} = 10\\log_10[\\frac{a^2}{N}\\sum_k\\frac{b_k^2}{s_k^2}]\n\nwhere :math:`\\\\b_k` is the signal on sensor :math:`k` provided by the\nforward model for a source with unit amplitude, :math:`a` is the\nsource amplitude, :math:`N` is the number of sensors, and\n:math:`s_k^2` is the noise variance on sensor :math:`k`.\n\nReferences\n----------\n.. footbibliography::", "metadata": {}}
{"_id": "mne_mne_source_estimate.py_center_of_mass_doc", "text": "Compute the center of mass of activity.\n\nThis function computes the spatial center of mass on the surface\nas well as the temporal center of mass as in :footcite:`LarsonLee2013`.\n\n.. note:: All activity must occur in a single hemisphere, otherwise\n          an error is raised. The \"mass\" of each point in space for\n          computing the spatial center of mass is computed by summing\n          across time, and vice-versa for each point in time in\n          computing the temporal center of mass. This is useful for\n          quantifying spatio-temporal cluster locations, especially\n          when combined with :func:`mne.vertex_to_mni`.\n\nParameters\n----------\nsubject : str | None\n    The subject the stc is defined for.\nhemi : int, or None\n    Calculate the center of mass for the left (0) or right (1)\n    hemisphere. If None, one of the hemispheres must be all zeroes,\n    and the center of mass will be calculated for the other\n    hemisphere (useful for getting COM for clusters).\nrestrict_vertices : bool | array of int | instance of SourceSpaces\n    If True, returned vertex will be one from stc. Otherwise, it could\n    be any vertex from surf. If an array of int, the returned vertex\n    will come from that array. If instance of SourceSpaces (as of\n    0.13), the returned vertex will be from the given source space.\n    For most accuruate estimates, do not restrict vertices.\n%(subjects_dir)s\nsurf : str\n    The surface to use for Euclidean distance center of mass\n    finding. The default here is \"sphere\", which finds the center\n    of mass on the spherical surface to help avoid potential issues\n    with cortical folding.\n\nReturns\n-------\nvertex : int\n    Vertex of the spatial center of mass for the inferred hemisphere,\n    with each vertex weighted by the sum of the stc across time. For a\n    boolean stc, then, this would be weighted purely by the duration\n    each vertex was active.\nhemi : int\n    Hemisphere the vertex was taken from.\nt : float\n    Time of the temporal center of mass (weighted by the sum across\n    source vertices).\n\nSee Also\n--------\nmne.Label.center_of_mass\nmne.vertex_to_mni\n\nReferences\n----------\n.. footbibliography::", "metadata": {}}
{"_id": "mne_mne_source_estimate.py_magnitude_doc", "text": "Compute magnitude of activity without directionality.\n\nReturns\n-------\nstc : instance of SourceEstimate\n    The source estimate without directionality information.", "metadata": {}}
{"_id": "mne_mne_source_estimate.py_project_doc", "text": "Project the data for each vertex in a given direction.\n\nParameters\n----------\ndirections : ndarray, shape (n_vertices, 3) | str\n    Can be:\n\n    - ``'normal'``\n        Project onto the source space normals.\n    - ``'pca'``\n        SVD will be used to project onto the direction of maximal\n        power for each source.\n    - :class:`~numpy.ndarray`, shape (n_vertices, 3)\n        Projection directions for each source.\nsrc : instance of SourceSpaces | None\n    The source spaces corresponding to the source estimate.\n    Not used when ``directions`` is an array, optional when\n    ``directions='pca'``.\n%(use_cps)s\n    Should be the same value that was used when the forward model\n    was computed (typically True).\n\nReturns\n-------\nstc : instance of SourceEstimate\n    The projected source estimate.\ndirections : ndarray, shape (n_vertices, 3)\n    The directions that were computed (or just used).\n\nNotes\n-----\nWhen using SVD, there is a sign ambiguity for the direction of maximal\npower. When ``src is None``, the direction is chosen that makes the\nresulting time waveform sum positive (i.e., have positive amplitudes).\nWhen ``src`` is provided, the directions are flipped in the direction\nof the source normals, i.e., outward from cortex for surface source\nspaces and in the +Z / superior direction for volume source spaces.\n\n.. versionadded:: 0.21", "metadata": {}}
{"_id": "mne_mne_source_estimate.py_extract_label_time_course_doc", "text": "Extract label time courses for lists of labels.\n\nThis function will extract one time course for each label. The way the\ntime courses are extracted depends on the mode parameter.\n\nParameters\n----------\n%(labels_eltc)s\n%(src_eltc)s\n%(mode_eltc)s\n%(allow_empty_eltc)s\n%(mri_resolution_eltc)s\n%(verbose)s\n\nReturns\n-------\n%(label_tc_el_returns)s\n\nSee Also\n--------\nextract_label_time_course : Extract time courses for multiple STCs.\n\nNotes\n-----\n%(eltc_mode_notes)s", "metadata": {}}
{"_id": "mne_mne_source_estimate.py_in_label_doc", "text": "Get a source estimate object restricted to a label.\n\nSourceEstimate contains the time course of\nactivation of all sources inside the label.\n\nParameters\n----------\nlabel : str | int\n    The label to use. Can be the name of a label if using a standard\n    FreeSurfer atlas, or an integer value to extract from the ``mri``.\nmri : str\n    Path to the atlas to use.\nsrc : instance of SourceSpaces\n    The volumetric source space. It must be a single, whole-brain\n    volume.\n%(verbose)s\n\nReturns\n-------\nstc : VolSourceEstimate | VolVectorSourceEstimate\n    The source estimate restricted to the given label.\n\nNotes\n-----\n.. versionadded:: 0.21.0", "metadata": {}}
{"_id": "mne_mne_source_estimate.py_save_as_volume_doc", "text": "Save a volume source estimate in a NIfTI file.\n\nParameters\n----------\nfname : path-like\n    The name of the generated nifti file.\nsrc : list\n    The list of source spaces (should all be of type volume).\ndest : ``'mri'`` | ``'surf'``\n    If ``'mri'`` the volume is defined in the coordinate system of\n    the original T1 image. If ``'surf'`` the coordinate system\n    of the FreeSurfer surface is used (Surface RAS).\nmri_resolution : bool\n    It True the image is saved in MRI resolution.\n\n    .. warning: If you have many time points the file produced can be\n                huge. The default is ``mri_resolution=False``.\nformat : str\n    Either ``'nifti1'`` (default) or ``'nifti2'``.\n\n    .. versionadded:: 0.17\n%(overwrite)s\n\n    .. versionadded:: 1.0\n%(verbose)s\n\n    .. versionadded:: 1.0\n\nReturns\n-------\nimg : instance Nifti1Image\n    The image object.\n\nNotes\n-----\n.. versionadded:: 0.9.0", "metadata": {}}
{"_id": "mne_mne_source_estimate.py_as_volume_doc", "text": "Export volume source estimate as a nifti object.\n\nParameters\n----------\nsrc : instance of SourceSpaces\n    The source spaces (should all be of type volume, or part of a\n    mixed source space).\ndest : ``'mri'`` | ``'surf'``\n    If ``'mri'`` the volume is defined in the coordinate system of\n    the original T1 image. If 'surf' the coordinate system\n    of the FreeSurfer surface is used (Surface RAS).\nmri_resolution : bool\n    It True the image is saved in MRI resolution.\n\n    .. warning: If you have many time points the file produced can be\n                huge. The default is ``mri_resolution=False``.\nformat : str\n    Either 'nifti1' (default) or 'nifti2'.\n\nReturns\n-------\nimg : instance of Nifti1Image\n    The image object.\n\nNotes\n-----\n.. versionadded:: 0.9.0", "metadata": {}}
{"_id": "mne_mne_source_estimate.py_save_doc", "text": "Save the source estimates to a file.\n\nParameters\n----------\nfname : path-like\n    The stem of the file name. The stem is extended with ``\"-vl.stc\"``\n    or ``\"-vl.w\"``.\nftype : str\n    File format to use. Allowed values are ``\"stc\"`` (default),\n    ``\"w\"``, and ``\"h5\"``. The ``\"w\"`` format only supports a single\n    time point.\n%(overwrite)s\n\n    .. versionadded:: 1.0\n%(verbose)s", "metadata": {}}
{"_id": "mne_mne_source_estimate.py_surface_doc", "text": "Return the cortical surface source estimate.\n\nReturns\n-------\nstc : instance of SourceEstimate or VectorSourceEstimate\n    The surface source estimate.", "metadata": {}}
{"_id": "mne_mne_source_estimate.py_volume_doc", "text": "Return the volume surface source estimate.\n\nReturns\n-------\nstc : instance of VolSourceEstimate or VolVectorSourceEstimate\n    The volume source estimate.", "metadata": {}}
{"_id": "mne_mne_filter.py_next_fast_len_doc", "text": "Find the next fast size of input data to `fft`, for zero-padding, etc.\n\nSciPy's FFTPACK has efficient functions for radix {2, 3, 4, 5}, so this\nreturns the next composite of the prime factors 2, 3, and 5 which is\ngreater than or equal to `target`. (These are also known as 5-smooth\nnumbers, regular numbers, or Hamming numbers.)\n\nParameters\n----------\ntarget : int\n    Length to start searching from.  Must be a positive integer.\n\nReturns\n-------\nout : int\n    The first 5-smooth number greater than or equal to `target`.\n\nNotes\n-----\nCopied from SciPy with minor modifications.", "metadata": {}}
{"_id": "mne_mne_filter.py_estimate_ringing_samples_doc", "text": "Estimate filter ringing.\n\nParameters\n----------\nsystem : tuple | ndarray\n    A tuple of (b, a) or ndarray of second-order sections coefficients.\nmax_try : int\n    Approximate maximum number of samples to try.\n    This will be changed to a multiple of 1000.\n\nReturns\n-------\nn : int\n    The approximate ringing.", "metadata": {}}
{"_id": "mne_mne_filter.py_construct_iir_filter_doc", "text": "Use IIR parameters to get filtering coefficients.\n\nThis function works like a wrapper for iirdesign and iirfilter in\nscipy.signal to make filter coefficients for IIR filtering. It also\nestimates the number of padding samples based on the filter ringing.\nIt creates a new iir_params dict (or updates the one passed to the\nfunction) with the filter coefficients ('b' and 'a') and an estimate\nof the padding necessary ('padlen') so IIR filtering can be performed.\n\nParameters\n----------\niir_params : dict\n    Dictionary of parameters to use for IIR filtering.\n\n        * If ``iir_params['sos']`` exists, it will be used as\n          second-order sections to perform IIR filtering.\n\n          .. versionadded:: 0.13\n\n        * Otherwise, if ``iir_params['b']`` and ``iir_params['a']``\n          exist, these will be used as coefficients to perform IIR\n          filtering.\n        * Otherwise, if ``iir_params['order']`` and\n          ``iir_params['ftype']`` exist, these will be used with\n          `scipy.signal.iirfilter` to make a filter.\n          You should also supply ``iir_params['rs']`` and\n          ``iir_params['rp']`` if using elliptic or Chebychev filters.\n        * Otherwise, if ``iir_params['gpass']`` and\n          ``iir_params['gstop']`` exist, these will be used with\n          `scipy.signal.iirdesign` to design a filter.\n        * ``iir_params['padlen']`` defines the number of samples to pad\n          (and an estimate will be calculated if it is not given).\n          See Notes for more details.\n        * ``iir_params['output']`` defines the system output kind when\n          designing filters, either \"sos\" or \"ba\". For 0.13 the\n          default is 'ba' but will change to 'sos' in 0.14.\n\nf_pass : float or list of float\n    Frequency for the pass-band. Low-pass and high-pass filters should\n    be a float, band-pass should be a 2-element list of float.\nf_stop : float or list of float\n    Stop-band frequency (same size as f_pass). Not used if 'order' is\n    specified in iir_params.\nsfreq : float | None\n    The sample rate.\nbtype : str\n    Type of filter. Should be 'lowpass', 'highpass', or 'bandpass'\n    (or analogous string representations known to\n    :func:`scipy.signal.iirfilter`).\nreturn_copy : bool\n    If False, the 'sos', 'b', 'a', and 'padlen' entries in\n    ``iir_params`` will be set inplace (if they weren't already).\n    Otherwise, a new ``iir_params`` instance will be created and\n    returned with these entries.\nphase : str\n    Phase of the filter.\n    ``phase='zero'`` (default) or equivalently ``'zero-double'`` constructs and\n    applies IIR filter twice, once forward, and once backward (making it non-causal)\n    using :func:`~scipy.signal.filtfilt`; ``phase='forward'`` will apply\n    the filter once in the forward (causal) direction using\n    :func:`~scipy.signal.lfilter`.\n\n    .. versionadded:: 0.13\n%(verbose)s\n\nReturns\n-------\niir_params : dict\n    Updated iir_params dict, with the entries (set only if they didn't\n    exist before) for 'sos' (or 'b', 'a'), and 'padlen' for\n    IIR filtering.\n\nSee Also\n--------\nmne.filter.filter_data\nmne.io.Raw.filter\n\nNotes\n-----\nThis function triages calls to :func:`scipy.signal.iirfilter` and\n:func:`scipy.signal.iirdesign` based on the input arguments (see\nlinked functions for more details).\n\n.. versionchanged:: 0.14\n   Second-order sections are used in filter design by default (replacing\n   ``output='ba'`` by ``output='sos'``) to help ensure filter stability\n   and reduce numerical error.\n\nExamples\n--------\niir_params can have several forms. Consider constructing a low-pass\nfilter at 40 Hz with 1000 Hz sampling rate.\n\nIn the most basic (2-parameter) form of iir_params, the order of the\nfilter 'N' and the type of filtering 'ftype' are specified. To get\ncoefficients for a 4th-order Butterworth filter, this would be:\n\n>>> iir_params = dict(order=4, ftype='butter', output='sos')  # doctest:+SKIP\n>>> iir_params = construct_iir_filter(iir_params, 40, None, 1000, 'low', return_copy=False)  # doctest:+SKIP\n>>> print((2 * len(iir_params['sos']), iir_params['padlen']))  # doctest:+SKIP\n(4, 82)\n\nFilters can also be constructed using filter design methods. To get a\n40 Hz Chebyshev type 1 lowpass with specific gain characteristics in the\npass and stop bands (assuming the desired stop band is at 45 Hz), this\nwould be a filter with much longer ringing:\n\n>>> iir_params = dict(ftype='cheby1', gpass=3, gstop=20, output='sos')  # doctest:+SKIP\n>>> iir_params = construct_iir_filter(iir_params, 40, 50, 1000, 'low')  # doctest:+SKIP\n>>> print((2 * len(iir_params['sos']), iir_params['padlen']))  # doctest:+SKIP\n(6, 439)\n\nPadding and/or filter coefficients can also be manually specified. For\na 10-sample moving window with no padding during filtering, for example,\none can just do:\n\n>>> iir_params = dict(b=np.ones((10)), a=[1, 0], padlen=0)  # doctest:+SKIP\n>>> iir_params = construct_iir_filter(iir_params, return_copy=False)  # doctest:+SKIP\n>>> print((iir_params['b'], iir_params['a'], iir_params['padlen']))  # doctest:+SKIP\n(array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), [1, 0], 0)\n\nFor more information, see the tutorials\n:ref:`disc-filtering` and :ref:`tut-filter-resample`.", "metadata": {}}
{"_id": "mne_mne_filter.py_filter_data_doc", "text": "Filter a subset of channels.\n\nParameters\n----------\ndata : ndarray, shape (..., n_times)\n    The data to filter.\nsfreq : float\n    The sample frequency in Hz.\n%(l_freq)s\n%(h_freq)s\n%(picks_nostr)s\n    Currently this is only supported for 2D (n_channels, n_times) and\n    3D (n_epochs, n_channels, n_times) arrays.\n%(filter_length)s\n%(l_trans_bandwidth)s\n%(h_trans_bandwidth)s\n%(n_jobs_fir)s\n%(method_fir)s\n%(iir_params)s\ncopy : bool\n    If True, a copy of x, filtered, is returned. Otherwise, it operates\n    on x in place.\n%(phase)s\n%(fir_window)s\n%(fir_design)s\n%(pad_fir)s\n    The default is ``'reflect_limited'``.\n\n    .. versionadded:: 0.15\n%(verbose)s\n\nReturns\n-------\ndata : ndarray, shape (..., n_times)\n    The filtered data.\n\nSee Also\n--------\nconstruct_iir_filter\ncreate_filter\nmne.io.Raw.filter\nnotch_filter\nresample\n\nNotes\n-----\nApplies a zero-phase low-pass, high-pass, band-pass, or band-stop\nfilter to the channels selected by ``picks``.\n\n``l_freq`` and ``h_freq`` are the frequencies below which and above\nwhich, respectively, to filter out of the data. Thus the uses are:\n\n    * ``l_freq < h_freq``: band-pass filter\n    * ``l_freq > h_freq``: band-stop filter\n    * ``l_freq is not None and h_freq is None``: high-pass filter\n    * ``l_freq is None and h_freq is not None``: low-pass filter\n\n.. note:: If n_jobs > 1, more memory is required as\n          ``len(picks) * n_times`` additional time points need to\n          be temporarily stored in memory.\n\nFor more information, see the tutorials\n:ref:`disc-filtering` and :ref:`tut-filter-resample` and\n:func:`mne.filter.create_filter`.", "metadata": {}}
{"_id": "mne_mne_filter.py_create_filter_doc", "text": "Create a FIR or IIR filter.\n\n``l_freq`` and ``h_freq`` are the frequencies below which and above\nwhich, respectively, to filter out of the data. Thus the uses are:\n\n    * ``l_freq < h_freq``: band-pass filter\n    * ``l_freq > h_freq``: band-stop filter\n    * ``l_freq is not None and h_freq is None``: high-pass filter\n    * ``l_freq is None and h_freq is not None``: low-pass filter\n\nParameters\n----------\ndata : ndarray, shape (..., n_times) | None\n    The data that will be filtered. This is used for sanity checking\n    only. If None, no sanity checking related to the length of the signal\n    relative to the filter order will be performed.\nsfreq : float\n    The sample frequency in Hz.\n%(l_freq)s\n%(h_freq)s\n%(filter_length)s\n%(l_trans_bandwidth)s\n%(h_trans_bandwidth)s\n%(method_fir)s\n%(iir_params)s\n%(phase)s\n%(fir_window)s\n%(fir_design)s\n%(verbose)s\n\nReturns\n-------\nfilt : array or dict\n    Will be an array of FIR coefficients for method='fir', and dict\n    with IIR parameters for method='iir'.\n\nSee Also\n--------\nfilter_data\n\nNotes\n-----\n.. note:: For FIR filters, the *cutoff frequency*, i.e. the -6 dB point,\n          is in the middle of the transition band (when using phase='zero'\n          and fir_design='firwin'). For IIR filters, the cutoff frequency\n          is given by ``l_freq`` or ``h_freq`` directly, and\n          ``l_trans_bandwidth`` and ``h_trans_bandwidth`` are ignored.\n\n**Band-pass filter**\n\nThe frequency response is (approximately) given by::\n\n   1-|               ----------\n     |             /|         | \\\n |H| |            / |         |  \\\n     |           /  |         |   \\\n     |          /   |         |    \\\n   0-|----------    |         |     --------------\n     |         |    |         |     |            |\n     0        Fs1  Fp1       Fp2   Fs2          Nyq\n\nWhere:\n\n    * Fs1 = Fp1 - l_trans_bandwidth in Hz\n    * Fs2 = Fp2 + h_trans_bandwidth in Hz\n\n**Band-stop filter**\n\nThe frequency response is (approximately) given by::\n\n    1-|---------                   ----------\n      |         \\                 /\n  |H| |          \\               /\n      |           \\             /\n      |            \\           /\n    0-|             -----------\n      |        |    |         |    |        |\n      0       Fp1  Fs1       Fs2  Fp2      Nyq\n\nWhere ``Fs1 = Fp1 + l_trans_bandwidth`` and\n``Fs2 = Fp2 - h_trans_bandwidth``.\n\nMultiple stop bands can be specified using arrays.\n\n**Low-pass filter**\n\nThe frequency response is (approximately) given by::\n\n    1-|------------------------\n      |                        \\\n  |H| |                         \\\n      |                          \\\n      |                           \\\n    0-|                            ----------------\n      |                       |    |              |\n      0                      Fp  Fstop           Nyq\n\nWhere ``Fstop = Fp + trans_bandwidth``.\n\n**High-pass filter**\n\nThe frequency response is (approximately) given by::\n\n    1-|             -----------------------\n      |            /\n  |H| |           /\n      |          /\n      |         /\n    0-|---------\n      |        |    |                     |\n      0      Fstop  Fp                   Nyq\n\nWhere ``Fstop = Fp - trans_bandwidth``.\n\n.. versionadded:: 0.14", "metadata": {}}
{"_id": "mne_mne_filter.py_notch_filter_doc", "text": "Notch filter for the signal x.\n\nApplies a zero-phase notch filter to the signal x, operating on the last\ndimension.\n\nParameters\n----------\nx : array\n    Signal to filter.\nFs : float\n    Sampling rate in Hz.\nfreqs : float | array of float | None\n    Frequencies to notch filter in Hz, e.g. np.arange(60, 241, 60).\n    Multiple stop-bands can only be used with method='fir'\n    and method='spectrum_fit'. None can only be used with the mode\n    'spectrum_fit', where an F test is used to find sinusoidal components.\n%(filter_length_notch)s\nnotch_widths : float | array of float | None\n    Width of the stop band (centred at each freq in freqs) in Hz.\n    If None, freqs / 200 is used.\ntrans_bandwidth : float\n    Width of the transition band in Hz.\n    Only used for ``method='fir'`` and ``method='iir'``.\n%(method_fir)s\n    'spectrum_fit' will use multi-taper estimation of sinusoidal\n    components. If freqs=None and method='spectrum_fit', significant\n    sinusoidal components are detected using an F test, and noted by\n    logging.\n%(iir_params)s\nmt_bandwidth : float | None\n    The bandwidth of the multitaper windowing function in Hz.\n    Only used in 'spectrum_fit' mode.\np_value : float\n    P-value to use in F-test thresholding to determine significant\n    sinusoidal components to remove when method='spectrum_fit' and\n    freqs=None. Note that this will be Bonferroni corrected for the\n    number of frequencies, so large p-values may be justified.\n%(picks_nostr)s\n    Only supported for 2D (n_channels, n_times) and 3D\n    (n_epochs, n_channels, n_times) data.\n%(n_jobs_fir)s\ncopy : bool\n    If True, a copy of x, filtered, is returned. Otherwise, it operates\n    on x in place.\n%(phase)s\n%(fir_window)s\n%(fir_design)s\n%(pad_fir)s\n    The default is ``'reflect_limited'``.\n%(verbose)s\n\nReturns\n-------\nxf : array\n    The x array filtered.\n\nSee Also\n--------\nfilter_data\nresample\n\nNotes\n-----\nThe frequency response is (approximately) given by::\n\n    1-|----------         -----------\n      |          \\       /\n  |H| |           \\     /\n      |            \\   /\n      |             \\ /\n    0-|              -\n      |         |    |    |         |\n      0        Fp1 freq  Fp2       Nyq\n\nFor each freq in freqs, where ``Fp1 = freq - trans_bandwidth / 2`` and\n``Fs2 = freq + trans_bandwidth / 2``.\n\nReferences\n----------\nMulti-taper removal is inspired by code from the Chronux toolbox, see\nwww.chronux.org and the book \"Observed Brain Dynamics\" by Partha Mitra\n& Hemant Bokil, Oxford University Press, New York, 2008. Please\ncite this in publications if method 'spectrum_fit' is used.", "metadata": {}}
{"_id": "mne_mne_filter.py_resample_doc", "text": "Resample an array.\n\nOperates along the last dimension of the array.\n\nParameters\n----------\nx : ndarray\n    Signal to resample.\nup : float\n    Factor to upsample by.\ndown : float\n    Factor to downsample by.\naxis : int\n    Axis along which to resample (default is the last axis).\n%(window_resample)s\n%(n_jobs_cuda)s\n    ``n_jobs='cuda'`` is only supported when ``method=\"fft\"``.\n%(pad_resample_auto)s\n\n    .. versionadded:: 0.15\n%(npad_resample)s\n%(method_resample)s\n\n    .. versionadded:: 1.7\n%(verbose)s\n\nReturns\n-------\ny : array\n    The x array resampled.\n\nNotes\n-----\nWhen using ``method=\"fft\"`` (default),\nthis uses (hopefully) intelligent edge padding and frequency-domain\nwindowing improve :func:`scipy.signal.resample`'s resampling method, which\nwe have adapted for our use here. Choices of npad and window have\nimportant consequences, and the default choices should work well\nfor most natural signals.", "metadata": {}}
{"_id": "mne_mne_filter.py_detrend_doc", "text": "Detrend the array x.\n\nParameters\n----------\nx : n-d array\n    Signal to detrend.\norder : int\n    Fit order. Currently must be '0' or '1'.\naxis : int\n    Axis of the array to operate on.\n\nReturns\n-------\ny : array\n    The x array detrended.\n\nExamples\n--------\nAs in :func:`scipy.signal.detrend`::\n\n    >>> randgen = np.random.RandomState(9)\n    >>> npoints = int(1e3)\n    >>> noise = randgen.randn(npoints)\n    >>> x = 3 + 2*np.linspace(0, 1, npoints) + noise\n    >>> bool((detrend(x) - noise).max() < 0.01)\n    True", "metadata": {}}
{"_id": "mne_mne_filter.py_design_mne_c_filter_doc", "text": "Create a FIR filter like that used by MNE-C.\n\nParameters\n----------\nsfreq : float\n    The sample frequency.\nl_freq : float | None\n    The low filter frequency in Hz, default None.\n    Can be None to avoid high-passing.\nh_freq : float\n    The high filter frequency in Hz, default 40.\n    Can be None to avoid low-passing.\nl_trans_bandwidth : float | None\n    Low transition bandwidthin Hz. Can be None (default) to use 3 samples.\nh_trans_bandwidth : float\n    High transition bandwidth in Hz.\n%(verbose)s\n\nReturns\n-------\nh : ndarray, shape (8193,)\n    The linear-phase (symmetric) FIR filter coefficients.\n\nNotes\n-----\nThis function is provided mostly for reference purposes.\n\nMNE-C uses a frequency-domain filter design technique by creating a\nlinear-phase filter of length 8193. In the frequency domain, the\n4197 frequencies are directly constructed, with zeroes in the stop-band\nand ones in the passband, with squared cosine ramps in between.", "metadata": {}}
{"_id": "mne_mne_filter.py_savgol_filter_doc", "text": "Filter the data using Savitzky-Golay polynomial method.\n\nParameters\n----------\nh_freq : float\n    Approximate high cut-off frequency in Hz. Note that this\n    is not an exact cutoff, since Savitzky-Golay filtering\n    :footcite:`SavitzkyGolay1964` is done using polynomial fits\n    instead of FIR/IIR filtering. This parameter is thus used to\n    determine the length of the window over which a 5th-order\n    polynomial smoothing is used.\n%(verbose)s\n\nReturns\n-------\ninst : instance of Epochs, Evoked or SourceEstimate\n    The object with the filtering applied.\n\nSee Also\n--------\nmne.io.Raw.filter\n\nNotes\n-----\nFor Savitzky-Golay low-pass approximation, see:\n\n    https://gist.github.com/larsoner/bbac101d50176611136b\n\nWhen working on SourceEstimates the sample rate of the original data is inferred from tstep.\n\n.. versionadded:: 0.9.0\n\nReferences\n----------\n.. footbibliography::\n\nExamples\n--------\n>>> import mne\n>>> from os import path as op\n>>> evoked_fname = op.join(mne.datasets.sample.data_path(), 'MEG', 'sample', 'sample_audvis-ave.fif')  # doctest:+SKIP\n>>> evoked = mne.read_evokeds(evoked_fname, baseline=(None, 0))[0]  # doctest:+SKIP\n>>> evoked.savgol_filter(10.)  # low-pass at around 10 Hz # doctest:+SKIP\n>>> evoked.plot()  # doctest:+SKIP", "metadata": {}}
{"_id": "mne_mne_filter.py_filter_doc", "text": "Filter a subset of channels/vertices.\n\nParameters\n----------\n%(l_freq)s\n%(h_freq)s\n%(picks_all_data)s\n%(filter_length)s\n%(l_trans_bandwidth)s\n%(h_trans_bandwidth)s\n%(n_jobs_fir)s\n%(method_fir)s\n%(iir_params)s\n%(phase)s\n%(fir_window)s\n%(fir_design)s\n%(skip_by_annotation)s\n\n    .. versionadded:: 0.16.\n%(pad_fir)s\n%(verbose)s\n\nReturns\n-------\ninst : instance of Epochs, Evoked, SourceEstimate, or Raw\n    The filtered data.\n\nSee Also\n--------\nmne.filter.create_filter\nmne.Evoked.savgol_filter\nmne.io.Raw.notch_filter\nmne.io.Raw.resample\nmne.filter.create_filter\nmne.filter.filter_data\nmne.filter.construct_iir_filter\n\nNotes\n-----\nApplies a zero-phase low-pass, high-pass, band-pass, or band-stop\nfilter to the channels selected by ``picks``.\nThe data are modified inplace.\n\nThe object has to have the data loaded e.g. with ``preload=True``\nor ``self.load_data()``.\n\n``l_freq`` and ``h_freq`` are the frequencies below which and above\nwhich, respectively, to filter out of the data. Thus the uses are:\n\n    * ``l_freq < h_freq``: band-pass filter\n    * ``l_freq > h_freq``: band-stop filter\n    * ``l_freq is not None and h_freq is None``: high-pass filter\n    * ``l_freq is None and h_freq is not None``: low-pass filter\n\n``self.info['lowpass']`` and ``self.info['highpass']`` are only\nupdated with picks=None.\n\n.. note:: If n_jobs > 1, more memory is required as\n          ``len(picks) * n_times`` additional time points need to\n          be temporarily stored in memory.\n\nWhen working on SourceEstimates the sample rate of the original\ndata is inferred from tstep.\n\nFor more information, see the tutorials\n:ref:`disc-filtering` and :ref:`tut-filter-resample` and\n:func:`mne.filter.create_filter`.\n\n.. versionadded:: 0.15", "metadata": {}}
{"_id": "mne_mne_filter.py_resample_doc", "text": "Resample data.\n\nIf appropriate, an anti-aliasing filter is applied before resampling.\nSee :ref:`resampling-and-decimating` for more information.\n\n.. note:: Data must be loaded.\n\nParameters\n----------\nsfreq : float\n    New sample rate to use.\n%(npad)s\n%(window_resample)s\n%(n_jobs_cuda)s\n%(pad_resample)s\n\n    .. versionadded:: 0.15\n%(method_resample)s\n\n    .. versionadded:: 1.7\n%(verbose)s\n\nReturns\n-------\ninst : instance of Epochs or Evoked\n    The resampled object.\n\nSee Also\n--------\nmne.io.Raw.resample\n\nNotes\n-----\nFor some data, it may be more accurate to use npad=0 to reduce\nartifacts. This is dataset dependent -- check your data!", "metadata": {}}
{"_id": "mne_mne_filter.py_apply_hilbert_doc", "text": "Compute analytic signal or envelope for a subset of channels/vertices.\n\nParameters\n----------\n%(picks_all_data_noref)s\nenvelope : bool\n    Compute the envelope signal of each channel/vertex. Default False.\n    See Notes.\n%(n_jobs)s\nn_fft : int | None | str\n    Points to use in the FFT for Hilbert transformation. The signal\n    will be padded with zeros before computing Hilbert, then cut back\n    to original length. If None, n == self.n_times. If 'auto',\n    the next highest fast FFT length will be use.\n%(verbose)s\n\nReturns\n-------\nself : instance of Raw, Epochs, Evoked or SourceEstimate\n    The raw object with transformed data.\n\nNotes\n-----\n**Parameters**\n\nIf ``envelope=False``, the analytic signal for the channels/vertices defined in\n``picks`` is computed and the data of the Raw object is converted to\na complex representation (the analytic signal is complex valued).\n\nIf ``envelope=True``, the absolute value of the analytic signal for the\nchannels/vertices defined in ``picks`` is computed, resulting in the envelope\nsignal.\n\n.. warning: Do not use ``envelope=True`` if you intend to compute\n            an inverse solution from the raw data. If you want to\n            compute the envelope in source space, use\n            ``envelope=False`` and compute the envelope after the\n            inverse solution has been obtained.\n\nIf envelope=False, more memory is required since the original raw data\nas well as the analytic signal have temporarily to be stored in memory.\nIf n_jobs > 1, more memory is required as ``len(picks) * n_times``\nadditional time points need to be temporarily stored in memory.\n\nAlso note that the ``n_fft`` parameter will allow you to pad the signal\nwith zeros before performing the Hilbert transform. This padding\nis cut off, but it may result in a slightly different result\n(particularly around the edges). Use at your own risk.\n\n**Analytic signal**\n\nThe analytic signal \"x_a(t)\" of \"x(t)\" is::\n\n    x_a = F^{-1}(F(x) 2U) = x + i y\n\nwhere \"F\" is the Fourier transform, \"U\" the unit step function,\nand \"y\" the Hilbert transform of \"x\". One usage of the analytic\nsignal is the computation of the envelope signal, which is given by\n\"e(t) = abs(x_a(t))\". Due to the linearity of Hilbert transform and the\nMNE inverse solution, the enevlope in source space can be obtained\nby computing the analytic signal in sensor space, applying the MNE\ninverse, and computing the envelope in source space.", "metadata": {}}
{"_id": "mne_mne_bem.py_make_bem_solution_doc", "text": "Create a BEM solution using the linear collocation approach.\n\nParameters\n----------\nsurfs : list of dict\n    The BEM surfaces to use (from :func:`mne.make_bem_model`).\nsolver : str\n    Can be ``'mne'`` (default) to use MNE-Python, or ``'openmeeg'`` to use the\n    `OpenMEEG <https://openmeeg.github.io>`__ package.\n\n    .. versionadded:: 1.2\n%(verbose)s\n\nReturns\n-------\nbem : instance of ConductorModel\n    The BEM solution.\n\nSee Also\n--------\nmake_bem_model\nread_bem_surfaces\nwrite_bem_surfaces\nread_bem_solution\nwrite_bem_solution\n\nNotes\n-----\n.. versionadded:: 0.10.0", "metadata": {}}
{"_id": "mne_mne_bem.py_make_bem_model_doc", "text": "Create a BEM model for a subject.\n\nUse :func:`~mne.make_bem_solution` to turn the returned surfaces into a\n:class:`~mne.bem.ConductorModel` suitable for forward calculation.\n\n.. note:: To get a single layer bem corresponding to the --homog flag in\n          the command line tool set the ``conductivity`` parameter\n          to a float (e.g. ``0.3``).\n\nParameters\n----------\n%(subject)s\nico : int | None\n    The surface ico downsampling to use, e.g. ``5=20484``, ``4=5120``,\n    ``3=1280``. If None, no subsampling is applied.\nconductivity : float | array of float of shape (3,) or (1,)\n    The conductivities to use for each shell. Should be a single element\n    for a one-layer model, or three elements for a three-layer model.\n    Defaults to ``[0.3, 0.006, 0.3]``. The MNE-C default for a\n    single-layer model is ``[0.3]``.\n%(subjects_dir)s\n%(verbose)s\n\nReturns\n-------\nsurfaces : list of dict\n    The BEM surfaces. Use :func:`~mne.make_bem_solution` to turn these into a\n    :class:`~mne.bem.ConductorModel` suitable for forward calculation.\n\nSee Also\n--------\nmake_bem_solution\nmake_sphere_model\nread_bem_surfaces\nwrite_bem_surfaces\n\nNotes\n-----\n.. versionadded:: 0.10.0", "metadata": {}}
{"_id": "mne_mne_bem.py_make_sphere_model_doc", "text": "Create a spherical model for forward solution calculation.\n\nParameters\n----------\nr0 : array-like | str\n    Head center to use (in head coordinates). If 'auto', the head\n    center will be calculated from the digitization points in info.\nhead_radius : float | str | None\n    If float, compute spherical shells for EEG using the given radius.\n    If ``'auto'``, estimate an appropriate radius from the dig points in the\n    :class:`~mne.Info` provided by the argument ``info``.\n    If None, exclude shells (single layer sphere model).\n%(info)s Only needed if ``r0`` or ``head_radius`` are ``'auto'``.\nrelative_radii : array-like\n    Relative radii for the spherical shells.\nsigmas : array-like\n    Sigma values for the spherical shells.\n%(verbose)s\n\nReturns\n-------\nsphere : instance of ConductorModel\n    The resulting spherical conductor model.\n\nSee Also\n--------\nmake_bem_model\nmake_bem_solution\n\nNotes\n-----\nThe default model has::\n\n    relative_radii = (0.90, 0.92, 0.97, 1.0)\n    sigmas = (0.33, 1.0, 0.004, 0.33)\n\nThese correspond to compartments (with relative radii in ``m`` and\nconductivities \u03c3 in ``S/m``) for the brain, CSF, skull, and scalp,\nrespectively.\n\n.. versionadded:: 0.9.0", "metadata": {}}
{"_id": "mne_mne_bem.py_fit_sphere_to_headshape_doc", "text": "Fit a sphere to the headshape points to determine head center.\n\nParameters\n----------\n%(info_not_none)s\n%(dig_kinds)s\nunits : str\n    Can be ``\"m\"`` (default) or ``\"mm\"``.\n\n    .. versionadded:: 0.12\n%(verbose)s\n\nReturns\n-------\nradius : float\n    Sphere radius.\norigin_head: ndarray, shape (3,)\n    Head center in head coordinates.\norigin_device: ndarray, shape (3,)\n    Head center in device coordinates.\n\nNotes\n-----\nThis function excludes any points that are low and frontal\n(``z < 0 and y > 0``) to improve the fit.", "metadata": {}}
{"_id": "mne_mne_bem.py_get_fitting_dig_doc", "text": "Get digitization points suitable for sphere fitting.\n\nParameters\n----------\n%(info_not_none)s\n%(dig_kinds)s\n%(exclude_frontal)s\n    Default is True.\n\n    .. versionadded:: 0.19\n%(verbose)s\n\nReturns\n-------\ndig : array, shape (n_pts, 3)\n    The digitization points (in head coordinates) to use for fitting.\n\nNotes\n-----\nThis will exclude digitization locations that have ``z < 0 and y > 0``,\ni.e. points on the nose and below the nose on the face.\n\n.. versionadded:: 0.14", "metadata": {}}
{"_id": "mne_mne_bem.py_make_watershed_bem_doc", "text": "Create BEM surfaces using the FreeSurfer watershed algorithm.\n\nSee :ref:`bem_watershed_algorithm` for additional information.\n\nParameters\n----------\nsubject : str\n    Subject name.\n%(subjects_dir)s\n%(overwrite)s\nvolume : str\n    Defaults to T1.\natlas : bool\n    Specify the ``--atlas option`` for ``mri_watershed``.\ngcaatlas : bool\n    Specify the ``--brain_atlas`` option for ``mri_watershed``.\npreflood : int\n    Change the preflood height.\nshow : bool\n    Show surfaces to visually inspect all three BEM surfaces (recommended).\n\n    .. versionadded:: 0.12\n\ncopy : bool\n    If True (default), use copies instead of symlinks for surfaces\n    (if they do not already exist).\n\n    .. versionadded:: 0.18\n    .. versionchanged:: 1.1 Use copies instead of symlinks.\nT1 : bool | None\n    If True, pass the ``-T1`` flag.\n    By default (None), this takes the same value as ``gcaatlas``.\n\n    .. versionadded:: 0.19\nbrainmask : str\n    The filename for the brainmask output file relative to the\n    ``$SUBJECTS_DIR/$SUBJECT/bem/watershed/`` directory.\n    Can be for example ``\"../../mri/brainmask.mgz\"`` to overwrite\n    the brainmask obtained via ``recon-all -autorecon1``.\n\n    .. versionadded:: 0.19\n%(verbose)s\n\nSee Also\n--------\nmne.viz.plot_bem\n\nNotes\n-----\nIf your BEM meshes do not look correct when viewed in\n:func:`mne.viz.plot_alignment` or :func:`mne.viz.plot_bem`, consider\npotential solutions from the :ref:`FAQ <faq_watershed_bem_meshes>`.\n\n.. versionadded:: 0.10", "metadata": {}}
{"_id": "mne_mne_bem.py_read_bem_surfaces_doc", "text": "Read the BEM surfaces from a FIF file.\n\nParameters\n----------\nfname : path-like\n    The name of the file containing the surfaces.\npatch_stats : bool, optional (default False)\n    Calculate and add cortical patch statistics to the surfaces.\ns_id : int | None\n    If int, only read and return the surface with the given ``s_id``.\n    An error will be raised if it doesn't exist. If None, all\n    surfaces are read and returned.\n%(on_defects)s\n\n    .. versionadded:: 0.23\n%(verbose)s\n\nReturns\n-------\nsurf: list | dict\n    A list of dictionaries that each contain a surface. If ``s_id``\n    is not None, only the requested surface will be returned.\n\nSee Also\n--------\nwrite_bem_surfaces, write_bem_solution, make_bem_model", "metadata": {}}
{"_id": "mne_mne_bem.py_read_bem_solution_doc", "text": "Read the BEM solution from a file.\n\nParameters\n----------\nfname : path-like\n    The file containing the BEM solution.\n%(verbose)s\n\nReturns\n-------\nbem : instance of ConductorModel\n    The BEM solution.\n\nSee Also\n--------\nread_bem_surfaces\nwrite_bem_surfaces\nmake_bem_solution\nwrite_bem_solution", "metadata": {}}
{"_id": "mne_mne_bem.py_write_bem_surfaces_doc", "text": "Write BEM surfaces to a FIF file.\n\nParameters\n----------\nfname : path-like\n    Filename to write. Can end with ``.h5`` to write using HDF5.\nsurfs : dict | list of dict\n    The surfaces, or a single surface.\n%(overwrite)s\n%(verbose)s", "metadata": {}}
{"_id": "mne_mne_bem.py_write_head_bem_doc", "text": "Write a head surface to a FIF file.\n\nParameters\n----------\nfname : path-like\n    Filename to write.\nrr : array, shape (n_vertices, 3)\n    Coordinate points in the MRI coordinate system.\ntris : ndarray of int, shape (n_tris, 3)\n    Triangulation (each line contains indices for three points which\n    together form a face).\n%(on_defects)s\n%(overwrite)s\n%(verbose)s", "metadata": {}}
{"_id": "mne_mne_bem.py_write_bem_solution_doc", "text": "Write a BEM model with solution.\n\nParameters\n----------\nfname : path-like\n    The filename to use. Can end with ``.h5`` to write using HDF5.\nbem : instance of ConductorModel\n    The BEM model with solution to save.\n%(overwrite)s\n%(verbose)s\n\nSee Also\n--------\nread_bem_solution", "metadata": {}}
{"_id": "mne_mne_bem.py_convert_flash_mris_doc", "text": "Synthesize the flash 5 files for use with make_flash_bem.\n\nThis function aims to produce a synthesized flash 5 MRI from\nmultiecho flash (MEF) MRI data. This function can use MEF data\nwith 5 or 30 flip angles. If flash5 (and flash30) images are not\nexplicitly provided, it will assume that the different echos are available\nin the mri/flash folder of the subject with the following naming\nconvention \"mef<angle>_<echo>.mgz\", e.g. \"mef05_001.mgz\"\nor \"mef30_001.mgz\".\n\nParameters\n----------\n%(subject)s\nflash30 : bool | list of SpatialImage or path-like | SpatialImage | path-like\n    If False do not use 30-degree flip angle data.\n    The list of flash 5 echos to use. If True it will look for files\n    named mef30_*.mgz in the subject's mri/flash directory and if not False\n    the list of flash 5 echos images will be written to the mri/flash\n    folder with convention mef05_<echo>.mgz. If a SpatialImage object\n    each frame of the image will be interpreted as an echo.\nunwarp : bool\n    Run grad_unwarp with -unwarp option on each of the converted\n    data sets. It requires FreeSurfer's MATLAB toolbox to be properly\n    installed.\n%(subjects_dir)s\nflash5 : list of SpatialImage or path-like | SpatialImage | path-like | True\n    The list of flash 5 echos to use. If True it will look for files\n    named mef05_*.mgz in the subject's mri/flash directory and if not None\n    the list of flash 5 echos images will be written to the mri/flash\n    folder with convention mef05_<echo>.mgz. If a SpatialImage object\n    each frame of the image will be interpreted as an echo.\n%(verbose)s\n\nReturns\n-------\nflash5_img : path-like\n    The path the synthesized flash 5 MRI.\n\nNotes\n-----\nThis function assumes that the Freesurfer segmentation of the subject\nhas been completed. In particular, the T1.mgz and brain.mgz MRI volumes\nshould be, as usual, in the subject's mri directory.", "metadata": {}}
{"_id": "mne_mne_bem.py_make_flash_bem_doc", "text": "Create 3-Layer BEM model from prepared flash MRI images.\n\nSee :ref:`bem_flash_algorithm` for additional information.\n\nParameters\n----------\n%(subject)s\noverwrite : bool\n    Write over existing .surf files in bem folder.\nshow : bool\n    Show surfaces to visually inspect all three BEM surfaces (recommended).\n%(subjects_dir)s\ncopy : bool\n    If True (default), use copies instead of symlinks for surfaces\n    (if they do not already exist).\n\n    .. versionadded:: 0.18\n    .. versionchanged:: 1.1 Use copies instead of symlinks.\nflash5_img : None | path-like | Nifti1Image\n    The path to the synthesized flash 5 MRI image or the image itself. If\n    None (default), the path defaults to\n    ``mri/flash/parameter_maps/flash5.mgz`` within the subject\n    reconstruction. If not present the image is copied or written to the\n    default location.\n\n    .. versionadded:: 1.1.0\nregister : bool\n    Register the flash 5 image with T1.mgz file. If False, we assume\n    that the images are already coregistered.\n\n    .. versionadded:: 1.1.0\n%(verbose)s\n\nSee Also\n--------\nconvert_flash_mris\n\nNotes\n-----\nThis program assumes that FreeSurfer is installed and sourced properly.\n\nThis function extracts the BEM surfaces (outer skull, inner skull, and\nouter skin) from a FLASH 5 MRI image synthesized from multiecho FLASH\nimages acquired with spin angles of 5 and 30 degrees.", "metadata": {}}
{"_id": "mne_mne_bem.py_make_scalp_surfaces_doc", "text": "Create surfaces of the scalp and neck.\n\nThe scalp surfaces are required for using the MNE coregistration GUI, and\nallow for a visualization of the alignment between anatomy and channel\nlocations.\n\nParameters\n----------\n%(subject)s\n%(subjects_dir)s\nforce : bool\n    Force creation of the surface even if it has some topological defects.\n    Defaults to ``True``. See :ref:`tut-fix-meshes` for ideas on how to\n    fix problematic meshes.\n%(overwrite)s\nno_decimate : bool\n    Disable the \"medium\" and \"sparse\" decimations. In this case, only\n    a \"dense\" surface will be generated. Defaults to ``False``, i.e.,\n    create surfaces for all three types of decimations.\nthreshold : int\n    The threshold to use with the MRI in the call to ``mkheadsurf``.\n    The default is ``20``.\n\n    .. versionadded:: 1.1\nmri : str\n    The MRI to use. Should exist in ``$SUBJECTS_DIR/$SUBJECT/mri``.\n\n    .. versionadded:: 1.1\n%(verbose)s", "metadata": {}}
{"_id": "mne_mne_bem.py_distance_to_bem_doc", "text": "Calculate the distance of positions to inner skull surface.\n\nParameters\n----------\npos : array, shape (..., 3)\n    Position(s) in m, in head coordinates.\nbem : instance of ConductorModel\n    Conductor model.\n%(trans)s If None (default), assumes bem is in head coordinates.\n\n    .. versionchanged:: 0.19\n        Support for 'fsaverage' argument.\n%(verbose)s\n\nReturns\n-------\ndistances : float | array, shape (...)\n    The computed distance(s). A float is returned if pos is\n    an array of shape (3,) corresponding to a single position.\n\nNotes\n-----\n.. versionadded:: 1.1", "metadata": {}}
{"_id": "mne_mne_bem.py_copy_doc", "text": "Return copy of ConductorModel instance.", "metadata": {}}
{"_id": "mne_mne_bem.py_radius_doc", "text": "Sphere radius if an EEG sphere model.", "metadata": {}}
{"_id": "mne_mne_coreg.py_coregister_fiducials_doc", "text": "Create a head-MRI transform by aligning 3 fiducial points.\n\nParameters\n----------\n%(info_not_none)s\nfiducials : path-like | list of dict\n    Fiducials in MRI coordinate space (either path to a ``*-fiducials.fif``\n    file or list of fiducials as returned by :func:`read_fiducials`.\n\nReturns\n-------\ntrans : Transform\n    The device-MRI transform.\n\n.. note:: The :class:`mne.Info` object fiducials must be in the\n          head coordinate space.", "metadata": {}}
{"_id": "mne_mne_coreg.py_create_default_subject_doc", "text": "Create an average brain subject for subjects without structural MRI.\n\nCreate a copy of fsaverage from the FreeSurfer directory in subjects_dir\nand add auxiliary files from the mne package.\n\nParameters\n----------\nfs_home : None | str\n    The FreeSurfer home directory (only needed if ``FREESURFER_HOME`` is\n    not specified as environment variable).\nupdate : bool\n    In cases where a copy of the fsaverage brain already exists in the\n    subjects_dir, this option allows to only copy files that don't already\n    exist in the fsaverage directory.\nsubjects_dir : None | path-like\n    Override the ``SUBJECTS_DIR`` environment variable\n    (``os.environ['SUBJECTS_DIR']``) as destination for the new subject.\n%(verbose)s\n\nNotes\n-----\nWhen no structural MRI is available for a subject, an average brain can be\nsubstituted. FreeSurfer comes with such an average brain model, and MNE\ncomes with some auxiliary files which make coregistration easier.\n:py:func:`create_default_subject` copies the relevant\nfiles from FreeSurfer into the current subjects_dir, and also adds the\nauxiliary files provided by MNE.", "metadata": {}}
{"_id": "mne_mne_coreg.py_fit_matched_points_doc", "text": "Find a transform between matched sets of points.\n\nThis minimizes the squared distance between two matching sets of points.\n\nUses :func:`scipy.optimize.leastsq` to find a transformation involving\na combination of rotation, translation, and scaling (in that order).\n\nParameters\n----------\nsrc_pts : array, shape = (n, 3)\n    Points to which the transform should be applied.\ntgt_pts : array, shape = (n, 3)\n    Points to which src_pts should be fitted. Each point in tgt_pts should\n    correspond to the point in src_pts with the same index.\nrotate : bool\n    Allow rotation of the ``src_pts``.\ntranslate : bool\n    Allow translation of the ``src_pts``.\nscale : bool\n    Number of scaling parameters. With False, points are not scaled. With\n    True, points are scaled by the same factor along all axes.\ntol : scalar | None\n    The error tolerance. If the distance between any of the matched points\n    exceeds this value in the solution, a RuntimeError is raised. With\n    None, no error check is performed.\nx0 : None | tuple\n    Initial values for the fit parameters.\nout : 'params' | 'trans'\n    In what format to return the estimate: 'params' returns a tuple with\n    the fit parameters; 'trans' returns a transformation matrix of shape\n    (4, 4).\n\nReturns\n-------\ntrans : array, shape (4, 4)\n    Transformation that, if applied to src_pts, minimizes the squared\n    distance to tgt_pts. Only returned if out=='trans'.\nparams : array, shape (n_params, )\n    A single tuple containing the rotation, translation, and scaling\n    parameters in that order (as applicable).", "metadata": {}}
{"_id": "mne_mne_coreg.py_read_mri_cfg_doc", "text": "Read information from the cfg file of a scaled MRI brain.\n\nParameters\n----------\nsubject : str\n    Name of the scaled MRI subject.\nsubjects_dir : None | path-like\n    Override the ``SUBJECTS_DIR`` environment variable.\n\nReturns\n-------\ncfg : dict\n    Dictionary with entries from the MRI's cfg file.", "metadata": {}}
{"_id": "mne_mne_coreg.py_scale_bem_doc", "text": "Scale a bem file.\n\nParameters\n----------\nsubject_to : str\n    Name of the scaled MRI subject (the destination mri subject).\nbem_name : str\n    Name of the bem file. For example, to scale\n    ``fsaverage-inner_skull-bem.fif``, the bem_name would be\n    \"inner_skull-bem\".\nsubject_from : None | str\n    The subject from which to read the source space. If None, subject_from\n    is read from subject_to's config file.\nscale : None | float | array, shape = (3,)\n    Scaling factor. Has to be specified if subjects_from is specified,\n    otherwise it is read from subject_to's config file.\nsubjects_dir : None | str\n    Override the SUBJECTS_DIR environment variable.\n%(on_defects)s\n\n    .. versionadded:: 1.0\n%(verbose)s", "metadata": {}}
{"_id": "mne_mne_coreg.py_scale_labels_doc", "text": "Scale labels to match a brain that was previously created by scaling.\n\nParameters\n----------\nsubject_to : str\n    Name of the scaled MRI subject (the destination brain).\npattern : str | None\n    Pattern for finding the labels relative to the label directory in the\n    MRI subject directory (e.g., \"lh.BA3a.label\" will scale\n    \"fsaverage/label/lh.BA3a.label\"; \"aparc/\\*.label\" will find all labels\n    in the \"fsaverage/label/aparc\" directory). With None, scale all labels.\noverwrite : bool\n    Overwrite any label file that already exists for subject_to (otherwise\n    existing labels are skipped).\nsubject_from : None | str\n    Name of the original MRI subject (the brain that was scaled to create\n    subject_to). If None, the value is read from subject_to's cfg file.\nscale : None | float | array_like, shape = (3,)\n    Scaling parameter. If None, the value is read from subject_to's cfg\n    file.\nsubjects_dir : None | path-like\n    Override the ``SUBJECTS_DIR`` environment variable.", "metadata": {}}
{"_id": "mne_mne_coreg.py_scale_mri_doc", "text": "Create a scaled copy of an MRI subject.\n\nParameters\n----------\nsubject_from : str\n    Name of the subject providing the MRI.\nsubject_to : str\n    New subject name for which to save the scaled MRI.\nscale : float | array_like, shape = (3,)\n    The scaling factor (one or 3 parameters).\noverwrite : bool\n    If an MRI already exists for subject_to, overwrite it.\nsubjects_dir : None | path-like\n    Override the ``SUBJECTS_DIR`` environment variable.\nskip_fiducials : bool\n    Do not scale the MRI fiducials. If False (default), an OSError will be\n    raised if no fiducials file can be found.\nlabels : bool\n    Also scale all labels (default True).\nannot : bool\n    Copy ``*.annot`` files to the new location (default False).\n%(on_defects)s\n\n    .. versionadded:: 1.0\n%(verbose)s\n\nSee Also\n--------\nscale_bem : Add a scaled BEM to a scaled MRI.\nscale_labels : Add labels to a scaled MRI.\nscale_source_space : Add a source space to a scaled MRI.\n\nNotes\n-----\nThis function will automatically call :func:`scale_bem`,\n:func:`scale_labels`, and :func:`scale_source_space` based on expected\nfilename patterns in the subject directory.", "metadata": {}}
{"_id": "mne_mne_coreg.py_scale_source_space_doc", "text": "Scale a source space for an mri created with scale_mri().\n\nParameters\n----------\nsubject_to : str\n    Name of the scaled MRI subject (the destination mri subject).\nsrc_name : str\n    Source space name. Can be a spacing parameter (e.g., ``'7'``,\n    ``'ico4'``, ``'oct6'``) or a file name of a source space file relative\n    to the bem directory; if the file name contains the subject name, it\n    should be indicated as \"{subject}\" in ``src_name`` (e.g.,\n    ``\"{subject}-my_source_space-src.fif\"``).\nsubject_from : None | str\n    The subject from which to read the source space. If None, subject_from\n    is read from subject_to's config file.\nscale : None | float | array, shape = (3,)\n    Scaling factor. Has to be specified if subjects_from is specified,\n    otherwise it is read from subject_to's config file.\nsubjects_dir : None | str\n    Override the SUBJECTS_DIR environment variable.\nn_jobs : int\n    Number of jobs to run in parallel if recomputing distances (only\n    applies if scale is an array of length 3, and will not use more cores\n    than there are source spaces).\n%(verbose)s\n\nNotes\n-----\nWhen scaling volume source spaces, the source (vertex) locations are\nscaled, but the reference to the MRI volume is left unchanged. Transforms\nare updated so that source estimates can be plotted on the original MRI\nvolume.", "metadata": {}}
{"_id": "mne_mne_coreg.py_set_scale_mode_doc", "text": "Select how to fit the scale parameters.\n\nParameters\n----------\nscale_mode : None | str\n    The scale mode can be 'uniform', '3-axis' or disabled.\n    Defaults to None.\n\n    * 'uniform': 1 scale factor is recovered.\n    * '3-axis': 3 scale factors are recovered.\n    * None: do not scale the MRI.\n\nReturns\n-------\nself : Coregistration\n    The modified Coregistration object.", "metadata": {}}
{"_id": "mne_mne_coreg.py_set_grow_hair_doc", "text": "Compensate for hair on the digitizer head shape.\n\nParameters\n----------\nvalue : float\n    Move the back of the MRI head outwards by ``value`` (mm).\n\nReturns\n-------\nself : Coregistration\n    The modified Coregistration object.", "metadata": {}}
{"_id": "mne_mne_coreg.py_set_rotation_doc", "text": "Set the rotation parameter.\n\nParameters\n----------\nrot : array, shape (3,)\n    The rotation parameter (in radians).\n\nReturns\n-------\nself : Coregistration\n    The modified Coregistration object.", "metadata": {}}
{"_id": "mne_mne_coreg.py_set_translation_doc", "text": "Set the translation parameter.\n\nParameters\n----------\ntra : array, shape (3,)\n    The translation parameter (in m.).\n\nReturns\n-------\nself : Coregistration\n    The modified Coregistration object.", "metadata": {}}
{"_id": "mne_mne_coreg.py_set_scale_doc", "text": "Set the scale parameter.\n\nParameters\n----------\nsca : array, shape (3,)\n    The scale parameter.\n\nReturns\n-------\nself : Coregistration\n    The modified Coregistration object.", "metadata": {}}
{"_id": "mne_mne_coreg.py_scale_doc", "text": "Get the current scale factor.\n\nReturns\n-------\nscale : ndarray, shape (3,)\n    The scale factors.", "metadata": {}}
{"_id": "mne_mne_coreg.py_fit_fiducials_doc", "text": "Find rotation and translation to fit all 3 fiducials.\n\nParameters\n----------\nlpa_weight : float\n    Relative weight for LPA. The default value is 1.\nnasion_weight : float\n    Relative weight for nasion. The default value is 10.\nrpa_weight : float\n    Relative weight for RPA. The default value is 1.\n%(verbose)s\n\nReturns\n-------\nself : Coregistration\n    The modified Coregistration object.", "metadata": {}}
{"_id": "mne_mne_coreg.py_set_fid_match_doc", "text": "Set the strategy for fitting anatomical landmark (fiducial) points.\n\nParameters\n----------\nmatch : 'nearest' | 'matched'\n    Alignment strategy; ``'nearest'`` aligns anatomical landmarks to\n    any point on the head surface; ``'matched'`` aligns to the fiducial\n    points in the MRI.\n\nReturns\n-------\nself : Coregistration\n    The modified Coregistration object.", "metadata": {}}
{"_id": "mne_mne_coreg.py_fit_icp_doc", "text": "Find MRI scaling, translation, and rotation to match HSP.\n\nParameters\n----------\nn_iterations : int\n    Maximum number of iterations.\nlpa_weight : float\n    Relative weight for LPA. The default value is 1.\nnasion_weight : float\n    Relative weight for nasion. The default value is 10.\nrpa_weight : float\n    Relative weight for RPA. The default value is 1.\nhsp_weight : float\n    Relative weight for HSP. The default value is 1.\neeg_weight : float\n    Relative weight for EEG. The default value is 1.\nhpi_weight : float\n    Relative weight for HPI. The default value is 1.\ncallback : callable | None\n    A function to call on each iteration. Useful for status message\n    updates. It will be passed the keyword arguments ``iteration``\n    and ``n_iterations``.\n%(verbose)s\n\nReturns\n-------\nself : Coregistration\n    The modified Coregistration object.", "metadata": {}}
{"_id": "mne_mne_coreg.py_omit_head_shape_points_doc", "text": "Exclude head shape points that are far away from the MRI head.\n\nParameters\n----------\ndistance : float\n    Exclude all points that are further away from the MRI head than\n    this distance (in m.). A value of distance <= 0 excludes nothing.\n\nReturns\n-------\nself : Coregistration\n    The modified Coregistration object.", "metadata": {}}
{"_id": "mne_mne_coreg.py_compute_dig_mri_distances_doc", "text": "Compute distance between head shape points and MRI skin surface.\n\nReturns\n-------\ndist : array, shape (n_points,)\n    The distance of the head shape points to the MRI skin surface.\n\nSee Also\n--------\nmne.dig_mri_distances", "metadata": {}}
{"_id": "mne_mne_coreg.py_trans_doc", "text": "The head->mri :class:`~mne.transforms.Transform`.", "metadata": {}}
{"_id": "mne_mne_coreg.py_reset_doc", "text": "Reset all the parameters affecting the coregistration.\n\nReturns\n-------\nself : Coregistration\n    The modified Coregistration object.", "metadata": {}}
{"_id": "mne_mne__ola.py_feed_generator_doc", "text": "Feed data and get interpolators as a generator.", "metadata": {}}
{"_id": "mne_mne__ola.py_feed_doc", "text": "Feed data and get interpolated values.", "metadata": {}}
{"_id": "mne_mne__ola.py_feed_doc", "text": "Pass in a chunk of data.", "metadata": {}}
{"_id": "mne_mne_dipole.py_read_dipole_doc", "text": "Read a dipole object from a file.\n\nNon-fixed-position :class:`mne.Dipole` objects are usually saved in ``.[b]dip``\nformat. Fixed-position :class:`mne.DipoleFixed` objects are usually saved in\nFIF format.\n\nParameters\n----------\nfname : path-like\n    The name of the ``.[b]dip`` or ``.fif[.gz]`` file.\n%(verbose)s\n\nReturns\n-------\n%(dipole)s\n\nSee Also\n--------\nDipole\nDipoleFixed\nfit_dipole\n\nNotes\n-----\n.. versionchanged:: 0.20\n   Support for reading bdip (Xfit binary) format.", "metadata": {}}
{"_id": "mne_mne_dipole.py_fit_dipole_doc", "text": "Fit a dipole.\n\nParameters\n----------\nevoked : instance of Evoked\n    The dataset to fit.\ncov : str | instance of Covariance\n    The noise covariance.\nbem : path-like | instance of ConductorModel\n    The BEM filename (str) or conductor model.\ntrans : path-like | None\n    The head<->MRI transform filename. Must be provided unless BEM\n    is a sphere model.\nmin_dist : float\n    Minimum distance (in millimeters) from the dipole to the inner skull.\n    Must be positive. Note that because this is a constraint passed to\n    a solver it is not strict but close, i.e. for a ``min_dist=5.`` the\n    fits could be 4.9 mm from the inner skull.\n%(n_jobs)s\n    It is used in field computation and fitting.\npos : ndarray, shape (3,) | None\n    Position of the dipole to use. If None (default), sequential\n    fitting (different position and orientation for each time instance)\n    is performed. If a position (in head coords) is given as an array,\n    the position is fixed during fitting.\n\n    .. versionadded:: 0.12\nori : ndarray, shape (3,) | None\n    Orientation of the dipole to use. If None (default), the\n    orientation is free to change as a function of time. If an\n    orientation (in head coordinates) is given as an array, ``pos``\n    must also be provided, and the routine computes the amplitude and\n    goodness of fit of the dipole at the given position and orientation\n    for each time instant.\n\n    .. versionadded:: 0.12\n%(rank_none)s\n\n    .. versionadded:: 0.20\naccuracy : str\n    Can be ``\"normal\"`` (default) or ``\"accurate\"``, which gives the most\n    accurate coil definition but is typically not necessary for real-world\n    data.\n\n    .. versionadded:: 0.24\ntol : float\n    Final accuracy of the optimization (see ``rhoend`` argument of\n    :func:`scipy.optimize.fmin_cobyla`).\n\n    .. versionadded:: 0.24\n%(verbose)s\n\nReturns\n-------\ndip : instance of Dipole or DipoleFixed\n    The dipole fits. A :class:`mne.DipoleFixed` is returned if\n    ``pos`` and ``ori`` are both not None, otherwise a\n    :class:`mne.Dipole` is returned.\nresidual : instance of Evoked\n    The M-EEG data channels with the fitted dipolar activity removed.\n\nSee Also\n--------\nmne.beamformer.rap_music\nDipole\nDipoleFixed\nread_dipole\n\nNotes\n-----\n.. versionadded:: 0.9.0", "metadata": {}}
{"_id": "mne_mne_dipole.py_get_phantom_dipoles_doc", "text": "Get standard phantom dipole locations and orientations.\n\nParameters\n----------\nkind : str\n    Get the information for the given system:\n\n        ``vectorview`` (default)\n          The Neuromag VectorView phantom.\n        ``otaniemi``\n          The older Neuromag phantom used at Otaniemi.\n        ``oyama``\n          The phantom from :footcite:`OyamaEtAl2015`.\n\n    .. versionchanged:: 1.6\n       Support added for ``'oyama'``.\n\nReturns\n-------\npos : ndarray, shape (n_dipoles, 3)\n    The dipole positions.\nori : ndarray, shape (n_dipoles, 3)\n    The dipole orientations.\n\nSee Also\n--------\nmne.datasets.fetch_phantom\n\nNotes\n-----\nThe Elekta phantoms have a radius of 79.5mm, and HPI coil locations\nin the XY-plane at the axis extrema (e.g., (79.5, 0), (0, -79.5), ...).\n\nReferences\n----------\n.. footbibliography::", "metadata": {}}
{"_id": "mne_mne_dipole.py_pos_doc", "text": "The dipoles positions (m) in head coordinates.", "metadata": {}}
{"_id": "mne_mne_dipole.py_amplitude_doc", "text": "The amplitude of the dipoles (Am).", "metadata": {}}
{"_id": "mne_mne_dipole.py_ori_doc", "text": "The dipole orientations (normalized to unit length).", "metadata": {}}
{"_id": "mne_mne_dipole.py_gof_doc", "text": "The goodness of fit.", "metadata": {}}
{"_id": "mne_mne_dipole.py_name_doc", "text": "Name of the dipole.", "metadata": {}}
{"_id": "mne_mne_dipole.py_conf_doc", "text": "Confidence limits in dipole orientation.", "metadata": {}}
{"_id": "mne_mne_dipole.py_khi2_doc", "text": "The \u03c7^2 values for the fits.", "metadata": {}}
{"_id": "mne_mne_dipole.py_nfree_doc", "text": "The number of free parameters for each fit.", "metadata": {}}
{"_id": "mne_mne_dipole.py_save_doc", "text": "Save dipole in a ``.dip`` or ``.bdip`` file.\n\nThe ``.[b]dip`` format is for :class:`mne.Dipole` objects, that is,\nfixed-position dipole fits. For these fits, the amplitude, orientation,\nand position vary as a function of time.\n\nParameters\n----------\nfname : path-like\n    The name of the ``.dip`` or ``.bdip`` file.\n%(overwrite)s\n\n    .. versionadded:: 0.20\n%(verbose)s\n\nSee Also\n--------\nread_dipole\n\nNotes\n-----\n.. versionchanged:: 0.20\n   Support for writing bdip (Xfit binary) files.", "metadata": {}}
{"_id": "mne_mne_dipole.py_crop_doc", "text": "Crop data to a given time interval.\n\nParameters\n----------\ntmin : float | None\n    Start time of selection in seconds.\ntmax : float | None\n    End time of selection in seconds.\n%(include_tmax)s\n%(verbose)s\n\nReturns\n-------\nself : instance of Dipole\n    The cropped instance.", "metadata": {}}
{"_id": "mne_mne_dipole.py_copy_doc", "text": "Copy the Dipoles object.\n\nReturns\n-------\ndip : instance of Dipole\n    The copied dipole instance.", "metadata": {}}
{"_id": "mne_mne_dipole.py_to_mni_doc", "text": "Convert dipole location from head to MNI coordinates.\n\nParameters\n----------\n%(subject)s\n%(trans_not_none)s\n%(subjects_dir)s\n%(verbose)s\n\nReturns\n-------\npos_mni : array, shape (n_pos, 3)\n    The MNI coordinates (in mm) of pos.", "metadata": {}}
{"_id": "mne_mne_dipole.py_to_mri_doc", "text": "Convert dipole location from head to MRI surface RAS coordinates.\n\nParameters\n----------\n%(subject)s\n%(trans_not_none)s\n%(subjects_dir)s\n%(verbose)s\n\nReturns\n-------\npos_mri : array, shape (n_pos, 3)\n    The Freesurfer surface RAS coordinates (in mm) of pos.", "metadata": {}}
{"_id": "mne_mne_dipole.py_to_volume_labels_doc", "text": "Find an ROI in atlas for the dipole positions.\n\nParameters\n----------\n%(trans)s\n\n    .. versionchanged:: 0.19\n        Support for 'fsaverage' argument.\n%(subject)s\n%(aseg)s\n%(subjects_dir)s\n%(verbose)s\n\nReturns\n-------\nlabels : list\n    List of anatomical region names from anatomical segmentation atlas.\n\nNotes\n-----\n.. versionadded:: 0.24", "metadata": {}}
{"_id": "mne_mne_dipole.py_plot_amplitudes_doc", "text": "Plot the dipole amplitudes as a function of time.\n\nParameters\n----------\ncolor : matplotlib color\n    Color to use for the trace.\nshow : bool\n    Show figure if True.\n\nReturns\n-------\nfig : matplotlib.figure.Figure\n    The figure object containing the plot.", "metadata": {}}
{"_id": "mne_mne_dipole.py_copy_doc", "text": "Copy the DipoleFixed object.\n\nReturns\n-------\ninst : instance of DipoleFixed\n    The copy.\n\nNotes\n-----\n.. versionadded:: 0.16", "metadata": {}}
{"_id": "mne_mne_dipole.py_ch_names_doc", "text": "Channel names.", "metadata": {}}
{"_id": "mne_mne_dipole.py_save_doc", "text": "Save fixed dipole in FIF format.\n\nThe ``.fif[.gz]`` format is for :class:`mne.DipoleFixed` objects, that is,\nfixed-position and optionally fixed-orientation dipole fits. For these fits,\nthe amplitude (and optionally orientation) vary as a function of time,\nbut not the position.\n\nParameters\n----------\nfname : path-like\n    The name of the FIF file. Must end with ``'-dip.fif'`` or\n    ``'-dip.fif.gz'`` to make it explicit that the file contains\n    dipole information in FIF format.\n%(overwrite)s\n\n    .. versionadded:: 1.10.0\n%(verbose)s\n\nSee Also\n--------\nread_dipole", "metadata": {}}
{"_id": "mne_mne_dipole.py_plot_doc", "text": "Plot dipole data.\n\nParameters\n----------\nshow : bool\n    Call pyplot.show() at the end or not.\ntime_unit : str\n    The units for the time axis, can be \"ms\" or \"s\" (default).\n\n    .. versionadded:: 0.16\n\nReturns\n-------\nfig : instance of matplotlib.figure.Figure\n    The figure containing the time courses.", "metadata": {}}
{"_id": "mne_mne_rank.py_estimate_rank_doc", "text": "Estimate the rank of data.\n\nThis function will normalize the rows of the data (typically\nchannels or vertices) such that non-zero singular values\nshould be close to one.\n\nParameters\n----------\ndata : array\n    Data to estimate the rank of (should be 2-dimensional).\n%(tol_rank)s\nreturn_singular : bool\n    If True, also return the singular values that were used\n    to determine the rank.\nnorm : bool\n    If True, data will be scaled by their estimated row-wise norm.\n    Else data are assumed to be scaled. Defaults to True.\n%(tol_kind_rank)s\n\nReturns\n-------\nrank : int\n    Estimated rank of the data.\ns : array\n    If return_singular is True, the singular values that were\n    thresholded to determine the rank are also returned.", "metadata": {}}
{"_id": "mne_mne_rank.py_compute_rank_doc", "text": "Compute the rank of data or noise covariance.\n\nThis function will normalize the rows of the data (typically\nchannels or vertices) such that non-zero singular values\nshould be close to one. It operates on :term:`data channels` only.\n\nParameters\n----------\ninst : instance of Raw, Epochs, or Covariance\n    Raw measurements to compute the rank from or the covariance.\n%(rank_none)s\nscalings : dict | None (default None)\n    Defaults to ``dict(mag=1e15, grad=1e13, eeg=1e6)``.\n    These defaults will scale different channel types\n    to comparable values.\n%(info)s Only necessary if ``inst`` is a :class:`mne.Covariance`\n    object (since this does not provide ``inst.info``).\n%(tol_rank)s\nproj : bool\n    If True, all projs in ``inst`` and ``info`` will be applied or\n    considered when ``rank=None`` or ``rank='info'``.\n%(tol_kind_rank)s\n%(on_rank_mismatch)s\n%(verbose)s\n\nReturns\n-------\nrank : dict\n    Estimated rank of the data for each channel type.\n    To get the total rank, you can use ``sum(rank.values())``.\n\nNotes\n-----\n.. versionadded:: 0.18", "metadata": {}}
{"_id": "mne_mne_io/_read_raw.py_split_name_ext_doc", "text": "Return name and supported file extension.", "metadata": {}}
{"_id": "mne_mne_io/_read_raw.py_read_raw_doc", "text": "Read raw file.\n\nThis function is a convenient wrapper for readers defined in `mne.io`. The\ncorrect reader is automatically selected based on the detected file format.\nAll function arguments are passed to the respective reader.\n\nThe following readers are currently supported:\n\n* `~mne.io.read_raw_ant`\n* `~mne.io.read_raw_artemis123`\n* `~mne.io.read_raw_bdf`\n* `~mne.io.read_raw_boxy`\n* `~mne.io.read_raw_brainvision`\n* `~mne.io.read_raw_cnt`\n* `~mne.io.read_raw_ctf`\n* `~mne.io.read_raw_curry`\n* `~mne.io.read_raw_edf`\n* `~mne.io.read_raw_eeglab`\n* `~mne.io.read_raw_egi`\n* `~mne.io.read_raw_eximia`\n* `~mne.io.read_raw_eyelink`\n* `~mne.io.read_raw_fieldtrip`\n* `~mne.io.read_raw_fif`\n* `~mne.io.read_raw_fil`\n* `~mne.io.read_raw_gdf`\n* `~mne.io.read_raw_kit`\n* `~mne.io.read_raw_nedf`\n* `~mne.io.read_raw_nicolet`\n* `~mne.io.read_raw_nihon`\n* `~mne.io.read_raw_nirx`\n* `~mne.io.read_raw_nsx`\n* `~mne.io.read_raw_persyst`\n* `~mne.io.read_raw_snirf`\n\nParameters\n----------\nfname : path-like\n    Name of the file to read.\n%(preload)s\n%(verbose)s\n**kwargs\n    Additional keyword arguments to pass to the underlying reader. For\n    details, see the arguments of the reader for the respective file\n    format.\n\nReturns\n-------\nraw : mne.io.Raw\n    Raw object.", "metadata": {}}
{"_id": "mne_mne_io/base.py_concatenate_raws_doc", "text": "Concatenate `~mne.io.Raw` instances as if they were continuous.\n\n.. note:: ``raws[0]`` is modified in-place to achieve the concatenation.\n          Boundaries of the raw files are annotated bad. If you wish to use\n          the data as continuous recording, you can remove the boundary\n          annotations after concatenation (see\n          :meth:`mne.Annotations.delete`).\n\nParameters\n----------\nraws : list\n    List of `~mne.io.Raw` instances to concatenate (in order).\n%(preload_concatenate)s\nevents_list : None | list\n    The events to concatenate. Defaults to ``None``.\n%(on_mismatch_info)s\n%(verbose)s\n\nReturns\n-------\nraw : instance of Raw\n    The result of the concatenation (first Raw instance passed in).\nevents : ndarray of int, shape (n_events, 3)\n    The events. Only returned if ``event_list`` is not None.", "metadata": {}}
{"_id": "mne_mne_io/base.py_match_channel_orders_doc", "text": "Ensure consistent channel order across instances (Raw, Epochs, or Evoked).\n\nParameters\n----------\ninsts : list\n    List of :class:`~mne.io.Raw`, :class:`~mne.Epochs`,\n    or :class:`~mne.Evoked` instances to order.\n%(copy_df)s\n\nReturns\n-------\nlist of Raw | list of Epochs | list of Evoked\n    List of instances (Raw, Epochs, or Evoked) with channel orders matched\n    according to the order they had in the first item in the ``insts`` list.", "metadata": {}}
{"_id": "mne_mne_io/base.py_apply_gradient_compensation_doc", "text": "Apply CTF gradient compensation.\n\n.. warning:: The compensation matrices are stored with single\n             precision, so repeatedly switching between different\n             of compensation (e.g., 0->1->3->2) can increase\n             numerical noise, especially if data are saved to\n             disk in between changing grades. It is thus best to\n             only use a single gradient compensation level in\n             final analyses.\n\nParameters\n----------\ngrade : int\n    CTF gradient compensation level.\n%(verbose)s\n\nReturns\n-------\nraw : instance of Raw\n    The modified Raw instance. Works in-place.", "metadata": {}}
{"_id": "mne_mne_io/base.py_load_data_doc", "text": "Load raw data.\n\nParameters\n----------\n%(verbose)s\n\nReturns\n-------\nraw : instance of Raw\n    The raw object with data.\n\nNotes\n-----\nThis function will load raw data if it was not already preloaded.\nIf data were already preloaded, it will do nothing.\n\n.. versionadded:: 0.10.0", "metadata": {}}
{"_id": "mne_mne_io/base.py_first_samp_doc", "text": "The first data sample.\n\nSee :term:`first_samp`.", "metadata": {}}
{"_id": "mne_mne_io/base.py_first_time_doc", "text": "The first time point (including first_samp but not meas_date).", "metadata": {}}
{"_id": "mne_mne_io/base.py_last_samp_doc", "text": "The last data sample.", "metadata": {}}
{"_id": "mne_mne_io/base.py_time_as_index_doc", "text": "Convert time to indices.\n\nParameters\n----------\ntimes : list-like | float | int\n    List of numbers or a number representing points in time.\nuse_rounding : bool\n    If True, use rounding (instead of truncation) when converting\n    times to indices. This can help avoid non-unique indices.\norigin : datetime | float | int | None\n    Time reference for times. If None, ``times`` are assumed to be\n    relative to :term:`first_samp`.\n\n    .. versionadded:: 0.17.0\n\nReturns\n-------\nindex : ndarray\n    Indices relative to :term:`first_samp` corresponding to the times\n    supplied.", "metadata": {}}
{"_id": "mne_mne_io/base.py_annotations_doc", "text": ":class:`~mne.Annotations` for marking segments of data.", "metadata": {}}
{"_id": "mne_mne_io/base.py_filenames_doc", "text": "The filenames used.\n\n:type: :class:`tuple` of :class:`pathlib.Path` | ``None``", "metadata": {}}
{"_id": "mne_mne_io/base.py_filenames_doc", "text": "The filenames used, cast to list of paths.", "metadata": {}}
{"_id": "mne_mne_io/base.py_set_annotations_doc", "text": "Setter for annotations.\n\nThis setter checks if they are inside the data range.\n\nParameters\n----------\nannotations : instance of mne.Annotations | None\n    Annotations to set. If None, the annotations is defined\n    but empty.\n%(emit_warning)s\n    The default is True.\n%(on_missing_ch_names)s\n%(verbose)s\n\nReturns\n-------\nself : instance of Raw\n    The raw object with annotations.", "metadata": {}}
{"_id": "mne_mne_io/base.py_get_data_doc", "text": "Get data in the given range.\n\nParameters\n----------\n%(picks_all)s\nstart : int\n    The first sample to include. Defaults to 0.\nstop : int | None\n    End sample (first not to include). If None (default), the end of\n    the data is  used.\nreject_by_annotation : None | 'omit' | 'NaN'\n    Whether to reject by annotation. If None (default), no rejection is\n    done. If 'omit', segments annotated with description starting with\n    'bad' are omitted. If 'NaN', the bad samples are filled with NaNs.\nreturn_times : bool\n    Whether to return times as well. Defaults to False.\n%(units)s\ntmin : int | float | None\n    Start time of data to get in seconds. The ``tmin`` parameter is\n    ignored if the ``start`` parameter is bigger than 0.\n\n    .. versionadded:: 0.24.0\ntmax : int | float | None\n    End time of data to get in seconds. The ``tmax`` parameter is\n    ignored if the ``stop`` parameter is defined.\n\n    .. versionadded:: 0.24.0\n%(verbose)s\n\nReturns\n-------\ndata : ndarray, shape (n_channels, n_times)\n    Copy of the data in the given range.\ntimes : ndarray, shape (n_times,)\n    Times associated with the data samples. Only returned if\n    return_times=True.\n\nNotes\n-----\n.. versionadded:: 0.14.0", "metadata": {}}
{"_id": "mne_mne_io/base.py_apply_function_doc", "text": "Apply a function to a subset of channels.\n\n%(applyfun_summary_raw)s\n\nParameters\n----------\n%(fun_applyfun)s\n%(picks_all_data_noref)s\n%(dtype_applyfun)s\n%(n_jobs)s Ignored if ``channel_wise=False`` as the workload\n    is split across channels.\n%(channel_wise_applyfun)s\n\n    .. versionadded:: 0.18\n%(verbose)s\n%(kwargs_fun)s\n\nReturns\n-------\nself : instance of Raw\n    The raw object with transformed data.", "metadata": {}}
{"_id": "mne_mne_io/base.py_notch_filter_doc", "text": "Notch filter a subset of channels.\n\nParameters\n----------\nfreqs : float | array of float | None\n    Specific frequencies to filter out from data, e.g.,\n    ``np.arange(60, 241, 60)`` in the US or ``np.arange(50, 251, 50)``\n    in Europe. ``None`` can only be used with the mode\n    ``'spectrum_fit'``, where an F test is used to find sinusoidal\n    components.\n%(picks_all_data)s\n%(filter_length_notch)s\nnotch_widths : float | array of float | None\n    Width of each stop band (centred at each freq in freqs) in Hz.\n    If None, ``freqs / 200`` is used.\ntrans_bandwidth : float\n    Width of the transition band in Hz.\n    Only used for ``method='fir'`` and ``method='iir'``.\n%(n_jobs_fir)s\n%(method_fir)s\n%(iir_params)s\nmt_bandwidth : float | None\n    The bandwidth of the multitaper windowing function in Hz.\n    Only used in 'spectrum_fit' mode.\np_value : float\n    P-value to use in F-test thresholding to determine significant\n    sinusoidal components to remove when ``method='spectrum_fit'`` and\n    ``freqs=None``. Note that this will be Bonferroni corrected for the\n    number of frequencies, so large p-values may be justified.\n%(phase)s\n%(fir_window)s\n%(fir_design)s\n%(pad_fir)s\n    The default is ``'reflect_limited'``.\n\n    .. versionadded:: 0.15\n%(skip_by_annotation)s\n%(verbose)s\n\nReturns\n-------\nraw : instance of Raw\n    The raw instance with filtered data.\n\nSee Also\n--------\nmne.filter.notch_filter\nmne.io.Raw.filter\n\nNotes\n-----\nApplies a zero-phase notch filter to the channels selected by\n\"picks\". By default the data of the Raw object is modified inplace.\n\nThe Raw object has to have the data loaded e.g. with ``preload=True``\nor ``self.load_data()``.\n\n.. note:: If n_jobs > 1, more memory is required as\n          ``len(picks) * n_times`` additional time points need to\n          be temporarily stored in memory.\n\nFor details, see :func:`mne.filter.notch_filter`.", "metadata": {}}
{"_id": "mne_mne_io/base.py_resample_doc", "text": "Resample all channels.\n\nIf appropriate, an anti-aliasing filter is applied before resampling.\nSee :ref:`resampling-and-decimating` for more information.\n\n.. warning:: The intended purpose of this function is primarily to\n             speed up computations (e.g., projection calculation) when\n             precise timing of events is not required, as downsampling\n             raw data effectively jitters trigger timings. It is\n             generally recommended not to epoch downsampled data,\n             but instead epoch and then downsample, as epoching\n             downsampled data jitters triggers.\n             For more, see\n             `this illustrative gist\n             <https://gist.github.com/larsoner/01642cb3789992fbca59>`_.\n\n             If resampling the continuous data is desired, it is\n             recommended to construct events using the original data.\n             The event onsets can be jointly resampled with the raw\n             data using the 'events' parameter (a resampled copy is\n             returned).\n\nParameters\n----------\nsfreq : float\n    New sample rate to use.\n%(npad_resample)s\n%(window_resample)s\nstim_picks : list of int | None\n    Stim channels. These channels are simply subsampled or\n    supersampled (without applying any filtering). This reduces\n    resampling artifacts in stim channels, but may lead to missing\n    triggers. If None, stim channels are automatically chosen using\n    :func:`mne.pick_types`.\n%(n_jobs_cuda)s\nevents : 2D array, shape (n_events, 3) | None\n    An optional event matrix. When specified, the onsets of the events\n    are resampled jointly with the data. NB: The input events are not\n    modified, but a new array is returned with the raw instead.\n%(pad_resample_auto)s\n\n    .. versionadded:: 0.15\n%(method_resample)s\n\n    .. versionadded:: 1.7\n%(verbose)s\n\nReturns\n-------\nraw : instance of Raw\n    The resampled version of the raw object.\nevents : array, shape (n_events, 3) | None\n    If events are jointly resampled, these are returned with the raw.\n\nSee Also\n--------\nmne.io.Raw.filter\nmne.Epochs.resample\n\nNotes\n-----\nFor some data, it may be more accurate to use ``npad=0`` to reduce\nartifacts. This is dataset dependent -- check your data!\n\nFor optimum performance and to make use of ``n_jobs > 1``, the raw\nobject has to have the data loaded e.g. with ``preload=True`` or\n``self.load_data()``, but this increases memory requirements. The\nresulting raw object will have the data loaded into memory.", "metadata": {}}
{"_id": "mne_mne_io/base.py_rescale_doc", "text": "Rescale channels.\n\n.. warning::\n    MNE-Python assumes data are stored in SI base units. This function should\n    typically only be used to fix an incorrect scaling factor in the data to get\n    it to be in SI base units, otherwise unintended problems (e.g., incorrect\n    source imaging results) and analysis errors can occur.\n\nParameters\n----------\nscalings : int | float | dict\n    The scaling factor(s) by which to multiply the data. If a float, the same\n    scaling factor is applied to all channels (this works only if all channels\n    are of the same type). If a dict, the keys must be valid channel types and\n    the values the scaling factors to apply to the corresponding channels.\n%(verbose)s\n\nReturns\n-------\nraw : Raw\n    The raw object with rescaled data (modified in-place).\n\nExamples\n--------\nA common use case for EEG data is to convert from \u00b5V to V, since many EEG\nsystems store data in \u00b5V, but MNE-Python expects the data to be in V. Therefore,\nthe data needs to be rescaled by a factor of 1e-6. To rescale all channels from\n\u00b5V to V, you can do::\n\n    >>> raw.rescale(1e-6)  # doctest: +SKIP\n\nNote that the previous example only works if all channels are of the same type.\nIf there are multiple channel types, you can pass a dict with the individual\nscaling factors. For example, to rescale only EEG channels, you can do::\n\n    >>> raw.rescale({\"eeg\": 1e-6})  # doctest: +SKIP", "metadata": {}}
{"_id": "mne_mne_io/base.py_crop_doc", "text": "Crop raw data file.\n\nLimit the data from the raw file to go between specific times. Note\nthat the new ``tmin`` is assumed to be ``t=0`` for all subsequently\ncalled functions (e.g., :meth:`~mne.io.Raw.time_as_index`, or\n:class:`~mne.Epochs`). New :term:`first_samp` and :term:`last_samp`\nare set accordingly.\n\nThus function operates in-place on the instance.\nUse :meth:`mne.io.Raw.copy` if operation on a copy is desired.\n\nParameters\n----------\n%(tmin_raw)s\n%(tmax_raw)s\n%(include_tmax)s\n%(verbose)s\n\nReturns\n-------\nraw : instance of Raw\n    The cropped raw object, modified in-place.", "metadata": {}}
{"_id": "mne_mne_io/base.py_crop_by_annotations_doc", "text": "Get crops of raw data file for selected annotations.\n\nParameters\n----------\nannotations : instance of Annotations | None\n    The annotations to use for cropping the raw file. If None,\n    the annotations from the instance are used.\n%(verbose)s\n\nReturns\n-------\nraws : list\n    The cropped raw objects.", "metadata": {}}
{"_id": "mne_mne_io/base.py_save_doc", "text": "Save raw data to file.\n\nParameters\n----------\nfname : path-like\n    File name of the new dataset. This has to be a new filename\n    unless data have been preloaded. Filenames should end with\n    ``raw.fif`` (common raw data), ``raw_sss.fif``\n    (Maxwell-filtered continuous data),\n    ``raw_tsss.fif`` (temporally signal-space-separated data),\n    ``_meg.fif`` (common MEG data), ``_eeg.fif`` (common EEG data),\n    or ``_ieeg.fif`` (common intracranial EEG data). You may also\n    append an additional ``.gz`` suffix to enable gzip compression.\n%(picks_all)s\n%(tmin_raw)s\n%(tmax_raw)s\nbuffer_size_sec : float | None\n    Size of data chunks in seconds. If None (default), the buffer\n    size of the original file is used.\ndrop_small_buffer : bool\n    Drop or not the last buffer. It is required by maxfilter (SSS)\n    that only accepts raw files with buffers of the same size.\nproj : bool\n    If True the data is saved with the projections applied (active).\n\n    .. note:: If ``apply_proj()`` was used to apply the projections,\n              the projectons will be active even if ``proj`` is False.\nfmt : 'single' | 'double' | 'int' | 'short'\n    Format to use to save raw data. Valid options are 'double',\n    'single', 'int', and 'short' for 64- or 32-bit float, or 32- or\n    16-bit integers, respectively. It is **strongly** recommended to\n    use 'single', as this is backward-compatible, and is standard for\n    maintaining precision. Note that using 'short' or 'int' may result\n    in loss of precision, complex data cannot be saved as 'short',\n    and neither complex data types nor real data stored as 'double'\n    can be loaded with the MNE command-line tools. See raw.orig_format\n    to determine the format the original data were stored in.\n%(overwrite)s\n    To overwrite original file (the same one that was loaded),\n    data must be preloaded upon reading.\nsplit_size : str | int\n    Large raw files are automatically split into multiple pieces. This\n    parameter specifies the maximum size of each piece. If the\n    parameter is an integer, it specifies the size in Bytes. It is\n    also possible to pass a human-readable string, e.g., 100MB.\n\n    .. note:: Due to FIFF file limitations, the maximum split\n              size is 2GB.\n%(split_naming)s\n\n    .. versionadded:: 0.17\n%(verbose)s\n\nReturns\n-------\nfnames : List of path-like\n    List of path-like objects containing the path to each file split.\n    .. versionadded:: 1.9\n\nNotes\n-----\nIf Raw is a concatenation of several raw files, **be warned** that\nonly the measurement information from the first raw file is stored.\nThis likely means that certain operations with external tools may not\nwork properly on a saved concatenated file (e.g., probably some\nor all forms of SSS). It is recommended not to concatenate and\nthen save raw files for this reason.\n\nSamples annotated ``BAD_ACQ_SKIP`` are not stored in order to optimize\nmemory. Whatever values, they will be loaded as 0s when reading file.", "metadata": {}}
{"_id": "mne_mne_io/base.py_export_doc", "text": "Export Raw to external formats.\n\n%(export_fmt_support_raw)s\n\n%(export_warning)s\n\nParameters\n----------\n%(fname_export_params)s\n%(export_fmt_params_raw)s\n%(physical_range_export_params)s\n%(add_ch_type_export_params)s\n%(overwrite)s\n\n    .. versionadded:: 0.24.1\n%(verbose)s\n\nNotes\n-----\n.. versionadded:: 0.24\n\n%(export_warning_note_raw)s\n%(export_eeglab_note)s\n%(export_edf_note)s", "metadata": {}}
{"_id": "mne_mne_io/base.py_ch_names_doc", "text": "Channel names.", "metadata": {}}
{"_id": "mne_mne_io/base.py_times_doc", "text": "Time points.", "metadata": {}}
{"_id": "mne_mne_io/base.py_n_times_doc", "text": "Number of time points.", "metadata": {}}
{"_id": "mne_mne_io/base.py_duration_doc", "text": "Duration of the data in seconds.\n\n.. versionadded:: 1.9", "metadata": {}}
{"_id": "mne_mne_io/base.py_load_bad_channels_doc", "text": "Mark channels as bad from a text file.\n\nThis function operates mostly in the style of the C function\n``mne_mark_bad_channels``. Each line in the text file will be\ninterpreted as a name of a bad channel.\n\nParameters\n----------\nbad_file : path-like | None\n    File name of the text file containing bad channels.\n    If ``None`` (default), bad channels are cleared, but this\n    is more easily done directly with ``raw.info['bads'] = []``.\nforce : bool\n    Whether or not to force bad channel marking (of those\n    that exist) if channels are not found, instead of\n    raising an error. Defaults to ``False``.\n%(verbose)s", "metadata": {}}
{"_id": "mne_mne_io/base.py_append_doc", "text": "Concatenate raw instances as if they were continuous.\n\n.. note:: Boundaries of the raw files are annotated bad. If you wish to\n          use the data as continuous recording, you can remove the\n          boundary annotations after concatenation (see\n          :meth:`mne.Annotations.delete`).\n\nParameters\n----------\nraws : list, or Raw instance\n    List of Raw instances to concatenate to the current instance\n    (in order), or a single raw instance to concatenate.\n%(preload_concatenate)s", "metadata": {}}
{"_id": "mne_mne_io/base.py_close_doc", "text": "Clean up the object.\n\nDoes nothing for objects that close their file descriptors.\nThings like Raw will override this method.", "metadata": {}}
{"_id": "mne_mne_io/base.py_copy_doc", "text": "Return copy of Raw instance.\n\nReturns\n-------\ninst : instance of Raw\n    A copy of the instance.", "metadata": {}}
{"_id": "mne_mne_io/base.py_add_events_doc", "text": "Add events to stim channel.\n\nParameters\n----------\nevents : ndarray, shape (n_events, 3)\n    Events to add. The first column specifies the sample number of\n    each event, the second column is ignored, and the third column\n    provides the event value. If events already exist in the Raw\n    instance at the given sample numbers, the event values will be\n    added together.\nstim_channel : str | None\n    Name of the stim channel to add to. If None, the config variable\n    'MNE_STIM_CHANNEL' is used. If this is not found, it will default\n    to ``'STI 014'``.\nreplace : bool\n    If True the old events on the stim channel are removed before\n    adding the new ones.\n\nNotes\n-----\nData must be preloaded in order to add events.", "metadata": {}}
{"_id": "mne_mne_io/base.py_compute_psd_doc", "text": "Perform spectral analysis on sensor data.\n\nParameters\n----------\n%(method_psd)s\n    Note that ``\"multitaper\"`` cannot be used if ``reject_by_annotation=True``\n    and there are ``\"bad_*\"`` annotations in the :class:`~mne.io.Raw` data;\n    in such cases use ``\"welch\"``. Default is ``'welch'``.\n%(fmin_fmax_psd)s\n%(tmin_tmax_psd)s\n%(picks_good_data_noref)s\n%(exclude_psd)s\n%(proj_psd)s\n%(remove_dc)s\n%(reject_by_annotation_psd)s\n%(n_jobs)s\n%(verbose)s\n%(method_kw_psd)s\n\nReturns\n-------\nspectrum : instance of Spectrum\n    The spectral representation of the data.\n\nNotes\n-----\n.. versionadded:: 1.2\n\nReferences\n----------\n.. footbibliography::", "metadata": {}}
{"_id": "mne_mne_io/base.py_compute_tfr_doc", "text": "Compute a time-frequency representation of sensor data.\n\nParameters\n----------\n%(method_tfr)s\n%(freqs_tfr)s\n%(tmin_tmax_psd)s\n%(picks_good_data_noref)s\n%(proj_psd)s\n%(output_compute_tfr)s\n%(reject_by_annotation_tfr)s\n%(decim_tfr)s\n%(n_jobs)s\n%(verbose)s\n%(method_kw_tfr)s\n\nReturns\n-------\ntfr : instance of RawTFR\n    The time-frequency-resolved power estimates of the data.\n\nNotes\n-----\n.. versionadded:: 1.7\n\nReferences\n----------\n.. footbibliography::", "metadata": {}}
{"_id": "mne_mne_io/base.py_to_data_frame_doc", "text": "Export data in tabular structure as a pandas DataFrame.\n\nChannels are converted to columns in the DataFrame. By default, an\nadditional column \"time\" is added, unless ``index`` is not ``None``\n(in which case time values form the DataFrame's index).\n\nParameters\n----------\n%(picks_all)s\n%(index_df_raw)s\n    Defaults to ``None``.\n%(scalings_df)s\n%(copy_df)s\nstart : int | None\n    Starting sample index for creating the DataFrame from a temporal\n    span of the Raw object. ``None`` (the default) uses the first\n    sample.\nstop : int | None\n    Ending sample index for creating the DataFrame from a temporal span\n    of the Raw object. ``None`` (the default) uses the last sample.\n%(long_format_df_raw)s\n%(time_format_df_raw)s\n\n    .. versionadded:: 0.20\n%(verbose)s\n\nReturns\n-------\n%(df_return)s", "metadata": {}}
{"_id": "mne_mne_io/base.py_describe_doc", "text": "Describe channels (name, type, descriptive statistics).\n\nParameters\n----------\ndata_frame : bool\n    If True, return results in a pandas.DataFrame. If False, only print\n    results. Columns 'ch', 'type', and 'unit' indicate channel index,\n    channel type, and unit of the remaining five columns. These columns\n    are 'min' (minimum), 'Q1' (first quartile or 25% percentile),\n    'median', 'Q3' (third quartile or 75% percentile), and 'max'\n    (maximum).\n\nReturns\n-------\nresult : None | pandas.DataFrame\n    If data_frame=False, returns None. If data_frame=True, returns\n    results in a pandas.DataFrame (requires pandas).", "metadata": {}}
{"_id": "mne_mne_io/snirf/_snirf.py_read_raw_snirf_doc", "text": "Reader for a continuous wave SNIRF data.\n\n.. note:: This reader supports the .snirf file type only,\n          not the .jnirs version.\n          Files with either 3D or 2D locations can be read.\n          However, we strongly recommend using 3D positions.\n          If 2D positions are used the behaviour of MNE functions\n          can not be guaranteed.\n\nParameters\n----------\nfname : path-like\n    Path to the SNIRF data file.\noptode_frame : str\n    Coordinate frame used for the optode positions. The default is unknown,\n    in which case the positions are not modified. If a known coordinate\n    frame is provided (head, meg, mri), then the positions are transformed\n    in to the Neuromag head coordinate frame (head).\nsfreq : float | None\n    The nominal sampling frequency at which the data were acquired. If ``None``,\n    will be estimated from the time data in the file.\n\n    .. versionadded:: 1.10\n%(preload)s\n%(verbose)s\n\nReturns\n-------\nraw : instance of RawSNIRF\n    A Raw object containing fNIRS data.\n    See :class:`mne.io.Raw` for documentation of attributes and methods.\n\nSee Also\n--------\nmne.io.Raw : Documentation of attributes and methods of RawSNIRF.", "metadata": {}}
{"_id": "mne_mne_io/nirx/nirx.py_read_raw_nirx_doc", "text": "Reader for a NIRX fNIRS recording.\n\nParameters\n----------\nfname : path-like\n    Path to the NIRX data folder or header file.\n%(saturated)s\n%(preload)s\n%(encoding_nirx)s\n%(verbose)s\n\nReturns\n-------\nraw : instance of RawNIRX\n    A Raw object containing NIRX data.\n    See :class:`mne.io.Raw` for documentation of attributes and methods.\n\nSee Also\n--------\nmne.io.Raw : Documentation of attributes and methods of RawNIRX.\n\nNotes\n-----\n%(nirx_notes)s", "metadata": {}}
{"_id": "mne_mne_io/bti/read.py_read_char_doc", "text": "Read character from bti file.", "metadata": {}}
{"_id": "mne_mne_io/bti/read.py_read_uint16_doc", "text": "Read unsigned 16bit integer from bti file.", "metadata": {}}
{"_id": "mne_mne_io/bti/read.py_read_int16_doc", "text": "Read 16bit integer from bti file.", "metadata": {}}
{"_id": "mne_mne_io/bti/read.py_read_uint32_doc", "text": "Read unsigned 32bit integer from bti file.", "metadata": {}}
{"_id": "mne_mne_io/bti/read.py_read_int32_doc", "text": "Read 32bit integer from bti file.", "metadata": {}}
{"_id": "mne_mne_io/bti/read.py_read_int64_doc", "text": "Read 64bit integer from bti file.", "metadata": {}}
{"_id": "mne_mne_io/bti/read.py_read_float_doc", "text": "Read 32bit float from bti file.", "metadata": {}}
{"_id": "mne_mne_io/bti/read.py_read_double_doc", "text": "Read 64bit float from bti file.", "metadata": {}}
{"_id": "mne_mne_io/bti/read.py_read_int16_matrix_doc", "text": "Read 16bit integer matrix from bti file.", "metadata": {}}
{"_id": "mne_mne_io/bti/read.py_read_float_matrix_doc", "text": "Read 32bit float matrix from bti file.", "metadata": {}}
{"_id": "mne_mne_io/bti/read.py_read_double_matrix_doc", "text": "Read 64bit float matrix from bti file.", "metadata": {}}
{"_id": "mne_mne_io/bti/read.py_read_transform_doc", "text": "Read 64bit float matrix transform from bti file.", "metadata": {}}
{"_id": "mne_mne_io/bti/read.py_read_dev_header_doc", "text": "Create a dev header.", "metadata": {}}
{"_id": "mne_mne_io/bti/bti.py_read_raw_bti_doc", "text": "Raw object from 4D Neuroimaging MagnesWH3600 data.\n\n.. note::\n    1. Currently direct inclusion of reference channel weights\n       is not supported. Please use ``mne_create_comp_data`` to include\n       the weights or use the low level functions from this module to\n       include them by yourself.\n    2. The informed guess for the 4D name is E31 for the ECG channel and\n       E63, E63 for the EOG channels. Please check and adjust if those\n       channels are present in your dataset but 'ECG 01' and 'EOG 01',\n       'EOG 02' don't appear in the channel names of the raw object.\n\nParameters\n----------\npdf_fname : path-like\n    Path to the processed data file (PDF).\nconfig_fname : path-like\n    Path to system config file.\nhead_shape_fname : path-like | None\n    Path to the head shape file.\nrotation_x : float\n    Degrees to tilt x-axis for sensor frame misalignment. Ignored\n    if convert is True.\ntranslation : array-like, shape (3,)\n    The translation to place the origin of coordinate system\n    to the center of the head. Ignored if convert is True.\nconvert : bool\n    Convert to Neuromag coordinates or not.\nrename_channels : bool\n    Whether to keep original 4D channel labels or not. Defaults to True.\nsort_by_ch_name : bool\n    Reorder channels according to channel label. 4D channels don't have\n    monotonically increasing numbers in their labels. Defaults to True.\necg_ch : str | None\n    The 4D name of the ECG channel. If None, the channel will be treated\n    as regular EEG channel.\neog_ch : tuple of str | None\n    The 4D names of the EOG channels. If None, the channels will be treated\n    as regular EEG channels.\n%(preload)s\n\n    .. versionadded:: 0.11\n%(verbose)s\n\nReturns\n-------\nraw : instance of RawBTi\n    A Raw object containing BTI data.\n    See :class:`mne.io.Raw` for documentation of attributes and methods.\n\nSee Also\n--------\nmne.io.Raw : Documentation of attributes and methods of RawBTi.", "metadata": {}}
{"_id": "mne_mne_io/neuralynx/neuralynx.py_read_raw_neuralynx_doc", "text": "Reader for Neuralynx files.\n\nParameters\n----------\nfname : path-like\n    Path to a folder with Neuralynx .ncs files.\n%(preload)s\nexclude_fname_patterns : list of str\n    List of glob-like string patterns to exclude from channel list.\n    Useful when not all channels have the same number of samples\n    so you can read separate instances.\n%(verbose)s\n\nReturns\n-------\nraw : instance of RawNeuralynx\n    A Raw object containing Neuralynx data.\n    See :class:`mne.io.Raw` for documentation of attributes and methods.\n\nSee Also\n--------\nmne.io.Raw : Documentation of attributes and methods of RawNeuralynx.\n\nNotes\n-----\nNeuralynx files are read from disk using the `Neo package\n<http://neuralensemble.org/neo/>`__.\nCurrently, only reading of the ``.ncs files`` is supported.\n\n``raw.info[\"meas_date\"]`` is read from the ``recording_opened`` property\nof the first ``.ncs`` file (i.e. channel) in the dataset (a warning is issued\nif files have different dates of acquisition).\n\nChannel-specific high and lowpass frequencies of online filters are determined\nbased on the ``DspLowCutFrequency`` and ``DspHighCutFrequency`` header fields,\nrespectively. If no filters were used for a channel, the default lowpass is set\nto the Nyquist frequency and the default highpass is set to 0.\nIf channels have different high/low cutoffs, ``raw.info[\"highpass\"]`` and\n``raw.info[\"lowpass\"]`` are then set to the maximum highpass and minimumlowpass\nvalues across channels, respectively.\n\nOther header variables can be inspected using Neo directly. For example::\n\n    from neo.io import NeuralynxIO  # doctest: +SKIP\n    fname = 'path/to/your/data'  # doctest: +SKIP\n    nlx_reader = NeuralynxIO(dirname=fname)  # doctest: +SKIP\n    print(nlx_reader.header)  # doctest: +SKIP\n    print(nlx_reader.file_headers.items())  # doctest: +SKIP", "metadata": {}}
{"_id": "mne_mne_io/hitachi/hitachi.py_read_raw_hitachi_doc", "text": "Reader for a Hitachi fNIRS recording.\n\nParameters\n----------\n%(hitachi_fname)s\n%(preload)s\n%(verbose)s\n\nReturns\n-------\nraw : instance of RawHitachi\n    A Raw object containing Hitachi data.\n    See :class:`mne.io.Raw` for documentation of attributes and methods.\n\nSee Also\n--------\nmne.io.Raw : Documentation of attributes and methods of RawHitachi.\n\nNotes\n-----\n%(hitachi_notes)s", "metadata": {}}
{"_id": "mne_mne_io/brainvision/brainvision.py_read_raw_brainvision_doc", "text": "Reader for Brain Vision EEG file.\n\nParameters\n----------\nvhdr_fname : path-like\n    Path to the EEG header file.\neog : list of (int | str) | tuple of (int | str)\n    Names of channels or list of indices that should be designated EOG channels.\n    Values should correspond to the header file Default is ``('HEOGL', 'HEOGR',\n    'VEOGb')``.\nmisc : list of (int | str) | tuple of (int | str) | ``'auto'``\n    Names of channels or list of indices that should be designated MISC channels.\n    Values should correspond to the electrodes in the header file. If ``'auto'``,\n    units in header file are used for inferring misc channels. Default is\n    ``'auto'``.\nscale : float\n    The scaling factor for EEG data. Unless specified otherwise by header file,\n    units are in microvolts. Default scale factor is 1.\nignore_marker_types : bool\n    If ``True``, ignore marker types and only use marker descriptions. Default is\n    ``False``.\n\n    .. versionadded:: 1.8\n%(preload)s\n%(verbose)s\n\nReturns\n-------\nraw : instance of RawBrainVision\n    A Raw object containing BrainVision data. See :class:`mne.io.Raw` for\n    documentation of attributes and methods.\n\nSee Also\n--------\nmne.io.Raw : Documentation of attributes and methods of RawBrainVision.\n\nNotes\n-----\nIf the BrainVision header file contains impedance measurements, these may be\naccessed using ``raw.impedances`` after reading using this function. However, this\nattribute will NOT be available after a save and re-load of the data. That is, it is\nonly available when reading data directly from the BrainVision header file.\n\nBrainVision markers consist of a type and a description (in addition to other fields\nlike onset and duration). In contrast, annotations in MNE only have a description.\nTherefore, a BrainVision marker of type \"Stimulus\" and description \"S  1\" will be\nconverted to an annotation \"Stimulus/S  1\" by default. If you want to ignore the\ntype and instead only use the description, set ``ignore_marker_types=True``, which\nwill convert the same marker to an annotation \"S  1\".\n\nThe first marker in a BrainVision file is usually a \"New Segment\" marker, which\ncontains the recording time. This time is stored in the ``info['meas_date']``\nattribute of the returned object and is not converted to an annotation.", "metadata": {}}
{"_id": "mne_mne_io/fil/fil.py_read_raw_fil_doc", "text": "Raw object from FIL-OPMEG formatted data.\n\nParameters\n----------\nbinfile : path-like\n    Path to the MEG data binary (ending in ``'_meg.bin'``).\nprecision : str, optional\n    How is the data represented? ``'single'`` if 32-bit or ``'double'`` if\n    64-bit (default is single).\n%(preload)s\n%(verbose)s\n\nReturns\n-------\nraw : instance of RawFIL\n    The raw data.\n    See :class:`mne.io.Raw` for documentation of attributes and methods.\n\nSee Also\n--------\nmne.io.Raw : Documentation of attributes and methods of RawFIL.", "metadata": {}}
{"_id": "mne_mne_io/eximia/eximia.py_read_raw_eximia_doc", "text": "Reader for an eXimia EEG file.\n\nParameters\n----------\nfname : path-like\n    Path to the eXimia ``.nxe`` data file.\n%(preload)s\n%(verbose)s\n\nReturns\n-------\nraw : instance of RawEximia\n    A Raw object containing eXimia data.\n    See :class:`mne.io.Raw` for documentation of attributes and methods.\n\nSee Also\n--------\nmne.io.Raw : Documentation of attributes and methods of RawEximia.", "metadata": {}}
{"_id": "mne_mne_io/nsx/nsx.py_read_raw_nsx_doc", "text": "Reader function for NSx (Blackrock Microsystems) files.\n\nParameters\n----------\ninput_fname : str\n    Path to the NSx file.\nstim_channel : ``'auto'`` | str | list of str | int | list of int\n    Defaults to ``'auto'``, which means that channels named ``'status'`` or\n    ``'trigger'`` (case insensitive) are set to STIM. If str (or list of\n    str), all channels matching the name(s) are set to STIM. If int (or\n    list of ints), channels corresponding to the indices are set to STIM.\neog : list or tuple\n    Names of channels or list of indices that should be designated EOG\n    channels. Values should correspond to the electrodes in the file.\n    Default is None.\nmisc : list or tuple\n    Names of channels or list of indices that should be designated MISC\n    channels. Values should correspond to the electrodes in the file.\n    Default is None.\n%(preload)s\n%(verbose)s\n\nReturns\n-------\nraw : instance of RawEDF\n    The raw instance.\n    See :class:`mne.io.Raw` for documentation of attributes and methods.\n\nNotes\n-----\nNSx files with id (= NEURALSG), i.e., version 2.1 is currently not\nsupported.\n\nIf channels named 'status' or 'trigger' are present, they are considered as\nSTIM channels by default. Use func:`mne.find_events` to parse events\nencoded in such analog stim channels.", "metadata": {}}
{"_id": "mne_mne_io/ant/ant.py_read_raw_ant_doc", "text": "Returns\n-------\nraw : instance of RawANT\n    A Raw object containing ANT data.\n    See :class:`mne.io.Raw` for documentation of attributes and methods.\n\nNotes\n-----\n.. versionadded:: 1.9", "metadata": {}}
{"_id": "mne_mne_io/fiff/raw.py_read_raw_fif_doc", "text": "Reader function for Raw FIF data.\n\nParameters\n----------\nfname : path-like | file-like\n    The raw filename to load. For files that have automatically been split,\n    the split part will be automatically loaded. Filenames should end\n    with raw.fif, raw.fif.gz, raw_sss.fif, raw_sss.fif.gz, raw_tsss.fif,\n    raw_tsss.fif.gz, or _meg.fif. If a file-like object is provided,\n    preloading must be used.\n\n    .. versionchanged:: 0.18\n       Support for file-like objects.\nallow_maxshield : bool | str (default False)\n    If True, allow loading of data that has been recorded with internal\n    active compensation (MaxShield). Data recorded with MaxShield should\n    generally not be loaded directly, but should first be processed using\n    SSS/tSSS to remove the compensation signals that may also affect brain\n    activity. Can also be \"yes\" to load without eliciting a warning.\n%(preload)s\n%(on_split_missing)s\n%(verbose)s\n\nReturns\n-------\nraw : instance of Raw\n    A Raw object containing FIF data.\n\nNotes\n-----\n.. versionadded:: 0.9.0\n\nWhen reading a FIF file, note that the first N seconds annotated\n``BAD_ACQ_SKIP`` are **skipped**. They are removed from ``raw.times`` and\n``raw.n_times`` parameters but ``raw.first_samp`` and ``raw.first_time``\nare updated accordingly.", "metadata": {}}
{"_id": "mne_mne_io/fiff/raw.py_fix_mag_coil_types_doc", "text": "Fix Elekta magnetometer coil types.\n\nReturns\n-------\nraw : instance of Raw\n    The raw object. Operates in place.\n\nNotes\n-----\nThis function changes magnetometer coil types 3022 (T1: SQ20483N) and\n3023 (T2: SQ20483-A) to 3024 (T3: SQ20950N) in the channel definition\nrecords in the info structure.\n\nNeuromag Vectorview systems can contain magnetometers with two\ndifferent coil sizes (3022 and 3023 vs. 3024). The systems\nincorporating coils of type 3024 were introduced last and are used at\nthe majority of MEG sites. At some sites with 3024 magnetometers,\nthe data files have still defined the magnetometers to be of type\n3022 to ensure compatibility with older versions of Neuromag software.\nIn the MNE software as well as in the present version of Neuromag\nsoftware coil type 3024 is fully supported. Therefore, it is now safe\nto upgrade the data files to use the true coil type.\n\n.. note:: The effect of the difference between the coil sizes on the\n          current estimates computed by the MNE software is very small.\n          Therefore the use of mne_fix_mag_coil_types is not mandatory.", "metadata": {}}
{"_id": "mne_mne_io/fiff/raw.py_acqparser_doc", "text": "The AcqParserFIF for the measurement info.\n\nSee Also\n--------\nmne.AcqParserFIF", "metadata": {}}
{"_id": "mne_mne_io/eyelink/eyelink.py_read_raw_eyelink_doc", "text": "Reader for an Eyelink ``.asc`` file.\n\nParameters\n----------\n%(eyelink_fname)s\n%(eyelink_create_annotations)s\n%(eyelink_apply_offsets)s\n%(eyelink_find_overlaps)s\n%(eyelink_overlap_threshold)s\n%(verbose)s\n\nReturns\n-------\nraw : instance of RawEyelink\n    A Raw object containing eyetracker data.\n\nSee Also\n--------\nmne.io.Raw : Documentation of attribute and methods.\n\nNotes\n-----\nIt is common for SR Research Eyelink eye trackers to only record data during trials.\nTo avoid frequent data discontinuities and to ensure that the data is continuous\nso that it can be aligned with EEG and MEG data (if applicable), this reader will\npreserve the times between recording trials and annotate them with\n``'BAD_ACQ_SKIP'``.", "metadata": {}}
{"_id": "mne_mne_io/artemis123/artemis123.py_read_raw_artemis123_doc", "text": "Read Artemis123 data as raw object.\n\nParameters\n----------\ninput_fname : path-like\n    Path to the data file (extension ``.bin``). The header file with the\n    same file name stem and an extension ``.txt`` is expected to be found\n    in the same directory.\n%(preload)s\n%(verbose)s\npos_fname : path-like | None\n    If not None, load digitized head points from this file.\nadd_head_trans : bool (default True)\n    If True attempt to perform initial head localization. Compute initial\n    device to head coordinate transform using HPI coils. If no\n    HPI coils are in info['dig'] hpi coils are assumed to be in canonical\n    order of fiducial points (nas, rpa, lpa).\n\nReturns\n-------\nraw : instance of Raw\n    A Raw object containing the data.\n\nSee Also\n--------\nmne.io.Raw : Documentation of attributes and methods.", "metadata": {}}
{"_id": "mne_mne_io/kit/kit.py_get_kit_info_doc", "text": "Extract all the information from the sqd/con file.\n\nParameters\n----------\nrawfile : path-like\n    KIT file to be read.\nallow_unknown_format : bool\n    Force reading old data that is not officially supported. Alternatively,\n    read and re-save the data with the KIT MEG Laboratory application.\n%(standardize_names)s\n%(verbose)s\n\nReturns\n-------\n%(info_not_none)s\nsqd : dict\n    A dict containing all the sqd parameter settings.", "metadata": {}}
{"_id": "mne_mne_io/kit/kit.py_read_raw_kit_doc", "text": "Reader function for Ricoh/KIT conversion to FIF.\n\nParameters\n----------\ninput_fname : path-like\n    Path to the SQD file.\n%(kit_mrk)s\n%(kit_elp)s\n%(kit_hsp)s\n%(kit_stim)s\n%(kit_slope)s\n%(kit_stimthresh)s\n%(preload)s\n%(kit_stimcode)s\nallow_unknown_format : bool\n    Force reading old data that is not officially supported. Alternatively,\n    read and re-save the data with the KIT MEG Laboratory application.\n%(standardize_names)s\n%(kit_badcoils)s\n%(verbose)s\n\nReturns\n-------\nraw : instance of RawKIT\n    A Raw object containing KIT data.\n    See :class:`mne.io.Raw` for documentation of attributes and methods.\n\nSee Also\n--------\nmne.io.Raw : Documentation of attributes and methods of RawKIT.\n\nNotes\n-----\n``elp`` and ``hsp`` are usually the exported text files (\\*.txt) from the\nPolhemus FastScan system. ``hsp`` refers to the headshape surface points.\n``elp`` refers to the points in head-space that corresponds to the HPI\npoints.\n\nIf ``mrk``\\, ``hsp`` or ``elp`` are :term:`array_like` inputs, then the\nnumbers in xyz coordinates should be in units of meters.", "metadata": {}}
{"_id": "mne_mne_io/kit/kit.py_read_epochs_kit_doc", "text": "Reader function for Ricoh/KIT epochs files.\n\nParameters\n----------\ninput_fname : path-like\n    Path to the SQD file.\nevents : array of int, shape (n_events, 3) | path-like\n    The array of :term:`events`. The first column contains the event time\n    in samples, with :term:`first_samp` included. The third column contains\n    the event id. If a path, must yield a ``.txt`` file containing the\n    events.\n    If some events don't match the events of interest as specified by\n    ``event_id``, they will be marked as ``IGNORED`` in the drop log.\n%(event_id)s\n%(kit_mrk)s\n%(kit_elp)s\n%(kit_hsp)s\nallow_unknown_format : bool\n    Force reading old data that is not officially supported. Alternatively,\n    read and re-save the data with the KIT MEG Laboratory application.\n%(standardize_names)s\n%(verbose)s\n\nReturns\n-------\nEpochsKIT : instance of BaseEpochs\n    The epochs.\n\nSee Also\n--------\nmne.Epochs : Documentation of attributes and methods.\n\nNotes\n-----\n.. versionadded:: 0.9.0", "metadata": {}}
{"_id": "mne_mne_io/kit/kit.py_read_stim_ch_doc", "text": "Read events from data.\n\nParameter\n---------\nbuffer_size : int\n    The size of chunk to by which the data are scanned.\n\nReturns\n-------\nevents : array, [samples]\n   The event vector (1 x samples).", "metadata": {}}
{"_id": "mne_mne_io/kit/coreg.py_read_mrk_doc", "text": "Marker Point Extraction in MEG space directly from sqd.\n\nParameters\n----------\nfname : path-like\n    Absolute path to Marker file.\n    File formats allowed: \\*.sqd, \\*.mrk, \\*.txt.\n\nReturns\n-------\nmrk_points : ndarray, shape (n_points, 3)\n    Marker points in MEG space [m].", "metadata": {}}
{"_id": "mne_mne_io/kit/coreg.py_read_sns_doc", "text": "Sensor coordinate extraction in MEG space.\n\nParameters\n----------\nfname : path-like\n    Absolute path to sensor definition file.\n\nReturns\n-------\nlocs : numpy.array, shape = (n_points, 3)\n    Sensor coil location.", "metadata": {}}
{"_id": "mne_mne_io/egi/egi.py_read_raw_egi_doc", "text": "Read EGI simple binary as raw object.\n\nParameters\n----------\ninput_fname : path-like\n    Path to the raw file. Files with an extension ``.mff`` are\n    automatically considered to be EGI's native MFF format files.\neog : list or tuple\n    Names of channels or list of indices that should be designated\n    EOG channels. Default is None.\nmisc : list or tuple\n    Names of channels or list of indices that should be designated\n    MISC channels. Default is None.\ninclude : None | list\n   The event channels to be included when creating the synthetic\n   trigger or annotations. Defaults to None.\n   Note. Overrides ``exclude`` parameter.\nexclude : None | list\n   The event channels to be ignored when creating the synthetic\n   trigger or annotations. Defaults to None. If None, the ``sync`` and ``TREV``\n   channels will be ignored. This is ignored when ``include`` is not None.\n%(preload)s\n\n    .. versionadded:: 0.11\nchannel_naming : str\n    Channel naming convention for the data channels. Defaults to ``'E%%d'``\n    (resulting in channel names ``'E1'``, ``'E2'``, ``'E3'``...). The\n    effective default prior to 0.14.0 was ``'EEG %%03d'``.\n    .. versionadded:: 0.14.0\n\nevents_as_annotations : bool\n    If True, annotations are created from experiment events. If False (default),\n    a synthetic trigger channel ``STI 014`` is created from experiment events.\n    See the Notes section for details.\n    The default will change from False to True in version 1.9.\n\n    .. versionadded:: 1.8.0\n%(verbose)s\n\nReturns\n-------\nraw : instance of RawEGI\n    A Raw object containing EGI data.\n    See :class:`mne.io.Raw` for documentation of attributes and methods.\n\nSee Also\n--------\nmne.io.Raw : Documentation of attributes and methods of RawEGI.\n\nNotes\n-----\nWhen ``events_from_annotations=True``, event codes on stimulus channels like\n``DIN1`` are stored as annotations with the ``description`` set to the stimulus\nchannel name.\n\nWhen ``events_from_annotations=False`` and events are present on the included\nstimulus channels, a new stim channel ``STI014`` will be synthesized from the\nevents. It will contain 1-sample pulses where the Netstation file had event\ntimestamps. A ``raw.event_id`` dictionary is added to the raw object that will have\narbitrary sequential integer IDs for the events. This will fail if any timestamps\nare duplicated. The ``event_id`` will also not survive a save/load roundtrip.\n\nFor these reasons, it is recommended to use ``events_as_annotations=True``.", "metadata": {}}
{"_id": "mne_mne_io/egi/egimff.py_read_evokeds_mff_doc", "text": "Read averaged MFF file as EvokedArray or list of EvokedArray.\n\nParameters\n----------\nfname : path-like\n    File path to averaged MFF file. Should end in ``.mff``.\ncondition : int or str | list of int or str | None\n    The index (indices) or category (categories) from which to read in\n    data. Averaged MFF files can contain separate averages for different\n    categories. These can be indexed by the block number or the category\n    name. If ``condition`` is a list or None, a list of EvokedArray objects\n    is returned.\nchannel_naming : str\n    Channel naming convention for EEG channels. Defaults to 'E%%d'\n    (resulting in channel names 'E1', 'E2', 'E3'...).\nbaseline : None (default) or tuple of length 2\n    The time interval to apply baseline correction. If None do not apply\n    it. If baseline is (a, b) the interval is between \"a (s)\" and \"b (s)\".\n    If a is None the beginning of the data is used and if b is None then b\n    is set to the end of the interval. If baseline is equal to (None, None)\n    all the time interval is used. Correction is applied by computing mean\n    of the baseline period and subtracting it from the data. The baseline\n    (a, b) includes both endpoints, i.e. all timepoints t such that\n    a <= t <= b.\n%(verbose)s\n\nReturns\n-------\nevoked : EvokedArray or list of EvokedArray\n    The evoked dataset(s); one EvokedArray if condition is int or str,\n    or list of EvokedArray if condition is None or list.\n\nRaises\n------\nValueError\n    If ``fname`` has file extension other than '.mff'.\nValueError\n    If the MFF file specified by ``fname`` is not averaged.\nValueError\n    If no categories.xml file in MFF directory specified by ``fname``.\n\nSee Also\n--------\nEvoked, EvokedArray, create_info\n\nNotes\n-----\n.. versionadded:: 0.22", "metadata": {}}
{"_id": "mne_mne_io/persyst/persyst.py_read_raw_persyst_doc", "text": "Reader for a Persyst (.lay/.dat) recording.\n\nParameters\n----------\nfname : path-like\n    Path to the Persyst header ``.lay`` file.\n%(preload)s\n%(verbose)s\n\nReturns\n-------\nraw : instance of RawPersyst\n    A Raw object containing Persyst data.\n    See :class:`mne.io.Raw` for documentation of attributes and methods.\n\nSee Also\n--------\nmne.io.Raw : Documentation of attributes and methods of RawPersyst.\n\nNotes\n-----\nIt is assumed that the ``.lay`` and ``.dat`` file\nare in the same directory. To get the correct file path to the\n``.dat`` file, ``read_raw_persyst`` will get the corresponding dat\nfilename from the lay file, and look for that file inside the same\ndirectory as the lay file.", "metadata": {}}
{"_id": "mne_mne_io/nihon/nihon.py_read_raw_nihon_doc", "text": "Reader for an Nihon Kohden EEG file.\n\nParameters\n----------\nfname : path-like\n    Path to the Nihon Kohden data file (``.EEG``).\npreload : bool\n    If True, all data are loaded at initialization.\n%(verbose)s\n\nReturns\n-------\nraw : instance of RawNihon\n    A Raw object containing Nihon Kohden data.\n    See :class:`mne.io.Raw` for documentation of attributes and methods.\n\nSee Also\n--------\nmne.io.Raw : Documentation of attributes and methods of RawNihon.", "metadata": {}}
{"_id": "mne_mne_io/besa/besa.py_read_evoked_besa_doc", "text": "Reader function for BESA ``.avr`` or ``.mul`` files.\n\nWhen a ``.elp`` sidecar file is present, it will be used to determine\nelectrode information.\n\nParameters\n----------\nfname : path-like\n    Path to the ``.avr`` or ``.mul`` file.\n%(verbose)s\n\nReturns\n-------\nev : Evoked\n    The evoked data in the .avr or .mul file.", "metadata": {}}
{"_id": "mne_mne_io/cnt/cnt.py_read_raw_cnt_doc", "text": "Read CNT data as raw object.\n\n.. Note::\n    2d spatial coordinates (x, y) for EEG channels are read from the file\n    header and fit to a sphere to compute corresponding z-coordinates.\n    If channels assigned as EEG channels have locations\n    far away from the head (i.e. x and y coordinates don't fit to a\n    sphere), all the channel locations will be distorted\n    (all channels that are not assigned with keywords ``eog``, ``ecg``,\n    ``emg`` and ``misc`` are assigned as EEG channels). If you are not\n    sure that the channel locations in the header are correct, it is\n    probably safer to replace them with :meth:`mne.io.Raw.set_montage`.\n    Montages can be created/imported with:\n\n    - Standard montages with :func:`mne.channels.make_standard_montage`\n    - Montages for `Compumedics systems\n      <https://compumedicsneuroscan.com>`__ with\n      :func:`mne.channels.read_dig_dat`\n    - Other reader functions are listed under *See Also* at\n      :class:`mne.channels.DigMontage`\n\nParameters\n----------\ninput_fname : path-like\n    Path to the data file.\neog : list | tuple | ``'auto'`` | ``'header'``\n    Names of channels or list of indices that should be designated\n    EOG channels. If 'header', VEOG and HEOG channels assigned in the file\n    header are used. If ``'auto'``, channel names containing ``'EOG'`` are\n    used. Defaults to empty tuple.\nmisc : list | tuple\n    Names of channels or list of indices that should be designated\n    MISC channels. Defaults to empty tuple.\necg : list | tuple | ``'auto'``\n    Names of channels or list of indices that should be designated\n    ECG channels. If ``'auto'``, the channel names containing ``'ECG'`` are\n    used. Defaults to empty tuple.\nemg : list | tuple\n    Names of channels or list of indices that should be designated\n    EMG channels. If 'auto', the channel names containing 'EMG' are used.\n    Defaults to empty tuple.\ndata_format : ``'auto'`` | ``'int16'`` | ``'int32'``\n    Defines the data format the data is read in. If ``'auto'``, it is\n    determined from the file header using ``numsamples`` field.\n    Defaults to ``'auto'``.\ndate_format : ``'mm/dd/yy'`` | ``'dd/mm/yy'``\n    Format of date in the header. Defaults to ``'mm/dd/yy'``.\nheader : ``'auto'`` | ``'new'`` | ``'old'``\n    Defines the header format. Used to describe how bad channels\n    are formatted. If auto, reads using old and new header and\n    if either contain a bad channel make channel bad.\n    Defaults to ``'auto'``.\n\n    .. versionadded:: 1.6\n%(preload)s\n%(verbose)s\n\nReturns\n-------\nraw : instance of RawCNT.\n    The raw data.\n    See :class:`mne.io.Raw` for documentation of attributes and methods.\n\nSee Also\n--------\nmne.io.Raw : Documentation of attributes and methods of RawCNT.\n\nNotes\n-----\n.. versionadded:: 0.12", "metadata": {}}
{"_id": "mne_mne_io/nicolet/nicolet.py_read_raw_nicolet_doc", "text": "Read Nicolet data as raw object.\n\n..note:: This reader takes data files with the extension ``.data`` as an\n         input. The header file with the same file name stem and an\n         extension ``.head`` is expected to be found in the same\n         directory.\n\nParameters\n----------\ninput_fname : path-like\n    Path to the data file (ending with ``.data`` not ``.head``).\nch_type : str\n    Channel type to designate to the data channels. Supported data types\n    include ``'eeg'``, ``'dbs'``.\neog : list | tuple | ``'auto'``\n    Names of channels or list of indices that should be designated\n    EOG channels. If ``'auto'``, the channel names beginning with\n    ``EOG`` are used. Defaults to empty tuple.\necg : list or tuple | ``'auto'``\n    Names of channels or list of indices that should be designated\n    ECG channels. If ``'auto'``, the channel names beginning with\n    ``ECG`` are used. Defaults to empty tuple.\nemg : list or tuple | ``'auto'``\n    Names of channels or list of indices that should be designated\n    EMG channels. If ``'auto'``, the channel names beginning with\n    ``EMG`` are used. Defaults to empty tuple.\nmisc : list or tuple\n    Names of channels or list of indices that should be designated\n    MISC channels. Defaults to empty tuple.\n%(preload)s\n%(verbose)s\n\nReturns\n-------\nraw : instance of Raw\n    A Raw object containing the data.\n\nSee Also\n--------\nmne.io.Raw : Documentation of attributes and methods.", "metadata": {}}
{"_id": "mne_mne_io/eeglab/eeglab.py_read_raw_eeglab_doc", "text": "Read an EEGLAB .set file.\n\nParameters\n----------\ninput_fname : path-like\n    Path to the ``.set`` file. If the data is stored in a separate ``.fdt``\n    file, it is expected to be in the same folder as the ``.set`` file.\neog : list | tuple | ``'auto'``\n    Names or indices of channels that should be designated EOG channels.\n    If 'auto', the channel names containing ``EOG`` or ``EYE`` are used.\n    Defaults to empty tuple.\n%(preload)s\n    Note that ``preload=False`` will be effective only if the data is\n    stored in a separate binary file.\n%(uint16_codec)s\n%(montage_units)s\n\n    .. versionchanged:: 1.6\n       Support for ``'auto'`` was added and is the new default.\n%(verbose)s\n\nReturns\n-------\nraw : instance of RawEEGLAB\n    A Raw object containing EEGLAB .set data.\n    See :class:`mne.io.Raw` for documentation of attributes and methods.\n\nSee Also\n--------\nmne.io.Raw : Documentation of attributes and methods of RawEEGLAB.\n\nNotes\n-----\n.. versionadded:: 0.11.0", "metadata": {}}
{"_id": "mne_mne_io/eeglab/eeglab.py_read_epochs_eeglab_doc", "text": "Reader function for EEGLAB epochs files.\n\nParameters\n----------\ninput_fname : path-like\n    Path to the ``.set`` file. If the data is stored in a separate ``.fdt``\n    file, it is expected to be in the same folder as the ``.set`` file.\nevents : path-like | array, shape (n_events, 3) | None\n    Path to events file. If array, it is the events typically returned\n    by the read_events function. If some events don't match the events\n    of interest as specified by event_id, they will be marked as 'IGNORED'\n    in the drop log. If None, it is constructed from the EEGLAB (.set) file\n    with each unique event encoded with a different integer.\nevent_id : int | list of int | dict | None\n    The id of the event to consider. If dict, the keys can later be used\n    to access associated events.\n    Example::\n\n        {\"auditory\":1, \"visual\":3}\n\n    If int, a dict will be created with\n    the id as string. If a list, all events with the IDs specified\n    in the list are used. If None, the event_id is constructed from the\n    EEGLAB (.set) file with each descriptions copied from ``eventtype``.\neog : list | tuple | 'auto'\n    Names or indices of channels that should be designated EOG channels.\n    If 'auto', the channel names containing ``EOG`` or ``EYE`` are used.\n    Defaults to empty tuple.\n%(uint16_codec)s\n%(montage_units)s\n\n    .. versionchanged:: 1.6\n       Support for ``'auto'`` was added and is the new default.\n%(verbose)s\n\nReturns\n-------\nEpochsEEGLAB : instance of BaseEpochs\n    The epochs.\n\nSee Also\n--------\nmne.Epochs : Documentation of attributes and methods.\n\nNotes\n-----\n.. versionadded:: 0.11.0", "metadata": {}}
{"_id": "mne_mne_io/ctf/ctf.py_read_raw_ctf_doc", "text": "Raw object from CTF directory.\n\nParameters\n----------\ndirectory : path-like\n    Path to the CTF data (ending in ``'.ds'``).\nsystem_clock : str\n    How to treat the system clock. Use \"truncate\" (default) to truncate\n    the data file when the system clock drops to zero, and use \"ignore\"\n    to ignore the system clock (e.g., if head positions are measured\n    multiple times during a recording).\n%(preload)s\nclean_names : bool, optional\n    If True main channel names and compensation channel names will\n    be cleaned from CTF suffixes. The default is False.\n%(verbose)s\n\nReturns\n-------\nraw : instance of RawCTF\n    The raw data.\n\nNotes\n-----\n.. versionadded:: 0.11\n\nTo read in the Polhemus digitization data (for example, from\na .pos file), include the file in the CTF directory. The\npoints will then automatically be read into the `mne.io.Raw`\ninstance via `mne.io.read_raw_ctf`.", "metadata": {}}
{"_id": "mne_mne_io/fieldtrip/fieldtrip.py_read_raw_fieldtrip_doc", "text": "Load continuous (raw) data from a FieldTrip preprocessing structure.\n\nThis function expects to find single trial raw data (FT_DATATYPE_RAW) in\nthe structure data_name is pointing at.\n\n.. warning:: FieldTrip does not normally store the original information\n             concerning channel location, orientation, type etc. It is\n             therefore **highly recommended** to provide the info field.\n             This can be obtained by reading the original raw data file\n             with MNE functions (without preload). The returned object\n             contains the necessary info field.\n\nParameters\n----------\nfname : path-like\n    Path and filename of the ``.mat`` file containing the data.\ninfo : dict or None\n    The info dict of the raw data file corresponding to the data to import.\n    If this is set to None, limited information is extracted from the\n    FieldTrip structure.\ndata_name : str\n    Name of heading dict/variable name under which the data was originally\n    saved in MATLAB.\n\nReturns\n-------\nraw : instance of RawArray\n    A Raw Object containing the loaded data.\n    See :class:`mne.io.Raw` for documentation of attributes and methods.\n\nSee Also\n--------\nmne.io.Raw : Documentation of attributes and methods of RawArray.", "metadata": {}}
{"_id": "mne_mne_io/fieldtrip/fieldtrip.py_read_epochs_fieldtrip_doc", "text": "Load epoched data from a FieldTrip preprocessing structure.\n\nThis function expects to find epoched data in the structure data_name is\npointing at.\n\n.. warning:: Only epochs with the same amount of channels and samples are\n             supported!\n\n.. warning:: FieldTrip does not normally store the original information\n             concerning channel location, orientation, type etc. It is\n             therefore **highly recommended** to provide the info field.\n             This can be obtained by reading the original raw data file\n             with MNE functions (without preload). The returned object\n             contains the necessary info field.\n\nParameters\n----------\nfname : path-like\n    Path and filename of the ``.mat`` file containing the data.\ninfo : dict or None\n    The info dict of the raw data file corresponding to the data to import.\n    If this is set to None, limited information is extracted from the\n    FieldTrip structure.\ndata_name : str\n    Name of heading dict/ variable name under which the data was originally\n    saved in MATLAB.\ntrialinfo_column : int\n    Column of the trialinfo matrix to use for the event codes.\n\nReturns\n-------\nepochs : instance of EpochsArray\n    An EpochsArray containing the loaded data.", "metadata": {}}
{"_id": "mne_mne_io/fieldtrip/fieldtrip.py_read_evoked_fieldtrip_doc", "text": "Load evoked data from a FieldTrip timelocked structure.\n\nThis function expects to find timelocked data in the structure data_name is\npointing at.\n\n.. warning:: FieldTrip does not normally store the original information\n             concerning channel location, orientation, type etc. It is\n             therefore **highly recommended** to provide the info field.\n             This can be obtained by reading the original raw data file\n             with MNE functions (without preload). The returned object\n             contains the necessary info field.\n\nParameters\n----------\nfname : path-like\n    Path and filename of the ``.mat`` file containing the data.\ninfo : dict or None\n    The info dict of the raw data file corresponding to the data to import.\n    If this is set to None, limited information is extracted from the\n    FieldTrip structure.\ncomment : str\n    Comment on dataset. Can be the condition.\ndata_name : str\n    Name of heading dict/ variable name under which the data was originally\n    saved in MATLAB.\n\nReturns\n-------\nevoked : instance of EvokedArray\n    An EvokedArray containing the loaded data.", "metadata": {}}
{"_id": "mne_mne_io/boxy/boxy.py_read_raw_boxy_doc", "text": "Reader for an optical imaging recording.\n\nThis function has been tested using the ISS Imagent I and II systems\nand versions 0.40/0.84 of the BOXY recording software.\n\nParameters\n----------\nfname : path-like\n    Path to the BOXY data file.\n%(preload)s\n%(verbose)s\n\nReturns\n-------\nraw : instance of RawBOXY\n    A Raw object containing BOXY data.\n    See :class:`mne.io.Raw` for documentation of attributes and methods.\n\nSee Also\n--------\nmne.io.Raw : Documentation of attributes and methods of RawBOXY.", "metadata": {}}
{"_id": "mne_mne_io/nedf/nedf.py_read_raw_nedf_doc", "text": "Read NeuroElectrics .nedf files.\n\nNEDF file versions starting from 1.3 are supported.\n\nParameters\n----------\nfilename : path-like\n    Path to the ``.nedf`` file.\n%(preload)s\n%(verbose)s\n\nReturns\n-------\nraw : instance of RawNedf\n    A Raw object containing NEDF data.\n    See :class:`mne.io.Raw` for documentation of attributes and methods.\n\nSee Also\n--------\nmne.io.Raw : Documentation of attributes and methods of RawNedf.", "metadata": {}}
{"_id": "mne_mne_io/curry/curry.py_read_raw_curry_doc", "text": "Read raw data from Curry files.\n\nParameters\n----------\nfname : path-like\n    Path to a curry file with extensions ``.dat``, ``.dap``, ``.rs3``,\n    ``.cdt``, ``.cdt.dpa``, ``.cdt.cef`` or ``.cef``.\n%(preload)s\n%(verbose)s\n\nReturns\n-------\nraw : instance of RawCurry\n    A Raw object containing Curry data.\n    See :class:`mne.io.Raw` for documentation of attributes and methods.\n\nSee Also\n--------\nmne.io.Raw : Documentation of attributes and methods of RawCurry.", "metadata": {}}
{"_id": "mne_mne_io/edf/edf.py_read_raw_edf_doc", "text": "Reader function for EDF and EDF+ files.\n\nParameters\n----------\ninput_fname : path-like\n    Path to the EDF or EDF+ file.\neog : list or tuple\n    Names of channels or list of indices that should be designated EOG\n    channels. Values should correspond to the electrodes in the file.\n    Default is None.\nmisc : list or tuple\n    Names of channels or list of indices that should be designated MISC\n    channels. Values should correspond to the electrodes in the file.\n    Default is None.\nstim_channel : ``'auto'`` | str | list of str | int | list of int\n    Defaults to ``'auto'``, which means that channels named ``'status'`` or\n    ``'trigger'`` (case insensitive) are set to STIM. If str (or list of\n    str), all channels matching the name(s) are set to STIM. If int (or\n    list of ints), channels corresponding to the indices are set to STIM.\nexclude : list of str | str\n    Channel names to exclude. This can help when reading data with\n    different sampling rates to avoid unnecessary resampling. A str is\n    interpreted as a regular expression.\ninfer_types : bool\n    If True, try to infer channel types from channel labels. If a channel\n    label starts with a known type (such as 'EEG') followed by a space and\n    a name (such as 'Fp1'), the channel type will be set accordingly, and\n    the channel will be renamed to the original label without the prefix.\n    For unknown prefixes, the type will be 'EEG' and the name will not be\n    modified. If False, do not infer types and assume all channels are of\n    type 'EEG'.\n\n    .. versionadded:: 0.24.1\ninclude : list of str | str\n    Channel names to be included. A str is interpreted as a regular\n    expression. 'exclude' must be empty if include is assigned.\n\n    .. versionadded:: 1.1\n%(preload)s\n%(units_edf_bdf_io)s\n%(encoding_edf)s\n%(exclude_after_unique)s\n%(verbose)s\n\nReturns\n-------\nraw : instance of RawEDF\n    The raw instance.\n    See :class:`mne.io.Raw` for documentation of attributes and methods.\n\nSee Also\n--------\nmne.io.read_raw_bdf : Reader function for BDF files.\nmne.io.read_raw_gdf : Reader function for GDF files.\nmne.export.export_raw : Export function for EDF files.\nmne.io.Raw : Documentation of attributes and methods of RawEDF.\n\nNotes\n-----\n%(edf_resamp_note)s\n\nIt is worth noting that in some special cases, it may be necessary to shift\nevent values in order to retrieve correct event triggers. This depends on\nthe triggering device used to perform the synchronization. For instance, in\nsome files events need to be shifted by 8 bits:\n\n    >>> events[:, 2] >>= 8  # doctest:+SKIP\n\nTAL channels called 'EDF Annotations' are parsed and extracted annotations\nare stored in raw.annotations. Use :func:`mne.events_from_annotations` to\nobtain events from these annotations.\n\nIf channels named 'status' or 'trigger' are present, they are considered as\nSTIM channels by default. Use func:`mne.find_events` to parse events\nencoded in such analog stim channels.\n\nThe EDF specification allows optional storage of channel types in the\nprefix of the signal label for each channel. For example, ``EEG Fz``\nimplies that ``Fz`` is an EEG channel and ``MISC E`` would imply ``E`` is\na MISC channel. However, there is no standard way of specifying all\nchannel types. MNE-Python will try to infer the channel type, when such a\nstring exists, defaulting to EEG, when there is no prefix or the prefix is\nnot recognized.\n\nThe following prefix strings are mapped to MNE internal types:\n\n    - 'EEG': 'eeg'\n    - 'SEEG': 'seeg'\n    - 'ECOG': 'ecog'\n    - 'DBS': 'dbs'\n    - 'EOG': 'eog'\n    - 'ECG': 'ecg'\n    - 'EMG': 'emg'\n    - 'BIO': 'bio'\n    - 'RESP': 'resp'\n    - 'MISC': 'misc'\n    - 'SAO2': 'bio'\n\nThe EDF specification allows storage of subseconds in measurement date.\nHowever, this reader currently sets subseconds to 0 by default.", "metadata": {}}
{"_id": "mne_mne_io/edf/edf.py_read_raw_bdf_doc", "text": "Reader function for BDF files.\n\nParameters\n----------\ninput_fname : path-like\n    Path to the BDF file.\neog : list or tuple\n    Names of channels or list of indices that should be designated EOG\n    channels. Values should correspond to the electrodes in the file.\n    Default is None.\nmisc : list or tuple\n    Names of channels or list of indices that should be designated MISC\n    channels. Values should correspond to the electrodes in the file.\n    Default is None.\nstim_channel : ``'auto'`` | str | list of str | int | list of int\n    Defaults to ``'auto'``, which means that channels named ``'status'`` or\n    ``'trigger'`` (case insensitive) are set to STIM. If str (or list of\n    str), all channels matching the name(s) are set to STIM. If int (or\n    list of ints), channels corresponding to the indices are set to STIM.\nexclude : list of str | str\n    Channel names to exclude. This can help when reading data with\n    different sampling rates to avoid unnecessary resampling. A str is\n    interpreted as a regular expression.\ninfer_types : bool\n    If True, try to infer channel types from channel labels. If a channel\n    label starts with a known type (such as 'EEG') followed by a space and\n    a name (such as 'Fp1'), the channel type will be set accordingly, and\n    the channel will be renamed to the original label without the prefix.\n    For unknown prefixes, the type will be 'EEG' and the name will not be\n    modified. If False, do not infer types and assume all channels are of\n    type 'EEG'.\n\n    .. versionadded:: 0.24.1\ninclude : list of str | str\n    Channel names to be included. A str is interpreted as a regular\n    expression. 'exclude' must be empty if include is assigned.\n\n    .. versionadded:: 1.1\n%(preload)s\n%(units_edf_bdf_io)s\n%(encoding_edf)s\n%(exclude_after_unique)s\n%(verbose)s\n\nReturns\n-------\nraw : instance of RawEDF\n    The raw instance.\n    See :class:`mne.io.Raw` for documentation of attributes and methods.\n\nSee Also\n--------\nmne.io.read_raw_edf : Reader function for EDF and EDF+ files.\nmne.io.read_raw_gdf : Reader function for GDF files.\nmne.io.Raw : Documentation of attributes and methods of RawEDF.\n\nNotes\n-----\n:class:`mne.io.Raw` only stores signals with matching sampling frequencies.\nTherefore, if mixed sampling frequency signals are requested, all signals\nare upsampled to the highest loaded sampling frequency. In this case, using\npreload=True is recommended, as otherwise, edge artifacts appear when\nslices of the signal are requested.\n\nBiosemi devices trigger codes are encoded in 16-bit format, whereas system\ncodes (CMS in/out-of range, battery low, etc.) are coded in bits 16-23 of\nthe status channel (see http://www.biosemi.com/faq/trigger_signals.htm).\nTo retrieve correct event values (bits 1-16), one could do:\n\n    >>> events = mne.find_events(...)  # doctest:+SKIP\n    >>> events[:, 2] &= (2**16 - 1)  # doctest:+SKIP\n\nThe above operation can be carried out directly in :func:`mne.find_events`\nusing the ``mask`` and ``mask_type`` parameters (see\n:func:`mne.find_events` for more details).\n\nIt is also possible to retrieve system codes, but no particular effort has\nbeen made to decode these in MNE. In case it is necessary, for instance to\ncheck the CMS bit, the following operation can be carried out:\n\n    >>> cms_bit = 20  # doctest:+SKIP\n    >>> cms_high = (events[:, 2] & (1 << cms_bit)) != 0  # doctest:+SKIP\n\nIt is worth noting that in some special cases, it may be necessary to shift\nevent values in order to retrieve correct event triggers. This depends on\nthe triggering device used to perform the synchronization. For instance, in\nsome files events need to be shifted by 8 bits:\n\n    >>> events[:, 2] >>= 8  # doctest:+SKIP\n\nTAL channels called 'BDF Annotations' are parsed and extracted annotations\nare stored in raw.annotations. Use :func:`mne.events_from_annotations` to\nobtain events from these annotations.\n\nIf channels named 'status' or 'trigger' are present, they are considered as\nSTIM channels by default. Use func:`mne.find_events` to parse events\nencoded in such analog stim channels.", "metadata": {}}
{"_id": "mne_mne_io/edf/edf.py_read_raw_gdf_doc", "text": "Reader function for GDF files.\n\nParameters\n----------\ninput_fname : path-like\n    Path to the GDF file.\neog : list or tuple\n    Names of channels or list of indices that should be designated EOG\n    channels. Values should correspond to the electrodes in the file.\n    Default is None.\nmisc : list or tuple\n    Names of channels or list of indices that should be designated MISC\n    channels. Values should correspond to the electrodes in the file.\n    Default is None.\nstim_channel : ``'auto'`` | str | list of str | int | list of int\n    Defaults to ``'auto'``, which means that channels named ``'status'`` or\n    ``'trigger'`` (case insensitive) are set to STIM. If str (or list of\n    str), all channels matching the name(s) are set to STIM. If int (or\n    list of ints), channels corresponding to the indices are set to STIM.\nexclude : list of str | str\n    Channel names to exclude. This can help when reading data with\n    different sampling rates to avoid unnecessary resampling. A str is\n    interpreted as a regular expression.\ninclude : list of str | str\n    Channel names to be included. A str is interpreted as a regular\n    expression. 'exclude' must be empty if include is assigned.\n%(preload)s\n%(verbose)s\n\nReturns\n-------\nraw : instance of RawGDF\n    The raw instance.\n    See :class:`mne.io.Raw` for documentation of attributes and methods.\n\nSee Also\n--------\nmne.io.read_raw_edf : Reader function for EDF and EDF+ files.\nmne.io.read_raw_bdf : Reader function for BDF files.\nmne.io.Raw : Documentation of attributes and methods of RawGDF.\n\nNotes\n-----\nIf channels named 'status' or 'trigger' are present, they are considered as\nSTIM channels by default. Use func:`mne.find_events` to parse events\nencoded in such analog stim channels.", "metadata": {}}
{"_id": "mne_mne_report/report.py_open_report_doc", "text": "Read a saved report or, if it doesn't exist yet, create a new one.\n\nThe returned report can be used as a context manager, in which case any\nchanges to the report are saved when exiting the context block.\n\nParameters\n----------\nfname : path-like\n    The file containing the report, stored in the HDF5 format. If the file\n    does not exist yet, a new report is created that will be saved to the\n    specified file.\n**params : kwargs\n    When creating a new report, any named parameters other than ``fname``\n    are passed to the ``__init__`` function of the `Report` object. When\n    reading an existing report, the parameters are checked with the\n    loaded report and an exception is raised when they don't match.\n\nReturns\n-------\nreport : instance of Report\n    The report.", "metadata": {}}
{"_id": "mne_mne_report/report.py_copy_doc", "text": "Return a deepcopy of the report.\n\nReturns\n-------\nreport : instance of Report\n    The copied report.", "metadata": {}}
{"_id": "mne_mne_report/report.py_get_contents_doc", "text": "Get the content of the report.\n\nReturns\n-------\ntitles : list of str\n    The title of each content element.\ntags : list of list of str\n    The tags for each content element, one list per element.\nhtmls : list of str\n    The HTML contents for each element.\n\nNotes\n-----\n.. versionadded:: 1.7", "metadata": {}}
{"_id": "mne_mne_report/report.py_reorder_doc", "text": "Reorder the report content.\n\nParameters\n----------\norder : array-like of int\n    The indices of the new order (as if you were reordering an array).\n    For example if there are 4 elements in the report,\n    ``order=[3, 0, 1, 2]`` would take the last element and move it to\n    the front. In other words, ``elements = [elements[ii] for ii in order]]``.\n\nNotes\n-----\n.. versionadded:: 1.7", "metadata": {}}
{"_id": "mne_mne_report/report.py_html_doc", "text": "A list of HTML representations for all content elements.", "metadata": {}}
{"_id": "mne_mne_report/report.py_tags_doc", "text": "A sorted tuple of all tags currently used in the report.", "metadata": {}}
{"_id": "mne_mne_report/report.py_add_custom_css_doc", "text": "Add custom CSS to the report.\n\nParameters\n----------\ncss : str\n    Style definitions to add to the report. The content of this string\n    will be embedded between HTML ``<style>`` and ``</style>`` tags.\n\nNotes\n-----\n.. versionadded:: 0.23", "metadata": {}}
{"_id": "mne_mne_report/report.py_add_custom_js_doc", "text": "Add custom JavaScript to the report.\n\nParameters\n----------\njs : str\n    JavaScript code to add to the report. The content of this string\n    will be embedded between HTML ``<script>`` and ``</script>`` tags.\n\nNotes\n-----\n.. versionadded:: 0.23", "metadata": {}}
{"_id": "mne_mne_report/report.py_add_epochs_doc", "text": "Add `~mne.Epochs` to the report.\n\nParameters\n----------\nepochs : path-like | instance of Epochs\n    The epochs to add to the report.\ntitle : str\n    The title to add.\npsd : bool | float\n    If a float, the duration of data to use for creation of PSD plots,\n    in seconds. PSD will be calculated on as many epochs as required to\n    cover at least this duration. Epochs will be picked across the\n    entire time range in equally-spaced distance.\n\n    .. note::\n      In rare edge cases, we may not be able to create a grid of\n      equally-spaced epochs that cover the entire requested time range.\n      In these situations, a warning will be emitted, informing you\n      about the duration that's actually being used.\n\n    If ``True``, add PSD plots based on all ``epochs``. If ``False``,\n    do not add PSD plots.\n%(projs_report)s\nimage_kwargs : dict | None\n    Keyword arguments to pass to the \"epochs image\"-generating\n    function (:meth:`mne.Epochs.plot_image`).\n    Keys are channel types, values are dicts containing kwargs to pass.\n    For example, to use the rejection limits per channel type you could pass::\n\n        image_kwargs=dict(\n            grad=dict(vmin=-reject['grad'], vmax=-reject['grad']),\n            mag=dict(vmin=-reject['mag'], vmax=reject['mag']),\n        )\n\n    .. versionadded:: 1.7\n%(topomap_kwargs)s\ndrop_log_ignore : array-like of str\n    The drop reasons to ignore when creating the drop log bar plot.\n    All epochs for which a drop reason listed here appears in\n    ``epochs.drop_log`` will be excluded from the drop log plot.\n%(tags_report)s\n%(replace_report)s\n\nNotes\n-----\n.. versionadded:: 0.24", "metadata": {}}
{"_id": "mne_mne_report/report.py_add_evokeds_doc", "text": "Add `~mne.Evoked` objects to the report.\n\nParameters\n----------\nevokeds : path-like | instance of Evoked | list of Evoked\n    The evoked data to add to the report. Multiple `~mne.Evoked`\n    objects \u2013 as returned from `mne.read_evokeds` \u2013 can be passed as\n    a list.\ntitles : str | list of str | None\n    The titles corresponding to the evoked data. If ``None``, the\n    content of ``evoked.comment`` from each evoked will be used as\n    title.\nnoise_cov : path-like | instance of Covariance | None\n    A noise covariance matrix. If provided, will be used to whiten\n    the ``evokeds``. If ``None``, will fall back to the ``cov_fname``\n    provided upon report creation.\n%(projs_report)s\nn_time_points : int | None\n    The number of equidistant time points to render. If ``None``,\n    will render each `~mne.Evoked` at 21 time points, unless the data\n    contains fewer time points, in which case all will be rendered.\n%(tags_report)s\n%(replace_report)s\n%(topomap_kwargs)s\n%(n_jobs)s\n\nNotes\n-----\n.. versionadded:: 0.24.0", "metadata": {}}
{"_id": "mne_mne_report/report.py_add_raw_doc", "text": "Add `~mne.io.Raw` objects to the report.\n\nParameters\n----------\nraw : path-like | instance of Raw\n    The data to add to the report.\ntitle : str\n    The title corresponding to the ``raw`` object.\npsd : bool | None\n    Whether to add PSD plots. Overrides the ``raw_psd`` parameter\n    passed when initializing the `~mne.Report`. If ``None``, use\n    ``raw_psd`` from `~mne.Report` creation.\n%(projs_report)s\nbutterfly : bool | int\n    Whether to add butterfly plots of the data. Can be useful to\n    spot problematic channels. If ``True``, 10 equally-spaced 1-second\n    segments will be plotted. If an integer, specifies the number of\n    1-second segments to plot. Larger numbers may take a considerable\n    amount of time if the data contains many sensors. You can disable\n    butterfly plots altogether by passing ``False``.\n%(scalings)s\n%(tags_report)s\n%(replace_report)s\n%(topomap_kwargs)s\n\nNotes\n-----\n.. versionadded:: 0.24.0", "metadata": {}}
{"_id": "mne_mne_report/report.py_add_stc_doc", "text": "Add a `~mne.SourceEstimate` (STC) to the report.\n\nParameters\n----------\nstc : path-like | instance of SourceEstimate\n    The `~mne.SourceEstimate` to add to the report.\ntitle : str\n    The title to add.\nsubject : str | None\n    The name of the FreeSurfer subject the STC belongs to. The name is\n    not stored with the STC data and therefore needs to be specified.\n    If ``None``, will use the value of ``subject`` passed on report\n    creation.\nsubjects_dir : path-like | None\n    The FreeSurfer ``SUBJECTS_DIR``.\nn_time_points : int | None\n    The number of equidistant time points to render. If ``None``,\n    will render ``stc`` at 51 time points, unless the data\n    contains fewer time points, in which case all will be rendered.\n%(tags_report)s\n%(replace_report)s\n%(section_report)s\n\n    .. versionadded:: 1.9\n%(stc_plot_kwargs_report)s\n\nNotes\n-----\n.. versionadded:: 0.24.0", "metadata": {}}
{"_id": "mne_mne_report/report.py_add_forward_doc", "text": "Add a forward solution.\n\nParameters\n----------\nforward : instance of Forward | path-like\n    The forward solution to add to the report.\ntitle : str\n    The title corresponding to forward solution.\nsubject : str | None\n    The name of the FreeSurfer subject ``forward`` belongs to. If\n    provided, the sensitivity maps of the forward solution will\n    be visualized. If ``None``, will use the value of ``subject``\n    passed on report creation. If supplied, also pass ``subjects_dir``.\nsubjects_dir : path-like | None\n    The FreeSurfer ``SUBJECTS_DIR``.\n%(tags_report)s\n%(section_report)s\n\n    .. versionadded:: 1.9\n%(replace_report)s\n\nNotes\n-----\n.. versionadded:: 0.24.0", "metadata": {}}
{"_id": "mne_mne_report/report.py_add_inverse_operator_doc", "text": "Add an inverse operator.\n\nParameters\n----------\ninverse_operator : instance of InverseOperator | path-like\n    The inverse operator to add to the report.\ntitle : str\n    The title corresponding to the inverse operator object.\nsubject : str | None\n    The name of the FreeSurfer subject ``inverse_op`` belongs to. If\n    provided, the source space the inverse solution is based on will\n    be visualized. If ``None``, will use the value of ``subject``\n    passed on report creation. If supplied, also pass ``subjects_dir``\n    and ``trans``.\nsubjects_dir : path-like | None\n    The FreeSurfer ``SUBJECTS_DIR``.\ntrans : path-like | instance of Transform | None\n    The ``head -> MRI`` transformation for ``subject``.\n%(tags_report)s\n%(section_report)s\n\n    .. versionadded:: 1.9\n%(replace_report)s\n\nNotes\n-----\n.. versionadded:: 0.24.0", "metadata": {}}
{"_id": "mne_mne_report/report.py_add_trans_doc", "text": "Add a coregistration visualization to the report.\n\nParameters\n----------\n%(trans)s \"auto\" will load trans from the FreeSurfer directory\n    specified by ``subject`` and ``subjects_dir`` parameters.\n\n    .. versionchanged:: 1.10\n        Support for 'fsaverage' argument.\ninfo : path-like | instance of Info\n    The `~mne.Info` corresponding to ``trans``.\ntitle : str\n    The title to add.\nsubject : str | None\n    The name of the FreeSurfer subject the ``trans`` belongs to. The\n    name is not stored with the ``trans`` and therefore needs to be\n    specified. If ``None``, will use the value of ``subject`` passed on\n    report creation.\nsubjects_dir : path-like | None\n    The FreeSurfer ``SUBJECTS_DIR``.\nalpha : float | None\n    The level of opacity to apply to the head surface. If a float, must\n    be between 0 and 1 (inclusive), where 1 means fully opaque. If\n    ``None``, will use the MNE-Python default value.\n%(tags_report)s\n%(section_report)s\n\n    .. versionadded:: 1.9\ncoord_frame : 'auto' | 'head' | 'meg' | 'mri'\n    Coordinate frame used for plotting. See :func:`mne.viz.plot_alignment`.\n%(replace_report)s\n\nNotes\n-----\n.. versionadded:: 0.24.0", "metadata": {}}
{"_id": "mne_mne_report/report.py_add_covariance_doc", "text": "Add covariance to the report.\n\nParameters\n----------\ncov : path-like | instance of Covariance\n    The `~mne.Covariance` to add to the report.\ninfo : path-like | instance of Info\n    The `~mne.Info` corresponding to ``cov``.\ntitle : str\n    The title corresponding to the `~mne.Covariance` object.\n%(tags_report)s\n%(replace_report)s\n\nNotes\n-----\n.. versionadded:: 0.24.0", "metadata": {}}
{"_id": "mne_mne_report/report.py_add_events_doc", "text": "Add events to the report.\n\nParameters\n----------\nevents : path-like | array, shape (n_events, 3)\n    An MNE-Python events array.\ntitle : str\n    The title corresponding to the events.\nevent_id : dict\n    A dictionary mapping event names (keys) to event codes (values).\nsfreq : float\n    The sampling frequency used while recording.\nfirst_samp : int\n    The first sample point in the recording. This corresponds to\n    ``raw.first_samp`` on files created with Elekta/Neuromag systems.\ncolor : dict | None\n    Dictionary of event_id integers as keys and colors as values. This\n    parameter is directly passed to :func:`mne.viz.plot_events`.\n\n    .. versionadded:: 1.8.0\n%(tags_report)s\n%(section_report)s\n\n    .. versionadded:: 1.9\n%(replace_report)s\n\nNotes\n-----\n.. versionadded:: 0.24.0", "metadata": {}}
{"_id": "mne_mne_report/report.py_add_projs_doc", "text": "Render (SSP) projection vectors.\n\nParameters\n----------\ninfo : instance of Info | instance of Evoked | path-like\n    An `~mne.Info` structure or the path of a file containing one.\ntitle : str\n    The title corresponding to the :class:`~mne.Projection` object.\nprojs : iterable of mne.Projection | path-like | None\n    The projection vectors to add to the report. Can be the path to a\n    file that will be loaded via `mne.read_proj`. If ``None``, the\n    projectors are taken from ``info['projs']``.\n%(topomap_kwargs)s\n%(tags_report)s\njoint : bool\n    If True (default False), plot the projectors using\n    :func:`mne.viz.plot_projs_joint`, otherwise use\n    :func:`mne.viz.plot_projs_topomap`. If True, then ``info`` must be an\n    instance of :class:`mne.Evoked`.\n\n    .. versionadded:: 1.9\n%(picks_plot_projs_joint_trace)s\n    Only used when ``joint=True``.\n\n    .. versionadded:: 1.9\n%(section_report)s\n\n    .. versionadded:: 1.9\n%(replace_report)s\n\nNotes\n-----\n.. versionadded:: 0.24.0", "metadata": {}}
{"_id": "mne_mne_report/report.py_add_ica_doc", "text": "Add (a fitted) `~mne.preprocessing.ICA` to the report.\n\nParameters\n----------\nica : path-like | instance of mne.preprocessing.ICA\n    The fitted ICA to add.\ntitle : str\n    The title to add.\ninst : path-like | mne.io.Raw | mne.Epochs | None\n    The data to use for visualization of the effects of ICA cleaning.\n    To only plot the ICA component topographies, explicitly pass\n    ``None``.\n%(picks_ica)s This only affects the behavior of the component\n    topography and properties plots.\necg_evoked, eog_evoked : path-line | mne.Evoked | None\n    Evoked signal based on ECG and EOG epochs, respectively. If passed,\n    will be used to visualize the effects of artifact rejection.\necg_scores, eog_scores : array of float | list of array of float | None\n    The scores produced by :meth:`mne.preprocessing.ICA.find_bads_ecg`\n    and :meth:`mne.preprocessing.ICA.find_bads_eog`, respectively.\n    If passed, will be used to visualize the scoring for each ICA\n    component.\n%(n_jobs)s\n%(tags_report)s\n%(replace_report)s\n\nNotes\n-----\n.. versionadded:: 0.24.0", "metadata": {}}
{"_id": "mne_mne_report/report.py_remove_doc", "text": "Remove elements from the report.\n\nThe element to remove is searched for by its title. Optionally, tags\nmay be specified as well to narrow down the search to elements that\nhave the supplied tags.\n\nParameters\n----------\ntitle : str\n    The title of the element(s) to remove.\n\n    .. versionadded:: 0.24.0\ntags : array-like of str | str | None\n     If supplied, restrict the operation to elements with the supplied\n     tags.\n\n    .. versionadded:: 0.24.0\nremove_all : bool\n    Controls the behavior if multiple elements match the search\n    criteria. If ``False`` (default) only the element last added to the\n    report will be removed. If ``True``, all matches will be removed.\n\n    .. versionadded:: 0.24.0\n\nReturns\n-------\nremoved_index : int | tuple of int | None\n    The indices of the elements that were removed, or ``None`` if no\n    element matched the search criteria. A tuple will always be\n    returned if ``remove_all`` was set to ``True`` and at least one\n    element was removed.\n\n    .. versionchanged:: 0.24.0\n       Returns tuple if ``remove_all`` is ``True``.", "metadata": {}}
{"_id": "mne_mne_report/report.py_add_code_doc", "text": "Add a code snippet (e.g., an analysis script) to the report.\n\nParameters\n----------\ncode : str | pathlib.Path\n    The code to add to the report as a string, or the path to a file\n    as a `pathlib.Path` object.\n\n    .. note:: Paths must be passed as `pathlib.Path` object, since\n              strings will be treated as literal code.\ntitle : str\n    The title corresponding to the code.\nlanguage : str\n    The programming language of ``code``. This will be used for syntax\n    highlighting. Can be ``'auto'`` to try to auto-detect the language.\n%(tags_report)s\n%(section_report)s\n\n    .. versionadded:: 1.9\n%(replace_report)s\n\nNotes\n-----\n.. versionadded:: 0.24.0", "metadata": {}}
{"_id": "mne_mne_report/report.py_add_sys_info_doc", "text": "Add a MNE-Python system information to the report.\n\nThis is a convenience method that captures the output of\n`mne.sys_info` and adds it to the report.\n\nParameters\n----------\ntitle : str\n    The title to assign.\n%(tags_report)s\n%(replace_report)s\n\nNotes\n-----\n.. versionadded:: 0.24.0", "metadata": {}}
{"_id": "mne_mne_report/report.py_add_figure_doc", "text": "Add figures to the report.\n\nParameters\n----------\nfig : matplotlib.figure.Figure | Figure3D | array | array-like of matplotlib.figure.Figure | array-like of Figure3D | array-like of array\n    One or more figures to add to the report. All figures must be an\n    instance of :class:`matplotlib.figure.Figure`,\n    :class:`mne.viz.Figure3D`, or :class:`numpy.ndarray`. If\n    multiple figures are passed, they will be added as \"slides\"\n    that can be navigated using buttons and a slider element.\ntitle : str\n    The title corresponding to the figure(s).\ncaption : str | array-like of str | None\n    The caption(s) to add to the figure(s).\n%(image_format_report)s\n%(tags_report)s\n%(section_report)s\n%(replace_report)s\n\nNotes\n-----\n.. versionadded:: 0.24.0", "metadata": {}}
{"_id": "mne_mne_report/report.py_add_image_doc", "text": "Add an image (e.g., PNG or JPEG pictures) to the report.\n\nParameters\n----------\nimage : path-like\n    The image to add.\ntitle : str\n    Title corresponding to the images.\ncaption : str | None\n    If not ``None``, the caption to add to the image.\n%(tags_report)s\n%(section_report)s\n%(replace_report)s\n\nNotes\n-----\n.. versionadded:: 0.24.0", "metadata": {}}
{"_id": "mne_mne_report/report.py_add_html_doc", "text": "Add HTML content to the report.\n\nParameters\n----------\nhtml : str\n    The HTML content to add.\ntitle : str\n    The title corresponding to ``html``.\n%(tags_report)s\n%(section_report)s\n\n    .. versionadded:: 1.3\n%(replace_report)s\n\nNotes\n-----\n.. versionadded:: 0.24.0", "metadata": {}}
{"_id": "mne_mne_report/report.py_add_bem_doc", "text": "Render a visualization of the boundary element model (BEM) surfaces.\n\nParameters\n----------\nsubject : str\n    The FreeSurfer subject name.\ntitle : str\n    The title corresponding to the BEM image.\n%(subjects_dir)s\ndecim : int\n    Use this decimation factor for generating MRI/BEM images\n    (since it can be time consuming).\nwidth : int\n    The width of the MRI images (in pixels). Larger values will have\n    clearer surface lines, but will create larger HTML files.\n    Typically a factor of 2 more than the number of MRI voxels along\n    each dimension (typically 512, default) is reasonable.\n%(n_jobs)s\n%(tags_report)s\n%(section_report)s\n\n    .. versionadded:: 1.9\n%(replace_report)s\n\nNotes\n-----\n.. versionadded:: 0.24.0", "metadata": {}}
{"_id": "mne_mne_report/report.py_parse_folder_doc", "text": "Render all the files in the folder.\n\nParameters\n----------\ndata_path : path-like\n    Path to the folder containing data whose HTML report will be created.\npattern : None | str | list of str\n    Filename global pattern(s) to include in the report.\n    For example, ``['\\*raw.fif', '\\*ave.fif']`` will include\n    :class:`~mne.io.Raw` as well as :class:`~mne.Evoked` files. If ``None``,\n    include all supported file formats.\n\n    .. versionchanged:: 0.23\n       Include supported non-FIFF files by default.\n%(n_jobs)s\nmri_decim : int\n    Use this decimation factor for generating MRI/BEM images\n    (since it can be time consuming).\nsort_content : bool\n    If ``True``, sort the content based on tags in the order:\n    raw -> events -> epochs -> evoked -> covariance -> coregistration\n    -> bem -> forward-solution -> inverse-operator -> source-estimate.\n\n    .. versionadded:: 0.24.0\non_error : ``'ignore'`` | ``'warn'`` | ``'raise'``\n    What to do if a file cannot be rendered. Can be ``'ignore'``, ``'warn'``\n    (default), or ``'raise'``.\n%(image_format_report)s\n\n    .. versionadded:: 0.15\nrender_bem : bool\n    If True (default), try to render the BEM.\n\n    .. versionadded:: 0.16\nn_time_points_evokeds, n_time_points_stcs : int | None\n    The number of equidistant time points to render for :class:`~mne.Evoked`\n    and :class:`~mne.SourceEstimate` data, respectively. If ``None``,\n    will render each :class:`~mne.Evoked` at 21 and each\n    :class:`~mne.SourceEstimate` at 51 time points, unless the respective data\n    contains fewer time points, in which case all will be rendered.\n\n    .. versionadded:: 0.24.0\nraw_butterfly : bool\n    Whether to render butterfly plots for (decimated) :class:`~mne.io.Raw` data.\n\n    .. versionadded:: 0.24.0\n%(stc_plot_kwargs_report)s\n\n    .. versionadded:: 0.24.0\n%(topomap_kwargs)s\n\n    .. versionadded:: 0.24.0\n%(verbose)s", "metadata": {}}
{"_id": "mne_mne_report/report.py_save_doc", "text": "Save the report and optionally open it in browser.\n\nParameters\n----------\nfname : path-like | None\n    Output filename. If the name ends with ``.h5`` or ``.hdf5``, the\n    report is saved in HDF5 format, so it can later be loaded again\n    with :func:`open_report`. For any other suffix, the report will be\n    saved in HTML format. If ``None`` and :meth:`Report.parse_folder`\n    was **not** called, the report is saved as ``report.html`` in the\n    current working directory. If ``None`` and\n    :meth:`Report.parse_folder` **was** used, the report is saved as\n    ``report.html`` inside the ``data_path`` supplied to\n    :meth:`Report.parse_folder`.\nopen_browser : bool\n    Whether to open the rendered HTML report in the default web browser\n    after saving. This is ignored when writing an HDF5 file.\n%(overwrite)s\nsort_content : bool\n    If ``True``, sort the content based on tags before saving in the\n    order:\n    raw -> events -> epochs -> evoked -> covariance -> coregistration\n    -> bem -> forward-solution -> inverse-operator -> source-estimate.\n\n    .. versionadded:: 0.24.0\n%(verbose)s\n\nReturns\n-------\nfname : str\n    The file name to which the report was saved.", "metadata": {}}
{"_id": "mne_mne_export/_egimff.py_export_evokeds_mff_doc", "text": "Export evoked dataset to MFF.\n\n%(export_warning)s\n\nParameters\n----------\n%(fname_export_params)s\nevoked : list of Evoked instances\n    List of evoked datasets to export to one file. Note that the\n    measurement info from the first evoked instance is used, so be sure\n    that information matches.\nhistory : None (default) | list of dict\n    Optional list of history entries (dictionaries) to be written to\n    history.xml. This must adhere to the format described in\n    mffpy.xml_files.History.content. If None, no history.xml will be\n    written.\n%(overwrite)s\n\n    .. versionadded:: 0.24.1\n%(verbose)s\n\nNotes\n-----\n.. versionadded:: 0.24\n\n%(export_warning_note_evoked)s\n\nOnly EEG channels are written to the output file.\n``info['device_info']['type']`` must be a valid MFF recording device\n(e.g. 'HydroCel GSN 256 1.0'). This field is automatically populated when\nusing MFF read functions.", "metadata": {}}
{"_id": "mne_mne_export/_export.py_export_raw_doc", "text": "Export Raw to external formats.\n\n%(export_fmt_support_raw)s\n\n%(export_warning)s\n\n.. warning::\n    When exporting ``Raw`` with annotations, ``raw.info[\"meas_date\"]`` must be the\n    same as ``raw.annotations.orig_time``. This guarantees that the annotations are\n    in the same reference frame as the samples. When\n    :attr:`Raw.first_time <mne.io.Raw.first_time>` is not zero (e.g., after\n    cropping), the onsets are automatically corrected so that onsets are always\n    relative to the first sample.\n\nParameters\n----------\n%(fname_export_params)s\nraw : instance of Raw\n    The raw instance to export.\n%(export_fmt_params_raw)s\n%(physical_range_export_params)s\n%(add_ch_type_export_params)s\n%(overwrite)s\n\n    .. versionadded:: 0.24.1\n%(verbose)s\n\nNotes\n-----\n.. versionadded:: 0.24\n\n%(export_warning_note_raw)s\n%(export_eeglab_note)s\n%(export_edf_note)s", "metadata": {}}
{"_id": "mne_mne_export/_export.py_export_epochs_doc", "text": "Export Epochs to external formats.\n\n%(export_fmt_support_epochs)s\n\n%(export_warning)s\n\nParameters\n----------\n%(fname_export_params)s\nepochs : instance of Epochs\n    The epochs to export.\n%(export_fmt_params_epochs)s\n%(overwrite)s\n\n    .. versionadded:: 0.24.1\n%(verbose)s\n\nNotes\n-----\n.. versionadded:: 0.24\n\n%(export_warning_note_epochs)s\n%(export_eeglab_note)s", "metadata": {}}
{"_id": "mne_mne_export/_export.py_export_evokeds_doc", "text": "Export evoked dataset to external formats.\n\nThis function is a wrapper for format-specific export functions. The export\nfunction is selected based on the inferred file format. For additional\noptions, use the format-specific functions.\n\n%(export_fmt_support_evoked)s\n\n%(export_warning)s\n\nParameters\n----------\n%(fname_export_params)s\nevoked : Evoked instance, or list of Evoked instances\n    The evoked dataset, or list of evoked datasets, to export to one file.\n    Note that the measurement info from the first evoked instance is used,\n    so be sure that information matches.\n%(export_fmt_params_evoked)s\n%(overwrite)s\n\n    .. versionadded:: 0.24.1\n%(verbose)s\n\nSee Also\n--------\nmne.write_evokeds\nmne.export.export_evokeds_mff\n\nNotes\n-----\n.. versionadded:: 0.24\n\n%(export_warning_note_evoked)s", "metadata": {}}
{"_id": "mne_mne_datasets/_fetch.py_fetch_dataset_doc", "text": "Fetch an MNE-compatible dataset using pooch.\n\nParameters\n----------\ndataset_params : list of dict | dict\n    The dataset name(s) and corresponding parameters to download the\n    dataset(s). The dataset parameters that contains the following keys:\n    ``archive_name``, ``url``, ``folder_name``, ``hash``,\n    ``config_key`` (optional). See Notes.\nprocessor : None | \"unzip\" | \"untar\" | instance of pooch.Unzip | instance of pooch.Untar\n    What to do after downloading the file. ``\"unzip\"`` and ``\"untar\"`` will\n    decompress the downloaded file in place; for custom extraction (e.g.,\n    only extracting certain files from the archive) pass an instance of\n    ``pooch.Unzip`` or ``pooch.Untar``. If ``None`` (the\n    default), the files are left as-is.\npath : None | str\n    Directory in which to put the dataset. If ``None``, the dataset\n    location is determined by first checking whether\n    ``dataset_params['config_key']`` is defined, and if so, whether that\n    config key exists in the MNE-Python config file. If so, the configured\n    path is used; if not, the location is set to the value of the\n    ``MNE_DATA`` config key (if it exists), or ``~/mne_data`` otherwise.\nforce_update : bool\n    Force update of the dataset even if a local copy exists.\n    Default is False.\nupdate_path : bool | None\n    If True (default), set the mne-python config to the given\n    path. If None, the user is prompted.\ndownload : bool\n    If False and the dataset has not been downloaded yet, it will not be\n    downloaded and the path will be returned as ``''`` (empty string). This\n    is mostly used for testing purposes and can be safely ignored by most\n    users.\ncheck_version : bool\n    Whether to check the version of the dataset or not. Each version\n    of the dataset is stored in the root with a ``version.txt`` file.\nreturn_version : bool\n    Whether or not to return the version of the dataset or not.\n    Defaults to False.\naccept : bool\n    Some MNE-supplied datasets require acceptance of an additional license.\n    Default is ``False``.\nauth : tuple | None\n    Optional authentication tuple containing the username and\n    password/token, passed to ``pooch.HTTPDownloader`` (e.g.,\n    ``auth=('foo', 012345)``).\ntoken : str | None\n    Optional authentication token passed to ``pooch.HTTPDownloader``.\n\nReturns\n-------\ndata_path : instance of Path\n    The path to the fetched dataset.\nversion : str\n    Only returned if ``return_version`` is True.\n\nSee Also\n--------\nmne.get_config\nmne.set_config\nmne.datasets.has_dataset\n\nNotes\n-----\nThe ``dataset_params`` argument must contain the following keys:\n\n- ``archive_name``: The name of the (possibly compressed) file to download\n- ``url``: URL from which the file can be downloaded\n- ``folder_name``: the subfolder within the ``MNE_DATA`` folder in which to\n    save and uncompress (if needed) the file(s)\n- ``hash``: the cryptographic hash type of the file followed by a colon and\n    then the hash value (examples: \"sha256:19uheid...\", \"md5:upodh2io...\")\n- ``config_key`` (optional): key passed to :func:`mne.set_config` to store\n    the on-disk location of the downloaded dataset (e.g.,\n    ``\"MNE_DATASETS_EEGBCI_PATH\"``). This will only work for the provided\n    datasets listed :ref:`here <datasets>`; do not use for user-defined\n    datasets.\n\nAn example would look like::\n\n    {'dataset_name': 'sample',\n     'archive_name': 'MNE-sample-data-processed.tar.gz',\n     'hash': 'md5:12b75d1cb7df9dfb4ad73ed82f61094f',\n     'url': 'https://osf.io/86qa2/download?version=5',\n     'folder_name': 'MNE-sample-data',\n     'config_key': 'MNE_DATASETS_SAMPLE_PATH'}\n\nFor datasets where a single (possibly compressed) file must be downloaded,\npass a single :class:`dict` as ``dataset_params``. For datasets where\nmultiple files must be downloaded and (optionally) uncompressed separately,\npass a list of dicts.", "metadata": {}}
{"_id": "mne_mne_datasets/utils.py_default_path_doc", "text": "Get the default MNE_DATA path.\n\nParameters\n----------\n%(verbose)s\n\nReturns\n-------\ndata_path : instance of Path\n    Path to the default MNE_DATA directory.", "metadata": {}}
{"_id": "mne_mne_datasets/utils.py_has_dataset_doc", "text": "Check for presence of a dataset.\n\nParameters\n----------\nname : str | dict\n    The dataset to check. Strings refer to one of the supported datasets\n    listed :ref:`here <datasets>`. A :class:`dict` can be used to check for\n    user-defined datasets (see the Notes section of :func:`fetch_dataset`),\n    and must contain keys ``dataset_name``, ``archive_name``, ``url``,\n    ``folder_name``, ``hash``.\n\nReturns\n-------\nhas : bool\n    True if the dataset is present.", "metadata": {}}
{"_id": "mne_mne_datasets/utils.py_fetch_aparc_sub_parcellation_doc", "text": "Fetch the modified subdivided aparc parcellation.\n\nThis will download and install the subdivided aparc parcellation\n:footcite:'KhanEtAl2018' files for\nFreeSurfer's fsaverage to the specified directory.\n\nParameters\n----------\nsubjects_dir : path-like | None\n    The subjects directory to use. The file will be placed in\n    ``subjects_dir + '/fsaverage/label'``.\n%(verbose)s\n\nReferences\n----------\n.. footbibliography::", "metadata": {}}
{"_id": "mne_mne_datasets/utils.py_fetch_hcp_mmp_parcellation_doc", "text": "Fetch the HCP-MMP parcellation.\n\nThis will download and install the HCP-MMP parcellation\n:footcite:`GlasserEtAl2016` files for FreeSurfer's fsaverage\n:footcite:`Mills2016` to the specified directory.\n\nParameters\n----------\nsubjects_dir : path-like | None\n    The subjects directory to use. The file will be placed in\n    ``subjects_dir + '/fsaverage/label'``.\ncombine : bool\n    If True, also produce the combined/reduced set of 23 labels per\n    hemisphere as ``HCPMMP1_combined.annot``\n    :footcite:`GlasserEtAl2016supp`.\n%(accept)s\n%(verbose)s\n\nNotes\n-----\nUse of this parcellation is subject to terms of use on the\n`HCP-MMP webpage <https://balsa.wustl.edu/WN56>`_.\n\nReferences\n----------\n.. footbibliography::", "metadata": {}}
{"_id": "mne_mne_datasets/_fsaverage/base.py_fetch_fsaverage_doc", "text": "Fetch and update fsaverage.\n\nParameters\n----------\nsubjects_dir : str | None\n    The path to use as the subjects directory in the MNE-Python\n    config file. None will use the existing config variable (i.e.,\n    will not change anything), and if it does not exist, will use\n    ``~/mne_data/MNE-fsaverage-data``.\n%(verbose)s\n\nReturns\n-------\nfs_dir : Path\n    The fsaverage directory.\n    (essentially ``subjects_dir / 'fsaverage'``).\n\n    .. versionchanged:: 1.8\n       A :class:`pathlib.Path` object is returned instead of a string.\n\nNotes\n-----\nThis function is designed to provide\n\n1. All modern (Freesurfer 6) fsaverage subject files\n2. All MNE fsaverage parcellations\n3. fsaverage head surface, fiducials, head<->MRI trans, 1- and 3-layer\n   BEMs (and surfaces)\n\nThis function will compare the contents of ``subjects_dir/fsaverage``\nto the ones provided in the remote zip file. If any are missing,\nthe zip file is downloaded and files are updated. No files will\nbe overwritten.\n\n.. versionadded:: 0.18", "metadata": {}}
{"_id": "mne_mne_datasets/_infant/base.py_fetch_infant_template_doc", "text": "Fetch and update an infant MRI template.\n\nParameters\n----------\nage : str\n    Age to download. Can be one of ``{'2wk', '1mo', '2mo', '3mo', '4.5mo',\n    '6mo', '7.5mo', '9mo', '10.5mo', '12mo', '15mo', '18mo', '2yr'}``.\nsubjects_dir : str | None\n    The path to download the template data to.\n%(verbose)s\n\nReturns\n-------\nsubject : str\n    The standard subject name, e.g. ``ANTS4-5Month3T``.\n\nNotes\n-----\nIf you use these templates in your work, please cite\n:footcite:`OReillyEtAl2021` and :footcite:`RichardsEtAl2016`.\n\n.. versionadded:: 0.23\n\nReferences\n----------\n.. footbibliography::", "metadata": {}}
{"_id": "mne_mne_datasets/kiloword/kiloword.py_data_path_doc", "text": "Get path to local copy of the kiloword dataset.\n\nThis is the dataset from :footcite:`DufauEtAl2015`.\n\nParameters\n----------\npath : None | str\n    Location of where to look for the kiloword data storing\n    location. If None, the environment variable or config parameter\n    MNE_DATASETS_KILOWORD_PATH is used. If it doesn't exist,\n    the \"mne-python/examples\" directory is used. If the\n    kiloword dataset is not found under the given path (e.g.,\n    as \"mne-python/examples/MNE-kiloword-data\"), the data\n    will be automatically downloaded to the specified folder.\nforce_update : bool\n    Force update of the dataset even if a local copy exists.\nupdate_path : bool | None\n    If True, set the MNE_DATASETS_KILOWORD_PATH in mne-python\n    config to the given path. If None, the user is prompted.\ndownload : bool\n    If False and the kiloword dataset has not been downloaded yet,\n    it will not be downloaded and the path will be returned as\n    '' (empty string). This is mostly used for debugging purposes\n    and can be safely ignored by most users.\n%(verbose)s\n\nReturns\n-------\npath : list of Path\n    Local path to the given data file. This path is contained inside a list\n    of length one, for compatibility.\n\nReferences\n----------\n.. footbibliography::", "metadata": {}}
{"_id": "mne_mne_datasets/kiloword/kiloword.py_get_version_doc", "text": "Get dataset version.", "metadata": {}}
{"_id": "mne_mne_datasets/limo/limo.py_data_path_doc", "text": "Get path to local copy of LIMO dataset URL.\n\nThis is a low-level function useful for getting a local copy of the\nremote LIMO dataset :footcite:`Rousselet2016`. The complete dataset is\navailable at datashare.is.ed.ac.uk/.\n\nParameters\n----------\nsubject : int\n    Subject to download. Must be of :class:`\u00ecnt` in the range from 1\n    to 18 (inclusive).\npath : None | str\n    Location of where to look for the LIMO data storing directory.\n    If None, the environment variable or config parameter\n    ``MNE_DATASETS_LIMO_PATH`` is used. If it doesn't exist, the\n    \"~/mne_data\" directory is used. If the LIMO dataset\n    is not found under the given path, the data\n    will be automatically downloaded to the specified folder.\nforce_update : bool\n    Force update of the dataset even if a local copy exists.\nupdate_path : bool | None\n    If True, set the MNE_DATASETS_LIMO_PATH in mne-python\n    config to the given path. If None, the user is prompted.\n%(verbose)s\n\nReturns\n-------\npath : str\n    Local path to the given data file.\n\nNotes\n-----\nFor example, one could do:\n\n    >>> from mne.datasets import limo\n    >>> limo.data_path(subject=1, path=os.getenv('HOME') + '/datasets') # doctest:+SKIP\n\nThis would download the LIMO data file to the 'datasets' folder,\nand prompt the user to save the 'datasets' path to the mne-python config,\nif it isn't there already.\n\nReferences\n----------\n.. footbibliography::", "metadata": {}}
{"_id": "mne_mne_datasets/limo/limo.py_load_data_doc", "text": "Fetch subjects epochs data for the LIMO data set.\n\nParameters\n----------\nsubject : int\n    Subject to use. Must be of class \u00ecnt in the range from 1 to 18.\npath : str\n    Location of where to look for the LIMO data.\n    If None, the environment variable or config parameter\n    ``MNE_DATASETS_LIMO_PATH`` is used. If it doesn't exist, the\n    \"~/mne_data\" directory is used.\nforce_update : bool\n    Force update of the dataset even if a local copy exists.\nupdate_path : bool | None\n    If True, set the MNE_DATASETS_LIMO_PATH in mne-python\n    config to the given path. If None, the user is prompted.\n%(verbose)s\n\nReturns\n-------\nepochs : instance of Epochs\n    The epochs.", "metadata": {}}
{"_id": "mne_mne_datasets/_phantom/base.py_fetch_phantom_doc", "text": "Fetch and update a phantom subject.\n\nParameters\n----------\nkind : str\n    The kind of phantom to fetch. Can only be ``'otaniemi'`` (default).\n%(subjects_dir)s\n%(verbose)s\n\nReturns\n-------\nsubject_dir : pathlib.Path\n    The resulting phantom subject directory.\n\nSee Also\n--------\nmne.dipole.get_phantom_dipoles\n\nNotes\n-----\nThis function is designed to provide a head surface and T1.mgz for\nthe 32-dipole Otaniemi phantom. The VectorView/TRIUX phantom has the same\nbasic outside geometry, but different internal dipole positions.\n\nUnlike most FreeSurfer subjects, the Otaniemi phantom scan was aligned\nto the \"head\" coordinate frame, so an identity head<->MRI :term:`trans`\nis appropriate.\n\n.. versionadded:: 0.24", "metadata": {}}
{"_id": "mne_mne_datasets/sleep_physionet/age.py_fetch_data_doc", "text": "Get paths to local copies of PhysioNet Polysomnography dataset files.\n\nThis will fetch data from the publicly available subjects from PhysioNet's\nstudy of age effects on sleep in healthy subjects\n:footcite:`MourtazaevEtAl1995,GoldbergerEtAl2000`. This\ncorresponds to a subset of 153 recordings from 37 males and 41 females that\nwere 25-101 years old at the time of the recordings. There are two night\nrecordings per subject except for subjects 13, 36 and 52 which have one\nrecord missing each due to missing recording hardware.\n\nSee more details in\n`physionet website <https://physionet.org/physiobank/database/sleep-edfx/sleep-cassette/>`_.\n\nParameters\n----------\nsubjects : list of int\n    The subjects to use. Can be in the range of 0-82 (inclusive), however\n    the following subjects are not available: 39, 68, 69, 78 and 79.\nrecording : list of int\n    The night recording indices. Valid values are : [1], [2], or [1, 2].\n    The following recordings are not available: recording 1 for subject 36\n    and 52, and recording 2 for subject 13.\npath : None | str\n    Location of where to look for the PhysioNet data storing location.\n    If None, the environment variable or config parameter\n    ``PHYSIONET_SLEEP_PATH`` is used. If it doesn't exist, the \"~/mne_data\"\n    directory is used. If the Polysomnography dataset is not found under\n    the given path, the data will be automatically downloaded to the\n    specified folder.\nforce_update : bool\n    Force update of the dataset even if a local copy exists.\nbase_url : str\n    The URL root.\non_missing : 'raise' | 'warn' | 'ignore'\n    What to do if one or several recordings are not available. Valid keys\n    are 'raise' | 'warn' | 'ignore'. Default is 'error'. If on_missing\n    is 'warn' it will proceed but warn, if 'ignore' it will proceed\n    silently.\n%(verbose)s\n\nReturns\n-------\npaths : list\n    List of local data paths of the given type.\n\nSee Also\n--------\nmne.datasets.sleep_physionet.temazepam.fetch_data\n\nNotes\n-----\nFor example, one could do:\n\n    >>> from mne.datasets import sleep_physionet\n    >>> sleep_physionet.age.fetch_data(subjects=[0])  # doctest: +SKIP\n\nThis would download data for subject 0 if it isn't there already.\n\nReferences\n----------\n.. footbibliography::", "metadata": {}}
{"_id": "mne_mne_datasets/sleep_physionet/temazepam.py_fetch_data_doc", "text": "Get paths to local copies of PhysioNet Polysomnography dataset files.\n\nThis will fetch data from the publicly available subjects from PhysioNet's\nstudy of Temazepam effects on sleep :footcite:`KempEtAl2000`. This\ncorresponds to a set of 22 subjects. Subjects had mild difficulty falling\nasleep but were otherwise healthy.\n\nSee more details in the `physionet website\n<https://physionet.org/physiobank/database/sleep-edfx/>`_\n:footcite:`GoldbergerEtAl2000`.\n\nParameters\n----------\nsubjects : list of int\n    The subjects to use. Can be in the range of 0-21 (inclusive).\npath : None | str\n    Location of where to look for the PhysioNet data storing location.\n    If None, the environment variable or config parameter\n    ``PHYSIONET_SLEEP_PATH`` is used. If it doesn't exist, the \"~/mne_data\"\n    directory is used. If the Polysomnography dataset is not found under\n    the given path, the data will be automatically downloaded to the\n    specified folder.\nforce_update : bool\n    Force update of the dataset even if a local copy exists.\nbase_url : str\n    The base URL to download from.\n%(verbose)s\n\nReturns\n-------\npaths : list\n    List of local data paths of the given type.\n\nSee Also\n--------\nmne.datasets.sleep_physionet.age.fetch_data\n\nNotes\n-----\nFor example, one could do:\n\n    >>> from mne.datasets import sleep_physionet\n    >>> sleep_physionet.temazepam.fetch_data(subjects=[1]) # doctest: +SKIP\n\nThis would download data for subject 0 if it isn't there already.\n\nReferences\n----------\n.. footbibliography::", "metadata": {}}
{"_id": "mne_mne_datasets/testing/_testing.py_requires_testing_data_doc", "text": "Skip testing data test.", "metadata": {}}
{"_id": "mne_mne_datasets/eegbci/eegbci.py_data_path_doc", "text": "Get path to local copy of EEGMMI dataset URL.\n\nThis is a low-level function useful for getting a local copy of a remote EEGBCI\ndataset :footcite:`SchalkEtAl2004`, which is also available at PhysioNet\n:footcite:`GoldbergerEtAl2000`. Metadata, such as the meaning of event markers\nmay be obtained from the\n`PhysioNet documentation page <https://physionet.org/content/eegmmidb/1.0.0/>`_.\n\nParameters\n----------\nurl : str\n    The dataset to use.\npath : None | path-like\n    Location of where to look for the EEGBCI data. If ``None``, the environment\n    variable or config parameter ``MNE_DATASETS_EEGBCI_PATH`` is used. If neither\n    exists, the ``~/mne_data`` directory is used. If the EEGBCI dataset is not found\n    under the given path, the data will be automatically downloaded to the specified\n    folder.\nforce_update : bool\n    Force update of the dataset even if a local copy exists.\nupdate_path : bool | None\n    If ``True``, set ``MNE_DATASETS_EEGBCI_PATH`` in the configuration to the given\n    path. If ``None``, the user is prompted.\n%(verbose)s\n\nReturns\n-------\npath : list of Path\n    Local path to the given data file. This path is contained inside a list of\n    length one for compatibility.\n\nNotes\n-----\nFor example, one could do:\n\n    >>> from mne.datasets import eegbci\n    >>> url = \"http://www.physionet.org/physiobank/database/eegmmidb/\"\n    >>> eegbci.data_path(url, \"~/datasets\") # doctest:+SKIP\n\nThis would download the given EEGBCI data file to the ``~/datasets`` folder and\nprompt the user to store this path in the config (if it does not already exist).\n\nReferences\n----------\n.. footbibliography::", "metadata": {}}
{"_id": "mne_mne_datasets/eegbci/eegbci.py_load_data_doc", "text": "Get paths to local copies of EEGBCI dataset files.\n\nThis will fetch data for the EEGBCI dataset :footcite:`SchalkEtAl2004`, which is\nalso available at PhysioNet :footcite:`GoldbergerEtAl2000`. Metadata, such as the\nmeaning of event markers may be obtained from the\n`PhysioNet documentation page <https://physionet.org/content/eegmmidb/1.0.0/>`_.\n\nParameters\n----------\nsubjects : int | list of int\n    The subjects to use. Can be in the range of 1-109 (inclusive).\nruns : int | list of int\n    The runs to use (see Notes for details).\npath : None | path-like\n    Location of where to look for the EEGBCI data. If ``None``, the environment\n    variable or config parameter ``MNE_DATASETS_EEGBCI_PATH`` is used. If neither\n    exists, the ``~/mne_data`` directory is used. If the EEGBCI dataset is not found\n    under the given path, the data will be automatically downloaded to the specified\n    folder.\nforce_update : bool\n    Force update of the dataset even if a local copy exists.\nupdate_path : bool | None\n    If ``True``, set ``MNE_DATASETS_EEGBCI_PATH`` in the configuration to the given\n    path. If ``None``, the user is prompted.\nbase_url : str\n    The URL root for the data.\n%(verbose)s\n\nReturns\n-------\npaths : list\n    List of local data paths of the given type.\n\nNotes\n-----\nThe run numbers correspond to:\n\n=========  ===================================\nrun        task\n=========  ===================================\n1          Baseline, eyes open\n2          Baseline, eyes closed\n3, 7, 11   Motor execution: left vs right hand\n4, 8, 12   Motor imagery: left vs right hand\n5, 9, 13   Motor execution: hands vs feet\n6, 10, 14  Motor imagery: hands vs feet\n=========  ===================================\n\nFor example, one could do::\n\n    >>> from mne.datasets import eegbci\n    >>> eegbci.load_data([1, 2], [6, 10, 14], \"~/datasets\") # doctest:+SKIP\n\nThis would download runs 6, 10, and 14 (hand/foot motor imagery) runs from subjects\n1 and 2 in the EEGBCI dataset to \"~/datasets\" and prompt the user to store this path\nin the config (if it does not already exist).\n\nReferences\n----------\n.. footbibliography::", "metadata": {}}
{"_id": "mne_mne_datasets/eegbci/eegbci.py_standardize_doc", "text": "Standardize channel positions and names.\n\nParameters\n----------\nraw : instance of Raw\n    The raw data to standardize. Operates in-place.", "metadata": {}}
{"_id": "mne_mne_datasets/hf_sef/hf_sef.py_data_path_doc", "text": "Get path to local copy of the high frequency SEF dataset.\n\nGets a local copy of the high frequency SEF MEG dataset\n:footcite:`NurminenEtAl2017`.\n\nParameters\n----------\ndataset : 'evoked' | 'raw'\n    Whether to get the main dataset (evoked, structural and the rest) or\n    the separate dataset containing raw MEG data only.\npath : None | str\n    Where to look for the HF-SEF data storing location.\n    If None, the environment variable or config parameter\n    ``MNE_DATASETS_HF_SEF_PATH`` is used. If it doesn't exist, the\n    \"~/mne_data\" directory is used. If the HF-SEF dataset\n    is not found under the given path, the data\n    will be automatically downloaded to the specified folder.\nforce_update : bool\n    Force update of the dataset even if a local copy exists.\nupdate_path : bool | None\n    If True, set the MNE_DATASETS_HF_SEF_PATH in mne-python\n    config to the given path. If None, the user is prompted.\n%(verbose)s\n\nReturns\n-------\npath : str\n    Local path to the directory where the HF-SEF data is stored.\n\nReferences\n----------\n.. footbibliography::", "metadata": {}}
{"_id": "mne_mne_datasets/visual_92_categories/visual_92_categories.py_data_path_doc", "text": "Get path to local copy of visual_92_categories dataset.\n\n.. note:: The dataset contains four fif-files, the trigger files and the T1\n          mri image. This dataset is rather big in size (more than 5 GB).\n\nParameters\n----------\npath : None | str\n    Location of where to look for the visual_92_categories data storing\n    location. If None, the environment variable or config parameter\n    MNE_DATASETS_VISUAL_92_CATEGORIES_PATH is used. If it doesn't exist,\n    the \"mne-python/examples\" directory is used. If the\n    visual_92_categories dataset is not found under the given path (e.g.,\n    as \"mne-python/examples/MNE-visual_92_categories-data\"), the data\n    will be automatically downloaded to the specified folder.\nforce_update : bool\n    Force update of the dataset even if a local copy exists.\nupdate_path : bool | None\n    If True, set the MNE_DATASETS_VISUAL_92_CATEGORIES_PATH in mne-python\n    config to the given path. If None, the user is prompted.\n%(verbose)s\n\nReturns\n-------\npath : instance of Path\n    Local path to the given data file.\n\nNotes\n-----\nThe visual_92_categories dataset is documented in the following publication\n    Radoslaw M. Cichy, Dimitrios Pantazis, Aude Oliva (2014) Resolving\n    human object recognition in space and time. doi: 10.1038/NN.3635", "metadata": {}}
{"_id": "mne_mne_datasets/visual_92_categories/visual_92_categories.py_get_version_doc", "text": "Get dataset version.", "metadata": {}}
{"_id": "mne_mne_datasets/spm_face/spm_data.py_requires_spm_data_doc", "text": "Skip testing data test.", "metadata": {}}
{"_id": "mne_mne_datasets/brainstorm/bst_auditory.py_description_doc", "text": "Get description of brainstorm (bst_auditory) dataset.", "metadata": {}}
{"_id": "mne_mne_datasets/brainstorm/bst_phantom_ctf.py_description_doc", "text": "Get description of brainstorm (bst_phantom_ctf) dataset.", "metadata": {}}
{"_id": "mne_mne_datasets/brainstorm/bst_raw.py_description_doc", "text": "Get description of brainstorm (bst_raw) dataset.", "metadata": {}}
{"_id": "mne_mne_datasets/brainstorm/bst_raw.py_requires_bstraw_data_doc", "text": "Skip testing data test.", "metadata": {}}
{"_id": "mne_mne_datasets/brainstorm/bst_resting.py_description_doc", "text": "Get description of brainstorm (bst_resting) dataset.", "metadata": {}}
{"_id": "mne_mne_datasets/brainstorm/bst_phantom_elekta.py_description_doc", "text": "Get description of brainstorm (bst_phantom_elekta) dataset.", "metadata": {}}
{"_id": "mne_mne_time_frequency/spectrum.py_combine_spectrum_doc", "text": "Merge spectral data by weighted addition.\n\nCreate a new :class:`mne.time_frequency.Spectrum` instance, using a combination of\nthe supplied instances as its data. By default, the mean (weighted by trials) is\nused. Subtraction can be performed by passing negative weights (e.g., ``[1, -1]``).\nData must have the same channels and the same frequencies.\n\nParameters\n----------\nall_spectrum : list of Spectrum\n    The Spectrum objects.\nweights : list of float | str\n    The weights to apply to the data of each :class:`~mne.time_frequency.Spectrum`\n    instance, or a string describing the weighting strategy to apply: 'nave'\n    computes sum-to-one weights proportional to each object\u2019s nave attribute;\n    'equal' weights each :class:`~mne.time_frequency.Spectrum` by\n    ``1 / len(all_spectrum)``.\n\nReturns\n-------\nspectrum : Spectrum\n    The new spectral data.\n\nNotes\n-----\n.. versionadded:: 1.10.0", "metadata": {}}
{"_id": "mne_mne_time_frequency/spectrum.py_read_spectrum_doc", "text": "Load a :class:`mne.time_frequency.Spectrum` object from disk.\n\nParameters\n----------\nfname : path-like\n    Path to a spectrum file in HDF5 format, which should end with ``.h5`` or\n    ``.hdf5``.\n\nReturns\n-------\nspectrum : instance of Spectrum\n    The loaded Spectrum object.\n\nSee Also\n--------\nmne.time_frequency.Spectrum.save", "metadata": {}}
{"_id": "mne_mne_time_frequency/spectrum.py_plot_psd_doc", "text": "%(plot_psd_doc)s.\n\nParameters\n----------\n%(fmin_fmax_psd)s\n%(tmin_tmax_psd)s\n%(picks_good_data_noref)s\n%(proj_psd)s\n%(reject_by_annotation_psd)s\n%(method_plot_psd_auto)s\n%(average_plot_psd)s\n%(dB_plot_psd)s\n%(estimate_plot_psd)s\n%(xscale_plot_psd)s\n%(area_mode_plot_psd)s\n%(area_alpha_plot_psd)s\n%(color_plot_psd)s\n%(line_alpha_plot_psd)s\n%(spatial_colors_psd)s\n%(sphere_topomap_auto)s\n\n    .. versionadded:: 0.22.0\nexclude : list of str | 'bads'\n    Channels names to exclude from being shown. If 'bads', the bad\n    channels are excluded. Pass an empty list to plot all channels\n    (including channels marked \"bad\", if any).\n\n    .. versionadded:: 0.24.0\n%(ax_plot_psd)s\n%(show)s\n%(n_jobs)s\n%(verbose)s\n%(method_kw_psd)s\n\nReturns\n-------\nfig : instance of Figure\n    Figure with frequency spectra of the data channels.\n\nNotes\n-----\n%(notes_plot_psd_meth)s", "metadata": {}}
{"_id": "mne_mne_time_frequency/spectrum.py_plot_psd_topo_doc", "text": "Plot power spectral density, separately for each channel.\n\nParameters\n----------\n%(tmin_tmax_psd)s\n%(fmin_fmax_psd_topo)s\n%(proj_psd)s\n%(method_plot_psd_auto)s\n%(dB_spectrum_plot_topo)s\n%(layout_spectrum_plot_topo)s\n%(color_spectrum_plot_topo)s\n%(fig_facecolor)s\n%(axis_facecolor)s\n%(axes_spectrum_plot_topo)s\n%(block)s\n%(show)s\n%(n_jobs)s\n%(verbose)s\n%(method_kw_psd)s Defaults to ``dict(n_fft=2048)``.\n\nReturns\n-------\nfig : instance of matplotlib.figure.Figure\n    Figure distributing one image per channel across sensor topography.", "metadata": {}}
{"_id": "mne_mne_time_frequency/spectrum.py_plot_psd_topomap_doc", "text": "Plot scalp topography of PSD for chosen frequency bands.\n\nParameters\n----------\n%(bands_psd_topo)s\n%(tmin_tmax_psd)s\n%(ch_type_topomap_psd)s\n%(proj_psd)s\n%(method_plot_psd_auto)s\n%(normalize_psd_topo)s\n%(agg_fun_psd_topo)s\n%(dB_plot_topomap)s\n%(sensors_topomap)s\n%(show_names_topomap)s\n%(mask_evoked_topomap)s\n%(mask_params_topomap)s\n%(contours_topomap)s\n%(outlines_topomap)s\n%(sphere_topomap_auto)s\n%(image_interp_topomap)s\n%(extrapolate_topomap)s\n%(border_topomap)s\n%(res_topomap)s\n%(size_topomap)s\n%(cmap_topomap)s\n%(vlim_plot_topomap_psd)s\n%(cnorm)s\n\n    .. versionadded:: 1.2\n%(colorbar_topomap)s\n%(cbar_fmt_topomap_psd)s\n%(units_topomap)s\n%(axes_spectrum_plot_topomap)s\n%(show)s\n%(n_jobs)s\n%(verbose)s\n%(method_kw_psd)s\n\nReturns\n-------\nfig : instance of Figure\n    Figure showing one scalp topography per frequency band.", "metadata": {}}
{"_id": "mne_mne_time_frequency/spectrum.py_copy_doc", "text": "Return copy of the Spectrum instance.\n\nReturns\n-------\nspectrum : instance of Spectrum\n    A copy of the object.", "metadata": {}}
{"_id": "mne_mne_time_frequency/spectrum.py_get_data_doc", "text": "Get spectrum data in NumPy array format.\n\nParameters\n----------\n%(picks_good_data_noref)s\n%(exclude_spectrum_get_data)s\n%(fmin_fmax_psd)s\nreturn_freqs : bool\n    Whether to return the frequency bin values for the requested\n    frequency range. Default is ``False``.\n\nReturns\n-------\ndata : array\n    The requested data in a NumPy array.\nfreqs : array\n    The frequency values for the requested range. Only returned if\n    ``return_freqs`` is ``True``.", "metadata": {}}
{"_id": "mne_mne_time_frequency/spectrum.py_plot_doc", "text": "%(plot_psd_doc)s.\n\nParameters\n----------\n%(picks_all_data_noref)s\n\n    .. versionchanged:: 1.5\n        In version 1.5, the default behavior changed so that all\n        :term:`data channels` (not just \"good\" data channels) are shown by\n        default.\naverage : bool\n    Whether to average across channels before plotting. If ``True``, interactive\n    plotting of scalp topography is disabled, and parameters ``ci`` and\n    ``ci_alpha`` control the style of the confidence band around the mean.\n    Default is ``False``.\n%(dB_spectrum_plot)s\namplitude : bool\n    Whether to plot an amplitude spectrum (``True``) or power spectrum\n    (``False``).\n\n        .. versionchanged:: 1.8\n            In version 1.8, the default changed to ``amplitude=False``.\n%(xscale_plot_psd)s\nci : float | 'sd' | 'range' | None\n    Type of confidence band drawn around the mean when ``average=True``. If\n    ``'sd'`` the band spans \u00b11 standard deviation across channels. If\n    ``'range'`` the band spans the range across channels at each frequency. If a\n    :class:`float`, it indicates the (bootstrapped) confidence interval to\n    display, and must satisfy ``0 < ci <= 100``. If ``None``, no band is drawn.\n    Default is ``sd``.\nci_alpha : float\n    Opacity of the confidence band. Must satisfy ``0 <= ci_alpha <= 1``. Default\n    is 0.3.\n%(color_plot_psd)s\nalpha : float | None\n    Opacity of the spectrum line(s). If :class:`float`, must satisfy\n    ``0 <= alpha <= 1``. If ``None``, opacity will be ``1`` when\n    ``average=True`` and ``0.1`` when ``average=False``. Default is ``None``.\n%(spatial_colors_psd)s\n%(sphere_topomap_auto)s\n%(exclude_spectrum_plot)s\n\n    .. versionchanged:: 1.5\n        In version 1.5, the default behavior changed from ``exclude='bads'`` to\n        ``exclude=()``.\n%(axes_spectrum_plot_topomap)s\n%(show)s\n\nReturns\n-------\nfig : instance of matplotlib.figure.Figure\n    Figure with spectra plotted in separate subplots for each channel type.", "metadata": {}}
{"_id": "mne_mne_time_frequency/spectrum.py_plot_topo_doc", "text": "Plot power spectral density, separately for each channel.\n\nParameters\n----------\n%(dB_spectrum_plot_topo)s\n%(layout_spectrum_plot_topo)s\n%(color_spectrum_plot_topo)s\n%(fig_facecolor)s\n%(axis_facecolor)s\n%(axes_spectrum_plot_topo)s\n%(block)s\n%(show)s\n\nReturns\n-------\nfig : instance of matplotlib.figure.Figure\n    Figure distributing one image per channel across sensor topography.", "metadata": {}}
{"_id": "mne_mne_time_frequency/spectrum.py_plot_topomap_doc", "text": "Plot scalp topography of PSD for chosen frequency bands.\n\nParameters\n----------\n%(bands_psd_topo)s\n%(ch_type_topomap_psd)s\n%(normalize_psd_topo)s\n%(agg_fun_psd_topo)s\n%(dB_plot_topomap)s\n%(sensors_topomap)s\n%(show_names_topomap)s\n%(mask_evoked_topomap)s\n%(mask_params_topomap)s\n%(contours_topomap)s\n%(outlines_topomap)s\n%(sphere_topomap_auto)s\n%(image_interp_topomap)s\n%(extrapolate_topomap)s\n%(border_topomap)s\n%(res_topomap)s\n%(size_topomap)s\n%(cmap_topomap)s\n%(vlim_plot_topomap_psd)s\n%(cnorm)s\n%(colorbar_topomap)s\n%(cbar_fmt_topomap_psd)s\n%(units_topomap)s\n%(axes_spectrum_plot_topomap)s\n%(show)s\n\nReturns\n-------\nfig : instance of Figure\n    Figure showing one scalp topography per frequency band.", "metadata": {}}
{"_id": "mne_mne_time_frequency/spectrum.py_save_doc", "text": "Save spectrum data to disk (in HDF5 format).\n\nParameters\n----------\nfname : path-like\n    Path of file to save to.\n%(overwrite)s\n%(verbose)s\n\nSee Also\n--------\nmne.time_frequency.read_spectrum", "metadata": {}}
{"_id": "mne_mne_time_frequency/spectrum.py_to_data_frame_doc", "text": "Export data in tabular structure as a pandas DataFrame.\n\nChannels are converted to columns in the DataFrame. By default,\nan additional column \"freq\" is added, unless ``index='freq'``\n(in which case frequency values form the DataFrame's index).\n\nParameters\n----------\n%(picks_all)s\nindex : str | list of str | None\n    Kind of index to use for the DataFrame. If ``None``, a sequential\n    integer index (:class:`pandas.RangeIndex`) will be used. If a\n    :class:`str`, a :class:`pandas.Index` will be used (see Notes). If\n    a list of two or more string values, a :class:`pandas.MultiIndex`\n    will be used. Defaults to ``None``.\n%(copy_df)s\n%(long_format_df_spe)s\n%(verbose)s\n\nReturns\n-------\n%(df_return)s\n\nNotes\n-----\nValid values for ``index`` depend on whether the Spectrum was created\nfrom continuous data (:class:`~mne.io.Raw`, :class:`~mne.Evoked`) or\ndiscontinuous data (:class:`~mne.Epochs`). For continuous data, only\n``None`` or ``'freq'`` is supported. For discontinuous data, additional\nvalid values are ``'epoch'`` and ``'condition'``, or a :class:`list`\ncomprising some of the valid string values (e.g.,\n``['freq', 'epoch']``).", "metadata": {}}
{"_id": "mne_mne_time_frequency/spectrum.py_units_doc", "text": "Get the spectrum units for each channel type.\n\nParameters\n----------\nlatex : bool\n    Whether to format the unit strings as LaTeX. Default is ``False``.\n\nReturns\n-------\nunits : dict\n    Mapping from channel type to a string representation of the units\n    for that channel type.", "metadata": {}}
{"_id": "mne_mne_time_frequency/spectrum.py_average_doc", "text": "Average the spectra across epochs.\n\nParameters\n----------\nmethod : 'mean' | 'median' | callable\n    How to aggregate spectra across epochs. If callable, must take a\n    :class:`NumPy array<numpy.ndarray>` of shape\n    ``(n_epochs, n_channels, n_freqs)`` and return an array of shape\n    ``(n_channels, n_freqs)``. Default is ``'mean'``.\n\nReturns\n-------\nspectrum : instance of Spectrum\n    The aggregated spectrum object.", "metadata": {}}
{"_id": "mne_mne_time_frequency/_stockwell.py_tfr_array_stockwell_doc", "text": "Compute power and intertrial coherence using Stockwell (S) transform.\n\nSame computation as `~mne.time_frequency.tfr_stockwell`, but operates on\n:class:`NumPy arrays <numpy.ndarray>` instead of `~mne.Epochs` objects.\n\nSee :footcite:`Stockwell2007,MoukademEtAl2014,WheatEtAl2010,JonesEtAl2006`\nfor more information.\n\nParameters\n----------\ndata : ndarray, shape (n_epochs, n_channels, n_times)\n    The signal to transform.\nsfreq : float\n    The sampling frequency.\nfmin : None, float\n    The minimum frequency to include. If None defaults to the minimum fft\n    frequency greater than zero.\nfmax : None, float\n    The maximum frequency to include. If None defaults to the maximum fft.\nn_fft : int | None\n    The length of the windows used for FFT. If None, it defaults to the\n    next power of 2 larger than the signal length.\nwidth : float\n    The width of the Gaussian window. If < 1, increased temporal\n    resolution, if > 1, increased frequency resolution. Defaults to 1.\n    (classical S-Transform).\n%(decim_tfr)s\nreturn_itc : bool\n    Return intertrial coherence (ITC) as well as averaged power.\n%(n_jobs)s\n%(verbose)s\n\nReturns\n-------\nst_power : ndarray\n    The multitaper power of the Stockwell transformed data.\n    The last two dimensions are frequency and time.\nitc : ndarray\n    The intertrial coherence. Only returned if return_itc is True.\nfreqs : ndarray\n    The frequencies.\n\nSee Also\n--------\nmne.time_frequency.tfr_stockwell\nmne.time_frequency.tfr_multitaper\nmne.time_frequency.tfr_array_multitaper\nmne.time_frequency.tfr_morlet\nmne.time_frequency.tfr_array_morlet\n\nReferences\n----------\n.. footbibliography::", "metadata": {}}
{"_id": "mne_mne_time_frequency/_stockwell.py_tfr_stockwell_doc", "text": "Compute Time-Frequency Representation (TFR) using Stockwell Transform.\n\nSame computation as `~mne.time_frequency.tfr_array_stockwell`, but operates\non `~mne.Epochs` objects instead of :class:`NumPy arrays <numpy.ndarray>`.\n\nSee :footcite:`Stockwell2007,MoukademEtAl2014,WheatEtAl2010,JonesEtAl2006`\nfor more information.\n\nParameters\n----------\ninst : Epochs | Evoked\n    The epochs or evoked object.\nfmin : None, float\n    The minimum frequency to include. If None defaults to the minimum fft\n    frequency greater than zero.\nfmax : None, float\n    The maximum frequency to include. If None defaults to the maximum fft.\nn_fft : int | None\n    The length of the windows used for FFT. If None, it defaults to the\n    next power of 2 larger than the signal length.\nwidth : float\n    The width of the Gaussian window. If < 1, increased temporal\n    resolution, if > 1, increased frequency resolution. Defaults to 1.\n    (classical S-Transform).\ndecim : int\n    The decimation factor on the time axis. To reduce memory usage.\nreturn_itc : bool\n    Return intertrial coherence (ITC) as well as averaged power.\nn_jobs : int\n    The number of jobs to run in parallel (over channels).\n%(verbose)s\n\nReturns\n-------\npower : AverageTFR\n    The averaged power.\nitc : AverageTFR\n    The intertrial coherence. Only returned if return_itc is True.\n\nSee Also\n--------\nmne.time_frequency.tfr_array_stockwell\nmne.time_frequency.tfr_multitaper\nmne.time_frequency.tfr_array_multitaper\nmne.time_frequency.tfr_morlet\nmne.time_frequency.tfr_array_morlet\n\nNotes\n-----\n.. versionadded:: 0.9.0\n\nReferences\n----------\n.. footbibliography::", "metadata": {}}
{"_id": "mne_mne_time_frequency/csd.py_pick_channels_csd_doc", "text": "Pick channels from cross-spectral density matrix.\n\nParameters\n----------\ncsd : instance of CrossSpectralDensity\n    The CSD object to select the channels from.\ninclude : list of str\n    List of channels to include (if empty, include all available).\nexclude : list of str\n    Channels to exclude (if empty, do not exclude any).\n%(ordered)s\ncopy : bool\n    If True (the default), return a copy of the CSD matrix with the\n    modified channels. If False, channels are modified in-place.\n\n    .. versionadded:: 0.20.0\n%(verbose)s\n\nReturns\n-------\nres : instance of CrossSpectralDensity\n    Cross-spectral density restricted to selected channels.", "metadata": {}}
{"_id": "mne_mne_time_frequency/csd.py_read_csd_doc", "text": "Read a CrossSpectralDensity object from an HDF5 file.\n\nParameters\n----------\nfname : path-like\n    The name of the file to read the CSD from. The extension ``'.h5'`` will\n    be appended if the given filename doesn't have it already.\n\nReturns\n-------\ncsd : instance of CrossSpectralDensity\n    The CSD that was stored in the file.\n\nSee Also\n--------\nCrossSpectralDensity.save : For saving CSD objects.", "metadata": {}}
{"_id": "mne_mne_time_frequency/csd.py_csd_fourier_doc", "text": "Estimate cross-spectral density from an array using short-time fourier.\n\nParameters\n----------\nepochs : instance of Epochs\n    The epochs to compute the CSD for.\nfmin : float\n    Minimum frequency of interest, in Hertz.\nfmax : float | np.inf\n    Maximum frequency of interest, in Hertz.\ntmin : float | None\n    Minimum time instant to consider, in seconds. If ``None`` start at\n    first sample.\ntmax : float | None\n    Maximum time instant to consider, in seconds. If ``None`` end at last\n    sample.\n%(picks_good_data_noref)s\nn_fft : int | None\n    Length of the FFT. If ``None``, the exact number of samples between\n    ``tmin`` and ``tmax`` will be used.\nprojs : list of Projection | None\n    List of projectors to store in the CSD object. Defaults to ``None``,\n    which means the projectors defined in the Epochs object will be copied.\n%(n_jobs)s\n%(verbose)s\n\nReturns\n-------\ncsd : instance of CrossSpectralDensity\n    The computed cross-spectral density.\n\nSee Also\n--------\ncsd_array_fourier\ncsd_array_morlet\ncsd_array_multitaper\ncsd_morlet\ncsd_multitaper", "metadata": {}}
{"_id": "mne_mne_time_frequency/csd.py_csd_array_fourier_doc", "text": "Estimate cross-spectral density from an array using short-time fourier.\n\nParameters\n----------\nX : array-like, shape (n_epochs, n_channels, n_times)\n    The time series data consisting of n_epochs separate observations\n    of signals with n_channels time-series of length n_times.\nsfreq : float\n    Sampling frequency of observations.\nt0 : float\n    Time of the first sample relative to the onset of the epoch, in\n    seconds. Defaults to 0.\nfmin : float\n    Minimum frequency of interest, in Hertz.\nfmax : float | np.inf\n    Maximum frequency of interest, in Hertz.\ntmin : float | None\n    Minimum time instant to consider, in seconds. If ``None`` start at\n    first sample.\ntmax : float | None\n    Maximum time instant to consider, in seconds. If ``None`` end at last\n    sample.\nch_names : list of str | None\n    A name for each time series. If ``None`` (the default), the series will\n    be named 'SERIES###'.\nn_fft : int | None\n    Length of the FFT. If ``None``, the exact number of samples between\n    ``tmin`` and ``tmax`` will be used.\nprojs : list of Projection | None\n    List of projectors to store in the CSD object. Defaults to ``None``,\n    which means no projectors are stored.\n%(n_jobs)s\n%(verbose)s\n\nReturns\n-------\ncsd : instance of CrossSpectralDensity\n    The computed cross-spectral density.\n\nSee Also\n--------\ncsd_array_morlet\ncsd_array_multitaper\ncsd_fourier\ncsd_morlet\ncsd_multitaper", "metadata": {}}
{"_id": "mne_mne_time_frequency/csd.py_csd_multitaper_doc", "text": "Estimate cross-spectral density from epochs using a multitaper method.\n\nParameters\n----------\nepochs : instance of Epochs\n    The epochs to compute the CSD for.\nfmin : float | None\n    Minimum frequency of interest, in Hertz.\nfmax : float | np.inf\n    Maximum frequency of interest, in Hertz.\ntmin : float\n    Minimum time instant to consider, in seconds. If ``None`` start at\n    first sample.\ntmax : float | None\n    Maximum time instant to consider, in seconds. If ``None`` end at last\n    sample.\n%(picks_good_data_noref)s\nn_fft : int | None\n    Length of the FFT. If ``None``, the exact number of samples between\n    ``tmin`` and ``tmax`` will be used.\nbandwidth : float | None\n    The bandwidth of the multitaper windowing function in Hz.\nadaptive : bool\n    Use adaptive weights to combine the tapered spectra into PSD.\nlow_bias : bool\n    Only use tapers with more than 90%% spectral concentration within\n    bandwidth.\nprojs : list of Projection | None\n    List of projectors to store in the CSD object. Defaults to ``None``,\n    which means the projectors defined in the Epochs object will by copied.\n%(n_jobs)s\n%(verbose)s\n\nReturns\n-------\ncsd : instance of CrossSpectralDensity\n    The computed cross-spectral density.\n\nSee Also\n--------\ncsd_array_fourier\ncsd_array_morlet\ncsd_array_multitaper\ncsd_fourier\ncsd_morlet", "metadata": {}}
{"_id": "mne_mne_time_frequency/csd.py_csd_array_multitaper_doc", "text": "Estimate cross-spectral density from an array using a multitaper method.\n\nParameters\n----------\nX : array-like, shape (n_epochs, n_channels, n_times)\n    The time series data consisting of n_epochs separate observations\n    of signals with n_channels time-series of length n_times.\nsfreq : float\n    Sampling frequency of observations.\nt0 : float\n    Time of the first sample relative to the onset of the epoch, in\n    seconds. Defaults to 0.\nfmin : float\n    Minimum frequency of interest, in Hertz.\nfmax : float | np.inf\n    Maximum frequency of interest, in Hertz.\ntmin : float | None\n    Minimum time instant to consider, in seconds. If ``None`` start at\n    first sample.\ntmax : float | None\n    Maximum time instant to consider, in seconds. If ``None`` end at last\n    sample.\nch_names : list of str | None\n    A name for each time series. If ``None`` (the default), the series will\n    be named 'SERIES###'.\nn_fft : int | None\n    Length of the FFT. If ``None``, the exact number of samples between\n    ``tmin`` and ``tmax`` will be used.\nbandwidth : float | None\n    The bandwidth of the multitaper windowing function in Hz.\nadaptive : bool\n    Use adaptive weights to combine the tapered spectra into PSD.\nlow_bias : bool\n    Only use tapers with more than 90%% spectral concentration within\n    bandwidth.\nprojs : list of Projection | None\n    List of projectors to store in the CSD object. Defaults to ``None``,\n    which means no projectors are stored.\n%(n_jobs)s\n%(max_iter_multitaper)s\n%(verbose)s\n\nReturns\n-------\ncsd : instance of CrossSpectralDensity\n    The computed cross-spectral density.\n\nSee Also\n--------\ncsd_array_fourier\ncsd_array_morlet\ncsd_fourier\ncsd_morlet\ncsd_multitaper", "metadata": {}}
{"_id": "mne_mne_time_frequency/csd.py_csd_morlet_doc", "text": "Estimate cross-spectral density from epochs using Morlet wavelets.\n\nParameters\n----------\nepochs : instance of Epochs\n    The epochs to compute the CSD for.\nfrequencies : list of float\n    The frequencies of interest, in Hertz.\ntmin : float | None\n    Minimum time instant to consider, in seconds. If ``None`` start at\n    first sample.\ntmax : float | None\n    Maximum time instant to consider, in seconds. If ``None`` end at last\n    sample.\n%(picks_good_data_noref)s\nn_cycles : float | list of float | None\n    Number of cycles to use when constructing Morlet wavelets. Fixed number\n    or one per frequency. Defaults to 7.\nuse_fft : bool\n    Whether to use FFT-based convolution to compute the wavelet transform.\n    Defaults to True.\ndecim : int | slice\n    To reduce memory usage, decimation factor during time-frequency\n    decomposition. Defaults to 1 (no decimation).\n\n    If `int`, uses tfr[..., ::decim].\n    If `slice`, uses tfr[..., decim].\n\nprojs : list of Projection | None\n    List of projectors to store in the CSD object. Defaults to ``None``,\n    which means the projectors defined in the Epochs object will be copied.\n%(n_jobs)s\n%(verbose)s\n\nReturns\n-------\ncsd : instance of CrossSpectralDensity\n    The computed cross-spectral density.\n\nSee Also\n--------\ncsd_array_fourier\ncsd_array_morlet\ncsd_array_multitaper\ncsd_fourier\ncsd_multitaper", "metadata": {}}
{"_id": "mne_mne_time_frequency/csd.py_csd_array_morlet_doc", "text": "Estimate cross-spectral density from an array using Morlet wavelets.\n\nParameters\n----------\nX : array-like, shape (n_epochs, n_channels, n_times)\n    The time series data consisting of n_epochs separate observations\n    of signals with n_channels time-series of length n_times.\nsfreq : float\n    Sampling frequency of observations.\nfrequencies : list of float\n    The frequencies of interest, in Hertz.\nt0 : float\n    Time of the first sample relative to the onset of the epoch, in\n    seconds. Defaults to 0.\ntmin : float | None\n    Minimum time instant to consider, in seconds. If ``None`` start at\n    first sample.\ntmax : float | None\n    Maximum time instant to consider, in seconds. If ``None`` end at last\n    sample.\nch_names : list of str | None\n    A name for each time series. If ``None`` (the default), the series will\n    be named 'SERIES###'.\nn_cycles : float | list of float | None\n    Number of cycles to use when constructing Morlet wavelets. Fixed number\n    or one per frequency. Defaults to 7.\nuse_fft : bool\n    Whether to use FFT-based convolution to compute the wavelet transform.\n    Defaults to True.\ndecim : int | slice\n    To reduce memory usage, decimation factor during time-frequency\n    decomposition. Defaults to 1 (no decimation).\n\n    If `int`, uses tfr[..., ::decim].\n    If `slice`, uses tfr[..., decim].\n\nprojs : list of Projection | None\n    List of projectors to store in the CSD object. Defaults to ``None``,\n    which means the projectors defined in the Epochs object will be copied.\n%(n_jobs)s\n%(verbose)s\n\nReturns\n-------\ncsd : instance of CrossSpectralDensity\n    The computed cross-spectral density.\n\nSee Also\n--------\ncsd_array_fourier\ncsd_array_multitaper\ncsd_fourier\ncsd_morlet\ncsd_multitaper", "metadata": {}}
{"_id": "mne_mne_time_frequency/csd.py_csd_tfr_doc", "text": "Compute covariance matrices across frequencies for TFR epochs.\n\nParameters\n----------\nepochs_tfr : EpochsTFR\n    The time-frequency resolved epochs over which to compute the\n    covariance.\ntmin : float | None\n    Minimum time instant to consider, in seconds. If ``None`` start at\n    first sample.\ntmax : float | None\n    Maximum time instant to consider, in seconds. If ``None`` end at last\n    sample.\n%(picks_good_data_noref)s\nprojs : list of Projection | None\n    List of projectors to store in the CSD object. Defaults to ``None``,\n    which means the projectors defined in the EpochsTFR object will be\n    copied.\n%(verbose)s\n\nReturns\n-------\nres : instance of CrossSpectralDensity\n    Cross-spectral density restricted to selected channels.", "metadata": {}}
{"_id": "mne_mne_time_frequency/csd.py_n_channels_doc", "text": "Number of time series defined in this CSD object.", "metadata": {}}
{"_id": "mne_mne_time_frequency/csd.py_sum_doc", "text": "Calculate the sum CSD in the given frequency range(s).\n\nIf the exact given frequencies are not available, the nearest\nfrequencies will be chosen.\n\nParameters\n----------\nfmin : float | list of float | None\n    Lower bound of the frequency range in Hertz. Defaults to the lowest\n    frequency available. When a list of frequencies is given, these are\n    used as the lower bounds (inclusive) of frequency bins and the sum\n    is taken for each bin.\nfmax : float | list of float | None\n    Upper bound of the frequency range in Hertz. Defaults to the\n    highest frequency available. When a list of frequencies is given,\n    these are used as the upper bounds (inclusive) of frequency bins\n    and the sum is taken for each bin.\n\nReturns\n-------\ncsd : instance of CrossSpectralDensity\n    The CSD matrix, summed across the given frequency range(s).", "metadata": {}}
{"_id": "mne_mne_time_frequency/csd.py_mean_doc", "text": "Calculate the mean CSD in the given frequency range(s).\n\nParameters\n----------\nfmin : float | list of float | None\n    Lower bound of the frequency range in Hertz. Defaults to the lowest\n    frequency available. When a list of frequencies is given, these are\n    used as the lower bounds (inclusive) of frequency bins and the mean\n    is taken for each bin.\nfmax : float | list of float | None\n    Upper bound of the frequency range in Hertz. Defaults to the\n    highest frequency available. When a list of frequencies is given,\n    these are used as the upper bounds (inclusive) of frequency bins\n    and the mean is taken for each bin.\n\nReturns\n-------\ncsd : instance of CrossSpectralDensity\n    The CSD matrix, averaged across the given frequency range(s).", "metadata": {}}
{"_id": "mne_mne_time_frequency/csd.py_pick_frequency_doc", "text": "Get a CrossSpectralDensity object with only the given frequency.\n\nParameters\n----------\nfreq : float | None\n    Return the CSD matrix for a specific frequency. Only available\n    when no averaging across frequencies has been done.\nindex : int | None\n    Return the CSD matrix for the frequency or frequency-bin with the\n    given index.\n\nReturns\n-------\ncsd : instance of CrossSpectralDensity\n    A CSD object containing a single CSD matrix that corresponds to the\n    requested frequency or frequency-bin.\n\nSee Also\n--------\nget_data", "metadata": {}}
{"_id": "mne_mne_time_frequency/csd.py_get_data_doc", "text": "Get the CSD matrix for a given frequency as NumPy array.\n\nIf there is only one matrix defined in the CSD object, calling this\nmethod without any parameters will return it. If multiple matrices are\ndefined, use either the ``frequency`` or ``index`` parameter to select\none.\n\nParameters\n----------\nfrequency : float | None\n    Return the CSD matrix for a specific frequency. Only available when\n    no averaging across frequencies has been done.\nindex : int | None\n    Return the CSD matrix for the frequency or frequency-bin with the\n    given index.\nas_cov : bool\n    Whether to return the data as a numpy array (`False`, the default),\n    or pack it in a :class:`mne.Covariance` object (`True`).\n\n    .. versionadded:: 0.20\n\nReturns\n-------\ncsd : ndarray, shape (n_channels, n_channels) | instance of Covariance\n    The CSD matrix corresponding to the requested frequency.\n\nSee Also\n--------\npick_frequency", "metadata": {}}
{"_id": "mne_mne_time_frequency/csd.py_save_doc", "text": "Save the CSD to an HDF5 file.\n\nParameters\n----------\nfname : path-like\n    The name of the file to save the CSD to. The extension ``'.h5'``\n    will be appended if the given filename doesn't have it already.\n%(overwrite)s\n\n    .. versionadded:: 1.0\n%(verbose)s\n\n    .. versionadded:: 1.0\n\nSee Also\n--------\nread_csd : For reading CSD objects from a file.", "metadata": {}}
{"_id": "mne_mne_time_frequency/csd.py_copy_doc", "text": "Return copy of the CrossSpectralDensity object.\n\nReturns\n-------\ncopy : instance of CrossSpectralDensity\n    A copy of the object.", "metadata": {}}
{"_id": "mne_mne_time_frequency/csd.py_pick_channels_doc", "text": "Pick channels from this cross-spectral density matrix.\n\nParameters\n----------\nch_names : list of str\n    List of channels to keep. All other channels are dropped.\nordered : bool\n    If True (default False), ensure that the order of the channels\n    matches the order of ``ch_names``.\n\nReturns\n-------\ncsd : instance of CrossSpectralDensity.\n    The modified cross-spectral density object.\n\nNotes\n-----\nOperates in-place.\n\n.. versionadded:: 0.20.0", "metadata": {}}
{"_id": "mne_mne_time_frequency/tfr.py_morlet_doc", "text": "Compute Morlet wavelets for the given frequency range.\n\nParameters\n----------\nsfreq : float\n    The sampling Frequency.\nfreqs : float | array-like, shape (n_freqs,)\n    Frequencies to compute Morlet wavelets for.\nn_cycles : float | array-like, shape (n_freqs,)\n    Number of cycles. Can be a fixed number (float) or one per frequency\n    (array-like).\nsigma : float, default None\n    It controls the width of the wavelet ie its temporal\n    resolution. If sigma is None the temporal resolution\n    is adapted with the frequency like for all wavelet transform.\n    The higher the frequency the shorter is the wavelet.\n    If sigma is fixed the temporal resolution is fixed\n    like for the short time Fourier transform and the number\n    of oscillations increases with the frequency.\nzero_mean : bool, default False\n    Make sure the wavelet has a mean of zero.\n\nReturns\n-------\nWs : list of ndarray | ndarray\n    The wavelets time series. If ``freqs`` was a float, a single\n    ndarray is returned instead of a list of ndarray.\n\nSee Also\n--------\nmne.time_frequency.fwhm\n\nNotes\n-----\n%(morlet_reference)s\n%(fwhm_morlet_notes)s\n\nReferences\n----------\n.. footbibliography::\n\nExamples\n--------\nLet's show a simple example of the relationship between ``n_cycles`` and\nthe FWHM using :func:`mne.time_frequency.fwhm`:\n\n.. plot::\n\n    import numpy as np\n    import matplotlib.pyplot as plt\n    from mne.time_frequency import morlet, fwhm\n\n    sfreq, freq, n_cycles = 1000., 10, 7  # i.e., 700 ms\n    this_fwhm = fwhm(freq, n_cycles)\n    wavelet = morlet(sfreq=sfreq, freqs=freq, n_cycles=n_cycles)\n    M, w = len(wavelet), n_cycles # convert to SciPy convention\n    s = w * sfreq / (2 * freq * np.pi)  # from SciPy docs\n\n    _, ax = plt.subplots(layout=\"constrained\")\n    colors = dict(real=\"#66CCEE\", imag=\"#EE6677\")\n    t = np.arange(-M // 2 + 1, M // 2 + 1) / sfreq\n    for kind in ('real', 'imag'):\n        ax.plot(\n            t, getattr(wavelet, kind), label=kind, color=colors[kind],\n        )\n    ax.plot(t, np.abs(wavelet), label=f'abs', color='k', lw=1., zorder=6)\n    half_max = np.max(np.abs(wavelet)) / 2.\n    ax.plot([-this_fwhm / 2., this_fwhm / 2.], [half_max, half_max],\n            color='k', linestyle='-', label='FWHM', zorder=6)\n    ax.legend(loc='upper right')\n    ax.set(xlabel='Time (s)', ylabel='Amplitude')", "metadata": {}}
{"_id": "mne_mne_time_frequency/tfr.py_fwhm_doc", "text": "Compute the full-width half maximum of a Morlet wavelet.\n\nUses the formula from :footcite:t:`Cohen2019`.\n\nParameters\n----------\nfreq : float\n    The oscillation frequency of the wavelet.\nn_cycles : float\n    The duration of the wavelet, expressed as the number of oscillation\n    cycles.\n\nReturns\n-------\nfwhm : float\n    The full-width half maximum of the wavelet.\n\nNotes\n-----\n .. versionadded:: 1.3\n\nReferences\n----------\n.. footbibliography::", "metadata": {}}
{"_id": "mne_mne_time_frequency/tfr.py_cwt_doc", "text": "Compute time-frequency decomposition with continuous wavelet transform.\n\nParameters\n----------\nX : array, shape (n_signals, n_times)\n    The signals.\nWs : list of array\n    Wavelets time series.\nuse_fft : bool\n    Use FFT for convolutions. Defaults to True.\nmode : 'same' | 'valid' | 'full'\n    Convention for convolution. 'full' is currently not implemented with\n    ``use_fft=False``. Defaults to ``'same'``.\n%(decim_tfr)s\n\nReturns\n-------\ntfr : array, shape (n_signals, n_freqs, n_times)\n    The time-frequency decompositions.\n\nSee Also\n--------\nmne.time_frequency.tfr_morlet : Compute time-frequency decomposition\n                                with Morlet wavelets.", "metadata": {}}
{"_id": "mne_mne_time_frequency/tfr.py_tfr_morlet_doc", "text": "Compute Time-Frequency Representation (TFR) using Morlet wavelets.\n\nSame computation as `~mne.time_frequency.tfr_array_morlet`, but\noperates on `~mne.Epochs` or `~mne.Evoked` objects instead of\n:class:`NumPy arrays <numpy.ndarray>`.\n\nParameters\n----------\ninst : Epochs | Evoked\n    The epochs or evoked object.\n%(freqs_tfr_array)s\n%(n_cycles_tfr)s\nuse_fft : bool, default False\n    The fft based convolution or not.\nreturn_itc : bool, default True\n    Return inter-trial coherence (ITC) as well as averaged power.\n    Must be ``False`` for evoked data.\n%(decim_tfr)s\n%(n_jobs)s\npicks : array-like of int | None, default None\n    The indices of the channels to decompose. If None, all available\n    good data channels are decomposed.\nzero_mean : bool, default True\n    Make sure the wavelet has a mean of zero.\n\n    .. versionadded:: 0.13.0\n%(average_tfr)s\noutput : str\n    Can be ``\"power\"`` (default) or ``\"complex\"``. If ``\"complex\"``, then\n    ``average`` must be ``False``.\n\n    .. versionadded:: 0.15.0\n%(verbose)s\n\nReturns\n-------\npower : AverageTFR | EpochsTFR\n    The averaged or single-trial power.\nitc : AverageTFR | EpochsTFR\n    The inter-trial coherence (ITC). Only returned if return_itc\n    is True.\n\nSee Also\n--------\nmne.time_frequency.tfr_array_morlet\nmne.time_frequency.tfr_multitaper\nmne.time_frequency.tfr_array_multitaper\nmne.time_frequency.tfr_stockwell\nmne.time_frequency.tfr_array_stockwell\n\nNotes\n-----\n%(morlet_reference)s\n%(temporal_window_tfr_intro)s\n%(temporal_window_tfr_morlet_notes)s\n\nSee :func:`mne.time_frequency.morlet` for more information about the\nMorlet wavelet.\n\nReferences\n----------\n.. footbibliography::", "metadata": {}}
{"_id": "mne_mne_time_frequency/tfr.py_tfr_array_morlet_doc", "text": "Compute Time-Frequency Representation (TFR) using Morlet wavelets.\n\nSame computation as `~mne.time_frequency.tfr_morlet`, but operates on\n:class:`NumPy arrays <numpy.ndarray>` instead of `~mne.Epochs` objects.\n\nParameters\n----------\ndata : array of shape (n_epochs, n_channels, n_times)\n    The epochs.\nsfreq : float | int\n    Sampling frequency of the data.\n%(freqs_tfr_array)s\n%(n_cycles_tfr)s\nzero_mean : bool | None\n    If True, make sure the wavelets have a mean of zero. default False.\n\n    .. versionchanged:: 1.8\n        The default will change from ``zero_mean=False`` in 1.6 to ``True`` in\n        1.8.\n\nuse_fft : bool\n    Use the FFT for convolutions or not. default True.\n%(decim_tfr)s\noutput : str, default ``'complex'``\n\n    * ``'complex'`` : single trial complex.\n    * ``'power'`` : single trial power.\n    * ``'phase'`` : single trial phase.\n    * ``'avg_power'`` : average of single trial power.\n    * ``'itc'`` : inter-trial coherence.\n    * ``'avg_power_itc'`` : average of single trial power and inter-trial\n      coherence across trials.\n%(n_jobs)s\n    The number of epochs to process at the same time. The parallelization\n    is implemented across channels. Default 1.\n%(verbose)s\n\nReturns\n-------\nout : array\n    Time frequency transform of ``data``.\n\n    - if ``output in ('complex', 'phase', 'power')``, array of shape\n      ``(n_epochs, n_chans, n_freqs, n_times)``\n    - else, array of shape ``(n_chans, n_freqs, n_times)``\n\n    If ``output`` is ``'avg_power_itc'``, the real values in ``out``\n    contain the average power and the imaginary values contain the ITC:\n    :math:`out = power_{avg} + i * itc`.\n\nSee Also\n--------\nmne.time_frequency.tfr_morlet\nmne.time_frequency.tfr_multitaper\nmne.time_frequency.tfr_array_multitaper\nmne.time_frequency.tfr_stockwell\nmne.time_frequency.tfr_array_stockwell\n\nNotes\n-----\n%(morlet_reference)s\n%(temporal_window_tfr_intro)s\n%(temporal_window_tfr_morlet_notes)s\n\n.. versionadded:: 0.14.0\n\nReferences\n----------\n.. footbibliography::", "metadata": {}}
{"_id": "mne_mne_time_frequency/tfr.py_tfr_multitaper_doc", "text": "Compute Time-Frequency Representation (TFR) using DPSS tapers.\n\nSame computation as :func:`~mne.time_frequency.tfr_array_multitaper`, but\noperates on :class:`~mne.Epochs` or :class:`~mne.Evoked` objects instead of\n:class:`NumPy arrays <numpy.ndarray>`.\n\nParameters\n----------\ninst : Epochs | Evoked\n    The epochs or evoked object.\n%(freqs_tfr_array)s\n%(n_cycles_tfr)s\n%(time_bandwidth_tfr)s\nuse_fft : bool, default True\n    The fft based convolution or not.\nreturn_itc : bool, default True\n    Return inter-trial coherence (ITC) as well as averaged (or\n    single-trial) power.\n%(decim_tfr)s\n%(n_jobs)s\n%(picks_good_data)s\n%(average_tfr)s\n%(verbose)s\n\nReturns\n-------\npower : AverageTFR | EpochsTFR\n    The averaged or single-trial power.\nitc : AverageTFR | EpochsTFR\n    The inter-trial coherence (ITC). Only returned if return_itc\n    is True.\n\nSee Also\n--------\nmne.time_frequency.tfr_array_multitaper\nmne.time_frequency.tfr_stockwell\nmne.time_frequency.tfr_array_stockwell\nmne.time_frequency.tfr_morlet\nmne.time_frequency.tfr_array_morlet\n\nNotes\n-----\n%(temporal_window_tfr_intro)s\n%(temporal_window_tfr_multitaper_notes)s\n%(time_bandwidth_tfr_notes)s\n\n.. versionadded:: 0.9.0", "metadata": {}}
{"_id": "mne_mne_time_frequency/tfr.py_combine_tfr_doc", "text": "Merge AverageTFR data by weighted addition.\n\nCreate a new :class:`mne.time_frequency.AverageTFR` instance, using a combination of\nthe supplied instances as its data. By default, the mean (weighted by trials) is\nused. Subtraction can be performed by passing negative weights (e.g., [1, -1]). Data\nmust have the same channels and the same time instants.\n\nParameters\n----------\nall_tfr : list of AverageTFR\n    The tfr datasets.\nweights : list of float | str\n    The weights to apply to the data of each AverageTFR instance.\n    Can also be ``'nave'`` to weight according to tfr.nave,\n    or ``'equal'`` to use equal weighting (each weighted as ``1/N``).\n\nReturns\n-------\ntfr : AverageTFR\n    The new TFR data.\n\nNotes\n-----\nAggregating multitaper TFR datasets with a taper dimension such as for complex or\nphase data is not supported.\n\n.. versionadded:: 0.11.0", "metadata": {}}
{"_id": "mne_mne_time_frequency/tfr.py_write_tfrs_doc", "text": "Write a TFR dataset to hdf5.\n\nParameters\n----------\nfname : path-like\n    The file name, which should end with ``-tfr.h5``.\ntfr : RawTFR | EpochsTFR | AverageTFR | list of RawTFR | list of EpochsTFR | list of AverageTFR\n    The (list of) TFR object(s) to save in one file. If ``tfr.comment`` is ``None``,\n    a sequential numeric string name will be generated on the fly, based on the\n    order in which the TFR objects are passed. This can be used to selectively load\n    single TFR objects from the file later.\n%(overwrite)s\n%(verbose)s\n\nSee Also\n--------\nread_tfrs\n\nNotes\n-----\n.. versionadded:: 0.9.0", "metadata": {}}
{"_id": "mne_mne_time_frequency/tfr.py_read_tfrs_doc", "text": "Load a TFR object from disk.\n\nParameters\n----------\nfname : path-like\n    Path to a TFR file in HDF5 format, which should end with ``-tfr.h5`` or\n    ``-tfr.hdf5``.\ncondition : int or str | list of int or str | None\n    The condition to load. If ``None``, all conditions will be returned.\n    Defaults to ``None``.\n%(verbose)s\n\nReturns\n-------\ntfr : RawTFR | EpochsTFR | AverageTFR | list of RawTFR | list of EpochsTFR | list of AverageTFR\n    The loaded time-frequency object.\n\nSee Also\n--------\nmne.time_frequency.RawTFR.save\nmne.time_frequency.EpochsTFR.save\nmne.time_frequency.AverageTFR.save\nwrite_tfrs\n\nNotes\n-----\n.. versionadded:: 0.9.0", "metadata": {}}
{"_id": "mne_mne_time_frequency/tfr.py_baseline_doc", "text": "Start and end of the baseline period (in seconds).", "metadata": {}}
{"_id": "mne_mne_time_frequency/tfr.py_ch_names_doc", "text": "The channel names.", "metadata": {}}
{"_id": "mne_mne_time_frequency/tfr.py_data_doc", "text": "The time-frequency-resolved power estimates.", "metadata": {}}
{"_id": "mne_mne_time_frequency/tfr.py_freqs_doc", "text": "The frequencies at which power estimates were computed.", "metadata": {}}
{"_id": "mne_mne_time_frequency/tfr.py_method_doc", "text": "The method used to compute the time-frequency power estimates.", "metadata": {}}
{"_id": "mne_mne_time_frequency/tfr.py_sfreq_doc", "text": "Sampling frequency of the data.", "metadata": {}}
{"_id": "mne_mne_time_frequency/tfr.py_shape_doc", "text": "Data shape.", "metadata": {}}
{"_id": "mne_mne_time_frequency/tfr.py_times_doc", "text": "The time points present in the data (in seconds).", "metadata": {}}
{"_id": "mne_mne_time_frequency/tfr.py_weights_doc", "text": "The weights used for each taper in the time-frequency estimates.", "metadata": {}}
{"_id": "mne_mne_time_frequency/tfr.py_crop_doc", "text": "Crop data to a given time interval in place.\n\nParameters\n----------\n%(tmin_tmax_psd)s\nfmin : float | None\n    Lowest frequency of selection in Hz.\n\n    .. versionadded:: 0.18.0\nfmax : float | None\n    Highest frequency of selection in Hz.\n\n    .. versionadded:: 0.18.0\n%(include_tmax)s\n\nReturns\n-------\n%(inst_tfr)s\n    The modified instance.", "metadata": {}}
{"_id": "mne_mne_time_frequency/tfr.py_copy_doc", "text": "Return copy of the TFR instance.\n\nReturns\n-------\n%(inst_tfr)s\n    A copy of the object.", "metadata": {}}
{"_id": "mne_mne_time_frequency/tfr.py_apply_baseline_doc", "text": "Baseline correct the data.\n\nParameters\n----------\n%(baseline_rescale)s\n\n    How baseline is computed is determined by the ``mode`` parameter.\nmode : 'mean' | 'ratio' | 'logratio' | 'percent' | 'zscore' | 'zlogratio'\n    Perform baseline correction by\n\n    - subtracting the mean of baseline values ('mean')\n    - dividing by the mean of baseline values ('ratio')\n    - dividing by the mean of baseline values and taking the log\n      ('logratio')\n    - subtracting the mean of baseline values followed by dividing by\n      the mean of baseline values ('percent')\n    - subtracting the mean of baseline values and dividing by the\n      standard deviation of baseline values ('zscore')\n    - dividing by the mean of baseline values, taking the log, and\n      dividing by the standard deviation of log baseline values\n      ('zlogratio')\n%(verbose)s\n\nReturns\n-------\n%(inst_tfr)s\n    The modified instance.", "metadata": {}}
{"_id": "mne_mne_time_frequency/tfr.py_get_data_doc", "text": "Get time-frequency data in NumPy array format.\n\nParameters\n----------\n%(picks_good_data_noref)s\n%(exclude_spectrum_get_data)s\n%(fmin_fmax_tfr)s\n%(tmin_tmax_psd)s\nreturn_times : bool\n    Whether to return the time values for the requested time range.\n    Default is ``False``.\nreturn_freqs : bool\n    Whether to return the frequency bin values for the requested\n    frequency range. Default is ``False``.\nreturn_tapers : bool\n    Whether to return the taper numbers. Default is ``False``.\n\n    .. versionadded:: 1.10.0\n\nReturns\n-------\ndata : array\n    The requested data in a NumPy array.\ntimes : array\n    The time values for the requested data range. Only returned if\n    ``return_times`` is ``True``.\nfreqs : array\n    The frequency values for the requested data range. Only returned if\n    ``return_freqs`` is ``True``.\ntapers : array | None\n    The taper numbers. Only returned if ``return_tapers`` is ``True``. Will be\n    ``None`` if a taper dimension is not present in the data.\n\nNotes\n-----\nReturns a copy of the underlying data (not a view).", "metadata": {}}
{"_id": "mne_mne_time_frequency/tfr.py_plot_doc", "text": "Plot TFRs as two-dimensional time-frequency images.\n\nParameters\n----------\n%(picks_good_data)s\n%(exclude_spectrum_plot)s\n%(tmin_tmax_psd)s\n%(fmin_fmax_tfr)s\n%(baseline_rescale)s\n\n    How baseline is computed is determined by the ``mode`` parameter.\n%(mode_tfr_plot)s\n%(dB_spectrum_plot)s\n%(combine_tfr_plot)s\n\n    .. versionchanged:: 1.3\n       Added support for ``callable``.\n%(layout_spectrum_plot_topo)s\n%(yscale_tfr_plot)s\n\n    .. versionadded:: 0.14.0\n%(vlim_tfr_plot)s\n%(cnorm)s\n\n    .. versionadded:: 0.24\n%(cmap_topomap)s\n%(colorbar)s\n%(title_tfr_plot)s\n%(mask_tfr_plot)s\n\n    .. versionadded:: 0.16.0\n%(mask_style_tfr_plot)s\n\n    .. versionadded:: 0.17\n%(mask_cmap_tfr_plot)s\n\n    .. versionadded:: 0.17\n%(mask_alpha_tfr_plot)s\n\n    .. versionadded:: 0.16.0\n%(axes_tfr_plot)s\n%(show)s\n%(verbose)s\n\nReturns\n-------\nfigs : list of instances of matplotlib.figure.Figure\n    A list of figures containing the time-frequency power.", "metadata": {}}
{"_id": "mne_mne_time_frequency/tfr.py_plot_joint_doc", "text": "Plot TFRs as a two-dimensional image with topomap highlights.\n\nParameters\n----------\n%(timefreqs)s\n%(picks_good_data)s\n%(exclude_psd)s\n    Default is an empty :class:`tuple` which includes all channels.\n%(combine_tfr_plot_joint)s\n\n    .. versionchanged:: 1.3\n        Added support for ``callable``.\n%(tmin_tmax_psd)s\n%(fmin_fmax_tfr)s\n%(baseline_rescale)s\n\n    How baseline is computed is determined by the ``mode`` parameter.\n%(mode_tfr_plot)s\n%(dB_tfr_plot_topo)s\n%(yscale_tfr_plot)s\n%(vlim_tfr_plot_joint)s\n%(cnorm)s\n%(cmap_tfr_plot_topo)s\n%(colorbar_tfr_plot_joint)s\n%(title_none)s\n%(show)s\n%(topomap_args)s\n%(image_args)s\n%(verbose)s\n\nReturns\n-------\nfig : matplotlib.figure.Figure\n    The figure containing the topography.\n\nNotes\n-----\n%(notes_timefreqs_tfr_plot_joint)s\n\n.. versionadded:: 0.16.0", "metadata": {}}
{"_id": "mne_mne_time_frequency/tfr.py_plot_topo_doc", "text": "Plot a TFR image for each channel in a sensor layout arrangement.\n\nParameters\n----------\n%(picks_good_data)s\n%(baseline_rescale)s\n\n    How baseline is computed is determined by the ``mode`` parameter.\n%(mode_tfr_plot)s\n%(tmin_tmax_psd)s\n%(fmin_fmax_tfr)s\n%(vmin_vmax_tfr_plot_topo)s\n%(layout_spectrum_plot_topo)s\n%(cmap_tfr_plot_topo)s\n%(title_none)s\n%(dB_tfr_plot_topo)s\n%(colorbar)s\n%(layout_scale)s\n%(show)s\n%(border_topo)s\n%(fig_facecolor)s\n%(fig_background)s\n%(font_color)s\n%(yscale_tfr_plot)s\n%(verbose)s\n\nReturns\n-------\nfig : matplotlib.figure.Figure\n    The figure containing the topography.", "metadata": {}}
{"_id": "mne_mne_time_frequency/tfr.py_save_doc", "text": "Save time-frequency data to disk (in HDF5 format).\n\nParameters\n----------\nfname : path-like\n    Path of file to save to, which should end with ``-tfr.h5`` or ``-tfr.hdf5``.\n%(overwrite)s\n%(verbose)s\n\nSee Also\n--------\nmne.time_frequency.read_tfrs", "metadata": {}}
{"_id": "mne_mne_time_frequency/tfr.py_to_data_frame_doc", "text": "Export data in tabular structure as a pandas DataFrame.\n\nChannels are converted to columns in the DataFrame. By default, additional\ncolumns ``'time'``, ``'freq'``, ``'taper'``, ``'epoch'``, and ``'condition'``\n(epoch event description) are added, unless ``index`` is not ``None`` (in which\ncase the columns specified in ``index`` will be used to form the DataFrame's\nindex instead). ``'epoch'``, and ``'condition'`` are not supported for\n``AverageTFR``. ``'taper'`` is only supported when a taper dimensions is\npresent, such as for complex or phase multitaper data.\n\nParameters\n----------\n%(picks_all)s\n%(index_df_epo)s\n    Valid string values are ``'time'``, ``'freq'``, ``'taper'``, ``'epoch'``,\n    and ``'condition'`` for ``EpochsTFR`` and ``'time'``, ``'freq'``, and\n    ``'taper'`` for ``AverageTFR``. Defaults to ``None``.\n%(long_format_df_epo)s\n%(time_format_df)s\n\n    .. versionadded:: 0.23\n%(verbose)s\n\nReturns\n-------\n%(df_return)s", "metadata": {}}
{"_id": "mne_mne_time_frequency/tfr.py_average_doc", "text": "Aggregate the EpochsTFR across epochs, frequencies, or times.\n\nParameters\n----------\nmethod : \"mean\" | \"median\" | callable\n    How to aggregate the data across the given ``dim``. If callable,\n    must take a :class:`NumPy array<numpy.ndarray>` of shape\n    ``(n_epochs, n_channels, n_freqs, n_times)`` and return an array\n    with one fewer dimensions (which dimension is collapsed depends on\n    the value of ``dim``). Default is ``\"mean\"``.\ndim : \"epochs\" | \"freqs\" | \"times\"\n    The dimension along which to combine the data.\ncopy : bool\n    Whether to return a copy of the modified instance, or modify in place.\n    Ignored when ``dim=\"epochs\"`` or ``\"times\"`` because those options return\n    different types (:class:`~mne.time_frequency.AverageTFR` and\n    :class:`~mne.time_frequency.EpochsSpectrum`, respectively).\n\nReturns\n-------\ntfr : instance of EpochsTFR | AverageTFR | EpochsSpectrum\n    The aggregated TFR object.\n\nNotes\n-----\nPassing in ``np.median`` is considered unsafe for complex data; pass\nthe string ``\"median\"`` instead to compute the *marginal* median\n(i.e. the median of the real and imaginary components separately).\nSee discussion here:\n\nhttps://github.com/scipy/scipy/pull/12676#issuecomment-783370228\n\nAveraging is not supported for data containing a taper dimension.", "metadata": {}}
{"_id": "mne_mne_time_frequency/tfr.py_drop_doc", "text": "Drop epochs based on indices or boolean mask.\n\n.. note:: The indices refer to the current set of undropped epochs\n          rather than the complete set of dropped and undropped epochs.\n          They are therefore not necessarily consistent with any\n          external indices (e.g., behavioral logs). To drop epochs\n          based on external criteria, do not use the ``preload=True``\n          flag when constructing an Epochs object, and call this\n          method before calling the :meth:`mne.Epochs.drop_bad` or\n          :meth:`mne.Epochs.load_data` methods.\n\nParameters\n----------\nindices : array of int or bool\n    Set epochs to remove by specifying indices to remove or a boolean\n    mask to apply (where True values get removed). Events are\n    correspondingly modified.\nreason : str\n    Reason for dropping the epochs ('ECG', 'timeout', 'blink' etc).\n    Default: 'USER'.\n%(verbose)s\n\nReturns\n-------\nepochs : instance of Epochs or EpochsTFR\n    The epochs with indices dropped. Operates in-place.", "metadata": {}}
{"_id": "mne_mne_time_frequency/tfr.py_iter_evoked_doc", "text": "Iterate over EpochsTFR to yield a sequence of AverageTFR objects.\n\nThe AverageTFR objects will each contain a single epoch (i.e., no averaging is\nperformed). This method resets the EpochTFR instance's iteration state to the\nfirst epoch.\n\nParameters\n----------\ncopy : bool\n    Whether to yield copies of the data and measurement info, or views/pointers.", "metadata": {}}
{"_id": "mne_mne_time_frequency/multitaper.py_dpss_windows_doc", "text": "Compute Discrete Prolate Spheroidal Sequences.\n\nWill give of orders [0,Kmax-1] for a given frequency-spacing multiple\nNW and sequence length N.\n\n.. note:: Copied from NiTime.\n\nParameters\n----------\nN : int\n    Sequence length.\nhalf_nbw : float\n    Standardized half bandwidth corresponding to 2 * half_bw = BW*f0\n    = BW*N/dt but with dt taken as 1.\nKmax : int\n    Number of DPSS windows to return is Kmax (orders 0 through Kmax-1).\nsym : bool\n    Whether to generate a symmetric window (``True``, for filter design) or\n    a periodic window (``False``, for spectral analysis). Default is\n    ``True``.\n\n    .. versionadded:: 1.3\nnorm : 2 | ``'approximate'`` | ``'subsample'`` | None\n    Window normalization method. If ``'approximate'`` or ``'subsample'``,\n    windows are normalized by the maximum, and a correction scale-factor\n    for even-length windows is applied either using\n    ``N**2/(N**2+half_nbw)`` (\"approximate\") or a FFT-based subsample shift\n    (\"subsample\"). ``2`` uses the L2 norm. ``None`` (the default) uses\n    ``\"approximate\"`` when ``Kmax=None`` and ``2`` otherwise.\n\n    .. versionadded:: 1.3\nlow_bias : bool\n    Keep only tapers with eigenvalues > 0.9.\n\nReturns\n-------\nv, e : tuple,\n    The v array contains DPSS windows shaped (Kmax, N).\n    e are the eigenvalues.\n\nNotes\n-----\nTridiagonal form of DPSS calculation from :footcite:`Slepian1978`.\n\nReferences\n----------\n.. footbibliography::", "metadata": {}}
{"_id": "mne_mne_time_frequency/multitaper.py_psd_array_multitaper_doc", "text": "Compute power spectral density (PSD) using a multi-taper method.\n\nThe power spectral density is computed with DPSS\ntapers :footcite:p:`Slepian1978`.\n\nParameters\n----------\nx : array, shape=(..., n_times)\n    The data to compute PSD from.\nsfreq : float\n    The sampling frequency.\n%(fmin_fmax_psd)s\nbandwidth : float\n    Frequency bandwidth of the multi-taper window function in Hz. For a\n    given frequency, frequencies at ``\u00b1 bandwidth / 2`` are smoothed\n    together. The default value is a bandwidth of\n    ``8 * (sfreq / n_times)``.\nadaptive : bool\n    Use adaptive weights to combine the tapered spectra into PSD\n    (slow, use n_jobs >> 1 to speed up computation).\nlow_bias : bool\n    Only use tapers with more than 90%% spectral concentration within\n    bandwidth.\n%(normalization)s\n%(remove_dc)s\noutput : str\n    The format of the returned ``psds`` array, ``'complex'`` or\n    ``'power'``:\n\n    * ``'power'`` : the power spectral density is returned.\n    * ``'complex'`` : the complex fourier coefficients are returned per\n      taper.\n%(n_jobs)s\n%(max_iter_multitaper)s\n%(verbose)s\n\nReturns\n-------\npsds : ndarray, shape (..., n_freqs) or (..., n_tapers, n_freqs)\n    The power spectral densities. All dimensions up to the last (or the\n    last two if ``output='complex'``) will be the same as input.\nfreqs : array\n    The frequency points in Hz of the PSD.\nweights : ndarray\n    The weights used for averaging across tapers. Only returned if\n    ``output='complex'``.\n\nSee Also\n--------\ncsd_multitaper\nmne.io.Raw.compute_psd\nmne.Epochs.compute_psd\nmne.Evoked.compute_psd\n\nNotes\n-----\n.. versionadded:: 0.14.0\n\nReferences\n----------\n.. footbibliography::", "metadata": {}}
{"_id": "mne_mne_time_frequency/multitaper.py_tfr_array_multitaper_doc", "text": "Compute Time-Frequency Representation (TFR) using DPSS tapers.\n\nSame computation as `~mne.time_frequency.tfr_multitaper`, but operates on\n:class:`NumPy arrays <numpy.ndarray>` instead of `~mne.Epochs` or\n`~mne.Evoked` objects.\n\nParameters\n----------\ndata : array of shape (n_epochs, n_channels, n_times)\n    The epochs.\nsfreq : float\n    Sampling frequency of the data in Hz.\n%(freqs_tfr_array)s\n%(n_cycles_tfr)s\nzero_mean : bool\n    If True, make sure the wavelets have a mean of zero. Defaults to True.\n%(time_bandwidth_tfr)s\nuse_fft : bool\n    Use the FFT for convolutions or not. Defaults to True.\n%(decim_tfr)s\noutput : str, default 'complex'\n\n    * ``'complex'`` : single trial per taper complex values.\n    * ``'power'`` : single trial power.\n    * ``'phase'`` : single trial per taper phase.\n    * ``'avg_power'`` : average of single trial power.\n    * ``'itc'`` : inter-trial coherence.\n    * ``'avg_power_itc'`` : average of single trial power and inter-trial\n      coherence across trials.\n%(n_jobs)s\n    The parallelization is implemented across channels.\nreturn_weights : bool, default False\n    If True, return the taper weights. Only applies if ``output='complex'`` or\n    ``'phase'``.\n\n    .. versionadded:: 1.10.0\n%(verbose)s\n\nReturns\n-------\nout : array\n    Time frequency transform of ``data``.\n\n    - if ``output in ('complex',' 'phase')``, array of shape\n      ``(n_epochs, n_chans, n_tapers, n_freqs, n_times)``\n    - if ``output`` is ``'power'``, array of shape ``(n_epochs, n_chans,\n      n_freqs, n_times)``\n    - else, array of shape ``(n_chans, n_freqs, n_times)``\n\n    If ``output`` is ``'avg_power_itc'``, the real values in ``out``\n    contain the average power and the imaginary values contain the\n    inter-trial coherence: :math:`out = power_{avg} + i * ITC`.\nweights : array of shape (n_tapers, n_freqs)\n    The taper weights. Only returned if ``output='complex'`` or ``'phase'`` and\n    ``return_weights=True``.\n\nSee Also\n--------\nmne.time_frequency.tfr_multitaper\nmne.time_frequency.tfr_morlet\nmne.time_frequency.tfr_array_morlet\nmne.time_frequency.tfr_stockwell\nmne.time_frequency.tfr_array_stockwell\n\nNotes\n-----\n%(temporal_window_tfr_intro)s\n%(temporal_window_tfr_multitaper_notes)s\n%(time_bandwidth_tfr_notes)s\n\n.. versionadded:: 0.14.0", "metadata": {}}
{"_id": "mne_mne_time_frequency/ar.py_fit_iir_model_raw_doc", "text": "Fit an AR model to raw data and creates the corresponding IIR filter.\n\nThe computed filter is fitted to data from all of the picked channels,\nwith frequency response given by the standard IIR formula:\n\n.. math::\n\n    H(e^{jw}) = \\frac{1}{a[0] + a[1]e^{-jw} + ... + a[n]e^{-jnw}}\n\nParameters\n----------\nraw : Raw object\n    An instance of Raw.\norder : int\n    Order of the FIR filter.\n%(picks_good_data)s\ntmin : float\n    The beginning of time interval in seconds.\ntmax : float\n    The end of time interval in seconds.\n%(verbose)s\n\nReturns\n-------\nb : ndarray\n    Numerator filter coefficients.\na : ndarray\n    Denominator filter coefficients.", "metadata": {}}
{"_id": "mne_mne_time_frequency/_stft.py_stft_doc", "text": "STFT Short-Term Fourier Transform using a sine window.\n\nThe transformation is designed to be a tight frame that can be\nperfectly inverted. It only returns the positive frequencies.\n\nParameters\n----------\nx : array, shape (n_signals, n_times)\n    Containing multi-channels signal.\nwsize : int\n    Length of the STFT window in samples (must be a multiple of 4).\ntstep : int\n    Step between successive windows in samples (must be a multiple of 2,\n    a divider of wsize and smaller than wsize/2) (default: wsize/2).\n%(verbose)s\n\nReturns\n-------\nX : array, shape (n_signals, wsize // 2 + 1, n_step)\n    STFT coefficients for positive frequencies with\n    ``n_step = ceil(T / tstep)``.\n\nSee Also\n--------\nistft\nstftfreq", "metadata": {}}
{"_id": "mne_mne_time_frequency/_stft.py_istft_doc", "text": "ISTFT Inverse Short-Term Fourier Transform using a sine window.\n\nParameters\n----------\nX : array, shape (..., wsize / 2 + 1, n_step)\n    The STFT coefficients for positive frequencies.\ntstep : int\n    Step between successive windows in samples (must be a multiple of 2,\n    a divider of wsize and smaller than wsize/2) (default: wsize/2).\nTx : int\n    Length of returned signal. If None Tx = n_step * tstep.\n\nReturns\n-------\nx : array, shape (Tx,)\n    Array containing the inverse STFT signal.\n\nSee Also\n--------\nstft", "metadata": {}}
{"_id": "mne_mne_time_frequency/_stft.py_stftfreq_doc", "text": "Compute frequencies of stft transformation.\n\nParameters\n----------\nwsize : int\n    Size of stft window.\nsfreq : float\n    Sampling frequency. If None the frequencies are given between 0 and pi\n    otherwise it's given in Hz.\n\nReturns\n-------\nfreqs : array\n    The positive frequencies returned by stft.\n\nSee Also\n--------\nstft\nistft", "metadata": {}}
{"_id": "mne_mne_time_frequency/_stft.py_stft_norm2_doc", "text": "Compute L2 norm of STFT transform.\n\nIt takes into account that stft only return positive frequencies.\nAs we use tight frame this quantity is conserved by the stft.\n\nParameters\n----------\nX : 3D complex array\n    The STFT transforms\n\nReturns\n-------\nnorms2 : array\n    The squared L2 norm of every row of X.", "metadata": {}}
{"_id": "mne_mne_time_frequency/_stft.py_stft_norm1_doc", "text": "Compute L1 norm of STFT transform.\n\nIt takes into account that stft only return positive frequencies.\n\nParameters\n----------\nX : 3D complex array\n    The STFT transforms\n\nReturns\n-------\nnorms : array\n    The L1 norm of every row of X.", "metadata": {}}
{"_id": "mne_mne_time_frequency/psd.py_psd_array_welch_doc", "text": "Compute power spectral density (PSD) using Welch's method.\n\nWelch's method is described in :footcite:t:`Welch1967`.\n\nParameters\n----------\nx : array, shape=(..., n_times)\n    The data to compute PSD from.\nsfreq : float\n    The sampling frequency.\nfmin : float\n    The lower frequency of interest.\nfmax : float\n    The upper frequency of interest.\nn_fft : int\n    The length of FFT used, must be ``>= n_per_seg`` (default: 256).\n    The segments will be zero-padded if ``n_fft > n_per_seg``.\nn_overlap : int\n    The number of points of overlap between segments. Will be adjusted\n    to be <= n_per_seg. The default value is 0.\nn_per_seg : int | None\n    Length of each Welch segment (windowed with a Hamming window). Defaults\n    to None, which sets n_per_seg equal to n_fft.\n%(n_jobs)s\n%(average_psd)s\n\n    .. versionadded:: 0.19.0\n%(window_psd)s\n\n    .. versionadded:: 0.22.0\n%(remove_dc)s\n\noutput : str\n    The format of the returned ``psds`` array, ``'complex'`` or\n    ``'power'``:\n\n    * ``'power'`` : the power spectral density is returned.\n    * ``'complex'`` : the complex fourier coefficients are returned per\n      window.\n\n    .. versionadded:: 1.4.0\n%(verbose)s\n\nReturns\n-------\npsds : ndarray, shape (..., n_freqs) or (..., n_freqs, n_segments)\n    The power spectral densities. If ``average='mean`` or\n    ``average='median'``, the returned array will have the same shape\n    as the input data plus an additional frequency dimension.\n    If ``average=None``, the returned array will have the same shape as\n    the input data plus two additional dimensions corresponding to\n    frequencies and the unaggregated segments, respectively.\nfreqs : ndarray, shape (n_freqs,)\n    The frequencies.\n\nNotes\n-----\n.. versionadded:: 0.14.0\n\nReferences\n----------\n.. footbibliography::", "metadata": {}}
{"_id": "mne_mne_inverse_sparse/mxne_debiasing.py_power_iteration_kron_doc", "text": "Find the largest singular value for the matrix kron(C.T, A).\n\nIt uses power iterations.\n\nParameters\n----------\nA : array\n    An array\nC : array\n    An array\nmax_iter : int\n    Maximum number of iterations\n%(random_state)s\n\nReturns\n-------\nL : float\n    largest singular value\n\nNotes\n-----\nhttp://en.wikipedia.org/wiki/Power_iteration", "metadata": {}}
{"_id": "mne_mne_inverse_sparse/mxne_debiasing.py_compute_bias_doc", "text": "Compute scaling to correct amplitude bias.\n\nIt solves the following optimization problem using FISTA:\n\nmin 1/2 * (|| M - GDX ||fro)^2\ns.t. D >= 1 and D is a diagonal matrix\n\nReference for the FISTA algorithm:\nAmir Beck and Marc Teboulle\nA Fast Iterative Shrinkage-Thresholding Algorithm for Linear Inverse\nProblems, SIAM J. Imaging Sci., 2(1), 183-202. (20 pages)\nhttp://epubs.siam.org/doi/abs/10.1137/080716542\n\nParameters\n----------\nM : array\n    measurement data.\nG : array\n    leadfield matrix.\nX : array\n    reconstructed time courses with amplitude bias.\nmax_iter : int\n    Maximum number of iterations.\ntol : float\n    The tolerance on convergence.\nn_orient : int\n    The number of orientations (1 for fixed and 3 otherwise).\n%(verbose)s\n\nReturns\n-------\nD : array\n    Debiasing weights.", "metadata": {}}
{"_id": "mne_mne_inverse_sparse/_gamma_map.py_gamma_map_doc", "text": "Hierarchical Bayes (Gamma-MAP) sparse source localization method.\n\nModels each source time course using a zero-mean Gaussian prior with an\nunknown variance (gamma) parameter. During estimation, most gammas are\ndriven to zero, resulting in a sparse source estimate, as in\n:footcite:`WipfEtAl2007` and :footcite:`WipfNagarajan2009`.\n\nFor fixed-orientation forward operators, a separate gamma is used for each\nsource time course, while for free-orientation forward operators, the same\ngamma is used for the three source time courses at each source space point\n(separate gammas can be used in this case by using xyz_same_gamma=False).\n\nParameters\n----------\nevoked : instance of Evoked\n    Evoked data to invert.\nforward : dict\n    Forward operator.\nnoise_cov : instance of Covariance\n    Noise covariance to compute whitener.\nalpha : float\n    Regularization parameter (noise variance).\n%(loose)s\n%(depth)s\nxyz_same_gamma : bool\n    Use same gamma for xyz current components at each source space point.\n    Recommended for free-orientation forward solutions.\nmaxit : int\n    Maximum number of iterations.\ntol : float\n    Tolerance parameter for convergence.\nupdate_mode : int\n    Update mode, 1: MacKay update (default), 2: Modified MacKay update.\ngammas : array, shape=(n_sources,)\n    Initial values for posterior variances (gammas). If None, a\n    variance of 1.0 is used.\npca : bool\n    If True the rank of the data is reduced to the true dimension.\nreturn_residual : bool\n    If True, the residual is returned as an Evoked instance.\nreturn_as_dipoles : bool\n    If True, the sources are returned as a list of Dipole instances.\n%(rank_none)s\n\n    .. versionadded:: 0.18\n%(pick_ori)s\n%(verbose)s\n\nReturns\n-------\nstc : instance of SourceEstimate\n    Source time courses.\nresidual : instance of Evoked\n    The residual a.k.a. data not explained by the sources.\n    Only returned if return_residual is True.\n\nReferences\n----------\n.. footbibliography::", "metadata": {}}
{"_id": "mne_mne_inverse_sparse/mxne_inverse.py_make_stc_from_dipoles_doc", "text": "Convert a list of spatio-temporal dipoles into a SourceEstimate.\n\nParameters\n----------\ndipoles : Dipole | list of instances of Dipole\n    The dipoles to convert.\nsrc : instance of SourceSpaces\n    The source space used to generate the forward operator.\n%(verbose)s\n\nReturns\n-------\nstc : SourceEstimate\n    The source estimate.", "metadata": {}}
{"_id": "mne_mne_inverse_sparse/mxne_inverse.py_mixed_norm_doc", "text": "Mixed-norm estimate (MxNE) and iterative reweighted MxNE (irMxNE).\n\nCompute L1/L2 mixed-norm solution :footcite:`GramfortEtAl2012` or L0.5/L2\n:footcite:`StrohmeierEtAl2016` mixed-norm solution on evoked data.\n\nParameters\n----------\nevoked : instance of Evoked or list of instances of Evoked\n    Evoked data to invert.\nforward : dict\n    Forward operator.\nnoise_cov : instance of Covariance\n    Noise covariance to compute whitener.\nalpha : float | str\n    Regularization parameter. If float it should be in the range [0, 100):\n    0 means no regularization, 100 would give 0 active dipole.\n    If ``'sure'`` (default), the SURE method from\n    :footcite:`DeledalleEtAl2014` will be used.\n\n    .. versionchanged:: 0.24\n      The default was changed to ``'sure'``.\n%(loose)s\n%(depth)s\nmaxit : int\n    Maximum number of iterations.\ntol : float\n    Tolerance parameter.\nactive_set_size : int | None\n    Size of active set increment. If None, no active set strategy is used.\ndebias : bool\n    Remove coefficient amplitude bias due to L1 penalty.\ntime_pca : bool or int\n    If True the rank of the concatenated epochs is reduced to\n    its true dimension. If is 'int' the rank is limited to this value.\nweights : None | array | SourceEstimate\n    Weight for penalty in mixed_norm. Can be None, a\n    1d array with shape (n_sources,), or a SourceEstimate (e.g. obtained\n    with wMNE, dSPM, or fMRI).\nweights_min : float\n    Do not consider in the estimation sources for which weights\n    is less than weights_min.\nsolver : 'cd' | 'bcd' | 'auto'\n    The algorithm to use for the optimization. 'cd' uses\n    coordinate descent, and 'bcd' applies block coordinate descent.\n    'cd' is only available for fixed orientation.\nn_mxne_iter : int\n    The number of MxNE iterations. If > 1, iterative reweighting\n    is applied.\nreturn_residual : bool\n    If True, the residual is returned as an Evoked instance.\nreturn_as_dipoles : bool\n    If True, the sources are returned as a list of Dipole instances.\ndgap_freq : int or np.inf\n    The duality gap is evaluated every dgap_freq iterations. Ignored if\n    solver is 'cd'.\n%(rank_none)s\n\n    .. versionadded:: 0.18\n%(pick_ori)s\nsure_alpha_grid : array | str\n    If ``'auto'`` (default), the SURE is evaluated along 15 uniformly\n    distributed alphas between alpha_max and 0.1 * alpha_max. If array, the\n    grid is directly specified. Ignored if alpha is not \"sure\".\n\n    .. versionadded:: 0.24\nrandom_state : int | None\n    The random state used in a random number generator for delta and\n    epsilon used for the SURE computation. Defaults to None.\n\n    .. versionadded:: 0.24\n%(verbose)s\n\nReturns\n-------\nstc : SourceEstimate | list of SourceEstimate\n    Source time courses for each evoked data passed as input.\nresidual : instance of Evoked\n    The residual a.k.a. data not explained by the sources.\n    Only returned if return_residual is True.\n\nSee Also\n--------\ntf_mixed_norm\n\nReferences\n----------\n.. footbibliography::", "metadata": {}}
{"_id": "mne_mne_inverse_sparse/mxne_inverse.py_tf_mixed_norm_doc", "text": "Time-Frequency Mixed-norm estimate (TF-MxNE).\n\nCompute L1/L2 + L1 mixed-norm solution on time-frequency\ndictionary. Works with evoked data\n:footcite:`GramfortEtAl2013b,GramfortEtAl2011`.\n\nParameters\n----------\nevoked : instance of Evoked\n    Evoked data to invert.\nforward : dict\n    Forward operator.\nnoise_cov : instance of Covariance\n    Noise covariance to compute whitener.\n%(loose)s\n%(depth)s\nmaxit : int\n    Maximum number of iterations.\ntol : float\n    Tolerance parameter.\nweights : None | array | SourceEstimate\n    Weight for penalty in mixed_norm. Can be None or\n    1d array of length n_sources or a SourceEstimate e.g. obtained\n    with wMNE or dSPM or fMRI.\nweights_min : float\n    Do not consider in the estimation sources for which weights\n    is less than weights_min.\npca : bool\n    If True the rank of the data is reduced to true dimension.\ndebias : bool\n    Remove coefficient amplitude bias due to L1 penalty.\nwsize : int or array-like\n    Length of the STFT window in samples (must be a multiple of 4).\n    If an array is passed, multiple TF dictionaries are used (each having\n    its own wsize and tstep) and each entry of wsize must be a multiple\n    of 4. See :footcite:`BekhtiEtAl2016`.\ntstep : int or array-like\n    Step between successive windows in samples (must be a multiple of 2,\n    a divider of wsize and smaller than wsize/2) (default: wsize/2).\n    If an array is passed, multiple TF dictionaries are used (each having\n    its own wsize and tstep), and each entry of tstep must be a multiple\n    of 2 and divide the corresponding entry of wsize. See\n    :footcite:`BekhtiEtAl2016`.\nwindow : float or (float, float)\n    Length of time window used to take care of edge artifacts in seconds.\n    It can be one float or float if the values are different for left\n    and right window length.\nreturn_residual : bool\n    If True, the residual is returned as an Evoked instance.\nreturn_as_dipoles : bool\n    If True, the sources are returned as a list of Dipole instances.\nalpha : float in [0, 100) or None\n    Overall regularization parameter.\n    If alpha and l1_ratio are not None, alpha_space and alpha_time are\n    overridden by alpha * alpha_max * (1. - l1_ratio) and alpha * alpha_max\n    * l1_ratio. 0 means no regularization, 100 would give 0 active dipole.\nl1_ratio : float in [0, 1] or None\n    Proportion of temporal regularization.\n    If l1_ratio and alpha are not None, alpha_space and alpha_time are\n    overridden by alpha * alpha_max * (1. - l1_ratio) and alpha * alpha_max\n    * l1_ratio. 0 means no time regularization a.k.a. MxNE.\ndgap_freq : int or np.inf\n    The duality gap is evaluated every dgap_freq iterations.\n%(rank_none)s\n\n    .. versionadded:: 0.18\n%(pick_ori)s\nn_tfmxne_iter : int\n    Number of TF-MxNE iterations. If > 1, iterative reweighting is applied.\n%(verbose)s\n\nReturns\n-------\nstc : instance of SourceEstimate\n    Source time courses.\nresidual : instance of Evoked\n    The residual a.k.a. data not explained by the sources.\n    Only returned if return_residual is True.\n\nSee Also\n--------\nmixed_norm\n\nReferences\n----------\n.. footbibliography::", "metadata": {}}
{"_id": "mne_mne_inverse_sparse/mxne_optim.py_groups_norm2_doc", "text": "Compute squared L2 norms of groups inplace.", "metadata": {}}
{"_id": "mne_mne_inverse_sparse/mxne_optim.py_norm_l2inf_doc", "text": "L2-inf norm.", "metadata": {}}
{"_id": "mne_mne_inverse_sparse/mxne_optim.py_norm_l21_doc", "text": "L21 norm.", "metadata": {}}
{"_id": "mne_mne_inverse_sparse/mxne_optim.py_dgap_l21_doc", "text": "Duality gap for the mixed norm inverse problem.\n\nSee :footcite:`GramfortEtAl2012`.\n\nParameters\n----------\nM : array, shape (n_sensors, n_times)\n    The data.\nG : array, shape (n_sensors, n_active)\n    The gain matrix a.k.a. lead field.\nX : array, shape (n_active, n_times)\n    Sources.\nactive_set : array of bool, shape (n_sources, )\n    Mask of active sources.\nalpha : float\n    The regularization parameter.\nn_orient : int\n    Number of dipoles per locations (typically 1 or 3).\n\nReturns\n-------\ngap : float\n    Dual gap.\np_obj : float\n    Primal objective.\nd_obj : float\n    Dual objective. gap = p_obj - d_obj.\nR : array, shape (n_sensors, n_times)\n    Current residual (M - G * X).\n\nReferences\n----------\n.. footbibilography::", "metadata": {}}
{"_id": "mne_mne_inverse_sparse/mxne_optim.py_mixed_norm_solver_doc", "text": "Solve L1/L2 mixed-norm inverse problem with active set strategy.\n\nSee references :footcite:`GramfortEtAl2012,StrohmeierEtAl2016,\nBertrandEtAl2020`.\n\nParameters\n----------\nM : array, shape (n_sensors, n_times)\n    The data.\nG : array, shape (n_sensors, n_dipoles)\n    The gain matrix a.k.a. lead field.\nalpha : float\n    The regularization parameter. It should be between 0 and 100.\n    A value of 100 will lead to an empty active set (no active source).\nmaxit : int\n    The number of iterations.\ntol : float\n    Tolerance on dual gap for convergence checking.\n%(verbose)s\nactive_set_size : int\n    Size of active set increase at each iteration.\ndebias : bool\n    Debias source estimates.\nn_orient : int\n    The number of orientation (1 : fixed or 3 : free or loose).\nsolver : 'cd' | 'bcd' | 'auto'\n    The algorithm to use for the optimization. Block Coordinate Descent\n    (BCD) uses Anderson acceleration for faster convergence.\nreturn_gap : bool\n    Return final duality gap.\ndgap_freq : int\n    The duality gap is computed every dgap_freq iterations of the solver on\n    the active set.\nactive_set_init : array, shape (n_dipoles,) or None\n    The initial active set (boolean array) used at the first iteration.\n    If None, the usual active set strategy is applied.\nX_init : array, shape (n_dipoles, n_times) or None\n    The initial weight matrix used for warm starting the solver. If None,\n    the weights are initialized at zero.\n\nReturns\n-------\nX : array, shape (n_active, n_times)\n    The source estimates.\nactive_set : array, shape (new_active_set_size,)\n    The mask of active sources. Note that new_active_set_size is the size\n    of the active set after convergence of the solver.\nE : list\n    The value of the objective function over the iterations.\ngap : float\n    Final duality gap. Returned only if return_gap is True.\n\nReferences\n----------\n.. footbibliography::", "metadata": {}}
{"_id": "mne_mne_inverse_sparse/mxne_optim.py_iterative_mixed_norm_solver_doc", "text": "Solve L0.5/L2 mixed-norm inverse problem with active set strategy.\n\nSee reference :footcite:`StrohmeierEtAl2016`.\n\nParameters\n----------\nM : array, shape (n_sensors, n_times)\n    The data.\nG : array, shape (n_sensors, n_dipoles)\n    The gain matrix a.k.a. lead field.\nalpha : float\n    The regularization parameter. It should be between 0 and 100.\n    A value of 100 will lead to an empty active set (no active source).\nn_mxne_iter : int\n    The number of MxNE iterations. If > 1, iterative reweighting\n    is applied.\nmaxit : int\n    The number of iterations.\ntol : float\n    Tolerance on dual gap for convergence checking.\n%(verbose)s\nactive_set_size : int\n    Size of active set increase at each iteration.\ndebias : bool\n    Debias source estimates.\nn_orient : int\n    The number of orientation (1 : fixed or 3 : free or loose).\ndgap_freq : int or np.inf\n    The duality gap is evaluated every dgap_freq iterations.\nsolver : 'cd' | 'bcd' | 'auto'\n    The algorithm to use for the optimization.\nweight_init : array, shape (n_dipoles,) or None\n    The initial weight used for reweighting the gain matrix. If None, the\n    weights are initialized with ones.\n\nReturns\n-------\nX : array, shape (n_active, n_times)\n    The source estimates.\nactive_set : array\n    The mask of active sources.\nE : list\n    The value of the objective function over the iterations.\n\nReferences\n----------\n.. footbibliography::", "metadata": {}}
{"_id": "mne_mne_inverse_sparse/mxne_optim.py_norm_l21_tf_doc", "text": "L21 norm for TF.", "metadata": {}}
{"_id": "mne_mne_inverse_sparse/mxne_optim.py_norm_l1_tf_doc", "text": "L1 norm for TF.", "metadata": {}}
{"_id": "mne_mne_inverse_sparse/mxne_optim.py_norm_epsilon_doc", "text": "Weighted epsilon norm.\n\nThe weighted epsilon norm is the dual norm of::\n\nw_{space} * (1. - l1_ratio) * ||Y||_2 + l1_ratio * ||Y||_{1, w_{time}}.\n\nwhere `||Y||_{1, w_{time}} = (np.abs(Y) * w_time).sum()`\n\nWarning: it takes into account the fact that Y only contains coefficients\ncorresponding to the positive frequencies (see `stft_norm2()`): some\nentries will be counted twice. It is also assumed that all entries of both\nY and w_time are non-negative. See\n:footcite:`NdiayeEtAl2016,BurdakovMerkulov2001`.\n\nParameters\n----------\nY : array, shape (n_coefs,)\n    The input data.\nl1_ratio : float between 0 and 1\n    Tradeoff between L2 and L1 regularization. When it is 0, no temporal\n    regularization is applied.\nphi : instance of _Phi\n    The TF operator.\nw_space : float\n    Scalar weight of the L2 norm. By default, it is taken equal to 1.\nw_time : array, shape (n_coefs, ) | None\n    Weights of each TF coefficient in the L1 norm. If None, weights equal\n    to 1 are used.\n\n\nReturns\n-------\nnu : float\n    The value of the dual norm evaluated at Y.\n\nReferences\n----------\n.. footbibliography::", "metadata": {}}
{"_id": "mne_mne_inverse_sparse/mxne_optim.py_norm_epsilon_inf_doc", "text": "Weighted epsilon-inf norm of phi(np.dot(G.T, R)).\n\nParameters\n----------\nG : array, shape (n_sensors, n_sources)\n    Gain matrix a.k.a. lead field.\nR : array, shape (n_sensors, n_times)\n    Residual.\nphi : instance of _Phi\n    The TF operator.\nl1_ratio : float between 0 and 1\n    Parameter controlling the tradeoff between L21 and L1 regularization.\n    0 corresponds to an absence of temporal regularization, ie MxNE.\nn_orient : int\n    Number of dipoles per location (typically 1 or 3).\nw_space : array, shape (n_positions,) or None.\n    Weights for the L2 term of the epsilon norm. If None, weights are\n    all equal to 1.\nw_time : array, shape (n_positions, n_coefs) or None\n    Weights for the L1 term of the epsilon norm. If None, weights are\n    all equal to 1.\n\nReturns\n-------\nnu : float\n    The maximum value of the epsilon norms over groups of n_orient dipoles\n    (consecutive rows of phi(np.dot(G.T, R))).", "metadata": {}}
{"_id": "mne_mne_inverse_sparse/mxne_optim.py_dgap_l21l1_doc", "text": "Duality gap for the time-frequency mixed norm inverse problem.\n\nSee :footcite:`GramfortEtAl2012,NdiayeEtAl2016`\n\nParameters\n----------\nM : array, shape (n_sensors, n_times)\n    The data.\nG : array, shape (n_sensors, n_sources)\n    Gain matrix a.k.a. lead field.\nZ : array, shape (n_active, n_coefs)\n    Sources in TF domain.\nactive_set : array of bool, shape (n_sources, )\n    Mask of active sources.\nalpha_space : float\n    The spatial regularization parameter.\nalpha_time : float\n    The temporal regularization parameter. The higher it is the smoother\n    will be the estimated time series.\nphi : instance of _Phi\n    The TF operator.\nphiT : instance of _PhiT\n    The transpose of the TF operator.\nn_orient : int\n    Number of dipoles per locations (typically 1 or 3).\nhighest_d_obj : float\n    The highest value of the dual objective so far.\nw_space : array, shape (n_positions, )\n    Array of spatial weights.\nw_time : array, shape (n_positions, n_coefs)\n    Array of TF weights.\n\nReturns\n-------\ngap : float\n    Dual gap\np_obj : float\n    Primal objective\nd_obj : float\n    Dual objective. gap = p_obj - d_obj\nR : array, shape (n_sensors, n_times)\n    Current residual (M - G * X)\n\nReferences\n----------\n.. footbibliography::", "metadata": {}}
{"_id": "mne_mne_inverse_sparse/mxne_optim.py_tf_mixed_norm_solver_doc", "text": "Solve TF L21+L1 inverse solver with BCD and active set approach.\n\nSee :footcite:`GramfortEtAl2013b,GramfortEtAl2011,BekhtiEtAl2016`.\n\nParameters\n----------\nM : array, shape (n_sensors, n_times)\n    The data.\nG : array, shape (n_sensors, n_dipoles)\n    The gain matrix a.k.a. lead field.\nalpha_space : float\n    The spatial regularization parameter.\nalpha_time : float\n    The temporal regularization parameter. The higher it is the smoother\n    will be the estimated time series.\nwsize: int or array-like\n    Length of the STFT window in samples (must be a multiple of 4).\n    If an array is passed, multiple TF dictionaries are used (each having\n    its own wsize and tstep) and each entry of wsize must be a multiple\n    of 4.\ntstep: int or array-like\n    Step between successive windows in samples (must be a multiple of 2,\n    a divider of wsize and smaller than wsize/2) (default: wsize/2).\n    If an array is passed, multiple TF dictionaries are used (each having\n    its own wsize and tstep), and each entry of tstep must be a multiple\n    of 2 and divide the corresponding entry of wsize.\nn_orient : int\n    The number of orientation (1 : fixed or 3 : free or loose).\nmaxit : int\n    The number of iterations.\ntol : float\n    If absolute difference between estimates at 2 successive iterations\n    is lower than tol, the convergence is reached.\ndebias : bool\n    Debias source estimates.\nreturn_gap : bool\n    Return final duality gap.\ndgap_freq : int or np.inf\n    The duality gap is evaluated every dgap_freq iterations.\n%(verbose)s\n\nReturns\n-------\nX : array, shape (n_active, n_times)\n    The source estimates.\nactive_set : array\n    The mask of active sources.\nE : list\n    The value of the objective function every dgap_freq iteration. If\n    log_objective is False or dgap_freq is np.inf, it will be empty.\ngap : float\n    Final duality gap. Returned only if return_gap is True.\n\nReferences\n----------\n.. footbibliography::", "metadata": {}}
{"_id": "mne_mne_inverse_sparse/mxne_optim.py_iterative_tf_mixed_norm_solver_doc", "text": "Solve TF L0.5/L1 + L0.5 inverse problem with BCD + active set approach.\n\nParameters\n----------\nM: array, shape (n_sensors, n_times)\n    The data.\nG: array, shape (n_sensors, n_dipoles)\n    The gain matrix a.k.a. lead field.\nalpha_space: float\n    The spatial regularization parameter. The higher it is the less there\n    will be active sources.\nalpha_time : float\n    The temporal regularization parameter. The higher it is the smoother\n    will be the estimated time series. 0 means no temporal regularization,\n    a.k.a. irMxNE.\nn_tfmxne_iter : int\n    Number of TF-MxNE iterations. If > 1, iterative reweighting is applied.\nwsize : int or array-like\n    Length of the STFT window in samples (must be a multiple of 4).\n    If an array is passed, multiple TF dictionaries are used (each having\n    its own wsize and tstep) and each entry of wsize must be a multiple\n    of 4.\ntstep : int or array-like\n    Step between successive windows in samples (must be a multiple of 2,\n    a divider of wsize and smaller than wsize/2) (default: wsize/2).\n    If an array is passed, multiple TF dictionaries are used (each having\n    its own wsize and tstep), and each entry of tstep must be a multiple\n    of 2 and divide the corresponding entry of wsize.\nmaxit : int\n    The maximum number of iterations for each TF-MxNE problem.\ntol : float\n    If absolute difference between estimates at 2 successive iterations\n    is lower than tol, the convergence is reached. Also used as criterion\n    on duality gap for each TF-MxNE problem.\ndebias : bool\n    Debias source estimates.\nn_orient : int\n    The number of orientation (1 : fixed or 3 : free or loose).\ndgap_freq : int or np.inf\n    The duality gap is evaluated every dgap_freq iterations.\n%(verbose)s\n\nReturns\n-------\nX : array, shape (n_active, n_times)\n    The source estimates.\nactive_set : array\n    The mask of active sources.\nE : list\n    The value of the objective function over iterations.", "metadata": {}}
{"_id": "mne_mne_inverse_sparse/mxne_optim.py_norm_doc", "text": "Squared L2 norm if ord == 2 and L1 norm if order == 1.", "metadata": {}}
{"_id": "mne_mne_preprocessing/ssp.py_compute_proj_ecg_doc", "text": "Compute SSP (signal-space projection) vectors for ECG artifacts.\n\n%(compute_proj_ecg)s\n\n.. note:: Raw data will be loaded if it hasn't been preloaded already.\n\nParameters\n----------\nraw : mne.io.Raw\n    Raw input file.\nraw_event : mne.io.Raw or None\n    Raw file to use for event detection (if None, raw is used).\ntmin : float\n    Time before event in seconds.\ntmax : float\n    Time after event in seconds.\nn_grad : int\n    Number of SSP vectors for gradiometers.\nn_mag : int\n    Number of SSP vectors for magnetometers.\nn_eeg : int\n    Number of SSP vectors for EEG.\nl_freq : float | None\n    Filter low cut-off frequency for the data channels in Hz.\nh_freq : float | None\n    Filter high cut-off frequency for the data channels in Hz.\naverage : bool\n    Compute SSP after averaging. Default is True.\nfilter_length : str | int | None\n    Number of taps to use for filtering.\n%(n_jobs)s\nch_name : str | None\n    Channel to use for ECG detection (Required if no ECG found).\nreject : dict | None\n    Epoch rejection configuration (see Epochs).\nflat : dict | None\n    Epoch flat configuration (see Epochs).\nbads : list\n    List with (additional) bad channels.\navg_ref : bool\n    Add EEG average reference proj.\nno_proj : bool\n    Exclude the SSP projectors currently in the fiff file.\nevent_id : int\n    ID to use for events.\necg_l_freq : float\n    Low pass frequency applied to the ECG channel for event detection.\necg_h_freq : float\n    High pass frequency applied to the ECG channel for event detection.\ntstart : float\n    Start artifact detection after tstart seconds.\nqrs_threshold : float | str\n    Between 0 and 1. qrs detection threshold. Can also be \"auto\" to\n    automatically choose the threshold that generates a reasonable\n    number of heartbeats (40-160 beats / min).\nfilter_method : str\n    Method for filtering ('iir' or 'fir').\niir_params : dict | None\n    Dictionary of parameters to use for IIR filtering.\n    See mne.filter.construct_iir_filter for details. If iir_params\n    is None and method=\"iir\", 4th order Butterworth will be used.\ncopy : bool\n    If False, filtering raw data is done in place. Defaults to True.\nreturn_drop_log : bool\n    If True, return the drop log.\n\n    .. versionadded:: 0.15\nmeg : str\n    Can be ``'separate'`` (default) or ``'combined'`` to compute projectors\n    for magnetometers and gradiometers separately or jointly.\n    If ``'combined'``, ``n_mag == n_grad`` is required and the number of\n    projectors computed for MEG will be ``n_mag``.\n\n    .. versionadded:: 0.18\n%(verbose)s\n\nReturns\n-------\n%(projs)s\necg_events : ndarray\n    Detected ECG events.\ndrop_log : list\n    The drop log, if requested.\n\nSee Also\n--------\nfind_ecg_events\ncreate_ecg_epochs\n\nNotes\n-----\nFiltering is applied to the ECG channel while finding events using\n``ecg_l_freq`` and ``ecg_h_freq``, and then to the ``raw`` instance\nusing ``l_freq`` and ``h_freq`` before creation of the epochs used to\ncreate the projectors.", "metadata": {}}
{"_id": "mne_mne_preprocessing/ssp.py_compute_proj_eog_doc", "text": "Compute SSP (signal-space projection) vectors for EOG artifacts.\n\n%(compute_proj_eog)s\n\n.. note:: Raw data must be preloaded.\n\nParameters\n----------\nraw : mne.io.Raw\n    Raw input file.\nraw_event : mne.io.Raw or None\n    Raw file to use for event detection (if None, raw is used).\ntmin : float\n    Time before event in seconds.\ntmax : float\n    Time after event in seconds.\nn_grad : int\n    Number of SSP vectors for gradiometers.\nn_mag : int\n    Number of SSP vectors for magnetometers.\nn_eeg : int\n    Number of SSP vectors for EEG.\nl_freq : float | None\n    Filter low cut-off frequency for the data channels in Hz.\nh_freq : float | None\n    Filter high cut-off frequency for the data channels in Hz.\naverage : bool\n    Compute SSP after averaging. Default is True.\nfilter_length : str | int | None\n    Number of taps to use for filtering.\n%(n_jobs)s\nreject : dict | None\n    Epoch rejection configuration (see Epochs).\nflat : dict | None\n    Epoch flat configuration (see Epochs).\nbads : list\n    List with (additional) bad channels.\navg_ref : bool\n    Add EEG average reference proj.\nno_proj : bool\n    Exclude the SSP projectors currently in the fiff file.\nevent_id : int\n    ID to use for events.\neog_l_freq : float\n    Low pass frequency applied to the E0G channel for event detection.\neog_h_freq : float\n    High pass frequency applied to the EOG channel for event detection.\ntstart : float\n    Start artifact detection after tstart seconds.\nfilter_method : str\n    Method for filtering ('iir' or 'fir').\niir_params : dict | None\n    Dictionary of parameters to use for IIR filtering.\n    See mne.filter.construct_iir_filter for details. If iir_params\n    is None and method=\"iir\", 4th order Butterworth will be used.\nch_name : str | None\n    If not None, specify EOG channel name.\ncopy : bool\n    If False, filtering raw data is done in place. Defaults to True.\nreturn_drop_log : bool\n    If True, return the drop log.\n\n    .. versionadded:: 0.15\nmeg : str\n    Can be 'separate' (default) or 'combined' to compute projectors\n    for magnetometers and gradiometers separately or jointly.\n    If 'combined', ``n_mag == n_grad`` is required and the number of\n    projectors computed for MEG will be ``n_mag``.\n\n    .. versionadded:: 0.18\n%(verbose)s\n\nReturns\n-------\n%(projs)s\neog_events: ndarray\n    Detected EOG events.\ndrop_log : list\n    The drop log, if requested.\n\nSee Also\n--------\nfind_eog_events\ncreate_eog_epochs\n\nNotes\n-----\nFiltering is applied to the EOG channel while finding events using\n``eog_l_freq`` and ``eog_h_freq``, and then to the ``raw`` instance\nusing ``l_freq`` and ``h_freq`` before creation of the epochs used to\ncreate the projectors.", "metadata": {}}
{"_id": "mne_mne_preprocessing/_lof.py_find_bad_channels_lof_doc", "text": "Find bad channels using Local Outlier Factor (LOF) algorithm.\n\nParameters\n----------\nraw : instance of Raw\n    Raw data to process.\nn_neighbors : int\n    Number of neighbors defining the local neighborhood (default is 20).\n    Smaller values will lead to higher LOF scores.\n%(picks_good_data)s\nmetric : str\n    Metric to use for distance computation. Default is \u201ceuclidean\u201d,\n    see :func:`sklearn.metrics.pairwise.distance_metrics` for details.\nthreshold : float\n    Threshold to define outliers. Theoretical threshold ranges anywhere\n    between 1.0 and any positive integer. Default: 1.5\n    It is recommended to consider this as an hyperparameter to optimize.\nreturn_scores : bool\n    If ``True``, return a dictionary with LOF scores for each\n    evaluated channel. Default is ``False``.\n%(verbose)s\n\nReturns\n-------\nnoisy_chs : list\n    List of bad M/EEG channels that were automatically detected.\nscores : ndarray, shape (n_picks,)\n    Only returned when ``return_scores`` is ``True``. It contains the\n    LOF outlier score for each channel in ``picks``.\n\nSee Also\n--------\nmaxwell_filter\nannotate_amplitude\n\nNotes\n-----\nSee :footcite:`KumaravelEtAl2022` and :footcite:`BreunigEtAl2000` for background on\nchoosing ``threshold``.\n\n.. versionadded:: 1.7\n\nReferences\n----------\n.. footbibliography::", "metadata": {}}
{"_id": "mne_mne_preprocessing/artifact_detection.py_annotate_muscle_zscore_doc", "text": "Create annotations for segments that likely contain muscle artifacts.\n\nDetects data segments containing activity in the frequency range given by\n``filter_freq`` whose envelope magnitude exceeds the specified z-score\nthreshold, when summed across channels and divided by ``sqrt(n_channels)``.\nFalse-positive transient peaks are prevented by low-pass filtering the\nresulting z-score time series at 4 Hz. Only operates on a single channel\ntype, if ``ch_type`` is ``None`` it will select the first type in the list\n``mag``, ``grad``, ``eeg``.\nSee :footcite:`Muthukumaraswamy2013` for background on choosing\n``filter_freq`` and ``threshold``.\n\nParameters\n----------\nraw : instance of Raw\n    Data to estimate segments with muscle artifacts.\nthreshold : float\n    The threshold in z-scores for marking segments as containing muscle\n    activity artifacts.\nch_type : 'mag' | 'grad' | 'eeg' | None\n    The type of sensors to use. If ``None`` it will take the first type in\n    ``mag``, ``grad``, ``eeg``.\nmin_length_good : float | None\n    The shortest allowed duration of \"good data\" (in seconds) between\n    adjacent annotations; shorter segments will be incorporated into the\n    surrounding annotations.``None`` is equivalent to ``0``.\n    Default is ``0.1``.\nfilter_freq : array-like, shape (2,)\n    The lower and upper frequencies of the band-pass filter.\n    Default is ``(110, 140)``.\n%(n_jobs)s\n%(verbose)s\n\nReturns\n-------\nannot : mne.Annotations\n    Periods with muscle artifacts annotated as BAD_muscle.\nscores_muscle : array\n    Z-score values averaged across channels for each sample.\n\nReferences\n----------\n.. footbibliography::", "metadata": {}}
{"_id": "mne_mne_preprocessing/artifact_detection.py_annotate_movement_doc", "text": "Detect segments with movement.\n\nDetects segments periods further from rotation_velocity_limit,\ntranslation_velocity_limit and mean_distance_limit. It returns an\nannotation with the bad segments.\n\nParameters\n----------\nraw : instance of Raw\n    Data to compute head position.\npos : array, shape (N, 10)\n    The position and quaternion parameters from cHPI fitting. Obtained\n    with `mne.chpi` functions.\nrotation_velocity_limit : float\n    Head rotation velocity limit in degrees per second.\ntranslation_velocity_limit : float\n    Head translation velocity limit in meters per second.\nmean_distance_limit : float\n    Head position limit from mean recording in meters.\nuse_dev_head_trans : 'average' (default) | 'info'\n    Identify the device to head transform used to define the\n    fixed HPI locations for computing moving distances.\n    If ``average`` the average device to head transform is\n    computed using ``compute_average_dev_head_t``.\n    If ``info``, ``raw.info['dev_head_t']`` is used.\n\nReturns\n-------\nannot : mne.Annotations\n    Periods with head motion.\nhpi_disp : array\n    Head position over time with respect to the mean head pos.\n\nSee Also\n--------\ncompute_average_dev_head_t", "metadata": {}}
{"_id": "mne_mne_preprocessing/artifact_detection.py_compute_average_dev_head_t_doc", "text": "Get new device to head transform based on good segments.\n\nSegments starting with \"BAD\" annotations are not included for calculating\nthe mean head position.\n\nParameters\n----------\nraw : instance of Raw | list of Raw\n    Data to compute head position. Can be a list containing multiple raw\n    instances.\npos : array, shape (N, 10) | list of ndarray\n    The position and quaternion parameters from cHPI fitting. Can be\n    a list containing multiple position arrays, one per raw instance passed.\n%(verbose)s\n\nReturns\n-------\ndev_head_t : instance of Transform\n    New ``dev_head_t`` transformation using the averaged good head positions.\n\nNotes\n-----\n.. versionchanged:: 1.7\n   Support for multiple raw instances and position arrays was added.", "metadata": {}}
{"_id": "mne_mne_preprocessing/artifact_detection.py_annotate_break_doc", "text": "Create `~mne.Annotations` for breaks in an ongoing recording.\n\nThis function first searches for segments in the data that are not\nannotated or do not contain any events and are at least\n``min_break_duration`` seconds long, and then proceeds to creating\nannotations for those break periods.\n\nParameters\n----------\nraw : instance of Raw\n    The continuous data to analyze.\nevents : None | array, shape (n_events, 3)\n    If ``None`` (default), operate based solely on the annotations present\n    in ``raw``. If an events array, ignore any annotations in the raw data,\n    and operate based on these events only.\nmin_break_duration : float\n    The minimum time span in seconds between the offset of one and the\n    onset of the subsequent annotation (if ``events`` is ``None``) or\n    between two consecutive events (if ``events`` is an array) to consider\n    this period a \"break\". Defaults to 15 seconds.\n\n    .. note:: This value defines the minimum duration of a break period in\n              the data, **not** the minimum duration of the generated\n              annotations! See also ``t_start_after_previous`` and\n              ``t_stop_before_next`` for details.\n\nt_start_after_previous, t_stop_before_next : float\n    Specifies how far the to-be-created \"break\" annotation extends towards\n    the two annotations or events spanning the break. This can be used to\n    ensure e.g. that the break annotation doesn't start and end immediately\n    with a stimulation event. If, for example, your data contains a break\n    of 30 seconds between two stimuli, and ``t_start_after_previous`` is\n    set to ``5`` and ``t_stop_before_next`` is set to ``3``, the break\n    annotation will start 5 seconds after the first stimulus, and end 3\n    seconds before the second stimulus, yielding an annotated break of\n    ``30 - 5 - 3 = 22`` seconds. Both default to 5 seconds.\n\n    .. note:: The beginning and the end of the recording will be annotated\n              as breaks, too, if the period from recording start until the\n              first annotation or event (or from last annotation or event\n              until recording end) is at least ``min_break_duration``\n              seconds long.\n\nignore : iterable of str\n    Annotation descriptions starting with these strings will be ignored by\n    the break-finding algorithm. The string comparison is case-insensitive,\n    i.e., ``('bad',)`` and ``('BAD',)`` are equivalent. By default, all\n    annotation descriptions starting with \"bad\" and annotations\n    indicating \"edges\" (produced by data concatenation) will be\n    ignored. Pass an empty list or tuple to take all existing annotations\n    into account. If ``events`` is passed, this parameter has no effect.\n%(verbose)s\n\nReturns\n-------\nbreak_annotations : instance of Annotations\n    The break annotations, each with the description ``'BAD_break'``. If\n    no breaks could be found given the provided function parameters, an\n    empty `~mne.Annotations` object will be returned.\n\nNotes\n-----\n.. versionadded:: 0.24", "metadata": {}}
{"_id": "mne_mne_preprocessing/otp.py_oversampled_temporal_projection_doc", "text": "Denoise MEG channels using leave-one-out temporal projection.\n\nParameters\n----------\nraw : instance of Raw\n    Raw data to denoise.\nduration : float | str\n    The window duration (in seconds; default 10.) to use. Can also\n    be \"min\" to use as short a window as possible.\n%(picks_all_data)s\n%(verbose)s\n\nReturns\n-------\nraw_clean : instance of Raw\n    The cleaned data.\n\nNotes\n-----\nThis algorithm is computationally expensive, and can be several times\nslower than realtime for conventional M/EEG datasets. It uses a\nleave-one-out procedure with parallel temporal projection to remove\nindividual sensor noise under the assumption that sampled fields\n(e.g., MEG and EEG) are oversampled by the sensor array\n:footcite:`LarsonTaulu2018`.\n\nOTP can improve sensor noise levels (especially under visual\ninspection) and repair some bad channels. This noise reduction is known\nto interact with :func:`tSSS <mne.preprocessing.maxwell_filter>` such\nthat increasing the ``st_correlation`` value will likely be necessary.\n\nChannels marked as bad will not be used to reconstruct good channels,\nbut good channels will be used to process the bad channels. Depending\non the type of noise present in the bad channels, this might make\nthem usable again.\n\nUse of this algorithm is covered by a provisional patent.\n\n.. versionadded:: 0.16\n\nReferences\n----------\n.. footbibliography::", "metadata": {}}
{"_id": "mne_mne_preprocessing/realign.py_realign_raw_doc", "text": "Realign two simultaneous recordings.\n\nDue to clock drift, recordings at a given same sample rate made by two\nseparate devices simultaneously can become out of sync over time. This\nfunction uses event times captured by both acquisition devices to resample\n``other`` to match ``raw``.\n\nParameters\n----------\nraw : instance of Raw\n    The first raw instance.\nother : instance of Raw\n    The second raw instance. It will be resampled to match ``raw``.\nt_raw : array-like, shape (n_events,)\n    The times of shared events in ``raw`` relative to ``raw.times[0]`` (0).\n    Typically these could be events on some TTL channel such as::\n\n        find_events(raw)[:, 0] / raw.info[\"sfreq\"] - raw.first_time\nt_other : array-like, shape (n_events,)\n    The times of shared events in ``other`` relative to ``other.times[0]``.\n%(verbose)s\n\nNotes\n-----\nThis function operates inplace. It will:\n\n1. Estimate the zero-order (start offset) and first-order (clock drift)\n   correction.\n2. Crop the start of ``raw`` or ``other``, depending on which started\n   recording first.\n3. Resample ``other`` to match ``raw`` based on the clock drift.\n4. Realign the onsets and durations in ``other.annotations``.\n5. Crop the end of ``raw`` or ``other``, depending on which stopped\n   recording first (and the clock drift rate).\n\nThis function is primarily designed to work on recordings made at the same\nsample rate, but it can also operate on recordings made at different\nsample rates to resample and deal with clock drift simultaneously.\n\n.. versionadded:: 0.22", "metadata": {}}
{"_id": "mne_mne_preprocessing/hfc.py_compute_proj_hfc_doc", "text": "Generate projectors to perform homogeneous/harmonic correction to data.\n\nRemove environmental fields from magnetometer data by assuming it is\nexplained as a homogeneous :footcite:`TierneyEtAl2021` or harmonic field\n:footcite:`TierneyEtAl2022`. Useful for arrays of OPMs.\n\nParameters\n----------\n%(info)s\norder : int\n    The order of the spherical harmonic basis set to use. Set to 1 to use\n    only the homogeneous field component (default), 2 to add gradients, 3\n    to add quadrature terms, etc.\npicks : str | array_like | slice | None\n    Channels to include. Default of ``'meg'`` (same as None) will select\n    all non-reference MEG channels. Use ``('meg', 'ref_meg')`` to include\n    reference sensors as well.\nexclude : list | 'bads'\n    List of channels to exclude from HFC, only used when picking\n    based on types (e.g., exclude=\"bads\" when picks=\"meg\").\n    Specify ``'bads'`` (the default) to exclude all channels marked as bad.\naccuracy : str\n    Can be ``\"point\"``, ``\"normal\"`` or ``\"accurate\"`` (default), defines\n    which level of coil definition accuracy is used to generate model.\n%(verbose)s\n\nReturns\n-------\n%(projs)s\n\nSee Also\n--------\nmne.io.Raw.add_proj\nmne.io.Raw.apply_proj\n\nNotes\n-----\nTo apply the projectors to a dataset, use\n``inst.add_proj(projs).apply_proj()``.\n\n.. versionadded:: 1.4\n\nReferences\n----------\n.. footbibliography::", "metadata": {}}
{"_id": "mne_mne_preprocessing/_fine_cal.py_compute_fine_calibration_doc", "text": "Compute fine calibration from empty-room data.\n\nParameters\n----------\nraw : instance of Raw\n    The raw data to use. Should be from an empty-room recording,\n    and all channels should be good.\nn_imbalance : int\n    Can be 1 or 3 (default), indicating the number of gradiometer\n    imbalance components. Only used if gradiometers are present.\nt_window : float\n    Time window to use for surface normal rotation in seconds.\n    Default is 10.\n%(ext_order_maxwell)s\n    Default is 2, which is lower than the default (3) for\n    :func:`mne.preprocessing.maxwell_filter` because it tends to yield\n    more stable parameter estimates.\n%(origin_maxwell)s\n%(cross_talk_maxwell)s\ncalibration : dict | None\n    Dictionary with existing calibration. If provided, the magnetometer\n    imbalances and adjusted normals will be used and only the gradiometer\n    imbalances will be estimated (see step 2 in Notes below).\nangle_limit : float\n    The maximum permitted angle in degrees between the original and adjusted\n    magnetometer normals. If the angle is exceeded, the segment is treated as\n    an outlier and discarded.\n\n    .. versionadded:: 1.9\nerr_limit : float\n    The maximum error (in percent) for each channel in order for a segment to\n    be used.\n\n    .. versionadded:: 1.9\n%(verbose)s\n\nReturns\n-------\ncalibration : dict\n    Fine calibration data.\ncount : int\n    The number of good segments used to compute the magnetometer\n    parameters.\n\nSee Also\n--------\nmne.preprocessing.maxwell_filter\n\nNotes\n-----\nThis algorithm proceeds in two steps, both optimizing the fit between the\ndata and a reconstruction of the data based only on an external multipole\nexpansion:\n\n1. Estimate magnetometer normal directions and scale factors. All\n   coils (mag and matching grad) are rotated by the adjusted normal\n   direction.\n2. Estimate gradiometer imbalance factors. These add point magnetometers\n   in just the gradiometer difference direction or in all three directions\n   (depending on ``n_imbalance``).\n\nMagnetometer normal and coefficient estimation (1) is typically the most\ntime consuming step. Gradiometer imbalance parameters (2) can be\niteratively reestimated (for example, first using ``n_imbalance=1`` then\nsubsequently ``n_imbalance=3``) by passing the previous ``calibration``\noutput to the ``calibration`` input in the second call.\n\nMaxFilter processes at most 120 seconds of data, so consider cropping\nyour raw instance prior to processing. It also checks to make sure that\nthere were some minimal usable ``count`` number of segments (default 5)\nthat were included in the estimate.\n\n.. versionadded:: 0.21", "metadata": {}}
{"_id": "mne_mne_preprocessing/_fine_cal.py_read_fine_calibration_doc", "text": "Read fine calibration information from a ``.dat`` file.\n\nThe fine calibration typically includes improved sensor locations,\ncalibration coefficients, and gradiometer imbalance information.\n\nParameters\n----------\nfname : path-like\n    The filename.\n\nReturns\n-------\ncalibration : dict\n    Fine calibration information. Key-value pairs are:\n\n    - ``ch_names``\n         List of str of the channel names.\n    - ``locs``\n         Coil location and orientation parameters.\n    - ``imb_cals``\n         For magnetometers, the calibration coefficients.\n         For gradiometers, one or three imbalance parameters.", "metadata": {}}
{"_id": "mne_mne_preprocessing/_fine_cal.py_write_fine_calibration_doc", "text": "Write fine calibration information to a ``.dat`` file.\n\nParameters\n----------\nfname : path-like\n    The filename to write out.\ncalibration : dict\n    Fine calibration information.", "metadata": {}}
{"_id": "mne_mne_preprocessing/eog.py_find_eog_events_doc", "text": "Locate EOG artifacts.\n\n.. note:: To control true-positive and true-negative detection rates, you\n          may adjust the ``thresh`` parameter.\n\nParameters\n----------\nraw : instance of Raw\n    The raw data.\nevent_id : int\n    The index to assign to found events.\nl_freq : float\n    Low cut-off frequency to apply to the EOG channel in Hz.\nh_freq : float\n    High cut-off frequency to apply to the EOG channel in Hz.\nfilter_length : str | int | None\n    Number of taps to use for filtering.\n%(ch_name_eog)s\ntstart : float\n    Start detection after tstart seconds.\nreject_by_annotation : bool\n    Whether to omit data that is annotated as bad.\nthresh : float | None\n    Threshold to trigger the detection of an EOG event. This controls the\n    thresholding of the underlying peak-finding algorithm. Larger values\n    mean that fewer peaks (i.e., fewer EOG events) will be detected.\n    If ``None``, use the default of ``(max(eog) - min(eog)) / 4``,\n    with ``eog`` being the filtered EOG signal.\n%(verbose)s\n\nReturns\n-------\neog_events : array\n    Events.\n\nSee Also\n--------\ncreate_eog_epochs\ncompute_proj_eog", "metadata": {}}
{"_id": "mne_mne_preprocessing/eog.py_create_eog_epochs_doc", "text": "Conveniently generate epochs around EOG artifact events.\n\n%(create_eog_epochs)s\n\nParameters\n----------\nraw : instance of Raw\n    The raw data.\n%(ch_name_eog)s\nevent_id : int\n    The index to assign to found events.\n%(picks_all)s\ntmin : float\n    Start time before event.\ntmax : float\n    End time after event.\nl_freq : float\n    Low pass frequency to apply to the EOG channel while finding events.\nh_freq : float\n    High pass frequency to apply to the EOG channel while finding events.\nreject : dict | None\n    Rejection parameters based on peak-to-peak amplitude.\n    Valid keys are 'grad' | 'mag' | 'eeg' | 'eog' | 'ecg'.\n    If reject is None then no rejection is done. Example::\n\n        reject = dict(grad=4000e-13, # T / m (gradiometers)\n                      mag=4e-12, # T (magnetometers)\n                      eeg=40e-6, # V (EEG channels)\n                      eog=250e-6 # V (EOG channels)\n                      )\n\nflat : dict | None\n    Rejection parameters based on flatness of signal.\n    Valid keys are 'grad' | 'mag' | 'eeg' | 'eog' | 'ecg', and values\n    are floats that set the minimum acceptable peak-to-peak amplitude.\n    If flat is None then no rejection is done.\nbaseline : tuple or list of length 2, or None\n    The time interval to apply rescaling / baseline correction.\n    If None do not apply it. If baseline is (a, b)\n    the interval is between \"a (s)\" and \"b (s)\".\n    If a is None the beginning of the data is used\n    and if b is None then b is set to the end of the interval.\n    If baseline is equal to (None, None) all the time\n    interval is used. If None, no correction is applied.\npreload : bool\n    Preload epochs or not.\n%(reject_by_annotation_epochs)s\n\n    .. versionadded:: 0.14.0\nthresh : float\n    Threshold to trigger EOG event.\n%(decim)s\n\n    .. versionadded:: 0.21.0\n%(verbose)s\n\nReturns\n-------\neog_epochs : instance of Epochs\n    Data epoched around EOG events.\n\nSee Also\n--------\nfind_eog_events\ncompute_proj_eog\n\nNotes\n-----\nFiltering is only applied to the EOG channel while finding events.\nThe resulting ``eog_epochs`` will have no filtering applied (i.e., have\nthe same filter properties as the input ``raw`` instance).", "metadata": {}}
{"_id": "mne_mne_preprocessing/infomax_.py_infomax_doc", "text": "Run (extended) Infomax ICA decomposition on raw data.\n\nParameters\n----------\ndata : np.ndarray, shape (n_samples, n_features)\n    The whitened data to unmix.\nweights : np.ndarray, shape (n_features, n_features)\n    The initialized unmixing matrix.\n    Defaults to None, which means the identity matrix is used.\nl_rate : float\n    This quantity indicates the relative size of the change in weights.\n    Defaults to ``0.01 / log(n_features ** 2)``.\n\n    .. note:: Smaller learning rates will slow down the ICA procedure.\n\nblock : int\n    The block size of randomly chosen data segments.\n    Defaults to floor(sqrt(n_times / 3.)).\nw_change : float\n    The change at which to stop iteration. Defaults to 1e-12.\nanneal_deg : float\n    The angle (in degrees) at which the learning rate will be reduced.\n    Defaults to 60.0.\nanneal_step : float\n    The factor by which the learning rate will be reduced once\n    ``anneal_deg`` is exceeded: ``l_rate *= anneal_step.``\n    Defaults to 0.9.\nextended : bool\n    Whether to use the extended Infomax algorithm or not.\n    Defaults to True.\nn_subgauss : int\n    The number of subgaussian components. Only considered for extended\n    Infomax. Defaults to 1.\nkurt_size : int\n    The window size for kurtosis estimation. Only considered for extended\n    Infomax. Defaults to 6000.\next_blocks : int\n    Only considered for extended Infomax. If positive, denotes the number\n    of blocks after which to recompute the kurtosis, which is used to\n    estimate the signs of the sources. In this case, the number of\n    sub-gaussian sources is automatically determined.\n    If negative, the number of sub-gaussian sources to be used is fixed\n    and equal to n_subgauss. In this case, the kurtosis is not estimated.\n    Defaults to 1.\nmax_iter : int\n    The maximum number of iterations. Defaults to 200.\n%(random_state)s\nblowup : float\n    The maximum difference allowed between two successive estimations of\n    the unmixing matrix. Defaults to 10000.\nblowup_fac : float\n    The factor by which the learning rate will be reduced if the difference\n    between two successive estimations of the unmixing matrix exceededs\n    ``blowup``: ``l_rate *= blowup_fac``. Defaults to 0.5.\nn_small_angle : int | None\n    The maximum number of allowed steps in which the angle between two\n    successive estimations of the unmixing matrix is less than\n    ``anneal_deg``. If None, this parameter is not taken into account to\n    stop the iterations. Defaults to 20.\nuse_bias : bool\n    This quantity indicates if the bias should be computed.\n    Defaults to True.\n%(verbose)s\nreturn_n_iter : bool\n    Whether to return the number of iterations performed. Defaults to\n    False.\n\nReturns\n-------\nunmixing_matrix : np.ndarray, shape (n_features, n_features)\n    The linear unmixing operator.\nn_iter : int\n    The number of iterations. Only returned if ``return_max_iter=True``.\n\nReferences\n----------\n.. [1] A. J. Bell, T. J. Sejnowski. An information-maximization approach to\n       blind separation and blind deconvolution. Neural Computation, 7(6),\n       1129-1159, 1995.\n.. [2] T. W. Lee, M. Girolami, T. J. Sejnowski. Independent component\n       analysis using an extended infomax algorithm for mixed subgaussian\n       and supergaussian sources. Neural Computation, 11(2), 417-441, 1999.", "metadata": {}}
{"_id": "mne_mne_preprocessing/_pca_obs.py_apply_pca_obs_doc", "text": "Apply the PCA-OBS algorithm to picks of a Raw object.\n\nUses the optimal basis set (OBS) algorithm from :footcite:`NiazyEtAl2005`.\n\nParameters\n----------\nraw : instance of Raw\n    The raw data to process.\n%(picks_all_data_noref)s\nqrs_times : ndarray, shape (n_peaks,)\n    Array of times in the Raw data of detected R-peaks in ECG channel.\nn_components : int\n    Number of PCA components to use to form the OBS (default 4).\n%(n_jobs)s\ncopy : bool\n    If False, modify the Raw instance in-place.\n    If True (default), copy the raw instance before processing.\n%(verbose)s\n\nReturns\n-------\nraw : instance of Raw\n    The modified raw instance.\n\nNotes\n-----\n.. versionadded:: 1.10\n\nReferences\n----------\n.. footbibliography::", "metadata": {}}
{"_id": "mne_mne_preprocessing/ctps_.py_ctps_doc", "text": "Compute cross-trial-phase-statistics [1].\n\nNote. It is assumed that the sources are already\nappropriately filtered\n\nParameters\n----------\ndata: ndarray, shape (n_epochs, n_channels, n_times)\n    Any kind of data of dimensions trials, traces, features.\nis_raw : bool\n    If True it is assumed that data haven't been transformed to Hilbert\n    space and phase angles haven't been normalized. Defaults to True.\n\nReturns\n-------\nks_dynamics : ndarray, shape (n_sources, n_times)\n    The kuiper statistics.\npk_dynamics : ndarray, shape (n_sources, n_times)\n    The normalized kuiper index for ICA sources and\n    time slices.\nphase_angles : ndarray, shape (n_epochs, n_sources, n_times) | None\n    The phase values for epochs, sources and time slices. If ``is_raw``\n    is False, None is returned.\n\nReferences\n----------\n[1] Dammers, J., Schiek, M., Boers, F., Silex, C., Zvyagintsev,\n    M., Pietrzyk, U., Mathiak, K., 2008. Integration of amplitude\n    and phase statistics for complete artifact removal in independent\n    components of neuromagnetic recordings. Biomedical\n    Engineering, IEEE Transactions on 55 (10), 2353-2362.", "metadata": {}}
{"_id": "mne_mne_preprocessing/ctps_.py_kuiper_doc", "text": "Kuiper's test of uniform distribution.\n\nParameters\n----------\ndata : ndarray, shape (n_sources,) | (n_sources, n_times)\n       Empirical distribution.\ndtype : str | obj\n    The data type to be used.\n\nReturns\n-------\nks : ndarray\n    Kuiper's statistic.\npk : ndarray\n    Normalized probability of Kuiper's statistic [0, 1].", "metadata": {}}
{"_id": "mne_mne_preprocessing/_peak_finder.py_peak_finder_doc", "text": "Noise-tolerant fast peak-finding algorithm.\n\nParameters\n----------\nx0 : 1d array\n    A real vector from the maxima will be found (required).\nthresh : float | None\n    The amount above surrounding data for a peak to be\n    identified. Larger values mean the algorithm is more selective in\n    finding peaks. If ``None``, use the default of\n    ``(max(x0) - min(x0)) / 4``.\nextrema : {-1, 1}\n    1 if maxima are desired, -1 if minima are desired\n    (default = maxima, 1).\n%(verbose)s\n\nReturns\n-------\npeak_loc : array\n    The indices of the identified peaks in x0.\npeak_mag : array\n    The magnitude of the identified peaks.\n\nNotes\n-----\nIf repeated values are found the first is identified as the peak.\nConversion from initial Matlab code from:\nNathanael C. Yoder (ncyoder@purdue.edu)\n\nExamples\n--------\n>>> import numpy as np\n>>> from mne.preprocessing import peak_finder\n>>> t = np.arange(0, 3, 0.01)\n>>> x = np.sin(np.pi*t) - np.sin(0.5*np.pi*t)\n>>> peak_locs, peak_mags = peak_finder(x) # doctest: +SKIP\n>>> peak_locs # doctest: +SKIP\narray([36, 260]) # doctest: +SKIP\n>>> peak_mags # doctest: +SKIP\narray([0.36900026, 1.76007351]) # doctest: +SKIP", "metadata": {}}
{"_id": "mne_mne_preprocessing/ica.py_get_score_funcs_doc", "text": "Get the score functions.\n\nReturns\n-------\nscore_funcs : dict\n    The score functions.", "metadata": {}}
{"_id": "mne_mne_preprocessing/ica.py_ica_find_ecg_events_doc", "text": "Find ECG peaks from one selected ICA source.\n\nParameters\n----------\nraw : instance of Raw\n    Raw object to draw sources from.\necg_source : ndarray\n    ICA source resembling ECG to find peaks from.\nevent_id : int\n    The index to assign to found events.\ntstart : float\n    Start detection after tstart seconds. Useful when beginning\n    of run is noisy.\nl_freq : float\n    Low pass frequency.\nh_freq : float\n    High pass frequency.\nqrs_threshold : float | str\n    Between 0 and 1. qrs detection threshold. Can also be \"auto\" to\n    automatically choose the threshold that generates a reasonable\n    number of heartbeats (40-160 beats / min).\n%(verbose)s\n\nReturns\n-------\necg_events : array\n    Events.\nch_ECG : string\n    Name of channel used.\naverage_pulse : float.\n    Estimated average pulse.", "metadata": {}}
{"_id": "mne_mne_preprocessing/ica.py_ica_find_eog_events_doc", "text": "Locate EOG artifacts from one selected ICA source.\n\nParameters\n----------\nraw : instance of Raw\n    The raw data.\neog_source : ndarray\n    ICA source resembling EOG to find peaks from.\nevent_id : int\n    The index to assign to found events.\nl_freq : float\n    Low cut-off frequency in Hz.\nh_freq : float\n    High cut-off frequency in Hz.\n%(verbose)s\n\nReturns\n-------\neog_events : array\n    Events.", "metadata": {}}
{"_id": "mne_mne_preprocessing/ica.py_read_ica_doc", "text": "Restore ICA solution from fif file.\n\nParameters\n----------\nfname : path-like\n    Absolute path to fif file containing ICA matrices.\n    The file name should end with -ica.fif or -ica.fif.gz.\n%(verbose)s\n\nReturns\n-------\nica : instance of ICA\n    The ICA estimator.", "metadata": {}}
{"_id": "mne_mne_preprocessing/ica.py_corrmap_doc", "text": "Find similar Independent Components across subjects by map similarity.\n\nCorrmap :footcite:p:`CamposViolaEtAl2009` identifies the best group\nmatch to a supplied template. Typically, feed it a list of fitted ICAs and\na template IC, for example, the blink for the first subject, to identify\nspecific ICs across subjects.\n\nThe specific procedure consists of two iterations. In a first step, the\nmaps best correlating with the template are identified. In the next step,\nthe analysis is repeated with the mean of the maps identified in the first\nstage.\n\nRun with ``plot`` and ``show`` set to ``True`` and ``label=False`` to find\ngood parameters. Then, run with labelling enabled to apply the\nlabelling in the IC objects. (Running with both ``plot`` and ``labels``\noff does nothing.)\n\nOutputs a list of fitted ICAs with the indices of the marked ICs in a\nspecified field.\n\nThe original Corrmap website: www.debener.de/corrmap/corrmapplugin1.html\n\nParameters\n----------\nicas : list of mne.preprocessing.ICA\n    A list of fitted ICA objects.\ntemplate : tuple | np.ndarray, shape (n_components,)\n    Either a tuple with two elements (int, int) representing the list\n    indices of the set from which the template should be chosen, and the\n    template. E.g., if template=(1, 0), the first IC of the 2nd ICA object\n    is used.\n    Or a numpy array whose size corresponds to each IC map from the\n    supplied maps, in which case this map is chosen as the template.\nthreshold : \"auto\" | list of float | float\n    Correlation threshold for identifying ICs\n    If \"auto\", search for the best map by trying all correlations between\n    0.6 and 0.95. In the original proposal, lower values are considered,\n    but this is not yet implemented.\n    If list of floats, search for the best map in the specified range of\n    correlation strengths. As correlation values, must be between 0 and 1\n    If float > 0, select ICs correlating better than this.\n    If float > 1, use z-scoring to identify ICs within subjects (not in\n    original Corrmap)\n    Defaults to \"auto\".\nlabel : None | str\n    If not None, categorised ICs are stored in a dictionary ``labels_``\n    under the given name. Preexisting entries will be appended to\n    (excluding repeats), not overwritten. If None, a dry run is performed\n    and the supplied ICs are not changed.\nch_type : 'mag' | 'grad' | 'planar1' | 'planar2' | 'eeg'\n    The channel type to plot. Defaults to 'eeg'.\n%(sensors_topomap)s\n%(show_names_topomap)s\n%(contours_topomap)s\n%(outlines_topomap)s\n%(sphere_topomap_auto)s\n%(image_interp_topomap)s\n\n    .. versionadded:: 1.2\n%(extrapolate_topomap)s\n\n    .. versionadded:: 1.2\n%(border_topomap)s\n\n    .. versionadded:: 1.2\n%(cmap_topomap_simple)s\nplot : bool\n    Should constructed template and selected maps be plotted? Defaults\n    to True.\n%(show)s\n%(verbose)s\n\nReturns\n-------\ntemplate_fig : Figure\n    Figure showing the template.\nlabelled_ics : Figure\n    Figure showing the labelled ICs in all ICA decompositions.\n\nReferences\n----------\n.. footbibliography::", "metadata": {}}
{"_id": "mne_mne_preprocessing/ica.py_read_ica_eeglab_doc", "text": "Load ICA information saved in an EEGLAB .set file.\n\nParameters\n----------\nfname : path-like\n    Complete path to a ``.set`` EEGLAB file that contains an ICA object.\n%(montage_units)s\n\n    .. versionadded:: 1.6\n%(verbose)s\n\nReturns\n-------\nica : instance of ICA\n    An ICA object based on the information contained in the input file.", "metadata": {}}
{"_id": "mne_mne_preprocessing/ica.py_fit_doc", "text": "Run the ICA decomposition on raw data.\n\nCaveat! If supplying a noise covariance keep track of the projections\navailable in the cov, the raw or the epochs object. For example,\nif you are interested in EOG or ECG artifacts, EOG and ECG projections\nshould be temporally removed before fitting the ICA.\n\nParameters\n----------\ninst : instance of Raw or Epochs\n    The data to be decomposed.\n%(picks_good_data_noref)s\n    This selection remains throughout the initialized ICA solution.\nstart, stop : int | float | None\n    First and last sample to include. If float, data will be\n    interpreted as time in seconds. If ``None``, data will be used from\n    the first sample and to the last sample, respectively.\n\n    .. note:: These parameters only have an effect if ``inst`` is\n              `~mne.io.Raw` data.\ndecim : int | None\n    Increment for selecting only each n-th sampling point. If ``None``,\n    all samples  between ``start`` and ``stop`` (inclusive) are used.\nreject, flat : dict | None\n    Rejection parameters based on peak-to-peak amplitude (PTP)\n    in the continuous data. Signal periods exceeding the thresholds\n    in ``reject`` or less than the thresholds in ``flat`` will be\n    removed before fitting the ICA.\n\n    .. note:: These parameters only have an effect if ``inst`` is\n              `~mne.io.Raw` data. For `~mne.Epochs`, perform PTP\n              rejection via :meth:`~mne.Epochs.drop_bad`.\n\n    Valid keys are all channel types present in the data. Values must\n    be integers or floats.\n\n    If ``None``, no PTP-based rejection will be performed. Example::\n\n        reject = dict(\n            grad=4000e-13, # T / m (gradiometers)\n            mag=4e-12, # T (magnetometers)\n            eeg=40e-6, # V (EEG channels)\n            eog=250e-6 # V (EOG channels)\n        )\n        flat = None  # no rejection based on flatness\ntstep : float\n    Length of data chunks for artifact rejection in seconds.\n\n    .. note:: This parameter only has an effect if ``inst`` is\n              `~mne.io.Raw` data.\n%(reject_by_annotation_raw)s\n\n    .. versionadded:: 0.14.0\n%(verbose)s\n\nReturns\n-------\nself : instance of ICA\n    Returns the modified instance.", "metadata": {}}
{"_id": "mne_mne_preprocessing/ica.py_get_components_doc", "text": "Get ICA topomap for components as numpy arrays.\n\nReturns\n-------\ncomponents : array, shape (n_channels, n_components)\n    The ICA components (maps).", "metadata": {}}
{"_id": "mne_mne_preprocessing/ica.py_get_explained_variance_ratio_doc", "text": "Get the proportion of data variance explained by ICA components.\n\nParameters\n----------\ninst : mne.io.BaseRaw | mne.BaseEpochs | mne.Evoked\n    The uncleaned data.\ncomponents : array-like of int | int | None\n    The component(s) for which to do the calculation. If more than one\n    component is specified, explained variance will be calculated\n    jointly across all supplied components. If ``None`` (default), uses\n    all available components.\nch_type : 'mag' | 'grad' | 'planar1' | 'planar2' | 'eeg' | array-like of str | None\n    The channel type(s) to include in the calculation. If ``None``, all\n    available channel types will be used.\n\nReturns\n-------\ndict (str, float)\n    The fraction of variance in ``inst`` that can be explained by the\n    ICA components, calculated separately for each channel type.\n    Dictionary keys are the channel types, and corresponding explained\n    variance ratios are the values.\n\nNotes\n-----\nA value similar to EEGLAB's ``pvaf`` (percent variance accounted for)\nwill be calculated for the specified component(s).\n\nSince ICA components cannot be assumed to be aligned orthogonally, the\nsum of the proportion of variance explained by all components may not\nbe equal to 1. In certain situations, the proportion of variance\nexplained by a component may even be negative.\n\n.. versionadded:: 1.2", "metadata": {}}
{"_id": "mne_mne_preprocessing/ica.py_get_sources_doc", "text": "Estimate sources given the unmixing matrix.\n\nThis method will return the sources in the container format passed.\nTypical usecases:\n\n1. pass Raw object to use `raw.plot <mne.io.Raw.plot>` for ICA sources\n2. pass Epochs object to compute trial-based statistics in ICA space\n3. pass Evoked object to investigate time-locking in ICA space\n\nParameters\n----------\ninst : instance of Raw, Epochs or Evoked\n    Object to compute sources from and to represent sources in.\nadd_channels : None | list of str\n    Additional channels  to be added. Useful to e.g. compare sources\n    with some reference. Defaults to None.\nstart : int | float | None\n    First sample to include. If float, data will be interpreted as\n    time in seconds. If None, the entire data will be used.\nstop : int | float | None\n    Last sample to not include. If float, data will be interpreted as\n    time in seconds. If None, the entire data will be used.\n\nReturns\n-------\nsources : instance of Raw, Epochs or Evoked\n    The ICA sources time series.", "metadata": {}}
{"_id": "mne_mne_preprocessing/ica.py_score_sources_doc", "text": "Assign score to components based on statistic or metric.\n\nParameters\n----------\ninst : instance of Raw, Epochs or Evoked\n    The object to reconstruct the sources from.\ntarget : array-like | str | None\n    Signal to which the sources shall be compared. It has to be of\n    the same shape as the sources. If str, a routine will try to find\n    a matching channel name. If None, a score\n    function expecting only one input-array argument must be used,\n    for instance, scipy.stats.skew (default).\nscore_func : callable | str\n    Callable taking as arguments either two input arrays\n    (e.g. Pearson correlation) or one input\n    array (e. g. skewness) and returns a float. For convenience the\n    most common score_funcs are available via string labels:\n    Currently, all distance metrics from scipy.spatial and All\n    functions from scipy.stats taking compatible input arguments are\n    supported. These function have been modified to support iteration\n    over the rows of a 2D array.\nstart : int | float | None\n    First sample to include. If float, data will be interpreted as\n    time in seconds. If None, data will be used from the first sample.\nstop : int | float | None\n    Last sample to not include. If float, data will be interpreted as\n    time in seconds. If None, data will be used to the last sample.\nl_freq : float\n    Low pass frequency.\nh_freq : float\n    High pass frequency.\n%(reject_by_annotation_all)s\n\n    .. versionadded:: 0.14.0\n%(verbose)s\n\nReturns\n-------\nscores : ndarray\n    Scores for each source as returned from score_func.", "metadata": {}}
{"_id": "mne_mne_preprocessing/ica.py_find_bads_ecg_doc", "text": "Detect ECG related components.\n\nCross-trial phase statistics :footcite:`DammersEtAl2008` or Pearson\ncorrelation can be used for detection.\n\n.. note:: If no ECG channel is available, an artificial ECG channel will be\n          created based on cross-channel averaging of ``\"mag\"`` or ``\"grad\"``\n          channels. If neither of these channel types are available in\n          ``inst``, artificial ECG channel creation is impossible.\n\nParameters\n----------\ninst : instance of Raw, Epochs or Evoked\n    Object to compute sources from.\n%(ch_name_ecg)s\nthreshold : float | 'auto'\n    Value above which a feature is classified as outlier. See Notes.\n\n    .. versionchanged:: 0.21\nstart : int | float | None\n    First sample to include. If float, data will be interpreted as\n    time in seconds. If None, data will be used from the first sample.\n    When working with Epochs or Evoked objects, must be float or None.\nstop : int | float | None\n    Last sample to not include. If float, data will be interpreted as\n    time in seconds. If None, data will be used to the last sample.\n    When working with Epochs or Evoked objects, must be float or None.\nl_freq : float\n    Low pass frequency.\nh_freq : float\n    High pass frequency.\nmethod : 'ctps' | 'correlation'\n    The method used for detection. If ``'ctps'``, cross-trial phase\n    statistics :footcite:`DammersEtAl2008` are used to detect\n    ECG-related components. See Notes.\n%(reject_by_annotation_all)s\n\n    .. versionadded:: 0.14.0\n%(measure)s\n%(verbose)s\n\nReturns\n-------\necg_idx : list of int\n    The indices of ECG-related components.\nscores : np.ndarray of float, shape (``n_components_``)\n    If method is 'ctps', the normalized Kuiper index scores. If method\n    is 'correlation', the correlation scores.\n\nSee Also\n--------\nfind_bads_eog, find_bads_ref, find_bads_muscle\n\nNotes\n-----\nThe ``threshold``, ``method``, and ``measure`` parameters interact in\nthe following ways:\n\n- If ``method='ctps'``, ``threshold`` refers to the significance value\n  of a Kuiper statistic, and ``threshold='auto'`` will compute the\n  threshold automatically based on the sampling frequency.\n- If ``method='correlation'`` and ``measure='correlation'``,\n  ``threshold`` refers to the Pearson correlation value, and\n  ``threshold='auto'`` sets the threshold to 0.9.\n- If ``method='correlation'`` and ``measure='zscore'``, ``threshold``\n  refers to the z-score value (i.e., standard deviations) used in the\n  iterative z-scoring method, and ``threshold='auto'`` sets the\n  threshold to 3.0.\n\nReferences\n----------\n.. footbibliography::", "metadata": {}}
{"_id": "mne_mne_preprocessing/ica.py_find_bads_ref_doc", "text": "Detect MEG reference related components using correlation.\n\nParameters\n----------\ninst : instance of Raw, Epochs or Evoked\n    Object to compute sources from. Should contain at least one channel\n    i.e. component derived from MEG reference channels.\nch_name : list of str\n    Which MEG reference components to use. If None, then all channels\n    that begin with REF_ICA.\nthreshold : float | str\n    Value above which a feature is classified as outlier.\n\n    - If ``measure`` is ``'zscore'``, defines the threshold on the\n      z-score used in the iterative z-scoring method.\n    - If ``measure`` is ``'correlation'``, defines the absolute\n      threshold on the correlation between 0 and 1.\n    - If ``'auto'``, defaults to 3.0 if ``measure`` is ``'zscore'`` and\n      0.9 if ``measure`` is ``'correlation'``.\n\n     .. warning::\n         If ``method`` is ``'together'``, the iterative z-score method\n         is always used.\nstart : int | float | None\n    First sample to include. If float, data will be interpreted as\n    time in seconds. If None, data will be used from the first sample.\nstop : int | float | None\n    Last sample to not include. If float, data will be interpreted as\n    time in seconds. If None, data will be used to the last sample.\nl_freq : float\n    Low pass frequency.\nh_freq : float\n    High pass frequency.\n%(reject_by_annotation_all)s\nmethod : 'together' | 'separate'\n    Method to use to identify reference channel related components.\n    Defaults to ``'together'``. See notes.\n\n    .. versionadded:: 0.21\n%(measure)s\n%(verbose)s\n\nReturns\n-------\nref_idx : list of int\n    The indices of MEG reference related components, sorted by score.\nscores : np.ndarray of float, shape (``n_components_``) | list of array\n    The correlation scores.\n\nSee Also\n--------\nfind_bads_ecg, find_bads_eog, find_bads_muscle\n\nNotes\n-----\nICA decomposition on MEG reference channels is used to assess external\nmagnetic noise and remove it from the MEG. Two methods are supported:\n\nWith the ``'together'`` method, only one ICA fit is used, which\nencompasses both MEG and reference channels together. Components which\nhave particularly strong weights on the reference channels may be\nthresholded and marked for removal.\n\nWith ``'separate'`` selected components from a separate ICA\ndecomposition on the reference channels are used as a ground truth for\nidentifying bad components in an ICA fit done on MEG channels only. The\nlogic here is similar to an EOG/ECG, with reference components\nreplacing the EOG/ECG channels. Recommended procedure is to perform ICA\nseparately on reference channels, extract them using\n:meth:`~mne.preprocessing.ICA.get_sources`, and then append them to the\ninst using :meth:`~mne.io.Raw.add_channels`, preferably with the prefix\n``REF_ICA`` so that they can be automatically detected.\n\nWith ``'together'``, thresholding is based on adaptative z-scoring.\n\nWith ``'separate'``:\n\n- If ``measure`` is ``'zscore'``, thresholding is based on adaptative\n  z-scoring.\n- If ``measure`` is ``'correlation'``, threshold defines the absolute\n  threshold on the correlation between 0 and 1.\n\nValidation and further documentation for this technique can be found\nin :footcite:`HannaEtAl2020`.\n\n.. versionadded:: 0.18\n\nReferences\n----------\n.. footbibliography::", "metadata": {}}
{"_id": "mne_mne_preprocessing/ica.py_find_bads_muscle_doc", "text": "Detect muscle-related components.\n\nDetection is based on :footcite:`DharmapraniEtAl2016` which uses\ndata from a subject who has been temporarily paralyzed\n:footcite:`WhithamEtAl2007`. The criteria are threefold:\n\n#. Positive log-log spectral slope from 7 to 45 Hz\n#. Peripheral component power (farthest away from the vertex)\n#. A single focal point measured by low spatial smoothness\n\nThe threshold is relative to the slope, focal point and smoothness\nof a typical muscle-related ICA component. Note the high frequency\nof the power spectral density slope was 75 Hz in the reference but\nhas been modified to 45 Hz as a default based on the criteria being\nmore accurate in practice.\n\nIf ``inst`` is supplied without sensor positions, only the first criterion\n(slope) is applied.\n\nParameters\n----------\ninst : instance of Raw, Epochs or Evoked\n    Object to compute sources from.\nthreshold : float | str\n    Value above which a component should be marked as muscle-related,\n    relative to a typical muscle component.\nstart : int | float | None\n    First sample to include. If float, data will be interpreted as\n    time in seconds. If None, data will be used from the first sample.\nstop : int | float | None\n    Last sample to not include. If float, data will be interpreted as\n    time in seconds. If None, data will be used to the last sample.\nl_freq : float\n    Low frequency for muscle-related power.\nh_freq : float\n    High frequency for muscle-related power.\n%(sphere_topomap_auto)s\n%(verbose)s\n\nReturns\n-------\nmuscle_idx : list of int\n    The indices of muscle-related components, sorted by score.\nscores : np.ndarray of float, shape (``n_components_``) | list of array\n    The correlation scores.\n\nSee Also\n--------\nfind_bads_ecg, find_bads_eog, find_bads_ref\n\nNotes\n-----\n.. versionadded:: 1.1", "metadata": {}}
{"_id": "mne_mne_preprocessing/ica.py_find_bads_eog_doc", "text": "Detect EOG related components using correlation.\n\nDetection is based on Pearson correlation between the\nfiltered data and the filtered EOG channel.\nThresholding is based on adaptive z-scoring. The above threshold\ncomponents will be masked and the z-score will be recomputed\nuntil no supra-threshold component remains.\n\nParameters\n----------\ninst : instance of Raw, Epochs or Evoked\n    Object to compute sources from.\nch_name : str\n    The name of the channel to use for EOG peak detection.\n    The argument is mandatory if the dataset contains no EOG\n    channels.\nthreshold : float | str\n    Value above which a feature is classified as outlier.\n\n    - If ``measure`` is ``'zscore'``, defines the threshold on the\n      z-score used in the iterative z-scoring method.\n    - If ``measure`` is ``'correlation'``, defines the absolute\n      threshold on the correlation between 0 and 1.\n    - If ``'auto'``, defaults to 3.0 if ``measure`` is ``'zscore'`` and\n      0.9 if ``measure`` is ``'correlation'``.\nstart : int | float | None\n    First sample to include. If float, data will be interpreted as\n    time in seconds. If None, data will be used from the first sample.\nstop : int | float | None\n    Last sample to not include. If float, data will be interpreted as\n    time in seconds. If None, data will be used to the last sample.\nl_freq : float\n    Low pass frequency.\nh_freq : float\n    High pass frequency.\n%(reject_by_annotation_all)s\n\n    .. versionadded:: 0.14.0\n%(measure)s\n%(verbose)s\n\nReturns\n-------\neog_idx : list of int\n    The indices of EOG related components, sorted by score.\nscores : np.ndarray of float, shape (``n_components_``) | list of array\n    The correlation scores.\n\nSee Also\n--------\nfind_bads_ecg, find_bads_ref, find_bads_muscle", "metadata": {}}
{"_id": "mne_mne_preprocessing/ica.py_apply_doc", "text": "Remove selected components from the signal.\n\nGiven the unmixing matrix, transform the data,\nzero out all excluded components, and inverse-transform the data.\nThis procedure will reconstruct M/EEG signals from which\nthe dynamics described by the excluded components is subtracted.\n\nParameters\n----------\ninst : instance of Raw, Epochs or Evoked\n    The data to be processed (i.e., cleaned). It will be modified\n    in-place.\ninclude : array_like of int\n    The indices referring to columns in the ummixing matrix. The\n    components to be kept. If ``None`` (default), all components\n    will be included (minus those defined in ``ica.exclude``\n    and the ``exclude`` parameter, see below).\nexclude : array_like of int\n    The indices referring to columns in the ummixing matrix. The\n    components to be zeroed out. If ``None`` (default) or an\n    empty list, only components from ``ica.exclude`` will be\n    excluded. Else, the union of ``exclude`` and ``ica.exclude``\n    will be excluded.\n%(n_pca_components_apply)s\nstart : int | float | None\n    First sample to include. If float, data will be interpreted as\n    time in seconds. If None, data will be used from the first sample.\nstop : int | float | None\n    Last sample to not include. If float, data will be interpreted as\n    time in seconds. If None, data will be used to the last sample.\n%(on_baseline_ica)s\n%(verbose)s\n\nReturns\n-------\nout : instance of Raw, Epochs or Evoked\n    The processed data.\n\nNotes\n-----\n.. note:: Applying ICA may introduce a DC shift. If you pass\n          baseline-corrected `~mne.Epochs` or `~mne.Evoked` data,\n          the baseline period of the cleaned data may not be of\n          zero mean anymore. If you require baseline-corrected\n          data, apply baseline correction again after cleaning\n          via ICA. A warning will be emitted to remind you of this\n          fact if you pass baseline-corrected data.\n\n.. versionchanged:: 0.23\n    Warn if instance was baseline-corrected.", "metadata": {}}
{"_id": "mne_mne_preprocessing/ica.py_save_doc", "text": "Store ICA solution into a fiff file.\n\nParameters\n----------\nfname : path-like\n    The absolute path of the file name to save the ICA solution into.\n    The file name should end with ``-ica.fif`` or ``-ica.fif.gz``.\n%(overwrite)s\n\n    .. versionadded:: 1.0\n%(verbose)s\n\nReturns\n-------\nica : instance of ICA\n    The object.\n\nSee Also\n--------\nread_ica", "metadata": {}}
{"_id": "mne_mne_preprocessing/ica.py_copy_doc", "text": "Copy the ICA object.\n\nReturns\n-------\nica : instance of ICA\n    The copied object.", "metadata": {}}
{"_id": "mne_mne_preprocessing/_csd.py_compute_current_source_density_doc", "text": "Get the current source density (CSD) transformation.\n\nTransformation based on spherical spline surface Laplacian\n:footcite:`PerrinEtAl1987,PerrinEtAl1989,Cohen2014,KayserTenke2015`.\n\nThis function can be used to re-reference the signal using a Laplacian\n(LAP) \"reference-free\" transformation.\n\nParameters\n----------\ninst : instance of Raw, Epochs or Evoked\n    The data to be transformed.\nsphere : array-like, shape (4,) | str\n    The sphere, head-model of the form (x, y, z, r) where x, y, z\n    is the center of the sphere and r is the radius in meters.\n    Can also be \"auto\" to use a digitization-based fit.\nlambda2 : float\n    Regularization parameter, produces smoothness. Defaults to 1e-5.\nstiffness : float\n    Stiffness of the spline.\nn_legendre_terms : int\n    Number of Legendre terms to evaluate.\ncopy : bool\n    Whether to overwrite instance data or create a copy.\n%(verbose)s\n\nReturns\n-------\ninst_csd : instance of Raw, Epochs or Evoked\n    The transformed data. Output type will match input type.\n\nNotes\n-----\n.. versionadded:: 0.20\n\nReferences\n----------\n.. footbibliography::", "metadata": {}}
{"_id": "mne_mne_preprocessing/_csd.py_compute_bridged_electrodes_doc", "text": "Compute bridged EEG electrodes using the intrinsic Hjorth algorithm.\n\nFirst, an electrical distance matrix is computed by taking the pairwise\nvariance between electrodes. Local minimums in this matrix below\n``lm_cutoff`` are indicative of bridging between a pair of electrodes.\nPairs of electrodes are marked as bridged as long as their electrical\ndistance is below ``lm_cutoff`` on more than the ``epoch_threshold``\nproportion of epochs.\n\nBased on :footcite:`TenkeKayser2001,GreischarEtAl2004,DelormeMakeig2004`\nand the `EEGLAB implementation\n<https://psychophysiology.cpmc.columbia.edu/>`__.\n\nParameters\n----------\ninst : instance of Raw, Epochs or Evoked\n    The data to compute electrode bridging on.\nlm_cutoff : float\n    The distance in :math:`{\\mu}V^2` cutoff below which to\n    search for a local minimum (lm) indicative of bridging.\n    EEGLAB defaults to 5 :math:`{\\mu}V^2`. MNE defaults to\n    16 :math:`{\\mu}V^2` to be conservative based on the distributions in\n    :footcite:t:`GreischarEtAl2004`.\nepoch_threshold : float\n    The proportion of epochs with electrical distance less than\n    ``lm_cutoff`` in order to consider the channel bridged.\n    The default is 0.5.\nl_freq : float\n    The low cutoff frequency to use. Default is 0.5 Hz.\nh_freq : float\n    The high cutoff frequency to use. Default is 30 Hz.\nepoch_duration : float\n    The time in seconds to divide the raw into fixed-length epochs\n    to check for consistent bridging. Only used if ``inst`` is\n    :class:`mne.io.BaseRaw`. The default is 2 seconds.\nbw_method : None\n    ``bw_method`` to pass to :class:`scipy.stats.gaussian_kde`.\n%(verbose)s\n\nReturns\n-------\nbridged_idx : list of tuple\n    The indices of channels marked as bridged with each bridged\n    pair stored as a tuple.\ned_matrix : ndarray of float, shape (n_epochs, n_channels, n_channels)\n    The electrical distance matrix for each pair of EEG electrodes.\n\nNotes\n-----\n.. versionadded:: 1.1\n\nReferences\n----------\n.. footbibliography::", "metadata": {}}
{"_id": "mne_mne_preprocessing/_regress.py_regress_artifact_doc", "text": "Remove artifacts using regression based on reference channels.\n\nParameters\n----------\ninst : instance of Epochs | Raw\n    The instance to process.\n%(picks_good_data)s\nexclude : list | 'bads'\n    List of channels to exclude from the regression, only used when picking\n    based on types (e.g., exclude=\"bads\" when picks=\"meg\").\n    Specify ``'bads'`` (the default) to exclude all channels marked as bad.\n\n    .. versionadded:: 1.2\npicks_artifact : array-like | str\n    Channel picks to use as predictor/explanatory variables capturing\n    the artifact of interest (default is \"eog\").\nbetas : ndarray, shape (n_picks, n_picks_ref) | None\n    The regression coefficients to use. If None (default), they will be\n    estimated from the data.\nproj : bool\n    Whether to automatically apply SSP projection vectors before performing\n    the regression. Default is ``True``.\ncopy : bool\n    If True (default), copy the instance before modifying it.\n%(verbose)s\n\nReturns\n-------\ninst : instance of Epochs | Raw\n    The processed data.\nbetas : ndarray, shape (n_picks, n_picks_ref)\n    The betas used during regression.\n\nNotes\n-----\nTo implement the method outlined in :footcite:`GrattonEtAl1983`,\nremove the evoked response from epochs before estimating the\nregression coefficients, then apply those regression coefficients to the\noriginal data in two calls like (here for a single-condition ``epochs``\nonly):\n\n    >>> epochs_no_ave = epochs.copy().subtract_evoked()  # doctest:+SKIP\n    >>> _, betas = mne.preprocessing.regress(epochs_no_ave)  # doctest:+SKIP\n    >>> epochs_clean, _ = mne.preprocessing.regress(epochs, betas=betas)  # doctest:+SKIP\n\nReferences\n----------\n.. footbibliography::", "metadata": {}}
{"_id": "mne_mne_preprocessing/_regress.py_read_eog_regression_doc", "text": "Read an EOG regression model from an HDF5 file.\n\nParameters\n----------\nfname : path-like\n    The file to read the regression model from. Should end in ``.h5``.\n\nReturns\n-------\nmodel : EOGRegression\n    The regression model read from the file.\n\nNotes\n-----\n.. versionadded:: 1.2", "metadata": {}}
{"_id": "mne_mne_preprocessing/_regress.py_fit_doc", "text": "Fit EOG regression coefficients.\n\nParameters\n----------\ninst : Raw | Epochs | Evoked\n    The data on which the EOG regression weights should be fitted.\n\nReturns\n-------\nself : EOGRegression\n    The fitted ``EOGRegression`` object. The regression coefficients\n    are available as the ``.coef_`` and ``.intercept_`` attributes.\n\nNotes\n-----\nIf your data contains EEG channels, make sure to apply the desired\nreference (see :func:`mne.set_eeg_reference`) before performing EOG\nregression.", "metadata": {}}
{"_id": "mne_mne_preprocessing/_regress.py_apply_doc", "text": "Apply the regression coefficients to data.\n\nParameters\n----------\ninst : Raw | Epochs | Evoked\n    The data on which to apply the regression.\n%(copy_df)s\n\nReturns\n-------\ninst : Raw | Epochs | Evoked\n    A version of the data with the artifact channels regressed out.\n\nNotes\n-----\nOnly works after ``.fit()`` has been used.\n\nReferences\n----------\n.. footbibliography::", "metadata": {}}
{"_id": "mne_mne_preprocessing/_regress.py_save_doc", "text": "Save the regression model to an HDF5 file.\n\nParameters\n----------\nfname : path-like\n    The file to write the regression weights to. Should end in ``.h5``.\n%(overwrite)s", "metadata": {}}
{"_id": "mne_mne_preprocessing/_annotate_amplitude.py_annotate_amplitude_doc", "text": "Annotate raw data based on peak-to-peak amplitude.\n\nCreates annotations ``BAD_peak`` or ``BAD_flat`` for spans of data where\nconsecutive samples exceed the threshold in ``peak`` or fall below the\nthreshold in ``flat`` for more than ``min_duration``.\nChannels where more than ``bad_percent`` of the total recording length\nshould be annotated with either ``BAD_peak`` or ``BAD_flat`` are returned\nin ``bads`` instead.\nNote that the annotations and the bads are not automatically added to the\n:class:`~mne.io.Raw` object; use :meth:`~mne.io.Raw.set_annotations` and\n:class:`info['bads'] <mne.Info>` to do so.\n\nParameters\n----------\nraw : instance of Raw\n    The raw data.\npeak : float | dict | None\n    Annotate segments based on **maximum** peak-to-peak signal amplitude\n    (PTP). Valid **keys** can be any channel type present in the object.\n    The **values** are floats that set the maximum acceptable PTP. If the\n    PTP is larger than this threshold, the segment will be annotated.\n    If float, the minimum acceptable PTP is applied to all channels.\nflat : float | dict | None\n    Annotate segments based on **minimum** peak-to-peak signal amplitude\n    (PTP). Valid **keys** can be any channel type present in the object.\n    The **values** are floats that set the minimum acceptable PTP. If the\n    PTP is smaller than this threshold, the segment will be annotated.\n    If float, the minimum acceptable PTP is applied to all channels.\nbad_percent : float\n    The percentage of the time a channel can be above or below thresholds.\n    Below this percentage, :class:`~mne.Annotations` are created.\n    Above this percentage, the channel involved is return in ``bads``. Note\n    the returned ``bads`` are not automatically added to\n    :class:`info['bads'] <mne.Info>`.\n    Defaults to ``5``, i.e. 5%%.\nmin_duration : float\n    The minimum duration (s) required by consecutives samples to be above\n    ``peak`` or below ``flat`` thresholds to be considered.\n    to consider as above or below threshold.\n    For some systems, adjacent time samples with exactly the same value are\n    not totally uncommon. Defaults to ``0.005`` (5 ms).\n%(picks_good_data)s\n%(verbose)s\n\nReturns\n-------\nannotations : instance of Annotations\n    The annotated bad segments.\nbads : list\n    The channels detected as bad.\n\nNotes\n-----\nThis function does not use a window to detect small peak-to-peak or large\npeak-to-peak amplitude changes as the ``reject`` and ``flat`` argument from\n:class:`~mne.Epochs` does. Instead, it looks at the difference between\nconsecutive samples.\n\n- When used to detect segments below ``flat``, at least ``min_duration``\n  seconds of consecutive samples must respect\n  ``abs(a[i+1] - a[i]) \u2264 flat``.\n- When used to detect segments above ``peak``, at least ``min_duration``\n  seconds of consecutive samples must respect\n  ``abs(a[i+1] - a[i]) \u2265 peak``.\n\nThus, this function does not detect every temporal event with large\npeak-to-peak amplitude, but only the ones where the peak-to-peak amplitude\nis supra-threshold between consecutive samples. For instance, segments\nexperiencing a DC shift will not be picked up. Only the edges from the DC\nshift will be annotated (and those only if the edge transitions are longer\nthan ``min_duration``).\n\nThis function may perform faster if data is loaded in memory, as it\nloads data one channel type at a time (across all time points), which is\ntypically not an efficient way to read raw data from disk.\n\n.. versionadded:: 1.0", "metadata": {}}
{"_id": "mne_mne_preprocessing/_css.py_cortical_signal_suppression_doc", "text": "Apply cortical signal suppression (CSS) to evoked data.\n\nParameters\n----------\nevoked : instance of Evoked\n    The evoked object to use for CSS. Must contain magnetometer,\n    gradiometer, and EEG channels.\n%(picks_good_data)s\nmag_picks : array-like of int\n    Array of the first set of channel indices that will be used to find\n    the common temporal subspace. If None (default), all magnetometers will\n    be used.\ngrad_picks : array-like of int\n    Array of the second set of channel indices that will be used to find\n    the common temporal subspace. If None (default), all gradiometers will\n    be used.\nn_proj : int\n    The number of projection vectors.\n%(verbose)s\n\nReturns\n-------\nevoked_subcortical : instance of Evoked\n    The evoked object with contributions from the ``mag_picks`` and ``grad_picks``\n    channels removed from the ``picks`` channels.\n\nNotes\n-----\nThis method removes the common signal subspace between two sets of\nchannels (``mag_picks`` and ``grad_picks``) from a set of channels\n(``picks``) via a temporal projection using ``n_proj`` number of\nprojection vectors. In the reference publication :footcite:`Samuelsson2019`,\nthe joint subspace between magnetometers and gradiometers is used to\nsuppress the cortical signal in the EEG data. In principle, other\ncombinations of sensor types (or channels) could be used to suppress\nsignals from other sources.\n\nReferences\n----------\n.. footbibliography::", "metadata": {}}
{"_id": "mne_mne_preprocessing/_annotate_nan.py_annotate_nan_doc", "text": "Detect segments with NaN and return a new Annotations instance.\n\nParameters\n----------\nraw : instance of Raw\n    Data to find segments with NaN values.\n%(verbose)s\n\nReturns\n-------\nannot : instance of Annotations\n    New channel-specific annotations for the data.", "metadata": {}}
{"_id": "mne_mne_preprocessing/maxwell.py_maxwell_filter_prepare_emptyroom_doc", "text": "Prepare an empty-room recording for Maxwell filtering.\n\nEmpty-room data by default lacks certain properties that are required to\nensure running :func:`~mne.preprocessing.maxwell_filter` will process the\nempty-room recording the same way as the experimental data. This function\npreconditions an empty-room raw data instance accordingly so it can be used\nfor Maxwell filtering. Please see the ``Notes`` section for details.\n\nParameters\n----------\nraw_er : instance of Raw\n    The empty-room recording. It will not be modified.\nraw : instance of Raw\n    The experimental recording, typically this will be the reference run\n    used for Maxwell filtering.\nbads : 'from_raw' | 'union' | 'keep'\n    How to populate the list of bad channel names to be injected into\n    the empty-room recording. If ``'from_raw'`` (default) the list of bad\n    channels will be overwritten with that of ``raw``. If ``'union'``, will\n    use the union of bad channels in ``raw`` and ``raw_er``. Note that\n    this may lead to additional bad channels in the empty-room in\n    comparison to the experimental recording. If ``'keep'``, don't alter\n    the existing list of bad channels.\n\n    .. note::\n       Non-MEG channels are silently dropped from the list of bads.\nannotations : 'from_raw' | 'union' | 'keep'\n    Whether to copy the annotations over from ``raw`` (default),\n    use the union of the annotations, or to keep them unchanged.\nmeas_date : 'keep' | 'from_raw'\n    Whether to transfer the measurement date from ``raw`` or to keep\n    it as is (default). If you intend to manually transfer annotations\n    from ``raw`` **after** running this function, you should set this to\n    ``'from_raw'``.\n%(emit_warning)s\n    Unlike :meth:`raw.set_annotations <mne.io.Raw.set_annotations>`, the\n    default here is ``False``, as empty-room recordings are often shorter\n    than raw.\n%(verbose)s\n\nReturns\n-------\nraw_er_prepared : instance of Raw\n    A copy of the passed empty-room recording, ready for Maxwell filtering.\n\nNotes\n-----\nThis function will:\n\n* Compile the list of bad channels according to the ``bads`` parameter.\n* Inject the device-to-head transformation matrix from the experimental\n  recording into the empty-room recording.\n* Set the following properties of the empty-room recording to match the\n  experimental recording:\n\n  * Montage\n  * ``raw.first_time`` and ``raw.first_samp``\n\n* Adjust annotations according to the ``annotations`` parameter.\n* Adjust the measurement date according to the ``meas_date`` parameter.\n\n.. versionadded:: 1.1", "metadata": {}}
{"_id": "mne_mne_preprocessing/maxwell.py_maxwell_filter_doc", "text": "Maxwell filter data using multipole moments.\n\nParameters\n----------\nraw : instance of Raw\n    Data to be filtered.\n\n    .. warning:: It is critical to mark bad channels in\n                 ``raw.info['bads']`` prior to processing in order to\n                 prevent artifact spreading. Manual inspection and use\n                 of :func:`~find_bad_channels_maxwell` is recommended.\n%(origin_maxwell)s\n%(int_order_maxwell)s\n%(ext_order_maxwell)s\n%(calibration_maxwell_cal)s\n%(cross_talk_maxwell)s\nst_duration : float | None\n    If not None, apply spatiotemporal SSS with specified buffer duration\n    (in seconds). MaxFilter\u2122's default is 10.0 seconds in v2.2.\n    Spatiotemporal SSS acts as implicitly as a high-pass filter where the\n    cut-off frequency is 1/st_duration Hz. For this (and other) reasons,\n    longer buffers are generally better as long as your system can handle\n    the higher memory usage. To ensure that each window is processed\n    identically, choose a buffer length that divides evenly into your data.\n    Any data at the trailing edge that doesn't fit evenly into a whole\n    buffer window will be lumped into the previous buffer.\nst_correlation : float\n    Correlation limit between inner and outer subspaces used to reject\n    overlapping intersecting inner/outer signals during spatiotemporal SSS.\n%(coord_frame_maxwell)s\n%(destination_maxwell_dest)s\n%(regularize_maxwell_reg)s\n%(ignore_ref_maxwell)s\n%(bad_condition_maxwell_cond)s\n%(head_pos_maxwell)s\n\n    .. versionadded:: 0.12\n%(st_fixed_maxwell_only)s\n%(mag_scale_maxwell)s\n\n    .. versionadded:: 0.13\n%(skip_by_annotation_maxwell)s\n\n    .. versionadded:: 0.17\n%(extended_proj_maxwell)s\nst_overlap : bool\n    If True (default in 1.11), tSSS processing will use a constant\n    overlap-add method. If False (default in 1.10), then\n    non-overlapping windows will be used.\n\n    .. versionadded:: 1.10\n%(maxwell_mc_interp)s\n%(verbose)s\n\nReturns\n-------\nraw_sss : instance of Raw\n    The raw data with Maxwell filtering applied.\n\nSee Also\n--------\nmne.preprocessing.annotate_amplitude\nmne.preprocessing.find_bad_channels_maxwell\nmne.chpi.filter_chpi\nmne.chpi.read_head_pos\nmne.epochs.average_movements\n\nNotes\n-----\n.. versionadded:: 0.11\n\nSome of this code was adapted and relicensed (with BSD form) with\npermission from Jussi Nurminen. These algorithms are based on work\nfrom :footcite:`TauluKajola2005` and :footcite:`TauluSimola2006`.\nIt will likely use multiple CPU cores, see the :ref:`FAQ <faq_cpu>`\nfor more information.\n\n.. warning:: Maxwell filtering in MNE is not designed or certified\n             for clinical use.\n\nCompared to the MEGIN MaxFilter\u2122 2.2.11 software, the MNE Maxwell filtering\nroutines currently provide the following features:\n\n.. table::\n   :widths: auto\n\n   +-----------------------------------------------------------------------------+-----+-----------+\n   | Feature                                                                     | MNE | MaxFilter |\n   +=============================================================================+=====+===========+\n   | Maxwell filtering software shielding                                        | \u2713   | \u2713         |\n   +-----------------------------------------------------------------------------+-----+-----------+\n   | Bad channel reconstruction                                                  | \u2713   | \u2713         |\n   +-----------------------------------------------------------------------------+-----+-----------+\n   | Cross-talk cancellation                                                     | \u2713   | \u2713         |\n   +-----------------------------------------------------------------------------+-----+-----------+\n   | Fine calibration correction (1D)                                            | \u2713   | \u2713         |\n   +-----------------------------------------------------------------------------+-----+-----------+\n   | Fine calibration correction (3D)                                            | \u2713   |           |\n   +-----------------------------------------------------------------------------+-----+-----------+\n   | Spatio-temporal SSS (tSSS)                                                  | \u2713   | \u2713         |\n   +-----------------------------------------------------------------------------+-----+-----------+\n   | Coordinate frame translation                                                | \u2713   | \u2713         |\n   +-----------------------------------------------------------------------------+-----+-----------+\n   | Regularization using information theory                                     | \u2713   | \u2713         |\n   +-----------------------------------------------------------------------------+-----+-----------+\n   | Movement compensation (raw)                                                 | \u2713   | \u2713         |\n   +-----------------------------------------------------------------------------+-----+-----------+\n   | Movement compensation (:func:`epochs <mne.epochs.average_movements>`)       | \u2713   |           |\n   +-----------------------------------------------------------------------------+-----+-----------+\n   | :func:`cHPI subtraction <mne.chpi.filter_chpi>`                             | \u2713   | \u2713         |\n   +-----------------------------------------------------------------------------+-----+-----------+\n   | Double floating point precision                                             | \u2713   |           |\n   +-----------------------------------------------------------------------------+-----+-----------+\n   | Seamless processing of split (``-1.fif``) and concatenated files            | \u2713   |           |\n   +-----------------------------------------------------------------------------+-----+-----------+\n   | Automatic bad channel detection (:func:`~find_bad_channels_maxwell`)        | \u2713   | \u2713         |\n   +-----------------------------------------------------------------------------+-----+-----------+\n   | Head position estimation (:func:`~mne.chpi.compute_head_pos`)               | \u2713   | \u2713         |\n   +-----------------------------------------------------------------------------+-----+-----------+\n   | Overlap-add processing for spatio-temporal projections                      | \u2713   |           |\n   +-----------------------------------------------------------------------------+-----+-----------+\n   | Smooth interpolation in movement compensation                               | \u2713   |           |\n   +-----------------------------------------------------------------------------+-----+-----------+\n   | Certified for clinical use                                                  |     | \u2713         |\n   +-----------------------------------------------------------------------------+-----+-----------+\n   | Extended external basis (eSSS)                                              | \u2713   |           |\n   +-----------------------------------------------------------------------------+-----+-----------+\n\nEpoch-based movement compensation is described in :footcite:`TauluKajola2005`.\n\nUse of Maxwell filtering routines with non-Neuromag systems is currently\n**experimental**. Worse results for non-Neuromag systems are expected due\nto (at least):\n\n* Missing fine-calibration and cross-talk cancellation data for\n  other systems.\n* Processing with reference sensors has not been vetted.\n* Regularization of components may not work well for all systems.\n* Coil integration has not been optimized using Abramowitz/Stegun\n  definitions.\n\n.. note:: Various Maxwell filtering algorithm components are covered by\n          patents owned by MEGIN. These patents include, but may not be\n          limited to:\n\n          - US2006031038 (Signal Space Separation)\n          - US6876196 (Head position determination)\n          - WO2005067789 (DC fields)\n          - WO2005078467 (MaxShield)\n          - WO2006114473 (Temporal Signal Space Separation)\n\n          These patents likely preclude the use of Maxwell filtering code\n          in commercial applications. Consult a lawyer if necessary.\n\nCurrently, in order to perform Maxwell filtering, the raw data must not\nhave any projectors applied. During Maxwell filtering, the spatial\nstructure of the data is modified, so projectors are discarded (unless\nin ``st_only=True`` mode).\n\nReferences\n----------\n.. footbibliography::", "metadata": {}}
{"_id": "mne_mne_preprocessing/maxwell.py_find_bad_channels_maxwell_doc", "text": "Find bad channels using Maxwell filtering.\n\nParameters\n----------\nraw : instance of Raw\n    Raw data to process.\nlimit : float\n    Detection limit for noisy segments (default is 7.). Smaller values will\n    find more bad channels at increased risk of including good ones. This\n    value can be interpreted as the standard score of differences between\n    the original and Maxwell-filtered data. See the ``Notes`` section for\n    details.\n\n    .. note:: This setting only concerns *noisy* channel detection.\n              The limit for *flat* channel detection currently cannot be\n              controlled by the user. Flat channel detection is always run\n              before noisy channel detection.\nduration : float\n    Duration of the segments into which to slice the data for processing,\n    in seconds. Default is 5.\nmin_count : int\n    Minimum number of times a channel must show up as bad in a chunk.\n    Default is 5.\nreturn_scores : bool\n    If ``True``, return a dictionary with scoring information for each\n    evaluated segment of the data. Default is ``False``.\n\n    .. warning:: This feature is experimental and may change in a future\n                 version of MNE-Python without prior notice. Please\n                 report any problems and enhancement proposals to the\n                 developers.\n\n    .. versionadded:: 0.21\n%(origin_maxwell)s\n%(int_order_maxwell)s\n%(ext_order_maxwell)s\n%(calibration_maxwell_cal)s\n%(cross_talk_maxwell)s\n%(coord_frame_maxwell)s\n%(regularize_maxwell_reg)s\n%(ignore_ref_maxwell)s\n%(bad_condition_maxwell_cond)s\n%(head_pos_maxwell)s\n%(mag_scale_maxwell)s\n%(skip_by_annotation_maxwell)s\nh_freq : float | None\n    The cutoff frequency (in Hz) of the low-pass filter that will be\n    applied before processing the data. This defaults to ``40.``, which\n    should provide similar results to MaxFilter. If you do not wish to\n    apply a filter, set this to ``None``.\n%(extended_proj_maxwell)s\n%(maxwell_mc_interp)s\n%(verbose)s\n\nReturns\n-------\nnoisy_chs : list\n    List of bad MEG channels that were automatically detected as being\n    noisy among the good MEG channels.\nflat_chs : list\n    List of MEG channels that were detected as being flat in at least\n    ``min_count`` segments.\nscores : dict\n    A dictionary with information produced by the scoring algorithms.\n    Only returned when ``return_scores`` is ``True``. It contains the\n    following keys:\n\n    - ``ch_names`` : ndarray, shape (n_meg,)\n        The names of the MEG channels. Their order corresponds to the\n        order of rows in the ``scores`` and ``limits`` arrays.\n    - ``ch_types`` : ndarray, shape (n_meg,)\n        The types of the MEG channels in ``ch_names`` (``'mag'``,\n        ``'grad'``).\n    - ``bins`` : ndarray, shape (n_windows, 2)\n        The inclusive window boundaries (start and stop; in seconds) used\n        to calculate the scores.\n    - ``scores_flat`` : ndarray, shape (n_meg, n_windows)\n        The scores for testing whether MEG channels are flat. These values\n        correspond to the standard deviation of a segment.\n        See the ``Notes`` section for details.\n    - ``limits_flat`` : ndarray, shape (n_meg, 1)\n        The score thresholds (in standard deviation) above which a segment\n        was classified as \"flat\".\n    - ``scores_noisy`` : ndarray, shape (n_meg, n_windows)\n        The scores for testing whether MEG channels are noisy. These values\n        correspond to the standard score of a segment.\n        See the ``Notes`` section for details.\n    - ``limits_noisy`` : ndarray, shape (n_meg, 1)\n        The score thresholds (in standard scores) above which a segment was\n        classified as \"noisy\".\n\n    .. note:: The scores and limits for channels marked as ``bad`` in the\n              input data will be set to ``np.nan``.\n\nSee Also\n--------\nannotate_amplitude\nmaxwell_filter\n\nNotes\n-----\nAll arguments after ``raw``, ``limit``, ``duration``, ``min_count``, and\n``return_scores`` are the same as :func:`~maxwell_filter`, except that the\nfollowing are not allowed in this function because they are unused:\n``st_duration``, ``st_correlation``, ``destination``, ``st_fixed``, and\n``st_only``.\n\nThis algorithm, for a given chunk of data:\n\n1. Runs SSS on the data, without removing external components.\n2. Excludes channels as *flat* that have had low variability\n   (standard deviation < 0.01 fT or fT/cm in a 30 ms window) in the given\n   or any previous chunk.\n3. For each channel :math:`k`, computes the *range* or peak-to-peak\n   :math:`d_k` of the difference between the reconstructed and original\n   data.\n4. Computes the average :math:`\\mu_d` and standard deviation\n   :math:`\\sigma_d` of the differences (after scaling magnetometer data\n   to roughly match the scale of the gradiometer data using ``mag_scale``).\n5. Marks channels as bad for the chunk when\n   :math:`d_k > \\mu_d + \\textrm{limit} \\times \\sigma_d`. Note that this\n   expression can be easily transformed into\n   :math:`(d_k - \\mu_d) / \\sigma_d > \\textrm{limit}`, which is equivalent\n   to :math:`z(d_k) > \\textrm{limit}`, with :math:`z(d_k)` being the\n   standard or z-score of the difference.\n\nData are processed in chunks of the given ``duration``, and channels that\nare bad for at least ``min_count`` chunks are returned.\n\nChannels marked as *flat* in step 2 are excluded from all subsequent steps\nof noisy channel detection.\n\nThis algorithm gives results similar to, but not identical with,\nMaxFilter. Differences arise because MaxFilter processes on a\nbuffer-by-buffer basis (using buffer-size-dependent downsampling logic),\nuses different filtering characteristics, and possibly other factors.\nChannels that are near the ``limit`` for a given ``min_count`` are\nparticularly susceptible to being different between the two\nimplementations.\n\n.. versionadded:: 0.20", "metadata": {}}
{"_id": "mne_mne_preprocessing/maxwell.py_compute_maxwell_basis_doc", "text": "Compute the SSS basis for a given measurement info structure.\n\nParameters\n----------\n%(info_not_none)s\n%(origin_maxwell)s\n%(int_order_maxwell)s\n%(ext_order_maxwell)s\n%(calibration_maxwell_cal)s\n%(coord_frame_maxwell)s\n%(regularize_maxwell_reg)s\n%(ignore_ref_maxwell)s\n%(bad_condition_maxwell_cond)s\n%(mag_scale_maxwell)s\n%(extended_proj_maxwell)s\n%(verbose)s\n\nReturns\n-------\nS : ndarray, shape (n_meg, n_moments)\n    The basis that can be used to reconstruct the data.\npS : ndarray, shape (n_moments, n_good_meg)\n    The (stabilized) pseudoinverse of the S array.\nreg_moments : ndarray, shape (n_moments,)\n    The moments that were kept after regularization.\nn_use_in : int\n    The number of kept moments that were in the internal space.\n\nNotes\n-----\nThis outputs variants of :math:`\\mathbf{S}` and :math:`\\mathbf{S^\\dagger}`\nfrom equations 27 and 37 of :footcite:`TauluKajola2005` with the coil scale\nfor magnetometers already factored in so that the resulting denoising\ntransform of the data to obtain :math:`\\hat{\\phi}_{in}` from equation\n38 would be::\n\n    phi_in = S[:, :n_use_in] @ pS[:n_use_in] @ data_meg_good\n\n.. versionadded:: 0.23\n\nReferences\n----------\n.. footbibliography::", "metadata": {}}
{"_id": "mne_mne_preprocessing/maxwell.py_initialize_doc", "text": "Secondary initialization.", "metadata": {}}
{"_id": "mne_mne_preprocessing/maxwell.py_get_avg_op_doc", "text": "Apply an average transformation over the next interval.", "metadata": {}}
{"_id": "mne_mne_preprocessing/xdawn.py_fit_doc", "text": "Fit Xdawn spatial filters.\n\nParameters\n----------\nX : array, shape (n_epochs, n_channels, n_samples)\n    The target data.\ny : array, shape (n_epochs,) | None\n    The target labels. If None, Xdawn fit on the average evoked.\n\nReturns\n-------\nself : Xdawn instance\n    The Xdawn instance.", "metadata": {}}
{"_id": "mne_mne_preprocessing/xdawn.py_transform_doc", "text": "Transform data with spatial filters.\n\nParameters\n----------\nX : array, shape (n_epochs, n_channels, n_samples)\n    The target data.\n\nReturns\n-------\nX : array, shape (n_epochs, n_components * n_classes, n_samples)\n    The transformed data.", "metadata": {}}
{"_id": "mne_mne_preprocessing/xdawn.py_inverse_transform_doc", "text": "Remove selected components from the signal.\n\nGiven the unmixing matrix, transform data, zero out components,\nand inverse transform the data. This procedure will reconstruct\nthe signals from which the dynamics described by the excluded\ncomponents is subtracted.\n\nParameters\n----------\nX : array, shape (n_epochs, n_components * n_classes, n_times)\n    The transformed data.\n\nReturns\n-------\nX : array, shape (n_epochs, n_channels * n_classes, n_times)\n    The inverse transform data.", "metadata": {}}
{"_id": "mne_mne_preprocessing/xdawn.py_fit_doc", "text": "Fit Xdawn from epochs.\n\nParameters\n----------\nepochs : instance of Epochs\n    An instance of Epoch on which Xdawn filters will be fitted.\ny : ndarray | None (default None)\n    If None, used epochs.events[:, 2].\n\nReturns\n-------\nself : instance of Xdawn\n    The Xdawn instance.", "metadata": {}}
{"_id": "mne_mne_preprocessing/xdawn.py_transform_doc", "text": "Apply Xdawn dim reduction.\n\nParameters\n----------\ninst : Epochs | Evoked | ndarray, shape ([n_epochs, ]n_channels, n_times)\n    Data on which Xdawn filters will be applied.\n\nReturns\n-------\nX : ndarray, shape ([n_epochs, ]n_components * n_event_types, n_times)\n    Spatially filtered signals.", "metadata": {}}
{"_id": "mne_mne_preprocessing/xdawn.py_apply_doc", "text": "Remove selected components from the signal.\n\nGiven the unmixing matrix, transform data,\nzero out components, and inverse transform the data.\nThis procedure will reconstruct the signals from which\nthe dynamics described by the excluded components is subtracted.\n\nParameters\n----------\ninst : instance of Raw | Epochs | Evoked\n    The data to be processed.\nevent_id : dict | list of str | None (default None)\n    The kind of event to apply. if None, a dict of inst will be return\n    one for each type of event xdawn has been fitted.\ninclude : array_like of int | None (default None)\n    The indices referring to columns in the ummixing matrix. The\n    components to be kept. If None, the first n_components (as defined\n    in the Xdawn constructor) will be kept.\nexclude : array_like of int | None (default None)\n    The indices referring to columns in the ummixing matrix. The\n    components to be zeroed out. If None, all the components except the\n    first n_components will be exclude.\n\nReturns\n-------\nout : dict\n    A dict of instance (from the same type as inst input) for each\n    event type in event_id.", "metadata": {}}
{"_id": "mne_mne_preprocessing/xdawn.py_inverse_transform_doc", "text": "Not implemented, see Xdawn.apply() instead.", "metadata": {}}
{"_id": "mne_mne_preprocessing/ecg.py_qrs_detector_doc", "text": "Detect QRS component in ECG channels.\n\nQRS is the main wave on the heart beat.\n\nParameters\n----------\nsfreq : float\n    Sampling rate\necg : array\n    ECG signal\nthresh_value : float | str\n    qrs detection threshold. Can also be \"auto\" for automatic\n    selection of threshold.\nlevels : float\n    number of std from mean to include for detection\nn_thresh : int\n    max number of crossings\nl_freq : float\n    Low pass frequency\nh_freq : float\n    High pass frequency\n%(tstart_ecg)s\n%(filter_length_ecg)s\n%(verbose)s\n\nReturns\n-------\nevents : array\n    Indices of ECG peaks.", "metadata": {}}
{"_id": "mne_mne_preprocessing/ecg.py_find_ecg_events_doc", "text": "Find ECG events by localizing the R wave peaks.\n\nParameters\n----------\nraw : instance of Raw\n    The raw data.\n%(event_id_ecg)s\n%(ch_name_ecg)s\n%(tstart_ecg)s\n%(l_freq_ecg_filter)s\nqrs_threshold : float | str\n    Between 0 and 1. qrs detection threshold. Can also be \"auto\" to\n    automatically choose the threshold that generates a reasonable\n    number of heartbeats (40-160 beats / min).\n%(filter_length_ecg)s\nreturn_ecg : bool\n    Return the ECG data. This is especially useful if no ECG channel\n    is present in the input data, so one will be synthesized (only works if MEG\n    channels are present in the data). Defaults to ``False``.\n%(reject_by_annotation_all)s\n\n    .. versionadded:: 0.18\n%(verbose)s\n\nReturns\n-------\necg_events : array\n    The events corresponding to the peaks of the R waves.\nch_ecg : int | None\n    Index of channel used.\naverage_pulse : float\n    The estimated average pulse. If no ECG events could be found, this will\n    be zero.\necg : array | None\n    The ECG data of the synthesized ECG channel, if any. This will only\n    be returned if ``return_ecg=True`` was passed.\n\nSee Also\n--------\ncreate_ecg_epochs\ncompute_proj_ecg", "metadata": {}}
{"_id": "mne_mne_preprocessing/ecg.py_create_ecg_epochs_doc", "text": "Conveniently generate epochs around ECG artifact events.\n\n%(create_ecg_epochs)s\n\n.. note:: Filtering is only applied to the ECG channel while finding\n            events. The resulting ``ecg_epochs`` will have no filtering\n            applied (i.e., have the same filter properties as the input\n            ``raw`` instance).\n\nParameters\n----------\nraw : instance of Raw\n    The raw data.\n%(ch_name_ecg)s\n%(event_id_ecg)s\n%(picks_all)s\ntmin : float\n    Start time before event.\ntmax : float\n    End time after event.\n%(l_freq_ecg_filter)s\n%(reject_epochs)s\n%(flat)s\n%(baseline_epochs)s\npreload : bool\n    Preload epochs or not (default True). Must be True if\n    keep_ecg is True.\nkeep_ecg : bool\n    When ECG is synthetically created (after picking), should it be added\n    to the epochs? Must be False when synthetic channel is not used.\n    Defaults to False.\n%(reject_by_annotation_epochs)s\n\n    .. versionadded:: 0.14.0\n%(decim)s\n\n    .. versionadded:: 0.21.0\n%(verbose)s\n\nReturns\n-------\necg_epochs : instance of Epochs\n    Data epoched around ECG R wave peaks.\n\nSee Also\n--------\nfind_ecg_events\ncompute_proj_ecg\n\nNotes\n-----\nIf you already have a list of R-peak times, or want to compute R-peaks\noutside MNE-Python using a different algorithm, the recommended approach is\nto call the :class:`~mne.Epochs` constructor directly, with your R-peaks\nformatted as an :term:`events` array (here we also demonstrate the relevant\ndefault values)::\n\n    mne.Epochs(raw, r_peak_events_array, tmin=-0.5, tmax=0.5,\n               baseline=None, preload=True, proj=False)  # doctest: +SKIP", "metadata": {}}
{"_id": "mne_mne_preprocessing/stim.py_fix_stim_artifact_doc", "text": "Eliminate stimulation's artifacts from instance.\n\n.. note:: This function operates in-place, consider passing\n          ``inst.copy()`` if this is not desired.\n\nParameters\n----------\ninst : instance of Raw or Epochs or Evoked\n    The data.\nevents : array, shape (n_events, 3)\n    The list of events. Required only when inst is Raw.\nevent_id : int\n    The id of the events generating the stimulation artifacts.\n    If None, read all events. Required only when inst is Raw.\ntmin : float\n    Start time of the interpolation window in seconds.\ntmax : float\n    End time of the interpolation window in seconds.\nbaseline : None | tuple, shape (2,)\n    The baseline to use when ``mode='constant'``, in which case it\n    must be non-None.\n\n    .. versionadded:: 1.8\nmode : 'linear' | 'window' | 'constant'\n    Way to fill the artifacted time interval.\n\n    ``\"linear\"``\n        Does linear interpolation.\n    ``\"window\"``\n        Applies a ``(1 - hanning)`` window.\n    ``\"constant\"``\n        Uses baseline average. baseline parameter must be provided.\n\n    .. versionchanged:: 1.8\n       Added the ``\"constant\"`` mode.\nstim_channel : str | None\n    Stim channel to use.\n%(picks_all_data)s\n\nReturns\n-------\ninst : instance of Raw or Evoked or Epochs\n    Instance with modified data.", "metadata": {}}
{"_id": "mne_mne_preprocessing/interpolate.py_equalize_bads_doc", "text": "Interpolate or mark bads consistently for a list of instances.\n\nOnce called on a list of instances, the instances can be concatenated\nas they will have the same list of bad channels.\n\nParameters\n----------\ninsts : list\n    The list of instances (Evoked, Epochs or Raw) to consider\n    for interpolation. Each instance should have marked channels.\ninterp_thresh : float\n    A float between 0 and 1 (default) that specifies the fraction of time\n    a channel should be good to be eventually interpolated for certain\n    instances. For example if 0.5, a channel which is good at least half\n    of the time will be interpolated in the instances where it is marked\n    as bad. If 1 then channels will never be interpolated and if 0 all bad\n    channels will be systematically interpolated.\ncopy : bool\n    If True then the returned instances will be copies.\n\nReturns\n-------\ninsts_bads : list\n    The list of instances, with the same channel(s) marked as bad in all of\n    them, possibly with some formerly bad channels interpolated.", "metadata": {}}
{"_id": "mne_mne_preprocessing/interpolate.py_interpolate_bridged_electrodes_doc", "text": "Interpolate bridged electrode pairs.\n\nBecause bridged electrodes contain brain signal, it's just that the\nsignal is spatially smeared between the two electrodes, we can\nmake a virtual channel midway between the bridged pairs and use\nthat to aid in interpolation rather than completely discarding the\ndata from the two channels.\n\nParameters\n----------\ninst : instance of Epochs, Evoked, or Raw\n    The data object with channels that are to be interpolated.\nbridged_idx : list of tuple\n    The indices of channels marked as bridged with each bridged\n    pair stored as a tuple.\nbad_limit : int\n    The maximum number of electrodes that can be bridged together\n    (included) and interpolated. Above this number, an error will be\n    raised.\n\n    .. versionadded:: 1.2\n\nReturns\n-------\ninst : instance of Epochs, Evoked, or Raw\n    The modified data object.\n\nSee Also\n--------\nmne.preprocessing.compute_bridged_electrodes", "metadata": {}}
{"_id": "mne_mne_preprocessing/eyetracking/calibration.py_read_eyelink_calibration_doc", "text": "Return info on calibrations collected in an eyelink file.\n\nParameters\n----------\nfname : path-like\n    Path to the eyelink file (.asc).\nscreen_size : array-like of shape ``(2,)``\n    The width and height (in meters) of the screen that the eyetracking\n    data was collected with. For example ``(.531, .298)`` for a monitor with\n    a display area of 531 x 298 mm. Defaults to ``None``.\nscreen_distance : float\n    The distance (in meters) from the participant's eyes to the screen.\n    Defaults to ``None``.\nscreen_resolution : array-like of shape ``(2,)``\n    The resolution (in pixels) of the screen that the eyetracking data\n    was collected with. For example, ``(1920, 1080)`` for a 1920x1080\n    resolution display. Defaults to ``None``.\n\nReturns\n-------\ncalibrations : list\n    A list of :class:`~mne.preprocessing.eyetracking.Calibration` instances, one for\n    each eye of every calibration that was performed during the recording session.", "metadata": {}}
{"_id": "mne_mne_preprocessing/eyetracking/calibration.py_copy_doc", "text": "Copy the instance.\n\nReturns\n-------\ncal : instance of Calibration\n    The copied Calibration.", "metadata": {}}
{"_id": "mne_mne_preprocessing/eyetracking/calibration.py_plot_doc", "text": "Visualize calibration.\n\nParameters\n----------\nshow_offsets : bool\n    Whether to display the offset (in visual degrees) of each calibration\n    point or not. Defaults to ``True``.\naxes : instance of matplotlib.axes.Axes | None\n    Axes to draw the calibration positions to. If ``None`` (default), a new axes\n    will be created.\nshow : bool\n    Whether to show the figure or not. Defaults to ``True``.\n\nReturns\n-------\nfig : instance of matplotlib.figure.Figure\n    The resulting figure object for the calibration plot.", "metadata": {}}
{"_id": "mne_mne_preprocessing/eyetracking/_pupillometry.py_interpolate_blinks_doc", "text": "Interpolate eyetracking signals during blinks.\n\nThis function uses the timing of blink annotations to estimate missing\ndata. Missing values are then interpolated linearly. Operates in place.\n\nParameters\n----------\nraw : instance of Raw\n    The raw data with at least one ``'pupil'`` or ``'eyegaze'`` channel.\nbuffer : float | array-like of float, shape ``(2,))``\n    The time in seconds before and after a blink to consider invalid and\n    include in the segment to be interpolated over. Default is ``0.05`` seconds\n    (50 ms). If array-like, the first element is the time before the blink and the\n    second element is the time after the blink to consider invalid, for example,\n    ``(0.025, .1)``.\nmatch : str | list of str\n    The description of annotations to interpolate over. If a list, the data within\n    all annotations that match any of the strings in the list will be interpolated\n    over. If a ``match`` starts with ``'BAD_'``, that part will be removed from the\n    annotation description after interpolation. Defaults to ``'BAD_blink'``.\ninterpolate_gaze : bool\n    If False, only apply interpolation to ``'pupil channels'``. If True, interpolate\n    over ``'eyegaze'`` channels as well. Defaults to False, because eye position can\n    change in unpredictable ways during blinks.\n\nReturns\n-------\nself : instance of Raw\n    Returns the modified instance.\n\nNotes\n-----\n.. versionadded:: 1.5", "metadata": {}}
{"_id": "mne_mne_preprocessing/eyetracking/eyetracking.py_set_channel_types_eyetrack_doc", "text": "Define sensor type for eyetrack channels.\n\nThis function can set all eye tracking specific information:\nchannel type, unit, eye (and x/y component; only for gaze channels)\n\nSupported channel types:\n``'eyegaze'`` and ``'pupil'``\n\nSupported units:\n``'au'``, ``'px'``, ``'deg'``, ``'rad'`` (for eyegaze)\n``'au'``, ``'mm'``, ``'m'`` (for pupil)\n\nParameters\n----------\ninst : instance of Raw, Epochs, or Evoked\n    The data instance.\nmapping : dict\n    A dictionary mapping a channel to a list/tuple including\n    channel type, unit, eye, [and x/y component] (all as str),  e.g.,\n    ``{'l_x': ('eyegaze', 'deg', 'left', 'x')}`` or\n    ``{'r_pupil': ('pupil', 'au', 'right')}``.\n\nReturns\n-------\ninst : instance of Raw | Epochs | Evoked\n    The instance, modified in place.\n\nNotes\n-----\n``inst.set_channel_types()`` to ``'eyegaze'`` or ``'pupil'``\nworks as well, but cannot correctly set unit, eye and x/y component.\n\nData will be stored in SI units:\nif your data comes in ``deg`` (visual angle) it will be converted to\n``rad``, if it is in ``mm`` it will be converted to ``m``.", "metadata": {}}
{"_id": "mne_mne_preprocessing/eyetracking/eyetracking.py_convert_units_doc", "text": "Convert Eyegaze data from pixels to radians of visual angle or vice versa.\n\n.. warning::\n    Currently, depending on the units (pixels or radians), eyegaze channels may not\n    be reported correctly in visualization functions like :meth:`mne.io.Raw.plot`.\n    They will be shown  correctly in :func:`mne.viz.eyetracking.plot_gaze`.\n    See :gh:`11879` for more information.\n\n.. Important::\n   There are important considerations to keep in mind when using this function,\n   see the Notes section below.\n\nParameters\n----------\ninst : instance of Raw, Epochs, or Evoked\n    The Raw, Epochs, or Evoked instance with eyegaze channels.\ncalibration : Calibration\n    Instance of  Calibration, containing information about the screen size\n    (in meters), viewing distance (in meters), and the screen resolution\n    (in pixels).\nto : str\n    Must be either ``\"radians\"`` or ``\"pixels\"``, indicating the desired unit.\n\nReturns\n-------\ninst : instance of Raw | Epochs | Evoked\n    The Raw, Epochs, or Evoked instance, modified in place.\n\nNotes\n-----\nThere are at least two important considerations to keep in mind when using this\nfunction:\n\n1. Converting between on-screen pixels and visual angle is not a linear\n   transformation. If the visual angle subtends less than approximately ``.44``\n   radians (``25`` degrees), the conversion could be considered to be approximately\n   linear. However, as the visual angle increases, the conversion becomes\n   increasingly non-linear. This may lead to unexpected results after converting\n   between pixels and visual angle.\n\n* This function assumes that the head is fixed in place and aligned with the center\n  of the screen, such that gaze to the center of the screen results in a visual\n  angle of ``0`` radians.\n\n.. versionadded:: 1.7", "metadata": {}}
{"_id": "mne_mne_preprocessing/eyetracking/utils.py_get_screen_visual_angle_doc", "text": "Calculate the radians of visual angle that the participant screen subtends.\n\nParameters\n----------\ncalibration : Calibration\n    An instance of Calibration. Must have valid values for ``\"screen_size\"`` and\n    ``\"screen_distance\"`` keys.\n\nReturns\n-------\nvisual angle in radians : ndarray, shape (2,)\n    The visual angle of the monitor width and height, respectively.", "metadata": {}}
{"_id": "mne_mne_preprocessing/nirs/_beer_lambert_law.py_beer_lambert_law_doc", "text": "Convert NIRS optical density data to haemoglobin concentration.\n\nParameters\n----------\nraw : instance of Raw\n    The optical density data.\nppf : tuple | float\n    The partial pathlength factors for each wavelength.\n\n    .. versionchanged:: 1.7\n       Support for different factors for the two wavelengths.\n\nReturns\n-------\nraw : instance of Raw\n    The modified raw instance.", "metadata": {}}
{"_id": "mne_mne_preprocessing/nirs/_tddr.py_temporal_derivative_distribution_repair_doc", "text": "Apply temporal derivative distribution repair to data.\n\nApplies temporal derivative distribution repair (TDDR) to data\n:footcite:`FishburnEtAl2019`. This approach removes baseline shift\nand spike artifacts without the need for any user-supplied parameters.\n\nParameters\n----------\nraw : instance of Raw\n    The raw data.\n%(verbose)s\n\nReturns\n-------\nraw : instance of Raw\n     Data with TDDR applied.\n\nNotes\n-----\nTDDR was initially designed to be used on optical density fNIRS data but\nhas been enabled to be applied on hemoglobin concentration fNIRS data as\nwell in MNE. We recommend applying the algorithm to optical density fNIRS\ndata as intended by the original author wherever possible.\n\nThere is a shorter alias ``mne.preprocessing.nirs.tddr`` that can be used\ninstead of this function (e.g. if line length is an issue).\n\nReferences\n----------\n.. footbibliography::", "metadata": {}}
{"_id": "mne_mne_preprocessing/nirs/_scalp_coupling_index.py_scalp_coupling_index_doc", "text": "Calculate scalp coupling index.\n\nThis function calculates the scalp coupling index\n:footcite:`pollonini2014auditory`. This is a measure of the quality of the\nconnection between the optode and the scalp.\n\nParameters\n----------\nraw : instance of Raw\n    The raw data.\n%(l_freq)s\n%(h_freq)s\n%(l_trans_bandwidth)s\n%(h_trans_bandwidth)s\n%(verbose)s\n\nReturns\n-------\nsci : array of float\n    Array containing scalp coupling index for each channel.\n\nReferences\n----------\n.. footbibliography::", "metadata": {}}
{"_id": "mne_mne_preprocessing/nirs/nirs.py_source_detector_distances_doc", "text": "Determine the distance between NIRS source and detectors.\n\nParameters\n----------\n%(info_not_none)s\n%(picks_all_data)s\n\nReturns\n-------\ndists : array of float\n    Array containing distances in meters.\n    Of shape equal to number of channels, or shape of picks if supplied.", "metadata": {}}
{"_id": "mne_mne_preprocessing/nirs/nirs.py_short_channels_doc", "text": "Determine which NIRS channels are short.\n\nChannels with a source to detector distance of less than\n``threshold`` are reported as short. The default threshold is 0.01 m.\n\nParameters\n----------\n%(info_not_none)s\nthreshold : float\n    The threshold distance for what is considered short in meters.\n\nReturns\n-------\nshort : array of bool\n    Array indicating which channels are short.\n    Of shape equal to number of channels.", "metadata": {}}
{"_id": "mne_mne_preprocessing/nirs/_optical_density.py_optical_density_doc", "text": "Convert NIRS raw data to optical density.\n\nParameters\n----------\nraw : instance of Raw\n    The raw data.\n%(verbose)s\n\nReturns\n-------\nraw : instance of Raw\n    The modified raw instance.", "metadata": {}}
{"_id": "mne_mne_preprocessing/ieeg/_projection.py_project_sensors_onto_brain_doc", "text": "Project sensors onto the brain surface.\n\nParameters\n----------\n%(info_not_none)s\n%(trans_not_none)s\n%(subject)s\n%(subjects_dir)s\n%(picks_base)s only ``ecog`` channels.\nn_neighbors : int\n    The number of neighbors to use to compute the normal vectors\n    for the projection. Must be 2 or greater. More neighbors makes\n    a normal vector with greater averaging which preserves the grid\n    structure. Fewer neighbors has less averaging which better\n    preserves contours in the grid.\ncopy : bool\n    If ``True``, return a new instance of ``info``, if ``False``\n    ``info`` is modified in place.\n%(verbose)s\n\nReturns\n-------\n%(info_not_none)s\n\nNotes\n-----\nThis is useful in ECoG analysis for compensating for \"brain shift\"\nor shrinking of the brain away from the skull due to changes\nin pressure during the craniotomy.\n\nTo use the brain surface, a BEM model must be created e.g. using\n:ref:`mne watershed_bem` using the T1 or :ref:`mne flash_bem`\nusing a FLASH scan.", "metadata": {}}
{"_id": "mne_mne_preprocessing/ieeg/_volume.py_warp_montage_doc", "text": "Warp a montage to a template with image volumes using SDR.\n\n.. note:: This is likely only applicable for channels inside the brain\n          (intracranial electrodes).\n\nParameters\n----------\nmontage : instance of mne.channels.DigMontage\n    The montage object containing the channels.\n%(moving)s\n%(static)s\n%(reg_affine)s\n%(sdr_morph)s\n%(verbose)s\n\nReturns\n-------\nmontage_warped : mne.channels.DigMontage\n    The modified montage object containing the channels.", "metadata": {}}
{"_id": "mne_mne_preprocessing/ieeg/_volume.py_make_montage_volume_doc", "text": "Make a volume from intracranial electrode contact locations.\n\nFind areas of the input volume with intensity greater than\na threshold surrounding local extrema near the channel location.\nMonotonicity from the peak is enforced to prevent channels\nbleeding into each other.\n\nParameters\n----------\nmontage : instance of mne.channels.DigMontage\n    The montage object containing the channels.\nbase_image : path-like | nibabel.spatialimages.SpatialImage\n    Path to a volumetric scan (e.g. CT) of the subject. Can be in any\n    format readable by nibabel. Can also be a nibabel image object.\n    Local extrema (max or min) should be nearby montage channel locations.\nthresh : float\n    The threshold relative to the peak to determine the size\n    of the sensors on the volume.\nmax_peak_dist : int\n    The number of voxels away from the channel location to\n    look in the ``image``. This will depend on the accuracy of\n    the channel locations, the default (one voxel in all directions)\n    will work only with localizations that are that accurate.\nvoxels_max : int\n    The maximum number of voxels for each channel.\nuse_min : bool\n    Whether to hypointensities in the volume as channel locations.\n    Default False uses hyperintensities.\n%(verbose)s\n\nReturns\n-------\nelec_image : nibabel.spatialimages.SpatialImage\n    An image in Freesurfer surface RAS space with voxel values\n    corresponding to the index of the channel. The background\n    is 0s and this index starts at 1.", "metadata": {}}
{"_id": "mne_mne_gui/_gui.py_coregistration_doc", "text": "Coregister an MRI with a subject's head shape.\n\nThe GUI can be launched through the command line interface:\n\n.. code-block::  bash\n\n    $ mne coreg\n\nor using a python interpreter as shown in :ref:`tut-source-alignment`.\n\nParameters\n----------\nwidth : int | None\n    Specify the width for window (in logical pixels).\n    Default is None, which uses ``MNE_COREG_WINDOW_WIDTH`` config value\n    (which defaults to ``800``).\nheight : int | None\n    Specify a height for window (in logical pixels).\n    Default is None, which uses ``MNE_COREG_WINDOW_WIDTH`` config value\n    (which defaults to ``400``).\ninst : None | path-like\n    Path to an instance file containing the digitizer data. Compatible for\n    Raw, Epochs, and Evoked files.\nsubject : None | str\n    Name of the mri subject.\n%(subjects_dir)s\nhead_opacity : float | None\n    The opacity of the head surface in the range ``[0., 1.]``.\n    Default is None, which uses ``MNE_COREG_HEAD_OPACITY`` config value\n    (which defaults to ``1.``).\nhead_high_res : bool | None\n    Use a high resolution head surface.\n    Default is None, which uses ``MNE_COREG_HEAD_HIGH_RES`` config value\n    (which defaults to True).\ntrans : path-like | Transform | None\n    The Head<->MRI transform or the path to its FIF file (``\"-trans.fif\"``).\norient_to_surface : bool | None\n    If True (default), orient EEG electrode and head shape points to the head\n    surface.\n\n    .. versionadded:: 0.16\nscale_by_distance : bool | None\n    If True (default), scale the digitization points by their distance from the\n    scalp surface.\n\n    .. versionadded:: 0.16\nmark_inside : bool | None\n    If True (default), mark points inside the head surface in a\n    different color.\n\n    .. versionadded:: 0.16\n%(interaction_scene_none)s\n    Defaults to ``'terrain'``.\n\n    .. versionadded:: 0.16\n    .. versionchanged:: 1.0\n       Default interaction mode if ``None`` and no config setting found\n       changed from ``'trackball'`` to ``'terrain'``.\n%(fullscreen)s\n    Default is ``None``, which uses ``MNE_COREG_FULLSCREEN`` config value\n    (which defaults to ``False``).\n\n    .. versionadded:: 1.1\nshow : bool\n    Show the GUI if True.\nblock : bool\n    Whether to halt program execution until the figure is closed.\n%(verbose)s\n\nReturns\n-------\nframe : instance of CoregistrationUI\n    The coregistration frame.\n\nNotes\n-----\nMany parameters (e.g., ``head_opacity``) take None as a parameter,\nwhich means that the default will be read from the MNE-Python\nconfiguration file (which gets saved when exiting).\n\nStep by step instructions for the coregistrations are shown below:\n\n.. youtube:: ALV5qqMHLlQ", "metadata": {}}
{"_id": "mne_mne_gui/_coreg.py_close_doc", "text": "Close interface and cleanup data structure.", "metadata": {}}
{"_id": "mne_mne_viz/_proj.py_plot_projs_joint_doc", "text": "Plot projectors and evoked jointly.\n\nParameters\n----------\nprojs : list of Projection\n    The projectors to plot.\nevoked : instance of Evoked\n    The data to plot. Typically this is the evoked instance created from\n    averaging the epochs used to create the projection.\n%(picks_plot_projs_joint_trace)s\ntopomap_kwargs : dict | None\n    Keyword arguments to pass to :func:`mne.viz.plot_projs_topomap`.\n%(show)s\n%(verbose)s\n\nReturns\n-------\nfig : instance of matplotlib Figure\n    The figure.\n\nNotes\n-----\nThis function creates a figure with three columns:\n\n1. The left shows the evoked data traces before (black) and after (green)\n   projection.\n2. The center shows the topomaps associated with each of the projectors.\n3. The right again shows the data traces (black), but this time with:\n\n   1. The data projected onto each projector with a single normalization\n      factor (solid lines). This is useful for seeing the relative power\n      in each projection vector.\n   2. The data projected onto each projector with individual normalization\n      factors (dashed lines). This is useful for visualizing each time\n      course regardless of its power.\n   3. Additional data traces from ``picks_trace`` (solid yellow lines).\n      This is useful for visualizing the \"ground truth\" of the time\n      course, e.g. the measured EOG or ECG channel time courses.\n\n.. versionadded:: 1.1", "metadata": {}}
{"_id": "mne_mne_viz/raw.py_plot_raw_doc", "text": "Plot raw data.\n\nParameters\n----------\nraw : instance of Raw\n    The raw data to plot.\nevents : array | None\n    Events to show with vertical bars.\nduration : float\n    Time window (s) to plot. The lesser of this value and the duration\n    of the raw file will be used.\nstart : float\n    Initial time to show (can be changed dynamically once plotted). If\n    show_first_samp is True, then it is taken relative to\n    ``raw.first_samp``.\nn_channels : int\n    Number of channels to plot at once. Defaults to 20. The lesser of\n    ``n_channels`` and ``len(raw.ch_names)`` will be shown.\n    Has no effect if ``order`` is 'position', 'selection' or 'butterfly'.\nbgcolor : color object\n    Color of the background.\ncolor : dict | color object | None\n    Color for the data traces. If None, defaults to::\n\n        dict(mag='darkblue', grad='b', eeg='k', eog='k', ecg='m',\n             emg='k', ref_meg='steelblue', misc='k', stim='k',\n             resp='k', chpi='k')\n\nbad_color : color object\n    Color to make bad channels.\n%(event_color)s\n    Defaults to ``'cyan'``.\n%(scalings)s\nremove_dc : bool\n    If True remove DC component when plotting data.\norder : array of int | None\n    Order in which to plot data. If the array is shorter than the number of\n    channels, only the given channels are plotted. If None (default), all\n    channels are plotted. If ``group_by`` is ``'position'`` or\n    ``'selection'``, the ``order`` parameter is used only for selecting the\n    channels to be plotted.\nshow_options : bool\n    If True, a dialog for options related to projection is shown.\ntitle : str | None\n    The title of the window. If None, and either the filename of the\n    raw object or '<unknown>' will be displayed as title.\nshow : bool\n    Show figure if True.\nblock : bool\n    Whether to halt program execution until the figure is closed.\n    Useful for setting bad channels on the fly by clicking on a line.\n    May not work on all systems / platforms.\n    (Only Qt) If you run from a script, this needs to\n    be ``True`` or a Qt-eventloop needs to be started somewhere\n    else in the script (e.g. if you want to implement the browser\n    inside another Qt-Application).\nhighpass : float | None\n    Highpass to apply when displaying data.\nlowpass : float | None\n    Lowpass to apply when displaying data.\n    If highpass > lowpass, a bandstop rather than bandpass filter\n    will be applied.\nfiltorder : int\n    Filtering order. 0 will use FIR filtering with MNE defaults.\n    Other values will construct an IIR filter of the given order\n    and apply it with :func:`~scipy.signal.filtfilt` (making the effective\n    order twice ``filtorder``). Filtering may produce some edge artifacts\n    (at the left and right edges) of the signals during display.\n\n    .. versionchanged:: 0.18\n       Support for ``filtorder=0`` to use FIR filtering.\nclipping : str | float | None\n    If None, channels are allowed to exceed their designated bounds in\n    the plot. If \"clamp\", then values are clamped to the appropriate\n    range for display, creating step-like artifacts. If \"transparent\",\n    then excessive values are not shown, creating gaps in the traces.\n    If float, clipping occurs for values beyond the ``clipping`` multiple\n    of their dedicated range, so ``clipping=1.`` is an alias for\n    ``clipping='transparent'``.\n\n    .. versionchanged:: 0.21\n       Support for float, and default changed from None to 1.5.\nshow_first_samp : bool\n    If True, show time axis relative to the ``raw.first_samp``.\nproj : bool\n    Whether to apply projectors prior to plotting (default is ``True``).\n    Individual projectors can be enabled/disabled interactively (see\n    Notes). This argument only affects the plot; use ``raw.apply_proj()``\n    to modify the data stored in the Raw object.\n%(group_by_browse)s\nbutterfly : bool\n    Whether to start in butterfly mode. Defaults to False.\ndecim : int | 'auto'\n    Amount to decimate the data during display for speed purposes.\n    You should only decimate if the data are sufficiently low-passed,\n    otherwise aliasing can occur. The 'auto' mode (default) uses\n    the decimation that results in a sampling rate least three times\n    larger than ``min(info['lowpass'], lowpass)`` (e.g., a 40 Hz lowpass\n    will result in at least a 120 Hz displayed sample rate).\nnoise_cov : instance of Covariance | str | None\n    Noise covariance used to whiten the data while plotting.\n    Whitened data channels are scaled by ``scalings['whitened']``,\n    and their channel names are shown in italic.\n    Can be a string to load a covariance from disk.\n    See also :meth:`mne.Evoked.plot_white` for additional inspection\n    of noise covariance properties when whitening evoked data.\n    For data processed with SSS, the effective dependence between\n    magnetometers and gradiometers may introduce differences in scaling,\n    consider using :meth:`mne.Evoked.plot_white`.\n\n    .. versionadded:: 0.16.0\nevent_id : dict | None\n    Event IDs used to show at event markers (default None shows\n    the event numbers).\n\n    .. versionadded:: 0.16.0\n%(show_scrollbars)s\n%(show_scalebars)s\n\n    .. versionadded:: 0.20.0\n%(time_format)s\n%(precompute)s\n%(use_opengl)s\n%(picks_all)s\n%(theme_pg)s\n\n    .. versionadded:: 1.0\n%(overview_mode)s\n\n    .. versionadded:: 1.1\n%(splash)s\n\n    .. versionadded:: 1.6\n%(verbose)s\n\nReturns\n-------\n%(browser)s\n\nNotes\n-----\nThe arrow keys (up/down/left/right) can typically be used to navigate\nbetween channels and time ranges, but this depends on the backend\nmatplotlib is configured to use (e.g., mpl.use('TkAgg') should work). The\nleft/right arrows will scroll by 25%% of ``duration``, whereas\nshift+left/shift+right will scroll by 100%% of ``duration``. The scaling\ncan be adjusted with - and + (or =) keys. The viewport dimensions can be\nadjusted with page up/page down and home/end keys. Full screen mode can be\ntoggled with the F11 key, and scrollbars can be hidden/shown by pressing\n'z'. Right-click a channel label to view its location. To mark or un-mark a\nchannel as bad, click on a channel label or a channel trace. The changes\nwill be reflected immediately in the raw object's ``raw.info['bads']``\nentry.\n\nIf projectors are present, a button labelled \"Prj\" in the lower right\ncorner of the plot window opens a secondary control window, which allows\nenabling/disabling specific projectors individually. This provides a means\nof interactively observing how each projector would affect the raw data if\nit were applied.\n\nAnnotation mode is toggled by pressing 'a', butterfly mode by pressing\n'b', and whitening mode (when ``noise_cov is not None``) by pressing 'w'.\nBy default, the channel means are removed when ``remove_dc`` is set to\n``True``. This flag can be toggled by pressing 'd'.\n\n%(notes_2d_backend)s", "metadata": {}}
{"_id": "mne_mne_viz/raw.py_plot_raw_psd_doc", "text": "%(plot_psd_doc)s.\n\nParameters\n----------\nraw : instance of Raw\n    The raw object.\n%(fmin_fmax_psd)s\n%(tmin_tmax_psd)s\n%(proj_psd)s\nn_fft : int | None\n    Number of points to use in Welch FFT calculations. Default is ``None``,\n    which uses the minimum of 2048 and the number of time points.\nn_overlap : int\n    The number of points of overlap between blocks. The default value\n    is 0 (no overlap).\n%(reject_by_annotation_psd)s\n%(picks_good_data_noref)s\n%(ax_plot_psd)s\n%(color_plot_psd)s\n%(xscale_plot_psd)s\n%(area_mode_plot_psd)s\n%(area_alpha_plot_psd)s\n%(dB_plot_psd)s\n%(estimate_plot_psd)s\n%(show)s\n%(n_jobs)s\n%(average_plot_psd)s\n%(line_alpha_plot_psd)s\n%(spatial_colors_psd)s\n%(sphere_topomap_auto)s\n%(window_psd)s\n\n    .. versionadded:: 0.22.0\nexclude : list of str | 'bads'\n    Channels names to exclude from being shown. If 'bads', the bad channels\n    are excluded. Pass an empty list to plot all channels (including\n    channels marked \"bad\", if any).\n\n    .. versionadded:: 0.24.0\n%(verbose)s\n\nReturns\n-------\nfig : instance of Figure\n    Figure with frequency spectra of the data channels.\n\nNotes\n-----\n%(notes_plot_*_psd_func)s", "metadata": {}}
{"_id": "mne_mne_viz/raw.py_plot_raw_psd_topo_doc", "text": "Plot power spectral density, separately for each channel.\n\nParameters\n----------\nraw : instance of io.Raw\n    The raw instance to use.\n%(tmin_tmax_psd)s\n%(fmin_fmax_psd_topo)s\n%(proj_psd)s\nn_fft : int\n    Number of points to use in Welch FFT calculations. Defaults to 2048.\nn_overlap : int\n    The number of points of overlap between blocks. Defaults to 0\n    (no overlap).\n%(dB_spectrum_plot_topo)s\nlayout : instance of Layout | None\n    Layout instance specifying sensor positions (does not need to be\n    specified for Neuromag data). If ``None`` (default), the layout is\n    inferred from the data.\ncolor : str | tuple\n    A matplotlib-compatible color to use for the curves. Defaults to white.\nfig_facecolor : str | tuple\n    A matplotlib-compatible color to use for the figure background.\n    Defaults to black.\naxis_facecolor : str | tuple\n    A matplotlib-compatible color to use for the axis background.\n    Defaults to black.\n%(axes_spectrum_plot_topo)s\nblock : bool\n    Whether to halt program execution until the figure is closed.\n    May not work on all systems / platforms. Defaults to False.\n%(show)s\n%(n_jobs)s\n%(verbose)s\n\nReturns\n-------\nfig : instance of matplotlib.figure.Figure\n    Figure distributing one image per channel across sensor topography.", "metadata": {}}
{"_id": "mne_mne_viz/topo.py_iter_topography_doc", "text": "Create iterator over channel positions.\n\nThis function returns a generator that unpacks into\na series of matplotlib axis objects and data / channel\nindices, both corresponding to the sensor positions\nof the related layout passed or inferred from the channel info.\nHence, this enables convenient topography plot customization.\n\nParameters\n----------\n%(info_not_none)s\nlayout : instance of mne.channels.Layout | None\n    The layout to use. If None, layout will be guessed.\non_pick : callable | None\n    The callback function to be invoked on clicking one\n    of the axes. Is supposed to instantiate the following\n    API: ``function(axis, channel_index)``.\nfig : matplotlib.figure.Figure | None\n    The figure object to be considered. If None, a new\n    figure will be created.\nfig_facecolor : color\n    The figure face color. Defaults to black.\naxis_facecolor : color\n    The axis face color. Defaults to black.\naxis_spinecolor : color\n    The axis spine color. Defaults to black. In other words,\n    the color of the axis' edge lines.\nlayout_scale : float | None\n    Scaling factor for adjusting the relative size of the layout\n    on the canvas. If None, nothing will be scaled.\nlegend : bool\n    If True, an additional axis is created in the bottom right corner\n    that can be used to, e.g., construct a legend. The index of this\n    axis will be -1.\nselect : bool\n    Whether to enable the lasso-selection tool to enable the user to select\n    channels. The selected channels will be available in\n    ``fig.lasso.selection``.\n\n    .. versionadded:: 1.10.0\n\nReturns\n-------\ngen : generator\n    A generator that can be unpacked into:\n\n    ax : matplotlib.axis.Axis\n        The current axis of the topo plot.\n    ch_dx : int\n        The related channel index.", "metadata": {}}
{"_id": "mne_mne_viz/topo.py_plot_topo_image_epochs_doc", "text": "Plot Event Related Potential / Fields image on topographies.\n\nParameters\n----------\nepochs : instance of :class:`~mne.Epochs`\n    The epochs.\nlayout : instance of Layout\n    System specific sensor positions.\nsigma : float\n    The standard deviation of the Gaussian smoothing to apply along\n    the epoch axis to apply in the image. If 0., no smoothing is applied.\nvmin : float\n    The min value in the image. The unit is \u00b5V for EEG channels,\n    fT for magnetometers and fT/cm for gradiometers.\nvmax : float\n    The max value in the image. The unit is \u00b5V for EEG channels,\n    fT for magnetometers and fT/cm for gradiometers.\ncolorbar : bool | None\n    Whether to display a colorbar or not. If ``None`` a colorbar will be\n    shown only if all channels are of the same type. Defaults to ``None``.\norder : None | array of int | callable\n    If not None, order is used to reorder the epochs on the y-axis\n    of the image. If it's an array of int it should be of length\n    the number of good epochs. If it's a callable the arguments\n    passed are the times vector and the data as 2d array\n    (data.shape[1] == len(times)).\ncmap : colormap\n    Colors to be mapped to the values.\nlayout_scale : float\n    Scaling factor for adjusting the relative size of the layout\n    on the canvas.\ntitle : str\n    Title of the figure.\nscalings : dict | None\n    The scalings of the channel types to be applied for plotting. If\n    ``None``, defaults to ``dict(eeg=1e6, grad=1e13, mag=1e15)``.\nborder : str\n    Matplotlib borders style to be used for each sensor plot.\nfig_facecolor : color\n    The figure face color. Defaults to black.\nfig_background : None | array\n    A background image for the figure. This must be a valid input to\n    :func:`matplotlib.pyplot.imshow`. Defaults to ``None``.\nfont_color : color\n    The color of tick labels in the colorbar. Defaults to white.\nselect : bool\n    Whether to enable the lasso-selection tool to enable the user to select\n    channels. The selected channels will be available in\n    ``fig.lasso.selection``.\n\n    .. versionadded:: 1.10.0\nshow : bool\n    Whether to show the figure. Defaults to ``True``.\n\nReturns\n-------\nfig : instance of :class:`matplotlib.figure.Figure`\n    Figure distributing one image per channel across sensor topography.\n\nNotes\n-----\nIn an interactive Python session, this plot will be interactive; clicking\non a channel image will pop open a larger view of the image; this image\nwill always have a colorbar even when the topo plot does not (because it\nshows multiple sensor types).", "metadata": {}}
{"_id": "mne_mne_viz/topo.py_format_coord_unified_doc", "text": "Update status bar with channel name under cursor.", "metadata": {}}
{"_id": "mne_mne_viz/topo.py_format_coord_multiaxis_doc", "text": "Update status bar with channel name under cursor.", "metadata": {}}
{"_id": "mne_mne_viz/conftest.py_fnirs_evoked_doc", "text": "Create an fnirs evoked structure.", "metadata": {}}
{"_id": "mne_mne_viz/conftest.py_fnirs_epochs_doc", "text": "Create an fnirs epoch structure.", "metadata": {}}
{"_id": "mne_mne_viz/ui_events.py_publish_doc", "text": "Publish an event to all subscribers of the figure's channel.\n\nThe figure's event channel and all linked event channels are searched for\nsubscribers to the given event. Each subscriber had provided a callback\nfunction when subscribing, so we call that.\n\nParameters\n----------\nfig : matplotlib.figure.Figure | Figure3D\n    The figure that publishes the event.\nevent : UIEvent\n    Event to publish.\n%(verbose)s", "metadata": {}}
{"_id": "mne_mne_viz/ui_events.py_subscribe_doc", "text": "Subscribe to an event on a figure's event channel.\n\nParameters\n----------\nfig : matplotlib.figure.Figure | Figure3D\n    The figure of which event channel to subscribe.\nevent_name : str\n    The name of the event to listen for.\ncallback : callable\n    The function that should be called whenever the event is published.\n%(verbose)s", "metadata": {}}
{"_id": "mne_mne_viz/ui_events.py_unsubscribe_doc", "text": "Unsubscribe from an event on a figure's event channel.\n\nParameters\n----------\nfig : matplotlib.figure.Figure | Figure3D\n    The figure of which event channel to unsubscribe from.\nevent_names : str | list of str\n    Select which events to stop subscribing to. Can be a single string\n    event name, a list of event names or ``\"all\"`` which will unsubscribe\n    from all events.\ncallback : callable | None\n    The callback function that should be unsubscribed, leaving all other\n    callback functions that may be subscribed untouched. By default\n    (``None``) all callback functions are unsubscribed from the event.\n%(verbose)s", "metadata": {}}
{"_id": "mne_mne_viz/ui_events.py_link_doc", "text": "Link the event channels of two figures together.\n\nWhen event channels are linked, any events that are published on one\nchannel are simultaneously published on the other channel. Links are\nbi-directional.\n\nParameters\n----------\n*figs : tuple of matplotlib.figure.Figure | tuple of Figure3D\n    The figures whose event channel will be linked.\ninclude_events : list of str | None\n    Select which events to publish across figures. By default (``None``),\n    both figures will receive all of each other's events. Passing a list of\n    event names will restrict the events being shared across the figures to\n    only the given ones.\nexclude_events : list of str | None\n    Select which events not to publish across figures. By default (``None``),\n    no events are excluded.\n%(verbose)s", "metadata": {}}
{"_id": "mne_mne_viz/ui_events.py_unlink_doc", "text": "Remove all links involving the event channel of the given figure.\n\nParameters\n----------\nfig : matplotlib.figure.Figure | Figure3D\n    The figure whose event channel should be unlinked from all other event\n    channels.\n%(verbose)s", "metadata": {}}
{"_id": "mne_mne_viz/ui_events.py_disable_ui_events_doc", "text": "Temporarily disable generation of UI events. Use as context manager.\n\nParameters\n----------\nfig : matplotlib.figure.Figure | Figure3D\n    The figure whose UI event generation should be temporarily disabled.", "metadata": {}}
{"_id": "mne_mne_viz/ui_events.py_name_doc", "text": "The name of the event, which is the class name in snake case.", "metadata": {}}
{"_id": "mne_mne_viz/ui_events.py_delete_event_channel_doc", "text": "Delete the event channel (callback function).", "metadata": {}}
{"_id": "mne_mne_viz/montage.py_plot_montage_doc", "text": "Plot a montage.\n\nParameters\n----------\nmontage : instance of DigMontage\n    The montage to visualize.\nscale : float\n    Determines the scale of the channel points and labels; values < 1 will scale\n    down, whereas values > 1 will scale up.\nshow_names : bool | list\n    Whether to display all channel names. If a list, only the channel\n    names in the list are shown. Defaults to True.\nkind : str\n    Whether to plot the montage as '3d' or 'topomap' (default).\nshow : bool\n    Show figure if True.\n%(sphere_topomap_auto)s\n%(axes_montage)s\n\n    .. versionadded:: 1.4\n%(verbose)s\n\nReturns\n-------\nfig : instance of matplotlib.figure.Figure\n    The figure object.", "metadata": {}}
{"_id": "mne_mne_viz/ica.py_plot_ica_sources_doc", "text": "Plot estimated latent sources given the unmixing matrix.\n\nTypical usecases:\n\n1. plot evolution of latent sources over time based on (Raw input)\n2. plot latent source around event related time windows (Epochs input)\n3. plot time-locking in ICA space (Evoked input)\n\nParameters\n----------\nica : instance of mne.preprocessing.ICA\n    The ICA solution.\ninst : instance of Raw, Epochs or Evoked\n    The object to plot the sources from.\n%(picks_ica)s\nstart, stop : float | int | None\n   If ``inst`` is a `~mne.io.Raw` or an `~mne.Evoked` object, the first and\n   last time point (in seconds) of the data to plot. If ``inst`` is a\n   `~mne.io.Raw` object, ``start=None`` and ``stop=None`` will be\n   translated into ``start=0.`` and ``stop=3.``, respectively. For\n   `~mne.Evoked`, ``None`` refers to the beginning and end of the evoked\n   signal. If ``inst`` is an `~mne.Epochs` object, specifies the index of\n   the first and last epoch to show.\ntitle : str | None\n    The window title. If None a default is provided.\nshow : bool\n    Show figure if True.\nblock : bool\n    Whether to halt program execution until the figure is closed.\n    Useful for interactive selection of components in raw and epoch\n    plotter. For evoked, this parameter has no effect. Defaults to False.\nshow_first_samp : bool\n    If True, show time axis relative to the ``raw.first_samp``.\n%(show_scrollbars)s\n%(time_format)s\n%(precompute)s\n%(use_opengl)s\npsd_args : dict | None\n    Dictionary of arguments to pass to :meth:`~mne.Epochs.compute_psd` in\n    interactive  mode. Ignored if ``inst`` is not supplied. If ``None``,\n    nothing is passed. Defaults to ``None``.\n\n    .. versionadded:: 1.9\n%(theme_pg)s\n\n    .. versionadded:: 1.0\n%(overview_mode)s\n\n    .. versionadded:: 1.1\n%(splash)s\n\n    .. versionadded:: 1.6\n\nReturns\n-------\n%(browser)s\n\nNotes\n-----\nFor raw and epoch instances, it is possible to select components for\nexclusion by clicking on the line. The selected components are added to\n``ica.exclude`` on close.\n\n%(notes_2d_backend)s\n\n.. versionadded:: 0.10.0", "metadata": {}}
{"_id": "mne_mne_viz/ica.py_plot_ica_properties_doc", "text": "Display component properties.\n\nProperties include the topography, epochs image, ERP/ERF, power\nspectrum, and epoch variance.\n\nParameters\n----------\nica : instance of mne.preprocessing.ICA\n    The ICA solution.\ninst : instance of Epochs or Raw\n    The data to use in plotting properties.\n\n    .. note::\n       You can interactively cycle through topographic maps for different\n       channel types by pressing :kbd:`T`.\npicks : int | list of int | slice | None\n    Indices of the independent components (ICs) to visualize.\n    If an integer, represents the index of the IC to pick.\n    Multiple ICs can be selected using a list of int or a slice.\n    The indices are 0-indexed, so ``picks=1`` will pick the second\n    IC: ``ICA001``. ``None`` will pick the first 5 components.\naxes : list of Axes | None\n    List of five matplotlib axes to use in plotting: [topomap_axis,\n    image_axis, erp_axis, spectrum_axis, variance_axis]. If None a new\n    figure with relevant axes is created. Defaults to None.\ndB : bool\n    Whether to plot spectrum in dB. Defaults to True.\nplot_std : bool | float\n    Whether to plot standard deviation/confidence intervals in ERP/ERF and\n    spectrum plots.\n    Defaults to True, which plots one standard deviation above/below for\n    the spectrum. If set to float allows to control how many standard\n    deviations are plotted for the spectrum. For example 2.5 will plot 2.5\n    standard deviation above/below.\n    For the ERP/ERF, by default, plot the 95 percent parametric confidence\n    interval is calculated. To change this, use ``ci`` in ``ts_args`` in\n    ``image_args`` (see below).\nlog_scale : bool\n    Whether to use a logarithmic frequency axis to plot the spectrum.\n    Defaults to ``False``.\n\n    .. note::\n       You can interactively toggle this setting by pressing :kbd:`L`.\n\n    .. versionadded:: 1.1\ntopomap_args : dict | None\n    Dictionary of arguments to ``plot_topomap``. If None, doesn't pass any\n    additional arguments. Defaults to None.\nimage_args : dict | None\n    Dictionary of arguments to ``plot_epochs_image``. If None, doesn't pass\n    any additional arguments. Defaults to None.\npsd_args : dict | None\n    Dictionary of arguments to :meth:`~mne.Epochs.compute_psd`. If\n    ``None``, doesn't pass any additional arguments. Defaults to ``None``.\nfigsize : array-like, shape (2,) | None\n    Allows to control size of the figure. If None, the figure size\n    defaults to [7., 6.].\nshow : bool\n    Show figure if True.\nreject : 'auto' | dict | None\n    Allows to specify rejection parameters used to drop epochs\n    (or segments if continuous signal is passed as inst).\n    If None, no rejection is applied. The default is 'auto',\n    which applies the rejection parameters used when fitting\n    the ICA object.\n%(reject_by_annotation_raw)s\n\n    .. versionadded:: 0.21.0\n%(estimate_plot_psd)s\n\n    .. versionadded:: 1.8.0\n%(verbose)s\n\nReturns\n-------\nfig : list\n    List of matplotlib figures.\n\nNotes\n-----\n.. versionadded:: 0.13", "metadata": {}}
{"_id": "mne_mne_viz/ica.py_plot_ica_scores_doc", "text": "Plot scores related to detected components.\n\nUse this function to asses how well your score describes outlier\nsources and how well you were detecting them.\n\nParameters\n----------\nica : instance of mne.preprocessing.ICA\n    The ICA object.\nscores : array-like of float, shape (n_ica_components,) | list of array\n    Scores based on arbitrary metric to characterize ICA components.\nexclude : array-like of int\n    The components marked for exclusion. If None (default), ICA.exclude\n    will be used.\nlabels : str | list | 'ecg' | 'eog' | None\n    The labels to consider for the axes tests. Defaults to None.\n    If list, should match the outer shape of ``scores``.\n    If 'ecg' or 'eog', the ``labels_`` attributes will be looked up.\n    Note that '/' is used internally for sublabels specifying ECG and\n    EOG channels.\naxhline : float\n    Draw horizontal line to e.g. visualize rejection threshold.\ntitle : str\n    The figure title.\nfigsize : tuple of int | None\n    The figure size. If None it gets set automatically.\nn_cols : int | None\n    Scores are plotted in a grid. This parameter controls how\n    many to plot side by side before starting a new row. By\n    default, a number will be chosen to make the grid as square as\n    possible.\nshow : bool\n    Show figure if True.\n\nReturns\n-------\nfig : instance of Figure\n    The figure object.", "metadata": {}}
{"_id": "mne_mne_viz/ica.py_plot_ica_overlay_doc", "text": "Overlay of raw and cleaned signals given the unmixing matrix.\n\nThis method helps visualizing signal quality and artifact rejection.\n\nParameters\n----------\nica : instance of mne.preprocessing.ICA\n    The ICA object.\ninst : instance of Raw or Evoked\n    The signal to plot. If `~mne.io.Raw`, the raw data per channel type is displayed\n    before and after cleaning. A second panel with the RMS for MEG sensors and the\n    :term:`GFP` for EEG sensors is displayed. If `~mne.Evoked`, butterfly traces for\n    signals before and after cleaning will be superimposed.\nexclude : array-like of int | None (default)\n    The components marked for exclusion. If ``None`` (default), the components\n    listed in ``ICA.exclude`` will be used.\n%(picks_base)s all channels that were included during fitting.\nstart, stop : float | None\n   The first and last time point (in seconds) of the data to plot. If\n   ``inst`` is a `~mne.io.Raw` object, ``start=None`` and ``stop=None``\n   will be translated into ``start=0.`` and ``stop=3.``, respectively. For\n   `~mne.Evoked`, ``None`` refers to the beginning and end of the evoked\n   signal.\n%(title_none)s\n%(show)s\n%(n_pca_components_apply)s\n\n    .. versionadded:: 0.22\n%(on_baseline_ica)s\n%(verbose)s\n\nReturns\n-------\nfig : instance of Figure\n    The figure.", "metadata": {}}
{"_id": "mne_mne_viz/epochs.py_plot_epochs_image_doc", "text": "Plot Event Related Potential / Fields image.\n\nParameters\n----------\nepochs : instance of Epochs\n    The epochs.\n%(picks_good_data)s\n    ``picks`` interacts with ``group_by`` and ``combine`` to determine the\n    number of figures generated; see Notes.\nsigma : float\n    The standard deviation of a Gaussian smoothing window applied along\n    the epochs axis of the image. If 0, no smoothing is applied.\n    Defaults to 0.\nvmin : None | float | callable\n    The min value in the image (and the ER[P/F]). The unit is \u00b5V for\n    EEG channels, fT for magnetometers and fT/cm for gradiometers.\n    If vmin is None and multiple plots are returned, the limit is\n    equalized within channel types.\n    Hint: to specify the lower limit of the data, use\n    ``vmin=lambda data: data.min()``.\nvmax : None | float | callable\n    The max value in the image (and the ER[P/F]). The unit is \u00b5V for\n    EEG channels, fT for magnetometers and fT/cm for gradiometers.\n    If vmin is None and multiple plots are returned, the limit is\n    equalized within channel types.\ncolorbar : bool\n    Display or not a colorbar.\norder : None | array of int | callable\n    If not ``None``, order is used to reorder the epochs along the y-axis\n    of the image. If it is an array of :class:`int`, its length should\n    match the number of good epochs. If it is a callable it should accept\n    two positional parameters (``times`` and ``data``, where\n    ``data.shape == (len(good_epochs), len(times))``) and return an\n    :class:`array <numpy.ndarray>` of indices that will sort ``data`` along\n    its first axis.\nshow : bool\n    Show figure if True.\nunits : dict | None\n    The units of the channel types used for axes labels. If None,\n    defaults to ``units=dict(eeg='\u00b5V', grad='fT/cm', mag='fT')``.\nscalings : dict | None\n    The scalings of the channel types to be applied for plotting.\n    If None, defaults to ``scalings=dict(eeg=1e6, grad=1e13, mag=1e15,\n    eog=1e6)``.\ncmap : None | colormap | (colormap, bool) | 'interactive'\n    Colormap. If tuple, the first value indicates the colormap to use and\n    the second value is a boolean defining interactivity. In interactive\n    mode the colors are adjustable by clicking and dragging the colorbar\n    with left and right mouse button. Left mouse button moves the scale up\n    and down and right mouse button adjusts the range. Hitting space bar\n    resets the scale. Up and down arrows can be used to change the\n    colormap. If 'interactive', translates to ('RdBu_r', True).\n    If None, \"RdBu_r\" is used, unless the data is all positive, in which\n    case \"Reds\" is used.\nfig : Figure | None\n    :class:`~matplotlib.figure.Figure` instance to draw the image to.\n    Figure must contain the correct number of axes for drawing the epochs\n    image, the evoked response, and a colorbar (depending on values of\n    ``evoked`` and ``colorbar``). If ``None`` a new figure is created.\n    Defaults to ``None``.\naxes : list of Axes | dict of list of Axes | None\n    List of :class:`~matplotlib.axes.Axes` objects in which to draw the\n    image, evoked response, and colorbar (in that order). Length of list\n    must be 1, 2, or 3 (depending on values of ``colorbar`` and ``evoked``\n    parameters). If a :class:`dict`, each entry must be a list of Axes\n    objects with the same constraints as above. If both ``axes`` and\n    ``group_by`` are dicts, their keys must match. Providing non-``None``\n    values for both ``fig`` and ``axes``  results in an error. Defaults to\n    ``None``.\noverlay_times : array_like, shape (n_epochs,) | None\n    Times (in seconds) at which to draw a line on the corresponding row of\n    the image (e.g., a reaction time associated with each epoch). Note that\n    ``overlay_times`` should be ordered to correspond with the\n    :class:`~mne.Epochs` object (i.e., ``overlay_times[0]`` corresponds to\n    ``epochs[0]``, etc).\n%(combine_plot_epochs_image)s\ngroup_by : None | dict\n    Specifies which channels are aggregated into a single figure, with\n    aggregation method determined by the ``combine`` parameter. If not\n    ``None``, one :class:`~matplotlib.figure.Figure` is made per dict\n    entry; the dict key will be used as the figure title and the dict\n    values must be lists of picks (either channel names or integer indices\n    of ``epochs.ch_names``). For example::\n\n        group_by=dict(Left_ROI=[1, 2, 3, 4], Right_ROI=[5, 6, 7, 8])\n\n    Note that within a dict entry all channels must have the same type.\n    ``group_by`` interacts with ``picks`` and ``combine`` to determine the\n    number of figures generated; see Notes. Defaults to ``None``.\nevoked : bool\n    Draw the ER[P/F] below the image or not.\nts_args : None | dict\n    Arguments passed to a call to `~mne.viz.plot_compare_evokeds` to style\n    the evoked plot below the image. Defaults to an empty dictionary,\n    meaning `~mne.viz.plot_compare_evokeds` will be called with default\n    parameters.\ntitle : None | str\n    If :class:`str`, will be plotted as figure title. Otherwise, the\n    title will indicate channel(s) or channel type being plotted. Defaults\n    to ``None``.\nclear : bool\n    Whether to clear the axes before plotting (if ``fig`` or ``axes`` are\n    provided). Defaults to ``False``.\n\nReturns\n-------\nfigs : list of Figure\n    One figure per channel, channel type, or group, depending on values of\n    ``picks``, ``group_by``, and ``combine``. See Notes.\n\nNotes\n-----\nYou can control how channels are aggregated into one figure or plotted in\nseparate figures through a combination of the ``picks``, ``group_by``, and\n``combine`` parameters. If ``group_by`` is a :class:`dict`, the result is\none :class:`~matplotlib.figure.Figure` per dictionary key (for any valid\nvalues of ``picks`` and ``combine``). If ``group_by`` is ``None``, the\nnumber and content of the figures generated depends on the values of\n``picks`` and ``combine``, as summarized in this table:\n\n.. cssclass:: table-bordered\n.. rst-class:: midvalign\n\n+----------+----------------------------+------------+-------------------+\n| group_by | picks                      | combine    | result            |\n+==========+============================+============+===================+\n|          | None, int, list of int,    | None,      |                   |\n| dict     | ch_name, list of ch_names, | string, or | 1 figure per      |\n|          | ch_type, list of ch_types  | callable   | dict key          |\n+----------+----------------------------+------------+-------------------+\n|          | None,                      | None,      |                   |\n|          | ch_type,                   | string, or | 1 figure per      |\n|          | list of ch_types           | callable   | ch_type           |\n| None     +----------------------------+------------+-------------------+\n|          | int,                       | None       | 1 figure per pick |\n|          | ch_name,                   +------------+-------------------+\n|          | list of int,               | string or  | 1 figure          |\n|          | list of ch_names           | callable   |                   |\n+----------+----------------------------+------------+-------------------+", "metadata": {}}
{"_id": "mne_mne_viz/epochs.py_plot_drop_log_doc", "text": "Show the channel stats based on a drop_log from Epochs.\n\nParameters\n----------\ndrop_log : list of list\n    Epoch drop log from Epochs.drop_log.\nthreshold : float\n    The percentage threshold to use to decide whether or not to\n    plot. Default is zero (always plot).\nn_max_plot : int\n    Maximum number of channels to show stats for.\nsubject : str | None\n    The subject name to use in the title of the plot. If ``None``, do not\n    display a subject name.\n\n    .. versionchanged:: 0.23\n       Added support for ``None``.\n\n    .. versionchanged:: 1.0\n       Defaults to ``None``.\ncolor : tuple | str\n    Color to use for the bars.\nwidth : float\n    Width of the bars.\nignore : list\n    The drop reasons to ignore.\nshow : bool\n    Show figure if True.\n\nReturns\n-------\nfig : instance of matplotlib.figure.Figure\n    The figure.", "metadata": {}}
{"_id": "mne_mne_viz/epochs.py_plot_epochs_doc", "text": "Visualize epochs.\n\nBad epochs can be marked with a left click on top of the epoch. Bad\nchannels can be selected by clicking the channel name on the left side of\nthe main axes. Calling this function drops all the selected bad epochs as\nwell as bad epochs marked beforehand with rejection parameters.\n\nParameters\n----------\nepochs : instance of Epochs\n    The epochs object.\n%(picks_good_data)s\n%(scalings)s\nn_epochs : int\n    The number of epochs per view. Defaults to 20.\nn_channels : int\n    The number of channels per view. Defaults to 20.\ntitle : str | None\n    The title of the window. If None, the event names (from\n    ``epochs.event_id``) will be displayed. Defaults to None.\nevents : bool | array, shape (n_events, 3)\n    Events to show with vertical bars. You can use `~mne.viz.plot_events`\n    as a legend for the colors. By default, the coloring scheme is the\n    same. ``True`` plots ``epochs.events``. Defaults to ``False`` (do not\n    plot events).\n\n    .. warning::  If the epochs have been resampled, the events no longer\n        align with the data.\n\n    .. versionadded:: 0.14.0\n\n    .. versionchanged:: 1.6\n        Passing ``events=None`` was disallowed.\n        The new equivalent is ``events=False``.\n%(event_color)s\n    Defaults to ``None``.\norder : array of str | None\n    Order in which to plot channel types.\n\n    .. versionadded:: 0.18.0\nshow : bool\n    Show figure if True. Defaults to True.\nblock : bool\n    Whether to halt program execution until the figure is closed.\n    Useful for rejecting bad trials on the fly by clicking on an epoch.\n    Defaults to False.\ndecim : int | 'auto'\n    Amount to decimate the data during display for speed purposes.\n    You should only decimate if the data are sufficiently low-passed,\n    otherwise aliasing can occur. The 'auto' mode (default) uses\n    the decimation that results in a sampling rate at least three times\n    larger than ``info['lowpass']`` (e.g., a 40 Hz lowpass will result in\n    at least a 120 Hz displayed sample rate).\n\n    .. versionadded:: 0.15.0\nnoise_cov : instance of Covariance | str | None\n    Noise covariance used to whiten the data while plotting.\n    Whitened data channels are scaled by ``scalings['whitened']``,\n    and their channel names are shown in italic.\n    Can be a string to load a covariance from disk.\n    See also :meth:`mne.Evoked.plot_white` for additional inspection\n    of noise covariance properties when whitening evoked data.\n    For data processed with SSS, the effective dependence between\n    magnetometers and gradiometers may introduce differences in scaling,\n    consider using :meth:`mne.Evoked.plot_white`.\n\n    .. versionadded:: 0.16.0\nbutterfly : bool\n    Whether to directly call the butterfly view.\n\n    .. versionadded:: 0.18.0\n%(show_scrollbars)s\n%(show_scalebars)s\n\n    .. versionadded:: 0.24.0\nepoch_colors : list of (n_epochs) list (of n_channels) | None\n    Colors to use for individual epochs. If None, use default colors.\nevent_id : bool | dict\n    Determines to label the event markers on the plot. If ``True``, uses\n    ``epochs.event_id``. If ``False``, uses integer event codes instead of IDs.\n    If a ``dict`` is passed, uses its *keys* as event labels on the plot for\n    entries whose *values* are integer codes for events being drawn. Ignored if\n    ``events=False``.\n\n    .. versionadded:: 0.20\n%(group_by_browse)s\n%(precompute)s\n%(use_opengl)s\n%(theme_pg)s\n\n    .. versionadded:: 1.0\n%(overview_mode)s\n\n    .. versionadded:: 1.1\n%(splash)s\n\n    .. versionadded:: 1.6\n\nReturns\n-------\n%(browser)s\n\nNotes\n-----\nThe arrow keys (up/down/left/right) can be used to navigate between\nchannels and epochs and the scaling can be adjusted with - and + (or =)\nkeys, but this depends on the backend matplotlib is configured to use\n(e.g., mpl.use(``TkAgg``) should work). Full screen mode can be toggled\nwith f11 key. The amount of epochs and channels per view can be adjusted\nwith home/end and page down/page up keys. ``h`` key plots a histogram of\npeak-to-peak values along with the used rejection thresholds. Butterfly\nplot can be toggled with ``b`` key. Left mouse click adds a vertical line\nto the plot. Click 'help' button at bottom left corner of the plotter to\nview all the options.\n\n%(notes_2d_backend)s\n\n.. versionadded:: 0.10.0", "metadata": {}}
{"_id": "mne_mne_viz/epochs.py_plot_epochs_psd_doc", "text": "%(plot_psd_doc)s.\n\nParameters\n----------\nepochs : instance of Epochs\n    The epochs object.\n%(fmin_fmax_psd)s\n%(tmin_tmax_psd)s\n%(proj_psd)s\nbandwidth : float\n    The bandwidth of the multi taper windowing function in Hz. The default\n    value is a window half-bandwidth of 4.\nadaptive : bool\n    Use adaptive weights to combine the tapered spectra into PSD\n    (slow, use n_jobs >> 1 to speed up computation).\nlow_bias : bool\n    Only use tapers with more than 90%% spectral concentration within\n    bandwidth.\n%(normalization)s\n%(picks_good_data_noref)s\n%(ax_plot_psd)s\n%(color_plot_psd)s\n%(xscale_plot_psd)s\n%(area_mode_plot_psd)s\n%(area_alpha_plot_psd)s\n%(dB_plot_psd)s\n%(estimate_plot_psd)s\n%(show)s\n%(n_jobs)s\n%(average_plot_psd)s\n%(line_alpha_plot_psd)s\n%(spatial_colors_psd)s\n%(sphere_topomap_auto)s\nexclude : list of str | 'bads'\n    Channels names to exclude from being shown. If 'bads', the bad channels\n    are excluded. Pass an empty list to plot all channels (including\n    channels marked \"bad\", if any).\n\n    .. versionadded:: 0.24.0\n%(verbose)s\n\nReturns\n-------\nfig : instance of Figure\n    Figure with frequency spectra of the data channels.\n\nNotes\n-----\n%(notes_plot_*_psd_func)s", "metadata": {}}
{"_id": "mne_mne_viz/evoked.py_plot_evoked_doc", "text": "Plot evoked data using butterfly plots.\n\nLeft click to a line shows the channel name. Selecting an area by clicking\nand holding left mouse button plots a topographic map of the painted area.\n\n.. note:: If bad channels are not excluded they are shown in red.\n\nParameters\n----------\nevoked : instance of Evoked\n    The evoked data.\n%(picks_all)s\nexclude : list of str | ``'bads'``\n    Channels names to exclude from being shown. If ``'bads'``, the\n    bad channels are excluded.\nunit : bool\n    Scale plot with channel (SI) unit.\nshow : bool\n    Show figure if True.\n%(evoked_ylim_plot)s\nxlim : ``'tight'`` | tuple | None\n    Limits for the X-axis of the plots.\n%(proj_plot)s\nhline : list of float | None\n    The values at which to show an horizontal line.\nunits : dict | None\n    The units of the channel types used for axes labels. If None,\n    defaults to ``dict(eeg='\u00b5V', grad='fT/cm', mag='fT')``.\nscalings : dict | None\n    The scalings of the channel types to be applied for plotting. If None,\n    defaults to ``dict(eeg=1e6, grad=1e13, mag=1e15)``.\ntitles : dict | None\n    The titles associated with the channels. If None, defaults to\n    ``dict(eeg='EEG', grad='Gradiometers', mag='Magnetometers')``.\naxes : instance of Axes | list | None\n    The axes to plot to. If list, the list must be a list of Axes of\n    the same length as the number of channel types. If instance of\n    Axes, there must be only one channel type plotted.\ngfp : bool | ``'only'``\n    Plot the global field power (GFP) or the root mean square (RMS) of the\n    data. For MEG data, this will plot the RMS. For EEG, it plots GFP,\n    i.e. the standard deviation of the signal across channels. The GFP is\n    equivalent to the RMS of an average-referenced signal.\n\n    - ``True``\n        Plot GFP or RMS (for EEG and MEG, respectively) and traces for all\n        channels.\n    - ``'only'``\n        Plot GFP or RMS (for EEG and MEG, respectively), and omit the\n        traces for individual channels.\n\n    The color of the GFP/RMS trace will be green if\n    ``spatial_colors=False``, and black otherwise.\n\n    .. versionchanged:: 0.23\n       Plot GFP for EEG instead of RMS. Label RMS traces correctly as such.\nwindow_title : str | None\n    The title to put at the top of the figure.\n%(spatial_colors)s\nzorder : str | callable\n    Which channels to put in the front or back. Only matters if\n    ``spatial_colors`` is used.\n    If str, must be ``std`` or ``unsorted`` (defaults to ``unsorted``). If\n    ``std``, data with the lowest standard deviation (weakest effects) will\n    be put in front so that they are not obscured by those with stronger\n    effects. If ``unsorted``, channels are z-sorted as in the evoked\n    instance.\n    If callable, must take one argument: a numpy array of the same\n    dimensionality as the evoked raw data; and return a list of\n    unique integers corresponding to the number of channels.\n\n    .. versionadded:: 0.13.0\n\nselectable : bool\n    Whether to use interactive features. If True (default), it is possible\n    to paint an area to draw topomaps. When False, the interactive features\n    are disabled. Disabling interactive features reduces memory consumption\n    and is useful when using ``axes`` parameter to draw multiaxes figures.\n\n    .. versionadded:: 0.13.0\n\nnoise_cov : instance of Covariance | str | None\n    Noise covariance used to whiten the data while plotting.\n    Whitened data channel names are shown in italic.\n    Can be a string to load a covariance from disk.\n    See also :meth:`mne.Evoked.plot_white` for additional inspection\n    of noise covariance properties when whitening evoked data.\n    For data processed with SSS, the effective dependence between\n    magnetometers and gradiometers may introduce differences in scaling,\n    consider using :meth:`mne.Evoked.plot_white`.\n\n    .. versionadded:: 0.16.0\n%(time_unit)s\n\n    .. versionadded:: 0.16\n%(sphere_topomap_auto)s\nhighlight : array-like of float, shape(2,) | array-like of float, shape (n, 2) | None\n    Segments of the data to highlight by means of a light-yellow\n    background color. Can be used to put visual emphasis on certain\n    time periods. The time periods must be specified as ``array-like``\n    objects in the form of ``(t_start, t_end)`` in the unit given by the\n    ``time_unit`` parameter.\n    Multiple time periods can be specified by passing an ``array-like``\n    object of individual time periods (e.g., for 3 time periods, the shape\n    of the passed object would be ``(3, 2)``. If ``None``, no highlighting\n    is applied.\n\n    .. versionadded:: 1.1\n%(verbose)s\n\nReturns\n-------\nfig : instance of matplotlib.figure.Figure\n    Figure containing the butterfly plots.\n\nSee Also\n--------\nmne.viz.plot_evoked_white", "metadata": {}}
{"_id": "mne_mne_viz/evoked.py_plot_evoked_topo_doc", "text": "Plot 2D topography of evoked responses.\n\nClicking on the plot of an individual sensor opens a new figure showing\nthe evoked response for the selected sensor.\n\nParameters\n----------\nevoked : list of Evoked | Evoked\n    The evoked response to plot.\nlayout : instance of Layout | None\n    Layout instance specifying sensor positions (does not need to\n    be specified for Neuromag data). If possible, the correct layout is\n    inferred from the data.\nlayout_scale : float\n    Scaling factor for adjusting the relative size of the layout\n    on the canvas.\ncolor : list of color | color | None\n    Everything matplotlib accepts to specify colors. If not list-like,\n    the color specified will be repeated. If None, colors are\n    automatically drawn.\nborder : str\n    Matplotlib borders style to be used for each sensor plot.\n%(evoked_ylim_plot)s\nscalings : dict | None\n    The scalings of the channel types to be applied for plotting. If None,`\n    defaults to ``dict(eeg=1e6, grad=1e13, mag=1e15)``.\ntitle : str\n    Title of the figure.\nproj : bool | ``'interactive'``\n    If true SSP projections are applied before display. If ``'interactive'``,\n    a check box for reversible selection of SSP projection vectors will\n    be shown.\nvline : list of float | float | None\n    The values at which to show a vertical line.\nfig_background : None | ndarray\n    A background image for the figure. This must work with a call to\n    ``plt.imshow``. Defaults to None.\nmerge_grads : bool\n    Whether to use RMS value of gradiometer pairs. Only works for Neuromag\n    data. Defaults to False.\nlegend : bool | int | str | tuple\n    If True, create a legend based on evoked.comment. If False, disable the\n    legend. Otherwise, the legend is created and the parameter value is\n    passed as the location parameter to the matplotlib legend call. It can\n    be an integer (e.g. 0 corresponds to upper right corner of the plot),\n    a string (e.g. ``'upper right'``), or a tuple (x, y coordinates of the\n    lower left corner of the legend in the axes coordinate system).\n    See matplotlib documentation for more details.\naxes : instance of matplotlib Axes | None\n    Axes to plot into. If None, axes will be created.\nbackground_color : color\n    Background color. Typically ``'k'`` (black) or ``'w'`` (white; default).\n\n    .. versionadded:: 0.15.0\nnoise_cov : instance of Covariance | str | None\n    Noise covariance used to whiten the data while plotting.\n    Whitened data channel names are shown in italic.\n    Can be a string to load a covariance from disk.\n\n    .. versionadded:: 0.16.0\nexclude : list of str | ``'bads'``\n    Channels names to exclude from the plot. If ``'bads'``, the\n    bad channels are excluded. By default, exclude is set to ``'bads'``.\nselect : bool\n    Whether to enable the lasso-selection tool to enable the user to select\n    channels. The selected channels will be available in\n    ``fig.lasso.selection``.\n\n    .. versionadded:: 1.10.0\nexclude : list of str | ``'bads'``\n    Channels names to exclude from the plot. If ``'bads'``, the\n    bad channels are excluded. By default, exclude is set to ``'bads'``.\nshow : bool\n    Show figure if True.\n\nReturns\n-------\nfig : instance of matplotlib.figure.Figure\n    Images of evoked responses at sensor locations.", "metadata": {}}
{"_id": "mne_mne_viz/evoked.py_plot_evoked_image_doc", "text": "Plot evoked data as images.\n\nParameters\n----------\nevoked : instance of Evoked\n    The evoked data.\n%(picks_all)s\n    This parameter can also be used to set the order the channels\n    are shown in, as the channel image is sorted by the order of picks.\nexclude : list of str | 'bads'\n    Channels names to exclude from being shown. If 'bads', the\n    bad channels are excluded.\nunit : bool\n    Scale plot with channel (SI) unit.\nshow : bool\n    Show figure if True.\nclim : dict | None\n    Color limits for plots (after scaling has been applied). e.g.\n    ``clim = dict(eeg=[-20, 20])``.\n    Valid keys are eeg, mag, grad, misc. If None, the clim parameter\n    for each channel equals the pyplot default.\nxlim : 'tight' | tuple | None\n    X limits for plots.\nproj : bool | 'interactive'\n    If true SSP projections are applied before display. If 'interactive',\n    a check box for reversible selection of SSP projection vectors will\n    be shown.\nunits : dict | None\n    The units of the channel types used for axes labels. If None,\n    defaults to ``dict(eeg='\u00b5V', grad='fT/cm', mag='fT')``.\nscalings : dict | None\n    The scalings of the channel types to be applied for plotting. If None,`\n    defaults to ``dict(eeg=1e6, grad=1e13, mag=1e15)``.\ntitles : dict | None\n    The titles associated with the channels. If None, defaults to\n    ``dict(eeg='EEG', grad='Gradiometers', mag='Magnetometers')``.\naxes : instance of Axes | list | dict | None\n    The axes to plot to. If list, the list must be a list of Axes of\n    the same length as the number of channel types. If instance of\n    Axes, there must be only one channel type plotted.\n    If ``group_by`` is a dict, this cannot be a list, but it can be a dict\n    of lists of axes, with the keys matching those of ``group_by``. In that\n    case, the provided axes will be used for the corresponding groups.\n    Defaults to ``None``.\ncmap : matplotlib colormap | (colormap, bool) | 'interactive'\n    Colormap. If tuple, the first value indicates the colormap to use and\n    the second value is a boolean defining interactivity. In interactive\n    mode the colors are adjustable by clicking and dragging the colorbar\n    with left and right mouse button. Left mouse button moves the scale up\n    and down and right mouse button adjusts the range. Hitting space bar\n    resets the scale. Up and down arrows can be used to change the\n    colormap. If 'interactive', translates to ``('RdBu_r', True)``.\n    Defaults to ``'RdBu_r'``.\ncolorbar : bool\n    If True, plot a colorbar. Defaults to True.\n\n    .. versionadded:: 0.16\nmask : ndarray | None\n    An array of booleans of the same shape as the data. Entries of the\n    data that correspond to ``False`` in the mask are masked (see\n    ``do_mask`` below). Useful for, e.g., masking for statistical\n    significance.\n\n    .. versionadded:: 0.16\nmask_style : None | 'both' | 'contour' | 'mask'\n    If ``mask`` is not None: if 'contour', a contour line is drawn around\n    the masked areas (``True`` in ``mask``). If 'mask', entries not\n    ``True`` in ``mask`` are shown transparently. If 'both', both a contour\n    and transparency are used.\n    If ``None``, defaults to 'both' if ``mask`` is not None, and is ignored\n    otherwise.\n\n     .. versionadded:: 0.16\nmask_cmap : matplotlib colormap | (colormap, bool) | 'interactive'\n    The colormap chosen for masked parts of the image (see below), if\n    ``mask`` is not ``None``. If None, ``cmap`` is reused. Defaults to\n    ``Greys``. Not interactive. Otherwise, as ``cmap``.\nmask_alpha : float\n    A float between 0 and 1. If ``mask`` is not None, this sets the\n    alpha level (degree of transparency) for the masked-out segments.\n    I.e., if 0, masked-out segments are not visible at all.\n    Defaults to .25.\n\n    .. versionadded:: 0.16\ntime_unit : str\n    The units for the time axis, can be \"ms\" or \"s\" (default).\n\n    .. versionadded:: 0.16\nshow_names : bool | 'auto' | 'all'\n    Determines if channel names should be plotted on the y axis. If False,\n    no names are shown. If True, ticks are set automatically by matplotlib\n    and the corresponding channel names are shown. If \"all\", all channel\n    names are shown. If \"auto\", is set to False if ``picks`` is ``None``,\n    to ``True`` if ``picks`` contains 25 or more entries, or to \"all\"\n    if ``picks`` contains fewer than 25 entries.\ngroup_by : None | dict\n    If a dict, the values must be picks, and ``axes`` must also be a dict\n    with matching keys, or None. If ``axes`` is None, one figure and one\n    axis will be created for each entry in ``group_by``.Then, for each\n    entry, the picked channels will be plotted to the corresponding axis.\n    If ``titles`` are None, keys will become plot titles. This is useful\n    for e.g. ROIs. Each entry must contain only one channel type.\n    For example::\n\n        group_by=dict(Left_ROI=[1, 2, 3, 4], Right_ROI=[5, 6, 7, 8])\n\n    If None, all picked channels are plotted to the same axis.\n%(sphere_topomap_auto)s\n\nReturns\n-------\nfig : instance of matplotlib.figure.Figure\n    Figure containing the images.", "metadata": {}}
{"_id": "mne_mne_viz/evoked.py_plot_evoked_white_doc", "text": "Plot whitened evoked response.\n\nPlots the whitened evoked response and the whitened GFP as described in\n:footcite:`EngemannGramfort2015`. This function is especially useful for\ninvestigating noise covariance properties to determine if data are\nproperly whitened (e.g., achieving expected values in line with model\nassumptions, see Notes below).\n\nParameters\n----------\nevoked : instance of mne.Evoked\n    The evoked response.\nnoise_cov : list | instance of Covariance | path-like\n    The noise covariance. Can be a string to load a covariance from disk.\nshow : bool\n    Show figure if True.\n%(rank_none)s\ntime_unit : str\n    The units for the time axis, can be \"ms\" or \"s\" (default).\n\n    .. versionadded:: 0.16\n%(sphere_topomap_auto)s\naxes : list | None\n    List of axes to plot into.\n\n    .. versionadded:: 0.21.0\n%(spatial_colors)s\n\n    .. versionadded:: 1.8.0\n%(verbose)s\n\nReturns\n-------\nfig : instance of matplotlib.figure.Figure\n    The figure object containing the plot.\n\nSee Also\n--------\nmne.Evoked.plot\n\nNotes\n-----\nIf baseline signals match the assumption of Gaussian white noise,\nvalues should be centered at 0, and be within 2 standard deviations\n(\u00b11.96) for 95%% of the time points. For the global field power (GFP),\nwe expect it to fluctuate around a value of 1.\n\nIf one single covariance object is passed, the GFP panel (bottom)\nwill depict different sensor types. If multiple covariance objects are\npassed as a list, the left column will display the whitened evoked\nresponses for each channel based on the whitener from the noise covariance\nthat has the highest log-likelihood. The left column will depict the\nwhitened GFPs based on each estimator separately for each sensor type.\nInstead of numbers of channels the GFP display shows the estimated rank.\nNote. The rank estimation will be printed by the logger\n(if ``verbose=True``) for each noise covariance estimator that is passed.\n\nReferences\n----------\n.. [1] Engemann D. and Gramfort A. (2015) Automated model selection in\n       covariance estimation and spatial whitening of MEG and EEG\n       signals, vol. 108, 328-342, NeuroImage.", "metadata": {}}
{"_id": "mne_mne_viz/evoked.py_plot_snr_estimate_doc", "text": "Plot a data SNR estimate.\n\nParameters\n----------\nevoked : instance of Evoked\n    The evoked instance. This should probably be baseline-corrected.\ninv : instance of InverseOperator\n    The minimum-norm inverse operator.\nshow : bool\n    Show figure if True.\naxes : instance of Axes | None\n    The axes to plot into.\n\n    .. versionadded:: 0.21.0\n%(verbose)s\n\nReturns\n-------\nfig : instance of matplotlib.figure.Figure\n    The figure object containing the plot.\n\nNotes\n-----\nThe bluish green line is the SNR determined by the GFP of the whitened\nevoked data. The orange line is the SNR estimated based on the mismatch\nbetween the data and the data re-estimated from the regularized inverse.\n\n.. versionadded:: 0.9.0", "metadata": {}}
{"_id": "mne_mne_viz/evoked.py_plot_evoked_joint_doc", "text": "Plot evoked data as butterfly plot and add topomaps for time points.\n\n.. note:: Axes to plot in can be passed by the user through ``ts_args`` or\n          ``topomap_args``. In that case both ``ts_args`` and\n          ``topomap_args`` axes have to be used. Be aware that when the\n          axes are provided, their position may be slightly modified.\n\nParameters\n----------\nevoked : instance of Evoked\n    The evoked instance.\ntimes : float | array of float | \"auto\" | \"peaks\"\n    The time point(s) to plot. If ``\"auto\"``, 5 evenly spaced topographies\n    between the first and last time instant will be shown. If ``\"peaks\"``,\n    finds time points automatically by checking for 3 local maxima in\n    Global Field Power. Defaults to ``\"peaks\"``.\ntitle : str | None\n    The title. If ``None``, suppress printing channel type title. If an\n    empty string, a default title is created. Defaults to ''. If custom\n    axes are passed make sure to set ``title=None``, otherwise some of your\n    axes may be removed during placement of the title axis.\n%(picks_all)s\nexclude : None | list of str | 'bads'\n    Channels names to exclude from being shown. If ``'bads'``, the\n    bad channels are excluded. Defaults to ``None``.\nshow : bool\n    Show figure if ``True``. Defaults to ``True``.\nts_args : None | dict\n    A dict of ``kwargs`` that are forwarded to :meth:`mne.Evoked.plot` to\n    style the butterfly plot. If they are not in this dict, the following\n    defaults are passed: ``spatial_colors=True``, ``zorder='std'``.\n    ``show`` and ``exclude`` are illegal.\n    If ``None``, no customizable arguments will be passed.\n    Defaults to ``None``.\ntopomap_args : None | dict\n    A dict of ``kwargs`` that are forwarded to\n    :meth:`mne.Evoked.plot_topomap` to style the topomaps.\n    If it is not in this dict, ``outlines='head'`` will be passed.\n    ``show``, ``times``, ``colorbar`` are illegal.\n    If ``None``, no customizable arguments will be passed.\n    Defaults to ``None``.\n\nReturns\n-------\nfig : instance of matplotlib.figure.Figure | list\n    The figure object containing the plot. If ``evoked`` has multiple\n    channel types, a list of figures, one for each channel type, is\n    returned.\n\nNotes\n-----\n.. versionadded:: 0.12.0", "metadata": {}}
{"_id": "mne_mne_viz/evoked.py_plot_compare_evokeds_doc", "text": "Plot evoked time courses for one or more conditions and/or channels.\n\nParameters\n----------\nevokeds : instance of mne.Evoked | list | dict\n    If a single Evoked instance, it is plotted as a time series.\n    If a list of Evokeds, the contents are plotted with their\n    ``.comment`` attributes used as condition labels. If no comment is set,\n    the index of the respective Evoked the list will be used instead,\n    starting with ``1`` for the first Evoked.\n    If a dict whose values are Evoked objects, the contents are plotted as\n    single time series each and the keys are used as labels.\n    If a [dict/list] of lists, the unweighted mean is plotted as a time\n    series and the parametric confidence interval is plotted as a shaded\n    area. All instances must have the same shape - channel numbers, time\n    points etc.\n    If dict, keys must be of type :class:`str`.\n%(picks_all_data)s\n\n    * If picks is None or a (collection of) data channel types, the\n      global field power will be plotted for all data channels.\n      Otherwise, picks will be averaged.\n    * If multiple channel types are selected, one\n      figure will be returned for each channel type.\n    * If the selected channels are gradiometers, the signal from\n      corresponding (gradiometer) pairs will be combined.\n\ncolors : list | dict | None\n    Colors to use when plotting the ERP/F lines and confidence bands. If\n    ``cmap`` is not ``None``, ``colors`` must be a :class:`list` or\n    :class:`dict` of :class:`ints <int>` or :class:`floats <float>`\n    indicating steps or percentiles (respectively) along the colormap. If\n    ``cmap`` is ``None``, list elements or dict values of ``colors`` must\n    be :class:`ints <int>` or valid :ref:`matplotlib colors\n    <matplotlib:colors_def>`; lists are cycled through\n    sequentially,\n    while dicts must have keys matching the keys or conditions of an\n    ``evokeds`` dict (see Notes for details). If ``None``, the current\n    :doc:`matplotlib color cycle\n    <matplotlib:gallery/color/color_cycle_default>`\n    is used. Defaults to ``None``.\nlinestyles : list | dict | None\n    Styles to use when plotting the ERP/F lines. If a :class:`list` or\n    :class:`dict`, elements must be valid :doc:`matplotlib linestyles\n    <matplotlib:gallery/lines_bars_and_markers/linestyles>`. Lists are\n    cycled through sequentially; dictionaries must have keys matching the\n    keys or conditions of an ``evokeds`` dict (see Notes for details). If\n    ``None``, all lines will be solid. Defaults to ``None``.\nstyles : dict | None\n    Dictionary of styles to use when plotting ERP/F lines. Keys must match\n    keys or conditions of ``evokeds``, and values must be a :class:`dict`\n    of legal inputs to :func:`matplotlib.pyplot.plot`. Those values will be\n    passed as parameters to the line plot call of the corresponding\n    condition, overriding defaults (e.g.,\n    ``styles={\"Aud/L\": {\"linewidth\": 3}}`` will set the linewidth for\n    \"Aud/L\" to 3). As with ``colors`` and ``linestyles``, keys matching\n    conditions in ``/``-separated ``evokeds`` keys are supported (see Notes\n    for details).\ncmap : None | str | tuple | instance of matplotlib.colors.Colormap\n    Colormap from which to draw color values when plotting the ERP/F lines\n    and confidence bands. If not ``None``, ints or floats in the ``colors``\n    parameter are mapped to steps or percentiles (respectively) along the\n    colormap. If ``cmap`` is a :class:`str`, it will be passed to\n    ``matplotlib.colormaps``; if ``cmap`` is a tuple, its first\n    element will be used as a string to label the colorbar, and its\n    second element will be passed to ``matplotlib.colormaps`` (unless\n    it is already an instance of :class:`~matplotlib.colors.Colormap`).\n\n    .. versionchanged:: 0.19\n        Support for passing :class:`~matplotlib.colors.Colormap` instances.\n\nvlines : ``\"auto\"`` | list of float\n    A list in seconds at which to plot dashed vertical lines.\n    If ``\"auto\"`` and the supplied data includes 0, it is set to ``[0.]``\n    and a vertical bar is plotted at time 0. If an empty list is passed,\n    no vertical lines are plotted.\nci : float | bool | callable | None\n    Confidence band around each ERP/F time series. If ``False`` or ``None``\n    no confidence band is drawn. If :class:`float`, ``ci`` must be between\n    0 and 1, and will set the threshold for a bootstrap\n    (single plot)/parametric (when ``axes=='topo'``)  estimation of the\n    confidence band; ``True`` is equivalent to setting a threshold of 0.95\n    (i.e., the 95%% confidence band is drawn). If a callable, it must take\n    a single array (n_observations \u00d7 n_times) as input and return upper and\n    lower confidence margins (2 \u00d7 n_times). Defaults to ``True``.\ntruncate_yaxis : bool | ``'auto'``\n    Whether to shorten the y-axis spine. If ``'auto'``, the spine is truncated\n    at the minimum and maximum ticks. If ``True``, it is truncated at the\n    multiple of 0.25 nearest to half the maximum absolute value of the\n    data. If ``truncate_xaxis=False``, only the far bound of the y-axis\n    will be truncated. Defaults to ``'auto'``.\ntruncate_xaxis : bool\n    Whether to shorten the x-axis spine. If ``True``, the spine is\n    truncated at the minimum and maximum ticks. If\n    ``truncate_yaxis=False``, only the far bound of the x-axis will be\n    truncated. Defaults to ``True``.\n%(evoked_ylim_plot)s\ninvert_y : bool\n    Whether to plot negative values upward (as is sometimes done\n    for ERPs out of tradition). Defaults to ``False``.\nshow_sensors : bool | int | str | None\n    Whether to display an inset showing sensor locations on a head outline.\n    If :class:`int` or :class:`str`, indicates position of the inset (see\n    :func:`mpl_toolkits.axes_grid1.inset_locator.inset_axes`). If ``None``,\n    treated as ``True`` if there is only one channel in ``picks``. If\n    ``True``, location is upper or lower right corner, depending on data\n    values. Defaults to ``None``.\nlegend : bool | int | str\n    Whether to show a legend for the colors/linestyles of the conditions\n    plotted. If :class:`int` or :class:`str`, indicates position of the\n    legend (see :func:`mpl_toolkits.axes_grid1.inset_locator.inset_axes`).\n    If ``True``, equivalent to ``'upper left'``. Defaults to ``True``.\nsplit_legend : bool | None\n    Whether to separate color and linestyle in the legend. If ``None``,\n    a separate linestyle legend will still be shown if ``cmap`` is\n    specified. Defaults to ``None``.\naxes : None | Axes instance | list of Axes | ``'topo'``\n    :class:`~matplotlib.axes.Axes` object to plot into. If plotting\n    multiple channel types (or multiple channels when ``combine=None``),\n    ``axes`` should be a list of appropriate length containing\n    :class:`~matplotlib.axes.Axes` objects. If ``'topo'``, a new\n    :class:`~matplotlib.figure.Figure` is created with one axis for each\n    channel, in a topographical layout. If ``None``, a new\n    :class:`~matplotlib.figure.Figure` is created for each channel type.\n    Defaults to ``None``.\ntitle : str | None\n    Title printed above the plot. If ``None``, a title will be\n    automatically generated based on channel name(s) or type(s) and the\n    value of the ``combine`` parameter. Defaults to ``None``.\nshow : bool\n    Whether to show the figure. Defaults to ``True``.\n%(combine_plot_compare_evokeds)s\n%(sphere_topomap_auto)s\n%(time_unit)s\n\n    .. versionadded:: 1.1\n\nReturns\n-------\nfig : list of Figure instances\n    A list of the figure(s) generated.\n\nNotes\n-----\nIf the parameters ``styles``, ``colors``, or ``linestyles`` are passed as\n:class:`dicts <python:dict>`, then ``evokeds`` must also be a\n:class:`python:dict`, and\nthe keys of the plot-style parameters must either match the keys of\n``evokeds``, or match a ``/``-separated partial key (\"condition\") of\n``evokeds``. For example, if evokeds has keys \"Aud/L\", \"Aud/R\", \"Vis/L\",\nand \"Vis/R\", then ``linestyles=dict(L='--', R='-')`` will plot both Aud/L\nand Vis/L conditions with dashed lines and both Aud/R and Vis/R conditions\nwith solid lines. Similarly, ``colors=dict(Aud='r', Vis='b')`` will plot\nAud/L and Aud/R conditions red and Vis/L and Vis/R conditions blue.\n\nColor specification depends on whether a colormap has been provided in the\n``cmap`` parameter. The following table summarizes how the ``colors``\nparameter is interpreted:\n\n.. cssclass:: table-bordered\n.. rst-class:: midvalign\n\n+-------------+----------------+------------------------------------------+\n| ``cmap``    | ``colors``     | result                                   |\n+=============+================+==========================================+\n|             | None           | matplotlib default color cycle; unique   |\n|             |                | color for each condition                 |\n|             +----------------+------------------------------------------+\n|             |                | matplotlib default color cycle; lowest   |\n|             | list or dict   | integer mapped to first cycle color;     |\n|             | of integers    | conditions with same integer get same    |\n| None        |                | color; unspecified conditions are \"gray\" |\n|             +----------------+------------------------------------------+\n|             | list or dict   | ``ValueError``                           |\n|             | of floats      |                                          |\n|             +----------------+------------------------------------------+\n|             | list or dict   | the specified hex colors; unspecified    |\n|             | of hexadecimal | conditions are \"gray\"                    |\n|             | color strings  |                                          |\n+-------------+----------------+------------------------------------------+\n|             | None           | equally spaced colors on the colormap;   |\n|             |                | unique color for each condition          |\n|             +----------------+------------------------------------------+\n|             |                | equally spaced colors on the colormap;   |\n|             | list or dict   | lowest integer mapped to first cycle     |\n| string or   | of integers    | color; conditions with same integer      |\n| instance of |                | get same color                           |\n| matplotlib  +----------------+------------------------------------------+\n| Colormap    | list or dict   | floats mapped to corresponding colormap  |\n|             | of floats      | values                                   |\n|             +----------------+------------------------------------------+\n|             | list or dict   |                                          |\n|             | of hexadecimal | ``TypeError``                            |\n|             | color strings  |                                          |\n+-------------+----------------+------------------------------------------+", "metadata": {}}
{"_id": "mne_mne_viz/evoked.py_whitened_gfp_doc", "text": "Whitened Global Field Power.\n\nThe MNE inverse solver assumes zero mean whitened data as input.\nTherefore, a chi^2 statistic will be best to detect model violations.", "metadata": {}}
{"_id": "mne_mne_viz/evoked_field.py_set_time_doc", "text": "Set the time to display (in seconds).\n\nParameters\n----------\ntime : float\n    The time to show, in seconds.", "metadata": {}}
{"_id": "mne_mne_viz/evoked_field.py_set_contours_doc", "text": "Adjust the number of contour lines to use when drawing the fieldlines.\n\nParameters\n----------\nn_contours : int\n    The number of contour lines to use.", "metadata": {}}
{"_id": "mne_mne_viz/evoked_field.py_set_vmax_doc", "text": "Change the color range of the density maps.\n\nParameters\n----------\nvmax : float\n    The new maximum value of the color range.\nkind : 'meg' | 'eeg'\n    Which field map to apply the new color range to.", "metadata": {}}
{"_id": "mne_mne_viz/misc.py_plot_cov_doc", "text": "Plot Covariance data.\n\nParameters\n----------\ncov : instance of Covariance\n    The covariance matrix.\n%(info_not_none)s\nexclude : list of str | str\n    List of channels to exclude. If empty do not exclude any channel.\n    If 'bads', exclude info['bads'].\ncolorbar : bool\n    Show colorbar or not.\nproj : bool\n    Apply projections or not.\nshow_svd : bool\n    Plot also singular values of the noise covariance for each sensor\n    type. We show square roots ie. standard deviations.\nshow : bool\n    Show figure if True.\n%(verbose)s\n\nReturns\n-------\nfig_cov : instance of matplotlib.figure.Figure\n    The covariance plot.\nfig_svd : instance of matplotlib.figure.Figure | None\n    The SVD plot of the covariance (i.e., the eigenvalues or \"matrix spectrum\").\n\nSee Also\n--------\nmne.compute_rank\n\nNotes\n-----\nFor each channel type, the rank is estimated using\n:func:`mne.compute_rank`.\n\n.. versionchanged:: 0.19\n   Approximate ranks for each channel type are shown with red dashed lines.", "metadata": {}}
{"_id": "mne_mne_viz/misc.py_plot_source_spectrogram_doc", "text": "Plot source power in time-freqency grid.\n\nParameters\n----------\nstcs : list of SourceEstimate\n    Source power for consecutive time windows, one SourceEstimate object\n    should be provided for each frequency bin.\nfreq_bins : list of tuples of float\n    Start and end points of frequency bins of interest.\ntmin : float\n    Minimum time instant to show.\ntmax : float\n    Maximum time instant to show.\nsource_index : int | None\n    Index of source for which the spectrogram will be plotted. If None,\n    the source with the largest activation will be selected.\ncolorbar : bool\n    If true, a colorbar will be added to the plot.\nshow : bool\n    Show figure if True.\n\nReturns\n-------\nfig : instance of Figure\n    The figure.", "metadata": {}}
{"_id": "mne_mne_viz/misc.py_plot_bem_doc", "text": "Plot BEM contours on anatomical MRI slices.\n\nParameters\n----------\n%(subject)s\n%(subjects_dir)s\norientation : str\n    'coronal' or 'axial' or 'sagittal'.\nslices : list of int | None\n    The indices of the MRI slices to plot. If ``None``, automatically\n    pick 12 equally-spaced slices.\nbrain_surfaces : str | list of str | None\n    One or more brain surface to plot (optional). Entries should correspond\n    to files in the subject's ``surf`` directory (e.g. ``\"white\"``).\nsrc : SourceSpaces | path-like | None\n    SourceSpaces instance or path to a source space to plot individual\n    sources as scatter-plot. Sources will be shown on exactly one slice\n    (whichever slice is closest to each source in the given orientation\n    plane). Path can be absolute or relative to the subject's ``bem``\n    folder.\n\n    .. versionchanged:: 0.20\n       All sources are shown on the nearest slice rather than some\n       being omitted.\nshow : bool\n    Show figure if True.\nshow_indices : bool\n    Show slice indices if True.\n\n    .. versionadded:: 0.20\nmri : str\n    The name of the MRI to use. Can be a standard FreeSurfer MRI such as\n    ``'T1.mgz'``, or a full path to a custom MRI file.\n\n    .. versionadded:: 0.21\nshow_orientation : bool | str\n    Show the orientation (L/R, P/A, I/S) of the data slices.\n    True (default) will only show it on the outside most edges of the\n    figure, False will never show labels, and \"always\" will label each\n    plot.\n\n    .. versionadded:: 0.21\n    .. versionchanged:: 0.24\n       Added support for \"always\".\n\nReturns\n-------\nfig : instance of matplotlib.figure.Figure\n    The figure.\n\nSee Also\n--------\nmne.viz.plot_alignment\n\nNotes\n-----\nImages are plotted in MRI voxel coordinates.\n\nIf ``src`` is not None, for a given slice index, all source points are\nshown that are halfway between the previous slice and the given slice,\nand halfway between the given slice and the next slice.\nFor large slice decimations, this can\nmake some source points appear outside the BEM contour, which is shown\nfor the given slice index. For example, in the case where the single\nmidpoint slice is used ``slices=[128]``, all source points will be shown\non top of the midpoint MRI slice with the BEM boundary drawn for that\nslice.", "metadata": {}}
{"_id": "mne_mne_viz/misc.py_plot_events_doc", "text": "Plot :term:`events` to get a visual display of the paradigm.\n\nParameters\n----------\n%(events)s\nsfreq : float | None\n    The sample frequency. If None, data will be displayed in samples (not\n    seconds).\nfirst_samp : int\n    The index of the first sample. Recordings made on Neuromag systems\n    number samples relative to the system start (not relative to the\n    beginning of the recording). In such cases the ``raw.first_samp``\n    attribute can be passed here. Default is 0.\ncolor : dict | None\n    Dictionary of event_id integers as keys and colors as values. If None,\n    colors are automatically drawn from a default list (cycled through if\n    number of events longer than list of default colors). Color can be any\n    valid :ref:`matplotlib color <matplotlib:colors_def>`.\nevent_id : dict | None\n    Dictionary of event labels (e.g. 'aud_l') as keys and their associated\n    event_id values. Labels are used to plot a legend. If None, no legend\n    is drawn.\naxes : instance of Axes\n   The subplot handle.\nequal_spacing : bool\n    Use equal spacing between events in y-axis.\nshow : bool\n    Show figure if True.\n%(on_missing_events)s\n%(verbose)s\n\nReturns\n-------\nfig : matplotlib.figure.Figure\n    The figure object containing the plot.\n\nNotes\n-----\n.. versionadded:: 0.9.0", "metadata": {}}
{"_id": "mne_mne_viz/misc.py_plot_dipole_amplitudes_doc", "text": "Plot the amplitude traces of a set of dipoles.\n\nParameters\n----------\ndipoles : list of instance of Dipole\n    The dipoles whose amplitudes should be shown.\ncolors : list of color | None\n    Color to plot with each dipole. If None default colors are used.\nshow : bool\n    Show figure if True.\n\nReturns\n-------\nfig : matplotlib.figure.Figure\n    The figure object containing the plot.\n\nNotes\n-----\n.. versionadded:: 0.9.0", "metadata": {}}
{"_id": "mne_mne_viz/misc.py_adjust_axes_doc", "text": "Adjust some properties of axes.\n\nParameters\n----------\naxes : list\n    List of axes to process.\nremove_spines : list of str\n    Which axis spines to remove.\ngrid : bool\n    Turn grid on (True) or off (False).", "metadata": {}}
{"_id": "mne_mne_viz/misc.py_plot_filter_doc", "text": "Plot properties of a filter.\n\nParameters\n----------\nh : dict or ndarray\n    An IIR dict or 1D ndarray of coefficients (for FIR filter).\nsfreq : float\n    Sample rate of the data (Hz).\nfreq : array-like or None\n    The ideal response frequencies to plot (must be in ascending order).\n    If None (default), do not plot the ideal response.\ngain : array-like or None\n    The ideal response gains to plot.\n    If None (default), do not plot the ideal response.\ntitle : str | None\n    The title to use. If None (default), determine the title based\n    on the type of the system.\ncolor : color object\n    The color to use (default '#1f77b4').\nflim : tuple or None\n    If not None, the x-axis frequency limits (Hz) to use.\n    If None, freq will be used. If None (default) and freq is None,\n    ``(0.1, sfreq / 2.)`` will be used.\nfscale : str\n    Frequency scaling to use, can be \"log\" (default) or \"linear\".\nalim : tuple\n    The y-axis amplitude limits (dB) to use (default: (-60, 10)).\nshow : bool\n    Show figure if True (default).\ncompensate : bool\n    If True, compensate for the filter delay (phase will not be shown).\n\n    - For linear-phase FIR filters, this visualizes the filter coefficients\n      assuming that the output will be shifted by ``N // 2``.\n    - For IIR filters, this changes the filter coefficient display\n      by filtering backward and forward, and the frequency response\n      by squaring it.\n\n    .. versionadded:: 0.18\nplot : list | tuple | str\n    A list of the requested plots from ``time``, ``magnitude`` and\n    ``delay``. Default is to plot all three filter properties\n    ('time', 'magnitude', 'delay').\n\n    .. versionadded:: 0.21.0\naxes : instance of Axes | list | None\n    The axes to plot to. If list, the list must be a list of Axes of\n    the same length as the number of requested plot types. If instance of\n    Axes, there must be only one filter property plotted.\n    Defaults to ``None``.\n\n    .. versionadded:: 0.21.0\ndlim : None | tuple\n    The y-axis delay limits (s) to use (default:\n    ``(-tmax / 2., tmax / 2.)``).\n\n    .. versionadded:: 1.1.0\n\nReturns\n-------\nfig : matplotlib.figure.Figure\n    The figure containing the plots.\n\nSee Also\n--------\nmne.filter.create_filter\nplot_ideal_filter\n\nNotes\n-----\n.. versionadded:: 0.14", "metadata": {}}
{"_id": "mne_mne_viz/misc.py_plot_ideal_filter_doc", "text": "Plot an ideal filter response.\n\nParameters\n----------\nfreq : array-like\n    The ideal response frequencies to plot (must be in ascending order).\ngain : array-like or None\n    The ideal response gains to plot.\naxes : instance of Axes | None\n    The subplot handle. With None (default), axes are created.\ntitle : str\n    The title to use, (default: '').\nflim : tuple or None\n    If not None, the x-axis frequency limits (Hz) to use.\n    If None (default), freq used.\nfscale : str\n    Frequency scaling to use, can be \"log\" (default) or \"linear\".\nalim : tuple\n    If not None (default), the y-axis limits (dB) to use.\ncolor : color object\n    The color to use (default: 'r').\nalpha : float\n    The alpha to use (default: 0.5).\nlinestyle : str\n    The line style to use (default: '--').\nshow : bool\n    Show figure if True (default).\n\nReturns\n-------\nfig : instance of matplotlib.figure.Figure\n    The figure.\n\nSee Also\n--------\nplot_filter\n\nNotes\n-----\n.. versionadded:: 0.14\n\nExamples\n--------\nPlot a simple ideal band-pass filter::\n\n    >>> from mne.viz import plot_ideal_filter\n    >>> freq = [0, 1, 40, 50]\n    >>> gain = [0, 1, 1, 0]\n    >>> plot_ideal_filter(freq, gain, flim=(0.1, 100))  #doctest: +SKIP\n    <...Figure...>", "metadata": {}}
{"_id": "mne_mne_viz/misc.py_plot_csd_doc", "text": "Plot CSD matrices.\n\nA sub-plot is created for each frequency. If an info object is passed to\nthe function, different channel types are plotted in different figures.\n\nParameters\n----------\ncsd : instance of CrossSpectralDensity\n    The CSD matrix to plot.\n%(info)s\n    Used to split the figure by channel-type, if provided.\n    By default, the CSD matrix is plotted as a whole.\nmode : 'csd' | 'coh'\n    Whether to plot the cross-spectral density ('csd', the default), or\n    the coherence ('coh') between the channels.\ncolorbar : bool\n    Whether to show a colorbar. Defaults to ``True``.\ncmap : str | None\n    The matplotlib colormap to use. Defaults to None, which means the\n    colormap will default to matplotlib's default.\nn_cols : int | None\n    CSD matrices are plotted in a grid. This parameter controls how\n    many matrix to plot side by side before starting a new row. By\n    default, a number will be chosen to make the grid as square as\n    possible.\nshow : bool\n    Whether to show the figure. Defaults to ``True``.\n\nReturns\n-------\nfig : list of Figure\n    The figures created by this function.", "metadata": {}}
{"_id": "mne_mne_viz/misc.py_plot_chpi_snr_doc", "text": "Plot time-varying SNR estimates of the HPI coils.\n\nParameters\n----------\nsnr_dict : dict\n    The dictionary returned by `~mne.chpi.compute_chpi_snr`. Must have keys\n    ``times``, ``freqs``, ``TYPE_snr``, ``TYPE_power``, and ``TYPE_resid``\n    (where ``TYPE`` can be ``mag`` or ``grad`` or both).\naxes : None | list of matplotlib.axes.Axes\n    Figure axes in which to draw the SNR, power, and residual plots. The\n    number of axes should be 3\u00d7 the number of MEG sensor types present in\n    ``snr_dict``. If ``None`` (the default), a new\n    `~matplotlib.figure.Figure` is created with the required number of\n    axes.\n\nReturns\n-------\nfig : instance of matplotlib.figure.Figure\n    A figure with subplots for SNR, power, and residual variance,\n    separately for magnetometers and/or gradiometers (depending on what is\n    present in ``snr_dict``).\n\nNotes\n-----\nIf you supply a list of existing `~matplotlib.axes.Axes`, then the figure\nlegend will not be drawn automatically. If you still want it, running\n``fig.legend(loc='right', title='cHPI frequencies')`` will recreate it.\n\n.. versionadded:: 0.24", "metadata": {}}
{"_id": "mne_mne_viz/topomap.py_plot_projs_topomap_doc", "text": "Plot topographic maps of SSP projections.\n\nParameters\n----------\nprojs : list of Projection\n    The projections.\n%(info_not_none)s Must be associated with the channels in the projectors.\n\n    .. versionchanged:: 0.20\n        The positional argument ``layout`` was replaced by ``info``.\n%(sensors_topomap)s\n%(show_names_topomap)s\n\n    .. versionadded:: 1.2\n%(contours_topomap)s\n%(outlines_topomap)s\n%(sphere_topomap_auto)s\n%(image_interp_topomap)s\n%(extrapolate_topomap)s\n\n    .. versionadded:: 0.20\n\n    .. versionchanged:: 0.21\n\n       - The default was changed to ``'local'`` for MEG sensors.\n       - ``'local'`` was changed to use a convex hull mask\n       - ``'head'`` was changed to extrapolate out to the clipping circle.\n%(border_topomap)s\n\n    .. versionadded:: 0.20\n%(res_topomap)s\n%(size_topomap)s\n%(cmap_topomap)s\n%(vlim_plot_topomap_proj)s\n%(cnorm)s\n\n    .. versionadded:: 1.2\n%(colorbar_topomap)s\n%(cbar_fmt_topomap)s\n\n    .. versionadded:: 1.2\n%(units_topomap)s\n\n    .. versionadded:: 1.2\n%(axes_plot_projs_topomap)s\n%(show)s\n\nReturns\n-------\nfig : instance of matplotlib.figure.Figure\n    Figure with a topomap subplot for each projector.\n\nNotes\n-----\n.. versionadded:: 0.9.0", "metadata": {}}
{"_id": "mne_mne_viz/topomap.py_plot_topomap_doc", "text": "Plot a topographic map as image.\n\nParameters\n----------\ndata : array, shape (n_chan,)\n    The data values to plot.\n%(pos_topomap)s\n    If an :class:`~mne.Info` object it must contain only one channel type\n    and exactly ``len(data)`` channels; the x/y coordinates will\n    be inferred from the montage in the :class:`~mne.Info` object.\n%(ch_type_topomap)s\n\n    .. versionadded:: 0.21\n%(sensors_topomap)s\n%(names_topomap)s\n%(mask_topomap)s\n%(mask_params_topomap)s\n%(contours_topomap)s\n%(outlines_topomap)s\n%(sphere_topomap_auto)s\n%(image_interp_topomap)s\n%(extrapolate_topomap)s\n\n    .. versionadded:: 0.18\n\n    .. versionchanged:: 0.21\n\n       - The default was changed to ``'local'`` for MEG sensors.\n       - ``'local'`` was changed to use a convex hull mask\n       - ``'head'`` was changed to extrapolate out to the clipping circle.\n%(border_topomap)s\n\n    .. versionadded:: 0.20\n%(res_topomap)s\n%(size_topomap)s\n%(cmap_topomap)s\n%(vlim_plot_topomap)s\n\n    .. versionadded:: 1.2\n%(cnorm)s\n\n    .. versionadded:: 0.24\n%(axes_plot_topomap)s\n\n    .. versionchanged:: 1.2\n       If ``axes=None``, a new :class:`~matplotlib.figure.Figure` is\n       created instead of plotting into the current axes.\n%(show)s\nonselect : callable | None\n    A function to be called when the user selects a set of channels by\n    click-dragging (uses a matplotlib\n    :class:`~matplotlib.widgets.RectangleSelector`). If ``None``\n    interactive channel selection is disabled. Defaults to ``None``.\n\nReturns\n-------\nim : matplotlib.image.AxesImage\n    The interpolated data.\ncn : matplotlib.contour.ContourSet\n    The fieldlines.", "metadata": {}}
{"_id": "mne_mne_viz/topomap.py_plot_ica_components_doc", "text": "Project mixing matrix on interpolated sensor topography.\n\nParameters\n----------\nica : instance of mne.preprocessing.ICA\n    The ICA solution.\n%(picks_ica)s\n%(ch_type_topomap)s\ninst : Raw | Epochs | None\n    To be able to see component properties after clicking on component\n    topomap you need to pass relevant data - instances of Raw or Epochs\n    (for example the data that ICA was trained on). This takes effect\n    only when running matplotlib in interactive mode.\nplot_std : bool | float\n    Whether to plot standard deviation in ERP/ERF and spectrum plots.\n    Defaults to True, which plots one standard deviation above/below.\n    If set to float allows to control how many standard deviations are\n    plotted. For example 2.5 will plot 2.5 standard deviation above/below.\nreject : ``'auto'`` | dict | None\n    Allows to specify rejection parameters used to drop epochs\n    (or segments if continuous signal is passed as inst).\n    If None, no rejection is applied. The default is 'auto',\n    which applies the rejection parameters used when fitting\n    the ICA object.\n%(sensors_topomap)s\n%(show_names_topomap)s\n%(contours_topomap)s\n%(outlines_topomap)s\n%(sphere_topomap_auto)s\n%(image_interp_topomap)s\n%(extrapolate_topomap)s\n\n    .. versionadded:: 1.3\n%(border_topomap)s\n\n    .. versionadded:: 1.3\n%(res_topomap)s\n%(size_topomap)s\n\n    .. versionadded:: 1.3\n%(cmap_topomap)s\n%(vlim_plot_topomap)s\n\n    .. versionadded:: 1.3\n%(cnorm)s\n\n    .. versionadded:: 1.3\n%(colorbar_topomap)s\n%(cbar_fmt_topomap)s\naxes : Axes | array of Axes | None\n    The subplot(s) to plot to. Either a single Axes or an iterable of Axes\n    if more than one subplot is needed. The number of subplots must match\n    the number of selected components. If None, new figures will be created\n    with the number of subplots per figure controlled by ``nrows`` and\n    ``ncols``.\ntitle : str | None\n    The title of the generated figure. If ``None`` (default) and\n    ``axes=None``, a default title of \"ICA Components\" will be used.\n%(nrows_ncols_ica_components)s\n\n    .. versionadded:: 1.3\n%(show)s\nimage_args : dict | None\n    Dictionary of arguments to pass to :func:`~mne.viz.plot_epochs_image`\n    in interactive mode. Ignored if ``inst`` is not supplied. If ``None``,\n    nothing is passed. Defaults to ``None``.\npsd_args : dict | None\n    Dictionary of arguments to pass to :meth:`~mne.Epochs.compute_psd` in\n    interactive  mode. Ignored if ``inst`` is not supplied. If ``None``,\n    nothing is passed. Defaults to ``None``.\n%(verbose)s\n\nReturns\n-------\nfig : instance of matplotlib.figure.Figure | list of matplotlib.figure.Figure\n    The figure object(s).\n\nNotes\n-----\nWhen run in interactive mode, ``plot_ica_components`` allows to reject\ncomponents by clicking on their title label. The state of each component\nis indicated by its label color (gray: rejected; black: retained). It is\nalso possible to open component properties by clicking on the component\ntopomap (this option is only available when the ``inst`` argument is\nsupplied).", "metadata": {}}
{"_id": "mne_mne_viz/topomap.py_plot_tfr_topomap_doc", "text": "Plot topographic maps of specific time-frequency intervals of TFR data.\n\nParameters\n----------\ntfr : AverageTFR\n    The AverageTFR object.\n%(tmin_tmax_psd)s\n%(fmin_fmax_psd)s\n%(ch_type_topomap_psd)s\nbaseline : tuple or list of length 2\n    The time interval to apply rescaling / baseline correction. If None do\n    not apply it. If baseline is (a, b) the interval is between \"a (s)\" and\n    \"b (s)\". If a is None the beginning of the data is used and if b is\n    None then b is set to the end of the interval. If baseline is equal to\n    (None, None) the whole time interval is used.\nmode : 'mean' | 'ratio' | 'logratio' | 'percent' | 'zscore' | 'zlogratio' | None\n    Perform baseline correction by\n\n      - subtracting the mean baseline power ('mean')\n      - dividing by the mean baseline power ('ratio')\n      - dividing by the mean baseline power and taking the log ('logratio')\n      - subtracting the mean baseline power followed by dividing by the\n        mean baseline power ('percent')\n      - subtracting the mean baseline power and dividing by the standard\n        deviation of the baseline power ('zscore')\n      - dividing by the mean baseline power, taking the log, and dividing\n        by the standard deviation of the baseline power ('zlogratio')\n\n    If None no baseline correction is applied.\n%(sensors_topomap)s\n%(show_names_topomap)s\n%(mask_evoked_topomap)s\n%(mask_params_topomap)s\n%(contours_topomap)s\n%(outlines_topomap)s\n%(sphere_topomap_auto)s\n%(image_interp_topomap)s\n%(extrapolate_topomap)s\n\n    .. versionchanged:: 0.21\n\n       - The default was changed to ``'local'`` for MEG sensors.\n       - ``'local'`` was changed to use a convex hull mask\n       - ``'head'`` was changed to extrapolate out to the clipping circle.\n%(border_topomap)s\n\n    .. versionadded:: 0.20\n%(res_topomap)s\n%(size_topomap)s\n%(cmap_topomap)s\n%(vlim_plot_topomap)s\n\n    .. versionadded:: 1.2\n%(cnorm)s\n\n    .. versionadded:: 1.2\n%(colorbar_topomap)s\n%(cbar_fmt_topomap)s\n%(units_topomap)s\n%(axes_plot_topomap)s\n%(show)s\n\nReturns\n-------\nfig : matplotlib.figure.Figure\n    The figure containing the topography.", "metadata": {}}
{"_id": "mne_mne_viz/topomap.py_plot_evoked_topomap_doc", "text": "Plot topographic maps of specific time points of evoked data.\n\nParameters\n----------\nevoked : Evoked\n    The Evoked object.\ntimes : float | array of float | \"auto\" | \"peaks\" | \"interactive\"\n    The time point(s) to plot. If \"auto\", the number of ``axes`` determines\n    the amount of time point(s). If ``axes`` is also None, at most 10\n    topographies will be shown with a regular time spacing between the\n    first and last time instant. If \"peaks\", finds time points\n    automatically by checking for local maxima in global field power. If\n    \"interactive\", the time can be set interactively at run-time by using a\n    slider.\n%(average_plot_evoked_topomap)s\n%(ch_type_topomap)s\n%(scalings_topomap)s\n%(proj_plot)s\n%(sensors_topomap)s\n%(show_names_topomap)s\n%(mask_evoked_topomap)s\n%(mask_params_topomap)s\n%(contours_topomap)s\n%(outlines_topomap)s\n%(sphere_topomap_auto)s\n%(image_interp_topomap)s\n%(extrapolate_topomap)s\n\n    .. versionadded:: 0.18\n\n    .. versionchanged:: 0.21\n\n       - The default was changed to ``'local'`` for MEG sensors.\n       - ``'local'`` was changed to use a convex hull mask\n       - ``'head'`` was changed to extrapolate out to the clipping circle.\n%(border_topomap)s\n\n    .. versionadded:: 0.20\n%(res_topomap)s\n%(size_topomap)s\n%(cmap_topomap)s\n%(vlim_plot_topomap_psd)s\n\n    .. versionadded:: 1.2\n%(cnorm)s\n\n    .. versionadded:: 1.2\n%(colorbar_topomap)s\n%(cbar_fmt_topomap)s\n%(units_topomap_evoked)s\n%(axes_evoked_plot_topomap)s\ntime_unit : str\n    The units for the time axis, can be \"ms\" or \"s\" (default).\n\n    .. versionadded:: 0.16\ntime_format : str | None\n    String format for topomap values. Defaults (None) to \"%%01d ms\" if\n    ``time_unit='ms'``, \"%%0.3f s\" if ``time_unit='s'``, and\n    \"%%g\" otherwise. Can be an empty string to omit the time label.\n%(nrows_ncols_topomap)s Ignored when times == 'interactive'.\n\n    .. versionadded:: 0.20\n%(show)s\n\nReturns\n-------\nfig : instance of matplotlib.figure.Figure\n   The figure.\n\nNotes\n-----\nWhen existing ``axes`` are provided and ``colorbar=True``, note that the\ncolorbar scale will only accurately reflect topomaps that are generated in\nthe same call as the colorbar. Note also that the colorbar will not be\nresized automatically when ``axes`` are provided; use Matplotlib's\n:meth:`axes.set_position() <matplotlib.axes.Axes.set_position>` method or\n:ref:`gridspec <matplotlib:arranging_axes>` interface to adjust the colorbar\nsize yourself.\n\nThe defaults for ``contours`` and ``vlim`` are handled as follows:\n\n* When neither ``vlim`` nor a list of ``contours`` is passed, MNE sets\n  ``vlim`` at \u00b1 the maximum absolute value of the data and then chooses\n  contours within those bounds.\n\n* When ``vlim`` but not a list of ``contours`` is passed, MNE chooses\n  contours to be within the ``vlim``.\n\n* When a list of ``contours`` but not ``vlim`` is passed, MNE chooses\n  ``vlim`` to encompass the ``contours`` and the maximum absolute value of the\n  data.\n\n* When both a list of ``contours`` and ``vlim`` are passed, MNE uses them\n  as-is.\n\nWhen ``time==\"interactive\"``, the figure will publish and subscribe to the\nfollowing UI events:\n\n* :class:`~mne.viz.ui_events.TimeChange` whenever a new time is selected.", "metadata": {}}
{"_id": "mne_mne_viz/topomap.py_plot_epochs_psd_topomap_doc", "text": "Plot the topomap of the power spectral density across epochs.\n\nParameters\n----------\nepochs : instance of Epochs\n    The epochs object.\n%(bands_psd_topo)s\n%(tmin_tmax_psd)s\n%(proj_psd)s\nbandwidth : float\n    The bandwidth of the multi taper windowing function in Hz. The default\n    value is a window half-bandwidth of 4 Hz.\nadaptive : bool\n    Use adaptive weights to combine the tapered spectra into PSD\n    (slow, use n_jobs >> 1 to speed up computation).\nlow_bias : bool\n    Only use tapers with more than 90%% spectral concentration within\n    bandwidth.\n%(normalization)s\n%(ch_type_topomap_psd)s\n%(normalize_psd_topo)s\n%(agg_fun_psd_topo)s\n%(dB_plot_topomap)s\n%(sensors_topomap)s\n%(names_topomap)s\n%(mask_evoked_topomap)s\n%(mask_params_topomap)s\n%(contours_topomap)s\n%(outlines_topomap)s\n%(sphere_topomap_auto)s\n%(image_interp_topomap)s\n%(extrapolate_topomap)s\n\n    .. versionchanged:: 0.21\n\n       - The default was changed to ``'local'`` for MEG sensors.\n       - ``'local'`` was changed to use a convex hull mask\n       - ``'head'`` was changed to extrapolate out to the clipping circle.\n%(border_topomap)s\n\n    .. versionadded:: 0.20\n%(res_topomap)s\n%(size_topomap)s\n%(cmap_topomap)s\n%(vlim_plot_topomap_psd)s\n\n    .. versionadded:: 0.21\n%(cnorm)s\n\n    .. versionadded:: 1.2\n%(colorbar_topomap)s\n%(cbar_fmt_topomap_psd)s\n%(units_topomap)s\n%(axes_spectrum_plot_topomap)s\n%(show)s\n%(n_jobs)s\n%(verbose)s\n\nReturns\n-------\nfig : instance of Figure\n    Figure showing one scalp topography per frequency band.", "metadata": {}}
{"_id": "mne_mne_viz/topomap.py_plot_psds_topomap_doc", "text": "Plot spatial maps of PSDs.\n\nParameters\n----------\npsds : array of float, shape (n_channels, n_freqs)\n    Power spectral densities.\nfreqs : array of float, shape (n_freqs,)\n    Frequencies used to compute psds.\n%(pos_topomap_psd)s\n%(bands_psd_topo)s\n%(ch_type_topomap)s\n%(normalize_psd_topo)s\n%(agg_fun_psd_topo)s\n%(dB_plot_topomap)s\n%(sensors_topomap)s\n%(names_topomap)s\n%(mask_evoked_topomap)s\n%(mask_params_topomap)s\n%(contours_topomap)s\n%(outlines_topomap)s\n%(sphere_topomap_auto)s\n%(image_interp_topomap)s\n%(extrapolate_topomap)s\n\n    .. versionchanged:: 0.21\n\n       - The default was changed to ``'local'`` for MEG sensors.\n       - ``'local'`` was changed to use a convex hull mask\n       - ``'head'`` was changed to extrapolate out to the clipping circle.\n%(border_topomap)s\n\n    .. versionadded:: 0.20\n%(res_topomap)s\n%(size_topomap)s\n%(cmap_topomap)s\n%(vlim_plot_topomap_psd)s\n\n    .. versionadded:: 0.21\n%(cnorm)s\n\n    .. versionadded:: 1.2\n%(colorbar_topomap)s\n%(cbar_fmt_topomap_psd)s\nunit : str | None\n    Measurement unit to be displayed with the colorbar. If ``None``, no\n    unit is displayed (only \"power\" or \"dB\" as appropriate).\n%(axes_spectrum_plot_topomap)s\n%(show)s\n\nReturns\n-------\nfig : instance of matplotlib.figure.Figure\n    Figure with a topomap subplot for each band.", "metadata": {}}
{"_id": "mne_mne_viz/topomap.py_plot_layout_doc", "text": "Plot the sensor positions.\n\nParameters\n----------\nlayout : None | Layout\n    Layout instance specifying sensor positions.\n%(picks_layout)s\nshow_axes : bool\n        Show layout axes if True. Defaults to False.\nshow : bool\n    Show figure if True. Defaults to True.\n\nReturns\n-------\nfig : instance of Figure\n    Figure containing the sensor topography.\n\nNotes\n-----\n.. versionadded:: 0.12.0", "metadata": {}}
{"_id": "mne_mne_viz/topomap.py_plot_arrowmap_doc", "text": "Plot arrow map.\n\nCompute arrowmaps, based upon the Hosaka-Cohen transformation\n:footcite:`CohenHosaka1976`, these arrows represents an estimation of the\ncurrent flow underneath the MEG sensors. They are a poor man's MNE.\n\nSince planar gradiometers takes gradients along latitude and longitude,\nthey need to be projected to the flattened manifold span by magnetometer\nor radial gradiometers before taking the gradients in the 2D Cartesian\ncoordinate system for visualization on the 2D topoplot. You can use the\n``info_from`` and ``info_to`` parameters to interpolate from\ngradiometer data to magnetometer data.\n\nParameters\n----------\ndata : array, shape (n_channels,)\n    The data values to plot.\ninfo_from : instance of Info\n    The measurement info from data to interpolate from.\ninfo_to : instance of Info | None\n    The measurement info to interpolate to. If None, it is assumed\n    to be the same as info_from.\nscale : float, default 3e-10\n    To scale the arrows.\n%(vlim_plot_topomap)s\n\n    .. versionadded:: 1.2\n%(cnorm)s\n\n    .. versionadded:: 1.2\n%(cmap_topomap_simple)s\n%(sensors_topomap)s\n%(res_topomap)s\n%(axes_plot_topomap)s\n%(show_names_topomap)s\n    If ``True``, a list of names must be provided (see ``names`` keyword).\n%(mask_topomap)s\n%(mask_params_topomap)s\n%(outlines_topomap)s\n%(contours_topomap)s\n%(image_interp_topomap)s\n%(show)s\nonselect : callable | None\n    Handle for a function that is called when the user selects a set of\n    channels by rectangle selection (matplotlib ``RectangleSelector``). If\n    None interactive selection is disabled. Defaults to None.\n%(extrapolate_topomap)s\n\n    .. versionadded:: 0.18\n\n    .. versionchanged:: 0.21\n\n       - The default was changed to ``'local'`` for MEG sensors.\n       - ``'local'`` was changed to use a convex hull mask\n       - ``'head'`` was changed to extrapolate out to the clipping circle.\n%(sphere_topomap_auto)s\n\nReturns\n-------\nfig : matplotlib.figure.Figure\n    The Figure of the plot.\n\nNotes\n-----\n.. versionadded:: 0.17\n\nReferences\n----------\n.. footbibliography::", "metadata": {}}
{"_id": "mne_mne_viz/topomap.py_plot_bridged_electrodes_doc", "text": "Topoplot electrode distance matrix with bridged electrodes connected.\n\nParameters\n----------\n%(info_not_none)s\nbridged_idx : list of tuple\n    The indices of channels marked as bridged with each bridged\n    pair stored as a tuple.\n    Can be generated via\n    :func:`mne.preprocessing.compute_bridged_electrodes`.\ned_matrix : array of float, shape (n_channels, n_channels)\n    The electrical distance matrix for each pair of EEG electrodes.\n    Can be generated via\n    :func:`mne.preprocessing.compute_bridged_electrodes`.\ntitle : str\n    A title to add to the plot.\ntopomap_args : dict | None\n    Arguments to pass to :func:`mne.viz.plot_topomap`.\n\nReturns\n-------\nfig : instance of matplotlib.figure.Figure\n    The topoplot figure handle.\n\nSee Also\n--------\nmne.preprocessing.compute_bridged_electrodes", "metadata": {}}
{"_id": "mne_mne_viz/topomap.py_plot_ch_adjacency_doc", "text": "Plot channel adjacency.\n\nParameters\n----------\ninfo : instance of Info\n    Info object with channel locations.\nadjacency : array\n    Array of channels x channels shape. Defines which channels are adjacent\n    to each other. Note that if you edit adjacencies\n    (via ``edit=True``), this array will be modified in place.\nch_names : list of str\n    Names of successive channels in the ``adjacency`` matrix.\nkind : str\n    How to plot the adjacency. Can be either ``'3d'`` or ``'2d'``.\nedit : bool\n    Whether to allow interactive editing of the adjacency matrix via\n    clicking respective channel pairs. Once clicked, the channel is\n    \"activated\" and turns green. Clicking on another channel adds or\n    removes adjacency relation between the activated and newly clicked\n    channel (depending on whether the channels are already adjacent or\n    not); the newly clicked channel now becomes activated. Clicking on\n    an activated channel deactivates it. Editing is currently only\n    supported for ``kind='2d'``.\n\nReturns\n-------\nfig : Figure\n    The :class:`~matplotlib.figure.Figure` instance where the channel\n    adjacency is plotted.\n\nSee Also\n--------\nmne.channels.get_builtin_ch_adjacencies\nmne.channels.read_ch_adjacency\nmne.channels.find_ch_adjacency\n\nNotes\n-----\n.. versionadded:: 1.1", "metadata": {}}
{"_id": "mne_mne_viz/topomap.py_plot_regression_weights_doc", "text": "Plot the regression weights of a fitted EOGRegression model.\n\nParameters\n----------\nmodel : EOGRegression\n    The fitted EOGRegression model whose weights will be plotted.\n%(ch_type_topomap)s\n%(sensors_topomap)s\n%(show_names_topomap)s\n%(mask_topomap)s\n%(mask_params_topomap)s\n%(contours_topomap)s\n%(outlines_topomap)s\n%(sphere_topomap_auto)s\n%(image_interp_topomap)s\n%(extrapolate_topomap)s\n\n    .. versionchanged:: 0.21\n\n       - The default was changed to ``'local'`` for MEG sensors.\n       - ``'local'`` was changed to use a convex hull mask\n       - ``'head'`` was changed to extrapolate out to the clipping circle.\n%(border_topomap)s\n\n    .. versionadded:: 0.20\n%(res_topomap)s\n%(size_topomap)s\n%(cmap_topomap)s\n%(vlim_plot_topomap)s\n%(cnorm)s\n%(axes_evoked_plot_topomap)s\n%(colorbar_topomap)s\n%(cbar_fmt_topomap)s\n%(title_none)s\n%(show)s\n\nReturns\n-------\nfig : instance of matplotlib.figure.Figure\n    Figure with a topomap subplot for each channel type.\n\nNotes\n-----\n.. versionadded:: 1.2", "metadata": {}}
{"_id": "mne_mne_viz/topomap.py_set_values_doc", "text": "Set the values at interpolation points.", "metadata": {}}
{"_id": "mne_mne_viz/topomap.py_set_locations_doc", "text": "Set locations for easier (delayed) calling.", "metadata": {}}
{"_id": "mne_mne_viz/utils.py_safe_event_doc", "text": "Protect against Qt exiting on event-handling errors.", "metadata": {}}
{"_id": "mne_mne_viz/utils.py_plt_show_doc", "text": "Show a figure while suppressing warnings.\n\nParameters\n----------\nshow : bool\n    Show the figure.\nfig : instance of Figure | None\n    If non-None, use fig.show().\n**kwargs : dict\n    Extra arguments for :func:`matplotlib.pyplot.show`.", "metadata": {}}
{"_id": "mne_mne_viz/utils.py_mne_analyze_colormap_doc", "text": "Return a colormap similar to that used by mne_analyze.\n\nParameters\n----------\nlimits : array-like of length 3 or 6\n    Bounds for the colormap, which will be mirrored across zero if length\n    3, or completely specified (and potentially asymmetric) if length 6.\nformat : str\n    Type of colormap to return. If 'matplotlib', will return a\n    matplotlib.colors.LinearSegmentedColormap. If 'vtk', will\n    return an RGBA array of shape (256, 4).\n\nReturns\n-------\ncmap : instance of colormap | array\n    A teal->blue->gray->red->yellow colormap. See docstring of the 'format'\n    argument for further details.\n\nNotes\n-----\nFor this will return a colormap that will display correctly for data\nthat are scaled by the plotting function to span [-fmax, fmax].", "metadata": {}}
{"_id": "mne_mne_viz/utils.py_compare_fiff_doc", "text": "Compare the contents of two fiff files using diff and show_fiff.\n\nParameters\n----------\nfname_1 : path-like\n    First file to compare.\nfname_2 : path-like\n    Second file to compare.\nfname_out : path-like | None\n    Filename to store the resulting diff. If None, a temporary\n    file will be created.\nshow : bool\n    If True, show the resulting diff in a new tab in a web browser.\nindent : str\n    How to indent the lines.\nread_limit : int\n    Max number of bytes of data to read from a tag. Can be np.inf\n    to always read all data (helps test read completion).\nmax_str : int\n    Max number of characters of string representation to print for\n    each tag's data.\n%(verbose)s\n\nReturns\n-------\nfname_out : str\n    The filename used for storing the diff. Could be useful for\n    when a temporary file is used.", "metadata": {}}
{"_id": "mne_mne_viz/utils.py_figure_nobar_doc", "text": "Make matplotlib figure with no toolbar.\n\nParameters\n----------\n*args : list\n    Arguments to pass to :func:`matplotlib.pyplot.figure`.\n**kwargs : dict\n    Keyword arguments to pass to :func:`matplotlib.pyplot.figure`.\n\nReturns\n-------\nfig : instance of Figure\n    The figure.", "metadata": {}}
{"_id": "mne_mne_viz/utils.py_add_background_image_doc", "text": "Add a background image to a plot.\n\nAdds the image specified in ``im`` to the\nfigure ``fig``. This is generally meant to\nbe done with topo plots, though it could work\nfor any plot.\n\n.. note:: This modifies the figure and/or axes in place.\n\nParameters\n----------\nfig : Figure\n    The figure you wish to add a bg image to.\nim : array, shape (M, N, {3, 4})\n    A background image for the figure. This must be a valid input to\n    `matplotlib.pyplot.imshow`. Defaults to None.\nset_ratios : None | str\n    Set the aspect ratio of any axes in fig\n    to the value in set_ratios. Defaults to None,\n    which does nothing to axes.\n\nReturns\n-------\nax_im : instance of Axes\n    Axes created corresponding to the image you added.\n\nNotes\n-----\n.. versionadded:: 0.9.0", "metadata": {}}
{"_id": "mne_mne_viz/utils.py_plot_sensors_doc", "text": "Plot sensors positions.\n\nParameters\n----------\n%(info_not_none)s\nkind : str\n    Whether to plot the sensors as 3d, topomap or as an interactive\n    sensor selection dialog. Available options ``'topomap'``, ``'3d'``,\n    ``'select'``. If ``'select'``, a set of channels can be selected\n    interactively by using lasso selector or clicking while holding the control\n    key. The selected channels are returned along with the figure instance.\n    Defaults to ``'topomap'``.\nch_type : None | str\n    The channel type to plot. Available options ``'mag'``, ``'grad'``,\n    ``'eeg'``, ``'seeg'``, ``'dbs'``, ``'ecog'``, ``'all'``. If ``'all'``,\n    all the available mag, grad, eeg, seeg, dbs and ecog channels are\n    plotted. If None (default), then channels are chosen in the order given\n    above.\ntitle : str | None\n    Title for the figure. If None (default), equals to\n    ``'Sensor positions (%%s)' %% ch_type``.\nshow_names : bool | array of str\n    Whether to display all channel names. If an array, only the channel\n    names in the array are shown. Defaults to False.\nch_groups : 'position' | list of list | None\n    Channel groups for coloring the sensors. If None (default), default\n    coloring scheme is used. If 'position', the sensors are divided\n    into 8 regions. See ``order`` kwarg of :func:`mne.viz.plot_raw`. If\n    array, the channels are divided by picks given in the array. Also\n    accepts a list of lists to allow channel groups of the same or\n    different sizes.\n\n    .. versionadded:: 0.13.0\nto_sphere : bool\n    Whether to project the 3d locations to a sphere. When False, the\n    sensor array appears similar as to looking downwards straight above the\n    subject's head. Has no effect when ``kind='3d'``. Defaults to True.\n\n    .. versionadded:: 0.14.0\n%(axes_montage)s\n\n    .. versionadded:: 0.13.0\nblock : bool\n    Whether to halt program execution until the figure is closed. Defaults\n    to False.\n\n    .. versionadded:: 0.13.0\nshow : bool\n    Show figure if True. Defaults to True.\n%(sphere_topomap_auto)s\npointsize : float | None\n    The size of the points. If None (default), will bet set to ``75`` if\n    ``kind='3d'``, or ``25`` otherwise.\nlinewidth : float\n    The width of the outline. If ``0``, the outline will not be drawn.\ncmap : str | instance of matplotlib.colors.Colormap | None\n    Colormap for coloring ch_groups. Has effect only when ``ch_groups``\n    is list of list. If None, set to ``matplotlib.rcParams[\"image.cmap\"]``.\n    Defaults to None.\n%(verbose)s\n\nReturns\n-------\nfig : instance of Figure\n    Figure containing the sensor topography.\nselection : list\n    A list of selected channels. Only returned if ``kind=='select'``.\n\nSee Also\n--------\nmne.viz.plot_layout\n\nNotes\n-----\nThis function plots the sensor locations from the info structure using\nmatplotlib. For drawing the sensors using PyVista see\n:func:`mne.viz.plot_alignment`.\n\n.. versionadded:: 0.12.0", "metadata": {}}
{"_id": "mne_mne_viz/utils.py_centers_to_edges_doc", "text": "Convert center points to edges.\n\nParameters\n----------\n*arrays : list of ndarray\n    Each input array should be 1D monotonically increasing,\n    and will be cast to float.\n\nReturns\n-------\narrays : list of ndarray\n    Given each input of shape (N,), the output will have shape (N+1,).\n\nExamples\n--------\n>>> x = [0., 0.1, 0.2, 0.3]\n>>> y = [20, 30, 40]\n>>> centers_to_edges(x, y)  # doctest: +SKIP\n[array([-0.05, 0.05, 0.15, 0.25, 0.35]), array([15., 25., 35., 45.])]", "metadata": {}}
{"_id": "mne_mne_viz/utils.py_concatenate_images_doc", "text": "Concatenate a list of images.\n\nParameters\n----------\nimages : list of ndarray\n    The list of images to concatenate.\naxis : 0 or 1\n    The images are concatenated horizontally if 0 and vertically otherwise.\n    The default orientation is horizontal.\nbgcolor : str | list\n    The color of the background. The name of the color is accepted\n    (e.g 'red') or a list of RGB values between 0 and 1. Defaults to\n    'black'.\ncentered : bool\n    If True, the images are centered. Defaults to True.\nn_channels : int\n    Number of color channels. Can be 3 or 4. The default value is 3.\n\nReturns\n-------\nimg : ndarray\n    The concatenated image.", "metadata": {}}
{"_id": "mne_mne_viz/utils.py_onclick_doc", "text": "Handle Mouse clicks.\n\nParameters\n----------\nevent : matplotlib.backend_bases.Event\n    The matplotlib object that we use to get x/y position.", "metadata": {}}
{"_id": "mne_mne_viz/utils.py_plot_clicks_doc", "text": "Plot the x/y positions stored in self.coords.\n\nParameters\n----------\n**kwargs : dict\n    Arguments are passed to imshow in displaying the bg image.", "metadata": {}}
{"_id": "mne_mne_viz/utils.py_to_layout_doc", "text": "Turn coordinates into an MNE Layout object.\n\nNormalizes by the image you used to generate clicks\n\nParameters\n----------\n**kwargs : dict\n    Arguments are passed to generate_2d_layout.\n\nReturns\n-------\nlayout : instance of Layout\n    The layout.", "metadata": {}}
{"_id": "mne_mne_viz/utils.py_connect_doc", "text": "Connect to all the events we need.", "metadata": {}}
{"_id": "mne_mne_viz/utils.py_on_press_doc", "text": "Handle button press.", "metadata": {}}
{"_id": "mne_mne_viz/utils.py_key_press_doc", "text": "Handle key press.", "metadata": {}}
{"_id": "mne_mne_viz/utils.py_on_motion_doc", "text": "Handle mouse movements.", "metadata": {}}
{"_id": "mne_mne_viz/utils.py_on_release_doc", "text": "Handle release.", "metadata": {}}
{"_id": "mne_mne_viz/utils.py_on_scroll_doc", "text": "Handle scroll.", "metadata": {}}
{"_id": "mne_mne_viz/utils.py_notify_doc", "text": "Notify listeners that a selection has been made.", "metadata": {}}
{"_id": "mne_mne_viz/utils.py_on_select_doc", "text": "Select a subset from the collection.", "metadata": {}}
{"_id": "mne_mne_viz/utils.py_select_one_doc", "text": "Select or deselect one sensor.", "metadata": {}}
{"_id": "mne_mne_viz/utils.py_select_many_doc", "text": "Select many sensors using indices (for predefined selections).", "metadata": {}}
{"_id": "mne_mne_viz/utils.py_style_objects_doc", "text": "Style selected sensors as \"active\".", "metadata": {}}
{"_id": "mne_mne_viz/utils.py_disconnect_doc", "text": "Disconnect the lasso selector.", "metadata": {}}
{"_id": "mne_mne_viz/utils.py_set_x_doc", "text": "Repoisition the line.", "metadata": {}}
{"_id": "mne_mne_viz/utils.py_on_press_doc", "text": "Store button press if on top of the line.", "metadata": {}}
{"_id": "mne_mne_viz/utils.py_on_motion_doc", "text": "Move the line on drag.", "metadata": {}}
{"_id": "mne_mne_viz/utils.py_on_release_doc", "text": "Handle release.", "metadata": {}}
{"_id": "mne_mne_viz/utils.py_remove_doc", "text": "Remove the line.", "metadata": {}}
{"_id": "mne_mne_viz/_figure.py_set_browser_backend_doc", "text": "Set the 2D browser backend for MNE.\n\nThe backend will be set as specified and operations will use\nthat backend.\n\nParameters\n----------\nbackend_name : str\n    The 2D browser backend to select. See Notes for the capabilities\n    of each backend (``'qt'``, ``'matplotlib'``). The ``'qt'`` browser\n    requires `mne-qt-browser\n    <https://github.com/mne-tools/mne-qt-browser>`__.\n%(verbose)s\n\nReturns\n-------\nold_backend_name : str | None\n    The old backend that was in use.\n\nNotes\n-----\nThis table shows the capabilities of each backend (\"\u2713\" for full support,\nand \"-\" for partial support):\n\n.. table::\n   :widths: auto\n\n   +--------------------------------------+------------+----+\n   | **2D browser function:**             | matplotlib | qt |\n   +======================================+============+====+\n   | :func:`plot_raw`                     | \u2713          | \u2713  |\n   +--------------------------------------+------------+----+\n   | :func:`plot_epochs`                  | \u2713          | \u2713  |\n   +--------------------------------------+------------+----+\n   | :func:`plot_ica_sources`             | \u2713          | \u2713  |\n   +--------------------------------------+------------+----+\n   +--------------------------------------+------------+----+\n   | **Feature:**                                           |\n   +--------------------------------------+------------+----+\n   | Show Events                          | \u2713          | \u2713  |\n   +--------------------------------------+------------+----+\n   | Add/Edit/Remove Annotations          | \u2713          | \u2713  |\n   +--------------------------------------+------------+----+\n   | Toggle Projections                   | \u2713          | \u2713  |\n   +--------------------------------------+------------+----+\n   | Butterfly Mode                       | \u2713          | \u2713  |\n   +--------------------------------------+------------+----+\n   | Selection Mode                       | \u2713          | \u2713  |\n   +--------------------------------------+------------+----+\n   | Smooth Scrolling                     |            | \u2713  |\n   +--------------------------------------+------------+----+\n   | Overview-Bar (with Z-Score-Mode)     |            | \u2713  |\n   +--------------------------------------+------------+----+\n\n.. versionadded:: 0.24", "metadata": {}}
{"_id": "mne_mne_viz/_figure.py_get_browser_backend_doc", "text": "Return the 2D backend currently used.\n\nReturns\n-------\nbackend_used : str | None\n    The 2D browser backend currently in use. If no backend is found,\n    returns ``None``.", "metadata": {}}
{"_id": "mne_mne_viz/_figure.py_use_browser_backend_doc", "text": "Create a 2D browser visualization context using the designated backend.\n\nSee :func:`mne.viz.set_browser_backend` for more details on the available\n2D browser backends and their capabilities.\n\nParameters\n----------\nbackend_name : {'qt', 'matplotlib'}\n    The 2D browser backend to use in the context.", "metadata": {}}
{"_id": "mne_mne_viz/_figure.py_fake_keypress_doc", "text": "Pass a fake keypress to the figure.\n\nParameters\n----------\nkey : str\n    The key to fake (e.g., ``'a'``).\nfig : instance of Figure\n    The figure to pass the keypress to.", "metadata": {}}
{"_id": "mne_mne_viz/circle.py_circular_layout_doc", "text": "Create layout arranging nodes on a circle.\n\nParameters\n----------\nnode_names : list of str\n    Node names.\nnode_order : list of str\n    List with node names defining the order in which the nodes are\n    arranged. Must have the elements as node_names but the order can be\n    different. The nodes are arranged clockwise starting at \"start_pos\"\n    degrees.\nstart_pos : float\n    Angle in degrees that defines where the first node is plotted.\nstart_between : bool\n    If True, the layout starts with the position between the nodes. This is\n    the same as adding \"180. / len(node_names)\" to start_pos.\ngroup_boundaries : None | array-like\n    List of of boundaries between groups at which point a \"group_sep\" will\n    be inserted. E.g. \"[0, len(node_names) / 2]\" will create two groups.\ngroup_sep : float\n    Group separation angle in degrees. See \"group_boundaries\".\n\nReturns\n-------\nnode_angles : array, shape=(n_node_names,)\n    Node angles in degrees.", "metadata": {}}
{"_id": "mne_mne_viz/circle.py_plot_channel_labels_circle_doc", "text": "Plot labels for each channel in a circle plot.\n\n.. note:: This primarily makes sense for sEEG channels where each\n          channel can be assigned an anatomical label as the electrode\n          passes through various brain areas.\n\nParameters\n----------\nlabels : dict\n    Lists of labels (values) associated with each channel (keys).\ncolors : dict\n    The color (value) for each label (key).\npicks : list | tuple\n    The channels to consider.\n**kwargs : kwargs\n    Keyword arguments for\n    :func:`mne_connectivity.viz.plot_connectivity_circle`.\n\nReturns\n-------\nfig : instance of matplotlib.figure.Figure\n    The figure handle.\naxes : instance of matplotlib.projections.polar.PolarAxes\n    The subplot handle.", "metadata": {}}
{"_id": "mne_mne_viz/_3d.py_plot_head_positions_doc", "text": "Plot head positions.\n\nParameters\n----------\npos : ndarray, shape (n_pos, 10) | list of ndarray\n    The head position data. Can also be a list to treat as a\n    concatenation of runs.\nmode : str\n    Can be 'traces' (default) to show position and quaternion traces,\n    or 'field' to show the position as a vector field over time.\ncmap : colormap\n    Colormap to use for the trace plot, default is \"viridis\".\ndirection : str\n    Can be any combination of \"x\", \"y\", or \"z\" (default: \"z\") to show\n    directional axes in \"field\" mode.\nshow : bool\n    Show figure if True. Defaults to True.\ndestination : path-like | array-like, shape (3,) | instance of Transform | None\n    The destination location for the head. See\n    :func:`mne.preprocessing.maxwell_filter` for details.\n\n    .. versionadded:: 0.16\n%(info)s If provided, will be used to show the destination position when\n    ``destination is None``, and for showing the MEG sensors.\n\n    .. versionadded:: 0.16\ncolor : color object\n    The color to use for lines in ``mode == 'traces'`` and quiver\n    arrows in ``mode == 'field'``.\n\n    .. versionadded:: 0.16\naxes : array-like, shape (3, 2) or (4, 2)\n    The matplotlib axes to use.\n\n    .. versionadded:: 0.16\n    .. versionchanged:: 1.8\n       Added support for making use of this argument when ``mode=\"field\"``.\ntotals : bool\n    If True and in traces mode, show the total distance and angle in a fourth row.\n\n    .. versionadded:: 1.9\n\nReturns\n-------\nfig : instance of matplotlib.figure.Figure\n    The figure.", "metadata": {}}
{"_id": "mne_mne_viz/_3d.py_plot_evoked_field_doc", "text": "Plot MEG/EEG fields on head surface and helmet in 3D.\n\nParameters\n----------\nevoked : instance of mne.Evoked\n    The evoked object.\nsurf_maps : list\n    The surface mapping information obtained with make_field_map.\ntime : float | None\n    The time point at which the field map shall be displayed. If None,\n    the average peak latency (across sensor types) is used.\ntime_label : str | None\n    How to print info about the time instant visualized.\n%(n_jobs)s\nfig : Figure3D | mne.viz.Brain | None\n    If None (default), a new figure will be created, otherwise it will\n    plot into the given figure.\n\n    .. versionadded:: 0.20\n    .. versionadded:: 1.4\n        ``fig`` can also be a ``Brain`` figure.\nvmax : float | dict | None\n    Maximum intensity. Can be a dictionary with two entries ``\"eeg\"`` and ``\"meg\"``\n    to specify separate values for EEG and MEG fields respectively. Can be\n    ``None`` to use the maximum value of the data.\n\n    .. versionadded:: 0.21\n    .. versionadded:: 1.4\n        ``vmax`` can be a dictionary to specify separate values for EEG and\n        MEG fields.\nn_contours : int\n    The number of contours.\n\n    .. versionadded:: 0.21\nshow_density : bool\n    Whether to draw the field density as an overlay on top of the helmet/head\n    surface. Defaults to ``True``.\n\n    .. versionadded:: 1.6\nalpha : float | dict | None\n    Opacity of the meshes (between 0 and 1). Can be a dictionary with two\n    entries ``\"eeg\"`` and ``\"meg\"`` to specify separate values for EEG and\n    MEG fields respectively. Can be ``None`` to use 1.0 when a single field\n    map is shown, or ``dict(eeg=1.0, meg=0.5)`` when both field maps are shown.\n\n    .. versionadded:: 1.4\n%(interpolation_brain_time)s\n\n    .. versionadded:: 1.6\n%(interaction_scene)s\n    Defaults to ``'terrain'``.\n\n    .. versionadded:: 1.1\ntime_viewer : bool | str\n    Display time viewer GUI. Can also be ``\"auto\"``, which will mean\n    ``True`` if there is more than one time point and ``False`` otherwise.\n\n    .. versionadded:: 1.6\n%(verbose)s\n\nReturns\n-------\nfig : Figure3D | mne.viz.EvokedField\n    Without the time viewer active, the figure is returned. With the time\n    viewer active, an object is returned that can be used to control\n    different aspects of the figure.", "metadata": {}}
{"_id": "mne_mne_viz/_3d.py_plot_alignment_doc", "text": "Plot head, sensor, and source space alignment in 3D.\n\nParameters\n----------\n%(info)s If None (default), no sensor information will be shown.\n%(trans)s \"auto\" will load trans from the FreeSurfer directory\n    specified by ``subject`` and ``subjects_dir`` parameters.\n\n    .. versionchanged:: 0.19\n        Support for 'fsaverage' argument.\n%(subject)s Can be omitted if ``src`` is provided.\n%(subjects_dir)s\nsurfaces : str | list | dict\n    Surfaces to plot. Supported values:\n\n    * scalp: one of 'head', 'outer_skin' (alias for 'head'),\n      'head-dense', or 'seghead' (alias for 'head-dense')\n    * skull: 'outer_skull', 'inner_skull', 'brain' (alias for\n      'inner_skull')\n    * brain: one of 'pial', 'white', 'inflated', or 'brain'\n      (alias for 'pial').\n\n    Can be dict to specify alpha values for each surface. Use None\n    to specify default value. Specified values must be between 0 and 1.\n    for example::\n\n        surfaces=dict(brain=0.4, outer_skull=0.6, head=None)\n\n    Defaults to 'auto', which will look for a head surface and plot\n    it if found.\n\n    .. note:: For single layer BEMs it is recommended to use ``'brain'``.\ncoord_frame : 'auto' | 'head' | 'meg' | 'mri'\n    The coordinate frame to use. If ``'auto'`` (default), chooses ``'mri'``\n    if ``trans`` was passed, and ``'head'`` otherwise.\n\n    .. versionchanged:: 1.0\n       Defaults to ``'auto'``.\n%(meg)s\n%(eeg)s\n%(fwd)s\ndig : bool | 'fiducials'\n    If True, plot the digitization points; 'fiducials' to plot fiducial\n    points only.\n%(ecog)s\nsrc : instance of SourceSpaces | None\n    If not None, also plot the source space points.\nmri_fiducials : bool | str | path-like\n    Plot MRI fiducials (default False). If ``True``, look for a file with\n    the canonical name (``bem/{subject}-fiducials.fif``). If ``str``,\n    it can be ``'estimated'`` to use :func:`mne.coreg.get_mni_fiducials`,\n    otherwise it should provide the full path to the fiducials file.\n\n    .. versionadded:: 0.22\n       Support for ``'estimated'``.\nbem : list of dict | instance of ConductorModel | None\n    Can be either the BEM surfaces (list of dict), a BEM solution or a\n    sphere model. If None, we first try loading\n    ``'$SUBJECTS_DIR/$SUBJECT/bem/$SUBJECT-$SOURCE.fif'``, and then look\n    for ``'$SUBJECT*$SOURCE.fif'`` in the same directory. For\n    ``'outer_skin'``, the subjects bem and bem/flash folders are searched.\n    Defaults to None.\n%(seeg)s\n%(fnirs)s\n    .. versionadded:: 0.20\nshow_axes : bool\n    If True (default False), coordinate frame axis indicators will be\n    shown:\n\n    * head in pink.\n    * MRI in gray (if ``trans is not None``).\n    * MEG in blue (if MEG sensors are present).\n\n    .. versionadded:: 0.16\n%(dbs)s\nfig : Figure3D | None\n    PyVista scene in which to plot the alignment.\n    If ``None``, creates a new 600x600 pixel figure with black background.\n\n    .. versionadded:: 0.16\n%(interaction_scene)s\n\n    .. versionadded:: 0.16\n    .. versionchanged:: 1.0\n       Defaults to ``'terrain'``.\n%(sensor_colors)s\n\n    .. versionchanged:: 1.6\n        Support for passing a ``dict`` was added.\n%(sensor_scales)s\n\n    .. versionadded:: 1.9\n%(verbose)s\n\nReturns\n-------\nfig : instance of Figure3D\n    The figure.\n\nSee Also\n--------\nmne.viz.plot_bem\n\nNotes\n-----\nThis function serves the purpose of checking the validity of the many\ndifferent steps of source reconstruction:\n\n- Transform matrix (keywords ``trans``, ``meg`` and ``mri_fiducials``),\n- BEM surfaces (keywords ``bem`` and ``surfaces``),\n- sphere conductor model (keywords ``bem`` and ``surfaces``) and\n- source space (keywords ``surfaces`` and ``src``).\n\n.. versionadded:: 0.15", "metadata": {}}
{"_id": "mne_mne_viz/_3d.py_link_brains_doc", "text": "Plot multiple SourceEstimate objects with PyVista.\n\nParameters\n----------\nbrains : list, tuple or np.ndarray\n    The collection of brains to plot.\ntime : bool\n    If True, link the time controllers. Defaults to True.\ncamera : bool\n    If True, link the camera controls. Defaults to False.\ncolorbar : bool\n    If True, link the colorbar controllers. Defaults to True.\npicking : bool\n    If True, link the vertices picked with the mouse. Defaults to False.", "metadata": {}}
{"_id": "mne_mne_viz/_3d.py_plot_source_estimates_doc", "text": "Plot SourceEstimate.\n\nParameters\n----------\nstc : SourceEstimate\n    The source estimates to plot.\n%(subject_none)s\n    If ``None``, ``stc.subject`` will be used.\nsurface : str\n    The type of surface (inflated, white etc.).\nhemi : str\n    Hemisphere id (ie ``'lh'``, ``'rh'``, ``'both'``, or ``'split'``). In\n    the case of ``'both'``, both hemispheres are shown in the same window.\n    In the case of ``'split'`` hemispheres are displayed side-by-side\n    in different viewing panes.\n%(colormap)s\n    The default ('auto') uses ``'hot'`` for one-sided data and\n    'mne' for two-sided data.\n%(time_label)s\nsmoothing_steps : int\n    The amount of smoothing.\n%(transparent)s\nalpha : float\n    Alpha value to apply globally to the overlay. Has no effect with mpl\n    backend.\ntime_viewer : bool | str\n    Display time viewer GUI. Can also be 'auto', which will mean True\n    for the PyVista backend and False otherwise.\n\n    .. versionchanged:: 0.20.0\n       \"auto\" mode added.\n%(subjects_dir)s\nfigure : instance of Figure3D | instance of matplotlib.figure.Figure | list | int | None\n    If None, a new figure will be created. If multiple views or a\n    split view is requested, this must be a list of the appropriate\n    length. If int is provided it will be used to identify the PyVista\n    figure by it's id or create a new figure with the given id. If an\n    instance of matplotlib figure, mpl backend is used for plotting.\n%(views)s\n\n    When plotting a standard SourceEstimate (not volume, mixed, or vector)\n    and using the PyVista backend, ``views='flat'`` is also supported to\n    plot cortex as a flatmap.\n\n    Using multiple views (list) is not supported by the matplotlib backend.\n\n    .. versionchanged:: 0.21.0\n       Support for flatmaps.\ncolorbar : bool\n    If True, display colorbar on scene.\n%(clim)s\ncortex : str | tuple\n    Specifies how binarized curvature values are rendered.\n    Either the name of a preset Brain cortex colorscheme (one of\n    ``'classic'``, ``'bone'``, ``'low_contrast'``, or ``'high_contrast'``),\n    or the name of a colormap, or a tuple with values\n    ``(colormap, min, max, reverse)`` to fully specify the curvature\n    colors. Has no effect with the matplotlib backend.\nsize : float or tuple of float\n    The size of the window, in pixels. can be one number to specify\n    a square window, or the (width, height) of a rectangular window.\n    Has no effect with mpl backend.\nbackground : matplotlib color\n    Color of the background of the display window.\nforeground : matplotlib color | None\n    Color of the foreground of the display window. Has no effect with mpl\n    backend. None will choose white or black based on the background color.\ninitial_time : float | None\n    The time to display on the plot initially. ``None`` to display the\n    first time sample (default).\ntime_unit : ``'s'`` | ``'ms'``\n    Whether time is represented in seconds (\"s\", default) or\n    milliseconds (\"ms\").\nbackend : ``'auto'`` | ``'pyvistaqt'`` | ``'matplotlib'``\n    Which backend to use. If ``'auto'`` (default), tries to plot with\n    pyvistaqt, but resorts to matplotlib if no 3d backend is available.\n\n    .. versionadded:: 0.15.0\nspacing : str\n    Only affects the matplotlib backend.\n    The spacing to use for the source space. Can be ``'ico#'`` for a\n    recursively subdivided icosahedron, ``'oct#'`` for a recursively\n    subdivided octahedron, or ``'all'`` for all points. In general, you can\n    speed up the plotting by selecting a sparser source space.\n    Defaults  to 'oct6'.\n\n    .. versionadded:: 0.15.0\n%(title_stc)s\n\n    .. versionadded:: 0.17.0\n%(show_traces)s\n%(src_volume_options)s\n%(view_layout)s\n%(add_data_kwargs)s\n%(brain_kwargs)s\n%(verbose)s\n\nReturns\n-------\nfigure : instance of mne.viz.Brain | matplotlib.figure.Figure\n    An instance of :class:`mne.viz.Brain` or matplotlib figure.\n\nNotes\n-----\nFlatmaps are available by default for ``fsaverage`` but not for other\nsubjects reconstructed by FreeSurfer. We recommend using\n:func:`mne.compute_source_morph` to morph source estimates to ``fsaverage``\nfor flatmap plotting. If you want to construct your own flatmap for a given\nsubject, these links might help:\n\n- https://surfer.nmr.mgh.harvard.edu/fswiki/FreeSurferOccipitalFlattenedPatch\n- https://openwetware.org/wiki/Beauchamp:FreeSurfer", "metadata": {}}
{"_id": "mne_mne_viz/_3d.py_plot_volume_source_estimates_doc", "text": "Plot Nutmeg style volumetric source estimates using nilearn.\n\nParameters\n----------\nstc : VectorSourceEstimate\n    The vector source estimate to plot.\nsrc : instance of SourceSpaces | instance of SourceMorph\n    The source space. Can also be a SourceMorph to morph the STC to\n    a new subject (see Examples).\n\n    .. versionchanged:: 0.18\n       Support for :class:`~nibabel.spatialimages.SpatialImage`.\n%(subject_none)s\n    If ``None``, ``stc.subject`` will be used.\n%(subjects_dir)s\nmode : ``'stat_map'`` | ``'glass_brain'``\n    The plotting mode to use. For ``'glass_brain'``, activation absolute values are\n    displayed after being transformed to a standard MNI brain.\nbg_img : instance of SpatialImage | str\n    The background image used in the nilearn plotting function.\n    Can also be a string to use the ``bg_img`` file in the subject's\n    MRI directory (default is ``'T1.mgz'``).\n    Not used in \"glass brain\" plotting.\ncolorbar : bool\n    If True, display a colorbar on the right of the plots.\n%(colormap)s\n%(clim)s\n%(transparent)s\nshow : bool\n    Show figures if True. Defaults to True.\ninitial_time : float | None\n    The initial time to plot. Can be None (default) to use the time point\n    with the maximal absolute value activation across all voxels\n    or the ``initial_pos`` voxel (if ``initial_pos is None`` or not,\n    respectively).\n\n    .. versionadded:: 0.19\ninitial_pos : ndarray, shape (3,) | None\n    The initial position to use (in m). Can be None (default) to use the\n    voxel with the maximum absolute value activation across all time points\n    or at ``initial_time`` (if ``initial_time is None`` or not,\n    respectively).\n\n    .. versionadded:: 0.19\n%(verbose)s\n\nReturns\n-------\nfig : instance of Figure\n    The figure.\n\nNotes\n-----\nClick on any of the anatomical slices to explore the time series.\nClicking on any time point will bring up the corresponding anatomical map.\n\nThe left and right arrow keys can be used to navigate in time.\nTo move in time by larger steps, use shift+left and shift+right.\n\nIn ``'glass_brain'`` mode, values are transformed to the standard MNI\nbrain using the FreeSurfer Talairach transformation\n``$SUBJECTS_DIR/$SUBJECT/mri/transforms/talairach.xfm``.\n\n.. versionadded:: 0.17\n\n.. versionchanged:: 0.19\n   MRI volumes are automatically transformed to MNI space in\n   ``'glass_brain'`` mode.\n\nExamples\n--------\nPassing a :class:`mne.SourceMorph` as the ``src``\nparameter can be useful for plotting in a different subject's space\n(here, a ``'sample'`` STC in ``'fsaverage'``'s space)::\n\n>>> morph = mne.compute_source_morph(src_sample, subject_to='fsaverage')  # doctest: +SKIP\n>>> fig = stc_vol_sample.plot(morph)  # doctest: +SKIP", "metadata": {}}
{"_id": "mne_mne_viz/_3d.py_plot_vector_source_estimates_doc", "text": "Plot VectorSourceEstimate with PyVista.\n\nA \"glass brain\" is drawn and all dipoles defined in the source estimate\nare shown using arrows, depicting the direction and magnitude of the\ncurrent moment at the dipole. Additionally, an overlay is plotted on top of\nthe cortex with the magnitude of the current.\n\nParameters\n----------\nstc : VectorSourceEstimate | MixedVectorSourceEstimate\n    The vector source estimate to plot.\n%(subject_none)s\n    If ``None``, ``stc.subject`` will be used.\nhemi : str, 'lh' | 'rh' | 'split' | 'both'\n    The hemisphere to display.\n%(colormap)s\n    This should be a sequential colormap.\n%(time_label)s\nsmoothing_steps : int\n    The amount of smoothing.\n%(transparent)s\nbrain_alpha : float\n    Alpha value to apply globally to the surface meshes. Defaults to 0.4.\noverlay_alpha : float\n    Alpha value to apply globally to the overlay. Defaults to\n    ``brain_alpha``.\nvector_alpha : float\n    Alpha value to apply globally to the vector glyphs. Defaults to 1.\nscale_factor : float | None\n    Scaling factor for the vector glyphs. By default, an attempt is made to\n    automatically determine a sane value.\ntime_viewer : bool | str\n    Display time viewer GUI. Can be \"auto\", which is True for the PyVista\n    backend and False otherwise.\n\n    .. versionchanged:: 0.20\n       Added \"auto\" option and default.\nsubjects_dir : str\n    The path to the freesurfer subjects reconstructions.\n    It corresponds to Freesurfer environment variable SUBJECTS_DIR.\nfigure : instance of Figure3D | list | int | None\n    If None, a new figure will be created. If multiple views or a\n    split view is requested, this must be a list of the appropriate\n    length. If int is provided it will be used to identify the PyVista\n    figure by it's id or create a new figure with the given id.\n%(views)s\ncolorbar : bool\n    If True, display colorbar on scene.\n%(clim_onesided)s\ncortex : str or tuple\n    Specifies how binarized curvature values are rendered.\n    either the name of a preset Brain cortex colorscheme (one of\n    'classic', 'bone', 'low_contrast', or 'high_contrast'), or the\n    name of a colormap, or a tuple with values (colormap, min,\n    max, reverse) to fully specify the curvature colors.\nsize : float or tuple of float\n    The size of the window, in pixels. can be one number to specify\n    a square window, or the (width, height) of a rectangular window.\nbackground : matplotlib color\n    Color of the background of the display window.\nforeground : matplotlib color | None\n    Color of the foreground of the display window.\n    None will choose black or white based on the background color.\ninitial_time : float | None\n    The time to display on the plot initially. ``None`` to display the\n    first time sample (default).\ntime_unit : 's' | 'ms'\n    Whether time is represented in seconds (\"s\", default) or\n    milliseconds (\"ms\").\n%(title_stc)s\n\n    .. versionadded:: 1.9\n%(show_traces)s\n%(src_volume_options)s\n%(view_layout)s\n%(add_data_kwargs)s\n%(brain_kwargs)s\n%(verbose)s\n\nReturns\n-------\nbrain : mne.viz.Brain\n    A instance of :class:`mne.viz.Brain`.\n\nNotes\n-----\n.. versionadded:: 0.15\n\nIf the current magnitude overlay is not desired, set ``overlay_alpha=0``\nand ``smoothing_steps=1``.", "metadata": {}}
{"_id": "mne_mne_viz/_3d.py_plot_sparse_source_estimates_doc", "text": "Plot source estimates obtained with sparse solver.\n\nActive dipoles are represented in a \"Glass\" brain.\nIf the same source is active in multiple source estimates it is\ndisplayed with a sphere otherwise with a cone in 3D.\n\nParameters\n----------\nsrc : dict\n    The source space.\nstcs : instance of SourceEstimate or list of instances of SourceEstimate\n    The source estimates.\ncolors : list\n    List of colors.\nlinewidth : int\n    Line width in 2D plot.\nfontsize : int\n    Font size.\nbgcolor : tuple of length 3\n    Background color in 3D.\nopacity : float in [0, 1]\n    Opacity of brain mesh.\nbrain_color : tuple of length 3\n    Brain color.\nshow : bool\n    Show figures if True.\nhigh_resolution : bool\n    If True, plot on the original (non-downsampled) cortical mesh.\nfig_name : str\n    PyVista figure name.\nfig_number : int\n    Matplotlib figure number.\nlabels : ndarray or list of ndarray\n    Labels to show sources in clusters. Sources with the same\n    label and the waveforms within each cluster are presented in\n    the same color. labels should be a list of ndarrays when\n    stcs is a list ie. one label for each stc.\nmodes : list\n    Should be a list, with each entry being ``'cone'`` or ``'sphere'``\n    to specify how the dipoles should be shown.\n    The pivot for the glyphs in ``'cone'`` mode is always the tail\n    whereas the pivot in ``'sphere'`` mode is the center.\nscale_factors : list\n    List of floating point scale factors for the markers.\n%(verbose)s\n**kwargs : kwargs\n    Keyword arguments to pass to renderer.mesh.\n\nReturns\n-------\nsurface : instance of Figure3D\n    The 3D figure containing the triangular mesh surface.", "metadata": {}}
{"_id": "mne_mne_viz/_3d.py_plot_dipole_locations_doc", "text": "Plot dipole locations.\n\nIf mode is set to 'arrow' or 'sphere', only the location of the first\ntime point of each dipole is shown else use the show_all parameter.\n\nParameters\n----------\ndipoles : list of instances of Dipole | Dipole\n    The dipoles to plot.\ntrans : dict | None\n    The mri to head trans.\n    Can be None with mode set to '3d'.\nsubject : str | None\n    The FreeSurfer subject name (will be used to set the FreeSurfer\n    environment variable ``SUBJECT``).\n    Can be ``None`` with mode set to ``'3d'``.\n%(subjects_dir)s\nmode : str\n    Can be:\n\n    ``'arrow'`` or ``'sphere'``\n        Plot in 3D mode using PyVista with the given glyph type.\n    ``'orthoview'``\n        Plot in matplotlib ``Axes3D`` using matplotlib with MRI slices\n        shown on the sides of a cube, with the dipole(s) shown as arrows\n        extending outward from a dot (i.e., the arrows pivot on the tail).\n    ``'outlines'``\n        Plot in matplotlib ``Axes`` using a quiver of arrows for the\n        dipoles in three axes (axial, coronal, and sagittal views),\n        with the arrow pivoting in the middle of the arrow.\n\n    .. versionchanged:: 1.1\n       Added support for ``'outlines'``.\ncoord_frame : str\n    Coordinate frame to use: 'head' or 'mri'. Can also be 'mri_rotated'\n    when mode equals ``'outlines'``. Defaults to 'mri'.\n\n    .. versionadded:: 0.14.0\n    .. versionchanged:: 1.1\n       Added support for ``'mri_rotated'``.\nidx : int | 'gof' | 'amplitude'\n    Index of the initially plotted dipole. Can also be 'gof' to plot the\n    dipole with highest goodness of fit value or 'amplitude' to plot the\n    dipole with the highest amplitude. The dipoles can also be browsed\n    through using up/down arrow keys or mouse scroll. Defaults to 'gof'.\n    Only used if mode equals 'orthoview'.\n\n    .. versionadded:: 0.14.0\nshow_all : bool\n    Whether to always plot all the dipoles. If ``True`` (default), the\n    active dipole is plotted as a red dot and its location determines the\n    shown MRI slices. The non-active dipoles are plotted as small blue\n    dots. If ``False``, only the active dipole is plotted.\n    Only used if ``mode='orthoview'``.\n\n    .. versionadded:: 0.14.0\nax : instance of matplotlib Axes3D | list of matplotlib Axes | None\n    Axes to plot into. If None (default), axes will be created.\n    If mode equals ``'orthoview'``, must be a single ``Axes3D``.\n    If mode equals ``'outlines'``, must be a list of three ``Axes``.\n\n    .. versionadded:: 0.14.0\nblock : bool\n    Whether to halt program execution until the figure is closed. Defaults\n    to False.\n    Only used if mode equals 'orthoview'.\n\n    .. versionadded:: 0.14.0\nshow : bool\n    Show figure if True. Defaults to True.\n    Only used if mode equals 'orthoview'.\nscale : float\n    The scale (size in meters) of the dipoles if ``mode`` is not\n    ``'orthoview'``. The default is 0.03 when mode is ``'outlines'`` and\n    0.005 otherwise.\ncolor : tuple\n    The color of the dipoles.\n    The default (None) will use ``'y'`` if mode is ``'orthoview'`` and\n    ``show_all`` is True, else 'r'. Can also be a list of colors to use\n    when mode is ``'outlines'``.\n\n    .. versionchanged:: 0.19.0\n       Color is now passed in orthoview mode.\nhighlight_color : color\n    The highlight color. Only used in orthoview mode with\n    ``show_all=True``.\n\n    .. versionadded:: 0.19.0\nfig : instance of Figure3D | None\n    3D figure in which to plot the alignment.\n    If ``None``, creates a new 600x600 pixel figure with black background.\n    Only used when mode is ``'arrow'`` or ``'sphere'``.\n\n    .. versionadded:: 0.19.0\ntitle : str | None\n    The title of the figure if ``mode='orthoview'`` (ignored for all other\n    modes). If ``None``, dipole number and its properties (amplitude,\n    orientation etc.) will be shown. Defaults to ``None``.\n\n    .. versionadded:: 0.21.0\n%(head_source)s\n    Only used when mode equals ``'outlines'``.\n\n    .. versionadded:: 1.1\nsurf : str | None\n    Brain surface to show outlines for, can be ``'white'``, ``'pial'``, or\n    ``None``. Only used when mode is ``'outlines'``.\n\n    .. versionadded:: 1.1\nwidth : float | None\n    Width of the matplotlib quiver arrow, see\n    :meth:`matplotlib:matplotlib.axes.Axes.quiver`. If None (default),\n    when mode is ``'outlines'`` 0.015 will be used, and when mode is\n    ``'orthoview'`` the matplotlib default is used.\n%(verbose)s\n\nReturns\n-------\nfig : instance of Figure3D or matplotlib.figure.Figure\n    The PyVista figure or matplotlib Figure.\n\nNotes\n-----\n.. versionadded:: 0.9.0", "metadata": {}}
{"_id": "mne_mne_viz/_3d.py_snapshot_brain_montage_doc", "text": "Take a snapshot of a PyVista Scene and project channels onto 2d coords.\n\nNote that this will take the raw values for 3d coordinates of each channel,\nwithout applying any transforms. If brain images are flipped up/dn upon\nusing `~matplotlib.pyplot.imshow`, check your matplotlib backend as this\nbehavior changes.\n\nParameters\n----------\nfig : instance of Figure3D\n    The figure on which you've plotted electrodes using\n    :func:`mne.viz.plot_alignment`.\nmontage : instance of DigMontage or Info | dict\n    The digital montage for the electrodes plotted in the scene. If\n    :class:`~mne.Info`, channel positions will be pulled from the ``loc``\n    field of ``chs``. dict should have ch:xyz mappings.\nhide_sensors : bool\n    Whether to remove the spheres in the scene before taking a snapshot.\n    The sensors will always be shown in the final figure. If you want an\n    image of just the brain, use :class:`mne.viz.Brain` instead.\n\nReturns\n-------\nxy : array, shape (n_channels, 2)\n    The 2d location of each channel on the image of the current scene view.\nim : array, shape (m, n, 3)\n    The screenshot of the current scene view.", "metadata": {}}
{"_id": "mne_mne_viz/_3d.py_plot_brain_colorbar_doc", "text": "Plot a colorbar that corresponds to a brain activation map.\n\nParameters\n----------\nax : instance of Axes\n    The Axes to plot into.\n%(clim)s\n%(colormap)s\n%(transparent)s\norientation : str\n    Orientation of the colorbar, can be \"vertical\" or \"horizontal\".\nlabel : str\n    The colorbar label.\nbgcolor : color\n    The color behind the colorbar (for alpha blending).\n\nReturns\n-------\ncbar : instance of ColorbarBase\n    The colorbar.\n\nNotes\n-----\n.. versionadded:: 0.19", "metadata": {}}
{"_id": "mne_mne_viz/_3d.py_set_3d_options_doc", "text": "Set 3D rendering options.\n\nParameters\n----------\nantialias : bool | None\n    If bool, whether to enable or disable full-screen anti-aliasing.\n    False is useful when renderers have problems (such as software\n    MESA renderers). If None, use the default setting. This option\n    can also be controlled using an environment variable, e.g.,\n    ``MNE_3D_OPTION_ANTIALIAS=false``.\ndepth_peeling : bool | None\n    If bool, whether to enable or disable accurate transparency.\n    False is useful when renderers have problems (for instance\n    while X forwarding on remote servers). If None, use the default\n    setting. This option can also be controlled using an environment\n    variable, e.g., ``MNE_3D_OPTION_DEPTH_PEELING=false``.\nsmooth_shading : bool | None\n    If bool, whether to enable or disable smooth color transitions\n    between polygons. False is useful on certain configurations\n    where this type of shading is not supported or for performance\n    reasons. This option can also be controlled using an environment\n    variable, e.g., ``MNE_3D_OPTION_SMOOTH_SHADING=false``.\nmulti_samples : int\n    Number of multi-samples. Should be 1 for MESA for volumetric rendering\n    to work properly.\n\n    .. versionadded:: 1.1\n\nNotes\n-----\n.. versionadded:: 0.21.0", "metadata": {}}
{"_id": "mne_mne_viz/backends/renderer.py_set_3d_backend_doc", "text": "Set the 3D backend for MNE.\n\nThe backend will be set as specified and operations will use\nthat backend.\n\nParameters\n----------\nbackend_name : str\n    The 3d backend to select. See Notes for the capabilities of each\n    backend (``'pyvistaqt'`` and ``'notebook'``).\n\n    .. versionchanged:: 0.24\n       The ``'pyvista'`` backend was renamed ``'pyvistaqt'``.\n%(verbose)s\n\nReturns\n-------\nold_backend_name : str | None\n    The old backend that was in use.\n\nNotes\n-----\nTo use PyVista, set ``backend_name`` to ``pyvistaqt`` but the value\n``pyvista`` is still supported for backward compatibility.\n\nThis table shows the capabilities of each backend (\"\u2713\" for full support,\nand \"-\" for partial support):\n\n.. table::\n   :widths: auto\n\n   +--------------------------------------+-----------+----------+\n   | **3D function:**                     | pyvistaqt | notebook |\n   +======================================+===========+==========+\n   | :func:`plot_vector_source_estimates` | \u2713         | \u2713        |\n   +--------------------------------------+-----------+----------+\n   | :func:`plot_source_estimates`        | \u2713         | \u2713        |\n   +--------------------------------------+-----------+----------+\n   | :func:`plot_alignment`               | \u2713         | \u2713        |\n   +--------------------------------------+-----------+----------+\n   | :func:`plot_sparse_source_estimates` | \u2713         | \u2713        |\n   +--------------------------------------+-----------+----------+\n   | :func:`plot_evoked_field`            | \u2713         | \u2713        |\n   +--------------------------------------+-----------+----------+\n   | :func:`snapshot_brain_montage`       | \u2713         | \u2713        |\n   +--------------------------------------+-----------+----------+\n   | :func:`link_brains`                  | \u2713         |          |\n   +--------------------------------------+-----------+----------+\n   +--------------------------------------+-----------+----------+\n   | **Feature:**                                                |\n   +--------------------------------------+-----------+----------+\n   | Large data                           | \u2713         | \u2713        |\n   +--------------------------------------+-----------+----------+\n   | Opacity/transparency                 | \u2713         | \u2713        |\n   +--------------------------------------+-----------+----------+\n   | Support geometric glyph              | \u2713         | \u2713        |\n   +--------------------------------------+-----------+----------+\n   | Smooth shading                       | \u2713         | \u2713        |\n   +--------------------------------------+-----------+----------+\n   | Subplotting                          | \u2713         | \u2713        |\n   +--------------------------------------+-----------+----------+\n   | Inline plot in Jupyter Notebook      |           | \u2713        |\n   +--------------------------------------+-----------+----------+\n   | Inline plot in JupyterLab            |           | \u2713        |\n   +--------------------------------------+-----------+----------+\n   | Inline plot in Google Colab          |           |          |\n   +--------------------------------------+-----------+----------+\n   | Toolbar                              | \u2713         | \u2713        |\n   +--------------------------------------+-----------+----------+", "metadata": {}}
{"_id": "mne_mne_viz/backends/renderer.py_get_3d_backend_doc", "text": "Return the 3D backend currently used.\n\nReturns\n-------\nbackend_used : str | None\n    The 3d backend currently in use. If no backend is found,\n    returns ``None``.\n\n    .. versionchanged:: 0.24\n       The ``'pyvista'`` backend has been renamed ``'pyvistaqt'``, so\n       ``'pyvista'`` is no longer returned by this function.", "metadata": {}}
{"_id": "mne_mne_viz/backends/renderer.py_use_3d_backend_doc", "text": "Create a 3d visualization context using the designated backend.\n\nSee :func:`mne.viz.set_3d_backend` for more details on the available\n3d backends and their capabilities.\n\nParameters\n----------\nbackend_name : {'pyvistaqt', 'notebook'}\n    The 3d backend to use in the context.", "metadata": {}}
{"_id": "mne_mne_viz/backends/renderer.py_set_3d_view_doc", "text": "Configure the view of the given scene.\n\nParameters\n----------\nfigure : object\n    The scene which is modified.\n%(azimuth)s\n%(elevation)s\n%(focalpoint)s\n%(distance)s\n%(roll)s", "metadata": {}}
{"_id": "mne_mne_viz/backends/renderer.py_set_3d_title_doc", "text": "Configure the title of the given scene.\n\nParameters\n----------\nfigure : object\n    The scene which is modified.\ntitle : str\n    The title of the scene.\nsize : int\n    The size of the title.\ncolor : matplotlib color\n    The color of the title.\n\n    .. versionadded:: 1.9\nposition : str\n    The position to use, e.g., \"upper_left\". See\n    :meth:`pyvista.Plotter.add_text` for details.\n\n    .. versionadded:: 1.9\n\nReturns\n-------\ntext : object\n    The text object returned by the given backend.\n\n    .. versionadded:: 1.0", "metadata": {}}
{"_id": "mne_mne_viz/backends/renderer.py_create_3d_figure_doc", "text": "Return an empty figure based on the current 3d backend.\n\n.. warning:: Proceed with caution when the renderer object is\n             returned (with ``scene=False``) because the _Renderer\n             API is not necessarily stable enough for production,\n             it's still actively in development.\n\nParameters\n----------\nsize : tuple\n    The dimensions of the 3d figure (width, height).\nbgcolor : tuple\n    The color of the background.\nsmooth_shading : bool | None\n    Whether to enable smooth shading. If ``None``, uses the config value\n    ``MNE_3D_OPTION_SMOOTH_SHADING``. Defaults to ``None``.\nhandle : int | None\n    The figure identifier.\nscene : bool\n    If True (default), the returned object is the Figure3D. If False,\n    an advanced, undocumented Renderer object is returned (the API is not\n    stable or documented, so this is not recommended).\nshow : bool\n    If True, show the renderer immediately.\n\n    .. versionadded:: 1.0\ntitle : str\n    The window title to use (if applicable).\n\n    .. versionadded:: 1.9\n\nReturns\n-------\nfigure : instance of Figure3D or ``Renderer``\n    The requested empty figure or renderer, depending on ``scene``.", "metadata": {}}
{"_id": "mne_mne_viz/backends/renderer.py_close_3d_figure_doc", "text": "Close the given scene.\n\nParameters\n----------\nfigure : object\n    The scene which needs to be closed.", "metadata": {}}
{"_id": "mne_mne_viz/backends/renderer.py_close_all_3d_figures_doc", "text": "Close all the scenes of the current 3d backend.", "metadata": {}}
{"_id": "mne_mne_viz/backends/renderer.py_get_brain_class_doc", "text": "Return the proper Brain class based on the current 3d backend.\n\nReturns\n-------\nbrain : object\n    The Brain class corresponding to the current 3d backend.", "metadata": {}}
{"_id": "mne_mne_viz/backends/_abstract.py_plotter_doc", "text": "The native 3D plotting widget.\n\nReturns\n-------\nplotter : instance of pyvista.Plotter\n    The plotter. Useful for interacting with the native 3D library.", "metadata": {}}
{"_id": "mne_mne_viz/backends/_abstract.py_subplot_doc", "text": "Set the active subplot.", "metadata": {}}
{"_id": "mne_mne_viz/backends/_abstract.py_scene_doc", "text": "Return scene handle.", "metadata": {}}
{"_id": "mne_mne_viz/backends/_abstract.py_set_interaction_doc", "text": "Set interaction mode.", "metadata": {}}
{"_id": "mne_mne_viz/backends/_abstract.py_legend_doc", "text": "Add a legend to the scene.\n\nParameters\n----------\nlabels : list of tuples\n    Each entry must contain two strings, (label, color),\n    where ``label`` is the name of the item to add, and\n    ``color`` is the color of the label to add.\nborder : bool\n    Controls if there will be a border around the legend.\n    The default is False.\nsize : float\n    The size of the entire figure window.\nloc : str\n    The location of the legend.\nface : str\n    Face shape of legend face.  One of the following:\n\n    * None: ``None``\n    * Line: ``\"-\"`` or ``\"line\"``\n    * Triangle: ``\"^\"`` or ``'triangle'``\n    * Circle: ``\"o\"`` or ``'circle'``\n    * Rectangle: ``\"r\"`` or ``'rectangle'``", "metadata": {}}
{"_id": "mne_mne_viz/backends/_abstract.py_mesh_doc", "text": "Add a mesh in the scene.\n\nParameters\n----------\nx : array, shape (n_vertices,)\n   The array containing the X component of the vertices.\ny : array, shape (n_vertices,)\n   The array containing the Y component of the vertices.\nz : array, shape (n_vertices,)\n   The array containing the Z component of the vertices.\ntriangles : array, shape (n_polygons, 3)\n   The array containing the indices of the polygons.\ncolor : tuple | str\n    The color of the mesh as a tuple (red, green, blue) of float\n    values between 0 and 1 or a valid color name (i.e. 'white'\n    or 'w').\nopacity : float\n    The opacity of the mesh.\nshading : bool\n    If True, enable the mesh shading.\nbackface_culling : bool\n    If True, enable backface culling on the mesh.\nscalars : ndarray, shape (n_vertices,)\n    The scalar valued associated to the vertices.\nvmin : float | None\n    vmin is used to scale the colormap.\n    If None, the min of the data will be used.\nvmax : float | None\n    vmax is used to scale the colormap.\n    If None, the max of the data will be used.\ncolormap : str | np.ndarray | matplotlib.colors.Colormap | None\n    The colormap to use.\ninterpolate_before_map :\n    Enabling makes for a smoother scalars display. Default is True.\n    When False, OpenGL will interpolate the mapped colors which can\n    result is showing colors that are not present in the color map.\nrepresentation : str\n    The representation of the mesh: either 'surface' or 'wireframe'.\nline_width : int\n    The width of the lines when representation='wireframe'.\nnormals : array, shape (n_vertices, 3)\n    The array containing the normal of each vertex.\npolygon_offset : float\n    If not None, the factor used to resolve coincident topology.\nname : str | None\n    The name of the mesh.\nkwargs : args\n    The arguments to pass to triangular_mesh\n\nReturns\n-------\nsurface :\n    Handle of the mesh in the scene.", "metadata": {}}
{"_id": "mne_mne_viz/backends/_abstract.py_contour_doc", "text": "Add a contour in the scene.\n\nParameters\n----------\nsurface : surface object\n    The mesh to use as support for contour.\nscalars : ndarray, shape (n_vertices,)\n    The scalar valued associated to the vertices.\ncontours : int | list\n     Specifying a list of values will only give the requested contours.\nwidth : float\n    The width of the lines or radius of the tubes.\nopacity : float\n    The opacity of the contour.\nvmin : float | None\n    vmin is used to scale the colormap.\n    If None, the min of the data will be used.\nvmax : float | None\n    vmax is used to scale the colormap.\n    If None, the max of the data will be used.\ncolormap : str | np.ndarray | matplotlib.colors.Colormap | None\n    The colormap to use.\nnormalized_colormap : bool\n    Specify if the values of the colormap are between 0 and 1.\nkind : 'line' | 'tube'\n    The type of the primitives to use to display the contours.\ncolor : tuple | str\n    The color of the mesh as a tuple (red, green, blue) of float\n    values between 0 and 1 or a valid color name (i.e. 'white'\n    or 'w').", "metadata": {}}
{"_id": "mne_mne_viz/backends/_abstract.py_surface_doc", "text": "Add a surface in the scene.\n\nParameters\n----------\nsurface : surface object\n    The information describing the surface.\ncolor : tuple | str\n    The color of the surface as a tuple (red, green, blue) of float\n    values between 0 and 1 or a valid color name (i.e. 'white'\n    or 'w').\nopacity : float\n    The opacity of the surface.\nvmin : float | None\n    vmin is used to scale the colormap.\n    If None, the min of the data will be used.\nvmax : float | None\n    vmax is used to scale the colormap.\n    If None, the max of the data will be used.\ncolormap : str | np.ndarray | matplotlib.colors.Colormap | None\n    The colormap to use.\nscalars : ndarray, shape (n_vertices,)\n    The scalar valued associated to the vertices.\nbackface_culling : bool\n    If True, enable backface culling on the surface.\npolygon_offset : float\n    If not None, the factor used to resolve coincident topology.\nname : str | None\n    Name of the surface.", "metadata": {}}
{"_id": "mne_mne_viz/backends/_abstract.py_sphere_doc", "text": "Add sphere in the scene.\n\nParameters\n----------\ncenter : ndarray, shape(n_center, 3)\n    The list of centers to use for the sphere(s).\ncolor : tuple | str\n    The color of the sphere as a tuple (red, green, blue) of float\n    values between 0 and 1 or a valid color name (i.e. 'white'\n    or 'w').\nscale : float\n    The scaling applied to the spheres. The given value specifies\n    the maximum size in drawing units.\nopacity : float\n    The opacity of the sphere(s).\nresolution : int\n    The resolution of the sphere created. This is the number\n    of divisions along theta and phi.\nbackface_culling : bool\n    If True, enable backface culling on the sphere(s).\nradius : float | None\n    Replace the glyph scaling by a fixed radius value for each\n    sphere.", "metadata": {}}
{"_id": "mne_mne_viz/backends/_abstract.py_tube_doc", "text": "Add tube in the scene.\n\nParameters\n----------\norigin : array, shape(n_lines, 3)\n    The coordinates of the first end of the tube(s).\ndestination : array, shape(n_lines, 3)\n    The coordinates of the other end of the tube(s).\nradius : float\n    The radius of the tube(s).\ncolor : tuple | str\n    The color of the tube as a tuple (red, green, blue) of float\n    values between 0 and 1 or a valid color name (i.e. 'white'\n    or 'w').\nscalars : array, shape (n_quivers,) | None\n    The optional scalar data to use.\nvmin : float | None\n    vmin is used to scale the colormap.\n    If None, the min of the data will be used.\nvmax : float | None\n    vmax is used to scale the colormap.\n    If None, the max of the data will be used.\ncolormap : str | np.ndarray | matplotlib.colors.Colormap | None\n    The colormap to use.\nopacity : float\n    The opacity of the tube(s).\nbackface_culling : bool\n    If True, enable backface culling on the tube(s).\nreverse_lut : bool\n    If True, reverse the lookup table.\n\nReturns\n-------\nactor :\n    The actor in the scene.\nsurface :\n    Handle of the tube in the scene.", "metadata": {}}
{"_id": "mne_mne_viz/backends/_abstract.py_quiver3d_doc", "text": "Add quiver3d in the scene.\n\nParameters\n----------\nx : array, shape (n_quivers,)\n    The X component of the position of the quiver.\ny : array, shape (n_quivers,)\n    The Y component of the position of the quiver.\nz : array, shape (n_quivers,)\n    The Z component of the position of the quiver.\nu : array, shape (n_quivers,)\n    The last X component of the quiver.\nv : array, shape (n_quivers,)\n    The last Y component of the quiver.\nw : array, shape (n_quivers,)\n    The last Z component of the quiver.\ncolor : tuple | str\n    The color of the quiver as a tuple (red, green, blue) of float\n    values between 0 and 1 or a valid color name (i.e. 'white'\n    or 'w').\nscale : float\n    The scaling applied to the glyphs. The size of the glyph\n    is by default calculated from the inter-glyph spacing.\n    The given value specifies the maximum glyph size in drawing units.\nmode : 'arrow', 'cone' or 'cylinder'\n    The type of the quiver.\nresolution : int\n    The resolution of the glyph created. Depending on the type of\n    glyph, it represents the number of divisions in its geometric\n    representation.\nglyph_height : float\n    The height of the glyph used with the quiver.\nglyph_center : tuple\n    The center of the glyph used with the quiver: (x, y, z).\nglyph_resolution : float\n    The resolution of the glyph used with the quiver.\nopacity : float\n    The opacity of the quiver.\nscale_mode : 'vector', 'scalar' or 'none'\n    The scaling mode for the glyph.\nscalars : array, shape (n_quivers,) | None\n    The optional scalar data to use.\nbackface_culling : bool\n    If True, enable backface culling on the quiver.\ncolormap : str | np.ndarray | matplotlib.colors.Colormap | None\n    The colormap to use.\nvmin : float | None\n    vmin is used to scale the colormap.\n    If None, the min of the data will be used\nvmax : float | None\n    vmax is used to scale the colormap.\n    If None, the max of the data will be used\nline_width : float\n    The width of the 2d arrows.\n\nReturns\n-------\nactor :\n    The actor in the scene.\nsurface :\n    Handle of the quiver in the scene.", "metadata": {}}
{"_id": "mne_mne_viz/backends/_abstract.py_text2d_doc", "text": "Add 2d text in the scene.\n\nParameters\n----------\nx : float\n    The X component to use as position of the text in the\n    window coordinates system (window_width, window_height).\ny : float\n    The Y component to use as position of the text in the\n    window coordinates system (window_width, window_height).\ntext : str\n    The content of the text.\nsize : int\n    The size of the font.\ncolor : tuple | str\n    The color of the text as a tuple (red, green, blue) of float\n    values between 0 and 1 or a valid color name (i.e. 'white'\n    or 'w').", "metadata": {}}
{"_id": "mne_mne_viz/backends/_abstract.py_text3d_doc", "text": "Add 2d text in the scene.\n\nParameters\n----------\nx : float\n    The X component to use as position of the text.\ny : float\n    The Y component to use as position of the text.\nz : float\n    The Z component to use as position of the text.\ntext : str\n    The content of the text.\nwidth : float\n    The width of the text.\ncolor : tuple | str\n    The color of the text as a tuple (red, green, blue) of float\n    values between 0 and 1 or a valid color name (i.e. 'white'\n    or 'w').", "metadata": {}}
{"_id": "mne_mne_viz/backends/_abstract.py_scalarbar_doc", "text": "Add a scalar bar in the scene.\n\nParameters\n----------\nsource\n    The object of the scene used for the colormap.\ncolor : tuple | str\n    The color of the label text.\ntitle : str | None\n    The title of the scalar bar.\nn_labels : int | None\n    The number of labels to display on the scalar bar.\nbgcolor : tuple | str\n    The color of the background when there is transparency.", "metadata": {}}
{"_id": "mne_mne_viz/backends/_abstract.py_show_doc", "text": "Render the scene.", "metadata": {}}
{"_id": "mne_mne_viz/backends/_abstract.py_close_doc", "text": "Close the scene.", "metadata": {}}
{"_id": "mne_mne_viz/backends/_abstract.py_set_camera_doc", "text": "Configure the camera of the scene.\n\nParameters\n----------\nazimuth : float\n    The azimuthal angle of the camera.\nelevation : float\n    The zenith angle of the camera.\ndistance : float\n    The distance to the focal point.\nfocalpoint : tuple\n    The focal point of the camera: (x, y, z).\nroll : float\n    The rotation of the camera along its axis.", "metadata": {}}
{"_id": "mne_mne_viz/backends/_abstract.py_screenshot_doc", "text": "Take a screenshot of the scene.\n\nParameters\n----------\nmode : str\n    Either 'rgb' or 'rgba' for values to return.\n    Default is 'rgb'.\nfilename : str | None\n    If not None, save the figure to the disk.", "metadata": {}}
{"_id": "mne_mne_viz/backends/_abstract.py_project_doc", "text": "Convert 3d points to a 2d perspective.\n\nParameters\n----------\nxyz : array, shape(n_points, 3)\n    The points to project.\nch_names : array, shape(_n_points,)\n    Names of the channels.", "metadata": {}}
{"_id": "mne_mne_viz/backends/_abstract.py_remove_mesh_doc", "text": "Remove the given mesh from the scene.\n\nParameters\n----------\nmesh_data : tuple | Surface\n    The mesh to remove.", "metadata": {}}
{"_id": "mne_mne_viz/backends/_abstract.py_show_doc", "text": "Show the canvas.", "metadata": {}}
{"_id": "mne_mne_viz/backends/_abstract.py_close_doc", "text": "Close the canvas.", "metadata": {}}
{"_id": "mne_mne_viz/backends/_abstract.py_update_doc", "text": "Update the canvas.", "metadata": {}}
{"_id": "mne_mne_viz/backends/_abstract.py_clear_doc", "text": "Clear internal variables.", "metadata": {}}
{"_id": "mne_mne_viz/backends/_abstract.py_plot_doc", "text": "Plot a curve.", "metadata": {}}
{"_id": "mne_mne_viz/backends/_abstract.py_plot_time_line_doc", "text": "Plot the vertical line.", "metadata": {}}
{"_id": "mne_mne_viz/backends/_abstract.py_update_plot_doc", "text": "Update the plot.", "metadata": {}}
{"_id": "mne_mne_viz/backends/_abstract.py_set_color_doc", "text": "Set the widget colors.", "metadata": {}}
{"_id": "mne_mne_viz/backends/_abstract.py_show_doc", "text": "Show the canvas.", "metadata": {}}
{"_id": "mne_mne_viz/backends/_abstract.py_close_doc", "text": "Close the canvas.", "metadata": {}}
{"_id": "mne_mne_viz/backends/_abstract.py_clear_doc", "text": "Clear internal variables.", "metadata": {}}
{"_id": "mne_mne_viz/backends/_abstract.py_on_resize_doc", "text": "Handle resize events.", "metadata": {}}
{"_id": "mne_mne_viz/backends/_abstract.py_update_plot_doc", "text": "Update the plot.", "metadata": {}}
{"_id": "mne_mne_viz/backends/_abstract.py_on_button_press_doc", "text": "Handle button presses.", "metadata": {}}
{"_id": "mne_mne_viz/backends/_abstract.py_clear_doc", "text": "Clear internal variables.", "metadata": {}}
{"_id": "mne_mne_viz/backends/_qt.py_minimum_doc", "text": "Get the minimum.", "metadata": {}}
{"_id": "mne_mne_viz/backends/_qt.py_setMinimum_doc", "text": "Set the minimum.", "metadata": {}}
{"_id": "mne_mne_viz/backends/_qt.py_maximum_doc", "text": "Get the maximum.", "metadata": {}}
{"_id": "mne_mne_viz/backends/_qt.py_setMaximum_doc", "text": "Set the maximum.", "metadata": {}}
{"_id": "mne_mne_viz/backends/_qt.py_value_doc", "text": "Get the current value.", "metadata": {}}
{"_id": "mne_mne_viz/backends/_qt.py_setValue_doc", "text": "Set the current value.", "metadata": {}}
{"_id": "mne_mne_viz/backends/_qt.py_mousePressEvent_doc", "text": "Add snap-to-location handling.", "metadata": {}}
{"_id": "mne_mne_viz/backends/_pyvista.py_visible_doc", "text": "Modify visibility attribute of the sensors.", "metadata": {}}
{"_id": "mne_mne_viz/eyetracking/heatmap.py_plot_gaze_doc", "text": "Plot a heatmap of eyetracking gaze data.\n\nParameters\n----------\nepochs : instance of Epochs\n    The :class:`~mne.Epochs` object containing eyegaze channels.\ncalibration : instance of Calibration | None\n    An instance of Calibration with information about the screen size, distance,\n    and resolution. If ``None``, you must provide a width and height.\nwidth : int\n    The width dimension of the plot canvas, only valid if eyegaze data are in\n    pixels. For example, if the participant screen resolution was 1920x1080, then\n    the width should be 1920.\nheight : int\n    The height dimension of the plot canvas, only valid if eyegaze data are in\n    pixels. For example, if the participant screen resolution was 1920x1080, then\n    the height should be 1080.\nsigma : float | None\n    The amount of Gaussian smoothing applied to the heatmap data (standard\n    deviation in pixels). If ``None``, no smoothing is applied. Default is 25.\n%(cmap)s\nalpha : float\n    The opacity of the heatmap (default is 1).\n%(vlim_plot_topomap)s\n%(axes_plot_topomap)s\n%(show)s\n\nReturns\n-------\nfig : instance of Figure\n    The resulting figure object for the heatmap plot.\n\nNotes\n-----\n.. versionadded:: 1.6", "metadata": {}}
{"_id": "mne_mne_viz/_brain/surface.py_load_geometry_doc", "text": "Load geometry of the surface.\n\nParameters\n----------\nNone\n\nReturns\n-------\nNone", "metadata": {}}
{"_id": "mne_mne_viz/_brain/surface.py_load_curvature_doc", "text": "Load in curvature values from the ?h.curv file.", "metadata": {}}
{"_id": "mne_mne_viz/_brain/_brain.py_setup_time_viewer_doc", "text": "Configure the time viewer parameters.\n\nParameters\n----------\ntime_viewer : bool\n    If True, enable widgets interaction. Defaults to True.\n\nshow_traces : bool\n    If True, enable visualization of time traces. Defaults to True.\n\nNotes\n-----\nThe keyboard shortcuts are the following:\n\n'?': Display help window\n'i': Toggle interface\n's': Apply auto-scaling\n'r': Restore original clim\n'c': Clear all traces\n'n': Shift the time forward by the playback speed\n'b': Shift the time backward by the playback speed\n'Space': Start/Pause playback\n'Up': Decrease camera elevation angle\n'Down': Increase camera elevation angle\n'Left': Decrease camera azimuth angle\n'Right': Increase camera azimuth angle", "metadata": {}}
{"_id": "mne_mne_viz/_brain/_brain.py_toggle_interface_doc", "text": "Toggle the interface.\n\nParameters\n----------\nvalue : bool | None\n    If True, the widgets are shown and if False, they\n    are hidden. If None, the state of the widgets is\n    toggled. Defaults to None.", "metadata": {}}
{"_id": "mne_mne_viz/_brain/_brain.py_apply_auto_scaling_doc", "text": "Detect automatically fitting scaling parameters.", "metadata": {}}
{"_id": "mne_mne_viz/_brain/_brain.py_restore_user_scaling_doc", "text": "Restore original scaling parameters.", "metadata": {}}
{"_id": "mne_mne_viz/_brain/_brain.py_toggle_playback_doc", "text": "Toggle time playback.\n\nParameters\n----------\nvalue : bool | None\n    If True, automatic time playback is enabled and if False,\n    it's disabled. If None, the state of time playback is toggled.\n    Defaults to None.", "metadata": {}}
{"_id": "mne_mne_viz/_brain/_brain.py_reset_doc", "text": "Reset view, current time and time step.", "metadata": {}}
{"_id": "mne_mne_viz/_brain/_brain.py_set_playback_speed_doc", "text": "Set the time playback speed.\n\nParameters\n----------\nspeed : float\n    The speed of the playback.", "metadata": {}}
{"_id": "mne_mne_viz/_brain/_brain.py_clear_glyphs_doc", "text": "Clear the picking glyphs.", "metadata": {}}
{"_id": "mne_mne_viz/_brain/_brain.py_plot_time_course_doc", "text": "Plot the vertex time course.\n\nParameters\n----------\nhemi : str\n    The hemisphere id of the vertex.\nvertex_id : int\n    The vertex identifier in the mesh.\ncolor : matplotlib color\n    The color of the time course.\n%(brain_update)s\n\nReturns\n-------\nline : matplotlib object\n    The time line object.", "metadata": {}}
{"_id": "mne_mne_viz/_brain/_brain.py_plot_time_line_doc", "text": "Add the time line to the MPL widget.\n\nParameters\n----------\n%(brain_update)s", "metadata": {}}
{"_id": "mne_mne_viz/_brain/_brain.py_help_doc", "text": "Display the help window.", "metadata": {}}
{"_id": "mne_mne_viz/_brain/_brain.py_interaction_doc", "text": "The interaction style.", "metadata": {}}
{"_id": "mne_mne_viz/_brain/_brain.py_interaction_doc", "text": "Set the interaction style.", "metadata": {}}
{"_id": "mne_mne_viz/_brain/_brain.py_add_data_doc", "text": "Display data from a numpy array on the surface or volume.\n\nThis provides a similar interface to PySurfer, but it displays\nit with a single colormap. It offers more flexibility over the\ncolormap, and provides a way to display four-dimensional data\n(i.e., a timecourse) or five-dimensional data (i.e., a\nvector-valued timecourse).\n\n.. note:: ``fmin`` sets the low end of the colormap, and is separate\n          from thresh (this is a different convention from PySurfer).\n\nParameters\n----------\narray : numpy array, shape (n_vertices[, 3][, n_times])\n    Data array. For the data to be understood as vector-valued\n    (3 values per vertex corresponding to X/Y/Z surface RAS),\n    then ``array`` must be have all 3 dimensions.\n    If vectors with no time dimension are desired, consider using a\n    singleton (e.g., ``np.newaxis``) to create a \"time\" dimension\n    and pass ``time_label=None`` (vector values are not supported).\n%(fmin_fmid_fmax)s\n%(thresh)s\n%(center)s\n%(transparent)s\ncolormap : str, list of color, or array\n    Name of matplotlib colormap to use, a list of matplotlib colors,\n    or a custom look up table (an n x 4 array coded with RBGA values\n    between 0 and 255), the default \"auto\" chooses a default divergent\n    colormap, if \"center\" is given (currently \"icefire\"), otherwise a\n    default sequential colormap (currently \"rocket\").\nalpha : float in [0, 1]\n    Alpha level to control opacity of the overlay.\nvertices : numpy array\n    Vertices for which the data is defined (needed if\n    ``len(data) < nvtx``).\nsmoothing_steps : int or None\n    Number of smoothing steps (smoothing is used if len(data) < nvtx)\n    The value 'nearest' can be used too. None (default) will use as\n    many as necessary to fill the surface.\ntime : numpy array\n    Time points in the data array (if data is 2D or 3D).\n%(time_label)s\ncolorbar : bool\n    Whether to add a colorbar to the figure. Can also be a tuple\n    to give the (row, col) index of where to put the colorbar.\nhemi : str | None\n    If None, it is assumed to belong to the hemisphere being\n    shown. If two hemispheres are being shown, an error will\n    be thrown.\nremove_existing : bool\n    Not supported yet.\n    Remove surface added by previous \"add_data\" call. Useful for\n    conserving memory when displaying different data in a loop.\ntime_label_size : int\n    Font size of the time label (default 14).\ninitial_time : float | None\n    Time initially shown in the plot. ``None`` to use the first time\n    sample (default).\nscale_factor : float | None (default)\n    The scale factor to use when displaying glyphs for vector-valued\n    data.\nvector_alpha : float | None\n    Alpha level to control opacity of the arrows. Only used for\n    vector-valued data. If None (default), ``alpha`` is used.\nclim : dict\n    Original clim arguments.\n%(src_volume_options)s\ncolorbar_kwargs : dict | None\n    Options to pass to ``pyvista.Plotter.add_scalar_bar``\n    (e.g., ``dict(title_font_size=10)``).\n%(verbose)s\n\nNotes\n-----\nIf the data is defined for a subset of vertices (specified\nby the \"vertices\" parameter), a smoothing method is used to interpolate\nthe data onto the high resolution surface. If the data is defined for\nsubsampled version of the surface, smoothing_steps can be set to None,\nin which case only as many smoothing steps are applied until the whole\nsurface is filled with non-zeros.\n\nDue to a VTK alpha rendering bug, ``vector_alpha`` is\nclamped to be strictly < 1.", "metadata": {}}
{"_id": "mne_mne_viz/_brain/_brain.py_remove_data_doc", "text": "Remove rendered data from the mesh.", "metadata": {}}
{"_id": "mne_mne_viz/_brain/_brain.py_remove_labels_doc", "text": "Remove all the ROI labels from the image.", "metadata": {}}
{"_id": "mne_mne_viz/_brain/_brain.py_remove_annotations_doc", "text": "Remove all annotations from the image.", "metadata": {}}
{"_id": "mne_mne_viz/_brain/_brain.py_add_label_doc", "text": "Add an ROI label to the image.\n\nParameters\n----------\nlabel : str | instance of Label\n    Label filepath or name. Can also be an instance of\n    an object with attributes \"hemi\", \"vertices\", \"name\", and\n    optionally \"color\" and \"values\" (if scalar_thresh is not None).\ncolor : matplotlib-style color | None\n    Anything matplotlib accepts: string, RGB, hex, etc. (default\n    \"crimson\").\nalpha : float in [0, 1]\n    Alpha level to control opacity.\nscalar_thresh : None | float\n    Threshold the label ids using this value in the label\n    file's scalar field (i.e. label only vertices with\n    scalar >= thresh).\nborders : bool | int\n    Show only label borders. If int, specify the number of steps\n    (away from the true border) along the cortical mesh to include\n    as part of the border definition.\nhemi : str | None\n    If None, it is assumed to belong to the hemisphere being\n    shown.\nsubdir : None | str\n    If a label is specified as name, subdir can be used to indicate\n    that the label file is in a sub-directory of the subject's\n    label directory rather than in the label directory itself (e.g.\n    for ``$SUBJECTS_DIR/$SUBJECT/label/aparc/lh.cuneus.label``\n    ``brain.add_label('cuneus', subdir='aparc')``).\n\nNotes\n-----\nTo remove previously added labels, run Brain.remove_labels().", "metadata": {}}
{"_id": "mne_mne_viz/_brain/_brain.py_add_forward_doc", "text": "Add a quiver to render positions of dipoles.\n\nParameters\n----------\n%(fwd)s\n%(trans_not_none)s\n%(alpha)s Default 1.\nscale : None | float\n    The size of the arrow representing the dipoles in\n    :class:`mne.viz.Brain` units. Default 1.5mm.\n\nNotes\n-----\n.. versionadded:: 1.0", "metadata": {}}
{"_id": "mne_mne_viz/_brain/_brain.py_remove_forward_doc", "text": "Remove forward sources from the rendered scene.", "metadata": {}}
{"_id": "mne_mne_viz/_brain/_brain.py_add_dipole_doc", "text": "Add a quiver to render positions of dipoles.\n\nParameters\n----------\ndipole : instance of Dipole\n    Dipole object containing position, orientation and amplitude of\n    one or more dipoles or in the forward solution.\n%(trans_not_none)s\ncolors : list | matplotlib-style color | None\n    A single color or list of anything matplotlib accepts:\n    string, RGB, hex, etc. Default red.\n%(alpha)s Default 1.\nscales : list | float | None\n    The size of the arrow representing the dipole in\n    :class:`mne.viz.Brain` units. Default 5mm.\nmode : \"2darrow\" | \"arrow\" | \"cone\" | \"cylinder\" | \"sphere\" | \"oct\"\n    The drawing mode for the dipole to render.\n    Defaults to ``\"arrow\"``.\n\nNotes\n-----\n.. versionadded:: 1.0", "metadata": {}}
{"_id": "mne_mne_viz/_brain/_brain.py_remove_dipole_doc", "text": "Remove dipole objects from the rendered scene.", "metadata": {}}
{"_id": "mne_mne_viz/_brain/_brain.py_add_head_doc", "text": "Add a mesh to render the outer head surface.\n\nParameters\n----------\ndense : bool\n    Whether to plot the dense head (``seghead``) or the less dense head\n    (``head``).\n%(color_matplotlib)s\n%(alpha)s\n\nNotes\n-----\n.. versionadded:: 0.24", "metadata": {}}
{"_id": "mne_mne_viz/_brain/_brain.py_remove_head_doc", "text": "Remove head objects from the rendered scene.", "metadata": {}}
{"_id": "mne_mne_viz/_brain/_brain.py_add_skull_doc", "text": "Add a mesh to render the skull surface.\n\nParameters\n----------\nouter : bool\n    Adds the outer skull if ``True``, otherwise adds the inner skull.\n%(color_matplotlib)s\n%(alpha)s\n\nNotes\n-----\n.. versionadded:: 0.24", "metadata": {}}
{"_id": "mne_mne_viz/_brain/_brain.py_remove_skull_doc", "text": "Remove skull objects from the rendered scene.", "metadata": {}}
{"_id": "mne_mne_viz/_brain/_brain.py_add_volume_labels_doc", "text": "Add labels to the rendering from an anatomical segmentation.\n\nParameters\n----------\n%(aseg)s\nlabels : list\n    Labeled regions of interest to plot. See\n    :func:`mne.get_montage_volume_labels`\n    for one way to determine regions of interest. Regions can also be\n    chosen from the :term:`FreeSurfer LUT`.\ncolors : list | matplotlib-style color | None\n    A list of anything matplotlib accepts: string, RGB, hex, etc.\n    (default :term:`FreeSurfer LUT` colors).\n%(alpha)s\n%(smooth)s\nfill_hole_size : int | None\n    The size of holes to remove in the mesh in voxels. Default is None,\n    no holes are removed. Warning, this dilates the boundaries of the\n    surface by ``fill_hole_size`` number of voxels so use the minimal\n    size.\nlegend : bool | None | dict\n    Add a legend displaying the names of the ``labels``. Default (None)\n    is ``True`` if the number of ``labels`` is 10 or fewer.\n    Can also be a dict of ``kwargs`` to pass to\n    ``pyvista.Plotter.add_legend``.\n\nNotes\n-----\n.. versionadded:: 0.24", "metadata": {}}
{"_id": "mne_mne_viz/_brain/_brain.py_remove_volume_labels_doc", "text": "Remove the volume labels from the rendered scene.", "metadata": {}}
{"_id": "mne_mne_viz/_brain/_brain.py_add_foci_doc", "text": "Add spherical foci, possibly mapping to displayed surf.\n\nThe foci spheres can be displayed at the coordinates given, or\nmapped through a surface geometry. In other words, coordinates\nfrom a volume-based analysis in MNI space can be displayed on an\ninflated average surface by finding the closest vertex on the\nwhite surface and mapping to that vertex on the inflated mesh.\n\nParameters\n----------\ncoords : ndarray, shape (n_coords, 3)\n    Coordinates in stereotaxic space (default) or array of\n    vertex ids (with ``coord_as_verts=True``).\ncoords_as_verts : bool\n    Whether the coords parameter should be interpreted as vertex ids.\nmap_surface : str | None\n    Surface to project the coordinates to, or None to use raw coords.\n    When set to a surface, each foci is positioned at the closest\n    vertex in the mesh.\nscale_factor : float\n    Controls the size of the foci spheres (relative to 1cm).\n%(color_matplotlib)s\n%(alpha)s Default is 1.\nname : str\n    Internal name to use.\nhemi : str | None\n    If None, it is assumed to belong to the hemisphere being\n    shown. If two hemispheres are being shown, an error will\n    be thrown.\nresolution : int\n    The resolution of the spheres.", "metadata": {}}
{"_id": "mne_mne_viz/_brain/_brain.py_add_sensors_doc", "text": "Add mesh objects to represent sensor positions.\n\nParameters\n----------\n%(info_not_none)s\n%(trans_not_none)s\n%(meg)s\n%(eeg)s\n%(fnirs)s\n%(ecog)s\n%(seeg)s\n%(dbs)s\n%(max_dist_ieeg)s\n%(sensor_colors)s\n\n    .. versionadded:: 1.6\n%(sensor_scales)s\n\n    .. versionadded:: 1.9\n%(verbose)s\n\nNotes\n-----\n.. versionadded:: 0.24", "metadata": {}}
{"_id": "mne_mne_viz/_brain/_brain.py_remove_sensors_doc", "text": "Remove sensors from the rendered scene.\n\nParameters\n----------\nkind : str | list | None\n    If None, removes all sensor-related data including the helmet.\n    Can be \"meg\", \"eeg\", \"fnirs\", \"ecog\", \"seeg\", \"dbs\" or \"helmet\"\n    to remove that item.", "metadata": {}}
{"_id": "mne_mne_viz/_brain/_brain.py_add_text_doc", "text": "Add a text to the visualization.\n\nParameters\n----------\nx : float\n    X coordinate.\ny : float\n    Y coordinate.\ntext : str\n    Text to add.\nname : str\n    Name of the text (text label can be updated using update_text()).\ncolor : tuple\n    Color of the text. Default is the foreground color set during\n    initialization (default is black or white depending on the\n    background color).\nopacity : float\n    Opacity of the text (default 1.0).\nrow : int | None\n    Row index of which brain to use. Default is the top row.\ncol : int | None\n    Column index of which brain to use. Default is the left-most\n    column.\nfont_size : float | None\n    The font size to use.\njustification : str | None\n    The text justification.", "metadata": {}}
{"_id": "mne_mne_viz/_brain/_brain.py_remove_text_doc", "text": "Remove text from the rendered scene.\n\nParameters\n----------\nname : str | None\n    Remove specific text by name. If None, all text will be removed.", "metadata": {}}
{"_id": "mne_mne_viz/_brain/_brain.py_add_annotation_doc", "text": "Add an annotation file.\n\nParameters\n----------\nannot : str | tuple\n    Either path to annotation file or annotation name. Alternatively,\n    the annotation can be specified as a ``(labels, ctab)`` tuple per\n    hemisphere, i.e. ``annot=(labels, ctab)`` for a single hemisphere\n    or ``annot=((lh_labels, lh_ctab), (rh_labels, rh_ctab))`` for both\n    hemispheres. ``labels`` and ``ctab`` should be arrays as returned\n    by :func:`nibabel.freesurfer.io.read_annot`.\nborders : bool | int\n    Show only label borders. If int, specify the number of steps\n    (away from the true border) along the cortical mesh to include\n    as part of the border definition.\n%(alpha)s Default is 1.\nhemi : str | None\n    If None, it is assumed to belong to the hemisphere being\n    shown. If two hemispheres are being shown, data must exist\n    for both hemispheres.\nremove_existing : bool\n    If True (default), remove old annotations.\ncolor : matplotlib-style color code\n    If used, show all annotations in the same (specified) color.\n    Probably useful only when showing annotation borders.", "metadata": {}}
{"_id": "mne_mne_viz/_brain/_brain.py_close_doc", "text": "Close all figures and cleanup data structure.", "metadata": {}}
{"_id": "mne_mne_viz/_brain/_brain.py_show_doc", "text": "Display the window.", "metadata": {}}
{"_id": "mne_mne_viz/_brain/_brain.py_get_view_doc", "text": "Get the camera orientation for a given subplot display.\n\nParameters\n----------\nrow : int\n    The row to use, default is the first one.\ncol : int\n    The column to check, the default is the first one.\n%(align_view)s\n\nReturns\n-------\n%(roll)s\n%(distance)s\n%(azimuth)s\n%(elevation)s\n%(focalpoint)s", "metadata": {}}
{"_id": "mne_mne_viz/_brain/_brain.py_show_view_doc", "text": "Orient camera to display view.\n\nParameters\n----------\n%(view)s\n%(roll)s\n%(distance)s\nrow : int | None\n    The row to set. Default all rows.\ncol : int | None\n    The column to set. Default all columns.\nhemi : str | None\n    Which hemi to use for view lookup (when in \"both\" mode).\n%(align_view)s\n%(azimuth)s\n%(elevation)s\n%(focalpoint)s\n%(brain_update)s\n\n    .. versionadded:: 1.6\n%(verbose)s\n\nNotes\n-----\nThe builtin string views are the following perspectives, based on the\n:term:`RAS` convention. If not otherwise noted, the view will have the\ntop of the brain (superior, +Z) in 3D space shown upward in the 2D\nperspective:\n\n``'lateral'``\n    From the left or right side such that the lateral (outside)\n    surface of the given hemisphere is visible.\n``'medial'``\n    From the left or right side such that the medial (inside)\n    surface of the given hemisphere is visible (at least when in split\n    or single-hemi mode).\n``'rostral'``\n    From the front.\n``'caudal'``\n    From the rear.\n``'dorsal'``\n    From above, with the front of the brain pointing up.\n``'ventral'``\n    From below, with the front of the brain pointing up.\n``'frontal'``\n    From the front and slightly lateral, with the brain slightly\n    tilted forward (yielding a view from slightly above).\n``'parietal'``\n    From the rear and slightly lateral, with the brain slightly tilted\n    backward (yielding a view from slightly above).\n``'axial'``\n    From above with the brain pointing up (same as ``'dorsal'``).\n``'sagittal'``\n    From the right side.\n``'coronal'``\n    From the rear.\n\nThree letter abbreviations (e.g., ``'lat'``) of all of the above are\nalso supported.", "metadata": {}}
{"_id": "mne_mne_viz/_brain/_brain.py_reset_view_doc", "text": "Reset the camera.", "metadata": {}}
{"_id": "mne_mne_viz/_brain/_brain.py_save_image_doc", "text": "Save view from all panels to disk.\n\nParameters\n----------\nfilename : path-like\n    Path to new image file.\nmode : str\n    Either ``'rgb'`` or ``'rgba'`` for values to return.", "metadata": {}}
{"_id": "mne_mne_viz/_brain/_brain.py_screenshot_doc", "text": "Generate a screenshot of current view.\n\nParameters\n----------\nmode : str\n    Either ``'rgb'`` or ``'rgba'`` for values to return.\n%(time_viewer_brain_screenshot)s\n\nReturns\n-------\nscreenshot : array\n    Image pixel values.", "metadata": {}}
{"_id": "mne_mne_viz/_brain/_brain.py_update_lut_doc", "text": "Update the range of the color map.\n\nParameters\n----------\n%(fmin_fmid_fmax)s\n%(alpha)s", "metadata": {}}
{"_id": "mne_mne_viz/_brain/_brain.py_set_data_smoothing_doc", "text": "Set the number of smoothing steps.\n\nParameters\n----------\nn_steps : int\n    Number of smoothing steps.", "metadata": {}}
{"_id": "mne_mne_viz/_brain/_brain.py_time_interpolation_doc", "text": "The interpolation mode.", "metadata": {}}
{"_id": "mne_mne_viz/_brain/_brain.py_set_time_interpolation_doc", "text": "Set the interpolation mode.\n\nParameters\n----------\n%(interpolation_brain_time)s", "metadata": {}}
{"_id": "mne_mne_viz/_brain/_brain.py_set_time_point_doc", "text": "Set the time point to display (can be a float to interpolate).\n\nParameters\n----------\ntime_idx : int | float\n    The time index to use. Can be a float to use interpolation\n    between indices.", "metadata": {}}
{"_id": "mne_mne_viz/_brain/_brain.py_set_time_doc", "text": "Set the time to display (in seconds).\n\nParameters\n----------\ntime : float\n    The time to show, in seconds.", "metadata": {}}
{"_id": "mne_mne_viz/_brain/_brain.py_data_doc", "text": "Data used by time viewer and color bar widgets.", "metadata": {}}
{"_id": "mne_mne_viz/_brain/_brain.py_save_movie_doc", "text": "Save a movie (for data with a time axis).\n\nThe movie is created through the :mod:`imageio` module. The format is\ndetermined by the extension, and additional options can be specified\nthrough keyword arguments that depend on the format, see\n:doc:`imageio's format page <imageio:formats/index>`.\n\n.. Warning::\n    This method assumes that time is specified in seconds when adding\n    data. If time is specified in milliseconds this will result in\n    movies 1000 times longer than expected.\n\nParameters\n----------\nfilename : str\n    Path at which to save the movie. The extension determines the\n    format (e.g., ``'*.mov'``, ``'*.gif'``, ...; see the :mod:`imageio`\n    documentation for available formats).\ntime_dilation : float\n    Factor by which to stretch time (default 4). For example, an epoch\n    from -100 to 600 ms lasts 700 ms. With ``time_dilation=4`` this\n    would result in a 2.8 s long movie.\ntmin : float\n    First time point to include (default: all data).\ntmax : float\n    Last time point to include (default: all data).\nframerate : float\n    Framerate of the movie (frames per second, default 24).\n%(interpolation_brain_time)s\n    If None, it uses the current ``brain.interpolation``,\n    which defaults to ``'nearest'``. Defaults to None.\ncodec : str | None\n    The codec to use.\nbitrate : float | None\n    The bitrate to use.\ncallback : callable | None\n    A function to call on each iteration. Useful for status message\n    updates. It will be passed keyword arguments ``frame`` and\n    ``n_frames``.\n%(time_viewer_brain_screenshot)s\n**kwargs : dict\n    Specify additional options for :mod:`imageio`.", "metadata": {}}
{"_id": "mne_mne_viz/_brain/_brain.py_get_picked_points_doc", "text": "Return the vertices of the picked points.\n\nReturns\n-------\npoints : list of int | None\n    The vertices picked by the time viewer.", "metadata": {}}
{"_id": "mne_mne_viz/_brain/colormap.py_create_lut_doc", "text": "Return a colormap suitable for setting as a LUT.", "metadata": {}}
{"_id": "mne_mne_viz/_brain/colormap.py_scale_sequential_lut_doc", "text": "Scale a sequential colormap.", "metadata": {}}
{"_id": "mne_mne_viz/_brain/colormap.py_get_fill_colors_doc", "text": "Get the fill colors for the middle of divergent colormaps.", "metadata": {}}
{"_id": "mne_mne_viz/_brain/colormap.py_calculate_lut_doc", "text": "Transparent color map calculation.\n\nA colormap may be sequential or divergent. When the colormap is\ndivergent indicate this by providing a value for 'center'. The\nmeanings of fmin, fmid and fmax are different for sequential and\ndivergent colormaps. A sequential colormap is characterised by::\n\n    [fmin, fmid, fmax]\n\nwhere fmin and fmax define the edges of the colormap and fmid\nwill be the value mapped to the center of the originally chosen colormap.\nA divergent colormap is characterised by::\n\n    [center-fmax, center-fmid, center-fmin, center,\n        center+fmin, center+fmid, center+fmax]\n\ni.e., values between center-fmin and center+fmin will not be shown\nwhile center-fmid will map to the fmid of the first half of the\noriginal colormap and center-fmid to the fmid of the second half.\n\nParameters\n----------\nlim_cmap : Colormap\n    Color map obtained from _process_mapdata.\nalpha : float\n    Alpha value to apply globally to the overlay. Has no effect with mpl\n    backend.\nfmin : float\n    Min value in colormap.\nfmid : float\n    Intermediate value in colormap.\nfmax : float\n    Max value in colormap.\ncenter : float or None\n    If not None, center of a divergent colormap, changes the meaning of\n    fmin, fmax and fmid.\ntransparent : boolean\n    if True: use a linear transparency between fmin and fmid and make\n    values below fmin fully transparent (symmetrically for divergent\n    colormaps)\n\nReturns\n-------\ncmap : matplotlib.ListedColormap\n    Color map with transparency channel.", "metadata": {}}
{"_id": "mne_mne_minimum_norm/resolution_matrix.py_make_inverse_resolution_matrix_doc", "text": "Compute resolution matrix for linear inverse operator.\n\nParameters\n----------\nforward : instance of Forward\n    Forward Operator.\ninverse_operator : instance of InverseOperator\n    Inverse operator.\nmethod : 'MNE' | 'dSPM' | 'sLORETA'\n    Inverse method to use (MNE, dSPM, sLORETA).\nlambda2 : float\n    The regularisation parameter.\n%(verbose)s\n\nReturns\n-------\nresmat: array, shape (n_orient_inv * n_dipoles, n_orient_fwd * n_dipoles)\n    Resolution matrix (inverse operator times forward operator).\n    The result of applying the inverse operator to the forward operator.\n    If source orientations are not fixed, all source components will be\n    computed (i.e. for n_orient_inv > 1 or n_orient_fwd > 1).\n    The columns of the resolution matrix are the point-spread functions\n    (PSFs) and the rows are the cross-talk functions (CTFs).", "metadata": {}}
{"_id": "mne_mne_minimum_norm/resolution_matrix.py_get_point_spread_doc", "text": "Get point-spread (PSFs) functions for vertices.\n\nParameters\n----------\nresmat : array, shape (n_dipoles, n_dipoles)\n    Forward Operator.\nsrc : instance of SourceSpaces | instance of InverseOperator | instance of Forward\n    Source space used to compute resolution matrix.\n    Must be an InverseOperator if ``vector=True`` and a surface\n    source space is used.\n%(idx_pctf)s\n%(mode_pctf)s\n%(n_comp_pctf_n)s\n%(norm_pctf)s\n%(return_pca_vars_pctf)s\n%(vector_pctf)s\n%(verbose)s\n\nReturns\n-------\n%(stcs_pctf)s\n%(pca_vars_pctf)s", "metadata": {}}
{"_id": "mne_mne_minimum_norm/resolution_matrix.py_get_cross_talk_doc", "text": "Get cross-talk (CTFs) function for vertices.\n\nParameters\n----------\nresmat : array, shape (n_dipoles, n_dipoles)\n    Forward Operator.\nsrc : instance of SourceSpaces | instance of InverseOperator | instance of Forward\n    Source space used to compute resolution matrix.\n    Must be an InverseOperator if ``vector=True`` and a surface\n    source space is used.\n%(idx_pctf)s\n%(mode_pctf)s\n%(n_comp_pctf_n)s\n%(norm_pctf)s\n%(return_pca_vars_pctf)s\n%(vector_pctf)s\n%(verbose)s\n\nReturns\n-------\n%(stcs_pctf)s\n%(pca_vars_pctf)s", "metadata": {}}
{"_id": "mne_mne_minimum_norm/inverse.py_read_inverse_operator_doc", "text": "Read the inverse operator decomposition from a FIF file.\n\nParameters\n----------\nfname : path-like\n    The name of the FIF file, which ends with ``-inv.fif`` or\n    ``-inv.fif.gz``.\n%(verbose)s\n\nReturns\n-------\ninv : instance of InverseOperator\n    The inverse operator.\n\nSee Also\n--------\nwrite_inverse_operator, make_inverse_operator", "metadata": {}}
{"_id": "mne_mne_minimum_norm/inverse.py_write_inverse_operator_doc", "text": "Write an inverse operator to a FIF file.\n\nParameters\n----------\nfname : path-like\n    The name of the FIF file, which ends with ``-inv.fif`` or\n    ``-inv.fif.gz``.\ninv : dict\n    The inverse operator.\n%(overwrite)s\n\n    .. versionadded:: 1.0\n%(verbose)s\n\nSee Also\n--------\nread_inverse_operator", "metadata": {}}
{"_id": "mne_mne_minimum_norm/inverse.py_combine_xyz_doc", "text": "Compute the three Cartesian components of a vector or matrix together.\n\nParameters\n----------\nvec : 2d array of shape [3 n x p]\n    Input [ x1 y1 z1 ... x_n y_n z_n ] where x1 ... z_n\n    can be vectors\n\nReturns\n-------\ncomb : array\n    Output vector [sqrt(x1^2+y1^2+z1^2), ..., sqrt(x_n^2+y_n^2+z_n^2)]", "metadata": {}}
{"_id": "mne_mne_minimum_norm/inverse.py_prepare_inverse_operator_doc", "text": "Prepare an inverse operator for actually computing the inverse.\n\nParameters\n----------\norig : dict\n    The inverse operator structure read from a file.\nnave : int\n    Number of averages (scales the noise covariance).\nlambda2 : float\n    The regularization factor. Recommended to be 1 / SNR**2.\nmethod : \"MNE\" | \"dSPM\" | \"sLORETA\" | \"eLORETA\"\n    Use minimum norm, dSPM (default), sLORETA, or eLORETA.\nmethod_params : dict | None\n    Additional options for eLORETA. See Notes of :func:`apply_inverse`.\n\n    .. versionadded:: 0.16\ncopy : bool | str\n    If True (default), copy the inverse. False will not copy.\n    Can be \"non-src\" to avoid copying the source space, which typically\n    is not modified and can be large in memory.\n\n    .. versionadded:: 0.21\n%(verbose)s\n\nReturns\n-------\ninv : instance of InverseOperator\n    Prepared inverse operator.", "metadata": {}}
{"_id": "mne_mne_minimum_norm/inverse.py_apply_inverse_doc", "text": "Apply inverse operator to evoked data.\n\nParameters\n----------\nevoked : Evoked object\n    Evoked data.\ninverse_operator : instance of InverseOperator\n    Inverse operator.\nlambda2 : float\n    The regularization parameter.\nmethod : \"MNE\" | \"dSPM\" | \"sLORETA\" | \"eLORETA\"\n    Use minimum norm :footcite:`HamalainenIlmoniemi1994`,\n    dSPM (default) :footcite:`DaleEtAl2000`,\n    sLORETA :footcite:`Pascual-Marqui2002`, or\n    eLORETA :footcite:`Pascual-Marqui2011`.\n%(pick_ori)s\nprepared : bool\n    If True, do not call :func:`prepare_inverse_operator`.\nlabel : Label | None\n    Restricts the source estimates to a given label. If None,\n    source estimates will be computed for the entire source space.\nmethod_params : dict | None\n    Additional options for eLORETA. See Notes for details.\n\n    .. versionadded:: 0.16\nreturn_residual : bool\n    If True (default False), return the residual evoked data.\n    Cannot be used with ``method=='eLORETA'``.\n\n    .. versionadded:: 0.17\n%(use_cps_restricted)s\n\n    .. versionadded:: 0.20\n%(verbose)s\n\nReturns\n-------\nstc : SourceEstimate | VectorSourceEstimate | VolSourceEstimate\n    The source estimates.\nresidual : instance of Evoked\n    The residual evoked data, only returned if return_residual is True.\n\nSee Also\n--------\napply_inverse_raw : Apply inverse operator to raw object.\napply_inverse_epochs : Apply inverse operator to epochs object.\napply_inverse_tfr_epochs : Apply inverse operator to epochs tfr object.\napply_inverse_cov : Apply inverse operator to covariance object.\n\nNotes\n-----\nCurrently only the ``method='eLORETA'`` has additional options.\nIt performs an iterative fit with a convergence criterion, so you can\npass a ``method_params`` :class:`dict` with string keys mapping to values\nfor:\n\n    'eps' : float\n        The convergence epsilon (default 1e-6).\n    'max_iter' : int\n        The maximum number of iterations (default 20).\n        If less regularization is applied, more iterations may be\n        necessary.\n    'force_equal' : bool\n        Force all eLORETA weights for each direction for a given\n        location equal. The default is None, which means ``True`` for\n        loose-orientation inverses and ``False`` for free- and\n        fixed-orientation inverses. See below.\n\nThe eLORETA paper :footcite:`Pascual-Marqui2011` defines how to compute\ninverses for fixed- and\nfree-orientation inverses. In the free orientation case, the X/Y/Z\norientation triplet for each location is effectively multiplied by a\n3x3 weight matrix. This is the behavior obtained with\n``force_equal=False`` parameter.\n\nHowever, other noise normalization methods (dSPM, sLORETA) multiply all\norientations for a given location by a single value.\nUsing ``force_equal=True`` mimics this behavior by modifying the iterative\nalgorithm to choose uniform weights (equivalent to a 3x3 diagonal matrix\nwith equal entries).\n\nIt is necessary to use ``force_equal=True``\nwith loose orientation inverses (e.g., ``loose=0.2``), otherwise the\nsolution resembles a free-orientation inverse (``loose=1.0``).\nIt is thus recommended to use ``force_equal=True`` for loose orientation\nand ``force_equal=False`` for free orientation inverses. This is the\nbehavior used when the parameter ``force_equal=None`` (default behavior).\n\nReferences\n----------\n.. footbibliography::", "metadata": {}}
{"_id": "mne_mne_minimum_norm/inverse.py_apply_inverse_raw_doc", "text": "Apply inverse operator to Raw data.\n\nParameters\n----------\nraw : Raw object\n    Raw data.\ninverse_operator : dict\n    Inverse operator.\nlambda2 : float\n    The regularization parameter.\nmethod : \"MNE\" | \"dSPM\" | \"sLORETA\" | \"eLORETA\"\n    Use minimum norm, dSPM (default), sLORETA, or eLORETA.\nlabel : Label | None\n    Restricts the source estimates to a given label. If None,\n    source estimates will be computed for the entire source space.\nstart : int\n    Index of first time sample (index not time is seconds).\nstop : int\n    Index of first time sample not to include (index not time is seconds).\nnave : int\n    Number of averages used to regularize the solution.\n    Set to 1 on raw data.\ntime_func : callable\n    Linear function applied to sensor space time series.\n%(pick_ori)s\nbuffer_size : int (or None)\n    If not None, the computation of the inverse and the combination of the\n    current components is performed in segments of length buffer_size\n    samples. While slightly slower, this is useful for long datasets as it\n    reduces the memory requirements by approx. a factor of 3 (assuming\n    buffer_size << data length).\n    Note that this setting has no effect for fixed-orientation inverse\n    operators.\nprepared : bool\n    If True, do not call :func:`prepare_inverse_operator`.\nmethod_params : dict | None\n    Additional options for eLORETA. See Notes of :func:`apply_inverse`.\n\n    .. versionadded:: 0.16\n%(use_cps_restricted)s\n\n    .. versionadded:: 0.20\n%(verbose)s\n\nReturns\n-------\nstc : SourceEstimate | VectorSourceEstimate | VolSourceEstimate\n    The source estimates.\n\nSee Also\n--------\napply_inverse : Apply inverse operator to evoked object.\napply_inverse_epochs : Apply inverse operator to epochs object.\napply_inverse_tfr_epochs : Apply inverse operator to epochs tfr object.\napply_inverse_cov : Apply inverse operator to covariance object.", "metadata": {}}
{"_id": "mne_mne_minimum_norm/inverse.py_apply_inverse_epochs_doc", "text": "Apply inverse operator to Epochs.\n\nParameters\n----------\nepochs : Epochs object\n    Single trial epochs.\ninverse_operator : dict\n    Inverse operator.\nlambda2 : float\n    The regularization parameter.\nmethod : \"MNE\" | \"dSPM\" | \"sLORETA\" | \"eLORETA\"\n    Use minimum norm, dSPM (default), sLORETA, or eLORETA.\nlabel : Label | None\n    Restricts the source estimates to a given label. If None,\n    source estimates will be computed for the entire source space.\nnave : int\n    Number of averages used to regularize the solution.\n    Set to 1 on single Epoch by default.\n%(pick_ori)s\nreturn_generator : bool\n    Return a generator object instead of a list. This allows iterating\n    over the stcs without having to keep them all in memory.\nprepared : bool\n    If True, do not call :func:`prepare_inverse_operator`.\nmethod_params : dict | None\n    Additional options for eLORETA. See Notes of :func:`apply_inverse`.\n\n    .. versionadded:: 0.16\n%(use_cps_restricted)s\n\n    .. versionadded:: 0.20\n%(verbose)s\n\nReturns\n-------\nstcs : list of (SourceEstimate | VectorSourceEstimate | VolSourceEstimate)\n    The source estimates for all epochs.\n\nSee Also\n--------\napply_inverse_raw : Apply inverse operator to raw object.\napply_inverse : Apply inverse operator to evoked object.\napply_inverse_tfr_epochs : Apply inverse operator to epochs tfr object.\napply_inverse_cov : Apply inverse operator to a covariance object.", "metadata": {}}
{"_id": "mne_mne_minimum_norm/inverse.py_apply_inverse_tfr_epochs_doc", "text": "Apply inverse operator to EpochsTFR.\n\nParameters\n----------\nepochs_tfr : EpochsTFR object\n    Single trial, phase-amplitude (complex-valued), time-frequency epochs.\ninverse_operator : list of dict | dict\n    The inverse operator for each frequency or a single inverse operator\n    to use for all frequencies.\nlambda2 : float\n    The regularization parameter.\nmethod : \"MNE\" | \"dSPM\" | \"sLORETA\" | \"eLORETA\"\n    Use minimum norm, dSPM (default), sLORETA, or eLORETA.\nlabel : Label | None\n    Restricts the source estimates to a given label. If None,\n    source estimates will be computed for the entire source space.\nnave : int\n    Number of averages used to regularize the solution.\n    Set to 1 on single Epoch by default.\n%(pick_ori)s\nreturn_generator : bool\n    Return a generator object instead of a list. This allows iterating\n    over the stcs without having to keep them all in memory.\nprepared : bool\n    If True, do not call :func:`prepare_inverse_operator`.\nmethod_params : dict | None\n    Additional options for eLORETA. See Notes of :func:`apply_inverse`.\n%(use_cps_restricted)s\n%(verbose)s\n\nReturns\n-------\nstcs : list of list of (SourceEstimate | VectorSourceEstimate | VolSourceEstimate)\n    The source estimates for all frequencies (outside list) and for\n    all epochs (inside list).\n\nSee Also\n--------\napply_inverse_raw : Apply inverse operator to raw object.\napply_inverse : Apply inverse operator to evoked object.\napply_inverse_epochs : Apply inverse operator to epochs object.\napply_inverse_cov : Apply inverse operator to a covariance object.", "metadata": {}}
{"_id": "mne_mne_minimum_norm/inverse.py_apply_inverse_cov_doc", "text": "Apply inverse operator to covariance data.\n\nParameters\n----------\ncov : instance of Covariance\n    Covariance data, computed on the time segment for which to compute\n    source power.\n%(info_not_none)s Used specify the channels to include.\ninverse_operator : instance of InverseOperator\n    Inverse operator.\nnave : int\n    Number of averages used to regularize the solution.\nlambda2 : float\n    The regularization parameter.\nmethod : \"MNE\" | \"dSPM\" | \"sLORETA\" | \"eLORETA\"\n    Use minimum norm, dSPM (default), sLORETA, or eLORETA.\n%(pick_ori_novec)s\nprepared : bool\n    If True, do not call :func:`prepare_inverse_operator`.\nlabel : Label | None\n    Restricts the source estimates to a given label. If None,\n    source estimates will be computed for the entire source space.\nmethod_params : dict | None\n    Additional options for eLORETA. See Notes for details.\n%(use_cps)s\n%(verbose)s\n\nReturns\n-------\nstc : SourceEstimate | VectorSourceEstimate | VolSourceEstimate\n    The source estimates.\n\nSee Also\n--------\napply_inverse : Apply inverse operator to evoked object.\napply_inverse_raw : Apply inverse operator to raw object.\napply_inverse_epochs : Apply inverse operator to epochs object.\napply_inverse_tfr_epochs : Apply inverse operator to epochs tfr object.\n\nNotes\n-----\n.. versionadded:: 0.20\n\nThis code is based on the original research code from\n:footcite:`Sabbagh2020` and has been useful to correct for individual field\nspread using source localization in the context of predictive modeling.\n\nReferences\n----------\n.. footbibliography::", "metadata": {}}
{"_id": "mne_mne_minimum_norm/inverse.py_make_inverse_operator_doc", "text": "Assemble inverse operator.\n\nParameters\n----------\n%(info_not_none)s\n    Specifies the channels to include. Bad channels (in ``info['bads']``)\n    are not used.\nforward : instance of Forward\n    Forward operator. See :func:`~mne.make_forward_solution` to create the operator.\nnoise_cov : instance of Covariance\n    The noise covariance matrix. See :func:`~mne.compute_raw_covariance` and\n    :func:`~mne.compute_covariance` to compute the noise covariance matrix on\n    :class:`~mne.io.Raw` and :class:`~mne.Epochs` respectively.\n%(loose)s\n%(depth)s\nfixed : bool | 'auto'\n    Use fixed source orientations normal to the cortical mantle. If True,\n    the loose parameter must be ``\"auto\"`` or ``0``. If ``'auto'``, the loose value\n    is used.\n%(rank_none)s\n%(use_cps)s\n%(verbose)s\n\nReturns\n-------\ninv : instance of InverseOperator\n    Inverse operator.\n\nNotes\n-----\nFor different sets of options (**loose**, **depth**, **fixed**) to work,\nthe forward operator must have been loaded using a certain configuration\n(i.e., with **force_fixed** and **surf_ori** set appropriately). For\nexample, given the desired inverse type (with representative choices\nof **loose** = 0.2 and **depth** = 0.8 shown in the table in various\nplaces, as these are the defaults for those parameters):\n\n    +---------------------+-----------+-----------+-----------+-----------------+--------------+\n    | Inverse desired                             | Forward parameters allowed                 |\n    +=====================+===========+===========+===========+=================+==============+\n    |                     | **loose** | **depth** | **fixed** | **force_fixed** | **surf_ori** |\n    +---------------------+-----------+-----------+-----------+-----------------+--------------+\n    | | Loose constraint, | 0.2       | 0.8       | False     | False           | True         |\n    | | Depth weighted    |           |           |           |                 |              |\n    +---------------------+-----------+-----------+-----------+-----------------+--------------+\n    | | Loose constraint  | 0.2       | None      | False     | False           | True         |\n    +---------------------+-----------+-----------+-----------+-----------------+--------------+\n    | | Free orientation, | 1.0       | 0.8       | False     | False           | True         |\n    | | Depth weighted    |           |           |           |                 |              |\n    +---------------------+-----------+-----------+-----------+-----------------+--------------+\n    | | Free orientation  | 1.0       | None      | False     | False           | True | False |\n    +---------------------+-----------+-----------+-----------+-----------------+--------------+\n    | | Fixed constraint, | 0.0       | 0.8       | True      | False           | True         |\n    | | Depth weighted    |           |           |           |                 |              |\n    +---------------------+-----------+-----------+-----------+-----------------+--------------+\n    | | Fixed constraint  | 0.0       | None      | True      | True            | True         |\n    +---------------------+-----------+-----------+-----------+-----------------+--------------+\n\nAlso note that, if the source space (as stored in the forward solution)\nhas patch statistics computed, these are used to improve the depth\nweighting. Thus slightly different results are to be expected with\nand without this information.\n\nFor depth weighting, 0.8 is generally good for MEG, and between 2 and 5\nis good for EEG, see :footcite:t:`LinEtAl2006a`.\n\nReferences\n----------\n.. footbibliography::", "metadata": {}}
{"_id": "mne_mne_minimum_norm/inverse.py_compute_rank_inverse_doc", "text": "Compute the rank of a linear inverse operator (MNE, dSPM, etc.).\n\nParameters\n----------\ninv : instance of InverseOperator\n    The inverse operator.\n\nReturns\n-------\nrank : int\n    The rank of the inverse operator.", "metadata": {}}
{"_id": "mne_mne_minimum_norm/inverse.py_estimate_snr_doc", "text": "Estimate the SNR as a function of time for evoked data.\n\nParameters\n----------\nevoked : instance of Evoked\n    Evoked instance.\ninv : instance of InverseOperator\n    The inverse operator.\n%(verbose)s\n\nReturns\n-------\nsnr : ndarray, shape (n_times,)\n    The SNR estimated from the whitened data (i.e., GFP of whitened data).\nsnr_est : ndarray, shape (n_times,)\n    The SNR estimated using the mismatch between the unregularized\n    solution and the regularized solution.\n\nNotes\n-----\n``snr_est`` is estimated by using different amounts of inverse\nregularization and checking the mismatch between predicted and\nmeasured whitened data.\n\nIn more detail, given our whitened inverse obtained from SVD:\n\n.. math::\n\n    \\tilde{M} = R^\\frac{1}{2}V\\Gamma U^T\n\nThe values in the diagonal matrix :math:`\\Gamma` are expressed in terms\nof the chosen regularization :math:`\\lambda^2 \\sim 1/\\rm{SNR}^2`\nand singular values :math:`\\lambda_k` as:\n\n.. math::\n\n    \\gamma_k = \\frac{1}{\\lambda_k}\\frac{\\lambda_k^2}{\\lambda_k^2 + \\lambda^2}\n\nWe also know that our predicted data is given by:\n\n.. math::\n\n    \\hat{x}(t) = G\\hat{j}(t)=C^\\frac{1}{2}U\\Pi w(t)\n\nAnd thus our predicted whitened data is just:\n\n.. math::\n\n    \\hat{w}(t) = U\\Pi w(t)\n\nWhere :math:`\\Pi` is diagonal with entries entries:\n\n.. math::\n\n    \\lambda_k\\gamma_k = \\frac{\\lambda_k^2}{\\lambda_k^2 + \\lambda^2}\n\nIf we use no regularization, note that :math:`\\Pi` is just the\nidentity matrix. Here we test the squared magnitude of the difference\nbetween unregularized solution and regularized solutions, choosing the\nbiggest regularization that achieves a :math:`\\chi^2`-test significance\nof 0.001.\n\n.. versionadded:: 0.9.0", "metadata": {}}
{"_id": "mne_mne_minimum_norm/inverse.py_copy_doc", "text": "Return a copy of the InverseOperator.", "metadata": {}}
{"_id": "mne_mne_minimum_norm/inverse.py_ch_names_doc", "text": "Name of channels attached to the inverse operator.", "metadata": {}}
{"_id": "mne_mne_minimum_norm/inverse.py_info_doc", "text": ":class:`~mne.Info` attached to the inverse operator.", "metadata": {}}
{"_id": "mne_mne_minimum_norm/spatial_resolution.py_resolution_metrics_doc", "text": "Compute spatial resolution metrics for linear solvers.\n\nParameters\n----------\nresmat : array, shape (n_orient * n_vertices, n_vertices)\n    The resolution matrix.\n    If not a square matrix and if the number of rows is a multiple of\n    number of columns (e.g. free or loose orientations), then the Euclidean\n    length per source location is computed (e.g. if inverse operator with\n    free orientations was applied to forward solution with fixed\n    orientations).\nsrc : instance of SourceSpaces\n    Source space object from forward or inverse operator.\nfunction : 'psf' | 'ctf'\n    Whether to compute metrics for columns (point-spread functions, PSFs)\n    or rows (cross-talk functions, CTFs) of the resolution matrix.\nmetric : str\n    The resolution metric to compute. Allowed options are:\n\n    Localization-based metrics:\n\n    - ``'peak_err'`` Peak localization error (PLE), Euclidean distance\n      between peak and true source location.\n    - ``'cog_err'`` Centre-of-gravity localisation error (CoG), Euclidean\n      distance between CoG and true source location.\n\n    Spatial-extent-based metrics:\n\n    - ``'sd_ext'`` Spatial deviation\n      (e.g. :footcite:`MolinsEtAl2008,HaukEtAl2019`).\n    - ``'maxrad_ext'`` Maximum radius to 50%% of max amplitude.\n\n    Amplitude-based metrics:\n\n    - ``'peak_amp'`` Ratio between absolute maximum amplitudes of peaks\n      per location and maximum peak across locations.\n    - ``'sum_amp'`` Ratio between sums of absolute amplitudes.\n\nthreshold : float\n    Amplitude fraction threshold for spatial extent metric 'maxrad_ext'.\n    Defaults to 0.5.\n%(verbose)s\n\nReturns\n-------\nresolution_metric : instance of SourceEstimate\n    The resolution metric.\n\nNotes\n-----\nFor details, see :footcite:`MolinsEtAl2008,HaukEtAl2019`.\n\n.. versionadded:: 0.20\n\nReferences\n----------\n.. footbibliography::", "metadata": {}}
{"_id": "mne_mne_minimum_norm/time_frequency.py_source_band_induced_power_doc", "text": "Compute source space induced power in given frequency bands.\n\nParameters\n----------\nepochs : instance of Epochs\n    The epochs.\ninverse_operator : instance of InverseOperator\n    The inverse operator.\nbands : dict\n    Example : bands = dict(alpha=[8, 9]).\nlabel : Label | list of Label\n    Restricts the source estimates to a given label or list of labels. If\n    labels are provided in a list, power will be averaged over vertices.\nlambda2 : float\n    The regularization parameter of the minimum norm.\nmethod : \"MNE\" | \"dSPM\" | \"sLORETA\" | \"eLORETA\"\n    Use minimum norm, dSPM (default), sLORETA, or eLORETA.\nnave : int\n    The number of averages used to scale the noise covariance matrix.\nn_cycles : float | array of float\n    Number of cycles. Fixed number or one per frequency.\ndf : float\n    Delta frequency within bands.\nuse_fft : bool\n    Do convolutions in time or frequency domain with FFT.\ndecim : int\n    Temporal decimation factor.\nbaseline : None (default) or tuple, shape (2,)\n    The time interval to apply baseline correction. If None do not apply\n    it. If baseline is (a, b) the interval is between \"a (s)\" and \"b (s)\".\n    If a is None the beginning of the data is used and if b is None then b\n    is set to the end of the interval. If baseline is equal to (None, None)\n    all the time interval is used.\nbaseline_mode : 'mean' | 'ratio' | 'logratio' | 'percent' | 'zscore' | 'zlogratio'\n    Perform baseline correction by\n\n    - subtracting the mean of baseline values ('mean')\n    - dividing by the mean of baseline values ('ratio')\n    - dividing by the mean of baseline values and taking the log\n      ('logratio')\n    - subtracting the mean of baseline values followed by dividing by\n      the mean of baseline values ('percent')\n    - subtracting the mean of baseline values and dividing by the\n      standard deviation of baseline values ('zscore')\n    - dividing by the mean of baseline values, taking the log, and\n      dividing by the standard deviation of log baseline values\n      ('zlogratio')\n\npca : bool\n    If True, the true dimension of data is estimated before running\n    the time-frequency transforms. It reduces the computation times\n    e.g. with a dataset that was maxfiltered (true dim is 64).\n%(n_jobs)s\nprepared : bool\n    If True, do not call :func:`prepare_inverse_operator`.\nmethod_params : dict | None\n    Additional options for eLORETA. See Notes of :func:`apply_inverse`.\n\n    .. versionadded:: 0.16\n%(use_cps_restricted)s\n\n    .. versionadded:: 0.20\n%(verbose)s\n\nReturns\n-------\nstcs : dict of SourceEstimate (or VolSourceEstimate)\n    The estimated source space induced power estimates in shape\n    (n_vertices, n_frequencies, n_samples) if label=None or label=label.\n    For lists of one or more labels, the induced power estimate has shape\n    (n_labels, n_frequencies, n_samples).", "metadata": {}}
{"_id": "mne_mne_minimum_norm/time_frequency.py_source_induced_power_doc", "text": "Compute induced power and phase lock.\n\nComputation can optionally be restricted in a label.\n\nParameters\n----------\nepochs : instance of Epochs\n    The epochs.\ninverse_operator : instance of InverseOperator\n    The inverse operator.\nfreqs : array\n    Array of frequencies of interest.\nlabel : Label | list of Label\n    Restricts the source estimates to a given label or list of labels. If\n    labels are provided in a list, power will be averaged over vertices within each\n    label.\nlambda2 : float\n    The regularization parameter of the minimum norm.\nmethod : \"MNE\" | \"dSPM\" | \"sLORETA\" | \"eLORETA\"\n    Use minimum norm, dSPM (default), sLORETA, or eLORETA.\nnave : int\n    The number of averages used to scale the noise covariance matrix.\nn_cycles : float | array of float\n    Number of cycles. Fixed number or one per frequency.\ndecim : int\n    Temporal decimation factor.\nuse_fft : bool\n    Do convolutions in time or frequency domain with FFT.\npick_ori : None | \"normal\"\n    If \"normal\", rather than pooling the orientations by taking the norm,\n    only the radial component is kept. This is only implemented\n    when working with loose orientations.\nbaseline : None (default) or tuple of length 2\n    The time interval to apply baseline correction.\n    If None do not apply it. If baseline is (a, b)\n    the interval is between \"a (s)\" and \"b (s)\".\n    If a is None the beginning of the data is used\n    and if b is None then b is set to the end of the interval.\n    If baseline is equal to (None, None) all the time\n    interval is used.\nbaseline_mode : 'mean' | 'ratio' | 'logratio' | 'percent' | 'zscore' | 'zlogratio'\n    Perform baseline correction by\n\n    - subtracting the mean of baseline values ('mean')\n    - dividing by the mean of baseline values ('ratio')\n    - dividing by the mean of baseline values and taking the log\n      ('logratio')\n    - subtracting the mean of baseline values followed by dividing by\n      the mean of baseline values ('percent')\n    - subtracting the mean of baseline values and dividing by the\n      standard deviation of baseline values ('zscore')\n    - dividing by the mean of baseline values, taking the log, and\n      dividing by the standard deviation of log baseline values\n      ('zlogratio')\n\npca : bool\n    If True, the true dimension of data is estimated before running\n    the time-frequency transforms. It reduces the computation times\n    e.g. with a dataset that was maxfiltered (true dim is 64).\n%(n_jobs)s\nreturn_plv : bool\n    If True, return the phase-locking value array. Else, only return power.\n\n    .. versionadded:: 1.6\nzero_mean : bool\n    Make sure the wavelets are zero mean.\nprepared : bool\n    If True, do not call :func:`prepare_inverse_operator`.\nmethod_params : dict | None\n    Additional options for eLORETA. See Notes of :func:`apply_inverse`.\n%(use_cps_restricted)s\n\n    .. versionadded:: 0.20\n%(verbose)s\n\nReturns\n-------\npower : array\n    The induced power array with shape (n_sources, n_freqs, n_samples) if\n    label=None or label=label. For lists of one or more labels, the induced\n    power estimate has shape (n_labels, n_frequencies, n_samples).\nplv : array\n    The phase-locking value array with shape (n_sources, n_freqs,\n    n_samples). Only returned if ``return_plv=True``.", "metadata": {}}
{"_id": "mne_mne_minimum_norm/time_frequency.py_compute_source_psd_doc", "text": "Compute source power spectral density (PSD).\n\nParameters\n----------\nraw : instance of Raw\n    The raw data.\ninverse_operator : instance of InverseOperator\n    The inverse operator.\nlambda2 : float\n    The regularization parameter.\nmethod : \"MNE\" | \"dSPM\" | \"sLORETA\"\n    Use minimum norm, dSPM (default), sLORETA, or eLORETA.\ntmin : float\n    The beginning of the time interval of interest (in seconds).\n    Use 0. for the beginning of the file.\ntmax : float | None\n    The end of the time interval of interest (in seconds). If None\n    stop at the end of the file.\nfmin : float\n    The lower frequency of interest.\nfmax : float\n    The upper frequency of interest.\nn_fft : int\n    Window size for the FFT. Should be a power of 2.\noverlap : float\n    The overlap fraction between windows. Should be between 0 and 1.\n    0 means no overlap.\npick_ori : None | \"normal\"\n    If \"normal\", rather than pooling the orientations by taking the norm,\n    only the radial component is kept. This is only implemented\n    when working with loose orientations.\nlabel : Label\n    Restricts the source estimates to a given label.\nnave : int\n    The number of averages used to scale the noise covariance matrix.\npca : bool\n    If True, the true dimension of data is estimated before running\n    the time-frequency transforms. It reduces the computation times\n    e.g. with a dataset that was maxfiltered (true dim is 64).\nprepared : bool\n    If True, do not call :func:`prepare_inverse_operator`.\nmethod_params : dict | None\n    Additional options for eLORETA. See Notes of :func:`apply_inverse`.\n\n    .. versionadded:: 0.16\ninv_split : int or None\n    Split inverse operator into inv_split parts in order to save memory.\n\n    .. versionadded:: 0.17\nbandwidth : float | str\n    The bandwidth of the multi taper windowing function in Hz.\n    Can also be a string (e.g., 'hann') to use a single window.\n\n    For backward compatibility, the default is 'hann'.\n\n    .. versionadded:: 0.17\nadaptive : bool\n    Use adaptive weights to combine the tapered spectra into PSD\n    (slow, use n_jobs >> 1 to speed up computation).\n\n    .. versionadded:: 0.17\nlow_bias : bool\n    Only use tapers with more than 90%% spectral concentration within\n    bandwidth.\n\n    .. versionadded:: 0.17\n%(n_jobs)s\n    It is only used if adaptive=True.\n\n    .. versionadded:: 0.17\nreturn_sensor : bool\n    If True, return the sensor PSDs as an EvokedArray.\n\n    .. versionadded:: 0.17\ndB : bool\n    If True (default False), return output it decibels.\n\n    .. versionadded:: 0.17\n%(verbose)s\n\nReturns\n-------\nstc_psd : instance of SourceEstimate | VolSourceEstimate\n    The PSD of each of the sources.\nsensor_psd : instance of EvokedArray\n    The PSD of each sensor. Only returned if ``return_sensor`` is True.\n\nSee Also\n--------\ncompute_source_psd_epochs\n\nNotes\n-----\nEach window is multiplied by a window before processing, so\nusing a non-zero overlap is recommended.\n\nThis function is different from :func:`compute_source_psd_epochs` in that:\n\n1. ``bandwidth='hann'`` by default, skipping multitaper estimation\n2. For convenience it wraps\n   :func:`mne.make_fixed_length_events` and :class:`mne.Epochs`.\n\nOtherwise the two should produce identical results.", "metadata": {}}
{"_id": "mne_mne_minimum_norm/time_frequency.py_compute_source_psd_epochs_doc", "text": "Compute source power spectral density (PSD) from Epochs.\n\nThis uses the multi-taper method to compute the PSD for each epoch.\n\nParameters\n----------\nepochs : instance of Epochs\n    The raw data.\ninverse_operator : instance of InverseOperator\n    The inverse operator.\nlambda2 : float\n    The regularization parameter.\nmethod : \"MNE\" | \"dSPM\" | \"sLORETA\" | \"eLORETA\"\n    Use minimum norm, dSPM (default), sLORETA, or eLORETA.\nfmin : float\n    The lower frequency of interest.\nfmax : float\n    The upper frequency of interest.\npick_ori : None | \"normal\"\n    If \"normal\", rather than pooling the orientations by taking the norm,\n    only the radial component is kept. This is only implemented\n    when working with loose orientations.\nlabel : Label\n    Restricts the source estimates to a given label.\nnave : int\n    The number of averages used to scale the noise covariance matrix.\npca : bool\n    If True, the true dimension of data is estimated before running\n    the time-frequency transforms. It reduces the computation times\n    e.g. with a dataset that was maxfiltered (true dim is 64).\ninv_split : int or None\n    Split inverse operator into inv_split parts in order to save memory.\nbandwidth : float | str\n    The bandwidth of the multi taper windowing function in Hz.\n    Can also be a string (e.g., 'hann') to use a single window.\nadaptive : bool\n    Use adaptive weights to combine the tapered spectra into PSD\n    (slow, use n_jobs >> 1 to speed up computation).\nlow_bias : bool\n    Only use tapers with more than 90%% spectral concentration within\n    bandwidth.\nreturn_generator : bool\n    Return a generator object instead of a list. This allows iterating\n    over the stcs without having to keep them all in memory.\n%(n_jobs)s\n    It is only used if adaptive=True.\nprepared : bool\n    If True, do not call :func:`prepare_inverse_operator`.\nmethod_params : dict | None\n    Additional options for eLORETA. See Notes of :func:`apply_inverse`.\n\n    .. versionadded:: 0.16\nreturn_sensor : bool\n    If True, also return the sensor PSD for each epoch as an EvokedArray.\n\n    .. versionadded:: 0.17\n%(use_cps_restricted)s\n\n    .. versionadded:: 0.20\n%(verbose)s\n\nReturns\n-------\nout : list (or generator object)\n    A list (or generator) for the source space PSD (and optionally the\n    sensor PSD) for each epoch.\n\nSee Also\n--------\ncompute_source_psd", "metadata": {}}
{"_id": "mne_mne_decoding/time_frequency.py_fit_transform_doc", "text": "Time-frequency transform of times series along the last axis.\n\nParameters\n----------\nX : array, shape (n_samples, n_channels, n_times)\n    The training data samples. The channel dimension can be zero- or\n    1-dimensional.\ny : None\n    For scikit-learn compatibility purposes.\n\nReturns\n-------\nXt : array, shape (n_samples, n_channels, n_freqs, n_times)\n    The time-frequency transform of the data, where n_channels can be\n    zero- or 1-dimensional.", "metadata": {}}
{"_id": "mne_mne_decoding/time_frequency.py_fit_doc", "text": "Do nothing (for scikit-learn compatibility purposes).\n\nParameters\n----------\nX : array, shape (n_samples, n_channels, n_times)\n    The training data.\ny : array | None\n    The target values.\n\nReturns\n-------\nself : object\n    Return self.", "metadata": {}}
{"_id": "mne_mne_decoding/time_frequency.py_transform_doc", "text": "Time-frequency transform of times series along the last axis.\n\nParameters\n----------\nX : array, shape (n_samples, [n_channels, ]n_times)\n    The training data samples. The channel dimension can be zero- or\n    1-dimensional.\n\nReturns\n-------\nXt : array, shape (n_samples, [n_channels, ]n_freqs, n_times)\n    The time-frequency transform of the data, where n_channels can be\n    zero- or 1-dimensional.", "metadata": {}}
{"_id": "mne_mne_decoding/receptive_field.py_fit_doc", "text": "Fit a receptive field model.\n\nParameters\n----------\nX : array, shape (n_times[, n_epochs], n_features)\n    The input features for the model.\ny : array, shape (n_times[, n_epochs][, n_outputs])\n    The output features for the model.\n\nReturns\n-------\nself : instance\n    The instance so you can chain operations.", "metadata": {}}
{"_id": "mne_mne_decoding/receptive_field.py_predict_doc", "text": "Generate predictions with a receptive field.\n\nParameters\n----------\nX : array, shape (n_times[, n_epochs], n_channels)\n    The input features for the model.\n\nReturns\n-------\ny_pred : array, shape (n_times[, n_epochs][, n_outputs])\n    The output predictions. \"Note that valid samples (those\n    unaffected by edge artifacts during the time delaying step) can\n    be obtained using ``y_pred[rf.valid_samples_]``.", "metadata": {}}
{"_id": "mne_mne_decoding/receptive_field.py_score_doc", "text": "Score predictions generated with a receptive field.\n\nThis calls ``self.predict``, then masks the output of this\nand ``y` with ``self.valid_samples_``. Finally, it passes\nthis to a :mod:`sklearn.metrics` scorer.\n\nParameters\n----------\nX : array, shape (n_times[, n_epochs], n_channels)\n    The input features for the model.\ny : array, shape (n_times[, n_epochs][, n_outputs])\n    Used for scikit-learn compatibility.\n\nReturns\n-------\nscores : list of float, shape (n_outputs,)\n    The scores estimated by the model for each output (e.g. mean\n    R2 of ``predict(X)``).", "metadata": {}}
{"_id": "mne_mne_decoding/search_light.py_fit_doc", "text": "Fit a series of independent estimators to the dataset.\n\nParameters\n----------\nX : array, shape (n_samples, nd_features, n_tasks)\n    The training input samples. For each data slice, a clone estimator\n    is fitted independently. The feature dimension can be\n    multidimensional e.g.\n    X.shape = (n_samples, n_features_1, n_features_2, n_tasks).\ny : array, shape (n_samples,) | (n_samples, n_targets)\n    The target values.\n**fit_params : dict of string -> object\n    Parameters to pass to the fit method of the estimator.\n\nReturns\n-------\nself : object\n    Return self.", "metadata": {}}
{"_id": "mne_mne_decoding/search_light.py_fit_transform_doc", "text": "Fit and transform a series of independent estimators to the dataset.\n\nParameters\n----------\nX : array, shape (n_samples, nd_features, n_tasks)\n    The training input samples. For each task, a clone estimator\n    is fitted independently. The feature dimension can be\n    multidimensional, e.g.::\n\n        X.shape = (n_samples, n_features_1, n_features_2, n_estimators)\ny : array, shape (n_samples,) | (n_samples, n_targets)\n    The target values.\n**fit_params : dict of string -> object\n    Parameters to pass to the fit method of the estimator.\n\nReturns\n-------\ny_pred : array, shape (n_samples, n_tasks) | (n_samples, n_tasks, n_targets)\n    The predicted values for each estimator.", "metadata": {}}
{"_id": "mne_mne_decoding/search_light.py_transform_doc", "text": "Transform each data slice/task with a series of independent estimators.\n\nThe number of tasks in X should match the number of tasks/estimators\ngiven at fit time.\n\nParameters\n----------\nX : array, shape (n_samples, nd_features, n_tasks)\n    The input samples. For each data slice/task, the corresponding\n    estimator makes a transformation of the data, e.g.\n    ``[estimators[ii].transform(X[..., ii]) for ii in range(n_estimators)]``.\n    The feature dimension can be multidimensional e.g.\n    X.shape = (n_samples, n_features_1, n_features_2, n_tasks).\n\nReturns\n-------\nXt : array, shape (n_samples, n_estimators)\n    The transformed values generated by each estimator.", "metadata": {}}
{"_id": "mne_mne_decoding/search_light.py_predict_doc", "text": "Predict each data slice/task with a series of independent estimators.\n\nThe number of tasks in X should match the number of tasks/estimators\ngiven at fit time.\n\nParameters\n----------\nX : array, shape (n_samples, nd_features, n_tasks)\n    The input samples. For each data slice, the corresponding estimator\n    makes the sample predictions, e.g.:\n    ``[estimators[ii].predict(X[..., ii]) for ii in range(n_estimators)]``.\n    The feature dimension can be multidimensional e.g.\n    X.shape = (n_samples, n_features_1, n_features_2, n_tasks).\n\nReturns\n-------\ny_pred : array, shape (n_samples, n_estimators) | (n_samples, n_tasks, n_targets)\n    Predicted values for each estimator/data slice.", "metadata": {}}
{"_id": "mne_mne_decoding/search_light.py_predict_proba_doc", "text": "Predict each data slice with a series of independent estimators.\n\nThe number of tasks in X should match the number of tasks/estimators\ngiven at fit time.\n\nParameters\n----------\nX : array, shape (n_samples, nd_features, n_tasks)\n    The input samples. For each data slice, the corresponding estimator\n    makes the sample probabilistic predictions, e.g.:\n    ``[estimators[ii].predict_proba(X[..., ii]) for ii in range(n_estimators)]``.\n    The feature dimension can be multidimensional e.g.\n    X.shape = (n_samples, n_features_1, n_features_2, n_tasks).\n\nReturns\n-------\ny_pred : array, shape (n_samples, n_tasks, n_classes)\n    Predicted probabilities for each estimator/data slice/task.", "metadata": {}}
{"_id": "mne_mne_decoding/search_light.py_decision_function_doc", "text": "Estimate distances of each data slice to the hyperplanes.\n\nParameters\n----------\nX : array, shape (n_samples, nd_features, n_tasks)\n    The input samples. For each data slice, the corresponding estimator\n    outputs the distance to the hyperplane, e.g.:\n    ``[estimators[ii].decision_function(X[..., ii]) for ii in range(n_estimators)]``.\n    The feature dimension can be multidimensional e.g.\n    X.shape = (n_samples, n_features_1, n_features_2, n_estimators).\n\nReturns\n-------\ny_pred : array, shape (n_samples, n_estimators, n_classes * (n_classes-1) // 2)\n    Predicted distances for each estimator/data slice.\n\nNotes\n-----\nThis requires base_estimator to have a ``decision_function`` method.", "metadata": {}}
{"_id": "mne_mne_decoding/search_light.py_score_doc", "text": "Score each estimator on each task.\n\nThe number of tasks in X should match the number of tasks/estimators\ngiven at fit time, i.e. we need\n``X.shape[-1] == len(self.estimators_)``.\n\nParameters\n----------\nX : array, shape (n_samples, nd_features, n_tasks)\n    The input samples. For each data slice, the corresponding estimator\n    scores the prediction, e.g.:\n    ``[estimators[ii].score(X[..., ii], y) for ii in range(n_estimators)]``.\n    The feature dimension can be multidimensional e.g.\n    X.shape = (n_samples, n_features_1, n_features_2, n_tasks).\ny : array, shape (n_samples,) | (n_samples, n_targets)\n    The target values.\n\nReturns\n-------\nscore : array, shape (n_samples, n_estimators)\n    Score for each estimator/task.", "metadata": {}}
{"_id": "mne_mne_decoding/search_light.py_transform_doc", "text": "Transform each data slice with all possible estimators.\n\nParameters\n----------\nX : array, shape (n_samples, nd_features, n_slices)\n    The input samples. For estimator the corresponding data slice is\n    used to make a transformation. The feature dimension can be\n    multidimensional e.g.\n    X.shape = (n_samples, n_features_1, n_features_2, n_estimators).\n\nReturns\n-------\nXt : array, shape (n_samples, n_estimators, n_slices)\n    The transformed values generated by each estimator.", "metadata": {}}
{"_id": "mne_mne_decoding/search_light.py_predict_doc", "text": "Predict each data slice with all possible estimators.\n\nParameters\n----------\nX : array, shape (n_samples, nd_features, n_slices)\n    The training input samples. For each data slice, a fitted estimator\n    predicts each slice of the data independently. The feature\n    dimension can be multidimensional e.g.\n    X.shape = (n_samples, n_features_1, n_features_2, n_estimators).\n\nReturns\n-------\ny_pred : array, shape (n_samples, n_estimators, n_slices) | (n_samples, n_estimators, n_slices, n_targets)\n    The predicted values for each estimator.", "metadata": {}}
{"_id": "mne_mne_decoding/search_light.py_predict_proba_doc", "text": "Estimate probabilistic estimates of each data slice with all possible estimators.\n\nParameters\n----------\nX : array, shape (n_samples, nd_features, n_slices)\n    The training input samples. For each data slice, a fitted estimator\n    predicts a slice of the data. The feature dimension can be\n    multidimensional e.g.\n    ``X.shape = (n_samples, n_features_1, n_features_2, n_estimators)``.\n\nReturns\n-------\ny_pred : array, shape (n_samples, n_estimators, n_slices, n_classes)\n    The predicted values for each estimator.\n\nNotes\n-----\nThis requires ``base_estimator`` to have a ``predict_proba`` method.", "metadata": {}}
{"_id": "mne_mne_decoding/search_light.py_decision_function_doc", "text": "Estimate distances of each data slice to all hyperplanes.\n\nParameters\n----------\nX : array, shape (n_samples, nd_features, n_slices)\n    The training input samples. Each estimator outputs the distance to\n    its hyperplane, e.g.:\n    ``[estimators[ii].decision_function(X[..., ii]) for ii in range(n_estimators)]``.\n    The feature dimension can be multidimensional e.g.\n    ``X.shape = (n_samples, n_features_1, n_features_2, n_estimators)``.\n\nReturns\n-------\ny_pred : array, shape (n_samples, n_estimators, n_slices, n_classes * (n_classes-1) // 2)\n    The predicted values for each estimator.\n\nNotes\n-----\nThis requires ``base_estimator`` to have a ``decision_function``\nmethod.", "metadata": {}}
{"_id": "mne_mne_decoding/search_light.py_score_doc", "text": "Score each of the estimators on the tested dimensions.\n\nParameters\n----------\nX : array, shape (n_samples, nd_features, n_slices)\n    The input samples. For each data slice, the corresponding estimator\n    scores the prediction, e.g.:\n    ``[estimators[ii].score(X[..., ii], y) for ii in range(n_slices)]``.\n    The feature dimension can be multidimensional e.g.\n    ``X.shape = (n_samples, n_features_1, n_features_2, n_estimators)``.\ny : array, shape (n_samples,) | (n_samples, n_targets)\n    The target values.\n\nReturns\n-------\nscore : array, shape (n_samples, n_estimators, n_slices)\n    Score for each estimator / data slice couple.", "metadata": {}}
{"_id": "mne_mne_decoding/ems.py_compute_ems_doc", "text": "Compute event-matched spatial filter on epochs.\n\nThis version of EMS :footcite:`SchurgerEtAl2013` operates on the entire\ntime course. No time\nwindow needs to be specified. The result is a spatial filter at each\ntime point and a corresponding time course. Intuitively, the result\ngives the similarity between the filter at each time point and the\ndata vector (sensors) at that time point.\n\n.. note : EMS only works for binary classification.\n\n.. note : The present function applies a leave-one-out cross-validation,\n          following Schurger et al's paper. However, we recommend using\n          a stratified k-fold cross-validation. Indeed, leave-one-out tends\n          to overfit and cannot be used to estimate the variance of the\n          prediction within a given fold.\n\n.. note : Because of the leave-one-out, this function needs an equal\n          number of epochs in each of the two conditions.\n\nParameters\n----------\nepochs : instance of mne.Epochs\n    The epochs.\nconditions : list of str | None, default None\n    If a list of strings, strings must match the epochs.event_id's key as\n    well as the number of conditions supported by the objective_function.\n    If None keys in epochs.event_id are used.\n%(picks_good_data)s\n%(n_jobs)s\ncv : cross-validation object | str | None, default LeaveOneOut\n    The cross-validation scheme.\n%(verbose)s\n\nReturns\n-------\nsurrogate_trials : ndarray, shape (n_trials // 2, n_times)\n    The trial surrogates.\nmean_spatial_filter : ndarray, shape (n_channels, n_times)\n    The set of spatial filters.\nconditions : ndarray, shape (n_classes,)\n    The conditions used. Values correspond to original event ids.\n\nReferences\n----------\n.. footbibliography::", "metadata": {}}
{"_id": "mne_mne_decoding/ems.py_fit_doc", "text": "Fit the spatial filters.\n\n.. note : EMS is fitted on data normalized by channel type before the\n          fitting of the spatial filters.\n\nParameters\n----------\nX : array, shape (n_epochs, n_channels, n_times)\n    The training data.\ny : array of int, shape (n_epochs)\n    The target classes.\n\nReturns\n-------\nself : instance of EMS\n    Returns self.", "metadata": {}}
{"_id": "mne_mne_decoding/ems.py_transform_doc", "text": "Transform the data by the spatial filters.\n\nParameters\n----------\nX : array, shape (n_epochs, n_channels, n_times)\n    The input data.\n\nReturns\n-------\nX : array, shape (n_epochs, n_times)\n    The input data transformed by the spatial filters.", "metadata": {}}
{"_id": "mne_mne_decoding/time_delaying_ridge.py_fit_doc", "text": "Estimate the coefficients of the linear model.\n\nParameters\n----------\nX : array, shape (n_samples[, n_epochs], n_features)\n    The training input samples to estimate the linear coefficients.\ny : array, shape (n_samples[, n_epochs],  n_outputs)\n    The target values.\n\nReturns\n-------\nself : instance of TimeDelayingRidge\n    Returns the modified instance.", "metadata": {}}
{"_id": "mne_mne_decoding/time_delaying_ridge.py_predict_doc", "text": "Predict the output.\n\nParameters\n----------\nX : array, shape (n_samples[, n_epochs], n_features)\n    The data.\n\nReturns\n-------\nX : ndarray\n    The predicted response.", "metadata": {}}
{"_id": "mne_mne_decoding/base.py_get_coef_doc", "text": "Retrieve the coefficients of an estimator ending with a Linear Model.\n\nThis is typically useful to retrieve \"spatial filters\" or \"spatial\npatterns\" of decoding models :footcite:`HaufeEtAl2014`.\n\nParameters\n----------\nestimator : object | None\n    An estimator from scikit-learn.\nattr : str\n    The name of the coefficient attribute to retrieve, typically\n    ``'filters_'`` (default) or ``'patterns_'``.\ninverse_transform : bool\n    If True, returns the coefficients after inverse transforming them with\n    the transformer steps of the estimator.\n%(verbose)s\n\nReturns\n-------\ncoef : array\n    The coefficients.\n\nReferences\n----------\n.. footbibliography::", "metadata": {}}
{"_id": "mne_mne_decoding/base.py_cross_val_multiscore_doc", "text": "Evaluate a score by cross-validation.\n\nParameters\n----------\nestimator : instance of sklearn.base.BaseEstimator\n    The object to use to fit the data.\n    Must implement the 'fit' method.\nX : array-like, shape (n_samples, n_dimensional_features,)\n    The data to fit. Can be, for example a list, or an array at least 2d.\ny : array-like, shape (n_samples, n_targets,)\n    The target variable to try to predict in the case of\n    supervised learning.\ngroups : array-like, with shape (n_samples,)\n    Group labels for the samples used while splitting the dataset into\n    train/test set.\nscoring : str, callable | None\n    A string (see model evaluation documentation) or\n    a scorer callable object / function with signature\n    ``scorer(estimator, X, y)``.\n    Note that when using an estimator which inherently returns\n    multidimensional output - in particular, SlidingEstimator\n    or GeneralizingEstimator - you should set the scorer\n    there, not here.\ncv : int, cross-validation generator | iterable\n    Determines the cross-validation splitting strategy.\n    Possible inputs for cv are:\n\n    - None, to use the default 5-fold cross validation,\n    - integer, to specify the number of folds in a ``(Stratified)KFold``,\n    - An object to be used as a cross-validation generator.\n    - An iterable yielding train, test splits.\n\n    For integer/None inputs, if the estimator is a classifier and ``y`` is\n    either binary or multiclass,\n    :class:`sklearn.model_selection.StratifiedKFold` is used. In all\n    other cases, :class:`sklearn.model_selection.KFold` is used.\n%(n_jobs)s\n%(verbose)s\nfit_params : dict, optional\n    Parameters to pass to the fit method of the estimator.\npre_dispatch : int, or str, optional\n    Controls the number of jobs that get dispatched during parallel\n    execution. Reducing this number can be useful to avoid an\n    explosion of memory consumption when more jobs get dispatched\n    than CPUs can process. This parameter can be:\n\n    - None, in which case all the jobs are immediately\n      created and spawned. Use this for lightweight and\n      fast-running jobs, to avoid delays due to on-demand\n      spawning of the jobs\n    - An int, giving the exact number of total jobs that are\n      spawned\n    - A string, giving an expression as a function of n_jobs,\n      as in '2*n_jobs'\n\nReturns\n-------\nscores : array of float, shape (n_splits,) | shape (n_splits, n_scores)\n    Array of scores of the estimator for each run of the cross validation.", "metadata": {}}
{"_id": "mne_mne_decoding/base.py_fit_doc", "text": "Estimate the coefficients of the linear model.\n\nSave the coefficients in the attribute ``filters_`` and\ncomputes the attribute ``patterns_``.\n\nParameters\n----------\nX : array, shape (n_samples, n_features)\n    The training input samples to estimate the linear coefficients.\ny : array, shape (n_samples, [n_targets])\n    The target values.\n**fit_params : dict of string -> object\n    Parameters to pass to the fit method of the estimator.\n\nReturns\n-------\nself : instance of LinearModel\n    Returns the modified instance.", "metadata": {}}
{"_id": "mne_mne_decoding/ssd.py_fit_doc", "text": "Estimate the SSD decomposition on raw or epoched data.\n\nParameters\n----------\nX : array, shape ([n_epochs, ]n_channels, n_times)\n    The input data from which to estimate the SSD. Either 2D array\n    obtained from continuous data or 3D array obtained from epoched\n    data.\ny : None\n    Ignored; exists for compatibility with scikit-learn pipelines.\n\nReturns\n-------\nself : instance of SSD\n    Returns the modified instance.", "metadata": {}}
{"_id": "mne_mne_decoding/ssd.py_transform_doc", "text": "Estimate epochs sources given the SSD filters.\n\nParameters\n----------\nX : array, shape ([n_epochs, ]n_channels, n_times)\n    The input data from which to estimate the SSD. Either 2D array\n    obtained from continuous data or 3D array obtained from epoched\n    data.\n\nReturns\n-------\nX_ssd : array, shape ([n_epochs, ]n_components, n_times)\n    The processed data.", "metadata": {}}
{"_id": "mne_mne_decoding/ssd.py_fit_transform_doc", "text": "Fit SSD to data, then transform it.\n\nFits transformer to ``X`` and ``y`` with optional parameters ``fit_params``, and\nreturns a transformed version of ``X``.\n\nParameters\n----------\nX : array, shape ([n_epochs, ]n_channels, n_times)\n    The input data from which to estimate the SSD. Either 2D array obtained from\n    continuous data or 3D array obtained from epoched data.\ny : None\n    Ignored; exists for compatibility with scikit-learn pipelines.\n**fit_params : dict\n    Additional fitting parameters passed to the :meth:`mne.decoding.SSD.fit`\n    method. Not used for this class.\n\nReturns\n-------\nX_ssd : array, shape ([n_epochs, ]n_components, n_times)\n    The processed data.", "metadata": {}}
{"_id": "mne_mne_decoding/ssd.py_get_spectral_ratio_doc", "text": "Get the spectal signal-to-noise ratio for each spatial filter.\n\nSpectral ratio measure for best n_components selection\nSee :footcite:`NikulinEtAl2011`, Eq. (24).\n\nParameters\n----------\nssd_sources : array\n    Data projected to SSD space.\n\nReturns\n-------\nspec_ratio : array, shape (n_channels)\n    Array with the sprectal ratio value for each component.\nsorter_spec : array, shape (n_channels)\n    Array of indices for sorting spec_ratio.\n\nReferences\n----------\n.. footbibliography::", "metadata": {}}
{"_id": "mne_mne_decoding/ssd.py_inverse_transform_doc", "text": "Not implemented yet.", "metadata": {}}
{"_id": "mne_mne_decoding/ssd.py_apply_doc", "text": "Remove selected components from the signal.\n\nThis procedure will reconstruct M/EEG signals from which the dynamics\ndescribed by the excluded components is subtracted\n(denoised by low-rank factorization).\nSee :footcite:`HaufeEtAl2014b` for more information.\n\n.. note:: Unlike in other classes with an apply method,\n   only NumPy arrays are supported (not instances of MNE objects).\n\nParameters\n----------\nX : array, shape ([n_epochs, ]n_channels, n_times)\n    The input data from which to estimate the SSD. Either 2D array\n    obtained from continuous data or 3D array obtained from epoched\n    data.\n\nReturns\n-------\nX : array, shape ([n_epochs, ]n_channels, n_times)\n    The processed data.", "metadata": {}}
{"_id": "mne_mne_decoding/transformer.py_fit_doc", "text": "Standardize data across channels.\n\nParameters\n----------\nepochs_data : array, shape (n_epochs, n_channels, n_times)\n    The data to concatenate channels.\ny : array, shape (n_epochs,)\n    The label for each epoch.\n\nReturns\n-------\nself : instance of Scaler\n    The modified instance.", "metadata": {}}
{"_id": "mne_mne_decoding/transformer.py_transform_doc", "text": "Standardize data across channels.\n\nParameters\n----------\nepochs_data : array, shape (n_epochs, n_channels[, n_times])\n    The data.\n\nReturns\n-------\nX : array, shape (n_epochs, n_channels, n_times)\n    The data concatenated over channels.\n\nNotes\n-----\nThis function makes a copy of the data before the operations and the\nmemory usage may be large with big data.", "metadata": {}}
{"_id": "mne_mne_decoding/transformer.py_fit_transform_doc", "text": "Fit to data, then transform it.\n\nFits transformer to epochs_data and y and returns a transformed version\nof epochs_data.\n\nParameters\n----------\nepochs_data : array, shape (n_epochs, n_channels, n_times)\n    The data.\ny : None | array, shape (n_epochs,)\n    The label for each epoch.\n    Defaults to None.\n\nReturns\n-------\nX : array, shape (n_epochs, n_channels, n_times)\n    The data concatenated over channels.\n\nNotes\n-----\nThis function makes a copy of the data before the operations and the\nmemory usage may be large with big data.", "metadata": {}}
{"_id": "mne_mne_decoding/transformer.py_inverse_transform_doc", "text": "Invert standardization of data across channels.\n\nParameters\n----------\nepochs_data : array, shape ([n_epochs, ]n_channels, n_times)\n    The data.\n\nReturns\n-------\nX : array, shape (n_epochs, n_channels, n_times)\n    The data concatenated over channels.\n\nNotes\n-----\nThis function makes a copy of the data before the operations and the\nmemory usage may be large with big data.", "metadata": {}}
{"_id": "mne_mne_decoding/transformer.py_fit_doc", "text": "Store the shape of the features of X.\n\nParameters\n----------\nX : array-like\n    The data to fit. Can be, for example a list, or an array of at\n    least 2d. The first dimension must be of length n_samples, where\n    samples are the independent samples used by the estimator\n    (e.g. n_epochs for epoched data).\ny : None | array, shape (n_samples,)\n    Used for scikit-learn compatibility.\n\nReturns\n-------\nself : instance of Vectorizer\n    Return the modified instance.", "metadata": {}}
{"_id": "mne_mne_decoding/transformer.py_transform_doc", "text": "Convert given array into two dimensions.\n\nParameters\n----------\nX : array-like\n    The data to fit. Can be, for example a list, or an array of at\n    least 2d. The first dimension must be of length n_samples, where\n    samples are the independent samples used by the estimator\n    (e.g. n_epochs for epoched data).\n\nReturns\n-------\nX : array, shape (n_samples, n_features)\n    The transformed data.", "metadata": {}}
{"_id": "mne_mne_decoding/transformer.py_fit_transform_doc", "text": "Fit the data, then transform in one step.\n\nParameters\n----------\nX : array-like\n    The data to fit. Can be, for example a list, or an array of at\n    least 2d. The first dimension must be of length n_samples, where\n    samples are the independent samples used by the estimator\n    (e.g. n_epochs for epoched data).\ny : None | array, shape (n_samples,)\n    Used for scikit-learn compatibility.\n\nReturns\n-------\nX : array, shape (n_samples, -1)\n    The transformed data.", "metadata": {}}
{"_id": "mne_mne_decoding/transformer.py_inverse_transform_doc", "text": "Transform 2D data back to its original feature shape.\n\nParameters\n----------\nX : array-like, shape (n_samples,  n_features)\n    Data to be transformed back to original shape.\n\nReturns\n-------\nX : array\n    The data transformed into shape as used in fit. The first\n    dimension is of length n_samples.", "metadata": {}}
{"_id": "mne_mne_decoding/transformer.py_fit_doc", "text": "Compute power spectral density (PSD) using a multi-taper method.\n\nParameters\n----------\nepochs_data : array, shape (n_epochs, n_channels, n_times)\n    The data.\ny : array, shape (n_epochs,)\n    The label for each epoch.\n\nReturns\n-------\nself : instance of PSDEstimator\n    The modified instance.", "metadata": {}}
{"_id": "mne_mne_decoding/transformer.py_transform_doc", "text": "Compute power spectral density (PSD) using a multi-taper method.\n\nParameters\n----------\nepochs_data : array, shape (n_epochs, n_channels, n_times)\n    The data.\n\nReturns\n-------\npsd : array, shape (n_signals, n_freqs) or (n_freqs,)\n    The computed PSD.", "metadata": {}}
{"_id": "mne_mne_decoding/transformer.py_fit_doc", "text": "Filter data.\n\nParameters\n----------\nepochs_data : array, shape (n_epochs, n_channels, n_times)\n    The data.\ny : array, shape (n_epochs,)\n    The label for each epoch.\n\nReturns\n-------\nself : instance of FilterEstimator\n    The modified instance.", "metadata": {}}
{"_id": "mne_mne_decoding/transformer.py_transform_doc", "text": "Filter data.\n\nParameters\n----------\nepochs_data : array, shape (n_epochs, n_channels, n_times)\n    The data.\n\nReturns\n-------\nX : array, shape (n_epochs, n_channels, n_times)\n    The data after filtering.", "metadata": {}}
{"_id": "mne_mne_decoding/transformer.py_fit_doc", "text": "Fit the spatial filters.\n\nParameters\n----------\nX : array, shape (n_epochs, n_channels, n_times)\n    The data to be filtered.\ny : None | array, shape (n_samples,)\n    Used for scikit-learn compatibility.\n\nReturns\n-------\nself : instance of UnsupervisedSpatialFilter\n    Return the modified instance.", "metadata": {}}
{"_id": "mne_mne_decoding/transformer.py_fit_transform_doc", "text": "Transform the data to its filtered components after fitting.\n\nParameters\n----------\nX : array, shape (n_epochs, n_channels, n_times)\n    The data to be filtered.\ny : None | array, shape (n_samples,)\n    Used for scikit-learn compatibility.\n\nReturns\n-------\nX : array, shape (n_epochs, n_channels, n_times)\n    The transformed data.", "metadata": {}}
{"_id": "mne_mne_decoding/transformer.py_transform_doc", "text": "Transform the data to its spatial filters.\n\nParameters\n----------\nX : array, shape (n_epochs, n_channels, n_times)\n    The data to be filtered.\n\nReturns\n-------\nX : array, shape (n_epochs, n_channels, n_times)\n    The transformed data.", "metadata": {}}
{"_id": "mne_mne_decoding/transformer.py_inverse_transform_doc", "text": "Inverse transform the data to its original space.\n\nParameters\n----------\nX : array, shape (n_epochs, n_components, n_times)\n    The data to be inverted.\n\nReturns\n-------\nX : array, shape (n_epochs, n_channels, n_times)\n    The transformed data.", "metadata": {}}
{"_id": "mne_mne_decoding/transformer.py_fit_doc", "text": "Do nothing (for scikit-learn compatibility purposes).\n\nParameters\n----------\nX : array, shape ([n_epochs, ]n_channels, n_times)\n    The data to be filtered over the last dimension. The channels\n    dimension can be zero when passing a 2D array.\ny : None\n    Not used, for scikit-learn compatibility issues.\n\nReturns\n-------\nself : instance of TemporalFilter\n    The modified instance.", "metadata": {}}
{"_id": "mne_mne_decoding/transformer.py_transform_doc", "text": "Filter data along the last dimension.\n\nParameters\n----------\nX : array, shape ([n_epochs, ]n_channels, n_times)\n    The data to be filtered over the last dimension. The channels\n    dimension can be zero when passing a 2D array.\n\nReturns\n-------\nX : array\n    The data after filtering.", "metadata": {}}
{"_id": "mne_mne_decoding/csp.py_fit_doc", "text": "Estimate the CSP decomposition on epochs.\n\nParameters\n----------\nX : ndarray, shape (n_epochs, n_channels, n_times)\n    The data on which to estimate the CSP.\ny : array, shape (n_epochs,)\n    The class for each epoch.\n\nReturns\n-------\nself : instance of CSP\n    Returns the modified instance.", "metadata": {}}
{"_id": "mne_mne_decoding/csp.py_transform_doc", "text": "Estimate epochs sources given the CSP filters.\n\nParameters\n----------\nX : array, shape (n_epochs, n_channels, n_times)\n    The data.\n\nReturns\n-------\nX : ndarray\n    If self.transform_into == 'average_power' then returns the power of\n    CSP features averaged over time and shape (n_epochs, n_components)\n    If self.transform_into == 'csp_space' then returns the data in CSP\n    space and shape is (n_epochs, n_components, n_times).", "metadata": {}}
{"_id": "mne_mne_decoding/csp.py_inverse_transform_doc", "text": "Project CSP features back to sensor space.\n\nParameters\n----------\nX : array, shape (n_epochs, n_components)\n    The data in CSP power space.\n\nReturns\n-------\nX : ndarray\n    The data in sensor space and shape (n_epochs, n_channels, n_components).", "metadata": {}}
{"_id": "mne_mne_decoding/csp.py_fit_transform_doc", "text": "Fit CSP to data, then transform it.\n\nFits transformer to ``X`` and ``y`` with optional parameters ``fit_params``, and\nreturns a transformed version of ``X``.\n\nParameters\n----------\nX : array, shape (n_epochs, n_channels, n_times)\n    The data on which to estimate the CSP.\ny : array, shape (n_epochs,)\n    The class for each epoch.\n**fit_params : dict\n    Additional fitting parameters passed to the :meth:`mne.decoding.CSP.fit`\n    method. Not used for this class.\n\nReturns\n-------\nX_csp : array, shape (n_epochs, n_components[, n_times])\n    If ``self.transform_into == 'average_power'`` then returns the power of CSP\n    features averaged over time and shape is ``(n_epochs, n_components)``. If\n    ``self.transform_into == 'csp_space'`` then returns the data in CSP space\n    and shape is ``(n_epochs, n_components, n_times)``.", "metadata": {}}
{"_id": "mne_mne_decoding/csp.py_plot_patterns_doc", "text": "Plot topographic patterns of components.\n\nThe patterns explain how the measured data was generated from the\nneural sources (a.k.a. the forward model).\n\nParameters\n----------\n%(info_not_none)s Used for fitting. If not available, consider using\n    :func:`mne.create_info`.\ncomponents : float | array of float | None\n   The patterns to plot. If ``None``, all components will be shown.\n%(ch_type_topomap)s\nscalings : dict | float | None\n    The scalings of the channel types to be applied for plotting.\n    If None, defaults to ``dict(eeg=1e6, grad=1e13, mag=1e15)``.\n%(sensors_topomap)s\n%(show_names_topomap)s\n%(mask_patterns_topomap)s\n%(mask_params_topomap)s\n%(contours_topomap)s\n%(outlines_topomap)s\n%(sphere_topomap_auto)s\n%(image_interp_topomap)s\n%(extrapolate_topomap)s\n\n    .. versionadded:: 1.3\n%(border_topomap)s\n\n    .. versionadded:: 1.3\n%(res_topomap)s\n%(size_topomap)s\n%(cmap_topomap)s\n%(vlim_plot_topomap)s\n\n    .. versionadded:: 1.3\n%(cnorm)s\n\n    .. versionadded:: 1.3\n%(colorbar_topomap)s\n%(cbar_fmt_topomap)s\n%(units_topomap)s\n%(axes_evoked_plot_topomap)s\nname_format : str\n    String format for topomap values. Defaults to \"CSP%%01d\".\n%(nrows_ncols_topomap)s\n\n    .. versionadded:: 1.3\n%(show)s\n\nReturns\n-------\nfig : instance of matplotlib.figure.Figure\n   The figure.", "metadata": {}}
{"_id": "mne_mne_decoding/csp.py_plot_filters_doc", "text": "Plot topographic filters of components.\n\nThe filters are used to extract discriminant neural sources from\nthe measured data (a.k.a. the backward model).\n\nParameters\n----------\n%(info_not_none)s Used for fitting. If not available, consider using\n    :func:`mne.create_info`.\ncomponents : float | array of float | None\n   The patterns to plot. If ``None``, all components will be shown.\n%(ch_type_topomap)s\nscalings : dict | float | None\n    The scalings of the channel types to be applied for plotting.\n    If None, defaults to ``dict(eeg=1e6, grad=1e13, mag=1e15)``.\n%(sensors_topomap)s\n%(show_names_topomap)s\n%(mask_patterns_topomap)s\n%(mask_params_topomap)s\n%(contours_topomap)s\n%(outlines_topomap)s\n%(sphere_topomap_auto)s\n%(image_interp_topomap)s\n%(extrapolate_topomap)s\n\n    .. versionadded:: 1.3\n%(border_topomap)s\n\n    .. versionadded:: 1.3\n%(res_topomap)s\n%(size_topomap)s\n%(cmap_topomap)s\n%(vlim_plot_topomap_psd)s\n\n    .. versionadded:: 1.3\n%(cnorm)s\n\n    .. versionadded:: 1.3\n%(colorbar_topomap)s\n%(cbar_fmt_topomap)s\n%(units_topomap)s\n%(axes_evoked_plot_topomap)s\nname_format : str\n    String format for topomap values. Defaults to \"CSP%%01d\".\n%(nrows_ncols_topomap)s\n\n    .. versionadded:: 1.3\n%(show)s\n\nReturns\n-------\nfig : instance of matplotlib.figure.Figure\n   The figure.", "metadata": {}}
{"_id": "mne_mne_decoding/csp.py_fit_doc", "text": "Estimate the SPoC decomposition on epochs.\n\nParameters\n----------\nX : ndarray, shape (n_epochs, n_channels, n_times)\n    The data on which to estimate the SPoC.\ny : array, shape (n_epochs,)\n    The class for each epoch.\n\nReturns\n-------\nself : instance of SPoC\n    Returns the modified instance.", "metadata": {}}
{"_id": "mne_mne_decoding/csp.py_transform_doc", "text": "Estimate epochs sources given the SPoC filters.\n\nParameters\n----------\nX : array, shape (n_epochs, n_channels, n_times)\n    The data.\n\nReturns\n-------\nX : ndarray\n    If self.transform_into == 'average_power' then returns the power of\n    CSP features averaged over time and shape (n_epochs, n_components)\n    If self.transform_into == 'csp_space' then returns the data in CSP\n    space and shape is (n_epochs, n_components, n_times).", "metadata": {}}
{"_id": "mne_mne_decoding/csp.py_fit_transform_doc", "text": "Fit SPoC to data, then transform it.\n\nFits transformer to ``X`` and ``y`` with optional parameters ``fit_params``, and\nreturns a transformed version of ``X``.\n\nParameters\n----------\nX : array, shape (n_epochs, n_channels, n_times)\n    The data on which to estimate the SPoC.\ny : array, shape (n_epochs,)\n    The class for each epoch.\n**fit_params : dict\n    Additional fitting parameters passed to the :meth:`mne.decoding.CSP.fit`\n    method. Not used for this class.\n\nReturns\n-------\nX : array, shape (n_epochs, n_components[, n_times])\n    If ``self.transform_into == 'average_power'`` then returns the power of CSP\n    features averaged over time and shape is ``(n_epochs, n_components)``. If\n    ``self.transform_into == 'csp_space'`` then returns the data in CSP space\n    and shape is ``(n_epochs, n_components, n_times)``.", "metadata": {}}
{"_id": "mne_mne_channels/montage.py_get_builtin_montages_doc", "text": "Get a list of all standard montages shipping with MNE-Python.\n\nThe names of the montages can be passed to :func:`make_standard_montage`.\n\nParameters\n----------\ndescriptions : bool\n    Whether to return not only the montage names, but also their\n    corresponding descriptions. If ``True``, a list of tuples is returned,\n    where the first tuple element is the montage name and the second is\n    the montage description. If ``False`` (default), only the names are\n    returned.\n\n    .. versionadded:: 1.1\n\nReturns\n-------\nmontages : list of str | list of tuple\n    If ``descriptions=False``, the names of all builtin montages that can\n    be used by :func:`make_standard_montage`.\n\n    If ``descriptions=True``, a list of tuples ``(name, description)``.", "metadata": {}}
{"_id": "mne_mne_channels/montage.py_make_dig_montage_doc", "text": "Make montage from arrays.\n\nParameters\n----------\nch_pos : dict | None\n    Dictionary of channel positions. Keys are channel names and values\n    are 3D coordinates - array of shape (3,) - in native digitizer space\n    in m.\nnasion : None | array, shape (3,)\n    The position of the nasion fiducial point.\n    This point is assumed to be in the native digitizer space in m.\nlpa : None | array, shape (3,)\n    The position of the left periauricular fiducial point.\n    This point is assumed to be in the native digitizer space in m.\nrpa : None | array, shape (3,)\n    The position of the right periauricular fiducial point.\n    This point is assumed to be in the native digitizer space in m.\nhsp : None | array, shape (n_points, 3)\n    This corresponds to an array of positions of the headshape points in\n    3d. These points are assumed to be in the native digitizer space in m.\nhpi : None | array, shape (n_hpi, 3)\n    This corresponds to an array of HPI points in the native digitizer\n    space. They only necessary if computation of a ``compute_dev_head_t``\n    is True.\ncoord_frame : str\n    The coordinate frame of the points. Usually this is ``'unknown'``\n    for native digitizer space.\n    Other valid values are: ``'head'``, ``'meg'``, ``'mri'``,\n    ``'mri_voxel'``, ``'mni_tal'``, ``'ras'``, ``'fs_tal'``,\n    ``'ctf_head'``, and ``'ctf_meg'``.\n\n    .. note::\n        For custom montages without fiducials, this parameter must be set\n        to ``'head'``.\n\nReturns\n-------\nmontage : instance of DigMontage\n    The montage.\n\nSee Also\n--------\nDigMontage\nread_dig_captrak\nread_dig_egi\nread_dig_fif\nread_dig_localite\nread_dig_polhemus_isotrak", "metadata": {}}
{"_id": "mne_mne_channels/montage.py_transform_to_head_doc", "text": "Transform a DigMontage object into head coordinate.\n\nParameters\n----------\nmontage : instance of DigMontage\n    The montage.\n\nReturns\n-------\nmontage : instance of DigMontage\n    The montage after transforming the points to head\n    coordinate system.\n\nNotes\n-----\nThis function requires that the LPA, RPA and Nasion fiducial\npoints are available. If they are not, they will be added based by\nprojecting the fiducials onto a sphere with radius equal to the average\ndistance of each point to the origin (in the given coordinate frame).\n\nThis function assumes that all fiducial points are in the same coordinate\nframe (e.g. 'unknown') and it will convert all the point in this coordinate\nsystem to Neuromag head coordinate system.\n\n.. versionchanged:: 1.2\n   Fiducial points will be added automatically if the montage does not\n   have them.", "metadata": {}}
{"_id": "mne_mne_channels/montage.py_read_dig_dat_doc", "text": "Read electrode positions from a ``*.dat`` file.\n\n.. Warning::\n    This function was implemented based on ``*.dat`` files available from\n    `Compumedics <https://compumedicsneuroscan.com>`__ and might not work\n    as expected with novel files. If it does not read your files correctly\n    please contact the MNE-Python developers.\n\nParameters\n----------\nfname : path-like\n    File from which to read electrode locations.\n\nReturns\n-------\nmontage : DigMontage\n    The montage.\n\nSee Also\n--------\nread_dig_captrak\nread_dig_dat\nread_dig_egi\nread_dig_fif\nread_dig_hpts\nread_dig_localite\nread_dig_polhemus_isotrak\nmake_dig_montage\n\nNotes\n-----\n``*.dat`` files are plain text files and can be inspected and amended with\na plain text editor.", "metadata": {}}
{"_id": "mne_mne_channels/montage.py_read_dig_fif_doc", "text": "Read digitized points from a .fif file.\n\nParameters\n----------\nfname : path-like\n    FIF file from which to read digitization locations.\n%(verbose)s\n\nReturns\n-------\nmontage : instance of DigMontage\n    The montage.\n\nSee Also\n--------\nDigMontage\nread_dig_dat\nread_dig_egi\nread_dig_captrak\nread_dig_polhemus_isotrak\nread_dig_hpts\nread_dig_localite\nmake_dig_montage\n\nNotes\n-----\n.. versionchanged:: 1.9\n   Added support for reading the associated channel names, if present.\n\nIn some files, electrode names are not present (e.g., in older files).\nFor those files, the channel names are defined with the convention from\nVectorView systems (EEG001, EEG002, etc.).", "metadata": {}}
{"_id": "mne_mne_channels/montage.py_read_dig_hpts_doc", "text": "Read historical ``.hpts`` MNE-C files.\n\nParameters\n----------\nfname : path-like\n    The filepath of .hpts file.\nunit : ``'m'`` | ``'cm'`` | ``'mm'``\n    Unit of the positions. Defaults to ``'mm'``.\n\nReturns\n-------\nmontage : instance of DigMontage\n    The montage.\n\nSee Also\n--------\nDigMontage\nread_dig_captrak\nread_dig_dat\nread_dig_egi\nread_dig_fif\nread_dig_localite\nread_dig_polhemus_isotrak\nmake_dig_montage\n\nNotes\n-----\nThe hpts format digitzer data file may contain comment lines starting\nwith the pound sign (#) and data lines of the form::\n\n     <*category*> <*identifier*> <*x/mm*> <*y/mm*> <*z/mm*>\n\nwhere:\n\n``<*category*>``\n    defines the type of points. Allowed categories are: ``hpi``,\n    ``cardinal`` (fiducial), ``eeg``, and ``extra`` corresponding to\n    head-position indicator coil locations, cardinal landmarks, EEG\n    electrode locations, and additional head surface points,\n    respectively.\n\n``<*identifier*>``\n    identifies the point. The identifiers are usually sequential\n    numbers. For cardinal landmarks, 1 = left auricular point,\n    2 = nasion, and 3 = right auricular point. For EEG electrodes,\n    identifier = 0 signifies the reference electrode.\n\n``<*x/mm*> , <*y/mm*> , <*z/mm*>``\n    Location of the point, usually in the head coordinate system\n    in millimeters. If your points are in [m] then unit parameter can\n    be changed.\n\nFor example::\n\n    cardinal    2    -5.6729  -12.3873  -30.3671\n    cardinal    1    -37.6782  -10.4957   91.5228\n    cardinal    3    -131.3127    9.3976  -22.2363\n    hpi    1    -30.4493  -11.8450   83.3601\n    hpi    2    -122.5353    9.2232  -28.6828\n    hpi    3    -6.8518  -47.0697  -37.0829\n    hpi    4    7.3744  -50.6297  -12.1376\n    hpi    5    -33.4264  -43.7352  -57.7756\n    eeg    FP1  3.8676  -77.0439  -13.0212\n    eeg    FP2  -31.9297  -70.6852  -57.4881\n    eeg    F7  -6.1042  -68.2969   45.4939\n    ...", "metadata": {}}
{"_id": "mne_mne_channels/montage.py_read_dig_egi_doc", "text": "Read electrode locations from EGI system.\n\nParameters\n----------\nfname : path-like\n    EGI MFF XML coordinates file from which to read digitization locations.\n\nReturns\n-------\nmontage : instance of DigMontage\n    The montage.\n\nSee Also\n--------\nDigMontage\nread_dig_captrak\nread_dig_dat\nread_dig_fif\nread_dig_hpts\nread_dig_localite\nread_dig_polhemus_isotrak\nmake_dig_montage", "metadata": {}}
{"_id": "mne_mne_channels/montage.py_read_dig_captrak_doc", "text": "Read electrode locations from CapTrak Brain Products system.\n\nParameters\n----------\nfname : path-like\n    BrainVision CapTrak coordinates file from which to read EEG electrode\n    locations. This is typically in XML format with the .bvct extension.\n\nReturns\n-------\nmontage : instance of DigMontage\n    The montage.\n\nSee Also\n--------\nDigMontage\nread_dig_dat\nread_dig_egi\nread_dig_fif\nread_dig_hpts\nread_dig_localite\nread_dig_polhemus_isotrak\nmake_dig_montage", "metadata": {}}
{"_id": "mne_mne_channels/montage.py_read_dig_localite_doc", "text": "Read Localite .csv file.\n\nParameters\n----------\nfname : path-like\n    File name.\nnasion : str | None\n    Name of nasion fiducial point.\nlpa : str | None\n    Name of left preauricular fiducial point.\nrpa : str | None\n    Name of right preauricular fiducial point.\n\nReturns\n-------\nmontage : instance of DigMontage\n    The montage.\n\nSee Also\n--------\nDigMontage\nread_dig_captrak\nread_dig_dat\nread_dig_egi\nread_dig_fif\nread_dig_hpts\nread_dig_polhemus_isotrak\nmake_dig_montage", "metadata": {}}
{"_id": "mne_mne_channels/montage.py_read_dig_polhemus_isotrak_doc", "text": "Read Polhemus digitizer data from a file.\n\nParameters\n----------\nfname : path-like\n    The filepath of Polhemus ISOTrak formatted file.\n    File extension is expected to be ``'.hsp'``, ``'.elp'`` or ``'.eeg'``.\nch_names : None | list of str\n    The names of the points. This will make the points\n    considered as EEG channels. If None, channels will be assumed\n    to be HPI if the extension is ``'.elp'``, and extra headshape\n    points otherwise.\nunit : ``'m'`` | ``'cm'`` | ``'mm'``\n    Unit of the digitizer file. Polhemus ISOTrak systems data is usually\n    exported in meters. Defaults to ``'m'``.\n\nReturns\n-------\nmontage : instance of DigMontage\n    The montage.\n\nSee Also\n--------\nDigMontage\nmake_dig_montage\nread_polhemus_fastscan\nread_dig_captrak\nread_dig_dat\nread_dig_egi\nread_dig_fif\nread_dig_localite", "metadata": {}}
{"_id": "mne_mne_channels/montage.py_read_polhemus_fastscan_doc", "text": "Read Polhemus FastSCAN digitizer data from a ``.txt`` file.\n\nParameters\n----------\nfname : path-like\n    The path of ``.txt`` Polhemus FastSCAN file.\nunit : ``'m'`` | ``'cm'`` | ``'mm'``\n    Unit of the digitizer file. Polhemus FastSCAN systems data is usually\n    exported in millimeters. Defaults to ``'mm'``.\n%(on_header_missing)s\n%(verbose)s\n\nReturns\n-------\npoints : array, shape (n_points, 3)\n    The digitization points in digitizer coordinates.\n\nSee Also\n--------\nread_dig_polhemus_isotrak\nmake_dig_montage", "metadata": {}}
{"_id": "mne_mne_channels/montage.py_read_custom_montage_doc", "text": "Read a montage from a file.\n\nParameters\n----------\nfname : path-like\n    File extension is expected to be:\n    ``'.loc'`` or ``'.locs'`` or ``'.eloc'`` (for EEGLAB files),\n    ``'.sfp'`` (BESA/EGI files), ``'.csd'``,\n    ``'.elc'``, ``'.txt'``, ``'.csd'``, ``'.elp'`` (BESA spherical),\n    ``'.bvef'`` (BrainVision files),\n    ``'.csv'``, ``'.tsv'``, ``'.xyz'`` (XYZ coordinates).\nhead_size : float | None\n    The size of the head (radius, in [m]). If ``None``, returns the values\n    read from the montage file with no modification. Defaults to 0.095m.\ncoord_frame : str | None\n    The coordinate frame of the points. Usually this is ``\"unknown\"``\n    for native digitizer space. Defaults to None, which is ``\"unknown\"``\n    for most readers but ``\"head\"`` for EEGLAB.\n\n    .. versionadded:: 0.20\n%(verbose)s\n\nReturns\n-------\nmontage : instance of DigMontage\n    The montage.\n\nSee Also\n--------\nmake_dig_montage\nmake_standard_montage\nread_dig_fif\n\nNotes\n-----\nThe function is a helper to read electrode positions you may have\nin various formats. Most of these format are weakly specified\nin terms of units, coordinate systems. It implies that setting\na montage using a DigMontage produced by this function may\nbe problematic. If you use a standard/template (eg. 10/20,\n10/10 or 10/05) we recommend you use :func:`make_standard_montage`.\nIf you can have positions in memory you can also use\n:func:`make_dig_montage` that takes arrays as input.", "metadata": {}}
{"_id": "mne_mne_channels/montage.py_compute_dev_head_t_doc", "text": "Compute device to head transform from a DigMontage.\n\nParameters\n----------\nmontage : DigMontage\n    The `~mne.channels.DigMontage` must contain the fiducials in head\n    coordinate system and hpi points in both head and\n    meg device coordinate system.\n\nReturns\n-------\ndev_head_t : Transform\n    A Device-to-Head transformation matrix.", "metadata": {}}
{"_id": "mne_mne_channels/montage.py_compute_native_head_t_doc", "text": "Compute the native-to-head transformation for a montage.\n\nThis uses the fiducials in the native space to transform to compute the\ntransform to the head coordinate frame.\n\nParameters\n----------\nmontage : instance of DigMontage\n    The montage.\n%(on_missing_fiducials)s\n\n    .. versionadded:: 1.2\n%(verbose)s\n\nReturns\n-------\nnative_head_t : instance of Transform\n    A native-to-head transformation matrix.", "metadata": {}}
{"_id": "mne_mne_channels/montage.py_make_standard_montage_doc", "text": "Read a generic (built-in) standard montage that ships with MNE-Python.\n\nParameters\n----------\nkind : str\n    The name of the montage to use.\n\n    .. note::\n        You can retrieve the names of all\n        built-in montages via :func:`mne.channels.get_builtin_montages`.\nhead_size : float | None | str\n    The head size (radius, in meters) to use for spherical montages.\n    Can be None to not scale the read sizes. ``'auto'`` (default) will\n    use 95mm for all montages except the ``'standard*'``, ``'mgh*'``, and\n    ``'artinis*'``, which are already in fsaverage's MRI coordinates\n    (same as MNI).\n\nReturns\n-------\nmontage : instance of DigMontage\n    The montage.\n\nSee Also\n--------\nget_builtin_montages\nmake_dig_montage\nread_custom_montage\n\nNotes\n-----\nIndividualized (digitized) electrode positions should be read in using\n:func:`read_dig_captrak`, :func:`read_dig_dat`, :func:`read_dig_egi`,\n:func:`read_dig_fif`, :func:`read_dig_polhemus_isotrak`,\n:func:`read_dig_hpts`, or manually made with :func:`make_dig_montage`.\n\n.. versionadded:: 0.19.0", "metadata": {}}
{"_id": "mne_mne_channels/montage.py_rename_channels_doc", "text": "Rename the channels.\n\nParameters\n----------\n%(mapping_rename_channels_duplicates)s\n\nReturns\n-------\ninst : instance of DigMontage\n    The instance. Operates in-place.", "metadata": {}}
{"_id": "mne_mne_channels/montage.py_save_doc", "text": "Save digitization points to FIF.\n\nParameters\n----------\nfname : path-like\n    The filename to use. Should end in ``-dig.fif`` or ``-dig.fif.gz``.\n%(overwrite)s\n%(verbose)s\n\nSee Also\n--------\nmne.channels.read_dig_fif\n\nNotes\n-----\n.. versionchanged:: 1.9\n   Added support for saving the associated channel names.", "metadata": {}}
{"_id": "mne_mne_channels/montage.py_copy_doc", "text": "Copy the DigMontage object.\n\nReturns\n-------\ndig : instance of DigMontage\n    The copied DigMontage instance.", "metadata": {}}
{"_id": "mne_mne_channels/montage.py_get_positions_doc", "text": "Get all channel and fiducial positions.\n\nReturns\n-------\npositions : dict\n    A dictionary of the positions for channels (``ch_pos``),\n    coordinate frame (``coord_frame``), nasion (``nasion``),\n    left preauricular point (``lpa``),\n    right preauricular point (``rpa``),\n    Head Shape Polhemus (``hsp``), and\n    Head Position Indicator(``hpi``).\n    E.g.::\n\n        {\n            'ch_pos': {'EEG061': [0, 0, 0]},\n            'nasion': [0, 0, 1],\n            'coord_frame': 'mni_tal',\n            'lpa': [0, 1, 0],\n            'rpa': [1, 0, 0],\n            'hsp': None,\n            'hpi': None\n        }", "metadata": {}}
{"_id": "mne_mne_channels/montage.py_apply_trans_doc", "text": "Apply a transformation matrix to the montage.\n\nParameters\n----------\ntrans : instance of mne.transforms.Transform\n    The transformation matrix to be applied.\n%(verbose)s", "metadata": {}}
{"_id": "mne_mne_channels/montage.py_add_estimated_fiducials_doc", "text": "Estimate fiducials based on FreeSurfer ``fsaverage`` subject.\n\nThis takes a montage with the ``mri`` coordinate frame,\ncorresponding to the FreeSurfer RAS (xyz in the volume) T1w\nimage of the specific subject. It will call\n:func:`mne.coreg.get_mni_fiducials` to estimate LPA, RPA and\nNasion fiducial points.\n\nParameters\n----------\n%(subject)s\n%(subjects_dir)s\n%(verbose)s\n\nReturns\n-------\ninst : instance of DigMontage\n    The instance, modified in-place.\n\nSee Also\n--------\n:ref:`tut-source-alignment`\n\nNotes\n-----\nSince MNE uses the FIF data structure, it relies on the ``head``\ncoordinate frame. Any coordinate frame can be transformed\nto ``head`` if the fiducials (i.e. LPA, RPA and Nasion) are\ndefined. One can use this function to estimate those fiducials\nand then use ``mne.channels.compute_native_head_t(montage)``\nto get the head <-> MRI transform.", "metadata": {}}
{"_id": "mne_mne_channels/montage.py_add_mni_fiducials_doc", "text": "Add fiducials to a montage in MNI space.\n\nParameters\n----------\n%(subjects_dir)s\n%(verbose)s\n\nReturns\n-------\ninst : instance of DigMontage\n    The instance, modified in-place.\n\nNotes\n-----\n``fsaverage`` is in MNI space and so its fiducials can be\nadded to a montage in \"mni_tal\". MNI is an ACPC-aligned\ncoordinate system (the posterior commissure is the origin)\nso since BIDS requires channel locations for ECoG, sEEG and\nDBS to be in ACPC space, this function can be used to allow\nthose coordinate to be transformed to \"head\" space (origin\nbetween LPA and RPA).", "metadata": {}}
{"_id": "mne_mne_channels/montage.py_remove_fiducials_doc", "text": "Remove the fiducial points from a montage.\n\nParameters\n----------\n%(verbose)s\n\nReturns\n-------\ninst : instance of DigMontage\n    The instance, modified in-place.\n\nNotes\n-----\nMNE will transform a montage to the internal \"head\" coordinate\nframe if the fiducials are present. Under most circumstances, this\nis ideal as it standardizes the coordinate frame for things like\nplotting. However, in some circumstances, such as saving a ``raw``\nwith intracranial data to BIDS format, the coordinate frame\nshould not be changed by removing fiducials.", "metadata": {}}
{"_id": "mne_mne_channels/layout.py_read_layout_doc", "text": "Read layout from a file.\n\nParameters\n----------\nfname : path-like | str\n    Either the path to a ``.lout`` or ``.lay`` file or the name of a\n    built-in layout. c.f. Notes for a list of the available built-in\n    layouts.\nscale : bool\n    Apply useful scaling for out the box plotting using ``layout.pos``.\n    Defaults to True.\n\nReturns\n-------\nlayout : instance of Layout\n    The layout.\n\nSee Also\n--------\nLayout.save\n\nNotes\n-----\nValid ``fname`` arguments are:\n\n.. table::\n   :widths: auto\n\n   +----------------------+\n   | Kind                 |\n   +======================+\n   | biosemi              |\n   +----------------------+\n   | CTF151               |\n   +----------------------+\n   | CTF275               |\n   +----------------------+\n   | CTF-275              |\n   +----------------------+\n   | EEG1005              |\n   +----------------------+\n   | EGI256               |\n   +----------------------+\n   | GeodesicHeadWeb-130  |\n   +----------------------+\n   | GeodesicHeadWeb-280  |\n   +----------------------+\n   | KIT-125              |\n   +----------------------+\n   | KIT-157              |\n   +----------------------+\n   | KIT-160              |\n   +----------------------+\n   | KIT-AD               |\n   +----------------------+\n   | KIT-AS-2008          |\n   +----------------------+\n   | KIT-UMD-3            |\n   +----------------------+\n   | magnesWH3600         |\n   +----------------------+\n   | Neuromag_122         |\n   +----------------------+\n   | Vectorview-all       |\n   +----------------------+\n   | Vectorview-grad      |\n   +----------------------+\n   | Vectorview-grad_norm |\n   +----------------------+\n   | Vectorview-mag       |\n   +----------------------+", "metadata": {}}
{"_id": "mne_mne_channels/layout.py_make_eeg_layout_doc", "text": "Create .lout file from EEG electrode digitization.\n\nParameters\n----------\n%(info_not_none)s\nradius : float\n    Viewport radius as a fraction of main figure height. Defaults to 0.5.\nwidth : float | None\n    Width of sensor axes as a fraction of main figure height. By default,\n    this will be the maximum width possible without axes overlapping.\nheight : float | None\n    Height of sensor axes as a fraction of main figure height. By default,\n    this will be the maximum height possible without axes overlapping.\nexclude : list of str | str\n    List of channels to exclude. If empty do not exclude any.\n    If 'bads', exclude channels in info['bads'] (default).\ncsd : bool\n    Whether the channels contain current-source-density-transformed data.\n\nReturns\n-------\nlayout : Layout\n    The generated Layout.\n\nSee Also\n--------\nmake_grid_layout, generate_2d_layout", "metadata": {}}
{"_id": "mne_mne_channels/layout.py_make_grid_layout_doc", "text": "Generate .lout file for custom data, i.e., ICA sources.\n\nParameters\n----------\n%(info_not_none)s\n%(picks_base)s all good misc channels.\nn_col : int | None\n    Number of columns to generate. If None, a square grid will be produced.\n\nReturns\n-------\nlayout : Layout\n    The generated layout.\n\nSee Also\n--------\nmake_eeg_layout, generate_2d_layout", "metadata": {}}
{"_id": "mne_mne_channels/layout.py_find_layout_doc", "text": "Choose a layout based on the channels in the info 'chs' field.\n\nParameters\n----------\n%(info_not_none)s\nch_type : {'mag', 'grad', 'meg', 'eeg'} | None\n    The channel type for selecting single channel layouts.\n    Defaults to None. Note, this argument will only be considered for\n    VectorView type layout. Use ``'meg'`` to force using the full layout\n    in situations where the info does only contain one sensor type.\nexclude : list of str | str\n    List of channels to exclude. If empty do not exclude any.\n    If 'bads', exclude channels in info['bads'] (default).\n\nReturns\n-------\nlayout : Layout instance | None\n    None if layout not found.", "metadata": {}}
{"_id": "mne_mne_channels/layout.py_generate_2d_layout_doc", "text": "Generate a custom 2D layout from xy points.\n\nGenerates a 2-D layout for plotting with plot_topo methods and\nfunctions. XY points will be normalized between 0 and 1, where\nnormalization extremes will be either the min/max of xy, or\nthe width/height of bg_image.\n\nParameters\n----------\nxy : ndarray, shape (N, 2)\n    The xy coordinates of sensor locations.\nw : float\n    The width of each sensor's axis (between 0 and 1).\nh : float\n    The height of each sensor's axis (between 0 and 1).\npad : float\n    Portion of the box to reserve for padding. The value can range between\n    0.0 (boxes will touch, default) to 1.0 (boxes consist of only padding).\nch_names : list\n    The names of each channel. Must be a list of strings, with one\n    string per channel.\nch_indices : list\n    Index of each channel - must be a collection of unique integers,\n    one index per channel.\nname : str\n    The name of this layout type.\nbg_image : path-like | ndarray\n    The image over which sensor axes will be plotted. Either a path to an\n    image file, or an array that can be plotted with plt.imshow. If\n    provided, xy points will be normalized by the width/height of this\n    image. If not, xy points will be normalized by their own min/max.\nnormalize : bool\n    Whether to normalize the coordinates to run from 0 to 1. Defaults to\n    True.\n\nReturns\n-------\nlayout : Layout\n    A Layout object that can be plotted with plot_topo\n    functions and methods.\n\nSee Also\n--------\nmake_eeg_layout, make_grid_layout\n\nNotes\n-----\n.. versionadded:: 0.9.0", "metadata": {}}
{"_id": "mne_mne_channels/layout.py_copy_doc", "text": "Return a copy of the layout.\n\nReturns\n-------\nlayout : instance of Layout\n    A deepcopy of the layout.\n\nNotes\n-----\n.. versionadded:: 1.7", "metadata": {}}
{"_id": "mne_mne_channels/layout.py_save_doc", "text": "Save Layout to disk.\n\nParameters\n----------\nfname : path-like\n    The file name (e.g. ``'my_layout.lout'``).\noverwrite : bool\n    If True, overwrites the destination file if it exists.\n\nSee Also\n--------\nread_layout", "metadata": {}}
{"_id": "mne_mne_channels/layout.py_plot_doc", "text": "Plot the sensor positions.\n\nParameters\n----------\n%(picks_nostr)s\nshow_axes : bool\n    Show layout axes if True. Defaults to False.\nshow : bool\n    Show figure if True. Defaults to True.\n\nReturns\n-------\nfig : instance of matplotlib.figure.Figure\n    Figure containing the sensor topography.\n\nNotes\n-----\n.. versionadded:: 0.12.0", "metadata": {}}
{"_id": "mne_mne_channels/layout.py_pick_doc", "text": "Pick a subset of channels.\n\nParameters\n----------\n%(picks_layout)s\nexclude : str | int | array-like of str or int\n    Set of channels to exclude, only used when ``picks`` is set to ``'all'`` or\n    ``None``. Exclude will not drop channels explicitly provided in ``picks``.\n%(verbose)s\n\nReturns\n-------\nlayout : instance of Layout\n    The modified layout.\n\nNotes\n-----\n.. versionadded:: 1.7", "metadata": {}}
{"_id": "mne_mne_channels/channels.py_equalize_channels_doc", "text": "Equalize channel picks and ordering across multiple MNE-Python objects.\n\nFirst, all channels that are not common to each object are dropped. Then,\nusing the first object in the list as a template, the channels of each\nobject are re-ordered to match the template. The end result is that all\ngiven objects define the same channels, in the same order.\n\nParameters\n----------\ninstances : list\n    A list of MNE-Python objects to equalize the channels for. Objects can\n    be of type Raw, Epochs, Evoked, AverageTFR, Forward, Covariance,\n    CrossSpectralDensity or Info.\ncopy : bool\n    When dropping and/or re-ordering channels, an object will be copied\n    when this parameter is set to ``True``. When set to ``False`` (the\n    default) the dropping and re-ordering of channels happens in-place.\n\n    .. versionadded:: 0.20.0\n%(verbose)s\n\nReturns\n-------\nequalized_instances : list\n    A list of MNE-Python objects that have the same channels defined in the\n    same order.\n\nSee Also\n--------\nmne.channels.unify_bad_channels\nmne.channels.rename_channels\nmne.channels.combine_channels", "metadata": {}}
{"_id": "mne_mne_channels/channels.py_unify_bad_channels_doc", "text": "Unify bad channels across a list of instances.\n\nAll instances must be of the same type and have matching channel names and channel\norder. The ``.info[\"bads\"]`` of each instance will be set to the union of\n``.info[\"bads\"]`` across all instances.\n\nParameters\n----------\ninsts : list\n    List of instances (:class:`~mne.io.Raw`, :class:`~mne.Epochs`,\n    :class:`~mne.Evoked`, :class:`~mne.time_frequency.Spectrum`,\n    :class:`~mne.time_frequency.EpochsSpectrum`) across which to unify bad channels.\n\nReturns\n-------\ninsts : list\n    List of instances with bad channels unified across instances.\n\nSee Also\n--------\nmne.channels.equalize_channels\nmne.channels.rename_channels\nmne.channels.combine_channels\n\nNotes\n-----\nThis function modifies the instances in-place.\n\n.. versionadded:: 1.6", "metadata": {}}
{"_id": "mne_mne_channels/channels.py_rename_channels_doc", "text": "Rename channels.\n\nParameters\n----------\n%(info_not_none)s Note: modified in place.\n%(mapping_rename_channels_duplicates)s\n%(verbose)s\n\nSee Also\n--------\nmne.channels.equalize_channels\nmne.channels.unify_bad_channels\nmne.channels.combine_channels", "metadata": {}}
{"_id": "mne_mne_channels/channels.py_get_builtin_ch_adjacencies_doc", "text": "Get a list of all FieldTrip neighbor definitions shipping with MNE.\n\nThe names of the these neighbor definitions can be passed to\n:func:`read_ch_adjacency`.\n\nParameters\n----------\ndescriptions : bool\n    Whether to return not only the neighbor definition names, but also\n    their corresponding descriptions. If ``True``, a list of tuples is\n    returned, where the first tuple element is the neighbor definition name\n    and the second is the description. If ``False`` (default), only the\n    names are returned.\n\nReturns\n-------\nneighbor_name : list of str | list of tuple\n    If ``descriptions=False``, the names of all builtin FieldTrip neighbor\n    definitions that can be loaded directly via :func:`read_ch_adjacency`.\n\n    If ``descriptions=True``, a list of tuples ``(name, description)``.\n\nNotes\n-----\n.. versionadded:: 1.1", "metadata": {}}
{"_id": "mne_mne_channels/channels.py_read_ch_adjacency_doc", "text": "Read a channel adjacency (\"neighbors\") file that ships with MNE.\n\nMore information on these neighbor definitions can be found on the related\n`FieldTrip documentation pages\n<http://www.fieldtriptoolbox.org/template/neighbours/>`__.\n\nParameters\n----------\nfname : path-like | str\n    The path to the file to load, or the name of a channel adjacency\n    matrix that ships with MNE-Python.\n\n    .. note::\n        You can retrieve the names of all\n        built-in channel adjacencies via\n        :func:`mne.channels.get_builtin_ch_adjacencies`.\n%(picks_all_notypes)s\n\nReturns\n-------\nch_adjacency : scipy.sparse.csr_array, shape (n_channels, n_channels)\n    The adjacency matrix.\nch_names : list\n    The list of channel names present in adjacency matrix.\n\nSee Also\n--------\nget_builtin_ch_adjacencies\nmne.viz.plot_ch_adjacency\nfind_ch_adjacency\nmne.stats.combine_adjacency\n\nNotes\n-----\nIf the neighbor definition you need is not shipped by MNE-Python,\nyou may use :func:`find_ch_adjacency` to compute the\nadjacency matrix based on your 2D sensor locations.\n\nNote that depending on your use case, you may need to additionally use\n:func:`mne.stats.combine_adjacency` to prepare a final \"adjacency\"\nto pass to the eventual function.", "metadata": {}}
{"_id": "mne_mne_channels/channels.py_find_ch_adjacency_doc", "text": "Find the adjacency matrix for the given channels.\n\nThis function tries to infer the appropriate adjacency matrix template\nfor the given channels. If a template is not found, the adjacency matrix\nis computed using Delaunay triangulation based on 2D sensor locations.\n\nParameters\n----------\n%(info_not_none)s\nch_type : str | None\n    The channel type for computing the adjacency matrix. Currently\n    supports ``'mag'``, ``'grad'``, ``'eeg'`` and ``None``.\n    If ``None``, the info must contain only one channel type.\n\nReturns\n-------\nch_adjacency : scipy.sparse.csr_array, shape (n_channels, n_channels)\n    The adjacency matrix.\nch_names : list\n    The list of channel names present in adjacency matrix.\n\nSee Also\n--------\nmne.viz.plot_ch_adjacency\nmne.stats.combine_adjacency\nget_builtin_ch_adjacencies\nread_ch_adjacency\n\nNotes\n-----\n.. versionadded:: 0.15\n\nAutomatic detection of an appropriate adjacency matrix template only\nworks for MEG data at the moment. This means that the adjacency matrix\nis always computed for EEG data and never loaded from a template file. If\nyou want to load a template for a given montage use\n:func:`read_ch_adjacency` directly.\n\n.. warning::\n    If Delaunay triangulation is used to calculate the adjacency matrix it\n    may yield partially unexpected results (e.g., include unwanted edges\n    between non-adjacent sensors). Therefore, it is recommended to check\n    (and, if necessary, manually modify) the result by inspecting it\n    via :func:`mne.viz.plot_ch_adjacency`.\n\nNote that depending on your use case, you may need to additionally use\n:func:`mne.stats.combine_adjacency` to prepare a final \"adjacency\"\nto pass to the eventual function.", "metadata": {}}
{"_id": "mne_mne_channels/channels.py_fix_mag_coil_types_doc", "text": "Fix magnetometer coil types.\n\nParameters\n----------\n%(info_not_none)s Corrections are done in-place.\nuse_cal : bool\n    If True, further refine the check for old coil types by checking\n    ``info['chs'][ii]['cal']``.\n\nNotes\n-----\nThis function changes magnetometer coil types 3022 (T1: SQ20483N) and\n3023 (T2: SQ20483-A) to 3024 (T3: SQ20950N) in the channel definition\nrecords in the info structure.\n\nNeuromag Vectorview systems can contain magnetometers with two\ndifferent coil sizes (3022 and 3023 vs. 3024). The systems\nincorporating coils of type 3024 were introduced last and are used at\nthe majority of MEG sites. At some sites with 3024 magnetometers,\nthe data files have still defined the magnetometers to be of type\n3022 to ensure compatibility with older versions of Neuromag software.\nIn the MNE software as well as in the present version of Neuromag\nsoftware coil type 3024 is fully supported. Therefore, it is now safe\nto upgrade the data files to use the true coil type.\n\n.. note:: The effect of the difference between the coil sizes on the\n          current estimates computed by the MNE software is very small.\n          Therefore the use of ``fix_mag_coil_types`` is not mandatory.", "metadata": {}}
{"_id": "mne_mne_channels/channels.py_make_1020_channel_selections_doc", "text": "Map hemisphere names to corresponding EEG channel names or indices.\n\nThis function uses a simple heuristic to separate channel names into three\nRegion of Interest-based selections: ``Left``, ``Midline`` and ``Right``.\n\nThe heuristic is that any of the channel names ending\nwith odd numbers are filed under ``Left``; those ending with even numbers\nare filed under ``Right``; and those ending with the character(s) specified\nin ``midline`` are filed under ``Midline``. Other channels are ignored.\n\nThis is appropriate for 10/20, 10/10, 10/05, \u2026, sensor arrangements, but\nnot for other naming conventions.\n\nParameters\n----------\n%(info_not_none)s If channel locations are present, the channel lists will\n    be sorted from posterior to anterior; otherwise, the order specified in\n    ``info[\"ch_names\"]`` will be kept.\nmidline : str\n    Names ending in any of these characters are stored under the\n    ``Midline`` key. Defaults to ``'z'``. Capitalization is ignored.\nreturn_ch_names : bool\n    Whether to return channel names instead of channel indices.\n\n    .. versionadded:: 1.4.0\n\nReturns\n-------\nselections : dict\n    A dictionary mapping from region of interest name to a list of channel\n    indices (if ``return_ch_names=False``) or to a list of channel names\n    (if ``return_ch_names=True``).", "metadata": {}}
{"_id": "mne_mne_channels/channels.py_combine_channels_doc", "text": "Combine channels based on specified channel grouping.\n\nParameters\n----------\ninst : instance of Raw, Epochs, or Evoked\n    An MNE-Python object to combine the channels for. The object can be of\n    type Raw, Epochs, or Evoked.\ngroups : dict\n    Specifies which channels are aggregated into a single channel, with\n    aggregation method determined by the ``method`` parameter. One new\n    pseudo-channel is made per dict entry; the dict values must be lists of\n    picks (integer indices of ``ch_names``). For example::\n\n        groups=dict(Left=[1, 2, 3, 4], Right=[5, 6, 7, 8])\n\n    Note that within a dict entry all channels must have the same type.\nmethod : str | callable\n    Which method to use to combine channels. If a :class:`str`, must be one\n    of 'mean', 'median', or 'std' (standard deviation). If callable, the\n    callable must accept one positional input (data of shape ``(n_channels,\n    n_times)``, or ``(n_epochs, n_channels, n_times)``) and return an\n    :class:`array <numpy.ndarray>` of shape ``(n_times,)``, or ``(n_epochs,\n    n_times)``. For example with an instance of Raw or Evoked::\n\n        method = lambda data: np.mean(data, axis=0)\n\n    Another example with an instance of Epochs::\n\n        method = lambda data: np.median(data, axis=1)\n\n    Defaults to ``'mean'``.\nkeep_stim : bool\n    If ``True``, include stimulus channels in the resulting object.\n    Defaults to ``False``.\ndrop_bad : bool\n    If ``True``, drop channels marked as bad before combining. Defaults to\n    ``False``.\n%(verbose)s\n\nReturns\n-------\ncombined_inst : instance of Raw, Epochs, or Evoked\n    An MNE-Python object of the same type as the input ``inst``, containing\n    one virtual channel for each group in ``groups`` (and, if ``keep_stim``\n    is ``True``, also containing stimulus channels).\n\nSee Also\n--------\nmne.channels.equalize_channels\nmne.channels.rename_channels\nmne.channels.unify_bad_channels", "metadata": {}}
{"_id": "mne_mne_channels/channels.py_read_vectorview_selection_doc", "text": "Read Neuromag Vector View channel selection from a file.\n\nParameters\n----------\nname : str | list of str\n    Name of the selection. If a list, the selections are combined.\n    Supported selections are: ``'Vertex'``, ``'Left-temporal'``,\n    ``'Right-temporal'``, ``'Left-parietal'``, ``'Right-parietal'``,\n    ``'Left-occipital'``, ``'Right-occipital'``, ``'Left-frontal'`` and\n    ``'Right-frontal'``. Selections can also be matched and combined by\n    spcecifying common substrings. For example, ``name='temporal`` will\n    produce a combination of ``'Left-temporal'`` and ``'Right-temporal'``.\nfname : path-like\n    Filename of the selection file (if ``None``, built-in selections are\n    used).\n%(info)s Used to determine which channel naming convention to use, e.g.\n    ``'MEG 0111'`` (with space) for old Neuromag systems and ``'MEG0111'``\n    (without space) for new ones.\n%(verbose)s\n\nReturns\n-------\nsel : list of str\n    List with channel names in the selection.", "metadata": {}}
{"_id": "mne_mne_channels/channels.py_set_eeg_reference_doc", "text": "Specify which reference to use for EEG data.\n\nUse this function to explicitly specify the desired reference for EEG.\nThis can be either an existing electrode or a new virtual channel.\nThis function will re-reference the data according to the desired\nreference.\n\nParameters\n----------\n%(ref_channels_set_eeg_reference)s\n%(projection_set_eeg_reference)s\n%(ch_type_set_eeg_reference)s\n%(forward_set_eeg_reference)s\n%(joint_set_eeg_reference)s\n%(verbose)s\n\nReturns\n-------\ninst : instance of Raw | Epochs | Evoked\n    Data with EEG channels re-referenced. If ``ref_channels='average'``\n    and ``projection=True`` a projection will be added instead of\n    directly re-referencing the data.\n%(set_eeg_reference_see_also_notes)s", "metadata": {}}
{"_id": "mne_mne_channels/channels.py_pick_types_doc", "text": "Pick some channels by type and names.\n\nParameters\n----------\n%(pick_types_params)s\n%(verbose)s\n\nReturns\n-------\ninst : instance of Raw, Epochs, or Evoked\n    The modified instance.\n\nSee Also\n--------\npick_channels\n\nNotes\n-----\n.. versionadded:: 0.9.0", "metadata": {}}
{"_id": "mne_mne_channels/channels.py_pick_channels_doc", "text": "Pick some channels.\n\nParameters\n----------\nch_names : list\n    The list of channels to select.\n%(ordered)s\n%(verbose)s\n\n    .. versionadded:: 1.1\n\nReturns\n-------\ninst : instance of Raw, Epochs, or Evoked\n    The modified instance.\n\nSee Also\n--------\ndrop_channels\npick_types\nreorder_channels\n\nNotes\n-----\nIf ``ordered`` is ``False``, the channel names given via ``ch_names`` are\nassumed to be a set, that is, their order does not matter. In that case, the\noriginal order of the channels in the data is preserved. Apart from using\n``ordered=True``, you may also use ``reorder_channels`` to set channel order,\nif necessary.\n\n.. versionadded:: 0.9.0", "metadata": {}}
{"_id": "mne_mne_channels/channels.py_pick_doc", "text": "Pick a subset of channels.\n\nParameters\n----------\n%(picks_all)s\nexclude : list | str\n    Set of channels to exclude, only used when picking based on\n    types (e.g., exclude=\"bads\" when picks=\"meg\").\n%(verbose)s\n\n    .. versionadded:: 0.24.0\n\nReturns\n-------\ninst : instance of Raw, Epochs, or Evoked\n    The modified instance.", "metadata": {}}
{"_id": "mne_mne_channels/channels.py_reorder_channels_doc", "text": "Reorder channels.\n\nParameters\n----------\nch_names : list\n    The desired channel order.\n\nReturns\n-------\ninst : instance of Raw, Epochs, or Evoked\n    The modified instance.\n\nSee Also\n--------\ndrop_channels\npick_types\npick_channels\n\nNotes\n-----\nChannel names must be unique. Channels that are not in ``ch_names``\nare dropped.\n\n.. versionadded:: 0.16.0", "metadata": {}}
{"_id": "mne_mne_channels/channels.py_drop_channels_doc", "text": "Drop channel(s).\n\nParameters\n----------\nch_names : iterable or str\n    Iterable (e.g. list) of channel name(s) or channel name to remove.\n%(on_missing_ch_names)s\n\nReturns\n-------\ninst : instance of Raw, Epochs, or Evoked\n    The modified instance.\n\nSee Also\n--------\nreorder_channels\npick_channels\npick_types\n\nNotes\n-----\n.. versionadded:: 0.9.0", "metadata": {}}
{"_id": "mne_mne_channels/channels.py_add_channels_doc", "text": "Append new channels from other MNE objects to the instance.\n\nParameters\n----------\nadd_list : list\n    A list of MNE objects to append to the current instance.\n    The channels contained in the other instances are appended to the\n    channels of the current instance. Therefore, all other instances\n    must be of the same type as the current object.\n    See notes on how to add data coming from an array.\nforce_update_info : bool\n    If True, force the info for objects to be appended to match the\n    values of the current instance. This should generally only be\n    used when adding stim channels for which important metadata won't\n    be overwritten.\n\n    .. versionadded:: 0.12\n\nReturns\n-------\ninst : instance of Raw, Epochs, or Evoked\n    The modified instance.\n\nSee Also\n--------\ndrop_channels\n\nNotes\n-----\nIf ``self`` is a Raw instance that has been preloaded into a\n:obj:`numpy.memmap` instance, the memmap will be resized.\n\nThis function expects an MNE object to be appended (e.g. :class:`~mne.io.Raw`,\n:class:`~mne.Epochs`, :class:`~mne.Evoked`). If you simply want to add a\nchannel based on values of an np.ndarray, you need to create a\n:class:`~mne.io.RawArray`.\nSee <https://mne.tools/mne-project-template/auto_examples/plot_mne_objects_from_arrays.html>`_", "metadata": {}}
{"_id": "mne_mne_channels/channels.py_add_reference_channels_doc", "text": "Add reference channels to data that consists of all zeros.\n\nAdds reference channels to data that were not included during\nrecording. This is useful when you need to re-reference your data\nto different channels. These added channels will consist of all zeros.\n\nParameters\n----------\n%(ref_channels)s\n\nReturns\n-------\ninst : instance of Raw | Epochs | Evoked\n       The modified instance.", "metadata": {}}
{"_id": "mne_mne_channels/channels.py_interpolate_bads_doc", "text": "Interpolate bad MEG and EEG channels.\n\nOperates in place.\n\nParameters\n----------\nreset_bads : bool\n    If True, remove the bads from info.\nmode : str\n    Either ``'accurate'`` or ``'fast'``, determines the quality of the\n    Legendre polynomial expansion used for interpolation of channels\n    using the minimum-norm method.\norigin : array-like, shape (3,) | str\n    Origin of the sphere in the head coordinate frame and in meters.\n    Can be ``'auto'`` (default), which means a head-digitization-based\n    origin fit.\n\n    .. versionadded:: 0.17\nmethod : dict | str | None\n    Method to use for each channel type.\n\n    - ``\"meg\"`` channels support ``\"MNE\"`` (default) and ``\"nan\"``\n    - ``\"eeg\"`` channels support ``\"spline\"`` (default), ``\"MNE\"`` and ``\"nan\"``\n    - ``\"fnirs\"`` channels support ``\"nearest\"`` (default) and ``\"nan\"``\n    - ``\"ecog\"`` channels support ``\"spline\"`` (default) and ``\"nan\"``\n    - ``\"seeg\"`` channels support ``\"spline\"`` (default) and ``\"nan\"``\n\n    None is an alias for::\n\n        method=dict(meg=\"MNE\", eeg=\"spline\", fnirs=\"nearest\")\n\n    If a :class:`str` is provided, the method will be applied to all channel\n    types supported and available in the instance. The method ``\"nan\"`` will\n    replace the channel data with ``np.nan``.\n\n    .. warning::\n        Be careful when using ``method=\"nan\"``; the default value\n        ``reset_bads=True`` may not be what you want.\n\n    .. versionadded:: 0.21\nexclude : list | tuple\n    The channels to exclude from interpolation. If excluded a bad\n    channel will stay in bads.\n%(verbose)s\n\nReturns\n-------\ninst : instance of Raw, Epochs, or Evoked\n    The modified instance.\n\nNotes\n-----\nThe ``\"MNE\"`` method uses minimum-norm projection to a sphere and back.\n\n.. versionadded:: 0.9.0", "metadata": {}}
{"_id": "mne_mne_channels/channels.py_interpolate_to_doc", "text": "Interpolate EEG data onto a new montage.\n\n.. warning::\n    Be careful, only EEG channels are interpolated. Other channel types are\n    not interpolated.\n\nParameters\n----------\nsensors : DigMontage\n    The target montage containing channel positions to interpolate onto.\norigin : array-like, shape (3,) | str\n    Origin of the sphere in the head coordinate frame and in meters.\n    Can be ``'auto'`` (default), which means a head-digitization-based\n    origin fit.\nmethod : str\n    Method to use for EEG channels.\n    Supported methods are 'spline' (default) and 'MNE'.\nreg : float\n    The regularization parameter for the interpolation method\n    (only used when the method is 'spline').\n\nReturns\n-------\ninst : instance of Raw, Epochs, or Evoked\n    The instance with updated channel locations and data.\n\nNotes\n-----\nThis method is useful for standardizing EEG layouts across datasets.\nHowever, some attributes may be lost after interpolation.\n\n.. versionadded:: 1.10.0", "metadata": {}}
{"_id": "mne_mne_stats/multi_comp.py_fdr_correction_doc", "text": "P-value correction with False Discovery Rate (FDR).\n\nCorrection for multiple comparison using FDR :footcite:`GenoveseEtAl2002`.\n\nThis covers Benjamini/Hochberg for independent or positively correlated and\nBenjamini/Yekutieli for general or negatively correlated tests.\n\nParameters\n----------\npvals : array_like\n    Set of p-values of the individual tests.\nalpha : float\n    Error rate.\nmethod : 'indep' | 'negcorr'\n    If 'indep' it implements Benjamini/Hochberg for independent or if\n    'negcorr' it corresponds to Benjamini/Yekutieli.\n\nReturns\n-------\nreject : array, bool\n    True if a hypothesis is rejected, False if not.\npval_corrected : array\n    P-values adjusted for multiple hypothesis testing to limit FDR.\n\nReferences\n----------\n.. footbibliography::", "metadata": {}}
{"_id": "mne_mne_stats/multi_comp.py_bonferroni_correction_doc", "text": "P-value correction with Bonferroni method.\n\nParameters\n----------\npval : array_like\n    Set of p-values of the individual tests.\nalpha : float\n    Error rate.\n\nReturns\n-------\nreject : array, bool\n    True if a hypothesis is rejected, False if not.\npval_corrected : array\n    P-values adjusted for multiple hypothesis testing to limit FDR.", "metadata": {}}
{"_id": "mne_mne_stats/permutations.py_permutation_t_test_doc", "text": "One sample/paired sample permutation test based on a t-statistic.\n\nThis function can perform the test on one variable or\nsimultaneously on multiple variables. When applying the test to multiple\nvariables, the \"tmax\" method is used for adjusting the p-values of each\nvariable for multiple comparisons. Like Bonferroni correction, this method\nadjusts p-values in a way that controls the family-wise error rate.\nHowever, the permutation method will be more\npowerful than Bonferroni correction when different variables in the test\nare correlated (see :footcite:`NicholsHolmes2002`).\n\nParameters\n----------\nX : array, shape (n_samples, n_tests)\n    Samples (observations) by number of tests (variables).\nn_permutations : int | 'all'\n    Number of permutations. If n_permutations is 'all' all possible\n    permutations are tested. It's the exact test, that\n    can be untractable when the number of samples is big (e.g. > 20).\n    If n_permutations >= 2**n_samples then the exact test is performed.\ntail : -1 or 0 or 1 (default = 0)\n    If tail is 1, the alternative hypothesis is that the\n    mean of the data is greater than 0 (upper tailed test).  If tail is 0,\n    the alternative hypothesis is that the mean of the data is different\n    than 0 (two tailed test).  If tail is -1, the alternative hypothesis\n    is that the mean of the data is less than 0 (lower tailed test).\n%(n_jobs)s\n%(seed)s\n%(verbose)s\n\nReturns\n-------\nT_obs : array of shape [n_tests]\n    T-statistic observed for all variables.\np_values : array of shape [n_tests]\n    P-values for all the tests (a.k.a. variables).\nH0 : array of shape [n_permutations]\n    T-statistic obtained by permutations and t-max trick for multiple\n    comparison.\n\nNotes\n-----\nIf ``n_permutations >= 2 ** (n_samples - (tail == 0))``,\n``n_permutations`` and ``seed`` will be ignored since an exact test\n(full permutation test) will be performed.\n\nReferences\n----------\n.. footbibliography::", "metadata": {}}
{"_id": "mne_mne_stats/permutations.py_bootstrap_confidence_interval_doc", "text": "Get confidence intervals from non-parametric bootstrap.\n\nParameters\n----------\narr : ndarray, shape (n_samples, ...)\n    The input data on which to calculate the confidence interval.\nci : float\n    Level of the confidence interval between 0 and 1.\nn_bootstraps : int\n    Number of bootstraps.\nstat_fun : str | callable\n    Can be \"mean\", \"median\", or a callable operating along ``axis=0``.\nrandom_state : int | float | array_like | None\n    The seed at which to initialize the bootstrap.\n\nReturns\n-------\ncis : ndarray, shape (2, ...)\n    Containing the lower boundary of the CI at ``cis[0, ...]`` and the\n    upper boundary of the CI at ``cis[1, ...]``.", "metadata": {}}
{"_id": "mne_mne_stats/erp.py_compute_sme_doc", "text": "Compute standardized measurement error (SME).\n\nThe standardized measurement error :footcite:`LuckEtAl2021` can be used as a\nuniversal measure of data quality in ERP studies.\n\nParameters\n----------\nepochs : mne.Epochs\n    The epochs containing the data for which to compute the SME.\nstart : int | float | None\n    Start time (in s) of the time window used for SME computation. If ``None``, use\n    the start of the epoch.\nstop : int | float | None\n    Stop time (in s) of the time window used for SME computation. If ``None``, use\n    the end of the epoch.\n\nReturns\n-------\nsme : array, shape (n_channels,)\n    SME in given time window for each channel.\n\nNotes\n-----\nCurrently, only the mean value in the given time window is supported, meaning that\nthe resulting SME is only valid in studies which quantify the amplitude of an ERP\ncomponent as the mean within the time window (as opposed to e.g. the peak, which\nwould require bootstrapping).\n\nReferences\n----------\n.. footbibliography::\n\nExamples\n--------\nGiven an :class:`~mne.Epochs` object, the SME for the entire epoch duration can be\ncomputed as follows:\n\n    >>> compute_sme(epochs)  # doctest: +SKIP\n\nHowever, the SME is best used to estimate the precision of a specific ERP measure,\nspecifically the mean amplitude of an ERP component in a time window of interest.\nFor example, the SME for the mean amplitude of the P3 component in the 300-500 ms\ntime window could be computed as follows:\n\n    >>> compute_sme(epochs, start=0.3, stop=0.5)  # doctest: +SKIP\n\nUsually, it will be more informative to compute the SME for specific conditions\nseparately. This can be done by selecting the epochs of interest as follows:\n\n    >>> compute_sme(epochs[\"oddball\"], 0.3, 0.5)  # doctest: +SKIP\n\nNote that the SME will be reported for each channel separately. If you are only\ninterested in a single channel (or a subset of channels), select the channels\nbefore computing the SME:\n\n    >>> compute_sme(epochs.pick(\"Pz\"), 0.3, 0.5)  # doctest: +SKIP\n\nSelecting both conditions and channels is also possible:\n\n    >>> compute_sme(epochs[\"oddball\"].pick(\"Pz\"), 0.3, 0.5)  # doctest: +SKIP\n\nIn any case, the output will be a NumPy array with the SME value for each channel.", "metadata": {}}
{"_id": "mne_mne_stats/cluster_level.py_bin_perm_rep_doc", "text": "Ndim permutations with repetitions of (a,b).\n\nReturns an array with all the possible permutations with repetitions of\n(0,1) in ndim dimensions.  The array is shaped as (2**ndim,ndim), and is\nordered with the last index changing fastest.  For examble, for ndim=3:\n\nExamples\n--------\n>>> bin_perm_rep(3)\narray([[0, 0, 0],\n       [0, 0, 1],\n       [0, 1, 0],\n       [0, 1, 1],\n       [1, 0, 0],\n       [1, 0, 1],\n       [1, 1, 0],\n       [1, 1, 1]])", "metadata": {}}
{"_id": "mne_mne_stats/cluster_level.py_permutation_cluster_test_doc", "text": "Cluster-level statistical permutation test.\n\nFor a list of :class:`NumPy arrays <numpy.ndarray>` of data,\ncalculate some statistics corrected for multiple comparisons using\npermutations and cluster-level correction. Each element of the list ``X``\nshould contain the data for one group of observations (e.g., 2D arrays for\ntime series, 3D arrays for time-frequency power values). Permutations are\ngenerated with random partitions of the data. For details, see\n:footcite:p:`MarisOostenveld2007,Sassenhagen2019`.\n\nParameters\n----------\nX : list of array, shape (n_observations, p[, q][, r])\n    The data to be clustered. Each array in ``X`` should contain the\n    observations for one group. The first dimension of each array is the\n    number of observations from that group; remaining dimensions comprise\n    the size of a single observation. For example if ``X = [X1, X2]``\n    with ``X1.shape = (20, 50, 4)`` and ``X2.shape = (17, 50, 4)``, then\n    ``X`` has 2 groups with respectively 20 and 17 observations in each,\n    and each data point is of shape ``(50, 4)``. Note: that the\n    *last dimension* of each element of ``X`` should correspond to the\n    dimension represented in the ``adjacency`` parameter\n    (e.g., spectral data should be provided as\n    ``(observations, frequencies, channels/vertices)``).\n%(threshold_clust_f)s\n%(n_permutations_clust_int)s\n%(tail_clust)s\n%(stat_fun_clust_f)s\n%(adjacency_clust_n)s\n%(n_jobs)s\n%(seed)s\n%(max_step_clust)s\n%(exclude_clust)s\n%(step_down_p_clust)s\n%(f_power_clust)s\n%(out_type_clust)s\n%(check_disjoint_clust)s\n%(buffer_size_clust)s\n%(verbose)s\n\nReturns\n-------\nF_obs : array, shape (p[, q][, r])\n    Statistic (F by default) observed for all variables.\nclusters : list\n    List type defined by out_type above.\ncluster_pv : array\n    P-value for each cluster.\nH0 : array, shape (n_permutations,)\n    Max cluster level stats observed under permutation.\n\nNotes\n-----\n%(threshold_clust_f_notes)s\n\nReferences\n----------\n.. footbibliography::", "metadata": {}}
{"_id": "mne_mne_stats/cluster_level.py_permutation_cluster_1samp_test_doc", "text": "Non-parametric cluster-level paired t-test.\n\nFor details, see :footcite:p:`MarisOostenveld2007,Sassenhagen2019`.\n\nParameters\n----------\nX : array, shape (n_observations, p[, q][, r])\n    The data to be clustered. The first dimension should correspond to the\n    difference between paired samples (observations) in two conditions.\n    The subarrays ``X[k]`` can be 1D (e.g., time series), 2D (e.g.,\n    time series over channels), or 3D (e.g., time-frequencies over\n    channels) associated with the kth observation. For spatiotemporal data,\n    see also :func:`mne.stats.spatio_temporal_cluster_1samp_test`.\n%(threshold_clust_t)s\n%(n_permutations_clust_all)s\n%(tail_clust)s\n%(stat_fun_clust_t)s\n%(adjacency_clust_1)s\n%(n_jobs)s\n%(seed)s\n%(max_step_clust)s\n%(exclude_clust)s\n%(step_down_p_clust)s\n%(t_power_clust)s\n%(out_type_clust)s\n%(check_disjoint_clust)s\n%(buffer_size_clust)s\n%(verbose)s\n\nReturns\n-------\nt_obs : array, shape (p[, q][, r])\n    T-statistic observed for all variables.\nclusters : list\n    List type defined by out_type above.\ncluster_pv : array\n    P-value for each cluster.\nH0 : array, shape (n_permutations,)\n    Max cluster level stats observed under permutation.\n\nNotes\n-----\nFrom an array of paired observations, e.g. a difference in signal\namplitudes or power spectra in two conditions, calculate if the data\ndistributions in the two conditions are significantly different.\nThe procedure uses a cluster analysis with permutation test\nfor calculating corrected p-values. Randomized data are generated with\nrandom sign flips. See :footcite:`MarisOostenveld2007` for more\ninformation.\n\nBecause a 1-sample t-test on the difference in observations is\nmathematically equivalent to a paired t-test, internally this function\ncomputes a 1-sample t-test (by default) and uses sign flipping (always)\nto perform permutations. This might not be suitable for the case where\nthere is truly a single observation under test; see :ref:`disc-stats`.\n%(threshold_clust_t_notes)s\n\nIf ``n_permutations`` exceeds the maximum number of possible permutations\ngiven the number of observations, then ``n_permutations`` and ``seed``\nwill be ignored since an exact test (full permutation test) will be\nperformed (this is the case when\n``n_permutations >= 2 ** (n_observations - (tail == 0))``).\n\nIf no initial clusters are found because all points in the true\ndistribution are below the threshold, then ``clusters``, ``cluster_pv``,\nand ``H0`` will all be empty arrays.\n\nReferences\n----------\n.. footbibliography::", "metadata": {}}
{"_id": "mne_mne_stats/cluster_level.py_spatio_temporal_cluster_1samp_test_doc", "text": "Non-parametric cluster-level paired t-test for spatio-temporal data.\n\nThis function provides a convenient wrapper for\n:func:`mne.stats.permutation_cluster_1samp_test`, for use with data\norganized in the form (observations \u00d7 time \u00d7 space),\n(observations \u00d7 frequencies \u00d7 space), or optionally\n(observations \u00d7 time \u00d7 frequencies \u00d7 space). For details, see\n:footcite:p:`MarisOostenveld2007,Sassenhagen2019`.\n\nParameters\n----------\nX : array, shape (n_observations, p[, q], n_vertices)\n    The data to be clustered. The first dimension should correspond to the\n    difference between paired samples (observations) in two conditions.\n    The second, and optionally third, dimensions correspond to the\n    time or time-frequency data. And, the last dimension should be spatial.\n%(threshold_clust_t)s\n%(n_permutations_clust_all)s\n%(tail_clust)s\n%(stat_fun_clust_t)s\n%(adjacency_clust_st1)s\n%(n_jobs)s\n%(seed)s\n%(max_step_clust)s\nspatial_exclude : list of int or None\n    List of spatial indices to exclude from clustering.\n%(step_down_p_clust)s\n%(t_power_clust)s\n%(out_type_clust)s\n%(check_disjoint_clust)s\n%(buffer_size_clust)s\n%(verbose)s\n\nReturns\n-------\nt_obs : array, shape (p[, q], n_vertices)\n    T-statistic observed for all variables.\nclusters : list\n    List type defined by out_type above.\ncluster_pv : array\n    P-value for each cluster.\nH0 : array, shape (n_permutations,)\n    Max cluster level stats observed under permutation.\n\nNotes\n-----\n%(threshold_clust_t_notes)s\n\nReferences\n----------\n.. footbibliography::", "metadata": {}}
{"_id": "mne_mne_stats/cluster_level.py_spatio_temporal_cluster_test_doc", "text": "Non-parametric cluster-level test for spatio-temporal data.\n\nThis function provides a convenient wrapper for\n:func:`mne.stats.permutation_cluster_test`, for use with data\norganized in the form (observations \u00d7 time \u00d7 space),\n(observations \u00d7 time \u00d7 space), or optionally\n(observations \u00d7 time \u00d7 frequencies \u00d7 space). For more information,\nsee :footcite:p:`MarisOostenveld2007,Sassenhagen2019`.\n\nParameters\n----------\nX : list of array, shape (n_observations, p[, q], n_vertices)\n    The data to be clustered. Each array in ``X`` should contain the\n    observations for one group. The first dimension of each array is the\n    number of observations from that group (and may vary between groups).\n    The second, and optionally third, dimensions correspond to the\n    time or time-frequency data. And, the last dimension should be spatial.\n    All dimensions except the first should match across all groups.\n%(threshold_clust_f)s\n%(n_permutations_clust_int)s\n%(tail_clust)s\n%(stat_fun_clust_f)s\n%(adjacency_clust_stn)s\n%(n_jobs)s\n%(seed)s\n%(max_step_clust)s\nspatial_exclude : list of int or None\n    List of spatial indices to exclude from clustering.\n%(step_down_p_clust)s\n%(f_power_clust)s\n%(out_type_clust)s\n%(check_disjoint_clust)s\n%(buffer_size_clust)s\n%(verbose)s\n\nReturns\n-------\nF_obs : array, shape (p[, q], n_vertices)\n    Statistic (F by default) observed for all variables.\nclusters : list\n    List type defined by out_type above.\ncluster_pv: array\n    P-value for each cluster.\nH0 : array, shape (n_permutations,)\n    Max cluster level stats observed under permutation.\n\nNotes\n-----\n%(threshold_clust_f_notes)s\n\nReferences\n----------\n.. footbibliography::", "metadata": {}}
{"_id": "mne_mne_stats/cluster_level.py_summarize_clusters_stc_doc", "text": "Assemble summary SourceEstimate from spatiotemporal cluster results.\n\nThis helps visualizing results from spatio-temporal-clustering\npermutation tests.\n\nParameters\n----------\nclu : tuple\n    The output from clustering permutation tests.\np_thresh : float\n    The significance threshold for inclusion of clusters.\ntstep : float\n    The time step between samples of the original :class:`STC\n    <mne.SourceEstimate>`, in seconds (i.e., ``1 / stc.sfreq``). Defaults\n    to ``1``, which will yield a colormap indicating cluster duration\n    measured in *samples* rather than *seconds*.\ntmin : float | int\n    The time of the first sample.\nsubject : str\n    The name of the subject.\nvertices : list of array | instance of SourceSpaces | None\n    The vertex numbers associated with the source space locations. Defaults\n    to None. If None, equals ``[np.arange(10242), np.arange(10242)]``.\n    Can also be an instance of SourceSpaces to get vertex numbers from.\n\n    .. versionchanged:: 0.21\n       Added support for SourceSpaces.\n\nReturns\n-------\nout : instance of SourceEstimate\n    A summary of the clusters. The first time point in this SourceEstimate\n    object is the summation of all the clusters. Subsequent time points\n    contain each individual cluster. The magnitude of the activity\n    corresponds to the duration spanned by the cluster (duration units are\n    determined by ``tstep``).\n\n    .. versionchanged:: 0.21\n       Added support for volume and mixed source estimates.", "metadata": {}}
{"_id": "mne_mne_stats/regression.py_linear_regression_doc", "text": "Fit Ordinary Least Squares (OLS) regression.\n\nParameters\n----------\ninst : instance of Epochs | iterable of SourceEstimate\n    The data to be regressed. Contains all the trials, sensors, and time\n    points for the regression. For Source Estimates, accepts either a list\n    or a generator object.\ndesign_matrix : ndarray, shape (n_observations, n_regressors)\n    The regressors to be used. Must be a 2d array with as many rows as\n    the first dimension of the data. The first column of this matrix will\n    typically consist of ones (intercept column).\nnames : array-like | None\n    Optional parameter to name the regressors (i.e., the columns in the\n    design matrix). If provided, the length must correspond to the number\n    of columns present in design matrix (including the intercept, if\n    present). Otherwise, the default names are ``'x0'``, ``'x1'``,\n    ``'x2', \u2026, 'x(n-1)'`` for ``n`` regressors.\n\nReturns\n-------\nresults : dict of namedtuple\n    For each regressor (key), a namedtuple is provided with the\n    following attributes:\n\n        - ``beta`` : regression coefficients\n        - ``stderr`` : standard error of regression coefficients\n        - ``t_val`` : t statistics (``beta`` / ``stderr``)\n        - ``p_val`` : two-sided p-value of t statistic under the t\n          distribution\n        - ``mlog10_p_val`` : -log\u2081\u2080-transformed p-value.\n\n    The tuple members are numpy arrays. The shape of each numpy array is\n    the shape of the data minus the first dimension; e.g., if the shape of\n    the original data was ``(n_observations, n_channels, n_timepoints)``,\n    then the shape of each of the arrays will be\n    ``(n_channels, n_timepoints)``.", "metadata": {}}
{"_id": "mne_mne_stats/regression.py_linear_regression_raw_doc", "text": "Estimate regression-based evoked potentials/fields by linear modeling.\n\nThis models the full M/EEG time course, including correction for\noverlapping potentials and allowing for continuous/scalar predictors.\nInternally, this constructs a predictor matrix X of size\nn_samples * (n_conds * window length), solving the linear system\n``Y = bX`` and returning ``b`` as evoked-like time series split by\ncondition. See :footcite:`SmithKutas2015`.\n\nParameters\n----------\nraw : instance of Raw\n    A raw object. Note: be very careful about data that is not\n    downsampled, as the resulting matrices can be enormous and easily\n    overload your computer. Typically, 100 Hz sampling rate is\n    appropriate - or using the decim keyword (see below).\nevents : ndarray of int, shape (n_events, 3)\n    An array where the first column corresponds to samples in raw\n    and the last to integer codes in event_id.\nevent_id : dict | None\n    As in Epochs; a dictionary where the values may be integers or\n    iterables of integers, corresponding to the 3rd column of\n    events, and the keys are condition names.\n    If None, uses all events in the events array.\ntmin : float | dict\n    If float, gives the lower limit (in seconds) for the time window for\n    which all event types' effects are estimated. If a dict, can be used to\n    specify time windows for specific event types: keys correspond to keys\n    in event_id and/or covariates; for missing values, the default (-.1) is\n    used.\ntmax : float | dict\n    If float, gives the upper limit (in seconds) for the time window for\n    which all event types' effects are estimated. If a dict, can be used to\n    specify time windows for specific event types: keys correspond to keys\n    in event_id and/or covariates; for missing values, the default (1.) is\n    used.\ncovariates : dict-like | None\n    If dict-like (e.g., a pandas DataFrame), values have to be array-like\n    and of the same length as the rows in ``events``. Keys correspond\n    to additional event types/conditions to be estimated and are matched\n    with the time points given by the first column of ``events``. If\n    None, only binary events (from event_id) are used.\nreject : None | dict\n    For cleaning raw data before the regression is performed: set up\n    rejection parameters based on peak-to-peak amplitude in continuously\n    selected subepochs. If None, no rejection is done.\n    If dict, keys are types ('grad' | 'mag' | 'eeg' | 'eog' | 'ecg')\n    and values are the maximal peak-to-peak values to select rejected\n    epochs, e.g.::\n\n        reject = dict(grad=4000e-12, # T / m (gradiometers)\n                      mag=4e-11, # T (magnetometers)\n                      eeg=40e-5, # V (EEG channels)\n                      eog=250e-5 # V (EOG channels))\n\nflat : None | dict\n    For cleaning raw data before the regression is performed: set up\n    rejection parameters based on flatness of the signal. If None, no\n    rejection is done. If a dict, keys are ('grad' | 'mag' |\n    'eeg' | 'eog' | 'ecg') and values are minimal peak-to-peak values to\n    select rejected epochs.\ntstep : float\n    Length of windows for peak-to-peak detection for raw data cleaning.\ndecim : int\n    Decimate by choosing only a subsample of data points. Highly\n    recommended for data recorded at high sampling frequencies, as\n    otherwise huge intermediate matrices have to be created and inverted.\n%(picks_good_data)s\nsolver : str | callable\n    Either a function which takes as its inputs the sparse predictor\n    matrix X and the observation matrix Y, and returns the coefficient\n    matrix b; or a string.\n    X is of shape (n_times, n_predictors * time_window_length).\n    y is of shape (n_channels, n_times).\n    If str, must be ``'cholesky'``, in which case the solver used is\n    ``linalg.solve(dot(X.T, X), dot(X.T, y))``.\n\nReturns\n-------\nevokeds : dict\n    A dict where the keys correspond to conditions and the values are\n    Evoked objects with the ER[F/P]s. These can be used exactly like any\n    other Evoked object, including e.g. plotting or statistics.\n\nReferences\n----------\n.. footbibliography::", "metadata": {}}
{"_id": "mne_mne_stats/_adjacency.py_combine_adjacency_doc", "text": "Create a sparse binary adjacency/neighbors matrix.\n\nParameters\n----------\n*structure : list\n    The adjacency along each dimension. Each entry can be:\n\n    - ndarray or scipy.sparse.sparray\n        A square binary adjacency matrix for the given dimension.\n        For example created by :func:`mne.channels.find_ch_adjacency`.\n    - int\n        The number of elements along the given dimension. A lattice\n        adjacency will be generated, which is a binary matrix\n        reflecting that element N of an array is adjacent to\n        elements at indices N - 1 and N + 1.\n\nReturns\n-------\nadjacency : scipy.sparse.coo_array, shape (n_features, n_features)\n    The square adjacency matrix, where the shape ``n_features``\n    corresponds to the product of the length of all dimensions.\n    For example ``len(times) * len(freqs) * len(chans)``.\n\nSee Also\n--------\nmne.channels.find_ch_adjacency\nmne.channels.read_ch_adjacency\n\nNotes\n-----\nFor 4-dimensional data with shape ``(n_obs, n_times, n_freqs, n_chans)``,\nyou can specify **no** connections among elements in a particular\ndimension by passing a matrix of zeros. For example:\n\n>>> import numpy as np\n>>> from scipy.sparse import diags\n>>> from mne.stats import combine_adjacency\n>>> n_times, n_freqs, n_chans = (50, 7, 16)\n>>> chan_adj = diags([1., 1.], offsets=(-1, 1), shape=(n_chans, n_chans))\n>>> combine_adjacency(\n...     n_times,  # regular lattice adjacency for times\n...     np.zeros((n_freqs, n_freqs)),  # no adjacency between freq. bins\n...     chan_adj,  # custom matrix, or use mne.channels.find_ch_adjacency\n...     )  # doctest: +SKIP\n<5600x5600 sparse array of type '<class 'numpy.float64'>'\n        with 27076 stored elements in COOrdinate format>", "metadata": {}}
{"_id": "mne_mne_stats/parametric.py_ttest_1samp_no_p_doc", "text": "Perform one-sample t-test.\n\nThis is a modified version of :func:`scipy.stats.ttest_1samp` that avoids\na (relatively) time-consuming p-value calculation, and can adjust\nfor implausibly small variance values :footcite:`RidgwayEtAl2012`.\n\nParameters\n----------\nX : array\n    Array to return t-values for.\nsigma : float\n    The variance estimate will be given by ``var + sigma * max(var)`` or\n    ``var + sigma``, depending on \"method\". By default this is 0 (no\n    adjustment). See Notes for details.\nmethod : str\n    If 'relative', the minimum variance estimate will be sigma * max(var),\n    if 'absolute' the minimum variance estimate will be sigma.\n\nReturns\n-------\nt : array\n    T-values, potentially adjusted using the hat method.\n\nNotes\n-----\nTo use the \"hat\" adjustment method :footcite:`RidgwayEtAl2012`, a value\nof ``sigma=1e-3`` may be a reasonable choice.\n\nReferences\n----------\n.. footbibliography::", "metadata": {}}
{"_id": "mne_mne_stats/parametric.py_ttest_ind_no_p_doc", "text": "Independent samples t-test without p calculation.\n\nThis is a modified version of :func:`scipy.stats.ttest_ind`. It operates\nalong the first axis. The ``sigma`` parameter provides an optional \"hat\"\nadjustment (see :func:`ttest_1samp_no_p` and :footcite:`RidgwayEtAl2012`).\n\nParameters\n----------\na : array-like\n    The first array.\nb : array-like\n    The second array.\nequal_var : bool\n    Assume equal variance. See :func:`scipy.stats.ttest_ind`.\nsigma : float\n    The regularization. See :func:`ttest_1samp_no_p`.\n\nReturns\n-------\nt : array\n    T values.\n\nReferences\n----------\n.. footbibliography::", "metadata": {}}
{"_id": "mne_mne_stats/parametric.py_f_oneway_doc", "text": "Perform a 1-way ANOVA.\n\nThe one-way ANOVA tests the null hypothesis that 2 or more groups have\nthe same population mean. The test is applied to samples from two or\nmore groups, possibly with differing sizes :footcite:`Lowry2014`.\n\nThis is a modified version of :func:`scipy.stats.f_oneway` that avoids\ncomputing the associated p-value.\n\nParameters\n----------\n*args : array_like\n    The sample measurements should be given as arguments.\n\nReturns\n-------\nF-value : float\n    The computed F-value of the test.\n\nNotes\n-----\nThe ANOVA test has important assumptions that must be satisfied in order\nfor the associated p-value to be valid.\n\n1. The samples are independent\n2. Each sample is from a normally distributed population\n3. The population standard deviations of the groups are all equal. This\n   property is known as homoscedasticity.\n\nIf these assumptions are not true for a given set of data, it may still be\npossible to use the Kruskal-Wallis H-test (:func:`scipy.stats.kruskal`)\nalthough with some loss of power.\n\nThe algorithm is from Heiman :footcite:`Heiman2002`, pp.394-7.\n\nReferences\n----------\n.. footbibliography::", "metadata": {}}
{"_id": "mne_mne_stats/parametric.py_f_threshold_mway_rm_doc", "text": "Compute F-value thresholds for a two-way ANOVA.\n\nParameters\n----------\nn_subjects : int\n    The number of subjects to be analyzed.\nfactor_levels : list-like\n    The number of levels per factor.\neffects : str\n    A string denoting the effect to be returned. The following\n    mapping is currently supported:\n\n        * ``'A'``: main effect of A\n        * ``'B'``: main effect of B\n        * ``'A:B'``: interaction effect\n        * ``'A+B'``: both main effects\n        * ``'A*B'``: all three effects\n\npvalue : float\n    The p-value to be thresholded.\n\nReturns\n-------\nF_threshold : list | float\n    List of F-values for each effect if the number of effects\n    requested > 2, else float.\n\nSee Also\n--------\nf_oneway\nf_mway_rm\n\nNotes\n-----\n.. versionadded:: 0.10", "metadata": {}}
{"_id": "mne_mne_stats/parametric.py_f_mway_rm_doc", "text": "Compute M-way repeated measures ANOVA for fully balanced designs.\n\nParameters\n----------\ndata : ndarray\n    3D array where the first two dimensions are compliant\n    with a subjects X conditions scheme where the first\n    factor repeats slowest::\n\n                    A1B1 A1B2 A2B1 A2B2\n        subject 1   1.34 2.53 0.97 1.74\n        subject ... .... .... .... ....\n        subject k   2.45 7.90 3.09 4.76\n\n    The last dimensions is thought to carry the observations\n    for mass univariate analysis.\nfactor_levels : list-like\n    The number of levels per factor.\neffects : str | list\n    A string denoting the effect to be returned. The following\n    mapping is currently supported (example with 2 factors):\n\n        * ``'A'``: main effect of A\n        * ``'B'``: main effect of B\n        * ``'A:B'``: interaction effect\n        * ``'A+B'``: both main effects\n        * ``'A*B'``: all three effects\n        * ``'all'``: all effects (equals 'A*B' in a 2 way design)\n\n    If list, effect names are used: ``['A', 'B', 'A:B']``.\ncorrection : bool\n    The correction method to be employed if one factor has more than two\n    levels. If True, sphericity correction using the Greenhouse-Geisser\n    method will be applied.\nreturn_pvals : bool\n    If True, return p-values corresponding to F-values.\n\nReturns\n-------\nF_vals : ndarray\n    An array of F-statistics with length corresponding to the number\n    of effects estimated. The shape depends on the number of effects\n    estimated.\np_vals : ndarray\n    If not requested via return_pvals, defaults to an empty array.\n\nSee Also\n--------\nf_oneway\nf_threshold_mway_rm\n\nNotes\n-----\n.. versionadded:: 0.10", "metadata": {}}
{"_id": "mne_mne_simulation/raw.py_simulate_raw_doc", "text": "Simulate raw data.\n\nHead movements can optionally be simulated using the ``head_pos``\nparameter.\n\nParameters\n----------\n%(info_not_none)s Used for simulation.\n\n    .. versionchanged:: 0.18\n       Support for :class:`mne.Info`.\nstc : iterable | SourceEstimate | SourceSimulator\n    The source estimates to use to simulate data. Each must have the same\n    sample rate as the raw data, and the vertices of all stcs in the\n    iterable must match. Each entry in the iterable can also be a tuple of\n    ``(SourceEstimate, ndarray)`` to allow specifying the stim channel\n    (e.g., STI001) data accompany the source estimate.\n    See Notes for details.\n\n    .. versionchanged:: 0.18\n       Support for tuple, iterable of tuple or `~mne.SourceEstimate`,\n       or `~mne.simulation.SourceSimulator`.\ntrans : dict | str | None\n    Either a transformation filename (usually made using mne_analyze)\n    or an info dict (usually opened using read_trans()).\n    If string, an ending of ``.fif`` or ``.fif.gz`` will be assumed to\n    be in FIF format, any other ending will be assumed to be a text\n    file with a 4x4 transformation matrix (like the ``--trans`` MNE-C\n    option). If trans is None, an identity transform will be used.\nsrc : path-like | instance of SourceSpaces | None\n    Source space corresponding to the stc. If string, should be a source\n    space filename. Can also be an instance of loaded or generated\n    SourceSpaces. Can be None if ``forward`` is provided.\nbem : path-like | dict | None\n    BEM solution  corresponding to the stc. If string, should be a BEM\n    solution filename (e.g., \"sample-5120-5120-5120-bem-sol.fif\").\n    Can be None if ``forward`` is provided.\n%(head_pos)s\n    See for example :footcite:`LarsonTaulu2017`.\nmindist : float\n    Minimum distance between sources and the inner skull boundary\n    to use during forward calculation.\n%(interp)s\n%(n_jobs)s\n%(use_cps)s\nforward : instance of Forward | None\n    The forward operator to use. If None (default) it will be computed\n    using ``bem``, ``trans``, and ``src``. If not None,\n    ``bem``, ``trans``, and ``src`` are ignored.\n\n    .. versionadded:: 0.17\nfirst_samp : int\n    The first_samp property in the output Raw instance.\n\n    .. versionadded:: 0.18\nmax_iter : int\n    The maximum number of STC iterations to allow.\n    This is a sanity parameter to prevent accidental blowups.\n\n    .. versionadded:: 0.18\n%(verbose)s\n\nReturns\n-------\nraw : instance of Raw\n    The simulated raw file.\n\nSee Also\n--------\nmne.chpi.read_head_pos\nadd_chpi\nadd_noise\nadd_ecg\nadd_eog\nsimulate_evoked\nsimulate_stc\nsimulate_sparse_stc\n\nNotes\n-----\n**Stim channel encoding**\n\nBy default, the stimulus channel will have the head position number\n(starting at 1) stored in the trigger channel (if available) at the\nt=0 point in each repetition of the ``stc``. If ``stc`` is a tuple of\n``(SourceEstimate, ndarray)`` the array values will be placed in the\nstim channel aligned with the :class:`mne.SourceEstimate`.\n\n**Data simulation**\n\nIn the most advanced case where ``stc`` is an iterable of tuples the output\nwill be concatenated in time as:\n\n.. table:: Data alignment and stim channel encoding\n\n   +---------+--------------------------+--------------------------+---------+\n   | Channel | Data                                                          |\n   +=========+==========================+==========================+=========+\n   | M/EEG   | ``fwd @ stc[0][0].data`` | ``fwd @ stc[1][0].data`` | ``...`` |\n   +---------+--------------------------+--------------------------+---------+\n   | STIM    | ``stc[0][1]``            | ``stc[1][1]``            | ``...`` |\n   +---------+--------------------------+--------------------------+---------+\n   |         | *time \u2192*                                                      |\n   +---------+--------------------------+--------------------------+---------+\n\n.. versionadded:: 0.10.0\n\nReferences\n----------\n.. footbibliography::", "metadata": {}}
{"_id": "mne_mne_simulation/raw.py_add_eog_doc", "text": "Add blink noise to raw data.\n\nParameters\n----------\nraw : instance of Raw\n    The raw instance to modify.\n%(head_pos)s\n%(interp)s\n%(n_jobs)s\n%(random_state)s\n    The random generator state used for blink, ECG, and sensor noise\n    randomization.\n%(verbose)s\n\nReturns\n-------\nraw : instance of Raw\n    The instance, modified in place.\n\nSee Also\n--------\nadd_chpi\nadd_ecg\nadd_noise\nsimulate_raw\n\nNotes\n-----\nThe blink artifacts are generated by:\n\n1. Random activation times are drawn from an inhomogeneous poisson\n   process whose blink rate oscillates between 4.5 blinks/minute\n   and 17 blinks/minute based on the low (reading) and high (resting)\n   blink rates from :footcite:`BentivoglioEtAl1997`.\n2. The activation kernel is a 250 ms Hanning window.\n3. Two activated dipoles are located in the z=0 plane (in head\n   coordinates) at \u00b130 degrees away from the y axis (nasion).\n4. Activations affect MEG and EEG channels.\n\nThe scale-factor of the activation function was chosen based on\nvisual inspection to yield amplitudes generally consistent with those\nseen in experimental data. Noisy versions of the activation will be\nstored in the first EOG channel in the raw instance, if it exists.\n\nReferences\n----------\n.. footbibliography::", "metadata": {}}
{"_id": "mne_mne_simulation/raw.py_add_ecg_doc", "text": "Add ECG noise to raw data.\n\nParameters\n----------\nraw : instance of Raw\n    The raw instance to modify.\n%(head_pos)s\n%(interp)s\n%(n_jobs)s\n%(random_state)s\n    The random generator state used for blink, ECG, and sensor noise\n    randomization.\n%(verbose)s\n\nReturns\n-------\nraw : instance of Raw\n    The instance, modified in place.\n\nSee Also\n--------\nadd_chpi\nadd_eog\nadd_noise\nsimulate_raw\n\nNotes\n-----\nThe ECG artifacts are generated by:\n\n1. Random inter-beat intervals are drawn from a uniform distribution\n   of times corresponding to 40 and 80 beats per minute.\n2. The activation function is the sum of three Hanning windows with\n   varying durations and scales to make a more complex waveform.\n3. The activated dipole is located one (estimated) head radius to\n   the left (-x) of head center and three head radii below (+z)\n   head center; this dipole is oriented in the +x direction.\n4. Activations only affect MEG channels.\n\nThe scale-factor of the activation function was chosen based on\nvisual inspection to yield amplitudes generally consistent with those\nseen in experimental data. Noisy versions of the activation will be\nstored in the first EOG channel in the raw instance, if it exists.\n\n.. versionadded:: 0.18", "metadata": {}}
{"_id": "mne_mne_simulation/raw.py_add_chpi_doc", "text": "Add cHPI activations to raw data.\n\nParameters\n----------\nraw : instance of Raw\n    The raw instance to be modified.\n%(head_pos)s\n%(interp)s\n%(n_jobs)s\n%(verbose)s\n\nReturns\n-------\nraw : instance of Raw\n    The instance, modified in place.\n\nNotes\n-----\n.. versionadded:: 0.18", "metadata": {}}
{"_id": "mne_mne_simulation/evoked.py_simulate_evoked_doc", "text": "Generate noisy evoked data.\n\n.. note:: No projections from ``info`` will be present in the\n          output ``evoked``. You can use e.g.\n          :func:`evoked.add_proj <mne.Evoked.add_proj>` or\n          :func:`evoked.set_eeg_reference <mne.Evoked.set_eeg_reference>`\n          to add them afterward as necessary.\n\nParameters\n----------\nfwd : instance of Forward\n    A forward solution.\nstc : SourceEstimate object\n    The source time courses.\n%(info_not_none)s Used to generate the evoked.\ncov : Covariance object | None\n    The noise covariance. If None, no noise is added.\nnave : int\n    Number of averaged epochs (defaults to 30).\n\n    .. versionadded:: 0.15.0\niir_filter : None | array\n    IIR filter coefficients (denominator) e.g. [1, -1, 0.2].\n%(random_state)s\n%(use_cps)s\n\n    .. versionadded:: 0.15\n%(verbose)s\n\nReturns\n-------\nevoked : Evoked object\n    The simulated evoked data.\n\nSee Also\n--------\nsimulate_raw\nsimulate_stc\nsimulate_sparse_stc\n\nNotes\n-----\nTo make the equivalence between snr and nave, when the snr is given\ninstead of nave::\n\n    nave = (1 / 10 ** ((actual_snr - snr)) / 20) ** 2\n\nwhere actual_snr is the snr to the generated noise before scaling.\n\n.. versionadded:: 0.10.0", "metadata": {}}
{"_id": "mne_mne_simulation/evoked.py_add_noise_doc", "text": "Create noise as a multivariate Gaussian.\n\nThe spatial covariance of the noise is given from the cov matrix.\n\nParameters\n----------\ninst : instance of Evoked, Epochs, or Raw\n    Instance to which to add noise.\ncov : instance of Covariance\n    The noise covariance.\niir_filter : None | array-like\n    IIR filter coefficients (denominator).\n%(random_state)s\n%(verbose)s\n\nReturns\n-------\ninst : instance of Evoked, Epochs, or Raw\n    The instance, modified to have additional noise.\n\nNotes\n-----\nOnly channels in both ``inst.info['ch_names']`` and\n``cov['names']`` will have noise added to them.\n\nThis function operates inplace on ``inst``.\n\n.. versionadded:: 0.18.0", "metadata": {}}
{"_id": "mne_mne_simulation/source.py_select_source_in_label_doc", "text": "Select source positions using a label.\n\nParameters\n----------\nsrc : list of dict\n    The source space.\nlabel : Label\n    The label.\n%(random_state)s\nlocation : str\n    The label location to choose. Can be 'random' (default) or 'center'\n    to use :func:`mne.Label.center_of_mass` (restricting to vertices\n    both in the label and in the source space). Note that for 'center'\n    mode the label values are used as weights.\n\n    .. versionadded:: 0.13\nsubject : str | None\n    The subject the label is defined for.\n    Only used with ``location='center'``.\n\n    .. versionadded:: 0.13\n%(subjects_dir)s\n\n    .. versionadded:: 0.13\nsurf : str\n    The surface to use for Euclidean distance center of mass\n    finding. The default here is \"sphere\", which finds the center\n    of mass on the spherical surface to help avoid potential issues\n    with cortical folding.\n\n    .. versionadded:: 0.13\n\nReturns\n-------\nlh_vertno : list\n    Selected source coefficients on the left hemisphere.\nrh_vertno : list\n    Selected source coefficients on the right hemisphere.", "metadata": {}}
{"_id": "mne_mne_simulation/source.py_simulate_sparse_stc_doc", "text": "Generate sparse (n_dipoles) sources time courses from data_fun.\n\nThis function randomly selects ``n_dipoles`` vertices in the whole\ncortex or one single vertex (randomly in or in the center of) each\nlabel if ``labels is not None``. It uses ``data_fun`` to generate\nwaveforms for each vertex.\n\nParameters\n----------\nsrc : instance of SourceSpaces\n    The source space.\nn_dipoles : int\n    Number of dipoles to simulate.\ntimes : array\n    Time array.\ndata_fun : callable\n    Function to generate the waveforms. The default is a 100 nAm, 10 Hz\n    sinusoid as ``1e-7 * np.sin(20 * pi * t)``. The function should take\n    as input the array of time samples in seconds and return an array of\n    the same length containing the time courses.\nlabels : None | list of Label\n    The labels. The default is None, otherwise its size must be n_dipoles.\n%(random_state)s\nlocation : str\n    The label location to choose. Can be ``'random'`` (default) or\n    ``'center'`` to use :func:`mne.Label.center_of_mass`. Note that for\n    ``'center'`` mode the label values are used as weights.\n\n    .. versionadded:: 0.13\nsubject : str | None\n    The subject the label is defined for.\n    Only used with ``location='center'``.\n\n    .. versionadded:: 0.13\n%(subjects_dir)s\n\n    .. versionadded:: 0.13\nsurf : str\n    The surface to use for Euclidean distance center of mass\n    finding. The default here is \"sphere\", which finds the center\n    of mass on the spherical surface to help avoid potential issues\n    with cortical folding.\n\n    .. versionadded:: 0.13\n\nReturns\n-------\nstc : SourceEstimate\n    The generated source time courses.\n\nSee Also\n--------\nsimulate_raw\nsimulate_evoked\nsimulate_stc\n\nNotes\n-----\n.. versionadded:: 0.10.0", "metadata": {}}
{"_id": "mne_mne_simulation/source.py_simulate_stc_doc", "text": "Simulate sources time courses from waveforms and labels.\n\nThis function generates a source estimate with extended sources by\nfilling the labels with the waveforms given in stc_data.\n\nParameters\n----------\nsrc : instance of SourceSpaces\n    The source space.\nlabels : list of Label\n    The labels.\nstc_data : array, shape (n_labels, n_times)\n    The waveforms.\ntmin : float\n    The beginning of the timeseries.\ntstep : float\n    The time step (1 / sampling frequency).\nvalue_fun : callable | None\n    Function to apply to the label values to obtain the waveform\n    scaling for each vertex in the label. If None (default), uniform\n    scaling is used.\nallow_overlap : bool\n    Allow overlapping labels or not. Default value is False.\n\n    .. versionadded:: 0.18\n\nReturns\n-------\nstc : SourceEstimate\n    The generated source time courses.\n\nSee Also\n--------\nsimulate_raw\nsimulate_evoked\nsimulate_sparse_stc", "metadata": {}}
{"_id": "mne_mne_simulation/source.py_duration_doc", "text": "Duration of the simulation in same units as tstep.", "metadata": {}}
{"_id": "mne_mne_simulation/source.py_n_times_doc", "text": "Number of time samples in the simulation.", "metadata": {}}
{"_id": "mne_mne_simulation/source.py_add_data_doc", "text": "Add data to the simulation.\n\nData should be added in the form of a triplet of\nLabel (Where) - Waveform(s) (What) - Event(s) (When)\n\nParameters\n----------\nlabel : instance of Label\n    The label (as created for example by mne.read_label). If the label\n    does not match any sources in the SourceEstimate, a ValueError is\n    raised.\nwaveform : array, shape (n_times,) or (n_events, n_times) | list\n    The waveform(s) describing the activity on the label vertices.\n    If list, it must have the same length as events.\nevents : array of int, shape (n_events, 3)\n    Events associated to the waveform(s) to specify when the activity\n    should occur.", "metadata": {}}
{"_id": "mne_mne_simulation/source.py_get_stim_channel_doc", "text": "Get the stim channel from the provided data.\n\nReturns the stim channel data according to the simulation parameters\nwhich should be added through the add_data method. If both start_sample\nand stop_sample are not specified, the entire duration is used.\n\nParameters\n----------\nstart_sample : int\n    First sample in chunk. Default is the value of the ``first_samp``\n    attribute.\nstop_sample : int | None\n    The final sample of the returned stc. If None, then all samples\n    from start_sample onward are returned.\n\nReturns\n-------\nstim_data : ndarray of int, shape (n_samples,)\n    The stimulation channel data.", "metadata": {}}
{"_id": "mne_mne_simulation/source.py_get_stc_doc", "text": "Simulate a SourceEstimate from the provided data.\n\nReturns a SourceEstimate object constructed according to the simulation\nparameters which should be added through function add_data. If both\nstart_sample and stop_sample are not specified, the entire duration is\nused.\n\nParameters\n----------\nstart_sample : int | None\n    First sample in chunk. If ``None`` the value of the ``first_samp``\n    attribute is used. Defaults to ``None``.\nstop_sample : int | None\n    The final sample of the returned STC. If ``None``, then all samples\n    past ``start_sample`` are returned.\n\nReturns\n-------\nstc : SourceEstimate object\n    The generated source time courses.", "metadata": {}}
{"_id": "mne_mne_simulation/metrics/metrics.py_source_estimate_quantification_doc", "text": "Calculate STC similarities across all sources and times.\n\nParameters\n----------\nstc1 : SourceEstimate\n    First source estimate for comparison.\nstc2 : SourceEstimate\n    Second source estimate for comparison.\nmetric : str\n    Metric to calculate, ``'rms'`` or ``'cosine'``.\n\nReturns\n-------\nscore : float | array\n    Calculated metric.\n\nNotes\n-----\nMetric calculation has multiple options:\n\n    * rms: Root mean square of difference between stc data matrices.\n    * cosine: Normalized correlation of all elements in stc data matrices.\n\n.. versionadded:: 0.10.0", "metadata": {}}
{"_id": "mne_mne_simulation/metrics/metrics.py_cosine_score_doc", "text": "Compute cosine similarity between 2 source estimates.\n\nParameters\n----------\n%(stc_true_metric)s\n%(stc_est_metric)s\n%(per_sample_metric)s\n\nReturns\n-------\n%(stc_metric)s\n\nNotes\n-----\n.. versionadded:: 1.2", "metadata": {}}
{"_id": "mne_mne_simulation/metrics/metrics.py_region_localization_error_doc", "text": "Compute region localization error (RLE) between 2 source estimates.\n\n.. math::\n\n    RLE = \\frac{1}{2Q}\\sum_{k \\in I} \\min_{l \\in \\hat{I}}{||r_k - r_l||} + \\frac{1}{2\\hat{Q}}\\sum_{l \\in \\hat{I}} \\min_{k \\in I}{||r_k - r_l||}\n\nwhere :math:`I` and :math:`\\hat{I}` denote respectively the original and\nestimated indexes of active sources, :math:`Q` and :math:`\\hat{Q}` are\nthe numbers of original and estimated active sources.\n:math:`r_k` denotes the position of the k-th source dipole in space\nand :math:`||\\cdot||` is an Euclidean norm in :math:`\\mathbb{R}^3`.\n\nParameters\n----------\n%(stc_true_metric)s\n%(stc_est_metric)s\nsrc : instance of SourceSpaces\n    The source space on which the source estimates are defined.\nthreshold : float | str\n    The threshold to apply to source estimates before computing\n    the dipole localization error. If a string the threshold is\n    a percentage and it should end with the percent character.\n%(per_sample_metric)s\n\nReturns\n-------\n%(stc_metric)s\n\nNotes\n-----\nPapers :footcite:`MaksymenkoEtAl2017` and :footcite:`BeckerEtAl2017`\nuse term Dipole Localization Error (DLE) for the same formula. Paper\n:footcite:`YaoEtAl2005` uses term Error Distance (ED) for the same formula.\nTo unify the terminology and to avoid confusion with other cases\nof using term DLE but for different metric :footcite:`MolinsEtAl2008`, we\nuse term Region Localization Error (RLE).\n\n.. versionadded:: 1.2\n\nReferences\n----------\n.. footbibliography::", "metadata": {}}
{"_id": "mne_mne_simulation/metrics/metrics.py_roc_auc_score_doc", "text": "Compute ROC AUC between 2 source estimates.\n\nROC stands for receiver operating curve and AUC is Area under the curve.\nWhen computing this metric the stc_true must be thresholded\nas any non-zero value will be considered as a positive.\n\nThe ROC-AUC metric is computed between amplitudes of the source\nestimates, i.e. after taking the absolute values.\n\nParameters\n----------\n%(stc_true_metric)s\n%(stc_est_metric)s\n%(per_sample_metric)s\n\nReturns\n-------\n%(stc_metric)s\n\nNotes\n-----\n.. versionadded:: 1.2", "metadata": {}}
{"_id": "mne_mne_simulation/metrics/metrics.py_f1_score_doc", "text": "Compute the F1 score, also known as balanced F-score or F-measure.\n\nThe F1 score can be interpreted as a weighted average of the precision\nand recall, where an F1 score reaches its best value at 1 and worst score\nat 0. The relative contribution of precision and recall to the F1\nscore are equal.\nThe formula for the F1 score is::\n\n    F1 = 2 * (precision * recall) / (precision + recall)\n\nThreshold is used first for data binarization.\n\nParameters\n----------\n%(stc_true_metric)s\n%(stc_est_metric)s\nthreshold : float | str\n    The threshold to apply to source estimates before computing\n    the f1 score. If a string the threshold is\n    a percentage and it should end with the percent character.\n%(per_sample_metric)s\n\nReturns\n-------\n%(stc_metric)s\n\nNotes\n-----\n.. versionadded:: 1.2", "metadata": {}}
{"_id": "mne_mne_simulation/metrics/metrics.py_precision_score_doc", "text": "Compute the precision.\n\nThe precision is the ratio ``tp / (tp + fp)`` where ``tp`` is the number of\ntrue positives and ``fp`` the number of false positives. The precision is\nintuitively the ability of the classifier not to label as positive a sample\nthat is negative.\n\nThe best value is 1 and the worst value is 0.\n\nThreshold is used first for data binarization.\n\nParameters\n----------\n%(stc_true_metric)s\n%(stc_est_metric)s\nthreshold : float | str\n    The threshold to apply to source estimates before computing\n    the precision. If a string the threshold is\n    a percentage and it should end with the percent character.\n%(per_sample_metric)s\n\nReturns\n-------\n%(stc_metric)s\n\nNotes\n-----\n.. versionadded:: 1.2", "metadata": {}}
{"_id": "mne_mne_simulation/metrics/metrics.py_recall_score_doc", "text": "Compute the recall.\n\nThe recall is the ratio ``tp / (tp + fn)`` where ``tp`` is the number of\ntrue positives and ``fn`` the number of false negatives. The recall is\nintuitively the ability of the classifier to find all the positive samples.\n\nThe best value is 1 and the worst value is 0.\n\nThreshold is used first for data binarization.\n\nParameters\n----------\n%(stc_true_metric)s\n%(stc_est_metric)s\nthreshold : float | str\n    The threshold to apply to source estimates before computing\n    the recall. If a string the threshold is\n    a percentage and it should end with the percent character.\n%(per_sample_metric)s\n\nReturns\n-------\n%(stc_metric)s\n\nNotes\n-----\n.. versionadded:: 1.2", "metadata": {}}
{"_id": "mne_mne_simulation/metrics/metrics.py_peak_position_error_doc", "text": "Compute the peak position error.\n\nThe peak position error measures the distance between the center-of-mass\nof the estimated and the true source.\n\n.. math::\n\n    PPE = \\| \\dfrac{\\sum_i|s_i|r_{i}}{\\sum_i|s_i|}\n    - r_{true}\\|,\n\nwhere :math:`r_{true}` is a true dipole position,\n:math:`r_i` and :math:`|s_i|` denote respectively the position\nand amplitude of i-th dipole in source estimate.\n\nThreshold is used on estimated source for focusing the metric to strong\namplitudes and omitting the low-amplitude values.\n\nParameters\n----------\n%(stc_true_metric)s\n%(stc_est_metric)s\nsrc : instance of SourceSpaces\n    The source space on which the source estimates are defined.\nthreshold : float | str\n    The threshold to apply to source estimates before computing\n    the recall. If a string the threshold is\n    a percentage and it should end with the percent character.\n%(per_sample_metric)s\n\nReturns\n-------\n%(stc_metric)s\n\nNotes\n-----\nThese metrics are documented in :footcite:`StenroosHauk2013` and\n:footcite:`LinEtAl2006a`.\n\n.. versionadded:: 1.2\n\nReferences\n----------\n.. footbibliography::", "metadata": {}}
{"_id": "mne_mne_simulation/metrics/metrics.py_spatial_deviation_error_doc", "text": "Compute the spatial deviation.\n\nThe spatial deviation characterizes the spread of the estimate source\naround the true source.\n\n.. math::\n\n    SD = \\dfrac{\\sum_i|s_i|\\|r_{i} - r_{true}\\|^2}{\\sum_i|s_i|}.\n\nwhere :math:`r_{true}` is a true dipole position,\n:math:`r_i` and :math:`|s_i|` denote respectively the position\nand amplitude of i-th dipole in source estimate.\n\nThreshold is used on estimated source for focusing the metric to strong\namplitudes and omitting the low-amplitude values.\n\nParameters\n----------\n%(stc_true_metric)s\n%(stc_est_metric)s\nsrc : instance of SourceSpaces\n    The source space on which the source estimates are defined.\nthreshold : float | str\n    The threshold to apply to source estimates before computing\n    the recall. If a string the threshold is\n    a percentage and it should end with the percent character.\n%(per_sample_metric)s\n\nReturns\n-------\n%(stc_metric)s\n\nNotes\n-----\nThese metrics are documented in :footcite:`StenroosHauk2013` and\n:footcite:`LinEtAl2006a`.\n\n.. versionadded:: 1.2\n\nReferences\n----------\n.. footbibliography::", "metadata": {}}
{"_id": "mne_mne_commands/mne_sys_info.py_run_doc", "text": "Run command.", "metadata": {}}
{"_id": "mne_mne_commands/mne_kit2fiff.py_run_doc", "text": "Run command.", "metadata": {}}
{"_id": "mne_mne_commands/mne_bti2fiff.py_run_doc", "text": "Run command.", "metadata": {}}
{"_id": "mne_mne_commands/mne_compare_fiff.py_run_doc", "text": "Run command.", "metadata": {}}
{"_id": "mne_mne_commands/mne_make_scalp_surfaces.py_run_doc", "text": "Run command.", "metadata": {}}
{"_id": "mne_mne_commands/mne_setup_source_space.py_run_doc", "text": "Run command.", "metadata": {}}
{"_id": "mne_mne_commands/mne_browse_raw.py_run_doc", "text": "Run command.", "metadata": {}}
{"_id": "mne_mne_commands/mne_freeview_bem_surfaces.py_freeview_bem_surfaces_doc", "text": "View 3-Layers BEM model with Freeview.\n\nParameters\n----------\nsubject : str\n    Subject name\nsubjects_dir : path-like\n    Directory containing subjects data (Freesurfer SUBJECTS_DIR)\nmethod : str | None\n    Can be ``'flash'`` or ``'watershed'``, or None to use the ``bem/`` directory\n    files.", "metadata": {}}
{"_id": "mne_mne_commands/mne_freeview_bem_surfaces.py_run_doc", "text": "Run command.", "metadata": {}}
{"_id": "mne_mne_commands/mne_show_info.py_run_doc", "text": "Run command.", "metadata": {}}
{"_id": "mne_mne_commands/mne_prepare_bem_model.py_run_doc", "text": "Run command.", "metadata": {}}
{"_id": "mne_mne_commands/mne_clean_eog_ecg.py_clean_ecg_eog_doc", "text": "Clean ECG from raw fif file.\n\nParameters\n----------\nin_fif_fname : path-like\n    Raw fif File\neog_event_fname : str\n    name of EOG event file required.\neog : bool\n    Reject or not EOG artifacts.\necg : bool\n    Reject or not ECG artifacts.\necg_event_fname : str\n    name of ECG event file required.\nin_path : str\n    Path where all the files are.", "metadata": {}}
{"_id": "mne_mne_commands/mne_clean_eog_ecg.py_run_doc", "text": "Run command.", "metadata": {}}
{"_id": "mne_mne_commands/mne_report.py_log_elapsed_doc", "text": "Log elapsed time.", "metadata": {}}
{"_id": "mne_mne_commands/mne_report.py_run_doc", "text": "Run command.", "metadata": {}}
{"_id": "mne_mne_commands/mne_coreg.py_run_doc", "text": "Run command.", "metadata": {}}
{"_id": "mne_mne_commands/mne_compute_proj_eog.py_run_doc", "text": "Run command.", "metadata": {}}
{"_id": "mne_mne_commands/mne_surf2bem.py_run_doc", "text": "Run command.", "metadata": {}}
{"_id": "mne_mne_commands/mne_show_fiff.py_run_doc", "text": "Run command.", "metadata": {}}
{"_id": "mne_mne_commands/mne_compute_proj_ecg.py_run_doc", "text": "Run command.", "metadata": {}}
{"_id": "mne_mne_commands/mne_anonymize.py_mne_anonymize_doc", "text": "Call *anonymize_info* on fif file and save.\n\nParameters\n----------\nfif_fname : path-like\n    Raw fif File\nout_fname : path-like | None\n    Output file name\n    relative paths are saved relative to parent dir of fif_fname\n    None will save to parent dir of fif_fname with default prefix\ndaysback : int | None\n    Number of days to subtract from all dates.\n    If None will default to move date of service to Jan 1 2000\nkeep_his : bool\n    If True his_id of subject_info will NOT be overwritten.\n    defaults to False\noverwrite : bool\n    Overwrite output file if it already exists", "metadata": {}}
{"_id": "mne_mne_commands/mne_anonymize.py_run_doc", "text": "Run *mne_anonymize* command.", "metadata": {}}
{"_id": "mne_mne_commands/mne_watershed_bem.py_run_doc", "text": "Run command.", "metadata": {}}
{"_id": "mne_mne_commands/utils.py_load_module_doc", "text": "Load module from .py/.pyc file.\n\nParameters\n----------\nname : str\n    Name of the module.\npath : str\n    Path to .py/.pyc file.\n\nReturns\n-------\nmod : module\n    Imported module.", "metadata": {}}
{"_id": "mne_mne_commands/utils.py_get_optparser_doc", "text": "Create OptionParser with cmd specific settings (e.g., prog value).", "metadata": {}}
{"_id": "mne_mne_commands/utils.py_main_doc", "text": "Entrypoint for mne <command> usage.", "metadata": {}}
{"_id": "mne_mne_commands/mne_what.py_run_doc", "text": "Run command.", "metadata": {}}
{"_id": "mne_mne_commands/mne_setup_forward_model.py_run_doc", "text": "Run command.", "metadata": {}}
{"_id": "mne_mne_commands/mne_flash_bem.py_run_doc", "text": "Run command.", "metadata": {}}
{"_id": "mne_mne_source_space/_source_space.py_read_source_spaces_doc", "text": "Read the source spaces from a FIF file.\n\nParameters\n----------\nfname : path-like\n    The name of the file, which should end with ``-src.fif`` or\n    ``-src.fif.gz``.\npatch_stats : bool, optional (default False)\n    Calculate and add cortical patch statistics to the surfaces.\n%(verbose)s\n\nReturns\n-------\nsrc : SourceSpaces\n    The source spaces.\n\nSee Also\n--------\nwrite_source_spaces, setup_source_space, setup_volume_source_space", "metadata": {}}
{"_id": "mne_mne_source_space/_source_space.py_find_source_space_hemi_doc", "text": "Return the hemisphere id for a source space.\n\nParameters\n----------\nsrc : dict\n    The source space to investigate.\n\nReturns\n-------\nhemi : int\n    Deduced hemisphere id.", "metadata": {}}
{"_id": "mne_mne_source_space/_source_space.py_label_src_vertno_sel_doc", "text": "Find vertex numbers and indices from label.\n\nParameters\n----------\nlabel : Label\n    Source space label.\nsrc : dict\n    Source space.\n\nReturns\n-------\nvertices : list of length 2\n    Vertex numbers for lh and rh.\nsrc_sel : array of int (len(idx) = len(vertices[0]) + len(vertices[1]))\n    Indices of the selected vertices in sourse space.", "metadata": {}}
{"_id": "mne_mne_source_space/_source_space.py_write_source_spaces_doc", "text": "Write source spaces to a file.\n\nParameters\n----------\nfname : path-like\n    The name of the file, which should end with ``-src.fif`` or\n    ``-src.fif.gz``.\nsrc : instance of SourceSpaces\n    The source spaces (as returned by read_source_spaces).\n%(overwrite)s\n%(verbose)s\n\nSee Also\n--------\nread_source_spaces", "metadata": {}}
{"_id": "mne_mne_source_space/_source_space.py_setup_source_space_doc", "text": "Set up bilateral hemisphere surface-based source space with subsampling.\n\nParameters\n----------\n%(subject)s\nspacing : str\n    The spacing to use. Can be ``'ico#'`` for a recursively subdivided\n    icosahedron, ``'oct#'`` for a recursively subdivided octahedron,\n    ``'all'`` for all points, or an integer to use approximate\n    distance-based spacing (in mm).\n\n    .. versionchanged:: 0.18\n       Support for integers for distance-based spacing.\nsurface : str\n    The surface to use.\n%(subjects_dir)s\nadd_dist : bool | str\n    Add distance and patch information to the source space. This takes some\n    time so precomputing it is recommended. Can also be 'patch' to only\n    compute patch information.\n\n    .. versionchanged:: 0.20\n       Support for ``add_dist='patch'``.\n%(n_jobs)s\n    Ignored if ``add_dist=='patch'``.\n%(verbose)s\n\nReturns\n-------\nsrc : SourceSpaces\n    The source space for each hemisphere.\n\nSee Also\n--------\nsetup_volume_source_space", "metadata": {}}
{"_id": "mne_mne_source_space/_source_space.py_setup_volume_source_space_doc", "text": "Set up a volume source space with grid spacing or discrete source space.\n\nParameters\n----------\nsubject : str | None\n    Subject to process. If None, the path to the MRI volume must be\n    absolute to get a volume source space. If a subject name\n    is provided the ``T1.mgz`` file will be found automatically.\n    Defaults to None.\npos : float | dict\n    Positions to use for sources. If float, a grid will be constructed\n    with the spacing given by ``pos`` in mm, generating a volume source\n    space. If dict, ``pos['rr']`` and ``pos['nn']`` will be used as the source\n    space locations (in meters) and normals, respectively, creating a\n    discrete source space.\n\n    .. note:: For a discrete source space (``pos`` is a dict),\n              ``mri`` must be None.\nmri : path-like | None\n    The filename of an MRI volume (mgh or mgz) to create the\n    interpolation matrix over. Source estimates obtained in the\n    volume source space can then be morphed onto the MRI volume\n    using this interpolator. If pos is a dict, this cannot be None.\n    If subject name is provided, ``pos`` is a float or ``volume_label``\n    are not provided then the ``mri`` parameter will default to ``'T1.mgz'``\n    or ``aseg.mgz``, respectively, else it will stay None.\nsphere : ndarray, shape (4,) | ConductorModel | None\n    Define spherical source space bounds using origin and radius given\n    by ``(Ox, Oy, Oz, rad)`` in ``sphere_units``.\n    Only used if ``bem`` and ``surface`` are both None. Can also be a\n    spherical ConductorModel, which will use the origin and radius.\n    None (the default) uses a head-digitization fit.\nbem : path-like | None | ConductorModel\n    Define source space bounds using a BEM file (specifically the inner\n    skull surface) or a :class:`~mne.bem.ConductorModel` for a 1-layer of 3-layers\n    BEM. See :func:`~mne.make_bem_model` and :func:`~mne.make_bem_solution` to\n    create a :class:`~mne.bem.ConductorModel`. If provided, ``surface`` must be\n    None.\nsurface : path-like | dict | None\n    Define source space bounds using a FreeSurfer surface file. Can\n    also be a dictionary with entries ``'rr'`` and ``'tris'``, such as\n    those returned by :func:`mne.read_surface`. If provided, ``bem`` must be None.\nmindist : float\n    Exclude points closer than this distance (mm) to the bounding surface.\nexclude : float\n    Exclude points closer than this distance (mm) from the center of mass\n    of the bounding surface.\n%(subjects_dir)s\nvolume_label : str | dict | list | None\n    Region(s) of interest to use. None (default) will create a single\n    whole-brain source space. Otherwise, a separate source space will be\n    created for each entry in the list or dict (str will be turned into\n    a single-element list). If list of str, standard Freesurfer labels\n    are assumed. If dict, should be a mapping of region names to atlas\n    id numbers, allowing the use of other atlases.\n\n    .. versionchanged:: 0.21.0\n       Support for dict added.\nadd_interpolator : bool\n    If True and ``mri`` is not None, then an interpolation matrix\n    will be produced.\nsphere_units : str\n    Defaults to ``\"m\"``.\n\n    .. versionadded:: 0.20\nsingle_volume : bool\n    If True, multiple values of ``volume_label`` will be merged into a\n    a single source space instead of occupying multiple source spaces\n    (one for each sub-volume), i.e., ``len(src)`` will be ``1`` instead of\n    ``len(volume_label)``. This can help conserve memory and disk space\n    when many labels are used.\n\n    .. versionadded:: 0.21\n%(n_jobs)s\n\n    .. versionadded:: 1.6\n%(verbose)s\n\nReturns\n-------\nsrc : SourceSpaces\n    A :class:`SourceSpaces` object containing one source space for each\n    entry of ``volume_labels``, or a single source space if\n    ``volume_labels`` was not specified.\n\nSee Also\n--------\nsetup_source_space\n\nNotes\n-----\nVolume source spaces are related to an MRI image such as T1 and allow to\nvisualize source estimates overlaid on MRIs and to morph estimates\nto a template brain for group analysis. Discrete source spaces\ndon't allow this. If you provide a subject name the T1 MRI will be\nused by default.\n\nWhen you work with a source space formed from a grid you need to specify\nthe domain in which the grid will be defined. There are three ways\nof specifying this:\n(i) sphere, (ii) bem model, and (iii) surface.\nThe default behavior is to use sphere model\n(``sphere=(0.0, 0.0, 0.0, 90.0)``) if ``bem`` or ``surface`` is not\n``None`` then ``sphere`` is ignored.\nIf you're going to use a BEM conductor model for forward model\nit is recommended to pass it here.\n\nTo create a discrete source space, ``pos`` must be a dict, ``mri`` must be\nNone, and ``volume_label`` must be None. To create a whole brain volume\nsource space, ``pos`` must be a float and 'mri' must be provided.\n\nTo create a volume source space from label, ``pos`` must be a float,\n``volume_label`` must be provided, and 'mri' must refer to a .mgh or .mgz\nfile with values corresponding to the freesurfer lookup-table (typically\n``aseg.mgz``).", "metadata": {}}
{"_id": "mne_mne_source_space/_source_space.py_add_source_space_distances_doc", "text": "Compute inter-source distances along the cortical surface.\n\nThis function will also try to add patch info for the source space.\nIt will only occur if the ``dist_limit`` is sufficiently high that all\npoints on the surface are within ``dist_limit`` of a point in the\nsource space.\n\nParameters\n----------\nsrc : instance of SourceSpaces\n    The source spaces to compute distances for.\ndist_limit : float\n    The upper limit of distances to include (in meters).\n    Note: if limit < np.inf, scipy > 0.13 (bleeding edge as of\n    10/2013) must be installed. If 0, then only patch (nearest vertex)\n    information is added.\n%(n_jobs)s\n    Ignored if ``dist_limit==0.``.\n%(verbose)s\n\nReturns\n-------\nsrc : instance of SourceSpaces\n    The original source spaces, with distance information added.\n    The distances are stored in src[n]['dist'].\n    Note: this function operates in-place.\n\nNotes\n-----\nThis function can be memory- and CPU-intensive. On a high-end machine\n(2012) running 6 jobs in parallel, an ico-5 (10242 per hemi) source space\ntakes about 10 minutes to compute all distances (``dist_limit = np.inf``).\nWith ``dist_limit = 0.007``, computing distances takes about 1 minute.\n\nWe recommend computing distances once per source space and then saving\nthe source space to disk, as the computed distances will automatically be\nstored along with the source space data for future use.", "metadata": {}}
{"_id": "mne_mne_source_space/_source_space.py_get_volume_labels_from_src_doc", "text": "Return a list of Label of segmented volumes included in the src space.\n\nParameters\n----------\nsrc : instance of SourceSpaces\n    The source space containing the volume regions.\n%(subject)s\nsubjects_dir : str\n    Freesurfer folder of the subjects.\n\nReturns\n-------\nlabels_aseg : list of Label\n    List of Label of segmented volumes included in src space.", "metadata": {}}
{"_id": "mne_mne_source_space/_source_space.py_morph_source_spaces_doc", "text": "Morph an existing source space to a different subject.\n\n.. warning:: This can be used in place of morphing source estimates for\n             multiple subjects, but there may be consequences in terms\n             of dipole topology.\n\nParameters\n----------\nsrc_from : instance of SourceSpaces\n    Surface source spaces to morph.\nsubject_to : str\n    The destination subject.\nsurf : str\n    The brain surface to use for the new source space.\nsubject_from : str | None\n    The \"from\" subject. For most source spaces this shouldn't need\n    to be provided, since it is stored in the source space itself.\nsubjects_dir : path-like | None\n    Path to ``SUBJECTS_DIR`` if it is not set in the environment.\n%(verbose)s\n\nReturns\n-------\nsrc : instance of SourceSpaces\n    The morphed source spaces.\n\nNotes\n-----\n.. versionadded:: 0.10.0", "metadata": {}}
{"_id": "mne_mne_source_space/_source_space.py_compute_distance_to_sensors_doc", "text": "Compute distances between vertices and sensors.\n\nParameters\n----------\nsrc : instance of SourceSpaces\n    The object with vertex positions for which to compute distances to\n    sensors.\n%(info)s Must contain sensor positions to which distances shall\n    be computed.\n%(picks_good_data)s\n%(trans_not_none)s\n%(verbose)s\n\nReturns\n-------\ndepth : array of shape (n_vertices, n_channels)\n    The Euclidean distances of source space vertices with respect to\n    sensors.", "metadata": {}}
{"_id": "mne_mne_source_space/_source_space.py_get_decimated_surfaces_doc", "text": "Get the decimated surfaces from a source space.\n\nParameters\n----------\nsrc : instance of SourceSpaces | path-like\n    The source space with decimated surfaces.\n\nReturns\n-------\nsurfaces : list of dict\n    The decimated surfaces present in the source space. Each dict\n    which contains 'rr' and 'tris' keys for vertices positions and\n    triangle indices.\n\nNotes\n-----\n.. versionadded:: 1.0", "metadata": {}}
{"_id": "mne_mne_source_space/_source_space.py_plot_doc", "text": "Plot the source space.\n\nParameters\n----------\nhead : bool\n    If True, show head surface.\nbrain : bool | str\n    If True, show the brain surfaces. Can also be a str for\n    surface type (e.g., ``'pial'``, same as True). Default is None,\n    which means ``'white'`` for surface source spaces and ``False``\n    otherwise.\nskull : bool | str | list of str | list of dict | None\n    Whether to plot skull surface. If string, common choices would be\n    ``'inner_skull'``, or ``'outer_skull'``. Can also be a list to plot\n    multiple skull surfaces. If a list of dicts, each dict must\n    contain the complete surface info (such as you get from\n    :func:`mne.make_bem_model`). True is an alias of 'outer_skull'.\n    The subjects bem and bem/flash folders are searched for the 'surf'\n    files. Defaults to None, which is False for surface source spaces,\n    and True otherwise.\nsubjects_dir : path-like | None\n    Path to ``SUBJECTS_DIR`` if it is not set in the environment.\ntrans : path-like | ``'auto'`` | dict | None\n    The full path to the head<->MRI transform ``*-trans.fif`` file\n    produced during coregistration. If trans is None, an identity\n    matrix is assumed. This is only needed when the source space is in\n    head coordinates.\n%(verbose)s\n\nReturns\n-------\nfig : instance of Figure3D\n    The figure.", "metadata": {}}
{"_id": "mne_mne_source_space/_source_space.py_copy_doc", "text": "Make a copy of the source spaces.\n\nReturns\n-------\nsrc : instance of SourceSpaces\n    The copied source spaces.", "metadata": {}}
{"_id": "mne_mne_source_space/_source_space.py_save_doc", "text": "Save the source spaces to a fif file.\n\nParameters\n----------\nfname : path-like\n    File to write, which should end with ``-src.fif`` or ``-src.fif.gz``.\n%(overwrite)s\n%(verbose)s", "metadata": {}}
{"_id": "mne_mne_source_space/_source_space.py_export_volume_doc", "text": "Export source spaces to nifti or mgz file.\n\nParameters\n----------\nfname : path-like\n    Name of nifti or mgz file to write.\ninclude_surfaces : bool\n    If True, include surface source spaces.\ninclude_discrete : bool\n    If True, include discrete source spaces.\ndest : ``'mri'`` | ``'surf'``\n    If ``'mri'`` the volume is defined in the coordinate system of the\n    original T1 image. If ``'surf'`` the coordinate system of the\n    FreeSurfer surface is used (Surface RAS).\ntrans : dict, str, or None\n    Either a transformation filename (usually made using mne_analyze)\n    or an info dict (usually opened using read_trans()). If string, an\n    ending of ``.fif`` or ``.fif.gz`` will be assumed to be in FIF\n    format, any other ending will be assumed to be a text file with a\n    4x4 transformation matrix (like the ``--trans`` MNE-C option.\n    Must be provided if source spaces are in head coordinates and\n    include_surfaces and mri_resolution are True.\nmri_resolution : bool | str\n    If True, the image is saved in MRI resolution\n    (e.g. 256 x 256 x 256), and each source region (surface or\n    segmentation volume) filled in completely. If \"sparse\", only a\n    single voxel in the high-resolution MRI is filled in for each\n    source point.\n\n    .. versionchanged:: 0.21.0\n       Support for ``\"sparse\"`` was added.\nuse_lut : bool\n    If True, assigns a numeric value to each source space that\n    corresponds to a color on the freesurfer lookup table.\n%(overwrite)s\n\n    .. versionadded:: 0.19\n%(verbose)s\n\nNotes\n-----\nThis method requires nibabel.", "metadata": {}}
{"_id": "mne_mne_forward/forward.py_read_forward_solution_doc", "text": "Read a forward solution a.k.a. lead field.\n\nParameters\n----------\nfname : path-like\n    The file name, which should end with ``-fwd.fif``, ``-fwd.fif.gz``,\n    ``_fwd.fif``, ``_fwd.fif.gz``, ``-fwd.h5``, or ``_fwd.h5``.\ninclude : list, optional\n    List of names of channels to include. If empty all channels\n    are included.\nexclude : list, optional\n    List of names of channels to exclude. If empty include all channels.\n%(ordered)s\n%(verbose)s\n\nReturns\n-------\nfwd : instance of Forward\n    The forward solution.\n\nSee Also\n--------\nwrite_forward_solution, make_forward_solution\n\nNotes\n-----\nForward solutions, which are derived from an original forward solution with\nfree orientation, are always stored on disk as forward solution with free\norientation in X/Y/Z RAS coordinates. To apply any transformation to the\nforward operator (surface orientation, fixed orientation) please apply\n:func:`convert_forward_solution` after reading the forward solution with\n:func:`read_forward_solution`.\n\nForward solutions, which are derived from an original forward solution with\nfixed orientation, are stored on disk as forward solution with fixed\nsurface-based orientations. Please note that the transformation to\nsurface-based, fixed orientation cannot be reverted after loading the\nforward solution with :func:`read_forward_solution`.", "metadata": {}}
{"_id": "mne_mne_forward/forward.py_convert_forward_solution_doc", "text": "Convert forward solution between different source orientations.\n\nParameters\n----------\nfwd : Forward\n    The forward solution to modify.\nsurf_ori : bool, optional (default False)\n    Use surface-based source coordinate system? Note that force_fixed=True\n    implies surf_ori=True.\nforce_fixed : bool, optional (default False)\n    If True, force fixed source orientation mode.\ncopy : bool\n    Whether to return a new instance or modify in place.\n%(use_cps)s\n%(verbose)s\n\nReturns\n-------\nfwd : Forward\n    The modified forward solution.", "metadata": {}}
{"_id": "mne_mne_forward/forward.py_write_forward_solution_doc", "text": "Write forward solution to a file.\n\nParameters\n----------\n%(fname_fwd)s\nfwd : Forward\n    Forward solution.\n%(overwrite)s\n%(verbose)s\n\nSee Also\n--------\nread_forward_solution\n\nNotes\n-----\nForward solutions, which are derived from an original forward solution with\nfree orientation, are always stored on disk as forward solution with free\norientation in X/Y/Z RAS coordinates. Transformations (surface orientation,\nfixed orientation) will be reverted. To reapply any transformation to the\nforward operator please apply :func:`convert_forward_solution` after\nreading the forward solution with :func:`read_forward_solution`.\n\nForward solutions, which are derived from an original forward solution with\nfixed orientation, are stored on disk as forward solution with fixed\nsurface-based orientations. Please note that the transformation to\nsurface-based, fixed orientation cannot be reverted after loading the\nforward solution with :func:`read_forward_solution`.", "metadata": {}}
{"_id": "mne_mne_forward/forward.py_is_fixed_orient_doc", "text": "Check if the forward operator is fixed orientation.\n\nParameters\n----------\nforward : instance of Forward\n    The forward.\norig : bool\n    If True, consider the original source orientation.\n    If False (default), consider the current source orientation.\n\nReturns\n-------\nfixed_ori : bool\n    Whether or not it is fixed orientation.", "metadata": {}}
{"_id": "mne_mne_forward/forward.py_write_forward_meas_info_doc", "text": "Write measurement info stored in forward solution.\n\nParameters\n----------\nfid : file id\n    The file id\n%(info_not_none)s", "metadata": {}}
{"_id": "mne_mne_forward/forward.py_compute_orient_prior_doc", "text": "Compute orientation prior.\n\nParameters\n----------\nforward : instance of Forward\n    Forward operator.\n%(loose)s\n%(verbose)s\n\nReturns\n-------\norient_prior : ndarray, shape (n_sources,)\n    Orientation priors.\n\nSee Also\n--------\ncompute_depth_prior", "metadata": {}}
{"_id": "mne_mne_forward/forward.py_compute_depth_prior_doc", "text": "Compute depth prior for depth weighting.\n\nParameters\n----------\nforward : instance of Forward\n    The forward solution.\n%(info_not_none)s\nexp : float\n    Exponent for the depth weighting, must be between 0 and 1.\nlimit : float | None\n    The upper bound on depth weighting.\n    Can be None to be bounded by the largest finite prior.\nlimit_depth_chs : bool | 'whiten'\n    How to deal with multiple channel types in depth weighting.\n    The default is True, which whitens based on the source sensitivity\n    of the highest-SNR channel type. See Notes for details.\n\n    .. versionchanged:: 0.18\n       Added the \"whiten\" option.\ncombine_xyz : 'spectral' | 'fro'\n    When a loose (or free) orientation is used, how the depth weighting\n    for each triplet should be calculated.\n    If 'spectral', use the squared spectral norm of Gk.\n    If 'fro', use the squared Frobenius norm of Gk.\n\n    .. versionadded:: 0.18\nnoise_cov : instance of Covariance | None\n    The noise covariance to use to whiten the gain matrix when\n    ``limit_depth_chs='whiten'``.\n\n    .. versionadded:: 0.18\n%(rank_none)s\n\n    .. versionadded:: 0.18\n%(verbose)s\n\nReturns\n-------\ndepth_prior : ndarray, shape (n_vertices,)\n    The depth prior.\n\nSee Also\n--------\ncompute_orient_prior\n\nNotes\n-----\nThe defaults used by the minimum norm code and sparse solvers differ.\nIn particular, the values for MNE are::\n\n    compute_depth_prior(..., limit=10., limit_depth_chs=True,\n                        combine_xyz='spectral')\n\nIn sparse solvers and LCMV, the values are::\n\n    compute_depth_prior(..., limit=None, limit_depth_chs='whiten',\n                        combine_xyz='fro')\n\nThe ``limit_depth_chs`` argument can take the following values:\n\n* :data:`python:True` (default)\n      Use only grad channels in depth weighting (equivalent to MNE C\n      minimum-norm code). If grad channels aren't present, only mag\n      channels will be used (if no mag, then eeg). This makes the depth\n      prior dependent only on the sensor geometry (and relationship\n      to the sources).\n* ``'whiten'``\n      Compute a whitener and apply it to the gain matrix before computing\n      the depth prior. In this case ``noise_cov`` must not be None.\n      Whitening the gain matrix makes the depth prior\n      depend on both sensor geometry and the data of interest captured\n      by the noise covariance (e.g., projections, SNR).\n\n      .. versionadded:: 0.18\n* :data:`python:False`\n      Use all channels. Not recommended since the depth weighting will be\n      biased toward whichever channel type has the largest values in\n      SI units (such as EEG being orders of magnitude larger than MEG).", "metadata": {}}
{"_id": "mne_mne_forward/forward.py_apply_forward_doc", "text": "Project source space currents to sensor space using a forward operator.\n\nThe sensor space data is computed for all channels present in fwd. Use\npick_channels_forward or pick_types_forward to restrict the solution to a\nsubset of channels.\n\nThe function returns an Evoked object, which is constructed from\nevoked_template. The evoked_template should be from the same MEG system on\nwhich the original data was acquired. An exception will be raised if the\nforward operator contains channels that are not present in the template.\n\nParameters\n----------\nfwd : Forward\n    Forward operator to use.\nstc : SourceEstimate\n    The source estimate from which the sensor space data is computed.\n%(info_not_none)s\nstart : int, optional\n    Index of first time sample (index not time is seconds).\nstop : int, optional\n    Index of first time sample not to include (index not time is seconds).\n%(use_cps)s\n\n    .. versionadded:: 0.15\n%(on_missing_fwd)s\n    Default is \"raise\".\n\n    .. versionadded:: 0.18\n%(verbose)s\n\nReturns\n-------\nevoked : Evoked\n    Evoked object with computed sensor space data.\n\nSee Also\n--------\napply_forward_raw: Compute sensor space data and return a Raw object.", "metadata": {}}
{"_id": "mne_mne_forward/forward.py_apply_forward_raw_doc", "text": "Project source space currents to sensor space using a forward operator.\n\nThe sensor space data is computed for all channels present in fwd. Use\npick_channels_forward or pick_types_forward to restrict the solution to a\nsubset of channels.\n\nThe function returns a Raw object, which is constructed using provided\ninfo. The info object should be from the same MEG system on which the\noriginal data was acquired. An exception will be raised if the forward\noperator contains channels that are not present in the info.\n\nParameters\n----------\nfwd : Forward\n    Forward operator to use.\nstc : SourceEstimate\n    The source estimate from which the sensor space data is computed.\n%(info_not_none)s\nstart : int, optional\n    Index of first time sample (index not time is seconds).\nstop : int, optional\n    Index of first time sample not to include (index not time is seconds).\n%(on_missing_fwd)s\n    Default is \"raise\".\n\n    .. versionadded:: 0.18\n%(use_cps)s\n\n    .. versionadded:: 0.21\n%(verbose)s\n\nReturns\n-------\nraw : Raw object\n    Raw object with computed sensor space data.\n\nSee Also\n--------\napply_forward: Compute sensor space data and return an Evoked object.", "metadata": {}}
{"_id": "mne_mne_forward/forward.py_restrict_forward_to_stc_doc", "text": "Restrict forward operator to active sources in a source estimate.\n\nParameters\n----------\nfwd : instance of Forward\n    Forward operator.\nstc : instance of SourceEstimate\n    Source estimate.\n%(on_missing_fwd)s\n    Default is \"ignore\".\n\n    .. versionadded:: 0.18\n\nReturns\n-------\nfwd_out : instance of Forward\n    Restricted forward operator.\n\nSee Also\n--------\nrestrict_forward_to_label", "metadata": {}}
{"_id": "mne_mne_forward/forward.py_restrict_forward_to_label_doc", "text": "Restrict forward operator to labels.\n\nParameters\n----------\nfwd : Forward\n    Forward operator.\nlabels : instance of Label | list\n    Label object or list of label objects.\n\nReturns\n-------\nfwd_out : dict\n    Restricted forward operator.\n\nSee Also\n--------\nrestrict_forward_to_stc", "metadata": {}}
{"_id": "mne_mne_forward/forward.py_average_forward_solutions_doc", "text": "Average forward solutions.\n\nParameters\n----------\nfwds : list of Forward\n    Forward solutions to average. Each entry (dict) should be a\n    forward solution.\nweights : array | None\n    Weights to apply to each forward solution in averaging. If None,\n    forward solutions will be equally weighted. Weights must be\n    non-negative, and will be adjusted to sum to one.\n%(verbose)s\n\nReturns\n-------\nfwd : Forward\n    The averaged forward solution.", "metadata": {}}
{"_id": "mne_mne_forward/forward.py_copy_doc", "text": "Copy the Forward instance.", "metadata": {}}
{"_id": "mne_mne_forward/forward.py_save_doc", "text": "Save the forward solution.\n\nParameters\n----------\n%(fname_fwd)s\n%(overwrite)s\n%(verbose)s", "metadata": {}}
{"_id": "mne_mne_forward/forward.py_pick_channels_doc", "text": "Pick channels from this forward operator.\n\nParameters\n----------\nch_names : list of str\n    List of channels to include.\nordered : bool\n    If true (default False), treat ``include`` as an ordered list\n    rather than a set.\n\nReturns\n-------\nfwd : instance of Forward.\n    The modified forward model.\n\nNotes\n-----\nOperates in-place.\n\n.. versionadded:: 0.20.0", "metadata": {}}
{"_id": "mne_mne_forward/_make_forward.py_make_forward_solution_doc", "text": "Calculate a forward solution for a subject.\n\nParameters\n----------\n%(info_str)s\n%(trans)s\n\n    .. versionchanged:: 0.19\n        Support for ``'fsaverage'`` argument.\nsrc : path-like | instance of SourceSpaces\n    Either a path to a source space file or a loaded or generated\n    :class:`~mne.SourceSpaces`.\nbem : path-like | ConductorModel\n    Filename of the BEM (e.g., ``\"sample-5120-5120-5120-bem-sol.fif\"``) to\n    use, or a loaded :class:`~mne.bem.ConductorModel`. See\n    :func:`~mne.make_bem_model` and :func:`~mne.make_bem_solution` to create a\n    :class:`mne.bem.ConductorModel`.\nmeg : bool\n    If True (default), include MEG computations.\neeg : bool\n    If True (default), include EEG computations.\nmindist : float\n    Minimum distance of sources from inner skull surface (in mm).\nignore_ref : bool\n    If True, do not include reference channels in compensation. This\n    option should be True for KIT files, since forward computation\n    with reference channels is not currently supported.\n%(n_jobs)s\n%(verbose)s\n\nReturns\n-------\nfwd : instance of Forward\n    The forward solution.\n\nSee Also\n--------\nconvert_forward_solution\n\nNotes\n-----\nThe ``--grad`` option from MNE-C (to compute gradients) is not implemented\nhere.\n\nTo create a fixed-orientation forward solution, use this function\nfollowed by :func:`mne.convert_forward_solution`.\n\n.. note::\n    If the BEM solution was computed with `OpenMEEG <https://openmeeg.github.io>`__\n    in :func:`mne.make_bem_solution`, then OpenMEEG will automatically\n    be used to compute the forward solution.\n\n.. versionchanged:: 1.2\n   Added support for OpenMEEG-based forward solution calculations.", "metadata": {}}
{"_id": "mne_mne_forward/_make_forward.py_make_forward_dipole_doc", "text": "Convert dipole object to source estimate and calculate forward operator.\n\nThe instance of Dipole is converted to a discrete source space,\nwhich is then combined with a BEM or a sphere model and\nthe sensor information in info to form a forward operator.\n\nThe source estimate object (with the forward operator) can be projected to\nsensor-space using :func:`mne.simulation.simulate_evoked`.\n\n.. note:: If the (unique) time points of the dipole object are unevenly\n          spaced, the first output will be a list of single-timepoint\n          source estimates.\n\nParameters\n----------\n%(dipole)s\nbem : str | dict\n    The BEM filename (str) or a loaded sphere model (dict).\ninfo : instance of Info\n    The measurement information dictionary. It is sensor-information etc.,\n    e.g., from a real data file.\ntrans : str | None\n    The head<->MRI transform filename. Must be provided unless BEM\n    is a sphere model.\n%(n_jobs)s\n%(verbose)s\n\nReturns\n-------\nfwd : instance of Forward\n    The forward solution corresponding to the source estimate(s).\nstc : instance of VolSourceEstimate | list of VolSourceEstimate\n    The dipoles converted to a discrete set of points and associated\n    time courses. If the time points of the dipole are unevenly spaced,\n    a list of single-timepoint source estimates are returned.\n\nSee Also\n--------\nmne.simulation.simulate_evoked\n\nNotes\n-----\n.. versionadded:: 0.12.0", "metadata": {}}
{"_id": "mne_mne_forward/_make_forward.py_use_coil_def_doc", "text": "Use a custom coil definition file.\n\nParameters\n----------\nfname : path-like\n    The filename of the coil definition file.\n\nReturns\n-------\ncontext : contextmanager\n    The context for using the coil definition.\n\nNotes\n-----\nThis is meant to be used a context manager such as:\n\n>>> with use_coil_def(my_fname):  # doctest:+SKIP\n...     make_forward_solution(...)\n\nThis allows using custom coil definitions with functions that require\nforward modeling.", "metadata": {}}
{"_id": "mne_mne_forward/_field_interpolation.py_make_field_map_doc", "text": "Compute surface maps used for field display in 3D.\n\nParameters\n----------\nevoked : Evoked | Epochs | Raw\n    The measurement file. Need to have info attribute.\n%(trans)s ``\"auto\"`` (default) will load trans from the FreeSurfer\n    directory specified by ``subject`` and ``subjects_dir`` parameters.\n\n    .. versionchanged:: 0.19\n        Support for ``'fsaverage'`` argument.\nsubject : str | None\n    The subject name corresponding to FreeSurfer environment\n    variable SUBJECT. If None, map for EEG data will not be available.\nsubjects_dir : path-like\n    The path to the freesurfer subjects reconstructions.\n    It corresponds to Freesurfer environment variable SUBJECTS_DIR.\nch_type : None | ``'eeg'`` | ``'meg'``\n    If None, a map for each available channel type will be returned.\n    Else only the specified type will be used.\nmode : ``'accurate'`` | ``'fast'``\n    Either ``'accurate'`` or ``'fast'``, determines the quality of the\n    Legendre polynomial expansion used. ``'fast'`` should be sufficient\n    for most applications.\nmeg_surf : 'helmet' | 'head'\n    Should be ``'helmet'`` or ``'head'`` to specify in which surface\n    to compute the MEG field map. The default value is ``'helmet'``.\norigin : array-like, shape (3,) | 'auto'\n    Origin of the sphere in the head coordinate frame and in meters.\n    Can be ``'auto'``, which means a head-digitization-based origin\n    fit. Default is ``(0., 0., 0.04)``.\n\n    .. versionadded:: 0.11\n%(n_jobs)s\n%(helmet_upsampling)s\n\n    .. versionadded:: 1.10\n%(head_source)s\n\n    .. versionadded:: 1.1\n%(verbose)s\n\nReturns\n-------\nsurf_maps : list\n    The surface maps to be used for field plots. The list contains\n    separate ones for MEG and EEG (if both MEG and EEG are present).", "metadata": {}}
{"_id": "mne_mne_utils/numerics.py_split_list_doc", "text": "Split list in n (approx) equal pieces, possibly giving indices.", "metadata": {}}
{"_id": "mne_mne_utils/numerics.py_array_split_idx_doc", "text": "Do what numpy.array_split does, but add indices.", "metadata": {}}
{"_id": "mne_mne_utils/numerics.py_sum_squared_doc", "text": "Compute norm of an array.\n\nParameters\n----------\nX : array\n    Data whose norm must be found.\n\nReturns\n-------\nvalue : float\n    Sum of squares of the input array X.", "metadata": {}}
{"_id": "mne_mne_utils/numerics.py_compute_corr_doc", "text": "Compute pearson correlations between a vector and a matrix.", "metadata": {}}
{"_id": "mne_mne_utils/numerics.py_random_permutation_doc", "text": "Emulate the randperm matlab function.\n\nIt returns a vector containing a random permutation of the\nintegers between 0 and n_samples-1. It returns the same random numbers\nthan randperm matlab function whenever the random_state is the same\nas the matlab's random seed.\n\nThis function is useful for comparing against matlab scripts\nwhich use the randperm function.\n\nNote: the randperm(n_samples) matlab function generates a random\nsequence between 1 and n_samples, whereas\nrandom_permutation(n_samples, random_state) function generates\na random sequence between 0 and n_samples-1, that is:\nrandperm(n_samples) = random_permutation(n_samples, random_state) - 1\n\nParameters\n----------\nn_samples : int\n    End point of the sequence to be permuted (excluded, i.e., the end point\n    is equal to n_samples-1)\n%(random_state)s\n\nReturns\n-------\nrandperm : ndarray, int\n    Randomly permuted sequence between 0 and n-1.", "metadata": {}}
{"_id": "mne_mne_utils/numerics.py_hashfunc_doc", "text": "Calculate the hash for a file.\n\nParameters\n----------\nfname : str\n    Filename.\nblock_size : int\n    Block size to use when reading.\n\nReturns\n-------\nhash_ : str\n    The hexadecimal digest of the hash.", "metadata": {}}
{"_id": "mne_mne_utils/numerics.py_create_slices_doc", "text": "Generate slices of time indexes.\n\nParameters\n----------\nstart : int\n    Index where first slice should start.\nstop : int\n    Index where last slice should maximally end.\nlength : int\n    Number of time sample included in a given slice.\nstep: int | None\n    Number of time samples separating two slices.\n    If step = None, step = length.\n\nReturns\n-------\nslices : list\n    List of slice objects.", "metadata": {}}
{"_id": "mne_mne_utils/numerics.py_grand_average_doc", "text": "Make grand average of a list of Evoked, AverageTFR, or Spectrum data.\n\nFor :class:`mne.Evoked` data, the function interpolates bad channels based on the\n``interpolate_bads`` parameter. If ``interpolate_bads`` is True, the grand average\nfile will contain good channels and the bad channels interpolated from the good\nMEG/EEG channels.\nFor :class:`mne.time_frequency.AverageTFR` and :class:`mne.time_frequency.Spectrum`\ndata, the function takes the subset of channels not marked as bad in any of the\ninstances.\n\nThe ``grand_average.nave`` attribute will be equal to the number of datasets used to\ncalculate the grand average.\n\n.. note:: A grand average evoked should not be used for source localization.\n\nParameters\n----------\nall_inst : list of Evoked, AverageTFR or Spectrum\n    The datasets.\n\n    .. versionchanged:: 1.10.0\n        Added support for :class:`~mne.time_frequency.Spectrum` objects.\n\ninterpolate_bads : bool\n    If True, bad MEG and EEG channels are interpolated. Ignored for\n    :class:`~mne.time_frequency.AverageTFR` and\n    :class:`~mne.time_frequency.Spectrum` data.\ndrop_bads : bool\n    If True, drop all bad channels marked as bad in any data set. If neither\n    ``interpolate_bads`` nor ``drop_bads`` is `True`, in the output file, every\n    channel marked as bad in at least one of the input files will be marked as bad,\n    but no interpolation or dropping will be performed.\n\nReturns\n-------\ngrand_average : Evoked | AverageTFR | Spectrum\n    The grand average data. Same type as input.\n\nNotes\n-----\nAggregating multitaper TFR datasets with a taper dimension such as for complex or\nphase data is not supported.\n\n.. versionadded:: 0.11.0", "metadata": {}}
{"_id": "mne_mne_utils/numerics.py_object_hash_doc", "text": "Hash a reasonable python object.\n\nParameters\n----------\nx : object\n    Object to hash. Can be anything comprised of nested versions of:\n    {dict, list, tuple, ndarray, str, bytes, float, int, None}.\nh : hashlib HASH object | None\n    Optional, object to add the hash to. None creates an MD5 hash.\n\nReturns\n-------\ndigest : int\n    The digest resulting from the hash.", "metadata": {}}
{"_id": "mne_mne_utils/numerics.py_object_size_doc", "text": "Estimate the size of a reasonable python object.\n\nParameters\n----------\nx : object\n    Object to approximate the size of.\n    Can be anything comprised of nested versions of:\n    {dict, list, tuple, ndarray, str, bytes, float, int, None}.\nmemo : dict | None\n    The memodict.\n\nReturns\n-------\nsize : int\n    The estimated size in bytes of the object.", "metadata": {}}
{"_id": "mne_mne_utils/numerics.py_object_diff_doc", "text": "Compute all differences between two python variables.\n\nParameters\n----------\na : object\n    Currently supported: class, dict, list, tuple, ndarray,\n    int, str, bytes, float, StringIO, BytesIO.\nb : object\n    Must be same type as ``a``.\npre : str\n    String to prepend to each line.\nallclose : bool\n    If True (default False), use assert_allclose.\n\nReturns\n-------\ndiffs : str\n    A string representation of the differences.", "metadata": {}}
{"_id": "mne_mne_utils/progressbar.py_update_doc", "text": "Update progressbar with current value of process.\n\nParameters\n----------\ncur_value : number\n    Current value of process.  Should be <= max_value (but this is not\n    enforced).  The percent of the progressbar will be computed as\n    ``(cur_value / max_value) * 100``.", "metadata": {}}
{"_id": "mne_mne_utils/progressbar.py_update_with_increment_value_doc", "text": "Update progressbar with an increment.\n\nParameters\n----------\nincrement_value : int\n    Value of the increment of process.  The percent of the progressbar\n    will be computed as\n    ``(self.cur_value + increment_value / max_value) * 100``.", "metadata": {}}
{"_id": "mne_mne_utils/progressbar.py_subset_doc", "text": "Make a joblib-friendly index subset updater.\n\nParameters\n----------\nidx : ndarray\n    List of indices for this subset.\n\nReturns\n-------\nupdater : instance of PBSubsetUpdater\n    Class with a ``.update(ii)`` method.", "metadata": {}}
{"_id": "mne_mne_utils/linalg.py_eigh_doc", "text": "Efficient wrapper for eigh.\n\nParameters\n----------\na : ndarray, shape (n_components, n_components)\n    The symmetric array operate on.\noverwrite_a : bool\n    If True, the contents of a can be overwritten for efficiency.\ncheck_finite : bool\n    If True, check that all elements are finite.\n\nReturns\n-------\nw : ndarray, shape (n_components,)\n    The N eigenvalues, in ascending order, each repeated according to\n    its multiplicity.\nv : ndarray, shape (n_components, n_components)\n    The normalized eigenvector corresponding to the eigenvalue ``w[i]``\n    is the column ``v[:, i]``.", "metadata": {}}
{"_id": "mne_mne_utils/linalg.py_sqrtm_sym_doc", "text": "Compute the sqrt of a positive, semi-definite matrix (or its inverse).\n\nParameters\n----------\nA : ndarray, shape (..., n, n)\n    The array to take the square root of.\nrcond : float\n    The relative condition number used during reconstruction.\ninv : bool\n    If True, compute the inverse of the square root rather than the\n    square root itself.\n\nReturns\n-------\nA_sqrt : ndarray, shape (..., n, n)\n    The (possibly inverted) square root of A.\ns : ndarray, shape (..., n)\n    The original square root singular values (not inverted).", "metadata": {}}
{"_id": "mne_mne_utils/linalg.py_pinvh_doc", "text": "Compute a pseudo-inverse of a Hermitian matrix.\n\nParameters\n----------\na : ndarray, shape (n, n)\n    The Hermitian array to invert.\nrtol : float | None\n    The relative tolerance.\n\nReturns\n-------\na_pinv : ndarray, shape (n, n)\n    The pseudo-inverse of a.", "metadata": {}}
{"_id": "mne_mne_utils/linalg.py_pinv_doc", "text": "Compute a pseudo-inverse of a matrix.\n\nParameters\n----------\na : ndarray, shape (n, m)\n    The array to invert.\nrtol : float | None\n    The relative tolerance.\n\nReturns\n-------\na_pinv : ndarray, shape (m, n)\n    The pseudo-inverse of a.", "metadata": {}}
{"_id": "mne_mne_utils/_logging.py_verbose_doc", "text": "Verbose decorator to allow functions to override log-level.\n\nParameters\n----------\nfunction : callable\n    Function to be decorated by setting the verbosity level.\n\nReturns\n-------\ndec : callable\n    The decorated function.\n\nSee Also\n--------\nset_log_level\nset_config\n\nNotes\n-----\nThis decorator is used to set the verbose level during a function or method\ncall, such as :func:`mne.compute_covariance`. The `verbose` keyword\nargument can be 'DEBUG', 'INFO', 'WARNING', 'ERROR', 'CRITICAL', True (an\nalias for 'INFO'), or False (an alias for 'WARNING'). To set the global\nverbosity level for all functions, use :func:`mne.set_log_level`.\n\nThis function also serves as a docstring filler.\n\nExamples\n--------\nYou can use the ``verbose`` argument to set the verbose level on the fly::\n\n    >>> import mne\n    >>> cov = mne.compute_raw_covariance(raw, verbose='WARNING')  # doctest: +SKIP\n    >>> cov = mne.compute_raw_covariance(raw, verbose='INFO')  # doctest: +SKIP\n    Using up to 49 segments\n    Number of samples used : 5880\n    [done]", "metadata": {}}
{"_id": "mne_mne_utils/_logging.py_set_log_level_doc", "text": "Set the logging level.\n\nParameters\n----------\nverbose : bool, str, int, or None\n    The verbosity of messages to print. If a str, it can be either DEBUG,\n    INFO, WARNING, ERROR, or CRITICAL. Note that these are for\n    convenience and are equivalent to passing in logging.DEBUG, etc.\n    For bool, True is the same as 'INFO', False is the same as 'WARNING'.\n    If None, the environment variable MNE_LOGGING_LEVEL is read, and if\n    it doesn't exist, defaults to INFO.\nreturn_old_level : bool\n    If True, return the old verbosity level.\n%(add_frames)s\n\nReturns\n-------\nold_level : int\n    The old level. Only returned if ``return_old_level`` is True.", "metadata": {}}
{"_id": "mne_mne_utils/_logging.py_set_log_file_doc", "text": "Set the log to print to a file.\n\nParameters\n----------\nfname : path-like | None\n    Filename of the log to print to. If None, stdout is used.\n    To suppress log outputs, use set_log_level('WARNING').\noutput_format : str\n    Format of the output messages. See the following for examples:\n\n        https://docs.python.org/dev/howto/logging.html\n\n    e.g., \"%(asctime)s - %(levelname)s - %(message)s\".\noverwrite : bool | None\n    Overwrite the log file (if it exists). Otherwise, statements\n    will be appended to the log (default). None is the same as False,\n    but additionally raises a warning to notify the user that log\n    entries will be appended.", "metadata": {}}
{"_id": "mne_mne_utils/_logging.py_warn_doc", "text": "Emit a warning with trace outside the mne namespace.\n\nThis function takes arguments like warnings.warn, and sends messages\nusing both ``warnings.warn`` and ``logger.warn``. Warnings can be\ngenerated deep within nested function calls. In order to provide a\nmore helpful warning, this function traverses the stack until it\nreaches a frame outside the ``mne`` namespace that caused the error.\n\nParameters\n----------\nmessage : str\n    Warning message.\ncategory : instance of Warning\n    The warning class. Defaults to ``RuntimeWarning``.\nmodule : str\n    The name of the module emitting the warning.\nignore_namespaces : list of str\n    Namespaces to ignore when traversing the stack.\n\n    .. versionadded:: 0.24", "metadata": {}}
{"_id": "mne_mne_utils/_logging.py_filter_out_warnings_doc", "text": "Remove particular records from ``warn_record``.\n\nThis helper takes a list of :class:`warnings.WarningMessage` objects,\nand remove those matching category and/or text.\n\nParameters\n----------\ncategory: WarningMessage type | None\n   class of the message to filter out\n\nmatch : str | None\n    text or regex that matches the error message to filter out", "metadata": {}}
{"_id": "mne_mne_utils/_logging.py_wrapped_stdout_doc", "text": "Wrap stdout writes to logger.info, with an optional indent prefix.\n\nParameters\n----------\nindent : str\n    The indentation to add.\ncull_newlines : bool\n    If True, cull any new/blank lines at the end.", "metadata": {}}
{"_id": "mne_mne_utils/_logging.py_getvalue_doc", "text": "Get the value.", "metadata": {}}
{"_id": "mne_mne_utils/misc.py_pformat_doc", "text": "Format a template string partially.\n\nExamples\n--------\n>>> pformat(\"{a}_{b}\", a='x')\n'x_{b}'", "metadata": {}}
{"_id": "mne_mne_utils/misc.py_run_subprocess_doc", "text": "Run command using subprocess.Popen.\n\nRun command and wait for command to complete. If the return code was zero\nthen return, otherwise raise CalledProcessError.\nBy default, this will also add stdout= and stderr=subproces.PIPE\nto the call to Popen to suppress printing to the terminal.\n\nParameters\n----------\ncommand : list of str | str\n    Command to run as subprocess (see subprocess.Popen documentation).\nreturn_code : bool\n    If True, return the return code instead of raising an error if it's\n    non-zero.\n\n    .. versionadded:: 0.20\n%(verbose)s\n*args, **kwargs : arguments\n    Additional arguments to pass to subprocess.Popen.\n\nReturns\n-------\nstdout : str\n    Stdout returned by the process.\nstderr : str\n    Stderr returned by the process.\ncode : int\n    The return code, only returned if ``return_code == True``.", "metadata": {}}
{"_id": "mne_mne_utils/misc.py_running_subprocess_doc", "text": "Context manager to do something with a command running via Popen.\n\nParameters\n----------\ncommand : list of str | str\n    Command to run as subprocess (see :class:`python:subprocess.Popen`).\nafter : str\n    Can be:\n\n    - \"wait\" to use :meth:`~python:subprocess.Popen.wait`\n    - \"communicate\" to use :meth:`~python.subprocess.Popen.communicate`\n    - \"terminate\" to use :meth:`~python:subprocess.Popen.terminate`\n    - \"kill\" to use :meth:`~python:subprocess.Popen.kill`\n\n%(verbose)s\n*args, **kwargs : arguments\n    Additional arguments to pass to subprocess.Popen.\n\nReturns\n-------\np : instance of Popen\n    The process.", "metadata": {}}
{"_id": "mne_mne_utils/misc.py_sizeof_fmt_doc", "text": "Turn number of bytes into human-readable str.\n\nParameters\n----------\nnum : int\n    The number of bytes.\n\nReturns\n-------\nsize : str\n    The size in human-readable format.", "metadata": {}}
{"_id": "mne_mne_utils/misc.py_repr_html_doc", "text": "Decorate _repr_html_ methods.\n\nIf a _repr_html_ method is decorated with this decorator, the repr in a\nnotebook will show HTML or plain text depending on the config value\nMNE_REPR_HTML (by default \"true\", which will render HTML).\n\nParameters\n----------\nf : function\n    The function to decorate.\n\nReturns\n-------\nwrapper : function\n    The decorated function.", "metadata": {}}
{"_id": "mne_mne_utils/mixin.py_metadata_doc", "text": "Get the metadata.", "metadata": {}}
{"_id": "mne_mne_utils/mixin.py_time_as_index_doc", "text": "Convert time to indices.\n\nParameters\n----------\ntimes : list-like | float | int\n    List of numbers or a number representing points in time.\nuse_rounding : bool\n    If True, use rounding (instead of truncation) when converting\n    times to indices. This can help avoid non-unique indices.\n\nReturns\n-------\nindex : ndarray\n    Indices corresponding to the times supplied.", "metadata": {}}
{"_id": "mne_mne_utils/mixin.py_times_doc", "text": "Time vector in seconds.", "metadata": {}}
{"_id": "mne_mne_utils/mixin.py_tmin_doc", "text": "First time point.", "metadata": {}}
{"_id": "mne_mne_utils/mixin.py_tmax_doc", "text": "Last time point.", "metadata": {}}
{"_id": "mne_mne_utils/mixin.py_crop_doc", "text": "Crop data to a given time interval.\n\nParameters\n----------\ntmin : float | None\n    Start time of selection in seconds.\ntmax : float | None\n    End time of selection in seconds.\n%(include_tmax)s\n%(verbose)s\n\nReturns\n-------\ninst : instance of Raw, Epochs, Evoked, AverageTFR, or SourceEstimate\n    The cropped time-series object, modified in-place.\n\nNotes\n-----\n%(notes_tmax_included_by_default)s", "metadata": {}}
{"_id": "mne_mne_utils/mixin.py_decimate_doc", "text": "Decimate the time-series data.\n\nParameters\n----------\n%(decim)s\n%(offset_decim)s\n%(verbose)s\n\nReturns\n-------\ninst : MNE-object\n    The decimated object.\n\nSee Also\n--------\nmne.Epochs.resample\nmne.io.Raw.resample\n\nNotes\n-----\n%(decim_notes)s\n\nIf ``decim`` is 1, this method does not copy the underlying data.\n\n.. versionadded:: 0.10.0\n\nReferences\n----------\n.. footbibliography::", "metadata": {}}
{"_id": "mne_mne_utils/mixin.py_shift_time_doc", "text": "Shift time scale in epoched or evoked data.\n\nParameters\n----------\ntshift : float\n    The (absolute or relative) time shift in seconds. If ``relative``\n    is True, positive tshift increases the time value associated with\n    each sample, while negative tshift decreases it.\nrelative : bool\n    If True, increase or decrease time values by ``tshift`` seconds.\n    Otherwise, shift the time values such that the time of the first\n    sample equals ``tshift``.\n\nReturns\n-------\nepochs : MNE-object\n    The modified instance.\n\nNotes\n-----\nThis method allows you to shift the *time* values associated with each\ndata sample by an arbitrary amount. It does *not* resample the signal\nor change the *data* values in any way.", "metadata": {}}
{"_id": "mne_mne_utils/check.py_check_fname_doc", "text": "Enforce MNE filename conventions.\n\nParameters\n----------\nfname : path-like\n    Name of the file.\nfiletype : str\n    Type of file. e.g., ICA, Epochs, etc.\nendings : tuple\n    Acceptable endings for the filename.\nendings_err : tuple\n    Obligatory possible endings for the filename.", "metadata": {}}
{"_id": "mne_mne_utils/check.py_check_version_doc", "text": "Check minimum library version required.\n\nParameters\n----------\nlibrary : str\n    The library name to import. Must have a ``__version__`` property.\nmin_version : str\n    The minimum version string. Anything that matches\n    ``'(\\d+ | [a-z]+ | \\.)'``. Can also be empty to skip version\n    check (just check for library presence).\nstrip : bool\n    If True (default), then PEP440 development markers like ``.devN``\n    will be stripped from the version. This makes it so that\n    ``check_version('mne', '1.1')`` will be ``True`` even when on version\n    ``'1.1.dev0'`` (prerelease/dev version). This option is provided for\n    backward compatibility with the behavior of ``LooseVersion``, and\n    diverges from how modern parsing in ``packaging.version.parse`` works.\n\n    .. versionadded:: 1.0\nreturn_version : bool\n    If True (default False), also return the version (can be None if the\n    library is missing).\n\n    .. versionadded:: 1.0\n\nReturns\n-------\nok : bool\n    True if the library exists with at least the specified version.\nversion : str | None\n    The version. Only returned when ``return_version=True``.", "metadata": {}}
{"_id": "mne_mne_utils/check.py_check_random_state_doc", "text": "Turn seed into a numpy.random.mtrand.RandomState instance.\n\nIf seed is None, return the RandomState singleton used by np.random.mtrand.\nIf seed is an int, return a new RandomState instance seeded with seed.\nIf seed is already a RandomState instance, return it.\nOtherwise raise ValueError.", "metadata": {}}
{"_id": "mne_mne_utils/check.py_cast_path_to_str_doc", "text": "Cast all paths value to string in data.", "metadata": {}}
{"_id": "mne_mne_utils/check.py_write_hdf5_doc", "text": "Write h5 and cast all paths to string in data.", "metadata": {}}
{"_id": "mne_mne_utils/config.py_set_cache_dir_doc", "text": "Set the directory to be used for temporary file storage.\n\nThis directory is used by joblib to store memmapped arrays,\nwhich reduces memory requirements and speeds up parallel\ncomputation.\n\nParameters\n----------\ncache_dir : str or None\n    Directory to use for temporary file storage. None disables\n    temporary file storage.", "metadata": {}}
{"_id": "mne_mne_utils/config.py_set_memmap_min_size_doc", "text": "Set the minimum size for memmaping of arrays for parallel processing.\n\nParameters\n----------\nmemmap_min_size : str or None\n    Threshold on the minimum size of arrays that triggers automated memory\n    mapping for parallel processing, e.g., '1M' for 1 megabyte.\n    Use None to disable memmaping of large arrays.", "metadata": {}}
{"_id": "mne_mne_utils/config.py_get_config_path_doc", "text": "Get path to standard mne-python config file.\n\nParameters\n----------\nhome_dir : str | None\n    The folder that contains the .mne config folder.\n    If None, it is found automatically.\n\nReturns\n-------\nconfig_path : str\n    The path to the mne-python configuration file. On windows, this\n    will be '%USERPROFILE%\\.mne\\mne-python.json'. On every other\n    system, this will be ~/.mne/mne-python.json.", "metadata": {}}
{"_id": "mne_mne_utils/config.py_get_config_doc", "text": "Read MNE-Python preferences from environment or config file.\n\nParameters\n----------\nkey : None | str\n    The preference key to look for. The os environment is searched first,\n    then the mne-python config file is parsed.\n    If None, all the config parameters present in environment variables or\n    the path are returned. If key is an empty string, a list of all valid\n    keys (but not values) is returned.\ndefault : str | None\n    Value to return if the key is not found.\nraise_error : bool\n    If True, raise an error if the key is not found (instead of returning\n    default).\nhome_dir : str | None\n    The folder that contains the .mne config folder.\n    If None, it is found automatically.\nuse_env : bool\n    If True, consider env vars, if available.\n    If False, only use MNE-Python configuration file values.\n\n    .. versionadded:: 0.18\n\nReturns\n-------\nvalue : dict | str | None\n    The preference key value.\n\nSee Also\n--------\nset_config", "metadata": {}}
{"_id": "mne_mne_utils/config.py_set_config_doc", "text": "Set a MNE-Python preference key in the config file and environment.\n\nParameters\n----------\nkey : str\n    The preference key to set.\nvalue : str |  None\n    The value to assign to the preference key. If None, the key is\n    deleted.\nhome_dir : str | None\n    The folder that contains the .mne config folder.\n    If None, it is found automatically.\nset_env : bool\n    If True (default), update :data:`os.environ` in addition to\n    updating the MNE-Python config file.\n\nSee Also\n--------\nget_config", "metadata": {}}
{"_id": "mne_mne_utils/config.py_get_subjects_dir_doc", "text": "Safely use subjects_dir input to return SUBJECTS_DIR.\n\nParameters\n----------\nsubjects_dir : path-like | None\n    If a value is provided, return subjects_dir. Otherwise, look for\n    SUBJECTS_DIR config and return the result.\nraise_error : bool\n    If True, raise a KeyError if no value for SUBJECTS_DIR can be found\n    (instead of returning None).\n\nReturns\n-------\nvalue : Path | None\n    The SUBJECTS_DIR value.", "metadata": {}}
{"_id": "mne_mne_utils/config.py_sys_info_doc", "text": "Print system information.\n\nThis function prints system information useful when triaging bugs.\n\nParameters\n----------\nfid : file-like | None\n    The file to write to. Will be passed to :func:`print()`. Can be None to\n    use :data:`sys.stdout`.\nshow_paths : bool\n    If True, print paths for each module.\ndependencies : 'user' | 'developer'\n    Show dependencies relevant for users (default) or for developers\n    (i.e., output includes additional dependencies).\nunicode : bool | \"auto\"\n    Include Unicode symbols in output. If \"auto\", corresponds to True on Linux and\n    macOS, and False on Windows.\n\n    .. versionadded:: 0.24\ncheck_version : bool | float\n    If True (default), attempt to check that the version of MNE-Python is up to date\n    with the latest release on GitHub. Can be a float to give a different timeout\n    (in sec) from the default (2 sec).\n\n    .. versionadded:: 1.6", "metadata": {}}
{"_id": "mne_mne_utils/_testing.py_requires_mne_doc", "text": "Decorate a function as requiring MNE.", "metadata": {}}
{"_id": "mne_mne_utils/_testing.py_requires_mne_mark_doc", "text": "Mark pytest tests that require MNE-C.", "metadata": {}}
{"_id": "mne_mne_utils/_testing.py_requires_openmeeg_mark_doc", "text": "Mark pytest tests that require OpenMEEG.", "metadata": {}}
{"_id": "mne_mne_utils/_testing.py_requires_freesurfer_doc", "text": "Require Freesurfer.", "metadata": {}}
{"_id": "mne_mne_utils/_testing.py_run_command_if_main_doc", "text": "Run a given command if it's __main__.", "metadata": {}}
{"_id": "mne_mne_utils/_testing.py_has_mne_c_doc", "text": "Check for MNE-C.", "metadata": {}}
{"_id": "mne_mne_utils/_testing.py_has_freesurfer_doc", "text": "Check for Freesurfer.", "metadata": {}}
{"_id": "mne_mne_utils/_testing.py_buggy_mkl_svd_doc", "text": "Decorate tests that make calls to SVD and intermittently fail.", "metadata": {}}
{"_id": "mne_mne_utils/_testing.py_assert_and_remove_boundary_annot_doc", "text": "Assert that there are boundary annotations and remove them.", "metadata": {}}
{"_id": "mne_mne_utils/_testing.py_assert_object_equal_doc", "text": "Assert two objects are equal.", "metadata": {}}
{"_id": "mne_mne_utils/_testing.py_assert_meg_snr_doc", "text": "Assert channel SNR of a certain level.\n\nMostly useful for operations like Maxwell filtering that modify\nMEG channels while leaving EEG and others intact.", "metadata": {}}
{"_id": "mne_mne_utils/_testing.py_assert_snr_doc", "text": "Assert actual and desired arrays are within some SNR tolerance.", "metadata": {}}
{"_id": "mne_mne_utils/_testing.py_assert_stcs_equal_doc", "text": "Check that two STC are equal.", "metadata": {}}
{"_id": "mne_mne_utils/_testing.py_assert_dig_allclose_doc", "text": "Assert dig allclose.", "metadata": {}}
{"_id": "mne_mne_utils/docs.py_fill_doc_doc", "text": "Fill a docstring with docdict entries.\n\nParameters\n----------\nf : callable\n    The function to fill the docstring of. Will be modified in place.\n\nReturns\n-------\nf : callable\n    The function, potentially with an updated ``__doc__``.", "metadata": {}}
{"_id": "mne_mne_utils/docs.py_copy_doc_doc", "text": "Copy the docstring from another function (decorator).\n\nThe docstring of the source function is prepepended to the docstring of the\nfunction wrapped by this decorator.\n\nThis is useful when inheriting from a class and overloading a method. This\ndecorator can be used to copy the docstring of the original method.\n\nDocstrings are processed by :func:`python:inspect.cleandoc` before being used.\n\nParameters\n----------\nsource : function\n    Function to copy the docstring from.\n\nReturns\n-------\nwrapper : function\n    The decorated function.\n\nExamples\n--------\n>>> class A:\n...     def m1():\n...         '''Docstring for m1'''\n...         pass\n>>> class B (A):\n...     @copy_doc(A.m1)\n...     def m1():\n...         ''' this gets appended'''\n...         pass\n>>> print(B.m1.__doc__)\nDocstring for m1\nthis gets appended", "metadata": {}}
{"_id": "mne_mne_utils/docs.py_copy_function_doc_to_method_doc_doc", "text": "Use the docstring from a function as docstring for a method.\n\nThe docstring of the source function is prepepended to the docstring of the\nfunction wrapped by this decorator. Additionally, the first parameter\nspecified in the docstring of the source function is removed in the new\ndocstring.\n\nThis decorator is useful when implementing a method that just calls a\nfunction.  This pattern is prevalent in for example the plotting functions\nof MNE.\n\nDocstrings are parsed by :func:`python:inspect.cleandoc` before being used.\nIf indentation and newlines are important, make the first line ``.``, and the dot\nwill be removed and all following lines dedented jointly.\n\nParameters\n----------\nsource : function\n    Function to copy the docstring from.\n\nReturns\n-------\nwrapper : function\n    The decorated method.\n\nNotes\n-----\nThe parsing performed is very basic and will break easily on docstrings\nthat are not formatted exactly according to the ``numpydoc`` standard.\nAlways inspect the resulting docstring when using this decorator.\n\nExamples\n--------\n>>> def plot_function(object, a, b):\n...     '''Docstring for plotting function.\n...\n...     Parameters\n...     ----------\n...     object : instance of object\n...         The object to plot\n...     a : int\n...         Some parameter\n...     b : int\n...         Some parameter\n...     '''\n...     pass\n...\n>>> class A:\n...     @copy_function_doc_to_method_doc(plot_function)\n...     def plot(self, a, b):\n...         '''.\n...\n...         Notes\n...         -----\n...         .. versionadded:: 0.13.0\n...         '''\n...         plot_function(self, a, b)\n>>> print(A.plot.__doc__)\nDocstring for plotting function.\n<BLANKLINE>\nParameters\n----------\na : int\n    Some parameter\nb : int\n    Some parameter\n<BLANKLINE>\nNotes\n-----\n.. versionadded:: 0.13.0", "metadata": {}}
{"_id": "mne_mne_utils/docs.py_linkcode_resolve_doc", "text": "Determine the URL corresponding to a Python object.\n\nParameters\n----------\ndomain : str\n    Only useful when 'py'.\ninfo : dict\n    With keys \"module\" and \"fullname\".\n\nReturns\n-------\nurl : str\n    The code URL.\n\nNotes\n-----\nThis has been adapted to deal with our \"verbose\" decorator.\n\nAdapted from SciPy (doc/source/conf.py).", "metadata": {}}
{"_id": "mne_mne_utils/docs.py_open_docs_doc", "text": "Launch a new web browser tab with the MNE documentation.\n\nParameters\n----------\nkind : str | None\n    Can be \"api\" (default), \"tutorials\", or \"examples\".\n    The default can be changed by setting the configuration value\n    MNE_DOCS_KIND.\nversion : str | None\n    Can be \"stable\" (default) or \"dev\".\n    The default can be changed by setting the configuration value\n    MNE_DOCS_VERSION.", "metadata": {}}
{"_id": "mne_mne_utils/docs.py_deprecated_alias_doc", "text": "Inject a deprecated alias into the namespace.", "metadata": {}}
{"_id": "mne_mne_beamformer/resolution_matrix.py_make_lcmv_resolution_matrix_doc", "text": "Compute resolution matrix for LCMV beamformer.\n\nParameters\n----------\nfilters : instance of Beamformer\n     Dictionary containing filter weights from LCMV beamformer\n     (see mne.beamformer.make_lcmv).\nforward : instance of Forward\n    Forward Solution with leadfield matrix.\n%(info_not_none)s Used to compute LCMV filters.\n\nReturns\n-------\nresmat : array, shape (n_dipoles_lcmv, n_dipoles_fwd)\n    Resolution matrix (filter matrix multiplied to leadfield from\n    forward solution). Numbers of rows (n_dipoles_lcmv) and columns\n    (n_dipoles_fwd) may differ by a factor depending on orientation\n    constraints of filter and forward solution, respectively (e.g. factor 3\n    for free dipole orientation versus factor 1 for scalar beamformers).", "metadata": {}}
{"_id": "mne_mne_beamformer/_compute_beamformer.py_read_beamformer_doc", "text": "Read a beamformer filter.\n\nParameters\n----------\nfname : path-like\n    The filename of the HDF5 file.\n\nReturns\n-------\nfilter : instance of Beamformer\n    The beamformer filter.", "metadata": {}}
{"_id": "mne_mne_beamformer/_compute_beamformer.py_copy_doc", "text": "Copy the beamformer.\n\nReturns\n-------\nbeamformer : instance of Beamformer\n    A deep copy of the beamformer.", "metadata": {}}
{"_id": "mne_mne_beamformer/_compute_beamformer.py_save_doc", "text": "Save the beamformer filter.\n\nParameters\n----------\nfname : path-like\n    The filename to use to write the HDF5 data.\n    Should end in ``'-lcmv.h5'`` or ``'-dics.h5'``.\n%(overwrite)s\n%(verbose)s", "metadata": {}}
{"_id": "mne_mne_beamformer/_dics.py_make_dics_doc", "text": "Compute a Dynamic Imaging of Coherent Sources (DICS) spatial filter.\n\nThis is a beamformer filter that can be used to estimate the source power\nat a specific frequency range :footcite:`GrossEtAl2001`. It does this by\nconstructing a spatial filter for each source point.\nThe computation of these filters is very similar to those of the LCMV\nbeamformer (:func:`make_lcmv`), but instead of operating on a covariance\nmatrix, the CSD matrix is used. When applying these filters to a CSD matrix\n(see :func:`apply_dics_csd`), the source power can be estimated for each\nsource point.\n\nParameters\n----------\n%(info_not_none)s\nforward : instance of Forward\n    Forward operator.\ncsd : instance of CrossSpectralDensity\n    The data cross-spectral density (CSD) matrices. A source estimate is\n    performed for each frequency or frequency-bin defined in the CSD\n    object.\nreg : float\n    The regularization to apply to the cross-spectral density before\n    computing the inverse.\nnoise_csd : instance of CrossSpectralDensity | None\n    Noise cross-spectral density (CSD) matrices. If provided, whitening\n    will be done. The noise CSDs need to have been computed for the same\n    frequencies as the data CSDs. Providing noise CSDs is mandatory if you\n    mix sensor types, e.g. gradiometers with magnetometers or EEG with\n    MEG.\n\n    .. versionadded:: 0.20\nlabel : Label | None\n    Restricts the solution to a given label.\n%(pick_ori_bf)s\n%(rank_none)s\n\n    .. versionadded:: 0.17\n%(weight_norm)s\n\n    Defaults to ``None``, in which case no normalization is performed.\n%(reduce_rank)s\n%(depth)s\nreal_filter : bool\n    If ``True``, take only the real part of the cross-spectral-density\n    matrices to compute real filters.\n\n    .. versionchanged:: 0.23\n        Version 0.23 an earlier used ``real_filter=False`` as the default,\n        as of version 0.24 ``True`` is the default.\n%(inversion_bf)s\n\n    .. versionchanged:: 0.21\n       Default changed to ``'matrix'``.\n%(verbose)s\n\nReturns\n-------\nfilters : instance of Beamformer\n    Dictionary containing filter weights from DICS beamformer.\n    Contains the following keys:\n\n        'kind' : str\n            The type of beamformer, in this case 'DICS'.\n        'weights' : ndarray, shape (n_frequencies, n_weights)\n            For each frequency, the filter weights of the beamformer.\n        'csd' : instance of CrossSpectralDensity\n            The data cross-spectral density matrices used to compute the\n            beamformer.\n        'ch_names' : list of str\n            Channels used to compute the beamformer.\n        'proj' : ndarray, shape (n_channels, n_channels)\n            Projections used to compute the beamformer.\n        'vertices' : list of ndarray\n            Vertices for which the filter weights were computed.\n        'n_sources' : int\n            Number of source location for which the filter weight were\n            computed.\n        'subject' : str\n            The subject ID.\n        'pick-ori' : None | 'max-power' | 'normal' | 'vector'\n            The orientation in which the beamformer filters were computed.\n        'inversion' : 'single' | 'matrix'\n            Whether the spatial filters were computed for each dipole\n            separately or jointly for all dipoles at each vertex using a\n            matrix inversion.\n        'weight_norm' : None | 'unit-noise-gain'\n            The normalization of the weights.\n        'src_type' : str\n            Type of source space.\n        'source_nn' : ndarray, shape (n_sources, 3)\n            For each source location, the surface normal.\n        'is_free_ori' : bool\n            Whether the filter was computed in a fixed direction\n            (pick_ori='max-power', pick_ori='normal') or not.\n        'whitener' : None | ndarray, shape (n_channels, n_channels)\n            Whitening matrix, provided if whitening was applied to the\n            covariance matrix and leadfield during computation of the\n            beamformer weights.\n        'max-power-ori' : ndarray, shape (n_sources, 3) | None\n            When pick_ori='max-power', this fields contains the estimated\n            direction of maximum power at each source location.\n\nSee Also\n--------\napply_dics_csd\n\nNotes\n-----\nThe original reference is :footcite:`GrossEtAl2001`. See\n:footcite:`vanVlietEtAl2018` for a tutorial style paper on the topic.\n\nThe DICS beamformer is very similar to the LCMV (:func:`make_lcmv`)\nbeamformer and many of the parameters are shared. However,\n:func:`make_dics` and :func:`make_lcmv` currently have different defaults\nfor these parameters, which were settled on separately through extensive\npractical use case testing (but not necessarily exhaustive parameter space\nsearching), and it remains to be seen how functionally interchangeable they\ncould be.\n\nThe default setting reproduce the DICS beamformer as described in\n:footcite:`vanVlietEtAl2018`::\n\n    inversion='single', weight_norm=None, depth=1.\n\nTo use the :func:`make_lcmv` defaults, use::\n\n    inversion='matrix', weight_norm='unit-noise-gain-invariant', depth=None\n\nFor more information about ``real_filter``, see the\nsupplemental information from :footcite:`HippEtAl2011`.\n\nReferences\n----------\n.. footbibliography::", "metadata": {}}
{"_id": "mne_mne_beamformer/_dics.py_apply_dics_doc", "text": "Apply Dynamic Imaging of Coherent Sources (DICS) beamformer weights.\n\nApply Dynamic Imaging of Coherent Sources (DICS) beamformer weights\non evoked data.\n\n.. warning:: The result of this function is meant as an intermediate step\n             for further processing (such as computing connectivity). If\n             you are interested in estimating source time courses, use an\n             LCMV beamformer (:func:`make_lcmv`, :func:`apply_lcmv`)\n             instead. If you are interested in estimating spectral power at\n             the source level, use :func:`apply_dics_csd`.\n.. warning:: This implementation has not been heavily tested so please\n             report any issues or suggestions.\n\nParameters\n----------\nevoked : Evoked\n    Evoked data to apply the DICS beamformer weights to.\nfilters : instance of Beamformer\n    DICS spatial filter (beamformer weights)\n    Filter weights returned from :func:`make_dics`.\n%(verbose)s\n\nReturns\n-------\nstc : SourceEstimate | VolSourceEstimate | list\n    Source time courses. If the DICS beamformer has been computed for more\n    than one frequency, a list is returned containing for each frequency\n    the corresponding time courses.\n\nSee Also\n--------\napply_dics_epochs\napply_dics_tfr_epochs\napply_dics_csd", "metadata": {}}
{"_id": "mne_mne_beamformer/_dics.py_apply_dics_epochs_doc", "text": "Apply Dynamic Imaging of Coherent Sources (DICS) beamformer weights.\n\nApply Dynamic Imaging of Coherent Sources (DICS) beamformer weights\non single trial data.\n\n.. warning:: The result of this function is meant as an intermediate step\n             for further processing (such as computing connectivity). If\n             you are interested in estimating source time courses, use an\n             LCMV beamformer (:func:`make_lcmv`, :func:`apply_lcmv`)\n             instead. If you are interested in estimating spectral power at\n             the source level, use :func:`apply_dics_csd`.\n.. warning:: This implementation has not been heavily tested so please\n             report any issue or suggestions.\n\nParameters\n----------\nepochs : Epochs\n    Single trial epochs.\nfilters : instance of Beamformer\n    DICS spatial filter (beamformer weights)\n    Filter weights returned from :func:`make_dics`. The DICS filters must\n    have been computed for a single frequency only.\nreturn_generator : bool\n    Return a generator object instead of a list. This allows iterating\n    over the stcs without having to keep them all in memory.\n%(verbose)s\n\nReturns\n-------\nstc: list | generator of (SourceEstimate | VolSourceEstimate)\n    The source estimates for all epochs.\n\nSee Also\n--------\napply_dics\napply_dics_tfr_epochs\napply_dics_csd", "metadata": {}}
{"_id": "mne_mne_beamformer/_dics.py_apply_dics_tfr_epochs_doc", "text": "Apply Dynamic Imaging of Coherent Sources (DICS) beamformer weights.\n\nApply Dynamic Imaging of Coherent Sources (DICS) beamformer weights\non single trial time-frequency data.\n\nParameters\n----------\nepochs_tfr : EpochsTFR\n    Single trial time-frequency epochs.\nfilters : instance of Beamformer\n    DICS spatial filter (beamformer weights)\n    Filter weights returned from :func:`make_dics`.\nreturn_generator : bool\n    Return a generator object instead of a list. This allows iterating\n    over the stcs without having to keep them all in memory.\n%(verbose)s\n\nReturns\n-------\nstcs : list of list of (SourceEstimate | VectorSourceEstimate | VolSourceEstimate)\n    The source estimates for all epochs (outside list) and for\n    all frequencies (inside list).\n\nSee Also\n--------\napply_dics\napply_dics_epochs\napply_dics_csd", "metadata": {}}
{"_id": "mne_mne_beamformer/_dics.py_apply_dics_csd_doc", "text": "Apply Dynamic Imaging of Coherent Sources (DICS) beamformer weights.\n\nApply a previously computed DICS beamformer to a cross-spectral density\n(CSD) object to estimate source power in time and frequency windows\nspecified in the CSD object :footcite:`GrossEtAl2001`.\n\n.. note:: Only power can computed from the cross-spectral density, not\n          complex phase-amplitude, so vector DICS filters will be\n          converted to scalar source estimates since power is strictly\n          positive and so 3D directions cannot be combined meaningfully\n          (the direction would be confined to the positive quadrant).\n\nParameters\n----------\ncsd : instance of CrossSpectralDensity\n    The data cross-spectral density (CSD) matrices. A source estimate is\n    performed for each frequency or frequency-bin defined in the CSD\n    object.\nfilters : instance of Beamformer\n    DICS spatial filter (beamformer weights)\n    Filter weights returned from `make_dics`.\n%(verbose)s\n\nReturns\n-------\nstc : SourceEstimate\n    Source power with frequency instead of time.\nfrequencies : list of float\n    The frequencies for which the source power has been computed. If the\n    data CSD object defines frequency-bins instead of exact frequencies,\n    the mean of each bin is returned.\n\nSee Also\n--------\napply_dics\napply_dics_epochs\napply_dics_tfr_epochs\n\nReferences\n----------\n.. footbibliography::", "metadata": {}}
{"_id": "mne_mne_beamformer/_rap_music.py_rap_music_doc", "text": "RAP-MUSIC source localization method.\n\nCompute Recursively Applied and Projected MUltiple SIgnal Classification\n(RAP-MUSIC) :footcite:`MosherLeahy1999,MosherLeahy1996` on evoked data.\n\n.. note:: The goodness of fit (GOF) of all the returned dipoles is the\n          same and corresponds to the GOF of the full set of dipoles.\n\nParameters\n----------\nevoked : instance of Evoked\n    Evoked data to localize.\nforward : instance of Forward\n    Forward operator.\nnoise_cov : instance of Covariance\n    The noise covariance.\nn_dipoles : int\n    The number of dipoles to look for. The default value is 5.\nreturn_residual : bool\n    If True, the residual is returned as an Evoked instance.\n%(verbose)s\n\nReturns\n-------\ndipoles : list of instance of Dipole\n    The dipole fits.\nresidual : instance of Evoked\n    The residual a.k.a. data not explained by the dipoles.\n    Only returned if return_residual is True.\n\nSee Also\n--------\nmne.fit_dipole\nmne.beamformer.trap_music\n\nNotes\n-----\n.. versionadded:: 0.9.0\n\nReferences\n----------\n.. footbibliography::", "metadata": {}}
{"_id": "mne_mne_beamformer/_rap_music.py_trap_music_doc", "text": "TRAP-MUSIC source localization method.\n\nCompute Truncated Recursively Applied and Projected MUltiple SIgnal Classification\n(TRAP-MUSIC) :footcite:`Makela2018` on evoked data.\n\n.. note:: The goodness of fit (GOF) of all the returned dipoles is the\n          same and corresponds to the GOF of the full set of dipoles.\n\nParameters\n----------\nevoked : instance of Evoked\n    Evoked data to localize.\nforward : instance of Forward\n    Forward operator.\nnoise_cov : instance of Covariance\n    The noise covariance.\nn_dipoles : int\n    The number of dipoles to look for. The default value is 5.\nreturn_residual : bool\n    If True, the residual is returned as an Evoked instance.\n%(verbose)s\n\nReturns\n-------\ndipoles : list of instance of Dipole\n    The dipole fits.\nresidual : instance of Evoked\n    The residual a.k.a. data not explained by the dipoles.\n    Only returned if return_residual is True.\n\nSee Also\n--------\nmne.fit_dipole\nmne.beamformer.rap_music\n\nNotes\n-----\n.. versionadded:: 1.4\n\nReferences\n----------\n.. footbibliography::", "metadata": {}}
{"_id": "mne_mne_beamformer/_lcmv.py_make_lcmv_doc", "text": "Compute LCMV spatial filter.\n\nParameters\n----------\n%(info_not_none)s\n    Specifies the channels to include. Bad channels (in ``info['bads']``)\n    are not used.\nforward : instance of Forward\n    Forward operator.\ndata_cov : instance of Covariance\n    The data covariance.\nreg : float\n    The regularization for the whitened data covariance.\nnoise_cov : instance of Covariance\n    The noise covariance. If provided, whitening will be done. Providing a\n    noise covariance is mandatory if you mix sensor types, e.g.\n    gradiometers with magnetometers or EEG with MEG.\n\n    .. note::\n        If ``noise_cov`` is ``None`` and ``weight_norm='unit-noise-gain'``,\n        the unit noise is assumed to be 1 in SI units, e.g., 1 T for\n        magnetometers, 1 V for EEG, so resulting amplitudes will be tiny.\n        Consider using :func:`mne.make_ad_hoc_cov` to provide a\n        ``noise_cov`` to set noise values that are more reasonable for\n        neural data or using ``weight_norm='nai'`` for weight-normalized\n        beamformer output that is scaled by a noise estimate.\nlabel : instance of Label\n    Restricts the LCMV solution to a given label.\n%(pick_ori_bf)s\n\n    - ``'vector'``\n        Keeps the currents for each direction separate\n%(rank_info)s\n%(weight_norm)s\n\n    Defaults to ``'unit-noise-gain-invariant'``.\n%(reduce_rank)s\n%(depth)s\n\n    .. versionadded:: 0.18\n%(inversion_bf)s\n\n    .. versionadded:: 0.21\n%(verbose)s\n\nReturns\n-------\nfilters : instance of Beamformer\n    Dictionary containing filter weights from LCMV beamformer.\n    Contains the following keys:\n\n        'kind' : str\n            The type of beamformer, in this case 'LCMV'.\n        'weights' : array\n            The filter weights of the beamformer.\n        'data_cov' : instance of Covariance\n            The data covariance matrix used to compute the beamformer.\n        'noise_cov' : instance of Covariance | None\n            The noise covariance matrix used to compute the beamformer.\n        'whitener' : None | ndarray, shape (n_channels, n_channels)\n            Whitening matrix, provided if whitening was applied to the\n            covariance matrix and leadfield during computation of the\n            beamformer weights.\n        'weight_norm' : str | None\n            Type of weight normalization used to compute the filter\n            weights.\n        'pick-ori' : None | 'max-power' | 'normal' | 'vector'\n            The orientation in which the beamformer filters were computed.\n        'ch_names' : list of str\n            Channels used to compute the beamformer.\n        'proj' : array\n            Projections used to compute the beamformer.\n        'is_ssp' : bool\n            If True, projections were applied prior to filter computation.\n        'vertices' : list\n            Vertices for which the filter weights were computed.\n        'is_free_ori' : bool\n            If True, the filter was computed with free source orientation.\n        'n_sources' : int\n            Number of source location for which the filter weight were\n            computed.\n        'src_type' : str\n            Type of source space.\n        'source_nn' : ndarray, shape (n_sources, 3)\n            For each source location, the surface normal.\n        'proj' : ndarray, shape (n_channels, n_channels)\n            Projections used to compute the beamformer.\n        'subject' : str\n            The subject ID.\n        'rank' : int\n            The rank of the data covariance matrix used to compute the\n            beamformer weights.\n        'max-power-ori' : ndarray, shape (n_sources, 3) | None\n            When pick_ori='max-power', this fields contains the estimated\n            direction of maximum power at each source location.\n        'inversion' : 'single' | 'matrix'\n            Whether the spatial filters were computed for each dipole\n            separately or jointly for all dipoles at each vertex using a\n            matrix inversion.\n\nNotes\n-----\nThe original reference is :footcite:`VanVeenEtAl1997`.\n\nTo obtain the Sekihara unit-noise-gain vector beamformer, you should use\n``weight_norm='unit-noise-gain', pick_ori='vector'`` followed by\n:meth:`vec_stc.project('pca', src) <mne.VectorSourceEstimate.project>`.\n\n.. versionchanged:: 0.21\n   The computations were extensively reworked, and the default for\n   ``weight_norm`` was set to ``'unit-noise-gain-invariant'``.\n\nReferences\n----------\n.. footbibliography::", "metadata": {}}
{"_id": "mne_mne_beamformer/_lcmv.py_apply_lcmv_doc", "text": "Apply Linearly Constrained Minimum Variance (LCMV) beamformer weights.\n\nApply Linearly Constrained Minimum Variance (LCMV) beamformer weights\non evoked data.\n\nParameters\n----------\nevoked : Evoked\n    Evoked data to invert.\nfilters : instance of Beamformer\n    LCMV spatial filter (beamformer weights).\n    Filter weights returned from :func:`make_lcmv`.\n%(verbose)s\n\nReturns\n-------\nstc : SourceEstimate | VolSourceEstimate | VectorSourceEstimate\n    Source time courses.\n\nSee Also\n--------\nmake_lcmv, apply_lcmv_raw, apply_lcmv_epochs, apply_lcmv_cov\n\nNotes\n-----\n.. versionadded:: 0.18", "metadata": {}}
{"_id": "mne_mne_beamformer/_lcmv.py_apply_lcmv_epochs_doc", "text": "Apply Linearly Constrained Minimum Variance (LCMV) beamformer weights.\n\nApply Linearly Constrained Minimum Variance (LCMV) beamformer weights\non single trial data.\n\nParameters\n----------\nepochs : Epochs\n    Single trial epochs.\nfilters : instance of Beamformer\n    LCMV spatial filter (beamformer weights)\n    Filter weights returned from :func:`make_lcmv`.\nreturn_generator : bool\n     Return a generator object instead of a list. This allows iterating\n     over the stcs without having to keep them all in memory.\n%(verbose)s\n\nReturns\n-------\nstc: list | generator of (SourceEstimate | VolSourceEstimate)\n    The source estimates for all epochs.\n\nSee Also\n--------\nmake_lcmv, apply_lcmv_raw, apply_lcmv, apply_lcmv_cov", "metadata": {}}
{"_id": "mne_mne_beamformer/_lcmv.py_apply_lcmv_raw_doc", "text": "Apply Linearly Constrained Minimum Variance (LCMV) beamformer weights.\n\nApply Linearly Constrained Minimum Variance (LCMV) beamformer weights\non raw data.\n\nParameters\n----------\nraw : mne.io.Raw\n    Raw data to invert.\nfilters : instance of Beamformer\n    LCMV spatial filter (beamformer weights).\n    Filter weights returned from :func:`make_lcmv`.\nstart : int\n    Index of first time sample (index not time is seconds).\nstop : int\n    Index of first time sample not to include (index not time is seconds).\n%(verbose)s\n\nReturns\n-------\nstc : SourceEstimate | VolSourceEstimate\n    Source time courses.\n\nSee Also\n--------\nmake_lcmv, apply_lcmv_epochs, apply_lcmv, apply_lcmv_cov", "metadata": {}}
{"_id": "mne_mne_beamformer/_lcmv.py_apply_lcmv_cov_doc", "text": "Apply Linearly Constrained  Minimum Variance (LCMV) beamformer weights.\n\nApply Linearly Constrained Minimum Variance (LCMV) beamformer weights\nto a data covariance matrix to estimate source power.\n\nParameters\n----------\ndata_cov : instance of Covariance\n    Data covariance matrix.\nfilters : instance of Beamformer\n    LCMV spatial filter (beamformer weights).\n    Filter weights returned from :func:`make_lcmv`.\n%(verbose)s\n\nReturns\n-------\nstc : SourceEstimate | VolSourceEstimate\n    Source power.\n\nSee Also\n--------\nmake_lcmv, apply_lcmv, apply_lcmv_epochs, apply_lcmv_raw", "metadata": {}}
{"_id": "mne_mne__fiff/meas_info.py_read_fiducials_doc", "text": "Read fiducials from a fiff file.\n\nParameters\n----------\nfname : path-like\n    The filename to read.\n%(verbose)s\n\nReturns\n-------\npts : list of dict\n    List of digitizer points (each point in a dict).\ncoord_frame : int\n    The coordinate frame of the points (one of\n    ``mne.io.constants.FIFF.FIFFV_COORD_...``).", "metadata": {}}
{"_id": "mne_mne__fiff/meas_info.py_write_fiducials_doc", "text": "Write fiducials to a fiff file.\n\nParameters\n----------\nfname : path-like\n    Destination file name.\npts : iterator of dict\n    Iterator through digitizer points. Each point is a dictionary with\n    the keys 'kind', 'ident' and 'r'.\ncoord_frame : str | int\n    The coordinate frame of the points. If a string, must be one of\n    ``'meg'``, ``'mri'``, ``'mri_voxel'``, ``'head'``,\n    ``'mri_tal'``, ``'ras'``, ``'fs_tal'``, ``'ctf_head'``,\n    ``'ctf_meg'``, and ``'unknown'``\n    If an integer, must be one of the constants defined as\n    ``mne.io.constants.FIFF.FIFFV_COORD_...``.\n%(overwrite)s\n\n    .. versionadded:: 1.0\n%(verbose)s", "metadata": {}}
{"_id": "mne_mne__fiff/meas_info.py_read_info_doc", "text": "Read measurement info from a file.\n\nParameters\n----------\nfname : path-like\n    File name.\n%(verbose)s\n\nReturns\n-------\n%(info_not_none)s", "metadata": {}}
{"_id": "mne_mne__fiff/meas_info.py_read_bad_channels_doc", "text": "Read bad channels.\n\nParameters\n----------\nfid : file\n    The file descriptor.\nnode : dict\n    The node of the FIF tree that contains info on the bad channels.\n\nReturns\n-------\nbads : list\n    A list of bad channel's names.", "metadata": {}}
{"_id": "mne_mne__fiff/meas_info.py_read_meas_info_doc", "text": "Read the measurement info.\n\nParameters\n----------\nfid : file\n    Open file descriptor.\ntree : tree\n    FIF tree structure.\nclean_bads : bool\n    If True, clean info['bads'] before running consistency check.\n    Should only be needed for old files where we did not check bads\n    before saving.\n%(verbose)s\n\nReturns\n-------\n%(info_not_none)s\nmeas : dict\n    Node in tree that contains the info.", "metadata": {}}
{"_id": "mne_mne__fiff/meas_info.py_write_meas_info_doc", "text": "Write measurement info into a file id (from a fif file).\n\nParameters\n----------\nfid : file\n    Open file descriptor.\n%(info_not_none)s\ndata_type : int\n    The data_type in case it is necessary. Should be 4 (FIFFT_FLOAT),\n    5 (FIFFT_DOUBLE), or 16 (FIFFT_DAU_PACK16) for\n    raw data.\nreset_range : bool\n    If True, info['chs'][k]['range'] will be set to unity.\n\nNotes\n-----\nTags are written in a particular order for compatibility with maxfilter.", "metadata": {}}
{"_id": "mne_mne__fiff/meas_info.py_write_info_doc", "text": "Write measurement info in fif file.\n\nParameters\n----------\nfname : path-like\n    The name of the file. Should end by ``-info.fif``.\n%(info_not_none)s\ndata_type : int\n    The data_type in case it is necessary. Should be 4 (FIFFT_FLOAT),\n    5 (FIFFT_DOUBLE), or 16 (FIFFT_DAU_PACK16) for\n    raw data.\nreset_range : bool\n    If True, info['chs'][k]['range'] will be set to unity.\n%(overwrite)s\n%(verbose)s", "metadata": {}}
{"_id": "mne_mne__fiff/meas_info.py_create_info_doc", "text": "Create a basic Info instance suitable for use with create_raw.\n\nParameters\n----------\nch_names : list of str | int\n    Channel names. If an int, a list of channel names will be created\n    from ``range(ch_names)``.\nsfreq : float\n    Sample rate of the data.\nch_types : list of str | str\n    Channel types, default is ``'misc'`` which is a\n    :term:`non-data channel <non-data channels>`.\n    Currently supported fields are 'bio', 'chpi', 'csd', 'dbs', 'dipole',\n    'ecg', 'ecog', 'eeg', 'emg', 'eog', 'exci', 'eyegaze',\n    'fnirs_cw_amplitude', 'fnirs_fd_ac_amplitude', 'fnirs_fd_phase',\n    'fnirs_od', 'gof', 'gsr', 'hbo', 'hbr', 'ias', 'misc', 'pupil',\n    'ref_meg', 'resp', 'seeg', 'stim', 'syst', 'temperature' (see also\n    :term:`sensor types`).\n    If str, then all channels are assumed to be of the same type.\n%(verbose)s\n\nReturns\n-------\n%(info_not_none)s\n\nNotes\n-----\nThe info dictionary will be sparsely populated to enable functionality\nwithin the rest of the package. Advanced functionality such as source\nlocalization can only be obtained through substantial, proper\nmodifications of the info structure (not recommended).\n\nNote that the MEG device-to-head transform ``info['dev_head_t']`` will\nbe initialized to the identity transform.\n\nProper units of measure:\n\n* V: eeg, eog, seeg, dbs, emg, ecg, bio, ecog, resp, fnirs_fd_ac_amplitude,\n  fnirs_cw_amplitude, fnirs_od\n* T: mag, chpi, ref_meg\n* T/m: grad\n* M: hbo, hbr\n* rad: fnirs_fd_phase\n* Am: dipole\n* S: gsr\n* C: temperature\n* V/m\u00b2: csd\n* GOF: gof\n* AU: misc, stim, eyegaze, pupil", "metadata": {}}
{"_id": "mne_mne__fiff/meas_info.py_anonymize_info_doc", "text": "Anonymize measurement information in place.\n\n.. warning:: If ``info`` is part of an object like\n             :class:`raw.info <mne.io.Raw>`, you should directly use\n             the method :meth:`raw.anonymize() <mne.io.Raw.anonymize>`\n             to ensure that all parts of the data are anonymized and\n             stay synchronized (e.g.,\n             :class:`raw.annotations <mne.Annotations>`).\n\nParameters\n----------\n%(info_not_none)s\n%(daysback_anonymize_info)s\n%(keep_his_anonymize_info)s\n%(verbose)s\n\nReturns\n-------\ninfo : instance of Info\n    The anonymized measurement information.\n\nNotes\n-----\n%(anonymize_info_notes)s", "metadata": {}}
{"_id": "mne_mne__fiff/meas_info.py_get_montage_doc", "text": "Get a DigMontage from instance.\n\nReturns\n-------\nmontage : None | DigMontage\n    A copy of the channel positions, if available, otherwise ``None``.", "metadata": {}}
{"_id": "mne_mne__fiff/meas_info.py_set_montage_doc", "text": "Set %(montage_types)s channel positions and digitization points.\n\nParameters\n----------\n%(montage)s\n%(match_case)s\n%(match_alias)s\n%(on_missing_montage)s\n%(verbose)s\n\nReturns\n-------\ninst : instance of Raw | Epochs | Evoked\n    The instance, modified in-place.\n\nSee Also\n--------\nmne.channels.make_standard_montage\nmne.channels.make_dig_montage\nmne.channels.read_custom_montage\n\nNotes\n-----\n.. warning::\n    Only %(montage_types)s channels can have their positions set using\n    a montage. Other channel types (e.g., MEG channels) should have\n    their positions defined properly using their data reading\n    functions.\n.. warning::\n    Applying a montage will only set locations of channels that exist\n    at the time it is applied. This means when\n    :ref:`re-referencing <tut-set-eeg-ref>`\n    make sure to apply the montage only after calling\n    :func:`mne.add_reference_channels`", "metadata": {}}
{"_id": "mne_mne__fiff/meas_info.py_set_channel_types_doc", "text": "Specify the sensor types of channels.\n\nParameters\n----------\nmapping : dict\n    A dictionary mapping channel names to sensor types, e.g.,\n    ``{'EEG061': 'eog'}``.\non_unit_change : ``'raise'`` | ``'warn'`` | ``'ignore'``\n    What to do if the measurement unit of a channel is changed\n    automatically to match the new sensor type.\n\n    .. versionadded:: 1.4\n%(verbose)s\n\nReturns\n-------\ninst : instance of Raw | Epochs | Evoked\n    The instance (modified in place).\n\n    .. versionchanged:: 0.20\n       Return the instance.\n\nNotes\n-----\nThe following :term:`sensor types` are accepted:\n\n    bio, chpi, csd, dbs, dipole, ecg, ecog, eeg, emg, eog, exci,\n    eyegaze, fnirs_cw_amplitude, fnirs_fd_ac_amplitude, fnirs_fd_phase,\n    fnirs_od, gof, gsr, hbo, hbr, ias, misc, pupil, ref_meg, resp,\n    seeg, stim, syst, temperature.\n\nWhen working with eye-tracking data, see\n:func:`mne.preprocessing.eyetracking.set_channel_types_eyetrack`.\n\n.. versionadded:: 0.9.0", "metadata": {}}
{"_id": "mne_mne__fiff/meas_info.py_rename_channels_doc", "text": "Rename channels.\n\nParameters\n----------\n%(mapping_rename_channels_duplicates)s\n%(verbose)s\n\nReturns\n-------\ninst : instance of Raw | Epochs | Evoked\n    The instance (modified in place).\n\n    .. versionchanged:: 0.20\n       Return the instance.\n\nNotes\n-----\n.. versionadded:: 0.9.0", "metadata": {}}
{"_id": "mne_mne__fiff/meas_info.py_plot_sensors_doc", "text": "Plot sensor positions.\n\nParameters\n----------\nkind : str\n    Whether to plot the sensors as 3d, topomap or as an interactive\n    sensor selection dialog. Available options 'topomap', '3d',\n    'select'. If 'select', a set of channels can be selected\n    interactively by using lasso selector or clicking while holding\n    control key. The selected channels are returned along with the\n    figure instance. Defaults to 'topomap'.\nch_type : None | str\n    The channel type to plot. Available options ``'mag'``, ``'grad'``,\n    ``'eeg'``, ``'seeg'``, ``'dbs'``, ``'ecog'``, ``'all'``. If ``'all'``, all\n    the available mag, grad, eeg, seeg, dbs, and ecog channels are plotted. If\n    None (default), then channels are chosen in the order given above.\ntitle : str | None\n    Title for the figure. If None (default), equals to ``'Sensor\n    positions (%%s)' %% ch_type``.\nshow_names : bool | array of str\n    Whether to display all channel names. If an array, only the channel\n    names in the array are shown. Defaults to False.\nch_groups : 'position' | array of shape (n_ch_groups, n_picks) | None\n    Channel groups for coloring the sensors. If None (default), default\n    coloring scheme is used. If 'position', the sensors are divided\n    into 8 regions. See ``order`` kwarg of :func:`mne.viz.plot_raw`. If\n    array, the channels are divided by picks given in the array.\n\n    .. versionadded:: 0.13.0\nto_sphere : bool\n    Whether to project the 3d locations to a sphere. When False, the\n    sensor array appears similar as to looking downwards straight above\n    the subject's head. Has no effect when kind='3d'. Defaults to True.\n\n    .. versionadded:: 0.14.0\naxes : instance of Axes | instance of Axes3D | None\n    Axes to draw the sensors to. If ``kind='3d'``, axes must be an\n    instance of Axes3D. If None (default), a new axes will be created.\n\n    .. versionadded:: 0.13.0\nblock : bool\n    Whether to halt program execution until the figure is closed.\n    Defaults to False.\n\n    .. versionadded:: 0.13.0\nshow : bool\n    Show figure if True. Defaults to True.\n%(sphere_topomap_auto)s\n%(verbose)s\n\nReturns\n-------\nfig : instance of Figure\n    Figure containing the sensor topography.\nselection : list\n    A list of selected channels. Only returned if ``kind=='select'``.\n\nSee Also\n--------\nmne.viz.plot_layout\n\nNotes\n-----\nThis function plots the sensor locations from the info structure using\nmatplotlib. For drawing the sensors using PyVista see\n:func:`mne.viz.plot_alignment`.\n\n.. versionadded:: 0.12.0", "metadata": {}}
{"_id": "mne_mne__fiff/meas_info.py_anonymize_doc", "text": "Anonymize measurement information in place.\n\nParameters\n----------\n%(daysback_anonymize_info)s\n%(keep_his_anonymize_info)s\n%(verbose)s\n\nReturns\n-------\ninst : instance of Raw | Epochs | Evoked\n    The modified instance.\n\nNotes\n-----\n%(anonymize_info_notes)s\n\n.. versionadded:: 0.13.0", "metadata": {}}
{"_id": "mne_mne__fiff/meas_info.py_set_meas_date_doc", "text": "Set the measurement start date.\n\nParameters\n----------\nmeas_date : datetime | float | tuple | None\n    The new measurement date.\n    If datetime object, it must be timezone-aware and in UTC.\n    A tuple of (seconds, microseconds) or float (alias for\n    ``(meas_date, 0)``) can also be passed and a datetime\n    object will be automatically created. If None, will remove\n    the time reference.\n\nReturns\n-------\ninst : instance of Raw | Epochs | Evoked\n    The modified raw instance. Operates in place.\n\nSee Also\n--------\nmne.io.Raw.anonymize\n\nNotes\n-----\nIf you want to remove all time references in the file, call\n:func:`mne.io.anonymize_info(inst.info) <mne.io.anonymize_info>`\nafter calling ``inst.set_meas_date(None)``.\n\n.. versionadded:: 0.20", "metadata": {}}
{"_id": "mne_mne__fiff/meas_info.py_compensation_grade_doc", "text": "The current gradient compensation grade.", "metadata": {}}
{"_id": "mne_mne__fiff/meas_info.py_get_channel_types_doc", "text": "Get a list of channel type for each channel.\n\nParameters\n----------\n%(picks_all)s\nunique : bool\n    Whether to return only unique channel types. Default is ``False``.\nonly_data_chs : bool\n    Whether to ignore non-data channels. Default is ``False``.\n\nReturns\n-------\nchannel_types : list\n    The channel types.", "metadata": {}}
{"_id": "mne_mne__fiff/meas_info.py_update_doc", "text": "Update method using __setitem__().", "metadata": {}}
{"_id": "mne_mne__fiff/meas_info.py_copy_doc", "text": "Copy the instance.\n\nReturns\n-------\ninfo : instance of Info\n    The copied info.", "metadata": {}}
{"_id": "mne_mne__fiff/meas_info.py_normalize_proj_doc", "text": "(Re-)Normalize projection vectors after subselection.\n\nApplying projection after sub-selecting a set of channels that\nwere originally used to compute the original projection vectors\ncan be dangerous (e.g., if few channels remain, most power was\nin channels that are no longer picked, etc.). By default, mne\nwill emit a warning when this is done.\n\nThis function will re-normalize projectors to use only the\nremaining channels, thus avoiding that warning. Only use this\nfunction if you're confident that the projection vectors still\nadequately capture the original signal of interest.", "metadata": {}}
{"_id": "mne_mne__fiff/meas_info.py_save_doc", "text": "Write measurement info in fif file.\n\nParameters\n----------\nfname : path-like\n    The name of the file. Should end by ``'-info.fif'``.\n%(overwrite)s\n\n    .. versionadded:: 1.10\n%(verbose)s\n\nSee Also\n--------\nmne.io.write_info", "metadata": {}}
{"_id": "mne_mne__fiff/_digitization.py_write_dig_doc", "text": "Write digitization data to a FIF file.\n\nParameters\n----------\nfname : path-like\n    Destination file name.\npts : iterator of dict\n    Iterator through digitizer points. Each point is a dictionary with\n    the keys 'kind', 'ident' and 'r'.\ncoord_frame : int | str | None\n    If all the points have the same coordinate frame, specify the type\n    here. Can be None (default) if the points could have varying\n    coordinate frames.\nch_names : list of str | None\n    Channel names associated with the digitization points, if available.\n\n    .. versionadded:: 1.9\n%(overwrite)s\n\n    .. versionadded:: 1.0\n%(verbose)s\n\n    .. versionadded:: 1.0", "metadata": {}}
{"_id": "mne_mne__fiff/open.py_fiff_open_doc", "text": "Open a FIF file.\n\nParameters\n----------\nfname : path-like | fid\n    Name of the fif file, or an opened file (will seek back to 0).\npreload : bool\n    If True, all data from the file is read into a memory buffer. This\n    requires more memory, but can be faster for I/O operations that require\n    frequent seeks.\n%(verbose)s\n\nReturns\n-------\nfid : file\n    The file descriptor of the open file.\ntree : fif tree\n    The tree is a complex structure filled with dictionaries,\n    lists and tags.\ndirectory : list\n    A list of tags.", "metadata": {}}
{"_id": "mne_mne__fiff/open.py_show_fiff_doc", "text": "Show FIFF information.\n\nThis function is similar to mne_show_fiff.\n\nParameters\n----------\nfname : path-like\n    Filename to evaluate.\nindent : str\n    How to indent the lines.\nread_limit : int\n    Max number of bytes of data to read from a tag. Can be np.inf\n    to always read all data (helps test read completion).\nmax_str : int\n    Max number of characters of string representation to print for\n    each tag's data.\noutput : type\n    Either str or list. str is a convenience output for printing.\ntag : int | None\n    Provide information about this tag. If None (default), all information\n    is shown.\nshow_bytes : bool\n    If True (default False), print the byte offsets of each tag.\n%(verbose)s\n\nReturns\n-------\ncontents : str\n    The contents of the file.", "metadata": {}}
{"_id": "mne_mne__fiff/reference.py_add_reference_channels_doc", "text": "Add reference channels to data that consists of all zeros.\n\nAdds reference channels to data that were not included during recording.\nThis is useful when you need to re-reference your data to different\nchannels. These added channels will consist of all zeros.\n\nParameters\n----------\ninst : instance of Raw | Epochs | Evoked\n    Instance of Raw or Epochs with EEG channels and reference channel(s).\n%(ref_channels)s\ncopy : bool\n    Specifies whether the data will be copied (True) or modified in-place\n    (False). Defaults to True.\n\nReturns\n-------\ninst : instance of Raw | Epochs | Evoked\n    Data with added EEG reference channels.\n\nNotes\n-----\n.. warning::\n    When :ref:`re-referencing <tut-set-eeg-ref>`,\n    make sure to apply the montage using :meth:`mne.io.Raw.set_montage`\n    only after calling this function. Applying a montage will only set\n    locations of channels that exist at the time it is applied.", "metadata": {}}
{"_id": "mne_mne__fiff/reference.py_set_eeg_reference_doc", "text": "Specify which reference to use for EEG data.\n\nUse this function to explicitly specify the desired reference for EEG.\nThis can be either an existing electrode or a new virtual channel.\nThis function will re-reference the data according to the desired\nreference.\n\nNote that it is also possible to re-reference the signal using a\nLaplacian (LAP) \"reference-free\" transformation using the\n:func:`.compute_current_source_density` function.\n\nParameters\n----------\ninst : instance of Raw | Epochs | Evoked\n    Instance of Raw or Epochs with EEG channels and reference channel(s).\n%(ref_channels_set_eeg_reference)s\ncopy : bool\n    Specifies whether the data will be copied (True) or modified in-place\n    (False). Defaults to True.\n%(projection_set_eeg_reference)s\n%(ch_type_set_eeg_reference)s\n%(forward_set_eeg_reference)s\n%(joint_set_eeg_reference)s\n%(verbose)s\n\nReturns\n-------\ninst : instance of Raw | Epochs | Evoked\n    Data with EEG channels re-referenced. If ``ref_channels=\"average\"`` and\n    ``projection=True`` a projection will be added instead of directly\n    re-referencing the data.\nref_data : array\n    Array of reference data subtracted from EEG channels. This will be\n    ``None`` if ``projection=True``, or if ``ref_channels`` is ``\"REST\"`` or a\n    :class:`dict`.\n%(set_eeg_reference_see_also_notes)s", "metadata": {}}
{"_id": "mne_mne__fiff/reference.py_set_bipolar_reference_doc", "text": "Re-reference selected channels using a bipolar referencing scheme.\n\nA bipolar reference takes the difference between two channels (the anode\nminus the cathode) and adds it as a new virtual channel. The original\nchannels will be dropped by default.\n\nMultiple anodes and cathodes can be specified, in which case multiple\nvirtual channels will be created. The 1st cathode will be subtracted\nfrom the 1st anode, the 2nd cathode from the 2nd anode, etc.\n\nBy default, the virtual channels will be annotated with channel-info and\n-location of the anodes and coil types will be set to EEG_BIPOLAR.\n\nParameters\n----------\ninst : instance of Raw | Epochs | Evoked\n    Data containing the unreferenced channels.\nanode : str | list of str\n    The name(s) of the channel(s) to use as anode in the bipolar reference.\ncathode : str | list of str\n    The name(s) of the channel(s) to use as cathode in the bipolar\n    reference.\nch_name : str | list of str | None\n    The channel name(s) for the virtual channel(s) containing the resulting\n    signal. By default, bipolar channels are named after the anode and\n    cathode, but it is recommended to supply a more meaningful name.\nch_info : dict | list of dict | None\n    This parameter can be used to supply a dictionary (or a dictionary for\n    each bipolar channel) containing channel information to merge in,\n    overwriting the default values. Defaults to None.\ndrop_refs : bool\n    Whether to drop the anode/cathode channels from the instance.\ncopy : bool\n    Whether to operate on a copy of the data (True) or modify it in-place\n    (False). Defaults to True.\non_bad : str\n    If a bipolar channel is created from a bad anode or a bad cathode, mne\n    warns if on_bad=\"warns\", raises ValueError if on_bad=\"raise\", and does\n    nothing if on_bad=\"ignore\". For \"warn\" and \"ignore\", the new bipolar\n    channel will be marked as bad. Defaults to on_bad=\"warns\".\n%(verbose)s\n\nReturns\n-------\ninst : instance of Raw | Epochs | Evoked\n    Data with the specified channels re-referenced.\n\nSee Also\n--------\nset_eeg_reference : Convenience function for creating an EEG reference.\n\nNotes\n-----\n1. If the anodes contain any EEG channels, this function removes\n   any pre-existing average reference projections.\n\n2. During source localization, the EEG signal should have an average\n   reference.\n\n3. The data must be preloaded.\n\n.. versionadded:: 0.9.0", "metadata": {}}
{"_id": "mne_mne__fiff/pick.py_get_channel_type_constants_doc", "text": "Return all known channel types, and associated FIFF constants.\n\nParameters\n----------\ninclude_defaults : bool\n    Whether to include default values for \"unit\" and \"coil_type\" for all\n    entries (see Notes). Defaults are generally based on values normally\n    present for a VectorView MEG system. Defaults to ``False``.\n\nReturns\n-------\nchannel_types : dict\n    The keys are channel type strings, and the values are dictionaries of\n    FIFF constants for \"kind\", and possibly \"unit\" and \"coil_type\".\n\nNotes\n-----\nValues which might vary within a channel type across real data\nrecordings are excluded unless ``include_defaults=True``. For example,\n\"ref_meg\" channels may have coil type\n``FIFFV_COIL_MAGNES_OFFDIAG_REF_GRAD``, ``FIFFV_COIL_VV_MAG_T3``, etc\n(depending on the recording system), so no \"coil_type\" entry is given\nfor \"ref_meg\" unless ``include_defaults`` is requested.", "metadata": {}}
{"_id": "mne_mne__fiff/pick.py_channel_type_doc", "text": "Get channel type.\n\nParameters\n----------\n%(info_not_none)s\nidx : int\n    Index of channel.\n\nReturns\n-------\ntype : str\n    Type of channel. Will be one of::\n\n        {'bio', 'chpi', 'dbs', 'dipole', 'ecg', 'ecog', 'eeg', 'emg',\n        'eog', 'exci', 'eyetrack', 'fnirs', 'gof', 'gsr', 'ias', 'misc',\n        'meg', 'ref_meg', 'resp', 'seeg', 'stim', 'syst', 'temperature'}", "metadata": {}}
{"_id": "mne_mne__fiff/pick.py_pick_channels_doc", "text": "Pick channels by names.\n\nReturns the indices of ``ch_names`` in ``include`` but not in ``exclude``.\n\nParameters\n----------\nch_names : list of str\n    List of channels.\ninclude : list of str\n    List of channels to include (if empty include all available).\n\n    .. note:: This is to be treated as a set. The order of this list\n       is not used or maintained in ``sel``.\n\nexclude : list of str\n    List of channels to exclude (if empty do not exclude any channel).\n    Defaults to [].\n%(ordered)s\n%(verbose)s\n\nReturns\n-------\nsel : array of int\n    Indices of good channels.\n\nSee Also\n--------\npick_channels_regexp, pick_types", "metadata": {}}
{"_id": "mne_mne__fiff/pick.py_pick_channels_regexp_doc", "text": "Pick channels using regular expression.\n\nReturns the indices of the good channels in ch_names.\n\nParameters\n----------\nch_names : list of str\n    List of channels.\n\nregexp : str\n    The regular expression. See python standard module for regular\n    expressions.\n\nReturns\n-------\nsel : array of int\n    Indices of good channels.\n\nSee Also\n--------\npick_channels\n\nExamples\n--------\n>>> pick_channels_regexp(['MEG 2331', 'MEG 2332', 'MEG 2333'], 'MEG ...1')\n[0]\n>>> pick_channels_regexp(['MEG 2331', 'MEG 2332', 'MEG 2333'], 'MEG *')\n[0, 1, 2]", "metadata": {}}
{"_id": "mne_mne__fiff/pick.py_pick_types_doc", "text": "Pick channels by type and names.\n\nParameters\n----------\n%(info_not_none)s\n%(pick_types_params)s\n\nReturns\n-------\nsel : array of int\n    Indices of good channels.", "metadata": {}}
{"_id": "mne_mne__fiff/pick.py_pick_info_doc", "text": "Restrict an info structure to a selection of channels.\n\nParameters\n----------\n%(info_not_none)s\nsel : list of int | None\n    Indices of channels to include. If None, all channels\n    are included.\ncopy : bool\n    If copy is False, info is modified inplace.\n%(verbose)s\n\nReturns\n-------\nres : dict\n    Info structure restricted to a selection of channels.", "metadata": {}}
{"_id": "mne_mne__fiff/pick.py_pick_channels_forward_doc", "text": "Pick channels from forward operator.\n\nParameters\n----------\norig : dict\n    A forward solution.\ninclude : list of str\n    List of channels to include (if empty, include all available).\n    Defaults to [].\nexclude : list of str | 'bads'\n    Channels to exclude (if empty, do not exclude any). Defaults to [].\n    If 'bads', then exclude bad channels in orig.\n%(ordered)s\ncopy : bool\n    If True (default), make a copy.\n\n    .. versionadded:: 0.19\n%(verbose)s\n\nReturns\n-------\nres : dict\n    Forward solution restricted to selected channels. If include and\n    exclude are empty it returns orig without copy.", "metadata": {}}
{"_id": "mne_mne__fiff/pick.py_pick_types_forward_doc", "text": "Pick by channel type and names from a forward operator.\n\nParameters\n----------\norig : dict\n    A forward solution.\nmeg : bool | str\n    If True include MEG channels. If string it can be 'mag', 'grad',\n    'planar1' or 'planar2' to select only magnetometers, all gradiometers,\n    or a specific type of gradiometer.\neeg : bool\n    If True include EEG channels.\nref_meg : bool\n    If True include CTF / 4D reference channels.\nseeg : bool\n    If True include stereotactic EEG channels.\necog : bool\n    If True include electrocorticography channels.\ndbs : bool\n    If True include deep brain stimulation channels.\ninclude : list of str\n    List of additional channels to include. If empty do not include any.\nexclude : list of str | str\n    List of channels to exclude. If empty do not exclude any (default).\n    If 'bads', exclude channels in orig['info']['bads'].\n\nReturns\n-------\nres : dict\n    Forward solution restricted to selected channel types.", "metadata": {}}
{"_id": "mne_mne__fiff/pick.py_channel_indices_by_type_doc", "text": "Get indices of channels by type.\n\nParameters\n----------\n%(info_not_none)s\n%(picks_all)s\n\nReturns\n-------\nidx_by_type : dict\n    A dictionary that maps each channel type to a (possibly empty) list of\n    channel indices.", "metadata": {}}
{"_id": "mne_mne__fiff/pick.py_pick_channels_cov_doc", "text": "Pick channels from covariance matrix.\n\nParameters\n----------\norig : Covariance\n    A covariance.\ninclude : list of str, (optional)\n    List of channels to include (if empty, include all available).\nexclude : list of str, (optional) | 'bads'\n    Channels to exclude (if empty, do not exclude any). Defaults to 'bads'.\n%(ordered)s\ncopy : bool\n    If True (the default), return a copy of the covariance matrix with the\n    modified channels. If False, channels are modified in-place.\n\n    .. versionadded:: 0.20.0\n%(verbose)s\n\nReturns\n-------\nres : dict\n    Covariance solution restricted to selected channels.", "metadata": {}}
{"_id": "mne_mne__fiff/write.py_write_nop_doc", "text": "Write a FIFF_NOP.", "metadata": {}}
{"_id": "mne_mne__fiff/write.py_write_int_doc", "text": "Write a 32-bit integer tag to a fif file.", "metadata": {}}
{"_id": "mne_mne__fiff/write.py_write_double_doc", "text": "Write a double-precision floating point tag to a fif file.", "metadata": {}}
{"_id": "mne_mne__fiff/write.py_write_float_doc", "text": "Write a single-precision floating point tag to a fif file.", "metadata": {}}
{"_id": "mne_mne__fiff/write.py_write_dau_pack16_doc", "text": "Write a dau_pack16 tag to a fif file.", "metadata": {}}
{"_id": "mne_mne__fiff/write.py_write_complex64_doc", "text": "Write a 64 bit complex floating point tag to a fif file.", "metadata": {}}
{"_id": "mne_mne__fiff/write.py_write_complex128_doc", "text": "Write a 128 bit complex floating point tag to a fif file.", "metadata": {}}
{"_id": "mne_mne__fiff/write.py_write_julian_doc", "text": "Write a Julian-formatted date to a FIF file.", "metadata": {}}
{"_id": "mne_mne__fiff/write.py_write_string_doc", "text": "Write a string tag.", "metadata": {}}
{"_id": "mne_mne__fiff/write.py_write_name_list_doc", "text": "Write a colon-separated list of names.\n\nParameters\n----------\ndata : list of strings", "metadata": {}}
{"_id": "mne_mne__fiff/write.py_write_name_list_sanitized_doc", "text": "Write a sanitized, colon-separated list of names.", "metadata": {}}
{"_id": "mne_mne__fiff/write.py_write_float_matrix_doc", "text": "Write a single-precision floating-point matrix tag.", "metadata": {}}
{"_id": "mne_mne__fiff/write.py_write_double_matrix_doc", "text": "Write a double-precision floating-point matrix tag.", "metadata": {}}
{"_id": "mne_mne__fiff/write.py_write_int_matrix_doc", "text": "Write integer 32 matrix tag.", "metadata": {}}
{"_id": "mne_mne__fiff/write.py_write_complex_float_matrix_doc", "text": "Write complex 64 matrix tag.", "metadata": {}}
{"_id": "mne_mne__fiff/write.py_write_complex_double_matrix_doc", "text": "Write complex 128 matrix tag.", "metadata": {}}
{"_id": "mne_mne__fiff/write.py_get_machid_doc", "text": "Get (mostly) unique machine ID.\n\nReturns\n-------\nids : array (length 2, int32)\n    The machine identifier used in MNE.", "metadata": {}}
{"_id": "mne_mne__fiff/write.py_get_new_file_id_doc", "text": "Create a new file ID tag.", "metadata": {}}
{"_id": "mne_mne__fiff/write.py_write_id_doc", "text": "Write fiff id.", "metadata": {}}
{"_id": "mne_mne__fiff/write.py_start_block_doc", "text": "Write a FIFF_BLOCK_START tag.", "metadata": {}}
{"_id": "mne_mne__fiff/write.py_end_block_doc", "text": "Write a FIFF_BLOCK_END tag.", "metadata": {}}
{"_id": "mne_mne__fiff/write.py_start_file_doc", "text": "Open a fif file for writing and writes the compulsory header tags.\n\nParameters\n----------\nfname : path-like | fid\n    The name of the file to open. It is recommended\n    that the name ends with .fif or .fif.gz. Can also be an\n    already opened file.\nid_ : dict | None\n    ID to use for the FIFF_FILE_ID.", "metadata": {}}
{"_id": "mne_mne__fiff/write.py_start_and_end_file_doc", "text": "Start and (if successfully written) close the file.", "metadata": {}}
{"_id": "mne_mne__fiff/write.py_check_fiff_length_doc", "text": "Ensure our file hasn't grown too large to work properly.", "metadata": {}}
{"_id": "mne_mne__fiff/write.py_end_file_doc", "text": "Write the closing tags to a fif file and closes the file.", "metadata": {}}
{"_id": "mne_mne__fiff/write.py_write_coord_trans_doc", "text": "Write a coordinate transformation structure.", "metadata": {}}
{"_id": "mne_mne__fiff/write.py_write_ch_info_doc", "text": "Write a channel information record to a fif file.", "metadata": {}}
{"_id": "mne_mne__fiff/write.py_write_dig_points_doc", "text": "Write a set of digitizer data points into a fif file.", "metadata": {}}
{"_id": "mne_mne__fiff/write.py_write_float_sparse_rcs_doc", "text": "Write a single-precision sparse compressed row matrix tag.", "metadata": {}}
{"_id": "mne_mne__fiff/write.py_write_float_sparse_doc", "text": "Write a single-precision floating-point sparse matrix tag.", "metadata": {}}
{"_id": "mne_mne__fiff/proj.py_make_projector_doc", "text": "Create an SSP operator from SSP projection vectors.\n\nParameters\n----------\nprojs : list\n    List of projection vectors.\nch_names : list of str\n    List of channels to include in the projection matrix.\nbads : list of str\n    Some bad channels to exclude. If bad channels were marked\n    in the raw file when projs were calculated using mne-python,\n    they should not need to be included here as they will\n    have been automatically omitted from the projectors.\ninclude_active : bool\n    Also include projectors that are already active.\n\nReturns\n-------\nproj : array of shape [n_channels, n_channels]\n    The projection operator to apply to the data.\nnproj : int\n    How many items in the projector.\nU : array\n    The orthogonal basis of the projection vectors.", "metadata": {}}
{"_id": "mne_mne__fiff/proj.py_make_projector_info_doc", "text": "Make an SSP operator using the measurement info.\n\nCalls make_projector on good channels.\n\nParameters\n----------\n%(info_not_none)s\ninclude_active : bool\n    Also include projectors that are already active.\n\nReturns\n-------\nproj : array of shape [n_channels, n_channels]\n    The projection operator to apply to the data.\nnproj : int\n    How many items in the projector.", "metadata": {}}
{"_id": "mne_mne__fiff/proj.py_activate_proj_doc", "text": "Set all projections to active.\n\nUseful before passing them to make_projector.\n\nParameters\n----------\nprojs : list\n    The projectors.\ncopy : bool\n    Modify projs in place or operate on a copy.\n%(verbose)s\n\nReturns\n-------\nprojs : list\n    The projectors.", "metadata": {}}
{"_id": "mne_mne__fiff/proj.py_deactivate_proj_doc", "text": "Set all projections to inactive.\n\nUseful before saving raw data without projectors applied.\n\nParameters\n----------\nprojs : list\n    The projectors.\ncopy : bool\n    Modify projs in place or operate on a copy.\n%(verbose)s\n\nReturns\n-------\nprojs : list\n    The projectors.", "metadata": {}}
{"_id": "mne_mne__fiff/proj.py_make_eeg_average_ref_proj_doc", "text": "Create an EEG average reference SSP projection vector.\n\nParameters\n----------\n%(info_not_none)s\nactivate : bool\n    If True projections are activated.\nch_type : str\n    The channel type to use for reference projection.\n    Valid types are ``'eeg'``, ``'ecog'``, ``'seeg'`` and ``'dbs'``.\n\n    .. versionadded:: 1.2\n%(verbose)s\n\nReturns\n-------\nproj: instance of Projection\n    The SSP/PCA projector.", "metadata": {}}
{"_id": "mne_mne__fiff/proj.py_setup_proj_doc", "text": "Set up projection for Raw and Epochs.\n\nParameters\n----------\n%(info_not_none)s Warning: will be modified in-place.\nadd_eeg_ref : bool\n    If True, an EEG average reference will be added (unless one\n    already exists).\nactivate : bool\n    If True projections are activated.\neeg_ref_ch_type : str\n    The channel type to use for reference projection.\n    Valid types are 'eeg', 'ecog', 'seeg' and 'dbs'.\n\n    .. versionadded:: 1.2\n%(verbose)s\n\nReturns\n-------\nprojector : array of shape [n_channels, n_channels]\n    The projection operator to apply to the data.\ninfo : mne.Info\n    The modified measurement info.", "metadata": {}}
{"_id": "mne_mne__fiff/proj.py_plot_topomap_doc", "text": "Plot topographic maps of SSP projections.\n\nParameters\n----------\n%(info_not_none)s Used to determine the layout.\n%(sensors_topomap)s\n%(show_names_topomap)s\n\n    .. versionadded:: 1.2\n%(contours_topomap)s\n%(outlines_topomap)s\n%(sphere_topomap_auto)s\n%(image_interp_topomap)s\n%(extrapolate_topomap)s\n\n    .. versionadded:: 1.2\n%(border_topomap)s\n\n    .. versionadded:: 0.20\n%(res_topomap)s\n%(size_topomap)s\n%(cmap_topomap)s\n%(vlim_plot_topomap_proj)s\n%(cnorm)s\n\n    .. versionadded:: 1.2\n%(colorbar_topomap)s\n%(cbar_fmt_topomap)s\n\n    .. versionadded:: 1.2\n%(units_topomap)s\n\n    .. versionadded:: 1.2\n%(axes_plot_projs_topomap)s\n%(show)s\n\nReturns\n-------\nfig : instance of Figure\n    Figure distributing one image per channel across sensor topography.\n\nNotes\n-----\n.. versionadded:: 0.15.0", "metadata": {}}
{"_id": "mne_mne__fiff/proj.py_proj_doc", "text": "Whether or not projections are active.", "metadata": {}}
{"_id": "mne_mne__fiff/proj.py_add_proj_doc", "text": "Add SSP projection vectors.\n\nParameters\n----------\nprojs : list\n    List with projection vectors.\nremove_existing : bool\n    Remove the projection vectors currently in the file.\n%(verbose)s\n\nReturns\n-------\nself : instance of Raw | Epochs | Evoked\n    The data container.", "metadata": {}}
{"_id": "mne_mne__fiff/proj.py_apply_proj_doc", "text": "Apply the signal space projection (SSP) operators to the data.\n\nParameters\n----------\n%(verbose)s\n\nReturns\n-------\nself : instance of Raw | Epochs | Evoked\n    The instance.\n\nNotes\n-----\nOnce the projectors have been applied, they can no longer be\nremoved. It is usually not recommended to apply the projectors at\ntoo early stages, as they are applied automatically later on\n(e.g. when computing inverse solutions).\nHint: using the copy method individual projection vectors\ncan be tested without affecting the original data.\nWith evoked data, consider the following example::\n\n    projs_a = mne.read_proj('proj_a.fif')\n    projs_b = mne.read_proj('proj_b.fif')\n    # add the first, copy, apply and see ...\n    evoked.add_proj(a).copy().apply_proj().plot()\n    # add the second, copy, apply and see ...\n    evoked.add_proj(b).copy().apply_proj().plot()\n    # drop the first and see again\n    evoked.copy().del_proj(0).apply_proj().plot()\n    evoked.apply_proj()  # finally keep both", "metadata": {}}
{"_id": "mne_mne__fiff/proj.py_del_proj_doc", "text": "Remove SSP projection vector.\n\n.. note:: The projection vector can only be removed if it is inactive\n          (has not been applied to the data).\n\nParameters\n----------\nidx : int | list of int | str\n    Index of the projector to remove. Can also be \"all\" (default)\n    to remove all projectors.\n\nReturns\n-------\nself : instance of Raw | Epochs | Evoked\n    The instance.", "metadata": {}}
{"_id": "mne_mne__fiff/proj.py_plot_projs_topomap_doc", "text": "Plot SSP vector.\n\nParameters\n----------\n%(ch_type_topomap_proj)s\n%(sensors_topomap)s\n%(show_names_topomap)s\n\n    .. versionadded:: 1.2\n%(contours_topomap)s\n%(outlines_topomap)s\n%(sphere_topomap_auto)s\n%(image_interp_topomap)s\n%(extrapolate_topomap)s\n\n    .. versionadded:: 0.20\n\n    .. versionchanged:: 0.21\n\n       - The default was changed to ``'local'`` for MEG sensors.\n       - ``'local'`` was changed to use a convex hull mask\n       - ``'head'`` was changed to extrapolate out to the clipping circle.\n%(border_topomap)s\n\n    .. versionadded:: 0.20\n%(res_topomap)s\n%(size_topomap)s\n    Only applies when plotting multiple topomaps at a time.\n%(cmap_topomap)s\n%(vlim_plot_topomap_proj)s\n%(cnorm)s\n\n    .. versionadded:: 1.2\n%(colorbar_topomap)s\n%(cbar_fmt_topomap)s\n\n    .. versionadded:: 1.2\n%(units_topomap)s\n\n    .. versionadded:: 1.2\n%(axes_plot_projs_topomap)s\n%(show)s\n\nReturns\n-------\nfig : instance of Figure\n    Figure distributing one image per channel across sensor topography.", "metadata": {}}
{"_id": "mne_mne__fiff/proj.py_sorter_doc", "text": "Sort in a nice way.", "metadata": {}}
{"_id": "mne_mne__fiff/matrix.py_write_named_matrix_doc", "text": "Write named matrix from the given node.\n\nParameters\n----------\nfid : file\n    The opened file descriptor.\nkind : int\n    The kind of the matrix.\nmatkind : int\n    The type of matrix.", "metadata": {}}
{"_id": "mne_mne__fiff/what.py_what_doc", "text": "Try to determine the type of the FIF file.\n\nParameters\n----------\nfname : path-like\n    The filename. Should end in ``.fif`` or ``.fif.gz``.\n\nReturns\n-------\nwhat : str | None\n    The type of the file. Will be 'unknown' if it could not be determined.\n\nNotes\n-----\n.. versionadded:: 0.19", "metadata": {}}
{"_id": "mne_mne__fiff/tree.py_dir_tree_find_doc", "text": "Find nodes of the given kind from a directory tree structure.\n\nParameters\n----------\ntree : dict\n    Directory tree.\nkind : int\n    Kind to find.\n\nReturns\n-------\nnodes : list\n    List of matching nodes.", "metadata": {}}
{"_id": "mne_mne__fiff/tree.py_make_dir_tree_doc", "text": "Create the directory tree structure.", "metadata": {}}
{"_id": "mne_mne__fiff/tag.py_read_tag_doc", "text": "Read a Tag from a file at a given position.\n\nParameters\n----------\nfid : file\n    The open FIF file descriptor.\npos : int\n    The position of the Tag in the file.\nshape : tuple | None\n    If tuple, the shape of the stored matrix. Only to be used with\n    data stored as a vector (not implemented for matrices yet).\nrlims : tuple | None\n    If tuple, the first (inclusive) and last (exclusive) rows to retrieve.\n    Note that data are assumed to be stored row-major in the file. Only to\n    be used with data stored as a vector (not implemented for matrices\n    yet).\n\nReturns\n-------\ntag : Tag\n    The Tag read.", "metadata": {}}
{"_id": "mne_mne__fiff/tag.py_find_tag_doc", "text": "Find Tag in an open FIF file descriptor.\n\nParameters\n----------\nfid : file-like\n    Open file.\nnode : dict\n    Node to search.\nfindkind : int\n    Tag kind to find.\n\nReturns\n-------\ntag : instance of Tag\n    The first tag found.", "metadata": {}}
{"_id": "mne_mne__fiff/tag.py_has_tag_doc", "text": "Check if the node contains a Tag of a given kind.", "metadata": {}}
{"_id": "mne_mne__fiff/tag.py_next_pos_doc", "text": "The next tag position.", "metadata": {}}
{"_id": "mne_mne__fiff/utils.py_read_str_doc", "text": "Read string from a binary file in a python version compatible way.", "metadata": {}}
{"_id": "mne_mne__fiff/compensator.py_get_current_comp_doc", "text": "Get the current compensation in effect in the data.", "metadata": {}}
{"_id": "mne_mne__fiff/compensator.py_set_current_comp_doc", "text": "Set the current compensation in effect in the data.", "metadata": {}}
{"_id": "mne_mne__fiff/compensator.py_make_compensator_doc", "text": "Return compensation matrix eg. for CTF system.\n\nCreate a compensation matrix to bring the data from one compensation\nstate to another.\n\nParameters\n----------\n%(info_not_none)s\nfrom_ : int\n    Compensation in the input data.\nto : int\n    Desired compensation in the output.\nexclude_comp_chs : bool\n    Exclude compensation channels from the output.\n\nReturns\n-------\ncomp : array | None.\n    The compensation matrix. Might be None if no compensation\n    is needed (from == to).", "metadata": {}}
{"_id": "mne_mne__fiff/ctf_comp.py_read_ctf_comp_doc", "text": "Read the CTF software compensation data from the given node.\n\nParameters\n----------\nfid : file\n    The file descriptor.\nnode : dict\n    The node in the FIF tree.\nchs : list\n    The list of channels from info['chs'] to match with\n    compensators that are read.\n%(verbose)s\n\nReturns\n-------\ncompdata : list\n    The compensation data", "metadata": {}}
{"_id": "mne_mne__fiff/ctf_comp.py_write_ctf_comp_doc", "text": "Write the CTF compensation data into a fif file.\n\nParameters\n----------\nfid : file\n    The open FIF file descriptor\n\ncomps : list\n    The compensation data to write", "metadata": {}}
{"_id": "eeg_query_001", "text": "How can I check if a specific EEG channel is marked as bad in PyPREP?", "metadata": {}}
{"_id": "eeg_query_002", "text": "How do I compute the median of a matrix in a MATLAB-compatible way using PyPREP?", "metadata": {}}
{"_id": "eeg_query_003", "text": "How can I calculate the mean of a matrix with behavior similar to MATLAB's mean function?", "metadata": {}}
{"_id": "eeg_query_004", "text": "How do I visualize RANSAC correlation results to assess EEG channel quality?", "metadata": {}}
{"_id": "eeg_query_005", "text": "How do I retrieve a boolean mask of bad EEG channels from the PREP pipeline?", "metadata": {}}
{"_id": "eeg_query_006", "text": "How can I save the cleaned EEG data after running the PREP pipeline?", "metadata": {}}
{"_id": "eeg_query_007", "text": "How do I check if two lists of EEG channels have any overlap?", "metadata": {}}
{"_id": "eeg_query_008", "text": "How do I remove duplicates from a list while preserving the original order in PyPREP?", "metadata": {}}
{"_id": "eeg_query_009", "text": "How do I plot statistical summaries of EEG channels after preprocessing?", "metadata": {}}
{"_id": "eeg_query_010", "text": "How can I extract clean EEG epochs after bad channel rejection?", "metadata": {}}
{"_id": "eeg_query_011", "text": "How do I compute the signal-to-noise ratio (SNR) of EEG signals using PyPREP?", "metadata": {}}
{"_id": "eeg_query_012", "text": "How do I validate input EEG data before running the PREP pipeline?", "metadata": {}}
{"_id": "eeg_query_013", "text": "How can I get a list of EEG channels not marked as bad?", "metadata": {}}
{"_id": "eeg_query_014", "text": "How do I summarize configuration parameters used in a PyPREP run?", "metadata": {}}
{"_id": "eeg_query_015", "text": "How do I run the PyPREP pipeline with custom filtering and reference settings?", "metadata": {}}
{"_id": "pyprep_pyprep_prep_pipeline.py___init___doc", "text": "How do I initialize the PREP class?", "metadata": {}}
{"_id": "pyprep_pyprep_prep_pipeline.py_raw_doc", "text": "How can I get a version of the EEG data that includes the non-EEG channels?", "metadata": {}}
{"_id": "pyprep_pyprep_prep_pipeline.py_fit_doc", "text": "How do I run the full PREP pipeline on EEG data?", "metadata": {}}
{"_id": "pyprep_pyprep_removeTrend.py_removeTrend_doc", "text": "How do I remove slow drifts or trends from EEG data using PyPREP?", "metadata": {}}
{"_id": "pyprep_pyprep_removeTrend.py_runline_doc", "text": "How can I perform local linear detrending using the runline method?", "metadata": {}}
{"_id": "pyprep_pyprep_reference.py___init___doc", "text": "How do I initialize the referencing class in PyPREP?", "metadata": {}}
{"_id": "pyprep_pyprep_reference.py_perform_reference_doc", "text": "How does the perform_reference function estimate the EEG signal mean and handle bad channels?", "metadata": {}}
{"_id": "pyprep_pyprep_reference.py_robust_reference_doc", "text": "How does the robust_reference function detect noisy channels and compute the robust reference signal?", "metadata": {}}
{"_id": "pyprep_pyprep_reference.py_remove_reference_doc", "text": "How do I remove a reference signal from EEG data using PyPREP?", "metadata": {}}
{"_id": "pyprep_pyprep_utils.py__union_doc", "text": "What does the union function in pyprep_utils.py do?", "metadata": {}}
{"_id": "pyprep_pyprep_utils.py__set_diff_doc", "text": "How do I find the difference between two sets in PyPREP?", "metadata": {}}
{"_id": "pyprep_pyprep_utils.py__mat_round_doc", "text": "How can I round a number like MATLAB does, with .5 always rounding up?", "metadata": {}}
{"_id": "pyprep_pyprep_utils.py__mat_quantile_doc", "text": "How do I calculate MATLAB-style quantiles for an array in PyPREP?", "metadata": {}}
{"_id": "pyprep_pyprep_utils.py__mat_iqr_doc", "text": "How can I calculate the inter-quartile range (IQR) like MATLAB does?", "metadata": {}}
{"_id": "pyprep_pyprep_utils.py__eeglab_create_highpass_doc", "text": "How do I create a high-pass FIR filter that mimics EEGLAB in MATLAB?", "metadata": {}}
{"_id": "pyprep_pyprep_utils.py__eeglab_fir_filter_doc", "text": "How do I apply an FIR filter to EEG data using EEGLAB\u2019s method?", "metadata": {}}
{"_id": "pyprep_pyprep_utils.py__eeglab_calc_g_doc", "text": "How can I calculate the spherical spline G matrix for EEG interpolation?", "metadata": {}}
{"_id": "pyprep_pyprep_utils.py__eeglab_interpolate_doc", "text": "How do I interpolate bad EEG channels using electrode positions in PyPREP?", "metadata": {}}
{"_id": "pyprep_pyprep_utils.py__eeglab_interpolate_bads_doc", "text": "How do I interpolate bad channels in an MNE Raw object using EEGLAB's method?", "metadata": {}}
{"_id": "pyprep_pyprep_utils.py__get_random_subset_doc", "text": "How do I randomly sample a subset from a list or array without replacement?", "metadata": {}}
{"_id": "pyprep_pyprep_utils.py__correlate_arrays_doc", "text": "How can I calculate correlations between two 2D EEG arrays, with optional MATLAB-style behavior?"}
{"_id": "pyprep_pyprep_utils.py__filter_design_doc", "text": "How do I create a FIR low-pass filter for EEG data using the frequency sampling method?"}
{"_id": "pyprep_pyprep_utils.py__split_list_doc", "text": "How can I split a list into chunks of a specified size in Python?"}
{"_id": "pyprep_pyprep_utils.py__verify_free_ram_doc", "text": "How do I check if there is enough free RAM to safely run RANSAC on EEG data?"}
{"_id": "pyprep_pyprep_ransac.py_find_bad_by_ransac_doc", "text": "How can I use RANSAC to detect bad EEG channels that aren't predicted well by others?"}
{"_id": "pyprep_pyprep_ransac.py__make_interpolation_matrices_doc", "text": "How do I create interpolation matrices from spatial coordinates of EEG channels for RANSAC?"}
{"_id": "pyprep_pyprep_ransac.py__ransac_by_window_doc", "text": "How can I compute window-wise RANSAC correlations between EEG channels and their predictions?"}
{"_id": "pyprep_pyprep_ransac.py__predict_median_signals_doc", "text": "How do I compute the median RANSAC-predicted signal for a given EEG time window?"}
{"_id": "pyprep_pyprep_ransac.py__ransac_by_channel_doc", "text": "How can I compute RANSAC correlations by channel for a chunk of EEG data?"}
{"_id": "pyprep_pyprep_ransac.py__predict_median_signals_channelwise_doc", "text": "How do I calculate the median RANSAC-predicted EEG signals for a chunk of channels?"}
{"_id": "pyprep_pyprep_find_noisy_channels.py___init___doc", "text": "How do I initialize the NoisyChannels class?", "metadata": {}}
{"_id": "pyprep_pyprep_find_noisy_channels.py__get_filtered_data_doc", "text": "How can I apply a [1 Hz - 50 Hz] bandpass filter to the EEG signal?", "metadata": {}}
{"_id": "pyprep_pyprep_find_noisy_channels.py_get_bads_doc", "text": "How do I get the names of all EEG channels currently flagged as bad?", "metadata": {}}
{"_id": "pyprep_pyprep_find_noisy_channels.py_find_all_bads_doc", "text": "How can I run all the bad channel detection functions, including optional RANSAC?", "metadata": {}}
{"_id": "pyprep_pyprep_find_noisy_channels.py_find_bad_by_nan_flat_doc", "text": "How do I detect EEG channels that contain NaN values or have flat signals?", "metadata": {}}
{"_id": "pyprep_pyprep_find_noisy_channels.py_find_bad_by_deviation_doc", "text": "How do I identify EEG channels with unusually high or low amplitudes?", "metadata": {}}
{"_id": "pyprep_pyprep_find_noisy_channels.py_find_bad_by_hfnoise_doc", "text": "How can I detect EEG channels with high-frequency noise above 50 Hz?", "metadata": {}}
{"_id": "pyprep_pyprep_find_noisy_channels.py_find_bad_by_correlation_doc", "text": "How do I find EEG channels that don't correlate well with others or have intermittent dropouts?", "metadata": {}}
{"_id": "pyprep_pyprep_find_noisy_channels.py_find_bad_by_SNR_doc", "text": "How can I identify channels with a low signal-to-noise ratio (SNR)?", "metadata": {}}
{"_id": "pyprep_pyprep_find_noisy_channels.py_find_bad_by_ransac_doc", "text": "How do I use RANSAC to detect EEG channels that are poorly predicted by other channels?", "metadata": {}}
