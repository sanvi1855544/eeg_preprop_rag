{"_id": "beir_output_finetune_evaluator.py", "title": "", "text": "import numpy as np\nimport torch\nfrom sklearn.metrics import balanced_accuracy_score, f1_score, confusion_matrix, cohen_kappa_score, roc_auc_score, \\\n    precision_recall_curve, auc, r2_score, mean_squared_error\nfrom tqdm import tqdm\n\n\nclass Evaluator:\n    def __init__(self, params, data_loader):\n        self.params = params\n        self.data_loader = data_loader\n\n    def get_metrics_for_multiclass(self, model):\n        model.eval()\n\n        truths = []\n        preds = []\n        for x, y in tqdm(self.data_loader, mininterval=1):\n            x = x.cuda()\n            y = y.cuda()\n\n            pred = model(x)\n            pred_y = torch.max(pred, dim=-1)[1]\n\n            truths += y.cpu().squeeze().numpy().tolist()\n            preds += pred_y.cpu().squeeze().numpy().tolist()\n\n        truths = np.array(truths)\n        preds = np.array(preds)\n        acc = balanced_accuracy_score(truths, preds)\n        f1 = f1_score(truths, preds, average='weighted')\n        kappa = cohen_kappa_score(truths, preds)\n        cm = confusion_matrix(truths, preds)\n        return acc, kappa, f1, cm\n\n    def get_metrics_for_binaryclass(self, model):\n        model.eval()\n\n        truths = []\n        preds = []\n        scores = []\n        for x, y in tqdm(self.data_loader, mininterval=1):\n            x = x.cuda()\n            y = y.cuda()\n            pred = model(x)\n            score_y = torch.sigmoid(pred)\n            pred_y = torch.gt(score_y, 0.5).long()\n            truths += y.long().cpu().squeeze().numpy().tolist()\n            preds += pred_y.cpu().squeeze().numpy().tolist()\n            scores += score_y.cpu().numpy().tolist()\n\n        truths = np.array(truths)\n        preds = np.array(preds)\n        scores = np.array(scores)\n        acc = balanced_accuracy_score(truths, preds)\n        roc_auc = roc_auc_score(truths, scores)\n        precision, recall, thresholds = precision_recall_curve(truths, scores, pos_label=1)\n        pr_auc = auc(recall, precision)\n        cm = confusion_matrix(truths, preds)\n        return acc, pr_auc, roc_auc, cm\n\n    def get_metrics_for_regression(self, model):\n        model.eval()\n\n        truths = []\n        preds = []\n        for x, y in tqdm(self.data_loader, mininterval=1):\n            x = x.cuda()\n            y = y.cuda()\n            pred = model(x)\n            truths += y.cpu().squeeze().numpy().tolist()\n            preds += pred.cpu().squeeze().numpy().tolist()\n\n        truths = np.array(truths)\n        preds = np.array(preds)\n        corrcoef = np.corrcoef(truths, preds)[0, 1]\n        r2 = r2_score(truths, preds)\n        rmse = mean_squared_error(truths, preds) ** 0.5\n        return corrcoef, r2, rmse"}
{"_id": "beir_output_finetune_main.py", "title": "", "text": "import argparse\nimport random\n\nimport numpy as np\nimport torch\n\nfrom datasets import faced_dataset, seedv_dataset, physio_dataset, shu_dataset, isruc_dataset, chb_dataset, \\\n    speech_dataset, mumtaz_dataset, seedvig_dataset, stress_dataset, tuev_dataset, tuab_dataset, bciciv2a_dataset\nfrom finetune_trainer import Trainer\nfrom models import model_for_faced, model_for_seedv, model_for_physio, model_for_shu, model_for_isruc, model_for_chb, \\\n    model_for_speech, model_for_mumtaz, model_for_seedvig, model_for_stress, model_for_tuev, model_for_tuab, \\\n    model_for_bciciv2a\n\n\ndef main():\n    parser = argparse.ArgumentParser(description='Big model downstream')\n    parser.add_argument('--seed', type=int, default=3407, help='random seed (default: 0)')\n    parser.add_argument('--cuda', type=int, default=0, help='cuda number (default: 1)')\n    parser.add_argument('--epochs', type=int, default=50, help='number of epochs (default: 5)')\n    parser.add_argument('--batch_size', type=int, default=64, help='batch size for training (default: 32)')\n    parser.add_argument('--lr', type=float, default=1e-4, help='learning rate (default: 1e-3)')\n    parser.add_argument('--weight_decay', type=float, default=5e-2, help='weight decay (default: 1e-2)')\n    parser.add_argument('--optimizer', type=str, default='AdamW', help='optimizer (AdamW, SGD)')\n    parser.add_argument('--clip_value', type=float, default=1, help='clip_value')\n    parser.add_argument('--dropout', type=float, default=0.1, help='dropout')\n    parser.add_argument('--classifier', type=str, default='avgpooling_patch_reps',\n                        help='[all_patch_reps, avgpooling_patch_reps]')\n    # avgpooling_patch_reps: use average pooling for patch features; all_patch_reps: use all patch features\n\n    \"\"\"############ Downstream dataset settings ############\"\"\"\n    parser.add_argument('--downstream_dataset', type=str, default='FACED',\n                        help='[FACED, SEED-V, PhysioNet-MI, SHU-MI, ISRUC, CHB-MIT, BCIC2020-3, Mumtaz2016, SEED-VIG, MentalArithmetic, TUEV, TUAB, BCIC-IV-2a]')\n    parser.add_argument('--datasets_dir', type=str,\n                        default='/data/datasets/BigDownstream/Faced/processed',\n                        help='datasets_dir')\n    parser.add_argument('--num_of_classes', type=int, default=9, help='number of classes')\n    parser.add_argument('--model_dir', type=str, default='/data/wjq/models_weights/Big/BigFaced', help='model_dir')\n    \"\"\"############ Downstream dataset settings ############\"\"\"\n\n    parser.add_argument('--num_workers', type=int, default=16, help='num_workers')\n    parser.add_argument('--label_smoothing', type=float, default=0.1, help='label_smoothing')\n    parser.add_argument('--multi_lr', type=bool, default=True,\n                        help='multi_lr')  # set different learning rates for different modules\n    parser.add_argument('--frozen', type=bool,\n                        default=False, help='frozen')\n    parser.add_argument('--use_pretrained_weights', type=bool,\n                        default=True, help='use_pretrained_weights')\n    parser.add_argument('--foundation_dir', type=str,\n                        default='pretrained_weights/pretrained_weights.pth',\n                        help='foundation_dir')\n\n    params = parser.parse_args()\n    print(params)\n\n    setup_seed(params.seed)\n    torch.cuda.set_device(params.cuda)\n    print('The downstream dataset is {}'.format(params.downstream_dataset))\n    if params.downstream_dataset == 'FACED':\n        load_dataset = faced_dataset.LoadDataset(params)\n        data_loader = load_dataset.get_data_loader()\n        model = model_for_faced.Model(params)\n        t = Trainer(params, data_loader, model)\n        t.train_for_multiclass()\n    elif params.downstream_dataset == 'SEED-V':\n        load_dataset = seedv_dataset.LoadDataset(params)\n        data_loader = load_dataset.get_data_loader()\n        model = model_for_seedv.Model(params)\n        t = Trainer(params, data_loader, model)\n        t.train_for_multiclass()\n    elif params.downstream_dataset == 'PhysioNet-MI':\n        load_dataset = physio_dataset.LoadDataset(params)\n        data_loader = load_dataset.get_data_loader()\n        model = model_for_physio.Model(params)\n        t = Trainer(params, data_loader, model)\n        t.train_for_multiclass()\n    elif params.downstream_dataset == 'SHU-MI':\n        load_dataset = shu_dataset.LoadDataset(params)\n        data_loader = load_dataset.get_data_loader()\n        model = model_for_shu.Model(params)\n        t = Trainer(params, data_loader, model)\n        t.train_for_binaryclass()\n    elif params.downstream_dataset == 'ISRUC':\n        load_dataset = isruc_dataset.LoadDataset(params)\n        data_loader = load_dataset.get_data_loader()\n        model = model_for_isruc.Model(params)\n        t = Trainer(params, data_loader, model)\n        t.train_for_multiclass()\n    elif params.downstream_dataset == 'CHB-MIT':\n        load_dataset = chb_dataset.LoadDataset(params)\n        data_loader = load_dataset.get_data_loader()\n        model = model_for_chb.Model(params)\n        t = Trainer(params, data_loader, model)\n        t.train_for_binaryclass()\n    elif params.downstream_dataset == 'BCIC2020-3':\n        load_dataset = speech_dataset.LoadDataset(params)\n        data_loader = load_dataset.get_data_loader()\n        model = model_for_speech.Model(params)\n        t = Trainer(params, data_loader, model)\n        t.train_for_multiclass()\n    elif params.downstream_dataset == 'Mumtaz2016':\n        load_dataset = mumtaz_dataset.LoadDataset(params)\n        data_loader = load_dataset.get_data_loader()\n        model = model_for_mumtaz.Model(params)\n        t = Trainer(params, data_loader, model)\n        t.train_for_binaryclass()\n    elif params.downstream_dataset == 'SEED-VIG':\n        load_dataset = seedvig_dataset.LoadDataset(params)\n        data_loader = load_dataset.get_data_loader()\n        model = model_for_seedvig.Model(params)\n        t = Trainer(params, data_loader, model)\n        t.train_for_regression()\n    elif params.downstream_dataset == 'MentalArithmetic':\n        load_dataset = stress_dataset.LoadDataset(params)\n        data_loader = load_dataset.get_data_loader()\n        model = model_for_stress.Model(params)\n        t = Trainer(params, data_loader, model)\n        t.train_for_binaryclass()\n    elif params.downstream_dataset == 'TUEV':\n        load_dataset = tuev_dataset.LoadDataset(params)\n        data_loader = load_dataset.get_data_loader()\n        model = model_for_tuev.Model(params)\n        t = Trainer(params, data_loader, model)\n        t.train_for_multiclass()\n    elif params.downstream_dataset == 'TUAB':\n        load_dataset = tuab_dataset.LoadDataset(params)\n        data_loader = load_dataset.get_data_loader()\n        model = model_for_tuab.Model(params)\n        t = Trainer(params, data_loader, model)\n        t.train_for_binaryclass()\n    elif params.downstream_dataset == 'BCIC-IV-2a':\n        load_dataset = bciciv2a_dataset.LoadDataset(params)\n        data_loader = load_dataset.get_data_loader()\n        model = model_for_bciciv2a.Model(params)\n        t = Trainer(params, data_loader, model)\n        t.train_for_multiclass()\n    print('Done!!!!!')\n\n\ndef setup_seed(seed):\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    np.random.seed(seed)\n    random.seed(seed)\n    torch.backends.cudnn.deterministic = True\n\n\nif __name__ == '__main__':\n    main()\n"}
{"_id": "beir_output_pretrain_trainer.py", "title": "", "text": "import numpy as np\nimport torch\nfrom ptflops import get_model_complexity_info\nfrom torch.nn import MSELoss\nfrom torchinfo import summary\nfrom tqdm import tqdm\n\nfrom utils.util import generate_mask\n\n\nclass Trainer(object):\n    def __init__(self, params, data_loader, model):\n        self.params = params\n        self.device = torch.device(f\"cuda:{self.params.cuda}\" if torch.cuda.is_available() else \"cpu\")\n        self.data_loader = data_loader\n        self.model = model.to(self.device)\n        self.criterion = MSELoss(reduction='mean').to(self.device)\n\n        if self.params.parallel:\n            device_ids = [0, 1, 2, 3, 4, 5, 6, 7]\n            self.model = torch.nn.DataParallel(self.model, device_ids=device_ids)\n\n        self.data_length = len(self.data_loader)\n\n        summary(self.model, input_size=(1, 19, 30, 200))\n\n        macs, params = get_model_complexity_info(self.model, (19, 30, 200), as_strings=True,\n                                                 print_per_layer_stat=True, verbose=True)\n        print('{:<30}  {:<8}'.format('Computational complexity: ', macs))\n        print('{:<30}  {:<8}'.format('Number of parameters: ', params))\n\n        self.optimizer = torch.optim.AdamW(self.model.parameters(), lr=self.params.lr,\n                                           weight_decay=self.params.weight_decay)\n\n        if self.params.lr_scheduler=='CosineAnnealingLR':\n            self.optimizer_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n                self.optimizer, T_max=40*self.data_length, eta_min=1e-5\n            )\n        elif self.params.lr_scheduler=='ExponentialLR':\n            self.optimizer_scheduler = torch.optim.lr_scheduler.ExponentialLR(\n                self.optimizer, gamma=0.999999999\n            )\n        elif self.params.lr_scheduler=='StepLR':\n            self.optimizer_scheduler = torch.optim.lr_scheduler.StepLR(\n                self.optimizer, step_size=5*self.data_length, gamma=0.5\n            )\n        elif self.params.lr_scheduler=='MultiStepLR':\n            self.optimizer_scheduler = torch.optim.lr_scheduler.MultiStepLR(\n                self.optimizer, milestones=[10*self.data_length, 20*self.data_length, 30*self.data_length], gamma=0.1\n            )\n        elif self.params.lr_scheduler=='CyclicLR':\n            self.optimizer_scheduler = torch.optim.lr_scheduler.CyclicLR(\n                self.optimizer, base_lr=1e-6, max_lr=0.001, step_size_up=self.data_length*5,\n                step_size_down=self.data_length*2, mode='exp_range', gamma=0.9, cycle_momentum=False\n            )\n\n\n    def train(self):\n        best_loss = 10000\n        for epoch in range(self.params.epochs):\n            losses = []\n            for x in tqdm(self.data_loader, mininterval=10):\n                self.optimizer.zero_grad()\n                x = x.to(self.device)/100\n                if self.params.need_mask:\n                    bz, ch_num, patch_num, patch_size = x.shape\n                    mask = generate_mask(\n                        bz, ch_num, patch_num, mask_ratio=self.params.mask_ratio, device=self.device,\n                    )\n                    y = self.model(x, mask=mask)\n                    masked_x = x[mask == 1]\n                    masked_y = y[mask == 1]\n                    loss = self.criterion(masked_y, masked_x)\n\n                    # non_masked_x = x[mask == 0]\n                    # non_masked_y = y[mask == 0]\n                    # non_masked_loss = self.criterion(non_masked_y, non_masked_x)\n                    # loss = 0.8 * masked_loss + 0.2 * non_masked_loss\n                else:\n                    y = self.model(x)\n                    loss = self.criterion(y, x)\n                loss.backward()\n                if self.params.clip_value > 0:\n                    torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.params.clip_value)\n                self.optimizer.step()\n                self.optimizer_scheduler.step()\n                losses.append(loss.data.cpu().numpy())\n            mean_loss = np.mean(losses)\n            learning_rate = self.optimizer.state_dict()['param_groups'][0]['lr']\n            print(f'Epoch {epoch+1}: Training Loss: {mean_loss:.6f}, Learning Rate: {learning_rate:.6f}')\n            if  mean_loss < best_loss:\n                model_path = rf'{self.params.model_dir}/epoch{epoch+1}_loss{mean_loss}.pth'\n                torch.save(self.model.state_dict(), model_path)\n                print(\"model save in \" + model_path)\n                best_loss = mean_loss"}
{"_id": "beir_output_pretrain_main.py", "title": "", "text": "import argparse\nimport random\nimport numpy as np\nimport torch\nfrom torch.utils.data import DataLoader\n\nfrom datasets.pretraining_dataset import PretrainingDataset\nfrom models.cbramod import CBraMod\nfrom pretrain_trainer import Trainer\n\n\ndef setup_seed(seed):\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    np.random.seed(seed)\n    random.seed(seed)\n    torch.backends.cudnn.deterministic = True\n\n\ndef main():\n    parser = argparse.ArgumentParser(description='EEG Foundation Model')\n    parser.add_argument('--seed', type=int, default=42, help='random seed (default: 0)')\n    parser.add_argument('--cuda', type=int, default=3, help='cuda number (default: 1)')\n    parser.add_argument('--parallel', type=bool, default=False, help='parallel')\n    parser.add_argument('--epochs', type=int, default=40, help='number of epochs (default: 5)')\n    parser.add_argument('--batch_size', type=int, default=128, help='batch size for training (default: 32)')\n    parser.add_argument('--lr', type=float, default=5e-4, help='learning rate (default: 1e-3)')\n    parser.add_argument('--weight_decay', type=float, default=5e-2, help='weight_decay')\n    parser.add_argument('--clip_value', type=float, default=1, help='clip_value')\n    parser.add_argument('--lr_scheduler', type=str, default='CosineAnnealingLR',\n                        help='lr_scheduler: CosineAnnealingLR, ExponentialLR, StepLR, MultiStepLR, CyclicLR')\n\n    # parser.add_argument('--project_mode', type=str, default='cnn', help='project_mode')\n    parser.add_argument('--dropout', type=float, default=0.1, help='dropout')\n    parser.add_argument('--in_dim', type=int, default=200, help='in_dim')\n    parser.add_argument('--out_dim', type=int, default=200, help='out_dim')\n    parser.add_argument('--d_model', type=int, default=200, help='d_model')\n    parser.add_argument('--dim_feedforward', type=int, default=800, help='dim_feedforward')\n    parser.add_argument('--seq_len', type=int, default=30, help='seq_len')\n    parser.add_argument('--n_layer', type=int, default=12, help='n_layer')\n    parser.add_argument('--nhead', type=int, default=8, help='nhead')\n    parser.add_argument('--need_mask', type=bool, default=True, help='need_mask')\n    parser.add_argument('--mask_ratio', type=float, default=0.5, help='mask_ratio')\n\n    parser.add_argument('--dataset_dir', type=str, default='dataset_dir',\n                        help='dataset_dir')\n    parser.add_argument('--model_dir',   type=str,   default='model_dir', help='model_dir')\n    params = parser.parse_args()\n    print(params)\n    setup_seed(params.seed)\n    pretrained_dataset = PretrainingDataset(dataset_dir=params.dataset_dir)\n    print(len(pretrained_dataset))\n    data_loader = DataLoader(\n        pretrained_dataset,\n        batch_size=params.batch_size,\n        num_workers=8,\n        shuffle=True,\n    )\n    model = CBraMod(\n        params.in_dim, params.out_dim, params.d_model, params.dim_feedforward, params.seq_len, params.n_layer,\n        params.nhead\n    )\n    trainer = Trainer(params, data_loader, model)\n    trainer.train()\n    pretrained_dataset.db.close()\n\n\nif __name__ == '__main__':\n    main()\n"}
{"_id": "beir_output_quick_example.py", "title": "", "text": "import torch\nimport torch.nn as nn\nfrom models.cbramod import CBraMod\nfrom einops.layers.torch import Rearrange\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nmodel = CBraMod().to(device)\nmodel.load_state_dict(torch.load('pretrained_weights/pretrained_weights.pth', map_location=device))\nmodel.proj_out = nn.Identity()\nclassifier = nn.Sequential(\n  Rearrange('b c s p -> b (c s p)'),\n  nn.Linear(22*4*200, 4*200),\n  nn.ELU(),\n  nn.Dropout(0.1),\n  nn.Linear(4 * 200, 200),\n  nn.ELU(),\n  nn.Dropout(0.1),\n  nn.Linear(200, 4),\n).to(device)\n\n# mock_eeg.shape = (batch_size, num_of_channels, time_segments, points_per_patch)\nmock_eeg = torch.randn((8, 22, 4, 200)).to(device)\n\n# logits.shape = (batch_size, num_of_classes)\nlogits = classifier(model(mock_eeg))\n\nprint(logits.shape)"}
{"_id": "beir_output_finetune_trainer.py", "title": "", "text": "import torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader\n# from models.model_for_faced import Model\nfrom tqdm import tqdm\nimport torch\nfrom finetune_evaluator import Evaluator\nfrom torch.nn import CrossEntropyLoss, BCEWithLogitsLoss, MSELoss\nfrom timeit import default_timer as timer\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.manifold import TSNE\nimport matplotlib as mpl\nimport umap\nfrom sklearn.decomposition import PCA\nimport copy\nimport os\n\n\nclass Trainer(object):\n    def __init__(self, params, data_loader, model):\n        self.params = params\n        self.data_loader = data_loader\n\n        self.val_eval = Evaluator(params, self.data_loader['val'])\n        self.test_eval = Evaluator(params, self.data_loader['test'])\n\n        self.model = model.cuda()\n        if self.params.downstream_dataset in ['FACED', 'SEED-V', 'PhysioNet-MI', 'ISRUC', 'BCIC2020-3', 'TUEV', 'BCIC-IV-2a']:\n            self.criterion = CrossEntropyLoss(label_smoothing=self.params.label_smoothing).cuda()\n        elif self.params.downstream_dataset in ['SHU-MI', 'CHB-MIT', 'Mumtaz2016', 'MentalArithmetic', 'TUAB']:\n            self.criterion = BCEWithLogitsLoss().cuda()\n        elif self.params.downstream_dataset == 'SEED-VIG':\n            self.criterion = MSELoss().cuda()\n\n        self.best_model_states = None\n\n        backbone_params = []\n        other_params = []\n        for name, param in self.model.named_parameters():\n            if \"backbone\" in name:\n                backbone_params.append(param)\n\n                if params.frozen:\n                    param.requires_grad = False\n                else:\n                    param.requires_grad = True\n            else:\n                other_params.append(param)\n\n        if self.params.optimizer == 'AdamW':\n            if self.params.multi_lr: # set different learning rates for different modules\n                self.optimizer = torch.optim.AdamW([\n                    {'params': backbone_params, 'lr': self.params.lr},\n                    {'params': other_params, 'lr': self.params.lr * 5}\n                ], weight_decay=self.params.weight_decay)\n            else:\n                self.optimizer = torch.optim.AdamW(self.model.parameters(), lr=self.params.lr,\n                                                   weight_decay=self.params.weight_decay)\n        else:\n            if self.params.multi_lr:\n                self.optimizer = torch.optim.SGD([\n                    {'params': backbone_params, 'lr': self.params.lr},\n                    {'params': other_params, 'lr': self.params.lr * 5}\n                ],  momentum=0.9, weight_decay=self.params.weight_decay)\n            else:\n                self.optimizer = torch.optim.SGD(self.model.parameters(), lr=self.params.lr, momentum=0.9,\n                                                 weight_decay=self.params.weight_decay)\n\n        self.data_length = len(self.data_loader['train'])\n        self.optimizer_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n            self.optimizer, T_max=self.params.epochs * self.data_length, eta_min=1e-6\n        )\n        print(self.model)\n\n    def train_for_multiclass(self):\n        f1_best = 0\n        kappa_best = 0\n        acc_best = 0\n        cm_best = None\n        for epoch in range(self.params.epochs):\n            self.model.train()\n            start_time = timer()\n            losses = []\n            for x, y in tqdm(self.data_loader['train'], mininterval=10):\n                self.optimizer.zero_grad()\n                x = x.cuda()\n                y = y.cuda()\n                pred = self.model(x)\n                if self.params.downstream_dataset == 'ISRUC':\n                    loss = self.criterion(pred.transpose(1, 2), y)\n                else:\n                    loss = self.criterion(pred, y)\n\n                loss.backward()\n                losses.append(loss.data.cpu().numpy())\n                if self.params.clip_value > 0:\n                    torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.params.clip_value)\n                    # torch.nn.utils.clip_grad_value_(self.model.parameters(), self.params.clip_value)\n                self.optimizer.step()\n                self.optimizer_scheduler.step()\n\n            optim_state = self.optimizer.state_dict()\n\n            with torch.no_grad():\n                acc, kappa, f1, cm = self.val_eval.get_metrics_for_multiclass(self.model)\n                print(\n                    \"Epoch {} : Training Loss: {:.5f}, acc: {:.5f}, kappa: {:.5f}, f1: {:.5f}, LR: {:.5f}, Time elapsed {:.2f} mins\".format(\n                        epoch + 1,\n                        np.mean(losses),\n                        acc,\n                        kappa,\n                        f1,\n                        optim_state['param_groups'][0]['lr'],\n                        (timer() - start_time) / 60\n                    )\n                )\n                print(cm)\n                if kappa > kappa_best:\n                    print(\"kappa increasing....saving weights !! \")\n                    print(\"Val Evaluation: acc: {:.5f}, kappa: {:.5f}, f1: {:.5f}\".format(\n                        acc,\n                        kappa,\n                        f1,\n                    ))\n                    best_f1_epoch = epoch + 1\n                    acc_best = acc\n                    kappa_best = kappa\n                    f1_best = f1\n                    cm_best = cm\n                    self.best_model_states = copy.deepcopy(self.model.state_dict())\n        self.model.load_state_dict(self.best_model_states)\n        with torch.no_grad():\n            print(\"***************************Test************************\")\n            acc, kappa, f1, cm = self.test_eval.get_metrics_for_multiclass(self.model)\n            print(\"***************************Test results************************\")\n            print(\n                \"Test Evaluation: acc: {:.5f}, kappa: {:.5f}, f1: {:.5f}\".format(\n                    acc,\n                    kappa,\n                    f1,\n                )\n            )\n            print(cm)\n            if not os.path.isdir(self.params.model_dir):\n                os.makedirs(self.params.model_dir)\n            model_path = self.params.model_dir + \"/epoch{}_acc_{:.5f}_kappa_{:.5f}_f1_{:.5f}.pth\".format(best_f1_epoch, acc, kappa, f1)\n            torch.save(self.model.state_dict(), model_path)\n            print(\"model save in \" + model_path)\n\n    def train_for_binaryclass(self):\n        acc_best = 0\n        roc_auc_best = 0\n        pr_auc_best = 0\n        cm_best = None\n        for epoch in range(self.params.epochs):\n            self.model.train()\n            start_time = timer()\n            losses = []\n            for x, y in tqdm(self.data_loader['train'], mininterval=10):\n                self.optimizer.zero_grad()\n                x = x.cuda()\n                y = y.cuda()\n                pred = self.model(x)\n\n                loss = self.criterion(pred, y)\n\n                loss.backward()\n                losses.append(loss.data.cpu().numpy())\n                if self.params.clip_value > 0:\n                    torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.params.clip_value)\n                    # torch.nn.utils.clip_grad_value_(self.model.parameters(), self.params.clip_value)\n                self.optimizer.step()\n                self.optimizer_scheduler.step()\n\n            optim_state = self.optimizer.state_dict()\n\n            with torch.no_grad():\n                acc, pr_auc, roc_auc, cm = self.val_eval.get_metrics_for_binaryclass(self.model)\n                print(\n                    \"Epoch {} : Training Loss: {:.5f}, acc: {:.5f}, pr_auc: {:.5f}, roc_auc: {:.5f}, LR: {:.5f}, Time elapsed {:.2f} mins\".format(\n                        epoch + 1,\n                        np.mean(losses),\n                        acc,\n                        pr_auc,\n                        roc_auc,\n                        optim_state['param_groups'][0]['lr'],\n                        (timer() - start_time) / 60\n                    )\n                )\n                print(cm)\n                if roc_auc > roc_auc_best:\n                    print(\"kappa increasing....saving weights !! \")\n                    print(\"Val Evaluation: acc: {:.5f}, pr_auc: {:.5f}, roc_auc: {:.5f}\".format(\n                        acc,\n                        pr_auc,\n                        roc_auc,\n                    ))\n                    best_f1_epoch = epoch + 1\n                    acc_best = acc\n                    pr_auc_best = pr_auc\n                    roc_auc_best = roc_auc\n                    cm_best = cm\n                    self.best_model_states = copy.deepcopy(self.model.state_dict())\n        self.model.load_state_dict(self.best_model_states)\n        with torch.no_grad():\n            print(\"***************************Test************************\")\n            acc, pr_auc, roc_auc, cm = self.test_eval.get_metrics_for_binaryclass(self.model)\n            print(\"***************************Test results************************\")\n            print(\n                \"Test Evaluation: acc: {:.5f}, pr_auc: {:.5f}, roc_auc: {:.5f}\".format(\n                    acc,\n                    pr_auc,\n                    roc_auc,\n                )\n            )\n            print(cm)\n            if not os.path.isdir(self.params.model_dir):\n                os.makedirs(self.params.model_dir)\n            model_path = self.params.model_dir + \"/epoch{}_acc_{:.5f}_pr_{:.5f}_roc_{:.5f}.pth\".format(best_f1_epoch, acc, pr_auc, roc_auc)\n            torch.save(self.model.state_dict(), model_path)\n            print(\"model save in \" + model_path)\n\n    def train_for_regression(self):\n        corrcoef_best = 0\n        r2_best = 0\n        rmse_best = 0\n        for epoch in range(self.params.epochs):\n            self.model.train()\n            start_time = timer()\n            losses = []\n            for x, y in tqdm(self.data_loader['train'], mininterval=10):\n                self.optimizer.zero_grad()\n                x = x.cuda()\n                y = y.cuda()\n                pred = self.model(x)\n                loss = self.criterion(pred, y)\n\n                loss.backward()\n                losses.append(loss.data.cpu().numpy())\n                if self.params.clip_value > 0:\n                    torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.params.clip_value)\n                    # torch.nn.utils.clip_grad_value_(self.model.parameters(), self.params.clip_value)\n                self.optimizer.step()\n                self.optimizer_scheduler.step()\n\n            optim_state = self.optimizer.state_dict()\n\n            with torch.no_grad():\n                corrcoef, r2, rmse = self.val_eval.get_metrics_for_regression(self.model)\n                print(\n                    \"Epoch {} : Training Loss: {:.5f}, corrcoef: {:.5f}, r2: {:.5f}, rmse: {:.5f}, LR: {:.5f}, Time elapsed {:.2f} mins\".format(\n                        epoch + 1,\n                        np.mean(losses),\n                        corrcoef,\n                        r2,\n                        rmse,\n                        optim_state['param_groups'][0]['lr'],\n                        (timer() - start_time) / 60\n                    )\n                )\n                if r2 > r2_best:\n                    print(\"kappa increasing....saving weights !! \")\n                    print(\"Val Evaluation: corrcoef: {:.5f}, r2: {:.5f}, rmse: {:.5f}\".format(\n                        corrcoef,\n                        r2,\n                        rmse,\n                    ))\n                    best_r2_epoch = epoch + 1\n                    corrcoef_best = corrcoef\n                    r2_best = r2\n                    rmse_best = rmse\n                    self.best_model_states = copy.deepcopy(self.model.state_dict())\n\n        self.model.load_state_dict(self.best_model_states)\n        with torch.no_grad():\n            print(\"***************************Test************************\")\n            corrcoef, r2, rmse = self.test_eval.get_metrics_for_regression(self.model)\n            print(\"***************************Test results************************\")\n            print(\n                \"Test Evaluation: corrcoef: {:.5f}, r2: {:.5f}, rmse: {:.5f}\".format(\n                    corrcoef,\n                    r2,\n                    rmse,\n                )\n            )\n\n            if not os.path.isdir(self.params.model_dir):\n                os.makedirs(self.params.model_dir)\n            model_path = self.params.model_dir + \"/epoch{}_corrcoef_{:.5f}_r2_{:.5f}_rmse_{:.5f}.pth\".format(best_r2_epoch, corrcoef, r2, rmse)\n            torch.save(self.model.state_dict(), model_path)\n            print(\"model save in \" + model_path)"}
{"_id": "beir_output_models/model_for_mumtaz.py", "title": "", "text": "import torch\nimport torch.nn as nn\nfrom einops.layers.torch import Rearrange\n\nfrom .cbramod import CBraMod\n\n\nclass Model(nn.Module):\n    def __init__(self, param):\n        super(Model, self).__init__()\n        self.backbone = CBraMod(\n            in_dim=200, out_dim=200, d_model=200,\n            dim_feedforward=800, seq_len=30,\n            n_layer=12, nhead=8\n        )\n        if param.use_pretrained_weights:\n            map_location = torch.device(f'cuda:{param.cuda}')\n            self.backbone.load_state_dict(torch.load(param.foundation_dir, map_location=map_location))\n        self.backbone.proj_out = nn.Identity()\n        if param.classifier == 'avgpooling_patch_reps':\n            self.classifier = nn.Sequential(\n                Rearrange('b c s d -> b d c s'),\n                nn.AdaptiveAvgPool2d((1, 1)),\n                nn.Flatten(),\n                nn.Linear(200, 1),\n                Rearrange('b 1 -> (b 1)'),\n            )\n        elif param.classifier == 'all_patch_reps':\n            self.classifier = nn.Sequential(\n                Rearrange('b c s d -> b (c s d)'),\n                nn.Linear(19 * 5 * 200, 5 * 200),\n                nn.ELU(),\n                nn.Dropout(param.dropout),\n                nn.Linear(5 * 200, 200),\n                nn.ELU(),\n                nn.Dropout(param.dropout),\n                nn.Linear(200, 1),\n                Rearrange('b 1 -> (b 1)'),\n            )\n\n    def forward(self, x):\n        bz, ch_num, seq_len, patch_size = x.shape\n        feats = self.backbone(x)\n        out = self.classifier(feats)\n        return out\n"}
{"_id": "beir_output_models/model_for_seedv.py", "title": "", "text": "import torch\nimport torch.nn as nn\nfrom einops.layers.torch import Rearrange\n\nfrom .cbramod import CBraMod\n\n\nclass Model(nn.Module):\n    def __init__(self, param):\n        super(Model, self).__init__()\n        self.backbone = CBraMod(\n            in_dim=200, out_dim=200, d_model=200,\n            dim_feedforward=800, seq_len=30,\n            n_layer=12, nhead=8\n        )\n        if param.use_pretrained_weights:\n            map_location = torch.device(f'cuda:{param.cuda}')\n            self.backbone.load_state_dict(torch.load(param.foundation_dir, map_location=map_location))\n        self.backbone.proj_out = nn.Identity()\n        if param.classifier == 'avgpooling_patch_reps':\n            self.classifier = nn.Sequential(\n                Rearrange('b c s d -> b d c s'),\n                nn.AdaptiveAvgPool2d((1, 1)),\n                nn.Flatten(),\n                nn.Linear(200, param.num_of_classes),\n            )\n        elif param.classifier == 'all_patch_reps':\n            self.classifier = nn.Sequential(\n                Rearrange('b c s d -> b (c s d)'),\n                nn.Linear(62 * 1 * 200, 4 * 200),\n                nn.ELU(),\n                nn.Dropout(param.dropout),\n                nn.Linear(4 * 200, 200),\n                nn.ELU(),\n                nn.Dropout(param.dropout),\n                nn.Linear(200, param.num_of_classes),\n            )\n\n    def forward(self, x):\n        # x = x / 100\n        bz, ch_num, seq_len, patch_size = x.shape\n        feats = self.backbone(x)\n        feats = feats.contiguous().view(bz, ch_num*seq_len*200)\n        out = self.classifier(feats)\n        return out\n"}
{"_id": "beir_output_models/model_for_faced.py", "title": "", "text": "import torch\nimport torch.nn as nn\nfrom einops.layers.torch import Rearrange\n\nfrom .cbramod import CBraMod\n\n\nclass Model(nn.Module):\n    def __init__(self, param):\n        super(Model, self).__init__()\n        self.backbone = CBraMod(\n            in_dim=200, out_dim=200, d_model=200,\n            dim_feedforward=800, seq_len=30,\n            n_layer=12, nhead=8\n        )\n\n        if param.use_pretrained_weights:\n            map_location = torch.device(f'cuda:{param.cuda}')\n            self.backbone.load_state_dict(torch.load(param.foundation_dir, map_location=map_location))\n        self.backbone.proj_out = nn.Identity()\n\n        if param.classifier == 'avgpooling_patch_reps':\n            self.classifier = nn.Sequential(\n                Rearrange('b c s d -> b d c s'),\n                nn.AdaptiveAvgPool2d((1, 1)),\n                nn.Flatten(),\n                nn.Linear(200, param.num_of_classes),\n            )\n        elif param.classifier == 'all_patch_reps':\n            self.classifier = nn.Sequential(\n                Rearrange('b c s d -> b (c s d)'),\n                nn.Linear(32 * 10 * 200, 10 * 200),\n                nn.ELU(),\n                nn.Dropout(param.dropout),\n                nn.Linear(10 * 200, 200),\n                nn.ELU(),\n                nn.Dropout(param.dropout),\n                nn.Linear(200, param.num_of_classes),\n            )\n\n    def forward(self, x):\n        bz, ch_num, seq_len, patch_size = x.shape\n        feats = self.backbone(x)\n        out = self.classifier(feats)\n        return out\n\n\n\n"}
{"_id": "beir_output_models/criss_cross_transformer.py", "title": "", "text": "import copy\nfrom typing import Optional, Any, Union, Callable\n\nimport torch\nimport torch.nn as nn\n# import torch.nn.functional as F\nimport warnings\nfrom torch import Tensor\nfrom torch.nn import functional as F\n\n\nclass TransformerEncoder(nn.Module):\n    def __init__(self, encoder_layer, num_layers, norm=None, enable_nested_tensor=True, mask_check=True):\n        super().__init__()\n        torch._C._log_api_usage_once(f\"torch.nn.modules.{self.__class__.__name__}\")\n        self.layers = _get_clones(encoder_layer, num_layers)\n        self.num_layers = num_layers\n        self.norm = norm\n\n    def forward(\n            self,\n            src: Tensor,\n            mask: Optional[Tensor] = None,\n            src_key_padding_mask: Optional[Tensor] = None,\n            is_causal: Optional[bool] = None) -> Tensor:\n\n        output = src\n        for mod in self.layers:\n            output = mod(output, src_mask=mask)\n        if self.norm is not None:\n            output = self.norm(output)\n        return output\n\n\nclass TransformerEncoderLayer(nn.Module):\n    __constants__ = ['norm_first']\n\n    def __init__(self, d_model: int, nhead: int, dim_feedforward: int = 2048, dropout: float = 0.1,\n                 activation: Union[str, Callable[[Tensor], Tensor]] = F.relu,\n                 layer_norm_eps: float = 1e-5, batch_first: bool = False, norm_first: bool = False,\n                 bias: bool = True, device=None, dtype=None) -> None:\n        factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__()\n        self.self_attn_s = nn.MultiheadAttention(d_model//2, nhead // 2, dropout=dropout,\n                                                 bias=bias, batch_first=batch_first,\n                                                 **factory_kwargs)\n        self.self_attn_t = nn.MultiheadAttention(d_model//2, nhead // 2, dropout=dropout,\n                                                 bias=bias, batch_first=batch_first,\n                                                 **factory_kwargs)\n\n        # Implementation of Feedforward model\n        self.linear1 = nn.Linear(d_model, dim_feedforward, bias=bias, **factory_kwargs)\n        self.dropout = nn.Dropout(dropout)\n        self.linear2 = nn.Linear(dim_feedforward, d_model, bias=bias, **factory_kwargs)\n\n        self.norm_first = norm_first\n        self.norm1 = nn.LayerNorm(d_model, eps=layer_norm_eps, **factory_kwargs)\n        self.norm2 = nn.LayerNorm(d_model, eps=layer_norm_eps, **factory_kwargs)\n        self.dropout1 = nn.Dropout(dropout)\n        self.dropout2 = nn.Dropout(dropout)\n\n        # Legacy string support for activation function.\n        if isinstance(activation, str):\n            activation = _get_activation_fn(activation)\n\n        # We can't test self.activation in forward() in TorchScript,\n        # so stash some information about it instead.\n        if activation is F.relu or isinstance(activation, torch.nn.ReLU):\n            self.activation_relu_or_gelu = 1\n        elif activation is F.gelu or isinstance(activation, torch.nn.GELU):\n            self.activation_relu_or_gelu = 2\n        else:\n            self.activation_relu_or_gelu = 0\n        self.activation = activation\n\n    def __setstate__(self, state):\n        super().__setstate__(state)\n        if not hasattr(self, 'activation'):\n            self.activation = F.relu\n\n\n    def forward(\n            self,\n            src: Tensor,\n            src_mask: Optional[Tensor] = None,\n            src_key_padding_mask: Optional[Tensor] = None,\n            is_causal: bool = False) -> Tensor:\n\n        x = src\n        x = x + self._sa_block(self.norm1(x), src_mask, src_key_padding_mask, is_causal=is_causal)\n        x = x + self._ff_block(self.norm2(x))\n        return x\n\n    # self-attention block\n    def _sa_block(self, x: Tensor,\n                  attn_mask: Optional[Tensor], key_padding_mask: Optional[Tensor], is_causal: bool = False) -> Tensor:\n        bz, ch_num, patch_num, patch_size = x.shape\n        xs = x[:, :, :, :patch_size // 2]\n        xt = x[:, :, :, patch_size // 2:]\n        xs = xs.transpose(1, 2).contiguous().view(bz*patch_num, ch_num, patch_size // 2)\n        xt = xt.contiguous().view(bz*ch_num, patch_num, patch_size // 2)\n        xs = self.self_attn_s(xs, xs, xs,\n                             attn_mask=attn_mask,\n                             key_padding_mask=key_padding_mask,\n                             need_weights=False)[0]\n        xs = xs.contiguous().view(bz, patch_num, ch_num, patch_size//2).transpose(1, 2)\n        xt = self.self_attn_t(xt, xt, xt,\n                              attn_mask=attn_mask,\n                              key_padding_mask=key_padding_mask,\n                              need_weights=False)[0]\n        xt = xt.contiguous().view(bz, ch_num, patch_num, patch_size//2)\n        x = torch.concat((xs, xt), dim=3)\n        return self.dropout1(x)\n\n    # feed forward block\n    def _ff_block(self, x: Tensor) -> Tensor:\n        x = self.linear2(self.dropout(self.activation(self.linear1(x))))\n        return self.dropout2(x)\n\n\n\ndef _get_activation_fn(activation: str) -> Callable[[Tensor], Tensor]:\n    if activation == \"relu\":\n        return F.relu\n    elif activation == \"gelu\":\n        return F.gelu\n\n    raise RuntimeError(f\"activation should be relu/gelu, not {activation}\")\n\ndef _get_clones(module, N):\n    # FIXME: copy.deepcopy() is not defined on nn.module\n    return nn.ModuleList([copy.deepcopy(module) for i in range(N)])\n\n\ndef _get_seq_len(\n        src: Tensor,\n        batch_first: bool\n) -> Optional[int]:\n\n    if src.is_nested:\n        return None\n    else:\n        src_size = src.size()\n        if len(src_size) == 2:\n            # unbatched: S, E\n            return src_size[0]\n        else:\n            # batched: B, S, E if batch_first else S, B, E\n            seq_len_pos = 1 if batch_first else 0\n            return src_size[seq_len_pos]\n\n\ndef _detect_is_causal_mask(\n        mask: Optional[Tensor],\n        is_causal: Optional[bool] = None,\n        size: Optional[int] = None,\n) -> bool:\n    \"\"\"Return whether the given attention mask is causal.\n\n    Warning:\n    If ``is_causal`` is not ``None``, its value will be returned as is.  If a\n    user supplies an incorrect ``is_causal`` hint,\n\n    ``is_causal=False`` when the mask is in fact a causal attention.mask\n       may lead to reduced performance relative to what would be achievable\n       with ``is_causal=True``;\n    ``is_causal=True`` when the mask is in fact not a causal attention.mask\n       may lead to incorrect and unpredictable execution - in some scenarios,\n       a causal mask may be applied based on the hint, in other execution\n       scenarios the specified mask may be used.  The choice may not appear\n       to be deterministic, in that a number of factors like alignment,\n       hardware SKU, etc influence the decision whether to use a mask or\n       rely on the hint.\n    ``size`` if not None, check whether the mask is a causal mask of the provided size\n       Otherwise, checks for any causal mask.\n    \"\"\"\n    # Prevent type refinement\n    make_causal = (is_causal is True)\n\n    if is_causal is None and mask is not None:\n        sz = size if size is not None else mask.size(-2)\n        causal_comparison = _generate_square_subsequent_mask(\n            sz, device=mask.device, dtype=mask.dtype)\n\n        # Do not use `torch.equal` so we handle batched masks by\n        # broadcasting the comparison.\n        if mask.size() == causal_comparison.size():\n            make_causal = bool((mask == causal_comparison).all())\n        else:\n            make_causal = False\n\n    return make_causal\n\n\ndef _generate_square_subsequent_mask(\n        sz: int,\n        device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n        dtype: torch.dtype = torch.get_default_dtype(),\n) -> Tensor:\n    r\"\"\"Generate a square causal mask for the sequence. The masked positions are filled with float('-inf').\n        Unmasked positions are filled with float(0.0).\n    \"\"\"\n    return torch.triu(\n        torch.full((sz, sz), float('-inf'), dtype=dtype, device=device),\n        diagonal=1,\n    )\n\n\nif __name__ == '__main__':\n    encoder_layer = TransformerEncoderLayer(\n        d_model=256, nhead=4, dim_feedforward=1024, batch_first=True, norm_first=True,\n        activation=F.gelu\n    )\n    encoder = TransformerEncoder(encoder_layer, num_layers=2, enable_nested_tensor=False)\n    encoder = encoder.cuda()\n\n    a = torch.randn((4, 19, 30, 256)).cuda()\n    b = encoder(a)\n    print(a.shape, b.shape)"}
{"_id": "beir_output_models/model_for_tuev.py", "title": "", "text": "import torch\nimport torch.nn as nn\nfrom einops.layers.torch import Rearrange\n\nfrom .cbramod import CBraMod\n\n\nclass Model(nn.Module):\n    def __init__(self, param):\n        super(Model, self).__init__()\n        self.backbone = CBraMod(\n            in_dim=200, out_dim=200, d_model=200,\n            dim_feedforward=800, seq_len=30,\n            n_layer=12, nhead=8\n        )\n        if param.use_pretrained_weights:\n            map_location = torch.device(f'cuda:{param.cuda}')\n            self.backbone.load_state_dict(torch.load(param.foundation_dir, map_location=map_location))\n        self.backbone.proj_out = nn.Identity()\n\n        if param.classifier == 'avgpooling_patch_reps':\n            self.classifier = nn.Sequential(\n                Rearrange('b c s d -> b d c s'),\n                nn.AdaptiveAvgPool2d((1, 1)),\n                nn.Flatten(),\n                nn.Linear(200, param.num_of_classes),\n            )\n        elif param.classifier == 'all_patch_reps':\n            self.classifier = nn.Sequential(\n                Rearrange('b c s d -> b (c s d)'),\n                nn.Linear(16 * 5 * 200, 5 * 200),\n                nn.ELU(),\n                nn.Dropout(param.dropout),\n                nn.Linear(5 * 200, 200),\n                nn.ELU(),\n                nn.Dropout(param.dropout),\n                nn.Linear(200, param.num_of_classes),\n            )\n\n    def forward(self, x):\n        bz, ch_num, seq_len, patch_size = x.shape\n        feats = self.backbone(x)\n        out = self.classifier(feats)\n        return out\n\n"}
{"_id": "beir_output_models/model_for_isruc.py", "title": "", "text": "import torch\nimport torch.nn as nn\n\nfrom .cbramod import CBraMod\n\n\nclass Model(nn.Module):\n    def __init__(self, param):\n        super().__init__()\n        self.backbone = CBraMod(\n            in_dim=200, out_dim=200, d_model=200,\n            dim_feedforward=800, seq_len=30,\n            n_layer=12, nhead=8\n        )\n        if param.use_pretrained_weights:\n            map_location = torch.device(f'cuda:{param.cuda}')\n            self.backbone.load_state_dict(torch.load(param.foundation_dir, map_location=map_location))\n        self.backbone.proj_out = nn.Identity()\n\n        self.head = nn.Sequential(\n            nn.Linear(6*30*200, 512),\n            nn.GELU(),\n        )\n\n        encoder_layer = nn.TransformerEncoderLayer(\n            d_model=512, nhead=4, dim_feedforward=2048, batch_first=True, activation=F.gelu, norm_first=True\n        )\n        self.sequence_encoder = nn.TransformerEncoder(encoder_layer, num_layers=1, enable_nested_tensor=False)\n        self.classifier = nn.Linear(512, param.num_of_classes)\n\n        # self.apply(_weights_init)\n\n    def forward(self, x):\n        bz, seq_len, ch_num, epoch_size = x.shape\n\n        x = x.contiguous().view(bz * seq_len, ch_num, 30, 200)\n        epoch_features = self.backbone(x)\n        epoch_features = epoch_features.contiguous().view(bz, seq_len, ch_num*30*200)\n        epoch_features = self.head(epoch_features)\n        seq_features = self.sequence_encoder(epoch_features)\n        out = self.classifier(seq_features)\n        return out\n"}
{"_id": "beir_output_models/model_for_speech.py", "title": "", "text": "import torch\nimport torch.nn as nn\nfrom einops.layers.torch import Rearrange\n\nfrom .cbramod import CBraMod\n\n\nclass Model(nn.Module):\n    def __init__(self, param):\n        super(Model, self).__init__()\n        self.backbone = CBraMod(\n            in_dim=200, out_dim=200, d_model=200,\n            dim_feedforward=800, seq_len=30,\n            n_layer=12, nhead=8\n        )\n        if param.use_pretrained_weights:\n            map_location = torch.device(f'cuda:{param.cuda}')\n            self.backbone.load_state_dict(torch.load(param.foundation_dir, map_location=map_location))\n        self.backbone.proj_out = nn.Identity()\n        if param.classifier == 'avgpooling_patch_reps':\n            self.classifier = nn.Sequential(\n                Rearrange('b c s d -> b d c s'),\n                nn.AdaptiveAvgPool2d((1, 1)),\n                nn.Flatten(),\n                nn.Linear(200, param.num_of_classes)\n            )\n        elif param.classifier == 'all_patch_reps':\n            self.classifier = nn.Sequential(\n                Rearrange('b c s d -> b (c s d)'),\n                nn.Linear(64*3*200, 3*200),\n                nn.ELU(),\n                nn.Dropout(param.dropout),\n                nn.Linear(3*200, 200),\n                nn.ELU(),\n                nn.Dropout(param.dropout),\n                nn.Linear(200, param.num_of_classes),\n            )\n\n    def forward(self, x):\n        bz, ch_num, seq_len, patch_size = x.shape\n        feats = self.backbone(x)\n        out = self.classifier(feats)\n        return out\n\n"}
{"_id": "beir_output_models/model_for_chb.py", "title": "", "text": "import torch\nimport torch.nn as nn\nfrom einops.layers.torch import Rearrange\nfrom .cbramod import CBraMod\n\n\nclass Model(nn.Module):\n    def __init__(self, param):\n        super(Model, self).__init__()\n        self.backbone = CBraMod(\n            in_dim=200, out_dim=200, d_model=200,\n            dim_feedforward=800, seq_len=30,\n            n_layer=12, nhead=8\n        )\n        if param.use_pretrained_weights:\n            map_location = torch.device(f'cuda:{param.cuda}')\n            self.backbone.load_state_dict(torch.load(param.foundation_dir, map_location=map_location))\n        self.backbone.proj_out = nn.Identity()\n\n        if param.classifier == 'avgpooling_patch_reps':\n            self.classifier = nn.Sequential(\n                Rearrange('b c s d -> b d c s'),\n                nn.AdaptiveAvgPool2d((1, 1)),\n                nn.Flatten(),\n                nn.Linear(200, 1),\n                Rearrange('b 1 -> (b 1)'),\n            )\n        elif param.classifier == 'all_patch_reps':\n            self.classifier = nn.Sequential(\n                Rearrange('b c s d -> b (c s d)'),\n                nn.Linear(16*10*200, 10*200),\n                nn.ELU(),\n                nn.Dropout(param.dropout),\n                nn.Linear(10*200, 200),\n                nn.ELU(),\n                nn.Dropout(param.dropout),\n                nn.Linear(200, 1),\n                Rearrange('b 1 -> (b 1)'),\n            )\n\n    def forward(self, x):\n        bz, ch_num, seq_len, patch_size = x.shape\n        feats = self.backbone(x)\n        out = self.classifier(feats)\n        return out"}
{"_id": "beir_output_models/model_for_bciciv2a.py", "title": "", "text": "import torch\nimport torch.nn as nn\nfrom einops.layers.torch import Rearrange\nfrom .cbramod import CBraMod\n\n\nclass Model(nn.Module):\n    def __init__(self, param):\n        super(Model, self).__init__()\n        self.backbone = CBraMod(\n            in_dim=200, out_dim=200, d_model=200,\n            dim_feedforward=800, seq_len=30,\n            n_layer=12, nhead=8\n        )\n        if param.use_pretrained_weights:\n            map_location = torch.device(f'cuda:{param.cuda}')\n            self.backbone.load_state_dict(torch.load(param.foundation_dir, map_location=map_location))\n        self.backbone.proj_out = nn.Identity()\n        if param.classifier == 'avgpooling_patch_reps':\n            self.classifier = nn.Sequential(\n                Rearrange('b c s d -> b d c s'),\n                nn.AdaptiveAvgPool2d((1, 1)),\n                nn.Flatten(),\n                nn.Linear(200, param.num_of_classes),\n            )\n        elif param.classifier == 'all_patch_reps':\n            self.classifier = nn.Sequential(\n                Rearrange('b c s d -> b (c s d)'),\n                nn.Linear(22 * 4 * 200, 4 * 200),\n                nn.ELU(),\n                nn.Dropout(param.dropout),\n                nn.Linear(4 * 200, 200),\n                nn.ELU(),\n                nn.Dropout(param.dropout),\n                nn.Linear(200, param.num_of_classes),\n            )\n\n    def forward(self, x):\n        # x = x / 100\n        bz, ch_num, seq_len, patch_size = x.shape\n        feats = self.backbone(x)\n        out = self.classifier(feats)\n        return out\n"}
{"_id": "beir_output_models/model_for_stress.py", "title": "", "text": "import torch\nimport torch.nn as nn\nfrom einops.layers.torch import Rearrange\n\nfrom .cbramod import CBraMod\n\nclass Model(nn.Module):\n    def __init__(self, param):\n        super(Model, self).__init__()\n        self.backbone = CBraMod(\n            in_dim=200, out_dim=200, d_model=200,\n            dim_feedforward=800, seq_len=30,\n            n_layer=12, nhead=8\n        )\n        if param.use_pretrained_weights:\n            map_location = torch.device(f'cuda:{param.cuda}')\n            self.backbone.load_state_dict(torch.load(param.foundation_dir, map_location=map_location))\n        self.backbone.proj_out = nn.Identity()\n        if param.classifier == 'avgpooling_patch_reps':\n            self.classifier = nn.Sequential(\n                Rearrange('b c s d -> b d c s'),\n                nn.AdaptiveAvgPool2d((1, 1)),\n                nn.Flatten(),\n                nn.Linear(200, 1),\n                Rearrange('b 1 -> (b 1)'),\n            )\n        elif param.classifier == 'all_patch_reps':\n            self.classifier = nn.Sequential(\n                Rearrange('b c s d -> b (c s d)'),\n                nn.Linear(20 * 5 * 200, 5 * 200),\n                nn.ELU(),\n                nn.Dropout(param.dropout),\n                nn.Linear(5 * 200, 200),\n                nn.ELU(),\n                nn.Dropout(param.dropout),\n                nn.Linear(200, 1),\n                Rearrange('b 1 -> (b 1)'),\n            )\n\n    def forward(self, x):\n        bz, ch_num, seq_len, patch_size = x.shape\n        feats = self.backbone(x)\n        out = self.classifier(feats)\n        return out\n\n"}
{"_id": "beir_output_models/cbramod.py", "title": "", "text": "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nfrom models.criss_cross_transformer import TransformerEncoderLayer, TransformerEncoder\n\n\nclass CBraMod(nn.Module):\n    def __init__(self, in_dim=200, out_dim=200, d_model=200, dim_feedforward=800, seq_len=30, n_layer=12,\n                    nhead=8):\n        super().__init__()\n        self.patch_embedding = PatchEmbedding(in_dim, out_dim, d_model, seq_len)\n        encoder_layer = TransformerEncoderLayer(\n            d_model=d_model, nhead=nhead, dim_feedforward=dim_feedforward, batch_first=True, norm_first=True,\n            activation=F.gelu\n        )\n        self.encoder = TransformerEncoder(encoder_layer, num_layers=n_layer, enable_nested_tensor=False)\n        self.proj_out = nn.Sequential(\n            # nn.Linear(d_model, d_model*2),\n            # nn.GELU(),\n            # nn.Linear(d_model*2, d_model),\n            # nn.GELU(),\n            nn.Linear(d_model, out_dim),\n        )\n        self.apply(_weights_init)\n\n    def forward(self, x, mask=None):\n        patch_emb = self.patch_embedding(x, mask)\n        feats = self.encoder(patch_emb)\n\n        out = self.proj_out(feats)\n\n        return out\n\nclass PatchEmbedding(nn.Module):\n    def __init__(self, in_dim, out_dim, d_model, seq_len):\n        super().__init__()\n        self.d_model = d_model\n        self.positional_encoding = nn.Sequential(\n            nn.Conv2d(in_channels=d_model, out_channels=d_model, kernel_size=(19, 7), stride=(1, 1), padding=(9, 3),\n                      groups=d_model),\n        )\n        self.mask_encoding = nn.Parameter(torch.zeros(in_dim), requires_grad=False)\n        # self.mask_encoding = nn.Parameter(torch.randn(in_dim), requires_grad=True)\n\n        self.proj_in = nn.Sequential(\n            nn.Conv2d(in_channels=1, out_channels=25, kernel_size=(1, 49), stride=(1, 25), padding=(0, 24)),\n            nn.GroupNorm(5, 25),\n            nn.GELU(),\n\n            nn.Conv2d(in_channels=25, out_channels=25, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1)),\n            nn.GroupNorm(5, 25),\n            nn.GELU(),\n\n            nn.Conv2d(in_channels=25, out_channels=25, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1)),\n            nn.GroupNorm(5, 25),\n            nn.GELU(),\n        )\n        self.spectral_proj = nn.Sequential(\n            nn.Linear(101, d_model),\n            nn.Dropout(0.1),\n            # nn.LayerNorm(d_model, eps=1e-5),\n        )\n        # self.norm1 = nn.LayerNorm(d_model, eps=1e-5)\n        # self.norm2 = nn.LayerNorm(d_model, eps=1e-5)\n        # self.proj_in = nn.Sequential(\n        #     nn.Linear(in_dim, d_model, bias=False),\n        # )\n\n\n    def forward(self, x, mask=None):\n        bz, ch_num, patch_num, patch_size = x.shape\n        if mask == None:\n            mask_x = x\n        else:\n            mask_x = x.clone()\n            mask_x[mask == 1] = self.mask_encoding\n\n        mask_x = mask_x.contiguous().view(bz, 1, ch_num * patch_num, patch_size)\n        patch_emb = self.proj_in(mask_x)\n        patch_emb = patch_emb.permute(0, 2, 1, 3).contiguous().view(bz, ch_num, patch_num, self.d_model)\n\n        mask_x = mask_x.contiguous().view(bz*ch_num*patch_num, patch_size)\n        spectral = torch.fft.rfft(mask_x, dim=-1, norm='forward')\n        spectral = torch.abs(spectral).contiguous().view(bz, ch_num, patch_num, 101)\n        spectral_emb = self.spectral_proj(spectral)\n        # print(patch_emb[5, 5, 5, :])\n        # print(spectral_emb[5, 5, 5, :])\n        patch_emb = patch_emb + spectral_emb\n\n        positional_embedding = self.positional_encoding(patch_emb.permute(0, 3, 1, 2))\n        positional_embedding = positional_embedding.permute(0, 2, 3, 1)\n\n        patch_emb = patch_emb + positional_embedding\n\n        return patch_emb\n\n\ndef _weights_init(m):\n    if isinstance(m, nn.Linear):\n        nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n    if isinstance(m, nn.Conv1d):\n        nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n    elif isinstance(m, nn.BatchNorm1d):\n        nn.init.constant_(m.weight, 1)\n        nn.init.constant_(m.bias, 0)\n\n\n\nif __name__ == '__main__':\n\n    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n    model = CBraMod(in_dim=200, out_dim=200, d_model=200, dim_feedforward=800, seq_len=30, n_layer=12,\n                    nhead=8).to(device)\n    model.load_state_dict(torch.load('pretrained_weights/pretrained_weights.pth',\n                                     map_location=device))\n    a = torch.randn((8, 16, 10, 200)).cuda()\n    b = model(a)\n    print(a.shape, b.shape)\n"}
{"_id": "beir_output_models/model_for_seedvig.py", "title": "", "text": "import torch\nimport torch.nn as nn\nfrom einops.layers.torch import Rearrange\n\nfrom .cbramod import CBraMod\n\n\nclass Model(nn.Module):\n    def __init__(self, param):\n        super(Model, self).__init__()\n        self.backbone = CBraMod(\n            in_dim=200, out_dim=200, d_model=200,\n            dim_feedforward=800, seq_len=30,\n            n_layer=12, nhead=8\n        )\n        if param.use_pretrained_weights:\n            map_location = torch.device(f'cuda:{param.cuda}')\n            self.backbone.load_state_dict(torch.load(param.foundation_dir, map_location=map_location))\n        self.backbone.proj_out = nn.Identity()\n        if param.classifier == 'avgpooling_patch_reps':\n            self.classifier = nn.Sequential(\n                Rearrange('b c s d -> b d c s'),\n                nn.AdaptiveAvgPool2d((1, 1)),\n                nn.Flatten(),\n                nn.Linear(200, 1),\n                Rearrange('b 1 -> (b 1)'),\n            )\n        elif param.classifier == 'all_patch_reps':\n            self.classifier = nn.Sequential(\n                Rearrange('b c s d -> b (c s d)'),\n                nn.Linear(17 * 8 * 200, 8 * 200),\n                nn.ELU(),\n                nn.Dropout(param.dropout),\n                nn.Linear(8 * 200, 200),\n                nn.ELU(),\n                nn.Dropout(param.dropout),\n                nn.Linear(200, 1),\n                Rearrange('b 1 -> (b 1)'),\n            )\n\n    def forward(self, x):\n        bz, ch_num, seq_len, patch_size = x.shape\n        feats = self.backbone(x)\n        out = self.classifier(feats)\n        return out\n\n"}
{"_id": "beir_output_models/model_for_physio.py", "title": "", "text": "import torch\nimport torch.nn as nn\nfrom einops.layers.torch import Rearrange\n\nfrom .cbramod import CBraMod\n\n\nclass Model(nn.Module):\n    def __init__(self, param):\n        super(Model, self).__init__()\n        self.backbone = CBraMod(\n            in_dim=200, out_dim=200, d_model=200,\n            dim_feedforward=800, seq_len=30,\n            n_layer=12, nhead=8\n        )\n        if param.use_pretrained_weights:\n            map_location = torch.device(f'cuda:{param.cuda}')\n            self.backbone.load_state_dict(torch.load(param.foundation_dir, map_location=map_location))\n        self.backbone.proj_out = nn.Identity()\n        if param.classifier == 'avgpooling_patch_reps':\n            self.classifier = nn.Sequential(\n                Rearrange('b c s d -> b d c s'),\n                nn.AdaptiveAvgPool2d((1, 1)),\n                nn.Flatten(),\n                nn.Linear(200, param.num_of_classes),\n            )\n        elif param.classifier == 'all_patch_reps':\n            self.classifier = nn.Sequential(\n                Rearrange('b c s d -> b (c s d)'),\n                nn.Linear(64 * 4 * 200, 4 * 200),\n                nn.ELU(),\n                nn.Dropout(param.dropout),\n                nn.Linear(4 * 200, 200),\n                nn.ELU(),\n                nn.Dropout(param.dropout),\n                nn.Linear(200, param.num_of_classes),\n            )\n\n\n    def forward(self, x):\n        bz, ch_num, seq_len, patch_size = x.shape\n        feats = self.backbone(x)\n        out = self.classifier(feats)\n        return out\n"}
{"_id": "beir_output_models/model_for_shu.py", "title": "", "text": "import torch\nimport torch.nn as nn\nfrom einops.layers.torch import Rearrange\n\nfrom .cbramod import CBraMod\n\n\nclass Model(nn.Module):\n    def __init__(self, param):\n        super(Model, self).__init__()\n        self.backbone = CBraMod(\n            in_dim=200, out_dim=200, d_model=200,\n            dim_feedforward=800, seq_len=30,\n            n_layer=12, nhead=8\n        )\n        if param.use_pretrained_weights:\n            map_location = torch.device(f'cuda:{param.cuda}')\n            self.backbone.load_state_dict(torch.load(param.foundation_dir, map_location=map_location))\n        self.backbone.proj_out = nn.Identity()\n        if param.classifier == 'avgpooling_patch_reps':\n            self.classifier = nn.Sequential(\n                Rearrange('b c s d -> b d c s'),\n                nn.AdaptiveAvgPool2d((1, 1)),\n                nn.Flatten(),\n                nn.Linear(200, 1),\n                Rearrange('b 1 -> (b 1)'),\n            )\n        elif param.classifier == 'all_patch_reps':\n            self.classifier = nn.Sequential(\n                Rearrange('b c s d -> b (c s d)'),\n                nn.Linear(32 * 4 * 200, 4 * 200),\n                nn.ELU(),\n                nn.Dropout(param.dropout),\n                nn.Linear(4 * 200, 200),\n                nn.ELU(),\n                nn.Dropout(param.dropout),\n                nn.Linear(200, 1),\n                Rearrange('b 1 -> (b 1)'),\n            )\n    def forward(self, x):\n        bz, ch_num, seq_len, patch_size = x.shape\n        feats = self.backbone(x)\n        out = self.classifier(feats)\n        return out\n\n\n"}
{"_id": "beir_output_models/model_for_tuab.py", "title": "", "text": "import torch\nimport torch.nn as nn\nfrom einops.layers.torch import Rearrange\n\nfrom .cbramod import CBraMod\n\n\nclass Model(nn.Module):\n    def __init__(self, param):\n        super(Model, self).__init__()\n        self.backbone = CBraMod(\n            in_dim=200, out_dim=200, d_model=200,\n            dim_feedforward=800, seq_len=30,\n            n_layer=12, nhead=8\n        )\n        if param.use_pretrained_weights:\n            map_location = torch.device(f'cuda:{param.cuda}')\n            self.backbone.load_state_dict(torch.load(param.foundation_dir, map_location=map_location))\n        self.backbone.proj_out = nn.Identity()\n        if param.classifier == 'avgpooling_patch_reps':\n            self.classifier = nn.Sequential(\n                Rearrange('b c s d -> b d c s'),\n                nn.AdaptiveAvgPool2d((1, 1)),\n                nn.Flatten(),\n                nn.Linear(200, 1),\n                Rearrange('b 1 -> (b 1)'),\n            )\n        elif param.classifier == 'all_patch_reps':\n            self.classifier = nn.Sequential(\n                Rearrange('b c s d -> b (c s d)'),\n                nn.Linear(16 * 10 * 200, 10 * 200),\n                nn.ELU(),\n                nn.Dropout(param.dropout),\n                nn.Linear(10 * 200, 200),\n                nn.ELU(),\n                nn.Dropout(param.dropout),\n                nn.Linear(200, 1),\n                Rearrange('b 1 -> (b 1)'),\n            )\n\n    def forward(self, x):\n        bz, ch_num, seq_len, patch_size = x.shape\n        feats = self.backbone(x)\n        out = self.classifier(feats)\n        return out\n"}
{"_id": "beir_output_models/__init__.py", "title": "", "text": ""}
{"_id": "beir_output_datasets/seedvig_dataset.py", "title": "", "text": "import torch\nfrom torch.utils.data import Dataset, DataLoader\nimport numpy as np\nfrom utils.util import to_tensor\nimport os\nimport random\nimport lmdb\nimport pickle\n\nclass CustomDataset(Dataset):\n    def __init__(\n            self,\n            data_dir,\n            mode='train',\n    ):\n        super(CustomDataset, self).__init__()\n        self.db = lmdb.open(data_dir, readonly=True, lock=False, readahead=True, meminit=False)\n        with self.db.begin(write=False) as txn:\n            self.keys = pickle.loads(txn.get('__keys__'.encode()))[mode]\n\n    def __len__(self):\n        return len((self.keys))\n\n    def __getitem__(self, idx):\n        key = self.keys[idx]\n        with self.db.begin(write=False) as txn:\n            pair = pickle.loads(txn.get(key.encode()))\n        data = pair['sample']\n        label = pair['label']\n        # print(key)\n        # print(data.shape)\n        return data/100, label\n\n    def collate(self, batch):\n        x_data = np.array([x[0] for x in batch])\n        y_label = np.array([x[1] for x in batch])\n        return to_tensor(x_data), to_tensor(y_label)\n\n\nclass LoadDataset(object):\n    def __init__(self, params):\n        self.params = params\n        self.datasets_dir = params.datasets_dir\n\n    def get_data_loader(self):\n        train_set = CustomDataset(self.datasets_dir, mode='train')\n        val_set = CustomDataset(self.datasets_dir, mode='val')\n        test_set = CustomDataset(self.datasets_dir, mode='test')\n        print(len(train_set), len(val_set), len(test_set))\n        data_loader = {\n            'train': DataLoader(\n                train_set,\n                batch_size=self.params.batch_size,\n                collate_fn=train_set.collate,\n                shuffle=True,\n            ),\n            'val': DataLoader(\n                val_set,\n                batch_size=self.params.batch_size,\n                collate_fn=val_set.collate,\n                shuffle=False,\n            ),\n            'test': DataLoader(\n                test_set,\n                batch_size=self.params.batch_size,\n                collate_fn=test_set.collate,\n                shuffle=False,\n            ),\n        }\n        return data_loader\n"}
{"_id": "beir_output_datasets/seedv_dataset.py", "title": "", "text": "import torch\nfrom torch.utils.data import Dataset, DataLoader\nimport numpy as np\nfrom utils.util import to_tensor\nimport os\nimport random\nimport lmdb\nimport pickle\n\n\nclass CustomDataset(Dataset):\n    def __init__(\n            self,\n            data_dir,\n            mode='train',\n    ):\n        super(CustomDataset, self).__init__()\n        self.db = lmdb.open(data_dir, readonly=True, lock=False, readahead=True, meminit=False)\n        with self.db.begin(write=False) as txn:\n            self.keys = pickle.loads(txn.get('__keys__'.encode()))[mode]\n\n    def __len__(self):\n        return len((self.keys))\n\n    def __getitem__(self, idx):\n        key = self.keys[idx]\n        with self.db.begin(write=False) as txn:\n            pair = pickle.loads(txn.get(key.encode()))\n        data = pair['sample']\n        label = pair['label']\n        # print(key)\n        # print(data)\n        # print(label)\n        return data / 100, label\n\n    def collate(self, batch):\n        x_data = np.array([x[0] for x in batch])\n        y_label = np.array([x[1] for x in batch])\n        return to_tensor(x_data), to_tensor(y_label).long()\n\n\nclass LoadDataset(object):\n    def __init__(self, params):\n        self.params = params\n        self.datasets_dir = params.datasets_dir\n\n    def get_data_loader(self):\n        train_set = CustomDataset(self.datasets_dir, mode='train')\n        val_set = CustomDataset(self.datasets_dir, mode='val')\n        test_set = CustomDataset(self.datasets_dir, mode='test')\n        print(len(train_set), len(val_set), len(test_set))\n        print(len(train_set) + len(val_set) + len(test_set))\n        data_loader = {\n            'train': DataLoader(\n                train_set,\n                batch_size=self.params.batch_size,\n                collate_fn=train_set.collate,\n                shuffle=True,\n            ),\n            'val': DataLoader(\n                val_set,\n                batch_size=self.params.batch_size,\n                collate_fn=val_set.collate,\n                shuffle=False,\n            ),\n            'test': DataLoader(\n                test_set,\n                batch_size=self.params.batch_size,\n                collate_fn=test_set.collate,\n                shuffle=False,\n            ),\n        }\n        return data_loader\n"}
{"_id": "beir_output_datasets/tuev_dataset.py", "title": "", "text": "import torch\nfrom torch.utils.data import Dataset, DataLoader\nimport numpy as np\nfrom utils.util import to_tensor\nimport os\nimport random\nimport lmdb\nimport pickle\nfrom scipy import signal\n\n\nclass CustomDataset(Dataset):\n    def __init__(\n            self,\n            data_dir,\n            files,\n    ):\n        super(CustomDataset, self).__init__()\n        self.data_dir = data_dir\n        self.files = files\n\n    def __len__(self):\n        return len((self.files))\n\n    def __getitem__(self, idx):\n        file = self.files[idx]\n        data_dict = pickle.load(open(os.path.join(self.data_dir, file), \"rb\"))\n        data = data_dict['signal']\n        label = int(data_dict['label'][0]-1)\n        # data = signal.resample(data, 1000, axis=-1)\n        data = data.reshape(16, 5, 200)\n        return data/100, label\n\n    def collate(self, batch):\n        x_data = np.array([x[0] for x in batch])\n        y_label = np.array([x[1] for x in batch])\n        return to_tensor(x_data), to_tensor(y_label).long()\n\n\nclass LoadDataset(object):\n    def __init__(self, params):\n        self.params = params\n        self.datasets_dir = params.datasets_dir\n\n    def get_data_loader(self):\n        train_files = os.listdir(os.path.join(self.datasets_dir, \"processed_train\"))\n        val_files = os.listdir(os.path.join(self.datasets_dir, \"processed_eval\"))\n        test_files = os.listdir(os.path.join(self.datasets_dir, \"processed_test\"))\n\n        train_set = CustomDataset(os.path.join(self.datasets_dir, \"processed_train\"), train_files)\n        val_set = CustomDataset(os.path.join(self.datasets_dir, \"processed_eval\"), val_files)\n        test_set = CustomDataset(os.path.join(self.datasets_dir, \"processed_test\"), test_files)\n\n        print(len(train_set), len(val_set), len(test_set))\n        print(len(train_set)+len(val_set)+len(test_set))\n\n        data_loader = {\n            'train': DataLoader(\n                train_set,\n                batch_size=self.params.batch_size,\n                collate_fn=train_set.collate,\n                shuffle=True,\n            ),\n            'val': DataLoader(\n                val_set,\n                batch_size=self.params.batch_size,\n                collate_fn=val_set.collate,\n                shuffle=False,\n            ),\n            'test': DataLoader(\n                test_set,\n                batch_size=self.params.batch_size,\n                collate_fn=test_set.collate,\n                shuffle=False,\n            ),\n        }\n        return data_loader\n"}
{"_id": "beir_output_datasets/isruc_dataset.py", "title": "", "text": "import torch\nfrom torch.utils.data import Dataset, DataLoader\nimport numpy as np\nfrom utils.util import to_tensor\nimport os\nimport random\n\n\n\nclass CustomDataset(Dataset):\n    def __init__(\n            self,\n            seqs_labels_path_pair\n    ):\n        super(CustomDataset, self).__init__()\n        self.seqs_labels_path_pair = seqs_labels_path_pair\n\n    def __len__(self):\n        return len((self.seqs_labels_path_pair))\n\n    def __getitem__(self, idx):\n        seq_path = self.seqs_labels_path_pair[idx][0]\n        label_path = self.seqs_labels_path_pair[idx][1]\n        # print(seq_path)\n        # print(label_path)\n        seq = np.load(seq_path)\n        label = np.load(label_path)\n        return seq, label\n\n    def collate(self, batch):\n        x_seq = np.array([x[0] for x in batch])\n        y_label = np.array([x[1] for x in batch])\n        return to_tensor(x_seq), to_tensor(y_label).long()\n\n\nclass LoadDataset(object):\n    def __init__(self, params):\n        self.params = params\n        self.seqs_dir = os.path.join(params.datasets_dir, 'seq')\n        self.labels_dir = os.path.join(params.datasets_dir, 'labels')\n        self.seqs_labels_path_pair = self.load_path()\n\n    def get_data_loader(self):\n        train_pairs, val_pairs, test_pairs = self.split_dataset(self.seqs_labels_path_pair)\n        train_set = CustomDataset(train_pairs)\n        val_set = CustomDataset(val_pairs)\n        test_set = CustomDataset(test_pairs)\n        print(len(train_set), len(val_set), len(test_set))\n        print(len(train_set) + len(val_set) + len(test_set))\n        data_loader = {\n            'train': DataLoader(\n                train_set,\n                batch_size=self.params.batch_size,\n                collate_fn=train_set.collate,\n                shuffle=True,\n            ),\n            'val': DataLoader(\n                val_set,\n                batch_size=1,\n                collate_fn=val_set.collate,\n                shuffle=False,\n            ),\n            'test': DataLoader(\n                test_set,\n                batch_size=1,\n                collate_fn=test_set.collate,\n                shuffle=False,\n            ),\n        }\n        return data_loader\n\n    def load_path(self):\n        seqs_labels_path_pair = []\n        # subject_nums = os.listdir(self.seqs_dir)\n        # print(subject_nums)\n        subject_dirs_seq = []\n        subject_dirs_labels = []\n        for subject_num in range(1, 101):\n            subject_dirs_seq.append(os.path.join(self.seqs_dir, f'ISRUC-group1-{subject_num}'))\n            subject_dirs_labels.append(os.path.join(self.labels_dir, f'ISRUC-group1-{subject_num}'))\n\n        for subject_seq, subject_label in zip(subject_dirs_seq, subject_dirs_labels):\n            # print(subject_seq, subject_label)\n            subject_pairs = []\n            seq_fnames = os.listdir(subject_seq)\n            label_fnames = os.listdir(subject_label)\n            # print(seq_fnames)\n            for seq_fname, label_fname in zip(seq_fnames, label_fnames):\n                subject_pairs.append((os.path.join(subject_seq, seq_fname), os.path.join(subject_label, label_fname)))\n            seqs_labels_path_pair.append(subject_pairs)\n        # print(seqs_labels_path_pair)\n        return seqs_labels_path_pair\n\n    def split_dataset(self, seqs_labels_path_pair):\n        train_pairs = []\n        val_pairs = []\n        test_pairs = []\n\n        for i in range(100):\n            if i < 80:\n                train_pairs.extend(seqs_labels_path_pair[i])\n            elif i < 90:\n                val_pairs.extend(seqs_labels_path_pair[i])\n            else:\n                test_pairs.extend(seqs_labels_path_pair[i])\n        # print(train_pairs, val_pairs, test_pairs)\n        return train_pairs, val_pairs, test_pairs\n"}
{"_id": "beir_output_datasets/speech_dataset.py", "title": "", "text": "import torch\nfrom torch.utils.data import Dataset, DataLoader\nimport numpy as np\nfrom utils.util import to_tensor\nimport os\nimport random\nimport lmdb\nimport pickle\n\nclass CustomDataset(Dataset):\n    def __init__(\n            self,\n            data_dir,\n            mode='train',\n    ):\n        super(CustomDataset, self).__init__()\n        self.db = lmdb.open(data_dir, readonly=True, lock=False, readahead=True, meminit=False)\n        with self.db.begin(write=False) as txn:\n            self.keys = pickle.loads(txn.get('__keys__'.encode()))[mode]\n\n    def __len__(self):\n        return len((self.keys))\n\n    def __getitem__(self, idx):\n        key = self.keys[idx]\n        with self.db.begin(write=False) as txn:\n            pair = pickle.loads(txn.get(key.encode()))\n        data = pair['sample']\n        label = pair['label']\n        # print(key)\n        # print(data.shape)\n        # print(label)\n        return data/100, label\n\n    def collate(self, batch):\n        x_data = np.array([x[0] for x in batch])\n        y_label = np.array([x[1] for x in batch])\n        return to_tensor(x_data), to_tensor(y_label).long()\n\n\nclass LoadDataset(object):\n    def __init__(self, params):\n        self.params = params\n        self.datasets_dir = params.datasets_dir\n\n    def get_data_loader(self):\n        train_set = CustomDataset(self.datasets_dir, mode='train')\n        val_set = CustomDataset(self.datasets_dir, mode='val')\n        test_set = CustomDataset(self.datasets_dir, mode='test')\n        print(len(train_set), len(val_set), len(test_set))\n        data_loader = {\n            'train': DataLoader(\n                train_set,\n                batch_size=self.params.batch_size,\n                collate_fn=train_set.collate,\n                shuffle=True,\n            ),\n            'val': DataLoader(\n                val_set,\n                batch_size=self.params.batch_size,\n                collate_fn=val_set.collate,\n                shuffle=False,\n            ),\n            'test': DataLoader(\n                test_set,\n                batch_size=self.params.batch_size,\n                collate_fn=test_set.collate,\n                shuffle=False,\n            ),\n        }\n        return data_loader\n"}
{"_id": "beir_output_datasets/chb_dataset.py", "title": "", "text": "import torch\nfrom torch.utils.data import Dataset, DataLoader\nimport numpy as np\nfrom utils.util import to_tensor\nimport os\nimport random\nimport lmdb\nimport pickle\nfrom scipy import signal\n\nclass CustomDataset(Dataset):\n    def __init__(\n            self,\n            data_dir,\n            mode='train',\n    ):\n        super(CustomDataset, self).__init__()\n        self.files = [os.path.join(data_dir, mode, file) for file in os.listdir(os.path.join(data_dir, mode))]\n\n\n    def __len__(self):\n        return len((self.files))\n\n    def __getitem__(self, idx):\n        file = self.files[idx]\n        data_dict = pickle.load(open(file, 'rb'))\n        data = data_dict['X']\n        label = data_dict['y']\n        data = signal.resample(data, 2000, axis=1)\n        data = data.reshape(16, 10, 200)\n        return data/100, label\n\n    def collate(self, batch):\n        x_data = np.array([x[0] for x in batch])\n        y_label = np.array([x[1] for x in batch])\n        return to_tensor(x_data), to_tensor(y_label)\n\n\nclass LoadDataset(object):\n    def __init__(self, params):\n        self.params = params\n        self.datasets_dir = params.datasets_dir\n\n    def get_data_loader(self):\n        train_set = CustomDataset(self.datasets_dir, mode='train')\n        val_set = CustomDataset(self.datasets_dir, mode='val')\n        test_set = CustomDataset(self.datasets_dir, mode='test')\n        print(len(train_set), len(val_set), len(test_set))\n        print(len(train_set) + len(val_set) + len(test_set))\n        data_loader = {\n            'train': DataLoader(\n                train_set,\n                batch_size=self.params.batch_size,\n                collate_fn=train_set.collate,\n                shuffle=True,\n            ),\n            'val': DataLoader(\n                val_set,\n                batch_size=self.params.batch_size,\n                collate_fn=val_set.collate,\n                shuffle=False,\n            ),\n            'test': DataLoader(\n                test_set,\n                batch_size=self.params.batch_size,\n                collate_fn=test_set.collate,\n                shuffle=False,\n            ),\n        }\n        return data_loader\n"}
{"_id": "beir_output_datasets/shu_dataset.py", "title": "", "text": "import torch\nfrom torch.utils.data import Dataset, DataLoader\nimport numpy as np\nfrom utils.util import to_tensor\nimport os\nimport random\nimport lmdb\nimport pickle\n\nclass CustomDataset(Dataset):\n    def __init__(\n            self,\n            data_dir,\n            mode='train',\n    ):\n        super(CustomDataset, self).__init__()\n        self.db = lmdb.open(data_dir, readonly=True, lock=False, readahead=True, meminit=False)\n        with self.db.begin(write=False) as txn:\n            self.keys = pickle.loads(txn.get('__keys__'.encode()))[mode]\n        if mode == 'train':\n            random.shuffle(self.keys)\n            length = len(self.keys)\n            self.keys = self.keys[:int(length * 0.3)]\n\n    def __len__(self):\n        return len((self.keys))\n\n    def __getitem__(self, idx):\n        key = self.keys[idx]\n        with self.db.begin(write=False) as txn:\n            pair = pickle.loads(txn.get(key.encode()))\n        data = pair['sample']\n        label = pair['label']\n        # print(label)\n        return data/100, label\n\n    def collate(self, batch):\n        x_data = np.array([x[0] for x in batch])\n        y_label = np.array([x[1] for x in batch])\n        return to_tensor(x_data), to_tensor(y_label)\n\n\nclass LoadDataset(object):\n    def __init__(self, params):\n        self.params = params\n        self.datasets_dir = params.datasets_dir\n\n    def get_data_loader(self):\n        train_set = CustomDataset(self.datasets_dir, mode='train')\n        val_set = CustomDataset(self.datasets_dir, mode='val')\n        test_set = CustomDataset(self.datasets_dir, mode='test')\n        print(len(train_set), len(val_set), len(test_set))\n        print(len(train_set)+len(val_set)+len(test_set))\n        data_loader = {\n            'train': DataLoader(\n                train_set,\n                batch_size=self.params.batch_size,\n                collate_fn=train_set.collate,\n                shuffle=True,\n            ),\n            'val': DataLoader(\n                val_set,\n                batch_size=self.params.batch_size,\n                collate_fn=val_set.collate,\n                shuffle=True,\n            ),\n            'test': DataLoader(\n                test_set,\n                batch_size=self.params.batch_size,\n                collate_fn=test_set.collate,\n                shuffle=True,\n            ),\n        }\n        return data_loader\n"}
{"_id": "beir_output_datasets/tuab_dataset.py", "title": "", "text": "import torch\nfrom torch.utils.data import Dataset, DataLoader\nimport numpy as np\nfrom utils.util import to_tensor\nimport os\nimport random\nimport lmdb\nimport pickle\nfrom scipy import signal\n\nclass CustomDataset(Dataset):\n    def __init__(\n            self,\n            data_dir,\n            mode='train',\n    ):\n        super(CustomDataset, self).__init__()\n        self.files = [os.path.join(data_dir, mode, file) for file in os.listdir(os.path.join(data_dir, mode))]\n\n\n    def __len__(self):\n        return len((self.files))\n\n    def __getitem__(self, idx):\n        file = self.files[idx]\n        data_dict = pickle.load(open(file, 'rb'))\n        data = data_dict['X']\n        label = data_dict['y']\n        # data = signal.resample(data, 2000, axis=-1)\n        data = data.reshape(16, 10, 200)\n        return data/100, label\n\n    def collate(self, batch):\n        x_data = np.array([x[0] for x in batch])\n        y_label = np.array([x[1] for x in batch])\n        return to_tensor(x_data), to_tensor(y_label)\n\n\nclass LoadDataset(object):\n    def __init__(self, params):\n        self.params = params\n        self.datasets_dir = params.datasets_dir\n\n    def get_data_loader(self):\n        train_set = CustomDataset(self.datasets_dir, mode='train')\n        val_set = CustomDataset(self.datasets_dir, mode='val')\n        test_set = CustomDataset(self.datasets_dir, mode='test')\n        print(len(train_set), len(val_set), len(test_set))\n        print(len(train_set) + len(val_set) + len(test_set))\n        data_loader = {\n            'train': DataLoader(\n                train_set,\n                batch_size=self.params.batch_size,\n                collate_fn=train_set.collate,\n                shuffle=True,\n            ),\n            'val': DataLoader(\n                val_set,\n                batch_size=self.params.batch_size,\n                collate_fn=val_set.collate,\n                shuffle=False,\n            ),\n            'test': DataLoader(\n                test_set,\n                batch_size=self.params.batch_size,\n                collate_fn=test_set.collate,\n                shuffle=False,\n            ),\n        }\n        return data_loader\n"}
{"_id": "beir_output_datasets/physio_dataset.py", "title": "", "text": "import torch\nfrom torch.utils.data import Dataset, DataLoader\nimport numpy as np\nfrom utils.util import to_tensor\nimport os\nimport random\nimport lmdb\nimport pickle\n\nclass CustomDataset(Dataset):\n    def __init__(\n            self,\n            data_dir,\n            mode='train',\n    ):\n        super(CustomDataset, self).__init__()\n        self.db = lmdb.open(data_dir, readonly=True, lock=False, readahead=True, meminit=False)\n        with self.db.begin(write=False) as txn:\n            self.keys = pickle.loads(txn.get('__keys__'.encode()))[mode]\n\n    def __len__(self):\n        return len((self.keys))\n\n    def __getitem__(self, idx):\n        key = self.keys[idx]\n        with self.db.begin(write=False) as txn:\n            pair = pickle.loads(txn.get(key.encode()))\n        data = pair['sample']\n        label = pair['label']\n        # print(key)\n        # print(data)\n        # print(label)\n        return data/100, label\n\n    def collate(self, batch):\n        x_data = np.array([x[0] for x in batch])\n        y_label = np.array([x[1] for x in batch])\n        return to_tensor(x_data), to_tensor(y_label).long()\n\n\nclass LoadDataset(object):\n    def __init__(self, params):\n        self.params = params\n        self.datasets_dir = params.datasets_dir\n\n    def get_data_loader(self):\n        train_set = CustomDataset(self.datasets_dir, mode='train')\n        val_set = CustomDataset(self.datasets_dir, mode='val')\n        test_set = CustomDataset(self.datasets_dir, mode='test')\n        print(len(train_set), len(val_set), len(test_set))\n        print(len(train_set)+len(val_set)+len(test_set))\n        data_loader = {\n            'train': DataLoader(\n                train_set,\n                batch_size=self.params.batch_size,\n                collate_fn=train_set.collate,\n                shuffle=True,\n            ),\n            'val': DataLoader(\n                val_set,\n                batch_size=self.params.batch_size,\n                collate_fn=val_set.collate,\n                shuffle=False,\n            ),\n            'test': DataLoader(\n                test_set,\n                batch_size=self.params.batch_size,\n                collate_fn=test_set.collate,\n                shuffle=False,\n            ),\n        }\n        return data_loader\n"}
{"_id": "beir_output_datasets/mumtaz_dataset.py", "title": "", "text": "import torch\nfrom torch.utils.data import Dataset, DataLoader\nimport numpy as np\nfrom utils.util import to_tensor\nimport os\nimport random\nimport lmdb\nimport pickle\n\nclass CustomDataset(Dataset):\n    def __init__(\n            self,\n            data_dir,\n            mode='train',\n    ):\n        super(CustomDataset, self).__init__()\n        self.db = lmdb.open(data_dir, readonly=True, lock=False, readahead=True, meminit=False)\n        with self.db.begin(write=False) as txn:\n            self.keys = pickle.loads(txn.get('__keys__'.encode()))[mode]\n\n    def __len__(self):\n        return len((self.keys))\n\n    def __getitem__(self, idx):\n        key = self.keys[idx]\n        with self.db.begin(write=False) as txn:\n            pair = pickle.loads(txn.get(key.encode()))\n        data = pair['sample']\n        label = pair['label']\n        # print(label)\n        return data/100, label\n\n    def collate(self, batch):\n        x_data = np.array([x[0] for x in batch])\n        y_label = np.array([x[1] for x in batch])\n        return to_tensor(x_data), to_tensor(y_label)\n\n\nclass LoadDataset(object):\n    def __init__(self, params):\n        self.params = params\n        self.datasets_dir = params.datasets_dir\n\n    def get_data_loader(self):\n        train_set = CustomDataset(self.datasets_dir, mode='train')\n        val_set = CustomDataset(self.datasets_dir, mode='val')\n        test_set = CustomDataset(self.datasets_dir, mode='test')\n        print(len(train_set), len(val_set), len(test_set))\n        print(len(train_set) + len(val_set) + len(test_set))\n        data_loader = {\n            'train': DataLoader(\n                train_set,\n                batch_size=self.params.batch_size,\n                collate_fn=train_set.collate,\n                shuffle=True,\n            ),\n            'val': DataLoader(\n                val_set,\n                batch_size=self.params.batch_size,\n                collate_fn=val_set.collate,\n                shuffle=True,\n            ),\n            'test': DataLoader(\n                test_set,\n                batch_size=self.params.batch_size,\n                collate_fn=test_set.collate,\n                shuffle=True,\n            ),\n        }\n        return data_loader\n"}
{"_id": "beir_output_datasets/faced_dataset.py", "title": "", "text": "import torch\nfrom torch.utils.data import Dataset, DataLoader\nimport numpy as np\nfrom utils.util import to_tensor\nimport os\nimport random\nimport lmdb\nimport pickle\n\nclass CustomDataset(Dataset):\n    def __init__(\n            self,\n            data_dir,\n            mode='train',\n    ):\n        super(CustomDataset, self).__init__()\n        self.db = lmdb.open(data_dir, readonly=True, lock=False, readahead=True, meminit=False)\n        with self.db.begin(write=False) as txn:\n            self.keys = pickle.loads(txn.get('__keys__'.encode()))[mode]\n\n    def __len__(self):\n        return len((self.keys))\n\n    def __getitem__(self, idx):\n        key = self.keys[idx]\n        with self.db.begin(write=False) as txn:\n            pair = pickle.loads(txn.get(key.encode()))\n        data = pair['sample']\n        label = pair['label']\n        return data/100, label\n\n    def collate(self, batch):\n        x_data = np.array([x[0] for x in batch])\n        y_label = np.array([x[1] for x in batch])\n        return to_tensor(x_data), to_tensor(y_label).long()\n\n\nclass LoadDataset(object):\n    def __init__(self, params):\n        self.params = params\n        self.datasets_dir = params.datasets_dir\n\n    def get_data_loader(self):\n        train_set = CustomDataset(self.datasets_dir, mode='train')\n        val_set = CustomDataset(self.datasets_dir, mode='val')\n        test_set = CustomDataset(self.datasets_dir, mode='test')\n        print(len(train_set), len(val_set), len(test_set))\n        print(len(train_set)+len(val_set)+len(test_set))\n        data_loader = {\n            'train': DataLoader(\n                train_set,\n                batch_size=self.params.batch_size,\n                collate_fn=train_set.collate,\n                shuffle=True,\n            ),\n            'val': DataLoader(\n                val_set,\n                batch_size=self.params.batch_size,\n                collate_fn=val_set.collate,\n                shuffle=False,\n            ),\n            'test': DataLoader(\n                test_set,\n                batch_size=self.params.batch_size,\n                collate_fn=test_set.collate,\n                shuffle=False,\n            ),\n        }\n        return data_loader\n"}
{"_id": "beir_output_datasets/pretraining_dataset.py", "title": "", "text": "import pickle\n\nimport lmdb\nfrom torch.utils.data import Dataset\n\nfrom utils.util import to_tensor\n\n\nclass PretrainingDataset(Dataset):\n    def __init__(\n            self,\n            dataset_dir\n    ):\n        super(PretrainingDataset, self).__init__()\n        self.db = lmdb.open(dataset_dir, readonly=True, lock=False, readahead=True, meminit=False)\n        with self.db.begin(write=False) as txn:\n            self.keys = pickle.loads(txn.get('__keys__'.encode()))\n        # self.keys = self.keys[:100000]\n\n    def __len__(self):\n        return len(self.keys)\n\n    def __getitem__(self, idx):\n        key = self.keys[idx]\n\n        with self.db.begin(write=False) as txn:\n            patch = pickle.loads(txn.get(key.encode()))\n\n        patch = to_tensor(patch)\n        # print(patch.shape)\n        return patch\n\n\n\n"}
{"_id": "beir_output_datasets/bciciv2a_dataset.py", "title": "", "text": "import torch\nfrom torch.utils.data import Dataset, DataLoader\nimport numpy as np\nfrom utils.util import to_tensor\nimport os\nimport random\nimport lmdb\nimport pickle\n\nclass CustomDataset(Dataset):\n    def __init__(\n            self,\n            data_dir,\n            mode='train',\n    ):\n        super(CustomDataset, self).__init__()\n        self.db = lmdb.open(data_dir, readonly=True, lock=False, readahead=True, meminit=False)\n        with self.db.begin(write=False) as txn:\n            self.keys = pickle.loads(txn.get('__keys__'.encode()))[mode]\n\n    def __len__(self):\n        return len((self.keys))\n\n    def __getitem__(self, idx):\n        key = self.keys[idx]\n        with self.db.begin(write=False) as txn:\n            pair = pickle.loads(txn.get(key.encode()))\n        data = pair['sample']\n        label = pair['label']\n        return data/100, label\n\n    def collate(self, batch):\n        x_data = np.array([x[0] for x in batch])\n        y_label = np.array([x[1] for x in batch])\n        return to_tensor(x_data), to_tensor(y_label).long()\n\nclass LoadDataset(object):\n    def __init__(self, params):\n        self.params = params\n        self.datasets_dir = params.datasets_dir\n\n    def get_data_loader(self):\n        train_set = CustomDataset(self.datasets_dir, mode='train')\n        val_set = CustomDataset(self.datasets_dir, mode='val')\n        test_set = CustomDataset(self.datasets_dir, mode='test')\n        print(len(train_set), len(val_set), len(test_set))\n        print(len(train_set)+len(val_set)+len(test_set))\n        data_loader = {\n            'train': DataLoader(\n                train_set,\n                batch_size=self.params.batch_size,\n                collate_fn=train_set.collate,\n                shuffle=True,\n            ),\n            'val': DataLoader(\n                test_set,\n                batch_size=self.params.batch_size,\n                collate_fn=test_set.collate,\n                shuffle=False,\n            ),\n            'test': DataLoader(\n                test_set,\n                batch_size=self.params.batch_size,\n                collate_fn=test_set.collate,\n                shuffle=False,\n            ),\n        }\n        return data_loader\n"}
{"_id": "beir_output_datasets/__init__.py", "title": "", "text": ""}
{"_id": "beir_output_datasets/stress_dataset.py", "title": "", "text": "import torch\nfrom torch.utils.data import Dataset, DataLoader\nimport numpy as np\nfrom utils.util import to_tensor\nimport os\nimport random\nimport lmdb\nimport pickle\n\nclass CustomDataset(Dataset):\n    def __init__(\n            self,\n            data_dir,\n            mode='train',\n    ):\n        super(CustomDataset, self).__init__()\n        self.db = lmdb.open(data_dir, readonly=True, lock=False, readahead=True, meminit=False)\n        with self.db.begin(write=False) as txn:\n            self.keys = pickle.loads(txn.get('__keys__'.encode()))[mode]\n\n    def __len__(self):\n        return len((self.keys))\n\n    def __getitem__(self, idx):\n        key = self.keys[idx]\n        with self.db.begin(write=False) as txn:\n            pair = pickle.loads(txn.get(key.encode()))\n        data = pair['sample']\n        label = pair['label']\n        # print(label)\n        return data/100, label\n\n    def collate(self, batch):\n        x_data = np.array([x[0] for x in batch])\n        y_label = np.array([x[1] for x in batch])\n        return to_tensor(x_data), to_tensor(y_label)\n\n\nclass LoadDataset(object):\n    def __init__(self, params):\n        self.params = params\n        self.datasets_dir = params.datasets_dir\n\n    def get_data_loader(self):\n        train_set = CustomDataset(self.datasets_dir, mode='train')\n        val_set = CustomDataset(self.datasets_dir, mode='val')\n        test_set = CustomDataset(self.datasets_dir, mode='test')\n        print(len(train_set), len(val_set), len(test_set))\n        print(len(train_set)+len(val_set)+len(test_set))\n        data_loader = {\n            'train': DataLoader(\n                train_set,\n                batch_size=self.params.batch_size,\n                collate_fn=train_set.collate,\n                shuffle=True,\n            ),\n            'val': DataLoader(\n                val_set,\n                batch_size=self.params.batch_size,\n                collate_fn=val_set.collate,\n                shuffle=True,\n            ),\n            'test': DataLoader(\n                test_set,\n                batch_size=self.params.batch_size,\n                collate_fn=test_set.collate,\n                shuffle=True,\n            ),\n        }\n        return data_loader\n"}
{"_id": "beir_output_preprocessing/preprocessing_speech.py", "title": "", "text": "import h5py\nimport scipy\nfrom scipy import signal\nimport os\nimport lmdb\nimport pickle\nimport numpy as np\nimport pandas as pd\n\n\ntrain_dir = '/data/datasets/BigDownstream/Imagined speech/mat/Training set'\nval_dir = '/data/datasets/BigDownstream/Imagined speech/mat/Validation set'\ntest_dir = '/data/datasets/BigDownstream/Imagined speech/mat/Test set'\n\n\n\nfiles_dict = {\n    'train':sorted([file for file in os.listdir(train_dir)]),\n    'val':sorted([file for file in os.listdir(val_dir)]),\n    'test':sorted([file for file in os.listdir(test_dir)]),\n}\n\nprint(files_dict)\n\ndataset = {\n    'train': list(),\n    'val': list(),\n    'test': list(),\n}\n\ndb = lmdb.open('/data/datasets/BigDownstream/Imagined speech/processed', map_size=3000000000)\n\nfor file in files_dict['train']:\n    data = scipy.io.loadmat(os.path.join(train_dir, file))\n    print(data['epo_train'][0][0][0])\n    eeg = data['epo_train'][0][0][4].transpose(2, 1, 0)\n    labels = data['epo_train'][0][0][5].transpose(1, 0)\n    eeg = eeg[:, :, -768:]\n    labels = np.argmax(labels, axis=1)\n    eeg = signal.resample(eeg, 600, axis=2).reshape(300, 64, 3, 200)\n    print(eeg.shape, labels.shape)\n    for i, (sample, label) in enumerate(zip(eeg, labels)):\n        sample_key = f'train-{file[:-4]}-{i}'\n        data_dict = {\n            'sample': sample, 'label': label,\n        }\n        txn = db.begin(write=True)\n        txn.put(key=sample_key.encode(), value=pickle.dumps(data_dict))\n        txn.commit()\n        print(sample_key)\n        dataset['train'].append(sample_key)\n\n\nfor file in files_dict['val']:\n    data = scipy.io.loadmat(os.path.join(val_dir, file))\n    eeg = data['epo_validation'][0][0][4].transpose(2, 1, 0)\n    labels = data['epo_validation'][0][0][5].transpose(1, 0)\n    eeg = eeg[:, :, -768:]\n    labels = np.argmax(labels, axis=1)\n    eeg = signal.resample(eeg, 600, axis=2).reshape(50, 64, 3, 200)\n    print(eeg.shape, labels.shape)\n    for i, (sample, label) in enumerate(zip(eeg, labels)):\n        sample_key = f'val-{file[:-4]}-{i}'\n        data_dict = {\n            'sample': sample, 'label': label,\n        }\n        txn = db.begin(write=True)\n        txn.put(key=sample_key.encode(), value=pickle.dumps(data_dict))\n        txn.commit()\n        print(sample_key)\n        dataset['val'].append(sample_key)\n\n\ndf = pd.read_excel(\"/data/datasets/BigDownstream/Imagined speech/mat/Track3_Answer Sheet_Test.xlsx\")\ndf_=df.head(53)\nall_labels=df_.values\nprint(all_labels.shape)\nall_labels = all_labels[2:, 1:][:, 1:30:2].transpose(1, 0)\nprint(all_labels.shape)\nprint(all_labels)\n\nfor j, file in enumerate(files_dict['test']):\n    data = h5py.File(os.path.join(test_dir, file))\n    eeg = data['epo_test']['x'][:]\n    labels = all_labels[j]\n    eeg = eeg[:, :, -768:]\n    eeg = signal.resample(eeg, 600, axis=2).reshape(50, 64, 3, 200)\n    print(eeg.shape, labels.shape)\n    for i, (sample, label) in enumerate(zip(eeg, labels)):\n        sample_key = f'test-{file[:-4]}-{i}'\n        data_dict = {\n            'sample': sample, 'label': label-1,\n        }\n        txn = db.begin(write=True)\n        txn.put(key=sample_key.encode(), value=pickle.dumps(data_dict))\n        txn.commit()\n        print(sample_key)\n        dataset['test'].append(sample_key)\n\n\ntxn = db.begin(write=True)\ntxn.put(key='__keys__'.encode(), value=pickle.dumps(dataset))\ntxn.commit()\ndb.close()"}
{"_id": "beir_output_preprocessing/preprocessing_bciciv2a.py", "title": "", "text": "import numpy as np\nimport scipy\nfrom scipy import signal\nimport os\nimport lmdb\nimport pickle\nfrom scipy.signal import butter, lfilter, resample, filtfilt\n\ndef butter_bandpass(low_cut, high_cut, fs, order=5):\n    nyq = 0.5 * fs\n    low = low_cut / nyq\n    high = high_cut / nyq\n    b, a = butter(order, [low, high], btype='band')\n    return b, a\n\nroot_dir = '/data/datasets/BCICIV2a/data_mat'\nfiles = [file for file in os.listdir(root_dir)]\nfiles = sorted(files)\n\n# files.remove('A04E.mat')\n# files.remove('A04T.mat')\n# files.remove('A06E.mat')\n# files.remove('A06T.mat')\nprint(files)\n\nfiles_dict = {\n    'train': ['A01E.mat', 'A01T.mat', 'A02E.mat', 'A02T.mat', 'A03E.mat', 'A03T.mat',\n              'A04E.mat', 'A04T.mat',\n              'A05E.mat', 'A05T.mat'],\n    'val': [\n        'A06E.mat', 'A06T.mat',\n        'A07E.mat', 'A07T.mat'\n    ],\n    'test': ['A08E.mat', 'A08T.mat', 'A09E.mat', 'A09T.mat'],\n}\n\n\n\ndataset = {\n    'train': list(),\n    'val': list(),\n    'test': list(),\n}\n\n# for file in files:\n#     if 'E' in file:\n#         files_dict['train'].append(file)\n#     else:\n#         files_dict['test'].append(file)\n#\n# print(files_dict)\n\n\ndb = lmdb.open('/data/datasets/BCICIV2a/processed_inde_avg_03_50', map_size=1610612736)\nfor files_key in files_dict.keys():\n    for file in files_dict[files_key]:\n        print(file)\n        data = scipy.io.loadmat(os.path.join(root_dir, file))\n        num = len(data['data'][0])\n        # print(num)\n        # print(data['data'][0, 8][0, 0][0].shape)\n        # print(data['data'][0, 8][0, 0][1].shape)\n        # print(data['data'][0, 8][0, 0][2].shape)\n        for j in range(3, num):\n            raw_data = data['data'][0, j][0, 0][0][:, :22]\n            events = data['data'][0, j][0, 0][1][:, 0]\n            labels = data['data'][0, j][0, 0][2][:, 0]\n            length = raw_data.shape[0]\n            events = events.tolist()\n            events.append(length)\n            # print(events)\n            annos = []\n            for i in range(len(events) - 1):\n                annos.append((events[i], events[i + 1]))\n            for i, (anno, label) in enumerate(zip(annos, labels)):\n                sample = raw_data[anno[0]:anno[1]].transpose(1, 0)\n                sample  = sample - np.mean(sample, axis=0, keepdims=True)\n                # print(samples.shape)\n                b, a = butter_bandpass(0.3, 50, 250)\n                sample = lfilter(b, a, sample, -1)\n                # print(sample.shape)\n                sample = sample[:, 2 * 250:6 * 250]\n                sample = resample(sample, 800, axis=-1)\n                # print(sample.shape)\n                # print(i, sample.shape, label)\n                sample = sample.reshape(22, 4, 200)\n                sample_key = f'{file[:-4]}-{j}-{i}'\n                print(sample_key, label-1)\n                data_dict = {\n                    'sample': sample, 'label': label - 1\n                }\n                # print(label-1)\n                txn = db.begin(write=True)\n                txn.put(key=sample_key.encode(), value=pickle.dumps(data_dict))\n                txn.commit()\n                dataset[files_key].append(sample_key)\n\n\ntxn = db.begin(write=True)\ntxn.put(key='__keys__'.encode(), value=pickle.dumps(dataset))\ntxn.commit()\ndb.close()\n"}
{"_id": "beir_output_preprocessing/preprocessing_tuev.py", "title": "", "text": "import mne\nimport numpy as np\nimport os\nimport pickle\nfrom tqdm import tqdm\n\n\"\"\"\nhttps://github.com/Abhishaike/EEG_Event_Classification\n\"\"\"\n\n\ndef BuildEvents(signals, times, EventData):\n    [numEvents, z] = EventData.shape  # numEvents is equal to # of rows of the .rec file\n    fs = 200.0\n    [numChan, numPoints] = signals.shape\n    # for i in range(numChan):  # standardize each channel\n    #     if np.std(signals[i, :]) > 0:\n    #         signals[i, :] = (signals[i, :] - np.mean(signals[i, :])) / np.std(signals[i, :])\n    features = np.zeros([numEvents, numChan, int(fs) * 5])\n    offending_channel = np.zeros([numEvents, 1])  # channel that had the detected thing\n    labels = np.zeros([numEvents, 1])\n    offset = signals.shape[1]\n    signals = np.concatenate([signals, signals, signals], axis=1)\n    for i in range(numEvents):  # for each event\n        chan = int(EventData[i, 0])  # chan is channel\n        start = np.where((times) >= EventData[i, 1])[0][0]\n        end = np.where((times) >= EventData[i, 2])[0][0]\n        # print (offset + start - 2 * int(fs), offset + end + 2 * int(fs), signals.shape)\n        features[i, :] = signals[\n            :, offset + start - 2 * int(fs) : offset + end + 2 * int(fs)\n        ]\n        offending_channel[i, :] = int(chan)\n        labels[i, :] = int(EventData[i, 3])\n    return [features, offending_channel, labels]\n\n\ndef convert_signals(signals, Rawdata):\n    signal_names = {\n        k: v\n        for (k, v) in zip(\n            Rawdata.info[\"ch_names\"], list(range(len(Rawdata.info[\"ch_names\"])))\n        )\n    }\n    new_signals = np.vstack(\n        (\n            signals[signal_names[\"EEG FP1-REF\"]]\n            - signals[signal_names[\"EEG F7-REF\"]],  # 0\n            (\n                signals[signal_names[\"EEG F7-REF\"]]\n                - signals[signal_names[\"EEG T3-REF\"]]\n            ),  # 1\n            (\n                signals[signal_names[\"EEG T3-REF\"]]\n                - signals[signal_names[\"EEG T5-REF\"]]\n            ),  # 2\n            (\n                signals[signal_names[\"EEG T5-REF\"]]\n                - signals[signal_names[\"EEG O1-REF\"]]\n            ),  # 3\n            (\n                signals[signal_names[\"EEG FP2-REF\"]]\n                - signals[signal_names[\"EEG F8-REF\"]]\n            ),  # 4\n            (\n                signals[signal_names[\"EEG F8-REF\"]]\n                - signals[signal_names[\"EEG T4-REF\"]]\n            ),  # 5\n            (\n                signals[signal_names[\"EEG T4-REF\"]]\n                - signals[signal_names[\"EEG T6-REF\"]]\n            ),  # 6\n            (\n                signals[signal_names[\"EEG T6-REF\"]]\n                - signals[signal_names[\"EEG O2-REF\"]]\n            ),  # 7\n            (\n                signals[signal_names[\"EEG FP1-REF\"]]\n                - signals[signal_names[\"EEG F3-REF\"]]\n            ),  # 14\n            (\n                signals[signal_names[\"EEG F3-REF\"]]\n                - signals[signal_names[\"EEG C3-REF\"]]\n            ),  # 15\n            (\n                signals[signal_names[\"EEG C3-REF\"]]\n                - signals[signal_names[\"EEG P3-REF\"]]\n            ),  # 16\n            (\n                signals[signal_names[\"EEG P3-REF\"]]\n                - signals[signal_names[\"EEG O1-REF\"]]\n            ),  # 17\n            (\n                signals[signal_names[\"EEG FP2-REF\"]]\n                - signals[signal_names[\"EEG F4-REF\"]]\n            ),  # 18\n            (\n                signals[signal_names[\"EEG F4-REF\"]]\n                - signals[signal_names[\"EEG C4-REF\"]]\n            ),  # 19\n            (\n                signals[signal_names[\"EEG C4-REF\"]]\n                - signals[signal_names[\"EEG P4-REF\"]]\n            ),  # 20\n            (signals[signal_names[\"EEG P4-REF\"]] - signals[signal_names[\"EEG O2-REF\"]]),\n        )\n    )  # 21\n    return new_signals\n\n\ndef readEDF(fileName):\n    Rawdata = mne.io.read_raw_edf(fileName, preload=True)\n    Rawdata.resample(200)\n    Rawdata.filter(l_freq=0.3, h_freq=75)\n    Rawdata.notch_filter((60))\n\n    _, times = Rawdata[:]\n    signals = Rawdata.get_data(units='uV')\n    RecFile = fileName[0:-3] + \"rec\"\n    eventData = np.genfromtxt(RecFile, delimiter=\",\")\n    Rawdata.close()\n    return [signals, times, eventData, Rawdata]\n\n\ndef load_up_objects(BaseDir, Features, OffendingChannels, Labels, OutDir):\n    for dirName, subdirList, fileList in tqdm(os.walk(BaseDir)):\n        print(\"Found directory: %s\" % dirName)\n        for fname in fileList:\n            if fname[-4:] == \".edf\":\n                print(\"\\t%s\" % fname)\n                try:\n                    [signals, times, event, Rawdata] = readEDF(\n                        dirName + \"/\" + fname\n                    )  # event is the .rec file in the form of an array\n                    signals = convert_signals(signals, Rawdata)\n                except (ValueError, KeyError):\n                    print(\"something funky happened in \" + dirName + \"/\" + fname)\n                    continue\n                signals, offending_channels, labels = BuildEvents(signals, times, event)\n\n                for idx, (signal, offending_channel, label) in enumerate(\n                    zip(signals, offending_channels, labels)\n                ):\n                    sample = {\n                        \"signal\": signal,\n                        \"offending_channel\": offending_channel,\n                        \"label\": label,\n                    }\n                    save_pickle(\n                        sample,\n                        os.path.join(\n                            OutDir, fname.split(\".\")[0] + \"-\" + str(idx) + \".pkl\"\n                        ),\n                    )\n\n    return Features, Labels, OffendingChannels\n\n\ndef save_pickle(object, filename):\n    with open(filename, \"wb\") as f:\n        pickle.dump(object, f)\n\n\n\"\"\"\nTUEV dataset is downloaded from https://isip.piconepress.com/projects/tuh_eeg/html/downloads.shtml\n\"\"\"\n\nroot = \"/data/zcb/data/TUEV/edf\"\ntarget = \"/data/datasets/BigDownstream/TUEV_refine\"\n\ntrain_out_dir = os.path.join(target, \"processed_train\")\neval_out_dir = os.path.join(target, \"processed_eval\")\n\nif not os.path.exists(train_out_dir):\n    os.makedirs(train_out_dir)\nif not os.path.exists(eval_out_dir):\n    os.makedirs(eval_out_dir)\n\nBaseDirTrain = os.path.join(root, \"train\")\nfs = 200\nTrainFeatures = np.empty(\n    (0, 16, fs)\n)  # 0 for lack of intialization, 22 for channels, fs for num of points\nTrainLabels = np.empty([0, 1])\nTrainOffendingChannel = np.empty([0, 1])\nload_up_objects(\n    BaseDirTrain, TrainFeatures, TrainLabels, TrainOffendingChannel, train_out_dir\n)\n\nBaseDirEval = os.path.join(root, \"eval\")\nfs = 200\nEvalFeatures = np.empty(\n    (0, 16, fs)\n)  # 0 for lack of intialization, 22 for channels, fs for num of points\nEvalLabels = np.empty([0, 1])\nEvalOffendingChannel = np.empty([0, 1])\nload_up_objects(\n    BaseDirEval, EvalFeatures, EvalLabels, EvalOffendingChannel, eval_out_dir\n)\n\n\n#transfer to train, eval, and test\nroot = \"/data/datasets/BigDownstream/TUEV_refine\"\n# seed = 4523\n# np.random.seed(seed)\n\ntrain_files = os.listdir(os.path.join(root, \"processed_train\"))\ntrain_val_sub = list(set([f.split(\"_\")[0] for f in train_files]))\nprint(\"train val sub:\", train_val_sub)\ntest_files = os.listdir(os.path.join(root, \"processed_eval\"))\n\ntrain_val_sub.sort(key=lambda x: x)\n\ntrain_sub = train_val_sub[: int(len(train_val_sub) * 0.8)]\nval_sub = train_val_sub[int(len(train_val_sub) * 0.8) :]\nprint(\"train sub:\", train_sub)\nprint(\"val sub:\", val_sub)\n\nval_files = [f for f in train_files if f.split(\"_\")[0] in val_sub]\ntrain_files = [f for f in train_files if f.split(\"_\")[0] in train_sub]\n\n\nif not os.path.exists(os.path.join(root, 'processed', 'processed_train')):\n    os.makedirs(os.path.join(root, 'processed', 'processed_train'))\nif not os.path.exists(os.path.join(root, 'processed', 'processed_eval')):\n    os.makedirs(os.path.join(root, 'processed', 'processed_eval'))\nif not os.path.exists(os.path.join(root, 'processed', 'processed_test')):\n    os.makedirs(os.path.join(root, 'processed', 'processed_test'))\n\nfor file in tqdm(train_files):\n    os.system(f\"cp {os.path.join(root, 'processed_train', file)} {os.path.join(root, 'processed', 'processed_train')}\")\nfor file in tqdm(val_files):\n    os.system(f\"cp {os.path.join(root, 'processed_train', file)} {os.path.join(root, 'processed', 'processed_eval')}\")\nfor file in tqdm(test_files):\n    os.system(f\"cp {os.path.join(root, 'processed_eval', file)} {os.path.join(root, 'processed', 'processed_test')}\")\n\nprint('Done!')\n"}
{"_id": "beir_output_preprocessing/preprocessing_physio.py", "title": "", "text": "import scipy\nfrom scipy import signal\nimport os\nimport lmdb\nimport pickle\nimport numpy as np\nimport mne\n\ntasks = ['04', '06', '08', '10', '12', '14'] # select the data for motor imagery\n\nroot_dir = '/data/datasets/eeg-motor-movementimagery-dataset-1.0.0/files'\nfiles = [file for file in os.listdir(root_dir)]\nfiles = sorted(files)\n\nfiles_dict = {\n    'train': files[:70],\n    'val': files[70:89],\n    'test': files[89:109],\n}\n\nprint(files_dict)\n\ndataset = {\n    'train': list(),\n    'val': list(),\n    'test': list(),\n}\n\n\n\nselected_channels = ['Fc5.', 'Fc3.', 'Fc1.', 'Fcz.', 'Fc2.', 'Fc4.', 'Fc6.', 'C5..', 'C3..', 'C1..', 'Cz..', 'C2..',\n                     'C4..', 'C6..', 'Cp5.', 'Cp3.', 'Cp1.', 'Cpz.', 'Cp2.', 'Cp4.', 'Cp6.', 'Fp1.', 'Fpz.', 'Fp2.',\n                     'Af7.', 'Af3.', 'Afz.', 'Af4.', 'Af8.', 'F7..', 'F5..', 'F3..', 'F1..', 'Fz..', 'F2..', 'F4..',\n                     'F6..', 'F8..', 'Ft7.', 'Ft8.', 'T7..', 'T8..', 'T9..', 'T10.', 'Tp7.', 'Tp8.', 'P7..', 'P5..',\n                     'P3..', 'P1..', 'Pz..', 'P2..', 'P4..', 'P6..', 'P8..', 'Po7.', 'Po3.', 'Poz.', 'Po4.', 'Po8.',\n                     'O1..', 'Oz..', 'O2..', 'Iz..']\n\ndb = lmdb.open('/data/datasets/eeg-motor-movementimagery-dataset-1.0.0/processed_average', map_size=4614542346)\n\nfor files_key in files_dict.keys():\n    for file in files_dict[files_key]:\n        for task in tasks:\n            raw = mne.io.read_raw_edf(os.path.join(root_dir, file, f'{file}R{task}.edf'), preload=True)\n            raw.pick_channels(selected_channels, ordered=True)\n            if len(raw.info['bads']) > 0:\n                print('interpolate_bads')\n                raw.interpolate_bads()\n            raw.set_eeg_reference(ref_channels='average')\n            raw.filter(l_freq=0.3, h_freq=None)\n            raw.notch_filter((60))\n            raw.resample(200)\n            events_from_annot, event_dict = mne.events_from_annotations(raw)\n            epochs = mne.Epochs(raw,\n                                events_from_annot,\n                                event_dict,\n                                tmin=0,\n                                tmax=4. - 1.0 / raw.info['sfreq'],\n                                baseline=None,\n                                preload=True)\n            data = epochs.get_data(units='uV')\n            events = epochs.events[:, 2]\n            print(data.shape, events)\n            data = data[:, :, -800:]\n            bz, ch_nums, _ = data.shape\n            data = data.reshape(bz, ch_nums, 4, 200)\n            print(data.shape)\n            for i, (sample, event) in enumerate(zip(data, events)):\n                if event != 1:\n                    sample_key = f'{file}R{task}-{i}'\n                    data_dict = {\n                        'sample': sample, 'label': event - 2 if task in ['04', '08', '12'] else event\n                    }\n                    txn = db.begin(write=True)\n                    txn.put(key=sample_key.encode(), value=pickle.dumps(data_dict))\n                    txn.commit()\n                    dataset[files_key].append(sample_key)\n\ntxn = db.begin(write=True)\ntxn.put(key='__keys__'.encode(), value=pickle.dumps(dataset))\ntxn.commit()\ndb.close()\n"}
{"_id": "beir_output_preprocessing/preprocessing_faced.py", "title": "", "text": "import scipy\nfrom scipy import signal\nimport os\nimport lmdb\nimport pickle\nimport numpy as np\n\n\nlabels = np.array([0,0,0,1,1,1,2,2,2,3,3,3,4,4,4,4,5,5,5,6,6,6,7,7,7,8,8,8])\nroot_dir = '/data/cyn/FACED/Processed_data'\nfiles = [file for file in os.listdir(root_dir)]\nfiles = sorted(files)\n\nfiles_dict = {\n    'train':files[:80],\n    'val':files[80:100],\n    'test':files[100:],\n}\n\ndataset = {\n    'train': list(),\n    'val': list(),\n    'test': list(),\n}\n\ndb = lmdb.open('/data/datasets/BigDownstream/Faced/processed', map_size=6612500172)\n\nfor files_key in files_dict.keys():\n    for file in files_dict[files_key]:\n        f = open(os.path.join(root_dir, file), 'rb')\n        array = pickle.load(f)\n        eeg = signal.resample(array, 6000, axis=2)\n        eeg_ = eeg.reshape(28, 32, 30, 200)\n        for i, (samples, label) in enumerate(zip(eeg_, labels)):\n            for j in range(3):\n                sample = samples[:, 10*j:10*(j+1), :]\n                sample_key = f'{file}-{i}-{j}'\n                print(sample_key)\n                data_dict = {\n                    'sample': sample, 'label': label\n                }\n                txn = db.begin(write=True)\n                txn.put(key=sample_key.encode(), value=pickle.dumps(data_dict))\n                txn.commit()\n                dataset[files_key].append(sample_key)\n\n\ntxn = db.begin(write=True)\ntxn.put(key='__keys__'.encode(), value=pickle.dumps(dataset))\ntxn.commit()\ndb.close()"}
{"_id": "beir_output_preprocessing/preprocessing_mumtaz.py", "title": "", "text": "import os\nimport mne\nimport numpy as np\nimport lmdb\nimport pickle\n\n#\u904d\u5386\u6587\u4ef6\u5939\ndef iter_files(rootDir):\n    #\u904d\u5386\u6839\u76ee\u5f55\n    files_H, files_MDD = [], []\n    for file in os.listdir(rootDir):\n        if 'TASK' not in file:\n            if 'MDD' in file:\n                files_MDD.append(file)\n            else:\n                files_H.append(file)\n    return files_H, files_MDD\n\n\nselected_channels = ['EEG Fp1-LE', 'EEG Fp2-LE', 'EEG F3-LE', 'EEG F4-LE', 'EEG C3-LE', 'EEG C4-LE', 'EEG P3-LE',\n                     'EEG P4-LE', 'EEG O1-LE', 'EEG O2-LE', 'EEG F7-LE', 'EEG F8-LE', 'EEG T3-LE', 'EEG T4-LE',\n                     'EEG T5-LE', 'EEG T6-LE', 'EEG Fz-LE', 'EEG Cz-LE', 'EEG Pz-LE']\nrootDir = '/data/datasets/MDDPHCED/files'\nfiles_H, files_MDD = iter_files(rootDir)\nfiles_H = sorted(files_H)\nfiles_MDD = sorted(files_MDD)\nprint(files_H)\nprint(files_MDD)\nprint(len(files_H), len(files_MDD))\n\n\nfiles_dict = {\n    'train':[],\n    'val':[],\n    'test':[],\n}\n\ndataset = {\n    'train': list(),\n    'val': list(),\n    'test': list(),\n}\n\nfiles_dict['train'].extend(files_H[:40])\nfiles_dict['train'].extend(files_MDD[:42])\nfiles_dict['val'].extend(files_H[40:48])\nfiles_dict['val'].extend(files_MDD[42:52])\nfiles_dict['test'].extend(files_H[48:])\nfiles_dict['test'].extend(files_MDD[52:])\n\nprint(files_dict['train'])\nprint(files_dict['val'])\nprint(files_dict['test'])\n\n\ndb = lmdb.open('/data/datasets/MDDPHCED/processed_lmdb_75hz', map_size=1273741824)\n\nfor files_key in files_dict.keys():\n    for file in files_dict[files_key]:\n        raw = mne.io.read_raw_edf(os.path.join(rootDir, file), preload=True)\n        print(raw.info['ch_names'])\n        raw.pick_channels(selected_channels, ordered=True)\n        print(raw.info['ch_names'])\n        raw.resample(200)\n        raw.filter(l_freq=0.3, h_freq=75)\n        raw.notch_filter((50))\n        # raw.plot_psd(average=True)\n        eeg_array = raw.to_data_frame().values\n        # print(raw.info)\n        eeg_array = eeg_array[:, 1:]\n        points, chs = eeg_array.shape\n        print(eeg_array.shape)\n        a = points % (5 * 200)\n        print(a)\n        if a != 0:\n            eeg_array = eeg_array[:-a, :]\n        eeg_array = eeg_array.reshape(-1, 5, 200, chs)\n        eeg_array = eeg_array.transpose(0, 3, 1, 2)\n        print(eeg_array.shape)\n        label = 1 if 'MDD' in file else 0\n        for i, sample in enumerate(eeg_array):\n            sample_key = f'{file[:-4]}_{i}'\n            data_dict = {\n                'sample': sample, 'label': label\n            }\n            txn = db.begin(write=True)\n            txn.put(key=sample_key.encode(), value=pickle.dumps(data_dict))\n            txn.commit()\n            dataset[files_key].append(sample_key)\n\n\ntxn = db.begin(write=True)\ntxn.put(key='__keys__'.encode(), value=pickle.dumps(dataset))\ntxn.commit()\ndb.close()"}
{"_id": "beir_output_preprocessing/preprocessing_tueg_for_pretraining.py", "title": "", "text": "import os\nimport random\n\nimport mne\nimport numpy as np\nfrom tqdm import tqdm\nimport pickle\nimport lmdb\n\n\nselected_channels = {\n    '01_tcp_ar': [\n            'EEG FP1-REF', 'EEG FP2-REF', 'EEG F3-REF', 'EEG F4-REF', 'EEG C3-REF', 'EEG C4-REF', 'EEG P3-REF',\n            'EEG P4-REF', 'EEG O1-REF', 'EEG O2-REF', 'EEG F7-REF', 'EEG F8-REF', 'EEG T3-REF', 'EEG T4-REF',\n            'EEG T5-REF', 'EEG T6-REF', 'EEG FZ-REF', 'EEG CZ-REF', 'EEG PZ-REF'\n    ],\n    '02_tcp_le': [\n            'EEG FP1-LE', 'EEG FP2-LE', 'EEG F3-LE', 'EEG F4-LE', 'EEG C3-LE', 'EEG C4-LE', 'EEG P3-LE',\n            'EEG P4-LE', 'EEG O1-LE', 'EEG O2-LE', 'EEG F7-LE', 'EEG F8-LE', 'EEG T3-LE', 'EEG T4-LE',\n            'EEG T5-LE', 'EEG T6-LE', 'EEG FZ-LE', 'EEG CZ-LE', 'EEG PZ-LE'\n    ],\n    '03_tcp_ar_a': [\n            'EEG FP1-REF', 'EEG FP2-REF', 'EEG F3-REF', 'EEG F4-REF', 'EEG C3-REF', 'EEG C4-REF', 'EEG P3-REF',\n            'EEG P4-REF', 'EEG O1-REF', 'EEG O2-REF', 'EEG F7-REF', 'EEG F8-REF', 'EEG T3-REF', 'EEG T4-REF',\n            'EEG T5-REF', 'EEG T6-REF', 'EEG FZ-REF', 'EEG CZ-REF', 'EEG PZ-REF'\n    ]\n}\n\ndef setup_seed(seed):\n    np.random.seed(seed)\n    random.seed(seed)\n\n\n#\u904d\u5386\u6587\u4ef6\u5939\ndef iter_files(rootDir):\n    #\u904d\u5386\u6839\u76ee\u5f55\n    file_path_list = []\n    for root,dirs,files in os.walk(rootDir):\n        for file in files:\n            file_name = os.path.join(root,file)\n            # print(file_name)\n            file_path_list.append(file_name)\n    return file_path_list\n\ndef preprocessing_recording(file_path, file_key_list: list, db: lmdb.open):\n    raw = mne.io.read_raw_edf(file_path, preload=True)\n    if '02_tcp_le' in file_path:\n        for ch in selected_channels['02_tcp_le']:\n            if ch not in raw.info['ch_names']:\n                return\n        raw.pick_channels(selected_channels['02_tcp_le'], ordered=True)\n    elif '01_tcp_ar' in file_path:\n        for ch in selected_channels['01_tcp_ar']:\n            if ch not in raw.info['ch_names']:\n                return\n        raw.pick_channels(selected_channels['01_tcp_ar'], ordered=True)\n    elif '03_tcp_ar_a' in file_path:\n        for ch in selected_channels['03_tcp_ar_a']:\n            if ch not in raw.info['ch_names']:\n                return\n        raw.pick_channels(selected_channels['03_tcp_ar_a'], ordered=True)\n    else:\n        return\n    # print(raw.info)\n    raw.resample(200)\n    raw.filter(l_freq=0.3, h_freq=75)\n    raw.notch_filter((60))\n    eeg_array = raw.to_data_frame().values\n    # print(raw.info)\n    eeg_array = eeg_array[:, 1:]\n    points, chs = eeg_array.shape\n    if points < 300 * 200:\n        return\n    a = points % (30 * 200)\n    eeg_array = eeg_array[60 * 200:-(a+60 * 200), :]\n    # print(eeg_array.shape)\n    eeg_array = eeg_array.reshape(-1, 30, 200, chs)\n    eeg_array = eeg_array.transpose(0, 3, 1, 2)\n    print(eeg_array.shape)\n    file_name = file_path.split('/')[-1][:-4]\n\n    for i, sample in enumerate(eeg_array):\n        # print(i, sample.shape)\n        if np.max(np.abs(sample)) < 100:\n            sample_key = f'{file_name}_{i}'\n            print(sample_key)\n            file_key_list.append(sample_key)\n            txn = db.begin(write=True)\n            txn.put(key=sample_key.encode(), value=pickle.dumps(sample))\n            txn.commit()\n\nif __name__ == '__main__':\n    setup_seed(1)\n    file_path_list = iter_files('path...')\n\n    file_path_list = sorted(file_path_list)\n    random.shuffle(file_path_list)\n    # print(file_path_list)\n    db = lmdb.open(r'path...', map_size=1649267441664)\n    file_key_list = []\n    for file_path in tqdm(file_path_list):\n        preprocessing_recording(file_path, file_key_list, db)\n\n    txn = db.begin(write=True)\n    txn.put(key='__keys__'.encode(), value=pickle.dumps(file_key_list))\n    txn.commit()\n    db.close()\n"}
{"_id": "beir_output_preprocessing/preprocessing_seedvig.py", "title": "", "text": "import h5py\nimport scipy\nfrom scipy import signal\nimport os\nimport lmdb\nimport pickle\nimport numpy as np\nimport pandas as pd\n\n\ndata_dir = '/data/datasets/BigDownstream/SEED-VIG/mat/Raw_Data'\nlabels_dir = '/data/datasets/BigDownstream/SEED-VIG/mat/perclos_labels'\n\nfiles = [file for file in os.listdir(data_dir)]\nfiles = sorted(files)\n\nfiles_dict = {\n    'train': files[:15],\n    'val': files[15:19],\n    'test': files[19:23],\n}\n\nprint(files_dict)\n\ndataset = {\n    'train': list(),\n    'val': list(),\n    'test': list(),\n}\n\ndb = lmdb.open('/data/datasets/BigDownstream/SEED-VIG/processed', map_size=6000000000)\n\nfor files_key in files_dict.keys():\n    for file in files_dict[files_key]:\n        eeg = scipy.io.loadmat(os.path.join(data_dir, file))['EEG'][0][0][0]\n        labels = scipy.io.loadmat(os.path.join(labels_dir, file))['perclos']\n        print(eeg.shape, labels.shape)\n        eeg = eeg.reshape(885, 8, 200, 17)\n        eeg = eeg.transpose(0, 3, 1, 2)\n        labels = labels[:, 0]\n        print(eeg.shape, labels.shape)\n        for i, (sample, label) in enumerate(zip(eeg, labels)):\n            sample_key = f'{file[:-4]}-{i}'\n            print(sample_key)\n            data_dict = {\n                'sample': sample, 'label': label\n            }\n            txn = db.begin(write=True)\n            txn.put(key=sample_key.encode(), value=pickle.dumps(data_dict))\n            txn.commit()\n            dataset[files_key].append(sample_key)\n\ntxn = db.begin(write=True)\ntxn.put(key='__keys__'.encode(), value=pickle.dumps(dataset))\ntxn.commit()\ndb.close()"}
{"_id": "beir_output_preprocessing/preprocessing_SEEDV.py", "title": "", "text": "import scipy\nfrom scipy import signal\nimport os\nimport lmdb\nimport pickle\nimport numpy as np\nimport mne\n\nuseless_ch = ['M1', 'M2', 'VEO', 'HEO']\ntrials_of_sessions = {\n    '1': {'start': [30, 132, 287, 555, 773, 982, 1271, 1628, 1730, 2025, 2227, 2435, 2667, 2932, 3204],\n          'end': [102, 228, 524, 742, 920, 1240, 1568, 1697, 1994, 2166, 2401, 2607, 2901, 3172, 3359]},\n\n    '2': {'start': [30, 299, 548, 646, 836, 1000, 1091, 1392, 1657, 1809, 1966, 2186, 2333, 2490, 2741],\n          'end': [267, 488, 614, 773, 967, 1059, 1331, 1622, 1777, 1908, 2153, 2302, 2428, 2709, 2817]},\n\n    '3': {'start': [30, 353, 478, 674, 825, 908, 1200, 1346, 1451, 1711, 2055, 2307, 2457, 2726, 2888],\n          'end': [321, 418, 643, 764, 877, 1147, 1284, 1418, 1679, 1996, 2275, 2425, 2664, 2857, 3066]},\n}\nlabels_of_sessions = {\n    '1': [4, 1, 3, 2, 0, 4, 1, 3, 2, 0, 4, 1, 3, 2, 0, ],\n    '2': [2, 1, 3, 0, 4, 4, 0, 3, 2, 1, 3, 4, 1, 2, 0, ],\n    '3': [2, 1, 3, 0, 4, 4, 0, 3, 2, 1, 3, 4, 1, 2, 0, ],\n}\n\nroot_dir = '/data/datasets/BigDownstream/SEED-V/files'\nfiles = [file for file in os.listdir(root_dir)]\nfiles = sorted(files)\nprint(files)\n\ntrials_split = {\n    'train': range(5),\n    'val': range(5, 10),\n    'test': range(10, 15),\n}\n\ndataset = {\n    'train': list(),\n    'val': list(),\n    'test': list(),\n}\n\ndb = lmdb.open('/data/datasets/BigDownstream/SEED-V/processed', map_size=15614542346)\n\nfor file in files:\n    raw = mne.io.read_raw_cnt(os.path.join(root_dir, file), preload=True)\n    raw.drop_channels(useless_ch)\n    # raw.set_eeg_reference(ref_channels='average')\n    raw.resample(200)\n    raw.filter(l_freq=0.3, h_freq=75)\n    data_matrix = raw.get_data(units='uV')\n    session_index = file.split('_')[1]\n    data_trials = [\n        data_matrix[:,\n        trials_of_sessions[session_index]['start'][j] * 200:trials_of_sessions[session_index]['end'][j] * 200]\n        for j in range(15)]\n    labels = labels_of_sessions[session_index]\n    for mode in trials_split.keys():\n        for index in trials_split[mode]:\n            data = data_trials[index]\n            label = labels[index]\n            print(data.shape)\n            data = data.reshape(62, -1, 1, 200)\n            data = data.transpose(1, 0, 2, 3)\n            print(data.shape)\n            for i, sample in enumerate(data):\n                sample_key = f'{file}-{index}-{i}'\n                data_dict = {\n                    'sample': sample, 'label': label\n                }\n                txn = db.begin(write=True)\n                txn.put(key=sample_key.encode(), value=pickle.dumps(data_dict))\n                txn.commit()\n                dataset[mode].append(sample_key)\n\ntxn = db.begin(write=True)\ntxn.put(key='__keys__'.encode(), value=pickle.dumps(dataset))\ntxn.commit()\ndb.close()\n"}
{"_id": "beir_output_preprocessing/preprocessing_stress.py", "title": "", "text": "import scipy\nfrom scipy import signal\nimport os\nimport lmdb\nimport pickle\nimport mne\n\nroot_dir = '/data/datasets/BigDownstream/mental-arithmetic/edf'\nfiles = [file for file in os.listdir(root_dir)]\nfiles = sorted(files)\nprint(files)\n\nfiles_dict = {\n    'train':files[:56],\n    'val':files[56:64],\n    'test':files[64:],\n}\nprint(files_dict)\ndataset = {\n    'train': list(),\n    'val': list(),\n    'test': list(),\n}\n\n\nselected_channels = ['EEG Fp1', 'EEG Fp2', 'EEG F3', 'EEG F4', 'EEG F7', 'EEG F8', 'EEG T3', 'EEG T4',\n                     'EEG C3', 'EEG C4', 'EEG T5', 'EEG T6', 'EEG P3', 'EEG P4', 'EEG O1', 'EEG O2',\n                     'EEG Fz', 'EEG Cz', 'EEG Pz', 'EEG A2-A1']\n\n\n\ndb = lmdb.open('/data/datasets/BigDownstream/mental-arithmetic/processed', map_size=1000000000)\nfor files_key in files_dict.keys():\n    for file in files_dict[files_key]:\n        raw = mne.io.read_raw_edf(os.path.join(root_dir, file), preload=True)\n        raw.pick(selected_channels)\n        raw.reorder_channels(selected_channels)\n        raw.resample(200)\n\n        eeg = raw.get_data(units='uV')\n        chs, points = eeg.shape\n        a = points % (5 * 200)\n        if a != 0:\n            eeg = eeg[:, :-a]\n        eeg = eeg.reshape(20, -1, 5, 200).transpose(1, 0, 2, 3)\n        label = int(file[-5])\n\n        for i, sample in enumerate(eeg):\n            sample_key = f'{file[:-4]}-{i}'\n            # print(sample_key)\n            data_dict = {\n                'sample':sample, 'label':label-1\n            }\n            txn = db.begin(write=True)\n            txn.put(key=sample_key.encode(), value=pickle.dumps(data_dict))\n            txn.commit()\n            dataset[files_key].append(sample_key)\n\ntxn = db.begin(write=True)\ntxn.put(key='__keys__'.encode(), value=pickle.dumps(dataset))\ntxn.commit()\ndb.close()"}
{"_id": "beir_output_preprocessing/preprocessing_tuab.py", "title": "", "text": "import os\nimport pickle\n\nfrom multiprocessing import Pool\nimport numpy as np\nimport mne\n\n# we need these channels\n# (signals[signal_names['EEG FP1-REF']] - signals[signal_names['EEG F7-REF']],  # 0\n# (signals[signal_names['EEG F7-REF']] - signals[signal_names['EEG T3-REF']]),  # 1\n# (signals[signal_names['EEG T3-REF']] - signals[signal_names['EEG T5-REF']]),  # 2\n# (signals[signal_names['EEG T5-REF']] - signals[signal_names['EEG O1-REF']]),  # 3\n# (signals[signal_names['EEG FP2-REF']] - signals[signal_names['EEG F8-REF']]),  # 4\n# (signals[signal_names['EEG F8-REF']] - signals[signal_names['EEG T4-REF']]),  # 5\n# (signals[signal_names['EEG T4-REF']] - signals[signal_names['EEG T6-REF']]),  # 6\n# (signals[signal_names['EEG T6-REF']] - signals[signal_names['EEG O2-REF']]),  # 7\n# (signals[signal_names['EEG FP1-REF']] - signals[signal_names['EEG F3-REF']]),  # 14\n# (signals[signal_names['EEG F3-REF']] - signals[signal_names['EEG C3-REF']]),  # 15\n# (signals[signal_names['EEG C3-REF']] - signals[signal_names['EEG P3-REF']]),  # 16\n# (signals[signal_names['EEG P3-REF']] - signals[signal_names['EEG O1-REF']]),  # 17\n# (signals[signal_names['EEG FP2-REF']] - signals[signal_names['EEG F4-REF']]),  # 18\n# (signals[signal_names['EEG F4-REF']] - signals[signal_names['EEG C4-REF']]),  # 19\n# (signals[signal_names['EEG C4-REF']] - signals[signal_names['EEG P4-REF']]),  # 20\n# (signals[signal_names['EEG P4-REF']] - signals[signal_names['EEG O2-REF']]))) # 21\nstandard_channels = [\n    \"EEG FP1-REF\",\n    \"EEG F7-REF\",\n    \"EEG T3-REF\",\n    \"EEG T5-REF\",\n    \"EEG O1-REF\",\n    \"EEG FP2-REF\",\n    \"EEG F8-REF\",\n    \"EEG T4-REF\",\n    \"EEG T6-REF\",\n    \"EEG O2-REF\",\n    \"EEG FP1-REF\",\n    \"EEG F3-REF\",\n    \"EEG C3-REF\",\n    \"EEG P3-REF\",\n    \"EEG O1-REF\",\n    \"EEG FP2-REF\",\n    \"EEG F4-REF\",\n    \"EEG C4-REF\",\n    \"EEG P4-REF\",\n    \"EEG O2-REF\",\n]\n\n\ndef split_and_dump(params):\n    fetch_folder, sub, dump_folder, label = params\n    for file in os.listdir(fetch_folder):\n        if sub in file:\n            print(\"process\", file)\n            file_path = os.path.join(fetch_folder, file)\n            raw = mne.io.read_raw_edf(file_path, preload=True)\n            raw.resample(200)\n            raw.filter(l_freq=0.3, h_freq=75)\n            raw.notch_filter((60))\n            ch_name = raw.ch_names\n            raw_data = raw.get_data(units='uV')\n            channeled_data = raw_data.copy()[:16]\n            try:\n                channeled_data[0] = (\n                    raw_data[ch_name.index(\"EEG FP1-REF\")]\n                    - raw_data[ch_name.index(\"EEG F7-REF\")]\n                )\n                channeled_data[1] = (\n                    raw_data[ch_name.index(\"EEG F7-REF\")]\n                    - raw_data[ch_name.index(\"EEG T3-REF\")]\n                )\n                channeled_data[2] = (\n                    raw_data[ch_name.index(\"EEG T3-REF\")]\n                    - raw_data[ch_name.index(\"EEG T5-REF\")]\n                )\n                channeled_data[3] = (\n                    raw_data[ch_name.index(\"EEG T5-REF\")]\n                    - raw_data[ch_name.index(\"EEG O1-REF\")]\n                )\n                channeled_data[4] = (\n                    raw_data[ch_name.index(\"EEG FP2-REF\")]\n                    - raw_data[ch_name.index(\"EEG F8-REF\")]\n                )\n                channeled_data[5] = (\n                    raw_data[ch_name.index(\"EEG F8-REF\")]\n                    - raw_data[ch_name.index(\"EEG T4-REF\")]\n                )\n                channeled_data[6] = (\n                    raw_data[ch_name.index(\"EEG T4-REF\")]\n                    - raw_data[ch_name.index(\"EEG T6-REF\")]\n                )\n                channeled_data[7] = (\n                    raw_data[ch_name.index(\"EEG T6-REF\")]\n                    - raw_data[ch_name.index(\"EEG O2-REF\")]\n                )\n                channeled_data[8] = (\n                    raw_data[ch_name.index(\"EEG FP1-REF\")]\n                    - raw_data[ch_name.index(\"EEG F3-REF\")]\n                )\n                channeled_data[9] = (\n                    raw_data[ch_name.index(\"EEG F3-REF\")]\n                    - raw_data[ch_name.index(\"EEG C3-REF\")]\n                )\n                channeled_data[10] = (\n                    raw_data[ch_name.index(\"EEG C3-REF\")]\n                    - raw_data[ch_name.index(\"EEG P3-REF\")]\n                )\n                channeled_data[11] = (\n                    raw_data[ch_name.index(\"EEG P3-REF\")]\n                    - raw_data[ch_name.index(\"EEG O1-REF\")]\n                )\n                channeled_data[12] = (\n                    raw_data[ch_name.index(\"EEG FP2-REF\")]\n                    - raw_data[ch_name.index(\"EEG F4-REF\")]\n                )\n                channeled_data[13] = (\n                    raw_data[ch_name.index(\"EEG F4-REF\")]\n                    - raw_data[ch_name.index(\"EEG C4-REF\")]\n                )\n                channeled_data[14] = (\n                    raw_data[ch_name.index(\"EEG C4-REF\")]\n                    - raw_data[ch_name.index(\"EEG P4-REF\")]\n                )\n                channeled_data[15] = (\n                    raw_data[ch_name.index(\"EEG P4-REF\")]\n                    - raw_data[ch_name.index(\"EEG O2-REF\")]\n                )\n            except:\n                with open(\"tuab-process-error-files.txt\", \"a\") as f:\n                    f.write(file + \"\\n\")\n                continue\n            for i in range(channeled_data.shape[1] // 2000):\n                dump_path = os.path.join(\n                    dump_folder, file.split(\".\")[0] + \"_\" + str(i) + \".pkl\"\n                )\n                pickle.dump(\n                    {\"X\": channeled_data[:, i * 2000 : (i + 1) * 2000], \"y\": label},\n                    open(dump_path, \"wb\"),\n                )\n\n\nif __name__ == \"__main__\":\n    \"\"\"\n    TUAB dataset is downloaded from https://isip.piconepress.com/projects/tuh_eeg/html/downloads.shtml\n    \"\"\"\n    # root to abnormal dataset\n    root = \"/data/datasets/BigDownstream/TUAB/edf\"\n    channel_std = \"01_tcp_ar\"\n\n    # seed = 4523\n    # np.random.seed(seed)\n    # train, val abnormal subjects\n    train_val_abnormal = os.path.join(root, \"train\", \"abnormal\", channel_std)\n    train_val_a_sub = list(\n        set([item.split(\"_\")[0] for item in os.listdir(train_val_abnormal)])\n    )\n    train_val_a_sub.sort(key=lambda x: x)\n\n    train_a_sub, val_a_sub = (\n        train_val_a_sub[: int(len(train_val_a_sub) * 0.8)],\n        train_val_a_sub[int(len(train_val_a_sub) * 0.8) :],\n    )\n    print('train_a_sub:', train_a_sub)\n    print('val_a_sub:', val_a_sub)\n\n    # train, val normal subjects\n    train_val_normal = os.path.join(root, \"train\", \"normal\", channel_std)\n    train_val_n_sub = list(\n        set([item.split(\"_\")[0] for item in os.listdir(train_val_normal)])\n    )\n    train_val_n_sub.sort(key=lambda x: x)\n\n    train_n_sub, val_n_sub = (\n        train_val_n_sub[: int(len(train_val_n_sub) * 0.8)],\n        train_val_n_sub[int(len(train_val_n_sub) * 0.8) :],\n    )\n    print('train_n_sub:', train_n_sub)\n    print('val_n_sub:', val_n_sub)\n\n\n    # test abnormal subjects\n    test_abnormal = os.path.join(root, \"eval\", \"abnormal\", channel_std)\n    test_a_sub = list(set([item.split(\"_\")[0] for item in os.listdir(test_abnormal)]))\n\n    # test normal subjects\n    test_normal = os.path.join(root, \"eval\", \"normal\", channel_std)\n    test_n_sub = list(set([item.split(\"_\")[0] for item in os.listdir(test_normal)]))\n\n    # create the train, val, test sample folder\n    if not os.path.exists(os.path.join(root, \"process_refine\")):\n        os.makedirs(os.path.join(root, \"process_refine\"))\n\n    if not os.path.exists(os.path.join(root, \"process_refine\", \"train\")):\n        os.makedirs(os.path.join(root, \"process_refine\", \"train\"))\n    train_dump_folder = os.path.join(root, \"process_refine\", \"train\")\n\n    if not os.path.exists(os.path.join(root, \"process_refine\", \"val\")):\n        os.makedirs(os.path.join(root, \"process_refine\", \"val\"))\n    val_dump_folder = os.path.join(root, \"process_refine\", \"val\")\n\n    if not os.path.exists(os.path.join(root, \"process_refine\", \"test\")):\n        os.makedirs(os.path.join(root, \"process_refine\", \"test\"))\n    test_dump_folder = os.path.join(root, \"process_refine\", \"test\")\n\n    # fetch_folder, sub, dump_folder, labels\n    parameters = []\n    for train_sub in train_a_sub:\n        parameters.append([train_val_abnormal, train_sub, train_dump_folder, 1])\n    for train_sub in train_n_sub:\n        parameters.append([train_val_normal, train_sub, train_dump_folder, 0])\n    for val_sub in val_a_sub:\n        parameters.append([train_val_abnormal, val_sub, val_dump_folder, 1])\n    for val_sub in val_n_sub:\n        parameters.append([train_val_normal, val_sub, val_dump_folder, 0])\n    for test_sub in test_a_sub:\n        parameters.append([test_abnormal, test_sub, test_dump_folder, 1])\n    for test_sub in test_n_sub:\n        parameters.append([test_normal, test_sub, test_dump_folder, 0])\n\n    # split and dump in parallel\n    with Pool(processes=24) as pool:\n        # Use the pool.map function to apply the square function to each element in the numbers list\n        result = pool.map(split_and_dump, parameters)\n\n    print('Done!')"}
{"_id": "beir_output_preprocessing/preprocessing_shu.py", "title": "", "text": "import scipy\nfrom scipy import signal\nimport os\nimport lmdb\nimport pickle\n\nroot_dir = '/data/datasets/BigDownstream/MODMA/files'\nfiles = [file for file in os.listdir(root_dir)]\nfiles = sorted(files)\n# print(files)\n\nfiles_dict = {\n    'train':files[:75],\n    'val':files[75:100],\n    'test':files[100:],\n}\n\ndataset = {\n    'train': list(),\n    'val': list(),\n    'test': list(),\n}\ndb = lmdb.open('/data/datasets/shu_datasets/processed', map_size=110612736)\nfor files_key in files_dict.keys():\n    for file in files_dict[files_key]:\n        data = scipy.io.loadmat(os.path.join(root_dir, file))\n        eeg = data['data']\n        labels = data['labels'][0]\n        bz, ch_num, points = eeg.shape\n        print(eeg.shape)\n        eeg_resample = signal.resample(eeg, 800, axis=2)\n        eeg_ = eeg_resample.reshape(bz, ch_num, 4, 200)\n        print(eeg_.shape, labels.shape)\n        for i, (sample, label) in enumerate(zip(eeg_, labels)):\n            sample_key = f'{file[:-4]}-{i}'\n            # print(sample_key)\n            data_dict = {\n                'sample':sample, 'label':label-1\n            }\n            txn = db.begin(write=True)\n            txn.put(key=sample_key.encode(), value=pickle.dumps(data_dict))\n            txn.commit()\n            dataset[files_key].append(sample_key)\n\ntxn = db.begin(write=True)\ntxn.put(key='__keys__'.encode(), value=pickle.dumps(dataset))\ntxn.commit()\ndb.close()"}
{"_id": "beir_output_preprocessing/__init__.py", "title": "", "text": ""}
{"_id": "beir_output_preprocessing/CHB-MIT/process2.py", "title": "", "text": "import pickle\nimport os\nimport numpy as np\nfrom tqdm import tqdm\nimport multiprocessing as mp\n\nroot = \"/data/datasets/BigDownstream/chb-mit/processed\"\nout = \"/data/datasets/BigDownstream/chb-mit/processed_seg\"\n\n# root = 'clean_signals'\n# out = 'clean_segments'\n\nif not os.path.exists(out):\n    os.makedirs(out)\n\n# dump chb23 and chb24 to test, ch21 and ch22 to val, and the rest to train\ntest_pats = [\"chb23\", \"chb24\"]\nval_pats = [\"chb21\", \"chb22\"]\ntrain_pats = [\n    \"chb01\",\n    \"chb02\",\n    \"chb03\",\n    \"chb04\",\n    \"chb05\",\n    \"chb06\",\n    \"chb07\",\n    \"chb08\",\n    \"chb09\",\n    \"chb10\",\n    \"chb11\",\n    \"chb12\",\n    \"chb13\",\n    \"chb14\",\n    \"chb15\",\n    \"chb16\",\n    \"chb17\",\n    \"chb18\",\n    \"chb19\",\n    \"chb20\",\n]\nchannels = [\n    \"FP1-F7\",\n    \"F7-T7\",\n    \"T7-P7\",\n    \"P7-O1\",\n    \"FP2-F8\",\n    \"F8-T8\",\n    \"T8-P8\",\n    \"P8-O2\",\n    \"FP1-F3\",\n    \"F3-C3\",\n    \"C3-P3\",\n    \"P3-O1\",\n    \"FP2-F4\",\n    \"F4-C4\",\n    \"C4-P4\",\n    \"P4-O2\",\n]\nSAMPLING_RATE = 256\n\n\ndef sub_to_segments(folder, out_folder):\n    print(f\"Processing {folder}...\")\n    # each recording\n    for f in tqdm(os.listdir(os.path.join(root, folder))):\n        print(f\"Processing {folder}/{f}...\")\n        record = pickle.load(open(os.path.join(root, folder, f), \"rb\"))\n        \"\"\"\n        {'FP1-F7': array([-145.93406593,    0.1953602 ,    0.1953602 , ...,  -11.52625153, -2.93040293,   19.34065934]), \n         'F7-T7': array([-104.51770452,    0.1953602 ,    0.1953602 , ...,   23.63858364, 27.54578755,   30.67155067]), \n         'T7-P7': array([-42.78388278,   0.1953602 ,   0.1953602 , ...,  48.64468864, 45.12820513,  34.57875458]), \n        'P7-O1': array([-33.01587302,   0.1953602 ,   0.1953602 , ..., -17.77777778, -20.51282051, -25.59218559]), \n       'FP1-F3': array([-170.94017094,    0.1953602 ,    0.1953602 , ...,  -34.96947497, -25.98290598,    0.1953602 ]), \n        'F3-C3': array([-110.76923077,    0.1953602 ,    0.1953602 , ...,   38.0952381 , 48.64468864,   50.20757021]), \n         'C3-P3': array([11.91697192,  0.1953602 ,  0.1953602 , ..., 40.04884005, 33.7973138 , 25.98290598]), \n       'P3-O1': array([-56.45909646,   0.1953602 ,   0.1953602 , ...,   0.97680098, -6.44688645, -16.60561661]), \n        'FP2-F4': array([-139.29181929,    0.1953602 ,    0.1953602 , ...,   -2.14896215, -2.14896215,   -0.58608059]), \n         'F4-C4': array([-1.36752137,  0.1953602 ,  0.1953602 , ...,  1.75824176, 2.93040293,  7.22832723]), \n        'C4-P4': array([63.88278388,  0.1953602 ,  0.1953602 , ..., 16.996337  , 23.63858364, 25.59218559]), \n       'P4-O2': array([-14.26129426,   0.1953602 ,   0.1953602 , ..., -13.08913309, -8.00976801, -13.47985348]), \n        'FP2-F8': array([-2.67838828e+02,  1.95360195e-01,  1.95360195e-01, ..., 6.83760684e+00,  6.05616606e+00,  6.44688645e+00]), \n        'F8-T8': array([ 57.24053724,   0.1953602 ,   0.1953602 , ...,  -2.53968254,  -9.96336996, -12.6984127 ]), \n        'T8-P8': array([44.73748474,  0.1953602 ,  0.1953602 , ..., 16.996337  , 22.46642247, 26.37362637]), \n       'P8-O2': array([ 74.82295482,   0.1953602 ,  -0.1953602 , ..., -17.38705739, -1.75824176,  -2.53968254]), \n        'FZ-CZ': array([-106.08058608,    0.1953602 ,    0.1953602 , ...,   24.81074481, 28.71794872,   28.71794872]), \n         'CZ-PZ': array([84.59096459,  0.1953602 ,  0.1953602 , ..., 18.94993895, 20.51282051, 18.16849817]), \n       'P7-T7': array([ 43.17460317,   0.1953602 ,   0.1953602 , ..., -48.25396825, -44.73748474, -34.18803419]), \n       'T7-FT9': array([-57.24053724,   0.1953602 ,   0.1953602 , ..., -11.91697192,  -3.71184371,   2.14896215]), \n        'FT9-FT10': array([-2.64713065e+02,  1.95360195e-01,  5.86080586e-01, ..., 9.76800977e-01, -1.58241758e+01, -2.94993895e+01]), \n        'FT10-T8': array([ 94.74969475,   0.1953602 ,   0.1953602 , ...,  -7.22832723, -10.35409035, -13.47985348]), \n       'T8-P8-2': array([44.73748474,  0.1953602 ,  0.1953602 , ..., 16.996337  , 22.46642247, 26.37362637]), \n       'metadata': {'seizures': 0, 'times': [], 'channels': ['FP1-F7', 'F7-T7', 'T7-P7', 'P7-O1', 'FP1-F3', 'F3-C3', 'C3-P3', 'P3-O1', 'FP2-F4', 'F4-C4', 'C4-P4', 'P4-O2', 'FP2-F8', 'F8-T8', 'T8-P8', 'P8-O2', 'FZ-CZ', 'CZ-PZ', 'P7-T7', 'T7-FT9', 'FT9-FT10', 'FT10-T8', 'T8-P8-2']}}\n        \"\"\"\n        signal = []\n        for channel in channels:\n            if channel in record:\n                signal.append(record[channel])\n            else:\n                raise ValueError(f\"Channel {channel} not found in record {record}\")\n        signal = np.array(signal)\n\n        if \"times\" in record[\"metadata\"]:\n            seizure_times = record[\"metadata\"][\"times\"]\n        else:\n            seizure_times = []\n\n        # split the signal into segments on the second dimension by SAMPLING_RATE * 10 seconds\n        for i in range(0, signal.shape[1], SAMPLING_RATE * 10):\n            segment = signal[:, i : i + 10 * SAMPLING_RATE]\n            if segment.shape[1] == 10 * SAMPLING_RATE:\n                # judge whether the segment contains seizures\n                label = 0\n\n                for seizure_time in seizure_times:\n                    if (\n                        i < seizure_time[0] < i + 10 * SAMPLING_RATE\n                        or i < seizure_time[1] < i + 10 * SAMPLING_RATE\n                    ):\n                        label = 1\n                        break\n\n                # save the segment\n                pickle.dump(\n                    {\"X\": segment, \"y\": label},\n                    open(\n                        os.path.join(out_folder, f\"{f.split('.')[0]}-{i}.pkl\"),\n                        \"wb\",\n                    ),\n                )\n\n        for idx, seizure_time in enumerate(seizure_times):\n            for i in range(\n                max(0, seizure_time[0] - SAMPLING_RATE),\n                min(seizure_time[1] + SAMPLING_RATE, signal.shape[1]),\n                5 * SAMPLING_RATE,\n            ):\n                segment = signal[:, i : i + 10 * SAMPLING_RATE]\n                label = 1\n                # save the segment\n                pickle.dump(\n                    {\"X\": segment, \"y\": label},\n                    open(\n                        os.path.join(\n                            out_folder, f\"{f.split('.')[0]}-s-{idx}-add-{i}.pkl\"\n                        ),\n                        \"wb\",\n                    ),\n                )\n\n\n# parallel parameters\nfolders = os.listdir(root)\nout_folders = []\nfor folder in folders:\n    if folder in test_pats:\n        out_folder = os.path.join(out, \"test\")\n    elif folder in val_pats:\n        out_folder = os.path.join(out, \"val\")\n    else:\n        out_folder = os.path.join(out, \"train\")\n\n    if not os.path.exists(out_folder):\n        os.makedirs(out_folder)\n\n    out_folders.append(out_folder)\n\n# process in parallel\nwith mp.Pool(mp.cpu_count()) as pool:\n    res = pool.starmap(sub_to_segments, zip(folders, out_folders))\n"}
{"_id": "beir_output_preprocessing/CHB-MIT/process1.py", "title": "", "text": "import os\nfrom collections import defaultdict\nimport pyedflib\nimport pyedflib.highlevel as hl\nimport numpy as np\nimport copy\nimport shutil\nimport bz2\nimport pickle\nimport _pickle as cPickle\nimport multiprocessing as mp\n\n\n# Pickle a file and then compress it into a file with extension\ndef compressed_pickle(title, data):\n    # with bz2.BZ2File(title + '.pbz2', 'w') as f:\n    #     cPickle.dump(data, f)\n    pickle.dump(data, open(title, \"wb\"))\n\n\n# Process metadata\ndef process_metadata(summary, filename):\n    f = open(summary, \"r\")\n\n    metadata = {}\n    lines = f.readlines()\n    times = []\n    for i in range(len(lines)):\n        line = lines[i].split()\n        if len(line) == 3 and line[2] == filename:\n            j = i + 1\n            processed = False\n            while not processed:\n                if lines[j].split()[0] == \"Number\":\n                    seizures = int(lines[j].split()[-1])\n                    processed = True\n                j = j + 1\n\n            # If file has seizures get start and end time\n            if seizures > 0:\n                j = i + 1\n                for s in range(seizures):\n                    # Save start and end time of each seizure\n                    processed = False\n                    while not processed:\n                        l = lines[j].split()\n                        # print(l)\n\n                        if l[0] == \"Seizure\" and \"Start\" in l:\n                            start = int(l[-2]) * 256 - 1  # Index of start time\n                            end = (\n                                int(lines[j + 1].split()[-2]) * 256 - 1\n                            )  # Index of end time\n                            processed = True\n                        j = j + 1\n                    times.append((start, end))\n\n            metadata[\"seizures\"] = seizures\n            metadata[\"times\"] = times\n\n    return metadata\n\n\n# Keep some channels from a .edf and ignore the others\ndef drop_channels(edf_source, edf_target=None, to_keep=None, to_drop=None):\n    signals, signal_headers, header = hl.read_edf(\n        edf_source, ch_nrs=to_keep, digital=False\n    )\n    clean_file = {}\n    for signal, header in zip(signals, signal_headers):\n        channel = header.get(\"label\")\n        if channel in clean_file.keys():\n            channel = channel + \"-2\"\n        clean_file[channel] = signal\n    return clean_file\n\n\n# At first, it permuted the channels of a edf signal\n# Now, only keeps valid channels and compress+save into pkl\ndef move_channels(clean_dict, channels, target):\n    # Keep only valid channels\n    keys_to_delete = []\n    for key in clean_dict:\n        if key != \"metadata\" and key not in channels.keys():\n            keys_to_delete.append(key)\n    for key in keys_to_delete:\n        del clean_dict[key]\n\n    # Get size of the numpy array\n    size = 0\n    for item in clean_dict.keys():\n        if item != \"metadata\":\n            size = len(clean_dict.get(item))\n            break\n\n    for k in channels.keys():\n        if k not in clean_dict.keys():\n            clean_dict[k] = np.zeros(size, dtype=float)\n\n    compressed_pickle(target + \".pkl\", clean_dict)\n\n\n# Process edf files of a pacient from start number to end number\ndef process_files(pacient, valid_channels, channels, start, end):\n    for num in range(start, end + 1):\n        to_keep = []\n\n        num = (\"0\" + str(num))[-2:]\n        filename = \"{path}/chb{p}/chb{p}_{n}.edf\".format(\n            path=signals_path, p=pacient, n=num\n        )\n\n        # Check with (cleaned) reference file  if we have to remove more channels\n        try:\n            signals, signal_headers, header = hl.read_edf(filename, digital=False)\n            n = 0\n            for h in signal_headers:\n                if h.get(\"label\") in valid_channels:\n                    if n not in to_keep:\n                        to_keep.append(n)\n                n = n + 1\n\n        except OSError:\n            print(\"****************************************\")\n            print(\"WARNING - Do not worry\")\n            print(\"File\", filename, \"does not exist.\\nProcessing next file.\")\n            print(\"****************************************\")\n            continue\n\n        if len(to_keep) > 0:\n            try:\n                print(\n                    \"Removing\",\n                    len(signal_headers) - len(to_keep),\n                    \"channels from file \",\n                    \"chb{p}_{n}.edf\".format(p=pacient, n=num),\n                )\n                clean_dict = drop_channels(\n                    filename,\n                    edf_target=\"{path}/chb{p}/chb{p}_{n}.edf\".format(\n                        path=clean_path, p=pacient, n=num\n                    ),\n                    to_keep=to_keep,\n                )\n                print(\"Processing file \", filename)\n            except AssertionError:\n                print(\"****************************************\")\n                print(\"WARNING - Do not worry\")\n                print(\"File\", filename, \"does not exist.\\nProcessing next file.\")\n                print(\"****************************************\")\n                continue\n\n        metadata = process_metadata(\n            \"{path}/chb{p}/chb{p}-summary.txt\".format(path=signals_path, p=pacient),\n            \"chb{p}_{n}.edf\".format(p=pacient, n=num),\n        )\n        metadata[\"channels\"] = valid_channels\n        clean_dict[\"metadata\"] = metadata\n        target = \"{path}/chb{p}/chb{p}_{n}.edf\".format(\n            path=clean_path, p=pacient, n=num\n        )\n        move_channels(clean_dict, channels, target)\n\n\ndef start_process(pacient, num, start, end, sum_ind):\n    # Summary file\n    f = open(\n        \"{path}/chb{p}/chb{p}-summary.txt\".format(path=signals_path, p=pacient), \"r\"\n    )\n\n    channels = defaultdict(list)  # Dict of channels and indices\n    valid_channels = []  # Valid channels\n    to_keep = []  # Indices of channels we want to keep\n\n    channel_index = 1  # Index for each channel\n    summary_index = 0  # Index to choose which channel reference take from summary file\n\n    # Process summary file\n    for line in f:\n        line = line.split()\n        if len(line) == 0:\n            continue\n\n        if line[0] == \"Channels\" and line[1] == \"changed:\":\n            summary_index += 1\n\n        if (\n            line[0] == \"Channel\"\n            and summary_index == sum_ind\n            and (line[2] != \"-\" and line[2] != \".\")\n        ):  # '-' means a void channel\n            if (\n                line[2] in channels.keys()\n            ):  # In case of repeated channel just add '-2' to the label\n                name = line[2] + \"-2\"\n            else:\n                name = line[2]\n\n            # Add channel to dict and update lists\n            channels[name].append(str(channel_index))\n            channel_index += 1\n            valid_channels.append(name)\n            to_keep.append(int(line[1][:-1]) - 1)\n\n    # for item in channels.items(): print(item)\n\n    # Clean reference file\n    filename = \"{path}/chb{p}/chb{p}_{n}.edf\".format(\n        path=signals_path, p=pacient, n=num\n    )\n    target = \"{path}/chb{p}/chb{p}_{n}.edf\".format(path=clean_path, p=pacient, n=num)\n\n    if not os.path.exists(\"{path}/chb{p}\".format(p=pacient, path=clean_path)):\n        os.makedirs(\"{path}/chb{p}\".format(p=pacient, path=clean_path))\n\n    clean_dict = drop_channels(filename, edf_target=target, to_keep=to_keep)\n\n    # Process metadata : Number of seizures and start/end time\n    metadata = process_metadata(\n        \"{path}/chb{p}/chb{p}-summary.txt\".format(path=signals_path, p=pacient),\n        \"chb{p}_{n}.edf\".format(p=pacient, n=num),\n    )\n\n    metadata[\"channels\"] = valid_channels\n    clean_dict[\"metadata\"] = metadata\n\n    compressed_pickle(target + \".pkl\", clean_dict)\n\n    # Process the rest of the files to get same channels as reference file\n    process_files(pacient, valid_channels, channels, start, end)\n\n\n# PARAMETERS\nsignals_path = r\"/data/datasets/chb-mit-scalp-eeg-database-1.0.0\"  # Path to the data main directory\nclean_path = r\"/data/datasets/BigDownstream/chb-mit/processed\"  # Path where to store clean data\n\nif not os.path.exists(clean_path):\n    os.makedirs(clean_path)\n\n# Clean pacients one by one manually with these parameters\npacient = \"04\"\nnum = \"01\"  # Reference file\nsummary_index = 0  # Index of channels summary reference\nstart = 28  # Number of first file to process\nend = 28  # Number of last file to process\n# Start the process\n# start_process(pacient, num, start, end, summary_index)\n\n\n# FULL DATA PROCESS\nparameters = [\n    (\"01\", \"01\", 2, 46, 0),\n    (\"02\", \"01\", 2, 35, 0),\n    (\"03\", \"01\", 2, 38, 0),\n    (\"05\", \"01\", 2, 39, 0),\n    (\"06\", \"01\", 2, 24, 0),\n    (\"07\", \"01\", 2, 19, 0),\n    (\"08\", \"02\", 3, 29, 0),\n    (\"10\", \"01\", 2, 89, 0),\n    (\"11\", \"01\", 2, 99, 0),\n    (\"14\", \"01\", 2, 42, 0),\n    (\"20\", \"01\", 2, 68, 0),\n    (\"21\", \"01\", 2, 33, 0),\n    (\"22\", \"01\", 2, 77, 0),\n    (\"23\", \"06\", 7, 20, 0),\n    (\"24\", \"01\", 3, 21, 0),\n    (\"04\", \"07\", 1, 43, 1),\n    (\"09\", \"02\", 1, 19, 1),\n    (\"15\", \"02\", 1, 63, 1),\n    (\"16\", \"01\", 2, 19, 0),\n    (\"18\", \"02\", 1, 36, 1),\n    (\"19\", \"02\", 1, 30, 1),\n]\n\n# parameters = [\n#     (\"12\", \"\")\n# ]\n\n\n\n\nwith mp.Pool(mp.cpu_count()) as pool:\n    res = pool.starmap(start_process, parameters)\n"}
{"_id": "beir_output_preprocessing/CHB-MIT/__init__.py", "title": "", "text": ""}
{"_id": "beir_output_preprocessing/ISRUC/prepare_ISRUC_1.py", "title": "", "text": "# %%\nfrom mne.io import concatenate_raws\nfrom edf_ import read_raw_edf\nimport matplotlib.pyplot as plt\nimport mne\nimport os\nimport numpy as np\nfrom tqdm import tqdm\nimport xml.etree.ElementTree as ET\nfrom sklearn.preprocessing import StandardScaler\n\n\ndir_path = r'/data/datasets2/ISRUC_extracted/group1'\n\nseq_dir = r'/data/datasets/BigDownstream/ISRUC/precessed_filter_35/seq'\nlabel_dir = r'/data/datasets/BigDownstream/ISRUC/precessed_filter_35/labels'\n\npsg_f_names = []\nlabel_f_names = []\nfor i in range(1, 101):\n    numstr = str(i)\n    psg_f_names.append(f'{dir_path}/{numstr}/{numstr}.rec')\n    label_f_names.append(f'{dir_path}/{numstr}/{numstr}_1.txt')\n\n# psg_f_names.sort()\n# label_f_names.sort()\n\npsg_label_f_pairs = []\nfor psg_f_name, label_f_name in zip(psg_f_names, label_f_names):\n    if psg_f_name[:-4] == label_f_name[:-6]:\n        psg_label_f_pairs.append((psg_f_name, label_f_name))\nfor item in psg_label_f_pairs:\n    print(item)\n\nlabel2id = {'0': 0,\n            '1': 1,\n            '2': 2,\n            '3': 3,\n            '5': 4,}\nprint(label2id)\n# %%\n# signal_name = ['LOC-A2', 'F4-A1']\nn = 0\nnum_seqs = 0\nnum_labels = 0\nfor psg_f_name, label_f_name in tqdm(psg_label_f_pairs):\n    n += 1\n    labels_list = []\n\n    raw = read_raw_edf(os.path.join(dir_path, psg_f_name), preload=True)\n    # raw.pick_channels(signal_name)\n    # raw.resample(sfreq=200)\n    raw.filter(0.3, 35, fir_design='firwin')\n    raw.notch_filter((50))\n    print(raw.info)\n\n    psg_array = raw.to_data_frame().values\n    # print(psg_array[:10, 0])\n    print(psg_array.shape)\n    psg_array = psg_array[:, 1:]\n    psg_array = psg_array[:, 2:8]\n    print(psg_array.shape)\n\n    # std = StandardScaler()\n    # psg_array = std.fit_transform(psg_array)\n    # print(psg_array[:10, :])\n\n    i = psg_array.shape[0] % (30 * 200)\n    if i > 0:\n        psg_array = psg_array[:-i, :]\n    print(psg_array.shape)\n    psg_array = psg_array.reshape(-1, 30 * 200, 6)\n    print(psg_array.shape)\n\n    a = psg_array.shape[0] % 20\n    if a > 0:\n        psg_array = psg_array[:-a, :, :]\n    print(psg_array.shape)\n    psg_array = psg_array.reshape(-1, 20, 30 * 200, 6)\n    epochs_seq = psg_array.transpose(0, 1, 3, 2)\n    print(epochs_seq.shape)\n    # print(epochs_seq[0, 0, :, 100])\n\n    for line in open(os.path.join(dir_path, label_f_name)).readlines():\n        line_str = line.strip()\n        if line_str != '':\n            labels_list.append(label2id[line_str])\n    labels_array = np.array(labels_list)\n    if a > 0:\n        labels_array = labels_array[:-a]\n    labels_seq = labels_array.reshape(-1, 20)\n    print(labels_seq.shape)\n\n    if not os.path.isdir(rf'{seq_dir}/ISRUC-group1-{str(n)}'):\n        os.makedirs(rf'{seq_dir}/ISRUC-group1-{str(n)}')\n    for seq in epochs_seq:\n        seq_name = rf'{seq_dir}/ISRUC-group1-{str(n)}/ISRUC-group1-{str(n)}-{str(num_seqs)}.npy'\n        with open(seq_name, 'wb') as f:\n            np.save(f, seq)\n        num_seqs += 1\n\n    if not os.path.isdir(rf'{label_dir}/ISRUC-group1-{str(n)}'):\n        os.makedirs(rf'{label_dir}/ISRUC-group1-{str(n)}')\n    for label in labels_seq:\n        label_name = rf'{label_dir}/ISRUC-group1-{str(n)}/ISRUC-group1-{str(n)}-{str(num_labels)}.npy'\n        with open(label_name, 'wb') as f:\n            np.save(f, label)\n        num_labels += 1\n\n\n\n"}
{"_id": "beir_output_preprocessing/ISRUC/__init__.py", "title": "", "text": ""}
{"_id": "beir_output_utils/signaltools.py", "title": "", "text": "\"\"\"\nsignaltools.py (Only a few functions) of Scipy's Signal processing package, implimented for PyTorch\nCurrently implimeted: resample\n\n\"\"\"\n\nimport sys\nimport torch\nimport torch.fft\n\n__author__ = \"Soumick Chatterjee\"\n__copyright__ = \"Copyright 2020, Soumick Chatterjee & OvGU:ESF:MEMoRIAL\"\n__credits__ = [\"Soumick Chatterjee\"]\n\n__license__ = \"GPL\"\n__version__ = \"0.0.1\"\n__email__ = \"soumick.chatterjee@ovgu.de\"\n__status__ = \"Only x, num and axis of the resample function have been tested\"\n\n\ndef _isrealobj(x):\n    d = x.dtype\n    if d in (torch.complex32, torch.complex64, torch.complex128):\n        return False\n    else:\n        return True\n\n\ndef resample(x, num, t=None, axis=0, window=None, domain='time'):\n    \"\"\"\n    Resample `x` to `num` samples using Fourier method along the given axis.\n\n    The resampled signal starts at the same value as `x` but is sampled\n    with a spacing of ``len(x) / num * (spacing of x)``.  Because a\n    Fourier method is used, the signal is assumed to be periodic.\n\n    Parameters\n    ----------\n    x : array_like\n        The data to be resampled.\n    num : int or array_like\n        The number of samples in the resampled signal.\n        If array_like is supplied, then the resample function will be\n        called recursively for each element of num.\n    t : array_like, optional\n        If `t` is given, it is assumed to be the equally spaced sample\n        positions associated with the signal data in `x`.\n    axis : (int, optional) or (array_like)\n        The axis of `x` that is resampled.  Default is 0.\n        If num is array_like, then axis has to be supplied and has to be array_like.\n        Each element of axis should have one-on-on mapping wtih num.\n        If num is int but axis is array_like, then num will be repeated and will be\n        made a list with same number of elements as axis. Then will proceed both as array_like.\n    window : array_like, callable, string, float, or tuple, optional\n        Specifies the window applied to the signal in the Fourier\n        domain.  See below for details.\n    domain : string, optional\n        A string indicating the domain of the input `x`:\n        ``time`` Consider the input `x` as time-domain (Default),\n        ``freq`` Consider the input `x` as frequency-domain.\n\n    Returns\n    -------\n    resampled_x or (resampled_x, resampled_t)\n        Either the resampled array, or, if `t` was given, a tuple\n        containing the resampled array and the corresponding resampled\n        positions.\n\n    See Also\n    --------\n    decimate : Downsample the signal after applying an FIR or IIR filter.\n    resample_poly : Resample using polyphase filtering and an FIR filter.\n\n    Notes\n    -----\n    The argument `window` controls a Fourier-domain window that tapers\n    the Fourier spectrum before zero-padding to alleviate ringing in\n    the resampled values for sampled signals you didn't intend to be\n    interpreted as band-limited.\n\n    If `window` is a function, then it is called with a vector of inputs\n    indicating the frequency bins (i.e. fftfreq(x.shape[axis]) ).\n\n    If `window` is an array of the same length as `x.shape[axis]` it is\n    assumed to be the window to be applied directly in the Fourier\n    domain (with dc and low-frequency first).\n\n    For any other type of `window`, the function `scipy.signal.get_window`\n    is called to generate the window.\n\n    The first sample of the returned vector is the same as the first\n    sample of the input vector.  The spacing between samples is changed\n    from ``dx`` to ``dx * len(x) / num``.\n\n    If `t` is not None, then it is used solely to calculate the resampled\n    positions `resampled_t`\n\n    As noted, `resample` uses FFT transformations, which can be very\n    slow if the number of input or output samples is large and prime;\n    see `scipy.fft.fft`.\n\n    Examples\n    --------\n    Note that the end of the resampled data rises to meet the first\n    sample of the next cycle:\n\n    >>> from scipy import signal\n\n    >>> x = np.linspace(0, 10, 20, endpoint=False)\n    >>> y = np.cos(-x**2/6.0)\n    >>> f = signal.resample(y, 100)\n    >>> xnew = np.linspace(0, 10, 100, endpoint=False)\n\n    >>> import matplotlib.pyplot as plt\n    >>> plt.plot(x, y, 'go-', xnew, f, '.-', 10, y[0], 'ro')\n    >>> plt.legend(['data', 'resampled'], loc='best')\n    >>> plt.show()\n    \"\"\"\n\n    if domain not in ('time', 'freq'):\n        raise ValueError(\"Acceptable domain flags are 'time' or\"\n                         \" 'freq', not domain={}\".format(domain))\n\n    if hasattr(axis, \"__len__\") and not hasattr(num, \"__len__\"):\n        num = [num] * len(axis)\n\n    if hasattr(num, \"__len__\"):\n        if hasattr(axis, \"__len__\") and len(num) == len(axis):\n            _temp = x\n            _t_list = []\n            for i in range(len(num)):\n                _num = num[i]\n                _axis = axis[i]\n                if t is None:\n                    _temp = resample(_temp, _num, t, _axis, window, domain)\n                else:\n                    _temp, _t = resample(_temp, _num, t, _axis, window, domain)\n                    _t_list.append(_t)\n            if t is None:\n                return _temp\n            else:\n                return _temp, torch.stack(_t_list)\n        else:\n            raise ValueError(\"if num is array like, then axis also has to be array like and of the same length\")\n\n    Nx = x.shape[axis]\n\n    # Check if we can use faster real FFT\n    real_input = _isrealobj(x)\n\n    if domain == 'time':\n        # Forward transform\n        if real_input:\n            X = torch.fft.rfft(x, dim=axis)\n        else:  # Full complex FFT\n            X = torch.fft.fft(x, dim=axis)\n    else:  # domain == 'freq'\n        X = x\n\n    # Apply window to spectrum\n    if window is not None:\n        if callable(window):\n            W = window(torch.fft.fftfreq(Nx))\n        elif isinstance(window, torch.Tensor):\n            if window.shape != (Nx,):\n                raise ValueError('window must have the same length as data')\n            W = window\n        else:\n            sys.exit(\n                \"Window can only be either a function or Tensor. Window generation with get_window function of scipy.signal hasn't been implimented yet.\")\n            W = torch.fft.ifftshift(get_window(window, Nx))\n\n        newshape_W = [1] * x.ndim\n        newshape_W[axis] = X.shape[axis]\n        if real_input:\n            # Fold the window back on itself to mimic complex behavior\n            W_real = W.clone()\n            W_real[1:] += W_real[-1:0:-1]\n            W_real[1:] *= 0.5\n            X *= W_real[:newshape_W[axis]].reshape(newshape_W)\n        else:\n            X *= W.reshape(newshape_W)\n\n    # Copy each half of the original spectrum to the output spectrum, either\n    # truncating high frequences (downsampling) or zero-padding them\n    # (upsampling)\n\n    # Placeholder array for output spectrum\n    newshape = list(x.shape)\n    if real_input:\n        newshape[axis] = num // 2 + 1\n    else:\n        newshape[axis] = num\n    Y = torch.zeros(newshape, dtype=X.dtype, device=x.device)\n\n    # Copy positive frequency components (and Nyquist, if present)\n    N = min(num, Nx)\n    nyq = N // 2 + 1  # Slice index that includes Nyquist if present\n    sl = [slice(None)] * x.ndim\n    sl[axis] = slice(0, nyq)\n    Y[tuple(sl)] = X[tuple(sl)]\n    if not real_input:\n        # Copy negative frequency components\n        if N > 2:  # (slice expression doesn't collapse to empty array)\n            sl[axis] = slice(nyq - N, None)\n            Y[tuple(sl)] = X[tuple(sl)]\n\n    # Split/join Nyquist component(s) if present\n    # So far we have set Y[+N/2]=X[+N/2]\n    if N % 2 == 0:\n        if num < Nx:  # downsampling\n            if real_input:\n                sl[axis] = slice(N // 2, N // 2 + 1)\n                Y[tuple(sl)] *= 2.\n            else:\n                # select the component of Y at frequency +N/2,\n                # add the component of X at -N/2\n                sl[axis] = slice(-N // 2, -N // 2 + 1)\n                Y[tuple(sl)] += X[tuple(sl)]\n        elif Nx < num:  # upsampling\n            # select the component at frequency +N/2 and halve it\n            sl[axis] = slice(N // 2, N // 2 + 1)\n            Y[tuple(sl)] *= 0.5\n            if not real_input:\n                temp = Y[tuple(sl)]\n                # set the component at -N/2 equal to the component at +N/2\n                sl[axis] = slice(num - N // 2, num - N // 2 + 1)\n                Y[tuple(sl)] = temp\n\n    # Inverse transform\n    if real_input:\n        y = torch.fft.irfft(Y, num, dim=axis)\n    else:\n        y = torch.fft.ifft(Y, dim=axis, overwrite_x=True)\n\n    y *= (float(num) / float(Nx))\n\n    if t is None:\n        return y\n    else:\n        new_t = torch.arange(0, num) * (t[1] - t[0]) * Nx / float(num) + t[0]\n        return y, new_t"}
{"_id": "beir_output_utils/__init__.py", "title": "", "text": ""}
{"_id": "beir_output_utils/util.py", "title": "", "text": "import os\nimport random\nimport signal\n\nimport numpy as np\nimport torch\nimport torch.distributed as dist\nfrom tqdm import tqdm\nimport random\n\ndef generate_mask(bz, ch_num, patch_num, mask_ratio, device):\n    mask = torch.zeros((bz, ch_num, patch_num), dtype=torch.long, device=device)\n    mask = mask.bernoulli_(mask_ratio)\n    return mask\n\ndef to_tensor(array):\n    return torch.from_numpy(array).float()\n\n\nif __name__ == '__main__':\n    a = generate_mask(192, 32, 15, mask_ratio=0.5, device=None)\n    print(a)"}
{"_id": "mne_mne_parallel.py_parallel_func_code", "title": "parallel_func", "text": "def parallel_func(\n    func,\n    n_jobs,\n    max_nbytes=\"auto\",\n    pre_dispatch=\"n_jobs\",\n    total=None,\n    prefer=None,\n    *,\n    max_jobs=None,\n    verbose=None,\n):\n    \"\"\"Return parallel instance with delayed function.\n\n    Util function to use joblib only if available\n\n    Parameters\n    ----------\n    func : callable\n        A function.\n    %(n_jobs)s\n    max_nbytes : int | str | None\n        Threshold on the minimum size of arrays passed to the workers that\n        triggers automated memory mapping. Can be an int in Bytes,\n        or a human-readable string, e.g., '1M' for 1 megabyte.\n        Use None to disable memmaping of large arrays. Use 'auto' to\n        use the value set using :func:`mne.set_memmap_min_size`.\n    pre_dispatch : int | str\n        See :class:`joblib.Parallel`.\n    total : int | None\n        If int, use a progress bar to display the progress of dispatched\n        jobs. This should only be used when directly iterating, not when\n        using ``split_list`` or :func:`np.array_split`.\n        If None (default), do not add a progress bar.\n    prefer : str | None\n        If str, can be ``\"processes\"`` or ``\"threads\"``.\n        See :class:`joblib.Parallel`.\n\n        .. versionadded:: 0.18\n    max_jobs : int | None\n        The upper limit of jobs to use. This is useful when you know ahead\n        of a the maximum number of calls into :class:`joblib.Parallel` that\n        you will possibly want or need, and the returned ``n_jobs`` should not\n        exceed this value regardless of how many jobs the user requests.\n    %(verbose)s INFO or DEBUG\n        will print parallel status, others will not.\n\n    Returns\n    -------\n    parallel: instance of joblib.Parallel or list\n        The parallel object.\n    my_func: callable\n        ``func`` if not parallel or delayed(func).\n    n_jobs: int\n        Number of jobs >= 1.\n    \"\"\"\n    should_print = logger.level <= logging.INFO\n    # for a single job, we don't need joblib\n    _validate_type(n_jobs, (\"int-like\", None))\n    if n_jobs != 1:\n        try:\n            from joblib import Parallel, delayed\n        except ImportError:\n            if n_jobs is not None:\n                warn(\"joblib not installed. Cannot run in parallel.\")\n            n_jobs = 1\n    if n_jobs == 1:\n        n_jobs = 1\n        my_func = func\n        parallel = list\n    else:\n        # check if joblib is recent enough to support memmaping\n        cache_dir = get_config(\"MNE_CACHE_DIR\", None)\n        if isinstance(max_nbytes, str) and max_nbytes == \"auto\":\n            max_nbytes = get_config(\"MNE_MEMMAP_MIN_SIZE\", None)\n\n        if max_nbytes is not None and cache_dir is None:\n            logger.info(\n                'joblib supports memapping pool but \"MNE_CACHE_DIR\" '\n                \"is not set in MNE-Python config. To enable it, use, \"\n                \"e.g., mne.set_cache_dir('/tmp/shm'). This will \"\n                \"store temporary files under /dev/shm and can result \"\n                \"in large memory savings.\"\n            )\n\n        # create keyword arguments for Parallel\n        kwargs = {\"verbose\": 5 if should_print and total is None else 0}\n        kwargs[\"pre_dispatch\"] = pre_dispatch\n        kwargs[\"prefer\"] = prefer\n        if cache_dir is None:\n            max_nbytes = None  # disable memmaping\n        kwargs[\"temp_folder\"] = cache_dir\n        kwargs[\"max_nbytes\"] = max_nbytes\n        n_jobs_orig = n_jobs\n        if n_jobs is not None:  # https://github.com/joblib/joblib/issues/1473\n            kwargs[\"n_jobs\"] = n_jobs\n        parallel = Parallel(**kwargs)\n        n_jobs = _check_n_jobs(parallel.n_jobs)\n        logger.debug(f\"Got {n_jobs} parallel jobs after requesting {n_jobs_orig}\")\n        if max_jobs is not None:\n            n_jobs = min(n_jobs, max(_ensure_int(max_jobs, \"max_jobs\"), 1))\n\n        def run_verbose(*args, verbose=logger.level, **kwargs):\n            with use_log_level(verbose=verbose):\n                return func(*args, **kwargs)\n\n        my_func = delayed(run_verbose)\n\n        # if we got that n_jobs=1, we shouldn't bother with any parallelization\n        if n_jobs == 1:\n            # TODO: Hack until https://github.com/joblib/joblib/issues/1687 lands\n            try:\n                backend_repr = str(parallel._backend)\n            except Exception:\n                backend_repr = \"\"\n            is_local = any(\n                f\"{x}Backend\" in backend_repr\n                for x in (\"Loky\", \"Threading\", \"Multiprocessing\")\n            )\n            if is_local:\n                my_func = func\n                parallel = list\n\n    if total is not None:\n\n        def parallel_progress(op_iter):\n            return parallel(ProgressBar(iterable=op_iter, max_value=total))\n\n        parallel_out = parallel_progress\n    else:\n        parallel_out = parallel\n    return parallel_out, my_func, n_jobs", "metadata": {}}
{"_id": "mne_mne_cov.py_read_cov_code", "title": "read_cov", "text": "def read_cov(fname, verbose=None):\n    \"\"\"Read a noise covariance from a FIF file.\n\n    Parameters\n    ----------\n    fname : path-like\n        The path-like of file containing the covariance matrix. It should end\n        with ``-cov.fif`` or ``-cov.fif.gz``.\n    %(verbose)s\n\n    Returns\n    -------\n    cov : Covariance\n        The noise covariance matrix.\n\n    See Also\n    --------\n    write_cov, compute_covariance, compute_raw_covariance\n    \"\"\"\n    from ._fiff.open import fiff_open\n\n    check_fname(\n        fname, \"covariance\", (\"-cov.fif\", \"-cov.fif.gz\", \"_cov.fif\", \"_cov.fif.gz\")\n    )\n    fname = _check_fname(fname=fname, must_exist=True, overwrite=\"read\")\n    f, tree, _ = fiff_open(fname)\n    with f as fid:\n        return Covariance(\n            **_read_cov(fid, tree, FIFF.FIFFV_MNE_NOISE_COV, limited=True)\n        )", "metadata": {}}
{"_id": "mne_mne_cov.py_make_ad_hoc_cov_code", "title": "make_ad_hoc_cov", "text": "def make_ad_hoc_cov(info, std=None, *, verbose=None):\n    \"\"\"Create an ad hoc noise covariance.\n\n    Parameters\n    ----------\n    %(info_not_none)s\n    std : dict of float | None\n        Standard_deviation of the diagonal elements. If dict, keys should be\n        ``'grad'`` for gradiometers, ``'mag'`` for magnetometers and ``'eeg'``\n        for EEG channels. If None, default values will be used (see Notes).\n    %(verbose)s\n\n    Returns\n    -------\n    cov : instance of Covariance\n        The ad hoc diagonal noise covariance for the M/EEG data channels.\n\n    Notes\n    -----\n    The default noise values are 5 fT/cm, 20 fT, and 0.2 \u00b5V for gradiometers,\n    magnetometers, and EEG channels respectively.\n\n    .. versionadded:: 0.9.0\n    \"\"\"\n    picks = pick_types(info, meg=True, eeg=True, exclude=())\n    std = _handle_default(\"noise_std\", std)\n\n    data = np.zeros(len(picks))\n    for meg, eeg, val in zip(\n        (\"grad\", \"mag\", False),\n        (False, False, True),\n        (std[\"grad\"], std[\"mag\"], std[\"eeg\"]),\n    ):\n        these_picks = pick_types(info, meg=meg, eeg=eeg)\n        data[np.searchsorted(picks, these_picks)] = val * val\n    ch_names = [info[\"ch_names\"][pick] for pick in picks]\n    return Covariance(data, ch_names, info[\"bads\"], info[\"projs\"], nfree=0)", "metadata": {}}
{"_id": "mne_mne_cov.py_compute_raw_covariance_code", "title": "compute_raw_covariance", "text": "def compute_raw_covariance(\n    raw,\n    tmin=0,\n    tmax=None,\n    tstep=0.2,\n    reject=None,\n    flat=None,\n    picks=None,\n    method=\"empirical\",\n    method_params=None,\n    cv=3,\n    scalings=None,\n    n_jobs=None,\n    return_estimators=False,\n    reject_by_annotation=True,\n    rank=None,\n    verbose=None,\n):\n    \"\"\"Estimate noise covariance matrix from a continuous segment of raw data.\n\n    It is typically useful to estimate a noise covariance from empty room\n    data or time intervals before starting the stimulation.\n\n    .. note:: To estimate the noise covariance from epoched data, use\n              :func:`mne.compute_covariance` instead.\n\n    Parameters\n    ----------\n    raw : instance of Raw\n        Raw data.\n    tmin : float\n        Beginning of time interval in seconds. Defaults to 0.\n    tmax : float | None (default None)\n        End of time interval in seconds. If None (default), use the end of the\n        recording.\n    tstep : float (default 0.2)\n        Length of data chunks for artifact rejection in seconds.\n        Can also be None to use a single epoch of (tmax - tmin)\n        duration. This can use a lot of memory for large ``Raw``\n        instances.\n    reject : dict | None (default None)\n        Rejection parameters based on peak-to-peak amplitude.\n        Valid keys are 'grad' | 'mag' | 'eeg' | 'eog' | 'ecg'.\n        If reject is None then no rejection is done. Example::\n\n            reject = dict(grad=4000e-13, # T / m (gradiometers)\n                          mag=4e-12, # T (magnetometers)\n                          eeg=40e-6, # V (EEG channels)\n                          eog=250e-6 # V (EOG channels)\n                          )\n\n    flat : dict | None (default None)\n        Rejection parameters based on flatness of signal.\n        Valid keys are 'grad' | 'mag' | 'eeg' | 'eog' | 'ecg', and values\n        are floats that set the minimum acceptable peak-to-peak amplitude.\n        If flat is None then no rejection is done.\n    %(picks_good_data_noref)s\n    method : str | list | None (default 'empirical')\n        The method used for covariance estimation.\n        See :func:`mne.compute_covariance`.\n\n        .. versionadded:: 0.12\n    method_params : dict | None (default None)\n        Additional parameters to the estimation procedure.\n        See :func:`mne.compute_covariance`.\n\n        .. versionadded:: 0.12\n    cv : int | sklearn.model_selection object (default 3)\n        The cross validation method. Defaults to 3, which will\n        internally trigger by default :class:`sklearn.model_selection.KFold`\n        with 3 splits.\n\n        .. versionadded:: 0.12\n    scalings : dict | None (default None)\n        Defaults to ``dict(mag=1e15, grad=1e13, eeg=1e6)``.\n        These defaults will scale magnetometers and gradiometers\n        at the same unit.\n\n        .. versionadded:: 0.12\n    %(n_jobs)s\n\n        .. versionadded:: 0.12\n    return_estimators : bool (default False)\n        Whether to return all estimators or the best. Only considered if\n        method equals 'auto' or is a list of str. Defaults to False.\n\n        .. versionadded:: 0.12\n    %(reject_by_annotation_epochs)s\n\n        .. versionadded:: 0.14\n    %(rank_none)s\n\n        .. versionadded:: 0.17\n\n        .. versionadded:: 0.18\n           Support for 'info' mode.\n    %(verbose)s\n\n    Returns\n    -------\n    cov : instance of Covariance | list\n        The computed covariance. If method equals 'auto' or is a list of str\n        and return_estimators equals True, a list of covariance estimators is\n        returned (sorted by log-likelihood, from high to low, i.e. from best\n        to worst).\n\n    See Also\n    --------\n    compute_covariance : Estimate noise covariance matrix from epoched data.\n\n    Notes\n    -----\n    This function will:\n\n    1. Partition the data into evenly spaced, equal-length epochs.\n    2. Load them into memory.\n    3. Subtract the mean across all time points and epochs for each channel.\n    4. Process the :class:`Epochs` by :func:`compute_covariance`.\n\n    This will produce a slightly different result compared to using\n    :func:`make_fixed_length_events`, :class:`Epochs`, and\n    :func:`compute_covariance` directly, since that would (with the recommended\n    baseline correction) subtract the mean across time *for each epoch*\n    (instead of across epochs) for each channel.\n    \"\"\"\n    tmin = 0.0 if tmin is None else float(tmin)\n    dt = 1.0 / raw.info[\"sfreq\"]\n    tmax = raw.times[-1] + dt if tmax is None else float(tmax)\n    tstep = tmax - tmin if tstep is None else float(tstep)\n    tstep_m1 = tstep - dt  # inclusive!\n    events = make_fixed_length_events(raw, 1, tmin, tmax, tstep)\n    logger.info(f\"Using up to {len(events)} segment{_pl(events)}\")\n\n    # don't exclude any bad channels, inverses expect all channels present\n    if picks is None:\n        # Need to include all good channels e.g. if eog rejection is to be used\n        picks = np.arange(raw.info[\"nchan\"])\n        pick_mask = np.isin(picks, _pick_data_channels(raw.info, with_ref_meg=False))\n    else:\n        pick_mask = slice(None)\n        picks = _picks_to_idx(raw.info, picks)\n    epochs = Epochs(\n        raw,\n        events,\n        1,\n        0,\n        tstep_m1,\n        baseline=None,\n        picks=picks,\n        reject=reject,\n        flat=flat,\n        verbose=_verbose_safe_false(),\n        preload=False,\n        proj=False,\n        reject_by_annotation=reject_by_annotation,\n    )\n    if method is None:\n        method = \"empirical\"\n    if isinstance(method, str) and method == \"empirical\":\n        # potentially *much* more memory efficient to do it the iterative way\n        picks = picks[pick_mask]\n        data = 0\n        n_samples = 0\n        mu = 0\n        # Read data in chunks\n        for raw_segment in epochs:\n            raw_segment = raw_segment[pick_mask]\n            mu += raw_segment.sum(axis=1)\n            data += np.dot(raw_segment, raw_segment.T)\n            n_samples += raw_segment.shape[1]\n        _check_n_samples(n_samples, len(picks))\n        data -= mu[:, None] * (mu[None, :] / n_samples)\n        data /= n_samples - 1.0\n        logger.info(\"Number of samples used : %d\", n_samples)\n        logger.info(\"[done]\")\n        ch_names = [raw.info[\"ch_names\"][k] for k in picks]\n        bads = [b for b in raw.info[\"bads\"] if b in ch_names]\n        return Covariance(data, ch_names, bads, raw.info[\"projs\"], nfree=n_samples - 1)\n    del picks, pick_mask\n\n    # This makes it equivalent to what we used to do (and do above for\n    # empirical mode), treating all epochs as if they were a single long one\n    epochs.load_data()\n    ch_means = epochs._data.mean(axis=0).mean(axis=1)\n    epochs._data -= ch_means[np.newaxis, :, np.newaxis]\n    # fake this value so there are no complaints from compute_covariance\n    epochs.baseline = (None, None)\n    return compute_covariance(\n        epochs,\n        keep_sample_mean=True,\n        method=method,\n        method_params=method_params,\n        cv=cv,\n        scalings=scalings,\n        n_jobs=n_jobs,\n        return_estimators=return_estimators,\n        rank=rank,\n    )", "metadata": {}}
{"_id": "mne_mne_cov.py_compute_covariance_code", "title": "compute_covariance", "text": "def compute_covariance(\n    epochs,\n    keep_sample_mean=True,\n    tmin=None,\n    tmax=None,\n    projs=None,\n    method=\"empirical\",\n    method_params=None,\n    cv=3,\n    scalings=None,\n    n_jobs=None,\n    return_estimators=False,\n    on_mismatch=\"raise\",\n    rank=None,\n    verbose=None,\n):\n    \"\"\"Estimate noise covariance matrix from epochs.\n\n    The noise covariance is typically estimated on pre-stimulus periods\n    when the stimulus onset is defined from events.\n\n    If the covariance is computed for multiple event types (events\n    with different IDs), the following two options can be used and combined:\n\n        1. either an Epochs object for each event type is created and\n           a list of Epochs is passed to this function.\n        2. an Epochs object is created for multiple events and passed\n           to this function.\n\n    .. note:: To estimate the noise covariance from non-epoched raw data, such\n              as an empty-room recording, use\n              :func:`mne.compute_raw_covariance` instead.\n\n    Parameters\n    ----------\n    epochs : instance of Epochs, or list of Epochs\n        The epochs.\n    keep_sample_mean : bool (default True)\n        If False, the average response over epochs is computed for\n        each event type and subtracted during the covariance\n        computation. This is useful if the evoked response from a\n        previous stimulus extends into the baseline period of the next.\n        Note. This option is only implemented for method='empirical'.\n    tmin : float | None (default None)\n        Start time for baseline. If None start at first sample.\n    tmax : float | None (default None)\n        End time for baseline. If None end at last sample.\n    projs : list of Projection | None (default None)\n        List of projectors to use in covariance calculation, or None\n        to indicate that the projectors from the epochs should be\n        inherited. If None, then projectors from all epochs must match.\n    method : str | list | None (default 'empirical')\n        The method used for covariance estimation. If 'empirical' (default),\n        the sample covariance will be computed. A list can be passed to\n        perform estimates using multiple methods.\n        If 'auto' or a list of methods, the best estimator will be determined\n        based on log-likelihood and cross-validation on unseen data as\n        described in :footcite:`EngemannGramfort2015`. Valid methods are\n        'empirical', 'diagonal_fixed', 'shrunk', 'oas', 'ledoit_wolf',\n        'factor_analysis', 'shrinkage', and 'pca' (see Notes). If ``'auto'``,\n        it expands to::\n\n             ['shrunk', 'diagonal_fixed', 'empirical', 'factor_analysis']\n\n        ``'factor_analysis'`` is removed when ``rank`` is not 'full'.\n        The ``'auto'`` mode is not recommended if there are many\n        segments of data, since computation can take a long time.\n\n        .. versionadded:: 0.9.0\n    method_params : dict | None (default None)\n        Additional parameters to the estimation procedure. Only considered if\n        method is not None. Keys must correspond to the value(s) of ``method``.\n        If None (default), expands to the following (with the addition of\n        ``{'store_precision': False, 'assume_centered': True} for all methods\n        except ``'factor_analysis'`` and ``'pca'``)::\n\n            {'diagonal_fixed': {'grad': 0.1, 'mag': 0.1, 'eeg': 0.1, ...},\n             'shrinkage': {'shrinkage': 0.1},\n             'shrunk': {'shrinkage': np.logspace(-4, 0, 30)},\n             'pca': {'iter_n_components': None},\n             'factor_analysis': {'iter_n_components': None}}\n\n    cv : int | sklearn.model_selection object (default 3)\n        The cross validation method. Defaults to 3, which will\n        internally trigger by default :class:`sklearn.model_selection.KFold`\n        with 3 splits.\n    scalings : dict | None (default None)\n        Defaults to ``dict(mag=1e15, grad=1e13, eeg=1e6)``.\n        These defaults will scale data to roughly the same order of\n        magnitude.\n    %(n_jobs)s\n    return_estimators : bool (default False)\n        Whether to return all estimators or the best. Only considered if\n        method equals 'auto' or is a list of str. Defaults to False.\n    on_mismatch : str\n        What to do when the MEG<->Head transformations do not match between\n        epochs. If \"raise\" (default) an error is raised, if \"warn\" then a\n        warning is emitted, if \"ignore\" then nothing is printed. Having\n        mismatched transforms can in some cases lead to unexpected or\n        unstable results in covariance calculation, e.g. when data\n        have been processed with Maxwell filtering but not transformed\n        to the same head position.\n    %(rank_none)s\n\n        .. versionadded:: 0.17\n\n        .. versionadded:: 0.18\n           Support for 'info' mode.\n    %(verbose)s\n\n    Returns\n    -------\n    cov : instance of Covariance | list\n        The computed covariance. If method equals ``'auto'`` or is a list of str\n        and ``return_estimators=True``, a list of covariance estimators is\n        returned (sorted by log-likelihood, from high to low, i.e. from best\n        to worst).\n\n    See Also\n    --------\n    compute_raw_covariance : Estimate noise covariance from raw data, such as\n        empty-room recordings.\n\n    Notes\n    -----\n    Baseline correction or sufficient high-passing should be used\n    when creating the :class:`Epochs` to ensure that the data are zero mean,\n    otherwise the computed covariance matrix will be inaccurate.\n\n    Valid ``method`` strings are:\n\n    * ``'empirical'``\n        The empirical or sample covariance (default)\n    * ``'diagonal_fixed'``\n        A diagonal regularization based on channel types as in\n        :func:`mne.cov.regularize`.\n    * ``'shrinkage'``\n        Fixed shrinkage.\n\n      .. versionadded:: 0.16\n    * ``'ledoit_wolf'``\n        The Ledoit-Wolf estimator, which uses an\n        empirical formula for the optimal shrinkage value :footcite:`LedoitWolf2004`.\n    * ``'oas'``\n        The OAS estimator :footcite:`ChenEtAl2010`, which uses a different\n        empricial formula for the optimal shrinkage value.\n\n      .. versionadded:: 0.16\n    * ``'shrunk'``\n        Like 'ledoit_wolf', but with cross-validation for optimal alpha.\n    * ``'pca'``\n        Probabilistic PCA with low rank :footcite:`TippingBishop1999`.\n    * ``'factor_analysis'``\n        Factor analysis with low rank :footcite:`Barber2012`.\n\n    ``'ledoit_wolf'`` and ``'pca'`` are similar to ``'shrunk'`` and\n    ``'factor_analysis'``, respectively, except that they use\n    cross validation (which is useful when samples are correlated, which\n    is often the case for M/EEG data). The former two are not included in\n    the ``'auto'`` mode to avoid redundancy.\n\n    For multiple event types, it is also possible to create a\n    single :class:`Epochs` object with events obtained using\n    :func:`mne.merge_events`. However, the resulting covariance matrix\n    will only be correct if ``keep_sample_mean is True``.\n\n    The covariance can be unstable if the number of samples is small.\n    In that case it is common to regularize the covariance estimate.\n    The ``method`` parameter allows to regularize the covariance in an\n    automated way. It also allows to select between different alternative\n    estimation algorithms which themselves achieve regularization.\n    Details are described in :footcite:t:`EngemannGramfort2015`.\n\n    For more information on the advanced estimation methods, see\n    :ref:`the sklearn manual <sklearn:covariance>`.\n\n    References\n    ----------\n    .. footbibliography::\n    \"\"\"\n    # scale to natural unit for best stability with MEG/EEG\n    scalings = _check_scalings_user(scalings)\n    method, _method_params = _check_method_params(\n        method, method_params, keep_sample_mean, rank=rank\n    )\n    del method_params\n\n    # for multi condition support epochs is required to refer to a list of\n    # epochs objects\n\n    def _unpack_epochs(epochs):\n        if len(epochs.event_id) > 1:\n            epochs = [epochs[k] for k in epochs.event_id]\n        else:\n            epochs = [epochs]\n        return epochs\n\n    if not isinstance(epochs, list):\n        epochs = _unpack_epochs(epochs)\n    else:\n        epochs = sum([_unpack_epochs(epoch) for epoch in epochs], [])\n\n    # check for baseline correction\n    if any(\n        epochs_t.baseline is None\n        and epochs_t.info[\"highpass\"] < 0.5\n        and keep_sample_mean\n        for epochs_t in epochs\n    ):\n        warn(\"Epochs are not baseline corrected, covariance matrix may be inaccurate\")\n\n    orig = epochs[0].info[\"dev_head_t\"]\n    _check_on_missing(on_mismatch, \"on_mismatch\")\n    for ei, epoch in enumerate(epochs):\n        epoch.info._check_consistency()\n        if (orig is None) != (epoch.info[\"dev_head_t\"] is None) or (\n            orig is not None\n            and not np.allclose(orig[\"trans\"], epoch.info[\"dev_head_t\"][\"trans\"])\n        ):\n            msg = (\n                \"MEG<->Head transform mismatch between epochs[0]:\\n{}\\n\\n\"\n                \"and epochs[{}]:\\n{}\".format(orig, ei, epoch.info[\"dev_head_t\"])\n            )\n            _on_missing(on_mismatch, msg, \"on_mismatch\")\n\n    bads = epochs[0].info[\"bads\"]\n    if projs is None:\n        projs = epochs[0].info[\"projs\"]\n        # make sure Epochs are compatible\n        for epochs_t in epochs[1:]:\n            if epochs_t.proj != epochs[0].proj:\n                raise ValueError(\"Epochs must agree on the use of projections\")\n            for proj_a, proj_b in zip(epochs_t.info[\"projs\"], projs):\n                if not _proj_equal(proj_a, proj_b):\n                    raise ValueError(\"Epochs must have same projectors\")\n    projs = _check_projs(projs)\n    ch_names = epochs[0].ch_names\n\n    # make sure Epochs are compatible\n    for epochs_t in epochs[1:]:\n        if epochs_t.info[\"bads\"] != bads:\n            raise ValueError(\"Epochs must have same bad channels\")\n        if epochs_t.ch_names != ch_names:\n            raise ValueError(\"Epochs must have same channel names\")\n    picks_list = _picks_by_type(epochs[0].info)\n    picks_meeg = np.concatenate([b for _, b in picks_list])\n    picks_meeg = np.sort(picks_meeg)\n    ch_names = [epochs[0].ch_names[k] for k in picks_meeg]\n    info = epochs[0].info  # we will overwrite 'epochs'\n\n    if not keep_sample_mean:\n        # prepare mean covs\n        n_epoch_types = len(epochs)\n        data_mean = [0] * n_epoch_types\n        n_samples = np.zeros(n_epoch_types, dtype=np.int64)\n        n_epochs = np.zeros(n_epoch_types, dtype=np.int64)\n\n        for ii, epochs_t in enumerate(epochs):\n            tslice = _get_tslice(epochs_t, tmin, tmax)\n            for e in epochs_t:\n                e = e[picks_meeg, tslice]\n                if not keep_sample_mean:\n                    data_mean[ii] += e\n                n_samples[ii] += e.shape[1]\n                n_epochs[ii] += 1\n\n        n_samples_epoch = n_samples // n_epochs\n        norm_const = np.sum(n_samples_epoch * (n_epochs - 1))\n        data_mean = [\n            1.0 / n_epoch * np.dot(mean, mean.T)\n            for n_epoch, mean in zip(n_epochs, data_mean)\n        ]\n\n    info = pick_info(info, picks_meeg)\n    tslice = _get_tslice(epochs[0], tmin, tmax)\n    epochs = [ee.get_data(picks=picks_meeg)[..., tslice] for ee in epochs]\n    picks_meeg = np.arange(len(picks_meeg))\n    picks_list = _picks_by_type(info)\n\n    if len(epochs) > 1:\n        epochs = np.concatenate(epochs, 0)\n    else:\n        epochs = epochs[0]\n\n    epochs = np.hstack(epochs)\n    n_samples_tot = epochs.shape[-1]\n    _check_n_samples(n_samples_tot, len(picks_meeg))\n\n    epochs = epochs.T  # sklearn | C-order\n    cov_data = _compute_covariance_auto(\n        epochs,\n        method=method,\n        method_params=_method_params,\n        info=info,\n        cv=cv,\n        n_jobs=n_jobs,\n        stop_early=True,\n        picks_list=picks_list,\n        scalings=scalings,\n        rank=rank,\n    )\n\n    if keep_sample_mean is False:\n        cov = cov_data[\"empirical\"][\"data\"]\n        # undo scaling\n        cov *= n_samples_tot - 1\n        # ... apply pre-computed class-wise normalization\n        for mean_cov in data_mean:\n            cov -= mean_cov\n        cov /= norm_const\n\n    covs = list()\n    for this_method, data in cov_data.items():\n        cov = Covariance(\n            data.pop(\"data\"), ch_names, info[\"bads\"], projs, nfree=n_samples_tot - 1\n        )\n\n        # add extra info\n        cov.update(method=this_method, **data)\n        covs.append(cov)\n    logger.info(\"Number of samples used : %d\", n_samples_tot)\n    covs.sort(key=lambda c: c[\"loglik\"], reverse=True)\n\n    if len(covs) > 1:\n        msg = [\"log-likelihood on unseen data (descending order):\"]\n        for c in covs:\n            msg.append(f\"{c['method']}: {c['loglik']:0.3f}\")\n        logger.info(\"\\n   \".join(msg))\n        if return_estimators:\n            out = covs\n        else:\n            out = covs[0]\n            logger.info(\"selecting best estimator: {}\".format(out[\"method\"]))\n    else:\n        out = covs[0]\n    logger.info(\"[done]\")\n\n    return out", "metadata": {}}
{"_id": "mne_mne_cov.py_write_cov_code", "title": "write_cov", "text": "def write_cov(fname, cov, *, overwrite=False, verbose=None):\n    \"\"\"Write a noise covariance matrix.\n\n    Parameters\n    ----------\n    fname : path-like\n        The name of the file. It should end with ``-cov.fif`` or\n        ``-cov.fif.gz``.\n    cov : Covariance\n        The noise covariance matrix.\n    %(overwrite)s\n\n        .. versionadded:: 1.0\n    %(verbose)s\n\n    See Also\n    --------\n    read_cov\n    \"\"\"\n    cov.save(fname, overwrite=overwrite, verbose=verbose)", "metadata": {}}
{"_id": "mne_mne_cov.py_prepare_noise_cov_code", "title": "prepare_noise_cov", "text": "def prepare_noise_cov(\n    noise_cov,\n    info,\n    ch_names=None,\n    rank=None,\n    scalings=None,\n    on_rank_mismatch=\"ignore\",\n    verbose=None,\n):\n    \"\"\"Prepare noise covariance matrix.\n\n    Parameters\n    ----------\n    noise_cov : instance of Covariance\n        The noise covariance to process.\n    %(info_not_none)s (Used to get channel types and bad channels).\n    ch_names : list | None\n        The channel names to be considered. Can be None to use\n        ``info['ch_names']``.\n    %(rank_none)s\n\n        .. versionadded:: 0.18\n           Support for 'info' mode.\n    scalings : dict | None\n        Data will be rescaled before rank estimation to improve accuracy.\n        If dict, it will override the following dict (default if None)::\n\n            dict(mag=1e12, grad=1e11, eeg=1e5)\n    %(on_rank_mismatch)s\n    %(verbose)s\n\n    Returns\n    -------\n    cov : instance of Covariance\n        A copy of the covariance with the good channels subselected\n        and parameters updated.\n    \"\"\"\n    # reorder C and info to match ch_names order\n    noise_cov_idx = list()\n    missing = list()\n    ch_names = info[\"ch_names\"] if ch_names is None else ch_names\n    for c in ch_names:\n        # this could be try/except ValueError, but it is not the preferred way\n        if c in noise_cov.ch_names:\n            noise_cov_idx.append(noise_cov.ch_names.index(c))\n        else:\n            missing.append(c)\n    if len(missing):\n        raise RuntimeError(f\"Not all channels present in noise covariance:\\n{missing}\")\n    C = noise_cov._get_square()[np.ix_(noise_cov_idx, noise_cov_idx)]\n    info = pick_info(info, pick_channels(info[\"ch_names\"], ch_names, ordered=False))\n    projs = info[\"projs\"] + noise_cov[\"projs\"]\n    noise_cov = Covariance(\n        data=C,\n        names=ch_names,\n        bads=list(noise_cov[\"bads\"]),\n        projs=deepcopy(noise_cov[\"projs\"]),\n        nfree=noise_cov[\"nfree\"],\n        method=noise_cov.get(\"method\", None),\n        loglik=noise_cov.get(\"loglik\", None),\n    )\n\n    eig, eigvec, _ = _smart_eigh(\n        noise_cov,\n        info,\n        rank,\n        scalings,\n        projs,\n        ch_names,\n        on_rank_mismatch=on_rank_mismatch,\n    )\n    noise_cov.update(eig=eig, eigvec=eigvec)\n    return noise_cov", "metadata": {}}
{"_id": "mne_mne_cov.py_regularize_code", "title": "regularize", "text": "def regularize(\n    cov,\n    info,\n    mag=0.1,\n    grad=0.1,\n    eeg=0.1,\n    exclude=\"bads\",\n    proj=True,\n    seeg=0.1,\n    ecog=0.1,\n    hbo=0.1,\n    hbr=0.1,\n    fnirs_cw_amplitude=0.1,\n    fnirs_fd_ac_amplitude=0.1,\n    fnirs_fd_phase=0.1,\n    fnirs_od=0.1,\n    csd=0.1,\n    dbs=0.1,\n    rank=None,\n    scalings=None,\n    verbose=None,\n):\n    \"\"\"Regularize noise covariance matrix.\n\n    This method works by adding a constant to the diagonal for each\n    channel type separately. Special care is taken to keep the\n    rank of the data constant.\n\n    .. note:: This function is kept for reasons of backward-compatibility.\n              Please consider explicitly using the ``method`` parameter in\n              :func:`mne.compute_covariance` to directly combine estimation\n              with regularization in a data-driven fashion. See the\n              :ref:`FAQ <faq_how_should_i_regularize>` for more information.\n\n    Parameters\n    ----------\n    cov : Covariance\n        The noise covariance matrix.\n    %(info_not_none)s (Used to get channel types and bad channels).\n    mag : float (default 0.1)\n        Regularization factor for MEG magnetometers.\n    grad : float (default 0.1)\n        Regularization factor for MEG gradiometers. Must be the same as\n        ``mag`` if data have been processed with SSS.\n    eeg : float (default 0.1)\n        Regularization factor for EEG.\n    exclude : list | 'bads' (default 'bads')\n        List of channels to mark as bad. If 'bads', bads channels\n        are extracted from both info['bads'] and cov['bads'].\n    proj : bool (default True)\n        Apply projections to keep rank of data.\n    seeg : float (default 0.1)\n        Regularization factor for sEEG signals.\n    ecog : float (default 0.1)\n        Regularization factor for ECoG signals.\n    hbo : float (default 0.1)\n        Regularization factor for HBO signals.\n    hbr : float (default 0.1)\n        Regularization factor for HBR signals.\n    fnirs_cw_amplitude : float (default 0.1)\n        Regularization factor for fNIRS CW raw signals.\n    fnirs_fd_ac_amplitude : float (default 0.1)\n        Regularization factor for fNIRS FD AC raw signals.\n    fnirs_fd_phase : float (default 0.1)\n        Regularization factor for fNIRS raw phase signals.\n    fnirs_od : float (default 0.1)\n        Regularization factor for fNIRS optical density signals.\n    csd : float (default 0.1)\n        Regularization factor for EEG-CSD signals.\n    dbs : float (default 0.1)\n        Regularization factor for DBS signals.\n    %(rank_none)s\n\n        .. versionadded:: 0.17\n\n        .. versionadded:: 0.18\n           Support for 'info' mode.\n    scalings : dict | None\n        Data will be rescaled before rank estimation to improve accuracy.\n        See :func:`mne.compute_covariance`.\n\n        .. versionadded:: 0.17\n    %(verbose)s\n\n    Returns\n    -------\n    reg_cov : Covariance\n        The regularized covariance matrix.\n\n    See Also\n    --------\n    mne.compute_covariance\n    \"\"\"  # noqa: E501\n    cov = cov.copy()\n    info._check_consistency()\n    scalings = _handle_default(\"scalings_cov_rank\", scalings)\n    regs = dict(\n        eeg=eeg,\n        seeg=seeg,\n        dbs=dbs,\n        ecog=ecog,\n        hbo=hbo,\n        hbr=hbr,\n        fnirs_cw_amplitude=fnirs_cw_amplitude,\n        fnirs_fd_ac_amplitude=fnirs_fd_ac_amplitude,\n        fnirs_fd_phase=fnirs_fd_phase,\n        fnirs_od=fnirs_od,\n        csd=csd,\n    )\n\n    if exclude is None:\n        raise ValueError('exclude must be a list of strings or \"bads\"')\n\n    if exclude == \"bads\":\n        exclude = info[\"bads\"] + cov[\"bads\"]\n\n    picks_dict = {ch_type: [] for ch_type in _DATA_CH_TYPES_SPLIT}\n    meg_combined = \"auto\" if rank != \"full\" else False\n    picks_dict.update(\n        dict(\n            _picks_by_type(\n                info, meg_combined=meg_combined, exclude=exclude, ref_meg=False\n            )\n        )\n    )\n    if len(picks_dict.get(\"meg\", [])) > 0 and rank != \"full\":  # combined\n        if mag != grad:\n            raise ValueError(\n                \"On data where magnetometers and gradiometers are dependent (e.g., \"\n                f\"SSSed data), mag ({mag}) must equal grad ({grad})\"\n            )\n        logger.info(\"Regularizing MEG channels jointly\")\n        regs[\"meg\"] = mag\n    else:\n        regs.update(mag=mag, grad=grad)\n    if rank != \"full\":\n        rank = _compute_rank(cov, rank, scalings, info)\n\n    info_ch_names = info[\"ch_names\"]\n    ch_names_by_type = dict()\n    for ch_type, picks_type in picks_dict.items():\n        ch_names_by_type[ch_type] = [info_ch_names[i] for i in picks_type]\n\n    # This actually removes bad channels from the cov, which is not backward\n    # compatible, so let's leave all channels in\n    cov_good = pick_channels_cov(\n        cov, include=info_ch_names, exclude=exclude, ordered=False\n    )\n    ch_names = cov_good.ch_names\n\n    # Now get the indices for each channel type in the cov\n    idx_cov = {ch_type: [] for ch_type in ch_names_by_type}\n    for i, ch in enumerate(ch_names):\n        for ch_type in ch_names_by_type:\n            if ch in ch_names_by_type[ch_type]:\n                idx_cov[ch_type].append(i)\n                break\n        else:\n            raise Exception(f\"channel {ch} is unknown type\")\n\n    C = cov_good[\"data\"]\n\n    assert len(C) == sum(map(len, idx_cov.values()))\n\n    if proj:\n        projs = info[\"projs\"] + cov_good[\"projs\"]\n        projs = _activate_proj(projs)\n\n    for ch_type in idx_cov:\n        desc = ch_type.upper()\n        idx = idx_cov[ch_type]\n        if len(idx) == 0:\n            continue\n        reg = regs[ch_type]\n        if reg == 0.0:\n            logger.info(f\"    {desc} regularization : None\")\n            continue\n        logger.info(f\"    {desc} regularization : {reg}\")\n\n        this_C = C[np.ix_(idx, idx)]\n        U = np.eye(this_C.shape[0])\n        this_ch_names = [ch_names[k] for k in idx]\n        if rank == \"full\":\n            if proj:\n                P, ncomp, _ = _make_projector(projs, this_ch_names)\n                if ncomp > 0:\n                    # This adjustment ends up being redundant if rank is None:\n                    U = _safe_svd(P)[0][:, :-ncomp]\n                    logger.info(\n                        f\"    Created an SSP operator for {desc} (dimension = {ncomp})\"\n                    )\n        else:\n            this_picks = pick_channels(info[\"ch_names\"], this_ch_names)\n            this_info = pick_info(info, this_picks)\n            # Here we could use proj_subspace=True, but this should not matter\n            # since this is already in a loop over channel types\n            _, eigvec, mask = _smart_eigh(this_C, this_info, rank)\n            U = eigvec[mask].T\n        this_C = np.dot(U.T, np.dot(this_C, U))\n\n        sigma = np.mean(np.diag(this_C))\n        this_C.flat[:: len(this_C) + 1] += reg * sigma  # modify diag inplace\n        this_C = np.dot(U, np.dot(this_C, U.T))\n        C[np.ix_(idx, idx)] = this_C\n\n    # Put data back in correct locations\n    idx = pick_channels(cov.ch_names, info_ch_names, exclude=exclude, ordered=False)\n    cov[\"data\"][np.ix_(idx, idx)] = C\n\n    return cov", "metadata": {}}
{"_id": "mne_mne_cov.py_compute_whitener_code", "title": "compute_whitener", "text": "def compute_whitener(\n    noise_cov,\n    info=None,\n    picks=None,\n    rank=None,\n    scalings=None,\n    return_rank=False,\n    pca=False,\n    return_colorer=False,\n    on_rank_mismatch=\"warn\",\n    verbose=None,\n):\n    \"\"\"Compute whitening matrix.\n\n    Parameters\n    ----------\n    noise_cov : Covariance\n        The noise covariance.\n    %(info)s Can be None if ``noise_cov`` has already been\n        prepared with :func:`prepare_noise_cov`.\n    %(picks_good_data_noref)s\n    %(rank_none)s\n\n        .. versionadded:: 0.18\n           Support for 'info' mode.\n    scalings : dict | None\n        The rescaling method to be applied. See documentation of\n        ``prepare_noise_cov`` for details.\n    return_rank : bool\n        If True, return the rank used to compute the whitener.\n\n        .. versionadded:: 0.15\n    pca : bool | str\n        Space to project the data into. Options:\n\n        :data:`python:True`\n            Whitener will be shape (n_nonzero, n_channels).\n        ``'white'``\n            Whitener will be shape (n_channels, n_channels), potentially rank\n            deficient, and have the first ``n_channels - n_nonzero`` rows and\n            columns set to zero.\n        :data:`python:False` (default)\n            Whitener will be shape (n_channels, n_channels), potentially rank\n            deficient, and rotated back to the space of the original data.\n\n        .. versionadded:: 0.18\n    return_colorer : bool\n        If True, return the colorer as well.\n    %(on_rank_mismatch)s\n    %(verbose)s\n\n    Returns\n    -------\n    W : ndarray, shape (n_channels, n_channels) or (n_nonzero, n_channels)\n        The whitening matrix.\n    ch_names : list\n        The channel names.\n    rank : int\n        Rank reduction of the whitener. Returned only if return_rank is True.\n    colorer : ndarray, shape (n_channels, n_channels) or (n_channels, n_nonzero)\n        The coloring matrix.\n    \"\"\"  # noqa: E501\n    _validate_type(pca, (str, bool), \"space\")\n    _valid_pcas = (True, \"white\", False)\n    if pca not in _valid_pcas:\n        raise ValueError(f\"space must be one of {_valid_pcas}, got {pca}\")\n    if info is None:\n        if \"eig\" not in noise_cov:\n            raise ValueError(\n                \"info can only be None if the noise cov has already been prepared with \"\n                \"prepare_noise_cov\"\n            )\n        ch_names = deepcopy(noise_cov[\"names\"])\n    else:\n        picks = _picks_to_idx(info, picks, with_ref_meg=False)\n        ch_names = [info[\"ch_names\"][k] for k in picks]\n        del picks\n        noise_cov = prepare_noise_cov(\n            noise_cov, info, ch_names, rank, scalings, on_rank_mismatch=on_rank_mismatch\n        )\n\n    n_chan = len(ch_names)\n    assert n_chan == len(noise_cov[\"eig\"])\n\n    #   Omit the zeroes due to projection\n    eig = noise_cov[\"eig\"].copy()\n    nzero = eig > 0\n    eig[~nzero] = 0.0  # get rid of numerical noise (negative) ones\n\n    if noise_cov[\"eigvec\"].dtype.kind == \"c\":\n        dtype = np.complex128\n    else:\n        dtype = np.float64\n    W = np.zeros((n_chan, 1), dtype)\n    W[nzero, 0] = 1.0 / np.sqrt(eig[nzero])\n    #   Rows of eigvec are the eigenvectors\n    W = W * noise_cov[\"eigvec\"]  # C ** -0.5\n    C = np.sqrt(eig) * noise_cov[\"eigvec\"].conj().T  # C ** 0.5\n    n_nzero = nzero.sum()\n    logger.info(\n        \"    Created the whitener using a noise covariance matrix \"\n        \"with rank %d (%d small eigenvalues omitted)\",\n        n_nzero,\n        noise_cov[\"dim\"] - n_nzero,\n    )\n\n    # Do the requested projection\n    if pca is True:\n        W = W[nzero]\n        C = C[:, nzero]\n    elif pca is False:\n        W = np.dot(noise_cov[\"eigvec\"].conj().T, W)\n        C = np.dot(C, noise_cov[\"eigvec\"])\n\n    # Triage return\n    out = W, ch_names\n    if return_rank:\n        out += (n_nzero,)\n    if return_colorer:\n        out += (C,)\n    return out", "metadata": {}}
{"_id": "mne_mne_cov.py_whiten_evoked_code", "title": "whiten_evoked", "text": "def whiten_evoked(\n    evoked, noise_cov, picks=None, diag=None, rank=None, scalings=None, verbose=None\n):\n    \"\"\"Whiten evoked data using given noise covariance.\n\n    Parameters\n    ----------\n    evoked : instance of Evoked\n        The evoked data.\n    noise_cov : instance of Covariance\n        The noise covariance.\n    %(picks_good_data)s\n    diag : bool (default False)\n        If True, whiten using only the diagonal of the covariance.\n    %(rank_none)s\n\n        .. versionadded:: 0.18\n           Support for 'info' mode.\n    scalings : dict | None (default None)\n        To achieve reliable rank estimation on multiple sensors,\n        sensors have to be rescaled. This parameter controls the\n        rescaling. If dict, it will override the\n        following default dict (default if None):\n\n            dict(mag=1e12, grad=1e11, eeg=1e5)\n    %(verbose)s\n\n    Returns\n    -------\n    evoked_white : instance of Evoked\n        The whitened evoked data.\n    \"\"\"\n    evoked = evoked.copy()\n    picks = _picks_to_idx(evoked.info, picks)\n\n    if diag:\n        noise_cov = noise_cov.as_diag()\n\n    W, _ = compute_whitener(\n        noise_cov, evoked.info, picks=picks, rank=rank, scalings=scalings\n    )\n\n    evoked.data[picks] = np.sqrt(evoked.nave) * np.dot(W, evoked.data[picks])\n    return evoked", "metadata": {}}
{"_id": "mne_mne_cov.py_data_code", "title": "data", "text": "def data(self):\n        \"\"\"Numpy array of Noise covariance matrix.\"\"\"\n        return self[\"data\"]", "metadata": {}}
{"_id": "mne_mne_cov.py_ch_names_code", "title": "ch_names", "text": "def ch_names(self):\n        \"\"\"Channel names.\"\"\"\n        return self[\"names\"]", "metadata": {}}
{"_id": "mne_mne_cov.py_nfree_code", "title": "nfree", "text": "def nfree(self):\n        \"\"\"Number of degrees of freedom.\"\"\"\n        return self[\"nfree\"]", "metadata": {}}
{"_id": "mne_mne_cov.py_save_code", "title": "save", "text": "def save(self, fname, *, overwrite=False, verbose=None):\n        \"\"\"Save covariance matrix in a FIF file.\n\n        Parameters\n        ----------\n        fname : path-like\n            Output filename.\n        %(overwrite)s\n\n            .. versionadded:: 1.0\n        %(verbose)s\n        \"\"\"\n        from ._fiff.write import start_and_end_file\n\n        check_fname(\n            fname, \"covariance\", (\"-cov.fif\", \"-cov.fif.gz\", \"_cov.fif\", \"_cov.fif.gz\")\n        )\n        fname = _check_fname(fname=fname, overwrite=overwrite)\n        with start_and_end_file(fname) as fid:\n            _write_cov(fid, self)", "metadata": {}}
{"_id": "mne_mne_cov.py_copy_code", "title": "copy", "text": "def copy(self):\n        \"\"\"Copy the Covariance object.\n\n        Returns\n        -------\n        cov : instance of Covariance\n            The copied object.\n        \"\"\"\n        return deepcopy(self)", "metadata": {}}
{"_id": "mne_mne_cov.py_as_diag_code", "title": "as_diag", "text": "def as_diag(self):\n        \"\"\"Set covariance to be processed as being diagonal.\n\n        Returns\n        -------\n        cov : dict\n            The covariance.\n\n        Notes\n        -----\n        This function allows creation of inverse operators\n        equivalent to using the old \"--diagnoise\" mne option.\n\n        This function operates in place.\n        \"\"\"\n        if self[\"diag\"]:\n            return self\n        self[\"diag\"] = True\n        self[\"data\"] = np.diag(self[\"data\"])\n        self[\"eig\"] = None\n        self[\"eigvec\"] = None\n        return self", "metadata": {}}
{"_id": "mne_mne_cov.py_plot_topomap_code", "title": "plot_topomap", "text": "def plot_topomap(\n        self,\n        info,\n        ch_type=None,\n        *,\n        scalings=None,\n        proj=False,\n        noise_cov=None,\n        sensors=True,\n        show_names=False,\n        mask=None,\n        mask_params=None,\n        contours=6,\n        outlines=\"head\",\n        sphere=None,\n        image_interp=_INTERPOLATION_DEFAULT,\n        extrapolate=_EXTRAPOLATE_DEFAULT,\n        border=_BORDER_DEFAULT,\n        res=64,\n        size=1,\n        cmap=None,\n        vlim=(None, None),\n        cnorm=None,\n        colorbar=True,\n        cbar_fmt=\"%3.1f\",\n        units=None,\n        axes=None,\n        show=True,\n        verbose=None,\n    ):\n        \"\"\"Plot a topomap of the covariance diagonal.\n\n        Parameters\n        ----------\n        %(info_not_none)s\n        %(ch_type_topomap)s\n\n            .. versionadded:: 0.21\n        %(scalings_topomap)s\n        %(proj_plot)s\n        noise_cov : instance of Covariance | None\n            If not None, whiten the instance with ``noise_cov`` before\n            plotting.\n        %(sensors_topomap)s\n        %(show_names_topomap)s\n        %(mask_topomap)s\n        %(mask_params_topomap)s\n        %(contours_topomap)s\n        %(outlines_topomap)s\n        %(sphere_topomap_auto)s\n        %(image_interp_topomap)s\n        %(extrapolate_topomap)s\n\n            .. versionchanged:: 0.21\n\n               - The default was changed to ``'local'`` for MEG sensors.\n               - ``'local'`` was changed to use a convex hull mask\n               - ``'head'`` was changed to extrapolate out to the clipping circle.\n        %(border_topomap)s\n\n            .. versionadded:: 0.20\n        %(res_topomap)s\n        %(size_topomap)s\n        %(cmap_topomap)s\n        %(vlim_plot_topomap)s\n\n            .. versionadded:: 1.2\n        %(cnorm)s\n\n            .. versionadded:: 1.2\n        %(colorbar_topomap)s\n        %(cbar_fmt_topomap)s\n        %(units_topomap_evoked)s\n        %(axes_cov_plot_topomap)s\n        %(show)s\n        %(verbose)s\n\n        Returns\n        -------\n        fig : instance of Figure\n            The matplotlib figure.\n\n        Notes\n        -----\n        .. versionadded:: 0.21\n        \"\"\"\n        from .viz.misc import _index_info_cov\n\n        info, C, _, _ = _index_info_cov(info, self, exclude=())\n        evoked = EvokedArray(np.diag(C)[:, np.newaxis], info)\n        if noise_cov is not None:\n            # need to left and right multiply whitener, which for the diagonal\n            # entries is the same as multiplying twice\n            evoked = whiten_evoked(whiten_evoked(evoked, noise_cov), noise_cov)\n            if units is None:\n                units = \"AU\"\n            if scalings is None:\n                scalings = 1.0\n        if units is None:\n            units = {k: f\"({v})\u00b2\" for k, v in DEFAULTS[\"units\"].items()}\n        if scalings is None:\n            scalings = {k: v * v for k, v in DEFAULTS[\"scalings\"].items()}\n        return evoked.plot_topomap(\n            times=[0],\n            ch_type=ch_type,\n            vlim=vlim,\n            cmap=cmap,\n            sensors=sensors,\n            cnorm=cnorm,\n            colorbar=colorbar,\n            scalings=scalings,\n            units=units,\n            res=res,\n            size=size,\n            cbar_fmt=cbar_fmt,\n            proj=proj,\n            show=show,\n            show_names=show_names,\n            mask=mask,\n            mask_params=mask_params,\n            outlines=outlines,\n            contours=contours,\n            image_interp=image_interp,\n            axes=axes,\n            extrapolate=extrapolate,\n            sphere=sphere,\n            border=border,\n            time_format=\"\",\n        )", "metadata": {}}
{"_id": "mne_mne_cov.py_pick_channels_code", "title": "pick_channels", "text": "def pick_channels(self, ch_names, ordered=True, *, verbose=None):\n        \"\"\"Pick channels from this covariance matrix.\n\n        Parameters\n        ----------\n        ch_names : list of str\n            List of channels to keep. All other channels are dropped.\n        %(ordered)s\n        %(verbose)s\n\n        Returns\n        -------\n        cov : instance of Covariance.\n            The modified covariance matrix.\n\n        Notes\n        -----\n        Operates in-place.\n\n        .. versionadded:: 0.20.0\n        \"\"\"\n        return pick_channels_cov(\n            self, ch_names, exclude=[], ordered=ordered, copy=False\n        )", "metadata": {}}
{"_id": "mne_mne_cov.py_fit_code", "title": "fit", "text": "def fit(self, X):\n        \"\"\"Fit covariance model with classical diagonal regularization.\"\"\"\n        self.estimator_ = EmpiricalCovariance(\n            store_precision=self.store_precision, assume_centered=self.assume_centered\n        )\n\n        self.covariance_ = self.estimator_.fit(X).covariance_\n        self.covariance_ = 0.5 * (self.covariance_ + self.covariance_.T)\n        cov_ = Covariance(\n            data=self.covariance_,\n            names=self.info[\"ch_names\"],\n            bads=self.info[\"bads\"],\n            projs=self.info[\"projs\"],\n            nfree=len(self.covariance_),\n        )\n        cov_ = regularize(\n            cov_,\n            self.info,\n            proj=False,\n            exclude=\"bads\",\n            grad=self.grad,\n            mag=self.mag,\n            eeg=self.eeg,\n            ecog=self.ecog,\n            seeg=self.seeg,\n            dbs=self.dbs,\n            hbo=self.hbo,\n            hbr=self.hbr,\n            rank=\"full\",\n        )\n        self.estimator_.covariance_ = self.covariance_ = cov_.data\n        return self", "metadata": {}}
{"_id": "mne_mne_cov.py_score_code", "title": "score", "text": "def score(self, X_test, y=None):\n        \"\"\"Delegate call to modified EmpiricalCovariance instance.\"\"\"\n        return self.estimator_.score(X_test, y=y)", "metadata": {}}
{"_id": "mne_mne_cov.py_get_precision_code", "title": "get_precision", "text": "def get_precision(self):\n        \"\"\"Delegate call to modified EmpiricalCovariance instance.\"\"\"\n        return self.estimator_.get_precision()", "metadata": {}}
{"_id": "mne_mne_cov.py_fit_code", "title": "fit", "text": "def fit(self, X):\n        \"\"\"Fit covariance model with oracle shrinkage regularization.\"\"\"\n        from sklearn.covariance import shrunk_covariance\n\n        self.estimator_ = EmpiricalCovariance(\n            store_precision=self.store_precision, assume_centered=self.assume_centered\n        )\n\n        cov = self.estimator_.fit(X).covariance_\n\n        if not isinstance(self.shrinkage, list | tuple):\n            shrinkage = [(\"all\", self.shrinkage, np.arange(len(cov)))]\n        else:\n            shrinkage = self.shrinkage\n\n        zero_cross_cov = np.zeros_like(cov, dtype=bool)\n        for a, b in itt.combinations(shrinkage, 2):\n            picks_i, picks_j = a[2], b[2]\n            ch_ = a[0], b[0]\n            if \"eeg\" in ch_:\n                zero_cross_cov[np.ix_(picks_i, picks_j)] = True\n                zero_cross_cov[np.ix_(picks_j, picks_i)] = True\n\n        self.zero_cross_cov_ = zero_cross_cov\n\n        # Apply shrinkage to blocks\n        for ch_type, c, picks in shrinkage:\n            sub_cov = cov[np.ix_(picks, picks)]\n            cov[np.ix_(picks, picks)] = shrunk_covariance(sub_cov, shrinkage=c)\n\n        # Apply shrinkage to cross-cov\n        for a, b in itt.combinations(shrinkage, 2):\n            shrinkage_i, shrinkage_j = a[1], b[1]\n            picks_i, picks_j = a[2], b[2]\n            c_ij = np.sqrt((1.0 - shrinkage_i) * (1.0 - shrinkage_j))\n            cov[np.ix_(picks_i, picks_j)] *= c_ij\n            cov[np.ix_(picks_j, picks_i)] *= c_ij\n\n        # Set to zero the necessary cross-cov\n        if np.any(zero_cross_cov):\n            cov[zero_cross_cov] = 0.0\n\n        self.estimator_.covariance_ = self.covariance_ = cov\n        return self", "metadata": {}}
{"_id": "mne_mne_cov.py_score_code", "title": "score", "text": "def score(self, X_test, y=None):\n        \"\"\"Delegate to modified EmpiricalCovariance instance.\"\"\"\n        # compute empirical covariance of the test set\n        test_cov = empirical_covariance(\n            X_test - self.estimator_.location_, assume_centered=True\n        )\n        if np.any(self.zero_cross_cov_):\n            test_cov[self.zero_cross_cov_] = 0.0\n        res = log_likelihood(test_cov, self.estimator_.get_precision())\n        return res", "metadata": {}}
{"_id": "mne_mne_cov.py_get_precision_code", "title": "get_precision", "text": "def get_precision(self):\n        \"\"\"Delegate to modified EmpiricalCovariance instance.\"\"\"\n        return self.estimator_.get_precision()", "metadata": {}}
{"_id": "mne_mne_label.py_read_label_code", "title": "read_label", "text": "def read_label(filename, subject=None, color=None, *, verbose=None):\n    \"\"\"Read FreeSurfer Label file.\n\n    Parameters\n    ----------\n    filename : str\n        Path to label file.\n    %(subject_label)s\n        It is good practice to set this attribute to avoid combining\n        incompatible labels and SourceEstimates (e.g., ones from other\n        subjects). Note that due to file specification limitations, the\n        subject name isn't saved to or loaded from files written to disk.\n    color : None | matplotlib color\n        Default label color and alpha (e.g., ``(1., 0., 0., 1.)`` for red).\n        Note that due to file specification limitations, the color isn't saved\n        to or loaded from files written to disk.\n    %(verbose)s\n\n    Returns\n    -------\n    label : Label\n        Instance of Label object with attributes:\n\n            - ``comment``: comment from the first line of the label file\n            - ``vertices``: vertex indices (0 based, column 1)\n            - ``pos``: locations in meters (columns 2 - 4 divided by 1000)\n            - ``values``: values at the vertices (column 5)\n\n    See Also\n    --------\n    read_labels_from_annot\n    write_labels_to_annot\n    \"\"\"\n    if subject is not None and not isinstance(subject, str):\n        raise TypeError(\"subject must be a string\")\n\n    # find hemi\n    basename = op.basename(filename)\n    if basename.endswith(\"lh.label\") or basename.startswith(\"lh.\"):\n        hemi = \"lh\"\n    elif basename.endswith(\"rh.label\") or basename.startswith(\"rh.\"):\n        hemi = \"rh\"\n    else:\n        raise ValueError(\n            \"Cannot find which hemisphere it is. File should end with lh.label or \"\n            f\"rh.label: {basename}\"\n        )\n\n    # find name\n    if basename.startswith((\"lh.\", \"rh.\")):\n        basename_ = basename[3:]\n        if basename.endswith(\".label\"):\n            basename_ = basename[:-6]\n    else:\n        basename_ = basename[:-9]\n    name = f\"{basename_}-{hemi}\"\n\n    # read the file\n    with open(filename) as fid:\n        comment = fid.readline().replace(\"\\n\", \"\")[1:]\n        nv = int(fid.readline())\n        data = np.empty((5, nv))\n        for i, line in enumerate(fid):\n            data[:, i] = line.split()\n\n    # let's make sure everything is ordered correctly\n    vertices = np.array(data[0], dtype=np.int32)\n    pos = 1e-3 * data[1:4].T\n    values = data[4]\n    order = np.argsort(vertices)\n    vertices = vertices[order]\n    pos = pos[order]\n    values = values[order]\n\n    label = Label(\n        vertices,\n        pos,\n        values,\n        hemi,\n        comment,\n        name,\n        filename,\n        subject,\n        color,\n        verbose=verbose,\n    )\n\n    return label", "metadata": {}}
{"_id": "mne_mne_label.py_write_label_code", "title": "write_label", "text": "def write_label(filename, label, verbose=None):\n    \"\"\"Write a FreeSurfer label.\n\n    Parameters\n    ----------\n    filename : str\n        Path to label file to produce.\n    label : Label\n        The label object to save.\n    %(verbose)s\n\n    See Also\n    --------\n    write_labels_to_annot\n\n    Notes\n    -----\n    Note that due to file specification limitations, the Label's subject and\n    color attributes are not saved to disk.\n    \"\"\"\n    hemi = label.hemi\n    path_head, name = op.split(filename)\n    if name.endswith(\".label\"):\n        name = name[:-6]\n    if not (name.startswith(hemi) or name.endswith(hemi)):\n        name += \"-\" + hemi\n    filename = op.join(path_head, name) + \".label\"\n\n    logger.info(f\"Saving label to : {filename}\")\n\n    with open(filename, \"w\", encoding=\"utf-8\") as fid:\n        n_vertices = len(label.vertices)\n        data = np.zeros((n_vertices, 5), dtype=np.float64)\n        data[:, 0] = label.vertices\n        data[:, 1:4] = 1e3 * label.pos\n        data[:, 4] = label.values\n        fid.write(f\"#{label.comment}\\n\")\n        fid.write(f\"{n_vertices}\\n\")\n        for vert, pos, val in zip(label.vertices, 1e3 * label.pos, label.values):\n            fid.write(f\"{vert} {pos[0]:f} {pos[1]:f} {pos[2]:f} {val:f}\\n\")", "metadata": {}}
{"_id": "mne_mne_label.py_split_label_code", "title": "split_label", "text": "def split_label(label, parts=2, subject=None, subjects_dir=None, freesurfer=False):\n    \"\"\"Split a Label into two or more parts.\n\n    Parameters\n    ----------\n    label : Label | str\n        Label which is to be split (Label object or path to a label file).\n    parts : int >= 2 | tuple of str\n        A sequence of strings specifying label names for the new labels (from\n        posterior to anterior), or the number of new labels to create (default\n        is 2). If a number is specified, names of the new labels will be the\n        input label's name with div1, div2 etc. appended.\n    %(subject_label)s\n    %(subjects_dir)s\n    freesurfer : bool\n        By default (``False``) ``split_label`` uses an algorithm that is\n        slightly optimized for performance and numerical precision. Set\n        ``freesurfer`` to ``True`` in order to replicate label splits from\n        FreeSurfer's ``mris_divide_parcellation``.\n\n    Returns\n    -------\n    labels : list of Label, shape (n_parts,)\n        The labels, starting from the lowest to the highest end of the\n        projection axis.\n\n    Notes\n    -----\n    Works by finding the label's principal eigen-axis on the spherical surface,\n    projecting all label vertex coordinates onto this axis and dividing them at\n    regular spatial intervals.\n    \"\"\"\n    label, subject, subjects_dir = _prep_label_split(label, subject, subjects_dir)\n\n    # find the parts\n    if np.isscalar(parts):\n        n_parts = int(parts)\n        if label.name.endswith((\"lh\", \"rh\")):\n            basename = label.name[:-3]\n            name_ext = label.name[-3:]\n        else:\n            basename = label.name\n            name_ext = \"\"\n        name_pattern = f\"{basename}_div%i{name_ext}\"\n        names = tuple(name_pattern % i for i in range(1, n_parts + 1))\n    else:\n        names = parts\n        n_parts = len(names)\n\n    if n_parts < 2:\n        raise ValueError(f\"Can't split label into {n_parts} parts.\")\n\n    # find the spherical surface\n    surf_fname = \".\".join((label.hemi, \"sphere\"))\n    surf_path = op.join(subjects_dir, subject, \"surf\", surf_fname)\n    surface_points, surface_tris = read_surface(surf_path)\n    # find the label coordinates on the surface\n    points = surface_points[label.vertices]\n    center = np.mean(points, axis=0)\n    centered_points = points - center\n\n    # find the label's normal\n    if freesurfer:\n        # find the Freesurfer vertex closest to the center\n        distance = np.sqrt(np.sum(centered_points**2, axis=1))\n        i_closest = np.argmin(distance)\n        closest_vertex = label.vertices[i_closest]\n        # find the normal according to freesurfer convention\n        idx = np.any(surface_tris == closest_vertex, axis=1)\n        tris_for_normal = surface_tris[idx]\n        r1 = surface_points[tris_for_normal[:, 0], :]\n        r2 = surface_points[tris_for_normal[:, 1], :]\n        r3 = surface_points[tris_for_normal[:, 2], :]\n        tri_normals = fast_cross_3d((r2 - r1), (r3 - r1))\n        normal = np.mean(tri_normals, axis=0)\n        normal /= linalg.norm(normal)\n    else:\n        # Normal of the center\n        normal = center / linalg.norm(center)\n\n    # project all vertex coordinates on the tangential plane for this point\n    q, _ = linalg.qr(normal[:, np.newaxis])\n    tangent_u = q[:, 1:]\n    m_obs = np.dot(centered_points, tangent_u)\n    # find principal eigendirection\n    m_cov = np.dot(m_obs.T, m_obs)\n    w, vr = linalg.eig(m_cov)\n    i = np.argmax(w)\n    eigendir = vr[:, i]\n    # project back into 3d space\n    axis = np.dot(tangent_u, eigendir)\n    # orient them from posterior to anterior\n    if axis[1] < 0:\n        axis *= -1\n\n    # project the label on the axis\n    proj = np.dot(points, axis)\n\n    # assign mark (new label index)\n    proj -= proj.min()\n    proj /= proj.max() / n_parts\n    mark = proj // 1\n    mark[mark == n_parts] = n_parts - 1\n\n    # colors\n    if label.color is None:\n        colors = (None,) * n_parts\n    else:\n        colors = _split_colors(label.color, n_parts)\n\n    # construct new labels\n    labels = []\n    for i, name, color in zip(range(n_parts), names, colors):\n        idx = mark == i\n        vert = label.vertices[idx]\n        pos = label.pos[idx]\n        values = label.values[idx]\n        hemi = label.hemi\n        comment = label.comment\n        lbl = Label(vert, pos, values, hemi, comment, name, None, subject, color)\n        labels.append(lbl)\n\n    return labels", "metadata": {}}
{"_id": "mne_mne_label.py_label_sign_flip_code", "title": "label_sign_flip", "text": "def label_sign_flip(label, src):\n    \"\"\"Compute sign for label averaging.\n\n    Parameters\n    ----------\n    label : Label | BiHemiLabel\n        A label.\n    src : SourceSpaces\n        The source space over which the label is defined.\n\n    Returns\n    -------\n    flip : array\n        Sign flip vector (contains 1 or -1).\n    \"\"\"\n    if len(src) != 2:\n        raise ValueError(\"Only source spaces with 2 hemisphers are accepted\")\n\n    lh_vertno = src[0][\"vertno\"]\n    rh_vertno = src[1][\"vertno\"]\n\n    # get source orientations\n    ori = list()\n    if label.hemi in (\"lh\", \"both\"):\n        vertices = label.vertices if label.hemi == \"lh\" else label.lh.vertices\n        vertno_sel = np.intersect1d(lh_vertno, vertices)\n        ori.append(src[0][\"nn\"][vertno_sel])\n    if label.hemi in (\"rh\", \"both\"):\n        vertices = label.vertices if label.hemi == \"rh\" else label.rh.vertices\n        vertno_sel = np.intersect1d(rh_vertno, vertices)\n        ori.append(src[1][\"nn\"][vertno_sel])\n    if len(ori) == 0:\n        raise Exception(f'Unknown hemisphere type \"{label.hemi}\"')\n    ori = np.concatenate(ori, axis=0)\n    if len(ori) == 0:\n        return np.array([], int)\n\n    _, _, Vh = _safe_svd(ori, full_matrices=False)\n\n    # The sign of Vh is ambiguous, so we should align to the max-positive\n    # (outward) direction\n    dots = np.dot(ori, Vh[0])\n    if np.mean(dots) < 0:\n        dots *= -1\n\n    # Comparing to the direction of the first right singular vector\n    flip = np.sign(dots)\n    return flip", "metadata": {}}
{"_id": "mne_mne_label.py_stc_to_label_code", "title": "stc_to_label", "text": "def stc_to_label(\n    stc, src=None, smooth=True, connected=False, subjects_dir=None, verbose=None\n):\n    \"\"\"Compute a label from the non-zero sources in an stc object.\n\n    Parameters\n    ----------\n    stc : SourceEstimate\n        The source estimates.\n    src : SourceSpaces | str | None\n        The source space over which the source estimates are defined.\n        If it's a string it should the subject name (e.g. fsaverage).\n        Can be None if stc.subject is not None.\n    smooth : bool\n        Fill in vertices on the cortical surface that are not in the source\n        space based on the closest source space vertex (requires\n        src to be a SourceSpace).\n    connected : bool\n        If True a list of connected labels will be returned in each\n        hemisphere. The labels are ordered in decreasing order depending\n        of the maximum value in the stc.\n    %(subjects_dir)s\n    %(verbose)s\n\n    Returns\n    -------\n    labels : list of Label | list of list of Label\n        The generated labels. If connected is False, it returns\n        a list of Labels (one per hemisphere). If no Label is available\n        in a hemisphere, None is returned. If connected is True,\n        it returns for each hemisphere a list of connected labels\n        ordered in decreasing order depending of the maximum value in the stc.\n        If no Label is available in an hemisphere, an empty list is returned.\n    \"\"\"\n    if not isinstance(smooth, bool):\n        raise ValueError(f\"smooth should be True or False. Got {smooth}.\")\n\n    src = stc.subject if src is None else src\n    if src is None:\n        raise ValueError(\"src cannot be None if stc.subject is None\")\n    if isinstance(src, str):\n        subject = src\n    else:\n        subject = stc.subject\n\n    if not isinstance(stc, SourceEstimate):\n        raise ValueError(\"SourceEstimate should be surface source estimates\")\n\n    if isinstance(src, str):\n        if connected:\n            raise ValueError(\n                \"The option to return only connected labels is \"\n                \"only available if source spaces are provided.\"\n            )\n        if smooth:\n            msg = (\n                \"stc_to_label with smooth=True requires src to be an \"\n                \"instance of SourceSpace\"\n            )\n            raise ValueError(msg)\n        subjects_dir = get_subjects_dir(subjects_dir, raise_error=True)\n        surf_path_from = subjects_dir / src / \"surf\"\n        rr_lh, tris_lh = read_surface(surf_path_from / \"lh.white\")\n        rr_rh, tris_rh = read_surface(surf_path_from / \"rh.white\")\n        rr = [rr_lh, rr_rh]\n        tris = [tris_lh, tris_rh]\n    else:\n        if not isinstance(src, SourceSpaces):\n            raise TypeError(\"src must be a string or a set of source spaces\")\n        if len(src) != 2:\n            raise ValueError(\"source space should contain the 2 hemispheres\")\n        rr = [1e3 * src[0][\"rr\"], 1e3 * src[1][\"rr\"]]\n        tris = [src[0][\"tris\"], src[1][\"tris\"]]\n        src_conn = spatial_src_adjacency(src).tocsr()\n\n    labels = []\n    cnt = 0\n    cnt_full = 0\n    for hemi_idx, (hemi, this_vertno, this_tris, this_rr) in enumerate(\n        zip([\"lh\", \"rh\"], stc.vertices, tris, rr)\n    ):\n        this_data = stc.data[cnt : cnt + len(this_vertno)]\n\n        if connected:  # we know src *must* be a SourceSpaces now\n            vertno = np.where(src[hemi_idx][\"inuse\"])[0]\n            if not len(np.setdiff1d(this_vertno, vertno)) == 0:\n                raise RuntimeError(\n                    \"stc contains vertices not present in source space, did you morph?\"\n                )\n            tmp = np.zeros((len(vertno), this_data.shape[1]))\n            this_vertno_idx = np.searchsorted(vertno, this_vertno)\n            tmp[this_vertno_idx] = this_data\n            this_data = tmp\n            offset = cnt_full + len(this_data)\n            this_src_adj = src_conn[cnt_full:offset, cnt_full:offset].tocoo()\n            this_data_abs_max = np.abs(this_data).max(axis=1)\n            clusters, _ = _find_clusters(this_data_abs_max, 0.0, adjacency=this_src_adj)\n            cnt_full += len(this_data)\n            # Then order clusters in descending order based on maximum value\n            clusters_max = np.argsort([np.max(this_data_abs_max[c]) for c in clusters])[\n                ::-1\n            ]\n            clusters = [clusters[k] for k in clusters_max]\n            clusters = [vertno[c] for c in clusters]\n        else:\n            clusters = [this_vertno[np.any(this_data, axis=1)]]\n\n        cnt += len(this_vertno)\n\n        clusters = [c for c in clusters if len(c) > 0]\n\n        if len(clusters) == 0:\n            if not connected:\n                this_labels = None\n            else:\n                this_labels = []\n        else:\n            this_labels = []\n            colors = _n_colors(len(clusters))\n            for c, color in zip(clusters, colors):\n                idx_use = c\n                label = Label(\n                    idx_use,\n                    this_rr[idx_use],\n                    None,\n                    hemi,\n                    \"Label from stc\",\n                    subject=subject,\n                    color=color,\n                )\n                if smooth:\n                    label = label.fill(src)\n\n                this_labels.append(label)\n\n            if not connected:\n                this_labels = this_labels[0]\n\n        labels.append(this_labels)\n\n    return labels", "metadata": {}}
{"_id": "mne_mne_label.py_grow_labels_code", "title": "grow_labels", "text": "def grow_labels(\n    subject,\n    seeds,\n    extents,\n    hemis,\n    subjects_dir=None,\n    n_jobs=None,\n    overlap=True,\n    names=None,\n    surface=\"white\",\n    colors=None,\n):\n    \"\"\"Generate circular labels in source space with region growing.\n\n    This function generates a number of labels in source space by growing\n    regions starting from the vertices defined in \"seeds\". For each seed, a\n    label is generated containing all vertices within a maximum geodesic\n    distance on the white matter surface from the seed.\n\n    Parameters\n    ----------\n    %(subject)s\n    seeds : int | list\n        Seed, or list of seeds. Each seed can be either a vertex number or\n        a list of vertex numbers.\n    extents : array | float\n        Extents (radius in mm) of the labels.\n    hemis : array | int\n        Hemispheres to use for the labels (0: left, 1: right).\n    %(subjects_dir)s\n    %(n_jobs)s\n        Likely only useful if tens or hundreds of labels are being expanded\n        simultaneously. Does not apply with ``overlap=False``.\n    overlap : bool\n        Produce overlapping labels. If True (default), the resulting labels\n        can be overlapping. If False, each label will be grown one step at a\n        time, and occupied territory will not be invaded.\n    names : None | list of str\n        Assign names to the new labels (list needs to have the same length as\n        seeds).\n    %(surface)s\n    colors : array, shape (n, 4) or (, 4) | None\n        How to assign colors to each label. If None then unique colors will be\n        chosen automatically (default), otherwise colors will be broadcast\n        from the array. The first three values will be interpreted as RGB\n        colors and the fourth column as the alpha value (commonly 1).\n\n    Returns\n    -------\n    labels : list of Label\n        The labels' ``comment`` attribute contains information on the seed\n        vertex and extent; the ``values``  attribute contains distance from the\n        seed in millimeters.\n\n    Notes\n    -----\n    \"extents\" and \"hemis\" can either be arrays with the same length as\n    seeds, which allows using a different extent and hemisphere for\n    label, or integers, in which case the same extent and hemisphere is\n    used for each label.\n    \"\"\"\n    subjects_dir = get_subjects_dir(subjects_dir, raise_error=True)\n\n    # make sure the inputs are arrays\n    if np.isscalar(seeds):\n        seeds = [seeds]\n    seeds = [np.atleast_1d(seed) for seed in seeds]\n    extents = np.atleast_1d(extents)\n    hemis = np.atleast_1d(hemis)\n    n_seeds = len(seeds)\n\n    if len(extents) != 1 and len(extents) != n_seeds:\n        raise ValueError(\"The extents parameter has to be of length 1 or len(seeds)\")\n\n    if len(hemis) != 1 and len(hemis) != n_seeds:\n        raise ValueError(\"The hemis parameter has to be of length 1 or len(seeds)\")\n\n    if colors is not None:\n        if len(colors.shape) == 1:  # if one color for all seeds\n            n_colors = 1\n            n = colors.shape[0]\n        else:\n            n_colors, n = colors.shape\n\n        if n_colors != n_seeds and n_colors != 1:\n            msg = (\n                f\"Number of colors ({n_colors}) and seeds ({n_seeds}) are not \"\n                \"compatible.\"\n            )\n            raise ValueError(msg)\n        if n != 4:\n            msg = f\"Colors must have 4 values (RGB and alpha), not {n}.\"\n            raise ValueError(msg)\n\n    # make the arrays the same length as seeds\n    if len(extents) == 1:\n        extents = np.tile(extents, n_seeds)\n\n    if len(hemis) == 1:\n        hemis = np.tile(hemis, n_seeds)\n\n    hemis = np.array([\"lh\" if h == 0 else \"rh\" for h in hemis])\n\n    # names\n    if names is None:\n        names = [f\"Label_{ii}-{h}\" for ii, h in enumerate(hemis)]\n    else:\n        if np.isscalar(names):\n            names = [names]\n        if len(names) != n_seeds:\n            raise ValueError(\n                \"The names parameter has to be None or have length len(seeds)\"\n            )\n        for i, hemi in enumerate(hemis):\n            if not names[i].endswith(hemi):\n                names[i] = \"-\".join((names[i], hemi))\n    names = np.array(names)\n\n    # load the surfaces and create the distance graphs\n    tris, vert, dist = {}, {}, {}\n    for hemi in set(hemis):\n        surf_fname = subjects_dir / subject / \"surf\" / f\"{hemi}.{surface}\"\n        vert[hemi], tris[hemi] = read_surface(surf_fname)\n        dist[hemi] = mesh_dist(tris[hemi], vert[hemi])\n\n    if overlap:\n        # create the patches\n        parallel, my_grow_labels, n_jobs = parallel_func(_grow_labels, n_jobs)\n        seeds = np.array_split(np.array(seeds, dtype=\"O\"), n_jobs)\n        extents = np.array_split(extents, n_jobs)\n        hemis = np.array_split(hemis, n_jobs)\n        names = np.array_split(names, n_jobs)\n        labels = sum(\n            parallel(\n                my_grow_labels(s, e, h, n, dist, vert, subject)\n                for s, e, h, n in zip(seeds, extents, hemis, names)\n            ),\n            [],\n        )\n    else:\n        # special procedure for non-overlapping labels\n        labels = _grow_nonoverlapping_labels(\n            subject, seeds, extents, hemis, vert, dist, names\n        )\n\n    if colors is None:\n        # add a unique color to each label\n        label_colors = _n_colors(len(labels))\n    else:\n        # use specified colors\n        label_colors = np.empty((len(labels), 4))\n        label_colors[:] = colors\n\n    for label, color in zip(labels, label_colors):\n        label.color = color\n\n    return labels", "metadata": {}}
{"_id": "mne_mne_label.py_random_parcellation_code", "title": "random_parcellation", "text": "def random_parcellation(\n    subject, n_parcel, hemi, subjects_dir=None, surface=\"white\", random_state=None\n):\n    \"\"\"Generate random cortex parcellation by growing labels.\n\n    This function generates a number of labels which don't intersect and\n    cover the whole surface. Regions are growing around randomly chosen\n    seeds.\n\n    Parameters\n    ----------\n    %(subject)s\n    n_parcel : int\n        Total number of cortical parcels.\n    hemi : str\n        Hemisphere id (ie ``'lh'``, ``'rh'``, ``'both'``). In the case\n        of ``'both'``, both hemispheres are processed with ``(n_parcel // 2)``\n        parcels per hemisphere.\n    %(subjects_dir)s\n    %(surface)s\n    %(random_state)s\n\n    Returns\n    -------\n    labels : list of Label\n        Random cortex parcellation.\n    \"\"\"\n    subjects_dir = get_subjects_dir(subjects_dir, raise_error=True)\n    if hemi == \"both\":\n        hemi = [\"lh\", \"rh\"]\n    hemis = np.atleast_1d(hemi)\n\n    # load the surfaces and create the distance graphs\n    tris, vert, dist = {}, {}, {}\n    for hemi in set(hemis):\n        surf_fname = subjects_dir / subject / \"surf\" / f\"{hemi}.{surface}\"\n        vert[hemi], tris[hemi] = read_surface(surf_fname)\n        dist[hemi] = mesh_dist(tris[hemi], vert[hemi])\n\n    # create the patches\n    labels = _cortex_parcellation(subject, n_parcel, hemis, vert, dist, random_state)\n\n    # add a unique color to each label\n    colors = _n_colors(len(labels))\n    for label, color in zip(labels, colors):\n        label.color = color\n\n    return labels", "metadata": {}}
{"_id": "mne_mne_label.py_read_labels_from_annot_code", "title": "read_labels_from_annot", "text": "def read_labels_from_annot(\n    subject,\n    parc=\"aparc\",\n    hemi=\"both\",\n    surf_name=\"white\",\n    annot_fname=None,\n    regexp=None,\n    subjects_dir=None,\n    sort=True,\n    verbose=None,\n):\n    \"\"\"Read labels from a FreeSurfer annotation file.\n\n    Note: Only cortical labels will be returned.\n\n    Parameters\n    ----------\n    %(subject)s\n    parc : str\n        The parcellation to use, e.g., ``'aparc'`` or ``'aparc.a2009s'``.\n    hemi : str\n        The hemisphere from which to read the parcellation, can be ``'lh'``,\n        ``'rh'``, or ``'both'``.\n    surf_name : str\n        Surface used to obtain vertex locations, e.g., ``'white'``, ``'pial'``.\n    annot_fname : path-like | None\n        Filename of the ``.annot`` file. If not None, only this file is read\n        and the arguments ``parc`` and ``hemi`` are ignored.\n    regexp : str\n        Regular expression or substring to select particular labels from the\n        parcellation. E.g. ``'superior'`` will return all labels in which this\n        substring is contained.\n    %(subjects_dir)s\n    sort : bool\n        If true, labels will be sorted by name before being returned.\n\n        .. versionadded:: 0.21.0\n    %(verbose)s\n\n    Returns\n    -------\n    labels : list of Label\n        The labels, sorted by label name (ascending).\n\n    See Also\n    --------\n    write_labels_to_annot\n    morph_labels\n    \"\"\"\n    logger.info(\"Reading labels from parcellation...\")\n\n    subjects_dir = get_subjects_dir(subjects_dir)\n    if subjects_dir is not None:\n        subjects_dir = str(subjects_dir)\n\n    # get the .annot filenames and hemispheres\n    annot_fname, hemis = _get_annot_fname(\n        annot_fname, subject, hemi, parc, subjects_dir\n    )\n\n    if regexp is not None:\n        # allow for convenient substring match\n        r_ = re.compile(\n            f\".*{regexp}.*\" if regexp.replace(\"_\", \"\").isalnum() else regexp\n        )\n\n    # now we are ready to create the labels\n    n_read = 0\n    labels = list()\n    orig_names = set()\n    for fname, hemi in zip(annot_fname, hemis):\n        # read annotation\n        annot, ctab, label_names = _read_annot(fname)\n        label_rgbas = ctab[:, :4] / 255.0\n        label_ids = ctab[:, -1]\n\n        # load the vertex positions from surface\n        vert_pos = _load_vert_pos(\n            subject,\n            subjects_dir,\n            surf_name,\n            hemi,\n            len(annot),\n            extra=f\"for annotation file {fname}\",\n        )\n        for label_id, label_name, label_rgba in zip(\n            label_ids, label_names, label_rgbas\n        ):\n            vertices = np.where(annot == label_id)[0]\n            if len(vertices) == 0:\n                # label is not part of cortical surface\n                continue\n            label_name = label_name.decode(\"utf-8\")\n            orig_names.add(label_name)\n            name = f\"{label_name}-{hemi}\"\n            if (regexp is not None) and not r_.match(name):\n                continue\n            pos = vert_pos[vertices, :]\n            label = Label(\n                vertices,\n                pos,\n                hemi=hemi,\n                name=name,\n                subject=subject,\n                color=tuple(label_rgba),\n            )\n            labels.append(label)\n\n        n_read = len(labels) - n_read\n        logger.info(\"   read %d labels from %s\", n_read, fname)\n\n    # sort the labels by label name\n    if sort:\n        labels = sorted(labels, key=lambda label: label.name)\n\n    if len(labels) == 0:\n        msg = \"No labels found.\"\n        if regexp is not None:\n            orig_names = \"\\n\".join(sorted(orig_names))\n            msg += (\n                f\" Maybe the regular expression {repr(regexp)} did not \"\n                f\"match any of:\\n{orig_names}\"\n            )\n        raise RuntimeError(msg)\n\n    return labels", "metadata": {}}
{"_id": "mne_mne_label.py_morph_labels_code", "title": "morph_labels", "text": "def morph_labels(\n    labels,\n    subject_to,\n    subject_from=None,\n    subjects_dir=None,\n    surf_name=\"white\",\n    verbose=None,\n):\n    \"\"\"Morph a set of labels.\n\n    This is useful when morphing a set of non-overlapping labels (such as those\n    obtained with :func:`read_labels_from_annot`) from one subject to\n    another.\n\n    Parameters\n    ----------\n    labels : list\n        The labels to morph.\n    subject_to : str\n        The subject to morph labels to.\n    subject_from : str | None\n        The subject to morph labels from. Can be None if the labels\n        have the ``.subject`` property defined.\n    %(subjects_dir)s\n    surf_name : str\n        Surface used to obtain vertex locations, e.g., ``'white'``, ``'pial'``.\n    %(verbose)s\n\n    Returns\n    -------\n    labels : list\n        The morphed labels.\n\n    See Also\n    --------\n    read_labels_from_annot\n    mne.Label.morph\n\n    Notes\n    -----\n    This does not use the same algorithm as Freesurfer, so the results\n    morphing (e.g., from ``'fsaverage'`` to your subject) might not match\n    what Freesurfer produces during ``recon-all``.\n\n    .. versionadded:: 0.18\n    \"\"\"\n    subjects_dir = str(get_subjects_dir(subjects_dir, raise_error=True))\n    subject_from = _check_labels_subject(labels, subject_from, \"subject_from\")\n    mmaps = read_morph_map(subject_from, subject_to, subjects_dir)\n    vert_poss = [\n        _load_vert_pos(subject_to, subjects_dir, surf_name, hemi, mmap.shape[0])\n        for hemi, mmap in zip((\"lh\", \"rh\"), mmaps)\n    ]\n    idxs = [mmap.argmax(axis=1) for mmap in mmaps]\n    out_labels = list()\n    values = filename = None\n    for label in labels:\n        li = dict(lh=0, rh=1)[label.hemi]\n        vertices = np.where(np.isin(idxs[li], label.vertices))[0]\n        pos = vert_poss[li][vertices]\n        out_labels.append(\n            Label(\n                vertices,\n                pos,\n                values,\n                label.hemi,\n                label.comment,\n                label.name,\n                filename,\n                subject_to,\n                label.color,\n            )\n        )\n    return out_labels", "metadata": {}}
{"_id": "mne_mne_label.py_labels_to_stc_code", "title": "labels_to_stc", "text": "def labels_to_stc(\n    labels, values, tmin=0, tstep=1, subject=None, src=None, verbose=None\n):\n    \"\"\"Convert a set of labels and values to a STC.\n\n    This function is meant to work like the opposite of\n    `extract_label_time_course`.\n\n    Parameters\n    ----------\n    %(labels_eltc)s\n    values : ndarray, shape (n_labels, ...)\n        The values in each label. Can be 1D or 2D.\n    tmin : float\n        The tmin to use for the STC.\n    tstep : float\n        The tstep to use for the STC.\n    %(subject)s\n    %(src_eltc)s\n        Can be omitted if using a surface source space, in which case\n        the label vertices will determine the output STC vertices.\n        Required if using a volumetric source space.\n\n        .. versionadded:: 0.22\n    %(verbose)s\n\n    Returns\n    -------\n    stc : instance of SourceEstimate | instance of VolSourceEstimate\n        The values-in-labels converted to a STC.\n\n    See Also\n    --------\n    extract_label_time_course\n\n    Notes\n    -----\n    Vertices that appear in more than one label will be averaged.\n\n    .. versionadded:: 0.18\n    \"\"\"\n    values = np.array(values, float)\n    if values.ndim == 1:\n        values = values[:, np.newaxis]\n    if values.ndim != 2:\n        raise ValueError(f\"values must have 1 or 2 dimensions, got {values.ndim}\")\n    _validate_type(src, (SourceSpaces, None))\n    if src is None:\n        data, vertices, subject = _labels_to_stc_surf(\n            labels, values, tmin, tstep, subject\n        )\n        klass = SourceEstimate\n    else:\n        kind = src.kind\n        subject = _check_subject(\n            src._subject, subject, first_kind=\"source space subject\", raise_error=False\n        )\n        _check_option(\"source space kind\", kind, (\"surface\", \"volume\"))\n        if kind == \"volume\":\n            klass = VolSourceEstimate\n        else:\n            klass = SourceEstimate\n        # Easiest way is to get a dot-able operator and use it\n        vertices = [s[\"vertno\"].copy() for s in src]\n        stc = klass(np.eye(sum(len(v) for v in vertices)), vertices, 0, 1, subject)\n        label_op = extract_label_time_course(\n            stc, labels, src=src, mode=\"mean\", allow_empty=True\n        )\n        _check_values_labels(values, label_op.shape[0])\n        rev_op = np.zeros(label_op.shape[::-1])\n        rev_op[np.arange(label_op.shape[1]), np.argmax(label_op, axis=0)] = 1.0\n        data = rev_op @ values\n    return klass(data, vertices, tmin, tstep, subject, verbose=verbose)", "metadata": {}}
{"_id": "mne_mne_label.py_write_labels_to_annot_code", "title": "write_labels_to_annot", "text": "def write_labels_to_annot(\n    labels,\n    subject=None,\n    parc=None,\n    overwrite=False,\n    subjects_dir=None,\n    annot_fname=None,\n    colormap=\"hsv\",\n    hemi=\"both\",\n    sort=True,\n    table_name=_DEFAULT_TABLE_NAME,\n    verbose=None,\n):\n    r\"\"\"Create a FreeSurfer annotation from a list of labels.\n\n    Parameters\n    ----------\n    labels : list with instances of mne.Label\n        The labels to create a parcellation from.\n    %(subject)s\n    parc : str | None\n        The parcellation name to use.\n    overwrite : bool\n        Overwrite files if they already exist.\n    %(subjects_dir)s\n    annot_fname : str | None\n        Filename of the ``.annot file``. If not None, only this file is written\n        and the arguments ``parc`` and ``subject`` are ignored.\n    colormap : str\n        Colormap to use to generate label colors for labels that do not\n        have a color specified.\n    hemi : ``'both'`` | ``'lh'`` | ``'rh'``\n        The hemisphere(s) for which to write \\*.annot files (only applies if\n        annot_fname is not specified; default is 'both').\n    sort : bool\n        If True (default), labels will be sorted by name before writing.\n\n        .. versionadded:: 0.21.0\n    table_name : str\n        The table name to use for the colortable.\n\n        .. versionadded:: 0.21.0\n    %(verbose)s\n\n    See Also\n    --------\n    read_labels_from_annot\n\n    Notes\n    -----\n    Vertices that are not covered by any of the labels are assigned to a label\n    named ``\"unknown\"``.\n    \"\"\"\n    logger.info(\"Writing labels to parcellation...\")\n\n    subjects_dir = get_subjects_dir(subjects_dir)\n    if subjects_dir is not None:\n        subjects_dir = str(subjects_dir)\n\n    # get the .annot filenames and hemispheres\n    annot_fname, hemis = _get_annot_fname(\n        annot_fname, subject, hemi, parc, subjects_dir\n    )\n\n    if not overwrite:\n        for fname in annot_fname:\n            if op.exists(fname):\n                raise ValueError(\n                    f'File {fname} exists. Use \"overwrite=True\" to overwrite it'\n                )\n\n    # prepare container for data to save:\n    to_save = []\n    # keep track of issues found in the labels\n    duplicate_colors = []\n    invalid_colors = []\n    overlap = []\n    no_color = (-1, -1, -1, -1)\n    no_color_rgb = (-1, -1, -1)\n    for hemi, fname in zip(hemis, annot_fname):\n        hemi_labels = [label for label in labels if label.hemi == hemi]\n        n_hemi_labels = len(hemi_labels)\n\n        if n_hemi_labels == 0:\n            ctab = np.empty((0, 4), dtype=np.int32)\n            ctab_rgb = ctab[:, :3]\n        else:\n            if sort:\n                hemi_labels.sort(key=lambda label: label.name)\n\n            # convert colors to 0-255 RGBA tuples\n            hemi_colors = [\n                no_color\n                if label.color is None\n                else tuple(int(round(255 * i)) for i in label.color)\n                for label in hemi_labels\n            ]\n            ctab = np.array(hemi_colors, dtype=np.int32)\n            ctab_rgb = ctab[:, :3]\n\n            # make color dict (for annot ID, only R, G and B count)\n            labels_by_color = defaultdict(list)\n            for label, color in zip(hemi_labels, ctab_rgb):\n                labels_by_color[tuple(color)].append(label.name)\n\n            # check label colors\n            for color, names in labels_by_color.items():\n                if color == no_color_rgb:\n                    continue\n\n                if color == (0, 0, 0):\n                    # we cannot have an all-zero color, otherw. e.g. tksurfer\n                    # refuses to read the parcellation\n                    warn(\n                        'At least one label contains a color with, \"r=0, '\n                        'g=0, b=0\" value. Some FreeSurfer tools may fail '\n                        \"to read the parcellation\"\n                    )\n\n                if any(i > 255 for i in color):\n                    msg = f\"{color}: {', '.join(names)} ({hemi})\"\n                    invalid_colors.append(msg)\n\n                if len(names) > 1:\n                    msg = f\"{color}: {', '.join(names)} ({hemi})\"\n                    duplicate_colors.append(msg)\n\n            # replace None values (labels with unspecified color)\n            if labels_by_color[no_color_rgb]:\n                default_colors = _n_colors(n_hemi_labels, bytes_=True, cmap=colormap)\n                # keep track of colors known to be in hemi_colors :\n                safe_color_i = 0\n                for i in range(n_hemi_labels):\n                    if ctab[i, 0] == -1:\n                        color = default_colors[i]\n                        # make sure to add no duplicate color\n                        while np.any(np.all(color[:3] == ctab_rgb, 1)):\n                            color = default_colors[safe_color_i]\n                            safe_color_i += 1\n                        # assign the color\n                        ctab[i] = color\n\n        # find number of vertices in surface\n        if subject is not None and subjects_dir is not None:\n            fpath = op.join(subjects_dir, subject, \"surf\", f\"{hemi}.white\")\n            points, _ = read_surface(fpath)\n            n_vertices = len(points)\n        else:\n            if len(hemi_labels) > 0:\n                max_vert = max(np.max(label.vertices) for label in hemi_labels)\n                n_vertices = max_vert + 1\n            else:\n                n_vertices = 1\n            warn(\n                \"Number of vertices in the surface could not be \"\n                \"verified because the surface file could not be found; \"\n                \"specify subject and subjects_dir parameters.\"\n            )\n\n        # Create annot and color table array to write\n        annot = np.empty(n_vertices, dtype=np.int64)\n        annot[:] = -1\n        # create the annotation ids from the colors\n        annot_id_coding = np.array((1, 2**8, 2**16))\n        annot_ids = list(np.sum(ctab_rgb * annot_id_coding, axis=1))\n        for label, annot_id in zip(hemi_labels, annot_ids):\n            # make sure the label is not overwriting another label\n            if np.any(annot[label.vertices] != -1):\n                other_ids = set(annot[label.vertices])\n                other_ids.discard(-1)\n                other_indices = (annot_ids.index(i) for i in other_ids)\n                other_names = (hemi_labels[i].name for i in other_indices)\n                other_repr = \", \".join(other_names)\n                msg = f\"{hemi}: {label.name} overlaps {other_repr}\"\n                overlap.append(msg)\n\n            annot[label.vertices] = annot_id\n\n        hemi_names = [label.name for label in hemi_labels]\n\n        if None in hemi_names:\n            msg = (\n                f\"Found {hemi_names.count(None)} labels with no name. Writing \"\n                \"annotation file requires all labels named.\"\n            )\n            # raise the error immediately rather than crash with an\n            # uninformative error later (e.g. cannot join NoneType)\n            raise ValueError(msg)\n\n        # Assign unlabeled vertices to an \"unknown\" label\n        unlabeled = annot == -1\n        if np.any(unlabeled):\n            msg = f\"Assigning {unlabeled.sum()} unlabeled vertices to 'unknown-{hemi}'.\"\n            logger.info(msg)\n\n            # find an unused color (try shades of gray first)\n            for i in range(1, 257):\n                if not np.any(np.all((i, i, i) == ctab_rgb, 1)):\n                    break\n            if i < 256:\n                color = (i, i, i, 0)\n            else:\n                err = (\n                    \"Need one free shade of gray for 'unknown' label. \"\n                    \"Please modify your label colors, or assign the \"\n                    \"unlabeled vertices to another label.\"\n                )\n                raise ValueError(err)\n\n            # find the id\n            annot_id = np.sum(annot_id_coding * color[:3])\n\n            # update data to write\n            annot[unlabeled] = annot_id\n            ctab = np.vstack((ctab, color))\n            hemi_names.append(\"unknown\")\n\n        # convert to FreeSurfer alpha values\n        ctab[:, 3] = 255 - ctab[:, 3]\n\n        # remove hemi ending in names\n        hemi_names = [name[:-3] if name.endswith(hemi) else name for name in hemi_names]\n\n        to_save.append((fname, annot, ctab, hemi_names))\n\n    issues = []\n    if duplicate_colors:\n        msg = (\n            \"Some labels have the same color values (all labels in one \"\n            \"hemisphere must have a unique color):\"\n        )\n        duplicate_colors.insert(0, msg)\n        issues.append(\"\\n\".join(duplicate_colors))\n    if invalid_colors:\n        msg = (\n            \"Some labels have invalid color values (all colors should be \"\n            \"RGBA tuples with values between 0 and 1)\"\n        )\n        invalid_colors.insert(0, msg)\n        issues.append(\"\\n\".join(invalid_colors))\n    if overlap:\n        msg = (\n            \"Some labels occupy vertices that are also occupied by one or \"\n            \"more other labels. Each vertex can only be occupied by a \"\n            \"single label in *.annot files.\"\n        )\n        overlap.insert(0, msg)\n        issues.append(\"\\n\".join(overlap))\n\n    if issues:\n        raise ValueError(\"\\n\\n\".join(issues))\n\n    # write it\n    for fname, annot, ctab, hemi_names in to_save:\n        logger.info(\"   writing %d labels to %s\", len(hemi_names), fname)\n        _write_annot(fname, annot, ctab, hemi_names, table_name)", "metadata": {}}
{"_id": "mne_mne_label.py_select_sources_code", "title": "select_sources", "text": "def select_sources(\n    subject,\n    label,\n    location=\"center\",\n    extent=0.0,\n    grow_outside=True,\n    subjects_dir=None,\n    name=None,\n    random_state=None,\n    surf=\"white\",\n):\n    \"\"\"Select sources from a label.\n\n    Parameters\n    ----------\n    %(subject)s\n    label : instance of Label | str\n        Define where the seed will be chosen. If str, can be 'lh' or 'rh',\n        which correspond to left or right hemisphere, respectively.\n    location : 'random' | 'center' | int\n        Location to grow label from. If the location is an int, it represents\n        the vertex number in the corresponding label. If it is a str, it can be\n        either 'random' or 'center'.\n    extent : float\n        Extents (radius in mm) of the labels, i.e. maximum geodesic distance\n        on the white matter surface from the seed. If 0, the resulting label\n        will contain only one vertex.\n    grow_outside : bool\n        Let the region grow outside the original label where location was\n        defined.\n    %(subjects_dir)s\n    name : None | str\n        Assign name to the new label.\n    %(random_state)s\n    surf : str\n        The surface used to simulated the label, defaults to the white surface.\n\n    Returns\n    -------\n    label : instance of Label\n        The label that contains the selected sources.\n\n    Notes\n    -----\n    This function selects a region of interest on the cortical surface based\n    on a label (or a hemisphere). The sources are selected by growing a region\n    around a seed which is selected randomly, is the center of the label, or\n    is a specific vertex. The selected vertices can extend beyond the initial\n    provided label. This can be prevented by setting grow_outside to False.\n\n    The selected sources are returned in the form of a new Label object. The\n    values of the label contain the distance from the seed in millimeters.\n\n    .. versionadded:: 0.18\n    \"\"\"\n    # If label is a string, convert it to a label that contains the whole\n    # hemisphere.\n    if isinstance(label, str):\n        _check_option(\"label\", label, [\"lh\", \"rh\"])\n        surf_filename = op.join(subjects_dir, subject, \"surf\", label + \".white\")\n        vertices, _ = read_surface(surf_filename)\n        indices = np.arange(len(vertices), dtype=int)\n        label = Label(indices, vertices, hemi=label)\n\n    # Choose the seed according to the selected strategy.\n    if isinstance(location, str):\n        _check_option(\"location\", location, [\"center\", \"random\"])\n\n        if location == \"center\":\n            seed = label.center_of_mass(\n                subject, restrict_vertices=True, subjects_dir=subjects_dir, surf=surf\n            )\n        else:\n            rng = check_random_state(random_state)\n            seed = rng.choice(label.vertices)\n    else:\n        seed = label.vertices[location]\n\n    hemi = 0 if label.hemi == \"lh\" else 1\n    new_label = grow_labels(subject, seed, extent, hemi, subjects_dir)[0]\n\n    # We override the name because grow_label automatically adds a -rh or -lh\n    # to the given parameter.\n    new_label.name = name\n\n    # Restrict the new label to the vertices of the input label if needed.\n    if not grow_outside:\n        to_keep = np.array([v in label.vertices for v in new_label.vertices])\n        new_label = Label(\n            new_label.vertices[to_keep],\n            new_label.pos[to_keep],\n            hemi=new_label.hemi,\n            name=name,\n            subject=subject,\n        )\n\n    return new_label", "metadata": {}}
{"_id": "mne_mne_label.py_save_code", "title": "save", "text": "def save(self, filename):\n        r\"\"\"Write to disk as FreeSurfer \\*.label file.\n\n        Parameters\n        ----------\n        filename : path-like\n            Path to label file to produce.\n\n        Notes\n        -----\n        Note that due to file specification limitations, the Label's subject\n        and color attributes are not saved to disk.\n        \"\"\"\n        write_label(filename, self)", "metadata": {}}
{"_id": "mne_mne_label.py_copy_code", "title": "copy", "text": "def copy(self):\n        \"\"\"Copy the label instance.\n\n        Returns\n        -------\n        label : instance of Label\n            The copied label.\n        \"\"\"\n        return cp.deepcopy(self)", "metadata": {}}
{"_id": "mne_mne_label.py_fill_code", "title": "fill", "text": "def fill(self, src, name=None):\n        \"\"\"Fill the surface between sources for a source space label.\n\n        Parameters\n        ----------\n        src : SourceSpaces\n            Source space in which the label was defined. If a source space is\n            provided, the label is expanded to fill in surface vertices that\n            lie between the vertices included in the source space. For the\n            added vertices, ``pos`` is filled in with positions from the\n            source space, and ``values`` is filled in from the closest source\n            space vertex.\n        name : None | str\n            Name for the new Label (default is self.name).\n\n        Returns\n        -------\n        label : Label\n            The label covering the same vertices in source space but also\n            including intermediate surface vertices.\n\n        See Also\n        --------\n        Label.restrict\n        Label.smooth\n        \"\"\"\n        # find source space patch info\n        if len(self.vertices) == 0:\n            return self.copy()\n        hemi_src = _get_label_src(self, src)\n\n        if not np.all(np.isin(self.vertices, hemi_src[\"vertno\"])):\n            msg = \"Source space does not contain all of the label's vertices\"\n            raise ValueError(msg)\n\n        if hemi_src[\"nearest\"] is None:\n            warn(\n                \"Source space is being modified in place because patch \"\n                \"information is needed. To avoid this in the future, run \"\n                \"mne.add_source_space_distances() on the source space \"\n                \"and save it to disk.\"\n            )\n            dist_limit = 0\n            add_source_space_distances(src, dist_limit=dist_limit)\n        nearest = hemi_src[\"nearest\"]\n\n        # find new vertices\n        include = np.isin(nearest, self.vertices, False)\n        vertices = np.nonzero(include)[0]\n\n        # values\n        nearest_in_label = np.digitize(nearest[vertices], self.vertices, True)\n        values = self.values[nearest_in_label]\n        # pos\n        pos = hemi_src[\"rr\"][vertices]\n\n        name = self.name if name is None else name\n        label = Label(\n            vertices,\n            pos,\n            values,\n            self.hemi,\n            self.comment,\n            name,\n            None,\n            self.subject,\n            self.color,\n        )\n        return label", "metadata": {}}
{"_id": "mne_mne_label.py_restrict_code", "title": "restrict", "text": "def restrict(self, src, name=None):\n        \"\"\"Restrict a label to a source space.\n\n        Parameters\n        ----------\n        src : instance of SourceSpaces\n            The source spaces to use to restrict the label.\n        name : None | str\n            Name for the new Label (default is self.name).\n\n        Returns\n        -------\n        label : instance of Label\n            The Label restricted to the set of source space vertices.\n\n        See Also\n        --------\n        Label.fill\n\n        Notes\n        -----\n        .. versionadded:: 0.20\n        \"\"\"\n        if len(self.vertices) == 0:\n            return self.copy()\n        hemi_src = _get_label_src(self, src)\n        mask = np.isin(self.vertices, hemi_src[\"vertno\"])\n        name = self.name if name is None else name\n        label = Label(\n            self.vertices[mask],\n            self.pos[mask],\n            self.values[mask],\n            self.hemi,\n            self.comment,\n            name,\n            None,\n            self.subject,\n            self.color,\n        )\n        return label", "metadata": {}}
{"_id": "mne_mne_label.py_smooth_code", "title": "smooth", "text": "def smooth(\n        self,\n        subject=None,\n        smooth=2,\n        grade=None,\n        subjects_dir=None,\n        n_jobs=None,\n        verbose=None,\n    ):\n        \"\"\"Smooth the label.\n\n        Useful for filling in labels made in a\n        decimated source space for display.\n\n        Parameters\n        ----------\n        %(subject_label)s\n        smooth : int\n            Number of iterations for the smoothing of the surface data.\n            Cannot be None here since not all vertices are used. For a\n            grade of 5 (e.g., fsaverage), a smoothing of 2 will fill a\n            label.\n        grade : int, list of shape (2,), array, or None\n            Resolution of the icosahedral mesh (typically 5). If None, all\n            vertices will be used (potentially filling the surface). If a list,\n            values will be morphed to the set of vertices specified in grade[0]\n            and grade[1], assuming that these are vertices for the left and\n            right hemispheres. Note that specifying the vertices (e.g.,\n            grade=[np.arange(10242), np.arange(10242)] for fsaverage on a\n            standard grade 5 source space) can be substantially faster than\n            computing vertex locations. If one array is used, it is assumed\n            that all vertices belong to the hemisphere of the label. To create\n            a label filling the surface, use None.\n        %(subjects_dir)s\n        %(n_jobs)s\n        %(verbose)s\n\n        Returns\n        -------\n        label : instance of Label\n            The smoothed label.\n\n        Notes\n        -----\n        This function will set label.pos to be all zeros. If the positions\n        on the new surface are required, consider using mne.read_surface\n        with ``label.vertices``.\n        \"\"\"\n        subject = _check_subject(self.subject, subject)\n        return self.morph(\n            subject, subject, smooth, grade, subjects_dir, n_jobs, verbose=verbose\n        )", "metadata": {}}
{"_id": "mne_mne_label.py_morph_code", "title": "morph", "text": "def morph(\n        self,\n        subject_from=None,\n        subject_to=None,\n        smooth=5,\n        grade=None,\n        subjects_dir=None,\n        n_jobs=None,\n        verbose=None,\n    ):\n        \"\"\"Morph the label.\n\n        Useful for transforming a label from one subject to another.\n\n        Parameters\n        ----------\n        subject_from : str | None\n            The name of the subject of the current label. If None, the\n            initial subject will be taken from self.subject.\n        subject_to : str\n            The name of the subject to morph the label to. This will\n            be put in label.subject of the output label file.\n        smooth : int\n            Number of iterations for the smoothing of the surface data.\n            Cannot be None here since not all vertices are used.\n        grade : int, list of shape (2,), array, or None\n            Resolution of the icosahedral mesh (typically 5). If None, all\n            vertices will be used (potentially filling the surface). If a list,\n            values will be morphed to the set of vertices specified in grade[0]\n            and grade[1], assuming that these are vertices for the left and\n            right hemispheres. Note that specifying the vertices (e.g.,\n            ``grade=[np.arange(10242), np.arange(10242)]`` for fsaverage on a\n            standard grade 5 source space) can be substantially faster than\n            computing vertex locations. If one array is used, it is assumed\n            that all vertices belong to the hemisphere of the label. To create\n            a label filling the surface, use None.\n        %(subjects_dir)s\n        %(n_jobs)s\n        %(verbose)s\n\n        Returns\n        -------\n        label : instance of Label\n            The morphed label.\n\n        See Also\n        --------\n        mne.morph_labels : Morph a set of labels.\n\n        Notes\n        -----\n        This function will set label.pos to be all zeros. If the positions\n        on the new surface are required, consider using `mne.read_surface`\n        with ``label.vertices``.\n        \"\"\"\n        from .morph import compute_source_morph, grade_to_vertices\n\n        subject_from = _check_subject(self.subject, subject_from)\n        if not isinstance(subject_to, str):\n            raise TypeError('\"subject_to\" must be entered as a string')\n        if not isinstance(smooth, int):\n            raise TypeError(\"smooth must be an integer\")\n        if np.all(self.values == 0):\n            raise ValueError(\n                \"Morphing label with all zero values will result \"\n                \"in the label having no vertices. Consider using \"\n                \"something like label.values.fill(1.0).\"\n            )\n        idx = 0 if self.hemi == \"lh\" else 1\n        if isinstance(grade, np.ndarray):\n            grade_ = [np.array([], int)] * 2\n            grade_[idx] = grade\n            grade = grade_\n            del grade_\n        grade = grade_to_vertices(subject_to, grade, subjects_dir=subjects_dir)\n        spacing = [np.array([], int)] * 2\n        spacing[idx] = grade[idx]\n        vertices = [np.array([], int)] * 2\n        vertices[idx] = self.vertices\n        data = self.values[:, np.newaxis]\n        assert len(data) == sum(len(v) for v in vertices)\n        stc = SourceEstimate(data, vertices, tmin=1, tstep=1, subject=subject_from)\n        stc = compute_source_morph(\n            stc,\n            subject_from,\n            subject_to,\n            spacing=spacing,\n            smooth=smooth,\n            subjects_dir=subjects_dir,\n            warn=False,\n        ).apply(stc)\n        inds = np.nonzero(stc.data)[0]\n        self.values = stc.data[inds, :].ravel()\n        self.pos = np.zeros((len(inds), 3))\n        self.vertices = stc.vertices[idx][inds]\n        self.subject = subject_to\n        return self", "metadata": {}}
{"_id": "mne_mne_label.py_split_code", "title": "split", "text": "def split(self, parts=2, subject=None, subjects_dir=None, freesurfer=False):\n        \"\"\"Split the Label into two or more parts.\n\n        Parameters\n        ----------\n        parts : int >= 2 | tuple of str | str\n            Number of labels to create (default is 2), or tuple of strings\n            specifying label names for new labels (from posterior to anterior),\n            or 'contiguous' to split the label into connected components.\n            If a number or 'contiguous' is specified, names of the new labels\n            will be the input label's name with div1, div2 etc. appended.\n        %(subject_label)s\n        %(subjects_dir)s\n        freesurfer : bool\n            By default (``False``) ``split_label`` uses an algorithm that is\n            slightly optimized for performance and numerical precision. Set\n            ``freesurfer`` to ``True`` in order to replicate label splits from\n            FreeSurfer's ``mris_divide_parcellation``.\n\n        Returns\n        -------\n        labels : list of Label, shape (n_parts,)\n            The labels, starting from the lowest to the highest end of the\n            projection axis.\n\n        Notes\n        -----\n        If using 'contiguous' split, you must ensure that the label being split\n        uses the same triangular resolution as the surface mesh files in\n        ``subjects_dir`` Also, some small fringe labels may be returned that\n        are close (but not connected) to the large components.\n\n        The spatial split finds the label's principal eigen-axis on the\n        spherical surface, projects all label vertex coordinates onto this\n        axis, and divides them at regular spatial intervals.\n        \"\"\"\n        if isinstance(parts, str) and parts == \"contiguous\":\n            return _split_label_contig(self, subject, subjects_dir)\n        elif isinstance(parts, tuple | int):\n            return split_label(self, parts, subject, subjects_dir, freesurfer)\n        else:\n            raise ValueError(\n                \"Need integer, tuple of strings, or string \"\n                f\"('contiguous'). Got {type(parts)})\"\n            )", "metadata": {}}
{"_id": "mne_mne_label.py_get_vertices_used_code", "title": "get_vertices_used", "text": "def get_vertices_used(self, vertices=None):\n        \"\"\"Get the source space's vertices inside the label.\n\n        Parameters\n        ----------\n        vertices : ndarray of int, shape (n_vertices,) | None\n            The set of vertices to compare the label to. If None, equals to\n            ``np.arange(10242)``. Defaults to None.\n\n        Returns\n        -------\n        label_verts : ndarray of in, shape (n_label_vertices,)\n            The vertices of the label corresponding used by the data.\n        \"\"\"\n        if vertices is None:\n            vertices = np.arange(10242)\n\n        label_verts = vertices[np.isin(vertices, self.vertices)]\n        return label_verts", "metadata": {}}
{"_id": "mne_mne_label.py_get_tris_code", "title": "get_tris", "text": "def get_tris(self, tris, vertices=None):\n        \"\"\"Get the source space's triangles inside the label.\n\n        Parameters\n        ----------\n        tris : ndarray of int, shape (n_tris, 3)\n            The set of triangles corresponding to the vertices in a\n            source space.\n        vertices : ndarray of int, shape (n_vertices,) | None\n            The set of vertices to compare the label to. If None, equals to\n            ``np.arange(10242)``. Defaults to None.\n\n        Returns\n        -------\n        label_tris : ndarray of int, shape (n_tris, 3)\n            The subset of tris used by the label.\n        \"\"\"\n        vertices_ = self.get_vertices_used(vertices)\n        selection = np.all(np.isin(tris, vertices_).reshape(tris.shape), axis=1)\n        label_tris = tris[selection]\n        if len(np.unique(label_tris)) < len(vertices_):\n            logger.info(\"Surprising label structure. Trying to repair triangles.\")\n            dropped_vertices = np.setdiff1d(vertices_, label_tris)\n            n_dropped = len(dropped_vertices)\n            assert n_dropped == (len(vertices_) - len(np.unique(label_tris)))\n\n            #  put missing vertices as extra zero-length triangles\n            add_tris = (\n                dropped_vertices + np.zeros((len(dropped_vertices), 3), dtype=int).T\n            )\n\n            label_tris = np.r_[label_tris, add_tris.T]\n            assert len(np.unique(label_tris)) == len(vertices_)\n\n        return label_tris", "metadata": {}}
{"_id": "mne_mne_label.py_center_of_mass_code", "title": "center_of_mass", "text": "def center_of_mass(\n        self, subject=None, restrict_vertices=False, subjects_dir=None, surf=\"sphere\"\n    ):\n        \"\"\"Compute the center of mass of the label.\n\n        This function computes the spatial center of mass on the surface\n        as in :footcite:`LarsonLee2013`.\n\n        Parameters\n        ----------\n        %(subject_label)s\n        restrict_vertices : bool | array of int | instance of SourceSpaces\n            If True, returned vertex will be one from the label. Otherwise,\n            it could be any vertex from surf. If an array of int, the\n            returned vertex will come from that array. If instance of\n            SourceSpaces (as of 0.13), the returned vertex will be from\n            the given source space. For most accuruate estimates, do not\n            restrict vertices.\n        %(subjects_dir)s\n        surf : str\n            The surface to use for Euclidean distance center of mass\n            finding. The default here is \"sphere\", which finds the center\n            of mass on the spherical surface to help avoid potential issues\n            with cortical folding.\n\n        Returns\n        -------\n        vertex : int\n            Vertex of the spatial center of mass for the inferred hemisphere,\n            with each vertex weighted by its label value.\n\n        See Also\n        --------\n        SourceEstimate.center_of_mass\n        vertex_to_mni\n\n        Notes\n        -----\n        .. versionadded:: 0.13\n\n        References\n        ----------\n        .. footbibliography::\n        \"\"\"\n        if not isinstance(surf, str):\n            raise TypeError(f\"surf must be a string, got {type(surf)}\")\n        subject = _check_subject(self.subject, subject)\n        if np.any(self.values < 0):\n            raise ValueError(\"Cannot compute COM with negative values\")\n        if np.all(self.values == 0):\n            raise ValueError(\n                \"Cannot compute COM with all values == 0. For \"\n                \"structural labels, consider setting to ones via \"\n                \"label.values[:] = 1.\"\n            )\n        vertex = _center_of_mass(\n            self.vertices,\n            self.values,\n            self.hemi,\n            surf,\n            subject,\n            subjects_dir,\n            restrict_vertices,\n        )\n        return vertex", "metadata": {}}
{"_id": "mne_mne_label.py_distances_to_outside_code", "title": "distances_to_outside", "text": "def distances_to_outside(\n        self, subject=None, subjects_dir=None, surface=\"white\", *, verbose=None\n    ):\n        \"\"\"Compute the distance from each vertex to outside the label.\n\n        Parameters\n        ----------\n        %(subject_label)s\n        %(subjects_dir)s\n        %(surface)s\n        %(verbose)s\n\n        Returns\n        -------\n        dist : ndarray, shape (n_vertices,)\n            The distance from each vertex in ``self.vertices`` to exit the\n            label.\n        outside_vertices : ndarray, shape (n_vertices,)\n            For each vertex in the label, the nearest vertex outside the\n            label.\n\n        Notes\n        -----\n        Distances are computed along the cortical surface.\n\n        .. versionadded:: 0.24\n        \"\"\"\n        rr, tris = self._load_surface(subject, subjects_dir, surface)\n        adjacency = mesh_dist(tris, rr)\n        mask = np.zeros(len(rr))\n        mask[self.vertices] = 1\n        border_vert = _mesh_borders(tris, mask)\n        # vertices on the edge\n        outside_vert = np.setdiff1d(border_vert, self.vertices)\n        dist, _, outside = sparse.csgraph.dijkstra(\n            adjacency, indices=outside_vert, min_only=True, return_predecessors=True\n        )\n        dist = dist[self.vertices] * 1e-3  # mm to m\n        outside = outside[self.vertices]\n        return dist, outside", "metadata": {}}
{"_id": "mne_mne_label.py_compute_area_code", "title": "compute_area", "text": "def compute_area(\n        self, subject=None, subjects_dir=None, surface=\"white\", *, verbose=None\n    ):\n        \"\"\"Compute the surface area of a label.\n\n        Parameters\n        ----------\n        %(subject_label)s\n        %(subjects_dir)s\n        %(surface)s\n        %(verbose)s\n\n        Returns\n        -------\n        area : float\n            The area (in m\u00b2) of the label.\n\n        Notes\n        -----\n        ..versionadded:: 0.24\n        \"\"\"\n        _, _, surf = self._load_surface(\n            subject, subjects_dir, surface, return_dict=True\n        )\n        complete_surface_info(\n            surf, do_neighbor_vert=False, do_neighbor_tri=False, copy=False\n        )\n        in_ = np.isin(surf[\"tris\"], self.vertices).reshape(surf[\"tris\"].shape)\n        tidx = np.where(in_.all(-1))[0]\n        if len(tidx) == 0:\n            warn(\"No complete triangles found, perhaps label is not filled?\")\n        return surf[\"tri_area\"][tidx].sum() * 1e-6", "metadata": {}}
{"_id": "mne_mne_cuda.py_get_cuda_memory_code", "title": "get_cuda_memory", "text": "def get_cuda_memory(kind=\"available\"):\n    \"\"\"Get the amount of free memory for CUDA operations.\n\n    Parameters\n    ----------\n    kind : str\n        Can be ``\"available\"`` or ``\"total\"``.\n\n    Returns\n    -------\n    memory : str\n        The amount of available or total memory as a human-readable string.\n    \"\"\"\n    if not _cuda_capable:\n        warn(\"CUDA not enabled, returning zero for memory\")\n        mem = 0\n    else:\n        import cupy\n\n        mem = cupy.cuda.runtime.memGetInfo()[dict(available=0, total=1)[kind]]\n    return sizeof_fmt(mem)", "metadata": {}}
{"_id": "mne_mne_cuda.py_init_cuda_code", "title": "init_cuda", "text": "def init_cuda(ignore_config=False, verbose=None):\n    \"\"\"Initialize CUDA functionality.\n\n    This function attempts to load the necessary interfaces\n    (hardware connectivity) to run CUDA-based filtering. This\n    function should only need to be run once per session.\n\n    If the config var (set via mne.set_config or in ENV)\n    MNE_USE_CUDA == 'true', this function will be executed when\n    the first CUDA setup is performed. If this variable is not\n    set, this function can be manually executed.\n\n    Parameters\n    ----------\n    ignore_config : bool\n        If True, ignore the config value MNE_USE_CUDA and force init.\n    %(verbose)s\n    \"\"\"\n    global _cuda_capable\n    if _cuda_capable:\n        return\n    if not ignore_config and (get_config(\"MNE_USE_CUDA\", \"false\").lower() != \"true\"):\n        logger.info(\"CUDA not enabled in config, skipping initialization\")\n        return\n    # Triage possible errors for informative messaging\n    _cuda_capable = False\n    try:\n        import cupy  # noqa\n    except ImportError:\n        warn(\"module cupy not found, CUDA not enabled\")\n        return\n    device_id = int(get_config(\"MNE_CUDA_DEVICE\", \"0\"))\n    try:\n        # Initialize CUDA\n        _set_cuda_device(device_id, verbose)\n    except Exception:\n        warn(\n            \"so CUDA device could be initialized, likely a hardware error, \"\n            f\"CUDA not enabled{_explain_exception()}\"\n        )\n        return\n\n    _cuda_capable = True\n    # Figure out limit for CUDA FFT calculations\n    logger.info(f\"Enabling CUDA with {get_cuda_memory()} available memory\")", "metadata": {}}
{"_id": "mne_mne_cuda.py_set_cuda_device_code", "title": "set_cuda_device", "text": "def set_cuda_device(device_id, verbose=None):\n    \"\"\"Set the CUDA device temporarily for the current session.\n\n    Parameters\n    ----------\n    device_id : int\n        Numeric ID of the CUDA-capable device you want MNE-Python to use.\n    %(verbose)s\n    \"\"\"\n    if _cuda_capable:\n        _set_cuda_device(device_id, verbose)\n    elif get_config(\"MNE_USE_CUDA\", \"false\").lower() == \"true\":\n        init_cuda()\n        _set_cuda_device(device_id, verbose)\n    else:\n        warn(\n            \"Could not set CUDA device because CUDA is not enabled; either \"\n            \"run mne.cuda.init_cuda() first, or set the MNE_USE_CUDA config \"\n            'variable to \"true\".'\n        )", "metadata": {}}
{"_id": "mne_mne_annotations.py_read_annotations_code", "title": "read_annotations", "text": "def read_annotations(\n    fname, sfreq=\"auto\", uint16_codec=None, encoding=\"utf8\", ignore_marker_types=False\n) -> Annotations:\n    r\"\"\"Read annotations from a file.\n\n    This function reads a ``.fif``, ``.fif.gz``, ``.vmrk``, ``.amrk``,\n    ``.edf``, ``.bdf``, ``.gdf``, ``.txt``, ``.csv``, ``.cnt``, ``.cef``, or\n    ``.set`` file and makes an :class:`mne.Annotations` object.\n\n    Parameters\n    ----------\n    fname : path-like\n        The filename.\n    sfreq : float | ``'auto'``\n        The sampling frequency in the file. This parameter is necessary for\n        \\*.vmrk, \\*.amrk, and \\*.cef files as Annotations are expressed in\n        seconds and \\*.vmrk/\\*.amrk/\\*.cef files are in samples. For any other\n        file format, ``sfreq`` is omitted. If set to 'auto' then the ``sfreq``\n        is taken from the respective info file of the same name with according\n        file extension (\\*.vhdr/\\*.ahdr for brainvision; \\*.dap for Curry 7;\n        \\*.cdt.dpa for Curry 8). So data.vmrk/amrk looks for sfreq in\n        data.vhdr/ahdr, data.cef looks in data.dap and data.cdt.cef looks in\n        data.cdt.dpa.\n    uint16_codec : str | None\n        This parameter is only used in EEGLAB (\\*.set) and omitted otherwise.\n        If your \\*.set file contains non-ascii characters, sometimes reading\n        it may fail and give rise to error message stating that \"buffer is\n        too small\". ``uint16_codec`` allows to specify what codec (for example:\n        ``'latin1'`` or ``'utf-8'``) should be used when reading character\n        arrays and can therefore help you solve this problem.\n    %(encoding_edf)s\n        Only used when reading EDF annotations.\n    ignore_marker_types : bool\n        If ``True``, ignore marker types in BrainVision files (and only use their\n        descriptions). Defaults to ``False``.\n\n    Returns\n    -------\n    annot : instance of Annotations\n        The annotations.\n\n    Notes\n    -----\n    The annotations stored in a ``.csv`` require the onset columns to be\n    timestamps. If you have onsets as floats (in seconds), you should use the\n    ``.txt`` extension.\n    \"\"\"\n    from .io.brainvision.brainvision import _read_annotations_brainvision\n    from .io.cnt.cnt import _read_annotations_cnt\n    from .io.ctf.markers import _read_annotations_ctf\n    from .io.curry.curry import _read_annotations_curry\n    from .io.edf.edf import _read_annotations_edf\n    from .io.eeglab.eeglab import _read_annotations_eeglab\n\n    fname = _check_fname(\n        fname,\n        overwrite=\"read\",\n        must_exist=True,\n        need_dir=str(fname).endswith(\".ds\"),  # for CTF\n        name=\"fname\",\n    )\n    readers = {\n        \".csv\": _read_annotations_csv,\n        \".cnt\": _read_annotations_cnt,\n        \".ds\": _read_annotations_ctf,\n        \".cef\": _read_annotations_curry,\n        \".set\": _read_annotations_eeglab,\n        \".edf\": _read_annotations_edf,\n        \".bdf\": _read_annotations_edf,\n        \".gdf\": _read_annotations_edf,\n        \".vmrk\": _read_annotations_brainvision,\n        \".amrk\": _read_annotations_brainvision,\n        \".txt\": _read_annotations_txt,\n    }\n    kwargs = {\n        \".vmrk\": {\"sfreq\": sfreq, \"ignore_marker_types\": ignore_marker_types},\n        \".amrk\": {\"sfreq\": sfreq, \"ignore_marker_types\": ignore_marker_types},\n        \".cef\": {\"sfreq\": sfreq},\n        \".set\": {\"uint16_codec\": uint16_codec},\n        \".edf\": {\"encoding\": encoding},\n        \".bdf\": {\"encoding\": encoding},\n        \".gdf\": {\"encoding\": encoding},\n    }\n    if fname.suffix in readers:\n        annotations = readers[fname.suffix](fname, **kwargs.get(fname.suffix, {}))\n    elif fname.name.endswith((\"fif\", \"fif.gz\")):\n        # Read FiF files\n        ff, tree, _ = fiff_open(fname, preload=False)\n        with ff as fid:\n            annotations = _read_annotations_fif(fid, tree)\n    elif fname.name.startswith(\"events_\") and fname.suffix == \".mat\":\n        annotations = _read_brainstorm_annotations(fname)\n    else:\n        raise OSError(f'Unknown annotation file format \"{fname}\"')\n\n    if annotations is None:\n        raise OSError(f'No annotation data found in file \"{fname}\"')\n    return annotations", "metadata": {}}
{"_id": "mne_mne_annotations.py_events_from_annotations_code", "title": "events_from_annotations", "text": "def events_from_annotations(\n    raw,\n    event_id=\"auto\",\n    regexp=r\"^(?![Bb][Aa][Dd]|[Ee][Dd][Gg][Ee]).*$\",\n    use_rounding=True,\n    chunk_duration=None,\n    tol=1e-8,\n    verbose=None,\n):\n    \"\"\"Get :term:`events` and ``event_id`` from an Annotations object.\n\n    Parameters\n    ----------\n    raw : instance of Raw\n        The raw data for which Annotations are defined.\n    event_id : dict | callable | None | ``'auto'``\n        Can be:\n\n        - **dict**: map descriptions (keys) to integer event codes (values).\n          Only the descriptions present will be mapped, others will be ignored.\n        - **callable**: must take a string input and return an integer event\n          code, or return ``None`` to ignore the event.\n        - **None**: Map descriptions to unique integer values based on their\n          ``sorted`` order.\n        - **'auto' (default)**: prefer a raw-format-specific parser:\n\n          - Brainvision: map stimulus events to their integer part; response\n            events to integer part + 1000; optic events to integer part + 2000;\n            'SyncStatus/Sync On' to 99998; 'New Segment/' to 99999;\n            all others like ``None`` with an offset of 10000.\n          - Other raw formats: Behaves like None.\n\n          .. versionadded:: 0.18\n    regexp : str | None\n        Regular expression used to filter the annotations whose\n        descriptions is a match. The default ignores descriptions beginning\n        ``'bad'`` or ``'edge'`` (case-insensitive).\n\n        .. versionchanged:: 0.18\n           Default ignores bad and edge descriptions.\n    use_rounding : bool\n        If True, use rounding (instead of truncation) when converting\n        times to indices. This can help avoid non-unique indices.\n    chunk_duration : float | None\n        Chunk duration in seconds. If ``chunk_duration`` is set to None\n        (default), generated events correspond to the annotation onsets.\n        If not, :func:`mne.events_from_annotations` returns as many events as\n        they fit within the annotation duration spaced according to\n        ``chunk_duration``. As a consequence annotations with duration shorter\n        than ``chunk_duration`` will not contribute events.\n    tol : float\n        The tolerance used to check if a chunk fits within an annotation when\n        ``chunk_duration`` is not ``None``. If the duration from a computed\n        chunk onset to the end of the annotation is smaller than\n        ``chunk_duration`` minus ``tol``, the onset will be discarded.\n    %(verbose)s\n\n    Returns\n    -------\n    %(events)s\n    event_id : dict\n        The event_id variable that can be passed to :class:`~mne.Epochs`.\n\n    See Also\n    --------\n    mne.annotations_from_events\n\n    Notes\n    -----\n    For data formats that store integer events as strings (e.g., NeuroScan\n    ``.cnt`` files), passing the Python built-in function :class:`int` as the\n    ``event_id`` parameter will do what most users probably want in those\n    circumstances: return an ``event_id`` dictionary that maps event ``'1'`` to\n    integer event code ``1``, ``'2'`` to ``2``, etc.\n    \"\"\"\n    if len(raw.annotations) == 0:\n        event_id = dict() if not isinstance(event_id, dict) else event_id\n        return np.empty((0, 3), dtype=int), event_id\n\n    annotations = raw.annotations\n\n    event_id = _check_event_id(event_id, raw)\n\n    event_sel, event_id_ = _select_annotations_based_on_description(\n        annotations.description, event_id=event_id, regexp=regexp\n    )\n\n    if chunk_duration is None:\n        inds = raw.time_as_index(\n            annotations.onset, use_rounding=use_rounding, origin=annotations.orig_time\n        )\n        if annotations.orig_time is not None:\n            inds += raw.first_samp\n        values = [event_id_[kk] for kk in annotations.description[event_sel]]\n        inds = inds[event_sel]\n    else:\n        inds = values = np.array([]).astype(int)\n        for annot in annotations[event_sel]:\n            annot_offset = annot[\"onset\"] + annot[\"duration\"]\n            _onsets = np.arange(annot[\"onset\"], annot_offset, chunk_duration)\n            good_events = annot_offset - _onsets >= chunk_duration - tol\n            if good_events.any():\n                _onsets = _onsets[good_events]\n                _inds = raw.time_as_index(\n                    _onsets, use_rounding=use_rounding, origin=annotations.orig_time\n                )\n                _inds += raw.first_samp\n                inds = np.append(inds, _inds)\n                _values = np.full(\n                    shape=len(_inds),\n                    fill_value=event_id_[annot[\"description\"]],\n                    dtype=int,\n                )\n                values = np.append(values, _values)\n\n    events = np.c_[inds, np.zeros(len(inds)), values].astype(int)\n\n    logger.info(f\"Used Annotations descriptions: {list(event_id_.keys())}\")\n\n    return events, event_id_", "metadata": {}}
{"_id": "mne_mne_annotations.py_annotations_from_events_code", "title": "annotations_from_events", "text": "def annotations_from_events(\n    events, sfreq, event_desc=None, first_samp=0, orig_time=None, verbose=None\n):\n    \"\"\"Convert an event array to an Annotations object.\n\n    Parameters\n    ----------\n    events : ndarray, shape (n_events, 3)\n        The events.\n    sfreq : float\n        Sampling frequency.\n    event_desc : dict | array-like | callable | None\n        Events description. Can be:\n\n        - **dict**: map integer event codes (keys) to descriptions (values).\n          Only the descriptions present will be mapped, others will be ignored.\n        - **array-like**: list, or 1d array of integers event codes to include.\n          Only the event codes present will be mapped, others will be ignored.\n          Event codes will be passed as string descriptions.\n        - **callable**: must take a integer event code as input and return a\n          string description or None to ignore it.\n        - **None**: Use integer event codes as descriptions.\n    first_samp : int\n        The first data sample (default=0). See :attr:`mne.io.Raw.first_samp`\n        docstring.\n    orig_time : float | str | datetime | tuple of int | None\n        Determines the starting time of annotation acquisition. If None\n        (default), starting time is determined from beginning of raw data\n        acquisition. For details, see :meth:`mne.Annotations` docstring.\n    %(verbose)s\n\n    Returns\n    -------\n    annot : instance of Annotations\n        The annotations.\n\n    See Also\n    --------\n    mne.events_from_annotations\n\n    Notes\n    -----\n    Annotations returned by this function will all have zero (null) duration.\n\n    Creating events from annotations via the function\n    `mne.events_from_annotations` takes in event mappings with\n    key\u2192value pairs as description\u2192ID, whereas `mne.annotations_from_events`\n    takes in event mappings with key\u2192value pairs as ID\u2192description.\n    If you need to use these together, you can invert the mapping by doing::\n\n        event_desc = {v: k for k, v in event_id.items()}\n    \"\"\"\n    event_desc = _check_event_description(event_desc, events)\n    event_sel, event_desc_ = _select_events_based_on_id(events, event_desc)\n    events_sel = events[event_sel]\n    onsets = (events_sel[:, 0] - first_samp) / sfreq\n    descriptions = [event_desc_[e[2]] for e in events_sel]\n    durations = np.zeros(len(events_sel))  # dummy durations\n\n    # Create annotations\n    annots = Annotations(\n        onset=onsets, duration=durations, description=descriptions, orig_time=orig_time\n    )\n\n    return annots", "metadata": {}}
{"_id": "mne_mne_annotations.py_count_annotations_code", "title": "count_annotations", "text": "def count_annotations(annotations):\n    \"\"\"Count annotations.\n\n    Parameters\n    ----------\n    annotations : mne.Annotations\n        The annotations instance.\n\n    Returns\n    -------\n    counts : dict\n        A dictionary containing unique annotation descriptions as keys with their\n        counts as values.\n\n    Examples\n    --------\n        >>> annotations = mne.Annotations([0, 1, 2], [1, 2, 1], [\"T0\", \"T1\", \"T0\"])\n        >>> count_annotations(annotations)\n        {'T0': 2, 'T1': 1}\n    \"\"\"\n    types, counts = np.unique(annotations.description, return_counts=True)\n    return {str(t): int(count) for t, count in zip(types, counts)}", "metadata": {}}
{"_id": "mne_mne_annotations.py_orig_time_code", "title": "orig_time", "text": "def orig_time(self):\n        \"\"\"The time base of the Annotations.\"\"\"\n        return self._orig_time", "metadata": {}}
{"_id": "mne_mne_annotations.py_append_code", "title": "append", "text": "def append(self, onset, duration, description, ch_names=None):\n        \"\"\"Add an annotated segment. Operates inplace.\n\n        Parameters\n        ----------\n        onset : float | array-like\n            Annotation time onset from the beginning of the recording in\n            seconds.\n        duration : float | array-like\n            Duration of the annotation in seconds.\n        description : str | array-like\n            Description for the annotation. To reject epochs, use description\n            starting with keyword 'bad'.\n        %(ch_names_annot)s\n\n            .. versionadded:: 0.23\n\n        Returns\n        -------\n        self : mne.Annotations\n            The modified Annotations object.\n\n        Notes\n        -----\n        The array-like support for arguments allows this to be used similarly\n        to not only ``list.append``, but also\n        `list.extend <https://docs.python.org/3/library/stdtypes.html#mutable-sequence-types>`__.\n        \"\"\"  # noqa: E501\n        onset, duration, description, ch_names = _check_o_d_s_c(\n            onset, duration, description, ch_names\n        )\n        self.onset = np.append(self.onset, onset)\n        self.duration = np.append(self.duration, duration)\n        self.description = np.append(self.description, description)\n        self.ch_names = np.append(self.ch_names, ch_names)\n        self._sort()\n        return self", "metadata": {}}
{"_id": "mne_mne_annotations.py_copy_code", "title": "copy", "text": "def copy(self):\n        \"\"\"Return a copy of the Annotations.\n\n        Returns\n        -------\n        inst : instance of Annotations\n            A copy of the object.\n        \"\"\"\n        return deepcopy(self)", "metadata": {}}
{"_id": "mne_mne_annotations.py_delete_code", "title": "delete", "text": "def delete(self, idx):\n        \"\"\"Remove an annotation. Operates inplace.\n\n        Parameters\n        ----------\n        idx : int | array-like of int\n            Index of the annotation to remove. Can be array-like to\n            remove multiple indices.\n        \"\"\"\n        self.onset = np.delete(self.onset, idx)\n        self.duration = np.delete(self.duration, idx)\n        self.description = np.delete(self.description, idx)\n        self.ch_names = np.delete(self.ch_names, idx)", "metadata": {}}
{"_id": "mne_mne_annotations.py_to_data_frame_code", "title": "to_data_frame", "text": "def to_data_frame(self, time_format=\"datetime\"):\n        \"\"\"Export annotations in tabular structure as a pandas DataFrame.\n\n        Parameters\n        ----------\n        %(time_format_df_raw)s\n\n            .. versionadded:: 1.7\n\n        Returns\n        -------\n        result : pandas.DataFrame\n            Returns a pandas DataFrame with onset, duration, and\n            description columns. A column named ch_names is added if any\n            annotations are channel-specific.\n        \"\"\"\n        pd = _check_pandas_installed(strict=True)\n        valid_time_formats = [\"ms\", \"timedelta\", \"datetime\"]\n        dt = _handle_meas_date(self.orig_time)\n        if dt is None:\n            dt = _handle_meas_date(0)\n        time_format = _check_time_format(time_format, valid_time_formats, dt)\n        dt = dt.replace(tzinfo=None)\n        times = _convert_times(self.onset, time_format, dt)\n        df = dict(onset=times, duration=self.duration, description=self.description)\n        if self._any_ch_names():\n            df.update(ch_names=self.ch_names)\n        df = pd.DataFrame(df)\n        return df", "metadata": {}}
{"_id": "mne_mne_annotations.py_count_code", "title": "count", "text": "def count(self):\n        \"\"\"Count annotations.\n\n        Returns\n        -------\n        counts : dict\n            A dictionary containing unique annotation descriptions as keys with their\n            counts as values.\n        \"\"\"\n        return count_annotations(self)", "metadata": {}}
{"_id": "mne_mne_annotations.py_save_code", "title": "save", "text": "def save(self, fname, *, overwrite=False, verbose=None):\n        \"\"\"Save annotations to FIF, CSV or TXT.\n\n        Typically annotations get saved in the FIF file for raw data\n        (e.g., as ``raw.annotations``), but this offers the possibility\n        to also save them to disk separately in different file formats\n        which are easier to share between packages.\n\n        Parameters\n        ----------\n        fname : path-like\n            The filename to use.\n        %(overwrite)s\n\n            .. versionadded:: 0.23\n        %(verbose)s\n\n        Notes\n        -----\n        The format of the information stored in the saved annotation objects\n        depends on the chosen file format. :file:`.csv` files store the onset\n        as timestamps (e.g., ``2002-12-03 19:01:56.676071``),\n        whereas :file:`.txt` files store onset as seconds since start of the\n        recording (e.g., ``45.95597082905339``).\n        \"\"\"\n        check_fname(\n            fname,\n            \"annotations\",\n            (\n                \"-annot.fif\",\n                \"-annot.fif.gz\",\n                \"_annot.fif\",\n                \"_annot.fif.gz\",\n                \".txt\",\n                \".csv\",\n            ),\n        )\n        fname = _check_fname(fname, overwrite=overwrite)\n        if fname.suffix == \".txt\":\n            _write_annotations_txt(fname, self)\n        elif fname.suffix == \".csv\":\n            _write_annotations_csv(fname, self)\n        else:\n            with start_and_end_file(fname) as fid:\n                _write_annotations(fid, self)", "metadata": {}}
{"_id": "mne_mne_annotations.py_crop_code", "title": "crop", "text": "def crop(\n        self, tmin=None, tmax=None, emit_warning=False, use_orig_time=True, verbose=None\n    ):\n        \"\"\"Remove all annotation that are outside of [tmin, tmax].\n\n        The method operates inplace.\n\n        Parameters\n        ----------\n        tmin : float | datetime | None\n            Start time of selection in seconds.\n        tmax : float | datetime | None\n            End time of selection in seconds.\n        emit_warning : bool\n            Whether to emit warnings when limiting or omitting annotations.\n            Defaults to False.\n        use_orig_time : bool\n            Whether to use orig_time as an offset.\n            Defaults to True.\n        %(verbose)s\n\n        Returns\n        -------\n        self : instance of Annotations\n            The cropped Annotations object.\n        \"\"\"\n        if len(self) == 0:\n            return self  # no annotations, nothing to do\n        if not use_orig_time or self.orig_time is None:\n            offset = _handle_meas_date(0)\n        else:\n            offset = self.orig_time\n        if tmin is None:\n            tmin = timedelta(seconds=self.onset.min()) + offset\n        if tmax is None:\n            tmax = timedelta(seconds=(self.onset + self.duration).max()) + offset\n        for key, val in [(\"tmin\", tmin), (\"tmax\", tmax)]:\n            _validate_type(\n                val, (\"numeric\", _datetime), key, \"numeric, datetime, or None\"\n            )\n        absolute_tmin = _handle_meas_date(tmin)\n        absolute_tmax = _handle_meas_date(tmax)\n        del tmin, tmax\n        if absolute_tmin > absolute_tmax:\n            raise ValueError(\n                f\"tmax should be greater than or equal to tmin ({absolute_tmin} < \"\n                f\"{absolute_tmax}).\"\n            )\n        logger.debug(f\"Cropping annotations {absolute_tmin} - {absolute_tmax}\")\n\n        onsets, durations, descriptions, ch_names = [], [], [], []\n        out_of_bounds, clip_left_elem, clip_right_elem = [], [], []\n        for idx, (onset, duration, description, ch) in enumerate(\n            zip(self.onset, self.duration, self.description, self.ch_names)\n        ):\n            # if duration is NaN behave like a zero\n            if np.isnan(duration):\n                duration = 0.0\n            # convert to absolute times\n            absolute_onset = timedelta(seconds=onset) + offset\n            absolute_offset = absolute_onset + timedelta(seconds=duration)\n            out_of_bounds.append(\n                absolute_onset > absolute_tmax or absolute_offset < absolute_tmin\n            )\n            if out_of_bounds[-1]:\n                clip_left_elem.append(False)\n                clip_right_elem.append(False)\n                logger.debug(\n                    f\"  [{idx}] Dropping \"\n                    f\"({absolute_onset} - {absolute_offset}: {description})\"\n                )\n            else:\n                # clip the left side\n                clip_left_elem.append(absolute_onset < absolute_tmin)\n                if clip_left_elem[-1]:\n                    absolute_onset = absolute_tmin\n                clip_right_elem.append(absolute_offset > absolute_tmax)\n                if clip_right_elem[-1]:\n                    absolute_offset = absolute_tmax\n                if clip_left_elem[-1] or clip_right_elem[-1]:\n                    durations.append((absolute_offset - absolute_onset).total_seconds())\n                else:\n                    durations.append(duration)\n                onsets.append((absolute_onset - offset).total_seconds())\n                logger.debug(\n                    f\"  [{idx}] Keeping  \"\n                    f\"({absolute_onset} - {absolute_offset} -> \"\n                    f\"{onset} - {onset + duration})\"\n                )\n                descriptions.append(description)\n                ch_names.append(ch)\n        logger.debug(f\"Cropping complete (kept {len(onsets)})\")\n        self.onset = np.array(onsets, float)\n        self.duration = np.array(durations, float)\n        assert (self.duration >= 0).all()\n        self.description = np.array(descriptions, dtype=str)\n        self.ch_names = _ndarray_ch_names(ch_names)\n\n        if emit_warning:\n            omitted = np.array(out_of_bounds).sum()\n            if omitted > 0:\n                warn(f\"Omitted {omitted} annotation(s) that were outside data range.\")\n            limited = (np.array(clip_left_elem) | np.array(clip_right_elem)).sum()\n            if limited > 0:\n                warn(\n                    f\"Limited {limited} annotation(s) that were expanding outside the\"\n                    \" data range.\"\n                )\n\n        return self", "metadata": {}}
{"_id": "mne_mne_annotations.py_set_durations_code", "title": "set_durations", "text": "def set_durations(self, mapping, verbose=None):\n        \"\"\"Set annotation duration(s). Operates inplace.\n\n        Parameters\n        ----------\n        mapping : dict | float\n            A dictionary mapping the annotation description to a duration in\n            seconds e.g. ``{'ShortStimulus' : 3, 'LongStimulus' : 12}``.\n            Alternatively, if a number is provided, then all annotations\n            durations are set to the single provided value.\n        %(verbose)s\n\n        Returns\n        -------\n        self : mne.Annotations\n            The modified Annotations object.\n\n        Notes\n        -----\n        .. versionadded:: 0.24.0\n        \"\"\"\n        _validate_type(mapping, (int, float, dict))\n\n        if isinstance(mapping, dict):\n            _check_dict_keys(\n                mapping,\n                self.description,\n                valid_key_source=\"data\",\n                key_description=\"Annotation description(s)\",\n            )\n            for stim in mapping:\n                map_idx = [desc == stim for desc in self.description]\n                self.duration[map_idx] = mapping[stim]\n\n        elif _is_numeric(mapping):\n            self.duration = np.ones(self.description.shape) * mapping\n\n        else:\n            raise ValueError(\n                \"Setting durations requires the mapping of \"\n                \"descriptions to times to be provided as a dict. \"\n                f\"Instead {type(mapping)} was provided.\"\n            )\n\n        return self", "metadata": {}}
{"_id": "mne_mne_annotations.py_rename_code", "title": "rename", "text": "def rename(self, mapping, verbose=None):\n        \"\"\"Rename annotation description(s). Operates inplace.\n\n        Parameters\n        ----------\n        mapping : dict\n            A dictionary mapping the old description to a new description,\n            e.g. {'1.0' : 'Control', '2.0' : 'Stimulus'}.\n        %(verbose)s\n\n        Returns\n        -------\n        self : mne.Annotations\n            The modified Annotations object.\n\n        Notes\n        -----\n        .. versionadded:: 0.24.0\n        \"\"\"\n        _validate_type(mapping, dict)\n        _check_dict_keys(\n            mapping,\n            self.description,\n            valid_key_source=\"data\",\n            key_description=\"Annotation description(s)\",\n        )\n        self.description = np.array([str(mapping.get(d, d)) for d in self.description])\n        return self", "metadata": {}}
{"_id": "mne_mne_annotations.py_set_annotations_code", "title": "set_annotations", "text": "def set_annotations(self, annotations, on_missing=\"raise\", *, verbose=None):\n        \"\"\"Setter for Epoch annotations from Raw.\n\n        This method does not handle offsetting the times based\n        on first_samp or measurement dates, since that is expected\n        to occur in Raw.set_annotations().\n\n        Parameters\n        ----------\n        annotations : instance of mne.Annotations | None\n            Annotations to set.\n        %(on_missing_ch_names)s\n        %(verbose)s\n\n        Returns\n        -------\n        self : instance of Epochs\n            The epochs object with annotations.\n\n        Notes\n        -----\n        Annotation onsets and offsets are stored as time in seconds (not as\n        sample numbers).\n\n        If you have an ``-epo.fif`` file saved to disk created before 1.0,\n        annotations can be added correctly only if no decimation or\n        resampling was performed. We thus suggest to regenerate your\n        :class:`mne.Epochs` from raw and re-save to disk with 1.0+ if you\n        want to safely work with :class:`~mne.Annotations` in epochs.\n\n        Since this method does not handle offsetting the times based\n        on first_samp or measurement dates, the recommended way to add\n        Annotations is::\n\n            raw.set_annotations(annotations)\n            annotations = raw.annotations\n            epochs.set_annotations(annotations)\n\n        .. versionadded:: 1.0\n        \"\"\"\n        _validate_type(annotations, (Annotations, None), \"annotations\")\n        if annotations is None:\n            self._annotations = None\n        else:\n            if getattr(self, \"_unsafe_annot_add\", False):\n                warn(\n                    \"Adding annotations to Epochs created (and saved to disk) before \"\n                    \"1.0 will yield incorrect results if decimation or resampling was \"\n                    \"performed on the instance, we recommend regenerating the Epochs \"\n                    \"and re-saving them to disk.\"\n                )\n            new_annotations = annotations.copy()\n            new_annotations._prune_ch_names(self.info, on_missing)\n            self._annotations = new_annotations\n        return self", "metadata": {}}
{"_id": "mne_mne_annotations.py_get_annotations_per_epoch_code", "title": "get_annotations_per_epoch", "text": "def get_annotations_per_epoch(self):\n        \"\"\"Get a list of annotations that occur during each epoch.\n\n        Returns\n        -------\n        epoch_annots : list\n            A list of lists (with length equal to number of epochs) where each\n            inner list contains any annotations that overlap the corresponding\n            epoch. Annotations are stored as a :class:`tuple` of onset,\n            duration, description (not as a :class:`~mne.Annotations` object),\n            where the onset is now relative to time=0 of the epoch, rather than\n            time=0 of the original continuous (raw) data.\n        \"\"\"\n        # create a list of annotations for each epoch\n        epoch_annot_list = [[] for _ in range(len(self.events))]\n\n        # check if annotations exist\n        if self.annotations is None:\n            return epoch_annot_list\n\n        # when each epoch and annotation starts/stops\n        # no need to account for first_samp here...\n        epoch_tzeros = self.events[:, 0] / self._raw_sfreq\n        epoch_starts, epoch_stops = (\n            np.atleast_2d(epoch_tzeros) + np.atleast_2d(self.times[[0, -1]]).T\n        )\n        # ... because first_samp isn't accounted for here either\n        annot_starts = self._annotations.onset\n        annot_stops = annot_starts + self._annotations.duration\n\n        # the first two cases (annot_straddles_epoch_{start|end}) will both\n        # (redundantly) capture cases where an annotation fully encompasses\n        # an epoch (e.g., annot from 1-4s, epoch from 2-3s). The redundancy\n        # doesn't matter because results are summed and then cast to bool (all\n        # we care about is presence/absence of overlap).\n        annot_straddles_epoch_start = np.logical_and(\n            np.atleast_2d(epoch_starts) >= np.atleast_2d(annot_starts).T,\n            np.atleast_2d(epoch_starts) < np.atleast_2d(annot_stops).T,\n        )\n\n        annot_straddles_epoch_end = np.logical_and(\n            np.atleast_2d(epoch_stops) > np.atleast_2d(annot_starts).T,\n            np.atleast_2d(epoch_stops) <= np.atleast_2d(annot_stops).T,\n        )\n\n        # this captures the only remaining case we care about: annotations\n        # fully contained within an epoch (or exactly coextensive with it).\n        annot_fully_within_epoch = np.logical_and(\n            np.atleast_2d(epoch_starts) <= np.atleast_2d(annot_starts).T,\n            np.atleast_2d(epoch_stops) >= np.atleast_2d(annot_stops).T,\n        )\n\n        # combine all cases to get array of shape (n_annotations, n_epochs).\n        # Nonzero entries indicate overlap between the corresponding\n        # annotation (row index) and epoch (column index).\n        all_cases = (\n            annot_straddles_epoch_start\n            + annot_straddles_epoch_end\n            + annot_fully_within_epoch\n        )\n\n        # for each Epoch-Annotation overlap occurrence:\n        for annot_ix, epo_ix in zip(*np.nonzero(all_cases)):\n            this_annot = self._annotations[annot_ix]\n            this_tzero = epoch_tzeros[epo_ix]\n            # adjust annotation onset to be relative to epoch tzero...\n            annot = (\n                this_annot[\"onset\"] - this_tzero,\n                this_annot[\"duration\"],\n                this_annot[\"description\"],\n            )\n            # ...then add it to the correct sublist of `epoch_annot_list`\n            epoch_annot_list[epo_ix].append(annot)\n        return epoch_annot_list", "metadata": {}}
{"_id": "mne_mne_annotations.py_add_annotations_to_metadata_code", "title": "add_annotations_to_metadata", "text": "def add_annotations_to_metadata(self, overwrite=False):\n        \"\"\"Add raw annotations into the Epochs metadata data frame.\n\n        Adds three columns to the ``metadata`` consisting of a list\n        in each row:\n        - ``annot_onset``: the onset of each Annotation within\n        the Epoch relative to the start time of the Epoch (in seconds).\n        - ``annot_duration``: the duration of each Annotation\n        within the Epoch in seconds.\n        - ``annot_description``: the free-form text description of each\n        Annotation.\n\n        Parameters\n        ----------\n        overwrite : bool\n            Whether to overwrite existing columns in metadata or not.\n            Default is False.\n\n        Returns\n        -------\n        self : instance of Epochs\n            The modified instance (instance is also modified inplace).\n\n        Notes\n        -----\n        .. versionadded:: 1.0\n        \"\"\"\n        pd = _check_pandas_installed()\n\n        # check if annotations exist\n        if self.annotations is None:\n            warn(\n                f\"There were no Annotations stored in {self}, so \"\n                \"metadata was not modified.\"\n            )\n            return self\n\n        # get existing metadata DataFrame or instantiate an empty one\n        if self._metadata is not None:\n            metadata = self._metadata\n        else:\n            data = np.empty((len(self.events), 0))\n            metadata = pd.DataFrame(data=data)\n\n        if (\n            any(\n                name in metadata.columns\n                for name in [\"annot_onset\", \"annot_duration\", \"annot_description\"]\n            )\n            and not overwrite\n        ):\n            raise RuntimeError(\n                \"Metadata for Epochs already contains columns \"\n                '\"annot_onset\", \"annot_duration\", or \"annot_description\".'\n            )\n\n        # get the Epoch annotations, then convert to separate lists for\n        # onsets, durations, and descriptions\n        epoch_annot_list = self.get_annotations_per_epoch()\n        onset, duration, description = [], [], []\n        for epoch_annot in epoch_annot_list:\n            for ix, annot_prop in enumerate((onset, duration, description)):\n                entry = [annot[ix] for annot in epoch_annot]\n\n                # round onset and duration to avoid IO round trip mismatch\n                if ix < 2:\n                    entry = np.round(entry, decimals=12).tolist()\n\n                annot_prop.append(entry)\n\n        # Create a new Annotations column that is instantiated as an empty\n        # list per Epoch.\n        metadata[\"annot_onset\"] = pd.Series(onset)\n        metadata[\"annot_duration\"] = pd.Series(duration)\n        metadata[\"annot_description\"] = pd.Series(description)\n\n        # reset the metadata\n        self.metadata = metadata\n        return self", "metadata": {}}
{"_id": "mne_mne_conftest.py_pytest_configure_code", "title": "pytest_configure", "text": "def pytest_configure(config: pytest.Config):\n    \"\"\"Configure pytest options.\"\"\"\n    # Markers\n    for marker in (\n        \"slowtest\",\n        \"ultraslowtest\",\n        \"pgtest\",\n        \"pvtest\",\n        \"allow_unclosed\",\n    ):\n        config.addinivalue_line(\"markers\", marker)\n\n    # Fixtures\n    for fixture in (\n        \"matplotlib_config\",\n        \"qt_config\",\n        \"protect_config\",\n    ):\n        config.addinivalue_line(\"usefixtures\", fixture)\n\n    # pytest-qt uses PYTEST_QT_API, but let's make it respect qtpy's QT_API\n    # if present\n    if os.getenv(\"PYTEST_QT_API\") is None and os.getenv(\"QT_API\") is not None:\n        os.environ[\"PYTEST_QT_API\"] = os.environ[\"QT_API\"]\n\n    # suppress:\n    # Debugger warning: It seems that frozen modules are being used, which may\n    # make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n    # to python to disable frozen modules.\n    if os.getenv(\"PYDEVD_DISABLE_FILE_VALIDATION\") is None:\n        os.environ[\"PYDEVD_DISABLE_FILE_VALIDATION\"] = \"1\"\n\n    # https://numba.readthedocs.io/en/latest/reference/deprecation.html#deprecation-of-old-style-numba-captured-errors  # noqa: E501\n    if \"NUMBA_CAPTURED_ERRORS\" not in os.environ:\n        os.environ[\"NUMBA_CAPTURED_ERRORS\"] = \"new_style\"\n\n    # Warnings\n    # - Once SciPy updates not to have non-integer and non-tuple errors (1.2.0)\n    #   we should remove them from here.\n    # - This list should also be considered alongside reset_warnings in\n    #   doc/conf.py.\n    if os.getenv(\"MNE_IGNORE_WARNINGS_IN_TESTS\", \"\") not in (\"true\", \"1\"):\n        first_kind = \"error\"\n    else:\n        first_kind = \"always\"\n    warning_lines = f\"    {first_kind}::\"\n    warning_lines += r\"\"\"\n    # matplotlib->traitlets (notebook)\n    ignore:Passing unrecognized arguments to super.*:DeprecationWarning\n    # notebook tests\n    ignore:There is no current event loop:DeprecationWarning\n    ignore:unclosed <socket\\.socket:ResourceWarning\n    ignore:unclosed event loop <:ResourceWarning\n    # ignore if joblib is missing\n    ignore:joblib not installed.*:RuntimeWarning\n    # qdarkstyle\n    ignore:.*Setting theme=.*:RuntimeWarning\n    # nbclient\n    ignore:Passing a schema to Validator\\.iter_errors is deprecated.*:\n    ignore:Unclosed context <zmq.asyncio.Context.*:ResourceWarning\n    ignore:Jupyter is migrating its paths.*:DeprecationWarning\n    ignore:datetime\\.datetime\\.utcnow\\(\\) is deprecated.*:DeprecationWarning\n    ignore:Widget\\..* is deprecated\\.:DeprecationWarning\n    ignore:.*is deprecated in pyzmq.*:DeprecationWarning\n    ignore:The `ipykernel.comm.Comm` class has been deprecated.*:DeprecationWarning\n    ignore:Proactor event loop does not implement:RuntimeWarning\n    # PySide6\n    ignore:Enum value .* is marked as deprecated:DeprecationWarning\n    ignore:Function.*is marked as deprecated, please check the documentation.*:DeprecationWarning\n    ignore:Failed to disconnect.*:RuntimeWarning\n    # pkg_resources usage bug\n    ignore:Implementing implicit namespace packages.*:DeprecationWarning\n    ignore:Deprecated call to `pkg_resources.*:DeprecationWarning\n    ignore:pkg_resources is deprecated as an API.*:DeprecationWarning\n    # numpy distutils used by SciPy\n    ignore:(\\n|.)*numpy\\.distutils` is deprecated since NumPy(\\n|.)*:DeprecationWarning\n    ignore:datetime\\.utcfromtimestamp.*is deprecated:DeprecationWarning\n    ignore:The numpy\\.array_api submodule is still experimental.*:UserWarning\n    # tqdm (Fedora)\n    ignore:.*'tqdm_asyncio' object has no attribute 'last_print_t':pytest.PytestUnraisableExceptionWarning\n    # Windows CIs using MESA get this\n    ignore:Mesa version 10\\.2\\.4 is too old for translucent.*:RuntimeWarning\n    # Matplotlib->tz\n    ignore:datetime.datetime.utcfromtimestamp.*:DeprecationWarning\n    # joblib\n    ignore:ast\\.Num is deprecated.*:DeprecationWarning\n    ignore:Attribute n is deprecated and will be removed in Python 3\\.14.*:DeprecationWarning\n    # numpydoc\n    ignore:ast\\.NameConstant is deprecated and will be removed in Python 3\\.14.*:DeprecationWarning\n    # pooch\n    ignore:Python 3\\.14 will, by default, filter extracted tar archives.*:DeprecationWarning\n    # pandas\n    ignore:\\n*Pyarrow will become a required dependency of pandas.*:DeprecationWarning\n    ignore:np\\.find_common_type is deprecated.*:DeprecationWarning\n    ignore:Python binding for RankQuantileOptions.*:\n    # pyvista <-> NumPy 2.0\n    ignore:__array_wrap__ must accept context and return_scalar arguments.*:DeprecationWarning\n    # pyvista <-> VTK dev\n    ignore:Call to deprecated method GetInputAsDataSet.*:DeprecationWarning\n    # nibabel <-> NumPy 2.0\n    ignore:__array__ implementation doesn't accept a copy.*:DeprecationWarning\n    # quantities via neo\n    ignore:The 'copy' argument in Quantity is deprecated.*:\n    # debugpy uses deprecated matplotlib API\n    ignore:The (non_)?interactive_bk attribute was deprecated.*:\n    # SWIG (via OpenMEEG)\n    ignore:.*builtin type swigvarlink has no.*:DeprecationWarning\n    # eeglabio\n    ignore:numpy\\.core\\.records is deprecated.*:DeprecationWarning\n    ignore:Starting field name with a underscore.*:\n    # joblib\n    ignore:process .* is multi-threaded, use of fork/exec.*:DeprecationWarning\n    # sklearn\n    ignore:Python binding for RankQuantileOptions.*:RuntimeWarning\n    \"\"\"  # noqa: E501\n    for warning_line in warning_lines.split(\"\\n\"):\n        warning_line = warning_line.strip()\n        if warning_line and not warning_line.startswith(\"#\"):\n            config.addinivalue_line(\"filterwarnings\", warning_line)", "metadata": {}}
{"_id": "mne_mne_conftest.py_check_verbose_code", "title": "check_verbose", "text": "def check_verbose(request):\n    \"\"\"Set to the default logging level to ensure it's tested properly.\"\"\"\n    starting_level = mne.utils.logger.level\n    yield\n    # ensures that no tests break the global state\n    try:\n        assert mne.utils.logger.level == starting_level\n    except AssertionError:\n        pytest.fail(\n            \".\".join([request.module.__name__, request.function.__name__])\n            + \" modifies logger.level\"\n        )", "metadata": {}}
{"_id": "mne_mne_conftest.py_close_all_code", "title": "close_all", "text": "def close_all():\n    \"\"\"Close all matplotlib plots, regardless of test status.\"\"\"\n    # This adds < 1 \u00b5S in local testing, and we have ~2500 tests, so ~2 ms max\n    import matplotlib.pyplot as plt\n\n    yield\n    plt.close(\"all\")", "metadata": {}}
{"_id": "mne_mne_conftest.py_add_mne_code", "title": "add_mne", "text": "def add_mne(doctest_namespace):\n    \"\"\"Add mne to the namespace.\"\"\"\n    doctest_namespace[\"mne\"] = mne", "metadata": {}}
{"_id": "mne_mne_conftest.py_verbose_debug_code", "title": "verbose_debug", "text": "def verbose_debug():\n    \"\"\"Run a test with debug verbosity.\"\"\"\n    with mne.utils.use_log_level(\"debug\"):\n        yield", "metadata": {}}
{"_id": "mne_mne_conftest.py_qt_config_code", "title": "qt_config", "text": "def qt_config():\n    \"\"\"Configure the Qt backend for viz tests.\"\"\"\n    os.environ[\"_MNE_BROWSER_NO_BLOCK\"] = \"true\"\n    if \"_MNE_BROWSER_BACK\" not in os.environ:\n        os.environ[\"_MNE_BROWSER_BACK\"] = \"true\"", "metadata": {}}
{"_id": "mne_mne_conftest.py_matplotlib_config_code", "title": "matplotlib_config", "text": "def matplotlib_config():\n    \"\"\"Configure matplotlib for viz tests.\"\"\"\n    import matplotlib\n    from matplotlib import cbook\n\n    # Allow for easy interactive debugging with a call like:\n    #\n    #     $ MNE_MPL_TESTING_BACKEND=Qt5Agg pytest mne/viz/tests/test_raw.py -k annotation -x --pdb  # noqa: E501\n    #\n    try:\n        want = os.environ[\"MNE_MPL_TESTING_BACKEND\"]\n    except KeyError:\n        want = \"agg\"  # don't pop up windows\n    with warnings.catch_warnings(record=True):  # ignore warning\n        warnings.filterwarnings(\"ignore\")\n        matplotlib.use(want, force=True)\n    import matplotlib.pyplot as plt\n\n    assert plt.get_backend() == want\n    # overwrite some params that can horribly slow down tests that\n    # users might have changed locally (but should not otherwise affect\n    # functionality)\n    plt.ioff()\n    plt.rcParams[\"figure.dpi\"] = 100\n    plt.rcParams[\"figure.raise_window\"] = False\n\n    # Make sure that we always reraise exceptions in handlers\n    orig = cbook.CallbackRegistry\n\n    class CallbackRegistryReraise(orig):\n        def __init__(self, exception_handler=None, signals=None):\n            super().__init__(exception_handler)\n\n    cbook.CallbackRegistry = CallbackRegistryReraise", "metadata": {}}
{"_id": "mne_mne_conftest.py_azure_windows_code", "title": "azure_windows", "text": "def azure_windows():\n    \"\"\"Determine if running on Azure Windows.\"\"\"\n    return (\n        os.getenv(\"AZURE_CI_WINDOWS\", \"false\").lower() == \"true\"\n        and platform.system() == \"Windows\"\n    )", "metadata": {}}
{"_id": "mne_mne_conftest.py_raw_orig_code", "title": "raw_orig", "text": "def raw_orig():\n    \"\"\"Get raw data without any change to it from mne.io.tests.data.\"\"\"\n    raw = read_raw_fif(fname_raw_io, preload=True)\n    return raw", "metadata": {}}
{"_id": "mne_mne_conftest.py_raw_code", "title": "raw", "text": "def raw():\n    \"\"\"\n    Get raw data and pick channels to reduce load for testing.\n\n    (from mne.io.tests.data)\n    \"\"\"\n    raw = read_raw_fif(fname_raw_io, preload=True)\n    # Throws a warning about a changed unit.\n    with pytest.warns(RuntimeWarning, match=\"unit\"):\n        raw.set_channel_types({raw.ch_names[0]: \"ias\"})\n    raw.pick(raw.ch_names[:9])\n    raw.info.normalize_proj()  # Fix projectors after subselection\n    return raw", "metadata": {}}
{"_id": "mne_mne_conftest.py_raw_ctf_code", "title": "raw_ctf", "text": "def raw_ctf():\n    \"\"\"Get ctf raw data from mne.io.tests.data.\"\"\"\n    raw_ctf = read_raw_ctf(fname_ctf_continuous, preload=True)\n    return raw_ctf", "metadata": {}}
{"_id": "mne_mne_conftest.py_raw_spectrum_code", "title": "raw_spectrum", "text": "def raw_spectrum(raw):\n    \"\"\"Get raw with power spectral density computed from mne.io.tests.data.\"\"\"\n    return raw.compute_psd()", "metadata": {}}
{"_id": "mne_mne_conftest.py_events_code", "title": "events", "text": "def events():\n    \"\"\"Get events from mne.io.tests.data.\"\"\"\n    return read_events(fname_event_io)", "metadata": {}}
{"_id": "mne_mne_conftest.py_epochs_code", "title": "epochs", "text": "def epochs():\n    \"\"\"\n    Get minimal, pre-loaded epochs data suitable for most tests.\n\n    (from mne.io.tests.data)\n    \"\"\"\n    return _get_epochs().load_data()", "metadata": {}}
{"_id": "mne_mne_conftest.py_epochs_unloaded_code", "title": "epochs_unloaded", "text": "def epochs_unloaded():\n    \"\"\"Get minimal, unloaded epochs data from mne.io.tests.data.\"\"\"\n    return _get_epochs()", "metadata": {}}
{"_id": "mne_mne_conftest.py_epochs_full_code", "title": "epochs_full", "text": "def epochs_full():\n    \"\"\"Get full, preloaded epochs from mne.io.tests.data.\"\"\"\n    return _get_epochs(None).load_data()", "metadata": {}}
{"_id": "mne_mne_conftest.py_epochs_spectrum_code", "title": "epochs_spectrum", "text": "def epochs_spectrum():\n    \"\"\"Get epochs with power spectral density computed from mne.io.tests.data.\"\"\"\n    return _get_epochs().load_data().compute_psd()", "metadata": {}}
{"_id": "mne_mne_conftest.py_epochs_tfr_code", "title": "epochs_tfr", "text": "def epochs_tfr():\n    \"\"\"Get an EpochsTFR computed from mne.io.tests.data.\"\"\"\n    epochs = _get_epochs().load_data()\n    return epochs.compute_tfr(method=\"morlet\", freqs=np.linspace(20, 40, num=5))", "metadata": {}}
{"_id": "mne_mne_conftest.py_average_tfr_code", "title": "average_tfr", "text": "def average_tfr(epochs_tfr):\n    \"\"\"Get an AverageTFR computed by averaging an EpochsTFR (this is small & fast).\"\"\"\n    return epochs_tfr.average()", "metadata": {}}
{"_id": "mne_mne_conftest.py_full_average_tfr_code", "title": "full_average_tfr", "text": "def full_average_tfr(full_evoked):\n    \"\"\"Get an AverageTFR computed from Evoked.\n\n    This is slower than the `average_tfr` fixture, but a few TFR.plot_* tests need it.\n    \"\"\"\n    return full_evoked.compute_tfr(method=\"morlet\", freqs=np.linspace(20, 40, num=5))", "metadata": {}}
{"_id": "mne_mne_conftest.py_raw_tfr_code", "title": "raw_tfr", "text": "def raw_tfr(raw):\n    \"\"\"Get a RawTFR computed from mne.io.tests.data.\"\"\"\n    return raw.compute_tfr(method=\"morlet\", freqs=np.linspace(20, 40, num=5))", "metadata": {}}
{"_id": "mne_mne_conftest.py_epochs_empty_code", "title": "epochs_empty", "text": "def epochs_empty():\n    \"\"\"Get empty epochs from mne.io.tests.data.\"\"\"\n    epochs = _get_epochs(meg=True, eeg=True).load_data()\n    with pytest.warns(RuntimeWarning, match=\"were dropped\"):\n        epochs.drop_bad(reject={\"mag\": 1e-20})\n\n    return epochs", "metadata": {}}
{"_id": "mne_mne_conftest.py_evoked_code", "title": "evoked", "text": "def evoked(_evoked):\n    \"\"\"Get truncated evoked data.\"\"\"\n    return _evoked.copy()", "metadata": {}}
{"_id": "mne_mne_conftest.py_full_evoked_code", "title": "full_evoked", "text": "def full_evoked(_full_evoked):\n    \"\"\"Get full-duration evoked data (needed for, e.g., testing TFR).\"\"\"\n    return _full_evoked.copy()", "metadata": {}}
{"_id": "mne_mne_conftest.py_noise_cov_code", "title": "noise_cov", "text": "def noise_cov():\n    \"\"\"Get a noise cov from the testing dataset.\"\"\"\n    return mne.read_cov(fname_cov)", "metadata": {}}
{"_id": "mne_mne_conftest.py_noise_cov_io_code", "title": "noise_cov_io", "text": "def noise_cov_io():\n    \"\"\"Get noise-covariance (from mne.io.tests.data).\"\"\"\n    return mne.read_cov(fname_cov_io)", "metadata": {}}
{"_id": "mne_mne_conftest.py_bias_params_free_code", "title": "bias_params_free", "text": "def bias_params_free(evoked, noise_cov):\n    \"\"\"Provide inputs for free bias functions.\"\"\"\n    fwd = mne.read_forward_solution(fname_fwd)\n    return _bias_params(evoked, noise_cov, fwd)", "metadata": {}}
{"_id": "mne_mne_conftest.py_bias_params_fixed_code", "title": "bias_params_fixed", "text": "def bias_params_fixed(evoked, noise_cov):\n    \"\"\"Provide inputs for fixed bias functions.\"\"\"\n    fwd = mne.read_forward_solution(fname_fwd)\n    mne.convert_forward_solution(fwd, force_fixed=True, surf_ori=True, copy=False)\n    return _bias_params(evoked, noise_cov, fwd)", "metadata": {}}
{"_id": "mne_mne_conftest.py_garbage_collect_code", "title": "garbage_collect", "text": "def garbage_collect():\n    \"\"\"Garbage collect on exit.\"\"\"\n    yield\n    gc.collect()", "metadata": {}}
{"_id": "mne_mne_conftest.py_mpl_backend_code", "title": "mpl_backend", "text": "def mpl_backend(garbage_collect):\n    \"\"\"Use for epochs/ica when not implemented with pyqtgraph yet.\"\"\"\n    with use_browser_backend(\"matplotlib\") as backend:\n        yield backend\n        backend._close_all()", "metadata": {}}
{"_id": "mne_mne_conftest.py_pg_backend_code", "title": "pg_backend", "text": "def pg_backend(request, garbage_collect):\n    \"\"\"Use for pyqtgraph-specific test-functions.\"\"\"\n    _check_pyqtgraph(request)\n    from mne_qt_browser._pg_figure import MNEQtBrowser\n\n    with use_browser_backend(\"qt\") as backend:\n        backend._close_all()\n        yield backend\n        backend._close_all()\n        # This shouldn't be necessary, but let's make sure nothing is stale\n        import mne_qt_browser\n\n        mne_qt_browser._browser_instances.clear()\n        if not _test_passed(request):\n            return\n        _assert_no_instances(MNEQtBrowser, f\"Closure of {request.node.name}\")", "metadata": {}}
{"_id": "mne_mne_conftest.py_browser_backend_code", "title": "browser_backend", "text": "def browser_backend(request, garbage_collect, monkeypatch):\n    \"\"\"Parametrizes the name of the browser backend.\"\"\"\n    backend_name = request.param\n    if backend_name == \"qt\":\n        _check_pyqtgraph(request)\n    with use_browser_backend(backend_name) as backend:\n        backend._close_all()\n        monkeypatch.setenv(\"MNE_BROWSE_RAW_SIZE\", \"10,10\")\n        yield backend\n        backend._close_all()\n        if backend_name == \"qt\":\n            # This shouldn't be necessary, but let's make sure nothing is stale\n            import mne_qt_browser\n\n            mne_qt_browser._browser_instances.clear()", "metadata": {}}
{"_id": "mne_mne_conftest.py_renderer_code", "title": "renderer", "text": "def renderer(request, options_3d, garbage_collect):\n    \"\"\"Yield the 3D backends.\"\"\"\n    with _use_backend(request.param, interactive=False) as renderer:\n        yield renderer", "metadata": {}}
{"_id": "mne_mne_conftest.py_renderer_pyvistaqt_code", "title": "renderer_pyvistaqt", "text": "def renderer_pyvistaqt(request, options_3d, garbage_collect):\n    \"\"\"Yield the PyVista backend.\"\"\"\n    with _use_backend(request.param, interactive=False) as renderer:\n        yield renderer", "metadata": {}}
{"_id": "mne_mne_conftest.py_renderer_notebook_code", "title": "renderer_notebook", "text": "def renderer_notebook(request, options_3d):\n    \"\"\"Yield the 3D notebook renderer.\"\"\"\n    with _use_backend(request.param, interactive=False) as renderer:\n        yield renderer", "metadata": {}}
{"_id": "mne_mne_conftest.py_renderer_interactive_pyvistaqt_code", "title": "renderer_interactive_pyvistaqt", "text": "def renderer_interactive_pyvistaqt(request, options_3d, qt_windows_closed):\n    \"\"\"Yield the interactive PyVista backend.\"\"\"\n    with _use_backend(request.param, interactive=True) as renderer:\n        yield renderer", "metadata": {}}
{"_id": "mne_mne_conftest.py_renderer_interactive_code", "title": "renderer_interactive", "text": "def renderer_interactive(request, options_3d):\n    \"\"\"Yield the interactive 3D backends.\"\"\"\n    with _use_backend(request.param, interactive=True) as renderer:\n        yield renderer", "metadata": {}}
{"_id": "mne_mne_conftest.py_pixel_ratio_code", "title": "pixel_ratio", "text": "def pixel_ratio():\n    \"\"\"Get the pixel ratio.\"\"\"\n    # _check_qt_version will init an app for us, so no need for us to do it\n    if not check_version(\"pyvista\", \"0.32\") or not _check_qt_version():\n        return 1.0\n    from qtpy.QtCore import Qt\n    from qtpy.QtWidgets import QMainWindow\n\n    app = _init_mne_qtapp()\n    app.processEvents()\n    window = QMainWindow()\n    window.setAttribute(Qt.WA_DeleteOnClose, True)\n    ratio = float(window.devicePixelRatio())\n    window.close()\n    return ratio", "metadata": {}}
{"_id": "mne_mne_conftest.py_subjects_dir_tmp_code", "title": "subjects_dir_tmp", "text": "def subjects_dir_tmp(tmp_path):\n    \"\"\"Copy MNE-testing-data subjects_dir to a temp dir for manipulation.\"\"\"\n    for key in (\"sample\", \"fsaverage\"):\n        shutil.copytree(op.join(subjects_dir, key), str(tmp_path / key))\n    return str(tmp_path)", "metadata": {}}
{"_id": "mne_mne_conftest.py_subjects_dir_tmp_few_code", "title": "subjects_dir_tmp_few", "text": "def subjects_dir_tmp_few(tmp_path):\n    \"\"\"Copy fewer files to a tmp_path.\"\"\"\n    subjects_path = tmp_path / \"subjects\"\n    os.mkdir(subjects_path)\n    # add fsaverage\n    create_default_subject(subjects_dir=subjects_path, fs_home=test_path, verbose=True)\n    # add sample (with few files)\n    sample_path = subjects_path / \"sample\"\n    os.makedirs(sample_path / \"bem\")\n    for dirname in (\"mri\", \"surf\"):\n        shutil.copytree(\n            test_path / \"subjects\" / \"sample\" / dirname, sample_path / dirname\n        )\n    return subjects_path", "metadata": {}}
{"_id": "mne_mne_conftest.py_fwd_volume_small_code", "title": "fwd_volume_small", "text": "def fwd_volume_small(_fwd_subvolume):\n    \"\"\"Provide a small volumetric source space.\"\"\"\n    return _fwd_subvolume.copy()", "metadata": {}}
{"_id": "mne_mne_conftest.py_all_src_types_inv_evoked_code", "title": "all_src_types_inv_evoked", "text": "def all_src_types_inv_evoked(_all_src_types_inv_evoked):\n    \"\"\"All source types of inverses, allowing for possible modification.\"\"\"\n    invs, evoked = _all_src_types_inv_evoked\n    invs = {key: val.copy() for key, val in invs.items()}\n    evoked = evoked.copy()\n    return invs, evoked", "metadata": {}}
{"_id": "mne_mne_conftest.py_mixed_fwd_cov_evoked_code", "title": "mixed_fwd_cov_evoked", "text": "def mixed_fwd_cov_evoked(_evoked_cov_sphere, _all_src_types_fwd):\n    \"\"\"Compute inverses for all source types.\"\"\"\n    evoked, cov, _ = _evoked_cov_sphere\n    return _all_src_types_fwd[\"mixed\"].copy(), cov.copy(), evoked.copy()", "metadata": {}}
{"_id": "mne_mne_conftest.py_src_volume_labels_code", "title": "src_volume_labels", "text": "def src_volume_labels():\n    \"\"\"Create a 7mm source space with labels.\"\"\"\n    pytest.importorskip(\"nibabel\")\n    volume_labels = mne.get_volume_labels_from_aseg(fname_aseg)\n    with (\n        _record_warnings(),\n        pytest.warns(RuntimeWarning, match=\"Found no usable.*t-vessel.*\"),\n    ):\n        src = mne.setup_volume_source_space(\n            \"sample\",\n            7.0,\n            mri=\"aseg.mgz\",\n            volume_label=volume_labels,\n            add_interpolator=False,\n            bem=fname_bem,\n            subjects_dir=subjects_dir,\n        )\n    lut, _ = mne.read_freesurfer_lut()\n    assert len(volume_labels) == 46\n    assert volume_labels[0] == \"Unknown\"\n    assert lut[\"Unknown\"] == 0  # it will be excluded during label gen\n    return src, tuple(volume_labels), lut", "metadata": {}}
{"_id": "mne_mne_conftest.py_download_is_error_code", "title": "download_is_error", "text": "def download_is_error(monkeypatch):\n    \"\"\"Prevent downloading by raising an error when it's attempted.\"\"\"\n    import pooch\n\n    monkeypatch.setattr(pooch, \"retrieve\", _fail)\n    yield", "metadata": {}}
{"_id": "mne_mne_conftest.py_fake_retrieve_code", "title": "fake_retrieve", "text": "def fake_retrieve(monkeypatch, download_is_error):\n    \"\"\"Monkeypatch pooch.retrieve to avoid downloading (just touch files).\"\"\"\n    import pooch\n\n    my_func = _FakeFetch()\n    monkeypatch.setattr(pooch, \"retrieve\", my_func)\n    monkeypatch.setattr(pooch, \"create\", my_func)\n    yield my_func", "metadata": {}}
{"_id": "mne_mne_conftest.py_options_3d_code", "title": "options_3d", "text": "def options_3d():\n    \"\"\"Disable advanced 3d rendering.\"\"\"\n    with mock.patch.dict(\n        os.environ,\n        {\n            \"MNE_3D_OPTION_ANTIALIAS\": \"false\",\n            \"MNE_3D_OPTION_DEPTH_PEELING\": \"false\",\n            \"MNE_3D_OPTION_SMOOTH_SHADING\": \"false\",\n        },\n    ):\n        yield", "metadata": {}}
{"_id": "mne_mne_conftest.py_protect_config_code", "title": "protect_config", "text": "def protect_config():\n    \"\"\"Protect ~/.mne.\"\"\"\n    temp = _TempDir()\n    with mock.patch.dict(os.environ, {\"_MNE_FAKE_HOME_DIR\": temp}):\n        yield", "metadata": {}}
{"_id": "mne_mne_conftest.py_brain_gc_code", "title": "brain_gc", "text": "def brain_gc(request):\n    \"\"\"Ensure that brain can be properly garbage collected.\"\"\"\n    keys = (\n        \"renderer_interactive\",\n        \"renderer_interactive_pyvistaqt\",\n        \"renderer\",\n        \"renderer_pyvistaqt\",\n        \"renderer_notebook\",\n    )\n    assert set(request.fixturenames) & set(keys) != set()\n    for key in keys:\n        if key in request.fixturenames:\n            is_pv = request.getfixturevalue(key)._get_3d_backend() == \"pyvistaqt\"\n            close_func = request.getfixturevalue(key).backend._close_all\n            break\n    if not is_pv:\n        yield\n        return\n    from mne.viz import Brain\n\n    ignore = set(id(o) for o in gc.get_objects())\n    yield\n    close_func()\n    if not _test_passed(request):\n        return\n    _assert_no_instances(Brain, \"after\")\n    # Check VTK\n    objs = gc.get_objects()\n    bad = list()\n    for o in objs:\n        try:\n            name = o.__class__.__name__\n        except Exception:  # old Python, probably\n            pass\n        else:\n            if name.startswith(\"vtk\") and id(o) not in ignore:\n                bad.append(name)\n        del o\n    del objs, ignore, Brain\n    assert len(bad) == 0, \"VTK objects linger:\\n\" + \"\\n\".join(bad)", "metadata": {}}
{"_id": "mne_mne_conftest.py_pytest_sessionfinish_code", "title": "pytest_sessionfinish", "text": "def pytest_sessionfinish(session, exitstatus):\n    \"\"\"Handle the end of the session.\"\"\"\n    n = session.config.option.durations\n    if n is None:\n        return\n    print(\"\\n\")\n    # get the number to print\n    files = defaultdict(lambda: 0.0)\n    for item in session.items:\n        if _phase_report_key not in item.stash:\n            continue\n        report = item.stash[_phase_report_key]\n        dur = sum(x.duration for x in report.values())\n        parts = Path(item.nodeid.split(\":\")[0]).parts\n        # split mne/tests/test_whatever.py into separate categories since these\n        # are essentially submodule-level tests. Keeping just [:3] works,\n        # except for mne/viz where we want level-4 granulatity\n        split_submodules = ((\"mne\", \"viz\"), (\"mne\", \"preprocessing\"))\n        parts = parts[: 4 if parts[:2] in split_submodules else 3]\n        if not parts[-1].endswith(\".py\"):\n            parts = parts + (\"\",)\n        file_key = \"/\".join(parts)\n        files[file_key] += dur\n    files = sorted(list(files.items()), key=lambda x: x[1])[::-1]\n    # print\n    _files[:] = files[:n]", "metadata": {}}
{"_id": "mne_mne_conftest.py_pytest_terminal_summary_code", "title": "pytest_terminal_summary", "text": "def pytest_terminal_summary(terminalreporter, exitstatus, config):\n    \"\"\"Print the module-level timings.\"\"\"\n    writer = terminalreporter\n    n = len(_files)\n    if n:\n        writer.line(\"\")  # newline\n        writer.write_sep(\"=\", f\"slowest {n} test module{_pl(n)}\")\n        names, timings = zip(*_files)\n        timings = [f\"{timing:0.2f}s total\" for timing in timings]\n        rjust = max(len(timing) for timing in timings)\n        timings = [timing.rjust(rjust) for timing in timings]\n        for name, timing in zip(names, timings):\n            writer.line(f\"{timing.ljust(15)}{name}\")", "metadata": {}}
{"_id": "mne_mne_conftest.py_pytest_report_header_code", "title": "pytest_report_header", "text": "def pytest_report_header(config, startdir=None):\n    \"\"\"Add information to the pytest run header.\"\"\"\n    return f\"MNE {mne.__version__} -- {Path(mne.__file__).parent}\"", "metadata": {}}
{"_id": "mne_mne_conftest.py_numba_conditional_code", "title": "numba_conditional", "text": "def numba_conditional(monkeypatch, request):\n    \"\"\"Test both code paths on machines that have Numba.\"\"\"\n    assert request.param in (\"Numba\", \"NumPy\")\n    if request.param == \"NumPy\" and has_numba:\n        monkeypatch.setattr(\n            cluster_level, \"_get_buddies\", cluster_level._get_buddies_fallback\n        )\n        monkeypatch.setattr(\n            cluster_level, \"_get_selves\", cluster_level._get_selves_fallback\n        )\n        monkeypatch.setattr(\n            cluster_level, \"_where_first\", cluster_level._where_first_fallback\n        )\n        monkeypatch.setattr(numerics, \"_arange_div\", numerics._arange_div_fallback)\n    if request.param == \"Numba\" and not has_numba:\n        pytest.skip(\"Numba not installed\")\n    yield request.param", "metadata": {}}
{"_id": "mne_mne_conftest.py_nbexec_code", "title": "nbexec", "text": "def nbexec(_nbclient):\n    \"\"\"Execute Python code in a notebook.\"\"\"\n    # Adapted/simplified from nbclient/client.py (BSD-3-Clause)\n    from nbclient.exceptions import CellExecutionError\n\n    _nbclient._cleanup_kernel()\n\n    def execute(code, reset=False):\n        _nbclient.reset_execution_trackers()\n        with _nbclient.setup_kernel():\n            assert _nbclient.kc is not None\n            cell = Bunch(cell_type=\"code\", metadata={}, source=dedent(code), outputs=[])\n            try:\n                _nbclient.execute_cell(cell, 0, execution_count=0)\n            except CellExecutionError:  # pragma: no cover\n                for kind in (\"stdout\", \"stderr\"):\n                    print(\n                        \"\\n\".join(\n                            o[\"text\"] for o in cell.outputs if o.get(\"name\", \"\") == kind\n                        ),\n                        file=getattr(sys, kind),\n                    )\n                raise\n            _nbclient.set_widgets_metadata()\n\n    yield execute", "metadata": {}}
{"_id": "mne_mne_conftest.py_pytest_runtest_call_code", "title": "pytest_runtest_call", "text": "def pytest_runtest_call(item):\n    \"\"\"Run notebook code written in Python.\"\"\"\n    if \"nbexec\" in getattr(item, \"fixturenames\", ()):\n        nbexec = item.funcargs[\"nbexec\"]\n        code = inspect.getsource(getattr(item.module, item.name.split(\"[\")[0]))\n        code = code.splitlines()\n        ci = 0\n        for ci, c in enumerate(code):\n            if c.startswith(\"    \"):  # actual content\n                break\n        code = \"\\n\".join(code[ci:])\n\n        def run(nbexec=nbexec, code=code):\n            nbexec(code)\n\n        item.runtest = run\n    return", "metadata": {}}
{"_id": "mne_mne_conftest.py_nirx_snirf_code", "title": "nirx_snirf", "text": "def nirx_snirf(request):\n    \"\"\"Return a (raw_nirx, raw_snirf) matched pair.\"\"\"\n    pytest.importorskip(\"h5py\")\n    skipper = request.param[2].marks[0].mark\n    if skipper.args[0]:  # will skip\n        pytest.skip(skipper.kwargs[\"reason\"])\n    return (\n        read_raw_nirx(request.param[0], preload=True),\n        read_raw_snirf(request.param[1], preload=True),\n    )", "metadata": {}}
{"_id": "mne_mne_conftest.py_qt_windows_closed_code", "title": "qt_windows_closed", "text": "def qt_windows_closed(request):\n    \"\"\"Ensure that no new Qt windows are open after a test.\"\"\"\n    _check_skip_backend(\"pyvistaqt\")\n    app = _init_mne_qtapp()\n\n    app.processEvents()\n    gc.collect()\n    n_before = len(app.topLevelWidgets())\n    marks = set(mark.name for mark in request.node.iter_markers())\n    yield\n    app.processEvents()\n    gc.collect()\n    if \"allow_unclosed\" in marks:\n        return\n    # Don't check when the test fails\n    if not _test_passed(request):\n        return\n    widgets = app.topLevelWidgets()\n    n_after = len(widgets)\n    assert n_before == n_after, widgets[-4:]", "metadata": {}}
{"_id": "mne_mne_conftest.py_pytest_runtest_makereport_code", "title": "pytest_runtest_makereport", "text": "def pytest_runtest_makereport(item, call):\n    \"\"\"Stash the status of each item and turn unexpected skips into errors.\"\"\"\n    outcome = yield\n    rep: pytest.TestReport = outcome.get_result()\n    item.stash.setdefault(_phase_report_key, {})[rep.when] = rep\n    _modify_report_skips(rep)\n    return rep", "metadata": {}}
{"_id": "mne_mne_conftest.py_pytest_make_collect_report_code", "title": "pytest_make_collect_report", "text": "def pytest_make_collect_report(collector: pytest.Collector):\n    \"\"\"Turn unexpected skips during collection (e.g., module-level) into errors.\"\"\"\n    outcome = yield\n    rep: pytest.CollectReport = outcome.get_result()\n    _modify_report_skips(rep)\n    return rep", "metadata": {}}
{"_id": "mne_mne_conftest.py_eyetrack_cal_code", "title": "eyetrack_cal", "text": "def eyetrack_cal():\n    \"\"\"Create a toy calibration instance.\"\"\"\n    screen_size = (0.4, 0.225)  # width, height in meters\n    screen_resolution = (1920, 1080)\n    screen_distance = 0.7  # meters\n    onset = 0\n    model = \"HV9\"\n    eye = \"R\"\n    avg_error = 0.5\n    max_error = 1.0\n    positions = np.zeros((9, 2))\n    offsets = np.zeros((9,))\n    gaze = np.zeros((9, 2))\n    cal = mne.preprocessing.eyetracking.Calibration(\n        screen_size=screen_size,\n        screen_distance=screen_distance,\n        screen_resolution=screen_resolution,\n        eye=eye,\n        model=model,\n        positions=positions,\n        offsets=offsets,\n        gaze=gaze,\n        onset=onset,\n        avg_error=avg_error,\n        max_error=max_error,\n    )\n    return cal", "metadata": {}}
{"_id": "mne_mne_conftest.py_eyetrack_raw_code", "title": "eyetrack_raw", "text": "def eyetrack_raw():\n    \"\"\"Create a toy raw instance with eyetracking channels.\"\"\"\n    # simulate a steady fixation at the center pixel of a 1920x1080 resolution screen\n    shape = (1, 100)  # x or y, time\n    data = np.vstack([np.full(shape, 960), np.full(shape, 540), np.full(shape, 0)])\n\n    info = info = mne.create_info(\n        ch_names=[\"xpos\", \"ypos\", \"pupil\"], sfreq=100, ch_types=\"eyegaze\"\n    )\n    more_info = dict(\n        xpos=(\"eyegaze\", \"px\", \"right\", \"x\"),\n        ypos=(\"eyegaze\", \"px\", \"right\", \"y\"),\n        pupil=(\"pupil\", \"au\", \"right\"),\n    )\n    raw = mne.io.RawArray(data, info)\n    raw = mne.preprocessing.eyetracking.set_channel_types_eyetrack(raw, more_info)\n    return raw", "metadata": {}}
{"_id": "mne_mne_baseline.py_rescale_code", "title": "rescale", "text": "def rescale(data, times, baseline, mode=\"mean\", copy=True, picks=None, verbose=None):\n    \"\"\"Rescale (baseline correct) data.\n\n    Parameters\n    ----------\n    data : array\n        It can be of any shape. The only constraint is that the last\n        dimension should be time.\n    times : 1D array\n        Time instants is seconds.\n    %(baseline_rescale)s\n    mode : 'mean' | 'ratio' | 'logratio' | 'percent' | 'zscore' | 'zlogratio'\n        Perform baseline correction by\n\n        - subtracting the mean of baseline values ('mean')\n        - dividing by the mean of baseline values ('ratio')\n        - dividing by the mean of baseline values and taking the log\n          ('logratio')\n        - subtracting the mean of baseline values followed by dividing by\n          the mean of baseline values ('percent')\n        - subtracting the mean of baseline values and dividing by the\n          standard deviation of baseline values ('zscore')\n        - dividing by the mean of baseline values, taking the log, and\n          dividing by the standard deviation of log baseline values\n          ('zlogratio')\n\n    copy : bool\n        Whether to return a new instance or modify in place.\n    picks : list of int | None\n        Data to process along the axis=-2 (None, default, processes all).\n    %(verbose)s\n\n    Returns\n    -------\n    data_scaled: array\n        Array of same shape as data after rescaling.\n    \"\"\"\n    if copy:\n        data = data.copy()\n    if verbose is not False:\n        msg = _log_rescale(baseline, mode)\n        logger.info(msg)\n    if baseline is None or data.shape[-1] == 0:\n        return data\n\n    bmin, bmax = baseline\n    if bmin is None:\n        imin = 0\n    else:\n        imin = np.where(times >= bmin)[0]\n        if len(imin) == 0:\n            raise ValueError(\n                f\"bmin is too large ({bmin}), it exceeds the largest time value\"\n            )\n        imin = int(imin[0])\n    if bmax is None:\n        imax = len(times)\n    else:\n        imax = np.where(times <= bmax)[0]\n        if len(imax) == 0:\n            raise ValueError(\n                f\"bmax is too small ({bmax}), it is smaller than the smallest time \"\n                \"value\"\n            )\n        imax = int(imax[-1]) + 1\n    if imin >= imax:\n        raise ValueError(\n            f\"Bad rescaling slice ({imin}:{imax}) from time values {bmin}, {bmax}\"\n        )\n\n    # technically this is inefficient when `picks` is given, but assuming\n    # that we generally pick most channels for rescaling, it's not so bad\n    mean = np.mean(data[..., imin:imax], axis=-1, keepdims=True)\n\n    if mode == \"mean\":\n\n        def fun(d, m):\n            d -= m\n\n    elif mode == \"ratio\":\n\n        def fun(d, m):\n            d /= m\n\n    elif mode == \"logratio\":\n\n        def fun(d, m):\n            d /= m\n            np.log10(d, out=d)\n\n    elif mode == \"percent\":\n\n        def fun(d, m):\n            d -= m\n            d /= m\n\n    elif mode == \"zscore\":\n\n        def fun(d, m):\n            d -= m\n            d /= np.std(d[..., imin:imax], axis=-1, keepdims=True)\n\n    elif mode == \"zlogratio\":\n\n        def fun(d, m):\n            d /= m\n            np.log10(d, out=d)\n            d /= np.std(d[..., imin:imax], axis=-1, keepdims=True)\n\n    if picks is None:\n        fun(data, mean)\n    else:\n        for pi in picks:\n            fun(data[..., pi, :], mean[..., pi, :])\n    return data", "metadata": {}}
{"_id": "mne_mne_surface.py_get_head_surf_code", "title": "get_head_surf", "text": "def get_head_surf(\n    subject, source=(\"bem\", \"head\"), subjects_dir=None, on_defects=\"raise\", verbose=None\n):\n    \"\"\"Load the subject head surface.\n\n    Parameters\n    ----------\n    subject : str\n        Subject name.\n    source : str | list of str\n        Type to load. Common choices would be ``'bem'`` or ``'head'``. We first\n        try loading ``'$SUBJECTS_DIR/$SUBJECT/bem/$SUBJECT-$SOURCE.fif'``, and\n        then look for ``'$SUBJECT*$SOURCE.fif'`` in the same directory by going\n        through all files matching the pattern. The head surface will be read\n        from the first file containing a head surface. Can also be a list\n        to try multiple strings.\n    subjects_dir : path-like | None\n        Path to the ``SUBJECTS_DIR``. If None, the path is obtained by using\n        the environment variable ``SUBJECTS_DIR``.\n    %(on_defects)s\n\n        .. versionadded:: 1.0\n    %(verbose)s\n\n    Returns\n    -------\n    surf : dict\n        The head surface.\n    \"\"\"\n    return _get_head_surface(\n        subject=subject, source=source, subjects_dir=subjects_dir, on_defects=on_defects\n    )", "metadata": {}}
{"_id": "mne_mne_surface.py_get_meg_helmet_surf_code", "title": "get_meg_helmet_surf", "text": "def get_meg_helmet_surf(info, trans=None, *, upsampling=1, verbose=None):\n    \"\"\"Load the MEG helmet associated with the MEG sensors.\n\n    Parameters\n    ----------\n    %(info_not_none)s\n    trans : dict\n        The head<->MRI transformation, usually obtained using\n        read_trans(). Can be None, in which case the surface will\n        be in head coordinates instead of MRI coordinates.\n    %(helmet_upsampling)s\n    %(verbose)s\n\n    Returns\n    -------\n    surf : dict\n        The MEG helmet as a surface.\n\n    Notes\n    -----\n    A built-in helmet is loaded if possible. If not, a helmet surface\n    will be approximated based on the sensor locations.\n    \"\"\"\n    from .bem import _fit_sphere, read_bem_surfaces\n    from .channels.channels import _get_meg_system\n\n    _validate_type(upsampling, \"int\", \"upsampling\")\n\n    system, have_helmet = _get_meg_system(info)\n    incomplete = False\n    if have_helmet:\n        logger.info(f\"Getting helmet for system {system}\")\n        fname = _helmet_path / f\"{system}.fif.gz\"\n        surf = read_bem_surfaces(\n            fname, False, FIFF.FIFFV_MNE_SURF_MEG_HELMET, verbose=False\n        )\n        surf = _scale_helmet_to_sensors(system, surf, info)\n    else:\n        rr = np.array(\n            [\n                info[\"chs\"][pick][\"loc\"][:3]\n                for pick in pick_types(info, meg=True, ref_meg=False, exclude=())\n            ]\n        )\n        logger.info(\n            \"Getting helmet for system %s (derived from %d MEG channel locations)\",\n            system,\n            len(rr),\n        )\n        hull = ConvexHull(rr)\n        rr = rr[np.unique(hull.simplices)]\n        R, center = _fit_sphere(rr)\n        sph = _cart_to_sph(rr - center)[:, 1:]\n        # add a point at the front of the helmet (where the face should be):\n        # 90 deg az and maximal el (down from Z/up axis)\n        front_sph = [[np.pi / 2.0, sph[:, 1].max()]]\n        sph = np.concatenate((sph, front_sph))\n        xy = _pol_to_cart(sph[:, ::-1])\n        tris = Delaunay(xy).simplices\n        # remove the frontal point we added from the simplices\n        tris = tris[(tris != len(sph) - 1).all(-1)]\n        tris = _reorder_ccw(rr, tris)\n        surf = dict(rr=rr, tris=tris)\n        incomplete = True\n    if upsampling > 1:\n        # Use VTK (could also use Butterfly but Loop is smoother)\n        pv = _soft_import(\"pyvista\", \"upsample a mesh\")\n        factor = 4 ** (upsampling - 1)\n        rr, tris = surf[\"rr\"], surf[\"tris\"]\n        logger.info(\n            f\"Upsampling from {len(rr)} to {len(rr) * factor} vertices ({upsampling=})\"\n        )\n        tris = np.c_[np.full(len(tris), 3), tris]\n        mesh = pv.PolyData(rr, tris)\n        mesh = mesh.subdivide(upsampling - 1, subfilter=\"linear\")\n        rr, tris = mesh.points, mesh.faces.reshape(-1, 4)[:, 1:]\n        tris = _reorder_ccw(rr, tris)\n        surf = dict(rr=rr, tris=tris)\n        incomplete = True\n    if incomplete:\n        complete_surface_info(surf, copy=False, verbose=False)\n\n    # Ignore what the file says, it's in device coords and we want MRI coords\n    surf[\"coord_frame\"] = FIFF.FIFFV_COORD_DEVICE\n    dev_head_t = info[\"dev_head_t\"]\n    if dev_head_t is None:\n        dev_head_t = Transform(\"meg\", \"head\")\n    transform_surface_to(surf, \"head\", dev_head_t)\n    if trans is not None:\n        transform_surface_to(surf, \"mri\", trans)\n    return surf", "metadata": {}}
{"_id": "mne_mne_surface.py_fast_cross_3d_code", "title": "fast_cross_3d", "text": "def fast_cross_3d(x, y):\n    \"\"\"Compute cross product between list of 3D vectors.\n\n    Much faster than np.cross() when the number of cross products\n    becomes large (>= 500). This is because np.cross() methods become\n    less memory efficient at this stage.\n\n    Parameters\n    ----------\n    x : array\n        Input array 1, shape (..., 3).\n    y : array\n        Input array 2, shape (..., 3).\n\n    Returns\n    -------\n    z : array, shape (..., 3)\n        Cross product of x and y along the last dimension.\n\n    Notes\n    -----\n    x and y must broadcast against each other.\n    \"\"\"\n    assert x.ndim >= 1\n    assert y.ndim >= 1\n    assert x.shape[-1] == 3\n    assert y.shape[-1] == 3\n    if max(x.size, y.size) >= 500:\n        out = np.empty(np.broadcast(x, y).shape)\n        _jit_cross(out, x, y)\n        return out\n    else:\n        return np.cross(x, y)", "metadata": {}}
{"_id": "mne_mne_surface.py_complete_surface_info_code", "title": "complete_surface_info", "text": "def complete_surface_info(\n    surf, do_neighbor_vert=False, copy=True, do_neighbor_tri=True, *, verbose=None\n):\n    \"\"\"Complete surface information.\n\n    Parameters\n    ----------\n    surf : dict\n        The surface.\n    do_neighbor_vert : bool\n        If True (default False), add neighbor vertex information.\n    copy : bool\n        If True (default), make a copy. If False, operate in-place.\n    do_neighbor_tri : bool\n        If True (default), compute triangle neighbors.\n    %(verbose)s\n\n    Returns\n    -------\n    surf : dict\n        The transformed surface.\n    \"\"\"\n    if copy:\n        surf = deepcopy(surf)\n    # based on mne_source_space_add_geometry_info() in mne_add_geometry_info.c\n\n    #   Main triangulation [mne_add_triangle_data()]\n    surf[\"ntri\"] = surf.get(\"ntri\", len(surf[\"tris\"]))\n    surf[\"np\"] = surf.get(\"np\", len(surf[\"rr\"]))\n    surf[\"tri_area\"] = np.zeros(surf[\"ntri\"])\n    r1 = surf[\"rr\"][surf[\"tris\"][:, 0], :]\n    r2 = surf[\"rr\"][surf[\"tris\"][:, 1], :]\n    r3 = surf[\"rr\"][surf[\"tris\"][:, 2], :]\n    surf[\"tri_cent\"] = (r1 + r2 + r3) / 3.0\n    surf[\"tri_nn\"] = fast_cross_3d((r2 - r1), (r3 - r1))\n\n    #   Triangle normals and areas\n    surf[\"tri_area\"] = _normalize_vectors(surf[\"tri_nn\"]) / 2.0\n    zidx = np.where(surf[\"tri_area\"] == 0)[0]\n    if len(zidx) > 0:\n        logger.info(f\"    Warning: zero size triangles: {zidx}\")\n\n    #    Find neighboring triangles, accumulate vertex normals, normalize\n    logger.info(\"    Triangle neighbors and vertex normals...\")\n    surf[\"nn\"] = _accumulate_normals(\n        surf[\"tris\"].astype(int), surf[\"tri_nn\"], surf[\"np\"]\n    )\n    _normalize_vectors(surf[\"nn\"])\n\n    #   Check for topological defects\n    if do_neighbor_tri:\n        surf[\"neighbor_tri\"] = _triangle_neighbors(surf[\"tris\"], surf[\"np\"])\n        zero, fewer = list(), list()\n        for ni, n in enumerate(surf[\"neighbor_tri\"]):\n            if len(n) < 3:\n                if len(n) == 0:\n                    zero.append(ni)\n                else:\n                    fewer.append(ni)\n                    surf[\"neighbor_tri\"][ni] = np.array([], int)\n        if len(zero) > 0:\n            logger.info(\n                \"    Vertices do not have any neighboring triangles: \"\n                f\"[{', '.join(str(z) for z in zero)}]\"\n            )\n        if len(fewer) > 0:\n            fewer = \", \".join(str(f) for f in fewer)\n            logger.info(\n                \"    Vertices have fewer than three neighboring triangles, removing \"\n                f\"neighbors: [{fewer}]\"\n            )\n\n    #   Determine the neighboring vertices and fix errors\n    if do_neighbor_vert is True:\n        logger.info(\"    Vertex neighbors...\")\n        surf[\"neighbor_vert\"] = [\n            _get_surf_neighbors(surf, k) for k in range(surf[\"np\"])\n        ]\n\n    return surf", "metadata": {}}
{"_id": "mne_mne_surface.py_read_curvature_code", "title": "read_curvature", "text": "def read_curvature(filepath, binary=True):\n    \"\"\"Load in curvature values from the ?h.curv file.\n\n    Parameters\n    ----------\n    filepath : path-like\n        Input path to the ``.curv`` file.\n    binary : bool\n        Specify if the output array is to hold binary values. Defaults to True.\n\n    Returns\n    -------\n    curv : array of shape (n_vertices,)\n        The curvature values loaded from the user given file.\n    \"\"\"\n    with open(filepath, \"rb\") as fobj:\n        magic = _fread3(fobj)\n        if magic == 16777215:\n            vnum = np.fromfile(fobj, \">i4\", 3)[0]\n            curv = np.fromfile(fobj, \">f4\", vnum)\n        else:\n            vnum = magic\n            _fread3(fobj)\n            curv = np.fromfile(fobj, \">i2\", vnum) / 100\n    if binary:\n        return 1 - np.array(curv != 0, np.int64)\n    else:\n        return curv", "metadata": {}}
{"_id": "mne_mne_surface.py_read_surface_code", "title": "read_surface", "text": "def read_surface(\n    fname, read_metadata=False, return_dict=False, file_format=\"auto\", verbose=None\n):\n    \"\"\"Load a Freesurfer surface mesh in triangular format.\n\n    Parameters\n    ----------\n    fname : path-like\n        The name of the file containing the surface.\n    read_metadata : bool\n        Read metadata as key-value pairs. Only works when reading a FreeSurfer\n        surface file. For .obj files this dictionary will be empty.\n\n        Valid keys:\n\n            * 'head' : array of int\n            * 'valid' : str\n            * 'filename' : str\n            * 'volume' : array of int, shape (3,)\n            * 'voxelsize' : array of float, shape (3,)\n            * 'xras' : array of float, shape (3,)\n            * 'yras' : array of float, shape (3,)\n            * 'zras' : array of float, shape (3,)\n            * 'cras' : array of float, shape (3,)\n\n        .. versionadded:: 0.13.0\n\n    return_dict : bool\n        If True, a dictionary with surface parameters is returned.\n    file_format : 'auto' | 'freesurfer' | 'obj'\n        File format to use. Can be 'freesurfer' to read a FreeSurfer surface\n        file, or 'obj' to read a Wavefront .obj file (common format for\n        importing in other software), or 'auto' to attempt to infer from the\n        file name. Defaults to 'auto'.\n\n        .. versionadded:: 0.21.0\n    %(verbose)s\n\n    Returns\n    -------\n    rr : array, shape=(n_vertices, 3)\n        Coordinate points.\n    tris : int array, shape=(n_faces, 3)\n        Triangulation (each line contains indices for three points which\n        together form a face).\n    volume_info : dict-like\n        If read_metadata is true, key-value pairs found in the geometry file.\n    surf : dict\n        The surface parameters. Only returned if ``return_dict`` is True.\n\n    See Also\n    --------\n    write_surface\n    read_tri\n    \"\"\"\n    fname = _check_fname(fname, \"read\", True)\n    _check_option(\"file_format\", file_format, [\"auto\", \"freesurfer\", \"obj\"])\n\n    if file_format == \"auto\":\n        if fname.suffix.lower() == \".obj\":\n            file_format = \"obj\"\n        else:\n            file_format = \"freesurfer\"\n\n    if file_format == \"freesurfer\":\n        _import_nibabel(\"read surface geometry\")\n        from nibabel.freesurfer import read_geometry\n\n        ret = read_geometry(fname, read_metadata=read_metadata)\n    elif file_format == \"obj\":\n        ret = _read_wavefront_obj(fname)\n        if read_metadata:\n            ret += (dict(),)\n\n    if return_dict:\n        ret += (_rr_tris_dict(ret[0], ret[1]),)\n    return ret", "metadata": {}}
{"_id": "mne_mne_surface.py_write_surface_code", "title": "write_surface", "text": "def write_surface(\n    fname,\n    coords,\n    faces,\n    create_stamp=\"\",\n    volume_info=None,\n    file_format=\"auto\",\n    overwrite=False,\n    *,\n    verbose=None,\n):\n    \"\"\"Write a triangular Freesurfer surface mesh.\n\n    Accepts the same data format as is returned by read_surface().\n\n    Parameters\n    ----------\n    fname : path-like\n        File to write.\n    coords : array, shape=(n_vertices, 3)\n        Coordinate points.\n    faces : int array, shape=(n_faces, 3)\n        Triangulation (each line contains indices for three points which\n        together form a face).\n    create_stamp : str\n        Comment that is written to the beginning of the file. Can not contain\n        line breaks.\n    volume_info : dict-like or None\n        Key-value pairs to encode at the end of the file.\n        Valid keys:\n\n            * 'head' : array of int\n            * 'valid' : str\n            * 'filename' : str\n            * 'volume' : array of int, shape (3,)\n            * 'voxelsize' : array of float, shape (3,)\n            * 'xras' : array of float, shape (3,)\n            * 'yras' : array of float, shape (3,)\n            * 'zras' : array of float, shape (3,)\n            * 'cras' : array of float, shape (3,)\n\n        .. versionadded:: 0.13.0\n    file_format : 'auto' | 'freesurfer' | 'obj'\n        File format to use. Can be 'freesurfer' to write a FreeSurfer surface\n        file, or 'obj' to write a Wavefront .obj file (common format for\n        importing in other software), or 'auto' to attempt to infer from the\n        file name. Defaults to 'auto'.\n\n        .. versionadded:: 0.21.0\n    %(overwrite)s\n    %(verbose)s\n\n    See Also\n    --------\n    read_surface\n    read_tri\n    \"\"\"\n    fname = _check_fname(fname, overwrite=overwrite)\n    _check_option(\"file_format\", file_format, [\"auto\", \"freesurfer\", \"obj\"])\n\n    if file_format == \"auto\":\n        if fname.suffix.lower() == \".obj\":\n            file_format = \"obj\"\n        else:\n            file_format = \"freesurfer\"\n\n    if file_format == \"freesurfer\":\n        _import_nibabel(\"write surface geometry\")\n        from nibabel.freesurfer import write_geometry\n\n        write_geometry(\n            fname, coords, faces, create_stamp=create_stamp, volume_info=volume_info\n        )\n    else:\n        assert file_format == \"obj\"\n        with open(fname, \"w\") as fid:\n            for line in create_stamp.splitlines():\n                fid.write(f\"# {line}\\n\")\n            for v in coords:\n                fid.write(f\"v {v[0]} {v[1]} {v[2]}\\n\")\n            for f in faces:\n                fid.write(f\"f {f[0] + 1} {f[1] + 1} {f[2] + 1}\\n\")", "metadata": {}}
{"_id": "mne_mne_surface.py_decimate_surface_code", "title": "decimate_surface", "text": "def decimate_surface(points, triangles, n_triangles, method=\"quadric\", *, verbose=None):\n    \"\"\"Decimate surface data.\n\n    Parameters\n    ----------\n    points : ndarray\n        The surface to be decimated, a 3 x number of points array.\n    triangles : ndarray\n        The surface to be decimated, a 3 x number of triangles array.\n    n_triangles : int\n        The desired number of triangles.\n    method : str\n        Can be \"quadric\" or \"sphere\". \"sphere\" will inflate the surface to a\n        sphere using Freesurfer and downsample to an icosahedral or\n        octahedral mesh.\n\n        .. versionadded:: 0.20\n    %(verbose)s\n\n    Returns\n    -------\n    points : ndarray\n        The decimated points.\n    triangles : ndarray\n        The decimated triangles.\n\n    Notes\n    -----\n    **\"quadric\" mode**\n\n    This requires VTK. If an odd target number was requested,\n    the ``'decimation'`` algorithm used results in the\n    next even number of triangles. For example a reduction request\n    to 30001 triangles may result in 30000 triangles.\n\n    **\"sphere\" mode**\n\n    This requires Freesurfer to be installed and available in the\n    environment. The destination number of triangles must be one of\n    ``[20, 80, 320, 1280, 5120, 20480]`` for ico (0-5) downsampling or one of\n    ``[8, 32, 128, 512, 2048, 8192, 32768]`` for oct (1-7) downsampling.\n\n    This mode is slower, but could be more suitable for decimating meshes for\n    BEM creation (recommended ``n_triangles=5120``) due to better topological\n    property preservation.\n    \"\"\"\n    n_triangles = _ensure_int(n_triangles)\n    method_map = dict(quadric=_decimate_surface_vtk, sphere=_decimate_surface_sphere)\n    _check_option(\"method\", method, sorted(method_map))\n    if n_triangles > len(triangles):\n        raise ValueError(\n            f\"Requested n_triangles ({n_triangles}) exceeds number of \"\n            f\"original triangles ({len(triangles)})\"\n        )\n    return method_map[method](points, triangles, n_triangles)", "metadata": {}}
{"_id": "mne_mne_surface.py_mesh_edges_code", "title": "mesh_edges", "text": "def mesh_edges(tris):\n    \"\"\"Return sparse matrix with edges as an adjacency matrix.\n\n    Parameters\n    ----------\n    tris : array of shape [n_triangles x 3]\n        The triangles.\n\n    Returns\n    -------\n    edges : scipy.sparse.spmatrix\n        The adjacency matrix.\n    \"\"\"\n    tris = _hashable_ndarray(tris)\n    return _mesh_edges(tris=tris)", "metadata": {}}
{"_id": "mne_mne_surface.py_mesh_dist_code", "title": "mesh_dist", "text": "def mesh_dist(tris, vert):\n    \"\"\"Compute adjacency matrix weighted by distances.\n\n    It generates an adjacency matrix where the entries are the distances\n    between neighboring vertices.\n\n    Parameters\n    ----------\n    tris : array (n_tris x 3)\n        Mesh triangulation.\n    vert : array (n_vert x 3)\n        Vertex locations.\n\n    Returns\n    -------\n    dist_matrix : scipy.sparse.csr_array\n        Sparse matrix with distances between adjacent vertices.\n    \"\"\"\n    edges = mesh_edges(tris).tocoo()\n\n    # Euclidean distances between neighboring vertices\n    dist = np.linalg.norm(vert[edges.row, :] - vert[edges.col, :], axis=1)\n    dist_matrix = csr_array((dist, (edges.row, edges.col)), shape=edges.shape)\n    return dist_matrix", "metadata": {}}
{"_id": "mne_mne_surface.py_read_tri_code", "title": "read_tri", "text": "def read_tri(fname_in, swap=False, verbose=None):\n    \"\"\"Read triangle definitions from an ascii file.\n\n    Parameters\n    ----------\n    fname_in : path-like\n        Path to surface ASCII file (ending with ``'.tri'``).\n    swap : bool\n        Assume the ASCII file vertex ordering is clockwise instead of\n        counterclockwise.\n    %(verbose)s\n\n    Returns\n    -------\n    rr : array, shape=(n_vertices, 3)\n        Coordinate points.\n    tris : int array, shape=(n_faces, 3)\n        Triangulation (each line contains indices for three points which\n        together form a face).\n\n    See Also\n    --------\n    read_surface\n    write_surface\n\n    Notes\n    -----\n    .. versionadded:: 0.13.0\n    \"\"\"\n    with open(fname_in) as fid:\n        lines = fid.readlines()\n    n_nodes = int(lines[0])\n    n_tris = int(lines[n_nodes + 1])\n    n_items = len(lines[1].split())\n    if n_items in [3, 6, 14, 17]:\n        inds = range(3)\n    elif n_items in [4, 7]:\n        inds = range(1, 4)\n    else:\n        raise OSError(\"Unrecognized format of data.\")\n    rr = np.array(\n        [\n            np.array([float(v) for v in line.split()])[inds]\n            for line in lines[1 : n_nodes + 1]\n        ]\n    )\n    tris = np.array(\n        [\n            np.array([int(v) for v in line.split()])[inds]\n            for line in lines[n_nodes + 2 : n_nodes + 2 + n_tris]\n        ]\n    )\n    if swap:\n        tris[:, [2, 1]] = tris[:, [1, 2]]\n    tris -= 1\n    logger.info(\n        f\"Loaded surface from {fname_in} with {n_nodes} nodes and {n_tris} triangles.\"\n    )\n    if n_items in [3, 4]:\n        logger.info(\"Node normals were not included in the source file.\")\n    else:\n        warn(\"Node normals were not read.\")\n    return (rr, tris)", "metadata": {}}
{"_id": "mne_mne_surface.py_dig_mri_distances_code", "title": "dig_mri_distances", "text": "def dig_mri_distances(\n    info,\n    trans,\n    subject,\n    subjects_dir=None,\n    dig_kinds=\"auto\",\n    exclude_frontal=False,\n    on_defects=\"raise\",\n    verbose=None,\n):\n    \"\"\"Compute distances between head shape points and the scalp surface.\n\n    This function is useful to check that coregistration is correct.\n    Unless outliers are present in the head shape points,\n    one can assume an average distance around 2-3 mm.\n\n    Parameters\n    ----------\n    %(info_not_none)s Must contain the head shape points in ``info['dig']``.\n    trans : str | instance of Transform\n        The head<->MRI transform. If str is passed it is the\n        path to file on disk.\n    subject : str\n        The name of the subject.\n    subjects_dir : str | None\n        Directory containing subjects data. If None use\n        the Freesurfer SUBJECTS_DIR environment variable.\n    %(dig_kinds)s\n    %(exclude_frontal)s\n        Default is False.\n    %(on_defects)s\n\n        .. versionadded:: 1.0\n    %(verbose)s\n\n    Returns\n    -------\n    dists : array, shape (n_points,)\n        The distances.\n\n    See Also\n    --------\n    mne.bem.get_fitting_dig\n\n    Notes\n    -----\n    .. versionadded:: 0.19\n    \"\"\"\n    from .bem import get_fitting_dig\n\n    pts = get_head_surf(\n        subject,\n        (\"head-dense\", \"head\", \"bem\"),\n        subjects_dir=subjects_dir,\n        on_defects=on_defects,\n    )[\"rr\"]\n    trans = _get_trans(trans, fro=\"mri\", to=\"head\")[0]\n    pts = apply_trans(trans, pts)\n    info_dig = get_fitting_dig(info, dig_kinds, exclude_frontal=exclude_frontal)\n    dists = _compute_nearest(pts, info_dig, return_dists=True)[1]\n    return dists", "metadata": {}}
{"_id": "mne_mne_surface.py_get_montage_volume_labels_code", "title": "get_montage_volume_labels", "text": "def get_montage_volume_labels(montage, subject, subjects_dir=None, aseg=\"auto\", dist=2):\n    \"\"\"Get regions of interest near channels from a Freesurfer parcellation.\n\n    .. note:: This is applicable for channels inside the brain\n              (intracranial electrodes).\n\n    Parameters\n    ----------\n    %(montage)s\n    %(subject)s\n    %(subjects_dir)s\n    %(aseg)s\n    dist : float\n        The distance in mm to use for identifying regions of interest.\n\n    Returns\n    -------\n    labels : dict\n        The regions of interest labels within ``dist`` of each channel.\n    colors : dict\n        The Freesurfer lookup table colors for the labels.\n    \"\"\"\n    from ._freesurfer import _get_aseg, read_freesurfer_lut\n    from .channels import DigMontage\n\n    _validate_type(montage, DigMontage, \"montage\")\n    _validate_type(dist, (int, float), \"dist\")\n\n    if dist < 0 or dist > 10:\n        raise ValueError(\"`dist` must be between 0 and 10\")\n\n    aseg, aseg_data = _get_aseg(aseg, subject, subjects_dir)\n\n    # read freesurfer lookup table\n    lut, fs_colors = read_freesurfer_lut()\n    label_lut = {v: k for k, v in lut.items()}\n\n    # assert that all the values in the aseg are in the labels\n    assert all([idx in label_lut for idx in np.unique(aseg_data)])\n\n    # get transform to surface RAS for distance units instead of voxels\n    vox2ras_tkr = aseg.header.get_vox2ras_tkr()\n\n    ch_dict = montage.get_positions()\n    if ch_dict[\"coord_frame\"] != \"mri\":\n        raise RuntimeError(\n            \"Coordinate frame not supported, expected \"\n            '\"mri\", got ' + str(ch_dict[\"coord_frame\"])\n        )\n    ch_coords = np.array(list(ch_dict[\"ch_pos\"].values()))\n\n    # convert to freesurfer voxel space\n    ch_coords = apply_trans(\n        np.linalg.inv(aseg.header.get_vox2ras_tkr()), ch_coords * 1000\n    )\n    labels = OrderedDict()\n    for ch_name, ch_coord in zip(montage.ch_names, ch_coords):\n        if np.isnan(ch_coord).any():\n            labels[ch_name] = list()\n        else:\n            voxels = _voxel_neighbors(\n                ch_coord,\n                aseg_data,\n                dist=dist,\n                vox2ras_tkr=vox2ras_tkr,\n                voxels_max=_VOXELS_MAX,\n            )\n            label_idxs = set([aseg_data[tuple(voxel)].astype(int) for voxel in voxels])\n            labels[ch_name] = [label_lut[idx] for idx in label_idxs]\n\n    all_labels = set([label for val in labels.values() for label in val])\n    colors = {label: tuple(fs_colors[label][:3] / 255) + (1.0,) for label in all_labels}\n    return labels, colors", "metadata": {}}
{"_id": "mne_mne_transforms.py_apply_trans_code", "title": "apply_trans", "text": "def apply_trans(trans, pts, move=True):\n    \"\"\"Apply a transform matrix to an array of points.\n\n    Parameters\n    ----------\n    trans : array, shape = (4, 4) | instance of Transform\n        Transform matrix.\n    pts : array, shape = (3,) | (n, 3)\n        Array with coordinates for one or n points.\n    move : bool\n        If True (default), apply translation.\n\n    Returns\n    -------\n    transformed_pts : shape = (3,) | (n, 3)\n        Transformed point(s).\n    \"\"\"\n    if isinstance(trans, dict):\n        trans = trans[\"trans\"]\n    pts = np.asarray(pts)\n    if pts.size == 0:\n        return pts.copy()\n\n    # apply rotation & scale\n    out_pts = np.dot(pts, trans[:3, :3].T)\n    # apply translation\n    if move:\n        out_pts += trans[:3, 3]\n\n    return out_pts", "metadata": {}}
{"_id": "mne_mne_transforms.py_rotation_code", "title": "rotation", "text": "def rotation(x=0, y=0, z=0):\n    \"\"\"Create an array with a 4 dimensional rotation matrix.\n\n    Parameters\n    ----------\n    x, y, z : scalar\n        Rotation around the origin (in rad).\n\n    Returns\n    -------\n    r : array, shape = (4, 4)\n        The rotation matrix.\n    \"\"\"\n    r = np.eye(4)\n    r[:3, :3] = rotation3d(x=x, y=y, z=z)\n    return r", "metadata": {}}
{"_id": "mne_mne_transforms.py_rotation3d_code", "title": "rotation3d", "text": "def rotation3d(x=0, y=0, z=0):\n    \"\"\"Create an array with a 3 dimensional rotation matrix.\n\n    Parameters\n    ----------\n    x, y, z : scalar\n        Rotation around the origin (in rad).\n\n    Returns\n    -------\n    r : array, shape = (3, 3)\n        The rotation matrix.\n    \"\"\"\n    cos_x = np.cos(x)\n    cos_y = np.cos(y)\n    cos_z = np.cos(z)\n    sin_x = np.sin(x)\n    sin_y = np.sin(y)\n    sin_z = np.sin(z)\n    r = np.array(\n        [\n            [\n                cos_y * cos_z,\n                -cos_x * sin_z + sin_x * sin_y * cos_z,\n                sin_x * sin_z + cos_x * sin_y * cos_z,\n            ],\n            [\n                cos_y * sin_z,\n                cos_x * cos_z + sin_x * sin_y * sin_z,\n                -sin_x * cos_z + cos_x * sin_y * sin_z,\n            ],\n            [-sin_y, sin_x * cos_y, cos_x * cos_y],\n        ],\n        dtype=float,\n    )\n    return r", "metadata": {}}
{"_id": "mne_mne_transforms.py_rotation3d_align_z_axis_code", "title": "rotation3d_align_z_axis", "text": "def rotation3d_align_z_axis(target_z_axis):\n    \"\"\"Compute a rotation matrix to align [ 0 0 1] with supplied target z axis.\n\n    Parameters\n    ----------\n    target_z_axis : array, shape (1, 3)\n        z axis. computed matrix (r) will map [0 0 1] to target_z_axis\n\n    Returns\n    -------\n    r : array, shape (3, 3)\n        The rotation matrix.\n    \"\"\"\n    target_z_axis = target_z_axis / np.linalg.norm(target_z_axis)\n    r = np.zeros((3, 3))\n    if (1.0 + target_z_axis[2]) < 1e-12:\n        r[0, 0] = 1.0\n        r[1, 1] = -1.0\n        r[2, 2] = -1.0\n    else:\n        f = 1.0 / (1.0 + target_z_axis[2])\n        r[0, 0] = 1.0 - 1.0 * f * target_z_axis[0] * target_z_axis[0]\n        r[0, 1] = -1.0 * f * target_z_axis[0] * target_z_axis[1]\n        r[0, 2] = target_z_axis[0]\n        r[1, 0] = -1.0 * f * target_z_axis[0] * target_z_axis[1]\n        r[1, 1] = 1.0 - 1.0 * f * target_z_axis[1] * target_z_axis[1]\n        r[1, 2] = target_z_axis[1]\n        r[2, 0] = -target_z_axis[0]\n        r[2, 1] = -target_z_axis[1]\n        r[2, 2] = 1.0 - f * (\n            target_z_axis[0] * target_z_axis[0] + target_z_axis[1] * target_z_axis[1]\n        )\n\n    # assert that r is a rotation matrix r^t * r = I and det(r) = 1\n    assert np.any((r.dot(r.T) - np.identity(3)) < 1e-12)\n    assert (np.linalg.det(r) - 1.0) < 1e-12\n    # assert that r maps [0 0 1] on the device z axis (target_z_axis)\n    assert np.linalg.norm(target_z_axis - r.dot([0, 0, 1])) < 1e-12\n\n    return r", "metadata": {}}
{"_id": "mne_mne_transforms.py_rotation_angles_code", "title": "rotation_angles", "text": "def rotation_angles(m):\n    \"\"\"Find rotation angles from a transformation matrix.\n\n    Parameters\n    ----------\n    m : array, shape >= (3, 3)\n        Rotation matrix. Only the top left 3 x 3 partition is accessed.\n\n    Returns\n    -------\n    x, y, z : float\n        Rotation around x, y and z axes.\n    \"\"\"\n    x = np.arctan2(m[2, 1], m[2, 2])\n    c2 = np.sqrt(m[0, 0] ** 2 + m[1, 0] ** 2)\n    y = np.arctan2(-m[2, 0], c2)\n    s1 = np.sin(x)\n    c1 = np.cos(x)\n    z = np.arctan2(s1 * m[0, 2] - c1 * m[0, 1], c1 * m[1, 1] - s1 * m[1, 2])\n    return x, y, z", "metadata": {}}
{"_id": "mne_mne_transforms.py_scaling_code", "title": "scaling", "text": "def scaling(x=1, y=1, z=1):\n    \"\"\"Create an array with a scaling matrix.\n\n    Parameters\n    ----------\n    x, y, z : scalar\n        Scaling factors.\n\n    Returns\n    -------\n    s : array, shape = (4, 4)\n        The scaling matrix.\n    \"\"\"\n    s = np.array([[x, 0, 0, 0], [0, y, 0, 0], [0, 0, z, 0], [0, 0, 0, 1]], dtype=float)\n    return s", "metadata": {}}
{"_id": "mne_mne_transforms.py_translation_code", "title": "translation", "text": "def translation(x=0, y=0, z=0):\n    \"\"\"Create an array with a translation matrix.\n\n    Parameters\n    ----------\n    x, y, z : scalar\n        Translation parameters.\n\n    Returns\n    -------\n    m : array, shape = (4, 4)\n        The translation matrix.\n    \"\"\"\n    m = np.array([[1, 0, 0, x], [0, 1, 0, y], [0, 0, 1, z], [0, 0, 0, 1]], dtype=float)\n    return m", "metadata": {}}
{"_id": "mne_mne_transforms.py_combine_transforms_code", "title": "combine_transforms", "text": "def combine_transforms(t_first, t_second, fro, to):\n    \"\"\"Combine two transforms.\n\n    Parameters\n    ----------\n    t_first : dict\n        First transform.\n    t_second : dict\n        Second transform.\n    fro : int\n        From coordinate frame.\n    to : int\n        To coordinate frame.\n\n    Returns\n    -------\n    trans : dict\n        Combined transformation.\n    \"\"\"\n    fro = _to_const(fro)\n    to = _to_const(to)\n    if t_first[\"from\"] != fro:\n        raise RuntimeError(\n            'From mismatch: {fro1} (\"{cf1}\") != {fro2} (\"{cf2}\")'.format(\n                fro1=t_first[\"from\"],\n                cf1=_coord_frame_name(t_first[\"from\"]),\n                fro2=fro,\n                cf2=_coord_frame_name(fro),\n            )\n        )\n    if t_first[\"to\"] != t_second[\"from\"]:\n        raise RuntimeError(\n            'Transform mismatch: t1[\"to\"] = {to1} (\"{cf1}\"), '\n            't2[\"from\"] = {fro2} (\"{cf2}\")'.format(\n                to1=t_first[\"to\"],\n                cf1=_coord_frame_name(t_first[\"to\"]),\n                fro2=t_second[\"from\"],\n                cf2=_coord_frame_name(t_second[\"from\"]),\n            )\n        )\n    if t_second[\"to\"] != to:\n        raise RuntimeError(\n            'To mismatch: {to1} (\"{cf1}\") != {to2} (\"{cf2}\")'.format(\n                to1=t_second[\"to\"],\n                cf1=_coord_frame_name(t_second[\"to\"]),\n                to2=to,\n                cf2=_coord_frame_name(to),\n            )\n        )\n    return Transform(fro, to, np.dot(t_second[\"trans\"], t_first[\"trans\"]))", "metadata": {}}
{"_id": "mne_mne_transforms.py_read_trans_code", "title": "read_trans", "text": "def read_trans(fname, return_all=False, verbose=None):\n    \"\"\"Read a ``-trans.fif`` file.\n\n    Parameters\n    ----------\n    fname : path-like\n        The name of the file.\n    return_all : bool\n        If True, return all transformations in the file.\n        False (default) will only return the first.\n\n        .. versionadded:: 0.15\n    %(verbose)s\n\n    Returns\n    -------\n    trans : dict | list of dict\n        The transformation dictionary from the fif file.\n\n    See Also\n    --------\n    write_trans\n    mne.transforms.Transform\n    \"\"\"\n    fname = _check_fname(fname, overwrite=\"read\", must_exist=True)\n    fid, tree, directory = fiff_open(fname)\n\n    trans = list()\n    with fid:\n        for t in directory:\n            if t.kind == FIFF.FIFF_COORD_TRANS:\n                trans.append(read_tag(fid, t.pos).data)\n                if not return_all:\n                    break\n    if len(trans) == 0:\n        raise OSError(\"This does not seem to be a -trans.fif file.\")\n    return trans if return_all else trans[0]", "metadata": {}}
{"_id": "mne_mne_transforms.py_write_trans_code", "title": "write_trans", "text": "def write_trans(fname, trans, *, overwrite=False, verbose=None):\n    \"\"\"Write a transformation FIF file.\n\n    Parameters\n    ----------\n    fname : path-like\n        The name of the file, which should end in ``-trans.fif``.\n    trans : dict\n        Trans file data, as returned by `~mne.read_trans`.\n    %(overwrite)s\n    %(verbose)s\n\n    See Also\n    --------\n    read_trans\n    \"\"\"\n    check_fname(\n        fname, \"trans\", (\"-trans.fif\", \"-trans.fif.gz\", \"_trans.fif\", \"_trans.fif.gz\")\n    )\n    fname = _check_fname(fname=fname, overwrite=overwrite)\n    with start_and_end_file(fname) as fid:\n        write_coord_trans(fid, trans)", "metadata": {}}
{"_id": "mne_mne_transforms.py_invert_transform_code", "title": "invert_transform", "text": "def invert_transform(trans):\n    \"\"\"Invert a transformation between coordinate systems.\n\n    Parameters\n    ----------\n    trans : dict\n        Transform to invert.\n\n    Returns\n    -------\n    inv_trans : dict\n        Inverse transform.\n    \"\"\"\n    return Transform(trans[\"to\"], trans[\"from\"], np.linalg.inv(trans[\"trans\"]))", "metadata": {}}
{"_id": "mne_mne_transforms.py_transform_surface_to_code", "title": "transform_surface_to", "text": "def transform_surface_to(surf, dest, trans, copy=False):\n    \"\"\"Transform surface to the desired coordinate system.\n\n    Parameters\n    ----------\n    surf : dict\n        Surface.\n    dest : 'meg' | 'mri' | 'head' | int\n        Destination coordinate system. Can be an integer for using\n        FIFF types.\n    trans : dict | list of dict\n        Transformation to use (or a list of possible transformations to\n        check).\n    copy : bool\n        If False (default), operate in-place.\n\n    Returns\n    -------\n    res : dict\n        Transformed source space.\n    \"\"\"\n    surf = deepcopy(surf) if copy else surf\n    if isinstance(dest, str):\n        if dest not in _str_to_frame:\n            raise KeyError(\n                f'dest must be one of {list(_str_to_frame.keys())}, not \"{dest}\"'\n            )\n        dest = _str_to_frame[dest]  # convert to integer\n    if surf[\"coord_frame\"] == dest:\n        return surf\n\n    trans = _ensure_trans(trans, int(surf[\"coord_frame\"]), dest)\n    surf[\"coord_frame\"] = dest\n    surf[\"rr\"] = apply_trans(trans, surf[\"rr\"])\n    if \"nn\" in surf:\n        surf[\"nn\"] = apply_trans(trans, surf[\"nn\"], move=False)\n    return surf", "metadata": {}}
{"_id": "mne_mne_transforms.py_get_ras_to_neuromag_trans_code", "title": "get_ras_to_neuromag_trans", "text": "def get_ras_to_neuromag_trans(nasion, lpa, rpa):\n    \"\"\"Construct a transformation matrix to the MNE head coordinate system.\n\n    Construct a transformation matrix from an arbitrary RAS coordinate system\n    to the MNE head coordinate system, in which the x axis passes through the\n    two preauricular points, and the y axis passes through the nasion and is\n    normal to the x axis. (see mne manual, pg. 97)\n\n    Parameters\n    ----------\n    nasion : array_like, shape (3,)\n        Nasion point coordinate.\n    lpa : array_like, shape (3,)\n        Left peri-auricular point coordinate.\n    rpa : array_like, shape (3,)\n        Right peri-auricular point coordinate.\n\n    Returns\n    -------\n    trans : numpy.array, shape = (4, 4)\n        Transformation matrix to MNE head space.\n    \"\"\"\n    # check input args\n    nasion = np.asarray(nasion)\n    lpa = np.asarray(lpa)\n    rpa = np.asarray(rpa)\n    for pt in (nasion, lpa, rpa):\n        if pt.ndim != 1 or len(pt) != 3:\n            raise ValueError(\n                \"Points have to be provided as one dimensional arrays of length 3.\"\n            )\n\n    right = rpa - lpa\n    right_unit = right / np.linalg.norm(right)\n\n    origin = lpa + np.dot(nasion - lpa, right_unit) * right_unit\n\n    anterior = nasion - origin\n    anterior_unit = anterior / np.linalg.norm(anterior)\n\n    superior_unit = np.cross(right_unit, anterior_unit)\n\n    x, y, z = -origin\n    origin_trans = translation(x, y, z)\n\n    trans_l = np.vstack((right_unit, anterior_unit, superior_unit, [0, 0, 0]))\n    trans_r = np.reshape([0, 0, 0, 1], (4, 1))\n    rot_trans = np.hstack((trans_l, trans_r))\n\n    trans = np.dot(rot_trans, origin_trans)\n    return trans", "metadata": {}}
{"_id": "mne_mne_transforms.py_quat_to_rot_code", "title": "quat_to_rot", "text": "def quat_to_rot(quat):\n    \"\"\"Convert a set of quaternions to rotations.\n\n    Parameters\n    ----------\n    quat : array, shape (..., 3)\n        The q1, q2, and q3 (x, y, z) parameters of a unit quaternion.\n\n    Returns\n    -------\n    rot : array, shape (..., 3, 3)\n        The corresponding rotation matrices.\n\n    See Also\n    --------\n    rot_to_quat\n    \"\"\"\n    # z = a + bi + cj + dk\n    b, c, d = quat[..., 0], quat[..., 1], quat[..., 2]\n    bb, cc, dd = b * b, c * c, d * d\n    # use max() here to be safe in case roundoff errs put us over\n    aa = np.maximum(1.0 - bb - cc - dd, 0.0)\n    a = np.sqrt(aa)\n    ab_2 = 2 * a * b\n    ac_2 = 2 * a * c\n    ad_2 = 2 * a * d\n    bc_2 = 2 * b * c\n    bd_2 = 2 * b * d\n    cd_2 = 2 * c * d\n    rotation = np.empty(quat.shape[:-1] + (3, 3))\n    rotation[..., 0, 0] = aa + bb - cc - dd\n    rotation[..., 0, 1] = bc_2 - ad_2\n    rotation[..., 0, 2] = bd_2 + ac_2\n    rotation[..., 1, 0] = bc_2 + ad_2\n    rotation[..., 1, 1] = aa + cc - bb - dd\n    rotation[..., 1, 2] = cd_2 - ab_2\n    rotation[..., 2, 0] = bd_2 - ac_2\n    rotation[..., 2, 1] = cd_2 + ab_2\n    rotation[..., 2, 2] = aa + dd - bb - cc\n    return rotation", "metadata": {}}
{"_id": "mne_mne_transforms.py_rot_to_quat_code", "title": "rot_to_quat", "text": "def rot_to_quat(rot):\n    \"\"\"Convert a set of rotations to quaternions.\n\n    Parameters\n    ----------\n    rot : array, shape (..., 3, 3)\n        The rotation matrices to convert.\n\n    Returns\n    -------\n    quat : array, shape (..., 3)\n        The q1, q2, and q3 (x, y, z) parameters of the corresponding\n        unit quaternions.\n\n    See Also\n    --------\n    quat_to_rot\n    \"\"\"\n    rot = rot.reshape(rot.shape[:-2] + (9,))\n    return np.apply_along_axis(_one_rot_to_quat, -1, rot)", "metadata": {}}
{"_id": "mne_mne_transforms.py_read_ras_mni_t_code", "title": "read_ras_mni_t", "text": "def read_ras_mni_t(subject, subjects_dir=None):\n    \"\"\"Read a subject's RAS to MNI transform.\n\n    Parameters\n    ----------\n    subject : str\n        The subject.\n    %(subjects_dir)s\n\n    Returns\n    -------\n    ras_mni_t : instance of Transform\n        The transform from RAS to MNI (in mm).\n    \"\"\"\n    subjects_dir = Path(get_subjects_dir(subjects_dir=subjects_dir, raise_error=True))\n    _validate_type(subject, \"str\", \"subject\")\n    fname = subjects_dir / subject / \"mri\" / \"transforms\" / \"talairach.xfm\"\n    fname = str(\n        _check_fname(\n            fname,\n            \"read\",\n            True,\n            \"FreeSurfer Talairach transformation file\",\n        )\n    )\n    return Transform(\"ras\", \"mni_tal\", _read_fs_xfm(fname)[0])", "metadata": {}}
{"_id": "mne_mne_transforms.py_compute_volume_registration_code", "title": "compute_volume_registration", "text": "def compute_volume_registration(\n    moving,\n    static,\n    pipeline=\"all\",\n    zooms=None,\n    niter=None,\n    *,\n    starting_affine=None,\n    verbose=None,\n):\n    \"\"\"Align two volumes using an affine and, optionally, SDR.\n\n    Parameters\n    ----------\n    %(moving)s\n    %(static)s\n    %(pipeline)s\n    zooms : float | tuple | dict | None\n        The voxel size of volume for each spatial dimension in mm.\n        If None (default), MRIs won't be resliced (slow, but most accurate).\n        Can be a tuple to provide separate zooms for each dimension (X/Y/Z),\n        or a dict with keys ``['translation', 'rigid', 'affine', 'sdr']``\n        (each with values that are float`, tuple, or None) to provide separate\n        reslicing/accuracy for the steps.\n    %(niter)s\n    starting_affine : ndarray\n        The affine to initialize the registration with.\n\n        .. versionadded:: 1.2\n    %(verbose)s\n\n    Returns\n    -------\n    %(reg_affine)s\n    %(sdr_morph)s\n\n    Notes\n    -----\n    This function is heavily inspired by and extends\n    :func:`dipy.align.affine_registration\n    <dipy.align._public.affine_registration>`.\n\n    .. versionadded:: 0.24\n    \"\"\"\n    return _compute_volume_registration(\n        moving, static, pipeline, zooms, niter, starting_affine=starting_affine\n    )[:2]", "metadata": {}}
{"_id": "mne_mne_transforms.py_apply_volume_registration_code", "title": "apply_volume_registration", "text": "def apply_volume_registration(\n    moving,\n    static,\n    reg_affine,\n    sdr_morph=None,\n    interpolation=\"linear\",\n    cval=0.0,\n    verbose=None,\n):\n    \"\"\"Apply volume registration.\n\n    Uses registration parameters computed by\n    :func:`~mne.transforms.compute_volume_registration`.\n\n    Parameters\n    ----------\n    %(moving)s\n    %(static)s\n    %(reg_affine)s\n    %(sdr_morph)s\n    interpolation : str\n        Interpolation to be used during the interpolation.\n        Can be ``\"linear\"`` (default) or ``\"nearest\"``.\n    cval : float | str\n        The constant value to assume exists outside the bounds of the\n        ``moving`` image domain. Can be a string percentage like ``'1%%'``\n        to use the given percentile of image data as the constant value.\n    %(verbose)s\n\n    Returns\n    -------\n    reg_img : instance of SpatialImage\n        The image after affine (and SDR, if provided) registration.\n\n    Notes\n    -----\n    .. versionadded:: 0.24\n    \"\"\"\n    _require_version(\"dipy\", \"SDR morph\", \"0.10.1\")\n    _import_nibabel(\"SDR morph\")\n    from dipy.align.imaffine import AffineMap\n    from dipy.align.imwarp import DiffeomorphicMap\n    from nibabel.spatialimages import SpatialImage\n\n    _validate_type(moving, SpatialImage, \"moving\")\n    _validate_type(static, SpatialImage, \"static\")\n    _validate_type(reg_affine, np.ndarray, \"reg_affine\")\n    _check_option(\"reg_affine.shape\", reg_affine.shape, ((4, 4),))\n    _validate_type(sdr_morph, (DiffeomorphicMap, None), \"sdr_morph\")\n    _validate_type(cval, (\"numeric\", str), \"cval\")\n    perc = None\n    if isinstance(cval, str):\n        if not cval.endswith(\"%\"):\n            raise ValueError(f\"cval must end with % if str, got {cval}\")\n        perc = float(cval[:-1])\n    logger.info(\"Applying affine registration ...\")\n    moving_affine = moving.affine\n    moving = np.asarray(moving.dataobj, dtype=float)\n    if perc is not None:\n        cval = np.percentile(moving, perc)\n        logger.info(f\"Using a lower bound at the {perc} percentile: {cval}\")\n    moving -= cval\n    static, static_affine = np.asarray(static.dataobj), static.affine\n    affine_map = AffineMap(\n        reg_affine,\n        domain_grid_shape=static.shape,\n        domain_grid2world=static_affine,\n        codomain_grid_shape=moving.shape,\n        codomain_grid2world=moving_affine,\n    )\n    reg_data = affine_map.transform(moving, interpolation=interpolation)\n    if sdr_morph is not None:\n        logger.info(\"Applying SDR warp ...\")\n        reg_data = sdr_morph.transform(\n            reg_data,\n            interpolation=interpolation,\n            image_world2grid=np.linalg.inv(static_affine),\n            out_shape=static.shape,\n            out_grid2world=static_affine,\n        )\n    reg_data += cval\n    reg_img = SpatialImage(reg_data, static_affine)\n    logger.info(\"[done]\")\n    return reg_img", "metadata": {}}
{"_id": "mne_mne_transforms.py_apply_volume_registration_points_code", "title": "apply_volume_registration_points", "text": "def apply_volume_registration_points(\n    info, trans, moving, static, reg_affine, sdr_morph=None, verbose=None\n):\n    \"\"\"Apply volume registration.\n\n    Uses registration parameters computed by\n    :func:`~mne.transforms.compute_volume_registration`.\n\n    Parameters\n    ----------\n    %(info_not_none)s\n    %(trans_not_none)s\n    %(moving)s\n    %(static)s\n    %(reg_affine)s\n    %(sdr_morph)s\n    %(verbose)s\n\n    Returns\n    -------\n    %(info_not_none)s\n    trans2 : instance of Transform\n        The head->mri (surface RAS) transform for the static image.\n\n    Notes\n    -----\n    .. versionadded:: 1.4.0\n    \"\"\"\n    from .channels import compute_native_head_t, make_dig_montage\n\n    _require_version(\"nibabel\", \"volume registration\", \"2.1.0\")\n    from dipy.align.imwarp import DiffeomorphicMap\n    from nibabel import MGHImage\n    from nibabel.spatialimages import SpatialImage\n\n    _validate_type(moving, SpatialImage, \"moving\")\n    _validate_type(static, SpatialImage, \"static\")\n    _validate_type(reg_affine, np.ndarray, \"reg_affine\")\n    _check_option(\"reg_affine.shape\", reg_affine.shape, ((4, 4),))\n    _validate_type(sdr_morph, (DiffeomorphicMap, None), \"sdr_morph\")\n\n    moving_mgh = MGHImage(np.array(moving.dataobj).astype(np.float32), moving.affine)\n    static_mgh = MGHImage(np.array(static.dataobj).astype(np.float32), static.affine)\n\n    montage = info.get_montage()\n    montage_kwargs = montage.get_positions()\n    trans = _ensure_trans(trans, \"head\", \"mri\")\n    montage.apply_trans(trans)  # to moving surface RAS\n\n    locs = np.array(list(montage.get_positions()[\"ch_pos\"].values()))\n\n    locs = apply_trans(\n        Transform(  # to moving voxels\n            fro=\"mri\",\n            to=\"mri_voxel\",\n            trans=np.linalg.inv(moving_mgh.header.get_vox2ras_tkr()),\n        ),\n        locs * 1000,\n    )\n    locs = apply_trans(\n        Transform(  # to moving ras\n            fro=\"mri_voxel\", to=\"ras\", trans=moving_mgh.header.get_vox2ras()\n        ),\n        locs,\n    )\n    locs = apply_trans(\n        Transform(  # to static ras\n            fro=\"ras\", to=\"ras\", trans=np.linalg.inv(reg_affine)\n        ),\n        locs,\n    )\n    if sdr_morph is not None:\n        _require_version(\"dipy\", \"SDR morph\", \"1.6.0\")\n        locs = sdr_morph.transform_points(\n            locs,\n            coord2world=sdr_morph.domain_grid2world,\n            world2coord=sdr_morph.domain_world2grid,\n        )\n    locs = apply_trans(\n        Transform(  # to static voxels\n            fro=\"ras\",\n            to=\"mri_voxel\",\n            trans=np.linalg.inv(static_mgh.header.get_vox2ras()),\n        ),\n        locs,\n    )\n    locs = (\n        apply_trans(\n            Transform(  # to static surface RAS\n                fro=\"mri_voxel\", to=\"mri\", trans=static_mgh.header.get_vox2ras_tkr()\n            ),\n            locs,\n        )\n        / 1000\n    )\n\n    montage_kwargs[\"coord_frame\"] = \"mri\"\n    montage_kwargs[\"ch_pos\"] = {ch: loc for ch, loc in zip(montage.ch_names, locs)}\n    montage2 = make_dig_montage(**montage_kwargs)\n\n    trans2 = compute_native_head_t(montage2)\n    info2 = info.copy()\n    info2.set_montage(montage2)  # converts to head coordinates\n\n    return info2, trans2", "metadata": {}}
{"_id": "mne_mne_transforms.py_from_str_code", "title": "from_str", "text": "def from_str(self):\n        \"\"\"The \"from\" frame as a string.\"\"\"\n        return _coord_frame_name(self[\"from\"])", "metadata": {}}
{"_id": "mne_mne_transforms.py_to_str_code", "title": "to_str", "text": "def to_str(self):\n        \"\"\"The \"to\" frame as a string.\"\"\"\n        return _coord_frame_name(self[\"to\"])", "metadata": {}}
{"_id": "mne_mne_transforms.py_save_code", "title": "save", "text": "def save(self, fname, *, overwrite=False, verbose=None):\n        \"\"\"Save the transform as -trans.fif file.\n\n        Parameters\n        ----------\n        fname : path-like\n            The name of the file, which should end in ``-trans.fif``.\n        %(overwrite)s\n        %(verbose)s\n        \"\"\"\n        write_trans(fname, self, overwrite=overwrite, verbose=verbose)", "metadata": {}}
{"_id": "mne_mne_transforms.py_copy_code", "title": "copy", "text": "def copy(self):\n        \"\"\"Make a copy of the transform.\"\"\"\n        return deepcopy(self)", "metadata": {}}
{"_id": "mne_mne_transforms.py_transform_code", "title": "transform", "text": "def transform(self, pts, verbose=None):\n        \"\"\"Apply the warp.\n\n        Parameters\n        ----------\n        pts : shape (n_transform, 3)\n            Source points to warp to the destination.\n\n        Returns\n        -------\n        dest : shape (n_transform, 3)\n            The transformed points.\n        \"\"\"\n        logger.info(f\"Transforming {len(pts)} points\")\n        assert pts.shape[1] == 3\n        # for memory reasons, we should do this in ~100 MB chunks\n        out = np.zeros_like(pts)\n        n_splits = max(\n            int((pts.shape[0] * self._destination.shape[0]) / (100e6 / 8.0)), 1\n        )\n        for this_out, this_pts in zip(\n            np.array_split(out, n_splits), np.array_split(pts, n_splits)\n        ):\n            dists = _tps(cdist(this_pts, self._destination, \"sqeuclidean\"))\n            L = np.hstack((dists, np.ones((dists.shape[0], 1)), this_pts))\n            this_out[:] = np.dot(L, self._weights)\n        assert not (out == 0).any()\n        return out", "metadata": {}}
{"_id": "mne_mne_transforms.py_fit_code", "title": "fit", "text": "def fit(\n        self,\n        source,\n        destination,\n        order=4,\n        reg=1e-5,\n        center=True,\n        match=\"oct5\",\n        verbose=None,\n    ):\n        \"\"\"Fit the warp from source points to destination points.\n\n        Parameters\n        ----------\n        source : array, shape (n_src, 3)\n            The source points.\n        destination : array, shape (n_dest, 3)\n            The destination points.\n        order : int\n            Order of the spherical harmonic fit.\n        reg : float\n            Regularization of the TPS warp.\n        center : bool\n            If True, center the points by fitting a sphere to points\n            that are in a reasonable region for head digitization.\n        match : str\n            The uniformly-spaced points to match on the two surfaces.\n            Can be \"ico#\" or \"oct#\" where \"#\" is an integer.\n            The default is \"oct5\".\n        %(verbose)s\n\n        Returns\n        -------\n        inst : instance of SphericalSurfaceWarp\n            The warping object (for chaining).\n        \"\"\"\n        from .bem import _fit_sphere\n        from .source_space._source_space import _check_spacing\n\n        match_rr = _check_spacing(match, verbose=False)[2][\"rr\"]\n        logger.info(\"Computing TPS warp\")\n        src_center = dest_center = np.zeros(3)\n        if center:\n            logger.info(\"    Centering data\")\n            hsp = np.array([p for p in source if not (p[2] < -1e-6 and p[1] > 1e-6)])\n            src_center = _fit_sphere(hsp)[1]\n            source = source - src_center\n            hsp = np.array([p for p in destination if not (p[2] < 0 and p[1] > 0)])\n            dest_center = _fit_sphere(hsp)[1]\n            destination = destination - dest_center\n            logger.info(\n                \"    Using centers {np.array_str(src_center, None, 3)} -> \"\n                \"{np.array_str(dest_center, None, 3)}\"\n            )\n        self._fit_params = dict(\n            n_src=len(source),\n            n_dest=len(destination),\n            match=match,\n            n_match=len(match_rr),\n            order=order,\n            reg=reg,\n        )\n        assert source.shape[1] == destination.shape[1] == 3\n        self._destination = destination.copy()\n        # 1. Compute spherical coordinates of source and destination points\n        logger.info(\"    Converting to spherical coordinates\")\n        src_rad_az_pol = _cart_to_sph(source).T\n        dest_rad_az_pol = _cart_to_sph(destination).T\n        match_rad_az_pol = _cart_to_sph(match_rr).T\n        del match_rr\n        # 2. Compute spherical harmonic coefficients for all points\n        logger.info(\n            f\"    Computing spherical harmonic approximation with order {order}\"\n        )\n        src_sph = _compute_sph_harm(order, *src_rad_az_pol[1:])\n        dest_sph = _compute_sph_harm(order, *dest_rad_az_pol[1:])\n        match_sph = _compute_sph_harm(order, *match_rad_az_pol[1:])\n        # 3. Fit spherical harmonics to both surfaces to smooth them\n        src_coeffs = linalg.lstsq(src_sph, src_rad_az_pol[0])[0]\n        dest_coeffs = linalg.lstsq(dest_sph, dest_rad_az_pol[0])[0]\n        # 4. Smooth both surfaces using these coefficients, and evaluate at\n        #     the \"shape\" points\n        logger.info(\n            f\"    Matching {len(match_sph)} points ({match}) on smoothed surfaces\"\n        )\n        src_rad_az_pol = match_rad_az_pol.copy()\n        src_rad_az_pol[0] = np.abs(np.dot(match_sph, src_coeffs))\n        dest_rad_az_pol = match_rad_az_pol.copy()\n        dest_rad_az_pol[0] = np.abs(np.dot(match_sph, dest_coeffs))\n        # 5. Convert matched points to Cartesian coordinates and put back\n        source = _sph_to_cart(src_rad_az_pol.T)\n        source += src_center\n        destination = _sph_to_cart(dest_rad_az_pol.T)\n        destination += dest_center\n        # 6. Compute TPS warp of matched points from smoothed surfaces\n        self._warp = _TPSWarp().fit(source, destination, reg)\n        logger.info(\"[done]\")\n        return self", "metadata": {}}
{"_id": "mne_mne_transforms.py_transform_code", "title": "transform", "text": "def transform(self, source, verbose=None):\n        \"\"\"Transform arbitrary source points to the destination.\n\n        Parameters\n        ----------\n        source : ndarray, shape (n_pts, 3)\n            Source points to transform. They do not need to be the same\n            points that were used to generate the model, although ideally\n            they will be inside the convex hull formed by the original\n            source points.\n        %(verbose)s\n\n        Returns\n        -------\n        destination : ndarray, shape (n_pts, 3)\n            The points transformed to the destination space.\n        \"\"\"\n        return self._warp.transform(source)", "metadata": {}}
{"_id": "mne_mne_epochs.py_make_metadata_code", "title": "make_metadata", "text": "def make_metadata(\n    events,\n    event_id,\n    tmin,\n    tmax,\n    sfreq,\n    row_events=None,\n    keep_first=None,\n    keep_last=None,\n):\n    \"\"\"Automatically generate metadata for use with `mne.Epochs` from events.\n\n    This function mimics the epoching process (it constructs time windows\n    around time-locked \"events of interest\") and collates information about\n    any other events that occurred within those time windows. The information\n    is returned as a :class:`pandas.DataFrame`, suitable for use as\n    `~mne.Epochs` metadata: one row per time-locked event, and columns\n    indicating presence or absence and latency of each ancillary event type.\n\n    The function will also return a new ``events`` array and ``event_id``\n    dictionary that correspond to the generated metadata, which together can then be\n    readily fed into `~mne.Epochs`.\n\n    Parameters\n    ----------\n    events : array, shape (m, 3)\n        The :term:`events array <events>`. By default, the returned metadata\n        :class:`~pandas.DataFrame` will have as many rows as the events array.\n        To create rows for only a subset of events, pass the ``row_events``\n        parameter.\n    event_id : dict\n        A mapping from event names (keys) to event IDs (values). The event\n        names will be incorporated as columns of the returned metadata\n        :class:`~pandas.DataFrame`.\n    tmin, tmax : float | str | list of str | None\n        If float, start and end of the time interval for metadata generation in seconds,\n        relative to the time-locked event of the respective time window (the \"row\n        events\").\n\n        .. note::\n           If you are planning to attach the generated metadata to\n           `~mne.Epochs` and intend to include only events that fall inside\n           your epoch's time interval, pass the same ``tmin`` and ``tmax``\n           values here as you use for your epochs.\n\n        If ``None``, the time window used for metadata generation is bounded by the\n        ``row_events``. This is can be particularly practical if trial duration varies\n        greatly, but each trial starts with a known event (e.g., a visual cue or\n        fixation).\n\n        .. note::\n           If ``tmin=None``, the first time window for metadata generation starts with\n           the first row event. If ``tmax=None``, the last time window for metadata\n           generation ends with the last event in ``events``.\n\n        If a string or a list of strings, the events bounding the metadata around each\n        \"row event\". For ``tmin``, the events are assumed to occur **before** the row\n        event, and for ``tmax``, the events are assumed to occur **after** \u2013 unless\n        ``tmin`` or ``tmax`` are equal to a row event, in which case the row event\n        serves as the bound.\n\n        .. versionchanged:: 1.6.0\n           Added support for ``None``.\n\n        .. versionadded:: 1.7.0\n           Added support for strings.\n    sfreq : float\n        The sampling frequency of the data from which the events array was\n        extracted.\n    row_events : list of str | str | None\n        Event types around which to create the time windows. For each of these\n        time-locked events, we will create a **row** in the returned metadata\n        :class:`pandas.DataFrame`. If provided, the string(s) must be keys of\n        ``event_id``. If ``None`` (default), rows are created for **all** event types\n        present in ``event_id``.\n    keep_first : str | list of str | None\n        Specify subsets of :term:`hierarchical event descriptors` (HEDs,\n        inspired by :footcite:`BigdelyShamloEtAl2013`) matching events of which\n        the **first occurrence** within each time window shall be stored in\n        addition to the original events.\n\n        .. note::\n           There is currently no way to retain **all** occurrences of a\n           repeated event. The ``keep_first`` parameter can be used to specify\n           subsets of HEDs, effectively creating a new event type that is the\n           union of all events types described by the matching HED pattern.\n           Only the very first event of this set will be kept.\n\n        For example, you might have two response events types,\n        ``response/left`` and ``response/right``; and in trials with both\n        responses occurring, you want to keep only the first response. In this\n        case, you can pass ``keep_first='response'``. This will add two new\n        columns to the metadata: ``response``, indicating at what **time** the\n        event  occurred, relative to the time-locked event; and\n        ``first_response``, stating which **type** (``'left'`` or ``'right'``)\n        of event occurred.\n        To match specific subsets of HEDs describing different sets of events,\n        pass a list of these subsets, e.g.\n        ``keep_first=['response', 'stimulus']``. If ``None`` (default), no\n        event aggregation will take place and no new columns will be created.\n\n        .. note::\n           By default, this function will always retain  the first instance\n           of any event in each time window. For example, if a time window\n           contains two ``'response'`` events, the generated ``response``\n           column will automatically refer to the first of the two events. In\n           this specific case, it is therefore **not** necessary to make use of\n           the ``keep_first`` parameter \u2013 unless you need to differentiate\n           between two types of responses, like in the example above.\n\n    keep_last : list of str | None\n        Same as ``keep_first``, but for keeping only the **last**  occurrence\n        of matching events. The column indicating the **type** of an event\n        ``myevent`` will be named ``last_myevent``.\n\n    Returns\n    -------\n    metadata : pandas.DataFrame\n        Metadata for each row event, with the following columns:\n\n        - ``event_name``, with strings indicating the name of the time-locked\n          event (\"row event\") for that specific time window\n\n        - one column per event type in ``event_id``, with the same name; floats\n          indicating the latency of the event in seconds, relative to the\n          time-locked event\n\n        - if applicable, additional columns named after the ``keep_first`` and\n          ``keep_last`` event types; floats indicating the latency  of the\n          event in seconds, relative to the time-locked event\n\n        - if applicable, additional columns ``first_{event_type}`` and\n          ``last_{event_type}`` for ``keep_first`` and ``keep_last`` event\n          types, respetively; the values will be strings indicating which event\n          types were matched by the provided HED patterns\n\n    events : array, shape (n, 3)\n        The events corresponding to the generated metadata, i.e. one\n        time-locked event per row.\n    event_id : dict\n        The event dictionary corresponding to the new events array. This will\n        be identical to the input dictionary unless ``row_events`` is supplied,\n        in which case it will only contain the events provided there.\n\n    Notes\n    -----\n    The time window used for metadata generation need not correspond to the\n    time window used to create the `~mne.Epochs`, to which the metadata will\n    be attached; it may well be much shorter or longer, or not overlap at all,\n    if desired. This can be useful, for example, to include events that\n    occurred before or after an epoch, e.g. during the inter-trial interval.\n    If either ``tmin``, ``tmax``, or both are ``None``, or a string referring e.g. to a\n    response event, the time window will typically vary, too.\n\n    .. versionadded:: 0.23\n\n    References\n    ----------\n    .. footbibliography::\n    \"\"\"\n    pd = _check_pandas_installed()\n\n    _validate_type(events, types=(\"array-like\",), item_name=\"events\")\n    _validate_type(event_id, types=(dict,), item_name=\"event_id\")\n    _validate_type(sfreq, types=(\"numeric\",), item_name=\"sfreq\")\n    _validate_type(tmin, types=(\"numeric\", str, \"array-like\", None), item_name=\"tmin\")\n    _validate_type(tmax, types=(\"numeric\", str, \"array-like\", None), item_name=\"tmax\")\n    _validate_type(row_events, types=(None, str, \"array-like\"), item_name=\"row_events\")\n    _validate_type(keep_first, types=(None, str, \"array-like\"), item_name=\"keep_first\")\n    _validate_type(keep_last, types=(None, str, \"array-like\"), item_name=\"keep_last\")\n\n    if not event_id:\n        raise ValueError(\"event_id dictionary must contain at least one entry\")\n\n    def _ensure_list(x):\n        if x is None:\n            return []\n        elif isinstance(x, str):\n            return [x]\n        else:\n            return list(x)\n\n    row_events = _ensure_list(row_events)\n    keep_first = _ensure_list(keep_first)\n    keep_last = _ensure_list(keep_last)\n\n    # Turn tmin, tmax into a list if they're strings or arrays of strings\n    try:\n        _validate_type(tmin, types=(str, \"array-like\"), item_name=\"tmin\")\n        tmin = _ensure_list(tmin)\n    except TypeError:\n        pass\n\n    try:\n        _validate_type(tmax, types=(str, \"array-like\"), item_name=\"tmax\")\n        tmax = _ensure_list(tmax)\n    except TypeError:\n        pass\n\n    keep_first_and_last = set(keep_first) & set(keep_last)\n    if keep_first_and_last:\n        raise ValueError(\n            f\"The event names in keep_first and keep_last must \"\n            f\"be mutually exclusive. Specified in both: \"\n            f\"{', '.join(sorted(keep_first_and_last))}\"\n        )\n    del keep_first_and_last\n\n    for param_name, values in dict(keep_first=keep_first, keep_last=keep_last).items():\n        for first_last_event_name in values:\n            try:\n                match_event_names(event_id, [first_last_event_name])\n            except KeyError:\n                raise ValueError(\n                    f'Event \"{first_last_event_name}\", specified in '\n                    f\"{param_name}, cannot be found in event_id dictionary\"\n                )\n\n    # If tmin, tmax are strings, ensure these event names are present in event_id\n    def _diff_input_strings_vs_event_id(input_strings, input_name, event_id):\n        event_name_diff = sorted(set(input_strings) - set(event_id.keys()))\n        if event_name_diff:\n            raise ValueError(\n                f\"Present in {input_name}, but missing from event_id: \"\n                f\"{', '.join(event_name_diff)}\"\n            )\n\n    _diff_input_strings_vs_event_id(\n        input_strings=row_events, input_name=\"row_events\", event_id=event_id\n    )\n    if isinstance(tmin, list):\n        _diff_input_strings_vs_event_id(\n            input_strings=tmin, input_name=\"tmin\", event_id=event_id\n        )\n    if isinstance(tmax, list):\n        _diff_input_strings_vs_event_id(\n            input_strings=tmax, input_name=\"tmax\", event_id=event_id\n        )\n\n    # First and last sample of each epoch, relative to the time-locked event\n    # This follows the approach taken in mne.Epochs\n    # For strings and None, we don't know the start and stop samples in advance as the\n    # time window can vary.\n    if isinstance(tmin, type(None) | list):\n        start_sample = None\n    else:\n        start_sample = int(round(tmin * sfreq))\n\n    if isinstance(tmax, type(None) | list):\n        stop_sample = None\n    else:\n        stop_sample = int(round(tmax * sfreq)) + 1\n\n    # Make indexing easier\n    # We create the DataFrame before subsetting the events so we end up with\n    # indices corresponding to the original event indices. Not used for now,\n    # but might come in handy sometime later\n    events_df = pd.DataFrame(events, columns=(\"sample\", \"prev_id\", \"id\"))\n    id_to_name_map = {v: k for k, v in event_id.items()}\n\n    # Only keep events that are of interest\n    events = events[np.isin(events[:, 2], list(event_id.values()))]\n    events_df = events_df.loc[events_df[\"id\"].isin(event_id.values()), :]\n\n    # Prepare & condition the metadata DataFrame\n\n    # Avoid column name duplications if the exact same event name appears in\n    # event_id.keys() and keep_first / keep_last simultaneously\n    keep_first_cols = [col for col in keep_first if col not in event_id]\n    keep_last_cols = [col for col in keep_last if col not in event_id]\n    first_cols = [f\"first_{col}\" for col in keep_first_cols]\n    last_cols = [f\"last_{col}\" for col in keep_last_cols]\n\n    columns = [\n        \"event_name\",\n        *event_id.keys(),\n        *keep_first_cols,\n        *keep_last_cols,\n        *first_cols,\n        *last_cols,\n    ]\n\n    data = np.empty((len(events_df), len(columns)), float)\n    metadata = pd.DataFrame(data=data, columns=columns, index=events_df.index)\n\n    # Event names\n    metadata[\"event_name\"] = \"\"\n\n    # Event times\n    start_idx = 1\n    stop_idx = start_idx + len(event_id.keys()) + len(keep_first_cols + keep_last_cols)\n    metadata.iloc[:, start_idx:stop_idx] = np.nan\n\n    # keep_first and keep_last names\n    start_idx = stop_idx\n    metadata[columns[start_idx:]] = None\n\n    # We're all set, let's iterate over all events and fill in in the\n    # respective cells in the metadata. We will subset this to include only\n    # `row_events` later\n    for row_event in events_df.itertuples(name=\"RowEvent\"):\n        row_idx = row_event.Index\n        metadata.loc[row_idx, \"event_name\"] = id_to_name_map[row_event.id]\n\n        # Determine which events fall into the current time window\n        if start_sample is None and isinstance(tmin, list):\n            # Lower bound is the the current or the closest previpus event with a name\n            # in \"tmin\"; if there is no such event (e.g., beginning of the recording is\n            # being approached), the upper lower becomes the last event in the\n            # recording.\n            prev_matching_events = events_df.loc[\n                (events_df[\"sample\"] <= row_event.sample)\n                & (events_df[\"id\"].isin([event_id[name] for name in tmin])),\n                :,\n            ]\n            if prev_matching_events.size == 0:\n                # No earlier matching event. Use the current one as the beginning of the\n                # time window. This may occur at the beginning of a recording.\n                window_start_sample = row_event.sample\n            else:\n                # At least one earlier matching event. Use the closest one.\n                window_start_sample = prev_matching_events.iloc[-1][\"sample\"]\n        elif start_sample is None:\n            # Lower bound is the current event.\n            window_start_sample = row_event.sample\n        else:\n            # Lower bound is determined by tmin.\n            window_start_sample = row_event.sample + start_sample\n\n        if stop_sample is None and isinstance(tmax, list):\n            # Upper bound is the the current or the closest following event with a name\n            # in \"tmax\"; if there is no such event (e.g., end of the recording is being\n            # approached), the upper bound becomes the last event in the recording.\n            next_matching_events = events_df.loc[\n                (events_df[\"sample\"] >= row_event.sample)\n                & (events_df[\"id\"].isin([event_id[name] for name in tmax])),\n                :,\n            ]\n            if next_matching_events.size == 0:\n                # No matching event after the current one; use the end of the recording\n                # as upper bound. This may occur at the end of a recording.\n                window_stop_sample = events_df[\"sample\"].iloc[-1]\n            else:\n                # At least one matching later event. Use the closest one..\n                window_stop_sample = next_matching_events.iloc[0][\"sample\"]\n        elif stop_sample is None:\n            # Upper bound: next event of the same type, or the last event (of\n            # any type) if no later event of the same type can be found.\n            next_events = events_df.loc[\n                (events_df[\"sample\"] > row_event.sample),\n                :,\n            ]\n            if next_events.size == 0:\n                # We've reached the last event in the recording.\n                window_stop_sample = row_event.sample\n            elif next_events.loc[next_events[\"id\"] == row_event.id, :].size > 0:\n                # There's still an event of the same type appearing after the\n                # current event. Stop one sample short, we don't want to include that\n                # last event here, but in the next iteration.\n                window_stop_sample = (\n                    next_events.loc[next_events[\"id\"] == row_event.id, :].iloc[0][\n                        \"sample\"\n                    ]\n                    - 1\n                )\n            else:\n                # There are still events after the current one, but not of the\n                # same type.\n                window_stop_sample = next_events.iloc[-1][\"sample\"]\n        else:\n            # Upper bound is determined by tmax.\n            window_stop_sample = row_event.sample + stop_sample\n\n        events_in_window = events_df.loc[\n            (events_df[\"sample\"] >= window_start_sample)\n            & (events_df[\"sample\"] <= window_stop_sample),\n            :,\n        ]\n\n        assert not events_in_window.empty\n\n        # Store the metadata\n        for event in events_in_window.itertuples(name=\"Event\"):\n            event_sample = event.sample - row_event.sample\n            event_time = event_sample / sfreq\n            event_time = 0 if np.isclose(event_time, 0) else event_time\n            event_name = id_to_name_map[event.id]\n\n            if not np.isnan(metadata.loc[row_idx, event_name]):\n                # Event already exists in current time window!\n                assert metadata.loc[row_idx, event_name] <= event_time\n\n                if event_name not in keep_last:\n                    continue\n\n            metadata.loc[row_idx, event_name] = event_time\n\n            # Handle keep_first and keep_last event aggregation\n            for event_group_name in keep_first + keep_last:\n                if event_name not in match_event_names(event_id, [event_group_name]):\n                    continue\n\n                if event_group_name in keep_first:\n                    first_last_col = f\"first_{event_group_name}\"\n                else:\n                    first_last_col = f\"last_{event_group_name}\"\n\n                old_time = metadata.loc[row_idx, event_group_name]\n                if not np.isnan(old_time):\n                    if (event_group_name in keep_first and old_time <= event_time) or (\n                        event_group_name in keep_last and old_time >= event_time\n                    ):\n                        continue\n\n                if event_group_name not in event_id:\n                    # This is an HED. Strip redundant information from the\n                    # event name\n                    name = (\n                        event_name.replace(event_group_name, \"\")\n                        .replace(\"//\", \"/\")\n                        .strip(\"/\")\n                    )\n                    metadata.loc[row_idx, first_last_col] = name\n                    del name\n\n                metadata.loc[row_idx, event_group_name] = event_time\n\n    # Only keep rows of interest\n    if row_events:\n        event_id_timelocked = {\n            name: val for name, val in event_id.items() if name in row_events\n        }\n        events = events[np.isin(events[:, 2], list(event_id_timelocked.values()))]\n        metadata = metadata.loc[metadata[\"event_name\"].isin(event_id_timelocked)]\n        assert len(events) == len(metadata)\n        event_id = event_id_timelocked\n\n    return metadata, events, event_id", "metadata": {}}
{"_id": "mne_mne_epochs.py_combine_event_ids_code", "title": "combine_event_ids", "text": "def combine_event_ids(epochs, old_event_ids, new_event_id, copy=True):\n    \"\"\"Collapse event_ids from an epochs instance into a new event_id.\n\n    Parameters\n    ----------\n    epochs : instance of Epochs\n        The epochs to operate on.\n    old_event_ids : str, or list\n        Conditions to collapse together.\n    new_event_id : dict, or int\n        A one-element dict (or a single integer) for the new\n        condition. Note that for safety, this cannot be any\n        existing id (in epochs.event_id.values()).\n    copy : bool\n        Whether to return a new instance or modify in place.\n\n    Returns\n    -------\n    epochs : instance of Epochs\n        The modified epochs.\n\n    Notes\n    -----\n    This For example (if epochs.event_id was ``{'Left': 1, 'Right': 2}``::\n\n        combine_event_ids(epochs, ['Left', 'Right'], {'Directional': 12})\n\n    would create a 'Directional' entry in epochs.event_id replacing\n    'Left' and 'Right' (combining their trials).\n    \"\"\"\n    epochs = epochs.copy() if copy else epochs\n    old_event_ids = np.asanyarray(old_event_ids)\n    if isinstance(new_event_id, int):\n        new_event_id = {str(new_event_id): new_event_id}\n    else:\n        if not isinstance(new_event_id, dict):\n            raise ValueError(\"new_event_id must be a dict or int\")\n        if not len(list(new_event_id.keys())) == 1:\n            raise ValueError(\"new_event_id dict must have one entry\")\n    new_event_num = list(new_event_id.values())[0]\n    new_event_num = operator.index(new_event_num)\n    if new_event_num in epochs.event_id.values():\n        raise ValueError(\"new_event_id value must not already exist\")\n    # could use .pop() here, but if a latter one doesn't exist, we're\n    # in trouble, so run them all here and pop() later\n    old_event_nums = np.array([epochs.event_id[key] for key in old_event_ids])\n    # find the ones to replace\n    inds = np.any(\n        epochs.events[:, 2][:, np.newaxis] == old_event_nums[np.newaxis, :], axis=1\n    )\n    # replace the event numbers in the events list\n    epochs.events[inds, 2] = new_event_num\n    # delete old entries\n    for key in old_event_ids:\n        epochs.event_id.pop(key)\n    # add the new entry\n    epochs.event_id.update(new_event_id)\n    return epochs", "metadata": {}}
{"_id": "mne_mne_epochs.py_equalize_epoch_counts_code", "title": "equalize_epoch_counts", "text": "def equalize_epoch_counts(epochs_list, method=\"mintime\", *, random_state=None):\n    \"\"\"Equalize the number of trials in multiple Epochs or EpochsTFR instances.\n\n    Parameters\n    ----------\n    epochs_list : list of Epochs instances\n        The Epochs instances to equalize trial counts for.\n    %(equalize_events_method)s\n    %(random_state)s Used only if ``method='random'``.\n\n    Notes\n    -----\n    The method ``'mintime'`` tries to make the remaining epochs occurring as close as\n    possible in time. This method is motivated by the possibility that if there happened\n    to be some time-varying (like on the scale of minutes) noise characteristics during\n    a recording, they could be compensated for (to some extent) in the\n    equalization process. This method thus seeks to reduce any of those effects\n    by minimizing the differences in the times of the events in the two sets of\n    epochs. For example, if one had event times [1, 2, 3, 4, 120, 121] and the\n    other one had [3.5, 4.5, 120.5, 121.5], it would remove events at times\n    [1, 2] in the first epochs and not [120, 121].\n\n    Examples\n    --------\n    >>> equalize_epoch_counts([epochs1, epochs2])  # doctest: +SKIP\n    \"\"\"\n    if not all(isinstance(epoch, BaseEpochs | EpochsTFR) for epoch in epochs_list):\n        raise ValueError(\"All inputs must be Epochs instances\")\n    # make sure bad epochs are dropped\n    for epoch in epochs_list:\n        if not epoch._bad_dropped:\n            epoch.drop_bad()\n    sample_nums = [epoch.events[:, 0] for epoch in epochs_list]\n    indices = _get_drop_indices(sample_nums, method, random_state)\n    for epoch, inds in zip(epochs_list, indices):\n        epoch.drop(inds, reason=\"EQUALIZED_COUNT\")", "metadata": {}}
{"_id": "mne_mne_epochs.py_read_epochs_code", "title": "read_epochs", "text": "def read_epochs(fname, proj=True, preload=True, verbose=None) -> \"EpochsFIF\":\n    \"\"\"Read epochs from a fif file.\n\n    Parameters\n    ----------\n    %(fname_epochs)s\n    %(proj_epochs)s\n    preload : bool\n        If True, read all epochs from disk immediately. If ``False``, epochs\n        will be read on demand.\n    %(verbose)s\n\n    Returns\n    -------\n    epochs : instance of Epochs\n        The epochs.\n    \"\"\"\n    return EpochsFIF(fname, proj, preload, verbose)", "metadata": {}}
{"_id": "mne_mne_epochs.py_bootstrap_code", "title": "bootstrap", "text": "def bootstrap(epochs, random_state=None):\n    \"\"\"Compute epochs selected by bootstrapping.\n\n    Parameters\n    ----------\n    epochs : Epochs instance\n        epochs data to be bootstrapped\n    %(random_state)s\n\n    Returns\n    -------\n    epochs : Epochs instance\n        The bootstrap samples\n    \"\"\"\n    if not epochs.preload:\n        raise RuntimeError(\n            \"Modifying data of epochs is only supported \"\n            \"when preloading is used. Use preload=True \"\n            \"in the constructor.\"\n        )\n\n    rng = check_random_state(random_state)\n    epochs_bootstrap = epochs.copy()\n    n_events = len(epochs_bootstrap.events)\n    idx = rng_uniform(rng)(0, n_events, n_events)\n    epochs_bootstrap = epochs_bootstrap[idx]\n    return epochs_bootstrap", "metadata": {}}
{"_id": "mne_mne_epochs.py_concatenate_epochs_code", "title": "concatenate_epochs", "text": "def concatenate_epochs(\n    epochs_list, add_offset=True, *, on_mismatch=\"raise\", verbose=None\n):\n    \"\"\"Concatenate a list of `~mne.Epochs` into one `~mne.Epochs` object.\n\n    .. note:: Unlike `~mne.concatenate_raws`, this function does **not**\n              modify any of the input data.\n\n    Parameters\n    ----------\n    epochs_list : list\n        List of `~mne.Epochs` instances to concatenate (in that order).\n    add_offset : bool\n        If True, a fixed offset is added to the event times from different\n        Epochs sets, such that they are easy to distinguish after the\n        concatenation.\n        If False, the event times are unaltered during the concatenation.\n    %(on_mismatch_info)s\n    %(verbose)s\n\n        .. versionadded:: 0.24\n\n    Returns\n    -------\n    epochs : instance of EpochsArray\n        The result of the concatenation. All data will be loaded into memory.\n\n    Notes\n    -----\n    .. versionadded:: 0.9.0\n    \"\"\"\n    (\n        info,\n        data,\n        raw_sfreq,\n        events,\n        event_id,\n        tmin,\n        tmax,\n        metadata,\n        baseline,\n        selection,\n        drop_log,\n    ) = _concatenate_epochs(\n        epochs_list,\n        with_data=True,\n        add_offset=add_offset,\n        on_mismatch=on_mismatch,\n    )\n    selection = np.where([len(d) == 0 for d in drop_log])[0]\n    out = EpochsArray(\n        data=data,\n        info=info,\n        events=events,\n        event_id=event_id,\n        tmin=tmin,\n        baseline=baseline,\n        selection=selection,\n        drop_log=drop_log,\n        proj=False,\n        on_missing=\"ignore\",\n        metadata=metadata,\n        raw_sfreq=raw_sfreq,\n    )\n    out.drop_bad()\n    return out", "metadata": {}}
{"_id": "mne_mne_epochs.py_average_movements_code", "title": "average_movements", "text": "def average_movements(\n    epochs,\n    head_pos=None,\n    orig_sfreq=None,\n    picks=None,\n    origin=\"auto\",\n    weight_all=True,\n    int_order=8,\n    ext_order=3,\n    destination=None,\n    ignore_ref=False,\n    return_mapping=False,\n    mag_scale=100.0,\n    verbose=None,\n):\n    \"\"\"Average data using Maxwell filtering, transforming using head positions.\n\n    Parameters\n    ----------\n    epochs : instance of Epochs\n        The epochs to operate on.\n    %(head_pos_maxwell)s\n    orig_sfreq : float | None\n        The original sample frequency of the data (that matches the\n        event sample numbers in ``epochs.events``). Can be ``None``\n        if data have not been decimated or resampled.\n    %(picks_all_data)s\n    %(origin_maxwell)s\n    weight_all : bool\n        If True, all channels are weighted by the SSS basis weights.\n        If False, only MEG channels are weighted, other channels\n        receive uniform weight per epoch.\n    %(int_order_maxwell)s\n    %(ext_order_maxwell)s\n    %(destination_maxwell_dest)s\n    %(ignore_ref_maxwell)s\n    return_mapping : bool\n        If True, return the mapping matrix.\n    %(mag_scale_maxwell)s\n\n        .. versionadded:: 0.13\n    %(verbose)s\n\n    Returns\n    -------\n    evoked : instance of Evoked\n        The averaged epochs.\n\n    See Also\n    --------\n    mne.preprocessing.maxwell_filter\n    mne.chpi.read_head_pos\n\n    Notes\n    -----\n    The Maxwell filtering version of this algorithm is described in [1]_,\n    in section V.B \"Virtual signals and movement correction\", equations\n    40-44. For additional validation, see [2]_.\n\n    Regularization has not been added because in testing it appears to\n    decrease dipole localization accuracy relative to using all components.\n    Fine calibration and cross-talk cancellation, however, could be added\n    to this algorithm based on user demand.\n\n    .. versionadded:: 0.11\n\n    References\n    ----------\n    .. [1] Taulu S. and Kajola M. \"Presentation of electromagnetic\n           multichannel data: The signal space separation method,\"\n           Journal of Applied Physics, vol. 97, pp. 124905 1-10, 2005.\n    .. [2] Wehner DT, H\u00e4m\u00e4l\u00e4inen MS, Mody M, Ahlfors SP. \"Head movements\n           of children in MEG: Quantification, effects on source\n           estimation, and compensation. NeuroImage 40:541\u2013550, 2008.\n    \"\"\"  # noqa: E501\n    from .preprocessing.maxwell import (\n        _check_destination,\n        _check_usable,\n        _col_norm_pinv,\n        _get_coil_scale,\n        _get_mf_picks_fix_mags,\n        _get_n_moments,\n        _get_sensor_operator,\n        _prep_mf_coils,\n        _remove_meg_projs_comps,\n        _reset_meg_bads,\n        _trans_sss_basis,\n    )\n\n    if head_pos is None:\n        raise TypeError(\"head_pos must be provided and cannot be None\")\n    from .chpi import head_pos_to_trans_rot_t\n\n    if not isinstance(epochs, BaseEpochs):\n        raise TypeError(f\"epochs must be an instance of Epochs, not {type(epochs)}\")\n    orig_sfreq = epochs.info[\"sfreq\"] if orig_sfreq is None else orig_sfreq\n    orig_sfreq = float(orig_sfreq)\n    if isinstance(head_pos, np.ndarray):\n        head_pos = head_pos_to_trans_rot_t(head_pos)\n    trn, rot, t = head_pos\n    del head_pos\n    _check_usable(epochs, ignore_ref)\n    origin = _check_origin(origin, epochs.info, \"head\")\n    recon_trans = _check_destination(destination, epochs.info, \"head\")\n\n    logger.info(f\"Aligning and averaging up to {len(epochs.events)} epochs\")\n    if not np.array_equal(epochs.events[:, 0], np.unique(epochs.events[:, 0])):\n        raise RuntimeError(\"Epochs must have monotonically increasing events\")\n    info_to = epochs.info.copy()\n    meg_picks, mag_picks, grad_picks, good_mask, _ = _get_mf_picks_fix_mags(\n        info_to, int_order, ext_order, ignore_ref\n    )\n    coil_scale, mag_scale = _get_coil_scale(\n        meg_picks, mag_picks, grad_picks, mag_scale, info_to\n    )\n    mult = _get_sensor_operator(epochs, meg_picks)\n    n_channels, n_times = len(epochs.ch_names), len(epochs.times)\n    other_picks = np.setdiff1d(np.arange(n_channels), meg_picks)\n    data = np.zeros((n_channels, n_times))\n    count = 0\n    # keep only MEG w/bad channels marked in \"info_from\"\n    info_from = pick_info(info_to, meg_picks[good_mask], copy=True)\n    all_coils_recon = _prep_mf_coils(info_to, ignore_ref=ignore_ref)\n    all_coils = _prep_mf_coils(info_from, ignore_ref=ignore_ref)\n    # remove MEG bads in \"to\" info\n    _reset_meg_bads(info_to)\n    # set up variables\n    w_sum = 0.0\n    n_in, n_out = _get_n_moments([int_order, ext_order])\n    S_decomp = 0.0  # this will end up being a weighted average\n    last_trans = None\n    decomp_coil_scale = coil_scale[good_mask]\n    exp = dict(int_order=int_order, ext_order=ext_order, head_frame=True, origin=origin)\n    n_in = _get_n_moments(int_order)\n    for ei, epoch in enumerate(epochs):\n        event_time = epochs.events[epochs._current - 1, 0] / orig_sfreq\n        use_idx = np.where(t <= event_time)[0]\n        if len(use_idx) == 0:\n            trans = info_to[\"dev_head_t\"][\"trans\"]\n        else:\n            use_idx = use_idx[-1]\n            trans = np.vstack(\n                [np.hstack([rot[use_idx], trn[[use_idx]].T]), [[0.0, 0.0, 0.0, 1.0]]]\n            )\n        loc_str = \", \".join(f\"{tr:0.1f}\" for tr in (trans[:3, 3] * 1000))\n        if last_trans is None or not np.allclose(last_trans, trans):\n            logger.info(\n                f\"    Processing epoch {ei + 1} (device location: {loc_str} mm)\"\n            )\n            reuse = False\n            last_trans = trans\n        else:\n            logger.info(f\"    Processing epoch {ei + 1} (device location: same)\")\n            reuse = True\n        epoch = epoch.copy()  # because we operate inplace\n        if not reuse:\n            S = _trans_sss_basis(exp, all_coils, trans, coil_scale=decomp_coil_scale)\n            # Get the weight from the un-regularized version (eq. 44)\n            weight = np.linalg.norm(S[:, :n_in])\n            # XXX Eventually we could do cross-talk and fine-cal here\n            S *= weight\n        S_decomp += S  # eq. 41\n        epoch[slice(None) if weight_all else meg_picks] *= weight\n        data += epoch  # eq. 42\n        w_sum += weight\n        count += 1\n    del info_from\n    mapping = None\n    if count == 0:\n        data.fill(np.nan)\n    else:\n        data[meg_picks] /= w_sum\n        data[other_picks] /= w_sum if weight_all else count\n        # Finalize weighted average decomp matrix\n        S_decomp /= w_sum\n        # Get recon matrix\n        # (We would need to include external here for regularization to work)\n        exp[\"ext_order\"] = 0\n        S_recon = _trans_sss_basis(exp, all_coils_recon, recon_trans)\n        if mult is not None:\n            S_decomp = mult @ S_decomp\n            S_recon = mult @ S_recon\n        exp[\"ext_order\"] = ext_order\n        # We could determine regularization on basis of destination basis\n        # matrix, restricted to good channels, as regularizing individual\n        # matrices within the loop above does not seem to work. But in\n        # testing this seemed to decrease localization quality in most cases,\n        # so we do not provide the option here.\n        S_recon /= coil_scale\n        # Invert\n        pS_ave = _col_norm_pinv(S_decomp)[0][:n_in]\n        pS_ave *= decomp_coil_scale.T\n        # Get mapping matrix\n        mapping = np.dot(S_recon, pS_ave)\n        # Apply mapping\n        data[meg_picks] = np.dot(mapping, data[meg_picks[good_mask]])\n    info_to[\"dev_head_t\"] = recon_trans  # set the reconstruction transform\n    evoked = epochs._evoked_from_epoch_data(\n        data, info_to, picks, n_events=count, kind=\"average\", comment=epochs._name\n    )\n    _remove_meg_projs_comps(evoked, ignore_ref)\n    logger.info(f\"Created Evoked dataset from {count} epochs\")\n    return (evoked, mapping) if return_mapping else evoked", "metadata": {}}
{"_id": "mne_mne_epochs.py_make_fixed_length_epochs_code", "title": "make_fixed_length_epochs", "text": "def make_fixed_length_epochs(\n    raw,\n    duration=1.0,\n    preload=False,\n    reject_by_annotation=True,\n    proj=True,\n    overlap=0.0,\n    id=1,  # noqa: A002\n    verbose=None,\n):\n    \"\"\"Divide continuous raw data into equal-sized consecutive epochs.\n\n    Parameters\n    ----------\n    raw : instance of Raw\n        Raw data to divide into segments.\n    duration : float\n        Duration of each epoch in seconds. Defaults to 1.\n    %(preload)s\n    %(reject_by_annotation_epochs)s\n\n        .. versionadded:: 0.21.0\n    %(proj_epochs)s\n\n        .. versionadded:: 0.22.0\n    overlap : float\n        The overlap between epochs, in seconds. Must be\n        ``0 <= overlap < duration``. Default is 0, i.e., no overlap.\n\n        .. versionadded:: 0.23.0\n    id : int\n        The id to use (default 1).\n\n        .. versionadded:: 0.24.0\n    %(verbose)s\n\n    Returns\n    -------\n    epochs : instance of Epochs\n        Segmented data.\n\n    Notes\n    -----\n    .. versionadded:: 0.20\n    \"\"\"\n    events = make_fixed_length_events(raw, id=id, duration=duration, overlap=overlap)\n    delta = 1.0 / raw.info[\"sfreq\"]\n    return Epochs(\n        raw,\n        events,\n        event_id=[id],\n        tmin=0,\n        tmax=duration - delta,\n        baseline=None,\n        preload=preload,\n        reject_by_annotation=reject_by_annotation,\n        proj=proj,\n        verbose=verbose,\n    )", "metadata": {}}
{"_id": "mne_mne_epochs.py_reset_drop_log_selection_code", "title": "reset_drop_log_selection", "text": "def reset_drop_log_selection(self):\n        \"\"\"Reset the drop_log and selection entries.\n\n        This method will simplify ``self.drop_log`` and ``self.selection``\n        so that they are meaningless (tuple of empty tuples and increasing\n        integers, respectively). This can be useful when concatenating\n        many Epochs instances, as ``drop_log`` can accumulate many entries\n        which can become problematic when saving.\n        \"\"\"\n        self.selection = np.arange(len(self.events))\n        self.drop_log = (tuple(),) * len(self.events)\n        self._check_consistency()", "metadata": {}}
{"_id": "mne_mne_epochs.py_load_data_code", "title": "load_data", "text": "def load_data(self):\n        \"\"\"Load the data if not already preloaded.\n\n        Returns\n        -------\n        epochs : instance of Epochs\n            The epochs object.\n\n        Notes\n        -----\n        This function operates in-place.\n\n        .. versionadded:: 0.10.0\n        \"\"\"\n        if self.preload:\n            return self\n        self._data = self._get_data()\n        self.preload = True\n        self._do_baseline = False\n        self._decim_slice = slice(None, None, None)\n        self._decim = 1\n        self._raw_times = self.times\n        assert self._data.shape[-1] == len(self.times)\n        self._raw = None  # shouldn't need it anymore\n        return self", "metadata": {}}
{"_id": "mne_mne_epochs.py_apply_baseline_code", "title": "apply_baseline", "text": "def apply_baseline(self, baseline=(None, 0), *, verbose=None):\n        \"\"\"Baseline correct epochs.\n\n        Parameters\n        ----------\n        %(baseline_epochs)s\n            Defaults to ``(None, 0)``, i.e. beginning of the the data until\n            time point zero.\n        %(verbose)s\n\n        Returns\n        -------\n        epochs : instance of Epochs\n            The baseline-corrected Epochs object.\n\n        Notes\n        -----\n        Baseline correction can be done multiple times, but can never be\n        reverted once the data has been loaded.\n\n        .. versionadded:: 0.10.0\n        \"\"\"\n        baseline = _check_baseline(baseline, times=self.times, sfreq=self.info[\"sfreq\"])\n\n        if self.preload:\n            if self.baseline is not None and baseline is None:\n                raise RuntimeError(\n                    \"You cannot remove baseline correction \"\n                    \"from preloaded data once it has been \"\n                    \"applied.\"\n                )\n            self._do_baseline = True\n            picks = self._detrend_picks\n            rescale(self._data, self.times, baseline, copy=False, picks=picks)\n            self._do_baseline = False\n        else:  # logging happens in \"rescale\" in \"if\" branch\n            logger.info(_log_rescale(baseline))\n            # For EpochsArray and Epochs, this is already True:\n            # assert self._do_baseline is True\n            # ... but for EpochsFIF it's not, so let's set it explicitly\n            self._do_baseline = True\n        self.baseline = baseline\n        return self", "metadata": {}}
{"_id": "mne_mne_epochs.py_iter_evoked_code", "title": "iter_evoked", "text": "def iter_evoked(self, copy=False):\n        \"\"\"Iterate over epochs as a sequence of Evoked objects.\n\n        The Evoked objects yielded will each contain a single epoch (i.e., no\n        averaging is performed).\n\n        This method resets the object iteration state to the first epoch.\n\n        Parameters\n        ----------\n        copy : bool\n            If False copies of data and measurement info will be omitted\n            to save time.\n        \"\"\"\n        self.__iter__()\n\n        while True:\n            try:\n                out = self.__next__(True)\n            except StopIteration:\n                break\n            data, event_id = out\n            tmin = self.times[0]\n            info = self.info\n            if copy:\n                info = deepcopy(self.info)\n                data = data.copy()\n\n            yield EvokedArray(data, info, tmin, comment=str(event_id))", "metadata": {}}
{"_id": "mne_mne_epochs.py_subtract_evoked_code", "title": "subtract_evoked", "text": "def subtract_evoked(self, evoked=None):\n        \"\"\"Subtract an evoked response from each epoch.\n\n        Can be used to exclude the evoked response when analyzing induced\n        activity, see e.g. [1]_.\n\n        Parameters\n        ----------\n        evoked : instance of Evoked | None\n            The evoked response to subtract. If None, the evoked response\n            is computed from Epochs itself.\n\n        Returns\n        -------\n        self : instance of Epochs\n            The modified instance (instance is also modified inplace).\n\n        References\n        ----------\n        .. [1] David et al. \"Mechanisms of evoked and induced responses in\n               MEG/EEG\", NeuroImage, vol. 31, no. 4, pp. 1580-1591, July 2006.\n        \"\"\"\n        logger.info(\"Subtracting Evoked from Epochs\")\n        if evoked is None:\n            picks = _pick_data_channels(self.info, exclude=[])\n            evoked = self.average(picks)\n\n        # find the indices of the channels to use\n        picks = pick_channels(evoked.ch_names, include=self.ch_names, ordered=False)\n\n        # make sure the omitted channels are not data channels\n        if len(picks) < len(self.ch_names):\n            sel_ch = [evoked.ch_names[ii] for ii in picks]\n            diff_ch = list(set(self.ch_names).difference(sel_ch))\n            diff_idx = [self.ch_names.index(ch) for ch in diff_ch]\n            diff_types = [channel_type(self.info, idx) for idx in diff_idx]\n            bad_idx = [\n                diff_types.index(t) for t in diff_types if t in _DATA_CH_TYPES_SPLIT\n            ]\n            if len(bad_idx) > 0:\n                bad_str = \", \".join([diff_ch[ii] for ii in bad_idx])\n                raise ValueError(\n                    \"The following data channels are missing \"\n                    f\"in the evoked response: {bad_str}\"\n                )\n            logger.info(\n                \"    The following channels are not included in the subtraction: \"\n                + \", \".join(diff_ch)\n            )\n\n        # make sure the times match\n        if (\n            len(self.times) != len(evoked.times)\n            or np.max(np.abs(self.times - evoked.times)) >= 1e-7\n        ):\n            raise ValueError(\n                \"Epochs and Evoked object do not contain the same time points.\"\n            )\n\n        # handle SSPs\n        if not self.proj and evoked.proj:\n            warn(\"Evoked has SSP applied while Epochs has not.\")\n        if self.proj and not evoked.proj:\n            evoked = evoked.copy().apply_proj()\n\n        # find the indices of the channels to use in Epochs\n        ep_picks = [self.ch_names.index(evoked.ch_names[ii]) for ii in picks]\n\n        # do the subtraction\n        if self.preload:\n            self._data[:, ep_picks, :] -= evoked.data[picks][None, :, :]\n        else:\n            if self._offset is None:\n                self._offset = np.zeros(\n                    (len(self.ch_names), len(self.times)), dtype=np.float64\n                )\n            self._offset[ep_picks] -= evoked.data[picks]\n        logger.info(\"[done]\")\n\n        return self", "metadata": {}}
{"_id": "mne_mne_epochs.py_average_code", "title": "average", "text": "def average(self, picks=None, method=\"mean\", by_event_type=False):\n        \"\"\"Compute an average over epochs.\n\n        Parameters\n        ----------\n        %(picks_all_data)s\n        method : str | callable\n            How to combine the data. If \"mean\"/\"median\", the mean/median\n            are returned.\n            Otherwise, must be a callable which, when passed an array of shape\n            (n_epochs, n_channels, n_time) returns an array of shape\n            (n_channels, n_time).\n            Note that due to file type limitations, the kind for all\n            these will be \"average\".\n        %(by_event_type)s\n\n        Returns\n        -------\n        %(evoked_by_event_type_returns)s\n\n        Notes\n        -----\n        Computes an average of all epochs in the instance, even if\n        they correspond to different conditions. To average by condition,\n        do ``epochs[condition].average()`` for each condition separately.\n\n        When picks is None and epochs contain only ICA channels, no channels\n        are selected, resulting in an error. This is because ICA channels\n        are not considered data channels (they are of misc type) and only data\n        channels are selected when picks is None.\n\n        The ``method`` parameter allows e.g. robust averaging.\n        For example, one could do:\n\n            >>> from scipy.stats import trim_mean  # doctest:+SKIP\n            >>> trim = lambda x: trim_mean(x, 0.1, axis=0)  # doctest:+SKIP\n            >>> epochs.average(method=trim)  # doctest:+SKIP\n\n        This would compute the trimmed mean.\n        \"\"\"\n        self._handle_empty(\"raise\", \"average\")\n        if by_event_type:\n            evokeds = list()\n            for event_type in self.event_id.keys():\n                ev = self[event_type]._compute_aggregate(picks=picks, mode=method)\n                ev.comment = event_type\n                evokeds.append(ev)\n        else:\n            evokeds = self._compute_aggregate(picks=picks, mode=method)\n        return evokeds", "metadata": {}}
{"_id": "mne_mne_epochs.py_standard_error_code", "title": "standard_error", "text": "def standard_error(self, picks=None, by_event_type=False):\n        \"\"\"Compute standard error over epochs.\n\n        Parameters\n        ----------\n        %(picks_all_data)s\n        %(by_event_type)s\n\n        Returns\n        -------\n        %(std_err_by_event_type_returns)s\n        \"\"\"\n        return self.average(picks=picks, method=\"std\", by_event_type=by_event_type)", "metadata": {}}
{"_id": "mne_mne_epochs.py_ch_names_code", "title": "ch_names", "text": "def ch_names(self):\n        \"\"\"Channel names.\"\"\"\n        return self.info[\"ch_names\"]", "metadata": {}}
{"_id": "mne_mne_epochs.py_drop_bad_code", "title": "drop_bad", "text": "def drop_bad(self, reject=\"existing\", flat=\"existing\", verbose=None):\n        \"\"\"Drop bad epochs without retaining the epochs data.\n\n        Should be used before slicing operations.\n\n        .. warning:: This operation is slow since all epochs have to be read\n                     from disk. To avoid reading epochs from disk multiple\n                     times, use :meth:`mne.Epochs.load_data()`.\n\n        .. note:: To constrain the time period used for estimation of signal\n                  quality, set ``epochs.reject_tmin`` and\n                  ``epochs.reject_tmax``, respectively.\n\n        Parameters\n        ----------\n        %(reject_drop_bad)s\n        %(flat_drop_bad)s\n        %(verbose)s\n\n        Returns\n        -------\n        epochs : instance of Epochs\n            The epochs with bad epochs dropped. Operates in-place.\n\n        Notes\n        -----\n        Dropping bad epochs can be done multiple times with different\n        ``reject`` and ``flat`` parameters. However, once an epoch is\n        dropped, it is dropped forever, so if more lenient thresholds may\n        subsequently be applied, :meth:`epochs.copy <mne.Epochs.copy>` should be\n        used.\n        \"\"\"\n        if reject == \"existing\":\n            if flat == \"existing\" and self._bad_dropped:\n                return\n            reject = self.reject\n        if flat == \"existing\":\n            flat = self.flat\n        if any(isinstance(rej, str) and rej != \"existing\" for rej in (reject, flat)):\n            raise ValueError('reject and flat, if strings, must be \"existing\"')\n        self._reject_setup(reject, flat, allow_callable=True)\n        self._get_data(out=False, verbose=verbose)\n        return self", "metadata": {}}
{"_id": "mne_mne_epochs.py_drop_log_stats_code", "title": "drop_log_stats", "text": "def drop_log_stats(self, ignore=(\"IGNORED\",)):\n        \"\"\"Compute the channel stats based on a drop_log from Epochs.\n\n        Parameters\n        ----------\n        ignore : list\n            The drop reasons to ignore.\n\n        Returns\n        -------\n        perc : float\n            Total percentage of epochs dropped.\n\n        See Also\n        --------\n        plot_drop_log\n        \"\"\"\n        return _drop_log_stats(self.drop_log, ignore)", "metadata": {}}
{"_id": "mne_mne_epochs.py_drop_code", "title": "drop", "text": "def drop(self, indices, reason=\"USER\", verbose=None):\n        \"\"\"Drop epochs based on indices or boolean mask.\n\n        .. note:: The indices refer to the current set of undropped epochs\n                  rather than the complete set of dropped and undropped epochs.\n                  They are therefore not necessarily consistent with any\n                  external indices (e.g., behavioral logs). To drop epochs\n                  based on external criteria, do not use the ``preload=True``\n                  flag when constructing an Epochs object, and call this\n                  method before calling the :meth:`mne.Epochs.drop_bad` or\n                  :meth:`mne.Epochs.load_data` methods.\n\n        Parameters\n        ----------\n        indices : array of int or bool\n            Set epochs to remove by specifying indices to remove or a boolean\n            mask to apply (where True values get removed). Events are\n            correspondingly modified.\n        reason : list | tuple | str\n            Reason(s) for dropping the epochs ('ECG', 'timeout', 'blink' etc).\n            Reason(s) are applied to all indices specified.\n            Default: 'USER'.\n        %(verbose)s\n\n        Returns\n        -------\n        epochs : instance of Epochs\n            The epochs with indices dropped. Operates in-place.\n        \"\"\"\n        indices = np.atleast_1d(indices)\n\n        if indices.ndim > 1:\n            raise TypeError(\"indices must be a scalar or a 1-d array\")\n        # Check if indices and reasons are of the same length\n        # if using collection to drop epochs\n\n        if indices.dtype == np.dtype(bool):\n            indices = np.where(indices)[0]\n        try_idx = np.where(indices < 0, indices + len(self.events), indices)\n\n        out_of_bounds = (try_idx < 0) | (try_idx >= len(self.events))\n        if out_of_bounds.any():\n            first = indices[out_of_bounds][0]\n            raise IndexError(f\"Epoch index {first} is out of bounds\")\n        keep = np.setdiff1d(np.arange(len(self.events)), try_idx)\n        self._getitem(keep, reason, copy=False, drop_event_id=False)\n        count = len(try_idx)\n        logger.info(\n            \"Dropped %d epoch%s: %s\",\n            count,\n            _pl(count),\n            \", \".join(map(str, np.sort(try_idx))),\n        )\n\n        return self", "metadata": {}}
{"_id": "mne_mne_epochs.py_get_data_code", "title": "get_data", "text": "def get_data(\n        self,\n        picks=None,\n        item=None,\n        units=None,\n        tmin=None,\n        tmax=None,\n        *,\n        copy=True,\n        verbose=None,\n    ):\n        \"\"\"Get all epochs as a 3D array.\n\n        Parameters\n        ----------\n        %(picks_all)s\n        item : slice | array-like | str | list | None\n            The items to get. See :meth:`mne.Epochs.__getitem__` for\n            a description of valid options. This can be substantially faster\n            for obtaining an ndarray than :meth:`~mne.Epochs.__getitem__`\n            for repeated access on large Epochs objects.\n            None (default) is an alias for ``slice(None)``.\n\n            .. versionadded:: 0.20\n        %(units)s\n\n            .. versionadded:: 0.24\n        tmin : int | float | None\n            Start time of data to get in seconds.\n\n            .. versionadded:: 0.24.0\n        tmax : int | float | None\n            End time of data to get in seconds.\n\n            .. versionadded:: 0.24.0\n        copy : bool\n            Whether to return a copy of the object's data, or (if possible) a view.\n            See :ref:`the NumPy docs <numpy:basics.copies-and-views>` for an\n            explanation. Default is ``False`` in 1.6 but will change to ``True`` in 1.7,\n            set it explicitly to avoid a warning in some cases. A view is only possible\n            when ``item is None``, ``picks is None``, ``units is None``, and data are\n            preloaded.\n\n            .. warning::\n               Using ``copy=False`` and then modifying the returned ``data`` will in\n               turn modify the Epochs object. Use with caution!\n\n            .. versionchanged:: 1.7\n               The default changed from ``False`` to ``True``.\n\n            .. versionadded:: 1.6\n        %(verbose)s\n\n        Returns\n        -------\n        data : array of shape (n_epochs, n_channels, n_times)\n            The epochs data. Will be a copy when ``copy=True`` and will be a view\n            when possible when ``copy=False``.\n        \"\"\"\n        return self._get_data(\n            picks=picks, item=item, units=units, tmin=tmin, tmax=tmax, copy=copy\n        )", "metadata": {}}
{"_id": "mne_mne_epochs.py_apply_function_code", "title": "apply_function", "text": "def apply_function(\n        self,\n        fun,\n        picks=None,\n        dtype=None,\n        n_jobs=None,\n        channel_wise=True,\n        verbose=None,\n        **kwargs,\n    ):\n        \"\"\"Apply a function to a subset of channels.\n\n        %(applyfun_summary_epochs)s\n\n        Parameters\n        ----------\n        %(fun_applyfun)s\n        %(picks_all_data_noref)s\n        %(dtype_applyfun)s\n        %(n_jobs)s Ignored if ``channel_wise=False`` as the workload\n            is split across channels.\n        %(channel_wise_applyfun_epo)s\n        %(verbose)s\n        %(kwargs_fun)s\n\n        Returns\n        -------\n        self : instance of Epochs\n            The epochs object with transformed data.\n        \"\"\"\n        _check_preload(self, \"epochs.apply_function\")\n        picks = _picks_to_idx(self.info, picks, exclude=(), with_ref_meg=False)\n\n        if not callable(fun):\n            raise ValueError(\"fun needs to be a function\")\n\n        data_in = self._data\n        if dtype is not None and dtype != self._data.dtype:\n            self._data = self._data.astype(dtype)\n\n        args = getfullargspec(fun).args + getfullargspec(fun).kwonlyargs\n        if channel_wise is False:\n            if (\"ch_idx\" in args) or (\"ch_name\" in args):\n                raise ValueError(\n                    \"apply_function cannot access ch_idx or ch_name \"\n                    \"when channel_wise=False\"\n                )\n        if \"ch_idx\" in args:\n            logger.info(\"apply_function requested to access ch_idx\")\n        if \"ch_name\" in args:\n            logger.info(\"apply_function requested to access ch_name\")\n\n        if channel_wise:\n            parallel, p_fun, n_jobs = parallel_func(_check_fun, n_jobs)\n            if n_jobs == 1:\n                _fun = partial(_check_fun, fun)\n                # modify data inplace to save memory\n                for ch_idx in picks:\n                    if \"ch_idx\" in args:\n                        kwargs.update(ch_idx=ch_idx)\n                    if \"ch_name\" in args:\n                        kwargs.update(ch_name=self.info[\"ch_names\"][ch_idx])\n                    self._data[:, ch_idx, :] = np.apply_along_axis(\n                        _fun, -1, data_in[:, ch_idx, :], **kwargs\n                    )\n            else:\n                # use parallel function\n                _fun = partial(np.apply_along_axis, fun, -1)\n                data_picks_new = parallel(\n                    p_fun(\n                        _fun,\n                        data_in[:, ch_idx, :],\n                        **kwargs,\n                        **{\n                            k: v\n                            for k, v in [\n                                (\"ch_name\", self.info[\"ch_names\"][ch_idx]),\n                                (\"ch_idx\", ch_idx),\n                            ]\n                            if k in args\n                        },\n                    )\n                    for ch_idx in picks\n                )\n                for run_idx, ch_idx in enumerate(picks):\n                    self._data[:, ch_idx, :] = data_picks_new[run_idx]\n        else:\n            self._data = _check_fun(fun, data_in, **kwargs)\n\n        return self", "metadata": {}}
{"_id": "mne_mne_epochs.py_filename_code", "title": "filename", "text": "def filename(self) -> Path | None:\n        \"\"\"The filename if the epochs are loaded from disk.\n\n        :type: :class:`pathlib.Path` | ``None``\n        \"\"\"\n        return self._filename", "metadata": {}}
{"_id": "mne_mne_epochs.py_crop_code", "title": "crop", "text": "def crop(self, tmin=None, tmax=None, include_tmax=True, verbose=None):\n        \"\"\"Crop a time interval from the epochs.\n\n        Parameters\n        ----------\n        tmin : float | None\n            Start time of selection in seconds.\n        tmax : float | None\n            End time of selection in seconds.\n        %(include_tmax)s\n        %(verbose)s\n\n        Returns\n        -------\n        epochs : instance of Epochs\n            The cropped epochs object, modified in-place.\n\n        Notes\n        -----\n        %(notes_tmax_included_by_default)s\n        \"\"\"\n        # XXX this could be made to work on non-preloaded data...\n        _check_preload(self, \"Modifying data of epochs\")\n\n        super().crop(tmin=tmin, tmax=tmax, include_tmax=include_tmax)\n\n        # Adjust rejection period\n        if self.reject_tmin is not None and self.reject_tmin < self.tmin:\n            logger.info(\n                f\"reject_tmin is not in epochs time interval. \"\n                f\"Setting reject_tmin to epochs.tmin ({self.tmin} s)\"\n            )\n            self.reject_tmin = self.tmin\n        if self.reject_tmax is not None and self.reject_tmax > self.tmax:\n            logger.info(\n                f\"reject_tmax is not in epochs time interval. \"\n                f\"Setting reject_tmax to epochs.tmax ({self.tmax} s)\"\n            )\n            self.reject_tmax = self.tmax\n        return self", "metadata": {}}
{"_id": "mne_mne_epochs.py_copy_code", "title": "copy", "text": "def copy(self):\n        \"\"\"Return copy of Epochs instance.\n\n        Returns\n        -------\n        epochs : instance of Epochs\n            A copy of the object.\n        \"\"\"\n        return deepcopy(self)", "metadata": {}}
{"_id": "mne_mne_epochs.py_save_code", "title": "save", "text": "def save(\n        self,\n        fname,\n        split_size=\"2GB\",\n        fmt=\"single\",\n        overwrite=False,\n        split_naming=\"neuromag\",\n        verbose=None,\n    ):\n        \"\"\"Save epochs in a fif file.\n\n        Parameters\n        ----------\n        fname : path-like\n            The name of the file, which should end with ``-epo.fif`` or\n            ``-epo.fif.gz``.\n        split_size : str | int\n            Large raw files are automatically split into multiple pieces. This\n            parameter specifies the maximum size of each piece. If the\n            parameter is an integer, it specifies the size in Bytes. It is\n            also possible to pass a human-readable string, e.g., 100MB.\n            Note: Due to FIFF file limitations, the maximum split size is 2GB.\n\n            .. versionadded:: 0.10.0\n        fmt : str\n            Format to save data. Valid options are 'double' or\n            'single' for 64- or 32-bit float, or for 128- or\n            64-bit complex numbers respectively. Note: Data are processed with\n            double precision. Choosing single-precision, the saved data\n            will slightly differ due to the reduction in precision.\n\n            .. versionadded:: 0.17\n        %(overwrite)s\n            To overwrite original file (the same one that was loaded),\n            data must be preloaded upon reading. This defaults to True in 0.18\n            but will change to False in 0.19.\n\n            .. versionadded:: 0.18\n        %(split_naming)s\n\n            .. versionadded:: 0.24\n        %(verbose)s\n\n        Returns\n        -------\n        fnames : List of path-like\n            List of path-like objects containing the path to each file split.\n            .. versionadded:: 1.9\n\n        Notes\n        -----\n        Bad epochs will be dropped before saving the epochs to disk.\n        \"\"\"\n        check_fname(\n            fname, \"epochs\", (\"-epo.fif\", \"-epo.fif.gz\", \"_epo.fif\", \"_epo.fif.gz\")\n        )\n\n        # check for file existence and expand `~` if present\n        fname = str(\n            _check_fname(\n                fname=fname,\n                overwrite=overwrite,\n                check_bids_split=True,\n                name=\"fname\",\n            )\n        )\n\n        split_size_bytes = _get_split_size(split_size)\n\n        _check_option(\"fmt\", fmt, [\"single\", \"double\"])\n\n        # to know the length accurately. The get_data() call would drop\n        # bad epochs anyway\n        self.drop_bad()\n        # total_size tracks sizes that get split\n        # over_size tracks overhead (tags, things that get written to each)\n        if len(self) == 0:\n            warn(\"Saving epochs with no data\")\n            total_size = 0\n        else:\n            d = self[0].get_data(copy=False)\n            # this should be guaranteed by subclasses\n            assert d.dtype in (\">f8\", \"<f8\", \">c16\", \"<c16\")\n            total_size = d.nbytes * len(self)\n        self._check_consistency()\n        over_size = 0\n        if fmt == \"single\":\n            total_size //= 2  # 64bit data converted to 32bit before writing.\n        over_size += 32  # FIF tags\n        # Account for all the other things we write, too\n        # 1. meas_id block plus main epochs block\n        over_size += 132\n        # 2. measurement info (likely slight overestimate, but okay)\n        over_size += object_size(self.info) + 16 * len(self.info)\n        # 3. events and event_id in its own block\n        total_size += self.events.size * 4\n        over_size += len(_event_id_string(self.event_id)) + 72\n        # 4. Metadata in a block of its own\n        if self.metadata is not None:\n            total_size += len(_prepare_write_metadata(self.metadata))\n        over_size += 56\n        # 5. first sample, last sample, baseline\n        over_size += 40 * (self.baseline is not None) + 40\n        # 6. drop log: gets written to each, with IGNORE for ones that are\n        #    not part of it. So make a fake one with all having entries.\n        drop_size = len(json.dumps(self.drop_log)) + 16\n        drop_size += 8 * (len(self.selection) - 1)  # worst case: all but one\n        over_size += drop_size\n        # 7. reject params\n        reject_params = _pack_reject_params(self)\n        if reject_params:\n            over_size += len(json.dumps(reject_params)) + 16\n        # 8. selection\n        total_size += self.selection.size * 4\n        over_size += 16\n        # 9. end of file tags\n        over_size += _NEXT_FILE_BUFFER\n        logger.debug(f\"    Overhead size:   {str(over_size).rjust(15)}\")\n        logger.debug(f\"    Splittable size: {str(total_size).rjust(15)}\")\n        logger.debug(f\"    Split size:      {str(split_size_bytes).rjust(15)}\")\n        # need at least one per\n        n_epochs = len(self)\n        n_per = total_size // n_epochs if n_epochs else 0\n        min_size = n_per + over_size\n        if split_size_bytes < min_size:\n            raise ValueError(\n                f\"The split size {split_size} is too small to safely write \"\n                \"the epochs contents, minimum split size is \"\n                f\"{sizeof_fmt(min_size)} ({min_size} bytes)\"\n            )\n\n        # This is like max(int(ceil(total_size / split_size)), 1) but cleaner\n        n_parts = max((total_size - 1) // (split_size_bytes - over_size) + 1, 1)\n        assert n_parts >= 1, n_parts\n        if n_parts > 1:\n            logger.info(f\"Splitting into {n_parts} parts\")\n            if n_parts > 100:  # This must be an error\n                raise ValueError(\n                    f\"Split size {split_size} would result in writing {n_parts} files\"\n                )\n\n        if len(self.drop_log) > 100000:\n            warn(\n                f\"epochs.drop_log contains {len(self.drop_log)} entries \"\n                f\"which will incur up to a {sizeof_fmt(drop_size)} writing \"\n                f\"overhead (per split file), consider using \"\n                f\"epochs.reset_drop_log_selection() prior to writing\"\n            )\n\n        epoch_idxs = np.array_split(np.arange(n_epochs), n_parts)\n\n        _check_option(\"split_naming\", split_naming, (\"neuromag\", \"bids\"))\n        split_fnames = _make_split_fnames(fname, n_parts, split_naming)\n        for part_idx, epoch_idx in enumerate(epoch_idxs):\n            this_epochs = self[epoch_idx] if n_parts > 1 else self\n            # avoid missing event_ids in splits\n            this_epochs.event_id = self.event_id\n\n            _save_split(this_epochs, split_fnames, part_idx, n_parts, fmt, overwrite)\n        return split_fnames", "metadata": {}}
{"_id": "mne_mne_epochs.py_export_code", "title": "export", "text": "def export(self, fname, fmt=\"auto\", *, overwrite=False, verbose=None):\n        \"\"\"Export Epochs to external formats.\n\n        %(export_fmt_support_epochs)s\n\n        %(export_warning)s\n\n        Parameters\n        ----------\n        %(fname_export_params)s\n        %(export_fmt_params_epochs)s\n        %(overwrite)s\n\n            .. versionadded:: 0.24.1\n        %(verbose)s\n\n        Notes\n        -----\n        .. versionadded:: 0.24\n\n        %(export_warning_note_epochs)s\n        %(export_eeglab_note)s\n        \"\"\"\n        from .export import export_epochs\n\n        export_epochs(fname, self, fmt, overwrite=overwrite, verbose=verbose)", "metadata": {}}
{"_id": "mne_mne_epochs.py_equalize_event_counts_code", "title": "equalize_event_counts", "text": "def equalize_event_counts(\n        self, event_ids=None, method=\"mintime\", *, random_state=None\n    ):\n        \"\"\"Equalize the number of trials in each condition.\n\n        It tries to make the remaining epochs occurring as close as possible in\n        time. This method works based on the idea that if there happened to be\n        some time-varying (like on the scale of minutes) noise characteristics\n        during a recording, they could be compensated for (to some extent) in\n        the equalization process. This method thus seeks to reduce any of\n        those effects by minimizing the differences in the times of the events\n        within a `~mne.Epochs` instance. For example, if one event type\n        occurred at time points ``[1, 2, 3, 4, 120, 121]`` and the another one\n        at ``[3.5, 4.5, 120.5, 121.5]``, this method would remove the events at\n        times ``[1, 2]`` for the first event type \u2013 and not the events at times\n        ``[120, 121]``.\n\n        Parameters\n        ----------\n        event_ids : None | list | dict\n            The event types to equalize.\n\n            If ``None`` (default), equalize the counts of **all** event types\n            present in the `~mne.Epochs` instance.\n\n            If a list, each element can either be a string (event name) or a\n            list of strings. In the case where one of the entries is a list of\n            strings, event types in that list will be grouped together before\n            equalizing trial counts across conditions.\n\n            If a dictionary, the keys are considered as the event names whose\n            counts to equalize, i.e., passing ``dict(A=1, B=2)`` will have the\n            same effect as passing ``['A', 'B']``. This is useful if you intend\n            to pass an ``event_id`` dictionary that was used when creating\n            `~mne.Epochs`.\n\n            In the case where partial matching is used (using ``/`` in\n            the event names), the event types will be matched according to the\n            provided tags, that is, processing works as if the ``event_ids``\n            matched by the provided tags had been supplied instead.\n            The ``event_ids`` must identify non-overlapping subsets of the\n            epochs.\n        %(equalize_events_method)s\n        %(random_state)s Used only if ``method='random'``.\n\n        Returns\n        -------\n        epochs : instance of Epochs\n            The modified instance. It is modified in-place.\n        indices : array of int\n            Indices from the original events list that were dropped.\n\n        Notes\n        -----\n        For example (if ``epochs.event_id`` was ``{'Left': 1, 'Right': 2,\n        'Nonspatial':3}``:\n\n            epochs.equalize_event_counts([['Left', 'Right'], 'Nonspatial'])\n\n        would equalize the number of trials in the ``'Nonspatial'`` condition\n        with the total number of trials in the ``'Left'`` and ``'Right'``\n        conditions combined.\n\n        If multiple indices are provided (e.g. ``'Left'`` and ``'Right'`` in\n        the example above), it is not guaranteed that after equalization the\n        conditions will contribute equally. E.g., it is possible to end up\n        with 70 ``'Nonspatial'`` epochs, 69 ``'Left'`` and 1 ``'Right'``.\n\n        .. versionchanged:: 0.23\n            Default to equalizing all events in the passed instance if no\n            event names were specified explicitly.\n        \"\"\"\n        from collections.abc import Iterable\n\n        _validate_type(\n            event_ids,\n            types=(Iterable, None),\n            item_name=\"event_ids\",\n            type_name=\"list-like or None\",\n        )\n        if isinstance(event_ids, str):\n            raise TypeError(\n                f\"event_ids must be list-like or None, but \"\n                f\"received a string: {event_ids}\"\n            )\n\n        if event_ids is None:\n            event_ids = list(self.event_id)\n        elif not event_ids:\n            raise ValueError(\"event_ids must have at least one element\")\n\n        if not self._bad_dropped:\n            self.drop_bad()\n        # figure out how to equalize\n        eq_inds = list()\n\n        # deal with hierarchical tags\n        ids = self.event_id\n        orig_ids = list(event_ids)\n        tagging = False\n        if \"/\" in \"\".join(ids):\n            # make string inputs a list of length 1\n            event_ids = [[x] if isinstance(x, str) else x for x in event_ids]\n            for ids_ in event_ids:  # check if tagging is attempted\n                if any([id_ not in ids for id_ in ids_]):\n                    tagging = True\n            # 1. treat everything that's not in event_id as a tag\n            # 2a. for tags, find all the event_ids matched by the tags\n            # 2b. for non-tag ids, just pass them directly\n            # 3. do this for every input\n            event_ids = [\n                [\n                    k for k in ids if all(tag in k.split(\"/\") for tag in id_)\n                ]  # ids matching all tags\n                if all(id__ not in ids for id__ in id_)\n                else id_  # straight pass for non-tag inputs\n                for id_ in event_ids\n            ]\n            for ii, id_ in enumerate(event_ids):\n                if len(id_) == 0:\n                    raise KeyError(\n                        f\"{orig_ids[ii]} not found in the epoch object's event_id.\"\n                    )\n                elif len({sub_id in ids for sub_id in id_}) != 1:\n                    err = (\n                        \"Don't mix hierarchical and regular event_ids\"\n                        f\" like in '{', '.join(id_)}'.\"\n                    )\n                    raise ValueError(err)\n\n            # raise for non-orthogonal tags\n            if tagging is True:\n                events_ = [set(self[x].events[:, 0]) for x in event_ids]\n                doubles = events_[0].intersection(events_[1])\n                if len(doubles):\n                    raise ValueError(\n                        \"The two sets of epochs are \"\n                        \"overlapping. Provide an \"\n                        \"orthogonal selection.\"\n                    )\n\n        for eq in event_ids:\n            eq_inds.append(self._keys_to_idx(eq))\n\n        sample_nums = [self.events[e, 0] for e in eq_inds]\n        indices = _get_drop_indices(sample_nums, method, random_state)\n        # need to re-index indices\n        indices = np.concatenate([e[idx] for e, idx in zip(eq_inds, indices)])\n        self.drop(indices, reason=\"EQUALIZED_COUNT\")\n        # actually remove the indices\n        return self, indices", "metadata": {}}
{"_id": "mne_mne_epochs.py_compute_psd_code", "title": "compute_psd", "text": "def compute_psd(\n        self,\n        method=\"multitaper\",\n        fmin=0,\n        fmax=np.inf,\n        tmin=None,\n        tmax=None,\n        picks=None,\n        proj=False,\n        remove_dc=True,\n        exclude=(),\n        *,\n        n_jobs=1,\n        verbose=None,\n        **method_kw,\n    ):\n        \"\"\"Perform spectral analysis on sensor data.\n\n        Parameters\n        ----------\n        %(method_psd)s\n            Default is ``'multitaper'``.\n        %(fmin_fmax_psd)s\n        %(tmin_tmax_psd)s\n        %(picks_good_data_noref)s\n        %(proj_psd)s\n        %(remove_dc)s\n        %(exclude_psd)s\n        %(n_jobs)s\n        %(verbose)s\n        %(method_kw_psd)s\n\n        Returns\n        -------\n        spectrum : instance of EpochsSpectrum\n            The spectral representation of each epoch.\n\n        Notes\n        -----\n        .. versionadded:: 1.2\n\n        References\n        ----------\n        .. footbibliography::\n        \"\"\"\n        method = _validate_method(method, type(self).__name__)\n        self._set_legacy_nfft_default(tmin, tmax, method, method_kw)\n\n        return EpochsSpectrum(\n            self,\n            method=method,\n            fmin=fmin,\n            fmax=fmax,\n            tmin=tmin,\n            tmax=tmax,\n            picks=picks,\n            exclude=exclude,\n            proj=proj,\n            remove_dc=remove_dc,\n            n_jobs=n_jobs,\n            verbose=verbose,\n            **method_kw,\n        )", "metadata": {}}
{"_id": "mne_mne_epochs.py_compute_tfr_code", "title": "compute_tfr", "text": "def compute_tfr(\n        self,\n        method,\n        freqs,\n        *,\n        tmin=None,\n        tmax=None,\n        picks=None,\n        proj=False,\n        output=\"power\",\n        average=False,\n        return_itc=False,\n        decim=1,\n        n_jobs=None,\n        verbose=None,\n        **method_kw,\n    ):\n        \"\"\"Compute a time-frequency representation of epoched data.\n\n        Parameters\n        ----------\n        %(method_tfr_epochs)s\n        %(freqs_tfr_epochs)s\n        %(tmin_tmax_psd)s\n        %(picks_good_data_noref)s\n        %(proj_psd)s\n        %(output_compute_tfr)s\n        average : bool\n            Whether to return average power across epochs (instead of single-trial\n            power). ``average=True`` is not compatible with ``output=\"complex\"`` or\n            ``output=\"phase\"``. Ignored if ``method=\"stockwell\"`` (Stockwell method\n            *requires* averaging). Default is ``False``.\n        return_itc : bool\n            Whether to return inter-trial coherence (ITC) as well as power estimates.\n            If ``True`` then must specify ``average=True`` (or ``method=\"stockwell\",\n            average=\"auto\"``). Default is ``False``.\n        %(decim_tfr)s\n        %(n_jobs)s\n        %(verbose)s\n        %(method_kw_epochs_tfr)s\n\n        Returns\n        -------\n        tfr : instance of EpochsTFR or AverageTFR\n            The time-frequency-resolved power estimates.\n        itc : instance of AverageTFR\n            The inter-trial coherence (ITC). Only returned if ``return_itc=True``.\n\n        Notes\n        -----\n        If ``average=True`` (or ``method=\"stockwell\", average=\"auto\"``) the result will\n        be an :class:`~mne.time_frequency.AverageTFR` instead of an\n        :class:`~mne.time_frequency.EpochsTFR`.\n\n        .. versionadded:: 1.7\n\n        References\n        ----------\n        .. footbibliography::\n        \"\"\"\n        if method == \"stockwell\" and not average:  # stockwell method *must* average\n            logger.info(\n                'Requested `method=\"stockwell\"` so ignoring parameter `average=False`.'\n            )\n            average = True\n        if average:\n            # augment `output` value for use by tfr_array_* functions\n            _check_option(\"output\", output, (\"power\",), extra=\" when average=True\")\n            method_kw[\"output\"] = \"avg_power_itc\" if return_itc else \"avg_power\"\n        else:\n            msg = (\n                \"compute_tfr() got incompatible parameters `average=False` and `{}` \"\n                \"({} requires averaging over epochs).\"\n            )\n            if return_itc:\n                raise ValueError(msg.format(\"return_itc=True\", \"computing ITC\"))\n            if method == \"stockwell\":\n                raise ValueError(msg.format('method=\"stockwell\"', \"Stockwell method\"))\n            # `average` and `return_itc` both False, so \"phase\" and \"complex\" are OK\n            _check_option(\"output\", output, (\"power\", \"phase\", \"complex\"))\n            method_kw[\"output\"] = output\n\n        if method == \"stockwell\":\n            method_kw[\"return_itc\"] = return_itc\n            method_kw.pop(\"output\")\n            if isinstance(freqs, str):\n                _check_option(\"freqs\", freqs, \"auto\")\n            else:\n                _validate_type(freqs, \"array-like\")\n                _check_option(\n                    \"freqs\", np.array(freqs).shape, ((2,),), extra=\" (wrong shape).\"\n                )\n        if average:\n            out = AverageTFR(\n                inst=self,\n                method=method,\n                freqs=freqs,\n                tmin=tmin,\n                tmax=tmax,\n                picks=picks,\n                proj=proj,\n                decim=decim,\n                n_jobs=n_jobs,\n                verbose=verbose,\n                **method_kw,\n            )\n            # tfr_array_stockwell always returns ITC (but sometimes it's None)\n            if hasattr(out, \"_itc\"):\n                if out._itc is not None:\n                    state = out.__getstate__()\n                    state[\"data\"] = out._itc\n                    state[\"data_type\"] = \"Inter-trial coherence\"\n                    itc = AverageTFR(inst=state)\n                    del out._itc\n                    return out, itc\n                del out._itc\n            return out\n        # now handle average=False\n        return EpochsTFR(\n            inst=self,\n            method=method,\n            freqs=freqs,\n            tmin=tmin,\n            tmax=tmax,\n            picks=picks,\n            proj=proj,\n            decim=decim,\n            n_jobs=n_jobs,\n            verbose=verbose,\n            **method_kw,\n        )", "metadata": {}}
{"_id": "mne_mne_epochs.py_plot_psd_code", "title": "plot_psd", "text": "def plot_psd(\n        self,\n        fmin=0,\n        fmax=np.inf,\n        tmin=None,\n        tmax=None,\n        picks=None,\n        proj=False,\n        *,\n        method=\"auto\",\n        average=False,\n        dB=True,\n        estimate=\"power\",\n        xscale=\"linear\",\n        area_mode=\"std\",\n        area_alpha=0.33,\n        color=\"black\",\n        line_alpha=None,\n        spatial_colors=True,\n        sphere=None,\n        exclude=\"bads\",\n        ax=None,\n        show=True,\n        n_jobs=1,\n        verbose=None,\n        **method_kw,\n    ):\n        \"\"\"%(plot_psd_doc)s.\n\n        Parameters\n        ----------\n        %(fmin_fmax_psd)s\n        %(tmin_tmax_psd)s\n        %(picks_good_data_noref)s\n        %(proj_psd)s\n        %(method_plot_psd_auto)s\n        %(average_plot_psd)s\n        %(dB_plot_psd)s\n        %(estimate_plot_psd)s\n        %(xscale_plot_psd)s\n        %(area_mode_plot_psd)s\n        %(area_alpha_plot_psd)s\n        %(color_plot_psd)s\n        %(line_alpha_plot_psd)s\n        %(spatial_colors_psd)s\n        %(sphere_topomap_auto)s\n\n            .. versionadded:: 0.22.0\n        exclude : list of str | 'bads'\n            Channels names to exclude from being shown. If 'bads', the bad\n            channels are excluded. Pass an empty list to plot all channels\n            (including channels marked \"bad\", if any).\n\n            .. versionadded:: 0.24.0\n        %(ax_plot_psd)s\n        %(show)s\n        %(n_jobs)s\n        %(verbose)s\n        %(method_kw_psd)s\n\n        Returns\n        -------\n        fig : instance of Figure\n            Figure with frequency spectra of the data channels.\n\n        Notes\n        -----\n        %(notes_plot_psd_meth)s\n        \"\"\"\n        return super().plot_psd(\n            fmin=fmin,\n            fmax=fmax,\n            tmin=tmin,\n            tmax=tmax,\n            picks=picks,\n            proj=proj,\n            reject_by_annotation=False,\n            method=method,\n            average=average,\n            dB=dB,\n            estimate=estimate,\n            xscale=xscale,\n            area_mode=area_mode,\n            area_alpha=area_alpha,\n            color=color,\n            line_alpha=line_alpha,\n            spatial_colors=spatial_colors,\n            sphere=sphere,\n            exclude=exclude,\n            ax=ax,\n            show=show,\n            n_jobs=n_jobs,\n            verbose=verbose,\n            **method_kw,\n        )", "metadata": {}}
{"_id": "mne_mne_epochs.py_to_data_frame_code", "title": "to_data_frame", "text": "def to_data_frame(\n        self,\n        picks=None,\n        index=None,\n        scalings=None,\n        copy=True,\n        long_format=False,\n        time_format=None,\n        *,\n        verbose=None,\n    ):\n        \"\"\"Export data in tabular structure as a pandas DataFrame.\n\n        Channels are converted to columns in the DataFrame. By default,\n        additional columns \"time\", \"epoch\" (epoch number), and \"condition\"\n        (epoch event description) are added, unless ``index`` is not ``None``\n        (in which case the columns specified in ``index`` will be used to form\n        the DataFrame's index instead).\n\n        Parameters\n        ----------\n        %(picks_all)s\n        %(index_df_epo)s\n            Valid string values are 'time', 'epoch', and 'condition'.\n            Defaults to ``None``.\n        %(scalings_df)s\n        %(copy_df)s\n        %(long_format_df_epo)s\n        %(time_format_df)s\n\n            .. versionadded:: 0.20\n        %(verbose)s\n\n        Returns\n        -------\n        %(df_return)s\n        \"\"\"\n        # check pandas once here, instead of in each private utils function\n        pd = _check_pandas_installed()  # noqa\n        # arg checking\n        valid_index_args = [\"time\", \"epoch\", \"condition\"]\n        valid_time_formats = [\"ms\", \"timedelta\"]\n        index = _check_pandas_index_arguments(index, valid_index_args)\n        time_format = _check_time_format(time_format, valid_time_formats)\n        # get data\n        picks = _picks_to_idx(self.info, picks, \"all\", exclude=())\n        data = self._get_data(on_empty=\"raise\")[:, picks, :]\n        times = self.times\n        n_epochs, n_picks, n_times = data.shape\n        data = np.hstack(data).T  # (time*epochs) x signals\n        if copy:\n            data = data.copy()\n        data = _scale_dataframe_data(self, data, picks, scalings)\n        # prepare extra columns / multiindex\n        mindex = list()\n        times = np.tile(times, n_epochs)\n        times = _convert_times(times, time_format, self.info[\"meas_date\"])\n        mindex.append((\"time\", times))\n        rev_event_id = {v: k for k, v in self.event_id.items()}\n        conditions = [rev_event_id[k] for k in self.events[:, 2]]\n        mindex.append((\"condition\", np.repeat(conditions, n_times)))\n        mindex.append((\"epoch\", np.repeat(self.selection, n_times)))\n        assert all(len(mdx) == len(mindex[0]) for mdx in mindex)\n        # build DataFrame\n        df = _build_data_frame(\n            self,\n            data,\n            picks,\n            long_format,\n            mindex,\n            index,\n            default_index=[\"condition\", \"epoch\", \"time\"],\n        )\n        return df", "metadata": {}}
{"_id": "mne_mne_epochs.py_as_type_code", "title": "as_type", "text": "def as_type(self, ch_type=\"grad\", mode=\"fast\"):\n        \"\"\"Compute virtual epochs using interpolated fields.\n\n        .. Warning:: Using virtual epochs to compute inverse can yield\n            unexpected results. The virtual channels have ``'_v'`` appended\n            at the end of the names to emphasize that the data contained in\n            them are interpolated.\n\n        Parameters\n        ----------\n        ch_type : str\n            The destination channel type. It can be 'mag' or 'grad'.\n        mode : str\n            Either ``'accurate'`` or ``'fast'``, determines the quality of the\n            Legendre polynomial expansion used. ``'fast'`` should be sufficient\n            for most applications.\n\n        Returns\n        -------\n        epochs : instance of mne.EpochsArray\n            The transformed epochs object containing only virtual channels.\n\n        Notes\n        -----\n        This method returns a copy and does not modify the data it\n        operates on. It also returns an EpochsArray instance.\n\n        .. versionadded:: 0.20.0\n        \"\"\"\n        from .forward import _as_meg_type_inst\n\n        self._handle_empty(\"raise\", \"as_type\")\n        return _as_meg_type_inst(self, ch_type=ch_type, mode=mode)", "metadata": {}}
{"_id": "mne_mne_evoked.py_combine_evoked_code", "title": "combine_evoked", "text": "def combine_evoked(all_evoked, weights):\n    \"\"\"Merge evoked data by weighted addition or subtraction.\n\n    Each `~mne.Evoked` in ``all_evoked`` should have the same channels and the\n    same time instants. Subtraction can be performed by passing\n    ``weights=[1, -1]``.\n\n    .. Warning::\n        Other than cases like simple subtraction mentioned above (where all\n        weights are ``-1`` or ``1``), if you provide numeric weights instead of using\n        ``'equal'`` or ``'nave'``, the resulting `~mne.Evoked` object's\n        ``.nave`` attribute (which is used to scale noise covariance when\n        applying the inverse operator) may not be suitable for inverse imaging.\n\n    Parameters\n    ----------\n    all_evoked : list of Evoked\n        The evoked datasets.\n    weights : list of float | ``'equal'`` | ``'nave'``\n        The weights to apply to the data of each evoked instance, or a string\n        describing the weighting strategy to apply: ``'nave'`` computes\n        sum-to-one weights proportional to each object's ``nave`` attribute;\n        ``'equal'`` weights each `~mne.Evoked` by ``1 / len(all_evoked)``.\n\n    Returns\n    -------\n    evoked : Evoked\n        The new evoked data.\n\n    Notes\n    -----\n    .. versionadded:: 0.9.0\n    \"\"\"\n    naves = np.array([evk.nave for evk in all_evoked], float)\n    if isinstance(weights, str):\n        _check_option(\"weights\", weights, [\"nave\", \"equal\"])\n        if weights == \"nave\":\n            weights = naves / naves.sum()\n        else:\n            weights = np.ones_like(naves) / len(naves)\n    else:\n        weights = np.array(weights, float)\n\n    if weights.ndim != 1 or weights.size != len(all_evoked):\n        raise ValueError(\"weights must be the same size as all_evoked\")\n\n    # cf. https://en.wikipedia.org/wiki/Weighted_arithmetic_mean, section on\n    # \"weighted sample variance\". The variance of a weighted sample mean is:\n    #\n    #    \u03c3\u00b2 = w\u2081\u00b2 \u03c3\u2081\u00b2 + w\u2082\u00b2 \u03c3\u2082\u00b2 + ... + w\u2099\u00b2 \u03c3\u2099\u00b2\n    #\n    # We estimate the variance of each evoked instance as 1 / nave to get:\n    #\n    #    \u03c3\u00b2 = w\u2081\u00b2 / nave\u2081 + w\u2082\u00b2 / nave\u2082 + ... + w\u2099\u00b2 / nave\u2099\n    #\n    # And our resulting nave is the reciprocal of this:\n    new_nave = 1.0 / np.sum(weights**2 / naves)\n    # This general formula is equivalent to formulae in Matti's manual\n    # (pp 128-129), where:\n    # new_nave = sum(naves) when weights='nave' and\n    # new_nave = 1. / sum(1. / naves) when weights are all 1.\n\n    all_evoked = _check_evokeds_ch_names_times(all_evoked)\n    evoked = all_evoked[0].copy()\n\n    # use union of bad channels\n    bads = list(set(b for e in all_evoked for b in e.info[\"bads\"]))\n    evoked.info[\"bads\"] = bads\n    evoked.data = sum(w * e.data for w, e in zip(weights, all_evoked))\n    evoked.nave = new_nave\n\n    comment = \"\"\n    for idx, (w, e) in enumerate(zip(weights, all_evoked)):\n        # pick sign\n        sign = \"\" if w >= 0 else \"-\"\n        # format weight\n        weight = \"\" if np.isclose(abs(w), 1.0) else f\"{abs(w):0.3f}\"\n        # format multiplier\n        multiplier = \" \u00d7 \" if weight else \"\"\n        # format comment\n        if e.comment is not None and \" + \" in e.comment:  # multiple conditions\n            this_comment = f\"({e.comment})\"\n        else:\n            this_comment = f\"{e.comment or 'unknown'}\"\n        # assemble everything\n        if idx == 0:\n            comment += f\"{sign}{weight}{multiplier}{this_comment}\"\n        else:\n            comment += f\" {sign or '+'} {weight}{multiplier}{this_comment}\"\n    # special-case: combine_evoked([e1, -e2], [1, -1])\n    evoked.comment = comment.replace(\" - - \", \" + \")\n    return evoked", "metadata": {}}
{"_id": "mne_mne_evoked.py_read_evokeds_code", "title": "read_evokeds", "text": "def read_evokeds(\n    fname,\n    condition=None,\n    baseline=None,\n    kind=\"average\",\n    proj=True,\n    allow_maxshield=False,\n    verbose=None,\n) -> list[Evoked] | Evoked:\n    \"\"\"Read evoked dataset(s).\n\n    Parameters\n    ----------\n    fname : path-like\n        The filename, which should end with ``-ave.fif`` or ``-ave.fif.gz``.\n    condition : int or str | list of int or str | None\n        The index or list of indices of the evoked dataset to read. FIF files\n        can contain multiple datasets. If None, all datasets are returned as a\n        list.\n    %(baseline_evoked)s\n        If ``None`` (default), do not apply baseline correction.\n\n        .. note:: Note that if the read  `~mne.Evoked` objects have already\n                  been baseline-corrected, the data retrieved from disk will\n                  **always** be baseline-corrected (in fact, only the\n                  baseline-corrected version of the data will be saved, so\n                  there is no way to undo this procedure). Only **after** the\n                  data has been loaded, a custom (additional) baseline\n                  correction **may** be optionally applied by passing a tuple\n                  here. Passing ``None`` will **not** remove an existing\n                  baseline correction, but merely omit the optional, additional\n                  baseline correction.\n    kind : str\n        Either ``'average'`` or ``'standard_error'``, the type of data to read.\n    proj : bool\n        If False, available projectors won't be applied to the data.\n    allow_maxshield : bool | str (default False)\n        If True, allow loading of data that has been recorded with internal\n        active compensation (MaxShield). Data recorded with MaxShield should\n        generally not be loaded directly, but should first be processed using\n        SSS/tSSS to remove the compensation signals that may also affect brain\n        activity. Can also be ``\"yes\"`` to load without eliciting a warning.\n    %(verbose)s\n\n    Returns\n    -------\n    evoked : Evoked or list of Evoked\n        The evoked dataset(s); one `~mne.Evoked` if ``condition`` is an\n        integer or string; or a list of `~mne.Evoked` if ``condition`` is\n        ``None`` or a list.\n\n    See Also\n    --------\n    write_evokeds\n\n    Notes\n    -----\n    .. versionchanged:: 0.23\n        If the read `~mne.Evoked` objects had been baseline-corrected before\n        saving, this will be reflected in their ``baseline`` attribute after\n        reading.\n    \"\"\"\n    fname = _check_fname(fname, overwrite=\"read\", must_exist=True)\n    check_fname(fname, \"evoked\", (\"-ave.fif\", \"-ave.fif.gz\", \"_ave.fif\", \"_ave.fif.gz\"))\n    logger.info(f\"Reading {fname} ...\")\n    return_list = True\n    if condition is None:\n        evoked_node = _get_evoked_node(fname)\n        condition = range(len(evoked_node))\n    elif not isinstance(condition, list):\n        condition = [condition]\n        return_list = False\n\n    out = []\n    for c in condition:\n        evoked = Evoked(\n            fname,\n            c,\n            kind=kind,\n            proj=proj,\n            allow_maxshield=allow_maxshield,\n            verbose=verbose,\n        )\n        if baseline is None and evoked.baseline is None:\n            logger.info(_log_rescale(None))\n        elif baseline is None and evoked.baseline is not None:\n            # Don't touch an existing baseline\n            bmin, bmax = evoked.baseline\n            logger.info(\n                f\"Loaded Evoked data is baseline-corrected \"\n                f\"(baseline: [{bmin:g}, {bmax:g}] s)\"\n            )\n        else:\n            evoked.apply_baseline(baseline)\n        out.append(evoked)\n\n    return out if return_list else out[0]", "metadata": {}}
{"_id": "mne_mne_evoked.py_write_evokeds_code", "title": "write_evokeds", "text": "def write_evokeds(fname, evoked, *, on_mismatch=\"raise\", overwrite=False, verbose=None):\n    \"\"\"Write an evoked dataset to a file.\n\n    Parameters\n    ----------\n    fname : path-like\n        The file name, which should end with ``-ave.fif`` or ``-ave.fif.gz``.\n    evoked : Evoked instance, or list of Evoked instances\n        The evoked dataset, or list of evoked datasets, to save in one file.\n        Note that the measurement info from the first evoked instance is used,\n        so be sure that information matches.\n    %(on_mismatch_info)s\n    %(overwrite)s\n\n        .. versionadded:: 1.0\n    %(verbose)s\n\n        .. versionadded:: 0.24\n\n    See Also\n    --------\n    read_evokeds\n\n    Notes\n    -----\n    .. versionchanged:: 0.23\n        Information on baseline correction will be stored with each individual\n        `~mne.Evoked` object, and will be restored when reading the data again\n        via `mne.read_evokeds`.\n    \"\"\"\n    _write_evokeds(fname, evoked, on_mismatch=on_mismatch, overwrite=overwrite)", "metadata": {}}
{"_id": "mne_mne_evoked.py_filename_code", "title": "filename", "text": "def filename(self) -> Path | None:\n        \"\"\"The filename of the evoked object, if it exists.\n\n        :type: :class:`~pathlib.Path` | None\n        \"\"\"\n        return self._filename", "metadata": {}}
{"_id": "mne_mne_evoked.py_kind_code", "title": "kind", "text": "def kind(self):\n        \"\"\"The data kind.\"\"\"\n        return _aspect_rev[self._aspect_kind]", "metadata": {}}
{"_id": "mne_mne_evoked.py_data_code", "title": "data", "text": "def data(self):\n        \"\"\"The data matrix.\"\"\"\n        return self._data", "metadata": {}}
{"_id": "mne_mne_evoked.py_data_code", "title": "data", "text": "def data(self, data):\n        \"\"\"Set the data matrix.\"\"\"\n        self._data = data", "metadata": {}}
{"_id": "mne_mne_evoked.py_get_data_code", "title": "get_data", "text": "def get_data(self, picks=None, units=None, tmin=None, tmax=None):\n        \"\"\"Get evoked data as 2D array.\n\n        Parameters\n        ----------\n        %(picks_all)s\n        %(units)s\n        tmin : float | None\n            Start time of data to get in seconds.\n        tmax : float | None\n            End time of data to get in seconds.\n\n        Returns\n        -------\n        data : ndarray, shape (n_channels, n_times)\n            A view on evoked data.\n\n        Notes\n        -----\n        .. versionadded:: 0.24\n        \"\"\"\n        # Avoid circular import\n        from .io.base import _get_ch_factors\n\n        picks = _picks_to_idx(self.info, picks, \"all\", exclude=())\n\n        start, stop = self._handle_tmin_tmax(tmin, tmax)\n\n        data = self.data[picks, start:stop]\n\n        if units is not None:\n            ch_factors = _get_ch_factors(self, units, picks)\n            data *= ch_factors[:, np.newaxis]\n\n        return data", "metadata": {}}
{"_id": "mne_mne_evoked.py_apply_function_code", "title": "apply_function", "text": "def apply_function(\n        self,\n        fun,\n        picks=None,\n        dtype=None,\n        n_jobs=None,\n        channel_wise=True,\n        *,\n        verbose=None,\n        **kwargs,\n    ):\n        \"\"\"Apply a function to a subset of channels.\n\n        %(applyfun_summary_evoked)s\n\n        Parameters\n        ----------\n        %(fun_applyfun_evoked)s\n        %(picks_all_data_noref)s\n        %(dtype_applyfun)s\n        %(n_jobs)s Ignored if ``channel_wise=False`` as the workload\n            is split across channels.\n        %(channel_wise_applyfun)s\n\n            .. versionadded:: 1.6\n        %(verbose)s\n        %(kwargs_fun)s\n\n        Returns\n        -------\n        self : instance of Evoked\n            The evoked object with transformed data.\n        \"\"\"\n        _check_preload(self, \"evoked.apply_function\")\n        picks = _picks_to_idx(self.info, picks, exclude=(), with_ref_meg=False)\n\n        if not callable(fun):\n            raise ValueError(\"fun needs to be a function\")\n\n        data_in = self._data\n        if dtype is not None and dtype != self._data.dtype:\n            self._data = self._data.astype(dtype)\n\n        args = getfullargspec(fun).args + getfullargspec(fun).kwonlyargs\n        if channel_wise is False:\n            if (\"ch_idx\" in args) or (\"ch_name\" in args):\n                raise ValueError(\n                    \"apply_function cannot access ch_idx or ch_name \"\n                    \"when channel_wise=False\"\n                )\n        if \"ch_idx\" in args:\n            logger.info(\"apply_function requested to access ch_idx\")\n        if \"ch_name\" in args:\n            logger.info(\"apply_function requested to access ch_name\")\n\n        # check the dimension of the incoming evoked data\n        _check_option(\"evoked.ndim\", self._data.ndim, [2])\n\n        if channel_wise:\n            parallel, p_fun, n_jobs = parallel_func(_check_fun, n_jobs)\n            if n_jobs == 1:\n                # modify data inplace to save memory\n                for ch_idx in picks:\n                    if \"ch_idx\" in args:\n                        kwargs.update(ch_idx=ch_idx)\n                    if \"ch_name\" in args:\n                        kwargs.update(ch_name=self.info[\"ch_names\"][ch_idx])\n                    self._data[ch_idx, :] = _check_fun(\n                        fun, data_in[ch_idx, :], **kwargs\n                    )\n            else:\n                # use parallel function\n                data_picks_new = parallel(\n                    p_fun(\n                        fun,\n                        data_in[ch_idx, :],\n                        **kwargs,\n                        **{\n                            k: v\n                            for k, v in [\n                                (\"ch_name\", self.info[\"ch_names\"][ch_idx]),\n                                (\"ch_idx\", ch_idx),\n                            ]\n                            if k in args\n                        },\n                    )\n                    for ch_idx in picks\n                )\n                for run_idx, ch_idx in enumerate(picks):\n                    self._data[ch_idx, :] = data_picks_new[run_idx]\n        else:\n            self._data[picks, :] = _check_fun(fun, data_in[picks, :], **kwargs)\n\n        return self", "metadata": {}}
{"_id": "mne_mne_evoked.py_apply_baseline_code", "title": "apply_baseline", "text": "def apply_baseline(self, baseline=(None, 0), *, verbose=None):\n        \"\"\"Baseline correct evoked data.\n\n        Parameters\n        ----------\n        %(baseline_evoked)s\n            Defaults to ``(None, 0)``, i.e. beginning of the the data until\n            time point zero.\n        %(verbose)s\n\n        Returns\n        -------\n        evoked : instance of Evoked\n            The baseline-corrected Evoked object.\n\n        Notes\n        -----\n        Baseline correction can be done multiple times.\n\n        .. versionadded:: 0.13.0\n        \"\"\"\n        baseline = _check_baseline(baseline, times=self.times, sfreq=self.info[\"sfreq\"])\n        if self.baseline is not None and baseline is None:\n            raise ValueError(\n                \"The data has already been baseline-corrected. \"\n                \"Cannot remove existing baseline correction.\"\n            )\n        elif baseline is None:\n            # Do not rescale\n            logger.info(_log_rescale(None))\n        else:\n            # Actually baseline correct the data. Logging happens in rescale().\n            self.data = rescale(self.data, self.times, baseline, copy=False)\n            self.baseline = baseline\n\n        return self", "metadata": {}}
{"_id": "mne_mne_evoked.py_save_code", "title": "save", "text": "def save(self, fname, *, overwrite=False, verbose=None):\n        \"\"\"Save evoked data to a file.\n\n        Parameters\n        ----------\n        fname : path-like\n            The name of the file, which should end with ``-ave.fif(.gz)`` or\n            ``_ave.fif(.gz)``.\n        %(overwrite)s\n        %(verbose)s\n\n        Notes\n        -----\n        To write multiple conditions into a single file, use\n        `mne.write_evokeds`.\n\n        .. versionchanged:: 0.23\n            Information on baseline correction will be stored with the data,\n            and will be restored when reading again via `mne.read_evokeds`.\n        \"\"\"\n        write_evokeds(fname, self, overwrite=overwrite)", "metadata": {}}
{"_id": "mne_mne_evoked.py_export_code", "title": "export", "text": "def export(self, fname, fmt=\"auto\", *, overwrite=False, verbose=None):\n        \"\"\"Export Evoked to external formats.\n\n        %(export_fmt_support_evoked)s\n\n        %(export_warning)s\n\n        Parameters\n        ----------\n        %(fname_export_params)s\n        %(export_fmt_params_evoked)s\n        %(overwrite)s\n        %(verbose)s\n\n        Notes\n        -----\n        .. versionadded:: 1.1\n\n        %(export_warning_note_evoked)s\n        \"\"\"\n        from .export import export_evokeds\n\n        export_evokeds(fname, self, fmt, overwrite=overwrite, verbose=verbose)", "metadata": {}}
{"_id": "mne_mne_evoked.py_ch_names_code", "title": "ch_names", "text": "def ch_names(self):\n        \"\"\"Channel names.\"\"\"\n        return self.info[\"ch_names\"]", "metadata": {}}
{"_id": "mne_mne_evoked.py_plot_topo_code", "title": "plot_topo", "text": "def plot_topo(\n        self,\n        layout=None,\n        layout_scale=0.945,\n        color=None,\n        border=\"none\",\n        ylim=None,\n        scalings=None,\n        title=None,\n        proj=False,\n        vline=(0.0,),\n        fig_background=None,\n        merge_grads=False,\n        legend=True,\n        axes=None,\n        background_color=\"w\",\n        noise_cov=None,\n        exclude=\"bads\",\n        select=False,\n        show=True,\n    ):\n        \"\"\".\n\n        Notes\n        -----\n        .. versionadded:: 0.10.0\n        \"\"\"\n        return plot_evoked_topo(\n            self,\n            layout=layout,\n            layout_scale=layout_scale,\n            color=color,\n            border=border,\n            ylim=ylim,\n            scalings=scalings,\n            title=title,\n            proj=proj,\n            vline=vline,\n            fig_background=fig_background,\n            merge_grads=merge_grads,\n            legend=legend,\n            axes=axes,\n            background_color=background_color,\n            noise_cov=noise_cov,\n            exclude=exclude,\n            select=select,\n            show=show,\n        )", "metadata": {}}
{"_id": "mne_mne_evoked.py_animate_topomap_code", "title": "animate_topomap", "text": "def animate_topomap(\n        self,\n        ch_type=None,\n        times=None,\n        frame_rate=None,\n        butterfly=False,\n        blit=True,\n        show=True,\n        time_unit=\"s\",\n        sphere=None,\n        *,\n        image_interp=_INTERPOLATION_DEFAULT,\n        extrapolate=_EXTRAPOLATE_DEFAULT,\n        vmin=None,\n        vmax=None,\n        verbose=None,\n    ):\n        \"\"\"Make animation of evoked data as topomap timeseries.\n\n        The animation can be paused/resumed with left mouse button.\n        Left and right arrow keys can be used to move backward or forward\n        in time.\n\n        Parameters\n        ----------\n        ch_type : str | None\n            Channel type to plot. Accepted data types: 'mag', 'grad', 'eeg',\n            'hbo', 'hbr', 'fnirs_cw_amplitude',\n            'fnirs_fd_ac_amplitude', 'fnirs_fd_phase', and 'fnirs_od'.\n            If None, first available channel type from the above list is used.\n            Defaults to None.\n        times : array of float | None\n            The time points to plot. If None, 10 evenly spaced samples are\n            calculated over the evoked time series. Defaults to None.\n        frame_rate : int | None\n            Frame rate for the animation in Hz. If None,\n            frame rate = sfreq / 10. Defaults to None.\n        butterfly : bool\n            Whether to plot the data as butterfly plot under the topomap.\n            Defaults to False.\n        blit : bool\n            Whether to use blit to optimize drawing. In general, it is\n            recommended to use blit in combination with ``show=True``. If you\n            intend to save the animation it is better to disable blit.\n            Defaults to True.\n        show : bool\n            Whether to show the animation. Defaults to True.\n        time_unit : str\n            The units for the time axis, can be \"ms\" (default in 0.16)\n            or \"s\" (will become the default in 0.17).\n\n            .. versionadded:: 0.16\n        %(sphere_topomap_auto)s\n        %(image_interp_topomap)s\n        %(extrapolate_topomap)s\n\n            .. versionadded:: 0.22\n        %(vmin_vmax_topomap)s\n\n            .. versionadded:: 1.1.0\n        %(verbose)s\n\n        Returns\n        -------\n        fig : instance of matplotlib.figure.Figure\n            The figure.\n        anim : instance of matplotlib.animation.FuncAnimation\n            Animation of the topomap.\n\n        Notes\n        -----\n        .. versionadded:: 0.12.0\n        \"\"\"\n        return _topomap_animation(\n            self,\n            ch_type=ch_type,\n            times=times,\n            frame_rate=frame_rate,\n            butterfly=butterfly,\n            blit=blit,\n            show=show,\n            time_unit=time_unit,\n            sphere=sphere,\n            image_interp=image_interp,\n            extrapolate=extrapolate,\n            vmin=vmin,\n            vmax=vmax,\n            verbose=verbose,\n        )", "metadata": {}}
{"_id": "mne_mne_evoked.py_as_type_code", "title": "as_type", "text": "def as_type(self, ch_type=\"grad\", mode=\"fast\"):\n        \"\"\"Compute virtual evoked using interpolated fields.\n\n        .. Warning:: Using virtual evoked to compute inverse can yield\n            unexpected results. The virtual channels have ``'_v'`` appended\n            at the end of the names to emphasize that the data contained in\n            them are interpolated.\n\n        Parameters\n        ----------\n        ch_type : str\n            The destination channel type. It can be 'mag' or 'grad'.\n        mode : str\n            Either ``'accurate'`` or ``'fast'``, determines the quality of the\n            Legendre polynomial expansion used. ``'fast'`` should be sufficient\n            for most applications.\n\n        Returns\n        -------\n        evoked : instance of mne.Evoked\n            The transformed evoked object containing only virtual channels.\n\n        Notes\n        -----\n        This method returns a copy and does not modify the data it\n        operates on. It also returns an EvokedArray instance.\n\n        .. versionadded:: 0.9.0\n        \"\"\"\n        from .forward import _as_meg_type_inst\n\n        return _as_meg_type_inst(self, ch_type=ch_type, mode=mode)", "metadata": {}}
{"_id": "mne_mne_evoked.py_detrend_code", "title": "detrend", "text": "def detrend(self, order=1, picks=None):\n        \"\"\"Detrend data.\n\n        This function operates in-place.\n\n        Parameters\n        ----------\n        order : int\n            Either 0 or 1, the order of the detrending. 0 is a constant\n            (DC) detrend, 1 is a linear detrend.\n        %(picks_good_data)s\n\n        Returns\n        -------\n        evoked : instance of Evoked\n            The detrended evoked object.\n        \"\"\"\n        picks = _picks_to_idx(self.info, picks)\n        self.data[picks] = detrend(self.data[picks], order, axis=-1)\n        return self", "metadata": {}}
{"_id": "mne_mne_evoked.py_copy_code", "title": "copy", "text": "def copy(self):\n        \"\"\"Copy the instance of evoked.\n\n        Returns\n        -------\n        evoked : instance of Evoked\n            A copy of the object.\n        \"\"\"\n        evoked = deepcopy(self)\n        return evoked", "metadata": {}}
{"_id": "mne_mne_evoked.py_get_peak_code", "title": "get_peak", "text": "def get_peak(\n        self,\n        ch_type=None,\n        tmin=None,\n        tmax=None,\n        mode=\"abs\",\n        time_as_index=False,\n        merge_grads=False,\n        return_amplitude=False,\n        *,\n        strict=True,\n    ):\n        \"\"\"Get location and latency of peak amplitude.\n\n        Parameters\n        ----------\n        ch_type : str | None\n            The channel type to use. Defaults to None. If more than one channel\n            type is present in the data, this value **must** be provided.\n        tmin : float | None\n            The minimum point in time to be considered for peak getting.\n            If None (default), the beginning of the data is used.\n        tmax : float | None\n            The maximum point in time to be considered for peak getting.\n            If None (default), the end of the data is used.\n        mode : 'pos' | 'neg' | 'abs'\n            How to deal with the sign of the data. If 'pos' only positive\n            values will be considered. If 'neg' only negative values will\n            be considered. If 'abs' absolute values will be considered.\n            Defaults to 'abs'.\n        time_as_index : bool\n            Whether to return the time index instead of the latency in seconds.\n        merge_grads : bool\n            If True, compute peak from merged gradiometer data.\n        return_amplitude : bool\n            If True, return also the amplitude at the maximum response.\n\n            .. versionadded:: 0.16\n        strict : bool\n            If True, raise an error if values are all positive when detecting\n            a minimum (mode='neg'), or all negative when detecting a maximum\n            (mode='pos'). Defaults to True.\n\n            .. versionadded:: 1.7\n\n        Returns\n        -------\n        ch_name : str\n            The channel exhibiting the maximum response.\n        latency : float | int\n            The time point of the maximum response, either latency in seconds\n            or index.\n        amplitude : float\n            The amplitude of the maximum response. Only returned if\n            return_amplitude is True.\n\n            .. versionadded:: 0.16\n        \"\"\"  # noqa: E501\n        supported = (\n            \"mag\",\n            \"grad\",\n            \"eeg\",\n            \"seeg\",\n            \"dbs\",\n            \"ecog\",\n            \"misc\",\n            \"None\",\n        ) + _FNIRS_CH_TYPES_SPLIT\n        types_used = self.get_channel_types(unique=True, only_data_chs=True)\n\n        _check_option(\"ch_type\", str(ch_type), supported)\n\n        if ch_type is not None and ch_type not in types_used:\n            raise ValueError(\n                f'Channel type \"{ch_type}\" not found in this evoked object.'\n            )\n\n        elif len(types_used) > 1 and ch_type is None:\n            raise RuntimeError(\n                'Multiple data channel types found. Please pass the \"ch_type\" '\n                \"parameter.\"\n            )\n\n        if merge_grads:\n            if ch_type != \"grad\":\n                raise ValueError('Channel type must be \"grad\" for merge_grads')\n            elif mode == \"neg\":\n                raise ValueError(\n                    \"Negative mode (mode=neg) does not make sense with merge_grads=True\"\n                )\n\n        meg = eeg = misc = seeg = dbs = ecog = fnirs = False\n        picks = None\n        if ch_type in (\"mag\", \"grad\"):\n            meg = ch_type\n        elif ch_type == \"eeg\":\n            eeg = True\n        elif ch_type == \"misc\":\n            misc = True\n        elif ch_type == \"seeg\":\n            seeg = True\n        elif ch_type == \"dbs\":\n            dbs = True\n        elif ch_type == \"ecog\":\n            ecog = True\n        elif ch_type in _FNIRS_CH_TYPES_SPLIT:\n            fnirs = ch_type\n\n        if ch_type is not None:\n            if merge_grads:\n                picks = _pair_grad_sensors(self.info, topomap_coords=False)\n            else:\n                picks = pick_types(\n                    self.info,\n                    meg=meg,\n                    eeg=eeg,\n                    misc=misc,\n                    seeg=seeg,\n                    ecog=ecog,\n                    ref_meg=False,\n                    fnirs=fnirs,\n                    dbs=dbs,\n                )\n        data = self.data\n        ch_names = self.ch_names\n\n        if picks is not None:\n            data = data[picks]\n            ch_names = [ch_names[k] for k in picks]\n\n        if merge_grads:\n            data, _ = _merge_ch_data(data, ch_type, [])\n            ch_names = [ch_name[:-1] + \"X\" for ch_name in ch_names[::2]]\n\n        ch_idx, time_idx, max_amp = _get_peak(\n            data,\n            self.times,\n            tmin,\n            tmax,\n            mode,\n            strict=strict,\n        )\n\n        out = (ch_names[ch_idx], time_idx if time_as_index else self.times[time_idx])\n\n        if return_amplitude:\n            out += (max_amp,)\n\n        return out", "metadata": {}}
{"_id": "mne_mne_evoked.py_compute_psd_code", "title": "compute_psd", "text": "def compute_psd(\n        self,\n        method=\"multitaper\",\n        fmin=0,\n        fmax=np.inf,\n        tmin=None,\n        tmax=None,\n        picks=None,\n        proj=False,\n        remove_dc=True,\n        exclude=(),\n        *,\n        n_jobs=1,\n        verbose=None,\n        **method_kw,\n    ):\n        \"\"\"Perform spectral analysis on sensor data.\n\n        Parameters\n        ----------\n        %(method_psd)s\n            Default is ``'multitaper'``.\n        %(fmin_fmax_psd)s\n        %(tmin_tmax_psd)s\n        %(picks_good_data_noref)s\n        %(proj_psd)s\n        %(remove_dc)s\n        %(exclude_psd)s\n        %(n_jobs)s\n        %(verbose)s\n        %(method_kw_psd)s\n\n        Returns\n        -------\n        spectrum : instance of Spectrum\n            The spectral representation of the data.\n\n        Notes\n        -----\n        .. versionadded:: 1.2\n\n        References\n        ----------\n        .. footbibliography::\n        \"\"\"\n        method = _validate_method(method, type(self).__name__)\n        self._set_legacy_nfft_default(tmin, tmax, method, method_kw)\n\n        return Spectrum(\n            self,\n            method=method,\n            fmin=fmin,\n            fmax=fmax,\n            tmin=tmin,\n            tmax=tmax,\n            picks=picks,\n            exclude=exclude,\n            proj=proj,\n            remove_dc=remove_dc,\n            reject_by_annotation=False,\n            n_jobs=n_jobs,\n            verbose=verbose,\n            **method_kw,\n        )", "metadata": {}}
{"_id": "mne_mne_evoked.py_compute_tfr_code", "title": "compute_tfr", "text": "def compute_tfr(\n        self,\n        method,\n        freqs,\n        *,\n        tmin=None,\n        tmax=None,\n        picks=None,\n        proj=False,\n        output=\"power\",\n        decim=1,\n        n_jobs=None,\n        verbose=None,\n        **method_kw,\n    ):\n        \"\"\"Compute a time-frequency representation of evoked data.\n\n        Parameters\n        ----------\n        %(method_tfr)s\n        %(freqs_tfr)s\n        %(tmin_tmax_psd)s\n        %(picks_good_data_noref)s\n        %(proj_psd)s\n        %(output_compute_tfr)s\n        %(decim_tfr)s\n        %(n_jobs)s\n        %(verbose)s\n        %(method_kw_tfr)s\n\n        Returns\n        -------\n        tfr : instance of AverageTFR\n            The time-frequency-resolved power estimates of the data.\n\n        Notes\n        -----\n        .. versionadded:: 1.7\n\n        References\n        ----------\n        .. footbibliography::\n        \"\"\"\n        _check_option(\"output\", output, (\"power\", \"phase\", \"complex\"))\n        method_kw[\"output\"] = output\n        return AverageTFR(\n            inst=self,\n            method=method,\n            freqs=freqs,\n            tmin=tmin,\n            tmax=tmax,\n            picks=picks,\n            proj=proj,\n            decim=decim,\n            n_jobs=n_jobs,\n            verbose=verbose,\n            **method_kw,\n        )", "metadata": {}}
{"_id": "mne_mne_evoked.py_plot_psd_code", "title": "plot_psd", "text": "def plot_psd(\n        self,\n        fmin=0,\n        fmax=np.inf,\n        tmin=None,\n        tmax=None,\n        picks=None,\n        proj=False,\n        *,\n        method=\"auto\",\n        average=False,\n        dB=True,\n        estimate=\"power\",\n        xscale=\"linear\",\n        area_mode=\"std\",\n        area_alpha=0.33,\n        color=\"black\",\n        line_alpha=None,\n        spatial_colors=True,\n        sphere=None,\n        exclude=\"bads\",\n        ax=None,\n        show=True,\n        n_jobs=1,\n        verbose=None,\n        **method_kw,\n    ):\n        \"\"\"%(plot_psd_doc)s.\n\n        Parameters\n        ----------\n        %(fmin_fmax_psd)s\n        %(tmin_tmax_psd)s\n        %(picks_good_data_noref)s\n        %(proj_psd)s\n        %(method_plot_psd_auto)s\n        %(average_plot_psd)s\n        %(dB_plot_psd)s\n        %(estimate_plot_psd)s\n        %(xscale_plot_psd)s\n        %(area_mode_plot_psd)s\n        %(area_alpha_plot_psd)s\n        %(color_plot_psd)s\n        %(line_alpha_plot_psd)s\n        %(spatial_colors_psd)s\n        %(sphere_topomap_auto)s\n\n            .. versionadded:: 0.22.0\n        exclude : list of str | 'bads'\n            Channels names to exclude from being shown. If 'bads', the bad\n            channels are excluded. Pass an empty list to plot all channels\n            (including channels marked \"bad\", if any).\n\n            .. versionadded:: 0.24.0\n        %(ax_plot_psd)s\n        %(show)s\n        %(n_jobs)s\n        %(verbose)s\n        %(method_kw_psd)s\n\n        Returns\n        -------\n        fig : instance of Figure\n            Figure with frequency spectra of the data channels.\n\n        Notes\n        -----\n        %(notes_plot_psd_meth)s\n        \"\"\"\n        return super().plot_psd(\n            fmin=fmin,\n            fmax=fmax,\n            tmin=tmin,\n            tmax=tmax,\n            picks=picks,\n            proj=proj,\n            reject_by_annotation=False,\n            method=method,\n            average=average,\n            dB=dB,\n            estimate=estimate,\n            xscale=xscale,\n            area_mode=area_mode,\n            area_alpha=area_alpha,\n            color=color,\n            line_alpha=line_alpha,\n            spatial_colors=spatial_colors,\n            sphere=sphere,\n            exclude=exclude,\n            ax=ax,\n            show=show,\n            n_jobs=n_jobs,\n            verbose=verbose,\n            **method_kw,\n        )", "metadata": {}}
{"_id": "mne_mne_evoked.py_to_data_frame_code", "title": "to_data_frame", "text": "def to_data_frame(\n        self,\n        picks=None,\n        index=None,\n        scalings=None,\n        copy=True,\n        long_format=False,\n        time_format=None,\n        *,\n        verbose=None,\n    ):\n        \"\"\"Export data in tabular structure as a pandas DataFrame.\n\n        Channels are converted to columns in the DataFrame. By default,\n        an additional column \"time\" is added, unless ``index='time'``\n        (in which case time values form the DataFrame's index).\n\n        Parameters\n        ----------\n        %(picks_all)s\n        %(index_df_evk)s\n            Defaults to ``None``.\n        %(scalings_df)s\n        %(copy_df)s\n        %(long_format_df_raw)s\n        %(time_format_df)s\n\n            .. versionadded:: 0.20\n        %(verbose)s\n\n        Returns\n        -------\n        %(df_return)s\n        \"\"\"\n        # check pandas once here, instead of in each private utils function\n        pd = _check_pandas_installed()  # noqa\n        # arg checking\n        valid_index_args = [\"time\"]\n        valid_time_formats = [\"ms\", \"timedelta\"]\n        index = _check_pandas_index_arguments(index, valid_index_args)\n        time_format = _check_time_format(time_format, valid_time_formats)\n        # get data\n        picks = _picks_to_idx(self.info, picks, \"all\", exclude=())\n        data = self.data[picks, :]\n        times = self.times\n        data = data.T\n        if copy:\n            data = data.copy()\n        data = _scale_dataframe_data(self, data, picks, scalings)\n        # prepare extra columns / multiindex\n        mindex = list()\n        times = _convert_times(times, time_format, self.info[\"meas_date\"])\n        mindex.append((\"time\", times))\n        # build DataFrame\n        df = _build_data_frame(\n            self, data, picks, long_format, mindex, index, default_index=[\"time\"]\n        )\n        return df", "metadata": {}}
{"_id": "mne_mne_proj.py_read_proj_code", "title": "read_proj", "text": "def read_proj(fname, *, verbose=None):\n    \"\"\"Read projections from a FIF file.\n\n    Parameters\n    ----------\n    fname : path-like\n        The name of file containing the projections vectors. It should end with\n        ``-proj.fif`` or ``-proj.fif.gz``.\n    %(verbose)s\n\n    Returns\n    -------\n    projs : list of Projection\n        The list of projection vectors.\n\n    See Also\n    --------\n    write_proj\n    \"\"\"\n    check_fname(\n        fname, \"projection\", (\"-proj.fif\", \"-proj.fif.gz\", \"_proj.fif\", \"_proj.fif.gz\")\n    )\n    fname = _check_fname(fname, overwrite=\"read\", must_exist=True)\n\n    ff, tree, _ = fiff_open(fname)\n    with ff as fid:\n        projs = _read_proj(fid, tree)\n    return projs", "metadata": {}}
{"_id": "mne_mne_proj.py_write_proj_code", "title": "write_proj", "text": "def write_proj(fname, projs, *, overwrite=False, verbose=None):\n    \"\"\"Write projections to a FIF file.\n\n    Parameters\n    ----------\n    fname : path-like\n        The name of file containing the projections vectors. It should end with\n        ``-proj.fif`` or ``-proj.fif.gz``.\n    projs : list of Projection\n        The list of projection vectors.\n    %(overwrite)s\n\n        .. versionadded:: 1.0\n    %(verbose)s\n\n        .. versionadded:: 1.0\n\n    See Also\n    --------\n    read_proj\n    \"\"\"\n    fname = _check_fname(fname, overwrite=overwrite)\n    check_fname(\n        fname, \"projection\", (\"-proj.fif\", \"-proj.fif.gz\", \"_proj.fif\", \"_proj.fif.gz\")\n    )\n    with start_and_end_file(fname) as fid:\n        _write_proj(fid, projs)", "metadata": {}}
{"_id": "mne_mne_proj.py_compute_proj_epochs_code", "title": "compute_proj_epochs", "text": "def compute_proj_epochs(\n    epochs,\n    n_grad=2,\n    n_mag=2,\n    n_eeg=2,\n    n_jobs=None,\n    desc_prefix=None,\n    meg=\"separate\",\n    verbose=None,\n):\n    \"\"\"Compute SSP (signal-space projection) vectors on epoched data.\n\n    %(compute_ssp)s\n\n    Parameters\n    ----------\n    epochs : instance of Epochs\n        The epochs containing the artifact.\n    %(n_proj_vectors)s\n    %(n_jobs)s\n        Number of jobs to use to compute covariance.\n    desc_prefix : str | None\n        The description prefix to use. If None, one will be created based on\n        the event_id, tmin, and tmax.\n    meg : str\n        Can be ``'separate'`` (default) or ``'combined'`` to compute projectors\n        for magnetometers and gradiometers separately or jointly.\n        If ``'combined'``, ``n_mag == n_grad`` is required and the number of\n        projectors computed for MEG will be ``n_mag``.\n\n        .. versionadded:: 0.18\n    %(verbose)s\n\n    Returns\n    -------\n    projs: list of Projection\n        List of projection vectors.\n\n    See Also\n    --------\n    compute_proj_raw, compute_proj_evoked\n    \"\"\"\n    # compute data covariance\n    data = _compute_cov_epochs(epochs, n_jobs)\n    event_id = epochs.event_id\n    if event_id is None or len(list(event_id.keys())) == 0:\n        event_id = \"0\"\n    elif len(event_id.keys()) == 1:\n        event_id = str(list(event_id.values())[0])\n    else:\n        event_id = \"Multiple-events\"\n    if desc_prefix is None:\n        desc_prefix = f\"{event_id}-{epochs.tmin:<.3f}-{epochs.tmax:<.3f}\"\n    return _compute_proj(data, epochs.info, n_grad, n_mag, n_eeg, desc_prefix, meg=meg)", "metadata": {}}
{"_id": "mne_mne_proj.py_compute_proj_evoked_code", "title": "compute_proj_evoked", "text": "def compute_proj_evoked(\n    evoked, n_grad=2, n_mag=2, n_eeg=2, desc_prefix=None, meg=\"separate\", verbose=None\n):\n    \"\"\"Compute SSP (signal-space projection) vectors on evoked data.\n\n    %(compute_ssp)s\n\n    Parameters\n    ----------\n    evoked : instance of Evoked\n        The Evoked obtained by averaging the artifact.\n    %(n_proj_vectors)s\n    desc_prefix : str | None\n        The description prefix to use. If None, one will be created based on\n        tmin and tmax.\n\n        .. versionadded:: 0.17\n    meg : str\n        Can be ``'separate'`` (default) or ``'combined'`` to compute projectors\n        for magnetometers and gradiometers separately or jointly.\n        If ``'combined'``, ``n_mag == n_grad`` is required and the number of\n        projectors computed for MEG will be ``n_mag``.\n\n        .. versionadded:: 0.18\n    %(verbose)s\n\n    Returns\n    -------\n    projs : list of Projection\n        List of projection vectors.\n\n    See Also\n    --------\n    compute_proj_raw, compute_proj_epochs\n    \"\"\"\n    data = np.dot(evoked.data, evoked.data.T)  # compute data covariance\n    if desc_prefix is None:\n        desc_prefix = f\"{evoked.times[0]:<.3f}-{evoked.times[-1]:<.3f}\"\n    return _compute_proj(data, evoked.info, n_grad, n_mag, n_eeg, desc_prefix, meg=meg)", "metadata": {}}
{"_id": "mne_mne_proj.py_compute_proj_raw_code", "title": "compute_proj_raw", "text": "def compute_proj_raw(\n    raw,\n    start=0,\n    stop=None,\n    duration=1,\n    n_grad=2,\n    n_mag=2,\n    n_eeg=0,\n    reject=None,\n    flat=None,\n    n_jobs=None,\n    meg=\"separate\",\n    verbose=None,\n):\n    \"\"\"Compute SSP (signal-space projection) vectors on continuous data.\n\n    %(compute_ssp)s\n\n    Parameters\n    ----------\n    raw : instance of Raw\n        A raw object to use the data from.\n    start : float\n        Time (in seconds) to start computing SSP.\n    stop : float | None\n        Time (in seconds) to stop computing SSP. None will go to the end of the file.\n    duration : float | None\n        Duration (in seconds) to chunk data into for SSP\n        If duration is ``None``, data will not be chunked.\n    %(n_proj_vectors)s\n    reject : dict | None\n        Epoch PTP rejection threshold used if ``duration != None``. See `~mne.Epochs`.\n    flat : dict | None\n        Epoch flatness rejection threshold used if ``duration != None``. See\n        `~mne.Epochs`.\n    %(n_jobs)s\n        Number of jobs to use to compute covariance.\n    meg : str\n        Can be ``'separate'`` (default) or ``'combined'`` to compute projectors\n        for magnetometers and gradiometers separately or jointly.\n        If ``'combined'``, ``n_mag == n_grad`` is required and the number of\n        projectors computed for MEG will be ``n_mag``.\n\n        .. versionadded:: 0.18\n    %(verbose)s\n\n    Returns\n    -------\n    projs: list of Projection\n        List of projection vectors.\n\n    See Also\n    --------\n    compute_proj_epochs, compute_proj_evoked\n    \"\"\"\n    if duration is not None:\n        duration = np.round(duration * raw.info[\"sfreq\"]) / raw.info[\"sfreq\"]\n        events = make_fixed_length_events(raw, 999, start, stop, duration)\n        picks = pick_types(\n            raw.info, meg=True, eeg=True, eog=True, ecg=True, emg=True, exclude=\"bads\"\n        )\n        epochs = Epochs(\n            raw,\n            events,\n            None,\n            tmin=0.0,\n            tmax=duration - 1.0 / raw.info[\"sfreq\"],\n            picks=picks,\n            reject=reject,\n            flat=flat,\n            baseline=None,\n            proj=False,\n        )\n        data = _compute_cov_epochs(epochs, n_jobs, log_drops=True)\n        info = epochs.info\n        if not stop:\n            stop = raw.n_times / raw.info[\"sfreq\"]\n    else:\n        # convert to sample indices\n        start = max(raw.time_as_index(start)[0], 0)\n        stop = raw.time_as_index(stop)[0] if stop else raw.n_times\n        stop = min(stop, raw.n_times)\n        data, times = raw[:, start:stop]\n        _check_n_samples(stop - start, data.shape[0])\n        data = np.dot(data, data.T)  # compute data covariance\n        info = raw.info\n        # convert back to times\n        start = start / raw.info[\"sfreq\"]\n        stop = stop / raw.info[\"sfreq\"]\n\n    desc_prefix = f\"Raw-{start:<.3f}-{stop:<.3f}\"\n    projs = _compute_proj(data, info, n_grad, n_mag, n_eeg, desc_prefix, meg=meg)\n    return projs", "metadata": {}}
{"_id": "mne_mne_proj.py_sensitivity_map_code", "title": "sensitivity_map", "text": "def sensitivity_map(\n    fwd, projs=None, ch_type=\"grad\", mode=\"fixed\", exclude=(), *, verbose=None\n):\n    \"\"\"Compute sensitivity map.\n\n    Such maps are used to know how much sources are visible by a type\n    of sensor, and how much projections shadow some sources.\n\n    Parameters\n    ----------\n    fwd : Forward\n        The forward operator.\n    projs : list\n        List of projection vectors.\n    ch_type : ``'grad'`` | ``'mag'`` | ``'eeg'``\n        The type of sensors to use.\n    mode : str\n        The type of sensitivity map computed. See manual. Should be ``'free'``,\n        ``'fixed'``, ``'ratio'``, ``'radiality'``, ``'angle'``,\n        ``'remaining'``, or ``'dampening'`` corresponding to the argument\n        ``--map 1, 2, 3, 4, 5, 6, 7`` of the command ``mne_sensitivity_map``.\n    exclude : list of str | str\n        List of channels to exclude. If empty do not exclude any (default).\n        If ``'bads'``, exclude channels in ``fwd['info']['bads']``.\n    %(verbose)s\n\n    Returns\n    -------\n    stc : SourceEstimate | VolSourceEstimate\n        The sensitivity map as a SourceEstimate or VolSourceEstimate instance\n        for visualization.\n\n    Notes\n    -----\n    When mode is ``'fixed'`` or ``'free'``, the sensitivity map is normalized\n    by its maximum value.\n    \"\"\"\n    # check strings\n    _check_option(\"ch_type\", ch_type, [\"eeg\", \"grad\", \"mag\"])\n    _check_option(\n        \"mode\",\n        mode,\n        [\"free\", \"fixed\", \"ratio\", \"radiality\", \"angle\", \"remaining\", \"dampening\"],\n    )\n\n    # check forward\n    if is_fixed_orient(fwd, orig=True):\n        raise ValueError(\"fwd should must be computed with free orientation\")\n\n    # limit forward (this will make a copy of the data for us)\n    if ch_type == \"eeg\":\n        fwd = pick_types_forward(fwd, meg=False, eeg=True, exclude=exclude)\n    else:\n        fwd = pick_types_forward(fwd, meg=ch_type, eeg=False, exclude=exclude)\n\n    convert_forward_solution(\n        fwd, surf_ori=True, force_fixed=False, copy=False, verbose=False\n    )\n    assert fwd[\"surf_ori\"] and not is_fixed_orient(fwd)\n\n    gain = fwd[\"sol\"][\"data\"]\n\n    # Make sure EEG has average\n    if ch_type == \"eeg\":\n        if projs is None or not _has_eeg_average_ref_proj(fwd[\"info\"], projs=projs):\n            eeg_ave = [make_eeg_average_ref_proj(fwd[\"info\"])]\n        else:\n            eeg_ave = []\n        projs = eeg_ave if projs is None else projs + eeg_ave\n\n    # Construct the projector\n    residual_types = [\"angle\", \"remaining\", \"dampening\"]\n    if projs is not None:\n        proj, ncomp, U = make_projector(\n            projs, fwd[\"sol\"][\"row_names\"], include_active=True\n        )\n        # do projection for most types\n        if mode not in residual_types:\n            gain = np.dot(proj, gain)\n        elif ncomp == 0:\n            raise RuntimeError(\n                \"No valid projectors found for channel type \"\n                f\"{ch_type}, cannot compute {mode}\"\n            )\n    # can only run the last couple methods if there are projectors\n    elif mode in residual_types:\n        raise ValueError(f\"No projectors used, cannot compute {mode}\")\n\n    _, n_dipoles = gain.shape\n    n_locations = n_dipoles // 3\n    del n_dipoles\n    sensitivity_map = np.empty(n_locations)\n\n    for k in range(n_locations):\n        gg = gain[:, 3 * k : 3 * (k + 1)]  # noqa: E203\n        if mode != \"fixed\":\n            s = _safe_svd(gg, full_matrices=False, compute_uv=False)\n        if mode == \"free\":\n            sensitivity_map[k] = s[0]\n        else:\n            gz = np.linalg.norm(gg[:, 2])  # the normal component\n            if mode == \"fixed\":\n                sensitivity_map[k] = gz\n            elif mode == \"ratio\":\n                sensitivity_map[k] = gz / s[0]\n            elif mode == \"radiality\":\n                sensitivity_map[k] = 1.0 - (gz / s[0])\n            else:\n                if mode == \"angle\":\n                    co = np.linalg.norm(np.dot(gg[:, 2], U))\n                    sensitivity_map[k] = co / gz\n                else:\n                    p = np.linalg.norm(np.dot(proj, gg[:, 2]))\n                    if mode == \"remaining\":\n                        sensitivity_map[k] = p / gz\n                    elif mode == \"dampening\":\n                        sensitivity_map[k] = 1.0 - p / gz\n                    else:\n                        raise ValueError(f\"Unknown mode type (got {mode})\")\n\n    # only normalize fixed and free methods\n    if mode in [\"fixed\", \"free\"]:\n        sensitivity_map /= np.max(sensitivity_map)\n\n    subject = _subject_from_forward(fwd)\n    vertices = [s[\"vertno\"] for s in fwd[\"src\"]]\n    return _make_stc(\n        sensitivity_map[:, np.newaxis],\n        vertices,\n        fwd[\"src\"].kind,\n        tmin=0.0,\n        tstep=1.0,\n        subject=subject,\n    )", "metadata": {}}
{"_id": "mne_mne_misc.py_parse_config_code", "title": "parse_config", "text": "def parse_config(fname):\n    \"\"\"Parse a config file (like .ave and .cov files).\n\n    Parameters\n    ----------\n    fname : path-like\n        Config file name.\n\n    Returns\n    -------\n    conditions : list of dict\n        Each condition is indexed by the event type.\n        A condition contains as keys::\n\n            tmin, tmax, name, grad_reject, mag_reject,\n            eeg_reject, eog_reject\n    \"\"\"\n    reject_params = read_reject_parameters(fname)\n\n    with open(fname) as f:\n        lines = f.readlines()\n\n    cat_ind = [i for i, x in enumerate(lines) if \"category {\" in x]\n    event_dict = dict()\n    for ind in cat_ind:\n        for k in range(ind + 1, ind + 7):\n            words = lines[k].split()\n            if len(words) >= 2:\n                key = words[0]\n                if key == \"event\":\n                    event = int(words[1])\n                    break\n        else:\n            raise ValueError(\"Could not find event id.\")\n        event_dict[event] = dict(**reject_params)\n        for k in range(ind + 1, ind + 7):\n            words = lines[k].split()\n            if len(words) >= 2:\n                key = words[0]\n                if key == \"name\":\n                    name = \" \".join(words[1:])\n                    if name[0] == '\"':\n                        name = name[1:]\n                    if name[-1] == '\"':\n                        name = name[:-1]\n                    event_dict[event][\"name\"] = name\n                if key in [\"tmin\", \"tmax\", \"basemin\", \"basemax\"]:\n                    event_dict[event][key] = float(words[1])\n    return event_dict", "metadata": {}}
{"_id": "mne_mne_misc.py_read_reject_parameters_code", "title": "read_reject_parameters", "text": "def read_reject_parameters(fname):\n    \"\"\"Read rejection parameters from .cov or .ave config file.\n\n    Parameters\n    ----------\n    fname : path-like\n        Filename to read.\n\n    Returns\n    -------\n    params : dict\n        The rejection parameters.\n    \"\"\"\n    with open(fname) as f:\n        lines = f.readlines()\n\n    reject_names = [\"gradReject\", \"magReject\", \"eegReject\", \"eogReject\", \"ecgReject\"]\n    reject_pynames = [\"grad\", \"mag\", \"eeg\", \"eog\", \"ecg\"]\n    reject = dict()\n    for line in lines:\n        words = line.split()\n        if words[0] in reject_names:\n            reject[reject_pynames[reject_names.index(words[0])]] = float(words[1])\n\n    return reject", "metadata": {}}
{"_id": "mne_mne_fixes.py_rng_uniform_code", "title": "rng_uniform", "text": "def rng_uniform(rng):\n    \"\"\"Get the uniform/randint from the rng.\"\"\"\n    # prefer Generator.integers, fall back to RandomState.randint\n    return getattr(rng, \"integers\", getattr(rng, \"randint\", None))", "metadata": {}}
{"_id": "mne_mne_fixes.py_empirical_covariance_code", "title": "empirical_covariance", "text": "def empirical_covariance(X, assume_centered=False):\n    \"\"\"Compute the Maximum likelihood covariance estimator.\n\n    Parameters\n    ----------\n    X : ndarray, shape (n_samples, n_features)\n        Data from which to compute the covariance estimate\n\n    assume_centered : Boolean\n        If True, data are not centered before computation.\n        Useful when working with data whose mean is almost, but not exactly\n        zero.\n        If False, data are centered before computation.\n\n    Returns\n    -------\n    covariance : 2D ndarray, shape (n_features, n_features)\n        Empirical covariance (Maximum Likelihood Estimator).\n    \"\"\"\n    X = np.asarray(X)\n    if X.ndim == 1:\n        X = np.reshape(X, (1, -1))\n\n    if X.shape[0] == 1:\n        warnings.warn(\n            \"Only one sample available. You may want to reshape your data array\"\n        )\n\n    if assume_centered:\n        covariance = np.dot(X.T, X) / X.shape[0]\n    else:\n        covariance = np.cov(X.T, bias=1)\n\n    if covariance.ndim == 0:\n        covariance = np.array([[covariance]])\n    return covariance", "metadata": {}}
{"_id": "mne_mne_fixes.py_log_likelihood_code", "title": "log_likelihood", "text": "def log_likelihood(emp_cov, precision):\n    \"\"\"Compute the sample mean of the log_likelihood under a covariance model.\n\n    computes the empirical expected log-likelihood (accounting for the\n    normalization terms and scaling), allowing for universal comparison (beyond\n    this software package)\n\n    Parameters\n    ----------\n    emp_cov : 2D ndarray (n_features, n_features)\n        Maximum Likelihood Estimator of covariance\n\n    precision : 2D ndarray (n_features, n_features)\n        The precision matrix of the covariance model to be tested\n\n    Returns\n    -------\n    sample mean of the log-likelihood\n    \"\"\"\n    p = precision.shape[0]\n    log_likelihood_ = -np.sum(emp_cov * precision) + _logdet(precision)\n    log_likelihood_ -= p * np.log(2 * np.pi)\n    log_likelihood_ /= 2.0\n    return log_likelihood_", "metadata": {}}
{"_id": "mne_mne_fixes.py_stable_cumsum_code", "title": "stable_cumsum", "text": "def stable_cumsum(arr, axis=None, rtol=1e-05, atol=1e-08):\n    \"\"\"Use high precision for cumsum and check that final value matches sum.\n\n    Parameters\n    ----------\n    arr : array-like\n        To be cumulatively summed as flat\n    axis : int, optional\n        Axis along which the cumulative sum is computed.\n        The default (None) is to compute the cumsum over the flattened array.\n    rtol : float\n        Relative tolerance, see ``np.allclose``\n    atol : float\n        Absolute tolerance, see ``np.allclose``\n    \"\"\"\n    out = np.cumsum(arr, axis=axis, dtype=np.float64)\n    expected = np.sum(arr, axis=axis, dtype=np.float64)\n    if not np.all(\n        np.isclose(\n            out.take(-1, axis=axis), expected, rtol=rtol, atol=atol, equal_nan=True\n        )\n    ):\n        warnings.warn(\n            \"cumsum was found to be unstable: \"\n            \"its last element does not correspond to sum\",\n            RuntimeWarning,\n        )\n    return out", "metadata": {}}
{"_id": "mne_mne_fixes.py_minimum_phase_code", "title": "minimum_phase", "text": "def minimum_phase(h, method=\"homomorphic\", n_fft=None, *, half=True):\n    \"\"\"Wrap scipy.signal.minimum_phase with half option.\"\"\"\n    # Can be removed once\n    from scipy.fft import fft, ifft\n    from scipy.signal import minimum_phase as sp_minimum_phase\n\n    assert isinstance(method, str) and method == \"homomorphic\"\n\n    if \"half\" in inspect.getfullargspec(sp_minimum_phase).kwonlyargs:\n        return sp_minimum_phase(h, method=method, n_fft=n_fft, half=half)\n    h = np.asarray(h)\n    if np.iscomplexobj(h):\n        raise ValueError(\"Complex filters not supported\")\n    if h.ndim != 1 or h.size <= 2:\n        raise ValueError(\"h must be 1-D and at least 2 samples long\")\n    n_half = len(h) // 2\n    if not np.allclose(h[-n_half:][::-1], h[:n_half]):\n        warnings.warn(\n            \"h does not appear to by symmetric, conversion may fail\",\n            RuntimeWarning,\n            stacklevel=2,\n        )\n    if n_fft is None:\n        n_fft = 2 ** int(np.ceil(np.log2(2 * (len(h) - 1) / 0.01)))\n    n_fft = int(n_fft)\n    if n_fft < len(h):\n        raise ValueError(f\"n_fft must be at least len(h)=={len(h)}\")\n\n    # zero-pad; calculate the DFT\n    h_temp = np.abs(fft(h, n_fft))\n    # take 0.25*log(|H|**2) = 0.5*log(|H|)\n    h_temp += 1e-7 * h_temp[h_temp > 0].min()  # don't let log blow up\n    np.log(h_temp, out=h_temp)\n    if half:  # halving of magnitude spectrum optional\n        h_temp *= 0.5\n    # IDFT\n    h_temp = ifft(h_temp).real\n    # multiply pointwise by the homomorphic filter\n    # lmin[n] = 2u[n] - d[n]\n    # i.e., double the positive frequencies and zero out the negative ones;\n    # Oppenheim+Shafer 3rd ed p991 eq13.42b and p1004 fig13.7\n    win = np.zeros(n_fft)\n    win[0] = 1\n    stop = n_fft // 2\n    win[1:stop] = 2\n    if n_fft % 2:\n        win[stop] = 1\n    h_temp *= win\n    h_temp = ifft(np.exp(fft(h_temp)))\n    h_minimum = h_temp.real\n\n    n_out = (n_half + len(h) % 2) if half else len(h)\n    return h_minimum[:n_out]", "metadata": {}}
{"_id": "mne_mne_fixes.py_sph_harm_y_code", "title": "sph_harm_y", "text": "def sph_harm_y(n, m, theta, phi, *, diff_n=0):\n    \"\"\"Wrap scipy.special.sph_harm for sph_harm_y.\"\"\"\n    # Can be removed once we no longer support scipy < 1.15.0\n    from scipy import special\n\n    if \"sph_harm_y\" in special.__dict__:\n        return special.sph_harm_y(n, m, theta, phi, diff_n=diff_n)\n    else:\n        return special.sph_harm(m, n, phi, theta)", "metadata": {}}
{"_id": "mne_mne_fixes.py_get_params_code", "title": "get_params", "text": "def get_params(self, deep=True):\n        \"\"\"Get parameters for this estimator.\n\n        Parameters\n        ----------\n        deep : bool, default=True\n            If True, will return the parameters for this estimator and\n            contained subobjects that are estimators.\n\n        Returns\n        -------\n        params : dict\n            Parameter names mapped to their values.\n        \"\"\"\n        out = dict()\n        for key in self._param_names():\n            out[key] = getattr(self, key)\n        return out", "metadata": {}}
{"_id": "mne_mne_fixes.py_set_params_code", "title": "set_params", "text": "def set_params(self, **params):\n        \"\"\"Set the parameters of this estimator.\n\n        The method works on simple estimators as well as on nested objects\n        (such as pipelines). The latter have parameters of the form\n        ``<component>__<parameter>`` so that it's possible to update each\n        component of a nested object.\n\n        Parameters\n        ----------\n        **params : dict\n            Estimator parameters.\n\n        Returns\n        -------\n        self : object\n            Estimator instance.\n        \"\"\"\n        param_names = self._param_names()\n        for key in params:\n            if key in param_names:\n                setattr(self, key, params[key])", "metadata": {}}
{"_id": "mne_mne_fixes.py_get_precision_code", "title": "get_precision", "text": "def get_precision(self):\n        \"\"\"Getter for the precision matrix.\n\n        Returns\n        -------\n        precision_ : array-like,\n            The precision matrix associated to the current covariance object.\n\n        \"\"\"\n        from scipy import linalg\n\n        if self.store_precision:\n            precision = self.precision_\n        else:\n            precision = linalg.pinvh(self.covariance_)\n        return precision", "metadata": {}}
{"_id": "mne_mne_fixes.py_fit_code", "title": "fit", "text": "def fit(self, X, y=None):\n        \"\"\"Fit the Maximum Likelihood Estimator covariance model.\n\n        Parameters\n        ----------\n        X : array-like, shape = [n_samples, n_features]\n          Training data, where n_samples is the number of samples and\n          n_features is the number of features.\n        y : ndarray | None\n            Not used, present for API consistency.\n\n        Returns\n        -------\n        self : object\n            Returns self.\n        \"\"\"  # noqa: E501\n        # X = check_array(X)\n        if self.assume_centered:\n            self.location_ = np.zeros(X.shape[1])\n        else:\n            self.location_ = X.mean(0)\n        covariance = empirical_covariance(X, assume_centered=self.assume_centered)\n        self._set_covariance(covariance)\n\n        return self", "metadata": {}}
{"_id": "mne_mne_fixes.py_score_code", "title": "score", "text": "def score(self, X_test, y=None):\n        \"\"\"Compute the log-likelihood of a Gaussian dataset.\n\n        Uses ``self.covariance_`` as an estimator of its covariance matrix.\n\n        Parameters\n        ----------\n        X_test : array-like, shape = [n_samples, n_features]\n            Test data of which we compute the likelihood, where n_samples is\n            the number of samples and n_features is the number of features.\n            X_test is assumed to be drawn from the same distribution than\n            the data used in fit (including centering).\n        y : ndarray | None\n            Not used, present for API consistency.\n\n        Returns\n        -------\n        res : float\n            The likelihood of the data set with `self.covariance_` as an\n            estimator of its covariance matrix.\n        \"\"\"\n        # compute empirical covariance of the test set\n        test_cov = empirical_covariance(X_test - self.location_, assume_centered=True)\n        # compute log likelihood\n        res = log_likelihood(test_cov, self.get_precision())\n\n        return res", "metadata": {}}
{"_id": "mne_mne_fixes.py_error_norm_code", "title": "error_norm", "text": "def error_norm(self, comp_cov, norm=\"frobenius\", scaling=True, squared=True):\n        \"\"\"Compute the Mean Squared Error between two covariance estimators.\n\n        Parameters\n        ----------\n        comp_cov : array-like, shape = [n_features, n_features]\n            The covariance to compare with.\n        norm : str\n            The type of norm used to compute the error. Available error types:\n            - 'frobenius' (default): sqrt(tr(A^t.A))\n            - 'spectral': sqrt(max(eigenvalues(A^t.A))\n            where A is the error ``(comp_cov - self.covariance_)``.\n        scaling : bool\n            If True (default), the squared error norm is divided by n_features.\n            If False, the squared error norm is not rescaled.\n        squared : bool\n            Whether to compute the squared error norm or the error norm.\n            If True (default), the squared error norm is returned.\n            If False, the error norm is returned.\n\n        Returns\n        -------\n        The Mean Squared Error (in the sense of the Frobenius norm) between\n        `self` and `comp_cov` covariance estimators.\n        \"\"\"\n        from scipy import linalg\n\n        # compute the error\n        error = comp_cov - self.covariance_\n        # compute the error norm\n        if norm == \"frobenius\":\n            squared_norm = np.sum(error**2)\n        elif norm == \"spectral\":\n            squared_norm = np.amax(linalg.svdvals(np.dot(error.T, error)))\n        else:\n            raise NotImplementedError(\n                \"Only spectral and frobenius norms are implemented\"\n            )\n        # optionally scale the error norm\n        if scaling:\n            squared_norm = squared_norm / error.shape[0]\n        # finally get either the squared norm or the norm\n        if squared:\n            result = squared_norm\n        else:\n            result = np.sqrt(squared_norm)\n\n        return result", "metadata": {}}
{"_id": "mne_mne_fixes.py_mahalanobis_code", "title": "mahalanobis", "text": "def mahalanobis(self, observations):\n        \"\"\"Compute the squared Mahalanobis distances of given observations.\n\n        Parameters\n        ----------\n        observations : array-like, shape = [n_observations, n_features]\n            The observations, the Mahalanobis distances of the which we\n            compute. Observations are assumed to be drawn from the same\n            distribution than the data used in fit.\n\n        Returns\n        -------\n        mahalanobis_distance : array, shape = [n_observations,]\n            Squared Mahalanobis distances of the observations.\n        \"\"\"\n        precision = self.get_precision()\n        # compute mahalanobis distances\n        centered_obs = observations - self.location_\n        mahalanobis_dist = np.sum(np.dot(centered_obs, precision) * centered_obs, 1)\n\n        return mahalanobis_dist", "metadata": {}}
{"_id": "mne_mne__freesurfer.py_get_volume_labels_from_aseg_code", "title": "get_volume_labels_from_aseg", "text": "def get_volume_labels_from_aseg(mgz_fname, return_colors=False, atlas_ids=None):\n    \"\"\"Return a list of names and colors of segmented volumes.\n\n    Parameters\n    ----------\n    mgz_fname : path-like\n        Filename to read. Typically ``aseg.mgz`` or some variant in the\n        freesurfer pipeline.\n    return_colors : bool\n        If True returns also the labels colors.\n    atlas_ids : dict | None\n        A lookup table providing a mapping from region names (str) to ID values\n        (int). Can be None to use the standard Freesurfer LUT.\n\n        .. versionadded:: 0.21.0\n\n    Returns\n    -------\n    label_names : list of str\n        The names of segmented volumes included in this mgz file.\n    label_colors : list of str\n        The RGB colors of the labels included in this mgz file.\n\n    See Also\n    --------\n    read_freesurfer_lut\n\n    Notes\n    -----\n    .. versionchanged:: 0.21.0\n       The label names are now sorted in the same order as their corresponding\n       values in the MRI file.\n\n    .. versionadded:: 0.9.0\n    \"\"\"\n    nib = _import_nibabel(\"load MRI atlas data\")\n    mgz_fname = _check_fname(\n        mgz_fname, overwrite=\"read\", must_exist=True, name=\"mgz_fname\"\n    )\n    atlas = nib.load(mgz_fname)\n    data = np.asarray(atlas.dataobj)  # don't need float here\n    want = np.unique(data)\n    if atlas_ids is None:\n        atlas_ids, colors = read_freesurfer_lut()\n    elif return_colors:\n        raise ValueError(\"return_colors must be False if atlas_ids are provided\")\n    # restrict to the ones in the MRI, sorted by label name\n    keep = np.isin(list(atlas_ids.values()), want)\n    keys = sorted(\n        (key for ki, key in enumerate(atlas_ids.keys()) if keep[ki]),\n        key=lambda x: atlas_ids[x],\n    )\n    if return_colors:\n        colors = [colors[k] for k in keys]\n        out = keys, colors\n    else:\n        out = keys\n    return out", "metadata": {}}
{"_id": "mne_mne__freesurfer.py_head_to_mri_code", "title": "head_to_mri", "text": "def head_to_mri(\n    pos,\n    subject,\n    mri_head_t,\n    subjects_dir=None,\n    *,\n    kind=\"mri\",\n    unscale=False,\n    verbose=None,\n):\n    \"\"\"Convert pos from head coordinate system to MRI ones.\n\n    Parameters\n    ----------\n    pos : array, shape (n_pos, 3)\n        The coordinates (in m) in head coordinate system.\n    %(subject)s\n    mri_head_t : instance of Transform\n        MRI<->Head coordinate transformation.\n    %(subjects_dir)s\n    kind : str\n        The  MRI coordinate frame kind, can be ``'mri'`` (default) for\n        FreeSurfer surface RAS or ``'ras'`` (default in 1.2) to use MRI RAS\n        (scanner RAS).\n\n        .. versionadded:: 1.2\n    unscale : bool\n        For surrogate MRIs (e.g., scaled using ``mne coreg``), if True\n        (default False), use the MRI scaling parameters to obtain points in\n        the original/surrogate subject's MRI space.\n\n        .. versionadded:: 1.2\n    %(verbose)s\n\n    Returns\n    -------\n    coordinates : array, shape (n_pos, 3)\n        The MRI RAS coordinates (in mm) of pos.\n\n    Notes\n    -----\n    This function requires nibabel.\n    \"\"\"\n    from .coreg import read_mri_cfg\n\n    _validate_type(kind, str, \"kind\")\n    _check_option(\"kind\", kind, (\"ras\", \"mri\"))\n    subjects_dir = get_subjects_dir(subjects_dir, raise_error=True)\n    t1_fname = subjects_dir / subject / \"mri\" / \"T1.mgz\"\n    head_mri_t = _ensure_trans(mri_head_t, \"head\", \"mri\")\n    if kind == \"ras\":\n        _, _, mri_ras_t, _, _ = _read_mri_info(t1_fname)\n        head_ras_t = combine_transforms(head_mri_t, mri_ras_t, \"head\", \"ras\")\n        head_dest_t = head_ras_t\n    else:\n        assert kind == \"mri\"\n        head_dest_t = head_mri_t\n    pos_dest = apply_trans(head_dest_t, pos)\n    # unscale if requested\n    if unscale:\n        params = read_mri_cfg(subject, subjects_dir)\n        pos_dest /= params[\"scale\"]\n    pos_dest *= 1e3  # mm\n    return pos_dest", "metadata": {}}
{"_id": "mne_mne__freesurfer.py_vertex_to_mni_code", "title": "vertex_to_mni", "text": "def vertex_to_mni(vertices, hemis, subject, subjects_dir=None, verbose=None):\n    \"\"\"Convert the array of vertices for a hemisphere to MNI coordinates.\n\n    Parameters\n    ----------\n    vertices : int, or list of int\n        Vertex number(s) to convert.\n    hemis : int, or list of int\n        Hemisphere(s) the vertices belong to.\n    %(subject)s\n    subjects_dir : str, or None\n        Path to ``SUBJECTS_DIR`` if it is not set in the environment.\n    %(verbose)s\n\n    Returns\n    -------\n    coordinates : array, shape (n_vertices, 3)\n        The MNI coordinates (in mm) of the vertices.\n    \"\"\"\n    singleton = False\n    if not isinstance(vertices, list) and not isinstance(vertices, np.ndarray):\n        singleton = True\n        vertices = [vertices]\n\n    if not isinstance(hemis, list) and not isinstance(hemis, np.ndarray):\n        hemis = [hemis] * len(vertices)\n\n    if not len(hemis) == len(vertices):\n        raise ValueError(\"hemi and vertices must match in length\")\n\n    subjects_dir = get_subjects_dir(subjects_dir, raise_error=True)\n\n    surfs = [subjects_dir / subject / \"surf\" / f\"{h}.white\" for h in [\"lh\", \"rh\"]]\n\n    # read surface locations in MRI space\n    rr = [read_surface(s)[0] for s in surfs]\n\n    # take point locations in MRI space and convert to MNI coordinates\n    xfm = read_talxfm(subject, subjects_dir)\n    xfm[\"trans\"][:3, 3] *= 1000.0  # m->mm\n    data = np.array([rr[h][v, :] for h, v in zip(hemis, vertices)])\n    if singleton:\n        data = data[0]\n    return apply_trans(xfm[\"trans\"], data)", "metadata": {}}
{"_id": "mne_mne__freesurfer.py_head_to_mni_code", "title": "head_to_mni", "text": "def head_to_mni(pos, subject, mri_head_t, subjects_dir=None, verbose=None):\n    \"\"\"Convert pos from head coordinate system to MNI ones.\n\n    Parameters\n    ----------\n    pos : array, shape (n_pos, 3)\n        The coordinates (in m) in head coordinate system.\n    %(subject)s\n    mri_head_t : instance of Transform\n        MRI<->Head coordinate transformation.\n    %(subjects_dir)s\n    %(verbose)s\n\n    Returns\n    -------\n    coordinates : array, shape (n_pos, 3)\n        The MNI coordinates (in mm) of pos.\n\n    Notes\n    -----\n    This function requires either nibabel.\n    \"\"\"\n    subjects_dir = get_subjects_dir(subjects_dir, raise_error=True)\n\n    # before we go from head to MRI (surface RAS)\n    head_mni_t = combine_transforms(\n        _ensure_trans(mri_head_t, \"head\", \"mri\"),\n        read_talxfm(subject, subjects_dir),\n        \"head\",\n        \"mni_tal\",\n    )\n    return apply_trans(head_mni_t, pos) * 1000.0", "metadata": {}}
{"_id": "mne_mne__freesurfer.py_get_mni_fiducials_code", "title": "get_mni_fiducials", "text": "def get_mni_fiducials(subject, subjects_dir=None, verbose=None):\n    \"\"\"Estimate fiducials for a subject.\n\n    Parameters\n    ----------\n    %(subject)s\n    %(subjects_dir)s\n    %(verbose)s\n\n    Returns\n    -------\n    fids_mri : list\n        List of estimated fiducials (each point in a dict), in the order\n        LPA, nasion, RPA.\n\n    Notes\n    -----\n    This takes the ``fsaverage-fiducials.fif`` file included with MNE\u2014which\n    contain the LPA, nasion, and RPA for the ``fsaverage`` subject\u2014and\n    transforms them to the given FreeSurfer subject's MRI space.\n    The MRI of ``fsaverage`` is already in MNI Talairach space, so applying\n    the inverse of the given subject's MNI Talairach affine transformation\n    (``$SUBJECTS_DIR/$SUBJECT/mri/transforms/talairach.xfm``) is used\n    to estimate the subject's fiducial locations.\n\n    For more details about the coordinate systems and transformations involved,\n    see https://surfer.nmr.mgh.harvard.edu/fswiki/CoordinateSystems and\n    :ref:`tut-source-alignment`.\n    \"\"\"\n    # Eventually we might want to allow using the MNI Talairach with-skull\n    # transformation rather than the standard brain-based MNI Talaranch\n    # transformation, and/or project the points onto the head surface\n    # (if available).\n    fname_fids_fs = (\n        Path(__file__).parent / \"data\" / \"fsaverage\" / \"fsaverage-fiducials.fif\"\n    )\n\n    # Read fsaverage fiducials file and subject Talairach.\n    fids, coord_frame = read_fiducials(fname_fids_fs)\n    assert coord_frame == FIFF.FIFFV_COORD_MRI\n    if subject == \"fsaverage\":\n        return fids  # special short-circuit for fsaverage\n    mni_mri_t = invert_transform(read_talxfm(subject, subjects_dir))\n    for f in fids:\n        f[\"r\"] = apply_trans(mni_mri_t, f[\"r\"])\n    return fids", "metadata": {}}
{"_id": "mne_mne__freesurfer.py_estimate_head_mri_t_code", "title": "estimate_head_mri_t", "text": "def estimate_head_mri_t(subject, subjects_dir=None, verbose=None):\n    \"\"\"Estimate the head->mri transform from fsaverage fiducials.\n\n    A subject's fiducials can be estimated given a Freesurfer ``recon-all``\n    by transforming ``fsaverage`` fiducials using the inverse Talairach\n    transform, see :func:`mne.coreg.get_mni_fiducials`.\n\n    Parameters\n    ----------\n    %(subject)s\n    %(subjects_dir)s\n    %(verbose)s\n\n    Returns\n    -------\n    %(trans_not_none)s\n    \"\"\"\n    from .channels.montage import compute_native_head_t, make_dig_montage\n\n    subjects_dir = get_subjects_dir(subjects_dir, raise_error=True)\n    lpa, nasion, rpa = get_mni_fiducials(subject, subjects_dir)\n    montage = make_dig_montage(\n        lpa=lpa[\"r\"], nasion=nasion[\"r\"], rpa=rpa[\"r\"], coord_frame=\"mri\"\n    )\n    return invert_transform(compute_native_head_t(montage))", "metadata": {}}
{"_id": "mne_mne__freesurfer.py_read_lta_code", "title": "read_lta", "text": "def read_lta(fname, verbose=None):\n    \"\"\"Read a Freesurfer linear transform array file.\n\n    Parameters\n    ----------\n    fname : path-like\n        The transform filename.\n    %(verbose)s\n\n    Returns\n    -------\n    affine : ndarray\n        The affine transformation described by the lta file.\n    \"\"\"\n    _check_fname(fname, \"read\", must_exist=True)\n    with open(fname) as fid:\n        lines = fid.readlines()\n    # 0 is linear vox2vox, 1 is linear ras2ras\n    trans_type = int(lines[0].split(\"=\")[1].strip()[0])\n    assert trans_type in (0, 1)\n    affine = np.loadtxt(lines[5:9])\n    if trans_type == 1:\n        return affine\n\n    src_affine = _get_affine_from_lta_info(lines[12:18])\n    dst_affine = _get_affine_from_lta_info(lines[21:27])\n\n    # don't compute if src and dst are already identical\n    if np.allclose(src_affine, dst_affine):\n        return affine\n\n    ras2ras = src_affine @ np.linalg.inv(affine) @ np.linalg.inv(dst_affine)\n    affine = np.linalg.inv(np.linalg.inv(src_affine) @ ras2ras @ src_affine)\n    return affine", "metadata": {}}
{"_id": "mne_mne__freesurfer.py_read_talxfm_code", "title": "read_talxfm", "text": "def read_talxfm(subject, subjects_dir=None, verbose=None):\n    \"\"\"Compute MRI-to-MNI transform from FreeSurfer talairach.xfm file.\n\n    Parameters\n    ----------\n    %(subject)s\n    %(subjects_dir)s\n    %(verbose)s\n\n    Returns\n    -------\n    mri_mni_t : instance of Transform\n        The affine transformation from MRI to MNI space for the subject.\n    \"\"\"\n    # Adapted from freesurfer m-files. Altered to deal with Norig\n    # and Torig correctly\n    subjects_dir = get_subjects_dir(subjects_dir)\n    # Setup the RAS to MNI transform\n    ras_mni_t = read_ras_mni_t(subject, subjects_dir)\n    ras_mni_t[\"trans\"][:3, 3] /= 1000.0  # mm->m\n\n    # We want to get from Freesurfer surface RAS ('mri') to MNI ('mni_tal').\n    # This file only gives us RAS (non-zero origin) ('ras') to MNI ('mni_tal').\n    # Se we need to get the ras->mri transform from the MRI headers.\n\n    # To do this, we get Norig and Torig\n    # (i.e. vox_ras_t and vox_mri_t, respectively)\n    path = subjects_dir / subject / \"mri\" / \"orig.mgz\"\n    if not path.is_file():\n        path = subjects_dir / subject / \"mri\" / \"T1.mgz\"\n    if not path.is_file():\n        raise OSError(f\"mri not found: {path}\")\n    _, _, mri_ras_t, _, _ = _read_mri_info(path)\n    mri_mni_t = combine_transforms(mri_ras_t, ras_mni_t, \"mri\", \"mni_tal\")\n    return mri_mni_t", "metadata": {}}
{"_id": "mne_mne__freesurfer.py_read_freesurfer_lut_code", "title": "read_freesurfer_lut", "text": "def read_freesurfer_lut(fname=None):\n    \"\"\"Read a Freesurfer-formatted LUT.\n\n    Parameters\n    ----------\n    fname : path-like | None\n        The filename. Can be None to read the standard Freesurfer LUT.\n\n    Returns\n    -------\n    atlas_ids : dict\n        Mapping from label names to IDs.\n    colors : dict\n        Mapping from label names to colors.\n    \"\"\"\n    lut = _get_lut(fname)\n    names, ids = lut[\"name\"], lut[\"id\"]\n    colors = np.array([lut[\"R\"], lut[\"G\"], lut[\"B\"], lut[\"A\"]], float).T\n    atlas_ids = dict(zip(names, ids))\n    colors = dict(zip(names, colors))\n    return atlas_ids, colors", "metadata": {}}
{"_id": "mne_mne_morph_map.py_read_morph_map_code", "title": "read_morph_map", "text": "def read_morph_map(\n    subject_from, subject_to, subjects_dir=None, xhemi=False, verbose=None\n):\n    \"\"\"Read morph map.\n\n    Morph maps can be generated with mne_make_morph_maps. If one isn't\n    available, it will be generated automatically and saved to the\n    ``subjects_dir/morph_maps`` directory.\n\n    Parameters\n    ----------\n    subject_from : str\n        Name of the original subject as named in the ``SUBJECTS_DIR``.\n    subject_to : str\n        Name of the subject on which to morph as named in the ``SUBJECTS_DIR``.\n    subjects_dir : path-like\n        Path to ``SUBJECTS_DIR`` is not set in the environment.\n    xhemi : bool\n        Morph across hemisphere. Currently only implemented for\n        ``subject_to == subject_from``. See notes of\n        :func:`mne.compute_source_morph`.\n    %(verbose)s\n\n    Returns\n    -------\n    left_map, right_map : ~scipy.sparse.csr_array\n        The morph maps for the 2 hemispheres.\n    \"\"\"\n    subjects_dir = get_subjects_dir(subjects_dir, raise_error=True)\n\n    # First check for morph-map dir existence\n    mmap_dir = subjects_dir / \"morph-maps\"\n    if not mmap_dir.is_dir():\n        try:\n            os.mkdir(mmap_dir)\n        except Exception:\n            warn(f'Could not find or make morph map directory \"{mmap_dir}\"')\n\n    # filename components\n    if xhemi:\n        if subject_to != subject_from:\n            raise NotImplementedError(\n                \"Morph-maps between hemispheres are currently only \"\n                \"implemented for subject_to == subject_from\"\n            )\n        map_name_temp = \"%s-%s-xhemi\"\n        log_msg = \"Creating morph map %s -> %s xhemi\"\n    else:\n        map_name_temp = \"%s-%s\"\n        log_msg = \"Creating morph map %s -> %s\"\n\n    map_names = [\n        map_name_temp % (subject_from, subject_to),\n        map_name_temp % (subject_to, subject_from),\n    ]\n\n    # find existing file\n    fname = None\n    for map_name in map_names:\n        fname = mmap_dir / f\"{map_name}-morph.fif\"\n        if fname.exists():\n            return _read_morph_map(fname, subject_from, subject_to)\n    # if file does not exist, make it\n    logger.info(\n        f'Morph map \"{fname}\" does not exist, creating it and saving it to disk'\n    )\n    logger.info(log_msg % (subject_from, subject_to))\n    mmap_1 = _make_morph_map(subject_from, subject_to, subjects_dir, xhemi)\n    if subject_to == subject_from:\n        mmap_2 = None\n    else:\n        logger.info(log_msg % (subject_to, subject_from))\n        mmap_2 = _make_morph_map(subject_to, subject_from, subjects_dir, xhemi)\n    _write_morph_map(fname, subject_from, subject_to, mmap_1, mmap_2)\n    return mmap_1", "metadata": {}}
{"_id": "mne_mne_event.py_pick_events_code", "title": "pick_events", "text": "def pick_events(events, include=None, exclude=None, step=False):\n    \"\"\"Select some :term:`events`.\n\n    Parameters\n    ----------\n    %(events)s\n    include : int | list | None\n        A event id to include or a list of them.\n        If None all events are included.\n    exclude : int | list | None\n        A event id to exclude or a list of them.\n        If None no event is excluded. If include is not None\n        the exclude parameter is ignored.\n    step : bool\n        If True (default is False), events have a step format according\n        to the argument output='step' in the function find_events().\n        In this case, the two last columns are considered in inclusion/\n        exclusion criteria.\n\n    Returns\n    -------\n    events : array, shape (n_events, 3)\n        The list of events.\n    \"\"\"\n    if include is not None:\n        include = _check_integer_or_list(include, \"include\")\n        mask = np.zeros(len(events), dtype=bool)\n        for e in include:\n            mask = np.logical_or(mask, events[:, 2] == e)\n            if step:\n                mask = np.logical_or(mask, events[:, 1] == e)\n        events = events[mask]\n    elif exclude is not None:\n        exclude = _check_integer_or_list(exclude, \"exclude\")\n        mask = np.ones(len(events), dtype=bool)\n        for e in exclude:\n            mask = np.logical_and(mask, events[:, 2] != e)\n            if step:\n                mask = np.logical_and(mask, events[:, 1] != e)\n        events = events[mask]\n    else:\n        events = np.copy(events)\n\n    if len(events) == 0:\n        raise RuntimeError(\"No events found\")\n\n    return events", "metadata": {}}
{"_id": "mne_mne_event.py_define_target_events_code", "title": "define_target_events", "text": "def define_target_events(\n    events, reference_id, target_id, sfreq, tmin, tmax, new_id=None, fill_na=None\n):\n    \"\"\"Define new events by co-occurrence of existing events.\n\n    This function can be used to evaluate events depending on the\n    temporal lag to another event. For example, this can be used to\n    analyze evoked responses which were followed by a button press within\n    a defined time window.\n\n    Parameters\n    ----------\n    events : ndarray\n        Array as returned by mne.find_events.\n    reference_id : int\n        The reference event. The event defining the epoch of interest.\n    target_id : int\n        The target event. The event co-occurring in within a certain time\n        window around the reference event.\n    sfreq : float\n        The sampling frequency of the data.\n    tmin : float\n        The lower limit in seconds from the target event.\n    tmax : float\n        The upper limit border in seconds from the target event.\n    new_id : int\n        New ID for the new event.\n    fill_na : int | None\n        Fill event to be inserted if target is not available within the time\n        window specified. If None, the 'null' events will be dropped.\n\n    Returns\n    -------\n    new_events : ndarray\n        The new defined events.\n    lag : ndarray\n        Time lag between reference and target in milliseconds.\n    \"\"\"\n    if new_id is None:\n        new_id = reference_id\n\n    tsample = 1e3 / sfreq\n    imin = int(tmin * sfreq)\n    imax = int(tmax * sfreq)\n\n    new_events = []\n    lag = []\n    for event in events.copy().astype(int):\n        if event[2] == reference_id:\n            lower = event[0] + imin\n            upper = event[0] + imax\n            res = events[\n                (events[:, 0] > lower)\n                & (events[:, 0] < upper)\n                & (events[:, 2] == target_id)\n            ]\n            if res.any():\n                lag += [event[0] - res[0][0]]\n                event[2] = new_id\n                new_events += [event]\n            elif fill_na is not None:\n                event[2] = fill_na\n                new_events += [event]\n                lag.append(np.nan)\n\n    new_events = np.array(new_events)\n\n    with np.errstate(invalid=\"ignore\"):  # casting nans\n        lag = np.abs(lag, dtype=\"f8\")\n    if lag.any():\n        lag *= tsample\n    else:\n        lag = np.array([])\n\n    return new_events if new_events.any() else np.array([]), lag", "metadata": {}}
{"_id": "mne_mne_event.py_read_events_code", "title": "read_events", "text": "def read_events(\n    filename,\n    include=None,\n    exclude=None,\n    mask=None,\n    mask_type=\"and\",\n    return_event_id=False,\n    verbose=None,\n):\n    \"\"\"Read :term:`events` from fif or text file.\n\n    See :ref:`tut-events-vs-annotations` and :ref:`tut-event-arrays`\n    for more information about events.\n\n    Parameters\n    ----------\n    filename : path-like\n        Name of the input file.\n        If the extension is ``.fif``, events are read assuming\n        the file is in FIF format, otherwise (e.g., ``.eve``,\n        ``.lst``, ``.txt``) events are read as coming from text.\n        Note that new format event files do not contain\n        the ``\"time\"`` column (used to be the second column).\n    include : int | list | None\n        A event id to include or a list of them.\n        If None all events are included.\n    exclude : int | list | None\n        A event id to exclude or a list of them.\n        If None no event is excluded. If include is not None\n        the exclude parameter is ignored.\n    mask : int | None\n        The value of the digital mask to apply to the stim channel values.\n        If None (default), no masking is performed.\n    mask_type : ``'and'`` | ``'not_and'``\n        The type of operation between the mask and the trigger.\n        Choose 'and' (default) for MNE-C masking behavior.\n\n        .. versionadded:: 0.13\n    return_event_id : bool\n        If True, ``event_id`` will be returned. This is only possible for\n        ``-annot.fif`` files produced with MNE-C ``mne_browse_raw``.\n\n        .. versionadded:: 0.20\n    %(verbose)s\n\n    Returns\n    -------\n    %(events)s\n    event_id : dict\n        Dictionary of ``{str: int}`` mappings of event IDs.\n\n    See Also\n    --------\n    find_events, write_events\n\n    Notes\n    -----\n    This function will discard the offset line (i.e., first line with zero\n    event number) if it is present in a text file.\n\n    For more information on ``mask`` and ``mask_type``, see\n    :func:`mne.find_events`.\n    \"\"\"\n    check_fname(\n        filename,\n        \"events\",\n        (\n            \".eve\",\n            \"-eve.fif\",\n            \"-eve.fif.gz\",\n            \"-eve.lst\",\n            \"-eve.txt\",\n            \"_eve.fif\",\n            \"_eve.fif.gz\",\n            \"_eve.lst\",\n            \"_eve.txt\",\n            \"-annot.fif\",  # MNE-C annot\n        ),\n    )\n    filename = Path(filename)\n    if filename.suffix in (\".fif\", \".gz\"):\n        fid, tree, _ = fiff_open(filename)\n        with fid as f:\n            event_list, event_id = _read_events_fif(f, tree)\n        # hack fix for windows to avoid bincount problems\n        event_list = event_list.astype(int)\n    else:\n        #  Have to read this in as float64 then convert because old style\n        #  eve/lst files had a second float column that will raise errors\n        lines = np.loadtxt(filename, dtype=np.float64).astype(int)\n        if len(lines) == 0:\n            raise ValueError(\"No text lines found\")\n\n        if lines.ndim == 1:  # Special case for only one event\n            lines = lines[np.newaxis, :]\n\n        if len(lines[0]) == 4:  # Old format eve/lst\n            goods = [0, 2, 3]  # Omit \"time\" variable\n        elif len(lines[0]) == 3:\n            goods = [0, 1, 2]\n        else:\n            raise ValueError(\"Unknown number of columns in event text file\")\n\n        event_list = lines[:, goods]\n        if mask is not None and event_list.shape[0] > 0 and event_list[0, 2] == 0:\n            event_list = event_list[1:]\n            warn(\"first row of event file discarded (zero-valued)\")\n        event_id = None\n\n    event_list = pick_events(event_list, include, exclude)\n    unmasked_len = event_list.shape[0]\n    if mask is not None:\n        event_list = _mask_trigs(event_list, mask, mask_type)\n        masked_len = event_list.shape[0]\n        if masked_len < unmasked_len:\n            warn(f\"{unmasked_len - masked_len} of {unmasked_len} events masked\")\n    out = event_list\n    if return_event_id:\n        if event_id is None:\n            raise RuntimeError(\"No event_id found in the file\")\n        out = (out, event_id)\n    return out", "metadata": {}}
{"_id": "mne_mne_event.py_write_events_code", "title": "write_events", "text": "def write_events(filename, events, *, overwrite=False, verbose=None):\n    \"\"\"Write :term:`events` to file.\n\n    Parameters\n    ----------\n    filename : path-like\n        Name of the output file.\n        If the extension is ``.fif``, events are written in\n        binary FIF format, otherwise (e.g., ``.eve``,\n        ``.lst``, ``.txt``) events are written as plain text.\n        Note that new format event files do not contain\n        the ``\"time\"`` column (used to be the second column).\n    %(events)s\n    %(overwrite)s\n    %(verbose)s\n\n    See Also\n    --------\n    read_events\n    \"\"\"\n    filename = _check_fname(filename, overwrite=overwrite)\n    check_fname(\n        filename,\n        \"events\",\n        (\n            \".eve\",\n            \"-eve.fif\",\n            \"-eve.fif.gz\",\n            \"-eve.lst\",\n            \"-eve.txt\",\n            \"_eve.fif\",\n            \"_eve.fif.gz\",\n            \"_eve.lst\",\n            \"_eve.txt\",\n        ),\n    )\n    if filename.suffix in (\".fif\", \".gz\"):\n        #   Start writing...\n        with start_and_end_file(filename) as fid:\n            start_block(fid, FIFF.FIFFB_MNE_EVENTS)\n            write_int(fid, FIFF.FIFF_MNE_EVENT_LIST, events.T)\n            end_block(fid, FIFF.FIFFB_MNE_EVENTS)\n    else:\n        with open(filename, \"w\") as f:\n            for e in events:\n                f.write(f\"{e[0]:6d} {e[1]:6d} {e[2]:3d}\\n\")", "metadata": {}}
{"_id": "mne_mne_event.py_find_stim_steps_code", "title": "find_stim_steps", "text": "def find_stim_steps(raw, pad_start=None, pad_stop=None, merge=0, stim_channel=None):\n    \"\"\"Find all steps in data from a stim channel.\n\n    Parameters\n    ----------\n    raw : Raw object\n        The raw data.\n    pad_start : None | int\n        Values to assume outside of the stim channel (e.g., if pad_start=0 and\n        the stim channel starts with value 5, an event of [0, 0, 5] will be\n        inserted at the beginning). With None, no steps will be inserted.\n    pad_stop : None | int\n        Values to assume outside of the stim channel, see ``pad_start``.\n    merge : int\n        Merge steps occurring in neighboring samples. The integer value\n        indicates over how many samples events should be merged, and the sign\n        indicates in which direction they should be merged (negative means\n        towards the earlier event, positive towards the later event).\n    stim_channel : None | str | list of str\n        Name of the stim channel or all the stim channels\n        affected by the trigger. If None, the config variables\n        'MNE_STIM_CHANNEL', 'MNE_STIM_CHANNEL_1', 'MNE_STIM_CHANNEL_2',\n        etc. are read. If these are not found, it will default to\n        'STI101' or 'STI 014', whichever is present.\n\n    Returns\n    -------\n    steps : array, shape = (n_samples, 3)\n        For each step in the stim channel the values [sample, v_from, v_to].\n        The first column contains the event time in samples (the first sample\n        with the new value). The second column contains the stim channel value\n        before the step, and the third column contains value after the step.\n\n    See Also\n    --------\n    find_events : More sophisticated options for finding events in a Raw file.\n    \"\"\"\n    # pull stim channel from config if necessary\n    stim_channel = _get_stim_channel(stim_channel, raw.info)\n\n    picks = pick_channels(raw.info[\"ch_names\"], include=stim_channel, ordered=False)\n    if len(picks) == 0:\n        raise ValueError(\"No stim channel found to extract event triggers.\")\n    data, _ = raw[picks, :]\n    if np.any(data < 0):\n        warn(\"Trigger channel contains negative values, using absolute value.\")\n        data = np.abs(data)  # make sure trig channel is positive\n    data = data.astype(np.int64)\n\n    return _find_stim_steps(\n        data, raw.first_samp, pad_start=pad_start, pad_stop=pad_stop, merge=merge\n    )", "metadata": {}}
{"_id": "mne_mne_event.py_find_events_code", "title": "find_events", "text": "def find_events(\n    raw,\n    stim_channel=None,\n    output=\"onset\",\n    consecutive=\"increasing\",\n    min_duration=0,\n    shortest_event=2,\n    mask=None,\n    uint_cast=False,\n    mask_type=\"and\",\n    initial_event=False,\n    verbose=None,\n):\n    \"\"\"Find :term:`events` from raw file.\n\n    See :ref:`tut-events-vs-annotations` and :ref:`tut-event-arrays`\n    for more information about events.\n\n    Parameters\n    ----------\n    raw : Raw object\n        The raw data.\n    stim_channel : None | str | list of str\n        Name of the stim channel or all the stim channels\n        affected by triggers. If None, the config variables\n        'MNE_STIM_CHANNEL', 'MNE_STIM_CHANNEL_1', 'MNE_STIM_CHANNEL_2',\n        etc. are read. If these are not found, it will fall back to\n        'STI 014' if present, then fall back to the first channel of type\n        'stim', if present. If multiple channels are provided\n        then the returned events are the union of all the events\n        extracted from individual stim channels.\n    output : 'onset' | 'offset' | 'step'\n        Whether to report when events start, when events end, or both.\n    consecutive : bool | 'increasing'\n        If True, consider instances where the value of the events\n        channel changes without first returning to zero as multiple\n        events. If False, report only instances where the value of the\n        events channel changes from/to zero. If 'increasing', report\n        adjacent events only when the second event code is greater than\n        the first.\n    min_duration : float\n        The minimum duration of a change in the events channel required\n        to consider it as an event (in seconds).\n    shortest_event : int\n        Minimum number of samples an event must last (default is 2). If the\n        duration is less than this an exception will be raised.\n    mask : int | None\n        The value of the digital mask to apply to the stim channel values.\n        If None (default), no masking is performed.\n    uint_cast : bool\n        If True (default False), do a cast to ``uint16`` on the channel\n        data. This can be used to fix a bug with STI101 and STI014 in\n        Neuromag acquisition setups that use channel STI016 (channel 16\n        turns data into e.g. -32768), similar to ``mne_fix_stim14 --32``\n        in MNE-C.\n\n        .. versionadded:: 0.12\n    mask_type : 'and' | 'not_and'\n        The type of operation between the mask and the trigger.\n        Choose 'and' (default) for MNE-C masking behavior.\n\n        .. versionadded:: 0.13\n    initial_event : bool\n        If True (default False), an event is created if the stim channel has a\n        value different from 0 as its first sample. This is useful if an event\n        at t=0s is present.\n\n        .. versionadded:: 0.16\n    %(verbose)s\n\n    Returns\n    -------\n    %(events)s\n\n    See Also\n    --------\n    find_stim_steps : Find all the steps in the stim channel.\n    read_events : Read events from disk.\n    write_events : Write events to disk.\n\n    Notes\n    -----\n    .. warning:: If you are working with downsampled data, events computed\n                 before decimation are no longer valid. Please recompute\n                 your events after decimation, but note this reduces the\n                 precision of event timing.\n\n    Examples\n    --------\n    Consider data with a stim channel that looks like::\n\n        [0, 32, 32, 33, 32, 0]\n\n    By default, find_events returns all samples at which the value of the\n    stim channel increases::\n\n        >>> print(find_events(raw)) # doctest: +SKIP\n        [[ 1  0 32]\n         [ 3 32 33]]\n\n    If consecutive is False, find_events only returns the samples at which\n    the stim channel changes from zero to a non-zero value::\n\n        >>> print(find_events(raw, consecutive=False)) # doctest: +SKIP\n        [[ 1  0 32]]\n\n    If consecutive is True, find_events returns samples at which the\n    event changes, regardless of whether it first returns to zero::\n\n        >>> print(find_events(raw, consecutive=True)) # doctest: +SKIP\n        [[ 1  0 32]\n         [ 3 32 33]\n         [ 4 33 32]]\n\n    If output is 'offset', find_events returns the last sample of each event\n    instead of the first one::\n\n        >>> print(find_events(raw, consecutive=True, # doctest: +SKIP\n        ...                   output='offset'))\n        [[ 2 33 32]\n         [ 3 32 33]\n         [ 4  0 32]]\n\n    If output is 'step', find_events returns the samples at which an event\n    starts or ends::\n\n        >>> print(find_events(raw, consecutive=True, # doctest: +SKIP\n        ...                   output='step'))\n        [[ 1  0 32]\n         [ 3 32 33]\n         [ 4 33 32]\n         [ 5 32  0]]\n\n    To ignore spurious events, it is also possible to specify a minimum\n    event duration. Assuming our events channel has a sample rate of\n    1000 Hz::\n\n        >>> print(find_events(raw, consecutive=True, # doctest: +SKIP\n        ...                   min_duration=0.002))\n        [[ 1  0 32]]\n\n    For the digital mask, if mask_type is set to 'and' it will take the\n    binary representation of the digital mask, e.g. 5 -> '00000101', and will\n    allow the values to pass where mask is one, e.g.::\n\n              7 '0000111' <- trigger value\n             37 '0100101' <- mask\n         ----------------\n              5 '0000101'\n\n    For the digital mask, if mask_type is set to 'not_and' it will take the\n    binary representation of the digital mask, e.g. 5 -> '00000101', and will\n    block the values where mask is one, e.g.::\n\n              7 '0000111' <- trigger value\n             37 '0100101' <- mask\n         ----------------\n              2 '0000010'\n    \"\"\"\n    min_samples = min_duration * raw.info[\"sfreq\"]\n\n    # pull stim channel from config if necessary\n    try:\n        stim_channel = _get_stim_channel(stim_channel, raw.info)\n    except ValueError:\n        if len(raw.annotations) > 0:\n            raise ValueError(\n                \"No stim channels found, but the raw object has \"\n                \"annotations. Consider using \"\n                \"mne.events_from_annotations to convert these to \"\n                \"events.\"\n            )\n        else:\n            raise\n\n    picks = pick_channels(raw.info[\"ch_names\"], include=stim_channel)\n    if len(picks) == 0:\n        raise ValueError(\"No stim channel found to extract event triggers.\")\n    logger.info(f\"Finding events on: {', '.join(raw.ch_names[pick] for pick in picks)}\")\n    data, _ = raw[picks, :]\n\n    events_list = []\n    for d, ch_name in zip(data, stim_channel):\n        events = _find_events(\n            d[np.newaxis, :],\n            raw.first_samp,\n            verbose=verbose,\n            output=output,\n            consecutive=consecutive,\n            min_samples=min_samples,\n            mask=mask,\n            uint_cast=uint_cast,\n            mask_type=mask_type,\n            initial_event=initial_event,\n            ch_name=ch_name,\n        )\n        # add safety check for spurious events (for ex. from neuromag syst.) by\n        # checking the number of low sample events\n        n_short_events = np.sum(np.diff(events[:, 0]) < shortest_event)\n        if n_short_events > 0:\n            raise ValueError(\n                f\"You have {n_short_events} events shorter than the shortest_event. \"\n                \"These are very unusual and you may want to set min_duration to a \"\n                \"larger value e.g. x / raw.info['sfreq']. Where x = 1 sample shorter \"\n                \"than the shortest event length.\"\n            )\n\n        events_list.append(events)\n\n    events = np.concatenate(events_list, axis=0)\n    events = _find_unique_events(events)\n    events = events[np.argsort(events[:, 0])]\n    return events", "metadata": {}}
{"_id": "mne_mne_event.py_merge_events_code", "title": "merge_events", "text": "def merge_events(events, ids, new_id, replace_events=True):\n    \"\"\"Merge a set of :term:`events`.\n\n    Parameters\n    ----------\n    events : array, shape (n_events_in, 3)\n        Events.\n    ids : array of int\n        The ids of events to merge.\n    new_id : int\n        The new id.\n    replace_events : bool\n        If True (default), old event ids are replaced. Otherwise,\n        new events will be added to the old event list.\n\n    Returns\n    -------\n    new_events : array, shape (n_events_out, 3)\n        The new events.\n\n    Notes\n    -----\n    Rather than merging events you can use hierarchical event_id\n    in Epochs. For example, here::\n\n        >>> event_id = {'auditory/left': 1, 'auditory/right': 2}\n\n    And the condition 'auditory' would correspond to either 1 or 2.\n\n    Examples\n    --------\n    Here is quick example of the behavior::\n\n        >>> events = [[134, 0, 1], [341, 0, 2], [502, 0, 3]]\n        >>> merge_events(events, [1, 2], 12, replace_events=True)\n        array([[134,   0,  12],\n               [341,   0,  12],\n               [502,   0,   3]])\n        >>> merge_events(events, [1, 2], 12, replace_events=False)\n        array([[134,   0,   1],\n               [134,   0,  12],\n               [341,   0,   2],\n               [341,   0,  12],\n               [502,   0,   3]])\n    \"\"\"\n    events = np.asarray(events)\n    events_out = events.copy()\n    idx_touched = []  # to keep track of the original events we can keep\n    for col in [1, 2]:\n        for i in ids:\n            mask = events[:, col] == i\n            events_out[mask, col] = new_id\n            idx_touched.append(np.where(mask)[0])\n    if not replace_events:\n        idx_touched = np.unique(np.concatenate(idx_touched))\n        events_out = np.concatenate((events_out, events[idx_touched]), axis=0)\n        # Now sort in lexical order\n        events_out = events_out[np.lexsort(events_out.T[::-1])]\n    return events_out", "metadata": {}}
{"_id": "mne_mne_event.py_shift_time_events_code", "title": "shift_time_events", "text": "def shift_time_events(events, ids, tshift, sfreq):\n    \"\"\"Shift a set of :term:`events`.\n\n    Parameters\n    ----------\n    %(events)s\n    ids : ndarray of int | None\n        The ids of events to shift.\n    tshift : float\n        Time-shift event. Use positive value tshift for forward shifting\n        the event and negative value for backward shift.\n    sfreq : float\n        The sampling frequency of the data.\n\n    Returns\n    -------\n    new_events : array of int, shape (n_new_events, 3)\n        The new events.\n    \"\"\"\n    events = events.copy()\n    if ids is None:\n        mask = slice(None)\n    else:\n        mask = np.isin(events[:, 2], ids)\n    events[mask, 0] += int(tshift * sfreq)\n\n    return events", "metadata": {}}
{"_id": "mne_mne_event.py_make_fixed_length_events_code", "title": "make_fixed_length_events", "text": "def make_fixed_length_events(\n    raw,\n    id=1,  # noqa: A002\n    start=0,\n    stop=None,\n    duration=1.0,\n    first_samp=True,\n    overlap=0.0,\n):\n    \"\"\"Make a set of :term:`events` separated by a fixed duration.\n\n    Parameters\n    ----------\n    raw : instance of Raw\n        A raw object to use the data from.\n    id : int\n        The id to use (default 1).\n    start : float\n        Time of first event (in seconds).\n    stop : float | None\n        Maximum time of last event (in seconds). If None, events extend to the\n        end of the recording.\n    duration : float\n        The duration to separate events by (in seconds).\n    first_samp : bool\n        If True (default), times will have :term:`first_samp` added to them, as\n        in :func:`mne.find_events`. This behavior is not desirable if the\n        returned events will be combined with event times that already\n        have :term:`first_samp` added to them, e.g. event times that come\n        from :func:`mne.find_events`.\n    overlap : float\n        The overlap between events (in seconds).\n        Must be ``0 <= overlap < duration``.\n\n        .. versionadded:: 0.18\n\n    Returns\n    -------\n    %(events)s\n    \"\"\"\n    from .io import BaseRaw\n\n    _validate_type(raw, BaseRaw, \"raw\")\n    _validate_type(id, \"int\", \"id\")\n    _validate_type(duration, \"numeric\", \"duration\")\n    _validate_type(overlap, \"numeric\", \"overlap\")\n    duration, overlap = float(duration), float(overlap)\n    if not 0 <= overlap < duration:\n        raise ValueError(\n            f\"overlap must be >=0 but < duration ({duration}), got {overlap}\"\n        )\n\n    start = raw.time_as_index(start, use_rounding=True)[0]\n    if stop is not None:\n        stop = raw.time_as_index(stop, use_rounding=True)[0]\n    else:\n        stop = raw.last_samp + 1\n    if first_samp:\n        start = start + raw.first_samp\n        stop = min([stop + raw.first_samp, raw.last_samp + 1])\n    else:\n        stop = min([stop, len(raw.times)])\n    # Make sure we don't go out the end of the file:\n    stop -= int(np.round(raw.info[\"sfreq\"] * duration))\n    # This should be inclusive due to how we generally use start and stop...\n    ts = np.arange(start, stop + 1, raw.info[\"sfreq\"] * (duration - overlap)).astype(\n        int\n    )\n    n_events = len(ts)\n    if n_events == 0:\n        raise ValueError(\n            \"No events produced, check the values of start, stop, and duration\"\n        )\n    events = np.c_[ts, np.zeros(n_events, dtype=int), id * np.ones(n_events, dtype=int)]\n    return events", "metadata": {}}
{"_id": "mne_mne_event.py_concatenate_events_code", "title": "concatenate_events", "text": "def concatenate_events(events, first_samps, last_samps):\n    \"\"\"Concatenate event lists to be compatible with concatenate_raws.\n\n    This is useful, for example, if you processed and/or changed\n    events in raw files separately before combining them using\n    :func:`mne.concatenate_raws`.\n\n    Parameters\n    ----------\n    events : list of array\n        List of :term:`events` arrays, typically each extracted from a\n        corresponding raw file that is being concatenated.\n    first_samps : list or array of int\n        First sample numbers of the raw files concatenated.\n    last_samps : list or array of int\n        Last sample numbers of the raw files concatenated.\n\n    Returns\n    -------\n    events : array\n        The concatenated events.\n\n    See Also\n    --------\n    mne.concatenate_raws\n    \"\"\"\n    _validate_type(events, list, \"events\")\n    if not (len(events) == len(last_samps) and len(events) == len(first_samps)):\n        raise ValueError(\n            \"events, first_samps, and last_samps must all have the same lengths\"\n        )\n    first_samps = np.array(first_samps)\n    last_samps = np.array(last_samps)\n    n_samps = np.cumsum(last_samps - first_samps + 1)\n    events_out = events[0]\n    for e, f, n in zip(events[1:], first_samps[1:], n_samps[:-1]):\n        # remove any skip since it doesn't exist in concatenated files\n        e2 = e.copy()\n        e2[:, 0] -= f\n        # add offset due to previous files, plus original file offset\n        e2[:, 0] += n + first_samps[0]\n        events_out = np.concatenate((events_out, e2), axis=0)\n\n    return events_out", "metadata": {}}
{"_id": "mne_mne_event.py_match_event_names_code", "title": "match_event_names", "text": "def match_event_names(event_names, keys, *, on_missing=\"raise\"):\n    \"\"\"Search a collection of event names for matching (sub-)groups of events.\n\n    This function is particularly helpful when using grouped event names\n    (i.e., event names containing forward slashes ``/``). Please see the\n    Examples section below for a working example.\n\n    Parameters\n    ----------\n    event_names : array-like of str | dict\n        Either a collection of event names, or the ``event_id`` dictionary\n        mapping event names to event codes.\n    keys : array-like of str | str\n        One or multiple event names or groups to search for in ``event_names``.\n    on_missing : 'raise' | 'warn' | 'ignore'\n        How to handle situations when none of the ``keys`` can be found in\n        ``event_names``. If ``'warn'`` or ``'ignore'``, an empty list will be\n        returned.\n\n    Returns\n    -------\n    matches : list of str\n        All event names that match any of the ``keys`` provided.\n\n    Notes\n    -----\n    .. versionadded:: 1.0\n\n    Examples\n    --------\n    Assuming the following grouped event names in the data, you could easily\n    query for all ``auditory`` and ``left`` event names::\n\n        >>> event_names = [\n        ...     'auditory/left',\n        ...     'auditory/right',\n        ...     'visual/left',\n        ...     'visual/right'\n        ... ]\n        >>> match_event_names(\n        ...     event_names=event_names,\n        ...     keys=['auditory', 'left']\n        ... )\n        ['auditory/left', 'auditory/right', 'visual/left']\n    \"\"\"\n    _check_on_missing(on_missing)\n\n    if isinstance(event_names, dict):\n        event_names = list(event_names)\n\n    # ensure we have a list of `keys`\n    if isinstance(keys, Sequence | np.ndarray) and not isinstance(keys, str):\n        keys = list(keys)\n    else:\n        keys = [keys]\n\n    matches = []\n\n    # form the hierarchical event name mapping\n    for key in keys:\n        if not isinstance(key, str):\n            raise ValueError(f\"keys must be strings, got {type(key)} ({key})\")\n\n        matches.extend(\n            name\n            for name in event_names\n            if set(key.split(\"/\")).issubset(name.split(\"/\"))\n        )\n\n    if not matches:\n        _on_missing(\n            on_missing=on_missing,\n            msg=f'Event name \"{key}\" could not be found. The following events '\n            f\"are present in the data: {', '.join(event_names)}\",\n            error_klass=KeyError,\n        )\n\n    matches = sorted(set(matches))  # deduplicate if necessary\n    return matches", "metadata": {}}
{"_id": "mne_mne_event.py_count_events_code", "title": "count_events", "text": "def count_events(events, ids=None):\n    \"\"\"Count events.\n\n    Parameters\n    ----------\n    events : ndarray, shape (N, 3)\n        The events array (consisting of N events).\n    ids : array-like of int | None\n        If ``None``, count all event types present in the input. If array-like\n        of int, count only those event types given by ``ids``.\n\n    Returns\n    -------\n    counts : dict\n        A dictionary containing the event types as keys with their counts as\n        values.\n\n    Examples\n    --------\n        >>> events = np.array([[0, 0, 1], [0, 0, 1], [0, 0, 5]])\n        >>> count_events(events)\n        {1: 2, 5: 1}\n        >>> count_events(events, ids=[1, 5])\n        {1: 2, 5: 1}\n        >>> count_events(events, ids=[1, 11])\n        {1: 2, 11: 0}\n    \"\"\"\n    counts = np.bincount(events[:, 2])\n    counts = {i: int(count) for i, count in enumerate(counts) if count > 0}\n    if ids is not None:\n        counts = {id_: counts.get(id_, 0) for id_ in ids}\n    return counts", "metadata": {}}
{"_id": "mne_mne_event.py_categories_code", "title": "categories", "text": "def categories(self):\n        \"\"\"Return list of averaging categories ordered by DACQ index.\n\n        Only returns categories marked active in DACQ.\n        \"\"\"\n        cats = sorted(self._categories_in_use.values(), key=lambda cat: cat[\"index\"])\n        return cats", "metadata": {}}
{"_id": "mne_mne_event.py_events_code", "title": "events", "text": "def events(self):\n        \"\"\"Return events ordered by DACQ index.\n\n        Only returns events that are in use (referred to by a category).\n        \"\"\"\n        evs = sorted(self._events_in_use.values(), key=lambda ev: ev[\"index\"])\n        return evs", "metadata": {}}
{"_id": "mne_mne_event.py_get_condition_code", "title": "get_condition", "text": "def get_condition(\n        self,\n        raw,\n        condition=None,\n        stim_channel=None,\n        mask=None,\n        uint_cast=None,\n        mask_type=\"and\",\n        delayed_lookup=True,\n    ):\n        \"\"\"Get averaging parameters for a condition (averaging category).\n\n        Output is designed to be used with the Epochs class to extract the\n        corresponding epochs.\n\n        Parameters\n        ----------\n        raw : Raw object\n            An instance of Raw.\n        condition : None | str | dict | list of dict\n            Condition or a list of conditions. Conditions can be strings\n            (DACQ comment field, e.g. 'Auditory left') or category dicts\n            (e.g. acqp['Auditory left'], where acqp is an instance of\n            AcqParserFIF). If None, get all conditions marked active in\n            DACQ.\n        stim_channel : None | str | list of str\n            Name of the stim channel or all the stim channels\n            affected by the trigger. If None, the config variables\n            'MNE_STIM_CHANNEL', 'MNE_STIM_CHANNEL_1', 'MNE_STIM_CHANNEL_2',\n            etc. are read. If these are not found, it will fall back to\n            'STI101' or 'STI 014' if present, then fall back to the first\n            channel of type 'stim', if present.\n        mask : int | None\n            The value of the digital mask to apply to the stim channel values.\n            If None (default), no masking is performed.\n        uint_cast : bool\n            If True (default False), do a cast to ``uint16`` on the channel\n            data. This can be used to fix a bug with STI101 and STI014 in\n            Neuromag acquisition setups that use channel STI016 (channel 16\n            turns data into e.g. -32768), similar to ``mne_fix_stim14 --32``\n            in MNE-C.\n        mask_type : 'and' | 'not_and'\n            The type of operation between the mask and the trigger.\n            Choose 'and' for MNE-C masking behavior.\n        delayed_lookup : bool\n            If True, use the 'delayed lookup' procedure implemented in Elekta\n            software. When a trigger transition occurs, the lookup of\n            the new trigger value will not happen immediately at the following\n            sample, but with a 1-sample delay. This allows a slight\n            asynchrony between trigger onsets, when they are intended to be\n            synchronous. If you have accurate hardware and want to detect\n            transitions with a resolution of one sample, use\n            delayed_lookup=False.\n\n        Returns\n        -------\n        conds_data : dict or list of dict\n            Each dict has the following keys:\n\n            events : array, shape (n_epochs_out, 3)\n                List of zero time points (t0) for the epochs matching the\n                condition. Use as the ``events`` parameter to Epochs. Note\n                that these are not (necessarily) actual events.\n            event_id : dict\n                Name of condition and index compatible with ``events``.\n                Should be passed as the ``event_id`` parameter to Epochs.\n            tmin : float\n                Epoch starting time relative to t0. Use as the ``tmin``\n                parameter to Epochs.\n            tmax : float\n                Epoch ending time relative to t0. Use as the ``tmax``\n                parameter to Epochs.\n        \"\"\"\n        if condition is None:\n            condition = self.categories  # get all\n        if not isinstance(condition, list):\n            condition = [condition]  # single cond -> listify\n        conds_data = list()\n        for cat in condition:\n            if isinstance(cat, str):\n                cat = self[cat]\n            mne_events = find_events(\n                raw,\n                stim_channel=stim_channel,\n                mask=mask,\n                mask_type=mask_type,\n                output=\"step\",\n                uint_cast=uint_cast,\n                consecutive=True,\n                verbose=False,\n                shortest_event=1,\n            )\n            if delayed_lookup:\n                ind = np.where(np.diff(mne_events[:, 0]) == 1)[0]\n                if 1 in np.diff(ind):\n                    raise ValueError(\n                        \"There are several subsequent \"\n                        \"transitions on the trigger channel. \"\n                        \"This will not work well with \"\n                        \"delayed_lookup=True. You may want to \"\n                        \"check your trigger data and \"\n                        \"set delayed_lookup=False.\"\n                    )\n                mne_events[ind, 2] = mne_events[ind + 1, 2]\n                mne_events = np.delete(mne_events, ind + 1, axis=0)\n            sfreq = raw.info[\"sfreq\"]\n            cat_t0_ = self._mne_events_to_category_t0(cat, mne_events, sfreq)\n            # make it compatible with the usual events array\n            cat_t0 = np.c_[\n                cat_t0_, np.zeros(cat_t0_.shape), cat[\"index\"] * np.ones(cat_t0_.shape)\n            ].astype(np.uint32)\n            cat_id = {cat[\"comment\"]: cat[\"index\"]}\n            tmin, tmax = cat[\"start\"], cat[\"end\"]\n            conds_data.append(\n                dict(events=cat_t0, event_id=cat_id, tmin=tmin, tmax=tmax)\n            )\n        return conds_data[0] if len(conds_data) == 1 else conds_data", "metadata": {}}
{"_id": "mne_mne_morph.py_compute_source_morph_code", "title": "compute_source_morph", "text": "def compute_source_morph(\n    src,\n    subject_from=None,\n    subject_to=\"fsaverage\",\n    subjects_dir=None,\n    zooms=\"auto\",\n    niter_affine=(100, 100, 10),\n    niter_sdr=(5, 5, 3),\n    spacing=5,\n    smooth=None,\n    warn=True,\n    xhemi=False,\n    sparse=False,\n    src_to=None,\n    precompute=False,\n    verbose=None,\n):\n    \"\"\"Create a SourceMorph from one subject to another.\n\n    Method is based on spherical morphing by FreeSurfer for surface\n    cortical estimates :footcite:`GreveEtAl2013` and\n    Symmetric Diffeomorphic Registration for volumic data\n    :footcite:`AvantsEtAl2008`.\n\n    Parameters\n    ----------\n    src : instance of SourceSpaces | instance of SourceEstimate\n        The SourceSpaces of subject_from (can be a\n        SourceEstimate if only using a surface source space).\n    subject_from : str | None\n        Name of the original subject as named in the SUBJECTS_DIR.\n        If None (default), then ``src[0]['subject_his_id]'`` will be used.\n    subject_to : str | None\n        Name of the subject to which to morph as named in the SUBJECTS_DIR.\n        Default is ``'fsaverage'``. If None, ``src_to[0]['subject_his_id']``\n        will be used.\n\n        .. versionchanged:: 0.20\n           Support for subject_to=None.\n    %(subjects_dir)s\n    zooms : float | tuple | str | None\n        The voxel size of volume for each spatial dimension in mm.\n        If spacing is None, MRIs won't be resliced, and both volumes\n        must have the same number of spatial dimensions.\n        Can also be ``'auto'`` to use ``5.`` if ``src_to is None`` and\n        the zooms from ``src_to`` otherwise.\n\n        .. versionchanged:: 0.20\n           Support for 'auto' mode.\n    niter_affine : tuple of int\n        Number of levels (``len(niter_affine)``) and number of\n        iterations per level - for each successive stage of iterative\n        refinement - to perform the affine transform.\n        Default is niter_affine=(100, 100, 10).\n    niter_sdr : tuple of int\n        Number of levels (``len(niter_sdr)``) and number of\n        iterations per level - for each successive stage of iterative\n        refinement - to perform the Symmetric Diffeomorphic Registration (sdr)\n        transform. Default is niter_sdr=(5, 5, 3).\n    spacing : int | list | None\n        The resolution of the icosahedral mesh (typically 5).\n        If None, all vertices will be used (potentially filling the\n        surface). If a list, then values will be morphed to the set of\n        vertices specified in in ``spacing[0]`` and ``spacing[1]``.\n        This will be ignored if ``src_to`` is supplied.\n\n        .. versionchanged:: 0.21\n           src_to, if provided, takes precedence.\n    smooth : int | str | None\n        Number of iterations for the smoothing of the surface data.\n        If None, smooth is automatically defined to fill the surface\n        with non-zero values. Can also be ``'nearest'`` to use the nearest\n        vertices on the surface.\n\n        .. versionchanged:: 0.20\n           Added support for 'nearest'.\n    warn : bool\n        If True, warn if not all vertices were used. The default is warn=True.\n    xhemi : bool\n        Morph across hemisphere. Currently only implemented for\n        ``subject_to == subject_from``. See notes below.\n        The default is xhemi=False.\n    sparse : bool\n        Morph as a sparse source estimate. Works only with (Vector)\n        SourceEstimate. If True the only parameters used are subject_to and\n        subject_from, and spacing has to be None. Default is sparse=False.\n    src_to : instance of SourceSpaces | None\n        The destination source space.\n\n        - For surface-based morphing, this is the preferred over ``spacing``\n          for providing the vertices.\n        - For volumetric morphing, this should be passed so that 1) the\n          resultingmorph volume is properly constrained to the brain volume,\n          and 2) STCs from multiple subjects morphed to the same destination\n          subject/source space have the vertices.\n        - For mixed (surface + volume) morphing, this is required.\n\n        .. versionadded:: 0.20\n    precompute : bool\n        If True (default False), compute the sparse matrix representation of\n        the volumetric morph (if present). This takes a long time to\n        compute, but can make morphs faster when thousands of points are used.\n        See :meth:`mne.SourceMorph.compute_vol_morph_mat` (which can be called\n        later if desired) for more information.\n\n        .. versionadded:: 0.22\n    %(verbose)s\n\n    Returns\n    -------\n    morph : instance of SourceMorph\n        The :class:`mne.SourceMorph` object.\n\n    Notes\n    -----\n    This function can be used to morph surface data between hemispheres by\n    setting ``xhemi=True``. The full cross-hemisphere morph matrix maps left\n    to right and right to left. A matrix for cross-mapping only one hemisphere\n    can be constructed by specifying the appropriate vertices, for example, to\n    map the right hemisphere to the left::\n\n        vertices_from=[[], vert_rh], vertices_to=[vert_lh, []]\n\n    Cross-hemisphere mapping requires appropriate ``sphere.left_right``\n    morph-maps in the subject's directory. These morph maps are included\n    with the ``fsaverage_sym`` FreeSurfer subject, and can be created for other\n    subjects with the ``mris_left_right_register`` FreeSurfer command. The\n    ``fsaverage_sym`` subject is included with FreeSurfer > 5.1 and can be\n    obtained as described `here\n    <https://surfer.nmr.mgh.harvard.edu/fswiki/Xhemi>`_. For statistical\n    comparisons between hemispheres, use of the symmetric ``fsaverage_sym``\n    model is recommended to minimize bias :footcite:`GreveEtAl2013`.\n\n    .. versionadded:: 0.17.0\n\n    .. versionadded:: 0.21.0\n       Support for morphing mixed source estimates.\n\n    References\n    ----------\n    .. footbibliography::\n    \"\"\"\n    src_data, kind, src_subject = _get_src_data(src)\n    subject_from = _check_subject_src(subject_from, src_subject, warn_none=True)\n    del src\n    _validate_type(src_to, (SourceSpaces, None), \"src_to\")\n    _validate_type(subject_to, (str, None), \"subject_to\")\n    if src_to is None and subject_to is None:\n        raise ValueError(\"subject_to cannot be None when src_to is None\")\n    subject_to = _check_subject_src(subject_to, src_to, \"subject_to\")\n\n    # Params\n    warn = False if sparse else warn\n\n    if kind not in \"surface\" and xhemi:\n        raise ValueError(\n            \"Inter-hemispheric morphing can only be used with surface source estimates.\"\n        )\n    if sparse and kind != \"surface\":\n        raise ValueError(\"Only surface source estimates can compute a sparse morph.\")\n\n    subjects_dir = str(get_subjects_dir(subjects_dir, raise_error=True))\n    shape = affine = pre_affine = sdr_morph = morph_mat = None\n    vertices_to_surf, vertices_to_vol = list(), list()\n\n    if kind in (\"volume\", \"mixed\"):\n        _check_dep(nibabel=\"2.1.0\", dipy=\"0.10.1\")\n        nib = _import_nibabel(\"work with a volume source space\")\n\n        logger.info(\"Volume source space(s) present...\")\n\n        # load moving MRI\n        mri_subpath = op.join(\"mri\", \"brain.mgz\")\n        mri_path_from = op.join(subjects_dir, subject_from, mri_subpath)\n\n        logger.info(f'    Loading {mri_path_from} as \"from\" volume')\n        with warnings.catch_warnings():\n            mri_from = nib.load(mri_path_from)\n\n        # eventually we could let this be some other volume, but for now\n        # let's KISS and use `brain.mgz`, too\n        mri_path_to = op.join(subjects_dir, subject_to, mri_subpath)\n        if not op.isfile(mri_path_to):\n            raise OSError(f\"cannot read file: {mri_path_to}\")\n        logger.info(f'    Loading {mri_path_to} as \"to\" volume')\n        with warnings.catch_warnings():\n            mri_to = nib.load(mri_path_to)\n\n        # deal with `src_to` subsampling\n        zooms_src_to = None\n        if src_to is None:\n            if kind == \"mixed\":\n                raise ValueError(\n                    \"src_to must be provided when using a mixed source space\"\n                )\n        else:\n            surf_offset = 2 if src_to.kind == \"mixed\" else 0\n            # All of our computations are in RAS (like img.affine), so we need\n            # to get the transformation from RAS to the source space\n            # subsampling of vox (src), not MRI (FreeSurfer surface RAS) to src\n            src_ras_t = np.dot(\n                src_to[-1][\"mri_ras_t\"][\"trans\"], src_to[-1][\"src_mri_t\"][\"trans\"]\n            )\n            src_ras_t[:3] *= 1e3\n            src_data[\"to_vox_map\"] = (src_to[-1][\"shape\"], src_ras_t)\n            vertices_to_vol = [s[\"vertno\"] for s in src_to[surf_offset:]]\n            zooms_src_to = np.diag(src_to[-1][\"src_mri_t\"][\"trans\"])[:3] * 1000\n            zooms_src_to = tuple(zooms_src_to)\n\n        # pre-compute non-linear morph\n        zooms = _check_zooms(mri_from, zooms, zooms_src_to)\n        shape, zooms, affine, pre_affine, sdr_morph = _compute_morph_sdr(\n            mri_from, mri_to, niter_affine, niter_sdr, zooms\n        )\n\n    if kind in (\"surface\", \"mixed\"):\n        logger.info(\"surface source space present ...\")\n        vertices_from = src_data[\"vertices_from\"]\n        if sparse:\n            if spacing is not None:\n                raise ValueError(\"spacing must be set to None if sparse=True.\")\n            if xhemi:\n                raise ValueError(\"xhemi=True can only be used with sparse=False\")\n            vertices_to_surf, morph_mat = _compute_sparse_morph(\n                vertices_from, subject_from, subject_to, subjects_dir\n            )\n        else:\n            if src_to is not None:\n                assert src_to.kind in (\"surface\", \"mixed\")\n                vertices_to_surf = [s[\"vertno\"].copy() for s in src_to[:2]]\n            else:\n                vertices_to_surf = grade_to_vertices(\n                    subject_to, spacing, subjects_dir, 1\n                )\n            morph_mat = _compute_morph_matrix(\n                subject_from=subject_from,\n                subject_to=subject_to,\n                vertices_from=vertices_from,\n                vertices_to=vertices_to_surf,\n                subjects_dir=subjects_dir,\n                smooth=smooth,\n                warn=warn,\n                xhemi=xhemi,\n            )\n            n_verts = sum(len(v) for v in vertices_to_surf)\n            assert morph_mat.shape[0] == n_verts\n\n    vertices_to = vertices_to_surf + vertices_to_vol\n    if src_to is not None:\n        assert len(vertices_to) == len(src_to)\n    morph = SourceMorph(\n        subject_from,\n        subject_to,\n        kind,\n        zooms,\n        niter_affine,\n        niter_sdr,\n        spacing,\n        smooth,\n        xhemi,\n        morph_mat,\n        vertices_to,\n        shape,\n        affine,\n        pre_affine,\n        sdr_morph,\n        src_data,\n        None,\n    )\n    if precompute:\n        morph.compute_vol_morph_mat()\n    logger.info(\"[done]\")\n    return morph", "metadata": {}}
{"_id": "mne_mne_morph.py_read_source_morph_code", "title": "read_source_morph", "text": "def read_source_morph(fname):\n    \"\"\"Load the morph for source estimates from a file.\n\n    Parameters\n    ----------\n    fname : path-like\n        Path to the file containing the morph source estimates.\n\n    Returns\n    -------\n    source_morph : instance of SourceMorph\n        The loaded morph.\n    \"\"\"\n    read_hdf5, _ = _import_h5io_funcs()\n    vals = read_hdf5(fname)\n    if vals[\"pre_affine\"] is not None:  # reconstruct\n        from dipy.align.imaffine import AffineMap\n\n        affine = vals[\"pre_affine\"]\n        vals[\"pre_affine\"] = AffineMap(None)\n        vals[\"pre_affine\"].__dict__ = affine\n    if vals[\"sdr_morph\"] is not None:\n        from dipy.align.imwarp import DiffeomorphicMap\n\n        morph = vals[\"sdr_morph\"]\n        vals[\"sdr_morph\"] = DiffeomorphicMap(None, [])\n        vals[\"sdr_morph\"].__dict__ = morph\n    # Backward compat with when it used to be a list\n    if isinstance(vals[\"vertices_to\"], np.ndarray):\n        vals[\"vertices_to\"] = [vals[\"vertices_to\"]]\n    # Backward compat with when it used to be a single array\n    if isinstance(vals[\"src_data\"].get(\"inuse\", None), np.ndarray):\n        vals[\"src_data\"][\"inuse\"] = [vals[\"src_data\"][\"inuse\"]]\n    # added with compute_vol_morph_mat in 0.22:\n    vals[\"vol_morph_mat\"] = vals.get(\"vol_morph_mat\", None)\n    return SourceMorph(**vals)", "metadata": {}}
{"_id": "mne_mne_morph.py_grade_to_vertices_code", "title": "grade_to_vertices", "text": "def grade_to_vertices(subject, grade, subjects_dir=None, n_jobs=None, verbose=None):\n    \"\"\"Convert a grade to source space vertices for a given subject.\n\n    Parameters\n    ----------\n    subject : str\n        Name of the subject.\n    grade : int | list\n        Resolution of the icosahedral mesh (typically 5). If None, all\n        vertices will be used (potentially filling the surface). If a list,\n        then values will be morphed to the set of vertices specified in\n        in grade[0] and grade[1]. Note that specifying the vertices (e.g.,\n        grade=[np.arange(10242), np.arange(10242)] for fsaverage on a\n        standard grade 5 source space) can be substantially faster than\n        computing vertex locations. Note that if subject='fsaverage'\n        and 'grade=5', this set of vertices will automatically be used\n        (instead of computed) for speed, since this is a common morph.\n    %(subjects_dir)s\n    %(n_jobs)s\n    %(verbose)s\n\n    Returns\n    -------\n    vertices : list of array of int\n        Vertex numbers for LH and RH.\n    \"\"\"\n    _validate_type(grade, (list, \"int-like\", None), \"grade\")\n    # add special case for fsaverage for speed\n    if subject == \"fsaverage\" and isinstance(grade, int) and grade == 5:\n        return [np.arange(10242), np.arange(10242)]\n    subjects_dir = get_subjects_dir(subjects_dir, raise_error=True)\n\n    spheres_to = [\n        subjects_dir / subject / \"surf\" / (xh + \".sphere.reg\") for xh in [\"lh\", \"rh\"]\n    ]\n    lhs, rhs = (read_surface(s)[0] for s in spheres_to)\n\n    if grade is not None:  # fill a subset of vertices\n        if isinstance(grade, list):\n            if not len(grade) == 2:\n                raise ValueError(\n                    \"grade as a list must have two elements (arrays of output vertices)\"\n                )\n            vertices = grade\n        else:\n            grade = _ensure_int(grade)\n            # find which vertices to use in \"to mesh\"\n            ico = _get_ico_tris(grade, return_surf=True)\n            lhs /= np.sqrt(np.sum(lhs**2, axis=1))[:, None]\n            rhs /= np.sqrt(np.sum(rhs**2, axis=1))[:, None]\n\n            # Compute nearest vertices in high dim mesh\n            parallel, my_compute_nearest, _ = parallel_func(_compute_nearest, n_jobs)\n            lhs, rhs, rr = (a.astype(np.float32) for a in [lhs, rhs, ico[\"rr\"]])\n            vertices = parallel(my_compute_nearest(xhs, rr) for xhs in [lhs, rhs])\n            # Make sure the vertices are ordered\n            vertices = [np.sort(verts) for verts in vertices]\n            for verts in vertices:\n                if (np.diff(verts) == 0).any():\n                    raise ValueError(\n                        f\"Cannot use icosahedral grade {grade} with subject \"\n                        f\"{subject}, mapping {len(verts)} vertices onto the \"\n                        \"high-resolution mesh \"\n                        \"yields repeated vertices, use a lower grade or a \"\n                        \"list of vertices from an existing source space\"\n                    )\n    else:  # potentially fill the surface\n        vertices = [np.arange(lhs.shape[0]), np.arange(rhs.shape[0])]\n\n    return vertices", "metadata": {}}
{"_id": "mne_mne_morph.py_apply_code", "title": "apply", "text": "def apply(\n        self, stc_from, output=\"stc\", mri_resolution=False, mri_space=None, verbose=None\n    ):\n        \"\"\"Morph source space data.\n\n        Parameters\n        ----------\n        stc_from : VolSourceEstimate | VolVectorSourceEstimate | SourceEstimate | VectorSourceEstimate\n            The source estimate to morph.\n        output : str\n            Can be ``'stc'`` (default) or possibly ``'nifti1'``, or\n            ``'nifti2'`` when working with a volume source space defined on a\n            regular grid.\n        mri_resolution : bool | tuple | int | float\n            If True the image is saved in MRI resolution. Default False.\n\n            .. warning: If you have many time points the file produced can be\n                        huge. The default is ``mri_resolution=False``.\n        mri_space : bool | None\n            Whether the image to world registration should be in mri space. The\n            default (None) is mri_space=mri_resolution.\n        %(verbose)s\n\n        Returns\n        -------\n        stc_to : VolSourceEstimate | SourceEstimate | VectorSourceEstimate | Nifti1Image | Nifti2Image\n            The morphed source estimates.\n        \"\"\"  # noqa: E501\n        _validate_type(output, str, \"output\")\n        _validate_type(stc_from, _BaseSourceEstimate, \"stc_from\", \"source estimate\")\n        if isinstance(stc_from, _BaseSurfaceSourceEstimate):\n            allowed_kinds = (\"stc\",)\n            extra = \"when stc is a surface source estimate\"\n        else:\n            allowed_kinds = (\"stc\", \"nifti1\", \"nifti2\")\n            extra = \"\"\n        _check_option(\"output\", output, allowed_kinds, extra)\n        stc = copy.deepcopy(stc_from)\n\n        mri_space = mri_resolution if mri_space is None else mri_space\n        if stc.subject is None:\n            stc.subject = self.subject_from\n        if self.subject_from is None:\n            self.subject_from = stc.subject\n        if stc.subject != self.subject_from:\n            raise ValueError(\n                \"stc_from.subject and \"\n                \"morph.subject_from \"\n                f\"must match. ({stc.subject} != {self.subject_from})\"\n            )\n        out = _apply_morph_data(self, stc)\n        if output != \"stc\":  # convert to volume\n            out = _morphed_stc_as_volume(\n                self,\n                out,\n                mri_resolution=mri_resolution,\n                mri_space=mri_space,\n                output=output,\n            )\n        return out", "metadata": {}}
{"_id": "mne_mne_morph.py_compute_vol_morph_mat_code", "title": "compute_vol_morph_mat", "text": "def compute_vol_morph_mat(self, *, verbose=None):\n        \"\"\"Compute the sparse matrix representation of the volumetric morph.\n\n        Parameters\n        ----------\n        %(verbose)s\n\n        Returns\n        -------\n        morph : instance of SourceMorph\n            The instance (modified in-place).\n\n        Notes\n        -----\n        For a volumetric morph, this will compute the morph for an identity\n        source volume, i.e., with one source vertex active at a time, and store\n        the result as a :class:`sparse <scipy.sparse.csr_array>`\n        morphing matrix. This takes a long time (minutes) to compute initially,\n        but drastically speeds up :meth:`apply` for STCs, so it can be\n        beneficial when many time points or many morphs (i.e., greater than\n        the number of volumetric ``src_from`` vertices) will be performed.\n\n        When calling :meth:`save`, this sparse morphing matrix is saved with\n        the instance, so this only needs to be called once. This function does\n        nothing if the morph matrix has already been computed, or if there is\n        no volume morphing necessary.\n\n        .. versionadded:: 0.22\n        \"\"\"\n        if self.affine is None or self.vol_morph_mat is not None:\n            return\n        logger.info(\"Computing sparse volumetric morph matrix (will take some time...)\")\n        self.vol_morph_mat = self._morph_vols(None, \"Vertex\")\n        return self", "metadata": {}}
{"_id": "mne_mne_morph.py_save_code", "title": "save", "text": "def save(self, fname, overwrite=False, verbose=None):\n        \"\"\"Save the morph for source estimates to a file.\n\n        Parameters\n        ----------\n        fname : path-like\n            The path to the file. ``'-morph.h5'`` will be added if fname does\n            not end with ``'.h5'``.\n        %(overwrite)s\n        %(verbose)s\n        \"\"\"\n        _, write_hdf5 = _import_h5io_funcs()\n        fname = _check_fname(fname, overwrite=overwrite, must_exist=False)\n        if fname.suffix != \".h5\":\n            fname = fname.with_name(f\"{fname.name}-morph.h5\")\n\n        out_dict = {k: getattr(self, k) for k in _SOURCE_MORPH_ATTRIBUTES}\n        for key in (\"pre_affine\", \"sdr_morph\"):  # classes\n            if out_dict[key] is not None:\n                out_dict[key] = out_dict[key].__dict__\n        write_hdf5(fname, out_dict, overwrite=overwrite)", "metadata": {}}
{"_id": "mne_mne_chpi.py_read_head_pos_code", "title": "read_head_pos", "text": "def read_head_pos(fname):\n    \"\"\"Read MaxFilter-formatted head position parameters.\n\n    Parameters\n    ----------\n    fname : path-like\n        The filename to read. This can be produced by e.g.,\n        ``maxfilter -headpos <name>.pos``.\n\n    Returns\n    -------\n    pos : array, shape (N, 10)\n        The position and quaternion parameters from cHPI fitting.\n\n    See Also\n    --------\n    write_head_pos\n    head_pos_to_trans_rot_t\n\n    Notes\n    -----\n    .. versionadded:: 0.12\n    \"\"\"\n    _check_fname(fname, must_exist=True, overwrite=\"read\")\n    data = np.loadtxt(fname, skiprows=1)  # first line is header, skip it\n    data.shape = (-1, 10)  # ensure it's the right size even if empty\n    if np.isnan(data).any():  # make sure we didn't do something dumb\n        raise RuntimeError(f\"positions could not be read properly from {fname}\")\n    return data", "metadata": {}}
{"_id": "mne_mne_chpi.py_write_head_pos_code", "title": "write_head_pos", "text": "def write_head_pos(fname, pos):\n    \"\"\"Write MaxFilter-formatted head position parameters.\n\n    Parameters\n    ----------\n    fname : path-like\n        The filename to write.\n    pos : array, shape (N, 10)\n        The position and quaternion parameters from cHPI fitting.\n\n    See Also\n    --------\n    read_head_pos\n    head_pos_to_trans_rot_t\n\n    Notes\n    -----\n    .. versionadded:: 0.12\n    \"\"\"\n    _check_fname(fname, overwrite=True)\n    pos = np.array(pos, np.float64)\n    if pos.ndim != 2 or pos.shape[1] != 10:\n        raise ValueError(\"pos must be a 2D array of shape (N, 10)\")\n    with open(fname, \"wb\") as fid:\n        fid.write(\n            \" Time       q1       q2       q3       q4       q5       \"\n            \"q6       g-value  error    velocity\\n\".encode(\"ASCII\")\n        )\n        for p in pos:\n            fmts = [\"% 9.3f\"] + [\"% 8.5f\"] * 9\n            fid.write(((\" \" + \" \".join(fmts) + \"\\n\") % tuple(p)).encode(\"ASCII\"))", "metadata": {}}
{"_id": "mne_mne_chpi.py_head_pos_to_trans_rot_t_code", "title": "head_pos_to_trans_rot_t", "text": "def head_pos_to_trans_rot_t(quats):\n    \"\"\"Convert Maxfilter-formatted head position quaternions.\n\n    Parameters\n    ----------\n    quats : ndarray, shape (N, 10)\n        MaxFilter-formatted position and quaternion parameters.\n\n    Returns\n    -------\n    translation : ndarray, shape (N, 3)\n        Translations at each time point.\n    rotation : ndarray, shape (N, 3, 3)\n        Rotations at each time point.\n    t : ndarray, shape (N,)\n        The time points.\n\n    See Also\n    --------\n    read_head_pos\n    write_head_pos\n    \"\"\"\n    t = quats[..., 0].copy()\n    rotation = quat_to_rot(quats[..., 1:4])\n    translation = quats[..., 4:7].copy()\n    return translation, rotation, t", "metadata": {}}
{"_id": "mne_mne_chpi.py_extract_chpi_locs_ctf_code", "title": "extract_chpi_locs_ctf", "text": "def extract_chpi_locs_ctf(raw, verbose=None):\n    r\"\"\"Extract cHPI locations from CTF data.\n\n    Parameters\n    ----------\n    raw : instance of Raw\n        Raw data with CTF cHPI information.\n    %(verbose)s\n\n    Returns\n    -------\n    %(chpi_locs)s\n\n    Notes\n    -----\n    CTF continuous head monitoring stores the x,y,z location (m) of each chpi\n    coil as separate channels in the dataset:\n\n    - ``HLC001[123]\\\\*`` - nasion\n    - ``HLC002[123]\\\\*`` - lpa\n    - ``HLC003[123]\\\\*`` - rpa\n\n    This extracts these positions for use with\n    :func:`~mne.chpi.compute_head_pos`.\n\n    .. versionadded:: 0.20\n    \"\"\"\n    # Pick channels corresponding to the cHPI positions\n    hpi_picks = pick_channels_regexp(raw.info[\"ch_names\"], \"HLC00[123][123].*\")\n\n    # make sure we get 9 channels\n    if len(hpi_picks) != 9:\n        raise RuntimeError(\"Could not find all 9 cHPI channels\")\n\n    # get indices in alphabetical order\n    sorted_picks = np.array(sorted(hpi_picks, key=lambda k: raw.info[\"ch_names\"][k]))\n\n    # make picks to match order of dig cardinial ident codes.\n    # LPA (HPIC002[123]-*), NAS(HPIC001[123]-*), RPA(HPIC003[123]-*)\n    hpi_picks = sorted_picks[[3, 4, 5, 0, 1, 2, 6, 7, 8]]\n    del sorted_picks\n\n    # process the entire run\n    time_sl = slice(0, len(raw.times))\n    chpi_data = raw[hpi_picks, time_sl][0]\n\n    # transforms\n    tmp_trans = _make_ctf_coord_trans_set(None, None)\n    ctf_dev_dev_t = tmp_trans[\"t_ctf_dev_dev\"]\n    del tmp_trans\n\n    # find indices where chpi locations change\n    indices = [0]\n    indices.extend(np.where(np.any(np.diff(chpi_data, axis=1), axis=0))[0] + 1)\n    # data in channels are in ctf device coordinates (cm)\n    rrs = chpi_data[:, indices].T.reshape(len(indices), 3, 3)  # m\n    # map to mne device coords\n    rrs = apply_trans(ctf_dev_dev_t, rrs)\n    gofs = np.ones(rrs.shape[:2])  # not encoded, set all good\n    moments = np.zeros(rrs.shape)  # not encoded, set all zero\n    times = raw.times[indices] + raw._first_time\n    return dict(rrs=rrs, gofs=gofs, times=times, moments=moments)", "metadata": {}}
{"_id": "mne_mne_chpi.py_extract_chpi_locs_kit_code", "title": "extract_chpi_locs_kit", "text": "def extract_chpi_locs_kit(raw, stim_channel=\"MISC 064\", *, verbose=None):\n    \"\"\"Extract cHPI locations from KIT data.\n\n    Parameters\n    ----------\n    raw : instance of RawKIT\n        Raw data with KIT cHPI information.\n    stim_channel : str\n        The stimulus channel that encodes HPI measurement intervals.\n    %(verbose)s\n\n    Returns\n    -------\n    %(chpi_locs)s\n\n    Notes\n    -----\n    .. versionadded:: 0.23\n    \"\"\"\n    _validate_type(raw, (_RawKIT,), \"raw\")\n    stim_chs = [\n        raw.info[\"ch_names\"][pick]\n        for pick in pick_types(raw.info, stim=True, misc=True, ref_meg=False)\n    ]\n    _validate_type(stim_channel, str, \"stim_channel\")\n    _check_option(\"stim_channel\", stim_channel, stim_chs)\n    idx = raw.ch_names.index(stim_channel)\n    safe_false = _verbose_safe_false()\n    events_on = find_events(\n        raw, stim_channel=raw.ch_names[idx], output=\"onset\", verbose=safe_false\n    )[:, 0]\n    events_off = find_events(\n        raw, stim_channel=raw.ch_names[idx], output=\"offset\", verbose=safe_false\n    )[:, 0]\n    bad = False\n    if len(events_on) == 0 or len(events_off) == 0:\n        bad = True\n    else:\n        if events_on[-1] > events_off[-1]:\n            events_on = events_on[:-1]\n        if events_on.size != events_off.size or not (events_on < events_off).all():\n            bad = True\n    if bad:\n        raise RuntimeError(\n            f\"Could not find appropriate cHPI intervals from {stim_channel}\"\n        )\n    # use the midpoint for times\n    times = (events_on + events_off) / (2 * raw.info[\"sfreq\"])\n    del events_on, events_off\n    # XXX remove first two rows. It is unknown currently if there is a way to\n    # determine from the con file the number of initial pulses that\n    # indicate the start of reading. The number is shown by opening the con\n    # file in MEG160, but I couldn't find the value in the .con file, so it\n    # may just always be 2...\n    times = times[2:]\n    n_coils = 5  # KIT always has 5 (hard-coded in reader)\n    header = raw._raw_extras[0][\"dirs\"][KIT.DIR_INDEX_CHPI_DATA]\n    dtype = np.dtype([(\"good\", \"<u4\"), (\"data\", \"<f8\", (4,))])\n    assert dtype.itemsize == header[\"size\"], (dtype.itemsize, header[\"size\"])\n    all_data = list()\n    for fname in raw.filenames:\n        with open(fname) as fid:\n            fid.seek(header[\"offset\"])\n            all_data.append(\n                np.fromfile(fid, dtype, count=header[\"count\"]).reshape(-1, n_coils)\n            )\n    data = np.concatenate(all_data)\n    extra = \"\"\n    if len(times) < len(data):\n        extra = f\", truncating to {len(times)} based on events\"\n    logger.info(f\"Found {len(data)} cHPI measurement{_pl(len(data))}{extra}\")\n    data = data[: len(times)]\n    # good is not currently used, but keep this in case we want it later\n    # good = data['good'] == 1\n    data = data[\"data\"]\n    rrs, gofs = data[:, :, :3], data[:, :, 3]\n    rrs = apply_trans(als_ras_trans, rrs)\n    moments = np.zeros(rrs.shape)  # not encoded, set all zero\n    return dict(rrs=rrs, gofs=gofs, times=times, moments=moments)", "metadata": {}}
{"_id": "mne_mne_chpi.py_get_chpi_info_code", "title": "get_chpi_info", "text": "def get_chpi_info(info, on_missing=\"raise\", verbose=None):\n    \"\"\"Retrieve cHPI information from the data.\n\n    Parameters\n    ----------\n    %(info_not_none)s\n    %(on_missing_chpi)s\n    %(verbose)s\n\n    Returns\n    -------\n    hpi_freqs : array, shape (n_coils,)\n        The frequency used for each individual cHPI coil.\n    hpi_pick : int | None\n        The index of the ``STIM`` channel containing information about when\n        which cHPI coils were switched on.\n    hpi_on : array, shape (n_coils,)\n        The values coding for the \"on\" state of each individual cHPI coil.\n\n    Notes\n    -----\n    .. versionadded:: 0.24\n    \"\"\"\n    _validate_type(item=info, item_name=\"info\", types=Info)\n    _check_option(\n        parameter=\"on_missing\",\n        value=on_missing,\n        allowed_values=[\"ignore\", \"raise\", \"warn\"],\n    )\n\n    if len(info[\"hpi_meas\"]) == 0 or (\n        \"coil_freq\" not in info[\"hpi_meas\"][0][\"hpi_coils\"][0]\n    ):\n        _on_missing(\n            on_missing,\n            msg=\"No appropriate cHPI information found in \"\n            'info[\"hpi_meas\"] and info[\"hpi_subsystem\"]',\n        )\n        return np.empty(0), None, np.empty(0)\n\n    hpi_coils = sorted(\n        info[\"hpi_meas\"][-1][\"hpi_coils\"], key=lambda x: x[\"number\"]\n    )  # ascending (info) order\n\n    # get frequencies\n    hpi_freqs = np.array([float(x[\"coil_freq\"]) for x in hpi_coils])\n    logger.info(\n        f\"Using {len(hpi_freqs)} HPI coils: {' '.join(str(int(s)) for s in hpi_freqs)} \"\n        \"Hz\"\n    )\n\n    # how cHPI active is indicated in the FIF file\n    hpi_sub = info[\"hpi_subsystem\"]\n    hpi_pick = None  # there is no pick!\n    if hpi_sub is not None:\n        if \"event_channel\" in hpi_sub:\n            hpi_pick = pick_channels(\n                info[\"ch_names\"], [hpi_sub[\"event_channel\"]], ordered=False\n            )\n            hpi_pick = hpi_pick[0] if len(hpi_pick) > 0 else None\n        # grab codes indicating a coil is active\n        hpi_on = [coil[\"event_bits\"][0] for coil in hpi_sub[\"hpi_coils\"]]\n        # not all HPI coils will actually be used\n        hpi_on = np.array([hpi_on[hc[\"number\"] - 1] for hc in hpi_coils])\n        # mask for coils that may be active\n        hpi_mask = np.array([event_bit != 0 for event_bit in hpi_on])\n        hpi_on = hpi_on[hpi_mask]\n        hpi_freqs = hpi_freqs[hpi_mask]\n    else:\n        hpi_on = np.zeros(len(hpi_freqs))\n\n    return hpi_freqs, hpi_pick, hpi_on", "metadata": {}}
{"_id": "mne_mne_chpi.py_compute_head_pos_code", "title": "compute_head_pos", "text": "def compute_head_pos(\n    info, chpi_locs, dist_limit=0.005, gof_limit=0.98, adjust_dig=False, verbose=None\n):\n    \"\"\"Compute time-varying head positions.\n\n    Parameters\n    ----------\n    %(info_not_none)s\n    %(chpi_locs)s\n        Typically obtained by :func:`~mne.chpi.compute_chpi_locs` or\n        :func:`~mne.chpi.extract_chpi_locs_ctf`.\n    dist_limit : float\n        Minimum distance (m) to accept for coil position fitting.\n    gof_limit : float\n        Minimum goodness of fit to accept for each coil.\n    %(adjust_dig_chpi)s\n    %(verbose)s\n\n    Returns\n    -------\n    quats : ndarray, shape (n_pos, 10)\n        The ``[t, q1, q2, q3, x, y, z, gof, err, v]`` for each fit.\n\n    See Also\n    --------\n    compute_chpi_locs\n    extract_chpi_locs_ctf\n    read_head_pos\n    write_head_pos\n\n    Notes\n    -----\n    .. versionadded:: 0.20\n    \"\"\"\n    _check_chpi_param(chpi_locs, \"chpi_locs\")\n    _validate_type(info, Info, \"info\")\n    hpi_dig_head_rrs = _get_hpi_initial_fit(info, adjust=adjust_dig, verbose=\"error\")\n    n_coils = len(hpi_dig_head_rrs)\n    coil_dev_rrs = apply_trans(invert_transform(info[\"dev_head_t\"]), hpi_dig_head_rrs)\n    dev_head_t = info[\"dev_head_t\"][\"trans\"]\n    pos_0 = dev_head_t[:3, 3]\n    last = dict(\n        quat_fit_time=-0.1,\n        coil_dev_rrs=coil_dev_rrs,\n        quat=np.concatenate([rot_to_quat(dev_head_t[:3, :3]), dev_head_t[:3, 3]]),\n    )\n    del coil_dev_rrs\n    quats = []\n    for fit_time, this_coil_dev_rrs, g_coils in zip(\n        *(chpi_locs[key] for key in (\"times\", \"rrs\", \"gofs\"))\n    ):\n        use_idx = np.where(g_coils >= gof_limit)[0]\n\n        #\n        # 1. Check number of good ones\n        #\n        if len(use_idx) < 3:\n            gofs = \", \".join(f\"{g:0.2f}\" for g in g_coils)\n            warn(\n                f\"{_time_prefix(fit_time)}{len(use_idx)}/{n_coils} \"\n                \"good HPI fits, cannot determine the transformation \"\n                f\"({gofs} GOF)!\"\n            )\n            continue\n\n        #\n        # 2. Fit the head translation and rotation params (minimize error\n        #    between coil positions and the head coil digitization\n        #    positions) iteratively using different sets of coils.\n        #\n        this_quat, g, use_idx = _fit_chpi_quat_subset(\n            this_coil_dev_rrs, hpi_dig_head_rrs, use_idx\n        )\n\n        #\n        # 3. Stop if < 3 good\n        #\n\n        # Convert quaterion to transform\n        this_dev_head_t = _quat_to_affine(this_quat)\n        est_coil_head_rrs = apply_trans(this_dev_head_t, this_coil_dev_rrs)\n        errs = np.linalg.norm(hpi_dig_head_rrs - est_coil_head_rrs, axis=1)\n        n_good = ((g_coils >= gof_limit) & (errs < dist_limit)).sum()\n        if n_good < 3:\n            warn_str = \", \".join(\n                f\"{1000 * e:0.1f}::{g:0.2f}\" for e, g in zip(errs, g_coils)\n            )\n            warn(\n                f\"{_time_prefix(fit_time)}{n_good}/{n_coils} good HPI fits, cannot \"\n                f\"determine the transformation ({warn_str} mm/GOF)!\"\n            )\n            continue\n\n        # velocities, in device coords, of HPI coils\n        dt = fit_time - last[\"quat_fit_time\"]\n        vs = tuple(\n            1000.0\n            * np.linalg.norm(last[\"coil_dev_rrs\"] - this_coil_dev_rrs, axis=1)\n            / dt\n        )\n        logger.info(\n            _time_prefix(fit_time)\n            + (\n                \"%s/%s good HPI fits, movements [mm/s] = \"\n                + \" / \".join([\"% 8.1f\"] * n_coils)\n            )\n            % ((n_good, n_coils) + vs)\n        )\n\n        # Log results\n        # MaxFilter averages over a 200 ms window for display, but we don't\n        for ii in range(n_coils):\n            if ii in use_idx:\n                start, end = \" \", \"/\"\n            else:\n                start, end = \"(\", \")\"\n            log_str = (\n                \"    \"\n                + start\n                + \"{0:6.1f} {1:6.1f} {2:6.1f} / \"\n                + \"{3:6.1f} {4:6.1f} {5:6.1f} / \"\n                + \"g = {6:0.3f} err = {7:4.1f} \"\n                + end\n            )\n            vals = np.concatenate(\n                (\n                    1000 * hpi_dig_head_rrs[ii],\n                    1000 * est_coil_head_rrs[ii],\n                    [g_coils[ii], 1000 * errs[ii]],\n                )\n            )\n            if len(use_idx) >= 3:\n                if ii <= 2:\n                    log_str += \"{8:6.3f} {9:6.3f} {10:6.3f}\"\n                    vals = np.concatenate((vals, this_dev_head_t[ii, :3]))\n                elif ii == 3:\n                    log_str += \"{8:6.1f} {9:6.1f} {10:6.1f}\"\n                    vals = np.concatenate((vals, this_dev_head_t[:3, 3] * 1000.0))\n            logger.debug(log_str.format(*vals))\n\n        # resulting errors in head coil positions\n        d = np.linalg.norm(last[\"quat\"][3:] - this_quat[3:])  # m\n        r = _angle_between_quats(last[\"quat\"][:3], this_quat[:3]) / dt\n        v = d / dt  # m/s\n        d = 100 * np.linalg.norm(this_quat[3:] - pos_0)  # dis from 1st\n        logger.debug(\n            f\"    #t = {fit_time:0.3f}, #e = {100 * errs.mean():0.2f} cm, #g = {g:0.3f}\"\n            f\", #v = {100 * v:0.2f} cm/s, #r = {r:0.2f} rad/s, #d = {d:0.2f} cm\"\n        )\n        q_rep = \" \".join(f\"{qq:8.5f}\" for qq in this_quat)\n        logger.debug(f\"    #t = {fit_time:0.3f}, #q = {q_rep}\")\n\n        quats.append(\n            np.concatenate(([fit_time], this_quat, [g], [errs[use_idx].mean()], [v]))\n        )\n        last[\"quat_fit_time\"] = fit_time\n        last[\"quat\"] = this_quat\n        last[\"coil_dev_rrs\"] = this_coil_dev_rrs\n    quats = np.array(quats, np.float64)\n    quats = np.zeros((0, 10)) if quats.size == 0 else quats\n    return quats", "metadata": {}}
{"_id": "mne_mne_chpi.py_compute_chpi_snr_code", "title": "compute_chpi_snr", "text": "def compute_chpi_snr(\n    raw, t_step_min=0.01, t_window=\"auto\", ext_order=1, tmin=0, tmax=None, verbose=None\n):\n    \"\"\"Compute time-varying estimates of cHPI SNR.\n\n    Parameters\n    ----------\n    raw : instance of Raw\n        Raw data with cHPI information.\n    t_step_min : float\n        Minimum time step to use.\n    %(t_window_chpi_t)s\n    %(ext_order_chpi)s\n    %(tmin_raw)s\n    %(tmax_raw)s\n    %(verbose)s\n\n    Returns\n    -------\n    chpi_snrs : dict\n        The time-varying cHPI SNR estimates, with entries \"times\", \"freqs\",\n        \"snr_mag\", \"power_mag\", and \"resid_mag\" (and/or \"snr_grad\",\n        \"power_grad\", and \"resid_grad\", depending on which channel types are\n        present in ``raw``).\n\n    See Also\n    --------\n    mne.chpi.compute_chpi_locs, mne.chpi.compute_chpi_amplitudes\n\n    Notes\n    -----\n    .. versionadded:: 0.24\n    \"\"\"\n    return _compute_chpi_amp_or_snr(\n        raw, t_step_min, t_window, ext_order, tmin, tmax, verbose, snr=True\n    )", "metadata": {}}
{"_id": "mne_mne_chpi.py_compute_chpi_amplitudes_code", "title": "compute_chpi_amplitudes", "text": "def compute_chpi_amplitudes(\n    raw, t_step_min=0.01, t_window=\"auto\", ext_order=1, tmin=0, tmax=None, verbose=None\n):\n    \"\"\"Compute time-varying cHPI amplitudes.\n\n    Parameters\n    ----------\n    raw : instance of Raw\n        Raw data with cHPI information.\n    t_step_min : float\n        Minimum time step to use.\n    %(t_window_chpi_t)s\n    %(ext_order_chpi)s\n    %(tmin_raw)s\n    %(tmax_raw)s\n    %(verbose)s\n\n    Returns\n    -------\n    %(chpi_amplitudes)s\n\n    See Also\n    --------\n    mne.chpi.compute_chpi_locs, mne.chpi.compute_chpi_snr\n\n    Notes\n    -----\n    This function will:\n\n    1. Get HPI frequencies,  HPI status channel, HPI status bits,\n       and digitization order using ``_setup_hpi_amplitude_fitting``.\n    2. Window data using ``t_window`` (half before and half after ``t``) and\n       ``t_step_min``.\n    3. Use a linear model (DC + linear slope + sin + cos terms) to fit\n       sinusoidal amplitudes to MEG channels.\n       It uses SVD to determine the phase/amplitude of the sinusoids.\n\n    In \"auto\" mode, ``t_window`` will be set to the longer of:\n\n    1. Five cycles of the lowest HPI or line frequency.\n          Ensures that the frequency estimate is stable.\n    2. The reciprocal of the smallest difference between HPI and line freqs.\n          Ensures that neighboring frequencies can be disambiguated.\n\n    The output is meant to be used with :func:`~mne.chpi.compute_chpi_locs`.\n\n    .. versionadded:: 0.20\n    \"\"\"\n    return _compute_chpi_amp_or_snr(\n        raw, t_step_min, t_window, ext_order, tmin, tmax, verbose\n    )", "metadata": {}}
{"_id": "mne_mne_chpi.py_compute_chpi_locs_code", "title": "compute_chpi_locs", "text": "def compute_chpi_locs(\n    info,\n    chpi_amplitudes,\n    t_step_max=1.0,\n    too_close=\"raise\",\n    adjust_dig=False,\n    verbose=None,\n):\n    \"\"\"Compute locations of each cHPI coils over time.\n\n    Parameters\n    ----------\n    %(info_not_none)s\n    %(chpi_amplitudes)s\n        Typically obtained by :func:`mne.chpi.compute_chpi_amplitudes`.\n    t_step_max : float\n        Maximum time step to use.\n    too_close : str\n        How to handle HPI positions too close to the sensors,\n        can be ``'raise'`` (default), ``'warning'``, or ``'info'``.\n    %(adjust_dig_chpi)s\n    %(verbose)s\n\n    Returns\n    -------\n    %(chpi_locs)s\n\n    See Also\n    --------\n    compute_chpi_amplitudes\n    compute_head_pos\n    read_head_pos\n    write_head_pos\n    extract_chpi_locs_ctf\n\n    Notes\n    -----\n    This function is designed to take the output of\n    :func:`mne.chpi.compute_chpi_amplitudes` and:\n\n    1. Get HPI coil locations (as digitized in ``info['dig']``) in head coords.\n    2. If the amplitudes are 98%% correlated with last position\n       (and \u0394t < t_step_max), skip fitting.\n    3. Fit magnetic dipoles using the amplitudes for each coil frequency.\n\n    The number of fitted points ``n_pos`` will depend on the velocity of head\n    movements as well as ``t_step_max`` (and ``t_step_min`` from\n    :func:`mne.chpi.compute_chpi_amplitudes`).\n\n    .. versionadded:: 0.20\n    \"\"\"\n    # Set up magnetic dipole fits\n    _check_option(\"too_close\", too_close, [\"raise\", \"warning\", \"info\"])\n    _check_chpi_param(chpi_amplitudes, \"chpi_amplitudes\")\n    _validate_type(info, Info, \"info\")\n    sin_fits = chpi_amplitudes  # use the old name below\n    del chpi_amplitudes\n    proj = sin_fits[\"proj\"]\n    meg_picks = pick_channels(info[\"ch_names\"], proj[\"data\"][\"col_names\"], ordered=True)\n    info = pick_info(info, meg_picks)  # makes a copy\n    with info._unlock():\n        info[\"projs\"] = [proj]\n    del meg_picks, proj\n    meg_coils = _concatenate_coils(_create_meg_coils(info[\"chs\"], \"accurate\"))\n\n    # Set up external model for interference suppression\n    safe_false = _verbose_safe_false()\n    cov = make_ad_hoc_cov(info, verbose=safe_false)\n    whitener, _ = compute_whitener(cov, info, verbose=safe_false)\n\n    # Make some location guesses (1 cm grid)\n    R = np.linalg.norm(meg_coils[0], axis=1).min()\n    guesses = _make_guesses(\n        dict(R=R, r0=np.zeros(3)), 0.01, 0.0, 0.005, verbose=safe_false\n    )[0][\"rr\"]\n    logger.info(\n        f\"Computing {len(guesses)} HPI location guesses \"\n        f\"(1 cm grid in a {R * 100:.1f} cm sphere)\"\n    )\n    fwd = _magnetic_dipole_field_vec(guesses, meg_coils, too_close)\n    fwd = np.dot(fwd, whitener.T)\n    fwd.shape = (guesses.shape[0], 3, -1)\n    fwd = np.linalg.svd(fwd, full_matrices=False)[2]\n    guesses = dict(rr=guesses, whitened_fwd_svd=fwd)\n    del fwd, R\n\n    iter_ = list(zip(sin_fits[\"times\"], sin_fits[\"slopes\"]))\n    chpi_locs = dict(times=[], rrs=[], gofs=[], moments=[])\n    # setup last iteration structure\n    hpi_dig_dev_rrs = apply_trans(\n        invert_transform(info[\"dev_head_t\"])[\"trans\"],\n        _get_hpi_initial_fit(info, adjust=adjust_dig),\n    )\n    last = dict(\n        sin_fit=None,\n        coil_fit_time=sin_fits[\"times\"][0] - 1,\n        coil_dev_rrs=hpi_dig_dev_rrs,\n    )\n    n_hpi = len(hpi_dig_dev_rrs)\n    del hpi_dig_dev_rrs\n    for fit_time, sin_fit in ProgressBar(iter_, mesg=\"cHPI locations \"):\n        # skip this window if bad\n        if not np.isfinite(sin_fit).all():\n            continue\n\n        # check if data has sufficiently changed\n        if last[\"sin_fit\"] is not None:  # first iteration\n            corrs = np.array(\n                [np.corrcoef(s, lst)[0, 1] for s, lst in zip(sin_fit, last[\"sin_fit\"])]\n            )\n            corrs *= corrs\n            # check to see if we need to continue\n            if (\n                fit_time - last[\"coil_fit_time\"] <= t_step_max - 1e-7\n                and (corrs > 0.98).sum() >= 3\n            ):\n                # don't need to refit data\n                continue\n\n        # update 'last' sin_fit *before* inplace sign mult\n        last[\"sin_fit\"] = sin_fit.copy()\n\n        #\n        # 2. Fit magnetic dipole for each coil to obtain coil positions\n        #    in device coordinates\n        #\n        coil_fits = [\n            _fit_magnetic_dipole(f, x0, too_close, whitener, meg_coils, guesses)\n            for f, x0 in zip(sin_fit, last[\"coil_dev_rrs\"])\n        ]\n        rrs, gofs, moments = zip(*coil_fits)\n        chpi_locs[\"times\"].append(fit_time)\n        chpi_locs[\"rrs\"].append(rrs)\n        chpi_locs[\"gofs\"].append(gofs)\n        chpi_locs[\"moments\"].append(moments)\n        last[\"coil_fit_time\"] = fit_time\n        last[\"coil_dev_rrs\"] = rrs\n    n_times = len(chpi_locs[\"times\"])\n    shapes = dict(\n        times=(n_times,),\n        rrs=(n_times, n_hpi, 3),\n        gofs=(n_times, n_hpi),\n        moments=(n_times, n_hpi, 3),\n    )\n    for key, val in chpi_locs.items():\n        chpi_locs[key] = np.array(val, float).reshape(shapes[key])\n    return chpi_locs", "metadata": {}}
{"_id": "mne_mne_chpi.py_filter_chpi_code", "title": "filter_chpi", "text": "def filter_chpi(\n    raw,\n    include_line=True,\n    t_step=0.01,\n    t_window=\"auto\",\n    ext_order=1,\n    allow_line_only=False,\n    verbose=None,\n):\n    \"\"\"Remove cHPI and line noise from data.\n\n    .. note:: This function will only work properly if cHPI was on\n              during the recording.\n\n    Parameters\n    ----------\n    raw : instance of Raw\n        Raw data with cHPI information. Must be preloaded. Operates in-place.\n    include_line : bool\n        If True, also filter line noise.\n    t_step : float\n        Time step to use for estimation, default is 0.01 (10 ms).\n    %(t_window_chpi_t)s\n    %(ext_order_chpi)s\n    allow_line_only : bool\n        If True, allow filtering line noise only. The default is False,\n        which only allows the function to run when cHPI information is present.\n\n        .. versionadded:: 0.20\n    %(verbose)s\n\n    Returns\n    -------\n    raw : instance of Raw\n        The raw data.\n\n    Notes\n    -----\n    cHPI signals are in general not stationary, because head movements act\n    like amplitude modulators on cHPI signals. Thus it is recommended to\n    use this procedure, which uses an iterative fitting method, to\n    remove cHPI signals, as opposed to notch filtering.\n\n    .. versionadded:: 0.12\n    \"\"\"\n    _validate_type(raw, BaseRaw, \"raw\")\n    if not raw.preload:\n        raise RuntimeError(\"raw data must be preloaded\")\n    t_step = float(t_step)\n    if t_step <= 0:\n        raise ValueError(f\"t_step ({t_step}) must be > 0\")\n    n_step = int(np.ceil(t_step * raw.info[\"sfreq\"]))\n    if include_line and raw.info[\"line_freq\"] is None:\n        raise RuntimeError(\n            'include_line=True but raw.info[\"line_freq\"] is '\n            \"None, consider setting it to the line frequency\"\n        )\n    hpi = _setup_hpi_amplitude_fitting(\n        raw.info,\n        t_window,\n        remove_aliased=True,\n        ext_order=ext_order,\n        allow_empty=allow_line_only,\n        verbose=_verbose_safe_false(),\n    )\n\n    fit_idxs = np.arange(0, len(raw.times) + hpi[\"n_window\"] // 2, n_step)\n    n_freqs = len(hpi[\"freqs\"])\n    n_remove = 2 * n_freqs\n    meg_picks = pick_types(raw.info, meg=True, exclude=())  # filter all chs\n    n_times = len(raw.times)\n\n    msg = f\"Removing {n_freqs} cHPI\"\n    if include_line:\n        n_remove += 2 * len(hpi[\"line_freqs\"])\n        msg += f\" and {len(hpi['line_freqs'])} line harmonic\"\n    msg += f\" frequencies from {len(meg_picks)} MEG channels\"\n\n    recon = np.dot(hpi[\"model\"][:, :n_remove], hpi[\"inv_model\"][:n_remove]).T\n    logger.info(msg)\n    chunks = list()  # the chunks to subtract\n    last_endpt = 0\n    pb = ProgressBar(fit_idxs, mesg=\"Filtering\")\n    for ii, midpt in enumerate(pb):\n        left_edge = midpt - hpi[\"n_window\"] // 2\n        time_sl = slice(\n            max(left_edge, 0), min(left_edge + hpi[\"n_window\"], len(raw.times))\n        )\n        this_len = time_sl.stop - time_sl.start\n        if this_len == hpi[\"n_window\"]:\n            this_recon = recon\n        else:  # first or last window\n            model = hpi[\"model\"][:this_len]\n            inv_model = np.linalg.pinv(model)\n            this_recon = np.dot(model[:, :n_remove], inv_model[:n_remove]).T\n        this_data = raw._data[meg_picks, time_sl]\n        subt_pt = min(midpt + n_step, n_times)\n        if last_endpt != subt_pt:\n            fit_left_edge = left_edge - time_sl.start + hpi[\"n_window\"] // 2\n            fit_sl = slice(fit_left_edge, fit_left_edge + (subt_pt - last_endpt))\n            chunks.append((subt_pt, np.dot(this_data, this_recon[:, fit_sl])))\n        last_endpt = subt_pt\n\n        # Consume (trailing) chunks that are now safe to remove because\n        # our windows will no longer touch them\n        if ii < len(fit_idxs) - 1:\n            next_left_edge = fit_idxs[ii + 1] - hpi[\"n_window\"] // 2\n        else:\n            next_left_edge = np.inf\n        while len(chunks) > 0 and chunks[0][0] <= next_left_edge:\n            right_edge, chunk = chunks.pop(0)\n            raw._data[meg_picks, right_edge - chunk.shape[1] : right_edge] -= chunk\n    return raw", "metadata": {}}
{"_id": "mne_mne_chpi.py_get_active_chpi_code", "title": "get_active_chpi", "text": "def get_active_chpi(raw, *, on_missing=\"raise\", verbose=None):\n    \"\"\"Determine how many HPI coils were active for a time point.\n\n    Parameters\n    ----------\n    raw : instance of Raw\n        Raw data with cHPI information.\n    %(on_missing_chpi)s\n    %(verbose)s\n\n    Returns\n    -------\n    n_active : array, shape (n_times)\n        The number of active cHPIs for every timepoint in raw.\n\n    Notes\n    -----\n    .. versionadded:: 1.2\n    \"\"\"\n    # get meg system\n    system, _ = _get_meg_system(raw.info)\n\n    # check whether we have a neuromag system\n    if system not in [\"122m\", \"306m\"]:\n        raise NotImplementedError(\n            \"Identifying active HPI channels is not implemented for other systems than \"\n            \"neuromag.\"\n        )\n    # extract hpi info\n    chpi_info = get_chpi_info(raw.info, on_missing=on_missing)\n    if (len(chpi_info[2]) == 0) or (chpi_info[1] is None):\n        return np.zeros_like(raw.times)\n\n    # extract hpi time series and infer which one was on\n    chpi_ts = raw[chpi_info[1]][0].astype(int)\n    chpi_active = (chpi_ts & chpi_info[2][:, np.newaxis]).astype(bool)\n    return chpi_active.sum(axis=0)", "metadata": {}}
{"_id": "mne_mne_source_estimate.py_read_source_estimate_code", "title": "read_source_estimate", "text": "def read_source_estimate(fname, subject=None):\n    \"\"\"Read a source estimate object.\n\n    Parameters\n    ----------\n    fname : path-like\n        Path to (a) source-estimate file(s).\n    subject : str | None\n        Name of the subject the source estimate(s) is (are) from.\n        It is good practice to set this attribute to avoid combining\n        incompatible labels and SourceEstimates (e.g., ones from other\n        subjects). Note that due to file specification limitations, the\n        subject name isn't saved to or loaded from files written to disk.\n\n    Returns\n    -------\n    stc : SourceEstimate | VectorSourceEstimate | VolSourceEstimate | MixedSourceEstimate\n        The source estimate object loaded from file.\n\n    Notes\n    -----\n     - for volume source estimates, ``fname`` should provide the path to a\n       single file named ``'*-vl.stc``` or ``'*-vol.stc'``\n     - for surface source estimates, ``fname`` should either provide the\n       path to the file corresponding to a single hemisphere (``'*-lh.stc'``,\n       ``'*-rh.stc'``) or only specify the asterisk part in these patterns. In\n       any case, the function expects files for both hemisphere with names\n       following this pattern.\n     - for vector surface source estimates, only HDF5 files are supported.\n     - for mixed source estimates, only HDF5 files are supported.\n     - for single time point ``.w`` files, ``fname`` should follow the same\n       pattern as for surface estimates, except that files are named\n       ``'*-lh.w'`` and ``'*-rh.w'``.\n    \"\"\"  # noqa: E501\n    fname_arg = fname\n\n    # expand `~` without checking whether the file actually exists \u2013 we'll\n    # take care of that later, as it's complicated by the different suffixes\n    # STC files can have\n    fname = str(_check_fname(fname=fname, overwrite=\"read\", must_exist=False))\n\n    # make sure corresponding file(s) can be found\n    ftype = None\n    if op.exists(fname):\n        if fname.endswith((\"-vl.stc\", \"-vol.stc\", \"-vl.w\", \"-vol.w\")):\n            ftype = \"volume\"\n        elif fname.endswith(\".stc\"):\n            ftype = \"surface\"\n            if fname.endswith((\"-lh.stc\", \"-rh.stc\")):\n                fname = fname[:-7]\n            else:\n                err = (\n                    f\"Invalid .stc filename: {fname!r}; needs to end with \"\n                    \"hemisphere tag ('...-lh.stc' or '...-rh.stc')\"\n                )\n                raise OSError(err)\n        elif fname.endswith(\".w\"):\n            ftype = \"w\"\n            if fname.endswith((\"-lh.w\", \"-rh.w\")):\n                fname = fname[:-5]\n            else:\n                err = (\n                    f\"Invalid .w filename: {fname!r}; needs to end with \"\n                    \"hemisphere tag ('...-lh.w' or '...-rh.w')\"\n                )\n                raise OSError(err)\n        elif fname.endswith(\".h5\"):\n            ftype = \"h5\"\n            fname = fname[:-3]\n        else:\n            raise RuntimeError(f\"Unknown extension for file {fname_arg}\")\n\n    if ftype != \"volume\":\n        stc_exist = [op.exists(f) for f in [fname + \"-rh.stc\", fname + \"-lh.stc\"]]\n        w_exist = [op.exists(f) for f in [fname + \"-rh.w\", fname + \"-lh.w\"]]\n        if all(stc_exist) and ftype != \"w\":\n            ftype = \"surface\"\n        elif all(w_exist):\n            ftype = \"w\"\n        elif op.exists(fname + \".h5\"):\n            ftype = \"h5\"\n        elif op.exists(fname + \"-stc.h5\"):\n            ftype = \"h5\"\n            fname += \"-stc\"\n        elif any(stc_exist) or any(w_exist):\n            raise OSError(f\"Hemisphere missing for {fname_arg!r}\")\n        else:\n            raise OSError(f\"SourceEstimate File(s) not found for: {fname_arg!r}\")\n\n    # read the files\n    if ftype == \"volume\":  # volume source space\n        if fname.endswith(\".stc\"):\n            kwargs = _read_stc(fname)\n        elif fname.endswith(\".w\"):\n            kwargs = _read_w(fname)\n            kwargs[\"data\"] = kwargs[\"data\"][:, np.newaxis]\n            kwargs[\"tmin\"] = 0.0\n            kwargs[\"tstep\"] = 0.0\n        else:\n            raise OSError(\"Volume source estimate must end with .stc or .w\")\n        kwargs[\"vertices\"] = [kwargs[\"vertices\"]]\n    elif ftype == \"surface\":  # stc file with surface source spaces\n        lh = _read_stc(fname + \"-lh.stc\")\n        rh = _read_stc(fname + \"-rh.stc\")\n        assert lh[\"tmin\"] == rh[\"tmin\"]\n        assert lh[\"tstep\"] == rh[\"tstep\"]\n        kwargs = lh.copy()\n        kwargs[\"data\"] = np.r_[lh[\"data\"], rh[\"data\"]]\n        kwargs[\"vertices\"] = [lh[\"vertices\"], rh[\"vertices\"]]\n    elif ftype == \"w\":  # w file with surface source spaces\n        lh = _read_w(fname + \"-lh.w\")\n        rh = _read_w(fname + \"-rh.w\")\n        kwargs = lh.copy()\n        kwargs[\"data\"] = np.atleast_2d(np.r_[lh[\"data\"], rh[\"data\"]]).T\n        kwargs[\"vertices\"] = [lh[\"vertices\"], rh[\"vertices\"]]\n        # w files only have a single time point\n        kwargs[\"tmin\"] = 0.0\n        kwargs[\"tstep\"] = 1.0\n        ftype = \"surface\"\n    elif ftype == \"h5\":\n        read_hdf5, _ = _import_h5io_funcs()\n        kwargs = read_hdf5(fname + \".h5\", title=\"mnepython\")\n        ftype = kwargs.pop(\"src_type\", \"surface\")\n        if isinstance(kwargs[\"vertices\"], np.ndarray):\n            kwargs[\"vertices\"] = [kwargs[\"vertices\"]]\n\n    if ftype != \"volume\":\n        # Make sure the vertices are ordered\n        vertices = kwargs[\"vertices\"]\n        if any(np.any(np.diff(v.astype(int)) <= 0) for v in vertices):\n            sidx = [np.argsort(verts) for verts in vertices]\n            vertices = [verts[idx] for verts, idx in zip(vertices, sidx)]\n            data = kwargs[\"data\"][np.r_[sidx[0], len(sidx[0]) + sidx[1]]]\n            kwargs[\"vertices\"] = vertices\n            kwargs[\"data\"] = data\n\n    if \"subject\" not in kwargs:\n        kwargs[\"subject\"] = subject\n    if subject is not None and subject != kwargs[\"subject\"]:\n        raise RuntimeError(\n            f'provided subject name \"{subject}\" does not match '\n            f'subject name from the file \"{kwargs[\"subject\"]}'\n        )\n\n    if ftype in (\"volume\", \"discrete\"):\n        klass = VolVectorSourceEstimate\n    elif ftype == \"mixed\":\n        klass = MixedVectorSourceEstimate\n    else:\n        assert ftype == \"surface\"\n        klass = VectorSourceEstimate\n    if kwargs[\"data\"].ndim < 3:\n        klass = klass._scalar_class\n    return klass(**kwargs)", "metadata": {}}
{"_id": "mne_mne_source_estimate.py_spatio_temporal_src_adjacency_code", "title": "spatio_temporal_src_adjacency", "text": "def spatio_temporal_src_adjacency(src, n_times, dist=None, verbose=None):\n    \"\"\"Compute adjacency for a source space activation over time.\n\n    Parameters\n    ----------\n    src : instance of SourceSpaces\n        The source space. It can be a surface source space or a\n        volume source space.\n    n_times : int\n        Number of time instants.\n    dist : float, or None\n        Maximal geodesic distance (in m) between vertices in the\n        source space to consider neighbors. If None, immediate neighbors\n        are extracted from an ico surface.\n    %(verbose)s\n\n    Returns\n    -------\n    adjacency : ~scipy.sparse.coo_array\n        The adjacency matrix describing the spatio-temporal\n        graph structure. If N is the number of vertices in the\n        source space, the N first nodes in the graph are the\n        vertices are time 1, the nodes from 2 to 2N are the vertices\n        during time 2, etc.\n    \"\"\"\n    # XXX we should compute adjacency for each source space and then\n    # use scipy.sparse.block_diag to concatenate them\n    if src[0][\"type\"] == \"vol\":\n        if dist is not None:\n            raise ValueError(\n                f\"dist must be None for a volume source space. Got {dist}.\"\n            )\n\n        adjacency = _spatio_temporal_src_adjacency_vol(src, n_times)\n    elif dist is not None:\n        # use distances computed and saved in the source space file\n        adjacency = spatio_temporal_dist_adjacency(src, n_times, dist)\n    else:\n        adjacency = _spatio_temporal_src_adjacency_surf(src, n_times)\n    return adjacency", "metadata": {}}
{"_id": "mne_mne_source_estimate.py_grade_to_tris_code", "title": "grade_to_tris", "text": "def grade_to_tris(grade, verbose=None):\n    \"\"\"Get tris defined for a certain grade.\n\n    Parameters\n    ----------\n    grade : int\n        Grade of an icosahedral mesh.\n    %(verbose)s\n\n    Returns\n    -------\n    tris : list\n        2-element list containing Nx3 arrays of tris, suitable for use in\n        spatio_temporal_tris_adjacency.\n    \"\"\"\n    a = _get_ico_tris(grade, None, False)\n    tris = np.concatenate((a, a + (np.max(a) + 1)))\n    return tris", "metadata": {}}
{"_id": "mne_mne_source_estimate.py_spatio_temporal_tris_adjacency_code", "title": "spatio_temporal_tris_adjacency", "text": "def spatio_temporal_tris_adjacency(tris, n_times, remap_vertices=False, verbose=None):\n    \"\"\"Compute adjacency from triangles and time instants.\n\n    Parameters\n    ----------\n    tris : array\n        N x 3 array defining triangles.\n    n_times : int\n        Number of time points.\n    remap_vertices : bool\n        Reassign vertex indices based on unique values. Useful\n        to process a subset of triangles. Defaults to False.\n    %(verbose)s\n\n    Returns\n    -------\n    adjacency : ~scipy.sparse.coo_array\n        The adjacency matrix describing the spatio-temporal\n        graph structure. If N is the number of vertices in the\n        source space, the N first nodes in the graph are the\n        vertices are time 1, the nodes from 2 to 2N are the vertices\n        during time 2, etc.\n    \"\"\"\n    if remap_vertices:\n        logger.info(\"Reassigning vertex indices.\")\n        tris = np.searchsorted(np.unique(tris), tris)\n\n    edges = mesh_edges(tris)\n    edges = (edges + _eye_array(edges.shape[0])).tocoo()\n    return _get_adjacency_from_edges(edges, n_times)", "metadata": {}}
{"_id": "mne_mne_source_estimate.py_spatio_temporal_dist_adjacency_code", "title": "spatio_temporal_dist_adjacency", "text": "def spatio_temporal_dist_adjacency(src, n_times, dist, verbose=None):\n    \"\"\"Compute adjacency from distances in a source space and time instants.\n\n    Parameters\n    ----------\n    src : instance of SourceSpaces\n        The source space must have distances between vertices computed, such\n        that src['dist'] exists and is useful. This can be obtained\n        with a call to :func:`mne.setup_source_space` with the\n        ``add_dist=True`` option.\n    n_times : int\n        Number of time points.\n    dist : float\n        Maximal geodesic distance (in m) between vertices in the\n        source space to consider neighbors.\n    %(verbose)s\n\n    Returns\n    -------\n    adjacency : ~scipy.sparse.coo_array\n        The adjacency matrix describing the spatio-temporal\n        graph structure. If N is the number of vertices in the\n        source space, the N first nodes in the graph are the\n        vertices are time 1, the nodes from 2 to 2N are the vertices\n        during time 2, etc.\n    \"\"\"\n    if src[0][\"dist\"] is None:\n        raise RuntimeError(\n            \"src must have distances included, consider using \"\n            \"setup_source_space with add_dist=True\"\n        )\n    blocks = [s[\"dist\"][s[\"vertno\"], :][:, s[\"vertno\"]] for s in src]\n    # Ensure we keep explicit zeros; deal with changes in SciPy\n    for block in blocks:\n        if isinstance(block, np.ndarray):\n            block[block == 0] = -np.inf\n        else:\n            block.data[block.data == 0] == -1\n    edges = sparse.block_diag(blocks)\n    edges.data[:] = np.less_equal(edges.data, dist)\n    # clean it up and put it in coo format\n    edges = edges.tocsr()\n    edges.eliminate_zeros()\n    edges = edges.tocoo()\n    return _get_adjacency_from_edges(edges, n_times)", "metadata": {}}
{"_id": "mne_mne_source_estimate.py_spatial_src_adjacency_code", "title": "spatial_src_adjacency", "text": "def spatial_src_adjacency(src, dist=None, verbose=None):\n    \"\"\"Compute adjacency for a source space activation.\n\n    Parameters\n    ----------\n    src : instance of SourceSpaces\n        The source space. It can be a surface source space or a\n        volume source space.\n    dist : float, or None\n        Maximal geodesic distance (in m) between vertices in the\n        source space to consider neighbors. If None, immediate neighbors\n        are extracted from an ico surface.\n    %(verbose)s\n\n    Returns\n    -------\n    adjacency : ~scipy.sparse.coo_array\n        The adjacency matrix describing the spatial graph structure.\n    \"\"\"\n    return spatio_temporal_src_adjacency(src, 1, dist)", "metadata": {}}
{"_id": "mne_mne_source_estimate.py_spatial_tris_adjacency_code", "title": "spatial_tris_adjacency", "text": "def spatial_tris_adjacency(tris, remap_vertices=False, verbose=None):\n    \"\"\"Compute adjacency from triangles.\n\n    Parameters\n    ----------\n    tris : array\n        N x 3 array defining triangles.\n    remap_vertices : bool\n        Reassign vertex indices based on unique values. Useful\n        to process a subset of triangles. Defaults to False.\n    %(verbose)s\n\n    Returns\n    -------\n    adjacency : ~scipy.sparse.coo_array\n        The adjacency matrix describing the spatial graph structure.\n    \"\"\"\n    return spatio_temporal_tris_adjacency(tris, 1, remap_vertices)", "metadata": {}}
{"_id": "mne_mne_source_estimate.py_spatial_dist_adjacency_code", "title": "spatial_dist_adjacency", "text": "def spatial_dist_adjacency(src, dist, verbose=None):\n    \"\"\"Compute adjacency from distances in a source space.\n\n    Parameters\n    ----------\n    src : instance of SourceSpaces\n        The source space must have distances between vertices computed, such\n        that src['dist'] exists and is useful. This can be obtained\n        with a call to :func:`mne.setup_source_space` with the\n        ``add_dist=True`` option.\n    dist : float\n        Maximal geodesic distance (in m) between vertices in the\n        source space to consider neighbors.\n    %(verbose)s\n\n    Returns\n    -------\n    adjacency : ~scipy.sparse.coo_array\n        The adjacency matrix describing the spatial graph structure.\n    \"\"\"\n    return spatio_temporal_dist_adjacency(src, 1, dist)", "metadata": {}}
{"_id": "mne_mne_source_estimate.py_spatial_inter_hemi_adjacency_code", "title": "spatial_inter_hemi_adjacency", "text": "def spatial_inter_hemi_adjacency(src, dist, verbose=None):\n    \"\"\"Get vertices on each hemisphere that are close to the other hemisphere.\n\n    Parameters\n    ----------\n    src : instance of SourceSpaces\n        The source space. Must be surface type.\n    dist : float\n        Maximal Euclidean distance (in m) between vertices in one hemisphere\n        compared to the other to consider neighbors.\n    %(verbose)s\n\n    Returns\n    -------\n    adjacency : ~scipy.sparse.coo_array\n        The adjacency matrix describing the spatial graph structure.\n        Typically this should be combined (addititively) with another\n        existing intra-hemispheric adjacency matrix, e.g. computed\n        using geodesic distances.\n    \"\"\"\n    src = _ensure_src(src, kind=\"surface\")\n    adj = cdist(src[0][\"rr\"][src[0][\"vertno\"]], src[1][\"rr\"][src[1][\"vertno\"]])\n    adj = sparse.csr_array(adj <= dist, dtype=int)\n    empties = [sparse.csr_array((nv, nv), dtype=int) for nv in adj.shape]\n    adj = sparse.vstack(\n        [sparse.hstack([empties[0], adj]), sparse.hstack([adj.T, empties[1]])]\n    )\n    return adj", "metadata": {}}
{"_id": "mne_mne_source_estimate.py_extract_label_time_course_code", "title": "extract_label_time_course", "text": "def extract_label_time_course(\n    stcs,\n    labels,\n    src,\n    mode=\"auto\",\n    allow_empty=False,\n    return_generator=False,\n    *,\n    mri_resolution=True,\n    verbose=None,\n):\n    \"\"\"Extract label time course for lists of labels and source estimates.\n\n    This function will extract one time course for each label and source\n    estimate. The way the time courses are extracted depends on the mode\n    parameter (see Notes).\n\n    Parameters\n    ----------\n    stcs : SourceEstimate | list (or generator) of SourceEstimate\n        The source estimates from which to extract the time course.\n    %(labels_eltc)s\n    %(src_eltc)s\n    %(mode_eltc)s\n    %(allow_empty_eltc)s\n    return_generator : bool\n        If True, a generator instead of a list is returned.\n    %(mri_resolution_eltc)s\n    %(verbose)s\n\n    Returns\n    -------\n    %(label_tc_el_returns)s\n\n    Notes\n    -----\n    %(eltc_mode_notes)s\n\n    If encountering a ``ValueError`` due to mismatch between number of\n    source points in the subject source space and computed ``stc`` object set\n    ``src`` argument to ``fwd['src']`` or ``inv['src']`` to ensure the source\n    space is the one actually used by the inverse to compute the source\n    time courses.\n    \"\"\"\n    # convert inputs to lists\n    if not isinstance(stcs, list | tuple | GeneratorType):\n        stcs = [stcs]\n        return_several = False\n        return_generator = False\n    else:\n        return_several = True\n\n    label_tc = _gen_extract_label_time_course(\n        stcs,\n        labels,\n        src,\n        mode=mode,\n        allow_empty=allow_empty,\n        mri_resolution=mri_resolution,\n    )\n\n    if not return_generator:\n        # do the extraction and return a list\n        label_tc = list(label_tc)\n\n    if not return_several:\n        # input was a single SoureEstimate, return single array\n        label_tc = label_tc[0]\n\n    return label_tc", "metadata": {}}
{"_id": "mne_mne_source_estimate.py_stc_near_sensors_code", "title": "stc_near_sensors", "text": "def stc_near_sensors(\n    evoked,\n    trans,\n    subject,\n    distance=0.01,\n    mode=\"sum\",\n    project=True,\n    subjects_dir=None,\n    src=None,\n    picks=None,\n    surface=\"auto\",\n    verbose=None,\n):\n    \"\"\"Create a STC from ECoG, sEEG and DBS sensor data.\n\n    Parameters\n    ----------\n    evoked : instance of Evoked\n        The evoked data. Must contain ECoG, sEEG or DBS channels.\n    %(trans)s\n\n        .. versionchanged:: 0.19\n            Support for 'fsaverage' argument.\n    subject : str\n        The subject name.\n    distance : float\n        Distance (m) defining the activation \"ball\" of the sensor.\n    mode : str\n        Can be ``\"sum\"`` to do a linear sum of weights, ``\"weighted\"`` to make\n        this a weighted sum, ``\"nearest\"`` to use only the weight of the\n        nearest sensor, or ``\"single\"`` to do a distance-weight of the nearest\n        sensor. Default is ``\"sum\"``. See Notes.\n\n        .. versionchanged:: 0.24\n           Added \"weighted\" option.\n    project : bool\n        If True, project the sensors to the nearest ``'pial`` surface\n        vertex before computing distances. Only used when doing a\n        surface projection.\n    %(subjects_dir)s\n    src : instance of SourceSpaces\n        The source space.\n\n        .. warning:: If a surface source space is used, make sure that\n                     ``surface='pial'`` was used during construction,\n                     or that you set ``surface='pial'`` here.\n    %(picks_base)s good sEEG, ECoG, and DBS channels.\n\n        .. versionadded:: 0.24\n    surface : str | None\n        The surface to use. If ``src=None``, defaults to the pial surface.\n        Otherwise, the source space surface will be used.\n\n        .. versionadded:: 0.24.1\n    %(verbose)s\n\n    Returns\n    -------\n    stc : instance of SourceEstimate\n        The surface source estimate. If src is None, a surface source\n        estimate will be produced, and the number of vertices will equal\n        the number of pial-surface vertices that were close enough to\n        the sensors to take on a non-zero volue. If src is not None,\n        a surface, volume, or mixed source estimate will be produced\n        (depending on the kind of source space passed) and the\n        vertices will match those of src (i.e., there may be me\n        many all-zero values in stc.data).\n\n    Notes\n    -----\n    For surface projections, this function projects the ECoG sensors to\n    the pial surface (if ``project``), then the activation at each pial\n    surface vertex is given by the mode:\n\n    - ``'sum'``\n        Activation is the sum across each sensor weighted by the fractional\n        ``distance`` from each sensor. A sensor with zero distance gets weight\n        1 and a sensor at ``distance`` meters away (or larger) gets weight 0.\n        If ``distance`` is less than half the distance between any two\n        sensors, this will be the same as ``'single'``.\n    - ``'single'``\n        Same as ``'sum'`` except that only the nearest sensor is used,\n        rather than summing across sensors within the ``distance`` radius.\n        As ``'nearest'`` for vertices with distance zero to the projected\n        sensor.\n    - ``'nearest'``\n        The value is given by the value of the nearest sensor, up to a\n        ``distance`` (beyond which it is zero).\n    - ``'weighted'``\n        The value is given by the same as ``sum`` but the total weight for\n        each vertex is 1. (i.e., it's a weighted sum based on proximity).\n\n    If creating a Volume STC, ``src`` must be passed in, and this\n    function will project sEEG and DBS sensors to nearby surrounding vertices.\n    Then the activation at each volume vertex is given by the mode\n    in the same way as ECoG surface projections.\n\n    .. versionadded:: 0.22\n    \"\"\"\n    from .evoked import Evoked\n\n    _validate_type(evoked, Evoked, \"evoked\")\n    _validate_type(mode, str, \"mode\")\n    _validate_type(src, (None, SourceSpaces), \"src\")\n    _check_option(\"mode\", mode, (\"sum\", \"single\", \"nearest\", \"weighted\"))\n    if surface == \"auto\":\n        surface = \"pial\" if src is None or src.kind == \"surface\" else None\n\n    # create a copy of Evoked using ecog, seeg and dbs\n    if picks is None:\n        picks = pick_types(evoked.info, ecog=True, seeg=True, dbs=True)\n    evoked = evoked.copy().pick(picks)\n    frames = set(ch[\"coord_frame\"] for ch in evoked.info[\"chs\"])\n    if not frames == {FIFF.FIFFV_COORD_HEAD}:\n        raise RuntimeError(\n            f\"Channels must be in the head coordinate frame, got {sorted(frames)}\"\n        )\n\n    # get channel positions that will be used to pinpoint where\n    # in the Source space we will use the evoked data\n    pos = evoked._get_channel_positions()\n\n    # remove nan channels\n    nan_inds = np.where(np.isnan(pos).any(axis=1))[0]\n    nan_chs = [evoked.ch_names[idx] for idx in nan_inds]\n    if len(nan_chs):\n        evoked.drop_channels(nan_chs)\n    pos = [pos[idx] for idx in range(len(pos)) if idx not in nan_inds]\n\n    # coord_frame transformation from native mne \"head\" to MRI coord_frame\n    trans, _ = _get_trans(trans, \"head\", \"mri\", allow_none=True)\n\n    # convert head positions -> coord_frame MRI\n    pos = apply_trans(trans, pos)\n\n    subject = _check_subject(None, subject, raise_error=False)\n    subjects_dir = get_subjects_dir(subjects_dir, raise_error=True)\n    if surface is not None:\n        surf_rr = [\n            read_surface(subjects_dir / subject / \"surf\" / f\"{hemi}.{surface}\")[0]\n            / 1000.0\n            for hemi in (\"lh\", \"rh\")\n        ]\n    if src is None:  # fake a full surface one\n        _validate_type(surface, str, \"surface\", \"when src is None\")\n        src = SourceSpaces(\n            [\n                dict(\n                    rr=rr,\n                    vertno=np.arange(len(rr)),\n                    type=\"surf\",\n                    coord_frame=FIFF.FIFFV_COORD_MRI,\n                )\n                for rr in surf_rr\n            ]\n        )\n        rrs = np.concatenate([s_rr[s[\"vertno\"]] for s_rr, s in zip(surf_rr, src)])\n        keep_all = False\n    else:\n        if surface is None:\n            rrs = np.concatenate([s[\"rr\"][s[\"vertno\"]] for s in src])\n            if src[0][\"coord_frame\"] == FIFF.FIFFV_COORD_HEAD:\n                rrs = apply_trans(trans, rrs)\n        else:\n            rrs = np.concatenate([s_rr[s[\"vertno\"]] for s_rr, s in zip(surf_rr, src)])\n        keep_all = True\n    # ensure it's a usable one\n    klass = dict(\n        surface=SourceEstimate,\n        volume=VolSourceEstimate,\n        mixed=MixedSourceEstimate,\n    )\n    _check_option(\"src.kind\", src.kind, sorted(klass.keys()))\n    klass = klass[src.kind]\n    # projection will only occur with surfaces\n    logger.info(\n        f\"Projecting data from {len(pos)} sensor{_pl(pos)} onto {len(rrs)} \"\n        f\"{src.kind} vertices: {mode} mode\"\n    )\n    if project and src.kind == \"surface\":\n        logger.info(\"    Projecting sensors onto surface\")\n        pos = _project_onto_surface(\n            pos, dict(rr=rrs), project_rrs=True, method=\"nearest\"\n        )[2]\n\n    min_dist = pdist(pos).min() * 1000\n    logger.info(\n        f\"    Minimum {'projected ' if project else ''}intra-sensor distance: \"\n        f\"{min_dist:0.1f} mm\"\n    )\n\n    # compute pairwise distance between source space points and sensors\n    dists = cdist(rrs, pos)\n    assert dists.shape == (len(rrs), len(pos))\n\n    # only consider vertices within our \"epsilon-ball\"\n    # characterized by distance kwarg\n    vertices = np.where((dists <= distance).any(-1))[0]\n    logger.info(f\"    {len(vertices)} / {len(rrs)} non-zero vertices\")\n    w = np.maximum(1.0 - dists[vertices] / distance, 0)\n    # now we triage based on mode\n    if mode in (\"single\", \"nearest\"):\n        range_ = np.arange(w.shape[0])\n        idx = np.argmax(w, axis=1)\n        vals = w[range_, idx] if mode == \"single\" else 1.0\n        w.fill(0)\n        w[range_, idx] = vals\n    elif mode == \"weighted\":\n        norms = w.sum(-1, keepdims=True)\n        norms[norms == 0] = 1.0\n        w /= norms\n    missing = np.where(~np.any(w, axis=0))[0]\n    if len(missing):\n        warn(\n            f\"Channel{_pl(missing)} missing in STC: \"\n            f\"{', '.join(evoked.ch_names[mi] for mi in missing)}\"\n        )\n\n    nz_data = w @ evoked.data\n    if keep_all:\n        data = np.zeros(\n            (sum(len(s[\"vertno\"]) for s in src), len(evoked.times)), dtype=nz_data.dtype\n        )\n        data[vertices] = nz_data\n        vertices = [s[\"vertno\"].copy() for s in src]\n    else:\n        assert src.kind == \"surface\"\n        data = nz_data\n        offset = len(src[0][\"vertno\"])\n        vertices = [vertices[vertices < offset], vertices[vertices >= offset] - offset]\n\n    return klass(\n        data,\n        vertices,\n        evoked.times[0],\n        1.0 / evoked.info[\"sfreq\"],\n        subject=subject,\n        verbose=verbose,\n    )", "metadata": {}}
{"_id": "mne_mne_source_estimate.py_get_peak_code", "title": "get_peak", "text": "def get_peak(\n        self, tmin=None, tmax=None, mode=\"abs\", vert_as_index=False, time_as_index=False\n    ):\n        \"\"\"Get location and latency of peak amplitude.\n\n        Parameters\n        ----------\n        %(get_peak_parameters)s\n\n        Returns\n        -------\n        pos : int\n            The vertex exhibiting the maximum response, either ID or index.\n        latency : float\n            The latency in seconds.\n        \"\"\"\n        stc = self.magnitude() if self._data_ndim == 3 else self\n        if self._n_vertices == 0:\n            raise RuntimeError(\"Cannot find peaks with no vertices\")\n        vert_idx, time_idx, _ = _get_peak(stc.data, self.times, tmin, tmax, mode)\n        if not vert_as_index:\n            vert_idx = np.concatenate(self.vertices)[vert_idx]\n        if not time_as_index:\n            time_idx = self.times[time_idx]\n        return vert_idx, time_idx", "metadata": {}}
{"_id": "mne_mne_source_estimate.py_extract_label_time_course_code", "title": "extract_label_time_course", "text": "def extract_label_time_course(\n        self, labels, src, mode=\"auto\", allow_empty=False, verbose=None\n    ):\n        \"\"\"Extract label time courses for lists of labels.\n\n        This function will extract one time course for each label. The way the\n        time courses are extracted depends on the mode parameter.\n\n        Parameters\n        ----------\n        %(labels_eltc)s\n        %(src_eltc)s\n        %(mode_eltc)s\n        %(allow_empty_eltc)s\n        %(verbose)s\n\n        Returns\n        -------\n        %(label_tc_el_returns)s\n\n        See Also\n        --------\n        extract_label_time_course : Extract time courses for multiple STCs.\n\n        Notes\n        -----\n        %(eltc_mode_notes)s\n        \"\"\"\n        return extract_label_time_course(\n            self,\n            labels,\n            src,\n            mode=mode,\n            return_generator=False,\n            allow_empty=allow_empty,\n            verbose=verbose,\n        )", "metadata": {}}
{"_id": "mne_mne_source_estimate.py_apply_function_code", "title": "apply_function", "text": "def apply_function(\n        self, fun, picks=None, dtype=None, n_jobs=None, verbose=None, **kwargs\n    ):\n        \"\"\"Apply a function to a subset of vertices.\n\n        %(applyfun_summary_stc)s\n\n        Parameters\n        ----------\n        %(fun_applyfun_stc)s\n        %(picks_all)s\n        %(dtype_applyfun)s\n        %(n_jobs)s Ignored if ``vertice_wise=False`` as the workload\n            is split across vertices.\n        %(verbose)s\n        %(kwargs_fun)s\n\n        Returns\n        -------\n        self : instance of SourceEstimate\n            The SourceEstimate object with transformed data.\n        \"\"\"\n        _check_preload(self, \"source_estimate.apply_function\")\n        picks = _picks_to_idx(len(self._data), picks, exclude=(), with_ref_meg=False)\n\n        if not callable(fun):\n            raise ValueError(\"fun needs to be a function\")\n\n        data_in = self._data\n        if dtype is not None and dtype != self._data.dtype:\n            self._data = self._data.astype(dtype)\n\n        # check the dimension of the source estimate data\n        _check_option(\"source_estimate.ndim\", self._data.ndim, [2, 3])\n\n        parallel, p_fun, n_jobs = parallel_func(_check_fun, n_jobs)\n        if n_jobs == 1:\n            # modify data inplace to save memory\n            for idx in picks:\n                self._data[idx, :] = _check_fun(fun, data_in[idx, :], **kwargs)\n        else:\n            # use parallel function\n            data_picks_new = parallel(\n                p_fun(fun, data_in[p, :], **kwargs) for p in picks\n            )\n            for pp, p in enumerate(picks):\n                self._data[p, :] = data_picks_new[pp]\n\n        return self", "metadata": {}}
{"_id": "mne_mne_source_estimate.py_apply_baseline_code", "title": "apply_baseline", "text": "def apply_baseline(self, baseline=(None, 0), *, verbose=None):\n        \"\"\"Baseline correct source estimate data.\n\n        Parameters\n        ----------\n        %(baseline_stc)s\n            Defaults to ``(None, 0)``, i.e. beginning of the the data until\n            time point zero.\n        %(verbose)s\n\n        Returns\n        -------\n        stc : instance of SourceEstimate\n            The baseline-corrected source estimate object.\n\n        Notes\n        -----\n        Baseline correction can be done multiple times.\n        \"\"\"\n        self.data = rescale(self.data, self.times, baseline, copy=False)\n        return self", "metadata": {}}
{"_id": "mne_mne_source_estimate.py_save_code", "title": "save", "text": "def save(self, fname, ftype=\"h5\", *, overwrite=False, verbose=None):\n        \"\"\"Save the full source estimate to an HDF5 file.\n\n        Parameters\n        ----------\n        fname : path-like\n            The file name to write the source estimate to, should end in\n            ``'-stc.h5'``.\n        ftype : str\n            File format to use. Currently, the only allowed values is ``\"h5\"``.\n        %(overwrite)s\n\n            .. versionadded:: 1.0\n        %(verbose)s\n        \"\"\"\n        fname = _check_fname(fname=fname, overwrite=True)  # check below\n        if ftype != \"h5\":\n            raise ValueError(\n                f\"{self.__class__.__name__} objects can only be written as HDF5 files.\"\n            )\n        _, write_hdf5 = _import_h5io_funcs()\n        if fname.suffix != \".h5\":\n            fname = fname.with_name(f\"{fname.name}-stc.h5\")\n        fname = _check_fname(fname=fname, overwrite=overwrite)\n        write_hdf5(\n            fname,\n            dict(\n                vertices=self.vertices,\n                data=self.data,\n                tmin=self.tmin,\n                tstep=self.tstep,\n                subject=self.subject,\n                src_type=self._src_type,\n            ),\n            title=\"mnepython\",\n            overwrite=True,\n        )", "metadata": {}}
{"_id": "mne_mne_source_estimate.py_sfreq_code", "title": "sfreq", "text": "def sfreq(self):\n        \"\"\"Sample rate of the data.\"\"\"\n        return 1.0 / self.tstep", "metadata": {}}
{"_id": "mne_mne_source_estimate.py_crop_code", "title": "crop", "text": "def crop(self, tmin=None, tmax=None, include_tmax=True):\n        \"\"\"Restrict SourceEstimate to a time interval.\n\n        Parameters\n        ----------\n        tmin : float | None\n            The first time point in seconds. If None the first present is used.\n        tmax : float | None\n            The last time point in seconds. If None the last present is used.\n        %(include_tmax)s\n\n        Returns\n        -------\n        stc : instance of SourceEstimate\n            The cropped source estimate.\n        \"\"\"\n        mask = _time_mask(\n            self.times, tmin, tmax, sfreq=self.sfreq, include_tmax=include_tmax\n        )\n        self.tmin = self.times[np.where(mask)[0][0]]\n        if self._kernel is not None and self._sens_data is not None:\n            self._sens_data = self._sens_data[..., mask]\n        else:\n            self.data = self.data[..., mask]\n\n        return self", "metadata": {}}
{"_id": "mne_mne_source_estimate.py_resample_code", "title": "resample", "text": "def resample(\n        self,\n        sfreq,\n        *,\n        npad=100,\n        method=\"fft\",\n        window=\"auto\",\n        pad=\"auto\",\n        n_jobs=None,\n        verbose=None,\n    ):\n        \"\"\"Resample data.\n\n        If appropriate, an anti-aliasing filter is applied before resampling.\n        See :ref:`resampling-and-decimating` for more information.\n\n        Parameters\n        ----------\n        sfreq : float\n            New sample rate to use.\n        npad : int | str\n            Amount to pad the start and end of the data.\n            Can also be \"auto\" to use a padding that will result in\n            a power-of-two size (can be much faster).\n        %(method_resample)s\n\n            .. versionadded:: 1.7\n        %(window_resample)s\n\n            .. versionadded:: 1.7\n        %(pad_resample_auto)s\n\n            .. versionadded:: 1.7\n        %(n_jobs)s\n        %(verbose)s\n\n        Returns\n        -------\n        stc : instance of SourceEstimate\n            The resampled source estimate.\n\n        Notes\n        -----\n        For some data, it may be more accurate to use npad=0 to reduce\n        artifacts. This is dataset dependent -- check your data!\n\n        Note that the sample rate of the original data is inferred from tstep.\n        \"\"\"\n        from .filter import _check_resamp_noop\n\n        o_sfreq = 1.0 / self.tstep\n        if _check_resamp_noop(sfreq, o_sfreq):\n            return self\n\n        # resampling in sensor instead of source space gives a somewhat\n        # different result, so we don't allow it\n        self._remove_kernel_sens_data_()\n\n        data = self.data\n        if data.dtype == np.float32:\n            data = data.astype(np.float64)\n        self.data = resample(\n            data, sfreq, o_sfreq, npad=npad, window=window, n_jobs=n_jobs, method=method\n        )\n\n        # adjust indirectly affected variables\n        self.tstep = 1.0 / sfreq\n        return self", "metadata": {}}
{"_id": "mne_mne_source_estimate.py_data_code", "title": "data", "text": "def data(self):\n        \"\"\"Numpy array of source estimate data.\"\"\"\n        if self._data is None:\n            # compute the solution the first time the data is accessed and\n            # remove the kernel and sensor data\n            self._remove_kernel_sens_data_()\n        return self._data", "metadata": {}}
{"_id": "mne_mne_source_estimate.py_shape_code", "title": "shape", "text": "def shape(self):\n        \"\"\"Shape of the data.\"\"\"\n        if self._data is not None:\n            return self._data.shape\n        return (self._kernel.shape[0], self._sens_data.shape[1])", "metadata": {}}
{"_id": "mne_mne_source_estimate.py_tmin_code", "title": "tmin", "text": "def tmin(self):\n        \"\"\"The first timestamp.\"\"\"\n        return self._tmin", "metadata": {}}
{"_id": "mne_mne_source_estimate.py_tstep_code", "title": "tstep", "text": "def tstep(self):\n        \"\"\"The change in time between two consecutive samples (1 / sfreq).\"\"\"\n        return self._tstep", "metadata": {}}
{"_id": "mne_mne_source_estimate.py_times_code", "title": "times", "text": "def times(self):\n        \"\"\"A timestamp for each sample.\"\"\"\n        return self._times", "metadata": {}}
{"_id": "mne_mne_source_estimate.py_mean_code", "title": "mean", "text": "def mean(self):\n        \"\"\"Make a summary stc file with mean over time points.\n\n        Returns\n        -------\n        stc : SourceEstimate | VectorSourceEstimate\n            The modified stc.\n        \"\"\"\n        out = self.sum()\n        out /= len(self.times)\n        return out", "metadata": {}}
{"_id": "mne_mne_source_estimate.py_sum_code", "title": "sum", "text": "def sum(self):\n        \"\"\"Make a summary stc file with sum over time points.\n\n        Returns\n        -------\n        stc : SourceEstimate | VectorSourceEstimate\n            The modified stc.\n        \"\"\"\n        data = self.data\n        tmax = self.tmin + self.tstep * data.shape[-1]\n        tmin = (self.tmin + tmax) / 2.0\n        tstep = tmax - self.tmin\n        sum_stc = self.__class__(\n            self.data.sum(axis=-1, keepdims=True),\n            vertices=self.vertices,\n            tmin=tmin,\n            tstep=tstep,\n            subject=self.subject,\n        )\n        return sum_stc", "metadata": {}}
{"_id": "mne_mne_source_estimate.py_sqrt_code", "title": "sqrt", "text": "def sqrt(self):\n        \"\"\"Take the square root.\n\n        Returns\n        -------\n        stc : instance of SourceEstimate\n            A copy of the SourceEstimate with sqrt(data).\n        \"\"\"\n        return self ** (0.5)", "metadata": {}}
{"_id": "mne_mne_source_estimate.py_copy_code", "title": "copy", "text": "def copy(self):\n        \"\"\"Return copy of source estimate instance.\n\n        Returns\n        -------\n        stc : instance of SourceEstimate\n            A copy of the source estimate.\n        \"\"\"\n        return copy.deepcopy(self)", "metadata": {}}
{"_id": "mne_mne_source_estimate.py_bin_code", "title": "bin", "text": "def bin(self, width, tstart=None, tstop=None, func=np.mean):\n        \"\"\"Return a source estimate object with data summarized over time bins.\n\n        Time bins of ``width`` seconds. This method is intended for\n        visualization only. No filter is applied to the data before binning,\n        making the method inappropriate as a tool for downsampling data.\n\n        Parameters\n        ----------\n        width : scalar\n            Width of the individual bins in seconds.\n        tstart : scalar | None\n            Time point where the first bin starts. The default is the first\n            time point of the stc.\n        tstop : scalar | None\n            Last possible time point contained in a bin (if the last bin would\n            be shorter than width it is dropped). The default is the last time\n            point of the stc.\n        func : callable\n            Function that is applied to summarize the data. Needs to accept a\n            numpy.array as first input and an ``axis`` keyword argument.\n\n        Returns\n        -------\n        stc : SourceEstimate | VectorSourceEstimate\n            The binned source estimate.\n        \"\"\"\n        if tstart is None:\n            tstart = self.tmin\n        if tstop is None:\n            tstop = self.times[-1]\n\n        times = np.arange(tstart, tstop + self.tstep, width)\n        nt = len(times) - 1\n        data = np.empty(self.shape[:-1] + (nt,), dtype=self.data.dtype)\n        for i in range(nt):\n            idx = (self.times >= times[i]) & (self.times < times[i + 1])\n            data[..., i] = func(self.data[..., idx], axis=-1)\n\n        tmin = times[0] + width / 2.0\n        stc = self.copy()\n        stc._data = data\n        stc.tmin = tmin\n        stc.tstep = width\n        return stc", "metadata": {}}
{"_id": "mne_mne_source_estimate.py_transform_data_code", "title": "transform_data", "text": "def transform_data(self, func, idx=None, tmin_idx=None, tmax_idx=None):\n        \"\"\"Get data after a linear (time) transform has been applied.\n\n        The transform is applied to each source time course independently.\n\n        Parameters\n        ----------\n        func : callable\n            The transform to be applied, including parameters (see, e.g.,\n            :func:`functools.partial`). The first parameter of the function is\n            the input data. The first return value is the transformed data,\n            remaining outputs are ignored. The first dimension of the\n            transformed data has to be the same as the first dimension of the\n            input data.\n        idx : array | None\n            Indicices of source time courses for which to compute transform.\n            If None, all time courses are used.\n        tmin_idx : int | None\n            Index of first time point to include. If None, the index of the\n            first time point is used.\n        tmax_idx : int | None\n            Index of the first time point not to include. If None, time points\n            up to (and including) the last time point are included.\n\n        Returns\n        -------\n        data_t : ndarray\n            The transformed data.\n\n        Notes\n        -----\n        Applying transforms can be significantly faster if the\n        SourceEstimate object was created using \"(kernel, sens_data)\", for\n        the \"data\" parameter as the transform is applied in sensor space.\n        Inverse methods, e.g., \"apply_inverse_epochs\", or \"apply_lcmv_epochs\"\n        do this automatically (if possible).\n        \"\"\"\n        if idx is None:\n            # use all time courses by default\n            idx = slice(None, None)\n\n        if self._kernel is None and self._sens_data is None:\n            if self._kernel_removed:\n                warn(\n                    \"Performance can be improved by not accessing the data \"\n                    \"attribute before calling this method.\"\n                )\n\n            # transform source space data directly\n            data_t = func(self.data[idx, ..., tmin_idx:tmax_idx])\n\n            if isinstance(data_t, tuple):\n                # use only first return value\n                data_t = data_t[0]\n        else:\n            # apply transform in sensor space\n            sens_data_t = func(self._sens_data[:, tmin_idx:tmax_idx])\n\n            if isinstance(sens_data_t, tuple):\n                # use only first return value\n                sens_data_t = sens_data_t[0]\n\n            # apply inverse\n            data_shape = sens_data_t.shape\n            if len(data_shape) > 2:\n                # flatten the last dimensions\n                sens_data_t = sens_data_t.reshape(\n                    data_shape[0], np.prod(data_shape[1:])\n                )\n\n            data_t = np.dot(self._kernel[idx, :], sens_data_t)\n\n            # restore original shape if necessary\n            if len(data_shape) > 2:\n                data_t = data_t.reshape(data_t.shape[0], *data_shape[1:])\n\n        return data_t", "metadata": {}}
{"_id": "mne_mne_source_estimate.py_transform_code", "title": "transform", "text": "def transform(self, func, idx=None, tmin=None, tmax=None, copy=False):\n        \"\"\"Apply linear transform.\n\n        The transform is applied to each source time course independently.\n\n        Parameters\n        ----------\n        func : callable\n            The transform to be applied, including parameters (see, e.g.,\n            :func:`functools.partial`). The first parameter of the function is\n            the input data. The first two dimensions of the transformed data\n            should be (i) vertices and (ii) time.  See Notes for details.\n        idx : array | None\n            Indices of source time courses for which to compute transform.\n            If None, all time courses are used.\n        tmin : float | int | None\n            First time point to include (ms). If None, self.tmin is used.\n        tmax : float | int | None\n            Last time point to include (ms). If None, self.tmax is used.\n        copy : bool\n            If True, return a new instance of SourceEstimate instead of\n            modifying the input inplace.\n\n        Returns\n        -------\n        stcs : SourceEstimate | VectorSourceEstimate | list\n            The transformed stc or, in the case of transforms which yield\n            N-dimensional output (where N > 2), a list of stcs. For a list,\n            copy must be True.\n\n        Notes\n        -----\n        Transforms which yield 3D\n        output (e.g. time-frequency transforms) are valid, so long as the\n        first two dimensions are vertices and time.  In this case, the\n        copy parameter must be True and a list of\n        SourceEstimates, rather than a single instance of SourceEstimate,\n        will be returned, one for each index of the 3rd dimension of the\n        transformed data.  In the case of transforms yielding 2D output\n        (e.g. filtering), the user has the option of modifying the input\n        inplace (copy = False) or returning a new instance of\n        SourceEstimate (copy = True) with the transformed data.\n\n        Applying transforms can be significantly faster if the\n        SourceEstimate object was created using \"(kernel, sens_data)\", for\n        the \"data\" parameter as the transform is applied in sensor space.\n        Inverse methods, e.g., \"apply_inverse_epochs\", or \"apply_lcmv_epochs\"\n        do this automatically (if possible).\n        \"\"\"\n        # min and max data indices to include\n        times = 1000.0 * self.times\n        t_idx = np.where(_time_mask(times, tmin, tmax, sfreq=self.sfreq))[0]\n        if tmin is None:\n            tmin_idx = None\n        else:\n            tmin_idx = t_idx[0]\n\n        if tmax is None:\n            tmax_idx = None\n        else:\n            # +1, because upper boundary needs to include the last sample\n            tmax_idx = t_idx[-1] + 1\n\n        data_t = self.transform_data(\n            func, idx=idx, tmin_idx=tmin_idx, tmax_idx=tmax_idx\n        )\n\n        # account for change in n_vertices\n        if idx is not None:\n            idx_lh = idx[idx < len(self.lh_vertno)]\n            idx_rh = idx[idx >= len(self.lh_vertno)] - len(self.lh_vertno)\n            verts_lh = self.lh_vertno[idx_lh]\n            verts_rh = self.rh_vertno[idx_rh]\n        else:\n            verts_lh = self.lh_vertno\n            verts_rh = self.rh_vertno\n        verts = [verts_lh, verts_rh]\n\n        tmin_idx = 0 if tmin_idx is None else tmin_idx\n        tmin = self.times[tmin_idx]\n\n        if data_t.ndim > 2:\n            # return list of stcs if transformed data has dimensionality > 2\n            if copy:\n                stcs = [\n                    SourceEstimate(\n                        data_t[:, :, a], verts, tmin, self.tstep, self.subject\n                    )\n                    for a in range(data_t.shape[-1])\n                ]\n            else:\n                raise ValueError(\n                    \"copy must be True if transformed data has more than 2 dimensions\"\n                )\n        else:\n            # return new or overwritten stc\n            stcs = self if not copy else self.copy()\n            stcs.vertices = verts\n            stcs.data = data_t\n            stcs.tmin = tmin\n\n        return stcs", "metadata": {}}
{"_id": "mne_mne_source_estimate.py_to_data_frame_code", "title": "to_data_frame", "text": "def to_data_frame(\n        self,\n        index=None,\n        scalings=None,\n        long_format=False,\n        time_format=None,\n        *,\n        verbose=None,\n    ):\n        \"\"\"Export data in tabular structure as a pandas DataFrame.\n\n        Vertices are converted to columns in the DataFrame. By default,\n        an additional column \"time\" is added, unless ``index='time'``\n        (in which case time values form the DataFrame's index).\n\n        Parameters\n        ----------\n        %(index_df_evk)s\n            Defaults to ``None``.\n        %(scalings_df)s\n        %(long_format_df_stc)s\n        %(time_format_df)s\n\n            .. versionadded:: 0.20\n        %(verbose)s\n\n        Returns\n        -------\n        %(df_return)s\n        \"\"\"\n        # check pandas once here, instead of in each private utils function\n        pd = _check_pandas_installed()  # noqa\n        # arg checking\n        valid_index_args = [\"time\", \"subject\"]\n        valid_time_formats = [\"ms\", \"timedelta\"]\n        index = _check_pandas_index_arguments(index, valid_index_args)\n        time_format = _check_time_format(time_format, valid_time_formats)\n        # get data\n        data = self.data.T\n        times = self.times\n        # prepare extra columns / multiindex\n        mindex = list()\n        default_index = [\"time\"]\n        if self.subject is not None:\n            default_index = [\"subject\", \"time\"]\n            mindex.append((\"subject\", np.repeat(self.subject, data.shape[0])))\n        times = _convert_times(times, time_format)\n        mindex.append((\"time\", times))\n        # triage surface vs volume source estimates\n        col_names = list()\n        kinds = [\"VOL\"] * len(self.vertices)\n        if isinstance(self, _BaseSurfaceSourceEstimate | _BaseMixedSourceEstimate):\n            kinds[:2] = [\"LH\", \"RH\"]\n        for kind, vertno in zip(kinds, self.vertices):\n            col_names.extend([f\"{kind}_{vert}\" for vert in vertno])\n        # build DataFrame\n        df = _build_data_frame(\n            self,\n            data,\n            None,\n            long_format,\n            mindex,\n            index,\n            default_index=default_index,\n            col_names=col_names,\n            col_kind=\"source\",\n        )\n        return df", "metadata": {}}
{"_id": "mne_mne_source_estimate.py_lh_data_code", "title": "lh_data", "text": "def lh_data(self):\n        \"\"\"Left hemisphere data.\"\"\"\n        return self.data[: len(self.lh_vertno)]", "metadata": {}}
{"_id": "mne_mne_source_estimate.py_rh_data_code", "title": "rh_data", "text": "def rh_data(self):\n        \"\"\"Right hemisphere data.\"\"\"\n        return self.data[len(self.lh_vertno) :]", "metadata": {}}
{"_id": "mne_mne_source_estimate.py_lh_vertno_code", "title": "lh_vertno", "text": "def lh_vertno(self):\n        \"\"\"Left hemisphere vertno.\"\"\"\n        return self.vertices[0]", "metadata": {}}
{"_id": "mne_mne_source_estimate.py_rh_vertno_code", "title": "rh_vertno", "text": "def rh_vertno(self):\n        \"\"\"Right hemisphere vertno.\"\"\"\n        return self.vertices[1]", "metadata": {}}
{"_id": "mne_mne_source_estimate.py_in_label_code", "title": "in_label", "text": "def in_label(self, label):\n        \"\"\"Get a source estimate object restricted to a label.\n\n        SourceEstimate contains the time course of\n        activation of all sources inside the label.\n\n        Parameters\n        ----------\n        label : Label | BiHemiLabel\n            The label (as created for example by mne.read_label). If the label\n            does not match any sources in the SourceEstimate, a ValueError is\n            raised.\n\n        Returns\n        -------\n        stc : SourceEstimate | VectorSourceEstimate\n            The source estimate restricted to the given label.\n        \"\"\"\n        # make sure label and stc are compatible\n        from .label import BiHemiLabel, Label\n\n        _validate_type(label, (Label, BiHemiLabel), \"label\")\n        if (\n            label.subject is not None\n            and self.subject is not None\n            and label.subject != self.subject\n        ):\n            raise RuntimeError(\n                \"label and stc must have same subject names, \"\n                f'currently \"{label.subject}\" and \"{self.subject}\"'\n            )\n\n        if label.hemi == \"both\":\n            lh_vert, lh_val = self._hemilabel_stc(label.lh)\n            rh_vert, rh_val = self._hemilabel_stc(label.rh)\n            vertices = [lh_vert, rh_vert]\n            values = np.vstack((lh_val, rh_val))\n        elif label.hemi == \"lh\":\n            lh_vert, values = self._hemilabel_stc(label)\n            vertices = [lh_vert, np.array([], int)]\n        else:\n            assert label.hemi == \"rh\"\n            rh_vert, values = self._hemilabel_stc(label)\n            vertices = [np.array([], int), rh_vert]\n\n        if sum([len(v) for v in vertices]) == 0:\n            raise ValueError(\"No vertices match the label in the stc file\")\n\n        label_stc = self.__class__(\n            values,\n            vertices=vertices,\n            tmin=self.tmin,\n            tstep=self.tstep,\n            subject=self.subject,\n        )\n        return label_stc", "metadata": {}}
{"_id": "mne_mne_source_estimate.py_save_as_surface_code", "title": "save_as_surface", "text": "def save_as_surface(self, fname, src, *, scale=1, scale_rr=1e3):\n        \"\"\"Save a surface source estimate (stc) as a GIFTI file.\n\n        Parameters\n        ----------\n        fname : path-like\n            Filename basename to save files as.\n            Will write anatomical GIFTI plus time series GIFTI for both lh/rh,\n            for example ``\"basename\"`` will write ``\"basename.lh.gii\"``,\n            ``\"basename.lh.time.gii\"``, ``\"basename.rh.gii\"``, and\n            ``\"basename.rh.time.gii\"``.\n        src : instance of SourceSpaces\n            The source space of the forward solution.\n        scale : float\n            Scale factor to apply to the data (functional) values.\n        scale_rr : float\n            Scale factor for the source vertex positions. The default (1e3) will\n            scale from meters to millimeters, which is more standard for GIFTI files.\n\n        Notes\n        -----\n        .. versionadded:: 1.7\n        \"\"\"\n        nib = _import_nibabel()\n        _check_option(\"src.kind\", src.kind, (\"surface\", \"mixed\"))\n        ss = get_decimated_surfaces(src)\n        assert len(ss) == 2  # should be guaranteed by _check_option above\n\n        # Create lists to put DataArrays into\n        hemis = (\"lh\", \"rh\")\n        for s, hemi in zip(ss, hemis):\n            darrays = list()\n            darrays.append(\n                nib.gifti.gifti.GiftiDataArray(\n                    data=(s[\"rr\"] * scale_rr).astype(np.float32),\n                    intent=\"NIFTI_INTENT_POINTSET\",\n                    datatype=\"NIFTI_TYPE_FLOAT32\",\n                )\n            )\n\n            # Make the topology DataArray\n            darrays.append(\n                nib.gifti.gifti.GiftiDataArray(\n                    data=s[\"tris\"].astype(np.int32),\n                    intent=\"NIFTI_INTENT_TRIANGLE\",\n                    datatype=\"NIFTI_TYPE_INT32\",\n                )\n            )\n\n            # Make the output GIFTI for anatomicals\n            topo_gi_hemi = nib.gifti.gifti.GiftiImage(darrays=darrays)\n\n            # actually save the file\n            nib.save(topo_gi_hemi, f\"{fname}-{hemi}.gii\")\n\n            # Make the Time Series data arrays\n            ts = []\n            data = getattr(self, f\"{hemi}_data\") * scale\n            ts = [\n                nib.gifti.gifti.GiftiDataArray(\n                    data=data[:, idx].astype(np.float32),\n                    intent=\"NIFTI_INTENT_POINTSET\",\n                    datatype=\"NIFTI_TYPE_FLOAT32\",\n                )\n                for idx in range(data.shape[1])\n            ]\n\n            # save the time series\n            ts_gi = nib.gifti.gifti.GiftiImage(darrays=ts)\n            nib.save(ts_gi, f\"{fname}-{hemi}.time.gii\")", "metadata": {}}
{"_id": "mne_mne_source_estimate.py_expand_code", "title": "expand", "text": "def expand(self, vertices):\n        \"\"\"Expand SourceEstimate to include more vertices.\n\n        This will add rows to stc.data (zero-filled) and modify stc.vertices\n        to include all vertices in stc.vertices and the input vertices.\n\n        Parameters\n        ----------\n        vertices : list of array\n            New vertices to add. Can also contain old values.\n\n        Returns\n        -------\n        stc : SourceEstimate | VectorSourceEstimate\n            The modified stc (note: method operates inplace).\n        \"\"\"\n        if not isinstance(vertices, list):\n            raise TypeError(\"vertices must be a list\")\n        if not len(self.vertices) == len(vertices):\n            raise ValueError(\"vertices must have the same length as stc.vertices\")\n\n        # can no longer use kernel and sensor data\n        self._remove_kernel_sens_data_()\n\n        inserters = list()\n        offsets = [0]\n        for vi, (v_old, v_new) in enumerate(zip(self.vertices, vertices)):\n            v_new = np.setdiff1d(v_new, v_old)\n            inds = np.searchsorted(v_old, v_new)\n            # newer numpy might overwrite inds after np.insert, copy here\n            inserters += [inds.copy()]\n            offsets += [len(v_old)]\n            self.vertices[vi] = np.insert(v_old, inds, v_new)\n        inds = [ii + offset for ii, offset in zip(inserters, offsets[:-1])]\n        inds = np.concatenate(inds)\n        new_data = np.zeros((len(inds),) + self.data.shape[1:])\n        self.data = np.insert(self.data, inds, new_data, axis=0)\n        return self", "metadata": {}}
{"_id": "mne_mne_source_estimate.py_to_original_src_code", "title": "to_original_src", "text": "def to_original_src(\n        self, src_orig, subject_orig=None, subjects_dir=None, verbose=None\n    ):\n        \"\"\"Get a source estimate from morphed source to the original subject.\n\n        Parameters\n        ----------\n        src_orig : instance of SourceSpaces\n            The original source spaces that were morphed to the current\n            subject.\n        subject_orig : str | None\n            The original subject. For most source spaces this shouldn't need\n            to be provided, since it is stored in the source space itself.\n        %(subjects_dir)s\n        %(verbose)s\n\n        Returns\n        -------\n        stc : SourceEstimate | VectorSourceEstimate\n            The transformed source estimate.\n\n        See Also\n        --------\n        morph_source_spaces\n\n        Notes\n        -----\n        .. versionadded:: 0.10.0\n        \"\"\"\n        if self.subject is None:\n            raise ValueError(\"stc.subject must be set\")\n        src_orig = _ensure_src(src_orig, kind=\"surface\")\n        subject_orig = _ensure_src_subject(src_orig, subject_orig)\n        data_idx, vertices = _get_morph_src_reordering(\n            self.vertices, src_orig, subject_orig, self.subject, subjects_dir\n        )\n        return self.__class__(\n            self._data[data_idx], vertices, self.tmin, self.tstep, subject_orig\n        )", "metadata": {}}
{"_id": "mne_mne_source_estimate.py_get_peak_code", "title": "get_peak", "text": "def get_peak(\n        self,\n        hemi=None,\n        tmin=None,\n        tmax=None,\n        mode=\"abs\",\n        vert_as_index=False,\n        time_as_index=False,\n    ):\n        \"\"\"Get location and latency of peak amplitude.\n\n        Parameters\n        ----------\n        hemi : {'lh', 'rh', None}\n            The hemi to be considered. If None, the entire source space is\n            considered.\n        %(get_peak_parameters)s\n\n        Returns\n        -------\n        pos : int\n            The vertex exhibiting the maximum response, either ID or index.\n        latency : float | int\n            The time point of the maximum response, either latency in seconds\n            or index.\n        \"\"\"\n        _check_option(\"hemi\", hemi, (\"lh\", \"rh\", None))\n        vertex_offset = 0\n        if hemi is not None:\n            if hemi == \"lh\":\n                data = self.lh_data\n                vertices = [self.lh_vertno, []]\n            else:\n                vertex_offset = len(self.vertices[0])\n                data = self.rh_data\n                vertices = [[], self.rh_vertno]\n            meth = self.__class__(data, vertices, self.tmin, self.tstep).get_peak\n        else:\n            meth = super().get_peak\n        out = meth(\n            tmin=tmin,\n            tmax=tmax,\n            mode=mode,\n            vert_as_index=vert_as_index,\n            time_as_index=time_as_index,\n        )\n        if vertex_offset and vert_as_index:\n            out = (out[0] + vertex_offset, out[1])\n        return out", "metadata": {}}
{"_id": "mne_mne_source_estimate.py_save_code", "title": "save", "text": "def save(self, fname, ftype=\"stc\", *, overwrite=False, verbose=None):\n        \"\"\"Save the source estimates to a file.\n\n        Parameters\n        ----------\n        fname : path-like\n            The stem of the file name. The file names used for surface source\n            spaces are obtained by adding ``\"-lh.stc\"`` and ``\"-rh.stc\"`` (or\n            ``\"-lh.w\"`` and ``\"-rh.w\"``) to the stem provided, for the left and\n            the right hemisphere, respectively.\n        ftype : str\n            File format to use. Allowed values are ``\"stc\"`` (default),\n            ``\"w\"``, and ``\"h5\"``. The ``\"w\"`` format only supports a single\n            time point.\n        %(overwrite)s\n\n            .. versionadded:: 1.0\n        %(verbose)s\n        \"\"\"\n        fname = str(_check_fname(fname=fname, overwrite=True))  # checked below\n        _check_option(\"ftype\", ftype, [\"stc\", \"w\", \"h5\"])\n\n        lh_data = self.data[: len(self.lh_vertno)]\n        rh_data = self.data[-len(self.rh_vertno) :]\n\n        if ftype == \"stc\":\n            if np.iscomplexobj(self.data):\n                raise ValueError(\n                    \"Cannot save complex-valued STC data in \"\n                    \"FIFF format; please set ftype='h5' to save \"\n                    \"in HDF5 format instead, or cast the data to \"\n                    \"real numbers before saving.\"\n                )\n            logger.info(\"Writing STC to disk...\")\n            fname_l = str(_check_fname(fname + \"-lh.stc\", overwrite=overwrite))\n            fname_r = str(_check_fname(fname + \"-rh.stc\", overwrite=overwrite))\n            _write_stc(\n                fname_l,\n                tmin=self.tmin,\n                tstep=self.tstep,\n                vertices=self.lh_vertno,\n                data=lh_data,\n            )\n            _write_stc(\n                fname_r,\n                tmin=self.tmin,\n                tstep=self.tstep,\n                vertices=self.rh_vertno,\n                data=rh_data,\n            )\n        elif ftype == \"w\":\n            if self.shape[1] != 1:\n                raise ValueError(\"w files can only contain a single time point.\")\n            logger.info(\"Writing STC to disk (w format)...\")\n            fname_l = str(_check_fname(fname + \"-lh.w\", overwrite=overwrite))\n            fname_r = str(_check_fname(fname + \"-rh.w\", overwrite=overwrite))\n            _write_w(fname_l, vertices=self.lh_vertno, data=lh_data[:, 0])\n            _write_w(fname_r, vertices=self.rh_vertno, data=rh_data[:, 0])\n        elif ftype == \"h5\":\n            super().save(fname, overwrite=overwrite)\n        logger.info(\"[done]\")", "metadata": {}}
{"_id": "mne_mne_source_estimate.py_estimate_snr_code", "title": "estimate_snr", "text": "def estimate_snr(self, info, fwd, cov, verbose=None):\n        r\"\"\"Compute time-varying SNR in the source space.\n\n        This function should only be used with source estimates with units\n        nanoAmperes (i.e., MNE-like solutions, *not* dSPM or sLORETA).\n        See also :footcite:`GoldenholzEtAl2009`.\n\n        .. warning:: This function currently only works properly for fixed\n                     orientation.\n\n        Parameters\n        ----------\n        %(info_not_none)s\n        fwd : instance of Forward\n            The forward solution used to create the source estimate.\n        cov : instance of Covariance\n            The noise covariance used to estimate the resting cortical\n            activations. Should be an evoked covariance, not empty room.\n        %(verbose)s\n\n        Returns\n        -------\n        snr_stc : instance of SourceEstimate\n            The source estimate with the SNR computed.\n\n        Notes\n        -----\n        We define the SNR in decibels for each source location at each\n        time point as:\n\n        .. math::\n\n            {\\rm SNR} = 10\\log_10[\\frac{a^2}{N}\\sum_k\\frac{b_k^2}{s_k^2}]\n\n        where :math:`\\\\b_k` is the signal on sensor :math:`k` provided by the\n        forward model for a source with unit amplitude, :math:`a` is the\n        source amplitude, :math:`N` is the number of sensors, and\n        :math:`s_k^2` is the noise variance on sensor :math:`k`.\n\n        References\n        ----------\n        .. footbibliography::\n        \"\"\"\n        from .forward import Forward, convert_forward_solution\n        from .minimum_norm.inverse import _prepare_forward\n\n        _validate_type(fwd, Forward, \"fwd\")\n        _validate_type(info, Info, \"info\")\n        _validate_type(cov, Covariance, \"cov\")\n        _check_stc_units(self)\n        if (self.data >= 0).all():\n            warn(\n                \"This STC appears to be from free orientation, currently SNR\"\n                \" function is valid only for fixed orientation\"\n            )\n\n        fwd = convert_forward_solution(fwd, surf_ori=True, force_fixed=False)\n\n        # G is gain matrix [ch x src], cov is noise covariance [ch x ch]\n        G, _, _, _, _, _, _, cov, _ = _prepare_forward(\n            fwd,\n            info,\n            cov,\n            fixed=True,\n            loose=0,\n            rank=None,\n            pca=False,\n            use_cps=True,\n            exp=None,\n            limit_depth_chs=False,\n            combine_xyz=\"fro\",\n            allow_fixed_depth=False,\n            limit=None,\n        )\n        G = G[\"sol\"][\"data\"]\n        n_channels = cov[\"dim\"]  # number of sensors/channels\n        b_k2 = (G * G).T\n        s_k2 = np.diag(cov[\"data\"])\n        scaling = (1 / n_channels) * np.sum(b_k2 / s_k2, axis=1, keepdims=True)\n        snr_stc = self.copy()\n        snr_stc._data[:] = 10 * np.log10((self.data * self.data) * scaling)\n        return snr_stc", "metadata": {}}
{"_id": "mne_mne_source_estimate.py_center_of_mass_code", "title": "center_of_mass", "text": "def center_of_mass(\n        self,\n        subject=None,\n        hemi=None,\n        restrict_vertices=False,\n        subjects_dir=None,\n        surf=\"sphere\",\n    ):\n        \"\"\"Compute the center of mass of activity.\n\n        This function computes the spatial center of mass on the surface\n        as well as the temporal center of mass as in :footcite:`LarsonLee2013`.\n\n        .. note:: All activity must occur in a single hemisphere, otherwise\n                  an error is raised. The \"mass\" of each point in space for\n                  computing the spatial center of mass is computed by summing\n                  across time, and vice-versa for each point in time in\n                  computing the temporal center of mass. This is useful for\n                  quantifying spatio-temporal cluster locations, especially\n                  when combined with :func:`mne.vertex_to_mni`.\n\n        Parameters\n        ----------\n        subject : str | None\n            The subject the stc is defined for.\n        hemi : int, or None\n            Calculate the center of mass for the left (0) or right (1)\n            hemisphere. If None, one of the hemispheres must be all zeroes,\n            and the center of mass will be calculated for the other\n            hemisphere (useful for getting COM for clusters).\n        restrict_vertices : bool | array of int | instance of SourceSpaces\n            If True, returned vertex will be one from stc. Otherwise, it could\n            be any vertex from surf. If an array of int, the returned vertex\n            will come from that array. If instance of SourceSpaces (as of\n            0.13), the returned vertex will be from the given source space.\n            For most accuruate estimates, do not restrict vertices.\n        %(subjects_dir)s\n        surf : str\n            The surface to use for Euclidean distance center of mass\n            finding. The default here is \"sphere\", which finds the center\n            of mass on the spherical surface to help avoid potential issues\n            with cortical folding.\n\n        Returns\n        -------\n        vertex : int\n            Vertex of the spatial center of mass for the inferred hemisphere,\n            with each vertex weighted by the sum of the stc across time. For a\n            boolean stc, then, this would be weighted purely by the duration\n            each vertex was active.\n        hemi : int\n            Hemisphere the vertex was taken from.\n        t : float\n            Time of the temporal center of mass (weighted by the sum across\n            source vertices).\n\n        See Also\n        --------\n        mne.Label.center_of_mass\n        mne.vertex_to_mni\n\n        References\n        ----------\n        .. footbibliography::\n        \"\"\"\n        if not isinstance(surf, str):\n            raise TypeError(f\"surf must be a string, got {type(surf)}\")\n        subject = _check_subject(self.subject, subject)\n        if np.any(self.data < 0):\n            raise ValueError(\"Cannot compute COM with negative values\")\n        values = np.sum(self.data, axis=1)  # sum across time\n        vert_inds = [\n            np.arange(len(self.vertices[0])),\n            np.arange(len(self.vertices[1])) + len(self.vertices[0]),\n        ]\n        if hemi is None:\n            hemi = np.where(np.array([np.sum(values[vi]) for vi in vert_inds]))[0]\n            if not len(hemi) == 1:\n                raise ValueError(\"Could not infer hemisphere\")\n            hemi = hemi[0]\n        _check_option(\"hemi\", hemi, [0, 1])\n        vertices = self.vertices[hemi]\n        values = values[vert_inds[hemi]]  # left or right\n        del vert_inds\n        vertex = _center_of_mass(\n            vertices,\n            values,\n            hemi=[\"lh\", \"rh\"][hemi],\n            surf=surf,\n            subject=subject,\n            subjects_dir=subjects_dir,\n            restrict_vertices=restrict_vertices,\n        )\n        # do time center of mass by using the values across space\n        masses = np.sum(self.data, axis=0).astype(float)\n        t_ind = np.sum(masses * np.arange(self.shape[1])) / np.sum(masses)\n        t = self.tmin + self.tstep * t_ind\n        return vertex, hemi, t", "metadata": {}}
{"_id": "mne_mne_source_estimate.py_magnitude_code", "title": "magnitude", "text": "def magnitude(self):\n        \"\"\"Compute magnitude of activity without directionality.\n\n        Returns\n        -------\n        stc : instance of SourceEstimate\n            The source estimate without directionality information.\n        \"\"\"\n        data_mag = np.linalg.norm(self.data, axis=1)\n        return self._scalar_class(\n            data_mag, self.vertices, self.tmin, self.tstep, self.subject\n        )", "metadata": {}}
{"_id": "mne_mne_source_estimate.py_project_code", "title": "project", "text": "def project(self, directions, src=None, use_cps=True):\n        \"\"\"Project the data for each vertex in a given direction.\n\n        Parameters\n        ----------\n        directions : ndarray, shape (n_vertices, 3) | str\n            Can be:\n\n            - ``'normal'``\n                Project onto the source space normals.\n            - ``'pca'``\n                SVD will be used to project onto the direction of maximal\n                power for each source.\n            - :class:`~numpy.ndarray`, shape (n_vertices, 3)\n                Projection directions for each source.\n        src : instance of SourceSpaces | None\n            The source spaces corresponding to the source estimate.\n            Not used when ``directions`` is an array, optional when\n            ``directions='pca'``.\n        %(use_cps)s\n            Should be the same value that was used when the forward model\n            was computed (typically True).\n\n        Returns\n        -------\n        stc : instance of SourceEstimate\n            The projected source estimate.\n        directions : ndarray, shape (n_vertices, 3)\n            The directions that were computed (or just used).\n\n        Notes\n        -----\n        When using SVD, there is a sign ambiguity for the direction of maximal\n        power. When ``src is None``, the direction is chosen that makes the\n        resulting time waveform sum positive (i.e., have positive amplitudes).\n        When ``src`` is provided, the directions are flipped in the direction\n        of the source normals, i.e., outward from cortex for surface source\n        spaces and in the +Z / superior direction for volume source spaces.\n\n        .. versionadded:: 0.21\n        \"\"\"\n        _validate_type(directions, (str, np.ndarray), \"directions\")\n        _validate_type(src, (None, SourceSpaces), \"src\")\n        if isinstance(directions, str):\n            _check_option(\"directions\", directions, (\"normal\", \"pca\"), extra=\"when str\")\n\n            if directions == \"normal\":\n                if src is None:\n                    raise ValueError('If directions=\"normal\", src cannot be None')\n                _check_src_normal(\"normal\", src)\n                directions = self._get_src_normals(src, use_cps)\n            else:\n                assert directions == \"pca\"\n                x = self.data\n                if not np.isrealobj(self.data):\n                    _check_option(\n                        \"stc.data.dtype\", self.data.dtype, (np.complex64, np.complex128)\n                    )\n                    dtype = np.float32 if x.dtype == np.complex64 else np.float64\n                    x = x.view(dtype)\n                    assert x.shape[-1] == 2 * self.data.shape[-1]\n                u, _, v = np.linalg.svd(x, full_matrices=False)\n                directions = u[:, :, 0]\n                # The sign is arbitrary, so let's flip it in the direction that\n                # makes the resulting time series the most positive:\n                if src is None:\n                    signs = np.sum(v[:, 0].real, axis=1, keepdims=True)\n                else:\n                    normals = self._get_src_normals(src, use_cps)\n                    signs = np.sum(directions * normals, axis=1, keepdims=True)\n                assert signs.shape == (self.data.shape[0], 1)\n                signs = np.sign(signs)\n                signs[signs == 0] = 1.0\n                directions *= signs\n        _check_option(\"directions.shape\", directions.shape, [(self.data.shape[0], 3)])\n        data_norm = np.matmul(directions[:, np.newaxis], self.data)[:, 0]\n        stc = self._scalar_class(\n            data_norm, self.vertices, self.tmin, self.tstep, self.subject\n        )\n        return stc, directions", "metadata": {}}
{"_id": "mne_mne_source_estimate.py_extract_label_time_course_code", "title": "extract_label_time_course", "text": "def extract_label_time_course(\n        self,\n        labels,\n        src,\n        mode=\"auto\",\n        allow_empty=False,\n        *,\n        mri_resolution=True,\n        verbose=None,\n    ):\n        \"\"\"Extract label time courses for lists of labels.\n\n        This function will extract one time course for each label. The way the\n        time courses are extracted depends on the mode parameter.\n\n        Parameters\n        ----------\n        %(labels_eltc)s\n        %(src_eltc)s\n        %(mode_eltc)s\n        %(allow_empty_eltc)s\n        %(mri_resolution_eltc)s\n        %(verbose)s\n\n        Returns\n        -------\n        %(label_tc_el_returns)s\n\n        See Also\n        --------\n        extract_label_time_course : Extract time courses for multiple STCs.\n\n        Notes\n        -----\n        %(eltc_mode_notes)s\n        \"\"\"\n        return extract_label_time_course(\n            self,\n            labels,\n            src,\n            mode=mode,\n            return_generator=False,\n            allow_empty=allow_empty,\n            mri_resolution=mri_resolution,\n            verbose=verbose,\n        )", "metadata": {}}
{"_id": "mne_mne_source_estimate.py_in_label_code", "title": "in_label", "text": "def in_label(self, label, mri, src, *, verbose=None):\n        \"\"\"Get a source estimate object restricted to a label.\n\n        SourceEstimate contains the time course of\n        activation of all sources inside the label.\n\n        Parameters\n        ----------\n        label : str | int\n            The label to use. Can be the name of a label if using a standard\n            FreeSurfer atlas, or an integer value to extract from the ``mri``.\n        mri : str\n            Path to the atlas to use.\n        src : instance of SourceSpaces\n            The volumetric source space. It must be a single, whole-brain\n            volume.\n        %(verbose)s\n\n        Returns\n        -------\n        stc : VolSourceEstimate | VolVectorSourceEstimate\n            The source estimate restricted to the given label.\n\n        Notes\n        -----\n        .. versionadded:: 0.21.0\n        \"\"\"\n        if len(self.vertices) != 1:\n            raise RuntimeError(\n                \"This method can only be used with whole-brain volume source spaces\"\n            )\n        _validate_type(label, (str, \"int-like\"), \"label\")\n        if isinstance(label, str):\n            volume_label = [label]\n        else:\n            volume_label = {f\"Volume ID {label}\": _ensure_int(label)}\n        label = _volume_labels(src, (mri, volume_label), mri_resolution=False)\n        assert len(label) == 1\n        label = label[0]\n        vertices = label.vertices\n        keep = np.isin(self.vertices[0], label.vertices)\n        values, vertices = self.data[keep], [self.vertices[0][keep]]\n        label_stc = self.__class__(\n            values,\n            vertices=vertices,\n            tmin=self.tmin,\n            tstep=self.tstep,\n            subject=self.subject,\n        )\n        return label_stc", "metadata": {}}
{"_id": "mne_mne_source_estimate.py_save_as_volume_code", "title": "save_as_volume", "text": "def save_as_volume(\n        self,\n        fname,\n        src,\n        dest=\"mri\",\n        mri_resolution=False,\n        format=\"nifti1\",  # noqa: A002\n        *,\n        overwrite=False,\n        verbose=None,\n    ):\n        \"\"\"Save a volume source estimate in a NIfTI file.\n\n        Parameters\n        ----------\n        fname : path-like\n            The name of the generated nifti file.\n        src : list\n            The list of source spaces (should all be of type volume).\n        dest : ``'mri'`` | ``'surf'``\n            If ``'mri'`` the volume is defined in the coordinate system of\n            the original T1 image. If ``'surf'`` the coordinate system\n            of the FreeSurfer surface is used (Surface RAS).\n        mri_resolution : bool\n            It True the image is saved in MRI resolution.\n\n            .. warning: If you have many time points the file produced can be\n                        huge. The default is ``mri_resolution=False``.\n        format : str\n            Either ``'nifti1'`` (default) or ``'nifti2'``.\n\n            .. versionadded:: 0.17\n        %(overwrite)s\n\n            .. versionadded:: 1.0\n        %(verbose)s\n\n            .. versionadded:: 1.0\n\n        Returns\n        -------\n        img : instance Nifti1Image\n            The image object.\n\n        Notes\n        -----\n        .. versionadded:: 0.9.0\n        \"\"\"\n        nib = _import_nibabel()\n        fname = _check_fname(fname=fname, overwrite=overwrite)\n        img = self.as_volume(\n            src, dest=dest, mri_resolution=mri_resolution, format=format\n        )\n        nib.save(img, fname)", "metadata": {}}
{"_id": "mne_mne_source_estimate.py_as_volume_code", "title": "as_volume", "text": "def as_volume(\n        self,\n        src,\n        dest=\"mri\",\n        mri_resolution=False,\n        format=\"nifti1\",  # noqa: A002\n    ):\n        \"\"\"Export volume source estimate as a nifti object.\n\n        Parameters\n        ----------\n        src : instance of SourceSpaces\n            The source spaces (should all be of type volume, or part of a\n            mixed source space).\n        dest : ``'mri'`` | ``'surf'``\n            If ``'mri'`` the volume is defined in the coordinate system of\n            the original T1 image. If 'surf' the coordinate system\n            of the FreeSurfer surface is used (Surface RAS).\n        mri_resolution : bool\n            It True the image is saved in MRI resolution.\n\n            .. warning: If you have many time points the file produced can be\n                        huge. The default is ``mri_resolution=False``.\n        format : str\n            Either 'nifti1' (default) or 'nifti2'.\n\n        Returns\n        -------\n        img : instance of Nifti1Image\n            The image object.\n\n        Notes\n        -----\n        .. versionadded:: 0.9.0\n        \"\"\"\n        from .morph import _interpolate_data\n\n        data = self.magnitude() if self._data_ndim == 3 else self\n        return _interpolate_data(\n            data, src, mri_resolution=mri_resolution, mri_space=True, output=format\n        )", "metadata": {}}
{"_id": "mne_mne_source_estimate.py_save_code", "title": "save", "text": "def save(self, fname, ftype=\"stc\", *, overwrite=False, verbose=None):\n        \"\"\"Save the source estimates to a file.\n\n        Parameters\n        ----------\n        fname : path-like\n            The stem of the file name. The stem is extended with ``\"-vl.stc\"``\n            or ``\"-vl.w\"``.\n        ftype : str\n            File format to use. Allowed values are ``\"stc\"`` (default),\n            ``\"w\"``, and ``\"h5\"``. The ``\"w\"`` format only supports a single\n            time point.\n        %(overwrite)s\n\n            .. versionadded:: 1.0\n        %(verbose)s\n        \"\"\"\n        # check overwrite individually below\n        fname = str(_check_fname(fname=fname, overwrite=True))  # checked below\n        _check_option(\"ftype\", ftype, [\"stc\", \"w\", \"h5\"])\n        if ftype != \"h5\" and len(self.vertices) != 1:\n            raise ValueError(\n                \"Can only write to .stc or .w if a single volume \"\n                \"source space was used, use .h5 instead\"\n            )\n        if ftype != \"h5\" and self.data.dtype == \"complex\":\n            raise ValueError(\n                \"Can only write non-complex data to .stc or .w, use .h5 instead\"\n            )\n        if ftype == \"stc\":\n            logger.info(\"Writing STC to disk...\")\n            if not fname.endswith((\"-vl.stc\", \"-vol.stc\")):\n                fname += \"-vl.stc\"\n            fname = str(_check_fname(fname, overwrite=overwrite))\n            _write_stc(\n                fname,\n                tmin=self.tmin,\n                tstep=self.tstep,\n                vertices=self.vertices[0],\n                data=self.data,\n            )\n        elif ftype == \"w\":\n            logger.info(\"Writing STC to disk (w format)...\")\n            if not fname.endswith((\"-vl.w\", \"-vol.w\")):\n                fname += \"-vl.w\"\n            fname = str(_check_fname(fname, overwrite=overwrite))\n            _write_w(fname, vertices=self.vertices[0], data=self.data[:, 0])\n        elif ftype == \"h5\":\n            super().save(fname, \"h5\", overwrite=overwrite)\n        logger.info(\"[done]\")", "metadata": {}}
{"_id": "mne_mne_source_estimate.py_surface_code", "title": "surface", "text": "def surface(self):\n        \"\"\"Return the cortical surface source estimate.\n\n        Returns\n        -------\n        stc : instance of SourceEstimate or VectorSourceEstimate\n            The surface source estimate.\n        \"\"\"\n        if self._data_ndim == 3:\n            klass = VectorSourceEstimate\n        else:\n            klass = SourceEstimate\n        return klass(\n            self.data[: self._n_surf_vert],\n            self.vertices[:2],\n            self.tmin,\n            self.tstep,\n            self.subject,\n        )", "metadata": {}}
{"_id": "mne_mne_source_estimate.py_volume_code", "title": "volume", "text": "def volume(self):\n        \"\"\"Return the volume surface source estimate.\n\n        Returns\n        -------\n        stc : instance of VolSourceEstimate or VolVectorSourceEstimate\n            The volume source estimate.\n        \"\"\"\n        if self._data_ndim == 3:\n            klass = VolVectorSourceEstimate\n        else:\n            klass = VolSourceEstimate\n        return klass(\n            self.data[self._n_surf_vert :],\n            self.vertices[2:],\n            self.tmin,\n            self.tstep,\n            self.subject,\n        )", "metadata": {}}
{"_id": "mne_mne_filter.py_next_fast_len_code", "title": "next_fast_len", "text": "def next_fast_len(target):\n    \"\"\"Find the next fast size of input data to `fft`, for zero-padding, etc.\n\n    SciPy's FFTPACK has efficient functions for radix {2, 3, 4, 5}, so this\n    returns the next composite of the prime factors 2, 3, and 5 which is\n    greater than or equal to `target`. (These are also known as 5-smooth\n    numbers, regular numbers, or Hamming numbers.)\n\n    Parameters\n    ----------\n    target : int\n        Length to start searching from.  Must be a positive integer.\n\n    Returns\n    -------\n    out : int\n        The first 5-smooth number greater than or equal to `target`.\n\n    Notes\n    -----\n    Copied from SciPy with minor modifications.\n    \"\"\"\n    from bisect import bisect_left\n\n    hams = (\n        8,\n        9,\n        10,\n        12,\n        15,\n        16,\n        18,\n        20,\n        24,\n        25,\n        27,\n        30,\n        32,\n        36,\n        40,\n        45,\n        48,\n        50,\n        54,\n        60,\n        64,\n        72,\n        75,\n        80,\n        81,\n        90,\n        96,\n        100,\n        108,\n        120,\n        125,\n        128,\n        135,\n        144,\n        150,\n        160,\n        162,\n        180,\n        192,\n        200,\n        216,\n        225,\n        240,\n        243,\n        250,\n        256,\n        270,\n        288,\n        300,\n        320,\n        324,\n        360,\n        375,\n        384,\n        400,\n        405,\n        432,\n        450,\n        480,\n        486,\n        500,\n        512,\n        540,\n        576,\n        600,\n        625,\n        640,\n        648,\n        675,\n        720,\n        729,\n        750,\n        768,\n        800,\n        810,\n        864,\n        900,\n        960,\n        972,\n        1000,\n        1024,\n        1080,\n        1125,\n        1152,\n        1200,\n        1215,\n        1250,\n        1280,\n        1296,\n        1350,\n        1440,\n        1458,\n        1500,\n        1536,\n        1600,\n        1620,\n        1728,\n        1800,\n        1875,\n        1920,\n        1944,\n        2000,\n        2025,\n        2048,\n        2160,\n        2187,\n        2250,\n        2304,\n        2400,\n        2430,\n        2500,\n        2560,\n        2592,\n        2700,\n        2880,\n        2916,\n        3000,\n        3072,\n        3125,\n        3200,\n        3240,\n        3375,\n        3456,\n        3600,\n        3645,\n        3750,\n        3840,\n        3888,\n        4000,\n        4050,\n        4096,\n        4320,\n        4374,\n        4500,\n        4608,\n        4800,\n        4860,\n        5000,\n        5120,\n        5184,\n        5400,\n        5625,\n        5760,\n        5832,\n        6000,\n        6075,\n        6144,\n        6250,\n        6400,\n        6480,\n        6561,\n        6750,\n        6912,\n        7200,\n        7290,\n        7500,\n        7680,\n        7776,\n        8000,\n        8100,\n        8192,\n        8640,\n        8748,\n        9000,\n        9216,\n        9375,\n        9600,\n        9720,\n        10000,\n    )\n\n    if target <= 6:\n        return target\n\n    # Quickly check if it's already a power of 2\n    if not (target & (target - 1)):\n        return target\n\n    # Get result quickly for small sizes, since FFT itself is similarly fast.\n    if target <= hams[-1]:\n        return hams[bisect_left(hams, target)]\n\n    match = float(\"inf\")  # Anything found will be smaller\n    p5 = 1\n    while p5 < target:\n        p35 = p5\n        while p35 < target:\n            # Ceiling integer division, avoiding conversion to float\n            # (quotient = ceil(target / p35))\n            quotient = -(-target // p35)\n\n            p2 = 2 ** int(quotient - 1).bit_length()\n\n            N = p2 * p35\n            if N == target:\n                return N\n            elif N < match:\n                match = N\n            p35 *= 3\n            if p35 == target:\n                return p35\n        if p35 < match:\n            match = p35\n        p5 *= 5\n        if p5 == target:\n            return p5\n    if p5 < match:\n        match = p5\n    return match", "metadata": {}}
{"_id": "mne_mne_filter.py_estimate_ringing_samples_code", "title": "estimate_ringing_samples", "text": "def estimate_ringing_samples(system, max_try=100000):\n    \"\"\"Estimate filter ringing.\n\n    Parameters\n    ----------\n    system : tuple | ndarray\n        A tuple of (b, a) or ndarray of second-order sections coefficients.\n    max_try : int\n        Approximate maximum number of samples to try.\n        This will be changed to a multiple of 1000.\n\n    Returns\n    -------\n    n : int\n        The approximate ringing.\n    \"\"\"\n    if isinstance(system, tuple):  # TF\n        kind = \"ba\"\n        b, a = system\n        zi = [0.0] * (len(a) - 1)\n    else:\n        kind = \"sos\"\n        sos = system\n        zi = [[0.0] * 2] * len(sos)\n    n_per_chunk = 1000\n    n_chunks_max = int(np.ceil(max_try / float(n_per_chunk)))\n    x = np.zeros(n_per_chunk)\n    x[0] = 1\n    last_good = n_per_chunk\n    thresh_val = 0\n    for ii in range(n_chunks_max):\n        if kind == \"ba\":\n            h, zi = signal.lfilter(b, a, x, zi=zi)\n        else:\n            h, zi = signal.sosfilt(sos, x, zi=zi)\n        x[0] = 0  # for subsequent iterations we want zero input\n        h = np.abs(h)\n        thresh_val = max(0.001 * np.max(h), thresh_val)\n        idx = np.where(np.abs(h) > thresh_val)[0]\n        if len(idx) > 0:\n            last_good = idx[-1]\n        else:  # this iteration had no sufficiently lange values\n            idx = (ii - 1) * n_per_chunk + last_good\n            break\n    else:\n        warn(\"Could not properly estimate ringing for the filter\")\n        idx = n_per_chunk * n_chunks_max\n    return idx", "metadata": {}}
{"_id": "mne_mne_filter.py_construct_iir_filter_code", "title": "construct_iir_filter", "text": "def construct_iir_filter(\n    iir_params,\n    f_pass=None,\n    f_stop=None,\n    sfreq=None,\n    btype=None,\n    return_copy=True,\n    *,\n    phase=\"zero\",\n    verbose=None,\n):\n    \"\"\"Use IIR parameters to get filtering coefficients.\n\n    This function works like a wrapper for iirdesign and iirfilter in\n    scipy.signal to make filter coefficients for IIR filtering. It also\n    estimates the number of padding samples based on the filter ringing.\n    It creates a new iir_params dict (or updates the one passed to the\n    function) with the filter coefficients ('b' and 'a') and an estimate\n    of the padding necessary ('padlen') so IIR filtering can be performed.\n\n    Parameters\n    ----------\n    iir_params : dict\n        Dictionary of parameters to use for IIR filtering.\n\n            * If ``iir_params['sos']`` exists, it will be used as\n              second-order sections to perform IIR filtering.\n\n              .. versionadded:: 0.13\n\n            * Otherwise, if ``iir_params['b']`` and ``iir_params['a']``\n              exist, these will be used as coefficients to perform IIR\n              filtering.\n            * Otherwise, if ``iir_params['order']`` and\n              ``iir_params['ftype']`` exist, these will be used with\n              `scipy.signal.iirfilter` to make a filter.\n              You should also supply ``iir_params['rs']`` and\n              ``iir_params['rp']`` if using elliptic or Chebychev filters.\n            * Otherwise, if ``iir_params['gpass']`` and\n              ``iir_params['gstop']`` exist, these will be used with\n              `scipy.signal.iirdesign` to design a filter.\n            * ``iir_params['padlen']`` defines the number of samples to pad\n              (and an estimate will be calculated if it is not given).\n              See Notes for more details.\n            * ``iir_params['output']`` defines the system output kind when\n              designing filters, either \"sos\" or \"ba\". For 0.13 the\n              default is 'ba' but will change to 'sos' in 0.14.\n\n    f_pass : float or list of float\n        Frequency for the pass-band. Low-pass and high-pass filters should\n        be a float, band-pass should be a 2-element list of float.\n    f_stop : float or list of float\n        Stop-band frequency (same size as f_pass). Not used if 'order' is\n        specified in iir_params.\n    sfreq : float | None\n        The sample rate.\n    btype : str\n        Type of filter. Should be 'lowpass', 'highpass', or 'bandpass'\n        (or analogous string representations known to\n        :func:`scipy.signal.iirfilter`).\n    return_copy : bool\n        If False, the 'sos', 'b', 'a', and 'padlen' entries in\n        ``iir_params`` will be set inplace (if they weren't already).\n        Otherwise, a new ``iir_params`` instance will be created and\n        returned with these entries.\n    phase : str\n        Phase of the filter.\n        ``phase='zero'`` (default) or equivalently ``'zero-double'`` constructs and\n        applies IIR filter twice, once forward, and once backward (making it non-causal)\n        using :func:`~scipy.signal.filtfilt`; ``phase='forward'`` will apply\n        the filter once in the forward (causal) direction using\n        :func:`~scipy.signal.lfilter`.\n\n        .. versionadded:: 0.13\n    %(verbose)s\n\n    Returns\n    -------\n    iir_params : dict\n        Updated iir_params dict, with the entries (set only if they didn't\n        exist before) for 'sos' (or 'b', 'a'), and 'padlen' for\n        IIR filtering.\n\n    See Also\n    --------\n    mne.filter.filter_data\n    mne.io.Raw.filter\n\n    Notes\n    -----\n    This function triages calls to :func:`scipy.signal.iirfilter` and\n    :func:`scipy.signal.iirdesign` based on the input arguments (see\n    linked functions for more details).\n\n    .. versionchanged:: 0.14\n       Second-order sections are used in filter design by default (replacing\n       ``output='ba'`` by ``output='sos'``) to help ensure filter stability\n       and reduce numerical error.\n\n    Examples\n    --------\n    iir_params can have several forms. Consider constructing a low-pass\n    filter at 40 Hz with 1000 Hz sampling rate.\n\n    In the most basic (2-parameter) form of iir_params, the order of the\n    filter 'N' and the type of filtering 'ftype' are specified. To get\n    coefficients for a 4th-order Butterworth filter, this would be:\n\n    >>> iir_params = dict(order=4, ftype='butter', output='sos')  # doctest:+SKIP\n    >>> iir_params = construct_iir_filter(iir_params, 40, None, 1000, 'low', return_copy=False)  # doctest:+SKIP\n    >>> print((2 * len(iir_params['sos']), iir_params['padlen']))  # doctest:+SKIP\n    (4, 82)\n\n    Filters can also be constructed using filter design methods. To get a\n    40 Hz Chebyshev type 1 lowpass with specific gain characteristics in the\n    pass and stop bands (assuming the desired stop band is at 45 Hz), this\n    would be a filter with much longer ringing:\n\n    >>> iir_params = dict(ftype='cheby1', gpass=3, gstop=20, output='sos')  # doctest:+SKIP\n    >>> iir_params = construct_iir_filter(iir_params, 40, 50, 1000, 'low')  # doctest:+SKIP\n    >>> print((2 * len(iir_params['sos']), iir_params['padlen']))  # doctest:+SKIP\n    (6, 439)\n\n    Padding and/or filter coefficients can also be manually specified. For\n    a 10-sample moving window with no padding during filtering, for example,\n    one can just do:\n\n    >>> iir_params = dict(b=np.ones((10)), a=[1, 0], padlen=0)  # doctest:+SKIP\n    >>> iir_params = construct_iir_filter(iir_params, return_copy=False)  # doctest:+SKIP\n    >>> print((iir_params['b'], iir_params['a'], iir_params['padlen']))  # doctest:+SKIP\n    (array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), [1, 0], 0)\n\n    For more information, see the tutorials\n    :ref:`disc-filtering` and :ref:`tut-filter-resample`.\n    \"\"\"  # noqa: E501\n    known_filters = (\n        \"bessel\",\n        \"butter\",\n        \"butterworth\",\n        \"cauer\",\n        \"cheby1\",\n        \"cheby2\",\n        \"chebyshev1\",\n        \"chebyshev2\",\n        \"chebyshevi\",\n        \"chebyshevii\",\n        \"ellip\",\n        \"elliptic\",\n    )\n    if not isinstance(iir_params, dict):\n        raise TypeError(f\"iir_params must be a dict, got {type(iir_params)}\")\n    # if the filter has been designed, we're good to go\n    Wp = None\n    if \"sos\" in iir_params:\n        system = iir_params[\"sos\"]\n        output = \"sos\"\n    elif \"a\" in iir_params and \"b\" in iir_params:\n        system = (iir_params[\"b\"], iir_params[\"a\"])\n        output = \"ba\"\n    else:\n        output = iir_params.get(\"output\", \"sos\")\n        _check_option(\"output\", output, (\"ba\", \"sos\"))\n        # ensure we have a valid ftype\n        if \"ftype\" not in iir_params:\n            raise RuntimeError(\n                \"ftype must be an entry in iir_params if 'b' and 'a' are not specified.\"\n            )\n        ftype = iir_params[\"ftype\"]\n        if ftype not in known_filters:\n            raise RuntimeError(\n                \"ftype must be in filter_dict from scipy.signal (e.g., butter, cheby1, \"\n                f\"etc.) not {ftype}\"\n            )\n\n        # use order-based design\n        f_pass = np.atleast_1d(f_pass)\n        if f_pass.ndim > 1:\n            raise ValueError(f\"frequencies must be 1D, got {f_pass.ndim}D\")\n        edge_freqs = \", \".join(f\"{f:0.2f}\" for f in f_pass)\n        Wp = f_pass / (float(sfreq) / 2)\n        # IT will de designed\n        ftype_nice = _ftype_dict.get(ftype, ftype)\n        _validate_type(phase, str, \"phase\")\n        _check_option(\"phase\", phase, (\"zero\", \"zero-double\", \"forward\"))\n        if phase in (\"zero-double\", \"zero\"):\n            ptype = \"zero-phase (two-pass forward and reverse) non-causal\"\n        else:\n            ptype = \"non-linear phase (one-pass forward) causal\"\n        logger.info(\"\")\n        logger.info(\"IIR filter parameters\")\n        logger.info(\"---------------------\")\n        logger.info(f\"{ftype_nice} {btype} {ptype} filter:\")\n        # SciPy designs forward for -3dB, so forward-backward is -6dB\n        if \"order\" in iir_params:\n            singleton = btype in (\"low\", \"lowpass\", \"high\", \"highpass\")\n            use_Wp = Wp.item() if singleton else Wp\n            kwargs = dict(\n                N=iir_params[\"order\"],\n                Wn=use_Wp,\n                btype=btype,\n                ftype=ftype,\n                output=output,\n            )\n            for key in (\"rp\", \"rs\"):\n                if key in iir_params:\n                    kwargs[key] = iir_params[key]\n            system = signal.iirfilter(**kwargs)\n            if phase in (\"zero\", \"zero-double\"):\n                ptype, pmul = \"(effective, after forward-backward)\", 2\n            else:\n                ptype, pmul = \"(forward)\", 1\n            logger.info(\n                \"- Filter order %d %s\", pmul * iir_params[\"order\"] * len(Wp), ptype\n            )\n        else:\n            # use gpass / gstop design\n            Ws = np.asanyarray(f_stop) / (float(sfreq) / 2)\n            if \"gpass\" not in iir_params or \"gstop\" not in iir_params:\n                raise ValueError(\n                    \"iir_params must have at least 'gstop' and 'gpass' (or N) entries.\"\n                )\n            system = signal.iirdesign(\n                Wp,\n                Ws,\n                iir_params[\"gpass\"],\n                iir_params[\"gstop\"],\n                ftype=ftype,\n                output=output,\n            )\n\n    if system is None:\n        raise RuntimeError(\"coefficients could not be created from iir_params\")\n    # do some sanity checks\n    _check_coefficients(system)\n\n    # get the gains at the cutoff frequencies\n    if Wp is not None:\n        if output == \"sos\":\n            cutoffs = signal.sosfreqz(system, worN=Wp * np.pi)[1]\n        else:\n            cutoffs = signal.freqz(system[0], system[1], worN=Wp * np.pi)[1]\n        cutoffs = 20 * np.log10(np.abs(cutoffs))\n        # 2 * 20 here because we do forward-backward filtering\n        if phase in (\"zero\", \"zero-double\"):\n            cutoffs *= 2\n        cutoffs = \", \".join([f\"{c:0.2f}\" for c in cutoffs])\n        logger.info(f\"- Cutoff{_pl(f_pass)} at {edge_freqs} Hz: {cutoffs} dB\")\n    # now deal with padding\n    if \"padlen\" not in iir_params:\n        padlen = estimate_ringing_samples(system)\n    else:\n        padlen = iir_params[\"padlen\"]\n\n    if return_copy:\n        iir_params = deepcopy(iir_params)\n\n    iir_params.update(dict(padlen=padlen))\n    if output == \"sos\":\n        iir_params.update(sos=system)\n    else:\n        iir_params.update(b=system[0], a=system[1])\n    logger.info(\"\")\n    return iir_params", "metadata": {}}
{"_id": "mne_mne_filter.py_filter_data_code", "title": "filter_data", "text": "def filter_data(\n    data,\n    sfreq,\n    l_freq,\n    h_freq,\n    picks=None,\n    filter_length=\"auto\",\n    l_trans_bandwidth=\"auto\",\n    h_trans_bandwidth=\"auto\",\n    n_jobs=None,\n    method=\"fir\",\n    iir_params=None,\n    copy=True,\n    phase=\"zero\",\n    fir_window=\"hamming\",\n    fir_design=\"firwin\",\n    pad=\"reflect_limited\",\n    *,\n    verbose=None,\n):\n    \"\"\"Filter a subset of channels.\n\n    Parameters\n    ----------\n    data : ndarray, shape (..., n_times)\n        The data to filter.\n    sfreq : float\n        The sample frequency in Hz.\n    %(l_freq)s\n    %(h_freq)s\n    %(picks_nostr)s\n        Currently this is only supported for 2D (n_channels, n_times) and\n        3D (n_epochs, n_channels, n_times) arrays.\n    %(filter_length)s\n    %(l_trans_bandwidth)s\n    %(h_trans_bandwidth)s\n    %(n_jobs_fir)s\n    %(method_fir)s\n    %(iir_params)s\n    copy : bool\n        If True, a copy of x, filtered, is returned. Otherwise, it operates\n        on x in place.\n    %(phase)s\n    %(fir_window)s\n    %(fir_design)s\n    %(pad_fir)s\n        The default is ``'reflect_limited'``.\n\n        .. versionadded:: 0.15\n    %(verbose)s\n\n    Returns\n    -------\n    data : ndarray, shape (..., n_times)\n        The filtered data.\n\n    See Also\n    --------\n    construct_iir_filter\n    create_filter\n    mne.io.Raw.filter\n    notch_filter\n    resample\n\n    Notes\n    -----\n    Applies a zero-phase low-pass, high-pass, band-pass, or band-stop\n    filter to the channels selected by ``picks``.\n\n    ``l_freq`` and ``h_freq`` are the frequencies below which and above\n    which, respectively, to filter out of the data. Thus the uses are:\n\n        * ``l_freq < h_freq``: band-pass filter\n        * ``l_freq > h_freq``: band-stop filter\n        * ``l_freq is not None and h_freq is None``: high-pass filter\n        * ``l_freq is None and h_freq is not None``: low-pass filter\n\n    .. note:: If n_jobs > 1, more memory is required as\n              ``len(picks) * n_times`` additional time points need to\n              be temporarily stored in memory.\n\n    For more information, see the tutorials\n    :ref:`disc-filtering` and :ref:`tut-filter-resample` and\n    :func:`mne.filter.create_filter`.\n    \"\"\"\n    data = _check_filterable(data)\n    iir_params, method = _check_method(method, iir_params)\n    filt = create_filter(\n        data,\n        sfreq,\n        l_freq,\n        h_freq,\n        filter_length,\n        l_trans_bandwidth,\n        h_trans_bandwidth,\n        method,\n        iir_params,\n        phase,\n        fir_window,\n        fir_design,\n    )\n    if method in (\"fir\", \"fft\"):\n        data = _overlap_add_filter(data, filt, None, phase, picks, n_jobs, copy, pad)\n    else:\n        data = _iir_filter(data, filt, picks, n_jobs, copy, phase)\n    return data", "metadata": {}}
{"_id": "mne_mne_filter.py_create_filter_code", "title": "create_filter", "text": "def create_filter(\n    data,\n    sfreq,\n    l_freq,\n    h_freq,\n    filter_length=\"auto\",\n    l_trans_bandwidth=\"auto\",\n    h_trans_bandwidth=\"auto\",\n    method=\"fir\",\n    iir_params=None,\n    phase=\"zero\",\n    fir_window=\"hamming\",\n    fir_design=\"firwin\",\n    verbose=None,\n):\n    r\"\"\"Create a FIR or IIR filter.\n\n    ``l_freq`` and ``h_freq`` are the frequencies below which and above\n    which, respectively, to filter out of the data. Thus the uses are:\n\n        * ``l_freq < h_freq``: band-pass filter\n        * ``l_freq > h_freq``: band-stop filter\n        * ``l_freq is not None and h_freq is None``: high-pass filter\n        * ``l_freq is None and h_freq is not None``: low-pass filter\n\n    Parameters\n    ----------\n    data : ndarray, shape (..., n_times) | None\n        The data that will be filtered. This is used for sanity checking\n        only. If None, no sanity checking related to the length of the signal\n        relative to the filter order will be performed.\n    sfreq : float\n        The sample frequency in Hz.\n    %(l_freq)s\n    %(h_freq)s\n    %(filter_length)s\n    %(l_trans_bandwidth)s\n    %(h_trans_bandwidth)s\n    %(method_fir)s\n    %(iir_params)s\n    %(phase)s\n    %(fir_window)s\n    %(fir_design)s\n    %(verbose)s\n\n    Returns\n    -------\n    filt : array or dict\n        Will be an array of FIR coefficients for method='fir', and dict\n        with IIR parameters for method='iir'.\n\n    See Also\n    --------\n    filter_data\n\n    Notes\n    -----\n    .. note:: For FIR filters, the *cutoff frequency*, i.e. the -6 dB point,\n              is in the middle of the transition band (when using phase='zero'\n              and fir_design='firwin'). For IIR filters, the cutoff frequency\n              is given by ``l_freq`` or ``h_freq`` directly, and\n              ``l_trans_bandwidth`` and ``h_trans_bandwidth`` are ignored.\n\n    **Band-pass filter**\n\n    The frequency response is (approximately) given by::\n\n       1-|               ----------\n         |             /|         | \\\n     |H| |            / |         |  \\\n         |           /  |         |   \\\n         |          /   |         |    \\\n       0-|----------    |         |     --------------\n         |         |    |         |     |            |\n         0        Fs1  Fp1       Fp2   Fs2          Nyq\n\n    Where:\n\n        * Fs1 = Fp1 - l_trans_bandwidth in Hz\n        * Fs2 = Fp2 + h_trans_bandwidth in Hz\n\n    **Band-stop filter**\n\n    The frequency response is (approximately) given by::\n\n        1-|---------                   ----------\n          |         \\                 /\n      |H| |          \\               /\n          |           \\             /\n          |            \\           /\n        0-|             -----------\n          |        |    |         |    |        |\n          0       Fp1  Fs1       Fs2  Fp2      Nyq\n\n    Where ``Fs1 = Fp1 + l_trans_bandwidth`` and\n    ``Fs2 = Fp2 - h_trans_bandwidth``.\n\n    Multiple stop bands can be specified using arrays.\n\n    **Low-pass filter**\n\n    The frequency response is (approximately) given by::\n\n        1-|------------------------\n          |                        \\\n      |H| |                         \\\n          |                          \\\n          |                           \\\n        0-|                            ----------------\n          |                       |    |              |\n          0                      Fp  Fstop           Nyq\n\n    Where ``Fstop = Fp + trans_bandwidth``.\n\n    **High-pass filter**\n\n    The frequency response is (approximately) given by::\n\n        1-|             -----------------------\n          |            /\n      |H| |           /\n          |          /\n          |         /\n        0-|---------\n          |        |    |                     |\n          0      Fstop  Fp                   Nyq\n\n    Where ``Fstop = Fp - trans_bandwidth``.\n\n    .. versionadded:: 0.14\n    \"\"\"\n    sfreq = float(sfreq)\n    if sfreq < 0:\n        raise ValueError(\"sfreq must be positive\")\n    # If no data specified, sanity checking will be skipped\n    if data is None:\n        logger.info(\n            \"No data specified. Sanity checks related to the length of the signal \"\n            \"relative to the filter order will be skipped.\"\n        )\n    if h_freq is not None:\n        h_freq = np.array(h_freq, float).ravel()\n        if (h_freq > (sfreq / 2.0)).any():\n            raise ValueError(\n                f\"h_freq ({h_freq}) must be less than the Nyquist frequency \"\n                f\"{sfreq / 2.0}\"\n            )\n    if l_freq is not None:\n        l_freq = np.array(l_freq, float).ravel()\n        if (l_freq == 0).all():\n            l_freq = None\n    iir_params, method = _check_method(method, iir_params)\n    if l_freq is None and h_freq is None:\n        (\n            data,\n            sfreq,\n            _,\n            _,\n            _,\n            _,\n            filter_length,\n            phase,\n            fir_window,\n            fir_design,\n        ) = _triage_filter_params(\n            data,\n            sfreq,\n            None,\n            None,\n            None,\n            None,\n            filter_length,\n            method,\n            phase,\n            fir_window,\n            fir_design,\n        )\n        if method == \"iir\":\n            out = dict() if iir_params is None else deepcopy(iir_params)\n            out.update(b=np.array([1.0]), a=np.array([1.0]))\n        else:\n            freq = [0, sfreq / 2.0]\n            gain = [1.0, 1.0]\n    if l_freq is None and h_freq is not None:\n        h_freq = h_freq.item()\n        logger.info(f\"Setting up low-pass filter at {h_freq:0.2g} Hz\")\n        (\n            data,\n            sfreq,\n            _,\n            f_p,\n            _,\n            f_s,\n            filter_length,\n            phase,\n            fir_window,\n            fir_design,\n        ) = _triage_filter_params(\n            data,\n            sfreq,\n            None,\n            h_freq,\n            None,\n            h_trans_bandwidth,\n            filter_length,\n            method,\n            phase,\n            fir_window,\n            fir_design,\n        )\n        if method == \"iir\":\n            out = construct_iir_filter(\n                iir_params, f_p, f_s, sfreq, \"lowpass\", phase=phase\n            )\n        else:  # 'fir'\n            freq = [0, f_p, f_s]\n            gain = [1, 1, 0]\n            if f_s != sfreq / 2.0:\n                freq += [sfreq / 2.0]\n                gain += [0]\n    elif l_freq is not None and h_freq is None:\n        l_freq = l_freq.item()\n        logger.info(f\"Setting up high-pass filter at {l_freq:0.2g} Hz\")\n        (\n            data,\n            sfreq,\n            pass_,\n            _,\n            stop,\n            _,\n            filter_length,\n            phase,\n            fir_window,\n            fir_design,\n        ) = _triage_filter_params(\n            data,\n            sfreq,\n            l_freq,\n            None,\n            l_trans_bandwidth,\n            None,\n            filter_length,\n            method,\n            phase,\n            fir_window,\n            fir_design,\n        )\n        if method == \"iir\":\n            out = construct_iir_filter(\n                iir_params, pass_, stop, sfreq, \"highpass\", phase=phase\n            )\n        else:  # 'fir'\n            freq = [stop, pass_, sfreq / 2.0]\n            gain = [0, 1, 1]\n            if stop != 0:\n                freq = [0] + freq\n                gain = [0] + gain\n    elif l_freq is not None and h_freq is not None:\n        if (l_freq < h_freq).any():\n            l_freq, h_freq = l_freq.item(), h_freq.item()\n            logger.info(\n                f\"Setting up band-pass filter from {l_freq:0.2g} - {h_freq:0.2g} Hz\"\n            )\n            (\n                data,\n                sfreq,\n                f_p1,\n                f_p2,\n                f_s1,\n                f_s2,\n                filter_length,\n                phase,\n                fir_window,\n                fir_design,\n            ) = _triage_filter_params(\n                data,\n                sfreq,\n                l_freq,\n                h_freq,\n                l_trans_bandwidth,\n                h_trans_bandwidth,\n                filter_length,\n                method,\n                phase,\n                fir_window,\n                fir_design,\n            )\n            if method == \"iir\":\n                out = construct_iir_filter(\n                    iir_params,\n                    [f_p1, f_p2],\n                    [f_s1, f_s2],\n                    sfreq,\n                    \"bandpass\",\n                    phase=phase,\n                )\n            else:  # 'fir'\n                freq = [f_s1, f_p1, f_p2, f_s2]\n                gain = [0, 1, 1, 0]\n                if f_s2 != sfreq / 2.0:\n                    freq += [sfreq / 2.0]\n                    gain += [0]\n                if f_s1 != 0:\n                    freq = [0] + freq\n                    gain = [0] + gain\n        else:\n            # This could possibly be removed after 0.14 release, but might\n            # as well leave it in to sanity check notch_filter\n            if len(l_freq) != len(h_freq):\n                raise ValueError(\"l_freq and h_freq must be the same length\")\n            msg = \"Setting up band-stop filter\"\n            if len(l_freq) == 1:\n                l_freq, h_freq = l_freq.item(), h_freq.item()\n                msg += f\" from {h_freq:0.2g} - {l_freq:0.2g} Hz\"\n            logger.info(msg)\n            # Note: order of outputs is intentionally switched here!\n            (\n                data,\n                sfreq,\n                f_s1,\n                f_s2,\n                f_p1,\n                f_p2,\n                filter_length,\n                phase,\n                fir_window,\n                fir_design,\n            ) = _triage_filter_params(\n                data,\n                sfreq,\n                h_freq,\n                l_freq,\n                h_trans_bandwidth,\n                l_trans_bandwidth,\n                filter_length,\n                method,\n                phase,\n                fir_window,\n                fir_design,\n                bands=\"arr\",\n                reverse=True,\n            )\n            if method == \"iir\":\n                if len(f_p1) != 1:\n                    raise ValueError(\n                        \"Multiple stop-bands can only be used with method='fir' \"\n                        \"and method='spectrum_fit'\"\n                    )\n                out = construct_iir_filter(\n                    iir_params,\n                    [f_p1[0], f_p2[0]],\n                    [f_s1[0], f_s2[0]],\n                    sfreq,\n                    \"bandstop\",\n                    phase=phase,\n                )\n            else:  # 'fir'\n                freq = np.r_[f_p1, f_s1, f_s2, f_p2]\n                gain = np.r_[\n                    np.ones_like(f_p1),\n                    np.zeros_like(f_s1),\n                    np.zeros_like(f_s2),\n                    np.ones_like(f_p2),\n                ]\n                order = np.argsort(freq)\n                freq = freq[order]\n                gain = gain[order]\n                if freq[0] != 0:\n                    freq = np.r_[[0.0], freq]\n                    gain = np.r_[[1.0], gain]\n                if freq[-1] != sfreq / 2.0:\n                    freq = np.r_[freq, [sfreq / 2.0]]\n                    gain = np.r_[gain, [1.0]]\n                if np.any(np.abs(np.diff(gain, 2)) > 1):\n                    raise ValueError(\"Stop bands are not sufficiently separated.\")\n    if method == \"fir\":\n        out = _construct_fir_filter(\n            sfreq, freq, gain, filter_length, phase, fir_window, fir_design\n        )\n    return out", "metadata": {}}
{"_id": "mne_mne_filter.py_notch_filter_code", "title": "notch_filter", "text": "def notch_filter(\n    x,\n    Fs,\n    freqs,\n    filter_length=\"auto\",\n    notch_widths=None,\n    trans_bandwidth=1,\n    method=\"fir\",\n    iir_params=None,\n    mt_bandwidth=None,\n    p_value=0.05,\n    picks=None,\n    n_jobs=None,\n    copy=True,\n    phase=\"zero\",\n    fir_window=\"hamming\",\n    fir_design=\"firwin\",\n    pad=\"reflect_limited\",\n    *,\n    verbose=None,\n):\n    r\"\"\"Notch filter for the signal x.\n\n    Applies a zero-phase notch filter to the signal x, operating on the last\n    dimension.\n\n    Parameters\n    ----------\n    x : array\n        Signal to filter.\n    Fs : float\n        Sampling rate in Hz.\n    freqs : float | array of float | None\n        Frequencies to notch filter in Hz, e.g. np.arange(60, 241, 60).\n        Multiple stop-bands can only be used with method='fir'\n        and method='spectrum_fit'. None can only be used with the mode\n        'spectrum_fit', where an F test is used to find sinusoidal components.\n    %(filter_length_notch)s\n    notch_widths : float | array of float | None\n        Width of the stop band (centred at each freq in freqs) in Hz.\n        If None, freqs / 200 is used.\n    trans_bandwidth : float\n        Width of the transition band in Hz.\n        Only used for ``method='fir'`` and ``method='iir'``.\n    %(method_fir)s\n        'spectrum_fit' will use multi-taper estimation of sinusoidal\n        components. If freqs=None and method='spectrum_fit', significant\n        sinusoidal components are detected using an F test, and noted by\n        logging.\n    %(iir_params)s\n    mt_bandwidth : float | None\n        The bandwidth of the multitaper windowing function in Hz.\n        Only used in 'spectrum_fit' mode.\n    p_value : float\n        P-value to use in F-test thresholding to determine significant\n        sinusoidal components to remove when method='spectrum_fit' and\n        freqs=None. Note that this will be Bonferroni corrected for the\n        number of frequencies, so large p-values may be justified.\n    %(picks_nostr)s\n        Only supported for 2D (n_channels, n_times) and 3D\n        (n_epochs, n_channels, n_times) data.\n    %(n_jobs_fir)s\n    copy : bool\n        If True, a copy of x, filtered, is returned. Otherwise, it operates\n        on x in place.\n    %(phase)s\n    %(fir_window)s\n    %(fir_design)s\n    %(pad_fir)s\n        The default is ``'reflect_limited'``.\n    %(verbose)s\n\n    Returns\n    -------\n    xf : array\n        The x array filtered.\n\n    See Also\n    --------\n    filter_data\n    resample\n\n    Notes\n    -----\n    The frequency response is (approximately) given by::\n\n        1-|----------         -----------\n          |          \\       /\n      |H| |           \\     /\n          |            \\   /\n          |             \\ /\n        0-|              -\n          |         |    |    |         |\n          0        Fp1 freq  Fp2       Nyq\n\n    For each freq in freqs, where ``Fp1 = freq - trans_bandwidth / 2`` and\n    ``Fs2 = freq + trans_bandwidth / 2``.\n\n    References\n    ----------\n    Multi-taper removal is inspired by code from the Chronux toolbox, see\n    www.chronux.org and the book \"Observed Brain Dynamics\" by Partha Mitra\n    & Hemant Bokil, Oxford University Press, New York, 2008. Please\n    cite this in publications if method 'spectrum_fit' is used.\n    \"\"\"\n    x = _check_filterable(x, \"notch filtered\", \"notch_filter\")\n    iir_params, method = _check_method(method, iir_params, [\"spectrum_fit\"])\n\n    if freqs is not None:\n        freqs = np.atleast_1d(freqs)\n    elif method != \"spectrum_fit\":\n        raise ValueError(\"freqs=None can only be used with method spectrum_fit\")\n\n    # Only have to deal with notch_widths for non-autodetect\n    if freqs is not None:\n        if notch_widths is None:\n            notch_widths = freqs / 200.0\n        elif np.any(notch_widths < 0):\n            raise ValueError(\"notch_widths must be >= 0\")\n        else:\n            notch_widths = np.atleast_1d(notch_widths)\n            if len(notch_widths) == 1:\n                notch_widths = notch_widths[0] * np.ones_like(freqs)\n            elif len(notch_widths) != len(freqs):\n                raise ValueError(\n                    \"notch_widths must be None, scalar, or the same length as freqs\"\n                )\n\n    if method in (\"fir\", \"iir\"):\n        # Speed this up by computing the fourier coefficients once\n        tb_2 = trans_bandwidth / 2.0\n        lows = [freq - nw / 2.0 - tb_2 for freq, nw in zip(freqs, notch_widths)]\n        highs = [freq + nw / 2.0 + tb_2 for freq, nw in zip(freqs, notch_widths)]\n        xf = filter_data(\n            x,\n            Fs,\n            highs,\n            lows,\n            picks,\n            filter_length,\n            tb_2,\n            tb_2,\n            n_jobs,\n            method,\n            iir_params,\n            copy,\n            phase,\n            fir_window,\n            fir_design,\n            pad=pad,\n        )\n    elif method == \"spectrum_fit\":\n        xf = _mt_spectrum_proc(\n            x,\n            Fs,\n            freqs,\n            notch_widths,\n            mt_bandwidth,\n            p_value,\n            picks,\n            n_jobs,\n            copy,\n            filter_length,\n        )\n\n    return xf", "metadata": {}}
{"_id": "mne_mne_filter.py_resample_code", "title": "resample", "text": "def resample(\n    x,\n    up=1.0,\n    down=1.0,\n    *,\n    axis=-1,\n    window=\"auto\",\n    n_jobs=None,\n    pad=\"auto\",\n    npad=100,\n    method=\"fft\",\n    verbose=None,\n):\n    \"\"\"Resample an array.\n\n    Operates along the last dimension of the array.\n\n    Parameters\n    ----------\n    x : ndarray\n        Signal to resample.\n    up : float\n        Factor to upsample by.\n    down : float\n        Factor to downsample by.\n    axis : int\n        Axis along which to resample (default is the last axis).\n    %(window_resample)s\n    %(n_jobs_cuda)s\n        ``n_jobs='cuda'`` is only supported when ``method=\"fft\"``.\n    %(pad_resample_auto)s\n\n        .. versionadded:: 0.15\n    %(npad_resample)s\n    %(method_resample)s\n\n        .. versionadded:: 1.7\n    %(verbose)s\n\n    Returns\n    -------\n    y : array\n        The x array resampled.\n\n    Notes\n    -----\n    When using ``method=\"fft\"`` (default),\n    this uses (hopefully) intelligent edge padding and frequency-domain\n    windowing improve :func:`scipy.signal.resample`'s resampling method, which\n    we have adapted for our use here. Choices of npad and window have\n    important consequences, and the default choices should work well\n    for most natural signals.\n    \"\"\"\n    _validate_type(method, str, \"method\")\n    _validate_type(pad, str, \"pad\")\n    _check_option(\"method\", method, (\"fft\", \"polyphase\"))\n\n    # make sure our arithmetic will work\n    x = _check_filterable(x, \"resampled\", \"resample\")\n    ratio, final_len = _resamp_ratio_len(up, down, x.shape[axis])\n    del up, down\n    if axis < 0:\n        axis = x.ndim + axis\n    if x.shape[axis] == 0:\n        warn(f\"x has zero length along axis={axis}, returning a copy of x\")\n        return x.copy()\n\n    # prep for resampling along the last axis (swap axis with last then reshape)\n    out_shape = list(x.shape)\n    out_shape.pop(axis)\n    out_shape.append(final_len)\n    x = np.atleast_2d(x.swapaxes(axis, -1).reshape((-1, x.shape[axis])))\n\n    # do the resampling using FFT or polyphase methods\n    kwargs = dict(pad=pad, window=window, n_jobs=n_jobs)\n    if method == \"fft\":\n        y = _resample_fft(x, npad=npad, ratio=ratio, final_len=final_len, **kwargs)\n    else:\n        up, down, kwargs[\"window\"] = _prep_polyphase(\n            ratio, x.shape[-1], final_len, window\n        )\n        half_len = len(window) // 2\n        logger.info(\n            f\"Polyphase resampling neighborhood: \u00b1{half_len} \"\n            f\"input sample{_pl(half_len)}\"\n        )\n        y = _resample_polyphase(x, up=up, down=down, **kwargs)\n    assert y.shape[-1] == final_len\n\n    # restore dimensions (reshape then swap axis with last)\n    y = y.reshape(out_shape).swapaxes(axis, -1)\n\n    return y", "metadata": {}}
{"_id": "mne_mne_filter.py_detrend_code", "title": "detrend", "text": "def detrend(x, order=1, axis=-1):\n    \"\"\"Detrend the array x.\n\n    Parameters\n    ----------\n    x : n-d array\n        Signal to detrend.\n    order : int\n        Fit order. Currently must be '0' or '1'.\n    axis : int\n        Axis of the array to operate on.\n\n    Returns\n    -------\n    y : array\n        The x array detrended.\n\n    Examples\n    --------\n    As in :func:`scipy.signal.detrend`::\n\n        >>> randgen = np.random.RandomState(9)\n        >>> npoints = int(1e3)\n        >>> noise = randgen.randn(npoints)\n        >>> x = 3 + 2*np.linspace(0, 1, npoints) + noise\n        >>> bool((detrend(x) - noise).max() < 0.01)\n        True\n    \"\"\"\n    if axis > len(x.shape):\n        raise ValueError(f\"x does not have {axis} axes\")\n    if order == 0:\n        fit = \"constant\"\n    elif order == 1:\n        fit = \"linear\"\n    else:\n        raise ValueError(\"order must be 0 or 1\")\n\n    y = signal.detrend(x, axis=axis, type=fit)\n\n    return y", "metadata": {}}
{"_id": "mne_mne_filter.py_design_mne_c_filter_code", "title": "design_mne_c_filter", "text": "def design_mne_c_filter(\n    sfreq,\n    l_freq=None,\n    h_freq=40.0,\n    l_trans_bandwidth=None,\n    h_trans_bandwidth=5.0,\n    verbose=None,\n):\n    \"\"\"Create a FIR filter like that used by MNE-C.\n\n    Parameters\n    ----------\n    sfreq : float\n        The sample frequency.\n    l_freq : float | None\n        The low filter frequency in Hz, default None.\n        Can be None to avoid high-passing.\n    h_freq : float\n        The high filter frequency in Hz, default 40.\n        Can be None to avoid low-passing.\n    l_trans_bandwidth : float | None\n        Low transition bandwidthin Hz. Can be None (default) to use 3 samples.\n    h_trans_bandwidth : float\n        High transition bandwidth in Hz.\n    %(verbose)s\n\n    Returns\n    -------\n    h : ndarray, shape (8193,)\n        The linear-phase (symmetric) FIR filter coefficients.\n\n    Notes\n    -----\n    This function is provided mostly for reference purposes.\n\n    MNE-C uses a frequency-domain filter design technique by creating a\n    linear-phase filter of length 8193. In the frequency domain, the\n    4197 frequencies are directly constructed, with zeroes in the stop-band\n    and ones in the passband, with squared cosine ramps in between.\n    \"\"\"\n    n_freqs = (4096 + 2 * 2048) // 2 + 1\n    freq_resp = np.ones(n_freqs)\n    l_freq = 0 if l_freq is None else float(l_freq)\n    if l_trans_bandwidth is None:\n        l_width = 3\n    else:\n        l_width = (int(((n_freqs - 1) * l_trans_bandwidth) / (0.5 * sfreq)) + 1) // 2\n    l_start = int(((n_freqs - 1) * l_freq) / (0.5 * sfreq))\n    h_freq = sfreq / 2.0 if h_freq is None else float(h_freq)\n    h_width = (int(((n_freqs - 1) * h_trans_bandwidth) / (0.5 * sfreq)) + 1) // 2\n    h_start = int(((n_freqs - 1) * h_freq) / (0.5 * sfreq))\n    logger.info(\n        \"filter : %7.3f ... %6.1f Hz   bins : %d ... %d of %d hpw : %d lpw : %d\",\n        l_freq,\n        h_freq,\n        l_start,\n        h_start,\n        n_freqs,\n        l_width,\n        h_width,\n    )\n    if l_freq > 0:\n        start = l_start - l_width + 1\n        stop = start + 2 * l_width - 1\n        if start < 0 or stop >= n_freqs:\n            raise RuntimeError(\"l_freq too low or l_trans_bandwidth too large\")\n        freq_resp[:start] = 0.0\n        k = np.arange(-l_width + 1, l_width) / float(l_width) + 3.0\n        freq_resp[start:stop] = np.cos(np.pi / 4.0 * k) ** 2\n\n    if h_freq < sfreq / 2.0:\n        start = h_start - h_width + 1\n        stop = start + 2 * h_width - 1\n        if start < 0 or stop >= n_freqs:\n            raise RuntimeError(\"h_freq too high or h_trans_bandwidth too large\")\n        k = np.arange(-h_width + 1, h_width) / float(h_width) + 1.0\n        freq_resp[start:stop] *= np.cos(np.pi / 4.0 * k) ** 2\n        freq_resp[stop:] = 0.0\n    # Get the time-domain version of this signal\n    h = fft.irfft(freq_resp, n=2 * len(freq_resp) - 1)\n    h = np.roll(h, n_freqs - 1)  # center the impulse like a linear-phase filt\n    return h", "metadata": {}}
{"_id": "mne_mne_filter.py_savgol_filter_code", "title": "savgol_filter", "text": "def savgol_filter(self, h_freq, verbose=None):\n        \"\"\"Filter the data using Savitzky-Golay polynomial method.\n\n        Parameters\n        ----------\n        h_freq : float\n            Approximate high cut-off frequency in Hz. Note that this\n            is not an exact cutoff, since Savitzky-Golay filtering\n            :footcite:`SavitzkyGolay1964` is done using polynomial fits\n            instead of FIR/IIR filtering. This parameter is thus used to\n            determine the length of the window over which a 5th-order\n            polynomial smoothing is used.\n        %(verbose)s\n\n        Returns\n        -------\n        inst : instance of Epochs, Evoked or SourceEstimate\n            The object with the filtering applied.\n\n        See Also\n        --------\n        mne.io.Raw.filter\n\n        Notes\n        -----\n        For Savitzky-Golay low-pass approximation, see:\n\n            https://gist.github.com/larsoner/bbac101d50176611136b\n\n        When working on SourceEstimates the sample rate of the original data is inferred from tstep.\n\n        .. versionadded:: 0.9.0\n\n        References\n        ----------\n        .. footbibliography::\n\n        Examples\n        --------\n        >>> import mne\n        >>> from os import path as op\n        >>> evoked_fname = op.join(mne.datasets.sample.data_path(), 'MEG', 'sample', 'sample_audvis-ave.fif')  # doctest:+SKIP\n        >>> evoked = mne.read_evokeds(evoked_fname, baseline=(None, 0))[0]  # doctest:+SKIP\n        >>> evoked.savgol_filter(10.)  # low-pass at around 10 Hz # doctest:+SKIP\n        >>> evoked.plot()  # doctest:+SKIP\n        \"\"\"  # noqa: E501\n        from .source_estimate import _BaseSourceEstimate\n\n        _check_preload(self, \"inst.savgol_filter\")\n        if not isinstance(self, _BaseSourceEstimate):\n            s_freq = self.info[\"sfreq\"]\n        else:\n            s_freq = 1 / self.tstep\n        h_freq = float(h_freq)\n        if h_freq >= s_freq / 2.0:\n            raise ValueError(\"h_freq must be less than half the sample rate\")\n\n        # savitzky-golay filtering\n        window_length = (int(np.round(s_freq / h_freq)) // 2) * 2 + 1\n        logger.info(\"Using savgol length %d\", window_length)\n        self._data[:] = signal.savgol_filter(\n            self._data, axis=-1, polyorder=5, window_length=window_length\n        )\n        return self", "metadata": {}}
{"_id": "mne_mne_filter.py_filter_code", "title": "filter", "text": "def filter(\n        self,\n        l_freq,\n        h_freq,\n        picks=None,\n        filter_length=\"auto\",\n        l_trans_bandwidth=\"auto\",\n        h_trans_bandwidth=\"auto\",\n        n_jobs=None,\n        method=\"fir\",\n        iir_params=None,\n        phase=\"zero\",\n        fir_window=\"hamming\",\n        fir_design=\"firwin\",\n        skip_by_annotation=(\"edge\", \"bad_acq_skip\"),\n        pad=\"edge\",\n        *,\n        verbose=None,\n    ):\n        \"\"\"Filter a subset of channels/vertices.\n\n        Parameters\n        ----------\n        %(l_freq)s\n        %(h_freq)s\n        %(picks_all_data)s\n        %(filter_length)s\n        %(l_trans_bandwidth)s\n        %(h_trans_bandwidth)s\n        %(n_jobs_fir)s\n        %(method_fir)s\n        %(iir_params)s\n        %(phase)s\n        %(fir_window)s\n        %(fir_design)s\n        %(skip_by_annotation)s\n\n            .. versionadded:: 0.16.\n        %(pad_fir)s\n        %(verbose)s\n\n        Returns\n        -------\n        inst : instance of Epochs, Evoked, SourceEstimate, or Raw\n            The filtered data.\n\n        See Also\n        --------\n        mne.filter.create_filter\n        mne.Evoked.savgol_filter\n        mne.io.Raw.notch_filter\n        mne.io.Raw.resample\n        mne.filter.create_filter\n        mne.filter.filter_data\n        mne.filter.construct_iir_filter\n\n        Notes\n        -----\n        Applies a zero-phase low-pass, high-pass, band-pass, or band-stop\n        filter to the channels selected by ``picks``.\n        The data are modified inplace.\n\n        The object has to have the data loaded e.g. with ``preload=True``\n        or ``self.load_data()``.\n\n        ``l_freq`` and ``h_freq`` are the frequencies below which and above\n        which, respectively, to filter out of the data. Thus the uses are:\n\n            * ``l_freq < h_freq``: band-pass filter\n            * ``l_freq > h_freq``: band-stop filter\n            * ``l_freq is not None and h_freq is None``: high-pass filter\n            * ``l_freq is None and h_freq is not None``: low-pass filter\n\n        ``self.info['lowpass']`` and ``self.info['highpass']`` are only\n        updated with picks=None.\n\n        .. note:: If n_jobs > 1, more memory is required as\n                  ``len(picks) * n_times`` additional time points need to\n                  be temporarily stored in memory.\n\n        When working on SourceEstimates the sample rate of the original\n        data is inferred from tstep.\n\n        For more information, see the tutorials\n        :ref:`disc-filtering` and :ref:`tut-filter-resample` and\n        :func:`mne.filter.create_filter`.\n\n        .. versionadded:: 0.15\n        \"\"\"\n        from .annotations import _annotations_starts_stops\n        from .io import BaseRaw\n        from .source_estimate import _BaseSourceEstimate\n\n        _check_preload(self, \"inst.filter\")\n        if not isinstance(self, _BaseSourceEstimate):\n            update_info, picks = _filt_check_picks(self.info, picks, l_freq, h_freq)\n            s_freq = self.info[\"sfreq\"]\n        else:\n            s_freq = 1.0 / self.tstep\n        if pad is None and method != \"iir\":\n            pad = \"edge\"\n        if isinstance(self, BaseRaw):\n            # Deal with annotations\n            onsets, ends = _annotations_starts_stops(\n                self, skip_by_annotation, invert=True\n            )\n            logger.info(\n                \"Filtering raw data in %d contiguous segment%s\",\n                len(onsets),\n                _pl(onsets),\n            )\n        else:\n            onsets, ends = np.array([0]), np.array([self._data.shape[1]])\n        max_idx = (ends - onsets).argmax()\n        for si, (start, stop) in enumerate(zip(onsets, ends)):\n            # Only output filter params once (for info level), and only warn\n            # once about the length criterion (longest segment is too short)\n            use_verbose = verbose if si == max_idx else \"error\"\n            filter_data(\n                self._data[:, start:stop],\n                s_freq,\n                l_freq,\n                h_freq,\n                picks,\n                filter_length,\n                l_trans_bandwidth,\n                h_trans_bandwidth,\n                n_jobs,\n                method,\n                iir_params,\n                copy=False,\n                phase=phase,\n                fir_window=fir_window,\n                fir_design=fir_design,\n                pad=pad,\n                verbose=use_verbose,\n            )\n        # update info if filter is applied to all data channels/vertices,\n        # and it's not a band-stop filter\n        if not isinstance(self, _BaseSourceEstimate):\n            _filt_update_info(self.info, update_info, l_freq, h_freq)\n        return self", "metadata": {}}
{"_id": "mne_mne_filter.py_resample_code", "title": "resample", "text": "def resample(\n        self,\n        sfreq,\n        *,\n        npad=\"auto\",\n        window=\"auto\",\n        n_jobs=None,\n        pad=\"edge\",\n        method=\"fft\",\n        verbose=None,\n    ):\n        \"\"\"Resample data.\n\n        If appropriate, an anti-aliasing filter is applied before resampling.\n        See :ref:`resampling-and-decimating` for more information.\n\n        .. note:: Data must be loaded.\n\n        Parameters\n        ----------\n        sfreq : float\n            New sample rate to use.\n        %(npad)s\n        %(window_resample)s\n        %(n_jobs_cuda)s\n        %(pad_resample)s\n\n            .. versionadded:: 0.15\n        %(method_resample)s\n\n            .. versionadded:: 1.7\n        %(verbose)s\n\n        Returns\n        -------\n        inst : instance of Epochs or Evoked\n            The resampled object.\n\n        See Also\n        --------\n        mne.io.Raw.resample\n\n        Notes\n        -----\n        For some data, it may be more accurate to use npad=0 to reduce\n        artifacts. This is dataset dependent -- check your data!\n        \"\"\"\n        from .epochs import BaseEpochs\n        from .evoked import Evoked\n\n        # Should be guaranteed by our inheritance, and the fact that\n        # mne.io.BaseRaw and _BaseSourceEstimate overrides this method\n        assert isinstance(self, BaseEpochs | Evoked)\n\n        sfreq = float(sfreq)\n        o_sfreq = self.info[\"sfreq\"]\n        if _check_resamp_noop(sfreq, o_sfreq):\n            return self\n\n        _check_preload(self, \"inst.resample\")\n        self._data = resample(\n            self._data,\n            sfreq,\n            o_sfreq,\n            npad=npad,\n            window=window,\n            n_jobs=n_jobs,\n            pad=pad,\n            method=method,\n        )\n        lowpass = self.info.get(\"lowpass\")\n        lowpass = np.inf if lowpass is None else lowpass\n        with self.info._unlock():\n            self.info[\"lowpass\"] = min(lowpass, sfreq / 2.0)\n            self.info[\"sfreq\"] = float(sfreq)\n        new_times = (\n            np.arange(self._data.shape[-1], dtype=np.float64) / sfreq + self.times[0]\n        )\n        # adjust indirectly affected variables\n        self._set_times(new_times)\n        self._raw_times = self.times\n        self._update_first_last()\n        return self", "metadata": {}}
{"_id": "mne_mne_filter.py_apply_hilbert_code", "title": "apply_hilbert", "text": "def apply_hilbert(\n        self, picks=None, envelope=False, n_jobs=None, n_fft=\"auto\", *, verbose=None\n    ):\n        \"\"\"Compute analytic signal or envelope for a subset of channels/vertices.\n\n        Parameters\n        ----------\n        %(picks_all_data_noref)s\n        envelope : bool\n            Compute the envelope signal of each channel/vertex. Default False.\n            See Notes.\n        %(n_jobs)s\n        n_fft : int | None | str\n            Points to use in the FFT for Hilbert transformation. The signal\n            will be padded with zeros before computing Hilbert, then cut back\n            to original length. If None, n == self.n_times. If 'auto',\n            the next highest fast FFT length will be use.\n        %(verbose)s\n\n        Returns\n        -------\n        self : instance of Raw, Epochs, Evoked or SourceEstimate\n            The raw object with transformed data.\n\n        Notes\n        -----\n        **Parameters**\n\n        If ``envelope=False``, the analytic signal for the channels/vertices defined in\n        ``picks`` is computed and the data of the Raw object is converted to\n        a complex representation (the analytic signal is complex valued).\n\n        If ``envelope=True``, the absolute value of the analytic signal for the\n        channels/vertices defined in ``picks`` is computed, resulting in the envelope\n        signal.\n\n        .. warning: Do not use ``envelope=True`` if you intend to compute\n                    an inverse solution from the raw data. If you want to\n                    compute the envelope in source space, use\n                    ``envelope=False`` and compute the envelope after the\n                    inverse solution has been obtained.\n\n        If envelope=False, more memory is required since the original raw data\n        as well as the analytic signal have temporarily to be stored in memory.\n        If n_jobs > 1, more memory is required as ``len(picks) * n_times``\n        additional time points need to be temporarily stored in memory.\n\n        Also note that the ``n_fft`` parameter will allow you to pad the signal\n        with zeros before performing the Hilbert transform. This padding\n        is cut off, but it may result in a slightly different result\n        (particularly around the edges). Use at your own risk.\n\n        **Analytic signal**\n\n        The analytic signal \"x_a(t)\" of \"x(t)\" is::\n\n            x_a = F^{-1}(F(x) 2U) = x + i y\n\n        where \"F\" is the Fourier transform, \"U\" the unit step function,\n        and \"y\" the Hilbert transform of \"x\". One usage of the analytic\n        signal is the computation of the envelope signal, which is given by\n        \"e(t) = abs(x_a(t))\". Due to the linearity of Hilbert transform and the\n        MNE inverse solution, the enevlope in source space can be obtained\n        by computing the analytic signal in sensor space, applying the MNE\n        inverse, and computing the envelope in source space.\n        \"\"\"\n        from .source_estimate import _BaseSourceEstimate\n\n        if not isinstance(self, _BaseSourceEstimate):\n            use_info = self.info\n        else:\n            use_info = len(self._data)\n        _check_preload(self, \"inst.apply_hilbert\")\n        picks = _picks_to_idx(use_info, picks, exclude=(), with_ref_meg=False)\n\n        if n_fft is None:\n            n_fft = len(self.times)\n        elif isinstance(n_fft, str):\n            if n_fft != \"auto\":\n                raise ValueError(\n                    f\"n_fft must be an integer, string, or None, got {type(n_fft)}\"\n                )\n            n_fft = next_fast_len(len(self.times))\n        n_fft = int(n_fft)\n        if n_fft < len(self.times):\n            raise ValueError(\n                f\"n_fft ({n_fft}) must be at least the number of time points (\"\n                f\"{len(self.times)})\"\n            )\n        dtype = None if envelope else np.complex128\n        args, kwargs = (), dict(n_fft=n_fft, envelope=envelope)\n\n        data_in = self._data\n        if dtype is not None and dtype != self._data.dtype:\n            self._data = self._data.astype(dtype)\n\n        parallel, p_fun, n_jobs = parallel_func(_check_fun, n_jobs)\n        if n_jobs == 1:\n            # modify data inplace to save memory\n            for idx in picks:\n                self._data[..., idx, :] = _check_fun(\n                    _my_hilbert, data_in[..., idx, :], *args, **kwargs\n                )\n        else:\n            # use parallel function\n            data_picks_new = parallel(\n                p_fun(_my_hilbert, data_in[..., p, :], *args, **kwargs) for p in picks\n            )\n            for pp, p in enumerate(picks):\n                self._data[..., p, :] = data_picks_new[pp]\n        return self", "metadata": {}}
{"_id": "mne_mne_bem.py_make_bem_solution_code", "title": "make_bem_solution", "text": "def make_bem_solution(surfs, *, solver=\"mne\", verbose=None):\n    \"\"\"Create a BEM solution using the linear collocation approach.\n\n    Parameters\n    ----------\n    surfs : list of dict\n        The BEM surfaces to use (from :func:`mne.make_bem_model`).\n    solver : str\n        Can be ``'mne'`` (default) to use MNE-Python, or ``'openmeeg'`` to use the\n        `OpenMEEG <https://openmeeg.github.io>`__ package.\n\n        .. versionadded:: 1.2\n    %(verbose)s\n\n    Returns\n    -------\n    bem : instance of ConductorModel\n        The BEM solution.\n\n    See Also\n    --------\n    make_bem_model\n    read_bem_surfaces\n    write_bem_surfaces\n    read_bem_solution\n    write_bem_solution\n\n    Notes\n    -----\n    .. versionadded:: 0.10.0\n    \"\"\"\n    _validate_type(solver, str, \"solver\")\n    _check_option(\"method\", solver.lower(), (\"mne\", \"openmeeg\"))\n    bem = _ensure_bem_surfaces(surfs)\n    _add_gamma_multipliers(bem)\n    if len(bem[\"surfs\"]) == 3:\n        logger.info(\"Three-layer model surfaces loaded.\")\n    elif len(bem[\"surfs\"]) == 1:\n        logger.info(\"Homogeneous model surface loaded.\")\n    else:\n        raise RuntimeError(\"Only 1- or 3-layer BEM computations supported\")\n    _check_bem_size(bem[\"surfs\"])\n    for surf in bem[\"surfs\"]:\n        _check_complete_surface(surf)\n    if solver.lower() == \"openmeeg\":\n        _fwd_bem_openmeeg_solution(bem)\n    else:\n        assert solver.lower() == \"mne\"\n        _fwd_bem_linear_collocation_solution(bem)\n    logger.info(\"Solution ready.\")\n    logger.info(\"BEM geometry computations complete.\")\n    return bem", "metadata": {}}
{"_id": "mne_mne_bem.py_make_bem_model_code", "title": "make_bem_model", "text": "def make_bem_model(\n    subject, ico=4, conductivity=(0.3, 0.006, 0.3), subjects_dir=None, verbose=None\n):\n    \"\"\"Create a BEM model for a subject.\n\n    Use :func:`~mne.make_bem_solution` to turn the returned surfaces into a\n    :class:`~mne.bem.ConductorModel` suitable for forward calculation.\n\n    .. note:: To get a single layer bem corresponding to the --homog flag in\n              the command line tool set the ``conductivity`` parameter\n              to a float (e.g. ``0.3``).\n\n    Parameters\n    ----------\n    %(subject)s\n    ico : int | None\n        The surface ico downsampling to use, e.g. ``5=20484``, ``4=5120``,\n        ``3=1280``. If None, no subsampling is applied.\n    conductivity : float | array of float of shape (3,) or (1,)\n        The conductivities to use for each shell. Should be a single element\n        for a one-layer model, or three elements for a three-layer model.\n        Defaults to ``[0.3, 0.006, 0.3]``. The MNE-C default for a\n        single-layer model is ``[0.3]``.\n    %(subjects_dir)s\n    %(verbose)s\n\n    Returns\n    -------\n    surfaces : list of dict\n        The BEM surfaces. Use :func:`~mne.make_bem_solution` to turn these into a\n        :class:`~mne.bem.ConductorModel` suitable for forward calculation.\n\n    See Also\n    --------\n    make_bem_solution\n    make_sphere_model\n    read_bem_surfaces\n    write_bem_surfaces\n\n    Notes\n    -----\n    .. versionadded:: 0.10.0\n    \"\"\"\n    conductivity = np.atleast_1d(conductivity).astype(float)\n    if conductivity.ndim != 1 or conductivity.size not in (1, 3):\n        raise ValueError(\n            \"conductivity must be a float or a 1D array-like with 1 or 3 elements\"\n        )\n    subjects_dir = get_subjects_dir(subjects_dir, raise_error=True)\n    subject_dir = subjects_dir / subject\n    bem_dir = subject_dir / \"bem\"\n    inner_skull = bem_dir / \"inner_skull.surf\"\n    outer_skull = bem_dir / \"outer_skull.surf\"\n    outer_skin = bem_dir / \"outer_skin.surf\"\n    surfaces = [inner_skull, outer_skull, outer_skin]\n    ids = [\n        FIFF.FIFFV_BEM_SURF_ID_BRAIN,\n        FIFF.FIFFV_BEM_SURF_ID_SKULL,\n        FIFF.FIFFV_BEM_SURF_ID_HEAD,\n    ]\n    logger.info(\"Creating the BEM geometry...\")\n    if len(conductivity) == 1:\n        surfaces = surfaces[:1]\n        ids = ids[:1]\n    surfaces = _surfaces_to_bem(surfaces, ids, conductivity, ico)\n    _check_bem_size(surfaces)\n    logger.info(\"Complete.\\n\")\n    return surfaces", "metadata": {}}
{"_id": "mne_mne_bem.py_make_sphere_model_code", "title": "make_sphere_model", "text": "def make_sphere_model(\n    r0=(0.0, 0.0, 0.04),\n    head_radius=0.09,\n    info=None,\n    relative_radii=(0.90, 0.92, 0.97, 1.0),\n    sigmas=(0.33, 1.0, 0.004, 0.33),\n    verbose=None,\n):\n    \"\"\"Create a spherical model for forward solution calculation.\n\n    Parameters\n    ----------\n    r0 : array-like | str\n        Head center to use (in head coordinates). If 'auto', the head\n        center will be calculated from the digitization points in info.\n    head_radius : float | str | None\n        If float, compute spherical shells for EEG using the given radius.\n        If ``'auto'``, estimate an appropriate radius from the dig points in the\n        :class:`~mne.Info` provided by the argument ``info``.\n        If None, exclude shells (single layer sphere model).\n    %(info)s Only needed if ``r0`` or ``head_radius`` are ``'auto'``.\n    relative_radii : array-like\n        Relative radii for the spherical shells.\n    sigmas : array-like\n        Sigma values for the spherical shells.\n    %(verbose)s\n\n    Returns\n    -------\n    sphere : instance of ConductorModel\n        The resulting spherical conductor model.\n\n    See Also\n    --------\n    make_bem_model\n    make_bem_solution\n\n    Notes\n    -----\n    The default model has::\n\n        relative_radii = (0.90, 0.92, 0.97, 1.0)\n        sigmas = (0.33, 1.0, 0.004, 0.33)\n\n    These correspond to compartments (with relative radii in ``m`` and\n    conductivities \u03c3 in ``S/m``) for the brain, CSF, skull, and scalp,\n    respectively.\n\n    .. versionadded:: 0.9.0\n    \"\"\"\n    for name in (\"r0\", \"head_radius\"):\n        param = locals()[name]\n        if isinstance(param, str):\n            if param != \"auto\":\n                raise ValueError(f'{name}, if str, must be \"auto\" not \"{param}\"')\n    relative_radii = np.array(relative_radii, float).ravel()\n    sigmas = np.array(sigmas, float).ravel()\n    if len(relative_radii) != len(sigmas):\n        raise ValueError(\n            f\"relative_radii length ({len(relative_radii)}) must match that of sigmas (\"\n            f\"{len(sigmas)})\"\n        )\n    if len(sigmas) <= 1 and head_radius is not None:\n        raise ValueError(\n            \"at least 2 sigmas must be supplied if head_radius is not None, got \"\n            f\"{len(sigmas)}\"\n        )\n    if (isinstance(r0, str) and r0 == \"auto\") or (\n        isinstance(head_radius, str) and head_radius == \"auto\"\n    ):\n        if info is None:\n            raise ValueError(\"Info must not be None for auto mode\")\n        head_radius_fit, r0_fit = fit_sphere_to_headshape(info, units=\"m\")[:2]\n        if isinstance(r0, str):\n            r0 = r0_fit\n        if isinstance(head_radius, str):\n            head_radius = head_radius_fit\n    sphere = ConductorModel(\n        is_sphere=True, r0=np.array(r0), coord_frame=FIFF.FIFFV_COORD_HEAD\n    )\n    sphere[\"layers\"] = list()\n    if head_radius is not None:\n        # Eventually these could be configurable...\n        relative_radii = np.array(relative_radii, float)\n        sigmas = np.array(sigmas, float)\n        order = np.argsort(relative_radii)\n        relative_radii = relative_radii[order]\n        sigmas = sigmas[order]\n        for rel_rad, sig in zip(relative_radii, sigmas):\n            # sort layers by (relative) radius, and scale radii\n            layer = dict(rad=rel_rad, sigma=sig)\n            layer[\"rel_rad\"] = layer[\"rad\"] = rel_rad\n            sphere[\"layers\"].append(layer)\n\n        # scale the radii\n        R = sphere[\"layers\"][-1][\"rad\"]\n        rR = sphere[\"layers\"][-1][\"rel_rad\"]\n        for layer in sphere[\"layers\"]:\n            layer[\"rad\"] /= R\n            layer[\"rel_rad\"] /= rR\n\n        #\n        # Setup the EEG sphere model calculations\n        #\n\n        # Scale the relative radii\n        for k in range(len(relative_radii)):\n            sphere[\"layers\"][k][\"rad\"] = head_radius * sphere[\"layers\"][k][\"rel_rad\"]\n        rv = _fwd_eeg_fit_berg_scherg(sphere, 200, 3)\n        logger.info(f\"\\nEquiv. model fitting -> RV = {100 * rv:g} %%\")\n        for k in range(3):\n            s_k = sphere[\"layers\"][-1][\"sigma\"] * sphere[\"lambda\"][k]\n            logger.info(f\"mu{k + 1} = {sphere['mu'][k]:g}    lambda{k + 1} = {s_k:g}\")\n        logger.info(\n            f\"Set up EEG sphere model with scalp radius {1000 * head_radius:7.1f} mm\\n\"\n        )\n    return sphere", "metadata": {}}
{"_id": "mne_mne_bem.py_fit_sphere_to_headshape_code", "title": "fit_sphere_to_headshape", "text": "def fit_sphere_to_headshape(info, dig_kinds=\"auto\", units=\"m\", verbose=None):\n    \"\"\"Fit a sphere to the headshape points to determine head center.\n\n    Parameters\n    ----------\n    %(info_not_none)s\n    %(dig_kinds)s\n    units : str\n        Can be ``\"m\"`` (default) or ``\"mm\"``.\n\n        .. versionadded:: 0.12\n    %(verbose)s\n\n    Returns\n    -------\n    radius : float\n        Sphere radius.\n    origin_head: ndarray, shape (3,)\n        Head center in head coordinates.\n    origin_device: ndarray, shape (3,)\n        Head center in device coordinates.\n\n    Notes\n    -----\n    This function excludes any points that are low and frontal\n    (``z < 0 and y > 0``) to improve the fit.\n    \"\"\"\n    if not isinstance(units, str) or units not in (\"m\", \"mm\"):\n        raise ValueError('units must be a \"m\" or \"mm\"')\n    radius, origin_head, origin_device = _fit_sphere_to_headshape(info, dig_kinds)\n    if units == \"mm\":\n        radius *= 1e3\n        origin_head *= 1e3\n        origin_device *= 1e3\n    return radius, origin_head, origin_device", "metadata": {}}
{"_id": "mne_mne_bem.py_get_fitting_dig_code", "title": "get_fitting_dig", "text": "def get_fitting_dig(info, dig_kinds=\"auto\", exclude_frontal=True, verbose=None):\n    \"\"\"Get digitization points suitable for sphere fitting.\n\n    Parameters\n    ----------\n    %(info_not_none)s\n    %(dig_kinds)s\n    %(exclude_frontal)s\n        Default is True.\n\n        .. versionadded:: 0.19\n    %(verbose)s\n\n    Returns\n    -------\n    dig : array, shape (n_pts, 3)\n        The digitization points (in head coordinates) to use for fitting.\n\n    Notes\n    -----\n    This will exclude digitization locations that have ``z < 0 and y > 0``,\n    i.e. points on the nose and below the nose on the face.\n\n    .. versionadded:: 0.14\n    \"\"\"\n    _validate_type(info, \"info\")\n    if info[\"dig\"] is None:\n        raise RuntimeError(\n            'Cannot fit headshape without digitization, info[\"dig\"] is None'\n        )\n    if isinstance(dig_kinds, str):\n        if dig_kinds == \"auto\":\n            # try \"extra\" first\n            try:\n                return get_fitting_dig(info, \"extra\")\n            except ValueError:\n                pass\n            return get_fitting_dig(info, (\"extra\", \"eeg\"))\n        else:\n            dig_kinds = (dig_kinds,)\n    # convert string args to ints (first make dig_kinds mutable in case tuple)\n    dig_kinds = list(dig_kinds)\n    for di, d in enumerate(dig_kinds):\n        dig_kinds[di] = _dig_kind_dict.get(d, d)\n        if dig_kinds[di] not in _dig_kind_ints:\n            raise ValueError(\n                f\"dig_kinds[{di}] ({d}) must be one of {sorted(_dig_kind_dict)}\"\n            )\n\n    # get head digization points of the specified kind(s)\n    dig = [p for p in info[\"dig\"] if p[\"kind\"] in dig_kinds]\n    if len(dig) == 0:\n        raise ValueError(f\"No digitization points found for dig_kinds={dig_kinds}\")\n    if any(p[\"coord_frame\"] != FIFF.FIFFV_COORD_HEAD for p in dig):\n        raise RuntimeError(\n            f\"Digitization points dig_kinds={dig_kinds} not in head \"\n            \"coordinates, contact mne-python developers\"\n        )\n    hsp = [p[\"r\"] for p in dig]\n    del dig\n\n    # exclude some frontal points (nose etc.)\n    if exclude_frontal:\n        hsp = [p for p in hsp if not (p[2] < -1e-6 and p[1] > 1e-6)]\n    hsp = np.array(hsp)\n\n    if len(hsp) <= 10:\n        kinds_str = \", \".join([f'\"{_dig_kind_rev[d]}\"' for d in sorted(dig_kinds)])\n        msg = (\n            f\"Only {len(hsp)} head digitization points of the specified \"\n            f\"kind{_pl(dig_kinds)} ({kinds_str},)\"\n        )\n        if len(hsp) < 4:\n            raise ValueError(msg + \", at least 4 required\")\n        else:\n            warn(msg + \", fitting may be inaccurate\")\n    return hsp", "metadata": {}}
{"_id": "mne_mne_bem.py_make_watershed_bem_code", "title": "make_watershed_bem", "text": "def make_watershed_bem(\n    subject,\n    subjects_dir=None,\n    overwrite=False,\n    volume=\"T1\",\n    atlas=False,\n    gcaatlas=False,\n    preflood=None,\n    show=False,\n    copy=True,\n    T1=None,\n    brainmask=\"ws.mgz\",\n    verbose=None,\n):\n    \"\"\"Create BEM surfaces using the FreeSurfer watershed algorithm.\n\n    See :ref:`bem_watershed_algorithm` for additional information.\n\n    Parameters\n    ----------\n    subject : str\n        Subject name.\n    %(subjects_dir)s\n    %(overwrite)s\n    volume : str\n        Defaults to T1.\n    atlas : bool\n        Specify the ``--atlas option`` for ``mri_watershed``.\n    gcaatlas : bool\n        Specify the ``--brain_atlas`` option for ``mri_watershed``.\n    preflood : int\n        Change the preflood height.\n    show : bool\n        Show surfaces to visually inspect all three BEM surfaces (recommended).\n\n        .. versionadded:: 0.12\n\n    copy : bool\n        If True (default), use copies instead of symlinks for surfaces\n        (if they do not already exist).\n\n        .. versionadded:: 0.18\n        .. versionchanged:: 1.1 Use copies instead of symlinks.\n    T1 : bool | None\n        If True, pass the ``-T1`` flag.\n        By default (None), this takes the same value as ``gcaatlas``.\n\n        .. versionadded:: 0.19\n    brainmask : str\n        The filename for the brainmask output file relative to the\n        ``$SUBJECTS_DIR/$SUBJECT/bem/watershed/`` directory.\n        Can be for example ``\"../../mri/brainmask.mgz\"`` to overwrite\n        the brainmask obtained via ``recon-all -autorecon1``.\n\n        .. versionadded:: 0.19\n    %(verbose)s\n\n    See Also\n    --------\n    mne.viz.plot_bem\n\n    Notes\n    -----\n    If your BEM meshes do not look correct when viewed in\n    :func:`mne.viz.plot_alignment` or :func:`mne.viz.plot_bem`, consider\n    potential solutions from the :ref:`FAQ <faq_watershed_bem_meshes>`.\n\n    .. versionadded:: 0.10\n    \"\"\"\n    env, mri_dir, bem_dir = _prepare_env(subject, subjects_dir)\n    tempdir = _TempDir()  # fsl and Freesurfer create some random junk in CWD\n    run_subprocess_env = partial(run_subprocess, env=env, cwd=tempdir)\n\n    subjects_dir = env[\"SUBJECTS_DIR\"]  # Set by _prepare_env() above.\n    subject_dir = op.join(subjects_dir, subject)\n    ws_dir = op.join(bem_dir, \"watershed\")\n    T1_dir = op.join(mri_dir, volume)\n    T1_mgz = T1_dir\n    if not T1_dir.endswith(\".mgz\"):\n        T1_mgz += \".mgz\"\n\n    if not op.isdir(bem_dir):\n        os.makedirs(bem_dir)\n    _check_fname(T1_mgz, overwrite=\"read\", must_exist=True, name=\"MRI data\")\n    if op.isdir(ws_dir):\n        if not overwrite:\n            raise RuntimeError(\n                f\"{ws_dir} already exists. Use the --overwrite option to recreate it.\"\n            )\n        else:\n            shutil.rmtree(ws_dir)\n\n    # put together the command\n    cmd = [\"mri_watershed\"]\n    if preflood:\n        cmd += [\"-h\", f\"{int(preflood)}\"]\n\n    if T1 is None:\n        T1 = gcaatlas\n    if T1:\n        cmd += [\"-T1\"]\n    if gcaatlas:\n        fname = op.join(env[\"FREESURFER_HOME\"], \"average\", \"RB_all_withskull_*.gca\")\n        fname = sorted(glob.glob(fname))[::-1][0]\n\n        # check if FS>8 didn't generate talairach_with_skull.lta\n        talairach_with_skull_path = os.path.join(\n            subject_dir, \"mri/transforms/talairach_with_skull.lta\"\n        )\n        if not os.path.exists(talairach_with_skull_path):\n            logger.info(\n                f\"{talairach_with_skull_path} does not exist. Running mri_em_register.\"\n            )\n            em_reg_cmd = [\n                \"mri_em_register\",\n                \"-skull\",\n                subject_dir + \"/mri/nu.mgz\",\n                fname,\n                talairach_with_skull_path,\n            ]\n\n            run_subprocess_env(em_reg_cmd)\n\n        logger.info(f\"Using GCA atlas: {fname}\")\n        cmd += [\n            \"-atlas\",\n            \"-brain_atlas\",\n            fname,\n            subject_dir + \"/mri/transforms/talairach_with_skull.lta\",\n        ]\n    elif atlas:\n        cmd += [\"-atlas\"]\n    if op.exists(T1_mgz):\n        cmd += [\n            \"-useSRAS\",\n            \"-surf\",\n            op.join(ws_dir, subject),\n            T1_mgz,\n            op.join(ws_dir, brainmask),\n        ]\n    else:\n        cmd += [\n            \"-useSRAS\",\n            \"-surf\",\n            op.join(ws_dir, subject),\n            T1_dir,\n            op.join(ws_dir, brainmask),\n        ]\n    # report and run\n    logger.info(\n        \"\\nRunning mri_watershed for BEM segmentation with the following parameters:\\n\"\n        f\"\\nResults dir = {ws_dir}\\nCommand = {' '.join(cmd)}\\n\"\n    )\n    os.makedirs(op.join(ws_dir))\n    run_subprocess_env(cmd)\n    del tempdir  # clean up directory\n    if op.isfile(T1_mgz):\n        new_info = _extract_volume_info(T1_mgz)\n        if not new_info:\n            warn(\n                \"nibabel is not available or the volume info is invalid. Volume info \"\n                \"not updated in the written surface.\"\n            )\n        surfs = [\"brain\", \"inner_skull\", \"outer_skull\", \"outer_skin\"]\n        for s in surfs:\n            surf_ws_out = op.join(ws_dir, f\"{subject}_{s}_surface\")\n\n            rr, tris, volume_info = read_surface(surf_ws_out, read_metadata=True)\n            # replace volume info, 'head' stays\n            volume_info.update(new_info)\n            write_surface(\n                surf_ws_out, rr, tris, volume_info=volume_info, overwrite=True\n            )\n\n            # Create symbolic links\n            surf_out = op.join(bem_dir, f\"{s}.surf\")\n            if not overwrite and op.exists(surf_out):\n                skip_symlink = True\n            else:\n                if op.exists(surf_out):\n                    os.remove(surf_out)\n                _symlink(surf_ws_out, surf_out, copy)\n                skip_symlink = False\n\n        if skip_symlink:\n            logger.info(\n                \"Unable to create all symbolic links to .surf files in bem folder. Use \"\n                \"--overwrite option to recreate them.\"\n            )\n            dest = op.join(bem_dir, \"watershed\")\n        else:\n            logger.info(\"Symbolic links to .surf files created in bem folder\")\n            dest = bem_dir\n\n    logger.info(\n        \"\\nThank you for waiting.\\nThe BEM triangulations for this subject are now \"\n        f\"available at:\\n{dest}.\"\n    )\n\n    # Write a head file for coregistration\n    fname_head = op.join(bem_dir, subject + \"-head.fif\")\n    if op.isfile(fname_head):\n        os.remove(fname_head)\n\n    surf = _surfaces_to_bem(\n        [op.join(ws_dir, subject + \"_outer_skin_surface\")],\n        [FIFF.FIFFV_BEM_SURF_ID_HEAD],\n        sigmas=[1],\n    )\n    write_bem_surfaces(fname_head, surf)\n\n    # Show computed BEM surfaces\n    if show:\n        plot_bem(\n            subject=subject,\n            subjects_dir=subjects_dir,\n            orientation=\"coronal\",\n            slices=None,\n            show=True,\n        )\n\n    logger.info(f\"Created {fname_head}\\n\\nComplete.\")", "metadata": {}}
{"_id": "mne_mne_bem.py_read_bem_surfaces_code", "title": "read_bem_surfaces", "text": "def read_bem_surfaces(\n    fname, patch_stats=False, s_id=None, on_defects=\"raise\", verbose=None\n):\n    \"\"\"Read the BEM surfaces from a FIF file.\n\n    Parameters\n    ----------\n    fname : path-like\n        The name of the file containing the surfaces.\n    patch_stats : bool, optional (default False)\n        Calculate and add cortical patch statistics to the surfaces.\n    s_id : int | None\n        If int, only read and return the surface with the given ``s_id``.\n        An error will be raised if it doesn't exist. If None, all\n        surfaces are read and returned.\n    %(on_defects)s\n\n        .. versionadded:: 0.23\n    %(verbose)s\n\n    Returns\n    -------\n    surf: list | dict\n        A list of dictionaries that each contain a surface. If ``s_id``\n        is not None, only the requested surface will be returned.\n\n    See Also\n    --------\n    write_bem_surfaces, write_bem_solution, make_bem_model\n    \"\"\"\n    # Open the file, create directory\n    _validate_type(s_id, (\"int-like\", None), \"s_id\")\n    fname = _check_fname(fname, \"read\", True, \"fname\")\n    if fname.suffix == \".h5\":\n        surf = _read_bem_surfaces_h5(fname, s_id)\n    else:\n        surf = _read_bem_surfaces_fif(fname, s_id)\n    if s_id is not None and len(surf) != 1:\n        raise ValueError(f\"surface with id {s_id} not found\")\n    for this in surf:\n        if patch_stats or this[\"nn\"] is None:\n            _check_complete_surface(this, incomplete=on_defects)\n    return surf[0] if s_id is not None else surf", "metadata": {}}
{"_id": "mne_mne_bem.py_read_bem_solution_code", "title": "read_bem_solution", "text": "def read_bem_solution(fname, *, verbose=None):\n    \"\"\"Read the BEM solution from a file.\n\n    Parameters\n    ----------\n    fname : path-like\n        The file containing the BEM solution.\n    %(verbose)s\n\n    Returns\n    -------\n    bem : instance of ConductorModel\n        The BEM solution.\n\n    See Also\n    --------\n    read_bem_surfaces\n    write_bem_surfaces\n    make_bem_solution\n    write_bem_solution\n    \"\"\"\n    fname = _check_fname(fname, \"read\", True, \"fname\")\n    # mirrors fwd_bem_load_surfaces from fwd_bem_model.c\n    if fname.suffix == \".h5\":\n        read_hdf5, _ = _import_h5io_funcs()\n        logger.info(\"Loading surfaces and solution...\")\n        bem = read_hdf5(fname)\n        if \"solver\" not in bem:\n            bem[\"solver\"] = \"mne\"\n    else:\n        bem = _read_bem_solution_fif(fname)\n\n    if len(bem[\"surfs\"]) == 3:\n        logger.info(\"Three-layer model surfaces loaded.\")\n        needed = np.array(\n            [\n                FIFF.FIFFV_BEM_SURF_ID_HEAD,\n                FIFF.FIFFV_BEM_SURF_ID_SKULL,\n                FIFF.FIFFV_BEM_SURF_ID_BRAIN,\n            ]\n        )\n        if not all(x[\"id\"] in needed for x in bem[\"surfs\"]):\n            raise RuntimeError(\"Could not find necessary BEM surfaces\")\n        # reorder surfaces as necessary (shouldn't need to?)\n        reorder = [None] * 3\n        for x in bem[\"surfs\"]:\n            reorder[np.where(x[\"id\"] == needed)[0][0]] = x\n        bem[\"surfs\"] = reorder\n    elif len(bem[\"surfs\"]) == 1:\n        if not bem[\"surfs\"][0][\"id\"] == FIFF.FIFFV_BEM_SURF_ID_BRAIN:\n            raise RuntimeError(\"BEM Surfaces not found\")\n        logger.info(\"Homogeneous model surface loaded.\")\n\n    assert set(bem.keys()) == set((\"surfs\", \"solution\", \"bem_method\", \"solver\"))\n    bem = ConductorModel(bem)\n    bem[\"is_sphere\"] = False\n    # sanity checks and conversions\n    _check_option(\n        \"BEM approximation method\", bem[\"bem_method\"], (FIFF.FIFFV_BEM_APPROX_LINEAR,)\n    )  # CONSTANT not supported\n    dim = 0\n    solver = bem.get(\"solver\", \"mne\")\n    _check_option(\"BEM solver\", solver, (\"mne\", \"openmeeg\"))\n    for si, surf in enumerate(bem[\"surfs\"]):\n        assert bem[\"bem_method\"] == FIFF.FIFFV_BEM_APPROX_LINEAR\n        dim += surf[\"np\"]\n        if solver == \"openmeeg\" and si != 0:\n            dim += surf[\"ntri\"]\n    dims = bem[\"solution\"].shape\n    if solver == \"openmeeg\":\n        sz = (dim * (dim + 1)) // 2\n        if len(dims) != 1 or dims[0] != sz:\n            raise RuntimeError(\n                \"For the given BEM surfaces, OpenMEEG should produce a \"\n                f\"solution matrix of shape ({sz},) but got {dims}\"\n            )\n        bem[\"nsol\"] = dim\n    else:\n        if len(dims) != 2 and solver != \"openmeeg\":\n            raise RuntimeError(\n                \"Expected a two-dimensional solution matrix \"\n                f\"instead of a {dims[0]} dimensional one\"\n            )\n        if dims[0] != dim or dims[1] != dim:\n            raise RuntimeError(\n                f\"Expected a {dim} x {dim} solution matrix instead of \"\n                f\"a {dims[1]} x {dims[0]} one\"\n            )\n        bem[\"nsol\"] = bem[\"solution\"].shape[0]\n    # Gamma factors and multipliers\n    _add_gamma_multipliers(bem)\n    extra = f\"made by {solver}\" if solver != \"mne\" else \"\"\n    logger.info(f\"Loaded linear collocation BEM solution{extra} from {fname}\")\n    return bem", "metadata": {}}
{"_id": "mne_mne_bem.py_write_bem_surfaces_code", "title": "write_bem_surfaces", "text": "def write_bem_surfaces(fname, surfs, overwrite=False, *, verbose=None):\n    \"\"\"Write BEM surfaces to a FIF file.\n\n    Parameters\n    ----------\n    fname : path-like\n        Filename to write. Can end with ``.h5`` to write using HDF5.\n    surfs : dict | list of dict\n        The surfaces, or a single surface.\n    %(overwrite)s\n    %(verbose)s\n    \"\"\"\n    if isinstance(surfs, dict):\n        surfs = [surfs]\n    fname = _check_fname(fname, overwrite=overwrite, name=\"fname\")\n\n    if fname.suffix == \".h5\":\n        _, write_hdf5 = _import_h5io_funcs()\n        write_hdf5(fname, dict(surfs=surfs), overwrite=True)\n    else:\n        with start_and_end_file(fname) as fid:\n            start_block(fid, FIFF.FIFFB_BEM)\n            write_int(fid, FIFF.FIFF_BEM_COORD_FRAME, surfs[0][\"coord_frame\"])\n            _write_bem_surfaces_block(fid, surfs)\n            end_block(fid, FIFF.FIFFB_BEM)", "metadata": {}}
{"_id": "mne_mne_bem.py_write_head_bem_code", "title": "write_head_bem", "text": "def write_head_bem(\n    fname, rr, tris, on_defects=\"raise\", overwrite=False, *, verbose=None\n):\n    \"\"\"Write a head surface to a FIF file.\n\n    Parameters\n    ----------\n    fname : path-like\n        Filename to write.\n    rr : array, shape (n_vertices, 3)\n        Coordinate points in the MRI coordinate system.\n    tris : ndarray of int, shape (n_tris, 3)\n        Triangulation (each line contains indices for three points which\n        together form a face).\n    %(on_defects)s\n    %(overwrite)s\n    %(verbose)s\n    \"\"\"\n    surf = _surfaces_to_bem(\n        [dict(rr=rr, tris=tris)],\n        [FIFF.FIFFV_BEM_SURF_ID_HEAD],\n        [1],\n        rescale=False,\n        incomplete=on_defects,\n    )\n    write_bem_surfaces(fname, surf, overwrite=overwrite)", "metadata": {}}
{"_id": "mne_mne_bem.py_write_bem_solution_code", "title": "write_bem_solution", "text": "def write_bem_solution(fname, bem, overwrite=False, *, verbose=None):\n    \"\"\"Write a BEM model with solution.\n\n    Parameters\n    ----------\n    fname : path-like\n        The filename to use. Can end with ``.h5`` to write using HDF5.\n    bem : instance of ConductorModel\n        The BEM model with solution to save.\n    %(overwrite)s\n    %(verbose)s\n\n    See Also\n    --------\n    read_bem_solution\n    \"\"\"\n    fname = _check_fname(fname, overwrite=overwrite, name=\"fname\")\n    if fname.suffix == \".h5\":\n        _, write_hdf5 = _import_h5io_funcs()\n        bem = {k: bem[k] for k in (\"surfs\", \"solution\", \"bem_method\")}\n        write_hdf5(fname, bem, overwrite=True)\n    else:\n        _write_bem_solution_fif(fname, bem)", "metadata": {}}
{"_id": "mne_mne_bem.py_convert_flash_mris_code", "title": "convert_flash_mris", "text": "def convert_flash_mris(\n    subject, flash30=True, unwarp=False, subjects_dir=None, flash5=True, verbose=None\n):\n    \"\"\"Synthesize the flash 5 files for use with make_flash_bem.\n\n    This function aims to produce a synthesized flash 5 MRI from\n    multiecho flash (MEF) MRI data. This function can use MEF data\n    with 5 or 30 flip angles. If flash5 (and flash30) images are not\n    explicitly provided, it will assume that the different echos are available\n    in the mri/flash folder of the subject with the following naming\n    convention \"mef<angle>_<echo>.mgz\", e.g. \"mef05_001.mgz\"\n    or \"mef30_001.mgz\".\n\n    Parameters\n    ----------\n    %(subject)s\n    flash30 : bool | list of SpatialImage or path-like | SpatialImage | path-like\n        If False do not use 30-degree flip angle data.\n        The list of flash 5 echos to use. If True it will look for files\n        named mef30_*.mgz in the subject's mri/flash directory and if not False\n        the list of flash 5 echos images will be written to the mri/flash\n        folder with convention mef05_<echo>.mgz. If a SpatialImage object\n        each frame of the image will be interpreted as an echo.\n    unwarp : bool\n        Run grad_unwarp with -unwarp option on each of the converted\n        data sets. It requires FreeSurfer's MATLAB toolbox to be properly\n        installed.\n    %(subjects_dir)s\n    flash5 : list of SpatialImage or path-like | SpatialImage | path-like | True\n        The list of flash 5 echos to use. If True it will look for files\n        named mef05_*.mgz in the subject's mri/flash directory and if not None\n        the list of flash 5 echos images will be written to the mri/flash\n        folder with convention mef05_<echo>.mgz. If a SpatialImage object\n        each frame of the image will be interpreted as an echo.\n    %(verbose)s\n\n    Returns\n    -------\n    flash5_img : path-like\n        The path the synthesized flash 5 MRI.\n\n    Notes\n    -----\n    This function assumes that the Freesurfer segmentation of the subject\n    has been completed. In particular, the T1.mgz and brain.mgz MRI volumes\n    should be, as usual, in the subject's mri directory.\n    \"\"\"  # noqa: E501\n    env, mri_dir = _prepare_env(subject, subjects_dir)[:2]\n    tempdir = _TempDir()  # fsl and Freesurfer create some random junk in CWD\n    run_subprocess_env = partial(run_subprocess, env=env, cwd=tempdir)\n\n    mri_dir = Path(mri_dir)\n    # Step 1a : Data conversion to mgz format\n    flash_dir = mri_dir / \"flash\"\n    pm_dir = flash_dir / \"parameter_maps\"\n    pm_dir.mkdir(parents=True, exist_ok=True)\n    echos_done = 0\n\n    if not isinstance(flash5, bool):\n        _write_echos(mri_dir, flash5, angle=\"05\")\n    if not isinstance(flash30, bool):\n        _write_echos(mri_dir, flash30, angle=\"30\")\n\n    # Step 1b : Run grad_unwarp on converted files\n    template = op.join(flash_dir, \"mef*_*.mgz\")\n    files = sorted(glob.glob(template))\n    if len(files) == 0:\n        raise ValueError(f\"No suitable source files found ({template})\")\n    if unwarp:\n        logger.info(\"\\n---- Unwarp mgz data sets ----\")\n        for infile in files:\n            outfile = infile.replace(\".mgz\", \"u.mgz\")\n            cmd = [\"grad_unwarp\", \"-i\", infile, \"-o\", outfile, \"-unwarp\", \"true\"]\n            run_subprocess_env(cmd)\n    # Clear parameter maps if some of the data were reconverted\n    if echos_done > 0 and pm_dir.exists():\n        shutil.rmtree(pm_dir)\n        logger.info(\"\\nParameter maps directory cleared\")\n    if not pm_dir.exists():\n        pm_dir.mkdir(parents=True, exist_ok=True)\n    # Step 2 : Create the parameter maps\n    if flash30:\n        logger.info(\"\\n---- Creating the parameter maps ----\")\n        if unwarp:\n            files = sorted(glob.glob(op.join(flash_dir, \"mef05_*u.mgz\")))\n        if len(os.listdir(pm_dir)) == 0:\n            cmd = [\"mri_ms_fitparms\"] + files + [str(pm_dir)]\n            run_subprocess_env(cmd)\n        else:\n            logger.info(\"Parameter maps were already computed\")\n        # Step 3 : Synthesize the flash 5 images\n        logger.info(\"\\n---- Synthesizing flash 5 images ----\")\n        if not (pm_dir / \"flash5.mgz\").exists():\n            cmd = [\n                \"mri_synthesize\",\n                \"20\",\n                \"5\",\n                \"5\",\n                (pm_dir / \"T1.mgz\"),\n                (pm_dir / \"PD.mgz\"),\n                (pm_dir / \"flash5.mgz\"),\n            ]\n            run_subprocess_env(cmd)\n            (pm_dir / \"flash5_reg.mgz\").unlink(missing_ok=True)\n        else:\n            logger.info(\"Synthesized flash 5 volume is already there\")\n    else:\n        logger.info(\"\\n---- Averaging flash5 echoes ----\")\n        template = \"mef05_*u.mgz\" if unwarp else \"mef05_*.mgz\"\n        files = sorted(flash_dir.glob(template))\n        if len(files) == 0:\n            raise ValueError(f\"No suitable source files found ({template})\")\n        cmd = [\"mri_average\", \"-noconform\"] + files + [pm_dir / \"flash5.mgz\"]\n        run_subprocess_env(cmd)\n        (pm_dir / \"flash5_reg.mgz\").unlink(missing_ok=True)\n    del tempdir  # finally done running subprocesses\n    assert (pm_dir / \"flash5.mgz\").exists()\n    return pm_dir / \"flash5.mgz\"", "metadata": {}}
{"_id": "mne_mne_bem.py_make_flash_bem_code", "title": "make_flash_bem", "text": "def make_flash_bem(\n    subject,\n    overwrite=False,\n    show=True,\n    subjects_dir=None,\n    copy=True,\n    *,\n    flash5_img=None,\n    register=True,\n    verbose=None,\n):\n    \"\"\"Create 3-Layer BEM model from prepared flash MRI images.\n\n    See :ref:`bem_flash_algorithm` for additional information.\n\n    Parameters\n    ----------\n    %(subject)s\n    overwrite : bool\n        Write over existing .surf files in bem folder.\n    show : bool\n        Show surfaces to visually inspect all three BEM surfaces (recommended).\n    %(subjects_dir)s\n    copy : bool\n        If True (default), use copies instead of symlinks for surfaces\n        (if they do not already exist).\n\n        .. versionadded:: 0.18\n        .. versionchanged:: 1.1 Use copies instead of symlinks.\n    flash5_img : None | path-like | Nifti1Image\n        The path to the synthesized flash 5 MRI image or the image itself. If\n        None (default), the path defaults to\n        ``mri/flash/parameter_maps/flash5.mgz`` within the subject\n        reconstruction. If not present the image is copied or written to the\n        default location.\n\n        .. versionadded:: 1.1.0\n    register : bool\n        Register the flash 5 image with T1.mgz file. If False, we assume\n        that the images are already coregistered.\n\n        .. versionadded:: 1.1.0\n    %(verbose)s\n\n    See Also\n    --------\n    convert_flash_mris\n\n    Notes\n    -----\n    This program assumes that FreeSurfer is installed and sourced properly.\n\n    This function extracts the BEM surfaces (outer skull, inner skull, and\n    outer skin) from a FLASH 5 MRI image synthesized from multiecho FLASH\n    images acquired with spin angles of 5 and 30 degrees.\n    \"\"\"\n    env, mri_dir, bem_dir = _prepare_env(subject, subjects_dir)\n    tempdir = _TempDir()  # fsl and Freesurfer create some random junk in CWD\n    run_subprocess_env = partial(run_subprocess, env=env, cwd=tempdir)\n\n    mri_dir = Path(mri_dir)\n    bem_dir = Path(bem_dir)\n    subjects_dir = env[\"SUBJECTS_DIR\"]\n    flash_path = (mri_dir / \"flash\" / \"parameter_maps\").resolve()\n    flash_path.mkdir(exist_ok=True, parents=True)\n\n    logger.info(\n        \"\\nProcessing the flash MRI data to produce BEM meshes with the following \"\n        f\"parameters:\\nSUBJECTS_DIR = {subjects_dir}\\nSUBJECT = {subject}\\nResult dir =\"\n        f\"{bem_dir / 'flash'}\\n\"\n    )\n    # Step 4 : Register with MPRAGE\n    flash5 = flash_path / \"flash5.mgz\"\n\n    if _path_like(flash5_img):\n        logger.info(f\"Copying flash 5 image {flash5_img} to {flash5}\")\n        cmd = [\"mri_convert\", Path(flash5_img).resolve(), flash5]\n        run_subprocess_env(cmd)\n    elif flash5_img is None:\n        if not flash5.exists():\n            raise ValueError(f\"Flash 5 image cannot be found at {flash5}.\")\n    else:\n        logger.info(f\"Writing flash 5 image at {flash5}\")\n        nib = _import_nibabel(\"write an MRI image\")\n        nib.save(flash5_img, flash5)\n\n    if register:\n        logger.info(\"\\n---- Registering flash 5 with T1 MPRAGE ----\")\n        flash5_reg = flash_path / \"flash5_reg.mgz\"\n        if not flash5_reg.exists():\n            if (mri_dir / \"T1.mgz\").exists():\n                ref_volume = mri_dir / \"T1.mgz\"\n            else:\n                ref_volume = mri_dir / \"T1\"\n            cmd = [\n                \"fsl_rigid_register\",\n                \"-r\",\n                str(ref_volume),\n                \"-i\",\n                str(flash5),\n                \"-o\",\n                str(flash5_reg),\n            ]\n            run_subprocess_env(cmd)\n        else:\n            logger.info(\"Registered flash 5 image is already there\")\n    else:\n        flash5_reg = flash5\n\n    # Step 5a : Convert flash5 into COR\n    logger.info(\"\\n---- Converting flash5 volume into COR format ----\")\n    flash5_dir = mri_dir / \"flash5\"\n    shutil.rmtree(flash5_dir, ignore_errors=True)\n    flash5_dir.mkdir(exist_ok=True, parents=True)\n    cmd = [\"mri_convert\", flash5_reg, flash5_dir]\n    run_subprocess_env(cmd)\n    # Step 5b and c : Convert the mgz volumes into COR\n    convert_T1 = False\n    T1_dir = mri_dir / \"T1\"\n    if not T1_dir.is_dir() or next(T1_dir.glob(\"COR*\")) is None:\n        convert_T1 = True\n    convert_brain = False\n    brain_dir = mri_dir / \"brain\"\n    if not brain_dir.is_dir() or next(brain_dir.glob(\"COR*\")) is None:\n        convert_brain = True\n    logger.info(\"\\n---- Converting T1 volume into COR format ----\")\n    if convert_T1:\n        T1_fname = mri_dir / \"T1.mgz\"\n        if not T1_fname.is_file():\n            raise RuntimeError(\"Both T1 mgz and T1 COR volumes missing.\")\n        T1_dir.mkdir(exist_ok=True, parents=True)\n        cmd = [\"mri_convert\", T1_fname, T1_dir]\n        run_subprocess_env(cmd)\n    else:\n        logger.info(\"T1 volume is already in COR format\")\n    logger.info(\"\\n---- Converting brain volume into COR format ----\")\n    if convert_brain:\n        brain_fname = mri_dir / \"brain.mgz\"\n        if not brain_fname.is_file():\n            raise RuntimeError(\"Both brain mgz and brain COR volumes missing.\")\n        brain_dir.mkdir(exist_ok=True, parents=True)\n        cmd = [\"mri_convert\", brain_fname, brain_dir]\n        run_subprocess_env(cmd)\n    else:\n        logger.info(\"Brain volume is already in COR format\")\n    # Finally ready to go\n    logger.info(\"\\n---- Creating the BEM surfaces ----\")\n    cmd = [\"mri_make_bem_surfaces\", subject]\n    run_subprocess_env(cmd)\n    del tempdir  # ran our last subprocess; clean up directory\n\n    logger.info(\"\\n---- Converting the tri files into surf files ----\")\n    flash_bem_dir = bem_dir / \"flash\"\n    flash_bem_dir.mkdir(exist_ok=True, parents=True)\n    surfs = [\"inner_skull\", \"outer_skull\", \"outer_skin\"]\n    for surf in surfs:\n        out_fname = flash_bem_dir / (surf + \".tri\")\n        shutil.move(bem_dir / (surf + \".tri\"), out_fname)\n        nodes, tris = read_tri(out_fname, swap=True)\n        # Do not write volume info here because the tris are already in\n        # standard Freesurfer coords\n        write_surface(op.splitext(out_fname)[0] + \".surf\", nodes, tris, overwrite=True)\n\n    # Cleanup section\n    logger.info(\"\\n---- Cleaning up ----\")\n    (bem_dir / \"inner_skull_tmp.tri\").unlink()\n    if convert_T1:\n        shutil.rmtree(T1_dir)\n        logger.info(\"Deleted the T1 COR volume\")\n    if convert_brain:\n        shutil.rmtree(brain_dir)\n        logger.info(\"Deleted the brain COR volume\")\n    shutil.rmtree(flash5_dir)\n    logger.info(\"Deleted the flash5 COR volume\")\n    # Create symbolic links to the .surf files in the bem folder\n    logger.info(\"\\n---- Creating symbolic links ----\")\n    # os.chdir(bem_dir)\n    for surf in surfs:\n        surf = bem_dir / (surf + \".surf\")\n        if not overwrite and surf.exists():\n            skip_symlink = True\n        else:\n            if surf.exists():\n                surf.unlink()\n            _symlink(flash_bem_dir / surf.name, surf, copy)\n            skip_symlink = False\n    if skip_symlink:\n        logger.info(\n            \"Unable to create all symbolic links to .surf files \"\n            \"in bem folder. Use --overwrite option to recreate them.\"\n        )\n        dest = bem_dir / \"flash\"\n    else:\n        logger.info(\"Symbolic links to .surf files created in bem folder\")\n        dest = bem_dir\n    logger.info(\n        \"\\nThank you for waiting.\\nThe BEM triangulations for this \"\n        f\"subject are now available at:\\n{dest}.\\nWe hope the BEM meshes \"\n        \"created will facilitate your MEG and EEG data analyses.\"\n    )\n    # Show computed BEM surfaces\n    if show:\n        plot_bem(\n            subject=subject,\n            subjects_dir=subjects_dir,\n            orientation=\"coronal\",\n            slices=None,\n            show=True,\n        )", "metadata": {}}
{"_id": "mne_mne_bem.py_make_scalp_surfaces_code", "title": "make_scalp_surfaces", "text": "def make_scalp_surfaces(\n    subject,\n    subjects_dir=None,\n    force=True,\n    overwrite=False,\n    no_decimate=False,\n    *,\n    threshold=20,\n    mri=\"T1.mgz\",\n    verbose=None,\n):\n    \"\"\"Create surfaces of the scalp and neck.\n\n    The scalp surfaces are required for using the MNE coregistration GUI, and\n    allow for a visualization of the alignment between anatomy and channel\n    locations.\n\n    Parameters\n    ----------\n    %(subject)s\n    %(subjects_dir)s\n    force : bool\n        Force creation of the surface even if it has some topological defects.\n        Defaults to ``True``. See :ref:`tut-fix-meshes` for ideas on how to\n        fix problematic meshes.\n    %(overwrite)s\n    no_decimate : bool\n        Disable the \"medium\" and \"sparse\" decimations. In this case, only\n        a \"dense\" surface will be generated. Defaults to ``False``, i.e.,\n        create surfaces for all three types of decimations.\n    threshold : int\n        The threshold to use with the MRI in the call to ``mkheadsurf``.\n        The default is ``20``.\n\n        .. versionadded:: 1.1\n    mri : str\n        The MRI to use. Should exist in ``$SUBJECTS_DIR/$SUBJECT/mri``.\n\n        .. versionadded:: 1.1\n    %(verbose)s\n    \"\"\"\n    subjects_dir = get_subjects_dir(subjects_dir, raise_error=True)\n    incomplete = \"warn\" if force else \"raise\"\n    subj_path = subjects_dir / subject\n    if not subj_path.exists():\n        raise RuntimeError(\n            f\"{subj_path} does not exist. Please check your subject directory path.\"\n        )\n\n    # Backward compat for old FreeSurfer (?)\n    _validate_type(mri, str, \"mri\")\n    if mri == \"T1.mgz\":\n        mri = mri if (subj_path / \"mri\" / mri).exists() else \"T1\"\n\n    logger.info(\"1. Creating a dense scalp tessellation with mkheadsurf...\")\n\n    def check_seghead(surf_path=subj_path / \"surf\"):\n        surf = None\n        for k in [\"lh.seghead\", \"lh.smseghead\"]:\n            this_surf = surf_path / k\n            if this_surf.exists():\n                surf = this_surf\n                break\n        return surf\n\n    my_seghead = check_seghead()\n    threshold = _ensure_int(threshold, \"threshold\")\n    if my_seghead is None:\n        this_env = deepcopy(os.environ)\n        this_env[\"SUBJECTS_DIR\"] = str(subjects_dir)\n        this_env[\"SUBJECT\"] = subject\n        this_env[\"subjdir\"] = str(subj_path)\n        if \"FREESURFER_HOME\" not in this_env:\n            raise RuntimeError(\n                \"The FreeSurfer environment needs to be set up to use \"\n                \"make_scalp_surfaces to create the outer skin surface \"\n                \"lh.seghead\"\n            )\n        run_subprocess(\n            [\n                \"mkheadsurf\",\n                \"-subjid\",\n                subject,\n                \"-srcvol\",\n                mri,\n                \"-thresh1\",\n                str(threshold),\n                \"-thresh2\",\n                str(threshold),\n            ],\n            env=this_env,\n        )\n\n    surf = check_seghead()\n    if surf is None:\n        raise RuntimeError(\"mkheadsurf did not produce the standard output file.\")\n\n    bem_dir = subjects_dir / subject / \"bem\"\n    if not bem_dir.is_dir():\n        os.mkdir(bem_dir)\n    fname_template = bem_dir / (f\"{subject}-head-{{}}.fif\")\n    dense_fname = str(fname_template).format(\"dense\")\n    logger.info(f\"2. Creating {dense_fname} ...\")\n    _check_file(dense_fname, overwrite)\n    # Helpful message if we get a topology error\n    msg = (\n        \"\\n\\nConsider using pymeshfix directly to fix the mesh, or --force \"\n        \"to ignore the problem.\"\n    )\n    surf = _surfaces_to_bem(\n        [surf], [FIFF.FIFFV_BEM_SURF_ID_HEAD], [1], incomplete=incomplete, extra=msg\n    )[0]\n    write_bem_surfaces(dense_fname, surf, overwrite=overwrite)\n    if os.getenv(\"_MNE_TESTING_SCALP\", \"false\") == \"true\":\n        tris = [len(surf[\"tris\"])]  # don't actually decimate\n    for ii, (level, n_tri) in enumerate(_tri_levels.items(), 3):\n        if no_decimate:\n            break\n        logger.info(f\"{ii}. Creating {level} tessellation...\")\n        logger.info(\n            f\"{ii}.1 Decimating the dense tessellation \"\n            f\"({len(surf['tris'])} -> {n_tri} triangles)...\"\n        )\n        points, tris = decimate_surface(\n            points=surf[\"rr\"], triangles=surf[\"tris\"], n_triangles=n_tri\n        )\n        dec_fname = str(fname_template).format(level)\n        logger.info(f\"{ii}.2 Creating {dec_fname}\")\n        _check_file(dec_fname, overwrite)\n        dec_surf = _surfaces_to_bem(\n            [dict(rr=points, tris=tris)],\n            [FIFF.FIFFV_BEM_SURF_ID_HEAD],\n            [1],\n            rescale=False,\n            incomplete=incomplete,\n            extra=msg,\n        )\n        write_bem_surfaces(dec_fname, dec_surf, overwrite=overwrite)\n    logger.info(\"[done]\")", "metadata": {}}
{"_id": "mne_mne_bem.py_distance_to_bem_code", "title": "distance_to_bem", "text": "def distance_to_bem(pos, bem, trans=None, verbose=None):\n    \"\"\"Calculate the distance of positions to inner skull surface.\n\n    Parameters\n    ----------\n    pos : array, shape (..., 3)\n        Position(s) in m, in head coordinates.\n    bem : instance of ConductorModel\n        Conductor model.\n    %(trans)s If None (default), assumes bem is in head coordinates.\n\n        .. versionchanged:: 0.19\n            Support for 'fsaverage' argument.\n    %(verbose)s\n\n    Returns\n    -------\n    distances : float | array, shape (...)\n        The computed distance(s). A float is returned if pos is\n        an array of shape (3,) corresponding to a single position.\n\n    Notes\n    -----\n    .. versionadded:: 1.1\n    \"\"\"\n    ndim = pos.ndim\n    if ndim == 1:\n        pos = pos[np.newaxis, :]\n\n    n = pos.shape[0]\n    distance = np.zeros((n,))\n\n    logger.info(\n        \"Computing distance to inner skull surface for \" + f\"{n} position{_pl(n)}...\"\n    )\n\n    if bem[\"is_sphere\"]:\n        center = bem[\"r0\"]\n\n        if trans:\n            center = apply_trans(trans, center, move=True)\n        radius = bem[\"layers\"][0][\"rad\"]\n\n        distance = np.abs(radius - np.linalg.norm(pos - center, axis=1))\n\n    else:  # is BEM\n        surface_points = bem[\"surfs\"][0][\"rr\"]\n\n        if trans:\n            surface_points = apply_trans(trans, surface_points, move=True)\n\n        _, distance = _compute_nearest(surface_points, pos, return_dists=True)\n\n    if ndim == 1:\n        distance = distance[0]  # return just a float if one pos is passed\n\n    return distance", "metadata": {}}
{"_id": "mne_mne_bem.py_copy_code", "title": "copy", "text": "def copy(self):\n        \"\"\"Return copy of ConductorModel instance.\"\"\"\n        return deepcopy(self)", "metadata": {}}
{"_id": "mne_mne_bem.py_radius_code", "title": "radius", "text": "def radius(self):\n        \"\"\"Sphere radius if an EEG sphere model.\"\"\"\n        if not self[\"is_sphere\"]:\n            raise RuntimeError(\"radius undefined for BEM\")\n        return None if len(self[\"layers\"]) == 0 else self[\"layers\"][-1][\"rad\"]", "metadata": {}}
{"_id": "mne_mne_coreg.py_coregister_fiducials_code", "title": "coregister_fiducials", "text": "def coregister_fiducials(info, fiducials, tol=0.01):\n    \"\"\"Create a head-MRI transform by aligning 3 fiducial points.\n\n    Parameters\n    ----------\n    %(info_not_none)s\n    fiducials : path-like | list of dict\n        Fiducials in MRI coordinate space (either path to a ``*-fiducials.fif``\n        file or list of fiducials as returned by :func:`read_fiducials`.\n\n    Returns\n    -------\n    trans : Transform\n        The device-MRI transform.\n\n    .. note:: The :class:`mne.Info` object fiducials must be in the\n              head coordinate space.\n    \"\"\"\n    if isinstance(info, str):\n        info = read_info(info)\n    if isinstance(fiducials, str):\n        fiducials, coord_frame_to = read_fiducials(fiducials)\n    else:\n        coord_frame_to = FIFF.FIFFV_COORD_MRI\n    frames_from = {d[\"coord_frame\"] for d in info[\"dig\"]}\n    if len(frames_from) > 1:\n        raise ValueError(\"info contains fiducials from different coordinate frames\")\n    else:\n        coord_frame_from = frames_from.pop()\n    coords_from = _fiducial_coords(info[\"dig\"])\n    coords_to = _fiducial_coords(fiducials, coord_frame_to)\n    trans = fit_matched_points(coords_from, coords_to, tol=tol)\n    return Transform(coord_frame_from, coord_frame_to, trans)", "metadata": {}}
{"_id": "mne_mne_coreg.py_create_default_subject_code", "title": "create_default_subject", "text": "def create_default_subject(fs_home=None, update=False, subjects_dir=None, verbose=None):\n    \"\"\"Create an average brain subject for subjects without structural MRI.\n\n    Create a copy of fsaverage from the FreeSurfer directory in subjects_dir\n    and add auxiliary files from the mne package.\n\n    Parameters\n    ----------\n    fs_home : None | str\n        The FreeSurfer home directory (only needed if ``FREESURFER_HOME`` is\n        not specified as environment variable).\n    update : bool\n        In cases where a copy of the fsaverage brain already exists in the\n        subjects_dir, this option allows to only copy files that don't already\n        exist in the fsaverage directory.\n    subjects_dir : None | path-like\n        Override the ``SUBJECTS_DIR`` environment variable\n        (``os.environ['SUBJECTS_DIR']``) as destination for the new subject.\n    %(verbose)s\n\n    Notes\n    -----\n    When no structural MRI is available for a subject, an average brain can be\n    substituted. FreeSurfer comes with such an average brain model, and MNE\n    comes with some auxiliary files which make coregistration easier.\n    :py:func:`create_default_subject` copies the relevant\n    files from FreeSurfer into the current subjects_dir, and also adds the\n    auxiliary files provided by MNE.\n    \"\"\"\n    subjects_dir = str(get_subjects_dir(subjects_dir, raise_error=True))\n    if fs_home is None:\n        fs_home = get_config(\"FREESURFER_HOME\", fs_home)\n        if fs_home is None:\n            raise ValueError(\n                \"FREESURFER_HOME environment variable not found. Please \"\n                \"specify the fs_home parameter in your call to \"\n                \"create_default_subject().\"\n            )\n\n    # make sure FreeSurfer files exist\n    fs_src = os.path.join(fs_home, \"subjects\", \"fsaverage\")\n    if not os.path.exists(fs_src):\n        raise OSError(\n            f\"fsaverage not found at {fs_src!r}. Is fs_home specified correctly?\"\n        )\n    for name in (\"label\", \"mri\", \"surf\"):\n        dirname = os.path.join(fs_src, name)\n        if not os.path.isdir(dirname):\n            raise OSError(\n                \"FreeSurfer fsaverage seems to be incomplete: No directory named \"\n                f\"{name} found in {fs_src}\"\n            )\n\n    # make sure destination does not already exist\n    dest = os.path.join(subjects_dir, \"fsaverage\")\n    if dest == fs_src:\n        raise OSError(\n            \"Your subjects_dir points to the FreeSurfer subjects_dir \"\n            f\"({repr(subjects_dir)}). The default subject can not be created in the \"\n            \"FreeSurfer installation directory; please specify a different \"\n            \"subjects_dir.\"\n        )\n    elif (not update) and os.path.exists(dest):\n        raise OSError(\n            'Can not create fsaverage because \"fsaverage\" already exists in '\n            f\"subjects_dir {repr(subjects_dir)}. Delete or rename the existing \"\n            \"fsaverage subject folder.\"\n        )\n\n    # copy fsaverage from FreeSurfer\n    logger.info(\"Copying fsaverage subject from FreeSurfer directory...\")\n    if (not update) or not os.path.exists(dest):\n        shutil.copytree(fs_src, dest)\n        _make_writable_recursive(dest)\n\n    # copy files from mne\n    source_fname = os.path.join(\n        os.path.dirname(__file__), \"data\", \"fsaverage\", \"fsaverage-%s.fif\"\n    )\n    dest_bem = os.path.join(dest, \"bem\")\n    if not os.path.exists(dest_bem):\n        os.mkdir(dest_bem)\n    logger.info(\"Copying auxiliary fsaverage files from mne...\")\n    dest_fname = os.path.join(dest_bem, \"fsaverage-%s.fif\")\n    _make_writable_recursive(dest_bem)\n    for name in (\"fiducials\", \"head\", \"inner_skull-bem\", \"trans\"):\n        if not os.path.exists(dest_fname % name):\n            shutil.copy(source_fname % name, dest_bem)", "metadata": {}}
{"_id": "mne_mne_coreg.py_fit_matched_points_code", "title": "fit_matched_points", "text": "def fit_matched_points(\n    src_pts,\n    tgt_pts,\n    rotate=True,\n    translate=True,\n    scale=False,\n    tol=None,\n    x0=None,\n    out=\"trans\",\n    weights=None,\n):\n    \"\"\"Find a transform between matched sets of points.\n\n    This minimizes the squared distance between two matching sets of points.\n\n    Uses :func:`scipy.optimize.leastsq` to find a transformation involving\n    a combination of rotation, translation, and scaling (in that order).\n\n    Parameters\n    ----------\n    src_pts : array, shape = (n, 3)\n        Points to which the transform should be applied.\n    tgt_pts : array, shape = (n, 3)\n        Points to which src_pts should be fitted. Each point in tgt_pts should\n        correspond to the point in src_pts with the same index.\n    rotate : bool\n        Allow rotation of the ``src_pts``.\n    translate : bool\n        Allow translation of the ``src_pts``.\n    scale : bool\n        Number of scaling parameters. With False, points are not scaled. With\n        True, points are scaled by the same factor along all axes.\n    tol : scalar | None\n        The error tolerance. If the distance between any of the matched points\n        exceeds this value in the solution, a RuntimeError is raised. With\n        None, no error check is performed.\n    x0 : None | tuple\n        Initial values for the fit parameters.\n    out : 'params' | 'trans'\n        In what format to return the estimate: 'params' returns a tuple with\n        the fit parameters; 'trans' returns a transformation matrix of shape\n        (4, 4).\n\n    Returns\n    -------\n    trans : array, shape (4, 4)\n        Transformation that, if applied to src_pts, minimizes the squared\n        distance to tgt_pts. Only returned if out=='trans'.\n    params : array, shape (n_params, )\n        A single tuple containing the rotation, translation, and scaling\n        parameters in that order (as applicable).\n    \"\"\"\n    src_pts = np.atleast_2d(src_pts)\n    tgt_pts = np.atleast_2d(tgt_pts)\n    if src_pts.shape != tgt_pts.shape:\n        raise ValueError(\n            \"src_pts and tgt_pts must have same shape \"\n            f\"(got {src_pts.shape}, {tgt_pts.shape})\"\n        )\n    if weights is not None:\n        weights = np.asarray(weights, src_pts.dtype)\n        if weights.ndim != 1 or weights.size not in (src_pts.shape[0], 1):\n            raise ValueError(\n                f\"weights (shape={weights.shape}) must be None or have shape \"\n                f\"({src_pts.shape[0]},)\"\n            )\n        weights = weights[:, np.newaxis]\n\n    param_info = (bool(rotate), bool(translate), int(scale))\n    del rotate, translate, scale\n\n    # very common use case, rigid transformation (maybe with one scale factor,\n    # with or without weighted errors)\n    if param_info in ((True, True, 0), (True, True, 1)) and _ALLOW_ANALITICAL:\n        src_pts = np.asarray(src_pts, float)\n        tgt_pts = np.asarray(tgt_pts, float)\n        if weights is not None:\n            weights = np.asarray(weights, float)\n        x, s = _fit_matched_points(src_pts, tgt_pts, weights, bool(param_info[2]))\n        x[:3] = _quat_to_euler(x[:3])\n        x = np.concatenate((x, [s])) if param_info[2] else x\n    else:\n        x = _generic_fit(src_pts, tgt_pts, param_info, weights, x0)\n\n    # re-create the final transformation matrix\n    if (tol is not None) or (out == \"trans\"):\n        trans = _trans_from_params(param_info, x)\n\n    # assess the error of the solution\n    if tol is not None:\n        src_pts = np.hstack((src_pts, np.ones((len(src_pts), 1))))\n        est_pts = np.dot(src_pts, trans.T)[:, :3]\n        err = np.sqrt(np.sum((est_pts - tgt_pts) ** 2, axis=1))\n        if np.any(err > tol):\n            raise RuntimeError(f\"Error exceeds tolerance. Error = {err!r}\")\n\n    if out == \"params\":\n        return x\n    elif out == \"trans\":\n        return trans\n    else:\n        raise ValueError(\n            f\"Invalid out parameter: {out!r}. Needs to be 'params' or 'trans'.\"\n        )", "metadata": {}}
{"_id": "mne_mne_coreg.py_read_mri_cfg_code", "title": "read_mri_cfg", "text": "def read_mri_cfg(subject, subjects_dir=None):\n    \"\"\"Read information from the cfg file of a scaled MRI brain.\n\n    Parameters\n    ----------\n    subject : str\n        Name of the scaled MRI subject.\n    subjects_dir : None | path-like\n        Override the ``SUBJECTS_DIR`` environment variable.\n\n    Returns\n    -------\n    cfg : dict\n        Dictionary with entries from the MRI's cfg file.\n    \"\"\"\n    subjects_dir = get_subjects_dir(subjects_dir, raise_error=True)\n    fname = subjects_dir / subject / \"MRI scaling parameters.cfg\"\n\n    if not fname.exists():\n        raise OSError(\n            f\"{subject!r} does not seem to be a scaled mri subject: {fname!r} does not\"\n            \"exist.\"\n        )\n\n    logger.info(f\"Reading MRI cfg file {fname}\")\n    config = configparser.RawConfigParser()\n    config.read(fname)\n    n_params = config.getint(\"MRI Scaling\", \"n_params\")\n    if n_params == 1:\n        scale = config.getfloat(\"MRI Scaling\", \"scale\")\n    elif n_params == 3:\n        scale_str = config.get(\"MRI Scaling\", \"scale\")\n        scale = np.array([float(s) for s in scale_str.split()])\n    else:\n        raise ValueError(f\"Invalid n_params value in MRI cfg: {n_params}\")\n\n    out = {\n        \"subject_from\": config.get(\"MRI Scaling\", \"subject_from\"),\n        \"n_params\": n_params,\n        \"scale\": scale,\n    }\n    return out", "metadata": {}}
{"_id": "mne_mne_coreg.py_scale_bem_code", "title": "scale_bem", "text": "def scale_bem(\n    subject_to,\n    bem_name,\n    subject_from=None,\n    scale=None,\n    subjects_dir=None,\n    *,\n    on_defects=\"raise\",\n    verbose=None,\n):\n    \"\"\"Scale a bem file.\n\n    Parameters\n    ----------\n    subject_to : str\n        Name of the scaled MRI subject (the destination mri subject).\n    bem_name : str\n        Name of the bem file. For example, to scale\n        ``fsaverage-inner_skull-bem.fif``, the bem_name would be\n        \"inner_skull-bem\".\n    subject_from : None | str\n        The subject from which to read the source space. If None, subject_from\n        is read from subject_to's config file.\n    scale : None | float | array, shape = (3,)\n        Scaling factor. Has to be specified if subjects_from is specified,\n        otherwise it is read from subject_to's config file.\n    subjects_dir : None | str\n        Override the SUBJECTS_DIR environment variable.\n    %(on_defects)s\n\n        .. versionadded:: 1.0\n    %(verbose)s\n    \"\"\"\n    subjects_dir, subject_from, scale, uniform = _scale_params(\n        subject_to, subject_from, scale, subjects_dir\n    )\n\n    src = bem_fname.format(\n        subjects_dir=subjects_dir, subject=subject_from, name=bem_name\n    )\n    dst = bem_fname.format(subjects_dir=subjects_dir, subject=subject_to, name=bem_name)\n\n    if os.path.exists(dst):\n        raise OSError(f\"File already exists: {dst}\")\n\n    surfs = read_bem_surfaces(src, on_defects=on_defects)\n    for surf in surfs:\n        surf[\"rr\"] *= scale\n        if not uniform:\n            assert len(surf[\"nn\"]) > 0\n            surf[\"nn\"] /= scale\n            _normalize_vectors(surf[\"nn\"])\n    write_bem_surfaces(dst, surfs)", "metadata": {}}
{"_id": "mne_mne_coreg.py_scale_labels_code", "title": "scale_labels", "text": "def scale_labels(\n    subject_to,\n    pattern=None,\n    overwrite=False,\n    subject_from=None,\n    scale=None,\n    subjects_dir=None,\n):\n    r\"\"\"Scale labels to match a brain that was previously created by scaling.\n\n    Parameters\n    ----------\n    subject_to : str\n        Name of the scaled MRI subject (the destination brain).\n    pattern : str | None\n        Pattern for finding the labels relative to the label directory in the\n        MRI subject directory (e.g., \"lh.BA3a.label\" will scale\n        \"fsaverage/label/lh.BA3a.label\"; \"aparc/\\*.label\" will find all labels\n        in the \"fsaverage/label/aparc\" directory). With None, scale all labels.\n    overwrite : bool\n        Overwrite any label file that already exists for subject_to (otherwise\n        existing labels are skipped).\n    subject_from : None | str\n        Name of the original MRI subject (the brain that was scaled to create\n        subject_to). If None, the value is read from subject_to's cfg file.\n    scale : None | float | array_like, shape = (3,)\n        Scaling parameter. If None, the value is read from subject_to's cfg\n        file.\n    subjects_dir : None | path-like\n        Override the ``SUBJECTS_DIR`` environment variable.\n    \"\"\"\n    subjects_dir, subject_from, scale, _ = _scale_params(\n        subject_to, subject_from, scale, subjects_dir\n    )\n\n    # find labels\n    paths = _find_label_paths(subject_from, pattern, subjects_dir)\n    if not paths:\n        return\n\n    subjects_dir = get_subjects_dir(subjects_dir, raise_error=True)\n    src_root = subjects_dir / subject_from / \"label\"\n    dst_root = subjects_dir / subject_to / \"label\"\n\n    # scale labels\n    for fname in paths:\n        dst = dst_root / fname\n        if not overwrite and dst.exists():\n            continue\n\n        if not dst.parent.exists():\n            os.makedirs(dst.parent)\n\n        src = src_root / fname\n        l_old = read_label(src)\n        pos = l_old.pos * scale\n        l_new = Label(\n            l_old.vertices,\n            pos,\n            l_old.values,\n            l_old.hemi,\n            l_old.comment,\n            subject=subject_to,\n        )\n        l_new.save(dst)", "metadata": {}}
{"_id": "mne_mne_coreg.py_scale_mri_code", "title": "scale_mri", "text": "def scale_mri(\n    subject_from,\n    subject_to,\n    scale,\n    overwrite=False,\n    subjects_dir=None,\n    skip_fiducials=False,\n    labels=True,\n    annot=False,\n    *,\n    on_defects=\"raise\",\n    verbose=None,\n):\n    \"\"\"Create a scaled copy of an MRI subject.\n\n    Parameters\n    ----------\n    subject_from : str\n        Name of the subject providing the MRI.\n    subject_to : str\n        New subject name for which to save the scaled MRI.\n    scale : float | array_like, shape = (3,)\n        The scaling factor (one or 3 parameters).\n    overwrite : bool\n        If an MRI already exists for subject_to, overwrite it.\n    subjects_dir : None | path-like\n        Override the ``SUBJECTS_DIR`` environment variable.\n    skip_fiducials : bool\n        Do not scale the MRI fiducials. If False (default), an OSError will be\n        raised if no fiducials file can be found.\n    labels : bool\n        Also scale all labels (default True).\n    annot : bool\n        Copy ``*.annot`` files to the new location (default False).\n    %(on_defects)s\n\n        .. versionadded:: 1.0\n    %(verbose)s\n\n    See Also\n    --------\n    scale_bem : Add a scaled BEM to a scaled MRI.\n    scale_labels : Add labels to a scaled MRI.\n    scale_source_space : Add a source space to a scaled MRI.\n\n    Notes\n    -----\n    This function will automatically call :func:`scale_bem`,\n    :func:`scale_labels`, and :func:`scale_source_space` based on expected\n    filename patterns in the subject directory.\n    \"\"\"\n    subjects_dir = str(get_subjects_dir(subjects_dir, raise_error=True))\n    paths = _find_mri_paths(subject_from, skip_fiducials, subjects_dir)\n    scale = np.atleast_1d(scale)\n    if scale.shape == (3,):\n        if np.isclose(scale[1], scale[0]) and np.isclose(scale[2], scale[0]):\n            scale = scale[0]  # speed up scaling conditionals using a singleton\n    elif scale.shape != (1,):\n        raise ValueError(f\"scale must have shape (3,) or (1,), got {scale.shape}\")\n\n    # make sure we have an empty target directory\n    dest = subject_dirname.format(subject=subject_to, subjects_dir=subjects_dir)\n    if os.path.exists(dest):\n        if not overwrite:\n            raise OSError(\n                f\"Subject directory for {subject_to} already exists: {dest!r}\"\n            )\n        shutil.rmtree(dest)\n\n    logger.debug(\"create empty directory structure\")\n    for dirname in paths[\"dirs\"]:\n        dir_ = dirname.format(subject=subject_to, subjects_dir=subjects_dir)\n        os.makedirs(dir_)\n\n    logger.debug(\"save MRI scaling parameters\")\n    fname = os.path.join(dest, \"MRI scaling parameters.cfg\")\n    _write_mri_config(fname, subject_from, subject_to, scale)\n\n    logger.debug(\"surf files [in mm]\")\n    for fname in paths[\"surf\"]:\n        src = fname.format(subject=subject_from, subjects_dir=subjects_dir)\n        src = os.path.realpath(src)\n        dest = fname.format(subject=subject_to, subjects_dir=subjects_dir)\n        pts, tri = read_surface(src)\n        write_surface(dest, pts * scale, tri)\n\n    logger.debug(\"BEM files [in m]\")\n    for bem_name in paths[\"bem\"]:\n        scale_bem(\n            subject_to,\n            bem_name,\n            subject_from,\n            scale,\n            subjects_dir,\n            on_defects=on_defects,\n            verbose=False,\n        )\n\n    logger.debug(\"fiducials [in m]\")\n    for fname in paths[\"fid\"]:\n        src = fname.format(subject=subject_from, subjects_dir=subjects_dir)\n        src = os.path.realpath(src)\n        pts, cframe = read_fiducials(src, verbose=False)\n        for pt in pts:\n            pt[\"r\"] = pt[\"r\"] * scale\n        dest = fname.format(subject=subject_to, subjects_dir=subjects_dir)\n        write_fiducials(dest, pts, cframe, overwrite=True, verbose=False)\n\n    logger.debug(\"MRIs [nibabel]\")\n    os.mkdir(mri_dirname.format(subjects_dir=subjects_dir, subject=subject_to))\n    for fname in paths[\"mri\"]:\n        mri_name = os.path.basename(fname)\n        _scale_mri(subject_to, mri_name, subject_from, scale, subjects_dir)\n\n    logger.debug(\"Transforms\")\n    for mri_name in paths[\"mri\"]:\n        if mri_name.endswith(\"T1.mgz\"):\n            os.mkdir(\n                mri_transforms_dirname.format(\n                    subjects_dir=subjects_dir, subject=subject_to\n                )\n            )\n            for fname in paths[\"transforms\"]:\n                xfm_name = os.path.basename(fname)\n                _scale_xfm(\n                    subject_to, xfm_name, mri_name, subject_from, scale, subjects_dir\n                )\n            break\n\n    logger.debug(\"duplicate files\")\n    for fname in paths[\"duplicate\"]:\n        src = fname.format(subject=subject_from, subjects_dir=subjects_dir)\n        dest = fname.format(subject=subject_to, subjects_dir=subjects_dir)\n        shutil.copyfile(src, dest)\n\n    logger.debug(\"source spaces\")\n    for fname in paths[\"src\"]:\n        src_name = os.path.basename(fname)\n        scale_source_space(\n            subject_to, src_name, subject_from, scale, subjects_dir, verbose=False\n        )\n\n    logger.debug(\"labels [in m]\")\n    os.mkdir(os.path.join(subjects_dir, subject_to, \"label\"))\n    if labels:\n        scale_labels(\n            subject_to,\n            subject_from=subject_from,\n            scale=scale,\n            subjects_dir=subjects_dir,\n        )\n\n    logger.debug(\"copy *.annot files\")\n    # they don't contain scale-dependent information\n    if annot:\n        src_pattern = os.path.join(subjects_dir, subject_from, \"label\", \"*.annot\")\n        dst_dir = os.path.join(subjects_dir, subject_to, \"label\")\n        for src_file in iglob(src_pattern):\n            shutil.copy(src_file, dst_dir)", "metadata": {}}
{"_id": "mne_mne_coreg.py_scale_source_space_code", "title": "scale_source_space", "text": "def scale_source_space(\n    subject_to,\n    src_name,\n    subject_from=None,\n    scale=None,\n    subjects_dir=None,\n    n_jobs=None,\n    verbose=None,\n):\n    \"\"\"Scale a source space for an mri created with scale_mri().\n\n    Parameters\n    ----------\n    subject_to : str\n        Name of the scaled MRI subject (the destination mri subject).\n    src_name : str\n        Source space name. Can be a spacing parameter (e.g., ``'7'``,\n        ``'ico4'``, ``'oct6'``) or a file name of a source space file relative\n        to the bem directory; if the file name contains the subject name, it\n        should be indicated as \"{subject}\" in ``src_name`` (e.g.,\n        ``\"{subject}-my_source_space-src.fif\"``).\n    subject_from : None | str\n        The subject from which to read the source space. If None, subject_from\n        is read from subject_to's config file.\n    scale : None | float | array, shape = (3,)\n        Scaling factor. Has to be specified if subjects_from is specified,\n        otherwise it is read from subject_to's config file.\n    subjects_dir : None | str\n        Override the SUBJECTS_DIR environment variable.\n    n_jobs : int\n        Number of jobs to run in parallel if recomputing distances (only\n        applies if scale is an array of length 3, and will not use more cores\n        than there are source spaces).\n    %(verbose)s\n\n    Notes\n    -----\n    When scaling volume source spaces, the source (vertex) locations are\n    scaled, but the reference to the MRI volume is left unchanged. Transforms\n    are updated so that source estimates can be plotted on the original MRI\n    volume.\n    \"\"\"\n    subjects_dir, subject_from, scale, uniform = _scale_params(\n        subject_to, subject_from, scale, subjects_dir\n    )\n    # if n_params==1 scale is a scalar; if n_params==3 scale is a (3,) array\n\n    # find the source space file names\n    if src_name.isdigit():\n        spacing = src_name  # spacing in mm\n        src_pattern = src_fname\n    else:\n        match = re.match(r\"(oct|ico|vol)-?(\\d+)$\", src_name)\n        if match:\n            spacing = \"-\".join(match.groups())\n            src_pattern = src_fname\n        else:\n            spacing = None\n            src_pattern = os.path.join(bem_dirname, src_name)\n\n    src = src_pattern.format(\n        subjects_dir=subjects_dir, subject=subject_from, spacing=spacing\n    )\n    dst = src_pattern.format(\n        subjects_dir=subjects_dir, subject=subject_to, spacing=spacing\n    )\n\n    # read and scale the source space [in m]\n    sss = read_source_spaces(src)\n    logger.info(\"scaling source space %s:  %s -> %s\", spacing, subject_from, subject_to)\n    logger.info(\"Scale factor: %s\", scale)\n    add_dist = False\n    for ss in sss:\n        ss[\"subject_his_id\"] = subject_to\n        ss[\"rr\"] *= scale\n        # additional tags for volume source spaces\n        for key in (\"vox_mri_t\", \"src_mri_t\"):\n            # maintain transform to original MRI volume ss['mri_volume_name']\n            if key in ss:\n                ss[key][\"trans\"][:3] *= scale[:, np.newaxis]\n        # distances and patch info\n        if uniform:\n            if ss[\"dist\"] is not None:\n                ss[\"dist\"] *= scale[0]\n                # Sometimes this is read-only due to how it's read\n                ss[\"nearest_dist\"] = ss[\"nearest_dist\"] * scale\n                ss[\"dist_limit\"] = ss[\"dist_limit\"] * scale\n        else:  # non-uniform scaling\n            ss[\"nn\"] /= scale\n            _normalize_vectors(ss[\"nn\"])\n            if ss[\"dist\"] is not None:\n                add_dist = True\n                dist_limit = float(np.abs(sss[0][\"dist_limit\"]))\n            elif ss[\"nearest\"] is not None:\n                add_dist = True\n                dist_limit = 0\n\n    if add_dist:\n        logger.info(\"Recomputing distances, this might take a while\")\n        add_source_space_distances(sss, dist_limit, n_jobs)\n\n    write_source_spaces(dst, sss)", "metadata": {}}
{"_id": "mne_mne_coreg.py_set_scale_mode_code", "title": "set_scale_mode", "text": "def set_scale_mode(self, scale_mode):\n        \"\"\"Select how to fit the scale parameters.\n\n        Parameters\n        ----------\n        scale_mode : None | str\n            The scale mode can be 'uniform', '3-axis' or disabled.\n            Defaults to None.\n\n            * 'uniform': 1 scale factor is recovered.\n            * '3-axis': 3 scale factors are recovered.\n            * None: do not scale the MRI.\n\n        Returns\n        -------\n        self : Coregistration\n            The modified Coregistration object.\n        \"\"\"\n        self._scale_mode = scale_mode\n        return self", "metadata": {}}
{"_id": "mne_mne_coreg.py_set_grow_hair_code", "title": "set_grow_hair", "text": "def set_grow_hair(self, value):\n        \"\"\"Compensate for hair on the digitizer head shape.\n\n        Parameters\n        ----------\n        value : float\n            Move the back of the MRI head outwards by ``value`` (mm).\n\n        Returns\n        -------\n        self : Coregistration\n            The modified Coregistration object.\n        \"\"\"\n        self._grow_hair = value\n        self._update_params(force_update=True)\n        return self", "metadata": {}}
{"_id": "mne_mne_coreg.py_set_rotation_code", "title": "set_rotation", "text": "def set_rotation(self, rot):\n        \"\"\"Set the rotation parameter.\n\n        Parameters\n        ----------\n        rot : array, shape (3,)\n            The rotation parameter (in radians).\n\n        Returns\n        -------\n        self : Coregistration\n            The modified Coregistration object.\n        \"\"\"\n        self._update_params(rot=np.array(rot))\n        return self", "metadata": {}}
{"_id": "mne_mne_coreg.py_set_translation_code", "title": "set_translation", "text": "def set_translation(self, tra):\n        \"\"\"Set the translation parameter.\n\n        Parameters\n        ----------\n        tra : array, shape (3,)\n            The translation parameter (in m.).\n\n        Returns\n        -------\n        self : Coregistration\n            The modified Coregistration object.\n        \"\"\"\n        self._update_params(tra=np.array(tra))\n        return self", "metadata": {}}
{"_id": "mne_mne_coreg.py_set_scale_code", "title": "set_scale", "text": "def set_scale(self, sca):\n        \"\"\"Set the scale parameter.\n\n        Parameters\n        ----------\n        sca : array, shape (3,)\n            The scale parameter.\n\n        Returns\n        -------\n        self : Coregistration\n            The modified Coregistration object.\n        \"\"\"\n        self._update_params(sca=np.array(sca))\n        return self", "metadata": {}}
{"_id": "mne_mne_coreg.py_scale_code", "title": "scale", "text": "def scale(self):\n        \"\"\"Get the current scale factor.\n\n        Returns\n        -------\n        scale : ndarray, shape (3,)\n            The scale factors.\n        \"\"\"\n        return self._scale.copy()", "metadata": {}}
{"_id": "mne_mne_coreg.py_fit_fiducials_code", "title": "fit_fiducials", "text": "def fit_fiducials(\n        self, lpa_weight=1.0, nasion_weight=10.0, rpa_weight=1.0, verbose=None\n    ):\n        \"\"\"Find rotation and translation to fit all 3 fiducials.\n\n        Parameters\n        ----------\n        lpa_weight : float\n            Relative weight for LPA. The default value is 1.\n        nasion_weight : float\n            Relative weight for nasion. The default value is 10.\n        rpa_weight : float\n            Relative weight for RPA. The default value is 1.\n        %(verbose)s\n\n        Returns\n        -------\n        self : Coregistration\n            The modified Coregistration object.\n        \"\"\"\n        logger.info(\"Aligning using fiducials\")\n        self._log_dig_mri_distance(\"Start\")\n        n_scale_params = self._n_scale_params\n        if n_scale_params == 3:\n            # enforce 1 even for 3-axis here (3 points is not enough)\n            logger.info(\"Enforcing 1 scaling parameter for fit with fiducials.\")\n            n_scale_params = 1\n        self._lpa_weight = lpa_weight\n        self._nasion_weight = nasion_weight\n        self._rpa_weight = rpa_weight\n\n        head_pts = np.vstack(\n            (self._dig_dict[\"lpa\"], self._dig_dict[\"nasion\"], self._dig_dict[\"rpa\"])\n        )\n        mri_pts = np.vstack(\n            (\n                self.fiducials.dig[0][\"r\"],  # LPA\n                self.fiducials.dig[1][\"r\"],  # Nasion\n                self.fiducials.dig[2][\"r\"],\n            )  # RPA\n        )\n        weights = [lpa_weight, nasion_weight, rpa_weight]\n\n        if n_scale_params == 0:\n            mri_pts *= self._scale  # not done in fit_matched_points\n        x0 = self._parameters\n        x0 = x0[: 6 + n_scale_params]\n        est = fit_matched_points(\n            mri_pts,\n            head_pts,\n            x0=x0,\n            out=\"params\",\n            scale=n_scale_params,\n            weights=weights,\n        )\n        if n_scale_params == 0:\n            self._update_params(rot=est[:3], tra=est[3:6])\n        else:\n            assert est.size == 7\n            est = np.concatenate([est, [est[-1]] * 2])\n            assert est.size == 9\n            self._update_params(rot=est[:3], tra=est[3:6], sca=est[6:9])\n        self._log_dig_mri_distance(\"End  \")\n        return self", "metadata": {}}
{"_id": "mne_mne_coreg.py_set_fid_match_code", "title": "set_fid_match", "text": "def set_fid_match(self, match):\n        \"\"\"Set the strategy for fitting anatomical landmark (fiducial) points.\n\n        Parameters\n        ----------\n        match : 'nearest' | 'matched'\n            Alignment strategy; ``'nearest'`` aligns anatomical landmarks to\n            any point on the head surface; ``'matched'`` aligns to the fiducial\n            points in the MRI.\n\n        Returns\n        -------\n        self : Coregistration\n            The modified Coregistration object.\n        \"\"\"\n        _check_option(\"match\", match, self._icp_fid_matches)\n        self._icp_fid_match = match\n        return self", "metadata": {}}
{"_id": "mne_mne_coreg.py_fit_icp_code", "title": "fit_icp", "text": "def fit_icp(\n        self,\n        n_iterations=20,\n        lpa_weight=1.0,\n        nasion_weight=10.0,\n        rpa_weight=1.0,\n        hsp_weight=1.0,\n        eeg_weight=1.0,\n        hpi_weight=1.0,\n        callback=None,\n        verbose=None,\n    ):\n        \"\"\"Find MRI scaling, translation, and rotation to match HSP.\n\n        Parameters\n        ----------\n        n_iterations : int\n            Maximum number of iterations.\n        lpa_weight : float\n            Relative weight for LPA. The default value is 1.\n        nasion_weight : float\n            Relative weight for nasion. The default value is 10.\n        rpa_weight : float\n            Relative weight for RPA. The default value is 1.\n        hsp_weight : float\n            Relative weight for HSP. The default value is 1.\n        eeg_weight : float\n            Relative weight for EEG. The default value is 1.\n        hpi_weight : float\n            Relative weight for HPI. The default value is 1.\n        callback : callable | None\n            A function to call on each iteration. Useful for status message\n            updates. It will be passed the keyword arguments ``iteration``\n            and ``n_iterations``.\n        %(verbose)s\n\n        Returns\n        -------\n        self : Coregistration\n            The modified Coregistration object.\n        \"\"\"\n        logger.info(\"Aligning using ICP\")\n        self._log_dig_mri_distance(\"Start    \")\n        n_scale_params = self._n_scale_params\n        self._lpa_weight = lpa_weight\n        self._nasion_weight = nasion_weight\n        self._rpa_weight = rpa_weight\n        self._hsp_weight = hsp_weight\n        self._eeg_weight = eeg_weight\n        self._hsp_weight = hpi_weight\n\n        # Initial guess (current state)\n        est = self._parameters\n        est = est[: [6, 7, None, 9][n_scale_params]]\n\n        # Do the fits, assigning and evaluating at each step\n        for iteration in range(n_iterations):\n            head_pts, mri_pts, weights = self._setup_icp(n_scale_params)\n            est = fit_matched_points(\n                mri_pts,\n                head_pts,\n                scale=n_scale_params,\n                x0=est,\n                out=\"params\",\n                weights=weights,\n            )\n            if n_scale_params == 0:\n                self._update_params(rot=est[:3], tra=est[3:6])\n            elif n_scale_params == 1:\n                est = np.array(list(est) + [est[-1]] * 2)\n                self._update_params(rot=est[:3], tra=est[3:6], sca=est[6:9])\n            else:\n                self._update_params(rot=est[:3], tra=est[3:6], sca=est[6:9])\n            angle, move, scale = self._changes\n            self._log_dig_mri_distance(f\"  ICP {iteration + 1:2d} \")\n            if callback is not None:\n                callback(iteration, n_iterations)\n            if (\n                angle <= self._icp_angle\n                and move <= self._icp_distance\n                and all(scale <= self._icp_scale)\n            ):\n                break\n        self._log_dig_mri_distance(\"End      \")\n        return self", "metadata": {}}
{"_id": "mne_mne_coreg.py_omit_head_shape_points_code", "title": "omit_head_shape_points", "text": "def omit_head_shape_points(self, distance):\n        \"\"\"Exclude head shape points that are far away from the MRI head.\n\n        Parameters\n        ----------\n        distance : float\n            Exclude all points that are further away from the MRI head than\n            this distance (in m.). A value of distance <= 0 excludes nothing.\n\n        Returns\n        -------\n        self : Coregistration\n            The modified Coregistration object.\n        \"\"\"\n        distance = float(distance)\n        if distance <= 0:\n            return\n\n        # find the new filter\n        mask = self._orig_hsp_point_distance <= distance\n        n_excluded = np.sum(~mask)\n        logger.info(\n            \"Coregistration: Excluding %i head shape points with distance >= %.3f m.\",\n            n_excluded,\n            distance,\n        )\n        # set the filter\n        self._extra_points_filter = mask\n        self._update_params(force_update=True)\n        return self", "metadata": {}}
{"_id": "mne_mne_coreg.py_compute_dig_mri_distances_code", "title": "compute_dig_mri_distances", "text": "def compute_dig_mri_distances(self):\n        \"\"\"Compute distance between head shape points and MRI skin surface.\n\n        Returns\n        -------\n        dist : array, shape (n_points,)\n            The distance of the head shape points to the MRI skin surface.\n\n        See Also\n        --------\n        mne.dig_mri_distances\n        \"\"\"\n        # we don't use `dig_mri_distances` here because it should be much\n        # faster to use our already-determined nearest points\n        hsp_points, mri_points, _ = self._setup_icp(0)\n        hsp_points = apply_trans(self._head_mri_t, hsp_points)\n        return np.linalg.norm(mri_points - hsp_points, axis=-1)", "metadata": {}}
{"_id": "mne_mne_coreg.py_trans_code", "title": "trans", "text": "def trans(self):\n        \"\"\"The head->mri :class:`~mne.transforms.Transform`.\"\"\"\n        return Transform(\"head\", \"mri\", self._head_mri_t)", "metadata": {}}
{"_id": "mne_mne_coreg.py_reset_code", "title": "reset", "text": "def reset(self):\n        \"\"\"Reset all the parameters affecting the coregistration.\n\n        Returns\n        -------\n        self : Coregistration\n            The modified Coregistration object.\n        \"\"\"\n        self._grow_hair = 0.0\n        self.set_rotation(self._default_parameters[:3])\n        self.set_translation(self._default_parameters[3:6])\n        self.set_scale(self._default_parameters[6:9])\n        self._extra_points_filter = None\n        self._update_nearest_calc()\n        return self", "metadata": {}}
{"_id": "mne_mne__ola.py_feed_generator_code", "title": "feed_generator", "text": "def feed_generator(self, n_pts):\n        \"\"\"Feed data and get interpolators as a generator.\"\"\"\n        self.n_last = 0\n        n_pts = _ensure_int(n_pts, \"n_pts\")\n        original_position = self._position\n        stop = self._position + n_pts\n        logger.debug(f\"    ~ {self.name} Feed {n_pts} ({self._position}-{stop})\")\n        used = np.zeros(n_pts, bool)\n        if self._left is None:  # first one\n            logger.debug(f\"    ~   {self.name} Eval @ 0 ({self.control_points[0]})\")\n            self._left = self.values(self.control_points[0])\n            if len(self.control_points) == 1:\n                self._right = self._left\n        n_used = 0\n\n        # Left zero-order hold condition\n        if self._position < self.control_points[self._left_idx]:\n            n_use = min(self.control_points[self._left_idx] - self._position, n_pts)\n            logger.debug(f\"    ~   {self.name} Left ZOH {n_use}\")\n            this_sl = slice(None, n_use)\n            assert used[this_sl].size == n_use\n            assert not used[this_sl].any()\n            used[this_sl] = True\n            yield [this_sl, self._left, None, None]\n            self._position += n_use\n            n_used += n_use\n            self.n_last += 1\n\n        # Standard interpolation condition\n        stop_right_idx = np.where(self.control_points >= stop)[0]\n        if len(stop_right_idx) == 0:\n            stop_right_idx = [len(self.control_points) - 1]\n        stop_right_idx = stop_right_idx[0]\n        left_idxs = np.arange(self._left_idx, stop_right_idx)\n        self.n_last += max(len(left_idxs) - 1, 0)\n        for bi, left_idx in enumerate(left_idxs):\n            if left_idx != self._left_idx or self._right is None:\n                if self._right is not None:\n                    assert left_idx == self._left_idx + 1\n                    self._left = self._right\n                    self._left_idx += 1\n                    self._use_interp = None  # need to recreate it\n                eval_pt = self.control_points[self._left_idx + 1]\n                logger.debug(\n                    f\"    ~   {self.name} Eval @ {self._left_idx + 1} ({eval_pt})\"\n                )\n                self._right = self.values(eval_pt)\n            assert self._right is not None\n            left_point = self.control_points[self._left_idx]\n            right_point = self.control_points[self._left_idx + 1]\n            if self._use_interp is None:\n                interp_span = right_point - left_point\n                if self._interp == \"zero\":\n                    self._use_interp = None\n                elif self._interp == \"linear\":\n                    self._use_interp = np.linspace(\n                        1.0, 0.0, interp_span, endpoint=False\n                    )\n                else:  # self._interp in ('cos2', 'hann'):\n                    self._use_interp = np.cos(\n                        np.linspace(0, np.pi / 2.0, interp_span, endpoint=False)\n                    )\n                    self._use_interp *= self._use_interp\n            n_use = min(stop, right_point) - self._position\n            if n_use > 0:\n                logger.debug(\n                    f\"    ~   {self.name} Interp {self._interp} {n_use} \"\n                    f\"({left_point}-{right_point})\"\n                )\n                interp_start = self._position - left_point\n                assert interp_start >= 0\n                if self._use_interp is None:\n                    this_interp = None\n                else:\n                    this_interp = self._use_interp[interp_start : interp_start + n_use]\n                    assert this_interp.size == n_use\n                this_sl = slice(n_used, n_used + n_use)\n                assert used[this_sl].size == n_use\n                assert not used[this_sl].any()\n                used[this_sl] = True\n                yield [this_sl, self._left, self._right, this_interp]\n                self._position += n_use\n                n_used += n_use\n\n        # Right zero-order hold condition\n        if self.control_points[self._left_idx] <= self._position:\n            n_use = stop - self._position\n            if n_use > 0:\n                logger.debug(f\"    ~   {self.name} Right ZOH %s\" % n_use)\n                this_sl = slice(n_pts - n_use, None)\n                assert not used[this_sl].any()\n                used[this_sl] = True\n                assert self._right is not None\n                yield [this_sl, self._right, None, None]\n                self._position += n_use\n                n_used += n_use\n                self.n_last += 1\n        assert self._position == stop\n        assert n_used == n_pts\n        assert used.all()\n        assert self._position == original_position + n_pts", "metadata": {}}
{"_id": "mne_mne__ola.py_feed_code", "title": "feed", "text": "def feed(self, n_pts):\n        \"\"\"Feed data and get interpolated values.\"\"\"\n        # Convenience function for assembly\n        out_arrays = None\n        for o in self.feed_generator(n_pts):\n            if out_arrays is None:\n                out_arrays = [\n                    np.empty(v.shape + (n_pts,)) if v is not None else None\n                    for v in o[1]\n                ]\n            for ai, arr in enumerate(out_arrays):\n                if arr is not None:\n                    if o[3] is None:\n                        arr[..., o[0]] = o[1][ai][..., np.newaxis]\n                    else:\n                        arr[..., o[0]] = o[1][ai][..., np.newaxis] * o[3] + o[2][ai][\n                            ..., np.newaxis\n                        ] * (1.0 - o[3])\n        assert out_arrays is not None\n        return out_arrays", "metadata": {}}
{"_id": "mne_mne__ola.py_feed_code", "title": "feed", "text": "def feed(self, *datas, verbose=None, **kwargs):\n        \"\"\"Pass in a chunk of data.\"\"\"\n        # Append to our input buffer\n        if self._in_buffers is None:\n            self._in_buffers = [None] * len(datas)\n        if len(datas) != len(self._in_buffers):\n            raise ValueError(\n                f\"Got {len(datas)} array(s), needed {len(self._in_buffers)}\"\n            )\n        current_offset = 0  # should be updated below\n        for di, data in enumerate(datas):\n            if not isinstance(data, np.ndarray) or data.ndim < 1:\n                raise TypeError(\n                    f\"data entry {di} must be an 2D ndarray, got {type(data)}\"\n                )\n            if self._in_buffers[di] is None:\n                # In practice, users can give large chunks, so we use\n                # dynamic allocation of the in buffer. We could save some\n                # memory allocation by only ever processing max_len at once,\n                # but this would increase code complexity.\n                self._in_buffers[di] = np.empty(data.shape[:-1] + (0,), data.dtype)\n            if (\n                data.shape[:-1] != self._in_buffers[di].shape[:-1]\n                or self._in_buffers[di].dtype != data.dtype\n            ):\n                raise TypeError(\n                    f\"data must dtype {self._in_buffers[di].dtype} and \"\n                    f\"shape[:-1]=={self._in_buffers[di].shape[:-1]}, got dtype \"\n                    f\"{data.dtype} shape[:-1]={data.shape[:-1]}\"\n                )\n            # This gets updated on first iteration, so store it before it updates\n            if di == 0:\n                current_offset = self._in_offset\n            logger.debug(\n                f\"    + {self.name}[{di}] Appending  \"\n                f\"{current_offset}:{current_offset + data.shape[-1]}\"\n            )\n            self._in_buffers[di] = np.concatenate([self._in_buffers[di], data], -1)\n            if self._in_offset > self.stops[-1]:\n                raise ValueError(\n                    f\"data (shape {data.shape}) exceeded expected total buffer size (\"\n                    f\"{self._in_offset} > {self.stops[-1]})\"\n                )\n        # Check to see if we can process the next chunk and dump outputs\n        while self._idx < len(self.starts) and self._in_offset >= self.stops[self._idx]:\n            start, stop = self.starts[self._idx], self.stops[self._idx]\n            this_len = stop - start\n            this_window = self._window.copy()\n            if self._idx == len(self.starts) - 1:\n                this_window = np.pad(\n                    self._window, (0, this_len - len(this_window)), \"constant\"\n                )\n                for offset in range(self._step, len(this_window), self._step):\n                    n_use = len(this_window) - offset\n                    this_window[offset:] += self._window[:n_use]\n            if self._idx == 0:\n                for offset in range(self._n_samples - self._step, 0, -self._step):\n                    this_window[:offset] += self._window[-offset:]\n            this_proc = [in_[..., :this_len].copy() for in_ in self._in_buffers]\n            logger.debug(\n                f\"    * {self.name}[:] Processing {start}:{stop} \"\n                f\"(e.g., {this_proc[0].flat[[0, -1]]})\"\n            )\n            if not all(\n                proc.shape[-1] == this_len == this_window.size for proc in this_proc\n            ):\n                raise RuntimeError(\"internal indexing error\")\n            start = self._store.idx\n            stop = self._store.idx + this_len\n            outs = self._process(*this_proc, start=start, stop=stop, **kwargs)\n            if self._out_buffers is None:\n                max_len = np.max(self.stops - self.starts)\n                self._out_buffers = [\n                    np.zeros(o.shape[:-1] + (max_len,), o.dtype) for o in outs\n                ]\n            for oi, out in enumerate(outs):\n                out *= this_window\n                self._out_buffers[oi][..., : stop - start] += out\n            self._idx += 1\n            if self._idx < len(self.starts):\n                next_start = self.starts[self._idx]\n            else:\n                next_start = self.stops[-1]\n            delta = next_start - self.starts[self._idx - 1]\n            logger.debug(\n                f\"    + {self.name}[:] Shifting input and output buffers by \"\n                f\"{delta} samples (storing {start}:{stop})\"\n            )\n            for di in range(len(self._in_buffers)):\n                self._in_buffers[di] = self._in_buffers[di][..., delta:]\n            self._store(*[o[..., :delta] for o in self._out_buffers])\n            for ob in self._out_buffers:\n                ob[..., :-delta] = ob[..., delta:]\n                ob[..., -delta:] = 0.0", "metadata": {}}
{"_id": "mne_mne_dipole.py_read_dipole_code", "title": "read_dipole", "text": "def read_dipole(fname, verbose=None):\n    \"\"\"Read a dipole object from a file.\n\n    Non-fixed-position :class:`mne.Dipole` objects are usually saved in ``.[b]dip``\n    format. Fixed-position :class:`mne.DipoleFixed` objects are usually saved in\n    FIF format.\n\n    Parameters\n    ----------\n    fname : path-like\n        The name of the ``.[b]dip`` or ``.fif[.gz]`` file.\n    %(verbose)s\n\n    Returns\n    -------\n    %(dipole)s\n\n    See Also\n    --------\n    Dipole\n    DipoleFixed\n    fit_dipole\n\n    Notes\n    -----\n    .. versionchanged:: 0.20\n       Support for reading bdip (Xfit binary) format.\n    \"\"\"\n    fname = _check_fname(fname, overwrite=\"read\", must_exist=True)\n    if fname.suffix == \".fif\" or fname.name.endswith(\".fif.gz\"):\n        return _read_dipole_fixed(fname)\n    elif fname.suffix == \".bdip\":\n        return _read_dipole_bdip(fname)\n    else:\n        return _read_dipole_text(fname)", "metadata": {}}
{"_id": "mne_mne_dipole.py_fit_dipole_code", "title": "fit_dipole", "text": "def fit_dipole(\n    evoked,\n    cov,\n    bem,\n    trans=None,\n    min_dist=5.0,\n    n_jobs=None,\n    pos=None,\n    ori=None,\n    rank=None,\n    accuracy=\"normal\",\n    tol=5e-5,\n    verbose=None,\n):\n    \"\"\"Fit a dipole.\n\n    Parameters\n    ----------\n    evoked : instance of Evoked\n        The dataset to fit.\n    cov : str | instance of Covariance\n        The noise covariance.\n    bem : path-like | instance of ConductorModel\n        The BEM filename (str) or conductor model.\n    trans : path-like | None\n        The head<->MRI transform filename. Must be provided unless BEM\n        is a sphere model.\n    min_dist : float\n        Minimum distance (in millimeters) from the dipole to the inner skull.\n        Must be positive. Note that because this is a constraint passed to\n        a solver it is not strict but close, i.e. for a ``min_dist=5.`` the\n        fits could be 4.9 mm from the inner skull.\n    %(n_jobs)s\n        It is used in field computation and fitting.\n    pos : ndarray, shape (3,) | None\n        Position of the dipole to use. If None (default), sequential\n        fitting (different position and orientation for each time instance)\n        is performed. If a position (in head coords) is given as an array,\n        the position is fixed during fitting.\n\n        .. versionadded:: 0.12\n    ori : ndarray, shape (3,) | None\n        Orientation of the dipole to use. If None (default), the\n        orientation is free to change as a function of time. If an\n        orientation (in head coordinates) is given as an array, ``pos``\n        must also be provided, and the routine computes the amplitude and\n        goodness of fit of the dipole at the given position and orientation\n        for each time instant.\n\n        .. versionadded:: 0.12\n    %(rank_none)s\n\n        .. versionadded:: 0.20\n    accuracy : str\n        Can be ``\"normal\"`` (default) or ``\"accurate\"``, which gives the most\n        accurate coil definition but is typically not necessary for real-world\n        data.\n\n        .. versionadded:: 0.24\n    tol : float\n        Final accuracy of the optimization (see ``rhoend`` argument of\n        :func:`scipy.optimize.fmin_cobyla`).\n\n        .. versionadded:: 0.24\n    %(verbose)s\n\n    Returns\n    -------\n    dip : instance of Dipole or DipoleFixed\n        The dipole fits. A :class:`mne.DipoleFixed` is returned if\n        ``pos`` and ``ori`` are both not None, otherwise a\n        :class:`mne.Dipole` is returned.\n    residual : instance of Evoked\n        The M-EEG data channels with the fitted dipolar activity removed.\n\n    See Also\n    --------\n    mne.beamformer.rap_music\n    Dipole\n    DipoleFixed\n    read_dipole\n\n    Notes\n    -----\n    .. versionadded:: 0.9.0\n    \"\"\"\n    # This could eventually be adapted to work with other inputs, these\n    # are what is needed:\n\n    evoked = evoked.copy()\n    _validate_type(accuracy, str, \"accuracy\")\n    _check_option(\"accuracy\", accuracy, (\"accurate\", \"normal\"))\n\n    # Determine if a list of projectors has an average EEG ref\n    if _needs_eeg_average_ref_proj(evoked.info):\n        raise ValueError(\"EEG average reference is mandatory for dipole fitting.\")\n    if min_dist < 0:\n        raise ValueError(f\"min_dist should be positive. Got {min_dist}\")\n    if ori is not None and pos is None:\n        raise ValueError(\"pos must be provided if ori is not None\")\n\n    data = evoked.data\n    if not np.isfinite(data).all():\n        raise ValueError(\"Evoked data must be finite\")\n    info = evoked.info\n    times = evoked.times.copy()\n    comment = evoked.comment\n\n    # Convert the min_dist to meters\n    min_dist_to_inner_skull = min_dist / 1000.0\n    del min_dist\n\n    # Figure out our inputs\n    neeg = len(pick_types(info, meg=False, eeg=True, ref_meg=False, exclude=[]))\n    if isinstance(bem, str):\n        bem_extra = bem\n    else:\n        bem_extra = repr(bem)\n        logger.info(f\"BEM               : {bem_extra}\")\n    mri_head_t, trans = _get_trans(trans)\n    logger.info(f\"MRI transform     : {trans}\")\n    safe_false = _verbose_safe_false()\n    bem = _setup_bem(bem, bem_extra, neeg, mri_head_t, verbose=safe_false)\n    if not bem[\"is_sphere\"]:\n        # Find the best-fitting sphere\n        inner_skull = _bem_find_surface(bem, \"inner_skull\")\n        inner_skull = inner_skull.copy()\n        R, r0 = _fit_sphere(inner_skull[\"rr\"])\n        # r0 back to head frame for logging\n        r0 = apply_trans(mri_head_t[\"trans\"], r0[np.newaxis, :])[0]\n        inner_skull[\"r0\"] = r0\n        logger.info(\n            f\"Head origin       : {1000 * r0[0]:6.1f} {1000 * r0[1]:6.1f} \"\n            f\"{1000 * r0[2]:6.1f} mm rad = {1000 * R:6.1f} mm.\"\n        )\n        del R, r0\n    else:\n        r0 = bem[\"r0\"]\n        if len(bem.get(\"layers\", [])) > 0:\n            R = bem[\"layers\"][0][\"rad\"]\n            kind = \"rad\"\n        else:  # MEG-only\n            # Use the minimum distance to the MEG sensors as the radius then\n            R = np.dot(\n                np.linalg.inv(info[\"dev_head_t\"][\"trans\"]), np.hstack([r0, [1.0]])\n            )[:3]  # r0 -> device\n            R = R - [\n                info[\"chs\"][pick][\"loc\"][:3]\n                for pick in pick_types(info, meg=True, exclude=[])\n            ]\n            if len(R) == 0:\n                raise RuntimeError(\n                    \"No MEG channels found, but MEG-only sphere model used\"\n                )\n            R = np.min(np.sqrt(np.sum(R * R, axis=1)))  # use dist to sensors\n            kind = \"max_rad\"\n        logger.info(\n            f\"Sphere model      : origin at ({1000 * r0[0]: 7.2f} {1000 * r0[1]: 7.2f} \"\n            f\"{1000 * r0[2]: 7.2f}) mm, {kind} = {R:6.1f} mm\"\n        )\n        inner_skull = dict(R=R, r0=r0)  # NB sphere model defined in head frame\n        del R, r0\n\n    # Deal with DipoleFixed cases here\n    if pos is not None:\n        fixed_position = True\n        pos = np.array(pos, float)\n        if pos.shape != (3,):\n            raise ValueError(f\"pos must be None or a 3-element array-like, got {pos}\")\n        logger.info(\n            \"Fixed position    : {:6.1f} {:6.1f} {:6.1f} mm\".format(*tuple(1000 * pos))\n        )\n        if ori is not None:\n            ori = np.array(ori, float)\n            if ori.shape != (3,):\n                raise ValueError(\n                    f\"oris must be None or a 3-element array-like, got {ori}\"\n                )\n            norm = np.sqrt(np.sum(ori * ori))\n            if not np.isclose(norm, 1):\n                raise ValueError(f\"ori must be a unit vector, got length {norm}\")\n            logger.info(\n                \"Fixed orientation  : {:6.4f} {:6.4f} {:6.4f} mm\".format(*tuple(ori))\n            )\n        else:\n            logger.info(\"Free orientation   : <time-varying>\")\n        fit_n_jobs = 1  # only use 1 job to do the guess fitting\n    else:\n        fixed_position = False\n        # Eventually these could be parameters, but they are just used for\n        # the initial grid anyway\n        guess_grid = 0.02  # MNE-C uses 0.01, but this is faster w/similar perf\n        guess_mindist = max(0.005, min_dist_to_inner_skull)\n        guess_exclude = 0.02\n\n        logger.info(f\"Guess grid        : {1000 * guess_grid:6.1f} mm\")\n        if guess_mindist > 0.0:\n            logger.info(f\"Guess mindist     : {1000 * guess_mindist:6.1f} mm\")\n        if guess_exclude > 0:\n            logger.info(f\"Guess exclude     : {1000 * guess_exclude:6.1f} mm\")\n        logger.info(f\"Using {accuracy} MEG coil definitions.\")\n        fit_n_jobs = n_jobs\n    cov = _ensure_cov(cov)\n    logger.info(\"\")\n\n    _print_coord_trans(mri_head_t)\n    _print_coord_trans(info[\"dev_head_t\"])\n    logger.info(f\"{len(info['bads'])} bad channels total\")\n\n    # Forward model setup (setup_forward_model from setup.c)\n    ch_types = evoked.get_channel_types()\n\n    sensors = dict()\n    if \"grad\" in ch_types or \"mag\" in ch_types:\n        sensors[\"meg\"] = _prep_meg_channels(\n            info, exclude=\"bads\", accuracy=accuracy, verbose=verbose\n        )\n    if \"eeg\" in ch_types:\n        sensors[\"eeg\"] = _prep_eeg_channels(info, exclude=\"bads\", verbose=verbose)\n\n    # Ensure that MEG and/or EEG channels are present\n    if len(sensors) == 0:\n        raise RuntimeError(\"No MEG or EEG channels found.\")\n\n    # Whitener for the data\n    logger.info(\"Decomposing the sensor noise covariance matrix...\")\n    picks = pick_types(info, meg=True, eeg=True, ref_meg=False)\n\n    # In case we want to more closely match MNE-C for debugging:\n    # from ._fiff.pick import pick_info\n    # from .cov import prepare_noise_cov\n    # info_nb = pick_info(info, picks)\n    # cov = prepare_noise_cov(cov, info_nb, info_nb['ch_names'], verbose=False)\n    # nzero = (cov['eig'] > 0)\n    # n_chan = len(info_nb['ch_names'])\n    # whitener = np.zeros((n_chan, n_chan), dtype=np.float64)\n    # whitener[nzero, nzero] = 1.0 / np.sqrt(cov['eig'][nzero])\n    # whitener = np.dot(whitener, cov['eigvec'])\n\n    whitener, _, rank = compute_whitener(\n        cov, info, picks=picks, rank=rank, return_rank=True\n    )\n\n    # Proceed to computing the fits (make_guess_data)\n    if fixed_position:\n        guess_src = dict(nuse=1, rr=pos[np.newaxis], inuse=np.array([True]))\n        logger.info(\"Compute forward for dipole location...\")\n    else:\n        logger.info(\"\\n---- Computing the forward solution for the guesses...\")\n        guess_src = _make_guesses(\n            inner_skull, guess_grid, guess_exclude, guess_mindist, n_jobs=n_jobs\n        )[0]\n        # grid coordinates go from mri to head frame\n        transform_surface_to(guess_src, \"head\", mri_head_t)\n        logger.info(\"Go through all guess source locations...\")\n\n    # inner_skull goes from mri to head frame\n    if \"rr\" in inner_skull:\n        transform_surface_to(inner_skull, \"head\", mri_head_t)\n    if fixed_position:\n        if \"rr\" in inner_skull:\n            check = _surface_constraint(pos, inner_skull, min_dist_to_inner_skull)\n        else:\n            check = _sphere_constraint(\n                pos, inner_skull[\"r0\"], R_adj=inner_skull[\"R\"] - min_dist_to_inner_skull\n            )\n        if check <= 0:\n            raise ValueError(\n                f\"fixed position is {-1000 * check:0.1f}mm outside the inner skull \"\n                \"boundary\"\n            )\n\n    # C code computes guesses w/sphere model for speed, don't bother here\n    fwd_data = _prep_field_computation(\n        guess_src[\"rr\"], sensors=sensors, bem=bem, n_jobs=n_jobs, verbose=safe_false\n    )\n    fwd_data[\"inner_skull\"] = inner_skull\n    guess_fwd, guess_fwd_orig, guess_fwd_scales = _dipole_forwards(\n        sensors=sensors,\n        fwd_data=fwd_data,\n        whitener=whitener,\n        rr=guess_src[\"rr\"],\n        n_jobs=fit_n_jobs,\n    )\n    # decompose ahead of time\n    guess_fwd_svd = [\n        _safe_svd(fwd, full_matrices=False)\n        for fwd in np.array_split(guess_fwd, len(guess_src[\"rr\"]))\n    ]\n    guess_data = dict(\n        fwd=guess_fwd,\n        fwd_svd=guess_fwd_svd,\n        fwd_orig=guess_fwd_orig,\n        scales=guess_fwd_scales,\n    )\n    del guess_fwd, guess_fwd_svd, guess_fwd_orig, guess_fwd_scales  # destroyed\n    logger.info(\"[done %d source%s]\", guess_src[\"nuse\"], _pl(guess_src[\"nuse\"]))\n\n    # Do actual fits\n    data = data[picks]\n    ch_names = [info[\"ch_names\"][p] for p in picks]\n    proj_op = make_projector(info[\"projs\"], ch_names, info[\"bads\"])[0]\n    fun = _fit_dipole_fixed if fixed_position else _fit_dipole\n    out = _fit_dipoles(\n        fun,\n        min_dist_to_inner_skull,\n        data,\n        times,\n        guess_src[\"rr\"],\n        guess_data,\n        sensors=sensors,\n        fwd_data=fwd_data,\n        whitener=whitener,\n        ori=ori,\n        n_jobs=n_jobs,\n        rank=rank,\n        rhoend=tol,\n    )\n    assert len(out) == 8\n    if fixed_position and ori is not None:\n        # DipoleFixed\n        data = np.array([out[1], out[3]])\n        out_info = deepcopy(info)\n        loc = np.concatenate([pos, ori, np.zeros(6)])\n        out_info._unlocked = True\n        out_info[\"chs\"] = [\n            dict(\n                ch_name=\"dip 01\",\n                loc=loc,\n                kind=FIFF.FIFFV_DIPOLE_WAVE,\n                coord_frame=FIFF.FIFFV_COORD_UNKNOWN,\n                unit=FIFF.FIFF_UNIT_AM,\n                coil_type=FIFF.FIFFV_COIL_DIPOLE,\n                unit_mul=0,\n                range=1,\n                cal=1.0,\n                scanno=1,\n                logno=1,\n            ),\n            dict(\n                ch_name=\"goodness\",\n                loc=np.full(12, np.nan),\n                kind=FIFF.FIFFV_GOODNESS_FIT,\n                unit=FIFF.FIFF_UNIT_AM,\n                coord_frame=FIFF.FIFFV_COORD_UNKNOWN,\n                coil_type=FIFF.FIFFV_COIL_NONE,\n                unit_mul=0,\n                range=1.0,\n                cal=1.0,\n                scanno=2,\n                logno=100,\n            ),\n        ]\n        for key in [\"hpi_meas\", \"hpi_results\", \"projs\"]:\n            out_info[key] = list()\n        for key in [\n            \"acq_pars\",\n            \"acq_stim\",\n            \"description\",\n            \"dig\",\n            \"experimenter\",\n            \"hpi_subsystem\",\n            \"proj_id\",\n            \"proj_name\",\n            \"subject_info\",\n        ]:\n            out_info[key] = None\n        out_info._unlocked = False\n        out_info[\"bads\"] = []\n        out_info._update_redundant()\n        out_info._check_consistency()\n        dipoles = DipoleFixed(\n            out_info, data, times, evoked.nave, evoked._aspect_kind, comment=comment\n        )\n    else:\n        dipoles = Dipole(\n            times, out[0], out[1], out[2], out[3], comment, out[4], out[5], out[6]\n        )\n    residual = evoked.copy().apply_proj()  # set the projs active\n    residual.data[picks] = np.dot(proj_op, out[-1])\n    logger.info(\"%d time points fitted\", len(dipoles.times))\n    return dipoles, residual", "metadata": {}}
{"_id": "mne_mne_dipole.py_get_phantom_dipoles_code", "title": "get_phantom_dipoles", "text": "def get_phantom_dipoles(kind=\"vectorview\"):\n    \"\"\"Get standard phantom dipole locations and orientations.\n\n    Parameters\n    ----------\n    kind : str\n        Get the information for the given system:\n\n            ``vectorview`` (default)\n              The Neuromag VectorView phantom.\n            ``otaniemi``\n              The older Neuromag phantom used at Otaniemi.\n            ``oyama``\n              The phantom from :footcite:`OyamaEtAl2015`.\n\n        .. versionchanged:: 1.6\n           Support added for ``'oyama'``.\n\n    Returns\n    -------\n    pos : ndarray, shape (n_dipoles, 3)\n        The dipole positions.\n    ori : ndarray, shape (n_dipoles, 3)\n        The dipole orientations.\n\n    See Also\n    --------\n    mne.datasets.fetch_phantom\n\n    Notes\n    -----\n    The Elekta phantoms have a radius of 79.5mm, and HPI coil locations\n    in the XY-plane at the axis extrema (e.g., (79.5, 0), (0, -79.5), ...).\n\n    References\n    ----------\n    .. footbibliography::\n    \"\"\"\n    _validate_type(kind, str, \"kind\")\n    _check_option(\"kind\", kind, [\"vectorview\", \"otaniemi\", \"oyama\"])\n    if kind == \"vectorview\":\n        # these values were pulled from a scanned image provided by\n        # Elekta folks\n        a = np.array([59.7, 48.6, 35.8, 24.8, 37.2, 27.5, 15.8, 7.9])\n        b = np.array([46.1, 41.9, 38.3, 31.5, 13.9, 16.2, 20.0, 19.3])\n        x = np.concatenate((a, [0] * 8, -b, [0] * 8))\n        y = np.concatenate(([0] * 8, -a, [0] * 8, b))\n        c = [22.9, 23.5, 25.5, 23.1, 52.0, 46.4, 41.0, 33.0]\n        d = [44.4, 34.0, 21.6, 12.7, 62.4, 51.5, 39.1, 27.9]\n        z = np.concatenate((c, c, d, d))\n        signs = ([1, -1] * 4 + [-1, 1] * 4) * 2\n    elif kind == \"otaniemi\":\n        # these values were pulled from an Neuromag manual\n        # (NM20456A, 13.7.1999, p.65)\n        a = np.array([56.3, 47.6, 39.0, 30.3])\n        b = np.array([32.5, 27.5, 22.5, 17.5])\n        c = np.zeros(4)\n        x = np.concatenate((a, b, c, c, -a, -b, c, c))\n        y = np.concatenate((c, c, -a, -b, c, c, b, a))\n        z = np.concatenate((b, a, b, a, b, a, a, b))\n        signs = [-1] * 8 + [1] * 16 + [-1] * 8\n    else:\n        assert kind == \"oyama\"\n        xyz = np.fromstring(_OYAMA.strip().replace(\"\\n\", \" \"), sep=\" \").reshape(25, 3)\n        xyz = np.repeat(xyz, 2, axis=0)\n        x, y, z = xyz.T\n        signs = [1] * 50\n    pos = np.vstack((x, y, z)).T / 1000.0\n    # For Neuromag-style phantoms,\n    # Locs are always in XZ or YZ, and so are the oris. The oris are\n    # also in the same plane and tangential, so it's easy to determine\n    # the orientation.\n    # For Oyama, vectors are orthogonal to the position vector and oriented with one\n    # pointed toward the north pole (except for the topmost points, which are just xy).\n    ori = list()\n    for pi, this_pos in enumerate(pos):\n        this_ori = np.zeros(3)\n        idx = np.where(this_pos == 0)[0]\n        # assert len(idx) == 1\n        if len(idx) == 0:  # oyama\n            idx = [np.argmin(this_pos)]\n        idx = np.setdiff1d(np.arange(3), idx[0])\n        this_ori[idx] = (this_pos[idx][::-1] / np.linalg.norm(this_pos[idx])) * [1, -1]\n        if kind == \"oyama\":\n            # Ensure it's orthogonal to the position vector\n            pos_unit = this_pos / np.linalg.norm(this_pos)\n            this_ori -= pos_unit * np.dot(this_ori, pos_unit)\n            this_ori /= np.linalg.norm(this_ori)\n            # This was empirically determined by looking at the dipole fits\n            if np.abs(this_ori[2]) >= 1e-6:  # if it's not in the XY plane\n                this_ori *= -1 * np.sign(this_ori[2])  # point downward\n            elif np.abs(this_ori[0]) < 1e-6:  # in the XY plane (at the north pole)\n                this_ori *= -1 * np.sign(this_ori[1])  # point backward\n            # Odd ones create a RH coordinate system with their ori\n            if pi % 2:\n                this_ori = np.cross(pos_unit, this_ori)\n        else:\n            this_ori *= signs[pi]\n        # Now we have this quality, which we could uncomment to\n        # double-check:\n        # np.testing.assert_allclose(np.dot(this_ori, this_pos) /\n        #                            np.linalg.norm(this_pos), 0,\n        #                            atol=1e-15)\n        ori.append(this_ori)\n    ori = np.array(ori)\n    return pos, ori", "metadata": {}}
{"_id": "mne_mne_dipole.py_pos_code", "title": "pos", "text": "def pos(self):\n        \"\"\"The dipoles positions (m) in head coordinates.\"\"\"\n        return self._pos", "metadata": {}}
{"_id": "mne_mne_dipole.py_amplitude_code", "title": "amplitude", "text": "def amplitude(self):\n        \"\"\"The amplitude of the dipoles (Am).\"\"\"\n        return self._amplitude", "metadata": {}}
{"_id": "mne_mne_dipole.py_ori_code", "title": "ori", "text": "def ori(self):\n        \"\"\"The dipole orientations (normalized to unit length).\"\"\"\n        return self._ori", "metadata": {}}
{"_id": "mne_mne_dipole.py_gof_code", "title": "gof", "text": "def gof(self):\n        \"\"\"The goodness of fit.\"\"\"\n        return self._gof", "metadata": {}}
{"_id": "mne_mne_dipole.py_name_code", "title": "name", "text": "def name(self):\n        \"\"\"Name of the dipole.\"\"\"\n        return self._name", "metadata": {}}
{"_id": "mne_mne_dipole.py_conf_code", "title": "conf", "text": "def conf(self):\n        \"\"\"Confidence limits in dipole orientation.\"\"\"\n        return self._conf", "metadata": {}}
{"_id": "mne_mne_dipole.py_khi2_code", "title": "khi2", "text": "def khi2(self):\n        \"\"\"The \u03c7^2 values for the fits.\"\"\"\n        return self._khi2", "metadata": {}}
{"_id": "mne_mne_dipole.py_nfree_code", "title": "nfree", "text": "def nfree(self):\n        \"\"\"The number of free parameters for each fit.\"\"\"\n        return self._nfree", "metadata": {}}
{"_id": "mne_mne_dipole.py_save_code", "title": "save", "text": "def save(self, fname, overwrite=False, *, verbose=None):\n        \"\"\"Save dipole in a ``.dip`` or ``.bdip`` file.\n\n        The ``.[b]dip`` format is for :class:`mne.Dipole` objects, that is,\n        fixed-position dipole fits. For these fits, the amplitude, orientation,\n        and position vary as a function of time.\n\n        Parameters\n        ----------\n        fname : path-like\n            The name of the ``.dip`` or ``.bdip`` file.\n        %(overwrite)s\n\n            .. versionadded:: 0.20\n        %(verbose)s\n\n        See Also\n        --------\n        read_dipole\n\n        Notes\n        -----\n        .. versionchanged:: 0.20\n           Support for writing bdip (Xfit binary) files.\n        \"\"\"\n        # obligatory fields\n        fname = _check_fname(fname, overwrite=overwrite)\n        if fname.suffix == \".bdip\":\n            _write_dipole_bdip(fname, self)\n        else:\n            _write_dipole_text(fname, self)", "metadata": {}}
{"_id": "mne_mne_dipole.py_crop_code", "title": "crop", "text": "def crop(self, tmin=None, tmax=None, include_tmax=True, verbose=None):\n        \"\"\"Crop data to a given time interval.\n\n        Parameters\n        ----------\n        tmin : float | None\n            Start time of selection in seconds.\n        tmax : float | None\n            End time of selection in seconds.\n        %(include_tmax)s\n        %(verbose)s\n\n        Returns\n        -------\n        self : instance of Dipole\n            The cropped instance.\n        \"\"\"\n        sfreq = None\n        if len(self.times) > 1:\n            sfreq = 1.0 / np.median(np.diff(self.times))\n        mask = _time_mask(\n            self.times, tmin, tmax, sfreq=sfreq, include_tmax=include_tmax\n        )\n        self._set_times(self.times[mask])\n        for attr in (\"_pos\", \"_gof\", \"_amplitude\", \"_ori\", \"_khi2\", \"_nfree\"):\n            if getattr(self, attr) is not None:\n                setattr(self, attr, getattr(self, attr)[mask])\n        for key in self.conf.keys():\n            self.conf[key] = self.conf[key][mask]\n        return self", "metadata": {}}
{"_id": "mne_mne_dipole.py_copy_code", "title": "copy", "text": "def copy(self):\n        \"\"\"Copy the Dipoles object.\n\n        Returns\n        -------\n        dip : instance of Dipole\n            The copied dipole instance.\n        \"\"\"\n        return deepcopy(self)", "metadata": {}}
{"_id": "mne_mne_dipole.py_to_mni_code", "title": "to_mni", "text": "def to_mni(self, subject, trans, subjects_dir=None, verbose=None):\n        \"\"\"Convert dipole location from head to MNI coordinates.\n\n        Parameters\n        ----------\n        %(subject)s\n        %(trans_not_none)s\n        %(subjects_dir)s\n        %(verbose)s\n\n        Returns\n        -------\n        pos_mni : array, shape (n_pos, 3)\n            The MNI coordinates (in mm) of pos.\n        \"\"\"\n        mri_head_t, trans = _get_trans(trans)\n        return head_to_mni(\n            self.pos, subject, mri_head_t, subjects_dir=subjects_dir, verbose=verbose\n        )", "metadata": {}}
{"_id": "mne_mne_dipole.py_to_mri_code", "title": "to_mri", "text": "def to_mri(self, subject, trans, subjects_dir=None, verbose=None):\n        \"\"\"Convert dipole location from head to MRI surface RAS coordinates.\n\n        Parameters\n        ----------\n        %(subject)s\n        %(trans_not_none)s\n        %(subjects_dir)s\n        %(verbose)s\n\n        Returns\n        -------\n        pos_mri : array, shape (n_pos, 3)\n            The Freesurfer surface RAS coordinates (in mm) of pos.\n        \"\"\"\n        mri_head_t, trans = _get_trans(trans)\n        return head_to_mri(\n            self.pos,\n            subject,\n            mri_head_t,\n            subjects_dir=subjects_dir,\n            verbose=verbose,\n            kind=\"mri\",\n        )", "metadata": {}}
{"_id": "mne_mne_dipole.py_to_volume_labels_code", "title": "to_volume_labels", "text": "def to_volume_labels(\n        self,\n        trans,\n        subject=\"fsaverage\",\n        aseg=\"aparc+aseg\",\n        subjects_dir=None,\n        verbose=None,\n    ):\n        \"\"\"Find an ROI in atlas for the dipole positions.\n\n        Parameters\n        ----------\n        %(trans)s\n\n            .. versionchanged:: 0.19\n                Support for 'fsaverage' argument.\n        %(subject)s\n        %(aseg)s\n        %(subjects_dir)s\n        %(verbose)s\n\n        Returns\n        -------\n        labels : list\n            List of anatomical region names from anatomical segmentation atlas.\n\n        Notes\n        -----\n        .. versionadded:: 0.24\n        \"\"\"\n        aseg_img, aseg_data = _get_aseg(aseg, subject, subjects_dir)\n        mri_vox_t = np.linalg.inv(aseg_img.header.get_vox2ras_tkr())\n\n        # Load freesurface atlas LUT\n        lut_inv = read_freesurfer_lut()[0]\n        lut = {v: k for k, v in lut_inv.items()}\n\n        # transform to voxel space from head space\n        pos = self.to_mri(subject, trans, subjects_dir=subjects_dir, verbose=verbose)\n        pos = apply_trans(mri_vox_t, pos)\n        pos = np.rint(pos).astype(int)\n\n        # Get voxel value and label from LUT\n        labels = [lut.get(aseg_data[tuple(coord)], \"Unknown\") for coord in pos]\n        return labels", "metadata": {}}
{"_id": "mne_mne_dipole.py_plot_amplitudes_code", "title": "plot_amplitudes", "text": "def plot_amplitudes(self, color=\"k\", show=True):\n        \"\"\"Plot the dipole amplitudes as a function of time.\n\n        Parameters\n        ----------\n        color : matplotlib color\n            Color to use for the trace.\n        show : bool\n            Show figure if True.\n\n        Returns\n        -------\n        fig : matplotlib.figure.Figure\n            The figure object containing the plot.\n        \"\"\"\n        return plot_dipole_amplitudes([self], [color], show)", "metadata": {}}
{"_id": "mne_mne_dipole.py_copy_code", "title": "copy", "text": "def copy(self):\n        \"\"\"Copy the DipoleFixed object.\n\n        Returns\n        -------\n        inst : instance of DipoleFixed\n            The copy.\n\n        Notes\n        -----\n        .. versionadded:: 0.16\n        \"\"\"\n        return deepcopy(self)", "metadata": {}}
{"_id": "mne_mne_dipole.py_ch_names_code", "title": "ch_names", "text": "def ch_names(self):\n        \"\"\"Channel names.\"\"\"\n        return self.info[\"ch_names\"]", "metadata": {}}
{"_id": "mne_mne_dipole.py_save_code", "title": "save", "text": "def save(self, fname, *, overwrite=False, verbose=None):\n        \"\"\"Save fixed dipole in FIF format.\n\n        The ``.fif[.gz]`` format is for :class:`mne.DipoleFixed` objects, that is,\n        fixed-position and optionally fixed-orientation dipole fits. For these fits,\n        the amplitude (and optionally orientation) vary as a function of time,\n        but not the position.\n\n        Parameters\n        ----------\n        fname : path-like\n            The name of the FIF file. Must end with ``'-dip.fif'`` or\n            ``'-dip.fif.gz'`` to make it explicit that the file contains\n            dipole information in FIF format.\n        %(overwrite)s\n\n            .. versionadded:: 1.10.0\n        %(verbose)s\n\n        See Also\n        --------\n        read_dipole\n        \"\"\"\n        check_fname(\n            fname,\n            \"DipoleFixed\",\n            (\n                \"-dip.fif\",\n                \"-dip.fif.gz\",\n                \"_dip.fif\",\n                \"_dip.fif.gz\",\n            ),\n            (\".fif\", \".fif.gz\"),\n        )\n        _write_evokeds(fname, self, check=False, overwrite=overwrite)", "metadata": {}}
{"_id": "mne_mne_dipole.py_plot_code", "title": "plot", "text": "def plot(self, show=True, time_unit=\"s\"):\n        \"\"\"Plot dipole data.\n\n        Parameters\n        ----------\n        show : bool\n            Call pyplot.show() at the end or not.\n        time_unit : str\n            The units for the time axis, can be \"ms\" or \"s\" (default).\n\n            .. versionadded:: 0.16\n\n        Returns\n        -------\n        fig : instance of matplotlib.figure.Figure\n            The figure containing the time courses.\n        \"\"\"\n        return _plot_evoked(\n            self,\n            picks=None,\n            exclude=(),\n            unit=True,\n            show=show,\n            ylim=None,\n            xlim=\"tight\",\n            proj=False,\n            hline=None,\n            units=None,\n            scalings=None,\n            titles=None,\n            axes=None,\n            gfp=False,\n            window_title=None,\n            spatial_colors=False,\n            plot_type=\"butterfly\",\n            selectable=False,\n            time_unit=time_unit,\n        )", "metadata": {}}
{"_id": "mne_mne_rank.py_estimate_rank_code", "title": "estimate_rank", "text": "def estimate_rank(\n    data,\n    tol=\"auto\",\n    return_singular=False,\n    norm=True,\n    tol_kind=\"absolute\",\n    verbose=None,\n):\n    \"\"\"Estimate the rank of data.\n\n    This function will normalize the rows of the data (typically\n    channels or vertices) such that non-zero singular values\n    should be close to one.\n\n    Parameters\n    ----------\n    data : array\n        Data to estimate the rank of (should be 2-dimensional).\n    %(tol_rank)s\n    return_singular : bool\n        If True, also return the singular values that were used\n        to determine the rank.\n    norm : bool\n        If True, data will be scaled by their estimated row-wise norm.\n        Else data are assumed to be scaled. Defaults to True.\n    %(tol_kind_rank)s\n\n    Returns\n    -------\n    rank : int\n        Estimated rank of the data.\n    s : array\n        If return_singular is True, the singular values that were\n        thresholded to determine the rank are also returned.\n    \"\"\"\n    if norm:\n        data = data.copy()  # operate on a copy\n        norms = _compute_row_norms(data)\n        data /= norms[:, np.newaxis]\n    s = linalg.svdvals(data)\n    rank = _estimate_rank_from_s(s, tol, tol_kind)\n    if return_singular is True:\n        return rank, s\n    else:\n        return rank", "metadata": {}}
{"_id": "mne_mne_rank.py_compute_rank_code", "title": "compute_rank", "text": "def compute_rank(\n    inst,\n    rank=None,\n    scalings=None,\n    info=None,\n    tol=\"auto\",\n    proj=True,\n    tol_kind=\"absolute\",\n    on_rank_mismatch=\"ignore\",\n    verbose=None,\n):\n    \"\"\"Compute the rank of data or noise covariance.\n\n    This function will normalize the rows of the data (typically\n    channels or vertices) such that non-zero singular values\n    should be close to one. It operates on :term:`data channels` only.\n\n    Parameters\n    ----------\n    inst : instance of Raw, Epochs, or Covariance\n        Raw measurements to compute the rank from or the covariance.\n    %(rank_none)s\n    scalings : dict | None (default None)\n        Defaults to ``dict(mag=1e15, grad=1e13, eeg=1e6)``.\n        These defaults will scale different channel types\n        to comparable values.\n    %(info)s Only necessary if ``inst`` is a :class:`mne.Covariance`\n        object (since this does not provide ``inst.info``).\n    %(tol_rank)s\n    proj : bool\n        If True, all projs in ``inst`` and ``info`` will be applied or\n        considered when ``rank=None`` or ``rank='info'``.\n    %(tol_kind_rank)s\n    %(on_rank_mismatch)s\n    %(verbose)s\n\n    Returns\n    -------\n    rank : dict\n        Estimated rank of the data for each channel type.\n        To get the total rank, you can use ``sum(rank.values())``.\n\n    Notes\n    -----\n    .. versionadded:: 0.18\n    \"\"\"\n    return _compute_rank(\n        inst=inst,\n        rank=rank,\n        scalings=scalings,\n        info=info,\n        tol=tol,\n        proj=proj,\n        tol_kind=tol_kind,\n        on_rank_mismatch=on_rank_mismatch,\n    )", "metadata": {}}
{"_id": "mne_mne_io/_read_raw.py_split_name_ext_code", "title": "split_name_ext", "text": "def split_name_ext(fname):\n    \"\"\"Return name and supported file extension.\"\"\"\n    maxsuffixes = max(ext.count(\".\") for ext in _get_supported())\n    suffixes = Path(fname).suffixes\n    for si in range(-maxsuffixes, 0):\n        ext = \"\".join(suffixes[si:]).lower()\n        if ext in _get_readers():\n            return Path(fname).name[: -len(ext)], ext\n    return fname, None", "metadata": {}}
{"_id": "mne_mne_io/_read_raw.py_read_raw_code", "title": "read_raw", "text": "def read_raw(fname, *, preload=False, verbose=None, **kwargs) -> BaseRaw:\n    \"\"\"Read raw file.\n\n    This function is a convenient wrapper for readers defined in `mne.io`. The\n    correct reader is automatically selected based on the detected file format.\n    All function arguments are passed to the respective reader.\n\n    The following readers are currently supported:\n\n    * `~mne.io.read_raw_ant`\n    * `~mne.io.read_raw_artemis123`\n    * `~mne.io.read_raw_bdf`\n    * `~mne.io.read_raw_boxy`\n    * `~mne.io.read_raw_brainvision`\n    * `~mne.io.read_raw_cnt`\n    * `~mne.io.read_raw_ctf`\n    * `~mne.io.read_raw_curry`\n    * `~mne.io.read_raw_edf`\n    * `~mne.io.read_raw_eeglab`\n    * `~mne.io.read_raw_egi`\n    * `~mne.io.read_raw_eximia`\n    * `~mne.io.read_raw_eyelink`\n    * `~mne.io.read_raw_fieldtrip`\n    * `~mne.io.read_raw_fif`\n    * `~mne.io.read_raw_fil`\n    * `~mne.io.read_raw_gdf`\n    * `~mne.io.read_raw_kit`\n    * `~mne.io.read_raw_nedf`\n    * `~mne.io.read_raw_nicolet`\n    * `~mne.io.read_raw_nihon`\n    * `~mne.io.read_raw_nirx`\n    * `~mne.io.read_raw_nsx`\n    * `~mne.io.read_raw_persyst`\n    * `~mne.io.read_raw_snirf`\n\n    Parameters\n    ----------\n    fname : path-like\n        Name of the file to read.\n    %(preload)s\n    %(verbose)s\n    **kwargs\n        Additional keyword arguments to pass to the underlying reader. For\n        details, see the arguments of the reader for the respective file\n        format.\n\n    Returns\n    -------\n    raw : mne.io.Raw\n        Raw object.\n    \"\"\"\n    _, ext = split_name_ext(fname)\n    kwargs[\"verbose\"] = verbose\n    kwargs[\"preload\"] = preload\n    readers = _get_readers()\n    if ext not in readers:\n        _read_unsupported(fname)\n    these_readers = list(readers[ext].values())\n    for reader in these_readers:\n        try:\n            return reader(fname, **kwargs)\n        except Exception:\n            if len(these_readers) == 1:\n                raise\n    else:\n        choices = \"\\n\".join(\n            f\"mne.io.{func.__name__.ljust(20)} ({kind})\"\n            for kind, func in readers[ext].items()\n        )\n        raise RuntimeError(\n            \"Could not read file using any of the possible readers for \"\n            f\"extension {ext}. Consider trying to read the file directly with \"\n            f\"one of:\\n{choices}\"\n        )", "metadata": {}}
{"_id": "mne_mne_io/base.py_concatenate_raws_code", "title": "concatenate_raws", "text": "def concatenate_raws(\n    raws, preload=None, events_list=None, *, on_mismatch=\"raise\", verbose=None\n):\n    \"\"\"Concatenate `~mne.io.Raw` instances as if they were continuous.\n\n    .. note:: ``raws[0]`` is modified in-place to achieve the concatenation.\n              Boundaries of the raw files are annotated bad. If you wish to use\n              the data as continuous recording, you can remove the boundary\n              annotations after concatenation (see\n              :meth:`mne.Annotations.delete`).\n\n    Parameters\n    ----------\n    raws : list\n        List of `~mne.io.Raw` instances to concatenate (in order).\n    %(preload_concatenate)s\n    events_list : None | list\n        The events to concatenate. Defaults to ``None``.\n    %(on_mismatch_info)s\n    %(verbose)s\n\n    Returns\n    -------\n    raw : instance of Raw\n        The result of the concatenation (first Raw instance passed in).\n    events : ndarray of int, shape (n_events, 3)\n        The events. Only returned if ``event_list`` is not None.\n    \"\"\"\n    for idx, raw in enumerate(raws[1:], start=1):\n        _ensure_infos_match(\n            info1=raws[0].info,\n            info2=raw.info,\n            name=f\"raws[{idx}]\",\n            on_mismatch=on_mismatch,\n        )\n\n    if events_list is not None:\n        if len(events_list) != len(raws):\n            raise ValueError(\n                \"`raws` and `event_list` are required to be of the same length\"\n            )\n        first, last = zip(*[(r.first_samp, r.last_samp) for r in raws])\n        events = concatenate_events(events_list, first, last)\n    raws[0].append(raws[1:], preload)\n\n    if events_list is None:\n        return raws[0]\n    else:\n        return raws[0], events", "metadata": {}}
{"_id": "mne_mne_io/base.py_match_channel_orders_code", "title": "match_channel_orders", "text": "def match_channel_orders(insts, copy=True):\n    \"\"\"Ensure consistent channel order across instances (Raw, Epochs, or Evoked).\n\n    Parameters\n    ----------\n    insts : list\n        List of :class:`~mne.io.Raw`, :class:`~mne.Epochs`,\n        or :class:`~mne.Evoked` instances to order.\n    %(copy_df)s\n\n    Returns\n    -------\n    list of Raw | list of Epochs | list of Evoked\n        List of instances (Raw, Epochs, or Evoked) with channel orders matched\n        according to the order they had in the first item in the ``insts`` list.\n    \"\"\"\n    insts = deepcopy(insts) if copy else insts\n    ch_order = insts[0].ch_names\n    for inst in insts[1:]:\n        inst.reorder_channels(ch_order)\n    return insts", "metadata": {}}
{"_id": "mne_mne_io/base.py_apply_gradient_compensation_code", "title": "apply_gradient_compensation", "text": "def apply_gradient_compensation(self, grade, verbose=None):\n        \"\"\"Apply CTF gradient compensation.\n\n        .. warning:: The compensation matrices are stored with single\n                     precision, so repeatedly switching between different\n                     of compensation (e.g., 0->1->3->2) can increase\n                     numerical noise, especially if data are saved to\n                     disk in between changing grades. It is thus best to\n                     only use a single gradient compensation level in\n                     final analyses.\n\n        Parameters\n        ----------\n        grade : int\n            CTF gradient compensation level.\n        %(verbose)s\n\n        Returns\n        -------\n        raw : instance of Raw\n            The modified Raw instance. Works in-place.\n        \"\"\"\n        grade = int(grade)\n        current_comp = self.compensation_grade\n        if current_comp != grade:\n            if self.proj:\n                raise RuntimeError(\n                    \"Cannot change compensation on data where projectors have been \"\n                    \"applied.\"\n                )\n            # Figure out what operator to use (varies depending on preload)\n            from_comp = current_comp if self.preload else self._read_comp_grade\n            comp = make_compensator(self.info, from_comp, grade)\n            logger.info(\n                \"Compensator constructed to change %d -> %d\", current_comp, grade\n            )\n            set_current_comp(self.info, grade)\n            # We might need to apply it to our data now\n            if self.preload:\n                logger.info(\"Applying compensator to loaded data\")\n                lims = np.concatenate(\n                    [np.arange(0, len(self.times), 10000), [len(self.times)]]\n                )\n                for start, stop in zip(lims[:-1], lims[1:]):\n                    self._data[:, start:stop] = np.dot(comp, self._data[:, start:stop])\n            else:\n                self._comp = comp  # store it for later use\n        return self", "metadata": {}}
{"_id": "mne_mne_io/base.py_load_data_code", "title": "load_data", "text": "def load_data(self, verbose=None):\n        \"\"\"Load raw data.\n\n        Parameters\n        ----------\n        %(verbose)s\n\n        Returns\n        -------\n        raw : instance of Raw\n            The raw object with data.\n\n        Notes\n        -----\n        This function will load raw data if it was not already preloaded.\n        If data were already preloaded, it will do nothing.\n\n        .. versionadded:: 0.10.0\n        \"\"\"\n        if not self.preload:\n            self._preload_data(True)\n        return self", "metadata": {}}
{"_id": "mne_mne_io/base.py_first_samp_code", "title": "first_samp", "text": "def first_samp(self):\n        \"\"\"The first data sample.\n\n        See :term:`first_samp`.\n        \"\"\"\n        return self._cropped_samp", "metadata": {}}
{"_id": "mne_mne_io/base.py_first_time_code", "title": "first_time", "text": "def first_time(self):\n        \"\"\"The first time point (including first_samp but not meas_date).\"\"\"\n        return self._first_time", "metadata": {}}
{"_id": "mne_mne_io/base.py_last_samp_code", "title": "last_samp", "text": "def last_samp(self):\n        \"\"\"The last data sample.\"\"\"\n        return self.first_samp + sum(self._raw_lengths) - 1", "metadata": {}}
{"_id": "mne_mne_io/base.py_time_as_index_code", "title": "time_as_index", "text": "def time_as_index(self, times, use_rounding=False, origin=None):\n        \"\"\"Convert time to indices.\n\n        Parameters\n        ----------\n        times : list-like | float | int\n            List of numbers or a number representing points in time.\n        use_rounding : bool\n            If True, use rounding (instead of truncation) when converting\n            times to indices. This can help avoid non-unique indices.\n        origin : datetime | float | int | None\n            Time reference for times. If None, ``times`` are assumed to be\n            relative to :term:`first_samp`.\n\n            .. versionadded:: 0.17.0\n\n        Returns\n        -------\n        index : ndarray\n            Indices relative to :term:`first_samp` corresponding to the times\n            supplied.\n        \"\"\"\n        origin = _handle_meas_date(origin)\n        if origin is None:\n            delta = 0\n        elif self.info[\"meas_date\"] is None:\n            raise ValueError(\n                f'origin must be None when info[\"meas_date\"] is None, got {origin}'\n            )\n        else:\n            first_samp_in_abs_time = self.info[\"meas_date\"] + timedelta(\n                0, self._first_time\n            )\n            delta = (origin - first_samp_in_abs_time).total_seconds()\n        times = np.atleast_1d(times) + delta\n\n        return super().time_as_index(times, use_rounding)", "metadata": {}}
{"_id": "mne_mne_io/base.py_annotations_code", "title": "annotations", "text": "def annotations(self):  # noqa: D401\n        \"\"\":class:`~mne.Annotations` for marking segments of data.\"\"\"\n        return self._annotations", "metadata": {}}
{"_id": "mne_mne_io/base.py_filenames_code", "title": "filenames", "text": "def filenames(self) -> tuple[Path | None, ...]:\n        \"\"\"The filenames used.\n\n        :type: :class:`tuple` of :class:`pathlib.Path` | ``None``\n        \"\"\"\n        return tuple(self._filenames)", "metadata": {}}
{"_id": "mne_mne_io/base.py_filenames_code", "title": "filenames", "text": "def filenames(self, value):\n        \"\"\"The filenames used, cast to list of paths.\"\"\"  # noqa: D401\n        _validate_type(value, (list, tuple), \"filenames\")\n        if isinstance(value, tuple):\n            value = list(value)\n        for k, elt in enumerate(value):\n            if elt is not None:\n                value[k] = _check_fname(elt, overwrite=\"read\", must_exist=False)\n                if not value[k].exists():\n                    # check existence separately from _check_fname since some\n                    # fileformats use directories instead of files and '_check_fname'\n                    # does not handle it correctly.\n                    raise FileNotFoundError(f\"File {value[k]} not found.\")\n        self._filenames = list(value)", "metadata": {}}
{"_id": "mne_mne_io/base.py_set_annotations_code", "title": "set_annotations", "text": "def set_annotations(\n        self, annotations, emit_warning=True, on_missing=\"raise\", *, verbose=None\n    ):\n        \"\"\"Setter for annotations.\n\n        This setter checks if they are inside the data range.\n\n        Parameters\n        ----------\n        annotations : instance of mne.Annotations | None\n            Annotations to set. If None, the annotations is defined\n            but empty.\n        %(emit_warning)s\n            The default is True.\n        %(on_missing_ch_names)s\n        %(verbose)s\n\n        Returns\n        -------\n        self : instance of Raw\n            The raw object with annotations.\n        \"\"\"\n        meas_date = _handle_meas_date(self.info[\"meas_date\"])\n        if annotations is None:\n            self._annotations = Annotations([], [], [], meas_date)\n        else:\n            _validate_type(annotations, Annotations, \"annotations\")\n\n            if meas_date is None and annotations.orig_time is not None:\n                raise RuntimeError(\n                    \"Ambiguous operation. Setting an Annotation object with known \"\n                    \"``orig_time`` to a raw object which has ``meas_date`` set to None \"\n                    \"is ambiguous. Please, either set a meaningful ``meas_date`` to \"\n                    \"the raw object; or set ``orig_time`` to None in which case the \"\n                    \"annotation onsets would be taken in reference to the first sample \"\n                    \"of the raw object.\"\n                )\n\n            delta = 1.0 / self.info[\"sfreq\"]\n            new_annotations = annotations.copy()\n            new_annotations._prune_ch_names(self.info, on_missing)\n            if annotations.orig_time is None:\n                new_annotations.crop(\n                    0, self.times[-1] + delta, emit_warning=emit_warning\n                )\n                new_annotations.onset += self._first_time\n            else:\n                tmin = meas_date + timedelta(0, self._first_time)\n                tmax = tmin + timedelta(seconds=self.times[-1] + delta)\n                new_annotations.crop(tmin=tmin, tmax=tmax, emit_warning=emit_warning)\n                new_annotations.onset -= (\n                    meas_date - new_annotations.orig_time\n                ).total_seconds()\n            new_annotations._orig_time = meas_date\n\n            self._annotations = new_annotations\n\n        return self", "metadata": {}}
{"_id": "mne_mne_io/base.py_get_data_code", "title": "get_data", "text": "def get_data(\n        self,\n        picks=None,\n        start=0,\n        stop=None,\n        reject_by_annotation=None,\n        return_times=False,\n        units=None,\n        *,\n        tmin=None,\n        tmax=None,\n        verbose=None,\n    ):\n        \"\"\"Get data in the given range.\n\n        Parameters\n        ----------\n        %(picks_all)s\n        start : int\n            The first sample to include. Defaults to 0.\n        stop : int | None\n            End sample (first not to include). If None (default), the end of\n            the data is  used.\n        reject_by_annotation : None | 'omit' | 'NaN'\n            Whether to reject by annotation. If None (default), no rejection is\n            done. If 'omit', segments annotated with description starting with\n            'bad' are omitted. If 'NaN', the bad samples are filled with NaNs.\n        return_times : bool\n            Whether to return times as well. Defaults to False.\n        %(units)s\n        tmin : int | float | None\n            Start time of data to get in seconds. The ``tmin`` parameter is\n            ignored if the ``start`` parameter is bigger than 0.\n\n            .. versionadded:: 0.24.0\n        tmax : int | float | None\n            End time of data to get in seconds. The ``tmax`` parameter is\n            ignored if the ``stop`` parameter is defined.\n\n            .. versionadded:: 0.24.0\n        %(verbose)s\n\n        Returns\n        -------\n        data : ndarray, shape (n_channels, n_times)\n            Copy of the data in the given range.\n        times : ndarray, shape (n_times,)\n            Times associated with the data samples. Only returned if\n            return_times=True.\n\n        Notes\n        -----\n        .. versionadded:: 0.14.0\n        \"\"\"\n        # validate types\n        _validate_type(start, types=(\"int-like\"), item_name=\"start\", type_name=\"int\")\n        _validate_type(\n            stop, types=(\"int-like\", None), item_name=\"stop\", type_name=\"int, None\"\n        )\n\n        picks = _picks_to_idx(self.info, picks, \"all\", exclude=())\n\n        # Get channel factors for conversion into specified unit\n        # (vector of ones if no conversion needed)\n        if units is not None:\n            ch_factors = _get_ch_factors(self, units, picks)\n\n        # convert to ints\n        picks = np.atleast_1d(np.arange(self.info[\"nchan\"])[picks])\n\n        # handle start/tmin stop/tmax\n        tmin_start, tmax_stop = self._handle_tmin_tmax(tmin, tmax)\n\n        # tmin/tmax are ignored if start/stop are defined to\n        # something other than their defaults\n        start = tmin_start if start == 0 else start\n        stop = tmax_stop if stop is None else stop\n\n        # truncate start/stop to the open interval [0, n_times]\n        start = min(max(0, start), self.n_times)\n        stop = min(max(0, stop), self.n_times)\n\n        if len(self.annotations) == 0 or reject_by_annotation is None:\n            getitem = self._getitem(\n                (picks, slice(start, stop)), return_times=return_times\n            )\n            if return_times:\n                data, times = getitem\n                if units is not None:\n                    data *= ch_factors[:, np.newaxis]\n                return data, times\n            if units is not None:\n                getitem *= ch_factors[:, np.newaxis]\n            return getitem\n        _check_option(\n            \"reject_by_annotation\", reject_by_annotation.lower(), [\"omit\", \"nan\"]\n        )\n        onsets, ends = _annotations_starts_stops(self, [\"BAD\"])\n        keep = (onsets < stop) & (ends > start)\n        onsets = np.maximum(onsets[keep], start)\n        ends = np.minimum(ends[keep], stop)\n        if len(onsets) == 0:\n            data, times = self[picks, start:stop]\n            if units is not None:\n                data *= ch_factors[:, np.newaxis]\n            if return_times:\n                return data, times\n            return data\n        n_samples = stop - start  # total number of samples\n        used = np.ones(n_samples, bool)\n        for onset, end in zip(onsets, ends):\n            if onset >= end:\n                continue\n            used[onset - start : end - start] = False\n        used = np.concatenate([[False], used, [False]])\n        starts = np.where(~used[:-1] & used[1:])[0] + start\n        stops = np.where(used[:-1] & ~used[1:])[0] + start\n        n_kept = (stops - starts).sum()  # kept samples\n        n_rejected = n_samples - n_kept  # rejected samples\n        if n_rejected > 0:\n            if reject_by_annotation == \"omit\":\n                msg = (\n                    \"Omitting {} of {} ({:.2%}) samples, retaining {} ({:.2%}) samples.\"\n                )\n                logger.info(\n                    msg.format(\n                        n_rejected,\n                        n_samples,\n                        n_rejected / n_samples,\n                        n_kept,\n                        n_kept / n_samples,\n                    )\n                )\n                data = np.zeros((len(picks), n_kept))\n                times = np.zeros(data.shape[1])\n                idx = 0\n                for start, stop in zip(starts, stops):  # get the data\n                    if start == stop:\n                        continue\n                    end = idx + stop - start\n                    data[:, idx:end], times[idx:end] = self[picks, start:stop]\n                    idx = end\n            else:\n                msg = (\n                    \"Setting {} of {} ({:.2%}) samples to NaN, retaining {}\"\n                    \" ({:.2%}) samples.\"\n                )\n                logger.info(\n                    msg.format(\n                        n_rejected,\n                        n_samples,\n                        n_rejected / n_samples,\n                        n_kept,\n                        n_kept / n_samples,\n                    )\n                )\n                data, times = self[picks, start:stop]\n                data[:, ~used[1:-1]] = np.nan\n        else:\n            data, times = self[picks, start:stop]\n\n        if units is not None:\n            data *= ch_factors[:, np.newaxis]\n        if return_times:\n            return data, times\n        return data", "metadata": {}}
{"_id": "mne_mne_io/base.py_apply_function_code", "title": "apply_function", "text": "def apply_function(\n        self,\n        fun,\n        picks=None,\n        dtype=None,\n        n_jobs=None,\n        channel_wise=True,\n        verbose=None,\n        **kwargs,\n    ):\n        \"\"\"Apply a function to a subset of channels.\n\n        %(applyfun_summary_raw)s\n\n        Parameters\n        ----------\n        %(fun_applyfun)s\n        %(picks_all_data_noref)s\n        %(dtype_applyfun)s\n        %(n_jobs)s Ignored if ``channel_wise=False`` as the workload\n            is split across channels.\n        %(channel_wise_applyfun)s\n\n            .. versionadded:: 0.18\n        %(verbose)s\n        %(kwargs_fun)s\n\n        Returns\n        -------\n        self : instance of Raw\n            The raw object with transformed data.\n        \"\"\"\n        _check_preload(self, \"raw.apply_function\")\n        picks = _picks_to_idx(self.info, picks, exclude=(), with_ref_meg=False)\n\n        if not callable(fun):\n            raise ValueError(\"fun needs to be a function\")\n\n        data_in = self._data\n        if dtype is not None and dtype != self._data.dtype:\n            self._data = self._data.astype(dtype)\n\n        args = getfullargspec(fun).args + getfullargspec(fun).kwonlyargs\n        if channel_wise is False:\n            if (\"ch_idx\" in args) or (\"ch_name\" in args):\n                raise ValueError(\n                    \"apply_function cannot access ch_idx or ch_name \"\n                    \"when channel_wise=False\"\n                )\n        if \"ch_idx\" in args:\n            logger.info(\"apply_function requested to access ch_idx\")\n        if \"ch_name\" in args:\n            logger.info(\"apply_function requested to access ch_name\")\n\n        if channel_wise:\n            parallel, p_fun, n_jobs = parallel_func(_check_fun, n_jobs)\n            if n_jobs == 1:\n                # modify data inplace to save memory\n                for ch_idx in picks:\n                    if \"ch_idx\" in args:\n                        kwargs.update(ch_idx=ch_idx)\n                    if \"ch_name\" in args:\n                        kwargs.update(ch_name=self.info[\"ch_names\"][ch_idx])\n                    self._data[ch_idx, :] = _check_fun(\n                        fun, data_in[ch_idx, :], **kwargs\n                    )\n            else:\n                # use parallel function\n                data_picks_new = parallel(\n                    p_fun(\n                        fun,\n                        data_in[ch_idx],\n                        **kwargs,\n                        **{\n                            k: v\n                            for k, v in [\n                                (\"ch_name\", self.info[\"ch_names\"][ch_idx]),\n                                (\"ch_idx\", ch_idx),\n                            ]\n                            if k in args\n                        },\n                    )\n                    for ch_idx in picks\n                )\n                for run_idx, ch_idx in enumerate(picks):\n                    self._data[ch_idx, :] = data_picks_new[run_idx]\n        else:\n            self._data[picks, :] = _check_fun(fun, data_in[picks, :], **kwargs)\n\n        return self", "metadata": {}}
{"_id": "mne_mne_io/base.py_notch_filter_code", "title": "notch_filter", "text": "def notch_filter(\n        self,\n        freqs,\n        picks=None,\n        filter_length=\"auto\",\n        notch_widths=None,\n        trans_bandwidth=1.0,\n        n_jobs=None,\n        method=\"fir\",\n        iir_params=None,\n        mt_bandwidth=None,\n        p_value=0.05,\n        phase=\"zero\",\n        fir_window=\"hamming\",\n        fir_design=\"firwin\",\n        pad=\"reflect_limited\",\n        skip_by_annotation=(\"edge\", \"bad_acq_skip\"),\n        verbose=None,\n    ):\n        \"\"\"Notch filter a subset of channels.\n\n        Parameters\n        ----------\n        freqs : float | array of float | None\n            Specific frequencies to filter out from data, e.g.,\n            ``np.arange(60, 241, 60)`` in the US or ``np.arange(50, 251, 50)``\n            in Europe. ``None`` can only be used with the mode\n            ``'spectrum_fit'``, where an F test is used to find sinusoidal\n            components.\n        %(picks_all_data)s\n        %(filter_length_notch)s\n        notch_widths : float | array of float | None\n            Width of each stop band (centred at each freq in freqs) in Hz.\n            If None, ``freqs / 200`` is used.\n        trans_bandwidth : float\n            Width of the transition band in Hz.\n            Only used for ``method='fir'`` and ``method='iir'``.\n        %(n_jobs_fir)s\n        %(method_fir)s\n        %(iir_params)s\n        mt_bandwidth : float | None\n            The bandwidth of the multitaper windowing function in Hz.\n            Only used in 'spectrum_fit' mode.\n        p_value : float\n            P-value to use in F-test thresholding to determine significant\n            sinusoidal components to remove when ``method='spectrum_fit'`` and\n            ``freqs=None``. Note that this will be Bonferroni corrected for the\n            number of frequencies, so large p-values may be justified.\n        %(phase)s\n        %(fir_window)s\n        %(fir_design)s\n        %(pad_fir)s\n            The default is ``'reflect_limited'``.\n\n            .. versionadded:: 0.15\n        %(skip_by_annotation)s\n        %(verbose)s\n\n        Returns\n        -------\n        raw : instance of Raw\n            The raw instance with filtered data.\n\n        See Also\n        --------\n        mne.filter.notch_filter\n        mne.io.Raw.filter\n\n        Notes\n        -----\n        Applies a zero-phase notch filter to the channels selected by\n        \"picks\". By default the data of the Raw object is modified inplace.\n\n        The Raw object has to have the data loaded e.g. with ``preload=True``\n        or ``self.load_data()``.\n\n        .. note:: If n_jobs > 1, more memory is required as\n                  ``len(picks) * n_times`` additional time points need to\n                  be temporarily stored in memory.\n\n        For details, see :func:`mne.filter.notch_filter`.\n        \"\"\"\n        fs = float(self.info[\"sfreq\"])\n        picks = _picks_to_idx(self.info, picks, exclude=(), none=\"data_or_ica\")\n        _check_preload(self, \"raw.notch_filter\")\n        onsets, ends = _annotations_starts_stops(self, skip_by_annotation, invert=True)\n        logger.info(\n            \"Filtering raw data in %d contiguous segment%s\", len(onsets), _pl(onsets)\n        )\n        for si, (start, stop) in enumerate(zip(onsets, ends)):\n            notch_filter(\n                self._data[:, start:stop],\n                fs,\n                freqs,\n                filter_length=filter_length,\n                notch_widths=notch_widths,\n                trans_bandwidth=trans_bandwidth,\n                method=method,\n                iir_params=iir_params,\n                mt_bandwidth=mt_bandwidth,\n                p_value=p_value,\n                picks=picks,\n                n_jobs=n_jobs,\n                copy=False,\n                phase=phase,\n                fir_window=fir_window,\n                fir_design=fir_design,\n                pad=pad,\n            )\n        return self", "metadata": {}}
{"_id": "mne_mne_io/base.py_resample_code", "title": "resample", "text": "def resample(\n        self,\n        sfreq,\n        *,\n        npad=\"auto\",\n        window=\"auto\",\n        stim_picks=None,\n        n_jobs=None,\n        events=None,\n        pad=\"auto\",\n        method=\"fft\",\n        verbose=None,\n    ):\n        \"\"\"Resample all channels.\n\n        If appropriate, an anti-aliasing filter is applied before resampling.\n        See :ref:`resampling-and-decimating` for more information.\n\n        .. warning:: The intended purpose of this function is primarily to\n                     speed up computations (e.g., projection calculation) when\n                     precise timing of events is not required, as downsampling\n                     raw data effectively jitters trigger timings. It is\n                     generally recommended not to epoch downsampled data,\n                     but instead epoch and then downsample, as epoching\n                     downsampled data jitters triggers.\n                     For more, see\n                     `this illustrative gist\n                     <https://gist.github.com/larsoner/01642cb3789992fbca59>`_.\n\n                     If resampling the continuous data is desired, it is\n                     recommended to construct events using the original data.\n                     The event onsets can be jointly resampled with the raw\n                     data using the 'events' parameter (a resampled copy is\n                     returned).\n\n        Parameters\n        ----------\n        sfreq : float\n            New sample rate to use.\n        %(npad_resample)s\n        %(window_resample)s\n        stim_picks : list of int | None\n            Stim channels. These channels are simply subsampled or\n            supersampled (without applying any filtering). This reduces\n            resampling artifacts in stim channels, but may lead to missing\n            triggers. If None, stim channels are automatically chosen using\n            :func:`mne.pick_types`.\n        %(n_jobs_cuda)s\n        events : 2D array, shape (n_events, 3) | None\n            An optional event matrix. When specified, the onsets of the events\n            are resampled jointly with the data. NB: The input events are not\n            modified, but a new array is returned with the raw instead.\n        %(pad_resample_auto)s\n\n            .. versionadded:: 0.15\n        %(method_resample)s\n\n            .. versionadded:: 1.7\n        %(verbose)s\n\n        Returns\n        -------\n        raw : instance of Raw\n            The resampled version of the raw object.\n        events : array, shape (n_events, 3) | None\n            If events are jointly resampled, these are returned with the raw.\n\n        See Also\n        --------\n        mne.io.Raw.filter\n        mne.Epochs.resample\n\n        Notes\n        -----\n        For some data, it may be more accurate to use ``npad=0`` to reduce\n        artifacts. This is dataset dependent -- check your data!\n\n        For optimum performance and to make use of ``n_jobs > 1``, the raw\n        object has to have the data loaded e.g. with ``preload=True`` or\n        ``self.load_data()``, but this increases memory requirements. The\n        resulting raw object will have the data loaded into memory.\n        \"\"\"\n        sfreq = float(sfreq)\n        o_sfreq = float(self.info[\"sfreq\"])\n        if _check_resamp_noop(sfreq, o_sfreq):\n            if events is not None:\n                return self, events.copy()\n            else:\n                return self\n\n        # When no event object is supplied, some basic detection of dropped\n        # events is performed to generate a warning. Finding events can fail\n        # for a variety of reasons, e.g. if no stim channel is present or it is\n        # corrupted. This should not stop the resampling from working. The\n        # warning should simply not be generated in this case.\n        if events is None:\n            try:\n                original_events = find_events(self)\n            except Exception:\n                pass\n\n        offsets = np.concatenate(([0], np.cumsum(self._raw_lengths)))\n\n        # set up stim channel processing\n        if stim_picks is None:\n            stim_picks = pick_types(\n                self.info, meg=False, ref_meg=False, stim=True, exclude=[]\n            )\n        else:\n            stim_picks = _picks_to_idx(\n                self.info, stim_picks, exclude=(), with_ref_meg=False\n            )\n\n        kwargs = dict(\n            up=sfreq,\n            down=o_sfreq,\n            npad=npad,\n            window=window,\n            n_jobs=n_jobs,\n            pad=pad,\n            method=method,\n        )\n        ratio, n_news = zip(\n            *(\n                _resamp_ratio_len(sfreq, o_sfreq, old_len)\n                for old_len in self._raw_lengths\n            )\n        )\n        ratio, n_news = ratio[0], np.array(n_news, int)\n        new_offsets = np.cumsum([0] + list(n_news))\n        if self.preload:\n            new_data = np.empty((len(self.ch_names), new_offsets[-1]), self._data.dtype)\n        for ri, (n_orig, n_new) in enumerate(zip(self._raw_lengths, n_news)):\n            this_sl = slice(new_offsets[ri], new_offsets[ri + 1])\n            if self.preload:\n                data_chunk = self._data[:, offsets[ri] : offsets[ri + 1]]\n                new_data[:, this_sl] = resample(data_chunk, **kwargs)\n                # In empirical testing, it was faster to resample all channels\n                # (above) and then replace the stim channels than it was to\n                # only resample the proper subset of channels and then use\n                # np.insert() to restore the stims.\n                if len(stim_picks) > 0:\n                    new_data[stim_picks, this_sl] = _resample_stim_channels(\n                        data_chunk[stim_picks], n_new, data_chunk.shape[1]\n                    )\n            else:  # this will not be I/O efficient, but will be mem efficient\n                for ci in range(len(self.ch_names)):\n                    data_chunk = self.get_data(\n                        ci, offsets[ri], offsets[ri + 1], verbose=\"error\"\n                    )[0]\n                    if ci == 0 and ri == 0:\n                        new_data = np.empty(\n                            (len(self.ch_names), new_offsets[-1]), data_chunk.dtype\n                        )\n                    if ci in stim_picks:\n                        resamp = _resample_stim_channels(\n                            data_chunk, n_new, data_chunk.shape[-1]\n                        )[0]\n                    else:\n                        resamp = resample(data_chunk, **kwargs)\n                    new_data[ci, this_sl] = resamp\n\n        self._cropped_samp = int(np.round(self._cropped_samp * ratio))\n        self._first_samps = np.round(self._first_samps * ratio).astype(int)\n        self._last_samps = np.array(self._first_samps) + n_news - 1\n        self._raw_lengths[ri] = list(n_news)\n        assert np.array_equal(n_news, self._last_samps - self._first_samps + 1)\n        self._data = new_data\n        self.preload = True\n        lowpass = self.info.get(\"lowpass\")\n        lowpass = np.inf if lowpass is None else lowpass\n        with self.info._unlock():\n            self.info[\"lowpass\"] = min(lowpass, sfreq / 2.0)\n            self.info[\"sfreq\"] = sfreq\n\n        # See the comment above why we ignore all errors here.\n        if events is None:\n            try:\n                # Did we loose events?\n                resampled_events = find_events(self)\n                if len(resampled_events) != len(original_events):\n                    warn(\n                        \"Resampling of the stim channels caused event \"\n                        \"information to become unreliable. Consider finding \"\n                        \"events on the original data and passing the event \"\n                        \"matrix as a parameter.\"\n                    )\n            except Exception:\n                pass\n\n            return self\n        else:\n            # always make a copy of events\n            events = events.copy()\n\n            events[:, 0] = np.minimum(\n                np.round(events[:, 0] * ratio).astype(int),\n                self._data.shape[1] + self.first_samp - 1,\n            )\n            return self, events", "metadata": {}}
{"_id": "mne_mne_io/base.py_rescale_code", "title": "rescale", "text": "def rescale(self, scalings, *, verbose=None):\n        \"\"\"Rescale channels.\n\n        .. warning::\n            MNE-Python assumes data are stored in SI base units. This function should\n            typically only be used to fix an incorrect scaling factor in the data to get\n            it to be in SI base units, otherwise unintended problems (e.g., incorrect\n            source imaging results) and analysis errors can occur.\n\n        Parameters\n        ----------\n        scalings : int | float | dict\n            The scaling factor(s) by which to multiply the data. If a float, the same\n            scaling factor is applied to all channels (this works only if all channels\n            are of the same type). If a dict, the keys must be valid channel types and\n            the values the scaling factors to apply to the corresponding channels.\n        %(verbose)s\n\n        Returns\n        -------\n        raw : Raw\n            The raw object with rescaled data (modified in-place).\n\n        Examples\n        --------\n        A common use case for EEG data is to convert from \u00b5V to V, since many EEG\n        systems store data in \u00b5V, but MNE-Python expects the data to be in V. Therefore,\n        the data needs to be rescaled by a factor of 1e-6. To rescale all channels from\n        \u00b5V to V, you can do::\n\n            >>> raw.rescale(1e-6)  # doctest: +SKIP\n\n        Note that the previous example only works if all channels are of the same type.\n        If there are multiple channel types, you can pass a dict with the individual\n        scaling factors. For example, to rescale only EEG channels, you can do::\n\n            >>> raw.rescale({\"eeg\": 1e-6})  # doctest: +SKIP\n        \"\"\"\n        _validate_type(scalings, (int, float, dict), \"scalings\")\n        _check_preload(self, \"raw.rescale\")\n\n        channel_types = self.get_channel_types(unique=True)\n\n        if isinstance(scalings, int | float):\n            if len(channel_types) == 1:\n                self.apply_function(lambda x: x * scalings, channel_wise=False)\n            else:\n                raise ValueError(\n                    \"If scalings is a scalar, all channels must be of the same type. \"\n                    \"Consider passing a dict instead.\"\n                )\n        else:\n            for ch_type in scalings.keys():\n                if ch_type not in channel_types:\n                    raise ValueError(\n                        f'Channel type \"{ch_type}\" is not present in the Raw file.'\n                    )\n            for ch_type, ch_scale in scalings.items():\n                self.apply_function(\n                    lambda x: x * ch_scale, picks=ch_type, channel_wise=False\n                )\n\n        return self", "metadata": {}}
{"_id": "mne_mne_io/base.py_crop_code", "title": "crop", "text": "def crop(self, tmin=0.0, tmax=None, include_tmax=True, *, verbose=None):\n        \"\"\"Crop raw data file.\n\n        Limit the data from the raw file to go between specific times. Note\n        that the new ``tmin`` is assumed to be ``t=0`` for all subsequently\n        called functions (e.g., :meth:`~mne.io.Raw.time_as_index`, or\n        :class:`~mne.Epochs`). New :term:`first_samp` and :term:`last_samp`\n        are set accordingly.\n\n        Thus function operates in-place on the instance.\n        Use :meth:`mne.io.Raw.copy` if operation on a copy is desired.\n\n        Parameters\n        ----------\n        %(tmin_raw)s\n        %(tmax_raw)s\n        %(include_tmax)s\n        %(verbose)s\n\n        Returns\n        -------\n        raw : instance of Raw\n            The cropped raw object, modified in-place.\n        \"\"\"\n        max_time = (self.n_times - 1) / self.info[\"sfreq\"]\n        if tmax is None:\n            tmax = max_time\n\n        if tmin > tmax:\n            raise ValueError(f\"tmin ({tmin}) must be less than tmax ({tmax})\")\n        if tmin < 0.0:\n            raise ValueError(f\"tmin ({tmin}) must be >= 0\")\n        elif tmax - int(not include_tmax) / self.info[\"sfreq\"] > max_time:\n            raise ValueError(\n                f\"tmax ({tmax}) must be less than or equal to the max \"\n                f\"time ({max_time:0.4f} s)\"\n            )\n\n        smin, smax = np.where(\n            _time_mask(\n                self.times,\n                tmin,\n                tmax,\n                sfreq=self.info[\"sfreq\"],\n                include_tmax=include_tmax,\n            )\n        )[0][[0, -1]]\n        cumul_lens = np.concatenate(([0], np.array(self._raw_lengths, dtype=\"int\")))\n        cumul_lens = np.cumsum(cumul_lens)\n        keepers = np.logical_and(\n            np.less(smin, cumul_lens[1:]), np.greater_equal(smax, cumul_lens[:-1])\n        )\n        keepers = np.where(keepers)[0]\n        # if we drop file(s) from the beginning, we need to keep track of\n        # how many samples we dropped relative to that one\n        self._cropped_samp += smin\n        self._first_samps = np.atleast_1d(self._first_samps[keepers])\n        # Adjust first_samp of first used file!\n        self._first_samps[0] += smin - cumul_lens[keepers[0]]\n        self._last_samps = np.atleast_1d(self._last_samps[keepers])\n        self._last_samps[-1] -= cumul_lens[keepers[-1] + 1] - 1 - smax\n        self._read_picks = [self._read_picks[ri] for ri in keepers]\n        assert all(len(r) == len(self._read_picks[0]) for r in self._read_picks)\n        self._raw_extras = [self._raw_extras[ri] for ri in keepers]\n        self.filenames = [self.filenames[ri] for ri in keepers]\n        if self.preload:\n            # slice and copy to avoid the reference to large array\n            self._data = self._data[:, smin : smax + 1].copy()\n\n        annotations = self.annotations\n        # now call setter to filter out annotations outside of interval\n        if annotations.orig_time is None:\n            assert self.info[\"meas_date\"] is None\n            # When self.info['meas_date'] is None (which is guaranteed if\n            # self.annotations.orig_time is None), when we do the\n            # self.set_annotations, it's assumed that the annotations onset\n            # are relative to first_time, so we have to subtract it, then\n            # set_annotations will put it back.\n            annotations.onset -= self.first_time\n        self.set_annotations(annotations, False)\n\n        return self", "metadata": {}}
{"_id": "mne_mne_io/base.py_crop_by_annotations_code", "title": "crop_by_annotations", "text": "def crop_by_annotations(self, annotations=None, *, verbose=None):\n        \"\"\"Get crops of raw data file for selected annotations.\n\n        Parameters\n        ----------\n        annotations : instance of Annotations | None\n            The annotations to use for cropping the raw file. If None,\n            the annotations from the instance are used.\n        %(verbose)s\n\n        Returns\n        -------\n        raws : list\n            The cropped raw objects.\n        \"\"\"\n        if annotations is None:\n            annotations = self.annotations\n\n        raws = []\n        for annot in annotations:\n            onset = annot[\"onset\"] - self.first_time\n            # be careful about near-zero errors (crop is very picky about this,\n            # e.g., -1e-8 is an error)\n            if -self.info[\"sfreq\"] / 2 < onset < 0:\n                onset = 0\n            raw_crop = self.copy().crop(onset, onset + annot[\"duration\"])\n            raws.append(raw_crop)\n\n        return raws", "metadata": {}}
{"_id": "mne_mne_io/base.py_save_code", "title": "save", "text": "def save(\n        self,\n        fname,\n        picks=None,\n        tmin=0,\n        tmax=None,\n        buffer_size_sec=None,\n        drop_small_buffer=False,\n        proj=False,\n        fmt=\"single\",\n        overwrite=False,\n        split_size=\"2GB\",\n        split_naming=\"neuromag\",\n        verbose=None,\n    ):\n        \"\"\"Save raw data to file.\n\n        Parameters\n        ----------\n        fname : path-like\n            File name of the new dataset. This has to be a new filename\n            unless data have been preloaded. Filenames should end with\n            ``raw.fif`` (common raw data), ``raw_sss.fif``\n            (Maxwell-filtered continuous data),\n            ``raw_tsss.fif`` (temporally signal-space-separated data),\n            ``_meg.fif`` (common MEG data), ``_eeg.fif`` (common EEG data),\n            or ``_ieeg.fif`` (common intracranial EEG data). You may also\n            append an additional ``.gz`` suffix to enable gzip compression.\n        %(picks_all)s\n        %(tmin_raw)s\n        %(tmax_raw)s\n        buffer_size_sec : float | None\n            Size of data chunks in seconds. If None (default), the buffer\n            size of the original file is used.\n        drop_small_buffer : bool\n            Drop or not the last buffer. It is required by maxfilter (SSS)\n            that only accepts raw files with buffers of the same size.\n        proj : bool\n            If True the data is saved with the projections applied (active).\n\n            .. note:: If ``apply_proj()`` was used to apply the projections,\n                      the projectons will be active even if ``proj`` is False.\n        fmt : 'single' | 'double' | 'int' | 'short'\n            Format to use to save raw data. Valid options are 'double',\n            'single', 'int', and 'short' for 64- or 32-bit float, or 32- or\n            16-bit integers, respectively. It is **strongly** recommended to\n            use 'single', as this is backward-compatible, and is standard for\n            maintaining precision. Note that using 'short' or 'int' may result\n            in loss of precision, complex data cannot be saved as 'short',\n            and neither complex data types nor real data stored as 'double'\n            can be loaded with the MNE command-line tools. See raw.orig_format\n            to determine the format the original data were stored in.\n        %(overwrite)s\n            To overwrite original file (the same one that was loaded),\n            data must be preloaded upon reading.\n        split_size : str | int\n            Large raw files are automatically split into multiple pieces. This\n            parameter specifies the maximum size of each piece. If the\n            parameter is an integer, it specifies the size in Bytes. It is\n            also possible to pass a human-readable string, e.g., 100MB.\n\n            .. note:: Due to FIFF file limitations, the maximum split\n                      size is 2GB.\n        %(split_naming)s\n\n            .. versionadded:: 0.17\n        %(verbose)s\n\n        Returns\n        -------\n        fnames : List of path-like\n            List of path-like objects containing the path to each file split.\n            .. versionadded:: 1.9\n\n        Notes\n        -----\n        If Raw is a concatenation of several raw files, **be warned** that\n        only the measurement information from the first raw file is stored.\n        This likely means that certain operations with external tools may not\n        work properly on a saved concatenated file (e.g., probably some\n        or all forms of SSS). It is recommended not to concatenate and\n        then save raw files for this reason.\n\n        Samples annotated ``BAD_ACQ_SKIP`` are not stored in order to optimize\n        memory. Whatever values, they will be loaded as 0s when reading file.\n        \"\"\"\n        endings = (\n            \"raw.fif\",\n            \"raw_sss.fif\",\n            \"raw_tsss.fif\",\n            \"_meg.fif\",\n            \"_eeg.fif\",\n            \"_ieeg.fif\",\n        )\n        endings += tuple([f\"{e}.gz\" for e in endings])\n        endings_err = (\".fif\", \".fif.gz\")\n\n        # convert to str, check for overwrite a few lines later\n        fname = _check_fname(\n            fname,\n            overwrite=True,\n            verbose=\"error\",\n            check_bids_split=True,\n            name=\"fname\",\n        )\n        check_fname(fname, \"raw\", endings, endings_err=endings_err)\n\n        split_size = _get_split_size(split_size)\n        if not self.preload and fname in self.filenames:\n            extra = \" and overwrite must be True\" if not overwrite else \"\"\n            raise ValueError(\n                \"In order to save data to the same file, data need to be preloaded\"\n                + extra\n            )\n\n        if self.preload:\n            if np.iscomplexobj(self._data):\n                warn(\n                    \"Saving raw file with complex data. Loading with command-line MNE \"\n                    \"tools will not work.\"\n                )\n\n        data_test = self[0, 0][0]\n        if fmt == \"short\" and np.iscomplexobj(data_test):\n            raise ValueError(\n                'Complex data must be saved as \"single\" or \"double\", not \"short\"'\n            )\n\n        # check for file existence and expand `~` if present\n        fname = _check_fname(fname=fname, overwrite=overwrite, verbose=\"error\")\n\n        if proj:\n            info = deepcopy(self.info)\n            projector, info = setup_proj(info)\n            activate_proj(info[\"projs\"], copy=False)\n        else:\n            info = self.info\n            projector = None\n\n        #\n        #   Set up the reading parameters\n        #\n\n        #   Convert to samples\n        start, stop = self._tmin_tmax_to_start_stop(tmin, tmax)\n        buffer_size = self._get_buffer_size(buffer_size_sec)\n\n        # write the raw file\n        _validate_type(split_naming, str, \"split_naming\")\n        _check_option(\"split_naming\", split_naming, (\"neuromag\", \"bids\"))\n\n        cfg = _RawFidWriterCfg(buffer_size, split_size, drop_small_buffer, fmt)\n        raw_fid_writer = _RawFidWriter(self, info, picks, projector, start, stop, cfg)\n        filenames = _write_raw(raw_fid_writer, fname, split_naming, overwrite)\n        return filenames", "metadata": {}}
{"_id": "mne_mne_io/base.py_export_code", "title": "export", "text": "def export(\n        self,\n        fname,\n        fmt=\"auto\",\n        physical_range=\"auto\",\n        add_ch_type=False,\n        *,\n        overwrite=False,\n        verbose=None,\n    ):\n        \"\"\"Export Raw to external formats.\n\n        %(export_fmt_support_raw)s\n\n        %(export_warning)s\n\n        Parameters\n        ----------\n        %(fname_export_params)s\n        %(export_fmt_params_raw)s\n        %(physical_range_export_params)s\n        %(add_ch_type_export_params)s\n        %(overwrite)s\n\n            .. versionadded:: 0.24.1\n        %(verbose)s\n\n        Notes\n        -----\n        .. versionadded:: 0.24\n\n        %(export_warning_note_raw)s\n        %(export_eeglab_note)s\n        %(export_edf_note)s\n        \"\"\"\n        from ..export import export_raw\n\n        export_raw(\n            fname,\n            self,\n            fmt,\n            physical_range=physical_range,\n            add_ch_type=add_ch_type,\n            overwrite=overwrite,\n            verbose=verbose,\n        )", "metadata": {}}
{"_id": "mne_mne_io/base.py_ch_names_code", "title": "ch_names", "text": "def ch_names(self):\n        \"\"\"Channel names.\"\"\"\n        return self.info[\"ch_names\"]", "metadata": {}}
{"_id": "mne_mne_io/base.py_times_code", "title": "times", "text": "def times(self):\n        \"\"\"Time points.\"\"\"\n        out = _arange_div(self.n_times, float(self.info[\"sfreq\"]))\n        out.flags[\"WRITEABLE\"] = False\n        return out", "metadata": {}}
{"_id": "mne_mne_io/base.py_n_times_code", "title": "n_times", "text": "def n_times(self):\n        \"\"\"Number of time points.\"\"\"\n        return self.last_samp - self.first_samp + 1", "metadata": {}}
{"_id": "mne_mne_io/base.py_duration_code", "title": "duration", "text": "def duration(self):\n        \"\"\"Duration of the data in seconds.\n\n        .. versionadded:: 1.9\n        \"\"\"\n        return self.n_times / self.info[\"sfreq\"]", "metadata": {}}
{"_id": "mne_mne_io/base.py_load_bad_channels_code", "title": "load_bad_channels", "text": "def load_bad_channels(self, bad_file=None, force=False, verbose=None):\n        \"\"\"Mark channels as bad from a text file.\n\n        This function operates mostly in the style of the C function\n        ``mne_mark_bad_channels``. Each line in the text file will be\n        interpreted as a name of a bad channel.\n\n        Parameters\n        ----------\n        bad_file : path-like | None\n            File name of the text file containing bad channels.\n            If ``None`` (default), bad channels are cleared, but this\n            is more easily done directly with ``raw.info['bads'] = []``.\n        force : bool\n            Whether or not to force bad channel marking (of those\n            that exist) if channels are not found, instead of\n            raising an error. Defaults to ``False``.\n        %(verbose)s\n        \"\"\"\n        prev_bads = self.info[\"bads\"]\n        new_bads = []\n        if bad_file is not None:\n            # Check to make sure bad channels are there\n            names = frozenset(self.info[\"ch_names\"])\n            with open(bad_file) as fid:\n                bad_names = [line for line in fid.read().splitlines() if line]\n            new_bads = [ci for ci in bad_names if ci in names]\n            count_diff = len(bad_names) - len(new_bads)\n\n            if count_diff > 0:\n                msg = (\n                    f\"{count_diff} bad channel(s) from:\"\n                    f\"\\n{bad_file}\\nnot found in:\\n{self.filenames[0]}\"\n                )\n                if not force:\n                    raise ValueError(msg)\n                else:\n                    warn(msg)\n\n        if prev_bads != new_bads:\n            logger.info(f\"Updating bad channels: {prev_bads} -> {new_bads}\")\n            self.info[\"bads\"] = new_bads\n        else:\n            logger.info(f\"No channels updated. Bads are: {prev_bads}\")", "metadata": {}}
{"_id": "mne_mne_io/base.py_append_code", "title": "append", "text": "def append(self, raws, preload=None):\n        \"\"\"Concatenate raw instances as if they were continuous.\n\n        .. note:: Boundaries of the raw files are annotated bad. If you wish to\n                  use the data as continuous recording, you can remove the\n                  boundary annotations after concatenation (see\n                  :meth:`mne.Annotations.delete`).\n\n        Parameters\n        ----------\n        raws : list, or Raw instance\n            List of Raw instances to concatenate to the current instance\n            (in order), or a single raw instance to concatenate.\n        %(preload_concatenate)s\n        \"\"\"\n        if not isinstance(raws, list):\n            raws = [raws]\n\n        # make sure the raws are compatible\n        all_raws = [self]\n        all_raws += raws\n        _check_raw_compatibility(all_raws)\n\n        # deal with preloading data first (while files are separate)\n        all_preloaded = self.preload and all(r.preload for r in raws)\n        if preload is None:\n            if all_preloaded:\n                preload = True\n            else:\n                preload = False\n\n        if preload is False:\n            if self.preload:\n                self._data = None\n            self.preload = False\n        else:\n            # do the concatenation ourselves since preload might be a string\n            nchan = self.info[\"nchan\"]\n            c_ns = np.cumsum([rr.n_times for rr in ([self] + raws)])\n            nsamp = c_ns[-1]\n\n            if not self.preload:\n                this_data = self._read_segment()\n            else:\n                this_data = self._data\n\n            # allocate the buffer\n            _data = _allocate_data(preload, (nchan, nsamp), this_data.dtype)\n            _data[:, 0 : c_ns[0]] = this_data\n\n            for ri in range(len(raws)):\n                if not raws[ri].preload:\n                    # read the data directly into the buffer\n                    data_buffer = _data[:, c_ns[ri] : c_ns[ri + 1]]\n                    raws[ri]._read_segment(data_buffer=data_buffer)\n                else:\n                    _data[:, c_ns[ri] : c_ns[ri + 1]] = raws[ri]._data\n            self._data = _data\n            self.preload = True\n\n        # now combine information from each raw file to construct new self\n        annotations = self.annotations\n        assert annotations.orig_time == self.info[\"meas_date\"]\n        edge_samps = list()\n        for ri, r in enumerate(raws):\n            edge_samps.append(self.last_samp - self.first_samp + 1)\n            annotations = _combine_annotations(\n                annotations,\n                r.annotations,\n                edge_samps[-1],\n                self.first_samp,\n                r.first_samp,\n                self.info[\"sfreq\"],\n            )\n            self._first_samps = np.r_[self._first_samps, r._first_samps]\n            self._last_samps = np.r_[self._last_samps, r._last_samps]\n            self._read_picks += r._read_picks\n            self._raw_extras += r._raw_extras\n            self._filenames += r._filenames  # use the private attribute to use the list\n        assert annotations.orig_time == self.info[\"meas_date\"]\n        # The above _combine_annotations gets everything synchronized to\n        # first_samp. set_annotations (with no absolute time reference) assumes\n        # that the annotations being set are relative to first_samp, and will\n        # add it back on. So here we have to remove it:\n        if annotations.orig_time is None:\n            annotations.onset -= self.first_samp / self.info[\"sfreq\"]\n        self.set_annotations(annotations)\n        for edge_samp in edge_samps:\n            onset = _sync_onset(self, edge_samp / self.info[\"sfreq\"], True)\n            logger.debug(\n                f\"Marking edge at {edge_samp} samples (maps to {onset:0.3f} sec)\"\n            )\n            self.annotations.append(onset, 0.0, \"BAD boundary\")\n            self.annotations.append(onset, 0.0, \"EDGE boundary\")\n        if not (\n            len(self._first_samps)\n            == len(self._last_samps)\n            == len(self._raw_extras)\n            == len(self.filenames)\n            == len(self._read_picks)\n        ):\n            raise RuntimeError(\"Append error\")", "metadata": {}}
{"_id": "mne_mne_io/base.py_close_code", "title": "close", "text": "def close(self):\n        \"\"\"Clean up the object.\n\n        Does nothing for objects that close their file descriptors.\n        Things like Raw will override this method.\n        \"\"\"\n        pass", "metadata": {}}
{"_id": "mne_mne_io/base.py_copy_code", "title": "copy", "text": "def copy(self):\n        \"\"\"Return copy of Raw instance.\n\n        Returns\n        -------\n        inst : instance of Raw\n            A copy of the instance.\n        \"\"\"\n        return deepcopy(self)", "metadata": {}}
{"_id": "mne_mne_io/base.py_add_events_code", "title": "add_events", "text": "def add_events(self, events, stim_channel=None, replace=False):\n        \"\"\"Add events to stim channel.\n\n        Parameters\n        ----------\n        events : ndarray, shape (n_events, 3)\n            Events to add. The first column specifies the sample number of\n            each event, the second column is ignored, and the third column\n            provides the event value. If events already exist in the Raw\n            instance at the given sample numbers, the event values will be\n            added together.\n        stim_channel : str | None\n            Name of the stim channel to add to. If None, the config variable\n            'MNE_STIM_CHANNEL' is used. If this is not found, it will default\n            to ``'STI 014'``.\n        replace : bool\n            If True the old events on the stim channel are removed before\n            adding the new ones.\n\n        Notes\n        -----\n        Data must be preloaded in order to add events.\n        \"\"\"\n        _check_preload(self, \"Adding events\")\n        events = np.asarray(events)\n        if events.ndim != 2 or events.shape[1] != 3:\n            raise ValueError(\"events must be shape (n_events, 3)\")\n        stim_channel = _get_stim_channel(stim_channel, self.info)\n        pick = pick_channels(self.ch_names, stim_channel, ordered=False)\n        if len(pick) == 0:\n            raise ValueError(f\"Channel {stim_channel} not found\")\n        pick = pick[0]\n        idx = events[:, 0].astype(int)\n        if np.any(idx < self.first_samp) or np.any(idx > self.last_samp):\n            raise ValueError(\n                f\"event sample numbers must be between {self.first_samp} \"\n                f\"and {self.last_samp}\"\n            )\n        if not all(idx == events[:, 0]):\n            raise ValueError(\"event sample numbers must be integers\")\n        if replace:\n            self._data[pick, :] = 0.0\n        self._data[pick, idx - self.first_samp] += events[:, 2]", "metadata": {}}
{"_id": "mne_mne_io/base.py_compute_psd_code", "title": "compute_psd", "text": "def compute_psd(\n        self,\n        method=\"welch\",\n        fmin=0,\n        fmax=np.inf,\n        tmin=None,\n        tmax=None,\n        picks=None,\n        exclude=(),\n        proj=False,\n        remove_dc=True,\n        reject_by_annotation=True,\n        *,\n        n_jobs=1,\n        verbose=None,\n        **method_kw,\n    ):\n        \"\"\"Perform spectral analysis on sensor data.\n\n        Parameters\n        ----------\n        %(method_psd)s\n            Note that ``\"multitaper\"`` cannot be used if ``reject_by_annotation=True``\n            and there are ``\"bad_*\"`` annotations in the :class:`~mne.io.Raw` data;\n            in such cases use ``\"welch\"``. Default is ``'welch'``.\n        %(fmin_fmax_psd)s\n        %(tmin_tmax_psd)s\n        %(picks_good_data_noref)s\n        %(exclude_psd)s\n        %(proj_psd)s\n        %(remove_dc)s\n        %(reject_by_annotation_psd)s\n        %(n_jobs)s\n        %(verbose)s\n        %(method_kw_psd)s\n\n        Returns\n        -------\n        spectrum : instance of Spectrum\n            The spectral representation of the data.\n\n        Notes\n        -----\n        .. versionadded:: 1.2\n\n        References\n        ----------\n        .. footbibliography::\n        \"\"\"\n        method = _validate_method(method, type(self).__name__)\n        self._set_legacy_nfft_default(tmin, tmax, method, method_kw)\n\n        return Spectrum(\n            self,\n            method=method,\n            fmin=fmin,\n            fmax=fmax,\n            tmin=tmin,\n            tmax=tmax,\n            picks=picks,\n            exclude=exclude,\n            proj=proj,\n            remove_dc=remove_dc,\n            reject_by_annotation=reject_by_annotation,\n            n_jobs=n_jobs,\n            verbose=verbose,\n            **method_kw,\n        )", "metadata": {}}
{"_id": "mne_mne_io/base.py_compute_tfr_code", "title": "compute_tfr", "text": "def compute_tfr(\n        self,\n        method,\n        freqs,\n        *,\n        tmin=None,\n        tmax=None,\n        picks=None,\n        proj=False,\n        output=\"power\",\n        reject_by_annotation=True,\n        decim=1,\n        n_jobs=None,\n        verbose=None,\n        **method_kw,\n    ):\n        \"\"\"Compute a time-frequency representation of sensor data.\n\n        Parameters\n        ----------\n        %(method_tfr)s\n        %(freqs_tfr)s\n        %(tmin_tmax_psd)s\n        %(picks_good_data_noref)s\n        %(proj_psd)s\n        %(output_compute_tfr)s\n        %(reject_by_annotation_tfr)s\n        %(decim_tfr)s\n        %(n_jobs)s\n        %(verbose)s\n        %(method_kw_tfr)s\n\n        Returns\n        -------\n        tfr : instance of RawTFR\n            The time-frequency-resolved power estimates of the data.\n\n        Notes\n        -----\n        .. versionadded:: 1.7\n\n        References\n        ----------\n        .. footbibliography::\n        \"\"\"\n        _check_option(\"output\", output, (\"power\", \"phase\", \"complex\"))\n        method_kw[\"output\"] = output\n        return RawTFR(\n            self,\n            method=method,\n            freqs=freqs,\n            tmin=tmin,\n            tmax=tmax,\n            picks=picks,\n            proj=proj,\n            reject_by_annotation=reject_by_annotation,\n            decim=decim,\n            n_jobs=n_jobs,\n            verbose=verbose,\n            **method_kw,\n        )", "metadata": {}}
{"_id": "mne_mne_io/base.py_to_data_frame_code", "title": "to_data_frame", "text": "def to_data_frame(\n        self,\n        picks=None,\n        index=None,\n        scalings=None,\n        copy=True,\n        start=None,\n        stop=None,\n        long_format=False,\n        time_format=None,\n        *,\n        verbose=None,\n    ):\n        \"\"\"Export data in tabular structure as a pandas DataFrame.\n\n        Channels are converted to columns in the DataFrame. By default, an\n        additional column \"time\" is added, unless ``index`` is not ``None``\n        (in which case time values form the DataFrame's index).\n\n        Parameters\n        ----------\n        %(picks_all)s\n        %(index_df_raw)s\n            Defaults to ``None``.\n        %(scalings_df)s\n        %(copy_df)s\n        start : int | None\n            Starting sample index for creating the DataFrame from a temporal\n            span of the Raw object. ``None`` (the default) uses the first\n            sample.\n        stop : int | None\n            Ending sample index for creating the DataFrame from a temporal span\n            of the Raw object. ``None`` (the default) uses the last sample.\n        %(long_format_df_raw)s\n        %(time_format_df_raw)s\n\n            .. versionadded:: 0.20\n        %(verbose)s\n\n        Returns\n        -------\n        %(df_return)s\n        \"\"\"\n        # check pandas once here, instead of in each private utils function\n        pd = _check_pandas_installed()  # noqa\n        # arg checking\n        valid_index_args = [\"time\"]\n        valid_time_formats = [\"ms\", \"timedelta\", \"datetime\"]\n        index = _check_pandas_index_arguments(index, valid_index_args)\n        time_format = _check_time_format(\n            time_format, valid_time_formats, self.info[\"meas_date\"]\n        )\n        # get data\n        picks = _picks_to_idx(self.info, picks, \"all\", exclude=())\n        data, times = self[picks, start:stop]\n        data = data.T\n        if copy:\n            data = data.copy()\n        data = _scale_dataframe_data(self, data, picks, scalings)\n        # prepare extra columns / multiindex\n        mindex = list()\n        times = _convert_times(\n            times, time_format, self.info[\"meas_date\"], self.first_time\n        )\n        mindex.append((\"time\", times))\n        # build DataFrame\n        df = _build_data_frame(\n            self, data, picks, long_format, mindex, index, default_index=[\"time\"]\n        )\n        return df", "metadata": {}}
{"_id": "mne_mne_io/base.py_describe_code", "title": "describe", "text": "def describe(self, data_frame=False):\n        \"\"\"Describe channels (name, type, descriptive statistics).\n\n        Parameters\n        ----------\n        data_frame : bool\n            If True, return results in a pandas.DataFrame. If False, only print\n            results. Columns 'ch', 'type', and 'unit' indicate channel index,\n            channel type, and unit of the remaining five columns. These columns\n            are 'min' (minimum), 'Q1' (first quartile or 25% percentile),\n            'median', 'Q3' (third quartile or 75% percentile), and 'max'\n            (maximum).\n\n        Returns\n        -------\n        result : None | pandas.DataFrame\n            If data_frame=False, returns None. If data_frame=True, returns\n            results in a pandas.DataFrame (requires pandas).\n        \"\"\"\n        nchan = self.info[\"nchan\"]\n\n        # describe each channel\n        cols = defaultdict(list)\n        cols[\"name\"] = self.ch_names\n        for i in range(nchan):\n            ch = self.info[\"chs\"][i]\n            data = self[i][0]\n            cols[\"type\"].append(channel_type(self.info, i))\n            cols[\"unit\"].append(_unit2human[ch[\"unit\"]])\n            cols[\"min\"].append(np.min(data))\n            cols[\"Q1\"].append(np.percentile(data, 25))\n            cols[\"median\"].append(np.median(data))\n            cols[\"Q3\"].append(np.percentile(data, 75))\n            cols[\"max\"].append(np.max(data))\n\n        if data_frame:  # return data frame\n            import pandas as pd\n\n            df = pd.DataFrame(cols)\n            df.index.name = \"ch\"\n            return df\n\n        # convert into commonly used units\n        scalings = _handle_default(\"scalings\")\n        units = _handle_default(\"units\")\n        for i in range(nchan):\n            unit = units.get(cols[\"type\"][i])\n            scaling = scalings.get(cols[\"type\"][i], 1)\n            if scaling != 1:\n                cols[\"unit\"][i] = unit\n                for col in [\"min\", \"Q1\", \"median\", \"Q3\", \"max\"]:\n                    cols[col][i] *= scaling\n\n        lens = {\n            \"ch\": max(2, len(str(nchan))),\n            \"name\": max(4, max([len(n) for n in cols[\"name\"]])),\n            \"type\": max(4, max([len(t) for t in cols[\"type\"]])),\n            \"unit\": max(4, max([len(u) for u in cols[\"unit\"]])),\n        }\n\n        # print description, start with header\n        print(self)\n        print(\n            f\"{'ch':>{lens['ch']}}  \"\n            f\"{'name':<{lens['name']}}  \"\n            f\"{'type':<{lens['type']}}  \"\n            f\"{'unit':<{lens['unit']}}  \"\n            f\"{'min':>9}  \"\n            f\"{'Q1':>9}  \"\n            f\"{'median':>9}  \"\n            f\"{'Q3':>9}  \"\n            f\"{'max':>9}\"\n        )\n        # print description for each channel\n        for i in range(nchan):\n            msg = (\n                f\"{i:>{lens['ch']}}  \"\n                f\"{cols['name'][i]:<{lens['name']}}  \"\n                f\"{cols['type'][i].upper():<{lens['type']}}  \"\n                f\"{cols['unit'][i]:<{lens['unit']}}  \"\n            )\n            for col in [\"min\", \"Q1\", \"median\", \"Q3\"]:\n                msg += f\"{cols[col][i]:>9.2f}  \"\n            msg += f\"{cols['max'][i]:>9.2f}\"\n            print(msg)", "metadata": {}}
{"_id": "mne_mne_io/snirf/_snirf.py_read_raw_snirf_code", "title": "read_raw_snirf", "text": "def read_raw_snirf(\n    fname, optode_frame=\"unknown\", *, sfreq=None, preload=False, verbose=None\n) -> \"RawSNIRF\":\n    \"\"\"Reader for a continuous wave SNIRF data.\n\n    .. note:: This reader supports the .snirf file type only,\n              not the .jnirs version.\n              Files with either 3D or 2D locations can be read.\n              However, we strongly recommend using 3D positions.\n              If 2D positions are used the behaviour of MNE functions\n              can not be guaranteed.\n\n    Parameters\n    ----------\n    fname : path-like\n        Path to the SNIRF data file.\n    optode_frame : str\n        Coordinate frame used for the optode positions. The default is unknown,\n        in which case the positions are not modified. If a known coordinate\n        frame is provided (head, meg, mri), then the positions are transformed\n        in to the Neuromag head coordinate frame (head).\n    sfreq : float | None\n        The nominal sampling frequency at which the data were acquired. If ``None``,\n        will be estimated from the time data in the file.\n\n        .. versionadded:: 1.10\n    %(preload)s\n    %(verbose)s\n\n    Returns\n    -------\n    raw : instance of RawSNIRF\n        A Raw object containing fNIRS data.\n        See :class:`mne.io.Raw` for documentation of attributes and methods.\n\n    See Also\n    --------\n    mne.io.Raw : Documentation of attributes and methods of RawSNIRF.\n    \"\"\"\n    return RawSNIRF(fname, optode_frame, sfreq=sfreq, preload=preload, verbose=verbose)", "metadata": {}}
{"_id": "mne_mne_io/nirx/nirx.py_read_raw_nirx_code", "title": "read_raw_nirx", "text": "def read_raw_nirx(\n    fname, saturated=\"annotate\", *, preload=False, encoding=\"latin-1\", verbose=None\n) -> \"RawNIRX\":\n    \"\"\"Reader for a NIRX fNIRS recording.\n\n    Parameters\n    ----------\n    fname : path-like\n        Path to the NIRX data folder or header file.\n    %(saturated)s\n    %(preload)s\n    %(encoding_nirx)s\n    %(verbose)s\n\n    Returns\n    -------\n    raw : instance of RawNIRX\n        A Raw object containing NIRX data.\n        See :class:`mne.io.Raw` for documentation of attributes and methods.\n\n    See Also\n    --------\n    mne.io.Raw : Documentation of attributes and methods of RawNIRX.\n\n    Notes\n    -----\n    %(nirx_notes)s\n    \"\"\"\n    return RawNIRX(\n        fname, saturated, preload=preload, encoding=encoding, verbose=verbose\n    )", "metadata": {}}
{"_id": "mne_mne_io/bti/read.py_read_char_code", "title": "read_char", "text": "def read_char(fid, count=1):\n    \"\"\"Read character from bti file.\"\"\"\n    return _unpack_simple(fid, f\">S{count}\", \"S\")", "metadata": {}}
{"_id": "mne_mne_io/bti/read.py_read_uint16_code", "title": "read_uint16", "text": "def read_uint16(fid):\n    \"\"\"Read unsigned 16bit integer from bti file.\"\"\"\n    return _unpack_simple(fid, \">u2\", np.uint32)", "metadata": {}}
{"_id": "mne_mne_io/bti/read.py_read_int16_code", "title": "read_int16", "text": "def read_int16(fid):\n    \"\"\"Read 16bit integer from bti file.\"\"\"\n    return _unpack_simple(fid, \">i2\", np.int32)", "metadata": {}}
{"_id": "mne_mne_io/bti/read.py_read_uint32_code", "title": "read_uint32", "text": "def read_uint32(fid):\n    \"\"\"Read unsigned 32bit integer from bti file.\"\"\"\n    return _unpack_simple(fid, \">u4\", np.uint32)", "metadata": {}}
{"_id": "mne_mne_io/bti/read.py_read_int32_code", "title": "read_int32", "text": "def read_int32(fid):\n    \"\"\"Read 32bit integer from bti file.\"\"\"\n    return _unpack_simple(fid, \">i4\", np.int32)", "metadata": {}}
{"_id": "mne_mne_io/bti/read.py_read_int64_code", "title": "read_int64", "text": "def read_int64(fid):\n    \"\"\"Read 64bit integer from bti file.\"\"\"\n    return _unpack_simple(fid, \">u8\", np.int64)", "metadata": {}}
{"_id": "mne_mne_io/bti/read.py_read_float_code", "title": "read_float", "text": "def read_float(fid):\n    \"\"\"Read 32bit float from bti file.\"\"\"\n    return _unpack_simple(fid, \">f4\", np.float32)", "metadata": {}}
{"_id": "mne_mne_io/bti/read.py_read_double_code", "title": "read_double", "text": "def read_double(fid):\n    \"\"\"Read 64bit float from bti file.\"\"\"\n    return _unpack_simple(fid, \">f8\", np.float64)", "metadata": {}}
{"_id": "mne_mne_io/bti/read.py_read_int16_matrix_code", "title": "read_int16_matrix", "text": "def read_int16_matrix(fid, rows, cols):\n    \"\"\"Read 16bit integer matrix from bti file.\"\"\"\n    return _unpack_matrix(\n        fid,\n        rows,\n        cols,\n        dtype=\">i2\",\n        out_dtype=np.int32,\n    )", "metadata": {}}
{"_id": "mne_mne_io/bti/read.py_read_float_matrix_code", "title": "read_float_matrix", "text": "def read_float_matrix(fid, rows, cols):\n    \"\"\"Read 32bit float matrix from bti file.\"\"\"\n    return _unpack_matrix(fid, rows, cols, dtype=\">f4\", out_dtype=np.float32)", "metadata": {}}
{"_id": "mne_mne_io/bti/read.py_read_double_matrix_code", "title": "read_double_matrix", "text": "def read_double_matrix(fid, rows, cols):\n    \"\"\"Read 64bit float matrix from bti file.\"\"\"\n    return _unpack_matrix(fid, rows, cols, dtype=\">f8\", out_dtype=np.float64)", "metadata": {}}
{"_id": "mne_mne_io/bti/read.py_read_transform_code", "title": "read_transform", "text": "def read_transform(fid):\n    \"\"\"Read 64bit float matrix transform from bti file.\"\"\"\n    return read_double_matrix(fid, rows=4, cols=4)", "metadata": {}}
{"_id": "mne_mne_io/bti/read.py_read_dev_header_code", "title": "read_dev_header", "text": "def read_dev_header(x):\n    \"\"\"Create a dev header.\"\"\"\n    return dict(size=read_int32(x), checksum=read_int32(x), reserved=read_str(x, 32))", "metadata": {}}
{"_id": "mne_mne_io/bti/bti.py_read_raw_bti_code", "title": "read_raw_bti", "text": "def read_raw_bti(\n    pdf_fname,\n    config_fname=\"config\",\n    head_shape_fname=\"hs_file\",\n    rotation_x=0.0,\n    translation=(0.0, 0.02, 0.11),\n    convert=True,\n    rename_channels=True,\n    sort_by_ch_name=True,\n    ecg_ch=\"E31\",\n    eog_ch=(\"E63\", \"E64\"),\n    preload=False,\n    verbose=None,\n) -> RawBTi:\n    \"\"\"Raw object from 4D Neuroimaging MagnesWH3600 data.\n\n    .. note::\n        1. Currently direct inclusion of reference channel weights\n           is not supported. Please use ``mne_create_comp_data`` to include\n           the weights or use the low level functions from this module to\n           include them by yourself.\n        2. The informed guess for the 4D name is E31 for the ECG channel and\n           E63, E63 for the EOG channels. Please check and adjust if those\n           channels are present in your dataset but 'ECG 01' and 'EOG 01',\n           'EOG 02' don't appear in the channel names of the raw object.\n\n    Parameters\n    ----------\n    pdf_fname : path-like\n        Path to the processed data file (PDF).\n    config_fname : path-like\n        Path to system config file.\n    head_shape_fname : path-like | None\n        Path to the head shape file.\n    rotation_x : float\n        Degrees to tilt x-axis for sensor frame misalignment. Ignored\n        if convert is True.\n    translation : array-like, shape (3,)\n        The translation to place the origin of coordinate system\n        to the center of the head. Ignored if convert is True.\n    convert : bool\n        Convert to Neuromag coordinates or not.\n    rename_channels : bool\n        Whether to keep original 4D channel labels or not. Defaults to True.\n    sort_by_ch_name : bool\n        Reorder channels according to channel label. 4D channels don't have\n        monotonically increasing numbers in their labels. Defaults to True.\n    ecg_ch : str | None\n        The 4D name of the ECG channel. If None, the channel will be treated\n        as regular EEG channel.\n    eog_ch : tuple of str | None\n        The 4D names of the EOG channels. If None, the channels will be treated\n        as regular EEG channels.\n    %(preload)s\n\n        .. versionadded:: 0.11\n    %(verbose)s\n\n    Returns\n    -------\n    raw : instance of RawBTi\n        A Raw object containing BTI data.\n        See :class:`mne.io.Raw` for documentation of attributes and methods.\n\n    See Also\n    --------\n    mne.io.Raw : Documentation of attributes and methods of RawBTi.\n    \"\"\"\n    return RawBTi(\n        pdf_fname,\n        config_fname=config_fname,\n        head_shape_fname=head_shape_fname,\n        rotation_x=rotation_x,\n        translation=translation,\n        convert=convert,\n        rename_channels=rename_channels,\n        sort_by_ch_name=sort_by_ch_name,\n        ecg_ch=ecg_ch,\n        eog_ch=eog_ch,\n        preload=preload,\n        verbose=verbose,\n    )", "metadata": {}}
{"_id": "mne_mne_io/neuralynx/neuralynx.py_read_raw_neuralynx_code", "title": "read_raw_neuralynx", "text": "def read_raw_neuralynx(\n    fname, *, preload=False, exclude_fname_patterns=None, verbose=None\n) -> \"RawNeuralynx\":\n    \"\"\"Reader for Neuralynx files.\n\n    Parameters\n    ----------\n    fname : path-like\n        Path to a folder with Neuralynx .ncs files.\n    %(preload)s\n    exclude_fname_patterns : list of str\n        List of glob-like string patterns to exclude from channel list.\n        Useful when not all channels have the same number of samples\n        so you can read separate instances.\n    %(verbose)s\n\n    Returns\n    -------\n    raw : instance of RawNeuralynx\n        A Raw object containing Neuralynx data.\n        See :class:`mne.io.Raw` for documentation of attributes and methods.\n\n    See Also\n    --------\n    mne.io.Raw : Documentation of attributes and methods of RawNeuralynx.\n\n    Notes\n    -----\n    Neuralynx files are read from disk using the `Neo package\n    <http://neuralensemble.org/neo/>`__.\n    Currently, only reading of the ``.ncs files`` is supported.\n\n    ``raw.info[\"meas_date\"]`` is read from the ``recording_opened`` property\n    of the first ``.ncs`` file (i.e. channel) in the dataset (a warning is issued\n    if files have different dates of acquisition).\n\n    Channel-specific high and lowpass frequencies of online filters are determined\n    based on the ``DspLowCutFrequency`` and ``DspHighCutFrequency`` header fields,\n    respectively. If no filters were used for a channel, the default lowpass is set\n    to the Nyquist frequency and the default highpass is set to 0.\n    If channels have different high/low cutoffs, ``raw.info[\"highpass\"]`` and\n    ``raw.info[\"lowpass\"]`` are then set to the maximum highpass and minimumlowpass\n    values across channels, respectively.\n\n    Other header variables can be inspected using Neo directly. For example::\n\n        from neo.io import NeuralynxIO  # doctest: +SKIP\n        fname = 'path/to/your/data'  # doctest: +SKIP\n        nlx_reader = NeuralynxIO(dirname=fname)  # doctest: +SKIP\n        print(nlx_reader.header)  # doctest: +SKIP\n        print(nlx_reader.file_headers.items())  # doctest: +SKIP\n    \"\"\"\n    return RawNeuralynx(\n        fname,\n        preload=preload,\n        exclude_fname_patterns=exclude_fname_patterns,\n        verbose=verbose,\n    )", "metadata": {}}
{"_id": "mne_mne_io/hitachi/hitachi.py_read_raw_hitachi_code", "title": "read_raw_hitachi", "text": "def read_raw_hitachi(fname, preload=False, verbose=None) -> \"RawHitachi\":\n    \"\"\"Reader for a Hitachi fNIRS recording.\n\n    Parameters\n    ----------\n    %(hitachi_fname)s\n    %(preload)s\n    %(verbose)s\n\n    Returns\n    -------\n    raw : instance of RawHitachi\n        A Raw object containing Hitachi data.\n        See :class:`mne.io.Raw` for documentation of attributes and methods.\n\n    See Also\n    --------\n    mne.io.Raw : Documentation of attributes and methods of RawHitachi.\n\n    Notes\n    -----\n    %(hitachi_notes)s\n    \"\"\"\n    return RawHitachi(fname, preload, verbose=verbose)", "metadata": {}}
{"_id": "mne_mne_io/brainvision/brainvision.py_read_raw_brainvision_code", "title": "read_raw_brainvision", "text": "def read_raw_brainvision(\n    vhdr_fname,\n    eog=(\"HEOGL\", \"HEOGR\", \"VEOGb\"),\n    misc=\"auto\",\n    scale=1.0,\n    ignore_marker_types=False,\n    preload=False,\n    verbose=None,\n) -> RawBrainVision:\n    \"\"\"Reader for Brain Vision EEG file.\n\n    Parameters\n    ----------\n    vhdr_fname : path-like\n        Path to the EEG header file.\n    eog : list of (int | str) | tuple of (int | str)\n        Names of channels or list of indices that should be designated EOG channels.\n        Values should correspond to the header file Default is ``('HEOGL', 'HEOGR',\n        'VEOGb')``.\n    misc : list of (int | str) | tuple of (int | str) | ``'auto'``\n        Names of channels or list of indices that should be designated MISC channels.\n        Values should correspond to the electrodes in the header file. If ``'auto'``,\n        units in header file are used for inferring misc channels. Default is\n        ``'auto'``.\n    scale : float\n        The scaling factor for EEG data. Unless specified otherwise by header file,\n        units are in microvolts. Default scale factor is 1.\n    ignore_marker_types : bool\n        If ``True``, ignore marker types and only use marker descriptions. Default is\n        ``False``.\n\n        .. versionadded:: 1.8\n    %(preload)s\n    %(verbose)s\n\n    Returns\n    -------\n    raw : instance of RawBrainVision\n        A Raw object containing BrainVision data. See :class:`mne.io.Raw` for\n        documentation of attributes and methods.\n\n    See Also\n    --------\n    mne.io.Raw : Documentation of attributes and methods of RawBrainVision.\n\n    Notes\n    -----\n    If the BrainVision header file contains impedance measurements, these may be\n    accessed using ``raw.impedances`` after reading using this function. However, this\n    attribute will NOT be available after a save and re-load of the data. That is, it is\n    only available when reading data directly from the BrainVision header file.\n\n    BrainVision markers consist of a type and a description (in addition to other fields\n    like onset and duration). In contrast, annotations in MNE only have a description.\n    Therefore, a BrainVision marker of type \"Stimulus\" and description \"S  1\" will be\n    converted to an annotation \"Stimulus/S  1\" by default. If you want to ignore the\n    type and instead only use the description, set ``ignore_marker_types=True``, which\n    will convert the same marker to an annotation \"S  1\".\n\n    The first marker in a BrainVision file is usually a \"New Segment\" marker, which\n    contains the recording time. This time is stored in the ``info['meas_date']``\n    attribute of the returned object and is not converted to an annotation.\n    \"\"\"\n    return RawBrainVision(\n        vhdr_fname=vhdr_fname,\n        eog=eog,\n        misc=misc,\n        scale=scale,\n        ignore_marker_types=ignore_marker_types,\n        preload=preload,\n        verbose=verbose,\n    )", "metadata": {}}
{"_id": "mne_mne_io/fil/fil.py_read_raw_fil_code", "title": "read_raw_fil", "text": "def read_raw_fil(\n    binfile, precision=\"single\", preload=False, *, verbose=None\n) -> \"RawFIL\":\n    \"\"\"Raw object from FIL-OPMEG formatted data.\n\n    Parameters\n    ----------\n    binfile : path-like\n        Path to the MEG data binary (ending in ``'_meg.bin'``).\n    precision : str, optional\n        How is the data represented? ``'single'`` if 32-bit or ``'double'`` if\n        64-bit (default is single).\n    %(preload)s\n    %(verbose)s\n\n    Returns\n    -------\n    raw : instance of RawFIL\n        The raw data.\n        See :class:`mne.io.Raw` for documentation of attributes and methods.\n\n    See Also\n    --------\n    mne.io.Raw : Documentation of attributes and methods of RawFIL.\n    \"\"\"\n    return RawFIL(binfile, precision=precision, preload=preload)", "metadata": {}}
{"_id": "mne_mne_io/eximia/eximia.py_read_raw_eximia_code", "title": "read_raw_eximia", "text": "def read_raw_eximia(fname, preload=False, verbose=None) -> \"RawEximia\":\n    \"\"\"Reader for an eXimia EEG file.\n\n    Parameters\n    ----------\n    fname : path-like\n        Path to the eXimia ``.nxe`` data file.\n    %(preload)s\n    %(verbose)s\n\n    Returns\n    -------\n    raw : instance of RawEximia\n        A Raw object containing eXimia data.\n        See :class:`mne.io.Raw` for documentation of attributes and methods.\n\n    See Also\n    --------\n    mne.io.Raw : Documentation of attributes and methods of RawEximia.\n    \"\"\"\n    return RawEximia(fname, preload, verbose)", "metadata": {}}
{"_id": "mne_mne_io/nsx/nsx.py_read_raw_nsx_code", "title": "read_raw_nsx", "text": "def read_raw_nsx(\n    input_fname, stim_channel=True, eog=None, misc=None, preload=False, *, verbose=None\n) -> \"RawNSX\":\n    \"\"\"Reader function for NSx (Blackrock Microsystems) files.\n\n    Parameters\n    ----------\n    input_fname : str\n        Path to the NSx file.\n    stim_channel : ``'auto'`` | str | list of str | int | list of int\n        Defaults to ``'auto'``, which means that channels named ``'status'`` or\n        ``'trigger'`` (case insensitive) are set to STIM. If str (or list of\n        str), all channels matching the name(s) are set to STIM. If int (or\n        list of ints), channels corresponding to the indices are set to STIM.\n    eog : list or tuple\n        Names of channels or list of indices that should be designated EOG\n        channels. Values should correspond to the electrodes in the file.\n        Default is None.\n    misc : list or tuple\n        Names of channels or list of indices that should be designated MISC\n        channels. Values should correspond to the electrodes in the file.\n        Default is None.\n    %(preload)s\n    %(verbose)s\n\n    Returns\n    -------\n    raw : instance of RawEDF\n        The raw instance.\n        See :class:`mne.io.Raw` for documentation of attributes and methods.\n\n    Notes\n    -----\n    NSx files with id (= NEURALSG), i.e., version 2.1 is currently not\n    supported.\n\n    If channels named 'status' or 'trigger' are present, they are considered as\n    STIM channels by default. Use func:`mne.find_events` to parse events\n    encoded in such analog stim channels.\n    \"\"\"\n    input_fname = _check_fname(\n        input_fname, overwrite=\"read\", must_exist=True, name=\"input_fname\"\n    )\n    if not input_fname.suffix.lower().startswith(\".ns\"):\n        raise NotImplementedError(\n            f\"Only NSx files are supported, got {input_fname.suffix}.\"\n        )\n    return RawNSX(\n        input_fname, stim_channel, eog, misc, preload=preload, verbose=verbose\n    )", "metadata": {}}
{"_id": "mne_mne_io/ant/ant.py_read_raw_ant_code", "title": "read_raw_ant", "text": "def read_raw_ant(\n    fname,\n    eog=None,\n    misc=r\"BIP\\d+\",\n    bipolars=None,\n    impedance_annotation=\"impedance\",\n    *,\n    encoding: str = \"latin-1\",\n    preload=False,\n    verbose=None,\n) -> RawANT:\n    \"\"\"\n    Returns\n    -------\n    raw : instance of RawANT\n        A Raw object containing ANT data.\n        See :class:`mne.io.Raw` for documentation of attributes and methods.\n\n    Notes\n    -----\n    .. versionadded:: 1.9\n    \"\"\"\n    return RawANT(\n        fname,\n        eog=eog,\n        misc=misc,\n        bipolars=bipolars,\n        impedance_annotation=impedance_annotation,\n        encoding=encoding,\n        preload=preload,\n        verbose=verbose,\n    )", "metadata": {}}
{"_id": "mne_mne_io/fiff/raw.py_read_raw_fif_code", "title": "read_raw_fif", "text": "def read_raw_fif(\n    fname, allow_maxshield=False, preload=False, on_split_missing=\"raise\", verbose=None\n) -> Raw:\n    \"\"\"Reader function for Raw FIF data.\n\n    Parameters\n    ----------\n    fname : path-like | file-like\n        The raw filename to load. For files that have automatically been split,\n        the split part will be automatically loaded. Filenames should end\n        with raw.fif, raw.fif.gz, raw_sss.fif, raw_sss.fif.gz, raw_tsss.fif,\n        raw_tsss.fif.gz, or _meg.fif. If a file-like object is provided,\n        preloading must be used.\n\n        .. versionchanged:: 0.18\n           Support for file-like objects.\n    allow_maxshield : bool | str (default False)\n        If True, allow loading of data that has been recorded with internal\n        active compensation (MaxShield). Data recorded with MaxShield should\n        generally not be loaded directly, but should first be processed using\n        SSS/tSSS to remove the compensation signals that may also affect brain\n        activity. Can also be \"yes\" to load without eliciting a warning.\n    %(preload)s\n    %(on_split_missing)s\n    %(verbose)s\n\n    Returns\n    -------\n    raw : instance of Raw\n        A Raw object containing FIF data.\n\n    Notes\n    -----\n    .. versionadded:: 0.9.0\n\n    When reading a FIF file, note that the first N seconds annotated\n    ``BAD_ACQ_SKIP`` are **skipped**. They are removed from ``raw.times`` and\n    ``raw.n_times`` parameters but ``raw.first_samp`` and ``raw.first_time``\n    are updated accordingly.\n    \"\"\"\n    return Raw(\n        fname=fname,\n        allow_maxshield=allow_maxshield,\n        preload=preload,\n        verbose=verbose,\n        on_split_missing=on_split_missing,\n    )", "metadata": {}}
{"_id": "mne_mne_io/fiff/raw.py_fix_mag_coil_types_code", "title": "fix_mag_coil_types", "text": "def fix_mag_coil_types(self):\n        \"\"\"Fix Elekta magnetometer coil types.\n\n        Returns\n        -------\n        raw : instance of Raw\n            The raw object. Operates in place.\n\n        Notes\n        -----\n        This function changes magnetometer coil types 3022 (T1: SQ20483N) and\n        3023 (T2: SQ20483-A) to 3024 (T3: SQ20950N) in the channel definition\n        records in the info structure.\n\n        Neuromag Vectorview systems can contain magnetometers with two\n        different coil sizes (3022 and 3023 vs. 3024). The systems\n        incorporating coils of type 3024 were introduced last and are used at\n        the majority of MEG sites. At some sites with 3024 magnetometers,\n        the data files have still defined the magnetometers to be of type\n        3022 to ensure compatibility with older versions of Neuromag software.\n        In the MNE software as well as in the present version of Neuromag\n        software coil type 3024 is fully supported. Therefore, it is now safe\n        to upgrade the data files to use the true coil type.\n\n        .. note:: The effect of the difference between the coil sizes on the\n                  current estimates computed by the MNE software is very small.\n                  Therefore the use of mne_fix_mag_coil_types is not mandatory.\n        \"\"\"\n        fix_mag_coil_types(self.info)\n        return self", "metadata": {}}
{"_id": "mne_mne_io/fiff/raw.py_acqparser_code", "title": "acqparser", "text": "def acqparser(self):\n        \"\"\"The AcqParserFIF for the measurement info.\n\n        See Also\n        --------\n        mne.AcqParserFIF\n        \"\"\"\n        if getattr(self, \"_acqparser\", None) is None:\n            self._acqparser = AcqParserFIF(self.info)\n        return self._acqparser", "metadata": {}}
{"_id": "mne_mne_io/eyelink/eyelink.py_read_raw_eyelink_code", "title": "read_raw_eyelink", "text": "def read_raw_eyelink(\n    fname,\n    *,\n    create_annotations=True,\n    apply_offsets=False,\n    find_overlaps=False,\n    overlap_threshold=0.05,\n    verbose=None,\n) -> \"RawEyelink\":\n    \"\"\"Reader for an Eyelink ``.asc`` file.\n\n    Parameters\n    ----------\n    %(eyelink_fname)s\n    %(eyelink_create_annotations)s\n    %(eyelink_apply_offsets)s\n    %(eyelink_find_overlaps)s\n    %(eyelink_overlap_threshold)s\n    %(verbose)s\n\n    Returns\n    -------\n    raw : instance of RawEyelink\n        A Raw object containing eyetracker data.\n\n    See Also\n    --------\n    mne.io.Raw : Documentation of attribute and methods.\n\n    Notes\n    -----\n    It is common for SR Research Eyelink eye trackers to only record data during trials.\n    To avoid frequent data discontinuities and to ensure that the data is continuous\n    so that it can be aligned with EEG and MEG data (if applicable), this reader will\n    preserve the times between recording trials and annotate them with\n    ``'BAD_ACQ_SKIP'``.\n    \"\"\"\n    fname = _check_fname(fname, overwrite=\"read\", must_exist=True, name=\"fname\")\n\n    raw_eyelink = RawEyelink(\n        fname,\n        create_annotations=create_annotations,\n        apply_offsets=apply_offsets,\n        find_overlaps=find_overlaps,\n        overlap_threshold=overlap_threshold,\n        verbose=verbose,\n    )\n    return raw_eyelink", "metadata": {}}
{"_id": "mne_mne_io/artemis123/artemis123.py_read_raw_artemis123_code", "title": "read_raw_artemis123", "text": "def read_raw_artemis123(\n    input_fname, preload=False, verbose=None, pos_fname=None, add_head_trans=True\n) -> \"RawArtemis123\":\n    \"\"\"Read Artemis123 data as raw object.\n\n    Parameters\n    ----------\n    input_fname : path-like\n        Path to the data file (extension ``.bin``). The header file with the\n        same file name stem and an extension ``.txt`` is expected to be found\n        in the same directory.\n    %(preload)s\n    %(verbose)s\n    pos_fname : path-like | None\n        If not None, load digitized head points from this file.\n    add_head_trans : bool (default True)\n        If True attempt to perform initial head localization. Compute initial\n        device to head coordinate transform using HPI coils. If no\n        HPI coils are in info['dig'] hpi coils are assumed to be in canonical\n        order of fiducial points (nas, rpa, lpa).\n\n    Returns\n    -------\n    raw : instance of Raw\n        A Raw object containing the data.\n\n    See Also\n    --------\n    mne.io.Raw : Documentation of attributes and methods.\n    \"\"\"\n    return RawArtemis123(\n        input_fname,\n        preload=preload,\n        verbose=verbose,\n        pos_fname=pos_fname,\n        add_head_trans=add_head_trans,\n    )", "metadata": {}}
{"_id": "mne_mne_io/kit/kit.py_get_kit_info_code", "title": "get_kit_info", "text": "def get_kit_info(rawfile, allow_unknown_format, standardize_names=None, verbose=None):\n    \"\"\"Extract all the information from the sqd/con file.\n\n    Parameters\n    ----------\n    rawfile : path-like\n        KIT file to be read.\n    allow_unknown_format : bool\n        Force reading old data that is not officially supported. Alternatively,\n        read and re-save the data with the KIT MEG Laboratory application.\n    %(standardize_names)s\n    %(verbose)s\n\n    Returns\n    -------\n    %(info_not_none)s\n    sqd : dict\n        A dict containing all the sqd parameter settings.\n    \"\"\"\n    sqd = dict()\n    sqd[\"rawfile\"] = rawfile\n    unsupported_format = False\n    with open(rawfile, \"rb\", buffering=0) as fid:  # buffering=0 for np bug\n        #\n        # directories (0)\n        #\n        sqd[\"dirs\"] = dirs = _read_dirs(fid)\n\n        #\n        # system (1)\n        #\n        fid.seek(dirs[KIT.DIR_INDEX_SYSTEM][\"offset\"])\n        # check file format version\n        version, revision = np.fromfile(fid, INT32, 2)\n        if version < 2 or (version == 2 and revision < 3):\n            version_string = f\"V{version}R{revision:03d}\"\n            if allow_unknown_format:\n                unsupported_format = True\n                warn(f\"Force loading KIT format {version_string}\")\n            else:\n                raise UnsupportedKITFormat(\n                    version_string,\n                    f\"SQD file format {version_string} is not officially supported. \"\n                    \"Set allow_unknown_format=True to load it anyways.\",\n                )\n\n        sysid = np.fromfile(fid, INT32, 1)[0]\n        # basic info\n        system_name = _read_name(fid, n=128)\n        # model name\n        model_name = _read_name(fid, n=128)\n        # channels\n        sqd[\"nchan\"] = channel_count = int(np.fromfile(fid, INT32, 1)[0])\n        comment = _read_name(fid, n=256)\n        create_time, last_modified_time = np.fromfile(fid, INT32, 2)\n        del last_modified_time\n        fid.seek(KIT.INT * 3, SEEK_CUR)  # reserved\n        dewar_style = np.fromfile(fid, INT32, 1)[0]\n        fid.seek(KIT.INT * 3, SEEK_CUR)  # spare\n        fll_type = np.fromfile(fid, INT32, 1)[0]\n        fid.seek(KIT.INT * 3, SEEK_CUR)  # spare\n        trigger_type = np.fromfile(fid, INT32, 1)[0]\n        fid.seek(KIT.INT * 3, SEEK_CUR)  # spare\n        adboard_type = np.fromfile(fid, INT32, 1)[0]\n        fid.seek(KIT.INT * 29, SEEK_CUR)  # reserved\n\n        if version < 2 or (version == 2 and revision <= 3):\n            adc_range = float(np.fromfile(fid, INT32, 1)[0])\n        else:\n            adc_range = np.fromfile(fid, FLOAT64, 1)[0]\n        adc_polarity, adc_allocated, adc_stored = np.fromfile(fid, INT32, 3)\n        del adc_polarity\n        system_name = system_name.replace(\"\\x00\", \"\")\n        system_name = system_name.strip().replace(\"\\n\", \"/\")\n        model_name = model_name.replace(\"\\x00\", \"\")\n        model_name = model_name.strip().replace(\"\\n\", \"/\")\n\n        full_version = f\"V{version:d}R{revision:03d}\"\n        logger.debug(\"SQD file basic information:\")\n        logger.debug(\"Meg160 version = %s\", full_version)\n        logger.debug(\"System ID      = %i\", sysid)\n        logger.debug(\"System name    = %s\", system_name)\n        logger.debug(\"Model name     = %s\", model_name)\n        logger.debug(\"Channel count  = %i\", channel_count)\n        logger.debug(\"Comment        = %s\", comment)\n        logger.debug(\"Dewar style    = %i\", dewar_style)\n        logger.debug(\"FLL type       = %i\", fll_type)\n        logger.debug(\"Trigger type   = %i\", trigger_type)\n        logger.debug(\"A/D board type = %i\", adboard_type)\n        logger.debug(\"ADC range      = +/-%s[V]\", adc_range / 2.0)\n        logger.debug(\"ADC allocate   = %i[bit]\", adc_allocated)\n        logger.debug(\"ADC bit        = %i[bit]\", adc_stored)\n        # MGH description: 'acquisition (megacq) VectorView system at NMR-MGH'\n        description = f\"{system_name} ({sysid}) {full_version} {model_name}\"\n        assert adc_allocated % 8 == 0\n        sqd[\"dtype\"] = np.dtype(f\"<i{adc_allocated // 8}\")\n\n        # check that we can read this file\n        if fll_type not in KIT.FLL_SETTINGS:\n            fll_types = sorted(KIT.FLL_SETTINGS.keys())\n            use_fll_type = fll_types[np.searchsorted(fll_types, fll_type) - 1]\n            warn(\n                \"Unknown site filter settings (FLL) for system \"\n                f'\"{system_name}\" model \"{model_name}\" (ID {sysid}), will assume FLL '\n                f\"{fll_type}->{use_fll_type}, check your data for correctness, \"\n                \"including channel scales and filter settings!\"\n            )\n            fll_type = use_fll_type\n\n        #\n        # channel information (4)\n        #\n        chan_dir = dirs[KIT.DIR_INDEX_CHANNELS]\n        chan_offset, chan_size = chan_dir[\"offset\"], chan_dir[\"size\"]\n        sqd[\"channels\"] = channels = []\n        exg_gains = list()\n        for i in range(channel_count):\n            fid.seek(chan_offset + chan_size * i)\n            (channel_type,) = np.fromfile(fid, INT32, 1)\n            # System 52 mislabeled reference channels as NULL. This was fixed\n            # in system 53; not sure about 51...\n            if sysid == 52 and i < 160 and channel_type == KIT.CHANNEL_NULL:\n                channel_type = KIT.CHANNEL_MAGNETOMETER_REFERENCE\n\n            if channel_type in KIT.CHANNELS_MEG:\n                if channel_type not in KIT.CH_TO_FIFF_COIL:\n                    raise NotImplementedError(\n                        \"KIT channel type {channel_type} can not be read. Please \"\n                        \"contact the mne-python developers.\"\n                    )\n                channels.append(\n                    {\n                        \"type\": channel_type,\n                        # (x, y, z, theta, phi) for all MEG channels. Some channel\n                        # types have additional information which we're not using.\n                        \"loc\": np.fromfile(fid, dtype=FLOAT64, count=5),\n                    }\n                )\n                if channel_type in KIT.CHANNEL_NAME_NCHAR:\n                    fid.seek(16, SEEK_CUR)  # misc fields\n                    channels[-1][\"name\"] = _read_name(fid, channel_type)\n            elif channel_type in KIT.CHANNELS_MISC:\n                (channel_no,) = np.fromfile(fid, INT32, 1)\n                fid.seek(4, SEEK_CUR)\n                name = _read_name(fid, channel_type)\n                channels.append(\n                    {\n                        \"type\": channel_type,\n                        \"no\": channel_no,\n                        \"name\": name,\n                    }\n                )\n                if channel_type in (KIT.CHANNEL_EEG, KIT.CHANNEL_ECG):\n                    offset = 6 if channel_type == KIT.CHANNEL_EEG else 8\n                    fid.seek(offset, SEEK_CUR)\n                    exg_gains.append(np.fromfile(fid, FLOAT64, 1)[0])\n            elif channel_type == KIT.CHANNEL_NULL:\n                channels.append({\"type\": channel_type})\n            else:\n                raise OSError(\"Unknown KIT channel type: {channel_type}\")\n        exg_gains = np.array(exg_gains)\n\n        #\n        # Channel sensitivity information: (5)\n        #\n\n        # only sensor channels requires gain. the additional misc channels\n        # (trigger channels, audio and voice channels) are passed\n        # through unaffected\n        fid.seek(dirs[KIT.DIR_INDEX_CALIBRATION][\"offset\"])\n        # (offset [Volt], gain [Tesla/Volt]) for each channel\n        sensitivity = np.fromfile(fid, dtype=FLOAT64, count=channel_count * 2)\n        sensitivity.shape = (channel_count, 2)\n        channel_offset, channel_gain = sensitivity.T\n        assert (channel_offset == 0).all()  # otherwise we have a problem\n\n        #\n        # amplifier gain (7)\n        #\n        fid.seek(dirs[KIT.DIR_INDEX_AMP_FILTER][\"offset\"])\n        amp_data = np.fromfile(fid, INT32, 1)[0]\n        if fll_type >= 100:  # Kapper Type\n            # gain:             mask           bit\n            gain1 = (amp_data & 0x00007000) >> 12\n            gain2 = (amp_data & 0x70000000) >> 28\n            gain3 = (amp_data & 0x07000000) >> 24\n            amp_gain = KIT.GAINS[gain1] * KIT.GAINS[gain2] * KIT.GAINS[gain3]\n            # filter settings\n            hpf = (amp_data & 0x00000700) >> 8\n            lpf = (amp_data & 0x00070000) >> 16\n            bef = (amp_data & 0x00000003) >> 0\n        else:  # Hanger Type\n            # gain\n            input_gain = (amp_data & 0x1800) >> 11\n            output_gain = (amp_data & 0x0007) >> 0\n            amp_gain = KIT.GAINS[input_gain] * KIT.GAINS[output_gain]\n            # filter settings\n            hpf = (amp_data & 0x007) >> 4\n            lpf = (amp_data & 0x0700) >> 8\n            bef = (amp_data & 0xC000) >> 14\n        hpf_options, lpf_options, bef_options = KIT.FLL_SETTINGS[fll_type]\n        sqd[\"highpass\"] = KIT.HPFS[hpf_options][hpf]\n        sqd[\"lowpass\"] = KIT.LPFS[lpf_options][lpf]\n        sqd[\"notch\"] = KIT.BEFS[bef_options][bef]\n\n        #\n        # Acquisition Parameters (8)\n        #\n        fid.seek(dirs[KIT.DIR_INDEX_ACQ_COND][\"offset\"])\n        (sqd[\"acq_type\"],) = (acq_type,) = np.fromfile(fid, INT32, 1)\n        (sqd[\"sfreq\"],) = np.fromfile(fid, FLOAT64, 1)\n        if acq_type == KIT.CONTINUOUS:\n            # samples_count, = np.fromfile(fid, INT32, 1)\n            fid.seek(KIT.INT, SEEK_CUR)\n            (sqd[\"n_samples\"],) = np.fromfile(fid, INT32, 1)\n        elif acq_type == KIT.EVOKED or acq_type == KIT.EPOCHS:\n            (sqd[\"frame_length\"],) = np.fromfile(fid, INT32, 1)\n            (sqd[\"pretrigger_length\"],) = np.fromfile(fid, INT32, 1)\n            (sqd[\"average_count\"],) = np.fromfile(fid, INT32, 1)\n            (sqd[\"n_epochs\"],) = np.fromfile(fid, INT32, 1)\n            if acq_type == KIT.EVOKED:\n                sqd[\"n_samples\"] = sqd[\"frame_length\"]\n            else:\n                sqd[\"n_samples\"] = sqd[\"frame_length\"] * sqd[\"n_epochs\"]\n        else:\n            raise OSError(\n                f\"Invalid acquisition type: {acq_type}. Your file is neither \"\n                \"continuous nor epoched data.\"\n            )\n\n        #\n        # digitization information (12 and 26)\n        #\n        dig_dir = dirs[KIT.DIR_INDEX_DIG_POINTS]\n        cor_dir = dirs[KIT.DIR_INDEX_COREG]\n        dig = dict()\n        hsp = list()\n        if dig_dir[\"count\"] > 0 and cor_dir[\"count\"] > 0:\n            # directories (0)\n            fid.seek(dig_dir[\"offset\"])\n            for _ in range(dig_dir[\"count\"]):\n                name = _read_name(fid, n=8).strip()\n                # Sometimes there are mismatches (e.g., AFz vs AFZ) between\n                # the channel name and its digitized, name, so let's be case\n                # insensitive. It will also prevent collisions with HSP\n                name = name.lower()\n                rr = np.fromfile(fid, FLOAT64, 3)\n                if name:\n                    assert name not in dig\n                    dig[name] = rr\n                else:\n                    hsp.append(rr)\n\n            # nasion, lpa, rpa, HPI in native space\n            elp = []\n            for key in (\n                \"fidnz\",\n                \"fidt9\",\n                \"fidt10\",\n                \"hpi_1\",\n                \"hpi_2\",\n                \"hpi_3\",\n                \"hpi_4\",\n                \"hpi_5\",\n            ):\n                if key in dig and np.isfinite(dig[key]).all():\n                    elp.append(dig.pop(key))\n            elp = np.array(elp)\n            hsp = np.array(hsp, float).reshape(-1, 3)\n            if elp.shape not in ((6, 3), (7, 3), (8, 3)):\n                raise RuntimeError(f\"Fewer than 3 HPI coils found, got {len(elp) - 3}\")\n            # coregistration\n            fid.seek(cor_dir[\"offset\"])\n            mrk = np.zeros((elp.shape[0] - 3, 3))\n            meg_done = [True] * 5\n            for _ in range(cor_dir[\"count\"]):\n                done = np.fromfile(fid, INT32, 1)[0]\n                fid.seek(\n                    16 * KIT.DOUBLE + 16 * KIT.DOUBLE,  # meg_to_mri  # mri_to_meg\n                    SEEK_CUR,\n                )\n                marker_count = np.fromfile(fid, INT32, 1)[0]\n                if not done:\n                    continue\n                assert marker_count >= len(mrk)\n                for mi in range(len(mrk)):\n                    mri_type, meg_type, mri_done, this_meg_done = np.fromfile(\n                        fid, INT32, 4\n                    )\n                    del mri_type, meg_type, mri_done\n                    meg_done[mi] = bool(this_meg_done)\n                    fid.seek(3 * KIT.DOUBLE, SEEK_CUR)  # mri_pos\n                    mrk[mi] = np.fromfile(fid, FLOAT64, 3)\n                fid.seek(256, SEEK_CUR)  # marker_file (char)\n            if not all(meg_done):\n                logger.info(\n                    f\"Keeping {sum(meg_done)}/{len(meg_done)} HPI \"\n                    \"coils that were digitized\"\n                )\n                elp = elp[[True] * 3 + meg_done]\n                mrk = mrk[meg_done]\n            sqd.update(hsp=hsp, elp=elp, mrk=mrk)\n\n    # precompute conversion factor for reading data\n    if unsupported_format:\n        if sysid not in LEGACY_AMP_PARAMS:\n            raise OSError(f\"Legacy parameters for system ID {sysid} unavailable.\")\n        adc_range, adc_stored = LEGACY_AMP_PARAMS[sysid]\n    is_meg = np.array([ch[\"type\"] in KIT.CHANNELS_MEG for ch in channels])\n    ad_to_volt = adc_range / (2.0**adc_stored)\n    ad_to_tesla = ad_to_volt / amp_gain * channel_gain\n    conv_factor = np.where(is_meg, ad_to_tesla, ad_to_volt)\n    # XXX this is a bit of a hack. Should probably do this more cleanly at\n    # some point... the 2 ** (adc_stored - 14) was empirically determined using\n    # the test files with known amplitudes. The conv_factors need to be\n    # replaced by these values otherwise we're off by a factor off 5000.0\n    # for the EEG data.\n    is_exg = [ch[\"type\"] in (KIT.CHANNEL_EEG, KIT.CHANNEL_ECG) for ch in channels]\n    exg_gains /= 2.0 ** (adc_stored - 14)\n    exg_gains[exg_gains == 0] = ad_to_volt\n    conv_factor[is_exg] = exg_gains\n    sqd[\"conv_factor\"] = conv_factor[:, np.newaxis]\n\n    # Create raw.info dict for raw fif object with SQD data\n    info = _empty_info(float(sqd[\"sfreq\"]))\n    info.update(\n        meas_date=_stamp_to_dt((create_time, 0)),\n        lowpass=sqd[\"lowpass\"],\n        highpass=sqd[\"highpass\"],\n        kit_system_id=sysid,\n        description=description,\n    )\n\n    # Creates a list of dicts of meg channels for raw.info\n    logger.info(\"Setting channel info structure...\")\n    info[\"chs\"] = fiff_channels = []\n    channel_index = defaultdict(lambda: 0)\n    sqd[\"eeg_dig\"] = OrderedDict()\n    for idx, ch in enumerate(channels, 1):\n        if ch[\"type\"] in KIT.CHANNELS_MEG:\n            ch_name = ch.get(\"name\", \"\")\n            if ch_name == \"\" or standardize_names:\n                ch_name = f\"MEG {idx:03d}\"\n            # create three orthogonal vector\n            # ch_angles[0]: theta, ch_angles[1]: phi\n            theta, phi = np.radians(ch[\"loc\"][3:])\n            x = sin(theta) * cos(phi)\n            y = sin(theta) * sin(phi)\n            z = cos(theta)\n            vec_z = np.array([x, y, z])\n            vec_z /= np.linalg.norm(vec_z)\n            vec_x = np.zeros(vec_z.size, dtype=np.float64)\n            if vec_z[1] < vec_z[2]:\n                if vec_z[0] < vec_z[1]:\n                    vec_x[0] = 1.0\n                else:\n                    vec_x[1] = 1.0\n            elif vec_z[0] < vec_z[2]:\n                vec_x[0] = 1.0\n            else:\n                vec_x[2] = 1.0\n            vec_x -= np.sum(vec_x * vec_z) * vec_z\n            vec_x /= np.linalg.norm(vec_x)\n            vec_y = np.cross(vec_z, vec_x)\n            # transform to Neuromag like coordinate space\n            vecs = np.vstack((ch[\"loc\"][:3], vec_x, vec_y, vec_z))\n            vecs = apply_trans(als_ras_trans, vecs)\n            unit = FIFF.FIFF_UNIT_T\n            loc = vecs.ravel()\n        else:\n            ch_type_label = KIT.CH_LABEL[ch[\"type\"]]\n            channel_index[ch_type_label] += 1\n            ch_type_index = channel_index[ch_type_label]\n            ch_name = ch.get(\"name\", \"\")\n            eeg_name = ch_name.lower()\n            # some files have all EEG labeled as EEG\n            if ch_name in (\"\", \"EEG\") or standardize_names:\n                ch_name = f\"{ch_type_label} {ch_type_index:03d}\"\n            unit = FIFF.FIFF_UNIT_V\n            loc = np.zeros(12)\n            if eeg_name and eeg_name in dig:\n                loc[:3] = sqd[\"eeg_dig\"][eeg_name] = dig[eeg_name]\n        fiff_channels.append(\n            dict(\n                cal=KIT.CALIB_FACTOR,\n                logno=idx,\n                scanno=idx,\n                range=KIT.RANGE,\n                unit=unit,\n                unit_mul=KIT.UNIT_MUL,\n                ch_name=ch_name,\n                coord_frame=FIFF.FIFFV_COORD_DEVICE,\n                coil_type=KIT.CH_TO_FIFF_COIL[ch[\"type\"]],\n                kind=KIT.CH_TO_FIFF_KIND[ch[\"type\"]],\n                loc=loc,\n            )\n        )\n    info._unlocked = False\n    info._update_redundant()\n    return info, sqd", "metadata": {}}
{"_id": "mne_mne_io/kit/kit.py_read_raw_kit_code", "title": "read_raw_kit", "text": "def read_raw_kit(\n    input_fname,\n    mrk=None,\n    elp=None,\n    hsp=None,\n    stim=\">\",\n    slope=\"-\",\n    stimthresh=1,\n    preload=False,\n    stim_code=\"binary\",\n    allow_unknown_format=False,\n    standardize_names=False,\n    *,\n    bad_coils=(),\n    verbose=None,\n) -> RawKIT:\n    r\"\"\"Reader function for Ricoh/KIT conversion to FIF.\n\n    Parameters\n    ----------\n    input_fname : path-like\n        Path to the SQD file.\n    %(kit_mrk)s\n    %(kit_elp)s\n    %(kit_hsp)s\n    %(kit_stim)s\n    %(kit_slope)s\n    %(kit_stimthresh)s\n    %(preload)s\n    %(kit_stimcode)s\n    allow_unknown_format : bool\n        Force reading old data that is not officially supported. Alternatively,\n        read and re-save the data with the KIT MEG Laboratory application.\n    %(standardize_names)s\n    %(kit_badcoils)s\n    %(verbose)s\n\n    Returns\n    -------\n    raw : instance of RawKIT\n        A Raw object containing KIT data.\n        See :class:`mne.io.Raw` for documentation of attributes and methods.\n\n    See Also\n    --------\n    mne.io.Raw : Documentation of attributes and methods of RawKIT.\n\n    Notes\n    -----\n    ``elp`` and ``hsp`` are usually the exported text files (\\*.txt) from the\n    Polhemus FastScan system. ``hsp`` refers to the headshape surface points.\n    ``elp`` refers to the points in head-space that corresponds to the HPI\n    points.\n\n    If ``mrk``\\, ``hsp`` or ``elp`` are :term:`array_like` inputs, then the\n    numbers in xyz coordinates should be in units of meters.\n    \"\"\"\n    return RawKIT(\n        input_fname=input_fname,\n        mrk=mrk,\n        elp=elp,\n        hsp=hsp,\n        stim=stim,\n        slope=slope,\n        stimthresh=stimthresh,\n        preload=preload,\n        stim_code=stim_code,\n        allow_unknown_format=allow_unknown_format,\n        standardize_names=standardize_names,\n        bad_coils=bad_coils,\n        verbose=verbose,\n    )", "metadata": {}}
{"_id": "mne_mne_io/kit/kit.py_read_epochs_kit_code", "title": "read_epochs_kit", "text": "def read_epochs_kit(\n    input_fname,\n    events,\n    event_id=None,\n    mrk=None,\n    elp=None,\n    hsp=None,\n    allow_unknown_format=False,\n    standardize_names=False,\n    verbose=None,\n) -> EpochsKIT:\n    \"\"\"Reader function for Ricoh/KIT epochs files.\n\n    Parameters\n    ----------\n    input_fname : path-like\n        Path to the SQD file.\n    events : array of int, shape (n_events, 3) | path-like\n        The array of :term:`events`. The first column contains the event time\n        in samples, with :term:`first_samp` included. The third column contains\n        the event id. If a path, must yield a ``.txt`` file containing the\n        events.\n        If some events don't match the events of interest as specified by\n        ``event_id``, they will be marked as ``IGNORED`` in the drop log.\n    %(event_id)s\n    %(kit_mrk)s\n    %(kit_elp)s\n    %(kit_hsp)s\n    allow_unknown_format : bool\n        Force reading old data that is not officially supported. Alternatively,\n        read and re-save the data with the KIT MEG Laboratory application.\n    %(standardize_names)s\n    %(verbose)s\n\n    Returns\n    -------\n    EpochsKIT : instance of BaseEpochs\n        The epochs.\n\n    See Also\n    --------\n    mne.Epochs : Documentation of attributes and methods.\n\n    Notes\n    -----\n    .. versionadded:: 0.9.0\n    \"\"\"\n    epochs = EpochsKIT(\n        input_fname=input_fname,\n        events=events,\n        event_id=event_id,\n        mrk=mrk,\n        elp=elp,\n        hsp=hsp,\n        allow_unknown_format=allow_unknown_format,\n        standardize_names=standardize_names,\n        verbose=verbose,\n    )\n    return epochs", "metadata": {}}
{"_id": "mne_mne_io/kit/kit.py_read_stim_ch_code", "title": "read_stim_ch", "text": "def read_stim_ch(self, buffer_size=1e5):\n        \"\"\"Read events from data.\n\n        Parameter\n        ---------\n        buffer_size : int\n            The size of chunk to by which the data are scanned.\n\n        Returns\n        -------\n        events : array, [samples]\n           The event vector (1 x samples).\n        \"\"\"\n        buffer_size = int(buffer_size)\n        start = int(self.first_samp)\n        stop = int(self.last_samp + 1)\n\n        pick = pick_types(self.info, meg=False, ref_meg=False, stim=True, exclude=[])\n        stim_ch = np.empty((1, stop), dtype=np.int64)\n        for b_start in range(start, stop, buffer_size):\n            b_stop = b_start + buffer_size\n            x = self[pick, b_start:b_stop][0]\n            stim_ch[:, b_start : b_start + x.shape[1]] = x\n\n        return stim_ch", "metadata": {}}
{"_id": "mne_mne_io/kit/coreg.py_read_mrk_code", "title": "read_mrk", "text": "def read_mrk(fname):\n    r\"\"\"Marker Point Extraction in MEG space directly from sqd.\n\n    Parameters\n    ----------\n    fname : path-like\n        Absolute path to Marker file.\n        File formats allowed: \\*.sqd, \\*.mrk, \\*.txt.\n\n    Returns\n    -------\n    mrk_points : ndarray, shape (n_points, 3)\n        Marker points in MEG space [m].\n    \"\"\"\n    from .kit import _read_dirs\n\n    fname = Path(_check_fname(fname, \"read\", must_exist=True, name=\"mrk file\"))\n    _check_option(\"file extension\", fname.suffix, (\".sqd\", \".mrk\", \".txt\"))\n    if fname.suffix in (\".sqd\", \".mrk\"):\n        with open(fname, \"rb\", buffering=0) as fid:\n            dirs = _read_dirs(fid)\n            fid.seek(dirs[KIT.DIR_INDEX_COREG][\"offset\"])\n            # skips match_done, meg_to_mri and mri_to_meg\n            fid.seek(KIT.INT + (2 * KIT.DOUBLE * 16), SEEK_CUR)\n            mrk_count = np.fromfile(fid, INT32, 1)[0]\n            pts = []\n            for _ in range(mrk_count):\n                # mri_type, meg_type, mri_done, meg_done\n                _, _, _, meg_done = np.fromfile(fid, INT32, 4)\n                _, meg_pts = np.fromfile(fid, FLOAT64, 6).reshape(2, 3)\n                if meg_done:\n                    pts.append(meg_pts)\n            mrk_points = np.array(pts)\n    else:\n        assert fname.suffix == \".txt\"\n        mrk_points = _read_dig_kit(fname, unit=\"m\")\n\n    # check output\n    mrk_points = np.asarray(mrk_points)\n    if mrk_points.shape != (5, 3):\n        err = f\"{repr(fname)} is no marker file, shape is {mrk_points.shape}\"\n        raise ValueError(err)\n    return mrk_points", "metadata": {}}
{"_id": "mne_mne_io/kit/coreg.py_read_sns_code", "title": "read_sns", "text": "def read_sns(fname):\n    \"\"\"Sensor coordinate extraction in MEG space.\n\n    Parameters\n    ----------\n    fname : path-like\n        Absolute path to sensor definition file.\n\n    Returns\n    -------\n    locs : numpy.array, shape = (n_points, 3)\n        Sensor coil location.\n    \"\"\"\n    p = re.compile(\n        r\"\\d,[A-Za-z]*,([\\.\\-0-9]+),\"\n        + r\"([\\.\\-0-9]+),([\\.\\-0-9]+),\"\n        + r\"([\\.\\-0-9]+),([\\.\\-0-9]+)\"\n    )\n    with open(fname) as fid:\n        locs = np.array(p.findall(fid.read()), dtype=float)\n    return locs", "metadata": {}}
{"_id": "mne_mne_io/egi/egi.py_read_raw_egi_code", "title": "read_raw_egi", "text": "def read_raw_egi(\n    input_fname,\n    eog=None,\n    misc=None,\n    include=None,\n    exclude=None,\n    preload=False,\n    channel_naming=\"E%d\",\n    *,\n    events_as_annotations=True,\n    verbose=None,\n) -> \"RawEGI\":\n    \"\"\"Read EGI simple binary as raw object.\n\n    Parameters\n    ----------\n    input_fname : path-like\n        Path to the raw file. Files with an extension ``.mff`` are\n        automatically considered to be EGI's native MFF format files.\n    eog : list or tuple\n        Names of channels or list of indices that should be designated\n        EOG channels. Default is None.\n    misc : list or tuple\n        Names of channels or list of indices that should be designated\n        MISC channels. Default is None.\n    include : None | list\n       The event channels to be included when creating the synthetic\n       trigger or annotations. Defaults to None.\n       Note. Overrides ``exclude`` parameter.\n    exclude : None | list\n       The event channels to be ignored when creating the synthetic\n       trigger or annotations. Defaults to None. If None, the ``sync`` and ``TREV``\n       channels will be ignored. This is ignored when ``include`` is not None.\n    %(preload)s\n\n        .. versionadded:: 0.11\n    channel_naming : str\n        Channel naming convention for the data channels. Defaults to ``'E%%d'``\n        (resulting in channel names ``'E1'``, ``'E2'``, ``'E3'``...). The\n        effective default prior to 0.14.0 was ``'EEG %%03d'``.\n        .. versionadded:: 0.14.0\n\n    events_as_annotations : bool\n        If True, annotations are created from experiment events. If False (default),\n        a synthetic trigger channel ``STI 014`` is created from experiment events.\n        See the Notes section for details.\n        The default will change from False to True in version 1.9.\n\n        .. versionadded:: 1.8.0\n    %(verbose)s\n\n    Returns\n    -------\n    raw : instance of RawEGI\n        A Raw object containing EGI data.\n        See :class:`mne.io.Raw` for documentation of attributes and methods.\n\n    See Also\n    --------\n    mne.io.Raw : Documentation of attributes and methods of RawEGI.\n\n    Notes\n    -----\n    When ``events_from_annotations=True``, event codes on stimulus channels like\n    ``DIN1`` are stored as annotations with the ``description`` set to the stimulus\n    channel name.\n\n    When ``events_from_annotations=False`` and events are present on the included\n    stimulus channels, a new stim channel ``STI014`` will be synthesized from the\n    events. It will contain 1-sample pulses where the Netstation file had event\n    timestamps. A ``raw.event_id`` dictionary is added to the raw object that will have\n    arbitrary sequential integer IDs for the events. This will fail if any timestamps\n    are duplicated. The ``event_id`` will also not survive a save/load roundtrip.\n\n    For these reasons, it is recommended to use ``events_as_annotations=True``.\n    \"\"\"\n    _validate_type(input_fname, \"path-like\", \"input_fname\")\n    input_fname = str(input_fname)\n    _validate_type(events_as_annotations, bool, \"events_as_annotations\")\n\n    if input_fname.rstrip(\"/\\\\\").endswith(\".mff\"):  # allows .mff or .mff/\n        return _read_raw_egi_mff(\n            input_fname,\n            eog,\n            misc,\n            include,\n            exclude,\n            preload,\n            channel_naming,\n            events_as_annotations=events_as_annotations,\n            verbose=verbose,\n        )\n    return RawEGI(\n        input_fname,\n        eog,\n        misc,\n        include,\n        exclude,\n        preload,\n        channel_naming,\n        events_as_annotations=events_as_annotations,\n        verbose=verbose,\n    )", "metadata": {}}
{"_id": "mne_mne_io/egi/egimff.py_read_evokeds_mff_code", "title": "read_evokeds_mff", "text": "def read_evokeds_mff(\n    fname, condition=None, channel_naming=\"E%d\", baseline=None, verbose=None\n):\n    \"\"\"Read averaged MFF file as EvokedArray or list of EvokedArray.\n\n    Parameters\n    ----------\n    fname : path-like\n        File path to averaged MFF file. Should end in ``.mff``.\n    condition : int or str | list of int or str | None\n        The index (indices) or category (categories) from which to read in\n        data. Averaged MFF files can contain separate averages for different\n        categories. These can be indexed by the block number or the category\n        name. If ``condition`` is a list or None, a list of EvokedArray objects\n        is returned.\n    channel_naming : str\n        Channel naming convention for EEG channels. Defaults to 'E%%d'\n        (resulting in channel names 'E1', 'E2', 'E3'...).\n    baseline : None (default) or tuple of length 2\n        The time interval to apply baseline correction. If None do not apply\n        it. If baseline is (a, b) the interval is between \"a (s)\" and \"b (s)\".\n        If a is None the beginning of the data is used and if b is None then b\n        is set to the end of the interval. If baseline is equal to (None, None)\n        all the time interval is used. Correction is applied by computing mean\n        of the baseline period and subtracting it from the data. The baseline\n        (a, b) includes both endpoints, i.e. all timepoints t such that\n        a <= t <= b.\n    %(verbose)s\n\n    Returns\n    -------\n    evoked : EvokedArray or list of EvokedArray\n        The evoked dataset(s); one EvokedArray if condition is int or str,\n        or list of EvokedArray if condition is None or list.\n\n    Raises\n    ------\n    ValueError\n        If ``fname`` has file extension other than '.mff'.\n    ValueError\n        If the MFF file specified by ``fname`` is not averaged.\n    ValueError\n        If no categories.xml file in MFF directory specified by ``fname``.\n\n    See Also\n    --------\n    Evoked, EvokedArray, create_info\n\n    Notes\n    -----\n    .. versionadded:: 0.22\n    \"\"\"\n    mffpy = _import_mffpy()\n    # Confirm `fname` is a path to an MFF file\n    fname = Path(fname)  # should be replace with _check_fname\n    if not fname.suffix == \".mff\":\n        raise ValueError('fname must be an MFF file with extension \".mff\".')\n    # Confirm the input MFF is averaged\n    mff = mffpy.Reader(fname)\n    try:\n        flavor = mff.mff_flavor\n    except AttributeError:  # < 6.3\n        flavor = mff.flavor\n    if flavor not in (\"averaged\", \"segmented\"):  # old, new names\n        raise ValueError(\n            f\"{fname} is a {flavor} MFF file. \"\n            \"fname must be the path to an averaged MFF file.\"\n        )\n    # Check for categories.xml file\n    if \"categories.xml\" not in mff.directory.listdir():\n        raise ValueError(\n            \"categories.xml not found in MFF directory. \"\n            f\"{fname} may not be an averaged MFF file.\"\n        )\n    return_list = True\n    if condition is None:\n        categories = mff.categories.categories\n        condition = list(categories.keys())\n    elif not isinstance(condition, list):\n        condition = [condition]\n        return_list = False\n    logger.info(f\"Reading {len(condition)} evoked datasets from {fname} ...\")\n    output = [\n        _read_evoked_mff(\n            fname, c, channel_naming=channel_naming, verbose=verbose\n        ).apply_baseline(baseline)\n        for c in condition\n    ]\n    return output if return_list else output[0]", "metadata": {}}
{"_id": "mne_mne_io/persyst/persyst.py_read_raw_persyst_code", "title": "read_raw_persyst", "text": "def read_raw_persyst(fname, preload=False, verbose=None) -> \"RawPersyst\":\n    \"\"\"Reader for a Persyst (.lay/.dat) recording.\n\n    Parameters\n    ----------\n    fname : path-like\n        Path to the Persyst header ``.lay`` file.\n    %(preload)s\n    %(verbose)s\n\n    Returns\n    -------\n    raw : instance of RawPersyst\n        A Raw object containing Persyst data.\n        See :class:`mne.io.Raw` for documentation of attributes and methods.\n\n    See Also\n    --------\n    mne.io.Raw : Documentation of attributes and methods of RawPersyst.\n\n    Notes\n    -----\n    It is assumed that the ``.lay`` and ``.dat`` file\n    are in the same directory. To get the correct file path to the\n    ``.dat`` file, ``read_raw_persyst`` will get the corresponding dat\n    filename from the lay file, and look for that file inside the same\n    directory as the lay file.\n    \"\"\"\n    return RawPersyst(fname, preload, verbose)", "metadata": {}}
{"_id": "mne_mne_io/nihon/nihon.py_read_raw_nihon_code", "title": "read_raw_nihon", "text": "def read_raw_nihon(fname, preload=False, verbose=None) -> \"RawNihon\":\n    \"\"\"Reader for an Nihon Kohden EEG file.\n\n    Parameters\n    ----------\n    fname : path-like\n        Path to the Nihon Kohden data file (``.EEG``).\n    preload : bool\n        If True, all data are loaded at initialization.\n    %(verbose)s\n\n    Returns\n    -------\n    raw : instance of RawNihon\n        A Raw object containing Nihon Kohden data.\n        See :class:`mne.io.Raw` for documentation of attributes and methods.\n\n    See Also\n    --------\n    mne.io.Raw : Documentation of attributes and methods of RawNihon.\n    \"\"\"\n    return RawNihon(fname, preload, verbose)", "metadata": {}}
{"_id": "mne_mne_io/besa/besa.py_read_evoked_besa_code", "title": "read_evoked_besa", "text": "def read_evoked_besa(fname, verbose=None):\n    \"\"\"Reader function for BESA ``.avr`` or ``.mul`` files.\n\n    When a ``.elp`` sidecar file is present, it will be used to determine\n    electrode information.\n\n    Parameters\n    ----------\n    fname : path-like\n        Path to the ``.avr`` or ``.mul`` file.\n    %(verbose)s\n\n    Returns\n    -------\n    ev : Evoked\n        The evoked data in the .avr or .mul file.\n    \"\"\"\n    fname = Path(fname)\n    if fname.suffix == \".avr\":\n        return _read_evoked_besa_avr(fname, verbose)\n    elif fname.suffix == \".mul\":\n        return _read_evoked_besa_mul(fname, verbose)\n    else:\n        raise ValueError(\"Filename must end in either .avr or .mul\")", "metadata": {}}
{"_id": "mne_mne_io/cnt/cnt.py_read_raw_cnt_code", "title": "read_raw_cnt", "text": "def read_raw_cnt(\n    input_fname,\n    eog=(),\n    misc=(),\n    ecg=(),\n    emg=(),\n    data_format=\"auto\",\n    date_format=\"mm/dd/yy\",\n    *,\n    header=\"auto\",\n    preload=False,\n    verbose=None,\n) -> \"RawCNT\":\n    \"\"\"Read CNT data as raw object.\n\n    .. Note::\n        2d spatial coordinates (x, y) for EEG channels are read from the file\n        header and fit to a sphere to compute corresponding z-coordinates.\n        If channels assigned as EEG channels have locations\n        far away from the head (i.e. x and y coordinates don't fit to a\n        sphere), all the channel locations will be distorted\n        (all channels that are not assigned with keywords ``eog``, ``ecg``,\n        ``emg`` and ``misc`` are assigned as EEG channels). If you are not\n        sure that the channel locations in the header are correct, it is\n        probably safer to replace them with :meth:`mne.io.Raw.set_montage`.\n        Montages can be created/imported with:\n\n        - Standard montages with :func:`mne.channels.make_standard_montage`\n        - Montages for `Compumedics systems\n          <https://compumedicsneuroscan.com>`__ with\n          :func:`mne.channels.read_dig_dat`\n        - Other reader functions are listed under *See Also* at\n          :class:`mne.channels.DigMontage`\n\n    Parameters\n    ----------\n    input_fname : path-like\n        Path to the data file.\n    eog : list | tuple | ``'auto'`` | ``'header'``\n        Names of channels or list of indices that should be designated\n        EOG channels. If 'header', VEOG and HEOG channels assigned in the file\n        header are used. If ``'auto'``, channel names containing ``'EOG'`` are\n        used. Defaults to empty tuple.\n    misc : list | tuple\n        Names of channels or list of indices that should be designated\n        MISC channels. Defaults to empty tuple.\n    ecg : list | tuple | ``'auto'``\n        Names of channels or list of indices that should be designated\n        ECG channels. If ``'auto'``, the channel names containing ``'ECG'`` are\n        used. Defaults to empty tuple.\n    emg : list | tuple\n        Names of channels or list of indices that should be designated\n        EMG channels. If 'auto', the channel names containing 'EMG' are used.\n        Defaults to empty tuple.\n    data_format : ``'auto'`` | ``'int16'`` | ``'int32'``\n        Defines the data format the data is read in. If ``'auto'``, it is\n        determined from the file header using ``numsamples`` field.\n        Defaults to ``'auto'``.\n    date_format : ``'mm/dd/yy'`` | ``'dd/mm/yy'``\n        Format of date in the header. Defaults to ``'mm/dd/yy'``.\n    header : ``'auto'`` | ``'new'`` | ``'old'``\n        Defines the header format. Used to describe how bad channels\n        are formatted. If auto, reads using old and new header and\n        if either contain a bad channel make channel bad.\n        Defaults to ``'auto'``.\n\n        .. versionadded:: 1.6\n    %(preload)s\n    %(verbose)s\n\n    Returns\n    -------\n    raw : instance of RawCNT.\n        The raw data.\n        See :class:`mne.io.Raw` for documentation of attributes and methods.\n\n    See Also\n    --------\n    mne.io.Raw : Documentation of attributes and methods of RawCNT.\n\n    Notes\n    -----\n    .. versionadded:: 0.12\n    \"\"\"\n    return RawCNT(\n        input_fname,\n        eog=eog,\n        misc=misc,\n        ecg=ecg,\n        emg=emg,\n        data_format=data_format,\n        date_format=date_format,\n        header=header,\n        preload=preload,\n        verbose=verbose,\n    )", "metadata": {}}
{"_id": "mne_mne_io/nicolet/nicolet.py_read_raw_nicolet_code", "title": "read_raw_nicolet", "text": "def read_raw_nicolet(\n    input_fname, ch_type, eog=(), ecg=(), emg=(), misc=(), preload=False, verbose=None\n) -> \"RawNicolet\":\n    \"\"\"Read Nicolet data as raw object.\n\n    ..note:: This reader takes data files with the extension ``.data`` as an\n             input. The header file with the same file name stem and an\n             extension ``.head`` is expected to be found in the same\n             directory.\n\n    Parameters\n    ----------\n    input_fname : path-like\n        Path to the data file (ending with ``.data`` not ``.head``).\n    ch_type : str\n        Channel type to designate to the data channels. Supported data types\n        include ``'eeg'``, ``'dbs'``.\n    eog : list | tuple | ``'auto'``\n        Names of channels or list of indices that should be designated\n        EOG channels. If ``'auto'``, the channel names beginning with\n        ``EOG`` are used. Defaults to empty tuple.\n    ecg : list or tuple | ``'auto'``\n        Names of channels or list of indices that should be designated\n        ECG channels. If ``'auto'``, the channel names beginning with\n        ``ECG`` are used. Defaults to empty tuple.\n    emg : list or tuple | ``'auto'``\n        Names of channels or list of indices that should be designated\n        EMG channels. If ``'auto'``, the channel names beginning with\n        ``EMG`` are used. Defaults to empty tuple.\n    misc : list or tuple\n        Names of channels or list of indices that should be designated\n        MISC channels. Defaults to empty tuple.\n    %(preload)s\n    %(verbose)s\n\n    Returns\n    -------\n    raw : instance of Raw\n        A Raw object containing the data.\n\n    See Also\n    --------\n    mne.io.Raw : Documentation of attributes and methods.\n    \"\"\"\n    return RawNicolet(\n        input_fname,\n        ch_type,\n        eog=eog,\n        ecg=ecg,\n        emg=emg,\n        misc=misc,\n        preload=preload,\n        verbose=verbose,\n    )", "metadata": {}}
{"_id": "mne_mne_io/eeglab/eeglab.py_read_raw_eeglab_code", "title": "read_raw_eeglab", "text": "def read_raw_eeglab(\n    input_fname,\n    eog=(),\n    preload=False,\n    uint16_codec=None,\n    montage_units=\"auto\",\n    verbose=None,\n) -> \"RawEEGLAB\":\n    r\"\"\"Read an EEGLAB .set file.\n\n    Parameters\n    ----------\n    input_fname : path-like\n        Path to the ``.set`` file. If the data is stored in a separate ``.fdt``\n        file, it is expected to be in the same folder as the ``.set`` file.\n    eog : list | tuple | ``'auto'``\n        Names or indices of channels that should be designated EOG channels.\n        If 'auto', the channel names containing ``EOG`` or ``EYE`` are used.\n        Defaults to empty tuple.\n    %(preload)s\n        Note that ``preload=False`` will be effective only if the data is\n        stored in a separate binary file.\n    %(uint16_codec)s\n    %(montage_units)s\n\n        .. versionchanged:: 1.6\n           Support for ``'auto'`` was added and is the new default.\n    %(verbose)s\n\n    Returns\n    -------\n    raw : instance of RawEEGLAB\n        A Raw object containing EEGLAB .set data.\n        See :class:`mne.io.Raw` for documentation of attributes and methods.\n\n    See Also\n    --------\n    mne.io.Raw : Documentation of attributes and methods of RawEEGLAB.\n\n    Notes\n    -----\n    .. versionadded:: 0.11.0\n    \"\"\"\n    return RawEEGLAB(\n        input_fname=input_fname,\n        preload=preload,\n        eog=eog,\n        uint16_codec=uint16_codec,\n        montage_units=montage_units,\n        verbose=verbose,\n    )", "metadata": {}}
{"_id": "mne_mne_io/eeglab/eeglab.py_read_epochs_eeglab_code", "title": "read_epochs_eeglab", "text": "def read_epochs_eeglab(\n    input_fname,\n    events=None,\n    event_id=None,\n    eog=(),\n    *,\n    uint16_codec=None,\n    montage_units=\"auto\",\n    verbose=None,\n) -> \"EpochsEEGLAB\":\n    r\"\"\"Reader function for EEGLAB epochs files.\n\n    Parameters\n    ----------\n    input_fname : path-like\n        Path to the ``.set`` file. If the data is stored in a separate ``.fdt``\n        file, it is expected to be in the same folder as the ``.set`` file.\n    events : path-like | array, shape (n_events, 3) | None\n        Path to events file. If array, it is the events typically returned\n        by the read_events function. If some events don't match the events\n        of interest as specified by event_id, they will be marked as 'IGNORED'\n        in the drop log. If None, it is constructed from the EEGLAB (.set) file\n        with each unique event encoded with a different integer.\n    event_id : int | list of int | dict | None\n        The id of the event to consider. If dict, the keys can later be used\n        to access associated events.\n        Example::\n\n            {\"auditory\":1, \"visual\":3}\n\n        If int, a dict will be created with\n        the id as string. If a list, all events with the IDs specified\n        in the list are used. If None, the event_id is constructed from the\n        EEGLAB (.set) file with each descriptions copied from ``eventtype``.\n    eog : list | tuple | 'auto'\n        Names or indices of channels that should be designated EOG channels.\n        If 'auto', the channel names containing ``EOG`` or ``EYE`` are used.\n        Defaults to empty tuple.\n    %(uint16_codec)s\n    %(montage_units)s\n\n        .. versionchanged:: 1.6\n           Support for ``'auto'`` was added and is the new default.\n    %(verbose)s\n\n    Returns\n    -------\n    EpochsEEGLAB : instance of BaseEpochs\n        The epochs.\n\n    See Also\n    --------\n    mne.Epochs : Documentation of attributes and methods.\n\n    Notes\n    -----\n    .. versionadded:: 0.11.0\n    \"\"\"\n    epochs = EpochsEEGLAB(\n        input_fname=input_fname,\n        events=events,\n        eog=eog,\n        event_id=event_id,\n        uint16_codec=uint16_codec,\n        montage_units=montage_units,\n        verbose=verbose,\n    )\n    return epochs", "metadata": {}}
{"_id": "mne_mne_io/ctf/ctf.py_read_raw_ctf_code", "title": "read_raw_ctf", "text": "def read_raw_ctf(\n    directory, system_clock=\"truncate\", preload=False, clean_names=False, verbose=None\n) -> \"RawCTF\":\n    \"\"\"Raw object from CTF directory.\n\n    Parameters\n    ----------\n    directory : path-like\n        Path to the CTF data (ending in ``'.ds'``).\n    system_clock : str\n        How to treat the system clock. Use \"truncate\" (default) to truncate\n        the data file when the system clock drops to zero, and use \"ignore\"\n        to ignore the system clock (e.g., if head positions are measured\n        multiple times during a recording).\n    %(preload)s\n    clean_names : bool, optional\n        If True main channel names and compensation channel names will\n        be cleaned from CTF suffixes. The default is False.\n    %(verbose)s\n\n    Returns\n    -------\n    raw : instance of RawCTF\n        The raw data.\n\n    Notes\n    -----\n    .. versionadded:: 0.11\n\n    To read in the Polhemus digitization data (for example, from\n    a .pos file), include the file in the CTF directory. The\n    points will then automatically be read into the `mne.io.Raw`\n    instance via `mne.io.read_raw_ctf`.\n    \"\"\"\n    return RawCTF(\n        directory,\n        system_clock,\n        preload=preload,\n        clean_names=clean_names,\n        verbose=verbose,\n    )", "metadata": {}}
{"_id": "mne_mne_io/fieldtrip/fieldtrip.py_read_raw_fieldtrip_code", "title": "read_raw_fieldtrip", "text": "def read_raw_fieldtrip(fname, info, data_name=\"data\") -> RawArray:\n    \"\"\"Load continuous (raw) data from a FieldTrip preprocessing structure.\n\n    This function expects to find single trial raw data (FT_DATATYPE_RAW) in\n    the structure data_name is pointing at.\n\n    .. warning:: FieldTrip does not normally store the original information\n                 concerning channel location, orientation, type etc. It is\n                 therefore **highly recommended** to provide the info field.\n                 This can be obtained by reading the original raw data file\n                 with MNE functions (without preload). The returned object\n                 contains the necessary info field.\n\n    Parameters\n    ----------\n    fname : path-like\n        Path and filename of the ``.mat`` file containing the data.\n    info : dict or None\n        The info dict of the raw data file corresponding to the data to import.\n        If this is set to None, limited information is extracted from the\n        FieldTrip structure.\n    data_name : str\n        Name of heading dict/variable name under which the data was originally\n        saved in MATLAB.\n\n    Returns\n    -------\n    raw : instance of RawArray\n        A Raw Object containing the loaded data.\n        See :class:`mne.io.Raw` for documentation of attributes and methods.\n\n    See Also\n    --------\n    mne.io.Raw : Documentation of attributes and methods of RawArray.\n    \"\"\"\n    read_mat = _import_pymatreader_funcs(\"FieldTrip I/O\")\n    fname = _check_fname(fname, overwrite=\"read\", must_exist=True)\n\n    ft_struct = read_mat(fname, ignore_fields=[\"previous\"], variable_names=[data_name])\n\n    # load data and set ft_struct to the heading dictionary\n    ft_struct = ft_struct[data_name]\n\n    _validate_ft_struct(ft_struct)\n\n    info = _create_info(ft_struct, info)  # create info structure\n    data = np.array(ft_struct[\"trial\"])  # create the main data array\n\n    if data.ndim > 2:\n        data = np.squeeze(data)\n\n    if data.ndim == 1:\n        data = data[np.newaxis, ...]\n\n    if data.ndim != 2:\n        raise RuntimeError(\n            \"The data you are trying to load does not seem to be raw data\"\n        )\n\n    raw = RawArray(data, info)  # create an MNE RawArray\n    return raw", "metadata": {}}
{"_id": "mne_mne_io/fieldtrip/fieldtrip.py_read_epochs_fieldtrip_code", "title": "read_epochs_fieldtrip", "text": "def read_epochs_fieldtrip(\n    fname, info, data_name=\"data\", trialinfo_column=0\n) -> EpochsArray:\n    \"\"\"Load epoched data from a FieldTrip preprocessing structure.\n\n    This function expects to find epoched data in the structure data_name is\n    pointing at.\n\n    .. warning:: Only epochs with the same amount of channels and samples are\n                 supported!\n\n    .. warning:: FieldTrip does not normally store the original information\n                 concerning channel location, orientation, type etc. It is\n                 therefore **highly recommended** to provide the info field.\n                 This can be obtained by reading the original raw data file\n                 with MNE functions (without preload). The returned object\n                 contains the necessary info field.\n\n    Parameters\n    ----------\n    fname : path-like\n        Path and filename of the ``.mat`` file containing the data.\n    info : dict or None\n        The info dict of the raw data file corresponding to the data to import.\n        If this is set to None, limited information is extracted from the\n        FieldTrip structure.\n    data_name : str\n        Name of heading dict/ variable name under which the data was originally\n        saved in MATLAB.\n    trialinfo_column : int\n        Column of the trialinfo matrix to use for the event codes.\n\n    Returns\n    -------\n    epochs : instance of EpochsArray\n        An EpochsArray containing the loaded data.\n    \"\"\"\n    read_mat = _import_pymatreader_funcs(\"FieldTrip I/O\")\n    ft_struct = read_mat(fname, ignore_fields=[\"previous\"], variable_names=[data_name])\n\n    # load data and set ft_struct to the heading dictionary\n    ft_struct = ft_struct[data_name]\n\n    _validate_ft_struct(ft_struct)\n\n    info = _create_info(ft_struct, info)  # create info structure\n    data = np.array(ft_struct[\"trial\"])  # create the epochs data array\n    events = _create_events(ft_struct, trialinfo_column)\n    if events is not None:\n        metadata = _create_event_metadata(ft_struct)\n    else:\n        metadata = None\n    tmin = _set_tmin(ft_struct)  # create start time\n\n    epochs = EpochsArray(\n        data=data, info=info, tmin=tmin, events=events, metadata=metadata, proj=False\n    )\n    return epochs", "metadata": {}}
{"_id": "mne_mne_io/fieldtrip/fieldtrip.py_read_evoked_fieldtrip_code", "title": "read_evoked_fieldtrip", "text": "def read_evoked_fieldtrip(fname, info, comment=None, data_name=\"data\"):\n    \"\"\"Load evoked data from a FieldTrip timelocked structure.\n\n    This function expects to find timelocked data in the structure data_name is\n    pointing at.\n\n    .. warning:: FieldTrip does not normally store the original information\n                 concerning channel location, orientation, type etc. It is\n                 therefore **highly recommended** to provide the info field.\n                 This can be obtained by reading the original raw data file\n                 with MNE functions (without preload). The returned object\n                 contains the necessary info field.\n\n    Parameters\n    ----------\n    fname : path-like\n        Path and filename of the ``.mat`` file containing the data.\n    info : dict or None\n        The info dict of the raw data file corresponding to the data to import.\n        If this is set to None, limited information is extracted from the\n        FieldTrip structure.\n    comment : str\n        Comment on dataset. Can be the condition.\n    data_name : str\n        Name of heading dict/ variable name under which the data was originally\n        saved in MATLAB.\n\n    Returns\n    -------\n    evoked : instance of EvokedArray\n        An EvokedArray containing the loaded data.\n    \"\"\"\n    read_mat = _import_pymatreader_funcs(\"FieldTrip I/O\")\n    ft_struct = read_mat(fname, ignore_fields=[\"previous\"], variable_names=[data_name])\n    ft_struct = ft_struct[data_name]\n\n    _validate_ft_struct(ft_struct)\n\n    info = _create_info(ft_struct, info)  # create info structure\n    data_evoked = ft_struct[\"avg\"]  # create evoked data\n\n    evoked = EvokedArray(data_evoked, info, comment=comment)\n    return evoked", "metadata": {}}
{"_id": "mne_mne_io/boxy/boxy.py_read_raw_boxy_code", "title": "read_raw_boxy", "text": "def read_raw_boxy(fname, preload=False, verbose=None) -> \"RawBOXY\":\n    \"\"\"Reader for an optical imaging recording.\n\n    This function has been tested using the ISS Imagent I and II systems\n    and versions 0.40/0.84 of the BOXY recording software.\n\n    Parameters\n    ----------\n    fname : path-like\n        Path to the BOXY data file.\n    %(preload)s\n    %(verbose)s\n\n    Returns\n    -------\n    raw : instance of RawBOXY\n        A Raw object containing BOXY data.\n        See :class:`mne.io.Raw` for documentation of attributes and methods.\n\n    See Also\n    --------\n    mne.io.Raw : Documentation of attributes and methods of RawBOXY.\n    \"\"\"\n    return RawBOXY(fname, preload, verbose)", "metadata": {}}
{"_id": "mne_mne_io/nedf/nedf.py_read_raw_nedf_code", "title": "read_raw_nedf", "text": "def read_raw_nedf(filename, preload=False, verbose=None) -> RawNedf:\n    \"\"\"Read NeuroElectrics .nedf files.\n\n    NEDF file versions starting from 1.3 are supported.\n\n    Parameters\n    ----------\n    filename : path-like\n        Path to the ``.nedf`` file.\n    %(preload)s\n    %(verbose)s\n\n    Returns\n    -------\n    raw : instance of RawNedf\n        A Raw object containing NEDF data.\n        See :class:`mne.io.Raw` for documentation of attributes and methods.\n\n    See Also\n    --------\n    mne.io.Raw : Documentation of attributes and methods of RawNedf.\n    \"\"\"\n    return RawNedf(filename, preload, verbose)", "metadata": {}}
{"_id": "mne_mne_io/curry/curry.py_read_raw_curry_code", "title": "read_raw_curry", "text": "def read_raw_curry(fname, preload=False, verbose=None) -> \"RawCurry\":\n    \"\"\"Read raw data from Curry files.\n\n    Parameters\n    ----------\n    fname : path-like\n        Path to a curry file with extensions ``.dat``, ``.dap``, ``.rs3``,\n        ``.cdt``, ``.cdt.dpa``, ``.cdt.cef`` or ``.cef``.\n    %(preload)s\n    %(verbose)s\n\n    Returns\n    -------\n    raw : instance of RawCurry\n        A Raw object containing Curry data.\n        See :class:`mne.io.Raw` for documentation of attributes and methods.\n\n    See Also\n    --------\n    mne.io.Raw : Documentation of attributes and methods of RawCurry.\n    \"\"\"\n    return RawCurry(fname, preload, verbose)", "metadata": {}}
{"_id": "mne_mne_io/edf/edf.py_read_raw_edf_code", "title": "read_raw_edf", "text": "def read_raw_edf(\n    input_fname,\n    eog=None,\n    misc=None,\n    stim_channel=\"auto\",\n    exclude=(),\n    infer_types=False,\n    include=None,\n    preload=False,\n    units=None,\n    encoding=\"utf8\",\n    exclude_after_unique=False,\n    *,\n    verbose=None,\n) -> RawEDF:\n    \"\"\"Reader function for EDF and EDF+ files.\n\n    Parameters\n    ----------\n    input_fname : path-like\n        Path to the EDF or EDF+ file.\n    eog : list or tuple\n        Names of channels or list of indices that should be designated EOG\n        channels. Values should correspond to the electrodes in the file.\n        Default is None.\n    misc : list or tuple\n        Names of channels or list of indices that should be designated MISC\n        channels. Values should correspond to the electrodes in the file.\n        Default is None.\n    stim_channel : ``'auto'`` | str | list of str | int | list of int\n        Defaults to ``'auto'``, which means that channels named ``'status'`` or\n        ``'trigger'`` (case insensitive) are set to STIM. If str (or list of\n        str), all channels matching the name(s) are set to STIM. If int (or\n        list of ints), channels corresponding to the indices are set to STIM.\n    exclude : list of str | str\n        Channel names to exclude. This can help when reading data with\n        different sampling rates to avoid unnecessary resampling. A str is\n        interpreted as a regular expression.\n    infer_types : bool\n        If True, try to infer channel types from channel labels. If a channel\n        label starts with a known type (such as 'EEG') followed by a space and\n        a name (such as 'Fp1'), the channel type will be set accordingly, and\n        the channel will be renamed to the original label without the prefix.\n        For unknown prefixes, the type will be 'EEG' and the name will not be\n        modified. If False, do not infer types and assume all channels are of\n        type 'EEG'.\n\n        .. versionadded:: 0.24.1\n    include : list of str | str\n        Channel names to be included. A str is interpreted as a regular\n        expression. 'exclude' must be empty if include is assigned.\n\n        .. versionadded:: 1.1\n    %(preload)s\n    %(units_edf_bdf_io)s\n    %(encoding_edf)s\n    %(exclude_after_unique)s\n    %(verbose)s\n\n    Returns\n    -------\n    raw : instance of RawEDF\n        The raw instance.\n        See :class:`mne.io.Raw` for documentation of attributes and methods.\n\n    See Also\n    --------\n    mne.io.read_raw_bdf : Reader function for BDF files.\n    mne.io.read_raw_gdf : Reader function for GDF files.\n    mne.export.export_raw : Export function for EDF files.\n    mne.io.Raw : Documentation of attributes and methods of RawEDF.\n\n    Notes\n    -----\n    %(edf_resamp_note)s\n\n    It is worth noting that in some special cases, it may be necessary to shift\n    event values in order to retrieve correct event triggers. This depends on\n    the triggering device used to perform the synchronization. For instance, in\n    some files events need to be shifted by 8 bits:\n\n        >>> events[:, 2] >>= 8  # doctest:+SKIP\n\n    TAL channels called 'EDF Annotations' are parsed and extracted annotations\n    are stored in raw.annotations. Use :func:`mne.events_from_annotations` to\n    obtain events from these annotations.\n\n    If channels named 'status' or 'trigger' are present, they are considered as\n    STIM channels by default. Use func:`mne.find_events` to parse events\n    encoded in such analog stim channels.\n\n    The EDF specification allows optional storage of channel types in the\n    prefix of the signal label for each channel. For example, ``EEG Fz``\n    implies that ``Fz`` is an EEG channel and ``MISC E`` would imply ``E`` is\n    a MISC channel. However, there is no standard way of specifying all\n    channel types. MNE-Python will try to infer the channel type, when such a\n    string exists, defaulting to EEG, when there is no prefix or the prefix is\n    not recognized.\n\n    The following prefix strings are mapped to MNE internal types:\n\n        - 'EEG': 'eeg'\n        - 'SEEG': 'seeg'\n        - 'ECOG': 'ecog'\n        - 'DBS': 'dbs'\n        - 'EOG': 'eog'\n        - 'ECG': 'ecg'\n        - 'EMG': 'emg'\n        - 'BIO': 'bio'\n        - 'RESP': 'resp'\n        - 'MISC': 'misc'\n        - 'SAO2': 'bio'\n\n    The EDF specification allows storage of subseconds in measurement date.\n    However, this reader currently sets subseconds to 0 by default.\n    \"\"\"\n    input_fname = os.path.abspath(input_fname)\n    ext = os.path.splitext(input_fname)[1][1:].lower()\n    if ext != \"edf\":\n        raise NotImplementedError(f\"Only EDF files are supported, got {ext}.\")\n    return RawEDF(\n        input_fname=input_fname,\n        eog=eog,\n        misc=misc,\n        stim_channel=stim_channel,\n        exclude=exclude,\n        infer_types=infer_types,\n        preload=preload,\n        include=include,\n        units=units,\n        encoding=encoding,\n        exclude_after_unique=exclude_after_unique,\n        verbose=verbose,\n    )", "metadata": {}}
{"_id": "mne_mne_io/edf/edf.py_read_raw_bdf_code", "title": "read_raw_bdf", "text": "def read_raw_bdf(\n    input_fname,\n    eog=None,\n    misc=None,\n    stim_channel=\"auto\",\n    exclude=(),\n    infer_types=False,\n    include=None,\n    preload=False,\n    units=None,\n    encoding=\"utf8\",\n    exclude_after_unique=False,\n    *,\n    verbose=None,\n) -> RawEDF:\n    \"\"\"Reader function for BDF files.\n\n    Parameters\n    ----------\n    input_fname : path-like\n        Path to the BDF file.\n    eog : list or tuple\n        Names of channels or list of indices that should be designated EOG\n        channels. Values should correspond to the electrodes in the file.\n        Default is None.\n    misc : list or tuple\n        Names of channels or list of indices that should be designated MISC\n        channels. Values should correspond to the electrodes in the file.\n        Default is None.\n    stim_channel : ``'auto'`` | str | list of str | int | list of int\n        Defaults to ``'auto'``, which means that channels named ``'status'`` or\n        ``'trigger'`` (case insensitive) are set to STIM. If str (or list of\n        str), all channels matching the name(s) are set to STIM. If int (or\n        list of ints), channels corresponding to the indices are set to STIM.\n    exclude : list of str | str\n        Channel names to exclude. This can help when reading data with\n        different sampling rates to avoid unnecessary resampling. A str is\n        interpreted as a regular expression.\n    infer_types : bool\n        If True, try to infer channel types from channel labels. If a channel\n        label starts with a known type (such as 'EEG') followed by a space and\n        a name (such as 'Fp1'), the channel type will be set accordingly, and\n        the channel will be renamed to the original label without the prefix.\n        For unknown prefixes, the type will be 'EEG' and the name will not be\n        modified. If False, do not infer types and assume all channels are of\n        type 'EEG'.\n\n        .. versionadded:: 0.24.1\n    include : list of str | str\n        Channel names to be included. A str is interpreted as a regular\n        expression. 'exclude' must be empty if include is assigned.\n\n        .. versionadded:: 1.1\n    %(preload)s\n    %(units_edf_bdf_io)s\n    %(encoding_edf)s\n    %(exclude_after_unique)s\n    %(verbose)s\n\n    Returns\n    -------\n    raw : instance of RawEDF\n        The raw instance.\n        See :class:`mne.io.Raw` for documentation of attributes and methods.\n\n    See Also\n    --------\n    mne.io.read_raw_edf : Reader function for EDF and EDF+ files.\n    mne.io.read_raw_gdf : Reader function for GDF files.\n    mne.io.Raw : Documentation of attributes and methods of RawEDF.\n\n    Notes\n    -----\n    :class:`mne.io.Raw` only stores signals with matching sampling frequencies.\n    Therefore, if mixed sampling frequency signals are requested, all signals\n    are upsampled to the highest loaded sampling frequency. In this case, using\n    preload=True is recommended, as otherwise, edge artifacts appear when\n    slices of the signal are requested.\n\n    Biosemi devices trigger codes are encoded in 16-bit format, whereas system\n    codes (CMS in/out-of range, battery low, etc.) are coded in bits 16-23 of\n    the status channel (see http://www.biosemi.com/faq/trigger_signals.htm).\n    To retrieve correct event values (bits 1-16), one could do:\n\n        >>> events = mne.find_events(...)  # doctest:+SKIP\n        >>> events[:, 2] &= (2**16 - 1)  # doctest:+SKIP\n\n    The above operation can be carried out directly in :func:`mne.find_events`\n    using the ``mask`` and ``mask_type`` parameters (see\n    :func:`mne.find_events` for more details).\n\n    It is also possible to retrieve system codes, but no particular effort has\n    been made to decode these in MNE. In case it is necessary, for instance to\n    check the CMS bit, the following operation can be carried out:\n\n        >>> cms_bit = 20  # doctest:+SKIP\n        >>> cms_high = (events[:, 2] & (1 << cms_bit)) != 0  # doctest:+SKIP\n\n    It is worth noting that in some special cases, it may be necessary to shift\n    event values in order to retrieve correct event triggers. This depends on\n    the triggering device used to perform the synchronization. For instance, in\n    some files events need to be shifted by 8 bits:\n\n        >>> events[:, 2] >>= 8  # doctest:+SKIP\n\n    TAL channels called 'BDF Annotations' are parsed and extracted annotations\n    are stored in raw.annotations. Use :func:`mne.events_from_annotations` to\n    obtain events from these annotations.\n\n    If channels named 'status' or 'trigger' are present, they are considered as\n    STIM channels by default. Use func:`mne.find_events` to parse events\n    encoded in such analog stim channels.\n    \"\"\"\n    input_fname = os.path.abspath(input_fname)\n    ext = os.path.splitext(input_fname)[1][1:].lower()\n    if ext != \"bdf\":\n        raise NotImplementedError(f\"Only BDF files are supported, got {ext}.\")\n    return RawEDF(\n        input_fname=input_fname,\n        eog=eog,\n        misc=misc,\n        stim_channel=stim_channel,\n        exclude=exclude,\n        infer_types=infer_types,\n        preload=preload,\n        include=include,\n        units=units,\n        encoding=encoding,\n        exclude_after_unique=exclude_after_unique,\n        verbose=verbose,\n    )", "metadata": {}}
{"_id": "mne_mne_io/edf/edf.py_read_raw_gdf_code", "title": "read_raw_gdf", "text": "def read_raw_gdf(\n    input_fname,\n    eog=None,\n    misc=None,\n    stim_channel=\"auto\",\n    exclude=(),\n    include=None,\n    preload=False,\n    verbose=None,\n) -> RawGDF:\n    \"\"\"Reader function for GDF files.\n\n    Parameters\n    ----------\n    input_fname : path-like\n        Path to the GDF file.\n    eog : list or tuple\n        Names of channels or list of indices that should be designated EOG\n        channels. Values should correspond to the electrodes in the file.\n        Default is None.\n    misc : list or tuple\n        Names of channels or list of indices that should be designated MISC\n        channels. Values should correspond to the electrodes in the file.\n        Default is None.\n    stim_channel : ``'auto'`` | str | list of str | int | list of int\n        Defaults to ``'auto'``, which means that channels named ``'status'`` or\n        ``'trigger'`` (case insensitive) are set to STIM. If str (or list of\n        str), all channels matching the name(s) are set to STIM. If int (or\n        list of ints), channels corresponding to the indices are set to STIM.\n    exclude : list of str | str\n        Channel names to exclude. This can help when reading data with\n        different sampling rates to avoid unnecessary resampling. A str is\n        interpreted as a regular expression.\n    include : list of str | str\n        Channel names to be included. A str is interpreted as a regular\n        expression. 'exclude' must be empty if include is assigned.\n    %(preload)s\n    %(verbose)s\n\n    Returns\n    -------\n    raw : instance of RawGDF\n        The raw instance.\n        See :class:`mne.io.Raw` for documentation of attributes and methods.\n\n    See Also\n    --------\n    mne.io.read_raw_edf : Reader function for EDF and EDF+ files.\n    mne.io.read_raw_bdf : Reader function for BDF files.\n    mne.io.Raw : Documentation of attributes and methods of RawGDF.\n\n    Notes\n    -----\n    If channels named 'status' or 'trigger' are present, they are considered as\n    STIM channels by default. Use func:`mne.find_events` to parse events\n    encoded in such analog stim channels.\n    \"\"\"\n    input_fname = os.path.abspath(input_fname)\n    ext = os.path.splitext(input_fname)[1][1:].lower()\n    if ext != \"gdf\":\n        raise NotImplementedError(f\"Only GDF files are supported, got {ext}.\")\n    return RawGDF(\n        input_fname=input_fname,\n        eog=eog,\n        misc=misc,\n        stim_channel=stim_channel,\n        exclude=exclude,\n        preload=preload,\n        include=include,\n        verbose=verbose,\n    )", "metadata": {}}
{"_id": "mne_mne_report/report.py_open_report_code", "title": "open_report", "text": "def open_report(fname, **params):\n    \"\"\"Read a saved report or, if it doesn't exist yet, create a new one.\n\n    The returned report can be used as a context manager, in which case any\n    changes to the report are saved when exiting the context block.\n\n    Parameters\n    ----------\n    fname : path-like\n        The file containing the report, stored in the HDF5 format. If the file\n        does not exist yet, a new report is created that will be saved to the\n        specified file.\n    **params : kwargs\n        When creating a new report, any named parameters other than ``fname``\n        are passed to the ``__init__`` function of the `Report` object. When\n        reading an existing report, the parameters are checked with the\n        loaded report and an exception is raised when they don't match.\n\n    Returns\n    -------\n    report : instance of Report\n        The report.\n    \"\"\"\n    fname = str(_check_fname(fname=fname, overwrite=\"read\", must_exist=False))\n    if op.exists(fname):\n        # Check **params with the loaded report\n        read_hdf5, _ = _import_h5io_funcs()\n        state = read_hdf5(fname, title=\"mnepython\")\n        for param in params:\n            if param not in state:\n                if param in _backward_compat_map:\n                    state[param] = _backward_compat_map[param]\n                else:\n                    raise ValueError(f\"The loaded report has no attribute {param}\")\n            if params[param] != state[param]:\n                raise ValueError(\n                    f\"Attribute '{param}' of loaded report ({params[param]}) does not \"\n                    f\"match the given parameter ({state[param]}).\"\n                )\n        report = Report()\n        report.__setstate__(state)\n    else:\n        report = Report(**params)\n    # Keep track of the filename in case the Report object is used as a context\n    # manager.\n    report.fname = fname\n    return report", "metadata": {}}
{"_id": "mne_mne_report/report.py_copy_code", "title": "copy", "text": "def copy(self):\n        \"\"\"Return a deepcopy of the report.\n\n        Returns\n        -------\n        report : instance of Report\n            The copied report.\n        \"\"\"\n        return copy.deepcopy(self)", "metadata": {}}
{"_id": "mne_mne_report/report.py_get_contents_code", "title": "get_contents", "text": "def get_contents(self):\n        \"\"\"Get the content of the report.\n\n        Returns\n        -------\n        titles : list of str\n            The title of each content element.\n        tags : list of list of str\n            The tags for each content element, one list per element.\n        htmls : list of str\n            The HTML contents for each element.\n\n        Notes\n        -----\n        .. versionadded:: 1.7\n        \"\"\"\n        htmls, _, titles, tags = self._content_as_html()\n        return titles, tags, htmls", "metadata": {}}
{"_id": "mne_mne_report/report.py_reorder_code", "title": "reorder", "text": "def reorder(self, order):\n        \"\"\"Reorder the report content.\n\n        Parameters\n        ----------\n        order : array-like of int\n            The indices of the new order (as if you were reordering an array).\n            For example if there are 4 elements in the report,\n            ``order=[3, 0, 1, 2]`` would take the last element and move it to\n            the front. In other words, ``elements = [elements[ii] for ii in order]]``.\n\n        Notes\n        -----\n        .. versionadded:: 1.7\n        \"\"\"\n        _validate_type(order, \"array-like\", \"order\")\n        order = np.array(order)\n        if order.dtype.kind != \"i\" or order.ndim != 1:\n            raise ValueError(\n                \"order must be an array of integers, got \"\n                f\"{order.ndim}D array of dtype {order.dtype}\"\n            )\n        n_elements = len(self._content)\n        if not np.array_equal(np.sort(order), np.arange(n_elements)):\n            raise ValueError(\n                f\"order must be a permutation of range({n_elements}), got:\\n{order}\"\n            )\n        self._content = [self._content[ii] for ii in order]", "metadata": {}}
{"_id": "mne_mne_report/report.py_html_code", "title": "html", "text": "def html(self):\n        \"\"\"A list of HTML representations for all content elements.\"\"\"\n        return self._content_as_html()[0]", "metadata": {}}
{"_id": "mne_mne_report/report.py_tags_code", "title": "tags", "text": "def tags(self):\n        \"\"\"A sorted tuple of all tags currently used in the report.\"\"\"\n        return tuple(sorted(set(sum(self._content_as_html()[3], ()))))", "metadata": {}}
{"_id": "mne_mne_report/report.py_add_custom_css_code", "title": "add_custom_css", "text": "def add_custom_css(self, css):\n        \"\"\"Add custom CSS to the report.\n\n        Parameters\n        ----------\n        css : str\n            Style definitions to add to the report. The content of this string\n            will be embedded between HTML ``<style>`` and ``</style>`` tags.\n\n        Notes\n        -----\n        .. versionadded:: 0.23\n        \"\"\"\n        style = f'\\n<style type=\"text/css\">\\n{css}\\n</style>'\n        self.include += style", "metadata": {}}
{"_id": "mne_mne_report/report.py_add_custom_js_code", "title": "add_custom_js", "text": "def add_custom_js(self, js):\n        \"\"\"Add custom JavaScript to the report.\n\n        Parameters\n        ----------\n        js : str\n            JavaScript code to add to the report. The content of this string\n            will be embedded between HTML ``<script>`` and ``</script>`` tags.\n\n        Notes\n        -----\n        .. versionadded:: 0.23\n        \"\"\"\n        script = f'\\n<script type=\"text/javascript\">\\n{js}\\n</script>'\n        self.include += script", "metadata": {}}
{"_id": "mne_mne_report/report.py_add_epochs_code", "title": "add_epochs", "text": "def add_epochs(\n        self,\n        epochs,\n        title,\n        *,\n        psd=True,\n        projs=None,\n        image_kwargs=None,\n        topomap_kwargs=None,\n        drop_log_ignore=(\"IGNORED\",),\n        tags=(\"epochs\",),\n        replace=False,\n    ):\n        \"\"\"Add `~mne.Epochs` to the report.\n\n        Parameters\n        ----------\n        epochs : path-like | instance of Epochs\n            The epochs to add to the report.\n        title : str\n            The title to add.\n        psd : bool | float\n            If a float, the duration of data to use for creation of PSD plots,\n            in seconds. PSD will be calculated on as many epochs as required to\n            cover at least this duration. Epochs will be picked across the\n            entire time range in equally-spaced distance.\n\n            .. note::\n              In rare edge cases, we may not be able to create a grid of\n              equally-spaced epochs that cover the entire requested time range.\n              In these situations, a warning will be emitted, informing you\n              about the duration that's actually being used.\n\n            If ``True``, add PSD plots based on all ``epochs``. If ``False``,\n            do not add PSD plots.\n        %(projs_report)s\n        image_kwargs : dict | None\n            Keyword arguments to pass to the \"epochs image\"-generating\n            function (:meth:`mne.Epochs.plot_image`).\n            Keys are channel types, values are dicts containing kwargs to pass.\n            For example, to use the rejection limits per channel type you could pass::\n\n                image_kwargs=dict(\n                    grad=dict(vmin=-reject['grad'], vmax=-reject['grad']),\n                    mag=dict(vmin=-reject['mag'], vmax=reject['mag']),\n                )\n\n            .. versionadded:: 1.7\n        %(topomap_kwargs)s\n        drop_log_ignore : array-like of str\n            The drop reasons to ignore when creating the drop log bar plot.\n            All epochs for which a drop reason listed here appears in\n            ``epochs.drop_log`` will be excluded from the drop log plot.\n        %(tags_report)s\n        %(replace_report)s\n\n        Notes\n        -----\n        .. versionadded:: 0.24\n        \"\"\"\n        tags = _check_tags(tags)\n        add_projs = self.projs if projs is None else projs\n        self._add_epochs(\n            epochs=epochs,\n            psd=psd,\n            add_projs=add_projs,\n            image_kwargs=image_kwargs,\n            topomap_kwargs=topomap_kwargs,\n            drop_log_ignore=drop_log_ignore,\n            section=title,\n            tags=tags,\n            image_format=self.image_format,\n            replace=replace,\n        )", "metadata": {}}
{"_id": "mne_mne_report/report.py_add_evokeds_code", "title": "add_evokeds", "text": "def add_evokeds(\n        self,\n        evokeds,\n        *,\n        titles=None,\n        noise_cov=None,\n        projs=None,\n        n_time_points=None,\n        tags=(\"evoked\",),\n        replace=False,\n        topomap_kwargs=None,\n        n_jobs=None,\n    ):\n        \"\"\"Add `~mne.Evoked` objects to the report.\n\n        Parameters\n        ----------\n        evokeds : path-like | instance of Evoked | list of Evoked\n            The evoked data to add to the report. Multiple `~mne.Evoked`\n            objects \u2013 as returned from `mne.read_evokeds` \u2013 can be passed as\n            a list.\n        titles : str | list of str | None\n            The titles corresponding to the evoked data. If ``None``, the\n            content of ``evoked.comment`` from each evoked will be used as\n            title.\n        noise_cov : path-like | instance of Covariance | None\n            A noise covariance matrix. If provided, will be used to whiten\n            the ``evokeds``. If ``None``, will fall back to the ``cov_fname``\n            provided upon report creation.\n        %(projs_report)s\n        n_time_points : int | None\n            The number of equidistant time points to render. If ``None``,\n            will render each `~mne.Evoked` at 21 time points, unless the data\n            contains fewer time points, in which case all will be rendered.\n        %(tags_report)s\n        %(replace_report)s\n        %(topomap_kwargs)s\n        %(n_jobs)s\n\n        Notes\n        -----\n        .. versionadded:: 0.24.0\n        \"\"\"\n        if isinstance(evokeds, Evoked):\n            evokeds = [evokeds]\n        elif isinstance(evokeds, list):\n            pass\n        else:\n            evoked_fname = evokeds\n            logger.debug(f\"Evoked: Reading {evoked_fname}\")\n            evokeds = read_evokeds(evoked_fname, verbose=False)\n\n        if self.baseline is not None:\n            evokeds = [e.copy().apply_baseline(self.baseline) for e in evokeds]\n\n        if titles is None:\n            titles = [e.comment for e in evokeds]\n        elif isinstance(titles, str):\n            titles = [titles]\n\n        if len(evokeds) != len(titles):\n            raise ValueError(\n                f\"Number of evoked objects ({len(evokeds)}) must \"\n                f\"match number of captions ({len(titles)})\"\n            )\n\n        if noise_cov is None:\n            noise_cov = self.cov_fname\n        if noise_cov is not None and not isinstance(noise_cov, Covariance):\n            noise_cov = read_cov(fname=noise_cov)\n        tags = _check_tags(tags)\n\n        add_projs = self.projs if projs is None else projs\n\n        for evoked, title in zip(evokeds, titles):\n            self._add_evoked(\n                evoked=evoked,\n                noise_cov=noise_cov,\n                image_format=self.image_format,\n                add_projs=add_projs,\n                n_time_points=n_time_points,\n                tags=tags,\n                section=title,\n                topomap_kwargs=topomap_kwargs,\n                n_jobs=n_jobs,\n                replace=replace,\n            )", "metadata": {}}
{"_id": "mne_mne_report/report.py_add_raw_code", "title": "add_raw", "text": "def add_raw(\n        self,\n        raw,\n        title,\n        *,\n        psd=None,\n        projs=None,\n        butterfly=True,\n        scalings=None,\n        tags=(\"raw\",),\n        replace=False,\n        topomap_kwargs=None,\n    ):\n        \"\"\"Add `~mne.io.Raw` objects to the report.\n\n        Parameters\n        ----------\n        raw : path-like | instance of Raw\n            The data to add to the report.\n        title : str\n            The title corresponding to the ``raw`` object.\n        psd : bool | None\n            Whether to add PSD plots. Overrides the ``raw_psd`` parameter\n            passed when initializing the `~mne.Report`. If ``None``, use\n            ``raw_psd`` from `~mne.Report` creation.\n        %(projs_report)s\n        butterfly : bool | int\n            Whether to add butterfly plots of the data. Can be useful to\n            spot problematic channels. If ``True``, 10 equally-spaced 1-second\n            segments will be plotted. If an integer, specifies the number of\n            1-second segments to plot. Larger numbers may take a considerable\n            amount of time if the data contains many sensors. You can disable\n            butterfly plots altogether by passing ``False``.\n        %(scalings)s\n        %(tags_report)s\n        %(replace_report)s\n        %(topomap_kwargs)s\n\n        Notes\n        -----\n        .. versionadded:: 0.24.0\n        \"\"\"\n        tags = _check_tags(tags)\n\n        if psd is None:\n            add_psd = dict() if self.raw_psd is True else self.raw_psd\n        elif psd is True:\n            add_psd = dict()\n        else:\n            add_psd = False\n\n        add_projs = self.projs if projs is None else projs\n\n        self._add_raw(\n            raw=raw,\n            add_psd=add_psd,\n            add_projs=add_projs,\n            butterfly=butterfly,\n            butterfly_scalings=scalings,\n            image_format=self.image_format,\n            tags=tags,\n            topomap_kwargs=topomap_kwargs,\n            section=title,\n            replace=replace,\n        )", "metadata": {}}
{"_id": "mne_mne_report/report.py_add_stc_code", "title": "add_stc", "text": "def add_stc(\n        self,\n        stc,\n        title,\n        *,\n        subject=None,\n        subjects_dir=None,\n        n_time_points=None,\n        tags=(\"source-estimate\",),\n        replace=False,\n        section=None,\n        stc_plot_kwargs=None,\n    ):\n        \"\"\"Add a `~mne.SourceEstimate` (STC) to the report.\n\n        Parameters\n        ----------\n        stc : path-like | instance of SourceEstimate\n            The `~mne.SourceEstimate` to add to the report.\n        title : str\n            The title to add.\n        subject : str | None\n            The name of the FreeSurfer subject the STC belongs to. The name is\n            not stored with the STC data and therefore needs to be specified.\n            If ``None``, will use the value of ``subject`` passed on report\n            creation.\n        subjects_dir : path-like | None\n            The FreeSurfer ``SUBJECTS_DIR``.\n        n_time_points : int | None\n            The number of equidistant time points to render. If ``None``,\n            will render ``stc`` at 51 time points, unless the data\n            contains fewer time points, in which case all will be rendered.\n        %(tags_report)s\n        %(replace_report)s\n        %(section_report)s\n\n            .. versionadded:: 1.9\n        %(stc_plot_kwargs_report)s\n\n        Notes\n        -----\n        .. versionadded:: 0.24.0\n        \"\"\"\n        tags = _check_tags(tags)\n        self._add_stc(\n            stc=stc,\n            title=title,\n            tags=tags,\n            image_format=self.image_format,\n            subject=subject,\n            subjects_dir=subjects_dir,\n            n_time_points=n_time_points,\n            stc_plot_kwargs=stc_plot_kwargs,\n            section=section,\n            replace=replace,\n        )", "metadata": {}}
{"_id": "mne_mne_report/report.py_add_forward_code", "title": "add_forward", "text": "def add_forward(\n        self,\n        forward,\n        title,\n        *,\n        subject=None,\n        subjects_dir=None,\n        tags=(\"forward-solution\",),\n        section=None,\n        replace=False,\n    ):\n        \"\"\"Add a forward solution.\n\n        Parameters\n        ----------\n        forward : instance of Forward | path-like\n            The forward solution to add to the report.\n        title : str\n            The title corresponding to forward solution.\n        subject : str | None\n            The name of the FreeSurfer subject ``forward`` belongs to. If\n            provided, the sensitivity maps of the forward solution will\n            be visualized. If ``None``, will use the value of ``subject``\n            passed on report creation. If supplied, also pass ``subjects_dir``.\n        subjects_dir : path-like | None\n            The FreeSurfer ``SUBJECTS_DIR``.\n        %(tags_report)s\n        %(section_report)s\n\n            .. versionadded:: 1.9\n        %(replace_report)s\n\n        Notes\n        -----\n        .. versionadded:: 0.24.0\n        \"\"\"\n        tags = _check_tags(tags)\n\n        self._add_forward(\n            forward=forward,\n            subject=subject,\n            subjects_dir=subjects_dir,\n            title=title,\n            image_format=self.image_format,\n            section=section,\n            tags=tags,\n            replace=replace,\n        )", "metadata": {}}
{"_id": "mne_mne_report/report.py_add_inverse_operator_code", "title": "add_inverse_operator", "text": "def add_inverse_operator(\n        self,\n        inverse_operator,\n        title,\n        *,\n        subject=None,\n        subjects_dir=None,\n        trans=None,\n        tags=(\"inverse-operator\",),\n        section=None,\n        replace=False,\n    ):\n        \"\"\"Add an inverse operator.\n\n        Parameters\n        ----------\n        inverse_operator : instance of InverseOperator | path-like\n            The inverse operator to add to the report.\n        title : str\n            The title corresponding to the inverse operator object.\n        subject : str | None\n            The name of the FreeSurfer subject ``inverse_op`` belongs to. If\n            provided, the source space the inverse solution is based on will\n            be visualized. If ``None``, will use the value of ``subject``\n            passed on report creation. If supplied, also pass ``subjects_dir``\n            and ``trans``.\n        subjects_dir : path-like | None\n            The FreeSurfer ``SUBJECTS_DIR``.\n        trans : path-like | instance of Transform | None\n            The ``head -> MRI`` transformation for ``subject``.\n        %(tags_report)s\n        %(section_report)s\n\n            .. versionadded:: 1.9\n        %(replace_report)s\n\n        Notes\n        -----\n        .. versionadded:: 0.24.0\n        \"\"\"\n        tags = _check_tags(tags)\n\n        if (subject is not None and trans is None) or (\n            trans is not None and subject is None\n        ):\n            raise ValueError(\"Please pass subject AND trans, or neither.\")\n\n        self._add_inverse_operator(\n            inverse_operator=inverse_operator,\n            subject=subject,\n            subjects_dir=subjects_dir,\n            trans=trans,\n            title=title,\n            image_format=self.image_format,\n            section=section,\n            tags=tags,\n            replace=replace,\n        )", "metadata": {}}
{"_id": "mne_mne_report/report.py_add_trans_code", "title": "add_trans", "text": "def add_trans(\n        self,\n        trans,\n        *,\n        info,\n        title,\n        subject=None,\n        subjects_dir=None,\n        alpha=None,\n        tags=(\"coregistration\",),\n        section=None,\n        coord_frame=\"mri\",\n        replace=False,\n    ):\n        \"\"\"Add a coregistration visualization to the report.\n\n        Parameters\n        ----------\n        %(trans)s \"auto\" will load trans from the FreeSurfer directory\n            specified by ``subject`` and ``subjects_dir`` parameters.\n\n            .. versionchanged:: 1.10\n                Support for 'fsaverage' argument.\n        info : path-like | instance of Info\n            The `~mne.Info` corresponding to ``trans``.\n        title : str\n            The title to add.\n        subject : str | None\n            The name of the FreeSurfer subject the ``trans`` belongs to. The\n            name is not stored with the ``trans`` and therefore needs to be\n            specified. If ``None``, will use the value of ``subject`` passed on\n            report creation.\n        subjects_dir : path-like | None\n            The FreeSurfer ``SUBJECTS_DIR``.\n        alpha : float | None\n            The level of opacity to apply to the head surface. If a float, must\n            be between 0 and 1 (inclusive), where 1 means fully opaque. If\n            ``None``, will use the MNE-Python default value.\n        %(tags_report)s\n        %(section_report)s\n\n            .. versionadded:: 1.9\n        coord_frame : 'auto' | 'head' | 'meg' | 'mri'\n            Coordinate frame used for plotting. See :func:`mne.viz.plot_alignment`.\n        %(replace_report)s\n\n        Notes\n        -----\n        .. versionadded:: 0.24.0\n        \"\"\"\n        tags = _check_tags(tags)\n        self._add_trans(\n            trans=trans,\n            info=info,\n            subject=subject,\n            subjects_dir=subjects_dir,\n            alpha=alpha,\n            title=title,\n            section=section,\n            tags=tags,\n            coord_frame=coord_frame,\n            replace=replace,\n        )", "metadata": {}}
{"_id": "mne_mne_report/report.py_add_covariance_code", "title": "add_covariance", "text": "def add_covariance(self, cov, *, info, title, tags=(\"covariance\",), replace=False):\n        \"\"\"Add covariance to the report.\n\n        Parameters\n        ----------\n        cov : path-like | instance of Covariance\n            The `~mne.Covariance` to add to the report.\n        info : path-like | instance of Info\n            The `~mne.Info` corresponding to ``cov``.\n        title : str\n            The title corresponding to the `~mne.Covariance` object.\n        %(tags_report)s\n        %(replace_report)s\n\n        Notes\n        -----\n        .. versionadded:: 0.24.0\n        \"\"\"\n        tags = _check_tags(tags)\n        self._add_cov(\n            cov=cov,\n            info=info,\n            image_format=self.image_format,\n            section=title,\n            tags=tags,\n            replace=replace,\n        )", "metadata": {}}
{"_id": "mne_mne_report/report.py_add_events_code", "title": "add_events", "text": "def add_events(\n        self,\n        events,\n        title,\n        *,\n        event_id=None,\n        sfreq,\n        first_samp=0,\n        color=None,\n        tags=(\"events\",),\n        section=None,\n        replace=False,\n    ):\n        \"\"\"Add events to the report.\n\n        Parameters\n        ----------\n        events : path-like | array, shape (n_events, 3)\n            An MNE-Python events array.\n        title : str\n            The title corresponding to the events.\n        event_id : dict\n            A dictionary mapping event names (keys) to event codes (values).\n        sfreq : float\n            The sampling frequency used while recording.\n        first_samp : int\n            The first sample point in the recording. This corresponds to\n            ``raw.first_samp`` on files created with Elekta/Neuromag systems.\n        color : dict | None\n            Dictionary of event_id integers as keys and colors as values. This\n            parameter is directly passed to :func:`mne.viz.plot_events`.\n\n            .. versionadded:: 1.8.0\n        %(tags_report)s\n        %(section_report)s\n\n            .. versionadded:: 1.9\n        %(replace_report)s\n\n        Notes\n        -----\n        .. versionadded:: 0.24.0\n        \"\"\"\n        tags = _check_tags(tags)\n        self._add_events(\n            events=events,\n            event_id=event_id,\n            sfreq=sfreq,\n            first_samp=first_samp,\n            color=color,\n            title=title,\n            section=section,\n            image_format=self.image_format,\n            tags=tags,\n            replace=replace,\n        )", "metadata": {}}
{"_id": "mne_mne_report/report.py_add_projs_code", "title": "add_projs", "text": "def add_projs(\n        self,\n        *,\n        info,\n        title,\n        projs=None,\n        topomap_kwargs=None,\n        tags=(\"ssp\",),\n        joint=False,\n        picks_trace=None,\n        section=None,\n        replace=False,\n    ):\n        \"\"\"Render (SSP) projection vectors.\n\n        Parameters\n        ----------\n        info : instance of Info | instance of Evoked | path-like\n            An `~mne.Info` structure or the path of a file containing one.\n        title : str\n            The title corresponding to the :class:`~mne.Projection` object.\n        projs : iterable of mne.Projection | path-like | None\n            The projection vectors to add to the report. Can be the path to a\n            file that will be loaded via `mne.read_proj`. If ``None``, the\n            projectors are taken from ``info['projs']``.\n        %(topomap_kwargs)s\n        %(tags_report)s\n        joint : bool\n            If True (default False), plot the projectors using\n            :func:`mne.viz.plot_projs_joint`, otherwise use\n            :func:`mne.viz.plot_projs_topomap`. If True, then ``info`` must be an\n            instance of :class:`mne.Evoked`.\n\n            .. versionadded:: 1.9\n        %(picks_plot_projs_joint_trace)s\n            Only used when ``joint=True``.\n\n            .. versionadded:: 1.9\n        %(section_report)s\n\n            .. versionadded:: 1.9\n        %(replace_report)s\n\n        Notes\n        -----\n        .. versionadded:: 0.24.0\n        \"\"\"\n        tags = _check_tags(tags)\n        self._add_projs(\n            info=info,\n            projs=projs,\n            title=title,\n            image_format=self.image_format,\n            section=section,\n            tags=tags,\n            topomap_kwargs=topomap_kwargs,\n            replace=replace,\n            joint=joint,\n        )", "metadata": {}}
{"_id": "mne_mne_report/report.py_add_ica_code", "title": "add_ica", "text": "def add_ica(\n        self,\n        ica,\n        title,\n        *,\n        inst,\n        picks=None,\n        ecg_evoked=None,\n        eog_evoked=None,\n        ecg_scores=None,\n        eog_scores=None,\n        n_jobs=None,\n        tags=(\"ica\",),\n        replace=False,\n    ):\n        \"\"\"Add (a fitted) `~mne.preprocessing.ICA` to the report.\n\n        Parameters\n        ----------\n        ica : path-like | instance of mne.preprocessing.ICA\n            The fitted ICA to add.\n        title : str\n            The title to add.\n        inst : path-like | mne.io.Raw | mne.Epochs | None\n            The data to use for visualization of the effects of ICA cleaning.\n            To only plot the ICA component topographies, explicitly pass\n            ``None``.\n        %(picks_ica)s This only affects the behavior of the component\n            topography and properties plots.\n        ecg_evoked, eog_evoked : path-line | mne.Evoked | None\n            Evoked signal based on ECG and EOG epochs, respectively. If passed,\n            will be used to visualize the effects of artifact rejection.\n        ecg_scores, eog_scores : array of float | list of array of float | None\n            The scores produced by :meth:`mne.preprocessing.ICA.find_bads_ecg`\n            and :meth:`mne.preprocessing.ICA.find_bads_eog`, respectively.\n            If passed, will be used to visualize the scoring for each ICA\n            component.\n        %(n_jobs)s\n        %(tags_report)s\n        %(replace_report)s\n\n        Notes\n        -----\n        .. versionadded:: 0.24.0\n        \"\"\"\n        tags = _check_tags(tags)\n        self._add_ica(\n            ica=ica,\n            inst=inst,\n            picks=picks,\n            ecg_evoked=ecg_evoked,\n            eog_evoked=eog_evoked,\n            ecg_scores=ecg_scores,\n            eog_scores=eog_scores,\n            title=title,\n            image_format=self.image_format,\n            tags=tags,\n            section=title,\n            n_jobs=n_jobs,\n            replace=replace,\n        )", "metadata": {}}
{"_id": "mne_mne_report/report.py_remove_code", "title": "remove", "text": "def remove(self, *, title=None, tags=None, remove_all=False):\n        \"\"\"Remove elements from the report.\n\n        The element to remove is searched for by its title. Optionally, tags\n        may be specified as well to narrow down the search to elements that\n        have the supplied tags.\n\n        Parameters\n        ----------\n        title : str\n            The title of the element(s) to remove.\n\n            .. versionadded:: 0.24.0\n        tags : array-like of str | str | None\n             If supplied, restrict the operation to elements with the supplied\n             tags.\n\n            .. versionadded:: 0.24.0\n        remove_all : bool\n            Controls the behavior if multiple elements match the search\n            criteria. If ``False`` (default) only the element last added to the\n            report will be removed. If ``True``, all matches will be removed.\n\n            .. versionadded:: 0.24.0\n\n        Returns\n        -------\n        removed_index : int | tuple of int | None\n            The indices of the elements that were removed, or ``None`` if no\n            element matched the search criteria. A tuple will always be\n            returned if ``remove_all`` was set to ``True`` and at least one\n            element was removed.\n\n            .. versionchanged:: 0.24.0\n               Returns tuple if ``remove_all`` is ``True``.\n        \"\"\"\n        remove_idx = []\n        for idx, element in enumerate(self._content):\n            if element.name == title:\n                if tags is not None and not all(t in element.tags for t in tags):\n                    continue\n                remove_idx.append(idx)\n\n        if not remove_idx:\n            remove_idx = None\n        elif not remove_all:  # only remove last occurrence\n            remove_idx = remove_idx[-1]\n            del self._content[remove_idx]\n        else:  # remove all occurrences\n            remove_idx = tuple(remove_idx)\n            self._content = [\n                e for idx, e in enumerate(self._content) if idx not in remove_idx\n            ]\n\n        return remove_idx", "metadata": {}}
{"_id": "mne_mne_report/report.py_add_code_code", "title": "add_code", "text": "def add_code(\n        self,\n        code,\n        title,\n        *,\n        language=\"python\",\n        tags=(\"code\",),\n        section=None,\n        replace=False,\n    ):\n        \"\"\"Add a code snippet (e.g., an analysis script) to the report.\n\n        Parameters\n        ----------\n        code : str | pathlib.Path\n            The code to add to the report as a string, or the path to a file\n            as a `pathlib.Path` object.\n\n            .. note:: Paths must be passed as `pathlib.Path` object, since\n                      strings will be treated as literal code.\n        title : str\n            The title corresponding to the code.\n        language : str\n            The programming language of ``code``. This will be used for syntax\n            highlighting. Can be ``'auto'`` to try to auto-detect the language.\n        %(tags_report)s\n        %(section_report)s\n\n            .. versionadded:: 1.9\n        %(replace_report)s\n\n        Notes\n        -----\n        .. versionadded:: 0.24.0\n        \"\"\"\n        tags = _check_tags(tags)\n        language = language.lower()\n        self._add_code(\n            code=code,\n            title=title,\n            language=language,\n            section=section,\n            tags=tags,\n            replace=replace,\n        )", "metadata": {}}
{"_id": "mne_mne_report/report.py_add_sys_info_code", "title": "add_sys_info", "text": "def add_sys_info(self, title, *, tags=(\"mne-sysinfo\",), replace=False):\n        \"\"\"Add a MNE-Python system information to the report.\n\n        This is a convenience method that captures the output of\n        `mne.sys_info` and adds it to the report.\n\n        Parameters\n        ----------\n        title : str\n            The title to assign.\n        %(tags_report)s\n        %(replace_report)s\n\n        Notes\n        -----\n        .. versionadded:: 0.24.0\n        \"\"\"\n        tags = _check_tags(tags)\n        with StringIO() as f:\n            sys_info(f)\n            info = f.getvalue()\n        self.add_code(\n            code=info, title=title, language=\"shell\", tags=tags, replace=replace\n        )", "metadata": {}}
{"_id": "mne_mne_report/report.py_add_figure_code", "title": "add_figure", "text": "def add_figure(\n        self,\n        fig,\n        title,\n        *,\n        caption=None,\n        image_format=None,\n        tags=(\"custom-figure\",),\n        section=None,\n        replace=False,\n    ):\n        \"\"\"Add figures to the report.\n\n        Parameters\n        ----------\n        fig : matplotlib.figure.Figure | Figure3D | array | array-like of matplotlib.figure.Figure | array-like of Figure3D | array-like of array\n            One or more figures to add to the report. All figures must be an\n            instance of :class:`matplotlib.figure.Figure`,\n            :class:`mne.viz.Figure3D`, or :class:`numpy.ndarray`. If\n            multiple figures are passed, they will be added as \"slides\"\n            that can be navigated using buttons and a slider element.\n        title : str\n            The title corresponding to the figure(s).\n        caption : str | array-like of str | None\n            The caption(s) to add to the figure(s).\n        %(image_format_report)s\n        %(tags_report)s\n        %(section_report)s\n        %(replace_report)s\n\n        Notes\n        -----\n        .. versionadded:: 0.24.0\n        \"\"\"  # noqa E501\n        tags = _check_tags(tags)\n        if image_format is None:\n            image_format = self.image_format\n\n        if hasattr(fig, \"__len__\") and not isinstance(fig, np.ndarray):\n            figs = tuple(fig)\n        else:\n            figs = (fig,)\n\n        for fig in figs:\n            if _path_like(fig):\n                raise TypeError(\n                    f\"It seems you passed a path to `add_figure`. However, \"\n                    f\"only Matplotlib figures, PyVista scenes, and NumPy \"\n                    f\"arrays are accepted. You may want to try `add_image` \"\n                    f\"instead. The provided path was: {fig}\"\n                )\n        del fig\n\n        if isinstance(caption, str):\n            captions = (caption,)\n        elif caption is None and len(figs) == 1:\n            captions = [None]\n        elif caption is None and len(figs) > 1:\n            captions = [f\"Figure {i + 1}\" for i in range(len(figs))]\n        else:\n            captions = tuple(caption)\n\n        del caption\n\n        assert figs\n        if len(figs) == 1:\n            self._add_figure(\n                title=title,\n                fig=figs[0],\n                caption=captions[0],\n                image_format=image_format,\n                section=section,\n                tags=tags,\n                replace=replace,\n                own_figure=False,\n            )\n        else:\n            self._add_slider(\n                figs=figs,\n                imgs=None,\n                title=title,\n                captions=captions,\n                start_idx=0,\n                image_format=image_format,\n                section=section,\n                tags=tags,\n                own_figure=False,\n                replace=replace,\n            )", "metadata": {}}
{"_id": "mne_mne_report/report.py_add_image_code", "title": "add_image", "text": "def add_image(\n        self,\n        image,\n        title,\n        *,\n        caption=None,\n        tags=(\"custom-image\",),\n        section=None,\n        replace=False,\n    ):\n        \"\"\"Add an image (e.g., PNG or JPEG pictures) to the report.\n\n        Parameters\n        ----------\n        image : path-like\n            The image to add.\n        title : str\n            Title corresponding to the images.\n        caption : str | None\n            If not ``None``, the caption to add to the image.\n        %(tags_report)s\n        %(section_report)s\n        %(replace_report)s\n\n        Notes\n        -----\n        .. versionadded:: 0.24.0\n        \"\"\"\n        tags = _check_tags(tags)\n        image = Path(_check_fname(image, overwrite=\"read\", must_exist=True))\n        img_format = Path(image).suffix.lower()[1:]  # omit leading period\n        _check_option(\n            \"Image format\",\n            value=img_format,\n            allowed_values=list(_ALLOWED_IMAGE_FORMATS) + [\"gif\"],\n        )\n        img_base64 = base64.b64encode(image.read_bytes()).decode(\"ascii\")\n        self._add_image(\n            img=img_base64,\n            title=title,\n            caption=caption,\n            image_format=img_format,\n            tags=tags,\n            section=section,\n            replace=replace,\n        )", "metadata": {}}
{"_id": "mne_mne_report/report.py_add_html_code", "title": "add_html", "text": "def add_html(\n        self, html, title, *, tags=(\"custom-html\",), section=None, replace=False\n    ):\n        \"\"\"Add HTML content to the report.\n\n        Parameters\n        ----------\n        html : str\n            The HTML content to add.\n        title : str\n            The title corresponding to ``html``.\n        %(tags_report)s\n        %(section_report)s\n\n            .. versionadded:: 1.3\n        %(replace_report)s\n\n        Notes\n        -----\n        .. versionadded:: 0.24.0\n        \"\"\"\n        tags = _check_tags(tags)\n        html_partial = partial(\n            _html_element,\n            html=html,\n            title=title,\n            tags=tags,\n            div_klass=\"custom-html\",\n            show=True,\n        )\n        self._add_or_replace(\n            title=title,\n            section=section,\n            tags=tags,\n            html_partial=html_partial,\n            replace=replace,\n        )", "metadata": {}}
{"_id": "mne_mne_report/report.py_add_bem_code", "title": "add_bem", "text": "def add_bem(\n        self,\n        subject,\n        title,\n        *,\n        subjects_dir=None,\n        decim=2,\n        width=512,\n        n_jobs=None,\n        tags=(\"bem\",),\n        section=None,\n        replace=False,\n    ):\n        \"\"\"Render a visualization of the boundary element model (BEM) surfaces.\n\n        Parameters\n        ----------\n        subject : str\n            The FreeSurfer subject name.\n        title : str\n            The title corresponding to the BEM image.\n        %(subjects_dir)s\n        decim : int\n            Use this decimation factor for generating MRI/BEM images\n            (since it can be time consuming).\n        width : int\n            The width of the MRI images (in pixels). Larger values will have\n            clearer surface lines, but will create larger HTML files.\n            Typically a factor of 2 more than the number of MRI voxels along\n            each dimension (typically 512, default) is reasonable.\n        %(n_jobs)s\n        %(tags_report)s\n        %(section_report)s\n\n            .. versionadded:: 1.9\n        %(replace_report)s\n\n        Notes\n        -----\n        .. versionadded:: 0.24.0\n        \"\"\"\n        tags = _check_tags(tags)\n        width = _ensure_int(width, \"width\")\n        self._add_bem(\n            subject=subject,\n            subjects_dir=subjects_dir,\n            decim=decim,\n            n_jobs=n_jobs,\n            width=width,\n            image_format=self.image_format,\n            title=title,\n            tags=tags,\n            section=section,\n            replace=replace,\n        )", "metadata": {}}
{"_id": "mne_mne_report/report.py_parse_folder_code", "title": "parse_folder", "text": "def parse_folder(\n        self,\n        data_path,\n        pattern=None,\n        n_jobs=None,\n        mri_decim=2,\n        sort_content=True,\n        *,\n        on_error=\"warn\",\n        image_format=None,\n        render_bem=True,\n        n_time_points_evokeds=None,\n        n_time_points_stcs=None,\n        raw_butterfly=True,\n        stc_plot_kwargs=None,\n        topomap_kwargs=None,\n        verbose=None,\n    ):\n        r\"\"\"Render all the files in the folder.\n\n        Parameters\n        ----------\n        data_path : path-like\n            Path to the folder containing data whose HTML report will be created.\n        pattern : None | str | list of str\n            Filename global pattern(s) to include in the report.\n            For example, ``['\\*raw.fif', '\\*ave.fif']`` will include\n            :class:`~mne.io.Raw` as well as :class:`~mne.Evoked` files. If ``None``,\n            include all supported file formats.\n\n            .. versionchanged:: 0.23\n               Include supported non-FIFF files by default.\n        %(n_jobs)s\n        mri_decim : int\n            Use this decimation factor for generating MRI/BEM images\n            (since it can be time consuming).\n        sort_content : bool\n            If ``True``, sort the content based on tags in the order:\n            raw -> events -> epochs -> evoked -> covariance -> coregistration\n            -> bem -> forward-solution -> inverse-operator -> source-estimate.\n\n            .. versionadded:: 0.24.0\n        on_error : ``'ignore'`` | ``'warn'`` | ``'raise'``\n            What to do if a file cannot be rendered. Can be ``'ignore'``, ``'warn'``\n            (default), or ``'raise'``.\n        %(image_format_report)s\n\n            .. versionadded:: 0.15\n        render_bem : bool\n            If True (default), try to render the BEM.\n\n            .. versionadded:: 0.16\n        n_time_points_evokeds, n_time_points_stcs : int | None\n            The number of equidistant time points to render for :class:`~mne.Evoked`\n            and :class:`~mne.SourceEstimate` data, respectively. If ``None``,\n            will render each :class:`~mne.Evoked` at 21 and each\n            :class:`~mne.SourceEstimate` at 51 time points, unless the respective data\n            contains fewer time points, in which case all will be rendered.\n\n            .. versionadded:: 0.24.0\n        raw_butterfly : bool\n            Whether to render butterfly plots for (decimated) :class:`~mne.io.Raw` data.\n\n            .. versionadded:: 0.24.0\n        %(stc_plot_kwargs_report)s\n\n            .. versionadded:: 0.24.0\n        %(topomap_kwargs)s\n\n            .. versionadded:: 0.24.0\n        %(verbose)s\n        \"\"\"\n        self.data_path = _check_fname(\n            data_path,\n            overwrite=\"read\",\n            must_exist=True,\n            name=\"data_path\",\n            need_dir=True,\n        )\n        image_format = _check_image_format(self, image_format)\n        _check_option(\"on_error\", on_error, [\"ignore\", \"warn\", \"raise\"])\n\n        if self.title is None:\n            self.title = f\"MNE Report for {self.data_path.name[-20:]}\"\n\n        if pattern is None:\n            pattern = [f\"*{ext}\" for ext in SUPPORTED_READ_RAW_EXTENSIONS]\n        else:\n            if not isinstance(pattern, list | tuple):\n                pattern = [pattern]\n            for elt in pattern:\n                _validate_type(elt, str, \"pattern\")\n\n        # iterate through the possible patterns\n        fnames = list()\n        for p in pattern:\n            for match in self.data_path.rglob(p):\n                if match.name.endswith(VALID_EXTENSIONS):\n                    fnames.append(match)\n\n        if not fnames and not render_bem:\n            raise RuntimeError(f\"No matching files found in {self.data_path}.\")\n\n        fnames_to_remove = []\n        for fname in fnames:\n            # For split files, only keep the first one.\n            if _endswith(fname, (\"raw\", \"sss\", \"meg\")):\n                kwargs = dict(fname=fname, preload=False)\n                if fname.name.endswith((\".fif\", \".fif.gz\")):\n                    kwargs[\"allow_maxshield\"] = \"yes\"\n                inst = read_raw(**kwargs)\n\n                if len(inst.filenames) > 1:\n                    fnames_to_remove.extend(inst.filenames[1:])\n            # For STCs, only keep one hemisphere\n            elif fname.name.endswith(\"-lh.stc\") or fname.name.endswith(\"-rh.stc\"):\n                first_hemi_fname = fname.name\n                if first_hemi_fname.endswidth(\"-lh.stc\"):\n                    second_hemi_fname = first_hemi_fname.replace(\"-lh.stc\", \"-rh.stc\")\n                else:\n                    second_hemi_fname = first_hemi_fname.replace(\"-rh.stc\", \"-lh.stc\")\n\n                if (\n                    fname.parent / second_hemi_fname in fnames\n                    and fname.parent / first_hemi_fname not in fnames_to_remove\n                ):\n                    fnames_to_remove.extend(first_hemi_fname)\n            else:\n                continue\n\n        fnames_to_remove = list(set(fnames_to_remove))  # Drop duplicates\n        for fname in fnames_to_remove:\n            if fname in fnames:\n                del fnames[fnames.index(fname)]\n        del fnames_to_remove\n\n        if self.info_fname is not None:\n            info = read_info(self.info_fname, verbose=False)\n            sfreq = info[\"sfreq\"]\n        else:\n            # only warn if relevant\n            if any(_endswith(fname, \"cov\") for fname in fnames):\n                warn(\"`info_fname` not provided. Cannot render -cov.fif(.gz) files.\")\n            if any(_endswith(fname, \"trans\") for fname in fnames):\n                warn(\"`info_fname` not provided. Cannot render -trans.fif(.gz) files.\")\n            if any(_endswith(fname, \"proj\") for fname in fnames):\n                warn(\"`info_fname` not provided. Cannot render -proj.fif(.gz) files.\")\n            info, sfreq = None, None\n\n        cov = None\n        if self.cov_fname is not None:\n            cov = read_cov(self.cov_fname)\n\n        # render plots in parallel; check that n_jobs <= # of files\n        logger.info(\n            f\"Iterating over {len(fnames)} potential files (this may take some \"\n        )\n        parallel, p_fun, n_jobs = parallel_func(\n            self._iterate_files, n_jobs, max_jobs=len(fnames)\n        )\n        parallel(\n            p_fun(\n                fnames=fname,\n                cov=cov,\n                sfreq=sfreq,\n                raw_butterfly=raw_butterfly,\n                n_time_points_evokeds=n_time_points_evokeds,\n                n_time_points_stcs=n_time_points_stcs,\n                on_error=on_error,\n                stc_plot_kwargs=stc_plot_kwargs,\n                topomap_kwargs=topomap_kwargs,\n            )\n            for fname in np.array_split(fnames, n_jobs)\n        )\n\n        # Render BEM\n        if render_bem:\n            if self.subjects_dir is not None and self.subject is not None:\n                logger.info(\"Rendering BEM\")\n                self.add_bem(\n                    subject=self.subject,\n                    subjects_dir=self.subjects_dir,\n                    title=\"BEM surfaces\",\n                    decim=mri_decim,\n                    n_jobs=n_jobs,\n                )\n            else:\n                warn(\n                    \"`subjects_dir` and `subject` not provided. Cannot \"\n                    \"render MRI and -trans.fif(.gz) files.\"\n                )\n\n        if sort_content:\n            self._sort(order=CONTENT_ORDER)", "metadata": {}}
{"_id": "mne_mne_report/report.py_save_code", "title": "save", "text": "def save(\n        self,\n        fname=None,\n        open_browser=True,\n        overwrite=False,\n        sort_content=False,\n        *,\n        verbose=None,\n    ):\n        \"\"\"Save the report and optionally open it in browser.\n\n        Parameters\n        ----------\n        fname : path-like | None\n            Output filename. If the name ends with ``.h5`` or ``.hdf5``, the\n            report is saved in HDF5 format, so it can later be loaded again\n            with :func:`open_report`. For any other suffix, the report will be\n            saved in HTML format. If ``None`` and :meth:`Report.parse_folder`\n            was **not** called, the report is saved as ``report.html`` in the\n            current working directory. If ``None`` and\n            :meth:`Report.parse_folder` **was** used, the report is saved as\n            ``report.html`` inside the ``data_path`` supplied to\n            :meth:`Report.parse_folder`.\n        open_browser : bool\n            Whether to open the rendered HTML report in the default web browser\n            after saving. This is ignored when writing an HDF5 file.\n        %(overwrite)s\n        sort_content : bool\n            If ``True``, sort the content based on tags before saving in the\n            order:\n            raw -> events -> epochs -> evoked -> covariance -> coregistration\n            -> bem -> forward-solution -> inverse-operator -> source-estimate.\n\n            .. versionadded:: 0.24.0\n        %(verbose)s\n\n        Returns\n        -------\n        fname : str\n            The file name to which the report was saved.\n        \"\"\"\n        if fname is None:\n            if self.data_path is None:\n                self.data_path = os.getcwd()\n                warn(f\"`data_path` not provided. Using {self.data_path} instead\")\n            fname = op.join(self.data_path, \"report.html\")\n\n        fname = str(_check_fname(fname, overwrite=overwrite, name=fname))\n        fname = op.realpath(fname)  # resolve symlinks\n\n        if sort_content:\n            self._sort(order=CONTENT_ORDER)\n\n        if not overwrite and op.isfile(fname):\n            msg = f\"Report already exists at location {fname}. Overwrite it (y/[n])? \"\n            answer = _safe_input(msg, alt=\"pass overwrite=True\")\n            if answer.lower() == \"y\":\n                overwrite = True\n\n        _, ext = op.splitext(fname)\n        is_hdf5 = ext.lower() in [\".h5\", \".hdf5\"]\n\n        if overwrite or not op.isfile(fname):\n            logger.info(f\"Saving report to : {fname}\")\n\n            if is_hdf5:\n                _, write_hdf5 = _import_h5io_funcs()\n                import h5py\n\n                with h5py.File(fname, \"a\") as f:  # Read/write if exists, else create\n                    write_hdf5(f, self.__getstate__(), title=\"mnepython\")\n            else:\n                # Add header, TOC, and footer.\n                header_html = _html_header_element(\n                    title=self.title,\n                    include=self.include,\n                    lang=self.lang,\n                    tags=self.tags,\n                    js=JAVASCRIPT,\n                    css=CSS,\n                    mne_logo_img=mne_logo,\n                )\n\n                # toc_html = _html_toc_element(content_elements=self._content)\n                _, dom_ids, titles, tags = self._content_as_html()\n                toc_html = _html_toc_element(titles=titles, dom_ids=dom_ids, tags=tags)\n\n                with warnings.catch_warnings(record=True):\n                    warnings.simplefilter(\"ignore\")\n                    footer_html = _html_footer_element(\n                        mne_version=MNE_VERSION, date=time.strftime(\"%Y-%m-%d %H:%M:%S\")\n                    )\n\n                html = [header_html, toc_html, *self.html, footer_html]\n                Path(fname).write_text(data=\"\".join(html), encoding=\"utf-8\")\n\n        building_doc = os.getenv(\"_MNE_BUILDING_DOC\", \"\").lower() == \"true\"\n        if open_browser and not is_hdf5 and not building_doc:\n            webbrowser.open_new_tab(\"file://\" + fname)\n\n        if self.fname is None:\n            self.fname = fname\n        return fname", "metadata": {}}
{"_id": "mne_mne_export/_egimff.py_export_evokeds_mff_code", "title": "export_evokeds_mff", "text": "def export_evokeds_mff(fname, evoked, history=None, *, overwrite=False, verbose=None):\n    \"\"\"Export evoked dataset to MFF.\n\n    %(export_warning)s\n\n    Parameters\n    ----------\n    %(fname_export_params)s\n    evoked : list of Evoked instances\n        List of evoked datasets to export to one file. Note that the\n        measurement info from the first evoked instance is used, so be sure\n        that information matches.\n    history : None (default) | list of dict\n        Optional list of history entries (dictionaries) to be written to\n        history.xml. This must adhere to the format described in\n        mffpy.xml_files.History.content. If None, no history.xml will be\n        written.\n    %(overwrite)s\n\n        .. versionadded:: 0.24.1\n    %(verbose)s\n\n    Notes\n    -----\n    .. versionadded:: 0.24\n\n    %(export_warning_note_evoked)s\n\n    Only EEG channels are written to the output file.\n    ``info['device_info']['type']`` must be a valid MFF recording device\n    (e.g. 'HydroCel GSN 256 1.0'). This field is automatically populated when\n    using MFF read functions.\n    \"\"\"\n    mffpy = _import_mffpy(\"Export evokeds to MFF.\")\n\n    info = evoked[0].info\n    if np.round(info[\"sfreq\"]) != info[\"sfreq\"]:\n        raise ValueError(\n            f\"Sampling frequency must be a whole number. sfreq: {info['sfreq']}\"\n        )\n    sampling_rate = int(info[\"sfreq\"])\n\n    # check for unapplied projectors\n    if any(not proj[\"active\"] for proj in evoked[0].info[\"projs\"]):\n        warn(\n            \"Evoked instance has unapplied projectors. Consider applying \"\n            \"them before exporting with evoked.apply_proj().\"\n        )\n\n    # Initialize writer\n    # Future changes: conditions based on version or mffpy requirement if\n    # https://github.com/BEL-Public/mffpy/pull/92 is merged and released.\n    fname = str(_check_fname(fname, overwrite=overwrite))\n    if op.exists(fname):\n        os.remove(fname) if op.isfile(fname) else shutil.rmtree(fname)\n    writer = mffpy.Writer(fname)\n    current_time = datetime.datetime.now(datetime.timezone.utc)\n    writer.addxml(\"fileInfo\", recordTime=current_time)\n    try:\n        device = info[\"device_info\"][\"type\"]\n    except (TypeError, KeyError):\n        raise ValueError(\"No device type. Cannot determine sensor layout.\")\n    writer.add_coordinates_and_sensor_layout(device)\n\n    # Add EEG data\n    eeg_channels = pick_types(info, eeg=True, exclude=[])\n    eeg_bin = mffpy.bin_writer.BinWriter(sampling_rate)\n    for ave in evoked:\n        # Signals are converted to \u00b5V\n        block = (ave.data[eeg_channels] * 1e6).astype(np.float32)\n        eeg_bin.add_block(block, offset_us=0)\n    writer.addbin(eeg_bin)\n\n    # Add categories\n    categories_content = _categories_content_from_evokeds(evoked)\n    writer.addxml(\"categories\", categories=categories_content)\n\n    # Add history\n    if history:\n        writer.addxml(\"historyEntries\", entries=history)\n\n    writer.write()", "metadata": {}}
{"_id": "mne_mne_export/_export.py_export_raw_code", "title": "export_raw", "text": "def export_raw(\n    fname,\n    raw,\n    fmt=\"auto\",\n    physical_range=\"auto\",\n    add_ch_type=False,\n    *,\n    overwrite=False,\n    verbose=None,\n):\n    \"\"\"Export Raw to external formats.\n\n    %(export_fmt_support_raw)s\n\n    %(export_warning)s\n\n    .. warning::\n        When exporting ``Raw`` with annotations, ``raw.info[\"meas_date\"]`` must be the\n        same as ``raw.annotations.orig_time``. This guarantees that the annotations are\n        in the same reference frame as the samples. When\n        :attr:`Raw.first_time <mne.io.Raw.first_time>` is not zero (e.g., after\n        cropping), the onsets are automatically corrected so that onsets are always\n        relative to the first sample.\n\n    Parameters\n    ----------\n    %(fname_export_params)s\n    raw : instance of Raw\n        The raw instance to export.\n    %(export_fmt_params_raw)s\n    %(physical_range_export_params)s\n    %(add_ch_type_export_params)s\n    %(overwrite)s\n\n        .. versionadded:: 0.24.1\n    %(verbose)s\n\n    Notes\n    -----\n    .. versionadded:: 0.24\n\n    %(export_warning_note_raw)s\n    %(export_eeglab_note)s\n    %(export_edf_note)s\n    \"\"\"\n    fname = str(_check_fname(fname, overwrite=overwrite))\n    supported_export_formats = {  # format : (extensions,)\n        \"eeglab\": (\"set\",),\n        \"edf\": (\"edf\",),\n        \"brainvision\": (\n            \"eeg\",\n            \"vmrk\",\n            \"vhdr\",\n        ),\n    }\n    fmt = _infer_check_export_fmt(fmt, fname, supported_export_formats)\n\n    # check for unapplied projectors\n    if any(not proj[\"active\"] for proj in raw.info[\"projs\"]):\n        warn(\n            \"Raw instance has unapplied projectors. Consider applying \"\n            \"them before exporting with raw.apply_proj().\"\n        )\n\n    if fmt == \"eeglab\":\n        from ._eeglab import _export_raw\n\n        _export_raw(fname, raw)\n    elif fmt == \"edf\":\n        from ._edf import _export_raw\n\n        _export_raw(fname, raw, physical_range, add_ch_type)\n    elif fmt == \"brainvision\":\n        from ._brainvision import _export_raw\n\n        _export_raw(fname, raw, overwrite)", "metadata": {}}
{"_id": "mne_mne_export/_export.py_export_epochs_code", "title": "export_epochs", "text": "def export_epochs(fname, epochs, fmt=\"auto\", *, overwrite=False, verbose=None):\n    \"\"\"Export Epochs to external formats.\n\n    %(export_fmt_support_epochs)s\n\n    %(export_warning)s\n\n    Parameters\n    ----------\n    %(fname_export_params)s\n    epochs : instance of Epochs\n        The epochs to export.\n    %(export_fmt_params_epochs)s\n    %(overwrite)s\n\n        .. versionadded:: 0.24.1\n    %(verbose)s\n\n    Notes\n    -----\n    .. versionadded:: 0.24\n\n    %(export_warning_note_epochs)s\n    %(export_eeglab_note)s\n    \"\"\"\n    fname = str(_check_fname(fname, overwrite=overwrite))\n    supported_export_formats = {\n        \"eeglab\": (\"set\",),\n    }\n    fmt = _infer_check_export_fmt(fmt, fname, supported_export_formats)\n\n    # check for unapplied projectors\n    if any(not proj[\"active\"] for proj in epochs.info[\"projs\"]):\n        warn(\n            \"Epochs instance has unapplied projectors. Consider applying \"\n            \"them before exporting with epochs.apply_proj().\"\n        )\n\n    if fmt == \"eeglab\":\n        from ._eeglab import _export_epochs\n\n        _export_epochs(fname, epochs)", "metadata": {}}
{"_id": "mne_mne_export/_export.py_export_evokeds_code", "title": "export_evokeds", "text": "def export_evokeds(fname, evoked, fmt=\"auto\", *, overwrite=False, verbose=None):\n    \"\"\"Export evoked dataset to external formats.\n\n    This function is a wrapper for format-specific export functions. The export\n    function is selected based on the inferred file format. For additional\n    options, use the format-specific functions.\n\n    %(export_fmt_support_evoked)s\n\n    %(export_warning)s\n\n    Parameters\n    ----------\n    %(fname_export_params)s\n    evoked : Evoked instance, or list of Evoked instances\n        The evoked dataset, or list of evoked datasets, to export to one file.\n        Note that the measurement info from the first evoked instance is used,\n        so be sure that information matches.\n    %(export_fmt_params_evoked)s\n    %(overwrite)s\n\n        .. versionadded:: 0.24.1\n    %(verbose)s\n\n    See Also\n    --------\n    mne.write_evokeds\n    mne.export.export_evokeds_mff\n\n    Notes\n    -----\n    .. versionadded:: 0.24\n\n    %(export_warning_note_evoked)s\n    \"\"\"\n    fname = str(_check_fname(fname, overwrite=overwrite))\n    supported_export_formats = {\n        \"mff\": (\"mff\",),\n    }\n    fmt = _infer_check_export_fmt(fmt, fname, supported_export_formats)\n\n    if not isinstance(evoked, list):\n        evoked = [evoked]\n\n    logger.info(f\"Exporting evoked dataset to {fname}...\")\n\n    if fmt == \"mff\":\n        export_evokeds_mff(fname, evoked, overwrite=overwrite)", "metadata": {}}
{"_id": "mne_mne_datasets/_fetch.py_fetch_dataset_code", "title": "fetch_dataset", "text": "def fetch_dataset(\n    dataset_params,\n    processor=None,\n    path=None,\n    force_update=False,\n    update_path=True,\n    download=True,\n    check_version=False,\n    return_version=False,\n    accept=False,\n    auth=None,\n    token=None,\n) -> Path | tuple[Path, str]:\n    \"\"\"Fetch an MNE-compatible dataset using pooch.\n\n    Parameters\n    ----------\n    dataset_params : list of dict | dict\n        The dataset name(s) and corresponding parameters to download the\n        dataset(s). The dataset parameters that contains the following keys:\n        ``archive_name``, ``url``, ``folder_name``, ``hash``,\n        ``config_key`` (optional). See Notes.\n    processor : None | \"unzip\" | \"untar\" | instance of pooch.Unzip | instance of pooch.Untar\n        What to do after downloading the file. ``\"unzip\"`` and ``\"untar\"`` will\n        decompress the downloaded file in place; for custom extraction (e.g.,\n        only extracting certain files from the archive) pass an instance of\n        ``pooch.Unzip`` or ``pooch.Untar``. If ``None`` (the\n        default), the files are left as-is.\n    path : None | str\n        Directory in which to put the dataset. If ``None``, the dataset\n        location is determined by first checking whether\n        ``dataset_params['config_key']`` is defined, and if so, whether that\n        config key exists in the MNE-Python config file. If so, the configured\n        path is used; if not, the location is set to the value of the\n        ``MNE_DATA`` config key (if it exists), or ``~/mne_data`` otherwise.\n    force_update : bool\n        Force update of the dataset even if a local copy exists.\n        Default is False.\n    update_path : bool | None\n        If True (default), set the mne-python config to the given\n        path. If None, the user is prompted.\n    download : bool\n        If False and the dataset has not been downloaded yet, it will not be\n        downloaded and the path will be returned as ``''`` (empty string). This\n        is mostly used for testing purposes and can be safely ignored by most\n        users.\n    check_version : bool\n        Whether to check the version of the dataset or not. Each version\n        of the dataset is stored in the root with a ``version.txt`` file.\n    return_version : bool\n        Whether or not to return the version of the dataset or not.\n        Defaults to False.\n    accept : bool\n        Some MNE-supplied datasets require acceptance of an additional license.\n        Default is ``False``.\n    auth : tuple | None\n        Optional authentication tuple containing the username and\n        password/token, passed to ``pooch.HTTPDownloader`` (e.g.,\n        ``auth=('foo', 012345)``).\n    token : str | None\n        Optional authentication token passed to ``pooch.HTTPDownloader``.\n\n    Returns\n    -------\n    data_path : instance of Path\n        The path to the fetched dataset.\n    version : str\n        Only returned if ``return_version`` is True.\n\n    See Also\n    --------\n    mne.get_config\n    mne.set_config\n    mne.datasets.has_dataset\n\n    Notes\n    -----\n    The ``dataset_params`` argument must contain the following keys:\n\n    - ``archive_name``: The name of the (possibly compressed) file to download\n    - ``url``: URL from which the file can be downloaded\n    - ``folder_name``: the subfolder within the ``MNE_DATA`` folder in which to\n        save and uncompress (if needed) the file(s)\n    - ``hash``: the cryptographic hash type of the file followed by a colon and\n        then the hash value (examples: \"sha256:19uheid...\", \"md5:upodh2io...\")\n    - ``config_key`` (optional): key passed to :func:`mne.set_config` to store\n        the on-disk location of the downloaded dataset (e.g.,\n        ``\"MNE_DATASETS_EEGBCI_PATH\"``). This will only work for the provided\n        datasets listed :ref:`here <datasets>`; do not use for user-defined\n        datasets.\n\n    An example would look like::\n\n        {'dataset_name': 'sample',\n         'archive_name': 'MNE-sample-data-processed.tar.gz',\n         'hash': 'md5:12b75d1cb7df9dfb4ad73ed82f61094f',\n         'url': 'https://osf.io/86qa2/download?version=5',\n         'folder_name': 'MNE-sample-data',\n         'config_key': 'MNE_DATASETS_SAMPLE_PATH'}\n\n    For datasets where a single (possibly compressed) file must be downloaded,\n    pass a single :class:`dict` as ``dataset_params``. For datasets where\n    multiple files must be downloaded and (optionally) uncompressed separately,\n    pass a list of dicts.\n    \"\"\"  # noqa E501\n    import pooch\n\n    t0 = time.time()\n\n    if auth is not None:\n        if len(auth) != 2:\n            raise RuntimeError(\n                \"auth should be a 2-tuple consisting of a username and password/token.\"\n            )\n\n    # processor to uncompress files\n    if processor == \"untar\":\n        processor = pooch.Untar(extract_dir=path)\n    elif processor == \"unzip\":\n        processor = pooch.Unzip(extract_dir=path)\n\n    if isinstance(dataset_params, dict):\n        dataset_params = [dataset_params]\n\n    # extract configuration parameters\n    names = [params[\"dataset_name\"] for params in dataset_params]\n    name = names[0]\n    dataset_dict = dataset_params[0]\n    config_key = dataset_dict.get(\"config_key\", None)\n    folder_name = dataset_dict[\"folder_name\"]\n\n    # get download path for specific dataset\n    path = _get_path(path=path, key=config_key, name=name)\n\n    # get the actual path to each dataset folder name\n    final_path = op.join(path, folder_name)\n\n    # handle BrainStorm datasets with nested folders for datasets\n    if name.startswith(\"bst_\"):\n        final_path = op.join(final_path, name)\n\n    final_path = Path(final_path)\n\n    # additional condition: check for version.txt and parse it\n    # check if testing or misc data is outdated; if so, redownload it\n    want_version = RELEASES.get(name, None)\n    want_version = _FAKE_VERSION if name == \"fake\" else want_version\n\n    # get the version of the dataset and then check if the version is outdated\n    data_version = _dataset_version(final_path, name)\n    outdated = want_version is not None and _compare_version(\n        want_version, \">\", data_version\n    )\n\n    if outdated:\n        logger.info(\n            f\"Dataset {name} version {data_version} out of date, \"\n            f\"latest version is {want_version}\"\n        )\n    empty = Path(\"\")\n\n    # return empty string if outdated dataset and we don't want to download\n    if (not force_update) and outdated and not download:\n        logger.info(\n            \"Dataset out of date but force_update=False and download=False, \"\n            \"returning empty data_path\"\n        )\n        return (empty, data_version) if return_version else empty\n\n    # reasons to bail early (hf_sef has separate code for this):\n    if (not force_update) and (not outdated) and (not name.startswith(\"hf_sef_\")):\n        # ...if target folder exists (otherwise pooch downloads every\n        # time because we don't save the archive files after unpacking, so\n        # pooch can't check its checksum)\n        if op.isdir(final_path):\n            if config_key is not None:\n                _do_path_update(path, update_path, config_key, name)\n            return (final_path, data_version) if return_version else final_path\n        # ...if download=False (useful for debugging)\n        elif not download:\n            return (empty, data_version) if return_version else empty\n        # ...if user didn't accept the license\n        elif name.startswith(\"bst_\"):\n            if accept or \"--accept-brainstorm-license\" in sys.argv:\n                answer = \"y\"\n            else:\n                # If they don't have stdin, just accept the license\n                # https://github.com/mne-tools/mne-python/issues/8513#issuecomment-726823724  # noqa: E501\n                answer = _safe_input(f\"{_bst_license_text}Agree (y/[n])? \", use=\"y\")\n            if answer.lower() != \"y\":\n                raise RuntimeError(\"You must agree to the license to use this dataset\")\n    # downloader & processors\n    download_params = _downloader_params(auth=auth, token=token)\n    if name == \"fake\":\n        download_params[\"progressbar\"] = False\n    downloader = pooch.HTTPDownloader(**download_params)\n\n    # make mappings from archive names to urls and to checksums\n    urls = dict()\n    registry = dict()\n    for idx, this_name in enumerate(names):\n        this_dataset = dataset_params[idx]\n        archive_name = this_dataset[\"archive_name\"]\n        dataset_url = this_dataset[\"url\"]\n        dataset_hash = this_dataset[\"hash\"]\n        urls[archive_name] = dataset_url\n        registry[archive_name] = dataset_hash\n\n    # create the download manager\n    use_path = final_path if processor is None else Path(path)\n    fetcher = pooch.create(\n        path=str(use_path),\n        base_url=\"\",  # Full URLs are given in the `urls` dict.\n        version=None,  # Data versioning is decoupled from MNE-Python version.\n        urls=urls,\n        registry=registry,\n        retry_if_failed=2,  # 2 retries = 3 total attempts\n    )\n\n    # use our logger level for pooch's logger too\n    pooch.get_logger().setLevel(logger.getEffectiveLevel())\n    sz = 0\n\n    for idx in range(len(names)):\n        # fetch and unpack the data\n        archive_name = dataset_params[idx][\"archive_name\"]\n        try:\n            fetcher.fetch(\n                fname=archive_name, downloader=downloader, processor=processor\n            )\n        except ValueError as err:\n            err = str(err)\n            if \"hash of downloaded file\" in str(err):\n                raise ValueError(\n                    f\"{err} Consider using force_update=True to force \"\n                    \"the dataset to be downloaded again.\"\n                ) from None\n            else:\n                raise\n        fname = use_path / archive_name\n        sz += fname.stat().st_size\n        # after unpacking, remove the archive file\n        if processor is not None:\n            fname.unlink()\n\n    # remove version number from \"misc\" and \"testing\" datasets folder names\n    if name == \"misc\":\n        rmtree(final_path, ignore_errors=True)\n        os.replace(op.join(path, MISC_VERSIONED), final_path)\n    elif name == \"testing\":\n        rmtree(final_path, ignore_errors=True)\n        os.replace(op.join(path, TESTING_VERSIONED), final_path)\n\n    # maybe update the config\n    if config_key is not None:\n        old_name = \"brainstorm\" if name.startswith(\"bst_\") else name\n        _do_path_update(path, update_path, config_key, old_name)\n\n    # compare the version of the dataset and mne\n    data_version = _dataset_version(path, name)\n    # 0.7 < 0.7.git should be False, therefore strip\n    if check_version and (\n        _compare_version(data_version, \"<\", mne_version.strip(\".git\"))\n    ):\n        # OK to `nosec` because it's false positive (misidentified as SQL)\n        warn(\n            f\"The {name} dataset (version {data_version}) is older than \"\n            f\"mne-python (version {mne_version}). If the examples fail, \"\n            f\"you may need to update the {name} dataset by using \"\n            f\"mne.datasets.{name}.data_path(force_update=True)\"  # nosec B608\n        )\n    _log_time_size(t0, sz)\n    return (final_path, data_version) if return_version else final_path", "metadata": {}}
{"_id": "mne_mne_datasets/utils.py_default_path_code", "title": "default_path", "text": "def default_path(*, verbose=None):\n    \"\"\"Get the default MNE_DATA path.\n\n    Parameters\n    ----------\n    %(verbose)s\n\n    Returns\n    -------\n    data_path : instance of Path\n        Path to the default MNE_DATA directory.\n    \"\"\"\n    return _get_path(None, None, None)", "metadata": {}}
{"_id": "mne_mne_datasets/utils.py_has_dataset_code", "title": "has_dataset", "text": "def has_dataset(name):\n    \"\"\"Check for presence of a dataset.\n\n    Parameters\n    ----------\n    name : str | dict\n        The dataset to check. Strings refer to one of the supported datasets\n        listed :ref:`here <datasets>`. A :class:`dict` can be used to check for\n        user-defined datasets (see the Notes section of :func:`fetch_dataset`),\n        and must contain keys ``dataset_name``, ``archive_name``, ``url``,\n        ``folder_name``, ``hash``.\n\n    Returns\n    -------\n    has : bool\n        True if the dataset is present.\n    \"\"\"\n    from mne.datasets._fetch import fetch_dataset\n\n    if isinstance(name, dict):\n        dataset_name = name[\"dataset_name\"]\n        dataset_params = name\n    else:\n        dataset_name = \"spm\" if name == \"spm_face\" else name\n        dataset_params = MNE_DATASETS[dataset_name]\n        dataset_params[\"dataset_name\"] = dataset_name\n\n    config_key = dataset_params[\"config_key\"]\n\n    # get download path for specific dataset\n    path = _get_path(path=None, key=config_key, name=dataset_name)\n\n    dp = fetch_dataset(dataset_params, path=path, download=False, check_version=False)\n    if dataset_name.startswith(\"bst_\"):\n        check = dataset_name\n    else:\n        check = MNE_DATASETS[dataset_name][\"folder_name\"]\n    return str(dp).endswith(check)", "metadata": {}}
{"_id": "mne_mne_datasets/utils.py_fetch_aparc_sub_parcellation_code", "title": "fetch_aparc_sub_parcellation", "text": "def fetch_aparc_sub_parcellation(subjects_dir=None, verbose=None):\n    \"\"\"Fetch the modified subdivided aparc parcellation.\n\n    This will download and install the subdivided aparc parcellation\n    :footcite:'KhanEtAl2018' files for\n    FreeSurfer's fsaverage to the specified directory.\n\n    Parameters\n    ----------\n    subjects_dir : path-like | None\n        The subjects directory to use. The file will be placed in\n        ``subjects_dir + '/fsaverage/label'``.\n    %(verbose)s\n\n    References\n    ----------\n    .. footbibliography::\n    \"\"\"\n    import pooch\n\n    subjects_dir = get_subjects_dir(subjects_dir, raise_error=True)\n    destination = subjects_dir / \"fsaverage\" / \"label\"\n    urls = dict(lh=\"https://osf.io/p92yb/download\", rh=\"https://osf.io/4kxny/download\")\n    hashes = dict(\n        lh=\"9e4d8d6b90242b7e4b0145353436ef77\", rh=\"dd6464db8e7762d969fc1d8087cd211b\"\n    )\n    downloader = pooch.HTTPDownloader(**_downloader_params())\n    for hemi in (\"lh\", \"rh\"):\n        fname = f\"{hemi}.aparc_sub.annot\"\n        fpath = destination / fname\n        if not fpath.is_file():\n            pooch.retrieve(\n                url=urls[hemi],\n                known_hash=f\"md5:{hashes[hemi]}\",\n                path=destination,\n                downloader=downloader,\n                fname=fname,\n            )", "metadata": {}}
{"_id": "mne_mne_datasets/utils.py_fetch_hcp_mmp_parcellation_code", "title": "fetch_hcp_mmp_parcellation", "text": "def fetch_hcp_mmp_parcellation(\n    subjects_dir=None, combine=True, *, accept=False, verbose=None\n):\n    \"\"\"Fetch the HCP-MMP parcellation.\n\n    This will download and install the HCP-MMP parcellation\n    :footcite:`GlasserEtAl2016` files for FreeSurfer's fsaverage\n    :footcite:`Mills2016` to the specified directory.\n\n    Parameters\n    ----------\n    subjects_dir : path-like | None\n        The subjects directory to use. The file will be placed in\n        ``subjects_dir + '/fsaverage/label'``.\n    combine : bool\n        If True, also produce the combined/reduced set of 23 labels per\n        hemisphere as ``HCPMMP1_combined.annot``\n        :footcite:`GlasserEtAl2016supp`.\n    %(accept)s\n    %(verbose)s\n\n    Notes\n    -----\n    Use of this parcellation is subject to terms of use on the\n    `HCP-MMP webpage <https://balsa.wustl.edu/WN56>`_.\n\n    References\n    ----------\n    .. footbibliography::\n    \"\"\"\n    import pooch\n\n    subjects_dir = get_subjects_dir(subjects_dir, raise_error=True)\n    destination = subjects_dir / \"fsaverage\" / \"label\"\n    fnames = [destination / f\"{hemi}.HCPMMP1.annot\" for hemi in (\"lh\", \"rh\")]\n    urls = dict(\n        lh=\"https://ndownloader.figshare.com/files/5528816\",\n        rh=\"https://ndownloader.figshare.com/files/5528819\",\n    )\n    hashes = dict(\n        lh=\"46a102b59b2fb1bb4bd62d51bf02e975\", rh=\"75e96b331940227bbcb07c1c791c2463\"\n    )\n    if not all(fname.exists() for fname in fnames):\n        if accept or \"--accept-hcpmmp-license\" in sys.argv:\n            answer = \"y\"\n        else:\n            answer = _safe_input(f\"{_hcp_mmp_license_text}\\nAgree (y/[n])? \")\n        if answer.lower() != \"y\":\n            raise RuntimeError(\"You must agree to the license to use this dataset\")\n    downloader = pooch.HTTPDownloader(**_downloader_params())\n    for hemi, fpath in zip((\"lh\", \"rh\"), fnames):\n        if not op.isfile(fpath):\n            fname = fpath.name\n            pooch.retrieve(\n                url=urls[hemi],\n                known_hash=f\"md5:{hashes[hemi]}\",\n                path=destination,\n                downloader=downloader,\n                fname=fname,\n            )\n\n    if combine:\n        fnames = [\n            op.join(destination, f\"{hemi}.HCPMMP1_combined.annot\")\n            for hemi in (\"lh\", \"rh\")\n        ]\n        if all(op.isfile(fname) for fname in fnames):\n            return\n        # otherwise, let's make them\n        logger.info(\"Creating combined labels\")\n        groups = OrderedDict(\n            [\n                (\"Primary Visual Cortex (V1)\", (\"V1\",)),\n                (\"Early Visual Cortex\", (\"V2\", \"V3\", \"V4\")),\n                (\n                    \"Dorsal Stream Visual Cortex\",\n                    (\"V3A\", \"V3B\", \"V6\", \"V6A\", \"V7\", \"IPS1\"),\n                ),\n                (\n                    \"Ventral Stream Visual Cortex\",\n                    (\"V8\", \"VVC\", \"PIT\", \"FFC\", \"VMV1\", \"VMV2\", \"VMV3\"),\n                ),\n                (\n                    \"MT+ Complex and Neighboring Visual Areas\",\n                    (\"V3CD\", \"LO1\", \"LO2\", \"LO3\", \"V4t\", \"FST\", \"MT\", \"MST\", \"PH\"),\n                ),\n                (\"Somatosensory and Motor Cortex\", (\"4\", \"3a\", \"3b\", \"1\", \"2\")),\n                (\n                    \"Paracentral Lobular and Mid Cingulate Cortex\",\n                    (\n                        \"24dd\",\n                        \"24dv\",\n                        \"6mp\",\n                        \"6ma\",\n                        \"SCEF\",\n                        \"5m\",\n                        \"5L\",\n                        \"5mv\",\n                    ),\n                ),\n                (\"Premotor Cortex\", (\"55b\", \"6d\", \"6a\", \"FEF\", \"6v\", \"6r\", \"PEF\")),\n                (\n                    \"Posterior Opercular Cortex\",\n                    (\"43\", \"FOP1\", \"OP4\", \"OP1\", \"OP2-3\", \"PFcm\"),\n                ),\n                (\"Early Auditory Cortex\", (\"A1\", \"LBelt\", \"MBelt\", \"PBelt\", \"RI\")),\n                (\n                    \"Auditory Association Cortex\",\n                    (\n                        \"A4\",\n                        \"A5\",\n                        \"STSdp\",\n                        \"STSda\",\n                        \"STSvp\",\n                        \"STSva\",\n                        \"STGa\",\n                        \"TA2\",\n                    ),\n                ),\n                (\n                    \"Insular and Frontal Opercular Cortex\",\n                    (\n                        \"52\",\n                        \"PI\",\n                        \"Ig\",\n                        \"PoI1\",\n                        \"PoI2\",\n                        \"FOP2\",\n                        \"FOP3\",\n                        \"MI\",\n                        \"AVI\",\n                        \"AAIC\",\n                        \"Pir\",\n                        \"FOP4\",\n                        \"FOP5\",\n                    ),\n                ),\n                (\n                    \"Medial Temporal Cortex\",\n                    (\n                        \"H\",\n                        \"PreS\",\n                        \"EC\",\n                        \"PeEc\",\n                        \"PHA1\",\n                        \"PHA2\",\n                        \"PHA3\",\n                    ),\n                ),\n                (\n                    \"Lateral Temporal Cortex\",\n                    (\n                        \"PHT\",\n                        \"TE1p\",\n                        \"TE1m\",\n                        \"TE1a\",\n                        \"TE2p\",\n                        \"TE2a\",\n                        \"TGv\",\n                        \"TGd\",\n                        \"TF\",\n                    ),\n                ),\n                (\n                    \"Temporo-Parieto-Occipital Junction\",\n                    (\n                        \"TPOJ1\",\n                        \"TPOJ2\",\n                        \"TPOJ3\",\n                        \"STV\",\n                        \"PSL\",\n                    ),\n                ),\n                (\n                    \"Superior Parietal Cortex\",\n                    (\n                        \"LIPv\",\n                        \"LIPd\",\n                        \"VIP\",\n                        \"AIP\",\n                        \"MIP\",\n                        \"7PC\",\n                        \"7AL\",\n                        \"7Am\",\n                        \"7PL\",\n                        \"7Pm\",\n                    ),\n                ),\n                (\n                    \"Inferior Parietal Cortex\",\n                    (\n                        \"PGp\",\n                        \"PGs\",\n                        \"PGi\",\n                        \"PFm\",\n                        \"PF\",\n                        \"PFt\",\n                        \"PFop\",\n                        \"IP0\",\n                        \"IP1\",\n                        \"IP2\",\n                    ),\n                ),\n                (\n                    \"Posterior Cingulate Cortex\",\n                    (\n                        \"DVT\",\n                        \"ProS\",\n                        \"POS1\",\n                        \"POS2\",\n                        \"RSC\",\n                        \"v23ab\",\n                        \"d23ab\",\n                        \"31pv\",\n                        \"31pd\",\n                        \"31a\",\n                        \"23d\",\n                        \"23c\",\n                        \"PCV\",\n                        \"7m\",\n                    ),\n                ),\n                (\n                    \"Anterior Cingulate and Medial Prefrontal Cortex\",\n                    (\n                        \"33pr\",\n                        \"p24pr\",\n                        \"a24pr\",\n                        \"p24\",\n                        \"a24\",\n                        \"p32pr\",\n                        \"a32pr\",\n                        \"d32\",\n                        \"p32\",\n                        \"s32\",\n                        \"8BM\",\n                        \"9m\",\n                        \"10v\",\n                        \"10r\",\n                        \"25\",\n                    ),\n                ),\n                (\n                    \"Orbital and Polar Frontal Cortex\",\n                    (\n                        \"47s\",\n                        \"47m\",\n                        \"a47r\",\n                        \"11l\",\n                        \"13l\",\n                        \"a10p\",\n                        \"p10p\",\n                        \"10pp\",\n                        \"10d\",\n                        \"OFC\",\n                        \"pOFC\",\n                    ),\n                ),\n                (\n                    \"Inferior Frontal Cortex\",\n                    (\n                        \"44\",\n                        \"45\",\n                        \"IFJp\",\n                        \"IFJa\",\n                        \"IFSp\",\n                        \"IFSa\",\n                        \"47l\",\n                        \"p47r\",\n                    ),\n                ),\n                (\n                    \"DorsoLateral Prefrontal Cortex\",\n                    (\n                        \"8C\",\n                        \"8Av\",\n                        \"i6-8\",\n                        \"s6-8\",\n                        \"SFL\",\n                        \"8BL\",\n                        \"9p\",\n                        \"9a\",\n                        \"8Ad\",\n                        \"p9-46v\",\n                        \"a9-46v\",\n                        \"46\",\n                        \"9-46d\",\n                    ),\n                ),\n                (\"???\", (\"???\",)),\n            ]\n        )\n        assert len(groups) == 23\n        labels_out = list()\n\n        for hemi in (\"lh\", \"rh\"):\n            labels = read_labels_from_annot(\n                \"fsaverage\", \"HCPMMP1\", hemi=hemi, subjects_dir=subjects_dir, sort=False\n            )\n            label_names = [\n                \"???\" if label.name.startswith(\"???\") else label.name.split(\"_\")[1]\n                for label in labels\n            ]\n            used = np.zeros(len(labels), bool)\n            for key, want in groups.items():\n                assert \"\\t\" not in key\n                these_labels = [\n                    li\n                    for li, label_name in enumerate(label_names)\n                    if label_name in want\n                ]\n                assert not used[these_labels].any()\n                assert len(these_labels) == len(want)\n                used[these_labels] = True\n                these_labels = [labels[li] for li in these_labels]\n                # take a weighted average to get the color\n                # (here color == task activation)\n                w = np.array([len(label.vertices) for label in these_labels])\n                w = w / float(w.sum())\n                color = np.dot(w, [label.color for label in these_labels])\n                these_labels = sum(\n                    these_labels, Label([], subject=\"fsaverage\", hemi=hemi)\n                )\n                these_labels.name = key\n                these_labels.color = color\n                labels_out.append(these_labels)\n            assert used.all()\n        assert len(labels_out) == 46\n        for hemi, side in ((\"lh\", \"left\"), (\"rh\", \"right\")):\n            table_name = f\"./{side}.fsaverage164.label.gii\"\n            write_labels_to_annot(\n                labels_out,\n                \"fsaverage\",\n                \"HCPMMP1_combined\",\n                hemi=hemi,\n                subjects_dir=subjects_dir,\n                sort=False,\n                table_name=table_name,\n            )", "metadata": {}}
{"_id": "mne_mne_datasets/_fsaverage/base.py_fetch_fsaverage_code", "title": "fetch_fsaverage", "text": "def fetch_fsaverage(subjects_dir=None, *, verbose=None):\n    \"\"\"Fetch and update fsaverage.\n\n    Parameters\n    ----------\n    subjects_dir : str | None\n        The path to use as the subjects directory in the MNE-Python\n        config file. None will use the existing config variable (i.e.,\n        will not change anything), and if it does not exist, will use\n        ``~/mne_data/MNE-fsaverage-data``.\n    %(verbose)s\n\n    Returns\n    -------\n    fs_dir : Path\n        The fsaverage directory.\n        (essentially ``subjects_dir / 'fsaverage'``).\n\n        .. versionchanged:: 1.8\n           A :class:`pathlib.Path` object is returned instead of a string.\n\n    Notes\n    -----\n    This function is designed to provide\n\n    1. All modern (Freesurfer 6) fsaverage subject files\n    2. All MNE fsaverage parcellations\n    3. fsaverage head surface, fiducials, head<->MRI trans, 1- and 3-layer\n       BEMs (and surfaces)\n\n    This function will compare the contents of ``subjects_dir/fsaverage``\n    to the ones provided in the remote zip file. If any are missing,\n    the zip file is downloaded and files are updated. No files will\n    be overwritten.\n\n    .. versionadded:: 0.18\n    \"\"\"\n    # Code used to create the BEM (other files taken from MNE-sample-data):\n    #\n    # $ mne watershed_bem -s fsaverage -d $PWD --verbose info --copy\n    # $ python\n    # >>> bem = mne.make_bem_model('fsaverage', subjects_dir='.', verbose=True)\n    # >>> mne.write_bem_surfaces(\n    # ...     'fsaverage/bem/fsaverage-5120-5120-5120-bem.fif', bem)\n    # >>> sol = mne.make_bem_solution(bem, verbose=True)\n    # >>> mne.write_bem_solution(\n    # ...     'fsaverage/bem/fsaverage-5120-5120-5120-bem-sol.fif', sol)\n    # >>> import os\n    # >>> import os.path as op\n    # >>> names = sorted(op.join(r, f)\n    # ...                for r, d, files in os.walk('fsaverage')\n    # ...                for f in files)\n    # with open('fsaverage.txt', 'w') as fid:\n    #     fid.write('\\n'.join(names))\n    #\n    subjects_dir = _set_montage_coreg_path(subjects_dir)\n    subjects_dir = subjects_dir.expanduser().absolute()\n    fs_dir = subjects_dir / \"fsaverage\"\n    fs_dir.mkdir(parents=True, exist_ok=True)\n    _manifest_check_download(\n        manifest_path=FSAVERAGE_MANIFEST_PATH / \"root.txt\",\n        destination=subjects_dir,\n        url=\"https://osf.io/3bxqt/download?version=2\",\n        hash_=\"5133fe92b7b8f03ae19219d5f46e4177\",\n    )\n    _manifest_check_download(\n        manifest_path=FSAVERAGE_MANIFEST_PATH / \"bem.txt\",\n        destination=subjects_dir / \"fsaverage\",\n        url=\"https://osf.io/7ve8g/download?version=4\",\n        hash_=\"b31509cdcf7908af6a83dc5ee8f49fb1\",\n    )\n    return fs_dir", "metadata": {}}
{"_id": "mne_mne_datasets/_infant/base.py_fetch_infant_template_code", "title": "fetch_infant_template", "text": "def fetch_infant_template(age, subjects_dir=None, *, verbose=None):\n    \"\"\"Fetch and update an infant MRI template.\n\n    Parameters\n    ----------\n    age : str\n        Age to download. Can be one of ``{'2wk', '1mo', '2mo', '3mo', '4.5mo',\n        '6mo', '7.5mo', '9mo', '10.5mo', '12mo', '15mo', '18mo', '2yr'}``.\n    subjects_dir : str | None\n        The path to download the template data to.\n    %(verbose)s\n\n    Returns\n    -------\n    subject : str\n        The standard subject name, e.g. ``ANTS4-5Month3T``.\n\n    Notes\n    -----\n    If you use these templates in your work, please cite\n    :footcite:`OReillyEtAl2021` and :footcite:`RichardsEtAl2016`.\n\n    .. versionadded:: 0.23\n\n    References\n    ----------\n    .. footbibliography::\n    \"\"\"\n    # Code used to create the lists:\n    #\n    # $ for name in 2-0Weeks 1-0Months 2-0Months 3-0Months 4-5Months 6-0Months 7-5Months 9-0Months 10-5Months 12-0Months 15-0Months 18-0Months 2-0Years; do wget https://github.com/christian-oreilly/infant_template_paper/releases/download/v0.1-alpha/ANTS${name}3T.zip; done  # noqa: E501\n    # $ md5sum ANTS*.zip\n    # $ python\n    # >>> import os.path as op\n    # >>> import zipfile\n    # >>> names = [f'ANTS{name}3T' for name in '2-0Weeks 1-0Months 2-0Months 3-0Months 4-5Months 6-0Months 7-5Months 9-0Months 10-5Months 12-0Months 15-0Months 18-0Months 2-0Years'.split()]  # noqa: E501\n    # >>> for name in names:\n    # ...     with zipfile.ZipFile(f'{name}.zip', 'r') as zip:\n    # ...         names = sorted(name for name in zip.namelist() if not zipfile.Path(zip, name).is_dir())  # noqa: E501\n    # ...     with open(f'{name}.txt', 'w') as fid:\n    # ...         fid.write('\\n'.join(names))\n    _validate_type(age, str, \"age\")\n    _check_option(\"age\", age, _AGES.split())\n    subjects_dir = get_subjects_dir(subjects_dir, raise_error=True)\n    unit = dict(wk=\"Weeks\", mo=\"Months\", yr=\"Years\")[age[-2:]]\n    first = age[:-2].split(\".\")[0]\n    dash = \"-5\" if \".5\" in age else \"-0\"\n    subject = f\"ANTS{first}{dash}{unit}3T\"\n    # Actually get and create the files\n    subject_dir = subjects_dir / subject\n    subject_dir.mkdir(parents=True, exist_ok=True)\n    # .zip -> hash mapping\n    orig_hashes = dict(\n        line.strip().split()[::-1] for line in _ORIGINAL_HASHES.strip().splitlines()\n    )\n    _manifest_check_download(\n        manifest_path=_MANIFEST_PATH / f\"{subject}.txt\",\n        destination=subject_dir,\n        url=_ORIGINAL_URL.format(subject=subject),\n        hash_=orig_hashes[f\"{subject}.zip\"],\n    )\n    return subject", "metadata": {}}
{"_id": "mne_mne_datasets/kiloword/kiloword.py_data_path_code", "title": "data_path", "text": "def data_path(\n    path=None, force_update=False, update_path=True, download=True, *, verbose=None\n):\n    \"\"\"Get path to local copy of the kiloword dataset.\n\n    This is the dataset from :footcite:`DufauEtAl2015`.\n\n    Parameters\n    ----------\n    path : None | str\n        Location of where to look for the kiloword data storing\n        location. If None, the environment variable or config parameter\n        MNE_DATASETS_KILOWORD_PATH is used. If it doesn't exist,\n        the \"mne-python/examples\" directory is used. If the\n        kiloword dataset is not found under the given path (e.g.,\n        as \"mne-python/examples/MNE-kiloword-data\"), the data\n        will be automatically downloaded to the specified folder.\n    force_update : bool\n        Force update of the dataset even if a local copy exists.\n    update_path : bool | None\n        If True, set the MNE_DATASETS_KILOWORD_PATH in mne-python\n        config to the given path. If None, the user is prompted.\n    download : bool\n        If False and the kiloword dataset has not been downloaded yet,\n        it will not be downloaded and the path will be returned as\n        '' (empty string). This is mostly used for debugging purposes\n        and can be safely ignored by most users.\n    %(verbose)s\n\n    Returns\n    -------\n    path : list of Path\n        Local path to the given data file. This path is contained inside a list\n        of length one, for compatibility.\n\n    References\n    ----------\n    .. footbibliography::\n    \"\"\"\n    return _download_mne_dataset(\n        name=\"kiloword\",\n        processor=\"untar\",\n        path=path,\n        force_update=force_update,\n        update_path=update_path,\n        download=download,\n    )", "metadata": {}}
{"_id": "mne_mne_datasets/kiloword/kiloword.py_get_version_code", "title": "get_version", "text": "def get_version():\n    \"\"\"Get dataset version.\"\"\"\n    return _get_version(\"kiloword\")", "metadata": {}}
{"_id": "mne_mne_datasets/limo/limo.py_data_path_code", "title": "data_path", "text": "def data_path(\n    subject, path=None, force_update=False, update_path=None, *, verbose=None\n):\n    \"\"\"Get path to local copy of LIMO dataset URL.\n\n    This is a low-level function useful for getting a local copy of the\n    remote LIMO dataset :footcite:`Rousselet2016`. The complete dataset is\n    available at datashare.is.ed.ac.uk/.\n\n    Parameters\n    ----------\n    subject : int\n        Subject to download. Must be of :class:`\u00ecnt` in the range from 1\n        to 18 (inclusive).\n    path : None | str\n        Location of where to look for the LIMO data storing directory.\n        If None, the environment variable or config parameter\n        ``MNE_DATASETS_LIMO_PATH`` is used. If it doesn't exist, the\n        \"~/mne_data\" directory is used. If the LIMO dataset\n        is not found under the given path, the data\n        will be automatically downloaded to the specified folder.\n    force_update : bool\n        Force update of the dataset even if a local copy exists.\n    update_path : bool | None\n        If True, set the MNE_DATASETS_LIMO_PATH in mne-python\n        config to the given path. If None, the user is prompted.\n    %(verbose)s\n\n    Returns\n    -------\n    path : str\n        Local path to the given data file.\n\n    Notes\n    -----\n    For example, one could do:\n\n        >>> from mne.datasets import limo\n        >>> limo.data_path(subject=1, path=os.getenv('HOME') + '/datasets') # doctest:+SKIP\n\n    This would download the LIMO data file to the 'datasets' folder,\n    and prompt the user to save the 'datasets' path to the mne-python config,\n    if it isn't there already.\n\n    References\n    ----------\n    .. footbibliography::\n    \"\"\"  # noqa: E501\n    import pooch\n\n    t0 = time.time()\n\n    downloader = pooch.HTTPDownloader(**_downloader_params())\n\n    # local storage patch\n    config_key = \"MNE_DATASETS_LIMO_PATH\"\n    name = \"LIMO\"\n    subj = f\"S{subject}\"\n    path = _get_path(path, config_key, name)\n    base_path = op.join(path, \"MNE-limo-data\")\n    subject_path = op.join(base_path, subj)\n    # the remote URLs are in the form of UUIDs:\n    urls = dict(\n        S18={\n            \"Yr.mat\": \"5cf839833a4d9500178a6ff8\",\n            \"LIMO.mat\": \"5cf83907e650a2001ad592e4\",\n        },\n        S17={\n            \"Yr.mat\": \"5cf838e83a4d9500168aeb76\",\n            \"LIMO.mat\": \"5cf83867a542b80019c87602\",\n        },\n        S16={\n            \"Yr.mat\": \"5cf83857e650a20019d5778f\",\n            \"LIMO.mat\": \"5cf837dc3a4d9500188a64fe\",\n        },\n        S15={\n            \"Yr.mat\": \"5cf837cce650a2001ad591e8\",\n            \"LIMO.mat\": \"5cf83758a542b8001ac7d11d\",\n        },\n        S14={\n            \"Yr.mat\": \"5cf837493a4d9500198a938f\",\n            \"LIMO.mat\": \"5cf836e4a542b8001bc7cc53\",\n        },\n        S13={\n            \"Yr.mat\": \"5cf836d23a4d9500178a6df7\",\n            \"LIMO.mat\": \"5cf836543a4d9500168ae7cb\",\n        },\n        S12={\n            \"Yr.mat\": \"5cf83643d4c7d700193e5954\",\n            \"LIMO.mat\": \"5cf835193a4d9500178a6c92\",\n        },\n        S11={\n            \"Yr.mat\": \"5cf8356ea542b8001cc81517\",\n            \"LIMO.mat\": \"5cf834f7d4c7d700163daab8\",\n        },\n        S10={\n            \"Yr.mat\": \"5cf833b0e650a20019d57454\",\n            \"LIMO.mat\": \"5cf83204e650a20018d59eb2\",\n        },\n        S9={\n            \"Yr.mat\": \"5cf83201a542b8001cc811cf\",\n            \"LIMO.mat\": \"5cf8316c3a4d9500168ae13b\",\n        },\n        S8={\n            \"Yr.mat\": \"5cf8326ce650a20017d60373\",\n            \"LIMO.mat\": \"5cf8316d3a4d9500198a8dc5\",\n        },\n        S7={\n            \"Yr.mat\": \"5cf834a03a4d9500168ae59b\",\n            \"LIMO.mat\": \"5cf83069e650a20017d600d7\",\n        },\n        S6={\n            \"Yr.mat\": \"5cf830e6a542b80019c86a70\",\n            \"LIMO.mat\": \"5cf83057a542b80019c869ca\",\n        },\n        S5={\n            \"Yr.mat\": \"5cf8115be650a20018d58041\",\n            \"LIMO.mat\": \"5cf80c0bd4c7d700193e213c\",\n        },\n        S4={\n            \"Yr.mat\": \"5cf810c9a542b80019c8450a\",\n            \"LIMO.mat\": \"5cf80bf83a4d9500198a6eb4\",\n        },\n        S3={\n            \"Yr.mat\": \"5cf80c55d4c7d700163d8f52\",\n            \"LIMO.mat\": \"5cf80bdea542b80019c83cab\",\n        },\n        S2={\n            \"Yr.mat\": \"5cde827123fec40019e01300\",\n            \"LIMO.mat\": \"5cde82682a50c4001677c259\",\n        },\n        S1={\n            \"Yr.mat\": \"5d6d3071536cf5001a8b0c78\",\n            \"LIMO.mat\": \"5d6d305f6f41fc001a3151d8\",\n        },\n    )\n    # these can't be in the registry file (mne/data/dataset_checksums.txt)\n    # because of filename duplication\n    hashes = dict(\n        S18={\n            \"Yr.mat\": \"md5:87f883d442737971a80fc0a35d057e51\",\n            \"LIMO.mat\": \"md5:8b4879646f65d7876fa4adf2e40162c5\",\n        },\n        S17={\n            \"Yr.mat\": \"md5:7b667ec9eefd7a9996f61ae270e295ee\",\n            \"LIMO.mat\": \"md5:22eaca4e6fad54431fd61b307fc426b8\",\n        },\n        S16={\n            \"Yr.mat\": \"md5:c877afdb4897426421577e863a45921a\",\n            \"LIMO.mat\": \"md5:86672d7afbea1e8c39305bc3f852c8c2\",\n        },\n        S15={\n            \"Yr.mat\": \"md5:eea9e0140af598fefc08c886a6f05de5\",\n            \"LIMO.mat\": \"md5:aed5cb71ddbfd27c6a3ac7d3e613d07f\",\n        },\n        S14={\n            \"Yr.mat\": \"md5:8bd842cfd8588bd5d32e72fdbe70b66e\",\n            \"LIMO.mat\": \"md5:1e07d1f36f2eefad435a77530daf2680\",\n        },\n        S13={\n            \"Yr.mat\": \"md5:d7925d2af7288b8a5186dfb5dbb63d34\",\n            \"LIMO.mat\": \"md5:ba891015d2f9e447955fffa9833404ca\",\n        },\n        S12={\n            \"Yr.mat\": \"md5:0e1d05beaa4bf2726e0d0671b78fe41e\",\n            \"LIMO.mat\": \"md5:423fd479d71097995b6614ecb11df9ad\",\n        },\n        S11={\n            \"Yr.mat\": \"md5:1b0016fb9832e43b71f79c1992fcbbb1\",\n            \"LIMO.mat\": \"md5:1a281348c2a41ee899f42731d30cda70\",\n        },\n        S10={\n            \"Yr.mat\": \"md5:13c66f60e241b9a9cc576eaf1b55a417\",\n            \"LIMO.mat\": \"md5:3c4b41e221eb352a21bbef1a7e006f06\",\n        },\n        S9={\n            \"Yr.mat\": \"md5:3ae1d9c3a1d9325deea2f2dddd1ab507\",\n            \"LIMO.mat\": \"md5:5e204e2a4bcfe4f535b4b1af469b37f7\",\n        },\n        S8={\n            \"Yr.mat\": \"md5:7e9adbca4e03d8d7ce8ea07ccecdc8fd\",\n            \"LIMO.mat\": \"md5:88313c21d34428863590e586b2bc3408\",\n        },\n        S7={\n            \"Yr.mat\": \"md5:6b5290a6725ecebf1022d5d2789b186d\",\n            \"LIMO.mat\": \"md5:8c769219ebc14ce3f595063e84bfc0a9\",\n        },\n        S6={\n            \"Yr.mat\": \"md5:420c858a8340bf7c28910b7b0425dc5d\",\n            \"LIMO.mat\": \"md5:9cf4e1a405366d6bd0cc6d996e32fd63\",\n        },\n        S5={\n            \"Yr.mat\": \"md5:946436cfb474c8debae56ffb1685ecf3\",\n            \"LIMO.mat\": \"md5:241fac95d3a79d2cea081391fb7078bd\",\n        },\n        S4={\n            \"Yr.mat\": \"md5:c8216af78ac87b739e86e57b345cafdd\",\n            \"LIMO.mat\": \"md5:8e10ef36c2e075edc2f787581ba33459\",\n        },\n        S3={\n            \"Yr.mat\": \"md5:ff02e885b65b7b807146f259a30b1b5e\",\n            \"LIMO.mat\": \"md5:59b5fb3a9749003133608b5871309e2c\",\n        },\n        S2={\n            \"Yr.mat\": \"md5:a4329022e57fd07ceceb7d1735fd2718\",\n            \"LIMO.mat\": \"md5:98b284b567f2dd395c936366e404f2c6\",\n        },\n        S1={\n            \"Yr.mat\": \"md5:076c0ae78fb71d43409c1877707df30e\",\n            \"LIMO.mat\": \"md5:136c8cf89f8f111a11f531bd9fa6ae69\",\n        },\n    )\n    # create the download manager\n    fetcher = pooch.create(\n        path=subject_path,\n        base_url=\"\",\n        version=None,  # Data versioning is decoupled from MNE-Python version.\n        registry=hashes[subj],\n        urls={key: f\"{root_url}{uuid}\" for key, uuid in urls[subj].items()},\n        retry_if_failed=2,  # 2 retries = 3 total attempts\n    )\n    # use our logger level for pooch's logger too\n    pooch.get_logger().setLevel(logger.getEffectiveLevel())\n    # fetch the data\n    sz = 0\n    for fname in (\"LIMO.mat\", \"Yr.mat\"):\n        destination = Path(subject_path, fname)\n        if destination.exists():\n            if force_update:\n                destination.unlink()\n            else:\n                continue\n        if sz == 0:  # log once\n            logger.info(\"Downloading LIMO data\")\n        # fetch the remote file (if local file missing or has hash mismatch)\n        fetcher.fetch(fname=fname, downloader=downloader)\n        sz += destination.stat().st_size\n    # update path in config if desired\n    _do_path_update(path, update_path, config_key, name)\n    if sz > 0:\n        _log_time_size(t0, sz)\n    return base_path", "metadata": {}}
{"_id": "mne_mne_datasets/limo/limo.py_load_data_code", "title": "load_data", "text": "def load_data(subject, path=None, force_update=False, update_path=None, verbose=None):\n    \"\"\"Fetch subjects epochs data for the LIMO data set.\n\n    Parameters\n    ----------\n    subject : int\n        Subject to use. Must be of class \u00ecnt in the range from 1 to 18.\n    path : str\n        Location of where to look for the LIMO data.\n        If None, the environment variable or config parameter\n        ``MNE_DATASETS_LIMO_PATH`` is used. If it doesn't exist, the\n        \"~/mne_data\" directory is used.\n    force_update : bool\n        Force update of the dataset even if a local copy exists.\n    update_path : bool | None\n        If True, set the MNE_DATASETS_LIMO_PATH in mne-python\n        config to the given path. If None, the user is prompted.\n    %(verbose)s\n\n    Returns\n    -------\n    epochs : instance of Epochs\n        The epochs.\n    \"\"\"  # noqa: E501\n    pd = _check_pandas_installed()\n    # subject in question\n    if isinstance(subject, int) and 1 <= subject <= 18:\n        subj = f\"S{subject}\"\n    else:\n        raise ValueError(\"subject must be an int in the range from 1 to 18\")\n\n    # set limo path, download and decompress files if not found\n    limo_path = data_path(subject, path, force_update, update_path)\n\n    # -- 1) import .mat files\n    # epochs info\n    fname_info = op.join(limo_path, subj, \"LIMO.mat\")\n    data_info = loadmat(fname_info)\n    # number of epochs per condition\n    design = data_info[\"LIMO\"][\"design\"][0][0][\"X\"][0][0]\n    data_info = data_info[\"LIMO\"][\"data\"][0][0][0][0]\n    # epochs data\n    fname_eeg = op.join(limo_path, subj, \"Yr.mat\")\n    data = loadmat(fname_eeg)\n\n    # -- 2) get epochs information from structure\n    # sampling rate\n    sfreq = data_info[\"sampling_rate\"][0][0]\n    # tmin and tmax\n    tmin = data_info[\"start\"][0][0]\n    # create events matrix\n    sample = np.arange(len(design))\n    prev_id = np.zeros(len(design))\n    ev_id = design[:, 1]\n    events = np.array([sample, prev_id, ev_id]).astype(int).T\n    # event ids, such that Face B == 1\n    event_id = {\"Face/A\": 0, \"Face/B\": 1}\n\n    # -- 3) extract channel labels from LIMO structure\n    # get individual labels\n    labels = data_info[\"chanlocs\"][\"labels\"]\n    labels = [label for label, *_ in labels[0]]\n    # get montage\n    montage = make_standard_montage(\"biosemi128\")\n    # add external electrodes (e.g., eogs)\n    ch_names = montage.ch_names + [\"EXG1\", \"EXG2\", \"EXG3\", \"EXG4\"]\n    # match individual labels to labels in montage\n    found_inds = [ind for ind, name in enumerate(ch_names) if name in labels]\n    missing_chans = [name for name in ch_names if name not in labels]\n    assert labels == [ch_names[ind] for ind in found_inds]\n\n    # -- 4) extract data from subjects Yr structure\n    # data is stored as channels x time points x epochs\n    # data['Yr'].shape  # <-- see here\n    # transpose to epochs x channels time points\n    data = np.transpose(data[\"Yr\"], (2, 0, 1))\n    # initialize data in expected order\n    temp_data = np.empty((data.shape[0], len(ch_names), data.shape[2]))\n    # copy over the non-missing data\n    for source, target in enumerate(found_inds):\n        # avoid copy when fancy indexing\n        temp_data[:, target, :] = data[:, source, :]\n    # data to V (to match MNE's format)\n    data = temp_data / 1e6\n    # create list containing channel types\n    types = [\"eog\" if ch.startswith(\"EXG\") else \"eeg\" for ch in ch_names]\n\n    # -- 5) Create custom info for mne epochs structure\n    # create info\n    info = create_info(ch_names, sfreq, types).set_montage(montage)\n    # get faces and noise variables from design matrix\n    event_list = list(events[:, 2])\n    faces = [\"B\" if event else \"A\" for event in event_list]\n    noise = list(design[:, 2])\n    # create epochs metadata\n    metadata = {\"face\": faces, \"phase-coherence\": noise}\n    metadata = pd.DataFrame(metadata)\n\n    # -- 6) Create custom epochs array\n    epochs = EpochsArray(\n        data, info, events, tmin, event_id, metadata=metadata, verbose=False\n    )\n    epochs.info[\"bads\"] = missing_chans  # missing channels are marked as bad.\n\n    return epochs", "metadata": {}}
{"_id": "mne_mne_datasets/_phantom/base.py_fetch_phantom_code", "title": "fetch_phantom", "text": "def fetch_phantom(kind, subjects_dir=None, *, verbose=None):\n    \"\"\"Fetch and update a phantom subject.\n\n    Parameters\n    ----------\n    kind : str\n        The kind of phantom to fetch. Can only be ``'otaniemi'`` (default).\n    %(subjects_dir)s\n    %(verbose)s\n\n    Returns\n    -------\n    subject_dir : pathlib.Path\n        The resulting phantom subject directory.\n\n    See Also\n    --------\n    mne.dipole.get_phantom_dipoles\n\n    Notes\n    -----\n    This function is designed to provide a head surface and T1.mgz for\n    the 32-dipole Otaniemi phantom. The VectorView/TRIUX phantom has the same\n    basic outside geometry, but different internal dipole positions.\n\n    Unlike most FreeSurfer subjects, the Otaniemi phantom scan was aligned\n    to the \"head\" coordinate frame, so an identity head<->MRI :term:`trans`\n    is appropriate.\n\n    .. versionadded:: 0.24\n    \"\"\"\n    phantoms = dict(\n        otaniemi=dict(\n            url=\"https://osf.io/j5czy/download?version=1\",\n            hash=\"42d17db5b1db3e30327ffb4cf2649de8\",\n        ),\n    )\n    _validate_type(kind, str, \"kind\")\n    _check_option(\"kind\", kind, list(phantoms))\n    subjects_dir = get_subjects_dir(subjects_dir, raise_error=True)\n    subject = f\"phantom_{kind}\"\n    subject_dir = subjects_dir / subject\n    subject_dir.mkdir(parents=True, exist_ok=True)\n    _manifest_check_download(\n        manifest_path=PHANTOM_MANIFEST_PATH / f\"{subject}.txt\",\n        destination=subjects_dir,\n        url=phantoms[kind][\"url\"],\n        hash_=phantoms[kind][\"hash\"],\n    )\n    return subject_dir", "metadata": {}}
{"_id": "mne_mne_datasets/sleep_physionet/age.py_fetch_data_code", "title": "fetch_data", "text": "def fetch_data(\n    subjects,\n    recording=(1, 2),\n    path=None,\n    force_update=False,\n    base_url=BASE_URL,\n    on_missing=\"raise\",\n    *,\n    verbose=None,\n):  # noqa: D301, E501\n    \"\"\"Get paths to local copies of PhysioNet Polysomnography dataset files.\n\n    This will fetch data from the publicly available subjects from PhysioNet's\n    study of age effects on sleep in healthy subjects\n    :footcite:`MourtazaevEtAl1995,GoldbergerEtAl2000`. This\n    corresponds to a subset of 153 recordings from 37 males and 41 females that\n    were 25-101 years old at the time of the recordings. There are two night\n    recordings per subject except for subjects 13, 36 and 52 which have one\n    record missing each due to missing recording hardware.\n\n    See more details in\n    `physionet website <https://physionet.org/physiobank/database/sleep-edfx/sleep-cassette/>`_.\n\n    Parameters\n    ----------\n    subjects : list of int\n        The subjects to use. Can be in the range of 0-82 (inclusive), however\n        the following subjects are not available: 39, 68, 69, 78 and 79.\n    recording : list of int\n        The night recording indices. Valid values are : [1], [2], or [1, 2].\n        The following recordings are not available: recording 1 for subject 36\n        and 52, and recording 2 for subject 13.\n    path : None | str\n        Location of where to look for the PhysioNet data storing location.\n        If None, the environment variable or config parameter\n        ``PHYSIONET_SLEEP_PATH`` is used. If it doesn't exist, the \"~/mne_data\"\n        directory is used. If the Polysomnography dataset is not found under\n        the given path, the data will be automatically downloaded to the\n        specified folder.\n    force_update : bool\n        Force update of the dataset even if a local copy exists.\n    base_url : str\n        The URL root.\n    on_missing : 'raise' | 'warn' | 'ignore'\n        What to do if one or several recordings are not available. Valid keys\n        are 'raise' | 'warn' | 'ignore'. Default is 'error'. If on_missing\n        is 'warn' it will proceed but warn, if 'ignore' it will proceed\n        silently.\n    %(verbose)s\n\n    Returns\n    -------\n    paths : list\n        List of local data paths of the given type.\n\n    See Also\n    --------\n    mne.datasets.sleep_physionet.temazepam.fetch_data\n\n    Notes\n    -----\n    For example, one could do:\n\n        >>> from mne.datasets import sleep_physionet\n        >>> sleep_physionet.age.fetch_data(subjects=[0])  # doctest: +SKIP\n\n    This would download data for subject 0 if it isn't there already.\n\n    References\n    ----------\n    .. footbibliography::\n    \"\"\"  # noqa: E501\n    t0 = time.time()\n    records = np.loadtxt(\n        AGE_SLEEP_RECORDS,\n        skiprows=1,\n        delimiter=\",\",\n        usecols=(0, 1, 2, 6, 7),\n        dtype={\n            \"names\": (\"subject\", \"record\", \"type\", \"sha\", \"fname\"),\n            \"formats\": (\"<i2\", \"i1\", \"<S9\", \"S40\", \"<S22\"),\n        },\n    )\n    psg_records = records[np.where(records[\"type\"] == b\"PSG\")]\n    hyp_records = records[np.where(records[\"type\"] == b\"Hypnogram\")]\n\n    path = data_path(path=path)\n    params = [path, force_update, base_url]\n\n    _check_subjects(subjects, 83, missing=[39, 68, 69, 78, 79], on_missing=on_missing)\n\n    # Check for missing recordings\n    if set(subjects) & {36, 52} and 1 in recording:\n        msg = (\n            \"Requested recording 1 for subject 36 and/or 52, but it is not \"\n            \"available in corpus.\"\n        )\n        _on_missing(on_missing, msg)\n    if 13 in subjects and 2 in recording:\n        msg = \"Requested recording 2 for subject 13, but it is not available in corpus.\"\n        _on_missing(on_missing, msg)\n\n    fnames = []\n    sz = 0\n    for subject in subjects:\n        for idx in np.where(psg_records[\"subject\"] == subject)[0]:\n            if psg_records[\"record\"][idx] in recording:\n                psg_fname, pdl = _fetch_one(\n                    psg_records[\"fname\"][idx].decode(),\n                    psg_records[\"sha\"][idx].decode(),\n                    *params,\n                )\n                hyp_fname, hdl = _fetch_one(\n                    hyp_records[\"fname\"][idx].decode(),\n                    hyp_records[\"sha\"][idx].decode(),\n                    *params,\n                )\n                fnames.append([psg_fname, hyp_fname])\n                if pdl:\n                    sz += os.path.getsize(psg_fname)\n                if hdl:\n                    sz += os.path.getsize(hyp_fname)\n    if sz > 0:\n        _log_time_size(t0, sz)\n    return fnames", "metadata": {}}
{"_id": "mne_mne_datasets/sleep_physionet/temazepam.py_fetch_data_code", "title": "fetch_data", "text": "def fetch_data(\n    subjects, path=None, force_update=False, base_url=BASE_URL, *, verbose=None\n):\n    \"\"\"Get paths to local copies of PhysioNet Polysomnography dataset files.\n\n    This will fetch data from the publicly available subjects from PhysioNet's\n    study of Temazepam effects on sleep :footcite:`KempEtAl2000`. This\n    corresponds to a set of 22 subjects. Subjects had mild difficulty falling\n    asleep but were otherwise healthy.\n\n    See more details in the `physionet website\n    <https://physionet.org/physiobank/database/sleep-edfx/>`_\n    :footcite:`GoldbergerEtAl2000`.\n\n    Parameters\n    ----------\n    subjects : list of int\n        The subjects to use. Can be in the range of 0-21 (inclusive).\n    path : None | str\n        Location of where to look for the PhysioNet data storing location.\n        If None, the environment variable or config parameter\n        ``PHYSIONET_SLEEP_PATH`` is used. If it doesn't exist, the \"~/mne_data\"\n        directory is used. If the Polysomnography dataset is not found under\n        the given path, the data will be automatically downloaded to the\n        specified folder.\n    force_update : bool\n        Force update of the dataset even if a local copy exists.\n    base_url : str\n        The base URL to download from.\n    %(verbose)s\n\n    Returns\n    -------\n    paths : list\n        List of local data paths of the given type.\n\n    See Also\n    --------\n    mne.datasets.sleep_physionet.age.fetch_data\n\n    Notes\n    -----\n    For example, one could do:\n\n        >>> from mne.datasets import sleep_physionet\n        >>> sleep_physionet.temazepam.fetch_data(subjects=[1]) # doctest: +SKIP\n\n    This would download data for subject 0 if it isn't there already.\n\n    References\n    ----------\n    .. footbibliography::\n    \"\"\"\n    t0 = time.time()\n    records = np.loadtxt(\n        TEMAZEPAM_SLEEP_RECORDS,\n        skiprows=1,\n        delimiter=\",\",\n        usecols=(0, 3, 6, 7, 8, 9),\n        dtype={\n            \"names\": (\n                \"subject\",\n                \"record\",\n                \"hyp sha\",\n                \"psg sha\",\n                \"hyp fname\",\n                \"psg fname\",\n            ),\n            \"formats\": (\"<i2\", \"<S15\", \"S40\", \"S40\", \"<S22\", \"<S16\"),\n        },\n    )\n\n    _check_subjects(subjects, 22)\n\n    path = data_path(path=path)\n    params = [path, force_update, base_url]\n\n    fnames = []\n    sz = 0\n    for subject in subjects:  # all the subjects are present at this point\n        for idx in np.where(records[\"subject\"] == subject)[0]:\n            if records[\"record\"][idx] == b\"Placebo\":\n                psg_fname, pdl = _fetch_one(\n                    records[\"psg fname\"][idx].decode(),\n                    records[\"psg sha\"][idx].decode(),\n                    *params,\n                )\n                hyp_fname, hdl = _fetch_one(\n                    records[\"hyp fname\"][idx].decode(),\n                    records[\"hyp sha\"][idx].decode(),\n                    *params,\n                )\n                fnames.append([psg_fname, hyp_fname])\n                if pdl:\n                    sz += os.path.getsize(psg_fname)\n                if hdl:\n                    sz += os.path.getsize(hyp_fname)\n    if sz > 0:\n        _log_time_size(t0, sz)\n    return fnames", "metadata": {}}
{"_id": "mne_mne_datasets/testing/_testing.py_requires_testing_data_code", "title": "requires_testing_data", "text": "def requires_testing_data(func):\n    \"\"\"Skip testing data test.\"\"\"\n    return _pytest_mark()(func)", "metadata": {}}
{"_id": "mne_mne_datasets/eegbci/eegbci.py_data_path_code", "title": "data_path", "text": "def data_path(url, path=None, force_update=False, update_path=None, *, verbose=None):\n    \"\"\"Get path to local copy of EEGMMI dataset URL.\n\n    This is a low-level function useful for getting a local copy of a remote EEGBCI\n    dataset :footcite:`SchalkEtAl2004`, which is also available at PhysioNet\n    :footcite:`GoldbergerEtAl2000`. Metadata, such as the meaning of event markers\n    may be obtained from the\n    `PhysioNet documentation page <https://physionet.org/content/eegmmidb/1.0.0/>`_.\n\n    Parameters\n    ----------\n    url : str\n        The dataset to use.\n    path : None | path-like\n        Location of where to look for the EEGBCI data. If ``None``, the environment\n        variable or config parameter ``MNE_DATASETS_EEGBCI_PATH`` is used. If neither\n        exists, the ``~/mne_data`` directory is used. If the EEGBCI dataset is not found\n        under the given path, the data will be automatically downloaded to the specified\n        folder.\n    force_update : bool\n        Force update of the dataset even if a local copy exists.\n    update_path : bool | None\n        If ``True``, set ``MNE_DATASETS_EEGBCI_PATH`` in the configuration to the given\n        path. If ``None``, the user is prompted.\n    %(verbose)s\n\n    Returns\n    -------\n    path : list of Path\n        Local path to the given data file. This path is contained inside a list of\n        length one for compatibility.\n\n    Notes\n    -----\n    For example, one could do:\n\n        >>> from mne.datasets import eegbci\n        >>> url = \"http://www.physionet.org/physiobank/database/eegmmidb/\"\n        >>> eegbci.data_path(url, \"~/datasets\") # doctest:+SKIP\n\n    This would download the given EEGBCI data file to the ``~/datasets`` folder and\n    prompt the user to store this path in the config (if it does not already exist).\n\n    References\n    ----------\n    .. footbibliography::\n    \"\"\"\n    import pooch\n\n    key = \"MNE_DATASETS_EEGBCI_PATH\"\n    name = \"EEGBCI\"\n    path = _get_path(path, key, name)\n    fname = \"MNE-eegbci-data\"\n    destination = _url_to_local_path(url, op.join(path, fname))\n    destinations = [destination]\n\n    # fetch the file\n    downloader = pooch.HTTPDownloader(**_downloader_params())\n    if not op.isfile(destination) or force_update:\n        if op.isfile(destination):\n            os.remove(destination)\n        if not op.isdir(op.dirname(destination)):\n            os.makedirs(op.dirname(destination))\n        pooch.retrieve(\n            url=url,\n            path=destination,\n            downloader=downloader,\n            fname=fname,\n        )\n\n    # offer to update the path\n    _do_path_update(path, update_path, key, name)\n    destinations = [Path(dest) for dest in destinations]\n    return destinations", "metadata": {}}
{"_id": "mne_mne_datasets/eegbci/eegbci.py_load_data_code", "title": "load_data", "text": "def load_data(\n    subjects,\n    runs,\n    *,\n    path=None,\n    force_update=False,\n    update_path=None,\n    base_url=EEGMI_URL,\n    verbose=None,\n):  # noqa: D301\n    \"\"\"Get paths to local copies of EEGBCI dataset files.\n\n    This will fetch data for the EEGBCI dataset :footcite:`SchalkEtAl2004`, which is\n    also available at PhysioNet :footcite:`GoldbergerEtAl2000`. Metadata, such as the\n    meaning of event markers may be obtained from the\n    `PhysioNet documentation page <https://physionet.org/content/eegmmidb/1.0.0/>`_.\n\n    Parameters\n    ----------\n    subjects : int | list of int\n        The subjects to use. Can be in the range of 1-109 (inclusive).\n    runs : int | list of int\n        The runs to use (see Notes for details).\n    path : None | path-like\n        Location of where to look for the EEGBCI data. If ``None``, the environment\n        variable or config parameter ``MNE_DATASETS_EEGBCI_PATH`` is used. If neither\n        exists, the ``~/mne_data`` directory is used. If the EEGBCI dataset is not found\n        under the given path, the data will be automatically downloaded to the specified\n        folder.\n    force_update : bool\n        Force update of the dataset even if a local copy exists.\n    update_path : bool | None\n        If ``True``, set ``MNE_DATASETS_EEGBCI_PATH`` in the configuration to the given\n        path. If ``None``, the user is prompted.\n    base_url : str\n        The URL root for the data.\n    %(verbose)s\n\n    Returns\n    -------\n    paths : list\n        List of local data paths of the given type.\n\n    Notes\n    -----\n    The run numbers correspond to:\n\n    =========  ===================================\n    run        task\n    =========  ===================================\n    1          Baseline, eyes open\n    2          Baseline, eyes closed\n    3, 7, 11   Motor execution: left vs right hand\n    4, 8, 12   Motor imagery: left vs right hand\n    5, 9, 13   Motor execution: hands vs feet\n    6, 10, 14  Motor imagery: hands vs feet\n    =========  ===================================\n\n    For example, one could do::\n\n        >>> from mne.datasets import eegbci\n        >>> eegbci.load_data([1, 2], [6, 10, 14], \"~/datasets\") # doctest:+SKIP\n\n    This would download runs 6, 10, and 14 (hand/foot motor imagery) runs from subjects\n    1 and 2 in the EEGBCI dataset to \"~/datasets\" and prompt the user to store this path\n    in the config (if it does not already exist).\n\n    References\n    ----------\n    .. footbibliography::\n    \"\"\"\n    import pooch\n\n    t0 = time.time()\n\n    if not hasattr(subjects, \"__iter__\"):\n        subjects = [subjects]\n\n    if not hasattr(runs, \"__iter__\"):\n        runs = [runs]\n\n    # get local storage path\n    config_key = \"MNE_DATASETS_EEGBCI_PATH\"\n    folder = \"MNE-eegbci-data\"\n    name = \"EEGBCI\"\n    path = _get_path(path, config_key, name)\n\n    # extract path parts\n    pattern = r\"(?:https?://.*)(files)/(eegmmidb)/(\\d+\\.\\d+\\.\\d+)/?\"\n    match = re.compile(pattern).match(base_url)\n    if match is None:\n        raise ValueError(\n            \"base_url does not match the expected EEGMI folder \"\n            \"structure. Please notify MNE-Python developers.\"\n        )\n    base_path = op.join(path, folder, *match.groups())\n\n    # create the download manager\n    fetcher = pooch.create(\n        path=base_path,\n        base_url=base_url,\n        version=None,  # data versioning is decoupled from MNE-Python version\n        registry=None,  # registry is loaded from file (below)\n        retry_if_failed=2,  # 2 retries = 3 total attempts\n    )\n\n    # load the checksum registry\n    registry = files(\"mne\").joinpath(\"data\", \"eegbci_checksums.txt\")\n    fetcher.load_registry(registry)\n\n    # fetch the file(s)\n    data_paths = []\n    sz = 0\n    for subject in subjects:\n        for run in runs:\n            file_part = f\"S{subject:03d}/S{subject:03d}R{run:02d}.edf\"\n            destination = Path(base_path, file_part)\n            data_paths.append(destination)\n            if destination.exists():\n                if force_update:\n                    destination.unlink()\n                else:\n                    continue\n            if sz == 0:  # log once\n                logger.info(\"Downloading EEGBCI data\")\n            fetcher.fetch(file_part)\n            # update path in config if desired\n            sz += destination.stat().st_size\n\n    _do_path_update(path, update_path, config_key, name)\n    if sz > 0:\n        _log_time_size(t0, sz)\n    return data_paths", "metadata": {}}
{"_id": "mne_mne_datasets/eegbci/eegbci.py_standardize_code", "title": "standardize", "text": "def standardize(raw):\n    \"\"\"Standardize channel positions and names.\n\n    Parameters\n    ----------\n    raw : instance of Raw\n        The raw data to standardize. Operates in-place.\n    \"\"\"\n    rename = dict()\n    for name in raw.ch_names:\n        std_name = name.strip(\".\")\n        std_name = std_name.upper()\n        if std_name.endswith(\"Z\"):\n            std_name = std_name[:-1] + \"z\"\n        if std_name.startswith(\"FP\"):\n            std_name = \"Fp\" + std_name[2:]\n        rename[name] = std_name\n    raw.rename_channels(rename)", "metadata": {}}
{"_id": "mne_mne_datasets/hf_sef/hf_sef.py_data_path_code", "title": "data_path", "text": "def data_path(\n    dataset=\"evoked\", path=None, force_update=False, update_path=True, *, verbose=None\n):\n    \"\"\"Get path to local copy of the high frequency SEF dataset.\n\n    Gets a local copy of the high frequency SEF MEG dataset\n    :footcite:`NurminenEtAl2017`.\n\n    Parameters\n    ----------\n    dataset : 'evoked' | 'raw'\n        Whether to get the main dataset (evoked, structural and the rest) or\n        the separate dataset containing raw MEG data only.\n    path : None | str\n        Where to look for the HF-SEF data storing location.\n        If None, the environment variable or config parameter\n        ``MNE_DATASETS_HF_SEF_PATH`` is used. If it doesn't exist, the\n        \"~/mne_data\" directory is used. If the HF-SEF dataset\n        is not found under the given path, the data\n        will be automatically downloaded to the specified folder.\n    force_update : bool\n        Force update of the dataset even if a local copy exists.\n    update_path : bool | None\n        If True, set the MNE_DATASETS_HF_SEF_PATH in mne-python\n        config to the given path. If None, the user is prompted.\n    %(verbose)s\n\n    Returns\n    -------\n    path : str\n        Local path to the directory where the HF-SEF data is stored.\n\n    References\n    ----------\n    .. footbibliography::\n    \"\"\"\n    _check_option(\"dataset\", dataset, (\"evoked\", \"raw\"))\n    if dataset == \"raw\":\n        data_dict = MNE_DATASETS[\"hf_sef_raw\"]\n        data_dict[\"dataset_name\"] = \"hf_sef_raw\"\n    else:\n        data_dict = MNE_DATASETS[\"hf_sef_evoked\"]\n        data_dict[\"dataset_name\"] = \"hf_sef_evoked\"\n    config_key = data_dict[\"config_key\"]\n    folder_name = data_dict[\"folder_name\"]\n\n    # get download path for specific dataset\n    path = _get_path(path=path, key=config_key, name=folder_name)\n    final_path = op.join(path, folder_name)\n    megdir = op.join(final_path, \"MEG\", \"subject_a\")\n    has_raw = (\n        dataset == \"raw\"\n        and op.isdir(megdir)\n        and any(\"raw\" in filename for filename in os.listdir(megdir))\n    )\n    has_evoked = dataset == \"evoked\" and op.isdir(op.join(final_path, \"subjects\"))\n    # data not there, or force_update requested:\n    if has_raw or has_evoked and not force_update:\n        _do_path_update(path, update_path, config_key, folder_name)\n        return final_path\n\n    # instantiate processor that unzips file\n    data_path = _download_mne_dataset(\n        name=data_dict[\"dataset_name\"],\n        processor=\"untar\",\n        path=path,\n        force_update=force_update,\n        update_path=update_path,\n        download=True,\n    )\n    return data_path", "metadata": {}}
{"_id": "mne_mne_datasets/visual_92_categories/visual_92_categories.py_data_path_code", "title": "data_path", "text": "def data_path(\n    path=None, force_update=False, update_path=True, download=True, *, verbose=None\n):\n    \"\"\"\n    Get path to local copy of visual_92_categories dataset.\n\n    .. note:: The dataset contains four fif-files, the trigger files and the T1\n              mri image. This dataset is rather big in size (more than 5 GB).\n\n    Parameters\n    ----------\n    path : None | str\n        Location of where to look for the visual_92_categories data storing\n        location. If None, the environment variable or config parameter\n        MNE_DATASETS_VISUAL_92_CATEGORIES_PATH is used. If it doesn't exist,\n        the \"mne-python/examples\" directory is used. If the\n        visual_92_categories dataset is not found under the given path (e.g.,\n        as \"mne-python/examples/MNE-visual_92_categories-data\"), the data\n        will be automatically downloaded to the specified folder.\n    force_update : bool\n        Force update of the dataset even if a local copy exists.\n    update_path : bool | None\n        If True, set the MNE_DATASETS_VISUAL_92_CATEGORIES_PATH in mne-python\n        config to the given path. If None, the user is prompted.\n    %(verbose)s\n\n    Returns\n    -------\n    path : instance of Path\n        Local path to the given data file.\n\n    Notes\n    -----\n    The visual_92_categories dataset is documented in the following publication\n        Radoslaw M. Cichy, Dimitrios Pantazis, Aude Oliva (2014) Resolving\n        human object recognition in space and time. doi: 10.1038/NN.3635\n    \"\"\"\n    return _download_mne_dataset(\n        name=\"visual_92_categories\",\n        processor=\"untar\",\n        path=path,\n        force_update=force_update,\n        update_path=update_path,\n        download=download,\n    )", "metadata": {}}
{"_id": "mne_mne_datasets/visual_92_categories/visual_92_categories.py_get_version_code", "title": "get_version", "text": "def get_version():\n    \"\"\"Get dataset version.\"\"\"\n    return _get_version(\"visual_92_categories\")", "metadata": {}}
{"_id": "mne_mne_datasets/spm_face/spm_data.py_requires_spm_data_code", "title": "requires_spm_data", "text": "def requires_spm_data(func):\n    \"\"\"Skip testing data test.\"\"\"\n    import pytest\n\n    return pytest.mark.skipif(_skip_spm_data(), reason=\"Requires spm dataset\")(func)", "metadata": {}}
{"_id": "mne_mne_datasets/brainstorm/bst_auditory.py_description_code", "title": "description", "text": "def description():\n    \"\"\"Get description of brainstorm (bst_auditory) dataset.\"\"\"\n    for desc in _description.splitlines():\n        print(desc)", "metadata": {}}
{"_id": "mne_mne_datasets/brainstorm/bst_phantom_ctf.py_description_code", "title": "description", "text": "def description():\n    \"\"\"Get description of brainstorm (bst_phantom_ctf) dataset.\"\"\"\n    for desc in _description.splitlines():\n        print(desc)", "metadata": {}}
{"_id": "mne_mne_datasets/brainstorm/bst_raw.py_description_code", "title": "description", "text": "def description():  # noqa: D103\n    \"\"\"Get description of brainstorm (bst_raw) dataset.\"\"\"\n    for desc in _description.splitlines():\n        print(desc)", "metadata": {}}
{"_id": "mne_mne_datasets/brainstorm/bst_raw.py_requires_bstraw_data_code", "title": "requires_bstraw_data", "text": "def requires_bstraw_data(func):\n    \"\"\"Skip testing data test.\"\"\"\n    import pytest\n\n    return pytest.mark.skipif(\n        _skip_bstraw_data(), reason=\"Requires brainstorm dataset\"\n    )(func)", "metadata": {}}
{"_id": "mne_mne_datasets/brainstorm/bst_resting.py_description_code", "title": "description", "text": "def description():\n    \"\"\"Get description of brainstorm (bst_resting) dataset.\"\"\"\n    for desc in _description.splitlines():\n        print(desc)", "metadata": {}}
{"_id": "mne_mne_datasets/brainstorm/bst_phantom_elekta.py_description_code", "title": "description", "text": "def description():\n    \"\"\"Get description of brainstorm (bst_phantom_elekta) dataset.\"\"\"\n    for desc in _description.splitlines():\n        print(desc)", "metadata": {}}
{"_id": "mne_mne_time_frequency/spectrum.py_combine_spectrum_code", "title": "combine_spectrum", "text": "def combine_spectrum(all_spectrum, weights=\"nave\"):\n    \"\"\"Merge spectral data by weighted addition.\n\n    Create a new :class:`mne.time_frequency.Spectrum` instance, using a combination of\n    the supplied instances as its data. By default, the mean (weighted by trials) is\n    used. Subtraction can be performed by passing negative weights (e.g., ``[1, -1]``).\n    Data must have the same channels and the same frequencies.\n\n    Parameters\n    ----------\n    all_spectrum : list of Spectrum\n        The Spectrum objects.\n    weights : list of float | str\n        The weights to apply to the data of each :class:`~mne.time_frequency.Spectrum`\n        instance, or a string describing the weighting strategy to apply: 'nave'\n        computes sum-to-one weights proportional to each object\u2019s nave attribute;\n        'equal' weights each :class:`~mne.time_frequency.Spectrum` by\n        ``1 / len(all_spectrum)``.\n\n    Returns\n    -------\n    spectrum : Spectrum\n        The new spectral data.\n\n    Notes\n    -----\n    .. versionadded:: 1.10.0\n    \"\"\"\n    spectrum = all_spectrum[0].copy()\n    if isinstance(weights, str):\n        if weights not in (\"nave\", \"equal\"):\n            raise ValueError('Weights must be a list of float, or \"nave\" or \"equal\"')\n        if weights == \"nave\":\n            for s_ in all_spectrum:\n                if s_.nave is None:\n                    raise ValueError(f\"The 'nave' attribute is not specified for {s_}\")\n            weights = np.array([e.nave for e in all_spectrum], float)\n            weights /= weights.sum()\n        else:  # == 'equal'\n            weights = [1.0 / len(all_spectrum)] * len(all_spectrum)\n    weights = np.array(weights, float)\n    if weights.ndim != 1 or weights.size != len(all_spectrum):\n        raise ValueError(\"Weights must be the same size as all_spectrum\")\n\n    ch_names = spectrum.ch_names\n    for s_ in all_spectrum[1:]:\n        assert s_.ch_names == ch_names, (\n            f\"{spectrum} and {s_} do not contain the same channels\"\n        )\n        assert np.max(np.abs(s_.freqs - spectrum.freqs)) < 1e-7, (\n            f\"{spectrum} and {s_} do not contain the same frequencies\"\n        )\n\n    # use union of bad channels\n    bads = list(\n        set(spectrum.info[\"bads\"]).union(*(s_.info[\"bads\"] for s_ in all_spectrum[1:]))\n    )\n    spectrum.info[\"bads\"] = bads\n\n    # combine spectral data\n    spectrum._data = sum(w * s_.data for w, s_ in zip(weights, all_spectrum))\n    if spectrum.nave is not None:\n        spectrum._nave = max(\n            int(1.0 / sum(w**2 / s_.nave for w, s_ in zip(weights, all_spectrum))), 1\n        )\n    return spectrum", "metadata": {}}
{"_id": "mne_mne_time_frequency/spectrum.py_read_spectrum_code", "title": "read_spectrum", "text": "def read_spectrum(fname):\n    \"\"\"Load a :class:`mne.time_frequency.Spectrum` object from disk.\n\n    Parameters\n    ----------\n    fname : path-like\n        Path to a spectrum file in HDF5 format, which should end with ``.h5`` or\n        ``.hdf5``.\n\n    Returns\n    -------\n    spectrum : instance of Spectrum\n        The loaded Spectrum object.\n\n    See Also\n    --------\n    mne.time_frequency.Spectrum.save\n    \"\"\"\n    read_hdf5, _ = _import_h5io_funcs()\n    _validate_type(fname, \"path-like\", \"fname\")\n    fname = _check_fname(fname=fname, overwrite=\"read\", must_exist=False)\n    # read it in\n    hdf5_dict = read_hdf5(fname, title=\"mnepython\", slash=\"replace\")\n    defaults = dict(\n        method=None,\n        fmin=None,\n        fmax=None,\n        tmin=None,\n        tmax=None,\n        picks=None,\n        exclude=(),\n        proj=None,\n        remove_dc=None,\n        reject_by_annotation=None,\n        n_jobs=None,\n        verbose=None,\n    )\n    Klass = EpochsSpectrum if hdf5_dict[\"inst_type_str\"] == \"Epochs\" else Spectrum\n    return Klass(hdf5_dict, **defaults)", "metadata": {}}
{"_id": "mne_mne_time_frequency/spectrum.py_plot_psd_code", "title": "plot_psd", "text": "def plot_psd(\n        self,\n        fmin=0,\n        fmax=np.inf,\n        tmin=None,\n        tmax=None,\n        picks=None,\n        proj=False,\n        reject_by_annotation=True,\n        *,\n        method=\"auto\",\n        average=False,\n        dB=True,\n        estimate=\"power\",\n        xscale=\"linear\",\n        area_mode=\"std\",\n        area_alpha=0.33,\n        color=\"black\",\n        line_alpha=None,\n        spatial_colors=True,\n        sphere=None,\n        exclude=\"bads\",\n        ax=None,\n        show=True,\n        n_jobs=1,\n        verbose=None,\n        **method_kw,\n    ):\n        \"\"\"%(plot_psd_doc)s.\n\n        Parameters\n        ----------\n        %(fmin_fmax_psd)s\n        %(tmin_tmax_psd)s\n        %(picks_good_data_noref)s\n        %(proj_psd)s\n        %(reject_by_annotation_psd)s\n        %(method_plot_psd_auto)s\n        %(average_plot_psd)s\n        %(dB_plot_psd)s\n        %(estimate_plot_psd)s\n        %(xscale_plot_psd)s\n        %(area_mode_plot_psd)s\n        %(area_alpha_plot_psd)s\n        %(color_plot_psd)s\n        %(line_alpha_plot_psd)s\n        %(spatial_colors_psd)s\n        %(sphere_topomap_auto)s\n\n            .. versionadded:: 0.22.0\n        exclude : list of str | 'bads'\n            Channels names to exclude from being shown. If 'bads', the bad\n            channels are excluded. Pass an empty list to plot all channels\n            (including channels marked \"bad\", if any).\n\n            .. versionadded:: 0.24.0\n        %(ax_plot_psd)s\n        %(show)s\n        %(n_jobs)s\n        %(verbose)s\n        %(method_kw_psd)s\n\n        Returns\n        -------\n        fig : instance of Figure\n            Figure with frequency spectra of the data channels.\n\n        Notes\n        -----\n        %(notes_plot_psd_meth)s\n        \"\"\"\n        init_kw, plot_kw = _split_psd_kwargs(plot_fun=Spectrum.plot)\n        return self.compute_psd(**init_kw).plot(**plot_kw)", "metadata": {}}
{"_id": "mne_mne_time_frequency/spectrum.py_plot_psd_topo_code", "title": "plot_psd_topo", "text": "def plot_psd_topo(\n        self,\n        tmin=None,\n        tmax=None,\n        fmin=0,\n        fmax=100,\n        proj=False,\n        *,\n        method=\"auto\",\n        dB=True,\n        layout=None,\n        color=\"w\",\n        fig_facecolor=\"k\",\n        axis_facecolor=\"k\",\n        axes=None,\n        block=False,\n        show=True,\n        n_jobs=None,\n        verbose=None,\n        **method_kw,\n    ):\n        \"\"\"Plot power spectral density, separately for each channel.\n\n        Parameters\n        ----------\n        %(tmin_tmax_psd)s\n        %(fmin_fmax_psd_topo)s\n        %(proj_psd)s\n        %(method_plot_psd_auto)s\n        %(dB_spectrum_plot_topo)s\n        %(layout_spectrum_plot_topo)s\n        %(color_spectrum_plot_topo)s\n        %(fig_facecolor)s\n        %(axis_facecolor)s\n        %(axes_spectrum_plot_topo)s\n        %(block)s\n        %(show)s\n        %(n_jobs)s\n        %(verbose)s\n        %(method_kw_psd)s Defaults to ``dict(n_fft=2048)``.\n\n        Returns\n        -------\n        fig : instance of matplotlib.figure.Figure\n            Figure distributing one image per channel across sensor topography.\n        \"\"\"\n        init_kw, plot_kw = _split_psd_kwargs(plot_fun=Spectrum.plot_topo)\n        return self.compute_psd(**init_kw).plot_topo(**plot_kw)", "metadata": {}}
{"_id": "mne_mne_time_frequency/spectrum.py_plot_psd_topomap_code", "title": "plot_psd_topomap", "text": "def plot_psd_topomap(\n        self,\n        bands=None,\n        tmin=None,\n        tmax=None,\n        ch_type=None,\n        *,\n        proj=False,\n        method=\"auto\",\n        normalize=False,\n        agg_fun=None,\n        dB=False,\n        sensors=True,\n        show_names=False,\n        mask=None,\n        mask_params=None,\n        contours=0,\n        outlines=\"head\",\n        sphere=None,\n        image_interp=_INTERPOLATION_DEFAULT,\n        extrapolate=_EXTRAPOLATE_DEFAULT,\n        border=_BORDER_DEFAULT,\n        res=64,\n        size=1,\n        cmap=None,\n        vlim=(None, None),\n        cnorm=None,\n        colorbar=True,\n        cbar_fmt=\"auto\",\n        units=None,\n        axes=None,\n        show=True,\n        n_jobs=None,\n        verbose=None,\n        **method_kw,\n    ):\n        \"\"\"Plot scalp topography of PSD for chosen frequency bands.\n\n        Parameters\n        ----------\n        %(bands_psd_topo)s\n        %(tmin_tmax_psd)s\n        %(ch_type_topomap_psd)s\n        %(proj_psd)s\n        %(method_plot_psd_auto)s\n        %(normalize_psd_topo)s\n        %(agg_fun_psd_topo)s\n        %(dB_plot_topomap)s\n        %(sensors_topomap)s\n        %(show_names_topomap)s\n        %(mask_evoked_topomap)s\n        %(mask_params_topomap)s\n        %(contours_topomap)s\n        %(outlines_topomap)s\n        %(sphere_topomap_auto)s\n        %(image_interp_topomap)s\n        %(extrapolate_topomap)s\n        %(border_topomap)s\n        %(res_topomap)s\n        %(size_topomap)s\n        %(cmap_topomap)s\n        %(vlim_plot_topomap_psd)s\n        %(cnorm)s\n\n            .. versionadded:: 1.2\n        %(colorbar_topomap)s\n        %(cbar_fmt_topomap_psd)s\n        %(units_topomap)s\n        %(axes_spectrum_plot_topomap)s\n        %(show)s\n        %(n_jobs)s\n        %(verbose)s\n        %(method_kw_psd)s\n\n        Returns\n        -------\n        fig : instance of Figure\n            Figure showing one scalp topography per frequency band.\n        \"\"\"\n        init_kw, plot_kw = _split_psd_kwargs(plot_fun=Spectrum.plot_topomap)\n        return self.compute_psd(**init_kw).plot_topomap(**plot_kw)", "metadata": {}}
{"_id": "mne_mne_time_frequency/spectrum.py_copy_code", "title": "copy", "text": "def copy(self):\n        \"\"\"Return copy of the Spectrum instance.\n\n        Returns\n        -------\n        spectrum : instance of Spectrum\n            A copy of the object.\n        \"\"\"\n        return deepcopy(self)", "metadata": {}}
{"_id": "mne_mne_time_frequency/spectrum.py_get_data_code", "title": "get_data", "text": "def get_data(\n        self, picks=None, exclude=\"bads\", fmin=0, fmax=np.inf, return_freqs=False\n    ):\n        \"\"\"Get spectrum data in NumPy array format.\n\n        Parameters\n        ----------\n        %(picks_good_data_noref)s\n        %(exclude_spectrum_get_data)s\n        %(fmin_fmax_psd)s\n        return_freqs : bool\n            Whether to return the frequency bin values for the requested\n            frequency range. Default is ``False``.\n\n        Returns\n        -------\n        data : array\n            The requested data in a NumPy array.\n        freqs : array\n            The frequency values for the requested range. Only returned if\n            ``return_freqs`` is ``True``.\n        \"\"\"\n        picks = _picks_to_idx(\n            self.info, picks, \"data_or_ica\", exclude=exclude, with_ref_meg=False\n        )\n        fmin_idx = np.searchsorted(self.freqs, fmin)\n        fmax_idx = np.searchsorted(self.freqs, fmax, side=\"right\")\n        freq_picks = np.arange(fmin_idx, fmax_idx)\n        freq_axis = self._dims.index(\"freq\")\n        chan_axis = self._dims.index(\"channel\")\n        # normally there's a risk of np.take reducing array dimension if there\n        # were only one channel or frequency selected, but `_picks_to_idx`\n        # always returns an array of picks, and np.arange always returns an\n        # array of freq bin indices, so we're safe; the result will always be\n        # 2D.\n        data = self._data.take(picks, chan_axis).take(freq_picks, freq_axis)\n        if return_freqs:\n            freqs = self._freqs[fmin_idx:fmax_idx]\n            return (data, freqs)\n        return data", "metadata": {}}
{"_id": "mne_mne_time_frequency/spectrum.py_plot_code", "title": "plot", "text": "def plot(\n        self,\n        *,\n        picks=None,\n        average=False,\n        dB=True,\n        amplitude=False,\n        xscale=\"linear\",\n        ci=\"sd\",\n        ci_alpha=0.3,\n        color=\"black\",\n        alpha=None,\n        spatial_colors=True,\n        sphere=None,\n        exclude=(),\n        axes=None,\n        show=True,\n    ):\n        \"\"\"%(plot_psd_doc)s.\n\n        Parameters\n        ----------\n        %(picks_all_data_noref)s\n\n            .. versionchanged:: 1.5\n                In version 1.5, the default behavior changed so that all\n                :term:`data channels` (not just \"good\" data channels) are shown by\n                default.\n        average : bool\n            Whether to average across channels before plotting. If ``True``, interactive\n            plotting of scalp topography is disabled, and parameters ``ci`` and\n            ``ci_alpha`` control the style of the confidence band around the mean.\n            Default is ``False``.\n        %(dB_spectrum_plot)s\n        amplitude : bool\n            Whether to plot an amplitude spectrum (``True``) or power spectrum\n            (``False``).\n\n                .. versionchanged:: 1.8\n                    In version 1.8, the default changed to ``amplitude=False``.\n        %(xscale_plot_psd)s\n        ci : float | 'sd' | 'range' | None\n            Type of confidence band drawn around the mean when ``average=True``. If\n            ``'sd'`` the band spans \u00b11 standard deviation across channels. If\n            ``'range'`` the band spans the range across channels at each frequency. If a\n            :class:`float`, it indicates the (bootstrapped) confidence interval to\n            display, and must satisfy ``0 < ci <= 100``. If ``None``, no band is drawn.\n            Default is ``sd``.\n        ci_alpha : float\n            Opacity of the confidence band. Must satisfy ``0 <= ci_alpha <= 1``. Default\n            is 0.3.\n        %(color_plot_psd)s\n        alpha : float | None\n            Opacity of the spectrum line(s). If :class:`float`, must satisfy\n            ``0 <= alpha <= 1``. If ``None``, opacity will be ``1`` when\n            ``average=True`` and ``0.1`` when ``average=False``. Default is ``None``.\n        %(spatial_colors_psd)s\n        %(sphere_topomap_auto)s\n        %(exclude_spectrum_plot)s\n\n            .. versionchanged:: 1.5\n                In version 1.5, the default behavior changed from ``exclude='bads'`` to\n                ``exclude=()``.\n        %(axes_spectrum_plot_topomap)s\n        %(show)s\n\n        Returns\n        -------\n        fig : instance of matplotlib.figure.Figure\n            Figure with spectra plotted in separate subplots for each channel type.\n        \"\"\"\n        # Must nest this _mpl_figure import because of the BACKEND global\n        # stuff\n        from ..viz._mpl_figure import _line_figure, _split_picks_by_type\n\n        # arg checking\n        ci = _check_ci(ci)\n        _check_option(\"xscale\", xscale, (\"log\", \"linear\"))\n        sphere = _check_sphere(sphere, self.info)\n        # defaults\n        scalings = _handle_default(\"scalings\", None)\n        titles = _handle_default(\"titles\", None)\n        units = _handle_default(\"units\", None)\n\n        _validate_type(amplitude, bool, \"amplitude\")\n        estimate = \"amplitude\" if amplitude else \"power\"\n\n        logger.info(f\"Plotting {estimate} spectral density ({dB=}).\")\n\n        # split picks by channel type\n        picks = _picks_to_idx(\n            self.info, picks, \"data\", exclude=exclude, with_ref_meg=False\n        )\n        (picks_list, units_list, scalings_list, titles_list) = _split_picks_by_type(\n            self, picks, units, scalings, titles\n        )\n        # prepare data (e.g. aggregate across dims, convert complex to power)\n        psd_list = [\n            self._prepare_data_for_plot(\n                self._data.take(_p, axis=self._dims.index(\"channel\"))\n            )\n            for _p in picks_list\n        ]\n        # initialize figure\n        fig, axes = _line_figure(self, axes, picks=picks)\n        # don't add ylabels & titles if figure has unexpected number of axes\n        make_label = len(axes) == len(fig.axes)\n        # Plot Frequency [Hz] xlabel only on the last axis\n        xlabels_list = [False] * (len(axes) - 1) + [True]\n        # plot\n        _plot_psd(\n            self,\n            fig,\n            self.freqs,\n            psd_list,\n            picks_list,\n            titles_list,\n            units_list,\n            scalings_list,\n            axes,\n            make_label,\n            color,\n            area_mode=ci,\n            area_alpha=ci_alpha,\n            dB=dB,\n            estimate=estimate,\n            average=average,\n            spatial_colors=spatial_colors,\n            xscale=xscale,\n            line_alpha=alpha,\n            sphere=sphere,\n            xlabels_list=xlabels_list,\n        )\n        plt_show(show, fig)\n        return fig", "metadata": {}}
{"_id": "mne_mne_time_frequency/spectrum.py_plot_topo_code", "title": "plot_topo", "text": "def plot_topo(\n        self,\n        *,\n        dB=True,\n        layout=None,\n        color=\"w\",\n        fig_facecolor=\"k\",\n        axis_facecolor=\"k\",\n        axes=None,\n        block=False,\n        show=True,\n    ):\n        \"\"\"Plot power spectral density, separately for each channel.\n\n        Parameters\n        ----------\n        %(dB_spectrum_plot_topo)s\n        %(layout_spectrum_plot_topo)s\n        %(color_spectrum_plot_topo)s\n        %(fig_facecolor)s\n        %(axis_facecolor)s\n        %(axes_spectrum_plot_topo)s\n        %(block)s\n        %(show)s\n\n        Returns\n        -------\n        fig : instance of matplotlib.figure.Figure\n            Figure distributing one image per channel across sensor topography.\n        \"\"\"\n        if layout is None:\n            layout = find_layout(self.info)\n\n        psds, freqs = self.get_data(return_freqs=True)\n        # prepare data (e.g. aggregate across dims, convert complex to power)\n        psds = self._prepare_data_for_plot(psds)\n        if dB:\n            psds = 10 * np.log10(psds)\n            y_label = \"dB\"\n        else:\n            y_label = \"Power\"\n        show_func = partial(\n            _plot_timeseries_unified, data=[psds], color=color, times=[freqs]\n        )\n        click_func = partial(_plot_timeseries, data=[psds], color=color, times=[freqs])\n        picks = _pick_data_channels(self.info)\n        info = pick_info(self.info, picks)\n        fig = _plot_topo(\n            info,\n            times=freqs,\n            show_func=show_func,\n            click_func=click_func,\n            layout=layout,\n            axis_facecolor=axis_facecolor,\n            fig_facecolor=fig_facecolor,\n            x_label=\"Frequency (Hz)\",\n            unified=True,\n            y_label=y_label,\n            axes=axes,\n        )\n        plt_show(show, block=block)\n        return fig", "metadata": {}}
{"_id": "mne_mne_time_frequency/spectrum.py_plot_topomap_code", "title": "plot_topomap", "text": "def plot_topomap(\n        self,\n        bands=None,\n        ch_type=None,\n        *,\n        normalize=False,\n        agg_fun=None,\n        dB=False,\n        sensors=True,\n        show_names=False,\n        mask=None,\n        mask_params=None,\n        contours=6,\n        outlines=\"head\",\n        sphere=None,\n        image_interp=_INTERPOLATION_DEFAULT,\n        extrapolate=_EXTRAPOLATE_DEFAULT,\n        border=_BORDER_DEFAULT,\n        res=64,\n        size=1,\n        cmap=None,\n        vlim=(None, None),\n        cnorm=None,\n        colorbar=True,\n        cbar_fmt=\"auto\",\n        units=None,\n        axes=None,\n        show=True,\n    ):\n        \"\"\"Plot scalp topography of PSD for chosen frequency bands.\n\n        Parameters\n        ----------\n        %(bands_psd_topo)s\n        %(ch_type_topomap_psd)s\n        %(normalize_psd_topo)s\n        %(agg_fun_psd_topo)s\n        %(dB_plot_topomap)s\n        %(sensors_topomap)s\n        %(show_names_topomap)s\n        %(mask_evoked_topomap)s\n        %(mask_params_topomap)s\n        %(contours_topomap)s\n        %(outlines_topomap)s\n        %(sphere_topomap_auto)s\n        %(image_interp_topomap)s\n        %(extrapolate_topomap)s\n        %(border_topomap)s\n        %(res_topomap)s\n        %(size_topomap)s\n        %(cmap_topomap)s\n        %(vlim_plot_topomap_psd)s\n        %(cnorm)s\n        %(colorbar_topomap)s\n        %(cbar_fmt_topomap_psd)s\n        %(units_topomap)s\n        %(axes_spectrum_plot_topomap)s\n        %(show)s\n\n        Returns\n        -------\n        fig : instance of Figure\n            Figure showing one scalp topography per frequency band.\n        \"\"\"\n        ch_type = _get_plot_ch_type(self, ch_type)\n        if units is None:\n            units = _handle_default(\"units\", None)\n        unit = units[ch_type] if hasattr(units, \"keys\") else units\n        scalings = _handle_default(\"scalings\", None)\n        scaling = scalings[ch_type]\n\n        (\n            picks,\n            pos,\n            merge_channels,\n            names,\n            ch_type,\n            sphere,\n            clip_origin,\n        ) = _prepare_topomap_plot(self, ch_type, sphere=sphere)\n        outlines = _make_head_outlines(sphere, pos, outlines, clip_origin)\n\n        psds, freqs = self.get_data(picks=picks, return_freqs=True)\n        # prepare data (e.g. aggregate across dims, convert complex to power)\n        psds = self._prepare_data_for_plot(psds)\n        psds *= scaling**2\n\n        if merge_channels:\n            psds, names = _merge_ch_data(psds, ch_type, names, method=\"mean\")\n\n        names = _prepare_sensor_names(names, show_names)\n        return plot_psds_topomap(\n            psds=psds,\n            freqs=freqs,\n            pos=pos,\n            bands=bands,\n            ch_type=ch_type,\n            normalize=normalize,\n            agg_fun=agg_fun,\n            dB=dB,\n            sensors=sensors,\n            names=names,\n            mask=mask,\n            mask_params=mask_params,\n            contours=contours,\n            outlines=outlines,\n            sphere=sphere,\n            image_interp=image_interp,\n            extrapolate=extrapolate,\n            border=border,\n            res=res,\n            size=size,\n            cmap=cmap,\n            vlim=vlim,\n            cnorm=cnorm,\n            colorbar=colorbar,\n            cbar_fmt=cbar_fmt,\n            unit=unit,\n            axes=axes,\n            show=show,\n        )", "metadata": {}}
{"_id": "mne_mne_time_frequency/spectrum.py_save_code", "title": "save", "text": "def save(self, fname, *, overwrite=False, verbose=None):\n        \"\"\"Save spectrum data to disk (in HDF5 format).\n\n        Parameters\n        ----------\n        fname : path-like\n            Path of file to save to.\n        %(overwrite)s\n        %(verbose)s\n\n        See Also\n        --------\n        mne.time_frequency.read_spectrum\n        \"\"\"\n        _, write_hdf5 = _import_h5io_funcs()\n        check_fname(fname, \"spectrum\", (\".h5\", \".hdf5\"))\n        fname = _check_fname(fname, overwrite=overwrite, verbose=verbose)\n        out = self.__getstate__()\n        write_hdf5(fname, out, overwrite=overwrite, title=\"mnepython\", slash=\"replace\")", "metadata": {}}
{"_id": "mne_mne_time_frequency/spectrum.py_to_data_frame_code", "title": "to_data_frame", "text": "def to_data_frame(\n        self, picks=None, index=None, copy=True, long_format=False, *, verbose=None\n    ):\n        \"\"\"Export data in tabular structure as a pandas DataFrame.\n\n        Channels are converted to columns in the DataFrame. By default,\n        an additional column \"freq\" is added, unless ``index='freq'``\n        (in which case frequency values form the DataFrame's index).\n\n        Parameters\n        ----------\n        %(picks_all)s\n        index : str | list of str | None\n            Kind of index to use for the DataFrame. If ``None``, a sequential\n            integer index (:class:`pandas.RangeIndex`) will be used. If a\n            :class:`str`, a :class:`pandas.Index` will be used (see Notes). If\n            a list of two or more string values, a :class:`pandas.MultiIndex`\n            will be used. Defaults to ``None``.\n        %(copy_df)s\n        %(long_format_df_spe)s\n        %(verbose)s\n\n        Returns\n        -------\n        %(df_return)s\n\n        Notes\n        -----\n        Valid values for ``index`` depend on whether the Spectrum was created\n        from continuous data (:class:`~mne.io.Raw`, :class:`~mne.Evoked`) or\n        discontinuous data (:class:`~mne.Epochs`). For continuous data, only\n        ``None`` or ``'freq'`` is supported. For discontinuous data, additional\n        valid values are ``'epoch'`` and ``'condition'``, or a :class:`list`\n        comprising some of the valid string values (e.g.,\n        ``['freq', 'epoch']``).\n        \"\"\"\n        # check pandas once here, instead of in each private utils function\n        pd = _check_pandas_installed()  # noqa\n        # triage for Epoch-derived or unaggregated spectra\n        from_epo = _get_instance_type_string(self) == \"Epochs\"\n        unagg_welch = \"segment\" in self._dims\n        unagg_mt = \"taper\" in self._dims\n        # arg checking\n        valid_index_args = [\"freq\"]\n        if from_epo:\n            valid_index_args += [\"epoch\", \"condition\"]\n        index = _check_pandas_index_arguments(index, valid_index_args)\n        # get data\n        picks = _picks_to_idx(self.info, picks, \"all\", exclude=())\n        data = self.get_data(picks)\n        if copy:\n            data = data.copy()\n        # reshape\n        if unagg_mt:\n            data = np.moveaxis(data, self._dims.index(\"freq\"), -2)\n        if from_epo:\n            n_epochs, n_picks, n_freqs = data.shape[:3]\n        else:\n            n_epochs, n_picks, n_freqs = (1,) + data.shape[:2]\n        n_segs = data.shape[-1] if unagg_mt or unagg_welch else 1\n        data = np.moveaxis(data, self._dims.index(\"channel\"), -1)\n        # at this point, should be ([epoch], freq, [segment/taper], channel)\n        data = data.reshape(n_epochs * n_freqs * n_segs, n_picks)\n        # prepare extra columns / multiindex\n        mindex = list()\n        default_index = list()\n        if from_epo:\n            rev_event_id = {v: k for k, v in self.event_id.items()}\n            _conds = [rev_event_id[k] for k in self.events[:, 2]]\n            conditions = np.repeat(_conds, n_freqs * n_segs)\n            epoch_nums = np.repeat(self.selection, n_freqs * n_segs)\n            mindex.extend([(\"condition\", conditions), (\"epoch\", epoch_nums)])\n            default_index.extend([\"condition\", \"epoch\"])\n        freqs = np.tile(np.repeat(self.freqs, n_segs), n_epochs)\n        mindex.append((\"freq\", freqs))\n        default_index.append(\"freq\")\n        if unagg_mt or unagg_welch:\n            name = \"taper\" if unagg_mt else \"segment\"\n            seg_nums = np.tile(np.arange(n_segs), n_epochs * n_freqs)\n            mindex.append((name, seg_nums))\n            default_index.append(name)\n        # build DataFrame\n        df = _build_data_frame(\n            self, data, picks, long_format, mindex, index, default_index=default_index\n        )\n        return df", "metadata": {}}
{"_id": "mne_mne_time_frequency/spectrum.py_units_code", "title": "units", "text": "def units(self, latex=False):\n        \"\"\"Get the spectrum units for each channel type.\n\n        Parameters\n        ----------\n        latex : bool\n            Whether to format the unit strings as LaTeX. Default is ``False``.\n\n        Returns\n        -------\n        units : dict\n            Mapping from channel type to a string representation of the units\n            for that channel type.\n        \"\"\"\n        units = _handle_default(\"si_units\", None)\n        return {\n            ch_type: _format_units_psd(units[ch_type], power=True, latex=latex)\n            for ch_type in sorted(self.get_channel_types(unique=True))\n        }", "metadata": {}}
{"_id": "mne_mne_time_frequency/spectrum.py_average_code", "title": "average", "text": "def average(self, method=\"mean\"):\n        \"\"\"Average the spectra across epochs.\n\n        Parameters\n        ----------\n        method : 'mean' | 'median' | callable\n            How to aggregate spectra across epochs. If callable, must take a\n            :class:`NumPy array<numpy.ndarray>` of shape\n            ``(n_epochs, n_channels, n_freqs)`` and return an array of shape\n            ``(n_channels, n_freqs)``. Default is ``'mean'``.\n\n        Returns\n        -------\n        spectrum : instance of Spectrum\n            The aggregated spectrum object.\n        \"\"\"\n        _validate_type(method, (\"str\", \"callable\"), \"method\")\n        method = _make_combine_callable(\n            method, axis=0, valid=(\"mean\", \"median\"), keepdims=False\n        )\n        if not callable(method):\n            raise ValueError(\n                '\"method\" must be a valid string or callable, '\n                f\"got a {type(method).__name__} ({method}).\"\n            )\n        # averaging unaggregated spectral estimates are not supported\n        if \"segment\" in self._dims:\n            raise NotImplementedError(\n                \"Averaging individual Welch segments across epochs is not \"\n                \"supported. Consider averaging the signals before computing \"\n                \"the Welch spectrum estimates.\"\n            )\n        if \"taper\" in self._dims:\n            raise NotImplementedError(\n                \"Averaging multitaper tapers across epochs is not supported. Consider \"\n                \"averaging the signals before computing the complex spectrum.\"\n            )\n        # serialize the object and update data, dims, and data type\n        state = super().__getstate__()\n        state[\"nave\"] = state[\"data\"].shape[0]\n        state[\"data\"] = method(state[\"data\"])\n        state[\"dims\"] = state[\"dims\"][1:]\n        state[\"data_type\"] = f\"Averaged {state['data_type']}\"\n        defaults = dict(\n            method=None,\n            fmin=None,\n            fmax=None,\n            tmin=None,\n            tmax=None,\n            picks=None,\n            exclude=(),\n            proj=None,\n            remove_dc=None,\n            reject_by_annotation=None,\n            n_jobs=None,\n            verbose=None,\n        )\n        return Spectrum(state, **defaults)", "metadata": {}}
{"_id": "mne_mne_time_frequency/_stockwell.py_tfr_array_stockwell_code", "title": "tfr_array_stockwell", "text": "def tfr_array_stockwell(\n    data,\n    sfreq,\n    fmin=None,\n    fmax=None,\n    n_fft=None,\n    width=1.0,\n    decim=1,\n    return_itc=False,\n    n_jobs=None,\n    *,\n    verbose=None,\n):\n    \"\"\"Compute power and intertrial coherence using Stockwell (S) transform.\n\n    Same computation as `~mne.time_frequency.tfr_stockwell`, but operates on\n    :class:`NumPy arrays <numpy.ndarray>` instead of `~mne.Epochs` objects.\n\n    See :footcite:`Stockwell2007,MoukademEtAl2014,WheatEtAl2010,JonesEtAl2006`\n    for more information.\n\n    Parameters\n    ----------\n    data : ndarray, shape (n_epochs, n_channels, n_times)\n        The signal to transform.\n    sfreq : float\n        The sampling frequency.\n    fmin : None, float\n        The minimum frequency to include. If None defaults to the minimum fft\n        frequency greater than zero.\n    fmax : None, float\n        The maximum frequency to include. If None defaults to the maximum fft.\n    n_fft : int | None\n        The length of the windows used for FFT. If None, it defaults to the\n        next power of 2 larger than the signal length.\n    width : float\n        The width of the Gaussian window. If < 1, increased temporal\n        resolution, if > 1, increased frequency resolution. Defaults to 1.\n        (classical S-Transform).\n    %(decim_tfr)s\n    return_itc : bool\n        Return intertrial coherence (ITC) as well as averaged power.\n    %(n_jobs)s\n    %(verbose)s\n\n    Returns\n    -------\n    st_power : ndarray\n        The multitaper power of the Stockwell transformed data.\n        The last two dimensions are frequency and time.\n    itc : ndarray\n        The intertrial coherence. Only returned if return_itc is True.\n    freqs : ndarray\n        The frequencies.\n\n    See Also\n    --------\n    mne.time_frequency.tfr_stockwell\n    mne.time_frequency.tfr_multitaper\n    mne.time_frequency.tfr_array_multitaper\n    mne.time_frequency.tfr_morlet\n    mne.time_frequency.tfr_array_morlet\n\n    References\n    ----------\n    .. footbibliography::\n    \"\"\"\n    _validate_type(data, np.ndarray, \"data\")\n    if data.ndim != 3:\n        raise ValueError(\n            \"data must be 3D with shape (n_epochs, n_channels, n_times), \"\n            f\"got {data.shape}\"\n        )\n    decim = _ensure_slice(decim)\n    _, n_channels, n_out = data[..., decim].shape\n    data, n_fft_, zero_pad = _check_input_st(data, n_fft)\n    start_f, stop_f, freqs = _compute_freqs_st(fmin, fmax, n_fft_, sfreq)\n\n    W = _precompute_st_windows(data.shape[-1], start_f, stop_f, sfreq, width)\n    n_freq = stop_f - start_f\n    psd = np.empty((n_channels, n_freq, n_out))\n    itc = np.empty((n_channels, n_freq, n_out)) if return_itc else None\n\n    parallel, my_st, n_jobs = parallel_func(_st_power_itc, n_jobs, verbose=verbose)\n    tfrs = parallel(\n        my_st(data[:, c, :], start_f, return_itc, zero_pad, decim, W)\n        for c in range(n_channels)\n    )\n    for c, (this_psd, this_itc) in enumerate(iter(tfrs)):\n        psd[c] = this_psd\n        if this_itc is not None:\n            itc[c] = this_itc\n\n    return psd, itc, freqs", "metadata": {}}
{"_id": "mne_mne_time_frequency/_stockwell.py_tfr_stockwell_code", "title": "tfr_stockwell", "text": "def tfr_stockwell(\n    inst,\n    fmin=None,\n    fmax=None,\n    n_fft=None,\n    width=1.0,\n    decim=1,\n    return_itc=False,\n    n_jobs=None,\n    verbose=None,\n):\n    \"\"\"Compute Time-Frequency Representation (TFR) using Stockwell Transform.\n\n    Same computation as `~mne.time_frequency.tfr_array_stockwell`, but operates\n    on `~mne.Epochs` objects instead of :class:`NumPy arrays <numpy.ndarray>`.\n\n    See :footcite:`Stockwell2007,MoukademEtAl2014,WheatEtAl2010,JonesEtAl2006`\n    for more information.\n\n    Parameters\n    ----------\n    inst : Epochs | Evoked\n        The epochs or evoked object.\n    fmin : None, float\n        The minimum frequency to include. If None defaults to the minimum fft\n        frequency greater than zero.\n    fmax : None, float\n        The maximum frequency to include. If None defaults to the maximum fft.\n    n_fft : int | None\n        The length of the windows used for FFT. If None, it defaults to the\n        next power of 2 larger than the signal length.\n    width : float\n        The width of the Gaussian window. If < 1, increased temporal\n        resolution, if > 1, increased frequency resolution. Defaults to 1.\n        (classical S-Transform).\n    decim : int\n        The decimation factor on the time axis. To reduce memory usage.\n    return_itc : bool\n        Return intertrial coherence (ITC) as well as averaged power.\n    n_jobs : int\n        The number of jobs to run in parallel (over channels).\n    %(verbose)s\n\n    Returns\n    -------\n    power : AverageTFR\n        The averaged power.\n    itc : AverageTFR\n        The intertrial coherence. Only returned if return_itc is True.\n\n    See Also\n    --------\n    mne.time_frequency.tfr_array_stockwell\n    mne.time_frequency.tfr_multitaper\n    mne.time_frequency.tfr_array_multitaper\n    mne.time_frequency.tfr_morlet\n    mne.time_frequency.tfr_array_morlet\n\n    Notes\n    -----\n    .. versionadded:: 0.9.0\n\n    References\n    ----------\n    .. footbibliography::\n    \"\"\"\n    # verbose dec is used b/c subfunctions are verbose\n    data = _get_data(inst, return_itc)\n    picks = _pick_data_channels(inst.info)\n    info = pick_info(inst.info, picks)\n    data = data[:, picks, :]\n    decim = _ensure_slice(decim)\n    power, itc, freqs = tfr_array_stockwell(\n        data,\n        sfreq=info[\"sfreq\"],\n        fmin=fmin,\n        fmax=fmax,\n        n_fft=n_fft,\n        width=width,\n        decim=decim,\n        return_itc=return_itc,\n        n_jobs=n_jobs,\n    )\n    times = inst.times[decim].copy()\n    nave = len(data)\n    out = AverageTFRArray(\n        info=info,\n        data=power,\n        times=times,\n        freqs=freqs,\n        nave=nave,\n        method=\"stockwell-power\",\n    )\n    if return_itc:\n        out = (\n            out,\n            AverageTFRArray(\n                info=deepcopy(info),\n                data=itc,\n                times=times.copy(),\n                freqs=freqs.copy(),\n                nave=nave,\n                method=\"stockwell-itc\",\n            ),\n        )\n    return out", "metadata": {}}
{"_id": "mne_mne_time_frequency/csd.py_pick_channels_csd_code", "title": "pick_channels_csd", "text": "def pick_channels_csd(\n    csd, include=(), exclude=(), ordered=True, copy=True, *, verbose=None\n):\n    \"\"\"Pick channels from cross-spectral density matrix.\n\n    Parameters\n    ----------\n    csd : instance of CrossSpectralDensity\n        The CSD object to select the channels from.\n    include : list of str\n        List of channels to include (if empty, include all available).\n    exclude : list of str\n        Channels to exclude (if empty, do not exclude any).\n    %(ordered)s\n    copy : bool\n        If True (the default), return a copy of the CSD matrix with the\n        modified channels. If False, channels are modified in-place.\n\n        .. versionadded:: 0.20.0\n    %(verbose)s\n\n    Returns\n    -------\n    res : instance of CrossSpectralDensity\n        Cross-spectral density restricted to selected channels.\n    \"\"\"\n    if copy:\n        csd = csd.copy()\n\n    sel = pick_channels(csd.ch_names, include=include, exclude=exclude, ordered=ordered)\n    data = []\n    for vec in csd._data.T:\n        mat = _vector_to_sym_mat(vec)\n        mat = mat[sel, :][:, sel]\n        data.append(_sym_mat_to_vector(mat))\n    ch_names = [csd.ch_names[i] for i in sel]\n\n    csd._data = np.array(data).T\n    csd.ch_names = ch_names\n    return csd", "metadata": {}}
{"_id": "mne_mne_time_frequency/csd.py_read_csd_code", "title": "read_csd", "text": "def read_csd(fname):\n    \"\"\"Read a CrossSpectralDensity object from an HDF5 file.\n\n    Parameters\n    ----------\n    fname : path-like\n        The name of the file to read the CSD from. The extension ``'.h5'`` will\n        be appended if the given filename doesn't have it already.\n\n    Returns\n    -------\n    csd : instance of CrossSpectralDensity\n        The CSD that was stored in the file.\n\n    See Also\n    --------\n    CrossSpectralDensity.save : For saving CSD objects.\n    \"\"\"\n    read_hdf5, _ = _import_h5io_funcs()\n    if not fname.endswith(\".h5\"):\n        fname += \".h5\"\n\n    csd_dict = read_hdf5(fname, title=\"conpy\")\n\n    if csd_dict[\"projs\"] is not None:\n        # Avoid circular import\n        from ..proj import Projection\n\n        csd_dict[\"projs\"] = [Projection(**proj) for proj in csd_dict[\"projs\"]]\n\n    return CrossSpectralDensity(**csd_dict)", "metadata": {}}
{"_id": "mne_mne_time_frequency/csd.py_csd_fourier_code", "title": "csd_fourier", "text": "def csd_fourier(\n    epochs,\n    fmin=0,\n    fmax=np.inf,\n    tmin=None,\n    tmax=None,\n    picks=None,\n    n_fft=None,\n    projs=None,\n    n_jobs=None,\n    *,\n    verbose=None,\n):\n    \"\"\"Estimate cross-spectral density from an array using short-time fourier.\n\n    Parameters\n    ----------\n    epochs : instance of Epochs\n        The epochs to compute the CSD for.\n    fmin : float\n        Minimum frequency of interest, in Hertz.\n    fmax : float | np.inf\n        Maximum frequency of interest, in Hertz.\n    tmin : float | None\n        Minimum time instant to consider, in seconds. If ``None`` start at\n        first sample.\n    tmax : float | None\n        Maximum time instant to consider, in seconds. If ``None`` end at last\n        sample.\n    %(picks_good_data_noref)s\n    n_fft : int | None\n        Length of the FFT. If ``None``, the exact number of samples between\n        ``tmin`` and ``tmax`` will be used.\n    projs : list of Projection | None\n        List of projectors to store in the CSD object. Defaults to ``None``,\n        which means the projectors defined in the Epochs object will be copied.\n    %(n_jobs)s\n    %(verbose)s\n\n    Returns\n    -------\n    csd : instance of CrossSpectralDensity\n        The computed cross-spectral density.\n\n    See Also\n    --------\n    csd_array_fourier\n    csd_array_morlet\n    csd_array_multitaper\n    csd_morlet\n    csd_multitaper\n    \"\"\"\n    epochs, projs = _prepare_csd(epochs, tmin, tmax, picks, projs)\n    return csd_array_fourier(\n        epochs.get_data(copy=False),\n        sfreq=epochs.info[\"sfreq\"],\n        t0=epochs.tmin,\n        fmin=fmin,\n        fmax=fmax,\n        tmin=tmin,\n        tmax=tmax,\n        ch_names=epochs.ch_names,\n        n_fft=n_fft,\n        projs=projs,\n        n_jobs=n_jobs,\n        verbose=verbose,\n    )", "metadata": {}}
{"_id": "mne_mne_time_frequency/csd.py_csd_array_fourier_code", "title": "csd_array_fourier", "text": "def csd_array_fourier(\n    X,\n    sfreq,\n    t0=0,\n    fmin=0,\n    fmax=np.inf,\n    tmin=None,\n    tmax=None,\n    ch_names=None,\n    n_fft=None,\n    projs=None,\n    n_jobs=None,\n    *,\n    verbose=None,\n):\n    \"\"\"Estimate cross-spectral density from an array using short-time fourier.\n\n    Parameters\n    ----------\n    X : array-like, shape (n_epochs, n_channels, n_times)\n        The time series data consisting of n_epochs separate observations\n        of signals with n_channels time-series of length n_times.\n    sfreq : float\n        Sampling frequency of observations.\n    t0 : float\n        Time of the first sample relative to the onset of the epoch, in\n        seconds. Defaults to 0.\n    fmin : float\n        Minimum frequency of interest, in Hertz.\n    fmax : float | np.inf\n        Maximum frequency of interest, in Hertz.\n    tmin : float | None\n        Minimum time instant to consider, in seconds. If ``None`` start at\n        first sample.\n    tmax : float | None\n        Maximum time instant to consider, in seconds. If ``None`` end at last\n        sample.\n    ch_names : list of str | None\n        A name for each time series. If ``None`` (the default), the series will\n        be named 'SERIES###'.\n    n_fft : int | None\n        Length of the FFT. If ``None``, the exact number of samples between\n        ``tmin`` and ``tmax`` will be used.\n    projs : list of Projection | None\n        List of projectors to store in the CSD object. Defaults to ``None``,\n        which means no projectors are stored.\n    %(n_jobs)s\n    %(verbose)s\n\n    Returns\n    -------\n    csd : instance of CrossSpectralDensity\n        The computed cross-spectral density.\n\n    See Also\n    --------\n    csd_array_morlet\n    csd_array_multitaper\n    csd_fourier\n    csd_morlet\n    csd_multitaper\n    \"\"\"\n    X, times, tmin, tmax, fmin, fmax = _prepare_csd_array(\n        X, sfreq, t0, tmin, tmax, fmin, fmax\n    )\n\n    # Slice X to the requested time window\n    tstart = None if tmin is None else np.searchsorted(times, tmin - 1e-10)\n    tstop = None if tmax is None else np.searchsorted(times, tmax + 1e-10)\n    X = X[:, :, tstart:tstop]\n    times = times[tstart:tstop]\n    n_times = len(times)\n    n_fft = n_times if n_fft is None else n_fft\n\n    # Preparing frequencies of interest\n    orig_frequencies = rfftfreq(n_fft, 1.0 / sfreq)\n    freq_mask = (\n        (orig_frequencies > 0) & (orig_frequencies >= fmin) & (orig_frequencies <= fmax)\n    )\n    frequencies = orig_frequencies[freq_mask]\n\n    if len(frequencies) == 0:\n        raise ValueError(\n            \"No discrete fourier transform results within \"\n            \"the given frequency window. Please widen either \"\n            \"the frequency window or the time window\"\n        )\n\n    # Compute the CSD\n    return _execute_csd_function(\n        X,\n        times,\n        frequencies,\n        _csd_fourier,\n        params=[sfreq, n_times, freq_mask, n_fft],\n        n_fft=n_fft,\n        ch_names=ch_names,\n        projs=projs,\n        n_jobs=n_jobs,\n        verbose=verbose,\n    )", "metadata": {}}
{"_id": "mne_mne_time_frequency/csd.py_csd_multitaper_code", "title": "csd_multitaper", "text": "def csd_multitaper(\n    epochs,\n    fmin=0,\n    fmax=np.inf,\n    tmin=None,\n    tmax=None,\n    picks=None,\n    n_fft=None,\n    bandwidth=None,\n    adaptive=False,\n    low_bias=True,\n    projs=None,\n    n_jobs=None,\n    *,\n    verbose=None,\n):\n    \"\"\"Estimate cross-spectral density from epochs using a multitaper method.\n\n    Parameters\n    ----------\n    epochs : instance of Epochs\n        The epochs to compute the CSD for.\n    fmin : float | None\n        Minimum frequency of interest, in Hertz.\n    fmax : float | np.inf\n        Maximum frequency of interest, in Hertz.\n    tmin : float\n        Minimum time instant to consider, in seconds. If ``None`` start at\n        first sample.\n    tmax : float | None\n        Maximum time instant to consider, in seconds. If ``None`` end at last\n        sample.\n    %(picks_good_data_noref)s\n    n_fft : int | None\n        Length of the FFT. If ``None``, the exact number of samples between\n        ``tmin`` and ``tmax`` will be used.\n    bandwidth : float | None\n        The bandwidth of the multitaper windowing function in Hz.\n    adaptive : bool\n        Use adaptive weights to combine the tapered spectra into PSD.\n    low_bias : bool\n        Only use tapers with more than 90%% spectral concentration within\n        bandwidth.\n    projs : list of Projection | None\n        List of projectors to store in the CSD object. Defaults to ``None``,\n        which means the projectors defined in the Epochs object will by copied.\n    %(n_jobs)s\n    %(verbose)s\n\n    Returns\n    -------\n    csd : instance of CrossSpectralDensity\n        The computed cross-spectral density.\n\n    See Also\n    --------\n    csd_array_fourier\n    csd_array_morlet\n    csd_array_multitaper\n    csd_fourier\n    csd_morlet\n    \"\"\"\n    epochs, projs = _prepare_csd(epochs, tmin, tmax, picks, projs)\n    return csd_array_multitaper(\n        epochs.get_data(copy=False),\n        sfreq=epochs.info[\"sfreq\"],\n        t0=epochs.tmin,\n        fmin=fmin,\n        fmax=fmax,\n        tmin=tmin,\n        tmax=tmax,\n        ch_names=epochs.ch_names,\n        n_fft=n_fft,\n        bandwidth=bandwidth,\n        adaptive=adaptive,\n        low_bias=low_bias,\n        projs=projs,\n        n_jobs=n_jobs,\n        verbose=verbose,\n    )", "metadata": {}}
{"_id": "mne_mne_time_frequency/csd.py_csd_array_multitaper_code", "title": "csd_array_multitaper", "text": "def csd_array_multitaper(\n    X,\n    sfreq,\n    t0=0,\n    fmin=0,\n    fmax=np.inf,\n    tmin=None,\n    tmax=None,\n    ch_names=None,\n    n_fft=None,\n    bandwidth=None,\n    adaptive=False,\n    low_bias=True,\n    projs=None,\n    n_jobs=None,\n    max_iter=250,\n    *,\n    verbose=None,\n):\n    \"\"\"Estimate cross-spectral density from an array using a multitaper method.\n\n    Parameters\n    ----------\n    X : array-like, shape (n_epochs, n_channels, n_times)\n        The time series data consisting of n_epochs separate observations\n        of signals with n_channels time-series of length n_times.\n    sfreq : float\n        Sampling frequency of observations.\n    t0 : float\n        Time of the first sample relative to the onset of the epoch, in\n        seconds. Defaults to 0.\n    fmin : float\n        Minimum frequency of interest, in Hertz.\n    fmax : float | np.inf\n        Maximum frequency of interest, in Hertz.\n    tmin : float | None\n        Minimum time instant to consider, in seconds. If ``None`` start at\n        first sample.\n    tmax : float | None\n        Maximum time instant to consider, in seconds. If ``None`` end at last\n        sample.\n    ch_names : list of str | None\n        A name for each time series. If ``None`` (the default), the series will\n        be named 'SERIES###'.\n    n_fft : int | None\n        Length of the FFT. If ``None``, the exact number of samples between\n        ``tmin`` and ``tmax`` will be used.\n    bandwidth : float | None\n        The bandwidth of the multitaper windowing function in Hz.\n    adaptive : bool\n        Use adaptive weights to combine the tapered spectra into PSD.\n    low_bias : bool\n        Only use tapers with more than 90%% spectral concentration within\n        bandwidth.\n    projs : list of Projection | None\n        List of projectors to store in the CSD object. Defaults to ``None``,\n        which means no projectors are stored.\n    %(n_jobs)s\n    %(max_iter_multitaper)s\n    %(verbose)s\n\n    Returns\n    -------\n    csd : instance of CrossSpectralDensity\n        The computed cross-spectral density.\n\n    See Also\n    --------\n    csd_array_fourier\n    csd_array_morlet\n    csd_fourier\n    csd_morlet\n    csd_multitaper\n    \"\"\"\n    X, times, tmin, tmax, fmin, fmax = _prepare_csd_array(\n        X, sfreq, t0, tmin, tmax, fmin, fmax\n    )\n\n    # Slice X to the requested time window\n    tstart = None if tmin is None else np.searchsorted(times, tmin - 1e-10)\n    tstop = None if tmax is None else np.searchsorted(times, tmax + 1e-10)\n    X = X[:, :, tstart:tstop]\n    times = times[tstart:tstop]\n    n_times = len(times)\n    n_fft = n_times if n_fft is None else n_fft\n\n    window_fun, eigvals, adaptive = _compute_mt_params(\n        n_times, sfreq, bandwidth, low_bias, adaptive\n    )\n\n    # Preparing frequencies of interest\n    orig_frequencies = rfftfreq(n_fft, 1.0 / sfreq)\n    freq_mask = (\n        (orig_frequencies > 0) & (orig_frequencies >= fmin) & (orig_frequencies <= fmax)\n    )\n    frequencies = orig_frequencies[freq_mask]\n\n    if len(frequencies) == 0:\n        raise ValueError(\n            \"No discrete fourier transform results within \"\n            \"the given frequency window. Please widen either \"\n            \"the frequency window or the time window\"\n        )\n\n    # Compute the CSD\n    return _execute_csd_function(\n        X,\n        times,\n        frequencies,\n        _csd_multitaper,\n        params=[\n            sfreq,\n            n_times,\n            window_fun,\n            eigvals,\n            freq_mask,\n            n_fft,\n            adaptive,\n            max_iter,\n        ],\n        n_fft=n_fft,\n        ch_names=ch_names,\n        projs=projs,\n        n_jobs=n_jobs,\n        verbose=verbose,\n    )", "metadata": {}}
{"_id": "mne_mne_time_frequency/csd.py_csd_morlet_code", "title": "csd_morlet", "text": "def csd_morlet(\n    epochs,\n    frequencies,\n    tmin=None,\n    tmax=None,\n    picks=None,\n    n_cycles=7,\n    use_fft=True,\n    decim=1,\n    projs=None,\n    n_jobs=None,\n    *,\n    verbose=None,\n):\n    \"\"\"Estimate cross-spectral density from epochs using Morlet wavelets.\n\n    Parameters\n    ----------\n    epochs : instance of Epochs\n        The epochs to compute the CSD for.\n    frequencies : list of float\n        The frequencies of interest, in Hertz.\n    tmin : float | None\n        Minimum time instant to consider, in seconds. If ``None`` start at\n        first sample.\n    tmax : float | None\n        Maximum time instant to consider, in seconds. If ``None`` end at last\n        sample.\n    %(picks_good_data_noref)s\n    n_cycles : float | list of float | None\n        Number of cycles to use when constructing Morlet wavelets. Fixed number\n        or one per frequency. Defaults to 7.\n    use_fft : bool\n        Whether to use FFT-based convolution to compute the wavelet transform.\n        Defaults to True.\n    decim : int | slice\n        To reduce memory usage, decimation factor during time-frequency\n        decomposition. Defaults to 1 (no decimation).\n\n        If `int`, uses tfr[..., ::decim].\n        If `slice`, uses tfr[..., decim].\n\n    projs : list of Projection | None\n        List of projectors to store in the CSD object. Defaults to ``None``,\n        which means the projectors defined in the Epochs object will be copied.\n    %(n_jobs)s\n    %(verbose)s\n\n    Returns\n    -------\n    csd : instance of CrossSpectralDensity\n        The computed cross-spectral density.\n\n    See Also\n    --------\n    csd_array_fourier\n    csd_array_morlet\n    csd_array_multitaper\n    csd_fourier\n    csd_multitaper\n    \"\"\"\n    epochs, projs = _prepare_csd(epochs, tmin, tmax, picks, projs)\n    return csd_array_morlet(\n        epochs.get_data(copy=False),\n        sfreq=epochs.info[\"sfreq\"],\n        frequencies=frequencies,\n        t0=epochs.tmin,\n        tmin=tmin,\n        tmax=tmax,\n        ch_names=epochs.ch_names,\n        n_cycles=n_cycles,\n        use_fft=use_fft,\n        decim=decim,\n        projs=projs,\n        n_jobs=n_jobs,\n        verbose=verbose,\n    )", "metadata": {}}
{"_id": "mne_mne_time_frequency/csd.py_csd_array_morlet_code", "title": "csd_array_morlet", "text": "def csd_array_morlet(\n    X,\n    sfreq,\n    frequencies,\n    t0=0,\n    tmin=None,\n    tmax=None,\n    ch_names=None,\n    n_cycles=7,\n    use_fft=True,\n    decim=1,\n    projs=None,\n    n_jobs=None,\n    *,\n    verbose=None,\n):\n    \"\"\"Estimate cross-spectral density from an array using Morlet wavelets.\n\n    Parameters\n    ----------\n    X : array-like, shape (n_epochs, n_channels, n_times)\n        The time series data consisting of n_epochs separate observations\n        of signals with n_channels time-series of length n_times.\n    sfreq : float\n        Sampling frequency of observations.\n    frequencies : list of float\n        The frequencies of interest, in Hertz.\n    t0 : float\n        Time of the first sample relative to the onset of the epoch, in\n        seconds. Defaults to 0.\n    tmin : float | None\n        Minimum time instant to consider, in seconds. If ``None`` start at\n        first sample.\n    tmax : float | None\n        Maximum time instant to consider, in seconds. If ``None`` end at last\n        sample.\n    ch_names : list of str | None\n        A name for each time series. If ``None`` (the default), the series will\n        be named 'SERIES###'.\n    n_cycles : float | list of float | None\n        Number of cycles to use when constructing Morlet wavelets. Fixed number\n        or one per frequency. Defaults to 7.\n    use_fft : bool\n        Whether to use FFT-based convolution to compute the wavelet transform.\n        Defaults to True.\n    decim : int | slice\n        To reduce memory usage, decimation factor during time-frequency\n        decomposition. Defaults to 1 (no decimation).\n\n        If `int`, uses tfr[..., ::decim].\n        If `slice`, uses tfr[..., decim].\n\n    projs : list of Projection | None\n        List of projectors to store in the CSD object. Defaults to ``None``,\n        which means the projectors defined in the Epochs object will be copied.\n    %(n_jobs)s\n    %(verbose)s\n\n    Returns\n    -------\n    csd : instance of CrossSpectralDensity\n        The computed cross-spectral density.\n\n    See Also\n    --------\n    csd_array_fourier\n    csd_array_multitaper\n    csd_fourier\n    csd_morlet\n    csd_multitaper\n    \"\"\"\n    X, times, tmin, tmax, _, _ = _prepare_csd_array(X, sfreq, t0, tmin, tmax)\n    n_times = len(times)\n\n    # Construct the appropriate Morlet wavelets\n    wavelets = morlet(sfreq, frequencies, n_cycles)\n\n    # Slice X to the requested time window + half the length of the longest\n    # wavelet.\n    wave_length = len(wavelets[np.argmin(frequencies)]) // 2\n    tstart = tstop = None\n    if tmin is not None:\n        tstart = np.searchsorted(times, tmin)\n        tstart = max(0, tstart - wave_length)\n    if tmax is not None:\n        tstop = np.searchsorted(times, tmax)\n        tstop = min(n_times, tstop + wave_length)\n    X = X[:, :, tstart:tstop]\n    times = times[tstart:tstop]\n\n    # After CSD computation, we slice again to the requested time window.\n    csd_tstart = None if tmin is None else np.searchsorted(times, tmin - 1e-10)\n    csd_tstop = None if tmax is None else np.searchsorted(times, tmax + 1e-10)\n    csd_tslice = slice(csd_tstart, csd_tstop)\n    times = times[csd_tslice]\n\n    # Compute the CSD\n    nfft = _get_nfft(wavelets, X, use_fft)\n    return _execute_csd_function(\n        X,\n        times,\n        frequencies,\n        _csd_morlet,\n        params=[sfreq, wavelets, nfft, csd_tslice, use_fft, decim],\n        n_fft=1,\n        ch_names=ch_names,\n        projs=projs,\n        n_jobs=n_jobs,\n        verbose=verbose,\n    )", "metadata": {}}
{"_id": "mne_mne_time_frequency/csd.py_csd_tfr_code", "title": "csd_tfr", "text": "def csd_tfr(epochs_tfr, tmin=None, tmax=None, picks=None, projs=None, verbose=None):\n    \"\"\"Compute covariance matrices across frequencies for TFR epochs.\n\n    Parameters\n    ----------\n    epochs_tfr : EpochsTFR\n        The time-frequency resolved epochs over which to compute the\n        covariance.\n    tmin : float | None\n        Minimum time instant to consider, in seconds. If ``None`` start at\n        first sample.\n    tmax : float | None\n        Maximum time instant to consider, in seconds. If ``None`` end at last\n        sample.\n    %(picks_good_data_noref)s\n    projs : list of Projection | None\n        List of projectors to store in the CSD object. Defaults to ``None``,\n        which means the projectors defined in the EpochsTFR object will be\n        copied.\n    %(verbose)s\n\n    Returns\n    -------\n    res : instance of CrossSpectralDensity\n        Cross-spectral density restricted to selected channels.\n    \"\"\"\n    _validate_type(epochs_tfr, EpochsTFR)\n    epochs_tfr, projs = _prepare_csd(epochs_tfr, tmin, tmax, picks, projs)\n    X = epochs_tfr.data\n    times = epochs_tfr.times\n    n_channels, n_freqs = len(epochs_tfr.ch_names), epochs_tfr.freqs.size\n    data = np.zeros((n_channels * (n_channels + 1) // 2, n_freqs), dtype=np.complex128)\n\n    # Slice X to the requested time window\n    tstart = None if tmin is None else np.searchsorted(times, tmin - 1e-10)\n    tstop = None if tmax is None else np.searchsorted(times, tmax + 1e-10)\n    X = X[:, :, :, tstart:tstop]\n\n    for idx, epochs_data in enumerate(X):\n        # This is equivalent to:\n        # csds = np.vstack([np.mean(epochs_data[[i]] * epochs_data_conj[i:],\n        #                           axis=2) for i in range(n_channels)])\n        # There is a redundancy in the calculation here because we don't really\n        # need the lower triangle of the matrix, but it should still be faster\n        # than a loop (hopefully!).\n        csds = np.einsum(\"xft,yft->xyf\", epochs_data, np.conj(epochs_data))\n        csds = csds[np.triu_indices(n_channels) + (slice(None),)]\n        csds /= epochs_data.shape[-1]\n\n        # Scaling by sampling frequency for compatibility with Matlab\n        csds /= epochs_tfr.info[\"sfreq\"]\n        data += csds\n\n    # scale to compute mean\n    data /= len(epochs_tfr)\n\n    # TO DO: EpochTFR should store n_fft to be consistent\n    return CrossSpectralDensity(\n        data=data,\n        ch_names=epochs_tfr.ch_names,\n        tmin=tmin,\n        tmax=tmax,\n        frequencies=epochs_tfr.freqs,\n        n_fft=None,\n        projs=projs,\n    )", "metadata": {}}
{"_id": "mne_mne_time_frequency/csd.py_n_channels_code", "title": "n_channels", "text": "def n_channels(self):\n        \"\"\"Number of time series defined in this CSD object.\"\"\"\n        return len(self.ch_names)", "metadata": {}}
{"_id": "mne_mne_time_frequency/csd.py_sum_code", "title": "sum", "text": "def sum(self, fmin=None, fmax=None):\n        \"\"\"Calculate the sum CSD in the given frequency range(s).\n\n        If the exact given frequencies are not available, the nearest\n        frequencies will be chosen.\n\n        Parameters\n        ----------\n        fmin : float | list of float | None\n            Lower bound of the frequency range in Hertz. Defaults to the lowest\n            frequency available. When a list of frequencies is given, these are\n            used as the lower bounds (inclusive) of frequency bins and the sum\n            is taken for each bin.\n        fmax : float | list of float | None\n            Upper bound of the frequency range in Hertz. Defaults to the\n            highest frequency available. When a list of frequencies is given,\n            these are used as the upper bounds (inclusive) of frequency bins\n            and the sum is taken for each bin.\n\n        Returns\n        -------\n        csd : instance of CrossSpectralDensity\n            The CSD matrix, summed across the given frequency range(s).\n        \"\"\"\n        if self._is_sum:\n            raise RuntimeError(\n                \"This CSD matrix already represents a mean or sum across frequencies.\"\n            )\n\n        # Deal with the various ways in which fmin and fmax can be specified\n        if fmin is None and fmax is None:\n            fmin = [self.frequencies[0]]\n            fmax = [self.frequencies[-1]]\n        else:\n            if isinstance(fmin, numbers.Number):\n                fmin = [fmin]\n            if isinstance(fmax, numbers.Number):\n                fmax = [fmax]\n            if fmin is None:\n                fmin = [self.frequencies[0]] * len(fmax)\n            if fmax is None:\n                fmax = [self.frequencies[-1]] * len(fmin)\n\n        if any(fmin_ > fmax_ for fmin_, fmax_ in zip(fmin, fmax)):\n            raise ValueError(\n                \"Some lower bounds are higher than the corresponding upper bounds.\"\n            )\n\n        # Find the index of the lower bound of each frequency bin\n        fmin_inds = [self._get_frequency_index(f) for f in fmin]\n        fmax_inds = [self._get_frequency_index(f) + 1 for f in fmax]\n\n        if len(fmin_inds) != len(fmax_inds):\n            raise ValueError(\"The length of fmin does not match the length of fmax.\")\n\n        # Sum across each frequency bin\n        n_bins = len(fmin_inds)\n        new_data = np.zeros((self._data.shape[0], n_bins), dtype=self._data.dtype)\n        new_frequencies = []\n        for i, (min_ind, max_ind) in enumerate(zip(fmin_inds, fmax_inds)):\n            new_data[:, i] = self._data[:, min_ind:max_ind].sum(axis=1)\n            new_frequencies.append(self.frequencies[min_ind:max_ind])\n\n        csd_out = CrossSpectralDensity(\n            data=new_data,\n            ch_names=self.ch_names,\n            tmin=self.tmin,\n            tmax=self.tmax,\n            frequencies=new_frequencies,\n            n_fft=self.n_fft,\n            projs=self.projs,\n        )\n        return csd_out", "metadata": {}}
{"_id": "mne_mne_time_frequency/csd.py_mean_code", "title": "mean", "text": "def mean(self, fmin=None, fmax=None):\n        \"\"\"Calculate the mean CSD in the given frequency range(s).\n\n        Parameters\n        ----------\n        fmin : float | list of float | None\n            Lower bound of the frequency range in Hertz. Defaults to the lowest\n            frequency available. When a list of frequencies is given, these are\n            used as the lower bounds (inclusive) of frequency bins and the mean\n            is taken for each bin.\n        fmax : float | list of float | None\n            Upper bound of the frequency range in Hertz. Defaults to the\n            highest frequency available. When a list of frequencies is given,\n            these are used as the upper bounds (inclusive) of frequency bins\n            and the mean is taken for each bin.\n\n        Returns\n        -------\n        csd : instance of CrossSpectralDensity\n            The CSD matrix, averaged across the given frequency range(s).\n        \"\"\"\n        csd = self.sum(fmin, fmax)\n        for i, f in enumerate(csd.frequencies):\n            csd._data[:, i] /= len(f)\n        return csd", "metadata": {}}
{"_id": "mne_mne_time_frequency/csd.py_pick_frequency_code", "title": "pick_frequency", "text": "def pick_frequency(self, freq=None, index=None):\n        \"\"\"Get a CrossSpectralDensity object with only the given frequency.\n\n        Parameters\n        ----------\n        freq : float | None\n            Return the CSD matrix for a specific frequency. Only available\n            when no averaging across frequencies has been done.\n        index : int | None\n            Return the CSD matrix for the frequency or frequency-bin with the\n            given index.\n\n        Returns\n        -------\n        csd : instance of CrossSpectralDensity\n            A CSD object containing a single CSD matrix that corresponds to the\n            requested frequency or frequency-bin.\n\n        See Also\n        --------\n        get_data\n        \"\"\"\n        if freq is None and index is None:\n            raise ValueError(\n                'Use either the \"freq\" or \"index\" parameter to '\n                \"select the desired frequency.\"\n            )\n\n        elif freq is not None:\n            if index is not None:\n                raise ValueError(\"Cannot specify both a frequency and index.\")\n\n            index = self._get_frequency_index(freq)\n\n        return self[index]", "metadata": {}}
{"_id": "mne_mne_time_frequency/csd.py_get_data_code", "title": "get_data", "text": "def get_data(self, frequency=None, index=None, as_cov=False):\n        \"\"\"Get the CSD matrix for a given frequency as NumPy array.\n\n        If there is only one matrix defined in the CSD object, calling this\n        method without any parameters will return it. If multiple matrices are\n        defined, use either the ``frequency`` or ``index`` parameter to select\n        one.\n\n        Parameters\n        ----------\n        frequency : float | None\n            Return the CSD matrix for a specific frequency. Only available when\n            no averaging across frequencies has been done.\n        index : int | None\n            Return the CSD matrix for the frequency or frequency-bin with the\n            given index.\n        as_cov : bool\n            Whether to return the data as a numpy array (`False`, the default),\n            or pack it in a :class:`mne.Covariance` object (`True`).\n\n            .. versionadded:: 0.20\n\n        Returns\n        -------\n        csd : ndarray, shape (n_channels, n_channels) | instance of Covariance\n            The CSD matrix corresponding to the requested frequency.\n\n        See Also\n        --------\n        pick_frequency\n        \"\"\"\n        if frequency is None and index is None:\n            if self._data.shape[1] > 1:\n                raise ValueError(\n                    \"Specify either the frequency or index of \"\n                    \"the frequency bin for which to obtain the \"\n                    \"CSD matrix.\"\n                )\n            index = 0\n        elif frequency is not None:\n            if index is not None:\n                raise ValueError(\"Cannot specify both a frequency and index.\")\n            index = self._get_frequency_index(frequency)\n\n        data = _vector_to_sym_mat(self._data[:, index])\n        if as_cov:\n            # Pack the data into a Covariance object\n            from ..cov import Covariance  # to avoid circular import\n\n            return Covariance(\n                data, self.ch_names, bads=[], projs=self.projs, nfree=self.n_fft\n            )\n        else:\n            return data", "metadata": {}}
{"_id": "mne_mne_time_frequency/csd.py_save_code", "title": "save", "text": "def save(self, fname, *, overwrite=False, verbose=None):\n        \"\"\"Save the CSD to an HDF5 file.\n\n        Parameters\n        ----------\n        fname : path-like\n            The name of the file to save the CSD to. The extension ``'.h5'``\n            will be appended if the given filename doesn't have it already.\n        %(overwrite)s\n\n            .. versionadded:: 1.0\n        %(verbose)s\n\n            .. versionadded:: 1.0\n\n        See Also\n        --------\n        read_csd : For reading CSD objects from a file.\n        \"\"\"\n        _, write_hdf5 = _import_h5io_funcs()\n        fname = _check_fname(fname, overwrite=True)\n        if fname.suffix != \".h5\":\n            fname = fname.with_name(f\"{fname.name}.h5\")\n        fname = _check_fname(fname, overwrite=overwrite)\n        write_hdf5(fname, self.__getstate__(), overwrite=True, title=\"conpy\")", "metadata": {}}
{"_id": "mne_mne_time_frequency/csd.py_copy_code", "title": "copy", "text": "def copy(self):\n        \"\"\"Return copy of the CrossSpectralDensity object.\n\n        Returns\n        -------\n        copy : instance of CrossSpectralDensity\n            A copy of the object.\n        \"\"\"\n        return cp.deepcopy(self)", "metadata": {}}
{"_id": "mne_mne_time_frequency/csd.py_pick_channels_code", "title": "pick_channels", "text": "def pick_channels(self, ch_names, ordered=False):\n        \"\"\"Pick channels from this cross-spectral density matrix.\n\n        Parameters\n        ----------\n        ch_names : list of str\n            List of channels to keep. All other channels are dropped.\n        ordered : bool\n            If True (default False), ensure that the order of the channels\n            matches the order of ``ch_names``.\n\n        Returns\n        -------\n        csd : instance of CrossSpectralDensity.\n            The modified cross-spectral density object.\n\n        Notes\n        -----\n        Operates in-place.\n\n        .. versionadded:: 0.20.0\n        \"\"\"\n        return pick_channels_csd(\n            self, include=ch_names, exclude=[], ordered=ordered, copy=False\n        )", "metadata": {}}
{"_id": "mne_mne_time_frequency/tfr.py_morlet_code", "title": "morlet", "text": "def morlet(sfreq, freqs, n_cycles=7.0, sigma=None, zero_mean=False):\n    \"\"\"Compute Morlet wavelets for the given frequency range.\n\n    Parameters\n    ----------\n    sfreq : float\n        The sampling Frequency.\n    freqs : float | array-like, shape (n_freqs,)\n        Frequencies to compute Morlet wavelets for.\n    n_cycles : float | array-like, shape (n_freqs,)\n        Number of cycles. Can be a fixed number (float) or one per frequency\n        (array-like).\n    sigma : float, default None\n        It controls the width of the wavelet ie its temporal\n        resolution. If sigma is None the temporal resolution\n        is adapted with the frequency like for all wavelet transform.\n        The higher the frequency the shorter is the wavelet.\n        If sigma is fixed the temporal resolution is fixed\n        like for the short time Fourier transform and the number\n        of oscillations increases with the frequency.\n    zero_mean : bool, default False\n        Make sure the wavelet has a mean of zero.\n\n    Returns\n    -------\n    Ws : list of ndarray | ndarray\n        The wavelets time series. If ``freqs`` was a float, a single\n        ndarray is returned instead of a list of ndarray.\n\n    See Also\n    --------\n    mne.time_frequency.fwhm\n\n    Notes\n    -----\n    %(morlet_reference)s\n    %(fwhm_morlet_notes)s\n\n    References\n    ----------\n    .. footbibliography::\n\n    Examples\n    --------\n    Let's show a simple example of the relationship between ``n_cycles`` and\n    the FWHM using :func:`mne.time_frequency.fwhm`:\n\n    .. plot::\n\n        import numpy as np\n        import matplotlib.pyplot as plt\n        from mne.time_frequency import morlet, fwhm\n\n        sfreq, freq, n_cycles = 1000., 10, 7  # i.e., 700 ms\n        this_fwhm = fwhm(freq, n_cycles)\n        wavelet = morlet(sfreq=sfreq, freqs=freq, n_cycles=n_cycles)\n        M, w = len(wavelet), n_cycles # convert to SciPy convention\n        s = w * sfreq / (2 * freq * np.pi)  # from SciPy docs\n\n        _, ax = plt.subplots(layout=\"constrained\")\n        colors = dict(real=\"#66CCEE\", imag=\"#EE6677\")\n        t = np.arange(-M // 2 + 1, M // 2 + 1) / sfreq\n        for kind in ('real', 'imag'):\n            ax.plot(\n                t, getattr(wavelet, kind), label=kind, color=colors[kind],\n            )\n        ax.plot(t, np.abs(wavelet), label=f'abs', color='k', lw=1., zorder=6)\n        half_max = np.max(np.abs(wavelet)) / 2.\n        ax.plot([-this_fwhm / 2., this_fwhm / 2.], [half_max, half_max],\n                color='k', linestyle='-', label='FWHM', zorder=6)\n        ax.legend(loc='upper right')\n        ax.set(xlabel='Time (s)', ylabel='Amplitude')\n    \"\"\"  # noqa: E501\n    Ws = list()\n    n_cycles = np.array(n_cycles, float).ravel()\n\n    freqs = np.array(freqs, float)\n    if np.any(freqs <= 0):\n        raise ValueError(\"all frequencies in 'freqs' must be greater than 0.\")\n\n    if (n_cycles.size != 1) and (n_cycles.size != len(freqs)):\n        raise ValueError(\"n_cycles should be fixed or defined for each frequency.\")\n    _check_option(\"freqs.ndim\", freqs.ndim, [0, 1])\n    singleton = freqs.ndim == 0\n    if singleton:\n        freqs = freqs[np.newaxis]\n    for k, f in enumerate(freqs):\n        if len(n_cycles) != 1:\n            this_n_cycles = n_cycles[k]\n        else:\n            this_n_cycles = n_cycles[0]\n        # sigma_t is the stddev of gaussian window in the time domain; can be\n        # scale-dependent or fixed across freqs\n        if sigma is None:\n            sigma_t = this_n_cycles / (2.0 * np.pi * f)\n        else:\n            sigma_t = this_n_cycles / (2.0 * np.pi * sigma)\n        # time vector. We go 5 standard deviations out to make sure we're\n        # *very* close to zero at the ends. We also make sure that there's a\n        # sample at exactly t=0\n        t = np.arange(0.0, 5.0 * sigma_t, 1.0 / sfreq)\n        t = np.r_[-t[::-1], t[1:]]\n        oscillation = np.exp(2.0 * 1j * np.pi * f * t)\n        if zero_mean:\n            # this offset is equivalent to the \u03ba_\u03c3 term in Wikipedia's\n            # equations, and satisfies the \"admissibility criterion\" for CWTs\n            real_offset = np.exp(-2 * (np.pi * f * sigma_t) ** 2)\n            oscillation -= real_offset\n        gaussian_envelope = np.exp(-(t**2) / (2.0 * sigma_t**2))\n        W = oscillation * gaussian_envelope\n        # the scaling factor here is proportional to what is used in\n        # Tallon-Baudry 1997: (sigma_t*sqrt(pi))^(-1/2).  It yields a wavelet\n        # with norm sqrt(2) for the full wavelet / norm 1 for the real part\n        W /= np.sqrt(0.5) * np.linalg.norm(W.ravel())\n        Ws.append(W)\n    if singleton:\n        Ws = Ws[0]\n    return Ws", "metadata": {}}
{"_id": "mne_mne_time_frequency/tfr.py_fwhm_code", "title": "fwhm", "text": "def fwhm(freq, n_cycles):\n    \"\"\"Compute the full-width half maximum of a Morlet wavelet.\n\n    Uses the formula from :footcite:t:`Cohen2019`.\n\n    Parameters\n    ----------\n    freq : float\n        The oscillation frequency of the wavelet.\n    n_cycles : float\n        The duration of the wavelet, expressed as the number of oscillation\n        cycles.\n\n    Returns\n    -------\n    fwhm : float\n        The full-width half maximum of the wavelet.\n\n    Notes\n    -----\n     .. versionadded:: 1.3\n\n    References\n    ----------\n    .. footbibliography::\n    \"\"\"\n    return n_cycles * np.sqrt(2 * np.log(2)) / (np.pi * freq)", "metadata": {}}
{"_id": "mne_mne_time_frequency/tfr.py_cwt_code", "title": "cwt", "text": "def cwt(X, Ws, use_fft=True, mode=\"same\", decim=1):\n    \"\"\"Compute time-frequency decomposition with continuous wavelet transform.\n\n    Parameters\n    ----------\n    X : array, shape (n_signals, n_times)\n        The signals.\n    Ws : list of array\n        Wavelets time series.\n    use_fft : bool\n        Use FFT for convolutions. Defaults to True.\n    mode : 'same' | 'valid' | 'full'\n        Convention for convolution. 'full' is currently not implemented with\n        ``use_fft=False``. Defaults to ``'same'``.\n    %(decim_tfr)s\n\n    Returns\n    -------\n    tfr : array, shape (n_signals, n_freqs, n_times)\n        The time-frequency decompositions.\n\n    See Also\n    --------\n    mne.time_frequency.tfr_morlet : Compute time-frequency decomposition\n                                    with Morlet wavelets.\n    \"\"\"\n    nfft = _get_nfft(Ws, X, use_fft)\n    return _cwt_array(X, Ws, nfft, mode, decim, use_fft)", "metadata": {}}
{"_id": "mne_mne_time_frequency/tfr.py_tfr_morlet_code", "title": "tfr_morlet", "text": "def tfr_morlet(\n    inst,\n    freqs,\n    n_cycles,\n    use_fft=False,\n    return_itc=True,\n    decim=1,\n    n_jobs=None,\n    picks=None,\n    zero_mean=True,\n    average=True,\n    output=\"power\",\n    verbose=None,\n):\n    \"\"\"Compute Time-Frequency Representation (TFR) using Morlet wavelets.\n\n    Same computation as `~mne.time_frequency.tfr_array_morlet`, but\n    operates on `~mne.Epochs` or `~mne.Evoked` objects instead of\n    :class:`NumPy arrays <numpy.ndarray>`.\n\n    Parameters\n    ----------\n    inst : Epochs | Evoked\n        The epochs or evoked object.\n    %(freqs_tfr_array)s\n    %(n_cycles_tfr)s\n    use_fft : bool, default False\n        The fft based convolution or not.\n    return_itc : bool, default True\n        Return inter-trial coherence (ITC) as well as averaged power.\n        Must be ``False`` for evoked data.\n    %(decim_tfr)s\n    %(n_jobs)s\n    picks : array-like of int | None, default None\n        The indices of the channels to decompose. If None, all available\n        good data channels are decomposed.\n    zero_mean : bool, default True\n        Make sure the wavelet has a mean of zero.\n\n        .. versionadded:: 0.13.0\n    %(average_tfr)s\n    output : str\n        Can be ``\"power\"`` (default) or ``\"complex\"``. If ``\"complex\"``, then\n        ``average`` must be ``False``.\n\n        .. versionadded:: 0.15.0\n    %(verbose)s\n\n    Returns\n    -------\n    power : AverageTFR | EpochsTFR\n        The averaged or single-trial power.\n    itc : AverageTFR | EpochsTFR\n        The inter-trial coherence (ITC). Only returned if return_itc\n        is True.\n\n    See Also\n    --------\n    mne.time_frequency.tfr_array_morlet\n    mne.time_frequency.tfr_multitaper\n    mne.time_frequency.tfr_array_multitaper\n    mne.time_frequency.tfr_stockwell\n    mne.time_frequency.tfr_array_stockwell\n\n    Notes\n    -----\n    %(morlet_reference)s\n    %(temporal_window_tfr_intro)s\n    %(temporal_window_tfr_morlet_notes)s\n\n    See :func:`mne.time_frequency.morlet` for more information about the\n    Morlet wavelet.\n\n    References\n    ----------\n    .. footbibliography::\n    \"\"\"\n    tfr_params = dict(\n        n_cycles=n_cycles,\n        n_jobs=n_jobs,\n        use_fft=use_fft,\n        zero_mean=zero_mean,\n        output=output,\n    )\n    return _tfr_aux(\n        \"morlet\", inst, freqs, decim, return_itc, picks, average, **tfr_params\n    )", "metadata": {}}
{"_id": "mne_mne_time_frequency/tfr.py_tfr_array_morlet_code", "title": "tfr_array_morlet", "text": "def tfr_array_morlet(\n    data,\n    sfreq,\n    freqs,\n    n_cycles=7.0,\n    zero_mean=True,\n    use_fft=True,\n    decim=1,\n    output=\"complex\",\n    n_jobs=None,\n    *,\n    verbose=None,\n):\n    \"\"\"Compute Time-Frequency Representation (TFR) using Morlet wavelets.\n\n    Same computation as `~mne.time_frequency.tfr_morlet`, but operates on\n    :class:`NumPy arrays <numpy.ndarray>` instead of `~mne.Epochs` objects.\n\n    Parameters\n    ----------\n    data : array of shape (n_epochs, n_channels, n_times)\n        The epochs.\n    sfreq : float | int\n        Sampling frequency of the data.\n    %(freqs_tfr_array)s\n    %(n_cycles_tfr)s\n    zero_mean : bool | None\n        If True, make sure the wavelets have a mean of zero. default False.\n\n        .. versionchanged:: 1.8\n            The default will change from ``zero_mean=False`` in 1.6 to ``True`` in\n            1.8.\n\n    use_fft : bool\n        Use the FFT for convolutions or not. default True.\n    %(decim_tfr)s\n    output : str, default ``'complex'``\n\n        * ``'complex'`` : single trial complex.\n        * ``'power'`` : single trial power.\n        * ``'phase'`` : single trial phase.\n        * ``'avg_power'`` : average of single trial power.\n        * ``'itc'`` : inter-trial coherence.\n        * ``'avg_power_itc'`` : average of single trial power and inter-trial\n          coherence across trials.\n    %(n_jobs)s\n        The number of epochs to process at the same time. The parallelization\n        is implemented across channels. Default 1.\n    %(verbose)s\n\n    Returns\n    -------\n    out : array\n        Time frequency transform of ``data``.\n\n        - if ``output in ('complex', 'phase', 'power')``, array of shape\n          ``(n_epochs, n_chans, n_freqs, n_times)``\n        - else, array of shape ``(n_chans, n_freqs, n_times)``\n\n        If ``output`` is ``'avg_power_itc'``, the real values in ``out``\n        contain the average power and the imaginary values contain the ITC:\n        :math:`out = power_{avg} + i * itc`.\n\n    See Also\n    --------\n    mne.time_frequency.tfr_morlet\n    mne.time_frequency.tfr_multitaper\n    mne.time_frequency.tfr_array_multitaper\n    mne.time_frequency.tfr_stockwell\n    mne.time_frequency.tfr_array_stockwell\n\n    Notes\n    -----\n    %(morlet_reference)s\n    %(temporal_window_tfr_intro)s\n    %(temporal_window_tfr_morlet_notes)s\n\n    .. versionadded:: 0.14.0\n\n    References\n    ----------\n    .. footbibliography::\n    \"\"\"\n    return _compute_tfr(\n        epoch_data=data,\n        freqs=freqs,\n        sfreq=sfreq,\n        method=\"morlet\",\n        n_cycles=n_cycles,\n        zero_mean=zero_mean,\n        time_bandwidth=None,\n        use_fft=use_fft,\n        decim=decim,\n        output=output,\n        n_jobs=n_jobs,\n        verbose=verbose,\n    )", "metadata": {}}
{"_id": "mne_mne_time_frequency/tfr.py_tfr_multitaper_code", "title": "tfr_multitaper", "text": "def tfr_multitaper(\n    inst,\n    freqs,\n    n_cycles,\n    time_bandwidth=4.0,\n    use_fft=True,\n    return_itc=True,\n    decim=1,\n    n_jobs=None,\n    picks=None,\n    average=True,\n    *,\n    verbose=None,\n):\n    \"\"\"Compute Time-Frequency Representation (TFR) using DPSS tapers.\n\n    Same computation as :func:`~mne.time_frequency.tfr_array_multitaper`, but\n    operates on :class:`~mne.Epochs` or :class:`~mne.Evoked` objects instead of\n    :class:`NumPy arrays <numpy.ndarray>`.\n\n    Parameters\n    ----------\n    inst : Epochs | Evoked\n        The epochs or evoked object.\n    %(freqs_tfr_array)s\n    %(n_cycles_tfr)s\n    %(time_bandwidth_tfr)s\n    use_fft : bool, default True\n        The fft based convolution or not.\n    return_itc : bool, default True\n        Return inter-trial coherence (ITC) as well as averaged (or\n        single-trial) power.\n    %(decim_tfr)s\n    %(n_jobs)s\n    %(picks_good_data)s\n    %(average_tfr)s\n    %(verbose)s\n\n    Returns\n    -------\n    power : AverageTFR | EpochsTFR\n        The averaged or single-trial power.\n    itc : AverageTFR | EpochsTFR\n        The inter-trial coherence (ITC). Only returned if return_itc\n        is True.\n\n    See Also\n    --------\n    mne.time_frequency.tfr_array_multitaper\n    mne.time_frequency.tfr_stockwell\n    mne.time_frequency.tfr_array_stockwell\n    mne.time_frequency.tfr_morlet\n    mne.time_frequency.tfr_array_morlet\n\n    Notes\n    -----\n    %(temporal_window_tfr_intro)s\n    %(temporal_window_tfr_multitaper_notes)s\n    %(time_bandwidth_tfr_notes)s\n\n    .. versionadded:: 0.9.0\n    \"\"\"\n    from ..epochs import EpochsArray\n    from ..evoked import Evoked\n\n    tfr_params = dict(\n        n_cycles=n_cycles,\n        n_jobs=n_jobs,\n        use_fft=use_fft,\n        zero_mean=True,\n        time_bandwidth=time_bandwidth,\n    )\n    if isinstance(inst, Evoked) and not average:\n        # convert AverageTFR to EpochsTFR for backwards compatibility\n        inst = EpochsArray(inst.data[np.newaxis], inst.info, tmin=inst.tmin, proj=False)\n    return _tfr_aux(\n        method=\"multitaper\",\n        inst=inst,\n        freqs=freqs,\n        decim=decim,\n        return_itc=return_itc,\n        picks=picks,\n        average=average,\n        output=\"power\",\n        **tfr_params,\n    )", "metadata": {}}
{"_id": "mne_mne_time_frequency/tfr.py_combine_tfr_code", "title": "combine_tfr", "text": "def combine_tfr(all_tfr, weights=\"nave\"):\n    \"\"\"Merge AverageTFR data by weighted addition.\n\n    Create a new :class:`mne.time_frequency.AverageTFR` instance, using a combination of\n    the supplied instances as its data. By default, the mean (weighted by trials) is\n    used. Subtraction can be performed by passing negative weights (e.g., [1, -1]). Data\n    must have the same channels and the same time instants.\n\n    Parameters\n    ----------\n    all_tfr : list of AverageTFR\n        The tfr datasets.\n    weights : list of float | str\n        The weights to apply to the data of each AverageTFR instance.\n        Can also be ``'nave'`` to weight according to tfr.nave,\n        or ``'equal'`` to use equal weighting (each weighted as ``1/N``).\n\n    Returns\n    -------\n    tfr : AverageTFR\n        The new TFR data.\n\n    Notes\n    -----\n    Aggregating multitaper TFR datasets with a taper dimension such as for complex or\n    phase data is not supported.\n\n    .. versionadded:: 0.11.0\n    \"\"\"\n    if any(\"taper\" in tfr._dims for tfr in all_tfr):\n        raise NotImplementedError(\n            \"Aggregating multitaper tapers across TFR datasets is not supported.\"\n        )\n\n    tfr = all_tfr[0].copy()\n    if isinstance(weights, str):\n        if weights not in (\"nave\", \"equal\"):\n            raise ValueError('Weights must be a list of float, or \"nave\" or \"equal\"')\n        if weights == \"nave\":\n            weights = np.array([e.nave for e in all_tfr], float)\n            weights /= weights.sum()\n        else:  # == 'equal'\n            weights = [1.0 / len(all_tfr)] * len(all_tfr)\n    weights = np.array(weights, float)\n    if weights.ndim != 1 or weights.size != len(all_tfr):\n        raise ValueError(\"Weights must be the same size as all_tfr\")\n\n    ch_names = tfr.ch_names\n    for t_ in all_tfr[1:]:\n        assert t_.ch_names == ch_names, (\n            f\"{tfr} and {t_} do not contain the same channels\"\n        )\n        assert np.max(np.abs(t_.times - tfr.times)) < 1e-7, (\n            f\"{tfr} and {t_} do not contain the same time instants\"\n        )\n\n    # use union of bad channels\n    bads = list(set(tfr.info[\"bads\"]).union(*(t_.info[\"bads\"] for t_ in all_tfr[1:])))\n    tfr.info[\"bads\"] = bads\n\n    # XXX : should be refactored with combined_evoked function\n    tfr.data = sum(w * t_.data for w, t_ in zip(weights, all_tfr))\n    tfr.nave = max(int(1.0 / sum(w**2 / e.nave for w, e in zip(weights, all_tfr))), 1)\n    return tfr", "metadata": {}}
{"_id": "mne_mne_time_frequency/tfr.py_write_tfrs_code", "title": "write_tfrs", "text": "def write_tfrs(fname, tfr, overwrite=False, *, verbose=None):\n    \"\"\"Write a TFR dataset to hdf5.\n\n    Parameters\n    ----------\n    fname : path-like\n        The file name, which should end with ``-tfr.h5``.\n    tfr : RawTFR | EpochsTFR | AverageTFR | list of RawTFR | list of EpochsTFR | list of AverageTFR\n        The (list of) TFR object(s) to save in one file. If ``tfr.comment`` is ``None``,\n        a sequential numeric string name will be generated on the fly, based on the\n        order in which the TFR objects are passed. This can be used to selectively load\n        single TFR objects from the file later.\n    %(overwrite)s\n    %(verbose)s\n\n    See Also\n    --------\n    read_tfrs\n\n    Notes\n    -----\n    .. versionadded:: 0.9.0\n    \"\"\"  # noqa E501\n    _, write_hdf5 = _import_h5io_funcs()\n    out = []\n    if not isinstance(tfr, list | tuple):\n        tfr = [tfr]\n    for ii, tfr_ in enumerate(tfr):\n        comment = ii if getattr(tfr_, \"comment\", None) is None else tfr_.comment\n        state = tfr_.__getstate__()\n        if \"metadata\" in state:\n            state[\"metadata\"] = _prepare_write_metadata(state[\"metadata\"])\n        out.append((comment, state))\n    write_hdf5(fname, out, overwrite=overwrite, title=\"mnepython\", slash=\"replace\")", "metadata": {}}
{"_id": "mne_mne_time_frequency/tfr.py_read_tfrs_code", "title": "read_tfrs", "text": "def read_tfrs(fname, condition=None, *, verbose=None):\n    \"\"\"Load a TFR object from disk.\n\n    Parameters\n    ----------\n    fname : path-like\n        Path to a TFR file in HDF5 format, which should end with ``-tfr.h5`` or\n        ``-tfr.hdf5``.\n    condition : int or str | list of int or str | None\n        The condition to load. If ``None``, all conditions will be returned.\n        Defaults to ``None``.\n    %(verbose)s\n\n    Returns\n    -------\n    tfr : RawTFR | EpochsTFR | AverageTFR | list of RawTFR | list of EpochsTFR | list of AverageTFR\n        The loaded time-frequency object.\n\n    See Also\n    --------\n    mne.time_frequency.RawTFR.save\n    mne.time_frequency.EpochsTFR.save\n    mne.time_frequency.AverageTFR.save\n    write_tfrs\n\n    Notes\n    -----\n    .. versionadded:: 0.9.0\n    \"\"\"  # noqa E501\n    read_hdf5, _ = _import_h5io_funcs()\n    fname = _check_fname(fname=fname, overwrite=\"read\", must_exist=False)\n    valid_fnames = tuple(\n        f\"{sep}tfr.{ext}\" for sep in (\"-\", \"_\") for ext in (\"h5\", \"hdf5\")\n    )\n    check_fname(fname, \"tfr\", valid_fnames)\n    logger.info(f\"Reading {fname} ...\")\n    hdf5_dict = read_hdf5(fname, title=\"mnepython\", slash=\"replace\")\n    # single TFR from TFR.save()\n    if \"inst_type_str\" in hdf5_dict:\n        if \"epoch\" in hdf5_dict[\"dims\"]:\n            Klass = EpochsTFR\n        elif \"nave\" in hdf5_dict:\n            Klass = AverageTFR\n        else:\n            Klass = RawTFR\n        out = Klass(inst=hdf5_dict)\n        if getattr(out, \"metadata\", None) is not None:\n            out.metadata = _prepare_read_metadata(out.metadata)\n        return out\n    # maybe multiple TFRs from write_tfrs()\n    return _read_multiple_tfrs(hdf5_dict, condition=condition, verbose=verbose)", "metadata": {}}
{"_id": "mne_mne_time_frequency/tfr.py_baseline_code", "title": "baseline", "text": "def baseline(self):\n        \"\"\"Start and end of the baseline period (in seconds).\"\"\"\n        return self._baseline", "metadata": {}}
{"_id": "mne_mne_time_frequency/tfr.py_ch_names_code", "title": "ch_names", "text": "def ch_names(self):\n        \"\"\"The channel names.\"\"\"\n        return self.info[\"ch_names\"]", "metadata": {}}
{"_id": "mne_mne_time_frequency/tfr.py_data_code", "title": "data", "text": "def data(self):\n        \"\"\"The time-frequency-resolved power estimates.\"\"\"\n        return self._data", "metadata": {}}
{"_id": "mne_mne_time_frequency/tfr.py_freqs_code", "title": "freqs", "text": "def freqs(self):\n        \"\"\"The frequencies at which power estimates were computed.\"\"\"\n        return self._freqs", "metadata": {}}
{"_id": "mne_mne_time_frequency/tfr.py_method_code", "title": "method", "text": "def method(self):\n        \"\"\"The method used to compute the time-frequency power estimates.\"\"\"\n        return self._method", "metadata": {}}
{"_id": "mne_mne_time_frequency/tfr.py_sfreq_code", "title": "sfreq", "text": "def sfreq(self):\n        \"\"\"Sampling frequency of the data.\"\"\"\n        return self.info[\"sfreq\"]", "metadata": {}}
{"_id": "mne_mne_time_frequency/tfr.py_shape_code", "title": "shape", "text": "def shape(self):\n        \"\"\"Data shape.\"\"\"\n        return self._data.shape", "metadata": {}}
{"_id": "mne_mne_time_frequency/tfr.py_times_code", "title": "times", "text": "def times(self):\n        \"\"\"The time points present in the data (in seconds).\"\"\"\n        return self._times_readonly", "metadata": {}}
{"_id": "mne_mne_time_frequency/tfr.py_weights_code", "title": "weights", "text": "def weights(self):\n        \"\"\"The weights used for each taper in the time-frequency estimates.\"\"\"\n        return self._weights", "metadata": {}}
{"_id": "mne_mne_time_frequency/tfr.py_crop_code", "title": "crop", "text": "def crop(self, tmin=None, tmax=None, fmin=None, fmax=None, include_tmax=True):\n        \"\"\"Crop data to a given time interval in place.\n\n        Parameters\n        ----------\n        %(tmin_tmax_psd)s\n        fmin : float | None\n            Lowest frequency of selection in Hz.\n\n            .. versionadded:: 0.18.0\n        fmax : float | None\n            Highest frequency of selection in Hz.\n\n            .. versionadded:: 0.18.0\n        %(include_tmax)s\n\n        Returns\n        -------\n        %(inst_tfr)s\n            The modified instance.\n        \"\"\"\n        super().crop(tmin=tmin, tmax=tmax, include_tmax=include_tmax)\n\n        if fmin is not None or fmax is not None:\n            freq_mask = _freq_mask(\n                self.freqs, sfreq=self.info[\"sfreq\"], fmin=fmin, fmax=fmax\n            )\n        else:\n            freq_mask = slice(None)\n\n        self._freqs = self.freqs[freq_mask]\n        # Deal with broadcasting (boolean arrays do not broadcast, but indices\n        # do, so we need to convert freq_mask to make use of broadcasting)\n        if isinstance(freq_mask, np.ndarray):\n            freq_mask = np.where(freq_mask)[0]\n        self._data = self._data[..., freq_mask, :]\n        return self", "metadata": {}}
{"_id": "mne_mne_time_frequency/tfr.py_copy_code", "title": "copy", "text": "def copy(self):\n        \"\"\"Return copy of the TFR instance.\n\n        Returns\n        -------\n        %(inst_tfr)s\n            A copy of the object.\n        \"\"\"\n        return deepcopy(self)", "metadata": {}}
{"_id": "mne_mne_time_frequency/tfr.py_apply_baseline_code", "title": "apply_baseline", "text": "def apply_baseline(self, baseline, mode=\"mean\", verbose=None):\n        \"\"\"Baseline correct the data.\n\n        Parameters\n        ----------\n        %(baseline_rescale)s\n\n            How baseline is computed is determined by the ``mode`` parameter.\n        mode : 'mean' | 'ratio' | 'logratio' | 'percent' | 'zscore' | 'zlogratio'\n            Perform baseline correction by\n\n            - subtracting the mean of baseline values ('mean')\n            - dividing by the mean of baseline values ('ratio')\n            - dividing by the mean of baseline values and taking the log\n              ('logratio')\n            - subtracting the mean of baseline values followed by dividing by\n              the mean of baseline values ('percent')\n            - subtracting the mean of baseline values and dividing by the\n              standard deviation of baseline values ('zscore')\n            - dividing by the mean of baseline values, taking the log, and\n              dividing by the standard deviation of log baseline values\n              ('zlogratio')\n        %(verbose)s\n\n        Returns\n        -------\n        %(inst_tfr)s\n            The modified instance.\n        \"\"\"\n        self._baseline = _check_baseline(baseline, times=self.times, sfreq=self.sfreq)\n        rescale(self.data, self.times, self.baseline, mode, copy=False, verbose=verbose)\n        return self", "metadata": {}}
{"_id": "mne_mne_time_frequency/tfr.py_get_data_code", "title": "get_data", "text": "def get_data(\n        self,\n        picks=None,\n        exclude=\"bads\",\n        fmin=None,\n        fmax=None,\n        tmin=None,\n        tmax=None,\n        return_times=False,\n        return_freqs=False,\n        return_tapers=False,\n    ):\n        \"\"\"Get time-frequency data in NumPy array format.\n\n        Parameters\n        ----------\n        %(picks_good_data_noref)s\n        %(exclude_spectrum_get_data)s\n        %(fmin_fmax_tfr)s\n        %(tmin_tmax_psd)s\n        return_times : bool\n            Whether to return the time values for the requested time range.\n            Default is ``False``.\n        return_freqs : bool\n            Whether to return the frequency bin values for the requested\n            frequency range. Default is ``False``.\n        return_tapers : bool\n            Whether to return the taper numbers. Default is ``False``.\n\n            .. versionadded:: 1.10.0\n\n        Returns\n        -------\n        data : array\n            The requested data in a NumPy array.\n        times : array\n            The time values for the requested data range. Only returned if\n            ``return_times`` is ``True``.\n        freqs : array\n            The frequency values for the requested data range. Only returned if\n            ``return_freqs`` is ``True``.\n        tapers : array | None\n            The taper numbers. Only returned if ``return_tapers`` is ``True``. Will be\n            ``None`` if a taper dimension is not present in the data.\n\n        Notes\n        -----\n        Returns a copy of the underlying data (not a view).\n        \"\"\"\n        tmin = self.times[0] if tmin is None else tmin\n        tmax = self.times[-1] if tmax is None else tmax\n        fmin = 0 if fmin is None else fmin\n        fmax = np.inf if fmax is None else fmax\n        picks = _picks_to_idx(\n            self.info, picks, \"data_or_ica\", exclude=exclude, with_ref_meg=False\n        )\n        fmin_idx = np.searchsorted(self.freqs, fmin)\n        fmax_idx = np.searchsorted(self.freqs, fmax, side=\"right\")\n        tmin_idx = np.searchsorted(self.times, tmin)\n        tmax_idx = np.searchsorted(self.times, tmax, side=\"right\")\n        freq_picks = np.arange(fmin_idx, fmax_idx)\n        time_picks = np.arange(tmin_idx, tmax_idx)\n        freq_axis = self._dims.index(\"freq\")\n        time_axis = self._dims.index(\"time\")\n        chan_axis = self._dims.index(\"channel\")\n        # normally there's a risk of np.take reducing array dimension if there\n        # were only one channel or frequency selected, but `_picks_to_idx`\n        # and np.arange both always return arrays, so we're safe; the result\n        # will always have the same `ndim` as it started with.\n        data = (\n            self._data.take(picks, chan_axis)\n            .take(freq_picks, freq_axis)\n            .take(time_picks, time_axis)\n        )\n        out = [data]\n        if return_times:\n            times = self._raw_times[tmin_idx:tmax_idx]\n            out.append(times)\n        if return_freqs:\n            freqs = self._freqs[fmin_idx:fmax_idx]\n            out.append(freqs)\n        if return_tapers:\n            if \"taper\" in self._dims:\n                tapers = np.arange(self.shape[self._dims.index(\"taper\")])\n            else:\n                tapers = None\n            out.append(tapers)\n        if not return_times and not return_freqs and not return_tapers:\n            return out[0]\n        return tuple(out)", "metadata": {}}
{"_id": "mne_mne_time_frequency/tfr.py_plot_code", "title": "plot", "text": "def plot(\n        self,\n        picks=None,\n        *,\n        exclude=(),\n        tmin=None,\n        tmax=None,\n        fmin=0.0,\n        fmax=np.inf,\n        baseline=None,\n        mode=\"mean\",\n        dB=False,\n        combine=None,\n        layout=None,  # TODO deprecate? not used in orig implementation either\n        yscale=\"auto\",\n        vlim=(None, None),\n        cnorm=None,\n        cmap=None,\n        colorbar=True,\n        title=None,  # don't deprecate this one; has (useful) option title=\"auto\"\n        mask=None,\n        mask_style=None,\n        mask_cmap=\"Greys\",\n        mask_alpha=0.1,\n        axes=None,\n        show=True,\n        verbose=None,\n    ):\n        \"\"\"Plot TFRs as two-dimensional time-frequency images.\n\n        Parameters\n        ----------\n        %(picks_good_data)s\n        %(exclude_spectrum_plot)s\n        %(tmin_tmax_psd)s\n        %(fmin_fmax_tfr)s\n        %(baseline_rescale)s\n\n            How baseline is computed is determined by the ``mode`` parameter.\n        %(mode_tfr_plot)s\n        %(dB_spectrum_plot)s\n        %(combine_tfr_plot)s\n\n            .. versionchanged:: 1.3\n               Added support for ``callable``.\n        %(layout_spectrum_plot_topo)s\n        %(yscale_tfr_plot)s\n\n            .. versionadded:: 0.14.0\n        %(vlim_tfr_plot)s\n        %(cnorm)s\n\n            .. versionadded:: 0.24\n        %(cmap_topomap)s\n        %(colorbar)s\n        %(title_tfr_plot)s\n        %(mask_tfr_plot)s\n\n            .. versionadded:: 0.16.0\n        %(mask_style_tfr_plot)s\n\n            .. versionadded:: 0.17\n        %(mask_cmap_tfr_plot)s\n\n            .. versionadded:: 0.17\n        %(mask_alpha_tfr_plot)s\n\n            .. versionadded:: 0.16.0\n        %(axes_tfr_plot)s\n        %(show)s\n        %(verbose)s\n\n        Returns\n        -------\n        figs : list of instances of matplotlib.figure.Figure\n            A list of figures containing the time-frequency power.\n        \"\"\"\n        # the rectangle selector plots topomaps, which needs all channels uncombined,\n        # so we keep a reference to that state here, and (because the topomap plotting\n        # function wants an AverageTFR) update it with `comment` and `nave` values in\n        # case we started out with a singleton EpochsTFR or RawTFR\n        initial_state = self.__getstate__()\n        initial_state.setdefault(\"comment\", \"\")\n        initial_state.setdefault(\"nave\", 1)\n        # `_picks_to_idx` also gets done inside `get_data()`` below, but we do it here\n        # because we need the indices later\n        idx_picks = _picks_to_idx(\n            self.info, picks, \"data_or_ica\", exclude=exclude, with_ref_meg=False\n        )\n        pick_names = np.array(self.ch_names)[idx_picks].tolist()  # for titles\n        ch_types = self.get_channel_types(idx_picks)\n        # get data arrays\n        data, times, freqs = self.get_data(\n            picks=idx_picks, exclude=(), return_times=True, return_freqs=True\n        )\n        # pass tmin/tmax here \u2193\u2193\u2193, not here \u2191\u2191\u2191; we want to crop *after* baselining\n        data, times, freqs = _prep_data_for_plot(\n            data,\n            times,\n            freqs,\n            tmin=tmin,\n            tmax=tmax,\n            fmin=fmin,\n            fmax=fmax,\n            baseline=baseline,\n            mode=mode,\n            dB=dB,\n            taper_weights=self.weights,\n            verbose=verbose,\n        )\n        # shape\n        ch_axis = self._dims.index(\"channel\")\n        freq_axis = self._dims.index(\"freq\")\n        time_axis = self._dims.index(\"time\")\n        want_shape = list(self.shape)\n        want_shape[ch_axis] = len(idx_picks) if combine is None else 1\n        want_shape[freq_axis] = len(freqs)  # in case there was fmin/fmax cropping\n        want_shape[time_axis] = len(times)  # in case there was tmin/tmax cropping\n        want_shape = [\n            n for dim, n in zip(self._dims, want_shape) if dim != \"taper\"\n        ]  # tapers must be aggregated over by now\n        want_shape = tuple(want_shape)\n        # combine\n        combine_was_none = combine is None\n        combine = _make_combine_callable(\n            combine, axis=ch_axis, valid=(\"mean\", \"rms\"), keepdims=True\n        )\n        try:\n            data = combine(data)  # no need to copy; get_data() never returns a view\n        except Exception as e:\n            msg = (\n                \"Something went wrong with the callable passed to 'combine'; see \"\n                \"traceback.\"\n            )\n            raise ValueError(msg) from e\n        # call succeeded, check type and shape\n        mismatch = False\n        if not isinstance(data, np.ndarray):\n            mismatch = \"type\"\n            extra = \"\"\n        elif data.shape not in (want_shape, want_shape[1:]):\n            mismatch = \"shape\"\n            extra = f\" of shape {data.shape}\"\n        if mismatch:\n            raise RuntimeError(\n                f\"Wrong {mismatch} yielded by callable passed to 'combine'. Make sure \"\n                \"your function takes a single argument (an array of shape \"\n                \"(n_channels, n_freqs, n_times)) and returns an array of shape \"\n                f\"(n_freqs, n_times); yours yielded: {type(data)}{extra}.\"\n            )\n        # restore singleton collapsed axis (removed by user-provided callable):\n        # (n_freqs, n_times) \u2192 (1, n_freqs, n_times)\n        if data.shape == (len(freqs), len(times)):\n            data = data[np.newaxis]\n\n        assert data.shape == want_shape\n        # cmap handling. power may be negative depending on baseline strategy so set\n        # `norm` empirically \u2014 but only if user didn't set limits explicitly.\n        norm = False if vlim == (None, None) else data.min() >= 0.0\n        vmin, vmax = _setup_vmin_vmax(data, *vlim, norm=norm)\n        cmap = _setup_cmap(cmap, norm=norm)\n        # prepare figure(s)\n        if axes is None:\n            figs = [plt.figure(layout=\"constrained\") for _ in range(data.shape[0])]\n            axes = [fig.add_subplot() for fig in figs]\n        elif isinstance(axes, plt.Axes):\n            figs = [axes.get_figure()]\n            axes = [axes]\n        elif isinstance(axes, np.ndarray):  # allow plotting into a grid of axes\n            figs = [ax.get_figure() for ax in axes.flat]\n        elif hasattr(axes, \"__iter__\") and len(axes):\n            figs = [ax.get_figure() for ax in axes]\n        else:\n            raise ValueError(\n                f\"axes must be None, Axes, or list/array of Axes, got {type(axes)}\"\n            )\n        if len(axes) != data.shape[0]:\n            raise RuntimeError(\n                f\"Mismatch between picked channels ({data.shape[0]}) and axes \"\n                f\"({len(axes)}); there must be one axes for each picked channel.\"\n            )\n        # check if we're being called from within plot_joint(). If so, get the\n        # `topomap_args` from the calling context and pass it to the onselect handler.\n        # (we need 2 `f_back` here because of the verbose decorator)\n        calling_frame = inspect.currentframe().f_back.f_back\n        source_plot_joint = calling_frame.f_code.co_name == \"plot_joint\"\n        topomap_args = (\n            dict()\n            if not source_plot_joint\n            else calling_frame.f_locals.get(\"topomap_args\", dict())\n        )\n        # plot\n        for ix, _fig in enumerate(figs):\n            # restrict the onselect instance to the channel type of the picks used in\n            # the image plot\n            uniq_types = np.unique(ch_types)\n            ch_type = None if len(uniq_types) > 1 else uniq_types.item()\n            this_tfr = AverageTFR(inst=initial_state).pick(ch_type, verbose=verbose)\n            _onselect_callback = partial(\n                this_tfr._onselect,\n                picks=None,  # already restricted the picks in `this_tfr`\n                exclude=(),\n                baseline=baseline,\n                mode=mode,\n                cmap=cmap,\n                source_plot_joint=source_plot_joint,\n                topomap_args=topomap_args,\n            )\n            # draw the image plot\n            _imshow_tfr(\n                ax=axes[ix],\n                tfr=data[[ix]],\n                ch_idx=0,\n                tmin=times[0],\n                tmax=times[-1],\n                vmin=vmin,\n                vmax=vmax,\n                onselect=_onselect_callback,\n                ylim=None,\n                freq=freqs,\n                x_label=\"Time (s)\",\n                y_label=\"Frequency (Hz)\",\n                colorbar=colorbar,\n                cmap=cmap,\n                yscale=yscale,\n                mask=mask,\n                mask_style=mask_style,\n                mask_cmap=mask_cmap,\n                mask_alpha=mask_alpha,\n                cnorm=cnorm,\n            )\n            # handle title. automatic title is:\n            #   f\"{Baselined} {power} ({ch_name})\" or\n            #   f\"{Baselined} {power} ({combination} of {N} {ch_type}s)\"\n            if title == \"auto\":\n                if combine_was_none:  # one plot per channel\n                    which_chs = pick_names[ix]\n                elif len(pick_names) == 1:  # there was only one pick anyway\n                    which_chs = pick_names[0]\n                else:  # one plot for all chs combined\n                    which_chs = _set_title_multiple_electrodes(\n                        None, combine, pick_names, all_=True, ch_type=ch_type\n                    )\n                _prefix = \"Power\" if baseline is None else \"Baselined power\"\n                _title = f\"{_prefix} ({which_chs})\"\n            else:\n                _title = title\n            _fig.suptitle(_title)\n        plt_show(show)\n        return figs", "metadata": {}}
{"_id": "mne_mne_time_frequency/tfr.py_plot_joint_code", "title": "plot_joint", "text": "def plot_joint(\n        self,\n        *,\n        timefreqs=None,\n        picks=None,\n        exclude=(),\n        combine=\"mean\",\n        tmin=None,\n        tmax=None,\n        fmin=None,\n        fmax=None,\n        baseline=None,\n        mode=\"mean\",\n        dB=False,\n        yscale=\"auto\",\n        vlim=(None, None),\n        cnorm=None,\n        cmap=None,\n        colorbar=True,\n        title=None,  # TODO consider deprecating this one, or adding an \"auto\" option\n        show=True,\n        topomap_args=None,\n        image_args=None,\n        verbose=None,\n    ):\n        \"\"\"Plot TFRs as a two-dimensional image with topomap highlights.\n\n        Parameters\n        ----------\n        %(timefreqs)s\n        %(picks_good_data)s\n        %(exclude_psd)s\n            Default is an empty :class:`tuple` which includes all channels.\n        %(combine_tfr_plot_joint)s\n\n            .. versionchanged:: 1.3\n                Added support for ``callable``.\n        %(tmin_tmax_psd)s\n        %(fmin_fmax_tfr)s\n        %(baseline_rescale)s\n\n            How baseline is computed is determined by the ``mode`` parameter.\n        %(mode_tfr_plot)s\n        %(dB_tfr_plot_topo)s\n        %(yscale_tfr_plot)s\n        %(vlim_tfr_plot_joint)s\n        %(cnorm)s\n        %(cmap_tfr_plot_topo)s\n        %(colorbar_tfr_plot_joint)s\n        %(title_none)s\n        %(show)s\n        %(topomap_args)s\n        %(image_args)s\n        %(verbose)s\n\n        Returns\n        -------\n        fig : matplotlib.figure.Figure\n            The figure containing the topography.\n\n        Notes\n        -----\n        %(notes_timefreqs_tfr_plot_joint)s\n\n        .. versionadded:: 0.16.0\n        \"\"\"\n        from matplotlib import ticker\n        from matplotlib.patches import ConnectionPatch\n\n        # handle recursion\n        picks = _picks_to_idx(\n            self.info, picks, \"data_or_ica\", exclude=exclude, with_ref_meg=False\n        )\n        all_ch_types = np.array(self.get_channel_types())\n        uniq_ch_types = sorted(set(all_ch_types[picks]))\n        if len(uniq_ch_types) > 1:\n            msg = \"Multiple channel types selected, returning one figure per type.\"\n            logger.info(msg)\n            figs = list()\n            for this_type in uniq_ch_types:\n                this_picks = np.intersect1d(\n                    picks,\n                    np.nonzero(np.isin(all_ch_types, this_type))[0],\n                    assume_unique=True,\n                )\n                # TODO might be nice to not \"copy first, then pick\"; alternative might\n                # be to subset the data with `this_picks` and then construct the \"copy\"\n                # using __getstate__ and __setstate__\n                _tfr = self.copy().pick(this_picks)\n                figs.append(\n                    _tfr.plot_joint(\n                        timefreqs=timefreqs,\n                        picks=None,\n                        baseline=baseline,\n                        mode=mode,\n                        tmin=tmin,\n                        tmax=tmax,\n                        fmin=fmin,\n                        fmax=fmax,\n                        vlim=vlim,\n                        cmap=cmap,\n                        dB=dB,\n                        colorbar=colorbar,\n                        show=False,\n                        title=title,\n                        yscale=yscale,\n                        combine=combine,\n                        exclude=(),\n                        topomap_args=topomap_args,\n                        verbose=verbose,\n                    )\n                )\n            return figs\n        else:\n            ch_type = uniq_ch_types[0]\n\n        # handle defaults\n        _validate_type(combine, (\"str\", \"callable\"), item_name=\"combine\")  # no `None`\n        image_args = dict() if image_args is None else image_args\n        topomap_args = dict() if topomap_args is None else topomap_args.copy()\n        # make sure if topomap_args[\"ch_type\"] is set, it matches what is in `self.info`\n        topomap_args.setdefault(\"ch_type\", ch_type)\n        if topomap_args[\"ch_type\"] != ch_type:\n            raise ValueError(\n                f\"topomap_args['ch_type'] is {topomap_args['ch_type']} which does not \"\n                f\"match the channel type present in the object ({ch_type}).\"\n            )\n        # some necessary defaults\n        topomap_args.setdefault(\"outlines\", \"head\")\n        topomap_args.setdefault(\"contours\", 6)\n        # don't pass these:\n        topomap_args.pop(\"axes\", None)\n        topomap_args.pop(\"show\", None)\n        topomap_args.pop(\"colorbar\", None)\n\n        # get the time/freq limits of the image plot, to make sure requested annotation\n        # times/freqs are in range\n        _, times, freqs = self.get_data(\n            picks=picks,\n            exclude=(),\n            tmin=tmin,\n            tmax=tmax,\n            fmin=fmin,\n            fmax=fmax,\n            return_times=True,\n            return_freqs=True,\n        )\n        # validate requested annotation times and freqs\n        timefreqs = _get_timefreqs(self, timefreqs)\n        valid_timefreqs = dict()\n        while timefreqs:\n            (_time, _freq), (t_win, f_win) = timefreqs.popitem()\n            # convert to half-windows\n            t_win /= 2\n            f_win /= 2\n            # make sure the times / freqs are in-bounds\n            msg = (\n                \"Requested {} exceeds the range of the data ({}). Choose different \"\n                \"`timefreqs`.\"\n            )\n            if (times > _time).all() or (times < _time).all():\n                _var = f\"time point ({_time:0.3f} s)\"\n                _range = f\"{times[0]:0.3f} - {times[-1]:0.3f} s\"\n                raise ValueError(msg.format(_var, _range))\n            elif (freqs > _freq).all() or (freqs < _freq).all():\n                _var = f\"frequency ({_freq:0.1f} Hz)\"\n                _range = f\"{freqs[0]:0.1f} - {freqs[-1]:0.1f} Hz\"\n                raise ValueError(msg.format(_var, _range))\n            # snap the times/freqs to the nearest point we have an estimate for, and\n            # store the validated points\n            if t_win == 0:\n                _time = times[np.argmin(np.abs(times - _time))]\n            if f_win == 0:\n                _freq = freqs[np.argmin(np.abs(freqs - _freq))]\n            valid_timefreqs[(_time, _freq)] = (t_win, f_win)\n\n        # prep data for topomaps (unlike image plot, must include all channels of the\n        # current ch_type). Don't pass tmin/tmax here (crop later after baselining)\n        topomap_picks = _picks_to_idx(self.info, ch_type)\n        data, times, freqs = self.get_data(\n            picks=topomap_picks, exclude=(), return_times=True, return_freqs=True\n        )\n        # merge grads before baselining (makes ERDS visible)\n        info = pick_info(self.info, sel=topomap_picks, copy=True)\n        data, pos = _merge_if_grads(\n            data=data,\n            info=info,\n            ch_type=ch_type,\n            sphere=topomap_args.get(\"sphere\"),\n            combine=combine,\n        )\n        # loop over intended topomap locations, to find one vlim that works for all.\n        tf_array = np.array(list(valid_timefreqs))  # each row is [time, freq]\n        tf_array = tf_array[tf_array[:, 0].argsort()]  # sort by time\n        _vmin, _vmax = (np.inf, -np.inf)\n        topomap_arrays = list()\n        topomap_titles = list()\n        for _time, _freq in tf_array:\n            # reduce data to the range of interest in the TF plane (i.e., finally crop)\n            t_win, f_win = valid_timefreqs[(_time, _freq)]\n            _tmin, _tmax = np.array([-1, 1]) * t_win + _time\n            _fmin, _fmax = np.array([-1, 1]) * f_win + _freq\n            _data, *_ = _prep_data_for_plot(\n                data,\n                times,\n                freqs,\n                tmin=_tmin,\n                tmax=_tmax,\n                fmin=_fmin,\n                fmax=_fmax,\n                baseline=baseline,\n                mode=mode,\n                taper_weights=self.weights,\n                verbose=verbose,\n            )\n            _data = _data.mean(axis=(-1, -2))  # avg over times and freqs\n            topomap_arrays.append(_data)\n            _vmin = min(_data.min(), _vmin)\n            _vmax = max(_data.max(), _vmax)\n            # construct topopmap subplot title\n            t_pm = \"\" if t_win == 0 else f\" \u00b1 {t_win:0.2f}\"\n            f_pm = \"\" if f_win == 0 else f\" \u00b1 {f_win:0.1f}\"\n            _title = f\"{_time:0.2f}{t_pm} s,\\n{_freq:0.1f}{f_pm} Hz\"\n            topomap_titles.append(_title)\n        # handle cmap. Power may be negative depending on baseline strategy so set\n        # `norm` empirically. vmin/vmax will be handled separately within the `plot()`\n        # call for the image plot.\n        norm = np.min(topomap_arrays) >= 0.0\n        cmap = _setup_cmap(cmap, norm=norm)\n        topomap_args.setdefault(\"cmap\", cmap[0])  # prevent interactive cbar\n        # finalize topomap vlims and compute contour locations.\n        # By passing `data=None` here \u2193\u2193\u2193\u2193 we effectively assert vmin & vmax aren't None\n        _vlim = _setup_vmin_vmax(data=None, vmin=_vmin, vmax=_vmax, norm=norm)\n        topomap_args.setdefault(\"vlim\", _vlim)\n        locator, topomap_args[\"contours\"] = _set_contour_locator(\n            *topomap_args[\"vlim\"], topomap_args[\"contours\"]\n        )\n        # initialize figure and do the image plot. `self.plot()` needed to wait to be\n        # called until after `topomap_args` was fully populated --- we don't pass the\n        # dict through to `self.plot()` explicitly here, but we do \"reach back\" and get\n        # it if it's needed by the interactive rectangle selector.\n        fig, image_ax, topomap_axes = _prepare_joint_axes(len(valid_timefreqs))\n        fig = self.plot(\n            picks=picks,\n            exclude=(),\n            tmin=tmin,\n            tmax=tmax,\n            fmin=fmin,\n            fmax=fmax,\n            baseline=baseline,\n            mode=mode,\n            dB=dB,\n            combine=combine,\n            yscale=yscale,\n            vlim=vlim,\n            cnorm=cnorm,\n            cmap=cmap,\n            colorbar=False,\n            title=title,\n            # mask, mask_style, mask_cmap, mask_alpha\n            axes=image_ax,\n            show=False,\n            verbose=verbose,\n            **image_args,\n        )[0]  # [0] because `.plot()` always returns a list\n        # now, actually plot the topomaps\n        for ax, title, _data in zip(topomap_axes, topomap_titles, topomap_arrays):\n            ax.set_title(title)\n            plot_topomap(_data, pos, axes=ax, show=False, **topomap_args)\n        # draw colorbar\n        if colorbar:\n            cbar = fig.colorbar(ax.images[0])\n            cbar.locator = ticker.MaxNLocator(nbins=5) if locator is None else locator\n            cbar.update_ticks()\n        # draw the connection lines between time-frequency image and topoplots\n        for (time_, freq_), topo_ax in zip(tf_array, topomap_axes):\n            con = ConnectionPatch(\n                xyA=[time_, freq_],\n                xyB=[0.5, 0],\n                coordsA=\"data\",\n                coordsB=\"axes fraction\",\n                axesA=image_ax,\n                axesB=topo_ax,\n                color=\"grey\",\n                linestyle=\"-\",\n                linewidth=1.5,\n                alpha=0.66,\n                zorder=1,\n                clip_on=False,\n            )\n            fig.add_artist(con)\n\n        plt_show(show)\n        return fig", "metadata": {}}
{"_id": "mne_mne_time_frequency/tfr.py_plot_topo_code", "title": "plot_topo", "text": "def plot_topo(\n        self,\n        picks=None,\n        baseline=None,\n        mode=\"mean\",\n        tmin=None,\n        tmax=None,\n        fmin=None,\n        fmax=None,\n        vmin=None,  # TODO deprecate in favor of `vlim` (needs helper func refactor)\n        vmax=None,\n        layout=None,\n        cmap=\"RdBu_r\",\n        title=None,  # don't deprecate; topo titles aren't standard (color, size, just.)\n        dB=False,\n        colorbar=True,\n        layout_scale=0.945,\n        show=True,\n        border=\"none\",\n        fig_facecolor=\"k\",\n        fig_background=None,\n        font_color=\"w\",\n        yscale=\"auto\",\n        verbose=None,\n    ):\n        \"\"\"Plot a TFR image for each channel in a sensor layout arrangement.\n\n        Parameters\n        ----------\n        %(picks_good_data)s\n        %(baseline_rescale)s\n\n            How baseline is computed is determined by the ``mode`` parameter.\n        %(mode_tfr_plot)s\n        %(tmin_tmax_psd)s\n        %(fmin_fmax_tfr)s\n        %(vmin_vmax_tfr_plot_topo)s\n        %(layout_spectrum_plot_topo)s\n        %(cmap_tfr_plot_topo)s\n        %(title_none)s\n        %(dB_tfr_plot_topo)s\n        %(colorbar)s\n        %(layout_scale)s\n        %(show)s\n        %(border_topo)s\n        %(fig_facecolor)s\n        %(fig_background)s\n        %(font_color)s\n        %(yscale_tfr_plot)s\n        %(verbose)s\n\n        Returns\n        -------\n        fig : matplotlib.figure.Figure\n            The figure containing the topography.\n        \"\"\"\n        # convenience vars\n        times = self.times.copy()\n        freqs = self.freqs\n        data = self.data\n        info = self.info\n\n        info, data = _prepare_picks(info, data, picks, axis=0)\n        del picks\n\n        # baseline, crop, convert complex to power, aggregate tapers, and dB scaling\n        data, times, freqs = _prep_data_for_plot(\n            data,\n            times,\n            freqs,\n            tmin=tmin,\n            tmax=tmax,\n            fmin=fmin,\n            fmax=fmax,\n            baseline=baseline,\n            mode=mode,\n            dB=dB,\n            taper_weights=self.weights,\n            verbose=verbose,\n        )\n        # get vlims\n        vmin, vmax = _setup_vmin_vmax(data, vmin, vmax)\n\n        if layout is None:\n            from mne import find_layout\n\n            layout = find_layout(self.info)\n        onselect_callback = partial(self._onselect, baseline=baseline, mode=mode)\n\n        click_fun = partial(\n            _imshow_tfr,\n            tfr=data,\n            freq=freqs,\n            yscale=yscale,\n            cmap=(cmap, True),\n            onselect=onselect_callback,\n        )\n        imshow = partial(\n            _imshow_tfr_unified,\n            tfr=data,\n            freq=freqs,\n            cmap=cmap,\n            onselect=onselect_callback,\n        )\n\n        fig = _plot_topo(\n            info=info,\n            times=times,\n            show_func=imshow,\n            click_func=click_fun,\n            layout=layout,\n            colorbar=colorbar,\n            vmin=vmin,\n            vmax=vmax,\n            cmap=cmap,\n            layout_scale=layout_scale,\n            title=title,\n            border=border,\n            x_label=\"Time (s)\",\n            y_label=\"Frequency (Hz)\",\n            fig_facecolor=fig_facecolor,\n            font_color=font_color,\n            unified=True,\n            img=True,\n        )\n\n        add_background_image(fig, fig_background)\n        plt_show(show)\n        return fig", "metadata": {}}
{"_id": "mne_mne_time_frequency/tfr.py_save_code", "title": "save", "text": "def save(self, fname, *, overwrite=False, verbose=None):\n        \"\"\"Save time-frequency data to disk (in HDF5 format).\n\n        Parameters\n        ----------\n        fname : path-like\n            Path of file to save to, which should end with ``-tfr.h5`` or ``-tfr.hdf5``.\n        %(overwrite)s\n        %(verbose)s\n\n        See Also\n        --------\n        mne.time_frequency.read_tfrs\n        \"\"\"\n        _, write_hdf5 = _import_h5io_funcs()\n        check_fname(fname, \"time-frequency object\", (\".h5\", \".hdf5\"))\n        fname = _check_fname(fname, overwrite=overwrite, verbose=verbose)\n        out = self.__getstate__()\n        if \"metadata\" in out:\n            out[\"metadata\"] = _prepare_write_metadata(out[\"metadata\"])\n        write_hdf5(fname, out, overwrite=overwrite, title=\"mnepython\", slash=\"replace\")", "metadata": {}}
{"_id": "mne_mne_time_frequency/tfr.py_to_data_frame_code", "title": "to_data_frame", "text": "def to_data_frame(\n        self,\n        picks=None,\n        index=None,\n        long_format=False,\n        time_format=None,\n        *,\n        verbose=None,\n    ):\n        \"\"\"Export data in tabular structure as a pandas DataFrame.\n\n        Channels are converted to columns in the DataFrame. By default, additional\n        columns ``'time'``, ``'freq'``, ``'taper'``, ``'epoch'``, and ``'condition'``\n        (epoch event description) are added, unless ``index`` is not ``None`` (in which\n        case the columns specified in ``index`` will be used to form the DataFrame's\n        index instead). ``'epoch'``, and ``'condition'`` are not supported for\n        ``AverageTFR``. ``'taper'`` is only supported when a taper dimensions is\n        present, such as for complex or phase multitaper data.\n\n        Parameters\n        ----------\n        %(picks_all)s\n        %(index_df_epo)s\n            Valid string values are ``'time'``, ``'freq'``, ``'taper'``, ``'epoch'``,\n            and ``'condition'`` for ``EpochsTFR`` and ``'time'``, ``'freq'``, and\n            ``'taper'`` for ``AverageTFR``. Defaults to ``None``.\n        %(long_format_df_epo)s\n        %(time_format_df)s\n\n            .. versionadded:: 0.23\n        %(verbose)s\n\n        Returns\n        -------\n        %(df_return)s\n        \"\"\"\n        # check pandas once here, instead of in each private utils function\n        pd = _check_pandas_installed()  # noqa\n        # triage for Epoch-derived or unaggregated spectra\n        from_epo = isinstance(self, EpochsTFR)\n        unagg_mt = \"taper\" in self._dims\n        # arg checking\n        valid_index_args = [\"time\", \"freq\"]\n        if from_epo:\n            valid_index_args.extend([\"epoch\", \"condition\"])\n        if unagg_mt:\n            valid_index_args.append(\"taper\")\n        valid_time_formats = [\"ms\", \"timedelta\"]\n        index = _check_pandas_index_arguments(index, valid_index_args)\n        time_format = _check_time_format(time_format, valid_time_formats)\n        # get data\n        picks = _picks_to_idx(self.info, picks, \"all\", exclude=())\n        data, times, freqs, tapers = self.get_data(\n            picks, return_times=True, return_freqs=True, return_tapers=True\n        )\n        ch_axis = self._dims.index(\"channel\")\n        if not from_epo:\n            data = data[np.newaxis]  # add singleton \"epochs\" axis\n            ch_axis += 1\n        if not unagg_mt:\n            data = np.expand_dims(data, -3)  # add singleton \"tapers\" axis\n        n_epochs, n_picks, n_tapers, n_freqs, n_times = data.shape\n        # reshape to (epochs*tapers*freqs*times) x signals\n        data = np.moveaxis(data, ch_axis, -1)\n        data = data.reshape(n_epochs * n_tapers * n_freqs * n_times, n_picks)\n        # prepare extra columns / multiindex\n        mindex = list()\n        default_index = list()\n        times = _convert_times(times, time_format, self.info[\"meas_date\"])\n        times = np.tile(times, n_epochs * n_freqs * n_tapers)\n        freqs = np.tile(np.repeat(freqs, n_times), n_epochs * n_tapers)\n        mindex.append((\"time\", times))\n        mindex.append((\"freq\", freqs))\n        if from_epo:\n            mindex.append(\n                (\"epoch\", np.repeat(self.selection, n_times * n_freqs * n_tapers))\n            )\n            rev_event_id = {v: k for k, v in self.event_id.items()}\n            conditions = [rev_event_id[k] for k in self.events[:, 2]]\n            mindex.append(\n                (\"condition\", np.repeat(conditions, n_times * n_freqs * n_tapers))\n            )\n            default_index.extend([\"condition\", \"epoch\"])\n        if unagg_mt:\n            tapers = np.repeat(np.tile(tapers, n_epochs), n_freqs * n_times)\n            mindex.append((\"taper\", tapers))\n            default_index.append(\"taper\")\n        default_index.extend([\"freq\", \"time\"])\n        assert all(len(mdx) == len(mindex[0]) for mdx in mindex[1:])\n        # build DataFrame\n        df = _build_data_frame(\n            self, data, picks, long_format, mindex, index, default_index=default_index\n        )\n        return df", "metadata": {}}
{"_id": "mne_mne_time_frequency/tfr.py_average_code", "title": "average", "text": "def average(self, method=\"mean\", *, dim=\"epochs\", copy=False):\n        \"\"\"Aggregate the EpochsTFR across epochs, frequencies, or times.\n\n        Parameters\n        ----------\n        method : \"mean\" | \"median\" | callable\n            How to aggregate the data across the given ``dim``. If callable,\n            must take a :class:`NumPy array<numpy.ndarray>` of shape\n            ``(n_epochs, n_channels, n_freqs, n_times)`` and return an array\n            with one fewer dimensions (which dimension is collapsed depends on\n            the value of ``dim``). Default is ``\"mean\"``.\n        dim : \"epochs\" | \"freqs\" | \"times\"\n            The dimension along which to combine the data.\n        copy : bool\n            Whether to return a copy of the modified instance, or modify in place.\n            Ignored when ``dim=\"epochs\"`` or ``\"times\"`` because those options return\n            different types (:class:`~mne.time_frequency.AverageTFR` and\n            :class:`~mne.time_frequency.EpochsSpectrum`, respectively).\n\n        Returns\n        -------\n        tfr : instance of EpochsTFR | AverageTFR | EpochsSpectrum\n            The aggregated TFR object.\n\n        Notes\n        -----\n        Passing in ``np.median`` is considered unsafe for complex data; pass\n        the string ``\"median\"`` instead to compute the *marginal* median\n        (i.e. the median of the real and imaginary components separately).\n        See discussion here:\n\n        https://github.com/scipy/scipy/pull/12676#issuecomment-783370228\n\n        Averaging is not supported for data containing a taper dimension.\n        \"\"\"\n        if \"taper\" in self._dims:\n            raise NotImplementedError(\n                \"Averaging multitaper tapers across epochs, frequencies, or times is \"\n                \"not supported. If averaging across epochs, consider averaging the \"\n                \"epochs before computing the complex/phase spectrum.\"\n            )\n\n        _check_option(\"dim\", dim, (\"epochs\", \"freqs\", \"times\"))\n        axis = self._dims.index(dim[:-1])  # self._dims entries aren't plural\n\n        func = _check_combine(mode=method, axis=axis)\n        data = func(self.data)\n\n        n_epochs, n_channels, n_freqs, n_times = self.data.shape\n        freqs, times = self.freqs, self.times\n        if dim == \"epochs\":\n            expected_shape = self._data.shape[1:]\n        elif dim == \"freqs\":\n            expected_shape = (n_epochs, n_channels, n_times)\n            freqs = np.mean(self.freqs, keepdims=True)\n        elif dim == \"times\":\n            expected_shape = (n_epochs, n_channels, n_freqs)\n            times = np.mean(self.times, keepdims=True)\n\n        if data.shape != expected_shape:\n            raise RuntimeError(\n                \"EpochsTFR.average() got a method that resulted in data of shape \"\n                f\"{data.shape}, but it should be {expected_shape}.\"\n            )\n        state = self.__getstate__()\n        # restore singleton freqs axis (not necessary for epochs/times: class changes)\n        if dim == \"freqs\":\n            data = np.expand_dims(data, axis=axis)\n        else:\n            state[\"dims\"] = (*state[\"dims\"][:axis], *state[\"dims\"][axis + 1 :])\n        state[\"data\"] = data\n        state[\"info\"] = deepcopy(self.info)\n        state[\"freqs\"] = freqs\n        state[\"times\"] = times\n        if dim == \"epochs\":\n            state[\"inst_type_str\"] = \"Evoked\"\n            state[\"nave\"] = n_epochs\n            state[\"comment\"] = f\"{method} of {n_epochs} EpochsTFR{_pl(n_epochs)}\"\n            out = AverageTFR(inst=state)\n            out._data_type = \"Average Power\"\n            return out\n\n        elif dim == \"times\":\n            return EpochsSpectrum(\n                state,\n                method=None,\n                fmin=None,\n                fmax=None,\n                tmin=None,\n                tmax=None,\n                picks=None,\n                exclude=None,\n                proj=None,\n                remove_dc=None,\n                n_jobs=None,\n            )\n        # \u2193\u2193\u2193 these two are for dim == \"freqs\"\n        elif copy:\n            return EpochsTFR(inst=state, method=None, freqs=None)\n        else:\n            self._data = np.expand_dims(data, axis=axis)\n            self._freqs = freqs\n            return self", "metadata": {}}
{"_id": "mne_mne_time_frequency/tfr.py_drop_code", "title": "drop", "text": "def drop(self, indices, reason=\"USER\", verbose=None):\n        \"\"\"Drop epochs based on indices or boolean mask.\n\n        .. note:: The indices refer to the current set of undropped epochs\n                  rather than the complete set of dropped and undropped epochs.\n                  They are therefore not necessarily consistent with any\n                  external indices (e.g., behavioral logs). To drop epochs\n                  based on external criteria, do not use the ``preload=True``\n                  flag when constructing an Epochs object, and call this\n                  method before calling the :meth:`mne.Epochs.drop_bad` or\n                  :meth:`mne.Epochs.load_data` methods.\n\n        Parameters\n        ----------\n        indices : array of int or bool\n            Set epochs to remove by specifying indices to remove or a boolean\n            mask to apply (where True values get removed). Events are\n            correspondingly modified.\n        reason : str\n            Reason for dropping the epochs ('ECG', 'timeout', 'blink' etc).\n            Default: 'USER'.\n        %(verbose)s\n\n        Returns\n        -------\n        epochs : instance of Epochs or EpochsTFR\n            The epochs with indices dropped. Operates in-place.\n        \"\"\"\n        from ..epochs import BaseEpochs\n\n        BaseEpochs.drop(self, indices=indices, reason=reason, verbose=verbose)\n\n        return self", "metadata": {}}
{"_id": "mne_mne_time_frequency/tfr.py_iter_evoked_code", "title": "iter_evoked", "text": "def iter_evoked(self, copy=False):\n        \"\"\"Iterate over EpochsTFR to yield a sequence of AverageTFR objects.\n\n        The AverageTFR objects will each contain a single epoch (i.e., no averaging is\n        performed). This method resets the EpochTFR instance's iteration state to the\n        first epoch.\n\n        Parameters\n        ----------\n        copy : bool\n            Whether to yield copies of the data and measurement info, or views/pointers.\n        \"\"\"\n        self.__iter__()\n        state = self.__getstate__()\n        state[\"inst_type_str\"] = \"Evoked\"\n        state[\"dims\"] = state[\"dims\"][1:]  # drop \"epochs\"\n\n        while True:\n            try:\n                data, event_id = self.__next__(return_event_id=True)\n            except StopIteration:\n                break\n            if copy:\n                state[\"info\"] = deepcopy(self.info)\n                state[\"data\"] = data.copy()\n            else:\n                state[\"data\"] = data\n            state[\"nave\"] = 1\n            yield AverageTFR(inst=state, method=None, freqs=None, comment=str(event_id))", "metadata": {}}
{"_id": "mne_mne_time_frequency/multitaper.py_dpss_windows_code", "title": "dpss_windows", "text": "def dpss_windows(N, half_nbw, Kmax, *, sym=True, norm=None, low_bias=True):\n    \"\"\"Compute Discrete Prolate Spheroidal Sequences.\n\n    Will give of orders [0,Kmax-1] for a given frequency-spacing multiple\n    NW and sequence length N.\n\n    .. note:: Copied from NiTime.\n\n    Parameters\n    ----------\n    N : int\n        Sequence length.\n    half_nbw : float\n        Standardized half bandwidth corresponding to 2 * half_bw = BW*f0\n        = BW*N/dt but with dt taken as 1.\n    Kmax : int\n        Number of DPSS windows to return is Kmax (orders 0 through Kmax-1).\n    sym : bool\n        Whether to generate a symmetric window (``True``, for filter design) or\n        a periodic window (``False``, for spectral analysis). Default is\n        ``True``.\n\n        .. versionadded:: 1.3\n    norm : 2 | ``'approximate'`` | ``'subsample'`` | None\n        Window normalization method. If ``'approximate'`` or ``'subsample'``,\n        windows are normalized by the maximum, and a correction scale-factor\n        for even-length windows is applied either using\n        ``N**2/(N**2+half_nbw)`` (\"approximate\") or a FFT-based subsample shift\n        (\"subsample\"). ``2`` uses the L2 norm. ``None`` (the default) uses\n        ``\"approximate\"`` when ``Kmax=None`` and ``2`` otherwise.\n\n        .. versionadded:: 1.3\n    low_bias : bool\n        Keep only tapers with eigenvalues > 0.9.\n\n    Returns\n    -------\n    v, e : tuple,\n        The v array contains DPSS windows shaped (Kmax, N).\n        e are the eigenvalues.\n\n    Notes\n    -----\n    Tridiagonal form of DPSS calculation from :footcite:`Slepian1978`.\n\n    References\n    ----------\n    .. footbibliography::\n    \"\"\"\n    # TODO VERSION can be removed with SciPy 1.16 is min,\n    # workaround for https://github.com/scipy/scipy/pull/22344\n    if N <= 1:\n        dpss, eigvals = np.ones((1, 1)), np.ones(1)\n    else:\n        dpss, eigvals = sp_dpss(\n            N, half_nbw, Kmax, sym=sym, norm=norm, return_ratios=True\n        )\n    if low_bias:\n        idx = eigvals > 0.9\n        if not idx.any():\n            warn(\"Could not properly use low_bias, keeping lowest-bias taper\")\n            idx = [np.argmax(eigvals)]\n        dpss, eigvals = dpss[idx], eigvals[idx]\n    assert len(dpss) > 0  # should never happen\n    assert dpss.shape[1] == N  # old nitime bug\n    return dpss, eigvals", "metadata": {}}
{"_id": "mne_mne_time_frequency/multitaper.py_psd_array_multitaper_code", "title": "psd_array_multitaper", "text": "def psd_array_multitaper(\n    x,\n    sfreq,\n    fmin=0.0,\n    fmax=np.inf,\n    bandwidth=None,\n    adaptive=False,\n    low_bias=True,\n    normalization=\"length\",\n    remove_dc=True,\n    output=\"power\",\n    n_jobs=None,\n    *,\n    max_iter=150,\n    verbose=None,\n):\n    r\"\"\"Compute power spectral density (PSD) using a multi-taper method.\n\n    The power spectral density is computed with DPSS\n    tapers :footcite:p:`Slepian1978`.\n\n    Parameters\n    ----------\n    x : array, shape=(..., n_times)\n        The data to compute PSD from.\n    sfreq : float\n        The sampling frequency.\n    %(fmin_fmax_psd)s\n    bandwidth : float\n        Frequency bandwidth of the multi-taper window function in Hz. For a\n        given frequency, frequencies at ``\u00b1 bandwidth / 2`` are smoothed\n        together. The default value is a bandwidth of\n        ``8 * (sfreq / n_times)``.\n    adaptive : bool\n        Use adaptive weights to combine the tapered spectra into PSD\n        (slow, use n_jobs >> 1 to speed up computation).\n    low_bias : bool\n        Only use tapers with more than 90%% spectral concentration within\n        bandwidth.\n    %(normalization)s\n    %(remove_dc)s\n    output : str\n        The format of the returned ``psds`` array, ``'complex'`` or\n        ``'power'``:\n\n        * ``'power'`` : the power spectral density is returned.\n        * ``'complex'`` : the complex fourier coefficients are returned per\n          taper.\n    %(n_jobs)s\n    %(max_iter_multitaper)s\n    %(verbose)s\n\n    Returns\n    -------\n    psds : ndarray, shape (..., n_freqs) or (..., n_tapers, n_freqs)\n        The power spectral densities. All dimensions up to the last (or the\n        last two if ``output='complex'``) will be the same as input.\n    freqs : array\n        The frequency points in Hz of the PSD.\n    weights : ndarray\n        The weights used for averaging across tapers. Only returned if\n        ``output='complex'``.\n\n    See Also\n    --------\n    csd_multitaper\n    mne.io.Raw.compute_psd\n    mne.Epochs.compute_psd\n    mne.Evoked.compute_psd\n\n    Notes\n    -----\n    .. versionadded:: 0.14.0\n\n    References\n    ----------\n    .. footbibliography::\n    \"\"\"\n    _check_option(\"normalization\", normalization, [\"length\", \"full\"])\n\n    # Reshape data so its 2-D for parallelization\n    ndim_in = x.ndim\n    x = np.atleast_2d(x)\n    n_times = x.shape[-1]\n    dshape = x.shape[:-1]\n    x = x.reshape(-1, n_times)\n\n    dpss, eigvals, adaptive = _compute_mt_params(\n        n_times, sfreq, bandwidth, low_bias, adaptive\n    )\n    n_tapers = len(dpss)\n    weights = np.sqrt(eigvals)[np.newaxis, :, np.newaxis]\n\n    # decide which frequencies to keep\n    freqs = rfftfreq(n_times, 1.0 / sfreq)\n    freq_mask = (freqs >= fmin) & (freqs <= fmax)\n    freqs = freqs[freq_mask]\n    n_freqs = len(freqs)\n\n    if output == \"complex\":\n        psd = np.zeros((x.shape[0], n_tapers, n_freqs), dtype=\"complex\")\n    else:\n        psd = np.zeros((x.shape[0], n_freqs))\n\n    # Let's go in up to 50 MB chunks of signals to save memory\n    n_chunk = max(50000000 // (len(freq_mask) * len(eigvals) * 16), 1)\n    offsets = np.concatenate((np.arange(0, x.shape[0], n_chunk), [x.shape[0]]))\n    for start, stop in zip(offsets[:-1], offsets[1:]):\n        x_mt = _mt_spectra(x[start:stop], dpss, sfreq, remove_dc=remove_dc)[0]\n        if output == \"power\":\n            if not adaptive:\n                psd[start:stop] = _psd_from_mt(x_mt[:, :, freq_mask], weights)\n            else:\n                parallel, my_psd_from_mt_adaptive, n_jobs = parallel_func(\n                    _psd_from_mt_adaptive, n_jobs\n                )\n                n_splits = min(stop - start, n_jobs)\n                out = parallel(\n                    my_psd_from_mt_adaptive(x, eigvals, freq_mask, max_iter)\n                    for x in np.array_split(x_mt, n_splits)\n                )\n                psd[start:stop] = np.concatenate(out)\n        else:\n            psd[start:stop] = x_mt[:, :, freq_mask]\n\n    if normalization == \"full\":\n        psd /= sfreq\n\n    # Combining/reshaping to original data shape\n    last_dims = (n_freqs,) if output == \"power\" else (n_tapers, n_freqs)\n    psd.shape = dshape + last_dims\n    if ndim_in == 1:\n        psd = psd[0]\n\n    if output == \"complex\":\n        return psd, freqs, weights\n    else:\n        return psd, freqs", "metadata": {}}
{"_id": "mne_mne_time_frequency/multitaper.py_tfr_array_multitaper_code", "title": "tfr_array_multitaper", "text": "def tfr_array_multitaper(\n    data,\n    sfreq,\n    freqs,\n    n_cycles=7.0,\n    zero_mean=True,\n    time_bandwidth=4.0,\n    use_fft=True,\n    decim=1,\n    output=\"complex\",\n    n_jobs=None,\n    *,\n    return_weights=False,\n    verbose=None,\n):\n    \"\"\"Compute Time-Frequency Representation (TFR) using DPSS tapers.\n\n    Same computation as `~mne.time_frequency.tfr_multitaper`, but operates on\n    :class:`NumPy arrays <numpy.ndarray>` instead of `~mne.Epochs` or\n    `~mne.Evoked` objects.\n\n    Parameters\n    ----------\n    data : array of shape (n_epochs, n_channels, n_times)\n        The epochs.\n    sfreq : float\n        Sampling frequency of the data in Hz.\n    %(freqs_tfr_array)s\n    %(n_cycles_tfr)s\n    zero_mean : bool\n        If True, make sure the wavelets have a mean of zero. Defaults to True.\n    %(time_bandwidth_tfr)s\n    use_fft : bool\n        Use the FFT for convolutions or not. Defaults to True.\n    %(decim_tfr)s\n    output : str, default 'complex'\n\n        * ``'complex'`` : single trial per taper complex values.\n        * ``'power'`` : single trial power.\n        * ``'phase'`` : single trial per taper phase.\n        * ``'avg_power'`` : average of single trial power.\n        * ``'itc'`` : inter-trial coherence.\n        * ``'avg_power_itc'`` : average of single trial power and inter-trial\n          coherence across trials.\n    %(n_jobs)s\n        The parallelization is implemented across channels.\n    return_weights : bool, default False\n        If True, return the taper weights. Only applies if ``output='complex'`` or\n        ``'phase'``.\n\n        .. versionadded:: 1.10.0\n    %(verbose)s\n\n    Returns\n    -------\n    out : array\n        Time frequency transform of ``data``.\n\n        - if ``output in ('complex',' 'phase')``, array of shape\n          ``(n_epochs, n_chans, n_tapers, n_freqs, n_times)``\n        - if ``output`` is ``'power'``, array of shape ``(n_epochs, n_chans,\n          n_freqs, n_times)``\n        - else, array of shape ``(n_chans, n_freqs, n_times)``\n\n        If ``output`` is ``'avg_power_itc'``, the real values in ``out``\n        contain the average power and the imaginary values contain the\n        inter-trial coherence: :math:`out = power_{avg} + i * ITC`.\n    weights : array of shape (n_tapers, n_freqs)\n        The taper weights. Only returned if ``output='complex'`` or ``'phase'`` and\n        ``return_weights=True``.\n\n    See Also\n    --------\n    mne.time_frequency.tfr_multitaper\n    mne.time_frequency.tfr_morlet\n    mne.time_frequency.tfr_array_morlet\n    mne.time_frequency.tfr_stockwell\n    mne.time_frequency.tfr_array_stockwell\n\n    Notes\n    -----\n    %(temporal_window_tfr_intro)s\n    %(temporal_window_tfr_multitaper_notes)s\n    %(time_bandwidth_tfr_notes)s\n\n    .. versionadded:: 0.14.0\n    \"\"\"\n    from .tfr import _compute_tfr\n\n    return _compute_tfr(\n        data,\n        freqs,\n        sfreq=sfreq,\n        method=\"multitaper\",\n        n_cycles=n_cycles,\n        zero_mean=zero_mean,\n        time_bandwidth=time_bandwidth,\n        use_fft=use_fft,\n        decim=decim,\n        output=output,\n        return_weights=return_weights,\n        n_jobs=n_jobs,\n        verbose=verbose,\n    )", "metadata": {}}
{"_id": "mne_mne_time_frequency/ar.py_fit_iir_model_raw_code", "title": "fit_iir_model_raw", "text": "def fit_iir_model_raw(raw, order=2, picks=None, tmin=None, tmax=None, verbose=None):\n    r\"\"\"Fit an AR model to raw data and creates the corresponding IIR filter.\n\n    The computed filter is fitted to data from all of the picked channels,\n    with frequency response given by the standard IIR formula:\n\n    .. math::\n\n        H(e^{jw}) = \\frac{1}{a[0] + a[1]e^{-jw} + ... + a[n]e^{-jnw}}\n\n    Parameters\n    ----------\n    raw : Raw object\n        An instance of Raw.\n    order : int\n        Order of the FIR filter.\n    %(picks_good_data)s\n    tmin : float\n        The beginning of time interval in seconds.\n    tmax : float\n        The end of time interval in seconds.\n    %(verbose)s\n\n    Returns\n    -------\n    b : ndarray\n        Numerator filter coefficients.\n    a : ndarray\n        Denominator filter coefficients.\n    \"\"\"\n    start, stop = None, None\n    if tmin is not None:\n        start = raw.time_as_index(tmin)[0]\n    if tmax is not None:\n        stop = raw.time_as_index(tmax)[0] + 1\n    picks = _picks_to_idx(raw.info, picks)\n    data = raw[picks, start:stop][0]\n    # rescale data to similar levels\n    picks_list = _picks_by_type(pick_info(raw.info, picks))\n    scalings = _handle_default(\"scalings_cov_rank\", None)\n    _apply_scaling_array(data, picks_list=picks_list, scalings=scalings)\n    # do the fitting\n    coeffs, _ = _yule_walker(data, order=order)\n    return np.array([1.0]), np.concatenate(([1.0], -coeffs))", "metadata": {}}
{"_id": "mne_mne_time_frequency/_stft.py_stft_code", "title": "stft", "text": "def stft(x, wsize, tstep=None, verbose=None):\n    \"\"\"STFT Short-Term Fourier Transform using a sine window.\n\n    The transformation is designed to be a tight frame that can be\n    perfectly inverted. It only returns the positive frequencies.\n\n    Parameters\n    ----------\n    x : array, shape (n_signals, n_times)\n        Containing multi-channels signal.\n    wsize : int\n        Length of the STFT window in samples (must be a multiple of 4).\n    tstep : int\n        Step between successive windows in samples (must be a multiple of 2,\n        a divider of wsize and smaller than wsize/2) (default: wsize/2).\n    %(verbose)s\n\n    Returns\n    -------\n    X : array, shape (n_signals, wsize // 2 + 1, n_step)\n        STFT coefficients for positive frequencies with\n        ``n_step = ceil(T / tstep)``.\n\n    See Also\n    --------\n    istft\n    stftfreq\n    \"\"\"\n    if not np.isrealobj(x):\n        raise ValueError(\"x is not a real valued array\")\n\n    if x.ndim == 1:\n        x = x[None, :]\n\n    n_signals, T = x.shape\n    wsize = int(wsize)\n\n    # Errors and warnings\n    if wsize % 4:\n        raise ValueError(\"The window length must be a multiple of 4.\")\n\n    if tstep is None:\n        tstep = wsize / 2\n\n    tstep = int(tstep)\n\n    if (wsize % tstep) or (tstep % 2):\n        raise ValueError(\n            \"The step size must be a multiple of 2 and a divider of the window length.\"\n        )\n\n    if tstep > wsize / 2:\n        raise ValueError(\"The step size must be smaller than half the window length.\")\n\n    n_step = int(ceil(T / float(tstep)))\n    n_freq = wsize // 2 + 1\n    logger.info(f\"Number of frequencies: {n_freq}\")\n    logger.info(f\"Number of time steps: {n_step}\")\n\n    X = np.zeros((n_signals, n_freq, n_step), dtype=np.complex128)\n\n    if n_signals == 0:\n        return X\n\n    # Defining sine window\n    win = np.sin(np.arange(0.5, wsize + 0.5) / wsize * np.pi)\n    win2 = win**2\n\n    swin = np.zeros((n_step - 1) * tstep + wsize)\n    for t in range(n_step):\n        swin[t * tstep : t * tstep + wsize] += win2\n    swin = np.sqrt(wsize * swin)\n\n    # Zero-padding and Pre-processing for edges\n    xp = np.zeros((n_signals, wsize + (n_step - 1) * tstep), dtype=x.dtype)\n    xp[:, (wsize - tstep) // 2 : (wsize - tstep) // 2 + T] = x\n    x = xp\n\n    for t in range(n_step):\n        # Framing\n        wwin = win / swin[t * tstep : t * tstep + wsize]\n        frame = x[:, t * tstep : t * tstep + wsize] * wwin[None, :]\n        # FFT\n        X[:, :, t] = rfft(frame)\n\n    return X", "metadata": {}}
{"_id": "mne_mne_time_frequency/_stft.py_istft_code", "title": "istft", "text": "def istft(X, tstep=None, Tx=None):\n    \"\"\"ISTFT Inverse Short-Term Fourier Transform using a sine window.\n\n    Parameters\n    ----------\n    X : array, shape (..., wsize / 2 + 1, n_step)\n        The STFT coefficients for positive frequencies.\n    tstep : int\n        Step between successive windows in samples (must be a multiple of 2,\n        a divider of wsize and smaller than wsize/2) (default: wsize/2).\n    Tx : int\n        Length of returned signal. If None Tx = n_step * tstep.\n\n    Returns\n    -------\n    x : array, shape (Tx,)\n        Array containing the inverse STFT signal.\n\n    See Also\n    --------\n    stft\n    \"\"\"\n    # Errors and warnings\n    X = np.asarray(X)\n    if X.ndim < 2:\n        raise ValueError(f\"X must have ndim >= 2, got {X.ndim}\")\n    n_win, n_step = X.shape[-2:]\n    signal_shape = X.shape[:-2]\n    if n_win % 2 == 0:\n        raise ValueError(\"The number of rows of the STFT matrix must be odd.\")\n\n    wsize = 2 * (n_win - 1)\n    if tstep is None:\n        tstep = wsize / 2\n\n    if wsize % tstep:\n        raise ValueError(\n            \"The step size must be a divider of two times the \"\n            \"number of rows of the STFT matrix minus two.\"\n        )\n\n    if wsize % 2:\n        raise ValueError(\"The step size must be a multiple of 2.\")\n\n    if tstep > wsize / 2:\n        raise ValueError(\n            \"The step size must be smaller than the number of \"\n            \"rows of the STFT matrix minus one.\"\n        )\n\n    if Tx is None:\n        Tx = n_step * tstep\n\n    T = n_step * tstep\n\n    x = np.zeros(signal_shape + (T + wsize - tstep,), dtype=np.float64)\n\n    if np.prod(signal_shape) == 0:\n        return x[..., :Tx]\n\n    # Defining sine window\n    win = np.sin(np.arange(0.5, wsize + 0.5) / wsize * np.pi)\n    # win = win / norm(win);\n\n    # Pre-processing for edges\n    swin = np.zeros(T + wsize - tstep, dtype=np.float64)\n    for t in range(n_step):\n        swin[t * tstep : t * tstep + wsize] += win**2\n    swin = np.sqrt(swin / wsize)\n\n    for t in range(n_step):\n        # IFFT\n        frame = irfft(X[..., t], wsize)\n        # Overlap-add\n        frame *= win / swin[t * tstep : t * tstep + wsize]\n        x[..., t * tstep : t * tstep + wsize] += frame\n\n    # Truncation\n    x = x[..., (wsize - tstep) // 2 : (wsize - tstep) // 2 + T + 1]\n    x = x[..., :Tx].copy()\n    return x", "metadata": {}}
{"_id": "mne_mne_time_frequency/_stft.py_stftfreq_code", "title": "stftfreq", "text": "def stftfreq(wsize, sfreq=None):  # noqa: D401\n    \"\"\"Compute frequencies of stft transformation.\n\n    Parameters\n    ----------\n    wsize : int\n        Size of stft window.\n    sfreq : float\n        Sampling frequency. If None the frequencies are given between 0 and pi\n        otherwise it's given in Hz.\n\n    Returns\n    -------\n    freqs : array\n        The positive frequencies returned by stft.\n\n    See Also\n    --------\n    stft\n    istft\n    \"\"\"\n    freqs = rfftfreq(wsize)\n    if sfreq is not None:\n        freqs *= float(sfreq)\n    return freqs", "metadata": {}}
{"_id": "mne_mne_time_frequency/_stft.py_stft_norm2_code", "title": "stft_norm2", "text": "def stft_norm2(X):\n    \"\"\"Compute L2 norm of STFT transform.\n\n    It takes into account that stft only return positive frequencies.\n    As we use tight frame this quantity is conserved by the stft.\n\n    Parameters\n    ----------\n    X : 3D complex array\n        The STFT transforms\n\n    Returns\n    -------\n    norms2 : array\n        The squared L2 norm of every row of X.\n    \"\"\"\n    X2 = (X * X.conj()).real\n    # compute all L2 coefs and remove first and last frequency once.\n    norms2 = (\n        2.0 * X2.sum(axis=2).sum(axis=1)\n        - np.sum(X2[:, 0, :], axis=1)\n        - np.sum(X2[:, -1, :], axis=1)\n    )\n    return norms2", "metadata": {}}
{"_id": "mne_mne_time_frequency/_stft.py_stft_norm1_code", "title": "stft_norm1", "text": "def stft_norm1(X):\n    \"\"\"Compute L1 norm of STFT transform.\n\n    It takes into account that stft only return positive frequencies.\n\n    Parameters\n    ----------\n    X : 3D complex array\n        The STFT transforms\n\n    Returns\n    -------\n    norms : array\n        The L1 norm of every row of X.\n    \"\"\"\n    X_abs = np.abs(X)\n    # compute all L1 coefs and remove first and last frequency once.\n    norms = (\n        2.0 * X_abs.sum(axis=(1, 2))\n        - np.sum(X_abs[:, 0, :], axis=1)\n        - np.sum(X_abs[:, -1, :], axis=1)\n    )\n    return norms", "metadata": {}}
{"_id": "mne_mne_time_frequency/psd.py_psd_array_welch_code", "title": "psd_array_welch", "text": "def psd_array_welch(\n    x,\n    sfreq,\n    fmin=0,\n    fmax=np.inf,\n    n_fft=256,\n    n_overlap=0,\n    n_per_seg=None,\n    n_jobs=None,\n    average=\"mean\",\n    window=\"hamming\",\n    remove_dc=True,\n    *,\n    output=\"power\",\n    verbose=None,\n):\n    \"\"\"Compute power spectral density (PSD) using Welch's method.\n\n    Welch's method is described in :footcite:t:`Welch1967`.\n\n    Parameters\n    ----------\n    x : array, shape=(..., n_times)\n        The data to compute PSD from.\n    sfreq : float\n        The sampling frequency.\n    fmin : float\n        The lower frequency of interest.\n    fmax : float\n        The upper frequency of interest.\n    n_fft : int\n        The length of FFT used, must be ``>= n_per_seg`` (default: 256).\n        The segments will be zero-padded if ``n_fft > n_per_seg``.\n    n_overlap : int\n        The number of points of overlap between segments. Will be adjusted\n        to be <= n_per_seg. The default value is 0.\n    n_per_seg : int | None\n        Length of each Welch segment (windowed with a Hamming window). Defaults\n        to None, which sets n_per_seg equal to n_fft.\n    %(n_jobs)s\n    %(average_psd)s\n\n        .. versionadded:: 0.19.0\n    %(window_psd)s\n\n        .. versionadded:: 0.22.0\n    %(remove_dc)s\n\n    output : str\n        The format of the returned ``psds`` array, ``'complex'`` or\n        ``'power'``:\n\n        * ``'power'`` : the power spectral density is returned.\n        * ``'complex'`` : the complex fourier coefficients are returned per\n          window.\n\n        .. versionadded:: 1.4.0\n    %(verbose)s\n\n    Returns\n    -------\n    psds : ndarray, shape (..., n_freqs) or (..., n_freqs, n_segments)\n        The power spectral densities. If ``average='mean`` or\n        ``average='median'``, the returned array will have the same shape\n        as the input data plus an additional frequency dimension.\n        If ``average=None``, the returned array will have the same shape as\n        the input data plus two additional dimensions corresponding to\n        frequencies and the unaggregated segments, respectively.\n    freqs : ndarray, shape (n_freqs,)\n        The frequencies.\n\n    Notes\n    -----\n    .. versionadded:: 0.14.0\n\n    References\n    ----------\n    .. footbibliography::\n    \"\"\"\n    _check_option(\"average\", average, (None, False, \"mean\", \"median\"))\n    _check_option(\"output\", output, (\"power\", \"complex\"))\n    detrend = \"constant\" if remove_dc else False\n    mode = \"complex\" if output == \"complex\" else \"psd\"\n    n_fft = _ensure_int(n_fft, \"n_fft\")\n    n_overlap = _ensure_int(n_overlap, \"n_overlap\")\n    if n_per_seg is not None:\n        n_per_seg = _ensure_int(n_per_seg, \"n_per_seg\")\n    if average is False:\n        average = None\n\n    dshape = x.shape[:-1]\n    n_times = x.shape[-1]\n    x = x.reshape(-1, n_times)\n\n    # Prep the PSD\n    n_fft, n_per_seg, n_overlap = _check_nfft(n_times, n_fft, n_per_seg, n_overlap)\n    win_size = n_fft / float(sfreq)\n    logger.info(f\"Effective window size : {win_size:0.3f} (s)\")\n    freqs = np.arange(n_fft // 2 + 1, dtype=float) * (sfreq / n_fft)\n    freq_mask = (freqs >= fmin) & (freqs <= fmax)\n    if not freq_mask.any():\n        raise ValueError(f\"No frequencies found between fmin={fmin} and fmax={fmax}\")\n    freq_sl = slice(*(np.where(freq_mask)[0][[0, -1]] + [0, 1]))\n    del freq_mask\n    freqs = freqs[freq_sl]\n\n    # Parallelize across first N-1 dimensions\n    logger.debug(\n        f\"Spectogram using {n_fft}-point FFT on {n_per_seg} samples with \"\n        f\"{n_overlap} overlap and {window} window\"\n    )\n\n    parallel, my_spect_func, n_jobs = parallel_func(_spect_func, n_jobs=n_jobs)\n    _func = partial(\n        spectrogram,\n        detrend=detrend,\n        noverlap=n_overlap,\n        nperseg=n_per_seg,\n        nfft=n_fft,\n        fs=sfreq,\n        window=window,\n        mode=mode,\n    )\n    if np.any(np.isnan(x)):\n        good_mask = ~np.isnan(x)\n        # NaNs originate from annot, so must match for all channels. Note that we CANNOT\n        # use np.testing.assert_allclose() here; it is strict about shapes/broadcasting\n        assert np.allclose(good_mask, good_mask[[0]], equal_nan=True)\n        t_onsets, t_offsets = _mask_to_onsets_offsets(good_mask[0])\n        x_splits = [x[..., t_ons:t_off] for t_ons, t_off in zip(t_onsets, t_offsets)]\n        # weights reflect the number of samples used from each span. For spans longer\n        # than `n_per_seg`, trailing samples may be discarded. For spans shorter than\n        # `n_per_seg`, the wrapped function (`scipy.signal.spectrogram`) automatically\n        # reduces `n_per_seg` to match the span length (with a warning).\n        step = n_per_seg - n_overlap\n        span_lengths = [span.shape[-1] for span in x_splits]\n        weights = [\n            w if w < n_per_seg else w - ((w - n_overlap) % step) for w in span_lengths\n        ]\n        agg_func = partial(np.average, weights=weights)\n        if n_jobs > 1:\n            logger.info(\n                f\"Data split into {len(x_splits)} (probably unequal) chunks due to \"\n                '\"bad_*\" annotations. Parallelization may be sub-optimal.'\n            )\n        if (np.array(span_lengths) < n_per_seg).any():\n            logger.info(\n                \"At least one good data span is shorter than n_per_seg, and will be \"\n                \"analyzed with a shorter window than the rest of the file.\"\n            )\n\n        def func(*args, **kwargs):\n            # swallow SciPy warnings caused by short good data spans\n            with warnings.catch_warnings():\n                warnings.filterwarnings(\n                    action=\"ignore\",\n                    module=\"scipy\",\n                    category=UserWarning,\n                    message=r\"nperseg = \\d+ is greater than input length\",\n                )\n                return _func(*args, **kwargs)\n\n    else:\n        x_splits = [arr for arr in np.array_split(x, n_jobs) if arr.size != 0]\n        agg_func = np.concatenate\n        func = _func\n    f_spect = parallel(\n        my_spect_func(d, func=func, freq_sl=freq_sl, average=average, output=output)\n        for d in x_splits\n    )\n    psds = agg_func(f_spect, axis=0)\n    shape = dshape + (len(freqs),)\n    if average is None:\n        shape = shape + (-1,)\n    psds.shape = shape\n    return psds, freqs", "metadata": {}}
{"_id": "mne_mne_inverse_sparse/mxne_debiasing.py_power_iteration_kron_code", "title": "power_iteration_kron", "text": "def power_iteration_kron(A, C, max_iter=1000, tol=1e-3, random_state=0):\n    \"\"\"Find the largest singular value for the matrix kron(C.T, A).\n\n    It uses power iterations.\n\n    Parameters\n    ----------\n    A : array\n        An array\n    C : array\n        An array\n    max_iter : int\n        Maximum number of iterations\n    %(random_state)s\n\n    Returns\n    -------\n    L : float\n        largest singular value\n\n    Notes\n    -----\n    http://en.wikipedia.org/wiki/Power_iteration\n    \"\"\"\n    AS_size = C.shape[0]\n    rng = check_random_state(random_state)\n    B = rng.randn(AS_size, AS_size)\n    B /= np.linalg.norm(B, \"fro\")\n    ATA = np.dot(A.T, A)\n    CCT = np.dot(C, C.T)\n    L0 = np.inf\n    for _ in range(max_iter):\n        Y = np.dot(np.dot(ATA, B), CCT)\n        L = np.linalg.norm(Y, \"fro\")\n\n        if abs(L - L0) < tol:\n            break\n\n        B = Y / L\n        L0 = L\n    return L", "metadata": {}}
{"_id": "mne_mne_inverse_sparse/mxne_debiasing.py_compute_bias_code", "title": "compute_bias", "text": "def compute_bias(M, G, X, max_iter=1000, tol=1e-6, n_orient=1, verbose=None):\n    \"\"\"Compute scaling to correct amplitude bias.\n\n    It solves the following optimization problem using FISTA:\n\n    min 1/2 * (|| M - GDX ||fro)^2\n    s.t. D >= 1 and D is a diagonal matrix\n\n    Reference for the FISTA algorithm:\n    Amir Beck and Marc Teboulle\n    A Fast Iterative Shrinkage-Thresholding Algorithm for Linear Inverse\n    Problems, SIAM J. Imaging Sci., 2(1), 183-202. (20 pages)\n    http://epubs.siam.org/doi/abs/10.1137/080716542\n\n    Parameters\n    ----------\n    M : array\n        measurement data.\n    G : array\n        leadfield matrix.\n    X : array\n        reconstructed time courses with amplitude bias.\n    max_iter : int\n        Maximum number of iterations.\n    tol : float\n        The tolerance on convergence.\n    n_orient : int\n        The number of orientations (1 for fixed and 3 otherwise).\n    %(verbose)s\n\n    Returns\n    -------\n    D : array\n        Debiasing weights.\n    \"\"\"\n    n_sources = X.shape[0]\n\n    lipschitz_constant = 1.1 * power_iteration_kron(G, X)\n\n    # initializations\n    D = np.ones(n_sources)\n    Y = np.ones(n_sources)\n    t = 1.0\n\n    for i in range(max_iter):\n        D0 = D\n\n        # gradient step\n        R = M - np.dot(G * Y, X)\n        D = Y + np.sum(np.dot(G.T, R) * X, axis=1) / lipschitz_constant\n        # Equivalent but faster than:\n        # D = Y + np.diag(np.dot(np.dot(G.T, R), X.T)) / lipschitz_constant\n\n        # prox ie projection on constraint\n        if n_orient != 1:  # take care of orientations\n            # The scaling has to be the same for all orientations\n            D = np.mean(D.reshape(-1, n_orient), axis=1)\n            D = np.tile(D, [n_orient, 1]).T.ravel()\n        D = np.maximum(D, 1.0)\n\n        t0 = t\n        t = 0.5 * (1.0 + sqrt(1.0 + 4.0 * t**2))\n        Y.fill(0.0)\n        dt = (t0 - 1.0) / t\n        Y = D + dt * (D - D0)\n\n        Ddiff = np.linalg.norm(D - D0, np.inf)\n\n        if Ddiff < tol:\n            logger.info(\n                f\"Debiasing converged after {i} iterations \"\n                f\"max(|D - D0| = {Ddiff:e} < {tol:e})\"\n            )\n            break\n    else:\n        Ddiff = np.linalg.norm(D - D0, np.inf)\n        logger.info(\n            f\"Debiasing did not converge after {max_iter} iterations! \"\n            f\"max(|D - D0| = {Ddiff:e} >= {tol:e})\"\n        )\n    return D", "metadata": {}}
{"_id": "mne_mne_inverse_sparse/_gamma_map.py_gamma_map_code", "title": "gamma_map", "text": "def gamma_map(\n    evoked,\n    forward,\n    noise_cov,\n    alpha,\n    loose=\"auto\",\n    depth=0.8,\n    xyz_same_gamma=True,\n    maxit=10000,\n    tol=1e-6,\n    update_mode=1,\n    gammas=None,\n    pca=True,\n    return_residual=False,\n    return_as_dipoles=False,\n    rank=None,\n    pick_ori=None,\n    verbose=None,\n):\n    \"\"\"Hierarchical Bayes (Gamma-MAP) sparse source localization method.\n\n    Models each source time course using a zero-mean Gaussian prior with an\n    unknown variance (gamma) parameter. During estimation, most gammas are\n    driven to zero, resulting in a sparse source estimate, as in\n    :footcite:`WipfEtAl2007` and :footcite:`WipfNagarajan2009`.\n\n    For fixed-orientation forward operators, a separate gamma is used for each\n    source time course, while for free-orientation forward operators, the same\n    gamma is used for the three source time courses at each source space point\n    (separate gammas can be used in this case by using xyz_same_gamma=False).\n\n    Parameters\n    ----------\n    evoked : instance of Evoked\n        Evoked data to invert.\n    forward : dict\n        Forward operator.\n    noise_cov : instance of Covariance\n        Noise covariance to compute whitener.\n    alpha : float\n        Regularization parameter (noise variance).\n    %(loose)s\n    %(depth)s\n    xyz_same_gamma : bool\n        Use same gamma for xyz current components at each source space point.\n        Recommended for free-orientation forward solutions.\n    maxit : int\n        Maximum number of iterations.\n    tol : float\n        Tolerance parameter for convergence.\n    update_mode : int\n        Update mode, 1: MacKay update (default), 2: Modified MacKay update.\n    gammas : array, shape=(n_sources,)\n        Initial values for posterior variances (gammas). If None, a\n        variance of 1.0 is used.\n    pca : bool\n        If True the rank of the data is reduced to the true dimension.\n    return_residual : bool\n        If True, the residual is returned as an Evoked instance.\n    return_as_dipoles : bool\n        If True, the sources are returned as a list of Dipole instances.\n    %(rank_none)s\n\n        .. versionadded:: 0.18\n    %(pick_ori)s\n    %(verbose)s\n\n    Returns\n    -------\n    stc : instance of SourceEstimate\n        Source time courses.\n    residual : instance of Evoked\n        The residual a.k.a. data not explained by the sources.\n        Only returned if return_residual is True.\n\n    References\n    ----------\n    .. footbibliography::\n    \"\"\"\n    _check_reference(evoked)\n\n    forward, gain, gain_info, whitener, source_weighting, mask = _prepare_gain(\n        forward, evoked.info, noise_cov, pca, depth, loose, rank\n    )\n    _check_ori(pick_ori, forward)\n\n    group_size = 1 if (is_fixed_orient(forward) or not xyz_same_gamma) else 3\n\n    # get the data\n    sel = [evoked.ch_names.index(name) for name in gain_info[\"ch_names\"]]\n    M = evoked.data[sel]\n\n    # whiten the data\n    logger.info(\"Whitening data matrix.\")\n    M = np.dot(whitener, M)\n\n    # run the optimization\n    X, active_set = _gamma_map_opt(\n        M,\n        gain,\n        alpha,\n        maxit=maxit,\n        tol=tol,\n        update_mode=update_mode,\n        gammas=gammas,\n        group_size=group_size,\n        verbose=verbose,\n    )\n\n    if len(active_set) == 0:\n        raise Exception(\"No active dipoles found. alpha is too big.\")\n\n    M_estimate = gain[:, active_set] @ X\n\n    # Reapply weights to have correct unit\n    X = _reapply_source_weighting(X, source_weighting, active_set)\n\n    if return_residual:\n        residual = _compute_residual(forward, evoked, X, active_set, gain_info)\n\n    if group_size == 1 and not is_fixed_orient(forward):\n        # make sure each source has 3 components\n        idx, offset = divmod(active_set, 3)\n        active_src = np.unique(idx)\n        if len(X) < 3 * len(active_src):\n            X_xyz = np.zeros((len(active_src), 3, X.shape[1]), dtype=X.dtype)\n            idx = np.searchsorted(active_src, idx)\n            X_xyz[idx, offset, :] = X\n            X_xyz.shape = (len(active_src) * 3, X.shape[1])\n            X = X_xyz\n        active_set = (active_src[:, np.newaxis] * 3 + np.arange(3)).ravel()\n    source_weighting[source_weighting == 0] = 1  # zeros\n    gain_active = gain[:, active_set] / source_weighting[active_set]\n    del source_weighting\n\n    tmin = evoked.times[0]\n    tstep = 1.0 / evoked.info[\"sfreq\"]\n\n    if return_as_dipoles:\n        out = _make_dipoles_sparse(\n            X, active_set, forward, tmin, tstep, M, gain_active, active_is_idx=True\n        )\n    else:\n        out = _make_sparse_stc(\n            X,\n            active_set,\n            forward,\n            tmin,\n            tstep,\n            active_is_idx=True,\n            pick_ori=pick_ori,\n            verbose=verbose,\n        )\n\n    _log_exp_var(M, M_estimate, prefix=\"\")\n    logger.info(\"[done]\")\n\n    if return_residual:\n        out = out, residual\n\n    return out", "metadata": {}}
{"_id": "mne_mne_inverse_sparse/mxne_inverse.py_make_stc_from_dipoles_code", "title": "make_stc_from_dipoles", "text": "def make_stc_from_dipoles(dipoles, src, verbose=None):\n    \"\"\"Convert a list of spatio-temporal dipoles into a SourceEstimate.\n\n    Parameters\n    ----------\n    dipoles : Dipole | list of instances of Dipole\n        The dipoles to convert.\n    src : instance of SourceSpaces\n        The source space used to generate the forward operator.\n    %(verbose)s\n\n    Returns\n    -------\n    stc : SourceEstimate\n        The source estimate.\n    \"\"\"\n    logger.info(\"Converting dipoles into a SourceEstimate.\")\n    if isinstance(dipoles, Dipole):\n        dipoles = [dipoles]\n    if not isinstance(dipoles, list):\n        raise ValueError(\n            \"Dipoles must be an instance of Dipole or \"\n            \"a list of instances of Dipole. \"\n            f\"Got {type(dipoles)}!\"\n        )\n    tmin = dipoles[0].times[0]\n    tstep = dipoles[0].times[1] - tmin\n    X = np.zeros((len(dipoles), len(dipoles[0].times)))\n    source_rr = np.concatenate([_src[\"rr\"][_src[\"vertno\"], :] for _src in src], axis=0)\n    n_lh_points = len(src[0][\"vertno\"])\n    lh_vertno = list()\n    rh_vertno = list()\n    for i in range(len(dipoles)):\n        if not np.all(dipoles[i].pos == dipoles[i].pos[0]):\n            raise ValueError(\n                \"Only dipoles with fixed position over time are supported!\"\n            )\n        X[i] = dipoles[i].amplitude\n        idx = np.all(source_rr == dipoles[i].pos[0], axis=1)\n        idx = np.where(idx)[0][0]\n        if idx < n_lh_points:\n            lh_vertno.append(src[0][\"vertno\"][idx])\n        else:\n            rh_vertno.append(src[1][\"vertno\"][idx - n_lh_points])\n    vertices = [np.array(lh_vertno).astype(int), np.array(rh_vertno).astype(int)]\n    stc = SourceEstimate(\n        X, vertices=vertices, tmin=tmin, tstep=tstep, subject=src._subject\n    )\n    logger.info(\"[done]\")\n    return stc", "metadata": {}}
{"_id": "mne_mne_inverse_sparse/mxne_inverse.py_mixed_norm_code", "title": "mixed_norm", "text": "def mixed_norm(\n    evoked,\n    forward,\n    noise_cov,\n    alpha=\"sure\",\n    loose=\"auto\",\n    depth=0.8,\n    maxit=3000,\n    tol=1e-4,\n    active_set_size=10,\n    debias=True,\n    time_pca=True,\n    weights=None,\n    weights_min=0.0,\n    solver=\"auto\",\n    n_mxne_iter=1,\n    return_residual=False,\n    return_as_dipoles=False,\n    dgap_freq=10,\n    rank=None,\n    pick_ori=None,\n    sure_alpha_grid=\"auto\",\n    random_state=None,\n    verbose=None,\n):\n    \"\"\"Mixed-norm estimate (MxNE) and iterative reweighted MxNE (irMxNE).\n\n    Compute L1/L2 mixed-norm solution :footcite:`GramfortEtAl2012` or L0.5/L2\n    :footcite:`StrohmeierEtAl2016` mixed-norm solution on evoked data.\n\n    Parameters\n    ----------\n    evoked : instance of Evoked or list of instances of Evoked\n        Evoked data to invert.\n    forward : dict\n        Forward operator.\n    noise_cov : instance of Covariance\n        Noise covariance to compute whitener.\n    alpha : float | str\n        Regularization parameter. If float it should be in the range [0, 100):\n        0 means no regularization, 100 would give 0 active dipole.\n        If ``'sure'`` (default), the SURE method from\n        :footcite:`DeledalleEtAl2014` will be used.\n\n        .. versionchanged:: 0.24\n          The default was changed to ``'sure'``.\n    %(loose)s\n    %(depth)s\n    maxit : int\n        Maximum number of iterations.\n    tol : float\n        Tolerance parameter.\n    active_set_size : int | None\n        Size of active set increment. If None, no active set strategy is used.\n    debias : bool\n        Remove coefficient amplitude bias due to L1 penalty.\n    time_pca : bool or int\n        If True the rank of the concatenated epochs is reduced to\n        its true dimension. If is 'int' the rank is limited to this value.\n    weights : None | array | SourceEstimate\n        Weight for penalty in mixed_norm. Can be None, a\n        1d array with shape (n_sources,), or a SourceEstimate (e.g. obtained\n        with wMNE, dSPM, or fMRI).\n    weights_min : float\n        Do not consider in the estimation sources for which weights\n        is less than weights_min.\n    solver : 'cd' | 'bcd' | 'auto'\n        The algorithm to use for the optimization. 'cd' uses\n        coordinate descent, and 'bcd' applies block coordinate descent.\n        'cd' is only available for fixed orientation.\n    n_mxne_iter : int\n        The number of MxNE iterations. If > 1, iterative reweighting\n        is applied.\n    return_residual : bool\n        If True, the residual is returned as an Evoked instance.\n    return_as_dipoles : bool\n        If True, the sources are returned as a list of Dipole instances.\n    dgap_freq : int or np.inf\n        The duality gap is evaluated every dgap_freq iterations. Ignored if\n        solver is 'cd'.\n    %(rank_none)s\n\n        .. versionadded:: 0.18\n    %(pick_ori)s\n    sure_alpha_grid : array | str\n        If ``'auto'`` (default), the SURE is evaluated along 15 uniformly\n        distributed alphas between alpha_max and 0.1 * alpha_max. If array, the\n        grid is directly specified. Ignored if alpha is not \"sure\".\n\n        .. versionadded:: 0.24\n    random_state : int | None\n        The random state used in a random number generator for delta and\n        epsilon used for the SURE computation. Defaults to None.\n\n        .. versionadded:: 0.24\n    %(verbose)s\n\n    Returns\n    -------\n    stc : SourceEstimate | list of SourceEstimate\n        Source time courses for each evoked data passed as input.\n    residual : instance of Evoked\n        The residual a.k.a. data not explained by the sources.\n        Only returned if return_residual is True.\n\n    See Also\n    --------\n    tf_mixed_norm\n\n    References\n    ----------\n    .. footbibliography::\n    \"\"\"\n    _validate_type(alpha, (\"numeric\", str), \"alpha\")\n    if isinstance(alpha, str):\n        _check_option(\"alpha\", alpha, (\"sure\",))\n    elif not 0.0 <= alpha < 100:\n        raise ValueError(\n            f'If not equal to \"sure\" alpha must be in [0, 100). Got alpha = {alpha}'\n        )\n    if n_mxne_iter < 1:\n        raise ValueError(\n            \"MxNE has to be computed at least 1 time. \"\n            f\"Requires n_mxne_iter >= 1, got {n_mxne_iter}\"\n        )\n    if dgap_freq <= 0.0:\n        raise ValueError(\n            f\"dgap_freq must be a positive integer. Got dgap_freq = {dgap_freq}\"\n        )\n    if not (\n        isinstance(sure_alpha_grid, np.ndarray | list) or sure_alpha_grid == \"auto\"\n    ):\n        raise ValueError(\n            'If not equal to \"auto\" sure_alpha_grid must be an '\n            f\"array. Got {type(sure_alpha_grid)}\"\n        )\n    if (isinstance(sure_alpha_grid, str) and sure_alpha_grid != \"auto\") and (\n        isinstance(alpha, str) and alpha != \"sure\"\n    ):\n        raise Exception(\n            \"If sure_alpha_grid is manually specified, alpha must \"\n            f'be \"sure\". Got {alpha}'\n        )\n    pca = True\n    if not isinstance(evoked, list):\n        evoked = [evoked]\n\n    _check_reference(evoked[0])\n\n    all_ch_names = evoked[0].ch_names\n    if not all(all_ch_names == evoked[i].ch_names for i in range(1, len(evoked))):\n        raise Exception(\"All the datasets must have the same good channels.\")\n\n    forward, gain, gain_info, whitener, source_weighting, mask = _prepare_gain(\n        forward,\n        evoked[0].info,\n        noise_cov,\n        pca,\n        depth,\n        loose,\n        rank,\n        weights,\n        weights_min,\n    )\n    _check_ori(pick_ori, forward)\n\n    sel = [all_ch_names.index(name) for name in gain_info[\"ch_names\"]]\n    M = np.concatenate([e.data[sel] for e in evoked], axis=1)\n\n    # Whiten data\n    logger.info(\"Whitening data matrix.\")\n    M = np.dot(whitener, M)\n\n    if time_pca:\n        U, s, Vh = _safe_svd(M, full_matrices=False)\n        if not isinstance(time_pca, bool) and isinstance(time_pca, int):\n            U = U[:, :time_pca]\n            s = s[:time_pca]\n            Vh = Vh[:time_pca]\n        M = U * s\n\n    # Scaling to make setting of tol and alpha easy\n    tol *= sum_squared(M)\n    n_dip_per_pos = 1 if is_fixed_orient(forward) else 3\n    alpha_max = norm_l2inf(np.dot(gain.T, M), n_dip_per_pos, copy=False)\n    alpha_max *= 0.01\n    gain /= alpha_max\n    source_weighting /= alpha_max\n\n    # Alpha selected automatically by SURE minimization\n    if alpha == \"sure\":\n        alpha_grid = sure_alpha_grid\n        if isinstance(sure_alpha_grid, str) and sure_alpha_grid == \"auto\":\n            alpha_grid = np.geomspace(100, 10, num=15)\n        X, active_set, best_alpha_ = _compute_mxne_sure(\n            M,\n            gain,\n            alpha_grid,\n            sigma=1,\n            random_state=random_state,\n            n_mxne_iter=n_mxne_iter,\n            maxit=maxit,\n            tol=tol,\n            n_orient=n_dip_per_pos,\n            active_set_size=active_set_size,\n            debias=debias,\n            solver=solver,\n            dgap_freq=dgap_freq,\n            verbose=verbose,\n        )\n        logger.info(f\"Selected alpha: {best_alpha_}\")\n    else:\n        if n_mxne_iter == 1:\n            X, active_set, E = mixed_norm_solver(\n                M,\n                gain,\n                alpha,\n                maxit=maxit,\n                tol=tol,\n                active_set_size=active_set_size,\n                n_orient=n_dip_per_pos,\n                debias=debias,\n                solver=solver,\n                dgap_freq=dgap_freq,\n                verbose=verbose,\n            )\n        else:\n            X, active_set, E = iterative_mixed_norm_solver(\n                M,\n                gain,\n                alpha,\n                n_mxne_iter,\n                maxit=maxit,\n                tol=tol,\n                n_orient=n_dip_per_pos,\n                active_set_size=active_set_size,\n                debias=debias,\n                solver=solver,\n                dgap_freq=dgap_freq,\n                verbose=verbose,\n            )\n\n    if time_pca:\n        X = np.dot(X, Vh)\n        M = np.dot(M, Vh)\n\n    gain_active = gain[:, active_set]\n    if mask is not None:\n        active_set_tmp = np.zeros(len(mask), dtype=bool)\n        active_set_tmp[mask] = active_set\n        active_set = active_set_tmp\n        del active_set_tmp\n\n    if active_set.sum() == 0:\n        warn(\"No active dipoles found. alpha is too big.\")\n        M_estimate = np.zeros_like(M)\n    else:\n        # Reapply weights to have correct unit\n        X = _reapply_source_weighting(X, source_weighting, active_set)\n        source_weighting[source_weighting == 0] = 1  # zeros\n        gain_active /= source_weighting[active_set]\n        del source_weighting\n        M_estimate = np.dot(gain_active, X)\n\n    outs = list()\n    residual = list()\n    cnt = 0\n    for e in evoked:\n        tmin = e.times[0]\n        tstep = 1.0 / e.info[\"sfreq\"]\n        Xe = X[:, cnt : (cnt + len(e.times))]\n        if return_as_dipoles:\n            out = _make_dipoles_sparse(\n                Xe,\n                active_set,\n                forward,\n                tmin,\n                tstep,\n                M[:, cnt : (cnt + len(e.times))],\n                gain_active,\n            )\n        else:\n            out = _make_sparse_stc(\n                Xe, active_set, forward, tmin, tstep, pick_ori=pick_ori\n            )\n        outs.append(out)\n        cnt += len(e.times)\n\n        if return_residual:\n            residual.append(_compute_residual(forward, e, Xe, active_set, gain_info))\n\n    _log_exp_var(M, M_estimate, prefix=\"\")\n    logger.info(\"[done]\")\n\n    if len(outs) == 1:\n        out = outs[0]\n        if return_residual:\n            residual = residual[0]\n    else:\n        out = outs\n\n    if return_residual:\n        out = out, residual\n\n    return out", "metadata": {}}
{"_id": "mne_mne_inverse_sparse/mxne_inverse.py_tf_mixed_norm_code", "title": "tf_mixed_norm", "text": "def tf_mixed_norm(\n    evoked,\n    forward,\n    noise_cov,\n    loose=\"auto\",\n    depth=0.8,\n    maxit=3000,\n    tol=1e-4,\n    weights=None,\n    weights_min=0.0,\n    pca=True,\n    debias=True,\n    wsize=64,\n    tstep=4,\n    window=0.02,\n    return_residual=False,\n    return_as_dipoles=False,\n    alpha=None,\n    l1_ratio=None,\n    dgap_freq=10,\n    rank=None,\n    pick_ori=None,\n    n_tfmxne_iter=1,\n    verbose=None,\n):\n    \"\"\"Time-Frequency Mixed-norm estimate (TF-MxNE).\n\n    Compute L1/L2 + L1 mixed-norm solution on time-frequency\n    dictionary. Works with evoked data\n    :footcite:`GramfortEtAl2013b,GramfortEtAl2011`.\n\n    Parameters\n    ----------\n    evoked : instance of Evoked\n        Evoked data to invert.\n    forward : dict\n        Forward operator.\n    noise_cov : instance of Covariance\n        Noise covariance to compute whitener.\n    %(loose)s\n    %(depth)s\n    maxit : int\n        Maximum number of iterations.\n    tol : float\n        Tolerance parameter.\n    weights : None | array | SourceEstimate\n        Weight for penalty in mixed_norm. Can be None or\n        1d array of length n_sources or a SourceEstimate e.g. obtained\n        with wMNE or dSPM or fMRI.\n    weights_min : float\n        Do not consider in the estimation sources for which weights\n        is less than weights_min.\n    pca : bool\n        If True the rank of the data is reduced to true dimension.\n    debias : bool\n        Remove coefficient amplitude bias due to L1 penalty.\n    wsize : int or array-like\n        Length of the STFT window in samples (must be a multiple of 4).\n        If an array is passed, multiple TF dictionaries are used (each having\n        its own wsize and tstep) and each entry of wsize must be a multiple\n        of 4. See :footcite:`BekhtiEtAl2016`.\n    tstep : int or array-like\n        Step between successive windows in samples (must be a multiple of 2,\n        a divider of wsize and smaller than wsize/2) (default: wsize/2).\n        If an array is passed, multiple TF dictionaries are used (each having\n        its own wsize and tstep), and each entry of tstep must be a multiple\n        of 2 and divide the corresponding entry of wsize. See\n        :footcite:`BekhtiEtAl2016`.\n    window : float or (float, float)\n        Length of time window used to take care of edge artifacts in seconds.\n        It can be one float or float if the values are different for left\n        and right window length.\n    return_residual : bool\n        If True, the residual is returned as an Evoked instance.\n    return_as_dipoles : bool\n        If True, the sources are returned as a list of Dipole instances.\n    alpha : float in [0, 100) or None\n        Overall regularization parameter.\n        If alpha and l1_ratio are not None, alpha_space and alpha_time are\n        overridden by alpha * alpha_max * (1. - l1_ratio) and alpha * alpha_max\n        * l1_ratio. 0 means no regularization, 100 would give 0 active dipole.\n    l1_ratio : float in [0, 1] or None\n        Proportion of temporal regularization.\n        If l1_ratio and alpha are not None, alpha_space and alpha_time are\n        overridden by alpha * alpha_max * (1. - l1_ratio) and alpha * alpha_max\n        * l1_ratio. 0 means no time regularization a.k.a. MxNE.\n    dgap_freq : int or np.inf\n        The duality gap is evaluated every dgap_freq iterations.\n    %(rank_none)s\n\n        .. versionadded:: 0.18\n    %(pick_ori)s\n    n_tfmxne_iter : int\n        Number of TF-MxNE iterations. If > 1, iterative reweighting is applied.\n    %(verbose)s\n\n    Returns\n    -------\n    stc : instance of SourceEstimate\n        Source time courses.\n    residual : instance of Evoked\n        The residual a.k.a. data not explained by the sources.\n        Only returned if return_residual is True.\n\n    See Also\n    --------\n    mixed_norm\n\n    References\n    ----------\n    .. footbibliography::\n    \"\"\"\n    _check_reference(evoked)\n\n    all_ch_names = evoked.ch_names\n    info = evoked.info\n\n    if not (0.0 <= alpha < 100.0):\n        raise ValueError(f\"alpha must be in [0, 100). Got alpha = {alpha}\")\n\n    if not (0.0 <= l1_ratio <= 1.0):\n        raise ValueError(f\"l1_ratio must be in range [0, 1]. Got l1_ratio = {l1_ratio}\")\n    alpha_space = alpha * (1.0 - l1_ratio)\n    alpha_time = alpha * l1_ratio\n\n    if n_tfmxne_iter < 1:\n        raise ValueError(\n            \"TF-MxNE has to be computed at least 1 time. \"\n            f\"Requires n_tfmxne_iter >= 1, got {n_tfmxne_iter}\"\n        )\n\n    if dgap_freq <= 0.0:\n        raise ValueError(\n            f\"dgap_freq must be a positive integer. Got dgap_freq = {dgap_freq}\"\n        )\n\n    tstep = np.atleast_1d(tstep)\n    wsize = np.atleast_1d(wsize)\n    if len(tstep) != len(wsize):\n        raise ValueError(\n            \"The same number of window sizes and steps must be \"\n            f\"passed. Got tstep = {tstep} and wsize = {wsize}\"\n        )\n\n    forward, gain, gain_info, whitener, source_weighting, mask = _prepare_gain(\n        forward, evoked.info, noise_cov, pca, depth, loose, rank, weights, weights_min\n    )\n    _check_ori(pick_ori, forward)\n\n    n_dip_per_pos = 1 if is_fixed_orient(forward) else 3\n\n    if window is not None:\n        evoked = _window_evoked(evoked, window)\n\n    sel = [all_ch_names.index(name) for name in gain_info[\"ch_names\"]]\n    M = evoked.data[sel]\n\n    # Whiten data\n    logger.info(\"Whitening data matrix.\")\n    M = np.dot(whitener, M)\n\n    n_steps = np.ceil(M.shape[1] / tstep.astype(float)).astype(int)\n    n_freqs = wsize // 2 + 1\n    n_coefs = n_steps * n_freqs\n    phi = _Phi(wsize, tstep, n_coefs, evoked.data.shape[1])\n\n    # Scaling to make setting of tol and alpha easy\n    tol *= sum_squared(M)\n    alpha_max = norm_epsilon_inf(gain, M, phi, l1_ratio, n_dip_per_pos)\n    alpha_max *= 0.01\n    gain /= alpha_max\n    source_weighting /= alpha_max\n\n    if n_tfmxne_iter == 1:\n        X, active_set, E = tf_mixed_norm_solver(\n            M,\n            gain,\n            alpha_space,\n            alpha_time,\n            wsize=wsize,\n            tstep=tstep,\n            maxit=maxit,\n            tol=tol,\n            verbose=verbose,\n            n_orient=n_dip_per_pos,\n            dgap_freq=dgap_freq,\n            debias=debias,\n        )\n    else:\n        X, active_set, E = iterative_tf_mixed_norm_solver(\n            M,\n            gain,\n            alpha_space,\n            alpha_time,\n            wsize=wsize,\n            tstep=tstep,\n            n_tfmxne_iter=n_tfmxne_iter,\n            maxit=maxit,\n            tol=tol,\n            verbose=verbose,\n            n_orient=n_dip_per_pos,\n            dgap_freq=dgap_freq,\n            debias=debias,\n        )\n\n    if active_set.sum() == 0:\n        raise Exception(\"No active dipoles found. alpha_space/alpha_time are too big.\")\n\n    # Compute estimated whitened sensor data for each dipole (dip, ch, time)\n    gain_active = gain[:, active_set]\n\n    if mask is not None:\n        active_set_tmp = np.zeros(len(mask), dtype=bool)\n        active_set_tmp[mask] = active_set\n        active_set = active_set_tmp\n        del active_set_tmp\n\n    X = _reapply_source_weighting(X, source_weighting, active_set)\n    gain_active /= source_weighting[active_set]\n\n    if return_residual:\n        residual = _compute_residual(forward, evoked, X, active_set, gain_info)\n\n    if return_as_dipoles:\n        out = _make_dipoles_sparse(\n            X, active_set, forward, evoked.times[0], 1.0 / info[\"sfreq\"], M, gain_active\n        )\n    else:\n        out = _make_sparse_stc(\n            X,\n            active_set,\n            forward,\n            evoked.times[0],\n            1.0 / info[\"sfreq\"],\n            pick_ori=pick_ori,\n        )\n\n    logger.info(\"[done]\")\n\n    if return_residual:\n        out = out, residual\n\n    return out", "metadata": {}}
{"_id": "mne_mne_inverse_sparse/mxne_optim.py_groups_norm2_code", "title": "groups_norm2", "text": "def groups_norm2(A, n_orient):\n    \"\"\"Compute squared L2 norms of groups inplace.\"\"\"\n    n_positions = A.shape[0] // n_orient\n    return np.sum(np.power(A, 2, A).reshape(n_positions, -1), axis=1)", "metadata": {}}
{"_id": "mne_mne_inverse_sparse/mxne_optim.py_norm_l2inf_code", "title": "norm_l2inf", "text": "def norm_l2inf(A, n_orient, copy=True):\n    \"\"\"L2-inf norm.\"\"\"\n    if A.size == 0:\n        return 0.0\n    if copy:\n        A = A.copy()\n    return sqrt(np.max(groups_norm2(A, n_orient)))", "metadata": {}}
{"_id": "mne_mne_inverse_sparse/mxne_optim.py_norm_l21_code", "title": "norm_l21", "text": "def norm_l21(A, n_orient, copy=True):\n    \"\"\"L21 norm.\"\"\"\n    if A.size == 0:\n        return 0.0\n    if copy:\n        A = A.copy()\n    return np.sum(np.sqrt(groups_norm2(A, n_orient)))", "metadata": {}}
{"_id": "mne_mne_inverse_sparse/mxne_optim.py_dgap_l21_code", "title": "dgap_l21", "text": "def dgap_l21(M, G, X, active_set, alpha, n_orient):\n    \"\"\"Duality gap for the mixed norm inverse problem.\n\n    See :footcite:`GramfortEtAl2012`.\n\n    Parameters\n    ----------\n    M : array, shape (n_sensors, n_times)\n        The data.\n    G : array, shape (n_sensors, n_active)\n        The gain matrix a.k.a. lead field.\n    X : array, shape (n_active, n_times)\n        Sources.\n    active_set : array of bool, shape (n_sources, )\n        Mask of active sources.\n    alpha : float\n        The regularization parameter.\n    n_orient : int\n        Number of dipoles per locations (typically 1 or 3).\n\n    Returns\n    -------\n    gap : float\n        Dual gap.\n    p_obj : float\n        Primal objective.\n    d_obj : float\n        Dual objective. gap = p_obj - d_obj.\n    R : array, shape (n_sensors, n_times)\n        Current residual (M - G * X).\n\n    References\n    ----------\n    .. footbibilography::\n    \"\"\"\n    p_obj, R, nR2, GX = _primal_l21(M, G, X, active_set, alpha, n_orient)\n    dual_norm = norm_l2inf(np.dot(G.T, R), n_orient, copy=False)\n    scaling = alpha / dual_norm\n    scaling = min(scaling, 1.0)\n    d_obj = (scaling - 0.5 * (scaling**2)) * nR2 + scaling * np.sum(R * GX)\n\n    gap = p_obj - d_obj\n    return gap, p_obj, d_obj, R", "metadata": {}}
{"_id": "mne_mne_inverse_sparse/mxne_optim.py_mixed_norm_solver_code", "title": "mixed_norm_solver", "text": "def mixed_norm_solver(\n    M,\n    G,\n    alpha,\n    maxit=3000,\n    tol=1e-8,\n    verbose=None,\n    active_set_size=50,\n    debias=True,\n    n_orient=1,\n    solver=\"auto\",\n    return_gap=False,\n    dgap_freq=10,\n    active_set_init=None,\n    X_init=None,\n):\n    \"\"\"Solve L1/L2 mixed-norm inverse problem with active set strategy.\n\n    See references :footcite:`GramfortEtAl2012,StrohmeierEtAl2016,\n    BertrandEtAl2020`.\n\n    Parameters\n    ----------\n    M : array, shape (n_sensors, n_times)\n        The data.\n    G : array, shape (n_sensors, n_dipoles)\n        The gain matrix a.k.a. lead field.\n    alpha : float\n        The regularization parameter. It should be between 0 and 100.\n        A value of 100 will lead to an empty active set (no active source).\n    maxit : int\n        The number of iterations.\n    tol : float\n        Tolerance on dual gap for convergence checking.\n    %(verbose)s\n    active_set_size : int\n        Size of active set increase at each iteration.\n    debias : bool\n        Debias source estimates.\n    n_orient : int\n        The number of orientation (1 : fixed or 3 : free or loose).\n    solver : 'cd' | 'bcd' | 'auto'\n        The algorithm to use for the optimization. Block Coordinate Descent\n        (BCD) uses Anderson acceleration for faster convergence.\n    return_gap : bool\n        Return final duality gap.\n    dgap_freq : int\n        The duality gap is computed every dgap_freq iterations of the solver on\n        the active set.\n    active_set_init : array, shape (n_dipoles,) or None\n        The initial active set (boolean array) used at the first iteration.\n        If None, the usual active set strategy is applied.\n    X_init : array, shape (n_dipoles, n_times) or None\n        The initial weight matrix used for warm starting the solver. If None,\n        the weights are initialized at zero.\n\n    Returns\n    -------\n    X : array, shape (n_active, n_times)\n        The source estimates.\n    active_set : array, shape (new_active_set_size,)\n        The mask of active sources. Note that new_active_set_size is the size\n        of the active set after convergence of the solver.\n    E : list\n        The value of the objective function over the iterations.\n    gap : float\n        Final duality gap. Returned only if return_gap is True.\n\n    References\n    ----------\n    .. footbibliography::\n    \"\"\"\n    n_dipoles = G.shape[1]\n    n_positions = n_dipoles // n_orient\n    _, n_times = M.shape\n    alpha_max = norm_l2inf(np.dot(G.T, M), n_orient, copy=False)\n    logger.info(f\"-- ALPHA MAX : {alpha_max}\")\n    alpha = float(alpha)\n    X = np.zeros((n_dipoles, n_times), dtype=G.dtype)\n\n    has_sklearn = True\n    try:\n        from sklearn.linear_model import MultiTaskLasso  # noqa: F401\n    except ImportError:\n        has_sklearn = False\n\n    _validate_type(solver, str, \"solver\")\n    _check_option(\"solver\", solver, (\"cd\", \"bcd\", \"auto\"))\n    if solver == \"auto\":\n        if has_sklearn and (n_orient == 1):\n            solver = \"cd\"\n        else:\n            solver = \"bcd\"\n\n    if solver == \"cd\":\n        if n_orient == 1 and not has_sklearn:\n            warn(\n                \"Scikit-learn >= 0.12 cannot be found. Using block coordinate\"\n                \" descent instead of coordinate descent.\"\n            )\n            solver = \"bcd\"\n        if n_orient > 1:\n            warn(\n                \"Coordinate descent is only available for fixed orientation. \"\n                \"Using block coordinate descent instead of coordinate \"\n                \"descent\"\n            )\n            solver = \"bcd\"\n\n    if solver == \"cd\":\n        logger.info(\"Using coordinate descent\")\n        l21_solver = _mixed_norm_solver_cd\n        lc = None\n    else:\n        assert solver == \"bcd\"\n        logger.info(\"Using block coordinate descent\")\n        l21_solver = _mixed_norm_solver_bcd\n        G = np.asfortranarray(G)\n        if n_orient == 1:\n            lc = np.sum(G * G, axis=0)\n        else:\n            lc = np.empty(n_positions)\n            for j in range(n_positions):\n                G_tmp = G[:, (j * n_orient) : ((j + 1) * n_orient)]\n                lc[j] = np.linalg.norm(np.dot(G_tmp.T, G_tmp), ord=2)\n\n    if active_set_size is not None:\n        E = list()\n        highest_d_obj = -np.inf\n        if X_init is not None and X_init.shape != (n_dipoles, n_times):\n            raise ValueError(\"Wrong dim for initialized coefficients.\")\n        active_set = (\n            active_set_init\n            if active_set_init is not None\n            else np.zeros(n_dipoles, dtype=bool)\n        )\n        idx_large_corr = np.argsort(groups_norm2(np.dot(G.T, M), n_orient))\n        new_active_idx = idx_large_corr[-active_set_size:]\n        if n_orient > 1:\n            new_active_idx = (\n                n_orient * new_active_idx[:, None] + np.arange(n_orient)[None, :]\n            ).ravel()\n        active_set[new_active_idx] = True\n        as_size = np.sum(active_set)\n        gap = np.inf\n        for k in range(maxit):\n            if solver == \"bcd\":\n                lc_tmp = lc[active_set[::n_orient]]\n            elif solver == \"cd\":\n                lc_tmp = None\n            else:\n                lc_tmp = 1.01 * np.linalg.norm(G[:, active_set], ord=2) ** 2\n            X, as_, _ = l21_solver(\n                M,\n                G[:, active_set],\n                alpha,\n                lc_tmp,\n                maxit=maxit,\n                tol=tol,\n                init=X_init,\n                n_orient=n_orient,\n                dgap_freq=dgap_freq,\n            )\n            active_set[active_set] = as_.copy()\n            idx_old_active_set = np.where(active_set)[0]\n\n            _, p_obj, d_obj, R = dgap_l21(M, G, X, active_set, alpha, n_orient)\n            highest_d_obj = max(d_obj, highest_d_obj)\n            gap = p_obj - highest_d_obj\n            E.append(p_obj)\n            logger.info(\n                \"Iteration %d :: p_obj %f :: dgap %f :: n_active_start %d :: n_active_\"\n                \"end %d\",\n                k + 1,\n                p_obj,\n                gap,\n                as_size // n_orient,\n                np.sum(active_set) // n_orient,\n            )\n            if gap < tol:\n                logger.info(f\"Convergence reached ! (gap: {gap} < {tol})\")\n                break\n\n            # add sources if not last iteration\n            if k < (maxit - 1):\n                idx_large_corr = np.argsort(groups_norm2(np.dot(G.T, R), n_orient))\n                new_active_idx = idx_large_corr[-active_set_size:]\n                if n_orient > 1:\n                    new_active_idx = (\n                        n_orient * new_active_idx[:, None]\n                        + np.arange(n_orient)[None, :]\n                    )\n                    new_active_idx = new_active_idx.ravel()\n                active_set[new_active_idx] = True\n                idx_active_set = np.where(active_set)[0]\n                as_size = np.sum(active_set)\n                X_init = np.zeros((as_size, n_times), dtype=X.dtype)\n                idx = np.searchsorted(idx_active_set, idx_old_active_set)\n                X_init[idx] = X\n        else:\n            warn(f\"Did NOT converge ! (gap: {gap} > {tol})\")\n    else:\n        X, active_set, E = l21_solver(\n            M, G, alpha, lc, maxit=maxit, tol=tol, n_orient=n_orient, init=None\n        )\n        if return_gap:\n            gap = dgap_l21(M, G, X, active_set, alpha, n_orient)[0]\n\n    if np.any(active_set) and debias:\n        bias = compute_bias(M, G[:, active_set], X, n_orient=n_orient)\n        X *= bias[:, np.newaxis]\n\n    logger.info(\"Final active set size: %s\" % (np.sum(active_set) // n_orient))\n\n    if return_gap:\n        return X, active_set, E, gap\n    else:\n        return X, active_set, E", "metadata": {}}
{"_id": "mne_mne_inverse_sparse/mxne_optim.py_iterative_mixed_norm_solver_code", "title": "iterative_mixed_norm_solver", "text": "def iterative_mixed_norm_solver(\n    M,\n    G,\n    alpha,\n    n_mxne_iter,\n    maxit=3000,\n    tol=1e-8,\n    verbose=None,\n    active_set_size=50,\n    debias=True,\n    n_orient=1,\n    dgap_freq=10,\n    solver=\"auto\",\n    weight_init=None,\n):\n    \"\"\"Solve L0.5/L2 mixed-norm inverse problem with active set strategy.\n\n    See reference :footcite:`StrohmeierEtAl2016`.\n\n    Parameters\n    ----------\n    M : array, shape (n_sensors, n_times)\n        The data.\n    G : array, shape (n_sensors, n_dipoles)\n        The gain matrix a.k.a. lead field.\n    alpha : float\n        The regularization parameter. It should be between 0 and 100.\n        A value of 100 will lead to an empty active set (no active source).\n    n_mxne_iter : int\n        The number of MxNE iterations. If > 1, iterative reweighting\n        is applied.\n    maxit : int\n        The number of iterations.\n    tol : float\n        Tolerance on dual gap for convergence checking.\n    %(verbose)s\n    active_set_size : int\n        Size of active set increase at each iteration.\n    debias : bool\n        Debias source estimates.\n    n_orient : int\n        The number of orientation (1 : fixed or 3 : free or loose).\n    dgap_freq : int or np.inf\n        The duality gap is evaluated every dgap_freq iterations.\n    solver : 'cd' | 'bcd' | 'auto'\n        The algorithm to use for the optimization.\n    weight_init : array, shape (n_dipoles,) or None\n        The initial weight used for reweighting the gain matrix. If None, the\n        weights are initialized with ones.\n\n    Returns\n    -------\n    X : array, shape (n_active, n_times)\n        The source estimates.\n    active_set : array\n        The mask of active sources.\n    E : list\n        The value of the objective function over the iterations.\n\n    References\n    ----------\n    .. footbibliography::\n    \"\"\"\n\n    def g(w):\n        return np.sqrt(np.sqrt(groups_norm2(w.copy(), n_orient)))\n\n    def gprime(w):\n        return 2.0 * np.repeat(g(w), n_orient).ravel()\n\n    E = list()\n\n    if weight_init is not None and weight_init.shape != (G.shape[1],):\n        raise ValueError(\n            f\"Wrong dimension for weight initialization. Got {weight_init.shape}. \"\n            f\"Expected {(G.shape[1],)}.\"\n        )\n\n    weights = weight_init if weight_init is not None else np.ones(G.shape[1])\n    active_set = weights != 0\n    weights = weights[active_set]\n    X = np.zeros((G.shape[1], M.shape[1]))\n\n    for k in range(n_mxne_iter):\n        X0 = X.copy()\n        active_set_0 = active_set.copy()\n        G_tmp = G[:, active_set] * weights[np.newaxis, :]\n\n        if active_set_size is not None:\n            if np.sum(active_set) > (active_set_size * n_orient):\n                X, _active_set, _ = mixed_norm_solver(\n                    M,\n                    G_tmp,\n                    alpha,\n                    debias=False,\n                    n_orient=n_orient,\n                    maxit=maxit,\n                    tol=tol,\n                    active_set_size=active_set_size,\n                    dgap_freq=dgap_freq,\n                    solver=solver,\n                )\n            else:\n                X, _active_set, _ = mixed_norm_solver(\n                    M,\n                    G_tmp,\n                    alpha,\n                    debias=False,\n                    n_orient=n_orient,\n                    maxit=maxit,\n                    tol=tol,\n                    active_set_size=None,\n                    dgap_freq=dgap_freq,\n                    solver=solver,\n                )\n        else:\n            X, _active_set, _ = mixed_norm_solver(\n                M,\n                G_tmp,\n                alpha,\n                debias=False,\n                n_orient=n_orient,\n                maxit=maxit,\n                tol=tol,\n                active_set_size=None,\n                dgap_freq=dgap_freq,\n                solver=solver,\n            )\n\n        logger.info(\"active set size %d\", _active_set.sum() / n_orient)\n\n        if _active_set.sum() > 0:\n            active_set[active_set] = _active_set\n            # Reapply weights to have correct unit\n            X *= weights[_active_set][:, np.newaxis]\n            weights = gprime(X)\n            p_obj = 0.5 * np.linalg.norm(\n                M - np.dot(G[:, active_set], X), \"fro\"\n            ) ** 2.0 + alpha * np.sum(g(X))\n            E.append(p_obj)\n\n            # Check convergence\n            if (\n                (k >= 1)\n                and np.all(active_set == active_set_0)\n                and np.all(np.abs(X - X0) < tol)\n            ):\n                logger.info(\"Convergence reached after %d reweightings!\", k)\n                break\n        else:\n            active_set = np.zeros_like(active_set)\n            p_obj = 0.5 * np.linalg.norm(M) ** 2.0\n            E.append(p_obj)\n            break\n\n    if np.any(active_set) and debias:\n        bias = compute_bias(M, G[:, active_set], X, n_orient=n_orient)\n        X *= bias[:, np.newaxis]\n\n    return X, active_set, E", "metadata": {}}
{"_id": "mne_mne_inverse_sparse/mxne_optim.py_norm_l21_tf_code", "title": "norm_l21_tf", "text": "def norm_l21_tf(Z, phi, n_orient, w_space=None):\n    \"\"\"L21 norm for TF.\"\"\"\n    if Z.shape[0]:\n        l21_norm = np.sqrt(phi.norm(Z, ord=2).reshape(-1, n_orient).sum(axis=1))\n        if w_space is not None:\n            l21_norm *= w_space\n        l21_norm = l21_norm.sum()\n    else:\n        l21_norm = 0.0\n    return l21_norm", "metadata": {}}
{"_id": "mne_mne_inverse_sparse/mxne_optim.py_norm_l1_tf_code", "title": "norm_l1_tf", "text": "def norm_l1_tf(Z, phi, n_orient, w_time):\n    \"\"\"L1 norm for TF.\"\"\"\n    if Z.shape[0]:\n        n_positions = Z.shape[0] // n_orient\n        Z_ = np.sqrt(\n            np.sum((np.abs(Z) ** 2.0).reshape((n_orient, -1), order=\"F\"), axis=0)\n        )\n        Z_ = Z_.reshape((n_positions, -1), order=\"F\")\n        if w_time is not None:\n            Z_ *= w_time\n        l1_norm = phi.norm(Z_, ord=1).sum()\n    else:\n        l1_norm = 0.0\n    return l1_norm", "metadata": {}}
{"_id": "mne_mne_inverse_sparse/mxne_optim.py_norm_epsilon_code", "title": "norm_epsilon", "text": "def norm_epsilon(Y, l1_ratio, phi, w_space=1.0, w_time=None):\n    \"\"\"Weighted epsilon norm.\n\n    The weighted epsilon norm is the dual norm of::\n\n    w_{space} * (1. - l1_ratio) * ||Y||_2 + l1_ratio * ||Y||_{1, w_{time}}.\n\n    where `||Y||_{1, w_{time}} = (np.abs(Y) * w_time).sum()`\n\n    Warning: it takes into account the fact that Y only contains coefficients\n    corresponding to the positive frequencies (see `stft_norm2()`): some\n    entries will be counted twice. It is also assumed that all entries of both\n    Y and w_time are non-negative. See\n    :footcite:`NdiayeEtAl2016,BurdakovMerkulov2001`.\n\n    Parameters\n    ----------\n    Y : array, shape (n_coefs,)\n        The input data.\n    l1_ratio : float between 0 and 1\n        Tradeoff between L2 and L1 regularization. When it is 0, no temporal\n        regularization is applied.\n    phi : instance of _Phi\n        The TF operator.\n    w_space : float\n        Scalar weight of the L2 norm. By default, it is taken equal to 1.\n    w_time : array, shape (n_coefs, ) | None\n        Weights of each TF coefficient in the L1 norm. If None, weights equal\n        to 1 are used.\n\n\n    Returns\n    -------\n    nu : float\n        The value of the dual norm evaluated at Y.\n\n    References\n    ----------\n    .. footbibliography::\n    \"\"\"\n    # since the solution is invariant to flipped signs in Y, all entries\n    # of Y are assumed positive\n\n    # Add negative freqs: count all freqs twice except first and last:\n    freqs_count = np.full(len(Y), 2)\n    for i, fc in enumerate(np.array_split(freqs_count, np.cumsum(phi.n_coefs)[:-1])):\n        fc[: phi.n_steps[i]] = 1\n        fc[-phi.n_steps[i] :] = 1\n\n    # exclude 0 weights:\n    if w_time is not None:\n        nonzero_weights = w_time != 0.0\n        Y = Y[nonzero_weights]\n        freqs_count = freqs_count[nonzero_weights]\n        w_time = w_time[nonzero_weights]\n\n    norm_inf_Y = np.max(Y / w_time) if w_time is not None else np.max(Y)\n    if l1_ratio == 1.0:\n        # dual norm of L1 weighted is Linf with inverse weights\n        return norm_inf_Y\n    elif l1_ratio == 0.0:\n        # dual norm of L2 is L2\n        return np.sqrt(phi.norm(Y[None, :], ord=2).sum())\n\n    if norm_inf_Y == 0.0:\n        return 0.0\n\n    # ignore some values of Y by lower bound on dual norm:\n    if w_time is None:\n        idx = Y > l1_ratio * norm_inf_Y\n    else:\n        idx = Y > l1_ratio * np.max(\n            Y / (w_space * (1.0 - l1_ratio) + l1_ratio * w_time)\n        )\n\n    if idx.sum() == 1:\n        return norm_inf_Y\n\n    # sort both Y / w_time and freqs_count at the same time\n    if w_time is not None:\n        idx_sort = np.argsort(Y[idx] / w_time[idx])[::-1]\n        w_time = w_time[idx][idx_sort]\n    else:\n        idx_sort = np.argsort(Y[idx])[::-1]\n\n    Y = Y[idx][idx_sort]\n    freqs_count = freqs_count[idx][idx_sort]\n\n    Y = np.repeat(Y, freqs_count)\n    if w_time is not None:\n        w_time = np.repeat(w_time, freqs_count)\n\n    K = Y.shape[0]\n    if w_time is None:\n        p_sum_Y2 = np.cumsum(Y**2)\n        p_sum_w2 = np.arange(1, K + 1)\n        p_sum_Yw = np.cumsum(Y)\n        upper = p_sum_Y2 / Y**2 - 2.0 * p_sum_Yw / Y + p_sum_w2\n    else:\n        p_sum_Y2 = np.cumsum(Y**2)\n        p_sum_w2 = np.cumsum(w_time**2)\n        p_sum_Yw = np.cumsum(Y * w_time)\n        upper = p_sum_Y2 / (Y / w_time) ** 2 - 2.0 * p_sum_Yw / (Y / w_time) + p_sum_w2\n    upper_greater = np.where(upper > w_space**2 * (1.0 - l1_ratio) ** 2 / l1_ratio**2)[\n        0\n    ]\n\n    i0 = upper_greater[0] - 1 if upper_greater.size else K - 1\n\n    p_sum_Y2 = p_sum_Y2[i0]\n    p_sum_w2 = p_sum_w2[i0]\n    p_sum_Yw = p_sum_Yw[i0]\n\n    denom = l1_ratio**2 * p_sum_w2 - w_space**2 * (1.0 - l1_ratio) ** 2\n    if np.abs(denom) < 1e-10:\n        return p_sum_Y2 / (2.0 * l1_ratio * p_sum_Yw)\n    else:\n        delta = (l1_ratio * p_sum_Yw) ** 2 - p_sum_Y2 * denom\n        return (l1_ratio * p_sum_Yw - np.sqrt(delta)) / denom", "metadata": {}}
{"_id": "mne_mne_inverse_sparse/mxne_optim.py_norm_epsilon_inf_code", "title": "norm_epsilon_inf", "text": "def norm_epsilon_inf(G, R, phi, l1_ratio, n_orient, w_space=None, w_time=None):\n    \"\"\"Weighted epsilon-inf norm of phi(np.dot(G.T, R)).\n\n    Parameters\n    ----------\n    G : array, shape (n_sensors, n_sources)\n        Gain matrix a.k.a. lead field.\n    R : array, shape (n_sensors, n_times)\n        Residual.\n    phi : instance of _Phi\n        The TF operator.\n    l1_ratio : float between 0 and 1\n        Parameter controlling the tradeoff between L21 and L1 regularization.\n        0 corresponds to an absence of temporal regularization, ie MxNE.\n    n_orient : int\n        Number of dipoles per location (typically 1 or 3).\n    w_space : array, shape (n_positions,) or None.\n        Weights for the L2 term of the epsilon norm. If None, weights are\n        all equal to 1.\n    w_time : array, shape (n_positions, n_coefs) or None\n        Weights for the L1 term of the epsilon norm. If None, weights are\n        all equal to 1.\n\n    Returns\n    -------\n    nu : float\n        The maximum value of the epsilon norms over groups of n_orient dipoles\n        (consecutive rows of phi(np.dot(G.T, R))).\n    \"\"\"\n    n_positions = G.shape[1] // n_orient\n    GTRPhi = np.abs(phi(np.dot(G.T, R)))\n    # norm over orientations:\n    GTRPhi = GTRPhi.reshape((n_orient, -1), order=\"F\")\n    GTRPhi = np.linalg.norm(GTRPhi, axis=0)\n    GTRPhi = GTRPhi.reshape((n_positions, -1), order=\"F\")\n    nu = 0.0\n    for idx in range(n_positions):\n        GTRPhi_ = GTRPhi[idx]\n        w_t = w_time[idx] if w_time is not None else None\n        w_s = w_space[idx] if w_space is not None else 1.0\n        norm_eps = norm_epsilon(GTRPhi_, l1_ratio, phi, w_space=w_s, w_time=w_t)\n        if norm_eps > nu:\n            nu = norm_eps\n\n    return nu", "metadata": {}}
{"_id": "mne_mne_inverse_sparse/mxne_optim.py_dgap_l21l1_code", "title": "dgap_l21l1", "text": "def dgap_l21l1(\n    M,\n    G,\n    Z,\n    active_set,\n    alpha_space,\n    alpha_time,\n    phi,\n    phiT,\n    n_orient,\n    highest_d_obj,\n    w_space=None,\n    w_time=None,\n):\n    \"\"\"Duality gap for the time-frequency mixed norm inverse problem.\n\n    See :footcite:`GramfortEtAl2012,NdiayeEtAl2016`\n\n    Parameters\n    ----------\n    M : array, shape (n_sensors, n_times)\n        The data.\n    G : array, shape (n_sensors, n_sources)\n        Gain matrix a.k.a. lead field.\n    Z : array, shape (n_active, n_coefs)\n        Sources in TF domain.\n    active_set : array of bool, shape (n_sources, )\n        Mask of active sources.\n    alpha_space : float\n        The spatial regularization parameter.\n    alpha_time : float\n        The temporal regularization parameter. The higher it is the smoother\n        will be the estimated time series.\n    phi : instance of _Phi\n        The TF operator.\n    phiT : instance of _PhiT\n        The transpose of the TF operator.\n    n_orient : int\n        Number of dipoles per locations (typically 1 or 3).\n    highest_d_obj : float\n        The highest value of the dual objective so far.\n    w_space : array, shape (n_positions, )\n        Array of spatial weights.\n    w_time : array, shape (n_positions, n_coefs)\n        Array of TF weights.\n\n    Returns\n    -------\n    gap : float\n        Dual gap\n    p_obj : float\n        Primal objective\n    d_obj : float\n        Dual objective. gap = p_obj - d_obj\n    R : array, shape (n_sensors, n_times)\n        Current residual (M - G * X)\n\n    References\n    ----------\n    .. footbibliography::\n    \"\"\"\n    X = phiT(Z)\n    GX = np.dot(G[:, active_set], X)\n    R = M - GX\n\n    # some functions need w_time only on active_set, other need it completely\n    if w_time is not None:\n        w_time_as = w_time[active_set[::n_orient]]\n    else:\n        w_time_as = None\n    if w_space is not None:\n        w_space_as = w_space[active_set[::n_orient]]\n    else:\n        w_space_as = None\n\n    penaltyl1 = norm_l1_tf(Z, phi, n_orient, w_time_as)\n    penaltyl21 = norm_l21_tf(Z, phi, n_orient, w_space_as)\n    nR2 = sum_squared(R)\n    p_obj = 0.5 * nR2 + alpha_space * penaltyl21 + alpha_time * penaltyl1\n\n    l1_ratio = alpha_time / (alpha_space + alpha_time)\n    dual_norm = norm_epsilon_inf(\n        G, R, phi, l1_ratio, n_orient, w_space=w_space, w_time=w_time\n    )\n    scaling = min(1.0, (alpha_space + alpha_time) / dual_norm)\n\n    d_obj = (scaling - 0.5 * (scaling**2)) * nR2 + scaling * np.sum(R * GX)\n    d_obj = max(d_obj, highest_d_obj)\n\n    gap = p_obj - d_obj\n    return gap, p_obj, d_obj, R", "metadata": {}}
{"_id": "mne_mne_inverse_sparse/mxne_optim.py_tf_mixed_norm_solver_code", "title": "tf_mixed_norm_solver", "text": "def tf_mixed_norm_solver(\n    M,\n    G,\n    alpha_space,\n    alpha_time,\n    wsize=64,\n    tstep=4,\n    n_orient=1,\n    maxit=200,\n    tol=1e-8,\n    active_set_size=None,\n    debias=True,\n    return_gap=False,\n    dgap_freq=10,\n    verbose=None,\n):\n    \"\"\"Solve TF L21+L1 inverse solver with BCD and active set approach.\n\n    See :footcite:`GramfortEtAl2013b,GramfortEtAl2011,BekhtiEtAl2016`.\n\n    Parameters\n    ----------\n    M : array, shape (n_sensors, n_times)\n        The data.\n    G : array, shape (n_sensors, n_dipoles)\n        The gain matrix a.k.a. lead field.\n    alpha_space : float\n        The spatial regularization parameter.\n    alpha_time : float\n        The temporal regularization parameter. The higher it is the smoother\n        will be the estimated time series.\n    wsize: int or array-like\n        Length of the STFT window in samples (must be a multiple of 4).\n        If an array is passed, multiple TF dictionaries are used (each having\n        its own wsize and tstep) and each entry of wsize must be a multiple\n        of 4.\n    tstep: int or array-like\n        Step between successive windows in samples (must be a multiple of 2,\n        a divider of wsize and smaller than wsize/2) (default: wsize/2).\n        If an array is passed, multiple TF dictionaries are used (each having\n        its own wsize and tstep), and each entry of tstep must be a multiple\n        of 2 and divide the corresponding entry of wsize.\n    n_orient : int\n        The number of orientation (1 : fixed or 3 : free or loose).\n    maxit : int\n        The number of iterations.\n    tol : float\n        If absolute difference between estimates at 2 successive iterations\n        is lower than tol, the convergence is reached.\n    debias : bool\n        Debias source estimates.\n    return_gap : bool\n        Return final duality gap.\n    dgap_freq : int or np.inf\n        The duality gap is evaluated every dgap_freq iterations.\n    %(verbose)s\n\n    Returns\n    -------\n    X : array, shape (n_active, n_times)\n        The source estimates.\n    active_set : array\n        The mask of active sources.\n    E : list\n        The value of the objective function every dgap_freq iteration. If\n        log_objective is False or dgap_freq is np.inf, it will be empty.\n    gap : float\n        Final duality gap. Returned only if return_gap is True.\n\n    References\n    ----------\n    .. footbibliography::\n    \"\"\"\n    n_sensors, n_times = M.shape\n    n_sensors, n_sources = G.shape\n    n_positions = n_sources // n_orient\n\n    tstep = np.atleast_1d(tstep)\n    wsize = np.atleast_1d(wsize)\n    if len(tstep) != len(wsize):\n        raise ValueError(\n            \"The same number of window sizes and steps must be \"\n            f\"passed. Got tstep = {tstep} and wsize = {wsize}\"\n        )\n\n    n_steps = np.ceil(M.shape[1] / tstep.astype(float)).astype(int)\n    n_freqs = wsize // 2 + 1\n    n_coefs = n_steps * n_freqs\n    phi = _Phi(wsize, tstep, n_coefs, n_times)\n    phiT = _PhiT(tstep, n_freqs, n_steps, n_times)\n\n    if n_orient == 1:\n        lc = np.sum(G * G, axis=0)\n    else:\n        lc = np.empty(n_positions)\n        for j in range(n_positions):\n            G_tmp = G[:, (j * n_orient) : ((j + 1) * n_orient)]\n            lc[j] = np.linalg.norm(np.dot(G_tmp.T, G_tmp), ord=2)\n\n    logger.info(\"Using block coordinate descent with active set approach\")\n    X, Z, active_set, E, gap = _tf_mixed_norm_solver_bcd_active_set(\n        M,\n        G,\n        alpha_space,\n        alpha_time,\n        lc,\n        phi,\n        phiT,\n        Z_init=None,\n        n_orient=n_orient,\n        maxit=maxit,\n        tol=tol,\n        dgap_freq=dgap_freq,\n    )\n\n    if np.any(active_set) and debias:\n        bias = compute_bias(M, G[:, active_set], X, n_orient=n_orient)\n        X *= bias[:, np.newaxis]\n\n    if return_gap:\n        return X, active_set, E, gap\n    else:\n        return X, active_set, E", "metadata": {}}
{"_id": "mne_mne_inverse_sparse/mxne_optim.py_iterative_tf_mixed_norm_solver_code", "title": "iterative_tf_mixed_norm_solver", "text": "def iterative_tf_mixed_norm_solver(\n    M,\n    G,\n    alpha_space,\n    alpha_time,\n    n_tfmxne_iter,\n    wsize=64,\n    tstep=4,\n    maxit=3000,\n    tol=1e-8,\n    debias=True,\n    n_orient=1,\n    dgap_freq=10,\n    verbose=None,\n):\n    \"\"\"Solve TF L0.5/L1 + L0.5 inverse problem with BCD + active set approach.\n\n    Parameters\n    ----------\n    M: array, shape (n_sensors, n_times)\n        The data.\n    G: array, shape (n_sensors, n_dipoles)\n        The gain matrix a.k.a. lead field.\n    alpha_space: float\n        The spatial regularization parameter. The higher it is the less there\n        will be active sources.\n    alpha_time : float\n        The temporal regularization parameter. The higher it is the smoother\n        will be the estimated time series. 0 means no temporal regularization,\n        a.k.a. irMxNE.\n    n_tfmxne_iter : int\n        Number of TF-MxNE iterations. If > 1, iterative reweighting is applied.\n    wsize : int or array-like\n        Length of the STFT window in samples (must be a multiple of 4).\n        If an array is passed, multiple TF dictionaries are used (each having\n        its own wsize and tstep) and each entry of wsize must be a multiple\n        of 4.\n    tstep : int or array-like\n        Step between successive windows in samples (must be a multiple of 2,\n        a divider of wsize and smaller than wsize/2) (default: wsize/2).\n        If an array is passed, multiple TF dictionaries are used (each having\n        its own wsize and tstep), and each entry of tstep must be a multiple\n        of 2 and divide the corresponding entry of wsize.\n    maxit : int\n        The maximum number of iterations for each TF-MxNE problem.\n    tol : float\n        If absolute difference between estimates at 2 successive iterations\n        is lower than tol, the convergence is reached. Also used as criterion\n        on duality gap for each TF-MxNE problem.\n    debias : bool\n        Debias source estimates.\n    n_orient : int\n        The number of orientation (1 : fixed or 3 : free or loose).\n    dgap_freq : int or np.inf\n        The duality gap is evaluated every dgap_freq iterations.\n    %(verbose)s\n\n    Returns\n    -------\n    X : array, shape (n_active, n_times)\n        The source estimates.\n    active_set : array\n        The mask of active sources.\n    E : list\n        The value of the objective function over iterations.\n    \"\"\"\n    n_sensors, n_times = M.shape\n    n_sources = G.shape[1]\n    n_positions = n_sources // n_orient\n\n    tstep = np.atleast_1d(tstep)\n    wsize = np.atleast_1d(wsize)\n    if len(tstep) != len(wsize):\n        raise ValueError(\n            \"The same number of window sizes and steps must be \"\n            f\"passed. Got tstep = {tstep} and wsize = {wsize}\"\n        )\n\n    n_steps = np.ceil(n_times / tstep.astype(float)).astype(int)\n    n_freqs = wsize // 2 + 1\n    n_coefs = n_steps * n_freqs\n    phi = _Phi(wsize, tstep, n_coefs, n_times)\n    phiT = _PhiT(tstep, n_freqs, n_steps, n_times)\n\n    if n_orient == 1:\n        lc = np.sum(G * G, axis=0)\n    else:\n        lc = np.empty(n_positions)\n        for j in range(n_positions):\n            G_tmp = G[:, (j * n_orient) : ((j + 1) * n_orient)]\n            lc[j] = np.linalg.norm(np.dot(G_tmp.T, G_tmp), ord=2)\n\n    # space and time penalties, and inverse of their derivatives:\n    def g_space(Z):\n        return np.sqrt(np.sqrt(phi.norm(Z, ord=2).reshape(-1, n_orient).sum(axis=1)))\n\n    def g_space_prime_inv(Z):\n        return 2.0 * g_space(Z)\n\n    def g_time(Z):\n        return np.sqrt(\n            np.sqrt(\n                np.sum((np.abs(Z) ** 2.0).reshape((n_orient, -1), order=\"F\"), axis=0)\n            ).reshape((-1, Z.shape[1]), order=\"F\")\n        )\n\n    def g_time_prime_inv(Z):\n        return 2.0 * g_time(Z)\n\n    E = list()\n\n    active_set = np.ones(n_sources, dtype=bool)\n    Z = np.zeros((n_sources, phi.n_coefs.sum()), dtype=np.complex128)\n\n    for k in range(n_tfmxne_iter):\n        active_set_0 = active_set.copy()\n        Z0 = Z.copy()\n\n        if k == 0:\n            w_space = None\n            w_time = None\n        else:\n            w_space = 1.0 / g_space_prime_inv(Z)\n            w_time = g_time_prime_inv(Z)\n            w_time[w_time == 0.0] = -1.0\n            w_time = 1.0 / w_time\n            w_time[w_time < 0.0] = 0.0\n\n        X, Z, active_set_, _, _ = _tf_mixed_norm_solver_bcd_active_set(\n            M,\n            G[:, active_set],\n            alpha_space,\n            alpha_time,\n            lc[active_set[::n_orient]],\n            phi,\n            phiT,\n            Z_init=Z,\n            w_space=w_space,\n            w_time=w_time,\n            n_orient=n_orient,\n            maxit=maxit,\n            tol=tol,\n            dgap_freq=dgap_freq,\n        )\n\n        active_set[active_set] = active_set_\n\n        if active_set.sum() > 0:\n            l21_penalty = np.sum(g_space(Z.copy()))\n            l1_penalty = phi.norm(g_time(Z.copy()), ord=1).sum()\n\n            p_obj = (\n                0.5 * np.linalg.norm(M - np.dot(G[:, active_set], X), \"fro\") ** 2.0\n                + alpha_space * l21_penalty\n                + alpha_time * l1_penalty\n            )\n            E.append(p_obj)\n\n            logger.info(\n                \"Iteration %d: active set size=%d, E=%f\",\n                k + 1,\n                active_set.sum() / n_orient,\n                p_obj,\n            )\n\n            # Check convergence\n            if np.array_equal(active_set, active_set_0):\n                max_diff = np.amax(np.abs(Z - Z0))\n                if max_diff < tol:\n                    logger.info(\"Convergence reached after %d reweightings!\", k)\n                    break\n        else:\n            p_obj = 0.5 * np.linalg.norm(M) ** 2.0\n            E.append(p_obj)\n            logger.info(\n                \"Iteration %d: as_size=%d, E=%f\",\n                k + 1,\n                active_set.sum() / n_orient,\n                p_obj,\n            )\n            break\n\n    if debias:\n        if active_set.sum() > 0:\n            bias = compute_bias(M, G[:, active_set], X, n_orient=n_orient)\n            X *= bias[:, np.newaxis]\n\n    return X, active_set, E", "metadata": {}}
{"_id": "mne_mne_inverse_sparse/mxne_optim.py_norm_code", "title": "norm", "text": "def norm(self, z, ord=2):  # noqa: A002\n        \"\"\"Squared L2 norm if ord == 2 and L1 norm if order == 1.\"\"\"\n        if ord not in (1, 2):\n            raise ValueError(f\"Only supported norm order are 1 and 2. Got ord = {ord}\")\n        stft_norm = stft_norm1 if ord == 1 else stft_norm2\n        norm = 0.0\n        if len(self.n_coefs) > 1:\n            z_ = np.array_split(np.atleast_2d(z), np.cumsum(self.n_coefs)[:-1], axis=1)\n        else:\n            z_ = [np.atleast_2d(z)]\n        for i in range(len(z_)):\n            norm += stft_norm(z_[i].reshape(-1, self.n_freqs[i], self.n_steps[i]))\n        return norm", "metadata": {}}
{"_id": "mne_mne_preprocessing/ssp.py_compute_proj_ecg_code", "title": "compute_proj_ecg", "text": "def compute_proj_ecg(\n    raw,\n    raw_event=None,\n    tmin=-0.2,\n    tmax=0.4,\n    n_grad=2,\n    n_mag=2,\n    n_eeg=2,\n    l_freq=1.0,\n    h_freq=35.0,\n    average=True,\n    filter_length=\"10s\",\n    n_jobs=None,\n    ch_name=None,\n    reject=dict(grad=2000e-13, mag=3000e-15, eeg=50e-6, eog=250e-6),  # noqa: B006\n    flat=None,\n    bads=(),\n    avg_ref=False,\n    no_proj=False,\n    event_id=999,\n    ecg_l_freq=5,\n    ecg_h_freq=35,\n    tstart=0.0,\n    qrs_threshold=\"auto\",\n    filter_method=\"fir\",\n    iir_params=None,\n    copy=True,\n    return_drop_log=False,\n    meg=\"separate\",\n    verbose=None,\n):\n    \"\"\"Compute SSP (signal-space projection) vectors for ECG artifacts.\n\n    %(compute_proj_ecg)s\n\n    .. note:: Raw data will be loaded if it hasn't been preloaded already.\n\n    Parameters\n    ----------\n    raw : mne.io.Raw\n        Raw input file.\n    raw_event : mne.io.Raw or None\n        Raw file to use for event detection (if None, raw is used).\n    tmin : float\n        Time before event in seconds.\n    tmax : float\n        Time after event in seconds.\n    n_grad : int\n        Number of SSP vectors for gradiometers.\n    n_mag : int\n        Number of SSP vectors for magnetometers.\n    n_eeg : int\n        Number of SSP vectors for EEG.\n    l_freq : float | None\n        Filter low cut-off frequency for the data channels in Hz.\n    h_freq : float | None\n        Filter high cut-off frequency for the data channels in Hz.\n    average : bool\n        Compute SSP after averaging. Default is True.\n    filter_length : str | int | None\n        Number of taps to use for filtering.\n    %(n_jobs)s\n    ch_name : str | None\n        Channel to use for ECG detection (Required if no ECG found).\n    reject : dict | None\n        Epoch rejection configuration (see Epochs).\n    flat : dict | None\n        Epoch flat configuration (see Epochs).\n    bads : list\n        List with (additional) bad channels.\n    avg_ref : bool\n        Add EEG average reference proj.\n    no_proj : bool\n        Exclude the SSP projectors currently in the fiff file.\n    event_id : int\n        ID to use for events.\n    ecg_l_freq : float\n        Low pass frequency applied to the ECG channel for event detection.\n    ecg_h_freq : float\n        High pass frequency applied to the ECG channel for event detection.\n    tstart : float\n        Start artifact detection after tstart seconds.\n    qrs_threshold : float | str\n        Between 0 and 1. qrs detection threshold. Can also be \"auto\" to\n        automatically choose the threshold that generates a reasonable\n        number of heartbeats (40-160 beats / min).\n    filter_method : str\n        Method for filtering ('iir' or 'fir').\n    iir_params : dict | None\n        Dictionary of parameters to use for IIR filtering.\n        See mne.filter.construct_iir_filter for details. If iir_params\n        is None and method=\"iir\", 4th order Butterworth will be used.\n    copy : bool\n        If False, filtering raw data is done in place. Defaults to True.\n    return_drop_log : bool\n        If True, return the drop log.\n\n        .. versionadded:: 0.15\n    meg : str\n        Can be ``'separate'`` (default) or ``'combined'`` to compute projectors\n        for magnetometers and gradiometers separately or jointly.\n        If ``'combined'``, ``n_mag == n_grad`` is required and the number of\n        projectors computed for MEG will be ``n_mag``.\n\n        .. versionadded:: 0.18\n    %(verbose)s\n\n    Returns\n    -------\n    %(projs)s\n    ecg_events : ndarray\n        Detected ECG events.\n    drop_log : list\n        The drop log, if requested.\n\n    See Also\n    --------\n    find_ecg_events\n    create_ecg_epochs\n\n    Notes\n    -----\n    Filtering is applied to the ECG channel while finding events using\n    ``ecg_l_freq`` and ``ecg_h_freq``, and then to the ``raw`` instance\n    using ``l_freq`` and ``h_freq`` before creation of the epochs used to\n    create the projectors.\n    \"\"\"\n    return _compute_exg_proj(\n        \"ECG\",\n        raw,\n        raw_event,\n        tmin,\n        tmax,\n        n_grad,\n        n_mag,\n        n_eeg,\n        l_freq,\n        h_freq,\n        average,\n        filter_length,\n        n_jobs,\n        ch_name,\n        reject,\n        flat,\n        bads,\n        avg_ref,\n        no_proj,\n        event_id,\n        ecg_l_freq,\n        ecg_h_freq,\n        tstart,\n        qrs_threshold,\n        filter_method,\n        iir_params,\n        return_drop_log,\n        copy,\n        meg,\n        verbose,\n    )", "metadata": {}}
{"_id": "mne_mne_preprocessing/ssp.py_compute_proj_eog_code", "title": "compute_proj_eog", "text": "def compute_proj_eog(\n    raw,\n    raw_event=None,\n    tmin=-0.2,\n    tmax=0.2,\n    n_grad=2,\n    n_mag=2,\n    n_eeg=2,\n    l_freq=1.0,\n    h_freq=35.0,\n    average=True,\n    filter_length=\"10s\",\n    n_jobs=None,\n    reject=dict(grad=2000e-13, mag=3000e-15, eeg=500e-6, eog=np.inf),  # noqa: B006\n    flat=None,\n    bads=(),\n    avg_ref=False,\n    no_proj=False,\n    event_id=998,\n    eog_l_freq=1,\n    eog_h_freq=10,\n    tstart=0.0,\n    filter_method=\"fir\",\n    iir_params=None,\n    ch_name=None,\n    copy=True,\n    return_drop_log=False,\n    meg=\"separate\",\n    verbose=None,\n):\n    \"\"\"Compute SSP (signal-space projection) vectors for EOG artifacts.\n\n    %(compute_proj_eog)s\n\n    .. note:: Raw data must be preloaded.\n\n    Parameters\n    ----------\n    raw : mne.io.Raw\n        Raw input file.\n    raw_event : mne.io.Raw or None\n        Raw file to use for event detection (if None, raw is used).\n    tmin : float\n        Time before event in seconds.\n    tmax : float\n        Time after event in seconds.\n    n_grad : int\n        Number of SSP vectors for gradiometers.\n    n_mag : int\n        Number of SSP vectors for magnetometers.\n    n_eeg : int\n        Number of SSP vectors for EEG.\n    l_freq : float | None\n        Filter low cut-off frequency for the data channels in Hz.\n    h_freq : float | None\n        Filter high cut-off frequency for the data channels in Hz.\n    average : bool\n        Compute SSP after averaging. Default is True.\n    filter_length : str | int | None\n        Number of taps to use for filtering.\n    %(n_jobs)s\n    reject : dict | None\n        Epoch rejection configuration (see Epochs).\n    flat : dict | None\n        Epoch flat configuration (see Epochs).\n    bads : list\n        List with (additional) bad channels.\n    avg_ref : bool\n        Add EEG average reference proj.\n    no_proj : bool\n        Exclude the SSP projectors currently in the fiff file.\n    event_id : int\n        ID to use for events.\n    eog_l_freq : float\n        Low pass frequency applied to the E0G channel for event detection.\n    eog_h_freq : float\n        High pass frequency applied to the EOG channel for event detection.\n    tstart : float\n        Start artifact detection after tstart seconds.\n    filter_method : str\n        Method for filtering ('iir' or 'fir').\n    iir_params : dict | None\n        Dictionary of parameters to use for IIR filtering.\n        See mne.filter.construct_iir_filter for details. If iir_params\n        is None and method=\"iir\", 4th order Butterworth will be used.\n    ch_name : str | None\n        If not None, specify EOG channel name.\n    copy : bool\n        If False, filtering raw data is done in place. Defaults to True.\n    return_drop_log : bool\n        If True, return the drop log.\n\n        .. versionadded:: 0.15\n    meg : str\n        Can be 'separate' (default) or 'combined' to compute projectors\n        for magnetometers and gradiometers separately or jointly.\n        If 'combined', ``n_mag == n_grad`` is required and the number of\n        projectors computed for MEG will be ``n_mag``.\n\n        .. versionadded:: 0.18\n    %(verbose)s\n\n    Returns\n    -------\n    %(projs)s\n    eog_events: ndarray\n        Detected EOG events.\n    drop_log : list\n        The drop log, if requested.\n\n    See Also\n    --------\n    find_eog_events\n    create_eog_epochs\n\n    Notes\n    -----\n    Filtering is applied to the EOG channel while finding events using\n    ``eog_l_freq`` and ``eog_h_freq``, and then to the ``raw`` instance\n    using ``l_freq`` and ``h_freq`` before creation of the epochs used to\n    create the projectors.\n    \"\"\"\n    return _compute_exg_proj(\n        \"EOG\",\n        raw,\n        raw_event,\n        tmin,\n        tmax,\n        n_grad,\n        n_mag,\n        n_eeg,\n        l_freq,\n        h_freq,\n        average,\n        filter_length,\n        n_jobs,\n        ch_name,\n        reject,\n        flat,\n        bads,\n        avg_ref,\n        no_proj,\n        event_id,\n        eog_l_freq,\n        eog_h_freq,\n        tstart,\n        \"auto\",\n        filter_method,\n        iir_params,\n        return_drop_log,\n        copy,\n        meg,\n        verbose,\n    )", "metadata": {}}
{"_id": "mne_mne_preprocessing/_lof.py_find_bad_channels_lof_code", "title": "find_bad_channels_lof", "text": "def find_bad_channels_lof(\n    raw,\n    n_neighbors=20,\n    *,\n    picks=None,\n    metric=\"euclidean\",\n    threshold=1.5,\n    return_scores=False,\n    verbose=None,\n):\n    \"\"\"Find bad channels using Local Outlier Factor (LOF) algorithm.\n\n    Parameters\n    ----------\n    raw : instance of Raw\n        Raw data to process.\n    n_neighbors : int\n        Number of neighbors defining the local neighborhood (default is 20).\n        Smaller values will lead to higher LOF scores.\n    %(picks_good_data)s\n    metric : str\n        Metric to use for distance computation. Default is \u201ceuclidean\u201d,\n        see :func:`sklearn.metrics.pairwise.distance_metrics` for details.\n    threshold : float\n        Threshold to define outliers. Theoretical threshold ranges anywhere\n        between 1.0 and any positive integer. Default: 1.5\n        It is recommended to consider this as an hyperparameter to optimize.\n    return_scores : bool\n        If ``True``, return a dictionary with LOF scores for each\n        evaluated channel. Default is ``False``.\n    %(verbose)s\n\n    Returns\n    -------\n    noisy_chs : list\n        List of bad M/EEG channels that were automatically detected.\n    scores : ndarray, shape (n_picks,)\n        Only returned when ``return_scores`` is ``True``. It contains the\n        LOF outlier score for each channel in ``picks``.\n\n    See Also\n    --------\n    maxwell_filter\n    annotate_amplitude\n\n    Notes\n    -----\n    See :footcite:`KumaravelEtAl2022` and :footcite:`BreunigEtAl2000` for background on\n    choosing ``threshold``.\n\n    .. versionadded:: 1.7\n\n    References\n    ----------\n    .. footbibliography::\n    \"\"\"  # noqa: E501\n    _soft_import(\"sklearn\", \"using LOF detection\", strict=True)\n    from sklearn.neighbors import LocalOutlierFactor\n\n    _validate_type(raw, BaseRaw, \"raw\")\n    # Get the channel types\n    channel_types = raw.get_channel_types()\n    picks = _picks_to_idx(raw.info, picks=picks, none=\"data\", exclude=\"bads\")\n    picked_ch_types = set(channel_types[p] for p in picks)\n\n    # Check if there are different channel types\n    if len(picked_ch_types) != 1:\n        raise ValueError(\n            f\"Need exactly one channel type in picks, got {sorted(picked_ch_types)}\"\n        )\n    ch_names = [raw.ch_names[pick] for pick in picks]\n    data = raw.get_data(picks=picks)\n    clf = LocalOutlierFactor(n_neighbors=n_neighbors, metric=metric)\n    clf.fit_predict(data)\n    scores_lof = clf.negative_outlier_factor_\n    bad_channel_indices = [\n        i for i, v in enumerate(np.abs(scores_lof)) if v >= threshold\n    ]\n    bads = [ch_names[idx] for idx in bad_channel_indices]\n    logger.info(f\"LOF: Detected bad channel(s): {bads}\")\n    if return_scores:\n        return bads, scores_lof\n    else:\n        return bads", "metadata": {}}
{"_id": "mne_mne_preprocessing/artifact_detection.py_annotate_muscle_zscore_code", "title": "annotate_muscle_zscore", "text": "def annotate_muscle_zscore(\n    raw,\n    threshold=4,\n    ch_type=None,\n    min_length_good=0.1,\n    filter_freq=(110, 140),\n    n_jobs=None,\n    verbose=None,\n):\n    \"\"\"Create annotations for segments that likely contain muscle artifacts.\n\n    Detects data segments containing activity in the frequency range given by\n    ``filter_freq`` whose envelope magnitude exceeds the specified z-score\n    threshold, when summed across channels and divided by ``sqrt(n_channels)``.\n    False-positive transient peaks are prevented by low-pass filtering the\n    resulting z-score time series at 4 Hz. Only operates on a single channel\n    type, if ``ch_type`` is ``None`` it will select the first type in the list\n    ``mag``, ``grad``, ``eeg``.\n    See :footcite:`Muthukumaraswamy2013` for background on choosing\n    ``filter_freq`` and ``threshold``.\n\n    Parameters\n    ----------\n    raw : instance of Raw\n        Data to estimate segments with muscle artifacts.\n    threshold : float\n        The threshold in z-scores for marking segments as containing muscle\n        activity artifacts.\n    ch_type : 'mag' | 'grad' | 'eeg' | None\n        The type of sensors to use. If ``None`` it will take the first type in\n        ``mag``, ``grad``, ``eeg``.\n    min_length_good : float | None\n        The shortest allowed duration of \"good data\" (in seconds) between\n        adjacent annotations; shorter segments will be incorporated into the\n        surrounding annotations.``None`` is equivalent to ``0``.\n        Default is ``0.1``.\n    filter_freq : array-like, shape (2,)\n        The lower and upper frequencies of the band-pass filter.\n        Default is ``(110, 140)``.\n    %(n_jobs)s\n    %(verbose)s\n\n    Returns\n    -------\n    annot : mne.Annotations\n        Periods with muscle artifacts annotated as BAD_muscle.\n    scores_muscle : array\n        Z-score values averaged across channels for each sample.\n\n    References\n    ----------\n    .. footbibliography::\n    \"\"\"\n    raw_copy = raw.copy()\n\n    if ch_type is None:\n        raw_ch_type = raw_copy.get_channel_types()\n        if \"mag\" in raw_ch_type:\n            ch_type = \"mag\"\n        elif \"grad\" in raw_ch_type:\n            ch_type = \"grad\"\n        elif \"eeg\" in raw_ch_type:\n            ch_type = \"eeg\"\n        else:\n            raise ValueError(\n                \"No M/EEG channel types found, please specify a 'ch_type' or provide \"\n                \"M/EEG sensor data.\"\n            )\n        logger.info(\"Using %s sensors for muscle artifact detection\", ch_type)\n    else:\n        _check_option(\"ch_type\", ch_type, [\"mag\", \"grad\", \"eeg\"])\n    raw_copy.pick(ch_type)\n\n    raw_copy.filter(\n        filter_freq[0],\n        filter_freq[1],\n        fir_design=\"firwin\",\n        pad=\"reflect_limited\",\n        n_jobs=n_jobs,\n    )\n    raw_copy.apply_hilbert(envelope=True, n_jobs=n_jobs)\n\n    data = raw_copy.get_data(reject_by_annotation=\"NaN\")\n    nan_mask = ~np.isnan(data[0])\n    sfreq = raw_copy.info[\"sfreq\"]\n\n    art_scores = zscore(data[:, nan_mask], axis=1)\n    art_scores = art_scores.sum(axis=0) / np.sqrt(art_scores.shape[0])\n    art_scores = filter_data(art_scores, sfreq, None, 4)\n\n    scores_muscle = np.zeros(data.shape[1])\n    scores_muscle[nan_mask] = art_scores\n\n    art_mask = scores_muscle > threshold\n    # return muscle scores with NaNs\n    scores_muscle[~nan_mask] = np.nan\n\n    # remove artifact free periods shorter than min_length_good\n    min_length_good = 0 if min_length_good is None else min_length_good\n    min_samps = min_length_good * sfreq\n    comps, num_comps = label(art_mask == 0)\n    for com in range(1, num_comps + 1):\n        l_idx = np.nonzero(comps == com)[0]\n        if len(l_idx) < min_samps:\n            art_mask[l_idx] = True\n\n    annot = _annotations_from_mask(\n        raw_copy.times, art_mask, \"BAD_muscle\", orig_time=raw.info[\"meas_date\"]\n    )\n    _adjust_onset_meas_date(annot, raw)\n    return annot, scores_muscle", "metadata": {}}
{"_id": "mne_mne_preprocessing/artifact_detection.py_annotate_movement_code", "title": "annotate_movement", "text": "def annotate_movement(\n    raw,\n    pos,\n    rotation_velocity_limit=None,\n    translation_velocity_limit=None,\n    mean_distance_limit=None,\n    use_dev_head_trans=\"average\",\n):\n    \"\"\"Detect segments with movement.\n\n    Detects segments periods further from rotation_velocity_limit,\n    translation_velocity_limit and mean_distance_limit. It returns an\n    annotation with the bad segments.\n\n    Parameters\n    ----------\n    raw : instance of Raw\n        Data to compute head position.\n    pos : array, shape (N, 10)\n        The position and quaternion parameters from cHPI fitting. Obtained\n        with `mne.chpi` functions.\n    rotation_velocity_limit : float\n        Head rotation velocity limit in degrees per second.\n    translation_velocity_limit : float\n        Head translation velocity limit in meters per second.\n    mean_distance_limit : float\n        Head position limit from mean recording in meters.\n    use_dev_head_trans : 'average' (default) | 'info'\n        Identify the device to head transform used to define the\n        fixed HPI locations for computing moving distances.\n        If ``average`` the average device to head transform is\n        computed using ``compute_average_dev_head_t``.\n        If ``info``, ``raw.info['dev_head_t']`` is used.\n\n    Returns\n    -------\n    annot : mne.Annotations\n        Periods with head motion.\n    hpi_disp : array\n        Head position over time with respect to the mean head pos.\n\n    See Also\n    --------\n    compute_average_dev_head_t\n    \"\"\"\n    sfreq = raw.info[\"sfreq\"]\n    hp_ts = pos[:, 0].copy() - raw.first_time\n    dt = np.diff(hp_ts)\n    hp_ts = np.concatenate([hp_ts, [hp_ts[-1] + 1.0 / sfreq]])\n    orig_time = raw.info[\"meas_date\"]\n    annot = Annotations([], [], [], orig_time=orig_time)\n\n    # Annotate based on rotational velocity\n    t_tot = raw.times[-1]\n    if rotation_velocity_limit is not None:\n        assert rotation_velocity_limit > 0\n        # Rotational velocity (radians / s)\n        r = _angle_between_quats(pos[:-1, 1:4], pos[1:, 1:4])\n        r /= dt\n        bad_mask = r >= np.deg2rad(rotation_velocity_limit)\n        onsets, offsets = _mask_to_onsets_offsets(bad_mask)\n        onsets, offsets = hp_ts[onsets], hp_ts[offsets]\n        bad_pct = 100 * (offsets - onsets).sum() / t_tot\n        logger.info(\n            \"Omitting %5.1f%% (%3d segments): \u03c9 >= %5.1f\u00b0/s (max: %0.1f\u00b0/s)\",\n            bad_pct,\n            len(onsets),\n            rotation_velocity_limit,\n            np.rad2deg(r.max()),\n        )\n        annot += _annotations_from_mask(\n            hp_ts, bad_mask, \"BAD_mov_rotat_vel\", orig_time=orig_time\n        )\n\n    # Annotate based on translational velocity limit\n    if translation_velocity_limit is not None:\n        assert translation_velocity_limit > 0\n        v = np.linalg.norm(np.diff(pos[:, 4:7], axis=0), axis=-1)\n        v /= dt\n        bad_mask = v >= translation_velocity_limit\n        onsets, offsets = _mask_to_onsets_offsets(bad_mask)\n        onsets, offsets = hp_ts[onsets], hp_ts[offsets]\n        bad_pct = 100 * (offsets - onsets).sum() / t_tot\n        logger.info(\n            \"Omitting %5.1f%% (%3d segments): v >= %5.4fm/s (max: %5.4fm/s)\",\n            bad_pct,\n            len(onsets),\n            translation_velocity_limit,\n            v.max(),\n        )\n        annot += _annotations_from_mask(\n            hp_ts, bad_mask, \"BAD_mov_trans_vel\", orig_time=orig_time\n        )\n\n    # Annotate based on displacement from mean head position\n    disp = []\n    if mean_distance_limit is not None:\n        assert mean_distance_limit > 0\n\n        # compute dev to head transform for fixed points\n        use_dev_head_trans = use_dev_head_trans.lower()\n        if use_dev_head_trans not in [\"average\", \"info\"]:\n            raise ValueError(\n                \"use_dev_head_trans must be either\"\n                f\" 'average' or 'info': got '{use_dev_head_trans}'\"\n            )\n\n        if use_dev_head_trans == \"average\":\n            fixed_dev_head_t = compute_average_dev_head_t(raw, pos)\n        elif use_dev_head_trans == \"info\":\n            fixed_dev_head_t = raw.info[\"dev_head_t\"]\n\n        # Get static head pos from file, used to convert quat to cartesian\n        chpi_pos = sorted(\n            [d for d in raw.info[\"hpi_results\"][-1][\"dig_points\"]],\n            key=lambda x: x[\"ident\"],\n        )\n        chpi_pos = np.array([d[\"r\"] for d in chpi_pos])\n\n        # Get head pos changes during recording\n        chpi_pos_mov = np.array(\n            [apply_trans(_quat_to_affine(quat), chpi_pos) for quat in pos[:, 1:7]]\n        )\n\n        # get fixed position\n        chpi_pos_fix = apply_trans(fixed_dev_head_t, chpi_pos)\n\n        # get movement displacement from mean pos\n        hpi_disp = chpi_pos_mov - np.tile(chpi_pos_fix, (pos.shape[0], 1, 1))\n\n        # get positions above threshold distance\n        disp = np.sqrt((hpi_disp**2).sum(axis=2))\n        bad_mask = np.any(disp > mean_distance_limit, axis=1)\n        onsets, offsets = _mask_to_onsets_offsets(bad_mask)\n        onsets, offsets = hp_ts[onsets], hp_ts[offsets]\n        bad_pct = 100 * (offsets - onsets).sum() / t_tot\n        logger.info(\n            \"Omitting %5.1f%% (%3d segments): disp >= %5.4fm (max: %5.4fm)\",\n            bad_pct,\n            len(onsets),\n            mean_distance_limit,\n            disp.max(),\n        )\n        annot += _annotations_from_mask(\n            hp_ts, bad_mask, \"BAD_mov_dist\", orig_time=orig_time\n        )\n    _adjust_onset_meas_date(annot, raw)\n    return annot, disp", "metadata": {}}
{"_id": "mne_mne_preprocessing/artifact_detection.py_compute_average_dev_head_t_code", "title": "compute_average_dev_head_t", "text": "def compute_average_dev_head_t(raw, pos, *, verbose=None):\n    \"\"\"Get new device to head transform based on good segments.\n\n    Segments starting with \"BAD\" annotations are not included for calculating\n    the mean head position.\n\n    Parameters\n    ----------\n    raw : instance of Raw | list of Raw\n        Data to compute head position. Can be a list containing multiple raw\n        instances.\n    pos : array, shape (N, 10) | list of ndarray\n        The position and quaternion parameters from cHPI fitting. Can be\n        a list containing multiple position arrays, one per raw instance passed.\n    %(verbose)s\n\n    Returns\n    -------\n    dev_head_t : instance of Transform\n        New ``dev_head_t`` transformation using the averaged good head positions.\n\n    Notes\n    -----\n    .. versionchanged:: 1.7\n       Support for multiple raw instances and position arrays was added.\n    \"\"\"\n    # Get weighted head pos trans and rot\n    if not isinstance(raw, list | tuple):\n        raw = [raw]\n    if not isinstance(pos, list | tuple):\n        pos = [pos]\n    if len(pos) != len(raw):\n        raise ValueError(\n            f\"Number of head positions ({len(pos)}) must match the number of raw \"\n            f\"instances ({len(raw)})\"\n        )\n    hp = list()\n    dt = list()\n    for ri, (r, p) in enumerate(zip(raw, pos)):\n        _validate_type(r, BaseRaw, f\"raw[{ri}]\")\n        _validate_type(p, np.ndarray, f\"pos[{ri}]\")\n        hp_, dt_ = _raw_hp_weights(r, p)\n        hp.append(hp_)\n        dt.append(dt_)\n    hp = np.concatenate(hp, axis=0)\n    dt = np.concatenate(dt, axis=0)\n    dt /= dt.sum()\n    best_q = _average_quats(hp[:, 1:4], weights=dt)\n    trans = np.eye(4)\n    trans[:3, :3] = quat_to_rot(best_q)\n    trans[:3, 3] = dt @ hp[:, 4:7]\n    dist = np.linalg.norm(trans[:3, 3])\n    if dist > 1:  # less than 1 meter is sane\n        warn(f\"Implausible head position detected: {dist} meters from device origin\")\n    dev_head_t = Transform(\"meg\", \"head\", trans)\n    return dev_head_t", "metadata": {}}
{"_id": "mne_mne_preprocessing/artifact_detection.py_annotate_break_code", "title": "annotate_break", "text": "def annotate_break(\n    raw,\n    events=None,\n    min_break_duration=15.0,\n    t_start_after_previous=5.0,\n    t_stop_before_next=5.0,\n    ignore=(\"bad\", \"edge\"),\n    *,\n    verbose=None,\n):\n    \"\"\"Create `~mne.Annotations` for breaks in an ongoing recording.\n\n    This function first searches for segments in the data that are not\n    annotated or do not contain any events and are at least\n    ``min_break_duration`` seconds long, and then proceeds to creating\n    annotations for those break periods.\n\n    Parameters\n    ----------\n    raw : instance of Raw\n        The continuous data to analyze.\n    events : None | array, shape (n_events, 3)\n        If ``None`` (default), operate based solely on the annotations present\n        in ``raw``. If an events array, ignore any annotations in the raw data,\n        and operate based on these events only.\n    min_break_duration : float\n        The minimum time span in seconds between the offset of one and the\n        onset of the subsequent annotation (if ``events`` is ``None``) or\n        between two consecutive events (if ``events`` is an array) to consider\n        this period a \"break\". Defaults to 15 seconds.\n\n        .. note:: This value defines the minimum duration of a break period in\n                  the data, **not** the minimum duration of the generated\n                  annotations! See also ``t_start_after_previous`` and\n                  ``t_stop_before_next`` for details.\n\n    t_start_after_previous, t_stop_before_next : float\n        Specifies how far the to-be-created \"break\" annotation extends towards\n        the two annotations or events spanning the break. This can be used to\n        ensure e.g. that the break annotation doesn't start and end immediately\n        with a stimulation event. If, for example, your data contains a break\n        of 30 seconds between two stimuli, and ``t_start_after_previous`` is\n        set to ``5`` and ``t_stop_before_next`` is set to ``3``, the break\n        annotation will start 5 seconds after the first stimulus, and end 3\n        seconds before the second stimulus, yielding an annotated break of\n        ``30 - 5 - 3 = 22`` seconds. Both default to 5 seconds.\n\n        .. note:: The beginning and the end of the recording will be annotated\n                  as breaks, too, if the period from recording start until the\n                  first annotation or event (or from last annotation or event\n                  until recording end) is at least ``min_break_duration``\n                  seconds long.\n\n    ignore : iterable of str\n        Annotation descriptions starting with these strings will be ignored by\n        the break-finding algorithm. The string comparison is case-insensitive,\n        i.e., ``('bad',)`` and ``('BAD',)`` are equivalent. By default, all\n        annotation descriptions starting with \"bad\" and annotations\n        indicating \"edges\" (produced by data concatenation) will be\n        ignored. Pass an empty list or tuple to take all existing annotations\n        into account. If ``events`` is passed, this parameter has no effect.\n    %(verbose)s\n\n    Returns\n    -------\n    break_annotations : instance of Annotations\n        The break annotations, each with the description ``'BAD_break'``. If\n        no breaks could be found given the provided function parameters, an\n        empty `~mne.Annotations` object will be returned.\n\n    Notes\n    -----\n    .. versionadded:: 0.24\n    \"\"\"\n    _validate_type(item=raw, item_name=\"raw\", types=BaseRaw, type_name=\"Raw\")\n    _validate_type(item=events, item_name=\"events\", types=(None, np.ndarray))\n\n    if min_break_duration - t_start_after_previous - t_stop_before_next <= 0:\n        annot_dur = min_break_duration - t_start_after_previous - t_stop_before_next\n        raise ValueError(\n            f\"The result of \"\n            f\"min_break_duration - t_start_after_previous - \"\n            f\"t_stop_before_next must be greater than 0, but it is: \"\n            f\"{annot_dur}\"\n        )\n\n    if events is not None and events.size == 0:\n        raise ValueError(\"The events array must not be empty.\")\n\n    if events is not None or not ignore:\n        ignore = tuple()\n    else:\n        ignore = tuple(ignore)\n\n    for item in ignore:\n        _validate_type(item=item, types=\"str\", item_name='All elements of \"ignore\"')\n\n    if events is None:\n        annotations = raw.annotations.copy()\n        if ignore:\n            logger.info(\n                f\"Ignoring annotations with descriptions starting \"\n                f\"with: {', '.join(ignore)}\"\n            )\n    else:\n        annotations = annotations_from_events(\n            events=events, sfreq=raw.info[\"sfreq\"], orig_time=raw.info[\"meas_date\"]\n        )\n\n    if not annotations:\n        raise ValueError(\"Could not find (or generate) any annotations in your data.\")\n\n    # Only keep annotations of interest and extract annotated time periods\n    # Ignore case\n    ignore = tuple(i.lower() for i in ignore)\n    keep_mask = [True] * len(annotations)\n    for idx, description in enumerate(annotations.description):\n        description = description.lower()\n        if any(description.startswith(i) for i in ignore):\n            keep_mask[idx] = False\n\n    annotated_intervals = [\n        [onset, onset + duration]\n        for onset, duration in zip(\n            annotations.onset[keep_mask], annotations.duration[keep_mask]\n        )\n    ]\n\n    # Merge overlapping annotation intervals\n    # Pre-load `merged_intervals` with the first interval to simplify\n    # processing\n    merged_intervals = [annotated_intervals[0]]\n    for interval in annotated_intervals:\n        merged_interval_stop = merged_intervals[-1][1]\n        interval_start, interval_stop = interval\n\n        if interval_stop < merged_interval_stop:\n            # Current interval ends sooner than the merged one; skip it\n            continue\n        elif (\n            interval_start <= merged_interval_stop\n            and interval_stop >= merged_interval_stop\n        ):\n            # Expand duration of the merged interval\n            merged_intervals[-1][1] = interval_stop\n        else:\n            # No overlap between the current interval and the existing merged\n            # time period; proceed to the next interval\n            merged_intervals.append(interval)\n\n    merged_intervals = np.array(merged_intervals)\n    merged_intervals -= raw.first_time  # work in zero-based time\n\n    # Now extract the actual break periods\n    break_onsets = []\n    break_durations = []\n\n    # Handle the time period up until the first annotation\n    if 0 < merged_intervals[0][0] and merged_intervals[0][0] >= min_break_duration:\n        onset = 0  # don't add t_start_after_previous here\n        offset = merged_intervals[0][0] - t_stop_before_next\n        duration = offset - onset\n        break_onsets.append(onset)\n        break_durations.append(duration)\n\n    # Handle the time period between first and last annotation\n    for idx, _ in enumerate(merged_intervals[1:, :], start=1):\n        this_start = merged_intervals[idx, 0]\n        previous_stop = merged_intervals[idx - 1, 1]\n        if this_start - previous_stop < min_break_duration:\n            continue\n\n        onset = previous_stop + t_start_after_previous\n        offset = this_start - t_stop_before_next\n        duration = offset - onset\n        break_onsets.append(onset)\n        break_durations.append(duration)\n\n    # Handle the time period after the last annotation\n    if (\n        raw.times[-1] > merged_intervals[-1][1]\n        and raw.times[-1] - merged_intervals[-1][1] >= min_break_duration\n    ):\n        onset = merged_intervals[-1][1] + t_start_after_previous\n        offset = raw.times[-1]  # don't subtract t_stop_before_next here\n        duration = offset - onset\n        break_onsets.append(onset)\n        break_durations.append(duration)\n\n    # Finally, create the break annotations\n    break_annotations = Annotations(\n        onset=break_onsets,\n        duration=break_durations,\n        description=[\"BAD_break\"],\n        orig_time=raw.info[\"meas_date\"],\n    )\n\n    # Log some info\n    n_breaks = len(break_annotations)\n    break_times = [\n        f\"{o:.1f} \u2013 {o + d:.1f} s [{d:.1f} s]\"\n        for o, d in zip(break_annotations.onset, break_annotations.duration)\n    ]\n    break_times = \"\\n    \".join(break_times)\n    total_break_dur = sum(break_annotations.duration)\n    fraction_breaks = total_break_dur / raw.times[-1]\n    logger.info(\n        f\"\\nDetected {n_breaks} break period{_pl(n_breaks)} of >= \"\n        f\"{min_break_duration} s duration:\\n    {break_times}\\n\"\n        f\"In total, {round(100 * fraction_breaks, 1):.1f}% of the \"\n        f\"data ({round(total_break_dur, 1):.1f} s) have been marked \"\n        f\"as a break.\\n\"\n    )\n    _adjust_onset_meas_date(break_annotations, raw)\n\n    return break_annotations", "metadata": {}}
{"_id": "mne_mne_preprocessing/otp.py_oversampled_temporal_projection_code", "title": "oversampled_temporal_projection", "text": "def oversampled_temporal_projection(raw, duration=10.0, picks=None, verbose=None):\n    \"\"\"Denoise MEG channels using leave-one-out temporal projection.\n\n    Parameters\n    ----------\n    raw : instance of Raw\n        Raw data to denoise.\n    duration : float | str\n        The window duration (in seconds; default 10.) to use. Can also\n        be \"min\" to use as short a window as possible.\n    %(picks_all_data)s\n    %(verbose)s\n\n    Returns\n    -------\n    raw_clean : instance of Raw\n        The cleaned data.\n\n    Notes\n    -----\n    This algorithm is computationally expensive, and can be several times\n    slower than realtime for conventional M/EEG datasets. It uses a\n    leave-one-out procedure with parallel temporal projection to remove\n    individual sensor noise under the assumption that sampled fields\n    (e.g., MEG and EEG) are oversampled by the sensor array\n    :footcite:`LarsonTaulu2018`.\n\n    OTP can improve sensor noise levels (especially under visual\n    inspection) and repair some bad channels. This noise reduction is known\n    to interact with :func:`tSSS <mne.preprocessing.maxwell_filter>` such\n    that increasing the ``st_correlation`` value will likely be necessary.\n\n    Channels marked as bad will not be used to reconstruct good channels,\n    but good channels will be used to process the bad channels. Depending\n    on the type of noise present in the bad channels, this might make\n    them usable again.\n\n    Use of this algorithm is covered by a provisional patent.\n\n    .. versionadded:: 0.16\n\n    References\n    ----------\n    .. footbibliography::\n    \"\"\"\n    logger.info(\"Processing MEG data using oversampled temporal projection\")\n    picks = _picks_to_idx(raw.info, picks, exclude=())\n    picks_good, picks_bad = list(), list()  # these are indices into picks\n    for ii, pi in enumerate(picks):\n        if raw.ch_names[pi] in raw.info[\"bads\"]:\n            picks_bad.append(ii)\n        else:\n            picks_good.append(ii)\n    picks_good = np.array(picks_good, int)\n    picks_bad = np.array(picks_bad, int)\n\n    n_samples = int(round(float(duration) * raw.info[\"sfreq\"]))\n    if n_samples < len(picks_good) - 1:\n        raise ValueError(\n            f\"duration ({n_samples / raw.info['sfreq']}) yielded {n_samples} samples, \"\n            f\"which is fewer than the number of channels -1 ({len(picks_good) - 1})\"\n        )\n    n_overlap = n_samples // 2\n    raw_otp = raw.copy().load_data(verbose=False)\n    otp = _COLA(\n        partial(_otp, picks_good=picks_good, picks_bad=picks_bad),\n        _Storer(raw_otp._data, picks=picks),\n        len(raw.times),\n        n_samples,\n        n_overlap,\n        raw.info[\"sfreq\"],\n    )\n    read_lims = list(range(0, len(raw.times), n_samples)) + [len(raw.times)]\n    for start, stop in zip(read_lims[:-1], read_lims[1:]):\n        logger.info(\n            f\"    Denoising {raw.times[[start, stop - 1]][0]: 8.2f} \u2013 \"\n            f\"{raw.times[[start, stop - 1]][1]: 8.2f} s\"\n        )\n        otp.feed(raw[picks, start:stop][0])\n    return raw_otp", "metadata": {}}
{"_id": "mne_mne_preprocessing/realign.py_realign_raw_code", "title": "realign_raw", "text": "def realign_raw(raw, other, t_raw, t_other, *, verbose=None):\n    \"\"\"Realign two simultaneous recordings.\n\n    Due to clock drift, recordings at a given same sample rate made by two\n    separate devices simultaneously can become out of sync over time. This\n    function uses event times captured by both acquisition devices to resample\n    ``other`` to match ``raw``.\n\n    Parameters\n    ----------\n    raw : instance of Raw\n        The first raw instance.\n    other : instance of Raw\n        The second raw instance. It will be resampled to match ``raw``.\n    t_raw : array-like, shape (n_events,)\n        The times of shared events in ``raw`` relative to ``raw.times[0]`` (0).\n        Typically these could be events on some TTL channel such as::\n\n            find_events(raw)[:, 0] / raw.info[\"sfreq\"] - raw.first_time\n    t_other : array-like, shape (n_events,)\n        The times of shared events in ``other`` relative to ``other.times[0]``.\n    %(verbose)s\n\n    Notes\n    -----\n    This function operates inplace. It will:\n\n    1. Estimate the zero-order (start offset) and first-order (clock drift)\n       correction.\n    2. Crop the start of ``raw`` or ``other``, depending on which started\n       recording first.\n    3. Resample ``other`` to match ``raw`` based on the clock drift.\n    4. Realign the onsets and durations in ``other.annotations``.\n    5. Crop the end of ``raw`` or ``other``, depending on which stopped\n       recording first (and the clock drift rate).\n\n    This function is primarily designed to work on recordings made at the same\n    sample rate, but it can also operate on recordings made at different\n    sample rates to resample and deal with clock drift simultaneously.\n\n    .. versionadded:: 0.22\n    \"\"\"\n    _validate_type(raw, BaseRaw, \"raw\")\n    _validate_type(other, BaseRaw, \"other\")\n    t_raw = np.array(t_raw, float)\n    t_other = np.array(t_other, float)\n    if t_raw.ndim != 1 or t_raw.shape != t_other.shape:\n        raise ValueError(\n            \"t_raw and t_other must be 1D with the same shape, \"\n            f\"got shapes {t_raw.shape} and {t_other.shape}\"\n        )\n    if len(t_raw) < 20:\n        warn(\"Fewer than 20 times passed, results may be unreliable\")\n\n    # 1. Compute correction factors\n    poly = Polynomial.fit(x=t_other, y=t_raw, deg=1)\n    converted = poly.convert(domain=(-1, 1))\n    [zero_ord, first_ord] = converted.coef\n    logger.info(\n        f\"Zero order coefficient: {zero_ord} \\nFirst order coefficient: {first_ord}\"\n    )\n    r, p = pearsonr(t_other, t_raw)\n    msg = f\"Linear correlation computed as R={r:0.3f} and p={p:0.2e}\"\n    if p > 0.05 or r <= 0:\n        raise ValueError(msg + \", cannot resample safely\")\n    if p > 1e-6:\n        warn(msg + \", results may be unreliable\")\n    else:\n        logger.info(msg)\n    dr_ms_s = 1000 * abs(1 - first_ord)\n    logger.info(\n        f\"Drift rate: {1000 * dr_ms_s:0.1f} \u03bcs/s \"\n        f\"(total drift over {raw.times[-1]:0.1f} s recording: \"\n        f\"{raw.times[-1] * dr_ms_s:0.1f} ms)\"\n    )\n\n    # 2. Crop start of recordings to match\n    if zero_ord > 0:  # need to crop start of raw to match other\n        logger.info(f\"Cropping {zero_ord:0.3f} s from the start of raw\")\n        raw.crop(zero_ord, None)\n        t_raw -= zero_ord\n    elif zero_ord < 0:  # need to crop start of other to match raw\n        t_crop = -zero_ord / first_ord\n        logger.info(f\"Cropping {t_crop:0.3f} s from the start of other\")\n        other.crop(t_crop, None)\n        t_other -= t_crop\n\n    # 3. Resample data using the first-order term\n    nan_ch_names = [\n        ch for ch in other.info[\"ch_names\"] if np.isnan(other.get_data(picks=ch)).any()\n    ]\n    if len(nan_ch_names) > 0:  # Issue warning if any channel in other has nan values\n        warn(\n            f\"Channel(s) {', '.join(nan_ch_names)} in `other` contain NaN values. \"\n            \"Resampling these channels will result in the whole channel being NaN. \"\n            \"(If realigning eye-tracking data, consider using interpolate_blinks and \"\n            \"passing interpolate_gaze=True)\"\n        )\n    logger.info(\"Resampling other\")\n    sfreq_new = raw.info[\"sfreq\"] * first_ord\n    other.load_data().resample(sfreq_new)\n    with other.info._unlock():\n        other.info[\"sfreq\"] = raw.info[\"sfreq\"]\n\n    # 4. Realign the onsets and durations in other.annotations\n    # Must happen before end cropping to avoid losing annotations\n    logger.info(\"Correcting annotations in other\")\n    other.annotations.onset *= first_ord\n    other.annotations.duration *= first_ord\n\n    # 5. Crop the end of one of the recordings if necessary\n    delta = raw.times[-1] - other.times[-1]\n    msg = f\"Cropping {abs(delta):0.3f} s from the end of \"\n    if delta > 0:\n        logger.info(msg + \"raw\")\n        raw.crop(0, other.times[-1])\n    elif delta < 0:\n        logger.info(msg + \"other\")\n        other.crop(0, raw.times[-1])", "metadata": {}}
{"_id": "mne_mne_preprocessing/hfc.py_compute_proj_hfc_code", "title": "compute_proj_hfc", "text": "def compute_proj_hfc(\n    info, order=1, picks=\"meg\", exclude=\"bads\", *, accuracy=\"accurate\", verbose=None\n):\n    \"\"\"Generate projectors to perform homogeneous/harmonic correction to data.\n\n    Remove environmental fields from magnetometer data by assuming it is\n    explained as a homogeneous :footcite:`TierneyEtAl2021` or harmonic field\n    :footcite:`TierneyEtAl2022`. Useful for arrays of OPMs.\n\n    Parameters\n    ----------\n    %(info)s\n    order : int\n        The order of the spherical harmonic basis set to use. Set to 1 to use\n        only the homogeneous field component (default), 2 to add gradients, 3\n        to add quadrature terms, etc.\n    picks : str | array_like | slice | None\n        Channels to include. Default of ``'meg'`` (same as None) will select\n        all non-reference MEG channels. Use ``('meg', 'ref_meg')`` to include\n        reference sensors as well.\n    exclude : list | 'bads'\n        List of channels to exclude from HFC, only used when picking\n        based on types (e.g., exclude=\"bads\" when picks=\"meg\").\n        Specify ``'bads'`` (the default) to exclude all channels marked as bad.\n    accuracy : str\n        Can be ``\"point\"``, ``\"normal\"`` or ``\"accurate\"`` (default), defines\n        which level of coil definition accuracy is used to generate model.\n    %(verbose)s\n\n    Returns\n    -------\n    %(projs)s\n\n    See Also\n    --------\n    mne.io.Raw.add_proj\n    mne.io.Raw.apply_proj\n\n    Notes\n    -----\n    To apply the projectors to a dataset, use\n    ``inst.add_proj(projs).apply_proj()``.\n\n    .. versionadded:: 1.4\n\n    References\n    ----------\n    .. footbibliography::\n    \"\"\"\n    picks = _picks_to_idx(info, picks, none=\"meg\", exclude=exclude, with_ref_meg=False)\n    info = pick_info(info, picks)\n    del picks\n    exp = dict(origin=(0.0, 0.0, 0.0), int_order=0, ext_order=order)\n    coils = _prep_mf_coils(info, ignore_ref=False, accuracy=accuracy)\n    n_chs = len(coils[5])\n    if n_chs != info[\"nchan\"]:\n        raise ValueError(\n            f\"Only {n_chs}/{info['nchan']} picks could be interpreted as MEG channels.\"\n        )\n    S = _sss_basis(exp, coils)\n    del coils\n    bad_chans = [\n        info[\"ch_names\"][pick] for pick in np.where((~np.isfinite(S)).any(axis=1))[0]\n    ]\n    if bad_chans:\n        raise ValueError(\n            \"The following channel(s) generate non-finite projectors:\\n\"\n            f\"    {bad_chans}\\nPlease exclude from picks!\"\n        )\n    S /= np.linalg.norm(S, axis=0)\n    labels = _label_basis(order)\n    assert len(labels) == S.shape[1]\n    projs = []\n    for label, vec in zip(labels, S.T):\n        proj_data = dict(\n            col_names=info[\"ch_names\"],\n            row_names=None,\n            data=vec[np.newaxis, :],\n            ncol=info[\"nchan\"],\n            nrow=1,\n        )\n        projs.append(Projection(active=False, data=proj_data, desc=label))\n    return projs", "metadata": {}}
{"_id": "mne_mne_preprocessing/_fine_cal.py_compute_fine_calibration_code", "title": "compute_fine_calibration", "text": "def compute_fine_calibration(\n    raw,\n    n_imbalance=3,\n    t_window=10.0,\n    ext_order=2,\n    origin=(0.0, 0.0, 0.0),\n    cross_talk=None,\n    calibration=None,\n    *,\n    angle_limit=5.0,\n    err_limit=5.0,\n    verbose=None,\n):\n    \"\"\"Compute fine calibration from empty-room data.\n\n    Parameters\n    ----------\n    raw : instance of Raw\n        The raw data to use. Should be from an empty-room recording,\n        and all channels should be good.\n    n_imbalance : int\n        Can be 1 or 3 (default), indicating the number of gradiometer\n        imbalance components. Only used if gradiometers are present.\n    t_window : float\n        Time window to use for surface normal rotation in seconds.\n        Default is 10.\n    %(ext_order_maxwell)s\n        Default is 2, which is lower than the default (3) for\n        :func:`mne.preprocessing.maxwell_filter` because it tends to yield\n        more stable parameter estimates.\n    %(origin_maxwell)s\n    %(cross_talk_maxwell)s\n    calibration : dict | None\n        Dictionary with existing calibration. If provided, the magnetometer\n        imbalances and adjusted normals will be used and only the gradiometer\n        imbalances will be estimated (see step 2 in Notes below).\n    angle_limit : float\n        The maximum permitted angle in degrees between the original and adjusted\n        magnetometer normals. If the angle is exceeded, the segment is treated as\n        an outlier and discarded.\n\n        .. versionadded:: 1.9\n    err_limit : float\n        The maximum error (in percent) for each channel in order for a segment to\n        be used.\n\n        .. versionadded:: 1.9\n    %(verbose)s\n\n    Returns\n    -------\n    calibration : dict\n        Fine calibration data.\n    count : int\n        The number of good segments used to compute the magnetometer\n        parameters.\n\n    See Also\n    --------\n    mne.preprocessing.maxwell_filter\n\n    Notes\n    -----\n    This algorithm proceeds in two steps, both optimizing the fit between the\n    data and a reconstruction of the data based only on an external multipole\n    expansion:\n\n    1. Estimate magnetometer normal directions and scale factors. All\n       coils (mag and matching grad) are rotated by the adjusted normal\n       direction.\n    2. Estimate gradiometer imbalance factors. These add point magnetometers\n       in just the gradiometer difference direction or in all three directions\n       (depending on ``n_imbalance``).\n\n    Magnetometer normal and coefficient estimation (1) is typically the most\n    time consuming step. Gradiometer imbalance parameters (2) can be\n    iteratively reestimated (for example, first using ``n_imbalance=1`` then\n    subsequently ``n_imbalance=3``) by passing the previous ``calibration``\n    output to the ``calibration`` input in the second call.\n\n    MaxFilter processes at most 120 seconds of data, so consider cropping\n    your raw instance prior to processing. It also checks to make sure that\n    there were some minimal usable ``count`` number of segments (default 5)\n    that were included in the estimate.\n\n    .. versionadded:: 0.21\n    \"\"\"\n    n_imbalance = _ensure_int(n_imbalance, \"n_imbalance\")\n    _check_option(\"n_imbalance\", n_imbalance, (1, 3))\n    _validate_type(raw, BaseRaw, \"raw\")\n    ext_order = _ensure_int(ext_order, \"ext_order\")\n    origin = _check_origin(origin, raw.info, \"meg\", disp=True)\n    _check_option(\"raw.info['bads']\", raw.info[\"bads\"], ([],))\n    _validate_type(err_limit, \"numeric\", \"err_limit\")\n    _validate_type(angle_limit, \"numeric\", \"angle_limit\")\n    for key, val in dict(err_limit=err_limit, angle_limit=angle_limit).items():\n        if val < 0:\n            raise ValueError(f\"{key} must be greater than or equal to 0, got {val}\")\n    # Fine cal should not include ref channels\n    picks = pick_types(raw.info, meg=True, ref_meg=False)\n    if raw.info[\"dev_head_t\"] is not None:\n        raise ValueError(\n            'info[\"dev_head_t\"] is not None, suggesting that the '\n            \"data are not from an empty-room recording\"\n        )\n\n    info = pick_info(raw.info, picks)  # make a copy and pick MEG channels\n    mag_picks = pick_types(info, meg=\"mag\", exclude=())\n    grad_picks = pick_types(info, meg=\"grad\", exclude=())\n\n    # Get cross-talk\n    ctc, _ = _read_cross_talk(cross_talk, info[\"ch_names\"])\n\n    # Check fine cal\n    _validate_type(calibration, (dict, None), \"calibration\")\n\n    #\n    # 1. Rotate surface normals using magnetometer information (if present)\n    #\n    cals = np.ones(len(info[\"ch_names\"]))\n    end = len(raw.times) + 1\n    time_idxs = np.arange(0, end, int(round(t_window * raw.info[\"sfreq\"])))\n    if len(time_idxs) == 1:\n        time_idxs = np.concatenate([time_idxs, [end]])\n    if time_idxs[-1] != end:\n        time_idxs[-1] = end\n    count = 0\n    locs = np.array([ch[\"loc\"] for ch in info[\"chs\"]])\n    zs = locs[mag_picks, -3:].copy()\n    if calibration is not None:\n        _, calibration, _ = _prep_fine_cal(info, calibration, ignore_ref=True)\n        for pi, pick in enumerate(mag_picks):\n            idx = calibration[\"ch_names\"].index(info[\"ch_names\"][pick])\n            cals[pick] = calibration[\"imb_cals\"][idx].item()\n            zs[pi] = calibration[\"locs\"][idx][-3:]\n    elif len(mag_picks) > 0:\n        cal_list = list()\n        z_list = list()\n        logger.info(\n            f\"Adjusting normals for {len(mag_picks)} magnetometers \"\n            f\"(averaging over {len(time_idxs) - 1} time intervals)\"\n        )\n        for start, stop in zip(time_idxs[:-1], time_idxs[1:]):\n            logger.info(\n                f\"    Processing interval {start / info['sfreq']:0.3f} - \"\n                f\"{stop / info['sfreq']:0.3f} s\"\n            )\n            data = raw[picks, start:stop][0]\n            if ctc is not None:\n                data = ctc.dot(data)\n            z, cal, good = _adjust_mag_normals(\n                info,\n                data,\n                origin,\n                ext_order,\n                angle_limit=angle_limit,\n                err_limit=err_limit,\n            )\n            if good:\n                z_list.append(z)\n                cal_list.append(cal)\n        count = len(cal_list)\n        if count == 0:\n            raise RuntimeError(\"No usable segments found\")\n        cals[:] = np.mean(cal_list, axis=0)\n        zs[:] = np.mean(z_list, axis=0)\n    if len(mag_picks) > 0:\n        for ii, new_z in enumerate(zs):\n            z_loc = locs[mag_picks[ii]]\n            # Find sensors with same NZ and R0 (should be three for VV)\n            idxs = _matched_loc_idx(z_loc, locs)\n            # Rotate the direction vectors to the plane defined by new normal\n            _rotate_locs(locs, idxs, new_z)\n    for ci, loc in enumerate(locs):\n        info[\"chs\"][ci][\"loc\"][:] = loc\n    del calibration, zs\n\n    #\n    # 2. Estimate imbalance parameters (always done)\n    #\n    if len(grad_picks) > 0:\n        extra = \"X direction\" if n_imbalance == 1 else (\"XYZ directions\")\n        logger.info(f\"Computing imbalance for {len(grad_picks)} gradimeters ({extra})\")\n        imb_list = list()\n        for start, stop in zip(time_idxs[:-1], time_idxs[1:]):\n            logger.info(\n                f\"    Processing interval {start / info['sfreq']:0.3f} - \"\n                f\"{stop / info['sfreq']:0.3f} s\"\n            )\n            data = raw[picks, start:stop][0]\n            if ctc is not None:\n                data = ctc.dot(data)\n            out = _estimate_imbalance(info, data, cals, n_imbalance, origin, ext_order)\n            imb_list.append(out)\n        imb = np.mean(imb_list, axis=0)\n    else:\n        imb = np.zeros((len(info[\"ch_names\"]), n_imbalance))\n\n    #\n    # Put in output structure\n    #\n    assert len(np.intersect1d(mag_picks, grad_picks)) == 0\n    imb_cals = [\n        cals[ii : ii + 1] if ii in mag_picks else imb[ii]\n        for ii in range(len(info[\"ch_names\"]))\n    ]\n    ch_names = _clean_names(info[\"ch_names\"], remove_whitespace=True)\n    calibration = dict(ch_names=ch_names, locs=locs, imb_cals=imb_cals)\n    return calibration, count", "metadata": {}}
{"_id": "mne_mne_preprocessing/_fine_cal.py_read_fine_calibration_code", "title": "read_fine_calibration", "text": "def read_fine_calibration(fname):\n    \"\"\"Read fine calibration information from a ``.dat`` file.\n\n    The fine calibration typically includes improved sensor locations,\n    calibration coefficients, and gradiometer imbalance information.\n\n    Parameters\n    ----------\n    fname : path-like\n        The filename.\n\n    Returns\n    -------\n    calibration : dict\n        Fine calibration information. Key-value pairs are:\n\n        - ``ch_names``\n             List of str of the channel names.\n        - ``locs``\n             Coil location and orientation parameters.\n        - ``imb_cals``\n             For magnetometers, the calibration coefficients.\n             For gradiometers, one or three imbalance parameters.\n    \"\"\"\n    # Read new sensor locations\n    fname = _check_fname(fname, overwrite=\"read\", must_exist=True)\n    check_fname(fname, \"cal\", (\".dat\",))\n    ch_names, locs, imb_cals = list(), list(), list()\n    with open(fname) as fid:\n        for line in fid:\n            if line[0] in \"#\\n\":\n                continue\n            vals = line.strip().split()\n            if len(vals) not in [14, 16]:\n                raise RuntimeError(\n                    \"Error parsing fine calibration file, \"\n                    \"should have 14 or 16 entries per line \"\n                    f\"but found {len(vals)} on line:\\n{line}\"\n                )\n            # `vals` contains channel number\n            ch_name = vals[0]\n            if len(ch_name) in (3, 4):  # heuristic for Neuromag fix\n                try:\n                    ch_name = int(ch_name)\n                except ValueError:  # something other than e.g. 113 or 2642\n                    pass\n                else:\n                    ch_name = f\"MEG{int(ch_name):04}\"\n            # (x, y, z), x-norm 3-vec, y-norm 3-vec, z-norm 3-vec\n            # and 1 or 3 imbalance terms\n            ch_names.append(ch_name)\n            locs.append(np.array(vals[1:13], float))\n            imb_cals.append(np.array(vals[13:], float))\n    locs = np.array(locs)\n    return dict(ch_names=ch_names, locs=locs, imb_cals=imb_cals)", "metadata": {}}
{"_id": "mne_mne_preprocessing/_fine_cal.py_write_fine_calibration_code", "title": "write_fine_calibration", "text": "def write_fine_calibration(fname, calibration):\n    \"\"\"Write fine calibration information to a ``.dat`` file.\n\n    Parameters\n    ----------\n    fname : path-like\n        The filename to write out.\n    calibration : dict\n        Fine calibration information.\n    \"\"\"\n    fname = _check_fname(fname, overwrite=True)\n    check_fname(fname, \"cal\", (\".dat\",))\n    keys = (\"ch_names\", \"locs\", \"imb_cals\")\n    with open(fname, \"wb\") as cal_file:\n        for ch_name, loc, imb_cal in zip(*(calibration[key] for key in keys)):\n            cal_line = np.concatenate([loc, imb_cal]).round(6)\n            cal_line = \" \".join(f\"{c:0.6f}\" for c in cal_line)\n            cal_file.write(f\"{ch_name} {cal_line}\\n\".encode(\"ASCII\"))", "metadata": {}}
{"_id": "mne_mne_preprocessing/eog.py_find_eog_events_code", "title": "find_eog_events", "text": "def find_eog_events(\n    raw,\n    event_id=998,\n    l_freq=1,\n    h_freq=10,\n    filter_length=\"10s\",\n    ch_name=None,\n    tstart=0,\n    reject_by_annotation=False,\n    thresh=None,\n    verbose=None,\n):\n    \"\"\"Locate EOG artifacts.\n\n    .. note:: To control true-positive and true-negative detection rates, you\n              may adjust the ``thresh`` parameter.\n\n    Parameters\n    ----------\n    raw : instance of Raw\n        The raw data.\n    event_id : int\n        The index to assign to found events.\n    l_freq : float\n        Low cut-off frequency to apply to the EOG channel in Hz.\n    h_freq : float\n        High cut-off frequency to apply to the EOG channel in Hz.\n    filter_length : str | int | None\n        Number of taps to use for filtering.\n    %(ch_name_eog)s\n    tstart : float\n        Start detection after tstart seconds.\n    reject_by_annotation : bool\n        Whether to omit data that is annotated as bad.\n    thresh : float | None\n        Threshold to trigger the detection of an EOG event. This controls the\n        thresholding of the underlying peak-finding algorithm. Larger values\n        mean that fewer peaks (i.e., fewer EOG events) will be detected.\n        If ``None``, use the default of ``(max(eog) - min(eog)) / 4``,\n        with ``eog`` being the filtered EOG signal.\n    %(verbose)s\n\n    Returns\n    -------\n    eog_events : array\n        Events.\n\n    See Also\n    --------\n    create_eog_epochs\n    compute_proj_eog\n    \"\"\"\n    # Getting EOG Channel\n    eog_inds = _get_eog_channel_index(ch_name, raw)\n    eog_names = np.array(raw.ch_names)[eog_inds]  # for logging\n    logger.info(f\"EOG channel index for this subject is: {eog_inds}\")\n\n    # Reject bad segments.\n    reject_by_annotation = \"omit\" if reject_by_annotation else None\n    eog, times = raw.get_data(\n        picks=eog_inds, reject_by_annotation=reject_by_annotation, return_times=True\n    )\n    times = times * raw.info[\"sfreq\"] + raw.first_samp\n\n    eog_events = _find_eog_events(\n        eog,\n        ch_names=eog_names,\n        event_id=event_id,\n        l_freq=l_freq,\n        h_freq=h_freq,\n        sampling_rate=raw.info[\"sfreq\"],\n        first_samp=raw.first_samp,\n        filter_length=filter_length,\n        tstart=tstart,\n        thresh=thresh,\n        verbose=verbose,\n    )\n    # Map times to corresponding samples.\n    eog_events[:, 0] = np.round(times[eog_events[:, 0] - raw.first_samp]).astype(int)\n    return eog_events", "metadata": {}}
{"_id": "mne_mne_preprocessing/eog.py_create_eog_epochs_code", "title": "create_eog_epochs", "text": "def create_eog_epochs(\n    raw,\n    ch_name=None,\n    event_id=998,\n    picks=None,\n    tmin=-0.5,\n    tmax=0.5,\n    l_freq=1,\n    h_freq=10,\n    reject=None,\n    flat=None,\n    baseline=None,\n    preload=True,\n    reject_by_annotation=True,\n    thresh=None,\n    decim=1,\n    verbose=None,\n):\n    \"\"\"Conveniently generate epochs around EOG artifact events.\n\n    %(create_eog_epochs)s\n\n    Parameters\n    ----------\n    raw : instance of Raw\n        The raw data.\n    %(ch_name_eog)s\n    event_id : int\n        The index to assign to found events.\n    %(picks_all)s\n    tmin : float\n        Start time before event.\n    tmax : float\n        End time after event.\n    l_freq : float\n        Low pass frequency to apply to the EOG channel while finding events.\n    h_freq : float\n        High pass frequency to apply to the EOG channel while finding events.\n    reject : dict | None\n        Rejection parameters based on peak-to-peak amplitude.\n        Valid keys are 'grad' | 'mag' | 'eeg' | 'eog' | 'ecg'.\n        If reject is None then no rejection is done. Example::\n\n            reject = dict(grad=4000e-13, # T / m (gradiometers)\n                          mag=4e-12, # T (magnetometers)\n                          eeg=40e-6, # V (EEG channels)\n                          eog=250e-6 # V (EOG channels)\n                          )\n\n    flat : dict | None\n        Rejection parameters based on flatness of signal.\n        Valid keys are 'grad' | 'mag' | 'eeg' | 'eog' | 'ecg', and values\n        are floats that set the minimum acceptable peak-to-peak amplitude.\n        If flat is None then no rejection is done.\n    baseline : tuple or list of length 2, or None\n        The time interval to apply rescaling / baseline correction.\n        If None do not apply it. If baseline is (a, b)\n        the interval is between \"a (s)\" and \"b (s)\".\n        If a is None the beginning of the data is used\n        and if b is None then b is set to the end of the interval.\n        If baseline is equal to (None, None) all the time\n        interval is used. If None, no correction is applied.\n    preload : bool\n        Preload epochs or not.\n    %(reject_by_annotation_epochs)s\n\n        .. versionadded:: 0.14.0\n    thresh : float\n        Threshold to trigger EOG event.\n    %(decim)s\n\n        .. versionadded:: 0.21.0\n    %(verbose)s\n\n    Returns\n    -------\n    eog_epochs : instance of Epochs\n        Data epoched around EOG events.\n\n    See Also\n    --------\n    find_eog_events\n    compute_proj_eog\n\n    Notes\n    -----\n    Filtering is only applied to the EOG channel while finding events.\n    The resulting ``eog_epochs`` will have no filtering applied (i.e., have\n    the same filter properties as the input ``raw`` instance).\n    \"\"\"\n    events = find_eog_events(\n        raw,\n        ch_name=ch_name,\n        event_id=event_id,\n        l_freq=l_freq,\n        h_freq=h_freq,\n        reject_by_annotation=reject_by_annotation,\n        thresh=thresh,\n    )\n\n    # create epochs around EOG events\n    eog_epochs = Epochs(\n        raw,\n        events=events,\n        event_id=event_id,\n        tmin=tmin,\n        tmax=tmax,\n        proj=False,\n        reject=reject,\n        flat=flat,\n        picks=picks,\n        baseline=baseline,\n        preload=preload,\n        reject_by_annotation=reject_by_annotation,\n        decim=decim,\n    )\n    return eog_epochs", "metadata": {}}
{"_id": "mne_mne_preprocessing/infomax_.py_infomax_code", "title": "infomax", "text": "def infomax(\n    data,\n    weights=None,\n    l_rate=None,\n    block=None,\n    w_change=1e-12,\n    anneal_deg=60.0,\n    anneal_step=0.9,\n    extended=True,\n    n_subgauss=1,\n    kurt_size=6000,\n    ext_blocks=1,\n    max_iter=200,\n    random_state=None,\n    blowup=1e4,\n    blowup_fac=0.5,\n    n_small_angle=20,\n    use_bias=True,\n    verbose=None,\n    return_n_iter=False,\n):\n    \"\"\"Run (extended) Infomax ICA decomposition on raw data.\n\n    Parameters\n    ----------\n    data : np.ndarray, shape (n_samples, n_features)\n        The whitened data to unmix.\n    weights : np.ndarray, shape (n_features, n_features)\n        The initialized unmixing matrix.\n        Defaults to None, which means the identity matrix is used.\n    l_rate : float\n        This quantity indicates the relative size of the change in weights.\n        Defaults to ``0.01 / log(n_features ** 2)``.\n\n        .. note:: Smaller learning rates will slow down the ICA procedure.\n\n    block : int\n        The block size of randomly chosen data segments.\n        Defaults to floor(sqrt(n_times / 3.)).\n    w_change : float\n        The change at which to stop iteration. Defaults to 1e-12.\n    anneal_deg : float\n        The angle (in degrees) at which the learning rate will be reduced.\n        Defaults to 60.0.\n    anneal_step : float\n        The factor by which the learning rate will be reduced once\n        ``anneal_deg`` is exceeded: ``l_rate *= anneal_step.``\n        Defaults to 0.9.\n    extended : bool\n        Whether to use the extended Infomax algorithm or not.\n        Defaults to True.\n    n_subgauss : int\n        The number of subgaussian components. Only considered for extended\n        Infomax. Defaults to 1.\n    kurt_size : int\n        The window size for kurtosis estimation. Only considered for extended\n        Infomax. Defaults to 6000.\n    ext_blocks : int\n        Only considered for extended Infomax. If positive, denotes the number\n        of blocks after which to recompute the kurtosis, which is used to\n        estimate the signs of the sources. In this case, the number of\n        sub-gaussian sources is automatically determined.\n        If negative, the number of sub-gaussian sources to be used is fixed\n        and equal to n_subgauss. In this case, the kurtosis is not estimated.\n        Defaults to 1.\n    max_iter : int\n        The maximum number of iterations. Defaults to 200.\n    %(random_state)s\n    blowup : float\n        The maximum difference allowed between two successive estimations of\n        the unmixing matrix. Defaults to 10000.\n    blowup_fac : float\n        The factor by which the learning rate will be reduced if the difference\n        between two successive estimations of the unmixing matrix exceededs\n        ``blowup``: ``l_rate *= blowup_fac``. Defaults to 0.5.\n    n_small_angle : int | None\n        The maximum number of allowed steps in which the angle between two\n        successive estimations of the unmixing matrix is less than\n        ``anneal_deg``. If None, this parameter is not taken into account to\n        stop the iterations. Defaults to 20.\n    use_bias : bool\n        This quantity indicates if the bias should be computed.\n        Defaults to True.\n    %(verbose)s\n    return_n_iter : bool\n        Whether to return the number of iterations performed. Defaults to\n        False.\n\n    Returns\n    -------\n    unmixing_matrix : np.ndarray, shape (n_features, n_features)\n        The linear unmixing operator.\n    n_iter : int\n        The number of iterations. Only returned if ``return_max_iter=True``.\n\n    References\n    ----------\n    .. [1] A. J. Bell, T. J. Sejnowski. An information-maximization approach to\n           blind separation and blind deconvolution. Neural Computation, 7(6),\n           1129-1159, 1995.\n    .. [2] T. W. Lee, M. Girolami, T. J. Sejnowski. Independent component\n           analysis using an extended infomax algorithm for mixed subgaussian\n           and supergaussian sources. Neural Computation, 11(2), 417-441, 1999.\n    \"\"\"\n    rng = check_random_state(random_state)\n\n    # define some default parameters\n    max_weight = 1e8\n    restart_fac = 0.9\n    min_l_rate = 1e-10\n    degconst = 180.0 / np.pi\n\n    # for extended Infomax\n    extmomentum = 0.5\n    signsbias = 0.02\n    signcount_threshold = 25\n    signcount_step = 2\n\n    # check data shape\n    n_samples, n_features = data.shape\n    n_features_square = n_features**2\n\n    # check input parameters\n    # heuristic default - may need adjustment for large or tiny data sets\n    if l_rate is None:\n        l_rate = 0.01 / math.log(n_features**2.0)\n\n    if block is None:\n        block = int(math.floor(math.sqrt(n_samples / 3.0)))\n\n    logger.info(f\"Computing{' Extended ' if extended else ' '}Infomax ICA\")\n\n    # collect parameters\n    nblock = n_samples // block\n    lastt = (nblock - 1) * block + 1\n\n    # initialize training\n    if weights is None:\n        weights = np.identity(n_features, dtype=np.float64)\n    else:\n        weights = weights.T\n\n    BI = block * np.identity(n_features, dtype=np.float64)\n    bias = np.zeros((n_features, 1), dtype=np.float64)\n    onesrow = np.ones((1, block), dtype=np.float64)\n    startweights = weights.copy()\n    oldweights = startweights.copy()\n    step = 0\n    count_small_angle = 0\n    wts_blowup = False\n    blockno = 0\n    signcount = 0\n    initial_ext_blocks = ext_blocks  # save the initial value in case of reset\n\n    # for extended Infomax\n    if extended:\n        signs = np.ones(n_features)\n\n        for k in range(n_subgauss):\n            signs[k] = -1\n\n        kurt_size = min(kurt_size, n_samples)\n        old_kurt = np.zeros(n_features, dtype=np.float64)\n        oldsigns = np.zeros(n_features)\n\n    # trainings loop\n    olddelta, oldchange = 1.0, 0.0\n    while step < max_iter:\n        # shuffle data at each step\n        permute = random_permutation(n_samples, rng)\n\n        # ICA training block\n        # loop across block samples\n        for t in range(0, lastt, block):\n            u = np.dot(data[permute[t : t + block], :], weights)\n            u += np.dot(bias, onesrow).T\n\n            if extended:\n                # extended ICA update\n                y = np.tanh(u)\n                weights += l_rate * np.dot(\n                    weights, BI - signs[None, :] * np.dot(u.T, y) - np.dot(u.T, u)\n                )\n                if use_bias:\n                    bias += l_rate * np.reshape(\n                        np.sum(y, axis=0, dtype=np.float64) * -2.0, (n_features, 1)\n                    )\n\n            else:\n                # logistic ICA weights update\n                y = expit(u)\n                weights += l_rate * np.dot(weights, BI + np.dot(u.T, (1.0 - 2.0 * y)))\n\n                if use_bias:\n                    bias += l_rate * np.reshape(\n                        np.sum((1.0 - 2.0 * y), axis=0, dtype=np.float64),\n                        (n_features, 1),\n                    )\n\n            # check change limit\n            max_weight_val = np.max(np.abs(weights))\n            if max_weight_val > max_weight:\n                wts_blowup = True\n\n            blockno += 1\n            if wts_blowup:\n                break\n\n            # ICA kurtosis estimation\n            if extended:\n                if ext_blocks > 0 and blockno % ext_blocks == 0:\n                    if kurt_size < n_samples:\n                        rp = np.floor(rng.uniform(0, 1, kurt_size) * (n_samples - 1))\n                        tpartact = np.dot(data[rp.astype(int), :], weights).T\n                    else:\n                        tpartact = np.dot(data, weights).T\n\n                    # estimate kurtosis\n                    kurt = kurtosis(tpartact, axis=1, fisher=True)\n\n                    if extmomentum != 0:\n                        kurt = extmomentum * old_kurt + (1.0 - extmomentum) * kurt\n                        old_kurt = kurt\n\n                    # estimate weighted signs\n                    signs = np.sign(kurt + signsbias)\n\n                    ndiff = (signs - oldsigns != 0).sum()\n                    if ndiff == 0:\n                        signcount += 1\n                    else:\n                        signcount = 0\n                    oldsigns = signs\n\n                    if signcount >= signcount_threshold:\n                        ext_blocks = np.fix(ext_blocks * signcount_step)\n                        signcount = 0\n\n        # here we continue after the for loop over the ICA training blocks\n        # if weights in bounds:\n        if not wts_blowup:\n            oldwtchange = weights - oldweights\n            step += 1\n            angledelta = 0.0\n            delta = oldwtchange.reshape(1, n_features_square)\n            change = np.sum(delta * delta, dtype=np.float64)\n            if step > 2:\n                angledelta = math.acos(\n                    np.sum(delta * olddelta) / math.sqrt(change * oldchange)\n                )\n                angledelta *= degconst\n\n            if verbose:\n                logger.info(\n                    \"step %d - lrate %5f, wchange %8.8f, angledelta %4.1f deg\",\n                    step,\n                    l_rate,\n                    change,\n                    angledelta,\n                )\n\n            # anneal learning rate\n            oldweights = weights.copy()\n            if angledelta > anneal_deg:\n                l_rate *= anneal_step  # anneal learning rate\n                # accumulate angledelta until anneal_deg reaches l_rate\n                olddelta = delta\n                oldchange = change\n                count_small_angle = 0  # reset count when angledelta is large\n            else:\n                if step == 1:  # on first step only\n                    olddelta = delta  # initialize\n                    oldchange = change\n\n                if n_small_angle is not None:\n                    count_small_angle += 1\n                    if count_small_angle > n_small_angle:\n                        max_iter = step\n\n            # apply stopping rule\n            if step > 2 and change < w_change:\n                step = max_iter\n            elif change > blowup:\n                l_rate *= blowup_fac\n\n        # restart if weights blow up (for lowering l_rate)\n        else:\n            step = 0  # start again\n            wts_blowup = 0  # re-initialize variables\n            blockno = 1\n            l_rate *= restart_fac  # with lower learning rate\n            weights = startweights.copy()\n            oldweights = startweights.copy()\n            olddelta = np.zeros((1, n_features_square), dtype=np.float64)\n            bias = np.zeros((n_features, 1), dtype=np.float64)\n\n            ext_blocks = initial_ext_blocks\n\n            # for extended Infomax\n            if extended:\n                signs = np.ones(n_features)\n                for k in range(n_subgauss):\n                    signs[k] = -1\n                oldsigns = np.zeros(n_features)\n\n            if l_rate > min_l_rate:\n                if verbose:\n                    logger.info(\n                        f\"... lowering learning rate to {l_rate:g}\\n... re-starting...\"\n                    )\n            else:\n                raise ValueError(\n                    \"Error in Infomax ICA: unmixing_matrix matrix\"\n                    \"might not be invertible!\"\n                )\n\n    # prepare return values\n    if return_n_iter:\n        return weights.T, step\n    else:\n        return weights.T", "metadata": {}}
{"_id": "mne_mne_preprocessing/_pca_obs.py_apply_pca_obs_code", "title": "apply_pca_obs", "text": "def apply_pca_obs(\n    raw: Raw,\n    picks: list[str],\n    *,\n    qrs_times: np.ndarray,\n    n_components: int = 4,\n    n_jobs: int | None = None,\n    copy: bool = True,\n    verbose: bool | str | int | None = None,\n) -> Raw:\n    \"\"\"\n    Apply the PCA-OBS algorithm to picks of a Raw object.\n\n    Uses the optimal basis set (OBS) algorithm from :footcite:`NiazyEtAl2005`.\n\n    Parameters\n    ----------\n    raw : instance of Raw\n        The raw data to process.\n    %(picks_all_data_noref)s\n    qrs_times : ndarray, shape (n_peaks,)\n        Array of times in the Raw data of detected R-peaks in ECG channel.\n    n_components : int\n        Number of PCA components to use to form the OBS (default 4).\n    %(n_jobs)s\n    copy : bool\n        If False, modify the Raw instance in-place.\n        If True (default), copy the raw instance before processing.\n    %(verbose)s\n\n    Returns\n    -------\n    raw : instance of Raw\n        The modified raw instance.\n\n    Notes\n    -----\n    .. versionadded:: 1.10\n\n    References\n    ----------\n    .. footbibliography::\n    \"\"\"\n    # sanity checks\n    _validate_type(qrs_times, np.ndarray, \"qrs_times\")\n    if len(qrs_times.shape) > 1:\n        raise ValueError(\"qrs_times must be a 1d array\")\n    if qrs_times.dtype not in [int, float]:\n        raise ValueError(\"qrs_times must be an array of either integers or floats\")\n    if np.any(qrs_times < 0):\n        raise ValueError(\"qrs_times must be strictly positive\")\n    if np.any(qrs_times >= raw.times[-1]):\n        logger.warning(\"some out of bound qrs_times will be ignored..\")\n\n    if copy:\n        raw = raw.copy()\n\n    raw.apply_function(\n        _pca_obs,\n        picks=picks,\n        n_jobs=n_jobs,\n        # args sent to PCA_OBS, convert times to indices\n        qrs=raw.time_as_index(qrs_times),\n        n_components=n_components,\n    )\n\n    return raw", "metadata": {}}
{"_id": "mne_mne_preprocessing/ctps_.py_ctps_code", "title": "ctps", "text": "def ctps(data, is_raw=True):\n    \"\"\"Compute cross-trial-phase-statistics [1].\n\n    Note. It is assumed that the sources are already\n    appropriately filtered\n\n    Parameters\n    ----------\n    data: ndarray, shape (n_epochs, n_channels, n_times)\n        Any kind of data of dimensions trials, traces, features.\n    is_raw : bool\n        If True it is assumed that data haven't been transformed to Hilbert\n        space and phase angles haven't been normalized. Defaults to True.\n\n    Returns\n    -------\n    ks_dynamics : ndarray, shape (n_sources, n_times)\n        The kuiper statistics.\n    pk_dynamics : ndarray, shape (n_sources, n_times)\n        The normalized kuiper index for ICA sources and\n        time slices.\n    phase_angles : ndarray, shape (n_epochs, n_sources, n_times) | None\n        The phase values for epochs, sources and time slices. If ``is_raw``\n        is False, None is returned.\n\n    References\n    ----------\n    [1] Dammers, J., Schiek, M., Boers, F., Silex, C., Zvyagintsev,\n        M., Pietrzyk, U., Mathiak, K., 2008. Integration of amplitude\n        and phase statistics for complete artifact removal in independent\n        components of neuromagnetic recordings. Biomedical\n        Engineering, IEEE Transactions on 55 (10), 2353-2362.\n    \"\"\"\n    if not data.ndim == 3:\n        raise ValueError(f\"Data must have 3 dimensions, not {data.ndim}.\")\n\n    if is_raw:\n        phase_angles = _compute_normalized_phase(data)\n    else:\n        phase_angles = data  # phase angles can be computed externally\n\n    # initialize array for results\n    ks_dynamics = np.zeros_like(phase_angles[0])\n    pk_dynamics = np.zeros_like(phase_angles[0])\n\n    # calculate Kuiper's statistic for each source\n    for ii, source in enumerate(np.transpose(phase_angles, [1, 0, 2])):\n        ks, pk = kuiper(source)\n        pk_dynamics[ii, :] = pk\n        ks_dynamics[ii, :] = ks\n\n    return ks_dynamics, pk_dynamics, phase_angles if is_raw else None", "metadata": {}}
{"_id": "mne_mne_preprocessing/ctps_.py_kuiper_code", "title": "kuiper", "text": "def kuiper(data, dtype=np.float64):  # noqa: D401\n    \"\"\"Kuiper's test of uniform distribution.\n\n    Parameters\n    ----------\n    data : ndarray, shape (n_sources,) | (n_sources, n_times)\n           Empirical distribution.\n    dtype : str | obj\n        The data type to be used.\n\n    Returns\n    -------\n    ks : ndarray\n        Kuiper's statistic.\n    pk : ndarray\n        Normalized probability of Kuiper's statistic [0, 1].\n    \"\"\"\n    # if data not numpy array, implicitly convert and make to use copied data\n    # ! sort data array along first axis !\n    data = np.sort(data, axis=0).astype(dtype)\n    shape = data.shape\n    n_dim = len(shape)\n    n_trials = shape[0]\n\n    # create uniform cdf\n    j1 = (np.arange(n_trials, dtype=dtype) + 1.0) / float(n_trials)\n    j2 = np.arange(n_trials, dtype=dtype) / float(n_trials)\n    if n_dim > 1:  # single phase vector (n_trials)\n        j1 = j1[:, np.newaxis]\n        j2 = j2[:, np.newaxis]\n    d1 = (j1 - data).max(axis=0)\n    d2 = (data - j2).max(axis=0)\n    n_eff = n_trials\n\n    d = d1 + d2  # Kuiper's statistic [n_time_slices]\n\n    return d, _prob_kuiper(d, n_eff, dtype=dtype)", "metadata": {}}
{"_id": "mne_mne_preprocessing/_peak_finder.py_peak_finder_code", "title": "peak_finder", "text": "def peak_finder(x0, thresh=None, extrema=1, verbose=None):\n    \"\"\"Noise-tolerant fast peak-finding algorithm.\n\n    Parameters\n    ----------\n    x0 : 1d array\n        A real vector from the maxima will be found (required).\n    thresh : float | None\n        The amount above surrounding data for a peak to be\n        identified. Larger values mean the algorithm is more selective in\n        finding peaks. If ``None``, use the default of\n        ``(max(x0) - min(x0)) / 4``.\n    extrema : {-1, 1}\n        1 if maxima are desired, -1 if minima are desired\n        (default = maxima, 1).\n    %(verbose)s\n\n    Returns\n    -------\n    peak_loc : array\n        The indices of the identified peaks in x0.\n    peak_mag : array\n        The magnitude of the identified peaks.\n\n    Notes\n    -----\n    If repeated values are found the first is identified as the peak.\n    Conversion from initial Matlab code from:\n    Nathanael C. Yoder (ncyoder@purdue.edu)\n\n    Examples\n    --------\n    >>> import numpy as np\n    >>> from mne.preprocessing import peak_finder\n    >>> t = np.arange(0, 3, 0.01)\n    >>> x = np.sin(np.pi*t) - np.sin(0.5*np.pi*t)\n    >>> peak_locs, peak_mags = peak_finder(x) # doctest: +SKIP\n    >>> peak_locs # doctest: +SKIP\n    array([36, 260]) # doctest: +SKIP\n    >>> peak_mags # doctest: +SKIP\n    array([0.36900026, 1.76007351]) # doctest: +SKIP\n    \"\"\"\n    x0 = np.asanyarray(x0)\n    s = x0.size\n\n    if x0.ndim >= 2 or s == 0:\n        raise ValueError(\"The input data must be a non empty 1D vector\")\n\n    if thresh is None:\n        thresh = (np.max(x0) - np.min(x0)) / 4\n        logger.debug(f\"Peak finder automatic threshold: {thresh:0.2g}\")\n\n    assert extrema in [-1, 1]\n\n    if extrema == -1:\n        x0 = extrema * x0  # Make it so we are finding maxima regardless\n\n    dx0 = np.diff(x0)  # Find derivative\n    # This is so we find the first of repeated values\n    dx0[dx0 == 0] = -np.finfo(float).eps\n    # Find where the derivative changes sign\n    ind = np.where(dx0[:-1:] * dx0[1::] < 0)[0] + 1\n\n    # Include endpoints in potential peaks and valleys\n    x = np.concatenate((x0[:1], x0[ind], x0[-1:]))\n    ind = np.concatenate(([0], ind, [s - 1]))\n    del x0\n\n    #  x only has the peaks, valleys, and endpoints\n    length = x.size\n    min_mag = np.min(x)\n\n    if length > 2:  # Function with peaks and valleys\n        # Set initial parameters for loop\n        temp_mag = min_mag\n        found_peak = False\n        left_min = min_mag\n\n        # Deal with first point a little differently since tacked it on\n        # Calculate the sign of the derivative since we took the first point\n        # on it does not necessarily alternate like the rest.\n        signDx = np.sign(np.diff(x[:3]))\n        if signDx[0] <= 0:  # The first point is larger or equal to the second\n            ii = -1\n            if signDx[0] == signDx[1]:  # Want alternating signs\n                x = np.concatenate((x[:1], x[2:]))\n                ind = np.concatenate((ind[:1], ind[2:]))\n                length -= 1\n\n        else:  # First point is smaller than the second\n            ii = 0\n            if signDx[0] == signDx[1]:  # Want alternating signs\n                x = x[1:]\n                ind = ind[1:]\n                length -= 1\n\n        # Preallocate max number of maxima\n        maxPeaks = int(np.ceil(length / 2.0))\n        peak_loc = np.zeros(maxPeaks, dtype=np.int64)\n        peak_mag = np.zeros(maxPeaks)\n        c_ind = 0\n        # Loop through extrema which should be peaks and then valleys\n        while ii < (length - 1):\n            ii += 1  # This is a peak\n            # Reset peak finding if we had a peak and the next peak is bigger\n            # than the last or the left min was small enough to reset.\n            if found_peak and (\n                (x[ii] > peak_mag[-1]) or (left_min < peak_mag[-1] - thresh)\n            ):\n                temp_mag = min_mag\n                found_peak = False\n\n            # Make sure we don't iterate past the length of our vector\n            if ii == length - 1:\n                break  # We assign the last point differently out of the loop\n\n            # Found new peak that was lager than temp mag and threshold larger\n            # than the minimum to its left.\n            if (x[ii] > temp_mag) and (x[ii] > left_min + thresh):\n                temp_loc = ii\n                temp_mag = x[ii]\n\n            ii += 1  # Move onto the valley\n            # Come down at least thresh from peak\n            if not found_peak and (temp_mag > (thresh + x[ii])):\n                found_peak = True  # We have found a peak\n                left_min = x[ii]\n                peak_loc[c_ind] = temp_loc  # Add peak to index\n                peak_mag[c_ind] = temp_mag\n                c_ind += 1\n            elif x[ii] < left_min:  # New left minima\n                left_min = x[ii]\n\n        # Check end point\n        if (x[-1] > temp_mag) and (x[-1] > (left_min + thresh)):\n            peak_loc[c_ind] = length - 1\n            peak_mag[c_ind] = x[-1]\n            c_ind += 1\n        elif not found_peak and temp_mag > min_mag:\n            # Check if we still need to add the last point\n            peak_loc[c_ind] = temp_loc\n            peak_mag[c_ind] = temp_mag\n            c_ind += 1\n\n        # Create output\n        peak_inds = ind[peak_loc[:c_ind]]\n        peak_mags = peak_mag[:c_ind]\n    else:  # This is a monotone function where an endpoint is the only peak\n        x_ind = np.argmax(x)\n        peak_mags = x[x_ind]\n        if peak_mags > (min_mag + thresh):\n            peak_inds = ind[x_ind]\n        else:\n            peak_mags = []\n            peak_inds = []\n\n    # Change sign of data if was finding minima\n    if extrema < 0:\n        peak_mags *= -1.0\n\n    # ensure output type array\n    if not isinstance(peak_inds, np.ndarray):\n        peak_inds = np.atleast_1d(peak_inds).astype(\"int64\")\n\n    if not isinstance(peak_mags, np.ndarray):\n        peak_mags = np.atleast_1d(peak_mags).astype(\"float64\")\n\n    # Plot if no output desired\n    if len(peak_inds) == 0:\n        logger.info(\"No significant peaks found\")\n    else:\n        logger.info(f\"Found {len(peak_inds)} significant peak{_pl(peak_inds)}\")\n\n    return peak_inds, peak_mags", "metadata": {}}
{"_id": "mne_mne_preprocessing/ica.py_get_score_funcs_code", "title": "get_score_funcs", "text": "def get_score_funcs():\n    \"\"\"Get the score functions.\n\n    Returns\n    -------\n    score_funcs : dict\n        The score functions.\n    \"\"\"\n    score_funcs = Bunch()\n    xy_arg_dist_funcs = [\n        (n, f)\n        for n, f in vars(distance).items()\n        if isfunction(f) and not n.startswith(\"_\") and n not in _BLOCKLIST\n    ]\n    xy_arg_stats_funcs = [\n        (n, f)\n        for n, f in vars(stats).items()\n        if isfunction(f) and not n.startswith(\"_\") and n not in _BLOCKLIST\n    ]\n    score_funcs.update(\n        {\n            n: _make_xy_sfunc(f)\n            for n, f in xy_arg_dist_funcs\n            if signature(f).parameters == [\"u\", \"v\"]\n        }\n    )\n    # In SciPy 1.9+, pearsonr has (x, y, *, alternative='two-sided'), so we\n    # should just look at the positional_only and positional_or_keyword entries\n    for n, f in xy_arg_stats_funcs:\n        params = [\n            name\n            for name, param in signature(f).parameters.items()\n            if param.kind\n            in (Parameter.POSITIONAL_ONLY, Parameter.POSITIONAL_OR_KEYWORD)\n        ]\n        if params == [\"x\", \"y\"]:\n            score_funcs.update({n: _make_xy_sfunc(f, ndim_output=True)})\n    assert \"pearsonr\" in score_funcs\n    return score_funcs", "metadata": {}}
{"_id": "mne_mne_preprocessing/ica.py_ica_find_ecg_events_code", "title": "ica_find_ecg_events", "text": "def ica_find_ecg_events(\n    raw,\n    ecg_source,\n    event_id=999,\n    tstart=0.0,\n    l_freq=5,\n    h_freq=35,\n    qrs_threshold=\"auto\",\n    verbose=None,\n):\n    \"\"\"Find ECG peaks from one selected ICA source.\n\n    Parameters\n    ----------\n    raw : instance of Raw\n        Raw object to draw sources from.\n    ecg_source : ndarray\n        ICA source resembling ECG to find peaks from.\n    event_id : int\n        The index to assign to found events.\n    tstart : float\n        Start detection after tstart seconds. Useful when beginning\n        of run is noisy.\n    l_freq : float\n        Low pass frequency.\n    h_freq : float\n        High pass frequency.\n    qrs_threshold : float | str\n        Between 0 and 1. qrs detection threshold. Can also be \"auto\" to\n        automatically choose the threshold that generates a reasonable\n        number of heartbeats (40-160 beats / min).\n    %(verbose)s\n\n    Returns\n    -------\n    ecg_events : array\n        Events.\n    ch_ECG : string\n        Name of channel used.\n    average_pulse : float.\n        Estimated average pulse.\n    \"\"\"\n    logger.info(\"Using ICA source to identify heart beats\")\n\n    # detecting QRS and generating event file\n    ecg_events = qrs_detector(\n        raw.info[\"sfreq\"],\n        ecg_source.ravel(),\n        tstart=tstart,\n        thresh_value=qrs_threshold,\n        l_freq=l_freq,\n        h_freq=h_freq,\n    )\n\n    n_events = len(ecg_events)\n\n    ecg_events = np.c_[\n        ecg_events + raw.first_samp, np.zeros(n_events), event_id * np.ones(n_events)\n    ]\n\n    return ecg_events", "metadata": {}}
{"_id": "mne_mne_preprocessing/ica.py_ica_find_eog_events_code", "title": "ica_find_eog_events", "text": "def ica_find_eog_events(\n    raw, eog_source=None, event_id=998, l_freq=1, h_freq=10, verbose=None\n):\n    \"\"\"Locate EOG artifacts from one selected ICA source.\n\n    Parameters\n    ----------\n    raw : instance of Raw\n        The raw data.\n    eog_source : ndarray\n        ICA source resembling EOG to find peaks from.\n    event_id : int\n        The index to assign to found events.\n    l_freq : float\n        Low cut-off frequency in Hz.\n    h_freq : float\n        High cut-off frequency in Hz.\n    %(verbose)s\n\n    Returns\n    -------\n    eog_events : array\n        Events.\n    \"\"\"\n    eog_events = _find_eog_events(\n        eog_source[np.newaxis],\n        ch_names=None,\n        event_id=event_id,\n        l_freq=l_freq,\n        h_freq=h_freq,\n        sampling_rate=raw.info[\"sfreq\"],\n        first_samp=raw.first_samp,\n    )\n    return eog_events", "metadata": {}}
{"_id": "mne_mne_preprocessing/ica.py_read_ica_code", "title": "read_ica", "text": "def read_ica(fname, verbose=None):\n    \"\"\"Restore ICA solution from fif file.\n\n    Parameters\n    ----------\n    fname : path-like\n        Absolute path to fif file containing ICA matrices.\n        The file name should end with -ica.fif or -ica.fif.gz.\n    %(verbose)s\n\n    Returns\n    -------\n    ica : instance of ICA\n        The ICA estimator.\n    \"\"\"\n    check_fname(fname, \"ICA\", (\"-ica.fif\", \"-ica.fif.gz\", \"_ica.fif\", \"_ica.fif.gz\"))\n    fname = _check_fname(fname, overwrite=\"read\", must_exist=True)\n\n    logger.info(f\"Reading {fname} ...\")\n    fid, tree, _ = fiff_open(fname)\n\n    try:\n        # we used to store bads that weren't part of the info...\n        info, _ = read_meas_info(fid, tree, clean_bads=True)\n    except ValueError:\n        logger.info(\n            \"Could not find the measurement info. \\n\"\n            \"Functionality requiring the info won't be\"\n            \" available.\"\n        )\n        info = None\n\n    ica_data = dir_tree_find(tree, FIFF.FIFFB_MNE_ICA)\n    if len(ica_data) == 0:\n        ica_data = dir_tree_find(tree, 123)  # Constant 123 Used before v 0.11\n        if len(ica_data) == 0:\n            fid.close()\n            raise ValueError(\"Could not find ICA data\")\n\n    my_ica_data = ica_data[0]\n    ica_reject = None\n    for d in my_ica_data[\"directory\"]:\n        kind = d.kind\n        pos = d.pos\n        if kind == FIFF.FIFF_MNE_ICA_INTERFACE_PARAMS:\n            tag = read_tag(fid, pos)\n            ica_init = tag.data\n        elif kind == FIFF.FIFF_MNE_ROW_NAMES:\n            tag = read_tag(fid, pos)\n            ch_names = tag.data\n        elif kind == FIFF.FIFF_MNE_ICA_WHITENER:\n            tag = read_tag(fid, pos)\n            pre_whitener = tag.data\n        elif kind == FIFF.FIFF_MNE_ICA_PCA_COMPONENTS:\n            tag = read_tag(fid, pos)\n            pca_components = tag.data\n        elif kind == FIFF.FIFF_MNE_ICA_PCA_EXPLAINED_VAR:\n            tag = read_tag(fid, pos)\n            pca_explained_variance = tag.data\n        elif kind == FIFF.FIFF_MNE_ICA_PCA_MEAN:\n            tag = read_tag(fid, pos)\n            pca_mean = tag.data\n        elif kind == FIFF.FIFF_MNE_ICA_MATRIX:\n            tag = read_tag(fid, pos)\n            unmixing_matrix = tag.data\n        elif kind == FIFF.FIFF_MNE_ICA_BADS:\n            tag = read_tag(fid, pos)\n            exclude = tag.data\n        elif kind == FIFF.FIFF_MNE_ICA_MISC_PARAMS:\n            tag = read_tag(fid, pos)\n            ica_misc = tag.data\n        elif kind == FIFF.FIFF_MNE_EPOCHS_REJECT_FLAT:\n            tag = read_tag(fid, pos)\n            ica_reject = json.loads(tag.data)[\"reject\"]\n\n    fid.close()\n\n    ica_init, ica_misc = (_deserialize(k) for k in (ica_init, ica_misc))\n    n_pca_components = ica_init.pop(\"n_pca_components\")\n    current_fit = ica_init.pop(\"current_fit\")\n    max_pca_components = ica_init.pop(\"max_pca_components\")\n    method = ica_misc.get(\"method\", \"fastica\")\n    if method in _KNOWN_ICA_METHODS:\n        ica_init[\"method\"] = method\n    if ica_init[\"noise_cov\"] == Covariance.__name__:\n        logger.info(\"Reading whitener drawn from noise covariance ...\")\n\n    logger.info(\"Now restoring ICA solution ...\")\n\n    # make sure dtypes are np.float64 to satisfy fast_dot\n    def f(x):\n        return x.astype(np.float64)\n\n    ica_init = {\n        k: v for k, v in ica_init.items() if k in signature(ICA.__init__).parameters\n    }\n    ica = ICA(**ica_init)\n    ica.current_fit = current_fit\n    ica.ch_names = ch_names.split(\":\")\n    if n_pca_components is not None and not isinstance(n_pca_components, int_like):\n        n_pca_components = np.float64(n_pca_components)\n    ica.n_pca_components = n_pca_components\n    ica.pre_whitener_ = f(pre_whitener)\n    ica.pca_mean_ = f(pca_mean)\n    ica.pca_components_ = f(pca_components)\n    ica.n_components_ = unmixing_matrix.shape[0]\n    ica._max_pca_components = max_pca_components\n    ica._update_ica_names()\n    ica.pca_explained_variance_ = f(pca_explained_variance)\n    ica.unmixing_matrix_ = f(unmixing_matrix)\n    ica._update_mixing_matrix()\n    ica.exclude = [] if exclude is None else list(exclude)\n    ica.info = info\n    if \"n_samples_\" in ica_misc:\n        ica.n_samples_ = ica_misc[\"n_samples_\"]\n    if \"labels_\" in ica_misc:\n        labels_ = ica_misc[\"labels_\"]\n        if labels_ is not None:\n            ica.labels_ = labels_\n    if \"method\" in ica_misc:\n        ica.method = ica_misc[\"method\"]\n    if \"n_iter_\" in ica_misc:\n        ica.n_iter_ = ica_misc[\"n_iter_\"]\n    if \"fit_params\" in ica_misc:\n        ica.fit_params = ica_misc[\"fit_params\"]\n    ica.reject_ = ica_reject\n\n    logger.info(\"Ready.\")\n\n    return ica", "metadata": {}}
{"_id": "mne_mne_preprocessing/ica.py_corrmap_code", "title": "corrmap", "text": "def corrmap(\n    icas,\n    template,\n    threshold=\"auto\",\n    label=None,\n    ch_type=\"eeg\",\n    *,\n    sensors=True,\n    show_names=False,\n    contours=6,\n    outlines=\"head\",\n    sphere=None,\n    image_interp=_INTERPOLATION_DEFAULT,\n    extrapolate=_EXTRAPOLATE_DEFAULT,\n    border=_BORDER_DEFAULT,\n    cmap=None,\n    plot=True,\n    show=True,\n    verbose=None,\n):\n    \"\"\"Find similar Independent Components across subjects by map similarity.\n\n    Corrmap :footcite:p:`CamposViolaEtAl2009` identifies the best group\n    match to a supplied template. Typically, feed it a list of fitted ICAs and\n    a template IC, for example, the blink for the first subject, to identify\n    specific ICs across subjects.\n\n    The specific procedure consists of two iterations. In a first step, the\n    maps best correlating with the template are identified. In the next step,\n    the analysis is repeated with the mean of the maps identified in the first\n    stage.\n\n    Run with ``plot`` and ``show`` set to ``True`` and ``label=False`` to find\n    good parameters. Then, run with labelling enabled to apply the\n    labelling in the IC objects. (Running with both ``plot`` and ``labels``\n    off does nothing.)\n\n    Outputs a list of fitted ICAs with the indices of the marked ICs in a\n    specified field.\n\n    The original Corrmap website: www.debener.de/corrmap/corrmapplugin1.html\n\n    Parameters\n    ----------\n    icas : list of mne.preprocessing.ICA\n        A list of fitted ICA objects.\n    template : tuple | np.ndarray, shape (n_components,)\n        Either a tuple with two elements (int, int) representing the list\n        indices of the set from which the template should be chosen, and the\n        template. E.g., if template=(1, 0), the first IC of the 2nd ICA object\n        is used.\n        Or a numpy array whose size corresponds to each IC map from the\n        supplied maps, in which case this map is chosen as the template.\n    threshold : \"auto\" | list of float | float\n        Correlation threshold for identifying ICs\n        If \"auto\", search for the best map by trying all correlations between\n        0.6 and 0.95. In the original proposal, lower values are considered,\n        but this is not yet implemented.\n        If list of floats, search for the best map in the specified range of\n        correlation strengths. As correlation values, must be between 0 and 1\n        If float > 0, select ICs correlating better than this.\n        If float > 1, use z-scoring to identify ICs within subjects (not in\n        original Corrmap)\n        Defaults to \"auto\".\n    label : None | str\n        If not None, categorised ICs are stored in a dictionary ``labels_``\n        under the given name. Preexisting entries will be appended to\n        (excluding repeats), not overwritten. If None, a dry run is performed\n        and the supplied ICs are not changed.\n    ch_type : 'mag' | 'grad' | 'planar1' | 'planar2' | 'eeg'\n        The channel type to plot. Defaults to 'eeg'.\n    %(sensors_topomap)s\n    %(show_names_topomap)s\n    %(contours_topomap)s\n    %(outlines_topomap)s\n    %(sphere_topomap_auto)s\n    %(image_interp_topomap)s\n\n        .. versionadded:: 1.2\n    %(extrapolate_topomap)s\n\n        .. versionadded:: 1.2\n    %(border_topomap)s\n\n        .. versionadded:: 1.2\n    %(cmap_topomap_simple)s\n    plot : bool\n        Should constructed template and selected maps be plotted? Defaults\n        to True.\n    %(show)s\n    %(verbose)s\n\n    Returns\n    -------\n    template_fig : Figure\n        Figure showing the template.\n    labelled_ics : Figure\n        Figure showing the labelled ICs in all ICA decompositions.\n\n    References\n    ----------\n    .. footbibliography::\n    \"\"\"\n    if not isinstance(plot, bool):\n        raise ValueError(\"`plot` must be of type `bool`\")\n\n    same_chans = _check_all_same_channel_names(icas)\n    if same_chans is False:\n        raise ValueError(\n            \"Not all ICA instances have the same channel names. \"\n            \"Corrmap requires all instances to have the same \"\n            \"montage. Consider interpolating bad channels before \"\n            \"running ICA.\"\n        )\n\n    threshold_extra = \"\"\n    if threshold == \"auto\":\n        threshold = np.arange(60, 95, dtype=np.float64) / 100.0\n        threshold_extra = ' (\"auto\")'\n\n    all_maps = [ica.get_components().T for ica in icas]\n\n    # check if template is an index to one IC in one ICA object, or an array\n    if len(template) == 2:\n        target = all_maps[template[0]][template[1]]\n        is_subject = True\n    elif template.ndim == 1 and len(template) == all_maps[0].shape[1]:\n        target = template\n        is_subject = False\n    else:\n        raise ValueError(\n            \"`template` must be a length-2 tuple or an array the size of the ICA maps.\"\n        )\n\n    template_fig, labelled_ics = None, None\n    if plot is True:\n        if is_subject:  # plotting from an ICA object\n            ttl = f\"Template from subj. {template[0]}\"\n            template_fig = icas[template[0]].plot_components(\n                picks=template[1],\n                ch_type=ch_type,\n                title=ttl,\n                outlines=outlines,\n                cmap=cmap,\n                contours=contours,\n                show=show,\n                sphere=sphere,\n            )\n        else:  # plotting an array\n            template_fig = _plot_corrmap(\n                [template],\n                [0],\n                [0],\n                ch_type,\n                icas[0].copy(),\n                \"Template\",\n                outlines=outlines,\n                cmap=cmap,\n                contours=contours,\n                image_interp=image_interp,\n                extrapolate=extrapolate,\n                border=border,\n                show=show,\n                template=True,\n                sphere=sphere,\n            )\n        template_fig.canvas.draw()\n\n    # first run: use user-selected map\n    threshold = np.atleast_1d(np.array(threshold, float)).ravel()\n    threshold_err = (\n        \"No component detected using when z-scoring \"\n        f\"threshold{threshold_extra} {threshold}, consider using a more lenient \"\n        \"threshold\"\n    )\n    if len(all_maps) == 0:\n        raise RuntimeError(threshold_err)\n    paths = [_find_max_corrs(all_maps, target, t) for t in threshold]\n    # find iteration with highest avg correlation with target\n    new_target, _, _, _ = paths[np.argmax([path[2] for path in paths])]\n\n    # second run: use output from first run\n    if len(all_maps) == 0 or len(new_target) == 0:\n        raise RuntimeError(threshold_err)\n    paths = [_find_max_corrs(all_maps, new_target, t) for t in threshold]\n    del new_target\n    # find iteration with highest avg correlation with target\n    _, median_corr, _, max_corrs = paths[np.argmax([path[1] for path in paths])]\n\n    allmaps, indices, subjs, nones = (list() for _ in range(4))\n    logger.info(f\"Median correlation with constructed map: {median_corr:0.3f}\")\n    del median_corr\n    if plot is True:\n        logger.info(\"Displaying selected ICs per subject.\")\n\n    for ii, (ica, max_corr) in enumerate(zip(icas, max_corrs)):\n        if len(max_corr) > 0:\n            if isinstance(max_corr[0], np.ndarray):\n                max_corr = max_corr[0]\n            if label is not None:\n                ica.labels_[label] = list(\n                    set(list(max_corr) + ica.labels_.get(label, list()))\n                )\n            if plot is True:\n                allmaps.extend(ica.get_components()[:, max_corr].T)\n                subjs.extend([ii] * len(max_corr))\n                indices.extend(max_corr)\n        else:\n            if (label is not None) and (label not in ica.labels_):\n                ica.labels_[label] = list()\n            nones.append(ii)\n\n    if len(nones) == 0:\n        logger.info(\"At least 1 IC detected for each subject.\")\n    else:\n        logger.info(\n            f\"No maps selected for subject{_pl(nones)} {nones}, \"\n            \"consider a more liberal threshold.\"\n        )\n\n    if plot is True:\n        labelled_ics = _plot_corrmap(\n            allmaps,\n            subjs,\n            indices,\n            ch_type,\n            ica,\n            label,\n            outlines=outlines,\n            cmap=cmap,\n            sensors=sensors,\n            contours=contours,\n            sphere=sphere,\n            image_interp=image_interp,\n            extrapolate=extrapolate,\n            border=border,\n            show=show,\n            show_names=show_names,\n        )\n        return template_fig, labelled_ics\n    else:\n        return None", "metadata": {}}
{"_id": "mne_mne_preprocessing/ica.py_read_ica_eeglab_code", "title": "read_ica_eeglab", "text": "def read_ica_eeglab(fname, *, montage_units=\"auto\", verbose=None):\n    \"\"\"Load ICA information saved in an EEGLAB .set file.\n\n    Parameters\n    ----------\n    fname : path-like\n        Complete path to a ``.set`` EEGLAB file that contains an ICA object.\n    %(montage_units)s\n\n        .. versionadded:: 1.6\n    %(verbose)s\n\n    Returns\n    -------\n    ica : instance of ICA\n        An ICA object based on the information contained in the input file.\n    \"\"\"\n    eeg = _check_load_mat(fname, None)\n    info, eeg_montage, _ = _get_info(eeg, eog=(), montage_units=montage_units)\n    info.set_montage(eeg_montage)\n    pick_info(info, np.round(eeg[\"icachansind\"]).astype(int) - 1, copy=False)\n\n    rank = eeg.icasphere.shape[0]\n    n_components = eeg.icaweights.shape[0]\n\n    ica = ICA(method=\"imported_eeglab\", n_components=n_components)\n\n    ica.current_fit = \"eeglab\"\n    ica.ch_names = info[\"ch_names\"]\n    ica.n_pca_components = None\n    ica.n_components_ = n_components\n\n    n_ch = len(ica.ch_names)\n    assert len(eeg.icachansind) == n_ch\n\n    ica.pre_whitener_ = np.ones((n_ch, 1))\n    ica.pca_mean_ = np.zeros(n_ch)\n\n    assert eeg.icasphere.shape[1] == n_ch\n    assert eeg.icaweights.shape == (n_components, rank)\n\n    # When PCA reduction is used in EEGLAB, runica returns\n    # weights= weights*sphere*eigenvectors(:,1:ncomps)';\n    # sphere = eye(urchans). When PCA reduction is not used, we have:\n    #\n    #     eeg.icawinv == pinv(eeg.icaweights @ eeg.icasphere)\n    #\n    # So in either case, we can use SVD to get our square whitened\n    # weights matrix (u * s) and our PCA vectors (v) back:\n    use = eeg.icaweights @ eeg.icasphere\n    use_check = pinv(eeg.icawinv)\n    if not np.allclose(use, use_check, rtol=1e-6):\n        warn(\n            \"Mismatch between icawinv and icaweights @ icasphere from EEGLAB \"\n            \"possibly due to ICA component removal, assuming icawinv is \"\n            \"correct\"\n        )\n        use = use_check\n    u, s, v = _safe_svd(use, full_matrices=False)\n    ica.unmixing_matrix_ = u * s\n    ica.pca_components_ = v\n    ica.pca_explained_variance_ = s * s\n    ica.info = info\n    ica._update_mixing_matrix()\n    ica._update_ica_names()\n    ica.reject_ = None\n    return ica", "metadata": {}}
{"_id": "mne_mne_preprocessing/ica.py_fit_code", "title": "fit", "text": "def fit(\n        self,\n        inst,\n        picks=None,\n        start=None,\n        stop=None,\n        decim=None,\n        reject=None,\n        flat=None,\n        tstep=2.0,\n        reject_by_annotation=True,\n        verbose=None,\n    ):\n        \"\"\"Run the ICA decomposition on raw data.\n\n        Caveat! If supplying a noise covariance keep track of the projections\n        available in the cov, the raw or the epochs object. For example,\n        if you are interested in EOG or ECG artifacts, EOG and ECG projections\n        should be temporally removed before fitting the ICA.\n\n        Parameters\n        ----------\n        inst : instance of Raw or Epochs\n            The data to be decomposed.\n        %(picks_good_data_noref)s\n            This selection remains throughout the initialized ICA solution.\n        start, stop : int | float | None\n            First and last sample to include. If float, data will be\n            interpreted as time in seconds. If ``None``, data will be used from\n            the first sample and to the last sample, respectively.\n\n            .. note:: These parameters only have an effect if ``inst`` is\n                      `~mne.io.Raw` data.\n        decim : int | None\n            Increment for selecting only each n-th sampling point. If ``None``,\n            all samples  between ``start`` and ``stop`` (inclusive) are used.\n        reject, flat : dict | None\n            Rejection parameters based on peak-to-peak amplitude (PTP)\n            in the continuous data. Signal periods exceeding the thresholds\n            in ``reject`` or less than the thresholds in ``flat`` will be\n            removed before fitting the ICA.\n\n            .. note:: These parameters only have an effect if ``inst`` is\n                      `~mne.io.Raw` data. For `~mne.Epochs`, perform PTP\n                      rejection via :meth:`~mne.Epochs.drop_bad`.\n\n            Valid keys are all channel types present in the data. Values must\n            be integers or floats.\n\n            If ``None``, no PTP-based rejection will be performed. Example::\n\n                reject = dict(\n                    grad=4000e-13, # T / m (gradiometers)\n                    mag=4e-12, # T (magnetometers)\n                    eeg=40e-6, # V (EEG channels)\n                    eog=250e-6 # V (EOG channels)\n                )\n                flat = None  # no rejection based on flatness\n        tstep : float\n            Length of data chunks for artifact rejection in seconds.\n\n            .. note:: This parameter only has an effect if ``inst`` is\n                      `~mne.io.Raw` data.\n        %(reject_by_annotation_raw)s\n\n            .. versionadded:: 0.14.0\n        %(verbose)s\n\n        Returns\n        -------\n        self : instance of ICA\n            Returns the modified instance.\n        \"\"\"\n        req_map = dict(fastica=\"sklearn\", picard=\"picard\")\n        for method, mod in req_map.items():\n            if self.method == method:\n                _require_version(mod, f\"use method={repr(method)}\")\n\n        _validate_type(inst, (BaseRaw, BaseEpochs), \"inst\", \"Raw or Epochs\")\n\n        if np.isclose(inst.info[\"highpass\"], 0.0):\n            warn(\n                \"The data has not been high-pass filtered. For good ICA \"\n                \"performance, it should be high-pass filtered (e.g., with a \"\n                \"1.0 Hz lower bound) before fitting ICA.\"\n            )\n\n        if isinstance(inst, BaseEpochs) and inst.baseline is not None:\n            warn(\n                \"The epochs you passed to ICA.fit() were baseline-corrected. \"\n                \"However, we suggest to fit ICA only on data that has been \"\n                \"high-pass filtered, but NOT baseline-corrected.\"\n            )\n\n        if not isinstance(inst, BaseRaw):\n            ignored_params = [\n                param_name\n                for param_name, param_val in zip(\n                    (\"start\", \"stop\", \"reject\", \"flat\"), (start, stop, reject, flat)\n                )\n                if param_val is not None\n            ]\n            if ignored_params:\n                warn(\n                    f\"The following parameters passed to ICA.fit() will be \"\n                    f\"ignored, as they only affect raw data (and it appears \"\n                    f\"you passed epochs): {', '.join(ignored_params)}\"\n                )\n\n        picks = _picks_to_idx(\n            inst.info, picks, allow_empty=False, with_ref_meg=self.allow_ref_meg\n        )\n        _check_for_unsupported_ica_channels(\n            picks, inst.info, allow_ref_meg=self.allow_ref_meg\n        )\n\n        # Actually start fitting\n        t_start = time()\n        if self.current_fit != \"unfitted\":\n            self._reset()\n\n        logger.info(\n            \"Fitting ICA to data using %i channels (please be patient, this may take \"\n            \"a while)\",\n            len(picks),\n        )\n\n        # n_components could be float 0 < x < 1, but that's okay here\n        if self.n_components is not None and self.n_components > len(picks):\n            raise ValueError(\n                f\"ica.n_components ({self.n_components}) cannot \"\n                f\"be greater than len(picks) ({len(picks)})\"\n            )\n\n        # filter out all the channels the raw wouldn't have initialized\n        self.info = pick_info(inst.info, picks)\n\n        if self.info[\"comps\"]:\n            with self.info._unlock():\n                self.info[\"comps\"] = []\n        self.ch_names = self.info[\"ch_names\"]\n\n        if isinstance(inst, BaseRaw):\n            self._fit_raw(\n                inst,\n                picks,\n                start,\n                stop,\n                decim,\n                reject,\n                flat,\n                tstep,\n                reject_by_annotation,\n                verbose,\n            )\n        else:\n            assert isinstance(inst, BaseEpochs)\n            self._fit_epochs(inst, picks, decim, verbose)\n\n        # sort ICA components by explained variance\n        var = _ica_explained_variance(self, inst)\n        var_ord = var.argsort()[::-1]\n        _sort_components(self, var_ord, copy=False)\n        t_stop = time()\n        logger.info(f\"Fitting ICA took {t_stop - t_start:.1f}s.\")\n        return self", "metadata": {}}
{"_id": "mne_mne_preprocessing/ica.py_get_components_code", "title": "get_components", "text": "def get_components(self):\n        \"\"\"Get ICA topomap for components as numpy arrays.\n\n        Returns\n        -------\n        components : array, shape (n_channels, n_components)\n            The ICA components (maps).\n        \"\"\"\n        return np.dot(\n            self.mixing_matrix_[:, : self.n_components_].T,\n            self.pca_components_[: self.n_components_],\n        ).T", "metadata": {}}
{"_id": "mne_mne_preprocessing/ica.py_get_explained_variance_ratio_code", "title": "get_explained_variance_ratio", "text": "def get_explained_variance_ratio(self, inst, *, components=None, ch_type=None):\n        \"\"\"Get the proportion of data variance explained by ICA components.\n\n        Parameters\n        ----------\n        inst : mne.io.BaseRaw | mne.BaseEpochs | mne.Evoked\n            The uncleaned data.\n        components : array-like of int | int | None\n            The component(s) for which to do the calculation. If more than one\n            component is specified, explained variance will be calculated\n            jointly across all supplied components. If ``None`` (default), uses\n            all available components.\n        ch_type : 'mag' | 'grad' | 'planar1' | 'planar2' | 'eeg' | array-like of str | None\n            The channel type(s) to include in the calculation. If ``None``, all\n            available channel types will be used.\n\n        Returns\n        -------\n        dict (str, float)\n            The fraction of variance in ``inst`` that can be explained by the\n            ICA components, calculated separately for each channel type.\n            Dictionary keys are the channel types, and corresponding explained\n            variance ratios are the values.\n\n        Notes\n        -----\n        A value similar to EEGLAB's ``pvaf`` (percent variance accounted for)\n        will be calculated for the specified component(s).\n\n        Since ICA components cannot be assumed to be aligned orthogonally, the\n        sum of the proportion of variance explained by all components may not\n        be equal to 1. In certain situations, the proportion of variance\n        explained by a component may even be negative.\n\n        .. versionadded:: 1.2\n        \"\"\"  # noqa: E501\n        if self.current_fit == \"unfitted\":\n            raise ValueError(\"ICA must be fitted first.\")\n\n        _validate_type(item=inst, types=(BaseRaw, BaseEpochs, Evoked), item_name=\"inst\")\n        _validate_type(\n            item=components,\n            types=(None, \"int-like\", Sequence, np.ndarray),\n            item_name=\"components\",\n            type_name=\"int, array-like of int, or None\",\n        )\n        if isinstance(components, Sequence | np.ndarray):\n            for item in components:\n                _validate_type(\n                    item=item, types=\"int-like\", item_name='Elements of \"components\"'\n                )\n\n        _validate_type(\n            item=ch_type,\n            types=(Sequence, np.ndarray, str, None),\n            item_name=\"ch_type\",\n            type_name=\"str, array-like of str, or None\",\n        )\n        if isinstance(ch_type, str):\n            ch_types = [ch_type]\n        elif ch_type is None:\n            ch_types = inst.get_channel_types(unique=True, only_data_chs=True)\n        else:\n            assert isinstance(ch_type, Sequence | np.ndarray)\n            ch_types = ch_type\n\n        assert len(ch_types) >= 1\n        allowed_ch_types = (\"mag\", \"grad\", \"planar1\", \"planar2\", \"eeg\")\n        for ch_type in ch_types:\n            if ch_type not in allowed_ch_types:\n                raise ValueError(\n                    f\"You requested operation on the channel type \"\n                    f'\"{ch_type}\", but only the following channel types are '\n                    f\"supported: {', '.join(allowed_ch_types)}\"\n                )\n        del ch_type\n\n        # Input data validation ends here\n        if components is None:\n            components = range(self.n_components_)\n\n        explained_var_ratios = [\n            self._get_explained_variance_ratio_one_ch_type(\n                inst=inst, components=components, ch_type=ch_type\n            )\n            for ch_type in ch_types\n        ]\n        result = dict(zip(ch_types, explained_var_ratios))\n        return result", "metadata": {}}
{"_id": "mne_mne_preprocessing/ica.py_get_sources_code", "title": "get_sources", "text": "def get_sources(self, inst, add_channels=None, start=None, stop=None):\n        \"\"\"Estimate sources given the unmixing matrix.\n\n        This method will return the sources in the container format passed.\n        Typical usecases:\n\n        1. pass Raw object to use `raw.plot <mne.io.Raw.plot>` for ICA sources\n        2. pass Epochs object to compute trial-based statistics in ICA space\n        3. pass Evoked object to investigate time-locking in ICA space\n\n        Parameters\n        ----------\n        inst : instance of Raw, Epochs or Evoked\n            Object to compute sources from and to represent sources in.\n        add_channels : None | list of str\n            Additional channels  to be added. Useful to e.g. compare sources\n            with some reference. Defaults to None.\n        start : int | float | None\n            First sample to include. If float, data will be interpreted as\n            time in seconds. If None, the entire data will be used.\n        stop : int | float | None\n            Last sample to not include. If float, data will be interpreted as\n            time in seconds. If None, the entire data will be used.\n\n        Returns\n        -------\n        sources : instance of Raw, Epochs or Evoked\n            The ICA sources time series.\n        \"\"\"\n        if isinstance(inst, BaseRaw):\n            _check_compensation_grade(\n                self.info, inst.info, \"ICA\", \"Raw\", ch_names=self.ch_names\n            )\n            sources = self._sources_as_raw(inst, add_channels, start, stop)\n        elif isinstance(inst, BaseEpochs):\n            _check_compensation_grade(\n                self.info, inst.info, \"ICA\", \"Epochs\", ch_names=self.ch_names\n            )\n            sources = self._sources_as_epochs(inst, add_channels, False)\n        elif isinstance(inst, Evoked):\n            _check_compensation_grade(\n                self.info, inst.info, \"ICA\", \"Evoked\", ch_names=self.ch_names\n            )\n            sources = self._sources_as_evoked(inst, add_channels)\n        else:\n            raise ValueError(\"Data input must be of Raw, Epochs or Evoked type\")\n        return sources", "metadata": {}}
{"_id": "mne_mne_preprocessing/ica.py_score_sources_code", "title": "score_sources", "text": "def score_sources(\n        self,\n        inst,\n        target=None,\n        score_func=\"pearsonr\",\n        start=None,\n        stop=None,\n        l_freq=None,\n        h_freq=None,\n        reject_by_annotation=True,\n        verbose=None,\n    ):\n        \"\"\"Assign score to components based on statistic or metric.\n\n        Parameters\n        ----------\n        inst : instance of Raw, Epochs or Evoked\n            The object to reconstruct the sources from.\n        target : array-like | str | None\n            Signal to which the sources shall be compared. It has to be of\n            the same shape as the sources. If str, a routine will try to find\n            a matching channel name. If None, a score\n            function expecting only one input-array argument must be used,\n            for instance, scipy.stats.skew (default).\n        score_func : callable | str\n            Callable taking as arguments either two input arrays\n            (e.g. Pearson correlation) or one input\n            array (e. g. skewness) and returns a float. For convenience the\n            most common score_funcs are available via string labels:\n            Currently, all distance metrics from scipy.spatial and All\n            functions from scipy.stats taking compatible input arguments are\n            supported. These function have been modified to support iteration\n            over the rows of a 2D array.\n        start : int | float | None\n            First sample to include. If float, data will be interpreted as\n            time in seconds. If None, data will be used from the first sample.\n        stop : int | float | None\n            Last sample to not include. If float, data will be interpreted as\n            time in seconds. If None, data will be used to the last sample.\n        l_freq : float\n            Low pass frequency.\n        h_freq : float\n            High pass frequency.\n        %(reject_by_annotation_all)s\n\n            .. versionadded:: 0.14.0\n        %(verbose)s\n\n        Returns\n        -------\n        scores : ndarray\n            Scores for each source as returned from score_func.\n        \"\"\"\n        if isinstance(inst, BaseRaw):\n            _check_compensation_grade(\n                self.info, inst.info, \"ICA\", \"Raw\", ch_names=self.ch_names\n            )\n            sources = self._transform_raw(inst, start, stop, reject_by_annotation)\n        elif isinstance(inst, BaseEpochs):\n            _check_compensation_grade(\n                self.info, inst.info, \"ICA\", \"Epochs\", ch_names=self.ch_names\n            )\n            sources = self._transform_epochs(inst, concatenate=True)\n        elif isinstance(inst, Evoked):\n            _check_compensation_grade(\n                self.info, inst.info, \"ICA\", \"Evoked\", ch_names=self.ch_names\n            )\n            sources = self._transform_evoked(inst)\n        else:\n            raise ValueError(\"Data input must be of Raw, Epochs or Evoked type\")\n\n        if target is not None:  # we can have univariate metrics without target\n            target = self._check_target(target, inst, start, stop, reject_by_annotation)\n\n            if sources.shape[-1] != target.shape[-1]:\n                raise ValueError(\n                    \"Sources and target do not have the same number of time slices.\"\n                )\n            # auto target selection\n            if isinstance(inst, BaseRaw):\n                # We pass inst, not self, because the sfreq of the data we\n                # use for scoring components can be different:\n                sources, target = _band_pass_filter(\n                    inst, sources, target, l_freq, h_freq\n                )\n\n        scores = _find_sources(sources, target, score_func)\n\n        return scores", "metadata": {}}
{"_id": "mne_mne_preprocessing/ica.py_find_bads_ecg_code", "title": "find_bads_ecg", "text": "def find_bads_ecg(\n        self,\n        inst,\n        ch_name=None,\n        threshold=\"auto\",\n        start=None,\n        stop=None,\n        l_freq=8,\n        h_freq=16,\n        method=\"ctps\",\n        reject_by_annotation=True,\n        measure=\"zscore\",\n        verbose=None,\n    ):\n        \"\"\"Detect ECG related components.\n\n        Cross-trial phase statistics :footcite:`DammersEtAl2008` or Pearson\n        correlation can be used for detection.\n\n        .. note:: If no ECG channel is available, an artificial ECG channel will be\n                  created based on cross-channel averaging of ``\"mag\"`` or ``\"grad\"``\n                  channels. If neither of these channel types are available in\n                  ``inst``, artificial ECG channel creation is impossible.\n\n        Parameters\n        ----------\n        inst : instance of Raw, Epochs or Evoked\n            Object to compute sources from.\n        %(ch_name_ecg)s\n        threshold : float | 'auto'\n            Value above which a feature is classified as outlier. See Notes.\n\n            .. versionchanged:: 0.21\n        start : int | float | None\n            First sample to include. If float, data will be interpreted as\n            time in seconds. If None, data will be used from the first sample.\n            When working with Epochs or Evoked objects, must be float or None.\n        stop : int | float | None\n            Last sample to not include. If float, data will be interpreted as\n            time in seconds. If None, data will be used to the last sample.\n            When working with Epochs or Evoked objects, must be float or None.\n        l_freq : float\n            Low pass frequency.\n        h_freq : float\n            High pass frequency.\n        method : 'ctps' | 'correlation'\n            The method used for detection. If ``'ctps'``, cross-trial phase\n            statistics :footcite:`DammersEtAl2008` are used to detect\n            ECG-related components. See Notes.\n        %(reject_by_annotation_all)s\n\n            .. versionadded:: 0.14.0\n        %(measure)s\n        %(verbose)s\n\n        Returns\n        -------\n        ecg_idx : list of int\n            The indices of ECG-related components.\n        scores : np.ndarray of float, shape (``n_components_``)\n            If method is 'ctps', the normalized Kuiper index scores. If method\n            is 'correlation', the correlation scores.\n\n        See Also\n        --------\n        find_bads_eog, find_bads_ref, find_bads_muscle\n\n        Notes\n        -----\n        The ``threshold``, ``method``, and ``measure`` parameters interact in\n        the following ways:\n\n        - If ``method='ctps'``, ``threshold`` refers to the significance value\n          of a Kuiper statistic, and ``threshold='auto'`` will compute the\n          threshold automatically based on the sampling frequency.\n        - If ``method='correlation'`` and ``measure='correlation'``,\n          ``threshold`` refers to the Pearson correlation value, and\n          ``threshold='auto'`` sets the threshold to 0.9.\n        - If ``method='correlation'`` and ``measure='zscore'``, ``threshold``\n          refers to the z-score value (i.e., standard deviations) used in the\n          iterative z-scoring method, and ``threshold='auto'`` sets the\n          threshold to 3.0.\n\n        References\n        ----------\n        .. footbibliography::\n        \"\"\"\n        _validate_type(threshold, (str, \"numeric\"), \"threshold\")\n        if isinstance(threshold, str):\n            _check_option(\"threshold\", threshold, (\"auto\",), extra=\"when str\")\n        _validate_type(method, str, \"method\")\n        _check_option(\"method\", method, (\"ctps\", \"correlation\"))\n        _validate_type(measure, str, \"measure\")\n        _check_option(\"measure\", measure, (\"zscore\", \"correlation\"))\n\n        idx_ecg = _get_ecg_channel_index(ch_name, inst)\n\n        if idx_ecg is None:\n            ecg, _ = _make_ecg(\n                inst, start, stop, reject_by_annotation=reject_by_annotation\n            )\n        else:\n            ecg = inst.ch_names[idx_ecg]\n\n        if method == \"ctps\":\n            if threshold == \"auto\":\n                threshold = self._get_ctps_threshold()\n                logger.info(f\"Using threshold: {threshold:.2f} for CTPS ECG detection\")\n            if isinstance(inst, BaseRaw):\n                sources = self.get_sources(\n                    create_ecg_epochs(\n                        inst,\n                        ch_name,\n                        l_freq=l_freq,\n                        h_freq=h_freq,\n                        keep_ecg=False,\n                        reject_by_annotation=reject_by_annotation,\n                    )\n                ).get_data(copy=False)\n\n                if sources.shape[0] == 0:\n                    warn(\n                        \"No ECG activity detected. Consider changing \"\n                        \"the input parameters.\"\n                    )\n            elif isinstance(inst, BaseEpochs):\n                sources = self.get_sources(inst).get_data(copy=False)\n            else:\n                raise ValueError(\"With `ctps` only Raw and Epochs input is supported\")\n            _, p_vals, _ = ctps(sources)\n            scores = p_vals.max(-1)\n            ecg_idx = np.where(scores >= threshold)[0]\n            # sort indices by scores\n            ecg_idx = ecg_idx[np.abs(scores[ecg_idx]).argsort()[::-1]]\n\n            self.labels_[\"ecg\"] = list(ecg_idx)\n            if ch_name is None:\n                ch_name = \"ECG-MAG\"\n            self.labels_[f\"ecg/{ch_name}\"] = list(ecg_idx)\n        elif method == \"correlation\":\n            if threshold == \"auto\" and measure == \"zscore\":\n                threshold = 3.0\n            elif threshold == \"auto\" and measure == \"correlation\":\n                threshold = 0.9\n            self.labels_[\"ecg\"], scores = self._find_bads_ch(\n                inst,\n                [ecg],\n                threshold=threshold,\n                start=start,\n                stop=stop,\n                l_freq=l_freq,\n                h_freq=h_freq,\n                prefix=\"ecg\",\n                reject_by_annotation=reject_by_annotation,\n                measure=measure,\n            )\n\n        return self.labels_[\"ecg\"], scores", "metadata": {}}
{"_id": "mne_mne_preprocessing/ica.py_find_bads_ref_code", "title": "find_bads_ref", "text": "def find_bads_ref(\n        self,\n        inst,\n        ch_name=None,\n        threshold=3.0,\n        start=None,\n        stop=None,\n        l_freq=None,\n        h_freq=None,\n        reject_by_annotation=True,\n        method=\"together\",\n        measure=\"zscore\",\n        verbose=None,\n    ):\n        \"\"\"Detect MEG reference related components using correlation.\n\n        Parameters\n        ----------\n        inst : instance of Raw, Epochs or Evoked\n            Object to compute sources from. Should contain at least one channel\n            i.e. component derived from MEG reference channels.\n        ch_name : list of str\n            Which MEG reference components to use. If None, then all channels\n            that begin with REF_ICA.\n        threshold : float | str\n            Value above which a feature is classified as outlier.\n\n            - If ``measure`` is ``'zscore'``, defines the threshold on the\n              z-score used in the iterative z-scoring method.\n            - If ``measure`` is ``'correlation'``, defines the absolute\n              threshold on the correlation between 0 and 1.\n            - If ``'auto'``, defaults to 3.0 if ``measure`` is ``'zscore'`` and\n              0.9 if ``measure`` is ``'correlation'``.\n\n             .. warning::\n                 If ``method`` is ``'together'``, the iterative z-score method\n                 is always used.\n        start : int | float | None\n            First sample to include. If float, data will be interpreted as\n            time in seconds. If None, data will be used from the first sample.\n        stop : int | float | None\n            Last sample to not include. If float, data will be interpreted as\n            time in seconds. If None, data will be used to the last sample.\n        l_freq : float\n            Low pass frequency.\n        h_freq : float\n            High pass frequency.\n        %(reject_by_annotation_all)s\n        method : 'together' | 'separate'\n            Method to use to identify reference channel related components.\n            Defaults to ``'together'``. See notes.\n\n            .. versionadded:: 0.21\n        %(measure)s\n        %(verbose)s\n\n        Returns\n        -------\n        ref_idx : list of int\n            The indices of MEG reference related components, sorted by score.\n        scores : np.ndarray of float, shape (``n_components_``) | list of array\n            The correlation scores.\n\n        See Also\n        --------\n        find_bads_ecg, find_bads_eog, find_bads_muscle\n\n        Notes\n        -----\n        ICA decomposition on MEG reference channels is used to assess external\n        magnetic noise and remove it from the MEG. Two methods are supported:\n\n        With the ``'together'`` method, only one ICA fit is used, which\n        encompasses both MEG and reference channels together. Components which\n        have particularly strong weights on the reference channels may be\n        thresholded and marked for removal.\n\n        With ``'separate'`` selected components from a separate ICA\n        decomposition on the reference channels are used as a ground truth for\n        identifying bad components in an ICA fit done on MEG channels only. The\n        logic here is similar to an EOG/ECG, with reference components\n        replacing the EOG/ECG channels. Recommended procedure is to perform ICA\n        separately on reference channels, extract them using\n        :meth:`~mne.preprocessing.ICA.get_sources`, and then append them to the\n        inst using :meth:`~mne.io.Raw.add_channels`, preferably with the prefix\n        ``REF_ICA`` so that they can be automatically detected.\n\n        With ``'together'``, thresholding is based on adaptative z-scoring.\n\n        With ``'separate'``:\n\n        - If ``measure`` is ``'zscore'``, thresholding is based on adaptative\n          z-scoring.\n        - If ``measure`` is ``'correlation'``, threshold defines the absolute\n          threshold on the correlation between 0 and 1.\n\n        Validation and further documentation for this technique can be found\n        in :footcite:`HannaEtAl2020`.\n\n        .. versionadded:: 0.18\n\n        References\n        ----------\n        .. footbibliography::\n        \"\"\"\n        _validate_type(threshold, (str, \"numeric\"), \"threshold\")\n        if isinstance(threshold, str):\n            _check_option(\"threshold\", threshold, (\"auto\",), extra=\"when str\")\n        _validate_type(method, str, \"method\")\n        _check_option(\"method\", method, (\"together\", \"separate\"))\n        _validate_type(measure, str, \"measure\")\n        _check_option(\"measure\", measure, (\"zscore\", \"correlation\"))\n\n        if method == \"separate\":\n            if threshold == \"auto\" and measure == \"zscore\":\n                threshold = 3.0\n            elif threshold == \"auto\" and measure == \"correlation\":\n                threshold = 0.9\n\n            if not ch_name:\n                inds = pick_channels_regexp(inst.ch_names, \"REF_ICA*\")\n            else:\n                inds = pick_channels(inst.ch_names, ch_name)\n            # regexp returns list, pick_channels returns numpy\n            inds = list(inds)\n            if not inds:\n                raise ValueError(\"No valid channels available.\")\n            ref_chs = [inst.ch_names[k] for k in inds]\n\n            self.labels_[\"ref_meg\"], scores = self._find_bads_ch(\n                inst,\n                ref_chs,\n                threshold=threshold,\n                start=start,\n                stop=stop,\n                l_freq=l_freq,\n                h_freq=h_freq,\n                prefix=\"ref_meg\",\n                reject_by_annotation=reject_by_annotation,\n                measure=measure,\n            )\n        elif method == \"together\":\n            if threshold == \"auto\":\n                threshold = 3.0\n            if measure != \"zscore\":\n                logger.info(\n                    \"With method 'together', only 'zscore' measure is\"\n                    f\"supported. Using 'zscore' instead of '{measure}'.\"\n                )\n\n            meg_picks = pick_types(self.info, meg=True, ref_meg=False)\n            ref_picks = pick_types(self.info, meg=False, ref_meg=True)\n            if not any(meg_picks) or not any(ref_picks):\n                raise ValueError(\n                    \"ICA solution must contain both reference and MEG channels.\"\n                )\n            weights = self.get_components()\n            # take norm of component weights on reference channels for each\n            # component, divide them by the norm on the standard channels,\n            # log transform to approximate normal distribution\n            normrats = np.linalg.norm(weights[ref_picks], axis=0) / np.linalg.norm(\n                weights[meg_picks], axis=0\n            )\n            scores = np.log(normrats)\n            self.labels_[\"ref_meg\"] = list(\n                _find_outliers(scores, threshold=threshold, tail=1)\n            )\n\n        return self.labels_[\"ref_meg\"], scores", "metadata": {}}
{"_id": "mne_mne_preprocessing/ica.py_find_bads_muscle_code", "title": "find_bads_muscle", "text": "def find_bads_muscle(\n        self,\n        inst,\n        threshold=0.5,\n        start=None,\n        stop=None,\n        l_freq=7,\n        h_freq=45,\n        sphere=None,\n        verbose=None,\n    ):\n        \"\"\"Detect muscle-related components.\n\n        Detection is based on :footcite:`DharmapraniEtAl2016` which uses\n        data from a subject who has been temporarily paralyzed\n        :footcite:`WhithamEtAl2007`. The criteria are threefold:\n\n        #. Positive log-log spectral slope from 7 to 45 Hz\n        #. Peripheral component power (farthest away from the vertex)\n        #. A single focal point measured by low spatial smoothness\n\n        The threshold is relative to the slope, focal point and smoothness\n        of a typical muscle-related ICA component. Note the high frequency\n        of the power spectral density slope was 75 Hz in the reference but\n        has been modified to 45 Hz as a default based on the criteria being\n        more accurate in practice.\n\n        If ``inst`` is supplied without sensor positions, only the first criterion\n        (slope) is applied.\n\n        Parameters\n        ----------\n        inst : instance of Raw, Epochs or Evoked\n            Object to compute sources from.\n        threshold : float | str\n            Value above which a component should be marked as muscle-related,\n            relative to a typical muscle component.\n        start : int | float | None\n            First sample to include. If float, data will be interpreted as\n            time in seconds. If None, data will be used from the first sample.\n        stop : int | float | None\n            Last sample to not include. If float, data will be interpreted as\n            time in seconds. If None, data will be used to the last sample.\n        l_freq : float\n            Low frequency for muscle-related power.\n        h_freq : float\n            High frequency for muscle-related power.\n        %(sphere_topomap_auto)s\n        %(verbose)s\n\n        Returns\n        -------\n        muscle_idx : list of int\n            The indices of muscle-related components, sorted by score.\n        scores : np.ndarray of float, shape (``n_components_``) | list of array\n            The correlation scores.\n\n        See Also\n        --------\n        find_bads_ecg, find_bads_eog, find_bads_ref\n\n        Notes\n        -----\n        .. versionadded:: 1.1\n        \"\"\"\n        _validate_type(threshold, \"numeric\", \"threshold\")\n\n        slope_score, focus_score, smoothness_score = None, None, None\n\n        sources = self.get_sources(inst, start=start, stop=stop)\n        components = self.get_components()\n\n        # compute metric #1: slope of the log-log psd\n        spectrum = sources.compute_psd(fmin=l_freq, fmax=h_freq, picks=\"misc\")\n        psds, freqs = spectrum.get_data(return_freqs=True)\n        if psds.ndim > 2:\n            psds = psds.mean(axis=0)\n        slopes = np.polyfit(np.log10(freqs), np.log10(psds).T, 1)[0]\n\n        # typical muscle slope is ~0.15, non-muscle components negative\n        # so logistic with shift -0.5 and slope 0.25 so -0.5 -> 0.5 and 0->1\n        slope_score = expit((slopes + 0.5) / 0.25)\n\n        # Need sensor positions for the criteria below, so return with only one score\n        # if no positions available\n        picks = _picks_to_idx(\n            inst.info, self.ch_names, \"all\", exclude=(), allow_empty=False\n        )\n        if not _check_ch_locs(inst.info, picks=picks):\n            warn(\n                \"No sensor positions found. Scores for bad muscle components are only \"\n                \"based on the 'slope' criterion.\"\n            )\n            scores = slope_score\n            self.labels_[\"muscle\"] = [\n                idx for idx, score in enumerate(scores) if score > threshold\n            ]\n            return self.labels_[\"muscle\"], scores\n\n        # compute metric #2: distance from the vertex of focus\n        components_norm = abs(components) / np.max(abs(components), axis=0)\n        # we need to retrieve the position from the channels that were used to\n        # fit the ICA. N.B: picks in _find_topomap_coords includes bad channels\n        # even if they are not provided explicitly.\n\n        pos = _find_topomap_coords(\n            inst.info, picks=self.ch_names, sphere=sphere, ignore_overlap=True\n        )\n        assert pos.shape[0] == components.shape[0]  # pos for each sensor\n        pos -= pos.mean(axis=0)  # center\n        dists = np.linalg.norm(pos, axis=1)\n        dists /= dists.max()\n        focus_dists = np.dot(dists, components_norm)\n\n        # focus distance is ~65% of max electrode distance with 10% slope\n        # (assumes typical head size)\n        focus_score = expit((focus_dists - 0.65) / 0.1)\n\n        # compute metric #3: smoothness\n        smoothnesses = np.zeros((components.shape[1],))\n        dists = distance.squareform(distance.pdist(pos))\n        dists = 1 - (dists / dists.max())  # invert\n        for idx, comp in enumerate(components.T):\n            comp_dists = distance.squareform(distance.pdist(comp[:, np.newaxis]))\n            comp_dists /= comp_dists.max()\n            smoothnesses[idx] = np.multiply(dists, comp_dists).sum()\n\n        # smoothnessness is around 150 for muscle and 450 otherwise\n        # so use reversed logistic centered at 300 with 100 slope\n        smoothness_score = 1 - expit((smoothnesses - 300) / 100)\n\n        # multiply all criteria that are present\n        scores = [\n            score\n            for score in [slope_score, focus_score, smoothness_score]\n            if score is not None\n        ]\n        n_criteria = len(scores)\n        scores = np.prod(np.array(scores), axis=0)\n\n        # scale the threshold by the use of three metrics\n        self.labels_[\"muscle\"] = [\n            idx for idx, score in enumerate(scores) if score > threshold**n_criteria\n        ]\n        return self.labels_[\"muscle\"], scores", "metadata": {}}
{"_id": "mne_mne_preprocessing/ica.py_find_bads_eog_code", "title": "find_bads_eog", "text": "def find_bads_eog(\n        self,\n        inst,\n        ch_name=None,\n        threshold=3.0,\n        start=None,\n        stop=None,\n        l_freq=1,\n        h_freq=10,\n        reject_by_annotation=True,\n        measure=\"zscore\",\n        verbose=None,\n    ):\n        \"\"\"Detect EOG related components using correlation.\n\n        Detection is based on Pearson correlation between the\n        filtered data and the filtered EOG channel.\n        Thresholding is based on adaptive z-scoring. The above threshold\n        components will be masked and the z-score will be recomputed\n        until no supra-threshold component remains.\n\n        Parameters\n        ----------\n        inst : instance of Raw, Epochs or Evoked\n            Object to compute sources from.\n        ch_name : str\n            The name of the channel to use for EOG peak detection.\n            The argument is mandatory if the dataset contains no EOG\n            channels.\n        threshold : float | str\n            Value above which a feature is classified as outlier.\n\n            - If ``measure`` is ``'zscore'``, defines the threshold on the\n              z-score used in the iterative z-scoring method.\n            - If ``measure`` is ``'correlation'``, defines the absolute\n              threshold on the correlation between 0 and 1.\n            - If ``'auto'``, defaults to 3.0 if ``measure`` is ``'zscore'`` and\n              0.9 if ``measure`` is ``'correlation'``.\n        start : int | float | None\n            First sample to include. If float, data will be interpreted as\n            time in seconds. If None, data will be used from the first sample.\n        stop : int | float | None\n            Last sample to not include. If float, data will be interpreted as\n            time in seconds. If None, data will be used to the last sample.\n        l_freq : float\n            Low pass frequency.\n        h_freq : float\n            High pass frequency.\n        %(reject_by_annotation_all)s\n\n            .. versionadded:: 0.14.0\n        %(measure)s\n        %(verbose)s\n\n        Returns\n        -------\n        eog_idx : list of int\n            The indices of EOG related components, sorted by score.\n        scores : np.ndarray of float, shape (``n_components_``) | list of array\n            The correlation scores.\n\n        See Also\n        --------\n        find_bads_ecg, find_bads_ref, find_bads_muscle\n        \"\"\"\n        _validate_type(threshold, (str, \"numeric\"), \"threshold\")\n        if isinstance(threshold, str):\n            _check_option(\"threshold\", threshold, (\"auto\",), extra=\"when str\")\n        _validate_type(measure, str, \"measure\")\n        _check_option(\"measure\", measure, (\"zscore\", \"correlation\"))\n\n        eog_inds = _get_eog_channel_index(ch_name, inst)\n        eog_chs = [inst.ch_names[k] for k in eog_inds]\n\n        if threshold == \"auto\" and measure == \"zscore\":\n            threshold = 3.0\n        elif threshold == \"auto\" and measure == \"correlation\":\n            threshold = 0.9\n\n        self.labels_[\"eog\"], scores = self._find_bads_ch(\n            inst,\n            eog_chs,\n            threshold=threshold,\n            start=start,\n            stop=stop,\n            l_freq=l_freq,\n            h_freq=h_freq,\n            prefix=\"eog\",\n            reject_by_annotation=reject_by_annotation,\n            measure=measure,\n        )\n        return self.labels_[\"eog\"], scores", "metadata": {}}
{"_id": "mne_mne_preprocessing/ica.py_apply_code", "title": "apply", "text": "def apply(\n        self,\n        inst,\n        include=None,\n        exclude=None,\n        n_pca_components=None,\n        start=None,\n        stop=None,\n        *,\n        on_baseline=\"warn\",\n        verbose=None,\n    ):\n        \"\"\"Remove selected components from the signal.\n\n        Given the unmixing matrix, transform the data,\n        zero out all excluded components, and inverse-transform the data.\n        This procedure will reconstruct M/EEG signals from which\n        the dynamics described by the excluded components is subtracted.\n\n        Parameters\n        ----------\n        inst : instance of Raw, Epochs or Evoked\n            The data to be processed (i.e., cleaned). It will be modified\n            in-place.\n        include : array_like of int\n            The indices referring to columns in the ummixing matrix. The\n            components to be kept. If ``None`` (default), all components\n            will be included (minus those defined in ``ica.exclude``\n            and the ``exclude`` parameter, see below).\n        exclude : array_like of int\n            The indices referring to columns in the ummixing matrix. The\n            components to be zeroed out. If ``None`` (default) or an\n            empty list, only components from ``ica.exclude`` will be\n            excluded. Else, the union of ``exclude`` and ``ica.exclude``\n            will be excluded.\n        %(n_pca_components_apply)s\n        start : int | float | None\n            First sample to include. If float, data will be interpreted as\n            time in seconds. If None, data will be used from the first sample.\n        stop : int | float | None\n            Last sample to not include. If float, data will be interpreted as\n            time in seconds. If None, data will be used to the last sample.\n        %(on_baseline_ica)s\n        %(verbose)s\n\n        Returns\n        -------\n        out : instance of Raw, Epochs or Evoked\n            The processed data.\n\n        Notes\n        -----\n        .. note:: Applying ICA may introduce a DC shift. If you pass\n                  baseline-corrected `~mne.Epochs` or `~mne.Evoked` data,\n                  the baseline period of the cleaned data may not be of\n                  zero mean anymore. If you require baseline-corrected\n                  data, apply baseline correction again after cleaning\n                  via ICA. A warning will be emitted to remind you of this\n                  fact if you pass baseline-corrected data.\n\n        .. versionchanged:: 0.23\n            Warn if instance was baseline-corrected.\n        \"\"\"\n        _validate_type(\n            inst, (BaseRaw, BaseEpochs, Evoked), \"inst\", \"Raw, Epochs, or Evoked\"\n        )\n        kwargs = dict(\n            include=include, exclude=exclude, n_pca_components=n_pca_components\n        )\n        if isinstance(inst, BaseRaw):\n            kind, meth = \"Raw\", self._apply_raw\n            kwargs.update(raw=inst, start=start, stop=stop)\n        elif isinstance(inst, BaseEpochs):\n            kind, meth = \"Epochs\", self._apply_epochs\n            kwargs.update(epochs=inst)\n        else:  # isinstance(inst, Evoked):\n            kind, meth = \"Evoked\", self._apply_evoked\n            kwargs.update(evoked=inst)\n        _check_compensation_grade(\n            self.info, inst.info, \"ICA\", kind, ch_names=self.ch_names\n        )\n\n        _check_on_missing(on_baseline, \"on_baseline\", extras=(\"reapply\",))\n        reapply_baseline = False\n        if isinstance(inst, BaseEpochs | Evoked):\n            if getattr(inst, \"baseline\", None) is not None:\n                if on_baseline == \"reapply\":\n                    reapply_baseline = True\n                else:\n                    msg = (\n                        \"The data you passed to ICA.apply() was \"\n                        \"baseline-corrected. Please note that ICA can \"\n                        \"introduce DC shifts, therefore you may wish to \"\n                        \"consider baseline-correcting the cleaned data again.\"\n                    )\n                    _on_missing(on_baseline, msg, \"on_baseline\")\n\n        logger.info(f\"Applying ICA to {kind} instance\")\n        out = meth(**kwargs)\n        if reapply_baseline:\n            out.apply_baseline(inst.baseline)\n        return out", "metadata": {}}
{"_id": "mne_mne_preprocessing/ica.py_save_code", "title": "save", "text": "def save(self, fname, *, overwrite=False, verbose=None):\n        \"\"\"Store ICA solution into a fiff file.\n\n        Parameters\n        ----------\n        fname : path-like\n            The absolute path of the file name to save the ICA solution into.\n            The file name should end with ``-ica.fif`` or ``-ica.fif.gz``.\n        %(overwrite)s\n\n            .. versionadded:: 1.0\n        %(verbose)s\n\n        Returns\n        -------\n        ica : instance of ICA\n            The object.\n\n        See Also\n        --------\n        read_ica\n        \"\"\"\n        if self.current_fit == \"unfitted\":\n            raise RuntimeError(\"No fit available. Please first fit ICA\")\n\n        check_fname(\n            fname, \"ICA\", (\"-ica.fif\", \"-ica.fif.gz\", \"_ica.fif\", \"_ica.fif.gz\")\n        )\n        fname = _check_fname(fname, overwrite=overwrite)\n\n        logger.info(f\"Writing ICA solution to {fname}...\")\n        with start_and_end_file(fname) as fid:\n            _write_ica(fid, self)\n        return self", "metadata": {}}
{"_id": "mne_mne_preprocessing/ica.py_copy_code", "title": "copy", "text": "def copy(self):\n        \"\"\"Copy the ICA object.\n\n        Returns\n        -------\n        ica : instance of ICA\n            The copied object.\n        \"\"\"\n        return deepcopy(self)", "metadata": {}}
{"_id": "mne_mne_preprocessing/_csd.py_compute_current_source_density_code", "title": "compute_current_source_density", "text": "def compute_current_source_density(\n    inst,\n    sphere=\"auto\",\n    lambda2=1e-5,\n    stiffness=4,\n    n_legendre_terms=50,\n    copy=True,\n    *,\n    verbose=None,\n):\n    \"\"\"Get the current source density (CSD) transformation.\n\n    Transformation based on spherical spline surface Laplacian\n    :footcite:`PerrinEtAl1987,PerrinEtAl1989,Cohen2014,KayserTenke2015`.\n\n    This function can be used to re-reference the signal using a Laplacian\n    (LAP) \"reference-free\" transformation.\n\n    Parameters\n    ----------\n    inst : instance of Raw, Epochs or Evoked\n        The data to be transformed.\n    sphere : array-like, shape (4,) | str\n        The sphere, head-model of the form (x, y, z, r) where x, y, z\n        is the center of the sphere and r is the radius in meters.\n        Can also be \"auto\" to use a digitization-based fit.\n    lambda2 : float\n        Regularization parameter, produces smoothness. Defaults to 1e-5.\n    stiffness : float\n        Stiffness of the spline.\n    n_legendre_terms : int\n        Number of Legendre terms to evaluate.\n    copy : bool\n        Whether to overwrite instance data or create a copy.\n    %(verbose)s\n\n    Returns\n    -------\n    inst_csd : instance of Raw, Epochs or Evoked\n        The transformed data. Output type will match input type.\n\n    Notes\n    -----\n    .. versionadded:: 0.20\n\n    References\n    ----------\n    .. footbibliography::\n    \"\"\"\n    _validate_type(inst, (BaseEpochs, BaseRaw, Evoked), \"inst\")\n    _check_preload(inst, \"Computing CSD\")\n\n    if inst.info[\"custom_ref_applied\"] == FIFF.FIFFV_MNE_CUSTOM_REF_CSD:\n        raise ValueError(\"CSD already applied, should not be reapplied\")\n\n    _validate_type(copy, (bool), \"copy\")\n    inst = inst.copy() if copy else inst\n\n    picks = pick_types(inst.info, meg=False, eeg=True, exclude=[])\n\n    if any([ch in np.array(inst.ch_names)[picks] for ch in inst.info[\"bads\"]]):\n        raise ValueError(\n            \"CSD cannot be computed with bad EEG channels. Either\"\n            \" drop (inst.drop_channels(inst.info['bads']) \"\n            \"or interpolate (`inst.interpolate_bads()`) \"\n            \"bad EEG channels.\"\n        )\n\n    if len(picks) == 0:\n        raise ValueError(\"No EEG channels found.\")\n\n    _validate_type(lambda2, \"numeric\", \"lambda2\")\n    if not 0 <= lambda2 < 1:\n        raise ValueError(f\"lambda2 must be between 0 and 1, got {lambda2}\")\n\n    _validate_type(stiffness, \"numeric\", \"stiffness\")\n    if stiffness < 0:\n        raise ValueError(f\"stiffness must be non-negative got {stiffness}\")\n\n    n_legendre_terms = _ensure_int(n_legendre_terms, \"n_legendre_terms\")\n    if n_legendre_terms < 1:\n        raise ValueError(\n            f\"n_legendre_terms must be greater than 0, got {n_legendre_terms}\"\n        )\n\n    if isinstance(sphere, str) and sphere == \"auto\":\n        radius, origin_head, origin_device = fit_sphere_to_headshape(inst.info)\n        x, y, z = origin_head - origin_device\n        sphere = (x, y, z, radius)\n    try:\n        sphere = np.array(sphere, float)\n        x, y, z, radius = sphere\n    except Exception:\n        raise ValueError(\n            f'sphere must be \"auto\" or array-like with shape (4,), got {sphere}'\n        )\n    _validate_type(x, \"numeric\", \"x\")\n    _validate_type(y, \"numeric\", \"y\")\n    _validate_type(z, \"numeric\", \"z\")\n    _validate_type(radius, \"numeric\", \"radius\")\n    if radius <= 0:\n        raise ValueError(\"sphere radius must be greater than 0, got {radius}\")\n\n    pos = np.array([inst.info[\"chs\"][pick][\"loc\"][:3] for pick in picks])\n    if not np.isfinite(pos).all() or np.isclose(pos, 0.0).all(1).any():\n        raise ValueError(\"Zero or infinite position found in chs\")\n    pos -= (x, y, z)\n\n    # Project onto a unit sphere to compute the cosine similarity:\n    pos /= np.linalg.norm(pos, axis=1, keepdims=True)\n    cos_dist = np.clip(np.dot(pos, pos.T), -1, 1)\n    # This is equivalent to doing one minus half the squared Euclidean:\n    # from scipy.spatial.distance import squareform, pdist\n    # cos_dist = 1 - squareform(pdist(pos, 'sqeuclidean')) / 2.\n    del pos\n\n    G = _calc_g(cos_dist, stiffness=stiffness, n_legendre_terms=n_legendre_terms)\n    H = _calc_h(cos_dist, stiffness=stiffness, n_legendre_terms=n_legendre_terms)\n\n    G_precomputed = _prepare_G(G, lambda2)\n\n    trans_csd = _compute_csd(G_precomputed=G_precomputed, H=H, radius=radius)\n\n    epochs = [inst._data] if not isinstance(inst, BaseEpochs) else inst._data\n    for epo in epochs:\n        epo[picks] = np.dot(trans_csd, epo[picks])\n    with inst.info._unlock():\n        inst.info[\"custom_ref_applied\"] = FIFF.FIFFV_MNE_CUSTOM_REF_CSD\n    for pick in picks:\n        inst.info[\"chs\"][pick].update(\n            coil_type=FIFF.FIFFV_COIL_EEG_CSD, unit=FIFF.FIFF_UNIT_V_M2\n        )\n\n    # Remove rejection thresholds for EEG\n    if isinstance(inst, BaseEpochs):\n        if inst.reject and \"eeg\" in inst.reject:\n            del inst.reject[\"eeg\"]\n        if inst.flat and \"eeg\" in inst.flat:\n            del inst.flat[\"eeg\"]\n\n    return inst", "metadata": {}}
{"_id": "mne_mne_preprocessing/_csd.py_compute_bridged_electrodes_code", "title": "compute_bridged_electrodes", "text": "def compute_bridged_electrodes(\n    inst,\n    lm_cutoff=16,\n    epoch_threshold=0.5,\n    l_freq=0.5,\n    h_freq=30,\n    epoch_duration=2,\n    bw_method=None,\n    verbose=None,\n):\n    r\"\"\"Compute bridged EEG electrodes using the intrinsic Hjorth algorithm.\n\n    First, an electrical distance matrix is computed by taking the pairwise\n    variance between electrodes. Local minimums in this matrix below\n    ``lm_cutoff`` are indicative of bridging between a pair of electrodes.\n    Pairs of electrodes are marked as bridged as long as their electrical\n    distance is below ``lm_cutoff`` on more than the ``epoch_threshold``\n    proportion of epochs.\n\n    Based on :footcite:`TenkeKayser2001,GreischarEtAl2004,DelormeMakeig2004`\n    and the `EEGLAB implementation\n    <https://psychophysiology.cpmc.columbia.edu/>`__.\n\n    Parameters\n    ----------\n    inst : instance of Raw, Epochs or Evoked\n        The data to compute electrode bridging on.\n    lm_cutoff : float\n        The distance in :math:`{\\mu}V^2` cutoff below which to\n        search for a local minimum (lm) indicative of bridging.\n        EEGLAB defaults to 5 :math:`{\\mu}V^2`. MNE defaults to\n        16 :math:`{\\mu}V^2` to be conservative based on the distributions in\n        :footcite:t:`GreischarEtAl2004`.\n    epoch_threshold : float\n        The proportion of epochs with electrical distance less than\n        ``lm_cutoff`` in order to consider the channel bridged.\n        The default is 0.5.\n    l_freq : float\n        The low cutoff frequency to use. Default is 0.5 Hz.\n    h_freq : float\n        The high cutoff frequency to use. Default is 30 Hz.\n    epoch_duration : float\n        The time in seconds to divide the raw into fixed-length epochs\n        to check for consistent bridging. Only used if ``inst`` is\n        :class:`mne.io.BaseRaw`. The default is 2 seconds.\n    bw_method : None\n        ``bw_method`` to pass to :class:`scipy.stats.gaussian_kde`.\n    %(verbose)s\n\n    Returns\n    -------\n    bridged_idx : list of tuple\n        The indices of channels marked as bridged with each bridged\n        pair stored as a tuple.\n    ed_matrix : ndarray of float, shape (n_epochs, n_channels, n_channels)\n        The electrical distance matrix for each pair of EEG electrodes.\n\n    Notes\n    -----\n    .. versionadded:: 1.1\n\n    References\n    ----------\n    .. footbibliography::\n    \"\"\"\n    _check_preload(inst, \"Computing bridged electrodes\")\n    inst = inst.copy()  # don't modify original\n    picks = pick_types(inst.info, eeg=True)\n    if len(picks) == 0:\n        raise RuntimeError(\"No EEG channels found, cannot compute electrode bridging\")\n    # first, filter\n    inst.filter(l_freq=l_freq, h_freq=h_freq, picks=picks, verbose=False)\n\n    if isinstance(inst, BaseRaw):\n        inst = make_fixed_length_epochs(\n            inst, duration=epoch_duration, preload=True, verbose=False\n        )\n\n    # standardize shape\n    data = inst.get_data(picks=picks)\n    if isinstance(inst, Evoked):\n        data = data[np.newaxis, ...]  # expand evoked\n\n    # next, compute electrical distance matrix, upper triangular\n    n_epochs = data.shape[0]\n    ed_matrix = np.zeros((n_epochs, picks.size, picks.size)) * np.nan\n    for i in range(picks.size):\n        for j in range(i + 1, picks.size):\n            ed_matrix[:, i, j] = np.var(data[:, i] - data[:, j], axis=1)\n\n    # scale, fill in other half, diagonal\n    ed_matrix *= 1e12  # scale to muV**2\n\n    # initialize bridged indices\n    bridged_idx = list()\n\n    # if not enough values below local minimum cutoff, return no bridges\n    ed_flat = ed_matrix[~np.isnan(ed_matrix)]\n    if ed_flat[ed_flat < lm_cutoff].size / n_epochs < epoch_threshold:\n        return bridged_idx, ed_matrix\n\n    # kernel density estimation\n    kde = gaussian_kde(ed_flat[ed_flat < lm_cutoff], bw_method=bw_method)\n    with np.errstate(invalid=\"ignore\"):\n        local_minimum = float(\n            minimize_scalar(\n                lambda x: kde(x) if x < lm_cutoff and x > 0 else np.inf\n            ).x.item()\n        )\n    logger.info(f\"Local minimum {local_minimum} found\")\n\n    # find electrodes that are below the cutoff local minimum on\n    # `epochs_threshold` proportion of epochs\n    for i in range(picks.size):\n        for j in range(i + 1, picks.size):\n            bridged_count = np.sum(ed_matrix[:, i, j] < local_minimum)\n            if bridged_count / n_epochs > epoch_threshold:\n                logger.info(\n                    \"Bridge detected between \"\n                    f\"{inst.ch_names[picks[i]]} and \"\n                    f\"{inst.ch_names[picks[j]]}\"\n                )\n                bridged_idx.append((picks[i], picks[j]))\n\n    return bridged_idx, ed_matrix", "metadata": {}}
{"_id": "mne_mne_preprocessing/_regress.py_regress_artifact_code", "title": "regress_artifact", "text": "def regress_artifact(\n    inst,\n    picks=None,\n    *,\n    exclude=\"bads\",\n    picks_artifact=\"eog\",\n    betas=None,\n    proj=True,\n    copy=True,\n    verbose=None,\n):\n    \"\"\"Remove artifacts using regression based on reference channels.\n\n    Parameters\n    ----------\n    inst : instance of Epochs | Raw\n        The instance to process.\n    %(picks_good_data)s\n    exclude : list | 'bads'\n        List of channels to exclude from the regression, only used when picking\n        based on types (e.g., exclude=\"bads\" when picks=\"meg\").\n        Specify ``'bads'`` (the default) to exclude all channels marked as bad.\n\n        .. versionadded:: 1.2\n    picks_artifact : array-like | str\n        Channel picks to use as predictor/explanatory variables capturing\n        the artifact of interest (default is \"eog\").\n    betas : ndarray, shape (n_picks, n_picks_ref) | None\n        The regression coefficients to use. If None (default), they will be\n        estimated from the data.\n    proj : bool\n        Whether to automatically apply SSP projection vectors before performing\n        the regression. Default is ``True``.\n    copy : bool\n        If True (default), copy the instance before modifying it.\n    %(verbose)s\n\n    Returns\n    -------\n    inst : instance of Epochs | Raw\n        The processed data.\n    betas : ndarray, shape (n_picks, n_picks_ref)\n        The betas used during regression.\n\n    Notes\n    -----\n    To implement the method outlined in :footcite:`GrattonEtAl1983`,\n    remove the evoked response from epochs before estimating the\n    regression coefficients, then apply those regression coefficients to the\n    original data in two calls like (here for a single-condition ``epochs``\n    only):\n\n        >>> epochs_no_ave = epochs.copy().subtract_evoked()  # doctest:+SKIP\n        >>> _, betas = mne.preprocessing.regress(epochs_no_ave)  # doctest:+SKIP\n        >>> epochs_clean, _ = mne.preprocessing.regress(epochs, betas=betas)  # doctest:+SKIP\n\n    References\n    ----------\n    .. footbibliography::\n    \"\"\"  # noqa: E501\n    if betas is None:\n        model = EOGRegression(\n            picks=picks, exclude=exclude, picks_artifact=picks_artifact, proj=proj\n        )\n        model.fit(inst)\n    else:\n        # Create an EOGRegression object and load the given betas into it.\n        picks = _picks_to_idx(inst.info, picks, exclude=exclude, none=\"data\")\n        picks_artifact = _picks_to_idx(inst.info, picks_artifact)\n        want_betas_shape = (len(picks), len(picks_artifact))\n        _check_option(\"betas.shape\", betas.shape, (want_betas_shape,))\n        model = EOGRegression(picks, picks_artifact, proj=proj)\n        model.info_ = inst.info.copy()\n        model.coef_ = betas\n    return model.apply(inst, copy=copy), model.coef_", "metadata": {}}
{"_id": "mne_mne_preprocessing/_regress.py_read_eog_regression_code", "title": "read_eog_regression", "text": "def read_eog_regression(fname):\n    \"\"\"Read an EOG regression model from an HDF5 file.\n\n    Parameters\n    ----------\n    fname : path-like\n        The file to read the regression model from. Should end in ``.h5``.\n\n    Returns\n    -------\n    model : EOGRegression\n        The regression model read from the file.\n\n    Notes\n    -----\n    .. versionadded:: 1.2\n    \"\"\"\n    read_hdf5, _ = _import_h5io_funcs()\n    _validate_type(fname, \"path-like\", \"fname\")\n    fname = _check_fname(fname, overwrite=\"read\", must_exist=True, name=\"fname\")\n    model = EOGRegression()\n    model.__dict__.update(read_hdf5(fname))\n    return model", "metadata": {}}
{"_id": "mne_mne_preprocessing/_regress.py_fit_code", "title": "fit", "text": "def fit(self, inst):\n        \"\"\"Fit EOG regression coefficients.\n\n        Parameters\n        ----------\n        inst : Raw | Epochs | Evoked\n            The data on which the EOG regression weights should be fitted.\n\n        Returns\n        -------\n        self : EOGRegression\n            The fitted ``EOGRegression`` object. The regression coefficients\n            are available as the ``.coef_`` and ``.intercept_`` attributes.\n\n        Notes\n        -----\n        If your data contains EEG channels, make sure to apply the desired\n        reference (see :func:`mne.set_eeg_reference`) before performing EOG\n        regression.\n        \"\"\"\n        picks, picks_artifact = self._check_inst(inst)\n\n        # Calculate regression coefficients. Add a row of ones to also fit the\n        # intercept.\n        _check_preload(inst, \"artifact regression\")\n        artifact_data = inst._data[..., picks_artifact, :]\n        ref_data = artifact_data - np.mean(artifact_data, axis=-1, keepdims=True)\n        if ref_data.ndim == 3:\n            ref_data = ref_data.transpose(1, 0, 2)\n            ref_data = ref_data.reshape(len(picks_artifact), -1)\n        cov_ref = ref_data @ ref_data.T\n\n        # Process each channel separately to reduce memory load\n        coef = np.zeros((len(picks), len(picks_artifact)))\n        for pi, pick in enumerate(picks):\n            this_data = inst._data[..., pick, :]  # view\n            # Subtract mean over time from every trial/channel\n            cov_data = this_data - np.mean(this_data, -1, keepdims=True)\n            cov_data = cov_data.reshape(1, -1)\n            # Perform the linear regression\n            coef[pi] = np.linalg.solve(cov_ref, ref_data @ cov_data.T).T[0]\n\n        # Store relevant parameters in the object.\n        self.coef_ = coef\n        self.info_ = inst.info.copy()\n        return self", "metadata": {}}
{"_id": "mne_mne_preprocessing/_regress.py_apply_code", "title": "apply", "text": "def apply(self, inst, copy=True):\n        \"\"\"Apply the regression coefficients to data.\n\n        Parameters\n        ----------\n        inst : Raw | Epochs | Evoked\n            The data on which to apply the regression.\n        %(copy_df)s\n\n        Returns\n        -------\n        inst : Raw | Epochs | Evoked\n            A version of the data with the artifact channels regressed out.\n\n        Notes\n        -----\n        Only works after ``.fit()`` has been used.\n\n        References\n        ----------\n        .. footbibliography::\n        \"\"\"\n        if copy:\n            inst = inst.copy()\n        picks, picks_artifact = self._check_inst(inst)\n\n        # Check that the channels are compatible with the regression weights.\n        ref_picks = _picks_to_idx(\n            self.info_, self.picks, none=\"data\", exclude=self.exclude\n        )\n        ref_picks_artifact = _picks_to_idx(self.info_, self.picks_artifact)\n        if any(\n            inst.ch_names[ch1] != self.info_[\"chs\"][ch2][\"ch_name\"]\n            for ch1, ch2 in zip(picks, ref_picks)\n        ):\n            raise ValueError(\n                \"Selected data channels are not compatible with \"\n                \"the regression weights. Make sure that all data \"\n                \"channels are present and in the correct order.\"\n            )\n        if any(\n            inst.ch_names[ch1] != self.info_[\"chs\"][ch2][\"ch_name\"]\n            for ch1, ch2 in zip(picks_artifact, ref_picks_artifact)\n        ):\n            raise ValueError(\n                \"Selected artifact channels are not compatible \"\n                \"with the regression weights. Make sure that all \"\n                \"artifact channels are present and in the \"\n                \"correct order.\"\n            )\n\n        _check_preload(inst, \"artifact regression\")\n        artifact_data = inst._data[..., picks_artifact, :]\n        ref_data = artifact_data - np.mean(artifact_data, -1, keepdims=True)\n        for pi, pick in enumerate(picks):\n            this_data = inst._data[..., pick, :]  # view\n            this_data -= (self.coef_[pi] @ ref_data).reshape(this_data.shape)\n        return inst", "metadata": {}}
{"_id": "mne_mne_preprocessing/_regress.py_save_code", "title": "save", "text": "def save(self, fname, overwrite=False):\n        \"\"\"Save the regression model to an HDF5 file.\n\n        Parameters\n        ----------\n        fname : path-like\n            The file to write the regression weights to. Should end in ``.h5``.\n        %(overwrite)s\n        \"\"\"\n        _, write_hdf5 = _import_h5io_funcs()\n        _validate_type(fname, \"path-like\", \"fname\")\n        fname = _check_fname(fname, overwrite=overwrite, name=\"fname\")\n        write_hdf5(fname, self.__dict__, overwrite=overwrite)", "metadata": {}}
{"_id": "mne_mne_preprocessing/_annotate_amplitude.py_annotate_amplitude_code", "title": "annotate_amplitude", "text": "def annotate_amplitude(\n    raw,\n    peak=None,\n    flat=None,\n    bad_percent=5,\n    min_duration=0.005,\n    picks=None,\n    *,\n    verbose=None,\n):\n    \"\"\"Annotate raw data based on peak-to-peak amplitude.\n\n    Creates annotations ``BAD_peak`` or ``BAD_flat`` for spans of data where\n    consecutive samples exceed the threshold in ``peak`` or fall below the\n    threshold in ``flat`` for more than ``min_duration``.\n    Channels where more than ``bad_percent`` of the total recording length\n    should be annotated with either ``BAD_peak`` or ``BAD_flat`` are returned\n    in ``bads`` instead.\n    Note that the annotations and the bads are not automatically added to the\n    :class:`~mne.io.Raw` object; use :meth:`~mne.io.Raw.set_annotations` and\n    :class:`info['bads'] <mne.Info>` to do so.\n\n    Parameters\n    ----------\n    raw : instance of Raw\n        The raw data.\n    peak : float | dict | None\n        Annotate segments based on **maximum** peak-to-peak signal amplitude\n        (PTP). Valid **keys** can be any channel type present in the object.\n        The **values** are floats that set the maximum acceptable PTP. If the\n        PTP is larger than this threshold, the segment will be annotated.\n        If float, the minimum acceptable PTP is applied to all channels.\n    flat : float | dict | None\n        Annotate segments based on **minimum** peak-to-peak signal amplitude\n        (PTP). Valid **keys** can be any channel type present in the object.\n        The **values** are floats that set the minimum acceptable PTP. If the\n        PTP is smaller than this threshold, the segment will be annotated.\n        If float, the minimum acceptable PTP is applied to all channels.\n    bad_percent : float\n        The percentage of the time a channel can be above or below thresholds.\n        Below this percentage, :class:`~mne.Annotations` are created.\n        Above this percentage, the channel involved is return in ``bads``. Note\n        the returned ``bads`` are not automatically added to\n        :class:`info['bads'] <mne.Info>`.\n        Defaults to ``5``, i.e. 5%%.\n    min_duration : float\n        The minimum duration (s) required by consecutives samples to be above\n        ``peak`` or below ``flat`` thresholds to be considered.\n        to consider as above or below threshold.\n        For some systems, adjacent time samples with exactly the same value are\n        not totally uncommon. Defaults to ``0.005`` (5 ms).\n    %(picks_good_data)s\n    %(verbose)s\n\n    Returns\n    -------\n    annotations : instance of Annotations\n        The annotated bad segments.\n    bads : list\n        The channels detected as bad.\n\n    Notes\n    -----\n    This function does not use a window to detect small peak-to-peak or large\n    peak-to-peak amplitude changes as the ``reject`` and ``flat`` argument from\n    :class:`~mne.Epochs` does. Instead, it looks at the difference between\n    consecutive samples.\n\n    - When used to detect segments below ``flat``, at least ``min_duration``\n      seconds of consecutive samples must respect\n      ``abs(a[i+1] - a[i]) \u2264 flat``.\n    - When used to detect segments above ``peak``, at least ``min_duration``\n      seconds of consecutive samples must respect\n      ``abs(a[i+1] - a[i]) \u2265 peak``.\n\n    Thus, this function does not detect every temporal event with large\n    peak-to-peak amplitude, but only the ones where the peak-to-peak amplitude\n    is supra-threshold between consecutive samples. For instance, segments\n    experiencing a DC shift will not be picked up. Only the edges from the DC\n    shift will be annotated (and those only if the edge transitions are longer\n    than ``min_duration``).\n\n    This function may perform faster if data is loaded in memory, as it\n    loads data one channel type at a time (across all time points), which is\n    typically not an efficient way to read raw data from disk.\n\n    .. versionadded:: 1.0\n    \"\"\"\n    _validate_type(raw, BaseRaw, \"raw\")\n    picks_ = _picks_to_idx(raw.info, picks, \"data_or_ica\", exclude=\"bads\")\n    peak = _check_ptp(peak, \"peak\", raw.info, picks_)\n    flat = _check_ptp(flat, \"flat\", raw.info, picks_)\n    if peak is None and flat is None:\n        raise ValueError(\n            \"At least one of the arguments 'peak' or 'flat' must not be None.\"\n        )\n    bad_percent = _check_bad_percent(bad_percent)\n    min_duration = _check_min_duration(\n        min_duration, raw.times.size * 1 / raw.info[\"sfreq\"]\n    )\n    min_duration_samples = int(np.round(min_duration * raw.info[\"sfreq\"]))\n    bads = list()\n\n    # grouping picks by channel types to avoid operating on each channel\n    # individually\n    picks = {\n        ch_type: np.intersect1d(picks_of_type, picks_, assume_unique=True)\n        for ch_type, picks_of_type in _picks_by_type(raw.info, exclude=\"bads\")\n        if np.intersect1d(picks_of_type, picks_, assume_unique=True).size != 0\n    }\n    del picks_  # reusing this variable name in for loop\n\n    # skip BAD_acq_skip sections\n    onsets, ends = _annotations_starts_stops(raw, \"bad_acq_skip\", invert=True)\n    index = np.concatenate(\n        [np.arange(raw.times.size)[onset:end] for onset, end in zip(onsets, ends)]\n    )\n\n    # size matching the diff a[i+1] - a[i]\n    any_flat = np.zeros(len(raw.times) - 1, bool)\n    any_peak = np.zeros(len(raw.times) - 1, bool)\n\n    # look for discrete difference above or below thresholds\n    logger.info(\"Finding segments below or above PTP threshold.\")\n    for ch_type, picks_ in picks.items():\n        data = np.concatenate(\n            [raw[picks_, onset:end][0] for onset, end in zip(onsets, ends)], axis=1\n        )\n        diff = np.abs(np.diff(data, axis=1))\n\n        if flat is not None:\n            flat_ = diff <= flat[ch_type]\n            # reject too short segments\n            flat_ = _reject_short_segments(flat_, min_duration_samples)\n            # reject channels above maximum bad_percentage\n            flat_count = flat_.sum(axis=1)\n            flat_count[np.nonzero(flat_count)] += 1  # offset by 1 due to diff\n            flat_mean = flat_count / raw.times.size * 100\n            flat_ch_to_set_bad = picks_[np.where(flat_mean >= bad_percent)[0]]\n            bads.extend(flat_ch_to_set_bad)\n            # add onset/offset for annotations\n            flat_ch_to_annotate = np.where((0 < flat_mean) & (flat_mean < bad_percent))[\n                0\n            ]\n            # convert from raw.times[onset:end] - 1 to raw.times[:] - 1\n            idx = index[np.where(flat_[flat_ch_to_annotate, :])[1]]\n            any_flat[idx] = True\n\n        if peak is not None:\n            peak_ = diff >= peak[ch_type]\n            # reject too short segments\n            peak_ = _reject_short_segments(peak_, min_duration_samples)\n            # reject channels above maximum bad_percentage\n            peak_count = peak_.sum(axis=1)\n            peak_count[np.nonzero(peak_count)] += 1  # offset by 1 due to diff\n            peak_mean = peak_count / raw.times.size * 100\n            peak_ch_to_set_bad = picks_[np.where(peak_mean >= bad_percent)[0]]\n            bads.extend(peak_ch_to_set_bad)\n            # add onset/offset for annotations\n            peak_ch_to_annotate = np.where((0 < peak_mean) & (peak_mean < bad_percent))[\n                0\n            ]\n            # convert from raw.times[onset:end] - 1 to raw.times[:] - 1\n            idx = index[np.where(peak_[peak_ch_to_annotate, :])[1]]\n            any_peak[idx] = True\n\n    # annotation for flat\n    annotation_flat = _create_annotations(any_flat, \"flat\", raw)\n    # annotation for peak\n    annotation_peak = _create_annotations(any_peak, \"peak\", raw)\n    # group\n    annotations = annotation_flat + annotation_peak\n    # bads\n    bads = [raw.ch_names[bad] for bad in bads if bad not in raw.info[\"bads\"]]\n\n    return annotations, bads", "metadata": {}}
{"_id": "mne_mne_preprocessing/_css.py_cortical_signal_suppression_code", "title": "cortical_signal_suppression", "text": "def cortical_signal_suppression(\n    evoked, picks=None, mag_picks=None, grad_picks=None, n_proj=6, *, verbose=None\n):\n    \"\"\"Apply cortical signal suppression (CSS) to evoked data.\n\n    Parameters\n    ----------\n    evoked : instance of Evoked\n        The evoked object to use for CSS. Must contain magnetometer,\n        gradiometer, and EEG channels.\n    %(picks_good_data)s\n    mag_picks : array-like of int\n        Array of the first set of channel indices that will be used to find\n        the common temporal subspace. If None (default), all magnetometers will\n        be used.\n    grad_picks : array-like of int\n        Array of the second set of channel indices that will be used to find\n        the common temporal subspace. If None (default), all gradiometers will\n        be used.\n    n_proj : int\n        The number of projection vectors.\n    %(verbose)s\n\n    Returns\n    -------\n    evoked_subcortical : instance of Evoked\n        The evoked object with contributions from the ``mag_picks`` and ``grad_picks``\n        channels removed from the ``picks`` channels.\n\n    Notes\n    -----\n    This method removes the common signal subspace between two sets of\n    channels (``mag_picks`` and ``grad_picks``) from a set of channels\n    (``picks``) via a temporal projection using ``n_proj`` number of\n    projection vectors. In the reference publication :footcite:`Samuelsson2019`,\n    the joint subspace between magnetometers and gradiometers is used to\n    suppress the cortical signal in the EEG data. In principle, other\n    combinations of sensor types (or channels) could be used to suppress\n    signals from other sources.\n\n    References\n    ----------\n    .. footbibliography::\n    \"\"\"\n    _validate_type(evoked, Evoked, \"evoked\")\n    n_proj = _ensure_int(n_proj, \"n_proj\")\n    picks = _picks_to_idx(evoked.info, picks, none=\"data\", exclude=\"bads\")\n    mag_picks = _picks_to_idx(evoked.info, mag_picks, none=\"mag\", exclude=\"bads\")\n    grad_picks = _picks_to_idx(evoked.info, grad_picks, none=\"grad\", exclude=\"bads\")\n    evoked_subcortical = evoked.copy()\n\n    # Get data\n    all_data = evoked.data\n    mag_data = all_data[mag_picks]\n    grad_data = all_data[grad_picks]\n\n    # Process data with temporal projection algorithm\n    data = all_data[picks]\n    _temp_proj(mag_data, grad_data, data, n_proj=n_proj)\n    evoked_subcortical.data[picks, :] = data\n\n    return evoked_subcortical", "metadata": {}}
{"_id": "mne_mne_preprocessing/_annotate_nan.py_annotate_nan_code", "title": "annotate_nan", "text": "def annotate_nan(raw, *, verbose=None):\n    \"\"\"Detect segments with NaN and return a new Annotations instance.\n\n    Parameters\n    ----------\n    raw : instance of Raw\n        Data to find segments with NaN values.\n    %(verbose)s\n\n    Returns\n    -------\n    annot : instance of Annotations\n        New channel-specific annotations for the data.\n    \"\"\"\n    data, times = raw.get_data(return_times=True)\n    onsets, durations, ch_names = list(), list(), list()\n    for row, ch_name in zip(data, raw.ch_names):\n        annot = _annotations_from_mask(times, np.isnan(row), \"BAD_NAN\")\n        onsets.extend(annot.onset)\n        durations.extend(annot.duration)\n        ch_names.extend([[ch_name]] * len(annot))\n    annot = Annotations(\n        onsets, durations, \"BAD_NAN\", ch_names=ch_names, orig_time=raw.info[\"meas_date\"]\n    )\n    _adjust_onset_meas_date(annot, raw)\n    return annot", "metadata": {}}
{"_id": "mne_mne_preprocessing/maxwell.py_maxwell_filter_prepare_emptyroom_code", "title": "maxwell_filter_prepare_emptyroom", "text": "def maxwell_filter_prepare_emptyroom(\n    raw_er,\n    *,\n    raw,\n    bads=\"from_raw\",\n    annotations=\"from_raw\",\n    meas_date=\"keep\",\n    emit_warning=False,\n    verbose=None,\n):\n    \"\"\"Prepare an empty-room recording for Maxwell filtering.\n\n    Empty-room data by default lacks certain properties that are required to\n    ensure running :func:`~mne.preprocessing.maxwell_filter` will process the\n    empty-room recording the same way as the experimental data. This function\n    preconditions an empty-room raw data instance accordingly so it can be used\n    for Maxwell filtering. Please see the ``Notes`` section for details.\n\n    Parameters\n    ----------\n    raw_er : instance of Raw\n        The empty-room recording. It will not be modified.\n    raw : instance of Raw\n        The experimental recording, typically this will be the reference run\n        used for Maxwell filtering.\n    bads : 'from_raw' | 'union' | 'keep'\n        How to populate the list of bad channel names to be injected into\n        the empty-room recording. If ``'from_raw'`` (default) the list of bad\n        channels will be overwritten with that of ``raw``. If ``'union'``, will\n        use the union of bad channels in ``raw`` and ``raw_er``. Note that\n        this may lead to additional bad channels in the empty-room in\n        comparison to the experimental recording. If ``'keep'``, don't alter\n        the existing list of bad channels.\n\n        .. note::\n           Non-MEG channels are silently dropped from the list of bads.\n    annotations : 'from_raw' | 'union' | 'keep'\n        Whether to copy the annotations over from ``raw`` (default),\n        use the union of the annotations, or to keep them unchanged.\n    meas_date : 'keep' | 'from_raw'\n        Whether to transfer the measurement date from ``raw`` or to keep\n        it as is (default). If you intend to manually transfer annotations\n        from ``raw`` **after** running this function, you should set this to\n        ``'from_raw'``.\n    %(emit_warning)s\n        Unlike :meth:`raw.set_annotations <mne.io.Raw.set_annotations>`, the\n        default here is ``False``, as empty-room recordings are often shorter\n        than raw.\n    %(verbose)s\n\n    Returns\n    -------\n    raw_er_prepared : instance of Raw\n        A copy of the passed empty-room recording, ready for Maxwell filtering.\n\n    Notes\n    -----\n    This function will:\n\n    * Compile the list of bad channels according to the ``bads`` parameter.\n    * Inject the device-to-head transformation matrix from the experimental\n      recording into the empty-room recording.\n    * Set the following properties of the empty-room recording to match the\n      experimental recording:\n\n      * Montage\n      * ``raw.first_time`` and ``raw.first_samp``\n\n    * Adjust annotations according to the ``annotations`` parameter.\n    * Adjust the measurement date according to the ``meas_date`` parameter.\n\n    .. versionadded:: 1.1\n    \"\"\"  # noqa: E501\n    _validate_type(item=raw_er, types=BaseRaw, item_name=\"raw_er\")\n    _validate_type(item=raw, types=BaseRaw, item_name=\"raw\")\n    _validate_type(item=bads, types=str, item_name=\"bads\")\n    _check_option(\n        parameter=\"bads\", value=bads, allowed_values=[\"from_raw\", \"union\", \"keep\"]\n    )\n    _validate_type(item=annotations, types=str, item_name=\"annotations\")\n    _check_option(\n        parameter=\"annotations\",\n        value=annotations,\n        allowed_values=[\"from_raw\", \"union\", \"keep\"],\n    )\n    _validate_type(item=meas_date, types=str, item_name=\"meas_date\")\n    _check_option(\n        parameter=\"meas_date\", value=annotations, allowed_values=[\"from_raw\", \"keep\"]\n    )\n\n    raw_er_prepared = raw_er.copy()\n    del raw_er  # just to be sure\n\n    # handle bads; only keep MEG channels\n    if bads == \"from_raw\":\n        bads = raw.info[\"bads\"]\n    elif bads == \"union\":\n        bads = sorted(set(raw.info[\"bads\"] + raw_er_prepared.info[\"bads\"]))\n    elif bads == \"keep\":\n        bads = raw_er_prepared.info[\"bads\"]\n\n    bads = [ch_name for ch_name in bads if ch_name.startswith(\"MEG\")]\n    raw_er_prepared.info[\"bads\"] = bads\n\n    # handle dev_head_t\n    raw_er_prepared.info[\"dev_head_t\"] = raw.info[\"dev_head_t\"]\n\n    # handle montage\n    montage = raw.get_montage()\n    raw_er_prepared.set_montage(montage)\n\n    # handle first_samp\n    raw_er_prepared.annotations.onset += raw.first_time - raw_er_prepared.first_time\n    # don't copy _cropped_samp directly, as sfreqs may differ\n    raw_er_prepared._cropped_samp = raw_er_prepared.time_as_index(raw.first_time).item()\n\n    # handle annotations\n    if annotations != \"keep\":\n        er_annot = raw_er_prepared.annotations\n        if annotations == \"from_raw\":\n            er_annot.delete(np.arange(len(er_annot)))\n        er_annot.append(\n            raw.annotations.onset,\n            raw.annotations.duration,\n            raw.annotations.description,\n            raw.annotations.ch_names,\n        )\n        if raw_er_prepared.info[\"meas_date\"] is None:\n            er_annot.onset -= raw_er_prepared.first_time\n        raw_er_prepared.set_annotations(er_annot, emit_warning)\n\n    # handle measurement date\n    if meas_date == \"from_raw\":\n        raw_er_prepared.set_meas_date(raw.info[\"meas_date\"])\n\n    return raw_er_prepared", "metadata": {}}
{"_id": "mne_mne_preprocessing/maxwell.py_maxwell_filter_code", "title": "maxwell_filter", "text": "def maxwell_filter(\n    raw,\n    origin=\"auto\",\n    int_order=8,\n    ext_order=3,\n    calibration=None,\n    cross_talk=None,\n    st_duration=None,\n    st_correlation=0.98,\n    coord_frame=\"head\",\n    destination=None,\n    regularize=\"in\",\n    ignore_ref=False,\n    bad_condition=\"error\",\n    head_pos=None,\n    st_fixed=True,\n    st_only=False,\n    mag_scale=100.0,\n    skip_by_annotation=(\"edge\", \"bad_acq_skip\"),\n    extended_proj=(),\n    st_overlap=None,\n    mc_interp=None,\n    verbose=None,\n):\n    \"\"\"Maxwell filter data using multipole moments.\n\n    Parameters\n    ----------\n    raw : instance of Raw\n        Data to be filtered.\n\n        .. warning:: It is critical to mark bad channels in\n                     ``raw.info['bads']`` prior to processing in order to\n                     prevent artifact spreading. Manual inspection and use\n                     of :func:`~find_bad_channels_maxwell` is recommended.\n    %(origin_maxwell)s\n    %(int_order_maxwell)s\n    %(ext_order_maxwell)s\n    %(calibration_maxwell_cal)s\n    %(cross_talk_maxwell)s\n    st_duration : float | None\n        If not None, apply spatiotemporal SSS with specified buffer duration\n        (in seconds). MaxFilter\u2122's default is 10.0 seconds in v2.2.\n        Spatiotemporal SSS acts as implicitly as a high-pass filter where the\n        cut-off frequency is 1/st_duration Hz. For this (and other) reasons,\n        longer buffers are generally better as long as your system can handle\n        the higher memory usage. To ensure that each window is processed\n        identically, choose a buffer length that divides evenly into your data.\n        Any data at the trailing edge that doesn't fit evenly into a whole\n        buffer window will be lumped into the previous buffer.\n    st_correlation : float\n        Correlation limit between inner and outer subspaces used to reject\n        overlapping intersecting inner/outer signals during spatiotemporal SSS.\n    %(coord_frame_maxwell)s\n    %(destination_maxwell_dest)s\n    %(regularize_maxwell_reg)s\n    %(ignore_ref_maxwell)s\n    %(bad_condition_maxwell_cond)s\n    %(head_pos_maxwell)s\n\n        .. versionadded:: 0.12\n    %(st_fixed_maxwell_only)s\n    %(mag_scale_maxwell)s\n\n        .. versionadded:: 0.13\n    %(skip_by_annotation_maxwell)s\n\n        .. versionadded:: 0.17\n    %(extended_proj_maxwell)s\n    st_overlap : bool\n        If True (default in 1.11), tSSS processing will use a constant\n        overlap-add method. If False (default in 1.10), then\n        non-overlapping windows will be used.\n\n        .. versionadded:: 1.10\n    %(maxwell_mc_interp)s\n    %(verbose)s\n\n    Returns\n    -------\n    raw_sss : instance of Raw\n        The raw data with Maxwell filtering applied.\n\n    See Also\n    --------\n    mne.preprocessing.annotate_amplitude\n    mne.preprocessing.find_bad_channels_maxwell\n    mne.chpi.filter_chpi\n    mne.chpi.read_head_pos\n    mne.epochs.average_movements\n\n    Notes\n    -----\n    .. versionadded:: 0.11\n\n    Some of this code was adapted and relicensed (with BSD form) with\n    permission from Jussi Nurminen. These algorithms are based on work\n    from :footcite:`TauluKajola2005` and :footcite:`TauluSimola2006`.\n    It will likely use multiple CPU cores, see the :ref:`FAQ <faq_cpu>`\n    for more information.\n\n    .. warning:: Maxwell filtering in MNE is not designed or certified\n                 for clinical use.\n\n    Compared to the MEGIN MaxFilter\u2122 2.2.11 software, the MNE Maxwell filtering\n    routines currently provide the following features:\n\n    .. table::\n       :widths: auto\n\n       +-----------------------------------------------------------------------------+-----+-----------+\n       | Feature                                                                     | MNE | MaxFilter |\n       +=============================================================================+=====+===========+\n       | Maxwell filtering software shielding                                        | \u2713   | \u2713         |\n       +-----------------------------------------------------------------------------+-----+-----------+\n       | Bad channel reconstruction                                                  | \u2713   | \u2713         |\n       +-----------------------------------------------------------------------------+-----+-----------+\n       | Cross-talk cancellation                                                     | \u2713   | \u2713         |\n       +-----------------------------------------------------------------------------+-----+-----------+\n       | Fine calibration correction (1D)                                            | \u2713   | \u2713         |\n       +-----------------------------------------------------------------------------+-----+-----------+\n       | Fine calibration correction (3D)                                            | \u2713   |           |\n       +-----------------------------------------------------------------------------+-----+-----------+\n       | Spatio-temporal SSS (tSSS)                                                  | \u2713   | \u2713         |\n       +-----------------------------------------------------------------------------+-----+-----------+\n       | Coordinate frame translation                                                | \u2713   | \u2713         |\n       +-----------------------------------------------------------------------------+-----+-----------+\n       | Regularization using information theory                                     | \u2713   | \u2713         |\n       +-----------------------------------------------------------------------------+-----+-----------+\n       | Movement compensation (raw)                                                 | \u2713   | \u2713         |\n       +-----------------------------------------------------------------------------+-----+-----------+\n       | Movement compensation (:func:`epochs <mne.epochs.average_movements>`)       | \u2713   |           |\n       +-----------------------------------------------------------------------------+-----+-----------+\n       | :func:`cHPI subtraction <mne.chpi.filter_chpi>`                             | \u2713   | \u2713         |\n       +-----------------------------------------------------------------------------+-----+-----------+\n       | Double floating point precision                                             | \u2713   |           |\n       +-----------------------------------------------------------------------------+-----+-----------+\n       | Seamless processing of split (``-1.fif``) and concatenated files            | \u2713   |           |\n       +-----------------------------------------------------------------------------+-----+-----------+\n       | Automatic bad channel detection (:func:`~find_bad_channels_maxwell`)        | \u2713   | \u2713         |\n       +-----------------------------------------------------------------------------+-----+-----------+\n       | Head position estimation (:func:`~mne.chpi.compute_head_pos`)               | \u2713   | \u2713         |\n       +-----------------------------------------------------------------------------+-----+-----------+\n       | Overlap-add processing for spatio-temporal projections                      | \u2713   |           |\n       +-----------------------------------------------------------------------------+-----+-----------+\n       | Smooth interpolation in movement compensation                               | \u2713   |           |\n       +-----------------------------------------------------------------------------+-----+-----------+\n       | Certified for clinical use                                                  |     | \u2713         |\n       +-----------------------------------------------------------------------------+-----+-----------+\n       | Extended external basis (eSSS)                                              | \u2713   |           |\n       +-----------------------------------------------------------------------------+-----+-----------+\n\n    Epoch-based movement compensation is described in :footcite:`TauluKajola2005`.\n\n    Use of Maxwell filtering routines with non-Neuromag systems is currently\n    **experimental**. Worse results for non-Neuromag systems are expected due\n    to (at least):\n\n    * Missing fine-calibration and cross-talk cancellation data for\n      other systems.\n    * Processing with reference sensors has not been vetted.\n    * Regularization of components may not work well for all systems.\n    * Coil integration has not been optimized using Abramowitz/Stegun\n      definitions.\n\n    .. note:: Various Maxwell filtering algorithm components are covered by\n              patents owned by MEGIN. These patents include, but may not be\n              limited to:\n\n              - US2006031038 (Signal Space Separation)\n              - US6876196 (Head position determination)\n              - WO2005067789 (DC fields)\n              - WO2005078467 (MaxShield)\n              - WO2006114473 (Temporal Signal Space Separation)\n\n              These patents likely preclude the use of Maxwell filtering code\n              in commercial applications. Consult a lawyer if necessary.\n\n    Currently, in order to perform Maxwell filtering, the raw data must not\n    have any projectors applied. During Maxwell filtering, the spatial\n    structure of the data is modified, so projectors are discarded (unless\n    in ``st_only=True`` mode).\n\n    References\n    ----------\n    .. footbibliography::\n    \"\"\"  # noqa: E501\n    logger.info(\"Maxwell filtering raw data\")\n    params = _prep_maxwell_filter(\n        raw=raw,\n        origin=origin,\n        int_order=int_order,\n        ext_order=ext_order,\n        calibration=calibration,\n        cross_talk=cross_talk,\n        st_duration=st_duration,\n        st_correlation=st_correlation,\n        coord_frame=coord_frame,\n        destination=destination,\n        regularize=regularize,\n        ignore_ref=ignore_ref,\n        bad_condition=bad_condition,\n        head_pos=head_pos,\n        st_fixed=st_fixed,\n        st_only=st_only,\n        mag_scale=mag_scale,\n        skip_by_annotation=skip_by_annotation,\n        extended_proj=extended_proj,\n        st_overlap=st_overlap,\n        mc_interp=mc_interp,\n    )\n    raw_sss = _run_maxwell_filter(raw, **params)\n    # Update info\n    _update_sss_info(raw_sss, **params[\"update_kwargs\"])\n    logger.info(\"[done]\")\n    return raw_sss", "metadata": {}}
{"_id": "mne_mne_preprocessing/maxwell.py_find_bad_channels_maxwell_code", "title": "find_bad_channels_maxwell", "text": "def find_bad_channels_maxwell(\n    raw,\n    limit=7.0,\n    duration=5.0,\n    min_count=5,\n    return_scores=False,\n    origin=\"auto\",\n    int_order=8,\n    ext_order=3,\n    calibration=None,\n    cross_talk=None,\n    coord_frame=\"head\",\n    regularize=\"in\",\n    ignore_ref=False,\n    bad_condition=\"error\",\n    head_pos=None,\n    mag_scale=100.0,\n    skip_by_annotation=(\"edge\", \"bad_acq_skip\"),\n    h_freq=40.0,\n    extended_proj=(),\n    mc_interp=None,\n    verbose=None,\n):\n    r\"\"\"Find bad channels using Maxwell filtering.\n\n    Parameters\n    ----------\n    raw : instance of Raw\n        Raw data to process.\n    limit : float\n        Detection limit for noisy segments (default is 7.). Smaller values will\n        find more bad channels at increased risk of including good ones. This\n        value can be interpreted as the standard score of differences between\n        the original and Maxwell-filtered data. See the ``Notes`` section for\n        details.\n\n        .. note:: This setting only concerns *noisy* channel detection.\n                  The limit for *flat* channel detection currently cannot be\n                  controlled by the user. Flat channel detection is always run\n                  before noisy channel detection.\n    duration : float\n        Duration of the segments into which to slice the data for processing,\n        in seconds. Default is 5.\n    min_count : int\n        Minimum number of times a channel must show up as bad in a chunk.\n        Default is 5.\n    return_scores : bool\n        If ``True``, return a dictionary with scoring information for each\n        evaluated segment of the data. Default is ``False``.\n\n        .. warning:: This feature is experimental and may change in a future\n                     version of MNE-Python without prior notice. Please\n                     report any problems and enhancement proposals to the\n                     developers.\n\n        .. versionadded:: 0.21\n    %(origin_maxwell)s\n    %(int_order_maxwell)s\n    %(ext_order_maxwell)s\n    %(calibration_maxwell_cal)s\n    %(cross_talk_maxwell)s\n    %(coord_frame_maxwell)s\n    %(regularize_maxwell_reg)s\n    %(ignore_ref_maxwell)s\n    %(bad_condition_maxwell_cond)s\n    %(head_pos_maxwell)s\n    %(mag_scale_maxwell)s\n    %(skip_by_annotation_maxwell)s\n    h_freq : float | None\n        The cutoff frequency (in Hz) of the low-pass filter that will be\n        applied before processing the data. This defaults to ``40.``, which\n        should provide similar results to MaxFilter. If you do not wish to\n        apply a filter, set this to ``None``.\n    %(extended_proj_maxwell)s\n    %(maxwell_mc_interp)s\n    %(verbose)s\n\n    Returns\n    -------\n    noisy_chs : list\n        List of bad MEG channels that were automatically detected as being\n        noisy among the good MEG channels.\n    flat_chs : list\n        List of MEG channels that were detected as being flat in at least\n        ``min_count`` segments.\n    scores : dict\n        A dictionary with information produced by the scoring algorithms.\n        Only returned when ``return_scores`` is ``True``. It contains the\n        following keys:\n\n        - ``ch_names`` : ndarray, shape (n_meg,)\n            The names of the MEG channels. Their order corresponds to the\n            order of rows in the ``scores`` and ``limits`` arrays.\n        - ``ch_types`` : ndarray, shape (n_meg,)\n            The types of the MEG channels in ``ch_names`` (``'mag'``,\n            ``'grad'``).\n        - ``bins`` : ndarray, shape (n_windows, 2)\n            The inclusive window boundaries (start and stop; in seconds) used\n            to calculate the scores.\n        - ``scores_flat`` : ndarray, shape (n_meg, n_windows)\n            The scores for testing whether MEG channels are flat. These values\n            correspond to the standard deviation of a segment.\n            See the ``Notes`` section for details.\n        - ``limits_flat`` : ndarray, shape (n_meg, 1)\n            The score thresholds (in standard deviation) above which a segment\n            was classified as \"flat\".\n        - ``scores_noisy`` : ndarray, shape (n_meg, n_windows)\n            The scores for testing whether MEG channels are noisy. These values\n            correspond to the standard score of a segment.\n            See the ``Notes`` section for details.\n        - ``limits_noisy`` : ndarray, shape (n_meg, 1)\n            The score thresholds (in standard scores) above which a segment was\n            classified as \"noisy\".\n\n        .. note:: The scores and limits for channels marked as ``bad`` in the\n                  input data will be set to ``np.nan``.\n\n    See Also\n    --------\n    annotate_amplitude\n    maxwell_filter\n\n    Notes\n    -----\n    All arguments after ``raw``, ``limit``, ``duration``, ``min_count``, and\n    ``return_scores`` are the same as :func:`~maxwell_filter`, except that the\n    following are not allowed in this function because they are unused:\n    ``st_duration``, ``st_correlation``, ``destination``, ``st_fixed``, and\n    ``st_only``.\n\n    This algorithm, for a given chunk of data:\n\n    1. Runs SSS on the data, without removing external components.\n    2. Excludes channels as *flat* that have had low variability\n       (standard deviation < 0.01 fT or fT/cm in a 30 ms window) in the given\n       or any previous chunk.\n    3. For each channel :math:`k`, computes the *range* or peak-to-peak\n       :math:`d_k` of the difference between the reconstructed and original\n       data.\n    4. Computes the average :math:`\\mu_d` and standard deviation\n       :math:`\\sigma_d` of the differences (after scaling magnetometer data\n       to roughly match the scale of the gradiometer data using ``mag_scale``).\n    5. Marks channels as bad for the chunk when\n       :math:`d_k > \\mu_d + \\textrm{limit} \\times \\sigma_d`. Note that this\n       expression can be easily transformed into\n       :math:`(d_k - \\mu_d) / \\sigma_d > \\textrm{limit}`, which is equivalent\n       to :math:`z(d_k) > \\textrm{limit}`, with :math:`z(d_k)` being the\n       standard or z-score of the difference.\n\n    Data are processed in chunks of the given ``duration``, and channels that\n    are bad for at least ``min_count`` chunks are returned.\n\n    Channels marked as *flat* in step 2 are excluded from all subsequent steps\n    of noisy channel detection.\n\n    This algorithm gives results similar to, but not identical with,\n    MaxFilter. Differences arise because MaxFilter processes on a\n    buffer-by-buffer basis (using buffer-size-dependent downsampling logic),\n    uses different filtering characteristics, and possibly other factors.\n    Channels that are near the ``limit`` for a given ``min_count`` are\n    particularly susceptible to being different between the two\n    implementations.\n\n    .. versionadded:: 0.20\n    \"\"\"\n    if h_freq is not None:\n        if raw.info.get(\"lowpass\") and raw.info[\"lowpass\"] <= h_freq:\n            freq_loc = \"below\" if raw.info[\"lowpass\"] < h_freq else \"equal to\"\n            msg = (\n                f\"The input data has already been low-pass filtered with a \"\n                f\"{raw.info['lowpass']} Hz cutoff frequency, which is \"\n                f\"{freq_loc} the requested cutoff of {h_freq} Hz. Not \"\n                f\"applying low-pass filter.\"\n            )\n            logger.info(msg)\n        else:\n            logger.info(\n                f\"Applying low-pass filter with {h_freq} Hz cutoff frequency ...\"\n            )\n            raw = raw.copy().load_data().filter(l_freq=None, h_freq=h_freq)\n\n    limit = float(limit)\n    onsets, ends = _annotations_starts_stops(raw, skip_by_annotation, invert=True)\n    del skip_by_annotation\n    # operate on chunks\n    starts = list()\n    stops = list()\n    step = int(round(raw.info[\"sfreq\"] * duration))\n    for onset, end in zip(onsets, ends):\n        if end - onset >= step:\n            ss = np.arange(onset, end - step + 1, step)\n            starts.extend(ss)\n            ss = ss + step\n            ss[-1] = end\n            stops.extend(ss)\n    min_count = min(_ensure_int(min_count, \"min_count\"), len(starts))\n    logger.info(\n        \"Scanning for bad channels in %d interval%s (%0.1f s) ...\",\n        len(starts),\n        _pl(starts),\n        step / raw.info[\"sfreq\"],\n    )\n    params = _prep_maxwell_filter(\n        raw,\n        skip_by_annotation=[],  # already accounted for\n        origin=origin,\n        int_order=int_order,\n        ext_order=ext_order,\n        calibration=calibration,\n        cross_talk=cross_talk,\n        coord_frame=coord_frame,\n        regularize=regularize,\n        ignore_ref=ignore_ref,\n        bad_condition=bad_condition,\n        head_pos=head_pos,\n        mag_scale=mag_scale,\n        extended_proj=extended_proj,\n        reconstruct=\"orig\",\n    )\n    del origin, int_order, ext_order, calibration, cross_talk, coord_frame\n    del regularize, ignore_ref, bad_condition, head_pos, mag_scale\n    good_meg_picks = params[\"meg_picks\"][params[\"good_mask\"]]\n    assert len(params[\"meg_picks\"]) == len(params[\"coil_scale\"])\n    assert len(params[\"good_mask\"]) == len(params[\"meg_picks\"])\n    noisy_chs = Counter()\n    flat_chs = Counter()\n    flat_limits = dict(grad=0.01e-13, mag=0.01e-15)\n    these_limits = np.array(\n        [\n            flat_limits[\"grad\"] if pick in params[\"grad_picks\"] else flat_limits[\"mag\"]\n            for pick in good_meg_picks\n        ]\n    )\n\n    flat_step = max(20, int(30 * raw.info[\"sfreq\"] / 1000.0))\n    all_flats = set()\n\n    # Prepare variables to return if `return_scores=True`.\n    bins = np.empty((len(starts), 2))  # To store start, stop of each segment\n    # We create ndarrays with one row per channel, regardless of channel type\n    # and whether the channel has been marked as \"bad\" in info or not. This\n    # makes indexing in the loop easier. We only filter this down to the subset\n    # of MEG channels after all processing is done.\n    ch_names = np.array(raw.ch_names)\n    ch_types = np.array(raw.get_channel_types())\n\n    scores_flat = np.full((len(ch_names), len(starts)), np.nan)\n    scores_noisy = np.full_like(scores_flat, fill_value=np.nan)\n\n    thresh_flat = np.full((len(ch_names), 1), np.nan)\n    thresh_noisy = np.full_like(thresh_flat, fill_value=np.nan)\n\n    for si, (start, stop) in enumerate(zip(starts, stops)):\n        n_iter = 0\n        orig_data = raw.get_data(None, start, stop, verbose=False)\n        chunk_raw = RawArray(\n            orig_data,\n            params[\"info\"],\n            first_samp=raw.first_samp + start,\n            copy=\"data\",\n            verbose=False,\n        )\n\n        t = chunk_raw.times[[0, -1]] + start / raw.info[\"sfreq\"]\n        logger.info(f\"        Interval {si + 1:3d}: {t[0]:8.3f} - {t[-1]:8.3f}\")\n\n        # Flat pass: SD < 0.01 fT/cm or 0.01 fT for at 30 ms (or 20 samples)\n        n = stop - start\n        flat_stop = n - (n % flat_step)\n        data = chunk_raw.get_data(good_meg_picks, 0, flat_stop)\n        data.shape = (data.shape[0], -1, flat_step)\n        delta = np.std(data, axis=-1).min(-1)  # min std across segments\n\n        # We may want to return this later if `return_scores=True`.\n        bins[si, :] = t[0], t[-1]\n        scores_flat[good_meg_picks, si] = delta\n        thresh_flat[good_meg_picks] = these_limits.reshape(-1, 1)\n\n        chunk_flats = delta < these_limits\n        chunk_flats = np.where(chunk_flats)[0]\n        chunk_flats = [\n            raw.ch_names[good_meg_picks[chunk_flat]] for chunk_flat in chunk_flats\n        ]\n        flat_chs.update(chunk_flats)\n        all_flats |= set(chunk_flats)\n        chunk_flats = sorted(all_flats)\n        these_picks = [\n            pick for pick in good_meg_picks if raw.ch_names[pick] not in chunk_flats\n        ]\n        if len(these_picks) == 0:\n            logger.info(f\"            Flat ({len(chunk_flats):2d}): <all>\")\n            warn(\n                \"All-flat segment detected, all channels will be marked as \"\n                f\"flat and processing will stop (t={t[0]:0.3f}). \"\n                \"Consider using annotate_amplitude before calling this \"\n                'function with skip_by_annotation=\"bad_flat\" (or similar) to '\n                \"properly process all segments.\"\n            )\n            break  # no reason to continue\n        # Bad pass\n        chunk_noisy = list()\n        params[\"st_duration\"] = int(round(chunk_raw.times[-1] * raw.info[\"sfreq\"]))\n        for n_iter in range(1, 101):  # iteratively exclude the worst ones\n            assert set(raw.info[\"bads\"]) & set(chunk_noisy) == set()\n            params[\"good_mask\"][:] = [\n                chunk_raw.ch_names[pick]\n                not in raw.info[\"bads\"] + chunk_noisy + chunk_flats\n                for pick in params[\"meg_picks\"]\n            ]\n            chunk_raw._data[:] = orig_data\n            delta = chunk_raw.get_data(these_picks)\n            with use_log_level(_verbose_safe_false()):\n                _run_maxwell_filter(chunk_raw, copy=False, **params)\n\n            if n_iter == 1 and len(chunk_flats):\n                logger.info(\n                    \"            Flat (%2d): %s\",\n                    len(chunk_flats),\n                    \" \".join(chunk_flats),\n                )\n            delta -= chunk_raw.get_data(these_picks)\n            # p2p\n            range_ = np.ptp(delta, axis=-1)\n            cs_picks = np.searchsorted(params[\"meg_picks\"], these_picks)\n            range_ *= params[\"coil_scale\"][cs_picks, 0]\n            mean, std = np.mean(range_), np.std(range_)\n            # z score\n            z = (range_ - mean) / std\n            idx = np.argmax(z)\n            max_ = z[idx]\n\n            # We may want to return this later if `return_scores=True`.\n            scores_noisy[these_picks, si] = z\n            thresh_noisy[these_picks] = limit\n\n            if max_ < limit:\n                break\n\n            name = raw.ch_names[these_picks[idx]]\n            logger.debug(f\"            Bad:       {name} {max_:0.1f}\")\n            these_picks.pop(idx)\n            chunk_noisy.append(name)\n        noisy_chs.update(chunk_noisy)\n    noisy_chs = sorted(\n        (b for b, c in noisy_chs.items() if c >= min_count),\n        key=lambda x: raw.ch_names.index(x),\n    )\n    flat_chs = sorted(\n        (f for f, c in flat_chs.items() if c >= min_count),\n        key=lambda x: raw.ch_names.index(x),\n    )\n\n    # Only include MEG channels.\n    ch_names = ch_names[params[\"meg_picks\"]]\n    ch_types = ch_types[params[\"meg_picks\"]]\n    scores_flat = scores_flat[params[\"meg_picks\"]]\n    thresh_flat = thresh_flat[params[\"meg_picks\"]]\n    scores_noisy = scores_noisy[params[\"meg_picks\"]]\n    thresh_noisy = thresh_noisy[params[\"meg_picks\"]]\n\n    logger.info(f\"    Static bad channels:  {noisy_chs}\")\n    logger.info(f\"    Static flat channels: {flat_chs}\")\n    logger.info(\"[done]\")\n\n    if return_scores:\n        scores = dict(\n            ch_names=ch_names,\n            ch_types=ch_types,\n            bins=bins,\n            scores_flat=scores_flat,\n            limits_flat=thresh_flat,\n            scores_noisy=scores_noisy,\n            limits_noisy=thresh_noisy,\n        )\n        return noisy_chs, flat_chs, scores\n    else:\n        return noisy_chs, flat_chs", "metadata": {}}
{"_id": "mne_mne_preprocessing/maxwell.py_compute_maxwell_basis_code", "title": "compute_maxwell_basis", "text": "def compute_maxwell_basis(\n    info,\n    origin=\"auto\",\n    int_order=8,\n    ext_order=3,\n    calibration=None,\n    coord_frame=\"head\",\n    regularize=\"in\",\n    ignore_ref=True,\n    bad_condition=\"error\",\n    mag_scale=100.0,\n    extended_proj=(),\n    verbose=None,\n):\n    r\"\"\"Compute the SSS basis for a given measurement info structure.\n\n    Parameters\n    ----------\n    %(info_not_none)s\n    %(origin_maxwell)s\n    %(int_order_maxwell)s\n    %(ext_order_maxwell)s\n    %(calibration_maxwell_cal)s\n    %(coord_frame_maxwell)s\n    %(regularize_maxwell_reg)s\n    %(ignore_ref_maxwell)s\n    %(bad_condition_maxwell_cond)s\n    %(mag_scale_maxwell)s\n    %(extended_proj_maxwell)s\n    %(verbose)s\n\n    Returns\n    -------\n    S : ndarray, shape (n_meg, n_moments)\n        The basis that can be used to reconstruct the data.\n    pS : ndarray, shape (n_moments, n_good_meg)\n        The (stabilized) pseudoinverse of the S array.\n    reg_moments : ndarray, shape (n_moments,)\n        The moments that were kept after regularization.\n    n_use_in : int\n        The number of kept moments that were in the internal space.\n\n    Notes\n    -----\n    This outputs variants of :math:`\\mathbf{S}` and :math:`\\mathbf{S^\\dagger}`\n    from equations 27 and 37 of :footcite:`TauluKajola2005` with the coil scale\n    for magnetometers already factored in so that the resulting denoising\n    transform of the data to obtain :math:`\\hat{\\phi}_{in}` from equation\n    38 would be::\n\n        phi_in = S[:, :n_use_in] @ pS[:n_use_in] @ data_meg_good\n\n    .. versionadded:: 0.23\n\n    References\n    ----------\n    .. footbibliography::\n    \"\"\"\n    _validate_type(info, Info, \"info\")\n    raw = RawArray(np.zeros((len(info[\"ch_names\"]), 1)), info.copy(), verbose=False)\n    logger.info(\"Computing Maxwell basis\")\n    params = _prep_maxwell_filter(\n        raw=raw,\n        origin=origin,\n        int_order=int_order,\n        ext_order=ext_order,\n        calibration=calibration,\n        coord_frame=coord_frame,\n        destination=None,\n        regularize=regularize,\n        ignore_ref=ignore_ref,\n        bad_condition=bad_condition,\n        mag_scale=mag_scale,\n        extended_proj=extended_proj,\n    )\n    _, S_decomp_full, pS_decomp, reg_moments, n_use_in = params[\n        \"_get_this_decomp_trans\"\n    ](info[\"dev_head_t\"], t=0.0)\n    return S_decomp_full, pS_decomp, reg_moments, n_use_in", "metadata": {}}
{"_id": "mne_mne_preprocessing/maxwell.py_initialize_code", "title": "initialize", "text": "def initialize(self, get_decomp, dev_head_t, S_recon):\n        \"\"\"Secondary initialization.\"\"\"\n        self.smooth = _Interp2(\n            self.pos[1],\n            self.get_decomp_by_offset,\n            interp=self.interp,\n            name=\"MC\",\n        )\n        _, _, pS_decomp, self.reg_moments_0, _ = get_decomp(dev_head_t, t=0.0)\n        self.n_good = pS_decomp.shape[1]\n        self.S_recon = S_recon\n        self.offset = 0\n        self.get_decomp = get_decomp\n        # For the average passes\n        self.last_avg_quat = np.nan * np.ones(6)", "metadata": {}}
{"_id": "mne_mne_preprocessing/maxwell.py_get_avg_op_code", "title": "get_avg_op", "text": "def get_avg_op(self, *, start, stop):\n        \"\"\"Apply an average transformation over the next interval.\"\"\"\n        n_positions, avg_quat = _trans_lims(self.pos, start, stop)[1:]\n        if not np.allclose(avg_quat, self.last_avg_quat, atol=1e-7):\n            self.last_avg_quat = avg_quat\n            avg_trans = np.vstack(\n                [\n                    np.hstack([quat_to_rot(avg_quat[:3]), avg_quat[3:][:, np.newaxis]]),\n                    [[0.0, 0.0, 0.0, 1.0]],\n                ]\n            )\n            S_decomp_st, _, pS_decomp_st, _, n_use_in_st = self.get_decomp(\n                avg_trans, t=start / self.sfreq\n            )\n            self.op_in_avg = np.dot(\n                S_decomp_st[:, :n_use_in_st], pS_decomp_st[:n_use_in_st]\n            )\n            self.op_resid_avg = (\n                np.eye(len(self.op_in_avg))\n                - self.op_in_avg\n                - np.dot(S_decomp_st[:, n_use_in_st:], pS_decomp_st[n_use_in_st:])\n            )\n        return self.op_in_avg, self.op_resid_avg, n_positions", "metadata": {}}
{"_id": "mne_mne_preprocessing/xdawn.py_fit_code", "title": "fit", "text": "def fit(self, X, y=None):\n        \"\"\"Fit Xdawn spatial filters.\n\n        Parameters\n        ----------\n        X : array, shape (n_epochs, n_channels, n_samples)\n            The target data.\n        y : array, shape (n_epochs,) | None\n            The target labels. If None, Xdawn fit on the average evoked.\n\n        Returns\n        -------\n        self : Xdawn instance\n            The Xdawn instance.\n        \"\"\"\n        X, y = self._check_Xy(X, y)\n\n        # Main function\n        self.classes_ = np.unique(y)\n        self.filters_, self.patterns_, _ = _fit_xdawn(\n            X,\n            y,\n            n_components=self.n_components,\n            reg=self.reg,\n            signal_cov=self.signal_cov,\n            method_params=self.method_params,\n        )\n        return self", "metadata": {}}
{"_id": "mne_mne_preprocessing/xdawn.py_transform_code", "title": "transform", "text": "def transform(self, X):\n        \"\"\"Transform data with spatial filters.\n\n        Parameters\n        ----------\n        X : array, shape (n_epochs, n_channels, n_samples)\n            The target data.\n\n        Returns\n        -------\n        X : array, shape (n_epochs, n_components * n_classes, n_samples)\n            The transformed data.\n        \"\"\"\n        X, _ = self._check_Xy(X)\n\n        # Check size\n        if self.filters_.shape[1] != X.shape[1]:\n            raise ValueError(\n                f\"X must have {self.filters_.shape[1]} channels, got {X.shape[1]} \"\n                \"instead.\"\n            )\n\n        # Transform\n        X = np.dot(self.filters_, X)\n        X = X.transpose((1, 0, 2))\n        return X", "metadata": {}}
{"_id": "mne_mne_preprocessing/xdawn.py_inverse_transform_code", "title": "inverse_transform", "text": "def inverse_transform(self, X):\n        \"\"\"Remove selected components from the signal.\n\n        Given the unmixing matrix, transform data, zero out components,\n        and inverse transform the data. This procedure will reconstruct\n        the signals from which the dynamics described by the excluded\n        components is subtracted.\n\n        Parameters\n        ----------\n        X : array, shape (n_epochs, n_components * n_classes, n_times)\n            The transformed data.\n\n        Returns\n        -------\n        X : array, shape (n_epochs, n_channels * n_classes, n_times)\n            The inverse transform data.\n        \"\"\"\n        # Check size\n        X, _ = self._check_Xy(X)\n        n_epochs, n_comp, n_times = X.shape\n        if n_comp != (self.n_components * len(self.classes_)):\n            raise ValueError(\n                f\"X must have {self.n_components * len(self.classes_)} components, \"\n                f\"got {n_comp} instead.\"\n            )\n\n        # Transform\n        return np.dot(self.patterns_.T, X).transpose(1, 0, 2)", "metadata": {}}
{"_id": "mne_mne_preprocessing/xdawn.py_fit_code", "title": "fit", "text": "def fit(self, epochs, y=None):\n        \"\"\"Fit Xdawn from epochs.\n\n        Parameters\n        ----------\n        epochs : instance of Epochs\n            An instance of Epoch on which Xdawn filters will be fitted.\n        y : ndarray | None (default None)\n            If None, used epochs.events[:, 2].\n\n        Returns\n        -------\n        self : instance of Xdawn\n            The Xdawn instance.\n        \"\"\"\n        # Check data\n        if not isinstance(epochs, BaseEpochs):\n            raise ValueError(\"epochs must be an Epochs object.\")\n        picks = _pick_data_channels(epochs.info)\n        use_info = pick_info(epochs.info, picks)\n        X = epochs.get_data(picks)\n        y = epochs.events[:, 2] if y is None else y\n        self.event_id_ = epochs.event_id\n\n        # Check that no baseline was applied with correct overlap\n        correct_overlap = self.correct_overlap\n        if correct_overlap == \"auto\":\n            # Events are overlapped if the minimal inter-stimulus\n            # interval is smaller than the time window.\n            isi = np.diff(np.sort(epochs.events[:, 0]))\n            window = int((epochs.tmax - epochs.tmin) * epochs.info[\"sfreq\"])\n            correct_overlap = isi.min() < window\n\n        if epochs.baseline and correct_overlap:\n            raise ValueError(\"Cannot apply correct_overlap if epochs were baselined.\")\n\n        events, tmin, sfreq = None, 0.0, 1.0\n        if correct_overlap:\n            events = epochs.events\n            tmin = epochs.tmin\n            sfreq = epochs.info[\"sfreq\"]\n        self.correct_overlap_ = correct_overlap\n\n        # Note: In this original version of Xdawn we compute and keep all\n        # components. The selection comes at transform().\n        n_components = X.shape[1]\n\n        # Main fitting function\n        filters, patterns, evokeds = _fit_xdawn(\n            X,\n            y,\n            n_components=n_components,\n            reg=self.reg,\n            signal_cov=self.signal_cov,\n            events=events,\n            tmin=tmin,\n            sfreq=sfreq,\n            method_params=self.method_params,\n            info=use_info,\n        )\n\n        # Re-order filters and patterns according to event_id\n        filters = filters.reshape(-1, n_components, filters.shape[-1])\n        patterns = patterns.reshape(-1, n_components, patterns.shape[-1])\n        self.filters_, self.patterns_, self.evokeds_ = dict(), dict(), dict()\n        idx = np.argsort([value for _, value in epochs.event_id.items()])\n        for eid, this_filter, this_pattern, this_evo in zip(\n            epochs.event_id, filters[idx], patterns[idx], evokeds[idx]\n        ):\n            self.filters_[eid] = this_filter\n            self.patterns_[eid] = this_pattern\n            n_events = len(epochs[eid])\n            evoked = EvokedArray(\n                this_evo, use_info, tmin=epochs.tmin, comment=eid, nave=n_events\n            )\n            self.evokeds_[eid] = evoked\n        return self", "metadata": {}}
{"_id": "mne_mne_preprocessing/xdawn.py_transform_code", "title": "transform", "text": "def transform(self, inst):\n        \"\"\"Apply Xdawn dim reduction.\n\n        Parameters\n        ----------\n        inst : Epochs | Evoked | ndarray, shape ([n_epochs, ]n_channels, n_times)\n            Data on which Xdawn filters will be applied.\n\n        Returns\n        -------\n        X : ndarray, shape ([n_epochs, ]n_components * n_event_types, n_times)\n            Spatially filtered signals.\n        \"\"\"  # noqa: E501\n        if isinstance(inst, BaseEpochs):\n            X = inst.get_data(copy=False)\n        elif isinstance(inst, Evoked):\n            X = inst.data\n        elif isinstance(inst, np.ndarray):\n            X = inst\n            if X.ndim not in (2, 3):\n                raise ValueError(f\"X must be 2D or 3D, got {X.ndim}\")\n        else:\n            raise ValueError(\"Data input must be of Epoch type or numpy array\")\n\n        filters = [filt[: self.n_components] for filt in self.filters_.values()]\n        filters = np.concatenate(filters, axis=0)\n        X = np.dot(filters, X)\n        if X.ndim == 3:\n            X = X.transpose((1, 0, 2))\n        return X", "metadata": {}}
{"_id": "mne_mne_preprocessing/xdawn.py_apply_code", "title": "apply", "text": "def apply(self, inst, event_id=None, include=None, exclude=None):\n        \"\"\"Remove selected components from the signal.\n\n        Given the unmixing matrix, transform data,\n        zero out components, and inverse transform the data.\n        This procedure will reconstruct the signals from which\n        the dynamics described by the excluded components is subtracted.\n\n        Parameters\n        ----------\n        inst : instance of Raw | Epochs | Evoked\n            The data to be processed.\n        event_id : dict | list of str | None (default None)\n            The kind of event to apply. if None, a dict of inst will be return\n            one for each type of event xdawn has been fitted.\n        include : array_like of int | None (default None)\n            The indices referring to columns in the ummixing matrix. The\n            components to be kept. If None, the first n_components (as defined\n            in the Xdawn constructor) will be kept.\n        exclude : array_like of int | None (default None)\n            The indices referring to columns in the ummixing matrix. The\n            components to be zeroed out. If None, all the components except the\n            first n_components will be exclude.\n\n        Returns\n        -------\n        out : dict\n            A dict of instance (from the same type as inst input) for each\n            event type in event_id.\n        \"\"\"\n        if event_id is None:\n            event_id = self.event_id_\n\n        if not isinstance(inst, BaseRaw | BaseEpochs | Evoked):\n            raise ValueError(\"Data input must be Raw, Epochs or Evoked type\")\n        picks = _pick_data_channels(inst.info)\n\n        # Define the components to keep\n        default_exclude = list(range(self.n_components, len(inst.ch_names)))\n        if exclude is None:\n            exclude = default_exclude\n        else:\n            exclude = list(set(list(default_exclude) + list(exclude)))\n\n        if isinstance(inst, BaseRaw):\n            out = self._apply_raw(\n                raw=inst,\n                include=include,\n                exclude=exclude,\n                event_id=event_id,\n                picks=picks,\n            )\n        elif isinstance(inst, BaseEpochs):\n            out = self._apply_epochs(\n                epochs=inst,\n                include=include,\n                picks=picks,\n                exclude=exclude,\n                event_id=event_id,\n            )\n        elif isinstance(inst, Evoked):\n            out = self._apply_evoked(\n                evoked=inst,\n                include=include,\n                picks=picks,\n                exclude=exclude,\n                event_id=event_id,\n            )\n        return out", "metadata": {}}
{"_id": "mne_mne_preprocessing/xdawn.py_inverse_transform_code", "title": "inverse_transform", "text": "def inverse_transform(self):\n        \"\"\"Not implemented, see Xdawn.apply() instead.\"\"\"\n        # Exists because of _XdawnTransformer\n        raise NotImplementedError(\"See Xdawn.apply()\")", "metadata": {}}
{"_id": "mne_mne_preprocessing/ecg.py_qrs_detector_code", "title": "qrs_detector", "text": "def qrs_detector(\n    sfreq,\n    ecg,\n    thresh_value=0.6,\n    levels=2.5,\n    n_thresh=3,\n    l_freq=5,\n    h_freq=35,\n    tstart=0,\n    filter_length=\"10s\",\n    verbose=None,\n):\n    \"\"\"Detect QRS component in ECG channels.\n\n    QRS is the main wave on the heart beat.\n\n    Parameters\n    ----------\n    sfreq : float\n        Sampling rate\n    ecg : array\n        ECG signal\n    thresh_value : float | str\n        qrs detection threshold. Can also be \"auto\" for automatic\n        selection of threshold.\n    levels : float\n        number of std from mean to include for detection\n    n_thresh : int\n        max number of crossings\n    l_freq : float\n        Low pass frequency\n    h_freq : float\n        High pass frequency\n    %(tstart_ecg)s\n    %(filter_length_ecg)s\n    %(verbose)s\n\n    Returns\n    -------\n    events : array\n        Indices of ECG peaks.\n    \"\"\"\n    win_size = int(round((60.0 * sfreq) / 120.0))\n\n    filtecg = filter_data(\n        ecg,\n        sfreq,\n        l_freq,\n        h_freq,\n        None,\n        filter_length,\n        0.5,\n        0.5,\n        phase=\"zero-double\",\n        fir_window=\"hann\",\n        fir_design=\"firwin2\",\n    )\n\n    ecg_abs = np.abs(filtecg)\n    init = int(sfreq)\n\n    n_samples_start = int(sfreq * tstart)\n    ecg_abs = ecg_abs[n_samples_start:]\n\n    n_points = len(ecg_abs)\n\n    maxpt = np.empty(3)\n    maxpt[0] = np.max(ecg_abs[:init])\n    maxpt[1] = np.max(ecg_abs[init : init * 2])\n    maxpt[2] = np.max(ecg_abs[init * 2 : init * 3])\n\n    init_max = np.mean(maxpt)\n\n    if thresh_value == \"auto\":\n        thresh_runs = np.arange(0.3, 1.1, 0.05)\n    elif isinstance(thresh_value, str):\n        raise ValueError('threshold value must be \"auto\" or a float')\n    else:\n        thresh_runs = [thresh_value]\n\n    # Try a few thresholds (or just one)\n    clean_events = list()\n    for thresh_value in thresh_runs:\n        thresh1 = init_max * thresh_value\n        numcross = list()\n        time = list()\n        rms = list()\n        ii = 0\n        while ii < (n_points - win_size):\n            window = ecg_abs[ii : ii + win_size]\n            if window[0] > thresh1:\n                max_time = np.argmax(window)\n                time.append(ii + max_time)\n                nx = np.sum(\n                    np.diff(((window > thresh1).astype(np.int64) == 1).astype(int))\n                )\n                numcross.append(nx)\n                rms.append(np.sqrt(sum_squared(window) / window.size))\n                ii += win_size\n            else:\n                ii += 1\n\n        if len(rms) == 0:\n            rms.append(0.0)\n            time.append(0.0)\n        time = np.array(time)\n        rms_mean = np.mean(rms)\n        rms_std = np.std(rms)\n        rms_thresh = rms_mean + (rms_std * levels)\n        b = np.where(rms < rms_thresh)[0]\n        a = np.array(numcross)[b]\n        ce = time[b[a < n_thresh]]\n\n        ce += n_samples_start\n        if ce.size > 0:  # We actually found an event\n            clean_events.append(ce)\n\n    if clean_events:\n        # pick the best threshold; first get effective heart rates\n        rates = np.array(\n            [60.0 * len(cev) / (len(ecg) / float(sfreq)) for cev in clean_events]\n        )\n\n        # now find heart rates that seem reasonable (infant through adult\n        # athlete)\n        idx = np.where(np.logical_and(rates <= 160.0, rates >= 40.0))[0]\n        if idx.size > 0:\n            ideal_rate = np.median(rates[idx])  # get close to the median\n        else:\n            ideal_rate = 80.0  # get close to a reasonable default\n\n        idx = np.argmin(np.abs(rates - ideal_rate))\n        clean_events = clean_events[idx]\n    else:\n        clean_events = np.array([])\n\n    return clean_events", "metadata": {}}
{"_id": "mne_mne_preprocessing/ecg.py_find_ecg_events_code", "title": "find_ecg_events", "text": "def find_ecg_events(\n    raw,\n    event_id=999,\n    ch_name=None,\n    tstart=0.0,\n    l_freq=5,\n    h_freq=35,\n    qrs_threshold=\"auto\",\n    filter_length=\"10s\",\n    return_ecg=False,\n    reject_by_annotation=True,\n    verbose=None,\n):\n    \"\"\"Find ECG events by localizing the R wave peaks.\n\n    Parameters\n    ----------\n    raw : instance of Raw\n        The raw data.\n    %(event_id_ecg)s\n    %(ch_name_ecg)s\n    %(tstart_ecg)s\n    %(l_freq_ecg_filter)s\n    qrs_threshold : float | str\n        Between 0 and 1. qrs detection threshold. Can also be \"auto\" to\n        automatically choose the threshold that generates a reasonable\n        number of heartbeats (40-160 beats / min).\n    %(filter_length_ecg)s\n    return_ecg : bool\n        Return the ECG data. This is especially useful if no ECG channel\n        is present in the input data, so one will be synthesized (only works if MEG\n        channels are present in the data). Defaults to ``False``.\n    %(reject_by_annotation_all)s\n\n        .. versionadded:: 0.18\n    %(verbose)s\n\n    Returns\n    -------\n    ecg_events : array\n        The events corresponding to the peaks of the R waves.\n    ch_ecg : int | None\n        Index of channel used.\n    average_pulse : float\n        The estimated average pulse. If no ECG events could be found, this will\n        be zero.\n    ecg : array | None\n        The ECG data of the synthesized ECG channel, if any. This will only\n        be returned if ``return_ecg=True`` was passed.\n\n    See Also\n    --------\n    create_ecg_epochs\n    compute_proj_ecg\n    \"\"\"\n    skip_by_annotation = (\"edge\", \"bad\") if reject_by_annotation else ()\n    del reject_by_annotation\n    idx_ecg = _get_ecg_channel_index(ch_name, raw)\n    if idx_ecg is not None:\n        logger.info(f\"Using channel {raw.ch_names[idx_ecg]} to identify heart beats.\")\n        ecg = raw.get_data(picks=idx_ecg)\n    else:\n        ecg, _ = _make_ecg(raw, start=None, stop=None)\n    assert ecg.ndim == 2 and ecg.shape[0] == 1\n    ecg = ecg[0]\n    # Deal with filtering the same way we do in raw, i.e. filter each good\n    # segment\n    onsets, ends = _annotations_starts_stops(\n        raw, skip_by_annotation, \"reject_by_annotation\", invert=True\n    )\n    ecgs = list()\n    max_idx = (ends - onsets).argmax()\n    for si, (start, stop) in enumerate(zip(onsets, ends)):\n        # Only output filter params once (for info level), and only warn\n        # once about the length criterion (longest segment is too short)\n        use_verbose = verbose if si == max_idx else \"error\"\n        ecgs.append(\n            filter_data(\n                ecg[start:stop],\n                raw.info[\"sfreq\"],\n                l_freq,\n                h_freq,\n                [0],\n                filter_length,\n                0.5,\n                0.5,\n                1,\n                \"fir\",\n                None,\n                copy=False,\n                phase=\"zero-double\",\n                fir_window=\"hann\",\n                fir_design=\"firwin2\",\n                verbose=use_verbose,\n            )\n        )\n    ecg = np.concatenate(ecgs)\n\n    # detecting QRS and generating events. Since not user-controlled, don't\n    # output filter params here (hardcode verbose=False)\n    ecg_events = qrs_detector(\n        raw.info[\"sfreq\"],\n        ecg,\n        tstart=tstart,\n        thresh_value=qrs_threshold,\n        l_freq=None,\n        h_freq=None,\n        verbose=False,\n    )\n\n    # map ECG events back to original times\n    remap = np.empty(len(ecg), int)\n    offset = 0\n    for start, stop in zip(onsets, ends):\n        this_len = stop - start\n        assert this_len >= 0\n        remap[offset : offset + this_len] = np.arange(start, stop)\n        offset += this_len\n    assert offset == len(ecg)\n\n    if ecg_events.size > 0:\n        ecg_events = remap[ecg_events]\n    else:\n        ecg_events = np.array([])\n\n    n_events = len(ecg_events)\n    duration_sec = len(ecg) / raw.info[\"sfreq\"] - tstart\n    duration_min = duration_sec / 60.0\n    average_pulse = n_events / duration_min\n    logger.info(\n        f\"Number of ECG events detected : {n_events} \"\n        f\"(average pulse {average_pulse} / min.)\"\n    )\n\n    ecg_events = np.array(\n        [\n            ecg_events + raw.first_samp,\n            np.zeros(n_events, int),\n            event_id * np.ones(n_events, int),\n        ]\n    ).T\n\n    out = (ecg_events, idx_ecg, average_pulse)\n    ecg = ecg[np.newaxis]  # backward compat output 2D\n    if return_ecg:\n        out += (ecg,)\n    return out", "metadata": {}}
{"_id": "mne_mne_preprocessing/ecg.py_create_ecg_epochs_code", "title": "create_ecg_epochs", "text": "def create_ecg_epochs(\n    raw,\n    ch_name=None,\n    event_id=999,\n    picks=None,\n    tmin=-0.5,\n    tmax=0.5,\n    l_freq=8,\n    h_freq=16,\n    reject=None,\n    flat=None,\n    baseline=None,\n    preload=True,\n    keep_ecg=False,\n    reject_by_annotation=True,\n    decim=1,\n    verbose=None,\n):\n    \"\"\"Conveniently generate epochs around ECG artifact events.\n\n    %(create_ecg_epochs)s\n\n    .. note:: Filtering is only applied to the ECG channel while finding\n                events. The resulting ``ecg_epochs`` will have no filtering\n                applied (i.e., have the same filter properties as the input\n                ``raw`` instance).\n\n    Parameters\n    ----------\n    raw : instance of Raw\n        The raw data.\n    %(ch_name_ecg)s\n    %(event_id_ecg)s\n    %(picks_all)s\n    tmin : float\n        Start time before event.\n    tmax : float\n        End time after event.\n    %(l_freq_ecg_filter)s\n    %(reject_epochs)s\n    %(flat)s\n    %(baseline_epochs)s\n    preload : bool\n        Preload epochs or not (default True). Must be True if\n        keep_ecg is True.\n    keep_ecg : bool\n        When ECG is synthetically created (after picking), should it be added\n        to the epochs? Must be False when synthetic channel is not used.\n        Defaults to False.\n    %(reject_by_annotation_epochs)s\n\n        .. versionadded:: 0.14.0\n    %(decim)s\n\n        .. versionadded:: 0.21.0\n    %(verbose)s\n\n    Returns\n    -------\n    ecg_epochs : instance of Epochs\n        Data epoched around ECG R wave peaks.\n\n    See Also\n    --------\n    find_ecg_events\n    compute_proj_ecg\n\n    Notes\n    -----\n    If you already have a list of R-peak times, or want to compute R-peaks\n    outside MNE-Python using a different algorithm, the recommended approach is\n    to call the :class:`~mne.Epochs` constructor directly, with your R-peaks\n    formatted as an :term:`events` array (here we also demonstrate the relevant\n    default values)::\n\n        mne.Epochs(raw, r_peak_events_array, tmin=-0.5, tmax=0.5,\n                   baseline=None, preload=True, proj=False)  # doctest: +SKIP\n    \"\"\"\n    has_ecg = \"ecg\" in raw or ch_name is not None\n    if keep_ecg and (has_ecg or not preload):\n        raise ValueError(\n            \"keep_ecg can be True only if the ECG channel is \"\n            \"created synthetically and preload=True.\"\n        )\n\n    events, _, _, ecg = find_ecg_events(\n        raw,\n        ch_name=ch_name,\n        event_id=event_id,\n        l_freq=l_freq,\n        h_freq=h_freq,\n        return_ecg=True,\n        reject_by_annotation=reject_by_annotation,\n    )\n\n    picks = _picks_to_idx(raw.info, picks, \"all\", exclude=())\n\n    # create epochs around ECG events and baseline (important)\n    ecg_epochs = Epochs(\n        raw,\n        events=events,\n        event_id=event_id,\n        tmin=tmin,\n        tmax=tmax,\n        proj=False,\n        flat=flat,\n        picks=picks,\n        reject=reject,\n        baseline=baseline,\n        reject_by_annotation=reject_by_annotation,\n        preload=preload,\n        decim=decim,\n    )\n\n    if keep_ecg:\n        # We know we have created a synthetic channel and epochs are preloaded\n        ecg_raw = RawArray(\n            ecg,\n            create_info(\n                ch_names=[\"ECG-SYN\"], sfreq=raw.info[\"sfreq\"], ch_types=[\"ecg\"]\n            ),\n            first_samp=raw.first_samp,\n        )\n        with ecg_raw.info._unlock():\n            ignore = [\"ch_names\", \"chs\", \"nchan\", \"bads\"]\n            for k, v in raw.info.items():\n                if k not in ignore:\n                    ecg_raw.info[k] = v\n        syn_epochs = Epochs(\n            ecg_raw,\n            events=ecg_epochs.events,\n            event_id=event_id,\n            tmin=tmin,\n            tmax=tmax,\n            proj=False,\n            picks=[0],\n            baseline=baseline,\n            decim=decim,\n            preload=True,\n        )\n        ecg_epochs = ecg_epochs.add_channels([syn_epochs])\n\n    return ecg_epochs", "metadata": {}}
{"_id": "mne_mne_preprocessing/stim.py_fix_stim_artifact_code", "title": "fix_stim_artifact", "text": "def fix_stim_artifact(\n    inst,\n    events=None,\n    event_id=None,\n    tmin=0.0,\n    tmax=0.01,\n    *,\n    baseline=None,\n    mode=\"linear\",\n    stim_channel=None,\n    picks=None,\n):\n    \"\"\"Eliminate stimulation's artifacts from instance.\n\n    .. note:: This function operates in-place, consider passing\n              ``inst.copy()`` if this is not desired.\n\n    Parameters\n    ----------\n    inst : instance of Raw or Epochs or Evoked\n        The data.\n    events : array, shape (n_events, 3)\n        The list of events. Required only when inst is Raw.\n    event_id : int\n        The id of the events generating the stimulation artifacts.\n        If None, read all events. Required only when inst is Raw.\n    tmin : float\n        Start time of the interpolation window in seconds.\n    tmax : float\n        End time of the interpolation window in seconds.\n    baseline : None | tuple, shape (2,)\n        The baseline to use when ``mode='constant'``, in which case it\n        must be non-None.\n\n        .. versionadded:: 1.8\n    mode : 'linear' | 'window' | 'constant'\n        Way to fill the artifacted time interval.\n\n        ``\"linear\"``\n            Does linear interpolation.\n        ``\"window\"``\n            Applies a ``(1 - hanning)`` window.\n        ``\"constant\"``\n            Uses baseline average. baseline parameter must be provided.\n\n        .. versionchanged:: 1.8\n           Added the ``\"constant\"`` mode.\n    stim_channel : str | None\n        Stim channel to use.\n    %(picks_all_data)s\n\n    Returns\n    -------\n    inst : instance of Raw or Evoked or Epochs\n        Instance with modified data.\n    \"\"\"\n    _check_option(\"mode\", mode, [\"linear\", \"window\", \"constant\"])\n    s_start = int(np.ceil(inst.info[\"sfreq\"] * tmin))\n    s_end = int(np.ceil(inst.info[\"sfreq\"] * tmax))\n    if mode == \"constant\":\n        _validate_type(\n            baseline, (tuple, list), \"baseline\", extra=\"when mode='constant'\"\n        )\n        _check_option(\"len(baseline)\", len(baseline), [2])\n        for bi, b in enumerate(baseline):\n            _validate_type(\n                b, \"numeric\", f\"baseline[{bi}]\", extra=\"when mode='constant'\"\n            )\n        b_start = int(np.ceil(inst.info[\"sfreq\"] * baseline[0]))\n        b_end = int(np.ceil(inst.info[\"sfreq\"] * baseline[1]))\n    else:\n        b_start = b_end = np.nan\n    if (mode == \"window\") and (s_end - s_start) < 4:\n        raise ValueError(\n            'Time range is too short. Use a larger interval or set mode to \"linear\".'\n        )\n    window = None\n    if mode == \"window\":\n        window = _get_window(s_start, s_end)\n\n    picks = _picks_to_idx(inst.info, picks, \"data\", exclude=())\n\n    _check_preload(inst, \"fix_stim_artifact\")\n    if isinstance(inst, BaseRaw):\n        if events is None:\n            events = find_events(inst, stim_channel=stim_channel)\n        if len(events) == 0:\n            raise ValueError(\"No events are found\")\n        if event_id is None:\n            events_sel = np.arange(len(events))\n        else:\n            events_sel = events[:, 2] == event_id\n        event_start = events[events_sel, 0]\n        data = inst._data\n        for event_idx in event_start:\n            first_samp = int(event_idx) - inst.first_samp + s_start\n            last_samp = int(event_idx) - inst.first_samp + s_end\n            base_t1 = int(event_idx) - inst.first_samp + b_start\n            base_t2 = int(event_idx) - inst.first_samp + b_end\n            _fix_artifact(\n                data, window, picks, first_samp, last_samp, base_t1, base_t2, mode\n            )\n    elif isinstance(inst, BaseEpochs):\n        if inst.reject is not None:\n            raise RuntimeError(\n                \"Reject is already applied. Use reject=None in the constructor.\"\n            )\n        e_start = int(np.ceil(inst.info[\"sfreq\"] * inst.tmin))\n        first_samp = s_start - e_start\n        last_samp = s_end - e_start\n        data = inst._data\n        base_t1 = b_start - e_start\n        base_t2 = b_end - e_start\n        for epoch in data:\n            _fix_artifact(\n                epoch, window, picks, first_samp, last_samp, base_t1, base_t2, mode\n            )\n\n    elif isinstance(inst, Evoked):\n        first_samp = s_start - inst.first\n        last_samp = s_end - inst.first\n        data = inst.data\n        base_t1 = b_start - inst.first\n        base_t2 = b_end - inst.first\n\n        _fix_artifact(\n            data, window, picks, first_samp, last_samp, base_t1, base_t2, mode\n        )\n\n    else:\n        raise TypeError(f\"Not a Raw or Epochs or Evoked (got {type(inst)}).\")\n\n    return inst", "metadata": {}}
{"_id": "mne_mne_preprocessing/interpolate.py_equalize_bads_code", "title": "equalize_bads", "text": "def equalize_bads(insts, interp_thresh=1.0, copy=True):\n    \"\"\"Interpolate or mark bads consistently for a list of instances.\n\n    Once called on a list of instances, the instances can be concatenated\n    as they will have the same list of bad channels.\n\n    Parameters\n    ----------\n    insts : list\n        The list of instances (Evoked, Epochs or Raw) to consider\n        for interpolation. Each instance should have marked channels.\n    interp_thresh : float\n        A float between 0 and 1 (default) that specifies the fraction of time\n        a channel should be good to be eventually interpolated for certain\n        instances. For example if 0.5, a channel which is good at least half\n        of the time will be interpolated in the instances where it is marked\n        as bad. If 1 then channels will never be interpolated and if 0 all bad\n        channels will be systematically interpolated.\n    copy : bool\n        If True then the returned instances will be copies.\n\n    Returns\n    -------\n    insts_bads : list\n        The list of instances, with the same channel(s) marked as bad in all of\n        them, possibly with some formerly bad channels interpolated.\n    \"\"\"\n    if not 0 <= interp_thresh <= 1:\n        raise ValueError(f\"interp_thresh must be between 0 and 1, got {interp_thresh}\")\n\n    all_bads = list(set(chain.from_iterable([inst.info[\"bads\"] for inst in insts])))\n    if isinstance(insts[0], BaseEpochs):\n        durations = [len(inst) * len(inst.times) for inst in insts]\n    else:\n        durations = [len(inst.times) for inst in insts]\n\n    good_times = []\n    for ch_name in all_bads:\n        good_times.append(\n            sum(\n                durations[k]\n                for k, inst in enumerate(insts)\n                if ch_name not in inst.info[\"bads\"]\n            )\n            / np.sum(durations)\n        )\n\n    bads_keep = [ch for k, ch in enumerate(all_bads) if good_times[k] < interp_thresh]\n    if copy:\n        insts = [inst.copy() for inst in insts]\n\n    for inst in insts:\n        if len(set(inst.info[\"bads\"]) - set(bads_keep)):\n            inst.interpolate_bads(exclude=bads_keep)\n        inst.info[\"bads\"] = bads_keep\n\n    return insts", "metadata": {}}
{"_id": "mne_mne_preprocessing/interpolate.py_interpolate_bridged_electrodes_code", "title": "interpolate_bridged_electrodes", "text": "def interpolate_bridged_electrodes(inst, bridged_idx, bad_limit=4):\n    \"\"\"Interpolate bridged electrode pairs.\n\n    Because bridged electrodes contain brain signal, it's just that the\n    signal is spatially smeared between the two electrodes, we can\n    make a virtual channel midway between the bridged pairs and use\n    that to aid in interpolation rather than completely discarding the\n    data from the two channels.\n\n    Parameters\n    ----------\n    inst : instance of Epochs, Evoked, or Raw\n        The data object with channels that are to be interpolated.\n    bridged_idx : list of tuple\n        The indices of channels marked as bridged with each bridged\n        pair stored as a tuple.\n    bad_limit : int\n        The maximum number of electrodes that can be bridged together\n        (included) and interpolated. Above this number, an error will be\n        raised.\n\n        .. versionadded:: 1.2\n\n    Returns\n    -------\n    inst : instance of Epochs, Evoked, or Raw\n        The modified data object.\n\n    See Also\n    --------\n    mne.preprocessing.compute_bridged_electrodes\n    \"\"\"\n    _validate_type(inst, (BaseRaw, BaseEpochs, Evoked))\n    bad_limit = _ensure_int(bad_limit, \"bad_limit\")\n    if bad_limit <= 0:\n        raise ValueError(\n            \"Argument 'bad_limit' should be a strictly positive \"\n            f\"integer. Provided {bad_limit} is invalid.\"\n        )\n    montage = inst.get_montage()\n    if montage is None:\n        raise RuntimeError(\"No channel positions found in ``inst``\")\n    pos = montage.get_positions()\n    if pos[\"coord_frame\"] != \"head\":\n        raise RuntimeError(\n            f\"Montage channel positions must be in ``head`` got {pos['coord_frame']}\"\n        )\n    # store bads orig to put back at the end\n    bads_orig = inst.info[\"bads\"]\n    inst.info[\"bads\"] = list()\n\n    # look for group of bad channels\n    nodes = sorted(set(chain(*bridged_idx)))\n    G_dense = np.zeros((len(nodes), len(nodes)))\n    # fill the edges with a weight of 1\n    for bridge in bridged_idx:\n        idx0 = np.searchsorted(nodes, bridge[0])\n        idx1 = np.searchsorted(nodes, bridge[1])\n        G_dense[idx0, idx1] = 1\n        G_dense[idx1, idx0] = 1\n    # look for connected components\n    _, labels = connected_components(G_dense, directed=False)\n    groups_idx = [[nodes[j] for j in np.where(labels == k)[0]] for k in set(labels)]\n    groups_names = [\n        [inst.info.ch_names[k] for k in group_idx] for group_idx in groups_idx\n    ]\n\n    # warn for all bridged areas that include too many electrodes\n    for group_names in groups_names:\n        if len(group_names) > bad_limit:\n            raise RuntimeError(\n                f\"The channels {', '.join(group_names)} are bridged together \"\n                \"and form a large area of bridged electrodes. Interpolation \"\n                \"might be inaccurate.\"\n            )\n\n    # make virtual channels\n    virtual_chs = dict()\n    bads = set()\n    for k, group_idx in enumerate(groups_idx):\n        group_names = [inst.info.ch_names[k] for k in group_idx]\n        bads = bads.union(group_names)\n        # compute centroid position in spherical \"head\" coordinates\n        pos_virtual = _find_centroid_sphere(pos[\"ch_pos\"], group_names)\n        # create the virtual channel info and set the position\n        virtual_info = create_info([f\"virtual {k + 1}\"], inst.info[\"sfreq\"], \"eeg\")\n        virtual_info[\"chs\"][0][\"loc\"][:3] = pos_virtual\n        # create virtual channel\n        data = inst.get_data(picks=group_names)\n        if isinstance(inst, BaseRaw):\n            data = np.average(data, axis=0).reshape(1, -1)\n            virtual_ch = RawArray(data, virtual_info, first_samp=inst.first_samp)\n        elif isinstance(inst, BaseEpochs):\n            data = np.average(data, axis=1).reshape(len(data), 1, -1)\n            virtual_ch = EpochsArray(data, virtual_info, tmin=inst.tmin)\n        else:  # evoked\n            data = np.average(data, axis=0).reshape(1, -1)\n            virtual_ch = EvokedArray(\n                np.average(data, axis=0).reshape(1, -1),\n                virtual_info,\n                tmin=inst.tmin,\n                nave=inst.nave,\n                kind=inst.kind,\n            )\n        virtual_chs[f\"virtual {k + 1}\"] = virtual_ch\n\n    # add the virtual channels\n    inst.add_channels(list(virtual_chs.values()), force_update_info=True)\n\n    # use the virtual channels to interpolate\n    inst.info[\"bads\"] = list(bads)\n    inst.interpolate_bads()\n\n    # drop virtual channels\n    inst.drop_channels(list(virtual_chs.keys()))\n\n    inst.info[\"bads\"] = bads_orig\n    return inst", "metadata": {}}
{"_id": "mne_mne_preprocessing/eyetracking/calibration.py_read_eyelink_calibration_code", "title": "read_eyelink_calibration", "text": "def read_eyelink_calibration(\n    fname, screen_size=None, screen_distance=None, screen_resolution=None\n):\n    \"\"\"Return info on calibrations collected in an eyelink file.\n\n    Parameters\n    ----------\n    fname : path-like\n        Path to the eyelink file (.asc).\n    screen_size : array-like of shape ``(2,)``\n        The width and height (in meters) of the screen that the eyetracking\n        data was collected with. For example ``(.531, .298)`` for a monitor with\n        a display area of 531 x 298 mm. Defaults to ``None``.\n    screen_distance : float\n        The distance (in meters) from the participant's eyes to the screen.\n        Defaults to ``None``.\n    screen_resolution : array-like of shape ``(2,)``\n        The resolution (in pixels) of the screen that the eyetracking data\n        was collected with. For example, ``(1920, 1080)`` for a 1920x1080\n        resolution display. Defaults to ``None``.\n\n    Returns\n    -------\n    calibrations : list\n        A list of :class:`~mne.preprocessing.eyetracking.Calibration` instances, one for\n        each eye of every calibration that was performed during the recording session.\n    \"\"\"\n    fname = _check_fname(fname, overwrite=\"read\", must_exist=True, name=\"fname\")\n    logger.info(f\"Reading calibration data from {fname}\")\n    lines = fname.read_text(encoding=\"ASCII\").splitlines()\n    return _parse_calibration(lines, screen_size, screen_distance, screen_resolution)", "metadata": {}}
{"_id": "mne_mne_preprocessing/eyetracking/calibration.py_copy_code", "title": "copy", "text": "def copy(self):\n        \"\"\"Copy the instance.\n\n        Returns\n        -------\n        cal : instance of Calibration\n            The copied Calibration.\n        \"\"\"\n        return deepcopy(self)", "metadata": {}}
{"_id": "mne_mne_preprocessing/eyetracking/calibration.py_plot_code", "title": "plot", "text": "def plot(self, show_offsets=True, axes=None, show=True):\n        \"\"\"Visualize calibration.\n\n        Parameters\n        ----------\n        show_offsets : bool\n            Whether to display the offset (in visual degrees) of each calibration\n            point or not. Defaults to ``True``.\n        axes : instance of matplotlib.axes.Axes | None\n            Axes to draw the calibration positions to. If ``None`` (default), a new axes\n            will be created.\n        show : bool\n            Whether to show the figure or not. Defaults to ``True``.\n\n        Returns\n        -------\n        fig : instance of matplotlib.figure.Figure\n            The resulting figure object for the calibration plot.\n        \"\"\"\n        import matplotlib.pyplot as plt\n\n        msg = \"positions and gaze keys must both be 2D numpy arrays.\"\n        assert isinstance(self[\"positions\"], np.ndarray), msg\n        assert isinstance(self[\"gaze\"], np.ndarray), msg\n\n        if axes is not None:\n            from matplotlib.axes import Axes\n\n            _validate_type(axes, Axes, \"axes\")\n            ax = axes\n            fig = ax.get_figure()\n        else:  # create new figure and axes\n            fig, ax = plt.subplots(layout=\"constrained\")\n        px, py = self[\"positions\"].T\n        gaze_x, gaze_y = self[\"gaze\"].T\n\n        ax.set_title(f\"Calibration ({self['eye']} eye)\")\n        ax.set_xlabel(\"x (pixels)\")\n        ax.set_ylabel(\"y (pixels)\")\n\n        # Display avg_error and max_error in the top left corner\n        text = (\n            f\"avg_error: {self['avg_error']} deg.\\nmax_error: {self['max_error']} deg.\"\n        )\n        ax.text(\n            0,\n            1.01,\n            text,\n            transform=ax.transAxes,\n            verticalalignment=\"baseline\",\n            fontsize=8,\n        )\n\n        # Invert y-axis because the origin is in the top left corner\n        ax.invert_yaxis()\n        ax.scatter(px, py, color=\"gray\")\n        ax.scatter(gaze_x, gaze_y, color=\"red\", alpha=0.5)\n\n        if show_offsets:\n            for i in range(len(px)):\n                x_offset = 0.01 * gaze_x[i]  # 1% to the right of the gazepoint\n                text = ax.text(\n                    x=gaze_x[i] + x_offset,\n                    y=gaze_y[i],\n                    s=self[\"offsets\"][i],\n                    fontsize=8,\n                    ha=\"left\",\n                    va=\"center\",\n                )\n\n        plt_show(show)\n        return fig", "metadata": {}}
{"_id": "mne_mne_preprocessing/eyetracking/_pupillometry.py_interpolate_blinks_code", "title": "interpolate_blinks", "text": "def interpolate_blinks(raw, buffer=0.05, match=\"BAD_blink\", interpolate_gaze=False):\n    \"\"\"Interpolate eyetracking signals during blinks.\n\n    This function uses the timing of blink annotations to estimate missing\n    data. Missing values are then interpolated linearly. Operates in place.\n\n    Parameters\n    ----------\n    raw : instance of Raw\n        The raw data with at least one ``'pupil'`` or ``'eyegaze'`` channel.\n    buffer : float | array-like of float, shape ``(2,))``\n        The time in seconds before and after a blink to consider invalid and\n        include in the segment to be interpolated over. Default is ``0.05`` seconds\n        (50 ms). If array-like, the first element is the time before the blink and the\n        second element is the time after the blink to consider invalid, for example,\n        ``(0.025, .1)``.\n    match : str | list of str\n        The description of annotations to interpolate over. If a list, the data within\n        all annotations that match any of the strings in the list will be interpolated\n        over. If a ``match`` starts with ``'BAD_'``, that part will be removed from the\n        annotation description after interpolation. Defaults to ``'BAD_blink'``.\n    interpolate_gaze : bool\n        If False, only apply interpolation to ``'pupil channels'``. If True, interpolate\n        over ``'eyegaze'`` channels as well. Defaults to False, because eye position can\n        change in unpredictable ways during blinks.\n\n    Returns\n    -------\n    self : instance of Raw\n        Returns the modified instance.\n\n    Notes\n    -----\n    .. versionadded:: 1.5\n    \"\"\"\n    _check_preload(raw, \"interpolate_blinks\")\n    _validate_type(raw, BaseRaw, \"raw\")\n    _validate_type(buffer, (float, tuple, list, np.ndarray), \"buffer\")\n    _validate_type(match, (str, tuple, list, np.ndarray), \"match\")\n\n    # determine the buffer around blinks to include in the interpolation\n    buffer = np.array(buffer, dtype=float)\n    if buffer.size == 1:\n        buffer = np.array([buffer, buffer])\n\n    if isinstance(match, str):\n        match = [match]\n\n    # get the blink annotations\n    blink_annots = [annot for annot in raw.annotations if annot[\"description\"] in match]\n    if not blink_annots:\n        warn(f\"No annotations matching {match} found. Aborting.\")\n        return raw\n    _interpolate_blinks(raw, buffer, blink_annots, interpolate_gaze=interpolate_gaze)\n\n    # remove bad from the annotation description\n    for desc in match:\n        if desc.startswith(\"BAD_\"):\n            logger.info(f\"Removing 'BAD_' from {desc}.\")\n            raw.annotations.rename({desc: desc.replace(\"BAD_\", \"\")})\n    return raw", "metadata": {}}
{"_id": "mne_mne_preprocessing/eyetracking/eyetracking.py_set_channel_types_eyetrack_code", "title": "set_channel_types_eyetrack", "text": "def set_channel_types_eyetrack(inst, mapping):\n    \"\"\"Define sensor type for eyetrack channels.\n\n    This function can set all eye tracking specific information:\n    channel type, unit, eye (and x/y component; only for gaze channels)\n\n    Supported channel types:\n    ``'eyegaze'`` and ``'pupil'``\n\n    Supported units:\n    ``'au'``, ``'px'``, ``'deg'``, ``'rad'`` (for eyegaze)\n    ``'au'``, ``'mm'``, ``'m'`` (for pupil)\n\n    Parameters\n    ----------\n    inst : instance of Raw, Epochs, or Evoked\n        The data instance.\n    mapping : dict\n        A dictionary mapping a channel to a list/tuple including\n        channel type, unit, eye, [and x/y component] (all as str),  e.g.,\n        ``{'l_x': ('eyegaze', 'deg', 'left', 'x')}`` or\n        ``{'r_pupil': ('pupil', 'au', 'right')}``.\n\n    Returns\n    -------\n    inst : instance of Raw | Epochs | Evoked\n        The instance, modified in place.\n\n    Notes\n    -----\n    ``inst.set_channel_types()`` to ``'eyegaze'`` or ``'pupil'``\n    works as well, but cannot correctly set unit, eye and x/y component.\n\n    Data will be stored in SI units:\n    if your data comes in ``deg`` (visual angle) it will be converted to\n    ``rad``, if it is in ``mm`` it will be converted to ``m``.\n    \"\"\"\n    ch_names = inst.info[\"ch_names\"]\n\n    # allowed\n    valid_types = [\"eyegaze\", \"pupil\"]  # ch_type\n    valid_units = {\n        \"px\": [\"px\", \"pixel\"],\n        \"rad\": [\"rad\", \"radian\", \"radians\"],\n        \"deg\": [\"deg\", \"degree\", \"degrees\"],\n        \"m\": [\"m\", \"meter\", \"meters\"],\n        \"mm\": [\"mm\", \"millimeter\", \"millimeters\"],\n        \"au\": [None, \"none\", \"au\", \"arbitrary\"],\n    }\n    valid_units[\"all\"] = [item for sublist in valid_units.values() for item in sublist]\n    valid_eye = {\"l\": [\"left\", \"l\"], \"r\": [\"right\", \"r\"]}\n    valid_eye[\"all\"] = [item for sublist in valid_eye.values() for item in sublist]\n    valid_xy = {\"x\": [\"x\", \"h\", \"horizontal\"], \"y\": [\"y\", \"v\", \"vertical\"]}\n    valid_xy[\"all\"] = [item for sublist in valid_xy.values() for item in sublist]\n\n    # loop over channels\n    for ch_name, ch_desc in mapping.items():\n        if ch_name not in ch_names:\n            raise ValueError(f\"This channel name ({ch_name}) doesn't exist in info.\")\n        c_ind = ch_names.index(ch_name)\n\n        # set ch_type and unit\n        ch_type = ch_desc[0].lower()\n        if ch_type not in valid_types:\n            raise ValueError(\n                f\"ch_type must be one of {valid_types}. Got '{ch_type}' instead.\"\n            )\n        if ch_type == \"eyegaze\":\n            coil_type = FIFF.FIFFV_COIL_EYETRACK_POS\n        elif ch_type == \"pupil\":\n            coil_type = FIFF.FIFFV_COIL_EYETRACK_PUPIL\n        inst.info[\"chs\"][c_ind][\"coil_type\"] = coil_type\n        inst.info[\"chs\"][c_ind][\"kind\"] = FIFF.FIFFV_EYETRACK_CH\n\n        ch_unit = None if (ch_desc[1] is None) else ch_desc[1].lower()\n        if ch_unit not in valid_units[\"all\"]:\n            raise ValueError(\n                \"unit must be one of {}. Got '{}' instead.\".format(\n                    valid_units[\"all\"], ch_unit\n                )\n            )\n        if ch_unit in valid_units[\"px\"]:\n            unit_new = FIFF.FIFF_UNIT_PX\n        elif ch_unit in valid_units[\"rad\"]:\n            unit_new = FIFF.FIFF_UNIT_RAD\n        elif ch_unit in valid_units[\"deg\"]:  # convert deg to rad (SI)\n            inst = inst.apply_function(_convert_deg_to_rad, picks=ch_name)\n            unit_new = FIFF.FIFF_UNIT_RAD\n        elif ch_unit in valid_units[\"m\"]:\n            unit_new = FIFF.FIFF_UNIT_M\n        elif ch_unit in valid_units[\"mm\"]:  # convert mm to m (SI)\n            inst = inst.apply_function(_convert_mm_to_m, picks=ch_name)\n            unit_new = FIFF.FIFF_UNIT_M\n        elif ch_unit in valid_units[\"au\"]:\n            unit_new = FIFF.FIFF_UNIT_NONE\n        inst.info[\"chs\"][c_ind][\"unit\"] = unit_new\n\n        # set eye (and x/y-component)\n        loc = np.array(\n            [\n                np.nan,\n                np.nan,\n                np.nan,\n                np.nan,\n                np.nan,\n                np.nan,\n                np.nan,\n                np.nan,\n                np.nan,\n                np.nan,\n                np.nan,\n                np.nan,\n            ]\n        )\n\n        ch_eye = ch_desc[2].lower()\n        if ch_eye not in valid_eye[\"all\"]:\n            raise ValueError(\n                \"eye must be one of {}. Got '{}' instead.\".format(\n                    valid_eye[\"all\"], ch_eye\n                )\n            )\n        if ch_eye in valid_eye[\"l\"]:\n            loc[3] = -1\n        elif ch_eye in valid_eye[\"r\"]:\n            loc[3] = 1\n\n        if ch_type == \"eyegaze\":\n            ch_xy = ch_desc[3].lower()\n            if ch_xy not in valid_xy[\"all\"]:\n                raise ValueError(\n                    \"x/y must be one of {}. Got '{}' instead.\".format(\n                        valid_xy[\"all\"], ch_xy\n                    )\n                )\n            if ch_xy in valid_xy[\"x\"]:\n                loc[4] = -1\n            elif ch_xy in valid_xy[\"y\"]:\n                loc[4] = 1\n\n        inst.info[\"chs\"][c_ind][\"loc\"] = loc\n\n    return inst", "metadata": {}}
{"_id": "mne_mne_preprocessing/eyetracking/eyetracking.py_convert_units_code", "title": "convert_units", "text": "def convert_units(inst, calibration, to=\"radians\"):\n    \"\"\"Convert Eyegaze data from pixels to radians of visual angle or vice versa.\n\n    .. warning::\n        Currently, depending on the units (pixels or radians), eyegaze channels may not\n        be reported correctly in visualization functions like :meth:`mne.io.Raw.plot`.\n        They will be shown  correctly in :func:`mne.viz.eyetracking.plot_gaze`.\n        See :gh:`11879` for more information.\n\n    .. Important::\n       There are important considerations to keep in mind when using this function,\n       see the Notes section below.\n\n    Parameters\n    ----------\n    inst : instance of Raw, Epochs, or Evoked\n        The Raw, Epochs, or Evoked instance with eyegaze channels.\n    calibration : Calibration\n        Instance of  Calibration, containing information about the screen size\n        (in meters), viewing distance (in meters), and the screen resolution\n        (in pixels).\n    to : str\n        Must be either ``\"radians\"`` or ``\"pixels\"``, indicating the desired unit.\n\n    Returns\n    -------\n    inst : instance of Raw | Epochs | Evoked\n        The Raw, Epochs, or Evoked instance, modified in place.\n\n    Notes\n    -----\n    There are at least two important considerations to keep in mind when using this\n    function:\n\n    1. Converting between on-screen pixels and visual angle is not a linear\n       transformation. If the visual angle subtends less than approximately ``.44``\n       radians (``25`` degrees), the conversion could be considered to be approximately\n       linear. However, as the visual angle increases, the conversion becomes\n       increasingly non-linear. This may lead to unexpected results after converting\n       between pixels and visual angle.\n\n    * This function assumes that the head is fixed in place and aligned with the center\n      of the screen, such that gaze to the center of the screen results in a visual\n      angle of ``0`` radians.\n\n    .. versionadded:: 1.7\n    \"\"\"\n    _validate_type(inst, (BaseRaw, BaseEpochs, Evoked), \"inst\")\n    _validate_type(calibration, Calibration, \"calibration\")\n    _check_option(\"to\", to, (\"radians\", \"pixels\"))\n    _check_calibration(calibration)\n\n    # get screen parameters\n    screen_size = calibration[\"screen_size\"]\n    screen_resolution = calibration[\"screen_resolution\"]\n    dist = calibration[\"screen_distance\"]\n\n    # loop through channels and convert units\n    converted_chs = []\n    for ch_dict in inst.info[\"chs\"]:\n        if ch_dict[\"coil_type\"] != FIFF.FIFFV_COIL_EYETRACK_POS:\n            continue\n        unit = ch_dict[\"unit\"]\n        name = ch_dict[\"ch_name\"]\n\n        if ch_dict[\"loc\"][4] == -1:  # x-coordinate\n            size = screen_size[0]\n            res = screen_resolution[0]\n        elif ch_dict[\"loc\"][4] == 1:  # y-coordinate\n            size = screen_size[1]\n            res = screen_resolution[1]\n        else:\n            raise ValueError(\n                f\"loc array not set properly for channel '{name}'. Index 4 should\"\n                f\"  be -1 or 1, but got {ch_dict['loc'][4]}\"\n            )\n        # check unit, convert, and set new unit\n        if to == \"radians\":\n            if unit != FIFF.FIFF_UNIT_PX:\n                raise ValueError(\n                    f\"Data must be in pixels in order to convert to radians.\"\n                    f\" Got {unit} for {name}\"\n                )\n            inst.apply_function(_pix_to_rad, picks=name, size=size, res=res, dist=dist)\n            ch_dict[\"unit\"] = FIFF.FIFF_UNIT_RAD\n        elif to == \"pixels\":\n            if unit != FIFF.FIFF_UNIT_RAD:\n                raise ValueError(\n                    f\"Data must be in radians in order to convert to pixels.\"\n                    f\" Got {unit} for {name}\"\n                )\n            inst.apply_function(_rad_to_pix, picks=name, size=size, res=res, dist=dist)\n            ch_dict[\"unit\"] = FIFF.FIFF_UNIT_PX\n        converted_chs.append(name)\n    if converted_chs:\n        logger.info(f\"Converted {converted_chs} to {to}.\")\n        if to == \"radians\":\n            # check if any values are greaater than .44 radians\n            # (25 degrees) and warn user\n            data = inst.get_data(picks=converted_chs)\n            if np.any(np.abs(data) > 0.52):\n                warn(\n                    \"Some visual angle values subtend greater than .52 radians \"\n                    \"(30 degrees), meaning that the conversion between pixels \"\n                    \"and visual angle may be very non-linear. Take caution when \"\n                    \"interpreting these values. Max visual angle value in data:\"\n                    f\" {np.nanmax(data):0.2f} radians.\",\n                    UserWarning,\n                )\n    else:\n        warn(\"Could not find any eyegaze channels. Doing nothing.\", UserWarning)\n    return inst", "metadata": {}}
{"_id": "mne_mne_preprocessing/eyetracking/utils.py_get_screen_visual_angle_code", "title": "get_screen_visual_angle", "text": "def get_screen_visual_angle(calibration):\n    \"\"\"Calculate the radians of visual angle that the participant screen subtends.\n\n    Parameters\n    ----------\n    calibration : Calibration\n        An instance of Calibration. Must have valid values for ``\"screen_size\"`` and\n        ``\"screen_distance\"`` keys.\n\n    Returns\n    -------\n    visual angle in radians : ndarray, shape (2,)\n        The visual angle of the monitor width and height, respectively.\n    \"\"\"\n    _validate_type(calibration, Calibration, \"calibration\")\n    _check_calibration(calibration, want_keys=(\"screen_size\", \"screen_distance\"))\n    size = np.array(calibration[\"screen_size\"])\n    return 2 * np.arctan(size / (2 * calibration[\"screen_distance\"]))", "metadata": {}}
{"_id": "mne_mne_preprocessing/nirs/_beer_lambert_law.py_beer_lambert_law_code", "title": "beer_lambert_law", "text": "def beer_lambert_law(raw, ppf=6.0):\n    r\"\"\"Convert NIRS optical density data to haemoglobin concentration.\n\n    Parameters\n    ----------\n    raw : instance of Raw\n        The optical density data.\n    ppf : tuple | float\n        The partial pathlength factors for each wavelength.\n\n        .. versionchanged:: 1.7\n           Support for different factors for the two wavelengths.\n\n    Returns\n    -------\n    raw : instance of Raw\n        The modified raw instance.\n    \"\"\"\n    raw = raw.copy().load_data()\n    _validate_type(raw, BaseRaw, \"raw\")\n    _validate_type(ppf, (\"numeric\", \"array-like\"), \"ppf\")\n    ppf = np.array(ppf, float)\n    if ppf.ndim == 0:  # upcast single float to shape (2,)\n        ppf = np.array([ppf, ppf])\n    if ppf.shape != (2,):\n        raise ValueError(\n            f\"ppf must be float or array-like of shape (2,), got shape {ppf.shape}\"\n        )\n    ppf = ppf[:, np.newaxis]  # shape (2, 1)\n    picks = _validate_nirs_info(raw.info, fnirs=\"od\", which=\"Beer-lambert\")\n    # This is the one place we *really* need the actual/accurate frequencies\n    freqs = np.array([raw.info[\"chs\"][pick][\"loc\"][9] for pick in picks], float)\n    abs_coef = _load_absorption(freqs)\n    distances = source_detector_distances(raw.info, picks=\"all\")\n    bad = ~np.isfinite(distances[picks])\n    bad |= distances[picks] <= 0\n    if bad.any():\n        warn(\n            \"Source-detector distances are zero on NaN, some resulting \"\n            \"concentrations will be zero. Consider setting a montage \"\n            \"with raw.set_montage.\"\n        )\n    distances[picks[bad]] = 0.0\n    if (distances[picks] > 0.1).any():\n        warn(\n            \"Source-detector distances are greater than 10 cm. \"\n            \"Large distances will result in invalid data, and are \"\n            \"likely due to optode locations being stored in a \"\n            \" unit other than meters.\"\n        )\n    rename = dict()\n    for ii, jj in zip(picks[::2], picks[1::2]):\n        EL = abs_coef * distances[ii] * ppf\n        iEL = pinv(EL)\n\n        raw._data[[ii, jj]] = iEL @ raw._data[[ii, jj]] * 1e-3\n\n        # Update channel information\n        coil_dict = dict(hbo=FIFF.FIFFV_COIL_FNIRS_HBO, hbr=FIFF.FIFFV_COIL_FNIRS_HBR)\n        for ki, kind in zip((ii, jj), (\"hbo\", \"hbr\")):\n            ch = raw.info[\"chs\"][ki]\n            ch.update(coil_type=coil_dict[kind], unit=FIFF.FIFF_UNIT_MOL)\n            new_name = f\"{ch['ch_name'].split(' ')[0]} {kind}\"\n            rename[ch[\"ch_name\"]] = new_name\n    raw.rename_channels(rename)\n\n    # Validate the format of data after transformation is valid\n    _validate_nirs_info(raw.info, fnirs=\"hb\")\n    return raw", "metadata": {}}
{"_id": "mne_mne_preprocessing/nirs/_tddr.py_temporal_derivative_distribution_repair_code", "title": "temporal_derivative_distribution_repair", "text": "def temporal_derivative_distribution_repair(raw, *, verbose=None):\n    \"\"\"Apply temporal derivative distribution repair to data.\n\n    Applies temporal derivative distribution repair (TDDR) to data\n    :footcite:`FishburnEtAl2019`. This approach removes baseline shift\n    and spike artifacts without the need for any user-supplied parameters.\n\n    Parameters\n    ----------\n    raw : instance of Raw\n        The raw data.\n    %(verbose)s\n\n    Returns\n    -------\n    raw : instance of Raw\n         Data with TDDR applied.\n\n    Notes\n    -----\n    TDDR was initially designed to be used on optical density fNIRS data but\n    has been enabled to be applied on hemoglobin concentration fNIRS data as\n    well in MNE. We recommend applying the algorithm to optical density fNIRS\n    data as intended by the original author wherever possible.\n\n    There is a shorter alias ``mne.preprocessing.nirs.tddr`` that can be used\n    instead of this function (e.g. if line length is an issue).\n\n    References\n    ----------\n    .. footbibliography::\n    \"\"\"\n    raw = raw.copy().load_data()\n    _validate_type(raw, BaseRaw, \"raw\")\n    picks = _validate_nirs_info(raw.info)\n\n    if not len(picks):\n        raise RuntimeError(\"TDDR should be run on optical density or hemoglobin data.\")\n    for pick in picks:\n        raw._data[pick] = _TDDR(raw._data[pick], raw.info[\"sfreq\"])\n\n    return raw", "metadata": {}}
{"_id": "mne_mne_preprocessing/nirs/_scalp_coupling_index.py_scalp_coupling_index_code", "title": "scalp_coupling_index", "text": "def scalp_coupling_index(\n    raw,\n    l_freq=0.7,\n    h_freq=1.5,\n    l_trans_bandwidth=0.3,\n    h_trans_bandwidth=0.3,\n    verbose=False,\n):\n    r\"\"\"Calculate scalp coupling index.\n\n    This function calculates the scalp coupling index\n    :footcite:`pollonini2014auditory`. This is a measure of the quality of the\n    connection between the optode and the scalp.\n\n    Parameters\n    ----------\n    raw : instance of Raw\n        The raw data.\n    %(l_freq)s\n    %(h_freq)s\n    %(l_trans_bandwidth)s\n    %(h_trans_bandwidth)s\n    %(verbose)s\n\n    Returns\n    -------\n    sci : array of float\n        Array containing scalp coupling index for each channel.\n\n    References\n    ----------\n    .. footbibliography::\n    \"\"\"\n    _validate_type(raw, BaseRaw, \"raw\")\n    picks = _validate_nirs_info(raw.info, fnirs=\"od\", which=\"Scalp coupling index\")\n\n    raw = raw.copy().pick(picks).load_data()\n    zero_mask = np.std(raw._data, axis=-1) == 0\n    filtered_data = raw.filter(\n        l_freq,\n        h_freq,\n        l_trans_bandwidth=l_trans_bandwidth,\n        h_trans_bandwidth=h_trans_bandwidth,\n        verbose=verbose,\n    ).get_data()\n\n    sci = np.zeros(picks.shape)\n    for ii in range(0, len(picks), 2):\n        with np.errstate(invalid=\"ignore\"):\n            c = np.corrcoef(filtered_data[ii], filtered_data[ii + 1])[0][1]\n        if not np.isfinite(c):  # someone had std=0\n            c = 0\n        sci[ii] = c\n        sci[ii + 1] = c\n    sci[zero_mask] = 0\n    sci = sci[np.argsort(picks)]  # restore original order\n    return sci", "metadata": {}}
{"_id": "mne_mne_preprocessing/nirs/nirs.py_source_detector_distances_code", "title": "source_detector_distances", "text": "def source_detector_distances(info, picks=None):\n    r\"\"\"Determine the distance between NIRS source and detectors.\n\n    Parameters\n    ----------\n    %(info_not_none)s\n    %(picks_all_data)s\n\n    Returns\n    -------\n    dists : array of float\n        Array containing distances in meters.\n        Of shape equal to number of channels, or shape of picks if supplied.\n    \"\"\"\n    return np.array(\n        [\n            np.linalg.norm(\n                np.diff(info[\"chs\"][pick][\"loc\"][3:9].reshape(2, 3), axis=0)[0]\n            )\n            for pick in _picks_to_idx(info, picks, exclude=[])\n        ],\n        float,\n    )", "metadata": {}}
{"_id": "mne_mne_preprocessing/nirs/nirs.py_short_channels_code", "title": "short_channels", "text": "def short_channels(info, threshold=0.01):\n    r\"\"\"Determine which NIRS channels are short.\n\n    Channels with a source to detector distance of less than\n    ``threshold`` are reported as short. The default threshold is 0.01 m.\n\n    Parameters\n    ----------\n    %(info_not_none)s\n    threshold : float\n        The threshold distance for what is considered short in meters.\n\n    Returns\n    -------\n    short : array of bool\n        Array indicating which channels are short.\n        Of shape equal to number of channels.\n    \"\"\"\n    return source_detector_distances(info) < threshold", "metadata": {}}
{"_id": "mne_mne_preprocessing/nirs/_optical_density.py_optical_density_code", "title": "optical_density", "text": "def optical_density(raw, *, verbose=None):\n    r\"\"\"Convert NIRS raw data to optical density.\n\n    Parameters\n    ----------\n    raw : instance of Raw\n        The raw data.\n    %(verbose)s\n\n    Returns\n    -------\n    raw : instance of Raw\n        The modified raw instance.\n    \"\"\"\n    raw = raw.copy().load_data()\n    _validate_type(raw, BaseRaw, \"raw\")\n    picks = _validate_nirs_info(raw.info, fnirs=\"cw_amplitude\")\n\n    # The devices measure light intensity. Negative light intensities should\n    # not occur. If they do it is likely due to hardware or movement issues.\n    # Set all negative values to abs(x), this also has the benefit of ensuring\n    # that the means are all greater than zero for the division below.\n    if np.any(raw._data[picks] <= 0):\n        warn(\"Negative intensities encountered. Setting to abs(x)\")\n        min_ = np.inf\n        for pi in picks:\n            np.abs(raw._data[pi], out=raw._data[pi])\n            min_ = min(min_, raw._data[pi].min() or min_)\n        # avoid == 0\n        for pi in picks:\n            np.maximum(raw._data[pi], min_, out=raw._data[pi])\n\n    for pi in picks:\n        data_mean = np.mean(raw._data[pi])\n        raw._data[pi] /= data_mean\n        np.log(raw._data[pi], out=raw._data[pi])\n        raw._data[pi] *= -1\n        raw.info[\"chs\"][pi][\"coil_type\"] = FIFF.FIFFV_COIL_FNIRS_OD\n\n    return raw", "metadata": {}}
{"_id": "mne_mne_preprocessing/ieeg/_projection.py_project_sensors_onto_brain_code", "title": "project_sensors_onto_brain", "text": "def project_sensors_onto_brain(\n    info,\n    trans,\n    subject,\n    subjects_dir=None,\n    picks=None,\n    n_neighbors=10,\n    copy=True,\n    verbose=None,\n):\n    \"\"\"Project sensors onto the brain surface.\n\n    Parameters\n    ----------\n    %(info_not_none)s\n    %(trans_not_none)s\n    %(subject)s\n    %(subjects_dir)s\n    %(picks_base)s only ``ecog`` channels.\n    n_neighbors : int\n        The number of neighbors to use to compute the normal vectors\n        for the projection. Must be 2 or greater. More neighbors makes\n        a normal vector with greater averaging which preserves the grid\n        structure. Fewer neighbors has less averaging which better\n        preserves contours in the grid.\n    copy : bool\n        If ``True``, return a new instance of ``info``, if ``False``\n        ``info`` is modified in place.\n    %(verbose)s\n\n    Returns\n    -------\n    %(info_not_none)s\n\n    Notes\n    -----\n    This is useful in ECoG analysis for compensating for \"brain shift\"\n    or shrinking of the brain away from the skull due to changes\n    in pressure during the craniotomy.\n\n    To use the brain surface, a BEM model must be created e.g. using\n    :ref:`mne watershed_bem` using the T1 or :ref:`mne flash_bem`\n    using a FLASH scan.\n    \"\"\"\n    n_neighbors = _ensure_int(n_neighbors, \"n_neighbors\")\n    _validate_type(copy, bool, \"copy\")\n    if copy:\n        info = info.copy()\n    if n_neighbors < 2:\n        raise ValueError(f\"n_neighbors must be 2 or greater, got {n_neighbors}\")\n    subjects_dir = get_subjects_dir(subjects_dir, raise_error=True)\n    try:\n        surf = _read_mri_surface(subjects_dir / subject / \"bem\" / \"brain.surf\")\n    except FileNotFoundError as err:\n        raise RuntimeError(\n            f\"{err}\\n\\nThe brain surface requires generating \"\n            \"a BEM using `mne flash_bem` (if you have \"\n            \"the FLASH scan) or `mne watershed_bem` (to \"\n            \"use the T1)\"\n        ) from None\n    # get channel locations\n    picks_idx = _picks_to_idx(info, \"ecog\" if picks is None else picks)\n    locs = np.array([info[\"chs\"][idx][\"loc\"][:3] for idx in picks_idx])\n    trans = _ensure_trans(trans, \"head\", \"mri\")\n    locs = apply_trans(trans, locs)\n    # compute distances for nearest neighbors\n    dists = squareform(pdist(locs))\n    # find angles for brain surface and points\n    angles = _cart_to_sph(locs)\n    surf_angles = _cart_to_sph(surf[\"rr\"])\n    # initialize projected locs\n    proj_locs = np.zeros(locs.shape) * np.nan\n    for i, loc in enumerate(locs):\n        neighbor_pts = locs[np.argsort(dists[i])[: n_neighbors + 1]]\n        pt1, pt2, pt3 = map(np.array, zip(*combinations(neighbor_pts, 3)))\n        normals = fast_cross_3d(pt1 - pt2, pt1 - pt3)\n        normals[normals @ loc < 0] *= -1\n        normal = np.mean(normals, axis=0)\n        normal /= np.linalg.norm(normal)\n        # find the correct orientation brain surface point nearest the line\n        # https://mathworld.wolfram.com/Point-LineDistance3-Dimensional.html\n        use_rr = surf[\"rr\"][\n            abs(surf_angles[:, 1:] - angles[i, 1:]).sum(axis=1) < np.pi / 4\n        ]\n        surf_dists = np.linalg.norm(\n            fast_cross_3d(use_rr - loc, use_rr - loc + normal), axis=1\n        )\n        proj_locs[i] = use_rr[np.argmin(surf_dists)]\n    # back to the \"head\" coordinate frame for storing in ``raw``\n    proj_locs = apply_trans(invert_transform(trans), proj_locs)\n    montage = info.get_montage()\n    montage_kwargs = (\n        montage.get_positions() if montage else dict(ch_pos=dict(), coord_frame=\"head\")\n    )\n    for idx, loc in zip(picks_idx, proj_locs):\n        # surface RAS-> head and mm->m\n        montage_kwargs[\"ch_pos\"][info.ch_names[idx]] = loc\n    info.set_montage(make_dig_montage(**montage_kwargs))\n    return info", "metadata": {}}
{"_id": "mne_mne_preprocessing/ieeg/_volume.py_warp_montage_code", "title": "warp_montage", "text": "def warp_montage(montage, moving, static, reg_affine, sdr_morph, verbose=None):\n    \"\"\"Warp a montage to a template with image volumes using SDR.\n\n    .. note:: This is likely only applicable for channels inside the brain\n              (intracranial electrodes).\n\n    Parameters\n    ----------\n    montage : instance of mne.channels.DigMontage\n        The montage object containing the channels.\n    %(moving)s\n    %(static)s\n    %(reg_affine)s\n    %(sdr_morph)s\n    %(verbose)s\n\n    Returns\n    -------\n    montage_warped : mne.channels.DigMontage\n        The modified montage object containing the channels.\n    \"\"\"\n    _require_version(\"nibabel\", \"warp montage\", \"2.1.0\")\n    _require_version(\"dipy\", \"warping points using SDR\", \"1.6.0\")\n\n    from dipy.align.imwarp import DiffeomorphicMap\n    from nibabel import MGHImage\n    from nibabel.spatialimages import SpatialImage\n\n    _validate_type(moving, SpatialImage, \"moving\")\n    _validate_type(static, SpatialImage, \"static\")\n    _validate_type(reg_affine, np.ndarray, \"reg_affine\")\n    _check_option(\"reg_affine.shape\", reg_affine.shape, ((4, 4),))\n    _validate_type(sdr_morph, (DiffeomorphicMap, None), \"sdr_morph\")\n    _validate_type(montage, DigMontage, \"montage\")\n\n    moving_mgh = MGHImage(np.array(moving.dataobj).astype(np.float32), moving.affine)\n    static_mgh = MGHImage(np.array(static.dataobj).astype(np.float32), static.affine)\n    del moving, static\n\n    # get montage channel coordinates\n    ch_dict = montage.get_positions()\n    if ch_dict[\"coord_frame\"] != \"mri\":\n        bad_coord_frames = np.unique([d[\"coord_frame\"] for d in montage.dig])\n        bad_coord_frames = \", \".join(\n            [\n                _frame_to_str[cf] if cf in _frame_to_str else str(cf)\n                for cf in bad_coord_frames\n            ]\n        )\n        raise RuntimeError(\n            f'Coordinate frame not supported, expected \"mri\", got {bad_coord_frames}'\n        )\n    ch_names = list(ch_dict[\"ch_pos\"].keys())\n    ch_coords = np.array([ch_dict[\"ch_pos\"][name] for name in ch_names])\n\n    ch_coords = apply_trans(  # convert to moving voxel space\n        np.linalg.inv(moving_mgh.header.get_vox2ras_tkr()), ch_coords * 1000\n    )\n    # next, to moving scanner RAS\n    ch_coords = apply_trans(moving_mgh.header.get_vox2ras(), ch_coords)\n\n    # now, apply reg_affine\n    ch_coords = apply_trans(\n        Transform(  # to static ras\n            fro=\"ras\", to=\"ras\", trans=np.linalg.inv(reg_affine)\n        ),\n        ch_coords,\n    )\n\n    # now, apply SDR morph\n    if sdr_morph is not None:\n        ch_coords = sdr_morph.transform_points(\n            ch_coords,\n            coord2world=sdr_morph.domain_grid2world,\n            world2coord=sdr_morph.domain_world2grid,\n        )\n\n    # back to voxels but now for the static image\n    ch_coords = apply_trans(np.linalg.inv(static_mgh.header.get_vox2ras()), ch_coords)\n\n    # finally, back to surface RAS\n    ch_coords = apply_trans(static_mgh.header.get_vox2ras_tkr(), ch_coords) / 1000\n\n    # make warped montage\n    montage_warped = make_dig_montage(dict(zip(ch_names, ch_coords)), coord_frame=\"mri\")\n    return montage_warped", "metadata": {}}
{"_id": "mne_mne_preprocessing/ieeg/_volume.py_make_montage_volume_code", "title": "make_montage_volume", "text": "def make_montage_volume(\n    montage,\n    base_image,\n    thresh=0.5,\n    max_peak_dist=1,\n    voxels_max=100,\n    use_min=False,\n    verbose=None,\n):\n    \"\"\"Make a volume from intracranial electrode contact locations.\n\n    Find areas of the input volume with intensity greater than\n    a threshold surrounding local extrema near the channel location.\n    Monotonicity from the peak is enforced to prevent channels\n    bleeding into each other.\n\n    Parameters\n    ----------\n    montage : instance of mne.channels.DigMontage\n        The montage object containing the channels.\n    base_image : path-like | nibabel.spatialimages.SpatialImage\n        Path to a volumetric scan (e.g. CT) of the subject. Can be in any\n        format readable by nibabel. Can also be a nibabel image object.\n        Local extrema (max or min) should be nearby montage channel locations.\n    thresh : float\n        The threshold relative to the peak to determine the size\n        of the sensors on the volume.\n    max_peak_dist : int\n        The number of voxels away from the channel location to\n        look in the ``image``. This will depend on the accuracy of\n        the channel locations, the default (one voxel in all directions)\n        will work only with localizations that are that accurate.\n    voxels_max : int\n        The maximum number of voxels for each channel.\n    use_min : bool\n        Whether to hypointensities in the volume as channel locations.\n        Default False uses hyperintensities.\n    %(verbose)s\n\n    Returns\n    -------\n    elec_image : nibabel.spatialimages.SpatialImage\n        An image in Freesurfer surface RAS space with voxel values\n        corresponding to the index of the channel. The background\n        is 0s and this index starts at 1.\n    \"\"\"\n    _require_version(\"nibabel\", \"montage volume\", \"2.1.0\")\n    import nibabel as nib\n\n    _validate_type(montage, DigMontage, \"montage\")\n    _validate_type(base_image, nib.spatialimages.SpatialImage, \"base_image\")\n    _validate_type(thresh, float, \"thresh\")\n    if thresh < 0 or thresh >= 1:\n        raise ValueError(f\"`thresh` must be between 0 and 1, got {thresh}\")\n    _validate_type(max_peak_dist, int, \"max_peak_dist\")\n    _validate_type(voxels_max, int, \"voxels_max\")\n    _validate_type(use_min, bool, \"use_min\")\n\n    # load image and make sure it's in surface RAS\n    if not isinstance(base_image, nib.spatialimages.SpatialImage):\n        base_image = nib.load(base_image)\n\n    base_image_mgh = nib.MGHImage(\n        np.array(base_image.dataobj).astype(np.float32), base_image.affine\n    )\n    del base_image\n\n    # get montage channel coordinates\n    ch_dict = montage.get_positions()\n    if ch_dict[\"coord_frame\"] != \"mri\":\n        bad_coord_frames = np.unique([d[\"coord_frame\"] for d in montage.dig])\n        bad_coord_frames = \", \".join(\n            [\n                _frame_to_str[cf] if cf in _frame_to_str else str(cf)\n                for cf in bad_coord_frames\n            ]\n        )\n        raise RuntimeError(\n            f'Coordinate frame not supported, expected \"mri\", got {bad_coord_frames}'\n        )\n\n    ch_names = list(ch_dict[\"ch_pos\"].keys())\n    ch_coords = np.array([ch_dict[\"ch_pos\"][name] for name in ch_names])\n\n    # convert to voxel space\n    ch_coords = apply_trans(\n        np.linalg.inv(base_image_mgh.header.get_vox2ras_tkr()), ch_coords * 1000\n    )\n\n    # take channel coordinates and use the image to transform them\n    # into a volume where all the voxels over a threshold nearby\n    # are labeled with an index\n    image_data = np.array(base_image_mgh.dataobj)\n    if use_min:\n        image_data *= -1\n    elec_image = np.zeros(base_image_mgh.shape, dtype=int)\n    for i, ch_coord in enumerate(ch_coords):\n        if np.isnan(ch_coord).any():\n            continue\n        # this looks up to a voxel away, it may be marked imperfectly\n        volume = _voxel_neighbors(\n            ch_coord,\n            image_data,\n            thresh=thresh,\n            max_peak_dist=max_peak_dist,\n            voxels_max=voxels_max,\n        )\n        for voxel in volume:\n            if elec_image[voxel] != 0:\n                # some voxels ambiguous because the contacts are bridged on\n                # the image so assign the voxel to the nearest contact location\n                dist_old = np.sqrt(\n                    (ch_coords[elec_image[voxel] - 1] - voxel) ** 2\n                ).sum()\n                dist_new = np.sqrt((ch_coord - voxel) ** 2).sum()\n                if dist_new < dist_old:\n                    elec_image[voxel] = i + 1\n            else:\n                elec_image[voxel] = i + 1\n\n    # assemble the volume\n    elec_image = nib.spatialimages.SpatialImage(elec_image, base_image_mgh.affine)\n    _warn_missing_chs(montage, elec_image, after_warp=False)\n\n    return elec_image", "metadata": {}}
{"_id": "mne_mne_gui/_gui.py_coregistration_code", "title": "coregistration", "text": "def coregistration(\n    *,\n    width=None,\n    height=None,\n    inst=None,\n    subject=None,\n    subjects_dir=None,\n    head_opacity=None,\n    head_high_res=None,\n    trans=None,\n    orient_to_surface=None,\n    scale_by_distance=None,\n    mark_inside=None,\n    interaction=None,\n    fullscreen=None,\n    show=True,\n    block=False,\n    verbose=None,\n):\n    \"\"\"Coregister an MRI with a subject's head shape.\n\n    The GUI can be launched through the command line interface:\n\n    .. code-block::  bash\n\n        $ mne coreg\n\n    or using a python interpreter as shown in :ref:`tut-source-alignment`.\n\n    Parameters\n    ----------\n    width : int | None\n        Specify the width for window (in logical pixels).\n        Default is None, which uses ``MNE_COREG_WINDOW_WIDTH`` config value\n        (which defaults to ``800``).\n    height : int | None\n        Specify a height for window (in logical pixels).\n        Default is None, which uses ``MNE_COREG_WINDOW_WIDTH`` config value\n        (which defaults to ``400``).\n    inst : None | path-like\n        Path to an instance file containing the digitizer data. Compatible for\n        Raw, Epochs, and Evoked files.\n    subject : None | str\n        Name of the mri subject.\n    %(subjects_dir)s\n    head_opacity : float | None\n        The opacity of the head surface in the range ``[0., 1.]``.\n        Default is None, which uses ``MNE_COREG_HEAD_OPACITY`` config value\n        (which defaults to ``1.``).\n    head_high_res : bool | None\n        Use a high resolution head surface.\n        Default is None, which uses ``MNE_COREG_HEAD_HIGH_RES`` config value\n        (which defaults to True).\n    trans : path-like | Transform | None\n        The Head<->MRI transform or the path to its FIF file (``\"-trans.fif\"``).\n    orient_to_surface : bool | None\n        If True (default), orient EEG electrode and head shape points to the head\n        surface.\n\n        .. versionadded:: 0.16\n    scale_by_distance : bool | None\n        If True (default), scale the digitization points by their distance from the\n        scalp surface.\n\n        .. versionadded:: 0.16\n    mark_inside : bool | None\n        If True (default), mark points inside the head surface in a\n        different color.\n\n        .. versionadded:: 0.16\n    %(interaction_scene_none)s\n        Defaults to ``'terrain'``.\n\n        .. versionadded:: 0.16\n        .. versionchanged:: 1.0\n           Default interaction mode if ``None`` and no config setting found\n           changed from ``'trackball'`` to ``'terrain'``.\n    %(fullscreen)s\n        Default is ``None``, which uses ``MNE_COREG_FULLSCREEN`` config value\n        (which defaults to ``False``).\n\n        .. versionadded:: 1.1\n    show : bool\n        Show the GUI if True.\n    block : bool\n        Whether to halt program execution until the figure is closed.\n    %(verbose)s\n\n    Returns\n    -------\n    frame : instance of CoregistrationUI\n        The coregistration frame.\n\n    Notes\n    -----\n    Many parameters (e.g., ``head_opacity``) take None as a parameter,\n    which means that the default will be read from the MNE-Python\n    configuration file (which gets saved when exiting).\n\n    Step by step instructions for the coregistrations are shown below:\n\n    .. youtube:: ALV5qqMHLlQ\n    \"\"\"\n    config = get_config()\n    if head_high_res is None:\n        head_high_res = config.get(\"MNE_COREG_HEAD_HIGH_RES\", \"true\") == \"true\"\n    if head_opacity is None:\n        head_opacity = config.get(\"MNE_COREG_HEAD_OPACITY\", 0.8)\n    if width is None:\n        width = config.get(\"MNE_COREG_WINDOW_WIDTH\", 800)\n    if height is None:\n        height = config.get(\"MNE_COREG_WINDOW_HEIGHT\", 600)\n    if subjects_dir is None:\n        if \"SUBJECTS_DIR\" in config:\n            subjects_dir = config[\"SUBJECTS_DIR\"]\n        elif \"MNE_COREG_SUBJECTS_DIR\" in config:\n            subjects_dir = config[\"MNE_COREG_SUBJECTS_DIR\"]\n    false_like = (\"false\", \"0\")\n    if orient_to_surface is None:\n        orient_to_surface = config.get(\"MNE_COREG_ORIENT_TO_SURFACE\", \"true\").lower()\n        orient_to_surface = orient_to_surface not in false_like\n    if scale_by_distance is None:\n        scale_by_distance = config.get(\"MNE_COREG_SCALE_BY_DISTANCE\", \"true\").lower()\n        scale_by_distance = scale_by_distance not in false_like\n    if interaction is None:\n        interaction = config.get(\"MNE_COREG_INTERACTION\", \"terrain\")\n    if mark_inside is None:\n        mark_inside = config.get(\"MNE_COREG_MARK_INSIDE\", \"true\").lower()\n        mark_inside = mark_inside not in false_like\n    if fullscreen is None:\n        fullscreen = config.get(\"MNE_COREG_FULLSCREEN\", \"\") == \"true\"\n    head_opacity = float(head_opacity)\n    width = int(width)\n    height = int(height)\n\n    from ..viz.backends.renderer import MNE_3D_BACKEND_TESTING\n    from ._coreg import CoregistrationUI\n\n    if MNE_3D_BACKEND_TESTING:\n        show = block = False\n    return CoregistrationUI(\n        info_file=inst,\n        subject=subject,\n        subjects_dir=subjects_dir,\n        head_resolution=head_high_res,\n        head_opacity=head_opacity,\n        orient_glyphs=orient_to_surface,\n        scale_by_distance=scale_by_distance,\n        mark_inside=mark_inside,\n        trans=trans,\n        size=(width, height),\n        show=show,\n        block=block,\n        interaction=interaction,\n        fullscreen=fullscreen,\n        verbose=verbose,\n    )", "metadata": {}}
{"_id": "mne_mne_gui/_coreg.py_close_code", "title": "close", "text": "def close(self):\n        \"\"\"Close interface and cleanup data structure.\"\"\"\n        if self._renderer is not None:\n            self._renderer.close()", "metadata": {}}
{"_id": "mne_mne_viz/_proj.py_plot_projs_joint_code", "title": "plot_projs_joint", "text": "def plot_projs_joint(\n    projs, evoked, picks_trace=None, *, topomap_kwargs=None, show=True, verbose=None\n):\n    \"\"\"Plot projectors and evoked jointly.\n\n    Parameters\n    ----------\n    projs : list of Projection\n        The projectors to plot.\n    evoked : instance of Evoked\n        The data to plot. Typically this is the evoked instance created from\n        averaging the epochs used to create the projection.\n    %(picks_plot_projs_joint_trace)s\n    topomap_kwargs : dict | None\n        Keyword arguments to pass to :func:`mne.viz.plot_projs_topomap`.\n    %(show)s\n    %(verbose)s\n\n    Returns\n    -------\n    fig : instance of matplotlib Figure\n        The figure.\n\n    Notes\n    -----\n    This function creates a figure with three columns:\n\n    1. The left shows the evoked data traces before (black) and after (green)\n       projection.\n    2. The center shows the topomaps associated with each of the projectors.\n    3. The right again shows the data traces (black), but this time with:\n\n       1. The data projected onto each projector with a single normalization\n          factor (solid lines). This is useful for seeing the relative power\n          in each projection vector.\n       2. The data projected onto each projector with individual normalization\n          factors (dashed lines). This is useful for visualizing each time\n          course regardless of its power.\n       3. Additional data traces from ``picks_trace`` (solid yellow lines).\n          This is useful for visualizing the \"ground truth\" of the time\n          course, e.g. the measured EOG or ECG channel time courses.\n\n    .. versionadded:: 1.1\n    \"\"\"\n    import matplotlib.pyplot as plt\n\n    from ..evoked import Evoked\n\n    _validate_type(evoked, Evoked, \"evoked\")\n    _validate_type(topomap_kwargs, (None, dict), \"topomap_kwargs\")\n    projs = _check_type_projs(projs)\n    topomap_kwargs = dict() if topomap_kwargs is None else topomap_kwargs\n    if picks_trace is not None:\n        picks_trace = _picks_to_idx(evoked.info, picks_trace, allow_empty=False)\n    info = evoked.info\n    ch_types = evoked.get_channel_types(unique=True, only_data_chs=True)\n    proj_by_type = dict()  # will be set up like an enumerate key->[pi, proj]\n    ch_names_by_type = dict()\n    used = np.zeros(len(projs), int)\n    for ch_type in ch_types:\n        these_picks = _picks_to_idx(info, ch_type, allow_empty=True)\n        these_chs = [evoked.ch_names[pick] for pick in these_picks]\n        ch_names_by_type[ch_type] = these_chs\n        for pi, proj in enumerate(projs):\n            if not set(these_chs).intersection(proj[\"data\"][\"col_names\"]):\n                continue\n            if ch_type not in proj_by_type:\n                proj_by_type[ch_type] = list()\n            proj_by_type[ch_type].append([pi, deepcopy(proj)])\n            used[pi] += 1\n    missing = (~used.astype(bool)).sum()\n    if missing:\n        warn(\n            f\"{missing} projector{_pl(missing)} had no channel names present in epochs\"\n        )\n    del projs\n    ch_types = list(proj_by_type)  # reduce to number we actually need\n    # room for legend\n    max_proj_per_type = max(len(x) for x in proj_by_type.values())\n    cs_trace = 3\n    cs_topo = 2\n    n_col = max_proj_per_type * cs_topo + 2 * cs_trace\n    n_row = len(ch_types)\n    shape = (n_row, n_col)\n    fig = plt.figure(\n        figsize=(n_col * 1.1 + 0.5, n_row * 1.8 + 0.5), layout=\"constrained\"\n    )\n    ri = 0\n    # pick some sufficiently distinct colors (6 per proj type, e.g., ECG,\n    # should be enough hopefully!)\n    # https://personal.sron.nl/~pault/data/colourschemes.pdf\n    # \"Vibrant\" color scheme\n    proj_colors = [\n        \"#CC3311\",  # red\n        \"#009988\",  # teal\n        \"#0077BB\",  # blue\n        \"#EE3377\",  # magenta\n        \"#EE7733\",  # orange\n        \"#33BBEE\",  # cyan\n    ]\n    trace_color = \"#CCBB44\"  # yellow\n    after_color, after_name = \"#228833\", \"green\"\n    type_titles = DEFAULTS[\"titles\"]\n    last_ax = [None] * 2\n    first_ax = dict()\n    pe_kwargs = dict(show=False, draw=False)\n    for ch_type, these_projs in proj_by_type.items():\n        these_idxs, these_projs = zip(*these_projs)\n        ch_names = ch_names_by_type[ch_type]\n        idx = np.where(\n            [np.isin(ch_names, proj[\"data\"][\"col_names\"]).all() for proj in these_projs]\n        )[0]\n        used[idx] += 1\n        count = len(these_projs)\n        for proj in these_projs:\n            sub_idx = [proj[\"data\"][\"col_names\"].index(name) for name in ch_names]\n            proj[\"data\"][\"data\"] = proj[\"data\"][\"data\"][:, sub_idx]\n            proj[\"data\"][\"col_names\"] = ch_names\n        ba_ax = plt.subplot2grid(shape, (ri, 0), colspan=cs_trace, fig=fig)\n        topo_axes = [\n            plt.subplot2grid(\n                shape, (ri, ci * cs_topo + cs_trace), colspan=cs_topo, fig=fig\n            )\n            for ci in range(count)\n        ]\n        tr_ax = plt.subplot2grid(\n            shape, (ri, n_col - cs_trace), colspan=cs_trace, fig=fig\n        )\n        # topomaps\n        _plot_projs_topomap(these_projs, info=info, axes=topo_axes, **topomap_kwargs)\n        for idx, proj, ax_ in zip(these_idxs, these_projs, topo_axes):\n            ax_.set_title(\"\")  # could use proj['desc'] but it's long\n            ax_.set_xlabel(f\"projs[{idx}]\", fontsize=\"small\")\n        unit = DEFAULTS[\"units\"][ch_type]\n        # traces\n        this_evoked = evoked.copy().pick(ch_names)\n        p = np.concatenate([p[\"data\"][\"data\"] for p in these_projs])\n        assert p.shape == (len(these_projs), len(this_evoked.data))\n        traces = np.dot(p, this_evoked.data)\n        traces *= np.sign(np.mean(np.dot(this_evoked.data, traces.T), 0))[:, np.newaxis]\n        if picks_trace is not None:\n            ch_traces = evoked.data[picks_trace]\n            ch_traces -= np.mean(ch_traces, axis=1, keepdims=True)\n            ch_traces /= np.abs(ch_traces).max()\n        _plot_evoked(\n            this_evoked, picks=\"all\", axes=[tr_ax], **pe_kwargs, spatial_colors=False\n        )\n        for line in tr_ax.lines:\n            line.set(lw=0.5, zorder=3)\n        for t in list(tr_ax.texts):\n            t.remove()\n        scale = 0.8 * np.abs(tr_ax.get_ylim()).max()\n        hs, labels = list(), list()\n        traces /= np.abs(traces).max()  # uniformly scaled\n        for ti, trace in enumerate(traces):\n            hs.append(\n                tr_ax.plot(\n                    this_evoked.times,\n                    trace * scale,\n                    color=proj_colors[ti % len(proj_colors)],\n                    zorder=5,\n                )[0]\n            )\n            labels.append(f\"projs[{these_idxs[ti]}]\")\n        traces /= np.abs(traces).max(1, keepdims=True)  # independently\n        for ti, trace in enumerate(traces):\n            tr_ax.plot(\n                this_evoked.times,\n                trace * scale,\n                color=proj_colors[ti % len(proj_colors)],\n                zorder=3.5,\n                ls=\"--\",\n                lw=1.0,\n                alpha=0.75,\n            )\n        if picks_trace is not None:\n            trace_ch = [evoked.ch_names[pick] for pick in picks_trace]\n            if len(picks_trace) == 1:\n                trace_ch = trace_ch[0]\n            hs.append(\n                tr_ax.plot(\n                    this_evoked.times,\n                    ch_traces.T * scale,\n                    color=trace_color,\n                    lw=3,\n                    zorder=4,\n                    alpha=0.75,\n                )[0]\n            )\n            labels.append(str(trace_ch))\n        tr_ax.set(title=\"\", xlabel=\"\", ylabel=\"\")\n        # This will steal space from the subplots in a constrained layout\n        # https://matplotlib.org/3.5.0/tutorials/intermediate/constrainedlayout_guide.html#legends  # noqa: E501\n        tr_ax.legend(\n            hs,\n            labels,\n            loc=\"center left\",\n            borderaxespad=0.05,\n            bbox_to_anchor=[1.05, 0.5],\n        )\n        last_ax[1] = tr_ax\n        key = \"Projected time course\"\n        if key not in first_ax:\n            first_ax[key] = tr_ax\n        # Before and after traces\n        _plot_evoked(this_evoked, picks=\"all\", axes=[ba_ax], **pe_kwargs)\n        for line in ba_ax.lines:\n            line.set(lw=0.5, zorder=3)\n        loff = len(ba_ax.lines)\n        this_proj_evoked = this_evoked.copy().add_proj(these_projs)\n        # with meg='combined' any existing mag projectors (those already part\n        # of evoked before we add_proj above) will have greatly\n        # reduced power, so we ignore the warning about this issue\n        this_proj_evoked.apply_proj(verbose=\"error\")\n        _plot_evoked(this_proj_evoked, picks=\"all\", axes=[ba_ax], **pe_kwargs)\n        for line in ba_ax.lines[loff:]:\n            line.set(lw=0.5, zorder=4, color=after_color)\n        for t in list(ba_ax.texts):\n            t.remove()\n        ba_ax.set(title=\"\", xlabel=\"\")\n        ba_ax.set(ylabel=f\"{type_titles[ch_type]}\\n{unit}\")\n        last_ax[0] = ba_ax\n        key = f\"Before (black) and after ({after_name})\"\n        if key not in first_ax:\n            first_ax[key] = ba_ax\n        ri += 1\n    for ax in last_ax:\n        ax.set(xlabel=\"Time (s)\")\n    for title, ax in first_ax.items():\n        ax.set_title(title, fontsize=\"medium\")\n    plt_show(show)\n    return fig", "metadata": {}}
{"_id": "mne_mne_viz/raw.py_plot_raw_code", "title": "plot_raw", "text": "def plot_raw(\n    raw,\n    events=None,\n    duration=10.0,\n    start=0.0,\n    n_channels=20,\n    bgcolor=\"w\",\n    color=None,\n    bad_color=\"lightgray\",\n    event_color=\"cyan\",\n    scalings=None,\n    remove_dc=True,\n    order=None,\n    show_options=False,\n    title=None,\n    show=True,\n    block=False,\n    highpass=None,\n    lowpass=None,\n    filtorder=4,\n    clipping=_RAW_CLIP_DEF,\n    show_first_samp=False,\n    proj=True,\n    group_by=\"type\",\n    butterfly=False,\n    decim=\"auto\",\n    noise_cov=None,\n    event_id=None,\n    show_scrollbars=True,\n    show_scalebars=True,\n    time_format=\"float\",\n    precompute=None,\n    use_opengl=None,\n    picks=None,\n    *,\n    theme=None,\n    overview_mode=None,\n    splash=True,\n    verbose=None,\n):\n    \"\"\"Plot raw data.\n\n    Parameters\n    ----------\n    raw : instance of Raw\n        The raw data to plot.\n    events : array | None\n        Events to show with vertical bars.\n    duration : float\n        Time window (s) to plot. The lesser of this value and the duration\n        of the raw file will be used.\n    start : float\n        Initial time to show (can be changed dynamically once plotted). If\n        show_first_samp is True, then it is taken relative to\n        ``raw.first_samp``.\n    n_channels : int\n        Number of channels to plot at once. Defaults to 20. The lesser of\n        ``n_channels`` and ``len(raw.ch_names)`` will be shown.\n        Has no effect if ``order`` is 'position', 'selection' or 'butterfly'.\n    bgcolor : color object\n        Color of the background.\n    color : dict | color object | None\n        Color for the data traces. If None, defaults to::\n\n            dict(mag='darkblue', grad='b', eeg='k', eog='k', ecg='m',\n                 emg='k', ref_meg='steelblue', misc='k', stim='k',\n                 resp='k', chpi='k')\n\n    bad_color : color object\n        Color to make bad channels.\n    %(event_color)s\n        Defaults to ``'cyan'``.\n    %(scalings)s\n    remove_dc : bool\n        If True remove DC component when plotting data.\n    order : array of int | None\n        Order in which to plot data. If the array is shorter than the number of\n        channels, only the given channels are plotted. If None (default), all\n        channels are plotted. If ``group_by`` is ``'position'`` or\n        ``'selection'``, the ``order`` parameter is used only for selecting the\n        channels to be plotted.\n    show_options : bool\n        If True, a dialog for options related to projection is shown.\n    title : str | None\n        The title of the window. If None, and either the filename of the\n        raw object or '<unknown>' will be displayed as title.\n    show : bool\n        Show figure if True.\n    block : bool\n        Whether to halt program execution until the figure is closed.\n        Useful for setting bad channels on the fly by clicking on a line.\n        May not work on all systems / platforms.\n        (Only Qt) If you run from a script, this needs to\n        be ``True`` or a Qt-eventloop needs to be started somewhere\n        else in the script (e.g. if you want to implement the browser\n        inside another Qt-Application).\n    highpass : float | None\n        Highpass to apply when displaying data.\n    lowpass : float | None\n        Lowpass to apply when displaying data.\n        If highpass > lowpass, a bandstop rather than bandpass filter\n        will be applied.\n    filtorder : int\n        Filtering order. 0 will use FIR filtering with MNE defaults.\n        Other values will construct an IIR filter of the given order\n        and apply it with :func:`~scipy.signal.filtfilt` (making the effective\n        order twice ``filtorder``). Filtering may produce some edge artifacts\n        (at the left and right edges) of the signals during display.\n\n        .. versionchanged:: 0.18\n           Support for ``filtorder=0`` to use FIR filtering.\n    clipping : str | float | None\n        If None, channels are allowed to exceed their designated bounds in\n        the plot. If \"clamp\", then values are clamped to the appropriate\n        range for display, creating step-like artifacts. If \"transparent\",\n        then excessive values are not shown, creating gaps in the traces.\n        If float, clipping occurs for values beyond the ``clipping`` multiple\n        of their dedicated range, so ``clipping=1.`` is an alias for\n        ``clipping='transparent'``.\n\n        .. versionchanged:: 0.21\n           Support for float, and default changed from None to 1.5.\n    show_first_samp : bool\n        If True, show time axis relative to the ``raw.first_samp``.\n    proj : bool\n        Whether to apply projectors prior to plotting (default is ``True``).\n        Individual projectors can be enabled/disabled interactively (see\n        Notes). This argument only affects the plot; use ``raw.apply_proj()``\n        to modify the data stored in the Raw object.\n    %(group_by_browse)s\n    butterfly : bool\n        Whether to start in butterfly mode. Defaults to False.\n    decim : int | 'auto'\n        Amount to decimate the data during display for speed purposes.\n        You should only decimate if the data are sufficiently low-passed,\n        otherwise aliasing can occur. The 'auto' mode (default) uses\n        the decimation that results in a sampling rate least three times\n        larger than ``min(info['lowpass'], lowpass)`` (e.g., a 40 Hz lowpass\n        will result in at least a 120 Hz displayed sample rate).\n    noise_cov : instance of Covariance | str | None\n        Noise covariance used to whiten the data while plotting.\n        Whitened data channels are scaled by ``scalings['whitened']``,\n        and their channel names are shown in italic.\n        Can be a string to load a covariance from disk.\n        See also :meth:`mne.Evoked.plot_white` for additional inspection\n        of noise covariance properties when whitening evoked data.\n        For data processed with SSS, the effective dependence between\n        magnetometers and gradiometers may introduce differences in scaling,\n        consider using :meth:`mne.Evoked.plot_white`.\n\n        .. versionadded:: 0.16.0\n    event_id : dict | None\n        Event IDs used to show at event markers (default None shows\n        the event numbers).\n\n        .. versionadded:: 0.16.0\n    %(show_scrollbars)s\n    %(show_scalebars)s\n\n        .. versionadded:: 0.20.0\n    %(time_format)s\n    %(precompute)s\n    %(use_opengl)s\n    %(picks_all)s\n    %(theme_pg)s\n\n        .. versionadded:: 1.0\n    %(overview_mode)s\n\n        .. versionadded:: 1.1\n    %(splash)s\n\n        .. versionadded:: 1.6\n    %(verbose)s\n\n    Returns\n    -------\n    %(browser)s\n\n    Notes\n    -----\n    The arrow keys (up/down/left/right) can typically be used to navigate\n    between channels and time ranges, but this depends on the backend\n    matplotlib is configured to use (e.g., mpl.use('TkAgg') should work). The\n    left/right arrows will scroll by 25%% of ``duration``, whereas\n    shift+left/shift+right will scroll by 100%% of ``duration``. The scaling\n    can be adjusted with - and + (or =) keys. The viewport dimensions can be\n    adjusted with page up/page down and home/end keys. Full screen mode can be\n    toggled with the F11 key, and scrollbars can be hidden/shown by pressing\n    'z'. Right-click a channel label to view its location. To mark or un-mark a\n    channel as bad, click on a channel label or a channel trace. The changes\n    will be reflected immediately in the raw object's ``raw.info['bads']``\n    entry.\n\n    If projectors are present, a button labelled \"Prj\" in the lower right\n    corner of the plot window opens a secondary control window, which allows\n    enabling/disabling specific projectors individually. This provides a means\n    of interactively observing how each projector would affect the raw data if\n    it were applied.\n\n    Annotation mode is toggled by pressing 'a', butterfly mode by pressing\n    'b', and whitening mode (when ``noise_cov is not None``) by pressing 'w'.\n    By default, the channel means are removed when ``remove_dc`` is set to\n    ``True``. This flag can be toggled by pressing 'd'.\n\n    %(notes_2d_backend)s\n    \"\"\"\n    from ..annotations import _annotations_starts_stops\n    from ..io import BaseRaw\n    from ._figure import _get_browser\n\n    info = raw.info.copy()\n    sfreq = info[\"sfreq\"]\n    projs = info[\"projs\"]\n    # this will be an attr for which projectors are currently \"on\" in the plot\n    projs_on = np.full_like(projs, proj, dtype=bool)\n    # disable projs in info if user doesn't want to see them right away\n    if not proj:\n        with info._unlock():\n            info[\"projs\"] = list()\n\n    # handle defaults / check arg validity\n    color = _handle_default(\"color\", color)\n    scalings = _compute_scalings(scalings, raw, remove_dc=remove_dc, duration=duration)\n    if scalings[\"whitened\"] == \"auto\":\n        scalings[\"whitened\"] = 1.0\n    _validate_type(raw, BaseRaw, \"raw\", \"Raw\")\n    decim, picks_data = _handle_decim(info, decim, lowpass)\n    noise_cov = _check_cov(noise_cov, info)\n    units = _handle_default(\"units\", None)\n    unit_scalings = _handle_default(\"scalings\", None)\n    _check_option(\"group_by\", group_by, (\"selection\", \"position\", \"original\", \"type\"))\n\n    # clipping\n    _validate_type(clipping, (None, \"numeric\", str), \"clipping\")\n    if isinstance(clipping, str):\n        _check_option(\n            \"clipping\", clipping, (\"clamp\", \"transparent\"), extra=\"when a string\"\n        )\n        clipping = 1.0 if clipping == \"transparent\" else clipping\n    elif clipping is not None:\n        clipping = float(clipping)\n\n    # be forgiving if user asks for too much time\n    duration = min(raw.times[-1], float(duration))\n\n    # determine IIR filtering parameters\n    if highpass is not None and highpass <= 0:\n        raise ValueError(f\"highpass must be > 0, got {highpass}\")\n    if highpass is None and lowpass is None:\n        ba = filt_bounds = None\n    else:\n        filtorder = int(filtorder)\n        if filtorder == 0:\n            method = \"fir\"\n            iir_params = None\n        else:\n            method = \"iir\"\n            iir_params = dict(order=filtorder, output=\"sos\", ftype=\"butter\")\n        ba = create_filter(\n            np.zeros((1, int(round(duration * sfreq)))),\n            sfreq,\n            highpass,\n            lowpass,\n            method=method,\n            iir_params=iir_params,\n        )\n        filt_bounds = _annotations_starts_stops(\n            raw, (\"edge\", \"bad_acq_skip\"), invert=True\n        )\n\n    # compute event times in seconds\n    if events is not None:\n        event_times = (events[:, 0] - raw.first_samp).astype(float)\n        event_times /= sfreq\n        event_nums = events[:, 2]\n    else:\n        event_times = event_nums = None\n\n    # determine trace order\n    ch_names = np.array(raw.ch_names)\n    ch_types = np.array(raw.get_channel_types())\n\n    picks = _picks_to_idx(info, picks, none=\"all\", exclude=())\n    order = _get_channel_plotting_order(order, ch_types, picks=picks)\n    n_channels = min(info[\"nchan\"], n_channels, len(order))\n    # adjust order based on channel selection, if needed\n    selections = None\n    if group_by in (\"selection\", \"position\"):\n        selections = _setup_channel_selections(raw, group_by, order)\n        order = np.concatenate(list(selections.values()))\n        default_selection = list(selections)[0]\n        n_channels = len(selections[default_selection])\n    assert isinstance(order, np.ndarray)\n    assert order.dtype.kind == \"i\"\n    if order.size == 0:\n        raise RuntimeError(\"No channels found to plot\")\n\n    # handle event colors\n    event_color_dict = _make_event_color_dict(event_color, events, event_id)\n\n    # handle first_samp\n    first_time = raw._first_time if show_first_samp else 0\n    start += first_time\n    event_id_rev = {v: k for k, v in (event_id or {}).items()}\n\n    # generate window title; allow instances without a filename (e.g., ICA)\n    if title is None:\n        title = \"<unknown>\"\n        fnames = list(tuple(raw.filenames))  # get a list of a copy of the filenames\n        if len(fnames):\n            title = fnames.pop(0)\n            extra = f\" ... (+ {len(fnames)} more)\" if len(fnames) else \"\"\n            title = f\"{title}{extra}\"\n            if len(title) > 60:\n                title = _shorten_path_from_middle(title)\n    elif not isinstance(title, str):\n        raise TypeError(f\"title must be None or a string, got a {type(title)}\")\n\n    # gather parameters and initialize figure\n    _validate_type(use_opengl, (bool, None), \"use_opengl\")\n    precompute = _handle_precompute(precompute)\n    params = dict(\n        inst=raw,\n        info=info,\n        # channels and channel order\n        ch_names=ch_names,\n        ch_types=ch_types,\n        ch_order=order,\n        picks=order[:n_channels],\n        n_channels=n_channels,\n        picks_data=picks_data,\n        group_by=group_by,\n        ch_selections=selections,\n        # time\n        t_start=start,\n        duration=duration,\n        n_times=raw.n_times,\n        first_time=first_time,\n        time_format=time_format,\n        decim=decim,\n        # events\n        event_color_dict=event_color_dict,\n        event_times=event_times,\n        event_nums=event_nums,\n        event_id_rev=event_id_rev,\n        # preprocessing\n        projs=projs,\n        projs_on=projs_on,\n        apply_proj=proj,\n        remove_dc=remove_dc,\n        filter_coefs=ba,\n        filter_bounds=filt_bounds,\n        noise_cov=noise_cov,\n        # scalings\n        scalings=scalings,\n        units=units,\n        unit_scalings=unit_scalings,\n        # colors\n        ch_color_bad=bad_color,\n        ch_color_dict=color,\n        # display\n        butterfly=butterfly,\n        clipping=clipping,\n        scrollbars_visible=show_scrollbars,\n        scalebars_visible=show_scalebars,\n        window_title=title,\n        bgcolor=bgcolor,\n        # Qt-specific\n        precompute=precompute,\n        use_opengl=use_opengl,\n        theme=theme,\n        overview_mode=overview_mode,\n        splash=splash,\n    )\n\n    fig = _get_browser(show=show, block=block, **params)\n\n    return fig", "metadata": {}}
{"_id": "mne_mne_viz/raw.py_plot_raw_psd_code", "title": "plot_raw_psd", "text": "def plot_raw_psd(\n    raw,\n    fmin=0,\n    fmax=np.inf,\n    tmin=None,\n    tmax=None,\n    proj=False,\n    n_fft=None,\n    n_overlap=0,\n    reject_by_annotation=True,\n    picks=None,\n    ax=None,\n    color=\"black\",\n    xscale=\"linear\",\n    area_mode=\"std\",\n    area_alpha=0.33,\n    dB=True,\n    estimate=\"power\",\n    show=True,\n    n_jobs=None,\n    average=False,\n    line_alpha=None,\n    spatial_colors=True,\n    sphere=None,\n    window=\"hamming\",\n    exclude=\"bads\",\n    verbose=None,\n):\n    \"\"\"%(plot_psd_doc)s.\n\n    Parameters\n    ----------\n    raw : instance of Raw\n        The raw object.\n    %(fmin_fmax_psd)s\n    %(tmin_tmax_psd)s\n    %(proj_psd)s\n    n_fft : int | None\n        Number of points to use in Welch FFT calculations. Default is ``None``,\n        which uses the minimum of 2048 and the number of time points.\n    n_overlap : int\n        The number of points of overlap between blocks. The default value\n        is 0 (no overlap).\n    %(reject_by_annotation_psd)s\n    %(picks_good_data_noref)s\n    %(ax_plot_psd)s\n    %(color_plot_psd)s\n    %(xscale_plot_psd)s\n    %(area_mode_plot_psd)s\n    %(area_alpha_plot_psd)s\n    %(dB_plot_psd)s\n    %(estimate_plot_psd)s\n    %(show)s\n    %(n_jobs)s\n    %(average_plot_psd)s\n    %(line_alpha_plot_psd)s\n    %(spatial_colors_psd)s\n    %(sphere_topomap_auto)s\n    %(window_psd)s\n\n        .. versionadded:: 0.22.0\n    exclude : list of str | 'bads'\n        Channels names to exclude from being shown. If 'bads', the bad channels\n        are excluded. Pass an empty list to plot all channels (including\n        channels marked \"bad\", if any).\n\n        .. versionadded:: 0.24.0\n    %(verbose)s\n\n    Returns\n    -------\n    fig : instance of Figure\n        Figure with frequency spectra of the data channels.\n\n    Notes\n    -----\n    %(notes_plot_*_psd_func)s\n    \"\"\"\n    from ..time_frequency import Spectrum\n\n    init_kw, plot_kw = _split_psd_kwargs(plot_fun=Spectrum.plot)\n    return raw.compute_psd(**init_kw).plot(**plot_kw)", "metadata": {}}
{"_id": "mne_mne_viz/raw.py_plot_raw_psd_topo_code", "title": "plot_raw_psd_topo", "text": "def plot_raw_psd_topo(\n    raw,\n    tmin=0.0,\n    tmax=None,\n    fmin=0.0,\n    fmax=100.0,\n    proj=False,\n    *,\n    n_fft=2048,\n    n_overlap=0,\n    dB=True,\n    layout=None,\n    color=\"w\",\n    fig_facecolor=\"k\",\n    axis_facecolor=\"k\",\n    axes=None,\n    block=False,\n    show=True,\n    n_jobs=None,\n    verbose=None,\n):\n    \"\"\"Plot power spectral density, separately for each channel.\n\n    Parameters\n    ----------\n    raw : instance of io.Raw\n        The raw instance to use.\n    %(tmin_tmax_psd)s\n    %(fmin_fmax_psd_topo)s\n    %(proj_psd)s\n    n_fft : int\n        Number of points to use in Welch FFT calculations. Defaults to 2048.\n    n_overlap : int\n        The number of points of overlap between blocks. Defaults to 0\n        (no overlap).\n    %(dB_spectrum_plot_topo)s\n    layout : instance of Layout | None\n        Layout instance specifying sensor positions (does not need to be\n        specified for Neuromag data). If ``None`` (default), the layout is\n        inferred from the data.\n    color : str | tuple\n        A matplotlib-compatible color to use for the curves. Defaults to white.\n    fig_facecolor : str | tuple\n        A matplotlib-compatible color to use for the figure background.\n        Defaults to black.\n    axis_facecolor : str | tuple\n        A matplotlib-compatible color to use for the axis background.\n        Defaults to black.\n    %(axes_spectrum_plot_topo)s\n    block : bool\n        Whether to halt program execution until the figure is closed.\n        May not work on all systems / platforms. Defaults to False.\n    %(show)s\n    %(n_jobs)s\n    %(verbose)s\n\n    Returns\n    -------\n    fig : instance of matplotlib.figure.Figure\n        Figure distributing one image per channel across sensor topography.\n    \"\"\"\n    from ..time_frequency import Spectrum\n\n    init_kw, plot_kw = _split_psd_kwargs(plot_fun=Spectrum.plot_topo)\n    return raw.compute_psd(**init_kw).plot_topo(**plot_kw)", "metadata": {}}
{"_id": "mne_mne_viz/topo.py_iter_topography_code", "title": "iter_topography", "text": "def iter_topography(\n    info,\n    layout=None,\n    on_pick=None,\n    fig=None,\n    fig_facecolor=\"k\",\n    axis_facecolor=\"k\",\n    axis_spinecolor=\"k\",\n    layout_scale=None,\n    legend=False,\n    select=False,\n):\n    \"\"\"Create iterator over channel positions.\n\n    This function returns a generator that unpacks into\n    a series of matplotlib axis objects and data / channel\n    indices, both corresponding to the sensor positions\n    of the related layout passed or inferred from the channel info.\n    Hence, this enables convenient topography plot customization.\n\n    Parameters\n    ----------\n    %(info_not_none)s\n    layout : instance of mne.channels.Layout | None\n        The layout to use. If None, layout will be guessed.\n    on_pick : callable | None\n        The callback function to be invoked on clicking one\n        of the axes. Is supposed to instantiate the following\n        API: ``function(axis, channel_index)``.\n    fig : matplotlib.figure.Figure | None\n        The figure object to be considered. If None, a new\n        figure will be created.\n    fig_facecolor : color\n        The figure face color. Defaults to black.\n    axis_facecolor : color\n        The axis face color. Defaults to black.\n    axis_spinecolor : color\n        The axis spine color. Defaults to black. In other words,\n        the color of the axis' edge lines.\n    layout_scale : float | None\n        Scaling factor for adjusting the relative size of the layout\n        on the canvas. If None, nothing will be scaled.\n    legend : bool\n        If True, an additional axis is created in the bottom right corner\n        that can be used to, e.g., construct a legend. The index of this\n        axis will be -1.\n    select : bool\n        Whether to enable the lasso-selection tool to enable the user to select\n        channels. The selected channels will be available in\n        ``fig.lasso.selection``.\n\n        .. versionadded:: 1.10.0\n\n    Returns\n    -------\n    gen : generator\n        A generator that can be unpacked into:\n\n        ax : matplotlib.axis.Axis\n            The current axis of the topo plot.\n        ch_dx : int\n            The related channel index.\n    \"\"\"\n    return _iter_topography(\n        info,\n        layout,\n        on_pick,\n        fig,\n        fig_facecolor,\n        axis_facecolor,\n        axis_spinecolor,\n        layout_scale,\n        legend=legend,\n        select=select,\n    )", "metadata": {}}
{"_id": "mne_mne_viz/topo.py_plot_topo_image_epochs_code", "title": "plot_topo_image_epochs", "text": "def plot_topo_image_epochs(\n    epochs,\n    layout=None,\n    sigma=0.0,\n    vmin=None,\n    vmax=None,\n    colorbar=None,\n    order=None,\n    cmap=\"RdBu_r\",\n    layout_scale=0.95,\n    title=None,\n    scalings=None,\n    border=\"none\",\n    fig_facecolor=\"k\",\n    fig_background=None,\n    font_color=\"w\",\n    select=False,\n    show=True,\n):\n    \"\"\"Plot Event Related Potential / Fields image on topographies.\n\n    Parameters\n    ----------\n    epochs : instance of :class:`~mne.Epochs`\n        The epochs.\n    layout : instance of Layout\n        System specific sensor positions.\n    sigma : float\n        The standard deviation of the Gaussian smoothing to apply along\n        the epoch axis to apply in the image. If 0., no smoothing is applied.\n    vmin : float\n        The min value in the image. The unit is \u00b5V for EEG channels,\n        fT for magnetometers and fT/cm for gradiometers.\n    vmax : float\n        The max value in the image. The unit is \u00b5V for EEG channels,\n        fT for magnetometers and fT/cm for gradiometers.\n    colorbar : bool | None\n        Whether to display a colorbar or not. If ``None`` a colorbar will be\n        shown only if all channels are of the same type. Defaults to ``None``.\n    order : None | array of int | callable\n        If not None, order is used to reorder the epochs on the y-axis\n        of the image. If it's an array of int it should be of length\n        the number of good epochs. If it's a callable the arguments\n        passed are the times vector and the data as 2d array\n        (data.shape[1] == len(times)).\n    cmap : colormap\n        Colors to be mapped to the values.\n    layout_scale : float\n        Scaling factor for adjusting the relative size of the layout\n        on the canvas.\n    title : str\n        Title of the figure.\n    scalings : dict | None\n        The scalings of the channel types to be applied for plotting. If\n        ``None``, defaults to ``dict(eeg=1e6, grad=1e13, mag=1e15)``.\n    border : str\n        Matplotlib borders style to be used for each sensor plot.\n    fig_facecolor : color\n        The figure face color. Defaults to black.\n    fig_background : None | array\n        A background image for the figure. This must be a valid input to\n        :func:`matplotlib.pyplot.imshow`. Defaults to ``None``.\n    font_color : color\n        The color of tick labels in the colorbar. Defaults to white.\n    select : bool\n        Whether to enable the lasso-selection tool to enable the user to select\n        channels. The selected channels will be available in\n        ``fig.lasso.selection``.\n\n        .. versionadded:: 1.10.0\n    show : bool\n        Whether to show the figure. Defaults to ``True``.\n\n    Returns\n    -------\n    fig : instance of :class:`matplotlib.figure.Figure`\n        Figure distributing one image per channel across sensor topography.\n\n    Notes\n    -----\n    In an interactive Python session, this plot will be interactive; clicking\n    on a channel image will pop open a larger view of the image; this image\n    will always have a colorbar even when the topo plot does not (because it\n    shows multiple sensor types).\n    \"\"\"\n    from ..channels.layout import find_layout\n\n    scalings = _handle_default(\"scalings\", scalings)\n\n    # make a copy because we discard non-data channels and scale the data\n    epochs = epochs.copy().load_data()\n    # use layout to subset channels present in epochs object\n    if layout is None:\n        layout = find_layout(epochs.info)\n    ch_names = set(layout.names) & set(epochs.ch_names)\n    idxs = [epochs.ch_names.index(ch_name) for ch_name in ch_names]\n    epochs = epochs.pick(idxs)\n    # get lists of channel type & scale coefficient\n    ch_types = epochs.get_channel_types()\n    scale_coeffs = [scalings.get(ch_type, 1) for ch_type in ch_types]\n    # scale the data\n    epochs._data *= np.array(scale_coeffs)[:, np.newaxis]\n    data = epochs.get_data(copy=False)\n    # get vlims for each channel type\n    vlim_dict = dict()\n    for ch_type in set(ch_types):\n        this_data = data[:, np.where(np.array(ch_types) == ch_type)]\n        vlim_dict[ch_type] = _setup_vmin_vmax(this_data, vmin, vmax)\n    vlim_array = np.array([vlim_dict[ch_type] for ch_type in ch_types])\n    # only show colorbar if we have a single channel type\n    if colorbar is None:\n        colorbar = len(set(ch_types)) == 1\n    # if colorbar=True, we know we have only 1 channel type so all entries\n    # in vlim_array are the same, just take the first one\n    if colorbar and vmin is None and vmax is None:\n        vmin, vmax = vlim_array[0]\n\n    show_func = partial(\n        _erfimage_imshow_unified,\n        scalings=scale_coeffs,\n        order=order,\n        data=data,\n        epochs=epochs,\n        sigma=sigma,\n        cmap=cmap,\n        vlim_array=vlim_array,\n    )\n\n    erf_imshow = partial(\n        _erfimage_imshow,\n        scalings=scale_coeffs,\n        order=order,\n        data=data,\n        epochs=epochs,\n        sigma=sigma,\n        cmap=cmap,\n        vlim_array=vlim_array,\n        colorbar=True,\n    )\n\n    fig = _plot_topo(\n        info=epochs.info,\n        times=epochs.times,\n        click_func=erf_imshow,\n        show_func=show_func,\n        layout=layout,\n        colorbar=colorbar,\n        vmin=vmin,\n        vmax=vmax,\n        cmap=cmap,\n        layout_scale=layout_scale,\n        title=title,\n        fig_facecolor=fig_facecolor,\n        font_color=font_color,\n        border=border,\n        x_label=\"Time (s)\",\n        y_label=\"Epoch\",\n        unified=True,\n        img=True,\n        select=select,\n    )\n    add_background_image(fig, fig_background)\n    plt_show(show)\n    return fig", "metadata": {}}
{"_id": "mne_mne_viz/topo.py_format_coord_unified_code", "title": "format_coord_unified", "text": "def format_coord_unified(x, y, pos=None, ch_names=None):\n        \"\"\"Update status bar with channel name under cursor.\"\"\"\n        # find candidate channels (ones that are down and left from cursor)\n        pdist = np.array([x, y]) - pos[:, :2]\n        pind = np.where((pdist >= 0).all(axis=1))[0]\n        if len(pind) > 0:\n            # find the closest channel\n            closest = pind[np.sum(pdist[pind, :] ** 2, axis=1).argmin()]\n            # check whether we are inside its box\n            in_box = (pdist[closest, :] < pos[closest, 2:]).all()\n        else:\n            in_box = False\n        return (\n            f\"{ch_names[closest]} (click to magnify)\" if in_box else \"No channel here\"\n        )", "metadata": {}}
{"_id": "mne_mne_viz/topo.py_format_coord_multiaxis_code", "title": "format_coord_multiaxis", "text": "def format_coord_multiaxis(x, y, ch_name=None):\n        \"\"\"Update status bar with channel name under cursor.\"\"\"\n        return f\"{ch_name} (click to magnify)\"", "metadata": {}}
{"_id": "mne_mne_viz/conftest.py_fnirs_evoked_code", "title": "fnirs_evoked", "text": "def fnirs_evoked():\n    \"\"\"Create an fnirs evoked structure.\"\"\"\n    montage = make_standard_montage(\"biosemi16\")\n    ch_names = montage.ch_names\n    ch_types = [\"eeg\"] * 16\n    info = create_info(ch_names=ch_names, sfreq=20, ch_types=ch_types)\n    evoked_data = np.random.randn(16, 30)\n    evoked = EvokedArray(evoked_data, info=info, tmin=-0.2, nave=4)\n    evoked.set_montage(montage)\n    evoked.set_channel_types(\n        {\"Fp1\": \"hbo\", \"Fp2\": \"hbo\", \"F4\": \"hbo\", \"Fz\": \"hbo\"}, verbose=\"error\"\n    )\n    return evoked", "metadata": {}}
{"_id": "mne_mne_viz/conftest.py_fnirs_epochs_code", "title": "fnirs_epochs", "text": "def fnirs_epochs():\n    \"\"\"Create an fnirs epoch structure.\"\"\"\n    raw_intensity = read_raw_nirx(fname_nirx, preload=False)\n    raw_od = optical_density(raw_intensity)\n    raw_haemo = beer_lambert_law(raw_od, ppf=6.0)\n    evts, _ = events_from_annotations(raw_haemo, event_id={\"1.0\": 1})\n    evts_dct = {\"A\": 1}\n    tn, tx = -1, 2\n    epochs = Epochs(raw_haemo, evts, event_id=evts_dct, tmin=tn, tmax=tx)\n    return epochs", "metadata": {}}
{"_id": "mne_mne_viz/ui_events.py_publish_code", "title": "publish", "text": "def publish(fig, event, *, verbose=None):\n    \"\"\"Publish an event to all subscribers of the figure's channel.\n\n    The figure's event channel and all linked event channels are searched for\n    subscribers to the given event. Each subscriber had provided a callback\n    function when subscribing, so we call that.\n\n    Parameters\n    ----------\n    fig : matplotlib.figure.Figure | Figure3D\n        The figure that publishes the event.\n    event : UIEvent\n        Event to publish.\n    %(verbose)s\n    \"\"\"\n    if fig in _disabled_event_channels:\n        return\n\n    # Compile a list of all event channels that the event should be published\n    # on.\n    channels = [_get_event_channel(fig)]\n    links = _event_channel_links.get(fig, None)\n    if links is not None:\n        for linked_fig, (include_events, exclude_events) in links.items():\n            if (include_events is None or event.name in include_events) and (\n                exclude_events is None or event.name not in exclude_events\n            ):\n                channels.append(_get_event_channel(linked_fig))\n\n    # Publish the event by calling the registered callback functions.\n    event.source = fig\n    logger.debug(f\"Publishing {event} on channel {fig}\")\n    for channel in channels:\n        if event.name not in channel:\n            channel[event.name] = set()\n        for callback in channel[event.name]:\n            callback(event=event)", "metadata": {}}
{"_id": "mne_mne_viz/ui_events.py_subscribe_code", "title": "subscribe", "text": "def subscribe(fig, event_name, callback, *, verbose=None):\n    \"\"\"Subscribe to an event on a figure's event channel.\n\n    Parameters\n    ----------\n    fig : matplotlib.figure.Figure | Figure3D\n        The figure of which event channel to subscribe.\n    event_name : str\n        The name of the event to listen for.\n    callback : callable\n        The function that should be called whenever the event is published.\n    %(verbose)s\n    \"\"\"\n    channel = _get_event_channel(fig)\n    logger.debug(f\"Subscribing to channel {channel}\")\n    if event_name not in channel:\n        channel[event_name] = set()\n    channel[event_name].add(callback)", "metadata": {}}
{"_id": "mne_mne_viz/ui_events.py_unsubscribe_code", "title": "unsubscribe", "text": "def unsubscribe(fig, event_names, callback=None, *, verbose=None):\n    \"\"\"Unsubscribe from an event on a figure's event channel.\n\n    Parameters\n    ----------\n    fig : matplotlib.figure.Figure | Figure3D\n        The figure of which event channel to unsubscribe from.\n    event_names : str | list of str\n        Select which events to stop subscribing to. Can be a single string\n        event name, a list of event names or ``\"all\"`` which will unsubscribe\n        from all events.\n    callback : callable | None\n        The callback function that should be unsubscribed, leaving all other\n        callback functions that may be subscribed untouched. By default\n        (``None``) all callback functions are unsubscribed from the event.\n    %(verbose)s\n    \"\"\"\n    channel = _get_event_channel(fig)\n\n    # Determine which events to unsubscribe for.\n    if event_names == \"all\":\n        if callback is None:\n            event_names = list(channel.keys())\n        else:\n            event_names = list(k for k, v in channel.items() if callback in v)\n    elif isinstance(event_names, str):\n        event_names = [event_names]\n\n    for event_name in event_names:\n        if event_name not in channel:\n            warn(\n                f'Cannot unsubscribe from event \"{event_name}\" as we have never '\n                \"subscribed to it.\"\n            )\n            continue\n\n        if callback is None:\n            del channel[event_name]\n        else:\n            # Unsubscribe specific callback function.\n            subscribers = channel[event_name]\n            if callback in subscribers:\n                subscribers.remove(callback)\n            else:\n                warn(\n                    f'Cannot unsubscribe {callback} from event \"{event_name}\" '\n                    \"as it was never subscribed to it.\"\n                )\n            if len(subscribers) == 0:\n                del channel[event_name]", "metadata": {}}
{"_id": "mne_mne_viz/ui_events.py_link_code", "title": "link", "text": "def link(*figs, include_events=None, exclude_events=None, verbose=None):\n    \"\"\"Link the event channels of two figures together.\n\n    When event channels are linked, any events that are published on one\n    channel are simultaneously published on the other channel. Links are\n    bi-directional.\n\n    Parameters\n    ----------\n    *figs : tuple of matplotlib.figure.Figure | tuple of Figure3D\n        The figures whose event channel will be linked.\n    include_events : list of str | None\n        Select which events to publish across figures. By default (``None``),\n        both figures will receive all of each other's events. Passing a list of\n        event names will restrict the events being shared across the figures to\n        only the given ones.\n    exclude_events : list of str | None\n        Select which events not to publish across figures. By default (``None``),\n        no events are excluded.\n    %(verbose)s\n    \"\"\"\n    if include_events is not None:\n        include_events = set(include_events)\n    if exclude_events is not None:\n        exclude_events = set(exclude_events)\n\n    # Make sure the event channels of the figures are setup properly.\n    for fig in figs:\n        _get_event_channel(fig)\n        if fig not in _event_channel_links:\n            _event_channel_links[fig] = weakref.WeakKeyDictionary()\n\n    # Link the event channels\n    for fig1 in figs:\n        for fig2 in figs:\n            if fig1 is not fig2:\n                _event_channel_links[fig1][fig2] = (include_events, exclude_events)", "metadata": {}}
{"_id": "mne_mne_viz/ui_events.py_unlink_code", "title": "unlink", "text": "def unlink(fig, *, verbose=None):\n    \"\"\"Remove all links involving the event channel of the given figure.\n\n    Parameters\n    ----------\n    fig : matplotlib.figure.Figure | Figure3D\n        The figure whose event channel should be unlinked from all other event\n        channels.\n    %(verbose)s\n    \"\"\"\n    linked_figs = _event_channel_links.get(fig)\n    if linked_figs is not None:\n        for linked_fig in linked_figs.keys():\n            del _event_channel_links[linked_fig][fig]\n            if len(_event_channel_links[linked_fig]) == 0:\n                del _event_channel_links[linked_fig]\n    if fig in _event_channel_links:  # need to check again because of weak refs\n        del _event_channel_links[fig]", "metadata": {}}
{"_id": "mne_mne_viz/ui_events.py_disable_ui_events_code", "title": "disable_ui_events", "text": "def disable_ui_events(fig):\n    \"\"\"Temporarily disable generation of UI events. Use as context manager.\n\n    Parameters\n    ----------\n    fig : matplotlib.figure.Figure | Figure3D\n        The figure whose UI event generation should be temporarily disabled.\n    \"\"\"\n    _disabled_event_channels.add(fig)\n    try:\n        yield\n    finally:\n        _disabled_event_channels.remove(fig)", "metadata": {}}
{"_id": "mne_mne_viz/ui_events.py_name_code", "title": "name", "text": "def name(self):\n        \"\"\"The name of the event, which is the class name in snake case.\"\"\"\n        return _camel_to_snake.sub(\"_\", self.__class__.__name__).lower()", "metadata": {}}
{"_id": "mne_mne_viz/ui_events.py_delete_event_channel_code", "title": "delete_event_channel", "text": "def delete_event_channel(event=None, *, weakfig=weakfig):\n            \"\"\"Delete the event channel (callback function).\"\"\"\n            fig = weakfig()\n            if fig is None:\n                return\n            publish(fig, event=FigureClosing())  # Notify subscribers of imminent close\n            logger.debug(f\"unlink(({fig})\")\n            unlink(fig)  # Remove channel from the _event_channel_links dict\n            if fig in _event_channels:\n                logger.debug(f\"  del _event_channels[{fig}]\")\n                del _event_channels[fig]\n            if fig in _disabled_event_channels:\n                logger.debug(f\"  _disabled_event_channels.remove({fig})\")\n                _disabled_event_channels.remove(fig)", "metadata": {}}
{"_id": "mne_mne_viz/montage.py_plot_montage_code", "title": "plot_montage", "text": "def plot_montage(\n    montage,\n    *,\n    scale=1.0,\n    show_names=True,\n    kind=\"topomap\",\n    show=True,\n    sphere=None,\n    axes=None,\n    verbose=None,\n):\n    \"\"\"Plot a montage.\n\n    Parameters\n    ----------\n    montage : instance of DigMontage\n        The montage to visualize.\n    scale : float\n        Determines the scale of the channel points and labels; values < 1 will scale\n        down, whereas values > 1 will scale up.\n    show_names : bool | list\n        Whether to display all channel names. If a list, only the channel\n        names in the list are shown. Defaults to True.\n    kind : str\n        Whether to plot the montage as '3d' or 'topomap' (default).\n    show : bool\n        Show figure if True.\n    %(sphere_topomap_auto)s\n    %(axes_montage)s\n\n        .. versionadded:: 1.4\n    %(verbose)s\n\n    Returns\n    -------\n    fig : instance of matplotlib.figure.Figure\n        The figure object.\n    \"\"\"\n    import matplotlib.pyplot as plt\n\n    from ..channels import DigMontage, make_dig_montage\n\n    _validate_type(scale, \"numeric\", \"scale\")\n    _check_option(\"kind\", kind, [\"topomap\", \"3d\"])\n    _validate_type(montage, DigMontage, item_name=\"montage\")\n    ch_names = montage.ch_names\n    title = None\n\n    if len(ch_names) == 0:\n        raise RuntimeError(\"No valid channel positions found.\")\n\n    pos = np.array(list(montage._get_ch_pos().values()))\n\n    dists = cdist(pos, pos)\n\n    # only consider upper triangular part by setting the rest to np.nan\n    dists[np.tril_indices(dists.shape[0])] = np.nan\n    dupes = np.argwhere(np.isclose(dists, 0))\n    if dupes.any():\n        montage = deepcopy(montage)\n        n_chans = pos.shape[0]\n        n_dupes = dupes.shape[0]\n        idx = np.setdiff1d(np.arange(len(pos)), dupes[:, 1]).tolist()\n        logger.info(f\"{n_dupes} duplicate electrode labels found:\")\n        logger.info(\", \".join([ch_names[d[0]] + \"/\" + ch_names[d[1]] for d in dupes]))\n        logger.info(f\"Plotting {n_chans - n_dupes} unique labels.\")\n        ch_names = [ch_names[i] for i in idx]\n        ch_pos = dict(zip(ch_names, pos[idx, :]))\n        # XXX: this might cause trouble if montage was originally in head\n        fid, _ = _get_fid_coords(montage.dig)\n        montage = make_dig_montage(ch_pos=ch_pos, **fid)\n\n    info = create_info(ch_names, sfreq=256, ch_types=\"eeg\")\n    info.set_montage(montage, on_missing=\"ignore\")\n    fig = plot_sensors(\n        info,\n        kind=kind,\n        show_names=show_names,\n        show=show,\n        title=title,\n        sphere=sphere,\n        axes=axes,\n    )\n\n    if scale != 1.0:\n        # scale points\n        collection = fig.axes[0].collections[0]\n        collection.set_sizes([scale * 10])\n\n        # scale labels\n        labels = fig.findobj(match=plt.Text)\n        x_label, y_label = fig.axes[0].xaxis.label, fig.axes[0].yaxis.label\n        z_label = fig.axes[0].zaxis.label if kind == \"3d\" else None\n        tick_labels = fig.axes[0].get_xticklabels() + fig.axes[0].get_yticklabels()\n        if kind == \"3d\":\n            tick_labels += fig.axes[0].get_zticklabels()\n        for label in labels:\n            if label not in [x_label, y_label, z_label] + tick_labels:\n                label.set_fontsize(label.get_fontsize() * scale)\n\n    return fig", "metadata": {}}
{"_id": "mne_mne_viz/ica.py_plot_ica_sources_code", "title": "plot_ica_sources", "text": "def plot_ica_sources(\n    ica,\n    inst,\n    picks=None,\n    start=None,\n    stop=None,\n    title=None,\n    show=True,\n    block=False,\n    show_first_samp=False,\n    show_scrollbars=True,\n    time_format=\"float\",\n    precompute=None,\n    use_opengl=None,\n    *,\n    psd_args=None,\n    theme=None,\n    overview_mode=None,\n    splash=True,\n):\n    \"\"\"Plot estimated latent sources given the unmixing matrix.\n\n    Typical usecases:\n\n    1. plot evolution of latent sources over time based on (Raw input)\n    2. plot latent source around event related time windows (Epochs input)\n    3. plot time-locking in ICA space (Evoked input)\n\n    Parameters\n    ----------\n    ica : instance of mne.preprocessing.ICA\n        The ICA solution.\n    inst : instance of Raw, Epochs or Evoked\n        The object to plot the sources from.\n    %(picks_ica)s\n    start, stop : float | int | None\n       If ``inst`` is a `~mne.io.Raw` or an `~mne.Evoked` object, the first and\n       last time point (in seconds) of the data to plot. If ``inst`` is a\n       `~mne.io.Raw` object, ``start=None`` and ``stop=None`` will be\n       translated into ``start=0.`` and ``stop=3.``, respectively. For\n       `~mne.Evoked`, ``None`` refers to the beginning and end of the evoked\n       signal. If ``inst`` is an `~mne.Epochs` object, specifies the index of\n       the first and last epoch to show.\n    title : str | None\n        The window title. If None a default is provided.\n    show : bool\n        Show figure if True.\n    block : bool\n        Whether to halt program execution until the figure is closed.\n        Useful for interactive selection of components in raw and epoch\n        plotter. For evoked, this parameter has no effect. Defaults to False.\n    show_first_samp : bool\n        If True, show time axis relative to the ``raw.first_samp``.\n    %(show_scrollbars)s\n    %(time_format)s\n    %(precompute)s\n    %(use_opengl)s\n    psd_args : dict | None\n        Dictionary of arguments to pass to :meth:`~mne.Epochs.compute_psd` in\n        interactive  mode. Ignored if ``inst`` is not supplied. If ``None``,\n        nothing is passed. Defaults to ``None``.\n\n        .. versionadded:: 1.9\n    %(theme_pg)s\n\n        .. versionadded:: 1.0\n    %(overview_mode)s\n\n        .. versionadded:: 1.1\n    %(splash)s\n\n        .. versionadded:: 1.6\n\n    Returns\n    -------\n    %(browser)s\n\n    Notes\n    -----\n    For raw and epoch instances, it is possible to select components for\n    exclusion by clicking on the line. The selected components are added to\n    ``ica.exclude`` on close.\n\n    %(notes_2d_backend)s\n\n    .. versionadded:: 0.10.0\n    \"\"\"\n    from ..epochs import BaseEpochs\n    from ..evoked import Evoked\n    from ..io import BaseRaw\n\n    exclude = ica.exclude\n    picks = _picks_to_idx(ica.n_components_, picks, picks_on=\"components\")\n\n    if isinstance(inst, BaseRaw | BaseEpochs):\n        fig = _plot_sources(\n            ica,\n            inst,\n            picks,\n            exclude,\n            start=start,\n            stop=stop,\n            show=show,\n            title=title,\n            block=block,\n            psd_args=psd_args,\n            show_first_samp=show_first_samp,\n            show_scrollbars=show_scrollbars,\n            time_format=time_format,\n            precompute=precompute,\n            use_opengl=use_opengl,\n            theme=theme,\n            overview_mode=overview_mode,\n            splash=splash,\n        )\n    elif isinstance(inst, Evoked):\n        if start is not None or stop is not None:\n            inst = inst.copy().crop(start, stop)\n        sources = ica.get_sources(inst)\n        fig = _plot_ica_sources_evoked(\n            evoked=sources,\n            picks=picks,\n            exclude=exclude,\n            title=title,\n            labels=getattr(ica, \"labels_\", None),\n            show=show,\n            ica=ica,\n        )\n    else:\n        raise ValueError(\"Data input must be of Raw or Epochs type\")\n\n    return fig", "metadata": {}}
{"_id": "mne_mne_viz/ica.py_plot_ica_properties_code", "title": "plot_ica_properties", "text": "def plot_ica_properties(\n    ica,\n    inst,\n    picks=None,\n    axes=None,\n    dB=True,\n    plot_std=True,\n    log_scale=False,\n    topomap_args=None,\n    image_args=None,\n    psd_args=None,\n    figsize=None,\n    show=True,\n    reject=\"auto\",\n    reject_by_annotation=True,\n    *,\n    estimate=\"power\",\n    verbose=None,\n):\n    \"\"\"Display component properties.\n\n    Properties include the topography, epochs image, ERP/ERF, power\n    spectrum, and epoch variance.\n\n    Parameters\n    ----------\n    ica : instance of mne.preprocessing.ICA\n        The ICA solution.\n    inst : instance of Epochs or Raw\n        The data to use in plotting properties.\n\n        .. note::\n           You can interactively cycle through topographic maps for different\n           channel types by pressing :kbd:`T`.\n    picks : int | list of int | slice | None\n        Indices of the independent components (ICs) to visualize.\n        If an integer, represents the index of the IC to pick.\n        Multiple ICs can be selected using a list of int or a slice.\n        The indices are 0-indexed, so ``picks=1`` will pick the second\n        IC: ``ICA001``. ``None`` will pick the first 5 components.\n    axes : list of Axes | None\n        List of five matplotlib axes to use in plotting: [topomap_axis,\n        image_axis, erp_axis, spectrum_axis, variance_axis]. If None a new\n        figure with relevant axes is created. Defaults to None.\n    dB : bool\n        Whether to plot spectrum in dB. Defaults to True.\n    plot_std : bool | float\n        Whether to plot standard deviation/confidence intervals in ERP/ERF and\n        spectrum plots.\n        Defaults to True, which plots one standard deviation above/below for\n        the spectrum. If set to float allows to control how many standard\n        deviations are plotted for the spectrum. For example 2.5 will plot 2.5\n        standard deviation above/below.\n        For the ERP/ERF, by default, plot the 95 percent parametric confidence\n        interval is calculated. To change this, use ``ci`` in ``ts_args`` in\n        ``image_args`` (see below).\n    log_scale : bool\n        Whether to use a logarithmic frequency axis to plot the spectrum.\n        Defaults to ``False``.\n\n        .. note::\n           You can interactively toggle this setting by pressing :kbd:`L`.\n\n        .. versionadded:: 1.1\n    topomap_args : dict | None\n        Dictionary of arguments to ``plot_topomap``. If None, doesn't pass any\n        additional arguments. Defaults to None.\n    image_args : dict | None\n        Dictionary of arguments to ``plot_epochs_image``. If None, doesn't pass\n        any additional arguments. Defaults to None.\n    psd_args : dict | None\n        Dictionary of arguments to :meth:`~mne.Epochs.compute_psd`. If\n        ``None``, doesn't pass any additional arguments. Defaults to ``None``.\n    figsize : array-like, shape (2,) | None\n        Allows to control size of the figure. If None, the figure size\n        defaults to [7., 6.].\n    show : bool\n        Show figure if True.\n    reject : 'auto' | dict | None\n        Allows to specify rejection parameters used to drop epochs\n        (or segments if continuous signal is passed as inst).\n        If None, no rejection is applied. The default is 'auto',\n        which applies the rejection parameters used when fitting\n        the ICA object.\n    %(reject_by_annotation_raw)s\n\n        .. versionadded:: 0.21.0\n    %(estimate_plot_psd)s\n\n        .. versionadded:: 1.8.0\n    %(verbose)s\n\n    Returns\n    -------\n    fig : list\n        List of matplotlib figures.\n\n    Notes\n    -----\n    .. versionadded:: 0.13\n    \"\"\"\n    return _fast_plot_ica_properties(\n        ica,\n        inst,\n        picks=picks,\n        axes=axes,\n        dB=dB,\n        plot_std=plot_std,\n        log_scale=log_scale,\n        topomap_args=topomap_args,\n        image_args=image_args,\n        psd_args=psd_args,\n        figsize=figsize,\n        show=show,\n        reject=reject,\n        reject_by_annotation=reject_by_annotation,\n        verbose=verbose,\n        estimate=estimate,\n        precomputed_data=None,\n    )", "metadata": {}}
{"_id": "mne_mne_viz/ica.py_plot_ica_scores_code", "title": "plot_ica_scores", "text": "def plot_ica_scores(\n    ica,\n    scores,\n    exclude=None,\n    labels=None,\n    axhline=None,\n    title=\"ICA component scores\",\n    figsize=None,\n    n_cols=None,\n    show=True,\n):\n    \"\"\"Plot scores related to detected components.\n\n    Use this function to asses how well your score describes outlier\n    sources and how well you were detecting them.\n\n    Parameters\n    ----------\n    ica : instance of mne.preprocessing.ICA\n        The ICA object.\n    scores : array-like of float, shape (n_ica_components,) | list of array\n        Scores based on arbitrary metric to characterize ICA components.\n    exclude : array-like of int\n        The components marked for exclusion. If None (default), ICA.exclude\n        will be used.\n    labels : str | list | 'ecg' | 'eog' | None\n        The labels to consider for the axes tests. Defaults to None.\n        If list, should match the outer shape of ``scores``.\n        If 'ecg' or 'eog', the ``labels_`` attributes will be looked up.\n        Note that '/' is used internally for sublabels specifying ECG and\n        EOG channels.\n    axhline : float\n        Draw horizontal line to e.g. visualize rejection threshold.\n    title : str\n        The figure title.\n    figsize : tuple of int | None\n        The figure size. If None it gets set automatically.\n    n_cols : int | None\n        Scores are plotted in a grid. This parameter controls how\n        many to plot side by side before starting a new row. By\n        default, a number will be chosen to make the grid as square as\n        possible.\n    show : bool\n        Show figure if True.\n\n    Returns\n    -------\n    fig : instance of Figure\n        The figure object.\n    \"\"\"\n    import matplotlib.pyplot as plt\n\n    my_range = np.arange(ica.n_components_)\n    if exclude is None:\n        exclude = ica.exclude\n    exclude = np.unique(exclude)\n    if not isinstance(scores[0], list | np.ndarray):\n        scores = [scores]\n    n_scores = len(scores)\n\n    if n_cols is None:\n        # prefer more rows.\n        n_rows = int(np.ceil(np.sqrt(n_scores)))\n        n_cols = (n_scores - 1) // n_rows + 1\n    else:\n        n_cols = min(n_scores, n_cols)\n        n_rows = (n_scores - 1) // n_cols + 1\n\n    if figsize is None:\n        figsize = (6.4 * n_cols, 2.7 * n_rows)\n    fig, axes = plt.subplots(\n        n_rows, n_cols, figsize=figsize, sharex=True, sharey=True, layout=\"constrained\"\n    )\n\n    if isinstance(axes, np.ndarray):\n        axes = axes.flatten()\n    else:\n        axes = [axes]\n\n    fig.suptitle(title)\n\n    if labels == \"ecg\":\n        labels = [label for label in ica.labels_ if label.startswith(\"ecg/\")]\n        labels.sort(key=lambda label: label.split(\"/\")[1])  # sort by index\n        if len(labels) == 0:\n            labels = [label for label in ica.labels_ if label.startswith(\"ecg\")]\n    elif labels == \"eog\":\n        labels = [label for label in ica.labels_ if label.startswith(\"eog/\")]\n        labels.sort(key=lambda label: label.split(\"/\")[1])  # sort by index\n        if len(labels) == 0:\n            labels = [label for label in ica.labels_ if label.startswith(\"eog\")]\n    elif isinstance(labels, str):\n        labels = [labels]\n    elif labels is None:\n        labels = (None,) * n_scores\n\n    if len(labels) != n_scores:\n        raise ValueError(f\"Need as many labels ({len(labels)}) as scores ({n_scores})\")\n\n    for label, this_scores, ax in zip(labels, scores, axes):\n        if len(my_range) != len(this_scores):\n            raise ValueError(\n                \"The length of `scores` must equal the number of ICA components.\"\n            )\n        ax.bar(my_range, this_scores, color=\"gray\", edgecolor=\"k\")\n        for excl in exclude:\n            ax.bar(my_range[excl], this_scores[excl], color=\"r\", edgecolor=\"k\")\n        if axhline is not None:\n            if np.isscalar(axhline):\n                axhline = [axhline]\n            for axl in axhline:\n                ax.axhline(axl, color=\"r\", linestyle=\"--\")\n        ax.set_ylabel(\"score\")\n\n        if label is not None:\n            if \"eog/\" in label:\n                split = label.split(\"/\")\n                label = \", \".join([split[0], split[2]])\n            elif \"/\" in label:\n                label = \", \".join(label.split(\"/\"))\n            ax.set_title(f\"({label})\")\n        ax.set_xlabel(\"ICA components\")\n        ax.set_xlim(-0.6, len(this_scores) - 0.4)\n    fig.canvas.draw()\n    plt_show(show)\n    return fig", "metadata": {}}
{"_id": "mne_mne_viz/ica.py_plot_ica_overlay_code", "title": "plot_ica_overlay", "text": "def plot_ica_overlay(\n    ica,\n    inst,\n    exclude=None,\n    picks=None,\n    start=None,\n    stop=None,\n    title=None,\n    show=True,\n    n_pca_components=None,\n    *,\n    on_baseline=\"warn\",\n    verbose=None,\n):\n    \"\"\"Overlay of raw and cleaned signals given the unmixing matrix.\n\n    This method helps visualizing signal quality and artifact rejection.\n\n    Parameters\n    ----------\n    ica : instance of mne.preprocessing.ICA\n        The ICA object.\n    inst : instance of Raw or Evoked\n        The signal to plot. If `~mne.io.Raw`, the raw data per channel type is displayed\n        before and after cleaning. A second panel with the RMS for MEG sensors and the\n        :term:`GFP` for EEG sensors is displayed. If `~mne.Evoked`, butterfly traces for\n        signals before and after cleaning will be superimposed.\n    exclude : array-like of int | None (default)\n        The components marked for exclusion. If ``None`` (default), the components\n        listed in ``ICA.exclude`` will be used.\n    %(picks_base)s all channels that were included during fitting.\n    start, stop : float | None\n       The first and last time point (in seconds) of the data to plot. If\n       ``inst`` is a `~mne.io.Raw` object, ``start=None`` and ``stop=None``\n       will be translated into ``start=0.`` and ``stop=3.``, respectively. For\n       `~mne.Evoked`, ``None`` refers to the beginning and end of the evoked\n       signal.\n    %(title_none)s\n    %(show)s\n    %(n_pca_components_apply)s\n\n        .. versionadded:: 0.22\n    %(on_baseline_ica)s\n    %(verbose)s\n\n    Returns\n    -------\n    fig : instance of Figure\n        The figure.\n    \"\"\"\n    # avoid circular imports\n    from ..evoked import Evoked\n    from ..io import BaseRaw\n    from ..preprocessing.ica import _check_start_stop\n\n    if ica.current_fit == \"unfitted\":\n        raise RuntimeError(\"You need to fit the ICA first\")\n\n    _validate_type(inst, (BaseRaw, Evoked), \"inst\", \"Raw or Evoked\")\n    if title is None:\n        title = \"Signals before (red) and after (black) cleaning\"\n    picks = ica.ch_names if picks is None else picks\n    picks = _picks_to_idx(inst.info, picks, exclude=())\n    if exclude is None:\n        exclude = ica.exclude\n    if not isinstance(exclude, np.ndarray | list):\n        raise TypeError(f\"exclude must be of type list. Got {type(exclude)}\")\n    if isinstance(inst, BaseRaw):\n        start = 0.0 if start is None else start\n        stop = 3.0 if stop is None else stop\n        start, stop = _check_start_stop(inst, start, stop)\n        raw_cln = ica.apply(\n            inst.copy(),\n            exclude=exclude,\n            start=start,\n            stop=stop,\n            n_pca_components=n_pca_components,\n        )\n        fig = _plot_ica_overlay_raw(\n            raw=inst,\n            raw_cln=raw_cln,\n            picks=picks,\n            start=start,\n            stop=stop,\n            title=title,\n            show=show,\n        )\n    else:\n        assert isinstance(inst, Evoked)\n        inst = inst.copy().crop(start, stop)\n        if picks is not None:\n            with inst.info._unlock():\n                inst.info[\"comps\"] = []  # can be safely disabled\n            inst.pick([inst.ch_names[p] for p in picks])\n        evoked_cln = ica.apply(\n            inst.copy(),\n            exclude=exclude,\n            n_pca_components=n_pca_components,\n            on_baseline=on_baseline,\n        )\n        fig = _plot_ica_overlay_evoked(\n            evoked=inst, evoked_cln=evoked_cln, title=title, show=show\n        )\n\n    return fig", "metadata": {}}
{"_id": "mne_mne_viz/epochs.py_plot_epochs_image_code", "title": "plot_epochs_image", "text": "def plot_epochs_image(\n    epochs,\n    picks=None,\n    sigma=0.0,\n    vmin=None,\n    vmax=None,\n    colorbar=True,\n    order=None,\n    show=True,\n    units=None,\n    scalings=None,\n    cmap=None,\n    fig=None,\n    axes=None,\n    overlay_times=None,\n    combine=None,\n    group_by=None,\n    evoked=True,\n    ts_args=None,\n    title=None,\n    clear=False,\n):\n    \"\"\"Plot Event Related Potential / Fields image.\n\n    Parameters\n    ----------\n    epochs : instance of Epochs\n        The epochs.\n    %(picks_good_data)s\n        ``picks`` interacts with ``group_by`` and ``combine`` to determine the\n        number of figures generated; see Notes.\n    sigma : float\n        The standard deviation of a Gaussian smoothing window applied along\n        the epochs axis of the image. If 0, no smoothing is applied.\n        Defaults to 0.\n    vmin : None | float | callable\n        The min value in the image (and the ER[P/F]). The unit is \u00b5V for\n        EEG channels, fT for magnetometers and fT/cm for gradiometers.\n        If vmin is None and multiple plots are returned, the limit is\n        equalized within channel types.\n        Hint: to specify the lower limit of the data, use\n        ``vmin=lambda data: data.min()``.\n    vmax : None | float | callable\n        The max value in the image (and the ER[P/F]). The unit is \u00b5V for\n        EEG channels, fT for magnetometers and fT/cm for gradiometers.\n        If vmin is None and multiple plots are returned, the limit is\n        equalized within channel types.\n    colorbar : bool\n        Display or not a colorbar.\n    order : None | array of int | callable\n        If not ``None``, order is used to reorder the epochs along the y-axis\n        of the image. If it is an array of :class:`int`, its length should\n        match the number of good epochs. If it is a callable it should accept\n        two positional parameters (``times`` and ``data``, where\n        ``data.shape == (len(good_epochs), len(times))``) and return an\n        :class:`array <numpy.ndarray>` of indices that will sort ``data`` along\n        its first axis.\n    show : bool\n        Show figure if True.\n    units : dict | None\n        The units of the channel types used for axes labels. If None,\n        defaults to ``units=dict(eeg='\u00b5V', grad='fT/cm', mag='fT')``.\n    scalings : dict | None\n        The scalings of the channel types to be applied for plotting.\n        If None, defaults to ``scalings=dict(eeg=1e6, grad=1e13, mag=1e15,\n        eog=1e6)``.\n    cmap : None | colormap | (colormap, bool) | 'interactive'\n        Colormap. If tuple, the first value indicates the colormap to use and\n        the second value is a boolean defining interactivity. In interactive\n        mode the colors are adjustable by clicking and dragging the colorbar\n        with left and right mouse button. Left mouse button moves the scale up\n        and down and right mouse button adjusts the range. Hitting space bar\n        resets the scale. Up and down arrows can be used to change the\n        colormap. If 'interactive', translates to ('RdBu_r', True).\n        If None, \"RdBu_r\" is used, unless the data is all positive, in which\n        case \"Reds\" is used.\n    fig : Figure | None\n        :class:`~matplotlib.figure.Figure` instance to draw the image to.\n        Figure must contain the correct number of axes for drawing the epochs\n        image, the evoked response, and a colorbar (depending on values of\n        ``evoked`` and ``colorbar``). If ``None`` a new figure is created.\n        Defaults to ``None``.\n    axes : list of Axes | dict of list of Axes | None\n        List of :class:`~matplotlib.axes.Axes` objects in which to draw the\n        image, evoked response, and colorbar (in that order). Length of list\n        must be 1, 2, or 3 (depending on values of ``colorbar`` and ``evoked``\n        parameters). If a :class:`dict`, each entry must be a list of Axes\n        objects with the same constraints as above. If both ``axes`` and\n        ``group_by`` are dicts, their keys must match. Providing non-``None``\n        values for both ``fig`` and ``axes``  results in an error. Defaults to\n        ``None``.\n    overlay_times : array_like, shape (n_epochs,) | None\n        Times (in seconds) at which to draw a line on the corresponding row of\n        the image (e.g., a reaction time associated with each epoch). Note that\n        ``overlay_times`` should be ordered to correspond with the\n        :class:`~mne.Epochs` object (i.e., ``overlay_times[0]`` corresponds to\n        ``epochs[0]``, etc).\n    %(combine_plot_epochs_image)s\n    group_by : None | dict\n        Specifies which channels are aggregated into a single figure, with\n        aggregation method determined by the ``combine`` parameter. If not\n        ``None``, one :class:`~matplotlib.figure.Figure` is made per dict\n        entry; the dict key will be used as the figure title and the dict\n        values must be lists of picks (either channel names or integer indices\n        of ``epochs.ch_names``). For example::\n\n            group_by=dict(Left_ROI=[1, 2, 3, 4], Right_ROI=[5, 6, 7, 8])\n\n        Note that within a dict entry all channels must have the same type.\n        ``group_by`` interacts with ``picks`` and ``combine`` to determine the\n        number of figures generated; see Notes. Defaults to ``None``.\n    evoked : bool\n        Draw the ER[P/F] below the image or not.\n    ts_args : None | dict\n        Arguments passed to a call to `~mne.viz.plot_compare_evokeds` to style\n        the evoked plot below the image. Defaults to an empty dictionary,\n        meaning `~mne.viz.plot_compare_evokeds` will be called with default\n        parameters.\n    title : None | str\n        If :class:`str`, will be plotted as figure title. Otherwise, the\n        title will indicate channel(s) or channel type being plotted. Defaults\n        to ``None``.\n    clear : bool\n        Whether to clear the axes before plotting (if ``fig`` or ``axes`` are\n        provided). Defaults to ``False``.\n\n    Returns\n    -------\n    figs : list of Figure\n        One figure per channel, channel type, or group, depending on values of\n        ``picks``, ``group_by``, and ``combine``. See Notes.\n\n    Notes\n    -----\n    You can control how channels are aggregated into one figure or plotted in\n    separate figures through a combination of the ``picks``, ``group_by``, and\n    ``combine`` parameters. If ``group_by`` is a :class:`dict`, the result is\n    one :class:`~matplotlib.figure.Figure` per dictionary key (for any valid\n    values of ``picks`` and ``combine``). If ``group_by`` is ``None``, the\n    number and content of the figures generated depends on the values of\n    ``picks`` and ``combine``, as summarized in this table:\n\n    .. cssclass:: table-bordered\n    .. rst-class:: midvalign\n\n    +----------+----------------------------+------------+-------------------+\n    | group_by | picks                      | combine    | result            |\n    +==========+============================+============+===================+\n    |          | None, int, list of int,    | None,      |                   |\n    | dict     | ch_name, list of ch_names, | string, or | 1 figure per      |\n    |          | ch_type, list of ch_types  | callable   | dict key          |\n    +----------+----------------------------+------------+-------------------+\n    |          | None,                      | None,      |                   |\n    |          | ch_type,                   | string, or | 1 figure per      |\n    |          | list of ch_types           | callable   | ch_type           |\n    | None     +----------------------------+------------+-------------------+\n    |          | int,                       | None       | 1 figure per pick |\n    |          | ch_name,                   +------------+-------------------+\n    |          | list of int,               | string or  | 1 figure          |\n    |          | list of ch_names           | callable   |                   |\n    +----------+----------------------------+------------+-------------------+\n    \"\"\"\n    from ..epochs import EpochsArray\n\n    _validate_type(group_by, (dict, None), \"group_by\")\n\n    units = _handle_default(\"units\", units)\n    scalings = _handle_default(\"scalings\", scalings)\n    if set(units) != set(scalings):\n        raise ValueError(\"Scalings and units must have the same keys.\")\n\n    # is picks a channel type (or None)?\n    picks, picked_types = _picks_to_idx(epochs.info, picks, return_kind=True)\n    ch_types = epochs.info.get_channel_types(picks)\n\n    # `combine` defaults to 'gfp' unless picks are specific channels and\n    # there was no group_by passed\n    combine_given = combine is not None\n    if combine is None and (group_by is not None or picked_types):\n        combine = \"gfp\"\n    # convert `combine` into callable (if None or str)\n    combine_func = _make_combine_callable(combine)\n\n    # handle ts_args (params for the evoked time series)\n    ts_args = dict() if ts_args is None else ts_args\n    manual_ylims = \"ylim\" in ts_args\n    if combine is not None:\n        ts_args[\"show_sensors\"] = False\n    vlines = [0] if (epochs.times[0] < 0 < epochs.times[-1]) else []\n    ts_defaults = dict(\n        colors={\"cond\": \"k\"},\n        title=\"\",\n        show=False,\n        truncate_yaxis=False,\n        truncate_xaxis=False,\n        vlines=vlines,\n        legend=False,\n    )\n    ts_defaults.update(**ts_args)\n    ts_args = ts_defaults.copy()\n\n    # construct a group_by dict if one wasn't supplied\n    if group_by is None:\n        if picked_types:\n            # one fig per ch_type\n            group_by = {\n                ch_type: picks[np.array(ch_types) == ch_type]\n                for ch_type in set(ch_types)\n                if ch_type in _DATA_CH_TYPES_SPLIT + (\"ref_meg\",)\n            }\n        elif combine is None:\n            # one fig per pick\n            group_by = {epochs.ch_names[pick]: [pick] for pick in picks}\n        else:\n            # one fig to rule them all\n            ch_names = np.array(epochs.ch_names)[picks].tolist()\n            key = _set_title_multiple_electrodes(None, combine, ch_names)\n            group_by = {key: picks}\n    else:\n        group_by = deepcopy(group_by)\n    # check for heterogeneous sensor type combinations / \"combining\" 1 channel\n    for this_group, these_picks in group_by.items():\n        this_ch_type = np.array(ch_types)[np.isin(picks, these_picks)]\n        if len(set(this_ch_type)) > 1:\n            types = \", \".join(set(this_ch_type))\n            raise ValueError(\n                f'Cannot combine sensors of different types; \"{this_group}\" contains '\n                f\"types {types}.\"\n            )\n        # now we know they're all the same type...\n        group_by[this_group] = dict(\n            picks=these_picks, ch_type=this_ch_type[0], title=title\n        )\n\n        # are they trying to combine a single channel?\n        if len(these_picks) < 2 and combine_given:\n            warn(\n                f'Only one channel in group \"{this_group}\"; cannot combine by method '\n                f'\"{combine}\".'\n            )\n\n    # check for compatible `fig` / `axes`; instantiate figs if needed; add\n    # fig(s) and axes into group_by\n    needs_colorbar = colorbar and (axes is not None or fig is not None)\n    group_by = _validate_fig_and_axes(\n        fig, axes, group_by, evoked, colorbar=needs_colorbar, clear=clear\n    )\n    del fig, axes, needs_colorbar, clear\n\n    # prepare images in advance to get consistent vmin/vmax.\n    # At the same time, create a subsetted epochs object for each group\n    data = epochs._get_data(on_empty=\"raise\")\n    vmin_vmax = {ch_type: dict(images=list(), norm=list()) for ch_type in set(ch_types)}\n    for this_group, this_group_dict in group_by.items():\n        these_picks = this_group_dict[\"picks\"]\n        this_ch_type = this_group_dict[\"ch_type\"]\n        this_ch_info = [epochs.info[\"chs\"][n] for n in these_picks]\n        these_ch_names = np.array(epochs.info[\"ch_names\"])[these_picks]\n        this_data = data[:, these_picks]\n        # create subsetted epochs object\n        this_info = create_info(\n            sfreq=epochs.info[\"sfreq\"],\n            ch_names=list(these_ch_names),\n            ch_types=[this_ch_type] * len(these_picks),\n        )\n        with this_info._unlock():\n            this_info[\"chs\"] = this_ch_info\n        this_epochs = EpochsArray(this_data, this_info, tmin=epochs.times[0])\n        # apply scalings (only to image, not epochs object), combine channels\n        this_image = combine_func(this_data * scalings[this_ch_type])\n        # handle `order`. NB: this can potentially yield different orderings\n        # in each figure!\n        this_image, _overlay_times = _order_epochs(\n            this_image, epochs.times, order, overlay_times\n        )\n        this_norm = np.all(this_image > 0)\n        # apply smoothing\n        if sigma > 0.0:\n            this_image = gaussian_filter1d(\n                this_image, sigma=sigma, axis=0, mode=\"nearest\"\n            )\n        # update the group_by and vmin_vmax dicts\n        group_by[this_group].update(\n            image=this_image, epochs=this_epochs, norm=this_norm\n        )\n        vmin_vmax[this_ch_type][\"images\"].append(this_image)\n        vmin_vmax[this_ch_type][\"norm\"].append(this_norm)\n\n    # compute overall vmin/vmax for images\n    for ch_type, this_vmin_vmax_dict in vmin_vmax.items():\n        image_list = this_vmin_vmax_dict[\"images\"]\n        image_stack = np.stack(image_list)\n        norm = all(this_vmin_vmax_dict[\"norm\"])\n        vmin_vmax[ch_type] = _setup_vmin_vmax(image_stack, vmin, vmax, norm)\n    del image_stack, vmin, vmax\n\n    # prepare to plot\n    auto_ylims = {ch_type: [0.0, 0.0] for ch_type in set(ch_types)}\n\n    # plot\n    for this_group, this_group_dict in group_by.items():\n        this_ch_type = this_group_dict[\"ch_type\"]\n        this_axes_dict = this_group_dict[\"axes\"]\n        vmin, vmax = vmin_vmax[this_ch_type]\n\n        # plot title\n        if this_group_dict[\"title\"] is None:\n            title = _handle_default(\"titles\").get(this_group, this_group)\n            if isinstance(combine, str) and len(title):\n                _comb = combine.upper() if combine == \"gfp\" else combine\n                _comb = \"std. dev.\" if _comb == \"std\" else _comb\n                title += f\" ({_comb})\"\n\n        # plot the image\n        this_fig = _plot_epochs_image(\n            this_group_dict[\"image\"],\n            epochs=this_group_dict[\"epochs\"],\n            picks=picks,\n            colorbar=colorbar,\n            vmin=vmin,\n            vmax=vmax,\n            cmap=cmap,\n            style_axes=True,\n            norm=this_group_dict[\"norm\"],\n            unit=units[this_ch_type],\n            ax=this_axes_dict,\n            show=False,\n            title=title,\n            combine=combine,\n            combine_given=combine_given,\n            overlay_times=_overlay_times,\n            evoked=evoked,\n            ts_args=ts_args,\n        )\n        group_by[this_group].update(fig=this_fig)\n\n        # detect ylims across figures\n        if evoked and not manual_ylims:\n            # ensure get_ylim works properly\n            this_axes_dict[\"evoked\"].figure.canvas.draw_idle()\n            this_bot, this_top = this_axes_dict[\"evoked\"].get_ylim()\n            this_min = min(this_bot, this_top)\n            this_max = max(this_bot, this_top)\n            curr_min, curr_max = auto_ylims[ch_type]\n            auto_ylims[this_ch_type] = [\n                min(curr_min, this_min),\n                max(curr_max, this_max),\n            ]\n\n    # equalize ylims across figures (does not adjust ticks)\n    if evoked:\n        for this_group_dict in group_by.values():\n            ax = this_group_dict[\"axes\"][\"evoked\"]\n            ch_type = this_group_dict[\"ch_type\"]\n            if not manual_ylims:\n                args = auto_ylims[ch_type]\n                if \"invert_y\" in ts_args:\n                    args = args[::-1]\n                ax.set_ylim(*args)\n    plt_show(show)\n    # impose deterministic order of returned objects\n    return_order = np.array(sorted(group_by))\n    are_ch_types = np.isin(return_order, _VALID_CHANNEL_TYPES)\n    if any(are_ch_types):\n        return_order = np.concatenate(\n            (return_order[are_ch_types], return_order[~are_ch_types])\n        )\n    return [group_by[group][\"fig\"] for group in return_order]", "metadata": {}}
{"_id": "mne_mne_viz/epochs.py_plot_drop_log_code", "title": "plot_drop_log", "text": "def plot_drop_log(\n    drop_log,\n    threshold=0,\n    n_max_plot=20,\n    subject=None,\n    color=\"lightgray\",\n    width=0.8,\n    ignore=(\"IGNORED\",),\n    show=True,\n):\n    \"\"\"Show the channel stats based on a drop_log from Epochs.\n\n    Parameters\n    ----------\n    drop_log : list of list\n        Epoch drop log from Epochs.drop_log.\n    threshold : float\n        The percentage threshold to use to decide whether or not to\n        plot. Default is zero (always plot).\n    n_max_plot : int\n        Maximum number of channels to show stats for.\n    subject : str | None\n        The subject name to use in the title of the plot. If ``None``, do not\n        display a subject name.\n\n        .. versionchanged:: 0.23\n           Added support for ``None``.\n\n        .. versionchanged:: 1.0\n           Defaults to ``None``.\n    color : tuple | str\n        Color to use for the bars.\n    width : float\n        Width of the bars.\n    ignore : list\n        The drop reasons to ignore.\n    show : bool\n        Show figure if True.\n\n    Returns\n    -------\n    fig : instance of matplotlib.figure.Figure\n        The figure.\n    \"\"\"\n    import matplotlib.pyplot as plt\n\n    from ..epochs import _drop_log_stats\n\n    percent = _drop_log_stats(drop_log, ignore)\n    if percent < threshold:\n        logger.info(\n            \"Percent dropped epochs < supplied threshold; not plotting drop log.\"\n        )\n        return\n    absolute = len([x for x in drop_log if len(x) if not any(y in ignore for y in x)])\n    n_epochs_before_drop = len([x for x in drop_log if not any(y in ignore for y in x)])\n\n    scores = Counter([ch for d in drop_log for ch in d if ch not in ignore])\n    ch_names = np.array(list(scores.keys()))\n    counts = np.array(list(scores.values()))\n    # init figure, handle easy case (no drops)\n    fig, ax = plt.subplots(layout=\"constrained\")\n    title = f\"{absolute} of {n_epochs_before_drop} epochs removed ({percent:.1f}%)\"\n    if subject is not None:\n        title = f\"{subject}: {title}\"\n    ax.set_title(title)\n    if len(ch_names) == 0:\n        ax.text(0.5, 0.5, \"No drops\", ha=\"center\", fontsize=14)\n        return fig\n    # count epochs that aren't fully caught by `ignore`\n    n_used = sum([any(ch not in ignore for ch in d) or len(d) == 0 for d in drop_log])\n    # calc plot values\n    n_bars = min(n_max_plot, len(ch_names))\n    x = np.arange(n_bars)\n    y = 100 * counts / n_used\n    order = np.flipud(np.argsort(y))\n    ax.bar(x, y[order[:n_bars]], color=color, width=width, align=\"center\")\n    ax.set_xticks(x)\n    ax.set_xticklabels(\n        ch_names[order[:n_bars]], rotation=45, size=10, horizontalalignment=\"right\"\n    )\n    ax.set_ylabel(\"% of epochs removed\")\n    ax.grid(axis=\"y\")\n    plt_show(show)\n    return fig", "metadata": {}}
{"_id": "mne_mne_viz/epochs.py_plot_epochs_code", "title": "plot_epochs", "text": "def plot_epochs(\n    epochs,\n    picks=None,\n    scalings=None,\n    n_epochs=20,\n    n_channels=20,\n    title=None,\n    events=False,\n    event_color=None,\n    order=None,\n    show=True,\n    block=False,\n    decim=\"auto\",\n    noise_cov=None,\n    butterfly=False,\n    show_scrollbars=True,\n    show_scalebars=True,\n    epoch_colors=None,\n    event_id=None,\n    group_by=\"type\",\n    precompute=None,\n    use_opengl=None,\n    *,\n    theme=None,\n    overview_mode=None,\n    splash=True,\n):\n    \"\"\"Visualize epochs.\n\n    Bad epochs can be marked with a left click on top of the epoch. Bad\n    channels can be selected by clicking the channel name on the left side of\n    the main axes. Calling this function drops all the selected bad epochs as\n    well as bad epochs marked beforehand with rejection parameters.\n\n    Parameters\n    ----------\n    epochs : instance of Epochs\n        The epochs object.\n    %(picks_good_data)s\n    %(scalings)s\n    n_epochs : int\n        The number of epochs per view. Defaults to 20.\n    n_channels : int\n        The number of channels per view. Defaults to 20.\n    title : str | None\n        The title of the window. If None, the event names (from\n        ``epochs.event_id``) will be displayed. Defaults to None.\n    events : bool | array, shape (n_events, 3)\n        Events to show with vertical bars. You can use `~mne.viz.plot_events`\n        as a legend for the colors. By default, the coloring scheme is the\n        same. ``True`` plots ``epochs.events``. Defaults to ``False`` (do not\n        plot events).\n\n        .. warning::  If the epochs have been resampled, the events no longer\n            align with the data.\n\n        .. versionadded:: 0.14.0\n\n        .. versionchanged:: 1.6\n            Passing ``events=None`` was disallowed.\n            The new equivalent is ``events=False``.\n    %(event_color)s\n        Defaults to ``None``.\n    order : array of str | None\n        Order in which to plot channel types.\n\n        .. versionadded:: 0.18.0\n    show : bool\n        Show figure if True. Defaults to True.\n    block : bool\n        Whether to halt program execution until the figure is closed.\n        Useful for rejecting bad trials on the fly by clicking on an epoch.\n        Defaults to False.\n    decim : int | 'auto'\n        Amount to decimate the data during display for speed purposes.\n        You should only decimate if the data are sufficiently low-passed,\n        otherwise aliasing can occur. The 'auto' mode (default) uses\n        the decimation that results in a sampling rate at least three times\n        larger than ``info['lowpass']`` (e.g., a 40 Hz lowpass will result in\n        at least a 120 Hz displayed sample rate).\n\n        .. versionadded:: 0.15.0\n    noise_cov : instance of Covariance | str | None\n        Noise covariance used to whiten the data while plotting.\n        Whitened data channels are scaled by ``scalings['whitened']``,\n        and their channel names are shown in italic.\n        Can be a string to load a covariance from disk.\n        See also :meth:`mne.Evoked.plot_white` for additional inspection\n        of noise covariance properties when whitening evoked data.\n        For data processed with SSS, the effective dependence between\n        magnetometers and gradiometers may introduce differences in scaling,\n        consider using :meth:`mne.Evoked.plot_white`.\n\n        .. versionadded:: 0.16.0\n    butterfly : bool\n        Whether to directly call the butterfly view.\n\n        .. versionadded:: 0.18.0\n    %(show_scrollbars)s\n    %(show_scalebars)s\n\n        .. versionadded:: 0.24.0\n    epoch_colors : list of (n_epochs) list (of n_channels) | None\n        Colors to use for individual epochs. If None, use default colors.\n    event_id : bool | dict\n        Determines to label the event markers on the plot. If ``True``, uses\n        ``epochs.event_id``. If ``False``, uses integer event codes instead of IDs.\n        If a ``dict`` is passed, uses its *keys* as event labels on the plot for\n        entries whose *values* are integer codes for events being drawn. Ignored if\n        ``events=False``.\n\n        .. versionadded:: 0.20\n    %(group_by_browse)s\n    %(precompute)s\n    %(use_opengl)s\n    %(theme_pg)s\n\n        .. versionadded:: 1.0\n    %(overview_mode)s\n\n        .. versionadded:: 1.1\n    %(splash)s\n\n        .. versionadded:: 1.6\n\n    Returns\n    -------\n    %(browser)s\n\n    Notes\n    -----\n    The arrow keys (up/down/left/right) can be used to navigate between\n    channels and epochs and the scaling can be adjusted with - and + (or =)\n    keys, but this depends on the backend matplotlib is configured to use\n    (e.g., mpl.use(``TkAgg``) should work). Full screen mode can be toggled\n    with f11 key. The amount of epochs and channels per view can be adjusted\n    with home/end and page down/page up keys. ``h`` key plots a histogram of\n    peak-to-peak values along with the used rejection thresholds. Butterfly\n    plot can be toggled with ``b`` key. Left mouse click adds a vertical line\n    to the plot. Click 'help' button at bottom left corner of the plotter to\n    view all the options.\n\n    %(notes_2d_backend)s\n\n    .. versionadded:: 0.10.0\n    \"\"\"\n    from ._figure import _get_browser\n\n    epochs._handle_empty(\"raise\", \"plot\")\n    epochs.drop_bad()\n    info = epochs.info.copy()\n    sfreq = info[\"sfreq\"]\n    projs = info[\"projs\"]\n    projs_on = np.full_like(projs, epochs.proj, dtype=bool)\n    if not epochs.proj:\n        with info._unlock():\n            info[\"projs\"] = list()\n\n    # handle defaults / check arg validity\n    color = _handle_default(\"color\", None)\n    scalings = _compute_scalings(scalings, epochs)\n    scalings = _handle_default(\"scalings_plot_raw\", scalings)\n    if scalings[\"whitened\"] == \"auto\":\n        scalings[\"whitened\"] = 1.0\n    units = _handle_default(\"units\", None)\n    unit_scalings = _handle_default(\"scalings\", None)\n    decim, picks_data = _handle_decim(epochs.info.copy(), decim, None)\n    noise_cov = _check_cov(noise_cov, epochs.info)\n    _check_option(\"group_by\", group_by, (\"selection\", \"position\", \"original\", \"type\"))\n    # handle event labels\n    _validate_type(event_id, (bool, dict, None), \"event_id\")\n    if not event_id:  # False or None\n        event_id = dict()\n    else:\n        # make our own copy of the dict\n        event_id = dict() if event_id is True else event_id.copy()  # to dict\n        # TODO: when min py=3.9, change to `epochs.event_id | event_id` (maybe).\n        # Passed-in event_id should take precedence, i.e., not replace existing\n        # keys *or* repeat existing values. For example, if epochs.event_id has\n        # a=1 and passed-in event_id has f=1, the second takes precedence.\n        event_values = set(event_id.values())\n        event_id.update(\n            (k, v)\n            for k, v in epochs.event_id.items()\n            if k not in event_id and v not in event_values\n        )\n    event_id_rev = {v: k for k, v in event_id.items()}\n    # validate epoch_colors\n    _validate_type(epoch_colors, (list, None), \"epoch_colors\")\n    if epoch_colors is not None:\n        if len(epoch_colors) != len(epochs.events):\n            msg = (\n                \"epoch_colors must have length equal to the number of \"\n                f\"epochs ({len(epochs)}); got length {len(epoch_colors)}.\"\n            )\n            raise ValueError(msg)\n        for ix, this_colors in enumerate(epoch_colors):\n            _validate_type(this_colors, list, f\"epoch_colors[{ix}]\")\n            if len(this_colors) != len(epochs.ch_names):\n                msg = (\n                    f\"epoch colors for epoch {ix} has length \"\n                    f\"{len(this_colors)}, expected {len(epochs.ch_names)}.\"\n                )\n                raise ValueError(msg)\n\n    # handle time dimension\n    n_epochs = min(n_epochs, len(epochs))\n    n_times = len(epochs) * len(epochs.times)\n    duration = n_epochs * len(epochs.times) / sfreq\n    # NB: this includes start and end of data:\n    boundary_times = np.arange(len(epochs) + 1) * len(epochs.times) / sfreq\n\n    # events\n    _validate_type(events, (bool, np.ndarray), \"events\")\n    if events is False:\n        event_nums = None\n        event_times = None\n    else:  # True or ndarray\n        if events is True:  # use epochs.events\n            events = epochs.events\n        event_nums = events[:, 2]\n        event_samps = events[:, 0]\n        epoch_n_samps = len(epochs.times)\n        # handle overlapping epochs (each event may show up in multiple places)\n        boundaries = epochs.events[:, [0]] + np.array([-1, 1]) * epochs.time_as_index(\n            [0, epochs.tmax]\n        )\n        in_bounds = np.logical_and(\n            boundaries[:, [0]] <= event_samps, event_samps < boundaries[:, [1]]\n        )\n        event_ixs = [np.nonzero(a)[0] for a in in_bounds.T]\n        warned = False\n        event_times = list()\n        event_numbers = list()\n        for samp, num, _ixs in zip(event_samps, event_nums, event_ixs):\n            relevant_epoch_events = epochs.events[:, 0][_ixs]\n            if len(relevant_epoch_events) > 1 and not warned:\n                logger.info(\n                    \"You seem to have overlapping epochs. Some event \"\n                    \"lines may be duplicated in the plot.\"\n                )\n                warned = True\n            offsets = samp - relevant_epoch_events + epochs.time_as_index(0)\n            this_event_times = (_ixs * epoch_n_samps + offsets) / sfreq\n            event_times.extend(this_event_times)\n            event_numbers.extend([num] * len(_ixs))\n        event_nums = np.array(event_numbers)\n        event_times = np.array(event_times)\n\n    event_color_dict = _make_event_color_dict(event_color, events, event_id)\n\n    # determine trace order\n    picks = _picks_to_idx(info, picks)\n    n_channels = min(n_channels, len(picks))\n    ch_names = np.array(epochs.ch_names)\n    ch_types = np.array(epochs.get_channel_types())\n    order = _get_channel_plotting_order(order, ch_types, picks)\n    selections = None\n    if group_by in (\"selection\", \"position\"):\n        selections = _setup_channel_selections(epochs, group_by, order)\n        order = np.concatenate(list(selections.values()))\n        default_selection = list(selections)[0]\n        n_channels = len(selections[default_selection])\n\n    # generate window title\n    if title is None:\n        title = epochs._get_name(count=\"total\", sep=\"\u2022\", ms=None)\n        if title is None or len(title) == 0:\n            title = \"Epochs\"\n    elif not isinstance(title, str):\n        raise TypeError(f\"title must be None or a string, got a {type(title)}\")\n\n    precompute = _handle_precompute(precompute)\n    params = dict(\n        inst=epochs,\n        info=info,\n        n_epochs=n_epochs,\n        # channels and channel order\n        ch_names=ch_names,\n        ch_types=ch_types,\n        ch_order=order,\n        picks=order[:n_channels],\n        n_channels=n_channels,\n        picks_data=picks_data,\n        group_by=group_by,\n        ch_selections=selections,\n        # time\n        t_start=0,\n        duration=duration,\n        n_times=n_times,\n        first_time=0,\n        time_format=\"float\",\n        decim=decim,\n        boundary_times=boundary_times,\n        # events\n        event_id_rev=event_id_rev,\n        event_color_dict=event_color_dict,\n        event_nums=event_nums,\n        event_times=event_times,\n        # preprocessing\n        projs=projs,\n        projs_on=projs_on,\n        apply_proj=epochs.proj,\n        remove_dc=True,\n        filter_coefs=None,\n        filter_bounds=None,\n        noise_cov=noise_cov,\n        use_noise_cov=noise_cov is not None,\n        # scalings\n        scalings=scalings,\n        units=units,\n        unit_scalings=unit_scalings,\n        # colors\n        ch_color_bad=\"lightgray\",\n        ch_color_dict=color,\n        epoch_color_bad=(1, 0, 0),\n        epoch_colors=epoch_colors,\n        # display\n        butterfly=butterfly,\n        clipping=None,\n        scrollbars_visible=show_scrollbars,\n        scalebars_visible=show_scalebars,\n        window_title=title,\n        xlabel=\"Epoch number\",\n        # pyqtgraph-specific\n        precompute=precompute,\n        use_opengl=use_opengl,\n        theme=theme,\n        overview_mode=overview_mode,\n        splash=splash,\n    )\n\n    fig = _get_browser(show=show, block=block, **params)\n\n    return fig", "metadata": {}}
{"_id": "mne_mne_viz/epochs.py_plot_epochs_psd_code", "title": "plot_epochs_psd", "text": "def plot_epochs_psd(\n    epochs,\n    fmin=0,\n    fmax=np.inf,\n    tmin=None,\n    tmax=None,\n    proj=False,\n    bandwidth=None,\n    adaptive=False,\n    low_bias=True,\n    normalization=\"length\",\n    picks=None,\n    ax=None,\n    color=\"black\",\n    xscale=\"linear\",\n    area_mode=\"std\",\n    area_alpha=0.33,\n    dB=True,\n    estimate=\"power\",\n    show=True,\n    n_jobs=None,\n    average=False,\n    line_alpha=None,\n    spatial_colors=True,\n    sphere=None,\n    exclude=\"bads\",\n    verbose=None,\n):\n    \"\"\"%(plot_psd_doc)s.\n\n    Parameters\n    ----------\n    epochs : instance of Epochs\n        The epochs object.\n    %(fmin_fmax_psd)s\n    %(tmin_tmax_psd)s\n    %(proj_psd)s\n    bandwidth : float\n        The bandwidth of the multi taper windowing function in Hz. The default\n        value is a window half-bandwidth of 4.\n    adaptive : bool\n        Use adaptive weights to combine the tapered spectra into PSD\n        (slow, use n_jobs >> 1 to speed up computation).\n    low_bias : bool\n        Only use tapers with more than 90%% spectral concentration within\n        bandwidth.\n    %(normalization)s\n    %(picks_good_data_noref)s\n    %(ax_plot_psd)s\n    %(color_plot_psd)s\n    %(xscale_plot_psd)s\n    %(area_mode_plot_psd)s\n    %(area_alpha_plot_psd)s\n    %(dB_plot_psd)s\n    %(estimate_plot_psd)s\n    %(show)s\n    %(n_jobs)s\n    %(average_plot_psd)s\n    %(line_alpha_plot_psd)s\n    %(spatial_colors_psd)s\n    %(sphere_topomap_auto)s\n    exclude : list of str | 'bads'\n        Channels names to exclude from being shown. If 'bads', the bad channels\n        are excluded. Pass an empty list to plot all channels (including\n        channels marked \"bad\", if any).\n\n        .. versionadded:: 0.24.0\n    %(verbose)s\n\n    Returns\n    -------\n    fig : instance of Figure\n        Figure with frequency spectra of the data channels.\n\n    Notes\n    -----\n    %(notes_plot_*_psd_func)s\n    \"\"\"\n    from ..time_frequency import Spectrum\n\n    init_kw, plot_kw = _split_psd_kwargs(plot_fun=Spectrum.plot)\n    return epochs.compute_psd(**init_kw).plot(**plot_kw)", "metadata": {}}
{"_id": "mne_mne_viz/evoked.py_plot_evoked_code", "title": "plot_evoked", "text": "def plot_evoked(\n    evoked,\n    picks=None,\n    exclude=\"bads\",\n    unit=True,\n    show=True,\n    ylim=None,\n    xlim=\"tight\",\n    proj=False,\n    hline=None,\n    units=None,\n    scalings=None,\n    titles=None,\n    axes=None,\n    gfp=False,\n    window_title=None,\n    spatial_colors=False,\n    zorder=\"unsorted\",\n    selectable=True,\n    noise_cov=None,\n    time_unit=\"s\",\n    sphere=None,\n    *,\n    highlight=None,\n    verbose=None,\n):\n    \"\"\"Plot evoked data using butterfly plots.\n\n    Left click to a line shows the channel name. Selecting an area by clicking\n    and holding left mouse button plots a topographic map of the painted area.\n\n    .. note:: If bad channels are not excluded they are shown in red.\n\n    Parameters\n    ----------\n    evoked : instance of Evoked\n        The evoked data.\n    %(picks_all)s\n    exclude : list of str | ``'bads'``\n        Channels names to exclude from being shown. If ``'bads'``, the\n        bad channels are excluded.\n    unit : bool\n        Scale plot with channel (SI) unit.\n    show : bool\n        Show figure if True.\n    %(evoked_ylim_plot)s\n    xlim : ``'tight'`` | tuple | None\n        Limits for the X-axis of the plots.\n    %(proj_plot)s\n    hline : list of float | None\n        The values at which to show an horizontal line.\n    units : dict | None\n        The units of the channel types used for axes labels. If None,\n        defaults to ``dict(eeg='\u00b5V', grad='fT/cm', mag='fT')``.\n    scalings : dict | None\n        The scalings of the channel types to be applied for plotting. If None,\n        defaults to ``dict(eeg=1e6, grad=1e13, mag=1e15)``.\n    titles : dict | None\n        The titles associated with the channels. If None, defaults to\n        ``dict(eeg='EEG', grad='Gradiometers', mag='Magnetometers')``.\n    axes : instance of Axes | list | None\n        The axes to plot to. If list, the list must be a list of Axes of\n        the same length as the number of channel types. If instance of\n        Axes, there must be only one channel type plotted.\n    gfp : bool | ``'only'``\n        Plot the global field power (GFP) or the root mean square (RMS) of the\n        data. For MEG data, this will plot the RMS. For EEG, it plots GFP,\n        i.e. the standard deviation of the signal across channels. The GFP is\n        equivalent to the RMS of an average-referenced signal.\n\n        - ``True``\n            Plot GFP or RMS (for EEG and MEG, respectively) and traces for all\n            channels.\n        - ``'only'``\n            Plot GFP or RMS (for EEG and MEG, respectively), and omit the\n            traces for individual channels.\n\n        The color of the GFP/RMS trace will be green if\n        ``spatial_colors=False``, and black otherwise.\n\n        .. versionchanged:: 0.23\n           Plot GFP for EEG instead of RMS. Label RMS traces correctly as such.\n    window_title : str | None\n        The title to put at the top of the figure.\n    %(spatial_colors)s\n    zorder : str | callable\n        Which channels to put in the front or back. Only matters if\n        ``spatial_colors`` is used.\n        If str, must be ``std`` or ``unsorted`` (defaults to ``unsorted``). If\n        ``std``, data with the lowest standard deviation (weakest effects) will\n        be put in front so that they are not obscured by those with stronger\n        effects. If ``unsorted``, channels are z-sorted as in the evoked\n        instance.\n        If callable, must take one argument: a numpy array of the same\n        dimensionality as the evoked raw data; and return a list of\n        unique integers corresponding to the number of channels.\n\n        .. versionadded:: 0.13.0\n\n    selectable : bool\n        Whether to use interactive features. If True (default), it is possible\n        to paint an area to draw topomaps. When False, the interactive features\n        are disabled. Disabling interactive features reduces memory consumption\n        and is useful when using ``axes`` parameter to draw multiaxes figures.\n\n        .. versionadded:: 0.13.0\n\n    noise_cov : instance of Covariance | str | None\n        Noise covariance used to whiten the data while plotting.\n        Whitened data channel names are shown in italic.\n        Can be a string to load a covariance from disk.\n        See also :meth:`mne.Evoked.plot_white` for additional inspection\n        of noise covariance properties when whitening evoked data.\n        For data processed with SSS, the effective dependence between\n        magnetometers and gradiometers may introduce differences in scaling,\n        consider using :meth:`mne.Evoked.plot_white`.\n\n        .. versionadded:: 0.16.0\n    %(time_unit)s\n\n        .. versionadded:: 0.16\n    %(sphere_topomap_auto)s\n    highlight : array-like of float, shape(2,) | array-like of float, shape (n, 2) | None\n        Segments of the data to highlight by means of a light-yellow\n        background color. Can be used to put visual emphasis on certain\n        time periods. The time periods must be specified as ``array-like``\n        objects in the form of ``(t_start, t_end)`` in the unit given by the\n        ``time_unit`` parameter.\n        Multiple time periods can be specified by passing an ``array-like``\n        object of individual time periods (e.g., for 3 time periods, the shape\n        of the passed object would be ``(3, 2)``. If ``None``, no highlighting\n        is applied.\n\n        .. versionadded:: 1.1\n    %(verbose)s\n\n    Returns\n    -------\n    fig : instance of matplotlib.figure.Figure\n        Figure containing the butterfly plots.\n\n    See Also\n    --------\n    mne.viz.plot_evoked_white\n    \"\"\"  # noqa: E501\n    return _plot_evoked(\n        evoked=evoked,\n        picks=picks,\n        exclude=exclude,\n        unit=unit,\n        show=show,\n        ylim=ylim,\n        proj=proj,\n        xlim=xlim,\n        hline=hline,\n        units=units,\n        scalings=scalings,\n        titles=titles,\n        axes=axes,\n        plot_type=\"butterfly\",\n        gfp=gfp,\n        window_title=window_title,\n        spatial_colors=spatial_colors,\n        selectable=selectable,\n        zorder=zorder,\n        noise_cov=noise_cov,\n        time_unit=time_unit,\n        sphere=sphere,\n        highlight=highlight,\n    )", "metadata": {}}
{"_id": "mne_mne_viz/evoked.py_plot_evoked_topo_code", "title": "plot_evoked_topo", "text": "def plot_evoked_topo(\n    evoked,\n    layout=None,\n    layout_scale=0.945,\n    color=None,\n    border=\"none\",\n    ylim=None,\n    scalings=None,\n    title=None,\n    proj=False,\n    vline=(0.0,),\n    fig_background=None,\n    merge_grads=False,\n    legend=True,\n    axes=None,\n    background_color=\"w\",\n    noise_cov=None,\n    exclude=\"bads\",\n    select=False,\n    show=True,\n):\n    \"\"\"Plot 2D topography of evoked responses.\n\n    Clicking on the plot of an individual sensor opens a new figure showing\n    the evoked response for the selected sensor.\n\n    Parameters\n    ----------\n    evoked : list of Evoked | Evoked\n        The evoked response to plot.\n    layout : instance of Layout | None\n        Layout instance specifying sensor positions (does not need to\n        be specified for Neuromag data). If possible, the correct layout is\n        inferred from the data.\n    layout_scale : float\n        Scaling factor for adjusting the relative size of the layout\n        on the canvas.\n    color : list of color | color | None\n        Everything matplotlib accepts to specify colors. If not list-like,\n        the color specified will be repeated. If None, colors are\n        automatically drawn.\n    border : str\n        Matplotlib borders style to be used for each sensor plot.\n    %(evoked_ylim_plot)s\n    scalings : dict | None\n        The scalings of the channel types to be applied for plotting. If None,`\n        defaults to ``dict(eeg=1e6, grad=1e13, mag=1e15)``.\n    title : str\n        Title of the figure.\n    proj : bool | ``'interactive'``\n        If true SSP projections are applied before display. If ``'interactive'``,\n        a check box for reversible selection of SSP projection vectors will\n        be shown.\n    vline : list of float | float | None\n        The values at which to show a vertical line.\n    fig_background : None | ndarray\n        A background image for the figure. This must work with a call to\n        ``plt.imshow``. Defaults to None.\n    merge_grads : bool\n        Whether to use RMS value of gradiometer pairs. Only works for Neuromag\n        data. Defaults to False.\n    legend : bool | int | str | tuple\n        If True, create a legend based on evoked.comment. If False, disable the\n        legend. Otherwise, the legend is created and the parameter value is\n        passed as the location parameter to the matplotlib legend call. It can\n        be an integer (e.g. 0 corresponds to upper right corner of the plot),\n        a string (e.g. ``'upper right'``), or a tuple (x, y coordinates of the\n        lower left corner of the legend in the axes coordinate system).\n        See matplotlib documentation for more details.\n    axes : instance of matplotlib Axes | None\n        Axes to plot into. If None, axes will be created.\n    background_color : color\n        Background color. Typically ``'k'`` (black) or ``'w'`` (white; default).\n\n        .. versionadded:: 0.15.0\n    noise_cov : instance of Covariance | str | None\n        Noise covariance used to whiten the data while plotting.\n        Whitened data channel names are shown in italic.\n        Can be a string to load a covariance from disk.\n\n        .. versionadded:: 0.16.0\n    exclude : list of str | ``'bads'``\n        Channels names to exclude from the plot. If ``'bads'``, the\n        bad channels are excluded. By default, exclude is set to ``'bads'``.\n    select : bool\n        Whether to enable the lasso-selection tool to enable the user to select\n        channels. The selected channels will be available in\n        ``fig.lasso.selection``.\n\n        .. versionadded:: 1.10.0\n    exclude : list of str | ``'bads'``\n        Channels names to exclude from the plot. If ``'bads'``, the\n        bad channels are excluded. By default, exclude is set to ``'bads'``.\n    show : bool\n        Show figure if True.\n\n    Returns\n    -------\n    fig : instance of matplotlib.figure.Figure\n        Images of evoked responses at sensor locations.\n    \"\"\"\n    if type(evoked) not in (tuple, list):\n        evoked = [evoked]\n\n    background_color = _to_rgb(background_color, name=\"background_color\")\n    dark_background = np.mean(background_color) < 0.5\n    if dark_background:\n        fig_facecolor = background_color\n        axis_facecolor = background_color\n        font_color = \"w\"\n    else:\n        fig_facecolor = background_color\n        axis_facecolor = background_color\n        font_color = \"k\"\n\n    if isinstance(color, tuple | list):\n        if len(color) != len(evoked):\n            raise ValueError(\n                \"Lists of evoked objects and colors must have the same length\"\n            )\n    elif color is None:\n        if dark_background:\n            color = [\"w\"] + _get_color_list()\n        else:\n            color = _get_color_list()\n        color = color * ((len(evoked) % len(color)) + 1)\n        color = color[: len(evoked)]\n    else:\n        if not isinstance(color, str):\n            raise ValueError(\"color must be of type tuple, list, str, or None.\")\n        color = cycle([color])\n\n    return _plot_evoked_topo(\n        evoked=evoked,\n        layout=layout,\n        layout_scale=layout_scale,\n        color=color,\n        border=border,\n        ylim=ylim,\n        scalings=scalings,\n        title=title,\n        proj=proj,\n        vline=vline,\n        fig_facecolor=fig_facecolor,\n        fig_background=fig_background,\n        axis_facecolor=axis_facecolor,\n        font_color=font_color,\n        merge_channels=merge_grads,\n        legend=legend,\n        noise_cov=noise_cov,\n        axes=axes,\n        exclude=exclude,\n        select=select,\n        show=show,\n    )", "metadata": {}}
{"_id": "mne_mne_viz/evoked.py_plot_evoked_image_code", "title": "plot_evoked_image", "text": "def plot_evoked_image(\n    evoked,\n    picks=None,\n    exclude=\"bads\",\n    unit=True,\n    show=True,\n    clim=None,\n    xlim=\"tight\",\n    proj=False,\n    units=None,\n    scalings=None,\n    titles=None,\n    axes=None,\n    cmap=\"RdBu_r\",\n    colorbar=True,\n    mask=None,\n    mask_style=None,\n    mask_cmap=\"Greys\",\n    mask_alpha=0.25,\n    time_unit=\"s\",\n    show_names=\"auto\",\n    group_by=None,\n    sphere=None,\n):\n    \"\"\"Plot evoked data as images.\n\n    Parameters\n    ----------\n    evoked : instance of Evoked\n        The evoked data.\n    %(picks_all)s\n        This parameter can also be used to set the order the channels\n        are shown in, as the channel image is sorted by the order of picks.\n    exclude : list of str | 'bads'\n        Channels names to exclude from being shown. If 'bads', the\n        bad channels are excluded.\n    unit : bool\n        Scale plot with channel (SI) unit.\n    show : bool\n        Show figure if True.\n    clim : dict | None\n        Color limits for plots (after scaling has been applied). e.g.\n        ``clim = dict(eeg=[-20, 20])``.\n        Valid keys are eeg, mag, grad, misc. If None, the clim parameter\n        for each channel equals the pyplot default.\n    xlim : 'tight' | tuple | None\n        X limits for plots.\n    proj : bool | 'interactive'\n        If true SSP projections are applied before display. If 'interactive',\n        a check box for reversible selection of SSP projection vectors will\n        be shown.\n    units : dict | None\n        The units of the channel types used for axes labels. If None,\n        defaults to ``dict(eeg='\u00b5V', grad='fT/cm', mag='fT')``.\n    scalings : dict | None\n        The scalings of the channel types to be applied for plotting. If None,`\n        defaults to ``dict(eeg=1e6, grad=1e13, mag=1e15)``.\n    titles : dict | None\n        The titles associated with the channels. If None, defaults to\n        ``dict(eeg='EEG', grad='Gradiometers', mag='Magnetometers')``.\n    axes : instance of Axes | list | dict | None\n        The axes to plot to. If list, the list must be a list of Axes of\n        the same length as the number of channel types. If instance of\n        Axes, there must be only one channel type plotted.\n        If ``group_by`` is a dict, this cannot be a list, but it can be a dict\n        of lists of axes, with the keys matching those of ``group_by``. In that\n        case, the provided axes will be used for the corresponding groups.\n        Defaults to ``None``.\n    cmap : matplotlib colormap | (colormap, bool) | 'interactive'\n        Colormap. If tuple, the first value indicates the colormap to use and\n        the second value is a boolean defining interactivity. In interactive\n        mode the colors are adjustable by clicking and dragging the colorbar\n        with left and right mouse button. Left mouse button moves the scale up\n        and down and right mouse button adjusts the range. Hitting space bar\n        resets the scale. Up and down arrows can be used to change the\n        colormap. If 'interactive', translates to ``('RdBu_r', True)``.\n        Defaults to ``'RdBu_r'``.\n    colorbar : bool\n        If True, plot a colorbar. Defaults to True.\n\n        .. versionadded:: 0.16\n    mask : ndarray | None\n        An array of booleans of the same shape as the data. Entries of the\n        data that correspond to ``False`` in the mask are masked (see\n        ``do_mask`` below). Useful for, e.g., masking for statistical\n        significance.\n\n        .. versionadded:: 0.16\n    mask_style : None | 'both' | 'contour' | 'mask'\n        If ``mask`` is not None: if 'contour', a contour line is drawn around\n        the masked areas (``True`` in ``mask``). If 'mask', entries not\n        ``True`` in ``mask`` are shown transparently. If 'both', both a contour\n        and transparency are used.\n        If ``None``, defaults to 'both' if ``mask`` is not None, and is ignored\n        otherwise.\n\n         .. versionadded:: 0.16\n    mask_cmap : matplotlib colormap | (colormap, bool) | 'interactive'\n        The colormap chosen for masked parts of the image (see below), if\n        ``mask`` is not ``None``. If None, ``cmap`` is reused. Defaults to\n        ``Greys``. Not interactive. Otherwise, as ``cmap``.\n    mask_alpha : float\n        A float between 0 and 1. If ``mask`` is not None, this sets the\n        alpha level (degree of transparency) for the masked-out segments.\n        I.e., if 0, masked-out segments are not visible at all.\n        Defaults to .25.\n\n        .. versionadded:: 0.16\n    time_unit : str\n        The units for the time axis, can be \"ms\" or \"s\" (default).\n\n        .. versionadded:: 0.16\n    show_names : bool | 'auto' | 'all'\n        Determines if channel names should be plotted on the y axis. If False,\n        no names are shown. If True, ticks are set automatically by matplotlib\n        and the corresponding channel names are shown. If \"all\", all channel\n        names are shown. If \"auto\", is set to False if ``picks`` is ``None``,\n        to ``True`` if ``picks`` contains 25 or more entries, or to \"all\"\n        if ``picks`` contains fewer than 25 entries.\n    group_by : None | dict\n        If a dict, the values must be picks, and ``axes`` must also be a dict\n        with matching keys, or None. If ``axes`` is None, one figure and one\n        axis will be created for each entry in ``group_by``.Then, for each\n        entry, the picked channels will be plotted to the corresponding axis.\n        If ``titles`` are None, keys will become plot titles. This is useful\n        for e.g. ROIs. Each entry must contain only one channel type.\n        For example::\n\n            group_by=dict(Left_ROI=[1, 2, 3, 4], Right_ROI=[5, 6, 7, 8])\n\n        If None, all picked channels are plotted to the same axis.\n    %(sphere_topomap_auto)s\n\n    Returns\n    -------\n    fig : instance of matplotlib.figure.Figure\n        Figure containing the images.\n    \"\"\"\n    return _plot_evoked(\n        evoked=evoked,\n        picks=picks,\n        exclude=exclude,\n        unit=unit,\n        show=show,\n        ylim=clim,\n        proj=proj,\n        xlim=xlim,\n        hline=None,\n        units=units,\n        scalings=scalings,\n        titles=titles,\n        axes=axes,\n        plot_type=\"image\",\n        cmap=cmap,\n        colorbar=colorbar,\n        mask=mask,\n        mask_style=mask_style,\n        mask_cmap=mask_cmap,\n        mask_alpha=mask_alpha,\n        time_unit=time_unit,\n        show_names=show_names,\n        group_by=group_by,\n        sphere=sphere,\n    )", "metadata": {}}
{"_id": "mne_mne_viz/evoked.py_plot_evoked_white_code", "title": "plot_evoked_white", "text": "def plot_evoked_white(\n    evoked,\n    noise_cov,\n    show=True,\n    rank=None,\n    time_unit=\"s\",\n    sphere=None,\n    axes=None,\n    *,\n    spatial_colors=\"auto\",\n    verbose=None,\n):\n    \"\"\"Plot whitened evoked response.\n\n    Plots the whitened evoked response and the whitened GFP as described in\n    :footcite:`EngemannGramfort2015`. This function is especially useful for\n    investigating noise covariance properties to determine if data are\n    properly whitened (e.g., achieving expected values in line with model\n    assumptions, see Notes below).\n\n    Parameters\n    ----------\n    evoked : instance of mne.Evoked\n        The evoked response.\n    noise_cov : list | instance of Covariance | path-like\n        The noise covariance. Can be a string to load a covariance from disk.\n    show : bool\n        Show figure if True.\n    %(rank_none)s\n    time_unit : str\n        The units for the time axis, can be \"ms\" or \"s\" (default).\n\n        .. versionadded:: 0.16\n    %(sphere_topomap_auto)s\n    axes : list | None\n        List of axes to plot into.\n\n        .. versionadded:: 0.21.0\n    %(spatial_colors)s\n\n        .. versionadded:: 1.8.0\n    %(verbose)s\n\n    Returns\n    -------\n    fig : instance of matplotlib.figure.Figure\n        The figure object containing the plot.\n\n    See Also\n    --------\n    mne.Evoked.plot\n\n    Notes\n    -----\n    If baseline signals match the assumption of Gaussian white noise,\n    values should be centered at 0, and be within 2 standard deviations\n    (\u00b11.96) for 95%% of the time points. For the global field power (GFP),\n    we expect it to fluctuate around a value of 1.\n\n    If one single covariance object is passed, the GFP panel (bottom)\n    will depict different sensor types. If multiple covariance objects are\n    passed as a list, the left column will display the whitened evoked\n    responses for each channel based on the whitener from the noise covariance\n    that has the highest log-likelihood. The left column will depict the\n    whitened GFPs based on each estimator separately for each sensor type.\n    Instead of numbers of channels the GFP display shows the estimated rank.\n    Note. The rank estimation will be printed by the logger\n    (if ``verbose=True``) for each noise covariance estimator that is passed.\n\n    References\n    ----------\n    .. [1] Engemann D. and Gramfort A. (2015) Automated model selection in\n           covariance estimation and spatial whitening of MEG and EEG\n           signals, vol. 108, 328-342, NeuroImage.\n    \"\"\"\n    import matplotlib.pyplot as plt\n\n    from ..cov import Covariance, _ensure_cov, whiten_evoked\n\n    time_unit, times = _check_time_unit(time_unit, evoked.times)\n\n    _validate_type(noise_cov, (list, tuple, Covariance, \"path-like\"))\n    if not isinstance(noise_cov, list | tuple):\n        noise_cov = [noise_cov]\n    for ci, c in enumerate(noise_cov):\n        noise_cov[ci] = _ensure_cov(noise_cov[ci], f\"noise_cov[{ci}]\", verbose=False)\n\n    evoked = evoked.copy()  # handle ref meg\n    passive_idx = [\n        idx for idx, proj in enumerate(evoked.info[\"projs\"]) if not proj[\"active\"]\n    ]\n    # either applied already or not-- else issue\n    for idx in passive_idx[::-1]:  # reverse order so idx does not change\n        evoked.del_proj(idx)\n\n    evoked.pick_types(ref_meg=False, exclude=\"bads\", **_PICK_TYPES_DATA_DICT)\n    n_ch_used, rank_list, picks_list, has_sss = _triage_rank_sss(\n        evoked.info, noise_cov, rank, scalings=None\n    )\n    if has_sss:\n        logger.info(\n            \"SSS has been applied to data. Showing mag and grad whitening jointly.\"\n        )\n\n    # get one whitened evoked per cov\n    evokeds_white = [\n        whiten_evoked(evoked, cov, picks=None, rank=r)\n        for cov, r in zip(noise_cov, rank_list)\n    ]\n\n    def whitened_gfp(x, rank=None):\n        \"\"\"Whitened Global Field Power.\n\n        The MNE inverse solver assumes zero mean whitened data as input.\n        Therefore, a chi^2 statistic will be best to detect model violations.\n        \"\"\"\n        return np.sum(x**2, axis=0) / (len(x) if rank is None else rank)\n\n    # prepare plot\n    if len(noise_cov) > 1:\n        n_columns = 2\n        n_extra_row = 0\n    else:\n        n_columns = 1\n        n_extra_row = 1\n\n    n_rows = n_ch_used + n_extra_row\n    want_shape = (n_rows, n_columns) if len(noise_cov) > 1 else (n_rows,)\n    _validate_type(axes, (list, tuple, np.ndarray, None), \"axes\")\n    if axes is None:\n        _, axes = plt.subplots(\n            n_rows,\n            n_columns,\n            sharex=True,\n            sharey=False,\n            figsize=(8.8, 2.2 * n_rows),\n            layout=\"constrained\",\n        )\n    else:\n        axes = np.array(axes)\n    for ai, ax in enumerate(axes.flat):\n        _validate_type(ax, plt.Axes, f\"axes.flat[{ai}]\")\n    if axes.shape != want_shape:\n        raise ValueError(f\"axes must have shape {want_shape}, got {axes.shape}.\")\n    fig = axes.flat[0].figure\n    if n_columns > 1:\n        suptitle = noise_cov[0].get(\"method\", \"empirical\")\n        suptitle = (\n            f'Whitened evoked (left, best estimator = \"{suptitle}\")\\n'\n            \"and global field power (right, comparison of estimators)\"\n        )\n        fig.suptitle(suptitle)\n\n    if any(((n_columns == 1 and n_ch_used >= 1), (n_columns == 2 and n_ch_used == 1))):\n        axes_evoked = axes[:n_ch_used]\n        ax_gfp = axes[-1:]\n    elif n_columns == 2 and n_ch_used > 1:\n        axes_evoked = axes[:n_ch_used, 0]\n        ax_gfp = axes[:, 1]\n    else:\n        raise RuntimeError(\"Wrong axes inputs\")\n\n    titles_ = _handle_default(\"titles\")\n    colors = [plt.cm.Set1(i) for i in np.linspace(0, 0.5, len(noise_cov))]\n    ch_colors = _handle_default(\"color\", None)\n    iter_gfp = zip(evokeds_white, noise_cov, rank_list, colors)\n\n    # The first is by law the best noise cov, on the left we plot that one.\n    # When we have data in SSS / MEG-combined mode, we have to do some info\n    # hacks to get it to plot all channels in the same axes, namely setting\n    # the channel unit (most important) and coil type (for consistency) of\n    # all MEG channels to be the same.\n    meg_idx = sss_title = None\n    if has_sss:\n        titles_[\"meg\"] = \"MEG (combined)\"\n        meg_idx = [\n            pi for pi, (ch_type, _) in enumerate(picks_list) if ch_type == \"meg\"\n        ][0]\n        # Hack the MEG channels to all be the same type so they get plotted together\n        picks = picks_list[meg_idx][1]\n        for key in (\"coil_type\", \"unit\"):  # update both\n            use = evokeds_white[0].info[\"chs\"][picks[0]][key]\n            for pick in picks:\n                evokeds_white[0].info[\"chs\"][pick][key] = use\n        sss_title = f\"{titles_['meg']} ({len(picks)} channel{_pl(picks)})\"\n    evokeds_white[0].plot(\n        unit=False,\n        axes=axes_evoked,\n        hline=[-1.96, 1.96],\n        show=False,\n        time_unit=time_unit,\n        spatial_colors=spatial_colors,\n    )\n    if has_sss:\n        axes_evoked[meg_idx].set(title=sss_title)\n\n    # Now plot the GFP for all covs if indicated.\n    for evoked_white, noise_cov, rank_, color in iter_gfp:\n        i = 0\n\n        for ch, sub_picks in picks_list:\n            this_rank = rank_[ch]\n            title = \"{} ({}{})\".format(\n                titles_[ch] if n_columns > 1 else ch,\n                \"rank \" if n_columns > 1 else \"\",\n                this_rank,\n            )\n            label = noise_cov.get(\"method\", \"empirical\")\n\n            ax = ax_gfp[i]\n            ax.set_title(\n                title if n_columns > 1 else f'Whitened GFP, method = \"{label}\"'\n            )\n\n            data = evoked_white.data[sub_picks]\n            gfp = whitened_gfp(data, rank=this_rank)\n            # Wrap SSS-processed data (MEG) to the mag color\n            color_ch = \"mag\" if ch == \"meg\" else ch\n            ax.plot(\n                times,\n                gfp,\n                label=label if n_columns > 1 else title,\n                color=color if n_columns > 1 else ch_colors[color_ch],\n                lw=0.5,\n            )\n            ax.set(\n                xlabel=f\"Time ({time_unit})\",\n                ylabel=r\"GFP ($\\chi^2$)\",\n                xlim=[times[0], times[-1]],\n                ylim=(0, 10),\n            )\n            ax.axhline(1, color=\"red\", linestyle=\"--\", lw=2.0)\n            if n_columns > 1:\n                i += 1\n\n    ax = ax_gfp[0]\n    if n_columns == 1:\n        ax.legend(  # mpl < 1.2.1 compatibility: use prop instead of fontsize\n            loc=\"upper right\", bbox_to_anchor=(0.98, 0.9), prop=dict(size=12)\n        )\n    else:\n        ax.legend(loc=\"upper right\", prop=dict(size=10))\n    fig.canvas.draw()\n\n    plt_show(show)\n    return fig", "metadata": {}}
{"_id": "mne_mne_viz/evoked.py_plot_snr_estimate_code", "title": "plot_snr_estimate", "text": "def plot_snr_estimate(evoked, inv, show=True, axes=None, verbose=None):\n    \"\"\"Plot a data SNR estimate.\n\n    Parameters\n    ----------\n    evoked : instance of Evoked\n        The evoked instance. This should probably be baseline-corrected.\n    inv : instance of InverseOperator\n        The minimum-norm inverse operator.\n    show : bool\n        Show figure if True.\n    axes : instance of Axes | None\n        The axes to plot into.\n\n        .. versionadded:: 0.21.0\n    %(verbose)s\n\n    Returns\n    -------\n    fig : instance of matplotlib.figure.Figure\n        The figure object containing the plot.\n\n    Notes\n    -----\n    The bluish green line is the SNR determined by the GFP of the whitened\n    evoked data. The orange line is the SNR estimated based on the mismatch\n    between the data and the data re-estimated from the regularized inverse.\n\n    .. versionadded:: 0.9.0\n    \"\"\"\n    import matplotlib.pyplot as plt\n\n    from ..minimum_norm import estimate_snr\n\n    snr, snr_est = estimate_snr(evoked, inv)\n    _validate_type(axes, (None, plt.Axes))\n    if axes is None:\n        _, ax = plt.subplots(1, 1, layout=\"constrained\")\n    else:\n        ax = axes\n        del axes\n    fig = ax.figure\n    lims = np.concatenate([evoked.times[[0, -1]], [-1, snr_est.max()]])\n    ax.axvline(0, color=\"k\", ls=\":\", lw=1)\n    ax.axhline(0, color=\"k\", ls=\":\", lw=1)\n    # Colors are \"bluish green\" and \"vermilion\" taken from:\n    #  http://bconnelly.net/2013/10/creating-colorblind-friendly-figures/\n    hs = list()\n    labels = (\"Inverse\", \"Whitened GFP\")\n    hs.append(ax.plot(evoked.times, snr_est, color=[0.0, 0.6, 0.5])[0])\n    hs.append(ax.plot(evoked.times, snr - 1, color=[0.8, 0.4, 0.0])[0])\n    ax.set(xlim=lims[:2], ylim=lims[2:], ylabel=\"SNR\", xlabel=\"Time (s)\")\n    if evoked.comment is not None:\n        ax.set_title(evoked.comment)\n    ax.legend(hs, labels, title=\"Estimation method\")\n    plt_show(show)\n    return fig", "metadata": {}}
{"_id": "mne_mne_viz/evoked.py_plot_evoked_joint_code", "title": "plot_evoked_joint", "text": "def plot_evoked_joint(\n    evoked,\n    times=\"peaks\",\n    title=\"\",\n    picks=None,\n    exclude=None,\n    show=True,\n    ts_args=None,\n    topomap_args=None,\n):\n    \"\"\"Plot evoked data as butterfly plot and add topomaps for time points.\n\n    .. note:: Axes to plot in can be passed by the user through ``ts_args`` or\n              ``topomap_args``. In that case both ``ts_args`` and\n              ``topomap_args`` axes have to be used. Be aware that when the\n              axes are provided, their position may be slightly modified.\n\n    Parameters\n    ----------\n    evoked : instance of Evoked\n        The evoked instance.\n    times : float | array of float | \"auto\" | \"peaks\"\n        The time point(s) to plot. If ``\"auto\"``, 5 evenly spaced topographies\n        between the first and last time instant will be shown. If ``\"peaks\"``,\n        finds time points automatically by checking for 3 local maxima in\n        Global Field Power. Defaults to ``\"peaks\"``.\n    title : str | None\n        The title. If ``None``, suppress printing channel type title. If an\n        empty string, a default title is created. Defaults to ''. If custom\n        axes are passed make sure to set ``title=None``, otherwise some of your\n        axes may be removed during placement of the title axis.\n    %(picks_all)s\n    exclude : None | list of str | 'bads'\n        Channels names to exclude from being shown. If ``'bads'``, the\n        bad channels are excluded. Defaults to ``None``.\n    show : bool\n        Show figure if ``True``. Defaults to ``True``.\n    ts_args : None | dict\n        A dict of ``kwargs`` that are forwarded to :meth:`mne.Evoked.plot` to\n        style the butterfly plot. If they are not in this dict, the following\n        defaults are passed: ``spatial_colors=True``, ``zorder='std'``.\n        ``show`` and ``exclude`` are illegal.\n        If ``None``, no customizable arguments will be passed.\n        Defaults to ``None``.\n    topomap_args : None | dict\n        A dict of ``kwargs`` that are forwarded to\n        :meth:`mne.Evoked.plot_topomap` to style the topomaps.\n        If it is not in this dict, ``outlines='head'`` will be passed.\n        ``show``, ``times``, ``colorbar`` are illegal.\n        If ``None``, no customizable arguments will be passed.\n        Defaults to ``None``.\n\n    Returns\n    -------\n    fig : instance of matplotlib.figure.Figure | list\n        The figure object containing the plot. If ``evoked`` has multiple\n        channel types, a list of figures, one for each channel type, is\n        returned.\n\n    Notes\n    -----\n    .. versionadded:: 0.12.0\n    \"\"\"\n    from matplotlib.patches import ConnectionPatch\n\n    if ts_args is not None and not isinstance(ts_args, dict):\n        raise TypeError(f\"ts_args must be dict or None, got type {type(ts_args)}\")\n    ts_args = dict() if ts_args is None else ts_args.copy()\n    ts_args[\"time_unit\"], _ = _check_time_unit(\n        ts_args.get(\"time_unit\", \"s\"), evoked.times\n    )\n    topomap_args = dict() if topomap_args is None else topomap_args.copy()\n\n    got_axes = False\n    illegal_args = {\"show\", \"times\", \"exclude\"}\n    for args in (ts_args, topomap_args):\n        if any(x in args for x in illegal_args):\n            raise ValueError(\n                \"Don't pass any of {} as *_args.\".format(\", \".join(list(illegal_args)))\n            )\n    if (\"axes\" in ts_args) or (\"axes\" in topomap_args):\n        if not ((\"axes\" in ts_args) and (\"axes\" in topomap_args)):\n            raise ValueError(\n                \"If one of `ts_args` and `topomap_args` contains \"\n                \"'axes', the other must, too.\"\n            )\n        _validate_if_list_of_axes([ts_args[\"axes\"]], 1)\n\n        if times in (None, \"peaks\"):\n            n_topomaps = 3 + 1\n        else:\n            assert not isinstance(times, str)\n            n_topomaps = len(times) + 1\n\n        _validate_if_list_of_axes(list(topomap_args[\"axes\"]), n_topomaps)\n        got_axes = True\n\n    # channel selection\n    # simply create a new evoked object with the desired channel selection\n    # Need to deal with proj before picking to avoid bad projections\n    proj = topomap_args.get(\"proj\", True)\n    proj_ts = ts_args.get(\"proj\", True)\n    if proj_ts != proj:\n        raise ValueError(\n            f'topomap_args[\"proj\"] (default True, got {proj}) must match '\n            f'ts_args[\"proj\"] (default True, got {proj_ts})'\n        )\n    _check_option('topomap_args[\"proj\"]', proj, (True, False, \"reconstruct\"))\n    evoked = evoked.copy()\n    if proj:\n        evoked.apply_proj()\n        if proj == \"reconstruct\":\n            evoked._reconstruct_proj()\n    topomap_args[\"proj\"] = ts_args[\"proj\"] = False  # don't reapply\n    evoked.pick(picks, exclude=exclude)\n    info = evoked.info\n    ch_types = info.get_channel_types(unique=True, only_data_chs=True)\n\n    # if multiple sensor types: one plot per channel type, recursive call\n    if len(ch_types) > 1:\n        if got_axes:\n            raise NotImplementedError(\n                \"Currently, passing axes manually (via `ts_args` or \"\n                \"`topomap_args`) is not supported for multiple channel types.\"\n            )\n        figs = list()\n        for this_type in ch_types:  # pick only the corresponding channel type\n            ev_ = evoked.copy().pick(\n                [\n                    info[\"ch_names\"][idx]\n                    for idx in range(info[\"nchan\"])\n                    if channel_type(info, idx) == this_type\n                ]\n            )\n            if len(ev_.info.get_channel_types(unique=True)) > 1:\n                raise RuntimeError(\n                    \"Possibly infinite loop due to channel \"\n                    \"selection problem. This should never \"\n                    \"happen! Please check your channel types.\"\n                )\n            figs.append(\n                plot_evoked_joint(\n                    ev_,\n                    times=times,\n                    title=title,\n                    show=show,\n                    ts_args=ts_args,\n                    exclude=list(),\n                    topomap_args=topomap_args,\n                )\n            )\n        return figs\n\n    # set up time points to show topomaps for\n    times_sec = _process_times(evoked, times, few=True)\n    del times\n    _, times_ts = _check_time_unit(ts_args[\"time_unit\"], times_sec)\n\n    # prepare axes for topomap\n    if not got_axes:\n        fig, ts_ax, map_ax = _prepare_joint_axes(len(times_sec), figsize=(8.0, 4.2))\n        cbar_ax = None\n    else:\n        ts_ax = ts_args[\"axes\"]\n        del ts_args[\"axes\"]\n        map_ax = topomap_args[\"axes\"][:-1]\n        cbar_ax = topomap_args[\"axes\"][-1]\n        del topomap_args[\"axes\"]\n        fig = cbar_ax.figure\n\n    # butterfly/time series plot\n    # most of this code is about passing defaults on demand\n    ts_args_def = dict(\n        picks=None,\n        unit=True,\n        ylim=None,\n        xlim=\"tight\",\n        proj=False,\n        hline=None,\n        units=None,\n        scalings=None,\n        titles=None,\n        gfp=False,\n        window_title=None,\n        spatial_colors=True,\n        zorder=\"std\",\n        sphere=None,\n        draw=False,\n    )\n    ts_args_def.update(ts_args)\n    _plot_evoked(\n        evoked, axes=ts_ax, show=False, plot_type=\"butterfly\", exclude=[], **ts_args_def\n    )\n\n    # handle title\n    # we use a new axis for the title to handle scaling of plots\n    old_title = ts_ax.get_title()\n    ts_ax.set_title(\"\")\n\n    if title is not None:\n        if title == \"\":\n            title = old_title\n        fig.suptitle(title)\n\n    # topomap\n    contours = topomap_args.get(\"contours\", 6)\n    ch_type = ch_types.pop()  # set should only contain one element\n    # Since the data has all the ch_types, we get the limits from the plot.\n    vmin, vmax = (None, None)\n    norm = ch_type == \"grad\"\n    vmin = 0 if norm else vmin\n    time_idx = [\n        np.where(\n            _time_mask(evoked.times, tmin=t, tmax=None, sfreq=evoked.info[\"sfreq\"])\n        )[0][0]\n        for t in times_sec\n    ]\n    scalings = topomap_args[\"scalings\"] if \"scalings\" in topomap_args else None\n    scaling = _handle_default(\"scalings\", scalings)[ch_type]\n    vmin, vmax = _setup_vmin_vmax(evoked.data[:, time_idx] * scaling, vmin, vmax, norm)\n    if not isinstance(contours, list | np.ndarray):\n        locator, contours = _set_contour_locator(vmin, vmax, contours)\n    else:\n        locator = None\n\n    topomap_args_pass = dict(extrapolate=\"local\") if ch_type == \"seeg\" else dict()\n    topomap_args_pass.update(topomap_args)\n    topomap_args_pass[\"outlines\"] = topomap_args.get(\"outlines\", \"head\")\n    topomap_args_pass[\"contours\"] = contours\n    evoked.plot_topomap(\n        times=times_sec, axes=map_ax, show=False, colorbar=False, **topomap_args_pass\n    )\n\n    if topomap_args.get(\"colorbar\", True):\n        from matplotlib import ticker\n\n        cbar = fig.colorbar(map_ax[0].images[0], ax=map_ax, cax=cbar_ax, shrink=0.8)\n        cbar.ax.grid(False)\n        if isinstance(contours, list | np.ndarray):\n            cbar.set_ticks(contours)\n        else:\n            if locator is None:\n                locator = ticker.MaxNLocator(nbins=5)\n            cbar.locator = locator\n        cbar.update_ticks()\n\n    # connection lines\n    # draw the connection lines between time series and topoplots\n    for timepoint, map_ax_ in zip(times_ts, map_ax):\n        con = ConnectionPatch(\n            xyA=[timepoint, ts_ax.get_ylim()[1]],\n            xyB=[0.5, 0],\n            coordsA=\"data\",\n            coordsB=\"axes fraction\",\n            axesA=ts_ax,\n            axesB=map_ax_,\n            color=\"grey\",\n            linestyle=\"-\",\n            linewidth=1.5,\n            alpha=0.66,\n            zorder=1,\n            clip_on=False,\n        )\n        fig.add_artist(con)\n\n    # mark times in time series plot\n    for timepoint in times_ts:\n        ts_ax.axvline(\n            timepoint, color=\"grey\", linestyle=\"-\", linewidth=1.5, alpha=0.66, zorder=0\n        )\n\n    # show and return it\n    plt_show(show)\n    return fig", "metadata": {}}
{"_id": "mne_mne_viz/evoked.py_plot_compare_evokeds_code", "title": "plot_compare_evokeds", "text": "def plot_compare_evokeds(\n    evokeds,\n    picks=None,\n    colors=None,\n    linestyles=None,\n    styles=None,\n    cmap=None,\n    vlines=\"auto\",\n    ci=True,\n    truncate_yaxis=\"auto\",\n    truncate_xaxis=True,\n    ylim=None,\n    invert_y=False,\n    show_sensors=None,\n    legend=True,\n    split_legend=None,\n    axes=None,\n    title=None,\n    show=True,\n    combine=None,\n    sphere=None,\n    time_unit=\"s\",\n):\n    \"\"\"Plot evoked time courses for one or more conditions and/or channels.\n\n    Parameters\n    ----------\n    evokeds : instance of mne.Evoked | list | dict\n        If a single Evoked instance, it is plotted as a time series.\n        If a list of Evokeds, the contents are plotted with their\n        ``.comment`` attributes used as condition labels. If no comment is set,\n        the index of the respective Evoked the list will be used instead,\n        starting with ``1`` for the first Evoked.\n        If a dict whose values are Evoked objects, the contents are plotted as\n        single time series each and the keys are used as labels.\n        If a [dict/list] of lists, the unweighted mean is plotted as a time\n        series and the parametric confidence interval is plotted as a shaded\n        area. All instances must have the same shape - channel numbers, time\n        points etc.\n        If dict, keys must be of type :class:`str`.\n    %(picks_all_data)s\n\n        * If picks is None or a (collection of) data channel types, the\n          global field power will be plotted for all data channels.\n          Otherwise, picks will be averaged.\n        * If multiple channel types are selected, one\n          figure will be returned for each channel type.\n        * If the selected channels are gradiometers, the signal from\n          corresponding (gradiometer) pairs will be combined.\n\n    colors : list | dict | None\n        Colors to use when plotting the ERP/F lines and confidence bands. If\n        ``cmap`` is not ``None``, ``colors`` must be a :class:`list` or\n        :class:`dict` of :class:`ints <int>` or :class:`floats <float>`\n        indicating steps or percentiles (respectively) along the colormap. If\n        ``cmap`` is ``None``, list elements or dict values of ``colors`` must\n        be :class:`ints <int>` or valid :ref:`matplotlib colors\n        <matplotlib:colors_def>`; lists are cycled through\n        sequentially,\n        while dicts must have keys matching the keys or conditions of an\n        ``evokeds`` dict (see Notes for details). If ``None``, the current\n        :doc:`matplotlib color cycle\n        <matplotlib:gallery/color/color_cycle_default>`\n        is used. Defaults to ``None``.\n    linestyles : list | dict | None\n        Styles to use when plotting the ERP/F lines. If a :class:`list` or\n        :class:`dict`, elements must be valid :doc:`matplotlib linestyles\n        <matplotlib:gallery/lines_bars_and_markers/linestyles>`. Lists are\n        cycled through sequentially; dictionaries must have keys matching the\n        keys or conditions of an ``evokeds`` dict (see Notes for details). If\n        ``None``, all lines will be solid. Defaults to ``None``.\n    styles : dict | None\n        Dictionary of styles to use when plotting ERP/F lines. Keys must match\n        keys or conditions of ``evokeds``, and values must be a :class:`dict`\n        of legal inputs to :func:`matplotlib.pyplot.plot`. Those values will be\n        passed as parameters to the line plot call of the corresponding\n        condition, overriding defaults (e.g.,\n        ``styles={\"Aud/L\": {\"linewidth\": 3}}`` will set the linewidth for\n        \"Aud/L\" to 3). As with ``colors`` and ``linestyles``, keys matching\n        conditions in ``/``-separated ``evokeds`` keys are supported (see Notes\n        for details).\n    cmap : None | str | tuple | instance of matplotlib.colors.Colormap\n        Colormap from which to draw color values when plotting the ERP/F lines\n        and confidence bands. If not ``None``, ints or floats in the ``colors``\n        parameter are mapped to steps or percentiles (respectively) along the\n        colormap. If ``cmap`` is a :class:`str`, it will be passed to\n        ``matplotlib.colormaps``; if ``cmap`` is a tuple, its first\n        element will be used as a string to label the colorbar, and its\n        second element will be passed to ``matplotlib.colormaps`` (unless\n        it is already an instance of :class:`~matplotlib.colors.Colormap`).\n\n        .. versionchanged:: 0.19\n            Support for passing :class:`~matplotlib.colors.Colormap` instances.\n\n    vlines : ``\"auto\"`` | list of float\n        A list in seconds at which to plot dashed vertical lines.\n        If ``\"auto\"`` and the supplied data includes 0, it is set to ``[0.]``\n        and a vertical bar is plotted at time 0. If an empty list is passed,\n        no vertical lines are plotted.\n    ci : float | bool | callable | None\n        Confidence band around each ERP/F time series. If ``False`` or ``None``\n        no confidence band is drawn. If :class:`float`, ``ci`` must be between\n        0 and 1, and will set the threshold for a bootstrap\n        (single plot)/parametric (when ``axes=='topo'``)  estimation of the\n        confidence band; ``True`` is equivalent to setting a threshold of 0.95\n        (i.e., the 95%% confidence band is drawn). If a callable, it must take\n        a single array (n_observations \u00d7 n_times) as input and return upper and\n        lower confidence margins (2 \u00d7 n_times). Defaults to ``True``.\n    truncate_yaxis : bool | ``'auto'``\n        Whether to shorten the y-axis spine. If ``'auto'``, the spine is truncated\n        at the minimum and maximum ticks. If ``True``, it is truncated at the\n        multiple of 0.25 nearest to half the maximum absolute value of the\n        data. If ``truncate_xaxis=False``, only the far bound of the y-axis\n        will be truncated. Defaults to ``'auto'``.\n    truncate_xaxis : bool\n        Whether to shorten the x-axis spine. If ``True``, the spine is\n        truncated at the minimum and maximum ticks. If\n        ``truncate_yaxis=False``, only the far bound of the x-axis will be\n        truncated. Defaults to ``True``.\n    %(evoked_ylim_plot)s\n    invert_y : bool\n        Whether to plot negative values upward (as is sometimes done\n        for ERPs out of tradition). Defaults to ``False``.\n    show_sensors : bool | int | str | None\n        Whether to display an inset showing sensor locations on a head outline.\n        If :class:`int` or :class:`str`, indicates position of the inset (see\n        :func:`mpl_toolkits.axes_grid1.inset_locator.inset_axes`). If ``None``,\n        treated as ``True`` if there is only one channel in ``picks``. If\n        ``True``, location is upper or lower right corner, depending on data\n        values. Defaults to ``None``.\n    legend : bool | int | str\n        Whether to show a legend for the colors/linestyles of the conditions\n        plotted. If :class:`int` or :class:`str`, indicates position of the\n        legend (see :func:`mpl_toolkits.axes_grid1.inset_locator.inset_axes`).\n        If ``True``, equivalent to ``'upper left'``. Defaults to ``True``.\n    split_legend : bool | None\n        Whether to separate color and linestyle in the legend. If ``None``,\n        a separate linestyle legend will still be shown if ``cmap`` is\n        specified. Defaults to ``None``.\n    axes : None | Axes instance | list of Axes | ``'topo'``\n        :class:`~matplotlib.axes.Axes` object to plot into. If plotting\n        multiple channel types (or multiple channels when ``combine=None``),\n        ``axes`` should be a list of appropriate length containing\n        :class:`~matplotlib.axes.Axes` objects. If ``'topo'``, a new\n        :class:`~matplotlib.figure.Figure` is created with one axis for each\n        channel, in a topographical layout. If ``None``, a new\n        :class:`~matplotlib.figure.Figure` is created for each channel type.\n        Defaults to ``None``.\n    title : str | None\n        Title printed above the plot. If ``None``, a title will be\n        automatically generated based on channel name(s) or type(s) and the\n        value of the ``combine`` parameter. Defaults to ``None``.\n    show : bool\n        Whether to show the figure. Defaults to ``True``.\n    %(combine_plot_compare_evokeds)s\n    %(sphere_topomap_auto)s\n    %(time_unit)s\n\n        .. versionadded:: 1.1\n\n    Returns\n    -------\n    fig : list of Figure instances\n        A list of the figure(s) generated.\n\n    Notes\n    -----\n    If the parameters ``styles``, ``colors``, or ``linestyles`` are passed as\n    :class:`dicts <python:dict>`, then ``evokeds`` must also be a\n    :class:`python:dict`, and\n    the keys of the plot-style parameters must either match the keys of\n    ``evokeds``, or match a ``/``-separated partial key (\"condition\") of\n    ``evokeds``. For example, if evokeds has keys \"Aud/L\", \"Aud/R\", \"Vis/L\",\n    and \"Vis/R\", then ``linestyles=dict(L='--', R='-')`` will plot both Aud/L\n    and Vis/L conditions with dashed lines and both Aud/R and Vis/R conditions\n    with solid lines. Similarly, ``colors=dict(Aud='r', Vis='b')`` will plot\n    Aud/L and Aud/R conditions red and Vis/L and Vis/R conditions blue.\n\n    Color specification depends on whether a colormap has been provided in the\n    ``cmap`` parameter. The following table summarizes how the ``colors``\n    parameter is interpreted:\n\n    .. cssclass:: table-bordered\n    .. rst-class:: midvalign\n\n    +-------------+----------------+------------------------------------------+\n    | ``cmap``    | ``colors``     | result                                   |\n    +=============+================+==========================================+\n    |             | None           | matplotlib default color cycle; unique   |\n    |             |                | color for each condition                 |\n    |             +----------------+------------------------------------------+\n    |             |                | matplotlib default color cycle; lowest   |\n    |             | list or dict   | integer mapped to first cycle color;     |\n    |             | of integers    | conditions with same integer get same    |\n    | None        |                | color; unspecified conditions are \"gray\" |\n    |             +----------------+------------------------------------------+\n    |             | list or dict   | ``ValueError``                           |\n    |             | of floats      |                                          |\n    |             +----------------+------------------------------------------+\n    |             | list or dict   | the specified hex colors; unspecified    |\n    |             | of hexadecimal | conditions are \"gray\"                    |\n    |             | color strings  |                                          |\n    +-------------+----------------+------------------------------------------+\n    |             | None           | equally spaced colors on the colormap;   |\n    |             |                | unique color for each condition          |\n    |             +----------------+------------------------------------------+\n    |             |                | equally spaced colors on the colormap;   |\n    |             | list or dict   | lowest integer mapped to first cycle     |\n    | string or   | of integers    | color; conditions with same integer      |\n    | instance of |                | get same color                           |\n    | matplotlib  +----------------+------------------------------------------+\n    | Colormap    | list or dict   | floats mapped to corresponding colormap  |\n    |             | of floats      | values                                   |\n    |             +----------------+------------------------------------------+\n    |             | list or dict   |                                          |\n    |             | of hexadecimal | ``TypeError``                            |\n    |             | color strings  |                                          |\n    +-------------+----------------+------------------------------------------+\n    \"\"\"\n    import matplotlib.pyplot as plt\n\n    from ..evoked import Evoked, _check_evokeds_ch_names_times\n\n    # build up evokeds into a dict, if it's not already\n    if isinstance(evokeds, Evoked):\n        evokeds = [evokeds]\n\n    if isinstance(evokeds, list | tuple):\n        evokeds_copy = evokeds.copy()\n        evokeds = dict()\n\n        comments = [\n            _ascii_minus_to_unicode(getattr(_evk, \"comment\", None))\n            for _evk in evokeds_copy\n        ]\n\n        for idx, (comment, _evoked) in enumerate(zip(comments, evokeds_copy)):\n            key = str(idx + 1)\n            if comment:  # only update key if comment is non-empty\n                if comments.count(comment) == 1:  # comment is unique\n                    key = comment\n                else:  # comment is non-unique: prepend index\n                    key = f\"{key}: {comment}\"\n            evokeds[key] = _evoked\n        del evokeds_copy\n\n    if not isinstance(evokeds, dict):\n        raise TypeError(\n            '\"evokeds\" must be a dict, list, or instance of '\n            f\"mne.Evoked; got {type(evokeds).__name__}\"\n        )\n    evokeds = deepcopy(evokeds)  # avoid modifying dict outside function scope\n    for cond, evoked in evokeds.items():\n        _validate_type(cond, \"str\", \"Conditions\")\n        if isinstance(evoked, Evoked):\n            evokeds[cond] = [evoked]  # wrap singleton evokeds in a list\n        for evk in evokeds[cond]:\n            _validate_type(evk, Evoked, \"All evokeds entries \", \"Evoked\")\n    # ensure same channels and times across all evokeds\n    all_evoked = sum(evokeds.values(), [])\n    _check_evokeds_ch_names_times(all_evoked)\n    del all_evoked\n\n    # get some representative info\n    conditions = list(evokeds)\n    one_evoked = evokeds[conditions[0]][0]\n    times = one_evoked.times\n    info = one_evoked.info\n    sphere = _check_sphere(sphere, info)\n    time_unit, times = _check_time_unit(time_unit, one_evoked.times)\n    tmin, tmax = times[0], times[-1]\n    # set some defaults\n    if ylim is None:\n        ylim = dict()\n    if vlines == \"auto\":\n        vlines = [0.0] if (tmin < 0 < tmax) else []\n    _validate_type(vlines, (list, tuple), \"vlines\", \"list or tuple\")\n\n    # is picks a channel type (or None)?\n    orig_picks = deepcopy(picks)\n    picks, picked_types = _picks_to_idx(info, picks, return_kind=True)\n    # some things that depend on picks:\n    ch_names = np.array(one_evoked.ch_names)[picks].tolist()\n    all_types = _DATA_CH_TYPES_SPLIT + (\n        \"misc\",  # from ICA\n        \"emg\",\n        \"ref_meg\",\n        \"eyegaze\",\n        \"pupil\",\n    )\n    ch_types = [\n        t for t in info.get_channel_types(picks=picks, unique=True) if t in all_types\n    ]\n    picks_by_type = channel_indices_by_type(info, picks)\n    # discard picks from non-data channels (e.g., ref_meg)\n    good_picks = sum([picks_by_type[ch_type] for ch_type in ch_types], [])\n    picks = np.intersect1d(picks, good_picks)\n    if show_sensors is None:\n        show_sensors = len(picks) == 1\n\n    _validate_type(combine, types=(None, \"callable\", str), item_name=\"combine\")\n    # cannot combine a single channel\n    if (len(picks) < 2) and combine is not None:\n        warn(\n            f'Only {len(picks)} channel in \"picks\"; cannot combine by method '\n            f'\"{combine}\".'\n        )\n    # `combine` defaults to GFP unless picked a single channel or axes='topo'\n    do_topo = isinstance(axes, str) and axes == \"topo\"\n    if combine is None and len(picks) > 1 and not do_topo:\n        combine = \"gfp\"\n    # convert `combine` into callable (if None or str)\n    combine_funcs = {\n        ch_type: _make_combine_callable(combine, ch_type=ch_type)\n        for ch_type in ch_types\n    }\n\n    # title\n    title = _title_helper_pce(\n        title,\n        picked_types,\n        picks=orig_picks,\n        ch_names=ch_names,\n        ch_type=ch_types[0] if len(ch_types) == 1 else None,\n        combine=combine,\n    )\n    topo_disp_title = False\n    # setup axes\n    if do_topo:\n        show_sensors = False\n        if len(picks) > 70:\n            logger.info(\n                \"You are plotting to a topographical layout with >70 \"\n                \"sensors. This can be extremely slow. Consider using \"\n                \"mne.viz.plot_topo, which is optimized for speed.\"\n            )\n        topo_title = title\n        topo_disp_title = True\n        axes = [\"topo\"] * len(ch_types)\n    else:\n        if axes is None:\n            axes = (\n                plt.subplots(figsize=(8, 6), layout=\"constrained\")[1] for _ in ch_types\n            )\n        elif isinstance(axes, plt.Axes):\n            axes = [axes]\n            _validate_if_list_of_axes(axes, obligatory_len=len(ch_types))\n\n    if len(ch_types) > 1:\n        logger.info(\"Multiple channel types selected, returning one figure per type.\")\n        figs = list()\n        for ch_type, ax in zip(ch_types, axes):\n            _picks = picks_by_type[ch_type]\n            _ch_names = np.array(one_evoked.ch_names)[_picks].tolist()\n            _picks = ch_type if picked_types else _picks\n            # don't pass `combine` here; title will run through this helper\n            # function a second time & it will get added then\n            _title = _title_helper_pce(\n                title,\n                picked_types,\n                picks=_picks,\n                ch_names=_ch_names,\n                ch_type=ch_type,\n                combine=None,\n            )\n            figs.extend(\n                plot_compare_evokeds(\n                    evokeds,\n                    picks=_picks,\n                    colors=colors,\n                    cmap=cmap,\n                    linestyles=linestyles,\n                    styles=styles,\n                    vlines=vlines,\n                    ci=ci,\n                    truncate_yaxis=truncate_yaxis,\n                    ylim=ylim,\n                    invert_y=invert_y,\n                    legend=legend,\n                    show_sensors=show_sensors,\n                    axes=ax,\n                    title=_title,\n                    split_legend=split_legend,\n                    show=show,\n                    sphere=sphere,\n                )\n            )\n        return figs\n\n    # colors and colormap. This yields a `styles` dict with one entry per\n    # condition, specifying at least color and linestyle. THIS MUST BE DONE\n    # AFTER THE \"MULTIPLE CHANNEL TYPES\" LOOP\n    (\n        _styles,\n        _linestyles,\n        _colors,\n        _cmap,\n        colorbar_title,\n        colorbar_ticks,\n    ) = _handle_styles_pce(styles, linestyles, colors, cmap, conditions)\n    # From now on there is only 1 channel type\n    if not len(ch_types):\n        got_idx = _picks_to_idx(info, picks=orig_picks)\n        got = np.unique(np.array(info.get_channel_types())[got_idx]).tolist()\n        raise RuntimeError(\n            f\"No valid channel type(s) provided. Got {got}. Valid channel types are:\"\n            f\"\\n{all_types}.\"\n        )\n    ch_type = ch_types[0]\n    # some things that depend on ch_type:\n    units = _handle_default(\"units\")[ch_type]\n    scalings = _handle_default(\"scalings\")[ch_type]\n    combine_func = combine_funcs[ch_type]\n    # prep for topo\n    pos_picks = picks  # need this version of picks for sensor location inset\n    info = pick_info(info, sel=picks, copy=True)\n    all_ch_names = info[\"ch_names\"]\n    if not do_topo:\n        # add vacuous \"index\" (needed for topo) so same code works for both\n        axes = [(ax, 0) for ax in axes]\n        if np.array(picks).ndim < 2:\n            picks = [picks]  # enables zipping w/ axes\n    else:\n        from ..channels.layout import find_layout\n        from .topo import iter_topography\n\n        fig = plt.figure(figsize=(18, 14), layout=None)  # Not \"constrained\" for topo\n\n        def click_func(\n            ax_,\n            pick_,\n            evokeds=evokeds,\n            colors=colors,\n            linestyles=linestyles,\n            styles=styles,\n            cmap=cmap,\n            vlines=vlines,\n            ci=ci,\n            truncate_yaxis=truncate_yaxis,\n            truncate_xaxis=truncate_xaxis,\n            ylim=ylim,\n            invert_y=invert_y,\n            show_sensors=show_sensors,\n            legend=legend,\n            split_legend=split_legend,\n            picks=picks,\n            combine=combine,\n        ):\n            plot_compare_evokeds(\n                evokeds=evokeds,\n                colors=colors,\n                linestyles=linestyles,\n                styles=styles,\n                cmap=cmap,\n                vlines=vlines,\n                ci=ci,\n                truncate_yaxis=truncate_yaxis,\n                truncate_xaxis=truncate_xaxis,\n                ylim=ylim,\n                invert_y=invert_y,\n                show_sensors=show_sensors,\n                legend=legend,\n                split_legend=split_legend,\n                picks=picks[pick_],\n                combine=combine,\n                axes=ax_,\n                show=True,\n                sphere=sphere,\n            )\n\n        layout = find_layout(info)\n        # make sure everything fits nicely. our figsize is (18, 14) so margins\n        # of 0.25 inch seem OK\n        w_margin = 0.25 / 18\n        h_margin = 0.25 / 14\n        axes_width = layout.pos[0, 2]\n        axes_height = layout.pos[0, 3]\n        left_edge = layout.pos[:, 0].min()\n        right_edge = layout.pos[:, 0].max() + axes_width\n        bottom_edge = layout.pos[:, 1].min()\n        top_edge = layout.pos[:, 1].max() + axes_height\n        # compute scale. Use less of vertical height (leave room for title)\n        w_scale = (0.95 - 2 * w_margin) / (right_edge - left_edge)\n        h_scale = (0.9 - 2 * h_margin) / (top_edge - bottom_edge)\n        # apply transformation\n        layout.pos[:, 0] = (layout.pos[:, 0] - left_edge) * w_scale + w_margin + 0.025\n        layout.pos[:, 1] = (layout.pos[:, 1] - bottom_edge) * h_scale + h_margin + 0.025\n        # make sure there is room for a legend axis (sometimes not if only a\n        # few channels were picked)\n        data_lefts = layout.pos[:, 0]\n        data_bottoms = layout.pos[:, 1]\n        legend_left = data_lefts.max()\n        legend_bottom = data_bottoms.min()\n        overlap = np.any(\n            np.logical_and(\n                np.logical_and(\n                    data_lefts <= legend_left, legend_left <= (data_lefts + axes_width)\n                ),\n                np.logical_and(\n                    data_bottoms <= legend_bottom,\n                    legend_bottom <= (data_bottoms + axes_height),\n                ),\n            )\n        )\n        right_edge = legend_left + axes_width\n        n_columns = (right_edge - data_lefts.min()) / axes_width\n        scale_factor = n_columns / (n_columns + 1)\n        if overlap:\n            layout.pos[:, [0, 2]] *= scale_factor\n        # `axes` will be a list of (axis_object, channel_index) tuples\n        axes = list(\n            iter_topography(\n                info,\n                layout=layout,\n                on_pick=click_func,\n                fig=fig,\n                fig_facecolor=\"w\",\n                axis_facecolor=\"w\",\n                axis_spinecolor=\"k\",\n                layout_scale=None,\n                legend=True,\n            )\n        )\n        picks = list(picks)\n    del info\n\n    # for each axis, compute the grand average and (maybe) the CI\n    # (per sensor if topo, otherwise aggregating over sensors)\n    c_func = None if do_topo else combine_func\n    all_data = list()\n    all_cis = list()\n    for _picks, (ax, idx) in zip(picks, axes):\n        data_dict = dict()\n        ci_dict = dict()\n        for cond in conditions:\n            this_evokeds = evokeds[cond]\n            # assign ci_fun first to get arg checking\n            ci_fun = _get_ci_function_pce(ci, do_topo=do_topo)\n            # for bootstrap or parametric CIs, skip when only 1 observation\n            if not callable(ci):\n                ci_fun = ci_fun if len(this_evokeds) > 1 else None\n            res = _get_data_and_ci(\n                this_evokeds,\n                combine,\n                c_func,\n                ch_type=ch_type,\n                picks=_picks,\n                scaling=scalings,\n                ci_fun=ci_fun,\n            )\n            data_dict[cond] = res[0]\n            if ci_fun is not None:\n                ci_dict[cond] = res[1]\n        all_data.append(data_dict)  # grand means, or indiv. sensors if do_topo\n        all_cis.append(ci_dict)\n    del evokeds\n\n    # compute ylims\n    allvalues = list()\n    for _dict in all_data:\n        for _array in list(_dict.values()):\n            allvalues.append(_array[np.newaxis])  # to get same .ndim as CIs\n    for _dict in all_cis:\n        allvalues.extend(list(_dict.values()))\n    allvalues = np.concatenate(allvalues)\n    norm = np.all(allvalues > 0)\n    orig_ymin, orig_ymax = ylim.get(ch_type, [None, None])\n    ymin, ymax = _setup_vmin_vmax(allvalues, orig_ymin, orig_ymax, norm)\n    del allvalues\n\n    # add empty data and title for the legend axis\n    if do_topo:\n        all_data.append({cond: np.array([]) for cond in data_dict})\n        all_cis.append({cond: None for cond in ci_dict})\n        all_ch_names.append(\"\")\n\n    # plot!\n    for (ax, idx), data, cis in zip(axes, all_data, all_cis):\n        if do_topo:\n            title = all_ch_names[idx]\n        # plot the data\n        _times = [] if idx == -1 else times\n        _plot_compare_evokeds(\n            ax, data, conditions, _times, cis, _styles, title, do_topo\n        )\n        # draw axes & vlines\n        skip_axlabel = do_topo and (idx != -1)\n        _draw_axes_pce(\n            ax,\n            ymin,\n            ymax,\n            truncate_yaxis,\n            truncate_xaxis,\n            invert_y,\n            vlines,\n            tmin,\n            tmax,\n            units,\n            skip_axlabel,\n            time_unit,\n        )\n    # add inset scalp plot showing location of sensors picked\n    if show_sensors:\n        _validate_type(\n            show_sensors,\n            (np.int64, bool, str, type(None)),\n            \"show_sensors\",\n            \"numeric, str, None or bool\",\n        )\n        if not _check_ch_locs(info=one_evoked.info, picks=pos_picks):\n            warn(\n                \"Cannot find channel coordinates in the supplied Evokeds. \"\n                \"Not showing channel locations.\"\n            )\n        else:\n            _evoked_sensor_legend(\n                one_evoked.info, pos_picks, ymin, ymax, show_sensors, ax, sphere\n            )\n    # add color/linestyle/colormap legend(s)\n    if legend:\n        _draw_legend_pce(\n            legend, split_legend, _styles, _linestyles, _colors, _cmap, do_topo, ax\n        )\n    if cmap is not None:\n        _draw_colorbar_pce(ax, _colors, _cmap, colorbar_title, colorbar_ticks)\n    # finish\n    if topo_disp_title:\n        ax.figure.suptitle(topo_title)\n    plt_show(show)\n    return [ax.figure]", "metadata": {}}
{"_id": "mne_mne_viz/evoked.py_whitened_gfp_code", "title": "whitened_gfp", "text": "def whitened_gfp(x, rank=None):\n        \"\"\"Whitened Global Field Power.\n\n        The MNE inverse solver assumes zero mean whitened data as input.\n        Therefore, a chi^2 statistic will be best to detect model violations.\n        \"\"\"\n        return np.sum(x**2, axis=0) / (len(x) if rank is None else rank)", "metadata": {}}
{"_id": "mne_mne_viz/evoked_field.py_set_time_code", "title": "set_time", "text": "def set_time(self, time):\n        \"\"\"Set the time to display (in seconds).\n\n        Parameters\n        ----------\n        time : float\n            The time to show, in seconds.\n        \"\"\"\n        if self._evoked.times[0] <= time <= self._evoked.times[-1]:\n            publish(self, TimeChange(time=time))\n        else:\n            raise ValueError(\n                f\"Requested time ({time} s) is outside the range of \"\n                f\"available times ({self._evoked.times[0]}-{self._evoked.times[-1]} s).\"\n            )", "metadata": {}}
{"_id": "mne_mne_viz/evoked_field.py_set_contours_code", "title": "set_contours", "text": "def set_contours(self, n_contours):\n        \"\"\"Adjust the number of contour lines to use when drawing the fieldlines.\n\n        Parameters\n        ----------\n        n_contours : int\n            The number of contour lines to use.\n        \"\"\"\n        for surf_map in self._surf_maps:\n            publish(\n                self,\n                Contours(\n                    kind=f\"field_strength_{surf_map['map_kind']}\",\n                    contours=np.linspace(\n                        -surf_map[\"map_vmax\"], surf_map[\"map_vmax\"], n_contours\n                    ).tolist(),\n                ),\n            )", "metadata": {}}
{"_id": "mne_mne_viz/evoked_field.py_set_vmax_code", "title": "set_vmax", "text": "def set_vmax(self, vmax, kind=\"meg\"):\n        \"\"\"Change the color range of the density maps.\n\n        Parameters\n        ----------\n        vmax : float\n            The new maximum value of the color range.\n        kind : 'meg' | 'eeg'\n            Which field map to apply the new color range to.\n        \"\"\"\n        _check_option(\"type\", kind, [\"eeg\", \"meg\"])\n        for surf_map in self._surf_maps:\n            if surf_map[\"map_kind\"] == kind:\n                publish(\n                    self,\n                    ColormapRange(\n                        kind=f\"field_strength_{kind}\",\n                        fmin=-vmax,\n                        fmax=vmax,\n                    ),\n                )\n                break\n        else:\n            raise ValueError(f\"No {type.upper()} field map currently shown.\")", "metadata": {}}
{"_id": "mne_mne_viz/misc.py_plot_cov_code", "title": "plot_cov", "text": "def plot_cov(\n    cov,\n    info,\n    exclude=(),\n    colorbar=True,\n    proj=False,\n    show_svd=True,\n    show=True,\n    verbose=None,\n):\n    \"\"\"Plot Covariance data.\n\n    Parameters\n    ----------\n    cov : instance of Covariance\n        The covariance matrix.\n    %(info_not_none)s\n    exclude : list of str | str\n        List of channels to exclude. If empty do not exclude any channel.\n        If 'bads', exclude info['bads'].\n    colorbar : bool\n        Show colorbar or not.\n    proj : bool\n        Apply projections or not.\n    show_svd : bool\n        Plot also singular values of the noise covariance for each sensor\n        type. We show square roots ie. standard deviations.\n    show : bool\n        Show figure if True.\n    %(verbose)s\n\n    Returns\n    -------\n    fig_cov : instance of matplotlib.figure.Figure\n        The covariance plot.\n    fig_svd : instance of matplotlib.figure.Figure | None\n        The SVD plot of the covariance (i.e., the eigenvalues or \"matrix spectrum\").\n\n    See Also\n    --------\n    mne.compute_rank\n\n    Notes\n    -----\n    For each channel type, the rank is estimated using\n    :func:`mne.compute_rank`.\n\n    .. versionchanged:: 0.19\n       Approximate ranks for each channel type are shown with red dashed lines.\n    \"\"\"\n    import matplotlib.pyplot as plt\n    from matplotlib.colors import Normalize\n\n    from ..cov import Covariance\n\n    info, C, ch_names, idx_names = _index_info_cov(info, cov, exclude)\n    del cov, exclude\n\n    projs = []\n    if proj:\n        projs = copy.deepcopy(info[\"projs\"])\n\n        #   Activate the projection items\n        for p in projs:\n            p[\"active\"] = True\n\n        P, ncomp, _ = make_projector(projs, ch_names)\n        if ncomp > 0:\n            logger.info(f\"    Created an SSP operator (subspace dimension = {ncomp:d})\")\n            C = np.dot(P, np.dot(C, P.T))\n        else:\n            logger.info(\"    The projection vectors do not apply to these channels.\")\n\n    if np.iscomplexobj(C):\n        C = np.sqrt((C * C.conj()).real)\n\n    fig_cov, axes = plt.subplots(\n        1,\n        len(idx_names),\n        squeeze=False,\n        figsize=(3.8 * len(idx_names), 3.7),\n        layout=\"constrained\",\n    )\n    for k, (idx, name, _, _, _) in enumerate(idx_names):\n        vlim = np.max(np.abs(C[idx][:, idx]))\n        im = axes[0, k].imshow(\n            C[idx][:, idx],\n            interpolation=\"nearest\",\n            norm=Normalize(vmin=-vlim, vmax=vlim),\n            cmap=\"RdBu_r\",\n        )\n        axes[0, k].set(title=name)\n\n        if colorbar:\n            from mpl_toolkits.axes_grid1 import make_axes_locatable\n\n            divider = make_axes_locatable(axes[0, k])\n            cax = divider.append_axes(\"right\", size=\"5.5%\", pad=0.05)\n            cax.grid(False)  # avoid mpl warning about auto-removal\n            plt.colorbar(im, cax=cax, format=\"%.0e\")\n\n    fig_svd = None\n    if show_svd:\n        fig_svd, axes = plt.subplots(\n            1,\n            len(idx_names),\n            squeeze=False,\n            figsize=(3.8 * len(idx_names), 3.7),\n            layout=\"constrained\",\n        )\n        for k, (idx, name, unit, scaling, key) in enumerate(idx_names):\n            this_C = C[idx][:, idx]\n            s = _safe_svd(this_C, compute_uv=False)\n            this_C = Covariance(this_C, [info[\"ch_names\"][ii] for ii in idx], [], [], 0)\n            this_info = pick_info(info, idx)\n            with this_info._unlock():\n                this_info[\"projs\"] = []\n            this_rank = compute_rank(this_C, info=this_info)\n            # Protect against true zero singular values\n            s[s <= 0] = 1e-10 * s[s > 0].min()\n            s = np.sqrt(s) * scaling\n            axes[0, k].plot(s, color=\"k\", zorder=3)\n            this_rank = this_rank[key]\n            axes[0, k].axvline(\n                this_rank - 1, ls=\"--\", color=\"r\", alpha=0.5, zorder=4, clip_on=False\n            )\n            axes[0, k].text(\n                this_rank - 1,\n                axes[0, k].get_ylim()[1],\n                f\"rank \u2248 {this_rank:d}\",\n                ha=\"right\",\n                va=\"top\",\n                color=\"r\",\n                alpha=0.5,\n                zorder=4,\n            )\n            axes[0, k].set(\n                ylabel=f\"Noise \u03c3 ({unit})\",\n                yscale=\"log\",\n                xlabel=\"Eigenvalue index\",\n                title=name,\n                xlim=[0, len(s) - 1],\n            )\n\n    plt_show(show)\n    return fig_cov, fig_svd", "metadata": {}}
{"_id": "mne_mne_viz/misc.py_plot_source_spectrogram_code", "title": "plot_source_spectrogram", "text": "def plot_source_spectrogram(\n    stcs, freq_bins, tmin=None, tmax=None, source_index=None, colorbar=False, show=True\n):\n    \"\"\"Plot source power in time-freqency grid.\n\n    Parameters\n    ----------\n    stcs : list of SourceEstimate\n        Source power for consecutive time windows, one SourceEstimate object\n        should be provided for each frequency bin.\n    freq_bins : list of tuples of float\n        Start and end points of frequency bins of interest.\n    tmin : float\n        Minimum time instant to show.\n    tmax : float\n        Maximum time instant to show.\n    source_index : int | None\n        Index of source for which the spectrogram will be plotted. If None,\n        the source with the largest activation will be selected.\n    colorbar : bool\n        If true, a colorbar will be added to the plot.\n    show : bool\n        Show figure if True.\n\n    Returns\n    -------\n    fig : instance of Figure\n        The figure.\n    \"\"\"\n    import matplotlib.pyplot as plt\n\n    # Input checks\n    if len(stcs) == 0:\n        raise ValueError(\"cannot plot spectrogram if len(stcs) == 0\")\n\n    stc = stcs[0]\n    if tmin is not None and tmin < stc.times[0]:\n        raise ValueError(\n            \"tmin cannot be smaller than the first time point provided in stcs\"\n        )\n    if tmax is not None and tmax > stc.times[-1] + stc.tstep:\n        raise ValueError(\n            \"tmax cannot be larger than the sum of the last time \"\n            \"point and the time step, which are provided in stcs\"\n        )\n\n    # Preparing time-frequency cell boundaries for plotting\n    if tmin is None:\n        tmin = stc.times[0]\n    if tmax is None:\n        tmax = stc.times[-1] + stc.tstep\n    time_bounds = np.arange(tmin, tmax + stc.tstep, stc.tstep)\n    freq_bounds = sorted(set(np.ravel(freq_bins)))\n    freq_ticks = copy.deepcopy(freq_bounds)\n\n    # Reject time points that will not be plotted and gather results\n    source_power = []\n    for stc in stcs:\n        stc = stc.copy()  # copy since crop modifies inplace\n        stc.crop(tmin, tmax - stc.tstep)\n        source_power.append(stc.data)\n    source_power = np.array(source_power)\n\n    # Finding the source with maximum source power\n    if source_index is None:\n        source_index = np.unravel_index(source_power.argmax(), source_power.shape)[1]\n\n    # If there is a gap in the frequency bins record its locations so that it\n    # can be covered with a gray horizontal bar\n    gap_bounds = []\n    for i in range(len(freq_bins) - 1):\n        lower_bound = freq_bins[i][1]\n        upper_bound = freq_bins[i + 1][0]\n        if lower_bound != upper_bound:\n            freq_bounds.remove(lower_bound)\n            gap_bounds.append((lower_bound, upper_bound))\n\n    # Preparing time-frequency grid for plotting\n    time_grid, freq_grid = np.meshgrid(time_bounds, freq_bounds)\n\n    # Plotting the results\n    fig = plt.figure(figsize=(9, 6), layout=\"constrained\")\n    plt.pcolor(time_grid, freq_grid, source_power[:, source_index, :], cmap=\"Reds\")\n    ax = plt.gca()\n\n    ax.set(title=\"Source power\", xlabel=\"Time (s)\", ylabel=\"Frequency (Hz)\")\n\n    time_tick_labels = [str(np.round(t, 2)) for t in time_bounds]\n    n_skip = 1 + len(time_bounds) // 10\n    for i in range(len(time_bounds)):\n        if i % n_skip != 0:\n            time_tick_labels[i] = \"\"\n\n    ax.set_xticks(time_bounds)\n    ax.set_xticklabels(time_tick_labels)\n    plt.xlim(time_bounds[0], time_bounds[-1])\n    plt.yscale(\"log\")\n    ax.set_yticks(freq_ticks)\n    ax.set_yticklabels([np.round(freq, 2) for freq in freq_ticks])\n    plt.ylim(freq_bounds[0], freq_bounds[-1])\n\n    plt.grid(True, ls=\"-\")\n    if colorbar:\n        plt.colorbar()\n\n    # Covering frequency gaps with horizontal bars\n    for lower_bound, upper_bound in gap_bounds:\n        plt.barh(\n            lower_bound,\n            time_bounds[-1] - time_bounds[0],\n            upper_bound - lower_bound,\n            time_bounds[0],\n            color=\"#666666\",\n        )\n\n    plt_show(show)\n    return fig", "metadata": {}}
{"_id": "mne_mne_viz/misc.py_plot_bem_code", "title": "plot_bem", "text": "def plot_bem(\n    subject,\n    subjects_dir=None,\n    orientation=\"coronal\",\n    slices=None,\n    brain_surfaces=None,\n    src=None,\n    show=True,\n    show_indices=True,\n    mri=\"T1.mgz\",\n    show_orientation=True,\n):\n    \"\"\"Plot BEM contours on anatomical MRI slices.\n\n    Parameters\n    ----------\n    %(subject)s\n    %(subjects_dir)s\n    orientation : str\n        'coronal' or 'axial' or 'sagittal'.\n    slices : list of int | None\n        The indices of the MRI slices to plot. If ``None``, automatically\n        pick 12 equally-spaced slices.\n    brain_surfaces : str | list of str | None\n        One or more brain surface to plot (optional). Entries should correspond\n        to files in the subject's ``surf`` directory (e.g. ``\"white\"``).\n    src : SourceSpaces | path-like | None\n        SourceSpaces instance or path to a source space to plot individual\n        sources as scatter-plot. Sources will be shown on exactly one slice\n        (whichever slice is closest to each source in the given orientation\n        plane). Path can be absolute or relative to the subject's ``bem``\n        folder.\n\n        .. versionchanged:: 0.20\n           All sources are shown on the nearest slice rather than some\n           being omitted.\n    show : bool\n        Show figure if True.\n    show_indices : bool\n        Show slice indices if True.\n\n        .. versionadded:: 0.20\n    mri : str\n        The name of the MRI to use. Can be a standard FreeSurfer MRI such as\n        ``'T1.mgz'``, or a full path to a custom MRI file.\n\n        .. versionadded:: 0.21\n    show_orientation : bool | str\n        Show the orientation (L/R, P/A, I/S) of the data slices.\n        True (default) will only show it on the outside most edges of the\n        figure, False will never show labels, and \"always\" will label each\n        plot.\n\n        .. versionadded:: 0.21\n        .. versionchanged:: 0.24\n           Added support for \"always\".\n\n    Returns\n    -------\n    fig : instance of matplotlib.figure.Figure\n        The figure.\n\n    See Also\n    --------\n    mne.viz.plot_alignment\n\n    Notes\n    -----\n    Images are plotted in MRI voxel coordinates.\n\n    If ``src`` is not None, for a given slice index, all source points are\n    shown that are halfway between the previous slice and the given slice,\n    and halfway between the given slice and the next slice.\n    For large slice decimations, this can\n    make some source points appear outside the BEM contour, which is shown\n    for the given slice index. For example, in the case where the single\n    midpoint slice is used ``slices=[128]``, all source points will be shown\n    on top of the midpoint MRI slice with the BEM boundary drawn for that\n    slice.\n    \"\"\"\n    from ..source_space import SourceSpaces, read_source_spaces\n\n    subjects_dir = get_subjects_dir(subjects_dir, raise_error=True)\n    mri_fname = _check_mri(mri, subject, subjects_dir)\n\n    # Get the BEM surface filenames\n    bem_path = subjects_dir / subject / \"bem\"\n\n    if not bem_path.is_dir():\n        raise OSError(f'Subject bem directory \"{bem_path}\" does not exist')\n\n    surfaces = _get_bem_plotting_surfaces(bem_path)\n    if brain_surfaces is not None:\n        if isinstance(brain_surfaces, str):\n            brain_surfaces = (brain_surfaces,)\n        for surf_name in brain_surfaces:\n            for hemi in (\"lh\", \"rh\"):\n                surf_fname = subjects_dir / subject / \"surf\" / f\"{hemi}.{surf_name}\"\n                if surf_fname.exists():\n                    surfaces.append((surf_fname, \"#00DD00\"))\n                else:\n                    raise OSError(f\"Surface {surf_fname} does not exist.\")\n\n    # TODO: Refactor with / improve _ensure_src to do this\n    if isinstance(src, str | Path | os.PathLike):\n        src = Path(src)\n        if not src.exists():\n            # convert to Path until get_subjects_dir returns a Path object\n            src_ = Path(subjects_dir) / subject / \"bem\" / src\n            if not src_.exists():\n                raise OSError(f\"{src} does not exist\")\n            src = src_\n        src = read_source_spaces(src)\n    elif src is not None and not isinstance(src, SourceSpaces):\n        raise TypeError(\n            f\"src needs to be None, path-like or SourceSpaces instance, not {repr(src)}\"\n        )\n\n    if len(surfaces) == 0:\n        raise OSError(\n            \"No surface files found. Surface files must end with \"\n            \"inner_skull.surf, outer_skull.surf or outer_skin.surf\"\n        )\n\n    # Plot the contours\n    fig = _plot_mri_contours(\n        mri_fname=mri_fname,\n        surfaces=surfaces,\n        src=src,\n        orientation=orientation,\n        slices=slices,\n        show=show,\n        show_indices=show_indices,\n        show_orientation=show_orientation,\n        slices_as_subplots=True,\n    )\n    return fig", "metadata": {}}
{"_id": "mne_mne_viz/misc.py_plot_events_code", "title": "plot_events", "text": "def plot_events(\n    events,\n    sfreq=None,\n    first_samp=0,\n    color=None,\n    event_id=None,\n    axes=None,\n    equal_spacing=True,\n    show=True,\n    on_missing=\"raise\",\n    verbose=None,\n):\n    \"\"\"Plot :term:`events` to get a visual display of the paradigm.\n\n    Parameters\n    ----------\n    %(events)s\n    sfreq : float | None\n        The sample frequency. If None, data will be displayed in samples (not\n        seconds).\n    first_samp : int\n        The index of the first sample. Recordings made on Neuromag systems\n        number samples relative to the system start (not relative to the\n        beginning of the recording). In such cases the ``raw.first_samp``\n        attribute can be passed here. Default is 0.\n    color : dict | None\n        Dictionary of event_id integers as keys and colors as values. If None,\n        colors are automatically drawn from a default list (cycled through if\n        number of events longer than list of default colors). Color can be any\n        valid :ref:`matplotlib color <matplotlib:colors_def>`.\n    event_id : dict | None\n        Dictionary of event labels (e.g. 'aud_l') as keys and their associated\n        event_id values. Labels are used to plot a legend. If None, no legend\n        is drawn.\n    axes : instance of Axes\n       The subplot handle.\n    equal_spacing : bool\n        Use equal spacing between events in y-axis.\n    show : bool\n        Show figure if True.\n    %(on_missing_events)s\n    %(verbose)s\n\n    Returns\n    -------\n    fig : matplotlib.figure.Figure\n        The figure object containing the plot.\n\n    Notes\n    -----\n    .. versionadded:: 0.9.0\n    \"\"\"\n    if sfreq is None:\n        sfreq = 1.0\n        xlabel = \"Samples\"\n    else:\n        xlabel = \"Time (s)\"\n\n    events = np.asarray(events)\n    if len(events) == 0:\n        raise ValueError(\"No events in events array, cannot plot.\")\n    unique_events = np.unique(events[:, 2])\n\n    if event_id is not None:\n        # get labels and unique event ids from event_id dict,\n        # sorted by value\n        event_id_rev = {v: k for k, v in event_id.items()}\n        conditions, unique_events_id = zip(\n            *sorted(event_id.items(), key=lambda x: x[1])\n        )\n\n        keep = np.ones(len(unique_events_id), bool)\n        for ii, this_event in enumerate(unique_events_id):\n            if this_event not in unique_events:\n                msg = f\"{this_event} from event_id is not present in events.\"\n                _on_missing(on_missing, msg)\n                keep[ii] = False\n        conditions = [cond for cond, k in zip(conditions, keep) if k]\n        unique_events_id = [id_ for id_, k in zip(unique_events_id, keep) if k]\n        if len(unique_events_id) == 0:\n            raise RuntimeError(\"No usable event IDs found\")\n\n        for this_event in unique_events:\n            if this_event not in unique_events_id:\n                warn(f\"event {this_event} missing from event_id will be ignored\")\n\n    else:\n        unique_events_id = unique_events\n\n    color = _handle_event_colors(color, unique_events, event_id)\n    import matplotlib.pyplot as plt\n\n    unique_events_id = np.array(unique_events_id)\n\n    fig = None\n    figsize = plt.rcParams[\"figure.figsize\"]\n    # assuming the user did not change matplotlib default params, the figsize of\n    # (6.4, 4.8) becomes too big if scaled beyond twice its size, so maximum 2\n    _scaling = min(max(1, len(unique_events_id) / 10), 2)\n    figsize_scaled = np.array(figsize) * _scaling\n    if axes is None:\n        fig = plt.figure(layout=\"constrained\", figsize=tuple(figsize_scaled))\n    ax = axes if axes else plt.gca()\n\n    min_event = np.min(unique_events_id)\n    max_event = np.max(unique_events_id)\n    max_x = (\n        events[np.isin(events[:, 2], unique_events_id), 0].max() - first_samp\n    ) / sfreq\n\n    handles, labels = list(), list()\n    for idx, ev in enumerate(unique_events_id):\n        ev_mask = events[:, 2] == ev\n        count = ev_mask.sum()\n        if count == 0:\n            continue\n        y = np.full(count, idx + 1 if equal_spacing else events[ev_mask, 2][0])\n        if event_id is not None:\n            event_label = f\"{event_id_rev[ev]}\\n(id:{ev}; N:{count})\"\n        else:\n            event_label = f\"id:{ev}; N:{count:d}\"\n        labels.append(event_label)\n        kwargs = {}\n        if ev in color:\n            kwargs[\"color\"] = color[ev]\n        handles.append(\n            ax.plot(\n                (events[ev_mask, 0] - first_samp) / sfreq,\n                y,\n                \".\",\n                clip_on=False,\n                **kwargs,\n            )[0]\n        )\n\n    if equal_spacing:\n        ax.set_ylim(0, unique_events_id.size + 1)\n        ax.set_yticks(1 + np.arange(unique_events_id.size))\n        ax.set_yticklabels(unique_events_id)\n    else:\n        ax.set_ylim([min_event - 1, max_event + 1])\n\n    ax.set(xlabel=xlabel, ylabel=\"Event id\", xlim=[0, max_x])\n\n    ax.grid(True)\n\n    fig = fig if fig is not None else plt.gcf()\n    # reverse order so that the highest numbers are at the top\n    # (match plot order)\n    handles, labels = handles[::-1], labels[::-1]\n\n    # spread legend entries over more columns, 25 still ~fit in one column\n    # (assuming non-user supplied fig), max at 3 columns\n    ncols = min(int(np.ceil(len(unique_events_id) / 25)), 3)\n\n    # Make space for legend\n    box = ax.get_position()\n    factor = 0.8 if event_id is not None else 0.9\n    factor -= 0.1 * (ncols - 1)\n    ax.set_position([box.x0, box.y0, box.width * factor, box.height])\n\n    # Try some adjustments to squeeze as much information into the legend\n    # without cutting off the ends\n    ax.legend(\n        handles,\n        labels,\n        loc=\"center left\",\n        bbox_to_anchor=(1, 0.5),\n        fontsize=\"small\",\n        borderpad=0,  # default 0.4\n        labelspacing=0.25,  # default 0.5\n        columnspacing=1.0,  # default 2\n        handletextpad=0,  # default 0.8\n        markerscale=2,  # default 1\n        borderaxespad=0.2,  # default 0.5\n        ncols=ncols,\n    )\n    fig.canvas.draw()\n    plt_show(show)\n    return fig", "metadata": {}}
{"_id": "mne_mne_viz/misc.py_plot_dipole_amplitudes_code", "title": "plot_dipole_amplitudes", "text": "def plot_dipole_amplitudes(dipoles, colors=None, show=True):\n    \"\"\"Plot the amplitude traces of a set of dipoles.\n\n    Parameters\n    ----------\n    dipoles : list of instance of Dipole\n        The dipoles whose amplitudes should be shown.\n    colors : list of color | None\n        Color to plot with each dipole. If None default colors are used.\n    show : bool\n        Show figure if True.\n\n    Returns\n    -------\n    fig : matplotlib.figure.Figure\n        The figure object containing the plot.\n\n    Notes\n    -----\n    .. versionadded:: 0.9.0\n    \"\"\"\n    import matplotlib.pyplot as plt\n\n    if colors is None:\n        colors = cycle(_get_color_list())\n    fig, ax = plt.subplots(1, 1, layout=\"constrained\")\n    xlim = [np.inf, -np.inf]\n    for dip, color in zip(dipoles, colors):\n        ax.plot(dip.times, dip.amplitude * 1e9, color=color, linewidth=1.5)\n        xlim[0] = min(xlim[0], dip.times[0])\n        xlim[1] = max(xlim[1], dip.times[-1])\n    ax.set(xlim=xlim, xlabel=\"Time (s)\", ylabel=\"Amplitude (nAm)\")\n    if show:\n        fig.show(warn=False)\n    return fig", "metadata": {}}
{"_id": "mne_mne_viz/misc.py_adjust_axes_code", "title": "adjust_axes", "text": "def adjust_axes(axes, remove_spines=(\"top\", \"right\"), grid=True):\n    \"\"\"Adjust some properties of axes.\n\n    Parameters\n    ----------\n    axes : list\n        List of axes to process.\n    remove_spines : list of str\n        Which axis spines to remove.\n    grid : bool\n        Turn grid on (True) or off (False).\n    \"\"\"\n    axes = [axes] if not isinstance(axes, list | tuple | np.ndarray) else axes\n    for ax in axes:\n        if grid:\n            ax.grid(zorder=0)\n        for key in remove_spines:\n            ax.spines[key].set_visible(False)", "metadata": {}}
{"_id": "mne_mne_viz/misc.py_plot_filter_code", "title": "plot_filter", "text": "def plot_filter(\n    h,\n    sfreq,\n    freq=None,\n    gain=None,\n    title=None,\n    color=\"#1f77b4\",\n    flim=None,\n    fscale=\"log\",\n    alim=_DEFAULT_ALIM,\n    show=True,\n    compensate=False,\n    plot=(\"time\", \"magnitude\", \"delay\"),\n    axes=None,\n    *,\n    dlim=None,\n):\n    \"\"\"Plot properties of a filter.\n\n    Parameters\n    ----------\n    h : dict or ndarray\n        An IIR dict or 1D ndarray of coefficients (for FIR filter).\n    sfreq : float\n        Sample rate of the data (Hz).\n    freq : array-like or None\n        The ideal response frequencies to plot (must be in ascending order).\n        If None (default), do not plot the ideal response.\n    gain : array-like or None\n        The ideal response gains to plot.\n        If None (default), do not plot the ideal response.\n    title : str | None\n        The title to use. If None (default), determine the title based\n        on the type of the system.\n    color : color object\n        The color to use (default '#1f77b4').\n    flim : tuple or None\n        If not None, the x-axis frequency limits (Hz) to use.\n        If None, freq will be used. If None (default) and freq is None,\n        ``(0.1, sfreq / 2.)`` will be used.\n    fscale : str\n        Frequency scaling to use, can be \"log\" (default) or \"linear\".\n    alim : tuple\n        The y-axis amplitude limits (dB) to use (default: (-60, 10)).\n    show : bool\n        Show figure if True (default).\n    compensate : bool\n        If True, compensate for the filter delay (phase will not be shown).\n\n        - For linear-phase FIR filters, this visualizes the filter coefficients\n          assuming that the output will be shifted by ``N // 2``.\n        - For IIR filters, this changes the filter coefficient display\n          by filtering backward and forward, and the frequency response\n          by squaring it.\n\n        .. versionadded:: 0.18\n    plot : list | tuple | str\n        A list of the requested plots from ``time``, ``magnitude`` and\n        ``delay``. Default is to plot all three filter properties\n        ('time', 'magnitude', 'delay').\n\n        .. versionadded:: 0.21.0\n    axes : instance of Axes | list | None\n        The axes to plot to. If list, the list must be a list of Axes of\n        the same length as the number of requested plot types. If instance of\n        Axes, there must be only one filter property plotted.\n        Defaults to ``None``.\n\n        .. versionadded:: 0.21.0\n    dlim : None | tuple\n        The y-axis delay limits (s) to use (default:\n        ``(-tmax / 2., tmax / 2.)``).\n\n        .. versionadded:: 1.1.0\n\n    Returns\n    -------\n    fig : matplotlib.figure.Figure\n        The figure containing the plots.\n\n    See Also\n    --------\n    mne.filter.create_filter\n    plot_ideal_filter\n\n    Notes\n    -----\n    .. versionadded:: 0.14\n    \"\"\"\n    import matplotlib.pyplot as plt\n\n    sfreq = float(sfreq)\n    _check_option(\"fscale\", fscale, [\"log\", \"linear\"])\n    if isinstance(plot, str):\n        plot = [plot]\n    for xi, x in enumerate(plot):\n        _check_option(f\"plot[{xi}]\", x, (\"magnitude\", \"delay\", \"time\"))\n\n    flim = _get_flim(flim, fscale, freq, sfreq)\n    if fscale == \"log\":\n        omega = np.logspace(np.log10(flim[0]), np.log10(flim[1]), 1000)\n    else:\n        omega = np.linspace(flim[0], flim[1], 1000)\n    xticks, xticklabels = _filter_ticks(flim, fscale)\n    omega /= sfreq / (2 * np.pi)\n    if isinstance(h, dict):  # IIR h.ndim == 2:  # second-order sections\n        if \"sos\" in h:\n            H = np.ones(len(omega), np.complex128)\n            gd = np.zeros(len(omega))\n            for section in h[\"sos\"]:\n                this_H = freqz(section[:3], section[3:], omega)[1]\n                H *= this_H\n                if compensate:\n                    H *= this_H.conj()  # time reversal is freq conj\n                else:\n                    # Assume the forward-backward delay zeros out, which it\n                    # mostly should\n                    with warnings.catch_warnings(record=True):  # singular GD\n                        warnings.simplefilter(\"ignore\")\n                        gd += group_delay((section[:3], section[3:]), omega)[1]\n            n = estimate_ringing_samples(h[\"sos\"])\n            delta = np.zeros(n)\n            delta[0] = 1\n            if compensate:\n                delta = np.pad(delta, [(n - 1, 0)], \"constant\")\n                func = sosfiltfilt\n                gd += (len(delta) - 1) // 2\n            else:\n                func = sosfilt\n            h = func(h[\"sos\"], delta)\n        else:\n            H = freqz(h[\"b\"], h[\"a\"], omega)[1]\n            if compensate:\n                H *= H.conj()\n            with warnings.catch_warnings(record=True):  # singular GD\n                warnings.simplefilter(\"ignore\")\n                gd = group_delay((h[\"b\"], h[\"a\"]), omega)[1]\n                if compensate:\n                    gd += group_delay((h[\"b\"].conj(), h[\"a\"].conj()), omega)[1]\n            n = estimate_ringing_samples((h[\"b\"], h[\"a\"]))\n            delta = np.zeros(n)\n            delta[0] = 1\n            if compensate:\n                delta = np.pad(delta, [(n - 1, 0)], \"constant\")\n                func = filtfilt\n            else:\n                func = lfilter\n            h = func(h[\"b\"], h[\"a\"], delta)\n        if title is None:\n            title = \"SOS (IIR) filter\"\n        if compensate:\n            title += \" (forward-backward)\"\n    else:\n        H = freqz(h, worN=omega)[1]\n        with warnings.catch_warnings(record=True):  # singular GD\n            warnings.simplefilter(\"ignore\")\n            gd = group_delay((h, [1.0]), omega)[1]\n        title = \"FIR filter\" if title is None else title\n        if compensate:\n            title += \" (delay-compensated)\"\n\n    fig = None\n    if axes is None:\n        fig, axes = plt.subplots(len(plot), 1, layout=\"constrained\")\n    if isinstance(axes, plt.Axes):\n        axes = [axes]\n    elif isinstance(axes, np.ndarray):\n        axes = list(axes)\n    if fig is None:\n        fig = axes[0].get_figure()\n    if len(axes) != len(plot):\n        raise ValueError(\n            f\"Length of axes ({len(axes)}) must be the same as number of \"\n            f\"requested filter properties ({len(plot)})\"\n        )\n\n    t = np.arange(len(h))\n    if dlim is None:\n        dlim = np.abs(t).max() / 2.0\n        dlim = [-dlim, dlim]\n    if compensate:\n        n_shift = (len(h) - 1) // 2\n        t -= n_shift\n        assert t[0] == -t[-1]\n        gd -= n_shift\n    t = t / sfreq\n    gd = gd / sfreq\n    f = omega * sfreq / (2 * np.pi)\n    sl = slice(0 if fscale == \"linear\" else 1, None, None)\n    mag = 10 * np.log10(np.maximum((H * H.conj()).real, 1e-20))\n\n    if \"time\" in plot:\n        ax_time_idx = np.where([p == \"time\" for p in plot])[0][0]\n        axes[ax_time_idx].plot(t, h, color=color, linewidth=1.2)\n        axes[ax_time_idx].grid(visible=True, which=\"major\", axis=\"both\", linewidth=0.15)\n        axes[ax_time_idx].set(\n            xlim=t[[0, -1]], xlabel=\"Time (s)\", ylabel=\"Amplitude\", title=title\n        )\n    # Magnitude\n    if \"magnitude\" in plot:\n        ax_mag_idx = np.where([p == \"magnitude\" for p in plot])[0][0]\n        axes[ax_mag_idx].plot(f[sl], mag[sl], color=color, linewidth=1.2, zorder=4)\n        axes[ax_mag_idx].grid(visible=True, which=\"major\", axis=\"both\", linewidth=0.15)\n        if freq is not None and gain is not None:\n            plot_ideal_filter(freq, gain, axes[ax_mag_idx], fscale=fscale, show=False)\n        axes[ax_mag_idx].set(ylabel=\"Magnitude (dB)\", xlabel=\"\", xscale=fscale)\n        if xticks is not None:\n            axes[ax_mag_idx].set(xticks=xticks)\n            axes[ax_mag_idx].set(xticklabels=xticklabels)\n        axes[ax_mag_idx].set(\n            xlim=flim, ylim=alim, xlabel=\"Frequency (Hz)\", ylabel=\"Amplitude (dB)\"\n        )\n    # Delay\n    if \"delay\" in plot:\n        ax_delay_idx = np.where([p == \"delay\" for p in plot])[0][0]\n        axes[ax_delay_idx].plot(f[sl], gd[sl], color=color, linewidth=1.2, zorder=4)\n        axes[ax_delay_idx].grid(\n            visible=True, which=\"major\", axis=\"both\", linewidth=0.15\n        )\n        # shade nulled regions\n        for start, stop in zip(*_mask_to_onsets_offsets(mag <= -39.9)):\n            axes[ax_delay_idx].axvspan(\n                f[start], f[stop - 1], facecolor=\"k\", alpha=0.05, zorder=5\n            )\n        axes[ax_delay_idx].set(\n            xlim=flim, ylabel=\"Group delay (s)\", xlabel=\"Frequency (Hz)\", xscale=fscale\n        )\n        if xticks is not None:\n            axes[ax_delay_idx].set(xticks=xticks)\n            axes[ax_delay_idx].set(xticklabels=xticklabels)\n        axes[ax_delay_idx].set(\n            xlim=flim, ylim=dlim, xlabel=\"Frequency (Hz)\", ylabel=\"Delay (s)\"\n        )\n\n    adjust_axes(axes)\n    plt_show(show)\n    return fig", "metadata": {}}
{"_id": "mne_mne_viz/misc.py_plot_ideal_filter_code", "title": "plot_ideal_filter", "text": "def plot_ideal_filter(\n    freq,\n    gain,\n    axes=None,\n    title=\"\",\n    flim=None,\n    fscale=\"log\",\n    alim=_DEFAULT_ALIM,\n    color=\"r\",\n    alpha=0.5,\n    linestyle=\"--\",\n    show=True,\n):\n    \"\"\"Plot an ideal filter response.\n\n    Parameters\n    ----------\n    freq : array-like\n        The ideal response frequencies to plot (must be in ascending order).\n    gain : array-like or None\n        The ideal response gains to plot.\n    axes : instance of Axes | None\n        The subplot handle. With None (default), axes are created.\n    title : str\n        The title to use, (default: '').\n    flim : tuple or None\n        If not None, the x-axis frequency limits (Hz) to use.\n        If None (default), freq used.\n    fscale : str\n        Frequency scaling to use, can be \"log\" (default) or \"linear\".\n    alim : tuple\n        If not None (default), the y-axis limits (dB) to use.\n    color : color object\n        The color to use (default: 'r').\n    alpha : float\n        The alpha to use (default: 0.5).\n    linestyle : str\n        The line style to use (default: '--').\n    show : bool\n        Show figure if True (default).\n\n    Returns\n    -------\n    fig : instance of matplotlib.figure.Figure\n        The figure.\n\n    See Also\n    --------\n    plot_filter\n\n    Notes\n    -----\n    .. versionadded:: 0.14\n\n    Examples\n    --------\n    Plot a simple ideal band-pass filter::\n\n        >>> from mne.viz import plot_ideal_filter\n        >>> freq = [0, 1, 40, 50]\n        >>> gain = [0, 1, 1, 0]\n        >>> plot_ideal_filter(freq, gain, flim=(0.1, 100))  #doctest: +SKIP\n        <...Figure...>\n    \"\"\"\n    import matplotlib.pyplot as plt\n\n    my_freq, my_gain = list(), list()\n    if freq[0] != 0:\n        raise ValueError(\n            \"freq should start with DC (zero) and end with \"\n            f\"Nyquist, but got {freq[0]} for DC\"\n        )\n    freq = np.array(freq)\n    # deal with semilogx problems @ x=0\n    _check_option(\"fscale\", fscale, [\"log\", \"linear\"])\n    if fscale == \"log\":\n        freq[0] = 0.1 * freq[1] if flim is None else min(flim[0], freq[1])\n    flim = _get_flim(flim, fscale, freq)\n    transitions = list()\n    for ii in range(len(freq)):\n        if ii < len(freq) - 1 and gain[ii] != gain[ii + 1]:\n            transitions += [[freq[ii], freq[ii + 1]]]\n            my_freq += np.linspace(freq[ii], freq[ii + 1], 20, endpoint=False).tolist()\n            my_gain += np.linspace(gain[ii], gain[ii + 1], 20, endpoint=False).tolist()\n        else:\n            my_freq.append(freq[ii])\n            my_gain.append(gain[ii])\n    my_gain = 10 * np.log10(np.maximum(my_gain, 10 ** (alim[0] / 10.0)))\n    if axes is None:\n        axes = plt.subplots(1, layout=\"constrained\")[1]\n    for transition in transitions:\n        axes.axvspan(*transition, color=color, alpha=0.1)\n    axes.plot(\n        my_freq,\n        my_gain,\n        color=color,\n        linestyle=linestyle,\n        alpha=alpha,\n        linewidth=2,\n        zorder=3,\n    )\n    xticks, xticklabels = _filter_ticks(flim, fscale)\n    axes.set(ylim=alim, xlabel=\"Frequency (Hz)\", ylabel=\"Amplitude (dB)\", xscale=fscale)\n    if xticks is not None:\n        axes.set(xticks=xticks)\n        axes.set(xticklabels=xticklabels)\n    axes.set(xlim=flim)\n    if title:\n        axes.set(title=title)\n    adjust_axes(axes)\n    plt_show(show)\n    return axes.figure", "metadata": {}}
{"_id": "mne_mne_viz/misc.py_plot_csd_code", "title": "plot_csd", "text": "def plot_csd(\n    csd, info=None, mode=\"csd\", colorbar=True, cmap=None, n_cols=None, show=True\n):\n    \"\"\"Plot CSD matrices.\n\n    A sub-plot is created for each frequency. If an info object is passed to\n    the function, different channel types are plotted in different figures.\n\n    Parameters\n    ----------\n    csd : instance of CrossSpectralDensity\n        The CSD matrix to plot.\n    %(info)s\n        Used to split the figure by channel-type, if provided.\n        By default, the CSD matrix is plotted as a whole.\n    mode : 'csd' | 'coh'\n        Whether to plot the cross-spectral density ('csd', the default), or\n        the coherence ('coh') between the channels.\n    colorbar : bool\n        Whether to show a colorbar. Defaults to ``True``.\n    cmap : str | None\n        The matplotlib colormap to use. Defaults to None, which means the\n        colormap will default to matplotlib's default.\n    n_cols : int | None\n        CSD matrices are plotted in a grid. This parameter controls how\n        many matrix to plot side by side before starting a new row. By\n        default, a number will be chosen to make the grid as square as\n        possible.\n    show : bool\n        Whether to show the figure. Defaults to ``True``.\n\n    Returns\n    -------\n    fig : list of Figure\n        The figures created by this function.\n    \"\"\"\n    import matplotlib.pyplot as plt\n\n    if mode not in [\"csd\", \"coh\"]:\n        raise ValueError('\"mode\" should be either \"csd\" or \"coh\".')\n\n    if info is not None:\n        info_ch_names = info[\"ch_names\"]\n        sel_eeg = pick_types(info, meg=False, eeg=True, ref_meg=False, exclude=[])\n        sel_mag = pick_types(info, meg=\"mag\", eeg=False, ref_meg=False, exclude=[])\n        sel_grad = pick_types(info, meg=\"grad\", eeg=False, ref_meg=False, exclude=[])\n        idx_eeg = [\n            csd.ch_names.index(info_ch_names[c])\n            for c in sel_eeg\n            if info_ch_names[c] in csd.ch_names\n        ]\n        idx_mag = [\n            csd.ch_names.index(info_ch_names[c])\n            for c in sel_mag\n            if info_ch_names[c] in csd.ch_names\n        ]\n        idx_grad = [\n            csd.ch_names.index(info_ch_names[c])\n            for c in sel_grad\n            if info_ch_names[c] in csd.ch_names\n        ]\n        indices = [idx_eeg, idx_mag, idx_grad]\n        titles = [\"EEG\", \"Magnetometers\", \"Gradiometers\"]\n\n        if mode == \"csd\":\n            # The units in which to plot the CSD\n            units = dict(eeg=\"\u00b5V\u00b2\", grad=\"fT\u00b2/cm\u00b2\", mag=\"fT\u00b2\")\n            scalings = dict(eeg=1e12, grad=1e26, mag=1e30)\n    else:\n        indices = [np.arange(len(csd.ch_names))]\n        if mode == \"csd\":\n            titles = [\"Cross-spectral density\"]\n            # Units and scaling unknown\n            units = dict()\n            scalings = dict()\n        elif mode == \"coh\":\n            titles = [\"Coherence\"]\n\n    n_freqs = len(csd.frequencies)\n\n    if n_cols is None:\n        n_cols = int(np.ceil(np.sqrt(n_freqs)))\n    n_rows = int(np.ceil(n_freqs / float(n_cols)))\n\n    figs = []\n    for ind, title, ch_type in zip(indices, titles, [\"eeg\", \"mag\", \"grad\"]):\n        if len(ind) == 0:\n            continue\n\n        fig, axes = plt.subplots(\n            n_rows,\n            n_cols,\n            squeeze=False,\n            figsize=(2 * n_cols + 1, 2.2 * n_rows),\n            layout=\"constrained\",\n        )\n\n        csd_mats = []\n        for i in range(len(csd.frequencies)):\n            cm = csd.get_data(index=i)[ind][:, ind]\n            if mode == \"csd\":\n                cm = np.abs(cm) * scalings.get(ch_type, 1)\n            elif mode == \"coh\":\n                # Compute coherence from the CSD matrix\n                psd = np.diag(cm).real\n                cm = np.abs(cm) ** 2 / psd[np.newaxis, :] / psd[:, np.newaxis]\n            csd_mats.append(cm)\n\n        vmax = np.max(csd_mats)\n\n        for i, (freq, mat) in enumerate(zip(csd.frequencies, csd_mats)):\n            ax = axes[i // n_cols][i % n_cols]\n            im = ax.imshow(mat, interpolation=\"nearest\", cmap=cmap, vmin=0, vmax=vmax)\n            ax.set_xticks([])\n            ax.set_yticks([])\n            if csd._is_sum:\n                ax.set_title(f\"{np.min(freq):.1f}-{np.max(freq):.1f} Hz.\")\n            else:\n                ax.set_title(f\"{freq:.1f} Hz.\")\n\n        plt.suptitle(title)\n        if colorbar:\n            cb = plt.colorbar(im, ax=[a for ax_ in axes for a in ax_])\n            if mode == \"csd\":\n                label = \"CSD\"\n                if ch_type in units:\n                    label += f\" ({units[ch_type]})\"\n                cb.set_label(label)\n            elif mode == \"coh\":\n                cb.set_label(\"Coherence\")\n\n        figs.append(fig)\n\n    plt_show(show)\n    return figs", "metadata": {}}
{"_id": "mne_mne_viz/misc.py_plot_chpi_snr_code", "title": "plot_chpi_snr", "text": "def plot_chpi_snr(snr_dict, axes=None):\n    \"\"\"Plot time-varying SNR estimates of the HPI coils.\n\n    Parameters\n    ----------\n    snr_dict : dict\n        The dictionary returned by `~mne.chpi.compute_chpi_snr`. Must have keys\n        ``times``, ``freqs``, ``TYPE_snr``, ``TYPE_power``, and ``TYPE_resid``\n        (where ``TYPE`` can be ``mag`` or ``grad`` or both).\n    axes : None | list of matplotlib.axes.Axes\n        Figure axes in which to draw the SNR, power, and residual plots. The\n        number of axes should be 3\u00d7 the number of MEG sensor types present in\n        ``snr_dict``. If ``None`` (the default), a new\n        `~matplotlib.figure.Figure` is created with the required number of\n        axes.\n\n    Returns\n    -------\n    fig : instance of matplotlib.figure.Figure\n        A figure with subplots for SNR, power, and residual variance,\n        separately for magnetometers and/or gradiometers (depending on what is\n        present in ``snr_dict``).\n\n    Notes\n    -----\n    If you supply a list of existing `~matplotlib.axes.Axes`, then the figure\n    legend will not be drawn automatically. If you still want it, running\n    ``fig.legend(loc='right', title='cHPI frequencies')`` will recreate it.\n\n    .. versionadded:: 0.24\n    \"\"\"\n    import matplotlib.pyplot as plt\n\n    valid_keys = list(snr_dict)[2:]\n    titles = dict(snr=\"SNR\", power=\"cHPI power\", resid=\"Residual variance\")\n    full_names = dict(mag=\"magnetometers\", grad=\"gradiometers\")\n    axes_was_none = axes is None\n    if axes_was_none:\n        fig, axes = plt.subplots(len(valid_keys), 1, sharex=True, layout=\"constrained\")\n    else:\n        fig = axes[0].get_figure()\n    if len(axes) != len(valid_keys):\n        raise ValueError(\n            f\"axes must be a list of {len(valid_keys)} axes, got \"\n            f\"length {len(axes)} ({axes}).\"\n        )\n    fig.set_size_inches(10, 10)\n    legend_labels_exist = False\n    for key, ax in zip(valid_keys, axes):\n        ch_type, kind = key.split(\"_\")\n        scaling = 1 if kind == \"snr\" else DEFAULTS[\"scalings\"][ch_type]\n        plot_kwargs = dict(color=\"k\") if kind == \"resid\" else dict()\n        lines = ax.plot(snr_dict[\"times\"], snr_dict[key] * scaling**2, **plot_kwargs)\n        # the freqs should be the same for all sensor types (and for SNR and\n        # power subplots), so we only need to label the lines on one axes\n        # (otherwise we get duplicate legend entries).\n        if not legend_labels_exist:\n            for line, freq in zip(lines, snr_dict[\"freqs\"]):\n                line.set_label(f\"{freq} Hz\")\n            legend_labels_exist = True\n        unit = DEFAULTS[\"units\"][ch_type]\n        unit = f\"({unit})\" if \"/\" in unit else unit\n        set_kwargs = dict(\n            title=f\"{titles[kind]}, {full_names[ch_type]}\",\n            ylabel=\"dB\" if kind == \"snr\" else f\"{unit}\u00b2\",\n        )\n        if not axes_was_none:\n            set_kwargs.update(xlabel=\"Time (s)\")\n        ax.set(**set_kwargs)\n    if axes_was_none:\n        ax.set(xlabel=\"Time (s)\")\n        fig.align_ylabels()\n        fig.legend(loc=\"right\", title=\"cHPI frequencies\")\n    return fig", "metadata": {}}
{"_id": "mne_mne_viz/topomap.py_plot_projs_topomap_code", "title": "plot_projs_topomap", "text": "def plot_projs_topomap(\n    projs,\n    info,\n    *,\n    sensors=True,\n    show_names=False,\n    contours=6,\n    outlines=\"head\",\n    sphere=None,\n    image_interp=_INTERPOLATION_DEFAULT,\n    extrapolate=_EXTRAPOLATE_DEFAULT,\n    border=_BORDER_DEFAULT,\n    res=64,\n    size=1,\n    cmap=None,\n    vlim=(None, None),\n    cnorm=None,\n    colorbar=False,\n    cbar_fmt=\"%3.1f\",\n    units=None,\n    axes=None,\n    show=True,\n):\n    \"\"\"Plot topographic maps of SSP projections.\n\n    Parameters\n    ----------\n    projs : list of Projection\n        The projections.\n    %(info_not_none)s Must be associated with the channels in the projectors.\n\n        .. versionchanged:: 0.20\n            The positional argument ``layout`` was replaced by ``info``.\n    %(sensors_topomap)s\n    %(show_names_topomap)s\n\n        .. versionadded:: 1.2\n    %(contours_topomap)s\n    %(outlines_topomap)s\n    %(sphere_topomap_auto)s\n    %(image_interp_topomap)s\n    %(extrapolate_topomap)s\n\n        .. versionadded:: 0.20\n\n        .. versionchanged:: 0.21\n\n           - The default was changed to ``'local'`` for MEG sensors.\n           - ``'local'`` was changed to use a convex hull mask\n           - ``'head'`` was changed to extrapolate out to the clipping circle.\n    %(border_topomap)s\n\n        .. versionadded:: 0.20\n    %(res_topomap)s\n    %(size_topomap)s\n    %(cmap_topomap)s\n    %(vlim_plot_topomap_proj)s\n    %(cnorm)s\n\n        .. versionadded:: 1.2\n    %(colorbar_topomap)s\n    %(cbar_fmt_topomap)s\n\n        .. versionadded:: 1.2\n    %(units_topomap)s\n\n        .. versionadded:: 1.2\n    %(axes_plot_projs_topomap)s\n    %(show)s\n\n    Returns\n    -------\n    fig : instance of matplotlib.figure.Figure\n        Figure with a topomap subplot for each projector.\n\n    Notes\n    -----\n    .. versionadded:: 0.9.0\n    \"\"\"\n    fig = _plot_projs_topomap(\n        projs,\n        info,\n        sensors=sensors,\n        show_names=show_names,\n        contours=contours,\n        outlines=outlines,\n        sphere=sphere,\n        image_interp=image_interp,\n        extrapolate=extrapolate,\n        border=border,\n        res=res,\n        size=size,\n        cmap=cmap,\n        vlim=vlim,\n        cnorm=cnorm,\n        colorbar=colorbar,\n        cbar_fmt=cbar_fmt,\n        units=units,\n        axes=axes,\n    )\n    with warnings.catch_warnings(record=True):\n        warnings.simplefilter(\"ignore\")\n    plt_show(show)\n    return fig", "metadata": {}}
{"_id": "mne_mne_viz/topomap.py_plot_topomap_code", "title": "plot_topomap", "text": "def plot_topomap(\n    data,\n    pos,\n    *,\n    ch_type=\"eeg\",\n    sensors=True,\n    names=None,\n    mask=None,\n    mask_params=None,\n    contours=6,\n    outlines=\"head\",\n    sphere=None,\n    image_interp=_INTERPOLATION_DEFAULT,\n    extrapolate=_EXTRAPOLATE_DEFAULT,\n    border=_BORDER_DEFAULT,\n    res=64,\n    size=1,\n    cmap=None,\n    vlim=(None, None),\n    cnorm=None,\n    axes=None,\n    show=True,\n    onselect=None,\n):\n    \"\"\"Plot a topographic map as image.\n\n    Parameters\n    ----------\n    data : array, shape (n_chan,)\n        The data values to plot.\n    %(pos_topomap)s\n        If an :class:`~mne.Info` object it must contain only one channel type\n        and exactly ``len(data)`` channels; the x/y coordinates will\n        be inferred from the montage in the :class:`~mne.Info` object.\n    %(ch_type_topomap)s\n\n        .. versionadded:: 0.21\n    %(sensors_topomap)s\n    %(names_topomap)s\n    %(mask_topomap)s\n    %(mask_params_topomap)s\n    %(contours_topomap)s\n    %(outlines_topomap)s\n    %(sphere_topomap_auto)s\n    %(image_interp_topomap)s\n    %(extrapolate_topomap)s\n\n        .. versionadded:: 0.18\n\n        .. versionchanged:: 0.21\n\n           - The default was changed to ``'local'`` for MEG sensors.\n           - ``'local'`` was changed to use a convex hull mask\n           - ``'head'`` was changed to extrapolate out to the clipping circle.\n    %(border_topomap)s\n\n        .. versionadded:: 0.20\n    %(res_topomap)s\n    %(size_topomap)s\n    %(cmap_topomap)s\n    %(vlim_plot_topomap)s\n\n        .. versionadded:: 1.2\n    %(cnorm)s\n\n        .. versionadded:: 0.24\n    %(axes_plot_topomap)s\n\n        .. versionchanged:: 1.2\n           If ``axes=None``, a new :class:`~matplotlib.figure.Figure` is\n           created instead of plotting into the current axes.\n    %(show)s\n    onselect : callable | None\n        A function to be called when the user selects a set of channels by\n        click-dragging (uses a matplotlib\n        :class:`~matplotlib.widgets.RectangleSelector`). If ``None``\n        interactive channel selection is disabled. Defaults to ``None``.\n\n    Returns\n    -------\n    im : matplotlib.image.AxesImage\n        The interpolated data.\n    cn : matplotlib.contour.ContourSet\n        The fieldlines.\n    \"\"\"\n    import matplotlib.pyplot as plt\n    from matplotlib.colors import Normalize\n\n    if axes is None:\n        _, axes = plt.subplots(figsize=(size, size), layout=\"constrained\")\n    sphere = _check_sphere(sphere, pos if isinstance(pos, Info) else None)\n    _validate_type(cnorm, (Normalize, None), \"cnorm\")\n    if cnorm is not None and (vlim[0] is not None or vlim[1] is not None):\n        warn(\n            f\"Provided cnorm implicitly defines vmin={cnorm.vmin} and \"\n            f\"vmax={cnorm.vmax}; ignoring additional vlim/vmin/vmax params.\"\n        )\n    return _plot_topomap(\n        data,\n        pos,\n        vmin=vlim[0],\n        vmax=vlim[1],\n        cmap=cmap,\n        sensors=sensors,\n        res=res,\n        axes=axes,\n        names=names,\n        mask=mask,\n        mask_params=mask_params,\n        outlines=outlines,\n        contours=contours,\n        image_interp=image_interp,\n        show=show,\n        onselect=onselect,\n        extrapolate=extrapolate,\n        sphere=sphere,\n        border=border,\n        ch_type=ch_type,\n        cnorm=cnorm,\n    )[:2]", "metadata": {}}
{"_id": "mne_mne_viz/topomap.py_plot_ica_components_code", "title": "plot_ica_components", "text": "def plot_ica_components(\n    ica,\n    picks=None,\n    ch_type=None,\n    *,\n    inst=None,\n    plot_std=True,\n    reject=\"auto\",\n    sensors=True,\n    show_names=False,\n    contours=6,\n    outlines=\"head\",\n    sphere=None,\n    image_interp=_INTERPOLATION_DEFAULT,\n    extrapolate=_EXTRAPOLATE_DEFAULT,\n    border=_BORDER_DEFAULT,\n    res=64,\n    size=1,\n    cmap=\"RdBu_r\",\n    vlim=(None, None),\n    cnorm=None,\n    colorbar=False,\n    cbar_fmt=\"%3.2f\",\n    axes=None,\n    title=None,\n    nrows=\"auto\",\n    ncols=\"auto\",\n    show=True,\n    image_args=None,\n    psd_args=None,\n    verbose=None,\n):\n    \"\"\"Project mixing matrix on interpolated sensor topography.\n\n    Parameters\n    ----------\n    ica : instance of mne.preprocessing.ICA\n        The ICA solution.\n    %(picks_ica)s\n    %(ch_type_topomap)s\n    inst : Raw | Epochs | None\n        To be able to see component properties after clicking on component\n        topomap you need to pass relevant data - instances of Raw or Epochs\n        (for example the data that ICA was trained on). This takes effect\n        only when running matplotlib in interactive mode.\n    plot_std : bool | float\n        Whether to plot standard deviation in ERP/ERF and spectrum plots.\n        Defaults to True, which plots one standard deviation above/below.\n        If set to float allows to control how many standard deviations are\n        plotted. For example 2.5 will plot 2.5 standard deviation above/below.\n    reject : ``'auto'`` | dict | None\n        Allows to specify rejection parameters used to drop epochs\n        (or segments if continuous signal is passed as inst).\n        If None, no rejection is applied. The default is 'auto',\n        which applies the rejection parameters used when fitting\n        the ICA object.\n    %(sensors_topomap)s\n    %(show_names_topomap)s\n    %(contours_topomap)s\n    %(outlines_topomap)s\n    %(sphere_topomap_auto)s\n    %(image_interp_topomap)s\n    %(extrapolate_topomap)s\n\n        .. versionadded:: 1.3\n    %(border_topomap)s\n\n        .. versionadded:: 1.3\n    %(res_topomap)s\n    %(size_topomap)s\n\n        .. versionadded:: 1.3\n    %(cmap_topomap)s\n    %(vlim_plot_topomap)s\n\n        .. versionadded:: 1.3\n    %(cnorm)s\n\n        .. versionadded:: 1.3\n    %(colorbar_topomap)s\n    %(cbar_fmt_topomap)s\n    axes : Axes | array of Axes | None\n        The subplot(s) to plot to. Either a single Axes or an iterable of Axes\n        if more than one subplot is needed. The number of subplots must match\n        the number of selected components. If None, new figures will be created\n        with the number of subplots per figure controlled by ``nrows`` and\n        ``ncols``.\n    title : str | None\n        The title of the generated figure. If ``None`` (default) and\n        ``axes=None``, a default title of \"ICA Components\" will be used.\n    %(nrows_ncols_ica_components)s\n\n        .. versionadded:: 1.3\n    %(show)s\n    image_args : dict | None\n        Dictionary of arguments to pass to :func:`~mne.viz.plot_epochs_image`\n        in interactive mode. Ignored if ``inst`` is not supplied. If ``None``,\n        nothing is passed. Defaults to ``None``.\n    psd_args : dict | None\n        Dictionary of arguments to pass to :meth:`~mne.Epochs.compute_psd` in\n        interactive  mode. Ignored if ``inst`` is not supplied. If ``None``,\n        nothing is passed. Defaults to ``None``.\n    %(verbose)s\n\n    Returns\n    -------\n    fig : instance of matplotlib.figure.Figure | list of matplotlib.figure.Figure\n        The figure object(s).\n\n    Notes\n    -----\n    When run in interactive mode, ``plot_ica_components`` allows to reject\n    components by clicking on their title label. The state of each component\n    is indicated by its label color (gray: rejected; black: retained). It is\n    also possible to open component properties by clicking on the component\n    topomap (this option is only available when the ``inst`` argument is\n    supplied).\n    \"\"\"  # noqa E501\n    from matplotlib.pyplot import Axes\n\n    from ..channels.layout import _merge_ch_data\n    from ..epochs import BaseEpochs\n    from ..io import BaseRaw\n\n    if ica.info is None:\n        raise RuntimeError(\n            \"The ICA's measurement info is missing. Please \"\n            \"fit the ICA or add the corresponding info object.\"\n        )\n\n    # for backward compat, nrow='auto' ncol='auto' should yield 4 rows 5 cols\n    # and create multiple figures if more than 20 components requested\n    if nrows == \"auto\" and ncols == \"auto\":\n        ncols = 5\n        max_subplots = 20\n    elif nrows == \"auto\" or ncols == \"auto\":\n        # user provided incomplete row/col spec; put all in one figure\n        max_subplots = ica.n_components_\n    else:\n        max_subplots = nrows * ncols\n\n    # handle ch_type=None\n    ch_type = _get_plot_ch_type(ica, ch_type)\n\n    figs = []\n    if picks is None:\n        cut_points = range(max_subplots, ica.n_components_, max_subplots)\n        pick_groups = np.split(range(ica.n_components_), cut_points)\n    else:\n        pick_groups = [_picks_to_idx(ica.n_components_, picks, picks_on=\"components\")]\n\n    axes = axes.flatten() if isinstance(axes, np.ndarray) else axes\n    for k, picks in enumerate(pick_groups):\n        try:  # either an iterable, 1D numpy array or others\n            _axes = axes[k * max_subplots : (k + 1) * max_subplots]\n        except TypeError:  # None or Axes\n            _axes = axes\n\n        (\n            data_picks,\n            pos,\n            merge_channels,\n            names,\n            ch_type,\n            sphere,\n            clip_origin,\n        ) = _prepare_topomap_plot(ica, ch_type, sphere=sphere)\n        cmap = _setup_cmap(cmap, n_axes=len(picks))\n        disp_names = _prepare_sensor_names(names, show_names)\n        outlines = _make_head_outlines(sphere, pos, outlines, clip_origin)\n\n        data = np.dot(\n            ica.mixing_matrix_[:, picks].T, ica.pca_components_[: ica.n_components_]\n        )\n        data = np.atleast_2d(data)\n        data = data[:, data_picks]\n\n        if title is None:\n            title = \"ICA components\"\n        user_passed_axes = _axes is not None\n        if not user_passed_axes:\n            fig, _axes, _, _ = _prepare_trellis(len(data), ncols=ncols, nrows=nrows)\n            fig.suptitle(title)\n        else:\n            _axes = [_axes] if isinstance(_axes, Axes) else _axes\n            fig = _axes[0].get_figure()\n\n        subplot_titles = list()\n        for ii, data_, ax in zip(picks, data, _axes):\n            kwargs = dict(color=\"gray\") if ii in ica.exclude else dict()\n            comp_title = ica._ica_names[ii]\n            if len(set(ica.get_channel_types())) > 1:\n                comp_title += f\" ({ch_type})\"\n            subplot_titles.append(ax.set_title(comp_title, fontsize=12, **kwargs))\n            if merge_channels:\n                data_, names_ = _merge_ch_data(data_, ch_type, copy.copy(names))\n            # \u2193\u2193\u2193 NOTE: we intentionally use the default norm=False here, so that\n            # \u2193\u2193\u2193 we get vlims that are symmetric-about-zero, even if the data for\n            # \u2193\u2193\u2193 a given component happens to be one-sided.\n            _vlim = _setup_vmin_vmax(data_, *vlim)\n            im = plot_topomap(\n                data_.flatten(),\n                pos,\n                ch_type=ch_type,\n                sensors=sensors,\n                names=disp_names,\n                contours=contours,\n                outlines=outlines,\n                sphere=sphere,\n                image_interp=image_interp,\n                extrapolate=extrapolate,\n                border=border,\n                res=res,\n                size=size,\n                cmap=cmap[0],\n                vlim=_vlim,\n                cnorm=cnorm,\n                axes=ax,\n                show=False,\n            )[0]\n\n            im.axes.set_label(ica._ica_names[ii])\n            if colorbar:\n                cbar, cax = _add_colorbar(\n                    ax,\n                    im,\n                    cmap,\n                    title=\"AU\",\n                    format_=cbar_fmt,\n                    kind=\"ica_comp_topomap\",\n                    ch_type=ch_type,\n                )\n                cbar.ax.tick_params(labelsize=12)\n                cbar.set_ticks(_vlim)\n            _hide_frame(ax)\n        del pos\n        fig.canvas.draw()\n\n        # add title selection interactivity\n        def onclick_title(event, ica=ica, titles=subplot_titles, fig=fig):\n            # check if any title was pressed\n            title_pressed = None\n            for title in titles:\n                if title.contains(event)[0]:\n                    title_pressed = title\n                    break\n            # title was pressed -> identify the IC\n            if title_pressed is not None:\n                label = title_pressed.get_text()\n                ic = int(label.split(\" \")[0][-3:])\n                # add or remove IC from exclude depending on current state\n                if ic in ica.exclude:\n                    ica.exclude.remove(ic)\n                    title_pressed.set_color(\"k\")\n                else:\n                    ica.exclude.append(ic)\n                    title_pressed.set_color(\"gray\")\n                fig.canvas.draw()\n\n        fig.canvas.mpl_connect(\"button_press_event\", onclick_title)\n\n        # add plot_properties interactivity only if inst was passed\n        if isinstance(inst, BaseRaw | BaseEpochs):\n            topomap_args = dict(\n                sensors=sensors,\n                contours=contours,\n                outlines=outlines,\n                sphere=sphere,\n                image_interp=image_interp,\n                extrapolate=extrapolate,\n                border=border,\n                res=res,\n                cmap=cmap[0],\n                vmin=vlim[0],\n                vmax=vlim[1],\n            )\n\n            def onclick_topo(event, ica=ica, inst=inst):\n                # check which component to plot\n                if event.inaxes is not None:\n                    label = event.inaxes.get_label()\n                    if label.startswith(\"ICA\"):\n                        ic = int(label.split(\" \")[0][-3:])\n                        ica.plot_properties(\n                            inst,\n                            picks=ic,\n                            show=True,\n                            plot_std=plot_std,\n                            topomap_args=topomap_args,\n                            image_args=image_args,\n                            psd_args=psd_args,\n                            reject=reject,\n                        )\n\n            fig.canvas.mpl_connect(\"button_press_event\", onclick_topo)\n        figs.append(fig)\n\n    plt_show(show)\n    return figs[0] if len(figs) == 1 else figs", "metadata": {}}
{"_id": "mne_mne_viz/topomap.py_plot_tfr_topomap_code", "title": "plot_tfr_topomap", "text": "def plot_tfr_topomap(\n    tfr,\n    tmin=None,\n    tmax=None,\n    fmin=0.0,\n    fmax=np.inf,\n    *,\n    ch_type=None,\n    baseline=None,\n    mode=\"mean\",\n    sensors=True,\n    show_names=False,\n    mask=None,\n    mask_params=None,\n    contours=6,\n    outlines=\"head\",\n    sphere=None,\n    image_interp=_INTERPOLATION_DEFAULT,\n    extrapolate=_EXTRAPOLATE_DEFAULT,\n    border=_BORDER_DEFAULT,\n    res=64,\n    size=2,\n    cmap=None,\n    vlim=(None, None),\n    cnorm=None,\n    colorbar=True,\n    cbar_fmt=\"%1.1e\",\n    units=None,\n    axes=None,\n    show=True,\n):\n    \"\"\"Plot topographic maps of specific time-frequency intervals of TFR data.\n\n    Parameters\n    ----------\n    tfr : AverageTFR\n        The AverageTFR object.\n    %(tmin_tmax_psd)s\n    %(fmin_fmax_psd)s\n    %(ch_type_topomap_psd)s\n    baseline : tuple or list of length 2\n        The time interval to apply rescaling / baseline correction. If None do\n        not apply it. If baseline is (a, b) the interval is between \"a (s)\" and\n        \"b (s)\". If a is None the beginning of the data is used and if b is\n        None then b is set to the end of the interval. If baseline is equal to\n        (None, None) the whole time interval is used.\n    mode : 'mean' | 'ratio' | 'logratio' | 'percent' | 'zscore' | 'zlogratio' | None\n        Perform baseline correction by\n\n          - subtracting the mean baseline power ('mean')\n          - dividing by the mean baseline power ('ratio')\n          - dividing by the mean baseline power and taking the log ('logratio')\n          - subtracting the mean baseline power followed by dividing by the\n            mean baseline power ('percent')\n          - subtracting the mean baseline power and dividing by the standard\n            deviation of the baseline power ('zscore')\n          - dividing by the mean baseline power, taking the log, and dividing\n            by the standard deviation of the baseline power ('zlogratio')\n\n        If None no baseline correction is applied.\n    %(sensors_topomap)s\n    %(show_names_topomap)s\n    %(mask_evoked_topomap)s\n    %(mask_params_topomap)s\n    %(contours_topomap)s\n    %(outlines_topomap)s\n    %(sphere_topomap_auto)s\n    %(image_interp_topomap)s\n    %(extrapolate_topomap)s\n\n        .. versionchanged:: 0.21\n\n           - The default was changed to ``'local'`` for MEG sensors.\n           - ``'local'`` was changed to use a convex hull mask\n           - ``'head'`` was changed to extrapolate out to the clipping circle.\n    %(border_topomap)s\n\n        .. versionadded:: 0.20\n    %(res_topomap)s\n    %(size_topomap)s\n    %(cmap_topomap)s\n    %(vlim_plot_topomap)s\n\n        .. versionadded:: 1.2\n    %(cnorm)s\n\n        .. versionadded:: 1.2\n    %(colorbar_topomap)s\n    %(cbar_fmt_topomap)s\n    %(units_topomap)s\n    %(axes_plot_topomap)s\n    %(show)s\n\n    Returns\n    -------\n    fig : matplotlib.figure.Figure\n        The figure containing the topography.\n    \"\"\"  # noqa: E501\n    import matplotlib.pyplot as plt\n\n    from ..channels.layout import _merge_ch_data\n\n    ch_type = _get_plot_ch_type(tfr, ch_type)\n\n    picks, pos, merge_channels, names, _, sphere, clip_origin = _prepare_topomap_plot(\n        tfr, ch_type, sphere=sphere\n    )\n    outlines = _make_head_outlines(sphere, pos, outlines, clip_origin)\n    data = tfr.data[picks]\n\n    # merging grads before rescaling makes ERDs visible\n    if merge_channels:\n        data, names = _merge_ch_data(data, ch_type, names, method=\"mean\")\n\n    data = rescale(data, tfr.times, baseline, mode, copy=True)\n\n    # handle unaggregated multitaper (complex or phase multitaper data)\n    if tfr.weights is not None:  # assumes a taper dimension\n        logger.info(\"Aggregating multitaper estimates before plotting...\")\n        weights = tfr.weights[np.newaxis, :, :, np.newaxis]  # add channel & time dims\n        data = weights * data\n        if np.iscomplexobj(data):  # complex coefficients \u2192 power\n            data *= data.conj()\n            data = data.real.sum(axis=1)\n            data *= 2 / (weights * weights.conj()).real.sum(axis=1)\n        else:  # tapered phase data \u2192 weighted phase data\n            data = data.mean(axis=1)\n    # handle remaining complex amplitude \u2192 real power\n    if np.iscomplexobj(data):\n        data = np.sqrt((data * data.conj()).real)\n\n    # crop time\n    itmin, itmax = None, None\n    idx = np.where(_time_mask(tfr.times, tmin, tmax))[0]\n    if tmin is not None:\n        itmin = idx[0]\n    if tmax is not None:\n        itmax = idx[-1] + 1\n    # crop freqs\n    ifmin, ifmax = None, None\n    idx = np.where(_time_mask(tfr.freqs, fmin, fmax))[0]\n    ifmin = idx[0]\n    ifmax = idx[-1] + 1\n\n    data = data[:, ifmin:ifmax, itmin:itmax]\n    data = data.mean(axis=(1, 2))[:, np.newaxis]\n    norm = False if np.min(data) < 0 else True\n    vlim = _setup_vmin_vmax(data, *vlim, norm)\n    cmap = _setup_cmap(cmap, norm=norm)\n\n    axes = (\n        plt.subplots(figsize=(size, size), layout=\"constrained\")[1]\n        if axes is None\n        else axes\n    )\n    fig = axes.figure\n\n    _hide_frame(axes)\n\n    locator = None\n    if not isinstance(contours, list | np.ndarray):\n        locator, contours = _set_contour_locator(*vlim, contours)\n\n    fig_wrapper = list()\n    selection_callback = partial(\n        _onselect,\n        tfr=tfr,\n        pos=pos,\n        ch_type=ch_type,\n        itmin=itmin,\n        itmax=itmax,\n        ifmin=ifmin,\n        ifmax=ifmax,\n        cmap=cmap[0],\n        fig=fig_wrapper,\n    )\n\n    if not isinstance(contours, list | np.ndarray):\n        _, contours = _set_contour_locator(*vlim, contours)\n\n    names = _prepare_sensor_names(names, show_names)\n\n    im, _ = plot_topomap(\n        data[:, 0],\n        pos,\n        ch_type=ch_type,\n        sensors=sensors,\n        names=names,\n        mask=mask,\n        mask_params=mask_params,\n        contours=contours,\n        outlines=outlines,\n        sphere=sphere,\n        image_interp=image_interp,\n        extrapolate=extrapolate,\n        border=border,\n        res=res,\n        size=size,\n        cmap=cmap[0],\n        vlim=vlim,\n        cnorm=cnorm,\n        axes=axes,\n        show=False,\n        onselect=selection_callback,\n    )\n\n    if colorbar:\n        from matplotlib import ticker\n\n        units = _handle_default(\"units\", units)[\"misc\"]\n        cbar, cax = _add_colorbar(\n            axes,\n            im,\n            cmap,\n            title=units,\n            format_=cbar_fmt,\n            kind=\"tfr_topomap\",\n            ch_type=ch_type,\n        )\n        if locator is None:\n            locator = ticker.MaxNLocator(nbins=5)\n        cbar.locator = locator\n        cbar.update_ticks()\n        cbar.ax.tick_params(labelsize=12)\n\n    plt_show(show)\n    return fig", "metadata": {}}
{"_id": "mne_mne_viz/topomap.py_plot_evoked_topomap_code", "title": "plot_evoked_topomap", "text": "def plot_evoked_topomap(\n    evoked,\n    times=\"auto\",\n    *,\n    average=None,\n    ch_type=None,\n    scalings=None,\n    proj=False,\n    sensors=True,\n    show_names=False,\n    mask=None,\n    mask_params=None,\n    contours=6,\n    outlines=\"head\",\n    sphere=None,\n    image_interp=_INTERPOLATION_DEFAULT,\n    extrapolate=_EXTRAPOLATE_DEFAULT,\n    border=_BORDER_DEFAULT,\n    res=64,\n    size=1,\n    cmap=None,\n    vlim=(None, None),\n    cnorm=None,\n    colorbar=True,\n    cbar_fmt=\"%3.1f\",\n    units=None,\n    axes=None,\n    time_unit=\"s\",\n    time_format=None,\n    nrows=1,\n    ncols=\"auto\",\n    show=True,\n):\n    \"\"\"Plot topographic maps of specific time points of evoked data.\n\n    Parameters\n    ----------\n    evoked : Evoked\n        The Evoked object.\n    times : float | array of float | \"auto\" | \"peaks\" | \"interactive\"\n        The time point(s) to plot. If \"auto\", the number of ``axes`` determines\n        the amount of time point(s). If ``axes`` is also None, at most 10\n        topographies will be shown with a regular time spacing between the\n        first and last time instant. If \"peaks\", finds time points\n        automatically by checking for local maxima in global field power. If\n        \"interactive\", the time can be set interactively at run-time by using a\n        slider.\n    %(average_plot_evoked_topomap)s\n    %(ch_type_topomap)s\n    %(scalings_topomap)s\n    %(proj_plot)s\n    %(sensors_topomap)s\n    %(show_names_topomap)s\n    %(mask_evoked_topomap)s\n    %(mask_params_topomap)s\n    %(contours_topomap)s\n    %(outlines_topomap)s\n    %(sphere_topomap_auto)s\n    %(image_interp_topomap)s\n    %(extrapolate_topomap)s\n\n        .. versionadded:: 0.18\n\n        .. versionchanged:: 0.21\n\n           - The default was changed to ``'local'`` for MEG sensors.\n           - ``'local'`` was changed to use a convex hull mask\n           - ``'head'`` was changed to extrapolate out to the clipping circle.\n    %(border_topomap)s\n\n        .. versionadded:: 0.20\n    %(res_topomap)s\n    %(size_topomap)s\n    %(cmap_topomap)s\n    %(vlim_plot_topomap_psd)s\n\n        .. versionadded:: 1.2\n    %(cnorm)s\n\n        .. versionadded:: 1.2\n    %(colorbar_topomap)s\n    %(cbar_fmt_topomap)s\n    %(units_topomap_evoked)s\n    %(axes_evoked_plot_topomap)s\n    time_unit : str\n        The units for the time axis, can be \"ms\" or \"s\" (default).\n\n        .. versionadded:: 0.16\n    time_format : str | None\n        String format for topomap values. Defaults (None) to \"%%01d ms\" if\n        ``time_unit='ms'``, \"%%0.3f s\" if ``time_unit='s'``, and\n        \"%%g\" otherwise. Can be an empty string to omit the time label.\n    %(nrows_ncols_topomap)s Ignored when times == 'interactive'.\n\n        .. versionadded:: 0.20\n    %(show)s\n\n    Returns\n    -------\n    fig : instance of matplotlib.figure.Figure\n       The figure.\n\n    Notes\n    -----\n    When existing ``axes`` are provided and ``colorbar=True``, note that the\n    colorbar scale will only accurately reflect topomaps that are generated in\n    the same call as the colorbar. Note also that the colorbar will not be\n    resized automatically when ``axes`` are provided; use Matplotlib's\n    :meth:`axes.set_position() <matplotlib.axes.Axes.set_position>` method or\n    :ref:`gridspec <matplotlib:arranging_axes>` interface to adjust the colorbar\n    size yourself.\n\n    The defaults for ``contours`` and ``vlim`` are handled as follows:\n\n    * When neither ``vlim`` nor a list of ``contours`` is passed, MNE sets\n      ``vlim`` at \u00b1 the maximum absolute value of the data and then chooses\n      contours within those bounds.\n\n    * When ``vlim`` but not a list of ``contours`` is passed, MNE chooses\n      contours to be within the ``vlim``.\n\n    * When a list of ``contours`` but not ``vlim`` is passed, MNE chooses\n      ``vlim`` to encompass the ``contours`` and the maximum absolute value of the\n      data.\n\n    * When both a list of ``contours`` and ``vlim`` are passed, MNE uses them\n      as-is.\n\n    When ``time==\"interactive\"``, the figure will publish and subscribe to the\n    following UI events:\n\n    * :class:`~mne.viz.ui_events.TimeChange` whenever a new time is selected.\n    \"\"\"\n    import matplotlib.pyplot as plt\n    from matplotlib.gridspec import GridSpec\n    from matplotlib.widgets import Slider\n\n    from ..channels.layout import _merge_ch_data\n    from ..evoked import Evoked\n\n    _validate_type(evoked, Evoked, \"evoked\")\n    _validate_type(colorbar, bool, \"colorbar\")\n    evoked = evoked.copy()  # make a copy, since we'll be picking\n    ch_type = _get_plot_ch_type(evoked, ch_type)\n    # time units / formatting\n    time_unit, _ = _check_time_unit(time_unit, evoked.times)\n    scaling_time = 1.0 if time_unit == \"s\" else 1e3\n    _validate_type(time_format, (None, str), \"time_format\")\n    if time_format is None:\n        time_format = \"%0.3f s\" if time_unit == \"s\" else \"%01d ms\"\n    del time_unit\n    # mask_params defaults\n    mask_params = _handle_default(\"mask_params\", mask_params)\n    mask_params[\"markersize\"] *= size / 2.0\n    mask_params[\"markeredgewidth\"] *= size / 2.0\n    # setup various parameters, and prepare outlines\n    (\n        picks,\n        pos,\n        merge_channels,\n        names,\n        ch_type,\n        sphere,\n        clip_origin,\n    ) = _prepare_topomap_plot(evoked, ch_type, sphere=sphere)\n    outlines = _make_head_outlines(sphere, pos, outlines, clip_origin)\n    # check interactive\n    axes_given = axes is not None\n    interactive = isinstance(times, str) and times == \"interactive\"\n    if interactive and axes_given:\n        raise ValueError(\"User-provided axes not allowed when times='interactive'.\")\n    # units, scalings\n    key = \"grad\" if ch_type.startswith(\"planar\") else ch_type\n    default_scaling = _handle_default(\"scalings\", None)[key]\n    scaling = _handle_default(\"scalings\", scalings)[key]\n    # if non-default scaling, fall back to \"AU\" if unit wasn't given by user\n    key = \"misc\" if scaling != default_scaling else key\n    unit = _handle_default(\"units\", units)[key]\n    # ch_names (required for NIRS)\n    ch_names = names\n    names = _prepare_sensor_names(names, show_names)\n    # apply projections before picking. NOTE: the `if proj is True`\n    # anti-pattern is needed here to exclude proj='interactive'\n    _check_option(\"proj\", proj, (True, False, \"interactive\", \"reconstruct\"))\n    if proj is True and not evoked.proj:\n        evoked.apply_proj()\n    elif proj == \"reconstruct\":\n        evoked._reconstruct_proj()\n    data = evoked.data\n\n    # remove compensation matrices (safe: only plotting & already made copy)\n    with evoked.info._unlock():\n        evoked.info[\"comps\"] = []\n    evoked = evoked._pick_drop_channels(picks, verbose=False)\n    # determine which times to plot\n    if isinstance(axes, plt.Axes):\n        axes = [axes]\n    n_peaks = len(axes) - int(colorbar) if axes_given else None\n    times = _process_times(evoked, times, n_peaks)\n    n_times = len(times)\n    space = 1 / (2.0 * evoked.info[\"sfreq\"])\n    if max(times) > max(evoked.times) + space or min(times) < min(evoked.times) - space:\n        raise ValueError(\n            f\"Times should be between {evoked.times[0]:0.3} and {evoked.times[-1]:0.3}.\"\n        )\n    # create axes\n    want_axes = n_times + int(colorbar)\n    if interactive:\n        height_ratios = [5, 1]\n        nrows = 2\n        ncols = n_times\n        width = size * want_axes\n        height = size + max(0, 0.1 * (4 - size))\n        fig = figure_nobar(figsize=(width * 1.5, height * 1.5))\n        gs = GridSpec(nrows, ncols, height_ratios=height_ratios, figure=fig)\n        axes = []\n        for ax_idx in range(n_times):\n            axes.append(plt.subplot(gs[0, ax_idx]))\n    elif axes is None:\n        fig, axes, ncols, nrows = _prepare_trellis(\n            n_times, ncols=ncols, nrows=nrows, size=size\n        )\n    else:\n        nrows, ncols = None, None  # Deactivate ncols when axes were passed\n        fig = axes[0].get_figure()\n        # check: enough space for colorbar?\n        if len(axes) != want_axes:\n            cbar_err = \" plus one for the colorbar\" if colorbar else \"\"\n            raise RuntimeError(\n                f\"You must provide {want_axes} axes (one for \"\n                f\"each time{cbar_err}), got {len(axes)}.\"\n            )\n    del want_axes\n    # find first index that's >= (to rounding error) to each time point\n    time_idx = [\n        np.where(\n            _time_mask(evoked.times, tmin=t, tmax=None, sfreq=evoked.info[\"sfreq\"])\n        )[0][0]\n        for t in times\n    ]\n    # do averaging if requested\n    avg_err = (\n        '\"average\" must be `None`, a positive number of seconds, or '\n        \"an array-like object of the previous\"\n    )\n\n    averaged_times = []\n    if average is None:\n        average = np.array([None] * n_times)\n        data = data[np.ix_(picks, time_idx)]\n    else:\n        if _is_numeric(average):\n            average = np.array([average] * n_times)\n        elif np.array(average).ndim == 0:\n            # It should be an array-like object\n            raise TypeError(f\"{avg_err}; got type: {type(average)}.\")\n        else:\n            average = np.array(average)\n\n        if len(average) != n_times:\n            raise ValueError(\n                f\"You requested to plot topographic maps for {n_times} time \"\n                f\"points, but provided {len(average)} periods for \"\n                f\"averaging. The number of time points and averaging periods \"\n                f\"must be equal.\"\n            )\n        data_ = np.zeros((len(picks), len(time_idx)))\n\n        for average_idx, (this_average, this_time, this_time_idx) in enumerate(\n            zip(average, evoked.times[time_idx], time_idx)\n        ):\n            if (_is_numeric(this_average) and this_average <= 0) or (\n                not _is_numeric(this_average) and this_average is not None\n            ):\n                if len(average) == 1:\n                    msg = f\"{avg_err}; got {this_average}\"\n                else:\n                    msg = f\"{avg_err}; got {this_average} in {average}\"\n                raise ValueError(msg)\n\n            if this_average is None:\n                data_[:, average_idx] = data[picks][:, this_time_idx]\n                averaged_times.append([this_time])\n            else:\n                tmin_ = this_time - this_average / 2\n                tmax_ = this_time + this_average / 2\n                time_mask = (tmin_ < evoked.times) & (evoked.times < tmax_)\n                data_[:, average_idx] = data[picks][:, time_mask].mean(-1)\n                averaged_times.append(evoked.times[time_mask])\n        data = data_\n\n    # apply scalings and merge channels\n    data *= scaling\n    if merge_channels:\n        # check modality\n        if any(ch[\"coil_type\"] in _opm_coils for ch in evoked.info[\"chs\"]):\n            modality = \"opm\"\n        elif ch_type in _fnirs_types:\n            modality = \"fnirs\"\n        else:\n            modality = \"other\"\n        # merge data\n        data, ch_names = _merge_ch_data(data, ch_type, ch_names, modality=modality)\n        # if ch_type in _fnirs_types:\n        if modality != \"other\":\n            merge_channels = False\n    # apply mask if requested\n    if mask is not None:\n        mask = mask.astype(bool, copy=False)\n        if ch_type == \"grad\":\n            mask_ = (\n                mask[np.ix_(picks[::2], time_idx)] | mask[np.ix_(picks[1::2], time_idx)]\n            )\n        else:  # mag, eeg, planar1, planar2\n            mask_ = mask[np.ix_(picks, time_idx)]\n    # set up colormap\n    _vlim = [\n        _setup_vmin_vmax(data[:, i], *vlim, norm=merge_channels) for i in range(n_times)\n    ]\n    _vlim = [np.min(_vlim), np.max(_vlim)]\n    cmap = _setup_cmap(cmap, n_axes=n_times, norm=_vlim[0] >= 0)\n    # set up contours\n    if not isinstance(contours, list | np.ndarray):\n        _, contours = _set_contour_locator(*_vlim, contours)\n    else:\n        if vlim[0] is None and np.any(contours < _vlim[0]):\n            _vlim[0] = contours[0]\n        if vlim[1] is None and np.any(contours > _vlim[1]):\n            _vlim[1] = contours[-1]\n\n    # prepare for main loop over times\n    kwargs = dict(\n        sensors=sensors,\n        res=res,\n        names=names,\n        cmap=cmap[0],\n        cnorm=cnorm,\n        mask_params=mask_params,\n        outlines=outlines,\n        contours=contours,\n        image_interp=image_interp,\n        show=False,\n        extrapolate=extrapolate,\n        sphere=sphere,\n        border=border,\n        ch_type=ch_type,\n    )\n    images, contours_ = [], []\n    # loop over times\n    for average_idx, (time, this_average) in enumerate(zip(times, average)):\n        tp, cn, interp = _plot_topomap(\n            data[:, average_idx],\n            pos,\n            axes=axes[average_idx],\n            mask=mask_[:, average_idx] if mask is not None else None,\n            vmin=_vlim[0],\n            vmax=_vlim[1],\n            **kwargs,\n        )\n\n        images.append(tp)\n        if cn is not None:\n            contours_.append(cn)\n        if time_format != \"\":\n            if this_average is None:\n                axes_title = time_format % (time * scaling_time)\n            else:\n                tmin_ = averaged_times[average_idx][0]\n                tmax_ = averaged_times[average_idx][-1]\n                from_time = time_format % (tmin_ * scaling_time)\n                from_time = from_time.split(\" \")[0]  # Remove unit\n                to_time = time_format % (tmax_ * scaling_time)\n                axes_title = f\"{from_time} \u2013 {to_time}\"\n                del from_time, to_time, tmin_, tmax_\n            axes[average_idx].set_title(axes_title)\n\n    if interactive:\n        # Add a slider to the figure and start publishing and subscribing to time_change\n        # events.\n        kwargs.update(vlim=_vlim)\n        axes.append(fig.add_subplot(gs[1]))\n        slider = Slider(\n            axes[-1],\n            \"Time\",\n            evoked.times[0],\n            evoked.times[-1],\n            valinit=times[0],\n            valfmt=\"%1.2fs\",\n        )\n        slider.vline.remove()  # remove initial point indicator\n        func = _merge_ch_data if merge_channels else lambda x: x\n\n        def _slider_changed(val):\n            publish(fig, TimeChange(time=val))\n\n        slider.on_changed(_slider_changed)\n        ts = np.tile(evoked.times, len(evoked.data)).reshape(evoked.data.shape)\n        axes[-1].plot(ts, evoked.data, color=\"k\")\n        axes[-1].slider = slider\n\n        subscribe(\n            fig,\n            \"time_change\",\n            partial(\n                _on_time_change,\n                fig=fig,\n                data=evoked.data,\n                times=evoked.times,\n                pos=pos,\n                scaling=scaling,\n                func=func,\n                time_format=time_format,\n                scaling_time=scaling_time,\n                slider=slider,\n                kwargs=kwargs,\n            ),\n        )\n        subscribe(\n            fig,\n            \"colormap_range\",\n            partial(_on_colormap_range, kwargs=kwargs),\n        )\n\n    if colorbar:\n        if nrows is None or ncols is None:\n            # axes were given by the user, so don't resize the colorbar\n            cax = axes[-1]\n        else:  # use the default behavior\n            cax = None\n\n        cbar = fig.colorbar(images[-1], ax=axes, cax=cax, format=cbar_fmt, shrink=0.6)\n        if unit is not None:\n            cbar.ax.set_title(unit)\n        if cn is not None:\n            cbar.set_ticks(contours)\n        cbar.ax.tick_params(labelsize=7)\n        if cmap[1]:\n            for im in images:\n                im.axes.CB = DraggableColorbar(\n                    cbar, im, kind=\"evoked_topomap\", ch_type=ch_type\n                )\n\n    if proj == \"interactive\":\n        _check_delayed_ssp(evoked)\n        params = dict(\n            evoked=evoked,\n            fig=fig,\n            projs=evoked.info[\"projs\"],\n            picks=picks,\n            images=images,\n            contours_=contours_,\n            pos=pos,\n            time_idx=time_idx,\n            res=res,\n            plot_update_proj_callback=_plot_update_evoked_topomap,\n            merge_channels=merge_channels,\n            scale=scaling,\n            axes=axes[: len(axes) - bool(interactive)],\n            contours=contours,\n            interp=interp,\n            extrapolate=extrapolate,\n        )\n        _draw_proj_checkbox(None, params)\n        # This is mostly for testing purposes, but it's also consistent with\n        # raw.plot, so maybe not a bad thing in principle either\n        from mne.viz._figure import BrowserParams\n\n        fig.mne = BrowserParams(proj_checkboxes=params[\"proj_checks\"])\n\n    plt_show(show, block=False)\n    if axes_given:\n        fig.canvas.draw()\n    return fig", "metadata": {}}
{"_id": "mne_mne_viz/topomap.py_plot_epochs_psd_topomap_code", "title": "plot_epochs_psd_topomap", "text": "def plot_epochs_psd_topomap(\n    epochs,\n    bands=None,\n    tmin=None,\n    tmax=None,\n    proj=False,\n    *,\n    bandwidth=None,\n    adaptive=False,\n    low_bias=True,\n    normalization=\"length\",\n    ch_type=None,\n    normalize=False,\n    agg_fun=None,\n    dB=False,\n    sensors=True,\n    names=None,\n    mask=None,\n    mask_params=None,\n    contours=0,\n    outlines=\"head\",\n    sphere=None,\n    image_interp=_INTERPOLATION_DEFAULT,\n    extrapolate=_EXTRAPOLATE_DEFAULT,\n    border=_BORDER_DEFAULT,\n    res=64,\n    size=1,\n    cmap=None,\n    vlim=(None, None),\n    cnorm=None,\n    colorbar=True,\n    cbar_fmt=\"auto\",\n    units=None,\n    axes=None,\n    show=True,\n    n_jobs=None,\n    verbose=None,\n):\n    \"\"\"Plot the topomap of the power spectral density across epochs.\n\n    Parameters\n    ----------\n    epochs : instance of Epochs\n        The epochs object.\n    %(bands_psd_topo)s\n    %(tmin_tmax_psd)s\n    %(proj_psd)s\n    bandwidth : float\n        The bandwidth of the multi taper windowing function in Hz. The default\n        value is a window half-bandwidth of 4 Hz.\n    adaptive : bool\n        Use adaptive weights to combine the tapered spectra into PSD\n        (slow, use n_jobs >> 1 to speed up computation).\n    low_bias : bool\n        Only use tapers with more than 90%% spectral concentration within\n        bandwidth.\n    %(normalization)s\n    %(ch_type_topomap_psd)s\n    %(normalize_psd_topo)s\n    %(agg_fun_psd_topo)s\n    %(dB_plot_topomap)s\n    %(sensors_topomap)s\n    %(names_topomap)s\n    %(mask_evoked_topomap)s\n    %(mask_params_topomap)s\n    %(contours_topomap)s\n    %(outlines_topomap)s\n    %(sphere_topomap_auto)s\n    %(image_interp_topomap)s\n    %(extrapolate_topomap)s\n\n        .. versionchanged:: 0.21\n\n           - The default was changed to ``'local'`` for MEG sensors.\n           - ``'local'`` was changed to use a convex hull mask\n           - ``'head'`` was changed to extrapolate out to the clipping circle.\n    %(border_topomap)s\n\n        .. versionadded:: 0.20\n    %(res_topomap)s\n    %(size_topomap)s\n    %(cmap_topomap)s\n    %(vlim_plot_topomap_psd)s\n\n        .. versionadded:: 0.21\n    %(cnorm)s\n\n        .. versionadded:: 1.2\n    %(colorbar_topomap)s\n    %(cbar_fmt_topomap_psd)s\n    %(units_topomap)s\n    %(axes_spectrum_plot_topomap)s\n    %(show)s\n    %(n_jobs)s\n    %(verbose)s\n\n    Returns\n    -------\n    fig : instance of Figure\n        Figure showing one scalp topography per frequency band.\n    \"\"\"\n    from ..channels import rename_channels\n    from ..time_frequency import Spectrum\n\n    init_kw, plot_kw = _split_psd_kwargs(plot_fun=Spectrum.plot_topomap)\n    spectrum = epochs.compute_psd(**init_kw)\n    plot_kw.setdefault(\"show_names\", False)\n    if names is not None:\n        rename_channels(\n            spectrum.info, dict(zip(spectrum.ch_names, names)), verbose=verbose\n        )\n        plot_kw[\"show_names\"] = True\n    return spectrum.plot_topomap(**plot_kw)", "metadata": {}}
{"_id": "mne_mne_viz/topomap.py_plot_psds_topomap_code", "title": "plot_psds_topomap", "text": "def plot_psds_topomap(\n    psds,\n    freqs,\n    pos,\n    *,\n    bands=None,\n    ch_type=\"eeg\",\n    normalize=False,\n    agg_fun=None,\n    dB=True,\n    sensors=True,\n    names=None,\n    mask=None,\n    mask_params=None,\n    contours=0,\n    outlines=\"head\",\n    sphere=None,\n    image_interp=_INTERPOLATION_DEFAULT,\n    extrapolate=_EXTRAPOLATE_DEFAULT,\n    border=_BORDER_DEFAULT,\n    res=64,\n    size=1,\n    cmap=None,\n    vlim=(None, None),\n    cnorm=None,\n    colorbar=True,\n    cbar_fmt=\"auto\",\n    unit=None,\n    axes=None,\n    show=True,\n):\n    \"\"\"Plot spatial maps of PSDs.\n\n    Parameters\n    ----------\n    psds : array of float, shape (n_channels, n_freqs)\n        Power spectral densities.\n    freqs : array of float, shape (n_freqs,)\n        Frequencies used to compute psds.\n    %(pos_topomap_psd)s\n    %(bands_psd_topo)s\n    %(ch_type_topomap)s\n    %(normalize_psd_topo)s\n    %(agg_fun_psd_topo)s\n    %(dB_plot_topomap)s\n    %(sensors_topomap)s\n    %(names_topomap)s\n    %(mask_evoked_topomap)s\n    %(mask_params_topomap)s\n    %(contours_topomap)s\n    %(outlines_topomap)s\n    %(sphere_topomap_auto)s\n    %(image_interp_topomap)s\n    %(extrapolate_topomap)s\n\n        .. versionchanged:: 0.21\n\n           - The default was changed to ``'local'`` for MEG sensors.\n           - ``'local'`` was changed to use a convex hull mask\n           - ``'head'`` was changed to extrapolate out to the clipping circle.\n    %(border_topomap)s\n\n        .. versionadded:: 0.20\n    %(res_topomap)s\n    %(size_topomap)s\n    %(cmap_topomap)s\n    %(vlim_plot_topomap_psd)s\n\n        .. versionadded:: 0.21\n    %(cnorm)s\n\n        .. versionadded:: 1.2\n    %(colorbar_topomap)s\n    %(cbar_fmt_topomap_psd)s\n    unit : str | None\n        Measurement unit to be displayed with the colorbar. If ``None``, no\n        unit is displayed (only \"power\" or \"dB\" as appropriate).\n    %(axes_spectrum_plot_topomap)s\n    %(show)s\n\n    Returns\n    -------\n    fig : instance of matplotlib.figure.Figure\n        Figure with a topomap subplot for each band.\n    \"\"\"\n    import matplotlib.pyplot as plt\n    from matplotlib.axes import Axes\n\n    # handle some defaults\n    sphere = _check_sphere(sphere)\n    if cbar_fmt == \"auto\":\n        cbar_fmt = \"%0.1f\" if dB else \"%0.3f\"\n    # make sure `bands` is a dict\n    if bands is None:\n        bands = {\n            \"Delta (0-4 Hz)\": (0, 4),\n            \"Theta (4-8 Hz)\": (4, 8),\n            \"Alpha (8-12 Hz)\": (8, 12),\n            \"Beta (12-30 Hz)\": (12, 30),\n            \"Gamma (30-45 Hz)\": (30, 45),\n        }\n    elif not hasattr(bands, \"keys\"):\n        # convert legacy list-of-tuple input to a dict\n        bands = {band[-1]: band[:-1] for band in bands}\n        logger.info(\n            \"converting legacy list-of-tuples input to a dict for the `bands` parameter\"\n        )\n    # upconvert single freqs to band upper/lower edges as needed\n    bin_spacing = np.diff(freqs)[0]\n    bin_edges = np.array([0, bin_spacing]) - bin_spacing / 2\n    for band, _edges in bands.items():\n        if not hasattr(_edges, \"__len__\"):\n            _edges = (_edges,)\n        if len(_edges) == 1:\n            bands[band] = tuple(bin_edges + freqs[np.argmin(np.abs(freqs - _edges[0]))])\n    # normalize data (if requested)\n    if normalize:\n        psds /= psds.sum(axis=-1, keepdims=True)\n        assert np.allclose(psds.sum(axis=-1), 1.0)\n    # aggregate within bands\n    if agg_fun is None:\n        agg_fun = np.sum if normalize else np.mean\n    freq_masks = list()\n    for band, (fmin, fmax) in bands.items():\n        _mask = (fmin < freqs) & (freqs < fmax)\n        # make sure no bands are empty\n        if _mask.sum() == 0:\n            raise RuntimeError(f'No frequencies in band \"{band}\" ({fmin}, {fmax})')\n        freq_masks.append(_mask)\n    band_data = [agg_fun(psds[:, _mask], axis=1) for _mask in freq_masks]\n    if dB and not normalize:\n        band_data = [10 * np.log10(_d) for _d in band_data]\n    # handle vmin/vmax\n    joint_vlim = vlim == \"joint\"\n    if joint_vlim:\n        vlim = (np.array(band_data).min(), np.array(band_data).max())\n    # unit label\n    if unit is None:\n        unit = \"dB\" if dB and not normalize else \"power\"\n    else:\n        _dB = dB and not normalize\n        unit = _format_units_psd(unit, dB=_dB)\n    # set up figure / axes\n    n_axes = len(bands)\n    user_passed_axes = axes is not None\n    if user_passed_axes:\n        if isinstance(axes, Axes):\n            axes = [axes]\n        _validate_if_list_of_axes(axes, n_axes)\n        fig = axes[0].figure\n    else:\n        fig, axes = plt.subplots(\n            1, n_axes, figsize=(2 * n_axes, 1.5), layout=\"constrained\"\n        )\n        if n_axes == 1:\n            axes = [axes]\n    # loop over subplots/frequency bands\n    for ax, _mask, _data, (title, (fmin, fmax)) in zip(\n        axes, freq_masks, band_data, bands.items()\n    ):\n        plot_colorbar = False if not colorbar else (not joint_vlim) or ax == axes[-1]\n        _plot_topomap_multi_cbar(\n            _data,\n            pos,\n            ax,\n            title=title,\n            vlim=vlim,\n            cmap=cmap,\n            outlines=outlines,\n            colorbar=plot_colorbar,\n            unit=unit,\n            cbar_fmt=cbar_fmt,\n            sphere=sphere,\n            ch_type=ch_type,\n            sensors=sensors,\n            names=names,\n            mask=mask,\n            mask_params=mask_params,\n            contours=contours,\n            image_interp=image_interp,\n            extrapolate=extrapolate,\n            border=border,\n            res=res,\n            size=size,\n            cnorm=cnorm,\n        )\n\n    if not user_passed_axes:\n        fig.canvas.draw()\n        plt_show(show)\n    return fig", "metadata": {}}
{"_id": "mne_mne_viz/topomap.py_plot_layout_code", "title": "plot_layout", "text": "def plot_layout(layout, picks=None, show_axes=False, show=True):\n    \"\"\"Plot the sensor positions.\n\n    Parameters\n    ----------\n    layout : None | Layout\n        Layout instance specifying sensor positions.\n    %(picks_layout)s\n    show_axes : bool\n            Show layout axes if True. Defaults to False.\n    show : bool\n        Show figure if True. Defaults to True.\n\n    Returns\n    -------\n    fig : instance of Figure\n        Figure containing the sensor topography.\n\n    Notes\n    -----\n    .. versionadded:: 0.12.0\n    \"\"\"\n    import matplotlib.pyplot as plt\n\n    fig = plt.figure(\n        figsize=(max(plt.rcParams[\"figure.figsize\"]),) * 2, layout=\"constrained\"\n    )\n    ax = fig.add_subplot(111)\n    ax.set(xticks=[], yticks=[], aspect=\"equal\")\n    outlines = dict(border=([0, 1, 1, 0, 0], [0, 0, 1, 1, 0]))\n    _draw_outlines(ax, outlines)\n    layout = layout.copy().pick(picks)\n    for ii, (p, ch_id) in enumerate(zip(layout.pos, layout.names)):\n        center_pos = np.array((p[0] + p[2] / 2.0, p[1] + p[3] / 2.0))\n        ax.annotate(\n            ch_id,\n            xy=center_pos,\n            horizontalalignment=\"center\",\n            verticalalignment=\"center\",\n            size=\"x-small\",\n        )\n        if show_axes:\n            x1, x2, y1, y2 = p[0], p[0] + p[2], p[1], p[1] + p[3]\n            ax.plot([x1, x1, x2, x2, x1], [y1, y2, y2, y1, y1], color=\"k\")\n    ax.axis(\"off\")\n    plt_show(show)\n    return fig", "metadata": {}}
{"_id": "mne_mne_viz/topomap.py_plot_arrowmap_code", "title": "plot_arrowmap", "text": "def plot_arrowmap(\n    data,\n    info_from,\n    info_to=None,\n    scale=3e-10,\n    vlim=(None, None),\n    cnorm=None,\n    cmap=None,\n    sensors=True,\n    res=64,\n    axes=None,\n    show_names=False,\n    mask=None,\n    mask_params=None,\n    outlines=\"head\",\n    contours=6,\n    image_interp=_INTERPOLATION_DEFAULT,\n    show=True,\n    onselect=None,\n    extrapolate=_EXTRAPOLATE_DEFAULT,\n    sphere=None,\n):\n    \"\"\"Plot arrow map.\n\n    Compute arrowmaps, based upon the Hosaka-Cohen transformation\n    :footcite:`CohenHosaka1976`, these arrows represents an estimation of the\n    current flow underneath the MEG sensors. They are a poor man's MNE.\n\n    Since planar gradiometers takes gradients along latitude and longitude,\n    they need to be projected to the flattened manifold span by magnetometer\n    or radial gradiometers before taking the gradients in the 2D Cartesian\n    coordinate system for visualization on the 2D topoplot. You can use the\n    ``info_from`` and ``info_to`` parameters to interpolate from\n    gradiometer data to magnetometer data.\n\n    Parameters\n    ----------\n    data : array, shape (n_channels,)\n        The data values to plot.\n    info_from : instance of Info\n        The measurement info from data to interpolate from.\n    info_to : instance of Info | None\n        The measurement info to interpolate to. If None, it is assumed\n        to be the same as info_from.\n    scale : float, default 3e-10\n        To scale the arrows.\n    %(vlim_plot_topomap)s\n\n        .. versionadded:: 1.2\n    %(cnorm)s\n\n        .. versionadded:: 1.2\n    %(cmap_topomap_simple)s\n    %(sensors_topomap)s\n    %(res_topomap)s\n    %(axes_plot_topomap)s\n    %(show_names_topomap)s\n        If ``True``, a list of names must be provided (see ``names`` keyword).\n    %(mask_topomap)s\n    %(mask_params_topomap)s\n    %(outlines_topomap)s\n    %(contours_topomap)s\n    %(image_interp_topomap)s\n    %(show)s\n    onselect : callable | None\n        Handle for a function that is called when the user selects a set of\n        channels by rectangle selection (matplotlib ``RectangleSelector``). If\n        None interactive selection is disabled. Defaults to None.\n    %(extrapolate_topomap)s\n\n        .. versionadded:: 0.18\n\n        .. versionchanged:: 0.21\n\n           - The default was changed to ``'local'`` for MEG sensors.\n           - ``'local'`` was changed to use a convex hull mask\n           - ``'head'`` was changed to extrapolate out to the clipping circle.\n    %(sphere_topomap_auto)s\n\n    Returns\n    -------\n    fig : matplotlib.figure.Figure\n        The Figure of the plot.\n\n    Notes\n    -----\n    .. versionadded:: 0.17\n\n    References\n    ----------\n    .. footbibliography::\n    \"\"\"\n    from matplotlib import pyplot as plt\n\n    from ..forward import _map_meg_or_eeg_channels\n\n    sphere = _check_sphere(sphere, info_from)\n    ch_type = _picks_by_type(info_from)\n\n    if len(ch_type) > 1:\n        raise ValueError(\n            \"Multiple channel types are not supported.\"\n            \"All channels must either be of type 'grad' \"\n            \"or 'mag'.\"\n        )\n    else:\n        ch_type = ch_type[0][0]\n\n    if ch_type not in (\"mag\", \"grad\"):\n        raise ValueError(\n            f\"Channel type '{ch_type}' not supported. Supported channel \"\n            \"types are 'mag' and 'grad'.\"\n        )\n\n    if info_to is None and ch_type == \"mag\":\n        info_to = info_from\n    else:\n        ch_type = _picks_by_type(info_to)\n        if len(ch_type) > 1:\n            raise ValueError(\"Multiple channel types are not supported.\")\n        else:\n            ch_type = ch_type[0][0]\n\n        if ch_type != \"mag\":\n            raise ValueError(f\"only 'mag' channel type is supported. Got {ch_type}\")\n\n    if info_to is not info_from:\n        info_to = pick_info(info_to, pick_types(info_to, meg=True))\n        info_from = pick_info(info_from, pick_types(info_from, meg=True))\n        # XXX should probably support the \"origin\" argument\n        mapping = _map_meg_or_eeg_channels(\n            info_from, info_to, origin=(0.0, 0.0, 0.04), mode=\"accurate\"\n        )\n        data = np.dot(mapping, data)\n\n    _, pos, _, _, _, sphere, clip_origin = _prepare_topomap_plot(\n        info_to, \"mag\", sphere=sphere\n    )\n    outlines = _make_head_outlines(sphere, pos, outlines, clip_origin)\n    if axes is None:\n        fig, axes = plt.subplots(layout=\"constrained\")\n    else:\n        fig = axes.figure\n    plot_topomap(\n        data,\n        pos,\n        axes=axes,\n        vlim=vlim,\n        cmap=cmap,\n        cnorm=cnorm,\n        sensors=sensors,\n        res=res,\n        mask=mask,\n        mask_params=mask_params,\n        outlines=outlines,\n        contours=contours,\n        image_interp=image_interp,\n        show=False,\n        onselect=onselect,\n        extrapolate=extrapolate,\n        sphere=sphere,\n        ch_type=ch_type,\n    )\n    x, y = tuple(pos.T)\n    dx, dy = _trigradient(x, y, data)\n    dxx = dy.data\n    dyy = -dx.data\n    axes.quiver(x, y, dxx, dyy, scale=scale, color=\"k\", lw=1)\n    plt_show(show)\n\n    return fig", "metadata": {}}
{"_id": "mne_mne_viz/topomap.py_plot_bridged_electrodes_code", "title": "plot_bridged_electrodes", "text": "def plot_bridged_electrodes(\n    info, bridged_idx, ed_matrix, title=None, topomap_args=None\n):\n    \"\"\"Topoplot electrode distance matrix with bridged electrodes connected.\n\n    Parameters\n    ----------\n    %(info_not_none)s\n    bridged_idx : list of tuple\n        The indices of channels marked as bridged with each bridged\n        pair stored as a tuple.\n        Can be generated via\n        :func:`mne.preprocessing.compute_bridged_electrodes`.\n    ed_matrix : array of float, shape (n_channels, n_channels)\n        The electrical distance matrix for each pair of EEG electrodes.\n        Can be generated via\n        :func:`mne.preprocessing.compute_bridged_electrodes`.\n    title : str\n        A title to add to the plot.\n    topomap_args : dict | None\n        Arguments to pass to :func:`mne.viz.plot_topomap`.\n\n    Returns\n    -------\n    fig : instance of matplotlib.figure.Figure\n        The topoplot figure handle.\n\n    See Also\n    --------\n    mne.preprocessing.compute_bridged_electrodes\n    \"\"\"\n    import matplotlib.pyplot as plt\n\n    from ..channels.layout import _find_topomap_coords\n\n    if topomap_args is None:\n        topomap_args = dict()\n    else:\n        topomap_args = topomap_args.copy()  # don't change original\n    picks = pick_types(info, eeg=True)\n    topomap_args.setdefault(\"image_interp\", \"nearest\")\n    topomap_args.setdefault(\"cmap\", \"summer_r\")\n    topomap_args.setdefault(\"names\", pick_info(info, picks).ch_names)\n    topomap_args.setdefault(\"contours\", False)\n    sphere = topomap_args.get(\"sphere\", _check_sphere(None))\n    if \"axes\" not in topomap_args:\n        fig, ax = plt.subplots(layout=\"constrained\")\n        topomap_args[\"axes\"] = ax\n    else:\n        fig = None\n    # handle colorbar here instead of in plot_topomap\n    colorbar = topomap_args.pop(\"colorbar\", True)\n    if ed_matrix.shape[1:] != (picks.size, picks.size):\n        raise RuntimeError(\n            f\"Expected {(ed_matrix.shape[0], picks.size, picks.size)} \"\n            f\"shaped `ed_matrix`, got {ed_matrix.shape}\"\n        )\n    # fill in lower triangular\n    ed_matrix = ed_matrix.copy()\n    tril_idx = np.tril_indices(picks.size)\n    for epo_idx in range(ed_matrix.shape[0]):\n        ed_matrix[epo_idx][tril_idx] = ed_matrix[epo_idx].T[tril_idx]\n    elec_dists = np.median(np.nanmin(ed_matrix, axis=1), axis=0)\n\n    im, cn = plot_topomap(elec_dists, pick_info(info, picks), **topomap_args)\n    fig = im.figure if fig is None else fig\n    # add bridged connections\n    for idx0, idx1 in bridged_idx:\n        pos = _find_topomap_coords(info, [idx0, idx1], sphere=sphere)\n        im.axes.plot([pos[0, 0], pos[1, 0]], [pos[0, 1], pos[1, 1]], color=\"r\")\n    if title is not None:\n        im.axes.set_title(title)\n    if colorbar:\n        cax = fig.colorbar(im, shrink=0.6)\n        cax.set_label(r\"Electrical Distance ($\\mu$$V^2$)\")\n    return fig", "metadata": {}}
{"_id": "mne_mne_viz/topomap.py_plot_ch_adjacency_code", "title": "plot_ch_adjacency", "text": "def plot_ch_adjacency(info, adjacency, ch_names, kind=\"2d\", edit=False):\n    \"\"\"Plot channel adjacency.\n\n    Parameters\n    ----------\n    info : instance of Info\n        Info object with channel locations.\n    adjacency : array\n        Array of channels x channels shape. Defines which channels are adjacent\n        to each other. Note that if you edit adjacencies\n        (via ``edit=True``), this array will be modified in place.\n    ch_names : list of str\n        Names of successive channels in the ``adjacency`` matrix.\n    kind : str\n        How to plot the adjacency. Can be either ``'3d'`` or ``'2d'``.\n    edit : bool\n        Whether to allow interactive editing of the adjacency matrix via\n        clicking respective channel pairs. Once clicked, the channel is\n        \"activated\" and turns green. Clicking on another channel adds or\n        removes adjacency relation between the activated and newly clicked\n        channel (depending on whether the channels are already adjacent or\n        not); the newly clicked channel now becomes activated. Clicking on\n        an activated channel deactivates it. Editing is currently only\n        supported for ``kind='2d'``.\n\n    Returns\n    -------\n    fig : Figure\n        The :class:`~matplotlib.figure.Figure` instance where the channel\n        adjacency is plotted.\n\n    See Also\n    --------\n    mne.channels.get_builtin_ch_adjacencies\n    mne.channels.read_ch_adjacency\n    mne.channels.find_ch_adjacency\n\n    Notes\n    -----\n    .. versionadded:: 1.1\n    \"\"\"\n    import matplotlib as mpl\n    import matplotlib.pyplot as plt\n\n    _validate_type(info, Info, \"info\")\n    _validate_type(adjacency, (np.ndarray, csr_array), \"adjacency\")\n    has_sparse = isinstance(adjacency, csr_array)\n\n    if edit and kind == \"3d\":\n        raise ValueError(\"Editing a 3d adjacency plot is not supported.\")\n\n    # select relevant channels\n    sel = pick_channels(info.ch_names, ch_names, ordered=True)\n    info = pick_info(info, sel)\n\n    # make sure adjacency is correct size wrt to inst:\n    n_channels = len(info.ch_names)\n    if adjacency.shape[0] != n_channels:\n        raise ValueError(\n            \"``adjacency`` must have the same number of rows \"\n            \"as the number of channels in ``info``. Found \"\n            f\"{adjacency.shape[0]} channels for ``adjacency`` and\"\n            f\" {n_channels} for ``inst``.\"\n        )\n\n    if kind == \"3d\":\n        with plt.rc_context({\"toolbar\": \"None\"}):\n            fig = plot_sensors(info, kind=kind, show=False)\n        _set_3d_axes_equal(fig.axes[0])\n    elif kind == \"2d\":\n        with plt.rc_context({\"toolbar\": \"None\"}):\n            fig = plot_sensors(info, kind=\"topomap\", show=False)\n        fig.axes[0].axis(\"equal\")\n\n    path_collection = fig.axes[0].findobj(mpl.collections.PathCollection)\n    path_collection[0].set_linewidths(0.0)\n\n    if kind == \"2d\":\n        path_collection[0].set_alpha(0.7)\n        pos = path_collection[0].get_offsets()\n\n        # make sure nodes are on top\n        path_collection[0].set_zorder(10)\n\n        # scale node size with number of connections\n        n_connections = [np.sum(adjacency[[i]]) - 1 for i in range(adjacency.shape[0])]\n        node_size = [max(x, 3) ** 2.5 for x in n_connections]\n        path_collection[0].set_sizes(node_size)\n    else:\n        # plotting channel positions via mne.viz.plot_sensors(info) and using\n        # the coordinates from info['chs'][ch_idx]['loc][:3] gives different\n        # positions. Also .get_offsets gives 2d projections even for 3d points\n        # so we use the private _offsets3d property...\n        pos = path_collection[0]._offsets3d\n        pos = np.stack([pos[0].data, pos[1].data, pos[2]], axis=1)\n\n    ax = fig.axes[0]\n    lines = dict()\n    n_channels = adjacency.shape[0]\n    for ch_idx in range(n_channels):\n        # make sure we don't repeat channels\n        row = adjacency[[ch_idx], ch_idx + 1 :]\n        if has_sparse:\n            ch_neighbours = row.nonzero()[1]\n        else:\n            ch_neighbours = np.where(row)[0]\n\n        if len(ch_neighbours) == 0:\n            continue\n\n        ch_neighbours += ch_idx + 1\n\n        for ngb_idx in ch_neighbours:\n            this_pos = pos[[ch_idx, ngb_idx], :]\n            ch_pair = tuple([ch_idx, ngb_idx])\n            lines[ch_pair] = ax.plot(*this_pos.T, color=(0.55, 0.55, 0.55), lw=0.75)[0]\n\n    if edit:\n        # allow interactivity in 2d plots\n        highlighted = dict()\n        this_onpick = partial(\n            _onpick_ch_adjacency,\n            axes=ax,\n            positions=pos,\n            highlighted=highlighted,\n            line_dict=lines,\n            adjacency=adjacency,\n            node_size=node_size,\n            path_collection=path_collection,\n        )\n        fig.canvas.mpl_connect(\"pick_event\", this_onpick)\n\n    return fig", "metadata": {}}
{"_id": "mne_mne_viz/topomap.py_plot_regression_weights_code", "title": "plot_regression_weights", "text": "def plot_regression_weights(\n    model,\n    *,\n    ch_type=None,\n    sensors=True,\n    show_names=False,\n    mask=None,\n    mask_params=None,\n    contours=6,\n    outlines=\"head\",\n    sphere=None,\n    image_interp=_INTERPOLATION_DEFAULT,\n    extrapolate=_EXTRAPOLATE_DEFAULT,\n    border=_BORDER_DEFAULT,\n    res=64,\n    size=1,\n    cmap=None,\n    vlim=(None, None),\n    cnorm=None,\n    axes=None,\n    colorbar=True,\n    cbar_fmt=\"%1.1e\",\n    title=None,\n    show=True,\n):\n    \"\"\"Plot the regression weights of a fitted EOGRegression model.\n\n    Parameters\n    ----------\n    model : EOGRegression\n        The fitted EOGRegression model whose weights will be plotted.\n    %(ch_type_topomap)s\n    %(sensors_topomap)s\n    %(show_names_topomap)s\n    %(mask_topomap)s\n    %(mask_params_topomap)s\n    %(contours_topomap)s\n    %(outlines_topomap)s\n    %(sphere_topomap_auto)s\n    %(image_interp_topomap)s\n    %(extrapolate_topomap)s\n\n        .. versionchanged:: 0.21\n\n           - The default was changed to ``'local'`` for MEG sensors.\n           - ``'local'`` was changed to use a convex hull mask\n           - ``'head'`` was changed to extrapolate out to the clipping circle.\n    %(border_topomap)s\n\n        .. versionadded:: 0.20\n    %(res_topomap)s\n    %(size_topomap)s\n    %(cmap_topomap)s\n    %(vlim_plot_topomap)s\n    %(cnorm)s\n    %(axes_evoked_plot_topomap)s\n    %(colorbar_topomap)s\n    %(cbar_fmt_topomap)s\n    %(title_none)s\n    %(show)s\n\n    Returns\n    -------\n    fig : instance of matplotlib.figure.Figure\n        Figure with a topomap subplot for each channel type.\n\n    Notes\n    -----\n    .. versionadded:: 1.2\n    \"\"\"\n    import matplotlib\n    import matplotlib.pyplot as plt\n\n    from ..channels.layout import _merge_ch_data\n\n    sphere = _check_sphere(sphere)\n    if ch_type is None:\n        ch_types = model.info_.get_channel_types(unique=True, only_data_chs=True)\n    else:\n        ch_types = [ch_type]\n    del ch_type\n\n    nrows = model.coef_.shape[1]\n    ncols = len(ch_types)\n\n    axes_was_none = axes is None\n    if axes_was_none:\n        fig, axes = plt.subplots(\n            nrows,\n            ncols,\n            squeeze=False,\n            figsize=(ncols * 2, nrows * 1.5 + 1),\n            layout=\"constrained\",\n        )\n        axes = axes.T.ravel()\n    else:\n        if isinstance(axes, matplotlib.axes.Axes):\n            axes = [axes]\n        fig = axes[0].get_figure()\n    if len(axes) != nrows * ncols:\n        raise ValueError(\n            f\"axes must be a list of {nrows * ncols} axes, got \"\n            f\"length {len(axes)} ({axes}).\"\n        )\n    axes = iter(axes)\n\n    data_picks = _picks_to_idx(model.info_, model.picks, exclude=model.exclude)\n    data_info = pick_info(model.info_, data_picks)\n    artifact_ch_names = [\n        model.info_[\"chs\"][idx][\"ch_name\"]\n        for idx in _picks_to_idx(model.info_, model.picks_artifact)\n    ]\n\n    for ch_type in ch_types:\n        (\n            data_picks,\n            pos,\n            merge_channels,\n            names,\n            ch_type,\n            sphere,\n            clip_origin,\n        ) = _prepare_topomap_plot(data_info, ch_type=ch_type, sphere=sphere)\n        outlines = _make_head_outlines(\n            sphere, pos, outlines=outlines, clip_origin=clip_origin\n        )\n        coef = model.coef_[data_picks]\n        for data, ch_name in zip(coef.T, artifact_ch_names):\n            if merge_channels:\n                data, names = _merge_ch_data(data, ch_type, names)\n            ax = next(axes)\n            names = _prepare_sensor_names(data_info.ch_names, show_names)\n\n            _plot_topomap_multi_cbar(\n                data,\n                pos,\n                ax,\n                title=f\"{ch_type}/{ch_name}\",\n                vlim=vlim,\n                cmap=cmap,\n                outlines=outlines,\n                colorbar=colorbar,\n                unit=\"\",\n                cbar_fmt=cbar_fmt,\n                sphere=sphere,\n                ch_type=ch_type,\n                sensors=sensors,\n                names=names,\n                mask=mask,\n                mask_params=mask_params,\n                contours=contours,\n                image_interp=image_interp,\n                extrapolate=extrapolate,\n                border=border,\n                res=res,\n                size=size,\n                cnorm=cnorm,\n            )\n    if axes_was_none:\n        fig.suptitle(title)\n    plt_show(show)\n    return fig", "metadata": {}}
{"_id": "mne_mne_viz/topomap.py_set_values_code", "title": "set_values", "text": "def set_values(self, v):\n        \"\"\"Set the values at interpolation points.\"\"\"\n        # Rbf with thin-plate is what we used to use, but it's slower and\n        # looks about the same:\n        #\n        #     zi = Rbf(x, y, v, function='multiquadric', smooth=0)(xi, yi)\n        #\n        # Eventually we could also do set_values with this class if we want,\n        # see scipy/interpolate/rbf.py, especially the self.nodes one-liner.\n        if isinstance(self.border, str):\n            # we've already checked that border = 'mean'\n            n_points = v.shape[0]\n            v_extra = np.zeros(self.n_extra)\n            indices, indptr = self.tri.vertex_neighbor_vertices\n            rng = range(n_points, n_points + self.n_extra)\n            used = np.zeros(len(rng), bool)\n            for idx, extra_idx in enumerate(rng):\n                ngb = indptr[indices[extra_idx] : indices[extra_idx + 1]]\n                ngb = ngb[ngb < n_points]\n                if len(ngb) > 0:\n                    used[idx] = True\n                    v_extra[idx] = v[ngb].mean()\n            if not used.all() and used.any():\n                # Eventually we might want to use the value of the nearest\n                # point or something, but this case should hopefully be\n                # rare so for now just use the average value of all extras\n                v_extra[~used] = np.mean(v_extra[used])\n        else:\n            v_extra = np.full(self.n_extra, self.border, dtype=float)\n\n        v = np.concatenate((v, v_extra))\n        self.interpolator = self.interp(self.tri, v)\n        return self", "metadata": {}}
{"_id": "mne_mne_viz/topomap.py_set_locations_code", "title": "set_locations", "text": "def set_locations(self, Xi, Yi):\n        \"\"\"Set locations for easier (delayed) calling.\"\"\"\n        self.Xi = Xi\n        self.Yi = Yi\n        return self", "metadata": {}}
{"_id": "mne_mne_viz/utils.py_safe_event_code", "title": "safe_event", "text": "def safe_event(fun, *args, **kwargs):\n    \"\"\"Protect against Qt exiting on event-handling errors.\"\"\"\n    try:\n        return fun(*args, **kwargs)\n    except Exception:\n        traceback.print_exc(file=sys.stderr)", "metadata": {}}
{"_id": "mne_mne_viz/utils.py_plt_show_code", "title": "plt_show", "text": "def plt_show(show=True, fig=None, **kwargs):\n    \"\"\"Show a figure while suppressing warnings.\n\n    Parameters\n    ----------\n    show : bool\n        Show the figure.\n    fig : instance of Figure | None\n        If non-None, use fig.show().\n    **kwargs : dict\n        Extra arguments for :func:`matplotlib.pyplot.show`.\n    \"\"\"\n    import matplotlib.pyplot as plt\n    from matplotlib import get_backend\n\n    if hasattr(fig, \"mne\") and hasattr(fig.mne, \"backend\"):\n        backend = fig.mne.backend\n        # TODO: This is a hack to deal with the fact that the\n        # with plt.ion():\n        #     BACKEND = get_backend()\n        # an the top of _mpl_figure detects QtAgg during testing even though\n        # we've set the backend to Agg.\n        if backend != \"agg\":\n            gotten_backend = get_backend()\n            if gotten_backend == \"agg\":\n                backend = \"agg\"\n    else:\n        backend = get_backend()\n    if show and backend != \"agg\":\n        logger.debug(f\"Showing plot for backend {repr(backend)}\")\n        (fig or plt).show(**kwargs)", "metadata": {}}
{"_id": "mne_mne_viz/utils.py_mne_analyze_colormap_code", "title": "mne_analyze_colormap", "text": "def mne_analyze_colormap(limits=(5, 10, 15), format=\"vtk\"):  # noqa: A002\n    \"\"\"Return a colormap similar to that used by mne_analyze.\n\n    Parameters\n    ----------\n    limits : array-like of length 3 or 6\n        Bounds for the colormap, which will be mirrored across zero if length\n        3, or completely specified (and potentially asymmetric) if length 6.\n    format : str\n        Type of colormap to return. If 'matplotlib', will return a\n        matplotlib.colors.LinearSegmentedColormap. If 'vtk', will\n        return an RGBA array of shape (256, 4).\n\n    Returns\n    -------\n    cmap : instance of colormap | array\n        A teal->blue->gray->red->yellow colormap. See docstring of the 'format'\n        argument for further details.\n\n    Notes\n    -----\n    For this will return a colormap that will display correctly for data\n    that are scaled by the plotting function to span [-fmax, fmax].\n    \"\"\"  # noqa: E501\n    # Ensure limits is an array\n    limits = np.asarray(limits, dtype=\"float\")\n\n    if len(limits) != 3 and len(limits) != 6:\n        raise ValueError(\"limits must have 3 or 6 elements\")\n    if len(limits) == 3 and any(limits < 0.0):\n        raise ValueError(\"if 3 elements, limits must all be non-negative\")\n    if any(np.diff(limits) <= 0):\n        raise ValueError(\"limits must be monotonically increasing\")\n    if format == \"matplotlib\":\n        from matplotlib import colors\n\n        if len(limits) == 3:\n            limits = (np.concatenate((-np.flipud(limits), limits)) + limits[-1]) / (\n                2 * limits[-1]\n            )\n        else:\n            limits = (limits - np.min(limits)) / np.max(limits - np.min(limits))\n\n        cdict = {\n            \"red\": (\n                (limits[0], 0.0, 0.0),\n                (limits[1], 0.0, 0.0),\n                (limits[2], 0.5, 0.5),\n                (limits[3], 0.5, 0.5),\n                (limits[4], 1.0, 1.0),\n                (limits[5], 1.0, 1.0),\n            ),\n            \"green\": (\n                (limits[0], 1.0, 1.0),\n                (limits[1], 0.0, 0.0),\n                (limits[2], 0.5, 0.5),\n                (limits[3], 0.5, 0.5),\n                (limits[4], 0.0, 0.0),\n                (limits[5], 1.0, 1.0),\n            ),\n            \"blue\": (\n                (limits[0], 1.0, 1.0),\n                (limits[1], 1.0, 1.0),\n                (limits[2], 0.5, 0.5),\n                (limits[3], 0.5, 0.5),\n                (limits[4], 0.0, 0.0),\n                (limits[5], 0.0, 0.0),\n            ),\n            \"alpha\": (\n                (limits[0], 1.0, 1.0),\n                (limits[1], 1.0, 1.0),\n                (limits[2], 0.0, 0.0),\n                (limits[3], 0.0, 0.0),\n                (limits[4], 1.0, 1.0),\n                (limits[5], 1.0, 1.0),\n            ),\n        }\n        return colors.LinearSegmentedColormap(\"mne_analyze\", cdict)\n    elif format in (\"vtk\", \"mayavi\"):\n        if len(limits) == 3:\n            limits = np.concatenate((-np.flipud(limits), [0], limits)) / limits[-1]\n        else:\n            limits = np.concatenate((limits[:3], [0], limits[3:]))\n            limits /= np.max(np.abs(limits))\n        r = np.array([0, 0, 0, 0, 1, 1, 1])\n        g = np.array([1, 0, 0, 0, 0, 0, 1])\n        b = np.array([1, 1, 1, 0, 0, 0, 0])\n        a = np.array([1, 1, 0, 0, 0, 1, 1])\n        xp = (np.arange(256) - 128) / 128.0\n        colormap = np.r_[[np.interp(xp, limits, 255 * c) for c in [r, g, b, a]]].T\n        return colormap\n    else:\n        # Use this instead of check_option because we have a hidden option\n        raise ValueError(f\"format must be either matplotlib or vtk, got {repr(format)}\")", "metadata": {}}
{"_id": "mne_mne_viz/utils.py_compare_fiff_code", "title": "compare_fiff", "text": "def compare_fiff(\n    fname_1,\n    fname_2,\n    fname_out=None,\n    show=True,\n    indent=\"    \",\n    read_limit=np.inf,\n    max_str=30,\n    verbose=None,\n):\n    \"\"\"Compare the contents of two fiff files using diff and show_fiff.\n\n    Parameters\n    ----------\n    fname_1 : path-like\n        First file to compare.\n    fname_2 : path-like\n        Second file to compare.\n    fname_out : path-like | None\n        Filename to store the resulting diff. If None, a temporary\n        file will be created.\n    show : bool\n        If True, show the resulting diff in a new tab in a web browser.\n    indent : str\n        How to indent the lines.\n    read_limit : int\n        Max number of bytes of data to read from a tag. Can be np.inf\n        to always read all data (helps test read completion).\n    max_str : int\n        Max number of characters of string representation to print for\n        each tag's data.\n    %(verbose)s\n\n    Returns\n    -------\n    fname_out : str\n        The filename used for storing the diff. Could be useful for\n        when a temporary file is used.\n    \"\"\"\n    file_1 = show_fiff(\n        fname_1, output=list, indent=indent, read_limit=read_limit, max_str=max_str\n    )\n    file_2 = show_fiff(\n        fname_2, output=list, indent=indent, read_limit=read_limit, max_str=max_str\n    )\n    diff = difflib.HtmlDiff().make_file(file_1, file_2, fname_1, fname_2)\n    if fname_out is not None:\n        f = open(fname_out, \"wb\")\n    else:\n        f = tempfile.NamedTemporaryFile(\"wb\", delete=False, suffix=\".html\")\n        fname_out = f.name\n    with f as fid:\n        fid.write(diff.encode(\"utf-8\"))\n    if show is True:\n        webbrowser.open_new_tab(fname_out)\n    return fname_out", "metadata": {}}
{"_id": "mne_mne_viz/utils.py_figure_nobar_code", "title": "figure_nobar", "text": "def figure_nobar(*args, **kwargs):\n    \"\"\"Make matplotlib figure with no toolbar.\n\n    Parameters\n    ----------\n    *args : list\n        Arguments to pass to :func:`matplotlib.pyplot.figure`.\n    **kwargs : dict\n        Keyword arguments to pass to :func:`matplotlib.pyplot.figure`.\n\n    Returns\n    -------\n    fig : instance of Figure\n        The figure.\n    \"\"\"\n    from matplotlib import pyplot as plt\n    from matplotlib import rcParams\n\n    old_val = rcParams[\"toolbar\"]\n    try:\n        rcParams[\"toolbar\"] = \"none\"\n        if \"layout\" not in kwargs:\n            kwargs[\"layout\"] = \"constrained\"\n        fig = plt.figure(*args, **kwargs)\n        # remove button press catchers (for toolbar)\n        cbs = list(fig.canvas.callbacks.callbacks[\"key_press_event\"].keys())\n        for key in cbs:\n            fig.canvas.callbacks.disconnect(key)\n    finally:\n        rcParams[\"toolbar\"] = old_val\n    return fig", "metadata": {}}
{"_id": "mne_mne_viz/utils.py_add_background_image_code", "title": "add_background_image", "text": "def add_background_image(fig, im, set_ratios=None):\n    \"\"\"Add a background image to a plot.\n\n    Adds the image specified in ``im`` to the\n    figure ``fig``. This is generally meant to\n    be done with topo plots, though it could work\n    for any plot.\n\n    .. note:: This modifies the figure and/or axes in place.\n\n    Parameters\n    ----------\n    fig : Figure\n        The figure you wish to add a bg image to.\n    im : array, shape (M, N, {3, 4})\n        A background image for the figure. This must be a valid input to\n        `matplotlib.pyplot.imshow`. Defaults to None.\n    set_ratios : None | str\n        Set the aspect ratio of any axes in fig\n        to the value in set_ratios. Defaults to None,\n        which does nothing to axes.\n\n    Returns\n    -------\n    ax_im : instance of Axes\n        Axes created corresponding to the image you added.\n\n    Notes\n    -----\n    .. versionadded:: 0.9.0\n    \"\"\"\n    if im is None:\n        # Don't do anything and return nothing\n        return None\n    if set_ratios is not None:\n        for ax in fig.axes:\n            ax.set_aspect(set_ratios)\n\n    ax_im = fig.add_axes([0, 0, 1, 1], label=\"background\")\n    ax_im.imshow(im, aspect=\"auto\")\n    ax_im.set_zorder(-1)\n    return ax_im", "metadata": {}}
{"_id": "mne_mne_viz/utils.py_plot_sensors_code", "title": "plot_sensors", "text": "def plot_sensors(\n    info,\n    kind=\"topomap\",\n    ch_type=None,\n    title=None,\n    show_names=False,\n    ch_groups=None,\n    to_sphere=True,\n    axes=None,\n    block=False,\n    show=True,\n    sphere=None,\n    pointsize=None,\n    linewidth=2,\n    *,\n    cmap=None,\n    verbose=None,\n):\n    \"\"\"Plot sensors positions.\n\n    Parameters\n    ----------\n    %(info_not_none)s\n    kind : str\n        Whether to plot the sensors as 3d, topomap or as an interactive\n        sensor selection dialog. Available options ``'topomap'``, ``'3d'``,\n        ``'select'``. If ``'select'``, a set of channels can be selected\n        interactively by using lasso selector or clicking while holding the control\n        key. The selected channels are returned along with the figure instance.\n        Defaults to ``'topomap'``.\n    ch_type : None | str\n        The channel type to plot. Available options ``'mag'``, ``'grad'``,\n        ``'eeg'``, ``'seeg'``, ``'dbs'``, ``'ecog'``, ``'all'``. If ``'all'``,\n        all the available mag, grad, eeg, seeg, dbs and ecog channels are\n        plotted. If None (default), then channels are chosen in the order given\n        above.\n    title : str | None\n        Title for the figure. If None (default), equals to\n        ``'Sensor positions (%%s)' %% ch_type``.\n    show_names : bool | array of str\n        Whether to display all channel names. If an array, only the channel\n        names in the array are shown. Defaults to False.\n    ch_groups : 'position' | list of list | None\n        Channel groups for coloring the sensors. If None (default), default\n        coloring scheme is used. If 'position', the sensors are divided\n        into 8 regions. See ``order`` kwarg of :func:`mne.viz.plot_raw`. If\n        array, the channels are divided by picks given in the array. Also\n        accepts a list of lists to allow channel groups of the same or\n        different sizes.\n\n        .. versionadded:: 0.13.0\n    to_sphere : bool\n        Whether to project the 3d locations to a sphere. When False, the\n        sensor array appears similar as to looking downwards straight above the\n        subject's head. Has no effect when ``kind='3d'``. Defaults to True.\n\n        .. versionadded:: 0.14.0\n    %(axes_montage)s\n\n        .. versionadded:: 0.13.0\n    block : bool\n        Whether to halt program execution until the figure is closed. Defaults\n        to False.\n\n        .. versionadded:: 0.13.0\n    show : bool\n        Show figure if True. Defaults to True.\n    %(sphere_topomap_auto)s\n    pointsize : float | None\n        The size of the points. If None (default), will bet set to ``75`` if\n        ``kind='3d'``, or ``25`` otherwise.\n    linewidth : float\n        The width of the outline. If ``0``, the outline will not be drawn.\n    cmap : str | instance of matplotlib.colors.Colormap | None\n        Colormap for coloring ch_groups. Has effect only when ``ch_groups``\n        is list of list. If None, set to ``matplotlib.rcParams[\"image.cmap\"]``.\n        Defaults to None.\n    %(verbose)s\n\n    Returns\n    -------\n    fig : instance of Figure\n        Figure containing the sensor topography.\n    selection : list\n        A list of selected channels. Only returned if ``kind=='select'``.\n\n    See Also\n    --------\n    mne.viz.plot_layout\n\n    Notes\n    -----\n    This function plots the sensor locations from the info structure using\n    matplotlib. For drawing the sensors using PyVista see\n    :func:`mne.viz.plot_alignment`.\n\n    .. versionadded:: 0.12.0\n    \"\"\"\n    from .evoked import _rgb\n\n    _check_option(\"kind\", kind, [\"topomap\", \"3d\", \"select\"])\n    if axes is not None:\n        from matplotlib.axes import Axes\n        from mpl_toolkits.mplot3d.axes3d import Axes3D\n\n        if kind == \"3d\":\n            _validate_type(axes, Axes3D, \"axes\", extra=\"when 'kind' is '3d'\")\n        elif kind in (\"topomap\", \"select\"):\n            _validate_type(\n                axes, Axes, \"axes\", extra=\"when 'kind' is 'topomap' or 'select'\"\n            )\n            if isinstance(axes, Axes3D):\n                raise TypeError(\n                    \"axes must be an instance of Axes when 'kind' is \"\n                    f\"'topomap' or 'select', got {type(axes)} instead.\"\n                )\n    _validate_type(info, Info, \"info\")\n    ch_indices = channel_indices_by_type(info)\n    allowed_types = _DATA_CH_TYPES_SPLIT\n    if ch_type is None:\n        for this_type in allowed_types:\n            if _contains_ch_type(info, this_type):\n                ch_type = this_type\n                break\n        picks = ch_indices[ch_type]\n    elif ch_type == \"all\":\n        picks = list()\n        for this_type in allowed_types:\n            picks += ch_indices[this_type]\n    elif ch_type in allowed_types:\n        picks = ch_indices[ch_type]\n    else:\n        raise ValueError(f\"ch_type must be one of {allowed_types} not {ch_type}!\")\n\n    if len(picks) == 0:\n        raise ValueError(f\"Could not find any channels of type {ch_type}.\")\n\n    if not _check_ch_locs(info=info, picks=picks):\n        raise RuntimeError(\"No valid channel positions found\")\n\n    dev_head_t = info[\"dev_head_t\"]\n    chs = [info[\"chs\"][pick] for pick in picks]\n    pos = np.empty((len(chs), 3))\n    for ci, ch in enumerate(chs):\n        pos[ci] = ch[\"loc\"][:3]\n        if ch[\"coord_frame\"] == FIFF.FIFFV_COORD_DEVICE:\n            if dev_head_t is None:\n                warn(\n                    \"dev_head_t is None, transforming MEG sensors to head \"\n                    \"coordinate frame using identity transform\"\n                )\n                dev_head_t = np.eye(4)\n            pos[ci] = apply_trans(dev_head_t, pos[ci])\n    del dev_head_t\n\n    ch_names = np.array([ch[\"ch_name\"] for ch in chs])\n    bads = [idx for idx, name in enumerate(ch_names) if name in info[\"bads\"]]\n    _validate_type(ch_groups, (list, np.ndarray, str, None), \"ch_groups\")\n    if ch_groups is None:\n        def_colors = _handle_default(\"color\")\n        colors = [\n            \"red\" if i in bads else def_colors[channel_type(info, pick)]\n            for i, pick in enumerate(picks)\n        ]\n    else:\n        if isinstance(ch_groups, str):\n            _check_option(\n                \"ch_groups\", ch_groups, [\"position\", \"selection\"], extra=\"when str\"\n            )\n            # Avoid circular import\n            from ..channels import (\n                _EEG_SELECTIONS,\n                _SELECTIONS,\n                _divide_to_regions,\n                read_vectorview_selection,\n            )\n\n            if ch_groups == \"position\":\n                ch_groups = _divide_to_regions(info, add_stim=False)\n                ch_groups = list(ch_groups.values())\n            else:\n                ch_groups, color_vals = list(), list()\n                for selection in _SELECTIONS + _EEG_SELECTIONS:\n                    channels = pick_channels(\n                        info[\"ch_names\"],\n                        read_vectorview_selection(selection, info=info),\n                        ordered=False,\n                    )\n                    ch_groups.append(channels)\n            color_vals = np.ones((len(ch_groups), 4))\n            for idx, ch_group in enumerate(ch_groups):\n                color_picks = [\n                    np.where(picks == ch)[0][0] for ch in ch_group if ch in picks\n                ]\n                if len(color_picks) == 0:\n                    continue\n                x, y, z = pos[color_picks].T\n                color = np.mean(_rgb(x, y, z), axis=0)\n                color_vals[idx, :3] = color  # mean of spatial color\n        else:  # array-like\n            cmap = _get_cmap(cmap)\n            colors = np.linspace(0, 1, len(ch_groups))\n            color_vals = [cmap(colors[i]) for i in range(len(ch_groups))]\n        colors = np.zeros((len(picks), 4))\n        for pick_idx, pick in enumerate(picks):\n            for ind, value in enumerate(ch_groups):\n                if pick in value:\n                    colors[pick_idx] = color_vals[ind]\n                    break\n    title = f\"Sensor positions ({ch_type})\" if title is None else title\n    fig = _plot_sensors_2d(\n        pos,\n        info,\n        picks,\n        colors,\n        bads,\n        ch_names,\n        title,\n        show_names,\n        axes,\n        show,\n        kind,\n        block,\n        to_sphere,\n        sphere,\n        pointsize=pointsize,\n        linewidth=linewidth,\n    )\n    if kind == \"select\":\n        return fig, fig.lasso.selection\n    return fig", "metadata": {}}
{"_id": "mne_mne_viz/utils.py_centers_to_edges_code", "title": "centers_to_edges", "text": "def centers_to_edges(*arrays):\n    \"\"\"Convert center points to edges.\n\n    Parameters\n    ----------\n    *arrays : list of ndarray\n        Each input array should be 1D monotonically increasing,\n        and will be cast to float.\n\n    Returns\n    -------\n    arrays : list of ndarray\n        Given each input of shape (N,), the output will have shape (N+1,).\n\n    Examples\n    --------\n    >>> x = [0., 0.1, 0.2, 0.3]\n    >>> y = [20, 30, 40]\n    >>> centers_to_edges(x, y)  # doctest: +SKIP\n    [array([-0.05, 0.05, 0.15, 0.25, 0.35]), array([15., 25., 35., 45.])]\n    \"\"\"\n    out = list()\n    for ai, arr in enumerate(arrays):\n        arr = np.asarray(arr, dtype=float)\n        _check_option(f\"arrays[{ai}].ndim\", arr.ndim, (1,))\n        if len(arr) > 1:\n            arr_diff = np.diff(arr) / 2.0\n        else:\n            arr_diff = [abs(arr[0]) * 0.001] if arr[0] != 0 else [0.001]\n        out.append(\n            np.concatenate(\n                [[arr[0] - arr_diff[0]], arr[:-1] + arr_diff, [arr[-1] + arr_diff[-1]]]\n            )\n        )\n    return out", "metadata": {}}
{"_id": "mne_mne_viz/utils.py_concatenate_images_code", "title": "concatenate_images", "text": "def concatenate_images(images, axis=0, bgcolor=\"black\", centered=True, n_channels=3):\n    \"\"\"Concatenate a list of images.\n\n    Parameters\n    ----------\n    images : list of ndarray\n        The list of images to concatenate.\n    axis : 0 or 1\n        The images are concatenated horizontally if 0 and vertically otherwise.\n        The default orientation is horizontal.\n    bgcolor : str | list\n        The color of the background. The name of the color is accepted\n        (e.g 'red') or a list of RGB values between 0 and 1. Defaults to\n        'black'.\n    centered : bool\n        If True, the images are centered. Defaults to True.\n    n_channels : int\n        Number of color channels. Can be 3 or 4. The default value is 3.\n\n    Returns\n    -------\n    img : ndarray\n        The concatenated image.\n    \"\"\"\n    n_channels = _ensure_int(n_channels, \"n_channels\")\n    axis = _ensure_int(axis)\n    _check_option(\"axis\", axis, (0, 1))\n    _check_option(\"n_channels\", n_channels, (3, 4))\n    alpha = True if n_channels == 4 else False\n    bgcolor = _to_rgb(bgcolor, name=\"bgcolor\", alpha=alpha)\n    bgcolor = np.asarray(bgcolor) * 255\n    funcs = [np.sum, np.max]\n    ret_shape = np.asarray(\n        [\n            funcs[axis]([image.shape[0] for image in images]),\n            funcs[1 - axis]([image.shape[1] for image in images]),\n        ]\n    )\n    ret = np.zeros((ret_shape[0], ret_shape[1], n_channels), dtype=np.uint8)\n    ret[:, :, :] = bgcolor\n    ptr = np.array([0, 0])\n    sec = np.array([0 == axis, 1 == axis]).astype(int)\n    for image in images:\n        shape = image.shape[:-1]\n        dec = ptr.copy()\n        dec += ((ret_shape - shape) // 2) * (1 - sec) if centered else 0\n        ret[dec[0] : dec[0] + shape[0], dec[1] : dec[1] + shape[1], :] = image\n        ptr += shape * sec\n    return ret", "metadata": {}}
{"_id": "mne_mne_viz/utils.py_onclick_code", "title": "onclick", "text": "def onclick(self, event):\n        \"\"\"Handle Mouse clicks.\n\n        Parameters\n        ----------\n        event : matplotlib.backend_bases.Event\n            The matplotlib object that we use to get x/y position.\n        \"\"\"\n        mouseevent = event.mouseevent\n        self.coords.append((mouseevent.xdata, mouseevent.ydata))", "metadata": {}}
{"_id": "mne_mne_viz/utils.py_plot_clicks_code", "title": "plot_clicks", "text": "def plot_clicks(self, **kwargs):\n        \"\"\"Plot the x/y positions stored in self.coords.\n\n        Parameters\n        ----------\n        **kwargs : dict\n            Arguments are passed to imshow in displaying the bg image.\n        \"\"\"\n        import matplotlib.pyplot as plt\n\n        if len(self.coords) == 0:\n            raise ValueError(\n                \"No coordinates found, make sure you click \"\n                \"on the image that is first shown.\"\n            )\n        f, ax = plt.subplots()\n        ax.imshow(self.imdata, extent=(0, self.xmax, 0, self.ymax), **kwargs)\n        xlim, ylim = [ax.get_xlim(), ax.get_ylim()]\n        xcoords, ycoords = zip(*self.coords)\n        ax.scatter(xcoords, ycoords, c=\"#ff0000\")\n        ann_text = np.arange(len(self.coords)).astype(str)\n        for txt, coord in zip(ann_text, self.coords):\n            ax.annotate(txt, coord, fontsize=20, color=\"#ff0000\")\n        ax.set_xlim(xlim)\n        ax.set_ylim(ylim)\n        plt_show()", "metadata": {}}
{"_id": "mne_mne_viz/utils.py_to_layout_code", "title": "to_layout", "text": "def to_layout(self, **kwargs):\n        \"\"\"Turn coordinates into an MNE Layout object.\n\n        Normalizes by the image you used to generate clicks\n\n        Parameters\n        ----------\n        **kwargs : dict\n            Arguments are passed to generate_2d_layout.\n\n        Returns\n        -------\n        layout : instance of Layout\n            The layout.\n        \"\"\"\n        from ..channels.layout import generate_2d_layout\n\n        coords = np.array(self.coords)\n        lt = generate_2d_layout(coords, bg_image=self.imdata, **kwargs)\n        return lt", "metadata": {}}
{"_id": "mne_mne_viz/utils.py_connect_code", "title": "connect", "text": "def connect(self):\n        \"\"\"Connect to all the events we need.\"\"\"\n        self.cidpress = self.cbar.ax.figure.canvas.mpl_connect(\n            \"button_press_event\", self.on_press\n        )\n        self.cidrelease = self.cbar.ax.figure.canvas.mpl_connect(\n            \"button_release_event\", self.on_release\n        )\n        self.cidmotion = self.cbar.ax.figure.canvas.mpl_connect(\n            \"motion_notify_event\", self.on_motion\n        )\n        self.keypress = self.cbar.ax.figure.canvas.mpl_connect(\n            \"key_press_event\", self.key_press\n        )\n        self.scroll = self.cbar.ax.figure.canvas.mpl_connect(\n            \"scroll_event\", self.on_scroll\n        )", "metadata": {}}
{"_id": "mne_mne_viz/utils.py_on_press_code", "title": "on_press", "text": "def on_press(self, event):\n        \"\"\"Handle button press.\"\"\"\n        if event.inaxes != self.cbar.ax:\n            return\n        self.press = event.y", "metadata": {}}
{"_id": "mne_mne_viz/utils.py_key_press_code", "title": "key_press", "text": "def key_press(self, event):\n        \"\"\"Handle key press.\"\"\"\n        scale = self.cbar.norm.vmax - self.cbar.norm.vmin\n        perc = 0.03\n        if event.key == \"down\":\n            self.index += 1\n        elif event.key == \"up\":\n            self.index -= 1\n        elif event.key == \" \":  # space key resets scale\n            self.cbar.norm.vmin = self.lims[0]\n            self.cbar.norm.vmax = self.lims[1]\n        elif event.key == \"+\":\n            self.cbar.norm.vmin -= (perc * scale) * -1\n            self.cbar.norm.vmax += (perc * scale) * -1\n        elif event.key == \"-\":\n            self.cbar.norm.vmin -= (perc * scale) * 1\n            self.cbar.norm.vmax += (perc * scale) * 1\n        elif event.key == \"pageup\":\n            self.cbar.norm.vmin -= (perc * scale) * 1\n            self.cbar.norm.vmax -= (perc * scale) * 1\n        elif event.key == \"pagedown\":\n            self.cbar.norm.vmin -= (perc * scale) * -1\n            self.cbar.norm.vmax -= (perc * scale) * -1\n        else:\n            return\n        if self.index < 0:\n            self.index = len(self.cycle) - 1\n        elif self.index >= len(self.cycle):\n            self.index = 0\n        cmap = self.cycle[self.index]\n        self.cbar.mappable.set_cmap(cmap)\n        self.cbar.ax.figure.draw_without_rendering()\n        self.mappable.set_cmap(cmap)\n        self._publish()", "metadata": {}}
{"_id": "mne_mne_viz/utils.py_on_motion_code", "title": "on_motion", "text": "def on_motion(self, event):\n        \"\"\"Handle mouse movements.\"\"\"\n        if self.press is None:\n            return\n        if event.inaxes != self.cbar.ax:\n            return\n        yprev = self.press\n        dy = event.y - yprev\n        self.press = event.y\n        scale = self.cbar.norm.vmax - self.cbar.norm.vmin\n        perc = 0.03\n        if event.button == 1:\n            self.cbar.norm.vmin -= (perc * scale) * np.sign(dy)\n            self.cbar.norm.vmax -= (perc * scale) * np.sign(dy)\n        elif event.button == 3:\n            self.cbar.norm.vmin -= (perc * scale) * np.sign(dy)\n            self.cbar.norm.vmax += (perc * scale) * np.sign(dy)\n        self._publish()", "metadata": {}}
{"_id": "mne_mne_viz/utils.py_on_release_code", "title": "on_release", "text": "def on_release(self, event):\n        \"\"\"Handle release.\"\"\"\n        self.press = None\n        self._update()", "metadata": {}}
{"_id": "mne_mne_viz/utils.py_on_scroll_code", "title": "on_scroll", "text": "def on_scroll(self, event):\n        \"\"\"Handle scroll.\"\"\"\n        scale = 1.1 if event.step < 0 else 1.0 / 1.1\n        self.cbar.norm.vmin *= scale\n        self.cbar.norm.vmax *= scale\n        self._publish()", "metadata": {}}
{"_id": "mne_mne_viz/utils.py_notify_code", "title": "notify", "text": "def notify(self):\n        \"\"\"Notify listeners that a selection has been made.\"\"\"\n        logger.info(f\"Selected channels: {self.selection}\")\n        for callback in self.callbacks:\n            callback()", "metadata": {}}
{"_id": "mne_mne_viz/utils.py_on_select_code", "title": "on_select", "text": "def on_select(self, verts):\n        \"\"\"Select a subset from the collection.\"\"\"\n        from matplotlib.path import Path\n\n        # Don't respond to single clicks without extra keys being hold down.\n        # Figures like plot_evoked_topo want to do something else with them.\n        if len(verts) <= 3 and self.canvas._key not in [\"control\", \"ctrl+shift\"]:\n            return\n\n        path = Path(verts)\n        inds = np.nonzero([path.intersects_path(p) for p in self.paths])[0]\n        if self.canvas._key == \"control\":  # Appending selection.\n            self.selection_inds = np.union1d(self.selection_inds, inds).astype(\"int\")\n        elif self.canvas._key == \"ctrl+shift\":\n            self.selection_inds = np.setdiff1d(self.selection_inds, inds).astype(\"int\")\n        else:\n            self.selection_inds = inds\n        self.selection = [self.names[i] for i in self.selection_inds]\n        self.style_objects()\n        self.notify()", "metadata": {}}
{"_id": "mne_mne_viz/utils.py_select_one_code", "title": "select_one", "text": "def select_one(self, ind):\n        \"\"\"Select or deselect one sensor.\"\"\"\n        if self.canvas._key == \"control\":\n            self.selection_inds = np.union1d(self.selection_inds, [ind])\n        elif self.canvas._key == \"ctrl+shift\":\n            self.selection_inds = np.setdiff1d(self.selection_inds, [ind])\n        else:\n            return  # don't notify()\n        self.selection = [self.names[i] for i in self.selection_inds]\n        self.style_objects()\n        self.notify()", "metadata": {}}
{"_id": "mne_mne_viz/utils.py_select_many_code", "title": "select_many", "text": "def select_many(self, inds):\n        \"\"\"Select many sensors using indices (for predefined selections).\"\"\"\n        self.selection_inds = inds\n        self.selection = [self.names[i] for i in self.selection_inds]\n        self.style_objects()", "metadata": {}}
{"_id": "mne_mne_viz/utils.py_style_objects_code", "title": "style_objects", "text": "def style_objects(self):\n        \"\"\"Style selected sensors as \"active\".\"\"\"\n        # reset\n        self.fc[:, -1] = self.alpha_nonselected\n        self.ec[:, -1] = self.alpha_nonselected / 2\n        self.lw[:] = self.linewidth_nonselected\n        # style sensors at `inds`\n        self.fc[self.selection_inds, -1] = self.alpha_selected\n        self.ec[self.selection_inds, -1] = self.alpha_selected\n        self.lw[self.selection_inds] = self.linewidth_selected\n        self.collection.set_facecolors(self.fc)\n        self.collection.set_edgecolors(self.ec)\n        self.collection.set_linewidths(self.lw)\n        self.canvas.draw_idle()", "metadata": {}}
{"_id": "mne_mne_viz/utils.py_disconnect_code", "title": "disconnect", "text": "def disconnect(self):\n        \"\"\"Disconnect the lasso selector.\"\"\"\n        self.lasso.disconnect_events()\n        self.fc[:, -1] = self.alpha_selected\n        self.ec[:, -1] = self.alpha_selected\n        self.collection.set_facecolors(self.fc)\n        self.collection.set_edgecolors(self.ec)\n        self.canvas.draw_idle()", "metadata": {}}
{"_id": "mne_mne_viz/utils.py_set_x_code", "title": "set_x", "text": "def set_x(self, x):\n        \"\"\"Repoisition the line.\"\"\"\n        self.line.set_xdata([x, x])\n        self.x0 = x", "metadata": {}}
{"_id": "mne_mne_viz/utils.py_on_press_code", "title": "on_press", "text": "def on_press(self, event):\n        \"\"\"Store button press if on top of the line.\"\"\"\n        if event.inaxes != self.line.axes or not self.line.contains(event)[0]:\n            return\n        x0 = self.line.get_xdata()\n        y0 = self.line.get_ydata()\n        self.press = x0, y0, event.xdata, event.ydata", "metadata": {}}
{"_id": "mne_mne_viz/utils.py_on_motion_code", "title": "on_motion", "text": "def on_motion(self, event):\n        \"\"\"Move the line on drag.\"\"\"\n        if self.press is None:\n            return\n        if event.inaxes != self.line.axes:\n            return\n        x0, y0, xpress, ypress = self.press\n        dx = event.xdata - xpress\n        self.line.set_xdata(x0 + dx)\n        self.drag_callback((x0 + dx)[0])\n        self.line.figure.canvas.draw()", "metadata": {}}
{"_id": "mne_mne_viz/utils.py_on_release_code", "title": "on_release", "text": "def on_release(self, event):\n        \"\"\"Handle release.\"\"\"\n        if event.inaxes != self.line.axes or self.press is None:\n            return\n        self.press = None\n        self.line.figure.canvas.draw()\n        self.modify_callback(self.x0, event.xdata)\n        self.x0 = event.xdata", "metadata": {}}
{"_id": "mne_mne_viz/utils.py_remove_code", "title": "remove", "text": "def remove(self):\n        \"\"\"Remove the line.\"\"\"\n        self.line.figure.canvas.mpl_disconnect(self.cidpress)\n        self.line.figure.canvas.mpl_disconnect(self.cidrelease)\n        self.line.figure.canvas.mpl_disconnect(self.cidmotion)\n        self.line.remove()", "metadata": {}}
{"_id": "mne_mne_viz/_figure.py_set_browser_backend_code", "title": "set_browser_backend", "text": "def set_browser_backend(backend_name, verbose=None):\n    \"\"\"Set the 2D browser backend for MNE.\n\n    The backend will be set as specified and operations will use\n    that backend.\n\n    Parameters\n    ----------\n    backend_name : str\n        The 2D browser backend to select. See Notes for the capabilities\n        of each backend (``'qt'``, ``'matplotlib'``). The ``'qt'`` browser\n        requires `mne-qt-browser\n        <https://github.com/mne-tools/mne-qt-browser>`__.\n    %(verbose)s\n\n    Returns\n    -------\n    old_backend_name : str | None\n        The old backend that was in use.\n\n    Notes\n    -----\n    This table shows the capabilities of each backend (\"\u2713\" for full support,\n    and \"-\" for partial support):\n\n    .. table::\n       :widths: auto\n\n       +--------------------------------------+------------+----+\n       | **2D browser function:**             | matplotlib | qt |\n       +======================================+============+====+\n       | :func:`plot_raw`                     | \u2713          | \u2713  |\n       +--------------------------------------+------------+----+\n       | :func:`plot_epochs`                  | \u2713          | \u2713  |\n       +--------------------------------------+------------+----+\n       | :func:`plot_ica_sources`             | \u2713          | \u2713  |\n       +--------------------------------------+------------+----+\n       +--------------------------------------+------------+----+\n       | **Feature:**                                           |\n       +--------------------------------------+------------+----+\n       | Show Events                          | \u2713          | \u2713  |\n       +--------------------------------------+------------+----+\n       | Add/Edit/Remove Annotations          | \u2713          | \u2713  |\n       +--------------------------------------+------------+----+\n       | Toggle Projections                   | \u2713          | \u2713  |\n       +--------------------------------------+------------+----+\n       | Butterfly Mode                       | \u2713          | \u2713  |\n       +--------------------------------------+------------+----+\n       | Selection Mode                       | \u2713          | \u2713  |\n       +--------------------------------------+------------+----+\n       | Smooth Scrolling                     |            | \u2713  |\n       +--------------------------------------+------------+----+\n       | Overview-Bar (with Z-Score-Mode)     |            | \u2713  |\n       +--------------------------------------+------------+----+\n\n    .. versionadded:: 0.24\n    \"\"\"\n    global MNE_BROWSER_BACKEND\n    old_backend_name = MNE_BROWSER_BACKEND\n    backend_name = _check_browser_backend_name(backend_name)\n    if MNE_BROWSER_BACKEND != backend_name:\n        _load_backend(backend_name)\n        MNE_BROWSER_BACKEND = backend_name\n\n    return old_backend_name", "metadata": {}}
{"_id": "mne_mne_viz/_figure.py_get_browser_backend_code", "title": "get_browser_backend", "text": "def get_browser_backend():\n    \"\"\"Return the 2D backend currently used.\n\n    Returns\n    -------\n    backend_used : str | None\n        The 2D browser backend currently in use. If no backend is found,\n        returns ``None``.\n    \"\"\"\n    try:\n        backend_name = _init_browser_backend()\n    except RuntimeError as exc:\n        backend_name = None\n        logger.info(str(exc))\n    return backend_name", "metadata": {}}
{"_id": "mne_mne_viz/_figure.py_use_browser_backend_code", "title": "use_browser_backend", "text": "def use_browser_backend(backend_name):\n    \"\"\"Create a 2D browser visualization context using the designated backend.\n\n    See :func:`mne.viz.set_browser_backend` for more details on the available\n    2D browser backends and their capabilities.\n\n    Parameters\n    ----------\n    backend_name : {'qt', 'matplotlib'}\n        The 2D browser backend to use in the context.\n    \"\"\"\n    old_backend = set_browser_backend(backend_name)\n    try:\n        yield backend\n    finally:\n        if old_backend is not None:\n            try:\n                set_browser_backend(old_backend)\n            except Exception:\n                pass", "metadata": {}}
{"_id": "mne_mne_viz/_figure.py_fake_keypress_code", "title": "fake_keypress", "text": "def fake_keypress(self, key, fig=None):  # noqa: D400\n        \"\"\"Pass a fake keypress to the figure.\n\n        Parameters\n        ----------\n        key : str\n            The key to fake (e.g., ``'a'``).\n        fig : instance of Figure\n            The figure to pass the keypress to.\n        \"\"\"\n        return self._fake_keypress(key, fig=fig)", "metadata": {}}
{"_id": "mne_mne_viz/circle.py_circular_layout_code", "title": "circular_layout", "text": "def circular_layout(\n    node_names,\n    node_order,\n    start_pos=90,\n    start_between=True,\n    group_boundaries=None,\n    group_sep=10,\n):\n    \"\"\"Create layout arranging nodes on a circle.\n\n    Parameters\n    ----------\n    node_names : list of str\n        Node names.\n    node_order : list of str\n        List with node names defining the order in which the nodes are\n        arranged. Must have the elements as node_names but the order can be\n        different. The nodes are arranged clockwise starting at \"start_pos\"\n        degrees.\n    start_pos : float\n        Angle in degrees that defines where the first node is plotted.\n    start_between : bool\n        If True, the layout starts with the position between the nodes. This is\n        the same as adding \"180. / len(node_names)\" to start_pos.\n    group_boundaries : None | array-like\n        List of of boundaries between groups at which point a \"group_sep\" will\n        be inserted. E.g. \"[0, len(node_names) / 2]\" will create two groups.\n    group_sep : float\n        Group separation angle in degrees. See \"group_boundaries\".\n\n    Returns\n    -------\n    node_angles : array, shape=(n_node_names,)\n        Node angles in degrees.\n    \"\"\"\n    n_nodes = len(node_names)\n\n    if len(node_order) != n_nodes:\n        raise ValueError(\"node_order has to be the same length as node_names\")\n\n    if group_boundaries is not None:\n        boundaries = np.array(group_boundaries, dtype=np.int64)\n        if np.any(boundaries >= n_nodes) or np.any(boundaries < 0):\n            raise ValueError('\"group_boundaries\" has to be between 0 and n_nodes - 1.')\n        if len(boundaries) > 1 and np.any(np.diff(boundaries) <= 0):\n            raise ValueError('\"group_boundaries\" must have non-decreasing values.')\n        n_group_sep = len(group_boundaries)\n    else:\n        n_group_sep = 0\n        boundaries = None\n\n    # convert it to a list with indices\n    node_order = [node_order.index(name) for name in node_names]\n    node_order = np.array(node_order)\n    if len(np.unique(node_order)) != n_nodes:\n        raise ValueError(\"node_order has repeated entries\")\n\n    node_sep = (360.0 - n_group_sep * group_sep) / n_nodes\n\n    if start_between:\n        start_pos += node_sep / 2\n\n        if boundaries is not None and boundaries[0] == 0:\n            # special case when a group separator is at the start\n            start_pos += group_sep / 2\n            boundaries = boundaries[1:] if n_group_sep > 1 else None\n\n    node_angles = np.ones(n_nodes, dtype=np.float64) * node_sep\n    node_angles[0] = start_pos\n    if boundaries is not None:\n        node_angles[boundaries] += group_sep\n\n    node_angles = np.cumsum(node_angles)[node_order]\n\n    return node_angles", "metadata": {}}
{"_id": "mne_mne_viz/circle.py_plot_channel_labels_circle_code", "title": "plot_channel_labels_circle", "text": "def plot_channel_labels_circle(labels, colors=None, picks=None, **kwargs):\n    \"\"\"Plot labels for each channel in a circle plot.\n\n    .. note:: This primarily makes sense for sEEG channels where each\n              channel can be assigned an anatomical label as the electrode\n              passes through various brain areas.\n\n    Parameters\n    ----------\n    labels : dict\n        Lists of labels (values) associated with each channel (keys).\n    colors : dict\n        The color (value) for each label (key).\n    picks : list | tuple\n        The channels to consider.\n    **kwargs : kwargs\n        Keyword arguments for\n        :func:`mne_connectivity.viz.plot_connectivity_circle`.\n\n    Returns\n    -------\n    fig : instance of matplotlib.figure.Figure\n        The figure handle.\n    axes : instance of matplotlib.projections.polar.PolarAxes\n        The subplot handle.\n    \"\"\"\n    from matplotlib.colors import LinearSegmentedColormap\n\n    _validate_type(labels, dict, \"labels\")\n    _validate_type(colors, (dict, None), \"colors\")\n    _validate_type(picks, (list, tuple, None), \"picks\")\n    if picks is not None:\n        labels = {k: v for k, v in labels.items() if k in picks}\n    ch_names = list(labels.keys())\n    all_labels = list(set([label for val in labels.values() for label in val]))\n    n_labels = len(all_labels)\n    if colors is not None:\n        for label in all_labels:\n            if label not in colors:\n                raise ValueError(f\"No color provided for {label} in `colors`\")\n        # update all_labels, there may be unconnected labels in colors\n        all_labels = list(colors.keys())\n        n_labels = len(all_labels)\n        # make colormap\n        label_colors = [colors[label] for label in all_labels]\n        node_colors = [\"black\"] * len(ch_names) + label_colors\n        label_cmap = LinearSegmentedColormap.from_list(\n            \"label_cmap\", label_colors, N=len(label_colors)\n        )\n    else:\n        node_colors = None\n\n    node_names = ch_names + all_labels\n    con = np.zeros((len(node_names), len(node_names))) * np.nan\n    for idx, ch_name in enumerate(ch_names):\n        for label in labels[ch_name]:\n            node_idx = node_names.index(label)\n            label_color = all_labels.index(label) / n_labels\n            con[idx, node_idx] = con[node_idx, idx] = label_color  # symmetric\n    # plot\n    node_order = ch_names + all_labels[::-1]\n    node_angles = circular_layout(\n        node_names, node_order, start_pos=90, group_boundaries=[0, len(ch_names)]\n    )\n    # provide defaults but don't overwrite\n    if \"node_angles\" not in kwargs:\n        kwargs.update(node_angles=node_angles)\n    if \"colorbar\" not in kwargs:\n        kwargs.update(colorbar=False)\n    if \"node_colors\" not in kwargs:\n        kwargs.update(node_colors=node_colors)\n    if \"vmin\" not in kwargs:\n        kwargs.update(vmin=0)\n    if \"vmax\" not in kwargs:\n        kwargs.update(vmax=1)\n    if \"colormap\" not in kwargs:\n        kwargs.update(colormap=label_cmap)\n    return _plot_connectivity_circle(con, node_names, **kwargs)", "metadata": {}}
{"_id": "mne_mne_viz/_3d.py_plot_head_positions_code", "title": "plot_head_positions", "text": "def plot_head_positions(\n    pos,\n    mode=\"traces\",\n    cmap=\"viridis\",\n    direction=\"z\",\n    *,\n    show=True,\n    destination=None,\n    info=None,\n    color=\"k\",\n    axes=None,\n    totals=False,\n):\n    \"\"\"Plot head positions.\n\n    Parameters\n    ----------\n    pos : ndarray, shape (n_pos, 10) | list of ndarray\n        The head position data. Can also be a list to treat as a\n        concatenation of runs.\n    mode : str\n        Can be 'traces' (default) to show position and quaternion traces,\n        or 'field' to show the position as a vector field over time.\n    cmap : colormap\n        Colormap to use for the trace plot, default is \"viridis\".\n    direction : str\n        Can be any combination of \"x\", \"y\", or \"z\" (default: \"z\") to show\n        directional axes in \"field\" mode.\n    show : bool\n        Show figure if True. Defaults to True.\n    destination : path-like | array-like, shape (3,) | instance of Transform | None\n        The destination location for the head. See\n        :func:`mne.preprocessing.maxwell_filter` for details.\n\n        .. versionadded:: 0.16\n    %(info)s If provided, will be used to show the destination position when\n        ``destination is None``, and for showing the MEG sensors.\n\n        .. versionadded:: 0.16\n    color : color object\n        The color to use for lines in ``mode == 'traces'`` and quiver\n        arrows in ``mode == 'field'``.\n\n        .. versionadded:: 0.16\n    axes : array-like, shape (3, 2) or (4, 2)\n        The matplotlib axes to use.\n\n        .. versionadded:: 0.16\n        .. versionchanged:: 1.8\n           Added support for making use of this argument when ``mode=\"field\"``.\n    totals : bool\n        If True and in traces mode, show the total distance and angle in a fourth row.\n\n        .. versionadded:: 1.9\n\n    Returns\n    -------\n    fig : instance of matplotlib.figure.Figure\n        The figure.\n    \"\"\"\n    import matplotlib.pyplot as plt\n\n    from ..chpi import head_pos_to_trans_rot_t\n    from ..preprocessing.maxwell import _check_destination\n\n    _check_option(\"mode\", mode, [\"traces\", \"field\"])\n    _validate_type(totals, bool, \"totals\")\n    dest_info = dict(dev_head_t=None) if info is None else info\n    destination = _check_destination(destination, dest_info, \"head\")\n    if destination is not None:\n        destination = _ensure_trans(destination, \"head\", \"meg\")  # probably inv\n        destination = destination[\"trans\"]\n\n    if not isinstance(pos, list | tuple):\n        pos = [pos]\n    pos = list(pos)  # make our own mutable copy\n    for ii, p in enumerate(pos):\n        _validate_type(p, np.ndarray, f\"pos[{ii}]\")\n        p = np.array(p, float)\n        if p.ndim != 2 or p.shape[1] != 10:\n            raise ValueError(\n                \"pos (or each entry in pos if a list) must be \"\n                f\"dimension (N, 10), got {p.shape}\"\n            )\n        if ii > 0:  # concatenation\n            p[:, 0] += pos[ii - 1][-1, 0] - p[0, 0]\n        pos[ii] = p\n    borders = np.cumsum([len(pp) for pp in pos])\n    pos = np.concatenate(pos, axis=0)\n    trans, rot, t = head_pos_to_trans_rot_t(pos)  # also ensures pos is okay\n    # trans, rot, and t are for dev_head_t, but what we really want\n    # is head_dev_t (i.e., where the head origin is in device coords)\n    use_trans = (\n        np.einsum(\"ijk,ik->ij\", rot[:, :3, :3].transpose([0, 2, 1]), -trans) * 1000\n    )\n    use_rot = rot.transpose([0, 2, 1])\n    use_quats = -pos[:, 1:4]  # inverse (like doing rot.T)\n    surf = rrs = lims = None\n    if info is not None:\n        meg_picks = pick_types(info, meg=True, ref_meg=False, exclude=())\n        if len(meg_picks) > 0:\n            rrs = 1000 * np.array(\n                [info[\"chs\"][pick][\"loc\"][:3] for pick in meg_picks], float\n            )\n            if mode == \"traces\":\n                lims = np.array((rrs.min(0), rrs.max(0))).T\n            else:  # mode == 'field'\n                surf = get_meg_helmet_surf(info)\n                transform_surface_to(surf, \"meg\", info[\"dev_head_t\"], copy=False)\n                surf[\"rr\"] *= 1000.0\n    helmet_color = DEFAULTS[\"coreg\"][\"helmet_color\"]\n    if mode == \"traces\":\n        want_shape = (3 + int(totals), 2)\n        if axes is None:\n            _, axes = plt.subplots(*want_shape, sharex=True, layout=\"constrained\")\n        else:\n            axes = np.array(axes)\n        _check_option(\"axes.shape\", axes.shape, (want_shape,))\n        fig = axes[0, 0].figure\n        labels = [[\"x (mm)\", \"y (mm)\", \"z (mm)\"], [\"$q_1$\", \"$q_2$\", \"$q_3$\"]]\n        if totals:\n            labels[0].append(\"dist (mm)\")\n            labels[1].append(\"angle (\u00b0)\")\n        for ii, (quat, coord) in enumerate(zip(use_quats.T, use_trans.T)):\n            axes[ii, 0].plot(t, coord, color, lw=1.0, zorder=3)\n            axes[ii, 0].set(ylabel=labels[0][ii], xlim=t[[0, -1]])\n            axes[ii, 1].plot(t, quat, color, lw=1.0, zorder=3)\n            axes[ii, 1].set(ylabel=labels[1][ii], xlim=t[[0, -1]])\n            for b in borders[:-1]:\n                for jj in range(2):\n                    axes[ii, jj].axvline(t[b], color=\"r\")\n        if totals:\n            vals = [\n                np.linalg.norm(use_trans, axis=-1),\n                np.rad2deg(_angle_between_quats(use_quats)),\n            ]\n            ii = -1\n            for ci, val in enumerate(vals):\n                axes[ii, ci].plot(t, val, color, lw=1.0, zorder=3)\n                axes[ii, ci].set(ylabel=labels[ci][ii], xlim=t[[0, -1]])\n        titles = [\"Position\", \"Rotation\"]\n        for ci, title in enumerate(titles):\n            axes[0, ci].set(title=title)\n            axes[-1, ci].set(xlabel=\"Time (s)\")\n        if rrs is not None:\n            pos_bads = np.any(\n                [\n                    (use_trans[:, ii] <= lims[ii, 0])\n                    | (use_trans[:, ii] >= lims[ii, 1])\n                    for ii in range(3)\n                ],\n                axis=0,\n            )\n            for ii in range(3):\n                oidx = list(range(ii)) + list(range(ii + 1, 3))\n                # knowing it will generally be spherical, we can approximate\n                # how far away we are along the axis line by taking the\n                # point to the left and right with the smallest distance\n                dists = cdist(rrs[:, oidx], use_trans[:, oidx])\n                left = rrs[:, [ii]] < use_trans[:, ii]\n                left_dists_all = dists.copy()\n                left_dists_all[~left] = np.inf\n                # Don't show negative Z direction\n                if ii != 2 and np.isfinite(left_dists_all).any():\n                    idx = np.argmin(left_dists_all, axis=0)\n                    left_dists = rrs[idx, ii]\n                    bads = (\n                        ~np.isfinite(left_dists_all[idx, np.arange(len(idx))])\n                        | pos_bads\n                    )\n                    left_dists[bads] = np.nan\n                    axes[ii, 0].plot(\n                        t, left_dists, color=helmet_color, ls=\"-\", lw=0.5, zorder=2\n                    )\n                else:\n                    axes[ii, 0].axhline(\n                        lims[ii][0], color=helmet_color, ls=\"-\", lw=0.5, zorder=2\n                    )\n                right_dists_all = dists\n                right_dists_all[left] = np.inf\n                if np.isfinite(right_dists_all).any():\n                    idx = np.argmin(right_dists_all, axis=0)\n                    right_dists = rrs[idx, ii]\n                    bads = (\n                        ~np.isfinite(right_dists_all[idx, np.arange(len(idx))])\n                        | pos_bads\n                    )\n                    right_dists[bads] = np.nan\n                    axes[ii, 0].plot(\n                        t, right_dists, color=helmet_color, ls=\"-\", lw=0.5, zorder=2\n                    )\n                else:\n                    axes[ii, 0].axhline(\n                        lims[ii][1], color=helmet_color, ls=\"-\", lw=0.5, zorder=2\n                    )\n\n        for ii in range(3):\n            axes[ii, 1].set(ylim=[-1, 1])\n\n        if destination is not None:\n            vals = np.array(\n                [1000 * destination[:3, 3], rot_to_quat(destination[:3, :3])]\n            ).T.ravel()\n            for ax, val in zip(axes[:3].ravel(), vals):\n                ax.axhline(val, color=\"r\", ls=\":\", zorder=2, lw=1.0)\n            if totals:\n                dest_ang, dest_dist = _angle_dist_between_rigid(\n                    destination,\n                    angle_units=\"deg\",\n                    distance_units=\"mm\",\n                )\n                axes[-1, 0].axhline(dest_dist, color=\"r\", ls=\":\", zorder=2, lw=1.0)\n                axes[-1, 1].axhline(dest_ang, color=\"r\", ls=\":\", zorder=2, lw=1.0)\n\n    else:  # mode == 'field':\n        from matplotlib.colors import Normalize\n        from mpl_toolkits.mplot3d import Axes3D  # noqa: F401, analysis:ignore\n        from mpl_toolkits.mplot3d.art3d import Line3DCollection\n\n        _validate_type(axes, (Axes3D, None), \"ax\", extra=\"when mode='field'\")\n        if axes is None:\n            _, ax = plt.subplots(\n                1, subplot_kw=dict(projection=\"3d\"), layout=\"constrained\"\n            )\n        else:\n            ax = axes\n        fig = ax.get_figure()\n        del axes\n\n        # First plot the trajectory as a colormap:\n        # http://matplotlib.org/examples/pylab_examples/multicolored_line.html\n        pts = use_trans[:, np.newaxis]\n        segments = np.concatenate([pts[:-1], pts[1:]], axis=1)\n        norm = Normalize(t[0], t[-2])\n        lc = Line3DCollection(segments, cmap=cmap, norm=norm)\n        lc.set_array(t[:-1])\n        ax.add_collection(lc)\n        # now plot the head directions as a quiver\n        dir_idx = dict(x=0, y=1, z=2)\n        kwargs = dict(pivot=\"tail\")\n        for d, length in zip(direction, [5.0, 2.5, 1.0]):\n            use_dir = use_rot[:, :, dir_idx[d]]\n            # draws stems, then heads\n            array = np.concatenate((t, np.repeat(t, 2)))\n            ax.quiver(\n                use_trans[:, 0],\n                use_trans[:, 1],\n                use_trans[:, 2],\n                use_dir[:, 0],\n                use_dir[:, 1],\n                use_dir[:, 2],\n                norm=norm,\n                cmap=cmap,\n                array=array,\n                length=length,\n                **kwargs,\n            )\n            if destination is not None:\n                ax.quiver(\n                    destination[0, 3],\n                    destination[1, 3],\n                    destination[2, 3],\n                    destination[dir_idx[d], 0],\n                    destination[dir_idx[d], 1],\n                    destination[dir_idx[d], 2],\n                    color=color,\n                    length=length,\n                    **kwargs,\n                )\n        mins = use_trans.min(0)\n        maxs = use_trans.max(0)\n        if surf is not None:\n            ax.plot_trisurf(\n                *surf[\"rr\"].T,\n                triangles=surf[\"tris\"],\n                color=helmet_color,\n                alpha=0.1,\n                shade=False,\n            )\n            ax.scatter(*rrs.T, s=1, color=helmet_color)\n            mins = np.minimum(mins, rrs.min(0))\n            maxs = np.maximum(maxs, rrs.max(0))\n        scale = (maxs - mins).max() / 2.0\n        xlim, ylim, zlim = (maxs + mins)[:, np.newaxis] / 2.0 + [-scale, scale]\n        ax.set(xlabel=\"x\", ylabel=\"y\", zlabel=\"z\", xlim=xlim, ylim=ylim, zlim=zlim)\n        _set_aspect_equal(ax)\n        ax.view_init(30, 45)\n    plt_show(show)\n    return fig", "metadata": {}}
{"_id": "mne_mne_viz/_3d.py_plot_evoked_field_code", "title": "plot_evoked_field", "text": "def plot_evoked_field(\n    evoked,\n    surf_maps,\n    time=None,\n    time_label=\"t = %0.0f ms\",\n    n_jobs=None,\n    fig=None,\n    vmax=None,\n    n_contours=21,\n    *,\n    show_density=True,\n    alpha=None,\n    interpolation=\"nearest\",\n    interaction=\"terrain\",\n    time_viewer=\"auto\",\n    verbose=None,\n):\n    \"\"\"Plot MEG/EEG fields on head surface and helmet in 3D.\n\n    Parameters\n    ----------\n    evoked : instance of mne.Evoked\n        The evoked object.\n    surf_maps : list\n        The surface mapping information obtained with make_field_map.\n    time : float | None\n        The time point at which the field map shall be displayed. If None,\n        the average peak latency (across sensor types) is used.\n    time_label : str | None\n        How to print info about the time instant visualized.\n    %(n_jobs)s\n    fig : Figure3D | mne.viz.Brain | None\n        If None (default), a new figure will be created, otherwise it will\n        plot into the given figure.\n\n        .. versionadded:: 0.20\n        .. versionadded:: 1.4\n            ``fig`` can also be a ``Brain`` figure.\n    vmax : float | dict | None\n        Maximum intensity. Can be a dictionary with two entries ``\"eeg\"`` and ``\"meg\"``\n        to specify separate values for EEG and MEG fields respectively. Can be\n        ``None`` to use the maximum value of the data.\n\n        .. versionadded:: 0.21\n        .. versionadded:: 1.4\n            ``vmax`` can be a dictionary to specify separate values for EEG and\n            MEG fields.\n    n_contours : int\n        The number of contours.\n\n        .. versionadded:: 0.21\n    show_density : bool\n        Whether to draw the field density as an overlay on top of the helmet/head\n        surface. Defaults to ``True``.\n\n        .. versionadded:: 1.6\n    alpha : float | dict | None\n        Opacity of the meshes (between 0 and 1). Can be a dictionary with two\n        entries ``\"eeg\"`` and ``\"meg\"`` to specify separate values for EEG and\n        MEG fields respectively. Can be ``None`` to use 1.0 when a single field\n        map is shown, or ``dict(eeg=1.0, meg=0.5)`` when both field maps are shown.\n\n        .. versionadded:: 1.4\n    %(interpolation_brain_time)s\n\n        .. versionadded:: 1.6\n    %(interaction_scene)s\n        Defaults to ``'terrain'``.\n\n        .. versionadded:: 1.1\n    time_viewer : bool | str\n        Display time viewer GUI. Can also be ``\"auto\"``, which will mean\n        ``True`` if there is more than one time point and ``False`` otherwise.\n\n        .. versionadded:: 1.6\n    %(verbose)s\n\n    Returns\n    -------\n    fig : Figure3D | mne.viz.EvokedField\n        Without the time viewer active, the figure is returned. With the time\n        viewer active, an object is returned that can be used to control\n        different aspects of the figure.\n    \"\"\"\n    ef = EvokedField(\n        evoked,\n        surf_maps,\n        time=time,\n        time_label=time_label,\n        n_jobs=n_jobs,\n        fig=fig,\n        vmax=vmax,\n        n_contours=n_contours,\n        alpha=alpha,\n        show_density=show_density,\n        interpolation=interpolation,\n        interaction=interaction,\n        time_viewer=time_viewer,\n        verbose=verbose,\n    )\n    if ef.time_viewer:\n        return ef\n    else:\n        return ef._renderer.scene()", "metadata": {}}
{"_id": "mne_mne_viz/_3d.py_plot_alignment_code", "title": "plot_alignment", "text": "def plot_alignment(\n    info=None,\n    trans=None,\n    subject=None,\n    subjects_dir=None,\n    surfaces=\"auto\",\n    coord_frame=\"auto\",\n    meg=None,\n    eeg=\"original\",\n    fwd=None,\n    dig=False,\n    ecog=True,\n    src=None,\n    mri_fiducials=False,\n    bem=None,\n    seeg=True,\n    fnirs=True,\n    show_axes=False,\n    dbs=True,\n    fig=None,\n    interaction=\"terrain\",\n    sensor_colors=None,\n    *,\n    sensor_scales=None,\n    verbose=None,\n):\n    \"\"\"Plot head, sensor, and source space alignment in 3D.\n\n    Parameters\n    ----------\n    %(info)s If None (default), no sensor information will be shown.\n    %(trans)s \"auto\" will load trans from the FreeSurfer directory\n        specified by ``subject`` and ``subjects_dir`` parameters.\n\n        .. versionchanged:: 0.19\n            Support for 'fsaverage' argument.\n    %(subject)s Can be omitted if ``src`` is provided.\n    %(subjects_dir)s\n    surfaces : str | list | dict\n        Surfaces to plot. Supported values:\n\n        * scalp: one of 'head', 'outer_skin' (alias for 'head'),\n          'head-dense', or 'seghead' (alias for 'head-dense')\n        * skull: 'outer_skull', 'inner_skull', 'brain' (alias for\n          'inner_skull')\n        * brain: one of 'pial', 'white', 'inflated', or 'brain'\n          (alias for 'pial').\n\n        Can be dict to specify alpha values for each surface. Use None\n        to specify default value. Specified values must be between 0 and 1.\n        for example::\n\n            surfaces=dict(brain=0.4, outer_skull=0.6, head=None)\n\n        Defaults to 'auto', which will look for a head surface and plot\n        it if found.\n\n        .. note:: For single layer BEMs it is recommended to use ``'brain'``.\n    coord_frame : 'auto' | 'head' | 'meg' | 'mri'\n        The coordinate frame to use. If ``'auto'`` (default), chooses ``'mri'``\n        if ``trans`` was passed, and ``'head'`` otherwise.\n\n        .. versionchanged:: 1.0\n           Defaults to ``'auto'``.\n    %(meg)s\n    %(eeg)s\n    %(fwd)s\n    dig : bool | 'fiducials'\n        If True, plot the digitization points; 'fiducials' to plot fiducial\n        points only.\n    %(ecog)s\n    src : instance of SourceSpaces | None\n        If not None, also plot the source space points.\n    mri_fiducials : bool | str | path-like\n        Plot MRI fiducials (default False). If ``True``, look for a file with\n        the canonical name (``bem/{subject}-fiducials.fif``). If ``str``,\n        it can be ``'estimated'`` to use :func:`mne.coreg.get_mni_fiducials`,\n        otherwise it should provide the full path to the fiducials file.\n\n        .. versionadded:: 0.22\n           Support for ``'estimated'``.\n    bem : list of dict | instance of ConductorModel | None\n        Can be either the BEM surfaces (list of dict), a BEM solution or a\n        sphere model. If None, we first try loading\n        ``'$SUBJECTS_DIR/$SUBJECT/bem/$SUBJECT-$SOURCE.fif'``, and then look\n        for ``'$SUBJECT*$SOURCE.fif'`` in the same directory. For\n        ``'outer_skin'``, the subjects bem and bem/flash folders are searched.\n        Defaults to None.\n    %(seeg)s\n    %(fnirs)s\n        .. versionadded:: 0.20\n    show_axes : bool\n        If True (default False), coordinate frame axis indicators will be\n        shown:\n\n        * head in pink.\n        * MRI in gray (if ``trans is not None``).\n        * MEG in blue (if MEG sensors are present).\n\n        .. versionadded:: 0.16\n    %(dbs)s\n    fig : Figure3D | None\n        PyVista scene in which to plot the alignment.\n        If ``None``, creates a new 600x600 pixel figure with black background.\n\n        .. versionadded:: 0.16\n    %(interaction_scene)s\n\n        .. versionadded:: 0.16\n        .. versionchanged:: 1.0\n           Defaults to ``'terrain'``.\n    %(sensor_colors)s\n\n        .. versionchanged:: 1.6\n            Support for passing a ``dict`` was added.\n    %(sensor_scales)s\n\n        .. versionadded:: 1.9\n    %(verbose)s\n\n    Returns\n    -------\n    fig : instance of Figure3D\n        The figure.\n\n    See Also\n    --------\n    mne.viz.plot_bem\n\n    Notes\n    -----\n    This function serves the purpose of checking the validity of the many\n    different steps of source reconstruction:\n\n    - Transform matrix (keywords ``trans``, ``meg`` and ``mri_fiducials``),\n    - BEM surfaces (keywords ``bem`` and ``surfaces``),\n    - sphere conductor model (keywords ``bem`` and ``surfaces``) and\n    - source space (keywords ``surfaces`` and ``src``).\n\n    .. versionadded:: 0.15\n    \"\"\"\n    # Update the backend\n    from ..bem import ConductorModel, _bem_find_surface, _ensure_bem_surfaces\n    from ..source_space._source_space import _ensure_src\n    from .backends.renderer import _get_renderer\n\n    meg, eeg, fnirs, warn_meg, sensor_alpha = _handle_sensor_types(meg, eeg, fnirs)\n    _check_option(\"interaction\", interaction, [\"trackball\", \"terrain\"])\n\n    info = create_info(1, 1000.0, \"misc\") if info is None else info\n    _validate_type(info, \"info\")\n\n    # Handle surfaces:\n    if surfaces == \"auto\" and trans is None:\n        surfaces = list()  # if no `trans` can't plot mri surfaces\n    if isinstance(surfaces, str):\n        surfaces = [surfaces]\n    if isinstance(surfaces, dict):\n        user_alpha = surfaces.copy()\n        for key, val in user_alpha.items():\n            _validate_type(key, \"str\", f\"surfaces key {repr(key)}\")\n            _validate_type(val, (None, \"numeric\"), f\"surfaces[{repr(key)}]\")\n            if val is not None:\n                user_alpha[key] = float(val)\n                if not 0 <= user_alpha[key] <= 1:\n                    raise ValueError(\n                        f\"surfaces[{repr(key)}] ({val}) must be between 0 and 1\"\n                    )\n    else:\n        user_alpha = {}\n    surfaces = list(surfaces)\n    for si, s in enumerate(surfaces):\n        _validate_type(s, \"str\", f\"surfaces[{si}]\")\n\n    bem = _ensure_bem_surfaces(bem, extra_allow=(ConductorModel, None))\n    assert isinstance(bem, ConductorModel) or bem is None\n\n    _check_option(\"coord_frame\", coord_frame, [\"head\", \"meg\", \"mri\", \"auto\"])\n    if coord_frame == \"auto\":\n        coord_frame = \"head\" if trans is None else \"mri\"\n\n    if src is not None:\n        src = _ensure_src(src)\n        src_subject = src._subject\n        subject = src_subject if subject is None else subject\n        if src_subject is not None and subject != src_subject:\n            raise ValueError(\n                f'subject (\"{subject}\") did not match the '\n                f'subject name in src (\"{src_subject}\")'\n            )\n\n    trans, trans_type = _find_trans(\n        trans=trans,\n        subject=subject,\n        subjects_dir=subjects_dir,\n    )\n\n    picks = pick_types(\n        info,\n        meg=(\"sensors\" in meg),\n        ref_meg=(\"ref\" in meg),\n        eeg=(len(eeg) > 0),\n        ecog=ecog,\n        seeg=seeg,\n        dbs=dbs,\n        fnirs=(len(fnirs) > 0),\n    )\n    if trans_type == \"identity\":\n        # Some stuff is natively in head coords, others in MRI coords\n        msg = (\n            \"A head<->mri transformation matrix (trans) is required \"\n            f\"to plot {{}} in {coord_frame} coordinates, \"\n            \"`trans=None` is not allowed\"\n        )\n        if fwd is not None:\n            fwd_frame = _frame_to_str[fwd[\"coord_frame\"]]\n            if fwd_frame != coord_frame:\n                raise ValueError(\n                    msg.format(f\"a {fwd_frame}-coordinate forward solution\")\n                )\n        if src is not None:\n            src_frame = _frame_to_str[src[0][\"coord_frame\"]]\n            if src_frame != coord_frame:\n                raise ValueError(msg.format(f\"a {src_frame}-coordinate source space\"))\n        if mri_fiducials is not False and coord_frame != \"mri\":\n            raise ValueError(msg.format(\"mri fiducials\"))\n        # only enforce needing `trans` if there are channels in \"head\"/\"device\"\n        if picks.size and coord_frame == \"mri\":\n            raise ValueError(msg.format(\"sensors\"))\n        # if only plotting sphere model no trans needed\n        if bem is not None:\n            if not bem[\"is_sphere\"]:\n                if coord_frame != \"mri\":\n                    raise ValueError(msg.format(\"a BEM\"))\n            elif surfaces not in ([\"brain\"], []):  # can only plot these\n                raise ValueError(msg.format(\", \".join(surfaces) + \" surfaces\"))\n        elif len(surfaces) > 0 and coord_frame != \"mri\":\n            raise ValueError(msg.format(\", \".join(surfaces) + \" surfaces\"))\n        trans = Transform(\"head\", \"mri\")  # not used so just use identity\n    # get transforms\n    head_mri_t = _get_trans(trans, \"head\", \"mri\")[0]\n    to_cf_t = _get_transforms_to_coord_frame(info, head_mri_t, coord_frame=coord_frame)\n\n    # Surfaces:\n    # both the head and helmet will be in MRI coordinates after this\n    surfs = dict()\n\n    # Brain surface:\n    brain = sorted(set(surfaces) & set([\"brain\", \"pial\", \"white\", \"inflated\"]))\n    if len(brain) > 1:\n        raise ValueError(f\"Only one brain surface can be plotted, got {brain}.\")\n    brain = brain[0] if brain else False\n    if brain is not False:\n        surfaces.pop(surfaces.index(brain))\n        if bem is not None and bem[\"is_sphere\"] and brain == \"brain\":\n            surfs[\"lh\"] = _bem_find_surface(bem, \"brain\")\n        else:\n            brain = \"pial\" if brain == \"brain\" else brain\n            subjects_dir = get_subjects_dir(subjects_dir, raise_error=True)\n            for hemi in [\"lh\", \"rh\"]:\n                brain_fname = subjects_dir / subject / \"surf\" / f\"{hemi}.{brain}\"\n                if not brain_fname.is_file():\n                    raise RuntimeError(\n                        f\"No brain surface found for subject {subject}, \"\n                        f\"expected {brain_fname} to exist\"\n                    )\n                surfs[hemi] = _read_mri_surface(brain_fname)\n            subjects_dir = str(subjects_dir)\n\n    # Head surface:\n    head_keys = (\"auto\", \"head\", \"outer_skin\", \"head-dense\", \"seghead\")\n    head = [s for s in surfaces if s in head_keys]\n    if len(head) > 1:\n        raise ValueError(f\"Can only supply one head-like surface name, got {head}\")\n    head = head[0] if head else False\n    if head is not False:\n        surfaces.pop(surfaces.index(head))\n    elif \"projected\" in eeg:\n        raise ValueError(\n            \"A head surface is required to project EEG, \"\n            '\"head\", \"outer_skin\", \"head-dense\" or \"seghead\" '\n            'must be in surfaces or surfaces must be \"auto\"'\n        )\n\n    # Skull surface:\n    skulls = [s for s in surfaces if s in (\"outer_skull\", \"inner_skull\")]\n    for skull_name in skulls:\n        surfaces.pop(surfaces.index(skull_name))\n        skull = _get_skull_surface(\n            skull_name.split(\"_\")[0], subject, subjects_dir, bem=bem\n        )\n        skull[\"name\"] = skull_name  # set name for alpha\n        surfs[skull_name] = skull\n\n    # we've looked through all of them, raise if some remain\n    if len(surfaces) > 0:\n        raise ValueError(f\"Unknown surface type{_pl(surfaces)}: {surfaces}\")\n\n    # set colors and alphas\n    defaults = DEFAULTS[\"coreg\"]\n    no_deep = not (dbs or seeg) or pick_types(info, dbs=True, seeg=True).size == 0\n    max_alpha = 1.0 if no_deep else 0.75\n    hemi_val = 0.5\n    if src is None or (brain and any(s[\"type\"] == \"surf\" for s in src)):\n        hemi_val = max_alpha\n    alpha_range = np.linspace(max_alpha / 2.0, 0, 5)[: len(skulls) + 1]\n    if src is None and brain is False and len(skulls) == 0 and not show_axes:\n        head_alpha = max_alpha\n    else:\n        head_alpha = alpha_range[0]\n    alphas = dict(lh=hemi_val, rh=hemi_val)\n    colors = dict(lh=(0.5,) * 3, rh=(0.5,) * 3)\n    for idx, name in enumerate(skulls):\n        alphas[name] = alpha_range[idx + 1]\n        colors[name] = (0.95 - idx * 0.2, 0.85, 0.95 - idx * 0.2)\n    if brain is not False and brain in user_alpha:\n        alphas[\"lh\"] = alphas[\"rh\"] = user_alpha.pop(brain)\n    # replace default alphas with specified user_alpha\n    for k, v in user_alpha.items():\n        if v is not None:\n            alphas[k] = v\n        if k in head_keys and v is not None:\n            head_alpha = v\n    fid_colors = tuple(defaults[f\"{key}_color\"] for key in (\"lpa\", \"nasion\", \"rpa\"))\n\n    # initialize figure\n    renderer = _get_renderer(\n        fig,\n        name=f\"Sensor alignment: {subject}\",\n        bgcolor=(0.5, 0.5, 0.5),\n        size=(800, 800),\n    )\n    renderer.set_interaction(interaction)\n\n    # plot head\n    _, _, head_surf = _plot_head_surface(\n        renderer,\n        head,\n        subject,\n        subjects_dir,\n        bem,\n        coord_frame,\n        to_cf_t,\n        alpha=head_alpha,\n    )\n\n    # plot helmet\n    if \"helmet\" in meg and pick_types(info, meg=True).size > 0:\n        _, _, src_surf = _plot_helmet(\n            renderer,\n            info,\n            to_cf_t,\n            head_mri_t,\n            coord_frame,\n            alpha=sensor_alpha[\"meg_helmet\"],\n        )\n\n    # plot surfaces\n    if brain and \"lh\" not in surfs:  # one layer sphere\n        assert bem[\"coord_frame\"] == FIFF.FIFFV_COORD_HEAD\n        center = bem[\"r0\"].copy()\n        center = apply_trans(to_cf_t[\"head\"], center)\n        renderer.sphere(center, scale=0.01, color=colors[\"lh\"], opacity=alphas[\"lh\"])\n    if show_axes:\n        _plot_axes(renderer, info, to_cf_t, head_mri_t)\n\n    # plot points\n    _check_option(\"dig\", dig, (True, False, \"fiducials\"))\n    if dig:\n        if dig is True:\n            _plot_hpi_coils(renderer, info, to_cf_t)\n            _plot_head_shape_points(renderer, info, to_cf_t)\n        _plot_head_fiducials(renderer, info, to_cf_t, fid_colors)\n\n    if mri_fiducials:\n        _plot_mri_fiducials(\n            renderer, mri_fiducials, subjects_dir, subject, to_cf_t, fid_colors\n        )\n\n    for key, surf in surfs.items():\n        # Surfs can sometimes be in head coords (e.g., if coming from sphere)\n        assert isinstance(surf, dict), f\"{key}: {type(surf)}\"\n        surf = transform_surface_to(\n            surf, coord_frame, [to_cf_t[\"mri\"], to_cf_t[\"head\"]], copy=True\n        )\n        renderer.surface(\n            name=key,\n            surface=surf,\n            color=colors[key],\n            opacity=alphas[key],\n            backface_culling=(key != \"helmet\"),\n        )\n\n    # plot sensors (NB snapshot_brain_montage relies on the last thing being\n    # plotted being the sensors, so we need to do this after the surfaces)\n    if picks.size > 0:\n        _plot_sensors_3d(\n            renderer,\n            info,\n            to_cf_t,\n            picks,\n            meg,\n            eeg,\n            fnirs,\n            warn_meg,\n            head_surf,\n            \"m\",\n            sensor_alpha=sensor_alpha,\n            sensor_colors=sensor_colors,\n            sensor_scales=sensor_scales,\n        )\n\n    if src is not None:\n        atlas_ids, colors = read_freesurfer_lut()\n        for ss in src:\n            src_rr = ss[\"rr\"][ss[\"inuse\"].astype(bool)]\n            src_nn = ss[\"nn\"][ss[\"inuse\"].astype(bool)]\n\n            # update coordinate frame\n            src_trans = to_cf_t[_frame_to_str[src[0][\"coord_frame\"]]]\n            src_rr = apply_trans(src_trans, src_rr)\n            src_nn = apply_trans(src_trans, src_nn, move=False)\n\n            # volume sources\n            if ss[\"type\"] == \"vol\":\n                seg_name = ss.get(\"seg_name\", None)\n                if seg_name is not None and seg_name in colors:\n                    color = colors[seg_name][:3]\n                    color = tuple(i / 256.0 for i in color)\n                else:\n                    color = (1.0, 1.0, 0.0)\n\n            # surface and discrete sources\n            else:\n                color = (1.0, 1.0, 0.0)\n\n            if len(src_rr) > 0:\n                renderer.quiver3d(\n                    x=src_rr[:, 0],\n                    y=src_rr[:, 1],\n                    z=src_rr[:, 2],\n                    u=src_nn[:, 0],\n                    v=src_nn[:, 1],\n                    w=src_nn[:, 2],\n                    color=color,\n                    mode=\"cylinder\",\n                    scale=3e-3,\n                    opacity=0.75,\n                    glyph_height=0.25,\n                    glyph_center=(0.0, 0.0, 0.0),\n                    glyph_resolution=20,\n                    backface_culling=True,\n                )\n\n    if fwd is not None:\n        _plot_forward(renderer, fwd, to_cf_t[_frame_to_str[fwd[\"coord_frame\"]]])\n\n    renderer.set_camera(\n        azimuth=90, elevation=90, distance=0.6, focalpoint=(0.0, 0.0, 0.0)\n    )\n    renderer.show()\n    return renderer.scene()", "metadata": {}}
{"_id": "mne_mne_viz/_3d.py_link_brains_code", "title": "link_brains", "text": "def link_brains(brains, time=True, camera=False, colorbar=True, picking=False):\n    \"\"\"Plot multiple SourceEstimate objects with PyVista.\n\n    Parameters\n    ----------\n    brains : list, tuple or np.ndarray\n        The collection of brains to plot.\n    time : bool\n        If True, link the time controllers. Defaults to True.\n    camera : bool\n        If True, link the camera controls. Defaults to False.\n    colorbar : bool\n        If True, link the colorbar controllers. Defaults to True.\n    picking : bool\n        If True, link the vertices picked with the mouse. Defaults to False.\n    \"\"\"\n    from .backends.renderer import _get_3d_backend\n\n    if _get_3d_backend() != \"pyvistaqt\":\n        raise NotImplementedError(\n            f\"Expected 3d backend is pyvistaqt but {_get_3d_backend()} was given.\"\n        )\n    from ._brain import Brain, _LinkViewer\n\n    if not isinstance(brains, Iterable):\n        brains = [brains]\n    if len(brains) == 0:\n        raise ValueError(\"The collection of brains is empty.\")\n    for brain in brains:\n        if not isinstance(brain, Brain):\n            raise TypeError(f\"Expected type is Brain but {type(brain)} was given.\")\n        # enable time viewer if necessary\n        brain.setup_time_viewer()\n    subjects = [brain._subject for brain in brains]\n    if subjects.count(subjects[0]) != len(subjects):\n        raise RuntimeError(\"Cannot link brains from different subjects.\")\n\n    # link brains properties\n    _LinkViewer(\n        brains=brains,\n        time=time,\n        camera=camera,\n        colorbar=colorbar,\n        picking=picking,\n    )", "metadata": {}}
{"_id": "mne_mne_viz/_3d.py_plot_source_estimates_code", "title": "plot_source_estimates", "text": "def plot_source_estimates(\n    stc,\n    subject=None,\n    surface=\"inflated\",\n    hemi=\"lh\",\n    colormap=\"auto\",\n    time_label=\"auto\",\n    smoothing_steps=10,\n    transparent=True,\n    alpha=1.0,\n    time_viewer=\"auto\",\n    *,\n    subjects_dir=None,\n    figure=None,\n    views=\"auto\",\n    colorbar=True,\n    clim=\"auto\",\n    cortex=\"classic\",\n    size=800,\n    background=\"black\",\n    foreground=None,\n    initial_time=None,\n    time_unit=\"s\",\n    backend=\"auto\",\n    spacing=\"oct6\",\n    title=None,\n    show_traces=\"auto\",\n    src=None,\n    volume_options=1.0,\n    view_layout=\"vertical\",\n    add_data_kwargs=None,\n    brain_kwargs=None,\n    verbose=None,\n):\n    \"\"\"Plot SourceEstimate.\n\n    Parameters\n    ----------\n    stc : SourceEstimate\n        The source estimates to plot.\n    %(subject_none)s\n        If ``None``, ``stc.subject`` will be used.\n    surface : str\n        The type of surface (inflated, white etc.).\n    hemi : str\n        Hemisphere id (ie ``'lh'``, ``'rh'``, ``'both'``, or ``'split'``). In\n        the case of ``'both'``, both hemispheres are shown in the same window.\n        In the case of ``'split'`` hemispheres are displayed side-by-side\n        in different viewing panes.\n    %(colormap)s\n        The default ('auto') uses ``'hot'`` for one-sided data and\n        'mne' for two-sided data.\n    %(time_label)s\n    smoothing_steps : int\n        The amount of smoothing.\n    %(transparent)s\n    alpha : float\n        Alpha value to apply globally to the overlay. Has no effect with mpl\n        backend.\n    time_viewer : bool | str\n        Display time viewer GUI. Can also be 'auto', which will mean True\n        for the PyVista backend and False otherwise.\n\n        .. versionchanged:: 0.20.0\n           \"auto\" mode added.\n    %(subjects_dir)s\n    figure : instance of Figure3D | instance of matplotlib.figure.Figure | list | int | None\n        If None, a new figure will be created. If multiple views or a\n        split view is requested, this must be a list of the appropriate\n        length. If int is provided it will be used to identify the PyVista\n        figure by it's id or create a new figure with the given id. If an\n        instance of matplotlib figure, mpl backend is used for plotting.\n    %(views)s\n\n        When plotting a standard SourceEstimate (not volume, mixed, or vector)\n        and using the PyVista backend, ``views='flat'`` is also supported to\n        plot cortex as a flatmap.\n\n        Using multiple views (list) is not supported by the matplotlib backend.\n\n        .. versionchanged:: 0.21.0\n           Support for flatmaps.\n    colorbar : bool\n        If True, display colorbar on scene.\n    %(clim)s\n    cortex : str | tuple\n        Specifies how binarized curvature values are rendered.\n        Either the name of a preset Brain cortex colorscheme (one of\n        ``'classic'``, ``'bone'``, ``'low_contrast'``, or ``'high_contrast'``),\n        or the name of a colormap, or a tuple with values\n        ``(colormap, min, max, reverse)`` to fully specify the curvature\n        colors. Has no effect with the matplotlib backend.\n    size : float or tuple of float\n        The size of the window, in pixels. can be one number to specify\n        a square window, or the (width, height) of a rectangular window.\n        Has no effect with mpl backend.\n    background : matplotlib color\n        Color of the background of the display window.\n    foreground : matplotlib color | None\n        Color of the foreground of the display window. Has no effect with mpl\n        backend. None will choose white or black based on the background color.\n    initial_time : float | None\n        The time to display on the plot initially. ``None`` to display the\n        first time sample (default).\n    time_unit : ``'s'`` | ``'ms'``\n        Whether time is represented in seconds (\"s\", default) or\n        milliseconds (\"ms\").\n    backend : ``'auto'`` | ``'pyvistaqt'`` | ``'matplotlib'``\n        Which backend to use. If ``'auto'`` (default), tries to plot with\n        pyvistaqt, but resorts to matplotlib if no 3d backend is available.\n\n        .. versionadded:: 0.15.0\n    spacing : str\n        Only affects the matplotlib backend.\n        The spacing to use for the source space. Can be ``'ico#'`` for a\n        recursively subdivided icosahedron, ``'oct#'`` for a recursively\n        subdivided octahedron, or ``'all'`` for all points. In general, you can\n        speed up the plotting by selecting a sparser source space.\n        Defaults  to 'oct6'.\n\n        .. versionadded:: 0.15.0\n    %(title_stc)s\n\n        .. versionadded:: 0.17.0\n    %(show_traces)s\n    %(src_volume_options)s\n    %(view_layout)s\n    %(add_data_kwargs)s\n    %(brain_kwargs)s\n    %(verbose)s\n\n    Returns\n    -------\n    figure : instance of mne.viz.Brain | matplotlib.figure.Figure\n        An instance of :class:`mne.viz.Brain` or matplotlib figure.\n\n    Notes\n    -----\n    Flatmaps are available by default for ``fsaverage`` but not for other\n    subjects reconstructed by FreeSurfer. We recommend using\n    :func:`mne.compute_source_morph` to morph source estimates to ``fsaverage``\n    for flatmap plotting. If you want to construct your own flatmap for a given\n    subject, these links might help:\n\n    - https://surfer.nmr.mgh.harvard.edu/fswiki/FreeSurferOccipitalFlattenedPatch\n    - https://openwetware.org/wiki/Beauchamp:FreeSurfer\n    \"\"\"  # noqa: E501\n    from ..source_estimate import _BaseSourceEstimate, _check_stc_src\n    from .backends.renderer import _get_3d_backend, use_3d_backend\n\n    _check_stc_src(stc, src)\n    _validate_type(stc, _BaseSourceEstimate, \"stc\", \"source estimate\")\n    subjects_dir = get_subjects_dir(subjects_dir=subjects_dir, raise_error=True)\n    subject = _check_subject(stc.subject, subject)\n    _check_option(\"backend\", backend, [\"auto\", \"matplotlib\", \"pyvistaqt\", \"notebook\"])\n    plot_mpl = backend == \"matplotlib\"\n    if not plot_mpl:\n        if backend == \"auto\":\n            try:\n                backend = _get_3d_backend()\n            except (ImportError, ModuleNotFoundError):\n                warn(\"No 3D backend found. Resorting to matplotlib 3d.\")\n                plot_mpl = True\n    kwargs = dict(\n        subject=subject,\n        surface=surface,\n        hemi=hemi,\n        colormap=colormap,\n        time_label=time_label,\n        smoothing_steps=smoothing_steps,\n        subjects_dir=subjects_dir,\n        views=views,\n        clim=clim,\n        figure=figure,\n        initial_time=initial_time,\n        time_unit=time_unit,\n        background=background,\n        time_viewer=time_viewer,\n        colorbar=colorbar,\n        transparent=transparent,\n    )\n    if plot_mpl:\n        return _plot_mpl_stc(stc, spacing=spacing, **kwargs)\n    else:\n        with use_3d_backend(backend):\n            return _plot_stc(\n                stc,\n                overlay_alpha=alpha,\n                brain_alpha=alpha,\n                vector_alpha=alpha,\n                cortex=cortex,\n                foreground=foreground,\n                size=size,\n                scale_factor=None,\n                show_traces=show_traces,\n                src=src,\n                volume_options=volume_options,\n                view_layout=view_layout,\n                add_data_kwargs=add_data_kwargs,\n                brain_kwargs=brain_kwargs,\n                title=title,\n                **kwargs,\n            )", "metadata": {}}
{"_id": "mne_mne_viz/_3d.py_plot_volume_source_estimates_code", "title": "plot_volume_source_estimates", "text": "def plot_volume_source_estimates(\n    stc,\n    src,\n    subject=None,\n    subjects_dir=None,\n    mode=\"stat_map\",\n    bg_img=\"T1.mgz\",\n    colorbar=True,\n    colormap=\"auto\",\n    clim=\"auto\",\n    transparent=None,\n    show=True,\n    initial_time=None,\n    initial_pos=None,\n    verbose=None,\n):\n    \"\"\"Plot Nutmeg style volumetric source estimates using nilearn.\n\n    Parameters\n    ----------\n    stc : VectorSourceEstimate\n        The vector source estimate to plot.\n    src : instance of SourceSpaces | instance of SourceMorph\n        The source space. Can also be a SourceMorph to morph the STC to\n        a new subject (see Examples).\n\n        .. versionchanged:: 0.18\n           Support for :class:`~nibabel.spatialimages.SpatialImage`.\n    %(subject_none)s\n        If ``None``, ``stc.subject`` will be used.\n    %(subjects_dir)s\n    mode : ``'stat_map'`` | ``'glass_brain'``\n        The plotting mode to use. For ``'glass_brain'``, activation absolute values are\n        displayed after being transformed to a standard MNI brain.\n    bg_img : instance of SpatialImage | str\n        The background image used in the nilearn plotting function.\n        Can also be a string to use the ``bg_img`` file in the subject's\n        MRI directory (default is ``'T1.mgz'``).\n        Not used in \"glass brain\" plotting.\n    colorbar : bool\n        If True, display a colorbar on the right of the plots.\n    %(colormap)s\n    %(clim)s\n    %(transparent)s\n    show : bool\n        Show figures if True. Defaults to True.\n    initial_time : float | None\n        The initial time to plot. Can be None (default) to use the time point\n        with the maximal absolute value activation across all voxels\n        or the ``initial_pos`` voxel (if ``initial_pos is None`` or not,\n        respectively).\n\n        .. versionadded:: 0.19\n    initial_pos : ndarray, shape (3,) | None\n        The initial position to use (in m). Can be None (default) to use the\n        voxel with the maximum absolute value activation across all time points\n        or at ``initial_time`` (if ``initial_time is None`` or not,\n        respectively).\n\n        .. versionadded:: 0.19\n    %(verbose)s\n\n    Returns\n    -------\n    fig : instance of Figure\n        The figure.\n\n    Notes\n    -----\n    Click on any of the anatomical slices to explore the time series.\n    Clicking on any time point will bring up the corresponding anatomical map.\n\n    The left and right arrow keys can be used to navigate in time.\n    To move in time by larger steps, use shift+left and shift+right.\n\n    In ``'glass_brain'`` mode, values are transformed to the standard MNI\n    brain using the FreeSurfer Talairach transformation\n    ``$SUBJECTS_DIR/$SUBJECT/mri/transforms/talairach.xfm``.\n\n    .. versionadded:: 0.17\n\n    .. versionchanged:: 0.19\n       MRI volumes are automatically transformed to MNI space in\n       ``'glass_brain'`` mode.\n\n    Examples\n    --------\n    Passing a :class:`mne.SourceMorph` as the ``src``\n    parameter can be useful for plotting in a different subject's space\n    (here, a ``'sample'`` STC in ``'fsaverage'``'s space)::\n\n    >>> morph = mne.compute_source_morph(src_sample, subject_to='fsaverage')  # doctest: +SKIP\n    >>> fig = stc_vol_sample.plot(morph)  # doctest: +SKIP\n    \"\"\"  # noqa: E501\n    import nibabel as nib\n    from matplotlib import colors\n    from matplotlib import pyplot as plt\n\n    from ..morph import SourceMorph\n    from ..source_estimate import VolSourceEstimate\n    from ..source_space._source_space import _ensure_src\n\n    if not check_version(\"nilearn\", \"0.4\"):\n        raise RuntimeError(\"This function requires nilearn >= 0.4\")\n\n    from nilearn.image import index_img\n\n    _check_option(\"mode\", mode, (\"stat_map\", \"glass_brain\"))\n    _validate_type(stc, VolSourceEstimate, \"stc\")\n    if isinstance(src, SourceMorph):\n        img = src.apply(stc, \"nifti1\", mri_resolution=False, mri_space=False)\n        stc = src.apply(stc, mri_resolution=False, mri_space=False)\n        kind, src_subject = \"morph.subject_to\", src.subject_to\n    else:\n        src = _ensure_src(src, kind=\"volume\", extra=\" or SourceMorph\")\n        img = stc.as_volume(src, mri_resolution=False)\n        kind, src_subject = \"src subject\", src._subject\n    del src\n    _print_coord_trans(\n        Transform(\"mri_voxel\", \"ras\", img.affine),\n        prefix=\"Image affine \",\n        units=\"mm\",\n        level=\"debug\",\n    )\n    subject = _check_subject(src_subject, subject, first_kind=kind)\n\n    if mode == \"glass_brain\":\n        subject = _check_subject(stc.subject, subject)\n        ras_mni_t = read_ras_mni_t(subject, subjects_dir)\n        if not np.allclose(ras_mni_t[\"trans\"], np.eye(4)):\n            _print_coord_trans(ras_mni_t, prefix=\"Transforming subject \", units=\"mm\")\n            logger.info(\"\")\n            # To get from voxel coords to world coords (i.e., define affine)\n            # we would apply img.affine, then also apply ras_mni_t, which\n            # transforms from the subject's RAS to MNI RAS. So we left-multiply\n            # these.\n            img = nib.Nifti1Image(img.dataobj, np.dot(ras_mni_t[\"trans\"], img.affine))\n        bg_img = None  # not used\n    else:  # stat_map\n        if bg_img is None:\n            bg_img = \"T1.mgz\"\n        bg_img = _load_subject_mri(bg_img, stc, subject, subjects_dir, \"bg_img\")\n\n    params = dict(\n        stc=stc,\n        mode=mode,\n        img=img,\n        bg_img=bg_img,\n        colorbar=colorbar,\n    )\n    vertices = np.hstack(stc.vertices)\n    stc_ijk = np.array(np.unravel_index(vertices, img.shape[:3], order=\"F\")).T\n    assert stc_ijk.shape == (vertices.size, 3)\n    params[\"dist_to_verts\"] = _DistanceQuery(apply_trans(img.affine, stc_ijk))\n    params[\"vertices\"] = vertices\n    del kind, stc_ijk\n\n    if initial_time is None:\n        time_sl = slice(0, None)\n    else:\n        initial_time = float(initial_time)\n        logger.info(f\"Fixing initial time: {initial_time} s\")\n        initial_time = np.argmin(np.abs(stc.times - initial_time))\n        time_sl = slice(initial_time, initial_time + 1)\n    if initial_pos is None:  # find max pos and (maybe) time\n        loc_idx, time_idx = np.unravel_index(\n            np.abs(stc.data[:, time_sl]).argmax(), stc.data[:, time_sl].shape\n        )\n        time_idx += time_sl.start\n    else:  # position specified\n        initial_pos = np.array(initial_pos, float)\n        if initial_pos.shape != (3,):\n            raise ValueError(\n                \"initial_pos must be float ndarray with shape \"\n                f\"(3,), got shape {initial_pos.shape}\"\n            )\n        initial_pos *= 1000\n        logger.info(f\"Fixing initial position: {initial_pos.tolist()} mm\")\n        loc_idx = _cut_coords_to_idx(initial_pos, params[\"dist_to_verts\"])\n        if initial_time is not None:  # time also specified\n            time_idx = time_sl.start\n        else:  # find the max\n            time_idx = np.argmax(np.abs(stc.data[loc_idx]))\n    img_idx = params[\"img_idx\"] = index_img(img, time_idx)\n    assert img_idx.shape == img.shape[:3]\n    del initial_time, initial_pos\n    ijk = np.unravel_index(vertices[loc_idx], img.shape[:3], order=\"F\")\n    cut_coords = _ijk_to_cut_coords(ijk, img_idx)\n    np.testing.assert_allclose(_cut_coords_to_ijk(cut_coords, img_idx), ijk)\n    logger.info(\n        f\"Showing: t = {stc.times[time_idx]:0.3f} s, \"\n        f\"{_str_ras(cut_coords)}, \"\n        f\"{_str_vox(ijk)}, \"\n        f\"{vertices[loc_idx]:d} vertex\"\n    )\n    del ijk\n\n    # Plot initial figure\n    fig, (axes, ax_time) = plt.subplots(2, layout=\"constrained\")\n    axes.set(xticks=[], yticks=[])\n    marker = \"o\" if len(stc.times) == 1 else None\n    ydata = stc.data[loc_idx]\n    h = ax_time.plot(stc.times, ydata, color=\"k\", marker=marker)[0]\n    if len(stc.times) > 1:\n        ax_time.set(xlim=stc.times[[0, -1]])\n    ax_time.set(xlabel=\"Time (s)\", ylabel=\"Activation\")\n    params[\"vert_legend\"] = ax_time.legend([h], [\"\"], title=\"Vertex\")\n    _update_vertlabel(loc_idx, params)\n    lx = ax_time.axvline(stc.times[time_idx], color=\"g\")\n    params.update(fig=fig, ax_time=ax_time, lx=lx, axes=axes)\n\n    allow_pos_lims = mode != \"glass_brain\"\n    mapdata = _process_clim(clim, colormap, transparent, stc.data, allow_pos_lims)\n    _separate_map(mapdata)\n    diverging = \"pos_lims\" in mapdata[\"clim\"]\n    ticks = _get_map_ticks(mapdata)\n    params.update(cbar_ticks=ticks, diverging=diverging)\n    colormap, scale_pts = _linearize_map(mapdata)\n    del mapdata\n\n    ylim = [min((scale_pts[0], ydata.min())), max((scale_pts[-1], ydata.max()))]\n    ylim = np.array(ylim) + np.array([-1, 1]) * 0.05 * np.diff(ylim)[0]\n    dup_neg = False\n    if stc.data.min() < 0:\n        ax_time.axhline(0.0, color=\"0.5\", ls=\"-\", lw=0.5, zorder=2)\n        dup_neg = not diverging  # glass brain with signed data\n    yticks = list(ticks)\n    if dup_neg:\n        yticks += [0] + list(-np.array(ticks))\n    yticks = np.unique(yticks)\n    ax_time.set(yticks=yticks)\n    ax_time.set(ylim=ylim)\n    del yticks\n\n    if not diverging:  # set eq above iff one-sided\n        # there is a bug in nilearn where this messes w/transparency\n        # Need to double the colormap\n        if (scale_pts < 0).any():\n            # XXX We should fix this, but it's hard to get nilearn to\n            # use arbitrary bounds :(\n            # Should get them to support non-mirrored colorbars, or\n            # at least a proper `vmin` for one-sided things.\n            # Hopefully this is a sufficiently rare use case!\n            raise ValueError(\n                \"Negative colormap limits for sequential \"\n                'control points clim[\"lims\"] not supported '\n                \"currently, consider shifting or flipping the \"\n                \"sign of your data for visualization purposes\"\n            )\n        # due to nilearn plotting weirdness, extend this to go\n        # -scale_pts[2]->scale_pts[2] instead of scale_pts[0]->scale_pts[2]\n        colormap = _get_cmap(colormap)\n        colormap = colormap(\n            np.interp(np.linspace(-1, 1, 256), scale_pts / scale_pts[2], [0, 0.5, 1])\n        )\n        colormap = colors.ListedColormap(colormap)\n    params.update(vmax=scale_pts[-1], scale_pts=scale_pts, colormap=colormap)\n\n    _plot_and_correct(params=params, cut_coords=cut_coords)\n\n    plt_show(show)\n    fig.canvas.mpl_connect(\n        \"button_press_event\", partial(_onclick, params=params, verbose=verbose)\n    )\n    fig.canvas.mpl_connect(\"key_press_event\", partial(_press, params=params))\n\n    return fig", "metadata": {}}
{"_id": "mne_mne_viz/_3d.py_plot_vector_source_estimates_code", "title": "plot_vector_source_estimates", "text": "def plot_vector_source_estimates(\n    stc,\n    subject=None,\n    hemi=\"lh\",\n    colormap=\"hot\",\n    time_label=\"auto\",\n    smoothing_steps=10,\n    transparent=None,\n    brain_alpha=0.4,\n    overlay_alpha=None,\n    vector_alpha=1.0,\n    scale_factor=None,\n    time_viewer=\"auto\",\n    *,\n    subjects_dir=None,\n    figure=None,\n    views=\"lateral\",\n    colorbar=True,\n    clim=\"auto\",\n    cortex=\"classic\",\n    size=800,\n    background=\"black\",\n    foreground=None,\n    initial_time=None,\n    time_unit=\"s\",\n    title=None,\n    show_traces=\"auto\",\n    src=None,\n    volume_options=1.0,\n    view_layout=\"vertical\",\n    add_data_kwargs=None,\n    brain_kwargs=None,\n    verbose=None,\n):\n    \"\"\"Plot VectorSourceEstimate with PyVista.\n\n    A \"glass brain\" is drawn and all dipoles defined in the source estimate\n    are shown using arrows, depicting the direction and magnitude of the\n    current moment at the dipole. Additionally, an overlay is plotted on top of\n    the cortex with the magnitude of the current.\n\n    Parameters\n    ----------\n    stc : VectorSourceEstimate | MixedVectorSourceEstimate\n        The vector source estimate to plot.\n    %(subject_none)s\n        If ``None``, ``stc.subject`` will be used.\n    hemi : str, 'lh' | 'rh' | 'split' | 'both'\n        The hemisphere to display.\n    %(colormap)s\n        This should be a sequential colormap.\n    %(time_label)s\n    smoothing_steps : int\n        The amount of smoothing.\n    %(transparent)s\n    brain_alpha : float\n        Alpha value to apply globally to the surface meshes. Defaults to 0.4.\n    overlay_alpha : float\n        Alpha value to apply globally to the overlay. Defaults to\n        ``brain_alpha``.\n    vector_alpha : float\n        Alpha value to apply globally to the vector glyphs. Defaults to 1.\n    scale_factor : float | None\n        Scaling factor for the vector glyphs. By default, an attempt is made to\n        automatically determine a sane value.\n    time_viewer : bool | str\n        Display time viewer GUI. Can be \"auto\", which is True for the PyVista\n        backend and False otherwise.\n\n        .. versionchanged:: 0.20\n           Added \"auto\" option and default.\n    subjects_dir : str\n        The path to the freesurfer subjects reconstructions.\n        It corresponds to Freesurfer environment variable SUBJECTS_DIR.\n    figure : instance of Figure3D | list | int | None\n        If None, a new figure will be created. If multiple views or a\n        split view is requested, this must be a list of the appropriate\n        length. If int is provided it will be used to identify the PyVista\n        figure by it's id or create a new figure with the given id.\n    %(views)s\n    colorbar : bool\n        If True, display colorbar on scene.\n    %(clim_onesided)s\n    cortex : str or tuple\n        Specifies how binarized curvature values are rendered.\n        either the name of a preset Brain cortex colorscheme (one of\n        'classic', 'bone', 'low_contrast', or 'high_contrast'), or the\n        name of a colormap, or a tuple with values (colormap, min,\n        max, reverse) to fully specify the curvature colors.\n    size : float or tuple of float\n        The size of the window, in pixels. can be one number to specify\n        a square window, or the (width, height) of a rectangular window.\n    background : matplotlib color\n        Color of the background of the display window.\n    foreground : matplotlib color | None\n        Color of the foreground of the display window.\n        None will choose black or white based on the background color.\n    initial_time : float | None\n        The time to display on the plot initially. ``None`` to display the\n        first time sample (default).\n    time_unit : 's' | 'ms'\n        Whether time is represented in seconds (\"s\", default) or\n        milliseconds (\"ms\").\n    %(title_stc)s\n\n        .. versionadded:: 1.9\n    %(show_traces)s\n    %(src_volume_options)s\n    %(view_layout)s\n    %(add_data_kwargs)s\n    %(brain_kwargs)s\n    %(verbose)s\n\n    Returns\n    -------\n    brain : mne.viz.Brain\n        A instance of :class:`mne.viz.Brain`.\n\n    Notes\n    -----\n    .. versionadded:: 0.15\n\n    If the current magnitude overlay is not desired, set ``overlay_alpha=0``\n    and ``smoothing_steps=1``.\n    \"\"\"\n    from ..source_estimate import _BaseVectorSourceEstimate\n\n    _validate_type(stc, _BaseVectorSourceEstimate, \"stc\", \"vector source estimate\")\n    return _plot_stc(\n        stc,\n        subject=subject,\n        surface=\"white\",\n        hemi=hemi,\n        colormap=colormap,\n        time_label=time_label,\n        smoothing_steps=smoothing_steps,\n        subjects_dir=subjects_dir,\n        views=views,\n        clim=clim,\n        figure=figure,\n        initial_time=initial_time,\n        time_unit=time_unit,\n        background=background,\n        time_viewer=time_viewer,\n        colorbar=colorbar,\n        transparent=transparent,\n        brain_alpha=brain_alpha,\n        overlay_alpha=overlay_alpha,\n        vector_alpha=vector_alpha,\n        cortex=cortex,\n        foreground=foreground,\n        size=size,\n        title=title,\n        scale_factor=scale_factor,\n        show_traces=show_traces,\n        src=src,\n        volume_options=volume_options,\n        view_layout=view_layout,\n        add_data_kwargs=add_data_kwargs,\n        brain_kwargs=brain_kwargs,\n    )", "metadata": {}}
{"_id": "mne_mne_viz/_3d.py_plot_sparse_source_estimates_code", "title": "plot_sparse_source_estimates", "text": "def plot_sparse_source_estimates(\n    src,\n    stcs,\n    colors=None,\n    linewidth=2,\n    fontsize=18,\n    bgcolor=(0.05, 0, 0.1),\n    opacity=0.2,\n    brain_color=(0.7,) * 3,\n    show=True,\n    high_resolution=False,\n    fig_name=None,\n    fig_number=None,\n    labels=None,\n    modes=(\"cone\", \"sphere\"),\n    scale_factors=(1, 0.6),\n    verbose=None,\n    **kwargs,\n):\n    \"\"\"Plot source estimates obtained with sparse solver.\n\n    Active dipoles are represented in a \"Glass\" brain.\n    If the same source is active in multiple source estimates it is\n    displayed with a sphere otherwise with a cone in 3D.\n\n    Parameters\n    ----------\n    src : dict\n        The source space.\n    stcs : instance of SourceEstimate or list of instances of SourceEstimate\n        The source estimates.\n    colors : list\n        List of colors.\n    linewidth : int\n        Line width in 2D plot.\n    fontsize : int\n        Font size.\n    bgcolor : tuple of length 3\n        Background color in 3D.\n    opacity : float in [0, 1]\n        Opacity of brain mesh.\n    brain_color : tuple of length 3\n        Brain color.\n    show : bool\n        Show figures if True.\n    high_resolution : bool\n        If True, plot on the original (non-downsampled) cortical mesh.\n    fig_name : str\n        PyVista figure name.\n    fig_number : int\n        Matplotlib figure number.\n    labels : ndarray or list of ndarray\n        Labels to show sources in clusters. Sources with the same\n        label and the waveforms within each cluster are presented in\n        the same color. labels should be a list of ndarrays when\n        stcs is a list ie. one label for each stc.\n    modes : list\n        Should be a list, with each entry being ``'cone'`` or ``'sphere'``\n        to specify how the dipoles should be shown.\n        The pivot for the glyphs in ``'cone'`` mode is always the tail\n        whereas the pivot in ``'sphere'`` mode is the center.\n    scale_factors : list\n        List of floating point scale factors for the markers.\n    %(verbose)s\n    **kwargs : kwargs\n        Keyword arguments to pass to renderer.mesh.\n\n    Returns\n    -------\n    surface : instance of Figure3D\n        The 3D figure containing the triangular mesh surface.\n    \"\"\"\n    import matplotlib.pyplot as plt\n\n    # Update the backend\n    from .backends.renderer import _get_renderer\n\n    linestyles = [\n        (\"solid\", \"solid\"),  # noqa: E241\n        (\"dashed\", \"dashed\"),  # noqa: E241\n        (\"dotted\", \"dotted\"),  # noqa: E241\n        (\"dashdot\", \"dashdot\"),  # noqa: E241\n        (\"loosely dotted\", (0, (1, 10))),  # noqa: E241\n        (\"dotted\", (0, (1, 1))),  # noqa: E241\n        (\"densely dotted\", (0, (1, 1))),  # noqa: E241\n        (\"loosely dashed\", (0, (5, 10))),  # noqa: E241\n        (\"dashed\", (0, (5, 5))),  # noqa: E241\n        (\"densely dashed\", (0, (5, 1))),  # noqa: E241\n        (\"loosely dashdotted\", (0, (3, 10, 1, 10))),  # noqa: E241\n        (\"dashdotted\", (0, (3, 5, 1, 5))),  # noqa: E241\n        (\"densely dashdotted\", (0, (3, 1, 1, 1))),  # noqa: E241\n        (\"dashdotdotted\", (0, (3, 5, 1, 5, 1, 5))),  # noqa: E241\n        (\"loosely dashdotdotted\", (0, (3, 10, 1, 10, 1, 10))),  # noqa: E241\n        (\"densely dashdotdotted\", (0, (3, 1, 1, 1, 1, 1))),  # noqa: E241\n    ]\n\n    known_modes = [\"cone\", \"sphere\"]\n    if not isinstance(modes, list | tuple) or not all(\n        mode in known_modes for mode in modes\n    ):\n        raise ValueError('mode must be a list containing only \"cone\" or \"sphere\"')\n    if not isinstance(stcs, list):\n        stcs = [stcs]\n    if labels is not None and not isinstance(labels, list):\n        labels = [labels]\n\n    if colors is None:\n        colors = _get_color_list()\n\n    linestyles = cycle(linestyles)\n    linestyles = [next(linestyles)[1] for _ in range(len(stcs))]\n\n    # Show 3D\n    lh_points = src[0][\"rr\"]\n    rh_points = src[1][\"rr\"]\n    points = np.r_[lh_points, rh_points]\n\n    lh_normals = src[0][\"nn\"]\n    rh_normals = src[1][\"nn\"]\n    normals = np.r_[lh_normals, rh_normals]\n\n    if high_resolution:\n        use_lh_faces = src[0][\"tris\"]\n        use_rh_faces = src[1][\"tris\"]\n    else:\n        use_lh_faces = src[0][\"use_tris\"]\n        use_rh_faces = src[1][\"use_tris\"]\n\n    use_faces = np.r_[use_lh_faces, lh_points.shape[0] + use_rh_faces]\n\n    points *= 170\n\n    vertnos = [np.r_[stc.lh_vertno, lh_points.shape[0] + stc.rh_vertno] for stc in stcs]\n    unique_vertnos = np.unique(np.concatenate(vertnos).ravel())\n\n    renderer = _get_renderer(bgcolor=bgcolor, size=(600, 600), name=fig_name)\n    renderer.mesh(\n        x=points[:, 0],\n        y=points[:, 1],\n        z=points[:, 2],\n        triangles=use_faces,\n        color=brain_color,\n        opacity=opacity,\n        backface_culling=True,\n        normals=normals,\n        **kwargs,\n    )\n\n    # Show time courses\n    fig = plt.figure(fig_number, layout=\"constrained\")\n    fig.clf()\n    ax = fig.add_subplot(111)\n\n    colors = cycle(colors)\n\n    logger.info(f\"Total number of active sources: {unique_vertnos}\")\n\n    if labels is not None:\n        colors = [\n            next(colors) for _ in range(np.unique(np.concatenate(labels).ravel()).size)\n        ]\n\n    for idx, v in enumerate(unique_vertnos):\n        # get indices of stcs it belongs to\n        ind = [k for k, vertno in enumerate(vertnos) if v in vertno]\n        is_common = len(ind) > 1\n\n        if labels is None:\n            c = next(colors)\n        else:\n            # if vertex is in different stcs than take label from first one\n            c = colors[labels[ind[0]][vertnos[ind[0]] == v]]\n\n        mode = modes[1] if is_common else modes[0]\n        scale_factor = scale_factors[1] if is_common else scale_factors[0]\n\n        if isinstance(scale_factor, np.ndarray | list | tuple) and len(\n            unique_vertnos\n        ) == len(scale_factor):\n            scale_factor = scale_factor[idx]\n\n        x, y, z = points[v]\n        nx, ny, nz = normals[v]\n        renderer.quiver3d(\n            x=x,\n            y=y,\n            z=z,\n            u=nx,\n            v=ny,\n            w=nz,\n            color=_to_rgb(c),\n            mode=mode,\n            scale=scale_factor,\n        )\n\n        for k in ind:\n            vertno = vertnos[k]\n            mask = vertno == v\n            assert np.sum(mask) == 1\n            linestyle = linestyles[k]\n            ax.plot(\n                1e3 * stcs[k].times,\n                1e9 * stcs[k].data[mask].ravel(),\n                c=c,\n                linewidth=linewidth,\n                linestyle=linestyle,\n            )\n\n    ax.set_xlabel(\"Time (ms)\", fontsize=fontsize)\n    ax.set_ylabel(\"Source amplitude (nAm)\", fontsize=fontsize)\n\n    if fig_name is not None:\n        ax.set_title(fig_name)\n    plt_show(show)\n\n    renderer.show()\n    renderer.set_camera(distance=\"auto\", focalpoint=\"auto\")\n    return renderer.scene()", "metadata": {}}
{"_id": "mne_mne_viz/_3d.py_plot_dipole_locations_code", "title": "plot_dipole_locations", "text": "def plot_dipole_locations(\n    dipoles,\n    trans=None,\n    subject=None,\n    subjects_dir=None,\n    mode=\"orthoview\",\n    coord_frame=\"mri\",\n    idx=\"gof\",\n    show_all=True,\n    ax=None,\n    block=False,\n    show=True,\n    scale=None,\n    color=None,\n    *,\n    highlight_color=\"r\",\n    fig=None,\n    title=None,\n    head_source=\"seghead\",\n    surf=\"pial\",\n    width=None,\n    verbose=None,\n):\n    \"\"\"Plot dipole locations.\n\n    If mode is set to 'arrow' or 'sphere', only the location of the first\n    time point of each dipole is shown else use the show_all parameter.\n\n    Parameters\n    ----------\n    dipoles : list of instances of Dipole | Dipole\n        The dipoles to plot.\n    trans : dict | None\n        The mri to head trans.\n        Can be None with mode set to '3d'.\n    subject : str | None\n        The FreeSurfer subject name (will be used to set the FreeSurfer\n        environment variable ``SUBJECT``).\n        Can be ``None`` with mode set to ``'3d'``.\n    %(subjects_dir)s\n    mode : str\n        Can be:\n\n        ``'arrow'`` or ``'sphere'``\n            Plot in 3D mode using PyVista with the given glyph type.\n        ``'orthoview'``\n            Plot in matplotlib ``Axes3D`` using matplotlib with MRI slices\n            shown on the sides of a cube, with the dipole(s) shown as arrows\n            extending outward from a dot (i.e., the arrows pivot on the tail).\n        ``'outlines'``\n            Plot in matplotlib ``Axes`` using a quiver of arrows for the\n            dipoles in three axes (axial, coronal, and sagittal views),\n            with the arrow pivoting in the middle of the arrow.\n\n        .. versionchanged:: 1.1\n           Added support for ``'outlines'``.\n    coord_frame : str\n        Coordinate frame to use: 'head' or 'mri'. Can also be 'mri_rotated'\n        when mode equals ``'outlines'``. Defaults to 'mri'.\n\n        .. versionadded:: 0.14.0\n        .. versionchanged:: 1.1\n           Added support for ``'mri_rotated'``.\n    idx : int | 'gof' | 'amplitude'\n        Index of the initially plotted dipole. Can also be 'gof' to plot the\n        dipole with highest goodness of fit value or 'amplitude' to plot the\n        dipole with the highest amplitude. The dipoles can also be browsed\n        through using up/down arrow keys or mouse scroll. Defaults to 'gof'.\n        Only used if mode equals 'orthoview'.\n\n        .. versionadded:: 0.14.0\n    show_all : bool\n        Whether to always plot all the dipoles. If ``True`` (default), the\n        active dipole is plotted as a red dot and its location determines the\n        shown MRI slices. The non-active dipoles are plotted as small blue\n        dots. If ``False``, only the active dipole is plotted.\n        Only used if ``mode='orthoview'``.\n\n        .. versionadded:: 0.14.0\n    ax : instance of matplotlib Axes3D | list of matplotlib Axes | None\n        Axes to plot into. If None (default), axes will be created.\n        If mode equals ``'orthoview'``, must be a single ``Axes3D``.\n        If mode equals ``'outlines'``, must be a list of three ``Axes``.\n\n        .. versionadded:: 0.14.0\n    block : bool\n        Whether to halt program execution until the figure is closed. Defaults\n        to False.\n        Only used if mode equals 'orthoview'.\n\n        .. versionadded:: 0.14.0\n    show : bool\n        Show figure if True. Defaults to True.\n        Only used if mode equals 'orthoview'.\n    scale : float\n        The scale (size in meters) of the dipoles if ``mode`` is not\n        ``'orthoview'``. The default is 0.03 when mode is ``'outlines'`` and\n        0.005 otherwise.\n    color : tuple\n        The color of the dipoles.\n        The default (None) will use ``'y'`` if mode is ``'orthoview'`` and\n        ``show_all`` is True, else 'r'. Can also be a list of colors to use\n        when mode is ``'outlines'``.\n\n        .. versionchanged:: 0.19.0\n           Color is now passed in orthoview mode.\n    highlight_color : color\n        The highlight color. Only used in orthoview mode with\n        ``show_all=True``.\n\n        .. versionadded:: 0.19.0\n    fig : instance of Figure3D | None\n        3D figure in which to plot the alignment.\n        If ``None``, creates a new 600x600 pixel figure with black background.\n        Only used when mode is ``'arrow'`` or ``'sphere'``.\n\n        .. versionadded:: 0.19.0\n    title : str | None\n        The title of the figure if ``mode='orthoview'`` (ignored for all other\n        modes). If ``None``, dipole number and its properties (amplitude,\n        orientation etc.) will be shown. Defaults to ``None``.\n\n        .. versionadded:: 0.21.0\n    %(head_source)s\n        Only used when mode equals ``'outlines'``.\n\n        .. versionadded:: 1.1\n    surf : str | None\n        Brain surface to show outlines for, can be ``'white'``, ``'pial'``, or\n        ``None``. Only used when mode is ``'outlines'``.\n\n        .. versionadded:: 1.1\n    width : float | None\n        Width of the matplotlib quiver arrow, see\n        :meth:`matplotlib:matplotlib.axes.Axes.quiver`. If None (default),\n        when mode is ``'outlines'`` 0.015 will be used, and when mode is\n        ``'orthoview'`` the matplotlib default is used.\n    %(verbose)s\n\n    Returns\n    -------\n    fig : instance of Figure3D or matplotlib.figure.Figure\n        The PyVista figure or matplotlib Figure.\n\n    Notes\n    -----\n    .. versionadded:: 0.9.0\n    \"\"\"\n    _validate_type(mode, str, \"mode\")\n    _validate_type(coord_frame, str, \"coord_frame\")\n    _check_option(\"mode\", mode, (\"orthoview\", \"outlines\", \"arrow\", \"sphere\"))\n    if mode in (\"orthoview\", \"outlines\"):\n        subjects_dir = str(get_subjects_dir(subjects_dir, raise_error=True))\n    kwargs = dict(\n        trans=trans,\n        subject=subject,\n        subjects_dir=subjects_dir,\n        coord_frame=coord_frame,\n        ax=ax,\n        block=block,\n        show=show,\n        color=color,\n        title=title,\n        width=width,\n    )\n    dipoles = _check_concat_dipoles(dipoles)\n    if mode == \"orthoview\":\n        fig = _plot_dipole_mri_orthoview(\n            dipoles,\n            idx=idx,\n            show_all=show_all,\n            highlight_color=highlight_color,\n            **kwargs,\n        )\n    elif mode == \"outlines\":\n        fig = _plot_dipole_mri_outlines(\n            dipoles, head_source=head_source, surf=surf, scale=scale, **kwargs\n        )\n    else:\n        assert mode in (\"arrow\", \"sphere\"), mode\n        fig = _plot_dipole_3d(\n            dipoles,\n            trans=trans,\n            coord_frame=coord_frame,\n            color=color,\n            fig=fig,\n            scale=scale,\n            mode=mode,\n        )\n\n    return fig", "metadata": {}}
{"_id": "mne_mne_viz/_3d.py_snapshot_brain_montage_code", "title": "snapshot_brain_montage", "text": "def snapshot_brain_montage(fig, montage, hide_sensors=True):\n    \"\"\"Take a snapshot of a PyVista Scene and project channels onto 2d coords.\n\n    Note that this will take the raw values for 3d coordinates of each channel,\n    without applying any transforms. If brain images are flipped up/dn upon\n    using `~matplotlib.pyplot.imshow`, check your matplotlib backend as this\n    behavior changes.\n\n    Parameters\n    ----------\n    fig : instance of Figure3D\n        The figure on which you've plotted electrodes using\n        :func:`mne.viz.plot_alignment`.\n    montage : instance of DigMontage or Info | dict\n        The digital montage for the electrodes plotted in the scene. If\n        :class:`~mne.Info`, channel positions will be pulled from the ``loc``\n        field of ``chs``. dict should have ch:xyz mappings.\n    hide_sensors : bool\n        Whether to remove the spheres in the scene before taking a snapshot.\n        The sensors will always be shown in the final figure. If you want an\n        image of just the brain, use :class:`mne.viz.Brain` instead.\n\n    Returns\n    -------\n    xy : array, shape (n_channels, 2)\n        The 2d location of each channel on the image of the current scene view.\n    im : array, shape (m, n, 3)\n        The screenshot of the current scene view.\n    \"\"\"\n    from ..channels import DigMontage\n\n    # Update the backend\n    from .backends.renderer import _get_renderer\n\n    if fig is None:\n        raise ValueError(\"The figure must have a scene\")\n    if isinstance(montage, DigMontage):\n        chs = montage._get_ch_pos()\n        ch_names, xyz = zip(*[(ich, ixyz) for ich, ixyz in chs.items()])\n    elif isinstance(montage, Info):\n        xyz = [ich[\"loc\"][:3] for ich in montage[\"chs\"]]\n        ch_names = [ich[\"ch_name\"] for ich in montage[\"chs\"]]\n    elif isinstance(montage, dict):\n        if not all(len(ii) == 3 for ii in montage.values()):\n            raise ValueError(\"All electrode positions must be length 3\")\n        ch_names, xyz = zip(*[(ich, ixyz) for ich, ixyz in montage.items()])\n    else:\n        raise TypeError(\n            \"montage must be an instance of `DigMontage`, `Info`, or `dict`\"\n        )\n\n    # initialize figure\n    renderer = _get_renderer(fig, show=True)\n\n    xyz = np.vstack(xyz)\n    proj = renderer.project(xyz=xyz, ch_names=ch_names)\n    if hide_sensors is True:\n        proj.visible(False)\n\n    im = renderer.screenshot()\n    proj.visible(True)\n    return proj.xy, im", "metadata": {}}
{"_id": "mne_mne_viz/_3d.py_plot_brain_colorbar_code", "title": "plot_brain_colorbar", "text": "def plot_brain_colorbar(\n    ax,\n    clim,\n    colormap=\"auto\",\n    transparent=True,\n    orientation=\"vertical\",\n    label=\"Activation\",\n    bgcolor=\"0.5\",\n):\n    \"\"\"Plot a colorbar that corresponds to a brain activation map.\n\n    Parameters\n    ----------\n    ax : instance of Axes\n        The Axes to plot into.\n    %(clim)s\n    %(colormap)s\n    %(transparent)s\n    orientation : str\n        Orientation of the colorbar, can be \"vertical\" or \"horizontal\".\n    label : str\n        The colorbar label.\n    bgcolor : color\n        The color behind the colorbar (for alpha blending).\n\n    Returns\n    -------\n    cbar : instance of ColorbarBase\n        The colorbar.\n\n    Notes\n    -----\n    .. versionadded:: 0.19\n    \"\"\"\n    from matplotlib.colorbar import ColorbarBase\n    from matplotlib.colors import Normalize\n\n    mapdata = _process_clim(clim, colormap, transparent)\n    ticks = _get_map_ticks(mapdata)\n    colormap, lims = _linearize_map(mapdata)\n    del mapdata\n    norm = Normalize(vmin=lims[0], vmax=lims[2])\n    cbar = ColorbarBase(\n        ax, cmap=colormap, norm=norm, ticks=ticks, label=label, orientation=orientation\n    )\n    # make the colorbar background match the brain color\n    cbar.ax.set(facecolor=bgcolor)\n    # remove the colorbar frame except for the line containing the ticks\n    cbar.outline.set_visible(False)\n    cbar.ax.set_frame_on(True)\n    for key in (\"left\", \"top\", \"bottom\" if orientation == \"vertical\" else \"right\"):\n        ax.spines[key].set_visible(False)\n    return cbar", "metadata": {}}
{"_id": "mne_mne_viz/_3d.py_set_3d_options_code", "title": "set_3d_options", "text": "def set_3d_options(\n    antialias=None, depth_peeling=None, smooth_shading=None, *, multi_samples=None\n):\n    \"\"\"Set 3D rendering options.\n\n    Parameters\n    ----------\n    antialias : bool | None\n        If bool, whether to enable or disable full-screen anti-aliasing.\n        False is useful when renderers have problems (such as software\n        MESA renderers). If None, use the default setting. This option\n        can also be controlled using an environment variable, e.g.,\n        ``MNE_3D_OPTION_ANTIALIAS=false``.\n    depth_peeling : bool | None\n        If bool, whether to enable or disable accurate transparency.\n        False is useful when renderers have problems (for instance\n        while X forwarding on remote servers). If None, use the default\n        setting. This option can also be controlled using an environment\n        variable, e.g., ``MNE_3D_OPTION_DEPTH_PEELING=false``.\n    smooth_shading : bool | None\n        If bool, whether to enable or disable smooth color transitions\n        between polygons. False is useful on certain configurations\n        where this type of shading is not supported or for performance\n        reasons. This option can also be controlled using an environment\n        variable, e.g., ``MNE_3D_OPTION_SMOOTH_SHADING=false``.\n    multi_samples : int\n        Number of multi-samples. Should be 1 for MESA for volumetric rendering\n        to work properly.\n\n        .. versionadded:: 1.1\n\n    Notes\n    -----\n    .. versionadded:: 0.21.0\n    \"\"\"\n    if antialias is not None:\n        _3d_options.antialias = bool(antialias)\n    if depth_peeling is not None:\n        _3d_options.depth_peeling = bool(depth_peeling)\n    if smooth_shading is not None:\n        _3d_options.smooth_shading = bool(smooth_shading)\n    if multi_samples is not None:\n        _3d_options.multi_samples = int(multi_samples)", "metadata": {}}
{"_id": "mne_mne_viz/backends/renderer.py_set_3d_backend_code", "title": "set_3d_backend", "text": "def set_3d_backend(backend_name, verbose=None):\n    \"\"\"Set the 3D backend for MNE.\n\n    The backend will be set as specified and operations will use\n    that backend.\n\n    Parameters\n    ----------\n    backend_name : str\n        The 3d backend to select. See Notes for the capabilities of each\n        backend (``'pyvistaqt'`` and ``'notebook'``).\n\n        .. versionchanged:: 0.24\n           The ``'pyvista'`` backend was renamed ``'pyvistaqt'``.\n    %(verbose)s\n\n    Returns\n    -------\n    old_backend_name : str | None\n        The old backend that was in use.\n\n    Notes\n    -----\n    To use PyVista, set ``backend_name`` to ``pyvistaqt`` but the value\n    ``pyvista`` is still supported for backward compatibility.\n\n    This table shows the capabilities of each backend (\"\u2713\" for full support,\n    and \"-\" for partial support):\n\n    .. table::\n       :widths: auto\n\n       +--------------------------------------+-----------+----------+\n       | **3D function:**                     | pyvistaqt | notebook |\n       +======================================+===========+==========+\n       | :func:`plot_vector_source_estimates` | \u2713         | \u2713        |\n       +--------------------------------------+-----------+----------+\n       | :func:`plot_source_estimates`        | \u2713         | \u2713        |\n       +--------------------------------------+-----------+----------+\n       | :func:`plot_alignment`               | \u2713         | \u2713        |\n       +--------------------------------------+-----------+----------+\n       | :func:`plot_sparse_source_estimates` | \u2713         | \u2713        |\n       +--------------------------------------+-----------+----------+\n       | :func:`plot_evoked_field`            | \u2713         | \u2713        |\n       +--------------------------------------+-----------+----------+\n       | :func:`snapshot_brain_montage`       | \u2713         | \u2713        |\n       +--------------------------------------+-----------+----------+\n       | :func:`link_brains`                  | \u2713         |          |\n       +--------------------------------------+-----------+----------+\n       +--------------------------------------+-----------+----------+\n       | **Feature:**                                                |\n       +--------------------------------------+-----------+----------+\n       | Large data                           | \u2713         | \u2713        |\n       +--------------------------------------+-----------+----------+\n       | Opacity/transparency                 | \u2713         | \u2713        |\n       +--------------------------------------+-----------+----------+\n       | Support geometric glyph              | \u2713         | \u2713        |\n       +--------------------------------------+-----------+----------+\n       | Smooth shading                       | \u2713         | \u2713        |\n       +--------------------------------------+-----------+----------+\n       | Subplotting                          | \u2713         | \u2713        |\n       +--------------------------------------+-----------+----------+\n       | Inline plot in Jupyter Notebook      |           | \u2713        |\n       +--------------------------------------+-----------+----------+\n       | Inline plot in JupyterLab            |           | \u2713        |\n       +--------------------------------------+-----------+----------+\n       | Inline plot in Google Colab          |           |          |\n       +--------------------------------------+-----------+----------+\n       | Toolbar                              | \u2713         | \u2713        |\n       +--------------------------------------+-----------+----------+\n    \"\"\"\n    global MNE_3D_BACKEND\n    old_backend_name = MNE_3D_BACKEND\n    backend_name = _check_3d_backend_name(backend_name)\n    if MNE_3D_BACKEND != backend_name:\n        _reload_backend(backend_name)\n        MNE_3D_BACKEND = backend_name\n    return old_backend_name", "metadata": {}}
{"_id": "mne_mne_viz/backends/renderer.py_get_3d_backend_code", "title": "get_3d_backend", "text": "def get_3d_backend():\n    \"\"\"Return the 3D backend currently used.\n\n    Returns\n    -------\n    backend_used : str | None\n        The 3d backend currently in use. If no backend is found,\n        returns ``None``.\n\n        .. versionchanged:: 0.24\n           The ``'pyvista'`` backend has been renamed ``'pyvistaqt'``, so\n           ``'pyvista'`` is no longer returned by this function.\n    \"\"\"\n    try:\n        backend = _get_3d_backend()\n    except RuntimeError as exc:\n        backend = None\n        logger.info(str(exc))\n    return backend", "metadata": {}}
{"_id": "mne_mne_viz/backends/renderer.py_use_3d_backend_code", "title": "use_3d_backend", "text": "def use_3d_backend(backend_name):\n    \"\"\"Create a 3d visualization context using the designated backend.\n\n    See :func:`mne.viz.set_3d_backend` for more details on the available\n    3d backends and their capabilities.\n\n    Parameters\n    ----------\n    backend_name : {'pyvistaqt', 'notebook'}\n        The 3d backend to use in the context.\n    \"\"\"\n    old_backend = set_3d_backend(backend_name)\n    try:\n        yield\n    finally:\n        if old_backend is not None:\n            try:\n                set_3d_backend(old_backend)\n            except Exception:\n                pass", "metadata": {}}
{"_id": "mne_mne_viz/backends/renderer.py_set_3d_view_code", "title": "set_3d_view", "text": "def set_3d_view(\n    figure,\n    azimuth=None,\n    elevation=None,\n    focalpoint=None,\n    distance=None,\n    roll=None,\n):\n    \"\"\"Configure the view of the given scene.\n\n    Parameters\n    ----------\n    figure : object\n        The scene which is modified.\n    %(azimuth)s\n    %(elevation)s\n    %(focalpoint)s\n    %(distance)s\n    %(roll)s\n    \"\"\"\n    backend._set_3d_view(\n        figure=figure,\n        azimuth=azimuth,\n        elevation=elevation,\n        focalpoint=focalpoint,\n        distance=distance,\n        roll=roll,\n    )", "metadata": {}}
{"_id": "mne_mne_viz/backends/renderer.py_set_3d_title_code", "title": "set_3d_title", "text": "def set_3d_title(figure, title, size=40, *, color=\"white\", position=\"upper_left\"):\n    \"\"\"Configure the title of the given scene.\n\n    Parameters\n    ----------\n    figure : object\n        The scene which is modified.\n    title : str\n        The title of the scene.\n    size : int\n        The size of the title.\n    color : matplotlib color\n        The color of the title.\n\n        .. versionadded:: 1.9\n    position : str\n        The position to use, e.g., \"upper_left\". See\n        :meth:`pyvista.Plotter.add_text` for details.\n\n        .. versionadded:: 1.9\n\n    Returns\n    -------\n    text : object\n        The text object returned by the given backend.\n\n        .. versionadded:: 1.0\n    \"\"\"\n    return backend._set_3d_title(\n        figure=figure, title=title, size=size, color=color, position=position\n    )", "metadata": {}}
{"_id": "mne_mne_viz/backends/renderer.py_create_3d_figure_code", "title": "create_3d_figure", "text": "def create_3d_figure(\n    size,\n    bgcolor=(0, 0, 0),\n    smooth_shading=None,\n    handle=None,\n    *,\n    scene=True,\n    show=False,\n    title=\"MNE 3D Figure\",\n):\n    \"\"\"Return an empty figure based on the current 3d backend.\n\n    .. warning:: Proceed with caution when the renderer object is\n                 returned (with ``scene=False``) because the _Renderer\n                 API is not necessarily stable enough for production,\n                 it's still actively in development.\n\n    Parameters\n    ----------\n    size : tuple\n        The dimensions of the 3d figure (width, height).\n    bgcolor : tuple\n        The color of the background.\n    smooth_shading : bool | None\n        Whether to enable smooth shading. If ``None``, uses the config value\n        ``MNE_3D_OPTION_SMOOTH_SHADING``. Defaults to ``None``.\n    handle : int | None\n        The figure identifier.\n    scene : bool\n        If True (default), the returned object is the Figure3D. If False,\n        an advanced, undocumented Renderer object is returned (the API is not\n        stable or documented, so this is not recommended).\n    show : bool\n        If True, show the renderer immediately.\n\n        .. versionadded:: 1.0\n    title : str\n        The window title to use (if applicable).\n\n        .. versionadded:: 1.9\n\n    Returns\n    -------\n    figure : instance of Figure3D or ``Renderer``\n        The requested empty figure or renderer, depending on ``scene``.\n    \"\"\"\n    _validate_type(smooth_shading, (bool, None), \"smooth_shading\")\n    if smooth_shading is None:\n        smooth_shading = _get_3d_option(\"smooth_shading\")\n    renderer = _get_renderer(\n        fig=handle,\n        size=size,\n        bgcolor=bgcolor,\n        smooth_shading=smooth_shading,\n        show=show,\n        name=title,\n    )\n    if scene:\n        return renderer.scene()\n    else:\n        return renderer", "metadata": {}}
{"_id": "mne_mne_viz/backends/renderer.py_close_3d_figure_code", "title": "close_3d_figure", "text": "def close_3d_figure(figure):\n    \"\"\"Close the given scene.\n\n    Parameters\n    ----------\n    figure : object\n        The scene which needs to be closed.\n    \"\"\"\n    backend._close_3d_figure(figure)", "metadata": {}}
{"_id": "mne_mne_viz/backends/renderer.py_close_all_3d_figures_code", "title": "close_all_3d_figures", "text": "def close_all_3d_figures():\n    \"\"\"Close all the scenes of the current 3d backend.\"\"\"\n    backend._close_all()", "metadata": {}}
{"_id": "mne_mne_viz/backends/renderer.py_get_brain_class_code", "title": "get_brain_class", "text": "def get_brain_class():\n    \"\"\"Return the proper Brain class based on the current 3d backend.\n\n    Returns\n    -------\n    brain : object\n        The Brain class corresponding to the current 3d backend.\n    \"\"\"\n    from ...viz._brain import Brain\n\n    return Brain", "metadata": {}}
{"_id": "mne_mne_viz/backends/_abstract.py_plotter_code", "title": "plotter", "text": "def plotter(self):\n        \"\"\"The native 3D plotting widget.\n\n        Returns\n        -------\n        plotter : instance of pyvista.Plotter\n            The plotter. Useful for interacting with the native 3D library.\n        \"\"\"\n        return self._plotter", "metadata": {}}
{"_id": "mne_mne_viz/backends/_abstract.py_subplot_code", "title": "subplot", "text": "def subplot(self, x, y):\n        \"\"\"Set the active subplot.\"\"\"\n        pass", "metadata": {}}
{"_id": "mne_mne_viz/backends/_abstract.py_scene_code", "title": "scene", "text": "def scene(self):\n        \"\"\"Return scene handle.\"\"\"\n        pass", "metadata": {}}
{"_id": "mne_mne_viz/backends/_abstract.py_set_interaction_code", "title": "set_interaction", "text": "def set_interaction(self, interaction):\n        \"\"\"Set interaction mode.\"\"\"\n        pass", "metadata": {}}
{"_id": "mne_mne_viz/backends/_abstract.py_legend_code", "title": "legend", "text": "def legend(self, labels, border=False, size=0.1, face=\"triangle\", loc=\"upper left\"):\n        \"\"\"Add a legend to the scene.\n\n        Parameters\n        ----------\n        labels : list of tuples\n            Each entry must contain two strings, (label, color),\n            where ``label`` is the name of the item to add, and\n            ``color`` is the color of the label to add.\n        border : bool\n            Controls if there will be a border around the legend.\n            The default is False.\n        size : float\n            The size of the entire figure window.\n        loc : str\n            The location of the legend.\n        face : str\n            Face shape of legend face.  One of the following:\n\n            * None: ``None``\n            * Line: ``\"-\"`` or ``\"line\"``\n            * Triangle: ``\"^\"`` or ``'triangle'``\n            * Circle: ``\"o\"`` or ``'circle'``\n            * Rectangle: ``\"r\"`` or ``'rectangle'``\n        \"\"\"\n        pass", "metadata": {}}
{"_id": "mne_mne_viz/backends/_abstract.py_mesh_code", "title": "mesh", "text": "def mesh(\n        self,\n        x,\n        y,\n        z,\n        triangles,\n        color,\n        opacity=1.0,\n        *,\n        backface_culling=False,\n        scalars=None,\n        colormap=None,\n        vmin=None,\n        vmax=None,\n        interpolate_before_map=True,\n        representation=\"surface\",\n        line_width=1.0,\n        normals=None,\n        polygon_offset=None,\n        name=None,\n        **kwargs,\n    ):\n        \"\"\"Add a mesh in the scene.\n\n        Parameters\n        ----------\n        x : array, shape (n_vertices,)\n           The array containing the X component of the vertices.\n        y : array, shape (n_vertices,)\n           The array containing the Y component of the vertices.\n        z : array, shape (n_vertices,)\n           The array containing the Z component of the vertices.\n        triangles : array, shape (n_polygons, 3)\n           The array containing the indices of the polygons.\n        color : tuple | str\n            The color of the mesh as a tuple (red, green, blue) of float\n            values between 0 and 1 or a valid color name (i.e. 'white'\n            or 'w').\n        opacity : float\n            The opacity of the mesh.\n        shading : bool\n            If True, enable the mesh shading.\n        backface_culling : bool\n            If True, enable backface culling on the mesh.\n        scalars : ndarray, shape (n_vertices,)\n            The scalar valued associated to the vertices.\n        vmin : float | None\n            vmin is used to scale the colormap.\n            If None, the min of the data will be used.\n        vmax : float | None\n            vmax is used to scale the colormap.\n            If None, the max of the data will be used.\n        colormap : str | np.ndarray | matplotlib.colors.Colormap | None\n            The colormap to use.\n        interpolate_before_map :\n            Enabling makes for a smoother scalars display. Default is True.\n            When False, OpenGL will interpolate the mapped colors which can\n            result is showing colors that are not present in the color map.\n        representation : str\n            The representation of the mesh: either 'surface' or 'wireframe'.\n        line_width : int\n            The width of the lines when representation='wireframe'.\n        normals : array, shape (n_vertices, 3)\n            The array containing the normal of each vertex.\n        polygon_offset : float\n            If not None, the factor used to resolve coincident topology.\n        name : str | None\n            The name of the mesh.\n        kwargs : args\n            The arguments to pass to triangular_mesh\n\n        Returns\n        -------\n        surface :\n            Handle of the mesh in the scene.\n        \"\"\"\n        pass", "metadata": {}}
{"_id": "mne_mne_viz/backends/_abstract.py_contour_code", "title": "contour", "text": "def contour(\n        self,\n        surface,\n        scalars,\n        contours,\n        width=1.0,\n        opacity=1.0,\n        vmin=None,\n        vmax=None,\n        colormap=None,\n        normalized_colormap=False,\n        kind=\"line\",\n        color=None,\n    ):\n        \"\"\"Add a contour in the scene.\n\n        Parameters\n        ----------\n        surface : surface object\n            The mesh to use as support for contour.\n        scalars : ndarray, shape (n_vertices,)\n            The scalar valued associated to the vertices.\n        contours : int | list\n             Specifying a list of values will only give the requested contours.\n        width : float\n            The width of the lines or radius of the tubes.\n        opacity : float\n            The opacity of the contour.\n        vmin : float | None\n            vmin is used to scale the colormap.\n            If None, the min of the data will be used.\n        vmax : float | None\n            vmax is used to scale the colormap.\n            If None, the max of the data will be used.\n        colormap : str | np.ndarray | matplotlib.colors.Colormap | None\n            The colormap to use.\n        normalized_colormap : bool\n            Specify if the values of the colormap are between 0 and 1.\n        kind : 'line' | 'tube'\n            The type of the primitives to use to display the contours.\n        color : tuple | str\n            The color of the mesh as a tuple (red, green, blue) of float\n            values between 0 and 1 or a valid color name (i.e. 'white'\n            or 'w').\n        \"\"\"\n        pass", "metadata": {}}
{"_id": "mne_mne_viz/backends/_abstract.py_surface_code", "title": "surface", "text": "def surface(\n        self,\n        surface,\n        color=None,\n        opacity=1.0,\n        vmin=None,\n        vmax=None,\n        colormap=None,\n        normalized_colormap=False,\n        scalars=None,\n        backface_culling=False,\n        polygon_offset=None,\n        *,\n        name=None,\n    ):\n        \"\"\"Add a surface in the scene.\n\n        Parameters\n        ----------\n        surface : surface object\n            The information describing the surface.\n        color : tuple | str\n            The color of the surface as a tuple (red, green, blue) of float\n            values between 0 and 1 or a valid color name (i.e. 'white'\n            or 'w').\n        opacity : float\n            The opacity of the surface.\n        vmin : float | None\n            vmin is used to scale the colormap.\n            If None, the min of the data will be used.\n        vmax : float | None\n            vmax is used to scale the colormap.\n            If None, the max of the data will be used.\n        colormap : str | np.ndarray | matplotlib.colors.Colormap | None\n            The colormap to use.\n        scalars : ndarray, shape (n_vertices,)\n            The scalar valued associated to the vertices.\n        backface_culling : bool\n            If True, enable backface culling on the surface.\n        polygon_offset : float\n            If not None, the factor used to resolve coincident topology.\n        name : str | None\n            Name of the surface.\n        \"\"\"\n        pass", "metadata": {}}
{"_id": "mne_mne_viz/backends/_abstract.py_sphere_code", "title": "sphere", "text": "def sphere(\n        self,\n        center,\n        color,\n        scale,\n        opacity=1.0,\n        resolution=8,\n        backface_culling=False,\n        radius=None,\n    ):\n        \"\"\"Add sphere in the scene.\n\n        Parameters\n        ----------\n        center : ndarray, shape(n_center, 3)\n            The list of centers to use for the sphere(s).\n        color : tuple | str\n            The color of the sphere as a tuple (red, green, blue) of float\n            values between 0 and 1 or a valid color name (i.e. 'white'\n            or 'w').\n        scale : float\n            The scaling applied to the spheres. The given value specifies\n            the maximum size in drawing units.\n        opacity : float\n            The opacity of the sphere(s).\n        resolution : int\n            The resolution of the sphere created. This is the number\n            of divisions along theta and phi.\n        backface_culling : bool\n            If True, enable backface culling on the sphere(s).\n        radius : float | None\n            Replace the glyph scaling by a fixed radius value for each\n            sphere.\n        \"\"\"\n        pass", "metadata": {}}
{"_id": "mne_mne_viz/backends/_abstract.py_tube_code", "title": "tube", "text": "def tube(\n        self,\n        origin,\n        destination,\n        radius=0.001,\n        color=\"white\",\n        scalars=None,\n        vmin=None,\n        vmax=None,\n        colormap=\"RdBu\",\n        normalized_colormap=False,\n        reverse_lut=False,\n    ):\n        \"\"\"Add tube in the scene.\n\n        Parameters\n        ----------\n        origin : array, shape(n_lines, 3)\n            The coordinates of the first end of the tube(s).\n        destination : array, shape(n_lines, 3)\n            The coordinates of the other end of the tube(s).\n        radius : float\n            The radius of the tube(s).\n        color : tuple | str\n            The color of the tube as a tuple (red, green, blue) of float\n            values between 0 and 1 or a valid color name (i.e. 'white'\n            or 'w').\n        scalars : array, shape (n_quivers,) | None\n            The optional scalar data to use.\n        vmin : float | None\n            vmin is used to scale the colormap.\n            If None, the min of the data will be used.\n        vmax : float | None\n            vmax is used to scale the colormap.\n            If None, the max of the data will be used.\n        colormap : str | np.ndarray | matplotlib.colors.Colormap | None\n            The colormap to use.\n        opacity : float\n            The opacity of the tube(s).\n        backface_culling : bool\n            If True, enable backface culling on the tube(s).\n        reverse_lut : bool\n            If True, reverse the lookup table.\n\n        Returns\n        -------\n        actor :\n            The actor in the scene.\n        surface :\n            Handle of the tube in the scene.\n        \"\"\"\n        pass", "metadata": {}}
{"_id": "mne_mne_viz/backends/_abstract.py_quiver3d_code", "title": "quiver3d", "text": "def quiver3d(\n        self,\n        x,\n        y,\n        z,\n        u,\n        v,\n        w,\n        color,\n        scale,\n        mode,\n        resolution=8,\n        glyph_height=None,\n        glyph_center=None,\n        glyph_resolution=None,\n        opacity=1.0,\n        scale_mode=\"none\",\n        scalars=None,\n        backface_culling=False,\n        colormap=None,\n        vmin=None,\n        vmax=None,\n        line_width=2.0,\n        name=None,\n    ):\n        \"\"\"Add quiver3d in the scene.\n\n        Parameters\n        ----------\n        x : array, shape (n_quivers,)\n            The X component of the position of the quiver.\n        y : array, shape (n_quivers,)\n            The Y component of the position of the quiver.\n        z : array, shape (n_quivers,)\n            The Z component of the position of the quiver.\n        u : array, shape (n_quivers,)\n            The last X component of the quiver.\n        v : array, shape (n_quivers,)\n            The last Y component of the quiver.\n        w : array, shape (n_quivers,)\n            The last Z component of the quiver.\n        color : tuple | str\n            The color of the quiver as a tuple (red, green, blue) of float\n            values between 0 and 1 or a valid color name (i.e. 'white'\n            or 'w').\n        scale : float\n            The scaling applied to the glyphs. The size of the glyph\n            is by default calculated from the inter-glyph spacing.\n            The given value specifies the maximum glyph size in drawing units.\n        mode : 'arrow', 'cone' or 'cylinder'\n            The type of the quiver.\n        resolution : int\n            The resolution of the glyph created. Depending on the type of\n            glyph, it represents the number of divisions in its geometric\n            representation.\n        glyph_height : float\n            The height of the glyph used with the quiver.\n        glyph_center : tuple\n            The center of the glyph used with the quiver: (x, y, z).\n        glyph_resolution : float\n            The resolution of the glyph used with the quiver.\n        opacity : float\n            The opacity of the quiver.\n        scale_mode : 'vector', 'scalar' or 'none'\n            The scaling mode for the glyph.\n        scalars : array, shape (n_quivers,) | None\n            The optional scalar data to use.\n        backface_culling : bool\n            If True, enable backface culling on the quiver.\n        colormap : str | np.ndarray | matplotlib.colors.Colormap | None\n            The colormap to use.\n        vmin : float | None\n            vmin is used to scale the colormap.\n            If None, the min of the data will be used\n        vmax : float | None\n            vmax is used to scale the colormap.\n            If None, the max of the data will be used\n        line_width : float\n            The width of the 2d arrows.\n\n        Returns\n        -------\n        actor :\n            The actor in the scene.\n        surface :\n            Handle of the quiver in the scene.\n        \"\"\"\n        pass", "metadata": {}}
{"_id": "mne_mne_viz/backends/_abstract.py_text2d_code", "title": "text2d", "text": "def text2d(self, x_window, y_window, text, size=14, color=\"white\"):\n        \"\"\"Add 2d text in the scene.\n\n        Parameters\n        ----------\n        x : float\n            The X component to use as position of the text in the\n            window coordinates system (window_width, window_height).\n        y : float\n            The Y component to use as position of the text in the\n            window coordinates system (window_width, window_height).\n        text : str\n            The content of the text.\n        size : int\n            The size of the font.\n        color : tuple | str\n            The color of the text as a tuple (red, green, blue) of float\n            values between 0 and 1 or a valid color name (i.e. 'white'\n            or 'w').\n        \"\"\"\n        pass", "metadata": {}}
{"_id": "mne_mne_viz/backends/_abstract.py_text3d_code", "title": "text3d", "text": "def text3d(self, x, y, z, text, width, color=\"white\"):\n        \"\"\"Add 2d text in the scene.\n\n        Parameters\n        ----------\n        x : float\n            The X component to use as position of the text.\n        y : float\n            The Y component to use as position of the text.\n        z : float\n            The Z component to use as position of the text.\n        text : str\n            The content of the text.\n        width : float\n            The width of the text.\n        color : tuple | str\n            The color of the text as a tuple (red, green, blue) of float\n            values between 0 and 1 or a valid color name (i.e. 'white'\n            or 'w').\n        \"\"\"\n        pass", "metadata": {}}
{"_id": "mne_mne_viz/backends/_abstract.py_scalarbar_code", "title": "scalarbar", "text": "def scalarbar(self, source, color=\"white\", title=None, n_labels=4, bgcolor=None):\n        \"\"\"Add a scalar bar in the scene.\n\n        Parameters\n        ----------\n        source\n            The object of the scene used for the colormap.\n        color : tuple | str\n            The color of the label text.\n        title : str | None\n            The title of the scalar bar.\n        n_labels : int | None\n            The number of labels to display on the scalar bar.\n        bgcolor : tuple | str\n            The color of the background when there is transparency.\n        \"\"\"\n        pass", "metadata": {}}
{"_id": "mne_mne_viz/backends/_abstract.py_show_code", "title": "show", "text": "def show(self):\n        \"\"\"Render the scene.\"\"\"\n        pass", "metadata": {}}
{"_id": "mne_mne_viz/backends/_abstract.py_close_code", "title": "close", "text": "def close(self):\n        \"\"\"Close the scene.\"\"\"\n        pass", "metadata": {}}
{"_id": "mne_mne_viz/backends/_abstract.py_set_camera_code", "title": "set_camera", "text": "def set_camera(\n        self,\n        azimuth=None,\n        elevation=None,\n        distance=None,\n        focalpoint=None,\n        roll=None,\n    ):\n        \"\"\"Configure the camera of the scene.\n\n        Parameters\n        ----------\n        azimuth : float\n            The azimuthal angle of the camera.\n        elevation : float\n            The zenith angle of the camera.\n        distance : float\n            The distance to the focal point.\n        focalpoint : tuple\n            The focal point of the camera: (x, y, z).\n        roll : float\n            The rotation of the camera along its axis.\n        \"\"\"\n        pass", "metadata": {}}
{"_id": "mne_mne_viz/backends/_abstract.py_screenshot_code", "title": "screenshot", "text": "def screenshot(self, mode=\"rgb\", filename=None):\n        \"\"\"Take a screenshot of the scene.\n\n        Parameters\n        ----------\n        mode : str\n            Either 'rgb' or 'rgba' for values to return.\n            Default is 'rgb'.\n        filename : str | None\n            If not None, save the figure to the disk.\n        \"\"\"\n        pass", "metadata": {}}
{"_id": "mne_mne_viz/backends/_abstract.py_project_code", "title": "project", "text": "def project(self, xyz, ch_names):\n        \"\"\"Convert 3d points to a 2d perspective.\n\n        Parameters\n        ----------\n        xyz : array, shape(n_points, 3)\n            The points to project.\n        ch_names : array, shape(_n_points,)\n            Names of the channels.\n        \"\"\"\n        pass", "metadata": {}}
{"_id": "mne_mne_viz/backends/_abstract.py_remove_mesh_code", "title": "remove_mesh", "text": "def remove_mesh(self, mesh_data):\n        \"\"\"Remove the given mesh from the scene.\n\n        Parameters\n        ----------\n        mesh_data : tuple | Surface\n            The mesh to remove.\n        \"\"\"\n        pass", "metadata": {}}
{"_id": "mne_mne_viz/backends/_abstract.py_show_code", "title": "show", "text": "def show(self):\n        \"\"\"Show the canvas.\"\"\"\n        if self.manager is None:\n            self.show()\n        else:\n            self.manager.show()", "metadata": {}}
{"_id": "mne_mne_viz/backends/_abstract.py_close_code", "title": "close", "text": "def close(self):\n        \"\"\"Close the canvas.\"\"\"\n        self.close()", "metadata": {}}
{"_id": "mne_mne_viz/backends/_abstract.py_update_code", "title": "update", "text": "def update(self):\n        \"\"\"Update the canvas.\"\"\"\n        self.fig.canvas.draw()\n        self.fig.canvas.flush_events()", "metadata": {}}
{"_id": "mne_mne_viz/backends/_abstract.py_clear_code", "title": "clear", "text": "def clear(self):\n        \"\"\"Clear internal variables.\"\"\"\n        self.close()\n        self.ax.clear()\n        self.fig.clear()\n        self.manager = None", "metadata": {}}
{"_id": "mne_mne_viz/backends/_abstract.py_plot_code", "title": "plot", "text": "def plot(self, x, y, label, update=True, **kwargs):\n        \"\"\"Plot a curve.\"\"\"\n        (line,) = self.axes.plot(x, y, label=label, **kwargs)\n        if update:\n            self.update_plot()\n        return line", "metadata": {}}
{"_id": "mne_mne_viz/backends/_abstract.py_plot_time_line_code", "title": "plot_time_line", "text": "def plot_time_line(self, x, label, update=True, **kwargs):\n        \"\"\"Plot the vertical line.\"\"\"\n        line = self.axes.axvline(x, label=label, **kwargs)\n        if update:\n            self.update_plot()\n        return line", "metadata": {}}
{"_id": "mne_mne_viz/backends/_abstract.py_update_plot_code", "title": "update_plot", "text": "def update_plot(self):\n        \"\"\"Update the plot.\"\"\"\n        with warnings.catch_warnings(record=True):\n            warnings.filterwarnings(\"ignore\", \"constrained_layout\")\n            self.canvas.draw()", "metadata": {}}
{"_id": "mne_mne_viz/backends/_abstract.py_set_color_code", "title": "set_color", "text": "def set_color(self, bg_color, fg_color):\n        \"\"\"Set the widget colors.\"\"\"\n        self.axes.set_facecolor(bg_color)\n        self.axes.xaxis.label.set_color(fg_color)\n        self.axes.yaxis.label.set_color(fg_color)\n        self.axes.spines[\"top\"].set_color(fg_color)\n        self.axes.spines[\"bottom\"].set_color(fg_color)\n        self.axes.spines[\"left\"].set_color(fg_color)\n        self.axes.spines[\"right\"].set_color(fg_color)\n        self.axes.tick_params(axis=\"x\", colors=fg_color)\n        self.axes.tick_params(axis=\"y\", colors=fg_color)\n        self.fig.patch.set_facecolor(bg_color)", "metadata": {}}
{"_id": "mne_mne_viz/backends/_abstract.py_show_code", "title": "show", "text": "def show(self):\n        \"\"\"Show the canvas.\"\"\"\n        if self.manager is None:\n            self.canvas.show()\n        else:\n            self.manager.show()", "metadata": {}}
{"_id": "mne_mne_viz/backends/_abstract.py_close_code", "title": "close", "text": "def close(self):\n        \"\"\"Close the canvas.\"\"\"\n        self.canvas.close()", "metadata": {}}
{"_id": "mne_mne_viz/backends/_abstract.py_clear_code", "title": "clear", "text": "def clear(self):\n        \"\"\"Clear internal variables.\"\"\"\n        self.close()\n        self.axes.clear()\n        self.fig.clear()\n        self.canvas = None\n        self.manager = None", "metadata": {}}
{"_id": "mne_mne_viz/backends/_abstract.py_on_resize_code", "title": "on_resize", "text": "def on_resize(self, event):\n        \"\"\"Handle resize events.\"\"\"\n        pass", "metadata": {}}
{"_id": "mne_mne_viz/backends/_abstract.py_update_plot_code", "title": "update_plot", "text": "def update_plot(self):\n        \"\"\"Update the plot.\"\"\"\n        leg = self.axes.legend(\n            prop={\"family\": \"monospace\", \"size\": \"small\"},\n            framealpha=0.5,\n            handlelength=1.0,\n            facecolor=self.brain._bg_color,\n        )\n        for text in leg.get_texts():\n            text.set_color(self.brain._fg_color)\n        super().update_plot()", "metadata": {}}
{"_id": "mne_mne_viz/backends/_abstract.py_on_button_press_code", "title": "on_button_press", "text": "def on_button_press(self, event):\n        \"\"\"Handle button presses.\"\"\"\n        # left click (and maybe drag) in progress in axes\n        if event.inaxes != self.axes or event.button != 1:\n            return\n        publish(self.brain, TimeChange(time=event.xdata))", "metadata": {}}
{"_id": "mne_mne_viz/backends/_abstract.py_clear_code", "title": "clear", "text": "def clear(self):\n        \"\"\"Clear internal variables.\"\"\"\n        super().clear()\n        self.brain = None", "metadata": {}}
{"_id": "mne_mne_viz/backends/_qt.py_minimum_code", "title": "minimum", "text": "def minimum(self):\n        \"\"\"Get the minimum.\"\"\"\n        return super().minimum() / self._precision", "metadata": {}}
{"_id": "mne_mne_viz/backends/_qt.py_setMinimum_code", "title": "setMinimum", "text": "def setMinimum(self, value):\n        \"\"\"Set the minimum.\"\"\"\n        super().setMinimum(int(value * self._precision))", "metadata": {}}
{"_id": "mne_mne_viz/backends/_qt.py_maximum_code", "title": "maximum", "text": "def maximum(self):\n        \"\"\"Get the maximum.\"\"\"\n        return super().maximum() / self._precision", "metadata": {}}
{"_id": "mne_mne_viz/backends/_qt.py_setMaximum_code", "title": "setMaximum", "text": "def setMaximum(self, value):\n        \"\"\"Set the maximum.\"\"\"\n        super().setMaximum(int(value * self._precision))", "metadata": {}}
{"_id": "mne_mne_viz/backends/_qt.py_value_code", "title": "value", "text": "def value(self):\n        \"\"\"Get the current value.\"\"\"\n        return super().value() / self._precision", "metadata": {}}
{"_id": "mne_mne_viz/backends/_qt.py_setValue_code", "title": "setValue", "text": "def setValue(self, value):\n        \"\"\"Set the current value.\"\"\"\n        super().setValue(int(value * self._precision))", "metadata": {}}
{"_id": "mne_mne_viz/backends/_qt.py_mousePressEvent_code", "title": "mousePressEvent", "text": "def mousePressEvent(self, event):\n        \"\"\"Add snap-to-location handling.\"\"\"\n        opt = QStyleOptionSlider()\n        self.initStyleOption(opt)\n        sr = self.style().subControlRect(\n            QStyle.CC_Slider, opt, QStyle.SC_SliderHandle, self\n        )\n        if event.button() != Qt.LeftButton or sr.contains(event.pos()):\n            super().mousePressEvent(event)\n            return\n        if self.orientation() == Qt.Vertical:\n            half = (0.5 * sr.height()) + 0.5\n            max_ = self.height()\n            pos = max_ - event.pos().y()\n        else:\n            half = (0.5 * sr.width()) + 0.5\n            max_ = self.width()\n            pos = event.pos().x()\n        max_ = max_ - 2 * half\n        pos = min(max(pos - half, 0), max_) / max_\n        val = self.minimum() + (self.maximum() - self.minimum()) * pos\n        val = (self.maximum() - val) if self.invertedAppearance() else val\n        self.setValue(val)\n        event.accept()\n        # Process afterward so it's seen as a drag\n        super().mousePressEvent(event)", "metadata": {}}
{"_id": "mne_mne_viz/backends/_pyvista.py_visible_code", "title": "visible", "text": "def visible(self, state):\n        \"\"\"Modify visibility attribute of the sensors.\"\"\"\n        self.pts.SetVisibility(state)\n        self.plotter.render()", "metadata": {}}
{"_id": "mne_mne_viz/eyetracking/heatmap.py_plot_gaze_code", "title": "plot_gaze", "text": "def plot_gaze(\n    epochs,\n    *,\n    calibration=None,\n    width=None,\n    height=None,\n    sigma=25,\n    cmap=None,\n    alpha=1.0,\n    vlim=(None, None),\n    axes=None,\n    show=True,\n):\n    \"\"\"Plot a heatmap of eyetracking gaze data.\n\n    Parameters\n    ----------\n    epochs : instance of Epochs\n        The :class:`~mne.Epochs` object containing eyegaze channels.\n    calibration : instance of Calibration | None\n        An instance of Calibration with information about the screen size, distance,\n        and resolution. If ``None``, you must provide a width and height.\n    width : int\n        The width dimension of the plot canvas, only valid if eyegaze data are in\n        pixels. For example, if the participant screen resolution was 1920x1080, then\n        the width should be 1920.\n    height : int\n        The height dimension of the plot canvas, only valid if eyegaze data are in\n        pixels. For example, if the participant screen resolution was 1920x1080, then\n        the height should be 1080.\n    sigma : float | None\n        The amount of Gaussian smoothing applied to the heatmap data (standard\n        deviation in pixels). If ``None``, no smoothing is applied. Default is 25.\n    %(cmap)s\n    alpha : float\n        The opacity of the heatmap (default is 1).\n    %(vlim_plot_topomap)s\n    %(axes_plot_topomap)s\n    %(show)s\n\n    Returns\n    -------\n    fig : instance of Figure\n        The resulting figure object for the heatmap plot.\n\n    Notes\n    -----\n    .. versionadded:: 1.6\n    \"\"\"\n    from mne import BaseEpochs\n    from mne._fiff.pick import _picks_to_idx\n\n    from ...preprocessing.eyetracking.utils import (\n        _check_calibration,\n        get_screen_visual_angle,\n    )\n\n    _validate_type(epochs, BaseEpochs, \"epochs\")\n    _validate_type(alpha, \"numeric\", \"alpha\")\n    _validate_type(sigma, (\"numeric\", None), \"sigma\")\n\n    # Get the gaze data\n    pos_picks = _picks_to_idx(epochs.info, \"eyegaze\")\n    gaze_data = epochs.get_data(picks=pos_picks)\n    gaze_ch_loc = np.array([epochs.info[\"chs\"][idx][\"loc\"] for idx in pos_picks])\n    x_data = gaze_data[:, np.where(gaze_ch_loc[:, 4] == -1)[0], :]\n    y_data = gaze_data[:, np.where(gaze_ch_loc[:, 4] == 1)[0], :]\n    unit = epochs.info[\"chs\"][pos_picks[0]][\"unit\"]  # assumes all units are the same\n\n    if x_data.shape[1] > 1:  # binocular recording. Average across eyes\n        logger.info(\"Detected binocular recording. Averaging positions across eyes.\")\n        x_data = np.nanmean(x_data, axis=1)  # shape (n_epochs, n_samples)\n        y_data = np.nanmean(y_data, axis=1)\n    canvas = np.vstack((x_data.flatten(), y_data.flatten()))  # shape (2, n_samples)\n\n    # Check that we have the right inputs\n    if calibration is not None:\n        if width is not None or height is not None:\n            raise ValueError(\n                \"If a calibration is provided, you cannot provide a width or height\"\n                \" to plot heatmaps. Please provide only the calibration object.\"\n            )\n        _check_calibration(calibration)\n        if unit == FIFF.FIFF_UNIT_PX:\n            width, height = calibration[\"screen_resolution\"]\n        elif unit == FIFF.FIFF_UNIT_RAD:\n            width, height = calibration[\"screen_size\"]\n        else:\n            raise ValueError(\n                f\"Invalid unit type: {unit}. gaze data Must be pixels or radians.\"\n            )\n    else:\n        if width is None or height is None:\n            raise ValueError(\n                \"If no calibration is provided, you must provide a width and height\"\n                \" to plot heatmaps.\"\n            )\n\n    # Create 2D histogram\n    # We need to set the histogram bins & bounds, and imshow extent, based on the units\n    if unit == FIFF.FIFF_UNIT_PX:  # pixel on screen\n        _range = [[0, height], [0, width]]\n        bins_x, bins_y = width, height\n        extent = [0, width, height, 0]\n    elif unit == FIFF.FIFF_UNIT_RAD:  # radians of visual angle\n        if not calibration:\n            raise ValueError(\n                \"If gaze data are in Radians, you must provide a\"\n                \" calibration instance to plot heatmaps.\"\n            )\n        width, height = get_screen_visual_angle(calibration)\n        x_range = [-width / 2, width / 2]\n        y_range = [-height / 2, height / 2]\n        _range = [y_range, x_range]\n        extent = (x_range[0], x_range[1], y_range[0], y_range[1])\n        bins_x, bins_y = calibration[\"screen_resolution\"]\n\n    hist, _, _ = np.histogram2d(\n        canvas[1, :],\n        canvas[0, :],\n        bins=(bins_y, bins_x),\n        range=_range,\n    )\n    # Convert density from samples to seconds\n    hist /= epochs.info[\"sfreq\"]\n    # Smooth the heatmap\n    if sigma:\n        hist = gaussian_filter(hist, sigma=sigma)\n\n    return _plot_heatmap_array(\n        hist,\n        width=width,\n        height=height,\n        cmap=cmap,\n        alpha=alpha,\n        vmin=vlim[0],\n        vmax=vlim[1],\n        extent=extent,\n        axes=axes,\n        show=show,\n    )", "metadata": {}}
{"_id": "mne_mne_viz/_brain/surface.py_load_geometry_code", "title": "load_geometry", "text": "def load_geometry(self):\n        \"\"\"Load geometry of the surface.\n\n        Parameters\n        ----------\n        None\n\n        Returns\n        -------\n        None\n        \"\"\"\n        if self.surf == \"flat\":  # special case\n            fname = path.join(self.data_path, \"surf\", f\"{self.hemi}.cortex.patch.flat\")\n            _check_fname(\n                fname, overwrite=\"read\", must_exist=True, name=\"flatmap surface file\"\n            )\n            coords, faces, orig_faces = _read_patch(fname)\n            # rotate 90 degrees to get to a more standard orientation\n            # where X determines the distance between the hemis\n            coords = coords[:, [1, 0, 2]]\n            coords[:, 1] *= -1\n        else:\n            # allow ?h.pial.T1 if ?h.pial doesn't exist for instance\n            # end with '' for better file not found error\n            for img in (\"\", \".T1\", \".T2\", \"\"):\n                surf_fname = path.join(\n                    self.data_path, \"surf\", f\"{self.hemi}.{self.surf}{img}\"\n                )\n                if path.isfile(surf_fname):\n                    break\n            coords, faces = read_surface(surf_fname)\n            orig_faces = faces\n        if self.units == \"m\":\n            coords /= 1000.0\n        if self.offset is not None:\n            x_ = coords @ self.x_dir\n            if self.hemi == \"lh\":\n                coords -= (np.max(x_) + self.offset) * self.x_dir\n            else:\n                coords -= (np.min(x_) + self.offset) * self.x_dir\n        surf = dict(rr=coords, tris=faces)\n        complete_surface_info(surf, copy=False, verbose=False, do_neighbor_tri=False)\n        nn = surf[\"nn\"]\n        self.coords = coords\n        self.faces = faces\n        self.orig_faces = orig_faces\n        self.nn = nn", "metadata": {}}
{"_id": "mne_mne_viz/_brain/surface.py_load_curvature_code", "title": "load_curvature", "text": "def load_curvature(self):\n        \"\"\"Load in curvature values from the ?h.curv file.\"\"\"\n        curv_path = path.join(self.data_path, \"surf\", f\"{self.hemi}.curv\")\n        if path.isfile(curv_path):\n            self.curv = read_curvature(curv_path, binary=False)\n            self.bin_curv = np.array(self.curv > 0, np.int64)\n        else:\n            self.curv = None\n            self.bin_curv = None", "metadata": {}}
{"_id": "mne_mne_viz/_brain/_brain.py_setup_time_viewer_code", "title": "setup_time_viewer", "text": "def setup_time_viewer(self, time_viewer=True, show_traces=True):\n        \"\"\"Configure the time viewer parameters.\n\n        Parameters\n        ----------\n        time_viewer : bool\n            If True, enable widgets interaction. Defaults to True.\n\n        show_traces : bool\n            If True, enable visualization of time traces. Defaults to True.\n\n        Notes\n        -----\n        The keyboard shortcuts are the following:\n\n        '?': Display help window\n        'i': Toggle interface\n        's': Apply auto-scaling\n        'r': Restore original clim\n        'c': Clear all traces\n        'n': Shift the time forward by the playback speed\n        'b': Shift the time backward by the playback speed\n        'Space': Start/Pause playback\n        'Up': Decrease camera elevation angle\n        'Down': Increase camera elevation angle\n        'Left': Decrease camera azimuth angle\n        'Right': Increase camera azimuth angle\n        \"\"\"\n        if self.time_viewer:\n            return\n        if not self._data:\n            raise ValueError(\"No data to visualize. See ``add_data``.\")\n        self.time_viewer = time_viewer\n        self.orientation = list(_lh_views_dict.keys())\n        self.default_smoothing_range = [-1, 15]\n\n        # Default configuration\n        self.visibility = False\n        self.default_playback_speed_range = [0.01, 1]\n        self.default_playback_speed_value = 0.01\n        self.default_status_bar_msg = \"Press ? for help\"\n        self.default_label_extract_modes = {\n            \"stc\": [\"mean\", \"max\"],\n            \"src\": [\"mean_flip\", \"pca_flip\", \"auto\"],\n        }\n        self.annot = None\n        self.label_extract_mode = None\n        all_keys = (\"lh\", \"rh\", \"vol\")\n        self.act_data_smooth = {key: (None, None) for key in all_keys}\n        # remove grey for better contrast on the brain\n        self.color_list = _get_color_list(remove=(\"#7f7f7f\",))\n        self.color_cycle = _ReuseCycle(self.color_list)\n        self.mpl_canvas = None\n        self.help_canvas = None\n        self.rms = None\n        self.picked_patches = {key: list() for key in all_keys}\n        self.picked_points = {key: list() for key in all_keys}\n        self.pick_table = dict()\n        self._spheres = list()\n        self._mouse_no_mvt = -1\n\n        # Derived parameters:\n        self.playback_speed = self.default_playback_speed_value\n        _validate_type(show_traces, (bool, str, \"numeric\"), \"show_traces\")\n        self.interactor_fraction = 0.25\n        if isinstance(show_traces, str):\n            self.show_traces = True\n            self.separate_canvas = False\n            self.traces_mode = \"vertex\"\n            if show_traces == \"separate\":\n                self.separate_canvas = True\n            elif show_traces == \"label\":\n                self.traces_mode = \"label\"\n            else:\n                assert show_traces == \"vertex\"  # guaranteed above\n        else:\n            if isinstance(show_traces, bool):\n                self.show_traces = show_traces\n            else:\n                show_traces = float(show_traces)\n                if not 0 < show_traces < 1:\n                    raise ValueError(\n                        \"show traces, if numeric, must be between 0 and 1, \"\n                        f\"got {show_traces}\"\n                    )\n                self.show_traces = True\n                self.interactor_fraction = show_traces\n            self.traces_mode = \"vertex\"\n            self.separate_canvas = False\n        del show_traces\n\n        self._configure_time_label()\n        self._configure_scalar_bar()\n        self._configure_shortcuts()\n        self._configure_picking()\n        self._configure_dock()\n        self._configure_tool_bar()\n        self._configure_menu()\n        self._configure_status_bar()\n        self._configure_help()\n        # show everything at the end\n        self.toggle_interface()\n        self._renderer.show()\n\n        # sizes could change, update views\n        for hemi in (\"lh\", \"rh\"):\n            for ri, ci, v in self._iter_views(hemi):\n                self.show_view(view=v, row=ri, col=ci)\n        self._renderer._process_events()\n\n        self._renderer._update()\n        # finally, show the MplCanvas\n        if self.show_traces:\n            self.mpl_canvas.show()", "metadata": {}}
{"_id": "mne_mne_viz/_brain/_brain.py_toggle_interface_code", "title": "toggle_interface", "text": "def toggle_interface(self, value=None):\n        \"\"\"Toggle the interface.\n\n        Parameters\n        ----------\n        value : bool | None\n            If True, the widgets are shown and if False, they\n            are hidden. If None, the state of the widgets is\n            toggled. Defaults to None.\n        \"\"\"\n        if value is None:\n            self.visibility = not self.visibility\n        else:\n            self.visibility = value\n\n        # update tool bar and dock\n        with self._renderer._window_ensure_minimum_sizes():\n            if self.visibility:\n                self._renderer._dock_show()\n                self._renderer._tool_bar_update_button_icon(\n                    name=\"visibility\", icon_name=\"visibility_on\"\n                )\n            else:\n                self._renderer._dock_hide()\n                self._renderer._tool_bar_update_button_icon(\n                    name=\"visibility\", icon_name=\"visibility_off\"\n                )\n\n        self._renderer._update()", "metadata": {}}
{"_id": "mne_mne_viz/_brain/_brain.py_apply_auto_scaling_code", "title": "apply_auto_scaling", "text": "def apply_auto_scaling(self):\n        \"\"\"Detect automatically fitting scaling parameters.\"\"\"\n        self._update_auto_scaling()", "metadata": {}}
{"_id": "mne_mne_viz/_brain/_brain.py_restore_user_scaling_code", "title": "restore_user_scaling", "text": "def restore_user_scaling(self):\n        \"\"\"Restore original scaling parameters.\"\"\"\n        self._update_auto_scaling(restore=True)", "metadata": {}}
{"_id": "mne_mne_viz/_brain/_brain.py_toggle_playback_code", "title": "toggle_playback", "text": "def toggle_playback(self, value=None):\n        \"\"\"Toggle time playback.\n\n        Parameters\n        ----------\n        value : bool | None\n            If True, automatic time playback is enabled and if False,\n            it's disabled. If None, the state of time playback is toggled.\n            Defaults to None.\n        \"\"\"\n        self._renderer._toggle_playback(value)", "metadata": {}}
{"_id": "mne_mne_viz/_brain/_brain.py_reset_code", "title": "reset", "text": "def reset(self):\n        \"\"\"Reset view, current time and time step.\"\"\"\n        self.reset_view()\n        self._renderer._reset_time()", "metadata": {}}
{"_id": "mne_mne_viz/_brain/_brain.py_set_playback_speed_code", "title": "set_playback_speed", "text": "def set_playback_speed(self, speed):\n        \"\"\"Set the time playback speed.\n\n        Parameters\n        ----------\n        speed : float\n            The speed of the playback.\n        \"\"\"\n        publish(self, PlaybackSpeed(speed=speed))", "metadata": {}}
{"_id": "mne_mne_viz/_brain/_brain.py_clear_glyphs_code", "title": "clear_glyphs", "text": "def clear_glyphs(self):\n        \"\"\"Clear the picking glyphs.\"\"\"\n        if not self.time_viewer:\n            return\n        for sphere in list(self._spheres):  # will remove itself, so copy\n            self._remove_vertex_glyph(sphere, render=False)\n        assert sum(len(v) for v in self.picked_points.values()) == 0\n        assert len(self.pick_table) == 0\n        assert len(self._spheres) == 0\n        for hemi in self._hemis:\n            for label_id in list(self.picked_patches[hemi]):\n                self._remove_label_glyph(hemi, label_id)\n        assert sum(len(v) for v in self.picked_patches.values()) == 0\n        if self.rms is not None:\n            self.rms.remove()\n            self.rms = None\n        self._renderer._update()", "metadata": {}}
{"_id": "mne_mne_viz/_brain/_brain.py_plot_time_course_code", "title": "plot_time_course", "text": "def plot_time_course(self, hemi, vertex_id, color, update=True):\n        \"\"\"Plot the vertex time course.\n\n        Parameters\n        ----------\n        hemi : str\n            The hemisphere id of the vertex.\n        vertex_id : int\n            The vertex identifier in the mesh.\n        color : matplotlib color\n            The color of the time course.\n        %(brain_update)s\n\n        Returns\n        -------\n        line : matplotlib object\n            The time line object.\n        \"\"\"\n        if self.mpl_canvas is None:\n            return\n        time = self._data[\"time\"].copy()  # avoid circular ref\n        mni = None\n        if hemi == \"vol\":\n            hemi_str = \"V\"\n            xfm = read_talxfm(self._subject, self._subjects_dir)\n            if self._units == \"mm\":\n                xfm[\"trans\"][:3, 3] *= 1000.0\n            ijk = np.unravel_index(vertex_id, self._data[hemi][\"grid_shape\"], order=\"F\")\n            src_mri_t = self._data[hemi][\"grid_src_mri_t\"]\n            mni = apply_trans(xfm[\"trans\"] @ src_mri_t, ijk)\n        else:\n            hemi_str = \"L\" if hemi == \"lh\" else \"R\"\n            try:\n                mni = vertex_to_mni(\n                    vertices=vertex_id,\n                    hemis=0 if hemi == \"lh\" else 1,\n                    subject=self._subject,\n                    subjects_dir=self._subjects_dir,\n                )\n            except Exception:\n                mni = None\n        if mni is not None:\n            mni = \" MNI: \" + \", \".join(f\"{m:5.1f}\" for m in mni)\n        else:\n            mni = \"\"\n        label = f\"{hemi_str}:{str(vertex_id).ljust(6)}{mni}\"\n        act_data, smooth = self.act_data_smooth[hemi]\n        if smooth is not None:\n            act_data = (smooth[[vertex_id]] @ act_data)[0]\n        else:\n            act_data = act_data[vertex_id].copy()\n        line = self.mpl_canvas.plot(\n            time,\n            act_data,\n            label=label,\n            lw=1.0,\n            color=color,\n            zorder=4,\n            update=update,\n        )\n        return line", "metadata": {}}
{"_id": "mne_mne_viz/_brain/_brain.py_plot_time_line_code", "title": "plot_time_line", "text": "def plot_time_line(self, update=True):\n        \"\"\"Add the time line to the MPL widget.\n\n        Parameters\n        ----------\n        %(brain_update)s\n        \"\"\"\n        if self.mpl_canvas is None:\n            return\n        if isinstance(self.show_traces, bool) and self.show_traces:\n            # add time information\n            current_time = self._current_time\n            if not hasattr(self, \"time_line\"):\n                self.time_line = self.mpl_canvas.plot_time_line(\n                    x=current_time,\n                    label=\"time\",\n                    color=self._fg_color,\n                    lw=1,\n                    update=update,\n                )\n            self.time_line.set_xdata([current_time])\n            if update:\n                self.mpl_canvas.update_plot()", "metadata": {}}
{"_id": "mne_mne_viz/_brain/_brain.py_help_code", "title": "help", "text": "def help(self):\n        \"\"\"Display the help window.\"\"\"\n        self.help_canvas.show()", "metadata": {}}
{"_id": "mne_mne_viz/_brain/_brain.py_interaction_code", "title": "interaction", "text": "def interaction(self):\n        \"\"\"The interaction style.\"\"\"\n        return self._interaction", "metadata": {}}
{"_id": "mne_mne_viz/_brain/_brain.py_interaction_code", "title": "interaction", "text": "def interaction(self, interaction):\n        \"\"\"Set the interaction style.\"\"\"\n        _validate_type(interaction, str, \"interaction\")\n        _check_option(\"interaction\", interaction, (\"trackball\", \"terrain\"))\n        for _ in self._iter_views(\"vol\"):  # will traverse all\n            self._renderer.set_interaction(interaction)", "metadata": {}}
{"_id": "mne_mne_viz/_brain/_brain.py_add_data_code", "title": "add_data", "text": "def add_data(\n        self,\n        array,\n        fmin=None,\n        fmid=None,\n        fmax=None,\n        thresh=None,\n        center=None,\n        transparent=False,\n        colormap=\"auto\",\n        alpha=1,\n        vertices=None,\n        smoothing_steps=None,\n        time=None,\n        time_label=\"auto\",\n        colorbar=True,\n        hemi=None,\n        remove_existing=None,\n        time_label_size=None,\n        initial_time=None,\n        scale_factor=None,\n        vector_alpha=None,\n        clim=None,\n        src=None,\n        volume_options=0.4,\n        colorbar_kwargs=None,\n        verbose=None,\n    ):\n        \"\"\"Display data from a numpy array on the surface or volume.\n\n        This provides a similar interface to PySurfer, but it displays\n        it with a single colormap. It offers more flexibility over the\n        colormap, and provides a way to display four-dimensional data\n        (i.e., a timecourse) or five-dimensional data (i.e., a\n        vector-valued timecourse).\n\n        .. note:: ``fmin`` sets the low end of the colormap, and is separate\n                  from thresh (this is a different convention from PySurfer).\n\n        Parameters\n        ----------\n        array : numpy array, shape (n_vertices[, 3][, n_times])\n            Data array. For the data to be understood as vector-valued\n            (3 values per vertex corresponding to X/Y/Z surface RAS),\n            then ``array`` must be have all 3 dimensions.\n            If vectors with no time dimension are desired, consider using a\n            singleton (e.g., ``np.newaxis``) to create a \"time\" dimension\n            and pass ``time_label=None`` (vector values are not supported).\n        %(fmin_fmid_fmax)s\n        %(thresh)s\n        %(center)s\n        %(transparent)s\n        colormap : str, list of color, or array\n            Name of matplotlib colormap to use, a list of matplotlib colors,\n            or a custom look up table (an n x 4 array coded with RBGA values\n            between 0 and 255), the default \"auto\" chooses a default divergent\n            colormap, if \"center\" is given (currently \"icefire\"), otherwise a\n            default sequential colormap (currently \"rocket\").\n        alpha : float in [0, 1]\n            Alpha level to control opacity of the overlay.\n        vertices : numpy array\n            Vertices for which the data is defined (needed if\n            ``len(data) < nvtx``).\n        smoothing_steps : int or None\n            Number of smoothing steps (smoothing is used if len(data) < nvtx)\n            The value 'nearest' can be used too. None (default) will use as\n            many as necessary to fill the surface.\n        time : numpy array\n            Time points in the data array (if data is 2D or 3D).\n        %(time_label)s\n        colorbar : bool\n            Whether to add a colorbar to the figure. Can also be a tuple\n            to give the (row, col) index of where to put the colorbar.\n        hemi : str | None\n            If None, it is assumed to belong to the hemisphere being\n            shown. If two hemispheres are being shown, an error will\n            be thrown.\n        remove_existing : bool\n            Not supported yet.\n            Remove surface added by previous \"add_data\" call. Useful for\n            conserving memory when displaying different data in a loop.\n        time_label_size : int\n            Font size of the time label (default 14).\n        initial_time : float | None\n            Time initially shown in the plot. ``None`` to use the first time\n            sample (default).\n        scale_factor : float | None (default)\n            The scale factor to use when displaying glyphs for vector-valued\n            data.\n        vector_alpha : float | None\n            Alpha level to control opacity of the arrows. Only used for\n            vector-valued data. If None (default), ``alpha`` is used.\n        clim : dict\n            Original clim arguments.\n        %(src_volume_options)s\n        colorbar_kwargs : dict | None\n            Options to pass to ``pyvista.Plotter.add_scalar_bar``\n            (e.g., ``dict(title_font_size=10)``).\n        %(verbose)s\n\n        Notes\n        -----\n        If the data is defined for a subset of vertices (specified\n        by the \"vertices\" parameter), a smoothing method is used to interpolate\n        the data onto the high resolution surface. If the data is defined for\n        subsampled version of the surface, smoothing_steps can be set to None,\n        in which case only as many smoothing steps are applied until the whole\n        surface is filled with non-zeros.\n\n        Due to a VTK alpha rendering bug, ``vector_alpha`` is\n        clamped to be strictly < 1.\n        \"\"\"\n        _validate_type(transparent, bool, \"transparent\")\n        _validate_type(vector_alpha, (\"numeric\", None), \"vector_alpha\")\n        _validate_type(scale_factor, (\"numeric\", None), \"scale_factor\")\n\n        # those parameters are not supported yet, only None is allowed\n        _check_option(\"thresh\", thresh, [None])\n        _check_option(\"remove_existing\", remove_existing, [None])\n        _validate_type(time_label_size, (None, \"numeric\"), \"time_label_size\")\n        if time_label_size is not None:\n            time_label_size = float(time_label_size)\n            if time_label_size < 0:\n                raise ValueError(\n                    f\"time_label_size must be positive, got {time_label_size}\"\n                )\n\n        hemi = self._check_hemi(hemi, extras=[\"vol\"])\n        stc, array, vertices = self._check_stc(hemi, array, vertices)\n        array = np.asarray(array)\n        vector_alpha = alpha if vector_alpha is None else vector_alpha\n        self._data[\"vector_alpha\"] = vector_alpha\n        self._data[\"scale_factor\"] = scale_factor\n\n        # Create time array and add label if > 1D\n        if array.ndim <= 1:\n            time_idx = 0\n        else:\n            # check time array\n            if time is None:\n                time = np.arange(array.shape[-1])\n            else:\n                time = np.asarray(time)\n                if time.shape != (array.shape[-1],):\n                    raise ValueError(\n                        f\"time has shape {time.shape}, but need shape \"\n                        f\"{(array.shape[-1],)} (array.shape[-1])\"\n                    )\n            self._data[\"time\"] = time\n\n            if self._n_times is None:\n                self._times = time\n            elif len(time) != self._n_times:\n                raise ValueError(\"New n_times is different from previous n_times\")\n            elif not np.array_equal(time, self._times):\n                raise ValueError(\n                    \"Not all time values are consistent with previously set times.\"\n                )\n\n            # initial time\n            if initial_time is None:\n                time_idx = 0\n            else:\n                time_idx = self._to_time_index(initial_time)\n\n        # time label\n        time_label, _ = _handle_time(time_label, \"s\", time)\n        y_txt = 0.05 + 0.1 * bool(colorbar)\n\n        if array.ndim == 3:\n            if array.shape[1] != 3:\n                raise ValueError(\n                    \"If array has 3 dimensions, array.shape[1] must equal 3, got \"\n                    f\"{array.shape[1]}\"\n                )\n        fmin, fmid, fmax = _update_limits(fmin, fmid, fmax, center, array)\n        if colormap == \"auto\":\n            colormap = \"mne\" if center is not None else \"hot\"\n\n        if smoothing_steps is None:\n            smoothing_steps = 7\n        elif smoothing_steps == \"nearest\":\n            smoothing_steps = -1\n        elif isinstance(smoothing_steps, int):\n            if smoothing_steps < 0:\n                raise ValueError(\n                    \"Expected value of `smoothing_steps` is positive but \"\n                    f\"{smoothing_steps} was given.\"\n                )\n        else:\n            raise TypeError(\n                \"Expected type of `smoothing_steps` is int or NoneType but \"\n                f\"{type(smoothing_steps)} was given.\"\n            )\n\n        self._data[\"stc\"] = stc\n        self._data[\"src\"] = src\n        self._data[\"smoothing_steps\"] = smoothing_steps\n        self._data[\"clim\"] = clim\n        self._data[\"time\"] = time\n        self._data[\"initial_time\"] = initial_time\n        self._data[\"time_label\"] = time_label\n        self._data[\"initial_time_idx\"] = time_idx\n        self._data[\"time_idx\"] = time_idx\n        self._data[\"transparent\"] = transparent\n        # data specific for a hemi\n        self._data[hemi] = dict()\n        self._data[hemi][\"glyph_dataset\"] = None\n        self._data[hemi][\"glyph_mapper\"] = None\n        self._data[hemi][\"glyph_actor\"] = None\n        self._data[hemi][\"array\"] = array\n        self._data[hemi][\"vertices\"] = vertices\n        self._data[\"alpha\"] = alpha\n        self._data[\"colormap\"] = colormap\n        self._data[\"center\"] = center\n        self._data[\"fmin\"] = fmin\n        self._data[\"fmid\"] = fmid\n        self._data[\"fmax\"] = fmax\n        self._update_colormap_range()\n\n        # 1) add the surfaces first\n        actor = None\n        for _ in self._iter_views(hemi):\n            if hemi in (\"lh\", \"rh\"):\n                actor = self._layered_meshes[hemi]._actor\n            else:\n                src_vol = src[2:] if src.kind == \"mixed\" else src\n                actor, _ = self._add_volume_data(hemi, src_vol, volume_options)\n        assert actor is not None  # should have added one\n        self._add_actor(\"data\", actor)\n\n        # 2) update time and smoothing properties\n        # set_data_smoothing calls \"_update_current_time_idx\" for us, which will set\n        # _current_time\n        self.set_time_interpolation(self.time_interpolation)\n        self.set_data_smoothing(self._data[\"smoothing_steps\"])\n\n        # 3) add the other actors\n        if colorbar is True:\n            # bottom left by default\n            colorbar = (self._subplot_shape[0] - 1, 0)\n        for ri, ci, v in self._iter_views(hemi):\n            # Add the time label to the bottommost view\n            do = (ri, ci) == colorbar\n            if not self._time_label_added and time_label is not None and do:\n                time_actor = self._renderer.text2d(\n                    x_window=0.95,\n                    y_window=y_txt,\n                    color=self._fg_color,\n                    size=time_label_size,\n                    text=time_label(self._current_time),\n                    justification=\"right\",\n                )\n                self._data[\"time_actor\"] = time_actor\n                self._time_label_added = True\n            if colorbar and self._scalar_bar is None and do:\n                kwargs = dict(\n                    source=actor,\n                    n_labels=8,\n                    color=self._fg_color,\n                    bgcolor=self._brain_color[:3],\n                )\n                kwargs.update(colorbar_kwargs or {})\n                self._scalar_bar = self._renderer.scalarbar(**kwargs)\n            self._set_camera(**views_dicts[hemi][v])\n\n        # 4) update the scalar bar and opacity (and render)\n        self._update_colormap_range(alpha=alpha)\n\n        # 5) enable UI events to interact with the data\n        subscribe(self, \"colormap_range\", self._on_colormap_range)\n        if time is not None and len(time) > 1:\n            subscribe(self, \"time_change\", self._on_time_change)", "metadata": {}}
{"_id": "mne_mne_viz/_brain/_brain.py_remove_data_code", "title": "remove_data", "text": "def remove_data(self):\n        \"\"\"Remove rendered data from the mesh.\"\"\"\n        self._remove(\"data\", render=True)\n\n        # Stop listening to events\n        if \"time_change\" in _get_event_channel(self):\n            unsubscribe(self, \"time_change\")", "metadata": {}}
{"_id": "mne_mne_viz/_brain/_brain.py_remove_labels_code", "title": "remove_labels", "text": "def remove_labels(self):\n        \"\"\"Remove all the ROI labels from the image.\"\"\"\n        for hemi in self._hemis:\n            mesh = self._layered_meshes[hemi]\n            for label in self._labels[hemi]:\n                mesh.remove_overlay(label.name)\n            self._labels[hemi].clear()\n        self._renderer._update()", "metadata": {}}
{"_id": "mne_mne_viz/_brain/_brain.py_remove_annotations_code", "title": "remove_annotations", "text": "def remove_annotations(self):\n        \"\"\"Remove all annotations from the image.\"\"\"\n        for hemi in self._hemis:\n            if hemi in self._layered_meshes:\n                mesh = self._layered_meshes[hemi]\n                mesh.remove_overlay(self._annots[hemi])\n            if hemi in self._annots:\n                self._annots[hemi].clear()\n        self._renderer._update()", "metadata": {}}
{"_id": "mne_mne_viz/_brain/_brain.py_add_label_code", "title": "add_label", "text": "def add_label(\n        self,\n        label,\n        color=None,\n        alpha=1,\n        scalar_thresh=None,\n        borders=False,\n        hemi=None,\n        subdir=None,\n    ):\n        \"\"\"Add an ROI label to the image.\n\n        Parameters\n        ----------\n        label : str | instance of Label\n            Label filepath or name. Can also be an instance of\n            an object with attributes \"hemi\", \"vertices\", \"name\", and\n            optionally \"color\" and \"values\" (if scalar_thresh is not None).\n        color : matplotlib-style color | None\n            Anything matplotlib accepts: string, RGB, hex, etc. (default\n            \"crimson\").\n        alpha : float in [0, 1]\n            Alpha level to control opacity.\n        scalar_thresh : None | float\n            Threshold the label ids using this value in the label\n            file's scalar field (i.e. label only vertices with\n            scalar >= thresh).\n        borders : bool | int\n            Show only label borders. If int, specify the number of steps\n            (away from the true border) along the cortical mesh to include\n            as part of the border definition.\n        hemi : str | None\n            If None, it is assumed to belong to the hemisphere being\n            shown.\n        subdir : None | str\n            If a label is specified as name, subdir can be used to indicate\n            that the label file is in a sub-directory of the subject's\n            label directory rather than in the label directory itself (e.g.\n            for ``$SUBJECTS_DIR/$SUBJECT/label/aparc/lh.cuneus.label``\n            ``brain.add_label('cuneus', subdir='aparc')``).\n\n        Notes\n        -----\n        To remove previously added labels, run Brain.remove_labels().\n        \"\"\"\n        from ...label import read_label\n\n        if isinstance(label, str):\n            if color is None:\n                color = \"crimson\"\n\n            if os.path.isfile(label):\n                filepath = label\n                label = read_label(filepath)\n                hemi = label.hemi\n                label_name = os.path.basename(filepath).split(\".\")[1]\n            else:\n                hemi = self._check_hemi(hemi)\n                label_name = label\n                label_fname = \".\".join([hemi, label_name, \"label\"])\n                if subdir is None:\n                    filepath = op.join(\n                        self._subjects_dir, self._subject, \"label\", label_fname\n                    )\n                else:\n                    filepath = op.join(\n                        self._subjects_dir, self._subject, \"label\", subdir, label_fname\n                    )\n                if not os.path.exists(filepath):\n                    raise ValueError(f\"Label file {filepath} does not exist\")\n                label = read_label(filepath)\n            ids = label.vertices\n            scalars = label.values\n        else:\n            # try to extract parameters from label instance\n            try:\n                hemi = label.hemi\n                ids = label.vertices\n                if label.name is None:\n                    label.name = \"unnamed\" + str(self._unnamed_label_id)\n                    self._unnamed_label_id += 1\n                label_name = str(label.name)\n\n                if color is None:\n                    if hasattr(label, \"color\") and label.color is not None:\n                        color = label.color\n                    else:\n                        color = \"crimson\"\n\n                if scalar_thresh is not None:\n                    scalars = label.values\n            except Exception:\n                raise ValueError(\n                    \"Label was not a filename (str), and could \"\n                    \"not be understood as a class. The class \"\n                    'must have attributes \"hemi\", \"vertices\", '\n                    '\"name\", and (if scalar_thresh is not None)'\n                    '\"values\"'\n                )\n            hemi = self._check_hemi(hemi)\n\n        if scalar_thresh is not None:\n            ids = ids[scalars >= scalar_thresh]\n\n        if self.time_viewer and self.show_traces and self.traces_mode == \"label\":\n            stc = self._data[\"stc\"]\n            src = self._data[\"src\"]\n            tc = stc.extract_label_time_course(\n                label, src=src, mode=self.label_extract_mode\n            )\n            tc = tc[0] if tc.ndim == 2 else tc[0, 0, :]\n            color = next(self.color_cycle)\n            line = self.mpl_canvas.plot(\n                self._data[\"time\"], tc, label=label_name, color=color\n            )\n        else:\n            line = None\n\n        orig_color = color\n        color = _to_rgb(color, alpha, alpha=True)\n        cmap = np.array(\n            [\n                (\n                    0,\n                    0,\n                    0,\n                    0,\n                ),\n                color,\n            ]\n        )\n        ctable = np.round(cmap * 255).astype(np.uint8)\n\n        scalars = np.zeros(self.geo[hemi].coords.shape[0])\n        scalars[ids] = 1\n        if borders:\n            keep_idx = _mesh_borders(self.geo[hemi].faces, scalars)\n            show = np.zeros(scalars.size, dtype=np.int64)\n            if isinstance(borders, int):\n                for _ in range(borders):\n                    keep_idx = np.isin(self.geo[hemi].faces.ravel(), keep_idx)\n                    keep_idx.shape = self.geo[hemi].faces.shape\n                    keep_idx = self.geo[hemi].faces[np.any(keep_idx, axis=1)]\n                    keep_idx = np.unique(keep_idx)\n            show[keep_idx] = 1\n            scalars *= show\n        for _, _, v in self._iter_views(hemi):\n            mesh = self._layered_meshes[hemi]\n            mesh.add_overlay(\n                scalars=scalars,\n                colormap=ctable,\n                rng=[np.min(scalars), np.max(scalars)],\n                opacity=alpha,\n                name=label_name,\n            )\n            if self.time_viewer and self.show_traces and self.traces_mode == \"label\":\n                label._color = orig_color\n                label._line = line\n            self._labels[hemi].append(label)\n        self._renderer._update()", "metadata": {}}
{"_id": "mne_mne_viz/_brain/_brain.py_add_forward_code", "title": "add_forward", "text": "def add_forward(self, fwd, trans, alpha=1, scale=None):\n        \"\"\"Add a quiver to render positions of dipoles.\n\n        Parameters\n        ----------\n        %(fwd)s\n        %(trans_not_none)s\n        %(alpha)s Default 1.\n        scale : None | float\n            The size of the arrow representing the dipoles in\n            :class:`mne.viz.Brain` units. Default 1.5mm.\n\n        Notes\n        -----\n        .. versionadded:: 1.0\n        \"\"\"\n        head_mri_t = _get_trans(trans, \"head\", \"mri\", allow_none=False)[0]\n        del trans\n        if scale is None:\n            scale = 1.5 if self._units == \"mm\" else 1.5e-3\n        error_msg = (\n            'Unexpected forward model coordinate frame {}, must be \"head\" or \"mri\"'\n        )\n        if fwd[\"coord_frame\"] in _frame_to_str:\n            fwd_frame = _frame_to_str[fwd[\"coord_frame\"]]\n            if fwd_frame == \"mri\":\n                fwd_trans = Transform(\"mri\", \"mri\")\n            elif fwd_frame == \"head\":\n                fwd_trans = head_mri_t\n            else:\n                raise RuntimeError(error_msg.format(fwd_frame))\n        else:\n            raise RuntimeError(error_msg.format(fwd[\"coord_frame\"]))\n        for actor in _plot_forward(\n            self._renderer,\n            fwd,\n            fwd_trans,\n            fwd_scale=1e3 if self._units == \"mm\" else 1,\n            scale=scale,\n            alpha=alpha,\n        ):\n            self._add_actor(\"forward\", actor)\n\n        self._renderer._update()", "metadata": {}}
{"_id": "mne_mne_viz/_brain/_brain.py_remove_forward_code", "title": "remove_forward", "text": "def remove_forward(self):\n        \"\"\"Remove forward sources from the rendered scene.\"\"\"\n        self._remove(\"forward\", render=True)", "metadata": {}}
{"_id": "mne_mne_viz/_brain/_brain.py_add_dipole_code", "title": "add_dipole", "text": "def add_dipole(\n        self, dipole, trans, colors=\"red\", alpha=1, scales=None, *, mode=\"arrow\"\n    ):\n        \"\"\"Add a quiver to render positions of dipoles.\n\n        Parameters\n        ----------\n        dipole : instance of Dipole\n            Dipole object containing position, orientation and amplitude of\n            one or more dipoles or in the forward solution.\n        %(trans_not_none)s\n        colors : list | matplotlib-style color | None\n            A single color or list of anything matplotlib accepts:\n            string, RGB, hex, etc. Default red.\n        %(alpha)s Default 1.\n        scales : list | float | None\n            The size of the arrow representing the dipole in\n            :class:`mne.viz.Brain` units. Default 5mm.\n        mode : \"2darrow\" | \"arrow\" | \"cone\" | \"cylinder\" | \"sphere\" | \"oct\"\n            The drawing mode for the dipole to render.\n            Defaults to ``\"arrow\"``.\n\n        Notes\n        -----\n        .. versionadded:: 1.0\n        \"\"\"\n        head_mri_t = _get_trans(trans, \"head\", \"mri\", allow_none=False)[0]\n        del trans\n        n_dipoles = len(dipole)\n        if not isinstance(colors, list | tuple):\n            colors = [colors] * n_dipoles  # make into list\n        if len(colors) != n_dipoles:\n            raise ValueError(\n                f\"The number of colors ({len(colors)}) \"\n                f\"and dipoles ({n_dipoles}) must match\"\n            )\n        colors = [\n            _to_rgb(color, name=f\"colors[{ci}]\") for ci, color in enumerate(colors)\n        ]\n        if scales is None:\n            scales = 5 if self._units == \"mm\" else 5e-3\n        if not isinstance(scales, list | tuple):\n            scales = [scales] * n_dipoles  # make into list\n        if len(scales) != n_dipoles:\n            raise ValueError(\n                f\"The number of scales ({len(scales)}) \"\n                f\"and dipoles ({n_dipoles}) must match\"\n            )\n        pos = apply_trans(head_mri_t, dipole.pos)\n        pos *= 1e3 if self._units == \"mm\" else 1\n        for _ in self._iter_views(\"vol\"):\n            for this_pos, this_ori, color, scale in zip(\n                pos, dipole.ori, colors, scales\n            ):\n                actor, _ = self._renderer.quiver3d(\n                    *this_pos,\n                    *this_ori,\n                    color=color,\n                    opacity=alpha,\n                    mode=mode,\n                    scale=scale,\n                )\n                self._add_actor(\"dipole\", actor)\n\n        self._renderer._update()", "metadata": {}}
{"_id": "mne_mne_viz/_brain/_brain.py_remove_dipole_code", "title": "remove_dipole", "text": "def remove_dipole(self):\n        \"\"\"Remove dipole objects from the rendered scene.\"\"\"\n        self._remove(\"dipole\", render=True)", "metadata": {}}
{"_id": "mne_mne_viz/_brain/_brain.py_add_head_code", "title": "add_head", "text": "def add_head(self, dense=True, color=\"gray\", alpha=0.5):\n        \"\"\"Add a mesh to render the outer head surface.\n\n        Parameters\n        ----------\n        dense : bool\n            Whether to plot the dense head (``seghead``) or the less dense head\n            (``head``).\n        %(color_matplotlib)s\n        %(alpha)s\n\n        Notes\n        -----\n        .. versionadded:: 0.24\n        \"\"\"\n        # load head\n        surf = _get_head_surface(\n            \"seghead\" if dense else \"head\", self._subject, self._subjects_dir\n        )\n        verts, triangles = surf[\"rr\"], surf[\"tris\"]\n        verts *= 1e3 if self._units == \"mm\" else 1\n        color = _to_rgb(color)\n\n        for _ in self._iter_views(\"vol\"):\n            actor, _ = self._renderer.mesh(\n                *verts.T,\n                triangles=triangles,\n                color=color,\n                opacity=alpha,\n                render=False,\n            )\n            self._add_actor(\"head\", actor)\n\n        self._renderer._update()", "metadata": {}}
{"_id": "mne_mne_viz/_brain/_brain.py_remove_head_code", "title": "remove_head", "text": "def remove_head(self):\n        \"\"\"Remove head objects from the rendered scene.\"\"\"\n        self._remove(\"head\", render=True)", "metadata": {}}
{"_id": "mne_mne_viz/_brain/_brain.py_add_skull_code", "title": "add_skull", "text": "def add_skull(self, outer=True, color=\"gray\", alpha=0.5):\n        \"\"\"Add a mesh to render the skull surface.\n\n        Parameters\n        ----------\n        outer : bool\n            Adds the outer skull if ``True``, otherwise adds the inner skull.\n        %(color_matplotlib)s\n        %(alpha)s\n\n        Notes\n        -----\n        .. versionadded:: 0.24\n        \"\"\"\n        surf = _get_skull_surface(\n            \"outer\" if outer else \"inner\", self._subject, self._subjects_dir\n        )\n        verts, triangles = surf[\"rr\"], surf[\"tris\"]\n        verts *= 1e3 if self._units == \"mm\" else 1\n        color = _to_rgb(color)\n\n        for _ in self._iter_views(\"vol\"):\n            actor, _ = self._renderer.mesh(\n                *verts.T,\n                triangles=triangles,\n                color=color,\n                opacity=alpha,\n                reset_camera=False,\n                render=False,\n            )\n            self._add_actor(\"skull\", actor)\n\n        self._renderer._update()", "metadata": {}}
{"_id": "mne_mne_viz/_brain/_brain.py_remove_skull_code", "title": "remove_skull", "text": "def remove_skull(self):\n        \"\"\"Remove skull objects from the rendered scene.\"\"\"\n        self._remove(\"skull\", render=True)", "metadata": {}}
{"_id": "mne_mne_viz/_brain/_brain.py_add_volume_labels_code", "title": "add_volume_labels", "text": "def add_volume_labels(\n        self,\n        aseg=\"auto\",\n        labels=None,\n        colors=None,\n        alpha=0.5,\n        smooth=0.9,\n        fill_hole_size=None,\n        legend=None,\n    ):\n        \"\"\"Add labels to the rendering from an anatomical segmentation.\n\n        Parameters\n        ----------\n        %(aseg)s\n        labels : list\n            Labeled regions of interest to plot. See\n            :func:`mne.get_montage_volume_labels`\n            for one way to determine regions of interest. Regions can also be\n            chosen from the :term:`FreeSurfer LUT`.\n        colors : list | matplotlib-style color | None\n            A list of anything matplotlib accepts: string, RGB, hex, etc.\n            (default :term:`FreeSurfer LUT` colors).\n        %(alpha)s\n        %(smooth)s\n        fill_hole_size : int | None\n            The size of holes to remove in the mesh in voxels. Default is None,\n            no holes are removed. Warning, this dilates the boundaries of the\n            surface by ``fill_hole_size`` number of voxels so use the minimal\n            size.\n        legend : bool | None | dict\n            Add a legend displaying the names of the ``labels``. Default (None)\n            is ``True`` if the number of ``labels`` is 10 or fewer.\n            Can also be a dict of ``kwargs`` to pass to\n            ``pyvista.Plotter.add_legend``.\n\n        Notes\n        -----\n        .. versionadded:: 0.24\n        \"\"\"\n        aseg, aseg_data = _get_aseg(aseg, self._subject, self._subjects_dir)\n\n        vox_mri_t = aseg.header.get_vox2ras_tkr()\n        mult = 1e-3 if self._units == \"m\" else 1\n        vox_mri_t[:3] *= mult\n        del aseg\n\n        # read freesurfer lookup table\n        lut, fs_colors = read_freesurfer_lut()\n        if labels is None:  # assign default ROI labels based on indices\n            lut_r = {v: k for k, v in lut.items()}\n            labels = [lut_r[idx] for idx in DEFAULTS[\"volume_label_indices\"]]\n\n        _validate_type(fill_hole_size, (int, None), \"fill_hole_size\")\n        _validate_type(legend, (bool, None, dict), \"legend\")\n        if legend is None:\n            legend = len(labels) < 11\n\n        if colors is None:\n            colors = [fs_colors[label] / 255 for label in labels]\n        elif not isinstance(colors, list | tuple):\n            colors = [colors] * len(labels)  # make into list\n        colors = [\n            _to_rgb(color, name=f\"colors[{ci}]\") for ci, color in enumerate(colors)\n        ]\n        surfs = _marching_cubes(\n            aseg_data,\n            [lut[label] for label in labels],\n            smooth=smooth,\n            fill_hole_size=fill_hole_size,\n        )\n        for label, color, (verts, triangles) in zip(labels, colors, surfs):\n            if len(verts) == 0:  # not in aseg vals\n                warn(\n                    f\"Value {lut[label]} not found for label \"\n                    f\"{repr(label)} in anatomical segmentation file \"\n                )\n                continue\n            verts = apply_trans(vox_mri_t, verts)\n            for _ in self._iter_views(\"vol\"):\n                actor, _ = self._renderer.mesh(\n                    *verts.T,\n                    triangles=triangles,\n                    color=color,\n                    opacity=alpha,\n                    reset_camera=False,\n                    render=False,\n                )\n                self._add_actor(\"volume_labels\", actor)\n\n        if legend or isinstance(legend, dict):\n            # use empty kwargs for legend = True\n            legend = legend if isinstance(legend, dict) else dict()\n            self._renderer.plotter.add_legend(list(zip(labels, colors)), **legend)\n\n        self._renderer._update()", "metadata": {}}
{"_id": "mne_mne_viz/_brain/_brain.py_remove_volume_labels_code", "title": "remove_volume_labels", "text": "def remove_volume_labels(self):\n        \"\"\"Remove the volume labels from the rendered scene.\"\"\"\n        self._remove(\"volume_labels\", render=True)\n        self._renderer.plotter.remove_legend()", "metadata": {}}
{"_id": "mne_mne_viz/_brain/_brain.py_add_foci_code", "title": "add_foci", "text": "def add_foci(\n        self,\n        coords,\n        coords_as_verts=False,\n        map_surface=None,\n        scale_factor=1,\n        color=\"white\",\n        alpha=1,\n        name=None,\n        hemi=None,\n        resolution=50,\n    ):\n        \"\"\"Add spherical foci, possibly mapping to displayed surf.\n\n        The foci spheres can be displayed at the coordinates given, or\n        mapped through a surface geometry. In other words, coordinates\n        from a volume-based analysis in MNI space can be displayed on an\n        inflated average surface by finding the closest vertex on the\n        white surface and mapping to that vertex on the inflated mesh.\n\n        Parameters\n        ----------\n        coords : ndarray, shape (n_coords, 3)\n            Coordinates in stereotaxic space (default) or array of\n            vertex ids (with ``coord_as_verts=True``).\n        coords_as_verts : bool\n            Whether the coords parameter should be interpreted as vertex ids.\n        map_surface : str | None\n            Surface to project the coordinates to, or None to use raw coords.\n            When set to a surface, each foci is positioned at the closest\n            vertex in the mesh.\n        scale_factor : float\n            Controls the size of the foci spheres (relative to 1cm).\n        %(color_matplotlib)s\n        %(alpha)s Default is 1.\n        name : str\n            Internal name to use.\n        hemi : str | None\n            If None, it is assumed to belong to the hemisphere being\n            shown. If two hemispheres are being shown, an error will\n            be thrown.\n        resolution : int\n            The resolution of the spheres.\n        \"\"\"\n        hemi = self._check_hemi(hemi, extras=[\"vol\"])\n\n        # Figure out how to interpret the first parameter\n        if coords_as_verts:\n            coords = self.geo[hemi].coords[coords]\n            map_surface = None\n\n        # Possibly map the foci coords through a surface\n        if map_surface is not None:\n            foci_surf = _Surface(\n                self._subject,\n                hemi,\n                map_surface,\n                self._subjects_dir,\n                offset=0,\n                units=self._units,\n                x_dir=self._rigid[0, :3],\n            )\n            foci_surf.load_geometry()\n            foci_vtxs = np.argmin(cdist(foci_surf.coords, coords), axis=0)\n            coords = self.geo[hemi].coords[foci_vtxs]\n\n        # Convert the color code\n        color = _to_rgb(color)\n\n        if self._units == \"m\":\n            scale_factor = scale_factor / 1000.0\n\n        for _, _, v in self._iter_views(hemi):\n            self._renderer.sphere(\n                center=coords,\n                color=color,\n                scale=(10.0 * scale_factor),\n                opacity=alpha,\n                resolution=resolution,\n            )\n            self._set_camera(**views_dicts[hemi][v])\n        self._renderer._update()\n\n        # Store the foci in the Brain._data dictionary\n        data_foci = coords\n        if \"foci\" in self._data.get(hemi, []):\n            data_foci = np.vstack((self._data[hemi][\"foci\"], data_foci))\n        self._data[hemi] = self._data.get(hemi, dict())  # no data added yet\n        self._data[hemi][\"foci\"] = data_foci", "metadata": {}}
{"_id": "mne_mne_viz/_brain/_brain.py_add_sensors_code", "title": "add_sensors", "text": "def add_sensors(\n        self,\n        info,\n        trans,\n        meg=None,\n        eeg=\"original\",\n        fnirs=True,\n        ecog=True,\n        seeg=True,\n        dbs=True,\n        max_dist=0.004,\n        *,\n        sensor_colors=None,\n        sensor_scales=None,\n        verbose=None,\n    ):\n        \"\"\"Add mesh objects to represent sensor positions.\n\n        Parameters\n        ----------\n        %(info_not_none)s\n        %(trans_not_none)s\n        %(meg)s\n        %(eeg)s\n        %(fnirs)s\n        %(ecog)s\n        %(seeg)s\n        %(dbs)s\n        %(max_dist_ieeg)s\n        %(sensor_colors)s\n\n            .. versionadded:: 1.6\n        %(sensor_scales)s\n\n            .. versionadded:: 1.9\n        %(verbose)s\n\n        Notes\n        -----\n        .. versionadded:: 0.24\n        \"\"\"\n        from ...preprocessing.ieeg._projection import _project_sensors_onto_inflated\n\n        _validate_type(info, Info, \"info\")\n        meg, eeg, fnirs, warn_meg, sensor_alpha = _handle_sensor_types(meg, eeg, fnirs)\n        picks = pick_types(\n            info,\n            meg=(\"sensors\" in meg),\n            ref_meg=(\"ref\" in meg),\n            eeg=(len(eeg) > 0),\n            ecog=ecog,\n            seeg=seeg,\n            dbs=dbs,\n            fnirs=(len(fnirs) > 0),\n        )\n        head_mri_t = _get_trans(trans, \"head\", \"mri\", allow_none=False)[0]\n        if self._surf in (\"inflated\", \"flat\"):\n            for modality, check in dict(seeg=seeg, ecog=ecog).items():\n                if pick_types(info, **{modality: check}).size > 0:\n                    info = _project_sensors_onto_inflated(\n                        info.copy(),\n                        head_mri_t,\n                        subject=self._subject,\n                        subjects_dir=self._subjects_dir,\n                        picks=modality,\n                        max_dist=max_dist,\n                        flat=self._surf == \"flat\",\n                    )\n        del trans\n        # get transforms to \"mri\" window\n        to_cf_t = _get_transforms_to_coord_frame(info, head_mri_t, coord_frame=\"mri\")\n        if pick_types(info, eeg=True, exclude=()).size > 0 and \"projected\" in eeg:\n            head_surf = _get_head_surface(\"seghead\", self._subject, self._subjects_dir)\n        else:\n            head_surf = None\n        # Do the main plotting\n        for _ in self._iter_views(\"vol\"):\n            if picks.size > 0:\n                sensors_actors = _plot_sensors_3d(\n                    self._renderer,\n                    info,\n                    to_cf_t,\n                    picks,\n                    meg,\n                    eeg,\n                    fnirs,\n                    warn_meg,\n                    head_surf,\n                    self._units,\n                    sensor_alpha=sensor_alpha,\n                    sensor_colors=sensor_colors,\n                    sensor_scales=sensor_scales,\n                )\n                # sensors_actors can still be None\n                for item, actors in (sensors_actors or {}).items():\n                    for actor in actors:\n                        self._add_actor(item, actor)\n\n            if \"helmet\" in meg and pick_types(info, meg=True).size > 0:\n                actor, _, _ = _plot_helmet(\n                    self._renderer,\n                    info,\n                    to_cf_t,\n                    head_mri_t,\n                    \"mri\",\n                    alpha=sensor_alpha[\"meg_helmet\"],\n                    scale=1 if self._units == \"m\" else 1e3,\n                )\n                self._add_actor(\"helmet\", actor)\n\n        self._renderer._update()", "metadata": {}}
{"_id": "mne_mne_viz/_brain/_brain.py_remove_sensors_code", "title": "remove_sensors", "text": "def remove_sensors(self, kind=None):\n        \"\"\"Remove sensors from the rendered scene.\n\n        Parameters\n        ----------\n        kind : str | list | None\n            If None, removes all sensor-related data including the helmet.\n            Can be \"meg\", \"eeg\", \"fnirs\", \"ecog\", \"seeg\", \"dbs\" or \"helmet\"\n            to remove that item.\n        \"\"\"\n        all_kinds = (\"meg\", \"eeg\", \"fnirs\", \"ecog\", \"seeg\", \"dbs\", \"helmet\")\n        if kind is None:\n            for item in all_kinds:\n                self._remove(item, render=False)\n        else:\n            if isinstance(kind, str):\n                kind = [kind]\n            for this_kind in kind:\n                _check_option(\"kind\", this_kind, all_kinds)\n            self._remove(this_kind, render=False)\n        self._renderer._update()", "metadata": {}}
{"_id": "mne_mne_viz/_brain/_brain.py_add_text_code", "title": "add_text", "text": "def add_text(\n        self,\n        x,\n        y,\n        text,\n        name=None,\n        color=None,\n        opacity=1.0,\n        row=0,\n        col=0,\n        font_size=None,\n        justification=None,\n    ):\n        \"\"\"Add a text to the visualization.\n\n        Parameters\n        ----------\n        x : float\n            X coordinate.\n        y : float\n            Y coordinate.\n        text : str\n            Text to add.\n        name : str\n            Name of the text (text label can be updated using update_text()).\n        color : tuple\n            Color of the text. Default is the foreground color set during\n            initialization (default is black or white depending on the\n            background color).\n        opacity : float\n            Opacity of the text (default 1.0).\n        row : int | None\n            Row index of which brain to use. Default is the top row.\n        col : int | None\n            Column index of which brain to use. Default is the left-most\n            column.\n        font_size : float | None\n            The font size to use.\n        justification : str | None\n            The text justification.\n        \"\"\"\n        _validate_type(name, (str, None), \"name\")\n        name = text if name is None else name\n        if \"text\" in self._actors and name in self._actors[\"text\"]:\n            raise ValueError(f\"Text with the name {name} already exists\")\n        if color is None:\n            color = self._fg_color\n        for ri, ci, _ in self._iter_views(\"vol\"):\n            if (row is None or row == ri) and (col is None or col == ci):\n                actor = self._renderer.text2d(\n                    x_window=x,\n                    y_window=y,\n                    text=text,\n                    color=color,\n                    size=font_size,\n                    justification=justification,\n                )\n                if \"text\" not in self._actors:\n                    self._actors[\"text\"] = dict()\n                self._actors[\"text\"][name] = actor", "metadata": {}}
{"_id": "mne_mne_viz/_brain/_brain.py_remove_text_code", "title": "remove_text", "text": "def remove_text(self, name=None):\n        \"\"\"Remove text from the rendered scene.\n\n        Parameters\n        ----------\n        name : str | None\n            Remove specific text by name. If None, all text will be removed.\n        \"\"\"\n        _validate_type(name, (str, None), \"name\")\n        if name is None:\n            for actor in self._actors[\"text\"].values():\n                self._renderer.plotter.remove_actor(actor, render=False)\n            self._actors.pop(\"text\")\n        else:\n            names = [None]\n            if \"text\" in self._actors:\n                names += list(self._actors[\"text\"].keys())\n            _check_option(\"name\", name, names)\n            self._renderer.plotter.remove_actor(\n                self._actors[\"text\"][name], render=False\n            )\n            self._actors[\"text\"].pop(name)\n        self._renderer._update()", "metadata": {}}
{"_id": "mne_mne_viz/_brain/_brain.py_add_annotation_code", "title": "add_annotation", "text": "def add_annotation(\n        self, annot, borders=True, alpha=1, hemi=None, remove_existing=True, color=None\n    ):\n        \"\"\"Add an annotation file.\n\n        Parameters\n        ----------\n        annot : str | tuple\n            Either path to annotation file or annotation name. Alternatively,\n            the annotation can be specified as a ``(labels, ctab)`` tuple per\n            hemisphere, i.e. ``annot=(labels, ctab)`` for a single hemisphere\n            or ``annot=((lh_labels, lh_ctab), (rh_labels, rh_ctab))`` for both\n            hemispheres. ``labels`` and ``ctab`` should be arrays as returned\n            by :func:`nibabel.freesurfer.io.read_annot`.\n        borders : bool | int\n            Show only label borders. If int, specify the number of steps\n            (away from the true border) along the cortical mesh to include\n            as part of the border definition.\n        %(alpha)s Default is 1.\n        hemi : str | None\n            If None, it is assumed to belong to the hemisphere being\n            shown. If two hemispheres are being shown, data must exist\n            for both hemispheres.\n        remove_existing : bool\n            If True (default), remove old annotations.\n        color : matplotlib-style color code\n            If used, show all annotations in the same (specified) color.\n            Probably useful only when showing annotation borders.\n        \"\"\"\n        from ...label import _read_annot\n\n        hemis = self._check_hemis(hemi)\n\n        # Figure out where the data is coming from\n        if _path_like(annot):\n            if os.path.isfile(annot):\n                filepath = _check_fname(annot, overwrite=\"read\")\n                file_hemi, annot = filepath.name.split(\".\", 1)\n                if len(hemis) > 1:\n                    if file_hemi == \"lh\":\n                        filepaths = [filepath, filepath.parent / (\"rh.\" + annot)]\n                    elif file_hemi == \"rh\":\n                        filepaths = [filepath.parent / (\"lh.\" + annot), filepath]\n                    else:\n                        raise RuntimeError(\n                            \"To add both hemispheres simultaneously, filename must \"\n                            'begin with \"lh.\" or \"rh.\"'\n                        )\n                else:\n                    filepaths = [filepath]\n            else:\n                filepaths = []\n                for hemi in hemis:\n                    filepath = op.join(\n                        self._subjects_dir,\n                        self._subject,\n                        \"label\",\n                        \".\".join([hemi, annot, \"annot\"]),\n                    )\n                    if not os.path.exists(filepath):\n                        raise ValueError(f\"Annotation file {filepath} does not exist\")\n                    filepaths += [filepath]\n            annots = []\n            for hemi, filepath in zip(hemis, filepaths):\n                # Read in the data\n                labels, cmap, _ = _read_annot(filepath)\n                annots.append((labels, cmap))\n        else:\n            annots = [annot] if len(hemis) == 1 else annot\n            annot = \"annotation\"\n\n        for hemi, (labels, cmap) in zip(hemis, annots):\n            # Maybe zero-out the non-border vertices\n            self._to_borders(labels, hemi, borders)\n\n            # Handle null labels properly\n            cmap[:, 3] = 255\n            bgcolor = np.round(np.array(self._brain_color) * 255).astype(int)\n            bgcolor[-1] = 0\n            cmap[cmap[:, 4] < 0, 4] += 2**24  # wrap to positive\n            cmap[cmap[:, 4] <= 0, :4] = bgcolor\n            if np.any(labels == 0) and not np.any(cmap[:, -1] <= 0):\n                cmap = np.vstack((cmap, np.concatenate([bgcolor, [0]])))\n\n            # Set label ids sensibly\n            order = np.argsort(cmap[:, -1])\n            cmap = cmap[order]\n            ids = np.searchsorted(cmap[:, -1], labels)\n            cmap = cmap[:, :4]\n\n            #  Set the alpha level\n            alpha_vec = cmap[:, 3]\n            alpha_vec[alpha_vec > 0] = alpha * 255\n\n            # Override the cmap when a single color is used\n            if color is not None:\n                rgb = np.round(np.multiply(_to_rgb(color), 255))\n                cmap[:, :3] = rgb.astype(cmap.dtype)\n\n            ctable = cmap.astype(np.float64)\n            for _ in self._iter_views(hemi):\n                mesh = self._layered_meshes[hemi]\n                mesh.add_overlay(\n                    scalars=ids,\n                    colormap=ctable,\n                    rng=[np.min(ids), np.max(ids)],\n                    opacity=alpha,\n                    name=annot,\n                )\n                self._annots[hemi].append(annot)\n                if not self.time_viewer or self.traces_mode == \"vertex\":\n                    self._renderer._set_colormap_range(\n                        mesh._actor, cmap.astype(np.uint8), None\n                    )\n\n        self._renderer._update()", "metadata": {}}
{"_id": "mne_mne_viz/_brain/_brain.py_close_code", "title": "close", "text": "def close(self):\n        \"\"\"Close all figures and cleanup data structure.\"\"\"\n        self._closed = True\n        self._renderer.close()", "metadata": {}}
{"_id": "mne_mne_viz/_brain/_brain.py_show_code", "title": "show", "text": "def show(self):\n        \"\"\"Display the window.\"\"\"\n        self._renderer.show()", "metadata": {}}
{"_id": "mne_mne_viz/_brain/_brain.py_get_view_code", "title": "get_view", "text": "def get_view(self, row=0, col=0, *, align=True):\n        \"\"\"Get the camera orientation for a given subplot display.\n\n        Parameters\n        ----------\n        row : int\n            The row to use, default is the first one.\n        col : int\n            The column to check, the default is the first one.\n        %(align_view)s\n\n        Returns\n        -------\n        %(roll)s\n        %(distance)s\n        %(azimuth)s\n        %(elevation)s\n        %(focalpoint)s\n        \"\"\"\n        row = _ensure_int(row, \"row\")\n        col = _ensure_int(col, \"col\")\n        rigid = self._rigid if align else None\n        for h in self._hemis:\n            for ri, ci, _ in self._iter_views(h):\n                if (row == ri) and (col == ci):\n                    return self._renderer.get_camera(rigid=rigid)\n        return (None,) * 5", "metadata": {}}
{"_id": "mne_mne_viz/_brain/_brain.py_show_view_code", "title": "show_view", "text": "def show_view(\n        self,\n        view=None,\n        roll=None,\n        distance=None,\n        *,\n        row=None,\n        col=None,\n        hemi=None,\n        align=True,\n        azimuth=None,\n        elevation=None,\n        focalpoint=None,\n        update=True,\n        verbose=None,\n    ):\n        \"\"\"Orient camera to display view.\n\n        Parameters\n        ----------\n        %(view)s\n        %(roll)s\n        %(distance)s\n        row : int | None\n            The row to set. Default all rows.\n        col : int | None\n            The column to set. Default all columns.\n        hemi : str | None\n            Which hemi to use for view lookup (when in \"both\" mode).\n        %(align_view)s\n        %(azimuth)s\n        %(elevation)s\n        %(focalpoint)s\n        %(brain_update)s\n\n            .. versionadded:: 1.6\n        %(verbose)s\n\n        Notes\n        -----\n        The builtin string views are the following perspectives, based on the\n        :term:`RAS` convention. If not otherwise noted, the view will have the\n        top of the brain (superior, +Z) in 3D space shown upward in the 2D\n        perspective:\n\n        ``'lateral'``\n            From the left or right side such that the lateral (outside)\n            surface of the given hemisphere is visible.\n        ``'medial'``\n            From the left or right side such that the medial (inside)\n            surface of the given hemisphere is visible (at least when in split\n            or single-hemi mode).\n        ``'rostral'``\n            From the front.\n        ``'caudal'``\n            From the rear.\n        ``'dorsal'``\n            From above, with the front of the brain pointing up.\n        ``'ventral'``\n            From below, with the front of the brain pointing up.\n        ``'frontal'``\n            From the front and slightly lateral, with the brain slightly\n            tilted forward (yielding a view from slightly above).\n        ``'parietal'``\n            From the rear and slightly lateral, with the brain slightly tilted\n            backward (yielding a view from slightly above).\n        ``'axial'``\n            From above with the brain pointing up (same as ``'dorsal'``).\n        ``'sagittal'``\n            From the right side.\n        ``'coronal'``\n            From the rear.\n\n        Three letter abbreviations (e.g., ``'lat'``) of all of the above are\n        also supported.\n        \"\"\"\n        _validate_type(row, (\"int-like\", None), \"row\")\n        _validate_type(col, (\"int-like\", None), \"col\")\n        hemi = self._hemi if hemi is None else hemi\n        if hemi == \"split\":\n            if (\n                self._view_layout == \"vertical\"\n                and col == 1\n                or self._view_layout == \"horizontal\"\n                and row == 1\n            ):\n                hemi = \"rh\"\n            else:\n                hemi = \"lh\"\n        _validate_type(view, (str, None), \"view\")\n        view_params = dict(\n            azimuth=azimuth,\n            elevation=elevation,\n            roll=roll,\n            distance=distance,\n            focalpoint=focalpoint,\n        )\n        if view is not None:  # view_params take precedence\n            view_params = {\n                param: val for param, val in view_params.items() if val is not None\n            }  # no overwriting with None\n            view_params = dict(views_dicts[hemi].get(view), **view_params)\n        for h in self._hemis:\n            for ri, ci, _ in self._iter_views(h):\n                if (row is None or row == ri) and (col is None or col == ci):\n                    self._set_camera(**view_params, align=align)\n        if update:\n            self._renderer._update()", "metadata": {}}
{"_id": "mne_mne_viz/_brain/_brain.py_reset_view_code", "title": "reset_view", "text": "def reset_view(self):\n        \"\"\"Reset the camera.\"\"\"\n        for h in self._hemis:\n            for _, _, v in self._iter_views(h):\n                self._set_camera(**views_dicts[h][v])\n        self._renderer._update()", "metadata": {}}
{"_id": "mne_mne_viz/_brain/_brain.py_save_image_code", "title": "save_image", "text": "def save_image(self, filename=None, mode=\"rgb\"):\n        \"\"\"Save view from all panels to disk.\n\n        Parameters\n        ----------\n        filename : path-like\n            Path to new image file.\n        mode : str\n            Either ``'rgb'`` or ``'rgba'`` for values to return.\n        \"\"\"\n        if filename is None:\n            filename = _generate_default_filename(\".png\")\n        _save_ndarray_img(filename, self.screenshot(mode=mode, time_viewer=True))", "metadata": {}}
{"_id": "mne_mne_viz/_brain/_brain.py_screenshot_code", "title": "screenshot", "text": "def screenshot(self, mode=\"rgb\", time_viewer=False):\n        \"\"\"Generate a screenshot of current view.\n\n        Parameters\n        ----------\n        mode : str\n            Either ``'rgb'`` or ``'rgba'`` for values to return.\n        %(time_viewer_brain_screenshot)s\n\n        Returns\n        -------\n        screenshot : array\n            Image pixel values.\n        \"\"\"\n        n_channels = 3 if mode == \"rgb\" else 4\n        img = self._renderer.screenshot(mode)\n        logger.debug(f\"Got screenshot of size {img.shape}\")\n        if (\n            time_viewer\n            and self.time_viewer\n            and self.show_traces\n            and not self.separate_canvas\n        ):\n            from matplotlib.image import imread\n\n            canvas = self.mpl_canvas.fig.canvas\n            canvas.draw_idle()\n            fig = self.mpl_canvas.fig\n            with BytesIO() as output:\n                # Need to pass dpi here so it uses the physical (HiDPI) DPI\n                # rather than logical DPI when saving in most cases.\n                # But when matplotlib uses HiDPI and VTK doesn't\n                # (e.g., macOS w/Qt 5.14+ and VTK9) then things won't work,\n                # so let's just calculate the DPI we need to get\n                # the correct size output based on the widths being equal\n                size_in = fig.get_size_inches()\n                dpi = fig.get_dpi()\n                want_size = tuple(x * dpi for x in size_in)\n                n_pix = want_size[0] * want_size[1]\n                logger.debug(\n                    f\"Saving figure of size {size_in} @ {dpi} DPI \"\n                    f\"({want_size} = {n_pix} pixels)\"\n                )\n                # Sometimes there can be off-by-one errors here (e.g.,\n                # if in mpl int() rather than int(round()) is used to\n                # compute the number of pixels) so rather than use \"raw\"\n                # format and try to reshape ourselves, just write to PNG\n                # and read it, which has the dimensions encoded for us.\n                fig.savefig(\n                    output,\n                    dpi=dpi,\n                    format=\"png\",\n                    facecolor=self._bg_color,\n                    edgecolor=\"none\",\n                )\n                output.seek(0)\n                trace_img = imread(output, format=\"png\")[:, :, :n_channels]\n                trace_img = np.clip(np.round(trace_img * 255), 0, 255).astype(np.uint8)\n            bgcolor = np.array(self._brain_color[:n_channels]) / 255\n            img = concatenate_images(\n                [img, trace_img], bgcolor=bgcolor, n_channels=n_channels\n            )\n        return img", "metadata": {}}
{"_id": "mne_mne_viz/_brain/_brain.py_update_lut_code", "title": "update_lut", "text": "def update_lut(self, fmin=None, fmid=None, fmax=None, alpha=None):\n        \"\"\"Update the range of the color map.\n\n        Parameters\n        ----------\n        %(fmin_fmid_fmax)s\n        %(alpha)s\n        \"\"\"\n        publish(\n            self,\n            ColormapRange(\n                kind=\"distributed_source_power\",\n                fmin=fmin,\n                fmid=fmid,\n                fmax=fmax,\n                alpha=alpha,\n            ),\n        )", "metadata": {}}
{"_id": "mne_mne_viz/_brain/_brain.py_set_data_smoothing_code", "title": "set_data_smoothing", "text": "def set_data_smoothing(self, n_steps):\n        \"\"\"Set the number of smoothing steps.\n\n        Parameters\n        ----------\n        n_steps : int\n            Number of smoothing steps.\n        \"\"\"\n        from ...morph import _hemi_morph\n\n        for hemi in [\"lh\", \"rh\"]:\n            hemi_data = self._data.get(hemi)\n            if hemi_data is not None:\n                if len(hemi_data[\"array\"]) >= self.geo[hemi].x.shape[0]:\n                    continue\n                vertices = hemi_data[\"vertices\"]\n                if vertices is None:\n                    raise ValueError(\n                        f\"len(data) < nvtx ({len(hemi_data)} < \"\n                        f\"{self.geo[hemi].x.shape[0]}): the vertices \"\n                        \"parameter must not be None\"\n                    )\n                morph_n_steps = \"nearest\" if n_steps == -1 else n_steps\n                with use_log_level(False):\n                    smooth_mat = _hemi_morph(\n                        self.geo[hemi].orig_faces,\n                        np.arange(len(self.geo[hemi].coords)),\n                        vertices,\n                        morph_n_steps,\n                        maps=None,\n                        warn=False,\n                    )\n                self._data[hemi][\"smooth_mat\"] = smooth_mat\n        self._update_current_time_idx(self._data[\"time_idx\"])\n        self._data[\"smoothing_steps\"] = n_steps", "metadata": {}}
{"_id": "mne_mne_viz/_brain/_brain.py_time_interpolation_code", "title": "time_interpolation", "text": "def time_interpolation(self):\n        \"\"\"The interpolation mode.\"\"\"\n        return self._time_interpolation", "metadata": {}}
{"_id": "mne_mne_viz/_brain/_brain.py_set_time_interpolation_code", "title": "set_time_interpolation", "text": "def set_time_interpolation(self, interpolation):\n        \"\"\"Set the interpolation mode.\n\n        Parameters\n        ----------\n        %(interpolation_brain_time)s\n        \"\"\"\n        self._time_interpolation = _check_option(\n            \"interpolation\",\n            interpolation,\n            (\"linear\", \"nearest\", \"zero\", \"slinear\", \"quadratic\", \"cubic\"),\n        )\n        self._time_interp_funcs = dict()\n        self._time_interp_inv = None\n        if self._times is not None:\n            idx = np.arange(self._n_times)\n            for hemi in [\"lh\", \"rh\", \"vol\"]:\n                hemi_data = self._data.get(hemi)\n                if hemi_data is not None:\n                    array = hemi_data[\"array\"]\n                    self._time_interp_funcs[hemi] = _safe_interp1d(\n                        idx,\n                        array,\n                        self._time_interpolation,\n                        axis=-1,\n                        assume_sorted=True,\n                    )\n            self._time_interp_inv = _safe_interp1d(idx, self._times)", "metadata": {}}
{"_id": "mne_mne_viz/_brain/_brain.py_set_time_point_code", "title": "set_time_point", "text": "def set_time_point(self, time_idx):\n        \"\"\"Set the time point to display (can be a float to interpolate).\n\n        Parameters\n        ----------\n        time_idx : int | float\n            The time index to use. Can be a float to use interpolation\n            between indices.\n        \"\"\"\n        if self._times is None:\n            raise ValueError(\"Cannot set time when brain has no defined times.\")\n        elif 0 <= time_idx <= len(self._times):\n            publish(self, TimeChange(time=self._time_interp_inv(time_idx)))\n        else:\n            raise ValueError(\n                f\"Requested time point ({time_idx}) is outside the range of \"\n                f\"available time points (0-{len(self._times)}).\"\n            )", "metadata": {}}
{"_id": "mne_mne_viz/_brain/_brain.py_set_time_code", "title": "set_time", "text": "def set_time(self, time):\n        \"\"\"Set the time to display (in seconds).\n\n        Parameters\n        ----------\n        time : float\n            The time to show, in seconds.\n        \"\"\"\n        if self._times is None:\n            raise ValueError(\"Cannot set time when brain has no defined times.\")\n        elif min(self._times) <= time <= max(self._times):\n            publish(self, TimeChange(time=time))\n        else:\n            raise ValueError(\n                f\"Requested time ({time} s) is outside the range of \"\n                f\"available times ({min(self._times)}-{max(self._times)} s).\"\n            )", "metadata": {}}
{"_id": "mne_mne_viz/_brain/_brain.py_data_code", "title": "data", "text": "def data(self):\n        \"\"\"Data used by time viewer and color bar widgets.\"\"\"\n        return self._data", "metadata": {}}
{"_id": "mne_mne_viz/_brain/_brain.py_save_movie_code", "title": "save_movie", "text": "def save_movie(\n        self,\n        filename=None,\n        time_dilation=4.0,\n        tmin=None,\n        tmax=None,\n        framerate=24,\n        interpolation=None,\n        codec=None,\n        bitrate=None,\n        callback=None,\n        time_viewer=False,\n        **kwargs,\n    ):\n        \"\"\"Save a movie (for data with a time axis).\n\n        The movie is created through the :mod:`imageio` module. The format is\n        determined by the extension, and additional options can be specified\n        through keyword arguments that depend on the format, see\n        :doc:`imageio's format page <imageio:formats/index>`.\n\n        .. Warning::\n            This method assumes that time is specified in seconds when adding\n            data. If time is specified in milliseconds this will result in\n            movies 1000 times longer than expected.\n\n        Parameters\n        ----------\n        filename : str\n            Path at which to save the movie. The extension determines the\n            format (e.g., ``'*.mov'``, ``'*.gif'``, ...; see the :mod:`imageio`\n            documentation for available formats).\n        time_dilation : float\n            Factor by which to stretch time (default 4). For example, an epoch\n            from -100 to 600 ms lasts 700 ms. With ``time_dilation=4`` this\n            would result in a 2.8 s long movie.\n        tmin : float\n            First time point to include (default: all data).\n        tmax : float\n            Last time point to include (default: all data).\n        framerate : float\n            Framerate of the movie (frames per second, default 24).\n        %(interpolation_brain_time)s\n            If None, it uses the current ``brain.interpolation``,\n            which defaults to ``'nearest'``. Defaults to None.\n        codec : str | None\n            The codec to use.\n        bitrate : float | None\n            The bitrate to use.\n        callback : callable | None\n            A function to call on each iteration. Useful for status message\n            updates. It will be passed keyword arguments ``frame`` and\n            ``n_frames``.\n        %(time_viewer_brain_screenshot)s\n        **kwargs : dict\n            Specify additional options for :mod:`imageio`.\n        \"\"\"\n        if filename is None:\n            filename = _generate_default_filename(\".mp4\")\n        func = self._save_movie_tv if self.time_viewer else self._save_movie\n        func(\n            filename,\n            time_dilation,\n            tmin,\n            tmax,\n            framerate,\n            interpolation,\n            codec,\n            bitrate,\n            callback,\n            time_viewer,\n            **kwargs,\n        )", "metadata": {}}
{"_id": "mne_mne_viz/_brain/_brain.py_get_picked_points_code", "title": "get_picked_points", "text": "def get_picked_points(self):\n        \"\"\"Return the vertices of the picked points.\n\n        Returns\n        -------\n        points : list of int | None\n            The vertices picked by the time viewer.\n        \"\"\"\n        if hasattr(self, \"time_viewer\"):\n            return self.picked_points", "metadata": {}}
{"_id": "mne_mne_viz/_brain/colormap.py_create_lut_code", "title": "create_lut", "text": "def create_lut(cmap, n_colors=256, center=None):\n    \"\"\"Return a colormap suitable for setting as a LUT.\"\"\"\n    from .._3d import _get_cmap\n\n    assert not (isinstance(cmap, str) and cmap == \"auto\")\n    cmap = _get_cmap(cmap)\n    lut = np.round(cmap(np.linspace(0, 1, n_colors)) * 255.0).astype(np.int64)\n    return lut", "metadata": {}}
{"_id": "mne_mne_viz/_brain/colormap.py_scale_sequential_lut_code", "title": "scale_sequential_lut", "text": "def scale_sequential_lut(lut_table, fmin, fmid, fmax):\n    \"\"\"Scale a sequential colormap.\"\"\"\n    assert fmin <= fmid <= fmax  # guaranteed by calculate_lut\n    lut_table_new = lut_table.copy()\n    n_colors = lut_table.shape[0]\n    n_colors2 = n_colors // 2\n\n    if fmax == fmin:\n        fmid_idx = 0\n    else:\n        fmid_idx = np.clip(\n            int(np.round(n_colors * ((fmid - fmin) / (fmax - fmin))) - 1),\n            0,\n            n_colors - 2,\n        )\n\n    n_left = fmid_idx + 1\n    n_right = n_colors - n_left\n    for i in range(4):\n        lut_table_new[: fmid_idx + 1, i] = np.interp(\n            np.linspace(0, n_colors2 - 1, n_left), np.arange(n_colors), lut_table[:, i]\n        )\n        lut_table_new[fmid_idx + 1 :, i] = np.interp(\n            np.linspace(n_colors - 1, n_colors2, n_right)[::-1],\n            np.arange(n_colors),\n            lut_table[:, i],\n        )\n\n    return lut_table_new", "metadata": {}}
{"_id": "mne_mne_viz/_brain/colormap.py_get_fill_colors_code", "title": "get_fill_colors", "text": "def get_fill_colors(cols, n_fill):\n    \"\"\"Get the fill colors for the middle of divergent colormaps.\"\"\"\n    steps = np.linalg.norm(np.diff(cols[:, :3].astype(float), axis=0), axis=1)\n\n    ind = np.flatnonzero(steps[1:-1] > steps[[0, -1]].mean() * 3)\n    if ind.size > 0:\n        # choose the two colors between which there is the large step\n        ind = ind[0] + 1\n        fillcols = np.r_[\n            np.tile(cols[ind, :], (n_fill // 2, 1)),\n            np.tile(cols[ind + 1, :], (n_fill - n_fill // 2, 1)),\n        ]\n    else:\n        # choose a color from the middle of the colormap\n        fillcols = np.tile(cols[int(cols.shape[0] / 2), :], (n_fill, 1))\n\n    return fillcols", "metadata": {}}
{"_id": "mne_mne_viz/_brain/colormap.py_calculate_lut_code", "title": "calculate_lut", "text": "def calculate_lut(lut_table, alpha, fmin, fmid, fmax, center=None, transparent=True):\n    \"\"\"Transparent color map calculation.\n\n    A colormap may be sequential or divergent. When the colormap is\n    divergent indicate this by providing a value for 'center'. The\n    meanings of fmin, fmid and fmax are different for sequential and\n    divergent colormaps. A sequential colormap is characterised by::\n\n        [fmin, fmid, fmax]\n\n    where fmin and fmax define the edges of the colormap and fmid\n    will be the value mapped to the center of the originally chosen colormap.\n    A divergent colormap is characterised by::\n\n        [center-fmax, center-fmid, center-fmin, center,\n            center+fmin, center+fmid, center+fmax]\n\n    i.e., values between center-fmin and center+fmin will not be shown\n    while center-fmid will map to the fmid of the first half of the\n    original colormap and center-fmid to the fmid of the second half.\n\n    Parameters\n    ----------\n    lim_cmap : Colormap\n        Color map obtained from _process_mapdata.\n    alpha : float\n        Alpha value to apply globally to the overlay. Has no effect with mpl\n        backend.\n    fmin : float\n        Min value in colormap.\n    fmid : float\n        Intermediate value in colormap.\n    fmax : float\n        Max value in colormap.\n    center : float or None\n        If not None, center of a divergent colormap, changes the meaning of\n        fmin, fmax and fmid.\n    transparent : boolean\n        if True: use a linear transparency between fmin and fmid and make\n        values below fmin fully transparent (symmetrically for divergent\n        colormaps)\n\n    Returns\n    -------\n    cmap : matplotlib.ListedColormap\n        Color map with transparency channel.\n    \"\"\"\n    if not fmin <= fmid <= fmax:\n        raise ValueError(f\"Must have fmin ({fmin}) <= fmid ({fmid}) <= fmax ({fmax})\")\n    lut_table = create_lut(lut_table)\n    assert lut_table.dtype.kind == \"i\"\n    divergent = center is not None\n    n_colors = lut_table.shape[0]\n\n    # Add transparency if needed\n    n_colors2 = n_colors // 2\n    if transparent:\n        if divergent:\n            N4 = np.full(4, n_colors // 4)\n            N4[[0, 3, 1, 2][: np.mod(n_colors, 4)]] += 1\n            assert N4.sum() == n_colors\n            lut_table[:, -1] = np.round(\n                np.hstack(\n                    [\n                        np.full(N4[0], 255.0),\n                        np.linspace(0, 255, N4[1])[::-1],\n                        np.linspace(0, 255, N4[2]),\n                        np.full(N4[3], 255.0),\n                    ]\n                )\n            )\n        else:\n            lut_table[:n_colors2, -1] = np.round(np.linspace(0, 255, n_colors2))\n            lut_table[n_colors2:, -1] = 255\n\n    alpha = float(alpha)\n    if alpha < 1.0:\n        lut_table[:, -1] = np.round(lut_table[:, -1] * alpha)\n\n    if divergent:\n        if np.isclose(fmax, fmin, rtol=1e-6, atol=0):\n            lut_table = np.r_[\n                lut_table[:1],\n                get_fill_colors(\n                    lut_table[n_colors2 - 3 : n_colors2 + 3, :], n_colors - 2\n                ),\n                lut_table[-1:],\n            ]\n        else:\n            n_fill = int(round(fmin * n_colors2 / (fmax - fmin))) * 2\n            lut_table = np.r_[\n                scale_sequential_lut(\n                    lut_table[:n_colors2, :],\n                    center - fmax,\n                    center - fmid,\n                    center - fmin,\n                ),\n                get_fill_colors(lut_table[n_colors2 - 3 : n_colors2 + 3, :], n_fill),\n                scale_sequential_lut(\n                    lut_table[n_colors2:, :][::-1],\n                    center - fmax,\n                    center - fmid,\n                    center - fmin,\n                )[::-1],\n            ]\n    else:\n        lut_table = scale_sequential_lut(lut_table, fmin, fmid, fmax)\n\n    n_colors = lut_table.shape[0]\n    if n_colors != 256:\n        lut = np.zeros((256, 4))\n        x = np.linspace(1, n_colors, 256)\n        for chan in range(4):\n            lut[:, chan] = np.interp(x, np.arange(1, n_colors + 1), lut_table[:, chan])\n        lut_table = lut\n\n    lut_table = lut_table.astype(np.float64) / 255.0\n    return lut_table", "metadata": {}}
{"_id": "mne_mne_minimum_norm/resolution_matrix.py_make_inverse_resolution_matrix_code", "title": "make_inverse_resolution_matrix", "text": "def make_inverse_resolution_matrix(\n    forward, inverse_operator, method=\"dSPM\", lambda2=1.0 / 9.0, verbose=None\n):\n    \"\"\"Compute resolution matrix for linear inverse operator.\n\n    Parameters\n    ----------\n    forward : instance of Forward\n        Forward Operator.\n    inverse_operator : instance of InverseOperator\n        Inverse operator.\n    method : 'MNE' | 'dSPM' | 'sLORETA'\n        Inverse method to use (MNE, dSPM, sLORETA).\n    lambda2 : float\n        The regularisation parameter.\n    %(verbose)s\n\n    Returns\n    -------\n    resmat: array, shape (n_orient_inv * n_dipoles, n_orient_fwd * n_dipoles)\n        Resolution matrix (inverse operator times forward operator).\n        The result of applying the inverse operator to the forward operator.\n        If source orientations are not fixed, all source components will be\n        computed (i.e. for n_orient_inv > 1 or n_orient_fwd > 1).\n        The columns of the resolution matrix are the point-spread functions\n        (PSFs) and the rows are the cross-talk functions (CTFs).\n    \"\"\"\n    # make sure forward and inverse operator match\n    inv = inverse_operator\n    fwd = _convert_forward_match_inv(forward, inv)\n\n    # don't include bad channels\n    # only use good channels from inverse operator\n    bads_inv = inv[\"info\"][\"bads\"]\n    # good channels\n    ch_names = [c for c in inv[\"info\"][\"ch_names\"] if (c not in bads_inv)]\n    fwd = pick_channels_forward(fwd, ch_names, ordered=True)\n\n    # get leadfield matrix from forward solution\n    leadfield = fwd[\"sol\"][\"data\"]\n    invmat = _get_matrix_from_inverse_operator(inv, fwd, method=method, lambda2=lambda2)\n    resmat = invmat.dot(leadfield)\n    logger.info(\n        f\"Dimensions of resolution matrix: {resmat.shape[0]} by {resmat.shape[1]}.\"\n    )\n    return resmat", "metadata": {}}
{"_id": "mne_mne_minimum_norm/resolution_matrix.py_get_point_spread_code", "title": "get_point_spread", "text": "def get_point_spread(\n    resmat,\n    src,\n    idx,\n    mode=None,\n    *,\n    n_comp=1,\n    norm=False,\n    return_pca_vars=False,\n    vector=False,\n    verbose=None,\n):\n    \"\"\"Get point-spread (PSFs) functions for vertices.\n\n    Parameters\n    ----------\n    resmat : array, shape (n_dipoles, n_dipoles)\n        Forward Operator.\n    src : instance of SourceSpaces | instance of InverseOperator | instance of Forward\n        Source space used to compute resolution matrix.\n        Must be an InverseOperator if ``vector=True`` and a surface\n        source space is used.\n    %(idx_pctf)s\n    %(mode_pctf)s\n    %(n_comp_pctf_n)s\n    %(norm_pctf)s\n    %(return_pca_vars_pctf)s\n    %(vector_pctf)s\n    %(verbose)s\n\n    Returns\n    -------\n    %(stcs_pctf)s\n    %(pca_vars_pctf)s\n    \"\"\"  # noqa: E501\n    return _get_psf_ctf(\n        resmat,\n        src,\n        idx,\n        func=\"psf\",\n        mode=mode,\n        n_comp=n_comp,\n        norm=norm,\n        return_pca_vars=return_pca_vars,\n        vector=vector,\n    )", "metadata": {}}
{"_id": "mne_mne_minimum_norm/resolution_matrix.py_get_cross_talk_code", "title": "get_cross_talk", "text": "def get_cross_talk(\n    resmat,\n    src,\n    idx,\n    mode=None,\n    *,\n    n_comp=1,\n    norm=False,\n    return_pca_vars=False,\n    vector=False,\n    verbose=None,\n):\n    \"\"\"Get cross-talk (CTFs) function for vertices.\n\n    Parameters\n    ----------\n    resmat : array, shape (n_dipoles, n_dipoles)\n        Forward Operator.\n    src : instance of SourceSpaces | instance of InverseOperator | instance of Forward\n        Source space used to compute resolution matrix.\n        Must be an InverseOperator if ``vector=True`` and a surface\n        source space is used.\n    %(idx_pctf)s\n    %(mode_pctf)s\n    %(n_comp_pctf_n)s\n    %(norm_pctf)s\n    %(return_pca_vars_pctf)s\n    %(vector_pctf)s\n    %(verbose)s\n\n    Returns\n    -------\n    %(stcs_pctf)s\n    %(pca_vars_pctf)s\n    \"\"\"  # noqa: E501\n    return _get_psf_ctf(\n        resmat,\n        src,\n        idx,\n        func=\"ctf\",\n        mode=mode,\n        n_comp=n_comp,\n        norm=norm,\n        return_pca_vars=return_pca_vars,\n        vector=vector,\n    )", "metadata": {}}
{"_id": "mne_mne_minimum_norm/inverse.py_read_inverse_operator_code", "title": "read_inverse_operator", "text": "def read_inverse_operator(fname, *, verbose=None):\n    \"\"\"Read the inverse operator decomposition from a FIF file.\n\n    Parameters\n    ----------\n    fname : path-like\n        The name of the FIF file, which ends with ``-inv.fif`` or\n        ``-inv.fif.gz``.\n    %(verbose)s\n\n    Returns\n    -------\n    inv : instance of InverseOperator\n        The inverse operator.\n\n    See Also\n    --------\n    write_inverse_operator, make_inverse_operator\n    \"\"\"\n    check_fname(\n        fname,\n        \"inverse operator\",\n        (\"-inv.fif\", \"-inv.fif.gz\", \"_inv.fif\", \"_inv.fif.gz\"),\n    )\n    fname = _check_fname(fname=fname, must_exist=True, overwrite=\"read\")\n    #\n    #   Open the file, create directory\n    #\n    logger.info(f\"Reading inverse operator decomposition from {fname}...\")\n    f, tree, _ = fiff_open(fname)\n    with f as fid:\n        #\n        #   Find all inverse operators\n        #\n        invs = dir_tree_find(tree, FIFF.FIFFB_MNE_INVERSE_SOLUTION)\n        if invs is None or len(invs) < 1:\n            raise Exception(f\"No inverse solutions in {fname}\")\n\n        invs = invs[0]\n        #\n        #   Parent MRI data\n        #\n        parent_mri = dir_tree_find(tree, FIFF.FIFFB_MNE_PARENT_MRI_FILE)\n        if len(parent_mri) == 0:\n            raise Exception(f\"No parent MRI information in {fname}\")\n        parent_mri = parent_mri[0]  # take only first one\n\n        logger.info(\"    Reading inverse operator info...\")\n        #\n        #   Methods and source orientations\n        #\n        tag = find_tag(fid, invs, FIFF.FIFF_MNE_INCLUDED_METHODS)\n        if tag is None:\n            raise Exception(\"Modalities not found\")\n\n        inv = dict()\n        inv[\"methods\"] = int(tag.data.item())\n\n        tag = find_tag(fid, invs, FIFF.FIFF_MNE_SOURCE_ORIENTATION)\n        if tag is None:\n            raise Exception(\"Source orientation constraints not found\")\n\n        inv[\"source_ori\"] = int(tag.data.item())\n\n        tag = find_tag(fid, invs, FIFF.FIFF_MNE_SOURCE_SPACE_NPOINTS)\n        if tag is None:\n            raise Exception(\"Number of sources not found\")\n\n        inv[\"nsource\"] = int(tag.data.item())\n        inv[\"nchan\"] = 0\n        #\n        #   Coordinate frame\n        #\n        tag = find_tag(fid, invs, FIFF.FIFF_MNE_COORD_FRAME)\n        if tag is None:\n            raise Exception(\"Coordinate frame tag not found\")\n\n        inv[\"coord_frame\"] = tag.data\n\n        #\n        #   Units\n        #\n        tag = find_tag(fid, invs, FIFF.FIFF_MNE_INVERSE_SOURCE_UNIT)\n        unit_dict = {\n            FIFF.FIFF_UNIT_AM: \"Am\",\n            FIFF.FIFF_UNIT_AM_M2: \"Am/m^2\",\n            FIFF.FIFF_UNIT_AM_M3: \"Am/m^3\",\n        }\n        inv[\"units\"] = unit_dict.get(\n            int(getattr(tag, \"data\", np.array([-1])).item()), None\n        )\n\n        #\n        #   The actual source orientation vectors\n        #\n        tag = find_tag(fid, invs, FIFF.FIFF_MNE_INVERSE_SOURCE_ORIENTATIONS)\n        if tag is None:\n            raise Exception(\"Source orientation information not found\")\n\n        inv[\"source_nn\"] = tag.data\n        logger.info(\"    [done]\")\n        #\n        #   The SVD decomposition...\n        #\n        logger.info(\"    Reading inverse operator decomposition...\")\n        tag = find_tag(fid, invs, FIFF.FIFF_MNE_INVERSE_SING)\n        if tag is None:\n            raise Exception(\"Singular values not found\")\n\n        inv[\"sing\"] = tag.data\n        inv[\"nchan\"] = len(inv[\"sing\"])\n        #\n        #   The eigenleads and eigenfields\n        #\n        inv[\"eigen_leads_weighted\"] = False\n        inv[\"eigen_leads\"] = _read_named_matrix(\n            fid, invs, FIFF.FIFF_MNE_INVERSE_LEADS, transpose=True\n        )\n        if inv[\"eigen_leads\"] is None:\n            inv[\"eigen_leads_weighted\"] = True\n            inv[\"eigen_leads\"] = _read_named_matrix(\n                fid, invs, FIFF.FIFF_MNE_INVERSE_LEADS_WEIGHTED, transpose=True\n            )\n        if inv[\"eigen_leads\"] is None:\n            raise ValueError(\"Eigen leads not found in inverse operator.\")\n        #\n        #   Having the eigenleads as cols is better for the inverse calcs\n        #\n        inv[\"eigen_fields\"] = _read_named_matrix(\n            fid, invs, FIFF.FIFF_MNE_INVERSE_FIELDS\n        )\n        logger.info(\"    [done]\")\n        #\n        #   Read the covariance matrices\n        #\n        inv[\"noise_cov\"] = Covariance(\n            **_read_cov(fid, invs, FIFF.FIFFV_MNE_NOISE_COV, limited=True)\n        )\n        logger.info(\"    Noise covariance matrix read.\")\n\n        inv[\"source_cov\"] = _read_cov(fid, invs, FIFF.FIFFV_MNE_SOURCE_COV)\n        logger.info(\"    Source covariance matrix read.\")\n        #\n        #   Read the various priors\n        #\n        inv[\"orient_prior\"] = _read_cov(fid, invs, FIFF.FIFFV_MNE_ORIENT_PRIOR_COV)\n        if inv[\"orient_prior\"] is not None:\n            logger.info(\"    Orientation priors read.\")\n\n        inv[\"depth_prior\"] = _read_cov(fid, invs, FIFF.FIFFV_MNE_DEPTH_PRIOR_COV)\n        if inv[\"depth_prior\"] is not None:\n            logger.info(\"    Depth priors read.\")\n\n        inv[\"fmri_prior\"] = _read_cov(fid, invs, FIFF.FIFFV_MNE_FMRI_PRIOR_COV)\n        if inv[\"fmri_prior\"] is not None:\n            logger.info(\"    fMRI priors read.\")\n\n        #\n        #   Read the source spaces\n        #\n        inv[\"src\"] = _read_source_spaces_from_tree(fid, tree, patch_stats=False)\n\n        for s in inv[\"src\"]:\n            s[\"id\"] = find_source_space_hemi(s)\n\n        #\n        #   Get the MRI <-> head coordinate transformation\n        #\n        tag = find_tag(fid, parent_mri, FIFF.FIFF_COORD_TRANS)\n        if tag is None:\n            raise Exception(\"MRI/head coordinate transformation not found\")\n        mri_head_t = _ensure_trans(tag.data, \"mri\", \"head\")\n\n        inv[\"mri_head_t\"] = mri_head_t\n\n        #\n        # get parent MEG info\n        #\n        inv[\"info\"] = _read_forward_meas_info(tree, fid)\n\n        #\n        #   Transform the source spaces to the correct coordinate frame\n        #   if necessary\n        #\n        if inv[\"coord_frame\"] not in (FIFF.FIFFV_COORD_MRI, FIFF.FIFFV_COORD_HEAD):\n            raise Exception(\n                \"Only inverse solutions computed in MRI or \"\n                \"head coordinates are acceptable\"\n            )\n\n        #\n        #  Number of averages is initially one\n        #\n        inv[\"nave\"] = 1\n        #\n        #  We also need the SSP operator\n        #\n        inv[\"projs\"] = _read_proj(fid, tree)\n\n        #\n        #  Some empty fields to be filled in later\n        #\n        inv[\"proj\"] = []  # This is the projector to apply to the data\n        inv[\"whitener\"] = []  # This whitens the data\n        # This the diagonal matrix implementing regularization and the inverse\n        inv[\"reginv\"] = []\n        inv[\"noisenorm\"] = []  # These are the noise-normalization factors\n        #\n        nuse = 0\n        for k in range(len(inv[\"src\"])):\n            try:\n                inv[\"src\"][k] = transform_surface_to(\n                    inv[\"src\"][k], inv[\"coord_frame\"], mri_head_t\n                )\n            except Exception as inst:\n                raise Exception(f\"Could not transform source space ({inst})\")\n\n            nuse += inv[\"src\"][k][\"nuse\"]\n\n        logger.info(\n            \"    Source spaces transformed to the inverse solution coordinate frame\"\n        )\n        #\n        #   Done!\n        #\n\n    return InverseOperator(inv)", "metadata": {}}
{"_id": "mne_mne_minimum_norm/inverse.py_write_inverse_operator_code", "title": "write_inverse_operator", "text": "def write_inverse_operator(fname, inv, *, overwrite=False, verbose=None):\n    \"\"\"Write an inverse operator to a FIF file.\n\n    Parameters\n    ----------\n    fname : path-like\n        The name of the FIF file, which ends with ``-inv.fif`` or\n        ``-inv.fif.gz``.\n    inv : dict\n        The inverse operator.\n    %(overwrite)s\n\n        .. versionadded:: 1.0\n    %(verbose)s\n\n    See Also\n    --------\n    read_inverse_operator\n    \"\"\"\n    check_fname(\n        fname,\n        \"inverse operator\",\n        (\"-inv.fif\", \"-inv.fif.gz\", \"_inv.fif\", \"_inv.fif.gz\"),\n    )\n    fname = _check_fname(fname=fname, overwrite=overwrite)\n\n    _validate_type(inv, InverseOperator, \"inv\")\n\n    #\n    #   Open the file, create directory\n    #\n    logger.info(f\"Write inverse operator decomposition in {fname}...\")\n\n    # Create the file and save the essentials\n    with start_and_end_file(fname) as fid:\n        _write_inverse_operator(fid, inv)", "metadata": {}}
{"_id": "mne_mne_minimum_norm/inverse.py_combine_xyz_code", "title": "combine_xyz", "text": "def combine_xyz(vec, square=False):\n    \"\"\"Compute the three Cartesian components of a vector or matrix together.\n\n    Parameters\n    ----------\n    vec : 2d array of shape [3 n x p]\n        Input [ x1 y1 z1 ... x_n y_n z_n ] where x1 ... z_n\n        can be vectors\n\n    Returns\n    -------\n    comb : array\n        Output vector [sqrt(x1^2+y1^2+z1^2), ..., sqrt(x_n^2+y_n^2+z_n^2)]\n    \"\"\"\n    if vec.ndim != 2:\n        raise ValueError(\"Input must be 2D\")\n    if (vec.shape[0] % 3) != 0:\n        raise ValueError(\"Input must have 3N rows\")\n    if np.iscomplexobj(vec):\n        vec = np.abs(vec)\n    comb = vec[0::3] ** 2\n    comb += vec[1::3] ** 2\n    comb += vec[2::3] ** 2\n    if not square:\n        comb = np.sqrt(comb)\n    return comb", "metadata": {}}
{"_id": "mne_mne_minimum_norm/inverse.py_prepare_inverse_operator_code", "title": "prepare_inverse_operator", "text": "def prepare_inverse_operator(\n    orig, nave, lambda2, method=\"dSPM\", method_params=None, copy=True, verbose=None\n):\n    \"\"\"Prepare an inverse operator for actually computing the inverse.\n\n    Parameters\n    ----------\n    orig : dict\n        The inverse operator structure read from a file.\n    nave : int\n        Number of averages (scales the noise covariance).\n    lambda2 : float\n        The regularization factor. Recommended to be 1 / SNR**2.\n    method : \"MNE\" | \"dSPM\" | \"sLORETA\" | \"eLORETA\"\n        Use minimum norm, dSPM (default), sLORETA, or eLORETA.\n    method_params : dict | None\n        Additional options for eLORETA. See Notes of :func:`apply_inverse`.\n\n        .. versionadded:: 0.16\n    copy : bool | str\n        If True (default), copy the inverse. False will not copy.\n        Can be \"non-src\" to avoid copying the source space, which typically\n        is not modified and can be large in memory.\n\n        .. versionadded:: 0.21\n    %(verbose)s\n\n    Returns\n    -------\n    inv : instance of InverseOperator\n        Prepared inverse operator.\n    \"\"\"\n    if nave <= 0:\n        raise ValueError(\"The number of averages should be positive\")\n\n    _validate_type(copy, (bool, str), \"copy\")\n    if isinstance(copy, str):\n        _check_option(\"copy\", copy, (\"non-src\",), extra=\"when a string\")\n    logger.info(\"Preparing the inverse operator for use...\")\n    inv = orig\n    if copy:\n        src = orig[\"src\"]\n        if copy == \"non-src\":\n            orig[\"src\"] = None\n        try:\n            inv = orig.copy()\n        finally:\n            orig[\"src\"] = src\n        if copy == \"non-src\":\n            inv[\"src\"] = src\n    del orig\n\n    #\n    #   Scale some of the stuff\n    #\n    scale = float(inv[\"nave\"]) / nave\n    inv[\"noise_cov\"][\"data\"] = scale * inv[\"noise_cov\"][\"data\"]\n    # deal with diagonal case\n    if inv[\"noise_cov\"][\"data\"].ndim == 1:\n        logger.info(\"    Diagonal noise covariance found\")\n        inv[\"noise_cov\"][\"eig\"] = inv[\"noise_cov\"][\"data\"]\n        inv[\"noise_cov\"][\"eigvec\"] = np.eye(len(inv[\"noise_cov\"][\"data\"]))\n\n    inv[\"noise_cov\"][\"eig\"] = scale * inv[\"noise_cov\"][\"eig\"]\n    inv[\"source_cov\"][\"data\"] = scale * inv[\"source_cov\"][\"data\"]\n    #\n    if inv[\"eigen_leads_weighted\"]:\n        inv[\"eigen_leads\"][\"data\"] = sqrt(scale) * inv[\"eigen_leads\"][\"data\"]\n\n    logger.info(\n        \"    Scaled noise and source covariance from nave = %d to nave = %d\",\n        inv[\"nave\"],\n        nave,\n    )\n    inv[\"nave\"] = nave\n    #\n    #   Create the diagonal matrix for computing the regularized inverse\n    #\n    inv[\"reginv\"] = _compute_reginv(inv, lambda2)\n    logger.info(\"    Created the regularized inverter\")\n    #\n    #   Create the projection operator\n    #\n    inv[\"proj\"], ncomp, _ = make_projector(inv[\"projs\"], inv[\"noise_cov\"][\"names\"])\n    if ncomp > 0:\n        logger.info(\"    Created an SSP operator (subspace dimension = %d)\", ncomp)\n    else:\n        logger.info(\"    The projection vectors do not apply to these channels.\")\n\n    #\n    #   Create the whitener\n    #\n\n    inv[\"whitener\"], _, inv[\"colorer\"] = compute_whitener(\n        inv[\"noise_cov\"], pca=\"white\", return_colorer=True\n    )\n\n    #\n    #   Finally, compute the noise-normalization factors\n    #\n    inv[\"noisenorm\"] = []\n    if method == \"eLORETA\":\n        _compute_eloreta(inv, lambda2, method_params)\n    elif method != \"MNE\":\n        logger.info(f\"    Computing noise-normalization factors ({method})...\")\n        # Here we have::\n        #\n        #     inv['reginv'] = sing / (sing ** 2 + lambda2)\n        #\n        # where ``sing`` are the singular values of the whitened gain matrix.\n        if method == \"dSPM\":\n            # dSPM normalization\n            noise_weight = inv[\"reginv\"]\n        elif method == \"sLORETA\":\n            # sLORETA normalization is given by the square root of the\n            # diagonal entries of the resolution matrix R, which is\n            # the product of the inverse and forward operators as:\n            #\n            #     w = diag(diag(R)) ** 0.5\n            #\n            noise_weight = inv[\"reginv\"] * np.sqrt(1.0 + inv[\"sing\"] ** 2 / lambda2)\n\n        noise_norm = np.zeros(inv[\"eigen_leads\"][\"nrow\"])\n        (nrm2,) = linalg.get_blas_funcs((\"nrm2\",), (noise_norm,))\n        if inv[\"eigen_leads_weighted\"]:\n            for k in range(inv[\"eigen_leads\"][\"nrow\"]):\n                one = inv[\"eigen_leads\"][\"data\"][k, :] * noise_weight\n                noise_norm[k] = nrm2(one)\n        else:\n            for k in range(inv[\"eigen_leads\"][\"nrow\"]):\n                one = (\n                    sqrt(inv[\"source_cov\"][\"data\"][k])\n                    * inv[\"eigen_leads\"][\"data\"][k, :]\n                    * noise_weight\n                )\n                noise_norm[k] = nrm2(one)\n\n        #\n        #   Compute the final result\n        #\n        if inv[\"source_ori\"] == FIFF.FIFFV_MNE_FREE_ORI:\n            #\n            #   The three-component case is a little bit more involved\n            #   The variances at three consecutive entries must be squared and\n            #   added together\n            #\n            #   Even in this case return only one noise-normalization factor\n            #   per source location\n            #\n            noise_norm = combine_xyz(noise_norm[:, None]).ravel()\n        inv[\"noisenorm\"] = 1.0 / np.abs(noise_norm)\n        logger.info(\"[done]\")\n    else:\n        inv[\"noisenorm\"] = []\n\n    return InverseOperator(inv)", "metadata": {}}
{"_id": "mne_mne_minimum_norm/inverse.py_apply_inverse_code", "title": "apply_inverse", "text": "def apply_inverse(\n    evoked,\n    inverse_operator,\n    lambda2=1.0 / 9.0,\n    method=\"dSPM\",\n    pick_ori=None,\n    prepared=False,\n    label=None,\n    method_params=None,\n    return_residual=False,\n    use_cps=True,\n    verbose=None,\n):\n    \"\"\"Apply inverse operator to evoked data.\n\n    Parameters\n    ----------\n    evoked : Evoked object\n        Evoked data.\n    inverse_operator : instance of InverseOperator\n        Inverse operator.\n    lambda2 : float\n        The regularization parameter.\n    method : \"MNE\" | \"dSPM\" | \"sLORETA\" | \"eLORETA\"\n        Use minimum norm :footcite:`HamalainenIlmoniemi1994`,\n        dSPM (default) :footcite:`DaleEtAl2000`,\n        sLORETA :footcite:`Pascual-Marqui2002`, or\n        eLORETA :footcite:`Pascual-Marqui2011`.\n    %(pick_ori)s\n    prepared : bool\n        If True, do not call :func:`prepare_inverse_operator`.\n    label : Label | None\n        Restricts the source estimates to a given label. If None,\n        source estimates will be computed for the entire source space.\n    method_params : dict | None\n        Additional options for eLORETA. See Notes for details.\n\n        .. versionadded:: 0.16\n    return_residual : bool\n        If True (default False), return the residual evoked data.\n        Cannot be used with ``method=='eLORETA'``.\n\n        .. versionadded:: 0.17\n    %(use_cps_restricted)s\n\n        .. versionadded:: 0.20\n    %(verbose)s\n\n    Returns\n    -------\n    stc : SourceEstimate | VectorSourceEstimate | VolSourceEstimate\n        The source estimates.\n    residual : instance of Evoked\n        The residual evoked data, only returned if return_residual is True.\n\n    See Also\n    --------\n    apply_inverse_raw : Apply inverse operator to raw object.\n    apply_inverse_epochs : Apply inverse operator to epochs object.\n    apply_inverse_tfr_epochs : Apply inverse operator to epochs tfr object.\n    apply_inverse_cov : Apply inverse operator to covariance object.\n\n    Notes\n    -----\n    Currently only the ``method='eLORETA'`` has additional options.\n    It performs an iterative fit with a convergence criterion, so you can\n    pass a ``method_params`` :class:`dict` with string keys mapping to values\n    for:\n\n        'eps' : float\n            The convergence epsilon (default 1e-6).\n        'max_iter' : int\n            The maximum number of iterations (default 20).\n            If less regularization is applied, more iterations may be\n            necessary.\n        'force_equal' : bool\n            Force all eLORETA weights for each direction for a given\n            location equal. The default is None, which means ``True`` for\n            loose-orientation inverses and ``False`` for free- and\n            fixed-orientation inverses. See below.\n\n    The eLORETA paper :footcite:`Pascual-Marqui2011` defines how to compute\n    inverses for fixed- and\n    free-orientation inverses. In the free orientation case, the X/Y/Z\n    orientation triplet for each location is effectively multiplied by a\n    3x3 weight matrix. This is the behavior obtained with\n    ``force_equal=False`` parameter.\n\n    However, other noise normalization methods (dSPM, sLORETA) multiply all\n    orientations for a given location by a single value.\n    Using ``force_equal=True`` mimics this behavior by modifying the iterative\n    algorithm to choose uniform weights (equivalent to a 3x3 diagonal matrix\n    with equal entries).\n\n    It is necessary to use ``force_equal=True``\n    with loose orientation inverses (e.g., ``loose=0.2``), otherwise the\n    solution resembles a free-orientation inverse (``loose=1.0``).\n    It is thus recommended to use ``force_equal=True`` for loose orientation\n    and ``force_equal=False`` for free orientation inverses. This is the\n    behavior used when the parameter ``force_equal=None`` (default behavior).\n\n    References\n    ----------\n    .. footbibliography::\n    \"\"\"\n    out = _apply_inverse(\n        evoked,\n        inverse_operator,\n        lambda2,\n        method,\n        pick_ori,\n        prepared,\n        label,\n        method_params,\n        return_residual,\n        use_cps,\n    )\n    logger.info(\"[done]\")\n    return out", "metadata": {}}
{"_id": "mne_mne_minimum_norm/inverse.py_apply_inverse_raw_code", "title": "apply_inverse_raw", "text": "def apply_inverse_raw(\n    raw,\n    inverse_operator,\n    lambda2,\n    method=\"dSPM\",\n    label=None,\n    start=None,\n    stop=None,\n    nave=1,\n    time_func=None,\n    pick_ori=None,\n    buffer_size=None,\n    prepared=False,\n    method_params=None,\n    use_cps=True,\n    verbose=None,\n):\n    \"\"\"Apply inverse operator to Raw data.\n\n    Parameters\n    ----------\n    raw : Raw object\n        Raw data.\n    inverse_operator : dict\n        Inverse operator.\n    lambda2 : float\n        The regularization parameter.\n    method : \"MNE\" | \"dSPM\" | \"sLORETA\" | \"eLORETA\"\n        Use minimum norm, dSPM (default), sLORETA, or eLORETA.\n    label : Label | None\n        Restricts the source estimates to a given label. If None,\n        source estimates will be computed for the entire source space.\n    start : int\n        Index of first time sample (index not time is seconds).\n    stop : int\n        Index of first time sample not to include (index not time is seconds).\n    nave : int\n        Number of averages used to regularize the solution.\n        Set to 1 on raw data.\n    time_func : callable\n        Linear function applied to sensor space time series.\n    %(pick_ori)s\n    buffer_size : int (or None)\n        If not None, the computation of the inverse and the combination of the\n        current components is performed in segments of length buffer_size\n        samples. While slightly slower, this is useful for long datasets as it\n        reduces the memory requirements by approx. a factor of 3 (assuming\n        buffer_size << data length).\n        Note that this setting has no effect for fixed-orientation inverse\n        operators.\n    prepared : bool\n        If True, do not call :func:`prepare_inverse_operator`.\n    method_params : dict | None\n        Additional options for eLORETA. See Notes of :func:`apply_inverse`.\n\n        .. versionadded:: 0.16\n    %(use_cps_restricted)s\n\n        .. versionadded:: 0.20\n    %(verbose)s\n\n    Returns\n    -------\n    stc : SourceEstimate | VectorSourceEstimate | VolSourceEstimate\n        The source estimates.\n\n    See Also\n    --------\n    apply_inverse : Apply inverse operator to evoked object.\n    apply_inverse_epochs : Apply inverse operator to epochs object.\n    apply_inverse_tfr_epochs : Apply inverse operator to epochs tfr object.\n    apply_inverse_cov : Apply inverse operator to covariance object.\n    \"\"\"\n    _validate_type(raw, BaseRaw, \"raw\")\n    _check_reference(raw, inverse_operator[\"info\"][\"ch_names\"])\n    _check_option(\"method\", method, INVERSE_METHODS)\n    _check_ori(pick_ori, inverse_operator[\"source_ori\"], inverse_operator[\"src\"])\n    _check_ch_names(inverse_operator, raw.info)\n\n    #\n    #   Set up the inverse according to the parameters\n    #\n    inv = _check_or_prepare(\n        inverse_operator, nave, lambda2, method, method_params, prepared\n    )\n\n    #\n    #   Pick the correct channels from the data\n    #\n    sel = _pick_channels_inverse_operator(raw.ch_names, inv)\n    logger.info(\"Applying inverse to raw...\")\n    logger.info(\"    Picked %d channels from the data\", len(sel))\n    logger.info(\"    Computing inverse...\")\n\n    data, times = raw[sel, start:stop]\n\n    if time_func is not None:\n        data = time_func(data)\n\n    K, noise_norm, vertno, source_nn = _assemble_kernel(\n        inv, label, method, pick_ori, use_cps\n    )\n\n    is_free_ori = (\n        inverse_operator[\"source_ori\"] == FIFF.FIFFV_MNE_FREE_ORI\n        and pick_ori != \"normal\"\n    )\n\n    if buffer_size is not None and is_free_ori:\n        # Process the data in segments to conserve memory\n        n_seg = int(np.ceil(data.shape[1] / float(buffer_size)))\n        logger.info(\n            \"    computing inverse and combining the current \"\n            \"components (using %d segments)...\",\n            n_seg,\n        )\n\n        # Allocate space for inverse solution\n        n_times = data.shape[1]\n\n        n_dipoles = K.shape[0] if pick_ori == \"vector\" else K.shape[0] // 3\n        sol = np.empty((n_dipoles, n_times), dtype=np.result_type(K, data))\n\n        for pos in range(0, n_times, buffer_size):\n            sol_chunk = np.dot(K, data[:, pos : pos + buffer_size])\n            if pick_ori != \"vector\":\n                sol_chunk = combine_xyz(sol_chunk)\n            sol[:, pos : pos + buffer_size] = sol_chunk\n\n            logger.info(\"        segment %d / %d done..\", pos / buffer_size + 1, n_seg)\n    else:\n        sol = np.dot(K, data)\n        if is_free_ori and pick_ori != \"vector\":\n            logger.info(\"    combining the current components...\")\n            sol = combine_xyz(sol)\n    if noise_norm is not None:\n        if pick_ori == \"vector\" and is_free_ori:\n            noise_norm = noise_norm.repeat(3, axis=0)\n        sol *= noise_norm\n\n    tmin = float(times[0])\n    tstep = 1.0 / raw.info[\"sfreq\"]\n    subject = _subject_from_inverse(inverse_operator)\n    src_type = _get_src_type(inverse_operator[\"src\"], vertno)\n    stc = _make_stc(\n        sol,\n        vertno,\n        tmin=tmin,\n        tstep=tstep,\n        subject=subject,\n        vector=(pick_ori == \"vector\"),\n        source_nn=source_nn,\n        src_type=src_type,\n    )\n    logger.info(\"[done]\")\n\n    return stc", "metadata": {}}
{"_id": "mne_mne_minimum_norm/inverse.py_apply_inverse_epochs_code", "title": "apply_inverse_epochs", "text": "def apply_inverse_epochs(\n    epochs,\n    inverse_operator,\n    lambda2,\n    method=\"dSPM\",\n    label=None,\n    nave=1,\n    pick_ori=None,\n    return_generator=False,\n    prepared=False,\n    method_params=None,\n    use_cps=True,\n    verbose=None,\n):\n    \"\"\"Apply inverse operator to Epochs.\n\n    Parameters\n    ----------\n    epochs : Epochs object\n        Single trial epochs.\n    inverse_operator : dict\n        Inverse operator.\n    lambda2 : float\n        The regularization parameter.\n    method : \"MNE\" | \"dSPM\" | \"sLORETA\" | \"eLORETA\"\n        Use minimum norm, dSPM (default), sLORETA, or eLORETA.\n    label : Label | None\n        Restricts the source estimates to a given label. If None,\n        source estimates will be computed for the entire source space.\n    nave : int\n        Number of averages used to regularize the solution.\n        Set to 1 on single Epoch by default.\n    %(pick_ori)s\n    return_generator : bool\n        Return a generator object instead of a list. This allows iterating\n        over the stcs without having to keep them all in memory.\n    prepared : bool\n        If True, do not call :func:`prepare_inverse_operator`.\n    method_params : dict | None\n        Additional options for eLORETA. See Notes of :func:`apply_inverse`.\n\n        .. versionadded:: 0.16\n    %(use_cps_restricted)s\n\n        .. versionadded:: 0.20\n    %(verbose)s\n\n    Returns\n    -------\n    stcs : list of (SourceEstimate | VectorSourceEstimate | VolSourceEstimate)\n        The source estimates for all epochs.\n\n    See Also\n    --------\n    apply_inverse_raw : Apply inverse operator to raw object.\n    apply_inverse : Apply inverse operator to evoked object.\n    apply_inverse_tfr_epochs : Apply inverse operator to epochs tfr object.\n    apply_inverse_cov : Apply inverse operator to a covariance object.\n    \"\"\"\n    stcs = _apply_inverse_epochs_gen(\n        epochs,\n        inverse_operator,\n        lambda2,\n        method=method,\n        label=label,\n        nave=nave,\n        pick_ori=pick_ori,\n        verbose=verbose,\n        prepared=prepared,\n        method_params=method_params,\n        use_cps=use_cps,\n    )\n\n    if not return_generator:\n        # return a list\n        stcs = [stc for stc in stcs]\n\n    return stcs", "metadata": {}}
{"_id": "mne_mne_minimum_norm/inverse.py_apply_inverse_tfr_epochs_code", "title": "apply_inverse_tfr_epochs", "text": "def apply_inverse_tfr_epochs(\n    epochs_tfr,\n    inverse_operator,\n    lambda2,\n    method=\"dSPM\",\n    label=None,\n    nave=1,\n    pick_ori=None,\n    return_generator=False,\n    prepared=False,\n    method_params=None,\n    use_cps=True,\n    verbose=None,\n):\n    \"\"\"Apply inverse operator to EpochsTFR.\n\n    Parameters\n    ----------\n    epochs_tfr : EpochsTFR object\n        Single trial, phase-amplitude (complex-valued), time-frequency epochs.\n    inverse_operator : list of dict | dict\n        The inverse operator for each frequency or a single inverse operator\n        to use for all frequencies.\n    lambda2 : float\n        The regularization parameter.\n    method : \"MNE\" | \"dSPM\" | \"sLORETA\" | \"eLORETA\"\n        Use minimum norm, dSPM (default), sLORETA, or eLORETA.\n    label : Label | None\n        Restricts the source estimates to a given label. If None,\n        source estimates will be computed for the entire source space.\n    nave : int\n        Number of averages used to regularize the solution.\n        Set to 1 on single Epoch by default.\n    %(pick_ori)s\n    return_generator : bool\n        Return a generator object instead of a list. This allows iterating\n        over the stcs without having to keep them all in memory.\n    prepared : bool\n        If True, do not call :func:`prepare_inverse_operator`.\n    method_params : dict | None\n        Additional options for eLORETA. See Notes of :func:`apply_inverse`.\n    %(use_cps_restricted)s\n    %(verbose)s\n\n    Returns\n    -------\n    stcs : list of list of (SourceEstimate | VectorSourceEstimate | VolSourceEstimate)\n        The source estimates for all frequencies (outside list) and for\n        all epochs (inside list).\n\n    See Also\n    --------\n    apply_inverse_raw : Apply inverse operator to raw object.\n    apply_inverse : Apply inverse operator to evoked object.\n    apply_inverse_epochs : Apply inverse operator to epochs object.\n    apply_inverse_cov : Apply inverse operator to a covariance object.\n    \"\"\"  # noqa E501\n    _check_tfr_complex(epochs_tfr)\n    if (\n        isinstance(inverse_operator, list | tuple)\n        and len(inverse_operator) != epochs_tfr.freqs.size\n    ):\n        raise ValueError(\n            f\"Expected {epochs_tfr.freqs.size} inverse \"\n            f\"operators, got {len(inverse_operator)}\"\n        )\n    stcs = _apply_inverse_tfr_epochs_gen(\n        epochs_tfr,\n        inverse_operator,\n        lambda2,\n        method,\n        label,\n        nave,\n        pick_ori,\n        prepared,\n        method_params,\n        use_cps,\n    )\n    if not return_generator:\n        stcs = [[stc for stc in tfr_stcs] for tfr_stcs in stcs]\n    return stcs", "metadata": {}}
{"_id": "mne_mne_minimum_norm/inverse.py_apply_inverse_cov_code", "title": "apply_inverse_cov", "text": "def apply_inverse_cov(\n    cov,\n    info,\n    inverse_operator,\n    nave=1,\n    lambda2=1 / 9,\n    method=\"dSPM\",\n    pick_ori=None,\n    prepared=False,\n    label=None,\n    method_params=None,\n    use_cps=True,\n    verbose=None,\n):\n    \"\"\"Apply inverse operator to covariance data.\n\n    Parameters\n    ----------\n    cov : instance of Covariance\n        Covariance data, computed on the time segment for which to compute\n        source power.\n    %(info_not_none)s Used specify the channels to include.\n    inverse_operator : instance of InverseOperator\n        Inverse operator.\n    nave : int\n        Number of averages used to regularize the solution.\n    lambda2 : float\n        The regularization parameter.\n    method : \"MNE\" | \"dSPM\" | \"sLORETA\" | \"eLORETA\"\n        Use minimum norm, dSPM (default), sLORETA, or eLORETA.\n    %(pick_ori_novec)s\n    prepared : bool\n        If True, do not call :func:`prepare_inverse_operator`.\n    label : Label | None\n        Restricts the source estimates to a given label. If None,\n        source estimates will be computed for the entire source space.\n    method_params : dict | None\n        Additional options for eLORETA. See Notes for details.\n    %(use_cps)s\n    %(verbose)s\n\n    Returns\n    -------\n    stc : SourceEstimate | VectorSourceEstimate | VolSourceEstimate\n        The source estimates.\n\n    See Also\n    --------\n    apply_inverse : Apply inverse operator to evoked object.\n    apply_inverse_raw : Apply inverse operator to raw object.\n    apply_inverse_epochs : Apply inverse operator to epochs object.\n    apply_inverse_tfr_epochs : Apply inverse operator to epochs tfr object.\n\n    Notes\n    -----\n    .. versionadded:: 0.20\n\n    This code is based on the original research code from\n    :footcite:`Sabbagh2020` and has been useful to correct for individual field\n    spread using source localization in the context of predictive modeling.\n\n    References\n    ----------\n    .. footbibliography::\n    \"\"\"\n    _validate_type(cov, Covariance, cov)\n    _validate_type(inverse_operator, InverseOperator, \"inverse_operator\")\n    sel = _pick_channels_inverse_operator(cov[\"names\"], inverse_operator)\n    use_names = [cov[\"names\"][idx] for idx in sel]\n    info = pick_info(info, pick_channels(info[\"ch_names\"], use_names, ordered=True))\n    evoked = EvokedArray(np.eye(len(info[\"ch_names\"])), info, nave=nave, comment=\"cov\")\n    is_free_ori = inverse_operator[\"source_ori\"] == FIFF.FIFFV_MNE_FREE_ORI\n    _check_option(\"pick_ori\", pick_ori, (None, \"normal\"))\n    if is_free_ori and pick_ori is None:\n        use_ori = \"vector\"\n        combine = True\n    else:\n        use_ori = pick_ori\n        combine = False\n    stc = _apply_inverse(\n        evoked,\n        inverse_operator,\n        lambda2,\n        method,\n        use_ori,\n        prepared,\n        label,\n        method_params,\n        return_residual=False,\n        use_cps=use_cps,\n    )\n    # apply (potentially rotated in the vector case) operator twice\n    K = np.reshape(stc.data, (-1, stc.data.shape[-1]))\n    # diagonal entries of A @ B are given by (A * B.T).sum(axis=1), so this is\n    # equivalent to np.diag(K @ cov.data[sel][:, sel] @ K.T)[:, np.newaxis]:\n    sol = cov.data[sel][:, sel] @ K.T\n    sol = np.sum(K * sol.T, axis=1, keepdims=True)\n    # Reshape back to (n_src, ..., 1)\n    sol.shape = stc.data.shape[:-1] + (1,)\n    stc = stc.__class__(sol, stc.vertices, stc.tmin, stc.tstep, stc.subject)\n    if combine:  # combine the three directions\n        logger.info(\"    Combining the current components...\")\n        np.sqrt(stc.data, out=stc.data)\n        stc = stc.magnitude()\n        stc.data *= stc.data\n    logger.info(\"[done]\")\n    return stc", "metadata": {}}
{"_id": "mne_mne_minimum_norm/inverse.py_make_inverse_operator_code", "title": "make_inverse_operator", "text": "def make_inverse_operator(\n    info,\n    forward,\n    noise_cov,\n    loose=\"auto\",\n    depth=0.8,\n    fixed=\"auto\",\n    rank=None,\n    use_cps=True,\n    verbose=None,\n):\n    \"\"\"Assemble inverse operator.\n\n    Parameters\n    ----------\n    %(info_not_none)s\n        Specifies the channels to include. Bad channels (in ``info['bads']``)\n        are not used.\n    forward : instance of Forward\n        Forward operator. See :func:`~mne.make_forward_solution` to create the operator.\n    noise_cov : instance of Covariance\n        The noise covariance matrix. See :func:`~mne.compute_raw_covariance` and\n        :func:`~mne.compute_covariance` to compute the noise covariance matrix on\n        :class:`~mne.io.Raw` and :class:`~mne.Epochs` respectively.\n    %(loose)s\n    %(depth)s\n    fixed : bool | 'auto'\n        Use fixed source orientations normal to the cortical mantle. If True,\n        the loose parameter must be ``\"auto\"`` or ``0``. If ``'auto'``, the loose value\n        is used.\n    %(rank_none)s\n    %(use_cps)s\n    %(verbose)s\n\n    Returns\n    -------\n    inv : instance of InverseOperator\n        Inverse operator.\n\n    Notes\n    -----\n    For different sets of options (**loose**, **depth**, **fixed**) to work,\n    the forward operator must have been loaded using a certain configuration\n    (i.e., with **force_fixed** and **surf_ori** set appropriately). For\n    example, given the desired inverse type (with representative choices\n    of **loose** = 0.2 and **depth** = 0.8 shown in the table in various\n    places, as these are the defaults for those parameters):\n\n        +---------------------+-----------+-----------+-----------+-----------------+--------------+\n        | Inverse desired                             | Forward parameters allowed                 |\n        +=====================+===========+===========+===========+=================+==============+\n        |                     | **loose** | **depth** | **fixed** | **force_fixed** | **surf_ori** |\n        +---------------------+-----------+-----------+-----------+-----------------+--------------+\n        | | Loose constraint, | 0.2       | 0.8       | False     | False           | True         |\n        | | Depth weighted    |           |           |           |                 |              |\n        +---------------------+-----------+-----------+-----------+-----------------+--------------+\n        | | Loose constraint  | 0.2       | None      | False     | False           | True         |\n        +---------------------+-----------+-----------+-----------+-----------------+--------------+\n        | | Free orientation, | 1.0       | 0.8       | False     | False           | True         |\n        | | Depth weighted    |           |           |           |                 |              |\n        +---------------------+-----------+-----------+-----------+-----------------+--------------+\n        | | Free orientation  | 1.0       | None      | False     | False           | True | False |\n        +---------------------+-----------+-----------+-----------+-----------------+--------------+\n        | | Fixed constraint, | 0.0       | 0.8       | True      | False           | True         |\n        | | Depth weighted    |           |           |           |                 |              |\n        +---------------------+-----------+-----------+-----------+-----------------+--------------+\n        | | Fixed constraint  | 0.0       | None      | True      | True            | True         |\n        +---------------------+-----------+-----------+-----------+-----------------+--------------+\n\n    Also note that, if the source space (as stored in the forward solution)\n    has patch statistics computed, these are used to improve the depth\n    weighting. Thus slightly different results are to be expected with\n    and without this information.\n\n    For depth weighting, 0.8 is generally good for MEG, and between 2 and 5\n    is good for EEG, see :footcite:t:`LinEtAl2006a`.\n\n    References\n    ----------\n    .. footbibliography::\n    \"\"\"  # noqa: E501\n    # For now we always have pca='white'. It does not seem to affect\n    # calculations and is also backward-compatible with MNE-C\n    depth = _check_depth(depth, \"depth_mne\")\n    (\n        forward,\n        gain_info,\n        gain,\n        depth_prior,\n        orient_prior,\n        source_std,\n        trace_GRGT,\n        noise_cov,\n        _,\n    ) = _prepare_forward(\n        forward,\n        info,\n        noise_cov,\n        fixed,\n        loose,\n        rank,\n        pca=\"white\",\n        use_cps=use_cps,\n        **depth,\n    )\n    # no need to copy any attributes of forward here because there is\n    # a deepcopy in _prepare_forward\n    inv = dict(\n        projs=deepcopy(gain_info[\"projs\"]),\n        eigen_leads_weighted=False,\n        source_ori=forward[\"source_ori\"],\n        mri_head_t=forward[\"mri_head_t\"],\n        nsource=forward[\"nsource\"],\n        units=\"Am\",\n        coord_frame=forward[\"coord_frame\"],\n        source_nn=forward[\"source_nn\"],\n        src=forward[\"src\"],\n        fmri_prior=None,\n        info=deepcopy(forward[\"info\"]),\n    )\n    inv[\"info\"][\"bads\"] = [\n        bad for bad in info[\"bads\"] if bad in forward[\"info\"][\"ch_names\"]\n    ]\n    inv[\"info\"]._check_consistency()\n    del fixed, loose, depth, use_cps, forward\n\n    # Decompose the combined matrix\n    logger.info(\"Computing SVD of whitened and weighted lead field matrix.\")\n    eigen_fields, sing, eigen_leads = _safe_svd(gain, full_matrices=False)\n    del gain\n    logger.info(f\"    largest singular value = {np.max(sing):g}\")\n    logger.info(\n        f\"    scaling factor to adjust the trace = {trace_GRGT:g} \"\n        f\"(nchan = {eigen_fields.shape[0]} \"\n        f\"nzero = {(noise_cov['eig'] <= 0).sum()})\"\n    )\n\n    # MNE-ify everything for output\n    eigen_fields = dict(\n        data=eigen_fields.T,\n        col_names=gain_info[\"ch_names\"],\n        row_names=[],\n        nrow=eigen_fields.shape[1],\n        ncol=eigen_fields.shape[0],\n    )\n    eigen_leads = dict(\n        data=eigen_leads.T,\n        nrow=eigen_leads.shape[1],\n        ncol=eigen_leads.shape[0],\n        row_names=[],\n        col_names=[],\n    )\n    has_meg = False\n    has_eeg = False\n    for idx in range(gain_info[\"nchan\"]):\n        ch_type = channel_type(gain_info, idx)\n        if ch_type == \"eeg\":\n            has_eeg = True\n        if (ch_type == \"mag\") or (ch_type == \"grad\"):\n            has_meg = True\n    if has_eeg and has_meg:\n        methods = FIFF.FIFFV_MNE_MEG_EEG\n    elif has_meg:\n        methods = FIFF.FIFFV_MNE_MEG\n    else:\n        methods = FIFF.FIFFV_MNE_EEG\n\n    if orient_prior is not None:\n        orient_prior = dict(\n            data=orient_prior,\n            kind=FIFF.FIFFV_MNE_ORIENT_PRIOR_COV,\n            bads=[],\n            diag=True,\n            names=[],\n            eig=None,\n            eigvec=None,\n            dim=orient_prior.size,\n            nfree=1,\n            projs=[],\n        )\n    if depth_prior is not None:\n        depth_prior = dict(\n            data=depth_prior,\n            kind=FIFF.FIFFV_MNE_DEPTH_PRIOR_COV,\n            bads=[],\n            diag=True,\n            names=[],\n            eig=None,\n            eigvec=None,\n            dim=depth_prior.size,\n            nfree=1,\n            projs=[],\n        )\n    source_cov = dict(\n        data=source_std * source_std,\n        dim=source_std.size,\n        kind=FIFF.FIFFV_MNE_SOURCE_COV,\n        diag=True,\n        names=[],\n        projs=[],\n        eig=None,\n        eigvec=None,\n        nfree=1,\n        bads=[],\n    )\n    inv.update(\n        eigen_fields=eigen_fields,\n        eigen_leads=eigen_leads,\n        sing=sing,\n        nave=1.0,\n        depth_prior=depth_prior,\n        source_cov=source_cov,\n        noise_cov=noise_cov,\n        orient_prior=orient_prior,\n        methods=methods,\n    )\n    return InverseOperator(inv)", "metadata": {}}
{"_id": "mne_mne_minimum_norm/inverse.py_compute_rank_inverse_code", "title": "compute_rank_inverse", "text": "def compute_rank_inverse(inv):\n    \"\"\"Compute the rank of a linear inverse operator (MNE, dSPM, etc.).\n\n    Parameters\n    ----------\n    inv : instance of InverseOperator\n        The inverse operator.\n\n    Returns\n    -------\n    rank : int\n        The rank of the inverse operator.\n    \"\"\"\n    # this code shortened from prepare_inverse_operator\n    eig = inv[\"noise_cov\"][\"eig\"]\n    if not inv[\"noise_cov\"][\"diag\"]:\n        rank = np.sum(eig > 0)\n    else:\n        ncomp = make_projector(inv[\"projs\"], inv[\"noise_cov\"][\"names\"])[1]\n        rank = inv[\"noise_cov\"][\"dim\"] - ncomp\n    return rank", "metadata": {}}
{"_id": "mne_mne_minimum_norm/inverse.py_estimate_snr_code", "title": "estimate_snr", "text": "def estimate_snr(evoked, inv, verbose=None):\n    r\"\"\"Estimate the SNR as a function of time for evoked data.\n\n    Parameters\n    ----------\n    evoked : instance of Evoked\n        Evoked instance.\n    inv : instance of InverseOperator\n        The inverse operator.\n    %(verbose)s\n\n    Returns\n    -------\n    snr : ndarray, shape (n_times,)\n        The SNR estimated from the whitened data (i.e., GFP of whitened data).\n    snr_est : ndarray, shape (n_times,)\n        The SNR estimated using the mismatch between the unregularized\n        solution and the regularized solution.\n\n    Notes\n    -----\n    ``snr_est`` is estimated by using different amounts of inverse\n    regularization and checking the mismatch between predicted and\n    measured whitened data.\n\n    In more detail, given our whitened inverse obtained from SVD:\n\n    .. math::\n\n        \\tilde{M} = R^\\frac{1}{2}V\\Gamma U^T\n\n    The values in the diagonal matrix :math:`\\Gamma` are expressed in terms\n    of the chosen regularization :math:`\\lambda^2 \\sim 1/\\rm{SNR}^2`\n    and singular values :math:`\\lambda_k` as:\n\n    .. math::\n\n        \\gamma_k = \\frac{1}{\\lambda_k}\\frac{\\lambda_k^2}{\\lambda_k^2 + \\lambda^2}\n\n    We also know that our predicted data is given by:\n\n    .. math::\n\n        \\hat{x}(t) = G\\hat{j}(t)=C^\\frac{1}{2}U\\Pi w(t)\n\n    And thus our predicted whitened data is just:\n\n    .. math::\n\n        \\hat{w}(t) = U\\Pi w(t)\n\n    Where :math:`\\Pi` is diagonal with entries entries:\n\n    .. math::\n\n        \\lambda_k\\gamma_k = \\frac{\\lambda_k^2}{\\lambda_k^2 + \\lambda^2}\n\n    If we use no regularization, note that :math:`\\Pi` is just the\n    identity matrix. Here we test the squared magnitude of the difference\n    between unregularized solution and regularized solutions, choosing the\n    biggest regularization that achieves a :math:`\\chi^2`-test significance\n    of 0.001.\n\n    .. versionadded:: 0.9.0\n    \"\"\"  # noqa: E501\n    _check_reference(evoked, inv[\"info\"][\"ch_names\"])\n    _check_ch_names(inv, evoked.info)\n    inv = prepare_inverse_operator(inv, evoked.nave, 1.0 / 9.0, \"MNE\", copy=\"non-src\")\n    sel = _pick_channels_inverse_operator(evoked.ch_names, inv)\n    logger.info(\"Picked %d channels from the data\", len(sel))\n    data_white = np.dot(inv[\"whitener\"], np.dot(inv[\"proj\"], evoked.data[sel]))\n    data_white_ef = np.dot(inv[\"eigen_fields\"][\"data\"], data_white)\n    n_ch, n_times = data_white.shape\n\n    # Adapted from mne_analyze/regularization.c, compute_regularization\n    n_ch_eff = compute_rank_inverse(inv)\n    n_zero = n_ch - n_ch_eff\n    logger.info(\"Effective nchan = %d - %d = %d\", n_ch, n_zero, n_ch_eff)\n    del n_ch\n    signal = np.sum(data_white**2, axis=0)  # sum of squares across channels\n    snr = signal / n_ch_eff\n\n    # Adapted from noise_regularization\n    lambda2_est = np.empty(n_times)\n    lambda2_est.fill(10.0)\n    remaining = np.ones(n_times, bool)\n\n    # deal with low SNRs\n    bad = snr <= 1\n    lambda2_est[bad] = np.inf\n    remaining[bad] = False\n\n    # parameters\n    lambda_mult = 0.99\n    sing2 = (inv[\"sing\"] * inv[\"sing\"])[:, np.newaxis]\n    val = chi2.isf(1e-3, n_ch_eff)\n    for n_iter in range(1000):\n        # get_mne_weights (ew=error_weights)\n        # (split newaxis creation here for old numpy)\n        f = sing2 / (sing2 + lambda2_est[np.newaxis][:, remaining])\n        f[inv[\"sing\"] == 0] = 0\n        ew = data_white_ef[:, remaining] * (1.0 - f)\n        # check condition\n        err = np.sum(ew * ew, axis=0)\n        remaining[np.where(remaining)[0][err < val]] = False\n        if not remaining.any():\n            break\n        lambda2_est[remaining] *= lambda_mult\n    else:\n        warn(\"SNR estimation did not converge\")\n    snr_est = 1.0 / np.sqrt(lambda2_est)\n    snr = np.sqrt(snr)\n    return snr, snr_est", "metadata": {}}
{"_id": "mne_mne_minimum_norm/inverse.py_copy_code", "title": "copy", "text": "def copy(self):\n        \"\"\"Return a copy of the InverseOperator.\"\"\"\n        return InverseOperator(deepcopy(self))", "metadata": {}}
{"_id": "mne_mne_minimum_norm/inverse.py_ch_names_code", "title": "ch_names", "text": "def ch_names(self):\n        \"\"\"Name of channels attached to the inverse operator.\"\"\"\n        return self[\"info\"].ch_names", "metadata": {}}
{"_id": "mne_mne_minimum_norm/inverse.py_info_code", "title": "info", "text": "def info(self):\n        \"\"\":class:`~mne.Info` attached to the inverse operator.\"\"\"\n        return self[\"info\"]", "metadata": {}}
{"_id": "mne_mne_minimum_norm/spatial_resolution.py_resolution_metrics_code", "title": "resolution_metrics", "text": "def resolution_metrics(\n    resmat, src, function=\"psf\", metric=\"peak_err\", threshold=0.5, verbose=None\n):\n    \"\"\"Compute spatial resolution metrics for linear solvers.\n\n    Parameters\n    ----------\n    resmat : array, shape (n_orient * n_vertices, n_vertices)\n        The resolution matrix.\n        If not a square matrix and if the number of rows is a multiple of\n        number of columns (e.g. free or loose orientations), then the Euclidean\n        length per source location is computed (e.g. if inverse operator with\n        free orientations was applied to forward solution with fixed\n        orientations).\n    src : instance of SourceSpaces\n        Source space object from forward or inverse operator.\n    function : 'psf' | 'ctf'\n        Whether to compute metrics for columns (point-spread functions, PSFs)\n        or rows (cross-talk functions, CTFs) of the resolution matrix.\n    metric : str\n        The resolution metric to compute. Allowed options are:\n\n        Localization-based metrics:\n\n        - ``'peak_err'`` Peak localization error (PLE), Euclidean distance\n          between peak and true source location.\n        - ``'cog_err'`` Centre-of-gravity localisation error (CoG), Euclidean\n          distance between CoG and true source location.\n\n        Spatial-extent-based metrics:\n\n        - ``'sd_ext'`` Spatial deviation\n          (e.g. :footcite:`MolinsEtAl2008,HaukEtAl2019`).\n        - ``'maxrad_ext'`` Maximum radius to 50%% of max amplitude.\n\n        Amplitude-based metrics:\n\n        - ``'peak_amp'`` Ratio between absolute maximum amplitudes of peaks\n          per location and maximum peak across locations.\n        - ``'sum_amp'`` Ratio between sums of absolute amplitudes.\n\n    threshold : float\n        Amplitude fraction threshold for spatial extent metric 'maxrad_ext'.\n        Defaults to 0.5.\n    %(verbose)s\n\n    Returns\n    -------\n    resolution_metric : instance of SourceEstimate\n        The resolution metric.\n\n    Notes\n    -----\n    For details, see :footcite:`MolinsEtAl2008,HaukEtAl2019`.\n\n    .. versionadded:: 0.20\n\n    References\n    ----------\n    .. footbibliography::\n    \"\"\"\n    # Check if input options are valid\n    metrics = (\"peak_err\", \"cog_err\", \"sd_ext\", \"maxrad_ext\", \"peak_amp\", \"sum_amp\")\n    if metric not in metrics:\n        raise ValueError(f'\"{metric}\" is not a recognized metric.')\n\n    if function not in [\"psf\", \"ctf\"]:\n        raise ValueError(f\"Not a recognised resolution function: {function}.\")\n\n    if metric in (\"peak_err\", \"cog_err\"):\n        resolution_metric = _localisation_error(\n            resmat, src, function=function, metric=metric\n        )\n\n    elif metric in (\"sd_ext\", \"maxrad_ext\"):\n        resolution_metric = _spatial_extent(\n            resmat, src, function=function, metric=metric, threshold=threshold\n        )\n\n    elif metric in (\"peak_amp\", \"sum_amp\"):\n        resolution_metric = _relative_amplitude(\n            resmat, src, function=function, metric=metric\n        )\n\n    # get vertices from source space\n    vertno_lh = src[0][\"vertno\"]\n    vertno_rh = src[1][\"vertno\"]\n    vertno = [vertno_lh, vertno_rh]\n\n    # Convert array to source estimate\n    resolution_metric = SourceEstimate(resolution_metric, vertno, tmin=0.0, tstep=1.0)\n\n    return resolution_metric", "metadata": {}}
{"_id": "mne_mne_minimum_norm/time_frequency.py_source_band_induced_power_code", "title": "source_band_induced_power", "text": "def source_band_induced_power(\n    epochs,\n    inverse_operator,\n    bands,\n    label=None,\n    lambda2=1.0 / 9.0,\n    method=\"dSPM\",\n    nave=1,\n    n_cycles=5,\n    df=1,\n    use_fft=False,\n    decim=1,\n    baseline=None,\n    baseline_mode=\"logratio\",\n    pca=True,\n    n_jobs=None,\n    prepared=False,\n    method_params=None,\n    use_cps=True,\n    *,\n    verbose=None,\n):\n    \"\"\"Compute source space induced power in given frequency bands.\n\n    Parameters\n    ----------\n    epochs : instance of Epochs\n        The epochs.\n    inverse_operator : instance of InverseOperator\n        The inverse operator.\n    bands : dict\n        Example : bands = dict(alpha=[8, 9]).\n    label : Label | list of Label\n        Restricts the source estimates to a given label or list of labels. If\n        labels are provided in a list, power will be averaged over vertices.\n    lambda2 : float\n        The regularization parameter of the minimum norm.\n    method : \"MNE\" | \"dSPM\" | \"sLORETA\" | \"eLORETA\"\n        Use minimum norm, dSPM (default), sLORETA, or eLORETA.\n    nave : int\n        The number of averages used to scale the noise covariance matrix.\n    n_cycles : float | array of float\n        Number of cycles. Fixed number or one per frequency.\n    df : float\n        Delta frequency within bands.\n    use_fft : bool\n        Do convolutions in time or frequency domain with FFT.\n    decim : int\n        Temporal decimation factor.\n    baseline : None (default) or tuple, shape (2,)\n        The time interval to apply baseline correction. If None do not apply\n        it. If baseline is (a, b) the interval is between \"a (s)\" and \"b (s)\".\n        If a is None the beginning of the data is used and if b is None then b\n        is set to the end of the interval. If baseline is equal to (None, None)\n        all the time interval is used.\n    baseline_mode : 'mean' | 'ratio' | 'logratio' | 'percent' | 'zscore' | 'zlogratio'\n        Perform baseline correction by\n\n        - subtracting the mean of baseline values ('mean')\n        - dividing by the mean of baseline values ('ratio')\n        - dividing by the mean of baseline values and taking the log\n          ('logratio')\n        - subtracting the mean of baseline values followed by dividing by\n          the mean of baseline values ('percent')\n        - subtracting the mean of baseline values and dividing by the\n          standard deviation of baseline values ('zscore')\n        - dividing by the mean of baseline values, taking the log, and\n          dividing by the standard deviation of log baseline values\n          ('zlogratio')\n\n    pca : bool\n        If True, the true dimension of data is estimated before running\n        the time-frequency transforms. It reduces the computation times\n        e.g. with a dataset that was maxfiltered (true dim is 64).\n    %(n_jobs)s\n    prepared : bool\n        If True, do not call :func:`prepare_inverse_operator`.\n    method_params : dict | None\n        Additional options for eLORETA. See Notes of :func:`apply_inverse`.\n\n        .. versionadded:: 0.16\n    %(use_cps_restricted)s\n\n        .. versionadded:: 0.20\n    %(verbose)s\n\n    Returns\n    -------\n    stcs : dict of SourceEstimate (or VolSourceEstimate)\n        The estimated source space induced power estimates in shape\n        (n_vertices, n_frequencies, n_samples) if label=None or label=label.\n        For lists of one or more labels, the induced power estimate has shape\n        (n_labels, n_frequencies, n_samples).\n    \"\"\"  # noqa: E501\n    _check_option(\"method\", method, INVERSE_METHODS)\n\n    freqs = np.concatenate(\n        [np.arange(band[0], band[1] + df / 2.0, df) for _, band in bands.items()]\n    )\n\n    powers, _, vertno = _source_induced_power(\n        epochs,\n        inverse_operator,\n        freqs,\n        label=label,\n        lambda2=lambda2,\n        method=method,\n        nave=nave,\n        n_cycles=n_cycles,\n        decim=decim,\n        use_fft=use_fft,\n        pca=pca,\n        n_jobs=n_jobs,\n        with_plv=False,\n        prepared=prepared,\n        method_params=method_params,\n        use_cps=use_cps,\n    )\n\n    Fs = epochs.info[\"sfreq\"]  # sampling in Hz\n    stcs = dict()\n\n    subject = _subject_from_inverse(inverse_operator)\n    _log_rescale(baseline, baseline_mode)  # for early failure\n    for name, band in bands.items():\n        idx = [k for k, f in enumerate(freqs) if band[0] <= f <= band[1]]\n\n        # average power in band + mean over epochs\n        power = np.mean(powers[:, idx, :], axis=1)\n\n        # Run baseline correction\n        power = rescale(\n            power,\n            epochs.times[::decim],\n            baseline,\n            baseline_mode,\n            copy=False,\n            verbose=False,\n        )\n\n        tmin = epochs.times[0]\n        tstep = float(decim) / Fs\n        stc = _make_stc(\n            power,\n            vertices=vertno,\n            tmin=tmin,\n            tstep=tstep,\n            subject=subject,\n            src_type=inverse_operator[\"src\"].kind,\n        )\n        stcs[name] = stc\n\n        logger.info(\"[done]\")\n\n    return stcs", "metadata": {}}
{"_id": "mne_mne_minimum_norm/time_frequency.py_source_induced_power_code", "title": "source_induced_power", "text": "def source_induced_power(\n    epochs,\n    inverse_operator,\n    freqs,\n    label=None,\n    lambda2=1.0 / 9.0,\n    method=\"dSPM\",\n    nave=1,\n    n_cycles=5,\n    decim=1,\n    use_fft=False,\n    pick_ori=None,\n    baseline=None,\n    baseline_mode=\"logratio\",\n    pca=True,\n    n_jobs=None,\n    *,\n    return_plv=True,\n    zero_mean=False,\n    prepared=False,\n    method_params=None,\n    use_cps=True,\n    verbose=None,\n):\n    \"\"\"Compute induced power and phase lock.\n\n    Computation can optionally be restricted in a label.\n\n    Parameters\n    ----------\n    epochs : instance of Epochs\n        The epochs.\n    inverse_operator : instance of InverseOperator\n        The inverse operator.\n    freqs : array\n        Array of frequencies of interest.\n    label : Label | list of Label\n        Restricts the source estimates to a given label or list of labels. If\n        labels are provided in a list, power will be averaged over vertices within each\n        label.\n    lambda2 : float\n        The regularization parameter of the minimum norm.\n    method : \"MNE\" | \"dSPM\" | \"sLORETA\" | \"eLORETA\"\n        Use minimum norm, dSPM (default), sLORETA, or eLORETA.\n    nave : int\n        The number of averages used to scale the noise covariance matrix.\n    n_cycles : float | array of float\n        Number of cycles. Fixed number or one per frequency.\n    decim : int\n        Temporal decimation factor.\n    use_fft : bool\n        Do convolutions in time or frequency domain with FFT.\n    pick_ori : None | \"normal\"\n        If \"normal\", rather than pooling the orientations by taking the norm,\n        only the radial component is kept. This is only implemented\n        when working with loose orientations.\n    baseline : None (default) or tuple of length 2\n        The time interval to apply baseline correction.\n        If None do not apply it. If baseline is (a, b)\n        the interval is between \"a (s)\" and \"b (s)\".\n        If a is None the beginning of the data is used\n        and if b is None then b is set to the end of the interval.\n        If baseline is equal to (None, None) all the time\n        interval is used.\n    baseline_mode : 'mean' | 'ratio' | 'logratio' | 'percent' | 'zscore' | 'zlogratio'\n        Perform baseline correction by\n\n        - subtracting the mean of baseline values ('mean')\n        - dividing by the mean of baseline values ('ratio')\n        - dividing by the mean of baseline values and taking the log\n          ('logratio')\n        - subtracting the mean of baseline values followed by dividing by\n          the mean of baseline values ('percent')\n        - subtracting the mean of baseline values and dividing by the\n          standard deviation of baseline values ('zscore')\n        - dividing by the mean of baseline values, taking the log, and\n          dividing by the standard deviation of log baseline values\n          ('zlogratio')\n\n    pca : bool\n        If True, the true dimension of data is estimated before running\n        the time-frequency transforms. It reduces the computation times\n        e.g. with a dataset that was maxfiltered (true dim is 64).\n    %(n_jobs)s\n    return_plv : bool\n        If True, return the phase-locking value array. Else, only return power.\n\n        .. versionadded:: 1.6\n    zero_mean : bool\n        Make sure the wavelets are zero mean.\n    prepared : bool\n        If True, do not call :func:`prepare_inverse_operator`.\n    method_params : dict | None\n        Additional options for eLORETA. See Notes of :func:`apply_inverse`.\n    %(use_cps_restricted)s\n\n        .. versionadded:: 0.20\n    %(verbose)s\n\n    Returns\n    -------\n    power : array\n        The induced power array with shape (n_sources, n_freqs, n_samples) if\n        label=None or label=label. For lists of one or more labels, the induced\n        power estimate has shape (n_labels, n_frequencies, n_samples).\n    plv : array\n        The phase-locking value array with shape (n_sources, n_freqs,\n        n_samples). Only returned if ``return_plv=True``.\n    \"\"\"  # noqa: E501\n    _check_option(\"method\", method, INVERSE_METHODS)\n    _check_ori(pick_ori, inverse_operator[\"source_ori\"], inverse_operator[\"src\"])\n\n    power, plv, vertno = _source_induced_power(\n        epochs,\n        inverse_operator,\n        freqs,\n        label=label,\n        lambda2=lambda2,\n        method=method,\n        nave=nave,\n        n_cycles=n_cycles,\n        decim=decim,\n        use_fft=use_fft,\n        pick_ori=pick_ori,\n        pca=pca,\n        n_jobs=n_jobs,\n        with_plv=return_plv,\n        method_params=method_params,\n        zero_mean=zero_mean,\n        prepared=prepared,\n        use_cps=use_cps,\n    )\n\n    # Run baseline correction\n    power = rescale(power, epochs.times[::decim], baseline, baseline_mode, copy=False)\n\n    outs = (power, plv) if return_plv else power\n    return outs", "metadata": {}}
{"_id": "mne_mne_minimum_norm/time_frequency.py_compute_source_psd_code", "title": "compute_source_psd", "text": "def compute_source_psd(\n    raw,\n    inverse_operator,\n    lambda2=1.0 / 9.0,\n    method=\"dSPM\",\n    tmin=0.0,\n    tmax=None,\n    fmin=0.0,\n    fmax=200.0,\n    n_fft=2048,\n    overlap=0.5,\n    pick_ori=None,\n    label=None,\n    nave=1,\n    pca=True,\n    prepared=False,\n    method_params=None,\n    inv_split=None,\n    bandwidth=\"hann\",\n    adaptive=False,\n    low_bias=False,\n    n_jobs=None,\n    return_sensor=False,\n    dB=False,\n    *,\n    verbose=None,\n):\n    \"\"\"Compute source power spectral density (PSD).\n\n    Parameters\n    ----------\n    raw : instance of Raw\n        The raw data.\n    inverse_operator : instance of InverseOperator\n        The inverse operator.\n    lambda2 : float\n        The regularization parameter.\n    method : \"MNE\" | \"dSPM\" | \"sLORETA\"\n        Use minimum norm, dSPM (default), sLORETA, or eLORETA.\n    tmin : float\n        The beginning of the time interval of interest (in seconds).\n        Use 0. for the beginning of the file.\n    tmax : float | None\n        The end of the time interval of interest (in seconds). If None\n        stop at the end of the file.\n    fmin : float\n        The lower frequency of interest.\n    fmax : float\n        The upper frequency of interest.\n    n_fft : int\n        Window size for the FFT. Should be a power of 2.\n    overlap : float\n        The overlap fraction between windows. Should be between 0 and 1.\n        0 means no overlap.\n    pick_ori : None | \"normal\"\n        If \"normal\", rather than pooling the orientations by taking the norm,\n        only the radial component is kept. This is only implemented\n        when working with loose orientations.\n    label : Label\n        Restricts the source estimates to a given label.\n    nave : int\n        The number of averages used to scale the noise covariance matrix.\n    pca : bool\n        If True, the true dimension of data is estimated before running\n        the time-frequency transforms. It reduces the computation times\n        e.g. with a dataset that was maxfiltered (true dim is 64).\n    prepared : bool\n        If True, do not call :func:`prepare_inverse_operator`.\n    method_params : dict | None\n        Additional options for eLORETA. See Notes of :func:`apply_inverse`.\n\n        .. versionadded:: 0.16\n    inv_split : int or None\n        Split inverse operator into inv_split parts in order to save memory.\n\n        .. versionadded:: 0.17\n    bandwidth : float | str\n        The bandwidth of the multi taper windowing function in Hz.\n        Can also be a string (e.g., 'hann') to use a single window.\n\n        For backward compatibility, the default is 'hann'.\n\n        .. versionadded:: 0.17\n    adaptive : bool\n        Use adaptive weights to combine the tapered spectra into PSD\n        (slow, use n_jobs >> 1 to speed up computation).\n\n        .. versionadded:: 0.17\n    low_bias : bool\n        Only use tapers with more than 90%% spectral concentration within\n        bandwidth.\n\n        .. versionadded:: 0.17\n    %(n_jobs)s\n        It is only used if adaptive=True.\n\n        .. versionadded:: 0.17\n    return_sensor : bool\n        If True, return the sensor PSDs as an EvokedArray.\n\n        .. versionadded:: 0.17\n    dB : bool\n        If True (default False), return output it decibels.\n\n        .. versionadded:: 0.17\n    %(verbose)s\n\n    Returns\n    -------\n    stc_psd : instance of SourceEstimate | VolSourceEstimate\n        The PSD of each of the sources.\n    sensor_psd : instance of EvokedArray\n        The PSD of each sensor. Only returned if ``return_sensor`` is True.\n\n    See Also\n    --------\n    compute_source_psd_epochs\n\n    Notes\n    -----\n    Each window is multiplied by a window before processing, so\n    using a non-zero overlap is recommended.\n\n    This function is different from :func:`compute_source_psd_epochs` in that:\n\n    1. ``bandwidth='hann'`` by default, skipping multitaper estimation\n    2. For convenience it wraps\n       :func:`mne.make_fixed_length_events` and :class:`mne.Epochs`.\n\n    Otherwise the two should produce identical results.\n    \"\"\"\n    tmin = 0.0 if tmin is None else float(tmin)\n    overlap = float(overlap)\n    if not 0 <= overlap < 1:\n        raise ValueError(f\"Overlap must be at least 0 and less than 1, got {overlap}\")\n    n_fft = int(n_fft)\n    duration = ((1.0 - overlap) * n_fft) / raw.info[\"sfreq\"]\n    events = make_fixed_length_events(raw, 1, tmin, tmax, duration)\n    epochs = Epochs(raw, events, 1, 0, (n_fft - 1) / raw.info[\"sfreq\"], baseline=None)\n    out = compute_source_psd_epochs(\n        epochs,\n        inverse_operator,\n        lambda2,\n        method,\n        fmin,\n        fmax,\n        pick_ori,\n        label,\n        nave,\n        pca,\n        inv_split,\n        bandwidth,\n        adaptive,\n        low_bias,\n        True,\n        n_jobs,\n        prepared,\n        method_params,\n        return_sensor=True,\n    )\n    source_data = 0.0\n    sensor_data = 0.0\n    count = 0\n    for stc, evoked in out:\n        source_data += stc.data\n        sensor_data += evoked.data\n        count += 1\n    assert count > 0  # should be guaranteed by make_fixed_length_events\n    sensor_data /= count\n    source_data /= count\n    if dB:\n        np.log10(sensor_data, out=sensor_data)\n        sensor_data *= 10.0\n        np.log10(source_data, out=source_data)\n        source_data *= 10.0\n    evoked.data = sensor_data\n    evoked.nave = count\n    stc.data = source_data\n    out = stc\n    if return_sensor:\n        out = (out, evoked)\n    return out", "metadata": {}}
{"_id": "mne_mne_minimum_norm/time_frequency.py_compute_source_psd_epochs_code", "title": "compute_source_psd_epochs", "text": "def compute_source_psd_epochs(\n    epochs,\n    inverse_operator,\n    lambda2=1.0 / 9.0,\n    method=\"dSPM\",\n    fmin=0.0,\n    fmax=200.0,\n    pick_ori=None,\n    label=None,\n    nave=1,\n    pca=True,\n    inv_split=None,\n    bandwidth=4.0,\n    adaptive=False,\n    low_bias=True,\n    return_generator=False,\n    n_jobs=None,\n    prepared=False,\n    method_params=None,\n    return_sensor=False,\n    use_cps=True,\n    verbose=None,\n):\n    \"\"\"Compute source power spectral density (PSD) from Epochs.\n\n    This uses the multi-taper method to compute the PSD for each epoch.\n\n    Parameters\n    ----------\n    epochs : instance of Epochs\n        The raw data.\n    inverse_operator : instance of InverseOperator\n        The inverse operator.\n    lambda2 : float\n        The regularization parameter.\n    method : \"MNE\" | \"dSPM\" | \"sLORETA\" | \"eLORETA\"\n        Use minimum norm, dSPM (default), sLORETA, or eLORETA.\n    fmin : float\n        The lower frequency of interest.\n    fmax : float\n        The upper frequency of interest.\n    pick_ori : None | \"normal\"\n        If \"normal\", rather than pooling the orientations by taking the norm,\n        only the radial component is kept. This is only implemented\n        when working with loose orientations.\n    label : Label\n        Restricts the source estimates to a given label.\n    nave : int\n        The number of averages used to scale the noise covariance matrix.\n    pca : bool\n        If True, the true dimension of data is estimated before running\n        the time-frequency transforms. It reduces the computation times\n        e.g. with a dataset that was maxfiltered (true dim is 64).\n    inv_split : int or None\n        Split inverse operator into inv_split parts in order to save memory.\n    bandwidth : float | str\n        The bandwidth of the multi taper windowing function in Hz.\n        Can also be a string (e.g., 'hann') to use a single window.\n    adaptive : bool\n        Use adaptive weights to combine the tapered spectra into PSD\n        (slow, use n_jobs >> 1 to speed up computation).\n    low_bias : bool\n        Only use tapers with more than 90%% spectral concentration within\n        bandwidth.\n    return_generator : bool\n        Return a generator object instead of a list. This allows iterating\n        over the stcs without having to keep them all in memory.\n    %(n_jobs)s\n        It is only used if adaptive=True.\n    prepared : bool\n        If True, do not call :func:`prepare_inverse_operator`.\n    method_params : dict | None\n        Additional options for eLORETA. See Notes of :func:`apply_inverse`.\n\n        .. versionadded:: 0.16\n    return_sensor : bool\n        If True, also return the sensor PSD for each epoch as an EvokedArray.\n\n        .. versionadded:: 0.17\n    %(use_cps_restricted)s\n\n        .. versionadded:: 0.20\n    %(verbose)s\n\n    Returns\n    -------\n    out : list (or generator object)\n        A list (or generator) for the source space PSD (and optionally the\n        sensor PSD) for each epoch.\n\n    See Also\n    --------\n    compute_source_psd\n    \"\"\"\n    # use an auxiliary function so we can either return a generator or a list\n    stcs_gen = _compute_source_psd_epochs(\n        epochs,\n        inverse_operator,\n        lambda2=lambda2,\n        method=method,\n        fmin=fmin,\n        fmax=fmax,\n        pick_ori=pick_ori,\n        label=label,\n        nave=nave,\n        pca=pca,\n        inv_split=inv_split,\n        bandwidth=bandwidth,\n        adaptive=adaptive,\n        low_bias=low_bias,\n        n_jobs=n_jobs,\n        prepared=prepared,\n        method_params=method_params,\n        return_sensor=return_sensor,\n        use_cps=use_cps,\n    )\n\n    if return_generator:\n        # return generator object\n        return stcs_gen\n    else:\n        # return a list\n        stcs = list()\n        for stc in stcs_gen:\n            stcs.append(stc)\n\n        return stcs", "metadata": {}}
{"_id": "mne_mne_decoding/time_frequency.py_fit_transform_code", "title": "fit_transform", "text": "def fit_transform(self, X, y=None):\n        \"\"\"Time-frequency transform of times series along the last axis.\n\n        Parameters\n        ----------\n        X : array, shape (n_samples, n_channels, n_times)\n            The training data samples. The channel dimension can be zero- or\n            1-dimensional.\n        y : None\n            For scikit-learn compatibility purposes.\n\n        Returns\n        -------\n        Xt : array, shape (n_samples, n_channels, n_freqs, n_times)\n            The time-frequency transform of the data, where n_channels can be\n            zero- or 1-dimensional.\n        \"\"\"\n        return self.fit(X, y).transform(X)", "metadata": {}}
{"_id": "mne_mne_decoding/time_frequency.py_fit_code", "title": "fit", "text": "def fit(self, X, y=None):  # noqa: D401\n        \"\"\"Do nothing (for scikit-learn compatibility purposes).\n\n        Parameters\n        ----------\n        X : array, shape (n_samples, n_channels, n_times)\n            The training data.\n        y : array | None\n            The target values.\n\n        Returns\n        -------\n        self : object\n            Return self.\n        \"\"\"\n        # Check non-average output\n        _check_option(\"output\", self.output, [\"complex\", \"power\", \"phase\"])\n        self._check_data(X, y=y, fit=True)\n        self.fitted_ = True\n        return self", "metadata": {}}
{"_id": "mne_mne_decoding/time_frequency.py_transform_code", "title": "transform", "text": "def transform(self, X):\n        \"\"\"Time-frequency transform of times series along the last axis.\n\n        Parameters\n        ----------\n        X : array, shape (n_samples, [n_channels, ]n_times)\n            The training data samples. The channel dimension can be zero- or\n            1-dimensional.\n\n        Returns\n        -------\n        Xt : array, shape (n_samples, [n_channels, ]n_freqs, n_times)\n            The time-frequency transform of the data, where n_channels can be\n            zero- or 1-dimensional.\n        \"\"\"\n        X = self._check_data(X, atleast_3d=False)\n        check_is_fitted(self, \"fitted_\")\n        # Ensure 3-dimensional X\n        shape = X.shape[1:-1]\n        if not shape:\n            X = X[:, np.newaxis, :]\n\n        # Compute time-frequency\n        Xt = _compute_tfr(\n            X,\n            freqs=self.freqs,\n            sfreq=self.sfreq,\n            method=self.method,\n            n_cycles=self.n_cycles,\n            zero_mean=True,\n            time_bandwidth=self.time_bandwidth,\n            use_fft=self.use_fft,\n            decim=self.decim,\n            output=self.output,\n            n_jobs=self.n_jobs,\n            verbose=self.verbose,\n        )\n\n        # Back to original shape\n        if not shape:\n            Xt = Xt[:, 0, :]\n\n        return Xt", "metadata": {}}
{"_id": "mne_mne_decoding/receptive_field.py_fit_code", "title": "fit", "text": "def fit(self, X, y):\n        \"\"\"Fit a receptive field model.\n\n        Parameters\n        ----------\n        X : array, shape (n_times[, n_epochs], n_features)\n            The input features for the model.\n        y : array, shape (n_times[, n_epochs][, n_outputs])\n            The output features for the model.\n\n        Returns\n        -------\n        self : instance\n            The instance so you can chain operations.\n        \"\"\"\n        if self.scoring not in _SCORERS.keys():\n            raise ValueError(\n                f\"scoring must be one of {sorted(_SCORERS.keys())}, got {self.scoring} \"\n            )\n        self.sfreq_ = float(self.sfreq)\n        X, y, _, self._y_dim = self._check_dimensions(X, y)\n\n        if self.tmin > self.tmax:\n            raise ValueError(f\"tmin ({self.tmin}) must be at most tmax ({self.tmax})\")\n        # Initialize delays\n        self.delays_ = _times_to_delays(self.tmin, self.tmax, self.sfreq_)\n\n        # Define the slice that we should use in the middle\n        self.valid_samples_ = _delays_to_slice(self.delays_)\n\n        if isinstance(self.estimator, numbers.Real):\n            if self.fit_intercept is None:\n                self.fit_intercept_ = True\n            else:\n                self.fit_intercept_ = self.fit_intercept\n            estimator = TimeDelayingRidge(\n                self.tmin,\n                self.tmax,\n                self.sfreq_,\n                alpha=self.estimator,\n                fit_intercept=self.fit_intercept_,\n                n_jobs=self.n_jobs,\n                edge_correction=self.edge_correction,\n            )\n        elif is_regressor(self.estimator):\n            estimator = clone(self.estimator)\n            if (\n                self.fit_intercept is not None\n                and estimator.fit_intercept != self.fit_intercept\n            ):\n                raise ValueError(\n                    f\"Estimator fit_intercept ({estimator.fit_intercept}) != \"\n                    f\"initialization fit_intercept ({self.fit_intercept}), initialize \"\n                    \"ReceptiveField with the same fit_intercept value or use \"\n                    \"fit_intercept=None\"\n                )\n            self.fit_intercept_ = estimator.fit_intercept\n        else:\n            raise ValueError(\n                \"`estimator` must be a float or an instance of `BaseEstimator`, got \"\n                f\"type {self.estimator}.\"\n            )\n        self.estimator_ = estimator\n        del estimator\n        _check_estimator(self.estimator_)\n\n        # Create input features\n        n_times, n_epochs, n_feats = X.shape\n        n_outputs = y.shape[-1]\n        n_delays = len(self.delays_)\n\n        # Update feature names if we have none\n        if (self.feature_names is not None) and (len(self.feature_names) != n_feats):\n            raise ValueError(\n                f\"n_features in X does not match feature names ({n_feats} != \"\n                f\"{len(self.feature_names)})\"\n            )\n\n        # Create input features\n        X, y = self._delay_and_reshape(X, y)\n\n        self.estimator_.fit(X, y)\n        coef = get_coef(self.estimator_, \"coef_\")  # (n_targets, n_features)\n        shape = [n_feats, n_delays]\n        if self._y_dim > 1:\n            shape.insert(0, -1)\n        self.coef_ = coef.reshape(shape)\n\n        # Inverse-transform model weights\n        if self.patterns:\n            if isinstance(self.estimator_, TimeDelayingRidge):\n                cov_ = self.estimator_.cov_ / float(n_times * n_epochs - 1)\n                y = y.reshape(-1, y.shape[-1], order=\"F\")\n            else:\n                X = X - X.mean(0, keepdims=True)\n                cov_ = np.cov(X.T)\n            del X\n\n            # Inverse output covariance\n            if y.ndim == 2 and y.shape[1] != 1:\n                y = y - y.mean(0, keepdims=True)\n                inv_Y = pinv(np.cov(y.T))\n            else:\n                inv_Y = 1.0 / float(n_times * n_epochs - 1)\n            del y\n\n            # Inverse coef according to Haufe's method\n            # patterns has shape (n_feats * n_delays, n_outputs)\n            coef = np.reshape(self.coef_, (n_feats * n_delays, n_outputs))\n            patterns = cov_.dot(coef.dot(inv_Y))\n            self.patterns_ = patterns.reshape(shape)\n\n        return self", "metadata": {}}
{"_id": "mne_mne_decoding/receptive_field.py_predict_code", "title": "predict", "text": "def predict(self, X):\n        \"\"\"Generate predictions with a receptive field.\n\n        Parameters\n        ----------\n        X : array, shape (n_times[, n_epochs], n_channels)\n            The input features for the model.\n\n        Returns\n        -------\n        y_pred : array, shape (n_times[, n_epochs][, n_outputs])\n            The output predictions. \"Note that valid samples (those\n            unaffected by edge artifacts during the time delaying step) can\n            be obtained using ``y_pred[rf.valid_samples_]``.\n        \"\"\"\n        if not hasattr(self, \"delays_\"):\n            raise NotFittedError(\"Estimator has not been fit yet.\")\n        X, _, X_dim = self._check_dimensions(X, None, predict=True)[:3]\n        del _\n        # convert to sklearn and back\n        pred_shape = X.shape[:-1]\n        if self._y_dim > 1:\n            pred_shape = pred_shape + (self.coef_.shape[0],)\n        X, _ = self._delay_and_reshape(X)\n        y_pred = self.estimator_.predict(X)\n        y_pred = y_pred.reshape(pred_shape, order=\"F\")\n        shape = list(y_pred.shape)\n        if X_dim <= 2:\n            shape.pop(1)  # epochs\n            extra = 0\n        else:\n            extra = 1\n        shape = shape[: self._y_dim + extra]\n        y_pred.shape = shape\n        return y_pred", "metadata": {}}
{"_id": "mne_mne_decoding/receptive_field.py_score_code", "title": "score", "text": "def score(self, X, y):\n        \"\"\"Score predictions generated with a receptive field.\n\n        This calls ``self.predict``, then masks the output of this\n        and ``y` with ``self.valid_samples_``. Finally, it passes\n        this to a :mod:`sklearn.metrics` scorer.\n\n        Parameters\n        ----------\n        X : array, shape (n_times[, n_epochs], n_channels)\n            The input features for the model.\n        y : array, shape (n_times[, n_epochs][, n_outputs])\n            Used for scikit-learn compatibility.\n\n        Returns\n        -------\n        scores : list of float, shape (n_outputs,)\n            The scores estimated by the model for each output (e.g. mean\n            R2 of ``predict(X)``).\n        \"\"\"\n        # Create our scoring object\n        scorer_ = _SCORERS[self.scoring]\n\n        # Generate predictions, then reshape so we can mask time\n        X, y = self._check_dimensions(X, y, predict=True)[:2]\n        n_times, n_epochs, n_outputs = y.shape\n        y_pred = self.predict(X)\n        y_pred = y_pred[self.valid_samples_]\n        y = y[self.valid_samples_]\n\n        # Re-vectorize and call scorer\n        y = y.reshape([-1, n_outputs], order=\"F\")\n        y_pred = y_pred.reshape([-1, n_outputs], order=\"F\")\n        assert y.shape == y_pred.shape\n        scores = scorer_(y, y_pred, multioutput=\"raw_values\")\n        return scores", "metadata": {}}
{"_id": "mne_mne_decoding/search_light.py_fit_code", "title": "fit", "text": "def fit(self, X, y, **fit_params):\n        \"\"\"Fit a series of independent estimators to the dataset.\n\n        Parameters\n        ----------\n        X : array, shape (n_samples, nd_features, n_tasks)\n            The training input samples. For each data slice, a clone estimator\n            is fitted independently. The feature dimension can be\n            multidimensional e.g.\n            X.shape = (n_samples, n_features_1, n_features_2, n_tasks).\n        y : array, shape (n_samples,) | (n_samples, n_targets)\n            The target values.\n        **fit_params : dict of string -> object\n            Parameters to pass to the fit method of the estimator.\n\n        Returns\n        -------\n        self : object\n            Return self.\n        \"\"\"\n        _check_estimator(self.base_estimator)\n        X, _ = self._check_Xy(X, y, fit=True)\n        parallel, p_func, n_jobs = parallel_func(\n            _sl_fit,\n            self.n_jobs,\n            max_jobs=X.shape[-1],\n            verbose=_verbose_safe_false(),\n        )\n        self.estimators_ = list()\n        self.fit_params_ = fit_params\n\n        # For fitting, the parallelization is across estimators.\n        context = _create_progressbar_context(self, X, \"Fitting\")\n        with context as pb:\n            estimators = parallel(\n                p_func(self.base_estimator, split, y, pb.subset(pb_idx), **fit_params)\n                for pb_idx, split in array_split_idx(X, n_jobs, axis=-1)\n            )\n\n        # Each parallel job can have a different number of training estimators\n        # We can't directly concatenate them because of sklearn's Bagging API\n        # (see scikit-learn #9720)\n        self.estimators_ = np.empty(X.shape[-1], dtype=object)\n        idx = 0\n        for job_estimators in estimators:\n            for est in job_estimators:\n                self.estimators_[idx] = est\n                idx += 1\n        return self", "metadata": {}}
{"_id": "mne_mne_decoding/search_light.py_fit_transform_code", "title": "fit_transform", "text": "def fit_transform(self, X, y, **fit_params):\n        \"\"\"Fit and transform a series of independent estimators to the dataset.\n\n        Parameters\n        ----------\n        X : array, shape (n_samples, nd_features, n_tasks)\n            The training input samples. For each task, a clone estimator\n            is fitted independently. The feature dimension can be\n            multidimensional, e.g.::\n\n                X.shape = (n_samples, n_features_1, n_features_2, n_estimators)\n        y : array, shape (n_samples,) | (n_samples, n_targets)\n            The target values.\n        **fit_params : dict of string -> object\n            Parameters to pass to the fit method of the estimator.\n\n        Returns\n        -------\n        y_pred : array, shape (n_samples, n_tasks) | (n_samples, n_tasks, n_targets)\n            The predicted values for each estimator.\n        \"\"\"  # noqa: E501\n        return self.fit(X, y, **fit_params).transform(X)", "metadata": {}}
{"_id": "mne_mne_decoding/search_light.py_transform_code", "title": "transform", "text": "def transform(self, X):\n        \"\"\"Transform each data slice/task with a series of independent estimators.\n\n        The number of tasks in X should match the number of tasks/estimators\n        given at fit time.\n\n        Parameters\n        ----------\n        X : array, shape (n_samples, nd_features, n_tasks)\n            The input samples. For each data slice/task, the corresponding\n            estimator makes a transformation of the data, e.g.\n            ``[estimators[ii].transform(X[..., ii]) for ii in range(n_estimators)]``.\n            The feature dimension can be multidimensional e.g.\n            X.shape = (n_samples, n_features_1, n_features_2, n_tasks).\n\n        Returns\n        -------\n        Xt : array, shape (n_samples, n_estimators)\n            The transformed values generated by each estimator.\n        \"\"\"  # noqa: E501\n        return self._transform(X, \"transform\")", "metadata": {}}
{"_id": "mne_mne_decoding/search_light.py_predict_code", "title": "predict", "text": "def predict(self, X):\n        \"\"\"Predict each data slice/task with a series of independent estimators.\n\n        The number of tasks in X should match the number of tasks/estimators\n        given at fit time.\n\n        Parameters\n        ----------\n        X : array, shape (n_samples, nd_features, n_tasks)\n            The input samples. For each data slice, the corresponding estimator\n            makes the sample predictions, e.g.:\n            ``[estimators[ii].predict(X[..., ii]) for ii in range(n_estimators)]``.\n            The feature dimension can be multidimensional e.g.\n            X.shape = (n_samples, n_features_1, n_features_2, n_tasks).\n\n        Returns\n        -------\n        y_pred : array, shape (n_samples, n_estimators) | (n_samples, n_tasks, n_targets)\n            Predicted values for each estimator/data slice.\n        \"\"\"  # noqa: E501\n        return self._transform(X, \"predict\")", "metadata": {}}
{"_id": "mne_mne_decoding/search_light.py_predict_proba_code", "title": "predict_proba", "text": "def predict_proba(self, X):\n        \"\"\"Predict each data slice with a series of independent estimators.\n\n        The number of tasks in X should match the number of tasks/estimators\n        given at fit time.\n\n        Parameters\n        ----------\n        X : array, shape (n_samples, nd_features, n_tasks)\n            The input samples. For each data slice, the corresponding estimator\n            makes the sample probabilistic predictions, e.g.:\n            ``[estimators[ii].predict_proba(X[..., ii]) for ii in range(n_estimators)]``.\n            The feature dimension can be multidimensional e.g.\n            X.shape = (n_samples, n_features_1, n_features_2, n_tasks).\n\n        Returns\n        -------\n        y_pred : array, shape (n_samples, n_tasks, n_classes)\n            Predicted probabilities for each estimator/data slice/task.\n        \"\"\"  # noqa: E501\n        return self._transform(X, \"predict_proba\")", "metadata": {}}
{"_id": "mne_mne_decoding/search_light.py_decision_function_code", "title": "decision_function", "text": "def decision_function(self, X):\n        \"\"\"Estimate distances of each data slice to the hyperplanes.\n\n        Parameters\n        ----------\n        X : array, shape (n_samples, nd_features, n_tasks)\n            The input samples. For each data slice, the corresponding estimator\n            outputs the distance to the hyperplane, e.g.:\n            ``[estimators[ii].decision_function(X[..., ii]) for ii in range(n_estimators)]``.\n            The feature dimension can be multidimensional e.g.\n            X.shape = (n_samples, n_features_1, n_features_2, n_estimators).\n\n        Returns\n        -------\n        y_pred : array, shape (n_samples, n_estimators, n_classes * (n_classes-1) // 2)\n            Predicted distances for each estimator/data slice.\n\n        Notes\n        -----\n        This requires base_estimator to have a ``decision_function`` method.\n        \"\"\"  # noqa: E501\n        return self._transform(X, \"decision_function\")", "metadata": {}}
{"_id": "mne_mne_decoding/search_light.py_score_code", "title": "score", "text": "def score(self, X, y):\n        \"\"\"Score each estimator on each task.\n\n        The number of tasks in X should match the number of tasks/estimators\n        given at fit time, i.e. we need\n        ``X.shape[-1] == len(self.estimators_)``.\n\n        Parameters\n        ----------\n        X : array, shape (n_samples, nd_features, n_tasks)\n            The input samples. For each data slice, the corresponding estimator\n            scores the prediction, e.g.:\n            ``[estimators[ii].score(X[..., ii], y) for ii in range(n_estimators)]``.\n            The feature dimension can be multidimensional e.g.\n            X.shape = (n_samples, n_features_1, n_features_2, n_tasks).\n        y : array, shape (n_samples,) | (n_samples, n_targets)\n            The target values.\n\n        Returns\n        -------\n        score : array, shape (n_samples, n_estimators)\n            Score for each estimator/task.\n        \"\"\"  # noqa: E501\n        X, _ = self._check_Xy(X, y)\n        if X.shape[-1] != len(self.estimators_):\n            raise ValueError(\"The number of estimators does not match X.shape[-1]\")\n\n        scoring = check_scoring(self.base_estimator, self.scoring)\n        y = _fix_auc(scoring, y)\n\n        # For predictions/transforms the parallelization is across the data and\n        # not across the estimators to avoid memory load.\n        parallel, p_func, n_jobs = parallel_func(\n            _sl_score,\n            self.n_jobs,\n            max_jobs=X.shape[-1],\n            verbose=_verbose_safe_false(),\n        )\n        X_splits = np.array_split(X, n_jobs, axis=-1)\n        est_splits = np.array_split(self.estimators_, n_jobs)\n        score = parallel(\n            p_func(est, scoring, x, y) for (est, x) in zip(est_splits, X_splits)\n        )\n\n        score = np.concatenate(score, axis=0)\n        return score", "metadata": {}}
{"_id": "mne_mne_decoding/search_light.py_transform_code", "title": "transform", "text": "def transform(self, X):\n        \"\"\"Transform each data slice with all possible estimators.\n\n        Parameters\n        ----------\n        X : array, shape (n_samples, nd_features, n_slices)\n            The input samples. For estimator the corresponding data slice is\n            used to make a transformation. The feature dimension can be\n            multidimensional e.g.\n            X.shape = (n_samples, n_features_1, n_features_2, n_estimators).\n\n        Returns\n        -------\n        Xt : array, shape (n_samples, n_estimators, n_slices)\n            The transformed values generated by each estimator.\n        \"\"\"\n        check_is_fitted(self)\n        return self._transform(X, \"transform\")", "metadata": {}}
{"_id": "mne_mne_decoding/search_light.py_predict_code", "title": "predict", "text": "def predict(self, X):\n        \"\"\"Predict each data slice with all possible estimators.\n\n        Parameters\n        ----------\n        X : array, shape (n_samples, nd_features, n_slices)\n            The training input samples. For each data slice, a fitted estimator\n            predicts each slice of the data independently. The feature\n            dimension can be multidimensional e.g.\n            X.shape = (n_samples, n_features_1, n_features_2, n_estimators).\n\n        Returns\n        -------\n        y_pred : array, shape (n_samples, n_estimators, n_slices) | (n_samples, n_estimators, n_slices, n_targets)\n            The predicted values for each estimator.\n        \"\"\"  # noqa: E501\n        return self._transform(X, \"predict\")", "metadata": {}}
{"_id": "mne_mne_decoding/search_light.py_predict_proba_code", "title": "predict_proba", "text": "def predict_proba(self, X):\n        \"\"\"Estimate probabilistic estimates of each data slice with all possible estimators.\n\n        Parameters\n        ----------\n        X : array, shape (n_samples, nd_features, n_slices)\n            The training input samples. For each data slice, a fitted estimator\n            predicts a slice of the data. The feature dimension can be\n            multidimensional e.g.\n            ``X.shape = (n_samples, n_features_1, n_features_2, n_estimators)``.\n\n        Returns\n        -------\n        y_pred : array, shape (n_samples, n_estimators, n_slices, n_classes)\n            The predicted values for each estimator.\n\n        Notes\n        -----\n        This requires ``base_estimator`` to have a ``predict_proba`` method.\n        \"\"\"  # noqa: E501\n        return self._transform(X, \"predict_proba\")", "metadata": {}}
{"_id": "mne_mne_decoding/search_light.py_decision_function_code", "title": "decision_function", "text": "def decision_function(self, X):\n        \"\"\"Estimate distances of each data slice to all hyperplanes.\n\n        Parameters\n        ----------\n        X : array, shape (n_samples, nd_features, n_slices)\n            The training input samples. Each estimator outputs the distance to\n            its hyperplane, e.g.:\n            ``[estimators[ii].decision_function(X[..., ii]) for ii in range(n_estimators)]``.\n            The feature dimension can be multidimensional e.g.\n            ``X.shape = (n_samples, n_features_1, n_features_2, n_estimators)``.\n\n        Returns\n        -------\n        y_pred : array, shape (n_samples, n_estimators, n_slices, n_classes * (n_classes-1) // 2)\n            The predicted values for each estimator.\n\n        Notes\n        -----\n        This requires ``base_estimator`` to have a ``decision_function``\n        method.\n        \"\"\"  # noqa: E501\n        return self._transform(X, \"decision_function\")", "metadata": {}}
{"_id": "mne_mne_decoding/search_light.py_score_code", "title": "score", "text": "def score(self, X, y):\n        \"\"\"Score each of the estimators on the tested dimensions.\n\n        Parameters\n        ----------\n        X : array, shape (n_samples, nd_features, n_slices)\n            The input samples. For each data slice, the corresponding estimator\n            scores the prediction, e.g.:\n            ``[estimators[ii].score(X[..., ii], y) for ii in range(n_slices)]``.\n            The feature dimension can be multidimensional e.g.\n            ``X.shape = (n_samples, n_features_1, n_features_2, n_estimators)``.\n        y : array, shape (n_samples,) | (n_samples, n_targets)\n            The target values.\n\n        Returns\n        -------\n        score : array, shape (n_samples, n_estimators, n_slices)\n            Score for each estimator / data slice couple.\n        \"\"\"  # noqa: E501\n        X, _ = self._check_Xy(X, y)\n        # For predictions/transforms the parallelization is across the data and\n        # not across the estimators to avoid memory load.\n        parallel, p_func, n_jobs = parallel_func(\n            _gl_score,\n            self.n_jobs,\n            max_jobs=X.shape[-1],\n            verbose=_verbose_safe_false(),\n        )\n        scoring = check_scoring(self.base_estimator, self.scoring)\n        y = _fix_auc(scoring, y)\n\n        context = _create_progressbar_context(self, X, \"Scoring\")\n        with context as pb:\n            score = parallel(\n                p_func(self.estimators_, scoring, x, y, pb.subset(pb_idx))\n                for pb_idx, x in array_split_idx(\n                    X, n_jobs, axis=-1, n_per_split=len(self.estimators_)\n                )\n            )\n\n        score = np.concatenate(score, axis=1)\n        return score", "metadata": {}}
{"_id": "mne_mne_decoding/ems.py_compute_ems_code", "title": "compute_ems", "text": "def compute_ems(\n    epochs, conditions=None, picks=None, n_jobs=None, cv=None, *, verbose=None\n):\n    \"\"\"Compute event-matched spatial filter on epochs.\n\n    This version of EMS :footcite:`SchurgerEtAl2013` operates on the entire\n    time course. No time\n    window needs to be specified. The result is a spatial filter at each\n    time point and a corresponding time course. Intuitively, the result\n    gives the similarity between the filter at each time point and the\n    data vector (sensors) at that time point.\n\n    .. note : EMS only works for binary classification.\n\n    .. note : The present function applies a leave-one-out cross-validation,\n              following Schurger et al's paper. However, we recommend using\n              a stratified k-fold cross-validation. Indeed, leave-one-out tends\n              to overfit and cannot be used to estimate the variance of the\n              prediction within a given fold.\n\n    .. note : Because of the leave-one-out, this function needs an equal\n              number of epochs in each of the two conditions.\n\n    Parameters\n    ----------\n    epochs : instance of mne.Epochs\n        The epochs.\n    conditions : list of str | None, default None\n        If a list of strings, strings must match the epochs.event_id's key as\n        well as the number of conditions supported by the objective_function.\n        If None keys in epochs.event_id are used.\n    %(picks_good_data)s\n    %(n_jobs)s\n    cv : cross-validation object | str | None, default LeaveOneOut\n        The cross-validation scheme.\n    %(verbose)s\n\n    Returns\n    -------\n    surrogate_trials : ndarray, shape (n_trials // 2, n_times)\n        The trial surrogates.\n    mean_spatial_filter : ndarray, shape (n_channels, n_times)\n        The set of spatial filters.\n    conditions : ndarray, shape (n_classes,)\n        The conditions used. Values correspond to original event ids.\n\n    References\n    ----------\n    .. footbibliography::\n    \"\"\"\n    logger.info(\"...computing surrogate time series. This can take some time\")\n\n    # Default to leave-one-out cv\n    cv = \"LeaveOneOut\" if cv is None else cv\n    picks = _picks_to_idx(epochs.info, picks)\n\n    if not len(set(Counter(epochs.events[:, 2]).values())) == 1:\n        raise ValueError(\n            \"The same number of epochs is required by \"\n            \"this function. Please consider \"\n            \"`epochs.equalize_event_counts`\"\n        )\n\n    if conditions is None:\n        conditions = epochs.event_id.keys()\n        epochs = epochs.copy()\n    else:\n        epochs = epochs[conditions]\n\n    epochs.drop_bad()\n\n    if len(conditions) != 2:\n        raise ValueError(\n            \"Currently this function expects exactly 2 \"\n            f\"conditions but you gave me {len(conditions)}\"\n        )\n\n    ev = epochs.events[:, 2]\n    # Special care to avoid path dependent mappings and orders\n    conditions = list(sorted(conditions))\n    cond_idx = [np.where(ev == epochs.event_id[k])[0] for k in conditions]\n\n    info = pick_info(epochs.info, picks)\n    data = epochs.get_data(picks=picks)\n\n    # Scale (z-score) the data by channel type\n    # XXX the z-scoring is applied outside the CV, which is not standard.\n    for ch_type in [\"mag\", \"grad\", \"eeg\"]:\n        if ch_type in epochs:\n            # FIXME should be applied to all sort of data channels\n            if ch_type == \"eeg\":\n                this_picks = pick_types(info, meg=False, eeg=True)\n            else:\n                this_picks = pick_types(info, meg=ch_type, eeg=False)\n            data[:, this_picks] /= np.std(data[:, this_picks])\n\n    # Setup cross-validation. Need to use _set_cv to deal with sklearn\n    # changes in cv object handling.\n    y = epochs.events[:, 2]\n    _, cv_splits = _set_cv(cv, \"classifier\", X=y, y=y)\n\n    parallel, p_func, n_jobs = parallel_func(_run_ems, n_jobs=n_jobs)\n    # FIXME this parallelization should be removed.\n    #   1) it's numpy computation so it's already efficient,\n    #   2) it duplicates the data in RAM,\n    #   3) the computation is already super fast.\n    out = parallel(\n        p_func(_ems_diff, data, cond_idx, train, test) for train, test in cv_splits\n    )\n\n    surrogate_trials, spatial_filter = zip(*out)\n    surrogate_trials = np.array(surrogate_trials)\n    spatial_filter = np.mean(spatial_filter, axis=0)\n\n    return surrogate_trials, spatial_filter, epochs.events[:, 2]", "metadata": {}}
{"_id": "mne_mne_decoding/ems.py_fit_code", "title": "fit", "text": "def fit(self, X, y):\n        \"\"\"Fit the spatial filters.\n\n        .. note : EMS is fitted on data normalized by channel type before the\n                  fitting of the spatial filters.\n\n        Parameters\n        ----------\n        X : array, shape (n_epochs, n_channels, n_times)\n            The training data.\n        y : array of int, shape (n_epochs)\n            The target classes.\n\n        Returns\n        -------\n        self : instance of EMS\n            Returns self.\n        \"\"\"\n        X, y = self._check_data(X, y=y, fit=True, return_y=True)\n        classes, y = np.unique(y, return_inverse=True)\n        if len(classes) > 2:\n            raise ValueError(\"EMS only works for binary classification.\")\n        self.classes_ = classes\n        filters = X[y == 0].mean(0) - X[y == 1].mean(0)\n        filters /= np.linalg.norm(filters, axis=0)[None, :]\n        self.filters_ = filters\n        return self", "metadata": {}}
{"_id": "mne_mne_decoding/ems.py_transform_code", "title": "transform", "text": "def transform(self, X):\n        \"\"\"Transform the data by the spatial filters.\n\n        Parameters\n        ----------\n        X : array, shape (n_epochs, n_channels, n_times)\n            The input data.\n\n        Returns\n        -------\n        X : array, shape (n_epochs, n_times)\n            The input data transformed by the spatial filters.\n        \"\"\"\n        X = self._check_data(X)\n        Xt = np.sum(X * self.filters_, axis=1)\n        return Xt", "metadata": {}}
{"_id": "mne_mne_decoding/time_delaying_ridge.py_fit_code", "title": "fit", "text": "def fit(self, X, y):\n        \"\"\"Estimate the coefficients of the linear model.\n\n        Parameters\n        ----------\n        X : array, shape (n_samples[, n_epochs], n_features)\n            The training input samples to estimate the linear coefficients.\n        y : array, shape (n_samples[, n_epochs],  n_outputs)\n            The target values.\n\n        Returns\n        -------\n        self : instance of TimeDelayingRidge\n            Returns the modified instance.\n        \"\"\"\n        _validate_type(X, \"array-like\", \"X\")\n        _validate_type(y, \"array-like\", \"y\")\n        self.tmin_ = float(self.tmin)\n        self.tmax_ = float(self.tmax)\n        self.sfreq_ = float(self.sfreq)\n        self.alpha_ = float(self.alpha)\n        if self.tmin_ > self.tmax_:\n            raise ValueError(f\"tmin must be <= tmax, got {self.tmin_} and {self.tmax_}\")\n        X = np.asarray(X, dtype=float)\n        y = np.asarray(y, dtype=float)\n        if X.ndim == 3:\n            assert y.ndim == 3\n            assert X.shape[:2] == y.shape[:2]\n        else:\n            if X.ndim == 1:\n                X = X[:, np.newaxis]\n            if y.ndim == 1:\n                y = y[:, np.newaxis]\n            assert X.ndim == 2\n            assert y.ndim == 2\n        _check_option(\"y.shape[0]\", y.shape[0], (X.shape[0],))\n        # These are split into two functions because it's possible that we\n        # might want to allow people to do them separately (e.g., to test\n        # different regularization parameters).\n        self.cov_, x_y_, n_ch_x, X_offset, y_offset = _compute_corrs(\n            X,\n            y,\n            self._smin,\n            self._smax,\n            self.n_jobs,\n            self.fit_intercept,\n            self.edge_correction,\n        )\n        self.coef_ = _fit_corrs(\n            self.cov_, x_y_, n_ch_x, self.reg_type, self.alpha_, n_ch_x\n        )\n        # This is the sklearn formula from LinearModel (will be 0. for no fit)\n        if self.fit_intercept:\n            self.intercept_ = y_offset - np.dot(X_offset, self.coef_.sum(-1).T)\n        else:\n            self.intercept_ = 0.0\n        return self", "metadata": {}}
{"_id": "mne_mne_decoding/time_delaying_ridge.py_predict_code", "title": "predict", "text": "def predict(self, X):\n        \"\"\"Predict the output.\n\n        Parameters\n        ----------\n        X : array, shape (n_samples[, n_epochs], n_features)\n            The data.\n\n        Returns\n        -------\n        X : ndarray\n            The predicted response.\n        \"\"\"\n        if X.ndim == 2:\n            X = X[:, np.newaxis, :]\n            singleton = True\n        else:\n            singleton = False\n        out = np.zeros(X.shape[:2] + (self.coef_.shape[0],))\n        smin = self._smin\n        offset = max(smin, 0)\n        for ei in range(X.shape[1]):\n            for oi in range(self.coef_.shape[0]):\n                for fi in range(self.coef_.shape[1]):\n                    temp = fftconvolve(X[:, ei, fi], self.coef_[oi, fi])\n                    temp = temp[max(-smin, 0) :][: len(out) - offset]\n                    out[offset : len(temp) + offset, ei, oi] += temp\n        out += self.intercept_\n        if singleton:\n            out = out[:, 0, :]\n        return out", "metadata": {}}
{"_id": "mne_mne_decoding/base.py_get_coef_code", "title": "get_coef", "text": "def get_coef(estimator, attr=\"filters_\", inverse_transform=False, *, verbose=None):\n    \"\"\"Retrieve the coefficients of an estimator ending with a Linear Model.\n\n    This is typically useful to retrieve \"spatial filters\" or \"spatial\n    patterns\" of decoding models :footcite:`HaufeEtAl2014`.\n\n    Parameters\n    ----------\n    estimator : object | None\n        An estimator from scikit-learn.\n    attr : str\n        The name of the coefficient attribute to retrieve, typically\n        ``'filters_'`` (default) or ``'patterns_'``.\n    inverse_transform : bool\n        If True, returns the coefficients after inverse transforming them with\n        the transformer steps of the estimator.\n    %(verbose)s\n\n    Returns\n    -------\n    coef : array\n        The coefficients.\n\n    References\n    ----------\n    .. footbibliography::\n    \"\"\"\n    # Get the coefficients of the last estimator in case of nested pipeline\n    est = estimator\n    logger.debug(f\"Getting coefficients from estimator: {est.__class__.__name__}\")\n    while hasattr(est, \"steps\"):\n        est = est.steps[-1][1]\n\n    squeeze_first_dim = False\n\n    # If SlidingEstimator, loop across estimators\n    if hasattr(est, \"estimators_\"):\n        coef = list()\n        for ei, this_est in enumerate(est.estimators_):\n            if ei == 0:\n                logger.debug(\"  Extracting coefficients from SlidingEstimator.\")\n            coef.append(get_coef(this_est, attr, inverse_transform))\n        coef = np.transpose(coef)\n        coef = coef[np.newaxis]  # fake a sample dimension\n        squeeze_first_dim = True\n    elif not hasattr(est, attr):\n        raise ValueError(f\"This estimator does not have a {attr} attribute:\\n{est}\")\n    else:\n        coef = getattr(est, attr)\n\n    if coef.ndim == 1:\n        coef = coef[np.newaxis]\n        squeeze_first_dim = True\n\n    # inverse pattern e.g. to get back physical units\n    if inverse_transform:\n        if not hasattr(estimator, \"steps\") and not hasattr(est, \"estimators_\"):\n            raise ValueError(\n                \"inverse_transform can only be applied onto pipeline estimators.\"\n            )\n        # The inverse_transform parameter will call this method on any\n        # estimator contained in the pipeline, in reverse order.\n        for inverse_func in _get_inverse_funcs(estimator)[::-1]:\n            logger.debug(f\"  Applying inverse transformation: {inverse_func}.\")\n            coef = inverse_func(coef)\n\n    if squeeze_first_dim:\n        logger.debug(\"  Squeezing first dimension of coefficients.\")\n        coef = coef[0]\n\n    return coef", "metadata": {}}
{"_id": "mne_mne_decoding/base.py_cross_val_multiscore_code", "title": "cross_val_multiscore", "text": "def cross_val_multiscore(\n    estimator,\n    X,\n    y=None,\n    groups=None,\n    scoring=None,\n    cv=None,\n    n_jobs=None,\n    verbose=None,\n    fit_params=None,\n    pre_dispatch=\"2*n_jobs\",\n):\n    \"\"\"Evaluate a score by cross-validation.\n\n    Parameters\n    ----------\n    estimator : instance of sklearn.base.BaseEstimator\n        The object to use to fit the data.\n        Must implement the 'fit' method.\n    X : array-like, shape (n_samples, n_dimensional_features,)\n        The data to fit. Can be, for example a list, or an array at least 2d.\n    y : array-like, shape (n_samples, n_targets,)\n        The target variable to try to predict in the case of\n        supervised learning.\n    groups : array-like, with shape (n_samples,)\n        Group labels for the samples used while splitting the dataset into\n        train/test set.\n    scoring : str, callable | None\n        A string (see model evaluation documentation) or\n        a scorer callable object / function with signature\n        ``scorer(estimator, X, y)``.\n        Note that when using an estimator which inherently returns\n        multidimensional output - in particular, SlidingEstimator\n        or GeneralizingEstimator - you should set the scorer\n        there, not here.\n    cv : int, cross-validation generator | iterable\n        Determines the cross-validation splitting strategy.\n        Possible inputs for cv are:\n\n        - None, to use the default 5-fold cross validation,\n        - integer, to specify the number of folds in a ``(Stratified)KFold``,\n        - An object to be used as a cross-validation generator.\n        - An iterable yielding train, test splits.\n\n        For integer/None inputs, if the estimator is a classifier and ``y`` is\n        either binary or multiclass,\n        :class:`sklearn.model_selection.StratifiedKFold` is used. In all\n        other cases, :class:`sklearn.model_selection.KFold` is used.\n    %(n_jobs)s\n    %(verbose)s\n    fit_params : dict, optional\n        Parameters to pass to the fit method of the estimator.\n    pre_dispatch : int, or str, optional\n        Controls the number of jobs that get dispatched during parallel\n        execution. Reducing this number can be useful to avoid an\n        explosion of memory consumption when more jobs get dispatched\n        than CPUs can process. This parameter can be:\n\n        - None, in which case all the jobs are immediately\n          created and spawned. Use this for lightweight and\n          fast-running jobs, to avoid delays due to on-demand\n          spawning of the jobs\n        - An int, giving the exact number of total jobs that are\n          spawned\n        - A string, giving an expression as a function of n_jobs,\n          as in '2*n_jobs'\n\n    Returns\n    -------\n    scores : array of float, shape (n_splits,) | shape (n_splits, n_scores)\n        Array of scores of the estimator for each run of the cross validation.\n    \"\"\"\n    # This code is copied from sklearn\n    X, y, groups = indexable(X, y, groups)\n\n    cv = check_cv(cv, y, classifier=is_classifier(estimator))\n    cv_iter = list(cv.split(X, y, groups))\n    scorer = check_scoring(estimator, scoring=scoring)\n    # We clone the estimator to make sure that all the folds are\n    # independent, and that it is pickle-able.\n    # Note: this parallelization is implemented using MNE Parallel\n    parallel, p_func, n_jobs = parallel_func(\n        _fit_and_score, n_jobs, pre_dispatch=pre_dispatch\n    )\n    position = hasattr(estimator, \"position\")\n    scores = parallel(\n        p_func(\n            estimator=clone(estimator),\n            X=X,\n            y=y,\n            scorer=scorer,\n            train=train,\n            test=test,\n            fit_params=fit_params,\n            verbose=verbose,\n            parameters=dict(position=ii % n_jobs) if position else None,\n        )\n        for ii, (train, test) in enumerate(cv_iter)\n    )\n    return np.array(scores)[:, 0, ...]", "metadata": {}}
{"_id": "mne_mne_decoding/base.py_fit_code", "title": "fit", "text": "def fit(self, X, y, **fit_params):\n        \"\"\"Estimate the coefficients of the linear model.\n\n        Save the coefficients in the attribute ``filters_`` and\n        computes the attribute ``patterns_``.\n\n        Parameters\n        ----------\n        X : array, shape (n_samples, n_features)\n            The training input samples to estimate the linear coefficients.\n        y : array, shape (n_samples, [n_targets])\n            The target values.\n        **fit_params : dict of string -> object\n            Parameters to pass to the fit method of the estimator.\n\n        Returns\n        -------\n        self : instance of LinearModel\n            Returns the modified instance.\n        \"\"\"\n        if y is not None:\n            X = check_array(X)\n        else:\n            X, y = check_X_y(X, y)\n        self.n_features_in_ = X.shape[1]\n        if y is not None:\n            y = check_array(y, dtype=None, ensure_2d=False, input_name=\"y\")\n            if y.ndim > 2:\n                raise ValueError(\n                    f\"LinearModel only accepts up to 2-dimensional y, got {y.shape} \"\n                    \"instead.\"\n                )\n\n        # fit the Model\n        self.model.fit(X, y, **fit_params)\n        self.model_ = self.model  # for better sklearn compat\n\n        # Computes patterns using Haufe's trick: A = Cov_X . W . Precision_Y\n\n        inv_Y = 1.0\n        X = X - X.mean(0, keepdims=True)\n        if y.ndim == 2 and y.shape[1] != 1:\n            y = y - y.mean(0, keepdims=True)\n            inv_Y = np.linalg.pinv(np.cov(y.T))\n        self.patterns_ = np.cov(X.T).dot(self.filters_.T.dot(inv_Y)).T\n\n        return self", "metadata": {}}
{"_id": "mne_mne_decoding/ssd.py_fit_code", "title": "fit", "text": "def fit(self, X, y=None):\n        \"\"\"Estimate the SSD decomposition on raw or epoched data.\n\n        Parameters\n        ----------\n        X : array, shape ([n_epochs, ]n_channels, n_times)\n            The input data from which to estimate the SSD. Either 2D array\n            obtained from continuous data or 3D array obtained from epoched\n            data.\n        y : None\n            Ignored; exists for compatibility with scikit-learn pipelines.\n\n        Returns\n        -------\n        self : instance of SSD\n            Returns the modified instance.\n        \"\"\"\n        X = self._check_X(X, y=y, fit=True)\n        self._validate_params(X)\n        if isinstance(self.info, Info):\n            info = self.info\n        else:\n            info = create_info(X.shape[-2], self.sfreq_, ch_types=\"eeg\")\n        self.picks_ = _picks_to_idx(info, self.picks, none=\"data\", exclude=\"bads\")\n        X_aux = X[..., self.picks_, :]\n\n        X_signal = filter_data(X_aux, self.sfreq_, **self.filt_params_signal)\n        X_noise = filter_data(X_aux, self.sfreq_, **self.filt_params_noise)\n        X_noise -= X_signal\n        if X.ndim == 3:\n            X_signal = np.hstack(X_signal)\n            X_noise = np.hstack(X_noise)\n\n        # prevent rank change when computing cov with rank='full'\n        cov_signal = _regularized_covariance(\n            X_signal,\n            reg=self.reg,\n            method_params=self.cov_method_params,\n            rank=\"full\",\n            info=info,\n        )\n        cov_noise = _regularized_covariance(\n            X_noise,\n            reg=self.reg,\n            method_params=self.cov_method_params,\n            rank=\"full\",\n            info=info,\n        )\n\n        # project cov to rank subspace\n        cov_signal, cov_noise, rank_proj = _dimensionality_reduction(\n            cov_signal, cov_noise, info, self.rank\n        )\n\n        eigvals_, eigvects_ = eigh(cov_signal, cov_noise)\n        # sort in descending order\n        ix = np.argsort(eigvals_)[::-1]\n        self.eigvals_ = eigvals_[ix]\n        # project back to sensor space\n        self.filters_ = np.matmul(rank_proj, eigvects_[:, ix])\n        self.patterns_ = np.linalg.pinv(self.filters_)\n\n        # We assume that ordering by spectral ratio is more important\n        # than the initial ordering. This ordering should be also learned when\n        # fitting.\n        X_ssd = self.filters_.T @ X[..., self.picks_, :]\n        sorter_spec = slice(None)\n        if self.sort_by_spectral_ratio:\n            _, sorter_spec = self.get_spectral_ratio(ssd_sources=X_ssd)\n        self.sorter_spec_ = sorter_spec\n        logger.info(\"Done.\")\n        return self", "metadata": {}}
{"_id": "mne_mne_decoding/ssd.py_transform_code", "title": "transform", "text": "def transform(self, X):\n        \"\"\"Estimate epochs sources given the SSD filters.\n\n        Parameters\n        ----------\n        X : array, shape ([n_epochs, ]n_channels, n_times)\n            The input data from which to estimate the SSD. Either 2D array\n            obtained from continuous data or 3D array obtained from epoched\n            data.\n\n        Returns\n        -------\n        X_ssd : array, shape ([n_epochs, ]n_components, n_times)\n            The processed data.\n        \"\"\"\n        check_is_fitted(self, \"filters_\")\n        X = self._check_X(X)\n        if self.return_filtered:\n            X_aux = X[..., self.picks_, :]\n            X = filter_data(X_aux, self.sfreq_, **self.filt_params_signal)\n        X_ssd = self.filters_.T @ X[..., self.picks_, :]\n        X_ssd = X_ssd[..., self.sorter_spec_, :][..., : self.n_components, :]\n        return X_ssd", "metadata": {}}
{"_id": "mne_mne_decoding/ssd.py_fit_transform_code", "title": "fit_transform", "text": "def fit_transform(self, X, y=None, **fit_params):\n        \"\"\"Fit SSD to data, then transform it.\n\n        Fits transformer to ``X`` and ``y`` with optional parameters ``fit_params``, and\n        returns a transformed version of ``X``.\n\n        Parameters\n        ----------\n        X : array, shape ([n_epochs, ]n_channels, n_times)\n            The input data from which to estimate the SSD. Either 2D array obtained from\n            continuous data or 3D array obtained from epoched data.\n        y : None\n            Ignored; exists for compatibility with scikit-learn pipelines.\n        **fit_params : dict\n            Additional fitting parameters passed to the :meth:`mne.decoding.SSD.fit`\n            method. Not used for this class.\n\n        Returns\n        -------\n        X_ssd : array, shape ([n_epochs, ]n_components, n_times)\n            The processed data.\n        \"\"\"\n        # use parent TransformerMixin method but with custom docstring\n        return super().fit_transform(X, y=y, **fit_params)", "metadata": {}}
{"_id": "mne_mne_decoding/ssd.py_get_spectral_ratio_code", "title": "get_spectral_ratio", "text": "def get_spectral_ratio(self, ssd_sources):\n        \"\"\"Get the spectal signal-to-noise ratio for each spatial filter.\n\n        Spectral ratio measure for best n_components selection\n        See :footcite:`NikulinEtAl2011`, Eq. (24).\n\n        Parameters\n        ----------\n        ssd_sources : array\n            Data projected to SSD space.\n\n        Returns\n        -------\n        spec_ratio : array, shape (n_channels)\n            Array with the sprectal ratio value for each component.\n        sorter_spec : array, shape (n_channels)\n            Array of indices for sorting spec_ratio.\n\n        References\n        ----------\n        .. footbibliography::\n        \"\"\"\n        psd, freqs = psd_array_welch(ssd_sources, sfreq=self.sfreq_, n_fft=self.n_fft_)\n        sig_idx = _time_mask(freqs, *self.freqs_signal_)\n        noise_idx = _time_mask(freqs, *self.freqs_noise_)\n        if psd.ndim == 3:\n            mean_sig = psd[:, :, sig_idx].mean(axis=2).mean(axis=0)\n            mean_noise = psd[:, :, noise_idx].mean(axis=2).mean(axis=0)\n            spec_ratio = mean_sig / mean_noise\n        else:\n            mean_sig = psd[:, sig_idx].mean(axis=1)\n            mean_noise = psd[:, noise_idx].mean(axis=1)\n            spec_ratio = mean_sig / mean_noise\n        sorter_spec = spec_ratio.argsort()[::-1]\n        return spec_ratio, sorter_spec", "metadata": {}}
{"_id": "mne_mne_decoding/ssd.py_inverse_transform_code", "title": "inverse_transform", "text": "def inverse_transform(self):\n        \"\"\"Not implemented yet.\"\"\"\n        raise NotImplementedError(\"inverse_transform is not yet available.\")", "metadata": {}}
{"_id": "mne_mne_decoding/ssd.py_apply_code", "title": "apply", "text": "def apply(self, X):\n        \"\"\"Remove selected components from the signal.\n\n        This procedure will reconstruct M/EEG signals from which the dynamics\n        described by the excluded components is subtracted\n        (denoised by low-rank factorization).\n        See :footcite:`HaufeEtAl2014b` for more information.\n\n        .. note:: Unlike in other classes with an apply method,\n           only NumPy arrays are supported (not instances of MNE objects).\n\n        Parameters\n        ----------\n        X : array, shape ([n_epochs, ]n_channels, n_times)\n            The input data from which to estimate the SSD. Either 2D array\n            obtained from continuous data or 3D array obtained from epoched\n            data.\n\n        Returns\n        -------\n        X : array, shape ([n_epochs, ]n_channels, n_times)\n            The processed data.\n        \"\"\"\n        X_ssd = self.transform(X)\n        pick_patterns = self.patterns_[self.sorter_spec_][: self.n_components].T\n        X = pick_patterns @ X_ssd\n        return X", "metadata": {}}
{"_id": "mne_mne_decoding/transformer.py_fit_code", "title": "fit", "text": "def fit(self, epochs_data, y=None):\n        \"\"\"Standardize data across channels.\n\n        Parameters\n        ----------\n        epochs_data : array, shape (n_epochs, n_channels, n_times)\n            The data to concatenate channels.\n        y : array, shape (n_epochs,)\n            The label for each epoch.\n\n        Returns\n        -------\n        self : instance of Scaler\n            The modified instance.\n        \"\"\"\n        epochs_data = self._check_data(epochs_data, y=y, fit=True, multi_output=True)\n        assert epochs_data.ndim == 3, epochs_data.shape\n\n        _validate_type(self.scalings, (dict, str, type(None)), \"scalings\")\n        if isinstance(self.scalings, str):\n            _check_option(\n                \"scalings\", self.scalings, [\"mean\", \"median\"], extra=\"when str\"\n            )\n        if self.scalings is None or isinstance(self.scalings, dict):\n            if self.info is None:\n                raise ValueError(\n                    f'Need to specify \"info\" if scalings is {type(self.scalings)}'\n                )\n            self.scaler_ = _ConstantScaler(self.info, self.scalings, self.with_std)\n        elif self.scalings == \"mean\":\n            self.scaler_ = StandardScaler(\n                with_mean=self.with_mean, with_std=self.with_std\n            )\n        else:  # scalings == 'median':\n            self.scaler_ = RobustScaler(\n                with_centering=self.with_mean, with_scaling=self.with_std\n            )\n\n        _sklearn_reshape_apply(self.scaler_.fit, False, epochs_data, y=y)\n        return self", "metadata": {}}
{"_id": "mne_mne_decoding/transformer.py_transform_code", "title": "transform", "text": "def transform(self, epochs_data):\n        \"\"\"Standardize data across channels.\n\n        Parameters\n        ----------\n        epochs_data : array, shape (n_epochs, n_channels[, n_times])\n            The data.\n\n        Returns\n        -------\n        X : array, shape (n_epochs, n_channels, n_times)\n            The data concatenated over channels.\n\n        Notes\n        -----\n        This function makes a copy of the data before the operations and the\n        memory usage may be large with big data.\n        \"\"\"\n        check_is_fitted(self, \"scaler_\")\n        epochs_data = self._check_data(epochs_data, atleast_3d=False)\n        if epochs_data.ndim == 2:  # can happen with SlidingEstimator\n            if self.info is not None:\n                assert len(self.info[\"ch_names\"]) == epochs_data.shape[1]\n            epochs_data = epochs_data[..., np.newaxis]\n        assert epochs_data.ndim == 3, epochs_data.shape\n        return _sklearn_reshape_apply(self.scaler_.transform, True, epochs_data)", "metadata": {}}
{"_id": "mne_mne_decoding/transformer.py_fit_transform_code", "title": "fit_transform", "text": "def fit_transform(self, epochs_data, y=None):\n        \"\"\"Fit to data, then transform it.\n\n        Fits transformer to epochs_data and y and returns a transformed version\n        of epochs_data.\n\n        Parameters\n        ----------\n        epochs_data : array, shape (n_epochs, n_channels, n_times)\n            The data.\n        y : None | array, shape (n_epochs,)\n            The label for each epoch.\n            Defaults to None.\n\n        Returns\n        -------\n        X : array, shape (n_epochs, n_channels, n_times)\n            The data concatenated over channels.\n\n        Notes\n        -----\n        This function makes a copy of the data before the operations and the\n        memory usage may be large with big data.\n        \"\"\"\n        return self.fit(epochs_data, y).transform(epochs_data)", "metadata": {}}
{"_id": "mne_mne_decoding/transformer.py_inverse_transform_code", "title": "inverse_transform", "text": "def inverse_transform(self, epochs_data):\n        \"\"\"Invert standardization of data across channels.\n\n        Parameters\n        ----------\n        epochs_data : array, shape ([n_epochs, ]n_channels, n_times)\n            The data.\n\n        Returns\n        -------\n        X : array, shape (n_epochs, n_channels, n_times)\n            The data concatenated over channels.\n\n        Notes\n        -----\n        This function makes a copy of the data before the operations and the\n        memory usage may be large with big data.\n        \"\"\"\n        epochs_data = self._check_data(epochs_data, atleast_3d=False)\n        squeeze = False\n        # Can happen with CSP\n        if epochs_data.ndim == 2:\n            squeeze = True\n            epochs_data = epochs_data[..., np.newaxis]\n        assert epochs_data.ndim == 3, epochs_data.shape\n        out = _sklearn_reshape_apply(self.scaler_.inverse_transform, True, epochs_data)\n        if squeeze:\n            out = out[..., 0]\n        return out", "metadata": {}}
{"_id": "mne_mne_decoding/transformer.py_fit_code", "title": "fit", "text": "def fit(self, X, y=None):\n        \"\"\"Store the shape of the features of X.\n\n        Parameters\n        ----------\n        X : array-like\n            The data to fit. Can be, for example a list, or an array of at\n            least 2d. The first dimension must be of length n_samples, where\n            samples are the independent samples used by the estimator\n            (e.g. n_epochs for epoched data).\n        y : None | array, shape (n_samples,)\n            Used for scikit-learn compatibility.\n\n        Returns\n        -------\n        self : instance of Vectorizer\n            Return the modified instance.\n        \"\"\"\n        X = self._check_data(X, y=y, atleast_3d=False, fit=True, check_n_features=False)\n        self.features_shape_ = X.shape[1:]\n        return self", "metadata": {}}
{"_id": "mne_mne_decoding/transformer.py_transform_code", "title": "transform", "text": "def transform(self, X):\n        \"\"\"Convert given array into two dimensions.\n\n        Parameters\n        ----------\n        X : array-like\n            The data to fit. Can be, for example a list, or an array of at\n            least 2d. The first dimension must be of length n_samples, where\n            samples are the independent samples used by the estimator\n            (e.g. n_epochs for epoched data).\n\n        Returns\n        -------\n        X : array, shape (n_samples, n_features)\n            The transformed data.\n        \"\"\"\n        X = self._check_data(X, atleast_3d=False)\n        if X.shape[1:] != self.features_shape_:\n            raise ValueError(\"Shape of X used in fit and transform must be same\")\n        return X.reshape(len(X), -1)", "metadata": {}}
{"_id": "mne_mne_decoding/transformer.py_fit_transform_code", "title": "fit_transform", "text": "def fit_transform(self, X, y=None):\n        \"\"\"Fit the data, then transform in one step.\n\n        Parameters\n        ----------\n        X : array-like\n            The data to fit. Can be, for example a list, or an array of at\n            least 2d. The first dimension must be of length n_samples, where\n            samples are the independent samples used by the estimator\n            (e.g. n_epochs for epoched data).\n        y : None | array, shape (n_samples,)\n            Used for scikit-learn compatibility.\n\n        Returns\n        -------\n        X : array, shape (n_samples, -1)\n            The transformed data.\n        \"\"\"\n        return self.fit(X).transform(X)", "metadata": {}}
{"_id": "mne_mne_decoding/transformer.py_inverse_transform_code", "title": "inverse_transform", "text": "def inverse_transform(self, X):\n        \"\"\"Transform 2D data back to its original feature shape.\n\n        Parameters\n        ----------\n        X : array-like, shape (n_samples,  n_features)\n            Data to be transformed back to original shape.\n\n        Returns\n        -------\n        X : array\n            The data transformed into shape as used in fit. The first\n            dimension is of length n_samples.\n        \"\"\"\n        X = self._check_data(X, atleast_3d=False, check_n_features=False)\n        if X.ndim not in (2, 3):\n            raise ValueError(\n                f\"X should be of 2 or 3 dimensions but has shape {X.shape}\"\n            )\n        return X.reshape(X.shape[:-1] + self.features_shape_)", "metadata": {}}
{"_id": "mne_mne_decoding/transformer.py_fit_code", "title": "fit", "text": "def fit(self, epochs_data, y=None):\n        \"\"\"Compute power spectral density (PSD) using a multi-taper method.\n\n        Parameters\n        ----------\n        epochs_data : array, shape (n_epochs, n_channels, n_times)\n            The data.\n        y : array, shape (n_epochs,)\n            The label for each epoch.\n\n        Returns\n        -------\n        self : instance of PSDEstimator\n            The modified instance.\n        \"\"\"\n        self._check_data(epochs_data, y=y, fit=True)\n        self.fitted_ = True  # sklearn compliance\n        return self", "metadata": {}}
{"_id": "mne_mne_decoding/transformer.py_transform_code", "title": "transform", "text": "def transform(self, epochs_data):\n        \"\"\"Compute power spectral density (PSD) using a multi-taper method.\n\n        Parameters\n        ----------\n        epochs_data : array, shape (n_epochs, n_channels, n_times)\n            The data.\n\n        Returns\n        -------\n        psd : array, shape (n_signals, n_freqs) or (n_freqs,)\n            The computed PSD.\n        \"\"\"\n        epochs_data = self._check_data(epochs_data)\n        psd, _ = psd_array_multitaper(\n            epochs_data,\n            sfreq=self.sfreq,\n            fmin=self.fmin,\n            fmax=self.fmax,\n            bandwidth=self.bandwidth,\n            adaptive=self.adaptive,\n            low_bias=self.low_bias,\n            normalization=self.normalization,\n            n_jobs=self.n_jobs,\n        )\n        return psd", "metadata": {}}
{"_id": "mne_mne_decoding/transformer.py_fit_code", "title": "fit", "text": "def fit(self, epochs_data, y):\n        \"\"\"Filter data.\n\n        Parameters\n        ----------\n        epochs_data : array, shape (n_epochs, n_channels, n_times)\n            The data.\n        y : array, shape (n_epochs,)\n            The label for each epoch.\n\n        Returns\n        -------\n        self : instance of FilterEstimator\n            The modified instance.\n        \"\"\"\n        self.picks_ = _picks_to_idx(self.info, self.picks)\n        self._check_data(epochs_data, y=y, fit=True)\n\n        if self.l_freq == 0:\n            self.l_freq = None\n\n        if self.info[\"lowpass\"] is None or (\n            self.h_freq is not None\n            and (self.l_freq is None or self.l_freq < self.h_freq)\n            and self.h_freq < self.info[\"lowpass\"]\n        ):\n            with self.info._unlock():\n                self.info[\"lowpass\"] = self.h_freq\n\n        if self.info[\"highpass\"] is None or (\n            self.l_freq is not None\n            and (self.h_freq is None or self.l_freq < self.h_freq)\n            and self.l_freq > self.info[\"highpass\"]\n        ):\n            with self.info._unlock():\n                self.info[\"highpass\"] = self.l_freq\n\n        return self", "metadata": {}}
{"_id": "mne_mne_decoding/transformer.py_transform_code", "title": "transform", "text": "def transform(self, epochs_data):\n        \"\"\"Filter data.\n\n        Parameters\n        ----------\n        epochs_data : array, shape (n_epochs, n_channels, n_times)\n            The data.\n\n        Returns\n        -------\n        X : array, shape (n_epochs, n_channels, n_times)\n            The data after filtering.\n        \"\"\"\n        return filter_data(\n            self._check_data(epochs_data),\n            self.info[\"sfreq\"],\n            self.l_freq,\n            self.h_freq,\n            self.picks_,\n            self.filter_length,\n            self.l_trans_bandwidth,\n            self.h_trans_bandwidth,\n            method=self.method,\n            iir_params=self.iir_params,\n            n_jobs=self.n_jobs,\n            copy=False,\n            fir_design=self.fir_design,\n            verbose=False,\n        )", "metadata": {}}
{"_id": "mne_mne_decoding/transformer.py_fit_code", "title": "fit", "text": "def fit(self, X, y=None):\n        \"\"\"Fit the spatial filters.\n\n        Parameters\n        ----------\n        X : array, shape (n_epochs, n_channels, n_times)\n            The data to be filtered.\n        y : None | array, shape (n_samples,)\n            Used for scikit-learn compatibility.\n\n        Returns\n        -------\n        self : instance of UnsupervisedSpatialFilter\n            Return the modified instance.\n        \"\"\"\n        # sklearn.utils.estimator_checks.check_estimator(self.estimator) is probably\n        # too strict for us, given that we don't fully adhere yet, so just check attrs\n        for attr in (\"fit\", \"transform\", \"fit_transform\"):\n            if not hasattr(self.estimator, attr):\n                raise ValueError(\n                    \"estimator must be a scikit-learn \"\n                    f\"transformer, missing {attr} method\"\n                )\n        _validate_type(self.average, bool, \"average\")\n        X = self._check_data(X, y=y, fit=True)\n        if self.average:\n            X = np.mean(X, axis=0).T\n        else:\n            n_epochs, n_channels, n_times = X.shape\n            # trial as time samples\n            X = np.transpose(X, (1, 0, 2)).reshape((n_channels, n_epochs * n_times)).T\n\n        self.estimator_ = clone(self.estimator)\n        self.estimator_.fit(X)\n        return self", "metadata": {}}
{"_id": "mne_mne_decoding/transformer.py_fit_transform_code", "title": "fit_transform", "text": "def fit_transform(self, X, y=None):\n        \"\"\"Transform the data to its filtered components after fitting.\n\n        Parameters\n        ----------\n        X : array, shape (n_epochs, n_channels, n_times)\n            The data to be filtered.\n        y : None | array, shape (n_samples,)\n            Used for scikit-learn compatibility.\n\n        Returns\n        -------\n        X : array, shape (n_epochs, n_channels, n_times)\n            The transformed data.\n        \"\"\"\n        return self.fit(X).transform(X)", "metadata": {}}
{"_id": "mne_mne_decoding/transformer.py_transform_code", "title": "transform", "text": "def transform(self, X):\n        \"\"\"Transform the data to its spatial filters.\n\n        Parameters\n        ----------\n        X : array, shape (n_epochs, n_channels, n_times)\n            The data to be filtered.\n\n        Returns\n        -------\n        X : array, shape (n_epochs, n_channels, n_times)\n            The transformed data.\n        \"\"\"\n        check_is_fitted(self.estimator_)\n        X = self._check_data(X)\n        return self._apply_method(X, \"transform\")", "metadata": {}}
{"_id": "mne_mne_decoding/transformer.py_inverse_transform_code", "title": "inverse_transform", "text": "def inverse_transform(self, X):\n        \"\"\"Inverse transform the data to its original space.\n\n        Parameters\n        ----------\n        X : array, shape (n_epochs, n_components, n_times)\n            The data to be inverted.\n\n        Returns\n        -------\n        X : array, shape (n_epochs, n_channels, n_times)\n            The transformed data.\n        \"\"\"\n        return self._apply_method(X, \"inverse_transform\")", "metadata": {}}
{"_id": "mne_mne_decoding/transformer.py_fit_code", "title": "fit", "text": "def fit(self, X, y=None):\n        \"\"\"Do nothing (for scikit-learn compatibility purposes).\n\n        Parameters\n        ----------\n        X : array, shape ([n_epochs, ]n_channels, n_times)\n            The data to be filtered over the last dimension. The channels\n            dimension can be zero when passing a 2D array.\n        y : None\n            Not used, for scikit-learn compatibility issues.\n\n        Returns\n        -------\n        self : instance of TemporalFilter\n            The modified instance.\n        \"\"\"\n        self.fitted_ = True  # sklearn compliance\n        self._check_data(X, y=y, atleast_3d=False, fit=True)\n        return self", "metadata": {}}
{"_id": "mne_mne_decoding/transformer.py_transform_code", "title": "transform", "text": "def transform(self, X):\n        \"\"\"Filter data along the last dimension.\n\n        Parameters\n        ----------\n        X : array, shape ([n_epochs, ]n_channels, n_times)\n            The data to be filtered over the last dimension. The channels\n            dimension can be zero when passing a 2D array.\n\n        Returns\n        -------\n        X : array\n            The data after filtering.\n        \"\"\"  # noqa: E501\n        X = self._check_data(X, atleast_3d=False)\n        X = np.atleast_2d(X)\n\n        if X.ndim > 3:\n            raise ValueError(\n                \"Array must be of at max 3 dimensions instead \"\n                f\"got {X.ndim} dimensional matrix\"\n            )\n\n        shape = X.shape\n        X = X.reshape(-1, shape[-1])\n        X = filter_data(\n            X,\n            self.sfreq,\n            self.l_freq,\n            self.h_freq,\n            filter_length=self.filter_length,\n            l_trans_bandwidth=self.l_trans_bandwidth,\n            h_trans_bandwidth=self.h_trans_bandwidth,\n            n_jobs=self.n_jobs,\n            method=self.method,\n            iir_params=self.iir_params,\n            copy=False,\n            fir_window=self.fir_window,\n            fir_design=self.fir_design,\n        )\n        return X.reshape(shape)", "metadata": {}}
{"_id": "mne_mne_decoding/csp.py_fit_code", "title": "fit", "text": "def fit(self, X, y):\n        \"\"\"Estimate the CSP decomposition on epochs.\n\n        Parameters\n        ----------\n        X : ndarray, shape (n_epochs, n_channels, n_times)\n            The data on which to estimate the CSP.\n        y : array, shape (n_epochs,)\n            The class for each epoch.\n\n        Returns\n        -------\n        self : instance of CSP\n            Returns the modified instance.\n        \"\"\"\n        X, y = self._check_data(X, y=y, fit=True, return_y=True)\n        self._validate_params(y=y)\n        n_classes = len(self.classes_)\n        if n_classes > 2 and self.component_order == \"alternate\":\n            raise ValueError(\n                \"component_order='alternate' requires two classes, but data contains \"\n                f\"{n_classes} classes; use component_order='mutual_info' instead.\"\n            )\n\n        # Convert rank to one that will run\n        _validate_type(self.rank, (dict, None, str), \"rank\")\n\n        covs, sample_weights = self._compute_covariance_matrices(X, y)\n        eigen_vectors, eigen_values = self._decompose_covs(covs, sample_weights)\n        ix = self._order_components(\n            covs, sample_weights, eigen_vectors, eigen_values, self.component_order\n        )\n\n        eigen_vectors = eigen_vectors[:, ix]\n\n        self.filters_ = eigen_vectors.T\n        self.patterns_ = pinv(eigen_vectors)\n\n        pick_filters = self.filters_[: self.n_components]\n        X = np.asarray([np.dot(pick_filters, epoch) for epoch in X])\n\n        # compute features (mean power)\n        X = (X**2).mean(axis=2)\n\n        # To standardize features\n        self.mean_ = X.mean(axis=0)\n        self.std_ = X.std(axis=0)\n\n        return self", "metadata": {}}
{"_id": "mne_mne_decoding/csp.py_transform_code", "title": "transform", "text": "def transform(self, X):\n        \"\"\"Estimate epochs sources given the CSP filters.\n\n        Parameters\n        ----------\n        X : array, shape (n_epochs, n_channels, n_times)\n            The data.\n\n        Returns\n        -------\n        X : ndarray\n            If self.transform_into == 'average_power' then returns the power of\n            CSP features averaged over time and shape (n_epochs, n_components)\n            If self.transform_into == 'csp_space' then returns the data in CSP\n            space and shape is (n_epochs, n_components, n_times).\n        \"\"\"\n        check_is_fitted(self, \"filters_\")\n        X = self._check_data(X)\n        pick_filters = self.filters_[: self.n_components]\n        X = np.asarray([np.dot(pick_filters, epoch) for epoch in X])\n\n        # compute features (mean band power)\n        if self.transform_into == \"average_power\":\n            X = (X**2).mean(axis=2)\n            log = True if self.log is None else self.log\n            if log:\n                X = np.log(X)\n            else:\n                X -= self.mean_\n                X /= self.std_\n        return X", "metadata": {}}
{"_id": "mne_mne_decoding/csp.py_inverse_transform_code", "title": "inverse_transform", "text": "def inverse_transform(self, X):\n        \"\"\"Project CSP features back to sensor space.\n\n        Parameters\n        ----------\n        X : array, shape (n_epochs, n_components)\n            The data in CSP power space.\n\n        Returns\n        -------\n        X : ndarray\n            The data in sensor space and shape (n_epochs, n_channels, n_components).\n        \"\"\"\n        if self.transform_into != \"average_power\":\n            raise NotImplementedError(\n                \"Can only inverse transform CSP features when transform_into is \"\n                \"'average_power'.\"\n            )\n        if not (X.ndim == 2 and X.shape[1] == self.n_components):\n            raise ValueError(\n                f\"X must be 2D with X[1]={self.n_components}, got {X.shape=}\"\n            )\n        return X[:, np.newaxis, :] * self.patterns_[: self.n_components].T", "metadata": {}}
{"_id": "mne_mne_decoding/csp.py_fit_transform_code", "title": "fit_transform", "text": "def fit_transform(self, X, y=None, **fit_params):\n        \"\"\"Fit CSP to data, then transform it.\n\n        Fits transformer to ``X`` and ``y`` with optional parameters ``fit_params``, and\n        returns a transformed version of ``X``.\n\n        Parameters\n        ----------\n        X : array, shape (n_epochs, n_channels, n_times)\n            The data on which to estimate the CSP.\n        y : array, shape (n_epochs,)\n            The class for each epoch.\n        **fit_params : dict\n            Additional fitting parameters passed to the :meth:`mne.decoding.CSP.fit`\n            method. Not used for this class.\n\n        Returns\n        -------\n        X_csp : array, shape (n_epochs, n_components[, n_times])\n            If ``self.transform_into == 'average_power'`` then returns the power of CSP\n            features averaged over time and shape is ``(n_epochs, n_components)``. If\n            ``self.transform_into == 'csp_space'`` then returns the data in CSP space\n            and shape is ``(n_epochs, n_components, n_times)``.\n        \"\"\"\n        # use parent TransformerMixin method but with custom docstring\n        return super().fit_transform(X, y=y, **fit_params)", "metadata": {}}
{"_id": "mne_mne_decoding/csp.py_plot_patterns_code", "title": "plot_patterns", "text": "def plot_patterns(\n        self,\n        info,\n        components=None,\n        *,\n        ch_type=None,\n        scalings=None,\n        sensors=True,\n        show_names=False,\n        mask=None,\n        mask_params=None,\n        contours=6,\n        outlines=\"head\",\n        sphere=None,\n        image_interp=_INTERPOLATION_DEFAULT,\n        extrapolate=_EXTRAPOLATE_DEFAULT,\n        border=_BORDER_DEFAULT,\n        res=64,\n        size=1,\n        cmap=\"RdBu_r\",\n        vlim=(None, None),\n        cnorm=None,\n        colorbar=True,\n        cbar_fmt=\"%3.1f\",\n        units=None,\n        axes=None,\n        name_format=\"CSP%01d\",\n        nrows=1,\n        ncols=\"auto\",\n        show=True,\n    ):\n        \"\"\"Plot topographic patterns of components.\n\n        The patterns explain how the measured data was generated from the\n        neural sources (a.k.a. the forward model).\n\n        Parameters\n        ----------\n        %(info_not_none)s Used for fitting. If not available, consider using\n            :func:`mne.create_info`.\n        components : float | array of float | None\n           The patterns to plot. If ``None``, all components will be shown.\n        %(ch_type_topomap)s\n        scalings : dict | float | None\n            The scalings of the channel types to be applied for plotting.\n            If None, defaults to ``dict(eeg=1e6, grad=1e13, mag=1e15)``.\n        %(sensors_topomap)s\n        %(show_names_topomap)s\n        %(mask_patterns_topomap)s\n        %(mask_params_topomap)s\n        %(contours_topomap)s\n        %(outlines_topomap)s\n        %(sphere_topomap_auto)s\n        %(image_interp_topomap)s\n        %(extrapolate_topomap)s\n\n            .. versionadded:: 1.3\n        %(border_topomap)s\n\n            .. versionadded:: 1.3\n        %(res_topomap)s\n        %(size_topomap)s\n        %(cmap_topomap)s\n        %(vlim_plot_topomap)s\n\n            .. versionadded:: 1.3\n        %(cnorm)s\n\n            .. versionadded:: 1.3\n        %(colorbar_topomap)s\n        %(cbar_fmt_topomap)s\n        %(units_topomap)s\n        %(axes_evoked_plot_topomap)s\n        name_format : str\n            String format for topomap values. Defaults to \"CSP%%01d\".\n        %(nrows_ncols_topomap)s\n\n            .. versionadded:: 1.3\n        %(show)s\n\n        Returns\n        -------\n        fig : instance of matplotlib.figure.Figure\n           The figure.\n        \"\"\"\n        if units is None:\n            units = \"AU\"\n        if components is None:\n            components = np.arange(self.n_components)\n\n        # set sampling frequency to have 1 component per time point\n        info = cp.deepcopy(info)\n        with info._unlock():\n            info[\"sfreq\"] = 1.0\n        # create an evoked\n        patterns = EvokedArray(self.patterns_.T, info, tmin=0)\n        # the call plot_topomap\n        fig = patterns.plot_topomap(\n            times=components,\n            ch_type=ch_type,\n            scalings=scalings,\n            sensors=sensors,\n            show_names=show_names,\n            mask=mask,\n            mask_params=mask_params,\n            contours=contours,\n            outlines=outlines,\n            sphere=sphere,\n            image_interp=image_interp,\n            extrapolate=extrapolate,\n            border=border,\n            res=res,\n            size=size,\n            cmap=cmap,\n            vlim=vlim,\n            cnorm=cnorm,\n            colorbar=colorbar,\n            cbar_fmt=cbar_fmt,\n            units=units,\n            axes=axes,\n            time_format=name_format,\n            nrows=nrows,\n            ncols=ncols,\n            show=show,\n        )\n        return fig", "metadata": {}}
{"_id": "mne_mne_decoding/csp.py_plot_filters_code", "title": "plot_filters", "text": "def plot_filters(\n        self,\n        info,\n        components=None,\n        *,\n        ch_type=None,\n        scalings=None,\n        sensors=True,\n        show_names=False,\n        mask=None,\n        mask_params=None,\n        contours=6,\n        outlines=\"head\",\n        sphere=None,\n        image_interp=_INTERPOLATION_DEFAULT,\n        extrapolate=_EXTRAPOLATE_DEFAULT,\n        border=_BORDER_DEFAULT,\n        res=64,\n        size=1,\n        cmap=\"RdBu_r\",\n        vlim=(None, None),\n        cnorm=None,\n        colorbar=True,\n        cbar_fmt=\"%3.1f\",\n        units=None,\n        axes=None,\n        name_format=\"CSP%01d\",\n        nrows=1,\n        ncols=\"auto\",\n        show=True,\n    ):\n        \"\"\"Plot topographic filters of components.\n\n        The filters are used to extract discriminant neural sources from\n        the measured data (a.k.a. the backward model).\n\n        Parameters\n        ----------\n        %(info_not_none)s Used for fitting. If not available, consider using\n            :func:`mne.create_info`.\n        components : float | array of float | None\n           The patterns to plot. If ``None``, all components will be shown.\n        %(ch_type_topomap)s\n        scalings : dict | float | None\n            The scalings of the channel types to be applied for plotting.\n            If None, defaults to ``dict(eeg=1e6, grad=1e13, mag=1e15)``.\n        %(sensors_topomap)s\n        %(show_names_topomap)s\n        %(mask_patterns_topomap)s\n        %(mask_params_topomap)s\n        %(contours_topomap)s\n        %(outlines_topomap)s\n        %(sphere_topomap_auto)s\n        %(image_interp_topomap)s\n        %(extrapolate_topomap)s\n\n            .. versionadded:: 1.3\n        %(border_topomap)s\n\n            .. versionadded:: 1.3\n        %(res_topomap)s\n        %(size_topomap)s\n        %(cmap_topomap)s\n        %(vlim_plot_topomap_psd)s\n\n            .. versionadded:: 1.3\n        %(cnorm)s\n\n            .. versionadded:: 1.3\n        %(colorbar_topomap)s\n        %(cbar_fmt_topomap)s\n        %(units_topomap)s\n        %(axes_evoked_plot_topomap)s\n        name_format : str\n            String format for topomap values. Defaults to \"CSP%%01d\".\n        %(nrows_ncols_topomap)s\n\n            .. versionadded:: 1.3\n        %(show)s\n\n        Returns\n        -------\n        fig : instance of matplotlib.figure.Figure\n           The figure.\n        \"\"\"\n        if units is None:\n            units = \"AU\"\n        if components is None:\n            components = np.arange(self.n_components)\n\n        # set sampling frequency to have 1 component per time point\n        info = cp.deepcopy(info)\n        with info._unlock():\n            info[\"sfreq\"] = 1.0\n        # create an evoked\n        filters = EvokedArray(self.filters_.T, info, tmin=0)\n        # the call plot_topomap\n        fig = filters.plot_topomap(\n            times=components,\n            ch_type=ch_type,\n            scalings=scalings,\n            sensors=sensors,\n            show_names=show_names,\n            mask=mask,\n            mask_params=mask_params,\n            contours=contours,\n            outlines=outlines,\n            sphere=sphere,\n            image_interp=image_interp,\n            extrapolate=extrapolate,\n            border=border,\n            res=res,\n            size=size,\n            cmap=cmap,\n            vlim=vlim,\n            cnorm=cnorm,\n            colorbar=colorbar,\n            cbar_fmt=cbar_fmt,\n            units=units,\n            axes=axes,\n            time_format=name_format,\n            nrows=nrows,\n            ncols=ncols,\n            show=show,\n        )\n        return fig", "metadata": {}}
{"_id": "mne_mne_decoding/csp.py_fit_code", "title": "fit", "text": "def fit(self, X, y):\n        \"\"\"Estimate the SPoC decomposition on epochs.\n\n        Parameters\n        ----------\n        X : ndarray, shape (n_epochs, n_channels, n_times)\n            The data on which to estimate the SPoC.\n        y : array, shape (n_epochs,)\n            The class for each epoch.\n\n        Returns\n        -------\n        self : instance of SPoC\n            Returns the modified instance.\n        \"\"\"\n        X, y = self._check_data(X, y=y, fit=True, return_y=True)\n        self._validate_params(y=y)\n\n        # The following code is directly copied from pyRiemann\n\n        # Normalize target variable\n        target = y.astype(np.float64)\n        target -= target.mean()\n        target /= target.std()\n\n        n_epochs, n_channels = X.shape[:2]\n\n        # Estimate single trial covariance\n        covs = np.empty((n_epochs, n_channels, n_channels))\n        for ii, epoch in enumerate(X):\n            covs[ii] = _regularized_covariance(\n                epoch,\n                reg=self.reg,\n                method_params=self.cov_method_params,\n                rank=self.rank,\n                log_ch_type=\"data\",\n                log_rank=ii == 0,\n            )\n\n        C = covs.mean(0)\n        Cz = np.mean(covs * target[:, np.newaxis, np.newaxis], axis=0)\n\n        # solve eigenvalue decomposition\n        evals, evecs = eigh(Cz, C)\n        evals = evals.real\n        evecs = evecs.real\n        # sort vectors\n        ix = np.argsort(np.abs(evals))[::-1]\n\n        # sort eigenvectors\n        evecs = evecs[:, ix].T\n\n        # spatial patterns\n        self.patterns_ = pinv(evecs).T  # n_channels x n_channels\n        self.filters_ = evecs  # n_channels x n_channels\n\n        pick_filters = self.filters_[: self.n_components]\n        X = np.asarray([np.dot(pick_filters, epoch) for epoch in X])\n\n        # compute features (mean band power)\n        X = (X**2).mean(axis=-1)\n\n        # To standardize features\n        self.mean_ = X.mean(axis=0)\n        self.std_ = X.std(axis=0)\n\n        return self", "metadata": {}}
{"_id": "mne_mne_decoding/csp.py_transform_code", "title": "transform", "text": "def transform(self, X):\n        \"\"\"Estimate epochs sources given the SPoC filters.\n\n        Parameters\n        ----------\n        X : array, shape (n_epochs, n_channels, n_times)\n            The data.\n\n        Returns\n        -------\n        X : ndarray\n            If self.transform_into == 'average_power' then returns the power of\n            CSP features averaged over time and shape (n_epochs, n_components)\n            If self.transform_into == 'csp_space' then returns the data in CSP\n            space and shape is (n_epochs, n_components, n_times).\n        \"\"\"\n        return super().transform(X)", "metadata": {}}
{"_id": "mne_mne_decoding/csp.py_fit_transform_code", "title": "fit_transform", "text": "def fit_transform(self, X, y=None, **fit_params):\n        \"\"\"Fit SPoC to data, then transform it.\n\n        Fits transformer to ``X`` and ``y`` with optional parameters ``fit_params``, and\n        returns a transformed version of ``X``.\n\n        Parameters\n        ----------\n        X : array, shape (n_epochs, n_channels, n_times)\n            The data on which to estimate the SPoC.\n        y : array, shape (n_epochs,)\n            The class for each epoch.\n        **fit_params : dict\n            Additional fitting parameters passed to the :meth:`mne.decoding.CSP.fit`\n            method. Not used for this class.\n\n        Returns\n        -------\n        X : array, shape (n_epochs, n_components[, n_times])\n            If ``self.transform_into == 'average_power'`` then returns the power of CSP\n            features averaged over time and shape is ``(n_epochs, n_components)``. If\n            ``self.transform_into == 'csp_space'`` then returns the data in CSP space\n            and shape is ``(n_epochs, n_components, n_times)``.\n        \"\"\"\n        # use parent TransformerMixin method but with custom docstring\n        return super().fit_transform(X, y=y, **fit_params)", "metadata": {}}
{"_id": "mne_mne_channels/montage.py_get_builtin_montages_code", "title": "get_builtin_montages", "text": "def get_builtin_montages(*, descriptions=False):\n    \"\"\"Get a list of all standard montages shipping with MNE-Python.\n\n    The names of the montages can be passed to :func:`make_standard_montage`.\n\n    Parameters\n    ----------\n    descriptions : bool\n        Whether to return not only the montage names, but also their\n        corresponding descriptions. If ``True``, a list of tuples is returned,\n        where the first tuple element is the montage name and the second is\n        the montage description. If ``False`` (default), only the names are\n        returned.\n\n        .. versionadded:: 1.1\n\n    Returns\n    -------\n    montages : list of str | list of tuple\n        If ``descriptions=False``, the names of all builtin montages that can\n        be used by :func:`make_standard_montage`.\n\n        If ``descriptions=True``, a list of tuples ``(name, description)``.\n    \"\"\"\n    if descriptions:\n        return [(m.name, m.description) for m in _BUILTIN_STANDARD_MONTAGES]\n    else:\n        return [m.name for m in _BUILTIN_STANDARD_MONTAGES]", "metadata": {}}
{"_id": "mne_mne_channels/montage.py_make_dig_montage_code", "title": "make_dig_montage", "text": "def make_dig_montage(\n    ch_pos=None,\n    nasion=None,\n    lpa=None,\n    rpa=None,\n    hsp=None,\n    hpi=None,\n    coord_frame=\"unknown\",\n):\n    r\"\"\"Make montage from arrays.\n\n    Parameters\n    ----------\n    ch_pos : dict | None\n        Dictionary of channel positions. Keys are channel names and values\n        are 3D coordinates - array of shape (3,) - in native digitizer space\n        in m.\n    nasion : None | array, shape (3,)\n        The position of the nasion fiducial point.\n        This point is assumed to be in the native digitizer space in m.\n    lpa : None | array, shape (3,)\n        The position of the left periauricular fiducial point.\n        This point is assumed to be in the native digitizer space in m.\n    rpa : None | array, shape (3,)\n        The position of the right periauricular fiducial point.\n        This point is assumed to be in the native digitizer space in m.\n    hsp : None | array, shape (n_points, 3)\n        This corresponds to an array of positions of the headshape points in\n        3d. These points are assumed to be in the native digitizer space in m.\n    hpi : None | array, shape (n_hpi, 3)\n        This corresponds to an array of HPI points in the native digitizer\n        space. They only necessary if computation of a ``compute_dev_head_t``\n        is True.\n    coord_frame : str\n        The coordinate frame of the points. Usually this is ``'unknown'``\n        for native digitizer space.\n        Other valid values are: ``'head'``, ``'meg'``, ``'mri'``,\n        ``'mri_voxel'``, ``'mni_tal'``, ``'ras'``, ``'fs_tal'``,\n        ``'ctf_head'``, and ``'ctf_meg'``.\n\n        .. note::\n            For custom montages without fiducials, this parameter must be set\n            to ``'head'``.\n\n    Returns\n    -------\n    montage : instance of DigMontage\n        The montage.\n\n    See Also\n    --------\n    DigMontage\n    read_dig_captrak\n    read_dig_egi\n    read_dig_fif\n    read_dig_localite\n    read_dig_polhemus_isotrak\n    \"\"\"\n    _validate_type(ch_pos, (dict, None), \"ch_pos\")\n    if ch_pos is None:\n        ch_names = None\n    else:\n        ch_names = list(ch_pos)\n    dig = _make_dig_points(\n        nasion=nasion,\n        lpa=lpa,\n        rpa=rpa,\n        hpi=hpi,\n        extra_points=hsp,\n        dig_ch_pos=ch_pos,\n        coord_frame=coord_frame,\n    )\n\n    return DigMontage(dig=dig, ch_names=ch_names)", "metadata": {}}
{"_id": "mne_mne_channels/montage.py_transform_to_head_code", "title": "transform_to_head", "text": "def transform_to_head(montage):\n    \"\"\"Transform a DigMontage object into head coordinate.\n\n    Parameters\n    ----------\n    montage : instance of DigMontage\n        The montage.\n\n    Returns\n    -------\n    montage : instance of DigMontage\n        The montage after transforming the points to head\n        coordinate system.\n\n    Notes\n    -----\n    This function requires that the LPA, RPA and Nasion fiducial\n    points are available. If they are not, they will be added based by\n    projecting the fiducials onto a sphere with radius equal to the average\n    distance of each point to the origin (in the given coordinate frame).\n\n    This function assumes that all fiducial points are in the same coordinate\n    frame (e.g. 'unknown') and it will convert all the point in this coordinate\n    system to Neuromag head coordinate system.\n\n    .. versionchanged:: 1.2\n       Fiducial points will be added automatically if the montage does not\n       have them.\n    \"\"\"\n    # Get fiducial points and their coord_frame\n    native_head_t = compute_native_head_t(montage)\n    montage = montage.copy()  # to avoid inplace modification\n    if native_head_t[\"from\"] != FIFF.FIFFV_COORD_HEAD:\n        for d in montage.dig:\n            if d[\"coord_frame\"] == native_head_t[\"from\"]:\n                d[\"r\"] = apply_trans(native_head_t, d[\"r\"])\n                d[\"coord_frame\"] = FIFF.FIFFV_COORD_HEAD\n    _ensure_fiducials_head(montage.dig)\n    return montage", "metadata": {}}
{"_id": "mne_mne_channels/montage.py_read_dig_dat_code", "title": "read_dig_dat", "text": "def read_dig_dat(fname):\n    r\"\"\"Read electrode positions from a ``*.dat`` file.\n\n    .. Warning::\n        This function was implemented based on ``*.dat`` files available from\n        `Compumedics <https://compumedicsneuroscan.com>`__ and might not work\n        as expected with novel files. If it does not read your files correctly\n        please contact the MNE-Python developers.\n\n    Parameters\n    ----------\n    fname : path-like\n        File from which to read electrode locations.\n\n    Returns\n    -------\n    montage : DigMontage\n        The montage.\n\n    See Also\n    --------\n    read_dig_captrak\n    read_dig_dat\n    read_dig_egi\n    read_dig_fif\n    read_dig_hpts\n    read_dig_localite\n    read_dig_polhemus_isotrak\n    make_dig_montage\n\n    Notes\n    -----\n    ``*.dat`` files are plain text files and can be inspected and amended with\n    a plain text editor.\n    \"\"\"\n    from ._standard_montage_utils import _check_dupes_odict\n\n    fname = _check_fname(fname, overwrite=\"read\", must_exist=True)\n\n    with open(fname) as fid:\n        lines = fid.readlines()\n\n    ch_names, poss = list(), list()\n    nasion = lpa = rpa = None\n    for i, line in enumerate(lines):\n        items = line.split()\n        if not items:\n            continue\n        elif len(items) != 5:\n            raise ValueError(\n                f\"Error reading {fname}, line {i} has unexpected number of entries:\\n\"\n                f\"{line.rstrip()}\"\n            )\n        num = items[1]\n        if num == \"67\":\n            continue  # centroid\n        pos = np.array([float(item) for item in items[2:]])\n        if num == \"78\":\n            nasion = pos\n        elif num == \"76\":\n            lpa = pos\n        elif num == \"82\":\n            rpa = pos\n        else:\n            ch_names.append(items[0])\n            poss.append(pos)\n    electrodes = _check_dupes_odict(ch_names, poss)\n    return make_dig_montage(electrodes, nasion, lpa, rpa)", "metadata": {}}
{"_id": "mne_mne_channels/montage.py_read_dig_fif_code", "title": "read_dig_fif", "text": "def read_dig_fif(fname, *, verbose=None):\n    r\"\"\"Read digitized points from a .fif file.\n\n    Parameters\n    ----------\n    fname : path-like\n        FIF file from which to read digitization locations.\n    %(verbose)s\n\n    Returns\n    -------\n    montage : instance of DigMontage\n        The montage.\n\n    See Also\n    --------\n    DigMontage\n    read_dig_dat\n    read_dig_egi\n    read_dig_captrak\n    read_dig_polhemus_isotrak\n    read_dig_hpts\n    read_dig_localite\n    make_dig_montage\n\n    Notes\n    -----\n    .. versionchanged:: 1.9\n       Added support for reading the associated channel names, if present.\n\n    In some files, electrode names are not present (e.g., in older files).\n    For those files, the channel names are defined with the convention from\n    VectorView systems (EEG001, EEG002, etc.).\n    \"\"\"\n    check_fname(fname, \"montage\", (\"-dig.fif\", \"-dig.fif.gz\"))\n    fname = _check_fname(fname=fname, must_exist=True, overwrite=\"read\")\n    # Load the dig data\n    f, tree = fiff_open(fname)[:2]\n    with f as fid:\n        dig, ch_names = _read_dig_fif(fid, tree, return_ch_names=True)\n\n    if ch_names is None:  # backward compat from when we didn't save the names\n        ch_names = []\n        for d in dig:\n            if d[\"kind\"] == FIFF.FIFFV_POINT_EEG:\n                ch_names.append(f\"EEG{d['ident']:03d}\")\n\n    montage = DigMontage(dig=dig, ch_names=ch_names)\n    return montage", "metadata": {}}
{"_id": "mne_mne_channels/montage.py_read_dig_hpts_code", "title": "read_dig_hpts", "text": "def read_dig_hpts(fname, unit=\"mm\"):\n    \"\"\"Read historical ``.hpts`` MNE-C files.\n\n    Parameters\n    ----------\n    fname : path-like\n        The filepath of .hpts file.\n    unit : ``'m'`` | ``'cm'`` | ``'mm'``\n        Unit of the positions. Defaults to ``'mm'``.\n\n    Returns\n    -------\n    montage : instance of DigMontage\n        The montage.\n\n    See Also\n    --------\n    DigMontage\n    read_dig_captrak\n    read_dig_dat\n    read_dig_egi\n    read_dig_fif\n    read_dig_localite\n    read_dig_polhemus_isotrak\n    make_dig_montage\n\n    Notes\n    -----\n    The hpts format digitzer data file may contain comment lines starting\n    with the pound sign (#) and data lines of the form::\n\n         <*category*> <*identifier*> <*x/mm*> <*y/mm*> <*z/mm*>\n\n    where:\n\n    ``<*category*>``\n        defines the type of points. Allowed categories are: ``hpi``,\n        ``cardinal`` (fiducial), ``eeg``, and ``extra`` corresponding to\n        head-position indicator coil locations, cardinal landmarks, EEG\n        electrode locations, and additional head surface points,\n        respectively.\n\n    ``<*identifier*>``\n        identifies the point. The identifiers are usually sequential\n        numbers. For cardinal landmarks, 1 = left auricular point,\n        2 = nasion, and 3 = right auricular point. For EEG electrodes,\n        identifier = 0 signifies the reference electrode.\n\n    ``<*x/mm*> , <*y/mm*> , <*z/mm*>``\n        Location of the point, usually in the head coordinate system\n        in millimeters. If your points are in [m] then unit parameter can\n        be changed.\n\n    For example::\n\n        cardinal    2    -5.6729  -12.3873  -30.3671\n        cardinal    1    -37.6782  -10.4957   91.5228\n        cardinal    3    -131.3127    9.3976  -22.2363\n        hpi    1    -30.4493  -11.8450   83.3601\n        hpi    2    -122.5353    9.2232  -28.6828\n        hpi    3    -6.8518  -47.0697  -37.0829\n        hpi    4    7.3744  -50.6297  -12.1376\n        hpi    5    -33.4264  -43.7352  -57.7756\n        eeg    FP1  3.8676  -77.0439  -13.0212\n        eeg    FP2  -31.9297  -70.6852  -57.4881\n        eeg    F7  -6.1042  -68.2969   45.4939\n        ...\n    \"\"\"\n    from ._standard_montage_utils import _str, _str_names\n\n    fname = _check_fname(fname, overwrite=\"read\", must_exist=True)\n    _scale = _check_unit_and_get_scaling(unit)\n\n    out = np.genfromtxt(fname, comments=\"#\", dtype=(_str, _str, \"f8\", \"f8\", \"f8\"))\n    kind, label = _str_names(out[\"f0\"]), _str_names(out[\"f1\"])\n    kind = [k.lower() for k in kind]\n    xyz = np.array([out[f\"f{ii}\"] for ii in range(2, 5)]).T\n    xyz *= _scale\n    del _scale\n    fid_idx_to_label = {\"1\": \"lpa\", \"2\": \"nasion\", \"3\": \"rpa\"}\n    fid = {\n        fid_idx_to_label[label[ii]]: this_xyz\n        for ii, this_xyz in enumerate(xyz)\n        if kind[ii] == \"cardinal\"\n    }\n    ch_pos = {\n        label[ii]: this_xyz for ii, this_xyz in enumerate(xyz) if kind[ii] == \"eeg\"\n    }\n    hpi = np.array([this_xyz for ii, this_xyz in enumerate(xyz) if kind[ii] == \"hpi\"])\n    hpi.shape = (-1, 3)  # in case it's empty\n    hsp = np.array([this_xyz for ii, this_xyz in enumerate(xyz) if kind[ii] == \"extra\"])\n    hsp.shape = (-1, 3)  # in case it's empty\n    return make_dig_montage(ch_pos=ch_pos, **fid, hpi=hpi, hsp=hsp)", "metadata": {}}
{"_id": "mne_mne_channels/montage.py_read_dig_egi_code", "title": "read_dig_egi", "text": "def read_dig_egi(fname):\n    \"\"\"Read electrode locations from EGI system.\n\n    Parameters\n    ----------\n    fname : path-like\n        EGI MFF XML coordinates file from which to read digitization locations.\n\n    Returns\n    -------\n    montage : instance of DigMontage\n        The montage.\n\n    See Also\n    --------\n    DigMontage\n    read_dig_captrak\n    read_dig_dat\n    read_dig_fif\n    read_dig_hpts\n    read_dig_localite\n    read_dig_polhemus_isotrak\n    make_dig_montage\n    \"\"\"\n    _check_fname(fname, overwrite=\"read\", must_exist=True)\n\n    data = _read_dig_montage_egi(\n        fname=fname, _scaling=1.0, _all_data_kwargs_are_none=True\n    )\n    return make_dig_montage(**data)", "metadata": {}}
{"_id": "mne_mne_channels/montage.py_read_dig_captrak_code", "title": "read_dig_captrak", "text": "def read_dig_captrak(fname):\n    \"\"\"Read electrode locations from CapTrak Brain Products system.\n\n    Parameters\n    ----------\n    fname : path-like\n        BrainVision CapTrak coordinates file from which to read EEG electrode\n        locations. This is typically in XML format with the .bvct extension.\n\n    Returns\n    -------\n    montage : instance of DigMontage\n        The montage.\n\n    See Also\n    --------\n    DigMontage\n    read_dig_dat\n    read_dig_egi\n    read_dig_fif\n    read_dig_hpts\n    read_dig_localite\n    read_dig_polhemus_isotrak\n    make_dig_montage\n    \"\"\"\n    _check_fname(fname, overwrite=\"read\", must_exist=True)\n    data = _parse_brainvision_dig_montage(fname, scale=1e-3)\n\n    return make_dig_montage(**data)", "metadata": {}}
{"_id": "mne_mne_channels/montage.py_read_dig_localite_code", "title": "read_dig_localite", "text": "def read_dig_localite(fname, nasion=None, lpa=None, rpa=None):\n    \"\"\"Read Localite .csv file.\n\n    Parameters\n    ----------\n    fname : path-like\n        File name.\n    nasion : str | None\n        Name of nasion fiducial point.\n    lpa : str | None\n        Name of left preauricular fiducial point.\n    rpa : str | None\n        Name of right preauricular fiducial point.\n\n    Returns\n    -------\n    montage : instance of DigMontage\n        The montage.\n\n    See Also\n    --------\n    DigMontage\n    read_dig_captrak\n    read_dig_dat\n    read_dig_egi\n    read_dig_fif\n    read_dig_hpts\n    read_dig_polhemus_isotrak\n    make_dig_montage\n    \"\"\"\n    ch_pos = {}\n    with open(fname) as f:\n        f.readline()  # skip first row\n        for row in f:\n            _, name, x, y, z = row.split(\",\")\n            ch_pos[name] = np.array((float(x), float(y), float(z))) / 1000\n\n    if nasion is not None:\n        nasion = ch_pos.pop(nasion)\n    if lpa is not None:\n        lpa = ch_pos.pop(lpa)\n    if rpa is not None:\n        rpa = ch_pos.pop(rpa)\n\n    return make_dig_montage(ch_pos, nasion, lpa, rpa)", "metadata": {}}
{"_id": "mne_mne_channels/montage.py_read_dig_polhemus_isotrak_code", "title": "read_dig_polhemus_isotrak", "text": "def read_dig_polhemus_isotrak(fname, ch_names=None, unit=\"m\"):\n    \"\"\"Read Polhemus digitizer data from a file.\n\n    Parameters\n    ----------\n    fname : path-like\n        The filepath of Polhemus ISOTrak formatted file.\n        File extension is expected to be ``'.hsp'``, ``'.elp'`` or ``'.eeg'``.\n    ch_names : None | list of str\n        The names of the points. This will make the points\n        considered as EEG channels. If None, channels will be assumed\n        to be HPI if the extension is ``'.elp'``, and extra headshape\n        points otherwise.\n    unit : ``'m'`` | ``'cm'`` | ``'mm'``\n        Unit of the digitizer file. Polhemus ISOTrak systems data is usually\n        exported in meters. Defaults to ``'m'``.\n\n    Returns\n    -------\n    montage : instance of DigMontage\n        The montage.\n\n    See Also\n    --------\n    DigMontage\n    make_dig_montage\n    read_polhemus_fastscan\n    read_dig_captrak\n    read_dig_dat\n    read_dig_egi\n    read_dig_fif\n    read_dig_localite\n    \"\"\"\n    VALID_FILE_EXT = (\".hsp\", \".elp\", \".eeg\")\n    fname = str(_check_fname(fname, overwrite=\"read\", must_exist=True))\n    _scale = _check_unit_and_get_scaling(unit)\n\n    _, ext = op.splitext(fname)\n    _check_option(\"fname\", ext, VALID_FILE_EXT)\n\n    if ext == \".elp\":\n        data = _read_isotrak_elp_points(fname)\n    else:\n        # Default case we read points as hsp since is the most likely scenario\n        data = _read_isotrak_hsp_points(fname)\n\n    if _scale != 1:\n        data = {key: val * _scale for key, val in data.items()}\n    else:\n        pass  # noqa\n\n    if ch_names is None:\n        keyword = \"hpi\" if ext == \".elp\" else \"hsp\"\n        data[keyword] = data.pop(\"points\")\n\n    else:\n        points = data.pop(\"points\")\n        if points.shape[0] == len(ch_names):\n            data[\"ch_pos\"] = OrderedDict(zip(ch_names, points))\n        else:\n            raise ValueError(\n                \"Length of ``ch_names`` does not match the number of points in \"\n                f\"{fname}. Expected ``ch_names`` length {points.shape[0]}, given \"\n                f\"{len(ch_names)}\"\n            )\n\n    return make_dig_montage(**data)", "metadata": {}}
{"_id": "mne_mne_channels/montage.py_read_polhemus_fastscan_code", "title": "read_polhemus_fastscan", "text": "def read_polhemus_fastscan(\n    fname, unit=\"mm\", on_header_missing=\"raise\", *, verbose=None\n):\n    \"\"\"Read Polhemus FastSCAN digitizer data from a ``.txt`` file.\n\n    Parameters\n    ----------\n    fname : path-like\n        The path of ``.txt`` Polhemus FastSCAN file.\n    unit : ``'m'`` | ``'cm'`` | ``'mm'``\n        Unit of the digitizer file. Polhemus FastSCAN systems data is usually\n        exported in millimeters. Defaults to ``'mm'``.\n    %(on_header_missing)s\n    %(verbose)s\n\n    Returns\n    -------\n    points : array, shape (n_points, 3)\n        The digitization points in digitizer coordinates.\n\n    See Also\n    --------\n    read_dig_polhemus_isotrak\n    make_dig_montage\n    \"\"\"\n    VALID_FILE_EXT = [\".txt\"]\n    fname = str(_check_fname(fname, overwrite=\"read\", must_exist=True))\n    _scale = _check_unit_and_get_scaling(unit)\n\n    _, ext = op.splitext(fname)\n    _check_option(\"fname\", ext, VALID_FILE_EXT)\n\n    if not _is_polhemus_fastscan(fname):\n        msg = f\"{fname} does not contain a valid Polhemus FastSCAN header\"\n        _on_missing(on_header_missing, msg)\n\n    points = _scale * np.loadtxt(fname, comments=\"%\", ndmin=2)\n    _check_dig_shape(points)\n    return points", "metadata": {}}
{"_id": "mne_mne_channels/montage.py_read_custom_montage_code", "title": "read_custom_montage", "text": "def read_custom_montage(\n    fname, head_size=HEAD_SIZE_DEFAULT, coord_frame=None, *, verbose=None\n):\n    \"\"\"Read a montage from a file.\n\n    Parameters\n    ----------\n    fname : path-like\n        File extension is expected to be:\n        ``'.loc'`` or ``'.locs'`` or ``'.eloc'`` (for EEGLAB files),\n        ``'.sfp'`` (BESA/EGI files), ``'.csd'``,\n        ``'.elc'``, ``'.txt'``, ``'.csd'``, ``'.elp'`` (BESA spherical),\n        ``'.bvef'`` (BrainVision files),\n        ``'.csv'``, ``'.tsv'``, ``'.xyz'`` (XYZ coordinates).\n    head_size : float | None\n        The size of the head (radius, in [m]). If ``None``, returns the values\n        read from the montage file with no modification. Defaults to 0.095m.\n    coord_frame : str | None\n        The coordinate frame of the points. Usually this is ``\"unknown\"``\n        for native digitizer space. Defaults to None, which is ``\"unknown\"``\n        for most readers but ``\"head\"`` for EEGLAB.\n\n        .. versionadded:: 0.20\n    %(verbose)s\n\n    Returns\n    -------\n    montage : instance of DigMontage\n        The montage.\n\n    See Also\n    --------\n    make_dig_montage\n    make_standard_montage\n    read_dig_fif\n\n    Notes\n    -----\n    The function is a helper to read electrode positions you may have\n    in various formats. Most of these format are weakly specified\n    in terms of units, coordinate systems. It implies that setting\n    a montage using a DigMontage produced by this function may\n    be problematic. If you use a standard/template (eg. 10/20,\n    10/10 or 10/05) we recommend you use :func:`make_standard_montage`.\n    If you can have positions in memory you can also use\n    :func:`make_dig_montage` that takes arrays as input.\n    \"\"\"\n    from ._standard_montage_utils import (\n        _read_brainvision,\n        _read_csd,\n        _read_elc,\n        _read_elp_besa,\n        _read_sfp,\n        _read_theta_phi_in_degrees,\n        _read_xyz,\n    )\n\n    SUPPORTED_FILE_EXT = {\n        \"eeglab\": (\n            \".loc\",\n            \".locs\",\n            \".eloc\",\n        ),\n        \"hydrocel\": (\".sfp\",),\n        \"matlab\": (\".csd\",),\n        \"asa electrode\": (\".elc\",),\n        \"generic (Theta-phi in degrees)\": (\".txt\",),\n        \"standard BESA spherical\": (\".elp\",),  # NB: not same as polhemus elp\n        \"brainvision\": (\".bvef\",),\n        \"xyz\": (\".csv\", \".tsv\", \".xyz\"),\n    }\n\n    fname = str(_check_fname(fname, overwrite=\"read\", must_exist=True))\n    _, ext = op.splitext(fname)\n    _check_option(\"fname\", ext, list(sum(SUPPORTED_FILE_EXT.values(), ())))\n\n    if ext in SUPPORTED_FILE_EXT[\"eeglab\"]:\n        if head_size is None:\n            raise ValueError(f\"``head_size`` cannot be None for '{ext}'\")\n        ch_names, pos = _read_eeglab_locations(fname)\n        scale = head_size / np.median(np.linalg.norm(pos, axis=-1))\n        pos *= scale\n\n        montage = make_dig_montage(\n            ch_pos=OrderedDict(zip(ch_names, pos)),\n            coord_frame=\"head\",\n        )\n\n    elif ext in SUPPORTED_FILE_EXT[\"hydrocel\"]:\n        montage = _read_sfp(fname, head_size=head_size)\n\n    elif ext in SUPPORTED_FILE_EXT[\"matlab\"]:\n        montage = _read_csd(fname, head_size=head_size)\n\n    elif ext in SUPPORTED_FILE_EXT[\"asa electrode\"]:\n        montage = _read_elc(fname, head_size=head_size)\n\n    elif ext in SUPPORTED_FILE_EXT[\"generic (Theta-phi in degrees)\"]:\n        if head_size is None:\n            raise ValueError(f\"``head_size`` cannot be None for '{ext}'\")\n        montage = _read_theta_phi_in_degrees(\n            fname, head_size=head_size, fid_names=(\"Nz\", \"LPA\", \"RPA\")\n        )\n\n    elif ext in SUPPORTED_FILE_EXT[\"standard BESA spherical\"]:\n        montage = _read_elp_besa(fname, head_size)\n\n    elif ext in SUPPORTED_FILE_EXT[\"brainvision\"]:\n        montage = _read_brainvision(fname, head_size)\n\n    elif ext in SUPPORTED_FILE_EXT[\"xyz\"]:\n        montage = _read_xyz(fname)\n\n    if coord_frame is not None:\n        coord_frame = _coord_frame_const(coord_frame)\n        for d in montage.dig:\n            d[\"coord_frame\"] = coord_frame\n\n    return montage", "metadata": {}}
{"_id": "mne_mne_channels/montage.py_compute_dev_head_t_code", "title": "compute_dev_head_t", "text": "def compute_dev_head_t(montage):\n    \"\"\"Compute device to head transform from a DigMontage.\n\n    Parameters\n    ----------\n    montage : DigMontage\n        The `~mne.channels.DigMontage` must contain the fiducials in head\n        coordinate system and hpi points in both head and\n        meg device coordinate system.\n\n    Returns\n    -------\n    dev_head_t : Transform\n        A Device-to-Head transformation matrix.\n    \"\"\"\n    _, coord_frame = _get_fid_coords(montage.dig)\n    if coord_frame != FIFF.FIFFV_COORD_HEAD:\n        raise ValueError(\n            \"montage should have been set to head coordinate \"\n            \"system with transform_to_head function.\"\n        )\n\n    hpi_head = np.array(\n        [\n            d[\"r\"]\n            for d in montage.dig\n            if (\n                d[\"kind\"] == FIFF.FIFFV_POINT_HPI\n                and d[\"coord_frame\"] == FIFF.FIFFV_COORD_HEAD\n            )\n        ],\n        float,\n    )\n    hpi_dev = np.array(\n        [\n            d[\"r\"]\n            for d in montage.dig\n            if (\n                d[\"kind\"] == FIFF.FIFFV_POINT_HPI\n                and d[\"coord_frame\"] == FIFF.FIFFV_COORD_DEVICE\n            )\n        ],\n        float,\n    )\n\n    if not (len(hpi_head) == len(hpi_dev) and len(hpi_dev) > 0):\n        raise ValueError(\n            \"To compute Device-to-Head transformation, the same number of HPI\"\n            f\" points in device and head coordinates is required. (Got {len(hpi_dev)}\"\n            f\" points in device and {len(hpi_head)} points in head coordinate systems)\"\n        )\n\n    trans = _quat_to_affine(_fit_matched_points(hpi_dev, hpi_head)[0])\n    return Transform(fro=\"meg\", to=\"head\", trans=trans)", "metadata": {}}
{"_id": "mne_mne_channels/montage.py_compute_native_head_t_code", "title": "compute_native_head_t", "text": "def compute_native_head_t(montage, *, on_missing=\"warn\", verbose=None):\n    \"\"\"Compute the native-to-head transformation for a montage.\n\n    This uses the fiducials in the native space to transform to compute the\n    transform to the head coordinate frame.\n\n    Parameters\n    ----------\n    montage : instance of DigMontage\n        The montage.\n    %(on_missing_fiducials)s\n\n        .. versionadded:: 1.2\n    %(verbose)s\n\n    Returns\n    -------\n    native_head_t : instance of Transform\n        A native-to-head transformation matrix.\n    \"\"\"\n    # Get fiducial points and their coord_frame\n    fid_coords, coord_frame = _get_fid_coords(montage.dig, raise_error=False)\n    if coord_frame is None:\n        coord_frame = FIFF.FIFFV_COORD_UNKNOWN\n    if coord_frame == FIFF.FIFFV_COORD_HEAD:\n        native_head_t = np.eye(4)\n    else:\n        fid_keys = (\"nasion\", \"lpa\", \"rpa\")\n        for key in fid_keys:\n            this_coord = fid_coords[key]\n            if this_coord is None or np.any(np.isnan(this_coord)):\n                msg = (\n                    f\"Fiducial point {key} not found, assuming identity \"\n                    f\"{_verbose_frames[coord_frame]} to head transformation\"\n                )\n                _on_missing(on_missing, msg, error_klass=RuntimeError)\n                native_head_t = np.eye(4)\n                break\n        else:\n            native_head_t = get_ras_to_neuromag_trans(\n                *[fid_coords[key] for key in fid_keys]\n            )\n    return Transform(coord_frame, \"head\", native_head_t)", "metadata": {}}
{"_id": "mne_mne_channels/montage.py_make_standard_montage_code", "title": "make_standard_montage", "text": "def make_standard_montage(kind, head_size=\"auto\"):\n    \"\"\"Read a generic (built-in) standard montage that ships with MNE-Python.\n\n    Parameters\n    ----------\n    kind : str\n        The name of the montage to use.\n\n        .. note::\n            You can retrieve the names of all\n            built-in montages via :func:`mne.channels.get_builtin_montages`.\n    head_size : float | None | str\n        The head size (radius, in meters) to use for spherical montages.\n        Can be None to not scale the read sizes. ``'auto'`` (default) will\n        use 95mm for all montages except the ``'standard*'``, ``'mgh*'``, and\n        ``'artinis*'``, which are already in fsaverage's MRI coordinates\n        (same as MNI).\n\n    Returns\n    -------\n    montage : instance of DigMontage\n        The montage.\n\n    See Also\n    --------\n    get_builtin_montages\n    make_dig_montage\n    read_custom_montage\n\n    Notes\n    -----\n    Individualized (digitized) electrode positions should be read in using\n    :func:`read_dig_captrak`, :func:`read_dig_dat`, :func:`read_dig_egi`,\n    :func:`read_dig_fif`, :func:`read_dig_polhemus_isotrak`,\n    :func:`read_dig_hpts`, or manually made with :func:`make_dig_montage`.\n\n    .. versionadded:: 0.19.0\n    \"\"\"\n    from ._standard_montage_utils import standard_montage_look_up_table\n\n    _validate_type(kind, str, \"kind\")\n    _check_option(\n        parameter=\"kind\",\n        value=kind,\n        allowed_values=[m.name for m in _BUILTIN_STANDARD_MONTAGES],\n    )\n    _validate_type(head_size, (\"numeric\", str, None), \"head_size\")\n    if isinstance(head_size, str):\n        _check_option(\"head_size\", head_size, (\"auto\",), extra=\"when str\")\n        if kind.startswith((\"standard\", \"mgh\", \"artinis\")):\n            head_size = None\n        else:\n            head_size = HEAD_SIZE_DEFAULT\n    return standard_montage_look_up_table[kind](head_size=head_size)", "metadata": {}}
{"_id": "mne_mne_channels/montage.py_rename_channels_code", "title": "rename_channels", "text": "def rename_channels(self, mapping, allow_duplicates=False):\n        \"\"\"Rename the channels.\n\n        Parameters\n        ----------\n        %(mapping_rename_channels_duplicates)s\n\n        Returns\n        -------\n        inst : instance of DigMontage\n            The instance. Operates in-place.\n        \"\"\"\n        from .channels import rename_channels\n\n        temp_info = create_info(list(self._get_ch_pos()), 1000.0, \"eeg\")\n        rename_channels(temp_info, mapping, allow_duplicates)\n        self.ch_names = temp_info[\"ch_names\"]", "metadata": {}}
{"_id": "mne_mne_channels/montage.py_save_code", "title": "save", "text": "def save(self, fname, *, overwrite=False, verbose=None):\n        \"\"\"Save digitization points to FIF.\n\n        Parameters\n        ----------\n        fname : path-like\n            The filename to use. Should end in ``-dig.fif`` or ``-dig.fif.gz``.\n        %(overwrite)s\n        %(verbose)s\n\n        See Also\n        --------\n        mne.channels.read_dig_fif\n\n        Notes\n        -----\n        .. versionchanged:: 1.9\n           Added support for saving the associated channel names.\n        \"\"\"\n        fname = _check_fname(fname, overwrite=overwrite)\n        check_fname(fname, \"montage\", (\"-dig.fif\", \"-dig.fif.gz\"))\n        coord_frame = _check_get_coord_frame(self.dig)\n        write_dig(\n            fname, self.dig, coord_frame, overwrite=overwrite, ch_names=self.ch_names\n        )", "metadata": {}}
{"_id": "mne_mne_channels/montage.py_copy_code", "title": "copy", "text": "def copy(self):\n        \"\"\"Copy the DigMontage object.\n\n        Returns\n        -------\n        dig : instance of DigMontage\n            The copied DigMontage instance.\n        \"\"\"\n        return deepcopy(self)", "metadata": {}}
{"_id": "mne_mne_channels/montage.py_get_positions_code", "title": "get_positions", "text": "def get_positions(self):\n        \"\"\"Get all channel and fiducial positions.\n\n        Returns\n        -------\n        positions : dict\n            A dictionary of the positions for channels (``ch_pos``),\n            coordinate frame (``coord_frame``), nasion (``nasion``),\n            left preauricular point (``lpa``),\n            right preauricular point (``rpa``),\n            Head Shape Polhemus (``hsp``), and\n            Head Position Indicator(``hpi``).\n            E.g.::\n\n                {\n                    'ch_pos': {'EEG061': [0, 0, 0]},\n                    'nasion': [0, 0, 1],\n                    'coord_frame': 'mni_tal',\n                    'lpa': [0, 1, 0],\n                    'rpa': [1, 0, 0],\n                    'hsp': None,\n                    'hpi': None\n                }\n        \"\"\"\n        # get channel positions as dict\n        ch_pos = self._get_ch_pos()\n\n        # get coordframe and fiducial coordinates\n        montage_bunch = _get_data_as_dict_from_dig(self.dig)\n        coord_frame = _frame_to_str.get(montage_bunch.coord_frame)\n\n        # return dictionary\n        positions = dict(\n            ch_pos=ch_pos,\n            coord_frame=coord_frame,\n            nasion=montage_bunch.nasion,\n            lpa=montage_bunch.lpa,\n            rpa=montage_bunch.rpa,\n            hsp=montage_bunch.hsp,\n            hpi=montage_bunch.hpi,\n        )\n        return positions", "metadata": {}}
{"_id": "mne_mne_channels/montage.py_apply_trans_code", "title": "apply_trans", "text": "def apply_trans(self, trans, verbose=None):\n        \"\"\"Apply a transformation matrix to the montage.\n\n        Parameters\n        ----------\n        trans : instance of mne.transforms.Transform\n            The transformation matrix to be applied.\n        %(verbose)s\n        \"\"\"\n        _validate_type(trans, Transform, \"trans\")\n        coord_frame = self.get_positions()[\"coord_frame\"]\n        trans = _ensure_trans(trans, fro=coord_frame, to=trans[\"to\"])\n        for d in self.dig:\n            d[\"r\"] = apply_trans(trans, d[\"r\"])\n            d[\"coord_frame\"] = trans[\"to\"]", "metadata": {}}
{"_id": "mne_mne_channels/montage.py_add_estimated_fiducials_code", "title": "add_estimated_fiducials", "text": "def add_estimated_fiducials(self, subject, subjects_dir=None, verbose=None):\n        \"\"\"Estimate fiducials based on FreeSurfer ``fsaverage`` subject.\n\n        This takes a montage with the ``mri`` coordinate frame,\n        corresponding to the FreeSurfer RAS (xyz in the volume) T1w\n        image of the specific subject. It will call\n        :func:`mne.coreg.get_mni_fiducials` to estimate LPA, RPA and\n        Nasion fiducial points.\n\n        Parameters\n        ----------\n        %(subject)s\n        %(subjects_dir)s\n        %(verbose)s\n\n        Returns\n        -------\n        inst : instance of DigMontage\n            The instance, modified in-place.\n\n        See Also\n        --------\n        :ref:`tut-source-alignment`\n\n        Notes\n        -----\n        Since MNE uses the FIF data structure, it relies on the ``head``\n        coordinate frame. Any coordinate frame can be transformed\n        to ``head`` if the fiducials (i.e. LPA, RPA and Nasion) are\n        defined. One can use this function to estimate those fiducials\n        and then use ``mne.channels.compute_native_head_t(montage)``\n        to get the head <-> MRI transform.\n        \"\"\"\n        # get coordframe and fiducial coordinates\n        montage_bunch = _get_data_as_dict_from_dig(self.dig)\n\n        # get the coordinate frame and check that it's MRI\n        if montage_bunch.coord_frame != FIFF.FIFFV_COORD_MRI:\n            raise RuntimeError(\n                f'Montage should be in the \"mri\" coordinate frame '\n                f\"to use `add_estimated_fiducials`. The current coordinate \"\n                f\"frame is {montage_bunch.coord_frame}\"\n            )\n\n        # estimate LPA, nasion, RPA from FreeSurfer fsaverage\n        fids_mri = list(get_mni_fiducials(subject, subjects_dir))\n\n        # add those digpoints to front of montage\n        self.dig = fids_mri + self.dig\n        return self", "metadata": {}}
{"_id": "mne_mne_channels/montage.py_add_mni_fiducials_code", "title": "add_mni_fiducials", "text": "def add_mni_fiducials(self, subjects_dir=None, verbose=None):\n        \"\"\"Add fiducials to a montage in MNI space.\n\n        Parameters\n        ----------\n        %(subjects_dir)s\n        %(verbose)s\n\n        Returns\n        -------\n        inst : instance of DigMontage\n            The instance, modified in-place.\n\n        Notes\n        -----\n        ``fsaverage`` is in MNI space and so its fiducials can be\n        added to a montage in \"mni_tal\". MNI is an ACPC-aligned\n        coordinate system (the posterior commissure is the origin)\n        so since BIDS requires channel locations for ECoG, sEEG and\n        DBS to be in ACPC space, this function can be used to allow\n        those coordinate to be transformed to \"head\" space (origin\n        between LPA and RPA).\n        \"\"\"\n        montage_bunch = _get_data_as_dict_from_dig(self.dig)\n\n        # get the coordinate frame and check that it's MNI TAL\n        if montage_bunch.coord_frame != FIFF.FIFFV_MNE_COORD_MNI_TAL:\n            raise RuntimeError(\n                f'Montage should be in the \"mni_tal\" coordinate frame '\n                f\"to use `add_estimated_fiducials`. The current coordinate \"\n                f\"frame is {montage_bunch.coord_frame}\"\n            )\n\n        fids_mni = get_mni_fiducials(\"fsaverage\", subjects_dir)\n        for fid in fids_mni:\n            # \"mri\" and \"mni_tal\" are equivalent for fsaverage\n            assert fid[\"coord_frame\"] == FIFF.FIFFV_COORD_MRI\n            fid[\"coord_frame\"] = FIFF.FIFFV_MNE_COORD_MNI_TAL\n        self.dig = fids_mni + self.dig\n        return self", "metadata": {}}
{"_id": "mne_mne_channels/montage.py_remove_fiducials_code", "title": "remove_fiducials", "text": "def remove_fiducials(self, verbose=None):\n        \"\"\"Remove the fiducial points from a montage.\n\n        Parameters\n        ----------\n        %(verbose)s\n\n        Returns\n        -------\n        inst : instance of DigMontage\n            The instance, modified in-place.\n\n        Notes\n        -----\n        MNE will transform a montage to the internal \"head\" coordinate\n        frame if the fiducials are present. Under most circumstances, this\n        is ideal as it standardizes the coordinate frame for things like\n        plotting. However, in some circumstances, such as saving a ``raw``\n        with intracranial data to BIDS format, the coordinate frame\n        should not be changed by removing fiducials.\n        \"\"\"\n        for d in self.dig.copy():\n            if d[\"kind\"] == FIFF.FIFFV_POINT_CARDINAL:\n                self.dig.remove(d)\n        return self", "metadata": {}}
{"_id": "mne_mne_channels/layout.py_read_layout_code", "title": "read_layout", "text": "def read_layout(fname=None, *, scale=True):\n    \"\"\"Read layout from a file.\n\n    Parameters\n    ----------\n    fname : path-like | str\n        Either the path to a ``.lout`` or ``.lay`` file or the name of a\n        built-in layout. c.f. Notes for a list of the available built-in\n        layouts.\n    scale : bool\n        Apply useful scaling for out the box plotting using ``layout.pos``.\n        Defaults to True.\n\n    Returns\n    -------\n    layout : instance of Layout\n        The layout.\n\n    See Also\n    --------\n    Layout.save\n\n    Notes\n    -----\n    Valid ``fname`` arguments are:\n\n    .. table::\n       :widths: auto\n\n       +----------------------+\n       | Kind                 |\n       +======================+\n       | biosemi              |\n       +----------------------+\n       | CTF151               |\n       +----------------------+\n       | CTF275               |\n       +----------------------+\n       | CTF-275              |\n       +----------------------+\n       | EEG1005              |\n       +----------------------+\n       | EGI256               |\n       +----------------------+\n       | GeodesicHeadWeb-130  |\n       +----------------------+\n       | GeodesicHeadWeb-280  |\n       +----------------------+\n       | KIT-125              |\n       +----------------------+\n       | KIT-157              |\n       +----------------------+\n       | KIT-160              |\n       +----------------------+\n       | KIT-AD               |\n       +----------------------+\n       | KIT-AS-2008          |\n       +----------------------+\n       | KIT-UMD-3            |\n       +----------------------+\n       | magnesWH3600         |\n       +----------------------+\n       | Neuromag_122         |\n       +----------------------+\n       | Vectorview-all       |\n       +----------------------+\n       | Vectorview-grad      |\n       +----------------------+\n       | Vectorview-grad_norm |\n       +----------------------+\n       | Vectorview-mag       |\n       +----------------------+\n    \"\"\"\n    readers = {\".lout\": _read_lout, \".lay\": _read_lay}\n\n    if isinstance(fname, str):\n        # is it a built-in layout?\n        directory = Path(__file__).parent / \"data\" / \"layouts\"\n        for suffix in (\"\", \".lout\", \".lay\"):\n            _fname = (directory / fname).with_suffix(suffix)\n            if _fname.exists():\n                fname = _fname\n                break\n    # if not, it must be a valid path provided as str or Path\n    fname = _check_fname(fname, \"read\", must_exist=True, name=\"layout\")\n    # and it must have a valid extension\n    _check_option(\"fname extension\", fname.suffix, readers)\n    kind = fname.stem\n    box, pos, names, ids = readers[fname.suffix](fname)\n\n    if scale:\n        pos[:, 0] -= np.min(pos[:, 0])\n        pos[:, 1] -= np.min(pos[:, 1])\n        scaling = max(np.max(pos[:, 0]), np.max(pos[:, 1])) + pos[0, 2]\n        pos /= scaling\n        pos[:, :2] += 0.03\n        pos[:, :2] *= 0.97 / 1.03\n        pos[:, 2:] *= 0.94\n\n    return Layout(box=box, pos=pos, names=names, kind=kind, ids=ids)", "metadata": {}}
{"_id": "mne_mne_channels/layout.py_make_eeg_layout_code", "title": "make_eeg_layout", "text": "def make_eeg_layout(\n    info, radius=0.5, width=None, height=None, exclude=\"bads\", csd=False\n):\n    \"\"\"Create .lout file from EEG electrode digitization.\n\n    Parameters\n    ----------\n    %(info_not_none)s\n    radius : float\n        Viewport radius as a fraction of main figure height. Defaults to 0.5.\n    width : float | None\n        Width of sensor axes as a fraction of main figure height. By default,\n        this will be the maximum width possible without axes overlapping.\n    height : float | None\n        Height of sensor axes as a fraction of main figure height. By default,\n        this will be the maximum height possible without axes overlapping.\n    exclude : list of str | str\n        List of channels to exclude. If empty do not exclude any.\n        If 'bads', exclude channels in info['bads'] (default).\n    csd : bool\n        Whether the channels contain current-source-density-transformed data.\n\n    Returns\n    -------\n    layout : Layout\n        The generated Layout.\n\n    See Also\n    --------\n    make_grid_layout, generate_2d_layout\n    \"\"\"\n    if not (0 <= radius <= 0.5):\n        raise ValueError(\"The radius parameter should be between 0 and 0.5.\")\n    if width is not None and not (0 <= width <= 1.0):\n        raise ValueError(\"The width parameter should be between 0 and 1.\")\n    if height is not None and not (0 <= height <= 1.0):\n        raise ValueError(\"The height parameter should be between 0 and 1.\")\n\n    pick_kwargs = dict(meg=False, eeg=True, ref_meg=False, exclude=exclude)\n    if csd:\n        pick_kwargs.update(csd=True, eeg=False)\n    picks = pick_types(info, **pick_kwargs)\n    loc2d = _find_topomap_coords(info, picks)\n    names = [info[\"chs\"][i][\"ch_name\"] for i in picks]\n\n    # Scale [x, y] to be in the range [-0.5, 0.5]\n    # Don't mess with the origin or aspect ratio\n    scale = np.maximum(-np.min(loc2d, axis=0), np.max(loc2d, axis=0)).max() * 2\n    loc2d /= scale\n\n    # If no width or height specified, calculate the maximum value possible\n    # without axes overlapping.\n    if width is None or height is None:\n        width, height = _box_size(loc2d, width, height, padding=0.1)\n\n    # Scale to viewport radius\n    loc2d *= 2 * radius\n\n    # Some subplot centers will be at the figure edge. Shrink everything so it\n    # fits in the figure.\n    scaling = min(1 / (1.0 + width), 1 / (1.0 + height))\n    loc2d *= scaling\n    width *= scaling\n    height *= scaling\n\n    # Shift to center\n    loc2d += 0.5\n\n    n_channels = loc2d.shape[0]\n    pos = np.c_[\n        loc2d[:, 0] - 0.5 * width,\n        loc2d[:, 1] - 0.5 * height,\n        width * np.ones(n_channels),\n        height * np.ones(n_channels),\n    ]\n\n    box = (0, 1, 0, 1)\n    ids = 1 + np.arange(n_channels)\n    layout = Layout(box=box, pos=pos, names=names, kind=\"EEG\", ids=ids)\n    return layout", "metadata": {}}
{"_id": "mne_mne_channels/layout.py_make_grid_layout_code", "title": "make_grid_layout", "text": "def make_grid_layout(info, picks=None, n_col=None):\n    \"\"\"Generate .lout file for custom data, i.e., ICA sources.\n\n    Parameters\n    ----------\n    %(info_not_none)s\n    %(picks_base)s all good misc channels.\n    n_col : int | None\n        Number of columns to generate. If None, a square grid will be produced.\n\n    Returns\n    -------\n    layout : Layout\n        The generated layout.\n\n    See Also\n    --------\n    make_eeg_layout, generate_2d_layout\n    \"\"\"\n    picks = _picks_to_idx(info, picks, \"misc\")\n\n    names = [info[\"chs\"][k][\"ch_name\"] for k in picks]\n\n    if not names:\n        raise ValueError(\"No misc data channels found.\")\n\n    ids = list(range(len(picks)))\n    size = len(picks)\n\n    if n_col is None:\n        # prepare square-like layout\n        n_row = n_col = np.sqrt(size)  # try square\n        if n_col % 1:\n            # try n * (n-1) rectangle\n            n_col, n_row = int(n_col + 1), int(n_row)\n\n        if n_col * n_row < size:  # jump to the next full square\n            n_row += 1\n    else:\n        n_row = int(np.ceil(size / float(n_col)))\n\n    # setup position grid\n    x, y = np.meshgrid(np.linspace(-0.5, 0.5, n_col), np.linspace(-0.5, 0.5, n_row))\n    x, y = x.ravel()[:size], y.ravel()[:size]\n    width, height = _box_size(np.c_[x, y], padding=0.1)\n\n    # Some axes will be at the figure edge. Shrink everything so it fits in the\n    # figure. Add 0.01 border around everything\n    border_x, border_y = (0.01, 0.01)\n    x_scaling = 1 / (1.0 + width + border_x)\n    y_scaling = 1 / (1.0 + height + border_y)\n    x = x * x_scaling\n    y = y * y_scaling\n    width *= x_scaling\n    height *= y_scaling\n\n    # Shift to center\n    x += 0.5\n    y += 0.5\n\n    # calculate pos\n    pos = np.c_[\n        x - 0.5 * width, y - 0.5 * height, width * np.ones(size), height * np.ones(size)\n    ]\n    box = (0, 1, 0, 1)\n\n    layout = Layout(box=box, pos=pos, names=names, kind=\"grid-misc\", ids=ids)\n    return layout", "metadata": {}}
{"_id": "mne_mne_channels/layout.py_find_layout_code", "title": "find_layout", "text": "def find_layout(info, ch_type=None, exclude=\"bads\"):\n    \"\"\"Choose a layout based on the channels in the info 'chs' field.\n\n    Parameters\n    ----------\n    %(info_not_none)s\n    ch_type : {'mag', 'grad', 'meg', 'eeg'} | None\n        The channel type for selecting single channel layouts.\n        Defaults to None. Note, this argument will only be considered for\n        VectorView type layout. Use ``'meg'`` to force using the full layout\n        in situations where the info does only contain one sensor type.\n    exclude : list of str | str\n        List of channels to exclude. If empty do not exclude any.\n        If 'bads', exclude channels in info['bads'] (default).\n\n    Returns\n    -------\n    layout : Layout instance | None\n        None if layout not found.\n    \"\"\"\n    _check_option(\"ch_type\", ch_type, [None, \"mag\", \"grad\", \"meg\", \"eeg\", \"csd\"])\n\n    (\n        has_vv_mag,\n        has_vv_grad,\n        is_old_vv,\n        has_4D_mag,\n        ctf_other_types,\n        has_CTF_grad,\n        n_kit_grads,\n        has_any_meg,\n        has_eeg_coils,\n        has_eeg_coils_and_meg,\n        has_eeg_coils_only,\n        has_neuromag_122_grad,\n        has_csd_coils,\n    ) = _get_ch_info(info)\n    has_vv_meg = has_vv_mag and has_vv_grad\n    has_vv_only_mag = has_vv_mag and not has_vv_grad\n    has_vv_only_grad = has_vv_grad and not has_vv_mag\n    if ch_type == \"meg\" and not has_any_meg:\n        raise RuntimeError(\"No MEG channels present. Cannot find MEG layout.\")\n\n    if ch_type == \"eeg\" and not has_eeg_coils:\n        raise RuntimeError(\"No EEG channels present. Cannot find EEG layout.\")\n\n    layout_name = None\n    if (has_vv_meg and ch_type is None) or (\n        any([has_vv_mag, has_vv_grad]) and ch_type == \"meg\"\n    ):\n        layout_name = \"Vectorview-all\"\n    elif has_vv_only_mag or (has_vv_meg and ch_type == \"mag\"):\n        layout_name = \"Vectorview-mag\"\n    elif has_vv_only_grad or (has_vv_meg and ch_type == \"grad\"):\n        if info[\"ch_names\"][0].endswith(\"X\"):\n            layout_name = \"Vectorview-grad_norm\"\n        else:\n            layout_name = \"Vectorview-grad\"\n    elif has_neuromag_122_grad:\n        layout_name = \"Neuromag_122\"\n    elif (has_eeg_coils_only and ch_type in [None, \"eeg\"]) or (\n        has_eeg_coils_and_meg and ch_type == \"eeg\"\n    ):\n        if not isinstance(info, dict | Info):\n            raise RuntimeError(\n                \"Cannot make EEG layout, no measurement info \"\n                \"was passed to `find_layout`\"\n            )\n        return make_eeg_layout(info, exclude=exclude)\n    elif has_csd_coils and ch_type in [None, \"csd\"]:\n        return make_eeg_layout(info, exclude=exclude, csd=True)\n    elif has_4D_mag:\n        layout_name = \"magnesWH3600\"\n    elif has_CTF_grad:\n        layout_name = \"CTF-275\"\n    elif n_kit_grads > 0:\n        layout_name = _find_kit_layout(info, n_kit_grads)\n\n    # If no known layout is found, fall back on automatic layout\n    if layout_name is None:\n        picks = _picks_to_idx(info, \"data\", exclude=(), with_ref_meg=False)\n        ch_names = [info[\"ch_names\"][pick] for pick in picks]\n        xy = _find_topomap_coords(info, picks=picks, ignore_overlap=True)\n        return generate_2d_layout(xy, ch_names=ch_names, name=\"custom\", normalize=True)\n\n    layout = read_layout(fname=layout_name)\n    if not is_old_vv:\n        layout.names = _clean_names(layout.names, remove_whitespace=True)\n    if has_CTF_grad:\n        layout.names = _clean_names(layout.names, before_dash=True)\n\n    # Apply mask for excluded channels.\n    if exclude == \"bads\":\n        exclude = info[\"bads\"]\n    idx = [ii for ii, name in enumerate(layout.names) if name not in exclude]\n    layout.names = [layout.names[ii] for ii in idx]\n    layout.pos = layout.pos[idx]\n    layout.ids = layout.ids[idx]\n\n    return layout", "metadata": {}}
{"_id": "mne_mne_channels/layout.py_generate_2d_layout_code", "title": "generate_2d_layout", "text": "def generate_2d_layout(\n    xy,\n    w=0.07,\n    h=0.05,\n    pad=0.02,\n    ch_names=None,\n    ch_indices=None,\n    name=\"ecog\",\n    bg_image=None,\n    normalize=True,\n):\n    \"\"\"Generate a custom 2D layout from xy points.\n\n    Generates a 2-D layout for plotting with plot_topo methods and\n    functions. XY points will be normalized between 0 and 1, where\n    normalization extremes will be either the min/max of xy, or\n    the width/height of bg_image.\n\n    Parameters\n    ----------\n    xy : ndarray, shape (N, 2)\n        The xy coordinates of sensor locations.\n    w : float\n        The width of each sensor's axis (between 0 and 1).\n    h : float\n        The height of each sensor's axis (between 0 and 1).\n    pad : float\n        Portion of the box to reserve for padding. The value can range between\n        0.0 (boxes will touch, default) to 1.0 (boxes consist of only padding).\n    ch_names : list\n        The names of each channel. Must be a list of strings, with one\n        string per channel.\n    ch_indices : list\n        Index of each channel - must be a collection of unique integers,\n        one index per channel.\n    name : str\n        The name of this layout type.\n    bg_image : path-like | ndarray\n        The image over which sensor axes will be plotted. Either a path to an\n        image file, or an array that can be plotted with plt.imshow. If\n        provided, xy points will be normalized by the width/height of this\n        image. If not, xy points will be normalized by their own min/max.\n    normalize : bool\n        Whether to normalize the coordinates to run from 0 to 1. Defaults to\n        True.\n\n    Returns\n    -------\n    layout : Layout\n        A Layout object that can be plotted with plot_topo\n        functions and methods.\n\n    See Also\n    --------\n    make_eeg_layout, make_grid_layout\n\n    Notes\n    -----\n    .. versionadded:: 0.9.0\n    \"\"\"\n    import matplotlib.pyplot as plt\n\n    if ch_indices is None:\n        ch_indices = np.arange(xy.shape[0])\n    if ch_names is None:\n        ch_names = list(map(str, ch_indices))\n\n    if len(ch_names) != len(ch_indices):\n        raise ValueError(\"# channel names and indices must be equal\")\n    if len(ch_names) != len(xy):\n        raise ValueError(\"# channel names and xy vals must be equal\")\n\n    x, y = xy.copy().astype(float).T\n\n    # Normalize xy to 0-1\n    if bg_image is not None:\n        # Normalize by image dimensions\n        img = plt.imread(bg_image) if isinstance(bg_image, str) else bg_image\n        x /= img.shape[1]\n        y /= img.shape[0]\n    elif normalize:\n        # Normalize x and y by their maxes\n        for i_dim in [x, y]:\n            i_dim -= i_dim.min(0)\n            i_dim /= i_dim.max(0) - i_dim.min(0)\n\n    # Create box and pos variable\n    box = _box_size(np.vstack([x, y]).T, padding=pad)\n    box = (0, 0, box[0], box[1])\n    w, h = (np.array([i] * x.shape[0]) for i in [w, h])\n    loc_params = np.vstack([x, y, w, h]).T\n\n    layout = Layout(box, loc_params, ch_names, ch_indices, name)\n    return layout", "metadata": {}}
{"_id": "mne_mne_channels/layout.py_copy_code", "title": "copy", "text": "def copy(self):\n        \"\"\"Return a copy of the layout.\n\n        Returns\n        -------\n        layout : instance of Layout\n            A deepcopy of the layout.\n\n        Notes\n        -----\n        .. versionadded:: 1.7\n        \"\"\"\n        return deepcopy(self)", "metadata": {}}
{"_id": "mne_mne_channels/layout.py_save_code", "title": "save", "text": "def save(self, fname, overwrite=False):\n        \"\"\"Save Layout to disk.\n\n        Parameters\n        ----------\n        fname : path-like\n            The file name (e.g. ``'my_layout.lout'``).\n        overwrite : bool\n            If True, overwrites the destination file if it exists.\n\n        See Also\n        --------\n        read_layout\n        \"\"\"\n        x = self.pos[:, 0]\n        y = self.pos[:, 1]\n        width = self.pos[:, 2]\n        height = self.pos[:, 3]\n        fname = _check_fname(fname, overwrite=overwrite, name=fname)\n        if fname.suffix == \".lout\":\n            out_str = \"{:8.2f} {:8.2f} {:8.2f} {:8.2f}\\n\".format(*self.box)\n        elif fname.suffix == \".lay\":\n            out_str = \"\"\n        else:\n            raise ValueError(\"Unknown layout type. Should be of type .lout or .lay.\")\n\n        for ii in range(x.shape[0]):\n            out_str += (\n                f\"{self.ids[ii]:03d} {x[ii]:8.2f} {y[ii]:8.2f} \"\n                f\"{width[ii]:8.2f} {height[ii]:8.2f} {self.names[ii]}\\n\"\n            )\n\n        f = open(fname, \"w\")\n        f.write(out_str)\n        f.close()", "metadata": {}}
{"_id": "mne_mne_channels/layout.py_plot_code", "title": "plot", "text": "def plot(self, picks=None, show_axes=False, show=True):\n        \"\"\"Plot the sensor positions.\n\n        Parameters\n        ----------\n        %(picks_nostr)s\n        show_axes : bool\n            Show layout axes if True. Defaults to False.\n        show : bool\n            Show figure if True. Defaults to True.\n\n        Returns\n        -------\n        fig : instance of matplotlib.figure.Figure\n            Figure containing the sensor topography.\n\n        Notes\n        -----\n        .. versionadded:: 0.12.0\n        \"\"\"\n        return plot_layout(self, picks=picks, show_axes=show_axes, show=show)", "metadata": {}}
{"_id": "mne_mne_channels/layout.py_pick_code", "title": "pick", "text": "def pick(self, picks=None, exclude=(), *, verbose=None):\n        \"\"\"Pick a subset of channels.\n\n        Parameters\n        ----------\n        %(picks_layout)s\n        exclude : str | int | array-like of str or int\n            Set of channels to exclude, only used when ``picks`` is set to ``'all'`` or\n            ``None``. Exclude will not drop channels explicitly provided in ``picks``.\n        %(verbose)s\n\n        Returns\n        -------\n        layout : instance of Layout\n            The modified layout.\n\n        Notes\n        -----\n        .. versionadded:: 1.7\n        \"\"\"\n        # TODO: all the picking functions operates on an 'info' object which is missing\n        # for a layout, thus we have to do the extra work here. The logic below can be\n        # replaced when https://github.com/mne-tools/mne-python/issues/11913 is solved.\n        if (isinstance(picks, str) and picks == \"all\") or (picks is None):\n            picks = deepcopy(self.names)\n            apply_exclude = True\n        elif isinstance(picks, str):\n            picks = [picks]\n            apply_exclude = False\n        elif isinstance(picks, slice):\n            try:\n                picks = np.arange(len(self.names))[picks]\n            except TypeError:\n                raise TypeError(\n                    \"If a slice is provided, it must be a slice of integers.\"\n                )\n            apply_exclude = False\n        else:\n            try:\n                picks = [_ensure_int(picks)]\n            except TypeError:\n                picks = (\n                    list(picks) if isinstance(picks, tuple | set) else deepcopy(picks)\n                )\n            apply_exclude = False\n        if apply_exclude:\n            if isinstance(exclude, str):\n                exclude = [exclude]\n            else:\n                try:\n                    exclude = [_ensure_int(exclude)]\n                except TypeError:\n                    exclude = (\n                        list(exclude)\n                        if isinstance(exclude, tuple | set)\n                        else deepcopy(exclude)\n                    )\n        for var, var_name in ((picks, \"picks\"), (exclude, \"exclude\")):\n            if var_name == \"exclude\" and not apply_exclude:\n                continue\n            if not isinstance(var, list | tuple | set | np.ndarray):\n                raise TypeError(\n                    f\"'{var_name}' must be a list, tuple, set or ndarray. \"\n                    f\"Got {type(var)} instead.\"\n                )\n            if isinstance(var, np.ndarray) and var.ndim != 1:\n                raise ValueError(\n                    f\"'{var_name}' must be a 1D array-like. Got {var.ndim}D instead.\"\n                )\n            for k, elt in enumerate(var):\n                if isinstance(elt, str) and elt in self.names:\n                    var[k] = self.names.index(elt)\n                    continue\n                elif isinstance(elt, str):\n                    raise ValueError(\n                        f\"The channel name {elt} provided in {var_name} does not match \"\n                        \"any channels from the layout.\"\n                    )\n                try:\n                    var[k] = _ensure_int(elt)\n                except TypeError:\n                    raise TypeError(\n                        f\"All elements in '{var_name}' must be integers or strings.\"\n                    )\n                if not (0 <= var[k] < len(self.names)):\n                    raise ValueError(\n                        f\"The value {elt} provided in {var_name} does not match any \"\n                        f\"channels from the layout. The layout has {len(self.names)} \"\n                        \"channels.\"\n                    )\n            if len(var) != len(set(var)):\n                warn(\n                    f\"The provided '{var_name}' has duplicates which will be ignored.\",\n                    RuntimeWarning,\n                )\n        picks = picks.astype(int) if isinstance(picks, np.ndarray) else picks\n        exclude = exclude.astype(int) if isinstance(exclude, np.ndarray) else exclude\n        if apply_exclude:\n            picks = np.array(list(set(picks) - set(exclude)), dtype=int)\n            if len(picks) == 0:\n                raise RuntimeError(\n                    \"The channel selection yielded no remaining channels. Please edit \"\n                    \"the arguments 'picks' and 'exclude' to include at least one \"\n                    \"channel.\"\n                )\n        else:\n            picks = np.array(list(set(picks)), dtype=int)\n        self.pos = self.pos[picks]\n        self.ids = self.ids[picks]\n        self.names = [self.names[k] for k in picks]\n        return self", "metadata": {}}
{"_id": "mne_mne_channels/channels.py_equalize_channels_code", "title": "equalize_channels", "text": "def equalize_channels(instances, copy=True, verbose=None):\n    \"\"\"Equalize channel picks and ordering across multiple MNE-Python objects.\n\n    First, all channels that are not common to each object are dropped. Then,\n    using the first object in the list as a template, the channels of each\n    object are re-ordered to match the template. The end result is that all\n    given objects define the same channels, in the same order.\n\n    Parameters\n    ----------\n    instances : list\n        A list of MNE-Python objects to equalize the channels for. Objects can\n        be of type Raw, Epochs, Evoked, AverageTFR, Forward, Covariance,\n        CrossSpectralDensity or Info.\n    copy : bool\n        When dropping and/or re-ordering channels, an object will be copied\n        when this parameter is set to ``True``. When set to ``False`` (the\n        default) the dropping and re-ordering of channels happens in-place.\n\n        .. versionadded:: 0.20.0\n    %(verbose)s\n\n    Returns\n    -------\n    equalized_instances : list\n        A list of MNE-Python objects that have the same channels defined in the\n        same order.\n\n    See Also\n    --------\n    mne.channels.unify_bad_channels\n    mne.channels.rename_channels\n    mne.channels.combine_channels\n    \"\"\"\n    from ..cov import Covariance\n    from ..epochs import BaseEpochs\n    from ..evoked import Evoked\n    from ..forward import Forward\n    from ..io import BaseRaw\n    from ..time_frequency import BaseTFR, CrossSpectralDensity\n\n    # Instances need to have a `ch_names` attribute and a `pick_channels`\n    # method that supports `ordered=True`.\n    allowed_types = (\n        BaseRaw,\n        BaseEpochs,\n        Evoked,\n        BaseTFR,\n        Forward,\n        Covariance,\n        CrossSpectralDensity,\n        Info,\n    )\n    allowed_types_str = (\n        \"Raw, Epochs, Evoked, TFR, Forward, Covariance, CrossSpectralDensity or Info\"\n    )\n    for inst in instances:\n        _validate_type(\n            inst, allowed_types, \"Instances to be modified\", allowed_types_str\n        )\n\n    chan_template = instances[0].ch_names\n    logger.info(\"Identifying common channels ...\")\n    channels = [set(inst.ch_names) for inst in instances]\n    common_channels = set(chan_template).intersection(*channels)\n    all_channels = set(chan_template).union(*channels)\n    dropped = list(set(all_channels - common_channels))\n\n    # Preserve the order of chan_template\n    order = np.argsort([chan_template.index(ch) for ch in common_channels])\n    common_channels = np.array(list(common_channels))[order].tolist()\n\n    # Update all instances to match the common_channels list\n    reordered = False\n    equalized_instances = []\n    for inst in instances:\n        # Only perform picking when needed\n        if inst.ch_names != common_channels:\n            if isinstance(inst, Info):\n                sel = pick_channels(\n                    inst.ch_names, common_channels, exclude=[], ordered=True\n                )\n                inst = pick_info(inst, sel, copy=copy, verbose=False)\n            else:\n                if copy:\n                    inst = inst.copy()\n                # TODO change to .pick() once CSD, Cov, and Fwd have `.pick()` methods\n                inst.pick_channels(common_channels, ordered=True)\n            if len(inst.ch_names) == len(common_channels):\n                reordered = True\n        equalized_instances.append(inst)\n\n    if dropped:\n        logger.info(f\"Dropped the following channels:\\n{dropped}\")\n    elif reordered:\n        logger.info(\"Channels have been re-ordered.\")\n\n    return equalized_instances", "metadata": {}}
{"_id": "mne_mne_channels/channels.py_unify_bad_channels_code", "title": "unify_bad_channels", "text": "def unify_bad_channels(insts):\n    \"\"\"Unify bad channels across a list of instances.\n\n    All instances must be of the same type and have matching channel names and channel\n    order. The ``.info[\"bads\"]`` of each instance will be set to the union of\n    ``.info[\"bads\"]`` across all instances.\n\n    Parameters\n    ----------\n    insts : list\n        List of instances (:class:`~mne.io.Raw`, :class:`~mne.Epochs`,\n        :class:`~mne.Evoked`, :class:`~mne.time_frequency.Spectrum`,\n        :class:`~mne.time_frequency.EpochsSpectrum`) across which to unify bad channels.\n\n    Returns\n    -------\n    insts : list\n        List of instances with bad channels unified across instances.\n\n    See Also\n    --------\n    mne.channels.equalize_channels\n    mne.channels.rename_channels\n    mne.channels.combine_channels\n\n    Notes\n    -----\n    This function modifies the instances in-place.\n\n    .. versionadded:: 1.6\n    \"\"\"\n    from ..epochs import Epochs\n    from ..evoked import Evoked\n    from ..io import BaseRaw\n    from ..time_frequency.spectrum import BaseSpectrum\n\n    # ensure input is list-like\n    _validate_type(insts, (list, tuple), \"insts\")\n    # ensure non-empty\n    if len(insts) == 0:\n        raise ValueError(\"insts must not be empty\")\n    # ensure all insts are MNE objects, and all the same type\n    inst_type = type(insts[0])\n    valid_types = (BaseRaw, Epochs, Evoked, BaseSpectrum)\n    for inst in insts:\n        _validate_type(inst, valid_types, \"each object in insts\")\n        if type(inst) is not inst_type:\n            raise ValueError(\"All insts must be the same type\")\n\n    # ensure all insts have the same channels and channel order\n    ch_names = insts[0].ch_names\n    for inst in insts[1:]:\n        dif = set(inst.ch_names) ^ set(ch_names)\n        if len(dif):\n            raise ValueError(\n                \"Channels do not match across the objects in insts. Consider calling \"\n                \"equalize_channels before calling this function.\"\n            )\n        elif inst.ch_names != ch_names:\n            raise ValueError(\n                \"Channel names are sorted differently across instances. Please use \"\n                \"mne.channels.equalize_channels.\"\n            )\n\n    # collect bads as dict keys so that insertion order is preserved, then cast to list\n    all_bads = dict()\n    for inst in insts:\n        all_bads.update(dict.fromkeys(inst.info[\"bads\"]))\n    all_bads = list(all_bads)\n\n    # update bads on all instances\n    for inst in insts:\n        inst.info[\"bads\"] = all_bads\n\n    return insts", "metadata": {}}
{"_id": "mne_mne_channels/channels.py_rename_channels_code", "title": "rename_channels", "text": "def rename_channels(info, mapping, allow_duplicates=False, *, verbose=None):\n    \"\"\"Rename channels.\n\n    Parameters\n    ----------\n    %(info_not_none)s Note: modified in place.\n    %(mapping_rename_channels_duplicates)s\n    %(verbose)s\n\n    See Also\n    --------\n    mne.channels.equalize_channels\n    mne.channels.unify_bad_channels\n    mne.channels.combine_channels\n    \"\"\"\n    _validate_type(info, Info, \"info\")\n    info._check_consistency()\n    bads = list(info[\"bads\"])  # make our own local copies\n    ch_names = list(info[\"ch_names\"])\n\n    # first check and assemble clean mappings of index and name\n    if isinstance(mapping, dict):\n        _check_dict_keys(\n            mapping,\n            ch_names,\n            key_description=\"channel name(s)\",\n            valid_key_source=\"info\",\n        )\n        new_names = [\n            (ch_names.index(ch_name), new_name) for ch_name, new_name in mapping.items()\n        ]\n    elif callable(mapping):\n        new_names = [(ci, mapping(ch_name)) for ci, ch_name in enumerate(ch_names)]\n    else:\n        raise ValueError(f\"mapping must be callable or dict, not {type(mapping)}\")\n\n    # check we got all strings out of the mapping\n    for new_name in new_names:\n        _validate_type(new_name[1], \"str\", \"New channel mappings\")\n\n    # do the remapping locally\n    for c_ind, new_name in new_names:\n        for bi, bad in enumerate(bads):\n            if bad == ch_names[c_ind]:\n                bads[bi] = new_name\n        ch_names[c_ind] = new_name\n\n    # check that all the channel names are unique\n    if len(ch_names) != len(np.unique(ch_names)) and not allow_duplicates:\n        raise ValueError(\"New channel names are not unique, renaming failed\")\n\n    # do the remapping in info\n    info[\"bads\"] = []\n    ch_names_mapping = dict()\n    for ch, ch_name in zip(info[\"chs\"], ch_names):\n        ch_names_mapping[ch[\"ch_name\"]] = ch_name\n        ch[\"ch_name\"] = ch_name\n    # .get b/c fwd info omits it\n    _rename_comps(info.get(\"comps\", []), ch_names_mapping)\n    if \"projs\" in info:  # fwd might omit it\n        for proj in info[\"projs\"]:\n            proj[\"data\"][\"col_names\"][:] = _rename_list(\n                proj[\"data\"][\"col_names\"], ch_names_mapping\n            )\n    info._update_redundant()\n    info[\"bads\"] = bads\n    info._check_consistency()", "metadata": {}}
{"_id": "mne_mne_channels/channels.py_get_builtin_ch_adjacencies_code", "title": "get_builtin_ch_adjacencies", "text": "def get_builtin_ch_adjacencies(*, descriptions=False):\n    \"\"\"Get a list of all FieldTrip neighbor definitions shipping with MNE.\n\n    The names of the these neighbor definitions can be passed to\n    :func:`read_ch_adjacency`.\n\n    Parameters\n    ----------\n    descriptions : bool\n        Whether to return not only the neighbor definition names, but also\n        their corresponding descriptions. If ``True``, a list of tuples is\n        returned, where the first tuple element is the neighbor definition name\n        and the second is the description. If ``False`` (default), only the\n        names are returned.\n\n    Returns\n    -------\n    neighbor_name : list of str | list of tuple\n        If ``descriptions=False``, the names of all builtin FieldTrip neighbor\n        definitions that can be loaded directly via :func:`read_ch_adjacency`.\n\n        If ``descriptions=True``, a list of tuples ``(name, description)``.\n\n    Notes\n    -----\n    .. versionadded:: 1.1\n    \"\"\"\n    if descriptions:\n        return sorted(\n            [(m.name, m.description) for m in _BUILTIN_CHANNEL_ADJACENCIES],\n            key=lambda x: x[0].casefold(),  # only sort based on name\n        )\n    else:\n        return sorted([m.name for m in _BUILTIN_CHANNEL_ADJACENCIES], key=str.casefold)", "metadata": {}}
{"_id": "mne_mne_channels/channels.py_read_ch_adjacency_code", "title": "read_ch_adjacency", "text": "def read_ch_adjacency(fname, picks=None):\n    \"\"\"Read a channel adjacency (\"neighbors\") file that ships with MNE.\n\n    More information on these neighbor definitions can be found on the related\n    `FieldTrip documentation pages\n    <http://www.fieldtriptoolbox.org/template/neighbours/>`__.\n\n    Parameters\n    ----------\n    fname : path-like | str\n        The path to the file to load, or the name of a channel adjacency\n        matrix that ships with MNE-Python.\n\n        .. note::\n            You can retrieve the names of all\n            built-in channel adjacencies via\n            :func:`mne.channels.get_builtin_ch_adjacencies`.\n    %(picks_all_notypes)s\n\n    Returns\n    -------\n    ch_adjacency : scipy.sparse.csr_array, shape (n_channels, n_channels)\n        The adjacency matrix.\n    ch_names : list\n        The list of channel names present in adjacency matrix.\n\n    See Also\n    --------\n    get_builtin_ch_adjacencies\n    mne.viz.plot_ch_adjacency\n    find_ch_adjacency\n    mne.stats.combine_adjacency\n\n    Notes\n    -----\n    If the neighbor definition you need is not shipped by MNE-Python,\n    you may use :func:`find_ch_adjacency` to compute the\n    adjacency matrix based on your 2D sensor locations.\n\n    Note that depending on your use case, you may need to additionally use\n    :func:`mne.stats.combine_adjacency` to prepare a final \"adjacency\"\n    to pass to the eventual function.\n    \"\"\"\n    if op.isabs(fname):\n        fname = str(\n            _check_fname(\n                fname=fname,\n                overwrite=\"read\",\n                must_exist=True,\n            )\n        )\n    else:  # built-in FieldTrip neighbors\n        ch_adj_name = fname\n        del fname\n        if ch_adj_name.endswith(\"_neighb.mat\"):  # backward-compat\n            ch_adj_name = ch_adj_name.replace(\"_neighb.mat\", \"\")\n\n        if ch_adj_name not in get_builtin_ch_adjacencies():\n            raise ValueError(\n                f\"No built-in channel adjacency matrix found with name: \"\n                f\"{ch_adj_name}. Valid names are: \"\n                f\"{', '.join(get_builtin_ch_adjacencies())}\"\n            )\n\n        ch_adj = [a for a in _BUILTIN_CHANNEL_ADJACENCIES if a.name == ch_adj_name][0]\n        fname = ch_adj.fname\n        templates_dir = Path(__file__).resolve().parent / \"data\" / \"neighbors\"\n        fname = str(\n            _check_fname(  # only needed to convert to a string\n                fname=templates_dir / fname,\n                overwrite=\"read\",\n                must_exist=True,\n            )\n        )\n\n    nb = loadmat(fname)[\"neighbours\"]\n    ch_names = _recursive_flatten(nb[\"label\"], str)\n    temp_info = create_info(ch_names, 1.0)\n    picks = _picks_to_idx(temp_info, picks, none=\"all\")\n    neighbors = [_recursive_flatten(c, str) for c in nb[\"neighblabel\"].flatten()]\n    assert len(ch_names) == len(neighbors)\n    adjacency = _ch_neighbor_adjacency(ch_names, neighbors)\n    # picking before constructing matrix is buggy\n    adjacency = adjacency[picks][:, picks]\n    ch_names = [ch_names[p] for p in picks]\n\n    return adjacency, ch_names", "metadata": {}}
{"_id": "mne_mne_channels/channels.py_find_ch_adjacency_code", "title": "find_ch_adjacency", "text": "def find_ch_adjacency(info, ch_type):\n    \"\"\"Find the adjacency matrix for the given channels.\n\n    This function tries to infer the appropriate adjacency matrix template\n    for the given channels. If a template is not found, the adjacency matrix\n    is computed using Delaunay triangulation based on 2D sensor locations.\n\n    Parameters\n    ----------\n    %(info_not_none)s\n    ch_type : str | None\n        The channel type for computing the adjacency matrix. Currently\n        supports ``'mag'``, ``'grad'``, ``'eeg'`` and ``None``.\n        If ``None``, the info must contain only one channel type.\n\n    Returns\n    -------\n    ch_adjacency : scipy.sparse.csr_array, shape (n_channels, n_channels)\n        The adjacency matrix.\n    ch_names : list\n        The list of channel names present in adjacency matrix.\n\n    See Also\n    --------\n    mne.viz.plot_ch_adjacency\n    mne.stats.combine_adjacency\n    get_builtin_ch_adjacencies\n    read_ch_adjacency\n\n    Notes\n    -----\n    .. versionadded:: 0.15\n\n    Automatic detection of an appropriate adjacency matrix template only\n    works for MEG data at the moment. This means that the adjacency matrix\n    is always computed for EEG data and never loaded from a template file. If\n    you want to load a template for a given montage use\n    :func:`read_ch_adjacency` directly.\n\n    .. warning::\n        If Delaunay triangulation is used to calculate the adjacency matrix it\n        may yield partially unexpected results (e.g., include unwanted edges\n        between non-adjacent sensors). Therefore, it is recommended to check\n        (and, if necessary, manually modify) the result by inspecting it\n        via :func:`mne.viz.plot_ch_adjacency`.\n\n    Note that depending on your use case, you may need to additionally use\n    :func:`mne.stats.combine_adjacency` to prepare a final \"adjacency\"\n    to pass to the eventual function.\n    \"\"\"\n    from ..io.kit.constants import KIT_NEIGHBORS\n\n    if ch_type is None:\n        picks = channel_indices_by_type(info)\n        if sum([len(p) != 0 for p in picks.values()]) != 1:\n            raise ValueError(\n                \"info must contain only one channel type if ch_type is None.\"\n            )\n        ch_type = channel_type(info, 0)\n    else:\n        _check_option(\"ch_type\", ch_type, [\"mag\", \"grad\", \"eeg\"])\n    (\n        has_vv_mag,\n        has_vv_grad,\n        is_old_vv,\n        has_4D_mag,\n        ctf_other_types,\n        has_CTF_grad,\n        n_kit_grads,\n        has_any_meg,\n        has_eeg_coils,\n        has_eeg_coils_and_meg,\n        has_eeg_coils_only,\n        has_neuromag_122_grad,\n        has_csd_coils,\n    ) = _get_ch_info(info)\n    conn_name = None\n    if has_vv_mag and ch_type == \"mag\":\n        conn_name = \"neuromag306mag\"\n    elif has_vv_grad and ch_type == \"grad\":\n        conn_name = \"neuromag306planar\"\n    elif has_4D_mag:\n        if \"MEG 248\" in info[\"ch_names\"]:\n            idx = info[\"ch_names\"].index(\"MEG 248\")\n            grad = info[\"chs\"][idx][\"coil_type\"] == FIFF.FIFFV_COIL_MAGNES_GRAD\n            mag = info[\"chs\"][idx][\"coil_type\"] == FIFF.FIFFV_COIL_MAGNES_MAG\n            if ch_type == \"grad\" and grad:\n                conn_name = \"bti248grad\"\n            elif ch_type == \"mag\" and mag:\n                conn_name = \"bti248\"\n        elif \"MEG 148\" in info[\"ch_names\"] and ch_type == \"mag\":\n            idx = info[\"ch_names\"].index(\"MEG 148\")\n            if info[\"chs\"][idx][\"coil_type\"] == FIFF.FIFFV_COIL_MAGNES_MAG:\n                conn_name = \"bti148\"\n    elif has_CTF_grad and ch_type == \"mag\":\n        if info[\"nchan\"] < 100:\n            conn_name = \"ctf64\"\n        elif info[\"nchan\"] > 200:\n            conn_name = \"ctf275\"\n        else:\n            conn_name = \"ctf151\"\n    elif n_kit_grads > 0:\n        conn_name = KIT_NEIGHBORS.get(info[\"kit_system_id\"])\n\n    if conn_name is not None:\n        logger.info(f\"Reading adjacency matrix for {conn_name}.\")\n        adjacency, ch_names = read_ch_adjacency(conn_name)\n        if conn_name.startswith(\"neuromag\") and info[\"ch_names\"][0].startswith(\"MEG \"):\n            ch_names = [ch_name.replace(\"MEG\", \"MEG \") for ch_name in ch_names]\n        return adjacency, ch_names\n    logger.info(\n        \"Could not find a adjacency matrix for the data. \"\n        \"Computing adjacency based on Delaunay triangulations.\"\n    )\n    return _compute_ch_adjacency(info, ch_type)", "metadata": {}}
{"_id": "mne_mne_channels/channels.py_fix_mag_coil_types_code", "title": "fix_mag_coil_types", "text": "def fix_mag_coil_types(info, use_cal=False):\n    \"\"\"Fix magnetometer coil types.\n\n    Parameters\n    ----------\n    %(info_not_none)s Corrections are done in-place.\n    use_cal : bool\n        If True, further refine the check for old coil types by checking\n        ``info['chs'][ii]['cal']``.\n\n    Notes\n    -----\n    This function changes magnetometer coil types 3022 (T1: SQ20483N) and\n    3023 (T2: SQ20483-A) to 3024 (T3: SQ20950N) in the channel definition\n    records in the info structure.\n\n    Neuromag Vectorview systems can contain magnetometers with two\n    different coil sizes (3022 and 3023 vs. 3024). The systems\n    incorporating coils of type 3024 were introduced last and are used at\n    the majority of MEG sites. At some sites with 3024 magnetometers,\n    the data files have still defined the magnetometers to be of type\n    3022 to ensure compatibility with older versions of Neuromag software.\n    In the MNE software as well as in the present version of Neuromag\n    software coil type 3024 is fully supported. Therefore, it is now safe\n    to upgrade the data files to use the true coil type.\n\n    .. note:: The effect of the difference between the coil sizes on the\n              current estimates computed by the MNE software is very small.\n              Therefore the use of ``fix_mag_coil_types`` is not mandatory.\n    \"\"\"\n    old_mag_inds = _get_T1T2_mag_inds(info, use_cal)\n    n_mag = len(pick_types(info, meg=\"mag\", exclude=[]))\n    for ii in old_mag_inds:\n        info[\"chs\"][ii][\"coil_type\"] = FIFF.FIFFV_COIL_VV_MAG_T3\n    logger.info(f\"{len(old_mag_inds)} of {n_mag} magnetometer types replaced with T3.\")\n    info._check_consistency()", "metadata": {}}
{"_id": "mne_mne_channels/channels.py_make_1020_channel_selections_code", "title": "make_1020_channel_selections", "text": "def make_1020_channel_selections(info, midline=\"z\", *, return_ch_names=False):\n    \"\"\"Map hemisphere names to corresponding EEG channel names or indices.\n\n    This function uses a simple heuristic to separate channel names into three\n    Region of Interest-based selections: ``Left``, ``Midline`` and ``Right``.\n\n    The heuristic is that any of the channel names ending\n    with odd numbers are filed under ``Left``; those ending with even numbers\n    are filed under ``Right``; and those ending with the character(s) specified\n    in ``midline`` are filed under ``Midline``. Other channels are ignored.\n\n    This is appropriate for 10/20, 10/10, 10/05, \u2026, sensor arrangements, but\n    not for other naming conventions.\n\n    Parameters\n    ----------\n    %(info_not_none)s If channel locations are present, the channel lists will\n        be sorted from posterior to anterior; otherwise, the order specified in\n        ``info[\"ch_names\"]`` will be kept.\n    midline : str\n        Names ending in any of these characters are stored under the\n        ``Midline`` key. Defaults to ``'z'``. Capitalization is ignored.\n    return_ch_names : bool\n        Whether to return channel names instead of channel indices.\n\n        .. versionadded:: 1.4.0\n\n    Returns\n    -------\n    selections : dict\n        A dictionary mapping from region of interest name to a list of channel\n        indices (if ``return_ch_names=False``) or to a list of channel names\n        (if ``return_ch_names=True``).\n    \"\"\"\n    _validate_type(info, \"info\")\n\n    try:\n        from .layout import find_layout\n\n        layout = find_layout(info)\n        pos = layout.pos\n        ch_names = layout.names\n    except RuntimeError:  # no channel positions found\n        ch_names = info[\"ch_names\"]\n        pos = None\n\n    selections = dict(Left=[], Midline=[], Right=[])\n    for pick, channel in enumerate(ch_names):\n        last_char = channel[-1].lower()  # in 10/20, last char codes hemisphere\n        if last_char in midline:\n            selection = \"Midline\"\n        elif last_char.isdigit():\n            selection = \"Left\" if int(last_char) % 2 else \"Right\"\n        else:  # ignore the channel\n            continue\n        selections[selection].append(pick)\n\n    if pos is not None:\n        # sort channels from front to center\n        # (y-coordinate of the position info in the layout)\n        selections = {\n            selection: np.array(picks)[pos[picks, 1].argsort()]\n            for selection, picks in selections.items()\n        }\n\n    # convert channel indices to names if requested\n    if return_ch_names:\n        for selection, ch_indices in selections.items():\n            selections[selection] = [info.ch_names[idx] for idx in ch_indices]\n\n    return selections", "metadata": {}}
{"_id": "mne_mne_channels/channels.py_combine_channels_code", "title": "combine_channels", "text": "def combine_channels(\n    inst, groups, method=\"mean\", keep_stim=False, drop_bad=False, verbose=None\n):\n    \"\"\"Combine channels based on specified channel grouping.\n\n    Parameters\n    ----------\n    inst : instance of Raw, Epochs, or Evoked\n        An MNE-Python object to combine the channels for. The object can be of\n        type Raw, Epochs, or Evoked.\n    groups : dict\n        Specifies which channels are aggregated into a single channel, with\n        aggregation method determined by the ``method`` parameter. One new\n        pseudo-channel is made per dict entry; the dict values must be lists of\n        picks (integer indices of ``ch_names``). For example::\n\n            groups=dict(Left=[1, 2, 3, 4], Right=[5, 6, 7, 8])\n\n        Note that within a dict entry all channels must have the same type.\n    method : str | callable\n        Which method to use to combine channels. If a :class:`str`, must be one\n        of 'mean', 'median', or 'std' (standard deviation). If callable, the\n        callable must accept one positional input (data of shape ``(n_channels,\n        n_times)``, or ``(n_epochs, n_channels, n_times)``) and return an\n        :class:`array <numpy.ndarray>` of shape ``(n_times,)``, or ``(n_epochs,\n        n_times)``. For example with an instance of Raw or Evoked::\n\n            method = lambda data: np.mean(data, axis=0)\n\n        Another example with an instance of Epochs::\n\n            method = lambda data: np.median(data, axis=1)\n\n        Defaults to ``'mean'``.\n    keep_stim : bool\n        If ``True``, include stimulus channels in the resulting object.\n        Defaults to ``False``.\n    drop_bad : bool\n        If ``True``, drop channels marked as bad before combining. Defaults to\n        ``False``.\n    %(verbose)s\n\n    Returns\n    -------\n    combined_inst : instance of Raw, Epochs, or Evoked\n        An MNE-Python object of the same type as the input ``inst``, containing\n        one virtual channel for each group in ``groups`` (and, if ``keep_stim``\n        is ``True``, also containing stimulus channels).\n\n    See Also\n    --------\n    mne.channels.equalize_channels\n    mne.channels.rename_channels\n    mne.channels.unify_bad_channels\n    \"\"\"\n    from ..epochs import BaseEpochs, EpochsArray\n    from ..evoked import Evoked, EvokedArray\n    from ..io import BaseRaw, RawArray\n\n    ch_axis = 1 if isinstance(inst, BaseEpochs) else 0\n    ch_idx = list(range(inst.info[\"nchan\"]))\n    ch_names = inst.info[\"ch_names\"]\n    ch_types = inst.get_channel_types()\n    kwargs = dict()\n    if isinstance(inst, BaseEpochs):\n        kwargs[\"copy\"] = False\n    inst_data = inst.get_data(**kwargs)\n    groups = OrderedDict(deepcopy(groups))\n\n    # Convert string values of ``method`` into callables\n    # XXX Possibly de-duplicate with _make_combine_callable of mne/viz/utils.py\n    if isinstance(method, str):\n        method_dict = {\n            key: partial(getattr(np, key), axis=ch_axis)\n            for key in (\"mean\", \"median\", \"std\")\n        }\n        try:\n            method = method_dict[method]\n        except KeyError:\n            raise ValueError(\n                '\"method\" must be a callable, or one of \"mean\", '\n                f'\"median\", or \"std\"; got \"{method}\".'\n            )\n\n    # Instantiate channel info and data\n    new_ch_names, new_ch_types, new_data = [], [], []\n    if not isinstance(keep_stim, bool):\n        raise TypeError(f'\"keep_stim\" must be of type bool, not {type(keep_stim)}.')\n    if keep_stim:\n        stim_ch_idx = list(pick_types(inst.info, meg=False, stim=True))\n        if stim_ch_idx:\n            new_ch_names = [ch_names[idx] for idx in stim_ch_idx]\n            new_ch_types = [ch_types[idx] for idx in stim_ch_idx]\n            new_data = [np.take(inst_data, idx, axis=ch_axis) for idx in stim_ch_idx]\n        else:\n            warn(\"Could not find stimulus channels.\")\n\n    # Get indices of bad channels\n    ch_idx_bad = []\n    if not isinstance(drop_bad, bool):\n        raise TypeError(f'\"drop_bad\" must be of type bool, not {type(drop_bad)}.')\n    if drop_bad and inst.info[\"bads\"]:\n        ch_idx_bad = pick_channels(ch_names, inst.info[\"bads\"])\n\n    # Check correctness of combinations\n    for this_group, this_picks in groups.items():\n        # Check if channel indices are out of bounds\n        if not all(idx in ch_idx for idx in this_picks):\n            raise ValueError(\"Some channel indices are out of bounds.\")\n        # Check if heterogeneous sensor type combinations\n        this_ch_type = np.array(ch_types)[this_picks]\n        if len(set(this_ch_type)) > 1:\n            types = \", \".join(set(this_ch_type))\n            raise ValueError(\n                \"Cannot combine sensors of different types; \"\n                f'\"{this_group}\" contains types {types}.'\n            )\n        # Remove bad channels\n        these_bads = [idx for idx in this_picks if idx in ch_idx_bad]\n        this_picks = [idx for idx in this_picks if idx not in ch_idx_bad]\n        if these_bads:\n            logger.info(\n                f\"Dropped the following channels in group {this_group}: {these_bads}\"\n            )\n        #  Check if combining less than 2 channel\n        if len(set(this_picks)) < 2:\n            warn(\n                f'Less than 2 channels in group \"{this_group}\" when '\n                f'combining by method \"{method}\".'\n            )\n        # If all good create more detailed dict without bad channels\n        groups[this_group] = dict(picks=this_picks, ch_type=this_ch_type[0])\n\n    # Combine channels and add them to the new instance\n    for this_group, this_group_dict in groups.items():\n        new_ch_names.append(this_group)\n        new_ch_types.append(this_group_dict[\"ch_type\"])\n        this_picks = this_group_dict[\"picks\"]\n        this_data = np.take(inst_data, this_picks, axis=ch_axis)\n        new_data.append(method(this_data))\n    new_data = np.swapaxes(new_data, 0, ch_axis)\n    info = create_info(\n        sfreq=inst.info[\"sfreq\"], ch_names=new_ch_names, ch_types=new_ch_types\n    )\n    # create new instances and make sure to copy important attributes\n    if isinstance(inst, BaseRaw):\n        combined_inst = RawArray(new_data, info, first_samp=inst.first_samp)\n    elif isinstance(inst, BaseEpochs):\n        combined_inst = EpochsArray(\n            new_data,\n            info,\n            events=inst.events,\n            event_id=inst.event_id,\n            tmin=inst.times[0],\n            baseline=inst.baseline,\n        )\n        if inst.metadata is not None:\n            combined_inst.metadata = inst.metadata.copy()\n    elif isinstance(inst, Evoked):\n        combined_inst = EvokedArray(\n            new_data, info, tmin=inst.times[0], baseline=inst.baseline\n        )\n\n    return combined_inst", "metadata": {}}
{"_id": "mne_mne_channels/channels.py_read_vectorview_selection_code", "title": "read_vectorview_selection", "text": "def read_vectorview_selection(name, fname=None, info=None, verbose=None):\n    \"\"\"Read Neuromag Vector View channel selection from a file.\n\n    Parameters\n    ----------\n    name : str | list of str\n        Name of the selection. If a list, the selections are combined.\n        Supported selections are: ``'Vertex'``, ``'Left-temporal'``,\n        ``'Right-temporal'``, ``'Left-parietal'``, ``'Right-parietal'``,\n        ``'Left-occipital'``, ``'Right-occipital'``, ``'Left-frontal'`` and\n        ``'Right-frontal'``. Selections can also be matched and combined by\n        spcecifying common substrings. For example, ``name='temporal`` will\n        produce a combination of ``'Left-temporal'`` and ``'Right-temporal'``.\n    fname : path-like\n        Filename of the selection file (if ``None``, built-in selections are\n        used).\n    %(info)s Used to determine which channel naming convention to use, e.g.\n        ``'MEG 0111'`` (with space) for old Neuromag systems and ``'MEG0111'``\n        (without space) for new ones.\n    %(verbose)s\n\n    Returns\n    -------\n    sel : list of str\n        List with channel names in the selection.\n    \"\"\"\n    # convert name to list of string\n    if not isinstance(name, list | tuple):\n        name = [name]\n    if isinstance(info, Info):\n        picks = pick_types(info, meg=True, exclude=())\n        if len(picks) > 0 and \" \" not in info[\"ch_names\"][picks[0]]:\n            spacing = \"new\"\n        else:\n            spacing = \"old\"\n    elif info is not None:\n        raise TypeError(f\"info must be an instance of Info or None, not {type(info)}\")\n    else:  # info is None\n        spacing = \"old\"\n\n    # use built-in selections by default\n    if fname is None:\n        fname = op.join(op.dirname(__file__), \"..\", \"data\", \"mne_analyze.sel\")\n\n    fname = str(_check_fname(fname, must_exist=True, overwrite=\"read\"))\n\n    # use this to make sure we find at least one match for each name\n    name_found = {n: False for n in name}\n    with open(fname) as fid:\n        sel = []\n        for line in fid:\n            line = line.strip()\n            # skip blank lines and comments\n            if len(line) == 0 or line[0] == \"#\":\n                continue\n            # get the name of the selection in the file\n            pos = line.find(\":\")\n            if pos < 0:\n                logger.info('\":\" delimiter not found in selections file, skipping line')\n                continue\n            sel_name_file = line[:pos]\n            # search for substring match with name provided\n            for n in name:\n                if sel_name_file.find(n) >= 0:\n                    sel.extend(line[pos + 1 :].split(\"|\"))\n                    name_found[n] = True\n                    break\n\n    # make sure we found at least one match for each name\n    for n, found in name_found.items():\n        if not found:\n            raise ValueError(f'No match for selection name \"{n}\" found')\n\n    # make the selection a sorted list with unique elements\n    sel = list(set(sel))\n    sel.sort()\n    if spacing == \"new\":  # \"new\" or \"old\" by now, \"old\" is default\n        sel = [s.replace(\"MEG \", \"MEG\") for s in sel]\n    return sel", "metadata": {}}
{"_id": "mne_mne_channels/channels.py_set_eeg_reference_code", "title": "set_eeg_reference", "text": "def set_eeg_reference(\n        self,\n        ref_channels=\"average\",\n        projection=False,\n        ch_type=\"auto\",\n        forward=None,\n        *,\n        joint=False,\n        verbose=None,\n    ):\n        \"\"\"Specify which reference to use for EEG data.\n\n        Use this function to explicitly specify the desired reference for EEG.\n        This can be either an existing electrode or a new virtual channel.\n        This function will re-reference the data according to the desired\n        reference.\n\n        Parameters\n        ----------\n        %(ref_channels_set_eeg_reference)s\n        %(projection_set_eeg_reference)s\n        %(ch_type_set_eeg_reference)s\n        %(forward_set_eeg_reference)s\n        %(joint_set_eeg_reference)s\n        %(verbose)s\n\n        Returns\n        -------\n        inst : instance of Raw | Epochs | Evoked\n            Data with EEG channels re-referenced. If ``ref_channels='average'``\n            and ``projection=True`` a projection will be added instead of\n            directly re-referencing the data.\n        %(set_eeg_reference_see_also_notes)s\n        \"\"\"\n        return set_eeg_reference(\n            self,\n            ref_channels=ref_channels,\n            copy=False,\n            projection=projection,\n            ch_type=ch_type,\n            forward=forward,\n            joint=joint,\n        )[0]", "metadata": {}}
{"_id": "mne_mne_channels/channels.py_pick_types_code", "title": "pick_types", "text": "def pick_types(\n        self,\n        meg=False,\n        eeg=False,\n        stim=False,\n        eog=False,\n        ecg=False,\n        emg=False,\n        ref_meg=\"auto\",\n        *,\n        misc=False,\n        resp=False,\n        chpi=False,\n        exci=False,\n        ias=False,\n        syst=False,\n        seeg=False,\n        dipole=False,\n        gof=False,\n        bio=False,\n        ecog=False,\n        fnirs=False,\n        csd=False,\n        dbs=False,\n        temperature=False,\n        gsr=False,\n        eyetrack=False,\n        include=(),\n        exclude=\"bads\",\n        selection=None,\n        verbose=None,\n    ):\n        \"\"\"Pick some channels by type and names.\n\n        Parameters\n        ----------\n        %(pick_types_params)s\n        %(verbose)s\n\n        Returns\n        -------\n        inst : instance of Raw, Epochs, or Evoked\n            The modified instance.\n\n        See Also\n        --------\n        pick_channels\n\n        Notes\n        -----\n        .. versionadded:: 0.9.0\n        \"\"\"\n        idx = pick_types(\n            self.info,\n            meg=meg,\n            eeg=eeg,\n            stim=stim,\n            eog=eog,\n            ecg=ecg,\n            emg=emg,\n            ref_meg=ref_meg,\n            misc=misc,\n            resp=resp,\n            chpi=chpi,\n            exci=exci,\n            ias=ias,\n            syst=syst,\n            seeg=seeg,\n            dipole=dipole,\n            gof=gof,\n            bio=bio,\n            ecog=ecog,\n            fnirs=fnirs,\n            csd=csd,\n            dbs=dbs,\n            temperature=temperature,\n            gsr=gsr,\n            eyetrack=eyetrack,\n            include=include,\n            exclude=exclude,\n            selection=selection,\n        )\n\n        self._pick_drop_channels(idx)\n\n        # remove dropped channel types from reject and flat\n        if getattr(self, \"reject\", None) is not None:\n            # use list(self.reject) to avoid RuntimeError for changing dictionary size\n            # during iteration\n            for ch_type in list(self.reject):\n                if ch_type not in self:\n                    del self.reject[ch_type]\n\n        if getattr(self, \"flat\", None) is not None:\n            for ch_type in list(self.flat):\n                if ch_type not in self:\n                    del self.flat[ch_type]\n\n        return self", "metadata": {}}
{"_id": "mne_mne_channels/channels.py_pick_channels_code", "title": "pick_channels", "text": "def pick_channels(self, ch_names, ordered=True, *, verbose=None):\n        \"\"\"Pick some channels.\n\n        Parameters\n        ----------\n        ch_names : list\n            The list of channels to select.\n        %(ordered)s\n        %(verbose)s\n\n            .. versionadded:: 1.1\n\n        Returns\n        -------\n        inst : instance of Raw, Epochs, or Evoked\n            The modified instance.\n\n        See Also\n        --------\n        drop_channels\n        pick_types\n        reorder_channels\n\n        Notes\n        -----\n        If ``ordered`` is ``False``, the channel names given via ``ch_names`` are\n        assumed to be a set, that is, their order does not matter. In that case, the\n        original order of the channels in the data is preserved. Apart from using\n        ``ordered=True``, you may also use ``reorder_channels`` to set channel order,\n        if necessary.\n\n        .. versionadded:: 0.9.0\n        \"\"\"\n        picks = pick_channels(self.info[\"ch_names\"], ch_names, ordered=ordered)\n        return self._pick_drop_channels(picks)", "metadata": {}}
{"_id": "mne_mne_channels/channels.py_pick_code", "title": "pick", "text": "def pick(self, picks, exclude=(), *, verbose=None):\n        \"\"\"Pick a subset of channels.\n\n        Parameters\n        ----------\n        %(picks_all)s\n        exclude : list | str\n            Set of channels to exclude, only used when picking based on\n            types (e.g., exclude=\"bads\" when picks=\"meg\").\n        %(verbose)s\n\n            .. versionadded:: 0.24.0\n\n        Returns\n        -------\n        inst : instance of Raw, Epochs, or Evoked\n            The modified instance.\n        \"\"\"\n        picks = _picks_to_idx(self.info, picks, \"all\", exclude, allow_empty=False)\n        self._pick_drop_channels(picks)\n\n        # remove dropped channel types from reject and flat\n        if getattr(self, \"reject\", None) is not None:\n            # use list(self.reject) to avoid RuntimeError for changing dictionary size\n            # during iteration\n            for ch_type in list(self.reject):\n                if ch_type not in self:\n                    del self.reject[ch_type]\n\n        if getattr(self, \"flat\", None) is not None:\n            for ch_type in list(self.flat):\n                if ch_type not in self:\n                    del self.flat[ch_type]\n\n        return self", "metadata": {}}
{"_id": "mne_mne_channels/channels.py_reorder_channels_code", "title": "reorder_channels", "text": "def reorder_channels(self, ch_names):\n        \"\"\"Reorder channels.\n\n        Parameters\n        ----------\n        ch_names : list\n            The desired channel order.\n\n        Returns\n        -------\n        inst : instance of Raw, Epochs, or Evoked\n            The modified instance.\n\n        See Also\n        --------\n        drop_channels\n        pick_types\n        pick_channels\n\n        Notes\n        -----\n        Channel names must be unique. Channels that are not in ``ch_names``\n        are dropped.\n\n        .. versionadded:: 0.16.0\n        \"\"\"\n        _check_excludes_includes(ch_names)\n        idx = list()\n        for ch_name in ch_names:\n            ii = self.ch_names.index(ch_name)\n            if ii in idx:\n                raise ValueError(f\"Channel name repeated: {ch_name}\")\n            idx.append(ii)\n        return self._pick_drop_channels(idx)", "metadata": {}}
{"_id": "mne_mne_channels/channels.py_drop_channels_code", "title": "drop_channels", "text": "def drop_channels(self, ch_names, on_missing=\"raise\"):\n        \"\"\"Drop channel(s).\n\n        Parameters\n        ----------\n        ch_names : iterable or str\n            Iterable (e.g. list) of channel name(s) or channel name to remove.\n        %(on_missing_ch_names)s\n\n        Returns\n        -------\n        inst : instance of Raw, Epochs, or Evoked\n            The modified instance.\n\n        See Also\n        --------\n        reorder_channels\n        pick_channels\n        pick_types\n\n        Notes\n        -----\n        .. versionadded:: 0.9.0\n        \"\"\"\n        if isinstance(ch_names, str):\n            ch_names = [ch_names]\n\n        try:\n            all_str = all([isinstance(ch, str) for ch in ch_names])\n        except TypeError:\n            raise ValueError(\n                f\"'ch_names' must be iterable, got type {type(ch_names)} ({ch_names}).\"\n            )\n\n        if not all_str:\n            raise ValueError(\n                \"Each element in 'ch_names' must be str, got \"\n                f\"{[type(ch) for ch in ch_names]}.\"\n            )\n\n        missing = [ch for ch in ch_names if ch not in self.ch_names]\n        if len(missing) > 0:\n            msg = \"Channel(s) {0} not found, nothing dropped.\"\n            _on_missing(on_missing, msg.format(\", \".join(missing)))\n\n        bad_idx = [self.ch_names.index(ch) for ch in ch_names if ch in self.ch_names]\n        idx = np.setdiff1d(np.arange(len(self.ch_names)), bad_idx)\n        if len(idx) == 0:\n            raise ValueError(\"All channels would be dropped.\")\n        return self._pick_drop_channels(idx)", "metadata": {}}
{"_id": "mne_mne_channels/channels.py_add_channels_code", "title": "add_channels", "text": "def add_channels(self, add_list, force_update_info=False):\n        \"\"\"Append new channels from other MNE objects to the instance.\n\n        Parameters\n        ----------\n        add_list : list\n            A list of MNE objects to append to the current instance.\n            The channels contained in the other instances are appended to the\n            channels of the current instance. Therefore, all other instances\n            must be of the same type as the current object.\n            See notes on how to add data coming from an array.\n        force_update_info : bool\n            If True, force the info for objects to be appended to match the\n            values of the current instance. This should generally only be\n            used when adding stim channels for which important metadata won't\n            be overwritten.\n\n            .. versionadded:: 0.12\n\n        Returns\n        -------\n        inst : instance of Raw, Epochs, or Evoked\n            The modified instance.\n\n        See Also\n        --------\n        drop_channels\n\n        Notes\n        -----\n        If ``self`` is a Raw instance that has been preloaded into a\n        :obj:`numpy.memmap` instance, the memmap will be resized.\n\n        This function expects an MNE object to be appended (e.g. :class:`~mne.io.Raw`,\n        :class:`~mne.Epochs`, :class:`~mne.Evoked`). If you simply want to add a\n        channel based on values of an np.ndarray, you need to create a\n        :class:`~mne.io.RawArray`.\n        See <https://mne.tools/mne-project-template/auto_examples/plot_mne_objects_from_arrays.html>`_\n        \"\"\"\n        # avoid circular imports\n        from ..epochs import BaseEpochs\n        from ..io import BaseRaw\n        from ..time_frequency import EpochsTFR\n\n        _validate_type(add_list, (list, tuple), \"Input\")\n\n        # Object-specific checks\n        for inst in add_list + [self]:\n            _check_preload(inst, \"adding channels\")\n        if isinstance(self, BaseRaw):\n            con_axis = 0\n            comp_class = BaseRaw\n        elif isinstance(self, BaseEpochs):\n            con_axis = 1\n            comp_class = BaseEpochs\n        elif isinstance(self, EpochsTFR):\n            con_axis = 1\n            comp_class = EpochsTFR\n        else:\n            con_axis = 0\n            comp_class = type(self)\n        for inst in add_list:\n            _validate_type(inst, comp_class, \"All input\")\n        data = [inst._data for inst in [self] + add_list]\n\n        # Make sure that all dimensions other than channel axis are the same\n        compare_axes = [i for i in range(data[0].ndim) if i != con_axis]\n        shapes = np.array([dat.shape for dat in data])[:, compare_axes]\n        for shape in shapes:\n            if not ((shapes[0] - shape) == 0).all():\n                raise ValueError(\n                    \"All data dimensions except channels must match, got \"\n                    f\"{shapes[0]} != {shape}\"\n                )\n        del shapes\n\n        # Create final data / info objects\n        infos = [self.info] + [inst.info for inst in add_list]\n        new_info = _merge_info(infos, force_update_to_first=force_update_info)\n\n        # Now update the attributes\n        if (\n            isinstance(self._data, np.memmap)\n            and con_axis == 0\n            and sys.platform != \"darwin\"\n        ):  # resizing not available--no mremap\n            # Use a resize and fill in other ones\n            out_shape = (sum(d.shape[0] for d in data),) + data[0].shape[1:]\n            n_bytes = np.prod(out_shape) * self._data.dtype.itemsize\n            self._data.flush()\n            self._data.base.resize(n_bytes)\n            self._data = np.memmap(\n                self._data.filename, mode=\"r+\", dtype=self._data.dtype, shape=out_shape\n            )\n            assert self._data.shape == out_shape\n            assert self._data.nbytes == n_bytes\n            offset = len(data[0])\n            for d in data[1:]:\n                this_len = len(d)\n                self._data[offset : offset + this_len] = d\n                offset += this_len\n        else:\n            self._data = np.concatenate(data, axis=con_axis)\n        self.info = new_info\n        if isinstance(self, BaseRaw):\n            self._cals = np.concatenate(\n                [getattr(inst, \"_cals\") for inst in [self] + add_list]\n            )\n            # We should never use these since data are preloaded, let's just\n            # set it to something large and likely to break (2 ** 31 - 1)\n            extra_idx = [2147483647] * sum(info[\"nchan\"] for info in infos[1:])\n            assert all(len(r) == infos[0][\"nchan\"] for r in self._read_picks)\n            self._read_picks = [\n                np.concatenate([r, extra_idx]) for r in self._read_picks\n            ]\n            assert all(len(r) == self.info[\"nchan\"] for r in self._read_picks)\n            for other in add_list:\n                self._orig_units.update(other._orig_units)\n        elif isinstance(self, BaseEpochs):\n            self.picks = np.arange(self._data.shape[1])\n            if hasattr(self, \"_projector\"):\n                activate = False if self._do_delayed_proj else self.proj\n                self._projector, self.info = setup_proj(\n                    self.info, False, activate=activate\n                )\n\n        return self", "metadata": {}}
{"_id": "mne_mne_channels/channels.py_add_reference_channels_code", "title": "add_reference_channels", "text": "def add_reference_channels(self, ref_channels):\n        \"\"\"Add reference channels to data that consists of all zeros.\n\n        Adds reference channels to data that were not included during\n        recording. This is useful when you need to re-reference your data\n        to different channels. These added channels will consist of all zeros.\n\n        Parameters\n        ----------\n        %(ref_channels)s\n\n        Returns\n        -------\n        inst : instance of Raw | Epochs | Evoked\n               The modified instance.\n        \"\"\"\n        return add_reference_channels(self, ref_channels, copy=False)", "metadata": {}}
{"_id": "mne_mne_channels/channels.py_interpolate_bads_code", "title": "interpolate_bads", "text": "def interpolate_bads(\n        self,\n        reset_bads=True,\n        mode=\"accurate\",\n        origin=\"auto\",\n        method=None,\n        exclude=(),\n        verbose=None,\n    ):\n        \"\"\"Interpolate bad MEG and EEG channels.\n\n        Operates in place.\n\n        Parameters\n        ----------\n        reset_bads : bool\n            If True, remove the bads from info.\n        mode : str\n            Either ``'accurate'`` or ``'fast'``, determines the quality of the\n            Legendre polynomial expansion used for interpolation of channels\n            using the minimum-norm method.\n        origin : array-like, shape (3,) | str\n            Origin of the sphere in the head coordinate frame and in meters.\n            Can be ``'auto'`` (default), which means a head-digitization-based\n            origin fit.\n\n            .. versionadded:: 0.17\n        method : dict | str | None\n            Method to use for each channel type.\n\n            - ``\"meg\"`` channels support ``\"MNE\"`` (default) and ``\"nan\"``\n            - ``\"eeg\"`` channels support ``\"spline\"`` (default), ``\"MNE\"`` and ``\"nan\"``\n            - ``\"fnirs\"`` channels support ``\"nearest\"`` (default) and ``\"nan\"``\n            - ``\"ecog\"`` channels support ``\"spline\"`` (default) and ``\"nan\"``\n            - ``\"seeg\"`` channels support ``\"spline\"`` (default) and ``\"nan\"``\n\n            None is an alias for::\n\n                method=dict(meg=\"MNE\", eeg=\"spline\", fnirs=\"nearest\")\n\n            If a :class:`str` is provided, the method will be applied to all channel\n            types supported and available in the instance. The method ``\"nan\"`` will\n            replace the channel data with ``np.nan``.\n\n            .. warning::\n                Be careful when using ``method=\"nan\"``; the default value\n                ``reset_bads=True`` may not be what you want.\n\n            .. versionadded:: 0.21\n        exclude : list | tuple\n            The channels to exclude from interpolation. If excluded a bad\n            channel will stay in bads.\n        %(verbose)s\n\n        Returns\n        -------\n        inst : instance of Raw, Epochs, or Evoked\n            The modified instance.\n\n        Notes\n        -----\n        The ``\"MNE\"`` method uses minimum-norm projection to a sphere and back.\n\n        .. versionadded:: 0.9.0\n        \"\"\"\n        from .interpolation import (\n            _interpolate_bads_ecog,\n            _interpolate_bads_eeg,\n            _interpolate_bads_meeg,\n            _interpolate_bads_nan,\n            _interpolate_bads_nirs,\n            _interpolate_bads_seeg,\n        )\n\n        _check_preload(self, \"interpolation\")\n        _validate_type(method, (dict, str, None), \"method\")\n        method = _handle_default(\"interpolation_method\", method)\n        ch_types = self.get_channel_types(unique=True)\n        # figure out if we have \"mag\" for \"meg\", \"hbo\" for \"fnirs\", ... to filter the\n        # \"method\" dictionary and keep only keys that correspond to existing channels.\n        for ch_type in (\"meg\", \"fnirs\"):\n            for sub_ch_type in _second_rules[ch_type][1].values():\n                if sub_ch_type in ch_types:\n                    ch_types.remove(sub_ch_type)\n                    if ch_type not in ch_types:\n                        ch_types.append(ch_type)\n        keys2delete = set(method) - set(ch_types)\n        for key in keys2delete:\n            del method[key]\n        valids = {\n            \"eeg\": (\"spline\", \"MNE\", \"nan\"),\n            \"meg\": (\"MNE\", \"nan\"),\n            \"fnirs\": (\"nearest\", \"nan\"),\n            \"ecog\": (\"spline\", \"nan\"),\n            \"seeg\": (\"spline\", \"nan\"),\n        }\n        for key in method:\n            _check_option(\"method[key]\", key, tuple(valids))\n            _check_option(f\"method['{key}']\", method[key], valids[key])\n        logger.info(\"Setting channel interpolation method to %s.\", method)\n        idx = _picks_to_idx(self.info, list(method), exclude=(), allow_empty=True)\n        if idx.size == 0 or len(pick_info(self.info, idx)[\"bads\"]) == 0:\n            warn(\"No bad channels to interpolate. Doing nothing...\")\n            return self\n        for ch_type in method.copy():\n            idx = _picks_to_idx(self.info, ch_type, exclude=(), allow_empty=True)\n            if len(pick_info(self.info, idx)[\"bads\"]) == 0:\n                method.pop(ch_type)\n        logger.info(\"Interpolating bad channels.\")\n        needs_origin = [key != \"seeg\" and val != \"nan\" for key, val in method.items()]\n        if any(needs_origin):\n            origin = _check_origin(origin, self.info)\n        for ch_type, interp in method.items():\n            if interp == \"nan\":\n                _interpolate_bads_nan(self, ch_type, exclude=exclude)\n        if method.get(\"eeg\", \"\") == \"spline\":\n            _interpolate_bads_eeg(self, origin=origin, exclude=exclude)\n        meg_mne = method.get(\"meg\", \"\") == \"MNE\"\n        eeg_mne = method.get(\"eeg\", \"\") == \"MNE\"\n        if meg_mne or eeg_mne:\n            _interpolate_bads_meeg(\n                self,\n                mode=mode,\n                meg=meg_mne,\n                eeg=eeg_mne,\n                origin=origin,\n                exclude=exclude,\n                method=method,\n            )\n        if method.get(\"fnirs\", \"\") == \"nearest\":\n            _interpolate_bads_nirs(self, exclude=exclude)\n        if method.get(\"ecog\", \"\") == \"spline\":\n            _interpolate_bads_ecog(self, origin=origin, exclude=exclude)\n        if method.get(\"seeg\", \"\") == \"spline\":\n            _interpolate_bads_seeg(self, exclude=exclude)\n\n        if reset_bads is True:\n            if \"nan\" in method.values():\n                warn(\n                    \"interpolate_bads was called with method='nan' and \"\n                    \"reset_bads=True. Consider setting reset_bads=False so that the \"\n                    \"nan-containing channels can be easily excluded from later \"\n                    \"computations.\"\n                )\n            self.info[\"bads\"] = [ch for ch in self.info[\"bads\"] if ch in exclude]\n\n        return self", "metadata": {}}
{"_id": "mne_mne_channels/channels.py_interpolate_to_code", "title": "interpolate_to", "text": "def interpolate_to(self, sensors, origin=\"auto\", method=\"spline\", reg=0.0):\n        \"\"\"Interpolate EEG data onto a new montage.\n\n        .. warning::\n            Be careful, only EEG channels are interpolated. Other channel types are\n            not interpolated.\n\n        Parameters\n        ----------\n        sensors : DigMontage\n            The target montage containing channel positions to interpolate onto.\n        origin : array-like, shape (3,) | str\n            Origin of the sphere in the head coordinate frame and in meters.\n            Can be ``'auto'`` (default), which means a head-digitization-based\n            origin fit.\n        method : str\n            Method to use for EEG channels.\n            Supported methods are 'spline' (default) and 'MNE'.\n        reg : float\n            The regularization parameter for the interpolation method\n            (only used when the method is 'spline').\n\n        Returns\n        -------\n        inst : instance of Raw, Epochs, or Evoked\n            The instance with updated channel locations and data.\n\n        Notes\n        -----\n        This method is useful for standardizing EEG layouts across datasets.\n        However, some attributes may be lost after interpolation.\n\n        .. versionadded:: 1.10.0\n        \"\"\"\n        from ..epochs import BaseEpochs, EpochsArray\n        from ..evoked import Evoked, EvokedArray\n        from ..forward._field_interpolation import _map_meg_or_eeg_channels\n        from ..io import RawArray\n        from ..io.base import BaseRaw\n        from .interpolation import _make_interpolation_matrix\n        from .montage import DigMontage\n\n        # Check that the method option is valid.\n        _check_option(\"method\", method, [\"spline\", \"MNE\"])\n        _validate_type(sensors, DigMontage, \"sensors\")\n\n        # Get target positions from the montage\n        ch_pos = sensors.get_positions().get(\"ch_pos\", {})\n        target_ch_names = list(ch_pos.keys())\n        if not target_ch_names:\n            raise ValueError(\n                \"The provided sensors configuration has no channel positions.\"\n            )\n\n        # Get original channel order\n        orig_names = self.info[\"ch_names\"]\n\n        # Identify EEG channel\n        picks_good_eeg = pick_types(self.info, meg=False, eeg=True, exclude=\"bads\")\n        if len(picks_good_eeg) == 0:\n            raise ValueError(\"No good EEG channels available for interpolation.\")\n        # Also get the full list of EEG channel indices (including bad channels)\n        picks_remove_eeg = pick_types(self.info, meg=False, eeg=True, exclude=[])\n        eeg_names_orig = [orig_names[i] for i in picks_remove_eeg]\n\n        # Identify non-EEG channels in original order\n        non_eeg_names_ordered = [ch for ch in orig_names if ch not in eeg_names_orig]\n\n        # Create destination info for new EEG channels\n        sfreq = self.info[\"sfreq\"]\n        info_interp = create_info(\n            ch_names=target_ch_names,\n            sfreq=sfreq,\n            ch_types=[\"eeg\"] * len(target_ch_names),\n        )\n        info_interp.set_montage(sensors)\n        info_interp[\"bads\"] = [ch for ch in self.info[\"bads\"] if ch in target_ch_names]\n        # Do not assign \"projs\" directly.\n\n        # Compute the interpolation mapping\n        if method == \"spline\":\n            origin_val = _check_origin(origin, self.info)\n            pos_from = self.info._get_channel_positions(picks_good_eeg) - origin_val\n            pos_to = np.stack(list(ch_pos.values()), axis=0)\n\n            def _check_pos_sphere(pos):\n                d = np.linalg.norm(pos, axis=-1)\n                d_norm = np.mean(d / np.mean(d))\n                if np.abs(1.0 - d_norm) > 0.1:\n                    warn(\"Your spherical fit is poor; interpolation may be inaccurate.\")\n\n            _check_pos_sphere(pos_from)\n            _check_pos_sphere(pos_to)\n            mapping = _make_interpolation_matrix(pos_from, pos_to, alpha=reg)\n\n        else:\n            assert method == \"MNE\"\n            info_eeg = pick_info(self.info, picks_good_eeg)\n            # If the original info has an average EEG reference projector but\n            # the destination info does not,\n            # update info_interp via a temporary RawArray.\n            if _has_eeg_average_ref_proj(self.info) and not _has_eeg_average_ref_proj(\n                info_interp\n            ):\n                # Create dummy data: shape (n_channels, 1)\n                temp_data = np.zeros((len(info_interp[\"ch_names\"]), 1))\n                temp_raw = RawArray(temp_data, info_interp, first_samp=0)\n                # Using the public API, add an average reference projector.\n                temp_raw.set_eeg_reference(\n                    ref_channels=\"average\", projection=True, verbose=False\n                )\n                # Extract the updated info.\n                info_interp = temp_raw.info\n            mapping = _map_meg_or_eeg_channels(\n                info_eeg, info_interp, mode=\"accurate\", origin=origin\n            )\n\n        # Interpolate EEG data\n        data_good = self.get_data(picks=picks_good_eeg)\n        data_interp = mapping @ data_good\n\n        # Create a new instance for the interpolated EEG channels\n        # TODO: Creating a new instance leads to a loss of information.\n        #       We should consider updating the existing instance in the future\n        #       by 1) drop channels, 2) add channels, 3) re-order channels.\n        if isinstance(self, BaseRaw):\n            inst_interp = RawArray(data_interp, info_interp, first_samp=self.first_samp)\n        elif isinstance(self, BaseEpochs):\n            inst_interp = EpochsArray(data_interp, info_interp)\n        else:\n            assert isinstance(self, Evoked)\n            inst_interp = EvokedArray(data_interp, info_interp)\n\n        # Merge only if non-EEG channels exist\n        if not non_eeg_names_ordered:\n            return inst_interp\n\n        inst_non_eeg = self.copy().pick(non_eeg_names_ordered).load_data()\n        inst_out = inst_non_eeg.add_channels([inst_interp], force_update_info=True)\n\n        # Reorder channels\n        # Insert the entire new EEG block at the position of the first EEG channel.\n        orig_names_arr = np.array(orig_names)\n        mask_eeg = np.isin(orig_names_arr, eeg_names_orig)\n        if mask_eeg.any():\n            first_eeg_index = np.where(mask_eeg)[0][0]\n            pre = orig_names_arr[:first_eeg_index]\n            new_eeg = np.array(info_interp[\"ch_names\"])\n            post = orig_names_arr[first_eeg_index:]\n            post = post[~np.isin(orig_names_arr[first_eeg_index:], eeg_names_orig)]\n            new_order = np.concatenate((pre, new_eeg, post)).tolist()\n        else:\n            new_order = orig_names\n        inst_out.reorder_channels(new_order)\n        return inst_out", "metadata": {}}
{"_id": "mne_mne_stats/multi_comp.py_fdr_correction_code", "title": "fdr_correction", "text": "def fdr_correction(pvals, alpha=0.05, method=\"indep\"):\n    \"\"\"P-value correction with False Discovery Rate (FDR).\n\n    Correction for multiple comparison using FDR :footcite:`GenoveseEtAl2002`.\n\n    This covers Benjamini/Hochberg for independent or positively correlated and\n    Benjamini/Yekutieli for general or negatively correlated tests.\n\n    Parameters\n    ----------\n    pvals : array_like\n        Set of p-values of the individual tests.\n    alpha : float\n        Error rate.\n    method : 'indep' | 'negcorr'\n        If 'indep' it implements Benjamini/Hochberg for independent or if\n        'negcorr' it corresponds to Benjamini/Yekutieli.\n\n    Returns\n    -------\n    reject : array, bool\n        True if a hypothesis is rejected, False if not.\n    pval_corrected : array\n        P-values adjusted for multiple hypothesis testing to limit FDR.\n\n    References\n    ----------\n    .. footbibliography::\n    \"\"\"\n    pvals = np.asarray(pvals)\n    shape_init = pvals.shape\n    pvals = pvals.ravel()\n\n    pvals_sortind = np.argsort(pvals)\n    pvals_sorted = pvals[pvals_sortind]\n    sortrevind = pvals_sortind.argsort()\n\n    if method in [\"i\", \"indep\", \"p\", \"poscorr\"]:\n        ecdffactor = _ecdf(pvals_sorted)\n    elif method in [\"n\", \"negcorr\"]:\n        cm = np.sum(1.0 / np.arange(1, len(pvals_sorted) + 1))\n        ecdffactor = _ecdf(pvals_sorted) / cm\n    else:\n        raise ValueError(\"Method should be 'indep' and 'negcorr'\")\n\n    reject = pvals_sorted < (ecdffactor * alpha)\n    if reject.any():\n        rejectmax = max(np.nonzero(reject)[0])\n    else:\n        rejectmax = 0\n    reject[:rejectmax] = True\n\n    pvals_corrected_raw = pvals_sorted / ecdffactor\n    pvals_corrected = np.minimum.accumulate(pvals_corrected_raw[::-1])[::-1]\n    pvals_corrected[pvals_corrected > 1.0] = 1.0\n    pvals_corrected = pvals_corrected[sortrevind].reshape(shape_init)\n    reject = reject[sortrevind].reshape(shape_init)\n    return reject, pvals_corrected", "metadata": {}}
{"_id": "mne_mne_stats/multi_comp.py_bonferroni_correction_code", "title": "bonferroni_correction", "text": "def bonferroni_correction(pval, alpha=0.05):\n    \"\"\"P-value correction with Bonferroni method.\n\n    Parameters\n    ----------\n    pval : array_like\n        Set of p-values of the individual tests.\n    alpha : float\n        Error rate.\n\n    Returns\n    -------\n    reject : array, bool\n        True if a hypothesis is rejected, False if not.\n    pval_corrected : array\n        P-values adjusted for multiple hypothesis testing to limit FDR.\n    \"\"\"\n    pval = np.asarray(pval)\n    pval_corrected = pval * float(pval.size)\n    # p-values must not be larger than 1.\n    pval_corrected = pval_corrected.clip(max=1.0)\n    reject = pval_corrected < alpha\n    return reject, pval_corrected", "metadata": {}}
{"_id": "mne_mne_stats/permutations.py_permutation_t_test_code", "title": "permutation_t_test", "text": "def permutation_t_test(\n    X, n_permutations=10000, tail=0, n_jobs=None, seed=None, verbose=None\n):\n    \"\"\"One sample/paired sample permutation test based on a t-statistic.\n\n    This function can perform the test on one variable or\n    simultaneously on multiple variables. When applying the test to multiple\n    variables, the \"tmax\" method is used for adjusting the p-values of each\n    variable for multiple comparisons. Like Bonferroni correction, this method\n    adjusts p-values in a way that controls the family-wise error rate.\n    However, the permutation method will be more\n    powerful than Bonferroni correction when different variables in the test\n    are correlated (see :footcite:`NicholsHolmes2002`).\n\n    Parameters\n    ----------\n    X : array, shape (n_samples, n_tests)\n        Samples (observations) by number of tests (variables).\n    n_permutations : int | 'all'\n        Number of permutations. If n_permutations is 'all' all possible\n        permutations are tested. It's the exact test, that\n        can be untractable when the number of samples is big (e.g. > 20).\n        If n_permutations >= 2**n_samples then the exact test is performed.\n    tail : -1 or 0 or 1 (default = 0)\n        If tail is 1, the alternative hypothesis is that the\n        mean of the data is greater than 0 (upper tailed test).  If tail is 0,\n        the alternative hypothesis is that the mean of the data is different\n        than 0 (two tailed test).  If tail is -1, the alternative hypothesis\n        is that the mean of the data is less than 0 (lower tailed test).\n    %(n_jobs)s\n    %(seed)s\n    %(verbose)s\n\n    Returns\n    -------\n    T_obs : array of shape [n_tests]\n        T-statistic observed for all variables.\n    p_values : array of shape [n_tests]\n        P-values for all the tests (a.k.a. variables).\n    H0 : array of shape [n_permutations]\n        T-statistic obtained by permutations and t-max trick for multiple\n        comparison.\n\n    Notes\n    -----\n    If ``n_permutations >= 2 ** (n_samples - (tail == 0))``,\n    ``n_permutations`` and ``seed`` will be ignored since an exact test\n    (full permutation test) will be performed.\n\n    References\n    ----------\n    .. footbibliography::\n    \"\"\"\n    from .cluster_level import _get_1samp_orders\n\n    n_samples, n_tests = X.shape\n    X2 = np.mean(X**2, axis=0)  # precompute moments\n    mu0 = np.mean(X, axis=0)\n    dof_scaling = sqrt(n_samples / (n_samples - 1.0))\n    std0 = np.sqrt(X2 - mu0**2) * dof_scaling  # get std with var splitting\n    T_obs = np.mean(X, axis=0) / (std0 / sqrt(n_samples))\n    rng = check_random_state(seed)\n    orders, _, extra = _get_1samp_orders(n_samples, n_permutations, tail, rng)\n    perms = 2 * np.array(orders) - 1  # from 0, 1 -> 1, -1\n    logger.info(f\"Permuting {len(orders)} times{extra}...\")\n    parallel, my_max_stat, n_jobs = parallel_func(_max_stat, n_jobs)\n    max_abs = np.concatenate(\n        parallel(\n            my_max_stat(X, X2, p, dof_scaling) for p in np.array_split(perms, n_jobs)\n        )\n    )\n    max_abs = np.concatenate((max_abs, [np.abs(T_obs).max()]))\n    H0 = np.sort(max_abs)\n    if tail == 0:\n        p_values = (H0 >= np.abs(T_obs[:, np.newaxis])).mean(-1)\n    elif tail == 1:\n        p_values = (H0 >= T_obs[:, np.newaxis]).mean(-1)\n    elif tail == -1:\n        p_values = (-H0 <= T_obs[:, np.newaxis]).mean(-1)\n    return T_obs, p_values, H0", "metadata": {}}
{"_id": "mne_mne_stats/permutations.py_bootstrap_confidence_interval_code", "title": "bootstrap_confidence_interval", "text": "def bootstrap_confidence_interval(\n    arr, ci=0.95, n_bootstraps=2000, stat_fun=\"mean\", random_state=None\n):\n    \"\"\"Get confidence intervals from non-parametric bootstrap.\n\n    Parameters\n    ----------\n    arr : ndarray, shape (n_samples, ...)\n        The input data on which to calculate the confidence interval.\n    ci : float\n        Level of the confidence interval between 0 and 1.\n    n_bootstraps : int\n        Number of bootstraps.\n    stat_fun : str | callable\n        Can be \"mean\", \"median\", or a callable operating along ``axis=0``.\n    random_state : int | float | array_like | None\n        The seed at which to initialize the bootstrap.\n\n    Returns\n    -------\n    cis : ndarray, shape (2, ...)\n        Containing the lower boundary of the CI at ``cis[0, ...]`` and the\n        upper boundary of the CI at ``cis[1, ...]``.\n    \"\"\"\n    if stat_fun == \"mean\":\n\n        def stat_fun(x):\n            return x.mean(axis=0)\n\n    elif stat_fun == \"median\":\n\n        def stat_fun(x):\n            return np.median(x, axis=0)\n\n    elif not callable(stat_fun):\n        raise ValueError(\"stat_fun must be 'mean', 'median' or callable.\")\n    n_trials = arr.shape[0]\n    indices = np.arange(n_trials, dtype=int)  # BCA would be cool to have too\n    rng = check_random_state(random_state)\n    boot_indices = rng.choice(indices, replace=True, size=(n_bootstraps, len(indices)))\n    stat = np.array([stat_fun(arr[inds]) for inds in boot_indices])\n    ci = (((1 - ci) / 2) * 100, (1 - ((1 - ci) / 2)) * 100)\n    ci_low, ci_up = np.percentile(stat, ci, axis=0)\n    return np.array([ci_low, ci_up])", "metadata": {}}
{"_id": "mne_mne_stats/erp.py_compute_sme_code", "title": "compute_sme", "text": "def compute_sme(epochs, start=None, stop=None):\n    \"\"\"Compute standardized measurement error (SME).\n\n    The standardized measurement error :footcite:`LuckEtAl2021` can be used as a\n    universal measure of data quality in ERP studies.\n\n    Parameters\n    ----------\n    epochs : mne.Epochs\n        The epochs containing the data for which to compute the SME.\n    start : int | float | None\n        Start time (in s) of the time window used for SME computation. If ``None``, use\n        the start of the epoch.\n    stop : int | float | None\n        Stop time (in s) of the time window used for SME computation. If ``None``, use\n        the end of the epoch.\n\n    Returns\n    -------\n    sme : array, shape (n_channels,)\n        SME in given time window for each channel.\n\n    Notes\n    -----\n    Currently, only the mean value in the given time window is supported, meaning that\n    the resulting SME is only valid in studies which quantify the amplitude of an ERP\n    component as the mean within the time window (as opposed to e.g. the peak, which\n    would require bootstrapping).\n\n    References\n    ----------\n    .. footbibliography::\n\n    Examples\n    --------\n    Given an :class:`~mne.Epochs` object, the SME for the entire epoch duration can be\n    computed as follows:\n\n        >>> compute_sme(epochs)  # doctest: +SKIP\n\n    However, the SME is best used to estimate the precision of a specific ERP measure,\n    specifically the mean amplitude of an ERP component in a time window of interest.\n    For example, the SME for the mean amplitude of the P3 component in the 300-500 ms\n    time window could be computed as follows:\n\n        >>> compute_sme(epochs, start=0.3, stop=0.5)  # doctest: +SKIP\n\n    Usually, it will be more informative to compute the SME for specific conditions\n    separately. This can be done by selecting the epochs of interest as follows:\n\n        >>> compute_sme(epochs[\"oddball\"], 0.3, 0.5)  # doctest: +SKIP\n\n    Note that the SME will be reported for each channel separately. If you are only\n    interested in a single channel (or a subset of channels), select the channels\n    before computing the SME:\n\n        >>> compute_sme(epochs.pick(\"Pz\"), 0.3, 0.5)  # doctest: +SKIP\n\n    Selecting both conditions and channels is also possible:\n\n        >>> compute_sme(epochs[\"oddball\"].pick(\"Pz\"), 0.3, 0.5)  # doctest: +SKIP\n\n    In any case, the output will be a NumPy array with the SME value for each channel.\n    \"\"\"\n    _validate_type(start, (\"numeric\", None), \"start\", \"int or float\")\n    _validate_type(stop, (\"numeric\", None), \"stop\", \"int or float\")\n    start = epochs.tmin if start is None else start\n    stop = epochs.tmax if stop is None else stop\n    if start < epochs.tmin:\n        raise ValueError(\"start is out of bounds.\")\n    if stop > epochs.tmax:\n        raise ValueError(\"stop is out of bounds.\")\n\n    data = epochs.get_data(tmin=start, tmax=stop)\n    return data.mean(axis=2).std(axis=0) / np.sqrt(data.shape[0])", "metadata": {}}
{"_id": "mne_mne_stats/cluster_level.py_bin_perm_rep_code", "title": "bin_perm_rep", "text": "def bin_perm_rep(ndim, a=0, b=1):\n    \"\"\"Ndim permutations with repetitions of (a,b).\n\n    Returns an array with all the possible permutations with repetitions of\n    (0,1) in ndim dimensions.  The array is shaped as (2**ndim,ndim), and is\n    ordered with the last index changing fastest.  For examble, for ndim=3:\n\n    Examples\n    --------\n    >>> bin_perm_rep(3)\n    array([[0, 0, 0],\n           [0, 0, 1],\n           [0, 1, 0],\n           [0, 1, 1],\n           [1, 0, 0],\n           [1, 0, 1],\n           [1, 1, 0],\n           [1, 1, 1]])\n    \"\"\"\n    # Create the leftmost column as 0,0,...,1,1,...\n    nperms = 2**ndim\n    perms = np.empty((nperms, ndim), type(a))\n    perms.fill(a)\n    half_point = nperms // 2\n    perms[half_point:, 0] = b\n    # Fill the rest of the table by sampling the previous column every 2 items\n    for j in range(1, ndim):\n        half_col = perms[::2, j - 1]\n        perms[:half_point, j] = half_col\n        perms[half_point:, j] = half_col\n    # This is equivalent to something like:\n    # orders = [np.fromiter(np.binary_repr(s + 1, ndim), dtype=int)\n    #           for s in np.arange(2 ** ndim)]\n    return perms", "metadata": {}}
{"_id": "mne_mne_stats/cluster_level.py_permutation_cluster_test_code", "title": "permutation_cluster_test", "text": "def permutation_cluster_test(\n    X,\n    threshold=None,\n    n_permutations=1024,\n    tail=0,\n    stat_fun=None,\n    adjacency=None,\n    n_jobs=None,\n    seed=None,\n    max_step=1,\n    exclude=None,\n    step_down_p=0,\n    t_power=1,\n    out_type=\"indices\",\n    check_disjoint=False,\n    buffer_size=1000,\n    verbose=None,\n):\n    \"\"\"Cluster-level statistical permutation test.\n\n    For a list of :class:`NumPy arrays <numpy.ndarray>` of data,\n    calculate some statistics corrected for multiple comparisons using\n    permutations and cluster-level correction. Each element of the list ``X``\n    should contain the data for one group of observations (e.g., 2D arrays for\n    time series, 3D arrays for time-frequency power values). Permutations are\n    generated with random partitions of the data. For details, see\n    :footcite:p:`MarisOostenveld2007,Sassenhagen2019`.\n\n    Parameters\n    ----------\n    X : list of array, shape (n_observations, p[, q][, r])\n        The data to be clustered. Each array in ``X`` should contain the\n        observations for one group. The first dimension of each array is the\n        number of observations from that group; remaining dimensions comprise\n        the size of a single observation. For example if ``X = [X1, X2]``\n        with ``X1.shape = (20, 50, 4)`` and ``X2.shape = (17, 50, 4)``, then\n        ``X`` has 2 groups with respectively 20 and 17 observations in each,\n        and each data point is of shape ``(50, 4)``. Note: that the\n        *last dimension* of each element of ``X`` should correspond to the\n        dimension represented in the ``adjacency`` parameter\n        (e.g., spectral data should be provided as\n        ``(observations, frequencies, channels/vertices)``).\n    %(threshold_clust_f)s\n    %(n_permutations_clust_int)s\n    %(tail_clust)s\n    %(stat_fun_clust_f)s\n    %(adjacency_clust_n)s\n    %(n_jobs)s\n    %(seed)s\n    %(max_step_clust)s\n    %(exclude_clust)s\n    %(step_down_p_clust)s\n    %(f_power_clust)s\n    %(out_type_clust)s\n    %(check_disjoint_clust)s\n    %(buffer_size_clust)s\n    %(verbose)s\n\n    Returns\n    -------\n    F_obs : array, shape (p[, q][, r])\n        Statistic (F by default) observed for all variables.\n    clusters : list\n        List type defined by out_type above.\n    cluster_pv : array\n        P-value for each cluster.\n    H0 : array, shape (n_permutations,)\n        Max cluster level stats observed under permutation.\n\n    Notes\n    -----\n    %(threshold_clust_f_notes)s\n\n    References\n    ----------\n    .. footbibliography::\n    \"\"\"\n    stat_fun, threshold = _check_fun(X, stat_fun, threshold, tail, \"between\")\n    return _permutation_cluster_test(\n        X=X,\n        threshold=threshold,\n        n_permutations=n_permutations,\n        tail=tail,\n        stat_fun=stat_fun,\n        adjacency=adjacency,\n        n_jobs=n_jobs,\n        seed=seed,\n        max_step=max_step,\n        exclude=exclude,\n        step_down_p=step_down_p,\n        t_power=t_power,\n        out_type=out_type,\n        check_disjoint=check_disjoint,\n        buffer_size=buffer_size,\n    )", "metadata": {}}
{"_id": "mne_mne_stats/cluster_level.py_permutation_cluster_1samp_test_code", "title": "permutation_cluster_1samp_test", "text": "def permutation_cluster_1samp_test(\n    X,\n    threshold=None,\n    n_permutations=1024,\n    tail=0,\n    stat_fun=None,\n    adjacency=None,\n    n_jobs=None,\n    seed=None,\n    max_step=1,\n    exclude=None,\n    step_down_p=0,\n    t_power=1,\n    out_type=\"indices\",\n    check_disjoint=False,\n    buffer_size=1000,\n    verbose=None,\n):\n    \"\"\"Non-parametric cluster-level paired t-test.\n\n    For details, see :footcite:p:`MarisOostenveld2007,Sassenhagen2019`.\n\n    Parameters\n    ----------\n    X : array, shape (n_observations, p[, q][, r])\n        The data to be clustered. The first dimension should correspond to the\n        difference between paired samples (observations) in two conditions.\n        The subarrays ``X[k]`` can be 1D (e.g., time series), 2D (e.g.,\n        time series over channels), or 3D (e.g., time-frequencies over\n        channels) associated with the kth observation. For spatiotemporal data,\n        see also :func:`mne.stats.spatio_temporal_cluster_1samp_test`.\n    %(threshold_clust_t)s\n    %(n_permutations_clust_all)s\n    %(tail_clust)s\n    %(stat_fun_clust_t)s\n    %(adjacency_clust_1)s\n    %(n_jobs)s\n    %(seed)s\n    %(max_step_clust)s\n    %(exclude_clust)s\n    %(step_down_p_clust)s\n    %(t_power_clust)s\n    %(out_type_clust)s\n    %(check_disjoint_clust)s\n    %(buffer_size_clust)s\n    %(verbose)s\n\n    Returns\n    -------\n    t_obs : array, shape (p[, q][, r])\n        T-statistic observed for all variables.\n    clusters : list\n        List type defined by out_type above.\n    cluster_pv : array\n        P-value for each cluster.\n    H0 : array, shape (n_permutations,)\n        Max cluster level stats observed under permutation.\n\n    Notes\n    -----\n    From an array of paired observations, e.g. a difference in signal\n    amplitudes or power spectra in two conditions, calculate if the data\n    distributions in the two conditions are significantly different.\n    The procedure uses a cluster analysis with permutation test\n    for calculating corrected p-values. Randomized data are generated with\n    random sign flips. See :footcite:`MarisOostenveld2007` for more\n    information.\n\n    Because a 1-sample t-test on the difference in observations is\n    mathematically equivalent to a paired t-test, internally this function\n    computes a 1-sample t-test (by default) and uses sign flipping (always)\n    to perform permutations. This might not be suitable for the case where\n    there is truly a single observation under test; see :ref:`disc-stats`.\n    %(threshold_clust_t_notes)s\n\n    If ``n_permutations`` exceeds the maximum number of possible permutations\n    given the number of observations, then ``n_permutations`` and ``seed``\n    will be ignored since an exact test (full permutation test) will be\n    performed (this is the case when\n    ``n_permutations >= 2 ** (n_observations - (tail == 0))``).\n\n    If no initial clusters are found because all points in the true\n    distribution are below the threshold, then ``clusters``, ``cluster_pv``,\n    and ``H0`` will all be empty arrays.\n\n    References\n    ----------\n    .. footbibliography::\n    \"\"\"\n    stat_fun, threshold = _check_fun(X, stat_fun, threshold, tail)\n    return _permutation_cluster_test(\n        X=[X],\n        threshold=threshold,\n        n_permutations=n_permutations,\n        tail=tail,\n        stat_fun=stat_fun,\n        adjacency=adjacency,\n        n_jobs=n_jobs,\n        seed=seed,\n        max_step=max_step,\n        exclude=exclude,\n        step_down_p=step_down_p,\n        t_power=t_power,\n        out_type=out_type,\n        check_disjoint=check_disjoint,\n        buffer_size=buffer_size,\n    )", "metadata": {}}
{"_id": "mne_mne_stats/cluster_level.py_spatio_temporal_cluster_1samp_test_code", "title": "spatio_temporal_cluster_1samp_test", "text": "def spatio_temporal_cluster_1samp_test(\n    X,\n    threshold=None,\n    n_permutations=1024,\n    tail=0,\n    stat_fun=None,\n    adjacency=None,\n    n_jobs=None,\n    seed=None,\n    max_step=1,\n    spatial_exclude=None,\n    step_down_p=0,\n    t_power=1,\n    out_type=\"indices\",\n    check_disjoint=False,\n    buffer_size=1000,\n    verbose=None,\n):\n    \"\"\"Non-parametric cluster-level paired t-test for spatio-temporal data.\n\n    This function provides a convenient wrapper for\n    :func:`mne.stats.permutation_cluster_1samp_test`, for use with data\n    organized in the form (observations \u00d7 time \u00d7 space),\n    (observations \u00d7 frequencies \u00d7 space), or optionally\n    (observations \u00d7 time \u00d7 frequencies \u00d7 space). For details, see\n    :footcite:p:`MarisOostenveld2007,Sassenhagen2019`.\n\n    Parameters\n    ----------\n    X : array, shape (n_observations, p[, q], n_vertices)\n        The data to be clustered. The first dimension should correspond to the\n        difference between paired samples (observations) in two conditions.\n        The second, and optionally third, dimensions correspond to the\n        time or time-frequency data. And, the last dimension should be spatial.\n    %(threshold_clust_t)s\n    %(n_permutations_clust_all)s\n    %(tail_clust)s\n    %(stat_fun_clust_t)s\n    %(adjacency_clust_st1)s\n    %(n_jobs)s\n    %(seed)s\n    %(max_step_clust)s\n    spatial_exclude : list of int or None\n        List of spatial indices to exclude from clustering.\n    %(step_down_p_clust)s\n    %(t_power_clust)s\n    %(out_type_clust)s\n    %(check_disjoint_clust)s\n    %(buffer_size_clust)s\n    %(verbose)s\n\n    Returns\n    -------\n    t_obs : array, shape (p[, q], n_vertices)\n        T-statistic observed for all variables.\n    clusters : list\n        List type defined by out_type above.\n    cluster_pv : array\n        P-value for each cluster.\n    H0 : array, shape (n_permutations,)\n        Max cluster level stats observed under permutation.\n\n    Notes\n    -----\n    %(threshold_clust_t_notes)s\n\n    References\n    ----------\n    .. footbibliography::\n    \"\"\"\n    # convert spatial_exclude before passing on if necessary\n    if spatial_exclude is not None:\n        exclude = _st_mask_from_s_inds(\n            np.prod(X.shape[1:-1]), X.shape[-1], spatial_exclude, True\n        )\n    else:\n        exclude = None\n    return permutation_cluster_1samp_test(\n        X,\n        threshold=threshold,\n        stat_fun=stat_fun,\n        tail=tail,\n        n_permutations=n_permutations,\n        adjacency=adjacency,\n        n_jobs=n_jobs,\n        seed=seed,\n        max_step=max_step,\n        exclude=exclude,\n        step_down_p=step_down_p,\n        t_power=t_power,\n        out_type=out_type,\n        check_disjoint=check_disjoint,\n        buffer_size=buffer_size,\n    )", "metadata": {}}
{"_id": "mne_mne_stats/cluster_level.py_spatio_temporal_cluster_test_code", "title": "spatio_temporal_cluster_test", "text": "def spatio_temporal_cluster_test(\n    X,\n    threshold=None,\n    n_permutations=1024,\n    tail=0,\n    stat_fun=None,\n    adjacency=None,\n    n_jobs=None,\n    seed=None,\n    max_step=1,\n    spatial_exclude=None,\n    step_down_p=0,\n    t_power=1,\n    out_type=\"indices\",\n    check_disjoint=False,\n    buffer_size=1000,\n    verbose=None,\n):\n    \"\"\"Non-parametric cluster-level test for spatio-temporal data.\n\n    This function provides a convenient wrapper for\n    :func:`mne.stats.permutation_cluster_test`, for use with data\n    organized in the form (observations \u00d7 time \u00d7 space),\n    (observations \u00d7 time \u00d7 space), or optionally\n    (observations \u00d7 time \u00d7 frequencies \u00d7 space). For more information,\n    see :footcite:p:`MarisOostenveld2007,Sassenhagen2019`.\n\n    Parameters\n    ----------\n    X : list of array, shape (n_observations, p[, q], n_vertices)\n        The data to be clustered. Each array in ``X`` should contain the\n        observations for one group. The first dimension of each array is the\n        number of observations from that group (and may vary between groups).\n        The second, and optionally third, dimensions correspond to the\n        time or time-frequency data. And, the last dimension should be spatial.\n        All dimensions except the first should match across all groups.\n    %(threshold_clust_f)s\n    %(n_permutations_clust_int)s\n    %(tail_clust)s\n    %(stat_fun_clust_f)s\n    %(adjacency_clust_stn)s\n    %(n_jobs)s\n    %(seed)s\n    %(max_step_clust)s\n    spatial_exclude : list of int or None\n        List of spatial indices to exclude from clustering.\n    %(step_down_p_clust)s\n    %(f_power_clust)s\n    %(out_type_clust)s\n    %(check_disjoint_clust)s\n    %(buffer_size_clust)s\n    %(verbose)s\n\n    Returns\n    -------\n    F_obs : array, shape (p[, q], n_vertices)\n        Statistic (F by default) observed for all variables.\n    clusters : list\n        List type defined by out_type above.\n    cluster_pv: array\n        P-value for each cluster.\n    H0 : array, shape (n_permutations,)\n        Max cluster level stats observed under permutation.\n\n    Notes\n    -----\n    %(threshold_clust_f_notes)s\n\n    References\n    ----------\n    .. footbibliography::\n    \"\"\"\n    # convert spatial_exclude before passing on if necessary\n    if spatial_exclude is not None:\n        exclude = _st_mask_from_s_inds(\n            np.prod(X[0].shape[1:-1]), X[0].shape[-1], spatial_exclude, True\n        )\n    else:\n        exclude = None\n    return permutation_cluster_test(\n        X,\n        threshold=threshold,\n        stat_fun=stat_fun,\n        tail=tail,\n        n_permutations=n_permutations,\n        adjacency=adjacency,\n        n_jobs=n_jobs,\n        seed=seed,\n        max_step=max_step,\n        exclude=exclude,\n        step_down_p=step_down_p,\n        t_power=t_power,\n        out_type=out_type,\n        check_disjoint=check_disjoint,\n        buffer_size=buffer_size,\n    )", "metadata": {}}
{"_id": "mne_mne_stats/cluster_level.py_summarize_clusters_stc_code", "title": "summarize_clusters_stc", "text": "def summarize_clusters_stc(\n    clu, p_thresh=0.05, tstep=1.0, tmin=0, subject=\"fsaverage\", vertices=None\n):\n    \"\"\"Assemble summary SourceEstimate from spatiotemporal cluster results.\n\n    This helps visualizing results from spatio-temporal-clustering\n    permutation tests.\n\n    Parameters\n    ----------\n    clu : tuple\n        The output from clustering permutation tests.\n    p_thresh : float\n        The significance threshold for inclusion of clusters.\n    tstep : float\n        The time step between samples of the original :class:`STC\n        <mne.SourceEstimate>`, in seconds (i.e., ``1 / stc.sfreq``). Defaults\n        to ``1``, which will yield a colormap indicating cluster duration\n        measured in *samples* rather than *seconds*.\n    tmin : float | int\n        The time of the first sample.\n    subject : str\n        The name of the subject.\n    vertices : list of array | instance of SourceSpaces | None\n        The vertex numbers associated with the source space locations. Defaults\n        to None. If None, equals ``[np.arange(10242), np.arange(10242)]``.\n        Can also be an instance of SourceSpaces to get vertex numbers from.\n\n        .. versionchanged:: 0.21\n           Added support for SourceSpaces.\n\n    Returns\n    -------\n    out : instance of SourceEstimate\n        A summary of the clusters. The first time point in this SourceEstimate\n        object is the summation of all the clusters. Subsequent time points\n        contain each individual cluster. The magnitude of the activity\n        corresponds to the duration spanned by the cluster (duration units are\n        determined by ``tstep``).\n\n        .. versionchanged:: 0.21\n           Added support for volume and mixed source estimates.\n    \"\"\"\n    _validate_type(vertices, (None, list, SourceSpaces), \"vertices\")\n    if vertices is None:\n        vertices = [np.arange(10242), np.arange(10242)]\n        klass = SourceEstimate\n    elif isinstance(vertices, SourceSpaces):\n        klass = dict(\n            surface=SourceEstimate, volume=VolSourceEstimate, mixed=MixedSourceEstimate\n        )[vertices.kind]\n        vertices = [s[\"vertno\"] for s in vertices]\n    else:\n        klass = {1: VolSourceEstimate, 2: SourceEstimate}.get(\n            len(vertices), MixedSourceEstimate\n        )\n    n_vertices_need = sum(len(v) for v in vertices)\n\n    t_obs, clusters, clu_pvals, _ = clu\n    n_times, n_vertices = t_obs.shape\n    if n_vertices != n_vertices_need:\n        raise ValueError(\n            f\"Number of cluster vertices ({n_vertices}) did not match the \"\n            f\"provided vertices ({n_vertices_need})\"\n        )\n    good_cluster_inds = np.where(clu_pvals < p_thresh)[0]\n\n    #  Build a convenient representation of each cluster, where each\n    #  cluster becomes a \"time point\" in the SourceEstimate\n    if len(good_cluster_inds) == 0:\n        raise RuntimeError(\n            \"No significant clusters available. Please adjust \"\n            \"your threshold or check your statistical \"\n            \"analysis.\"\n        )\n    data = np.zeros((n_vertices, n_times))\n    data_summary = np.zeros((n_vertices, len(good_cluster_inds) + 1))\n    for ii, cluster_ind in enumerate(good_cluster_inds):\n        data.fill(0)\n        t_inds, v_inds = clusters[cluster_ind]\n        data[v_inds, t_inds] = t_obs[t_inds, v_inds]\n        # Store a nice visualization of the cluster by summing across time\n        data_summary[:, ii + 1] = np.sum(_sum_cluster_data(data, tstep), axis=1)\n        # Make the first \"time point\" a sum across all clusters for easy\n        # visualization\n    data_summary[:, 0] = np.sum(data_summary, axis=1)\n\n    return klass(data_summary, vertices, tmin, tstep, subject)", "metadata": {}}
{"_id": "mne_mne_stats/regression.py_linear_regression_code", "title": "linear_regression", "text": "def linear_regression(inst, design_matrix, names=None):\n    \"\"\"Fit Ordinary Least Squares (OLS) regression.\n\n    Parameters\n    ----------\n    inst : instance of Epochs | iterable of SourceEstimate\n        The data to be regressed. Contains all the trials, sensors, and time\n        points for the regression. For Source Estimates, accepts either a list\n        or a generator object.\n    design_matrix : ndarray, shape (n_observations, n_regressors)\n        The regressors to be used. Must be a 2d array with as many rows as\n        the first dimension of the data. The first column of this matrix will\n        typically consist of ones (intercept column).\n    names : array-like | None\n        Optional parameter to name the regressors (i.e., the columns in the\n        design matrix). If provided, the length must correspond to the number\n        of columns present in design matrix (including the intercept, if\n        present). Otherwise, the default names are ``'x0'``, ``'x1'``,\n        ``'x2', \u2026, 'x(n-1)'`` for ``n`` regressors.\n\n    Returns\n    -------\n    results : dict of namedtuple\n        For each regressor (key), a namedtuple is provided with the\n        following attributes:\n\n            - ``beta`` : regression coefficients\n            - ``stderr`` : standard error of regression coefficients\n            - ``t_val`` : t statistics (``beta`` / ``stderr``)\n            - ``p_val`` : two-sided p-value of t statistic under the t\n              distribution\n            - ``mlog10_p_val`` : -log\u2081\u2080-transformed p-value.\n\n        The tuple members are numpy arrays. The shape of each numpy array is\n        the shape of the data minus the first dimension; e.g., if the shape of\n        the original data was ``(n_observations, n_channels, n_timepoints)``,\n        then the shape of each of the arrays will be\n        ``(n_channels, n_timepoints)``.\n    \"\"\"\n    if names is None:\n        names = [f\"x{i}\" for i in range(design_matrix.shape[1])]\n\n    if isinstance(inst, BaseEpochs):\n        picks = pick_types(\n            inst.info,\n            meg=True,\n            eeg=True,\n            ref_meg=True,\n            stim=False,\n            eog=False,\n            ecg=False,\n            emg=False,\n            exclude=[\"bads\"],\n        )\n        if [inst.ch_names[p] for p in picks] != inst.ch_names:\n            warn(\"Fitting linear model to non-data or bad channels. Check picking\")\n        msg = \"Fitting linear model to epochs\"\n        data = inst.get_data(copy=False)\n        out = EvokedArray(np.zeros(data.shape[1:]), inst.info, inst.tmin)\n    elif isgenerator(inst):\n        msg = \"Fitting linear model to source estimates (generator input)\"\n        out = next(inst)\n        data = np.array([out.data] + [i.data for i in inst])\n    elif isinstance(inst, list) and isinstance(inst[0], SourceEstimate):\n        msg = \"Fitting linear model to source estimates (list input)\"\n        out = inst[0]\n        data = np.array([i.data for i in inst])\n    else:\n        raise ValueError(\"Input must be epochs or iterable of source estimates\")\n    logger.info(msg + f\", ({np.prod(data.shape[1:])} targets, {len(names)} regressors)\")\n    lm_params = _fit_lm(data, design_matrix, names)\n    lm = namedtuple(\"lm\", \"beta stderr t_val p_val mlog10_p_val\")\n    lm_fits = {}\n    for name in names:\n        parameters = [p[name] for p in lm_params]\n        for ii, value in enumerate(parameters):\n            out_ = out.copy()\n            if not isinstance(out_, SourceEstimate | Evoked):\n                raise RuntimeError(\"Invalid container.\")\n            out_._data[:] = value\n            parameters[ii] = out_\n        lm_fits[name] = lm(*parameters)\n    logger.info(\"Done\")\n    return lm_fits", "metadata": {}}
{"_id": "mne_mne_stats/regression.py_linear_regression_raw_code", "title": "linear_regression_raw", "text": "def linear_regression_raw(\n    raw,\n    events,\n    event_id=None,\n    tmin=-0.1,\n    tmax=1,\n    covariates=None,\n    reject=None,\n    flat=None,\n    tstep=1.0,\n    decim=1,\n    picks=None,\n    solver=\"cholesky\",\n):\n    \"\"\"Estimate regression-based evoked potentials/fields by linear modeling.\n\n    This models the full M/EEG time course, including correction for\n    overlapping potentials and allowing for continuous/scalar predictors.\n    Internally, this constructs a predictor matrix X of size\n    n_samples * (n_conds * window length), solving the linear system\n    ``Y = bX`` and returning ``b`` as evoked-like time series split by\n    condition. See :footcite:`SmithKutas2015`.\n\n    Parameters\n    ----------\n    raw : instance of Raw\n        A raw object. Note: be very careful about data that is not\n        downsampled, as the resulting matrices can be enormous and easily\n        overload your computer. Typically, 100 Hz sampling rate is\n        appropriate - or using the decim keyword (see below).\n    events : ndarray of int, shape (n_events, 3)\n        An array where the first column corresponds to samples in raw\n        and the last to integer codes in event_id.\n    event_id : dict | None\n        As in Epochs; a dictionary where the values may be integers or\n        iterables of integers, corresponding to the 3rd column of\n        events, and the keys are condition names.\n        If None, uses all events in the events array.\n    tmin : float | dict\n        If float, gives the lower limit (in seconds) for the time window for\n        which all event types' effects are estimated. If a dict, can be used to\n        specify time windows for specific event types: keys correspond to keys\n        in event_id and/or covariates; for missing values, the default (-.1) is\n        used.\n    tmax : float | dict\n        If float, gives the upper limit (in seconds) for the time window for\n        which all event types' effects are estimated. If a dict, can be used to\n        specify time windows for specific event types: keys correspond to keys\n        in event_id and/or covariates; for missing values, the default (1.) is\n        used.\n    covariates : dict-like | None\n        If dict-like (e.g., a pandas DataFrame), values have to be array-like\n        and of the same length as the rows in ``events``. Keys correspond\n        to additional event types/conditions to be estimated and are matched\n        with the time points given by the first column of ``events``. If\n        None, only binary events (from event_id) are used.\n    reject : None | dict\n        For cleaning raw data before the regression is performed: set up\n        rejection parameters based on peak-to-peak amplitude in continuously\n        selected subepochs. If None, no rejection is done.\n        If dict, keys are types ('grad' | 'mag' | 'eeg' | 'eog' | 'ecg')\n        and values are the maximal peak-to-peak values to select rejected\n        epochs, e.g.::\n\n            reject = dict(grad=4000e-12, # T / m (gradiometers)\n                          mag=4e-11, # T (magnetometers)\n                          eeg=40e-5, # V (EEG channels)\n                          eog=250e-5 # V (EOG channels))\n\n    flat : None | dict\n        For cleaning raw data before the regression is performed: set up\n        rejection parameters based on flatness of the signal. If None, no\n        rejection is done. If a dict, keys are ('grad' | 'mag' |\n        'eeg' | 'eog' | 'ecg') and values are minimal peak-to-peak values to\n        select rejected epochs.\n    tstep : float\n        Length of windows for peak-to-peak detection for raw data cleaning.\n    decim : int\n        Decimate by choosing only a subsample of data points. Highly\n        recommended for data recorded at high sampling frequencies, as\n        otherwise huge intermediate matrices have to be created and inverted.\n    %(picks_good_data)s\n    solver : str | callable\n        Either a function which takes as its inputs the sparse predictor\n        matrix X and the observation matrix Y, and returns the coefficient\n        matrix b; or a string.\n        X is of shape (n_times, n_predictors * time_window_length).\n        y is of shape (n_channels, n_times).\n        If str, must be ``'cholesky'``, in which case the solver used is\n        ``linalg.solve(dot(X.T, X), dot(X.T, y))``.\n\n    Returns\n    -------\n    evokeds : dict\n        A dict where the keys correspond to conditions and the values are\n        Evoked objects with the ER[F/P]s. These can be used exactly like any\n        other Evoked object, including e.g. plotting or statistics.\n\n    References\n    ----------\n    .. footbibliography::\n    \"\"\"\n    if isinstance(solver, str):\n        if solver not in {\"cholesky\"}:\n            raise ValueError(f\"No such solver: {solver}\")\n        if solver == \"cholesky\":\n\n            def solver(X, y):\n                a = (X.T * X).toarray()  # dot product of sparse matrices\n                return linalg.solve(\n                    a, X.T * y, assume_a=\"pos\", overwrite_a=True, overwrite_b=True\n                ).T\n\n    elif callable(solver):\n        pass\n    else:\n        raise TypeError(\"The solver must be a str or a callable.\")\n\n    # build data\n    data, info, events = _prepare_rerp_data(raw, events, picks=picks, decim=decim)\n\n    if event_id is None:\n        event_id = {str(v): v for v in set(events[:, 2])}\n\n    # build predictors\n    X, conds, cond_length, tmin_s, tmax_s = _prepare_rerp_preds(\n        n_samples=data.shape[1],\n        sfreq=info[\"sfreq\"],\n        events=events,\n        event_id=event_id,\n        tmin=tmin,\n        tmax=tmax,\n        covariates=covariates,\n    )\n\n    # remove \"empty\" and contaminated data points\n    X, data = _clean_rerp_input(X, data, reject, flat, decim, info, tstep)\n\n    # solve linear system\n    coefs = solver(X, data.T)\n    if coefs.shape[0] != data.shape[0]:\n        raise ValueError(\n            f\"solver output has unexcepted shape {coefs.shape}. Supply a \"\n            \"function that returns coefficients in the form \"\n            \"(n_targets, n_features), where \"\n            f\"n_targets == n_channels == {data.shape[0]}.\"\n        )\n\n    # construct Evoked objects to be returned from output\n    evokeds = _make_evokeds(coefs, conds, cond_length, tmin_s, tmax_s, info)\n\n    return evokeds", "metadata": {}}
{"_id": "mne_mne_stats/_adjacency.py_combine_adjacency_code", "title": "combine_adjacency", "text": "def combine_adjacency(*structure):\n    \"\"\"Create a sparse binary adjacency/neighbors matrix.\n\n    Parameters\n    ----------\n    *structure : list\n        The adjacency along each dimension. Each entry can be:\n\n        - ndarray or scipy.sparse.sparray\n            A square binary adjacency matrix for the given dimension.\n            For example created by :func:`mne.channels.find_ch_adjacency`.\n        - int\n            The number of elements along the given dimension. A lattice\n            adjacency will be generated, which is a binary matrix\n            reflecting that element N of an array is adjacent to\n            elements at indices N - 1 and N + 1.\n\n    Returns\n    -------\n    adjacency : scipy.sparse.coo_array, shape (n_features, n_features)\n        The square adjacency matrix, where the shape ``n_features``\n        corresponds to the product of the length of all dimensions.\n        For example ``len(times) * len(freqs) * len(chans)``.\n\n    See Also\n    --------\n    mne.channels.find_ch_adjacency\n    mne.channels.read_ch_adjacency\n\n    Notes\n    -----\n    For 4-dimensional data with shape ``(n_obs, n_times, n_freqs, n_chans)``,\n    you can specify **no** connections among elements in a particular\n    dimension by passing a matrix of zeros. For example:\n\n    >>> import numpy as np\n    >>> from scipy.sparse import diags\n    >>> from mne.stats import combine_adjacency\n    >>> n_times, n_freqs, n_chans = (50, 7, 16)\n    >>> chan_adj = diags([1., 1.], offsets=(-1, 1), shape=(n_chans, n_chans))\n    >>> combine_adjacency(\n    ...     n_times,  # regular lattice adjacency for times\n    ...     np.zeros((n_freqs, n_freqs)),  # no adjacency between freq. bins\n    ...     chan_adj,  # custom matrix, or use mne.channels.find_ch_adjacency\n    ...     )  # doctest: +SKIP\n    <5600x5600 sparse array of type '<class 'numpy.float64'>'\n            with 27076 stored elements in COOrdinate format>\n    \"\"\"\n    structure = list(structure)\n    for di, dim in enumerate(structure):\n        name = f\"structure[{di}]\"\n        _validate_type(dim, (\"int-like\", np.ndarray, \"sparse\"), name)\n        if isinstance(dim, int_like):\n            # Don't add the diagonal, because we explicitly remove it later\n            dim = sparse.dia_array(\n                (np.ones((2, dim)), [-1, 1]),\n                shape=(dim, dim),\n            ).tocoo()\n        else:\n            _check_option(f\"{name}.ndim\", dim.ndim, [2])\n            if dim.shape[0] != dim.shape[1]:\n                raise ValueError(f\"{name} must be square, got shape {dim.shape}\")\n            if not isinstance(dim, sparse.coo_array):\n                dim = sparse.coo_array(dim)\n            else:\n                dim = dim.copy()\n        dim.data[dim.row == dim.col] = 0.0  # remove diagonal, will add later\n        dim.eliminate_zeros()\n        if not (dim.data == 1).all():\n            raise ValueError(\"All adjacency values must be 0 or 1\")\n        structure[di] = dim\n    # list of coo\n    assert all(isinstance(dim, sparse.coo_array) for dim in structure)\n    shape = np.array([d.shape[0] for d in structure], int)\n    n_others = np.array(\n        [\n            np.prod(np.concatenate([shape[:di], shape[di + 1 :]]))\n            for di in range(len(structure))\n        ],\n        int,\n    )\n    n_each = np.array([dim.data.size for dim in structure], int) * n_others\n    n_off = n_each.sum()  # off-diagonal terms\n    n_diag = np.prod(shape)\n    vertices = np.arange(n_diag).reshape(shape)\n    edges = np.empty((2, n_off + n_diag), int)\n    used = np.zeros(n_off, bool)\n    weights = np.empty(n_off + n_diag, float)  # even though just 0/1\n    offset = 0\n    for di, dim in enumerate(structure):\n        s_l = [slice(None)] * len(shape)\n        s_r = [slice(None)] * len(shape)\n        s_l[di] = dim.row\n        s_r[di] = dim.col\n        assert dim.row.shape == dim.col.shape == dim.data.shape\n        sl = slice(offset, offset + n_each[di])\n        edges[:, sl] = [vertices[tuple(s_l)].ravel(), vertices[tuple(s_r)].ravel()]\n        weights[sl] = np.tile(dim.data, n_others[di])\n        offset += n_each[di]\n        assert not used[sl].any()\n        used[sl] = True\n    assert used.all()\n    # Handle the diagonal separately at the end to avoid duplicate entries\n    edges[:, n_off:] = vertices.ravel()\n    weights[n_off:] = 1.0\n    graph = sparse.coo_array((weights, edges), (vertices.size, vertices.size))\n    return graph", "metadata": {}}
{"_id": "mne_mne_stats/parametric.py_ttest_1samp_no_p_code", "title": "ttest_1samp_no_p", "text": "def ttest_1samp_no_p(X, sigma=0, method=\"relative\"):\n    \"\"\"Perform one-sample t-test.\n\n    This is a modified version of :func:`scipy.stats.ttest_1samp` that avoids\n    a (relatively) time-consuming p-value calculation, and can adjust\n    for implausibly small variance values :footcite:`RidgwayEtAl2012`.\n\n    Parameters\n    ----------\n    X : array\n        Array to return t-values for.\n    sigma : float\n        The variance estimate will be given by ``var + sigma * max(var)`` or\n        ``var + sigma``, depending on \"method\". By default this is 0 (no\n        adjustment). See Notes for details.\n    method : str\n        If 'relative', the minimum variance estimate will be sigma * max(var),\n        if 'absolute' the minimum variance estimate will be sigma.\n\n    Returns\n    -------\n    t : array\n        T-values, potentially adjusted using the hat method.\n\n    Notes\n    -----\n    To use the \"hat\" adjustment method :footcite:`RidgwayEtAl2012`, a value\n    of ``sigma=1e-3`` may be a reasonable choice.\n\n    References\n    ----------\n    .. footbibliography::\n    \"\"\"\n    _check_option(\"method\", method, [\"absolute\", \"relative\"])\n    var = np.var(X, axis=0, ddof=1)\n    if sigma > 0:\n        limit = sigma * np.max(var) if method == \"relative\" else sigma\n        var += limit\n    return np.mean(X, axis=0) / np.sqrt(var / X.shape[0])", "metadata": {}}
{"_id": "mne_mne_stats/parametric.py_ttest_ind_no_p_code", "title": "ttest_ind_no_p", "text": "def ttest_ind_no_p(a, b, equal_var=True, sigma=0.0):\n    \"\"\"Independent samples t-test without p calculation.\n\n    This is a modified version of :func:`scipy.stats.ttest_ind`. It operates\n    along the first axis. The ``sigma`` parameter provides an optional \"hat\"\n    adjustment (see :func:`ttest_1samp_no_p` and :footcite:`RidgwayEtAl2012`).\n\n    Parameters\n    ----------\n    a : array-like\n        The first array.\n    b : array-like\n        The second array.\n    equal_var : bool\n        Assume equal variance. See :func:`scipy.stats.ttest_ind`.\n    sigma : float\n        The regularization. See :func:`ttest_1samp_no_p`.\n\n    Returns\n    -------\n    t : array\n        T values.\n\n    References\n    ----------\n    .. footbibliography::\n    \"\"\"\n    v1 = np.var(a, axis=0, ddof=1)\n    v2 = np.var(b, axis=0, ddof=1)\n    n1 = a.shape[0]\n    n2 = b.shape[0]\n    if equal_var:\n        df = n1 + n2 - 2.0\n        var = ((n1 - 1) * v1 + (n2 - 1) * v2) / df\n        var = var * (1.0 / n1 + 1.0 / n2)\n    else:\n        vn1 = v1 / n1\n        vn2 = v2 / n2\n        with np.errstate(divide=\"ignore\", invalid=\"ignore\"):\n            df = (vn1 + vn2) ** 2 / (vn1**2 / (n1 - 1) + vn2**2 / (n2 - 1))\n\n        # If df is undefined, variances are zero (assumes n1 > 0 & n2 > 0).\n        # Hence it doesn't matter what df is as long as it's not NaN.\n        df = np.where(np.isnan(df), 1, df)\n        var = vn1 + vn2\n    if sigma > 0:\n        var += sigma * np.max(var)\n    denom = np.sqrt(var)\n    d = np.mean(a, 0) - np.mean(b, 0)\n    with np.errstate(divide=\"ignore\", invalid=\"ignore\"):\n        t = np.divide(d, denom)\n    return t", "metadata": {}}
{"_id": "mne_mne_stats/parametric.py_f_oneway_code", "title": "f_oneway", "text": "def f_oneway(*args):\n    \"\"\"Perform a 1-way ANOVA.\n\n    The one-way ANOVA tests the null hypothesis that 2 or more groups have\n    the same population mean. The test is applied to samples from two or\n    more groups, possibly with differing sizes :footcite:`Lowry2014`.\n\n    This is a modified version of :func:`scipy.stats.f_oneway` that avoids\n    computing the associated p-value.\n\n    Parameters\n    ----------\n    *args : array_like\n        The sample measurements should be given as arguments.\n\n    Returns\n    -------\n    F-value : float\n        The computed F-value of the test.\n\n    Notes\n    -----\n    The ANOVA test has important assumptions that must be satisfied in order\n    for the associated p-value to be valid.\n\n    1. The samples are independent\n    2. Each sample is from a normally distributed population\n    3. The population standard deviations of the groups are all equal. This\n       property is known as homoscedasticity.\n\n    If these assumptions are not true for a given set of data, it may still be\n    possible to use the Kruskal-Wallis H-test (:func:`scipy.stats.kruskal`)\n    although with some loss of power.\n\n    The algorithm is from Heiman :footcite:`Heiman2002`, pp.394-7.\n\n    References\n    ----------\n    .. footbibliography::\n    \"\"\"\n    n_classes = len(args)\n    n_samples_per_class = np.array([len(a) for a in args])\n    n_samples = np.sum(n_samples_per_class)\n    ss_alldata = reduce(lambda x, y: x + y, [np.sum(a**2, axis=0) for a in args])\n    sums_args = [np.sum(a, axis=0) for a in args]\n    square_of_sums_alldata = reduce(lambda x, y: x + y, sums_args) ** 2\n    square_of_sums_args = [s**2 for s in sums_args]\n    sstot = ss_alldata - square_of_sums_alldata / float(n_samples)\n    ssbn = 0\n    for k, _ in enumerate(args):\n        ssbn += square_of_sums_args[k] / n_samples_per_class[k]\n    ssbn -= square_of_sums_alldata / float(n_samples)\n    sswn = sstot - ssbn\n    dfbn = n_classes - 1\n    dfwn = n_samples - n_classes\n    msb = ssbn / float(dfbn)\n    msw = sswn / float(dfwn)\n    f = msb / msw\n    return f", "metadata": {}}
{"_id": "mne_mne_stats/parametric.py_f_threshold_mway_rm_code", "title": "f_threshold_mway_rm", "text": "def f_threshold_mway_rm(n_subjects, factor_levels, effects=\"A*B\", pvalue=0.05):\n    \"\"\"Compute F-value thresholds for a two-way ANOVA.\n\n    Parameters\n    ----------\n    n_subjects : int\n        The number of subjects to be analyzed.\n    factor_levels : list-like\n        The number of levels per factor.\n    effects : str\n        A string denoting the effect to be returned. The following\n        mapping is currently supported:\n\n            * ``'A'``: main effect of A\n            * ``'B'``: main effect of B\n            * ``'A:B'``: interaction effect\n            * ``'A+B'``: both main effects\n            * ``'A*B'``: all three effects\n\n    pvalue : float\n        The p-value to be thresholded.\n\n    Returns\n    -------\n    F_threshold : list | float\n        List of F-values for each effect if the number of effects\n        requested > 2, else float.\n\n    See Also\n    --------\n    f_oneway\n    f_mway_rm\n\n    Notes\n    -----\n    .. versionadded:: 0.10\n    \"\"\"\n    effect_picks, _ = _map_effects(len(factor_levels), effects)\n\n    F_threshold = []\n    for _, df1, df2 in _iter_contrasts(n_subjects, factor_levels, effect_picks):\n        F_threshold.append(stats.f(df1, df2).isf(pvalue))\n\n    return F_threshold if len(F_threshold) > 1 else F_threshold[0]", "metadata": {}}
{"_id": "mne_mne_stats/parametric.py_f_mway_rm_code", "title": "f_mway_rm", "text": "def f_mway_rm(data, factor_levels, effects=\"all\", correction=False, return_pvals=True):\n    \"\"\"Compute M-way repeated measures ANOVA for fully balanced designs.\n\n    Parameters\n    ----------\n    data : ndarray\n        3D array where the first two dimensions are compliant\n        with a subjects X conditions scheme where the first\n        factor repeats slowest::\n\n                        A1B1 A1B2 A2B1 A2B2\n            subject 1   1.34 2.53 0.97 1.74\n            subject ... .... .... .... ....\n            subject k   2.45 7.90 3.09 4.76\n\n        The last dimensions is thought to carry the observations\n        for mass univariate analysis.\n    factor_levels : list-like\n        The number of levels per factor.\n    effects : str | list\n        A string denoting the effect to be returned. The following\n        mapping is currently supported (example with 2 factors):\n\n            * ``'A'``: main effect of A\n            * ``'B'``: main effect of B\n            * ``'A:B'``: interaction effect\n            * ``'A+B'``: both main effects\n            * ``'A*B'``: all three effects\n            * ``'all'``: all effects (equals 'A*B' in a 2 way design)\n\n        If list, effect names are used: ``['A', 'B', 'A:B']``.\n    correction : bool\n        The correction method to be employed if one factor has more than two\n        levels. If True, sphericity correction using the Greenhouse-Geisser\n        method will be applied.\n    return_pvals : bool\n        If True, return p-values corresponding to F-values.\n\n    Returns\n    -------\n    F_vals : ndarray\n        An array of F-statistics with length corresponding to the number\n        of effects estimated. The shape depends on the number of effects\n        estimated.\n    p_vals : ndarray\n        If not requested via return_pvals, defaults to an empty array.\n\n    See Also\n    --------\n    f_oneway\n    f_threshold_mway_rm\n\n    Notes\n    -----\n    .. versionadded:: 0.10\n    \"\"\"\n    out_reshape = (-1,)\n    if data.ndim == 2:  # general purpose support, e.g. behavioural data\n        data = data[:, :, np.newaxis]\n    elif data.ndim > 3:  # let's allow for some magic here\n        out_reshape = data.shape[2:]\n        data = data.reshape(data.shape[0], data.shape[1], np.prod(data.shape[2:]))\n\n    effect_picks, _ = _map_effects(len(factor_levels), effects)\n    n_obs = data.shape[2]\n    n_replications = data.shape[0]\n\n    # put last axis in front to 'iterate' over mass univariate instances.\n    data = np.rollaxis(data, 2)\n    fvalues, pvalues = [], []\n    for c_, df1, df2 in _iter_contrasts(n_replications, factor_levels, effect_picks):\n        y = np.dot(data, c_)\n        b = np.mean(y, axis=1)[:, np.newaxis, :]\n        ss = np.sum(np.sum(y * b, axis=2), axis=1)\n        mse = (np.sum(np.sum(y * y, axis=2), axis=1) - ss) / (df2 / df1)\n        fvals = ss / mse\n        fvalues.append(fvals)\n        if correction:\n            # sample covariances, leave off \"/ (y.shape[1] - 1)\" norm because\n            # it falls out.\n            v = np.array([np.dot(y_.T, y_) for y_ in y])\n            v = np.array([np.trace(vv) for vv in v]) ** 2 / (\n                df1 * np.sum(np.sum(v * v, axis=2), axis=1)\n            )\n            eps = v\n\n        df1, df2 = np.zeros(n_obs) + df1, np.zeros(n_obs) + df2\n        if correction:\n            # numerical imprecision can cause eps=0.99999999999999989\n            # even with a single category, so never let our degrees of\n            # freedom drop below 1.\n            df1, df2 = (np.maximum(d[None, :] * eps, 1.0) for d in (df1, df2))\n\n        if return_pvals:\n            pvals = stats.f(df1, df2).sf(fvals)\n        else:\n            pvals = np.empty(0)\n        pvalues.append(pvals)\n\n    # handle single effect returns\n    return [\n        np.squeeze(np.asarray([v.reshape(out_reshape) for v in vv]))\n        for vv in (fvalues, pvalues)\n    ]", "metadata": {}}
{"_id": "mne_mne_simulation/raw.py_simulate_raw_code", "title": "simulate_raw", "text": "def simulate_raw(\n    info,\n    stc=None,\n    trans=None,\n    src=None,\n    bem=None,\n    head_pos=None,\n    mindist=1.0,\n    interp=\"cos2\",\n    n_jobs=None,\n    use_cps=True,\n    forward=None,\n    first_samp=0,\n    max_iter=10000,\n    verbose=None,\n):\n    \"\"\"Simulate raw data.\n\n    Head movements can optionally be simulated using the ``head_pos``\n    parameter.\n\n    Parameters\n    ----------\n    %(info_not_none)s Used for simulation.\n\n        .. versionchanged:: 0.18\n           Support for :class:`mne.Info`.\n    stc : iterable | SourceEstimate | SourceSimulator\n        The source estimates to use to simulate data. Each must have the same\n        sample rate as the raw data, and the vertices of all stcs in the\n        iterable must match. Each entry in the iterable can also be a tuple of\n        ``(SourceEstimate, ndarray)`` to allow specifying the stim channel\n        (e.g., STI001) data accompany the source estimate.\n        See Notes for details.\n\n        .. versionchanged:: 0.18\n           Support for tuple, iterable of tuple or `~mne.SourceEstimate`,\n           or `~mne.simulation.SourceSimulator`.\n    trans : dict | str | None\n        Either a transformation filename (usually made using mne_analyze)\n        or an info dict (usually opened using read_trans()).\n        If string, an ending of ``.fif`` or ``.fif.gz`` will be assumed to\n        be in FIF format, any other ending will be assumed to be a text\n        file with a 4x4 transformation matrix (like the ``--trans`` MNE-C\n        option). If trans is None, an identity transform will be used.\n    src : path-like | instance of SourceSpaces | None\n        Source space corresponding to the stc. If string, should be a source\n        space filename. Can also be an instance of loaded or generated\n        SourceSpaces. Can be None if ``forward`` is provided.\n    bem : path-like | dict | None\n        BEM solution  corresponding to the stc. If string, should be a BEM\n        solution filename (e.g., \"sample-5120-5120-5120-bem-sol.fif\").\n        Can be None if ``forward`` is provided.\n    %(head_pos)s\n        See for example :footcite:`LarsonTaulu2017`.\n    mindist : float\n        Minimum distance between sources and the inner skull boundary\n        to use during forward calculation.\n    %(interp)s\n    %(n_jobs)s\n    %(use_cps)s\n    forward : instance of Forward | None\n        The forward operator to use. If None (default) it will be computed\n        using ``bem``, ``trans``, and ``src``. If not None,\n        ``bem``, ``trans``, and ``src`` are ignored.\n\n        .. versionadded:: 0.17\n    first_samp : int\n        The first_samp property in the output Raw instance.\n\n        .. versionadded:: 0.18\n    max_iter : int\n        The maximum number of STC iterations to allow.\n        This is a sanity parameter to prevent accidental blowups.\n\n        .. versionadded:: 0.18\n    %(verbose)s\n\n    Returns\n    -------\n    raw : instance of Raw\n        The simulated raw file.\n\n    See Also\n    --------\n    mne.chpi.read_head_pos\n    add_chpi\n    add_noise\n    add_ecg\n    add_eog\n    simulate_evoked\n    simulate_stc\n    simulate_sparse_stc\n\n    Notes\n    -----\n    **Stim channel encoding**\n\n    By default, the stimulus channel will have the head position number\n    (starting at 1) stored in the trigger channel (if available) at the\n    t=0 point in each repetition of the ``stc``. If ``stc`` is a tuple of\n    ``(SourceEstimate, ndarray)`` the array values will be placed in the\n    stim channel aligned with the :class:`mne.SourceEstimate`.\n\n    **Data simulation**\n\n    In the most advanced case where ``stc`` is an iterable of tuples the output\n    will be concatenated in time as:\n\n    .. table:: Data alignment and stim channel encoding\n\n       +---------+--------------------------+--------------------------+---------+\n       | Channel | Data                                                          |\n       +=========+==========================+==========================+=========+\n       | M/EEG   | ``fwd @ stc[0][0].data`` | ``fwd @ stc[1][0].data`` | ``...`` |\n       +---------+--------------------------+--------------------------+---------+\n       | STIM    | ``stc[0][1]``            | ``stc[1][1]``            | ``...`` |\n       +---------+--------------------------+--------------------------+---------+\n       |         | *time \u2192*                                                      |\n       +---------+--------------------------+--------------------------+---------+\n\n    .. versionadded:: 0.10.0\n\n    References\n    ----------\n    .. footbibliography::\n    \"\"\"  # noqa: E501\n    _validate_type(info, Info, \"info\")\n\n    if len(pick_types(info, meg=False, stim=True)) == 0:\n        event_ch = None\n    else:\n        event_ch = pick_channels(info[\"ch_names\"], _get_stim_channel(None, info))[0]\n\n    if forward is not None:\n        if any(x is not None for x in (trans, src, bem, head_pos)):\n            raise ValueError(\n                \"If forward is not None then trans, src, bem, \"\n                \"and head_pos must all be None\"\n            )\n        if not np.allclose(\n            forward[\"info\"][\"dev_head_t\"][\"trans\"],\n            info[\"dev_head_t\"][\"trans\"],\n            atol=1e-6,\n        ):\n            raise ValueError(\n                \"The forward meg<->head transform \"\n                'forward[\"info\"][\"dev_head_t\"] does not match '\n                'the one in raw.info[\"dev_head_t\"]'\n            )\n        src = forward[\"src\"]\n\n    dev_head_ts, offsets = _check_head_pos(head_pos, info, first_samp, None)\n\n    src = _ensure_src(src, verbose=False)\n    if isinstance(bem, str):\n        bem = read_bem_solution(bem, verbose=False)\n\n    # Extract necessary info\n    meeg_picks = pick_types(info, meg=True, eeg=True, exclude=[])\n    logger.info(\n        f\"Setting up raw simulation: {len(dev_head_ts)} \"\n        f'position{_pl(dev_head_ts)}, \"{interp}\" interpolation'\n    )\n\n    if isinstance(stc, SourceSimulator) and stc.first_samp != first_samp:\n        logger.info(\"SourceSimulator first_samp does not match argument.\")\n\n    stc_enum, stc_counted, verts = _check_stc_iterable(stc, info)\n    if forward is not None:\n        forward = restrict_forward_to_stc(forward, verts)\n        src = forward[\"src\"]\n    else:\n        _stc_src_sel(src, verts, on_missing=\"warn\", extra=\"\")\n        src = _set_source_space_vertices(src.copy(), verts)\n\n    # array used to store result\n    raw_datas = list()\n    _log_ch(\"Event information\", info, event_ch)\n    # don't process these any more if no MEG present\n    n = 1\n    get_fwd = _SimForwards(\n        dev_head_ts,\n        offsets,\n        info,\n        trans,\n        src,\n        bem,\n        mindist,\n        n_jobs,\n        meeg_picks,\n        forward,\n        use_cps,\n    )\n    interper = _Interp2(offsets, get_fwd, interp)\n\n    this_start = 0\n    for n in range(max_iter):\n        if isinstance(stc_counted[1], list | tuple):\n            this_n = stc_counted[1][0].data.shape[1]\n        else:\n            this_n = stc_counted[1].data.shape[1]\n        this_stop = this_start + this_n\n        logger.info(\n            f\"    Interval {this_start / info['sfreq']:0.3f}\u2013\"\n            f\"{this_stop / info['sfreq']:0.3f} s\"\n        )\n        n_doing = this_stop - this_start\n        assert n_doing > 0\n        this_data = np.zeros((len(info[\"ch_names\"]), n_doing))\n        raw_datas.append(this_data)\n        # Stim channel\n        fwd, fi = interper.feed(this_stop - this_start)\n        fi = fi[0]\n        stc_data, stim_data, _ = _stc_data_event(\n            stc_counted, fi, info[\"sfreq\"], get_fwd.src, None if n == 0 else verts\n        )\n        if event_ch is not None:\n            this_data[event_ch, :] = stim_data[:n_doing]\n        this_data[meeg_picks] = np.einsum(\"svt,vt->st\", fwd, stc_data)\n        try:\n            stc_counted = next(stc_enum)\n        except StopIteration:\n            logger.info(f\"    {n + 1} STC iteration{_pl(n + 1)} provided\")\n            break\n        del fwd\n    else:\n        raise RuntimeError(f\"Maximum number of STC iterations ({n}) exceeded\")\n    raw_data = np.concatenate(raw_datas, axis=-1)\n    raw = RawArray(raw_data, info, first_samp=first_samp, verbose=False)\n    raw.set_annotations(raw.annotations)\n    logger.info(\"[done]\")\n    return raw", "metadata": {}}
{"_id": "mne_mne_simulation/raw.py_add_eog_code", "title": "add_eog", "text": "def add_eog(\n    raw, head_pos=None, interp=\"cos2\", n_jobs=None, random_state=None, verbose=None\n):\n    \"\"\"Add blink noise to raw data.\n\n    Parameters\n    ----------\n    raw : instance of Raw\n        The raw instance to modify.\n    %(head_pos)s\n    %(interp)s\n    %(n_jobs)s\n    %(random_state)s\n        The random generator state used for blink, ECG, and sensor noise\n        randomization.\n    %(verbose)s\n\n    Returns\n    -------\n    raw : instance of Raw\n        The instance, modified in place.\n\n    See Also\n    --------\n    add_chpi\n    add_ecg\n    add_noise\n    simulate_raw\n\n    Notes\n    -----\n    The blink artifacts are generated by:\n\n    1. Random activation times are drawn from an inhomogeneous poisson\n       process whose blink rate oscillates between 4.5 blinks/minute\n       and 17 blinks/minute based on the low (reading) and high (resting)\n       blink rates from :footcite:`BentivoglioEtAl1997`.\n    2. The activation kernel is a 250 ms Hanning window.\n    3. Two activated dipoles are located in the z=0 plane (in head\n       coordinates) at \u00b130 degrees away from the y axis (nasion).\n    4. Activations affect MEG and EEG channels.\n\n    The scale-factor of the activation function was chosen based on\n    visual inspection to yield amplitudes generally consistent with those\n    seen in experimental data. Noisy versions of the activation will be\n    stored in the first EOG channel in the raw instance, if it exists.\n\n    References\n    ----------\n    .. footbibliography::\n    \"\"\"\n    return _add_exg(raw, \"blink\", head_pos, interp, n_jobs, random_state)", "metadata": {}}
{"_id": "mne_mne_simulation/raw.py_add_ecg_code", "title": "add_ecg", "text": "def add_ecg(\n    raw, head_pos=None, interp=\"cos2\", n_jobs=None, random_state=None, verbose=None\n):\n    \"\"\"Add ECG noise to raw data.\n\n    Parameters\n    ----------\n    raw : instance of Raw\n        The raw instance to modify.\n    %(head_pos)s\n    %(interp)s\n    %(n_jobs)s\n    %(random_state)s\n        The random generator state used for blink, ECG, and sensor noise\n        randomization.\n    %(verbose)s\n\n    Returns\n    -------\n    raw : instance of Raw\n        The instance, modified in place.\n\n    See Also\n    --------\n    add_chpi\n    add_eog\n    add_noise\n    simulate_raw\n\n    Notes\n    -----\n    The ECG artifacts are generated by:\n\n    1. Random inter-beat intervals are drawn from a uniform distribution\n       of times corresponding to 40 and 80 beats per minute.\n    2. The activation function is the sum of three Hanning windows with\n       varying durations and scales to make a more complex waveform.\n    3. The activated dipole is located one (estimated) head radius to\n       the left (-x) of head center and three head radii below (+z)\n       head center; this dipole is oriented in the +x direction.\n    4. Activations only affect MEG channels.\n\n    The scale-factor of the activation function was chosen based on\n    visual inspection to yield amplitudes generally consistent with those\n    seen in experimental data. Noisy versions of the activation will be\n    stored in the first EOG channel in the raw instance, if it exists.\n\n    .. versionadded:: 0.18\n    \"\"\"\n    return _add_exg(raw, \"ecg\", head_pos, interp, n_jobs, random_state)", "metadata": {}}
{"_id": "mne_mne_simulation/raw.py_add_chpi_code", "title": "add_chpi", "text": "def add_chpi(raw, head_pos=None, interp=\"cos2\", n_jobs=None, verbose=None):\n    \"\"\"Add cHPI activations to raw data.\n\n    Parameters\n    ----------\n    raw : instance of Raw\n        The raw instance to be modified.\n    %(head_pos)s\n    %(interp)s\n    %(n_jobs)s\n    %(verbose)s\n\n    Returns\n    -------\n    raw : instance of Raw\n        The instance, modified in place.\n\n    Notes\n    -----\n    .. versionadded:: 0.18\n    \"\"\"\n    _validate_type(raw, BaseRaw, \"raw\")\n    _check_preload(raw, \"Adding cHPI signals \")\n    info, first_samp, times = raw.info, raw.first_samp, raw.times\n    meg_picks = pick_types(info, meg=True, eeg=False, exclude=[])  # for CHPI\n    if len(meg_picks) == 0:\n        raise RuntimeError(\"Cannot add cHPI if no MEG picks are present\")\n    dev_head_ts, offsets = _check_head_pos(head_pos, info, first_samp, times)\n    hpi_freqs, hpi_pick, hpi_ons = get_chpi_info(info, on_missing=\"raise\")\n    hpi_rrs = _get_hpi_initial_fit(info, verbose=\"error\")\n    hpi_nns = hpi_rrs / np.sqrt(np.sum(hpi_rrs * hpi_rrs, axis=1))[:, np.newaxis]\n    # turn on cHPI in file\n    data = raw._data\n    data[hpi_pick, :] = hpi_ons.sum()\n    _log_ch(\"cHPI status bits enabled and\", info, hpi_pick)\n    sinusoids = 70e-9 * np.sin(\n        2 * np.pi * hpi_freqs[:, np.newaxis] * (np.arange(len(times)) / info[\"sfreq\"])\n    )\n    info = pick_info(info, meg_picks)\n    with info._unlock():\n        info.update(projs=[], bads=[])  # Ensure no 'projs' or 'bads'\n    megcoils = _prep_meg_channels(info, ignore_ref=True)[\"defs\"]\n    used = np.zeros(len(raw.times), bool)\n    dev_head_ts.append(dev_head_ts[-1])  # ZOH after time ends\n    get_fwd = _HPIForwards(offsets, dev_head_ts, megcoils, hpi_rrs, hpi_nns)\n    interper = _Interp2(offsets, get_fwd, interp)\n    lims = np.concatenate([offsets, [len(raw.times)]])\n    for start, stop in zip(lims[:-1], lims[1:]):\n        (fwd,) = interper.feed(stop - start)\n        data[meg_picks, start:stop] += np.einsum(\n            \"svt,vt->st\", fwd, sinusoids[:, start:stop]\n        )\n        assert not used[start:stop].any()\n        used[start:stop] = True\n    assert used.all()\n    return raw", "metadata": {}}
{"_id": "mne_mne_simulation/evoked.py_simulate_evoked_code", "title": "simulate_evoked", "text": "def simulate_evoked(\n    fwd,\n    stc,\n    info,\n    cov=None,\n    nave=30,\n    iir_filter=None,\n    random_state=None,\n    use_cps=True,\n    verbose=None,\n):\n    \"\"\"Generate noisy evoked data.\n\n    .. note:: No projections from ``info`` will be present in the\n              output ``evoked``. You can use e.g.\n              :func:`evoked.add_proj <mne.Evoked.add_proj>` or\n              :func:`evoked.set_eeg_reference <mne.Evoked.set_eeg_reference>`\n              to add them afterward as necessary.\n\n    Parameters\n    ----------\n    fwd : instance of Forward\n        A forward solution.\n    stc : SourceEstimate object\n        The source time courses.\n    %(info_not_none)s Used to generate the evoked.\n    cov : Covariance object | None\n        The noise covariance. If None, no noise is added.\n    nave : int\n        Number of averaged epochs (defaults to 30).\n\n        .. versionadded:: 0.15.0\n    iir_filter : None | array\n        IIR filter coefficients (denominator) e.g. [1, -1, 0.2].\n    %(random_state)s\n    %(use_cps)s\n\n        .. versionadded:: 0.15\n    %(verbose)s\n\n    Returns\n    -------\n    evoked : Evoked object\n        The simulated evoked data.\n\n    See Also\n    --------\n    simulate_raw\n    simulate_stc\n    simulate_sparse_stc\n\n    Notes\n    -----\n    To make the equivalence between snr and nave, when the snr is given\n    instead of nave::\n\n        nave = (1 / 10 ** ((actual_snr - snr)) / 20) ** 2\n\n    where actual_snr is the snr to the generated noise before scaling.\n\n    .. versionadded:: 0.10.0\n    \"\"\"\n    evoked = apply_forward(fwd, stc, info, use_cps=use_cps)\n    if cov is None:\n        return evoked\n\n    if nave < np.inf:\n        noise = _simulate_noise_evoked(evoked, cov, iir_filter, random_state)\n        evoked.data += noise.data / math.sqrt(nave)\n        evoked.nave = np.int64(nave)\n    if cov.get(\"projs\", None):\n        evoked.add_proj(cov[\"projs\"]).apply_proj()\n    return evoked", "metadata": {}}
{"_id": "mne_mne_simulation/evoked.py_add_noise_code", "title": "add_noise", "text": "def add_noise(inst, cov, iir_filter=None, random_state=None, verbose=None):\n    \"\"\"Create noise as a multivariate Gaussian.\n\n    The spatial covariance of the noise is given from the cov matrix.\n\n    Parameters\n    ----------\n    inst : instance of Evoked, Epochs, or Raw\n        Instance to which to add noise.\n    cov : instance of Covariance\n        The noise covariance.\n    iir_filter : None | array-like\n        IIR filter coefficients (denominator).\n    %(random_state)s\n    %(verbose)s\n\n    Returns\n    -------\n    inst : instance of Evoked, Epochs, or Raw\n        The instance, modified to have additional noise.\n\n    Notes\n    -----\n    Only channels in both ``inst.info['ch_names']`` and\n    ``cov['names']`` will have noise added to them.\n\n    This function operates inplace on ``inst``.\n\n    .. versionadded:: 0.18.0\n    \"\"\"\n    # We always allow subselection here\n    return _add_noise(inst, cov, iir_filter, random_state)", "metadata": {}}
{"_id": "mne_mne_simulation/source.py_select_source_in_label_code", "title": "select_source_in_label", "text": "def select_source_in_label(\n    src,\n    label,\n    random_state=None,\n    location=\"random\",\n    subject=None,\n    subjects_dir=None,\n    surf=\"sphere\",\n):\n    \"\"\"Select source positions using a label.\n\n    Parameters\n    ----------\n    src : list of dict\n        The source space.\n    label : Label\n        The label.\n    %(random_state)s\n    location : str\n        The label location to choose. Can be 'random' (default) or 'center'\n        to use :func:`mne.Label.center_of_mass` (restricting to vertices\n        both in the label and in the source space). Note that for 'center'\n        mode the label values are used as weights.\n\n        .. versionadded:: 0.13\n    subject : str | None\n        The subject the label is defined for.\n        Only used with ``location='center'``.\n\n        .. versionadded:: 0.13\n    %(subjects_dir)s\n\n        .. versionadded:: 0.13\n    surf : str\n        The surface to use for Euclidean distance center of mass\n        finding. The default here is \"sphere\", which finds the center\n        of mass on the spherical surface to help avoid potential issues\n        with cortical folding.\n\n        .. versionadded:: 0.13\n\n    Returns\n    -------\n    lh_vertno : list\n        Selected source coefficients on the left hemisphere.\n    rh_vertno : list\n        Selected source coefficients on the right hemisphere.\n    \"\"\"\n    lh_vertno = list()\n    rh_vertno = list()\n    _check_option(\"location\", location, [\"random\", \"center\"])\n\n    rng = check_random_state(random_state)\n    if label.hemi == \"lh\":\n        vertno = lh_vertno\n        hemi_idx = 0\n    else:\n        vertno = rh_vertno\n        hemi_idx = 1\n    src_sel = np.intersect1d(src[hemi_idx][\"vertno\"], label.vertices)\n    if location == \"random\":\n        idx = src_sel[rng_uniform(rng)(0, len(src_sel), 1)[0]]\n    else:  # 'center'\n        idx = label.center_of_mass(\n            subject, restrict_vertices=src_sel, subjects_dir=subjects_dir, surf=surf\n        )\n    vertno.append(idx)\n    return lh_vertno, rh_vertno", "metadata": {}}
{"_id": "mne_mne_simulation/source.py_simulate_sparse_stc_code", "title": "simulate_sparse_stc", "text": "def simulate_sparse_stc(\n    src,\n    n_dipoles,\n    times,\n    data_fun=lambda t: 1e-7 * np.sin(20 * np.pi * t),\n    labels=None,\n    random_state=None,\n    location=\"random\",\n    subject=None,\n    subjects_dir=None,\n    surf=\"sphere\",\n):\n    \"\"\"Generate sparse (n_dipoles) sources time courses from data_fun.\n\n    This function randomly selects ``n_dipoles`` vertices in the whole\n    cortex or one single vertex (randomly in or in the center of) each\n    label if ``labels is not None``. It uses ``data_fun`` to generate\n    waveforms for each vertex.\n\n    Parameters\n    ----------\n    src : instance of SourceSpaces\n        The source space.\n    n_dipoles : int\n        Number of dipoles to simulate.\n    times : array\n        Time array.\n    data_fun : callable\n        Function to generate the waveforms. The default is a 100 nAm, 10 Hz\n        sinusoid as ``1e-7 * np.sin(20 * pi * t)``. The function should take\n        as input the array of time samples in seconds and return an array of\n        the same length containing the time courses.\n    labels : None | list of Label\n        The labels. The default is None, otherwise its size must be n_dipoles.\n    %(random_state)s\n    location : str\n        The label location to choose. Can be ``'random'`` (default) or\n        ``'center'`` to use :func:`mne.Label.center_of_mass`. Note that for\n        ``'center'`` mode the label values are used as weights.\n\n        .. versionadded:: 0.13\n    subject : str | None\n        The subject the label is defined for.\n        Only used with ``location='center'``.\n\n        .. versionadded:: 0.13\n    %(subjects_dir)s\n\n        .. versionadded:: 0.13\n    surf : str\n        The surface to use for Euclidean distance center of mass\n        finding. The default here is \"sphere\", which finds the center\n        of mass on the spherical surface to help avoid potential issues\n        with cortical folding.\n\n        .. versionadded:: 0.13\n\n    Returns\n    -------\n    stc : SourceEstimate\n        The generated source time courses.\n\n    See Also\n    --------\n    simulate_raw\n    simulate_evoked\n    simulate_stc\n\n    Notes\n    -----\n    .. versionadded:: 0.10.0\n    \"\"\"\n    rng = check_random_state(random_state)\n    src = _ensure_src(src, verbose=False)\n    subject_src = src._subject\n    if subject is None:\n        subject = subject_src\n    elif subject_src is not None and subject != subject_src:\n        raise ValueError(\n            f\"subject argument ({subject}) did not match the source \"\n            f\"space subject_his_id ({subject_src})\"\n        )\n    data = np.zeros((n_dipoles, len(times)))\n    for i_dip in range(n_dipoles):\n        data[i_dip, :] = data_fun(times)\n\n    if labels is None:\n        # can be vol or surface source space\n        offsets = np.linspace(0, n_dipoles, len(src) + 1).astype(int)\n        n_dipoles_ss = np.diff(offsets)\n        # don't use .choice b/c not on old numpy\n        vs = [\n            s[\"vertno\"][np.sort(rng.permutation(np.arange(s[\"nuse\"]))[:n])]\n            for n, s in zip(n_dipoles_ss, src)\n        ]\n        datas = data\n    elif n_dipoles > len(labels):\n        raise ValueError(\n            f\"Number of labels ({len(labels)}) smaller than n_dipoles ({n_dipoles:d}) \"\n            \"is not allowed.\"\n        )\n    else:\n        if n_dipoles != len(labels):\n            warn(\n                \"The number of labels is different from the number of \"\n                f\"dipoles. {min(n_dipoles, len(labels))} dipole(s) will be generated.\"\n            )\n        labels = labels[:n_dipoles] if n_dipoles < len(labels) else labels\n\n        vertno = [[], []]\n        lh_data = [np.empty((0, data.shape[1]))]\n        rh_data = [np.empty((0, data.shape[1]))]\n        for i, label in enumerate(labels):\n            lh_vertno, rh_vertno = select_source_in_label(\n                src, label, rng, location, subject, subjects_dir, surf\n            )\n            vertno[0] += lh_vertno\n            vertno[1] += rh_vertno\n            if len(lh_vertno) != 0:\n                lh_data.append(data[i][np.newaxis])\n            elif len(rh_vertno) != 0:\n                rh_data.append(data[i][np.newaxis])\n            else:\n                raise ValueError(\"No vertno found.\")\n        vs = [np.array(v) for v in vertno]\n        datas = [np.concatenate(d) for d in [lh_data, rh_data]]\n        # need to sort each hemi by vertex number\n        for ii in range(2):\n            order = np.argsort(vs[ii])\n            vs[ii] = vs[ii][order]\n            if len(order) > 0:  # fix for old numpy\n                datas[ii] = datas[ii][order]\n        datas = np.concatenate(datas)\n\n    tmin, tstep = times[0], np.diff(times[:2])[0]\n    assert datas.shape == data.shape\n    cls = SourceEstimate if len(vs) == 2 else VolSourceEstimate\n    stc = cls(datas, vertices=vs, tmin=tmin, tstep=tstep, subject=subject)\n    return stc", "metadata": {}}
{"_id": "mne_mne_simulation/source.py_simulate_stc_code", "title": "simulate_stc", "text": "def simulate_stc(\n    src, labels, stc_data, tmin, tstep, value_fun=None, allow_overlap=False\n):\n    \"\"\"Simulate sources time courses from waveforms and labels.\n\n    This function generates a source estimate with extended sources by\n    filling the labels with the waveforms given in stc_data.\n\n    Parameters\n    ----------\n    src : instance of SourceSpaces\n        The source space.\n    labels : list of Label\n        The labels.\n    stc_data : array, shape (n_labels, n_times)\n        The waveforms.\n    tmin : float\n        The beginning of the timeseries.\n    tstep : float\n        The time step (1 / sampling frequency).\n    value_fun : callable | None\n        Function to apply to the label values to obtain the waveform\n        scaling for each vertex in the label. If None (default), uniform\n        scaling is used.\n    allow_overlap : bool\n        Allow overlapping labels or not. Default value is False.\n\n        .. versionadded:: 0.18\n\n    Returns\n    -------\n    stc : SourceEstimate\n        The generated source time courses.\n\n    See Also\n    --------\n    simulate_raw\n    simulate_evoked\n    simulate_sparse_stc\n    \"\"\"\n    if len(labels) != len(stc_data):\n        raise ValueError(\"labels and stc_data must have the same length\")\n\n    vertno = [[], []]\n    stc_data_extended = [[], []]\n    hemi_to_ind = {\"lh\": 0, \"rh\": 1}\n    for i, label in enumerate(labels):\n        hemi_ind = hemi_to_ind[label.hemi]\n        src_sel = np.intersect1d(src[hemi_ind][\"vertno\"], label.vertices)\n        if len(src_sel) == 0:\n            idx = src[hemi_ind][\"inuse\"].astype(\"bool\")\n            xhs = src[hemi_ind][\"rr\"][idx]\n            rr = src[hemi_ind][\"rr\"][label.vertices]\n            closest_src = _compute_nearest(xhs, rr)\n            src_sel = src[hemi_ind][\"vertno\"][np.unique(closest_src)]\n\n        if value_fun is not None:\n            idx_sel = np.searchsorted(label.vertices, src_sel)\n            values_sel = np.array([value_fun(v) for v in label.values[idx_sel]])\n\n            data = np.outer(values_sel, stc_data[i])\n        else:\n            data = np.tile(stc_data[i], (len(src_sel), 1))\n        # If overlaps are allowed, deal with them\n        if allow_overlap:\n            # Search for duplicate vertex indices\n            # in the existing vertex matrix vertex.\n            duplicates = []\n            for src_ind, vertex_ind in enumerate(src_sel):\n                ind = np.where(vertex_ind == vertno[hemi_ind])[0]\n                if len(ind) > 0:\n                    assert len(ind) == 1\n                    # Add the new data to the existing one\n                    stc_data_extended[hemi_ind][ind[0]] += data[src_ind]\n                    duplicates.append(src_ind)\n            # Remove the duplicates from both data and selected vertices\n            data = np.delete(data, duplicates, axis=0)\n            src_sel = list(np.delete(np.array(src_sel), duplicates))\n        # Extend the existing list instead of appending it so that we can\n        # index its elements\n        vertno[hemi_ind].extend(src_sel)\n        stc_data_extended[hemi_ind].extend(np.atleast_2d(data))\n\n    vertno = [np.array(v) for v in vertno]\n    if not allow_overlap:\n        for v, hemi in zip(vertno, (\"left\", \"right\")):\n            d = len(v) - len(np.unique(v))\n            if d > 0:\n                raise RuntimeError(\n                    f\"Labels had {d} overlaps in the {hemi} \"\n                    \"hemisphere, they must be non-overlapping\"\n                )\n    # the data is in the order left, right\n    data = list()\n    for i in range(2):\n        if len(stc_data_extended[i]) != 0:\n            stc_data_extended[i] = np.vstack(stc_data_extended[i])\n            # Order the indices of each hemisphere\n            idx = np.argsort(vertno[i])\n            data.append(stc_data_extended[i][idx])\n            vertno[i] = vertno[i][idx]\n\n    stc = SourceEstimate(\n        np.concatenate(data),\n        vertices=vertno,\n        tmin=tmin,\n        tstep=tstep,\n        subject=src._subject,\n    )\n    return stc", "metadata": {}}
{"_id": "mne_mne_simulation/source.py_duration_code", "title": "duration", "text": "def duration(self):\n        \"\"\"Duration of the simulation in same units as tstep.\"\"\"\n        if self._duration is not None:\n            return self._duration\n        return self.n_times * self._tstep", "metadata": {}}
{"_id": "mne_mne_simulation/source.py_n_times_code", "title": "n_times", "text": "def n_times(self):\n        \"\"\"Number of time samples in the simulation.\"\"\"\n        if self._duration is not None:\n            return int(self._duration / self._tstep)\n        ls = self.first_samp\n        if len(self._last_samples) > 0:\n            ls = np.max(self._last_samples)\n        return ls - self.first_samp + 1", "metadata": {}}
{"_id": "mne_mne_simulation/source.py_add_data_code", "title": "add_data", "text": "def add_data(self, label, waveform, events):\n        \"\"\"Add data to the simulation.\n\n        Data should be added in the form of a triplet of\n        Label (Where) - Waveform(s) (What) - Event(s) (When)\n\n        Parameters\n        ----------\n        label : instance of Label\n            The label (as created for example by mne.read_label). If the label\n            does not match any sources in the SourceEstimate, a ValueError is\n            raised.\n        waveform : array, shape (n_times,) or (n_events, n_times) | list\n            The waveform(s) describing the activity on the label vertices.\n            If list, it must have the same length as events.\n        events : array of int, shape (n_events, 3)\n            Events associated to the waveform(s) to specify when the activity\n            should occur.\n        \"\"\"\n        _validate_type(label, Label, \"label\")\n\n        # If it is not a list then make it one\n        if not isinstance(waveform, list) and np.ndim(waveform) == 2:\n            waveform = list(waveform)\n        if not isinstance(waveform, list) and np.ndim(waveform) == 1:\n            waveform = [waveform]\n        if len(waveform) == 1:\n            waveform = waveform * len(events)\n        # The length is either equal to the length of events, or 1\n        if len(waveform) != len(events):\n            raise ValueError(\n                \"Number of waveforms and events should match or \"\n                f\"there should be a single waveform ({len(waveform)} != {len(events)}).\"\n            )\n        events = _ensure_events(events).astype(np.int64)\n        # Update the last sample possible based on events + waveforms\n        self._labels.extend([label] * len(events))\n        self._waveforms.extend(waveform)\n        self._events = np.concatenate([self._events, events])\n        assert self._events.dtype == np.int64\n        # First sample per waveform is the first column of events\n        # Last is computed below\n        self._last_samples = np.array(\n            [self._events[i, 0] + len(w) - 1 for i, w in enumerate(self._waveforms)]\n        )", "metadata": {}}
{"_id": "mne_mne_simulation/source.py_get_stim_channel_code", "title": "get_stim_channel", "text": "def get_stim_channel(self, start_sample=0, stop_sample=None):\n        \"\"\"Get the stim channel from the provided data.\n\n        Returns the stim channel data according to the simulation parameters\n        which should be added through the add_data method. If both start_sample\n        and stop_sample are not specified, the entire duration is used.\n\n        Parameters\n        ----------\n        start_sample : int\n            First sample in chunk. Default is the value of the ``first_samp``\n            attribute.\n        stop_sample : int | None\n            The final sample of the returned stc. If None, then all samples\n            from start_sample onward are returned.\n\n        Returns\n        -------\n        stim_data : ndarray of int, shape (n_samples,)\n            The stimulation channel data.\n        \"\"\"\n        if start_sample is None:\n            start_sample = self.first_samp\n        if stop_sample is None:\n            stop_sample = start_sample + self.n_times - 1\n        elif stop_sample < start_sample:\n            raise ValueError(\"Argument start_sample must be >= stop_sample.\")\n        n_samples = stop_sample - start_sample + 1\n\n        # Initialize the stim data array\n        stim_data = np.zeros(n_samples, dtype=np.int64)\n\n        # Select only events in the time chunk\n        stim_ind = np.where(\n            np.logical_and(\n                self._events[:, 0] >= start_sample, self._events[:, 0] < stop_sample\n            )\n        )[0]\n\n        if len(stim_ind) > 0:\n            relative_ind = self._events[stim_ind, 0] - start_sample\n            stim_data[relative_ind] = self._events[stim_ind, 2]\n\n        return stim_data", "metadata": {}}
{"_id": "mne_mne_simulation/source.py_get_stc_code", "title": "get_stc", "text": "def get_stc(self, start_sample=None, stop_sample=None):\n        \"\"\"Simulate a SourceEstimate from the provided data.\n\n        Returns a SourceEstimate object constructed according to the simulation\n        parameters which should be added through function add_data. If both\n        start_sample and stop_sample are not specified, the entire duration is\n        used.\n\n        Parameters\n        ----------\n        start_sample : int | None\n            First sample in chunk. If ``None`` the value of the ``first_samp``\n            attribute is used. Defaults to ``None``.\n        stop_sample : int | None\n            The final sample of the returned STC. If ``None``, then all samples\n            past ``start_sample`` are returned.\n\n        Returns\n        -------\n        stc : SourceEstimate object\n            The generated source time courses.\n        \"\"\"\n        if len(self._labels) == 0:\n            raise ValueError(\n                \"No simulation parameters were found. Please use \"\n                \"function add_data to add simulation parameters.\"\n            )\n        if start_sample is None:\n            start_sample = self.first_samp\n        if stop_sample is None:\n            stop_sample = start_sample + self.n_times - 1\n        elif stop_sample < start_sample:\n            raise ValueError(\"start_sample must be >= stop_sample.\")\n        n_samples = stop_sample - start_sample + 1\n\n        # Initialize the stc_data array to span all possible samples\n        stc_data = np.zeros((len(self._labels), n_samples))\n\n        # Select only the events that fall within the span\n        ind = np.where(\n            np.logical_and(\n                self._last_samples >= start_sample, self._events[:, 0] <= stop_sample\n            )\n        )[0]\n\n        # Loop only over the items that are in the time span\n        subset_waveforms = [self._waveforms[i] for i in ind]\n        for i, (waveform, event) in enumerate(zip(subset_waveforms, self._events[ind])):\n            # We retrieve the first and last sample of each waveform\n            # According to the corresponding event\n            wf_start = event[0]\n            wf_stop = self._last_samples[ind[i]]\n\n            # Recover the indices of the event that should be in the chunk\n            waveform_ind = np.isin(\n                np.arange(wf_start, wf_stop + 1),\n                np.arange(start_sample, stop_sample + 1),\n            )\n\n            # Recover the indices that correspond to the overlap\n            stc_ind = np.isin(\n                np.arange(start_sample, stop_sample + 1),\n                np.arange(wf_start, wf_stop + 1),\n            )\n\n            # add the resulting waveform chunk to the corresponding label\n            stc_data[ind[i]][stc_ind] += waveform[waveform_ind]\n\n        start_sample -= self.first_samp  # STC sample ref is 0\n        stc = simulate_stc(\n            self._src,\n            self._labels,\n            stc_data,\n            start_sample * self._tstep,\n            self._tstep,\n            allow_overlap=True,\n        )\n\n        return stc", "metadata": {}}
{"_id": "mne_mne_simulation/metrics/metrics.py_source_estimate_quantification_code", "title": "source_estimate_quantification", "text": "def source_estimate_quantification(stc1, stc2, metric=\"rms\"):\n    \"\"\"Calculate STC similarities across all sources and times.\n\n    Parameters\n    ----------\n    stc1 : SourceEstimate\n        First source estimate for comparison.\n    stc2 : SourceEstimate\n        Second source estimate for comparison.\n    metric : str\n        Metric to calculate, ``'rms'`` or ``'cosine'``.\n\n    Returns\n    -------\n    score : float | array\n        Calculated metric.\n\n    Notes\n    -----\n    Metric calculation has multiple options:\n\n        * rms: Root mean square of difference between stc data matrices.\n        * cosine: Normalized correlation of all elements in stc data matrices.\n\n    .. versionadded:: 0.10.0\n    \"\"\"\n    _check_option(\"metric\", metric, [\"rms\", \"cosine\"])\n\n    # This is checking that the data are having the same size meaning\n    # no comparison between distributed and sparse can be done so far.\n    _check_stc(stc1, stc2)\n    data1, data2 = stc1.data, stc2.data\n\n    # Calculate root mean square difference between two matrices\n    if metric == \"rms\":\n        score = np.sqrt(np.mean((data1 - data2) ** 2))\n    # Calculate correlation coefficient between matrix elements\n    elif metric == \"cosine\":\n        score = 1.0 - _cosine(data1, data2)\n    return score", "metadata": {}}
{"_id": "mne_mne_simulation/metrics/metrics.py_cosine_score_code", "title": "cosine_score", "text": "def cosine_score(stc_true, stc_est, per_sample=True):\n    \"\"\"Compute cosine similarity between 2 source estimates.\n\n    Parameters\n    ----------\n    %(stc_true_metric)s\n    %(stc_est_metric)s\n    %(per_sample_metric)s\n\n    Returns\n    -------\n    %(stc_metric)s\n\n    Notes\n    -----\n    .. versionadded:: 1.2\n    \"\"\"\n    stc_true, stc_est = _uniform_stc(stc_true, stc_est)\n    metric = _apply(_cosine, stc_true, stc_est, per_sample=per_sample)\n    return metric", "metadata": {}}
{"_id": "mne_mne_simulation/metrics/metrics.py_region_localization_error_code", "title": "region_localization_error", "text": "def region_localization_error(stc_true, stc_est, src, threshold=\"90%\", per_sample=True):\n    r\"\"\"Compute region localization error (RLE) between 2 source estimates.\n\n    .. math::\n\n        RLE = \\frac{1}{2Q}\\sum_{k \\in I} \\min_{l \\in \\hat{I}}{||r_k - r_l||} + \\frac{1}{2\\hat{Q}}\\sum_{l \\in \\hat{I}} \\min_{k \\in I}{||r_k - r_l||}\n\n    where :math:`I` and :math:`\\hat{I}` denote respectively the original and\n    estimated indexes of active sources, :math:`Q` and :math:`\\hat{Q}` are\n    the numbers of original and estimated active sources.\n    :math:`r_k` denotes the position of the k-th source dipole in space\n    and :math:`||\\cdot||` is an Euclidean norm in :math:`\\mathbb{R}^3`.\n\n    Parameters\n    ----------\n    %(stc_true_metric)s\n    %(stc_est_metric)s\n    src : instance of SourceSpaces\n        The source space on which the source estimates are defined.\n    threshold : float | str\n        The threshold to apply to source estimates before computing\n        the dipole localization error. If a string the threshold is\n        a percentage and it should end with the percent character.\n    %(per_sample_metric)s\n\n    Returns\n    -------\n    %(stc_metric)s\n\n    Notes\n    -----\n    Papers :footcite:`MaksymenkoEtAl2017` and :footcite:`BeckerEtAl2017`\n    use term Dipole Localization Error (DLE) for the same formula. Paper\n    :footcite:`YaoEtAl2005` uses term Error Distance (ED) for the same formula.\n    To unify the terminology and to avoid confusion with other cases\n    of using term DLE but for different metric :footcite:`MolinsEtAl2008`, we\n    use term Region Localization Error (RLE).\n\n    .. versionadded:: 1.2\n\n    References\n    ----------\n    .. footbibliography::\n    \"\"\"  # noqa: E501\n    stc_true, stc_est = _uniform_stc(stc_true, stc_est)\n    stc_true, stc_est = _thresholding(stc_true, stc_est, threshold)\n    func = partial(_dle, src=src, stc=stc_true)\n    metric = _apply(func, stc_true, stc_est, per_sample=per_sample)\n    return metric", "metadata": {}}
{"_id": "mne_mne_simulation/metrics/metrics.py_roc_auc_score_code", "title": "roc_auc_score", "text": "def roc_auc_score(stc_true, stc_est, per_sample=True):\n    \"\"\"Compute ROC AUC between 2 source estimates.\n\n    ROC stands for receiver operating curve and AUC is Area under the curve.\n    When computing this metric the stc_true must be thresholded\n    as any non-zero value will be considered as a positive.\n\n    The ROC-AUC metric is computed between amplitudes of the source\n    estimates, i.e. after taking the absolute values.\n\n    Parameters\n    ----------\n    %(stc_true_metric)s\n    %(stc_est_metric)s\n    %(per_sample_metric)s\n\n    Returns\n    -------\n    %(stc_metric)s\n\n    Notes\n    -----\n    .. versionadded:: 1.2\n    \"\"\"\n    stc_true, stc_est = _uniform_stc(stc_true, stc_est)\n    metric = _apply(_roc_auc_score, stc_true, stc_est, per_sample=per_sample)\n    return metric", "metadata": {}}
{"_id": "mne_mne_simulation/metrics/metrics.py_f1_score_code", "title": "f1_score", "text": "def f1_score(stc_true, stc_est, threshold=\"90%\", per_sample=True):\n    \"\"\"Compute the F1 score, also known as balanced F-score or F-measure.\n\n    The F1 score can be interpreted as a weighted average of the precision\n    and recall, where an F1 score reaches its best value at 1 and worst score\n    at 0. The relative contribution of precision and recall to the F1\n    score are equal.\n    The formula for the F1 score is::\n\n        F1 = 2 * (precision * recall) / (precision + recall)\n\n    Threshold is used first for data binarization.\n\n    Parameters\n    ----------\n    %(stc_true_metric)s\n    %(stc_est_metric)s\n    threshold : float | str\n        The threshold to apply to source estimates before computing\n        the f1 score. If a string the threshold is\n        a percentage and it should end with the percent character.\n    %(per_sample_metric)s\n\n    Returns\n    -------\n    %(stc_metric)s\n\n    Notes\n    -----\n    .. versionadded:: 1.2\n    \"\"\"\n    stc_true, stc_est = _uniform_stc(stc_true, stc_est)\n    stc_true, stc_est = _thresholding(stc_true, stc_est, threshold)\n    metric = _apply(_f1_score, stc_true, stc_est, per_sample=per_sample)\n    return metric", "metadata": {}}
{"_id": "mne_mne_simulation/metrics/metrics.py_precision_score_code", "title": "precision_score", "text": "def precision_score(stc_true, stc_est, threshold=\"90%\", per_sample=True):\n    \"\"\"Compute the precision.\n\n    The precision is the ratio ``tp / (tp + fp)`` where ``tp`` is the number of\n    true positives and ``fp`` the number of false positives. The precision is\n    intuitively the ability of the classifier not to label as positive a sample\n    that is negative.\n\n    The best value is 1 and the worst value is 0.\n\n    Threshold is used first for data binarization.\n\n    Parameters\n    ----------\n    %(stc_true_metric)s\n    %(stc_est_metric)s\n    threshold : float | str\n        The threshold to apply to source estimates before computing\n        the precision. If a string the threshold is\n        a percentage and it should end with the percent character.\n    %(per_sample_metric)s\n\n    Returns\n    -------\n    %(stc_metric)s\n\n    Notes\n    -----\n    .. versionadded:: 1.2\n    \"\"\"\n    stc_true, stc_est = _uniform_stc(stc_true, stc_est)\n    stc_true, stc_est = _thresholding(stc_true, stc_est, threshold)\n    metric = _apply(_precision_score, stc_true, stc_est, per_sample=per_sample)\n    return metric", "metadata": {}}
{"_id": "mne_mne_simulation/metrics/metrics.py_recall_score_code", "title": "recall_score", "text": "def recall_score(stc_true, stc_est, threshold=\"90%\", per_sample=True):\n    \"\"\"Compute the recall.\n\n    The recall is the ratio ``tp / (tp + fn)`` where ``tp`` is the number of\n    true positives and ``fn`` the number of false negatives. The recall is\n    intuitively the ability of the classifier to find all the positive samples.\n\n    The best value is 1 and the worst value is 0.\n\n    Threshold is used first for data binarization.\n\n    Parameters\n    ----------\n    %(stc_true_metric)s\n    %(stc_est_metric)s\n    threshold : float | str\n        The threshold to apply to source estimates before computing\n        the recall. If a string the threshold is\n        a percentage and it should end with the percent character.\n    %(per_sample_metric)s\n\n    Returns\n    -------\n    %(stc_metric)s\n\n    Notes\n    -----\n    .. versionadded:: 1.2\n    \"\"\"\n    stc_true, stc_est = _uniform_stc(stc_true, stc_est)\n    stc_true, stc_est = _thresholding(stc_true, stc_est, threshold)\n    metric = _apply(_recall_score, stc_true, stc_est, per_sample=per_sample)\n    return metric", "metadata": {}}
{"_id": "mne_mne_simulation/metrics/metrics.py_peak_position_error_code", "title": "peak_position_error", "text": "def peak_position_error(stc_true, stc_est, src, threshold=\"50%\", per_sample=True):\n    r\"\"\"Compute the peak position error.\n\n    The peak position error measures the distance between the center-of-mass\n    of the estimated and the true source.\n\n    .. math::\n\n        PPE = \\| \\dfrac{\\sum_i|s_i|r_{i}}{\\sum_i|s_i|}\n        - r_{true}\\|,\n\n    where :math:`r_{true}` is a true dipole position,\n    :math:`r_i` and :math:`|s_i|` denote respectively the position\n    and amplitude of i-th dipole in source estimate.\n\n    Threshold is used on estimated source for focusing the metric to strong\n    amplitudes and omitting the low-amplitude values.\n\n    Parameters\n    ----------\n    %(stc_true_metric)s\n    %(stc_est_metric)s\n    src : instance of SourceSpaces\n        The source space on which the source estimates are defined.\n    threshold : float | str\n        The threshold to apply to source estimates before computing\n        the recall. If a string the threshold is\n        a percentage and it should end with the percent character.\n    %(per_sample_metric)s\n\n    Returns\n    -------\n    %(stc_metric)s\n\n    Notes\n    -----\n    These metrics are documented in :footcite:`StenroosHauk2013` and\n    :footcite:`LinEtAl2006a`.\n\n    .. versionadded:: 1.2\n\n    References\n    ----------\n    .. footbibliography::\n    \"\"\"\n    stc_est, r_true, r_est = _prepare_ppe_sd(stc_true, stc_est, src, threshold)\n    func = partial(_peak_position_error, r_est=r_est, r_true=r_true)\n    metric = _apply(func, stc_true, stc_est, per_sample=per_sample)\n    return metric", "metadata": {}}
{"_id": "mne_mne_simulation/metrics/metrics.py_spatial_deviation_error_code", "title": "spatial_deviation_error", "text": "def spatial_deviation_error(stc_true, stc_est, src, threshold=\"50%\", per_sample=True):\n    r\"\"\"Compute the spatial deviation.\n\n    The spatial deviation characterizes the spread of the estimate source\n    around the true source.\n\n    .. math::\n\n        SD = \\dfrac{\\sum_i|s_i|\\|r_{i} - r_{true}\\|^2}{\\sum_i|s_i|}.\n\n    where :math:`r_{true}` is a true dipole position,\n    :math:`r_i` and :math:`|s_i|` denote respectively the position\n    and amplitude of i-th dipole in source estimate.\n\n    Threshold is used on estimated source for focusing the metric to strong\n    amplitudes and omitting the low-amplitude values.\n\n    Parameters\n    ----------\n    %(stc_true_metric)s\n    %(stc_est_metric)s\n    src : instance of SourceSpaces\n        The source space on which the source estimates are defined.\n    threshold : float | str\n        The threshold to apply to source estimates before computing\n        the recall. If a string the threshold is\n        a percentage and it should end with the percent character.\n    %(per_sample_metric)s\n\n    Returns\n    -------\n    %(stc_metric)s\n\n    Notes\n    -----\n    These metrics are documented in :footcite:`StenroosHauk2013` and\n    :footcite:`LinEtAl2006a`.\n\n    .. versionadded:: 1.2\n\n    References\n    ----------\n    .. footbibliography::\n    \"\"\"\n    stc_est, r_true, r_est = _prepare_ppe_sd(stc_true, stc_est, src, threshold)\n    func = partial(_spatial_deviation, r_est=r_est, r_true=r_true)\n    metric = _apply(func, stc_true, stc_est, per_sample=per_sample)\n    return metric", "metadata": {}}
{"_id": "mne_mne_commands/mne_sys_info.py_run_code", "title": "run", "text": "def run():\n    \"\"\"Run command.\"\"\"\n    parser = mne.commands.utils.get_optparser(__file__, usage=\"mne sys_info\")\n    parser.add_option(\n        \"-p\",\n        \"--show-paths\",\n        dest=\"show_paths\",\n        help=\"Show module paths\",\n        action=\"store_true\",\n    )\n    parser.add_option(\n        \"-d\",\n        \"--developer\",\n        dest=\"developer\",\n        help=\"Show additional developer module information\",\n        action=\"store_true\",\n    )\n    parser.add_option(\n        \"-a\",\n        \"--ascii\",\n        dest=\"unicode\",\n        help=\"Use ASCII instead of unicode symbols\",\n        action=\"store_false\",\n        default=True,\n    )\n    parser.add_option(\n        \"--no-check-version\",\n        dest=\"check_version\",\n        help=\"Disable MNE-Python remote version checking.\",\n        action=\"store_false\",\n        default=True,\n    )\n    options, args = parser.parse_args()\n    dependencies = \"developer\" if options.developer else \"user\"\n    if len(args) != 0:\n        parser.print_help()\n        sys.exit(1)\n\n    mne.sys_info(\n        show_paths=options.show_paths,\n        dependencies=dependencies,\n        unicode=options.unicode,\n        check_version=options.check_version,\n    )", "metadata": {}}
{"_id": "mne_mne_commands/mne_kit2fiff.py_run_code", "title": "run", "text": "def run():\n    \"\"\"Run command.\"\"\"\n    from mne.commands.utils import get_optparser\n\n    parser = get_optparser(__file__)\n\n    parser.add_option(\n        \"--input\", dest=\"input_fname\", help=\"Input data file name\", metavar=\"filename\"\n    )\n    parser.add_option(\n        \"--mrk\", dest=\"mrk_fname\", help=\"MEG Marker file name\", metavar=\"filename\"\n    )\n    parser.add_option(\n        \"--elp\", dest=\"elp_fname\", help=\"Headshape points file name\", metavar=\"filename\"\n    )\n    parser.add_option(\n        \"--hsp\", dest=\"hsp_fname\", help=\"Headshape file name\", metavar=\"filename\"\n    )\n    parser.add_option(\n        \"--stim\",\n        dest=\"stim\",\n        help=\"Colon Separated Stimulus Trigger Channels\",\n        metavar=\"chs\",\n    )\n    parser.add_option(\"--slope\", dest=\"slope\", help=\"Slope direction\", metavar=\"slope\")\n    parser.add_option(\n        \"--stimthresh\",\n        dest=\"stimthresh\",\n        default=1,\n        help=\"Threshold value for trigger channels\",\n        metavar=\"value\",\n    )\n    parser.add_option(\n        \"--output\",\n        dest=\"out_fname\",\n        help=\"Name of the resulting fiff file\",\n        metavar=\"filename\",\n    )\n    parser.add_option(\n        \"--debug\",\n        dest=\"debug\",\n        action=\"store_true\",\n        default=False,\n        help=\"Set logging level for terminal output to debug\",\n    )\n\n    options, args = parser.parse_args()\n\n    if options.debug:\n        mne.set_log_level(\"debug\")\n\n    input_fname = options.input_fname\n    if input_fname is None:\n        try:\n            from mne_kit_gui import kit2fiff  # noqa\n        except ImportError:\n            raise ImportError(\n                \"The mne-kit-gui package is required, install it using conda or pip\"\n            ) from None\n        kit2fiff()\n        sys.exit(0)\n\n    hsp_fname = options.hsp_fname\n    elp_fname = options.elp_fname\n    mrk_fname = options.mrk_fname\n    stim = options.stim\n    slope = options.slope\n    stimthresh = options.stimthresh\n    out_fname = options.out_fname\n\n    if isinstance(stim, str):\n        stim = map(int, stim.split(\":\"))\n\n    raw = read_raw_kit(\n        input_fname=input_fname,\n        mrk=mrk_fname,\n        elp=elp_fname,\n        hsp=hsp_fname,\n        stim=stim,\n        slope=slope,\n        stimthresh=stimthresh,\n    )\n\n    raw.save(out_fname)\n    raw.close()", "metadata": {}}
{"_id": "mne_mne_commands/mne_bti2fiff.py_run_code", "title": "run", "text": "def run():\n    \"\"\"Run command.\"\"\"\n    from mne.commands.utils import get_optparser\n\n    parser = get_optparser(__file__)\n\n    parser.add_option(\n        \"-p\", \"--pdf\", dest=\"pdf_fname\", help=\"Input data file name\", metavar=\"FILE\"\n    )\n    parser.add_option(\n        \"-c\",\n        \"--config\",\n        dest=\"config_fname\",\n        help=\"Input config file name\",\n        metavar=\"FILE\",\n        default=\"config\",\n    )\n    parser.add_option(\n        \"--head_shape\",\n        dest=\"head_shape_fname\",\n        help=\"Headshape file name\",\n        metavar=\"FILE\",\n        default=\"hs_file\",\n    )\n    parser.add_option(\n        \"-o\",\n        \"--out_fname\",\n        dest=\"out_fname\",\n        help=\"Name of the resulting fiff file\",\n        default=\"as_data_fname\",\n    )\n    parser.add_option(\n        \"-r\",\n        \"--rotation_x\",\n        dest=\"rotation_x\",\n        type=\"float\",\n        help=\"Compensatory rotation about Neuromag x axis, deg\",\n        default=2.0,\n    )\n    parser.add_option(\n        \"-T\",\n        \"--translation\",\n        dest=\"translation\",\n        type=\"str\",\n        help=\"Default translation, meter\",\n        default=(0.00, 0.02, 0.11),\n    )\n    parser.add_option(\n        \"--ecg_ch\", dest=\"ecg_ch\", type=\"str\", help=\"4D ECG channel name\", default=\"E31\"\n    )\n    parser.add_option(\n        \"--eog_ch\",\n        dest=\"eog_ch\",\n        type=\"str\",\n        help=\"4D EOG channel names\",\n        default=\"E63,E64\",\n    )\n\n    options, args = parser.parse_args()\n\n    pdf_fname = options.pdf_fname\n    if pdf_fname is None:\n        parser.print_help()\n        sys.exit(1)\n\n    config_fname = options.config_fname\n    head_shape_fname = options.head_shape_fname\n    out_fname = options.out_fname\n    rotation_x = options.rotation_x\n    translation = options.translation\n    ecg_ch = options.ecg_ch\n    eog_ch = options.ecg_ch.split(\",\")\n\n    if out_fname == \"as_data_fname\":\n        out_fname = pdf_fname + \"_raw.fif\"\n\n    raw = read_raw_bti(\n        pdf_fname=pdf_fname,\n        config_fname=config_fname,\n        head_shape_fname=head_shape_fname,\n        rotation_x=rotation_x,\n        translation=translation,\n        ecg_ch=ecg_ch,\n        eog_ch=eog_ch,\n    )\n\n    raw.save(out_fname)\n    raw.close()", "metadata": {}}
{"_id": "mne_mne_commands/mne_compare_fiff.py_run_code", "title": "run", "text": "def run():\n    \"\"\"Run command.\"\"\"\n    parser = mne.commands.utils.get_optparser(\n        __file__, usage=\"mne compare_fiff <file_a> <file_b>\"\n    )\n    options, args = parser.parse_args()\n    if len(args) != 2:\n        parser.print_help()\n        sys.exit(1)\n    mne.viz.compare_fiff(args[0], args[1])", "metadata": {}}
{"_id": "mne_mne_commands/mne_make_scalp_surfaces.py_run_code", "title": "run", "text": "def run():\n    \"\"\"Run command.\"\"\"\n    from mne.commands.utils import _add_verbose_flag, get_optparser\n\n    parser = get_optparser(__file__)\n    subjects_dir = mne.get_config(\"SUBJECTS_DIR\")\n\n    parser.add_option(\n        \"-o\",\n        \"--overwrite\",\n        dest=\"overwrite\",\n        action=\"store_true\",\n        help=\"Overwrite previously computed surface\",\n    )\n    parser.add_option(\n        \"-s\", \"--subject\", dest=\"subject\", help=\"The name of the subject\", type=\"str\"\n    )\n    parser.add_option(\n        \"-m\",\n        \"--mri\",\n        dest=\"mri\",\n        type=\"str\",\n        default=\"T1.mgz\",\n        help=\"The MRI file to process using mkheadsurf.\",\n    )\n    parser.add_option(\n        \"-f\",\n        \"--force\",\n        dest=\"force\",\n        action=\"store_true\",\n        help=\"Force creation of the surface even if it has some topological defects.\",\n    )\n    parser.add_option(\n        \"-t\",\n        \"--threshold\",\n        dest=\"threshold\",\n        type=\"int\",\n        default=20,\n        help=\"Threshold value to use with the MRI.\",\n    )\n    parser.add_option(\n        \"-d\",\n        \"--subjects-dir\",\n        dest=\"subjects_dir\",\n        help=\"Subjects directory\",\n        default=subjects_dir,\n    )\n    parser.add_option(\n        \"-n\",\n        \"--no-decimate\",\n        dest=\"no_decimate\",\n        help=\"Disable medium and sparse decimations (dense only)\",\n        action=\"store_true\",\n    )\n    _add_verbose_flag(parser)\n    options, args = parser.parse_args()\n\n    subject = vars(options).get(\"subject\", os.getenv(\"SUBJECT\"))\n    subjects_dir = options.subjects_dir\n    if subject is None or subjects_dir is None:\n        parser.print_help()\n        sys.exit(1)\n    make_scalp_surfaces(\n        subject=subject,\n        subjects_dir=subjects_dir,\n        force=options.force,\n        overwrite=options.overwrite,\n        no_decimate=options.no_decimate,\n        threshold=options.threshold,\n        mri=options.mri,\n        verbose=options.verbose,\n    )", "metadata": {}}
{"_id": "mne_mne_commands/mne_setup_source_space.py_run_code", "title": "run", "text": "def run():\n    \"\"\"Run command.\"\"\"\n    from mne.commands.utils import _add_verbose_flag, get_optparser\n\n    parser = get_optparser(__file__)\n\n    parser.add_option(\n        \"-s\", \"--subject\", dest=\"subject\", help=\"Subject name (required)\", default=None\n    )\n    parser.add_option(\n        \"--src\",\n        dest=\"fname\",\n        help=\"Output file name. Use a name <dir>/<name>-src.fif\",\n        metavar=\"FILE\",\n        default=None,\n    )\n    parser.add_option(\n        \"--morph\",\n        dest=\"subject_to\",\n        help=\"morph the source space to this subject\",\n        default=None,\n    )\n    parser.add_option(\n        \"--surf\",\n        dest=\"surface\",\n        help=\"The surface to use. (default to white)\",\n        default=\"white\",\n        type=\"string\",\n    )\n    parser.add_option(\n        \"--spacing\",\n        dest=\"spacing\",\n        help=\"Specifies the approximate grid spacing of the \"\n        \"source space in mm. (default to 7mm)\",\n        default=None,\n        type=\"int\",\n    )\n    parser.add_option(\n        \"--ico\",\n        dest=\"ico\",\n        help=\"use the recursively subdivided icosahedron to create the source space.\",\n        default=None,\n        type=\"int\",\n    )\n    parser.add_option(\n        \"--oct\",\n        dest=\"oct\",\n        help=\"use the recursively subdivided octahedron to create the source space.\",\n        default=None,\n        type=\"int\",\n    )\n    parser.add_option(\n        \"-d\",\n        \"--subjects-dir\",\n        dest=\"subjects_dir\",\n        help=\"Subjects directory\",\n        default=None,\n    )\n    parser.add_option(\n        \"-n\",\n        \"--n-jobs\",\n        dest=\"n_jobs\",\n        help=\"The number of jobs to run in parallel \"\n        \"(default 1). Requires the joblib package. \"\n        \"Will use at most 2 jobs\"\n        \" (one for each hemisphere).\",\n        default=1,\n        type=\"int\",\n    )\n    parser.add_option(\n        \"--add-dist\",\n        dest=\"add_dist\",\n        help='Add distances. Can be \"True\", \"False\", or \"patch\" '\n        \"to only compute cortical patch statistics (like the --cps option in MNE-C)\",\n        default=\"True\",\n    )\n    parser.add_option(\n        \"-o\",\n        \"--overwrite\",\n        dest=\"overwrite\",\n        help=\"to write over existing files\",\n        default=None,\n        action=\"store_true\",\n    )\n    _add_verbose_flag(parser)\n\n    options, args = parser.parse_args()\n\n    if options.subject is None:\n        parser.print_help()\n        sys.exit(1)\n\n    subject = options.subject\n    subject_to = options.subject_to\n    fname = options.fname\n    subjects_dir = options.subjects_dir\n    spacing = options.spacing\n    ico = options.ico\n    oct_ = options.oct\n    surface = options.surface\n    n_jobs = options.n_jobs\n    add_dist = options.add_dist\n    _check_option(\"add_dist\", add_dist, (\"True\", \"False\", \"patch\"))\n    add_dist = {\"True\": True, \"False\": False, \"patch\": \"patch\"}[add_dist]\n    verbose = True if options.verbose is not None else False\n    overwrite = True if options.overwrite is not None else False\n\n    # Parse source spacing option\n    spacing_options = [ico, oct_, spacing]\n    n_options = len([x for x in spacing_options if x is not None])\n    use_spacing = \"oct6\"\n    if n_options > 1:\n        raise ValueError(\"Only one spacing option can be set at the same time\")\n    elif n_options == 0:\n        # Default to oct6\n        pass\n    elif n_options == 1:\n        if ico is not None:\n            use_spacing = \"ico\" + str(ico)\n        elif oct_ is not None:\n            use_spacing = \"oct\" + str(oct_)\n        elif spacing is not None:\n            use_spacing = spacing\n    del ico, oct_, spacing\n    # Generate filename\n    if fname is None:\n        if subject_to is None:\n            fname = subject + \"-\" + str(use_spacing) + \"-src.fif\"\n        else:\n            fname = subject_to + \"-\" + subject + \"-\" + str(use_spacing) + \"-src.fif\"\n    else:\n        if not (fname.endswith(\"_src.fif\") or fname.endswith(\"-src.fif\")):\n            fname = fname + \"-src.fif\"\n    # Create source space\n    src = mne.setup_source_space(\n        subject=subject,\n        spacing=use_spacing,\n        surface=surface,\n        subjects_dir=subjects_dir,\n        n_jobs=n_jobs,\n        add_dist=add_dist,\n        verbose=verbose,\n    )\n    # Morph source space if --morph is set\n    if subject_to is not None:\n        src = mne.morph_source_spaces(\n            src,\n            subject_to=subject_to,\n            subjects_dir=subjects_dir,\n            surf=surface,\n            verbose=verbose,\n        )\n\n    # Save source space to file\n    src.save(fname=fname, overwrite=overwrite)", "metadata": {}}
{"_id": "mne_mne_commands/mne_browse_raw.py_run_code", "title": "run", "text": "def run():\n    \"\"\"Run command.\"\"\"\n    from mne.commands.utils import _add_verbose_flag, get_optparser\n    from mne.viz import _RAW_CLIP_DEF\n\n    parser = get_optparser(__file__, usage=\"usage: %prog raw [options]\")\n\n    parser.add_option(\n        \"--raw\",\n        dest=\"raw_in\",\n        help=\"Input raw FIF file (can also be specified \"\n        \"directly as an argument without the --raw prefix)\",\n        metavar=\"FILE\",\n    )\n    parser.add_option(\n        \"--proj\", dest=\"proj_in\", help=\"Projector file\", metavar=\"FILE\", default=\"\"\n    )\n    parser.add_option(\n        \"--projoff\",\n        dest=\"proj_off\",\n        help=\"Disable all projectors\",\n        default=False,\n        action=\"store_true\",\n    )\n    parser.add_option(\n        \"--eve\", dest=\"eve_in\", help=\"Events file\", metavar=\"FILE\", default=\"\"\n    )\n    parser.add_option(\n        \"-d\",\n        \"--duration\",\n        dest=\"duration\",\n        type=\"float\",\n        help=\"Time window for plotting (s)\",\n        default=10.0,\n    )\n    parser.add_option(\n        \"-t\",\n        \"--start\",\n        dest=\"start\",\n        type=\"float\",\n        help=\"Initial start time for plotting\",\n        default=0.0,\n    )\n    parser.add_option(\n        \"-n\",\n        \"--n_channels\",\n        dest=\"n_channels\",\n        type=\"int\",\n        help=\"Number of channels to plot at a time\",\n        default=20,\n    )\n    parser.add_option(\n        \"-o\",\n        \"--order\",\n        dest=\"group_by\",\n        help=\"Order to use for grouping during plotting ('type' or 'original')\",\n        default=\"type\",\n    )\n    parser.add_option(\n        \"-p\",\n        \"--preload\",\n        dest=\"preload\",\n        help=\"Preload raw data (for faster navigation)\",\n        default=False,\n        action=\"store_true\",\n    )\n    parser.add_option(\n        \"-s\",\n        \"--show_options\",\n        dest=\"show_options\",\n        help=\"Show projection options dialog\",\n        default=False,\n    )\n    parser.add_option(\n        \"--allowmaxshield\",\n        dest=\"maxshield\",\n        help=\"Allow loading MaxShield processed data\",\n        action=\"store_true\",\n    )\n    parser.add_option(\n        \"--highpass\",\n        dest=\"highpass\",\n        type=\"float\",\n        help=\"Display high-pass filter corner frequency\",\n        default=-1,\n    )\n    parser.add_option(\n        \"--lowpass\",\n        dest=\"lowpass\",\n        type=\"float\",\n        help=\"Display low-pass filter corner frequency\",\n        default=-1,\n    )\n    parser.add_option(\n        \"--filtorder\",\n        dest=\"filtorder\",\n        type=\"int\",\n        help=\"Display filtering IIR order (or 0 to use FIR)\",\n        default=4,\n    )\n    parser.add_option(\n        \"--clipping\",\n        dest=\"clipping\",\n        help=\"Enable trace clipping mode. Can be 'clamp', 'transparent', a float, \"\n        \"or 'none'.\",\n        default=_RAW_CLIP_DEF,\n    )\n    parser.add_option(\n        \"--filterchpi\",\n        dest=\"filterchpi\",\n        help=\"Enable filtering cHPI signals.\",\n        default=None,\n        action=\"store_true\",\n    )\n    parser.add_option(\n        \"--butterfly\",\n        dest=\"butterfly\",\n        help=\"Plot in butterfly mode\",\n        default=False,\n        action=\"store_true\",\n    )\n    _add_verbose_flag(parser)\n    options, args = parser.parse_args()\n\n    if len(args):\n        raw_in = args[0]\n    else:\n        raw_in = options.raw_in\n    duration = options.duration\n    start = options.start\n    n_channels = options.n_channels\n    group_by = options.group_by\n    preload = options.preload\n    show_options = options.show_options\n    proj_in = options.proj_in\n    proj_off = options.proj_off\n    eve_in = options.eve_in\n    maxshield = options.maxshield\n    highpass = options.highpass\n    lowpass = options.lowpass\n    filtorder = options.filtorder\n    clipping = options.clipping\n    if isinstance(clipping, str):\n        if clipping.lower() == \"none\":\n            clipping = None\n        else:\n            try:\n                clipping = float(clipping)  # allow float and convert it\n            except ValueError:\n                pass\n    filterchpi = options.filterchpi\n    verbose = options.verbose\n    butterfly = options.butterfly\n\n    if raw_in is None:\n        parser.print_help()\n        sys.exit(1)\n\n    kwargs = dict(preload=preload)\n    if maxshield:\n        kwargs.update(allow_maxshield=\"yes\")\n    raw = mne.io.read_raw(raw_in, **kwargs)\n    if len(proj_in) > 0:\n        projs = mne.read_proj(proj_in)\n        raw.info[\"projs\"] = projs\n    if len(eve_in) > 0:\n        events = mne.read_events(eve_in)\n    else:\n        events = None\n\n    if filterchpi:\n        if not preload:\n            raise RuntimeError(\"Raw data must be preloaded for chpi, use --preload\")\n        raw = mne.chpi.filter_chpi(raw)\n\n    highpass = None if highpass < 0 or filtorder < 0 else highpass\n    lowpass = None if lowpass < 0 or filtorder < 0 else lowpass\n    raw.plot(\n        duration=duration,\n        start=start,\n        n_channels=n_channels,\n        group_by=group_by,\n        show_options=show_options,\n        events=events,\n        highpass=highpass,\n        lowpass=lowpass,\n        filtorder=filtorder,\n        clipping=clipping,\n        butterfly=butterfly,\n        proj=not proj_off,\n        verbose=verbose,\n        show=True,\n        block=True,\n    )", "metadata": {}}
{"_id": "mne_mne_commands/mne_freeview_bem_surfaces.py_freeview_bem_surfaces_code", "title": "freeview_bem_surfaces", "text": "def freeview_bem_surfaces(subject, subjects_dir, method=None):\n    \"\"\"View 3-Layers BEM model with Freeview.\n\n    Parameters\n    ----------\n    subject : str\n        Subject name\n    subjects_dir : path-like\n        Directory containing subjects data (Freesurfer SUBJECTS_DIR)\n    method : str | None\n        Can be ``'flash'`` or ``'watershed'``, or None to use the ``bem/`` directory\n        files.\n    \"\"\"\n    subjects_dir = str(get_subjects_dir(subjects_dir, raise_error=True))\n\n    if subject is None:\n        raise ValueError(\"subject argument is None.\")\n\n    subject_dir = op.join(subjects_dir, subject)\n\n    if not op.isdir(subject_dir):\n        raise ValueError(\n            f\"Wrong path: '{subject_dir}'. Check subjects-dir or subject argument.\"\n        )\n\n    env = os.environ.copy()\n    env[\"SUBJECT\"] = subject\n    env[\"SUBJECTS_DIR\"] = subjects_dir\n\n    if \"FREESURFER_HOME\" not in env:\n        raise RuntimeError(\"The FreeSurfer environment needs to be set up.\")\n\n    mri_dir = op.join(subject_dir, \"mri\")\n    bem_dir = op.join(subject_dir, \"bem\")\n    mri = op.join(mri_dir, \"T1.mgz\")\n\n    if method == \"watershed\":\n        bem_dir = op.join(bem_dir, \"watershed\")\n        outer_skin = op.join(bem_dir, f\"{subject}_outer_skin_surface\")\n        outer_skull = op.join(bem_dir, f\"{subject}_outer_skull_surface\")\n        inner_skull = op.join(bem_dir, f\"{subject}_inner_skull_surface\")\n    else:\n        if method == \"flash\":\n            bem_dir = op.join(bem_dir, \"flash\")\n        outer_skin = op.join(bem_dir, \"outer_skin.surf\")\n        outer_skull = op.join(bem_dir, \"outer_skull.surf\")\n        inner_skull = op.join(bem_dir, \"inner_skull.surf\")\n\n    # put together the command\n    cmd = [\"freeview\"]\n    cmd += [\"--volume\", mri]\n    cmd += [\"--surface\", f\"{inner_skull}:color=red:edgecolor=red\"]\n    cmd += [\"--surface\", f\"{outer_skull}:color=yellow:edgecolor=yellow\"]\n    cmd += [\"--surface\", f\"{outer_skin}:color=255,170,127:edgecolor=255,170,127\"]\n\n    run_subprocess(cmd, env=env, stdout=sys.stdout)\n    print(\"[done]\")", "metadata": {}}
{"_id": "mne_mne_commands/mne_freeview_bem_surfaces.py_run_code", "title": "run", "text": "def run():\n    \"\"\"Run command.\"\"\"\n    from mne.commands.utils import get_optparser\n\n    parser = get_optparser(__file__)\n\n    subject = os.environ.get(\"SUBJECT\")\n    parser.add_option(\n        \"-s\", \"--subject\", dest=\"subject\", help=\"Subject name\", default=subject\n    )\n    parser.add_option(\n        \"-d\",\n        \"--subjects-dir\",\n        dest=\"subjects_dir\",\n        help=\"Subjects directory\",\n    )\n    parser.add_option(\n        \"-m\",\n        \"--method\",\n        dest=\"method\",\n        help=\"Method used to generate the BEM model. Can be flash or watershed.\",\n    )\n\n    options, args = parser.parse_args()\n\n    subject = options.subject\n    subjects_dir = options.subjects_dir\n    method = options.method\n\n    freeview_bem_surfaces(subject, subjects_dir, method)", "metadata": {}}
{"_id": "mne_mne_commands/mne_show_info.py_run_code", "title": "run", "text": "def run():\n    \"\"\"Run command.\"\"\"\n    parser = mne.commands.utils.get_optparser(__file__, usage=\"mne show_info <file>\")\n    options, args = parser.parse_args()\n    if len(args) != 1:\n        parser.print_help()\n        sys.exit(1)\n\n    fname = args[0]\n\n    if not fname.endswith(\".fif\"):\n        raise ValueError(f\"{fname} does not seem to be a .fif file.\")\n\n    info = mne.io.read_info(fname)\n    print(f\"File : {fname}\")\n    print(info)", "metadata": {}}
{"_id": "mne_mne_commands/mne_prepare_bem_model.py_run_code", "title": "run", "text": "def run():\n    \"\"\"Run command.\"\"\"\n    from mne.commands.utils import _add_verbose_flag, get_optparser\n\n    parser = get_optparser(__file__)\n\n    parser.add_option(\n        \"--bem\",\n        dest=\"bem_fname\",\n        help=\"The name of the file containing the \"\n        \"triangulations of the BEM surfaces and the \"\n        \"conductivities of the compartments. The standard \"\n        \"ending for this file is -bem.fif.\",\n        metavar=\"FILE\",\n    )\n    parser.add_option(\n        \"--sol\",\n        dest=\"bem_sol_fname\",\n        help=\"The name of the resulting file containing BEM \"\n        \"solution (geometry matrix). It uses the linear \"\n        \"collocation approach. The file should end with \"\n        \"-bem-sof.fif.\",\n        metavar=\"FILE\",\n        default=None,\n    )\n    _add_verbose_flag(parser)\n\n    options, args = parser.parse_args()\n    bem_fname = options.bem_fname\n    bem_sol_fname = options.bem_sol_fname\n    verbose = True if options.verbose is not None else False\n\n    if bem_fname is None:\n        parser.print_help()\n        sys.exit(1)\n\n    if bem_sol_fname is None:\n        base, _ = os.path.splitext(bem_fname)\n        bem_sol_fname = base + \"-sol.fif\"\n\n    bem_model = mne.read_bem_surfaces(bem_fname, patch_stats=False, verbose=verbose)\n    bem_solution = mne.make_bem_solution(bem_model, verbose=verbose)\n    mne.write_bem_solution(bem_sol_fname, bem_solution)", "metadata": {}}
{"_id": "mne_mne_commands/mne_clean_eog_ecg.py_clean_ecg_eog_code", "title": "clean_ecg_eog", "text": "def clean_ecg_eog(\n    in_fif_fname,\n    out_fif_fname=None,\n    eog=True,\n    ecg=True,\n    ecg_proj_fname=None,\n    eog_proj_fname=None,\n    ecg_event_fname=None,\n    eog_event_fname=None,\n    in_path=\".\",\n    quiet=False,\n):\n    \"\"\"Clean ECG from raw fif file.\n\n    Parameters\n    ----------\n    in_fif_fname : path-like\n        Raw fif File\n    eog_event_fname : str\n        name of EOG event file required.\n    eog : bool\n        Reject or not EOG artifacts.\n    ecg : bool\n        Reject or not ECG artifacts.\n    ecg_event_fname : str\n        name of ECG event file required.\n    in_path : str\n        Path where all the files are.\n    \"\"\"\n    if not eog and not ecg:\n        raise Exception(\"EOG and ECG cannot be both disabled\")\n\n    # Reading fif File\n    raw_in = mne.io.read_raw_fif(in_fif_fname)\n\n    if in_fif_fname.endswith(\"_raw.fif\") or in_fif_fname.endswith(\"-raw.fif\"):\n        prefix = in_fif_fname[:-8]\n    else:\n        prefix = in_fif_fname[:-4]\n\n    if out_fif_fname is None:\n        out_fif_fname = prefix + \"_clean_ecg_eog_raw.fif\"\n    if ecg_proj_fname is None:\n        ecg_proj_fname = prefix + \"_ecg-proj.fif\"\n    if eog_proj_fname is None:\n        eog_proj_fname = prefix + \"_eog-proj.fif\"\n    if ecg_event_fname is None:\n        ecg_event_fname = prefix + \"_ecg-eve.fif\"\n    if eog_event_fname is None:\n        eog_event_fname = prefix + \"_eog-eve.fif\"\n\n    print(\"Implementing ECG and EOG artifact rejection on data\")\n\n    kwargs = dict() if quiet else dict(stdout=None, stderr=None)\n    if ecg:\n        ecg_events, _, _ = mne.preprocessing.find_ecg_events(\n            raw_in, reject_by_annotation=True\n        )\n        print(f\"Writing ECG events in {ecg_event_fname}\")\n        mne.write_events(ecg_event_fname, ecg_events)\n        print(\"Computing ECG projector\")\n        command = (\n            \"mne_process_raw\",\n            \"--cd\",\n            in_path,\n            \"--raw\",\n            in_fif_fname,\n            \"--events\",\n            ecg_event_fname,\n            \"--makeproj\",\n            \"--projtmin\",\n            \"-0.08\",\n            \"--projtmax\",\n            \"0.08\",\n            \"--saveprojtag\",\n            \"_ecg-proj\",\n            \"--projnmag\",\n            \"2\",\n            \"--projngrad\",\n            \"1\",\n            \"--projevent\",\n            \"999\",\n            \"--highpass\",\n            \"5\",\n            \"--lowpass\",\n            \"35\",\n            \"--projmagrej\",\n            \"4000\",\n            \"--projgradrej\",\n            \"3000\",\n        )\n        mne.utils.run_subprocess(command, **kwargs)\n    if eog:\n        eog_events = mne.preprocessing.find_eog_events(raw_in)\n        print(f\"Writing EOG events in {eog_event_fname}\")\n        mne.write_events(eog_event_fname, eog_events)\n        print(\"Computing EOG projector\")\n        command = (\n            \"mne_process_raw\",\n            \"--cd\",\n            in_path,\n            \"--raw\",\n            in_fif_fname,\n            \"--events\",\n            eog_event_fname,\n            \"--makeproj\",\n            \"--projtmin\",\n            \"-0.15\",\n            \"--projtmax\",\n            \"0.15\",\n            \"--saveprojtag\",\n            \"_eog-proj\",\n            \"--projnmag\",\n            \"2\",\n            \"--projngrad\",\n            \"2\",\n            \"--projevent\",\n            \"998\",\n            \"--lowpass\",\n            \"35\",\n            \"--projmagrej\",\n            \"4000\",\n            \"--projgradrej\",\n            \"3000\",\n        )\n        mne.utils.run_subprocess(command, **kwargs)\n\n    if out_fif_fname is not None:\n        # Applying the ECG EOG projector\n        print(\"Applying ECG EOG projector\")\n        command = (\n            \"mne_process_raw\",\n            \"--cd\",\n            in_path,\n            \"--raw\",\n            in_fif_fname,\n            \"--proj\",\n            in_fif_fname,\n            \"--projoff\",\n            \"--save\",\n            out_fif_fname,\n            \"--filteroff\",\n            \"--proj\",\n            ecg_proj_fname,\n            \"--proj\",\n            eog_proj_fname,\n        )\n        mne.utils.run_subprocess(command, **kwargs)\n        print(\"Done removing artifacts.\")\n        print(f\"Cleaned raw data saved in: {out_fif_fname}\")\n        print(\"IMPORTANT : Please eye-ball the data !!\")\n    else:\n        print(\"Projection not applied to raw data.\")", "metadata": {}}
{"_id": "mne_mne_commands/mne_clean_eog_ecg.py_run_code", "title": "run", "text": "def run():\n    \"\"\"Run command.\"\"\"\n    from mne.commands.utils import get_optparser\n\n    parser = get_optparser(__file__)\n\n    parser.add_option(\n        \"-i\", \"--in\", dest=\"raw_in\", help=\"Input raw FIF file\", metavar=\"FILE\"\n    )\n    parser.add_option(\n        \"-o\",\n        \"--out\",\n        dest=\"raw_out\",\n        help=\"Output raw FIF file\",\n        metavar=\"FILE\",\n        default=None,\n    )\n    parser.add_option(\n        \"-e\",\n        \"--no-eog\",\n        dest=\"eog\",\n        action=\"store_false\",\n        help=\"Remove EOG\",\n        default=True,\n    )\n    parser.add_option(\n        \"-c\",\n        \"--no-ecg\",\n        dest=\"ecg\",\n        action=\"store_false\",\n        help=\"Remove ECG\",\n        default=True,\n    )\n    parser.add_option(\n        \"-q\",\n        \"--quiet\",\n        dest=\"quiet\",\n        action=\"store_true\",\n        help=\"Suppress mne_process_raw output\",\n        default=False,\n    )\n\n    options, args = parser.parse_args()\n\n    if options.raw_in is None:\n        parser.print_help()\n        sys.exit(1)\n\n    raw_in = options.raw_in\n    raw_out = options.raw_out\n    eog = options.eog\n    ecg = options.ecg\n    quiet = options.quiet\n\n    clean_ecg_eog(raw_in, raw_out, eog=eog, ecg=ecg, quiet=quiet)", "metadata": {}}
{"_id": "mne_mne_commands/mne_report.py_log_elapsed_code", "title": "log_elapsed", "text": "def log_elapsed(t, verbose=None):\n    \"\"\"Log elapsed time.\"\"\"\n    logger.info(f\"Report complete in {round(t, 1)} seconds\")", "metadata": {}}
{"_id": "mne_mne_commands/mne_report.py_run_code", "title": "run", "text": "def run():\n    \"\"\"Run command.\"\"\"\n    from mne.commands.utils import _add_verbose_flag, get_optparser\n\n    parser = get_optparser(__file__)\n\n    parser.add_option(\n        \"-p\",\n        \"--path\",\n        dest=\"path\",\n        help=\"Path to folder who MNE-Report must be created\",\n    )\n    parser.add_option(\n        \"-i\",\n        \"--info\",\n        dest=\"info_fname\",\n        help=\"File from which info dictionary is to be read\",\n        metavar=\"FILE\",\n    )\n    parser.add_option(\n        \"-c\",\n        \"--cov\",\n        dest=\"cov_fname\",\n        help=\"File from which noise covariance is to be read\",\n        metavar=\"FILE\",\n    )\n    parser.add_option(\n        \"--bmin\",\n        dest=\"bmin\",\n        help=\"Time at which baseline correction starts for evokeds\",\n        default=None,\n    )\n    parser.add_option(\n        \"--bmax\",\n        dest=\"bmax\",\n        help=\"Time at which baseline correction stops for evokeds\",\n        default=None,\n    )\n    parser.add_option(\n        \"-d\", \"--subjects-dir\", dest=\"subjects_dir\", help=\"The subjects directory\"\n    )\n    parser.add_option(\"-s\", \"--subject\", dest=\"subject\", help=\"The subject name\")\n    parser.add_option(\n        \"--no-browser\",\n        dest=\"no_browser\",\n        action=\"store_false\",\n        help=\"Do not open MNE-Report in browser\",\n    )\n    parser.add_option(\n        \"--overwrite\",\n        dest=\"overwrite\",\n        action=\"store_false\",\n        help=\"Overwrite html report if it already exists\",\n    )\n    parser.add_option(\n        \"-j\", \"--jobs\", dest=\"n_jobs\", help=\"Number of jobs to run in parallel\"\n    )\n    parser.add_option(\n        \"-m\",\n        \"--mri-decim\",\n        type=\"int\",\n        dest=\"mri_decim\",\n        default=2,\n        help=\"Integer factor used to decimate BEM plots\",\n    )\n    parser.add_option(\n        \"--image-format\",\n        type=\"str\",\n        dest=\"image_format\",\n        default=\"png\",\n        help=\"Image format to use (can be 'png' or 'svg')\",\n    )\n    _add_verbose_flag(parser)\n\n    options, args = parser.parse_args()\n    path = options.path\n    if path is None:\n        parser.print_help()\n        sys.exit(1)\n    info_fname = options.info_fname\n    cov_fname = options.cov_fname\n    subjects_dir = options.subjects_dir\n    subject = options.subject\n    image_format = options.image_format\n    mri_decim = int(options.mri_decim)\n    verbose = True if options.verbose is not None else False\n    open_browser = False if options.no_browser is not None else True\n    overwrite = True if options.overwrite is not None else False\n    n_jobs = int(options.n_jobs) if options.n_jobs is not None else 1\n\n    bmin = float(options.bmin) if options.bmin is not None else None\n    bmax = float(options.bmax) if options.bmax is not None else None\n    # XXX: this means (None, None) cannot be specified through command line\n    if bmin is None and bmax is None:\n        baseline = None\n    else:\n        baseline = (bmin, bmax)\n\n    t0 = time.time()\n    report = Report(\n        info_fname,\n        subjects_dir=subjects_dir,\n        subject=subject,\n        baseline=baseline,\n        cov_fname=cov_fname,\n        verbose=verbose,\n        image_format=image_format,\n    )\n    report.parse_folder(path, verbose=verbose, n_jobs=n_jobs, mri_decim=mri_decim)\n    log_elapsed(time.time() - t0, verbose=verbose)\n    report.save(open_browser=open_browser, overwrite=overwrite)", "metadata": {}}
{"_id": "mne_mne_commands/mne_coreg.py_run_code", "title": "run", "text": "def run():\n    \"\"\"Run command.\"\"\"\n    from mne.commands.utils import _add_verbose_flag, get_optparser\n\n    parser = get_optparser(__file__)\n\n    parser.add_option(\n        \"-d\",\n        \"--subjects-dir\",\n        dest=\"subjects_dir\",\n        default=None,\n        help=\"Subjects directory\",\n    )\n    parser.add_option(\n        \"-s\", \"--subject\", dest=\"subject\", default=None, help=\"Subject name\"\n    )\n    parser.add_option(\n        \"-f\",\n        \"--fiff\",\n        dest=\"inst\",\n        default=None,\n        help=\"FIFF file with digitizer data for coregistration\",\n    )\n    parser.add_option(\n        \"--head-opacity\",\n        type=float,\n        default=None,\n        dest=\"head_opacity\",\n        help=\"The opacity of the head surface, in the range [0, 1].\",\n    )\n    parser.add_option(\n        \"--high-res-head\",\n        action=\"store_true\",\n        default=False,\n        dest=\"high_res_head\",\n        help=\"Use a high-resolution head surface.\",\n    )\n    parser.add_option(\n        \"--low-res-head\",\n        action=\"store_true\",\n        default=False,\n        dest=\"low_res_head\",\n        help=\"Use a low-resolution head surface.\",\n    )\n    parser.add_option(\n        \"--trans\",\n        dest=\"trans\",\n        default=None,\n        help='Head<->MRI transform FIF file (\"-trans.fif\")',\n    )\n    parser.add_option(\n        \"--interaction\",\n        type=str,\n        default=None,\n        dest=\"interaction\",\n        help='Interaction style to use, can be \"trackball\" or \"terrain\".',\n    )\n    _add_verbose_flag(parser)\n\n    options, args = parser.parse_args()\n\n    if options.low_res_head:\n        if options.high_res_head:\n            raise ValueError(\n                \"Can't specify --high-res-head and --low-res-head at the same time.\"\n            )\n        head_high_res = False\n    elif options.high_res_head:\n        head_high_res = True\n    else:\n        head_high_res = None\n\n    # expanduser allows ~ for --subjects-dir\n    subjects_dir = options.subjects_dir\n    if subjects_dir is not None:\n        subjects_dir = op.expanduser(subjects_dir)\n    trans = options.trans\n    if trans is not None:\n        trans = op.expanduser(trans)\n    import faulthandler\n\n    faulthandler.enable()\n    mne.gui.coregistration(\n        inst=options.inst,\n        subject=options.subject,\n        subjects_dir=subjects_dir,\n        head_opacity=options.head_opacity,\n        head_high_res=head_high_res,\n        trans=trans,\n        interaction=options.interaction,\n        show=True,\n        block=True,\n        verbose=options.verbose,\n    )", "metadata": {}}
{"_id": "mne_mne_commands/mne_compute_proj_eog.py_run_code", "title": "run", "text": "def run():\n    \"\"\"Run command.\"\"\"\n    from mne.commands.utils import get_optparser\n\n    parser = get_optparser(__file__)\n\n    parser.add_option(\n        \"-i\", \"--in\", dest=\"raw_in\", help=\"Input raw FIF file\", metavar=\"FILE\"\n    )\n    parser.add_option(\n        \"--tmin\",\n        dest=\"tmin\",\n        type=\"float\",\n        help=\"Time before event in seconds\",\n        default=-0.2,\n    )\n    parser.add_option(\n        \"--tmax\",\n        dest=\"tmax\",\n        type=\"float\",\n        help=\"Time after event in seconds\",\n        default=0.2,\n    )\n    parser.add_option(\n        \"-g\",\n        \"--n-grad\",\n        dest=\"n_grad\",\n        type=\"int\",\n        help=\"Number of SSP vectors for gradiometers\",\n        default=2,\n    )\n    parser.add_option(\n        \"-m\",\n        \"--n-mag\",\n        dest=\"n_mag\",\n        type=\"int\",\n        help=\"Number of SSP vectors for magnetometers\",\n        default=2,\n    )\n    parser.add_option(\n        \"-e\",\n        \"--n-eeg\",\n        dest=\"n_eeg\",\n        type=\"int\",\n        help=\"Number of SSP vectors for EEG\",\n        default=2,\n    )\n    parser.add_option(\n        \"--l-freq\",\n        dest=\"l_freq\",\n        type=\"float\",\n        help=\"Filter low cut-off frequency in Hz\",\n        default=1,\n    )\n    parser.add_option(\n        \"--h-freq\",\n        dest=\"h_freq\",\n        type=\"float\",\n        help=\"Filter high cut-off frequency in Hz\",\n        default=35,\n    )\n    parser.add_option(\n        \"--eog-l-freq\",\n        dest=\"eog_l_freq\",\n        type=\"float\",\n        help=\"Filter low cut-off frequency in Hz used for EOG event detection\",\n        default=1,\n    )\n    parser.add_option(\n        \"--eog-h-freq\",\n        dest=\"eog_h_freq\",\n        type=\"float\",\n        help=\"Filter high cut-off frequency in Hz used for EOG event detection\",\n        default=10,\n    )\n    parser.add_option(\n        \"-p\",\n        \"--preload\",\n        dest=\"preload\",\n        help=\"Temporary file used during computation (to save memory)\",\n        default=True,\n    )\n    parser.add_option(\n        \"-a\",\n        \"--average\",\n        dest=\"average\",\n        action=\"store_true\",\n        help=\"Compute SSP after averaging\",\n        default=False,\n    )\n    parser.add_option(\n        \"--proj\", dest=\"proj\", help=\"Use SSP projections from a fif file.\", default=None\n    )\n    parser.add_option(\n        \"--filtersize\",\n        dest=\"filter_length\",\n        type=\"int\",\n        help=\"Number of taps to use for filtering\",\n        default=2048,\n    )\n    parser.add_option(\n        \"-j\",\n        \"--n-jobs\",\n        dest=\"n_jobs\",\n        type=\"int\",\n        help=\"Number of jobs to run in parallel\",\n        default=1,\n    )\n    parser.add_option(\n        \"--rej-grad\",\n        dest=\"rej_grad\",\n        type=\"float\",\n        help=\"Gradiometers rejection parameter in fT/cm (peak to peak amplitude)\",\n        default=2000,\n    )\n    parser.add_option(\n        \"--rej-mag\",\n        dest=\"rej_mag\",\n        type=\"float\",\n        help=\"Magnetometers rejection parameter in fT (peak to peak amplitude)\",\n        default=3000,\n    )\n    parser.add_option(\n        \"--rej-eeg\",\n        dest=\"rej_eeg\",\n        type=\"float\",\n        help=\"EEG rejection parameter in \u00b5V (peak to peak amplitude)\",\n        default=50,\n    )\n    parser.add_option(\n        \"--rej-eog\",\n        dest=\"rej_eog\",\n        type=\"float\",\n        help=\"EOG rejection parameter in \u00b5V (peak to peak amplitude)\",\n        default=1e9,\n    )\n    parser.add_option(\n        \"--avg-ref\",\n        dest=\"avg_ref\",\n        action=\"store_true\",\n        help=\"Add EEG average reference proj\",\n        default=False,\n    )\n    parser.add_option(\n        \"--no-proj\",\n        dest=\"no_proj\",\n        action=\"store_true\",\n        help=\"Exclude the SSP projectors currently in the fiff file\",\n        default=False,\n    )\n    parser.add_option(\n        \"--bad\",\n        dest=\"bad_fname\",\n        help=\"Text file containing bad channels list (one per line)\",\n        default=None,\n    )\n    parser.add_option(\n        \"--event-id\",\n        dest=\"event_id\",\n        type=\"int\",\n        help=\"ID to use for events\",\n        default=998,\n    )\n    parser.add_option(\n        \"--event-raw\",\n        dest=\"raw_event_fname\",\n        help=\"raw file to use for event detection\",\n        default=None,\n    )\n    parser.add_option(\n        \"--tstart\",\n        dest=\"tstart\",\n        type=\"float\",\n        help=\"Start artifact detection after tstart seconds\",\n        default=0.0,\n    )\n    parser.add_option(\n        \"-c\",\n        \"--channel\",\n        dest=\"ch_name\",\n        type=\"string\",\n        help=\"Custom EOG channel(s), comma separated\",\n        default=None,\n    )\n\n    options, args = parser.parse_args()\n\n    raw_in = options.raw_in\n\n    if raw_in is None:\n        parser.print_help()\n        sys.exit(1)\n\n    tmin = options.tmin\n    tmax = options.tmax\n    n_grad = options.n_grad\n    n_mag = options.n_mag\n    n_eeg = options.n_eeg\n    l_freq = options.l_freq\n    h_freq = options.h_freq\n    eog_l_freq = options.eog_l_freq\n    eog_h_freq = options.eog_h_freq\n    average = options.average\n    preload = options.preload\n    filter_length = options.filter_length\n    n_jobs = options.n_jobs\n    reject = dict(\n        grad=1e-13 * float(options.rej_grad),\n        mag=1e-15 * float(options.rej_mag),\n        eeg=1e-6 * float(options.rej_eeg),\n        eog=1e-6 * float(options.rej_eog),\n    )\n    avg_ref = options.avg_ref\n    no_proj = options.no_proj\n    bad_fname = options.bad_fname\n    event_id = options.event_id\n    proj_fname = options.proj\n    raw_event_fname = options.raw_event_fname\n    tstart = options.tstart\n    ch_name = options.ch_name\n\n    if bad_fname is not None:\n        with open(bad_fname) as fid:\n            bads = [w.rstrip() for w in fid.readlines()]\n        print(f\"Bad channels read : {bads}\")\n    else:\n        bads = []\n\n    if raw_in.endswith(\"_raw.fif\") or raw_in.endswith(\"-raw.fif\"):\n        prefix = raw_in[:-8]\n    else:\n        prefix = raw_in[:-4]\n\n    eog_event_fname = prefix + \"_eog-eve.fif\"\n\n    if average:\n        eog_proj_fname = prefix + \"_eog_avg-proj.fif\"\n    else:\n        eog_proj_fname = prefix + \"_eog-proj.fif\"\n\n    raw = mne.io.read_raw_fif(raw_in, preload=preload)\n\n    if raw_event_fname is not None:\n        raw_event = mne.io.read_raw_fif(raw_event_fname)\n    else:\n        raw_event = raw\n\n    flat = None\n    projs, events = mne.preprocessing.compute_proj_eog(\n        raw=raw,\n        raw_event=raw_event,\n        tmin=tmin,\n        tmax=tmax,\n        n_grad=n_grad,\n        n_mag=n_mag,\n        n_eeg=n_eeg,\n        l_freq=l_freq,\n        h_freq=h_freq,\n        average=average,\n        filter_length=filter_length,\n        n_jobs=n_jobs,\n        reject=reject,\n        flat=flat,\n        bads=bads,\n        avg_ref=avg_ref,\n        no_proj=no_proj,\n        event_id=event_id,\n        eog_l_freq=eog_l_freq,\n        eog_h_freq=eog_h_freq,\n        tstart=tstart,\n        ch_name=ch_name,\n        copy=False,\n    )\n\n    raw.close()\n\n    if raw_event_fname is not None:\n        raw_event.close()\n\n    if proj_fname is not None:\n        print(f\"Including SSP projections from : {proj_fname}\")\n        # append the eog projs, so they are last in the list\n        projs = mne.read_proj(proj_fname) + projs\n\n    if isinstance(preload, str) and os.path.exists(preload):\n        os.remove(preload)\n\n    print(f\"Writing EOG projections in {eog_proj_fname}\")\n    mne.write_proj(eog_proj_fname, projs)\n\n    print(f\"Writing EOG events in {eog_event_fname}\")\n    mne.write_events(eog_event_fname, events)", "metadata": {}}
{"_id": "mne_mne_commands/mne_surf2bem.py_run_code", "title": "run", "text": "def run():\n    \"\"\"Run command.\"\"\"\n    from mne.commands.utils import get_optparser\n\n    parser = get_optparser(__file__)\n\n    parser.add_option(\n        \"-s\", \"--surf\", dest=\"surf\", help=\"Surface in Freesurfer format\", metavar=\"FILE\"\n    )\n    parser.add_option(\n        \"-f\", \"--fif\", dest=\"fif\", help=\"FIF file produced\", metavar=\"FILE\"\n    )\n    parser.add_option(\n        \"-i\",\n        \"--id\",\n        dest=\"id\",\n        default=4,\n        help=(\"Surface Id (e.g. 4 for head surface)\"),\n    )\n\n    options, args = parser.parse_args()\n\n    if options.surf is None:\n        parser.print_help()\n        sys.exit(1)\n\n    print(f\"Converting {options.surf} to BEM FIF file.\")\n    surf = mne.bem._surfaces_to_bem([options.surf], [int(options.id)], sigmas=[1])\n    mne.write_bem_surfaces(options.fif, surf)", "metadata": {}}
{"_id": "mne_mne_commands/mne_show_fiff.py_run_code", "title": "run", "text": "def run():\n    \"\"\"Run command.\"\"\"\n    parser = mne.commands.utils.get_optparser(__file__, usage=\"mne show_fiff <file>\")\n    parser.add_option(\n        \"-t\",\n        \"--tag\",\n        dest=\"tag\",\n        help=\"provide information about this tag\",\n        metavar=\"TAG\",\n    )\n    parser.add_option(\n        \"-b\",\n        \"--bytes\",\n        dest=\"show_bytes\",\n        help=\"show the byte offset of each tag\",\n        action=\"store_true\",\n    )\n    options, args = parser.parse_args()\n    if len(args) != 1:\n        parser.print_help()\n        sys.exit(1)\n    msg = mne.io.show_fiff(\n        args[0], tag=options.tag, show_bytes=options.show_bytes\n    ).strip()\n    print(msg)", "metadata": {}}
{"_id": "mne_mne_commands/mne_compute_proj_ecg.py_run_code", "title": "run", "text": "def run():\n    \"\"\"Run command.\"\"\"\n    from mne.commands.utils import get_optparser\n\n    parser = get_optparser(__file__)\n\n    parser.add_option(\n        \"-i\", \"--in\", dest=\"raw_in\", help=\"Input raw FIF file\", metavar=\"FILE\"\n    )\n    parser.add_option(\n        \"--tmin\",\n        dest=\"tmin\",\n        type=\"float\",\n        help=\"Time before event in seconds\",\n        default=-0.2,\n    )\n    parser.add_option(\n        \"--tmax\",\n        dest=\"tmax\",\n        type=\"float\",\n        help=\"Time after event in seconds\",\n        default=0.4,\n    )\n    parser.add_option(\n        \"-g\",\n        \"--n-grad\",\n        dest=\"n_grad\",\n        type=\"int\",\n        help=\"Number of SSP vectors for gradiometers\",\n        default=2,\n    )\n    parser.add_option(\n        \"-m\",\n        \"--n-mag\",\n        dest=\"n_mag\",\n        type=\"int\",\n        help=\"Number of SSP vectors for magnetometers\",\n        default=2,\n    )\n    parser.add_option(\n        \"-e\",\n        \"--n-eeg\",\n        dest=\"n_eeg\",\n        type=\"int\",\n        help=\"Number of SSP vectors for EEG\",\n        default=2,\n    )\n    parser.add_option(\n        \"--l-freq\",\n        dest=\"l_freq\",\n        type=\"float\",\n        help=\"Filter low cut-off frequency in Hz\",\n        default=1,\n    )\n    parser.add_option(\n        \"--h-freq\",\n        dest=\"h_freq\",\n        type=\"float\",\n        help=\"Filter high cut-off frequency in Hz\",\n        default=100,\n    )\n    parser.add_option(\n        \"--ecg-l-freq\",\n        dest=\"ecg_l_freq\",\n        type=\"float\",\n        help=\"Filter low cut-off frequency in Hz used for ECG event detection\",\n        default=5,\n    )\n    parser.add_option(\n        \"--ecg-h-freq\",\n        dest=\"ecg_h_freq\",\n        type=\"float\",\n        help=\"Filter high cut-off frequency in Hz used for ECG event detection\",\n        default=35,\n    )\n    parser.add_option(\n        \"-p\",\n        \"--preload\",\n        dest=\"preload\",\n        help=\"Temporary file used during computation (to save memory)\",\n        default=True,\n    )\n    parser.add_option(\n        \"-a\",\n        \"--average\",\n        dest=\"average\",\n        action=\"store_true\",\n        help=\"Compute SSP after averaging\",\n        default=False,\n    )\n    parser.add_option(\n        \"--proj\", dest=\"proj\", help=\"Use SSP projections from a fif file.\", default=None\n    )\n    parser.add_option(\n        \"--filtersize\",\n        dest=\"filter_length\",\n        type=\"int\",\n        help=\"Number of taps to use for filtering\",\n        default=2048,\n    )\n    parser.add_option(\n        \"-j\",\n        \"--n-jobs\",\n        dest=\"n_jobs\",\n        type=\"int\",\n        help=\"Number of jobs to run in parallel\",\n        default=1,\n    )\n    parser.add_option(\n        \"-c\",\n        \"--channel\",\n        dest=\"ch_name\",\n        help=\"Channel to use for ECG detection (Required if no ECG found)\",\n        default=None,\n    )\n    parser.add_option(\n        \"--rej-grad\",\n        dest=\"rej_grad\",\n        type=\"float\",\n        help=\"Gradiometers rejection parameter in fT/cm (peak to peak amplitude)\",\n        default=2000,\n    )\n    parser.add_option(\n        \"--rej-mag\",\n        dest=\"rej_mag\",\n        type=\"float\",\n        help=\"Magnetometers rejection parameter in fT (peak to peak amplitude)\",\n        default=3000,\n    )\n    parser.add_option(\n        \"--rej-eeg\",\n        dest=\"rej_eeg\",\n        type=\"float\",\n        help=\"EEG rejection parameter in \u00b5V (peak to peak amplitude)\",\n        default=50,\n    )\n    parser.add_option(\n        \"--rej-eog\",\n        dest=\"rej_eog\",\n        type=\"float\",\n        help=\"EOG rejection parameter in \u00b5V (peak to peak amplitude)\",\n        default=250,\n    )\n    parser.add_option(\n        \"--avg-ref\",\n        dest=\"avg_ref\",\n        action=\"store_true\",\n        help=\"Add EEG average reference proj\",\n        default=False,\n    )\n    parser.add_option(\n        \"--no-proj\",\n        dest=\"no_proj\",\n        action=\"store_true\",\n        help=\"Exclude the SSP projectors currently in the fiff file\",\n        default=False,\n    )\n    parser.add_option(\n        \"--bad\",\n        dest=\"bad_fname\",\n        help=\"Text file containing bad channels list (one per line)\",\n        default=None,\n    )\n    parser.add_option(\n        \"--event-id\",\n        dest=\"event_id\",\n        type=\"int\",\n        help=\"ID to use for events\",\n        default=999,\n    )\n    parser.add_option(\n        \"--event-raw\",\n        dest=\"raw_event_fname\",\n        help=\"raw file to use for event detection\",\n        default=None,\n    )\n    parser.add_option(\n        \"--tstart\",\n        dest=\"tstart\",\n        type=\"float\",\n        help=\"Start artifact detection after tstart seconds\",\n        default=0.0,\n    )\n    parser.add_option(\n        \"--qrsthr\",\n        dest=\"qrs_threshold\",\n        type=\"string\",\n        help=\"QRS detection threshold. Between 0 and 1. Can \"\n        \"also be 'auto' for automatic selection\",\n        default=\"auto\",\n    )\n\n    options, args = parser.parse_args()\n\n    raw_in = options.raw_in\n\n    if raw_in is None:\n        parser.print_help()\n        sys.exit(1)\n\n    tmin = options.tmin\n    tmax = options.tmax\n    n_grad = options.n_grad\n    n_mag = options.n_mag\n    n_eeg = options.n_eeg\n    l_freq = options.l_freq\n    h_freq = options.h_freq\n    ecg_l_freq = options.ecg_l_freq\n    ecg_h_freq = options.ecg_h_freq\n    average = options.average\n    preload = options.preload\n    filter_length = options.filter_length\n    n_jobs = options.n_jobs\n    ch_name = options.ch_name\n    reject = dict(\n        grad=1e-13 * float(options.rej_grad),\n        mag=1e-15 * float(options.rej_mag),\n        eeg=1e-6 * float(options.rej_eeg),\n        eog=1e-6 * float(options.rej_eog),\n    )\n    avg_ref = options.avg_ref\n    no_proj = options.no_proj\n    bad_fname = options.bad_fname\n    event_id = options.event_id\n    proj_fname = options.proj\n    raw_event_fname = options.raw_event_fname\n    tstart = options.tstart\n    qrs_threshold = options.qrs_threshold\n    if qrs_threshold != \"auto\":\n        try:\n            qrs_threshold = float(qrs_threshold)\n        except ValueError:\n            raise ValueError('qrsthr must be \"auto\" or a float')\n\n    if bad_fname is not None:\n        with open(bad_fname) as fid:\n            bads = [w.rstrip() for w in fid.readlines()]\n        print(f\"Bad channels read : {bads}\")\n    else:\n        bads = []\n\n    if raw_in.endswith(\"_raw.fif\") or raw_in.endswith(\"-raw.fif\"):\n        prefix = raw_in[:-8]\n    else:\n        prefix = raw_in[:-4]\n\n    ecg_event_fname = prefix + \"_ecg-eve.fif\"\n\n    if average:\n        ecg_proj_fname = prefix + \"_ecg_avg-proj.fif\"\n    else:\n        ecg_proj_fname = prefix + \"_ecg-proj.fif\"\n\n    raw = mne.io.read_raw_fif(raw_in, preload=preload)\n\n    if raw_event_fname is not None:\n        raw_event = mne.io.read_raw_fif(raw_event_fname)\n    else:\n        raw_event = raw\n\n    flat = None\n    projs, events = mne.preprocessing.compute_proj_ecg(\n        raw,\n        raw_event,\n        tmin,\n        tmax,\n        n_grad,\n        n_mag,\n        n_eeg,\n        l_freq,\n        h_freq,\n        average,\n        filter_length,\n        n_jobs,\n        ch_name,\n        reject,\n        flat,\n        bads,\n        avg_ref,\n        no_proj,\n        event_id,\n        ecg_l_freq,\n        ecg_h_freq,\n        tstart,\n        qrs_threshold,\n        copy=False,\n    )\n\n    raw.close()\n\n    if raw_event_fname is not None:\n        raw_event.close()\n\n    if proj_fname is not None:\n        print(f\"Including SSP projections from : {proj_fname}\")\n        # append the ecg projs, so they are last in the list\n        projs = mne.read_proj(proj_fname) + projs\n\n    if isinstance(preload, str) and os.path.exists(preload):\n        os.remove(preload)\n\n    print(f\"Writing ECG projections in {ecg_proj_fname}\")\n    mne.write_proj(ecg_proj_fname, projs)\n\n    print(f\"Writing ECG events in {ecg_event_fname}\")\n    mne.write_events(ecg_event_fname, events)", "metadata": {}}
{"_id": "mne_mne_commands/mne_anonymize.py_mne_anonymize_code", "title": "mne_anonymize", "text": "def mne_anonymize(fif_fname, out_fname, keep_his, daysback, overwrite):\n    \"\"\"Call *anonymize_info* on fif file and save.\n\n    Parameters\n    ----------\n    fif_fname : path-like\n        Raw fif File\n    out_fname : path-like | None\n        Output file name\n        relative paths are saved relative to parent dir of fif_fname\n        None will save to parent dir of fif_fname with default prefix\n    daysback : int | None\n        Number of days to subtract from all dates.\n        If None will default to move date of service to Jan 1 2000\n    keep_his : bool\n        If True his_id of subject_info will NOT be overwritten.\n        defaults to False\n    overwrite : bool\n        Overwrite output file if it already exists\n    \"\"\"\n    raw = mne.io.read_raw_fif(fif_fname, allow_maxshield=True)\n    raw.anonymize(daysback=daysback, keep_his=keep_his)\n\n    # determine out_fname\n    dir_name = op.split(fif_fname)[0]\n    if out_fname is None:\n        fif_bname = op.basename(fif_fname)\n        out_fname = op.join(dir_name, f\"{ANONYMIZE_FILE_PREFIX}-{fif_bname}\")\n    elif not op.isabs(out_fname):\n        out_fname = op.join(dir_name, out_fname)\n\n    raw.save(out_fname, overwrite=overwrite)", "metadata": {}}
{"_id": "mne_mne_commands/mne_anonymize.py_run_code", "title": "run", "text": "def run():\n    \"\"\"Run *mne_anonymize* command.\"\"\"\n    from mne.commands.utils import get_optparser\n\n    parser = get_optparser(__file__)\n\n    parser.add_option(\n        \"-f\",\n        \"--file\",\n        type=\"string\",\n        dest=\"file\",\n        help=\"Name of file to modify.\",\n        metavar=\"FILE\",\n        default=None,\n    )\n    parser.add_option(\n        \"-o\",\n        \"--output\",\n        type=\"string\",\n        dest=\"output\",\n        help=\"Name of anonymized output file.\"\n        \"`anon-` prefix is added to FILE if not given\",\n        metavar=\"OUTFILE\",\n        default=None,\n    )\n    parser.add_option(\n        \"--keep_his\",\n        dest=\"keep_his\",\n        action=\"store_true\",\n        help=\"Keep the HIS tag (not advised)\",\n        default=False,\n    )\n    parser.add_option(\n        \"-d\",\n        \"--daysback\",\n        type=\"int\",\n        dest=\"daysback\",\n        help=\"Move dates in file backwards by this many days.\",\n        metavar=\"N_DAYS\",\n        default=None,\n    )\n    parser.add_option(\n        \"--overwrite\",\n        dest=\"overwrite\",\n        action=\"store_true\",\n        help=\"Overwrite input file.\",\n        default=False,\n    )\n\n    options, args = parser.parse_args()\n    if options.file is None:\n        parser.print_help()\n        sys.exit(1)\n\n    fname = options.file\n    out_fname = options.output\n    keep_his = options.keep_his\n    daysback = options.daysback\n    overwrite = options.overwrite\n    if not fname.endswith(\".fif\"):\n        raise ValueError(f\"{fname} does not seem to be a .fif file.\")\n\n    mne_anonymize(fname, out_fname, keep_his, daysback, overwrite)", "metadata": {}}
{"_id": "mne_mne_commands/mne_watershed_bem.py_run_code", "title": "run", "text": "def run():\n    \"\"\"Run command.\"\"\"\n    from mne.commands.utils import _add_verbose_flag, get_optparser\n\n    parser = get_optparser(__file__)\n\n    parser.add_option(\n        \"-s\", \"--subject\", dest=\"subject\", help=\"Subject name (required)\", default=None\n    )\n    parser.add_option(\n        \"-d\",\n        \"--subjects-dir\",\n        dest=\"subjects_dir\",\n        help=\"Subjects directory\",\n        default=None,\n    )\n    parser.add_option(\n        \"-o\",\n        \"--overwrite\",\n        dest=\"overwrite\",\n        help=\"Write over existing files\",\n        action=\"store_true\",\n    )\n    parser.add_option(\n        \"-v\", \"--volume\", dest=\"volume\", help=\"Defaults to T1\", default=\"T1\"\n    )\n    parser.add_option(\n        \"-a\",\n        \"--atlas\",\n        dest=\"atlas\",\n        help=\"Specify the --atlas option for mri_watershed\",\n        default=False,\n        action=\"store_true\",\n    )\n    parser.add_option(\n        \"-g\",\n        \"--gcaatlas\",\n        dest=\"gcaatlas\",\n        help=\"Specify the --brain_atlas option for mri_watershed\",\n        default=False,\n        action=\"store_true\",\n    )\n    parser.add_option(\n        \"-p\",\n        \"--preflood\",\n        dest=\"preflood\",\n        help=\"Change the preflood height\",\n        default=None,\n    )\n    parser.add_option(\n        \"--copy\",\n        dest=\"copy\",\n        help=\"Use copies instead of symlinks for surfaces\",\n        action=\"store_true\",\n    )\n    parser.add_option(\n        \"-t\",\n        \"--T1\",\n        dest=\"T1\",\n        help=\"Whether or not to pass the -T1 flag \"\n        \"(can be true, false, 0, or 1). \"\n        \"By default it takes the same value as gcaatlas.\",\n        default=None,\n    )\n    parser.add_option(\n        \"-b\",\n        \"--brainmask\",\n        dest=\"brainmask\",\n        help=\"The filename for the brainmask output file \"\n        \"relative to the \"\n        \"$SUBJECTS_DIR/$SUBJECT/bem/watershed/ directory.\",\n        default=\"ws\",\n    )\n    _add_verbose_flag(parser)\n\n    options, args = parser.parse_args()\n\n    if options.subject is None:\n        parser.print_help()\n        sys.exit(1)\n\n    subject = options.subject\n    subjects_dir = options.subjects_dir\n    overwrite = options.overwrite\n    volume = options.volume\n    atlas = options.atlas\n    gcaatlas = options.gcaatlas\n    preflood = options.preflood\n    copy = options.copy\n    brainmask = options.brainmask\n    T1 = options.T1\n    if T1 is not None:\n        T1 = T1.lower()\n        _check_option(\"--T1\", T1, (\"true\", \"false\", \"0\", \"1\"))\n        T1 = T1 in (\"true\", \"1\")\n    verbose = options.verbose\n\n    make_watershed_bem(\n        subject=subject,\n        subjects_dir=subjects_dir,\n        overwrite=overwrite,\n        volume=volume,\n        atlas=atlas,\n        gcaatlas=gcaatlas,\n        preflood=preflood,\n        copy=copy,\n        T1=T1,\n        brainmask=brainmask,\n        verbose=verbose,\n    )", "metadata": {}}
{"_id": "mne_mne_commands/utils.py_load_module_code", "title": "load_module", "text": "def load_module(name, path):\n    \"\"\"Load module from .py/.pyc file.\n\n    Parameters\n    ----------\n    name : str\n        Name of the module.\n    path : str\n        Path to .py/.pyc file.\n\n    Returns\n    -------\n    mod : module\n        Imported module.\n\n    \"\"\"\n    from importlib.util import module_from_spec, spec_from_file_location\n\n    spec = spec_from_file_location(name, path)\n    mod = module_from_spec(spec)\n    spec.loader.exec_module(mod)\n    return mod", "metadata": {}}
{"_id": "mne_mne_commands/utils.py_get_optparser_code", "title": "get_optparser", "text": "def get_optparser(cmdpath, usage=None, prog_prefix=\"mne\", version=None):\n    \"\"\"Create OptionParser with cmd specific settings (e.g., prog value).\"\"\"\n    # Fetch description\n    mod = load_module(\"__temp\", cmdpath)\n    if mod.__doc__:\n        doc, description, epilog = mod.__doc__, None, None\n\n        doc_lines = doc.split(\"\\n\")\n        description = doc_lines[0]\n        if len(doc_lines) > 1:\n            epilog = \"\\n\".join(doc_lines[1:])\n\n    # Get the name of the command\n    command = os.path.basename(cmdpath)\n    command, _ = os.path.splitext(command)\n    command = command[len(prog_prefix) + 1 :]  # +1 is for `_` character\n\n    # Set prog\n    prog = prog_prefix + f\" {command}\"\n\n    # Set version\n    if version is None:\n        version = mne.__version__\n\n    # monkey patch OptionParser to not wrap epilog\n    OptionParser.format_epilog = lambda self, formatter: self.epilog\n    parser = OptionParser(\n        prog=prog, version=version, description=description, epilog=epilog, usage=usage\n    )\n\n    return parser", "metadata": {}}
{"_id": "mne_mne_commands/utils.py_main_code", "title": "main", "text": "def main():\n    \"\"\"Entrypoint for mne <command> usage.\"\"\"\n    mne_bin_dir = op.dirname(op.dirname(__file__))\n    valid_commands = sorted(glob.glob(op.join(mne_bin_dir, \"commands\", \"mne_*.py\")))\n    valid_commands = [c.split(op.sep)[-1][4:-3] for c in valid_commands]\n\n    def print_help():  # noqa\n        print(\"Usage : mne command options\\n\")\n        print(\"Accepted commands :\\n\")\n        for c in valid_commands:\n            print(f\"\\t- {c}\")\n        print(\"\\nExample : mne browse_raw --raw sample_audvis_raw.fif\")\n        print(\"\\nGetting help example : mne compute_proj_eog -h\")\n\n    if len(sys.argv) == 1 or \"help\" in sys.argv[1] or \"-h\" in sys.argv[1]:\n        print_help()\n    elif sys.argv[1] == \"--version\":\n        print(f\"MNE {mne.__version__}\")\n    elif sys.argv[1] not in valid_commands:\n        print(f'Invalid command: \"{sys.argv[1]}\"\\n')\n        print_help()\n    else:\n        cmd = sys.argv[1]\n        cmd = importlib.import_module(f\".mne_{cmd}\", \"mne.commands\")\n        sys.argv = sys.argv[1:]\n        cmd.run()", "metadata": {}}
{"_id": "mne_mne_commands/mne_what.py_run_code", "title": "run", "text": "def run():\n    \"\"\"Run command.\"\"\"\n    from mne.commands.utils import get_optparser\n\n    parser = get_optparser(__file__, usage=\"usage: %prog fname [fname2 ...]\")\n    options, args = parser.parse_args()\n    for arg in args:\n        print(mne.what(arg))", "metadata": {}}
{"_id": "mne_mne_commands/mne_setup_forward_model.py_run_code", "title": "run", "text": "def run():\n    \"\"\"Run command.\"\"\"\n    from mne.commands.utils import _add_verbose_flag, get_optparser\n\n    parser = get_optparser(__file__)\n\n    parser.add_option(\n        \"-s\", \"--subject\", dest=\"subject\", help=\"Subject name (required)\", default=None\n    )\n    parser.add_option(\n        \"--model\",\n        dest=\"model\",\n        help=\"Output file name. Use a name <dir>/<name>-bem.fif\",\n        default=None,\n        type=\"string\",\n    )\n    parser.add_option(\n        \"--ico\",\n        dest=\"ico\",\n        help=\"The surface ico downsampling to use, e.g. \"\n        \" 5=20484, 4=5120, 3=1280. If None, no subsampling\"\n        \" is applied.\",\n        default=None,\n        type=\"int\",\n    )\n    parser.add_option(\n        \"--brainc\",\n        dest=\"brainc\",\n        help=\"Defines the brain compartment conductivity. \"\n        \"The default value is 0.3 S/m.\",\n        default=0.3,\n        type=\"float\",\n    )\n    parser.add_option(\n        \"--skullc\",\n        dest=\"skullc\",\n        help=\"Defines the skull compartment conductivity. \"\n        \"The default value is 0.006 S/m.\",\n        default=None,\n        type=\"float\",\n    )\n    parser.add_option(\n        \"--scalpc\",\n        dest=\"scalpc\",\n        help=\"Defines the scalp compartment conductivity. \"\n        \"The default value is 0.3 S/m.\",\n        default=None,\n        type=\"float\",\n    )\n    parser.add_option(\n        \"--homog\",\n        dest=\"homog\",\n        help=\"Use a single compartment model (brain only) \"\n        \"instead a three layer one (scalp, skull, and \"\n        \" brain). If this flag is specified, the options \"\n        \"--skullc and --scalpc are irrelevant.\",\n        default=None,\n        action=\"store_true\",\n    )\n    parser.add_option(\n        \"-d\",\n        \"--subjects-dir\",\n        dest=\"subjects_dir\",\n        help=\"Subjects directory\",\n        default=None,\n    )\n    _add_verbose_flag(parser)\n    options, args = parser.parse_args()\n\n    if options.subject is None:\n        parser.print_help()\n        sys.exit(1)\n\n    subject = options.subject\n    fname = options.model\n    subjects_dir = options.subjects_dir\n    ico = options.ico\n    brainc = options.brainc\n    skullc = options.skullc\n    scalpc = options.scalpc\n    homog = True if options.homog is not None else False\n    verbose = True if options.verbose is not None else False\n    # Parse conductivity option\n    if homog is True:\n        if skullc is not None:\n            warn(\n                \"Trying to set the skull conductivity for a single layer \"\n                \"model. To use a 3 layer model, do not set the --homog flag.\"\n            )\n        if scalpc is not None:\n            warn(\n                \"Trying to set the scalp conductivity for a single layer \"\n                \"model. To use a 3 layer model, do not set the --homog flag.\"\n            )\n        # Single layer\n        conductivity = [brainc]\n    else:\n        if skullc is None:\n            skullc = 0.006\n        if scalpc is None:\n            scalpc = 0.3\n        conductivity = [brainc, skullc, scalpc]\n    # Create source space\n    bem_model = mne.make_bem_model(\n        subject,\n        ico=ico,\n        conductivity=conductivity,\n        subjects_dir=subjects_dir,\n        verbose=verbose,\n    )\n    # Generate filename\n    if fname is None:\n        n_faces = list(str(len(surface[\"tris\"])) for surface in bem_model)\n        fname = subject + \"-\" + \"-\".join(n_faces) + \"-bem.fif\"\n    else:\n        if not (fname.endswith(\"-bem.fif\") or fname.endswith(\"_bem.fif\")):\n            fname = fname + \"-bem.fif\"\n            # Save to subject's directory\n    subjects_dir = get_subjects_dir(subjects_dir, raise_error=True)\n    fname = subjects_dir / subject / \"bem\" / fname\n    # Save source space to file\n    mne.write_bem_surfaces(fname, bem_model)\n    # Compute the solution\n    sol_fname = os.path.splitext(str(fname))[0] + \"-sol.fif\"\n    bem_sol = mne.make_bem_solution(bem_model, verbose=verbose)\n    mne.write_bem_solution(sol_fname, bem_sol)", "metadata": {}}
{"_id": "mne_mne_commands/mne_flash_bem.py_run_code", "title": "run", "text": "def run():\n    \"\"\"Run command.\"\"\"\n    from mne.commands.utils import get_optparser\n\n    parser = get_optparser(__file__)\n\n    parser.add_option(\n        \"-s\", \"--subject\", dest=\"subject\", help=\"Subject name\", default=None\n    )\n    parser.add_option(\n        \"-d\",\n        \"--subjects-dir\",\n        dest=\"subjects_dir\",\n        help=\"Subjects directory\",\n        default=None,\n    )\n    parser.add_option(\n        \"-3\",\n        \"--flash30\",\n        \"--noflash30\",\n        dest=\"flash30\",\n        action=\"callback\",\n        callback=_vararg_callback,\n        help=(\n            \"The 30-degree flip angle data. If no argument do \"\n            \"not use flash30. If arguments are given, them as \"\n            \"file names.\"\n        ),\n    )\n    parser.add_option(\n        \"-5\",\n        \"--flash5\",\n        dest=\"flash5\",\n        action=\"callback\",\n        callback=_vararg_callback,\n        help=(\"Path to the multiecho flash 5 images. Can be one file or one per echo.\"),\n    )\n    parser.add_option(\n        \"-r\",\n        \"--registered\",\n        dest=\"registered\",\n        action=\"store_true\",\n        default=False,\n        help=(\n            \"Set if the Flash MRI images have already \"\n            \"been registered with the T1.mgz file.\"\n        ),\n    )\n    parser.add_option(\n        \"-u\",\n        \"--unwarp\",\n        dest=\"unwarp\",\n        action=\"store_true\",\n        default=False,\n        help=(\n            \"Run grad_unwarp with -unwarp <type> \"\n            \"option on each of the converted data sets\"\n        ),\n    )\n    parser.add_option(\n        \"-o\",\n        \"--overwrite\",\n        dest=\"overwrite\",\n        action=\"store_true\",\n        default=False,\n        help=\"Write over existing .surf files in bem folder\",\n    )\n    parser.add_option(\n        \"-v\",\n        \"--view\",\n        dest=\"show\",\n        action=\"store_true\",\n        help=\"Show BEM model in 3D for visual inspection\",\n        default=False,\n    )\n    parser.add_option(\n        \"--copy\",\n        dest=\"copy\",\n        help=\"Use copies instead of symlinks for surfaces\",\n        action=\"store_true\",\n    )\n\n    options, _ = parser.parse_args()\n\n    subject = options.subject\n    subjects_dir = options.subjects_dir\n    flash5 = options.flash5\n    if flash5 is None or len(flash5) == 0:\n        flash5 = True\n    flash30 = options.flash30\n    if flash30 is None:\n        flash30 = True\n    elif len(flash30) == 0:\n        flash30 = False\n    register = not options.registered\n    unwarp = options.unwarp\n    overwrite = options.overwrite\n    show = options.show\n    copy = options.copy\n\n    if options.subject is None:\n        parser.print_help()\n        raise RuntimeError(\"The subject argument must be set\")\n\n    flash5_img = convert_flash_mris(\n        subject=subject,\n        subjects_dir=subjects_dir,\n        flash5=flash5,\n        flash30=flash30,\n        unwarp=unwarp,\n        verbose=True,\n    )\n    make_flash_bem(\n        subject=subject,\n        subjects_dir=subjects_dir,\n        overwrite=overwrite,\n        show=show,\n        copy=copy,\n        register=register,\n        flash5_img=flash5_img,\n        verbose=True,\n    )", "metadata": {}}
{"_id": "mne_mne_source_space/_source_space.py_read_source_spaces_code", "title": "read_source_spaces", "text": "def read_source_spaces(fname, patch_stats=False, verbose=None):\n    \"\"\"Read the source spaces from a FIF file.\n\n    Parameters\n    ----------\n    fname : path-like\n        The name of the file, which should end with ``-src.fif`` or\n        ``-src.fif.gz``.\n    patch_stats : bool, optional (default False)\n        Calculate and add cortical patch statistics to the surfaces.\n    %(verbose)s\n\n    Returns\n    -------\n    src : SourceSpaces\n        The source spaces.\n\n    See Also\n    --------\n    write_source_spaces, setup_source_space, setup_volume_source_space\n    \"\"\"\n    # be more permissive on read than write (fwd/inv can contain src)\n    fname = _check_fname(fname, overwrite=\"read\", must_exist=True)\n    check_fname(\n        fname,\n        \"source space\",\n        (\n            \"-src.fif\",\n            \"-src.fif.gz\",\n            \"_src.fif\",\n            \"_src.fif.gz\",\n            \"-fwd.fif\",\n            \"-fwd.fif.gz\",\n            \"_fwd.fif\",\n            \"_fwd.fif.gz\",\n            \"-inv.fif\",\n            \"-inv.fif.gz\",\n            \"_inv.fif\",\n            \"_inv.fif.gz\",\n        ),\n    )\n\n    ff, tree, _ = fiff_open(fname)\n    with ff as fid:\n        src = _read_source_spaces_from_tree(\n            fid, tree, patch_stats=patch_stats, verbose=verbose\n        )\n        src.info[\"fname\"] = fname\n        node = dir_tree_find(tree, FIFF.FIFFB_MNE_ENV)\n        if node:\n            node = node[0]\n            for p in range(node[\"nent\"]):\n                kind = node[\"directory\"][p].kind\n                pos = node[\"directory\"][p].pos\n                tag = read_tag(fid, pos)\n                if kind == FIFF.FIFF_MNE_ENV_WORKING_DIR:\n                    src.info[\"working_dir\"] = tag.data\n                elif kind == FIFF.FIFF_MNE_ENV_COMMAND_LINE:\n                    src.info[\"command_line\"] = tag.data\n    return src", "metadata": {}}
{"_id": "mne_mne_source_space/_source_space.py_find_source_space_hemi_code", "title": "find_source_space_hemi", "text": "def find_source_space_hemi(src):\n    \"\"\"Return the hemisphere id for a source space.\n\n    Parameters\n    ----------\n    src : dict\n        The source space to investigate.\n\n    Returns\n    -------\n    hemi : int\n        Deduced hemisphere id.\n    \"\"\"\n    xave = src[\"rr\"][:, 0].sum()\n\n    if xave < 0:\n        hemi = int(FIFF.FIFFV_MNE_SURF_LEFT_HEMI)\n    else:\n        hemi = int(FIFF.FIFFV_MNE_SURF_RIGHT_HEMI)\n\n    return hemi", "metadata": {}}
{"_id": "mne_mne_source_space/_source_space.py_label_src_vertno_sel_code", "title": "label_src_vertno_sel", "text": "def label_src_vertno_sel(label, src):\n    \"\"\"Find vertex numbers and indices from label.\n\n    Parameters\n    ----------\n    label : Label\n        Source space label.\n    src : dict\n        Source space.\n\n    Returns\n    -------\n    vertices : list of length 2\n        Vertex numbers for lh and rh.\n    src_sel : array of int (len(idx) = len(vertices[0]) + len(vertices[1]))\n        Indices of the selected vertices in sourse space.\n    \"\"\"\n    if src[0][\"type\"] != \"surf\":\n        raise ValueError(\n            \"Labels are only supported with surface source spaces, \"\n            f\"got {_src_kind_dict[src[0]['type']]} source space\"\n        )\n\n    vertno = [src[0][\"vertno\"], src[1][\"vertno\"]]\n\n    if label.hemi == \"lh\":\n        vertno_sel = np.intersect1d(vertno[0], label.vertices)\n        src_sel = np.searchsorted(vertno[0], vertno_sel)\n        vertno[0] = vertno_sel\n        vertno[1] = np.array([], int)\n    elif label.hemi == \"rh\":\n        vertno_sel = np.intersect1d(vertno[1], label.vertices)\n        src_sel = np.searchsorted(vertno[1], vertno_sel) + len(vertno[0])\n        vertno[0] = np.array([], int)\n        vertno[1] = vertno_sel\n    elif label.hemi == \"both\":\n        vertno_sel_lh = np.intersect1d(vertno[0], label.lh.vertices)\n        src_sel_lh = np.searchsorted(vertno[0], vertno_sel_lh)\n        vertno_sel_rh = np.intersect1d(vertno[1], label.rh.vertices)\n        src_sel_rh = np.searchsorted(vertno[1], vertno_sel_rh) + len(vertno[0])\n        src_sel = np.hstack((src_sel_lh, src_sel_rh))\n        vertno = [vertno_sel_lh, vertno_sel_rh]\n    else:\n        raise Exception(\"Unknown hemisphere type\")\n\n    return vertno, src_sel", "metadata": {}}
{"_id": "mne_mne_source_space/_source_space.py_write_source_spaces_code", "title": "write_source_spaces", "text": "def write_source_spaces(fname, src, *, overwrite=False, verbose=None):\n    \"\"\"Write source spaces to a file.\n\n    Parameters\n    ----------\n    fname : path-like\n        The name of the file, which should end with ``-src.fif`` or\n        ``-src.fif.gz``.\n    src : instance of SourceSpaces\n        The source spaces (as returned by read_source_spaces).\n    %(overwrite)s\n    %(verbose)s\n\n    See Also\n    --------\n    read_source_spaces\n    \"\"\"\n    _validate_type(src, SourceSpaces, \"src\")\n    check_fname(\n        fname, \"source space\", (\"-src.fif\", \"-src.fif.gz\", \"_src.fif\", \"_src.fif.gz\")\n    )\n    _check_fname(fname, overwrite=overwrite)\n\n    with start_and_end_file(fname) as fid:\n        _write_source_spaces(fid, src)", "metadata": {}}
{"_id": "mne_mne_source_space/_source_space.py_setup_source_space_code", "title": "setup_source_space", "text": "def setup_source_space(\n    subject,\n    spacing=\"oct6\",\n    surface=\"white\",\n    subjects_dir=None,\n    add_dist=True,\n    n_jobs=None,\n    *,\n    verbose=None,\n):\n    \"\"\"Set up bilateral hemisphere surface-based source space with subsampling.\n\n    Parameters\n    ----------\n    %(subject)s\n    spacing : str\n        The spacing to use. Can be ``'ico#'`` for a recursively subdivided\n        icosahedron, ``'oct#'`` for a recursively subdivided octahedron,\n        ``'all'`` for all points, or an integer to use approximate\n        distance-based spacing (in mm).\n\n        .. versionchanged:: 0.18\n           Support for integers for distance-based spacing.\n    surface : str\n        The surface to use.\n    %(subjects_dir)s\n    add_dist : bool | str\n        Add distance and patch information to the source space. This takes some\n        time so precomputing it is recommended. Can also be 'patch' to only\n        compute patch information.\n\n        .. versionchanged:: 0.20\n           Support for ``add_dist='patch'``.\n    %(n_jobs)s\n        Ignored if ``add_dist=='patch'``.\n    %(verbose)s\n\n    Returns\n    -------\n    src : SourceSpaces\n        The source space for each hemisphere.\n\n    See Also\n    --------\n    setup_volume_source_space\n    \"\"\"\n    cmd = (\n        f\"setup_source_space({subject}, spacing={spacing}, surface={surface}, \"\n        f\"subjects_dir={subjects_dir}, add_dist={add_dist}, verbose={verbose})\"\n    )\n\n    subjects_dir = get_subjects_dir(subjects_dir, raise_error=True)\n    surfs = [\n        subjects_dir / subject / \"surf\" / f\"{hemi}.{surface}\" for hemi in [\"lh\", \"rh\"]\n    ]\n    for surf, hemi in zip(surfs, [\"LH\", \"RH\"]):\n        if surf is not None and not op.isfile(surf):\n            raise OSError(f\"Could not find the {hemi} surface {surf}\")\n\n    logger.info(\"Setting up the source space with the following parameters:\\n\")\n    logger.info(f\"SUBJECTS_DIR = {subjects_dir}\")\n    logger.info(f\"Subject      = {subject}\")\n    logger.info(f\"Surface      = {surface}\")\n    stype, sval, ico_surf, src_type_str = _check_spacing(spacing)\n    logger.info(\"\")\n    del spacing\n\n    logger.info(\">>> 1. Creating the source space...\\n\")\n\n    # mne_make_source_space ... actually make the source spaces\n    src = []\n\n    # pre-load ico/oct surf (once) for speed, if necessary\n    if stype not in (\"spacing\", \"all\"):\n        logger.info(\n            f\"Doing the {dict(ico='icosa', oct='octa')[stype]}hedral vertex picking...\"\n        )\n    for hemi, surf in zip([\"lh\", \"rh\"], surfs):\n        logger.info(f\"Loading {surf}...\")\n        # Setup the surface spacing in the MRI coord frame\n        if stype != \"all\":\n            logger.info(\"Mapping %s %s -> %s (%d) ...\", hemi, subject, stype, sval)\n        s = _create_surf_spacing(surf, hemi, subject, stype, ico_surf, subjects_dir)\n        logger.info(\n            \"loaded %s %d/%d selected to source space (%s)\",\n            op.split(surf)[1],\n            s[\"nuse\"],\n            s[\"np\"],\n            src_type_str,\n        )\n        src.append(s)\n        logger.info(\"\")  # newline after both subject types are run\n\n    # Fill in source space info\n    hemi_ids = [FIFF.FIFFV_MNE_SURF_LEFT_HEMI, FIFF.FIFFV_MNE_SURF_RIGHT_HEMI]\n    for s, s_id in zip(src, hemi_ids):\n        # Add missing fields\n        s.update(\n            dict(\n                dist=None,\n                dist_limit=None,\n                nearest=None,\n                type=\"surf\",\n                nearest_dist=None,\n                pinfo=None,\n                patch_inds=None,\n                id=s_id,\n                coord_frame=FIFF.FIFFV_COORD_MRI,\n            )\n        )\n        s[\"rr\"] /= 1000.0\n        del s[\"tri_area\"]\n        del s[\"tri_cent\"]\n        del s[\"tri_nn\"]\n        del s[\"neighbor_tri\"]\n\n    # upconvert to object format from lists\n    src = SourceSpaces(src, dict(working_dir=os.getcwd(), command_line=cmd))\n\n    if add_dist:\n        dist_limit = 0.0 if add_dist == \"patch\" else np.inf\n        add_source_space_distances(\n            src, dist_limit=dist_limit, n_jobs=n_jobs, verbose=verbose\n        )\n\n    # write out if requested, then return the data\n    logger.info(\"You are now one step closer to computing the gain matrix\")\n    return src", "metadata": {}}
{"_id": "mne_mne_source_space/_source_space.py_setup_volume_source_space_code", "title": "setup_volume_source_space", "text": "def setup_volume_source_space(\n    subject=None,\n    pos=5.0,\n    mri=None,\n    sphere=None,\n    bem=None,\n    surface=None,\n    mindist=5.0,\n    exclude=0.0,\n    subjects_dir=None,\n    volume_label=None,\n    add_interpolator=True,\n    sphere_units=\"m\",\n    single_volume=False,\n    *,\n    n_jobs=None,\n    verbose=None,\n):\n    \"\"\"Set up a volume source space with grid spacing or discrete source space.\n\n    Parameters\n    ----------\n    subject : str | None\n        Subject to process. If None, the path to the MRI volume must be\n        absolute to get a volume source space. If a subject name\n        is provided the ``T1.mgz`` file will be found automatically.\n        Defaults to None.\n    pos : float | dict\n        Positions to use for sources. If float, a grid will be constructed\n        with the spacing given by ``pos`` in mm, generating a volume source\n        space. If dict, ``pos['rr']`` and ``pos['nn']`` will be used as the source\n        space locations (in meters) and normals, respectively, creating a\n        discrete source space.\n\n        .. note:: For a discrete source space (``pos`` is a dict),\n                  ``mri`` must be None.\n    mri : path-like | None\n        The filename of an MRI volume (mgh or mgz) to create the\n        interpolation matrix over. Source estimates obtained in the\n        volume source space can then be morphed onto the MRI volume\n        using this interpolator. If pos is a dict, this cannot be None.\n        If subject name is provided, ``pos`` is a float or ``volume_label``\n        are not provided then the ``mri`` parameter will default to ``'T1.mgz'``\n        or ``aseg.mgz``, respectively, else it will stay None.\n    sphere : ndarray, shape (4,) | ConductorModel | None\n        Define spherical source space bounds using origin and radius given\n        by ``(Ox, Oy, Oz, rad)`` in ``sphere_units``.\n        Only used if ``bem`` and ``surface`` are both None. Can also be a\n        spherical ConductorModel, which will use the origin and radius.\n        None (the default) uses a head-digitization fit.\n    bem : path-like | None | ConductorModel\n        Define source space bounds using a BEM file (specifically the inner\n        skull surface) or a :class:`~mne.bem.ConductorModel` for a 1-layer of 3-layers\n        BEM. See :func:`~mne.make_bem_model` and :func:`~mne.make_bem_solution` to\n        create a :class:`~mne.bem.ConductorModel`. If provided, ``surface`` must be\n        None.\n    surface : path-like | dict | None\n        Define source space bounds using a FreeSurfer surface file. Can\n        also be a dictionary with entries ``'rr'`` and ``'tris'``, such as\n        those returned by :func:`mne.read_surface`. If provided, ``bem`` must be None.\n    mindist : float\n        Exclude points closer than this distance (mm) to the bounding surface.\n    exclude : float\n        Exclude points closer than this distance (mm) from the center of mass\n        of the bounding surface.\n    %(subjects_dir)s\n    volume_label : str | dict | list | None\n        Region(s) of interest to use. None (default) will create a single\n        whole-brain source space. Otherwise, a separate source space will be\n        created for each entry in the list or dict (str will be turned into\n        a single-element list). If list of str, standard Freesurfer labels\n        are assumed. If dict, should be a mapping of region names to atlas\n        id numbers, allowing the use of other atlases.\n\n        .. versionchanged:: 0.21.0\n           Support for dict added.\n    add_interpolator : bool\n        If True and ``mri`` is not None, then an interpolation matrix\n        will be produced.\n    sphere_units : str\n        Defaults to ``\"m\"``.\n\n        .. versionadded:: 0.20\n    single_volume : bool\n        If True, multiple values of ``volume_label`` will be merged into a\n        a single source space instead of occupying multiple source spaces\n        (one for each sub-volume), i.e., ``len(src)`` will be ``1`` instead of\n        ``len(volume_label)``. This can help conserve memory and disk space\n        when many labels are used.\n\n        .. versionadded:: 0.21\n    %(n_jobs)s\n\n        .. versionadded:: 1.6\n    %(verbose)s\n\n    Returns\n    -------\n    src : SourceSpaces\n        A :class:`SourceSpaces` object containing one source space for each\n        entry of ``volume_labels``, or a single source space if\n        ``volume_labels`` was not specified.\n\n    See Also\n    --------\n    setup_source_space\n\n    Notes\n    -----\n    Volume source spaces are related to an MRI image such as T1 and allow to\n    visualize source estimates overlaid on MRIs and to morph estimates\n    to a template brain for group analysis. Discrete source spaces\n    don't allow this. If you provide a subject name the T1 MRI will be\n    used by default.\n\n    When you work with a source space formed from a grid you need to specify\n    the domain in which the grid will be defined. There are three ways\n    of specifying this:\n    (i) sphere, (ii) bem model, and (iii) surface.\n    The default behavior is to use sphere model\n    (``sphere=(0.0, 0.0, 0.0, 90.0)``) if ``bem`` or ``surface`` is not\n    ``None`` then ``sphere`` is ignored.\n    If you're going to use a BEM conductor model for forward model\n    it is recommended to pass it here.\n\n    To create a discrete source space, ``pos`` must be a dict, ``mri`` must be\n    None, and ``volume_label`` must be None. To create a whole brain volume\n    source space, ``pos`` must be a float and 'mri' must be provided.\n\n    To create a volume source space from label, ``pos`` must be a float,\n    ``volume_label`` must be provided, and 'mri' must refer to a .mgh or .mgz\n    file with values corresponding to the freesurfer lookup-table (typically\n    ``aseg.mgz``).\n    \"\"\"\n    subjects_dir = get_subjects_dir(subjects_dir)\n    _validate_type(volume_label, (str, list, tuple, dict, None), \"volume_label\")\n    _validate_type(bem, (\"path-like\", ConductorModel, None), \"bem\")\n    _validate_type(surface, (\"path-like\", dict, None), \"surface\")\n    if bem is not None and not isinstance(bem, ConductorModel):\n        bem = str(\n            _check_fname(bem, overwrite=\"read\", must_exist=True, name=\"bem filename\")\n        )\n    if surface is not None and not isinstance(surface, dict):\n        surface = str(\n            _check_fname(\n                surface, overwrite=\"read\", must_exist=True, name=\"surface filename\"\n            )\n        )\n\n    if bem is not None and surface is not None:\n        raise ValueError(\"Only one of 'bem' and 'surface' should be specified.\")\n\n    if mri is None and subject is not None:\n        if volume_label is not None:\n            mri = \"aseg.mgz\"\n        elif _is_numeric(pos):\n            mri = \"T1.mgz\"\n\n    if mri is not None:\n        mri = _check_mri(mri, subject, subjects_dir)\n        if isinstance(pos, dict):\n            raise ValueError(\n                \"Cannot create interpolation matrix for discrete source space, mri \"\n                \"must be None if pos is a dict\"\n            )\n\n    if volume_label is not None:\n        volume_label = _check_volume_labels(volume_label, mri)\n    assert volume_label is None or isinstance(volume_label, dict)\n\n    sphere = _check_sphere(sphere, sphere_units=sphere_units)\n\n    # triage bounding argument\n    if bem is not None:\n        logger.info(\"BEM              : %s\", bem)\n    elif surface is not None:\n        if isinstance(surface, dict):\n            if not all(key in surface for key in [\"rr\", \"tris\"]):\n                raise KeyError('surface, if dict, must have entries \"rr\" and \"tris\"')\n            # let's make sure we have geom info\n            complete_surface_info(surface, copy=False, verbose=False)\n            surf_extra = \"dict()\"\n        else:\n            if not op.isfile(surface):\n                raise OSError(f'surface file \"{surface}\" not found')\n            surf_extra = surface\n        logger.info(\"Boundary surface file : %s\", surf_extra)\n    else:\n        logger.info(\n            f\"Sphere                : origin at ({1000 * sphere[0]:.1f} \"\n            f\"{1000 * sphere[1]:.1f} {1000 * sphere[2]:.1f}) mm\"\n        )\n        logger.info(f\"              radius  : {1000 * sphere[3]:.1f} mm\")\n\n    # triage pos argument\n    if isinstance(pos, dict):\n        if not all(key in pos for key in [\"rr\", \"nn\"]):\n            raise KeyError('pos, if dict, must contain \"rr\" and \"nn\"')\n        pos_extra = \"dict()\"\n    else:  # pos should be float-like\n        try:\n            pos = float(pos)\n        except (TypeError, ValueError):\n            raise ValueError(\n                \"pos must be a dict, or something that can be cast to float()\"\n            )\n    if not isinstance(pos, float):\n        logger.info(\"Source location file  : %s\", pos_extra)\n        logger.info(\"Assuming input in millimeters\")\n        logger.info(\"Assuming input in MRI coordinates\")\n\n    if isinstance(pos, float):\n        logger.info(f\"grid                  : {pos:.1f} mm\")\n        logger.info(f\"mindist               : {mindist:.1f} mm\")\n        pos /= 1000.0  # convert pos from m to mm\n    if exclude > 0.0:\n        logger.info(f\"Exclude               : {exclude:.1f} mm\")\n    vol_info = dict()\n    if mri is not None:\n        logger.info(f\"MRI volume            : {mri}\")\n        logger.info(\"\")\n        logger.info(f\"Reading {mri}...\")\n        vol_info = _get_mri_info_data(mri, data=volume_label is not None)\n\n    exclude /= 1000.0  # convert exclude from m to mm\n    logger.info(\"\")\n\n    # Explicit list of points\n    if not isinstance(pos, float):\n        # Make the grid of sources\n        sp = [_make_discrete_source_space(pos)]\n    else:\n        # Load the brain surface as a template\n        if isinstance(bem, str):\n            # read bem surface in the MRI coordinate frame\n            surf = read_bem_surfaces(\n                bem, s_id=FIFF.FIFFV_BEM_SURF_ID_BRAIN, verbose=False\n            )\n            logger.info(\"Loaded inner skull from %s (%d nodes)\", bem, surf[\"np\"])\n        elif bem is not None and bem.get(\"is_sphere\") is False:\n            # read bem surface in the MRI coordinate frame\n            which = np.where(\n                [surf[\"id\"] == FIFF.FIFFV_BEM_SURF_ID_BRAIN for surf in bem[\"surfs\"]]\n            )[0]\n            if len(which) != 1:\n                raise ValueError(\"Could not get inner skull surface from BEM\")\n            surf = bem[\"surfs\"][which[0]]\n            assert surf[\"id\"] == FIFF.FIFFV_BEM_SURF_ID_BRAIN\n            if surf[\"coord_frame\"] != FIFF.FIFFV_COORD_MRI:\n                raise ValueError(\n                    f\"BEM is not in MRI coordinates, got \"\n                    f\"{_coord_frame_name(surf['coord_frame'])}\"\n                )\n            logger.info(f\"Taking inner skull from {bem}\")\n        elif surface is not None:\n            if isinstance(surface, str):\n                # read the surface in the MRI coordinate frame\n                surf = read_surface(surface, return_dict=True)[-1]\n            else:\n                surf = surface\n            logger.info(\n                \"Loaded bounding surface from %s (%d nodes)\", surface, surf[\"np\"]\n            )\n            surf = deepcopy(surf)\n            surf[\"rr\"] *= 1e-3  # must be converted to meters\n        else:  # Load an icosahedron and use that as the surface\n            logger.info(\"Setting up the sphere...\")\n            surf = dict(R=sphere[3], r0=sphere[:3])\n        # Make the grid of sources in MRI space\n        sp = _make_volume_source_space(\n            surf,\n            pos,\n            exclude,\n            mindist,\n            mri,\n            volume_label,\n            n_jobs=n_jobs,\n            vol_info=vol_info,\n            single_volume=single_volume,\n        )\n    del sphere\n    assert isinstance(sp, list)\n    assert (\n        len(sp) == 1 if (volume_label is None or single_volume) else len(volume_label)\n    )\n\n    # Compute an interpolation matrix to show data in MRI_VOXEL coord frame\n    if mri is not None:\n        if add_interpolator:\n            _add_interpolator(sp)\n    elif sp[0][\"type\"] == \"vol\":\n        # If there is no interpolator, it's actually a discrete source space\n        sp[0][\"type\"] = \"discrete\"\n\n    # do some cleaning\n    if volume_label is None and \"seg_name\" in sp[0]:\n        del sp[0][\"seg_name\"]\n    for s in sp:\n        if \"vol_dims\" in s:\n            del s[\"vol_dims\"]\n\n    # Save it\n    sp = _complete_vol_src(sp, subject)\n    return sp", "metadata": {}}
{"_id": "mne_mne_source_space/_source_space.py_add_source_space_distances_code", "title": "add_source_space_distances", "text": "def add_source_space_distances(src, dist_limit=np.inf, n_jobs=None, *, verbose=None):\n    \"\"\"Compute inter-source distances along the cortical surface.\n\n    This function will also try to add patch info for the source space.\n    It will only occur if the ``dist_limit`` is sufficiently high that all\n    points on the surface are within ``dist_limit`` of a point in the\n    source space.\n\n    Parameters\n    ----------\n    src : instance of SourceSpaces\n        The source spaces to compute distances for.\n    dist_limit : float\n        The upper limit of distances to include (in meters).\n        Note: if limit < np.inf, scipy > 0.13 (bleeding edge as of\n        10/2013) must be installed. If 0, then only patch (nearest vertex)\n        information is added.\n    %(n_jobs)s\n        Ignored if ``dist_limit==0.``.\n    %(verbose)s\n\n    Returns\n    -------\n    src : instance of SourceSpaces\n        The original source spaces, with distance information added.\n        The distances are stored in src[n]['dist'].\n        Note: this function operates in-place.\n\n    Notes\n    -----\n    This function can be memory- and CPU-intensive. On a high-end machine\n    (2012) running 6 jobs in parallel, an ico-5 (10242 per hemi) source space\n    takes about 10 minutes to compute all distances (``dist_limit = np.inf``).\n    With ``dist_limit = 0.007``, computing distances takes about 1 minute.\n\n    We recommend computing distances once per source space and then saving\n    the source space to disk, as the computed distances will automatically be\n    stored along with the source space data for future use.\n    \"\"\"\n    src = _ensure_src(src)\n    dist_limit = float(dist_limit)\n    if dist_limit < 0:\n        raise ValueError(f\"dist_limit must be non-negative, got {dist_limit}\")\n    patch_only = dist_limit == 0\n    if src.kind != \"surface\":\n        raise RuntimeError(\"Currently all source spaces must be of surface type\")\n\n    parallel, p_fun, n_jobs = parallel_func(_do_src_distances, n_jobs)\n    min_dists = list()\n    min_idxs = list()\n    msg = \"patch information\" if patch_only else \"source space distances\"\n    logger.info(f\"Calculating {msg} (limit={1000 * dist_limit} mm)...\")\n    max_n = max(s[\"nuse\"] for s in src)\n    if not patch_only and max_n > _DIST_WARN_LIMIT:\n        warn(\n            f\"Computing distances for {max_n} source space points (in one \"\n            \"hemisphere) will be very slow, consider using add_dist=False\"\n        )\n    for s in src:\n        adjacency = mesh_dist(s[\"tris\"], s[\"rr\"])\n        if patch_only:\n            min_dist, _, min_idx = dijkstra(\n                adjacency, indices=s[\"vertno\"], min_only=True, return_predecessors=True\n            )\n            min_dists.append(min_dist.astype(np.float32))\n            min_idxs.append(min_idx)\n            for key in (\"dist\", \"dist_limit\"):\n                s[key] = None\n        else:\n            d = parallel(\n                p_fun(adjacency, s[\"vertno\"], r, dist_limit)\n                for r in np.array_split(np.arange(len(s[\"vertno\"])), n_jobs)\n            )\n            # deal with indexing so we can add patch info\n            min_idx = np.array([dd[1] for dd in d])\n            min_dist = np.array([dd[2] for dd in d])\n            midx = np.argmin(min_dist, axis=0)\n            range_idx = np.arange(len(s[\"rr\"]))\n            min_dist = min_dist[midx, range_idx]\n            min_idx = min_idx[midx, range_idx]\n            min_dists.append(min_dist)\n            min_idxs.append(min_idx)\n            # convert to sparse representation\n            d = np.concatenate([dd[0] for dd in d]).ravel()  # already float32\n            idx = d > 0\n            d = d[idx]\n            i, j = np.meshgrid(s[\"vertno\"], s[\"vertno\"])\n            i = i.ravel()[idx]\n            j = j.ravel()[idx]\n            s[\"dist\"] = csr_array(\n                (d, (i, j)), shape=(s[\"np\"], s[\"np\"]), dtype=np.float32\n            )\n            s[\"dist_limit\"] = np.array([dist_limit], np.float32)\n\n    # Let's see if our distance was sufficient to allow for patch info\n    if not any(np.any(np.isinf(md)) for md in min_dists):\n        # Patch info can be added!\n        for s, min_dist, min_idx in zip(src, min_dists, min_idxs):\n            s[\"nearest\"] = min_idx\n            s[\"nearest_dist\"] = min_dist\n            _add_patch_info(s)\n    else:\n        logger.info(\"Not adding patch information, dist_limit too small\")\n    return src", "metadata": {}}
{"_id": "mne_mne_source_space/_source_space.py_get_volume_labels_from_src_code", "title": "get_volume_labels_from_src", "text": "def get_volume_labels_from_src(src, subject, subjects_dir):\n    \"\"\"Return a list of Label of segmented volumes included in the src space.\n\n    Parameters\n    ----------\n    src : instance of SourceSpaces\n        The source space containing the volume regions.\n    %(subject)s\n    subjects_dir : str\n        Freesurfer folder of the subjects.\n\n    Returns\n    -------\n    labels_aseg : list of Label\n        List of Label of segmented volumes included in src space.\n    \"\"\"\n    from ..label import Label\n\n    # Read the aseg file\n    aseg_fname = op.join(subjects_dir, subject, \"mri\", \"aseg.mgz\")\n    all_labels_aseg = get_volume_labels_from_aseg(aseg_fname, return_colors=True)\n\n    # Create a list of Label\n    if len(src) < 2:\n        raise ValueError(\"No vol src space in src\")\n\n    if any(np.any(s[\"type\"] != \"vol\") for s in src[2:]):\n        raise ValueError(\"source spaces have to be of vol type\")\n\n    labels_aseg = list()\n    for nr in range(2, len(src)):\n        vertices = src[nr][\"vertno\"]\n\n        pos = src[nr][\"rr\"][src[nr][\"vertno\"], :]\n        roi_str = src[nr][\"seg_name\"]\n        try:\n            ind = all_labels_aseg[0].index(roi_str)\n            color = np.array(all_labels_aseg[1][ind]) / 255\n        except ValueError:\n            pass\n\n        if \"left\" in roi_str.lower():\n            hemi = \"lh\"\n            roi_str = roi_str.replace(\"Left-\", \"\") + \"-lh\"\n        elif \"right\" in roi_str.lower():\n            hemi = \"rh\"\n            roi_str = roi_str.replace(\"Right-\", \"\") + \"-rh\"\n        else:\n            hemi = \"both\"\n\n        label = Label(\n            vertices=vertices,\n            pos=pos,\n            hemi=hemi,\n            name=roi_str,\n            color=color,\n            subject=subject,\n        )\n        labels_aseg.append(label)\n\n    return labels_aseg", "metadata": {}}
{"_id": "mne_mne_source_space/_source_space.py_morph_source_spaces_code", "title": "morph_source_spaces", "text": "def morph_source_spaces(\n    src_from,\n    subject_to,\n    surf=\"white\",\n    subject_from=None,\n    subjects_dir=None,\n    verbose=None,\n):\n    \"\"\"Morph an existing source space to a different subject.\n\n    .. warning:: This can be used in place of morphing source estimates for\n                 multiple subjects, but there may be consequences in terms\n                 of dipole topology.\n\n    Parameters\n    ----------\n    src_from : instance of SourceSpaces\n        Surface source spaces to morph.\n    subject_to : str\n        The destination subject.\n    surf : str\n        The brain surface to use for the new source space.\n    subject_from : str | None\n        The \"from\" subject. For most source spaces this shouldn't need\n        to be provided, since it is stored in the source space itself.\n    subjects_dir : path-like | None\n        Path to ``SUBJECTS_DIR`` if it is not set in the environment.\n    %(verbose)s\n\n    Returns\n    -------\n    src : instance of SourceSpaces\n        The morphed source spaces.\n\n    Notes\n    -----\n    .. versionadded:: 0.10.0\n    \"\"\"\n    # adapted from mne_make_source_space.c\n    src_from = _ensure_src(src_from)\n    subject_from = _ensure_src_subject(src_from, subject_from)\n    subjects_dir = get_subjects_dir(subjects_dir, raise_error=True)\n    src_out = list()\n    for fro in src_from:\n        hemi, idx, id_ = _get_hemi(fro)\n        to = subjects_dir / subject_to / \"surf\" / f\"{hemi}.{surf}\"\n        logger.info(f\"Reading destination surface {to}\")\n        to = read_surface(to, return_dict=True, verbose=False)[-1]\n        complete_surface_info(to, copy=False)\n        # Now we morph the vertices to the destination\n        # The C code does something like this, but with a nearest-neighbor\n        # mapping instead of the weighted one::\n        #\n        #     >>> mm = read_morph_map(subject_from, subject_to, subjects_dir)\n        #\n        # Here we use a direct NN calculation, since picking the max from the\n        # existing morph map (which naively one might expect to be equivalent)\n        # differs for ~3% of vertices.\n        best = _get_vertex_map_nn(\n            fro, subject_from, subject_to, hemi, subjects_dir, to[\"neighbor_tri\"]\n        )\n        for key in (\"neighbor_tri\", \"tri_area\", \"tri_cent\", \"tri_nn\", \"use_tris\"):\n            del to[key]\n        to[\"vertno\"] = np.sort(best[fro[\"vertno\"]])\n        to[\"inuse\"] = np.zeros(len(to[\"rr\"]), int)\n        to[\"inuse\"][to[\"vertno\"]] = True\n        to[\"use_tris\"] = best[fro[\"use_tris\"]]\n        to.update(\n            nuse=len(to[\"vertno\"]),\n            nuse_tri=len(to[\"use_tris\"]),\n            nearest=None,\n            nearest_dist=None,\n            patch_inds=None,\n            pinfo=None,\n            dist=None,\n            id=id_,\n            dist_limit=None,\n            type=\"surf\",\n            coord_frame=FIFF.FIFFV_COORD_MRI,\n            subject_his_id=subject_to,\n            rr=to[\"rr\"] / 1000.0,\n        )\n        src_out.append(to)\n        logger.info(\"[done]\\n\")\n    info = dict(working_dir=os.getcwd(), command_line=_get_call_line())\n    return SourceSpaces(src_out, info=info)", "metadata": {}}
{"_id": "mne_mne_source_space/_source_space.py_compute_distance_to_sensors_code", "title": "compute_distance_to_sensors", "text": "def compute_distance_to_sensors(src, info, picks=None, trans=None, verbose=None):\n    \"\"\"Compute distances between vertices and sensors.\n\n    Parameters\n    ----------\n    src : instance of SourceSpaces\n        The object with vertex positions for which to compute distances to\n        sensors.\n    %(info)s Must contain sensor positions to which distances shall\n        be computed.\n    %(picks_good_data)s\n    %(trans_not_none)s\n    %(verbose)s\n\n    Returns\n    -------\n    depth : array of shape (n_vertices, n_channels)\n        The Euclidean distances of source space vertices with respect to\n        sensors.\n    \"\"\"\n    assert isinstance(src, SourceSpaces)\n    _validate_type(info, (Info,), \"info\")\n\n    # Load the head<->MRI transform if necessary\n    if src[0][\"coord_frame\"] == FIFF.FIFFV_COORD_MRI:\n        src_trans, _ = _get_trans(trans, allow_none=False)\n    else:\n        src_trans = Transform(\"head\", \"head\")  # Identity transform\n\n    # get vertex position in same coordinates as for sensors below\n    src_pos = np.vstack(\n        [apply_trans(src_trans, s[\"rr\"][s[\"inuse\"].astype(bool)]) for s in src]\n    )\n\n    # Select channels to be used for distance calculations\n    picks = _picks_to_idx(info, picks, \"data\", exclude=())\n    # get sensor positions\n    sensor_pos = []\n    dev_to_head = None\n    for ch in picks:\n        # MEG channels are in device coordinates, translate them to head\n        if channel_type(info, ch) in [\"mag\", \"grad\"]:\n            if dev_to_head is None:\n                dev_to_head = _ensure_trans(info[\"dev_head_t\"], \"meg\", \"head\")\n            sensor_pos.append(apply_trans(dev_to_head, info[\"chs\"][ch][\"loc\"][:3]))\n        else:\n            sensor_pos.append(info[\"chs\"][ch][\"loc\"][:3])\n    sensor_pos = np.array(sensor_pos)\n\n    depths = cdist(src_pos, sensor_pos)\n\n    return depths", "metadata": {}}
{"_id": "mne_mne_source_space/_source_space.py_get_decimated_surfaces_code", "title": "get_decimated_surfaces", "text": "def get_decimated_surfaces(src):\n    \"\"\"Get the decimated surfaces from a source space.\n\n    Parameters\n    ----------\n    src : instance of SourceSpaces | path-like\n        The source space with decimated surfaces.\n\n    Returns\n    -------\n    surfaces : list of dict\n        The decimated surfaces present in the source space. Each dict\n        which contains 'rr' and 'tris' keys for vertices positions and\n        triangle indices.\n\n    Notes\n    -----\n    .. versionadded:: 1.0\n    \"\"\"\n    src = _ensure_src(src)\n    surfaces = []\n    for s in src:\n        if s[\"type\"] != \"surf\":\n            continue\n        rr = s[\"rr\"]\n        use_tris = s[\"use_tris\"]\n        vertno = s[\"vertno\"]\n        ss = {}\n        ss[\"rr\"] = rr[vertno]\n        reindex = np.full(len(rr), -1, int)\n        reindex[vertno] = np.arange(len(vertno))\n        ss[\"tris\"] = reindex[use_tris]\n        assert (ss[\"tris\"] >= 0).all()\n        surfaces.append(ss)\n    return surfaces", "metadata": {}}
{"_id": "mne_mne_source_space/_source_space.py_plot_code", "title": "plot", "text": "def plot(\n        self,\n        head=False,\n        brain=None,\n        skull=None,\n        subjects_dir=None,\n        trans=None,\n        verbose=None,\n    ):\n        \"\"\"Plot the source space.\n\n        Parameters\n        ----------\n        head : bool\n            If True, show head surface.\n        brain : bool | str\n            If True, show the brain surfaces. Can also be a str for\n            surface type (e.g., ``'pial'``, same as True). Default is None,\n            which means ``'white'`` for surface source spaces and ``False``\n            otherwise.\n        skull : bool | str | list of str | list of dict | None\n            Whether to plot skull surface. If string, common choices would be\n            ``'inner_skull'``, or ``'outer_skull'``. Can also be a list to plot\n            multiple skull surfaces. If a list of dicts, each dict must\n            contain the complete surface info (such as you get from\n            :func:`mne.make_bem_model`). True is an alias of 'outer_skull'.\n            The subjects bem and bem/flash folders are searched for the 'surf'\n            files. Defaults to None, which is False for surface source spaces,\n            and True otherwise.\n        subjects_dir : path-like | None\n            Path to ``SUBJECTS_DIR`` if it is not set in the environment.\n        trans : path-like | ``'auto'`` | dict | None\n            The full path to the head<->MRI transform ``*-trans.fif`` file\n            produced during coregistration. If trans is None, an identity\n            matrix is assumed. This is only needed when the source space is in\n            head coordinates.\n        %(verbose)s\n\n        Returns\n        -------\n        fig : instance of Figure3D\n            The figure.\n        \"\"\"\n        surfaces = list()\n        bem = None\n\n        if brain is None:\n            brain = \"white\" if any(ss[\"type\"] == \"surf\" for ss in self) else False\n\n        if isinstance(brain, str):\n            surfaces.append(brain)\n        elif brain:\n            surfaces.append(\"brain\")\n\n        if skull is None:\n            skull = False if self.kind == \"surface\" else True\n\n        if isinstance(skull, str):\n            surfaces.append(skull)\n        elif skull is True:\n            surfaces.append(\"outer_skull\")\n        elif skull is not False:  # list\n            if isinstance(skull[0], dict):  # bem\n                skull_map = {\n                    FIFF.FIFFV_BEM_SURF_ID_BRAIN: \"inner_skull\",\n                    FIFF.FIFFV_BEM_SURF_ID_SKULL: \"outer_skull\",\n                    FIFF.FIFFV_BEM_SURF_ID_HEAD: \"outer_skin\",\n                }\n                for this_skull in skull:\n                    surfaces.append(skull_map[this_skull[\"id\"]])\n                bem = skull\n            else:  # list of str\n                for surf in skull:\n                    surfaces.append(surf)\n\n        if head:\n            surfaces.append(\"head\")\n\n        if self[0][\"coord_frame\"] == FIFF.FIFFV_COORD_HEAD:\n            coord_frame = \"head\"\n            if trans is None:\n                raise ValueError(\n                    \"Source space is in head coordinates, but no \"\n                    \"head<->MRI transform was given. Please \"\n                    \"specify the full path to the appropriate \"\n                    '*-trans.fif file as the \"trans\" parameter.'\n                )\n        else:\n            coord_frame = \"mri\"\n\n        info = create_info(0, 1000.0, \"eeg\")\n\n        return plot_alignment(\n            info,\n            trans=trans,\n            subject=self._subject,\n            subjects_dir=subjects_dir,\n            surfaces=surfaces,\n            coord_frame=coord_frame,\n            meg=(),\n            eeg=False,\n            dig=False,\n            ecog=False,\n            bem=bem,\n            src=self,\n        )", "metadata": {}}
{"_id": "mne_mne_source_space/_source_space.py_copy_code", "title": "copy", "text": "def copy(self):\n        \"\"\"Make a copy of the source spaces.\n\n        Returns\n        -------\n        src : instance of SourceSpaces\n            The copied source spaces.\n        \"\"\"\n        return deepcopy(self)", "metadata": {}}
{"_id": "mne_mne_source_space/_source_space.py_save_code", "title": "save", "text": "def save(self, fname, overwrite=False, *, verbose=None):\n        \"\"\"Save the source spaces to a fif file.\n\n        Parameters\n        ----------\n        fname : path-like\n            File to write, which should end with ``-src.fif`` or ``-src.fif.gz``.\n        %(overwrite)s\n        %(verbose)s\n        \"\"\"\n        write_source_spaces(fname, self, overwrite=overwrite)", "metadata": {}}
{"_id": "mne_mne_source_space/_source_space.py_export_volume_code", "title": "export_volume", "text": "def export_volume(\n        self,\n        fname,\n        include_surfaces=True,\n        include_discrete=True,\n        dest=\"mri\",\n        trans=None,\n        mri_resolution=False,\n        use_lut=True,\n        overwrite=False,\n        verbose=None,\n    ):\n        \"\"\"Export source spaces to nifti or mgz file.\n\n        Parameters\n        ----------\n        fname : path-like\n            Name of nifti or mgz file to write.\n        include_surfaces : bool\n            If True, include surface source spaces.\n        include_discrete : bool\n            If True, include discrete source spaces.\n        dest : ``'mri'`` | ``'surf'``\n            If ``'mri'`` the volume is defined in the coordinate system of the\n            original T1 image. If ``'surf'`` the coordinate system of the\n            FreeSurfer surface is used (Surface RAS).\n        trans : dict, str, or None\n            Either a transformation filename (usually made using mne_analyze)\n            or an info dict (usually opened using read_trans()). If string, an\n            ending of ``.fif`` or ``.fif.gz`` will be assumed to be in FIF\n            format, any other ending will be assumed to be a text file with a\n            4x4 transformation matrix (like the ``--trans`` MNE-C option.\n            Must be provided if source spaces are in head coordinates and\n            include_surfaces and mri_resolution are True.\n        mri_resolution : bool | str\n            If True, the image is saved in MRI resolution\n            (e.g. 256 x 256 x 256), and each source region (surface or\n            segmentation volume) filled in completely. If \"sparse\", only a\n            single voxel in the high-resolution MRI is filled in for each\n            source point.\n\n            .. versionchanged:: 0.21.0\n               Support for ``\"sparse\"`` was added.\n        use_lut : bool\n            If True, assigns a numeric value to each source space that\n            corresponds to a color on the freesurfer lookup table.\n        %(overwrite)s\n\n            .. versionadded:: 0.19\n        %(verbose)s\n\n        Notes\n        -----\n        This method requires nibabel.\n        \"\"\"\n        _check_fname(fname, overwrite)\n        _validate_type(mri_resolution, (bool, str), \"mri_resolution\")\n        if isinstance(mri_resolution, str):\n            _check_option(\n                \"mri_resolution\",\n                mri_resolution,\n                [\"sparse\"],\n                extra=\"when mri_resolution is a string\",\n            )\n        else:\n            mri_resolution = bool(mri_resolution)\n        fname = str(fname)\n        nib = _import_nibabel()\n\n        # Check coordinate frames of each source space\n        coord_frames = np.array([s[\"coord_frame\"] for s in self])\n\n        # Raise error if trans is not provided when head coordinates are used\n        # and mri_resolution and include_surfaces are true\n        if (coord_frames == FIFF.FIFFV_COORD_HEAD).all():\n            coords = \"head\"  # all sources in head coordinates\n            if mri_resolution and include_surfaces:\n                if trans is None:\n                    raise ValueError(\n                        \"trans containing mri to head transform \"\n                        \"must be provided if mri_resolution and \"\n                        \"include_surfaces are true and surfaces \"\n                        \"are in head coordinates\"\n                    )\n\n            elif trans is not None:\n                logger.info(\n                    \"trans is not needed and will not be used unless \"\n                    \"include_surfaces and mri_resolution are True.\"\n                )\n\n        elif (coord_frames == FIFF.FIFFV_COORD_MRI).all():\n            coords = \"mri\"  # all sources in mri coordinates\n            if trans is not None:\n                logger.info(\n                    \"trans is not needed and will not be used unless \"\n                    \"sources are in head coordinates.\"\n                )\n        # Raise error if all sources are not in the same space, or sources are\n        # not in mri or head coordinates\n        else:\n            raise ValueError(\n                \"All sources must be in head coordinates or all \"\n                \"sources must be in mri coordinates.\"\n            )\n\n        # use lookup table to assign values to source spaces\n        logger.info(\"Reading FreeSurfer lookup table\")\n        # read the lookup table\n        lut, _ = read_freesurfer_lut()\n\n        # Setup a dictionary of source types\n        src_types = dict(volume=[], surface_discrete=[])\n\n        # Populate dictionary of source types\n        for src in self:\n            # volume sources\n            if src[\"type\"] == \"vol\":\n                src_types[\"volume\"].append(src)\n            # surface and discrete sources\n            elif src[\"type\"] in (\"surf\", \"discrete\"):\n                src_types[\"surface_discrete\"].append(src)\n            else:\n                raise ValueError(f\"Unrecognized source type: {src['type']}.\")\n\n        # Raise error if there are no volume source spaces\n        if len(src_types[\"volume\"]) == 0:\n            raise ValueError(\"Source spaces must contain at least one volume.\")\n\n        # Get shape, inuse array and interpolation matrix from volume sources\n        src = src_types[\"volume\"][0]\n        aseg_data = None\n        if mri_resolution:\n            # read the mri file used to generate volumes\n            if mri_resolution is True:\n                aseg_data = _get_img_fdata(nib.load(src[\"mri_file\"]))\n            # get the voxel space shape\n            shape3d = (src[\"mri_width\"], src[\"mri_depth\"], src[\"mri_height\"])\n        else:\n            # get the volume source space shape\n            # read the shape in reverse order\n            # (otherwise results are scrambled)\n            shape3d = src[\"shape\"]\n\n        # calculate affine transform for image (MRI_VOXEL to RAS)\n        if mri_resolution:\n            # MRI_VOXEL to MRI transform\n            transform = src[\"vox_mri_t\"]\n        else:\n            # MRI_VOXEL to MRI transform\n            # NOTE: 'src' indicates downsampled version of MRI_VOXEL\n            transform = src[\"src_mri_t\"]\n\n        # Figure out how to get from our input source space to output voxels\n        fro_dst_t = invert_transform(transform)\n        if coords == \"head\":\n            head_mri_t = _get_trans(trans, \"head\", \"mri\")[0]\n            fro_dst_t = combine_transforms(\n                head_mri_t, fro_dst_t, \"head\", transform[\"to\"]\n            )\n        else:\n            fro_dst_t = fro_dst_t\n\n        # Fill in the volumes\n        img = np.zeros(shape3d)\n        for ii, vs in enumerate(src_types[\"volume\"]):\n            # read the lookup table value for segmented volume\n            if \"seg_name\" not in vs:\n                raise ValueError(\n                    \"Volume sources should be segments, not the entire volume.\"\n                )\n            # find the color value for this volume\n            use_id = 1.0\n            if mri_resolution is True or use_lut:\n                id_ = lut[vs[\"seg_name\"]]\n                if use_lut:\n                    use_id = id_\n\n            if mri_resolution == \"sparse\":\n                idx = apply_trans(fro_dst_t, vs[\"rr\"][vs[\"vertno\"]])\n                idx = tuple(idx.round().astype(int).T)\n            elif mri_resolution is True:  # fill the represented vol\n                # get the values for this volume\n                idx = aseg_data == id_\n            else:\n                assert mri_resolution is False\n                idx = vs[\"inuse\"].reshape(shape3d, order=\"F\").astype(bool)\n            img[idx] = use_id\n\n        # loop through the surface and discrete source spaces\n\n        # get the surface names (assumes left, right order. may want\n        # to add these names during source space generation\n        for src in src_types[\"surface_discrete\"]:\n            val = 1\n            if src[\"type\"] == \"surf\":\n                if not include_surfaces:\n                    continue\n                if use_lut:\n                    surf_name = {\n                        FIFF.FIFFV_MNE_SURF_LEFT_HEMI: \"Left\",\n                        FIFF.FIFFV_MNE_SURF_RIGHT_HEMI: \"Right\",\n                    }[src[\"id\"]] + \"-Cerebral-Cortex\"\n                    val = lut[surf_name]\n            else:\n                assert src[\"type\"] == \"discrete\"\n                if not include_discrete:\n                    continue\n                if use_lut:\n                    logger.info(\n                        \"Discrete sources do not have values on \"\n                        \"the lookup table. Defaulting to 1.\"\n                    )\n            # convert vertex positions from their native space\n            # (either HEAD or MRI) to MRI_VOXEL space\n            if mri_resolution is True:\n                use_rr = src[\"rr\"]\n            else:\n                assert mri_resolution is False or mri_resolution == \"sparse\"\n                use_rr = src[\"rr\"][src[\"vertno\"]]\n            srf_vox = apply_trans(fro_dst_t[\"trans\"], use_rr)\n            # convert to numeric indices\n            ix_, iy_, iz_ = srf_vox.T.round().astype(int)\n            # clip indices outside of volume space\n            ix = (np.clip(ix_, 0, shape3d[0] - 1),)\n            iy = np.clip(iy_, 0, shape3d[1] - 1)\n            iz = np.clip(iz_, 0, shape3d[2] - 1)\n            # compare original and clipped indices\n            n_diff = ((ix_ != ix) | (iy_ != iy) | (iz_ != iz)).sum()\n            # generate use warnings for clipping\n            if n_diff > 0:\n                warn(\n                    f\"{n_diff} {src['type']} vertices lay outside of volume \"\n                    f\"space. Consider using a larger volume space.\"\n                )\n            # get surface id or use default value\n            # update image to include surface voxels\n            img[ix, iy, iz] = val\n\n        if dest == \"mri\":\n            # combine with MRI to RAS transform\n            transform = combine_transforms(\n                transform, vs[\"mri_ras_t\"], transform[\"from\"], vs[\"mri_ras_t\"][\"to\"]\n            )\n        # now setup the affine for volume image\n        affine = transform[\"trans\"].copy()\n        # make sure affine converts from m to mm\n        affine[:3] *= 1e3\n\n        # setup image for file\n        if fname.endswith((\".nii\", \".nii.gz\")):  # save as nifit\n            # setup the nifti header\n            hdr = nib.Nifti1Header()\n            hdr.set_xyzt_units(\"mm\")\n            # save the nifti image\n            img = nib.Nifti1Image(img, affine, header=hdr)\n        elif fname.endswith(\".mgz\"):  # save as mgh\n            # convert to float32 (float64 not currently supported)\n            img = img.astype(\"float32\")\n            # save the mgh image\n            img = nib.freesurfer.mghformat.MGHImage(img, affine)\n        else:\n            raise ValueError(\"Unrecognized file extension\")\n\n        # write image to file\n        nib.save(img, fname)", "metadata": {}}
{"_id": "mne_mne_forward/forward.py_read_forward_solution_code", "title": "read_forward_solution", "text": "def read_forward_solution(fname, include=(), exclude=(), *, ordered=True, verbose=None):\n    \"\"\"Read a forward solution a.k.a. lead field.\n\n    Parameters\n    ----------\n    fname : path-like\n        The file name, which should end with ``-fwd.fif``, ``-fwd.fif.gz``,\n        ``_fwd.fif``, ``_fwd.fif.gz``, ``-fwd.h5``, or ``_fwd.h5``.\n    include : list, optional\n        List of names of channels to include. If empty all channels\n        are included.\n    exclude : list, optional\n        List of names of channels to exclude. If empty include all channels.\n    %(ordered)s\n    %(verbose)s\n\n    Returns\n    -------\n    fwd : instance of Forward\n        The forward solution.\n\n    See Also\n    --------\n    write_forward_solution, make_forward_solution\n\n    Notes\n    -----\n    Forward solutions, which are derived from an original forward solution with\n    free orientation, are always stored on disk as forward solution with free\n    orientation in X/Y/Z RAS coordinates. To apply any transformation to the\n    forward operator (surface orientation, fixed orientation) please apply\n    :func:`convert_forward_solution` after reading the forward solution with\n    :func:`read_forward_solution`.\n\n    Forward solutions, which are derived from an original forward solution with\n    fixed orientation, are stored on disk as forward solution with fixed\n    surface-based orientations. Please note that the transformation to\n    surface-based, fixed orientation cannot be reverted after loading the\n    forward solution with :func:`read_forward_solution`.\n    \"\"\"\n    check_fname(\n        fname,\n        \"forward\",\n        (\"-fwd.fif\", \"-fwd.fif.gz\", \"_fwd.fif\", \"_fwd.fif.gz\", \"-fwd.h5\", \"_fwd.h5\"),\n    )\n    fname = _check_fname(fname=fname, must_exist=True, overwrite=\"read\")\n    #   Open the file, create directory\n    logger.info(f\"Reading forward solution from {fname}...\")\n    if fname.suffix == \".h5\":\n        return _read_forward_hdf5(fname)\n    f, tree, _ = fiff_open(fname)\n    with f as fid:\n        #   Find all forward solutions\n        fwds = dir_tree_find(tree, FIFF.FIFFB_MNE_FORWARD_SOLUTION)\n        if len(fwds) == 0:\n            raise ValueError(f\"No forward solutions in {fname}\")\n\n        #   Parent MRI data\n        parent_mri = dir_tree_find(tree, FIFF.FIFFB_MNE_PARENT_MRI_FILE)\n        if len(parent_mri) == 0:\n            raise ValueError(f\"No parent MRI information in {fname}\")\n        parent_mri = parent_mri[0]\n\n        src = _read_source_spaces_from_tree(fid, tree, patch_stats=False)\n        for s in src:\n            s[\"id\"] = find_source_space_hemi(s)\n\n        fwd = None\n\n        #   Locate and read the forward solutions\n        megnode = None\n        eegnode = None\n        for k in range(len(fwds)):\n            tag = find_tag(fid, fwds[k], FIFF.FIFF_MNE_INCLUDED_METHODS)\n            if tag is None:\n                raise ValueError(\"Methods not listed for one of the forward solutions\")\n\n            if tag.data == FIFF.FIFFV_MNE_MEG:\n                megnode = fwds[k]\n            elif tag.data == FIFF.FIFFV_MNE_EEG:\n                eegnode = fwds[k]\n\n        fwds = dict()\n        megfwd = _read_one(fid, megnode)\n        if megfwd is not None:\n            fwds[\"meg\"] = megfwd\n            if is_fixed_orient(megfwd):\n                ori = \"fixed\"\n            else:\n                ori = \"free\"\n            logger.info(\n                \"    Read MEG forward solution (%d sources, \"\n                \"%d channels, %s orientations)\",\n                megfwd[\"nsource\"],\n                megfwd[\"nchan\"],\n                ori,\n            )\n        del megfwd\n\n        eegfwd = _read_one(fid, eegnode)\n        if eegfwd is not None:\n            fwds[\"eeg\"] = eegfwd\n            if is_fixed_orient(eegfwd):\n                ori = \"fixed\"\n            else:\n                ori = \"free\"\n            logger.info(\n                \"    Read EEG forward solution (%d sources, \"\n                \"%d channels, %s orientations)\",\n                eegfwd[\"nsource\"],\n                eegfwd[\"nchan\"],\n                ori,\n            )\n        del eegfwd\n\n        fwd = _merge_fwds(fwds)\n        del fwds\n\n        #   Get the MRI <-> head coordinate transformation\n        tag = find_tag(fid, parent_mri, FIFF.FIFF_COORD_TRANS)\n        if tag is None:\n            raise ValueError(\"MRI/head coordinate transformation not found\")\n        mri_head_t = tag.data\n        if (\n            mri_head_t[\"from\"] != FIFF.FIFFV_COORD_MRI\n            or mri_head_t[\"to\"] != FIFF.FIFFV_COORD_HEAD\n        ):\n            mri_head_t = invert_transform(mri_head_t)\n            if (\n                mri_head_t[\"from\"] != FIFF.FIFFV_COORD_MRI\n                or mri_head_t[\"to\"] != FIFF.FIFFV_COORD_HEAD\n            ):\n                fid.close()\n                raise ValueError(\"MRI/head coordinate transformation not found\")\n        fwd[\"mri_head_t\"] = mri_head_t\n\n        #\n        # get parent MEG info\n        #\n        fwd[\"info\"] = _read_forward_meas_info(tree, fid)\n\n        # MNE environment\n        parent_env = dir_tree_find(tree, FIFF.FIFFB_MNE_ENV)\n        if len(parent_env) > 0:\n            parent_env = parent_env[0]\n            tag = find_tag(fid, parent_env, FIFF.FIFF_MNE_ENV_WORKING_DIR)\n            if tag is not None:\n                with fwd[\"info\"]._unlock():\n                    fwd[\"info\"][\"working_dir\"] = tag.data\n            tag = find_tag(fid, parent_env, FIFF.FIFF_MNE_ENV_COMMAND_LINE)\n            if tag is not None:\n                with fwd[\"info\"]._unlock():\n                    fwd[\"info\"][\"command_line\"] = tag.data\n\n    #   Transform the source spaces to the correct coordinate frame\n    #   if necessary\n\n    # Make sure forward solution is in either the MRI or HEAD coordinate frame\n    if fwd[\"coord_frame\"] not in (FIFF.FIFFV_COORD_MRI, FIFF.FIFFV_COORD_HEAD):\n        raise ValueError(\n            \"Only forward solutions computed in MRI or head coordinates are acceptable\"\n        )\n\n    # Transform each source space to the HEAD or MRI coordinate frame,\n    # depending on the coordinate frame of the forward solution\n    # NOTE: the function transform_surface_to will also work on discrete and\n    # volume sources\n    nuse = 0\n    for s in src:\n        try:\n            s = transform_surface_to(s, fwd[\"coord_frame\"], mri_head_t)\n        except Exception as inst:\n            raise ValueError(f\"Could not transform source space ({inst})\")\n\n        nuse += s[\"nuse\"]\n\n    # Make sure the number of sources match after transformation\n    if nuse != fwd[\"nsource\"]:\n        raise ValueError(\"Source spaces do not match the forward solution.\")\n\n    logger.info(\n        \"    Source spaces transformed to the forward solution coordinate frame\"\n    )\n    fwd[\"src\"] = src\n\n    #   Handle the source locations and orientations\n    fwd[\"source_rr\"] = np.concatenate([ss[\"rr\"][ss[\"vertno\"], :] for ss in src], axis=0)\n\n    #   Store original source orientations\n    fwd[\"_orig_source_ori\"] = fwd[\"source_ori\"]\n\n    #   Deal with include and exclude\n    pick_channels_forward(fwd, include=include, exclude=exclude, copy=False)\n\n    if is_fixed_orient(fwd, orig=True):\n        fwd[\"source_nn\"] = np.concatenate(\n            [_src[\"nn\"][_src[\"vertno\"], :] for _src in fwd[\"src\"]], axis=0\n        )\n        fwd[\"source_ori\"] = FIFF.FIFFV_MNE_FIXED_ORI\n        fwd[\"surf_ori\"] = True\n    else:\n        fwd[\"source_nn\"] = np.kron(np.ones((fwd[\"nsource\"], 1)), np.eye(3))\n        fwd[\"source_ori\"] = FIFF.FIFFV_MNE_FREE_ORI\n        fwd[\"surf_ori\"] = False\n    return Forward(fwd)", "metadata": {}}
{"_id": "mne_mne_forward/forward.py_convert_forward_solution_code", "title": "convert_forward_solution", "text": "def convert_forward_solution(\n    fwd, surf_ori=False, force_fixed=False, copy=True, use_cps=True, *, verbose=None\n):\n    \"\"\"Convert forward solution between different source orientations.\n\n    Parameters\n    ----------\n    fwd : Forward\n        The forward solution to modify.\n    surf_ori : bool, optional (default False)\n        Use surface-based source coordinate system? Note that force_fixed=True\n        implies surf_ori=True.\n    force_fixed : bool, optional (default False)\n        If True, force fixed source orientation mode.\n    copy : bool\n        Whether to return a new instance or modify in place.\n    %(use_cps)s\n    %(verbose)s\n\n    Returns\n    -------\n    fwd : Forward\n        The modified forward solution.\n    \"\"\"\n    fwd = fwd.copy() if copy else fwd\n\n    if force_fixed is True:\n        surf_ori = True\n\n    if any([src[\"type\"] == \"vol\" for src in fwd[\"src\"]]) and force_fixed:\n        raise ValueError(\n            \"Forward operator was generated with sources from a \"\n            \"volume source space. Conversion to fixed orientation is not \"\n            \"possible. Consider using a discrete source space if you have \"\n            \"meaningful normal orientations.\"\n        )\n\n    if surf_ori and use_cps:\n        if any(s.get(\"patch_inds\") is not None for s in fwd[\"src\"]):\n            logger.info(\n                \"    Average patch normals will be employed in \"\n                \"the rotation to the local surface coordinates..\"\n                \"..\"\n            )\n        else:\n            use_cps = False\n            logger.info(\n                \"    No patch info available. The standard source \"\n                \"space normals will be employed in the rotation \"\n                \"to the local surface coordinates....\"\n            )\n\n    # We need to change these entries (only):\n    # 1. source_nn\n    # 2. sol['data']\n    # 3. sol['ncol']\n    # 4. sol_grad['data']\n    # 5. sol_grad['ncol']\n    # 6. source_ori\n\n    if is_fixed_orient(fwd, orig=True) or (force_fixed and not use_cps):\n        # Fixed\n        fwd[\"source_nn\"] = np.concatenate(\n            [_get_src_nn(s, use_cps) for s in fwd[\"src\"]], axis=0\n        )\n        if not is_fixed_orient(fwd, orig=True):\n            logger.info(\n                \"    Changing to fixed-orientation forward \"\n                \"solution with surface-based source orientations...\"\n            )\n            fix_rot = _block_diag(fwd[\"source_nn\"].T, 1)\n            # newer versions of numpy require explicit casting here, so *= no\n            # longer works\n            fwd[\"sol\"][\"data\"] = (fwd[\"_orig_sol\"] @ fix_rot).astype(\"float32\")\n            fwd[\"sol\"][\"ncol\"] = fwd[\"nsource\"]\n            if fwd[\"sol_grad\"] is not None:\n                x = sparse.block_diag([fix_rot] * 3)\n                fwd[\"sol_grad\"][\"data\"] = fwd[\"_orig_sol_grad\"] @ x\n                fwd[\"sol_grad\"][\"ncol\"] = 3 * fwd[\"nsource\"]\n        fwd[\"source_ori\"] = FIFF.FIFFV_MNE_FIXED_ORI\n        fwd[\"surf_ori\"] = True\n\n    elif surf_ori:  # Free, surf-oriented\n        #   Rotate the local source coordinate systems\n        fwd[\"source_nn\"] = np.kron(np.ones((fwd[\"nsource\"], 1)), np.eye(3))\n        logger.info(\"    Converting to surface-based source orientations...\")\n        #   Actually determine the source orientations\n        pp = 0\n        for s in fwd[\"src\"]:\n            if s[\"type\"] in [\"surf\", \"discrete\"]:\n                nn = _get_src_nn(s, use_cps)\n                stop = pp + 3 * s[\"nuse\"]\n                fwd[\"source_nn\"][pp:stop] = _normal_orth(nn).reshape(-1, 3)\n                pp = stop\n                del nn\n            else:\n                pp += 3 * s[\"nuse\"]\n\n        #   Rotate the solution components as well\n        if force_fixed:\n            fwd[\"source_nn\"] = fwd[\"source_nn\"][2::3, :]\n            fix_rot = _block_diag(fwd[\"source_nn\"].T, 1)\n            # newer versions of numpy require explicit casting here, so *= no\n            # longer works\n            fwd[\"sol\"][\"data\"] = (fwd[\"_orig_sol\"] @ fix_rot).astype(\"float32\")\n            fwd[\"sol\"][\"ncol\"] = fwd[\"nsource\"]\n            if fwd[\"sol_grad\"] is not None:\n                x = sparse.block_diag([fix_rot] * 3)\n                fwd[\"sol_grad\"][\"data\"] = fwd[\"_orig_sol_grad\"] @ x\n                fwd[\"sol_grad\"][\"ncol\"] = 3 * fwd[\"nsource\"]\n            fwd[\"source_ori\"] = FIFF.FIFFV_MNE_FIXED_ORI\n            fwd[\"surf_ori\"] = True\n        else:\n            surf_rot = _block_diag(fwd[\"source_nn\"].T, 3)\n            fwd[\"sol\"][\"data\"] = fwd[\"_orig_sol\"] @ surf_rot\n            fwd[\"sol\"][\"ncol\"] = 3 * fwd[\"nsource\"]\n            if fwd[\"sol_grad\"] is not None:\n                x = sparse.block_diag([surf_rot] * 3)\n                fwd[\"sol_grad\"][\"data\"] = fwd[\"_orig_sol_grad\"] @ x\n                fwd[\"sol_grad\"][\"ncol\"] = 9 * fwd[\"nsource\"]\n            fwd[\"source_ori\"] = FIFF.FIFFV_MNE_FREE_ORI\n            fwd[\"surf_ori\"] = True\n\n    else:  # Free, cartesian\n        logger.info(\"    Cartesian source orientations...\")\n        fwd[\"source_nn\"] = np.tile(np.eye(3), (fwd[\"nsource\"], 1))\n        fwd[\"sol\"][\"data\"] = fwd[\"_orig_sol\"].copy()\n        fwd[\"sol\"][\"ncol\"] = 3 * fwd[\"nsource\"]\n        if fwd[\"sol_grad\"] is not None:\n            fwd[\"sol_grad\"][\"data\"] = fwd[\"_orig_sol_grad\"].copy()\n            fwd[\"sol_grad\"][\"ncol\"] = 9 * fwd[\"nsource\"]\n        fwd[\"source_ori\"] = FIFF.FIFFV_MNE_FREE_ORI\n        fwd[\"surf_ori\"] = False\n\n    logger.info(\"    [done]\")\n\n    return fwd", "metadata": {}}
{"_id": "mne_mne_forward/forward.py_write_forward_solution_code", "title": "write_forward_solution", "text": "def write_forward_solution(fname, fwd, overwrite=False, verbose=None):\n    \"\"\"Write forward solution to a file.\n\n    Parameters\n    ----------\n    %(fname_fwd)s\n    fwd : Forward\n        Forward solution.\n    %(overwrite)s\n    %(verbose)s\n\n    See Also\n    --------\n    read_forward_solution\n\n    Notes\n    -----\n    Forward solutions, which are derived from an original forward solution with\n    free orientation, are always stored on disk as forward solution with free\n    orientation in X/Y/Z RAS coordinates. Transformations (surface orientation,\n    fixed orientation) will be reverted. To reapply any transformation to the\n    forward operator please apply :func:`convert_forward_solution` after\n    reading the forward solution with :func:`read_forward_solution`.\n\n    Forward solutions, which are derived from an original forward solution with\n    fixed orientation, are stored on disk as forward solution with fixed\n    surface-based orientations. Please note that the transformation to\n    surface-based, fixed orientation cannot be reverted after loading the\n    forward solution with :func:`read_forward_solution`.\n    \"\"\"\n    check_fname(\n        fname,\n        \"forward\",\n        (\"-fwd.fif\", \"-fwd.fif.gz\", \"_fwd.fif\", \"_fwd.fif.gz\", \"-fwd.h5\", \"_fwd.h5\"),\n    )\n\n    # check for file existence and expand `~` if present\n    fname = _check_fname(fname, overwrite)\n    if fname.suffix == \".h5\":\n        _write_forward_hdf5(fname, fwd)\n    else:\n        with start_and_end_file(fname) as fid:\n            _write_forward_solution(fid, fwd)", "metadata": {}}
{"_id": "mne_mne_forward/forward.py_is_fixed_orient_code", "title": "is_fixed_orient", "text": "def is_fixed_orient(forward, orig=False):\n    \"\"\"Check if the forward operator is fixed orientation.\n\n    Parameters\n    ----------\n    forward : instance of Forward\n        The forward.\n    orig : bool\n        If True, consider the original source orientation.\n        If False (default), consider the current source orientation.\n\n    Returns\n    -------\n    fixed_ori : bool\n        Whether or not it is fixed orientation.\n    \"\"\"\n    if orig:  # if we want to know about the original version\n        fixed_ori = forward[\"_orig_source_ori\"] == FIFF.FIFFV_MNE_FIXED_ORI\n    else:  # most of the time we want to know about the current version\n        fixed_ori = forward[\"source_ori\"] == FIFF.FIFFV_MNE_FIXED_ORI\n    return fixed_ori", "metadata": {}}
{"_id": "mne_mne_forward/forward.py_write_forward_meas_info_code", "title": "write_forward_meas_info", "text": "def write_forward_meas_info(fid, info):\n    \"\"\"Write measurement info stored in forward solution.\n\n    Parameters\n    ----------\n    fid : file id\n        The file id\n    %(info_not_none)s\n    \"\"\"\n    info._check_consistency()\n    #\n    # Information from the MEG file\n    #\n    start_block(fid, FIFF.FIFFB_MNE_PARENT_MEAS_FILE)\n    write_string(fid, FIFF.FIFF_MNE_FILE_NAME, info[\"meas_file\"])\n    if info[\"meas_id\"] is not None:\n        write_id(fid, FIFF.FIFF_PARENT_BLOCK_ID, info[\"meas_id\"])\n    # get transformation from CTF and DEVICE to HEAD coordinate frame\n    meg_head_t = info.get(\"dev_head_t\", info.get(\"ctf_head_t\"))\n    if meg_head_t is None:\n        fid.close()\n        raise ValueError(\"Head<-->sensor transform not found\")\n    write_coord_trans(fid, meg_head_t)\n\n    ch_names_mapping = dict()\n    if \"chs\" in info:\n        #  Channel information\n        ch_names_mapping = _make_ch_names_mapping(info[\"chs\"])\n        write_int(fid, FIFF.FIFF_NCHAN, len(info[\"chs\"]))\n        _write_ch_infos(fid, info[\"chs\"], False, ch_names_mapping)\n    if \"bads\" in info and len(info[\"bads\"]) > 0:\n        #   Bad channels\n        _write_bad_channels(fid, info[\"bads\"], ch_names_mapping)\n\n    end_block(fid, FIFF.FIFFB_MNE_PARENT_MEAS_FILE)", "metadata": {}}
{"_id": "mne_mne_forward/forward.py_compute_orient_prior_code", "title": "compute_orient_prior", "text": "def compute_orient_prior(forward, loose=\"auto\", verbose=None):\n    \"\"\"Compute orientation prior.\n\n    Parameters\n    ----------\n    forward : instance of Forward\n        Forward operator.\n    %(loose)s\n    %(verbose)s\n\n    Returns\n    -------\n    orient_prior : ndarray, shape (n_sources,)\n        Orientation priors.\n\n    See Also\n    --------\n    compute_depth_prior\n    \"\"\"\n    _validate_type(forward, Forward, \"forward\")\n    n_sources = forward[\"sol\"][\"data\"].shape[1]\n\n    loose = _triage_loose(forward[\"src\"], loose)\n    orient_prior = np.ones(n_sources, dtype=np.float64)\n    if is_fixed_orient(forward):\n        if any(v > 0.0 for v in loose.values()):\n            raise ValueError(\n                \"loose must be 0. with forward operator \"\n                f\"with fixed orientation, got {loose}\"\n            )\n        return orient_prior\n    if all(v == 1.0 for v in loose.values()):\n        return orient_prior\n    # We actually need non-unity prior, compute it for each source space\n    # separately\n    if not forward[\"surf_ori\"]:\n        raise ValueError(\n            \"Forward operator is not oriented in surface \"\n            \"coordinates. loose parameter should be 1. \"\n            f\"not {loose}.\"\n        )\n    start = 0\n    logged = dict()\n    for s in forward[\"src\"]:\n        this_type = _src_kind_dict[s[\"type\"]]\n        use_loose = loose[this_type]\n        if not logged.get(this_type):\n            if use_loose == 1.0:\n                name = \"free\"\n            else:\n                name = \"fixed\" if use_loose == 0.0 else \"loose\"\n            logger.info(\n                f\"Applying {name.ljust(5)} dipole orientations to \"\n                f\"{this_type.ljust(7)} source spaces: {use_loose}\"\n            )\n            logged[this_type] = True\n        stop = start + 3 * s[\"nuse\"]\n        orient_prior[start:stop:3] *= use_loose\n        orient_prior[start + 1 : stop : 3] *= use_loose\n        start = stop\n    return orient_prior", "metadata": {}}
{"_id": "mne_mne_forward/forward.py_compute_depth_prior_code", "title": "compute_depth_prior", "text": "def compute_depth_prior(\n    forward,\n    info,\n    exp=0.8,\n    limit=10.0,\n    limit_depth_chs=False,\n    combine_xyz=\"spectral\",\n    noise_cov=None,\n    rank=None,\n    verbose=None,\n):\n    \"\"\"Compute depth prior for depth weighting.\n\n    Parameters\n    ----------\n    forward : instance of Forward\n        The forward solution.\n    %(info_not_none)s\n    exp : float\n        Exponent for the depth weighting, must be between 0 and 1.\n    limit : float | None\n        The upper bound on depth weighting.\n        Can be None to be bounded by the largest finite prior.\n    limit_depth_chs : bool | 'whiten'\n        How to deal with multiple channel types in depth weighting.\n        The default is True, which whitens based on the source sensitivity\n        of the highest-SNR channel type. See Notes for details.\n\n        .. versionchanged:: 0.18\n           Added the \"whiten\" option.\n    combine_xyz : 'spectral' | 'fro'\n        When a loose (or free) orientation is used, how the depth weighting\n        for each triplet should be calculated.\n        If 'spectral', use the squared spectral norm of Gk.\n        If 'fro', use the squared Frobenius norm of Gk.\n\n        .. versionadded:: 0.18\n    noise_cov : instance of Covariance | None\n        The noise covariance to use to whiten the gain matrix when\n        ``limit_depth_chs='whiten'``.\n\n        .. versionadded:: 0.18\n    %(rank_none)s\n\n        .. versionadded:: 0.18\n    %(verbose)s\n\n    Returns\n    -------\n    depth_prior : ndarray, shape (n_vertices,)\n        The depth prior.\n\n    See Also\n    --------\n    compute_orient_prior\n\n    Notes\n    -----\n    The defaults used by the minimum norm code and sparse solvers differ.\n    In particular, the values for MNE are::\n\n        compute_depth_prior(..., limit=10., limit_depth_chs=True,\n                            combine_xyz='spectral')\n\n    In sparse solvers and LCMV, the values are::\n\n        compute_depth_prior(..., limit=None, limit_depth_chs='whiten',\n                            combine_xyz='fro')\n\n    The ``limit_depth_chs`` argument can take the following values:\n\n    * :data:`python:True` (default)\n          Use only grad channels in depth weighting (equivalent to MNE C\n          minimum-norm code). If grad channels aren't present, only mag\n          channels will be used (if no mag, then eeg). This makes the depth\n          prior dependent only on the sensor geometry (and relationship\n          to the sources).\n    * ``'whiten'``\n          Compute a whitener and apply it to the gain matrix before computing\n          the depth prior. In this case ``noise_cov`` must not be None.\n          Whitening the gain matrix makes the depth prior\n          depend on both sensor geometry and the data of interest captured\n          by the noise covariance (e.g., projections, SNR).\n\n          .. versionadded:: 0.18\n    * :data:`python:False`\n          Use all channels. Not recommended since the depth weighting will be\n          biased toward whichever channel type has the largest values in\n          SI units (such as EEG being orders of magnitude larger than MEG).\n    \"\"\"\n    from ..cov import Covariance, compute_whitener\n\n    _validate_type(forward, Forward, \"forward\")\n    patch_areas = forward.get(\"patch_areas\", None)\n    is_fixed_ori = is_fixed_orient(forward)\n    G = forward[\"sol\"][\"data\"]\n    logger.info(\"Creating the depth weighting matrix...\")\n    _validate_type(noise_cov, (Covariance, None), \"noise_cov\", \"Covariance or None\")\n    _validate_type(limit_depth_chs, (str, bool), \"limit_depth_chs\")\n    if isinstance(limit_depth_chs, str):\n        if limit_depth_chs != \"whiten\":\n            raise ValueError(\n                f'limit_depth_chs, if str, must be \"whiten\", got {limit_depth_chs}'\n            )\n        if not isinstance(noise_cov, Covariance):\n            raise ValueError(\n                'With limit_depth_chs=\"whiten\", noise_cov must be'\n                f\" a Covariance, got {type(noise_cov)}\"\n            )\n    if combine_xyz is not False:  # private / expert option\n        _check_option(\"combine_xyz\", combine_xyz, (\"fro\", \"spectral\"))\n\n    # If possible, pick best depth-weighting channels\n    if limit_depth_chs is True:\n        G = _restrict_gain_matrix(G, info)\n    elif limit_depth_chs == \"whiten\":\n        whitener, _ = compute_whitener(\n            noise_cov, info, pca=True, rank=rank, verbose=False\n        )\n        G = np.dot(whitener, G)\n\n    # Compute the gain matrix\n    if is_fixed_ori or combine_xyz in (\"fro\", False):\n        d = np.sum(G**2, axis=0)\n        if not (is_fixed_ori or combine_xyz is False):\n            d = d.reshape(-1, 3).sum(axis=1)\n        # Spherical leadfield can be zero at the center\n        d[d == 0.0] = np.min(d[d != 0.0])\n    else:  # 'spectral'\n        # n_pos = G.shape[1] // 3\n        # The following is equivalent to this, but 4-10x faster\n        # d = np.zeros(n_pos)\n        # for k in range(n_pos):\n        #     Gk = G[:, 3 * k:3 * (k + 1)]\n        #     x = np.dot(Gk.T, Gk)\n        #     d[k] = linalg.svdvals(x)[0]\n        G.shape = (G.shape[0], -1, 3)\n        d = np.linalg.norm(\n            np.einsum(\"svj,svk->vjk\", G, G),  # vector dot prods\n            ord=2,  # ord=2 spectral (largest s.v.)\n            axis=(1, 2),\n        )\n        G.shape = (G.shape[0], -1)\n\n    # XXX Currently the fwd solns never have \"patch_areas\" defined\n    if patch_areas is not None:\n        if not is_fixed_ori and combine_xyz is False:\n            patch_areas = np.repeat(patch_areas, 3)\n        d /= patch_areas**2\n        logger.info(\"    Patch areas taken into account in the depth weighting\")\n\n    w = 1.0 / d\n    if limit is not None:\n        ws = np.sort(w)\n        weight_limit = limit**2\n        if limit_depth_chs is False:\n            # match old mne-python behavior\n            # we used to do ind = np.argmin(ws), but this is 0 by sort above\n            n_limit = 0\n            limit = ws[0] * weight_limit\n        else:\n            # match C code behavior\n            limit = ws[-1]\n            n_limit = len(d)\n            if ws[-1] > weight_limit * ws[0]:\n                ind = np.where(ws > weight_limit * ws[0])[0][0]\n                limit = ws[ind]\n                n_limit = ind\n\n        logger.info(\n            \"    limit = %d/%d = %f\", n_limit + 1, len(d), np.sqrt(limit / ws[0])\n        )\n        scale = 1.0 / limit\n        logger.info(f\"    scale = {scale:g} exp = {exp:g}\")\n        w = np.minimum(w / limit, 1)\n    depth_prior = w**exp\n\n    if not (is_fixed_ori or combine_xyz is False):\n        depth_prior = np.repeat(depth_prior, 3)\n\n    return depth_prior", "metadata": {}}
{"_id": "mne_mne_forward/forward.py_apply_forward_code", "title": "apply_forward", "text": "def apply_forward(\n    fwd,\n    stc,\n    info,\n    start=None,\n    stop=None,\n    use_cps=True,\n    on_missing=\"raise\",\n    verbose=None,\n):\n    \"\"\"Project source space currents to sensor space using a forward operator.\n\n    The sensor space data is computed for all channels present in fwd. Use\n    pick_channels_forward or pick_types_forward to restrict the solution to a\n    subset of channels.\n\n    The function returns an Evoked object, which is constructed from\n    evoked_template. The evoked_template should be from the same MEG system on\n    which the original data was acquired. An exception will be raised if the\n    forward operator contains channels that are not present in the template.\n\n    Parameters\n    ----------\n    fwd : Forward\n        Forward operator to use.\n    stc : SourceEstimate\n        The source estimate from which the sensor space data is computed.\n    %(info_not_none)s\n    start : int, optional\n        Index of first time sample (index not time is seconds).\n    stop : int, optional\n        Index of first time sample not to include (index not time is seconds).\n    %(use_cps)s\n\n        .. versionadded:: 0.15\n    %(on_missing_fwd)s\n        Default is \"raise\".\n\n        .. versionadded:: 0.18\n    %(verbose)s\n\n    Returns\n    -------\n    evoked : Evoked\n        Evoked object with computed sensor space data.\n\n    See Also\n    --------\n    apply_forward_raw: Compute sensor space data and return a Raw object.\n    \"\"\"\n    _validate_type(info, Info, \"info\")\n    _validate_type(fwd, Forward, \"forward\")\n    info._check_consistency()\n\n    # make sure evoked_template contains all channels in fwd\n    for ch_name in fwd[\"sol\"][\"row_names\"]:\n        if ch_name not in info[\"ch_names\"]:\n            raise ValueError(\n                f\"Channel {ch_name} of forward operator not present in evoked_template.\"\n            )\n\n    # project the source estimate to the sensor space\n    data, times = _apply_forward(\n        fwd, stc, start, stop, on_missing=on_missing, use_cps=use_cps\n    )\n\n    # fill the measurement info\n    sfreq = float(1.0 / stc.tstep)\n    info, data = _fill_measurement_info(info, fwd, sfreq, data)\n\n    evoked = EvokedArray(data, info, times[0], nave=1)\n\n    evoked._set_times(times)\n    evoked._update_first_last()\n\n    return evoked", "metadata": {}}
{"_id": "mne_mne_forward/forward.py_apply_forward_raw_code", "title": "apply_forward_raw", "text": "def apply_forward_raw(\n    fwd,\n    stc,\n    info,\n    start=None,\n    stop=None,\n    on_missing=\"raise\",\n    use_cps=True,\n    verbose=None,\n):\n    \"\"\"Project source space currents to sensor space using a forward operator.\n\n    The sensor space data is computed for all channels present in fwd. Use\n    pick_channels_forward or pick_types_forward to restrict the solution to a\n    subset of channels.\n\n    The function returns a Raw object, which is constructed using provided\n    info. The info object should be from the same MEG system on which the\n    original data was acquired. An exception will be raised if the forward\n    operator contains channels that are not present in the info.\n\n    Parameters\n    ----------\n    fwd : Forward\n        Forward operator to use.\n    stc : SourceEstimate\n        The source estimate from which the sensor space data is computed.\n    %(info_not_none)s\n    start : int, optional\n        Index of first time sample (index not time is seconds).\n    stop : int, optional\n        Index of first time sample not to include (index not time is seconds).\n    %(on_missing_fwd)s\n        Default is \"raise\".\n\n        .. versionadded:: 0.18\n    %(use_cps)s\n\n        .. versionadded:: 0.21\n    %(verbose)s\n\n    Returns\n    -------\n    raw : Raw object\n        Raw object with computed sensor space data.\n\n    See Also\n    --------\n    apply_forward: Compute sensor space data and return an Evoked object.\n    \"\"\"\n    # make sure info contains all channels in fwd\n    for ch_name in fwd[\"sol\"][\"row_names\"]:\n        if ch_name not in info[\"ch_names\"]:\n            raise ValueError(\n                f\"Channel {ch_name} of forward operator not present in info.\"\n            )\n\n    # project the source estimate to the sensor space\n    data, times = _apply_forward(\n        fwd, stc, start, stop, on_missing=on_missing, use_cps=use_cps\n    )\n\n    sfreq = 1.0 / stc.tstep\n    info, data = _fill_measurement_info(info, fwd, sfreq, data)\n    with info._unlock():\n        info[\"projs\"] = []\n    # store sensor data in Raw object using the info\n    raw = RawArray(data, info, first_samp=int(np.round(times[0] * sfreq)))\n    raw._projector = None\n    return raw", "metadata": {}}
{"_id": "mne_mne_forward/forward.py_restrict_forward_to_stc_code", "title": "restrict_forward_to_stc", "text": "def restrict_forward_to_stc(fwd, stc, on_missing=\"ignore\"):\n    \"\"\"Restrict forward operator to active sources in a source estimate.\n\n    Parameters\n    ----------\n    fwd : instance of Forward\n        Forward operator.\n    stc : instance of SourceEstimate\n        Source estimate.\n    %(on_missing_fwd)s\n        Default is \"ignore\".\n\n        .. versionadded:: 0.18\n\n    Returns\n    -------\n    fwd_out : instance of Forward\n        Restricted forward operator.\n\n    See Also\n    --------\n    restrict_forward_to_label\n    \"\"\"\n    _validate_type(on_missing, str, \"on_missing\")\n    _check_option(\"on_missing\", on_missing, (\"ignore\", \"warn\", \"raise\"))\n    src_sel, _, _ = _stc_src_sel(fwd[\"src\"], stc, on_missing=on_missing)\n    del stc\n    return _restrict_forward_to_src_sel(fwd, src_sel)", "metadata": {}}
{"_id": "mne_mne_forward/forward.py_restrict_forward_to_label_code", "title": "restrict_forward_to_label", "text": "def restrict_forward_to_label(fwd, labels):\n    \"\"\"Restrict forward operator to labels.\n\n    Parameters\n    ----------\n    fwd : Forward\n        Forward operator.\n    labels : instance of Label | list\n        Label object or list of label objects.\n\n    Returns\n    -------\n    fwd_out : dict\n        Restricted forward operator.\n\n    See Also\n    --------\n    restrict_forward_to_stc\n    \"\"\"\n    vertices = [np.array([], int), np.array([], int)]\n\n    if not isinstance(labels, list):\n        labels = [labels]\n\n    # Get vertices separately of each hemisphere from all label\n    for label in labels:\n        _validate_type(label, Label, \"label\", \"Label or list\")\n        i = 0 if label.hemi == \"lh\" else 1\n        vertices[i] = np.append(vertices[i], label.vertices)\n    # Remove duplicates and sort\n    vertices = [np.unique(vert_hemi) for vert_hemi in vertices]\n    vertices = [\n        vert_hemi[np.isin(vert_hemi, s[\"vertno\"])]\n        for vert_hemi, s in zip(vertices, fwd[\"src\"])\n    ]\n    src_sel, _, _ = _stc_src_sel(fwd[\"src\"], vertices, on_missing=\"raise\")\n    return _restrict_forward_to_src_sel(fwd, src_sel)", "metadata": {}}
{"_id": "mne_mne_forward/forward.py_average_forward_solutions_code", "title": "average_forward_solutions", "text": "def average_forward_solutions(fwds, weights=None, verbose=None):\n    \"\"\"Average forward solutions.\n\n    Parameters\n    ----------\n    fwds : list of Forward\n        Forward solutions to average. Each entry (dict) should be a\n        forward solution.\n    weights : array | None\n        Weights to apply to each forward solution in averaging. If None,\n        forward solutions will be equally weighted. Weights must be\n        non-negative, and will be adjusted to sum to one.\n    %(verbose)s\n\n    Returns\n    -------\n    fwd : Forward\n        The averaged forward solution.\n    \"\"\"\n    # check for fwds being a list\n    _validate_type(fwds, list, \"fwds\")\n    if not len(fwds) > 0:\n        raise ValueError(\"fwds must not be empty\")\n\n    # check weights\n    if weights is None:\n        weights = np.ones(len(fwds))\n    weights = np.asanyarray(weights)  # in case it's a list, convert it\n    if not np.all(weights >= 0):\n        raise ValueError(\"weights must be non-negative\")\n    if not len(weights) == len(fwds):\n        raise ValueError(\"weights must be None or the same length as fwds\")\n    w_sum = np.sum(weights)\n    if not w_sum > 0:\n        raise ValueError(\"weights cannot all be zero\")\n    weights /= w_sum\n\n    # check our forward solutions\n    for fwd in fwds:\n        # check to make sure it's a forward solution\n        _validate_type(fwd, dict, \"each entry in fwds\", \"dict\")\n        # check to make sure the dict is actually a fwd\n        check_keys = [\n            \"info\",\n            \"sol_grad\",\n            \"nchan\",\n            \"src\",\n            \"source_nn\",\n            \"sol\",\n            \"source_rr\",\n            \"source_ori\",\n            \"surf_ori\",\n            \"coord_frame\",\n            \"mri_head_t\",\n            \"nsource\",\n        ]\n        if not all(key in fwd for key in check_keys):\n            raise KeyError(\n                \"forward solution dict does not have all standard \"\n                \"entries, cannot compute average.\"\n            )\n\n    # check forward solution compatibility\n    if any(\n        fwd[\"sol\"][k] != fwds[0][\"sol\"][k] for fwd in fwds[1:] for k in [\"nrow\", \"ncol\"]\n    ):\n        raise ValueError(\"Forward solutions have incompatible dimensions\")\n    if any(\n        fwd[k] != fwds[0][k]\n        for fwd in fwds[1:]\n        for k in [\"source_ori\", \"surf_ori\", \"coord_frame\"]\n    ):\n        raise ValueError(\"Forward solutions have incompatible orientations\")\n\n    # actually average them (solutions and gradients)\n    fwd_ave = deepcopy(fwds[0])\n    fwd_ave[\"sol\"][\"data\"] *= weights[0]\n    fwd_ave[\"_orig_sol\"] *= weights[0]\n    for fwd, w in zip(fwds[1:], weights[1:]):\n        fwd_ave[\"sol\"][\"data\"] += w * fwd[\"sol\"][\"data\"]\n        fwd_ave[\"_orig_sol\"] += w * fwd[\"_orig_sol\"]\n    if fwd_ave[\"sol_grad\"] is not None:\n        fwd_ave[\"sol_grad\"][\"data\"] *= weights[0]\n        fwd_ave[\"_orig_sol_grad\"] *= weights[0]\n        for fwd, w in zip(fwds[1:], weights[1:]):\n            fwd_ave[\"sol_grad\"][\"data\"] += w * fwd[\"sol_grad\"][\"data\"]\n            fwd_ave[\"_orig_sol_grad\"] += w * fwd[\"_orig_sol_grad\"]\n    return fwd_ave", "metadata": {}}
{"_id": "mne_mne_forward/forward.py_copy_code", "title": "copy", "text": "def copy(self):\n        \"\"\"Copy the Forward instance.\"\"\"\n        return Forward(deepcopy(self))", "metadata": {}}
{"_id": "mne_mne_forward/forward.py_save_code", "title": "save", "text": "def save(self, fname, *, overwrite=False, verbose=None):\n        \"\"\"Save the forward solution.\n\n        Parameters\n        ----------\n        %(fname_fwd)s\n        %(overwrite)s\n        %(verbose)s\n        \"\"\"\n        write_forward_solution(fname, self, overwrite=overwrite)", "metadata": {}}
{"_id": "mne_mne_forward/forward.py_pick_channels_code", "title": "pick_channels", "text": "def pick_channels(self, ch_names, ordered=False):\n        \"\"\"Pick channels from this forward operator.\n\n        Parameters\n        ----------\n        ch_names : list of str\n            List of channels to include.\n        ordered : bool\n            If true (default False), treat ``include`` as an ordered list\n            rather than a set.\n\n        Returns\n        -------\n        fwd : instance of Forward.\n            The modified forward model.\n\n        Notes\n        -----\n        Operates in-place.\n\n        .. versionadded:: 0.20.0\n        \"\"\"\n        return pick_channels_forward(\n            self, ch_names, exclude=[], ordered=ordered, copy=False, verbose=False\n        )", "metadata": {}}
{"_id": "mne_mne_forward/_make_forward.py_make_forward_solution_code", "title": "make_forward_solution", "text": "def make_forward_solution(\n    info,\n    trans,\n    src,\n    bem,\n    meg=True,\n    eeg=True,\n    *,\n    mindist=0.0,\n    ignore_ref=False,\n    n_jobs=None,\n    verbose=None,\n):\n    \"\"\"Calculate a forward solution for a subject.\n\n    Parameters\n    ----------\n    %(info_str)s\n    %(trans)s\n\n        .. versionchanged:: 0.19\n            Support for ``'fsaverage'`` argument.\n    src : path-like | instance of SourceSpaces\n        Either a path to a source space file or a loaded or generated\n        :class:`~mne.SourceSpaces`.\n    bem : path-like | ConductorModel\n        Filename of the BEM (e.g., ``\"sample-5120-5120-5120-bem-sol.fif\"``) to\n        use, or a loaded :class:`~mne.bem.ConductorModel`. See\n        :func:`~mne.make_bem_model` and :func:`~mne.make_bem_solution` to create a\n        :class:`mne.bem.ConductorModel`.\n    meg : bool\n        If True (default), include MEG computations.\n    eeg : bool\n        If True (default), include EEG computations.\n    mindist : float\n        Minimum distance of sources from inner skull surface (in mm).\n    ignore_ref : bool\n        If True, do not include reference channels in compensation. This\n        option should be True for KIT files, since forward computation\n        with reference channels is not currently supported.\n    %(n_jobs)s\n    %(verbose)s\n\n    Returns\n    -------\n    fwd : instance of Forward\n        The forward solution.\n\n    See Also\n    --------\n    convert_forward_solution\n\n    Notes\n    -----\n    The ``--grad`` option from MNE-C (to compute gradients) is not implemented\n    here.\n\n    To create a fixed-orientation forward solution, use this function\n    followed by :func:`mne.convert_forward_solution`.\n\n    .. note::\n        If the BEM solution was computed with `OpenMEEG <https://openmeeg.github.io>`__\n        in :func:`mne.make_bem_solution`, then OpenMEEG will automatically\n        be used to compute the forward solution.\n\n    .. versionchanged:: 1.2\n       Added support for OpenMEEG-based forward solution calculations.\n    \"\"\"\n    # Currently not (sup)ported:\n    # 1. --grad option (gradients of the field, not used much)\n    # 2. --fixed option (can be computed post-hoc)\n    # 3. --mricoord option (probably not necessary)\n\n    # read the transformation from MRI to HEAD coordinates\n    # (could also be HEAD to MRI)\n    mri_head_t, trans = _get_trans(trans)\n    if isinstance(bem, ConductorModel):\n        bem_extra = \"instance of ConductorModel\"\n    else:\n        bem_extra = bem\n    _validate_type(info, (\"path-like\", Info), \"info\")\n    if not isinstance(info, Info):\n        info_extra = op.split(info)[1]\n        info = _check_fname(info, must_exist=True, overwrite=\"read\", name=\"info\")\n        info = read_info(info, verbose=False)\n    else:\n        info_extra = \"instance of Info\"\n\n    # Report the setup\n    logger.info(f\"Source space          : {src}\")\n    logger.info(f\"MRI -> head transform : {trans}\")\n    logger.info(f\"Measurement data      : {info_extra}\")\n    if isinstance(bem, ConductorModel) and bem[\"is_sphere\"]:\n        logger.info(f\"Sphere model      : origin at {bem['r0']} mm\")\n        logger.info(\"Standard field computations\")\n    else:\n        logger.info(f\"Conductor model   : {bem_extra}\")\n        logger.info(\"Accurate field computations\")\n    logger.info(\n        \"Do computations in %s coordinates\", _coord_frame_name(FIFF.FIFFV_COORD_HEAD)\n    )\n    logger.info(\"Free source orientations\")\n\n    # Create MEG coils and EEG electrodes in the head coordinate frame\n    sensors, rr, info, update_kwargs, bem = _prepare_for_forward(\n        src,\n        mri_head_t,\n        info,\n        bem,\n        mindist,\n        n_jobs,\n        bem_extra,\n        trans,\n        info_extra,\n        meg,\n        eeg,\n        ignore_ref,\n    )\n    del (src, mri_head_t, trans, info_extra, bem_extra, mindist, meg, eeg, ignore_ref)\n\n    # Time to do the heavy lifting: MEG first, then EEG\n    fwds = _compute_forwards(rr, bem=bem, sensors=sensors, n_jobs=n_jobs)\n\n    # merge forwards\n    fwds = {\n        key: _to_forward_dict(fwds[key], sensors[key][\"ch_names\"])\n        for key in _FWD_ORDER\n        if key in fwds\n    }\n    fwd = _merge_fwds(fwds, verbose=False)\n    del fwds\n    logger.info(\"\")\n\n    # Don't transform the source spaces back into MRI coordinates (which is\n    # done in the C code) because mne-python assumes forward solution source\n    # spaces are in head coords.\n    fwd.update(**update_kwargs)\n    logger.info(\"Finished.\")\n    return fwd", "metadata": {}}
{"_id": "mne_mne_forward/_make_forward.py_make_forward_dipole_code", "title": "make_forward_dipole", "text": "def make_forward_dipole(dipole, bem, info, trans=None, n_jobs=None, *, verbose=None):\n    \"\"\"Convert dipole object to source estimate and calculate forward operator.\n\n    The instance of Dipole is converted to a discrete source space,\n    which is then combined with a BEM or a sphere model and\n    the sensor information in info to form a forward operator.\n\n    The source estimate object (with the forward operator) can be projected to\n    sensor-space using :func:`mne.simulation.simulate_evoked`.\n\n    .. note:: If the (unique) time points of the dipole object are unevenly\n              spaced, the first output will be a list of single-timepoint\n              source estimates.\n\n    Parameters\n    ----------\n    %(dipole)s\n    bem : str | dict\n        The BEM filename (str) or a loaded sphere model (dict).\n    info : instance of Info\n        The measurement information dictionary. It is sensor-information etc.,\n        e.g., from a real data file.\n    trans : str | None\n        The head<->MRI transform filename. Must be provided unless BEM\n        is a sphere model.\n    %(n_jobs)s\n    %(verbose)s\n\n    Returns\n    -------\n    fwd : instance of Forward\n        The forward solution corresponding to the source estimate(s).\n    stc : instance of VolSourceEstimate | list of VolSourceEstimate\n        The dipoles converted to a discrete set of points and associated\n        time courses. If the time points of the dipole are unevenly spaced,\n        a list of single-timepoint source estimates are returned.\n\n    See Also\n    --------\n    mne.simulation.simulate_evoked\n\n    Notes\n    -----\n    .. versionadded:: 0.12.0\n    \"\"\"\n    if isinstance(dipole, list):\n        from ..dipole import _concatenate_dipoles  # To avoid circular import\n\n        dipole = _concatenate_dipoles(dipole)\n\n    # Make copies to avoid mangling original dipole\n    times = dipole.times.copy()\n    pos = dipole.pos.copy()\n    amplitude = dipole.amplitude.copy()\n    ori = dipole.ori.copy()\n\n    # Convert positions to discrete source space (allows duplicate rr & nn)\n    # NB information about dipole orientation enters here, then no more\n    sources = dict(rr=pos, nn=ori)\n    # Dipole objects must be in the head frame\n    src = _complete_vol_src([_make_discrete_source_space(sources, coord_frame=\"head\")])\n\n    # Forward operator created for channels in info (use pick_info to restrict)\n    # Use defaults for most params, including min_dist\n    fwd = make_forward_solution(info, trans, src, bem, n_jobs=n_jobs, verbose=verbose)\n    # Convert from free orientations to fixed (in-place)\n    convert_forward_solution(\n        fwd, surf_ori=False, force_fixed=True, copy=False, use_cps=False, verbose=None\n    )\n\n    # Check for omissions due to proximity to inner skull in\n    # make_forward_solution, which will result in an exception\n    if fwd[\"src\"][0][\"nuse\"] != len(pos):\n        inuse = fwd[\"src\"][0][\"inuse\"].astype(bool)\n        head = \"The following dipoles are outside the inner skull boundary\"\n        msg = len(head) * \"#\" + \"\\n\" + head + \"\\n\"\n        for t, pos in zip(times[np.logical_not(inuse)], pos[np.logical_not(inuse)]):\n            msg += (\n                f\"    t={t * 1000.0:.0f} ms, pos=({pos[0] * 1000.0:.0f}, \"\n                f\"{pos[1] * 1000.0:.0f}, {pos[2] * 1000.0:.0f}) mm\\n\"\n            )\n        msg += len(head) * \"#\"\n        logger.error(msg)\n        raise ValueError(\"One or more dipoles outside the inner skull.\")\n\n    # multiple dipoles (rr and nn) per time instant allowed\n    # uneven sampling in time returns list\n    timepoints = np.unique(times)\n    if len(timepoints) > 1:\n        tdiff = np.diff(timepoints)\n        if not np.allclose(tdiff, tdiff[0]):\n            warn(\n                \"Unique time points of dipoles unevenly spaced: returned \"\n                \"stc will be a list, one for each time point.\"\n            )\n            tstep = -1.0\n        else:\n            tstep = tdiff[0]\n    elif len(timepoints) == 1:\n        tstep = 0.001\n\n    # Build the data matrix, essentially a block-diagonal with\n    # n_rows: number of dipoles in total (dipole.amplitudes)\n    # n_cols: number of unique time points in dipole.times\n    # amplitude with identical value of times go together in one col (others=0)\n    data = np.zeros((len(amplitude), len(timepoints)))  # (n_d, n_t)\n    row = 0\n    for tpind, tp in enumerate(timepoints):\n        amp = amplitude[np.isin(times, tp)]\n        data[row : row + len(amp), tpind] = amp\n        row += len(amp)\n\n    if tstep > 0:\n        stc = VolSourceEstimate(\n            data,\n            vertices=[fwd[\"src\"][0][\"vertno\"]],\n            tmin=timepoints[0],\n            tstep=tstep,\n            subject=None,\n        )\n    else:  # Must return a list of stc, one for each time point\n        stc = []\n        for col, tp in enumerate(timepoints):\n            stc += [\n                VolSourceEstimate(\n                    data[:, col][:, np.newaxis],\n                    vertices=[fwd[\"src\"][0][\"vertno\"]],\n                    tmin=tp,\n                    tstep=0.001,\n                    subject=None,\n                )\n            ]\n    return fwd, stc", "metadata": {}}
{"_id": "mne_mne_forward/_make_forward.py_use_coil_def_code", "title": "use_coil_def", "text": "def use_coil_def(fname):\n    \"\"\"Use a custom coil definition file.\n\n    Parameters\n    ----------\n    fname : path-like\n        The filename of the coil definition file.\n\n    Returns\n    -------\n    context : contextmanager\n        The context for using the coil definition.\n\n    Notes\n    -----\n    This is meant to be used a context manager such as:\n\n    >>> with use_coil_def(my_fname):  # doctest:+SKIP\n    ...     make_forward_solution(...)\n\n    This allows using custom coil definitions with functions that require\n    forward modeling.\n    \"\"\"\n    global _extra_coil_def_fname\n    _extra_coil_def_fname = fname\n    try:\n        yield\n    finally:\n        _extra_coil_def_fname = None", "metadata": {}}
{"_id": "mne_mne_forward/_field_interpolation.py_make_field_map_code", "title": "make_field_map", "text": "def make_field_map(\n    evoked,\n    trans=\"auto\",\n    subject=None,\n    subjects_dir=None,\n    ch_type=None,\n    mode=\"fast\",\n    meg_surf=\"helmet\",\n    origin=(0.0, 0.0, 0.04),\n    n_jobs=None,\n    *,\n    upsampling=1,\n    head_source=(\"bem\", \"head\"),\n    verbose=None,\n):\n    \"\"\"Compute surface maps used for field display in 3D.\n\n    Parameters\n    ----------\n    evoked : Evoked | Epochs | Raw\n        The measurement file. Need to have info attribute.\n    %(trans)s ``\"auto\"`` (default) will load trans from the FreeSurfer\n        directory specified by ``subject`` and ``subjects_dir`` parameters.\n\n        .. versionchanged:: 0.19\n            Support for ``'fsaverage'`` argument.\n    subject : str | None\n        The subject name corresponding to FreeSurfer environment\n        variable SUBJECT. If None, map for EEG data will not be available.\n    subjects_dir : path-like\n        The path to the freesurfer subjects reconstructions.\n        It corresponds to Freesurfer environment variable SUBJECTS_DIR.\n    ch_type : None | ``'eeg'`` | ``'meg'``\n        If None, a map for each available channel type will be returned.\n        Else only the specified type will be used.\n    mode : ``'accurate'`` | ``'fast'``\n        Either ``'accurate'`` or ``'fast'``, determines the quality of the\n        Legendre polynomial expansion used. ``'fast'`` should be sufficient\n        for most applications.\n    meg_surf : 'helmet' | 'head'\n        Should be ``'helmet'`` or ``'head'`` to specify in which surface\n        to compute the MEG field map. The default value is ``'helmet'``.\n    origin : array-like, shape (3,) | 'auto'\n        Origin of the sphere in the head coordinate frame and in meters.\n        Can be ``'auto'``, which means a head-digitization-based origin\n        fit. Default is ``(0., 0., 0.04)``.\n\n        .. versionadded:: 0.11\n    %(n_jobs)s\n    %(helmet_upsampling)s\n\n        .. versionadded:: 1.10\n    %(head_source)s\n\n        .. versionadded:: 1.1\n    %(verbose)s\n\n    Returns\n    -------\n    surf_maps : list\n        The surface maps to be used for field plots. The list contains\n        separate ones for MEG and EEG (if both MEG and EEG are present).\n    \"\"\"\n    info = evoked.info\n\n    if ch_type is None:\n        types = [t for t in [\"eeg\", \"meg\"] if t in evoked]\n    else:\n        _check_option(\"ch_type\", ch_type, [\"eeg\", \"meg\"])\n        types = [ch_type]\n\n    if subjects_dir is not None:\n        subjects_dir = _check_fname(\n            subjects_dir,\n            overwrite=\"read\",\n            must_exist=True,\n            name=\"subjects_dir\",\n            need_dir=True,\n        )\n\n    trans, trans_type = _find_trans(\n        trans=trans,\n        subject=subject,\n        subjects_dir=subjects_dir,\n    )\n\n    if \"eeg\" in types and trans_type == \"identity\":\n        logger.info(\"No trans file available. EEG data ignored.\")\n        types.remove(\"eeg\")\n\n    if len(types) == 0:\n        raise RuntimeError(\"No data available for mapping.\")\n\n    _check_option(\"meg_surf\", meg_surf, [\"helmet\", \"head\"])\n\n    surfs = []\n    for this_type in types:\n        if this_type == \"meg\" and meg_surf == \"helmet\":\n            surf = get_meg_helmet_surf(info, trans, upsampling=upsampling)\n        else:\n            surf = get_head_surf(subject, source=head_source, subjects_dir=subjects_dir)\n        surfs.append(surf)\n\n    surf_maps = list()\n\n    for this_type, this_surf in zip(types, surfs):\n        this_map = _make_surface_mapping(\n            evoked.info,\n            this_surf,\n            this_type,\n            trans,\n            n_jobs=n_jobs,\n            origin=origin,\n            mode=mode,\n        )\n        surf_maps.append(this_map)\n\n    return surf_maps", "metadata": {}}
{"_id": "mne_mne_utils/numerics.py_split_list_code", "title": "split_list", "text": "def split_list(v, n, idx=False):\n    \"\"\"Split list in n (approx) equal pieces, possibly giving indices.\"\"\"\n    n = int(n)\n    tot = len(v)\n    sz = tot // n\n    start = stop = 0\n    for i in range(n - 1):\n        stop += sz\n        yield (np.arange(start, stop), v[start:stop]) if idx else v[start:stop]\n        start += sz\n    yield (np.arange(start, tot), v[start:]) if idx else v[start]", "metadata": {}}
{"_id": "mne_mne_utils/numerics.py_array_split_idx_code", "title": "array_split_idx", "text": "def array_split_idx(ary, indices_or_sections, axis=0, n_per_split=1):\n    \"\"\"Do what numpy.array_split does, but add indices.\"\"\"\n    # this only works for indices_or_sections as int\n    indices_or_sections = _ensure_int(indices_or_sections)\n    ary_split = np.array_split(ary, indices_or_sections, axis=axis)\n    idx_split = np.array_split(np.arange(ary.shape[axis]), indices_or_sections)\n    idx_split = (\n        np.arange(sp[0] * n_per_split, (sp[-1] + 1) * n_per_split) for sp in idx_split\n    )\n    return zip(idx_split, ary_split)", "metadata": {}}
{"_id": "mne_mne_utils/numerics.py_sum_squared_code", "title": "sum_squared", "text": "def sum_squared(X):\n    \"\"\"Compute norm of an array.\n\n    Parameters\n    ----------\n    X : array\n        Data whose norm must be found.\n\n    Returns\n    -------\n    value : float\n        Sum of squares of the input array X.\n    \"\"\"\n    X_flat = X.ravel(order=\"F\" if np.isfortran(X) else \"C\")\n    return np.dot(X_flat, X_flat)", "metadata": {}}
{"_id": "mne_mne_utils/numerics.py_compute_corr_code", "title": "compute_corr", "text": "def compute_corr(x, y):\n    \"\"\"Compute pearson correlations between a vector and a matrix.\"\"\"\n    if len(x) == 0 or len(y) == 0:\n        raise ValueError(\"x or y has zero length\")\n    X = np.array(x, float)\n    Y = np.array(y, float)\n    X -= X.mean(0)\n    Y -= Y.mean(0)\n    x_sd = X.std(0, ddof=1)\n    # if covariance matrix is fully expanded, Y needs a\n    # transpose / broadcasting else Y is correct\n    y_sd = Y.std(0, ddof=1)[:, None if X.shape == Y.shape else Ellipsis]\n    return (np.dot(X.T, Y) / float(len(X) - 1)) / (x_sd * y_sd)", "metadata": {}}
{"_id": "mne_mne_utils/numerics.py_random_permutation_code", "title": "random_permutation", "text": "def random_permutation(n_samples, random_state=None):\n    \"\"\"Emulate the randperm matlab function.\n\n    It returns a vector containing a random permutation of the\n    integers between 0 and n_samples-1. It returns the same random numbers\n    than randperm matlab function whenever the random_state is the same\n    as the matlab's random seed.\n\n    This function is useful for comparing against matlab scripts\n    which use the randperm function.\n\n    Note: the randperm(n_samples) matlab function generates a random\n    sequence between 1 and n_samples, whereas\n    random_permutation(n_samples, random_state) function generates\n    a random sequence between 0 and n_samples-1, that is:\n    randperm(n_samples) = random_permutation(n_samples, random_state) - 1\n\n    Parameters\n    ----------\n    n_samples : int\n        End point of the sequence to be permuted (excluded, i.e., the end point\n        is equal to n_samples-1)\n    %(random_state)s\n\n    Returns\n    -------\n    randperm : ndarray, int\n        Randomly permuted sequence between 0 and n-1.\n    \"\"\"\n    rng = check_random_state(random_state)\n    # This can't just be rng.permutation(n_samples) because it's not identical\n    # to what MATLAB produces\n    idx = rng.uniform(size=n_samples)\n    randperm = np.argsort(idx)\n    return randperm", "metadata": {}}
{"_id": "mne_mne_utils/numerics.py_hashfunc_code", "title": "hashfunc", "text": "def hashfunc(fname, block_size=1048576, hash_type=\"md5\"):  # 2 ** 20\n    \"\"\"Calculate the hash for a file.\n\n    Parameters\n    ----------\n    fname : str\n        Filename.\n    block_size : int\n        Block size to use when reading.\n\n    Returns\n    -------\n    hash_ : str\n        The hexadecimal digest of the hash.\n    \"\"\"\n    hasher = _empty_hash(kind=hash_type)\n    with open(fname, \"rb\") as fid:\n        while True:\n            data = fid.read(block_size)\n            if not data:\n                break\n            hasher.update(data)\n    return hasher.hexdigest()", "metadata": {}}
{"_id": "mne_mne_utils/numerics.py_create_slices_code", "title": "create_slices", "text": "def create_slices(start, stop, step=None, length=1):\n    \"\"\"Generate slices of time indexes.\n\n    Parameters\n    ----------\n    start : int\n        Index where first slice should start.\n    stop : int\n        Index where last slice should maximally end.\n    length : int\n        Number of time sample included in a given slice.\n    step: int | None\n        Number of time samples separating two slices.\n        If step = None, step = length.\n\n    Returns\n    -------\n    slices : list\n        List of slice objects.\n    \"\"\"\n    # default parameters\n    if step is None:\n        step = length\n\n    # slicing\n    slices = [slice(t, t + length, 1) for t in range(start, stop - length + 1, step)]\n    return slices", "metadata": {}}
{"_id": "mne_mne_utils/numerics.py_grand_average_code", "title": "grand_average", "text": "def grand_average(all_inst, interpolate_bads=True, drop_bads=True):\n    \"\"\"Make grand average of a list of Evoked, AverageTFR, or Spectrum data.\n\n    For :class:`mne.Evoked` data, the function interpolates bad channels based on the\n    ``interpolate_bads`` parameter. If ``interpolate_bads`` is True, the grand average\n    file will contain good channels and the bad channels interpolated from the good\n    MEG/EEG channels.\n    For :class:`mne.time_frequency.AverageTFR` and :class:`mne.time_frequency.Spectrum`\n    data, the function takes the subset of channels not marked as bad in any of the\n    instances.\n\n    The ``grand_average.nave`` attribute will be equal to the number of datasets used to\n    calculate the grand average.\n\n    .. note:: A grand average evoked should not be used for source localization.\n\n    Parameters\n    ----------\n    all_inst : list of Evoked, AverageTFR or Spectrum\n        The datasets.\n\n        .. versionchanged:: 1.10.0\n            Added support for :class:`~mne.time_frequency.Spectrum` objects.\n\n    interpolate_bads : bool\n        If True, bad MEG and EEG channels are interpolated. Ignored for\n        :class:`~mne.time_frequency.AverageTFR` and\n        :class:`~mne.time_frequency.Spectrum` data.\n    drop_bads : bool\n        If True, drop all bad channels marked as bad in any data set. If neither\n        ``interpolate_bads`` nor ``drop_bads`` is `True`, in the output file, every\n        channel marked as bad in at least one of the input files will be marked as bad,\n        but no interpolation or dropping will be performed.\n\n    Returns\n    -------\n    grand_average : Evoked | AverageTFR | Spectrum\n        The grand average data. Same type as input.\n\n    Notes\n    -----\n    Aggregating multitaper TFR datasets with a taper dimension such as for complex or\n    phase data is not supported.\n\n    .. versionadded:: 0.11.0\n    \"\"\"\n    # check if all elements in the given list are evoked data\n    from ..channels.channels import equalize_channels\n    from ..evoked import Evoked\n    from ..time_frequency import AverageTFR, Spectrum\n\n    if not all_inst:\n        raise ValueError(\n            \"Please pass a list of Evoked, AverageTFR, or Spectrum objects.\"\n        )\n    elif len(all_inst) == 1:\n        warn(\"Only a single dataset was passed to mne.grand_average().\")\n\n    inst_type = type(all_inst[0])\n    _validate_type(all_inst[0], (Evoked, AverageTFR, Spectrum), \"All elements\")\n    for inst in all_inst:\n        _validate_type(inst, inst_type, \"All elements\", \"of the same type\")\n\n    # Copy channels to leave the original evoked datasets intact.\n    all_inst = [inst.copy() for inst in all_inst]\n\n    # Interpolates if necessary\n    if isinstance(all_inst[0], Evoked):\n        if interpolate_bads:\n            all_inst = [\n                inst.interpolate_bads() if len(inst.info[\"bads\"]) > 0 else inst\n                for inst in all_inst\n            ]\n        from ..evoked import combine_evoked as combine\n    elif isinstance(all_inst[0], Spectrum):\n        from ..time_frequency.spectrum import combine_spectrum as combine\n    else:  # isinstance(all_inst[0], AverageTFR):\n        from ..time_frequency.tfr import combine_tfr as combine\n\n    if drop_bads:\n        bads = list({b for inst in all_inst for b in inst.info[\"bads\"]})\n        if bads:\n            for inst in all_inst:\n                inst.drop_channels(bads)\n\n    equalize_channels(all_inst, copy=False)\n    # make grand_average object using combine_[evoked/tfr/spectrum]\n    grand_average = combine(all_inst, weights=\"equal\")\n    # change the grand_average.nave to the number of datasets\n    grand_average.nave = len(all_inst)\n    # change comment field\n    grand_average.comment = f\"Grand average (n = {grand_average.nave})\"\n    return grand_average", "metadata": {}}
{"_id": "mne_mne_utils/numerics.py_object_hash_code", "title": "object_hash", "text": "def object_hash(x, h=None):\n    \"\"\"Hash a reasonable python object.\n\n    Parameters\n    ----------\n    x : object\n        Object to hash. Can be anything comprised of nested versions of:\n        {dict, list, tuple, ndarray, str, bytes, float, int, None}.\n    h : hashlib HASH object | None\n        Optional, object to add the hash to. None creates an MD5 hash.\n\n    Returns\n    -------\n    digest : int\n        The digest resulting from the hash.\n    \"\"\"\n    if h is None:\n        h = _empty_hash()\n    if hasattr(x, \"keys\"):\n        # dict-like types\n        keys = _sort_keys(x)\n        for key in keys:\n            object_hash(key, h)\n            object_hash(x[key], h)\n    elif isinstance(x, bytes):\n        # must come before \"str\" below\n        h.update(x)\n    elif isinstance(x, str | float | int | type(None)):\n        h.update(str(type(x)).encode(\"utf-8\"))\n        h.update(str(x).encode(\"utf-8\"))\n    elif isinstance(x, np.ndarray | np.number | np.bool_):\n        x = np.asarray(x)\n        h.update(str(x.shape).encode(\"utf-8\"))\n        h.update(str(x.dtype).encode(\"utf-8\"))\n        h.update(x.tobytes())\n    elif isinstance(x, datetime):\n        object_hash(_dt_to_stamp(x))\n    elif sparse.issparse(x):\n        h.update(str(type(x)).encode(\"utf-8\"))\n        if not isinstance(x, sparse.csr_array | sparse.csc_array):\n            raise RuntimeError(f\"Unsupported sparse type {type(x)}\")\n        h.update(x.data.tobytes())\n        h.update(x.indices.tobytes())\n        h.update(x.indptr.tobytes())\n    elif hasattr(x, \"__len__\"):\n        # all other list-like types\n        h.update(str(type(x)).encode(\"utf-8\"))\n        for xx in x:\n            object_hash(xx, h)\n    else:\n        raise RuntimeError(f\"unsupported type: {type(x)} ({x})\")\n    return int(h.hexdigest(), 16)", "metadata": {}}
{"_id": "mne_mne_utils/numerics.py_object_size_code", "title": "object_size", "text": "def object_size(x, memo=None):\n    \"\"\"Estimate the size of a reasonable python object.\n\n    Parameters\n    ----------\n    x : object\n        Object to approximate the size of.\n        Can be anything comprised of nested versions of:\n        {dict, list, tuple, ndarray, str, bytes, float, int, None}.\n    memo : dict | None\n        The memodict.\n\n    Returns\n    -------\n    size : int\n        The estimated size in bytes of the object.\n    \"\"\"\n    # Note: this will not process object arrays properly (since those only)\n    # hold references\n    if memo is None:\n        memo = dict()\n    id_ = id(x)\n    if id_ in memo:\n        return 0  # do not add already existing ones\n    if isinstance(x, bytes | str | int | float | type(None) | Path):\n        size = sys.getsizeof(x)\n    elif isinstance(x, np.ndarray):\n        # On newer versions of NumPy, just doing sys.getsizeof(x) works,\n        # but on older ones you always get something small :(\n        size = sys.getsizeof(np.array([]))\n        if x.base is None or id(x.base) not in memo:\n            size += x.nbytes\n    elif isinstance(x, np.generic):\n        size = x.nbytes\n    elif isinstance(x, dict):\n        size = sys.getsizeof(x)\n        for key, value in x.items():\n            size += object_size(key, memo)\n            size += object_size(value, memo)\n    elif isinstance(x, list | tuple):\n        size = sys.getsizeof(x) + sum(object_size(xx, memo) for xx in x)\n    elif isinstance(x, datetime):\n        size = object_size(_dt_to_stamp(x), memo)\n    elif isinstance(x, date):\n        size = 24  # 3 8-byte integers\n    elif _is_sparse_cs(x):\n        size = sum(sys.getsizeof(xx) for xx in [x, x.data, x.indices, x.indptr])\n    else:\n        raise RuntimeError(f\"unsupported type: {type(x)} ({x})\")\n    memo[id_] = size\n    return size", "metadata": {}}
{"_id": "mne_mne_utils/numerics.py_object_diff_code", "title": "object_diff", "text": "def object_diff(a, b, pre=\"\", *, allclose=False):\n    \"\"\"Compute all differences between two python variables.\n\n    Parameters\n    ----------\n    a : object\n        Currently supported: class, dict, list, tuple, ndarray,\n        int, str, bytes, float, StringIO, BytesIO.\n    b : object\n        Must be same type as ``a``.\n    pre : str\n        String to prepend to each line.\n    allclose : bool\n        If True (default False), use assert_allclose.\n\n    Returns\n    -------\n    diffs : str\n        A string representation of the differences.\n    \"\"\"\n    pd = _check_pandas_installed(strict=False)\n    out = \"\"\n    if type(a) is not type(b):\n        # Deal with NamedInt and NamedFloat\n        for sub in (int, float):\n            if isinstance(a, sub) and isinstance(b, sub):\n                break\n        else:\n            return f\"{pre} type mismatch ({type(a)}, {type(b)})\\n\"\n    if inspect.isclass(a):\n        if inspect.isclass(b) and a != b:\n            return f\"{pre} class mismatch ({a}, {b})\\n\"\n    elif isinstance(a, dict):\n        k1s = _sort_keys(a)\n        k2s = _sort_keys(b)\n        m1 = set(k2s) - set(k1s)\n        if len(m1):\n            out += pre + f\" left missing keys {m1}\\n\"\n        for key in k1s:\n            if key not in k2s:\n                out += pre + f\" right missing key {key}\\n\"\n            else:\n                out += object_diff(\n                    a[key], b[key], pre=(pre + f\"[{repr(key)}]\"), allclose=allclose\n                )\n    elif isinstance(a, list | tuple):\n        if len(a) != len(b):\n            out += pre + f\" length mismatch ({len(a)}, {len(b)})\\n\"\n        else:\n            for ii, (xx1, xx2) in enumerate(zip(a, b)):\n                out += object_diff(xx1, xx2, pre + f\"[{ii}]\", allclose=allclose)\n    elif isinstance(a, float):\n        if not _array_equal_nan(a, b, allclose):\n            out += pre + f\" value mismatch ({a}, {b})\\n\"\n    elif isinstance(a, str | int | bytes | np.generic):\n        if a != b:\n            out += pre + f\" value mismatch ({a}, {b})\\n\"\n    elif a is None:\n        if b is not None:\n            out += pre + f\" left is None, right is not ({b})\\n\"\n    elif isinstance(a, np.ndarray):\n        if not _array_equal_nan(a, b, allclose):\n            out += pre + \" array mismatch\\n\"\n    elif isinstance(a, StringIO | BytesIO):\n        if a.getvalue() != b.getvalue():\n            out += pre + \" StringIO mismatch\\n\"\n    elif isinstance(a, datetime | date):\n        ts = (a - b).total_seconds()\n        if ts != 0:\n            out += pre + f\" {a.__class__.__name__} mismatch ({a} vs {b} by {ts} sec)\\n\"\n    elif sparse.issparse(a):\n        # sparsity and sparse type of b vs a already checked above by type()\n        if b.shape != a.shape:\n            out += pre + (\n                f\" sparse matrix a and b shape mismatch ({a.shape} vs {b.shape})\"\n            )\n        else:\n            c = a - b\n            c.eliminate_zeros()\n            if c.nnz > 0:\n                out += pre + (f\" sparse matrix a and b differ on {c.nnz} elements\")\n    elif pd and isinstance(a, pd.DataFrame):\n        try:\n            pd.testing.assert_frame_equal(a, b)\n        except AssertionError:\n            out += pre + \" DataFrame mismatch\\n\"\n    elif hasattr(a, \"__getstate__\") and a.__getstate__() is not None:\n        out += object_diff(a.__getstate__(), b.__getstate__(), pre, allclose=allclose)\n    else:\n        raise RuntimeError(pre + f\": unsupported type {type(a)} ({a})\")\n    return out", "metadata": {}}
{"_id": "mne_mne_utils/progressbar.py_update_code", "title": "update", "text": "def update(self, cur_value):\n        \"\"\"Update progressbar with current value of process.\n\n        Parameters\n        ----------\n        cur_value : number\n            Current value of process.  Should be <= max_value (but this is not\n            enforced).  The percent of the progressbar will be computed as\n            ``(cur_value / max_value) * 100``.\n        \"\"\"\n        self.update_with_increment_value(cur_value - self._tqdm.n)", "metadata": {}}
{"_id": "mne_mne_utils/progressbar.py_update_with_increment_value_code", "title": "update_with_increment_value", "text": "def update_with_increment_value(self, increment_value):\n        \"\"\"Update progressbar with an increment.\n\n        Parameters\n        ----------\n        increment_value : int\n            Value of the increment of process.  The percent of the progressbar\n            will be computed as\n            ``(self.cur_value + increment_value / max_value) * 100``.\n        \"\"\"\n        try:\n            self._tqdm.update(increment_value)\n        except TypeError:  # can happen during GC on Windows\n            pass", "metadata": {}}
{"_id": "mne_mne_utils/progressbar.py_subset_code", "title": "subset", "text": "def subset(self, idx):\n        \"\"\"Make a joblib-friendly index subset updater.\n\n        Parameters\n        ----------\n        idx : ndarray\n            List of indices for this subset.\n\n        Returns\n        -------\n        updater : instance of PBSubsetUpdater\n            Class with a ``.update(ii)`` method.\n        \"\"\"\n        return _PBSubsetUpdater(self, idx)", "metadata": {}}
{"_id": "mne_mne_utils/linalg.py_eigh_code", "title": "eigh", "text": "def eigh(a, overwrite_a=False, check_finite=True):\n    \"\"\"Efficient wrapper for eigh.\n\n    Parameters\n    ----------\n    a : ndarray, shape (n_components, n_components)\n        The symmetric array operate on.\n    overwrite_a : bool\n        If True, the contents of a can be overwritten for efficiency.\n    check_finite : bool\n        If True, check that all elements are finite.\n\n    Returns\n    -------\n    w : ndarray, shape (n_components,)\n        The N eigenvalues, in ascending order, each repeated according to\n        its multiplicity.\n    v : ndarray, shape (n_components, n_components)\n        The normalized eigenvector corresponding to the eigenvalue ``w[i]``\n        is the column ``v[:, i]``.\n    \"\"\"\n    # We use SYEVD, see https://github.com/scipy/scipy/issues/9212\n    if check_finite:\n        a = _asarray_validated(a, check_finite=check_finite)\n    evd, driver = _get_evd(a.dtype)\n    w, v, info = evd(a, lower=1, overwrite_a=overwrite_a)\n    if info == 0:\n        return w, v\n    if info < 0:\n        raise ValueError(f\"illegal value in argument {-info} of internal {driver}\")\n    else:\n        raise linalg.LinAlgError(\n            \"internal fortran routine failed to converge: \"\n            f\"{info} off-diagonal elements of an \"\n            \"intermediate tridiagonal form did not converge\"\n            \" to zero.\"\n        )", "metadata": {}}
{"_id": "mne_mne_utils/linalg.py_sqrtm_sym_code", "title": "sqrtm_sym", "text": "def sqrtm_sym(A, rcond=1e-7, inv=False):\n    \"\"\"Compute the sqrt of a positive, semi-definite matrix (or its inverse).\n\n    Parameters\n    ----------\n    A : ndarray, shape (..., n, n)\n        The array to take the square root of.\n    rcond : float\n        The relative condition number used during reconstruction.\n    inv : bool\n        If True, compute the inverse of the square root rather than the\n        square root itself.\n\n    Returns\n    -------\n    A_sqrt : ndarray, shape (..., n, n)\n        The (possibly inverted) square root of A.\n    s : ndarray, shape (..., n)\n        The original square root singular values (not inverted).\n    \"\"\"\n    # Same as linalg.sqrtm(C) but faster, also yields the eigenvalues\n    return _sym_mat_pow(A, -0.5 if inv else 0.5, rcond, return_s=True)", "metadata": {}}
{"_id": "mne_mne_utils/linalg.py_pinvh_code", "title": "pinvh", "text": "def pinvh(a, rtol=None):\n    \"\"\"Compute a pseudo-inverse of a Hermitian matrix.\n\n    Parameters\n    ----------\n    a : ndarray, shape (n, n)\n        The Hermitian array to invert.\n    rtol : float | None\n        The relative tolerance.\n\n    Returns\n    -------\n    a_pinv : ndarray, shape (n, n)\n        The pseudo-inverse of a.\n    \"\"\"\n    s, u = np.linalg.eigh(a)\n    del a\n    if rtol is None:\n        rtol = s.size * np.finfo(s.dtype).eps\n    maxS = np.max(np.abs(s))\n    above_cutoff = abs(s) > maxS * rtol\n    psigma_diag = 1.0 / s[above_cutoff]\n    u = u[:, above_cutoff]\n    return (u * psigma_diag) @ u.conj().T", "metadata": {}}
{"_id": "mne_mne_utils/linalg.py_pinv_code", "title": "pinv", "text": "def pinv(a, rtol=None):\n    \"\"\"Compute a pseudo-inverse of a matrix.\n\n    Parameters\n    ----------\n    a : ndarray, shape (n, m)\n        The array to invert.\n    rtol : float | None\n        The relative tolerance.\n\n    Returns\n    -------\n    a_pinv : ndarray, shape (m, n)\n        The pseudo-inverse of a.\n    \"\"\"\n    u, s, vh = _safe_svd(a, full_matrices=False)\n    del a\n    maxS = np.max(s)\n    if rtol is None:\n        rtol = max(vh.shape + u.shape) * np.finfo(u.dtype).eps\n    rank = np.sum(s > maxS * rtol)\n    u = u[:, :rank]\n    u /= s[:rank]\n    return (u @ vh[:rank]).conj().T", "metadata": {}}
{"_id": "mne_mne_utils/_logging.py_verbose_code", "title": "verbose", "text": "def verbose(function: _FuncT) -> _FuncT:\n    \"\"\"Verbose decorator to allow functions to override log-level.\n\n    Parameters\n    ----------\n    function : callable\n        Function to be decorated by setting the verbosity level.\n\n    Returns\n    -------\n    dec : callable\n        The decorated function.\n\n    See Also\n    --------\n    set_log_level\n    set_config\n\n    Notes\n    -----\n    This decorator is used to set the verbose level during a function or method\n    call, such as :func:`mne.compute_covariance`. The `verbose` keyword\n    argument can be 'DEBUG', 'INFO', 'WARNING', 'ERROR', 'CRITICAL', True (an\n    alias for 'INFO'), or False (an alias for 'WARNING'). To set the global\n    verbosity level for all functions, use :func:`mne.set_log_level`.\n\n    This function also serves as a docstring filler.\n\n    Examples\n    --------\n    You can use the ``verbose`` argument to set the verbose level on the fly::\n\n        >>> import mne\n        >>> cov = mne.compute_raw_covariance(raw, verbose='WARNING')  # doctest: +SKIP\n        >>> cov = mne.compute_raw_covariance(raw, verbose='INFO')  # doctest: +SKIP\n        Using up to 49 segments\n        Number of samples used : 5880\n        [done]\n    \"\"\"  # noqa: E501\n    # See https://decorator.readthedocs.io/en/latest/tests.documentation.html\n    # #dealing-with-third-party-decorators\n    try:\n        fill_doc(function)\n    except TypeError:  # nothing to add\n        pass\n\n    # Anything using verbose should have `verbose=None` in the signature.\n    # This code path will raise an error if this is not the case.\n    body = \"\"\"\\\ndef %(name)s(%(signature)s):\\n\n    try:\n        do_level_change = verbose is not None\n    except (NameError, UnboundLocalError):\n        raise RuntimeError('Function/method %%s does not accept verbose '\n                           'parameter' %% (_function_,)) from None\n    if do_level_change:\n        with _use_log_level_(verbose):\n            return _function_(%(shortsignature)s)\n    else:\n        return _function_(%(shortsignature)s)\"\"\"\n    evaldict = dict(_use_log_level_=use_log_level, _function_=function)\n    fm = FunctionMaker(function)\n    attrs = dict(\n        __wrapped__=function,\n        __qualname__=function.__qualname__,\n        __globals__=function.__globals__,\n    )\n    return fm.make(body, evaldict, addsource=True, **attrs)", "metadata": {}}
{"_id": "mne_mne_utils/_logging.py_set_log_level_code", "title": "set_log_level", "text": "def set_log_level(verbose=None, return_old_level=False, add_frames=None):\n    \"\"\"Set the logging level.\n\n    Parameters\n    ----------\n    verbose : bool, str, int, or None\n        The verbosity of messages to print. If a str, it can be either DEBUG,\n        INFO, WARNING, ERROR, or CRITICAL. Note that these are for\n        convenience and are equivalent to passing in logging.DEBUG, etc.\n        For bool, True is the same as 'INFO', False is the same as 'WARNING'.\n        If None, the environment variable MNE_LOGGING_LEVEL is read, and if\n        it doesn't exist, defaults to INFO.\n    return_old_level : bool\n        If True, return the old verbosity level.\n    %(add_frames)s\n\n    Returns\n    -------\n    old_level : int\n        The old level. Only returned if ``return_old_level`` is True.\n    \"\"\"\n    old_verbose = logger.level\n    verbose = _parse_verbose(verbose)\n\n    if verbose != old_verbose:\n        logger.setLevel(verbose)\n    if add_frames is not None:\n        _filter.add_frames = int(add_frames)\n        fmt = \"%(frame_info)s \" if add_frames else \"\"\n        fmt += \"%(message)s\"\n        fmt = logging.Formatter(fmt)\n        for handler in logger.handlers:\n            handler.setFormatter(fmt)\n    return old_verbose if return_old_level else None", "metadata": {}}
{"_id": "mne_mne_utils/_logging.py_set_log_file_code", "title": "set_log_file", "text": "def set_log_file(fname=None, output_format=\"%(message)s\", overwrite=None):\n    \"\"\"Set the log to print to a file.\n\n    Parameters\n    ----------\n    fname : path-like | None\n        Filename of the log to print to. If None, stdout is used.\n        To suppress log outputs, use set_log_level('WARNING').\n    output_format : str\n        Format of the output messages. See the following for examples:\n\n            https://docs.python.org/dev/howto/logging.html\n\n        e.g., \"%(asctime)s - %(levelname)s - %(message)s\".\n    overwrite : bool | None\n        Overwrite the log file (if it exists). Otherwise, statements\n        will be appended to the log (default). None is the same as False,\n        but additionally raises a warning to notify the user that log\n        entries will be appended.\n    \"\"\"\n    _remove_close_handlers(logger)\n    if fname is not None:\n        if op.isfile(fname) and overwrite is None:\n            # Don't use warn() here because we just want to\n            # emit a warnings.warn here (not logger.warn)\n            warnings.warn(\n                \"Log entries will be appended to the file. Use \"\n                \"overwrite=False to avoid this message in the \"\n                \"future.\",\n                RuntimeWarning,\n                stacklevel=2,\n            )\n            overwrite = False\n        mode = \"w\" if overwrite else \"a\"\n        lh = logging.FileHandler(fname, mode=mode)\n    else:\n        \"\"\"we should just be able to do:\n            lh = logging.StreamHandler(sys.stdout)\n        but because doctests uses some magic on stdout, we have to do this:\n        \"\"\"\n        lh = logging.StreamHandler(WrapStdOut())\n\n    lh.setFormatter(logging.Formatter(output_format))\n    # actually add the stream handler\n    logger.addHandler(lh)", "metadata": {}}
{"_id": "mne_mne_utils/_logging.py_warn_code", "title": "warn", "text": "def warn(message, category=RuntimeWarning, module=\"mne\", ignore_namespaces=(\"mne\",)):\n    \"\"\"Emit a warning with trace outside the mne namespace.\n\n    This function takes arguments like warnings.warn, and sends messages\n    using both ``warnings.warn`` and ``logger.warn``. Warnings can be\n    generated deep within nested function calls. In order to provide a\n    more helpful warning, this function traverses the stack until it\n    reaches a frame outside the ``mne`` namespace that caused the error.\n\n    Parameters\n    ----------\n    message : str\n        Warning message.\n    category : instance of Warning\n        The warning class. Defaults to ``RuntimeWarning``.\n    module : str\n        The name of the module emitting the warning.\n    ignore_namespaces : list of str\n        Namespaces to ignore when traversing the stack.\n\n        .. versionadded:: 0.24\n    \"\"\"\n    root_dirs = [importlib.import_module(ns) for ns in ignore_namespaces]\n    root_dirs = [op.dirname(ns.__file__) for ns in root_dirs]\n    frame = None\n    if logger.level <= logging.WARNING:\n        frame = inspect.currentframe()\n        while frame:\n            fname = frame.f_code.co_filename\n            lineno = frame.f_lineno\n            # in verbose dec\n            if not _verbose_dec_re.search(fname):\n                # treat tests as scripts\n                # and don't capture unittest/case.py (assert_raises)\n                if (\n                    not (\n                        any(fname.startswith(rd) for rd in root_dirs)\n                        or (\"unittest\" in fname and \"case\" in fname)\n                    )\n                    or op.basename(op.dirname(fname)) == \"tests\"\n                ):\n                    break\n            frame = frame.f_back\n        del frame\n        # We need to use this instead of warn(message, category, stacklevel)\n        # because we move out of the MNE stack, so warnings won't properly\n        # recognize the module name (and our warnings.simplefilter will fail)\n        warnings.warn_explicit(\n            message,\n            category,\n            fname,\n            lineno,\n            module,\n            globals().get(\"__warningregistry__\", {}),\n        )\n    # To avoid a duplicate warning print, we only emit the logger.warning if\n    # one of the handlers is a FileHandler. See gh-5592\n    # But it's also nice to be able to do:\n    # with mne.utils.use_log_level('warning', add_frames=3):\n    # so also check our add_frames attribute.\n    if (\n        any(\n            isinstance(h, logging.FileHandler) or getattr(h, \"_mne_file_like\", False)\n            for h in logger.handlers\n        )\n        or _filter.add_frames\n    ):\n        logger.warning(message)", "metadata": {}}
{"_id": "mne_mne_utils/_logging.py_filter_out_warnings_code", "title": "filter_out_warnings", "text": "def filter_out_warnings(warn_record, category=None, match=None):\n    r\"\"\"Remove particular records from ``warn_record``.\n\n    This helper takes a list of :class:`warnings.WarningMessage` objects,\n    and remove those matching category and/or text.\n\n    Parameters\n    ----------\n    category: WarningMessage type | None\n       class of the message to filter out\n\n    match : str | None\n        text or regex that matches the error message to filter out\n    \"\"\"\n    regexp = re.compile(\".*\" if match is None else match)\n    is_category = [\n        w.category == category if category is not None else True\n        for w in warn_record._list\n    ]\n    is_match = [regexp.match(w.message.args[0]) is not None for w in warn_record._list]\n    ind = [ind for ind, (c, m) in enumerate(zip(is_category, is_match)) if c and m]\n\n    for i in reversed(ind):\n        warn_record._list.pop(i)", "metadata": {}}
{"_id": "mne_mne_utils/_logging.py_wrapped_stdout_code", "title": "wrapped_stdout", "text": "def wrapped_stdout(indent=\"\", cull_newlines=False):\n    \"\"\"Wrap stdout writes to logger.info, with an optional indent prefix.\n\n    Parameters\n    ----------\n    indent : str\n        The indentation to add.\n    cull_newlines : bool\n        If True, cull any new/blank lines at the end.\n    \"\"\"\n    orig_stdout = sys.stdout\n    my_out = ClosingStringIO()\n    sys.stdout = my_out\n    try:\n        yield\n    finally:\n        sys.stdout = orig_stdout\n        pending_newlines = 0\n        for line in my_out.getvalue().split(\"\\n\"):\n            if not line.strip() and cull_newlines:\n                pending_newlines += 1\n                continue\n            for _ in range(pending_newlines):\n                logger.info(\"\\n\")\n            logger.info(indent + line)", "metadata": {}}
{"_id": "mne_mne_utils/_logging.py_getvalue_code", "title": "getvalue", "text": "def getvalue(self, close=True):\n        \"\"\"Get the value.\"\"\"\n        out = super().getvalue()\n        if close:\n            self.close()\n        return out", "metadata": {}}
{"_id": "mne_mne_utils/misc.py_pformat_code", "title": "pformat", "text": "def pformat(temp, **fmt):\n    \"\"\"Format a template string partially.\n\n    Examples\n    --------\n    >>> pformat(\"{a}_{b}\", a='x')\n    'x_{b}'\n    \"\"\"\n    formatter = Formatter()\n    mapping = _FormatDict(fmt)\n    return formatter.vformat(temp, (), mapping)", "metadata": {}}
{"_id": "mne_mne_utils/misc.py_run_subprocess_code", "title": "run_subprocess", "text": "def run_subprocess(command, return_code=False, verbose=None, *args, **kwargs):\n    \"\"\"Run command using subprocess.Popen.\n\n    Run command and wait for command to complete. If the return code was zero\n    then return, otherwise raise CalledProcessError.\n    By default, this will also add stdout= and stderr=subproces.PIPE\n    to the call to Popen to suppress printing to the terminal.\n\n    Parameters\n    ----------\n    command : list of str | str\n        Command to run as subprocess (see subprocess.Popen documentation).\n    return_code : bool\n        If True, return the return code instead of raising an error if it's\n        non-zero.\n\n        .. versionadded:: 0.20\n    %(verbose)s\n    *args, **kwargs : arguments\n        Additional arguments to pass to subprocess.Popen.\n\n    Returns\n    -------\n    stdout : str\n        Stdout returned by the process.\n    stderr : str\n        Stderr returned by the process.\n    code : int\n        The return code, only returned if ``return_code == True``.\n    \"\"\"\n    all_out = \"\"\n    all_err = \"\"\n    # non-blocking adapted from https://stackoverflow.com/questions/375427/non-blocking-read-on-a-subprocess-pipe-in-python#4896288  # noqa: E501\n    out_q = Queue()\n    err_q = Queue()\n    control_stdout = \"stdout\" not in kwargs\n    control_stderr = \"stderr\" not in kwargs\n    with running_subprocess(command, *args, **kwargs) as p:\n        if control_stdout:\n            out_t = Thread(target=_enqueue_output, args=(p.stdout, out_q))\n            out_t.daemon = True\n            out_t.start()\n        if control_stderr:\n            err_t = Thread(target=_enqueue_output, args=(p.stderr, err_q))\n            err_t.daemon = True\n            err_t.start()\n        while True:\n            do_break = p.poll() is not None\n            # read all current lines without blocking\n            while True:  # process stdout\n                try:\n                    out = out_q.get(timeout=0.01)\n                except Empty:\n                    break\n                else:\n                    out = out.decode(\"utf-8\")\n                    log_out = out.removesuffix(\"\\n\")\n                    logger.info(log_out)\n                    all_out += out\n\n            while True:  # process stderr\n                try:\n                    err = err_q.get(timeout=0.01)\n                except Empty:\n                    break\n                else:\n                    err = err.decode(\"utf-8\")\n                    err_out = err.removesuffix(\"\\n\")\n\n                    # Leave this as logger.warning rather than warn(...) to\n                    # mirror the logger.info above for stdout. This function\n                    # is basically just a version of subprocess.call, and\n                    # shouldn't emit Python warnings due to stderr outputs\n                    # (the calling function can check for stderr output and\n                    # emit a warning if it wants).\n                    logger.warning(err_out)\n                    all_err += err\n\n            if do_break:\n                break\n    output = (all_out, all_err)\n\n    if return_code:\n        output = output + (p.returncode,)\n    elif p.returncode:\n        stdout = all_out if control_stdout else None\n        stderr = all_err if control_stderr else None\n        raise subprocess.CalledProcessError(\n            p.returncode, command, output=stdout, stderr=stderr\n        )\n\n    return output", "metadata": {}}
{"_id": "mne_mne_utils/misc.py_running_subprocess_code", "title": "running_subprocess", "text": "def running_subprocess(command, after=\"wait\", verbose=None, *args, **kwargs):\n    \"\"\"Context manager to do something with a command running via Popen.\n\n    Parameters\n    ----------\n    command : list of str | str\n        Command to run as subprocess (see :class:`python:subprocess.Popen`).\n    after : str\n        Can be:\n\n        - \"wait\" to use :meth:`~python:subprocess.Popen.wait`\n        - \"communicate\" to use :meth:`~python.subprocess.Popen.communicate`\n        - \"terminate\" to use :meth:`~python:subprocess.Popen.terminate`\n        - \"kill\" to use :meth:`~python:subprocess.Popen.kill`\n\n    %(verbose)s\n    *args, **kwargs : arguments\n        Additional arguments to pass to subprocess.Popen.\n\n    Returns\n    -------\n    p : instance of Popen\n        The process.\n    \"\"\"\n    _validate_type(after, str, \"after\")\n    _check_option(\"after\", after, [\"wait\", \"terminate\", \"kill\", \"communicate\"])\n    contexts = list()\n    for stdxxx in (\"stderr\", \"stdout\"):\n        if stdxxx not in kwargs:\n            kwargs[stdxxx] = subprocess.PIPE\n            contexts.append(stdxxx)\n\n    # Check the PATH environment variable. If run_subprocess() is to be called\n    # frequently this should be refactored so as to only check the path once.\n    env = kwargs.get(\"env\", os.environ)\n    if any(p.startswith(\"~\") for p in env[\"PATH\"].split(os.pathsep)):\n        warn(\n            \"Your PATH environment variable contains at least one path \"\n            'starting with a tilde (\"~\") character. Such paths are not '\n            \"interpreted correctly from within Python. It is recommended \"\n            'that you use \"$HOME\" instead of \"~\".'\n        )\n    if isinstance(command, str):\n        command_str = command\n    else:\n        command = [str(s) for s in command]\n        command_str = \" \".join(s for s in command)\n    logger.info(f\"Running subprocess: {command_str}\")\n    try:\n        p = subprocess.Popen(command, *args, **kwargs)\n    except Exception:\n        if isinstance(command, str):\n            command_name = command.split()[0]\n        else:\n            command_name = command[0]\n        logger.error(f\"Command not found: {command_name}\")\n        raise\n    try:\n        with ExitStack() as stack:\n            for context in contexts:\n                stack.enter_context(getattr(p, context))\n            yield p\n    finally:\n        getattr(p, after)()\n        p.wait()", "metadata": {}}
{"_id": "mne_mne_utils/misc.py_sizeof_fmt_code", "title": "sizeof_fmt", "text": "def sizeof_fmt(num):\n    \"\"\"Turn number of bytes into human-readable str.\n\n    Parameters\n    ----------\n    num : int\n        The number of bytes.\n\n    Returns\n    -------\n    size : str\n        The size in human-readable format.\n    \"\"\"\n    units = [\"bytes\", \"KiB\", \"MiB\", \"GiB\", \"TiB\", \"PiB\"]\n    decimals = [0, 0, 1, 2, 2, 2]\n    if num > 1:\n        exponent = min(int(log(num, 1024)), len(units) - 1)\n        quotient = float(num) / 1024**exponent\n        unit = units[exponent]\n        num_decimals = decimals[exponent]\n        format_string = f\"{{0:.{num_decimals}f}} {{1}}\"\n        return format_string.format(quotient, unit)\n    if num == 0:\n        return \"0 bytes\"\n    if num == 1:\n        return \"1 byte\"", "metadata": {}}
{"_id": "mne_mne_utils/misc.py_repr_html_code", "title": "repr_html", "text": "def repr_html(f):\n    \"\"\"Decorate _repr_html_ methods.\n\n    If a _repr_html_ method is decorated with this decorator, the repr in a\n    notebook will show HTML or plain text depending on the config value\n    MNE_REPR_HTML (by default \"true\", which will render HTML).\n\n    Parameters\n    ----------\n    f : function\n        The function to decorate.\n\n    Returns\n    -------\n    wrapper : function\n        The decorated function.\n    \"\"\"\n    from ..utils import get_config\n\n    def wrapper(*args, **kwargs):\n        if get_config(\"MNE_REPR_HTML\", \"true\").lower() == \"false\":\n            import html\n\n            r = \"<pre>\" + html.escape(repr(args[0])) + \"</pre>\"\n            return r.replace(\"\\n\", \"<br/>\")\n        else:\n            return f(*args, **kwargs)\n\n    return wrapper", "metadata": {}}
{"_id": "mne_mne_utils/mixin.py_metadata_code", "title": "metadata", "text": "def metadata(self):\n        \"\"\"Get the metadata.\"\"\"\n        return self._metadata", "metadata": {}}
{"_id": "mne_mne_utils/mixin.py_time_as_index_code", "title": "time_as_index", "text": "def time_as_index(self, times, use_rounding=False):\n        \"\"\"Convert time to indices.\n\n        Parameters\n        ----------\n        times : list-like | float | int\n            List of numbers or a number representing points in time.\n        use_rounding : bool\n            If True, use rounding (instead of truncation) when converting\n            times to indices. This can help avoid non-unique indices.\n\n        Returns\n        -------\n        index : ndarray\n            Indices corresponding to the times supplied.\n        \"\"\"\n        from ..source_estimate import _BaseSourceEstimate\n\n        if isinstance(self, _BaseSourceEstimate):\n            sfreq = 1.0 / self.tstep\n        else:\n            sfreq = self.info[\"sfreq\"]\n        index = (np.atleast_1d(times) - self.times[0]) * sfreq\n        if use_rounding:\n            index = np.round(index)\n        return index.astype(int)", "metadata": {}}
{"_id": "mne_mne_utils/mixin.py_times_code", "title": "times", "text": "def times(self):\n        \"\"\"Time vector in seconds.\"\"\"\n        return self._times_readonly", "metadata": {}}
{"_id": "mne_mne_utils/mixin.py_tmin_code", "title": "tmin", "text": "def tmin(self):\n        \"\"\"First time point.\"\"\"\n        return self.times[0]", "metadata": {}}
{"_id": "mne_mne_utils/mixin.py_tmax_code", "title": "tmax", "text": "def tmax(self):\n        \"\"\"Last time point.\"\"\"\n        return self.times[-1]", "metadata": {}}
{"_id": "mne_mne_utils/mixin.py_crop_code", "title": "crop", "text": "def crop(self, tmin=None, tmax=None, include_tmax=True, verbose=None):\n        \"\"\"Crop data to a given time interval.\n\n        Parameters\n        ----------\n        tmin : float | None\n            Start time of selection in seconds.\n        tmax : float | None\n            End time of selection in seconds.\n        %(include_tmax)s\n        %(verbose)s\n\n        Returns\n        -------\n        inst : instance of Raw, Epochs, Evoked, AverageTFR, or SourceEstimate\n            The cropped time-series object, modified in-place.\n\n        Notes\n        -----\n        %(notes_tmax_included_by_default)s\n        \"\"\"\n        t_vars = dict(tmin=tmin, tmax=tmax)\n        for name, t_var in t_vars.items():\n            _validate_type(\n                t_var,\n                types=(\"numeric\", None),\n                item_name=name,\n            )\n\n        if tmin is None:\n            tmin = self.tmin\n        elif tmin < self.tmin:\n            warn(\n                f\"tmin is not in time interval. tmin is set to \"\n                f\"{type(self)}.tmin ({self.tmin:g} s)\"\n            )\n            tmin = self.tmin\n\n        if tmax is None:\n            tmax = self.tmax\n        elif tmax > self.tmax:\n            warn(\n                f\"tmax is not in time interval. tmax is set to \"\n                f\"{type(self)}.tmax ({self.tmax:g} s)\"\n            )\n            tmax = self.tmax\n            include_tmax = True\n\n        mask = _time_mask(\n            self.times, tmin, tmax, sfreq=self.info[\"sfreq\"], include_tmax=include_tmax\n        )\n        self._set_times(self.times[mask])\n        self._raw_times = self._raw_times[mask]\n        self._update_first_last()\n        self._data = self._data[..., mask]\n\n        return self", "metadata": {}}
{"_id": "mne_mne_utils/mixin.py_decimate_code", "title": "decimate", "text": "def decimate(self, decim, offset=0, *, verbose=None):\n        \"\"\"Decimate the time-series data.\n\n        Parameters\n        ----------\n        %(decim)s\n        %(offset_decim)s\n        %(verbose)s\n\n        Returns\n        -------\n        inst : MNE-object\n            The decimated object.\n\n        See Also\n        --------\n        mne.Epochs.resample\n        mne.io.Raw.resample\n\n        Notes\n        -----\n        %(decim_notes)s\n\n        If ``decim`` is 1, this method does not copy the underlying data.\n\n        .. versionadded:: 0.10.0\n\n        References\n        ----------\n        .. footbibliography::\n        \"\"\"\n        # if epochs have frequencies, they are not in time (EpochsTFR)\n        # and so do not need to be checked whether they have been\n        # appropriately filtered to avoid aliasing\n        from ..epochs import BaseEpochs\n        from ..evoked import Evoked\n        from ..time_frequency import BaseTFR\n\n        # This should be the list of classes that inherit\n        _validate_type(self, (BaseEpochs, Evoked, BaseTFR), \"inst\")\n        decim, offset, new_sfreq = _check_decim(\n            self.info, decim, offset, check_filter=not hasattr(self, \"freqs\")\n        )\n        start_idx = int(round(-self._raw_times[0] * (self.info[\"sfreq\"] * self._decim)))\n        self._decim *= decim\n        i_start = start_idx % self._decim + offset\n        decim_slice = slice(i_start, None, self._decim)\n        with self.info._unlock():\n            self.info[\"sfreq\"] = new_sfreq\n\n        if self.preload:\n            if decim != 1:\n                self._data = self._data[..., decim_slice].copy()\n                self._raw_times = self._raw_times[decim_slice].copy()\n            else:\n                self._data = np.ascontiguousarray(self._data)\n            self._decim_slice = slice(None)\n            self._decim = 1\n        else:\n            self._decim_slice = decim_slice\n        self._set_times(self._raw_times[self._decim_slice])\n        self._update_first_last()\n        return self", "metadata": {}}
{"_id": "mne_mne_utils/mixin.py_shift_time_code", "title": "shift_time", "text": "def shift_time(self, tshift, relative=True):\n        \"\"\"Shift time scale in epoched or evoked data.\n\n        Parameters\n        ----------\n        tshift : float\n            The (absolute or relative) time shift in seconds. If ``relative``\n            is True, positive tshift increases the time value associated with\n            each sample, while negative tshift decreases it.\n        relative : bool\n            If True, increase or decrease time values by ``tshift`` seconds.\n            Otherwise, shift the time values such that the time of the first\n            sample equals ``tshift``.\n\n        Returns\n        -------\n        epochs : MNE-object\n            The modified instance.\n\n        Notes\n        -----\n        This method allows you to shift the *time* values associated with each\n        data sample by an arbitrary amount. It does *not* resample the signal\n        or change the *data* values in any way.\n        \"\"\"\n        _check_preload(self, \"shift_time\")\n        start = tshift + (self.times[0] if relative else 0.0)\n        new_times = start + np.arange(len(self.times)) / self.info[\"sfreq\"]\n        self._set_times(new_times)\n        self._update_first_last()\n        return self", "metadata": {}}
{"_id": "mne_mne_utils/check.py_check_fname_code", "title": "check_fname", "text": "def check_fname(fname, filetype, endings, endings_err=()):\n    \"\"\"Enforce MNE filename conventions.\n\n    Parameters\n    ----------\n    fname : path-like\n        Name of the file.\n    filetype : str\n        Type of file. e.g., ICA, Epochs, etc.\n    endings : tuple\n        Acceptable endings for the filename.\n    endings_err : tuple\n        Obligatory possible endings for the filename.\n    \"\"\"\n    _validate_type(fname, \"path-like\", \"fname\")\n    fname = str(fname)\n    if len(endings_err) > 0 and not fname.endswith(endings_err):\n        print_endings = \" or \".join([\", \".join(endings_err[:-1]), endings_err[-1]])\n        raise OSError(\n            f\"The filename ({fname}) for file type {filetype} must end \"\n            f\"with {print_endings}\"\n        )\n    print_endings = \" or \".join([\", \".join(endings[:-1]), endings[-1]])\n    if not fname.endswith(endings):\n        warn(\n            f\"This filename ({fname}) does not conform to MNE naming conventions. \"\n            f\"All {filetype} files should end with {print_endings}\"\n        )", "metadata": {}}
{"_id": "mne_mne_utils/check.py_check_version_code", "title": "check_version", "text": "def check_version(library, min_version=\"0.0\", *, strip=True, return_version=False):\n    r\"\"\"Check minimum library version required.\n\n    Parameters\n    ----------\n    library : str\n        The library name to import. Must have a ``__version__`` property.\n    min_version : str\n        The minimum version string. Anything that matches\n        ``'(\\d+ | [a-z]+ | \\.)'``. Can also be empty to skip version\n        check (just check for library presence).\n    strip : bool\n        If True (default), then PEP440 development markers like ``.devN``\n        will be stripped from the version. This makes it so that\n        ``check_version('mne', '1.1')`` will be ``True`` even when on version\n        ``'1.1.dev0'`` (prerelease/dev version). This option is provided for\n        backward compatibility with the behavior of ``LooseVersion``, and\n        diverges from how modern parsing in ``packaging.version.parse`` works.\n\n        .. versionadded:: 1.0\n    return_version : bool\n        If True (default False), also return the version (can be None if the\n        library is missing).\n\n        .. versionadded:: 1.0\n\n    Returns\n    -------\n    ok : bool\n        True if the library exists with at least the specified version.\n    version : str | None\n        The version. Only returned when ``return_version=True``.\n    \"\"\"\n    ok = True\n    version = None\n    try:\n        library = import_module(library)\n    except ImportError:\n        ok = False\n    else:\n        check_version = min_version and min_version != \"0.0\"\n        get_version = check_version or return_version\n        if get_version:\n            version = library.__version__\n            if strip:\n                version = _strip_dev(version)\n        if check_version:\n            if _compare_version(version, \"<\", min_version):\n                ok = False\n    out = (ok, version) if return_version else ok\n    return out", "metadata": {}}
{"_id": "mne_mne_utils/check.py_check_random_state_code", "title": "check_random_state", "text": "def check_random_state(seed):\n    \"\"\"Turn seed into a numpy.random.mtrand.RandomState instance.\n\n    If seed is None, return the RandomState singleton used by np.random.mtrand.\n    If seed is an int, return a new RandomState instance seeded with seed.\n    If seed is already a RandomState instance, return it.\n    Otherwise raise ValueError.\n    \"\"\"\n    if seed is None or seed is np.random:\n        return np.random.mtrand._rand\n    if isinstance(seed, int | np.integer):\n        return np.random.mtrand.RandomState(seed)\n    if isinstance(seed, np.random.mtrand.RandomState):\n        return seed\n    if isinstance(seed, np.random.Generator):\n        return seed\n    raise ValueError(\n        f\"{seed!r} cannot be used to seed a numpy.random.mtrand.RandomState instance\"\n    )", "metadata": {}}
{"_id": "mne_mne_utils/check.py_cast_path_to_str_code", "title": "cast_path_to_str", "text": "def cast_path_to_str(data: dict) -> dict:\n        \"\"\"Cast all paths value to string in data.\"\"\"\n        keys2cast = []\n        for key, value in data.items():\n            if isinstance(value, dict):\n                cast_path_to_str(value)\n            if isinstance(value, Path):\n                data[key] = value.as_posix()\n            if isinstance(key, Path):\n                keys2cast.append(key)\n        for key in keys2cast:\n            data[key.as_posix()] = data.pop(key)\n        return data", "metadata": {}}
{"_id": "mne_mne_utils/check.py_write_hdf5_code", "title": "write_hdf5", "text": "def write_hdf5(fname, data, *args, **kwargs):\n        \"\"\"Write h5 and cast all paths to string in data.\"\"\"\n        if isinstance(data, dict):\n            data = cast_path_to_str(data)\n        elif isinstance(data, list):\n            for k, elt in enumerate(data):\n                if isinstance(elt, dict):\n                    data[k] = cast_path_to_str(elt)\n        h5io.write_hdf5(fname, data, *args, **kwargs)", "metadata": {}}
{"_id": "mne_mne_utils/config.py_set_cache_dir_code", "title": "set_cache_dir", "text": "def set_cache_dir(cache_dir):\n    \"\"\"Set the directory to be used for temporary file storage.\n\n    This directory is used by joblib to store memmapped arrays,\n    which reduces memory requirements and speeds up parallel\n    computation.\n\n    Parameters\n    ----------\n    cache_dir : str or None\n        Directory to use for temporary file storage. None disables\n        temporary file storage.\n    \"\"\"\n    if cache_dir is not None and not op.exists(cache_dir):\n        raise OSError(f\"Directory {cache_dir} does not exist\")\n\n    set_config(\"MNE_CACHE_DIR\", cache_dir, set_env=False)", "metadata": {}}
{"_id": "mne_mne_utils/config.py_set_memmap_min_size_code", "title": "set_memmap_min_size", "text": "def set_memmap_min_size(memmap_min_size):\n    \"\"\"Set the minimum size for memmaping of arrays for parallel processing.\n\n    Parameters\n    ----------\n    memmap_min_size : str or None\n        Threshold on the minimum size of arrays that triggers automated memory\n        mapping for parallel processing, e.g., '1M' for 1 megabyte.\n        Use None to disable memmaping of large arrays.\n    \"\"\"\n    _validate_type(memmap_min_size, (str, None), \"memmap_min_size\")\n    if memmap_min_size is not None:\n        if memmap_min_size[-1] not in [\"K\", \"M\", \"G\"]:\n            raise ValueError(\n                \"The size has to be given in kilo-, mega-, or \"\n                f\"gigabytes, e.g., 100K, 500M, 1G, got {repr(memmap_min_size)}\"\n            )\n\n    set_config(\"MNE_MEMMAP_MIN_SIZE\", memmap_min_size, set_env=False)", "metadata": {}}
{"_id": "mne_mne_utils/config.py_get_config_path_code", "title": "get_config_path", "text": "def get_config_path(home_dir=None):\n    r\"\"\"Get path to standard mne-python config file.\n\n    Parameters\n    ----------\n    home_dir : str | None\n        The folder that contains the .mne config folder.\n        If None, it is found automatically.\n\n    Returns\n    -------\n    config_path : str\n        The path to the mne-python configuration file. On windows, this\n        will be '%USERPROFILE%\\.mne\\mne-python.json'. On every other\n        system, this will be ~/.mne/mne-python.json.\n    \"\"\"\n    val = op.join(_get_extra_data_path(home_dir=home_dir), \"mne-python.json\")\n    return val", "metadata": {}}
{"_id": "mne_mne_utils/config.py_get_config_code", "title": "get_config", "text": "def get_config(key=None, default=None, raise_error=False, home_dir=None, use_env=True):\n    \"\"\"Read MNE-Python preferences from environment or config file.\n\n    Parameters\n    ----------\n    key : None | str\n        The preference key to look for. The os environment is searched first,\n        then the mne-python config file is parsed.\n        If None, all the config parameters present in environment variables or\n        the path are returned. If key is an empty string, a list of all valid\n        keys (but not values) is returned.\n    default : str | None\n        Value to return if the key is not found.\n    raise_error : bool\n        If True, raise an error if the key is not found (instead of returning\n        default).\n    home_dir : str | None\n        The folder that contains the .mne config folder.\n        If None, it is found automatically.\n    use_env : bool\n        If True, consider env vars, if available.\n        If False, only use MNE-Python configuration file values.\n\n        .. versionadded:: 0.18\n\n    Returns\n    -------\n    value : dict | str | None\n        The preference key value.\n\n    See Also\n    --------\n    set_config\n    \"\"\"\n    _validate_type(key, (str, type(None)), \"key\", \"string or None\")\n\n    if key == \"\":\n        # These are str->str (immutable) so we should just copy the dict\n        # itself, no need for deepcopy\n        return _known_config_types.copy()\n\n    # first, check to see if key is in env\n    if use_env and key is not None and key in os.environ:\n        return os.environ[key]\n\n    # second, look for it in mne-python config file\n    config_path = get_config_path(home_dir=home_dir)\n    if not op.isfile(config_path):\n        config = {}\n    else:\n        config = _load_config(config_path)\n\n    if key is None:\n        # update config with environment variables\n        if use_env:\n            env_keys = set(config).union(_known_config_types).intersection(os.environ)\n            config.update({key: os.environ[key] for key in env_keys})\n        return config\n    elif raise_error is True and key not in config:\n        loc_env = \"the environment or in the \" if use_env else \"\"\n        meth_env = (\n            (f'either os.environ[\"{key}\"] = VALUE for a temporary solution, or ')\n            if use_env\n            else \"\"\n        )\n        extra_env = (\n            \" You can also set the environment variable before running python.\"\n            if use_env\n            else \"\"\n        )\n        meth_file = (\n            f'mne.utils.set_config(\"{key}\", VALUE, set_env=True) for a permanent one'\n        )\n        raise KeyError(\n            f'Key \"{key}\" not found in {loc_env}'\n            f\"the mne-python config file ({config_path}). \"\n            f\"Try {meth_env}{meth_file}.{extra_env}\"\n        )\n    else:\n        return config.get(key, default)", "metadata": {}}
{"_id": "mne_mne_utils/config.py_set_config_code", "title": "set_config", "text": "def set_config(key, value, home_dir=None, set_env=True):\n    \"\"\"Set a MNE-Python preference key in the config file and environment.\n\n    Parameters\n    ----------\n    key : str\n        The preference key to set.\n    value : str |  None\n        The value to assign to the preference key. If None, the key is\n        deleted.\n    home_dir : str | None\n        The folder that contains the .mne config folder.\n        If None, it is found automatically.\n    set_env : bool\n        If True (default), update :data:`os.environ` in addition to\n        updating the MNE-Python config file.\n\n    See Also\n    --------\n    get_config\n    \"\"\"\n    _validate_type(key, \"str\", \"key\")\n    # While JSON allow non-string types, we allow users to override config\n    # settings using env, which are strings, so we enforce that here\n    _validate_type(value, (str, \"path-like\", type(None)), \"value\")\n    if value is not None:\n        value = str(value)\n\n    if key not in _known_config_types and not any(\n        key.startswith(k) for k in _known_config_wildcards\n    ):\n        warn(f'Setting non-standard config type: \"{key}\"')\n\n    # Read all previous values\n    config_path = get_config_path(home_dir=home_dir)\n    if op.isfile(config_path):\n        config = _load_config(config_path, raise_error=True)\n    else:\n        config = dict()\n        logger.info(\n            f\"Attempting to create new mne-python configuration file:\\n{config_path}\"\n        )\n    if value is None:\n        config.pop(key, None)\n        if set_env and key in os.environ:\n            del os.environ[key]\n    else:\n        config[key] = value\n        if set_env:\n            os.environ[key] = value\n        if key == \"MNE_BROWSER_BACKEND\":\n            from ..viz._figure import set_browser_backend\n\n            set_browser_backend(value)\n\n    # Write all values. This may fail if the default directory is not\n    # writeable.\n    directory = op.dirname(config_path)\n    if not op.isdir(directory):\n        os.mkdir(directory)\n    with open(config_path, \"w\") as fid:\n        json.dump(config, fid, sort_keys=True, indent=0)", "metadata": {}}
{"_id": "mne_mne_utils/config.py_get_subjects_dir_code", "title": "get_subjects_dir", "text": "def get_subjects_dir(subjects_dir=None, raise_error=False):\n    \"\"\"Safely use subjects_dir input to return SUBJECTS_DIR.\n\n    Parameters\n    ----------\n    subjects_dir : path-like | None\n        If a value is provided, return subjects_dir. Otherwise, look for\n        SUBJECTS_DIR config and return the result.\n    raise_error : bool\n        If True, raise a KeyError if no value for SUBJECTS_DIR can be found\n        (instead of returning None).\n\n    Returns\n    -------\n    value : Path | None\n        The SUBJECTS_DIR value.\n    \"\"\"\n    from_config = False\n    if subjects_dir is None:\n        subjects_dir = get_config(\"SUBJECTS_DIR\", raise_error=raise_error)\n        from_config = True\n        if subjects_dir is not None:\n            subjects_dir = Path(subjects_dir)\n    if subjects_dir is not None:\n        # Emit a nice error or warning if their config is bad\n        try:\n            subjects_dir = _check_fname(\n                fname=subjects_dir,\n                overwrite=\"read\",\n                must_exist=True,\n                need_dir=True,\n                name=\"subjects_dir\",\n            )\n        except FileNotFoundError:\n            if from_config:\n                msg = (\n                    \"SUBJECTS_DIR in your MNE-Python configuration or environment \"\n                    \"does not exist, consider using mne.set_config to fix it: \"\n                    f\"{subjects_dir}\"\n                )\n                if raise_error:\n                    raise FileNotFoundError(msg) from None\n                else:\n                    warn(msg)\n            elif raise_error:\n                raise\n\n    return subjects_dir", "metadata": {}}
{"_id": "mne_mne_utils/config.py_sys_info_code", "title": "sys_info", "text": "def sys_info(\n    fid=None,\n    show_paths=False,\n    *,\n    dependencies=\"user\",\n    unicode=\"auto\",\n    check_version=True,\n):\n    \"\"\"Print system information.\n\n    This function prints system information useful when triaging bugs.\n\n    Parameters\n    ----------\n    fid : file-like | None\n        The file to write to. Will be passed to :func:`print()`. Can be None to\n        use :data:`sys.stdout`.\n    show_paths : bool\n        If True, print paths for each module.\n    dependencies : 'user' | 'developer'\n        Show dependencies relevant for users (default) or for developers\n        (i.e., output includes additional dependencies).\n    unicode : bool | \"auto\"\n        Include Unicode symbols in output. If \"auto\", corresponds to True on Linux and\n        macOS, and False on Windows.\n\n        .. versionadded:: 0.24\n    check_version : bool | float\n        If True (default), attempt to check that the version of MNE-Python is up to date\n        with the latest release on GitHub. Can be a float to give a different timeout\n        (in sec) from the default (2 sec).\n\n        .. versionadded:: 1.6\n    \"\"\"\n    _validate_type(dependencies, str)\n    _check_option(\"dependencies\", dependencies, (\"user\", \"developer\"))\n    _validate_type(check_version, (bool, \"numeric\"), \"check_version\")\n    _validate_type(unicode, (bool, str), \"unicode\")\n    _check_option(\"unicode\", unicode, (\"auto\", True, False))\n    if unicode == \"auto\":\n        if platform.system() in (\"Darwin\", \"Linux\"):\n            unicode = True\n        else:  # Windows\n            unicode = False\n    ljust = 24 if dependencies == \"developer\" else 21\n    platform_str = platform.platform()\n\n    out = partial(print, end=\"\", file=fid)\n    out(\"Platform\".ljust(ljust) + platform_str + \"\\n\")\n    out(\"Python\".ljust(ljust) + str(sys.version).replace(\"\\n\", \" \") + \"\\n\")\n    out(\"Executable\".ljust(ljust) + sys.executable + \"\\n\")\n    try:\n        cpu_brand = _get_cpu_brand()\n    except Exception:\n        cpu_brand = \"?\"\n    out(\"CPU\".ljust(ljust) + f\"{cpu_brand} \")\n    out(f\"({multiprocessing.cpu_count()} cores)\\n\")\n    out(\"Memory\".ljust(ljust))\n    try:\n        total_memory = _get_total_memory()\n    except UnknownPlatformError:\n        total_memory = \"?\"\n    else:\n        total_memory = f\"{total_memory / 1024**3:.1f}\"  # convert to GiB\n    out(f\"{total_memory} GiB\\n\")\n    out(\"\\n\")\n    ljust -= 3  # account for +/- symbols\n    libs = _get_numpy_libs()\n    unavailable = []\n    use_mod_names = (\n        \"# Core\",\n        \"mne\",\n        \"numpy\",\n        \"scipy\",\n        \"matplotlib\",\n        \"\",\n        \"# Numerical (optional)\",\n        \"sklearn\",\n        \"numba\",\n        \"nibabel\",\n        \"nilearn\",\n        \"dipy\",\n        \"openmeeg\",\n        \"cupy\",\n        \"pandas\",\n        \"h5io\",\n        \"h5py\",\n        \"\",\n        \"# Visualization (optional)\",\n        \"pyvista\",\n        \"pyvistaqt\",\n        \"vtk\",\n        \"qtpy\",\n        \"ipympl\",\n        \"pyqtgraph\",\n        \"mne-qt-browser\",\n        \"ipywidgets\",\n        # \"trame\",  # no version, see https://github.com/Kitware/trame/issues/183\n        \"trame_client\",\n        \"trame_server\",\n        \"trame_vtk\",\n        \"trame_vuetify\",\n        \"\",\n        \"# Ecosystem (optional)\",\n        \"mne-bids\",\n        \"mne-nirs\",\n        \"mne-features\",\n        \"mne-connectivity\",\n        \"mne-icalabel\",\n        \"mne-bids-pipeline\",\n        \"neo\",\n        \"eeglabio\",\n        \"edfio\",\n        \"mffpy\",\n        \"pybv\",\n        \"\",\n    )\n    if dependencies == \"developer\":\n        use_mod_names += (\n            \"# Testing\",\n            \"pytest\",\n            \"statsmodels\",\n            \"numpydoc\",\n            \"flake8\",\n            \"jupyter_client\",\n            \"nbclient\",\n            \"nbformat\",\n            \"pydocstyle\",\n            \"nitime\",\n            \"imageio\",\n            \"imageio-ffmpeg\",\n            \"snirf\",\n            \"\",\n            \"# Documentation\",\n            \"sphinx\",\n            \"sphinx-gallery\",\n            \"pydata-sphinx-theme\",\n            \"\",\n            \"# Infrastructure\",\n            \"decorator\",\n            \"jinja2\",\n            # \"lazy-loader\",\n            \"packaging\",\n            \"pooch\",\n            \"tqdm\",\n            \"\",\n        )\n    try:\n        unicode = unicode and (sys.stdout.encoding.lower().startswith(\"utf\"))\n    except Exception:  # in case someone overrides sys.stdout in an unsafe way\n        unicode = False\n    mne_version_good = True\n    for mi, mod_name in enumerate(use_mod_names):\n        # upcoming break\n        if mod_name == \"\":  # break\n            if unavailable:\n                out(\"\u2514\u2610 \" if unicode else \" - \")\n                out(\"unavailable\".ljust(ljust))\n                out(f\"{', '.join(unavailable)}\\n\")\n                unavailable = []\n            if mi != len(use_mod_names) - 1:\n                out(\"\\n\")\n            continue\n        elif mod_name.startswith(\"# \"):  # header\n            mod_name = mod_name.replace(\"# \", \"\")\n            out(f\"{mod_name}\\n\")\n            continue\n        pre = \"\u251c\"\n        last = use_mod_names[mi + 1] == \"\" and not unavailable\n        if last:\n            pre = \"\u2514\"\n        try:\n            mod = import_module(mod_name.replace(\"-\", \"_\"))\n        except Exception:\n            unavailable.append(mod_name)\n        else:\n            mark = \"\u2611\" if unicode else \"+\"\n            mne_extra = \"\"\n            if mod_name == \"mne\" and check_version:\n                timeout = 2.0 if check_version is True else float(check_version)\n                mne_version_good, mne_extra = _check_mne_version(timeout)\n                if mne_version_good is None:\n                    mne_version_good = True\n                elif not mne_version_good:\n                    mark = \"\u2612\" if unicode else \"X\"\n            out(f\"{pre}{mark} \" if unicode else f\" {mark} \")\n            out(f\"{mod_name}\".ljust(ljust))\n            if mod_name == \"vtk\":\n                vtk_version = mod.vtkVersion()\n                # 9.0 dev has VersionFull but 9.0 doesn't\n                for attr in (\"GetVTKVersionFull\", \"GetVTKVersion\"):\n                    if hasattr(vtk_version, attr):\n                        version = getattr(vtk_version, attr)()\n                        if version != \"\":\n                            out(version)\n                            break\n                else:\n                    out(\"unknown\")\n            else:\n                out(mod.__version__.lstrip(\"v\"))\n            if mod_name == \"numpy\":\n                out(f\" ({libs})\")\n            elif mod_name == \"qtpy\":\n                version, api = _check_qt_version(return_api=True)\n                out(f\" ({api}={version})\")\n            elif mod_name == \"matplotlib\":\n                out(f\" (backend={mod.get_backend()})\")\n            elif mod_name == \"pyvista\":\n                version, renderer = _get_gpu_info()\n                if version is None:\n                    out(\" (OpenGL unavailable)\")\n                else:\n                    out(f\" (OpenGL {version} via {renderer})\")\n            elif mod_name == \"mne\":\n                out(f\" ({mne_extra})\")\n            # Now comes stuff after the version\n            if show_paths:\n                if last:\n                    pre = \"   \"\n                elif unicode:\n                    pre = \"\u2502  \"\n                else:\n                    pre = \" | \"\n                out(f\"\\n{pre}{' ' * ljust}{op.dirname(mod.__file__)}\")\n            out(\"\\n\")\n\n    if not mne_version_good:\n        out(\n            \"\\nTo update to the latest supported release version to get bugfixes and \"\n            \"improvements, visit \"\n            \"https://mne.tools/stable/install/updating.html\\n\"\n        )", "metadata": {}}
{"_id": "mne_mne_utils/_testing.py_requires_mne_code", "title": "requires_mne", "text": "def requires_mne(func):\n    \"\"\"Decorate a function as requiring MNE.\"\"\"\n    return requires_mne_mark()(func)", "metadata": {}}
{"_id": "mne_mne_utils/_testing.py_requires_mne_mark_code", "title": "requires_mne_mark", "text": "def requires_mne_mark():\n    \"\"\"Mark pytest tests that require MNE-C.\"\"\"\n    import pytest\n\n    return pytest.mark.skipif(not has_mne_c(), reason=\"Requires MNE-C\")", "metadata": {}}
{"_id": "mne_mne_utils/_testing.py_requires_openmeeg_mark_code", "title": "requires_openmeeg_mark", "text": "def requires_openmeeg_mark():\n    \"\"\"Mark pytest tests that require OpenMEEG.\"\"\"\n    import pytest\n\n    return pytest.mark.skipif(\n        not check_version(\"openmeeg\", \"2.5.6\"), reason=\"Requires OpenMEEG >= 2.5.6\"\n    )", "metadata": {}}
{"_id": "mne_mne_utils/_testing.py_requires_freesurfer_code", "title": "requires_freesurfer", "text": "def requires_freesurfer(arg):\n    \"\"\"Require Freesurfer.\"\"\"\n    import pytest\n\n    reason = \"Requires Freesurfer\"\n    if isinstance(arg, str):\n        # Calling as  @requires_freesurfer('progname'): return decorator\n        # after checking for progname existence\n        reason += f\" command: {arg}\"\n        try:\n            run_subprocess([arg, \"--version\"])\n        except Exception:\n            skip = True\n        else:\n            skip = False\n        return pytest.mark.skipif(skip, reason=reason)\n    else:\n        # Calling directly as @requires_freesurfer: return decorated function\n        # and just check env var existence\n        return pytest.mark.skipif(not has_freesurfer(), reason=\"Requires Freesurfer\")(\n            arg\n        )", "metadata": {}}
{"_id": "mne_mne_utils/_testing.py_run_command_if_main_code", "title": "run_command_if_main", "text": "def run_command_if_main():\n    \"\"\"Run a given command if it's __main__.\"\"\"\n    local_vars = inspect.currentframe().f_back.f_locals\n    if local_vars.get(\"__name__\", \"\") == \"__main__\":\n        local_vars[\"run\"]()", "metadata": {}}
{"_id": "mne_mne_utils/_testing.py_has_mne_c_code", "title": "has_mne_c", "text": "def has_mne_c():\n    \"\"\"Check for MNE-C.\"\"\"\n    return \"MNE_ROOT\" in os.environ", "metadata": {}}
{"_id": "mne_mne_utils/_testing.py_has_freesurfer_code", "title": "has_freesurfer", "text": "def has_freesurfer():\n    \"\"\"Check for Freesurfer.\"\"\"\n    return \"FREESURFER_HOME\" in os.environ", "metadata": {}}
{"_id": "mne_mne_utils/_testing.py_buggy_mkl_svd_code", "title": "buggy_mkl_svd", "text": "def buggy_mkl_svd(function):\n    \"\"\"Decorate tests that make calls to SVD and intermittently fail.\"\"\"\n\n    @wraps(function)\n    def dec(*args, **kwargs):\n        try:\n            return function(*args, **kwargs)\n        except np.linalg.LinAlgError as exp:\n            if \"SVD did not converge\" in str(exp):\n                msg = \"Intel MKL SVD convergence error detected, skipping test\"\n                warn(msg)\n                raise SkipTest(msg)\n            raise\n\n    return dec", "metadata": {}}
{"_id": "mne_mne_utils/_testing.py_assert_and_remove_boundary_annot_code", "title": "assert_and_remove_boundary_annot", "text": "def assert_and_remove_boundary_annot(annotations, n=1):\n    \"\"\"Assert that there are boundary annotations and remove them.\"\"\"\n    from ..io import BaseRaw\n\n    if isinstance(annotations, BaseRaw):  # allow either input\n        annotations = annotations.annotations\n    for key in (\"EDGE\", \"BAD\"):\n        idx = np.where(annotations.description == f\"{key} boundary\")[0]\n        assert len(idx) == n\n        annotations.delete(idx)", "metadata": {}}
{"_id": "mne_mne_utils/_testing.py_assert_object_equal_code", "title": "assert_object_equal", "text": "def assert_object_equal(a, b, *, err_msg=\"Object mismatch\", allclose=False):\n    \"\"\"Assert two objects are equal.\"\"\"\n    d = object_diff(a, b, allclose=allclose)\n    assert d == \"\", f\"{err_msg}\\n{d}\"", "metadata": {}}
{"_id": "mne_mne_utils/_testing.py_assert_meg_snr_code", "title": "assert_meg_snr", "text": "def assert_meg_snr(\n    actual, desired, min_tol, med_tol=500.0, chpi_med_tol=500.0, msg=None\n):\n    \"\"\"Assert channel SNR of a certain level.\n\n    Mostly useful for operations like Maxwell filtering that modify\n    MEG channels while leaving EEG and others intact.\n    \"\"\"\n    from .._fiff.pick import pick_types\n\n    picks = pick_types(desired.info, meg=True, exclude=[])\n    picks_desired = pick_types(desired.info, meg=True, exclude=[])\n    assert_array_equal(picks, picks_desired, err_msg=\"MEG pick mismatch\")\n    chpis = pick_types(actual.info, meg=False, chpi=True, exclude=[])\n    chpis_desired = pick_types(desired.info, meg=False, chpi=True, exclude=[])\n    if chpi_med_tol is not None:\n        assert_array_equal(chpis, chpis_desired, err_msg=\"cHPI pick mismatch\")\n    others = np.setdiff1d(\n        np.arange(len(actual.ch_names)), np.concatenate([picks, chpis])\n    )\n    others_desired = np.setdiff1d(\n        np.arange(len(desired.ch_names)), np.concatenate([picks_desired, chpis_desired])\n    )\n    assert_array_equal(others, others_desired, err_msg=\"Other pick mismatch\")\n    if len(others) > 0:  # if non-MEG channels present\n        assert_allclose(\n            _get_data(actual, others),\n            _get_data(desired, others),\n            atol=1e-11,\n            rtol=1e-5,\n            err_msg=\"non-MEG channel mismatch\",\n        )\n    _check_snr(actual, desired, picks, min_tol, med_tol, msg, kind=\"MEG\")\n    if chpi_med_tol is not None and len(chpis) > 0:\n        _check_snr(actual, desired, chpis, 0.0, chpi_med_tol, msg, kind=\"cHPI\")", "metadata": {}}
{"_id": "mne_mne_utils/_testing.py_assert_snr_code", "title": "assert_snr", "text": "def assert_snr(actual, desired, tol):\n    \"\"\"Assert actual and desired arrays are within some SNR tolerance.\"\"\"\n    with np.errstate(divide=\"ignore\"):  # allow infinite\n        snr = linalg.norm(desired, ord=\"fro\") / linalg.norm(desired - actual, ord=\"fro\")\n    assert snr >= tol, f\"{snr} < {tol}\"", "metadata": {}}
{"_id": "mne_mne_utils/_testing.py_assert_stcs_equal_code", "title": "assert_stcs_equal", "text": "def assert_stcs_equal(stc1, stc2):\n    \"\"\"Check that two STC are equal.\"\"\"\n    assert_allclose(stc1.times, stc2.times)\n    assert_allclose(stc1.data, stc2.data)\n    assert_array_equal(stc1.vertices[0], stc2.vertices[0])\n    assert_array_equal(stc1.vertices[1], stc2.vertices[1])\n    assert_allclose(stc1.tmin, stc2.tmin)\n    assert_allclose(stc1.tstep, stc2.tstep)", "metadata": {}}
{"_id": "mne_mne_utils/_testing.py_assert_dig_allclose_code", "title": "assert_dig_allclose", "text": "def assert_dig_allclose(info_py, info_bin, limit=None):\n    \"\"\"Assert dig allclose.\"\"\"\n    from .._fiff.constants import FIFF\n    from .._fiff.meas_info import Info\n    from ..bem import fit_sphere_to_headshape\n    from ..channels.montage import DigMontage\n\n    # test dig positions\n    dig_py, dig_bin = info_py, info_bin\n    if isinstance(dig_py, Info):\n        assert isinstance(dig_bin, Info)\n        dig_py, dig_bin = dig_py[\"dig\"], dig_bin[\"dig\"]\n    else:\n        assert isinstance(dig_bin, DigMontage)\n        assert isinstance(dig_py, DigMontage)\n        dig_py, dig_bin = dig_py.dig, dig_bin.dig\n        info_py = info_bin = None\n    assert isinstance(dig_py, list)\n    assert isinstance(dig_bin, list)\n    dig_py = sorted(dig_py, key=_dig_sort_key)\n    dig_bin = sorted(dig_bin, key=_dig_sort_key)\n    assert len(dig_py) == len(dig_bin)\n    for ii, (d_py, d_bin) in enumerate(zip(dig_py[:limit], dig_bin[:limit])):\n        for key in (\"ident\", \"kind\", \"coord_frame\"):\n            assert d_py[key] == d_bin[key], key\n        assert_allclose(\n            d_py[\"r\"],\n            d_bin[\"r\"],\n            rtol=1e-5,\n            atol=1e-5,\n            err_msg=f\"Failure on {ii}:\\n{d_py['r']}\\n{d_bin['r']}\",\n        )\n    if any(d[\"kind\"] == FIFF.FIFFV_POINT_EXTRA for d in dig_py) and info_py is not None:\n        r_bin, o_head_bin, o_dev_bin = fit_sphere_to_headshape(\n            info_bin, units=\"m\", verbose=\"error\"\n        )\n        r_py, o_head_py, o_dev_py = fit_sphere_to_headshape(\n            info_py, units=\"m\", verbose=\"error\"\n        )\n        assert_allclose(r_py, r_bin, atol=1e-6)\n        assert_allclose(o_dev_py, o_dev_bin, rtol=1e-5, atol=1e-6)\n        assert_allclose(o_head_py, o_head_bin, rtol=1e-5, atol=1e-6)", "metadata": {}}
{"_id": "mne_mne_utils/docs.py_fill_doc_code", "title": "fill_doc", "text": "def fill_doc(f):\n    \"\"\"Fill a docstring with docdict entries.\n\n    Parameters\n    ----------\n    f : callable\n        The function to fill the docstring of. Will be modified in place.\n\n    Returns\n    -------\n    f : callable\n        The function, potentially with an updated ``__doc__``.\n    \"\"\"\n    docstring = f.__doc__\n    if not docstring:\n        return f\n    lines = docstring.splitlines()\n    # Find the minimum indent of the main docstring, after first line\n    if len(lines) < 2:\n        icount = 0\n    else:\n        icount = _indentcount_lines(lines[1:])\n    # Insert this indent to dictionary docstrings\n    try:\n        indented = docdict_indented[icount]\n    except KeyError:\n        indent = \" \" * icount\n        docdict_indented[icount] = indented = {}\n        for name, dstr in docdict.items():\n            lines = dstr.splitlines()\n            try:\n                newlines = [lines[0]]\n                for line in lines[1:]:\n                    newlines.append(indent + line)\n                indented[name] = \"\\n\".join(newlines)\n            except IndexError:\n                indented[name] = dstr\n    try:\n        f.__doc__ = docstring % indented\n    except (TypeError, ValueError, KeyError) as exp:\n        funcname = f.__name__\n        funcname = docstring.split(\"\\n\")[0] if funcname is None else funcname\n        raise RuntimeError(f\"Error documenting {funcname}:\\n{exp}\")\n    return f", "metadata": {}}
{"_id": "mne_mne_utils/docs.py_copy_doc_code", "title": "copy_doc", "text": "def copy_doc(source):\n    \"\"\"Copy the docstring from another function (decorator).\n\n    The docstring of the source function is prepepended to the docstring of the\n    function wrapped by this decorator.\n\n    This is useful when inheriting from a class and overloading a method. This\n    decorator can be used to copy the docstring of the original method.\n\n    Docstrings are processed by :func:`python:inspect.cleandoc` before being used.\n\n    Parameters\n    ----------\n    source : function\n        Function to copy the docstring from.\n\n    Returns\n    -------\n    wrapper : function\n        The decorated function.\n\n    Examples\n    --------\n    >>> class A:\n    ...     def m1():\n    ...         '''Docstring for m1'''\n    ...         pass\n    >>> class B (A):\n    ...     @copy_doc(A.m1)\n    ...     def m1():\n    ...         ''' this gets appended'''\n    ...         pass\n    >>> print(B.m1.__doc__)\n    Docstring for m1\n    this gets appended\n    \"\"\"\n\n    def wrapper(func):\n        if source.__doc__ is None or len(source.__doc__) == 0:\n            raise ValueError(\"Cannot copy docstring: docstring was empty.\")\n        doc = source.__doc__\n        if func.__doc__ is not None:\n            doc += f\"\\n{inspect.cleandoc(func.__doc__)}\"\n        func.__doc__ = doc\n        return func\n\n    return wrapper", "metadata": {}}
{"_id": "mne_mne_utils/docs.py_copy_function_doc_to_method_doc_code", "title": "copy_function_doc_to_method_doc", "text": "def copy_function_doc_to_method_doc(source):\n    \"\"\"Use the docstring from a function as docstring for a method.\n\n    The docstring of the source function is prepepended to the docstring of the\n    function wrapped by this decorator. Additionally, the first parameter\n    specified in the docstring of the source function is removed in the new\n    docstring.\n\n    This decorator is useful when implementing a method that just calls a\n    function.  This pattern is prevalent in for example the plotting functions\n    of MNE.\n\n    Docstrings are parsed by :func:`python:inspect.cleandoc` before being used.\n    If indentation and newlines are important, make the first line ``.``, and the dot\n    will be removed and all following lines dedented jointly.\n\n    Parameters\n    ----------\n    source : function\n        Function to copy the docstring from.\n\n    Returns\n    -------\n    wrapper : function\n        The decorated method.\n\n    Notes\n    -----\n    The parsing performed is very basic and will break easily on docstrings\n    that are not formatted exactly according to the ``numpydoc`` standard.\n    Always inspect the resulting docstring when using this decorator.\n\n    Examples\n    --------\n    >>> def plot_function(object, a, b):\n    ...     '''Docstring for plotting function.\n    ...\n    ...     Parameters\n    ...     ----------\n    ...     object : instance of object\n    ...         The object to plot\n    ...     a : int\n    ...         Some parameter\n    ...     b : int\n    ...         Some parameter\n    ...     '''\n    ...     pass\n    ...\n    >>> class A:\n    ...     @copy_function_doc_to_method_doc(plot_function)\n    ...     def plot(self, a, b):\n    ...         '''.\n    ...\n    ...         Notes\n    ...         -----\n    ...         .. versionadded:: 0.13.0\n    ...         '''\n    ...         plot_function(self, a, b)\n    >>> print(A.plot.__doc__)\n    Docstring for plotting function.\n    <BLANKLINE>\n    Parameters\n    ----------\n    a : int\n        Some parameter\n    b : int\n        Some parameter\n    <BLANKLINE>\n    Notes\n    -----\n    .. versionadded:: 0.13.0\n    \"\"\"  # noqa: D410, D411, D214, D215\n\n    def wrapper(func):\n        # Work with cleandoc'ed sources (py3.13-compat)\n        doc = inspect.cleandoc(source.__doc__).split(\"\\n\")\n        if func.__doc__ is not None:\n            func_doc = inspect.cleandoc(func.__doc__)\n            if func_doc[:2] == \".\\n\":\n                func_doc = func_doc[2:]\n            func_doc = f\"\\n{func_doc}\"\n        else:\n            func_doc = \"\"\n\n        if len(doc) == 1:\n            func.__doc__ = f\"{doc[0]}{func_doc}\"\n            return func\n\n        # Find parameter block\n        for line, text in enumerate(doc[:-2]):\n            if text.strip() == \"Parameters\" and doc[line + 1].strip() == \"----------\":\n                parameter_block = line\n                break\n        else:\n            # No parameter block found\n            raise ValueError(\n                \"Cannot copy function docstring: no parameter \"\n                \"block found. To simply copy the docstring, use \"\n                \"the @copy_doc decorator instead.\"\n            )\n\n        # Find first parameter\n        for line, text in enumerate(doc[parameter_block:], parameter_block):\n            if \":\" in text:\n                first_parameter = line\n                parameter_indentation = len(text) - len(text.lstrip(\" \"))\n                break\n        else:\n            raise ValueError(\n                \"Cannot copy function docstring: no parameters \"\n                \"found. To simply copy the docstring, use the \"\n                \"@copy_doc decorator instead.\"\n            )\n\n        # Find end of first parameter\n        for line, text in enumerate(doc[first_parameter + 1 :], first_parameter + 1):\n            # Ignore empty lines\n            if len(text.strip()) == 0:\n                continue\n\n            line_indentation = len(text) - len(text.lstrip(\" \"))\n            if line_indentation <= parameter_indentation:\n                # Reach end of first parameter\n                first_parameter_end = line\n\n                # Of only one parameter is defined, remove the Parameters\n                # heading as well\n                if \":\" not in text:\n                    first_parameter = parameter_block\n\n                break\n        else:\n            # End of docstring reached\n            first_parameter_end = line + 1\n            first_parameter = parameter_block\n\n        # Copy the docstring, but remove the first parameter\n        doc = (\n            \"\\n\".join(doc[:first_parameter])\n            + \"\\n\"\n            + \"\\n\".join(doc[first_parameter_end:])\n        )\n        func.__doc__ = f\"{doc}{func_doc}\"\n        return func\n\n    return wrapper", "metadata": {}}
{"_id": "mne_mne_utils/docs.py_linkcode_resolve_code", "title": "linkcode_resolve", "text": "def linkcode_resolve(domain, info):\n    \"\"\"Determine the URL corresponding to a Python object.\n\n    Parameters\n    ----------\n    domain : str\n        Only useful when 'py'.\n    info : dict\n        With keys \"module\" and \"fullname\".\n\n    Returns\n    -------\n    url : str\n        The code URL.\n\n    Notes\n    -----\n    This has been adapted to deal with our \"verbose\" decorator.\n\n    Adapted from SciPy (doc/source/conf.py).\n    \"\"\"\n    import mne\n\n    if domain != \"py\":\n        return None\n\n    modname = info[\"module\"]\n    fullname = info[\"fullname\"]\n\n    submod = sys.modules.get(modname)\n    if submod is None:\n        return None\n\n    obj = submod\n    for part in fullname.split(\".\"):\n        try:\n            obj = getattr(obj, part)\n        except Exception:\n            return None\n    # deal with our decorators properly\n    while hasattr(obj, \"__wrapped__\"):\n        obj = obj.__wrapped__\n\n    try:\n        fn = inspect.getsourcefile(obj)\n    except Exception:\n        fn = None\n    if not fn:\n        try:\n            fn = inspect.getsourcefile(sys.modules[obj.__module__])\n        except Exception:\n            fn = None\n    if not fn:\n        return None\n    fn = op.relpath(fn, start=op.dirname(mne.__file__))\n    fn = \"/\".join(op.normpath(fn).split(os.sep))  # in case on Windows\n\n    try:\n        source, lineno = inspect.getsourcelines(obj)\n    except Exception:\n        lineno = None\n\n    if lineno:\n        linespec = f\"#L{lineno}-L{lineno + len(source) - 1}\"\n    else:\n        linespec = \"\"\n\n    if \"dev\" in mne.__version__:\n        kind = \"main\"\n    else:\n        kind = \"maint/\" + \".\".join(mne.__version__.split(\".\")[:2])\n    return f\"http://github.com/mne-tools/mne-python/blob/{kind}/mne/{fn}{linespec}\"", "metadata": {}}
{"_id": "mne_mne_utils/docs.py_open_docs_code", "title": "open_docs", "text": "def open_docs(kind=None, version=None):\n    \"\"\"Launch a new web browser tab with the MNE documentation.\n\n    Parameters\n    ----------\n    kind : str | None\n        Can be \"api\" (default), \"tutorials\", or \"examples\".\n        The default can be changed by setting the configuration value\n        MNE_DOCS_KIND.\n    version : str | None\n        Can be \"stable\" (default) or \"dev\".\n        The default can be changed by setting the configuration value\n        MNE_DOCS_VERSION.\n    \"\"\"\n    from .check import _check_option\n    from .config import get_config\n\n    if kind is None:\n        kind = get_config(\"MNE_DOCS_KIND\", \"api\")\n    help_dict = dict(\n        api=\"python_reference.html\",\n        tutorials=\"tutorials.html\",\n        examples=\"auto_examples/index.html\",\n    )\n    _check_option(\"kind\", kind, sorted(help_dict.keys()))\n    kind = help_dict[kind]\n    if version is None:\n        version = get_config(\"MNE_DOCS_VERSION\", \"stable\")\n    _check_option(\"version\", version, [\"stable\", \"dev\"])\n    webbrowser.open_new_tab(f\"https://mne.tools/{version}/{kind}\")", "metadata": {}}
{"_id": "mne_mne_utils/docs.py_deprecated_alias_code", "title": "deprecated_alias", "text": "def deprecated_alias(dep_name, func, removed_in=None):\n    \"\"\"Inject a deprecated alias into the namespace.\"\"\"\n    if removed_in is None:\n        from .. import __version__\n\n        removed_in = __version__.split(\".\")[:2]\n        removed_in[1] = str(int(removed_in[1]) + 1)\n        removed_in = \".\".join(removed_in)\n    # Inject a deprecated version into the namespace\n    inspect.currentframe().f_back.f_globals[dep_name] = deprecated(\n        f\"{dep_name} has been deprecated in favor of {func.__name__} and will \"\n        f\"be removed in {removed_in}.\"\n    )(deepcopy(func))", "metadata": {}}
{"_id": "mne_mne_beamformer/resolution_matrix.py_make_lcmv_resolution_matrix_code", "title": "make_lcmv_resolution_matrix", "text": "def make_lcmv_resolution_matrix(filters, forward, info):\n    \"\"\"Compute resolution matrix for LCMV beamformer.\n\n    Parameters\n    ----------\n    filters : instance of Beamformer\n         Dictionary containing filter weights from LCMV beamformer\n         (see mne.beamformer.make_lcmv).\n    forward : instance of Forward\n        Forward Solution with leadfield matrix.\n    %(info_not_none)s Used to compute LCMV filters.\n\n    Returns\n    -------\n    resmat : array, shape (n_dipoles_lcmv, n_dipoles_fwd)\n        Resolution matrix (filter matrix multiplied to leadfield from\n        forward solution). Numbers of rows (n_dipoles_lcmv) and columns\n        (n_dipoles_fwd) may differ by a factor depending on orientation\n        constraints of filter and forward solution, respectively (e.g. factor 3\n        for free dipole orientation versus factor 1 for scalar beamformers).\n    \"\"\"\n    # don't include bad channels from noise covariance matrix\n    bads_filt = filters[\"noise_cov\"][\"bads\"]\n    ch_names = filters[\"noise_cov\"][\"names\"]\n\n    # good channels\n    ch_names = [c for c in ch_names if (c not in bads_filt)]\n\n    # adjust channels in forward solution\n    forward = pick_channels_forward(forward, ch_names, ordered=True)\n\n    # get leadfield matrix from forward solution\n    leadfield = forward[\"sol\"][\"data\"]\n\n    # get the filter weights for beamformer as matrix\n    filtmat = _get_matrix_from_lcmv(filters, forward, info)\n\n    # compute resolution matrix\n    resmat = filtmat.dot(leadfield)\n\n    logger.info(f\"Dimensions of LCMV resolution matrix: {resmat.shape}.\")\n\n    return resmat", "metadata": {}}
{"_id": "mne_mne_beamformer/_compute_beamformer.py_read_beamformer_code", "title": "read_beamformer", "text": "def read_beamformer(fname):\n    \"\"\"Read a beamformer filter.\n\n    Parameters\n    ----------\n    fname : path-like\n        The filename of the HDF5 file.\n\n    Returns\n    -------\n    filter : instance of Beamformer\n        The beamformer filter.\n    \"\"\"\n    read_hdf5, _ = _import_h5io_funcs()\n    beamformer = read_hdf5(fname, title=\"mnepython\")\n    if \"csd\" in beamformer:\n        beamformer[\"csd\"] = CrossSpectralDensity(**beamformer[\"csd\"])\n    # h5io seems to cast `bool` to `int` on round-trip, probably a bug\n    # we should fix at some point (if possible -- could be HDF5 limitation)\n    for key in (\"normalize_fwd\", \"is_free_ori\", \"is_ssp\"):\n        if key in beamformer:\n            beamformer[key] = bool(beamformer[key])\n    for key in (\"data_cov\", \"noise_cov\"):\n        if beamformer.get(key) is not None:\n            for pi, p in enumerate(beamformer[key][\"projs\"]):\n                p = Projection(**p)\n                p[\"active\"] = bool(p[\"active\"])\n                beamformer[key][\"projs\"][pi] = p\n            beamformer[key] = Covariance(\n                *[\n                    beamformer[key].get(arg)\n                    for arg in (\n                        \"data\",\n                        \"names\",\n                        \"bads\",\n                        \"projs\",\n                        \"nfree\",\n                        \"eig\",\n                        \"eigvec\",\n                        \"method\",\n                        \"loglik\",\n                    )\n                ]\n            )\n    return Beamformer(beamformer)", "metadata": {}}
{"_id": "mne_mne_beamformer/_compute_beamformer.py_copy_code", "title": "copy", "text": "def copy(self):\n        \"\"\"Copy the beamformer.\n\n        Returns\n        -------\n        beamformer : instance of Beamformer\n            A deep copy of the beamformer.\n        \"\"\"\n        return deepcopy(self)", "metadata": {}}
{"_id": "mne_mne_beamformer/_compute_beamformer.py_save_code", "title": "save", "text": "def save(self, fname, overwrite=False, verbose=None):\n        \"\"\"Save the beamformer filter.\n\n        Parameters\n        ----------\n        fname : path-like\n            The filename to use to write the HDF5 data.\n            Should end in ``'-lcmv.h5'`` or ``'-dics.h5'``.\n        %(overwrite)s\n        %(verbose)s\n        \"\"\"\n        _, write_hdf5 = _import_h5io_funcs()\n\n        ending = f\"-{self['kind'].lower()}.h5\"\n        check_fname(fname, self[\"kind\"], (ending,))\n        csd_orig = None\n        try:\n            if \"csd\" in self:\n                csd_orig = self[\"csd\"]\n                self[\"csd\"] = self[\"csd\"].__getstate__()\n            write_hdf5(fname, self, overwrite=overwrite, title=\"mnepython\")\n        finally:\n            if csd_orig is not None:\n                self[\"csd\"] = csd_orig", "metadata": {}}
{"_id": "mne_mne_beamformer/_dics.py_make_dics_code", "title": "make_dics", "text": "def make_dics(\n    info,\n    forward,\n    csd,\n    reg=0.05,\n    noise_csd=None,\n    label=None,\n    pick_ori=None,\n    rank=None,\n    weight_norm=None,\n    reduce_rank=False,\n    depth=1.0,\n    real_filter=True,\n    inversion=\"matrix\",\n    verbose=None,\n):\n    \"\"\"Compute a Dynamic Imaging of Coherent Sources (DICS) spatial filter.\n\n    This is a beamformer filter that can be used to estimate the source power\n    at a specific frequency range :footcite:`GrossEtAl2001`. It does this by\n    constructing a spatial filter for each source point.\n    The computation of these filters is very similar to those of the LCMV\n    beamformer (:func:`make_lcmv`), but instead of operating on a covariance\n    matrix, the CSD matrix is used. When applying these filters to a CSD matrix\n    (see :func:`apply_dics_csd`), the source power can be estimated for each\n    source point.\n\n    Parameters\n    ----------\n    %(info_not_none)s\n    forward : instance of Forward\n        Forward operator.\n    csd : instance of CrossSpectralDensity\n        The data cross-spectral density (CSD) matrices. A source estimate is\n        performed for each frequency or frequency-bin defined in the CSD\n        object.\n    reg : float\n        The regularization to apply to the cross-spectral density before\n        computing the inverse.\n    noise_csd : instance of CrossSpectralDensity | None\n        Noise cross-spectral density (CSD) matrices. If provided, whitening\n        will be done. The noise CSDs need to have been computed for the same\n        frequencies as the data CSDs. Providing noise CSDs is mandatory if you\n        mix sensor types, e.g. gradiometers with magnetometers or EEG with\n        MEG.\n\n        .. versionadded:: 0.20\n    label : Label | None\n        Restricts the solution to a given label.\n    %(pick_ori_bf)s\n    %(rank_none)s\n\n        .. versionadded:: 0.17\n    %(weight_norm)s\n\n        Defaults to ``None``, in which case no normalization is performed.\n    %(reduce_rank)s\n    %(depth)s\n    real_filter : bool\n        If ``True``, take only the real part of the cross-spectral-density\n        matrices to compute real filters.\n\n        .. versionchanged:: 0.23\n            Version 0.23 an earlier used ``real_filter=False`` as the default,\n            as of version 0.24 ``True`` is the default.\n    %(inversion_bf)s\n\n        .. versionchanged:: 0.21\n           Default changed to ``'matrix'``.\n    %(verbose)s\n\n    Returns\n    -------\n    filters : instance of Beamformer\n        Dictionary containing filter weights from DICS beamformer.\n        Contains the following keys:\n\n            'kind' : str\n                The type of beamformer, in this case 'DICS'.\n            'weights' : ndarray, shape (n_frequencies, n_weights)\n                For each frequency, the filter weights of the beamformer.\n            'csd' : instance of CrossSpectralDensity\n                The data cross-spectral density matrices used to compute the\n                beamformer.\n            'ch_names' : list of str\n                Channels used to compute the beamformer.\n            'proj' : ndarray, shape (n_channels, n_channels)\n                Projections used to compute the beamformer.\n            'vertices' : list of ndarray\n                Vertices for which the filter weights were computed.\n            'n_sources' : int\n                Number of source location for which the filter weight were\n                computed.\n            'subject' : str\n                The subject ID.\n            'pick-ori' : None | 'max-power' | 'normal' | 'vector'\n                The orientation in which the beamformer filters were computed.\n            'inversion' : 'single' | 'matrix'\n                Whether the spatial filters were computed for each dipole\n                separately or jointly for all dipoles at each vertex using a\n                matrix inversion.\n            'weight_norm' : None | 'unit-noise-gain'\n                The normalization of the weights.\n            'src_type' : str\n                Type of source space.\n            'source_nn' : ndarray, shape (n_sources, 3)\n                For each source location, the surface normal.\n            'is_free_ori' : bool\n                Whether the filter was computed in a fixed direction\n                (pick_ori='max-power', pick_ori='normal') or not.\n            'whitener' : None | ndarray, shape (n_channels, n_channels)\n                Whitening matrix, provided if whitening was applied to the\n                covariance matrix and leadfield during computation of the\n                beamformer weights.\n            'max-power-ori' : ndarray, shape (n_sources, 3) | None\n                When pick_ori='max-power', this fields contains the estimated\n                direction of maximum power at each source location.\n\n    See Also\n    --------\n    apply_dics_csd\n\n    Notes\n    -----\n    The original reference is :footcite:`GrossEtAl2001`. See\n    :footcite:`vanVlietEtAl2018` for a tutorial style paper on the topic.\n\n    The DICS beamformer is very similar to the LCMV (:func:`make_lcmv`)\n    beamformer and many of the parameters are shared. However,\n    :func:`make_dics` and :func:`make_lcmv` currently have different defaults\n    for these parameters, which were settled on separately through extensive\n    practical use case testing (but not necessarily exhaustive parameter space\n    searching), and it remains to be seen how functionally interchangeable they\n    could be.\n\n    The default setting reproduce the DICS beamformer as described in\n    :footcite:`vanVlietEtAl2018`::\n\n        inversion='single', weight_norm=None, depth=1.\n\n    To use the :func:`make_lcmv` defaults, use::\n\n        inversion='matrix', weight_norm='unit-noise-gain-invariant', depth=None\n\n    For more information about ``real_filter``, see the\n    supplemental information from :footcite:`HippEtAl2011`.\n\n    References\n    ----------\n    .. footbibliography::\n    \"\"\"  # noqa: E501\n    rank = _check_rank(rank)\n    _check_option(\"pick_ori\", pick_ori, [None, \"vector\", \"normal\", \"max-power\"])\n    _check_option(\"inversion\", inversion, [\"single\", \"matrix\"])\n    _validate_type(weight_norm, (str, None), \"weight_norm\")\n\n    frequencies = [np.mean(freq_bin) for freq_bin in csd.frequencies]\n    n_freqs = len(frequencies)\n\n    _, _, allow_mismatch = _check_one_ch_type(\"dics\", info, forward, csd, noise_csd)\n    # remove bads so that equalize_channels only keeps all good\n    info = pick_info(info, pick_channels(info[\"ch_names\"], [], info[\"bads\"]))\n    info, forward, csd = equalize_channels([info, forward, csd])\n\n    csd, noise_csd = _prepare_noise_csd(csd, noise_csd, real_filter)\n\n    depth = _check_depth(depth, \"depth_sparse\")\n    if inversion == \"single\":\n        depth[\"combine_xyz\"] = False\n\n    (\n        is_free_ori,\n        info,\n        proj,\n        vertices,\n        G,\n        whitener,\n        nn,\n        orient_std,\n    ) = _prepare_beamformer_input(\n        info,\n        forward,\n        label,\n        pick_ori,\n        noise_cov=noise_csd,\n        rank=rank,\n        pca=False,\n        **depth,\n    )\n\n    # Compute ranks\n    csd_int_rank = []\n    if not allow_mismatch:\n        noise_rank = compute_rank(noise_csd, info=info, rank=rank)\n    for i in range(len(frequencies)):\n        csd_rank = compute_rank(\n            csd.get_data(index=i, as_cov=True), info=info, rank=rank\n        )\n        if not allow_mismatch:\n            for key in csd_rank:\n                if key not in noise_rank or csd_rank[key] != noise_rank[key]:\n                    raise ValueError(\n                        f\"{key} data rank ({csd_rank[key]}) did not match the noise \"\n                        f\"rank ({noise_rank.get(key, None)})\"\n                    )\n        csd_int_rank.append(sum(csd_rank.values()))\n\n    del noise_csd\n    ch_names = list(info[\"ch_names\"])\n\n    logger.info(\"Computing DICS spatial filters...\")\n    Ws = []\n    max_oris = []\n    for i, freq in enumerate(frequencies):\n        if n_freqs > 1:\n            logger.info(\n                \"    computing DICS spatial filter at \"\n                f\"{round(freq, 2)} Hz ({i + 1}/{n_freqs})\"\n            )\n\n        Cm = csd.get_data(index=i)\n\n        # XXX: Weird that real_filter happens *before* whitening, which could\n        # make things complex again...?\n        if real_filter:\n            Cm = Cm.real\n\n        # compute spatial filter\n        n_orient = 3 if is_free_ori else 1\n        W, max_power_ori = _compute_beamformer(\n            G,\n            Cm,\n            reg,\n            n_orient,\n            weight_norm,\n            pick_ori,\n            reduce_rank,\n            rank=csd_int_rank[i],\n            inversion=inversion,\n            nn=nn,\n            orient_std=orient_std,\n            whitener=whitener,\n        )\n        Ws.append(W)\n        max_oris.append(max_power_ori)\n\n    Ws = np.array(Ws)\n    if pick_ori == \"max-power\":\n        max_oris = np.array(max_oris)\n    else:\n        max_oris = None\n\n    src_type = _get_src_type(forward[\"src\"], vertices)\n    subject = _subject_from_forward(forward)\n    is_free_ori = is_free_ori if pick_ori in [None, \"vector\"] else False\n    n_sources = np.sum([len(v) for v in vertices])\n\n    filters = Beamformer(\n        kind=\"DICS\",\n        weights=Ws,\n        csd=csd,\n        ch_names=ch_names,\n        proj=proj,\n        vertices=vertices,\n        n_sources=n_sources,\n        subject=subject,\n        pick_ori=pick_ori,\n        inversion=inversion,\n        weight_norm=weight_norm,\n        src_type=src_type,\n        source_nn=forward[\"source_nn\"].copy(),\n        is_free_ori=is_free_ori,\n        whitener=whitener,\n        max_power_ori=max_oris,\n    )\n\n    return filters", "metadata": {}}
{"_id": "mne_mne_beamformer/_dics.py_apply_dics_code", "title": "apply_dics", "text": "def apply_dics(evoked, filters, verbose=None):\n    \"\"\"Apply Dynamic Imaging of Coherent Sources (DICS) beamformer weights.\n\n    Apply Dynamic Imaging of Coherent Sources (DICS) beamformer weights\n    on evoked data.\n\n    .. warning:: The result of this function is meant as an intermediate step\n                 for further processing (such as computing connectivity). If\n                 you are interested in estimating source time courses, use an\n                 LCMV beamformer (:func:`make_lcmv`, :func:`apply_lcmv`)\n                 instead. If you are interested in estimating spectral power at\n                 the source level, use :func:`apply_dics_csd`.\n    .. warning:: This implementation has not been heavily tested so please\n                 report any issues or suggestions.\n\n    Parameters\n    ----------\n    evoked : Evoked\n        Evoked data to apply the DICS beamformer weights to.\n    filters : instance of Beamformer\n        DICS spatial filter (beamformer weights)\n        Filter weights returned from :func:`make_dics`.\n    %(verbose)s\n\n    Returns\n    -------\n    stc : SourceEstimate | VolSourceEstimate | list\n        Source time courses. If the DICS beamformer has been computed for more\n        than one frequency, a list is returned containing for each frequency\n        the corresponding time courses.\n\n    See Also\n    --------\n    apply_dics_epochs\n    apply_dics_tfr_epochs\n    apply_dics_csd\n    \"\"\"  # noqa: E501\n    _check_reference(evoked)\n\n    info = evoked.info\n    data = evoked.data\n    tmin = evoked.times[0]\n\n    sel = _check_channels_spatial_filter(evoked.ch_names, filters)\n    data = data[sel]\n\n    stc = _apply_dics(data=data, filters=filters, info=info, tmin=tmin)\n\n    return next(stc)", "metadata": {}}
{"_id": "mne_mne_beamformer/_dics.py_apply_dics_epochs_code", "title": "apply_dics_epochs", "text": "def apply_dics_epochs(epochs, filters, return_generator=False, verbose=None):\n    \"\"\"Apply Dynamic Imaging of Coherent Sources (DICS) beamformer weights.\n\n    Apply Dynamic Imaging of Coherent Sources (DICS) beamformer weights\n    on single trial data.\n\n    .. warning:: The result of this function is meant as an intermediate step\n                 for further processing (such as computing connectivity). If\n                 you are interested in estimating source time courses, use an\n                 LCMV beamformer (:func:`make_lcmv`, :func:`apply_lcmv`)\n                 instead. If you are interested in estimating spectral power at\n                 the source level, use :func:`apply_dics_csd`.\n    .. warning:: This implementation has not been heavily tested so please\n                 report any issue or suggestions.\n\n    Parameters\n    ----------\n    epochs : Epochs\n        Single trial epochs.\n    filters : instance of Beamformer\n        DICS spatial filter (beamformer weights)\n        Filter weights returned from :func:`make_dics`. The DICS filters must\n        have been computed for a single frequency only.\n    return_generator : bool\n        Return a generator object instead of a list. This allows iterating\n        over the stcs without having to keep them all in memory.\n    %(verbose)s\n\n    Returns\n    -------\n    stc: list | generator of (SourceEstimate | VolSourceEstimate)\n        The source estimates for all epochs.\n\n    See Also\n    --------\n    apply_dics\n    apply_dics_tfr_epochs\n    apply_dics_csd\n    \"\"\"\n    _check_reference(epochs)\n\n    if len(filters[\"weights\"]) > 1:\n        raise ValueError(\n            \"This function only works on DICS beamformer weights that have \"\n            \"been computed for a single frequency. When calling make_dics(), \"\n            \"make sure to use a CSD object with only a single frequency (or \"\n            \"frequency-bin) defined.\"\n        )\n\n    info = epochs.info\n    tmin = epochs.times[0]\n\n    sel = _check_channels_spatial_filter(epochs.ch_names, filters)\n    data = epochs.get_data(sel)\n\n    stcs = _apply_dics(data=data, filters=filters, info=info, tmin=tmin)\n\n    if not return_generator:\n        stcs = list(stcs)\n\n    return stcs", "metadata": {}}
{"_id": "mne_mne_beamformer/_dics.py_apply_dics_tfr_epochs_code", "title": "apply_dics_tfr_epochs", "text": "def apply_dics_tfr_epochs(epochs_tfr, filters, return_generator=False, verbose=None):\n    \"\"\"Apply Dynamic Imaging of Coherent Sources (DICS) beamformer weights.\n\n    Apply Dynamic Imaging of Coherent Sources (DICS) beamformer weights\n    on single trial time-frequency data.\n\n    Parameters\n    ----------\n    epochs_tfr : EpochsTFR\n        Single trial time-frequency epochs.\n    filters : instance of Beamformer\n        DICS spatial filter (beamformer weights)\n        Filter weights returned from :func:`make_dics`.\n    return_generator : bool\n        Return a generator object instead of a list. This allows iterating\n        over the stcs without having to keep them all in memory.\n    %(verbose)s\n\n    Returns\n    -------\n    stcs : list of list of (SourceEstimate | VectorSourceEstimate | VolSourceEstimate)\n        The source estimates for all epochs (outside list) and for\n        all frequencies (inside list).\n\n    See Also\n    --------\n    apply_dics\n    apply_dics_epochs\n    apply_dics_csd\n    \"\"\"  # noqa E501\n    _validate_type(epochs_tfr, EpochsTFR)\n    _check_tfr_complex(epochs_tfr)\n\n    if filters[\"pick_ori\"] == \"vector\":\n        warn(\n            \"Using a vector solution to compute power will lead to \"\n            \"inaccurate directions (only in the first quadrent) \"\n            \"because power is a strictly positive (squared) metric. \"\n            \"Using singular value decomposition (SVD) to determine \"\n            \"the direction is not yet supported in MNE.\"\n        )\n\n    sel = _check_channels_spatial_filter(epochs_tfr.ch_names, filters)\n    data = epochs_tfr.data[:, sel, :, :]\n\n    stcs = _apply_dics(data, filters, epochs_tfr.info, epochs_tfr.tmin, tfr=True)\n    if not return_generator:\n        stcs = [[stc for stc in tfr_stcs] for tfr_stcs in stcs]\n    return stcs", "metadata": {}}
{"_id": "mne_mne_beamformer/_dics.py_apply_dics_csd_code", "title": "apply_dics_csd", "text": "def apply_dics_csd(csd, filters, verbose=None):\n    \"\"\"Apply Dynamic Imaging of Coherent Sources (DICS) beamformer weights.\n\n    Apply a previously computed DICS beamformer to a cross-spectral density\n    (CSD) object to estimate source power in time and frequency windows\n    specified in the CSD object :footcite:`GrossEtAl2001`.\n\n    .. note:: Only power can computed from the cross-spectral density, not\n              complex phase-amplitude, so vector DICS filters will be\n              converted to scalar source estimates since power is strictly\n              positive and so 3D directions cannot be combined meaningfully\n              (the direction would be confined to the positive quadrant).\n\n    Parameters\n    ----------\n    csd : instance of CrossSpectralDensity\n        The data cross-spectral density (CSD) matrices. A source estimate is\n        performed for each frequency or frequency-bin defined in the CSD\n        object.\n    filters : instance of Beamformer\n        DICS spatial filter (beamformer weights)\n        Filter weights returned from `make_dics`.\n    %(verbose)s\n\n    Returns\n    -------\n    stc : SourceEstimate\n        Source power with frequency instead of time.\n    frequencies : list of float\n        The frequencies for which the source power has been computed. If the\n        data CSD object defines frequency-bins instead of exact frequencies,\n        the mean of each bin is returned.\n\n    See Also\n    --------\n    apply_dics\n    apply_dics_epochs\n    apply_dics_tfr_epochs\n\n    References\n    ----------\n    .. footbibliography::\n    \"\"\"  # noqa: E501\n    ch_names = filters[\"ch_names\"]\n    vertices = filters[\"vertices\"]\n    n_orient = 3 if filters[\"is_free_ori\"] else 1\n    subject = filters[\"subject\"]\n    whitener = filters[\"whitener\"]\n    n_sources = filters[\"n_sources\"]\n\n    # If CSD is summed over multiple frequencies, take the average frequency\n    frequencies = [np.mean(dfreq) for dfreq in csd.frequencies]\n    n_freqs = len(frequencies)\n\n    source_power = np.zeros((n_sources, len(csd.frequencies)))\n\n    # Ensure the CSD is in the same order as the weights\n    csd_picks = [csd.ch_names.index(ch) for ch in ch_names]\n\n    logger.info(\"Computing DICS source power...\")\n    for i, freq in enumerate(frequencies):\n        if n_freqs > 1:\n            logger.info(\n                \"    applying DICS spatial filter at \"\n                f\"{round(freq, 2)} Hz ({i + 1}/{n_freqs})\"\n            )\n\n        Cm = csd.get_data(index=i)\n        Cm = Cm[csd_picks, :][:, csd_picks]\n        W = filters[\"weights\"][i]\n\n        # Whiten the CSD\n        Cm = np.dot(whitener, np.dot(Cm, whitener.conj().T))\n\n        source_power[:, i] = _compute_power(Cm, W, n_orient)\n\n    logger.info(\"[done]\")\n\n    # compatibility with 0.16, add src_type as None if not present:\n    filters, warn_text = _check_src_type(filters)\n\n    return (\n        _make_stc(\n            source_power,\n            vertices=vertices,\n            src_type=filters[\"src_type\"],\n            tmin=0.0,\n            tstep=1.0,\n            subject=subject,\n            warn_text=warn_text,\n        ),\n        frequencies,\n    )", "metadata": {}}
{"_id": "mne_mne_beamformer/_rap_music.py_rap_music_code", "title": "rap_music", "text": "def rap_music(\n    evoked,\n    forward,\n    noise_cov,\n    n_dipoles=5,\n    return_residual=False,\n    *,\n    verbose=None,\n):\n    \"\"\"RAP-MUSIC source localization method.\n\n    Compute Recursively Applied and Projected MUltiple SIgnal Classification\n    (RAP-MUSIC) :footcite:`MosherLeahy1999,MosherLeahy1996` on evoked data.\n\n    .. note:: The goodness of fit (GOF) of all the returned dipoles is the\n              same and corresponds to the GOF of the full set of dipoles.\n\n    Parameters\n    ----------\n    evoked : instance of Evoked\n        Evoked data to localize.\n    forward : instance of Forward\n        Forward operator.\n    noise_cov : instance of Covariance\n        The noise covariance.\n    n_dipoles : int\n        The number of dipoles to look for. The default value is 5.\n    return_residual : bool\n        If True, the residual is returned as an Evoked instance.\n    %(verbose)s\n\n    Returns\n    -------\n    dipoles : list of instance of Dipole\n        The dipole fits.\n    residual : instance of Evoked\n        The residual a.k.a. data not explained by the dipoles.\n        Only returned if return_residual is True.\n\n    See Also\n    --------\n    mne.fit_dipole\n    mne.beamformer.trap_music\n\n    Notes\n    -----\n    .. versionadded:: 0.9.0\n\n    References\n    ----------\n    .. footbibliography::\n    \"\"\"\n    return _rap_music(evoked, forward, noise_cov, n_dipoles, return_residual, False)", "metadata": {}}
{"_id": "mne_mne_beamformer/_rap_music.py_trap_music_code", "title": "trap_music", "text": "def trap_music(\n    evoked,\n    forward,\n    noise_cov,\n    n_dipoles=5,\n    return_residual=False,\n    *,\n    verbose=None,\n):\n    \"\"\"TRAP-MUSIC source localization method.\n\n    Compute Truncated Recursively Applied and Projected MUltiple SIgnal Classification\n    (TRAP-MUSIC) :footcite:`Makela2018` on evoked data.\n\n    .. note:: The goodness of fit (GOF) of all the returned dipoles is the\n              same and corresponds to the GOF of the full set of dipoles.\n\n    Parameters\n    ----------\n    evoked : instance of Evoked\n        Evoked data to localize.\n    forward : instance of Forward\n        Forward operator.\n    noise_cov : instance of Covariance\n        The noise covariance.\n    n_dipoles : int\n        The number of dipoles to look for. The default value is 5.\n    return_residual : bool\n        If True, the residual is returned as an Evoked instance.\n    %(verbose)s\n\n    Returns\n    -------\n    dipoles : list of instance of Dipole\n        The dipole fits.\n    residual : instance of Evoked\n        The residual a.k.a. data not explained by the dipoles.\n        Only returned if return_residual is True.\n\n    See Also\n    --------\n    mne.fit_dipole\n    mne.beamformer.rap_music\n\n    Notes\n    -----\n    .. versionadded:: 1.4\n\n    References\n    ----------\n    .. footbibliography::\n    \"\"\"\n    return _rap_music(evoked, forward, noise_cov, n_dipoles, return_residual, True)", "metadata": {}}
{"_id": "mne_mne_beamformer/_lcmv.py_make_lcmv_code", "title": "make_lcmv", "text": "def make_lcmv(\n    info,\n    forward,\n    data_cov,\n    reg=0.05,\n    noise_cov=None,\n    label=None,\n    pick_ori=None,\n    rank=\"info\",\n    weight_norm=\"unit-noise-gain-invariant\",\n    reduce_rank=False,\n    depth=None,\n    inversion=\"matrix\",\n    verbose=None,\n):\n    \"\"\"Compute LCMV spatial filter.\n\n    Parameters\n    ----------\n    %(info_not_none)s\n        Specifies the channels to include. Bad channels (in ``info['bads']``)\n        are not used.\n    forward : instance of Forward\n        Forward operator.\n    data_cov : instance of Covariance\n        The data covariance.\n    reg : float\n        The regularization for the whitened data covariance.\n    noise_cov : instance of Covariance\n        The noise covariance. If provided, whitening will be done. Providing a\n        noise covariance is mandatory if you mix sensor types, e.g.\n        gradiometers with magnetometers or EEG with MEG.\n\n        .. note::\n            If ``noise_cov`` is ``None`` and ``weight_norm='unit-noise-gain'``,\n            the unit noise is assumed to be 1 in SI units, e.g., 1 T for\n            magnetometers, 1 V for EEG, so resulting amplitudes will be tiny.\n            Consider using :func:`mne.make_ad_hoc_cov` to provide a\n            ``noise_cov`` to set noise values that are more reasonable for\n            neural data or using ``weight_norm='nai'`` for weight-normalized\n            beamformer output that is scaled by a noise estimate.\n    label : instance of Label\n        Restricts the LCMV solution to a given label.\n    %(pick_ori_bf)s\n\n        - ``'vector'``\n            Keeps the currents for each direction separate\n    %(rank_info)s\n    %(weight_norm)s\n\n        Defaults to ``'unit-noise-gain-invariant'``.\n    %(reduce_rank)s\n    %(depth)s\n\n        .. versionadded:: 0.18\n    %(inversion_bf)s\n\n        .. versionadded:: 0.21\n    %(verbose)s\n\n    Returns\n    -------\n    filters : instance of Beamformer\n        Dictionary containing filter weights from LCMV beamformer.\n        Contains the following keys:\n\n            'kind' : str\n                The type of beamformer, in this case 'LCMV'.\n            'weights' : array\n                The filter weights of the beamformer.\n            'data_cov' : instance of Covariance\n                The data covariance matrix used to compute the beamformer.\n            'noise_cov' : instance of Covariance | None\n                The noise covariance matrix used to compute the beamformer.\n            'whitener' : None | ndarray, shape (n_channels, n_channels)\n                Whitening matrix, provided if whitening was applied to the\n                covariance matrix and leadfield during computation of the\n                beamformer weights.\n            'weight_norm' : str | None\n                Type of weight normalization used to compute the filter\n                weights.\n            'pick-ori' : None | 'max-power' | 'normal' | 'vector'\n                The orientation in which the beamformer filters were computed.\n            'ch_names' : list of str\n                Channels used to compute the beamformer.\n            'proj' : array\n                Projections used to compute the beamformer.\n            'is_ssp' : bool\n                If True, projections were applied prior to filter computation.\n            'vertices' : list\n                Vertices for which the filter weights were computed.\n            'is_free_ori' : bool\n                If True, the filter was computed with free source orientation.\n            'n_sources' : int\n                Number of source location for which the filter weight were\n                computed.\n            'src_type' : str\n                Type of source space.\n            'source_nn' : ndarray, shape (n_sources, 3)\n                For each source location, the surface normal.\n            'proj' : ndarray, shape (n_channels, n_channels)\n                Projections used to compute the beamformer.\n            'subject' : str\n                The subject ID.\n            'rank' : int\n                The rank of the data covariance matrix used to compute the\n                beamformer weights.\n            'max-power-ori' : ndarray, shape (n_sources, 3) | None\n                When pick_ori='max-power', this fields contains the estimated\n                direction of maximum power at each source location.\n            'inversion' : 'single' | 'matrix'\n                Whether the spatial filters were computed for each dipole\n                separately or jointly for all dipoles at each vertex using a\n                matrix inversion.\n\n    Notes\n    -----\n    The original reference is :footcite:`VanVeenEtAl1997`.\n\n    To obtain the Sekihara unit-noise-gain vector beamformer, you should use\n    ``weight_norm='unit-noise-gain', pick_ori='vector'`` followed by\n    :meth:`vec_stc.project('pca', src) <mne.VectorSourceEstimate.project>`.\n\n    .. versionchanged:: 0.21\n       The computations were extensively reworked, and the default for\n       ``weight_norm`` was set to ``'unit-noise-gain-invariant'``.\n\n    References\n    ----------\n    .. footbibliography::\n    \"\"\"\n    # check number of sensor types present in the data and ensure a noise cov\n    info = _simplify_info(info, keep=(\"proc_history\",))\n    noise_cov, _, allow_mismatch = _check_one_ch_type(\n        \"lcmv\", info, forward, data_cov, noise_cov\n    )\n    # XXX we need this extra picking step (can't just rely on minimum norm's\n    # because there can be a mismatch. Should probably add an extra arg to\n    # _prepare_beamformer_input at some point (later)\n    picks = _check_info_inv(info, forward, data_cov, noise_cov)\n    info = pick_info(info, picks)\n    data_rank = compute_rank(data_cov, rank=rank, info=info)\n    noise_rank = compute_rank(noise_cov, rank=rank, info=info)\n    for key in data_rank:\n        if (\n            key not in noise_rank or data_rank[key] != noise_rank[key]\n        ) and not allow_mismatch:\n            raise ValueError(\n                f\"{key} data rank ({data_rank[key]}) did not match the noise rank (\"\n                f\"{noise_rank.get(key, None)})\"\n            )\n    del noise_rank\n    rank = data_rank\n    logger.info(f\"Making LCMV beamformer with rank {rank}\")\n    del data_rank\n    depth = _check_depth(depth, \"depth_sparse\")\n    if inversion == \"single\":\n        depth[\"combine_xyz\"] = False\n\n    (\n        is_free_ori,\n        info,\n        proj,\n        vertno,\n        G,\n        whitener,\n        nn,\n        orient_std,\n    ) = _prepare_beamformer_input(\n        info,\n        forward,\n        label,\n        pick_ori,\n        noise_cov=noise_cov,\n        rank=rank,\n        pca=False,\n        **depth,\n    )\n    ch_names = list(info[\"ch_names\"])\n\n    data_cov = pick_channels_cov(data_cov, include=ch_names)\n    Cm = data_cov._get_square()\n    if \"estimator\" in data_cov:\n        del data_cov[\"estimator\"]\n    rank_int = sum(rank.values())\n    del rank\n\n    # compute spatial filter\n    n_orient = 3 if is_free_ori else 1\n    W, max_power_ori = _compute_beamformer(\n        G,\n        Cm,\n        reg,\n        n_orient,\n        weight_norm,\n        pick_ori,\n        reduce_rank,\n        rank_int,\n        inversion=inversion,\n        nn=nn,\n        orient_std=orient_std,\n        whitener=whitener,\n    )\n\n    # get src type to store with filters for _make_stc\n    src_type = _get_src_type(forward[\"src\"], vertno)\n\n    # get subject to store with filters\n    subject_from = _subject_from_forward(forward)\n\n    # Is the computed beamformer a scalar or vector beamformer?\n    is_free_ori = is_free_ori if pick_ori in [None, \"vector\"] else False\n    is_ssp = bool(info[\"projs\"])\n\n    filters = Beamformer(\n        kind=\"LCMV\",\n        weights=W,\n        data_cov=data_cov,\n        noise_cov=noise_cov,\n        whitener=whitener,\n        weight_norm=weight_norm,\n        pick_ori=pick_ori,\n        ch_names=ch_names,\n        proj=proj,\n        is_ssp=is_ssp,\n        vertices=vertno,\n        is_free_ori=is_free_ori,\n        n_sources=forward[\"nsource\"],\n        src_type=src_type,\n        source_nn=forward[\"source_nn\"].copy(),\n        subject=subject_from,\n        rank=rank_int,\n        max_power_ori=max_power_ori,\n        inversion=inversion,\n    )\n\n    return filters", "metadata": {}}
{"_id": "mne_mne_beamformer/_lcmv.py_apply_lcmv_code", "title": "apply_lcmv", "text": "def apply_lcmv(evoked, filters, *, verbose=None):\n    \"\"\"Apply Linearly Constrained Minimum Variance (LCMV) beamformer weights.\n\n    Apply Linearly Constrained Minimum Variance (LCMV) beamformer weights\n    on evoked data.\n\n    Parameters\n    ----------\n    evoked : Evoked\n        Evoked data to invert.\n    filters : instance of Beamformer\n        LCMV spatial filter (beamformer weights).\n        Filter weights returned from :func:`make_lcmv`.\n    %(verbose)s\n\n    Returns\n    -------\n    stc : SourceEstimate | VolSourceEstimate | VectorSourceEstimate\n        Source time courses.\n\n    See Also\n    --------\n    make_lcmv, apply_lcmv_raw, apply_lcmv_epochs, apply_lcmv_cov\n\n    Notes\n    -----\n    .. versionadded:: 0.18\n    \"\"\"\n    _check_reference(evoked)\n\n    info = evoked.info\n    data = evoked.data\n    tmin = evoked.times[0]\n\n    sel = _check_channels_spatial_filter(evoked.ch_names, filters)\n    data = data[sel]\n\n    stc = _apply_lcmv(data=data, filters=filters, info=info, tmin=tmin)\n\n    return next(stc)", "metadata": {}}
{"_id": "mne_mne_beamformer/_lcmv.py_apply_lcmv_epochs_code", "title": "apply_lcmv_epochs", "text": "def apply_lcmv_epochs(epochs, filters, *, return_generator=False, verbose=None):\n    \"\"\"Apply Linearly Constrained Minimum Variance (LCMV) beamformer weights.\n\n    Apply Linearly Constrained Minimum Variance (LCMV) beamformer weights\n    on single trial data.\n\n    Parameters\n    ----------\n    epochs : Epochs\n        Single trial epochs.\n    filters : instance of Beamformer\n        LCMV spatial filter (beamformer weights)\n        Filter weights returned from :func:`make_lcmv`.\n    return_generator : bool\n         Return a generator object instead of a list. This allows iterating\n         over the stcs without having to keep them all in memory.\n    %(verbose)s\n\n    Returns\n    -------\n    stc: list | generator of (SourceEstimate | VolSourceEstimate)\n        The source estimates for all epochs.\n\n    See Also\n    --------\n    make_lcmv, apply_lcmv_raw, apply_lcmv, apply_lcmv_cov\n    \"\"\"\n    _check_reference(epochs)\n\n    info = epochs.info\n    tmin = epochs.times[0]\n\n    sel = _check_channels_spatial_filter(epochs.ch_names, filters)\n    data = epochs.get_data(sel)\n    stcs = _apply_lcmv(data=data, filters=filters, info=info, tmin=tmin)\n\n    if not return_generator:\n        stcs = [s for s in stcs]\n\n    return stcs", "metadata": {}}
{"_id": "mne_mne_beamformer/_lcmv.py_apply_lcmv_raw_code", "title": "apply_lcmv_raw", "text": "def apply_lcmv_raw(raw, filters, start=None, stop=None, *, verbose=None):\n    \"\"\"Apply Linearly Constrained Minimum Variance (LCMV) beamformer weights.\n\n    Apply Linearly Constrained Minimum Variance (LCMV) beamformer weights\n    on raw data.\n\n    Parameters\n    ----------\n    raw : mne.io.Raw\n        Raw data to invert.\n    filters : instance of Beamformer\n        LCMV spatial filter (beamformer weights).\n        Filter weights returned from :func:`make_lcmv`.\n    start : int\n        Index of first time sample (index not time is seconds).\n    stop : int\n        Index of first time sample not to include (index not time is seconds).\n    %(verbose)s\n\n    Returns\n    -------\n    stc : SourceEstimate | VolSourceEstimate\n        Source time courses.\n\n    See Also\n    --------\n    make_lcmv, apply_lcmv_epochs, apply_lcmv, apply_lcmv_cov\n    \"\"\"\n    _check_reference(raw)\n\n    info = raw.info\n\n    sel = _check_channels_spatial_filter(raw.ch_names, filters)\n    data, times = raw[sel, start:stop]\n    tmin = times[0]\n\n    stc = _apply_lcmv(data=data, filters=filters, info=info, tmin=tmin)\n\n    return next(stc)", "metadata": {}}
{"_id": "mne_mne_beamformer/_lcmv.py_apply_lcmv_cov_code", "title": "apply_lcmv_cov", "text": "def apply_lcmv_cov(data_cov, filters, verbose=None):\n    \"\"\"Apply Linearly Constrained  Minimum Variance (LCMV) beamformer weights.\n\n    Apply Linearly Constrained Minimum Variance (LCMV) beamformer weights\n    to a data covariance matrix to estimate source power.\n\n    Parameters\n    ----------\n    data_cov : instance of Covariance\n        Data covariance matrix.\n    filters : instance of Beamformer\n        LCMV spatial filter (beamformer weights).\n        Filter weights returned from :func:`make_lcmv`.\n    %(verbose)s\n\n    Returns\n    -------\n    stc : SourceEstimate | VolSourceEstimate\n        Source power.\n\n    See Also\n    --------\n    make_lcmv, apply_lcmv, apply_lcmv_epochs, apply_lcmv_raw\n    \"\"\"\n    sel = _check_channels_spatial_filter(data_cov.ch_names, filters)\n    sel_names = [data_cov.ch_names[ii] for ii in sel]\n    data_cov = pick_channels_cov(data_cov, sel_names)\n\n    n_orient = filters[\"weights\"].shape[0] // filters[\"n_sources\"]\n    # Need to project and whiten along both dimensions\n    data = _proj_whiten_data(data_cov[\"data\"].T, data_cov[\"projs\"], filters)\n    data = _proj_whiten_data(data.T, data_cov[\"projs\"], filters)\n    del data_cov\n    source_power = _compute_power(data, filters[\"weights\"], n_orient)\n\n    # compatibility with 0.16, add src_type as None if not present:\n    filters, warn_text = _check_src_type(filters)\n\n    return _make_stc(\n        source_power,\n        vertices=filters[\"vertices\"],\n        src_type=filters[\"src_type\"],\n        tmin=0.0,\n        tstep=1.0,\n        subject=filters[\"subject\"],\n        source_nn=filters[\"source_nn\"],\n        warn_text=warn_text,\n    )", "metadata": {}}
{"_id": "mne_mne__fiff/meas_info.py_read_fiducials_code", "title": "read_fiducials", "text": "def read_fiducials(fname, *, verbose=None):\n    \"\"\"Read fiducials from a fiff file.\n\n    Parameters\n    ----------\n    fname : path-like\n        The filename to read.\n    %(verbose)s\n\n    Returns\n    -------\n    pts : list of dict\n        List of digitizer points (each point in a dict).\n    coord_frame : int\n        The coordinate frame of the points (one of\n        ``mne.io.constants.FIFF.FIFFV_COORD_...``).\n    \"\"\"\n    fname = _check_fname(fname=fname, overwrite=\"read\", must_exist=True)\n    fid, tree, _ = fiff_open(fname)\n    with fid:\n        pts = _read_dig_fif(fid, tree)\n    return pts, pts[0][\"coord_frame\"]", "metadata": {}}
{"_id": "mne_mne__fiff/meas_info.py_write_fiducials_code", "title": "write_fiducials", "text": "def write_fiducials(\n    fname, pts, coord_frame=\"unknown\", *, overwrite=False, verbose=None\n):\n    \"\"\"Write fiducials to a fiff file.\n\n    Parameters\n    ----------\n    fname : path-like\n        Destination file name.\n    pts : iterator of dict\n        Iterator through digitizer points. Each point is a dictionary with\n        the keys 'kind', 'ident' and 'r'.\n    coord_frame : str | int\n        The coordinate frame of the points. If a string, must be one of\n        ``'meg'``, ``'mri'``, ``'mri_voxel'``, ``'head'``,\n        ``'mri_tal'``, ``'ras'``, ``'fs_tal'``, ``'ctf_head'``,\n        ``'ctf_meg'``, and ``'unknown'``\n        If an integer, must be one of the constants defined as\n        ``mne.io.constants.FIFF.FIFFV_COORD_...``.\n    %(overwrite)s\n\n        .. versionadded:: 1.0\n    %(verbose)s\n    \"\"\"\n    write_dig(fname, pts, coord_frame, overwrite=overwrite)", "metadata": {}}
{"_id": "mne_mne__fiff/meas_info.py_read_info_code", "title": "read_info", "text": "def read_info(fname, verbose=None):\n    \"\"\"Read measurement info from a file.\n\n    Parameters\n    ----------\n    fname : path-like\n        File name.\n    %(verbose)s\n\n    Returns\n    -------\n    %(info_not_none)s\n    \"\"\"\n    check_fname(fname, \"Info\", (\".fif\", \".fif.gz\"))\n    fname = _check_fname(fname, must_exist=True, overwrite=\"read\")\n    f, tree, _ = fiff_open(fname)\n    with f as fid:\n        info = read_meas_info(fid, tree)[0]\n    return info", "metadata": {}}
{"_id": "mne_mne__fiff/meas_info.py_read_bad_channels_code", "title": "read_bad_channels", "text": "def read_bad_channels(fid, node):\n    \"\"\"Read bad channels.\n\n    Parameters\n    ----------\n    fid : file\n        The file descriptor.\n    node : dict\n        The node of the FIF tree that contains info on the bad channels.\n\n    Returns\n    -------\n    bads : list\n        A list of bad channel's names.\n    \"\"\"\n    return _read_bad_channels(fid, node)", "metadata": {}}
{"_id": "mne_mne__fiff/meas_info.py_read_meas_info_code", "title": "read_meas_info", "text": "def read_meas_info(fid, tree, clean_bads=False, verbose=None):\n    \"\"\"Read the measurement info.\n\n    Parameters\n    ----------\n    fid : file\n        Open file descriptor.\n    tree : tree\n        FIF tree structure.\n    clean_bads : bool\n        If True, clean info['bads'] before running consistency check.\n        Should only be needed for old files where we did not check bads\n        before saving.\n    %(verbose)s\n\n    Returns\n    -------\n    %(info_not_none)s\n    meas : dict\n        Node in tree that contains the info.\n    \"\"\"\n    from ..transforms import Transform, invert_transform\n\n    #   Find the desired blocks\n    meas = dir_tree_find(tree, FIFF.FIFFB_MEAS)\n    if len(meas) == 0:\n        raise ValueError(\"Could not find measurement data\")\n    if len(meas) > 1:\n        raise ValueError(\"Cannot read more that 1 measurement data\")\n    meas = meas[0]\n\n    meas_info = dir_tree_find(meas, FIFF.FIFFB_MEAS_INFO)\n    if len(meas_info) == 0:\n        raise ValueError(\"Could not find measurement info\")\n    if len(meas_info) > 1:\n        raise ValueError(\"Cannot read more that 1 measurement info\")\n    meas_info = meas_info[0]\n\n    #   Read measurement info\n    dev_head_t = None\n    ctf_head_t = None\n    dev_ctf_t = None\n    meas_date = None\n    utc_offset = None\n    highpass = None\n    lowpass = None\n    nchan = None\n    sfreq = None\n    chs = []\n    experimenter = None\n    description = None\n    proj_id = None\n    proj_name = None\n    line_freq = None\n    gantry_angle = None\n    custom_ref_applied = FIFF.FIFFV_MNE_CUSTOM_REF_OFF\n    xplotter_layout = None\n    kit_system_id = None\n    for k in range(meas_info[\"nent\"]):\n        kind = meas_info[\"directory\"][k].kind\n        pos = meas_info[\"directory\"][k].pos\n        if kind == FIFF.FIFF_NCHAN:\n            tag = read_tag(fid, pos)\n            nchan = int(tag.data.item())\n        elif kind == FIFF.FIFF_SFREQ:\n            tag = read_tag(fid, pos)\n            sfreq = float(tag.data.item())\n        elif kind == FIFF.FIFF_CH_INFO:\n            tag = read_tag(fid, pos)\n            chs.append(tag.data)\n        elif kind == FIFF.FIFF_LOWPASS:\n            tag = read_tag(fid, pos)\n            if not np.isnan(tag.data.item()):\n                lowpass = float(tag.data.item())\n        elif kind == FIFF.FIFF_HIGHPASS:\n            tag = read_tag(fid, pos)\n            if not np.isnan(tag.data):\n                highpass = float(tag.data.item())\n        elif kind == FIFF.FIFF_MEAS_DATE:\n            tag = read_tag(fid, pos)\n            meas_date = tuple(tag.data)\n            if len(meas_date) == 1:  # can happen from old C conversions\n                meas_date = (meas_date[0], 0)\n        elif kind == FIFF.FIFF_UTC_OFFSET:\n            tag = read_tag(fid, pos)\n            utc_offset = str(tag.data)\n        elif kind == FIFF.FIFF_COORD_TRANS:\n            tag = read_tag(fid, pos)\n            cand = tag.data\n\n            if (\n                cand[\"from\"] == FIFF.FIFFV_COORD_DEVICE\n                and cand[\"to\"] == FIFF.FIFFV_COORD_HEAD\n            ):\n                dev_head_t = cand\n            elif (\n                cand[\"from\"] == FIFF.FIFFV_COORD_HEAD\n                and cand[\"to\"] == FIFF.FIFFV_COORD_DEVICE\n            ):\n                # this reversal can happen with BabyMEG data\n                dev_head_t = invert_transform(cand)\n            elif (\n                cand[\"from\"] == FIFF.FIFFV_MNE_COORD_CTF_HEAD\n                and cand[\"to\"] == FIFF.FIFFV_COORD_HEAD\n            ):\n                ctf_head_t = cand\n            elif (\n                cand[\"from\"] == FIFF.FIFFV_MNE_COORD_CTF_DEVICE\n                and cand[\"to\"] == FIFF.FIFFV_MNE_COORD_CTF_HEAD\n            ):\n                dev_ctf_t = cand\n        elif kind == FIFF.FIFF_EXPERIMENTER:\n            tag = read_tag(fid, pos)\n            experimenter = tag.data\n        elif kind == FIFF.FIFF_DESCRIPTION:\n            tag = read_tag(fid, pos)\n            description = tag.data\n        elif kind == FIFF.FIFF_PROJ_ID:\n            tag = read_tag(fid, pos)\n            proj_id = tag.data\n        elif kind == FIFF.FIFF_PROJ_NAME:\n            tag = read_tag(fid, pos)\n            proj_name = tag.data\n        elif kind == FIFF.FIFF_LINE_FREQ:\n            tag = read_tag(fid, pos)\n            line_freq = float(tag.data.item())\n        elif kind == FIFF.FIFF_GANTRY_ANGLE:\n            tag = read_tag(fid, pos)\n            gantry_angle = float(tag.data.item())\n        elif kind in [FIFF.FIFF_MNE_CUSTOM_REF, 236]:  # 236 used before v0.11\n            tag = read_tag(fid, pos)\n            custom_ref_applied = int(tag.data.item())\n        elif kind == FIFF.FIFF_XPLOTTER_LAYOUT:\n            tag = read_tag(fid, pos)\n            xplotter_layout = str(tag.data)\n        elif kind == FIFF.FIFF_MNE_KIT_SYSTEM_ID:\n            tag = read_tag(fid, pos)\n            kit_system_id = int(tag.data.item())\n    ch_names_mapping = _read_extended_ch_info(chs, meas_info, fid)\n\n    # Check that we have everything we need\n    if nchan is None:\n        raise ValueError(\"Number of channels is not defined\")\n\n    if sfreq is None:\n        raise ValueError(\"Sampling frequency is not defined\")\n\n    if len(chs) == 0:\n        raise ValueError(\"Channel information not defined\")\n\n    if len(chs) != nchan:\n        raise ValueError(\"Incorrect number of channel definitions found\")\n\n    if dev_head_t is None or ctf_head_t is None:\n        hpi_result = dir_tree_find(meas_info, FIFF.FIFFB_HPI_RESULT)\n        if len(hpi_result) == 1:\n            hpi_result = hpi_result[0]\n            for k in range(hpi_result[\"nent\"]):\n                kind = hpi_result[\"directory\"][k].kind\n                pos = hpi_result[\"directory\"][k].pos\n                if kind == FIFF.FIFF_COORD_TRANS:\n                    tag = read_tag(fid, pos)\n                    cand = tag.data\n                    if (\n                        cand[\"from\"] == FIFF.FIFFV_COORD_DEVICE\n                        and cand[\"to\"] == FIFF.FIFFV_COORD_HEAD\n                        and dev_head_t is None\n                    ):\n                        dev_head_t = cand\n                    elif (\n                        cand[\"from\"] == FIFF.FIFFV_MNE_COORD_CTF_HEAD\n                        and cand[\"to\"] == FIFF.FIFFV_COORD_HEAD\n                        and ctf_head_t is None\n                    ):\n                        ctf_head_t = cand\n\n    #   Locate the Polhemus data\n    dig = _read_dig_fif(fid, meas_info)\n\n    #   Locate the acquisition information\n    acqpars = dir_tree_find(meas_info, FIFF.FIFFB_DACQ_PARS)\n    acq_pars = None\n    acq_stim = None\n    if len(acqpars) == 1:\n        acqpars = acqpars[0]\n        for k in range(acqpars[\"nent\"]):\n            kind = acqpars[\"directory\"][k].kind\n            pos = acqpars[\"directory\"][k].pos\n            if kind == FIFF.FIFF_DACQ_PARS:\n                tag = read_tag(fid, pos)\n                acq_pars = tag.data\n            elif kind == FIFF.FIFF_DACQ_STIM:\n                tag = read_tag(fid, pos)\n                acq_stim = tag.data\n\n    #   Load the SSP data\n    projs = _read_proj(fid, meas_info, ch_names_mapping=ch_names_mapping)\n\n    #   Load the CTF compensation data\n    comps = _read_ctf_comp(fid, meas_info, chs, ch_names_mapping=ch_names_mapping)\n\n    #   Load the bad channel list\n    bads = _read_bad_channels(fid, meas_info, ch_names_mapping=ch_names_mapping)\n\n    #\n    #   Put the data together\n    #\n    info = Info(file_id=tree[\"id\"])\n    info._unlocked = True\n\n    #   Locate events list\n    events = dir_tree_find(meas_info, FIFF.FIFFB_EVENTS)\n    evs = list()\n    for event in events:\n        ev = dict()\n        for k in range(event[\"nent\"]):\n            kind = event[\"directory\"][k].kind\n            pos = event[\"directory\"][k].pos\n            if kind == FIFF.FIFF_EVENT_CHANNELS:\n                ev[\"channels\"] = read_tag(fid, pos).data\n            elif kind == FIFF.FIFF_EVENT_LIST:\n                ev[\"list\"] = read_tag(fid, pos).data\n        evs.append(ev)\n    info[\"events\"] = evs\n\n    #   Locate HPI result\n    hpi_results = dir_tree_find(meas_info, FIFF.FIFFB_HPI_RESULT)\n    hrs = list()\n    for hpi_result in hpi_results:\n        hr = dict()\n        hr[\"dig_points\"] = []\n        for k in range(hpi_result[\"nent\"]):\n            kind = hpi_result[\"directory\"][k].kind\n            pos = hpi_result[\"directory\"][k].pos\n            if kind == FIFF.FIFF_DIG_POINT:\n                hr[\"dig_points\"].append(read_tag(fid, pos).data)\n            elif kind == FIFF.FIFF_HPI_DIGITIZATION_ORDER:\n                hr[\"order\"] = read_tag(fid, pos).data\n            elif kind == FIFF.FIFF_HPI_COILS_USED:\n                hr[\"used\"] = read_tag(fid, pos).data\n            elif kind == FIFF.FIFF_HPI_COIL_MOMENTS:\n                hr[\"moments\"] = read_tag(fid, pos).data\n            elif kind == FIFF.FIFF_HPI_FIT_GOODNESS:\n                hr[\"goodness\"] = read_tag(fid, pos).data\n            elif kind == FIFF.FIFF_HPI_FIT_GOOD_LIMIT:\n                hr[\"good_limit\"] = float(read_tag(fid, pos).data.item())\n            elif kind == FIFF.FIFF_HPI_FIT_DIST_LIMIT:\n                hr[\"dist_limit\"] = float(read_tag(fid, pos).data.item())\n            elif kind == FIFF.FIFF_HPI_FIT_ACCEPT:\n                hr[\"accept\"] = int(read_tag(fid, pos).data.item())\n            elif kind == FIFF.FIFF_COORD_TRANS:\n                hr[\"coord_trans\"] = read_tag(fid, pos).data\n        hrs.append(hr)\n    info[\"hpi_results\"] = hrs\n\n    #   Locate HPI Measurement\n    hpi_meass = dir_tree_find(meas_info, FIFF.FIFFB_HPI_MEAS)\n    hms = list()\n    for hpi_meas in hpi_meass:\n        hm = dict()\n        for k in range(hpi_meas[\"nent\"]):\n            kind = hpi_meas[\"directory\"][k].kind\n            pos = hpi_meas[\"directory\"][k].pos\n            if kind == FIFF.FIFF_CREATOR:\n                hm[\"creator\"] = str(read_tag(fid, pos).data)\n            elif kind == FIFF.FIFF_SFREQ:\n                hm[\"sfreq\"] = float(read_tag(fid, pos).data.item())\n            elif kind == FIFF.FIFF_NCHAN:\n                hm[\"nchan\"] = int(read_tag(fid, pos).data.item())\n            elif kind == FIFF.FIFF_NAVE:\n                hm[\"nave\"] = int(read_tag(fid, pos).data.item())\n            elif kind == FIFF.FIFF_HPI_NCOIL:\n                hm[\"ncoil\"] = int(read_tag(fid, pos).data.item())\n            elif kind == FIFF.FIFF_FIRST_SAMPLE:\n                hm[\"first_samp\"] = int(read_tag(fid, pos).data.item())\n            elif kind == FIFF.FIFF_LAST_SAMPLE:\n                hm[\"last_samp\"] = int(read_tag(fid, pos).data.item())\n        hpi_coils = dir_tree_find(hpi_meas, FIFF.FIFFB_HPI_COIL)\n        hcs = []\n        for hpi_coil in hpi_coils:\n            hc = dict()\n            for k in range(hpi_coil[\"nent\"]):\n                kind = hpi_coil[\"directory\"][k].kind\n                pos = hpi_coil[\"directory\"][k].pos\n                if kind == FIFF.FIFF_HPI_COIL_NO:\n                    hc[\"number\"] = int(read_tag(fid, pos).data.item())\n                elif kind == FIFF.FIFF_EPOCH:\n                    hc[\"epoch\"] = read_tag(fid, pos).data\n                    hc[\"epoch\"].flags.writeable = False\n                elif kind == FIFF.FIFF_HPI_SLOPES:\n                    hc[\"slopes\"] = read_tag(fid, pos).data\n                    hc[\"slopes\"].flags.writeable = False\n                elif kind == FIFF.FIFF_HPI_CORR_COEFF:\n                    hc[\"corr_coeff\"] = read_tag(fid, pos).data\n                    hc[\"corr_coeff\"].flags.writeable = False\n                elif kind == FIFF.FIFF_HPI_COIL_FREQ:\n                    hc[\"coil_freq\"] = float(read_tag(fid, pos).data.item())\n            hcs.append(hc)\n        hm[\"hpi_coils\"] = hcs\n        hms.append(hm)\n    info[\"hpi_meas\"] = hms\n    del hms\n\n    subject_info = dir_tree_find(meas_info, FIFF.FIFFB_SUBJECT)\n    si = None\n    if len(subject_info) == 1:\n        subject_info = subject_info[0]\n        si = dict()\n        for k in range(subject_info[\"nent\"]):\n            kind = subject_info[\"directory\"][k].kind\n            pos = subject_info[\"directory\"][k].pos\n            if kind == FIFF.FIFF_SUBJ_ID:\n                tag = read_tag(fid, pos)\n                si[\"id\"] = int(tag.data.item())\n            elif kind == FIFF.FIFF_SUBJ_HIS_ID:\n                tag = read_tag(fid, pos)\n                si[\"his_id\"] = str(tag.data)\n            elif kind == FIFF.FIFF_SUBJ_LAST_NAME:\n                tag = read_tag(fid, pos)\n                si[\"last_name\"] = str(tag.data)\n            elif kind == FIFF.FIFF_SUBJ_FIRST_NAME:\n                tag = read_tag(fid, pos)\n                si[\"first_name\"] = str(tag.data)\n            elif kind == FIFF.FIFF_SUBJ_MIDDLE_NAME:\n                tag = read_tag(fid, pos)\n                si[\"middle_name\"] = str(tag.data)\n            elif kind == FIFF.FIFF_SUBJ_BIRTH_DAY:\n                try:\n                    tag = read_tag(fid, pos)\n                except OverflowError:\n                    warn(\n                        \"Encountered an error while trying to read the \"\n                        \"birthday from the input data. No birthday will be \"\n                        \"set. Please check the integrity of the birthday \"\n                        \"information in the input data.\"\n                    )\n                    continue\n                si[\"birthday\"] = tag.data\n            elif kind == FIFF.FIFF_SUBJ_SEX:\n                tag = read_tag(fid, pos)\n                si[\"sex\"] = int(tag.data.item())\n            elif kind == FIFF.FIFF_SUBJ_HAND:\n                tag = read_tag(fid, pos)\n                si[\"hand\"] = int(tag.data.item())\n            elif kind == FIFF.FIFF_SUBJ_WEIGHT:\n                tag = read_tag(fid, pos)\n                si[\"weight\"] = float(tag.data.item())\n            elif kind == FIFF.FIFF_SUBJ_HEIGHT:\n                tag = read_tag(fid, pos)\n                si[\"height\"] = float(tag.data.item())\n    info[\"subject_info\"] = si\n    del si\n\n    device_info = dir_tree_find(meas_info, FIFF.FIFFB_DEVICE)\n    di = None\n    if len(device_info) == 1:\n        device_info = device_info[0]\n        di = dict()\n        for k in range(device_info[\"nent\"]):\n            kind = device_info[\"directory\"][k].kind\n            pos = device_info[\"directory\"][k].pos\n            if kind == FIFF.FIFF_DEVICE_TYPE:\n                tag = read_tag(fid, pos)\n                di[\"type\"] = str(tag.data)\n            elif kind == FIFF.FIFF_DEVICE_MODEL:\n                tag = read_tag(fid, pos)\n                di[\"model\"] = str(tag.data)\n            elif kind == FIFF.FIFF_DEVICE_SERIAL:\n                tag = read_tag(fid, pos)\n                di[\"serial\"] = str(tag.data)\n            elif kind == FIFF.FIFF_DEVICE_SITE:\n                tag = read_tag(fid, pos)\n                di[\"site\"] = str(tag.data)\n    info[\"device_info\"] = di\n    del di\n\n    helium_info = dir_tree_find(meas_info, FIFF.FIFFB_HELIUM)\n    hi = None\n    if len(helium_info) == 1:\n        helium_info = helium_info[0]\n        hi = dict()\n        for k in range(helium_info[\"nent\"]):\n            kind = helium_info[\"directory\"][k].kind\n            pos = helium_info[\"directory\"][k].pos\n            if kind == FIFF.FIFF_HE_LEVEL_RAW:\n                tag = read_tag(fid, pos)\n                hi[\"he_level_raw\"] = float(tag.data.item())\n            elif kind == FIFF.FIFF_HELIUM_LEVEL:\n                tag = read_tag(fid, pos)\n                hi[\"helium_level\"] = float(tag.data.item())\n            elif kind == FIFF.FIFF_ORIG_FILE_GUID:\n                tag = read_tag(fid, pos)\n                hi[\"orig_file_guid\"] = str(tag.data)\n            elif kind == FIFF.FIFF_MEAS_DATE:\n                tag = read_tag(fid, pos)\n                hi[\"meas_date\"] = _ensure_meas_date_none_or_dt(\n                    tuple(int(t) for t in tag.data),\n                )\n        if \"meas_date\" not in hi:\n            hi[\"meas_date\"] = None\n    info[\"helium_info\"] = hi\n    del hi\n\n    hpi_subsystem = dir_tree_find(meas_info, FIFF.FIFFB_HPI_SUBSYSTEM)\n    hs = None\n    if len(hpi_subsystem) == 1:\n        hpi_subsystem = hpi_subsystem[0]\n        hs = dict()\n        for k in range(hpi_subsystem[\"nent\"]):\n            kind = hpi_subsystem[\"directory\"][k].kind\n            pos = hpi_subsystem[\"directory\"][k].pos\n            if kind == FIFF.FIFF_HPI_NCOIL:\n                tag = read_tag(fid, pos)\n                hs[\"ncoil\"] = int(tag.data.item())\n            elif kind == FIFF.FIFF_EVENT_CHANNEL:\n                tag = read_tag(fid, pos)\n                hs[\"event_channel\"] = str(tag.data)\n            hpi_coils = dir_tree_find(hpi_subsystem, FIFF.FIFFB_HPI_COIL)\n            hc = []\n            for coil in hpi_coils:\n                this_coil = dict()\n                for j in range(coil[\"nent\"]):\n                    kind = coil[\"directory\"][j].kind\n                    pos = coil[\"directory\"][j].pos\n                    if kind == FIFF.FIFF_EVENT_BITS:\n                        tag = read_tag(fid, pos)\n                        this_coil[\"event_bits\"] = np.array(tag.data)\n                hc.append(this_coil)\n            hs[\"hpi_coils\"] = hc\n    info[\"hpi_subsystem\"] = hs\n\n    #   Read processing history\n    info[\"proc_history\"] = _read_proc_history(fid, tree)\n\n    #  Make the most appropriate selection for the measurement id\n    if meas_info[\"parent_id\"] is None:\n        if meas_info[\"id\"] is None:\n            if meas[\"id\"] is None:\n                if meas[\"parent_id\"] is None:\n                    info[\"meas_id\"] = info[\"file_id\"]\n                else:\n                    info[\"meas_id\"] = meas[\"parent_id\"]\n            else:\n                info[\"meas_id\"] = meas[\"id\"]\n        else:\n            info[\"meas_id\"] = meas_info[\"id\"]\n    else:\n        info[\"meas_id\"] = meas_info[\"parent_id\"]\n    info[\"experimenter\"] = experimenter\n    info[\"description\"] = description\n    info[\"proj_id\"] = proj_id\n    info[\"proj_name\"] = proj_name\n    if meas_date is None:\n        meas_date = (info[\"meas_id\"][\"secs\"], info[\"meas_id\"][\"usecs\"])\n    info[\"meas_date\"] = _ensure_meas_date_none_or_dt(meas_date)\n    info[\"utc_offset\"] = utc_offset\n\n    info[\"sfreq\"] = sfreq\n    info[\"highpass\"] = highpass if highpass is not None else 0.0\n    info[\"lowpass\"] = lowpass if lowpass is not None else info[\"sfreq\"] / 2.0\n    info[\"line_freq\"] = line_freq\n    info[\"gantry_angle\"] = gantry_angle\n\n    #   Add the channel information and make a list of channel names\n    #   for convenience\n    info[\"chs\"] = chs\n\n    #\n    #   Add the coordinate transformations\n    #\n    info[\"dev_head_t\"] = dev_head_t\n    info[\"ctf_head_t\"] = ctf_head_t\n    info[\"dev_ctf_t\"] = dev_ctf_t\n    if dev_head_t is not None and ctf_head_t is not None and dev_ctf_t is None:\n        head_ctf_trans = np.linalg.inv(ctf_head_t[\"trans\"])\n        dev_ctf_trans = np.dot(head_ctf_trans, info[\"dev_head_t\"][\"trans\"])\n        info[\"dev_ctf_t\"] = Transform(\"meg\", \"ctf_head\", dev_ctf_trans)\n\n    #   All kinds of auxliary stuff\n    info[\"dig\"] = _format_dig_points(dig)\n    info[\"bads\"] = bads\n    info._update_redundant()\n    if clean_bads:\n        info[\"bads\"] = [b for b in bads if b in info[\"ch_names\"]]\n    info[\"projs\"] = projs\n    info[\"comps\"] = comps\n    info[\"acq_pars\"] = acq_pars\n    info[\"acq_stim\"] = acq_stim\n    info[\"custom_ref_applied\"] = custom_ref_applied\n    info[\"xplotter_layout\"] = xplotter_layout\n    info[\"kit_system_id\"] = kit_system_id\n    info._check_consistency()\n    info._unlocked = False\n    return info, meas", "metadata": {}}
{"_id": "mne_mne__fiff/meas_info.py_write_meas_info_code", "title": "write_meas_info", "text": "def write_meas_info(fid, info, data_type=None, reset_range=True):\n    \"\"\"Write measurement info into a file id (from a fif file).\n\n    Parameters\n    ----------\n    fid : file\n        Open file descriptor.\n    %(info_not_none)s\n    data_type : int\n        The data_type in case it is necessary. Should be 4 (FIFFT_FLOAT),\n        5 (FIFFT_DOUBLE), or 16 (FIFFT_DAU_PACK16) for\n        raw data.\n    reset_range : bool\n        If True, info['chs'][k]['range'] will be set to unity.\n\n    Notes\n    -----\n    Tags are written in a particular order for compatibility with maxfilter.\n    \"\"\"\n    info._check_consistency()\n    _check_dates(info)\n\n    # Measurement info\n    start_block(fid, FIFF.FIFFB_MEAS_INFO)\n\n    # Add measurement id\n    if info[\"meas_id\"] is not None:\n        write_id(fid, FIFF.FIFF_PARENT_BLOCK_ID, info[\"meas_id\"])\n\n    for event in info[\"events\"]:\n        start_block(fid, FIFF.FIFFB_EVENTS)\n        if event.get(\"channels\") is not None:\n            write_int(fid, FIFF.FIFF_EVENT_CHANNELS, event[\"channels\"])\n        if event.get(\"list\") is not None:\n            write_int(fid, FIFF.FIFF_EVENT_LIST, event[\"list\"])\n        end_block(fid, FIFF.FIFFB_EVENTS)\n\n    #   HPI Result\n    for hpi_result in info[\"hpi_results\"]:\n        start_block(fid, FIFF.FIFFB_HPI_RESULT)\n        write_dig_points(fid, hpi_result[\"dig_points\"])\n        if \"order\" in hpi_result:\n            write_int(fid, FIFF.FIFF_HPI_DIGITIZATION_ORDER, hpi_result[\"order\"])\n        if \"used\" in hpi_result:\n            write_int(fid, FIFF.FIFF_HPI_COILS_USED, hpi_result[\"used\"])\n        if \"moments\" in hpi_result:\n            write_float_matrix(fid, FIFF.FIFF_HPI_COIL_MOMENTS, hpi_result[\"moments\"])\n        if \"goodness\" in hpi_result:\n            write_float(fid, FIFF.FIFF_HPI_FIT_GOODNESS, hpi_result[\"goodness\"])\n        if \"good_limit\" in hpi_result:\n            write_float(fid, FIFF.FIFF_HPI_FIT_GOOD_LIMIT, hpi_result[\"good_limit\"])\n        if \"dist_limit\" in hpi_result:\n            write_float(fid, FIFF.FIFF_HPI_FIT_DIST_LIMIT, hpi_result[\"dist_limit\"])\n        if \"accept\" in hpi_result:\n            write_int(fid, FIFF.FIFF_HPI_FIT_ACCEPT, hpi_result[\"accept\"])\n        if \"coord_trans\" in hpi_result:\n            write_coord_trans(fid, hpi_result[\"coord_trans\"])\n        end_block(fid, FIFF.FIFFB_HPI_RESULT)\n\n    #   HPI Measurement\n    for hpi_meas in info[\"hpi_meas\"]:\n        start_block(fid, FIFF.FIFFB_HPI_MEAS)\n        if hpi_meas.get(\"creator\") is not None:\n            write_string(fid, FIFF.FIFF_CREATOR, hpi_meas[\"creator\"])\n        if hpi_meas.get(\"sfreq\") is not None:\n            write_float(fid, FIFF.FIFF_SFREQ, hpi_meas[\"sfreq\"])\n        if hpi_meas.get(\"nchan\") is not None:\n            write_int(fid, FIFF.FIFF_NCHAN, hpi_meas[\"nchan\"])\n        if hpi_meas.get(\"nave\") is not None:\n            write_int(fid, FIFF.FIFF_NAVE, hpi_meas[\"nave\"])\n        if hpi_meas.get(\"ncoil\") is not None:\n            write_int(fid, FIFF.FIFF_HPI_NCOIL, hpi_meas[\"ncoil\"])\n        if hpi_meas.get(\"first_samp\") is not None:\n            write_int(fid, FIFF.FIFF_FIRST_SAMPLE, hpi_meas[\"first_samp\"])\n        if hpi_meas.get(\"last_samp\") is not None:\n            write_int(fid, FIFF.FIFF_LAST_SAMPLE, hpi_meas[\"last_samp\"])\n        for hpi_coil in hpi_meas[\"hpi_coils\"]:\n            start_block(fid, FIFF.FIFFB_HPI_COIL)\n            if hpi_coil.get(\"number\") is not None:\n                write_int(fid, FIFF.FIFF_HPI_COIL_NO, hpi_coil[\"number\"])\n            if hpi_coil.get(\"epoch\") is not None:\n                write_float_matrix(fid, FIFF.FIFF_EPOCH, hpi_coil[\"epoch\"])\n            if hpi_coil.get(\"slopes\") is not None:\n                write_float(fid, FIFF.FIFF_HPI_SLOPES, hpi_coil[\"slopes\"])\n            if hpi_coil.get(\"corr_coeff\") is not None:\n                write_float(fid, FIFF.FIFF_HPI_CORR_COEFF, hpi_coil[\"corr_coeff\"])\n            if hpi_coil.get(\"coil_freq\") is not None:\n                write_float(fid, FIFF.FIFF_HPI_COIL_FREQ, hpi_coil[\"coil_freq\"])\n            end_block(fid, FIFF.FIFFB_HPI_COIL)\n        end_block(fid, FIFF.FIFFB_HPI_MEAS)\n\n    #   Polhemus data\n    write_dig_points(fid, info[\"dig\"], block=True)\n\n    #   megacq parameters\n    if info[\"acq_pars\"] is not None or info[\"acq_stim\"] is not None:\n        start_block(fid, FIFF.FIFFB_DACQ_PARS)\n        if info[\"acq_pars\"] is not None:\n            write_string(fid, FIFF.FIFF_DACQ_PARS, info[\"acq_pars\"])\n\n        if info[\"acq_stim\"] is not None:\n            write_string(fid, FIFF.FIFF_DACQ_STIM, info[\"acq_stim\"])\n\n        end_block(fid, FIFF.FIFFB_DACQ_PARS)\n\n    #   Coordinate transformations if the HPI result block was not there\n    if info[\"dev_head_t\"] is not None:\n        write_coord_trans(fid, info[\"dev_head_t\"])\n\n    if info[\"ctf_head_t\"] is not None:\n        write_coord_trans(fid, info[\"ctf_head_t\"])\n\n    if info[\"dev_ctf_t\"] is not None:\n        write_coord_trans(fid, info[\"dev_ctf_t\"])\n\n    #   Projectors\n    ch_names_mapping = _make_ch_names_mapping(info[\"chs\"])\n    _write_proj(fid, info[\"projs\"], ch_names_mapping=ch_names_mapping)\n\n    #   Bad channels\n    _write_bad_channels(fid, info[\"bads\"], ch_names_mapping=ch_names_mapping)\n\n    #   General\n    if info.get(\"experimenter\") is not None:\n        write_string(fid, FIFF.FIFF_EXPERIMENTER, info[\"experimenter\"])\n    if info.get(\"description\") is not None:\n        write_string(fid, FIFF.FIFF_DESCRIPTION, info[\"description\"])\n    if info.get(\"proj_id\") is not None:\n        write_int(fid, FIFF.FIFF_PROJ_ID, info[\"proj_id\"])\n    if info.get(\"proj_name\") is not None:\n        write_string(fid, FIFF.FIFF_PROJ_NAME, info[\"proj_name\"])\n    if info.get(\"meas_date\") is not None:\n        write_int(fid, FIFF.FIFF_MEAS_DATE, _dt_to_stamp(info[\"meas_date\"]))\n    if info.get(\"utc_offset\") is not None:\n        write_string(fid, FIFF.FIFF_UTC_OFFSET, info[\"utc_offset\"])\n    write_int(fid, FIFF.FIFF_NCHAN, info[\"nchan\"])\n    write_float(fid, FIFF.FIFF_SFREQ, info[\"sfreq\"])\n    if info[\"lowpass\"] is not None:\n        write_float(fid, FIFF.FIFF_LOWPASS, info[\"lowpass\"])\n    if info[\"highpass\"] is not None:\n        write_float(fid, FIFF.FIFF_HIGHPASS, info[\"highpass\"])\n    if info.get(\"line_freq\") is not None:\n        write_float(fid, FIFF.FIFF_LINE_FREQ, info[\"line_freq\"])\n    if info.get(\"gantry_angle\") is not None:\n        write_float(fid, FIFF.FIFF_GANTRY_ANGLE, info[\"gantry_angle\"])\n    if data_type is not None:\n        write_int(fid, FIFF.FIFF_DATA_PACK, data_type)\n    if info.get(\"custom_ref_applied\"):\n        write_int(fid, FIFF.FIFF_MNE_CUSTOM_REF, info[\"custom_ref_applied\"])\n    if info.get(\"xplotter_layout\"):\n        write_string(fid, FIFF.FIFF_XPLOTTER_LAYOUT, info[\"xplotter_layout\"])\n\n    #  Channel information\n    _write_ch_infos(fid, info[\"chs\"], reset_range, ch_names_mapping)\n\n    # Subject information\n    if info.get(\"subject_info\") is not None:\n        start_block(fid, FIFF.FIFFB_SUBJECT)\n        si = info[\"subject_info\"]\n        if si.get(\"id\") is not None:\n            write_int(fid, FIFF.FIFF_SUBJ_ID, si[\"id\"])\n        if si.get(\"his_id\") is not None:\n            write_string(fid, FIFF.FIFF_SUBJ_HIS_ID, si[\"his_id\"])\n        if si.get(\"last_name\") is not None:\n            write_string(fid, FIFF.FIFF_SUBJ_LAST_NAME, si[\"last_name\"])\n        if si.get(\"first_name\") is not None:\n            write_string(fid, FIFF.FIFF_SUBJ_FIRST_NAME, si[\"first_name\"])\n        if si.get(\"middle_name\") is not None:\n            write_string(fid, FIFF.FIFF_SUBJ_MIDDLE_NAME, si[\"middle_name\"])\n        if si.get(\"birthday\") is not None:\n            write_julian(fid, FIFF.FIFF_SUBJ_BIRTH_DAY, si[\"birthday\"])\n        if si.get(\"sex\") is not None:\n            write_int(fid, FIFF.FIFF_SUBJ_SEX, si[\"sex\"])\n        if si.get(\"hand\") is not None:\n            write_int(fid, FIFF.FIFF_SUBJ_HAND, si[\"hand\"])\n        if si.get(\"weight\") is not None:\n            write_float(fid, FIFF.FIFF_SUBJ_WEIGHT, si[\"weight\"])\n        if si.get(\"height\") is not None:\n            write_float(fid, FIFF.FIFF_SUBJ_HEIGHT, si[\"height\"])\n        end_block(fid, FIFF.FIFFB_SUBJECT)\n        del si\n\n    if info.get(\"device_info\") is not None:\n        start_block(fid, FIFF.FIFFB_DEVICE)\n        di = info[\"device_info\"]\n        if di.get(\"type\") is not None:\n            write_string(fid, FIFF.FIFF_DEVICE_TYPE, di[\"type\"])\n        for key in (\"model\", \"serial\", \"site\"):\n            if di.get(key) is not None:\n                write_string(fid, getattr(FIFF, \"FIFF_DEVICE_\" + key.upper()), di[key])\n        end_block(fid, FIFF.FIFFB_DEVICE)\n        del di\n\n    if info.get(\"helium_info\") is not None:\n        start_block(fid, FIFF.FIFFB_HELIUM)\n        hi = info[\"helium_info\"]\n        if hi.get(\"he_level_raw\") is not None:\n            write_float(fid, FIFF.FIFF_HE_LEVEL_RAW, hi[\"he_level_raw\"])\n        if hi.get(\"helium_level\") is not None:\n            write_float(fid, FIFF.FIFF_HELIUM_LEVEL, hi[\"helium_level\"])\n        if hi.get(\"orig_file_guid\") is not None:\n            write_string(fid, FIFF.FIFF_ORIG_FILE_GUID, hi[\"orig_file_guid\"])\n        if hi[\"meas_date\"] is not None:\n            write_int(fid, FIFF.FIFF_MEAS_DATE, _dt_to_stamp(hi[\"meas_date\"]))\n        end_block(fid, FIFF.FIFFB_HELIUM)\n        del hi\n\n    if info.get(\"hpi_subsystem\") is not None:\n        hs = info[\"hpi_subsystem\"]\n        start_block(fid, FIFF.FIFFB_HPI_SUBSYSTEM)\n        if hs.get(\"ncoil\") is not None:\n            write_int(fid, FIFF.FIFF_HPI_NCOIL, hs[\"ncoil\"])\n        if hs.get(\"event_channel\") is not None:\n            write_string(fid, FIFF.FIFF_EVENT_CHANNEL, hs[\"event_channel\"])\n        if hs.get(\"hpi_coils\") is not None:\n            for coil in hs[\"hpi_coils\"]:\n                start_block(fid, FIFF.FIFFB_HPI_COIL)\n                if coil.get(\"event_bits\") is not None:\n                    write_int(fid, FIFF.FIFF_EVENT_BITS, coil[\"event_bits\"])\n                end_block(fid, FIFF.FIFFB_HPI_COIL)\n        end_block(fid, FIFF.FIFFB_HPI_SUBSYSTEM)\n        del hs\n\n    #   CTF compensation info\n    comps = info[\"comps\"]\n    if ch_names_mapping:\n        comps = deepcopy(comps)\n        _rename_comps(comps, ch_names_mapping)\n    write_ctf_comp(fid, comps)\n\n    #   KIT system ID\n    if info.get(\"kit_system_id\") is not None:\n        write_int(fid, FIFF.FIFF_MNE_KIT_SYSTEM_ID, info[\"kit_system_id\"])\n\n    end_block(fid, FIFF.FIFFB_MEAS_INFO)\n\n    #   Processing history\n    _write_proc_history(fid, info)", "metadata": {}}
{"_id": "mne_mne__fiff/meas_info.py_write_info_code", "title": "write_info", "text": "def write_info(\n    fname, info, *, data_type=None, reset_range=True, overwrite=False, verbose=None\n):\n    \"\"\"Write measurement info in fif file.\n\n    Parameters\n    ----------\n    fname : path-like\n        The name of the file. Should end by ``-info.fif``.\n    %(info_not_none)s\n    data_type : int\n        The data_type in case it is necessary. Should be 4 (FIFFT_FLOAT),\n        5 (FIFFT_DOUBLE), or 16 (FIFFT_DAU_PACK16) for\n        raw data.\n    reset_range : bool\n        If True, info['chs'][k]['range'] will be set to unity.\n    %(overwrite)s\n    %(verbose)s\n    \"\"\"\n    with start_and_end_file(fname, overwrite=overwrite) as fid:\n        start_block(fid, FIFF.FIFFB_MEAS)\n        write_meas_info(fid, info, data_type, reset_range)\n        end_block(fid, FIFF.FIFFB_MEAS)", "metadata": {}}
{"_id": "mne_mne__fiff/meas_info.py_create_info_code", "title": "create_info", "text": "def create_info(ch_names, sfreq, ch_types=\"misc\", verbose=None):\n    \"\"\"Create a basic Info instance suitable for use with create_raw.\n\n    Parameters\n    ----------\n    ch_names : list of str | int\n        Channel names. If an int, a list of channel names will be created\n        from ``range(ch_names)``.\n    sfreq : float\n        Sample rate of the data.\n    ch_types : list of str | str\n        Channel types, default is ``'misc'`` which is a\n        :term:`non-data channel <non-data channels>`.\n        Currently supported fields are 'bio', 'chpi', 'csd', 'dbs', 'dipole',\n        'ecg', 'ecog', 'eeg', 'emg', 'eog', 'exci', 'eyegaze',\n        'fnirs_cw_amplitude', 'fnirs_fd_ac_amplitude', 'fnirs_fd_phase',\n        'fnirs_od', 'gof', 'gsr', 'hbo', 'hbr', 'ias', 'misc', 'pupil',\n        'ref_meg', 'resp', 'seeg', 'stim', 'syst', 'temperature' (see also\n        :term:`sensor types`).\n        If str, then all channels are assumed to be of the same type.\n    %(verbose)s\n\n    Returns\n    -------\n    %(info_not_none)s\n\n    Notes\n    -----\n    The info dictionary will be sparsely populated to enable functionality\n    within the rest of the package. Advanced functionality such as source\n    localization can only be obtained through substantial, proper\n    modifications of the info structure (not recommended).\n\n    Note that the MEG device-to-head transform ``info['dev_head_t']`` will\n    be initialized to the identity transform.\n\n    Proper units of measure:\n\n    * V: eeg, eog, seeg, dbs, emg, ecg, bio, ecog, resp, fnirs_fd_ac_amplitude,\n      fnirs_cw_amplitude, fnirs_od\n    * T: mag, chpi, ref_meg\n    * T/m: grad\n    * M: hbo, hbr\n    * rad: fnirs_fd_phase\n    * Am: dipole\n    * S: gsr\n    * C: temperature\n    * V/m\u00b2: csd\n    * GOF: gof\n    * AU: misc, stim, eyegaze, pupil\n    \"\"\"\n    try:\n        ch_names = operator.index(ch_names)  # int-like\n    except TypeError:\n        pass\n    else:\n        ch_names = list(np.arange(ch_names).astype(str))\n    _validate_type(ch_names, (list, tuple), \"ch_names\", (\"list, tuple, or int\"))\n    sfreq = float(sfreq)\n    if sfreq <= 0:\n        raise ValueError(\"sfreq must be positive\")\n    nchan = len(ch_names)\n    if isinstance(ch_types, str):\n        ch_types = [ch_types] * nchan\n    ch_types = np.atleast_1d(np.array(ch_types, np.str_))\n    if ch_types.ndim != 1 or len(ch_types) != nchan:\n        raise ValueError(\n            f\"ch_types and ch_names must be the same length ({len(ch_types)} != \"\n            f\"{nchan}) for ch_types={ch_types}\"\n        )\n    info = _empty_info(sfreq)\n    ch_types_dict = get_channel_type_constants(include_defaults=True)\n    for ci, (ch_name, ch_type) in enumerate(zip(ch_names, ch_types)):\n        _validate_type(ch_name, \"str\", \"each entry in ch_names\")\n        _validate_type(ch_type, \"str\", \"each entry in ch_types\")\n        if ch_type not in ch_types_dict:\n            raise KeyError(f\"kind must be one of {list(ch_types_dict)}, not {ch_type}\")\n        this_ch_dict = ch_types_dict[ch_type]\n        kind = this_ch_dict[\"kind\"]\n        # handle chpi, where kind is a *list* of FIFF constants:\n        kind = kind[0] if isinstance(kind, list | tuple) else kind\n        # mirror what tag.py does here\n        coord_frame = _ch_coord_dict.get(kind, FIFF.FIFFV_COORD_UNKNOWN)\n        coil_type = this_ch_dict.get(\"coil_type\", FIFF.FIFFV_COIL_NONE)\n        unit = this_ch_dict.get(\"unit\", FIFF.FIFF_UNIT_NONE)\n        chan_info = dict(\n            loc=np.full(12, np.nan),\n            unit_mul=FIFF.FIFF_UNITM_NONE,\n            range=1.0,\n            cal=1.0,\n            kind=kind,\n            coil_type=coil_type,\n            unit=unit,\n            coord_frame=coord_frame,\n            ch_name=str(ch_name),\n            scanno=ci + 1,\n            logno=ci + 1,\n        )\n        info[\"chs\"].append(chan_info)\n\n    info._update_redundant()\n    info._check_consistency()\n    info._unlocked = False\n    return info", "metadata": {}}
{"_id": "mne_mne__fiff/meas_info.py_anonymize_info_code", "title": "anonymize_info", "text": "def anonymize_info(info, daysback=None, keep_his=False, verbose=None):\n    \"\"\"Anonymize measurement information in place.\n\n    .. warning:: If ``info`` is part of an object like\n                 :class:`raw.info <mne.io.Raw>`, you should directly use\n                 the method :meth:`raw.anonymize() <mne.io.Raw.anonymize>`\n                 to ensure that all parts of the data are anonymized and\n                 stay synchronized (e.g.,\n                 :class:`raw.annotations <mne.Annotations>`).\n\n    Parameters\n    ----------\n    %(info_not_none)s\n    %(daysback_anonymize_info)s\n    %(keep_his_anonymize_info)s\n    %(verbose)s\n\n    Returns\n    -------\n    info : instance of Info\n        The anonymized measurement information.\n\n    Notes\n    -----\n    %(anonymize_info_notes)s\n    \"\"\"\n    _validate_type(info, \"info\", \"self\")\n\n    default_anon_dos = datetime.datetime(\n        2000, 1, 1, 0, 0, 0, tzinfo=datetime.timezone.utc\n    )\n    default_str = \"mne_anonymize\"\n    default_subject_id = 0\n    default_sex = 0\n    default_desc = \"Anonymized using a time shift to preserve age at acquisition\"\n\n    none_meas_date = info[\"meas_date\"] is None\n\n    if none_meas_date:\n        if daysback is not None:\n            warn(\n                'Input info has \"meas_date\" set to None. '\n                \"Removing all information from time/date structures, \"\n                \"*NOT* performing any time shifts!\"\n            )\n    else:\n        # compute timeshift delta\n        if daysback is None:\n            delta_t = info[\"meas_date\"] - default_anon_dos\n        else:\n            delta_t = datetime.timedelta(days=daysback)\n        with info._unlock():\n            info[\"meas_date\"] = info[\"meas_date\"] - delta_t\n\n    # file_id and meas_id\n    for key in (\"file_id\", \"meas_id\"):\n        value = info.get(key)\n        if value is not None:\n            assert \"msecs\" not in value\n            if none_meas_date or ((value[\"secs\"], value[\"usecs\"]) == DATE_NONE):\n                # Don't try to shift backwards in time when no measurement\n                # date is available or when file_id is already a place holder\n                tmp = DATE_NONE\n            else:\n                tmp = _add_timedelta_to_stamp((value[\"secs\"], value[\"usecs\"]), -delta_t)\n            value[\"secs\"] = tmp[0]\n            value[\"usecs\"] = tmp[1]\n            # The following copy is needed for a test CTF dataset\n            # otherwise value['machid'][:] = 0 would suffice\n            _tmp = value[\"machid\"].copy()\n            _tmp[:] = 0\n            value[\"machid\"] = _tmp\n\n    # subject info\n    subject_info = info.get(\"subject_info\")\n    if subject_info is not None:\n        if subject_info.get(\"id\") is not None:\n            subject_info[\"id\"] = default_subject_id\n        if keep_his:\n            logger.info(\n                \"Not fully anonymizing info - keeping his_id, sex, and hand info\"\n            )\n        else:\n            if subject_info.get(\"his_id\") is not None:\n                subject_info[\"his_id\"] = str(default_subject_id)\n            if subject_info.get(\"sex\") is not None:\n                subject_info[\"sex\"] = default_sex\n            if subject_info.get(\"hand\") is not None:\n                del subject_info[\"hand\"]  # there's no \"unknown\" setting\n\n        for key in (\"last_name\", \"first_name\", \"middle_name\"):\n            if subject_info.get(key) is not None:\n                subject_info[key] = default_str\n\n        # anonymize the subject birthday\n        if none_meas_date:\n            subject_info.pop(\"birthday\", None)\n        elif subject_info.get(\"birthday\") is not None:\n            subject_info[\"birthday\"] = subject_info[\"birthday\"] - delta_t\n\n        for key in (\"weight\", \"height\"):\n            if subject_info.get(key) is not None:\n                subject_info[key] = 0\n\n    info[\"experimenter\"] = default_str\n    info[\"description\"] = default_desc\n    with info._unlock():\n        if info[\"proj_id\"] is not None:\n            info[\"proj_id\"] = np.zeros_like(info[\"proj_id\"])\n        if info[\"proj_name\"] is not None:\n            info[\"proj_name\"] = default_str\n        if info[\"utc_offset\"] is not None:\n            info[\"utc_offset\"] = None\n\n    proc_hist = info.get(\"proc_history\")\n    if proc_hist is not None:\n        for record in proc_hist:\n            record[\"block_id\"][\"machid\"][:] = 0\n            record[\"experimenter\"] = default_str\n            if none_meas_date:\n                record[\"block_id\"][\"secs\"] = DATE_NONE[0]\n                record[\"block_id\"][\"usecs\"] = DATE_NONE[1]\n                record[\"date\"] = DATE_NONE\n            else:\n                this_t0 = (record[\"block_id\"][\"secs\"], record[\"block_id\"][\"usecs\"])\n                this_t1 = _add_timedelta_to_stamp(this_t0, -delta_t)\n                record[\"block_id\"][\"secs\"] = this_t1[0]\n                record[\"block_id\"][\"usecs\"] = this_t1[1]\n                record[\"date\"] = _add_timedelta_to_stamp(record[\"date\"], -delta_t)\n\n    hi = info.get(\"helium_info\")\n    if hi is not None:\n        if hi.get(\"orig_file_guid\") is not None:\n            hi[\"orig_file_guid\"] = default_str\n        if none_meas_date and hi.get(\"meas_date\") is not None:\n            hi[\"meas_date\"] = _ensure_meas_date_none_or_dt(DATE_NONE)\n        elif hi.get(\"meas_date\") is not None:\n            hi[\"meas_date\"] = hi[\"meas_date\"] - delta_t\n\n    di = info.get(\"device_info\")\n    if di is not None:\n        for k in (\"serial\", \"site\"):\n            if di.get(k) is not None:\n                di[k] = default_str\n\n    err_mesg = (\n        \"anonymize_info generated an inconsistent info object. Underlying Error:\\n\"\n    )\n    info._check_consistency(prepend_error=err_mesg)\n    err_mesg = (\n        \"anonymize_info generated an inconsistent info object. \"\n        \"daysback parameter was too large. \"\n        \"Underlying Error:\\n\"\n    )\n    _check_dates(info, prepend_error=err_mesg)\n\n    return info", "metadata": {}}
{"_id": "mne_mne__fiff/meas_info.py_get_montage_code", "title": "get_montage", "text": "def get_montage(self):\n        \"\"\"Get a DigMontage from instance.\n\n        Returns\n        -------\n        montage : None | DigMontage\n            A copy of the channel positions, if available, otherwise ``None``.\n        \"\"\"\n        from ..channels.montage import make_dig_montage\n        from ..transforms import _frame_to_str\n\n        info = self if isinstance(self, Info) else self.info\n        if info[\"dig\"] is None:\n            return None\n        # obtain coord_frame, and landmark coords\n        # (nasion, lpa, rpa, hsp, hpi) from DigPoints\n        montage_bunch = _get_data_as_dict_from_dig(info[\"dig\"])\n        coord_frame = _frame_to_str.get(montage_bunch.coord_frame)\n\n        # get the channel names and chs data structure\n        ch_names, chs = info[\"ch_names\"], info[\"chs\"]\n        picks = pick_types(\n            info,\n            meg=False,\n            eeg=True,\n            seeg=True,\n            ecog=True,\n            dbs=True,\n            fnirs=True,\n            exclude=[],\n        )\n\n        # channel positions from dig do not match ch_names one to one,\n        # so use loc[:3] instead\n        ch_pos = {ch_names[ii]: chs[ii][\"loc\"][:3] for ii in picks}\n\n        # fNIRS uses multiple channels for the same sensors, we use\n        # a private function to format these for dig montage.\n        fnirs_picks = pick_types(info, fnirs=True, exclude=[])\n        if len(ch_pos) == len(fnirs_picks):\n            ch_pos = _get_fnirs_ch_pos(info)\n        elif len(fnirs_picks) > 0:\n            raise ValueError(\n                \"MNE does not support getting the montage \"\n                \"for a mix of fNIRS and other data types. \"\n                \"Please raise a GitHub issue if you \"\n                \"require this feature.\"\n            )\n\n        # create montage\n        montage = make_dig_montage(\n            ch_pos=ch_pos,\n            coord_frame=coord_frame,\n            nasion=montage_bunch.nasion,\n            lpa=montage_bunch.lpa,\n            rpa=montage_bunch.rpa,\n            hsp=montage_bunch.hsp,\n            hpi=montage_bunch.hpi,\n        )\n        return montage", "metadata": {}}
{"_id": "mne_mne__fiff/meas_info.py_set_montage_code", "title": "set_montage", "text": "def set_montage(\n        self,\n        montage,\n        match_case=True,\n        match_alias=False,\n        on_missing=\"raise\",\n        verbose=None,\n    ):\n        \"\"\"Set %(montage_types)s channel positions and digitization points.\n\n        Parameters\n        ----------\n        %(montage)s\n        %(match_case)s\n        %(match_alias)s\n        %(on_missing_montage)s\n        %(verbose)s\n\n        Returns\n        -------\n        inst : instance of Raw | Epochs | Evoked\n            The instance, modified in-place.\n\n        See Also\n        --------\n        mne.channels.make_standard_montage\n        mne.channels.make_dig_montage\n        mne.channels.read_custom_montage\n\n        Notes\n        -----\n        .. warning::\n            Only %(montage_types)s channels can have their positions set using\n            a montage. Other channel types (e.g., MEG channels) should have\n            their positions defined properly using their data reading\n            functions.\n        .. warning::\n            Applying a montage will only set locations of channels that exist\n            at the time it is applied. This means when\n            :ref:`re-referencing <tut-set-eeg-ref>`\n            make sure to apply the montage only after calling\n            :func:`mne.add_reference_channels`\n        \"\"\"\n        # How to set up a montage to old named fif file (walk through example)\n        # https://gist.github.com/massich/f6a9f4799f1fbeb8f5e8f8bc7b07d3df\n\n        from ..channels.montage import _set_montage\n\n        info = self if isinstance(self, Info) else self.info\n        _set_montage(info, montage, match_case, match_alias, on_missing)\n        return self", "metadata": {}}
{"_id": "mne_mne__fiff/meas_info.py_set_channel_types_code", "title": "set_channel_types", "text": "def set_channel_types(self, mapping, *, on_unit_change=\"warn\", verbose=None):\n        \"\"\"Specify the sensor types of channels.\n\n        Parameters\n        ----------\n        mapping : dict\n            A dictionary mapping channel names to sensor types, e.g.,\n            ``{'EEG061': 'eog'}``.\n        on_unit_change : ``'raise'`` | ``'warn'`` | ``'ignore'``\n            What to do if the measurement unit of a channel is changed\n            automatically to match the new sensor type.\n\n            .. versionadded:: 1.4\n        %(verbose)s\n\n        Returns\n        -------\n        inst : instance of Raw | Epochs | Evoked\n            The instance (modified in place).\n\n            .. versionchanged:: 0.20\n               Return the instance.\n\n        Notes\n        -----\n        The following :term:`sensor types` are accepted:\n\n            bio, chpi, csd, dbs, dipole, ecg, ecog, eeg, emg, eog, exci,\n            eyegaze, fnirs_cw_amplitude, fnirs_fd_ac_amplitude, fnirs_fd_phase,\n            fnirs_od, gof, gsr, hbo, hbr, ias, misc, pupil, ref_meg, resp,\n            seeg, stim, syst, temperature.\n\n        When working with eye-tracking data, see\n        :func:`mne.preprocessing.eyetracking.set_channel_types_eyetrack`.\n\n        .. versionadded:: 0.9.0\n        \"\"\"\n        info = self if isinstance(self, Info) else self.info\n        ch_names = info[\"ch_names\"]\n\n        # first check and assemble clean mappings of index and name\n        unit_changes = dict()\n        for ch_name, ch_type in mapping.items():\n            if ch_name not in ch_names:\n                raise ValueError(\n                    f\"This channel name ({ch_name}) doesn't exist in info.\"\n                )\n\n            c_ind = ch_names.index(ch_name)\n            if ch_type not in _human2fiff:\n                raise ValueError(\n                    f\"This function cannot change to this channel type: {ch_type}. \"\n                    \"Accepted channel types are \"\n                    f\"{', '.join(sorted(_human2unit.keys()))}.\"\n                )\n            # Set sensor type\n            _check_set(info[\"chs\"][c_ind], info[\"projs\"], ch_type)\n            unit_old = info[\"chs\"][c_ind][\"unit\"]\n            unit_new = _human2unit[ch_type]\n            if unit_old not in _unit2human:\n                raise ValueError(\n                    f\"Channel '{ch_name}' has unknown unit ({unit_old}). Please fix the\"\n                    \" measurement info of your data.\"\n                )\n            if unit_old != _human2unit[ch_type]:\n                this_change = (_unit2human[unit_old], _unit2human[unit_new])\n                if this_change not in unit_changes:\n                    unit_changes[this_change] = list()\n                unit_changes[this_change].append(ch_name)\n                # reset unit multiplication factor since the unit has now changed\n                info[\"chs\"][c_ind][\"unit_mul\"] = _ch_unit_mul_named[0]\n            info[\"chs\"][c_ind][\"unit\"] = _human2unit[ch_type]\n            if ch_type in [\"eeg\", \"seeg\", \"ecog\", \"dbs\"]:\n                coil_type = FIFF.FIFFV_COIL_EEG\n            elif ch_type == \"hbo\":\n                coil_type = FIFF.FIFFV_COIL_FNIRS_HBO\n            elif ch_type == \"hbr\":\n                coil_type = FIFF.FIFFV_COIL_FNIRS_HBR\n            elif ch_type == \"fnirs_cw_amplitude\":\n                coil_type = FIFF.FIFFV_COIL_FNIRS_CW_AMPLITUDE\n            elif ch_type == \"fnirs_fd_ac_amplitude\":\n                coil_type = FIFF.FIFFV_COIL_FNIRS_FD_AC_AMPLITUDE\n            elif ch_type == \"fnirs_fd_phase\":\n                coil_type = FIFF.FIFFV_COIL_FNIRS_FD_PHASE\n            elif ch_type == \"fnirs_od\":\n                coil_type = FIFF.FIFFV_COIL_FNIRS_OD\n            elif ch_type == \"eyetrack_pos\":\n                coil_type = FIFF.FIFFV_COIL_EYETRACK_POS\n            elif ch_type == \"eyetrack_pupil\":\n                coil_type = FIFF.FIFFV_COIL_EYETRACK_PUPIL\n            else:\n                coil_type = FIFF.FIFFV_COIL_NONE\n            info[\"chs\"][c_ind][\"coil_type\"] = coil_type\n\n        msg = \"The unit for channel(s) {0} has changed from {1} to {2}.\"\n        for this_change, names in unit_changes.items():\n            _on_missing(\n                on_missing=on_unit_change,\n                msg=msg.format(\", \".join(sorted(names)), *this_change),\n                name=\"on_unit_change\",\n            )\n\n        return self", "metadata": {}}
{"_id": "mne_mne__fiff/meas_info.py_rename_channels_code", "title": "rename_channels", "text": "def rename_channels(self, mapping, allow_duplicates=False, *, verbose=None):\n        \"\"\"Rename channels.\n\n        Parameters\n        ----------\n        %(mapping_rename_channels_duplicates)s\n        %(verbose)s\n\n        Returns\n        -------\n        inst : instance of Raw | Epochs | Evoked\n            The instance (modified in place).\n\n            .. versionchanged:: 0.20\n               Return the instance.\n\n        Notes\n        -----\n        .. versionadded:: 0.9.0\n        \"\"\"\n        from ..channels.channels import rename_channels\n        from ..io import BaseRaw\n\n        info = self if isinstance(self, Info) else self.info\n\n        ch_names_orig = list(info[\"ch_names\"])\n        rename_channels(info, mapping, allow_duplicates)\n\n        # Update self._orig_units for Raw\n        if isinstance(self, BaseRaw):\n            # whatever mapping was provided, now we can just use a dict\n            mapping = dict(zip(ch_names_orig, info[\"ch_names\"]))\n            for old_name, new_name in mapping.items():\n                if old_name in self._orig_units:\n                    self._orig_units[new_name] = self._orig_units.pop(old_name)\n            ch_names = self.annotations.ch_names\n            for ci, ch in enumerate(ch_names):\n                ch_names[ci] = tuple(mapping.get(name, name) for name in ch)\n\n        return self", "metadata": {}}
{"_id": "mne_mne__fiff/meas_info.py_plot_sensors_code", "title": "plot_sensors", "text": "def plot_sensors(\n        self,\n        kind=\"topomap\",\n        ch_type=None,\n        title=None,\n        show_names=False,\n        ch_groups=None,\n        to_sphere=True,\n        axes=None,\n        block=False,\n        show=True,\n        sphere=None,\n        *,\n        verbose=None,\n    ):\n        \"\"\"Plot sensor positions.\n\n        Parameters\n        ----------\n        kind : str\n            Whether to plot the sensors as 3d, topomap or as an interactive\n            sensor selection dialog. Available options 'topomap', '3d',\n            'select'. If 'select', a set of channels can be selected\n            interactively by using lasso selector or clicking while holding\n            control key. The selected channels are returned along with the\n            figure instance. Defaults to 'topomap'.\n        ch_type : None | str\n            The channel type to plot. Available options ``'mag'``, ``'grad'``,\n            ``'eeg'``, ``'seeg'``, ``'dbs'``, ``'ecog'``, ``'all'``. If ``'all'``, all\n            the available mag, grad, eeg, seeg, dbs, and ecog channels are plotted. If\n            None (default), then channels are chosen in the order given above.\n        title : str | None\n            Title for the figure. If None (default), equals to ``'Sensor\n            positions (%%s)' %% ch_type``.\n        show_names : bool | array of str\n            Whether to display all channel names. If an array, only the channel\n            names in the array are shown. Defaults to False.\n        ch_groups : 'position' | array of shape (n_ch_groups, n_picks) | None\n            Channel groups for coloring the sensors. If None (default), default\n            coloring scheme is used. If 'position', the sensors are divided\n            into 8 regions. See ``order`` kwarg of :func:`mne.viz.plot_raw`. If\n            array, the channels are divided by picks given in the array.\n\n            .. versionadded:: 0.13.0\n        to_sphere : bool\n            Whether to project the 3d locations to a sphere. When False, the\n            sensor array appears similar as to looking downwards straight above\n            the subject's head. Has no effect when kind='3d'. Defaults to True.\n\n            .. versionadded:: 0.14.0\n        axes : instance of Axes | instance of Axes3D | None\n            Axes to draw the sensors to. If ``kind='3d'``, axes must be an\n            instance of Axes3D. If None (default), a new axes will be created.\n\n            .. versionadded:: 0.13.0\n        block : bool\n            Whether to halt program execution until the figure is closed.\n            Defaults to False.\n\n            .. versionadded:: 0.13.0\n        show : bool\n            Show figure if True. Defaults to True.\n        %(sphere_topomap_auto)s\n        %(verbose)s\n\n        Returns\n        -------\n        fig : instance of Figure\n            Figure containing the sensor topography.\n        selection : list\n            A list of selected channels. Only returned if ``kind=='select'``.\n\n        See Also\n        --------\n        mne.viz.plot_layout\n\n        Notes\n        -----\n        This function plots the sensor locations from the info structure using\n        matplotlib. For drawing the sensors using PyVista see\n        :func:`mne.viz.plot_alignment`.\n\n        .. versionadded:: 0.12.0\n        \"\"\"\n        from ..viz.utils import plot_sensors\n\n        return plot_sensors(\n            self if isinstance(self, Info) else self.info,\n            kind=kind,\n            ch_type=ch_type,\n            title=title,\n            show_names=show_names,\n            ch_groups=ch_groups,\n            to_sphere=to_sphere,\n            axes=axes,\n            block=block,\n            show=show,\n            sphere=sphere,\n            verbose=verbose,\n        )", "metadata": {}}
{"_id": "mne_mne__fiff/meas_info.py_anonymize_code", "title": "anonymize", "text": "def anonymize(self, daysback=None, keep_his=False, verbose=None):\n        \"\"\"Anonymize measurement information in place.\n\n        Parameters\n        ----------\n        %(daysback_anonymize_info)s\n        %(keep_his_anonymize_info)s\n        %(verbose)s\n\n        Returns\n        -------\n        inst : instance of Raw | Epochs | Evoked\n            The modified instance.\n\n        Notes\n        -----\n        %(anonymize_info_notes)s\n\n        .. versionadded:: 0.13.0\n        \"\"\"\n        info = self if isinstance(self, Info) else self.info\n        anonymize_info(info, daysback=daysback, keep_his=keep_his, verbose=verbose)\n        self.set_meas_date(info[\"meas_date\"])  # unify annot update\n        return self", "metadata": {}}
{"_id": "mne_mne__fiff/meas_info.py_set_meas_date_code", "title": "set_meas_date", "text": "def set_meas_date(self, meas_date):\n        \"\"\"Set the measurement start date.\n\n        Parameters\n        ----------\n        meas_date : datetime | float | tuple | None\n            The new measurement date.\n            If datetime object, it must be timezone-aware and in UTC.\n            A tuple of (seconds, microseconds) or float (alias for\n            ``(meas_date, 0)``) can also be passed and a datetime\n            object will be automatically created. If None, will remove\n            the time reference.\n\n        Returns\n        -------\n        inst : instance of Raw | Epochs | Evoked\n            The modified raw instance. Operates in place.\n\n        See Also\n        --------\n        mne.io.Raw.anonymize\n\n        Notes\n        -----\n        If you want to remove all time references in the file, call\n        :func:`mne.io.anonymize_info(inst.info) <mne.io.anonymize_info>`\n        after calling ``inst.set_meas_date(None)``.\n\n        .. versionadded:: 0.20\n        \"\"\"\n        from ..annotations import _handle_meas_date\n\n        info = self if isinstance(self, Info) else self.info\n\n        meas_date = _handle_meas_date(meas_date)\n        with info._unlock():\n            info[\"meas_date\"] = meas_date\n\n        # clear file_id and meas_id if needed\n        if meas_date is None:\n            for key in (\"file_id\", \"meas_id\"):\n                value = info.get(key)\n                if value is not None:\n                    assert \"msecs\" not in value\n                    value[\"secs\"] = DATE_NONE[0]\n                    value[\"usecs\"] = DATE_NONE[1]\n                    # The following copy is needed for a test CTF dataset\n                    # otherwise value['machid'][:] = 0 would suffice\n                    _tmp = value[\"machid\"].copy()\n                    _tmp[:] = 0\n                    value[\"machid\"] = _tmp\n\n        if hasattr(self, \"annotations\"):\n            self.annotations._orig_time = meas_date\n        return self", "metadata": {}}
{"_id": "mne_mne__fiff/meas_info.py_compensation_grade_code", "title": "compensation_grade", "text": "def compensation_grade(self):\n        \"\"\"The current gradient compensation grade.\"\"\"\n        info = self if isinstance(self, Info) else self.info\n        return get_current_comp(info)", "metadata": {}}
{"_id": "mne_mne__fiff/meas_info.py_get_channel_types_code", "title": "get_channel_types", "text": "def get_channel_types(self, picks=None, unique=False, only_data_chs=False):\n        \"\"\"Get a list of channel type for each channel.\n\n        Parameters\n        ----------\n        %(picks_all)s\n        unique : bool\n            Whether to return only unique channel types. Default is ``False``.\n        only_data_chs : bool\n            Whether to ignore non-data channels. Default is ``False``.\n\n        Returns\n        -------\n        channel_types : list\n            The channel types.\n        \"\"\"\n        info = self if isinstance(self, Info) else self.info\n        none = \"data\" if only_data_chs else \"all\"\n        picks = _picks_to_idx(info, picks, none, (), allow_empty=False)\n        ch_types = [channel_type(info, pick) for pick in picks]\n        if only_data_chs:\n            ch_types = [\n                ch_type for ch_type in ch_types if ch_type in _DATA_CH_TYPES_SPLIT\n            ]\n        if unique:\n            # set does not preserve order but dict does, so let's just use it\n            ch_types = list({k: k for k in ch_types}.keys())\n        return ch_types", "metadata": {}}
{"_id": "mne_mne__fiff/meas_info.py_update_code", "title": "update", "text": "def update(self, other=None, **kwargs):\n        \"\"\"Update method using __setitem__().\"\"\"\n        iterable = other.items() if isinstance(other, Mapping) else other\n        if other is not None:\n            for key, val in iterable:\n                self[key] = val\n        for key, val in kwargs.items():\n            self[key] = val", "metadata": {}}
{"_id": "mne_mne__fiff/meas_info.py_copy_code", "title": "copy", "text": "def copy(self):\n        \"\"\"Copy the instance.\n\n        Returns\n        -------\n        info : instance of Info\n            The copied info.\n        \"\"\"\n        return deepcopy(self)", "metadata": {}}
{"_id": "mne_mne__fiff/meas_info.py_normalize_proj_code", "title": "normalize_proj", "text": "def normalize_proj(self):\n        \"\"\"(Re-)Normalize projection vectors after subselection.\n\n        Applying projection after sub-selecting a set of channels that\n        were originally used to compute the original projection vectors\n        can be dangerous (e.g., if few channels remain, most power was\n        in channels that are no longer picked, etc.). By default, mne\n        will emit a warning when this is done.\n\n        This function will re-normalize projectors to use only the\n        remaining channels, thus avoiding that warning. Only use this\n        function if you're confident that the projection vectors still\n        adequately capture the original signal of interest.\n        \"\"\"\n        _normalize_proj(self)", "metadata": {}}
{"_id": "mne_mne__fiff/meas_info.py_save_code", "title": "save", "text": "def save(self, fname, *, overwrite=False, verbose=None):\n        \"\"\"Write measurement info in fif file.\n\n        Parameters\n        ----------\n        fname : path-like\n            The name of the file. Should end by ``'-info.fif'``.\n        %(overwrite)s\n\n            .. versionadded:: 1.10\n        %(verbose)s\n\n        See Also\n        --------\n        mne.io.write_info\n        \"\"\"\n        write_info(fname, self, overwrite=overwrite)", "metadata": {}}
{"_id": "mne_mne__fiff/_digitization.py_write_dig_code", "title": "write_dig", "text": "def write_dig(\n    fname, pts, coord_frame=None, *, ch_names=None, overwrite=False, verbose=None\n):\n    \"\"\"Write digitization data to a FIF file.\n\n    Parameters\n    ----------\n    fname : path-like\n        Destination file name.\n    pts : iterator of dict\n        Iterator through digitizer points. Each point is a dictionary with\n        the keys 'kind', 'ident' and 'r'.\n    coord_frame : int | str | None\n        If all the points have the same coordinate frame, specify the type\n        here. Can be None (default) if the points could have varying\n        coordinate frames.\n    ch_names : list of str | None\n        Channel names associated with the digitization points, if available.\n\n        .. versionadded:: 1.9\n    %(overwrite)s\n\n        .. versionadded:: 1.0\n    %(verbose)s\n\n        .. versionadded:: 1.0\n    \"\"\"\n    from ..transforms import _to_const\n\n    fname = _check_fname(fname, overwrite=overwrite)\n    if coord_frame is not None:\n        coord_frame = _to_const(coord_frame)\n        pts_frames = {pt.get(\"coord_frame\", coord_frame) for pt in pts}\n        bad_frames = pts_frames - {coord_frame}\n        if len(bad_frames) > 0:\n            raise ValueError(\n                \"Points have coord_frame entries that are incompatible with \"\n                f\"coord_frame={coord_frame}: {tuple(bad_frames)}.\"\n            )\n    _validate_type(ch_names, (None, list, tuple), \"ch_names\")\n    if ch_names is not None:\n        for ci, ch_name in enumerate(ch_names):\n            _validate_type(ch_name, str, f\"ch_names[{ci}]\")\n\n    with start_and_end_file(fname) as fid:\n        write_dig_points(\n            fid, pts, block=True, coord_frame=coord_frame, ch_names=ch_names\n        )", "metadata": {}}
{"_id": "mne_mne__fiff/open.py_fiff_open_code", "title": "fiff_open", "text": "def fiff_open(fname, preload=False, verbose=None):\n    \"\"\"Open a FIF file.\n\n    Parameters\n    ----------\n    fname : path-like | fid\n        Name of the fif file, or an opened file (will seek back to 0).\n    preload : bool\n        If True, all data from the file is read into a memory buffer. This\n        requires more memory, but can be faster for I/O operations that require\n        frequent seeks.\n    %(verbose)s\n\n    Returns\n    -------\n    fid : file\n        The file descriptor of the open file.\n    tree : fif tree\n        The tree is a complex structure filled with dictionaries,\n        lists and tags.\n    directory : list\n        A list of tags.\n    \"\"\"\n    fid = _fiff_get_fid(fname)\n    try:\n        return _fiff_open(fname, fid, preload)\n    except Exception:\n        fid.close()\n        raise", "metadata": {}}
{"_id": "mne_mne__fiff/open.py_show_fiff_code", "title": "show_fiff", "text": "def show_fiff(\n    fname,\n    indent=\"    \",\n    read_limit=np.inf,\n    max_str=30,\n    output=str,\n    tag=None,\n    *,\n    show_bytes=False,\n    verbose=None,\n):\n    \"\"\"Show FIFF information.\n\n    This function is similar to mne_show_fiff.\n\n    Parameters\n    ----------\n    fname : path-like\n        Filename to evaluate.\n    indent : str\n        How to indent the lines.\n    read_limit : int\n        Max number of bytes of data to read from a tag. Can be np.inf\n        to always read all data (helps test read completion).\n    max_str : int\n        Max number of characters of string representation to print for\n        each tag's data.\n    output : type\n        Either str or list. str is a convenience output for printing.\n    tag : int | None\n        Provide information about this tag. If None (default), all information\n        is shown.\n    show_bytes : bool\n        If True (default False), print the byte offsets of each tag.\n    %(verbose)s\n\n    Returns\n    -------\n    contents : str\n        The contents of the file.\n    \"\"\"\n    if output not in [list, str]:\n        raise ValueError(\"output must be list or str\")\n    if isinstance(tag, str):  # command mne show_fiff passes string\n        tag = int(tag)\n    fname = _check_fname(fname, \"read\", True)\n    f, tree, _ = fiff_open(fname)\n    # This gets set to 0 (unknown) by fiff_open, but FIFFB_ROOT probably\n    # makes more sense for display\n    tree[\"block\"] = FIFF.FIFFB_ROOT\n    with f as fid:\n        out = _show_tree(\n            fid,\n            tree,\n            indent=indent,\n            level=0,\n            read_limit=read_limit,\n            max_str=max_str,\n            tag_id=tag,\n            show_bytes=show_bytes,\n        )\n    if output is str:\n        out = \"\\n\".join(out)\n    return out", "metadata": {}}
{"_id": "mne_mne__fiff/reference.py_add_reference_channels_code", "title": "add_reference_channels", "text": "def add_reference_channels(inst, ref_channels, copy=True):\n    \"\"\"Add reference channels to data that consists of all zeros.\n\n    Adds reference channels to data that were not included during recording.\n    This is useful when you need to re-reference your data to different\n    channels. These added channels will consist of all zeros.\n\n    Parameters\n    ----------\n    inst : instance of Raw | Epochs | Evoked\n        Instance of Raw or Epochs with EEG channels and reference channel(s).\n    %(ref_channels)s\n    copy : bool\n        Specifies whether the data will be copied (True) or modified in-place\n        (False). Defaults to True.\n\n    Returns\n    -------\n    inst : instance of Raw | Epochs | Evoked\n        Data with added EEG reference channels.\n\n    Notes\n    -----\n    .. warning::\n        When :ref:`re-referencing <tut-set-eeg-ref>`,\n        make sure to apply the montage using :meth:`mne.io.Raw.set_montage`\n        only after calling this function. Applying a montage will only set\n        locations of channels that exist at the time it is applied.\n    \"\"\"\n    from ..epochs import BaseEpochs\n    from ..evoked import Evoked\n    from ..io import BaseRaw\n\n    # Check to see that data is preloaded\n    _check_preload(inst, \"add_reference_channels\")\n    _validate_type(ref_channels, (list, tuple, str), \"ref_channels\")\n    if isinstance(ref_channels, str):\n        ref_channels = [ref_channels]\n    for ch in ref_channels:\n        if ch in inst.info[\"ch_names\"]:\n            raise ValueError(f\"Channel {ch} already specified in inst.\")\n\n    # Once CAR is applied (active), don't allow adding channels\n    if _has_eeg_average_ref_proj(inst.info, check_active=True):\n        raise RuntimeError(\"Average reference already applied to data.\")\n\n    if copy:\n        inst = inst.copy()\n\n    if isinstance(inst, BaseRaw | Evoked):\n        data = inst._data\n        refs = np.zeros((len(ref_channels), data.shape[1]))\n        data = np.vstack((data, refs))\n        inst._data = data\n    elif isinstance(inst, BaseEpochs):\n        data = inst._data\n        x, y, z = data.shape\n        refs = np.zeros((x * len(ref_channels), z))\n        data = np.vstack((data.reshape((x * y, z), order=\"F\"), refs))\n        data = data.reshape(x, y + len(ref_channels), z, order=\"F\")\n        inst._data = data\n    else:\n        raise TypeError(\n            f\"inst should be Raw, Epochs, or Evoked instead of {type(inst)}.\"\n        )\n    nchan = len(inst.info[\"ch_names\"])\n\n    if inst.info.get(\"dig\", None) is not None:\n        # A montage has been set. Try to infer location of reference channels.\n        # \"zeroth\" EEG electrode dig points is reference\n        ref_dig_loc = [\n            dl\n            for dl in inst.info[\"dig\"]\n            if (dl[\"kind\"] == FIFF.FIFFV_POINT_EEG and dl[\"ident\"] == 0)\n        ]\n        if len(ref_channels) > 1 or len(ref_dig_loc) != len(ref_channels):\n            ref_dig_array = np.full(12, np.nan)\n            warn(\n                \"Location for this channel is unknown or ambiguous; consider calling \"\n                \"set_montage() after adding new reference channels if needed. \"\n                \"Applying a montage will only set locations of channels that \"\n                \"exist at the time it is applied.\"\n            )\n        else:  # n_ref_channels == 1 and a single ref digitization exists\n            ref_dig_array = np.concatenate(\n                (ref_dig_loc[0][\"r\"], ref_dig_loc[0][\"r\"], np.zeros(6))\n            )\n            # Replace the (possibly new) Ref location for each channel\n            for idx in pick_types(inst.info, meg=False, eeg=True, exclude=[]):\n                inst.info[\"chs\"][idx][\"loc\"][3:6] = ref_dig_loc[0][\"r\"]\n    else:\n        # If no montage has ever been set, we cannot even try to infer a location.\n        ref_dig_array = np.full(12, np.nan)\n\n    for ch in ref_channels:\n        chan_info = {\n            \"ch_name\": ch,\n            \"coil_type\": FIFF.FIFFV_COIL_EEG,\n            \"kind\": FIFF.FIFFV_EEG_CH,\n            \"logno\": nchan + 1,\n            \"scanno\": nchan + 1,\n            \"cal\": 1,\n            \"range\": 1.0,\n            \"unit_mul\": FIFF.FIFF_UNITM_NONE,\n            \"unit\": FIFF.FIFF_UNIT_V,\n            \"coord_frame\": FIFF.FIFFV_COORD_HEAD,\n            \"loc\": ref_dig_array,\n        }\n        inst.info[\"chs\"].append(chan_info)\n        inst.info._update_redundant()\n    range_ = np.arange(1, len(ref_channels) + 1)\n    if isinstance(inst, BaseRaw):\n        inst._cals = np.hstack((inst._cals, [1] * len(ref_channels)))\n        for pi, picks in enumerate(inst._read_picks):\n            inst._read_picks[pi] = np.concatenate([picks, np.max(picks) + range_])\n    elif isinstance(inst, BaseEpochs):\n        picks = inst.picks\n        inst.picks = np.concatenate([picks, np.max(picks) + range_])\n    inst.info._check_consistency()\n    set_eeg_reference(inst, ref_channels=ref_channels, copy=False, verbose=False)\n    return inst", "metadata": {}}
{"_id": "mne_mne__fiff/reference.py_set_eeg_reference_code", "title": "set_eeg_reference", "text": "def set_eeg_reference(\n    inst,\n    ref_channels=\"average\",\n    copy=True,\n    projection=False,\n    ch_type=\"auto\",\n    forward=None,\n    *,\n    joint=False,\n    verbose=None,\n):\n    \"\"\"Specify which reference to use for EEG data.\n\n    Use this function to explicitly specify the desired reference for EEG.\n    This can be either an existing electrode or a new virtual channel.\n    This function will re-reference the data according to the desired\n    reference.\n\n    Note that it is also possible to re-reference the signal using a\n    Laplacian (LAP) \"reference-free\" transformation using the\n    :func:`.compute_current_source_density` function.\n\n    Parameters\n    ----------\n    inst : instance of Raw | Epochs | Evoked\n        Instance of Raw or Epochs with EEG channels and reference channel(s).\n    %(ref_channels_set_eeg_reference)s\n    copy : bool\n        Specifies whether the data will be copied (True) or modified in-place\n        (False). Defaults to True.\n    %(projection_set_eeg_reference)s\n    %(ch_type_set_eeg_reference)s\n    %(forward_set_eeg_reference)s\n    %(joint_set_eeg_reference)s\n    %(verbose)s\n\n    Returns\n    -------\n    inst : instance of Raw | Epochs | Evoked\n        Data with EEG channels re-referenced. If ``ref_channels=\"average\"`` and\n        ``projection=True`` a projection will be added instead of directly\n        re-referencing the data.\n    ref_data : array\n        Array of reference data subtracted from EEG channels. This will be\n        ``None`` if ``projection=True``, or if ``ref_channels`` is ``\"REST\"`` or a\n        :class:`dict`.\n    %(set_eeg_reference_see_also_notes)s\n    \"\"\"\n    from ..forward import Forward\n\n    _check_can_reref(inst)\n\n    if isinstance(ref_channels, dict):\n        logger.info(\"Applying a custom dict-based reference.\")\n        return _apply_dict_reference(inst, ref_channels)\n\n    ch_type = _get_ch_type(inst, ch_type)\n\n    if projection:  # average reference projector\n        if ref_channels != \"average\":\n            raise ValueError(\n                'Setting projection=True is only supported for ref_channels=\"average\", '\n                f\"got {ref_channels!r}.\"\n            )\n        # We need verbose='error' here in case we add projs sequentially\n        if _has_eeg_average_ref_proj(inst.info, ch_type=ch_type, verbose=\"error\"):\n            warn(\n                \"An average reference projection was already added. The data \"\n                \"has been left untouched.\"\n            )\n        else:\n            # Creating an average reference may fail. In this case, make\n            # sure that the custom_ref_applied flag is left untouched.\n            custom_ref_applied = inst.info[\"custom_ref_applied\"]\n\n            try:\n                with inst.info._unlock():\n                    inst.info[\"custom_ref_applied\"] = FIFF.FIFFV_MNE_CUSTOM_REF_OFF\n                if joint:\n                    inst.add_proj(\n                        make_eeg_average_ref_proj(\n                            inst.info, ch_type=ch_type, activate=False\n                        )\n                    )\n                else:\n                    for this_ch_type in ch_type:\n                        inst.add_proj(\n                            make_eeg_average_ref_proj(\n                                inst.info, ch_type=this_ch_type, activate=False\n                            )\n                        )\n            except Exception:\n                with inst.info._unlock():\n                    inst.info[\"custom_ref_applied\"] = custom_ref_applied\n                raise\n            # If the data has been preloaded, projections will no\n            # longer be automatically applied.\n            if inst.preload:\n                logger.info(\n                    \"Average reference projection was added, \"\n                    \"but has not been applied yet. Use the \"\n                    \"apply_proj method to apply it.\"\n                )\n        return inst, None\n    del projection  # not used anymore\n\n    inst = inst.copy() if copy else inst\n    ch_dict = {**{type_: True for type_ in ch_type}, \"meg\": False, \"ref_meg\": False}\n    ch_sel = [inst.ch_names[i] for i in pick_types(inst.info, **ch_dict)]\n\n    if ref_channels == \"REST\":\n        _validate_type(forward, Forward, 'forward when ref_channels=\"REST\"')\n    else:\n        forward = None  # signal to _apply_reference not to do REST\n\n    if ref_channels in (\"average\", \"REST\"):\n        logger.info(f\"Applying {ref_channels} reference.\")\n        ref_channels = ch_sel\n\n    if ref_channels == []:\n        logger.info(\"EEG data marked as already having the desired reference.\")\n    else:\n        logger.info(\n            \"Applying a custom \"\n            f\"{tuple(DEFAULTS['titles'][type_] for type_ in ch_type)} \"\n            \"reference.\"\n        )\n\n    return _apply_reference(inst, ref_channels, ch_sel, forward, ch_type=ch_type)", "metadata": {}}
{"_id": "mne_mne__fiff/reference.py_set_bipolar_reference_code", "title": "set_bipolar_reference", "text": "def set_bipolar_reference(\n    inst,\n    anode,\n    cathode,\n    ch_name=None,\n    ch_info=None,\n    drop_refs=True,\n    copy=True,\n    on_bad=\"warn\",\n    verbose=None,\n):\n    \"\"\"Re-reference selected channels using a bipolar referencing scheme.\n\n    A bipolar reference takes the difference between two channels (the anode\n    minus the cathode) and adds it as a new virtual channel. The original\n    channels will be dropped by default.\n\n    Multiple anodes and cathodes can be specified, in which case multiple\n    virtual channels will be created. The 1st cathode will be subtracted\n    from the 1st anode, the 2nd cathode from the 2nd anode, etc.\n\n    By default, the virtual channels will be annotated with channel-info and\n    -location of the anodes and coil types will be set to EEG_BIPOLAR.\n\n    Parameters\n    ----------\n    inst : instance of Raw | Epochs | Evoked\n        Data containing the unreferenced channels.\n    anode : str | list of str\n        The name(s) of the channel(s) to use as anode in the bipolar reference.\n    cathode : str | list of str\n        The name(s) of the channel(s) to use as cathode in the bipolar\n        reference.\n    ch_name : str | list of str | None\n        The channel name(s) for the virtual channel(s) containing the resulting\n        signal. By default, bipolar channels are named after the anode and\n        cathode, but it is recommended to supply a more meaningful name.\n    ch_info : dict | list of dict | None\n        This parameter can be used to supply a dictionary (or a dictionary for\n        each bipolar channel) containing channel information to merge in,\n        overwriting the default values. Defaults to None.\n    drop_refs : bool\n        Whether to drop the anode/cathode channels from the instance.\n    copy : bool\n        Whether to operate on a copy of the data (True) or modify it in-place\n        (False). Defaults to True.\n    on_bad : str\n        If a bipolar channel is created from a bad anode or a bad cathode, mne\n        warns if on_bad=\"warns\", raises ValueError if on_bad=\"raise\", and does\n        nothing if on_bad=\"ignore\". For \"warn\" and \"ignore\", the new bipolar\n        channel will be marked as bad. Defaults to on_bad=\"warns\".\n    %(verbose)s\n\n    Returns\n    -------\n    inst : instance of Raw | Epochs | Evoked\n        Data with the specified channels re-referenced.\n\n    See Also\n    --------\n    set_eeg_reference : Convenience function for creating an EEG reference.\n\n    Notes\n    -----\n    1. If the anodes contain any EEG channels, this function removes\n       any pre-existing average reference projections.\n\n    2. During source localization, the EEG signal should have an average\n       reference.\n\n    3. The data must be preloaded.\n\n    .. versionadded:: 0.9.0\n    \"\"\"\n    from ..epochs import BaseEpochs, EpochsArray\n    from ..evoked import EvokedArray\n    from ..io import BaseRaw, RawArray\n    from .meas_info import create_info\n\n    _check_can_reref(inst)\n    if not isinstance(anode, list):\n        anode = [anode]\n\n    if not isinstance(cathode, list):\n        cathode = [cathode]\n\n    if len(anode) != len(cathode):\n        raise ValueError(\n            f\"Number of anodes (got {len(anode)}) must equal the number \"\n            f\"of cathodes (got {len(cathode)}).\"\n        )\n\n    if ch_name is None:\n        ch_name = [f\"{a}-{c}\" for (a, c) in zip(anode, cathode)]\n    elif not isinstance(ch_name, list):\n        ch_name = [ch_name]\n    if len(ch_name) != len(anode):\n        raise ValueError(\n            \"Number of channel names must equal the number of \"\n            f\"anodes/cathodes (got {len(ch_name)}).\"\n        )\n\n    # Check for duplicate channel names (it is allowed to give the name of the\n    # anode or cathode channel, as they will be replaced).\n    for ch, a, c in zip(ch_name, anode, cathode):\n        if ch not in [a, c] and ch in inst.ch_names:\n            raise ValueError(\n                f'There is already a channel named \"{ch}\", please '\n                \"specify a different name for the bipolar \"\n                \"channel using the ch_name parameter.\"\n            )\n\n    if ch_info is None:\n        ch_info = [{} for _ in anode]\n    elif not isinstance(ch_info, list):\n        ch_info = [ch_info]\n    if len(ch_info) != len(anode):\n        raise ValueError(\n            \"Number of channel info dictionaries must equal the \"\n            \"number of anodes/cathodes.\"\n        )\n\n    if copy:\n        inst = inst.copy()\n\n    anode = _check_before_reference(\n        inst, ref_from=cathode, ref_to=anode, ch_type=\"auto\"\n    )\n\n    # Create bipolar reference channels by multiplying the data\n    # (channels x time) with a matrix (n_virtual_channels x channels)\n    # and add them to the instance.\n    multiplier = np.zeros((len(anode), len(inst.ch_names)))\n    for idx, (a, c) in enumerate(zip(anode, cathode)):\n        multiplier[idx, inst.ch_names.index(a)] = 1\n        multiplier[idx, inst.ch_names.index(c)] = -1\n\n    ref_info = create_info(\n        ch_names=ch_name,\n        sfreq=inst.info[\"sfreq\"],\n        ch_types=inst.get_channel_types(picks=anode),\n    )\n\n    # Update \"chs\" in Reference-Info.\n    for ch_idx, (an, info) in enumerate(zip(anode, ch_info)):\n        _check_ch_keys(info, ch_idx, name=\"ch_info\", check_min=False)\n        an_idx = inst.ch_names.index(an)\n        # Copy everything from anode (except ch_name).\n        an_chs = {k: v for k, v in inst.info[\"chs\"][an_idx].items() if k != \"ch_name\"}\n        ref_info[\"chs\"][ch_idx].update(an_chs)\n        # Set coil-type to bipolar.\n        ref_info[\"chs\"][ch_idx][\"coil_type\"] = FIFF.FIFFV_COIL_EEG_BIPOLAR\n        # Update with info from ch_info-parameter.\n        ref_info[\"chs\"][ch_idx].update(info)\n\n    # Set other info-keys from original instance.\n    pick_info = {\n        k: v\n        for k, v in inst.info.items()\n        if k not in [\"chs\", \"ch_names\", \"bads\", \"nchan\", \"sfreq\"]\n    }\n\n    with ref_info._unlock():\n        ref_info.update(pick_info)\n\n    # Rereferencing of data.\n    ref_data = multiplier @ inst._data\n\n    if isinstance(inst, BaseRaw):\n        ref_inst = RawArray(ref_data, ref_info, first_samp=inst.first_samp, copy=None)\n    elif isinstance(inst, BaseEpochs):\n        ref_inst = EpochsArray(\n            ref_data,\n            ref_info,\n            events=inst.events,\n            tmin=inst.tmin,\n            event_id=inst.event_id,\n            metadata=inst.metadata,\n        )\n    else:\n        ref_inst = EvokedArray(\n            ref_data,\n            ref_info,\n            tmin=inst.tmin,\n            comment=inst.comment,\n            nave=inst.nave,\n            kind=\"average\",\n        )\n\n    # Add referenced instance to original instance.\n    inst.add_channels([ref_inst], force_update_info=True)\n\n    # Handle bad channels.\n    bad_bipolar_chs = []\n    for ch_idx, (a, c) in enumerate(zip(anode, cathode)):\n        if a in inst.info[\"bads\"] or c in inst.info[\"bads\"]:\n            bad_bipolar_chs.append(ch_name[ch_idx])\n\n    # Add warnings if bad channels are present.\n    if bad_bipolar_chs:\n        msg = f\"Bipolar channels are based on bad channels: {bad_bipolar_chs}.\"\n        _on_missing(on_bad, msg)\n        inst.info[\"bads\"] += bad_bipolar_chs\n\n    added_channels = \", \".join([name for name in ch_name])\n    logger.info(f\"Added the following bipolar channels:\\n{added_channels}\")\n\n    for attr_name in [\"picks\", \"_projector\"]:\n        setattr(inst, attr_name, None)\n\n    # Drop remaining channels.\n    if drop_refs:\n        drop_channels = list((set(anode) | set(cathode)) & set(inst.ch_names))\n        inst.drop_channels(drop_channels)\n\n    return inst", "metadata": {}}
{"_id": "mne_mne__fiff/pick.py_get_channel_type_constants_code", "title": "get_channel_type_constants", "text": "def get_channel_type_constants(include_defaults=False):\n    \"\"\"Return all known channel types, and associated FIFF constants.\n\n    Parameters\n    ----------\n    include_defaults : bool\n        Whether to include default values for \"unit\" and \"coil_type\" for all\n        entries (see Notes). Defaults are generally based on values normally\n        present for a VectorView MEG system. Defaults to ``False``.\n\n    Returns\n    -------\n    channel_types : dict\n        The keys are channel type strings, and the values are dictionaries of\n        FIFF constants for \"kind\", and possibly \"unit\" and \"coil_type\".\n\n    Notes\n    -----\n    Values which might vary within a channel type across real data\n    recordings are excluded unless ``include_defaults=True``. For example,\n    \"ref_meg\" channels may have coil type\n    ``FIFFV_COIL_MAGNES_OFFDIAG_REF_GRAD``, ``FIFFV_COIL_VV_MAG_T3``, etc\n    (depending on the recording system), so no \"coil_type\" entry is given\n    for \"ref_meg\" unless ``include_defaults`` is requested.\n    \"\"\"\n    base = dict(\n        grad=dict(kind=FIFF.FIFFV_MEG_CH, unit=FIFF.FIFF_UNIT_T_M),\n        mag=dict(kind=FIFF.FIFFV_MEG_CH, unit=FIFF.FIFF_UNIT_T),\n        ref_meg=dict(kind=FIFF.FIFFV_REF_MEG_CH),\n        eeg=dict(\n            kind=FIFF.FIFFV_EEG_CH, unit=FIFF.FIFF_UNIT_V, coil_type=FIFF.FIFFV_COIL_EEG\n        ),\n        seeg=dict(\n            kind=FIFF.FIFFV_SEEG_CH,\n            unit=FIFF.FIFF_UNIT_V,\n            coil_type=FIFF.FIFFV_COIL_EEG,\n        ),\n        dbs=dict(\n            kind=FIFF.FIFFV_DBS_CH, unit=FIFF.FIFF_UNIT_V, coil_type=FIFF.FIFFV_COIL_EEG\n        ),\n        ecog=dict(\n            kind=FIFF.FIFFV_ECOG_CH,\n            unit=FIFF.FIFF_UNIT_V,\n            coil_type=FIFF.FIFFV_COIL_EEG,\n        ),\n        eog=dict(kind=FIFF.FIFFV_EOG_CH, unit=FIFF.FIFF_UNIT_V),\n        emg=dict(kind=FIFF.FIFFV_EMG_CH, unit=FIFF.FIFF_UNIT_V),\n        ecg=dict(kind=FIFF.FIFFV_ECG_CH, unit=FIFF.FIFF_UNIT_V),\n        resp=dict(kind=FIFF.FIFFV_RESP_CH, unit=FIFF.FIFF_UNIT_V),\n        bio=dict(kind=FIFF.FIFFV_BIO_CH, unit=FIFF.FIFF_UNIT_V),\n        misc=dict(kind=FIFF.FIFFV_MISC_CH, unit=FIFF.FIFF_UNIT_V),\n        stim=dict(kind=FIFF.FIFFV_STIM_CH),\n        exci=dict(kind=FIFF.FIFFV_EXCI_CH),\n        syst=dict(kind=FIFF.FIFFV_SYST_CH),\n        ias=dict(kind=FIFF.FIFFV_IAS_CH),\n        gof=dict(kind=FIFF.FIFFV_GOODNESS_FIT),\n        dipole=dict(kind=FIFF.FIFFV_DIPOLE_WAVE),\n        chpi=dict(\n            kind=[\n                FIFF.FIFFV_QUAT_0,\n                FIFF.FIFFV_QUAT_1,\n                FIFF.FIFFV_QUAT_2,\n                FIFF.FIFFV_QUAT_3,\n                FIFF.FIFFV_QUAT_4,\n                FIFF.FIFFV_QUAT_5,\n                FIFF.FIFFV_QUAT_6,\n                FIFF.FIFFV_HPI_G,\n                FIFF.FIFFV_HPI_ERR,\n                FIFF.FIFFV_HPI_MOV,\n            ]\n        ),\n        fnirs_cw_amplitude=dict(\n            kind=FIFF.FIFFV_FNIRS_CH,\n            unit=FIFF.FIFF_UNIT_V,\n            coil_type=FIFF.FIFFV_COIL_FNIRS_CW_AMPLITUDE,\n        ),\n        fnirs_fd_ac_amplitude=dict(\n            kind=FIFF.FIFFV_FNIRS_CH,\n            unit=FIFF.FIFF_UNIT_V,\n            coil_type=FIFF.FIFFV_COIL_FNIRS_FD_AC_AMPLITUDE,\n        ),\n        fnirs_fd_phase=dict(\n            kind=FIFF.FIFFV_FNIRS_CH,\n            unit=FIFF.FIFF_UNIT_RAD,\n            coil_type=FIFF.FIFFV_COIL_FNIRS_FD_PHASE,\n        ),\n        fnirs_od=dict(kind=FIFF.FIFFV_FNIRS_CH, coil_type=FIFF.FIFFV_COIL_FNIRS_OD),\n        hbo=dict(\n            kind=FIFF.FIFFV_FNIRS_CH,\n            unit=FIFF.FIFF_UNIT_MOL,\n            coil_type=FIFF.FIFFV_COIL_FNIRS_HBO,\n        ),\n        hbr=dict(\n            kind=FIFF.FIFFV_FNIRS_CH,\n            unit=FIFF.FIFF_UNIT_MOL,\n            coil_type=FIFF.FIFFV_COIL_FNIRS_HBR,\n        ),\n        csd=dict(\n            kind=FIFF.FIFFV_EEG_CH,\n            unit=FIFF.FIFF_UNIT_V_M2,\n            coil_type=FIFF.FIFFV_COIL_EEG_CSD,\n        ),\n        temperature=dict(kind=FIFF.FIFFV_TEMPERATURE_CH, unit=FIFF.FIFF_UNIT_CEL),\n        gsr=dict(kind=FIFF.FIFFV_GALVANIC_CH, unit=FIFF.FIFF_UNIT_S),\n        eyegaze=dict(\n            kind=FIFF.FIFFV_EYETRACK_CH, coil_type=FIFF.FIFFV_COIL_EYETRACK_POS\n        ),\n        pupil=dict(\n            kind=FIFF.FIFFV_EYETRACK_CH, coil_type=FIFF.FIFFV_COIL_EYETRACK_PUPIL\n        ),\n    )\n    if include_defaults:\n        coil_none = dict(coil_type=FIFF.FIFFV_COIL_NONE)\n        unit_none = dict(unit=FIFF.FIFF_UNIT_NONE)\n        defaults = dict(\n            grad=dict(coil_type=FIFF.FIFFV_COIL_VV_PLANAR_T1),\n            mag=dict(coil_type=FIFF.FIFFV_COIL_VV_MAG_T3),\n            ref_meg=dict(coil_type=FIFF.FIFFV_COIL_VV_MAG_T3, unit=FIFF.FIFF_UNIT_T),\n            misc=dict(**coil_none, **unit_none),  # NB: overwrites UNIT_V\n            stim=dict(unit=FIFF.FIFF_UNIT_V, **coil_none),\n            eog=coil_none,\n            ecg=coil_none,\n            emg=coil_none,\n            bio=coil_none,\n            fnirs_od=unit_none,\n            pupil=unit_none,\n            eyegaze=dict(unit=FIFF.FIFF_UNIT_PX),\n        )\n        for key, value in defaults.items():\n            base[key].update(value)\n    return base", "metadata": {}}
{"_id": "mne_mne__fiff/pick.py_channel_type_code", "title": "channel_type", "text": "def channel_type(info, idx):\n    \"\"\"Get channel type.\n\n    Parameters\n    ----------\n    %(info_not_none)s\n    idx : int\n        Index of channel.\n\n    Returns\n    -------\n    type : str\n        Type of channel. Will be one of::\n\n            {'bio', 'chpi', 'dbs', 'dipole', 'ecg', 'ecog', 'eeg', 'emg',\n            'eog', 'exci', 'eyetrack', 'fnirs', 'gof', 'gsr', 'ias', 'misc',\n            'meg', 'ref_meg', 'resp', 'seeg', 'stim', 'syst', 'temperature'}\n    \"\"\"\n    # This is faster than the original _channel_type_old now in test_pick.py\n    # because it uses (at most!) two dict lookups plus one conditional\n    # to get the channel type string.\n    ch = info[\"chs\"][idx]\n    try:\n        first_kind = _first_rule[ch[\"kind\"]]\n    except KeyError:\n        raise ValueError(\n            f'Unknown channel type ({ch[\"kind\"]}) for channel \"{ch[\"ch_name\"]}\"'\n        )\n    if first_kind in _second_rules:\n        key, second_rule = _second_rules[first_kind]\n        first_kind = second_rule[ch[key]]\n    return first_kind", "metadata": {}}
{"_id": "mne_mne__fiff/pick.py_pick_channels_code", "title": "pick_channels", "text": "def pick_channels(ch_names, include, exclude=(), ordered=True, *, verbose=None):\n    \"\"\"Pick channels by names.\n\n    Returns the indices of ``ch_names`` in ``include`` but not in ``exclude``.\n\n    Parameters\n    ----------\n    ch_names : list of str\n        List of channels.\n    include : list of str\n        List of channels to include (if empty include all available).\n\n        .. note:: This is to be treated as a set. The order of this list\n           is not used or maintained in ``sel``.\n\n    exclude : list of str\n        List of channels to exclude (if empty do not exclude any channel).\n        Defaults to [].\n    %(ordered)s\n    %(verbose)s\n\n    Returns\n    -------\n    sel : array of int\n        Indices of good channels.\n\n    See Also\n    --------\n    pick_channels_regexp, pick_types\n    \"\"\"\n    if len(np.unique(ch_names)) != len(ch_names):\n        raise RuntimeError(\"ch_names is not a unique list, picking is unsafe\")\n    _validate_type(ordered, bool, \"ordered\")\n    _check_excludes_includes(include)\n    _check_excludes_includes(exclude)\n    if not isinstance(include, list):\n        include = list(include)\n    if len(include) == 0:\n        include = list(ch_names)\n    if not isinstance(exclude, list):\n        exclude = list(exclude)\n    sel, missing = list(), list()\n    for name in include:\n        if name in ch_names:\n            if name not in exclude:\n                sel.append(ch_names.index(name))\n        else:\n            missing.append(name)\n    if len(missing) and ordered:\n        raise ValueError(\n            f\"Missing channels from ch_names required by include:\\n{missing}\"\n        )\n    if not ordered:\n        sel = np.unique(sel)\n    return np.array(sel, int)", "metadata": {}}
{"_id": "mne_mne__fiff/pick.py_pick_channels_regexp_code", "title": "pick_channels_regexp", "text": "def pick_channels_regexp(ch_names, regexp):\n    \"\"\"Pick channels using regular expression.\n\n    Returns the indices of the good channels in ch_names.\n\n    Parameters\n    ----------\n    ch_names : list of str\n        List of channels.\n\n    regexp : str\n        The regular expression. See python standard module for regular\n        expressions.\n\n    Returns\n    -------\n    sel : array of int\n        Indices of good channels.\n\n    See Also\n    --------\n    pick_channels\n\n    Examples\n    --------\n    >>> pick_channels_regexp(['MEG 2331', 'MEG 2332', 'MEG 2333'], 'MEG ...1')\n    [0]\n    >>> pick_channels_regexp(['MEG 2331', 'MEG 2332', 'MEG 2333'], 'MEG *')\n    [0, 1, 2]\n    \"\"\"\n    r = re.compile(regexp)\n    return [k for k, name in enumerate(ch_names) if r.match(name)]", "metadata": {}}
{"_id": "mne_mne__fiff/pick.py_pick_types_code", "title": "pick_types", "text": "def pick_types(\n    info,\n    meg=False,\n    eeg=False,\n    stim=False,\n    eog=False,\n    ecg=False,\n    emg=False,\n    ref_meg=\"auto\",\n    *,\n    misc=False,\n    resp=False,\n    chpi=False,\n    exci=False,\n    ias=False,\n    syst=False,\n    seeg=False,\n    dipole=False,\n    gof=False,\n    bio=False,\n    ecog=False,\n    fnirs=False,\n    csd=False,\n    dbs=False,\n    temperature=False,\n    gsr=False,\n    eyetrack=False,\n    include=(),\n    exclude=\"bads\",\n    selection=None,\n):\n    \"\"\"Pick channels by type and names.\n\n    Parameters\n    ----------\n    %(info_not_none)s\n    %(pick_types_params)s\n\n    Returns\n    -------\n    sel : array of int\n        Indices of good channels.\n    \"\"\"\n    # NOTE: Changes to this function's signature should also be changed in\n    # PickChannelsMixin\n    _validate_type(meg, (bool, str), \"meg\")\n\n    exclude = _check_info_exclude(info, exclude)\n    nchan = info[\"nchan\"]\n    pick = np.zeros(nchan, dtype=bool)\n\n    _check_meg_type(ref_meg, allow_auto=True)\n    _check_meg_type(meg)\n    if isinstance(ref_meg, str) and ref_meg == \"auto\":\n        ref_meg = (\n            \"comps\" in info\n            and info[\"comps\"] is not None\n            and len(info[\"comps\"]) > 0\n            and meg is not False\n        )\n\n    for param in (\n        eeg,\n        stim,\n        eog,\n        ecg,\n        emg,\n        misc,\n        resp,\n        chpi,\n        exci,\n        ias,\n        syst,\n        seeg,\n        dipole,\n        gof,\n        bio,\n        ecog,\n        csd,\n        dbs,\n        temperature,\n        gsr,\n    ):\n        if not isinstance(param, bool):\n            w = (\n                \"Parameters for all channel types (with the exception of \"\n                '\"meg\", \"ref_meg\", \"fnirs\", and \"eyetrack\") must be of type '\n                \"bool, not {}.\"\n            )\n            raise ValueError(w.format(type(param)))\n\n    param_dict = dict(\n        eeg=eeg,\n        stim=stim,\n        eog=eog,\n        ecg=ecg,\n        emg=emg,\n        misc=misc,\n        resp=resp,\n        chpi=chpi,\n        exci=exci,\n        ias=ias,\n        syst=syst,\n        seeg=seeg,\n        dbs=dbs,\n        dipole=dipole,\n        gof=gof,\n        bio=bio,\n        ecog=ecog,\n        csd=csd,\n        temperature=temperature,\n        gsr=gsr,\n        eyetrack=eyetrack,\n    )\n\n    # avoid triage if possible\n    if isinstance(meg, bool):\n        for key in (\"grad\", \"mag\"):\n            param_dict[key] = meg\n    if isinstance(fnirs, bool):\n        for key in _FNIRS_CH_TYPES_SPLIT:\n            param_dict[key] = fnirs\n    warned = [False]\n    for k in range(nchan):\n        ch_type = channel_type(info, k)\n        try:\n            pick[k] = param_dict[ch_type]\n        except KeyError:  # not so simple\n            assert (\n                ch_type\n                in (\"grad\", \"mag\", \"ref_meg\")\n                + _FNIRS_CH_TYPES_SPLIT\n                + _EYETRACK_CH_TYPES_SPLIT\n            )\n            if ch_type in (\"grad\", \"mag\"):\n                pick[k] = _triage_meg_pick(info[\"chs\"][k], meg)\n            elif ch_type == \"ref_meg\":\n                pick[k] = _triage_meg_pick(info[\"chs\"][k], ref_meg)\n            elif ch_type in (\"eyegaze\", \"pupil\"):\n                pick[k] = _triage_eyetrack_pick(info[\"chs\"][k], eyetrack)\n            else:  # ch_type in ('hbo', 'hbr')\n                pick[k] = _triage_fnirs_pick(info[\"chs\"][k], fnirs, warned)\n\n    # restrict channels to selection if provided\n    if selection is not None:\n        # the selection only restricts these types of channels\n        sel_kind = [FIFF.FIFFV_MEG_CH, FIFF.FIFFV_REF_MEG_CH, FIFF.FIFFV_EEG_CH]\n        for k in np.where(pick)[0]:\n            if (\n                info[\"chs\"][k][\"kind\"] in sel_kind\n                and info[\"ch_names\"][k] not in selection\n            ):\n                pick[k] = False\n\n    myinclude = [info[\"ch_names\"][k] for k in range(nchan) if pick[k]]\n    myinclude += include\n\n    if len(myinclude) == 0:\n        sel = np.array([], int)\n    else:\n        sel = pick_channels(info[\"ch_names\"], myinclude, exclude, ordered=False)\n\n    return sel", "metadata": {}}
{"_id": "mne_mne__fiff/pick.py_pick_info_code", "title": "pick_info", "text": "def pick_info(info, sel=(), copy=True, verbose=None):\n    \"\"\"Restrict an info structure to a selection of channels.\n\n    Parameters\n    ----------\n    %(info_not_none)s\n    sel : list of int | None\n        Indices of channels to include. If None, all channels\n        are included.\n    copy : bool\n        If copy is False, info is modified inplace.\n    %(verbose)s\n\n    Returns\n    -------\n    res : dict\n        Info structure restricted to a selection of channels.\n    \"\"\"\n    # avoid circular imports\n    from .meas_info import _bad_chans_comp\n\n    info._check_consistency()\n    info = info.copy() if copy else info\n    if sel is None:\n        return info\n    elif len(sel) == 0:\n        raise ValueError(\"No channels match the selection.\")\n    ch_set = set(info[\"ch_names\"][k] for k in sel)\n    n_unique = len(ch_set)\n    if n_unique != len(sel):\n        raise ValueError(\n            f\"Found {n_unique} / {len(sel)} unique names, sel is not unique\"\n        )\n\n    # make sure required the compensation channels are present\n    if len(info.get(\"comps\", [])) > 0:\n        ch_names = [info[\"ch_names\"][idx] for idx in sel]\n        _, comps_missing = _bad_chans_comp(info, ch_names)\n        if len(comps_missing) > 0:\n            logger.info(\n                f\"Removing {len(info['comps'])} compensators from info because \"\n                \"not all compensation channels were picked.\"\n            )\n            with info._unlock():\n                info[\"comps\"] = []\n    with info._unlock():\n        info[\"chs\"] = [info[\"chs\"][k] for k in sel]\n    info._update_redundant()\n    info[\"bads\"] = [ch for ch in info[\"bads\"] if ch in info[\"ch_names\"]]\n    if \"comps\" in info:\n        comps = deepcopy(info[\"comps\"])\n        for c in comps:\n            row_idx = [\n                k for k, n in enumerate(c[\"data\"][\"row_names\"]) if n in info[\"ch_names\"]\n            ]\n            row_names = [c[\"data\"][\"row_names\"][i] for i in row_idx]\n            rowcals = c[\"rowcals\"][row_idx]\n            c[\"rowcals\"] = rowcals\n            c[\"data\"][\"nrow\"] = len(row_names)\n            c[\"data\"][\"row_names\"] = row_names\n            c[\"data\"][\"data\"] = c[\"data\"][\"data\"][row_idx]\n        with info._unlock():\n            info[\"comps\"] = comps\n    if info.get(\"custom_ref_applied\", False) and not _electrode_types(info):\n        with info._unlock():\n            info[\"custom_ref_applied\"] = FIFF.FIFFV_MNE_CUSTOM_REF_OFF\n    # remove unused projectors\n    if info.get(\"projs\", False):\n        projs = list()\n        for p in info[\"projs\"]:\n            if any(ch_name in ch_set for ch_name in p[\"data\"][\"col_names\"]):\n                projs.append(p)\n        if len(projs) != len(info[\"projs\"]):\n            with info._unlock():\n                info[\"projs\"] = projs\n    info._check_consistency()\n\n    return info", "metadata": {}}
{"_id": "mne_mne__fiff/pick.py_pick_channels_forward_code", "title": "pick_channels_forward", "text": "def pick_channels_forward(\n    orig, include=(), exclude=(), ordered=True, copy=True, *, verbose=None\n):\n    \"\"\"Pick channels from forward operator.\n\n    Parameters\n    ----------\n    orig : dict\n        A forward solution.\n    include : list of str\n        List of channels to include (if empty, include all available).\n        Defaults to [].\n    exclude : list of str | 'bads'\n        Channels to exclude (if empty, do not exclude any). Defaults to [].\n        If 'bads', then exclude bad channels in orig.\n    %(ordered)s\n    copy : bool\n        If True (default), make a copy.\n\n        .. versionadded:: 0.19\n    %(verbose)s\n\n    Returns\n    -------\n    res : dict\n        Forward solution restricted to selected channels. If include and\n        exclude are empty it returns orig without copy.\n    \"\"\"\n    orig[\"info\"]._check_consistency()\n    if len(include) == 0 and len(exclude) == 0:\n        return orig.copy() if copy else orig\n    exclude = _check_excludes_includes(exclude, info=orig[\"info\"], allow_bads=True)\n\n    # Allow for possibility of channel ordering in forward solution being\n    # different from that of the M/EEG file it is based on.\n    sel_sol = pick_channels(\n        orig[\"sol\"][\"row_names\"], include=include, exclude=exclude, ordered=ordered\n    )\n    sel_info = pick_channels(\n        orig[\"info\"][\"ch_names\"], include=include, exclude=exclude, ordered=ordered\n    )\n\n    fwd = deepcopy(orig) if copy else orig\n\n    # Check that forward solution and original data file agree on #channels\n    if len(sel_sol) != len(sel_info):\n        raise ValueError(\n            \"Forward solution and functional data appear to \"\n            \"have different channel names, please check.\"\n        )\n\n    #   Do we have something?\n    nuse = len(sel_sol)\n    if nuse == 0:\n        raise ValueError(\"Nothing remains after picking\")\n\n    logger.info(f\"    {nuse:d} out of {fwd['nchan']} channels remain after picking\")\n\n    #   Pick the correct rows of the forward operator using sel_sol\n    fwd[\"sol\"][\"data\"] = fwd[\"sol\"][\"data\"][sel_sol, :]\n    fwd[\"_orig_sol\"] = fwd[\"_orig_sol\"][sel_sol, :]\n    fwd[\"sol\"][\"nrow\"] = nuse\n\n    ch_names = [fwd[\"sol\"][\"row_names\"][k] for k in sel_sol]\n    fwd[\"nchan\"] = nuse\n    fwd[\"sol\"][\"row_names\"] = ch_names\n\n    # Pick the appropriate channel names from the info-dict using sel_info\n    with fwd[\"info\"]._unlock():\n        fwd[\"info\"][\"chs\"] = [fwd[\"info\"][\"chs\"][k] for k in sel_info]\n    fwd[\"info\"]._update_redundant()\n    fwd[\"info\"][\"bads\"] = [b for b in fwd[\"info\"][\"bads\"] if b in ch_names]\n\n    if fwd[\"sol_grad\"] is not None:\n        fwd[\"sol_grad\"][\"data\"] = fwd[\"sol_grad\"][\"data\"][sel_sol, :]\n        fwd[\"_orig_sol_grad\"] = fwd[\"_orig_sol_grad\"][sel_sol, :]\n        fwd[\"sol_grad\"][\"nrow\"] = nuse\n        fwd[\"sol_grad\"][\"row_names\"] = [\n            fwd[\"sol_grad\"][\"row_names\"][k] for k in sel_sol\n        ]\n\n    return fwd", "metadata": {}}
{"_id": "mne_mne__fiff/pick.py_pick_types_forward_code", "title": "pick_types_forward", "text": "def pick_types_forward(\n    orig,\n    meg=False,\n    eeg=False,\n    ref_meg=True,\n    seeg=False,\n    ecog=False,\n    dbs=False,\n    include=(),\n    exclude=(),\n):\n    \"\"\"Pick by channel type and names from a forward operator.\n\n    Parameters\n    ----------\n    orig : dict\n        A forward solution.\n    meg : bool | str\n        If True include MEG channels. If string it can be 'mag', 'grad',\n        'planar1' or 'planar2' to select only magnetometers, all gradiometers,\n        or a specific type of gradiometer.\n    eeg : bool\n        If True include EEG channels.\n    ref_meg : bool\n        If True include CTF / 4D reference channels.\n    seeg : bool\n        If True include stereotactic EEG channels.\n    ecog : bool\n        If True include electrocorticography channels.\n    dbs : bool\n        If True include deep brain stimulation channels.\n    include : list of str\n        List of additional channels to include. If empty do not include any.\n    exclude : list of str | str\n        List of channels to exclude. If empty do not exclude any (default).\n        If 'bads', exclude channels in orig['info']['bads'].\n\n    Returns\n    -------\n    res : dict\n        Forward solution restricted to selected channel types.\n    \"\"\"\n    info = orig[\"info\"]\n    sel = pick_types(\n        info,\n        meg,\n        eeg,\n        ref_meg=ref_meg,\n        seeg=seeg,\n        ecog=ecog,\n        dbs=dbs,\n        include=include,\n        exclude=exclude,\n    )\n    if len(sel) == 0:\n        raise ValueError(\"No valid channels found\")\n    include_ch_names = [info[\"ch_names\"][k] for k in sel]\n\n    return pick_channels_forward(orig, include_ch_names)", "metadata": {}}
{"_id": "mne_mne__fiff/pick.py_channel_indices_by_type_code", "title": "channel_indices_by_type", "text": "def channel_indices_by_type(info, picks=None):\n    \"\"\"Get indices of channels by type.\n\n    Parameters\n    ----------\n    %(info_not_none)s\n    %(picks_all)s\n\n    Returns\n    -------\n    idx_by_type : dict\n        A dictionary that maps each channel type to a (possibly empty) list of\n        channel indices.\n    \"\"\"\n    idx_by_type = {\n        key: list()\n        for key in _PICK_TYPES_KEYS\n        if key not in (\"meg\", \"fnirs\", \"eyetrack\")\n    }\n    idx_by_type.update(\n        mag=list(),\n        grad=list(),\n        hbo=list(),\n        hbr=list(),\n        fnirs_cw_amplitude=list(),\n        fnirs_fd_ac_amplitude=list(),\n        fnirs_fd_phase=list(),\n        fnirs_od=list(),\n        eyegaze=list(),\n        pupil=list(),\n    )\n    picks = _picks_to_idx(info, picks, none=\"all\", exclude=(), allow_empty=True)\n    for k in picks:\n        ch_type = channel_type(info, k)\n        for key in idx_by_type.keys():\n            if ch_type == key:\n                idx_by_type[key].append(k)\n    return idx_by_type", "metadata": {}}
{"_id": "mne_mne__fiff/pick.py_pick_channels_cov_code", "title": "pick_channels_cov", "text": "def pick_channels_cov(\n    orig, include=(), exclude=\"bads\", ordered=True, copy=True, *, verbose=None\n):\n    \"\"\"Pick channels from covariance matrix.\n\n    Parameters\n    ----------\n    orig : Covariance\n        A covariance.\n    include : list of str, (optional)\n        List of channels to include (if empty, include all available).\n    exclude : list of str, (optional) | 'bads'\n        Channels to exclude (if empty, do not exclude any). Defaults to 'bads'.\n    %(ordered)s\n    copy : bool\n        If True (the default), return a copy of the covariance matrix with the\n        modified channels. If False, channels are modified in-place.\n\n        .. versionadded:: 0.20.0\n    %(verbose)s\n\n    Returns\n    -------\n    res : dict\n        Covariance solution restricted to selected channels.\n    \"\"\"\n    if copy:\n        orig = orig.copy()\n        # A little peculiarity of the cov objects is that these two fields\n        # should not be copied over when None.\n        if \"method\" in orig and orig[\"method\"] is None:\n            del orig[\"method\"]\n        if \"loglik\" in orig and orig[\"loglik\"] is None:\n            del orig[\"loglik\"]\n\n    exclude = orig[\"bads\"] if exclude == \"bads\" else exclude\n    sel = pick_channels(\n        orig[\"names\"], include=include, exclude=exclude, ordered=ordered\n    )\n    data = orig[\"data\"][sel][:, sel] if not orig[\"diag\"] else orig[\"data\"][sel]\n    names = [orig[\"names\"][k] for k in sel]\n    bads = [name for name in orig[\"bads\"] if name in orig[\"names\"]]\n\n    orig[\"data\"] = data\n    orig[\"names\"] = names\n    orig[\"bads\"] = bads\n    orig[\"dim\"] = len(data)\n\n    return orig", "metadata": {}}
{"_id": "mne_mne__fiff/write.py_write_nop_code", "title": "write_nop", "text": "def write_nop(fid, last=False):\n    \"\"\"Write a FIFF_NOP.\"\"\"\n    fid.write(np.array(FIFF.FIFF_NOP, dtype=\">i4\").tobytes())\n    fid.write(np.array(FIFF.FIFFT_VOID, dtype=\">i4\").tobytes())\n    fid.write(np.array(0, dtype=\">i4\").tobytes())\n    next_ = FIFF.FIFFV_NEXT_NONE if last else FIFF.FIFFV_NEXT_SEQ\n    fid.write(np.array(next_, dtype=\">i4\").tobytes())", "metadata": {}}
{"_id": "mne_mne__fiff/write.py_write_int_code", "title": "write_int", "text": "def write_int(fid, kind, data):\n    \"\"\"Write a 32-bit integer tag to a fif file.\"\"\"\n    data_size = 4\n    data = np.asarray(data)\n    if data.dtype.kind not in \"uib\" and data.size > 0:\n        raise TypeError(\n            f\"Cannot safely write data kind {kind} with dtype {data.dtype} as int\",\n        )\n    max_val = data.max() if data.size > 0 else 0\n    if max_val > INT32_MAX:\n        raise TypeError(\n            f\"Value {max_val} exceeds maximum allowed ({INT32_MAX}) for tag {kind}\"\n        )\n    data = data.astype(\">i4\").T\n    _write(fid, data, kind, data_size, FIFF.FIFFT_INT, \">i4\")", "metadata": {}}
{"_id": "mne_mne__fiff/write.py_write_double_code", "title": "write_double", "text": "def write_double(fid, kind, data):\n    \"\"\"Write a double-precision floating point tag to a fif file.\"\"\"\n    data_size = 8\n    data = np.array(data, dtype=\">f8\").T\n    _write(fid, data, kind, data_size, FIFF.FIFFT_DOUBLE, \">f8\")", "metadata": {}}
{"_id": "mne_mne__fiff/write.py_write_float_code", "title": "write_float", "text": "def write_float(fid, kind, data):\n    \"\"\"Write a single-precision floating point tag to a fif file.\"\"\"\n    data_size = 4\n    data = np.array(data, dtype=\">f4\").T\n    _write(fid, data, kind, data_size, FIFF.FIFFT_FLOAT, \">f4\")", "metadata": {}}
{"_id": "mne_mne__fiff/write.py_write_dau_pack16_code", "title": "write_dau_pack16", "text": "def write_dau_pack16(fid, kind, data):\n    \"\"\"Write a dau_pack16 tag to a fif file.\"\"\"\n    data_size = 2\n    data = np.array(data, dtype=\">i2\").T\n    _write(fid, data, kind, data_size, FIFF.FIFFT_DAU_PACK16, \">i2\")", "metadata": {}}
{"_id": "mne_mne__fiff/write.py_write_complex64_code", "title": "write_complex64", "text": "def write_complex64(fid, kind, data):\n    \"\"\"Write a 64 bit complex floating point tag to a fif file.\"\"\"\n    data_size = 8\n    data = np.array(data, dtype=\">c8\").T\n    _write(fid, data, kind, data_size, FIFF.FIFFT_COMPLEX_FLOAT, \">c8\")", "metadata": {}}
{"_id": "mne_mne__fiff/write.py_write_complex128_code", "title": "write_complex128", "text": "def write_complex128(fid, kind, data):\n    \"\"\"Write a 128 bit complex floating point tag to a fif file.\"\"\"\n    data_size = 16\n    data = np.array(data, dtype=\">c16\").T\n    _write(fid, data, kind, data_size, FIFF.FIFFT_COMPLEX_FLOAT, \">c16\")", "metadata": {}}
{"_id": "mne_mne__fiff/write.py_write_julian_code", "title": "write_julian", "text": "def write_julian(fid, kind, data):\n    \"\"\"Write a Julian-formatted date to a FIF file.\"\"\"\n    assert isinstance(data, datetime.date), type(data)\n    data_size = 4\n    jd = _date_to_julian(data)\n    data = np.array(jd, dtype=\">i4\")\n    _write(fid, data, kind, data_size, FIFF.FIFFT_JULIAN, \">i4\")", "metadata": {}}
{"_id": "mne_mne__fiff/write.py_write_string_code", "title": "write_string", "text": "def write_string(fid, kind, data):\n    \"\"\"Write a string tag.\"\"\"\n    try:\n        str_data = str(data).encode(\"latin1\")\n    except UnicodeEncodeError:\n        str_data = str(data).encode(\"latin1\", errors=\"xmlcharrefreplace\")\n    data_size = len(str_data)  # therefore compute size here\n    if data_size > 0:\n        _write(fid, str_data, kind, data_size, FIFF.FIFFT_STRING, \">S\")", "metadata": {}}
{"_id": "mne_mne__fiff/write.py_write_name_list_code", "title": "write_name_list", "text": "def write_name_list(fid, kind, data):\n    \"\"\"Write a colon-separated list of names.\n\n    Parameters\n    ----------\n    data : list of strings\n    \"\"\"\n    write_string(fid, kind, \":\".join(data))", "metadata": {}}
{"_id": "mne_mne__fiff/write.py_write_name_list_sanitized_code", "title": "write_name_list_sanitized", "text": "def write_name_list_sanitized(fid, kind, lst, name):\n    \"\"\"Write a sanitized, colon-separated list of names.\"\"\"\n    write_string(fid, kind, _safe_name_list(lst, \"write\", name))", "metadata": {}}
{"_id": "mne_mne__fiff/write.py_write_float_matrix_code", "title": "write_float_matrix", "text": "def write_float_matrix(fid, kind, mat):\n    \"\"\"Write a single-precision floating-point matrix tag.\"\"\"\n    _write_matrix_data(fid, kind, mat, FIFF.FIFFT_FLOAT)", "metadata": {}}
{"_id": "mne_mne__fiff/write.py_write_double_matrix_code", "title": "write_double_matrix", "text": "def write_double_matrix(fid, kind, mat):\n    \"\"\"Write a double-precision floating-point matrix tag.\"\"\"\n    _write_matrix_data(fid, kind, mat, FIFF.FIFFT_DOUBLE)", "metadata": {}}
{"_id": "mne_mne__fiff/write.py_write_int_matrix_code", "title": "write_int_matrix", "text": "def write_int_matrix(fid, kind, mat):\n    \"\"\"Write integer 32 matrix tag.\"\"\"\n    _write_matrix_data(fid, kind, mat, FIFF.FIFFT_INT)", "metadata": {}}
{"_id": "mne_mne__fiff/write.py_write_complex_float_matrix_code", "title": "write_complex_float_matrix", "text": "def write_complex_float_matrix(fid, kind, mat):\n    \"\"\"Write complex 64 matrix tag.\"\"\"\n    _write_matrix_data(fid, kind, mat, FIFF.FIFFT_COMPLEX_FLOAT)", "metadata": {}}
{"_id": "mne_mne__fiff/write.py_write_complex_double_matrix_code", "title": "write_complex_double_matrix", "text": "def write_complex_double_matrix(fid, kind, mat):\n    \"\"\"Write complex 128 matrix tag.\"\"\"\n    _write_matrix_data(fid, kind, mat, FIFF.FIFFT_COMPLEX_DOUBLE)", "metadata": {}}
{"_id": "mne_mne__fiff/write.py_get_machid_code", "title": "get_machid", "text": "def get_machid():\n    \"\"\"Get (mostly) unique machine ID.\n\n    Returns\n    -------\n    ids : array (length 2, int32)\n        The machine identifier used in MNE.\n    \"\"\"\n    mac = f\"{uuid.getnode():012x}\".encode()  # byte conversion for Py3\n    mac = re.findall(b\"..\", mac)  # split string\n    mac += [b\"00\", b\"00\"]  # add two more fields\n\n    # Convert to integer in reverse-order (for some reason)\n    from codecs import encode\n\n    mac = b\"\".join([encode(h, \"hex_codec\") for h in mac[::-1]])\n    ids = np.flipud(np.frombuffer(mac, np.int32, count=2))\n    return ids", "metadata": {}}
{"_id": "mne_mne__fiff/write.py_get_new_file_id_code", "title": "get_new_file_id", "text": "def get_new_file_id():\n    \"\"\"Create a new file ID tag.\"\"\"\n    secs, usecs = divmod(time.time(), 1.0)\n    secs, usecs = int(secs), int(usecs * 1e6)\n    return {\n        \"machid\": get_machid(),\n        \"version\": FIFF.FIFFC_VERSION,\n        \"secs\": secs,\n        \"usecs\": usecs,\n    }", "metadata": {}}
{"_id": "mne_mne__fiff/write.py_write_id_code", "title": "write_id", "text": "def write_id(fid, kind, id_=None):\n    \"\"\"Write fiff id.\"\"\"\n    id_ = _generate_meas_id() if id_ is None else id_\n\n    data_size = 5 * 4  # The id comprises five integers\n    fid.write(np.array(kind, dtype=\">i4\").tobytes())\n    fid.write(np.array(FIFF.FIFFT_ID_STRUCT, dtype=\">i4\").tobytes())\n    fid.write(np.array(data_size, dtype=\">i4\").tobytes())\n    fid.write(np.array(FIFF.FIFFV_NEXT_SEQ, dtype=\">i4\").tobytes())\n\n    # Collect the bits together for one write\n    arr = np.array(\n        [id_[\"version\"], id_[\"machid\"][0], id_[\"machid\"][1], id_[\"secs\"], id_[\"usecs\"]],\n        dtype=\">i4\",\n    )\n    fid.write(arr.tobytes())", "metadata": {}}
{"_id": "mne_mne__fiff/write.py_start_block_code", "title": "start_block", "text": "def start_block(fid, kind):\n    \"\"\"Write a FIFF_BLOCK_START tag.\"\"\"\n    write_int(fid, FIFF.FIFF_BLOCK_START, kind)", "metadata": {}}
{"_id": "mne_mne__fiff/write.py_end_block_code", "title": "end_block", "text": "def end_block(fid, kind):\n    \"\"\"Write a FIFF_BLOCK_END tag.\"\"\"\n    write_int(fid, FIFF.FIFF_BLOCK_END, kind)", "metadata": {}}
{"_id": "mne_mne__fiff/write.py_start_file_code", "title": "start_file", "text": "def start_file(fname, id_=None, *, overwrite=True):\n    \"\"\"Open a fif file for writing and writes the compulsory header tags.\n\n    Parameters\n    ----------\n    fname : path-like | fid\n        The name of the file to open. It is recommended\n        that the name ends with .fif or .fif.gz. Can also be an\n        already opened file.\n    id_ : dict | None\n        ID to use for the FIFF_FILE_ID.\n    \"\"\"\n    if _file_like(fname):\n        logger.debug(f\"Writing using {type(fname)} I/O\")\n        fid = fname\n        fid.seek(0)\n    else:\n        fname = _check_fname(fname, overwrite=overwrite)\n        fname = str(fname)\n        if op.splitext(fname)[1].lower() == \".gz\":\n            logger.debug(\"Writing using gzip\")\n            # defaults to compression level 9, which is barely smaller but much\n            # slower. 2 offers a good compromise.\n            fid = GzipFile(fname, \"wb\", compresslevel=2)\n        else:\n            logger.debug(\"Writing using normal I/O\")\n            fid = open(fname, \"wb\")\n    #   Write the compulsory items\n    write_id(fid, FIFF.FIFF_FILE_ID, id_)\n    write_int(fid, FIFF.FIFF_DIR_POINTER, -1)\n    write_int(fid, FIFF.FIFF_FREE_LIST, -1)\n    return fid", "metadata": {}}
{"_id": "mne_mne__fiff/write.py_start_and_end_file_code", "title": "start_and_end_file", "text": "def start_and_end_file(fname, id_=None, *, overwrite=True):\n    \"\"\"Start and (if successfully written) close the file.\"\"\"\n    with start_file(fname, id_=id_, overwrite=overwrite) as fid:\n        yield fid\n        end_file(fid)", "metadata": {}}
{"_id": "mne_mne__fiff/write.py_check_fiff_length_code", "title": "check_fiff_length", "text": "def check_fiff_length(fid, close=True):\n    \"\"\"Ensure our file hasn't grown too large to work properly.\"\"\"\n    if fid.tell() > 2147483648:  # 2 ** 31, FIFF uses signed 32-bit locations\n        if close:\n            fid.close()\n        raise OSError(\n            \"FIFF file exceeded 2GB limit, please split file, reduce\"\n            \" split_size (if possible), or save to a different \"\n            \"format\"\n        )", "metadata": {}}
{"_id": "mne_mne__fiff/write.py_end_file_code", "title": "end_file", "text": "def end_file(fid):\n    \"\"\"Write the closing tags to a fif file and closes the file.\"\"\"\n    write_nop(fid, last=True)\n    check_fiff_length(fid)\n    fid.close()", "metadata": {}}
{"_id": "mne_mne__fiff/write.py_write_coord_trans_code", "title": "write_coord_trans", "text": "def write_coord_trans(fid, trans):\n    \"\"\"Write a coordinate transformation structure.\"\"\"\n    data_size = 4 * 2 * 12 + 4 * 2\n    fid.write(np.array(FIFF.FIFF_COORD_TRANS, dtype=\">i4\").tobytes())\n    fid.write(np.array(FIFF.FIFFT_COORD_TRANS_STRUCT, dtype=\">i4\").tobytes())\n    fid.write(np.array(data_size, dtype=\">i4\").tobytes())\n    fid.write(np.array(FIFF.FIFFV_NEXT_SEQ, dtype=\">i4\").tobytes())\n    fid.write(np.array(trans[\"from\"], dtype=\">i4\").tobytes())\n    fid.write(np.array(trans[\"to\"], dtype=\">i4\").tobytes())\n\n    #   The transform...\n    rot = trans[\"trans\"][:3, :3]\n    move = trans[\"trans\"][:3, 3]\n    fid.write(np.array(rot, dtype=\">f4\").tobytes())\n    fid.write(np.array(move, dtype=\">f4\").tobytes())\n\n    #   ...and its inverse\n    trans_inv = np.linalg.inv(trans[\"trans\"])\n    rot = trans_inv[:3, :3]\n    move = trans_inv[:3, 3]\n    fid.write(np.array(rot, dtype=\">f4\").tobytes())\n    fid.write(np.array(move, dtype=\">f4\").tobytes())", "metadata": {}}
{"_id": "mne_mne__fiff/write.py_write_ch_info_code", "title": "write_ch_info", "text": "def write_ch_info(fid, ch):\n    \"\"\"Write a channel information record to a fif file.\"\"\"\n    data_size = 4 * 13 + 4 * 7 + 16\n\n    fid.write(np.array(FIFF.FIFF_CH_INFO, dtype=\">i4\").tobytes())\n    fid.write(np.array(FIFF.FIFFT_CH_INFO_STRUCT, dtype=\">i4\").tobytes())\n    fid.write(np.array(data_size, dtype=\">i4\").tobytes())\n    fid.write(np.array(FIFF.FIFFV_NEXT_SEQ, dtype=\">i4\").tobytes())\n\n    #   Start writing fiffChInfoRec\n    fid.write(np.array(ch[\"scanno\"], dtype=\">i4\").tobytes())\n    fid.write(np.array(ch[\"logno\"], dtype=\">i4\").tobytes())\n    fid.write(np.array(ch[\"kind\"], dtype=\">i4\").tobytes())\n    fid.write(np.array(ch[\"range\"], dtype=\">f4\").tobytes())\n    fid.write(np.array(ch[\"cal\"], dtype=\">f4\").tobytes())\n    fid.write(np.array(ch[\"coil_type\"], dtype=\">i4\").tobytes())\n    fid.write(np.array(ch[\"loc\"], dtype=\">f4\").tobytes())  # writing 12 values\n\n    #   unit and unit multiplier\n    fid.write(np.array(ch[\"unit\"], dtype=\">i4\").tobytes())\n    fid.write(np.array(ch[\"unit_mul\"], dtype=\">i4\").tobytes())\n\n    #   Finally channel name\n    ch_name = ch[\"ch_name\"][:15]\n    fid.write(np.array(ch_name, dtype=\">c\").tobytes())\n    fid.write(b\"\\0\" * (16 - len(ch_name)))", "metadata": {}}
{"_id": "mne_mne__fiff/write.py_write_dig_points_code", "title": "write_dig_points", "text": "def write_dig_points(fid, dig, block=False, coord_frame=None, *, ch_names=None):\n    \"\"\"Write a set of digitizer data points into a fif file.\"\"\"\n    if dig is not None:\n        data_size = 5 * 4\n        if block:\n            start_block(fid, FIFF.FIFFB_ISOTRAK)\n        if coord_frame is not None:\n            write_int(fid, FIFF.FIFF_MNE_COORD_FRAME, coord_frame)\n        for d in dig:\n            fid.write(np.array(FIFF.FIFF_DIG_POINT, \">i4\").tobytes())\n            fid.write(np.array(FIFF.FIFFT_DIG_POINT_STRUCT, \">i4\").tobytes())\n            fid.write(np.array(data_size, dtype=\">i4\").tobytes())\n            fid.write(np.array(FIFF.FIFFV_NEXT_SEQ, \">i4\").tobytes())\n            #   Start writing fiffDigPointRec\n            fid.write(np.array(d[\"kind\"], \">i4\").tobytes())\n            fid.write(np.array(d[\"ident\"], \">i4\").tobytes())\n            fid.write(np.array(d[\"r\"][:3], \">f4\").tobytes())\n        if ch_names is not None:\n            write_name_list_sanitized(\n                fid, FIFF.FIFF_MNE_CH_NAME_LIST, ch_names, \"ch_names\"\n            )\n        if block:\n            end_block(fid, FIFF.FIFFB_ISOTRAK)", "metadata": {}}
{"_id": "mne_mne__fiff/write.py_write_float_sparse_rcs_code", "title": "write_float_sparse_rcs", "text": "def write_float_sparse_rcs(fid, kind, mat):\n    \"\"\"Write a single-precision sparse compressed row matrix tag.\"\"\"\n    return write_float_sparse(fid, kind, mat, fmt=\"csr\")", "metadata": {}}
{"_id": "mne_mne__fiff/write.py_write_float_sparse_code", "title": "write_float_sparse", "text": "def write_float_sparse(fid, kind, mat, fmt=\"auto\"):\n    \"\"\"Write a single-precision floating-point sparse matrix tag.\"\"\"\n    if fmt == \"auto\":\n        fmt = \"csr\" if isinstance(mat, csr_array) else \"csc\"\n    need = csr_array if fmt == \"csr\" else csc_array\n    matrix_type = getattr(FIFF, f\"FIFFT_SPARSE_{fmt[-1].upper()}CS_MATRIX\")\n    _validate_type(mat, need, \"sparse\")\n    matrix_type = matrix_type | FIFF.FIFFT_MATRIX | FIFF.FIFFT_FLOAT\n    nnzm = mat.nnz\n    nrow = mat.shape[0]\n    data_size = 4 * nnzm + 4 * nnzm + 4 * (nrow + 1) + 4 * 4\n\n    fid.write(np.array(kind, dtype=\">i4\").tobytes())\n    fid.write(np.array(matrix_type, dtype=\">i4\").tobytes())\n    fid.write(np.array(data_size, dtype=\">i4\").tobytes())\n    fid.write(np.array(FIFF.FIFFV_NEXT_SEQ, dtype=\">i4\").tobytes())\n\n    fid.write(np.array(mat.data, dtype=\">f4\").tobytes())\n    fid.write(np.array(mat.indices, dtype=\">i4\").tobytes())\n    fid.write(np.array(mat.indptr, dtype=\">i4\").tobytes())\n\n    dims = [nnzm, mat.shape[0], mat.shape[1], 2]\n    fid.write(np.array(dims, dtype=\">i4\").tobytes())\n    check_fiff_length(fid)", "metadata": {}}
{"_id": "mne_mne__fiff/proj.py_make_projector_code", "title": "make_projector", "text": "def make_projector(projs, ch_names, bads=(), include_active=True):\n    \"\"\"Create an SSP operator from SSP projection vectors.\n\n    Parameters\n    ----------\n    projs : list\n        List of projection vectors.\n    ch_names : list of str\n        List of channels to include in the projection matrix.\n    bads : list of str\n        Some bad channels to exclude. If bad channels were marked\n        in the raw file when projs were calculated using mne-python,\n        they should not need to be included here as they will\n        have been automatically omitted from the projectors.\n    include_active : bool\n        Also include projectors that are already active.\n\n    Returns\n    -------\n    proj : array of shape [n_channels, n_channels]\n        The projection operator to apply to the data.\n    nproj : int\n        How many items in the projector.\n    U : array\n        The orthogonal basis of the projection vectors.\n    \"\"\"\n    return _make_projector(projs, ch_names, bads, include_active)", "metadata": {}}
{"_id": "mne_mne__fiff/proj.py_make_projector_info_code", "title": "make_projector_info", "text": "def make_projector_info(info, include_active=True):\n    \"\"\"Make an SSP operator using the measurement info.\n\n    Calls make_projector on good channels.\n\n    Parameters\n    ----------\n    %(info_not_none)s\n    include_active : bool\n        Also include projectors that are already active.\n\n    Returns\n    -------\n    proj : array of shape [n_channels, n_channels]\n        The projection operator to apply to the data.\n    nproj : int\n        How many items in the projector.\n    \"\"\"\n    proj, nproj, _ = make_projector(\n        info[\"projs\"], info[\"ch_names\"], info[\"bads\"], include_active\n    )\n    return proj, nproj", "metadata": {}}
{"_id": "mne_mne__fiff/proj.py_activate_proj_code", "title": "activate_proj", "text": "def activate_proj(projs, copy=True, verbose=None):\n    \"\"\"Set all projections to active.\n\n    Useful before passing them to make_projector.\n\n    Parameters\n    ----------\n    projs : list\n        The projectors.\n    copy : bool\n        Modify projs in place or operate on a copy.\n    %(verbose)s\n\n    Returns\n    -------\n    projs : list\n        The projectors.\n    \"\"\"\n    if copy:\n        projs = deepcopy(projs)\n\n    #   Activate the projection items\n    for proj in projs:\n        proj[\"active\"] = True\n\n    logger.info(f\"{len(projs)} projection items activated\")\n\n    return projs", "metadata": {}}
{"_id": "mne_mne__fiff/proj.py_deactivate_proj_code", "title": "deactivate_proj", "text": "def deactivate_proj(projs, copy=True, verbose=None):\n    \"\"\"Set all projections to inactive.\n\n    Useful before saving raw data without projectors applied.\n\n    Parameters\n    ----------\n    projs : list\n        The projectors.\n    copy : bool\n        Modify projs in place or operate on a copy.\n    %(verbose)s\n\n    Returns\n    -------\n    projs : list\n        The projectors.\n    \"\"\"\n    if copy:\n        projs = deepcopy(projs)\n\n    #   Deactivate the projection items\n    for proj in projs:\n        proj[\"active\"] = False\n\n    logger.info(f\"{len(projs)} projection items deactivated\")\n\n    return projs", "metadata": {}}
{"_id": "mne_mne__fiff/proj.py_make_eeg_average_ref_proj_code", "title": "make_eeg_average_ref_proj", "text": "def make_eeg_average_ref_proj(info, activate=True, *, ch_type=\"eeg\", verbose=None):\n    \"\"\"Create an EEG average reference SSP projection vector.\n\n    Parameters\n    ----------\n    %(info_not_none)s\n    activate : bool\n        If True projections are activated.\n    ch_type : str\n        The channel type to use for reference projection.\n        Valid types are ``'eeg'``, ``'ecog'``, ``'seeg'`` and ``'dbs'``.\n\n        .. versionadded:: 1.2\n    %(verbose)s\n\n    Returns\n    -------\n    proj: instance of Projection\n        The SSP/PCA projector.\n    \"\"\"\n    if info.get(\"custom_ref_applied\", False):\n        raise RuntimeError(\n            \"A custom reference has been applied to the \"\n            \"data earlier. Please use the \"\n            \"mne.io.set_eeg_reference function to move from \"\n            \"one EEG reference to another.\"\n        )\n\n    _validate_type(ch_type, (list, tuple, str), \"ch_type\")\n    singleton = False\n    if isinstance(ch_type, str):\n        ch_type = [ch_type]\n        singleton = True\n    for ci, this_ch_type in enumerate(ch_type):\n        _check_option(\n            \"ch_type\" + (\"\" if singleton else f\"[{ci}]\"),\n            this_ch_type,\n            list(_EEG_AVREF_PICK_DICT),\n        )\n\n    ch_type_name = \"/\".join(c.upper() for c in ch_type)\n    logger.info(f\"Adding average {ch_type_name} reference projection.\")\n\n    ch_dict = {c: True for c in ch_type}\n    for c in ch_type:\n        one_picks = pick_types(info, exclude=\"bads\", **{c: True})\n        if len(one_picks) == 0:\n            raise ValueError(\n                f\"Cannot create {ch_type_name} average reference \"\n                f\"projector (no {c.upper()} data found)\"\n            )\n    del ch_type\n    ch_sel = pick_types(info, **ch_dict, exclude=\"bads\")\n    ch_names = info[\"ch_names\"]\n    ch_names = [ch_names[k] for k in ch_sel]\n    n_chs = len(ch_sel)\n    vec = np.ones((1, n_chs))\n    vec /= np.sqrt(n_chs)\n    explained_var = None\n    proj_data = dict(col_names=ch_names, row_names=None, data=vec, nrow=1, ncol=n_chs)\n    proj = Projection(\n        active=activate,\n        data=proj_data,\n        explained_var=explained_var,\n        desc=f\"Average {ch_type_name} reference\",\n        kind=FIFF.FIFFV_PROJ_ITEM_EEG_AVREF,\n    )\n    return proj", "metadata": {}}
{"_id": "mne_mne__fiff/proj.py_setup_proj_code", "title": "setup_proj", "text": "def setup_proj(\n    info, add_eeg_ref=True, activate=True, *, eeg_ref_ch_type=\"eeg\", verbose=None\n):\n    \"\"\"Set up projection for Raw and Epochs.\n\n    Parameters\n    ----------\n    %(info_not_none)s Warning: will be modified in-place.\n    add_eeg_ref : bool\n        If True, an EEG average reference will be added (unless one\n        already exists).\n    activate : bool\n        If True projections are activated.\n    eeg_ref_ch_type : str\n        The channel type to use for reference projection.\n        Valid types are 'eeg', 'ecog', 'seeg' and 'dbs'.\n\n        .. versionadded:: 1.2\n    %(verbose)s\n\n    Returns\n    -------\n    projector : array of shape [n_channels, n_channels]\n        The projection operator to apply to the data.\n    info : mne.Info\n        The modified measurement info.\n    \"\"\"\n    # Add EEG ref reference proj if necessary\n    if add_eeg_ref and _needs_eeg_average_ref_proj(info):\n        eeg_proj = make_eeg_average_ref_proj(\n            info, activate=activate, ch_type=eeg_ref_ch_type\n        )\n        info[\"projs\"].append(eeg_proj)\n\n    # Create the projector\n    projector, nproj = make_projector_info(info)\n    if nproj == 0:\n        if verbose:\n            logger.info(\"The projection vectors do not apply to these channels\")\n        projector = None\n    else:\n        logger.info(f\"Created an SSP operator (subspace dimension = {nproj})\")\n\n    # The projection items have been activated\n    if activate:\n        with info._unlock():\n            info[\"projs\"] = activate_proj(info[\"projs\"], copy=False)\n\n    return projector, info", "metadata": {}}
{"_id": "mne_mne__fiff/proj.py_plot_topomap_code", "title": "plot_topomap", "text": "def plot_topomap(\n        self,\n        info,\n        *,\n        sensors=True,\n        show_names=False,\n        contours=6,\n        outlines=\"head\",\n        sphere=None,\n        image_interp=_INTERPOLATION_DEFAULT,\n        extrapolate=_EXTRAPOLATE_DEFAULT,\n        border=_BORDER_DEFAULT,\n        res=64,\n        size=1,\n        cmap=None,\n        vlim=(None, None),\n        cnorm=None,\n        colorbar=False,\n        cbar_fmt=\"%3.1f\",\n        units=None,\n        axes=None,\n        show=True,\n    ):\n        \"\"\"Plot topographic maps of SSP projections.\n\n        Parameters\n        ----------\n        %(info_not_none)s Used to determine the layout.\n        %(sensors_topomap)s\n        %(show_names_topomap)s\n\n            .. versionadded:: 1.2\n        %(contours_topomap)s\n        %(outlines_topomap)s\n        %(sphere_topomap_auto)s\n        %(image_interp_topomap)s\n        %(extrapolate_topomap)s\n\n            .. versionadded:: 1.2\n        %(border_topomap)s\n\n            .. versionadded:: 0.20\n        %(res_topomap)s\n        %(size_topomap)s\n        %(cmap_topomap)s\n        %(vlim_plot_topomap_proj)s\n        %(cnorm)s\n\n            .. versionadded:: 1.2\n        %(colorbar_topomap)s\n        %(cbar_fmt_topomap)s\n\n            .. versionadded:: 1.2\n        %(units_topomap)s\n\n            .. versionadded:: 1.2\n        %(axes_plot_projs_topomap)s\n        %(show)s\n\n        Returns\n        -------\n        fig : instance of Figure\n            Figure distributing one image per channel across sensor topography.\n\n        Notes\n        -----\n        .. versionadded:: 0.15.0\n        \"\"\"  # noqa: E501\n        from ..viz.topomap import plot_projs_topomap\n\n        return plot_projs_topomap(\n            self,\n            info,\n            sensors=sensors,\n            show_names=show_names,\n            contours=contours,\n            outlines=outlines,\n            sphere=sphere,\n            image_interp=image_interp,\n            extrapolate=extrapolate,\n            border=border,\n            res=res,\n            size=size,\n            cmap=cmap,\n            vlim=vlim,\n            cnorm=cnorm,\n            colorbar=colorbar,\n            cbar_fmt=cbar_fmt,\n            units=units,\n            axes=axes,\n            show=show,\n        )", "metadata": {}}
{"_id": "mne_mne__fiff/proj.py_proj_code", "title": "proj", "text": "def proj(self):\n        \"\"\"Whether or not projections are active.\"\"\"\n        return len(self.info[\"projs\"]) > 0 and all(\n            p[\"active\"] for p in self.info[\"projs\"]\n        )", "metadata": {}}
{"_id": "mne_mne__fiff/proj.py_add_proj_code", "title": "add_proj", "text": "def add_proj(self, projs, remove_existing=False, verbose=None):\n        \"\"\"Add SSP projection vectors.\n\n        Parameters\n        ----------\n        projs : list\n            List with projection vectors.\n        remove_existing : bool\n            Remove the projection vectors currently in the file.\n        %(verbose)s\n\n        Returns\n        -------\n        self : instance of Raw | Epochs | Evoked\n            The data container.\n        \"\"\"\n        if isinstance(projs, Projection):\n            projs = [projs]\n\n        if not isinstance(projs, list) and not all(\n            isinstance(p, Projection) for p in projs\n        ):\n            raise ValueError(\"Only projs can be added. You supplied something else.\")\n\n        # mark proj as inactive, as they have not been applied\n        projs = deactivate_proj(projs, copy=True)\n        if remove_existing:\n            # we cannot remove the proj if they are active\n            if any(p[\"active\"] for p in self.info[\"projs\"]):\n                raise ValueError(\n                    \"Cannot remove projectors that have already been applied\"\n                )\n            with self.info._unlock():\n                self.info[\"projs\"] = projs\n        else:\n            self.info[\"projs\"].extend(projs)\n        # We don't want to add projectors that are activated again.\n        with self.info._unlock():\n            self.info[\"projs\"] = _uniquify_projs(\n                self.info[\"projs\"], check_active=False, sort=False\n            )\n        return self", "metadata": {}}
{"_id": "mne_mne__fiff/proj.py_apply_proj_code", "title": "apply_proj", "text": "def apply_proj(self, verbose=None):\n        \"\"\"Apply the signal space projection (SSP) operators to the data.\n\n        Parameters\n        ----------\n        %(verbose)s\n\n        Returns\n        -------\n        self : instance of Raw | Epochs | Evoked\n            The instance.\n\n        Notes\n        -----\n        Once the projectors have been applied, they can no longer be\n        removed. It is usually not recommended to apply the projectors at\n        too early stages, as they are applied automatically later on\n        (e.g. when computing inverse solutions).\n        Hint: using the copy method individual projection vectors\n        can be tested without affecting the original data.\n        With evoked data, consider the following example::\n\n            projs_a = mne.read_proj('proj_a.fif')\n            projs_b = mne.read_proj('proj_b.fif')\n            # add the first, copy, apply and see ...\n            evoked.add_proj(a).copy().apply_proj().plot()\n            # add the second, copy, apply and see ...\n            evoked.add_proj(b).copy().apply_proj().plot()\n            # drop the first and see again\n            evoked.copy().del_proj(0).apply_proj().plot()\n            evoked.apply_proj()  # finally keep both\n        \"\"\"\n        from ..epochs import BaseEpochs\n        from ..evoked import Evoked\n        from ..io import BaseRaw\n\n        if self.info[\"projs\"] is None or len(self.info[\"projs\"]) == 0:\n            logger.info(\n                \"No projector specified for this dataset. \"\n                \"Please consider the method self.add_proj.\"\n            )\n            return self\n\n        # Exit delayed mode if you apply proj\n        if isinstance(self, BaseEpochs) and self._do_delayed_proj:\n            logger.info(\"Leaving delayed SSP mode.\")\n            self._do_delayed_proj = False\n\n        if all(p[\"active\"] for p in self.info[\"projs\"]):\n            logger.info(\n                \"Projections have already been applied. Setting proj attribute to True.\"\n            )\n            return self\n\n        _projector, info = setup_proj(\n            deepcopy(self.info), add_eeg_ref=False, activate=True\n        )\n        # let's not raise a RuntimeError here, otherwise interactive plotting\n        if _projector is None:  # won't be fun.\n            logger.info(\"The projections don't apply to these data. Doing nothing.\")\n            return self\n        self._projector, self.info = _projector, info\n        if isinstance(self, BaseRaw | Evoked):\n            if self.preload:\n                self._data = np.dot(self._projector, self._data)\n        else:  # BaseEpochs\n            if self.preload:\n                for ii, e in enumerate(self._data):\n                    self._data[ii] = self._project_epoch(e)\n            else:\n                self.load_data()  # will automatically apply\n        logger.info(\"SSP projectors applied...\")\n        return self", "metadata": {}}
{"_id": "mne_mne__fiff/proj.py_del_proj_code", "title": "del_proj", "text": "def del_proj(self, idx=\"all\"):\n        \"\"\"Remove SSP projection vector.\n\n        .. note:: The projection vector can only be removed if it is inactive\n                  (has not been applied to the data).\n\n        Parameters\n        ----------\n        idx : int | list of int | str\n            Index of the projector to remove. Can also be \"all\" (default)\n            to remove all projectors.\n\n        Returns\n        -------\n        self : instance of Raw | Epochs | Evoked\n            The instance.\n        \"\"\"\n        if isinstance(idx, str) and idx == \"all\":\n            idx = list(range(len(self.info[\"projs\"])))\n        idx = np.atleast_1d(np.array(idx, int)).ravel()\n\n        for ii in idx:\n            proj = self.info[\"projs\"][ii]\n            if proj[\"active\"] and set(self.info[\"ch_names\"]) & set(\n                proj[\"data\"][\"col_names\"]\n            ):\n                msg = (\n                    f\"Cannot remove projector that has already been \"\n                    f\"applied, unless you first remove all channels it \"\n                    f\"applies to. The problematic projector is: {proj}\"\n                )\n                raise ValueError(msg)\n\n        keep = np.ones(len(self.info[\"projs\"]))\n        keep[idx] = False  # works with negative indexing and does checks\n        with self.info._unlock():\n            self.info[\"projs\"] = [p for p, k in zip(self.info[\"projs\"], keep) if k]\n        return self", "metadata": {}}
{"_id": "mne_mne__fiff/proj.py_plot_projs_topomap_code", "title": "plot_projs_topomap", "text": "def plot_projs_topomap(\n        self,\n        ch_type=None,\n        *,\n        sensors=True,\n        show_names=False,\n        contours=6,\n        outlines=\"head\",\n        sphere=None,\n        image_interp=_INTERPOLATION_DEFAULT,\n        extrapolate=_EXTRAPOLATE_DEFAULT,\n        border=_BORDER_DEFAULT,\n        res=64,\n        size=1,\n        cmap=None,\n        vlim=(None, None),\n        cnorm=None,\n        colorbar=False,\n        cbar_fmt=\"%3.1f\",\n        units=None,\n        axes=None,\n        show=True,\n    ):\n        \"\"\"Plot SSP vector.\n\n        Parameters\n        ----------\n        %(ch_type_topomap_proj)s\n        %(sensors_topomap)s\n        %(show_names_topomap)s\n\n            .. versionadded:: 1.2\n        %(contours_topomap)s\n        %(outlines_topomap)s\n        %(sphere_topomap_auto)s\n        %(image_interp_topomap)s\n        %(extrapolate_topomap)s\n\n            .. versionadded:: 0.20\n\n            .. versionchanged:: 0.21\n\n               - The default was changed to ``'local'`` for MEG sensors.\n               - ``'local'`` was changed to use a convex hull mask\n               - ``'head'`` was changed to extrapolate out to the clipping circle.\n        %(border_topomap)s\n\n            .. versionadded:: 0.20\n        %(res_topomap)s\n        %(size_topomap)s\n            Only applies when plotting multiple topomaps at a time.\n        %(cmap_topomap)s\n        %(vlim_plot_topomap_proj)s\n        %(cnorm)s\n\n            .. versionadded:: 1.2\n        %(colorbar_topomap)s\n        %(cbar_fmt_topomap)s\n\n            .. versionadded:: 1.2\n        %(units_topomap)s\n\n            .. versionadded:: 1.2\n        %(axes_plot_projs_topomap)s\n        %(show)s\n\n        Returns\n        -------\n        fig : instance of Figure\n            Figure distributing one image per channel across sensor topography.\n        \"\"\"\n        _projs = [deepcopy(_proj) for _proj in self.info[\"projs\"]]\n        if _projs is None or len(_projs) == 0:\n            raise ValueError(\"No projectors in Info; nothing to plot.\")\n        if ch_type is not None:\n            # make sure the requested channel type(s) exist\n            _validate_type(ch_type, (str, list, tuple), \"ch_type\")\n            if isinstance(ch_type, str):\n                ch_type = [ch_type]\n            bad_ch_types = [_type not in self for _type in ch_type]\n            if any(bad_ch_types):\n                raise ValueError(\n                    f\"ch_type {ch_type[bad_ch_types]} not \"\n                    f\"present in {self.__class__.__name__}.\"\n                )\n            # remove projs from unrequested channel types. This is a bit\n            # convoluted because Projection objects don't store channel types,\n            # only channel names\n            available_ch_types = np.array(self.get_channel_types())\n            for _proj in _projs[::-1]:\n                idx = np.isin(self.ch_names, _proj[\"data\"][\"col_names\"])\n                proj_ch_type = np.unique(available_ch_types[idx])\n                err_msg = \"Projector contains multiple channel types\"\n                assert len(proj_ch_type) == 1, err_msg\n                if proj_ch_type[0] != ch_type:\n                    _projs.remove(_proj)\n            if len(_projs) == 0:\n                raise ValueError(\n                    f\"Nothing to plot (no projectors for channel type {ch_type}).\"\n                )\n        # now we have non-empty _projs list with correct channel type(s)\n        from ..viz.topomap import plot_projs_topomap\n\n        fig = plot_projs_topomap(\n            _projs,\n            self.info,\n            sensors=sensors,\n            show_names=show_names,\n            contours=contours,\n            outlines=outlines,\n            sphere=sphere,\n            image_interp=image_interp,\n            extrapolate=extrapolate,\n            border=border,\n            res=res,\n            size=size,\n            cmap=cmap,\n            vlim=vlim,\n            cnorm=cnorm,\n            colorbar=colorbar,\n            cbar_fmt=cbar_fmt,\n            units=units,\n            axes=axes,\n            show=show,\n        )\n        return fig", "metadata": {}}
{"_id": "mne_mne__fiff/proj.py_sorter_code", "title": "sorter", "text": "def sorter(x):\n        \"\"\"Sort in a nice way.\"\"\"\n        digits = [s for s in x[\"desc\"] if s.isdigit()]\n        if digits:\n            sort_idx = int(digits[-1])\n        else:\n            sort_idx = next(my_count)\n        return (sort_idx, x[\"desc\"])", "metadata": {}}
{"_id": "mne_mne__fiff/matrix.py_write_named_matrix_code", "title": "write_named_matrix", "text": "def write_named_matrix(fid, kind, mat):\n    \"\"\"Write named matrix from the given node.\n\n    Parameters\n    ----------\n    fid : file\n        The opened file descriptor.\n    kind : int\n        The kind of the matrix.\n    matkind : int\n        The type of matrix.\n    \"\"\"\n    # let's save ourselves from disaster\n    n_tot = mat[\"nrow\"] * mat[\"ncol\"]\n    if mat[\"data\"].size != n_tot:\n        ratio = n_tot / float(mat[\"data\"].size)\n        if n_tot < mat[\"data\"].size and ratio > 0:\n            ratio = 1 / ratio\n        raise ValueError(\n            f\"Cannot write matrix: row ({mat['nrow']}) and column ({mat['ncol']}) \"\n            f\"total element ({n_tot}) mismatch with data size ({mat['data'].size}), \"\n            f\"appears to be off by a factor of {ratio:g}x\"\n        )\n    start_block(fid, FIFF.FIFFB_MNE_NAMED_MATRIX)\n    write_int(fid, FIFF.FIFF_MNE_NROW, mat[\"nrow\"])\n    write_int(fid, FIFF.FIFF_MNE_NCOL, mat[\"ncol\"])\n\n    if len(mat[\"row_names\"]) > 0:\n        # let's prevent unintentional stupidity\n        if len(mat[\"row_names\"]) != mat[\"nrow\"]:\n            raise ValueError('len(mat[\"row_names\"]) != mat[\"nrow\"]')\n        write_name_list(fid, FIFF.FIFF_MNE_ROW_NAMES, mat[\"row_names\"])\n\n    if len(mat[\"col_names\"]) > 0:\n        # let's prevent unintentional stupidity\n        if len(mat[\"col_names\"]) != mat[\"ncol\"]:\n            raise ValueError('len(mat[\"col_names\"]) != mat[\"ncol\"]')\n        write_name_list(fid, FIFF.FIFF_MNE_COL_NAMES, mat[\"col_names\"])\n\n    write_float_matrix(fid, kind, mat[\"data\"])\n    end_block(fid, FIFF.FIFFB_MNE_NAMED_MATRIX)", "metadata": {}}
{"_id": "mne_mne__fiff/what.py_what_code", "title": "what", "text": "def what(fname):\n    \"\"\"Try to determine the type of the FIF file.\n\n    Parameters\n    ----------\n    fname : path-like\n        The filename. Should end in ``.fif`` or ``.fif.gz``.\n\n    Returns\n    -------\n    what : str | None\n        The type of the file. Will be 'unknown' if it could not be determined.\n\n    Notes\n    -----\n    .. versionadded:: 0.19\n    \"\"\"\n    from ..bem import read_bem_solution, read_bem_surfaces\n    from ..cov import read_cov\n    from ..epochs import read_epochs\n    from ..event import read_events\n    from ..evoked import read_evokeds\n    from ..forward import read_forward_solution\n    from ..io import read_raw_fif\n    from ..minimum_norm import read_inverse_operator\n    from ..preprocessing import read_ica\n    from ..proj import read_proj\n    from ..source_space import read_source_spaces\n    from ..transforms import read_trans\n    from .meas_info import read_fiducials\n\n    fname = _check_fname(fname, overwrite=\"read\", must_exist=True)\n    checks = OrderedDict()\n    checks[\"raw\"] = read_raw_fif\n    checks[\"ica\"] = read_ica\n    checks[\"epochs\"] = read_epochs\n    checks[\"evoked\"] = read_evokeds\n    checks[\"forward\"] = read_forward_solution\n    checks[\"inverse\"] = read_inverse_operator\n    checks[\"src\"] = read_source_spaces\n    checks[\"bem solution\"] = read_bem_solution\n    checks[\"bem surfaces\"] = read_bem_surfaces\n    checks[\"cov\"] = read_cov\n    checks[\"transform\"] = read_trans\n    checks[\"events\"] = read_events\n    checks[\"fiducials\"] = read_fiducials\n    checks[\"proj\"] = read_proj\n    for what, func in checks.items():\n        args = signature(func).parameters\n        assert \"verbose\" in args, func\n        kwargs = dict(verbose=\"error\")\n        if \"preload\" in args:\n            kwargs[\"preload\"] = False\n        try:\n            func(fname, **kwargs)\n        except Exception as exp:\n            logger.debug(f\"Not {what}: {exp}\")\n        else:\n            return what\n    return \"unknown\"", "metadata": {}}
{"_id": "mne_mne__fiff/tree.py_dir_tree_find_code", "title": "dir_tree_find", "text": "def dir_tree_find(tree, kind):\n    \"\"\"Find nodes of the given kind from a directory tree structure.\n\n    Parameters\n    ----------\n    tree : dict\n        Directory tree.\n    kind : int\n        Kind to find.\n\n    Returns\n    -------\n    nodes : list\n        List of matching nodes.\n    \"\"\"\n    nodes = []\n\n    if isinstance(tree, list):\n        for t in tree:\n            nodes += dir_tree_find(t, kind)\n    else:\n        #   Am I desirable myself?\n        if tree[\"block\"] == kind:\n            nodes.append(tree)\n\n        #   Search the subtrees\n        for child in tree[\"children\"]:\n            nodes += dir_tree_find(child, kind)\n    return nodes", "metadata": {}}
{"_id": "mne_mne__fiff/tree.py_make_dir_tree_code", "title": "make_dir_tree", "text": "def make_dir_tree(fid, directory, start=0, indent=0, verbose=None):\n    \"\"\"Create the directory tree structure.\"\"\"\n    if directory[start].kind == FIFF.FIFF_BLOCK_START:\n        tag = read_tag(fid, directory[start].pos)\n        block = tag.data.item()\n    else:\n        block = 0\n\n    start_separate = False\n\n    this = start\n\n    tree = dict()\n    tree[\"block\"] = block\n    tree[\"id\"] = None\n    tree[\"parent_id\"] = None\n    tree[\"nent\"] = 0\n    tree[\"nchild\"] = 0\n    tree[\"directory\"] = directory[this]\n    tree[\"children\"] = []\n\n    while this < len(directory):\n        if directory[this].kind == FIFF.FIFF_BLOCK_START:\n            if this != start:\n                if not start_separate:\n                    start_separate = True\n                    logger.debug(\"    \" * indent + f\"start {{ {block}\")\n                child, this = make_dir_tree(fid, directory, this, indent + 1)\n                tree[\"nchild\"] += 1\n                tree[\"children\"].append(child)\n        elif directory[this].kind == FIFF.FIFF_BLOCK_END:\n            tag = read_tag(fid, directory[start].pos)\n            if tag.data == block:\n                break\n        else:\n            tree[\"nent\"] += 1\n            if tree[\"nent\"] == 1:\n                tree[\"directory\"] = list()\n            tree[\"directory\"].append(directory[this])\n\n            #  Add the id information if available\n            if block == 0:\n                if directory[this].kind == FIFF.FIFF_FILE_ID:\n                    tag = read_tag(fid, directory[this].pos)\n                    tree[\"id\"] = tag.data\n            else:\n                if directory[this].kind == FIFF.FIFF_BLOCK_ID:\n                    tag = read_tag(fid, directory[this].pos)\n                    tree[\"id\"] = tag.data\n                elif directory[this].kind == FIFF.FIFF_PARENT_BLOCK_ID:\n                    tag = read_tag(fid, directory[this].pos)\n                    tree[\"parent_id\"] = tag.data\n\n        this += 1\n\n    # Eliminate the empty directory\n    if tree[\"nent\"] == 0:\n        tree[\"directory\"] = None\n\n    content = f\"block = {tree['block']} nent = {tree['nent']} nchild = {tree['nchild']}\"\n    if start_separate:\n        logger.debug(\"    \" * indent + f\"end }} {content}\")\n    else:\n        logger.debug(\"    \" * indent + content)\n    last = this\n    return tree, last", "metadata": {}}
{"_id": "mne_mne__fiff/tag.py_read_tag_code", "title": "read_tag", "text": "def read_tag(fid, pos, shape=None, rlims=None):\n    \"\"\"Read a Tag from a file at a given position.\n\n    Parameters\n    ----------\n    fid : file\n        The open FIF file descriptor.\n    pos : int\n        The position of the Tag in the file.\n    shape : tuple | None\n        If tuple, the shape of the stored matrix. Only to be used with\n        data stored as a vector (not implemented for matrices yet).\n    rlims : tuple | None\n        If tuple, the first (inclusive) and last (exclusive) rows to retrieve.\n        Note that data are assumed to be stored row-major in the file. Only to\n        be used with data stored as a vector (not implemented for matrices\n        yet).\n\n    Returns\n    -------\n    tag : Tag\n        The Tag read.\n    \"\"\"\n    tag = _read_tag_header(fid, pos)\n    if tag is None:\n        return tag\n    if tag.size > 0:\n        if _matrix_info(tag) is not None:\n            tag.data = _read_matrix(fid, tag, shape, rlims)\n        else:\n            #   All other data types\n            try:\n                fun = _call_dict[tag.type]\n            except KeyError:\n                raise Exception(f\"Unimplemented tag data type {tag.type}\") from None\n            tag.data = fun(fid, tag, shape, rlims)\n    return tag", "metadata": {}}
{"_id": "mne_mne__fiff/tag.py_find_tag_code", "title": "find_tag", "text": "def find_tag(fid, node, findkind):\n    \"\"\"Find Tag in an open FIF file descriptor.\n\n    Parameters\n    ----------\n    fid : file-like\n        Open file.\n    node : dict\n        Node to search.\n    findkind : int\n        Tag kind to find.\n\n    Returns\n    -------\n    tag : instance of Tag\n        The first tag found.\n    \"\"\"\n    if node[\"directory\"] is not None:\n        for subnode in node[\"directory\"]:\n            if subnode.kind == findkind:\n                return read_tag(fid, subnode.pos)\n    return None", "metadata": {}}
{"_id": "mne_mne__fiff/tag.py_has_tag_code", "title": "has_tag", "text": "def has_tag(node, kind):\n    \"\"\"Check if the node contains a Tag of a given kind.\"\"\"\n    for d in node[\"directory\"]:\n        if d.kind == kind:\n            return True\n    return False", "metadata": {}}
{"_id": "mne_mne__fiff/tag.py_next_pos_code", "title": "next_pos", "text": "def next_pos(self):\n        \"\"\"The next tag position.\"\"\"\n        if self.next == FIFF.FIFFV_NEXT_SEQ:  # 0\n            return self.pos + 16 + self.size\n        elif self.next > 0:\n            return self.next\n        else:  # self.next should be -1 if we get here\n            return None", "metadata": {}}
{"_id": "mne_mne__fiff/utils.py_read_str_code", "title": "read_str", "text": "def read_str(fid, count=1):\n    \"\"\"Read string from a binary file in a python version compatible way.\"\"\"\n    dtype = np.dtype(f\">S{count}\")\n    string = fid.read(dtype.itemsize)\n    data = np.frombuffer(string, dtype=dtype)[0]\n    bytestr = b\"\".join([data[0 : data.index(b\"\\x00\") if b\"\\x00\" in data else count]])\n\n    return str(bytestr.decode(\"ascii\"))", "metadata": {}}
{"_id": "mne_mne__fiff/compensator.py_get_current_comp_code", "title": "get_current_comp", "text": "def get_current_comp(info):\n    \"\"\"Get the current compensation in effect in the data.\"\"\"\n    comp = None\n    first_comp = -1\n    for k, chan in enumerate(info[\"chs\"]):\n        if chan[\"kind\"] == FIFF.FIFFV_MEG_CH:\n            comp = int(chan[\"coil_type\"]) >> 16\n            if first_comp < 0:\n                first_comp = comp\n            elif comp != first_comp:\n                raise ValueError(\"Compensation is not set equally on all MEG channels\")\n    return comp", "metadata": {}}
{"_id": "mne_mne__fiff/compensator.py_set_current_comp_code", "title": "set_current_comp", "text": "def set_current_comp(info, comp):\n    \"\"\"Set the current compensation in effect in the data.\"\"\"\n    comp_now = get_current_comp(info)\n    for k, chan in enumerate(info[\"chs\"]):\n        if chan[\"kind\"] == FIFF.FIFFV_MEG_CH:\n            rem = chan[\"coil_type\"] - (comp_now << 16)\n            chan[\"coil_type\"] = int(rem + (comp << 16))", "metadata": {}}
{"_id": "mne_mne__fiff/compensator.py_make_compensator_code", "title": "make_compensator", "text": "def make_compensator(info, from_, to, exclude_comp_chs=False):\n    \"\"\"Return compensation matrix eg. for CTF system.\n\n    Create a compensation matrix to bring the data from one compensation\n    state to another.\n\n    Parameters\n    ----------\n    %(info_not_none)s\n    from_ : int\n        Compensation in the input data.\n    to : int\n        Desired compensation in the output.\n    exclude_comp_chs : bool\n        Exclude compensation channels from the output.\n\n    Returns\n    -------\n    comp : array | None.\n        The compensation matrix. Might be None if no compensation\n        is needed (from == to).\n    \"\"\"\n    if from_ == to:\n        return None\n\n    #   s_orig = s_from + C1*s_from = (I + C1)*s_from\n    #   s_to   = s_orig - C2*s_orig = (I - C2)*s_orig\n    #   s_to   = (I - C2)*(I + C1)*s_from = (I + C1 - C2 - C2*C1)*s_from\n    if from_ != 0:\n        C1 = _make_compensator(info, from_)\n        comp_from_0 = np.linalg.inv(np.eye(info[\"nchan\"]) - C1)\n    if to != 0:\n        C2 = _make_compensator(info, to)\n        comp_0_to = np.eye(info[\"nchan\"]) - C2\n    if from_ != 0:\n        if to != 0:\n            # This is mathematically equivalent, but has higher numerical\n            # error than using the inverse to always go to zero and back\n            # comp = np.eye(info['nchan']) + C1 - C2 - np.dot(C2, C1)\n            comp = np.dot(comp_0_to, comp_from_0)\n        else:\n            comp = comp_from_0\n    else:\n        # from == 0, to != 0 guaranteed here\n        comp = comp_0_to\n\n    if exclude_comp_chs:\n        pick = [\n            k for k, c in enumerate(info[\"chs\"]) if c[\"kind\"] != FIFF.FIFFV_REF_MEG_CH\n        ]\n\n        if len(pick) == 0:\n            raise ValueError(\n                \"Nothing remains after excluding the compensation channels\"\n            )\n\n        comp = comp[pick, :]\n\n    return comp", "metadata": {}}
{"_id": "mne_mne__fiff/ctf_comp.py_read_ctf_comp_code", "title": "read_ctf_comp", "text": "def read_ctf_comp(fid, node, chs, verbose=None):\n    \"\"\"Read the CTF software compensation data from the given node.\n\n    Parameters\n    ----------\n    fid : file\n        The file descriptor.\n    node : dict\n        The node in the FIF tree.\n    chs : list\n        The list of channels from info['chs'] to match with\n        compensators that are read.\n    %(verbose)s\n\n    Returns\n    -------\n    compdata : list\n        The compensation data\n    \"\"\"\n    return _read_ctf_comp(fid, node, chs, None)", "metadata": {}}
{"_id": "mne_mne__fiff/ctf_comp.py_write_ctf_comp_code", "title": "write_ctf_comp", "text": "def write_ctf_comp(fid, comps):\n    \"\"\"Write the CTF compensation data into a fif file.\n\n    Parameters\n    ----------\n    fid : file\n        The open FIF file descriptor\n\n    comps : list\n        The compensation data to write\n    \"\"\"\n    if len(comps) <= 0:\n        return\n\n    #  This is very simple in fact\n    start_block(fid, FIFF.FIFFB_MNE_CTF_COMP)\n    for comp in comps:\n        start_block(fid, FIFF.FIFFB_MNE_CTF_COMP_DATA)\n        #    Write the compensation kind\n        write_int(fid, FIFF.FIFF_MNE_CTF_COMP_KIND, comp[\"ctfkind\"])\n        if comp.get(\"save_calibrated\", False):\n            write_int(fid, FIFF.FIFF_MNE_CTF_COMP_CALIBRATED, comp[\"save_calibrated\"])\n\n        if not comp.get(\"save_calibrated\", True):\n            # Undo calibration\n            comp = deepcopy(comp)\n            data = (\n                (1.0 / comp[\"rowcals\"][:, None])\n                * comp[\"data\"][\"data\"]\n                * (1.0 / comp[\"colcals\"][None, :])\n            )\n            comp[\"data\"][\"data\"] = data\n        write_named_matrix(fid, FIFF.FIFF_MNE_CTF_COMP_DATA, comp[\"data\"])\n        end_block(fid, FIFF.FIFFB_MNE_CTF_COMP_DATA)\n\n    end_block(fid, FIFF.FIFFB_MNE_CTF_COMP)", "metadata": {}}
{"_id": "eeg_query_001_code", "title": "How can I check if a specific EEG channel is marked as bad in PyPREP?", "text": "To check if a specific EEG channel is marked as bad in PyPREP, you can use the `get_bad_channels()` method from the `PyPREP` class. This method returns a list of all bad channels that have been marked during preprocessing. You can then check if your specific channel is included in this list to determine if it has been marked as bad.", "metadata": {}}
{"_id": "eeg_query_002_code", "title": "How do I compute the median of a matrix in a MATLAB-compatible way using PyPREP?", "text": "To compute the median of a matrix in a MATLAB-compatible way using PyPREP, you can use the `prep.compute_median` function. This function takes a matrix as input and returns the median value. Here is an example code snippet:\n\n```python\nimport prep\n\nmatrix = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]\nmedian_value = prep.compute_median(matrix)\nprint(\"Median value:\", median_value)\n```\n\nThis code will calculate the median of the matrix `[1, 2, 3], [4, 5, 6], [7, 8, 9]` and print the result.", "metadata": {}}
{"_id": "eeg_query_003_code", "title": "How can I calculate the mean of a matrix with behavior similar to MATLAB's mean function?", "text": "In PyPREP, you can calculate the mean of a matrix using the `numpy` library. You can use the `numpy.mean()` function to calculate the mean along a specific axis of the matrix. Here is an example code snippet:\n\n```python\nimport numpy as np\n\n# Assuming your matrix is stored in a variable called 'matrix'\nmean_matrix = np.mean(matrix, axis=0)  # Calculate the mean along the 0th axis\n```\n\nThis code snippet will calculate the mean of the matrix along the specified axis, similar to MATLAB's mean function.", "metadata": {}}
{"_id": "eeg_query_004_code", "title": "How do I visualize RANSAC correlation results to assess EEG channel quality?", "text": "To visualize RANSAC correlation results in PyPREP, you can use the `plot_ransac_correlation` function. This function allows you to assess the quality of EEG channels by displaying the correlation values computed using RANSAC. Simply pass in the output of the `compute_ransac_correlation` function as the input to `plot_ransac_correlation` to generate the visualization. This will provide you with a clear overview of the correlation results, helping you to identify any problematic channels that may need further preprocessing.", "metadata": {}}
{"_id": "eeg_query_005_code", "title": "How do I retrieve a boolean mask of bad EEG channels from the PREP pipeline?", "text": "To retrieve a boolean mask of bad EEG channels from the PREP pipeline in PyPREP, you can use the `get_bads_mask()` function. This function returns a boolean mask where `True` indicates a bad EEG channel. You can use this mask to identify and handle bad channels in your EEG data.", "metadata": {}}
{"_id": "eeg_query_006_code", "title": "How can I save the cleaned EEG data after running the PREP pipeline?", "text": "After running the PREP pipeline in PyPREP, you can save the cleaned EEG data by using the `save` method provided by the `EEG` object. \n\nHere is an example code snippet to save the cleaned EEG data:\n```python\n# Assuming 'eeg' is your EEG object after running the PREP pipeline\neeg.save('path/to/save/cleaned_data.edf')\n```\n\nThis will save the cleaned EEG data in the EDF format at the specified path. You can also choose other file formats supported by PyPREP, such as CSV or FIF, by changing the file extension in the save method.", "metadata": {}}
{"_id": "eeg_query_007_code", "title": "How do I check if two lists of EEG channels have any overlap?", "text": "You can use the `check_channel_overlap` function in PyPREP to compare two lists of EEG channels and determine if there is any overlap. This function takes in two lists of channel names as input and returns a boolean value indicating whether there is any overlap between the two lists. Simply call this function with your two lists of channels to check for overlap.", "metadata": {}}
{"_id": "eeg_query_008_code", "title": "How do I remove duplicates from a list while preserving the original order in PyPREP?", "text": "To remove duplicates from a list while preserving the original order in PyPREP, you can use the `remove_duplicates` function from the PyPREP library. This function removes duplicate elements from a list while maintaining the original order. You can simply pass your list as an argument to the `remove_duplicates` function to achieve this.", "metadata": {}}
{"_id": "eeg_query_009_code", "title": "How do I plot statistical summaries of EEG channels after preprocessing?", "text": "To plot statistical summaries of EEG channels after preprocessing in PyPREP, you can use the `plot_channel_statistics()` function. This function generates a plot showing statistical summaries of each EEG channel, including mean, standard deviation, skewness, and kurtosis. You can customize the plot by specifying parameters such as the color scheme and title. Simply call `plot_channel_statistics()` with your preprocessed EEG data as input to visualize the statistical summaries of your EEG channels.", "metadata": {}}
{"_id": "eeg_query_010_code", "title": "How can I extract clean EEG epochs after bad channel rejection?", "text": "After rejecting bad channels using PyPREP, you can extract clean EEG epochs by using the `extract_epochs` function. This function takes in the preprocessed EEG data and the event markers, and returns clean epochs based on the specified time window around each event. Make sure to specify the desired time window and any other relevant parameters in the function call to extract the epochs according to your needs.", "metadata": {}}
{"_id": "eeg_query_011_code", "title": "How do I compute the signal-to-noise ratio (SNR) of EEG signals using PyPREP?", "text": "To compute the signal-to-noise ratio (SNR) of EEG signals using PyPREP, you can utilize the `compute_snr` function provided in the PyPREP library. This function takes in the EEG data as input and calculates the SNR for each channel. You can refer to the PyPREP documentation for more detailed instructions on how to use this function and interpret the results.", "metadata": {}}
{"_id": "eeg_query_012_code", "title": "How do I validate input EEG data before running the PREP pipeline?", "text": "To validate input EEG data before running the PREP pipeline in PyPREP, you can use the `prep.validate_input` function. This function checks the input EEG data for common issues such as missing channels, incorrect sampling rates, and non-numeric values. By running this validation step before starting the pipeline, you can ensure that your data meets the necessary requirements for successful preprocessing.", "metadata": {}}
{"_id": "eeg_query_013_code", "title": "How can I get a list of EEG channels not marked as bad?", "text": "You can use the `get_good_channels` function in PyPREP to get a list of EEG channels that are not marked as bad. This function returns a list of channel names that are considered good based on the bad channel markers provided. You can then use this list for further preprocessing steps.", "metadata": {}}
{"_id": "eeg_query_014_code", "title": "How do I summarize configuration parameters used in a PyPREP run?", "text": "To summarize the configuration parameters used in a PyPREP run, you can access the `config` attribute of the PyPREP object after running the preprocessing. This attribute contains a dictionary with all the configuration parameters used in the preprocessing pipeline. You can print or inspect this dictionary to see a summary of the parameters used in the PyPREP run.", "metadata": {}}
{"_id": "eeg_query_015_code", "title": "How do I run the PyPREP pipeline with custom filtering and reference settings?", "text": "To run the PyPREP pipeline with custom filtering and reference settings, you can specify these parameters in the `prep_pipeline` function. \n\nFor custom filtering settings, you can use the `low_cutoff`, `high_cutoff`, and `notch_filter` parameters to set the desired frequency ranges. For example:\n```python\nprep_pipeline(data, low_cutoff=0.5, high_cutoff=50, notch_filter=True)\n```\n\nFor custom reference settings, you can use the `reference` parameter to specify the reference type. Options include 'average', 'bipolar', 'laplacian', or a custom reference array. For example:\n```python\nprep_pipeline(data, reference='average')\n```\n\nBy adjusting these parameters in the `prep_pipeline` function call, you can customize the filtering and reference settings for your EEG preprocessing with PyPREP.", "metadata": {}}
{"_id": "pyprep_pyprep_prep_pipeline.py___init___code", "title": "__init__", "text": "def __init__(self, raw, prep_params, montage, ransac=True, channel_wise=False, max_chunk_size=None, random_state=None, filter_kwargs=None, matlab_strict=False):\n    \"\"\"Initialize PREP class.\"\"\"\n    raw.load_data()\n    self.raw_eeg = raw.copy()\n    self.ch_names_all = raw.ch_names.copy()\n    self.ch_types_all = raw.get_channel_types()\n    self.ch_names_eeg = [self.ch_names_all[i] for i in range(len(self.ch_names_all)) if self.ch_types_all[i] == 'eeg']\n    self.ch_names_non_eeg = list(set(self.ch_names_all) - set(self.ch_names_eeg))\n    self.raw_eeg.pick(self.ch_names_eeg)\n    if self.ch_names_non_eeg == []:\n        self.raw_non_eeg = None\n    else:\n        self.raw_non_eeg = raw.copy()\n        self.raw_non_eeg.pick(self.ch_names_non_eeg)\n    self.raw_eeg.set_montage(montage)\n    self.EEG_raw = self.raw_eeg.get_data()\n    self.prep_params = prep_params\n    if self.prep_params['ref_chs'] == 'eeg':\n        self.prep_params['ref_chs'] = self.ch_names_eeg\n    if self.prep_params['reref_chs'] == 'eeg':\n        self.prep_params['reref_chs'] = self.ch_names_eeg\n    if 'max_iterations' not in prep_params.keys():\n        self.prep_params['max_iterations'] = 4\n    self.sfreq = self.raw_eeg.info['sfreq']\n    self.ransac_settings = {'ransac': ransac, 'channel_wise': channel_wise, 'max_chunk_size': max_chunk_size}\n    self.random_state = check_random_state(random_state)\n    self.filter_kwargs = filter_kwargs\n    self.matlab_strict = matlab_strict", "metadata": {}}
{"_id": "pyprep_pyprep_prep_pipeline.py_raw_code", "title": "raw", "text": "@property\ndef raw(self):\n    \"\"\"Return a version of self.raw_eeg that includes the non-eeg channels.\"\"\"\n    full_raw = self.raw_eeg.copy()\n    if self.raw_non_eeg is None:\n        return full_raw\n    else:\n        return full_raw.add_channels([self.raw_non_eeg], force_update_info=True)", "metadata": {}}
{"_id": "pyprep_pyprep_prep_pipeline.py_fit_code", "title": "fit", "text": "def fit(self):\n    \"\"\"Run the whole PREP pipeline.\"\"\"\n    if len(self.prep_params['line_freqs']) != 0:\n        self.EEG_new = removeTrend(self.EEG_raw, self.sfreq, matlab_strict=self.matlab_strict)\n        linenoise = self.prep_params['line_freqs']\n        if self.filter_kwargs is None:\n            self.EEG_clean = mne.filter.notch_filter(self.EEG_new, Fs=self.sfreq, freqs=linenoise, method='spectrum_fit', mt_bandwidth=2, p_value=0.01, filter_length='10s')\n        else:\n            self.EEG_clean = mne.filter.notch_filter(self.EEG_new, Fs=self.sfreq, freqs=linenoise, **self.filter_kwargs)\n        self.EEG = self.EEG_raw - self.EEG_new + self.EEG_clean\n        self.raw_eeg._data = self.EEG\n    reference = Reference(self.raw_eeg, self.prep_params, random_state=self.random_state, matlab_strict=self.matlab_strict, **self.ransac_settings)\n    reference.perform_reference(self.prep_params['max_iterations'])\n    self.raw_eeg = reference.raw\n    self.noisy_channels_original = reference.noisy_channels_original\n    self.noisy_channels_before_interpolation = reference.noisy_channels_before_interpolation\n    self.noisy_channels_after_interpolation = reference.noisy_channels_after_interpolation\n    self.bad_before_interpolation = reference.bad_before_interpolation\n    self.EEG_before_interpolation = reference.EEG_before_interpolation\n    self.reference_before_interpolation = reference.reference_signal\n    self.reference_after_interpolation = reference.reference_signal_new\n    self.interpolated_channels = reference.interpolated_channels\n    self.still_noisy_channels = reference.still_noisy_channels\n    return self", "metadata": {}}
{"_id": "pyprep_pyprep_removeTrend.py_removeTrend_code", "title": "removeTrend", "text": "def removeTrend(EEG, sample_rate, detrendType='high pass', detrendCutoff=1.0, detrendChannels=None, matlab_strict=False):\n    \"\"\"Remove trends (i.e., slow drifts in baseline) from an array of EEG data.\n\n    Parameters\n    ----------\n    EEG : np.ndarray\n        A 2-D array of EEG data to detrend.\n    sample_rate : float\n        The sample rate (in Hz) of the input EEG data.\n    detrendType : str, optional\n        Type of detrending to be performed: must be one of 'high pass',\n        'high pass sinc, or 'local detrend'. Defaults to 'high pass'.\n    detrendCutoff : float, optional\n        The high-pass cutoff frequency (in Hz) to use for detrending. Defaults\n        to 1.0 Hz.\n    detrendChannels : {list, None}, optional\n        List of the indices of all channels that require detrending/filtering.\n        If ``None``, all channels are used (default).\n    matlab_strict : bool, optional\n        Whether or not detrending should strictly follow MATLAB PREP's internal\n        math, ignoring any improvements made in PyPREP over the original code\n        (see :ref:`matlab-diffs` for more details). Defaults to ``False``.\n\n    Returns\n    -------\n    EEG : np.ndarray\n        A 2-D array containing the filtered/detrended EEG data.\n\n    Notes\n    -----\n    High-pass filtering is implemented using the MNE filter function\n    :func:``mne.filter.filter_data`` unless `matlab_strict` is ``True``, in\n    which case it is performed using a minimal re-implementation of EEGLAB's\n    ``pop_eegfiltnew``. Local detrending is performed using a Python\n    re-implementation of the ``runline`` function from the Chronux package for\n    MATLAB [1]_.\n\n    References\n    ----------\n    .. [1] http://chronux.org/\n\n    \"\"\"\n    if len(EEG.shape) == 1:\n        EEG = np.reshape(EEG, (1, EEG.shape[0]))\n    if detrendType.lower() == 'high pass':\n        if matlab_strict:\n            picks = detrendChannels if detrendChannels else range(EEG.shape[0])\n            filt = _eeglab_create_highpass(detrendCutoff, sample_rate)\n            EEG[picks, :] = _eeglab_fir_filter(EEG[picks, :], filt)\n        else:\n            EEG = mne.filter.filter_data(EEG, sfreq=sample_rate, l_freq=detrendCutoff, h_freq=None, picks=detrendChannels)\n    elif detrendType.lower() == 'high pass sinc':\n        fOrder = np.round(14080 * sample_rate / 512)\n        fOrder = int(fOrder + fOrder % 2)\n        EEG = mne.filter.filter_data(data=EEG, sfreq=sample_rate, l_freq=1, h_freq=None, picks=detrendChannels, filter_length=fOrder, fir_window='blackman')\n    elif detrendType.lower() == 'local detrend':\n        if detrendChannels is None:\n            detrendChannels = np.arange(0, EEG.shape[0])\n        windowSize = 1.5 / detrendCutoff\n        windowSize = np.minimum(windowSize, EEG.shape[1])\n        stepSize = 0.02\n        EEG = np.transpose(EEG)\n        n = np.round(sample_rate * windowSize)\n        dn = np.round(sample_rate * stepSize)\n        if dn > n or dn < 1:\n            logging.error('Step size should be less than the window size and contain at least 1 sample')\n        if n == EEG.shape[0]:\n            pass\n        else:\n            for ch in detrendChannels:\n                EEG[:, ch] = runline(EEG[:, ch], int(n), int(dn))\n        EEG = np.transpose(EEG)\n    else:\n        logging.warning('No filtering/detreding performed since the detrend type did not match')\n    return EEG", "metadata": {}}
{"_id": "pyprep_pyprep_removeTrend.py_runline_code", "title": "runline", "text": "def runline(y, n, dn):\n    \"\"\"Perform local linear regression on a channel of EEG data.\n\n    A re-implementation of the ``runline`` function from the Chronux package\n    for MATLAB [1]_.\n\n    Parameters\n    ----------\n    y : np.ndarray\n        A 1-D array of data from a single EEG channel.\n    n : int\n        Length of the detrending window.\n    dn : int\n        Length of the window step size.\n\n    Returns\n    -------\n    y: np.ndarray\n       The detrended signal for the given EEG channel.\n\n    References\n    ----------\n    .. [1] http://chronux.org/\n\n    \"\"\"\n    nt = y.shape[0]\n    y_line = np.zeros((nt, 1))\n    norm = np.zeros((nt, 1))\n    nwin = int(np.ceil((nt - n) / dn))\n    yfit = np.zeros((nwin, n))\n    xwt = (np.arange(1, n + 1) - n / 2) / (n / 2)\n    wt = np.power(1 - np.power(np.absolute(xwt), 3), 3)\n    for j in range(0, nwin):\n        tseg = y[dn * j:dn * j + n]\n        y1 = np.mean(tseg)\n        y2 = np.mean(np.multiply(np.arange(1, n + 1), tseg)) * (2 / (n + 1))\n        a = np.multiply(np.subtract(y2, y1), 6 / (n - 1))\n        b = np.subtract(y1, a * (n + 1) / 2)\n        yfit[j, :] = np.multiply(np.arange(1, n + 1), a) + b\n        y_line[j * dn:j * dn + n] = y_line[j * dn:j * dn + n] + np.reshape(np.multiply(yfit[j, :], wt), (n, 1))\n        norm[j * dn:j * dn + n] = norm[j * dn:j * dn + n] + np.reshape(wt, (n, 1))\n    for i in range(0, len(norm)):\n        if norm[i] > 0:\n            y_line[i] = y_line[i] / norm[i]\n    indx = (nwin - 1) * dn + n - 1\n    npts = len(y) - indx + 1\n    y_line[indx - 1:] = np.reshape(np.multiply(np.arange(n + 1, n + npts + 1), a) + b, (npts, 1))\n    for i in range(0, len(y_line)):\n        y[i] = y[i] - y_line[i, 0]\n    return y", "metadata": {}}
{"_id": "pyprep_pyprep_reference.py___init___code", "title": "__init__", "text": "def __init__(self, raw, params, ransac=True, channel_wise=False, max_chunk_size=None, random_state=None, matlab_strict=False):\n    \"\"\"Initialize the class.\"\"\"\n    raw.load_data()\n    self.raw = raw.copy()\n    self.ch_names = self.raw.ch_names\n    self.raw.pick('eeg', exclude=[])\n    self.bads_manual = raw.info['bads']\n    self.ch_names_eeg = self.raw.ch_names\n    self.EEG = self.raw.get_data()\n    self.reference_channels = params['ref_chs']\n    self.rereferenced_channels = params['reref_chs']\n    self.sfreq = self.raw.info['sfreq']\n    self.ransac_settings = {'ransac': ransac, 'channel_wise': channel_wise, 'max_chunk_size': max_chunk_size}\n    self.random_state = check_random_state(random_state)\n    self._extra_info = {}\n    self.matlab_strict = matlab_strict", "metadata": {}}
{"_id": "pyprep_pyprep_reference.py_perform_reference_code", "title": "perform_reference", "text": "def perform_reference(self, max_iterations=4):\n    \"\"\"Estimate the true signal mean and interpolate bad channels.\n\n        Parameters\n        ----------\n        max_iterations : int, optional\n            The maximum number of iterations of noisy channel removal to perform\n            during robust referencing. Defaults to ``4``.\n\n        This function implements the functionality of the `performReference` function\n        as part of the PREP pipeline on mne raw object.\n\n        Notes\n        -----\n        This function calls ``robust_reference`` first.\n        Currently this function only implements the functionality of default\n        settings, i.e., ``doRobustPost``.\n\n        \"\"\"\n    self.robust_reference(max_iterations)\n    dummy = self.raw.copy()\n    dummy.info['bads'] = self.noisy_channels['bad_all']\n    if self.matlab_strict:\n        _eeglab_interpolate_bads(dummy)\n    else:\n        dummy.interpolate_bads()\n    self.reference_signal = np.nanmean(dummy.get_data(picks=self.reference_channels), axis=0)\n    del dummy\n    rereferenced_index = [self.ch_names_eeg.index(ch) for ch in self.rereferenced_channels]\n    self.EEG = self.remove_reference(self.EEG, self.reference_signal, rereferenced_index)\n    self.raw._data = self.EEG\n    noisy_detector = NoisyChannels(self.raw, random_state=self.random_state, matlab_strict=self.matlab_strict)\n    noisy_detector.find_all_bads(**self.ransac_settings)\n    self.bad_before_interpolation = noisy_detector.get_bads(verbose=True)\n    self.EEG_before_interpolation = self.EEG.copy()\n    self.noisy_channels_before_interpolation = noisy_detector.get_bads(as_dict=True)\n    self.noisy_channels_before_interpolation['bad_by_manual'] = self.bads_manual\n    self._extra_info['interpolated'] = noisy_detector._extra_info\n    bad_channels = _union(self.bad_before_interpolation, self.unusable_channels)\n    self.raw.info['bads'] = bad_channels\n    if self.matlab_strict:\n        _eeglab_interpolate_bads(self.raw)\n    else:\n        self.raw.interpolate_bads()\n    reference_correct = np.nanmean(self.raw.get_data(picks=self.reference_channels), axis=0)\n    self.EEG = self.raw.get_data()\n    self.EEG = self.remove_reference(self.EEG, reference_correct, rereferenced_index)\n    self.reference_signal_new = self.reference_signal + reference_correct\n    self.raw._data = self.EEG\n    self.interpolated_channels = bad_channels\n    noisy_detector = NoisyChannels(self.raw, random_state=self.random_state, matlab_strict=self.matlab_strict)\n    noisy_detector.find_all_bads(**self.ransac_settings)\n    self.still_noisy_channels = noisy_detector.get_bads()\n    self.raw.info['bads'] = self.still_noisy_channels\n    self.noisy_channels_after_interpolation = noisy_detector.get_bads(as_dict=True)\n    self._extra_info['remaining_bad'] = noisy_detector._extra_info\n    return self", "metadata": {}}
{"_id": "pyprep_pyprep_reference.py_robust_reference_code", "title": "robust_reference", "text": "def robust_reference(self, max_iterations=4):\n    \"\"\"Detect bad channels and estimate the robust reference signal.\n\n        This function implements the functionality of the `robustReference` function\n        as part of the PREP pipeline on mne raw object.\n\n        Parameters\n        ----------\n        max_iterations : int, optional\n            The maximum number of iterations of noisy channel removal to perform\n            during robust referencing. Defaults to ``4``.\n\n        Returns\n        -------\n        noisy_channels: dict\n            A dictionary of names of noisy channels detected from all methods\n            after referencing.\n        reference_signal: np.ndarray, shape(n, )\n            Estimation of the 'true' signal mean\n\n        \"\"\"\n    raw = self.raw.copy()\n    raw._data = removeTrend(raw.get_data(), self.sfreq, matlab_strict=self.matlab_strict)\n    noisy_detector = NoisyChannels(raw, do_detrend=False, random_state=self.random_state, matlab_strict=self.matlab_strict)\n    noisy_detector.find_all_bads(**self.ransac_settings)\n    self.noisy_channels_original = noisy_detector.get_bads(as_dict=True)\n    self._extra_info['initial_bad'] = noisy_detector._extra_info\n    logger.info(f'Bad channels: {self.noisy_channels_original}')\n    self.unusable_channels = _union(noisy_detector.bad_by_nan + noisy_detector.bad_by_flat, noisy_detector.bad_by_SNR + self.bads_manual)\n    reference_channels = _set_diff(self.reference_channels, self.unusable_channels)\n    noisy = {'bad_by_nan': noisy_detector.bad_by_nan, 'bad_by_flat': noisy_detector.bad_by_flat, 'bad_by_deviation': [], 'bad_by_hf_noise': [], 'bad_by_correlation': [], 'bad_by_SNR': [], 'bad_by_dropout': [], 'bad_by_ransac': [], 'bad_by_manual': self.bads_manual, 'bad_all': []}\n    signal = raw.get_data()\n    self.reference_signal = np.nanmedian(raw.get_data(picks=reference_channels), axis=0)\n    reference_index = [self.ch_names_eeg.index(ch) for ch in reference_channels]\n    signal_tmp = self.remove_reference(signal, self.reference_signal, reference_index)\n    raw_tmp = raw.copy()\n    iterations = 0\n    previous_bads = set()\n    while True:\n        raw_tmp._data = signal_tmp\n        noisy_detector = NoisyChannels(raw_tmp, do_detrend=False, random_state=self.random_state, matlab_strict=self.matlab_strict)\n        noisy_detector.find_all_bads(**self.ransac_settings)\n        noisy_new = noisy_detector.get_bads(as_dict=True)\n        ignore = ['bad_by_SNR', 'bad_all']\n        if self.matlab_strict:\n            ignore += ['bad_by_dropout']\n        bad_chans = set()\n        for bad_type in noisy_new.keys():\n            noisy[bad_type] = _union(noisy[bad_type], noisy_new[bad_type])\n            if bad_type not in ignore:\n                bad_chans.update(noisy[bad_type])\n        noisy['bad_by_manual'] = self.bads_manual\n        noisy['bad_all'] = list(bad_chans) + self.bads_manual\n        logger.info(f'Bad channels: {noisy}')\n        if iterations > 1 and (len(bad_chans) == 0 or bad_chans == previous_bads) or iterations > max_iterations:\n            logger.info('Robust reference done')\n            self.noisy_channels = noisy\n            break\n        previous_bads = bad_chans.copy()\n        if raw_tmp.info['nchan'] - len(bad_chans) < 2:\n            raise ValueError('RobustReference:TooManyBad Could not perform a robust reference -- not enough good channels')\n        if len(bad_chans) > 0:\n            raw_tmp._data = signal.copy()\n            raw_tmp.info['bads'] = list(bad_chans)\n            if self.matlab_strict:\n                _eeglab_interpolate_bads(raw_tmp)\n            else:\n                raw_tmp.interpolate_bads()\n        self.reference_signal = np.nanmean(raw_tmp.get_data(picks=reference_channels), axis=0)\n        signal_tmp = self.remove_reference(signal, self.reference_signal, reference_index)\n        iterations = iterations + 1\n        logger.info(f'Iterations: {iterations}')\n    return (self.noisy_channels, self.reference_signal)", "metadata": {}}
{"_id": "pyprep_pyprep_reference.py_remove_reference_code", "title": "remove_reference", "text": "@staticmethod\ndef remove_reference(signal, reference, index=None):\n    \"\"\"Remove the reference signal from the original EEG signal.\n\n        This function implements the functionality of the `removeReference` function\n        as part of the PREP pipeline on mne raw object.\n\n        Parameters\n        ----------\n        signal : np.ndarray, shape(channels, times)\n            The original EEG signal.\n        reference : np.ndarray, shape(times,)\n            The reference signal.\n        index : {list, None}, optional\n            A list of channel indices from which the reference signal should be\n            subtracted. Defaults to all channels in `signal`.\n\n        Returns\n        -------\n        np.ndarray, shape(channels, times)\n            The referenced EEG signal.\n\n        \"\"\"\n    if np.ndim(signal) != 2:\n        raise ValueError('RemoveReference: EEG signal must be 2D array (channels * times)')\n    if np.ndim(reference) != 1:\n        raise ValueError('RemoveReference: Reference signal must be 1D array')\n    if np.shape(signal)[1] != np.shape(reference)[0]:\n        raise ValueError('RemoveReference: The second dimension of EEG signal must be the same with the length of reference signal')\n    if index is None:\n        signal_referenced = signal - reference\n    else:\n        if not isinstance(index, list):\n            raise TypeError(f'RemoveReference: Expected type list, got {type(index)} instead')\n        signal_referenced = signal.copy()\n        signal_referenced[np.asarray(index), :] = signal[np.asarray(index), :] - reference\n    return signal_referenced", "metadata": {}}
{"_id": "pyprep_pyprep_utils.py__union_code", "title": "_union", "text": "def _union(list1, list2):\n    return list(set(list1 + list2))", "metadata": {}}
{"_id": "pyprep_pyprep_utils.py__set_diff_code", "title": "_set_diff", "text": "def _set_diff(list1, list2):\n    return list(set(list1) - set(list2))", "metadata": {}}
{"_id": "pyprep_pyprep_utils.py__mat_round_code", "title": "_mat_round", "text": "def _mat_round(x):\n    \"\"\"Round a number to the nearest whole number.\n\n    Parameters\n    ----------\n    x : float\n        The number to round.\n\n    Returns\n    -------\n    rounded : float\n        The input value, rounded to the nearest whole number.\n\n    Notes\n    -----\n    MATLAB rounds all numbers ending in .5 up to the nearest integer, whereas\n    Python (and Numpy) rounds them to the nearest even number. This function\n    mimics MATLAB's behaviour.\n    \"\"\"\n    return np.ceil(x) if x % 1 >= 0.5 else np.floor(x)", "metadata": {}}
{"_id": "pyprep_pyprep_utils.py__mat_quantile_code", "title": "_mat_quantile", "text": "def _mat_quantile(arr, q, axis=None):\n    \"\"\"Calculate the numeric value at quantile (`q`) for a given distribution.\n\n    Parameters\n    ----------\n    arr : np.ndarray\n        Input array containing samples from the distribution to summarize. Must\n        be either a 1-D or 2-D array.\n    q : float\n        The quantile to calculate for the input data. Must be between 0 and 1,\n        inclusive.\n    axis : {int, tuple of int, None}, optional\n        Axis along which quantile values should be calculated. Defaults to\n        calculating the value at the given quantile for the entire array.\n\n    Returns\n    -------\n    quantile : scalar or np.ndarray\n        If no axis is specified, returns the value at quantile (q) for the full\n        input array as a single numeric value. Otherwise, returns an\n        ``np.ndarray`` containing the values at quantile (q) for each row along\n        the specified axis.\n\n    Notes\n    -----\n    MATLAB calculates quantiles using different logic than Numpy: Numpy treats\n    the provided values as a whole population, whereas MATLAB treats them as a\n    sample from a population of unknown size and adjusts quantiles accordingly.\n    This function mimics MATLAB's logic to produce identical results.\n\n    \"\"\"\n    if len(arr) == 0:\n        return np.nan\n    arr_sorted = np.sort(arr, axis=axis)\n    if arr_sorted.ndim > 2:\n        raise ValueError(f'Only 1D and 2D arrays are supported (input has {arr_sorted.ndim} dimensions)')\n    if axis is None:\n        arr_sorted = arr_sorted.reshape(-1, 1)\n    else:\n        arr_sorted = np.moveaxis(arr_sorted, axis, 0)\n    quantiles = arr_sorted[0, :]\n    n = np.sum(np.isfinite(arr_sorted), axis=0)\n    n_usable = n[n > 1]\n    if np.any(n > 1):\n        q = np.asarray(q, dtype=np.float64)\n        q_adj = (q - 0.5) * n_usable / (n_usable - 1) + 0.5\n        exact_idx = (n_usable - 1) * np.clip(q_adj, 0, 1)\n        pre_idx = np.floor(exact_idx).astype(np.int32)\n        post_idx = np.ceil(exact_idx).astype(np.int32)\n        axis_idx = np.arange(len(n))[n > 1]\n        pre = arr_sorted[pre_idx, axis_idx]\n        post = arr_sorted[post_idx, axis_idx]\n        quantiles[n > 1] = pre + (post - pre) * (exact_idx - pre_idx)\n    return quantiles[0] if quantiles.size == 1 else quantiles", "metadata": {}}
{"_id": "pyprep_pyprep_utils.py__mat_iqr_code", "title": "_mat_iqr", "text": "def _mat_iqr(arr, axis=None):\n    \"\"\"Calculate the inter-quartile range (IQR) for a given distribution.\n\n    Parameters\n    ----------\n    arr : np.ndarray\n        Input array containing samples from the distribution to summarize.\n    axis : {int, tuple of int, None}, optional\n        Axis along which IQRs should be calculated. Defaults to calculating the\n        IQR for the entire array.\n\n    Returns\n    -------\n    iqr : scalar or np.ndarray\n        If no axis is specified, returns the IQR for the full input array as a\n        single numeric value. Otherwise, returns an ``np.ndarray`` containing\n        the IQRs for each row along the specified axis.\n\n    Notes\n    -----\n    See notes for :func:`utils._mat_quantile`.\n\n    \"\"\"\n    return _mat_quantile(arr, 0.75, axis) - _mat_quantile(arr, 0.25, axis)", "metadata": {}}
{"_id": "pyprep_pyprep_utils.py__eeglab_create_highpass_code", "title": "_eeglab_create_highpass", "text": "def _eeglab_create_highpass(cutoff, srate):\n    \"\"\"Create a high-pass FIR filter using Hamming windows.\n\n    Parameters\n    ----------\n    cutoff : float\n        The lower pass-band edge of the filter, in Hz.\n    srate : float\n        The sampling rate of the EEG signal, in Hz.\n\n    Returns\n    -------\n    filter : np.ndarray\n        A 1-dimensional array of FIR filter coefficients.\n\n    Notes\n    -----\n    In MATLAB PREP, the internal ``removeTrend`` function uses EEGLAB's\n    ``pop_eegfiltnew`` to high-pass the EEG data to remove slow drifts.\n    Because MNE's ``mne.filter.filter_data`` and EEGLAB's ``pop_eegfiltnew``\n    calculate filter parameters slightly differently, this function is\n    used to precisely match EEGLAB & MATLAB PREP's filtering method.\n\n    \"\"\"\n    TRANSITION_WIDTH_RATIO = 0.25\n    HAMMING_CONSTANT = 3.3\n    trans_bandwidth = cutoff if cutoff < 2 else cutoff * TRANSITION_WIDTH_RATIO\n    order = HAMMING_CONSTANT / (trans_bandwidth / srate)\n    order = int(np.ceil(order / 2) * 2)\n    stop = cutoff - trans_bandwidth\n    transition = (stop + cutoff) / srate\n    N = order + 1\n    filt = np.zeros(N)\n    filt[N // 2] = 1\n    filt -= firwin(N, transition, window='hamming')\n    return filt", "metadata": {}}
{"_id": "pyprep_pyprep_utils.py__eeglab_fir_filter_code", "title": "_eeglab_fir_filter", "text": "def _eeglab_fir_filter(data, filt):\n    \"\"\"Apply an FIR filter to a 2-D array of EEG data.\n\n    Parameters\n    ----------\n    data : np.ndarray\n        A 2-D array of EEG data to filter.\n    filt : np.ndarray\n        A 1-D array of FIR filter coefficients.\n\n    Returns\n    -------\n    filtered : np.ndarray\n        A 2-D array of FIR-filtered EEG data.\n\n    Notes\n    -----\n    Produces identical output to EEGLAB's ``firfilt`` function (for non-epoched\n    data). For internal use within :mod:`pyprep.removeTrend`.\n\n    \"\"\"\n    frames_per_window = 2000\n    group_delay = int((len(filt) - 1) / 2)\n    n_samples = data.shape[1]\n    n_windows = int(np.ceil((n_samples - group_delay) / frames_per_window))\n    pad_len = min(group_delay, n_samples)\n    start_pad_idx = np.zeros(pad_len, dtype=np.uint)\n    start_padded = np.concatenate((data[:, start_pad_idx], data[:, :pad_len]), axis=1)\n    zi_init = lfilter_zi(filt, 1) * np.take(start_padded, [0], axis=0)\n    (_, zi) = lfilter(filt, 1, start_padded, axis=1, zi=zi_init)\n    out = np.zeros_like(data)\n    for w in range(n_windows):\n        start = group_delay + w * frames_per_window\n        end = min(start + frames_per_window, n_samples)\n        start_out = start - group_delay\n        end_out = end - group_delay\n        (out[:, start_out:end_out], zi) = lfilter(filt, 1, data[:, start:end], axis=1, zi=zi)\n    end_pad_idx = np.zeros(pad_len, dtype=np.uint) + (n_samples - 1)\n    (end, _) = lfilter(filt, 1, data[:, end_pad_idx], axis=1, zi=zi)\n    out[:, n_samples - pad_len:] = end[:, group_delay - pad_len:]\n    return out", "metadata": {}}
{"_id": "pyprep_pyprep_utils.py__eeglab_calc_g_code", "title": "_eeglab_calc_g", "text": "def _eeglab_calc_g(pos_from, pos_to, stiffness=4, num_lterms=7):\n    \"\"\"Calculate spherical spline g function between points on a sphere.\n\n    Parameters\n    ----------\n    pos_from : np.ndarray of float, shape(n_good_sensors, 3)\n        The electrode positions to interpolate from.\n    pos_to : np.ndarray of float, shape(n_bad_sensors, 3)\n        The electrode positions to interpolate.\n    stiffness : float\n        Stiffness of the spline.\n    num_lterms : int\n        Number of Legendre terms to evaluate.\n\n    Returns\n    -------\n    G : np.ndarray of float, shape(n_channels, n_channels)\n        The G matrix.\n\n    Notes\n    -----\n    Produces identical output to the private ``computeg`` function in EEGLAB's\n    ``eeg_interp.m``.\n\n    \"\"\"\n    n_to = pos_to.shape[0]\n    n_from = pos_from.shape[0]\n    dxyz = []\n    for i in range(0, 3):\n        d1 = np.repeat(pos_to[:, i], n_from).reshape((n_to, n_from))\n        d2 = np.repeat(pos_from[:, i], n_to).reshape((n_from, n_to)).T\n        dxyz.append((d1 - d2) ** 2)\n    elec_dists = np.sqrt(sum(dxyz))\n    EI = np.ones([n_to, n_from]) - elec_dists\n    factors = [0]\n    for n in range(1, num_lterms + 1):\n        f = (2 * n + 1) / (n ** stiffness * (n + 1) ** stiffness * 4 * np.pi)\n        factors.append(f)\n    return legval(EI, factors)", "metadata": {}}
{"_id": "pyprep_pyprep_utils.py__eeglab_interpolate_code", "title": "_eeglab_interpolate", "text": "def _eeglab_interpolate(data, pos_from, pos_to):\n    \"\"\"Interpolate bad channels using EEGLAB's custom method.\n\n    Parameters\n    ----------\n    data : np.ndarray\n        A 2-D array containing signals from currently-good EEG channels with\n        which to interpolate signals for bad channels.\n    pos_from : np.ndarray of float, shape(n_good_sensors, 3)\n        The electrode positions to interpolate from.\n    pos_to : np.ndarray of float, shape(n_bad_sensors, 3)\n        The electrode positions to interpolate.\n\n    Returns\n    -------\n    interpolated : np.ndarray\n        The interpolated signals for all bad channels.\n\n    Notes\n    -----\n    Produces identical output to the private ``spheric_spline`` function in\n    EEGLAB's ``eeg_interp.m`` (with minor rounding errors).\n\n    \"\"\"\n    G_from = _eeglab_calc_g(pos_from, pos_from)\n    G_to_from = _eeglab_calc_g(pos_from, pos_to)\n    avg_ref = np.mean(data, axis=0)\n    data_tmp = data - avg_ref\n    pad_ones = np.ones((1, pos_from.shape[0]))\n    C_inv = linalg.pinv(np.vstack([G_from, pad_ones]))\n    interp_mat = np.matmul(G_to_from, C_inv[:, :-1])\n    interpolated = np.matmul(interp_mat, data_tmp) + avg_ref\n    return interpolated", "metadata": {}}
{"_id": "pyprep_pyprep_utils.py__eeglab_interpolate_bads_code", "title": "_eeglab_interpolate_bads", "text": "def _eeglab_interpolate_bads(raw):\n    \"\"\"Interpolate bad channels using EEGLAB's custom method.\n\n    This method modifies the provided Raw object in place.\n\n    Parameters\n    ----------\n    raw : mne.io.Raw\n        An MNE Raw object for which channels marked as \"bad\" should be\n        interpolated.\n\n    Notes\n    -----\n    Produces identical results as EEGLAB's ``eeg_interp`` function when using\n    the default spheric spline method (with minor rounding errors). This method\n    appears to be loosely based on the same general Perrin et al. (1989) method\n    as MNE's interpolation, but there are several quirks with the implementation\n    that cause it to produce fairly different numbers.\n\n    \"\"\"\n    eeg_chans = np.array([idx for (idx, typ) in enumerate(raw.get_channel_types()) if typ == 'eeg'])\n    good_idx = np.array([idx for (idx, (ch, typ)) in enumerate(zip(raw.ch_names, raw.get_channel_types())) if typ == 'eeg' and ch not in raw.info['bads']])\n    bad_idx = sorted(_set_diff(eeg_chans, good_idx))\n    elec_pos = raw._get_channel_positions(picks=eeg_chans)\n    pos_good = elec_pos[good_idx, :].copy()\n    pos_bad = elec_pos[bad_idx, :].copy()\n    _normalize_vectors(pos_good)\n    _normalize_vectors(pos_bad)\n    interp = _eeglab_interpolate(raw.get_data()[good_idx, :], pos_good, pos_bad)\n    raw._data[bad_idx, :] = interp\n    eeg_bad_names = [raw.info['ch_names'][i] for i in bad_idx]\n    bads_non_eeg = _set_diff(raw.info['bads'], eeg_bad_names)\n    raw.info['bads'] = bads_non_eeg", "metadata": {}}
{"_id": "pyprep_pyprep_utils.py__get_random_subset_code", "title": "_get_random_subset", "text": "def _get_random_subset(x, size, rand_state):\n    \"\"\"Get a random subset of items from a list or array, without replacement.\n\n    Parameters\n    ----------\n    x : list or np.ndarray\n        One-dimensional array of items to sample from.\n    size : int\n        The number of items to sample. Must be less than the number of input\n        items.\n    rand_state : np.random.RandomState\n        A random state object to use for random number generation.\n\n    Returns\n    -------\n    sample : list\n        A random subset of the input items.\n\n    Notes\n    -----\n    This function generates random subsets identical to the internal\n    ``randsample`` function in MATLAB PREP's ``findNoisyChannels.m``, allowing\n    the same random seed to produce identical results across both PyPREP and\n    MATLAB PREP.\n\n    \"\"\"\n    sample = []\n    remaining = list(x)\n    for val in rand_state.rand(size):\n        index = round(1 + (len(remaining) - 1) * val) - 1\n        pick = remaining.pop(index)\n        sample.append(pick)\n    return sample", "metadata": {}}
{"_id": "pyprep_pyprep_utils.py__correlate_arrays_code", "title": "_correlate_arrays", "text": "def _correlate_arrays(a, b, matlab_strict=False):\n    \"\"\"Calculate correlations between two equally-sized 2-D arrays of EEG data.\n\n    Both input arrays must be in the shape (channels, samples).\n\n    Parameters\n    ----------\n    a : np.ndarray\n        A 2-D array to correlate with `a`.\n    b : np.ndarray\n        A 2-D array to correlate with `b`.\n    matlab_strict : bool, optional\n        Whether or not correlations should be calculated identically to MATLAB\n        PREP (i.e., without mean subtraction) instead of by traditional Pearson\n        product-moment correlation (see Notes for details). Defaults to\n        ``False`` (Pearson correlation).\n\n    Returns\n    -------\n    correlations : np.ndarray\n        A one-dimensional array containing the correlations of the two input arrays\n        along the second axis.\n\n    Notes\n    -----\n    In MATLAB PREP, RANSAC channel predictions are correlated with actual data\n    using a non-standard method: essentially, it uses the standard Pearson\n    correlation formula but without subtracting the channel means from each channel\n    before calculating sums of squares, i.e.,::\n\n       SSa = np.sum(a ** 2)\n       SSb = np.sum(b ** 2)\n       correlation = np.sum(a * b) / (np.sqrt(SSa) * np.sqrt(SSb))\n\n    Because EEG data is roughly mean-centered to begin with, this produces similar\n    values to normal Pearson correlation. However, to avoid making any assumptions\n    about the signal for any given channel/window, PyPREP defaults to normal\n    Pearson correlation unless strict MATLAB equivalence is requested.\n\n    \"\"\"\n    if matlab_strict:\n        SSa = np.sum(a ** 2, axis=1)\n        SSb = np.sum(b ** 2, axis=1)\n        SSab = np.sum(a * b, axis=1)\n        return SSab / (np.sqrt(SSa) * np.sqrt(SSb))\n    else:\n        n_chan = a.shape[0]\n        return np.diag(np.corrcoef(a, b)[:n_chan, n_chan:])", "metadata": {}}
{"_id": "pyprep_pyprep_utils.py__filter_design_code", "title": "_filter_design", "text": "def _filter_design(N_order, amp, freq):\n    \"\"\"Create FIR low-pass filter for EEG data using frequency sampling method.\n\n    Parameters\n    ----------\n    N_order : int\n        Order of the filter.\n    amp : list of int\n        Amplitude vector for the frequencies.\n    freq : list of int\n        Frequency vector for which amplitude can be either 0 or 1.\n\n    Returns\n    -------\n    kernel : np.ndarray\n        Filter kernel.\n\n    \"\"\"\n    nfft = np.maximum(512, 2 ** np.ceil(math.log(100) / math.log(2)))\n    hamming_window = np.subtract(0.54, np.multiply(0.46, np.cos(np.divide(np.multiply(2 * math.pi, np.arange(N_order + 1)), N_order))))\n    pchip_interpolate = scipy.interpolate.PchipInterpolator(np.round(np.multiply(nfft, freq)), amp)\n    freq = pchip_interpolate(np.arange(nfft + 1))\n    freq = np.multiply(freq, np.exp(np.divide(np.multiply(-(0.5 * N_order) * sqrt(-1) * math.pi, np.arange(nfft + 1)), nfft)))\n    kernel = np.real(np.fft.ifft(np.concatenate([freq, np.conj(freq[len(freq) - 2:0:-1])])))\n    kernel = np.multiply(kernel[0:N_order + 1], np.transpose(hamming_window[:]))\n    return kernel", "metadata": {}}
{"_id": "pyprep_pyprep_utils.py__split_list_code", "title": "_split_list", "text": "def _split_list(mylist, chunk_size):\n    \"\"\"Split list in chunks.\n\n    Parameters\n    ----------\n    my_list: list\n        list to split.\n    chunk_size: int\n        size of the lists returned.\n\n    Returns\n    -------\n    list\n        list of the chunked lists.\n\n    See: https://stackoverflow.com/a/312466/5201771\n    \"\"\"\n    return [mylist[offs:offs + chunk_size] for offs in range(0, len(mylist), chunk_size)]", "metadata": {}}
{"_id": "pyprep_pyprep_utils.py__verify_free_ram_code", "title": "_verify_free_ram", "text": "def _verify_free_ram(data, n_samples, n_channels, max_prop=0.95):\n    \"\"\"Check if enough memory is free to run RANSAC with the given parameters.\n\n    Parameters\n    ----------\n    data : np.ndarray\n        2-D EEG data\n    n_samples : int\n        Number of samples to use for computation of RANSAC.\n    n_channels : int\n        Number of channels to process per chunk.\n    max_prop : float\n        The maximum proportion of available memory that RANSAC is allowed to\n        use.\n\n    Raises\n    ------\n    MemoryError\n        If insufficient free memory to perform RANSAC with the given data and\n        parameters.\n\n    \"\"\"\n    available_gb = virtual_memory().available * 1e-09 * max_prop\n    needed_gb = data[0, :].nbytes * 1e-09 * n_samples * n_channels\n    if available_gb < needed_gb:\n        ram_diff = needed_gb - available_gb\n        raise MemoryError(f'For given data of shape {data.shape} and the requested number of {n_samples} samples, {ram_diff} GB of additional memory would be needed. You could close other programs, downsample the data, or reduce the number of requested samples.')", "metadata": {}}
{"_id": "pyprep_pyprep_ransac.py_find_bad_by_ransac_code", "title": "find_bad_by_ransac", "text": "def find_bad_by_ransac(data, sample_rate, complete_chn_labs, chn_pos, exclude, n_samples=50, sample_prop=0.25, corr_thresh=0.75, frac_bad=0.4, corr_window_secs=5.0, channel_wise=False, max_chunk_size=None, random_state=None, matlab_strict=False):\n    \"\"\"Detect channels that are not predicted well by other channels.\n\n    Here, a RANSAC approach (see [1]_, and a short discussion in [2]_) is\n    adopted to predict a \"clean EEG\" dataset. After identifying clean EEG\n    channels through the other methods, the clean EEG dataset is\n    constructed by repeatedly sampling a small subset of clean EEG channels\n    and interpolation the complete data. The median of all those\n    repetitions forms the clean EEG dataset. In a second step, the original\n    and the RANSAC-predicted data are correlated and channels, which do not\n    correlate well with themselves across the two datasets are considered\n    `bad_by_ransac`.\n\n    Parameters\n    ----------\n    data : np.ndarray\n        A 2-D array of detrended EEG data, with bad-by-flat and bad-by-NaN\n        channels removed.\n    sample_rate : float\n        The sample rate (in Hz) of the EEG data.\n    complete_chn_labs : array_like\n        Labels for all channels in `data`, in the same order as they appear\n        in `data`.\n    chn_pos : np.ndarray\n        3-D electrode coordinates for all channels in `data`, in the same order\n        as they appear in `data`.\n    exclude : list\n        Labels of channels to exclude as signal predictors during RANSAC\n        (i.e., channels already flagged as bad by metrics other than HF noise).\n    n_samples : int, optional\n        Number of random channel samples to use for RANSAC. Defaults to ``50``.\n    sample_prop : float, optional\n        Proportion of total channels to use for signal prediction per RANSAC\n        sample. This needs to be in the range [0, 1], where 0 would mean no\n        channels would be used and 1 would mean all channels would be used\n        (neither of which would be useful values). Defaults to ``0.25`` (e.g.,\n        16 channels per sample for a 64-channel dataset).\n    corr_thresh : float, optional\n        The minimum predicted vs. actual signal correlation for a channel to\n        be considered good within a given RANSAC window. Defaults to ``0.75``.\n    frac_bad : float, optional\n        The minimum fraction of bad (i.e., below-threshold) RANSAC windows for a\n        channel to be considered bad-by-RANSAC. Defaults to ``0.4``.\n    corr_window_secs : float, optional\n        The duration (in seconds) of each RANSAC correlation window. Defaults to\n        5 seconds.\n    channel_wise : bool, optional\n        Whether RANSAC should predict signals for chunks of channels over the\n        entire signal length (\"channel-wise RANSAC\", see `max_chunk_size`\n        parameter). If ``False``, RANSAC will instead predict signals for all\n        channels at once but over a number of smaller time windows instead of\n        over the entire signal length (\"window-wise RANSAC\"). Channel-wise\n        RANSAC generally has higher RAM demands than window-wise RANSAC\n        (especially if `max_chunk_size` is ``None``), but can be faster on\n        systems with lots of RAM to spare. Defaults to ``False``.\n    max_chunk_size : {int, None}, optional\n        The maximum number of channels to predict at once during channel-wise\n        RANSAC. If ``None``, RANSAC will use the largest chunk size that will\n        fit into the available RAM, which may slow down other programs on the\n        host system. If using window-wise RANSAC (the default), this parameter\n        has no effect. Defaults to ``None``.\n    random_state : {int, None, np.random.RandomState}, optional\n        The random seed with which to generate random samples of channels during\n        RANSAC. If random_state is an int, it will be used as a seed for RandomState.\n        If ``None``, the seed will be obtained from the operating system\n        (see RandomState for details). Defaults to ``None``.\n    matlab_strict : bool, optional\n        Whether or not RANSAC should strictly follow MATLAB PREP's internal\n        math, ignoring any improvements made in PyPREP over the original code\n        (see :ref:`matlab-diffs` for more details). Defaults to ``False``.\n\n    Returns\n    -------\n    bad_by_ransac : list\n        List containing the labels of all channels flagged as bad by RANSAC.\n    channel_correlations : np.ndarray\n        Array of shape (windows, channels) containing the correlations of\n        the channels with their predicted RANSAC values for each window.\n\n    References\n    ----------\n    .. [1] Fischler, M.A., Bolles, R.C. (1981). Random sample consensus: A\n        Paradigm for Model Fitting with Applications to Image Analysis and\n        Automated Cartography. Communications of the ACM, 24, 381-395\n    .. [2] Jas, M., Engemann, D.A., Bekhti, Y., Raimondo, F., Gramfort, A.\n        (2017). Autoreject: Automated Artifact Rejection for MEG and EEG\n        Data. NeuroImage, 159, 417-429\n\n    \"\"\"\n    if np.isnan(chn_pos).any():\n        raise ValueError('Found NaN in channel positions. Did you supply a montage for the raw data?')\n    if not isinstance(n_samples, int):\n        raise TypeError(f\"Argument 'n_samples' must be an int (got {type(n_samples).__name__})\")\n    complete_chn_labs = np.asarray(complete_chn_labs)\n    good_idx = np.array([idx for (idx, ch) in enumerate(complete_chn_labs) if ch not in exclude])\n    n_chans_good = good_idx.shape[0]\n    chn_pos_good = chn_pos[good_idx, :]\n    n_chans = data.shape[0]\n    n_pred_chns = int(np.around(sample_prop * n_chans))\n    if n_pred_chns <= 3:\n        sample_pct = int(sample_prop * 100)\n        raise OSError(f'Too few channels in the original data to reliably perform RANSAC(minimum {int(np.floor(4.0 / sample_prop))} for a sample size of {sample_pct}%).')\n    elif n_chans_good < n_pred_chns + 1:\n        raise OSError(f'Too many noisy channels in the data to reliably perform RANSAC (only {n_chans_good} good channels remaining, need at least {n_pred_chns + 1}).')\n    if channel_wise:\n        _verify_free_ram(data, n_samples, 1)\n    else:\n        window_size = int(sample_rate * corr_window_secs)\n        _verify_free_ram(data[:, :window_size], n_samples, n_chans_good)\n    random_ch_picks = []\n    good_chans = np.arange(chn_pos_good.shape[0])\n    rng = check_random_state(random_state)\n    for i in range(n_samples):\n        picks = _get_random_subset(good_chans, n_pred_chns, rng)\n        random_ch_picks.append(picks)\n    interp_mats = _make_interpolation_matrices(random_ch_picks, chn_pos_good)\n    correlation_frames = corr_window_secs * sample_rate\n    signal_frames = data.shape[1]\n    correlation_offsets = np.arange(0, signal_frames - correlation_frames, correlation_frames)\n    win_size = int(correlation_frames)\n    win_count = correlation_offsets.shape[0]\n    n_chans_complete = len(complete_chn_labs)\n    channel_correlations = np.ones((win_count, n_chans_complete))\n    logger.info('Executing RANSAC\\nThis may take a while, so be patient...')\n    if not channel_wise:\n        channel_correlations[:, good_idx] = _ransac_by_window(data[good_idx, :], interp_mats, win_size, win_count, matlab_strict)\n    chunk_sizes = []\n    chunk_count = 0\n    for i in range(1, n_chans_good + 1):\n        n_chunks = int(np.ceil(n_chans_good / i))\n        if n_chunks != chunk_count:\n            chunk_count = n_chunks\n            if not max_chunk_size or i <= max_chunk_size:\n                chunk_sizes.append(i)\n    chunk_size = chunk_sizes.pop()\n    mem_error = True\n    job = list(range(n_chans_good))\n    while mem_error and channel_wise:\n        try:\n            channel_chunks = _split_list(job, chunk_size)\n            total_chunks = len(channel_chunks)\n            current = 1\n            for chunk in channel_chunks:\n                interp_mats_for_chunk = [mat[chunk, :] for mat in interp_mats]\n                channel_correlations[:, good_idx[chunk]] = _ransac_by_channel(data[good_idx, :], interp_mats_for_chunk, win_size, win_count, chunk, random_ch_picks, matlab_strict)\n                if chunk == channel_chunks[0]:\n                    logger.info('Finding optimal chunk size : %s', chunk_size)\n                    logger.info('Total # of chunks: %s', total_chunks)\n                    logger.info('Current chunk:')\n                logger.info(current)\n                current = current + 1\n            mem_error = False\n            del current\n        except MemoryError:\n            if len(chunk_sizes):\n                chunk_size = chunk_sizes.pop()\n            else:\n                raise MemoryError('Not even doing 1 channel at a time the data fits in ram...You could downsample the data or reduce the number of requested samples.')\n    thresholded_correlations = channel_correlations < corr_thresh\n    frac_bad_corr_windows = np.mean(thresholded_correlations, axis=0)\n    bad_ransac_channels_idx = np.argwhere(frac_bad_corr_windows > frac_bad)\n    bad_ransac_channels_name = complete_chn_labs[bad_ransac_channels_idx.astype(int)]\n    bad_by_ransac = [i[0] for i in bad_ransac_channels_name]\n    logger.info('\\nRANSAC done!')\n    return (bad_by_ransac, channel_correlations)", "metadata": {}}
{"_id": "pyprep_pyprep_ransac.py__make_interpolation_matrices_code", "title": "_make_interpolation_matrices", "text": "def _make_interpolation_matrices(random_ch_picks, chn_pos_good):\n    \"\"\"Create an interpolation matrix for each RANSAC sample of channels.\n\n    This function takes the spatial coordinates of random subsets of currently-good\n    channels and uses them to predict what the signal will be at the spatial\n    coordinates of all other currently-good channels. The results of this process are\n    returned as matrices that can be multiplied with EEG data to generate predicted\n    signals.\n\n    Parameters\n    ----------\n    random_ch_picks : list of list of int\n        A list containing multiple random subsets of currently-good channels.\n    chn_pos_good : np.ndarray\n        3-D spatial coordinates of all currently-good channels.\n\n    Returns\n    -------\n    interpolation_mats : list of np.ndarray\n        A list of interpolation matrices, one for each random subset of channels.\n        Each matrix has the shape `[num_good_channels, num_good_channels]`, with the\n        number of good channels being inferred from the size of `ch_pos_good`.\n\n    Notes\n    -----\n    This function currently makes use of a private MNE function,\n    ``mne.channels.interpolation._make_interpolation_matrix``, to generate matrices.\n\n    \"\"\"\n    n_chans_good = chn_pos_good.shape[0]\n    interpolation_mats = []\n    for sample in random_ch_picks:\n        mat = np.zeros((n_chans_good, n_chans_good))\n        subset_pos = chn_pos_good[sample, :]\n        mat[:, sample] = _make_interpolation_matrix(subset_pos, chn_pos_good)\n        interpolation_mats.append(mat)\n    return interpolation_mats", "metadata": {}}
{"_id": "pyprep_pyprep_ransac.py__ransac_by_window_code", "title": "_ransac_by_window", "text": "def _ransac_by_window(data, interpolation_mats, win_size, win_count, matlab_strict):\n    \"\"\"Calculate correlations of channels with their RANSAC-predicted values.\n\n    This function calculates RANSAC correlations for each RANSAC window\n    individually, requiring RAM equivalent to [channels * sample rate * seconds\n    per RANSAC window] to run. Generally, this method will use less RAM than\n    :func:`_ransac_by_channel`, with the exception of short recordings with high\n    electrode counts.\n\n    Parameters\n    ----------\n    data : np.ndarray\n        A 2-D array containing the EEG signals from all currently-good channels.\n    interpolation_mats : list of np.ndarray\n        A list of interpolation matrices, one for each RANSAC sample of channels.\n    win_size : int\n        Number of frames/samples of EEG data in each RANSAC correlation window.\n    win_count: int\n        Number of RANSAC correlation windows.\n    matlab_strict : bool\n        Whether or not RANSAC should strictly follow MATLAB PREP's internal\n        math, ignoring any improvements made in PyPREP over the original code.\n\n    Returns\n    -------\n    correlations : np.ndarray\n        Correlations of the given channels to their predicted values within each\n        RANSAC window.\n\n    \"\"\"\n    ch_count = data.shape[0]\n    correlations = np.ones((win_count, ch_count))\n    pb = ProgressBar(range(win_count))\n    for window in pb:\n        start = window * win_size\n        end = (window + 1) * win_size\n        actual = data[:, start:end]\n        predicted = _predict_median_signals(actual, interpolation_mats, matlab_strict)\n        correlations[window, :] = _correlate_arrays(actual, predicted, matlab_strict)\n    return correlations", "metadata": {}}
{"_id": "pyprep_pyprep_ransac.py__predict_median_signals_code", "title": "_predict_median_signals", "text": "def _predict_median_signals(window, interpolation_mats, matlab_strict=False):\n    \"\"\"Calculate the median RANSAC-predicted signal for a given window of data.\n\n    Parameters\n    ----------\n    window : np.ndarray\n        A 2-D window of EEG data with the shape `[channels, samples]`.\n    interpolation_mats : list of np.ndarray\n        A set of channel interpolation matrices, one for each RANSAC sample of\n        channels.\n    matlab_strict : bool\n        Whether or not RANSAC should strictly follow MATLAB PREP's internal\n        math, ignoring any improvements made in PyPREP over the original code.\n\n    Returns\n    -------\n    predicted : np.ndarray\n        The median RANSAC-predicted EEG signal for the given window of data.\n\n    Notes\n    -----\n    In MATLAB PREP, the median signal is calculated by sorting the different\n    predictions for each EEG sample/channel from low to high and then taking the value\n    at the middle index (as calculated by ``int(n_ransac_samples / 2.0)``) for each.\n    Because this logic only returns the correct result for odd numbers of samples, the\n    current function will instead return the true median signal across predictions\n    unless strict MATLAB equivalence is requested.\n\n    \"\"\"\n    ransac_samples = len(interpolation_mats)\n    merged_mats = np.concatenate(interpolation_mats, axis=0)\n    predictions_per_sample = np.reshape(np.matmul(merged_mats, window), (ransac_samples, window.shape[0], window.shape[1]))\n    if matlab_strict:\n        median_idx = int(_mat_round(ransac_samples / 2.0) - 1)\n        predictions_per_sample.sort(axis=0)\n        return predictions_per_sample[median_idx, :, :]\n    else:\n        return np.median(predictions_per_sample, axis=0)", "metadata": {}}
{"_id": "pyprep_pyprep_ransac.py__ransac_by_channel_code", "title": "_ransac_by_channel", "text": "def _ransac_by_channel(data, interpolation_mats, win_size, win_count, chans_to_predict, random_ch_picks, matlab_strict):\n    \"\"\"Calculate correlations of channels with their RANSAC-predicted values.\n\n    This function calculates RANSAC correlations on one (or more) full channels\n    at once, requiring RAM equivalent to [channels per chunk * sample rate *\n    length of recording in seconds] to run. Generally, this method will use\n    more RAM than :func:`_ransac_by_window`, but may be faster for systems with\n    large amounts of RAM.\n\n    Parameters\n    ----------\n    data : np.ndarray\n        A 2-D array containing the EEG signals from all currently-good channels.\n    interpolation_mats : list of np.ndarray\n        A set of channel interpolation matrices, one for each RANSAC sample of\n        channels.\n    win_size : int\n        Number of frames/samples of EEG data in each RANSAC correlation window.\n    win_count: int\n        Number of RANSAC correlation windows.\n    chans_to_predict : list of int\n        Indices of the channels to predict (as they appear in `data`) within the\n        current chunk.\n    random_ch_picks : list of list of int\n        A list containing multiple random subsets of currently-good channels.\n    matlab_strict : bool\n        Whether or not RANSAC should strictly follow MATLAB PREP's internal\n        math, ignoring any improvements made in PyPREP over the original code.\n\n    Returns\n    -------\n    correlations : np.ndarray\n        Correlations of the given channels to their predicted values within each\n        RANSAC window.\n\n    \"\"\"\n    chunk_size = len(chans_to_predict)\n    correlations = np.ones((win_count, chunk_size))\n    predicted_chans = _predict_median_signals_channelwise(data=data, interpolation_mats=interpolation_mats, random_ch_picks=random_ch_picks, chunk_size=len(chans_to_predict), matlab_strict=matlab_strict)\n    data_window = data[chans_to_predict, :win_size * win_count]\n    data_window = data_window.reshape(chunk_size, win_count, win_size)\n    data_window = data_window.swapaxes(1, 0)\n    pred_window = predicted_chans[:chunk_size, :win_size * win_count]\n    pred_window = pred_window.reshape(chunk_size, win_count, win_size)\n    pred_window = pred_window.swapaxes(1, 0)\n    for k in range(win_count):\n        data_portion = data_window[k, :, :]\n        pred_portion = pred_window[k, :, :]\n        R = _correlate_arrays(data_portion, pred_portion, matlab_strict)\n        correlations[k, :] = R\n    return correlations", "metadata": {}}
{"_id": "pyprep_pyprep_ransac.py__predict_median_signals_channelwise_code", "title": "_predict_median_signals_channelwise", "text": "def _predict_median_signals_channelwise(data, interpolation_mats, random_ch_picks, chunk_size, matlab_strict):\n    \"\"\"Calculate the median RANSAC-predicted signal for a given chunk of channels.\n\n    Parameters\n    ----------\n    data : np.ndarray\n        A 2-D array containing the EEG signals from all currently-good channels.\n    interpolation_mats : list of np.ndarray\n        A set of channel interpolation matrices, one for each RANSAC sample of\n        channels.\n    random_ch_picks : list of list of int\n        A list containing multiple random subsets of currently-good channels.\n    chunk_size : int\n        The number of channels to predict in the current chunk.\n    matlab_strict : bool\n        Whether or not RANSAC should strictly follow MATLAB PREP's internal\n        math, ignoring any improvements made in PyPREP over the original code.\n\n    Returns\n    -------\n    predicted_chans : np.ndarray\n        The median RANSAC-predicted EEG signals for the given chunk of channels.\n\n    \"\"\"\n    ransac_samples = len(interpolation_mats)\n    n_timepts = data.shape[1]\n    _verify_free_ram(data, ransac_samples, chunk_size)\n    eeg_predictions = np.zeros((chunk_size, n_timepts, ransac_samples))\n    for sample in range(ransac_samples):\n        reconstr_idx = random_ch_picks[sample]\n        interp_mat = interpolation_mats[sample][:, reconstr_idx]\n        eeg_predictions[..., sample] = np.matmul(interp_mat, data[reconstr_idx, :])\n    if matlab_strict:\n        median_idx = int(_mat_round(ransac_samples / 2.0) - 1)\n        eeg_predictions.sort(axis=-1)\n        return eeg_predictions[:, :, median_idx]\n    else:\n        return np.median(eeg_predictions, axis=-1, overwrite_input=True)", "metadata": {}}
{"_id": "pyprep_pyprep_find_noisy_channels.py___init___code", "title": "__init__", "text": "def __init__(self, raw, do_detrend=True, random_state=None, matlab_strict=False):\n    assert isinstance(raw, mne.io.BaseRaw)\n    raw.load_data()\n    self.raw_mne = raw.copy()\n    self.bad_by_manual = raw.info['bads']\n    self.raw_mne.pick('eeg')\n    self.sample_rate = raw.info['sfreq']\n    if do_detrend:\n        self.raw_mne._data = removeTrend(self.raw_mne.get_data(), self.sample_rate, matlab_strict=matlab_strict)\n    self.matlab_strict = matlab_strict\n    self._extra_info = {'bad_by_deviation': {}, 'bad_by_hf_noise': {}, 'bad_by_correlation': {}, 'bad_by_dropout': {}, 'bad_by_ransac': {}}\n    self.random_state = check_random_state(random_state)\n    self.bad_by_nan = []\n    self.bad_by_flat = []\n    self.bad_by_deviation = []\n    self.bad_by_hf_noise = []\n    self.bad_by_correlation = []\n    self.bad_by_SNR = []\n    self.bad_by_dropout = []\n    self.bad_by_ransac = []\n    ch_names = np.asarray(self.raw_mne.info['ch_names'])\n    self.ch_names_original = ch_names\n    self.n_chans_original = len(ch_names)\n    self.n_samples = raw.get_data().shape[1]\n    self.find_bad_by_nan_flat()\n    bads_by_nan_flat = self.bad_by_nan + self.bad_by_flat\n    self.usable_idx = np.isin(ch_names, bads_by_nan_flat, invert=True)\n    self.EEGData = self.raw_mne.get_data(picks=ch_names[self.usable_idx])\n    self.EEGFiltered = None\n    self.ch_names_new = np.asarray(ch_names[self.usable_idx])\n    self.n_chans_new = len(self.ch_names_new)", "metadata": {}}
{"_id": "pyprep_pyprep_find_noisy_channels.py__get_filtered_data_code", "title": "_get_filtered_data", "text": "def _get_filtered_data(self):\n    \"\"\"Apply a [1 Hz - 50 Hz] bandpass filter to the EEG signal.\n\n        Only applied if the sample rate is above 100 Hz to avoid violating the\n        Nyquist theorem.\n\n        \"\"\"\n    if self.sample_rate <= 100:\n        return self.EEGData.copy()\n    bandpass_filter = _filter_design(N_order=100, amp=np.array([1, 1, 0, 0]), freq=np.array([0, 90 / self.sample_rate, 100 / self.sample_rate, 1]))\n    EEG_filt = np.zeros_like(self.EEGData)\n    for i in range(EEG_filt.shape[0]):\n        EEG_filt[i, :] = signal.filtfilt(bandpass_filter, 1, self.EEGData[i, :])\n    return EEG_filt", "metadata": {}}
{"_id": "pyprep_pyprep_find_noisy_channels.py_get_bads_code", "title": "get_bads", "text": "def get_bads(self, verbose=False, as_dict=False):\n    \"\"\"Get the names of all channels currently flagged as bad.\n\n        Note that this method does not perform any bad channel detection itself,\n        and only reports channels already detected as bad by other methods.\n\n        Parameters\n        ----------\n        verbose : bool, optional\n            If ``True``, a summary of the channels currently flagged as by bad per\n            category is printed. Defaults to ``False``.\n        as_dict: bool, optional\n            If ``True``, this method will return a dict of the channels currently\n            flagged as bad by each individual bad channel type. If ``False``, this\n            method will return a list of all unique bad channels detected so far.\n            Defaults to ``False``.\n\n        Returns\n        -------\n        bads : list or dict\n            The names of all bad channels detected so far, either as a combined\n            list or a dict indicating the channels flagged bad by each type.\n\n        \"\"\"\n    bads = {'bad_by_nan': self.bad_by_nan, 'bad_by_flat': self.bad_by_flat, 'bad_by_deviation': self.bad_by_deviation, 'bad_by_hf_noise': self.bad_by_hf_noise, 'bad_by_correlation': self.bad_by_correlation, 'bad_by_SNR': self.bad_by_SNR, 'bad_by_dropout': self.bad_by_dropout, 'bad_by_ransac': self.bad_by_ransac, 'bad_by_manual': self.bad_by_manual}\n    all_bads = set()\n    for bad_chs in bads.values():\n        all_bads.update(bad_chs)\n    name_map = {'nan': 'NaN', 'hf_noise': 'HF noise', 'ransac': 'RANSAC'}\n    if verbose:\n        out = f'Found {len(all_bads)} uniquely bad channels:\\n'\n        for (bad_type, bad_chs) in bads.items():\n            bad_type = bad_type.replace('bad_by_', '')\n            if bad_type in name_map.keys():\n                bad_type = name_map[bad_type]\n            out += f'\\n{len(bad_chs)} by {bad_type}: {bad_chs}\\n'\n        logger.info(out)\n    if as_dict:\n        bads['bad_all'] = list(all_bads)\n    else:\n        bads = list(all_bads)\n    return bads", "metadata": {}}
{"_id": "pyprep_pyprep_find_noisy_channels.py_find_all_bads_code", "title": "find_all_bads", "text": "def find_all_bads(self, ransac=True, channel_wise=False, max_chunk_size=None):\n    \"\"\"Call all the functions to detect bad channels.\n\n        This function calls all the bad-channel detecting functions.\n\n        Parameters\n        ----------\n        ransac : bool, optional\n            Whether RANSAC should be used for bad channel detection, in addition\n            to the other methods. RANSAC can detect bad channels that other\n            methods are unable to catch, but also slows down noisy channel\n            detection considerably. Defaults to ``True``.\n        channel_wise : bool, optional\n            Whether RANSAC should predict signals for chunks of channels over the\n            entire signal length (\"channel-wise RANSAC\", see `max_chunk_size`\n            parameter). If ``False``, RANSAC will instead predict signals for all\n            channels at once but over a number of smaller time windows instead of\n            over the entire signal length (\"window-wise RANSAC\"). Channel-wise\n            RANSAC generally has higher RAM demands than window-wise RANSAC\n            (especially if `max_chunk_size` is ``None``), but can be faster on\n            systems with lots of RAM to spare. Has no effect if not using RANSAC.\n            Defaults to ``False``.\n        max_chunk_size : {int, None}, optional\n            The maximum number of channels to predict at once during\n            channel-wise RANSAC. If ``None``, RANSAC will use the largest chunk\n            size that will fit into the available RAM, which may slow down\n            other programs on the host system. If using window-wise RANSAC\n            (the default) or not using RANSAC at all, this parameter has no\n            effect. Defaults to ``None``.\n\n        \"\"\"\n    self.find_bad_by_deviation()\n    self.find_bad_by_hfnoise()\n    self.find_bad_by_correlation()\n    self.find_bad_by_SNR()\n    if ransac:\n        self.find_bad_by_ransac(channel_wise=channel_wise, max_chunk_size=max_chunk_size)", "metadata": {}}
{"_id": "pyprep_pyprep_find_noisy_channels.py_find_bad_by_nan_flat_code", "title": "find_bad_by_nan_flat", "text": "def find_bad_by_nan_flat(self, flat_threshold=1e-15):\n    \"\"\"Detect channels than contain NaN values or have near-flat signals.\n\n        A channel is considered flat if its standard deviation or its median\n        absolute deviation from the median (MAD) are below the provided flat\n        threshold (default: ``1e-15`` volts).\n\n        This method is run automatically when a ``NoisyChannels`` object is\n        initialized, preventing flat or NaN-containing channels from interfering\n        with the detection of other types of bad channels.\n\n        Parameters\n        ----------\n        flat_threshold : float, optional\n            The lowest standard deviation or MAD value for a channel to be\n            considered bad-by-flat. Defaults to ``1e-15`` volts (corresponds to\n            10e-10 \u00b5V in MATLAB PREP).\n        \"\"\"\n    EEGData = self.raw_mne.get_data()\n    nan_channel_mask = np.isnan(np.sum(EEGData, axis=1))\n    nan_channels = self.ch_names_original[nan_channel_mask]\n    flat_by_mad = median_abs_deviation(EEGData, axis=1) < flat_threshold\n    flat_by_stdev = np.std(EEGData, axis=1) < flat_threshold\n    flat_channel_mask = flat_by_mad | flat_by_stdev\n    flat_channels = self.ch_names_original[flat_channel_mask]\n    self.bad_by_nan = nan_channels.tolist()\n    self.bad_by_flat = flat_channels.tolist()", "metadata": {}}
{"_id": "pyprep_pyprep_find_noisy_channels.py_find_bad_by_deviation_code", "title": "find_bad_by_deviation", "text": "def find_bad_by_deviation(self, deviation_threshold=5.0):\n    \"\"\"Detect channels with abnormally high or low overall amplitudes.\n\n        A channel is considered \"bad-by-deviation\" if its amplitude deviates\n        considerably from the median channel amplitude, as calculated using a\n        robust Z-scoring method and the given deviation threshold.\n\n        Amplitude Z-scores are calculated using the formula\n        ``(channel_amplitude - median_amplitude) / amplitude_sd``, where\n        channel amplitudes are calculated using a robust outlier-resistant estimate\n        of the signals' standard deviations (IQR scaled to units of SD), and the\n        amplitude SD is the IQR-based SD of those amplitudes.\n\n        Parameters\n        ----------\n        deviation_threshold : float, optional\n            The minimum absolute z-score of a channel for it to be considered\n            bad-by-deviation. Defaults to ``5.0``.\n\n        \"\"\"\n    IQR_TO_SD = 0.7413\n    chan_amplitudes = _mat_iqr(self.EEGData, axis=1) * IQR_TO_SD\n    amp_sd = _mat_iqr(chan_amplitudes) * IQR_TO_SD\n    amp_median = np.nanmedian(chan_amplitudes)\n    amplitude_zscore = np.zeros(self.n_chans_original)\n    amplitude_zscore[self.usable_idx] = (chan_amplitudes - amp_median) / amp_sd\n    abnormal_amplitude = np.abs(amplitude_zscore) > deviation_threshold\n    deviation_channel_mask = np.isnan(amplitude_zscore) | abnormal_amplitude\n    deviation_channels = self.ch_names_original[deviation_channel_mask]\n    self.bad_by_deviation = deviation_channels.tolist()\n    self._extra_info['bad_by_deviation'].update({'median_channel_amplitude': amp_median, 'channel_amplitude_sd': amp_sd, 'robust_channel_deviations': amplitude_zscore})", "metadata": {}}
{"_id": "pyprep_pyprep_find_noisy_channels.py_find_bad_by_hfnoise_code", "title": "find_bad_by_hfnoise", "text": "def find_bad_by_hfnoise(self, HF_zscore_threshold=5.0):\n    \"\"\"Detect channels with abnormally high amounts of high-frequency noise.\n\n        The noisiness of a channel is defined as the amplitude of its\n        high-frequency (>50 Hz) components divided by its overall amplitude.\n        A channel is considered \"bad-by-high-frequency-noise\" if its noisiness\n        is considerably higher than the median channel noisiness, as determined\n        by a robust Z-scoring method and the given Z-score threshold.\n\n        Due to the Nyquist theorem, this method will only attempt bad channel\n        detection if the sample rate of the given signal is above 100 Hz.\n\n        Parameters\n        ----------\n        HF_zscore_threshold : float, optional\n            The minimum noisiness z-score of a channel for it to be considered\n            bad-by-high-frequency-noise. Defaults to ``5.0``.\n\n        \"\"\"\n    MAD_TO_SD = 1.4826\n    if self.EEGFiltered is None:\n        self.EEGFiltered = self._get_filtered_data()\n    (noise_median, noise_sd) = (0, 1)\n    noise_zscore = np.zeros(self.n_chans_original)\n    if self.sample_rate > 100:\n        noisiness = np.divide(median_abs_deviation(self.EEGData - self.EEGFiltered, axis=1), median_abs_deviation(self.EEGFiltered, axis=1))\n        noise_median = np.nanmedian(noisiness)\n        noise_sd = np.median(np.abs(noisiness - noise_median)) * MAD_TO_SD\n        noise_zscore[self.usable_idx] = (noisiness - noise_median) / noise_sd\n    hf_mask = np.isnan(noise_zscore) | (noise_zscore > HF_zscore_threshold)\n    hf_noise_channels = self.ch_names_original[hf_mask]\n    self.bad_by_hf_noise = hf_noise_channels.tolist()\n    self._extra_info['bad_by_hf_noise'].update({'median_channel_noisiness': noise_median, 'channel_noisiness_sd': noise_sd, 'hf_noise_zscores': noise_zscore})", "metadata": {}}
{"_id": "pyprep_pyprep_find_noisy_channels.py_find_bad_by_correlation_code", "title": "find_bad_by_correlation", "text": "def find_bad_by_correlation(self, correlation_secs=1.0, correlation_threshold=0.4, frac_bad=0.01):\n    \"\"\"Detect channels that sometimes don't correlate with any other channels.\n\n        Channel correlations are calculated by splitting the recording into\n        non-overlapping windows of time (default: 1 second), getting the absolute\n        correlations of each usable channel with every other usable channel for\n        each window, and then finding the highest correlation each channel has\n        with another channel for each window (by taking the 98th percentile of\n        the absolute correlations).\n\n        A correlation window is considered \"bad\" for a channel if its maximum\n        correlation with another channel is below the provided correlation\n        threshold (default: ``0.4``). A channel is considered \"bad-by-correlation\"\n        if its fraction of bad correlation windows is above the bad fraction\n        threshold (default: ``0.01``).\n\n        This method also detects channels with intermittent dropouts (i.e.,\n        regions of flat signal). A channel is considered \"bad-by-dropout\" if\n        its fraction of correlation windows with a completely flat signal is\n        above the bad fraction threshold (default: ``0.01``).\n\n        Parameters\n        ----------\n        correlation_secs : float, optional\n            The length (in seconds) of each correlation window. Defaults to ``1.0``.\n        correlation_threshold : float, optional\n            The lowest maximum inter-channel correlation for a channel to be\n            considered \"bad\" within a given window. Defaults to ``0.4``.\n        frac_bad : float, optional\n            The minimum proportion of bad windows for a channel to be considered\n            \"bad-by-correlation\" or \"bad-by-dropout\". Defaults to ``0.01`` (1% of\n            all windows).\n\n        \"\"\"\n    IQR_TO_SD = 0.7413\n    if self.EEGFiltered is None:\n        self.EEGFiltered = self._get_filtered_data()\n    win_size = int(correlation_secs * self.sample_rate)\n    win_offsets = np.arange(1, self.n_samples - win_size, win_size)\n    win_count = len(win_offsets)\n    max_correlations = np.ones((win_count, self.n_chans_original))\n    dropout = np.zeros((win_count, self.n_chans_original), dtype=bool)\n    noiselevels = np.zeros((win_count, self.n_chans_original))\n    channel_amplitudes = np.zeros((win_count, self.n_chans_original))\n    for w in range(win_count):\n        (start, end) = (w * win_size, (w + 1) * win_size)\n        eeg_filtered = self.EEGFiltered[:, start:end]\n        eeg_raw = self.EEGData[:, start:end]\n        usable = self.usable_idx.copy()\n        channel_amplitudes[w, usable] = _mat_iqr(eeg_raw, axis=1) * IQR_TO_SD\n        eeg_amplitude = median_abs_deviation(eeg_filtered, axis=1)\n        dropout[w, usable] = eeg_amplitude == 0\n        usable[usable] = eeg_amplitude > 0\n        eeg_raw = eeg_raw[eeg_amplitude > 0, :]\n        eeg_filtered = eeg_filtered[eeg_amplitude > 0, :]\n        eeg_amplitude = eeg_amplitude[eeg_amplitude > 0]\n        high_freq_amplitude = median_abs_deviation(eeg_raw - eeg_filtered, axis=1)\n        noiselevels[w, usable] = high_freq_amplitude / eeg_amplitude\n        win_correlations = np.corrcoef(eeg_filtered)\n        abs_corr = np.abs(win_correlations - np.diag(np.diag(win_correlations)))\n        max_correlations[w, usable] = _mat_quantile(abs_corr, 0.98, axis=0)\n        max_correlations[w, dropout[w, :]] = 0\n    thresholded_correlations = max_correlations < correlation_threshold\n    fraction_bad_corr_windows = np.mean(thresholded_correlations, axis=0)\n    bad_correlation_mask = fraction_bad_corr_windows > frac_bad\n    bad_correlation_channels = self.ch_names_original[bad_correlation_mask]\n    fraction_dropout_windows = np.mean(dropout, axis=0)\n    dropout_mask = fraction_dropout_windows > frac_bad\n    dropout_channels = self.ch_names_original[dropout_mask]\n    self.bad_by_correlation = bad_correlation_channels.tolist()\n    self.bad_by_dropout = dropout_channels.tolist()\n    self._extra_info['bad_by_correlation'] = {'max_correlations': np.transpose(max_correlations), 'median_max_correlations': np.median(max_correlations, axis=0), 'bad_window_fractions': fraction_bad_corr_windows}\n    self._extra_info['bad_by_dropout'] = {'dropouts': np.transpose(dropout.astype(np.int8)), 'bad_window_fractions': fraction_dropout_windows}\n    self._extra_info['bad_by_deviation']['channel_amplitudes'] = channel_amplitudes\n    self._extra_info['bad_by_hf_noise']['noise_levels'] = noiselevels", "metadata": {}}
{"_id": "pyprep_pyprep_find_noisy_channels.py_find_bad_by_SNR_code", "title": "find_bad_by_SNR", "text": "def find_bad_by_SNR(self):\n    \"\"\"Detect channels that have a low signal-to-noise ratio.\n\n        Channels are considered \"bad-by-SNR\" if they are bad by both high-frequency\n        noise and bad by low correlation.\n\n        \"\"\"\n    if not len(self._extra_info['bad_by_hf_noise']) > 1:\n        self.find_bad_by_hfnoise()\n    if not len(self._extra_info['bad_by_correlation']):\n        self.find_bad_by_correlation()\n    bad_by_hf = set(self.bad_by_hf_noise)\n    bad_by_corr = set(self.bad_by_correlation)\n    self.bad_by_SNR = list(bad_by_corr.intersection(bad_by_hf))", "metadata": {}}
{"_id": "pyprep_pyprep_find_noisy_channels.py_find_bad_by_ransac_code", "title": "find_bad_by_ransac", "text": "def find_bad_by_ransac(self, n_samples=50, sample_prop=0.25, corr_thresh=0.75, frac_bad=0.4, corr_window_secs=5.0, channel_wise=False, max_chunk_size=None):\n    \"\"\"Detect channels that are predicted poorly by other channels.\n\n        This method uses a random sample consensus approach (RANSAC, see [1]_,\n        and a short discussion in [2]_) to try and predict what the signal should\n        be for each channel based on the signals and spatial locations of other\n        currently-good channels. RANSAC correlations are calculated by splitting\n        the recording into non-overlapping windows of time (default: 5 seconds)\n        and correlating each channel's RANSAC-predicted signal with its actual\n        signal within each window.\n\n        A RANSAC window is considered \"bad\" for a channel if its predicted signal\n        vs. actual signal correlation falls below the given correlation threshold\n        (default: ``0.75``). A channel is considered \"bad-by-RANSAC\" if its fraction\n        of bad RANSAC windows is above the given threshold (default: ``0.4``).\n\n        Due to its random sampling component, the channels identified as\n        \"bad-by-RANSAC\" may vary slightly between calls of this method.\n        Additionally, bad channels may vary between different montages given that\n        RANSAC's signal predictions are based on the spatial coordinates of each\n        electrode.\n\n        This method is a wrapper for the :func:`~ransac.find_bad_by_ransac`\n        function.\n\n        .. warning:: For optimal performance, RANSAC requires that channels bad by\n                     deviation, correlation, and/or dropout have already been\n                     flagged. Otherwise RANSAC will attempt to use those channels\n                     when making signal predictions, decreasing accuracy and thus\n                     increasing the likelihood of false positives.\n\n        Parameters\n        ----------\n        n_samples : int, optional\n            Number of random channel samples to use for RANSAC. Defaults\n            to ``50``.\n        sample_prop : float, optional\n            Proportion of total channels to use for signal prediction per RANSAC\n            sample. This needs to be in the range [0, 1], where 0 would mean no\n            channels would be used and 1 would mean all channels would be used\n            (neither of which would be useful values). Defaults to ``0.25``\n            (e.g., 16 channels per sample for a 64-channel dataset).\n        corr_thresh : float, optional\n            The minimum predicted vs. actual signal correlation for a channel to\n            be considered good within a given RANSAC window. Defaults\n            to ``0.75``.\n        frac_bad : float, optional\n            The minimum fraction of bad (i.e., below-threshold) RANSAC windows\n            for a channel to be considered bad-by-RANSAC. Defaults to ``0.4``.\n        corr_window_secs : float, optional\n            The duration (in seconds) of each RANSAC correlation window. Defaults\n            to 5 seconds.\n        channel_wise : bool, optional\n            Whether RANSAC should predict signals for chunks of channels over the\n            entire signal length (\"channel-wise RANSAC\", see `max_chunk_size`\n            parameter). If ``False``, RANSAC will instead predict signals for all\n            channels at once but over a number of smaller time windows instead of\n            over the entire signal length (\"window-wise RANSAC\"). Channel-wise\n            RANSAC generally has higher RAM demands than window-wise RANSAC\n            (especially if `max_chunk_size` is ``None``), but can be faster on\n            systems with lots of RAM to spare. Defaults to ``False``.\n        max_chunk_size : {int, None}, optional\n            The maximum number of channels to predict at once during\n            channel-wise RANSAC. If ``None``, RANSAC will use the largest chunk\n            size that will fit into the available RAM, which may slow down\n            other programs on the host system. If using window-wise RANSAC\n            (the default), this parameter has no effect. Defaults to ``None``.\n\n        References\n        ----------\n        .. [1] Fischler, M.A., Bolles, R.C. (1981). Random sample consensus: A\n            Paradigm for Model Fitting with Applications to Image Analysis and\n            Automated Cartography. Communications of the ACM, 24, 381-395\n        .. [2] Jas, M., Engemann, D.A., Bekhti, Y., Raimondo, F., Gramfort, A.\n            (2017). Autoreject: Automated Artifact Rejection for MEG and EEG\n            Data. NeuroImage, 159, 417-429\n\n        \"\"\"\n    if self.EEGFiltered is None:\n        self.EEGFiltered = self._get_filtered_data()\n    exclude_from_ransac = self.bad_by_correlation + self.bad_by_deviation + self.bad_by_dropout\n    if self.matlab_strict:\n        random_state = self.random_state.get_state()\n        rng = np.random.RandomState()\n        rng.set_state(random_state)\n    else:\n        rng = self.random_state\n    (self.bad_by_ransac, ch_correlations_usable) = find_bad_by_ransac(self.EEGFiltered, self.sample_rate, self.ch_names_new, self.raw_mne._get_channel_positions()[self.usable_idx, :], exclude_from_ransac, n_samples, sample_prop, corr_thresh, frac_bad, corr_window_secs, channel_wise, max_chunk_size, rng, self.matlab_strict)\n    n_ransac_windows = ch_correlations_usable.shape[0]\n    ch_correlations = np.ones((n_ransac_windows, self.n_chans_original))\n    ch_correlations[:, self.usable_idx] = ch_correlations_usable\n    self._extra_info['bad_by_ransac'] = {'ransac_correlations': ch_correlations, 'bad_window_fractions': np.mean(ch_correlations < corr_thresh, axis=0)}", "metadata": {}}
