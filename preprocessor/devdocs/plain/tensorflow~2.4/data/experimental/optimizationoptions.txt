# tf.data.experimental.OptimizationOptions

View source on GitHub  Represents options for dataset optimizations.

#### View aliases

Compat aliases for migration See Migration guide for more details.
`tf.compat.v1.data.experimental.OptimizationOptions`

    
    tf.data.experimental.OptimizationOptions()
    
You can set the optimization options of a dataset through the
`experimental_optimization` property of `tf.data.Options`; the property is an
instance of `tf.data.experimental.OptimizationOptions`.

    
    options = tf.data.Options()
    options.experimental_optimization.noop_elimination = True
    options.experimental_optimization.map_vectorization.enabled = True
    options.experimental_optimization.apply_default_optimizations = False
    dataset = dataset.with_options(options)
    
| Attributes  
---  
`apply_default_optimizations` |  Whether to apply default graph optimizations. If False, only graph optimizations that have been explicitly enabled will be applied.   
`autotune` |  Whether to automatically tune performance knobs. If None, defaults to True.   
`autotune_buffers` |  When autotuning is enabled (through `autotune`), determines whether to also autotune buffer sizes for datasets with parallelism. If None, defaults to False.   
`autotune_cpu_budget` |  When autotuning is enabled (through `autotune`), determines the CPU budget to use. Values greater than the number of schedulable CPU cores are allowed but may result in CPU contention. If None, defaults to the number of schedulable CPU cores.   
`autotune_ram_budget` |  When autotuning is enabled (through `autotune`), determines the RAM budget to use. Values greater than the available RAM in bytes may result in OOM. If None, defaults to half of the available RAM in bytes.   
`filter_fusion` |  Whether to fuse filter transformations. If None, defaults to False.   
`filter_with_random_uniform_fusion` |  Whether to fuse filter dataset that predicts random_uniform < rate into a sampling dataset. If None, defaults to False.   
`hoist_random_uniform` |  Whether to hoist `tf.random_uniform()` ops out of map transformations. If None, defaults to False.   
`map_and_batch_fusion` |  Whether to fuse map and batch transformations. If None, defaults to True.   
`map_and_filter_fusion` |  Whether to fuse map and filter transformations. If None, defaults to False.   
`map_fusion` |  Whether to fuse map transformations. If None, defaults to False.   
`map_parallelization` |  Whether to parallelize stateless map transformations. If None, defaults to False.   
`map_vectorization` |  The map vectorization options associated with the dataset. See `tf.data.experimental.MapVectorizationOptions` for more details.   
`noop_elimination` |  Whether to eliminate no-op transformations. If None, defaults to True.   
`parallel_batch` |  Whether to parallelize copying of batch elements. This optimization is highly experimental and can cause performance degradation (e.g. when the parallelization overhead exceeds the benefits of performing the data copies in parallel). You should only enable this optimization if a) your input pipeline is bottlenecked on batching and b) you have validated that this optimization improves performance. If None, defaults to False.   
`reorder_data_discarding_ops` |  Whether to reorder ops that will discard data to the front of unary cardinality preserving transformations, e.g. dataset.map(...).take(3) will be optimized to dataset.take(3).map(...). For now this optimization will move `skip`, `shard` and `take` to the front of `map` and `prefetch`. This optimization is only for performance; it will not affect the output of the dataset. If None, defaults to True.   
`shuffle_and_repeat_fusion` |  Whether to fuse shuffle and repeat transformations. If None, defaults to True.   
## Methods

### `__eq__`

View source

    
    __eq__(
        other
    )
    
Return self==value.

### `__ne__`

View source

    
    __ne__(
        other
    )
    
Return self!=value.

Â© 2020 The TensorFlow Authors. All rights reserved.  
Licensed under the Creative Commons Attribution License 3.0.  
Code samples licensed under the Apache 2.0 License.  
https://www.tensorflow.org/versions/r2.4/api_docs/python/tf/data/experimental/OptimizationOptions

  *[ISP]: Internet Service Provider
  *[LIFO]: last-in, first-out
  *[FIFO]: first-in, first-out

