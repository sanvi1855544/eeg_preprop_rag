# tf.data.Options

View source on GitHub  Represents options for `tf.data.Dataset`.

#### View aliases

Compat aliases for migration See Migration guide for more details.
`tf.compat.v1.data.Options`

    
    tf.data.Options()
    
A `tf.data.Options` object can be, for instance, used to control which static
optimizations to apply to the input pipeline graph or whether to use
performance modeling to dynamically tune the parallelism of operations such as
`tf.data.Dataset.map` or `tf.data.Dataset.interleave`. The options are set for
the entire dataset and are carried over to datasets created through tf.data
transformations. The options can be set either by mutating the object returned
by `tf.data.Dataset.options()` or by constructing an `Options` object and
using the `tf.data.Dataset.with_options(options)` transformation, which
returns a dataset with the options set.

    
    dataset = tf.data.Dataset.range(42)
    dataset.options().experimental_deterministic = False
    print(dataset.options().experimental_deterministic)
    False
    
    
    dataset = tf.data.Dataset.range(42)
    options = tf.data.Options()
    options.experimental_deterministic = False
    dataset = dataset.with_options(options)
    print(dataset.options().experimental_deterministic)
    False
    
> Note: A known limitation of the `tf.data.Options` implementation is that the
> options are not preserved across tf.function boundaries. In particular, to
> set options for a dataset that is iterated within a tf.function, the options
> need to be set within the same tf.function.
| Attributes  
---  
`experimental_deterministic` |  Whether the outputs need to be produced in deterministic order. If None, defaults to True.   
`experimental_distribute` |  The distribution strategy options associated with the dataset. See `tf.data.experimental.DistributeOptions` for more details.   
`experimental_external_state_policy` |  This option can be used to override the default policy for how to handle external state when serializing a dataset or checkpointing its iterator. There are three settings available - IGNORE: in which we completely ignore any state; WARN: We warn the user that some state might be thrown away; FAIL: We fail if any state is being captured.   
`experimental_optimization` |  The optimization options associated with the dataset. See `tf.data.experimental.OptimizationOptions` for more details.   
`experimental_slack` |  Whether to introduce 'slack' in the last `prefetch` of the input pipeline, if it exists. This may reduce CPU contention with accelerator host-side activity at the start of a step. The slack frequency is determined by the number of devices attached to this input pipeline. If None, defaults to False.   
`experimental_stats` |  The statistics options associated with the dataset. See `tf.data.experimental.StatsOptions` for more details.   
`experimental_threading` |  The threading options associated with the dataset. See `tf.data.experimental.ThreadingOptions` for more details.   
## Methods

### `merge`

View source

    
    merge(
        options
    )
    
Merges itself with the given `tf.data.Options`.

If this object and the `options` to merge set an option differently, a warning
is generated and this object's value is updated with the `options` object's
value.

Args  
---  
`options` |  a `tf.data.Options` to merge with   
Returns  
---  
New `tf.data.Options` object which is the result of merging self with the
input `tf.data.Options`.  
### `__eq__`

View source

    
    __eq__(
        other
    )
    
Return self==value.

### `__ne__`

View source

    
    __ne__(
        other
    )
    
Return self!=value.

Â© 2020 The TensorFlow Authors. All rights reserved.  
Licensed under the Creative Commons Attribution License 3.0.  
Code samples licensed under the Apache 2.0 License.  
https://www.tensorflow.org/versions/r2.4/api_docs/python/tf/data/Options

  *[ISP]: Internet Service Provider
  *[LIFO]: last-in, first-out
  *[FIFO]: first-in, first-out

