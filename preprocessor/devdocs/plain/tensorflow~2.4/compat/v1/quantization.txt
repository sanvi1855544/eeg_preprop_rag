# Module: tf.compat.v1.quantization

Public API for tf.quantization namespace.

## Functions

`dequantize(...)`: Dequantize the 'input' tensor into a float or bfloat16
Tensor.

`fake_quant_with_min_max_args(...)`: Fake-quantize the 'inputs' tensor, type
float to 'outputs' tensor of same type.

`fake_quant_with_min_max_args_gradient(...)`: Compute gradients for a
FakeQuantWithMinMaxArgs operation.

`fake_quant_with_min_max_vars(...)`: Fake-quantize the 'inputs' tensor of type
float via global float scalars

`fake_quant_with_min_max_vars_gradient(...)`: Compute gradients for a
FakeQuantWithMinMaxVars operation.

`fake_quant_with_min_max_vars_per_channel(...)`: Fake-quantize the 'inputs'
tensor of type float via per-channel floats

`fake_quant_with_min_max_vars_per_channel_gradient(...)`: Compute gradients
for a FakeQuantWithMinMaxVarsPerChannel operation.

`quantize(...)`: Quantize the 'input' tensor of type float to 'output' tensor
of type 'T'.

`quantize_and_dequantize(...)`: Quantizes then dequantizes a tensor.
(deprecated)

`quantize_and_dequantize_v2(...)`: Quantizes then dequantizes a tensor.

`quantized_concat(...)`: Concatenates quantized tensors along one dimension.

Â© 2020 The TensorFlow Authors. All rights reserved.  
Licensed under the Creative Commons Attribution License 3.0.  
Code samples licensed under the Apache 2.0 License.  
https://www.tensorflow.org/versions/r2.4/api_docs/python/tf/compat/v1/quantization

  *[ISP]: Internet Service Provider
  *[LIFO]: last-in, first-out
  *[FIFO]: first-in, first-out

