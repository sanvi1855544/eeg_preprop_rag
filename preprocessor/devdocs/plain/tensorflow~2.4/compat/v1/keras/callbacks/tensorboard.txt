# tf.compat.v1.keras.callbacks.TensorBoard

Enable visualizations for TensorBoard.

Inherits From: `TensorBoard`, `Callback`

    
    tf.compat.v1.keras.callbacks.TensorBoard(
        log_dir='./logs', histogram_freq=0, batch_size=32, write_graph=True,
        write_grads=False, write_images=False, embeddings_freq=0,
        embeddings_layer_names=None, embeddings_metadata=None, embeddings_data=None,
        update_freq='epoch', profile_batch=2
    )
    
TensorBoard is a visualization tool provided with TensorFlow.

This callback logs events for TensorBoard, including:

  * Metrics summary plots
  * Training graph visualization
  * Activation histograms
  * Sampled profiling

If you have installed TensorFlow with pip, you should be able to launch
TensorBoard from the command line:

    
    tensorboard --logdir=path_to_your_logs
    
You can find more information about TensorBoard here.

Arguments  
---  
`log_dir` |  the path of the directory where to save the log files to be parsed by TensorBoard.   
`histogram_freq` |  frequency (in epochs) at which to compute activation and weight histograms for the layers of the model. If set to 0, histograms won't be computed. Validation data (or split) must be specified for histogram visualizations.   
`write_graph` |  whether to visualize the graph in TensorBoard. The log file can become quite large when write_graph is set to True.   
`write_grads` |  whether to visualize gradient histograms in TensorBoard. `histogram_freq` must be greater than 0.   
`batch_size` |  size of batch of inputs to feed to the network for histograms computation.   
`write_images` |  whether to write model weights to visualize as image in TensorBoard.   
`embeddings_freq` |  frequency (in epochs) at which selected embedding layers will be saved. If set to 0, embeddings won't be computed. Data to be visualized in TensorBoard's Embedding tab must be passed as `embeddings_data`.   
`embeddings_layer_names` |  a list of names of layers to keep eye on. If None or empty list all the embedding layer will be watched.   
`embeddings_metadata` |  a dictionary which maps layer name to a file name in which metadata for this embedding layer is saved. Here are details about metadata files format. In case if the same metadata file is used for all embedding layers, string can be passed.   
`embeddings_data` |  data to be embedded at layers specified in `embeddings_layer_names`. Numpy array (if the model has a single input) or list of Numpy arrays (if the model has multiple inputs). Learn more about embeddings in this guide.   
`update_freq` |  `'batch'` or `'epoch'` or integer. When using `'batch'`, writes the losses and metrics to TensorBoard after each batch. The same applies for `'epoch'`. If using an integer, let's say `1000`, the callback will write the metrics and losses to TensorBoard every 1000 samples. Note that writing too frequently to TensorBoard can slow down your training.   
`profile_batch` |  Profile the batch to sample compute characteristics. By default, it will profile the second batch. Set profile_batch=0 to disable profiling.   
Raises  
---  
`ValueError` |  If histogram_freq is set and no validation data is provided.   
#### Eager Compatibility

Using the `TensorBoard` callback will work when eager execution is enabled,
with the restriction that outputting histogram summaries of weights and
gradients is not supported. Consequently, `histogram_freq` will be ignored.

## Methods

### `set_model`

View source

    
    set_model(
        model
    )
    
Sets Keras model and creates summary ops.

### `set_params`

View source

    
    set_params(
        params
    )
    
Â© 2020 The TensorFlow Authors. All rights reserved.  
Licensed under the Creative Commons Attribution License 3.0.  
Code samples licensed under the Apache 2.0 License.  
https://www.tensorflow.org/versions/r2.4/api_docs/python/tf/compat/v1/keras/callbacks/TensorBoard

  *[ISP]: Internet Service Provider
  *[LIFO]: last-in, first-out
  *[FIFO]: first-in, first-out

