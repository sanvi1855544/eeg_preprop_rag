# tf.raw_ops.ResourceAccumulatorApplyGradient

Applies a gradient to a given accumulator.

#### View aliases

Compat aliases for migration

See Migration guide for more details.

`tf.compat.v1.raw_ops.ResourceAccumulatorApplyGradient`

    
    tf.raw_ops.ResourceAccumulatorApplyGradient(
        handle, local_step, gradient, name=None
    )
    
Does not add if local_step is lesser than the accumulator's global_step.

Args  
---  
`handle` |  A `Tensor` of type `resource`. The handle to a accumulator.   
`local_step` |  A `Tensor` of type `int64`. The local_step value at which the gradient was computed.   
`gradient` |  A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`. A tensor of the gradient to be accumulated.   
`name` |  A name for the operation (optional).   
Returns  
---  
The created Operation.  
Â© 2020 The TensorFlow Authors. All rights reserved.  
Licensed under the Creative Commons Attribution License 3.0.  
Code samples licensed under the Apache 2.0 License.  
https://www.tensorflow.org/versions/r2.4/api_docs/python/tf/raw_ops/ResourceAccumulatorApplyGradient

  *[ISP]: Internet Service Provider
  *[LIFO]: last-in, first-out
  *[FIFO]: first-in, first-out

