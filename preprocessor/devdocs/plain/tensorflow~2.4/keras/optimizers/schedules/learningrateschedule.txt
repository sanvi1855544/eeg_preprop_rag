# tf.keras.optimizers.schedules.LearningRateSchedule

View source on GitHub  A serializable learning rate decay schedule.

#### View aliases

Main aliases `tf.optimizers.schedules.LearningRateSchedule` Compat aliases for
migration See Migration guide for more details.
`tf.compat.v1.keras.optimizers.schedules.LearningRateSchedule`
`LearningRateSchedule`s can be passed in as the learning rate of optimizers in
`tf.keras.optimizers`. They can be serialized and deserialized using
`tf.keras.optimizers.schedules.serialize` and
`tf.keras.optimizers.schedules.deserialize`.

## Methods

### `from_config`

View source

    
    @classmethod
    from_config(
        config
    )
    
Instantiates a `LearningRateSchedule` from its config. | Args  
---  
`config` |  Output of `get_config()`.   
Returns  
---  
A `LearningRateSchedule` instance.  
### `get_config`

View source

    
    @abc.abstractmethod
    get_config()
    
### `__call__`

View source

    
    @abc.abstractmethod
    __call__(
        step
    )
    
Call self as a function.

Â© 2020 The TensorFlow Authors. All rights reserved.  
Licensed under the Creative Commons Attribution License 3.0.  
Code samples licensed under the Apache 2.0 License.  
https://www.tensorflow.org/versions/r2.4/api_docs/python/tf/keras/optimizers/schedules/LearningRateSchedule

  *[ISP]: Internet Service Provider
  *[LIFO]: last-in, first-out
  *[FIFO]: first-in, first-out

