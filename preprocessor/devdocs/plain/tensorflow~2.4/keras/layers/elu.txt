# tf.keras.layers.ELU

View source on GitHub  Exponential Linear Unit. Inherits From: `Layer`,
`Module`

#### View aliases

Compat aliases for migration See Migration guide for more details.
`tf.compat.v1.keras.layers.ELU`

    
    tf.keras.layers.ELU(
        alpha=1.0, **kwargs
    )
    
#### It follows:

    
    f(x) =  alpha * (exp(x) - 1.) for x < 0
    f(x) = x for x >= 0
    
#### Input shape:

Arbitrary. Use the keyword argument `input_shape` (tuple of integers, does not
include the samples axis) when using this layer as the first layer in a model.

#### Output shape:

Same shape as the input. | Arguments  
---  
`alpha` |  Scale for the negative factor.   
Â© 2020 The TensorFlow Authors. All rights reserved.  
Licensed under the Creative Commons Attribution License 3.0.  
Code samples licensed under the Apache 2.0 License.  
https://www.tensorflow.org/versions/r2.4/api_docs/python/tf/keras/layers/ELU

  *[ISP]: Internet Service Provider
  *[LIFO]: last-in, first-out
  *[FIFO]: first-in, first-out

