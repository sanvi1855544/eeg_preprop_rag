# tf.keras.metrics.SpecificityAtSensitivity

View source on GitHub  Computes best specificity where sensitivity is >=
specified value. Inherits From: `Metric`, `Layer`, `Module`

#### View aliases

Main aliases `tf.metrics.SpecificityAtSensitivity` Compat aliases for
migration See Migration guide for more details.
`tf.compat.v1.keras.metrics.SpecificityAtSensitivity`

    
    tf.keras.metrics.SpecificityAtSensitivity(
        sensitivity, num_thresholds=200, name=None, dtype=None
    )
    
`Sensitivity` measures the proportion of actual positives that are correctly identified as such (tp / (tp + fn)). `Specificity` measures the proportion of actual negatives that are correctly identified as such (tn / (tn + fp)). This metric creates four local variables, `true_positives`, `true_negatives`, `false_positives` and `false_negatives` that are used to compute the specificity at the given sensitivity. The threshold for the given sensitivity value is computed and used to evaluate the corresponding specificity. If `sample_weight` is `None`, weights default to 1. Use `sample_weight` of 0 to mask values. For additional information about specificity and sensitivity, see the following. | Args  
---  
`sensitivity` |  A scalar value in range `[0, 1]`.   
`num_thresholds` |  (Optional) Defaults to 200. The number of thresholds to use for matching the given sensitivity.   
`name` |  (Optional) string name of the metric instance.   
`dtype` |  (Optional) data type of the metric result.   
#### Standalone usage:

    
    m = tf.keras.metrics.SpecificityAtSensitivity(0.5)
    m.update_state([0, 0, 0, 1, 1], [0, 0.3, 0.8, 0.3, 0.8])
    m.result().numpy()
    0.66666667
    
    
    m.reset_states()
    m.update_state([0, 0, 0, 1, 1], [0, 0.3, 0.8, 0.3, 0.8],
                   sample_weight=[1, 1, 2, 2, 2])
    m.result().numpy()
    0.5
    
Usage with `compile()` API:

    
    model.compile(
        optimizer='sgd',
        loss='mse',
        metrics=[tf.keras.metrics.SpecificityAtSensitivity()])
    
## Methods

### `reset_states`

View source

    
    reset_states()
    
Resets all of the metric state variables.

This function is called between epochs/steps, when a metric is evaluated
during training.

### `result`

View source

    
    result()
    
Computes and returns the metric value tensor.

Result computation is an idempotent operation that simply calculates the
metric value using the state variables.

### `update_state`

View source

    
    update_state(
        y_true, y_pred, sample_weight=None
    )
    
Accumulates confusion matrix statistics.

Args  
---  
`y_true` |  The ground truth values.   
`y_pred` |  The predicted values.   
`sample_weight` |  Optional weighting of each example. Defaults to 1. Can be a `Tensor` whose rank is either 0, or the same rank as `y_true`, and must be broadcastable to `y_true`.   
Returns  
---  
Update op.  
Â© 2020 The TensorFlow Authors. All rights reserved.  
Licensed under the Creative Commons Attribution License 3.0.  
Code samples licensed under the Apache 2.0 License.  
https://www.tensorflow.org/versions/r2.4/api_docs/python/tf/keras/metrics/SpecificityAtSensitivity

  *[ISP]: Internet Service Provider
  *[LIFO]: last-in, first-out
  *[FIFO]: first-in, first-out

