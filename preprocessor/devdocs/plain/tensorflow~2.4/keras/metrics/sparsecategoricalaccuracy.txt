# tf.keras.metrics.SparseCategoricalAccuracy

View source on GitHub  Calculates how often predictions matches integer
labels. Inherits From: `Mean`, `Metric`, `Layer`, `Module`

#### View aliases

Main aliases `tf.metrics.SparseCategoricalAccuracy` Compat aliases for
migration See Migration guide for more details.
`tf.compat.v1.keras.metrics.SparseCategoricalAccuracy`

    
    tf.keras.metrics.SparseCategoricalAccuracy(
        name='sparse_categorical_accuracy', dtype=None
    )
    
    
    acc = np.dot(sample_weight, np.equal(y_true, np.argmax(y_pred, axis=1))
    
You can provide logits of classes as `y_pred`, since argmax of logits and probabilities are same. This metric creates two local variables, `total` and `count` that are used to compute the frequency with which `y_pred` matches `y_true`. This frequency is ultimately returned as `sparse categorical accuracy`: an idempotent operation that simply divides `total` by `count`. If `sample_weight` is `None`, weights default to 1. Use `sample_weight` of 0 to mask values. | Args  
---  
`name` |  (Optional) string name of the metric instance.   
`dtype` |  (Optional) data type of the metric result.   
#### Standalone usage:

    
    m = tf.keras.metrics.SparseCategoricalAccuracy()
    m.update_state([[2], [1]], [[0.1, 0.6, 0.3], [0.05, 0.95, 0]])
    m.result().numpy()
    0.5
    
    
    m.reset_states()
    m.update_state([[2], [1]], [[0.1, 0.6, 0.3], [0.05, 0.95, 0]],
                   sample_weight=[0.7, 0.3])
    m.result().numpy()
    0.3
    
Usage with `compile()` API:

    
    model.compile(
        optimizer='sgd',
        loss='mse',
        metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])
    
## Methods

### `reset_states`

View source

    
    reset_states()
    
Resets all of the metric state variables.

This function is called between epochs/steps, when a metric is evaluated
during training.

### `result`

View source

    
    result()
    
Computes and returns the metric value tensor.

Result computation is an idempotent operation that simply calculates the
metric value using the state variables.

### `update_state`

View source

    
    update_state(
        y_true, y_pred, sample_weight=None
    )
    
Accumulates metric statistics.

`y_true` and `y_pred` should have the same shape.

Args  
---  
`y_true` |  Ground truth values. shape = `[batch_size, d0, .. dN]`.   
`y_pred` |  The predicted values. shape = `[batch_size, d0, .. dN]`.   
`sample_weight` |  Optional `sample_weight` acts as a coefficient for the metric. If a scalar is provided, then the metric is simply scaled by the given value. If `sample_weight` is a tensor of size `[batch_size]`, then the metric for each sample of the batch is rescaled by the corresponding element in the `sample_weight` vector. If the shape of `sample_weight` is `[batch_size, d0, .. dN-1]` (or can be broadcasted to this shape), then each metric element of `y_pred` is scaled by the corresponding value of `sample_weight`. (Note on `dN-1`: all metric functions reduce by 1 dimension, usually the last axis (-1)).   
Returns  
---  
Update op.  
Â© 2020 The TensorFlow Authors. All rights reserved.  
Licensed under the Creative Commons Attribution License 3.0.  
Code samples licensed under the Apache 2.0 License.  
https://www.tensorflow.org/versions/r2.4/api_docs/python/tf/keras/metrics/SparseCategoricalAccuracy

  *[ISP]: Internet Service Provider
  *[LIFO]: last-in, first-out
  *[FIFO]: first-in, first-out

