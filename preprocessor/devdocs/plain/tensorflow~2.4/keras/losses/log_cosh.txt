# tf.keras.losses.log_cosh

Logarithm of the hyperbolic cosine of the prediction error.

#### View aliases

Main aliases

`tf.keras.losses.logcosh`, `tf.keras.metrics.log_cosh`,
`tf.keras.metrics.logcosh`, `tf.losses.log_cosh`, `tf.losses.logcosh`,
`tf.metrics.log_cosh`, `tf.metrics.logcosh`

Compat aliases for migration

See Migration guide for more details.

`tf.compat.v1.keras.losses.log_cosh`, `tf.compat.v1.keras.losses.logcosh`,
`tf.compat.v1.keras.metrics.log_cosh`, `tf.compat.v1.keras.metrics.logcosh`

    
    tf.keras.losses.log_cosh(
        y_true, y_pred
    )
    
`log(cosh(x))` is approximately equal to `(x ** 2) / 2` for small `x` and to
`abs(x) - log(2)` for large `x`. This means that 'logcosh' works mostly like
the mean squared error, but will not be so strongly affected by the occasional
wildly incorrect prediction.

#### Standalone usage:

    
    y_true = np.random.random(size=(2, 3))
    y_pred = np.random.random(size=(2, 3))
    loss = tf.keras.losses.logcosh(y_true, y_pred)
    assert loss.shape == (2,)
    x = y_pred - y_true
    assert np.allclose(
        loss.numpy(),
        np.mean(x + np.log(np.exp(-2. * x) + 1.) - math_ops.log(2.), axis=-1),
        atol=1e-5)
    
Args  
---  
`y_true` |  Ground truth values. shape = `[batch_size, d0, .. dN]`.   
`y_pred` |  The predicted values. shape = `[batch_size, d0, .. dN]`.   
Returns  
---  
Logcosh error values. shape = `[batch_size, d0, .. dN-1]`.  
Â© 2020 The TensorFlow Authors. All rights reserved.  
Licensed under the Creative Commons Attribution License 3.0.  
Code samples licensed under the Apache 2.0 License.  
https://www.tensorflow.org/versions/r2.4/api_docs/python/tf/keras/losses/log_cosh

  *[ISP]: Internet Service Provider
  *[LIFO]: last-in, first-out
  *[FIFO]: first-in, first-out

