# tf.keras.activations.hard_sigmoid

View source on GitHub  Hard sigmoid activation function.

#### View aliases

Compat aliases for migration See Migration guide for more details.
`tf.compat.v1.keras.activations.hard_sigmoid`

    
    tf.keras.activations.hard_sigmoid(
        x
    )
    
A faster approximation of the sigmoid activation.

#### For example:

    
    a = tf.constant([-3.0,-1.0, 0.0,1.0,3.0], dtype = tf.float32)
    b = tf.keras.activations.hard_sigmoid(a)
    b.numpy()
    array([0. , 0.3, 0.5, 0.7, 1. ], dtype=float32)
    
| Arguments  
---  
`x` |  Input tensor.   
Returns  
---  
The hard sigmoid activation, defined as:

  * `if x < -2.5: return 0`
  * `if x > 2.5: return 1`
  * `if -2.5 <= x <= 2.5: return 0.2 * x + 0.5`

  
Â© 2020 The TensorFlow Authors. All rights reserved.  
Licensed under the Creative Commons Attribution License 3.0.  
Code samples licensed under the Apache 2.0 License.  
https://www.tensorflow.org/versions/r2.4/api_docs/python/tf/keras/activations/hard_sigmoid

  *[ISP]: Internet Service Provider
  *[LIFO]: last-in, first-out
  *[FIFO]: first-in, first-out

