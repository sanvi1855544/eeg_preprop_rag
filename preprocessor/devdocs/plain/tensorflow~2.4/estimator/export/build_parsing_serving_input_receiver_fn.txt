# tf.estimator.export.build_parsing_serving_input_receiver_fn

View source on GitHub  Build a serving_input_receiver_fn expecting fed
tf.Examples.

#### View aliases

Compat aliases for migration See Migration guide for more details.
`tf.compat.v1.estimator.export.build_parsing_serving_input_receiver_fn`

    
    tf.estimator.export.build_parsing_serving_input_receiver_fn(
        feature_spec, default_batch_size=None
    )
    
Creates a serving_input_receiver_fn that expects a serialized tf.Example fed into a string placeholder. The function parses the tf.Example according to the provided feature_spec, and returns all parsed Tensors as features. | Args  
---  
`feature_spec` |  a dict of string to `VarLenFeature`/`FixedLenFeature`.   
`default_batch_size` |  the number of query examples expected per batch. Leave unset for variable batch size (recommended).   
Returns  
---  
A serving_input_receiver_fn suitable for use in serving.  
Â© 2020 The TensorFlow Authors. All rights reserved.  
Licensed under the Creative Commons Attribution License 3.0.  
Code samples licensed under the Apache 2.0 License.  
https://www.tensorflow.org/versions/r2.4/api_docs/python/tf/estimator/export/build_parsing_serving_input_receiver_fn

  *[ISP]: Internet Service Provider
  *[LIFO]: last-in, first-out
  *[FIFO]: first-in, first-out

