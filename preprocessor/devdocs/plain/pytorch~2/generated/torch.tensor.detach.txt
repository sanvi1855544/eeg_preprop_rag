# torch.Tensor.detach

`Tensor.detach()`

    
Returns a new Tensor, detached from the current graph.

The result will never require gradient.

This method also affects forward mode AD gradients and the result will never
have forward mode AD gradients.

Note

Returned Tensor shares the same storage with the original one. In-place
modifications on either of them will be seen, and may trigger errors in
correctness checks. IMPORTANT NOTE: Previously, in-place size / stride /
storage changes (such as `resize_` / `resize_as_` / `set_` / `transpose_`) to
the returned tensor also update the original tensor. Now, these in-place
changes will not update the original tensor anymore, and will instead trigger
an error. For sparse tensors: In-place indices / values changes (such as
`zero_` / `copy_` / `add_`) to the returned tensor will not update the
original tensor anymore, and will instead trigger an error.

Â© 2024, PyTorch Contributors  
PyTorch has a BSD-style license, as found in the LICENSE file.  
https://pytorch.org/docs/2.1/generated/torch.Tensor.detach.html

  *[ISP]: Internet Service Provider
  *[LIFO]: last-in, first-out
  *[FIFO]: first-in, first-out

