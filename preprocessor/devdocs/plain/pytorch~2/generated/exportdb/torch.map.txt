# torch.map

## dynamic_shape_map

Note

Tags: torch.map, torch.dynamic-shape

Support Level: SUPPORTED

Original source code:

    
    import torch
    
    from functorch.experimental.control_flow import map
    
    
    def dynamic_shape_map(xs, y):
        """
        functorch map() maps a function over the first tensor dimension.
        """
    
        def body(x, y):
            return x + y
    
        return map(body, xs, y)
    
Result:

    
    ExportedProgram:
        class GraphModule(torch.nn.Module):
            def forward(self, arg0_1: f32[3, 2], arg1_1: f32[2]):
                #
                submodule_0 = self.submodule_0
                map_impl = torch.ops.map_impl(submodule_0, 1, arg0_1, arg1_1);  submodule_0 = arg0_1 = arg1_1 = None
                getitem: f32[3, 2] = map_impl[0];  map_impl = None
                return (getitem,)
    
            class GraphModule(torch.nn.Module):
                def forward(self, arg0_1: f32[2], arg1_1: f32[2]):
                            add: f32[2] = torch.ops.aten.add.Tensor(arg0_1, arg1_1);  arg0_1 = arg1_1 = None
                    return [add]
    
    Graph Signature: ExportGraphSignature(parameters=[], buffers=[], user_inputs=['arg0_1', 'arg1_1'], user_outputs=['getitem'], inputs_to_parameters={}, inputs_to_buffers={}, buffers_to_mutate={}, backward_signature=None, assertion_dep_token=None)
    Symbol to range: {}
    
Â© 2024, PyTorch Contributors  
PyTorch has a BSD-style license, as found in the LICENSE file.  
https://pytorch.org/docs/2.1/generated/exportdb/torch.map.html

  *[ISP]: Internet Service Provider
  *[LIFO]: last-in, first-out
  *[FIFO]: first-in, first-out

