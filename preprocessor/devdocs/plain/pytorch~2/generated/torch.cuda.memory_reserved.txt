# torch.cuda.memory_reserved

`torch.cuda.memory_reserved(device=None)` [source]

    
Returns the current GPU memory managed by the caching allocator in bytes for a
given device.

Parameters

    
device (torch.device or int, optional) – selected device. Returns statistic
for the current device, given by `current_device()`, if `device` is `None`
(default).

Return type

    
int

Note

See Memory management for more details about GPU memory management.

© 2024, PyTorch Contributors  
PyTorch has a BSD-style license, as found in the LICENSE file.  
https://pytorch.org/docs/2.1/generated/torch.cuda.memory_reserved.html

  *[ISP]: Internet Service Provider
  *[LIFO]: last-in, first-out
  *[FIFO]: first-in, first-out

