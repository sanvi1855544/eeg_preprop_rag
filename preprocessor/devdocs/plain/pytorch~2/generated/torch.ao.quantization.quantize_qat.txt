# quantize_qat

`class torch.ao.quantization.quantize_qat(model, run_fn, run_args,
inplace=False)` [source]

    
Do quantization aware training and output a quantized model

Parameters

    
  * model – input model
  * run_fn – a function for evaluating the prepared model, can be a function that simply runs the prepared model or a training loop
  * run_args – positional arguments for `run_fn`

Returns

    
Quantized model.

© 2024, PyTorch Contributors  
PyTorch has a BSD-style license, as found in the LICENSE file.  
https://pytorch.org/docs/2.1/generated/torch.ao.quantization.quantize_qat.html

  *[ISP]: Internet Service Provider
  *[LIFO]: last-in, first-out
  *[FIFO]: first-in, first-out

