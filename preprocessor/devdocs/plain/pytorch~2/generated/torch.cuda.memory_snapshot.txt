# torch.cuda.memory_snapshot

`torch.cuda.memory_snapshot()` [source]

    
Returns a snapshot of the CUDA memory allocator state across all devices.

Interpreting the output of this function requires familiarity with the memory
allocator internals.

Note

See Memory management for more details about GPU memory management.

Â© 2024, PyTorch Contributors  
PyTorch has a BSD-style license, as found in the LICENSE file.  
https://pytorch.org/docs/2.1/generated/torch.cuda.memory_snapshot.html

  *[ISP]: Internet Service Provider
  *[LIFO]: last-in, first-out
  *[FIFO]: first-in, first-out

