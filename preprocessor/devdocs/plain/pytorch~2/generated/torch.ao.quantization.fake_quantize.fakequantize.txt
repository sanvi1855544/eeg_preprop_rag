# FakeQuantize

`class torch.ao.quantization.fake_quantize.FakeQuantize(observer=<class
'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, quant_min=None,
quant_max=None, **observer_kwargs)` [source]

    
Simulate the quantize and dequantize operations in training time. The output
of this module is given by:

    
    x_out = (
      clamp(round(x/scale + zero_point), quant_min, quant_max) - zero_point
    ) * scale
    
  * `scale` defines the scale factor used for quantization.
  * `zero_point` specifies the quantized value to which 0 in floating point maps to
  * `fake_quant_enabled` controls the application of fake quantization on tensors, note that statistics can still be updated.
  * `observer_enabled` controls statistics collection on tensors
  * `dtype specifies the quantized dtype that is being emulated with fake-quantization,`
    
allowable values are torch.qint8 and torch.quint8.

Parameters

    
  * observer (module) – Module for observing statistics on input tensors and calculating scale and zero-point.
  * observer_kwargs (optional) – Arguments for the observer module

Variables

    
activation_post_process (Module) – User provided module that collects
statistics on the input tensor and provides a method to calculate scale and
zero-point.

© 2024, PyTorch Contributors  
PyTorch has a BSD-style license, as found in the LICENSE file.  
https://pytorch.org/docs/2.1/generated/torch.ao.quantization.fake_quantize.FakeQuantize.html

  *[ISP]: Internet Service Provider
  *[LIFO]: last-in, first-out
  *[FIFO]: first-in, first-out

