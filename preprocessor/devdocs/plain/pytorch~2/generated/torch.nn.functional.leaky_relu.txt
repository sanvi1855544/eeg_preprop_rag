# torch.nn.functional.leaky_relu

`torch.nn.functional.leaky_relu(input, negative_slope=0.01, inplace=False) →
Tensor` [source]

    
Applies element-wise,
LeakyReLU(x)=max⁡(0,x)+negative_slope∗min⁡(0,x)\text{LeakyReLU}(x) = \max(0,
x) + \text{negative\\_slope} * \min(0, x)

See `LeakyReLU` for more details.

Return type

    
Tensor

© 2024, PyTorch Contributors  
PyTorch has a BSD-style license, as found in the LICENSE file.  
https://pytorch.org/docs/2.1/generated/torch.nn.functional.leaky_relu.html

  *[ISP]: Internet Service Provider
  *[LIFO]: last-in, first-out
  *[FIFO]: first-in, first-out

