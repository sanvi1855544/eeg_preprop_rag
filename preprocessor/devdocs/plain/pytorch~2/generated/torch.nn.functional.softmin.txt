# torch.nn.functional.softmin

`torch.nn.functional.softmin(input, dim=None, _stacklevel=3, dtype=None)`
[source]

    
Applies a softmin function.

Note that Softmin(x)=Softmax(−x)\text{Softmin}(x) = \text{Softmax}(-x). See
softmax definition for mathematical formula.

See `Softmin` for more details.

Parameters

    
  * input (Tensor) – input
  * dim (int) – A dimension along which softmin will be computed (so every slice along dim will sum to 1).
  * dtype (`torch.dtype`, optional) – the desired data type of returned tensor. If specified, the input tensor is casted to `dtype` before the operation is performed. This is useful for preventing data type overflows. Default: None.

Return type

    
Tensor

© 2024, PyTorch Contributors  
PyTorch has a BSD-style license, as found in the LICENSE file.  
https://pytorch.org/docs/2.1/generated/torch.nn.functional.softmin.html

  *[ISP]: Internet Service Provider
  *[LIFO]: last-in, first-out
  *[FIFO]: first-in, first-out

