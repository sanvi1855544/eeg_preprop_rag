# torch._logging.set_logs

`torch._logging.set_logs(*, all=None, dynamo=None, aot=None, dynamic=None,
inductor=None, distributed=None, onnx=None, bytecode=False, aot_graphs=False,
aot_joint_graph=False, ddp_graphs=False, graph=False, graph_code=False,
graph_breaks=False, graph_sizes=False, guards=False, recompiles=False,
trace_source=False, trace_call=False, output_code=False, schedule=False,
perf_hints=False, onnx_diagnostics=False, modules=None)` [source]

    
Sets the log level for individual components and toggles individual log
artifact types.

Warning

This feature is a prototype and may have compatibility breaking changes in the
future.

Note

The `TORCH_LOGS` environment variable has complete precedence over this
function, so if it was set, this function does nothing.

A component is a set of related features in PyTorch. All of the log messages
emitted from a given component have their own log levels. If the log level of
a particular message has priority greater than or equal to its component’s log
level setting, it is emitted. Otherwise, it is supressed. This allows you to,
for instance, silence large groups of log messages that are not relevant to
you and increase verbosity of logs for components that are relevant. The
expected log level values, ordered from highest to lowest priority, are:

  * `logging.CRITICAL`
  * `logging.ERROR`
  * `logging.WARNING`
  * `logging.INFO`
  * `logging.DEBUG`
  * `logging.NOTSET`

See documentation for the Python `logging` module for more information on log
levels: https://docs.python.org/3/library/logging.html#logging-levels

An artifact is a particular type of log message. Each artifact is assigned to
a parent component. A component can emit many different kinds of artifacts. In
general, an artifact is emitted if either its corresponding setting in the
argument list below is turned on or if its parent component is set to a log
level less than or equal to the log level of the artifact.

Keyword Arguments

    
  * all (`Optional[int]`) – The default log level for all components. Default: `logging.WARN`
  * dynamo (`Optional[int]`) – The log level for the TorchDynamo component. Default: `logging.WARN`
  * aot (`Optional[int]`) – The log level for the AOTAutograd component. Default: `logging.WARN`
  * inductor (`Optional[int]`) – The log level for the TorchInductor component. Default: `logging.WARN`
  * dynamic (`Optional[int]`) – The log level for dynamic shapes. Default: `logging.WARN`
  * distributed (`Optional[int]`) – Whether to log communication operations and other debug info from pytorch distributed components. Default: `logging.WARN`
  * onnx (`Optional[int]`) – The log level for the ONNX exporter component. Default: `logging.WARN`
  * bytecode (`bool`) – Whether to emit the original and generated bytecode from TorchDynamo. Default: `False`
  * aot_graphs (`bool`) – Whether to emit the graphs generated by AOTAutograd. Default: `False`
  * aot_joint_graph (`bool`) – Whether to emit the joint forward-backward graph generated by AOTAutograd. Default: `False`
  * ddp_graphs (`bool`) – Whether to emit graphs generated by DDPOptimizer. Default: `False`
  * graph (`bool`) – Whether to emit the graph captured by TorchDynamo in tabular format. Default: `False`
  * graph_code (`bool`) – Whether to emit the python source of the graph captured by TorchDynamo. Default: `False`
  * graph_breaks (`bool`) – Whether to emit the graph breaks encountered by TorchDynamo. Default: `False`
  * graph_sizes (`bool`) – Whether to emit tensor sizes of the graph captured by TorchDynamo. Default: `False`
  * guards (`bool`) – Whether to emit the guards generated by TorchDynamo for each compiled function. Default: `False`
  * recompiles (`bool`) – Whether to emit a guard failure reason and message every time TorchDynamo recompiles a function. Default: `False`
  * trace_source (`bool`) – Whether to emit when TorchDynamo begins tracing a new line. Default: `False`
  * trace_call (`bool`) – Whether to emit detailed line location when TorchDynamo creates an FX node corresponding to function call. Python 3.11+ only. Default: `False`
  * output_code (`bool`) – Whether to emit the TorchInductor output code. Default: `False`
  * schedule (`bool`) – Whether to emit the TorchInductor schedule. Default: `False`
  * perf_hints (`bool`) – Whether to emit the TorchInductor perf hints. Default: `False`
  * onnx_diagnostics (`bool`) – Whether to emit the ONNX exporter diagnostics in logging. Default: `False`
  * modules (dict) – This argument provides an alternate way to specify the above log component and artifact settings, in the format of a keyword args dictionary given as a single argument. There are two cases where this is useful (1) if a new log component or artifact has been registered but a keyword argument for it has not been added to this function and (2) if the log level for an unregistered module needs to be set. This can be done by providing the fully-qualified module name as the key, with the log level as the value. Default: `None`

Example:

    
    >>> import logging
    
    # The following changes the "dynamo" component to emit DEBUG-level
    # logs, and to emit "graph_code" artifacts.
    
    >>> torch._logging.set_logs(dynamo=logging.DEBUG, graph_code=True)
    
    # The following enables the logs for a different module
    
    >>> torch._logging.set_logs(modules={"unregistered.module.name": logging.DEBUG})
    
© 2024, PyTorch Contributors  
PyTorch has a BSD-style license, as found in the LICENSE file.  
https://pytorch.org/docs/2.1/generated/torch._logging.set_logs.html

  *[ISP]: Internet Service Provider
  *[LIFO]: last-in, first-out
  *[FIFO]: first-in, first-out

