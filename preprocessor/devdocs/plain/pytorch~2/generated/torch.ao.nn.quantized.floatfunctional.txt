# FloatFunctional

`class torch.ao.nn.quantized.FloatFunctional` [source]

    
State collector class for float operations.

The instance of this class can be used instead of the `torch.` prefix for some
operations. See example usage below.

Note

This class does not provide a `forward` hook. Instead, you must use one of the
underlying functions (e.g. `add`).

Examples:

    
    >>> f_add = FloatFunctional()
    >>> a = torch.tensor(3.0)
    >>> b = torch.tensor(4.0)
    >>> f_add.add(a, b)  # Equivalent to ``torch.add(a, b)``
    
Valid operation names:

    
  * add
  * cat
  * mul
  * add_relu
  * add_scalar
  * mul_scalar

Â© 2024, PyTorch Contributors  
PyTorch has a BSD-style license, as found in the LICENSE file.  
https://pytorch.org/docs/2.1/generated/torch.ao.nn.quantized.FloatFunctional.html

  *[ISP]: Internet Service Provider
  *[LIFO]: last-in, first-out
  *[FIFO]: first-in, first-out

