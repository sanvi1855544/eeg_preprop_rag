# pandas.read_pickle

pandas.read_pickle(filepath_or_buffer, compression='infer',
storage_options=None)[source]

    
Load pickled pandas object (or any object) from file.

Warning

Loading pickled data received from untrusted sources can be unsafe. See here.

Parameters

    
filepath_or_buffer:str, path object, or file-like object

    
String, path object (implementing `os.PathLike[str]`), or file-like object
implementing a binary `readlines()` function.

Changed in version 1.0.0: Accept URL. URL is not limited to S3 and GCS.

compression:str or dict, default ‘infer’

    
For on-the-fly decompression of on-disk data. If ‘infer’ and
‘filepath_or_buffer’ is path-like, then detect compression from the following
extensions: ‘.gz’, ‘.bz2’, ‘.zip’, ‘.xz’, or ‘.zst’ (otherwise no
compression). If using ‘zip’, the ZIP file must contain only one data file to
be read in. Set to `None` for no decompression. Can also be a dict with key
`'method'` set to one of {`'zip'`, `'gzip'`, `'bz2'`, `'zstd'`} and other key-
value pairs are forwarded to `zipfile.ZipFile`, `gzip.GzipFile`,
`bz2.BZ2File`, or `zstandard.ZstdDecompressor`, respectively. As an example,
the following could be passed for Zstandard decompression using a custom
compression dictionary: `compression={'method': 'zstd', 'dict_data':
my_compression_dict}`.

Changed in version 1.4.0: Zstandard support.

storage_options:dict, optional

    
Extra options that make sense for a particular storage connection, e.g. host,
port, username, password, etc. For HTTP(S) URLs the key-value pairs are
forwarded to `urllib` as header options. For other URLs (e.g. starting with
“s3://”, and “gcs://”) the key-value pairs are forwarded to `fsspec`. Please
see `fsspec` and `urllib` for more details.

New in version 1.2.0.

Returns

    
unpickled:same type as object stored in file

See also

`DataFrame.to_pickle`

    
Pickle (serialize) DataFrame object to file.

`Series.to_pickle`

    
Pickle (serialize) Series object to file.

`read_hdf`

    
Read HDF5 file into a DataFrame.

`read_sql`

    
Read SQL query or database table into a DataFrame.

`read_parquet`

    
Load a parquet object, returning a DataFrame.

Notes

read_pickle is only guaranteed to be backwards compatible to pandas 0.20.3.

Examples

    
    >>> original_df = pd.DataFrame({"foo": range(5), "bar": range(5, 10)})  
    >>> original_df  
       foo  bar
    0    0    5
    1    1    6
    2    2    7
    3    3    8
    4    4    9
    >>> pd.to_pickle(original_df, "./dummy.pkl")  
    
    
    >>> unpickled_df = pd.read_pickle("./dummy.pkl")  
    >>> unpickled_df  
       foo  bar
    0    0    5
    1    1    6
    2    2    7
    3    3    8
    4    4    9
    
© 2008–2022, AQR Capital Management, LLC, Lambda Foundry, Inc. and PyData
Development Team  
Licensed under the 3-clause BSD License.  
https://pandas.pydata.org/pandas-
docs/version/1.4.0/reference/api/pandas.read_pickle.html

