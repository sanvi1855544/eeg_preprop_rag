# Scalable learning with polynomial kernel aproximation

This example illustrates the use of `PolynomialCountSketch` to efficiently
generate polynomial kernel feature-space approximations. This is used to train
linear classifiers that approximate the accuracy of kernelized ones.

We use the Covtype dataset [2], trying to reproduce the experiments on the
original paper of Tensor Sketch [1], i.e. the algorithm implemented by
`PolynomialCountSketch`.

First, we compute the accuracy of a linear classifier on the original
features. Then, we train linear classifiers on different numbers of features
(`n_components`) generated by `PolynomialCountSketch`, approximating the
accuracy of a kernelized classifier in a scalable manner.

    
    print(__doc__)
    
    # Author: Daniel Lopez-Sanchez <lope@usal.es>
    # License: BSD 3 clause
    import matplotlib.pyplot as plt
    from sklearn.datasets import fetch_covtype
    from sklearn.model_selection import train_test_split
    from sklearn.preprocessing import MinMaxScaler, Normalizer
    from sklearn.svm import LinearSVC
    from sklearn.kernel_approximation import PolynomialCountSketch
    from sklearn.pipeline import Pipeline, make_pipeline
    import time
    
Load the Covtype dataset, which contains 581,012 samples with 54 features
each, distributed among 6 classes. The goal of this dataset is to predict
forest cover type from cartographic variables only (no remotely sensed data).
After loading, we transform it into a binary classification problem to match
the version of the dataset in the LIBSVM webpage [2], which was the one used
in [1].

    
    X, y = fetch_covtype(return_X_y=True)
    
    y[y != 2] = 0
    y[y == 2] = 1  # We will try to separate class 2 from the other 6 classes.
    
Here we select 5,000 samples for training and 10,000 for testing. To actually
reproduce the results in the original Tensor Sketch paper, select 100,000 for
training.

    
    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=5_000,
                                                        test_size=10_000,
                                                        random_state=42)
    
Now scale features to the range [0, 1] to match the format of the dataset in
the LIBSVM webpage, and then normalize to unit length as done in the original
Tensor Sketch paper [1].

    
    mm = make_pipeline(MinMaxScaler(), Normalizer())
    X_train = mm.fit_transform(X_train)
    X_test = mm.transform(X_test)
    
As a baseline, train a linear SVM on the original features and print the
accuracy. We also measure and store accuracies and training times to plot them
latter.

    
    results = {}
    
    lsvm = LinearSVC()
    start = time.time()
    lsvm.fit(X_train, y_train)
    lsvm_time = time.time() - start
    lsvm_score = 100 * lsvm.score(X_test, y_test)
    
    results["LSVM"] = {"time": lsvm_time, "score": lsvm_score}
    print(f"Linear SVM score on raw features: {lsvm_score:.2f}%")
    
Out:

    
    Linear SVM score on raw features: 75.62%
    
Then we train linear SVMs on the features generated by `PolynomialCountSketch`
with different values for `n_components`, showing that these kernel feature
approximations improve the accuracy of linear classification. In typical
application scenarios, `n_components` should be larger than the number of
features in the input representation in order to achieve an improvement with
respect to linear classification. As a rule of thumb, the optimum of
evaluation score / run time cost is typically achieved at around
`n_components` = 10 * `n_features`, though this might depend on the specific
dataset being handled. Note that, since the original samples have 54 features,
the explicit feature map of the polynomial kernel of degree four would have
approximately 8.5 million features (precisely, 54^4). Thanks to
`PolynomialCountSketch`, we can condense most of the discriminative
information of that feature space into a much more compact representation. We
repeat the experiment 5 times to compensate for the stochastic nature of
`PolynomialCountSketch`.

    
    n_runs = 3
    for n_components in [250, 500, 1000, 2000]:
    
        ps_lsvm_time = 0
        ps_lsvm_score = 0
        for _ in range(n_runs):
    
            pipeline = Pipeline(steps=[("kernel_approximator",
                                        PolynomialCountSketch(
                                            n_components=n_components,
                                            degree=4)),
                                       ("linear_classifier", LinearSVC())])
    
            start = time.time()
            pipeline.fit(X_train, y_train)
            ps_lsvm_time += time.time() - start
            ps_lsvm_score += 100 * pipeline.score(X_test, y_test)
    
        ps_lsvm_time /= n_runs
        ps_lsvm_score /= n_runs
    
        results[f"LSVM + PS({n_components})"] = {
            "time": ps_lsvm_time, "score": ps_lsvm_score
        }
        print(f"Linear SVM score on {n_components} PolynomialCountSketch " +
              f"features: {ps_lsvm_score:.2f}%")
    
Out:

    
    Linear SVM score on 250 PolynomialCountSketch features: 76.25%
    Linear SVM score on 500 PolynomialCountSketch features: 77.40%
    Linear SVM score on 1000 PolynomialCountSketch features: 78.11%
    Linear SVM score on 2000 PolynomialCountSketch features: 78.17%
    
Train a kernelized SVM to see how well `PolynomialCountSketch` is
approximating the performance of the kernel. This, of course, may take some
time, as the SVC class has a relatively poor scalability. This is the reason
why kernel approximators are so useful:

    
    from sklearn.svm import SVC
    
    ksvm = SVC(C=500., kernel="poly", degree=4, coef0=0, gamma=1.)
    
    start = time.time()
    ksvm.fit(X_train, y_train)
    ksvm_time = time.time() - start
    ksvm_score = 100 * ksvm.score(X_test, y_test)
    
    results["KSVM"] = {"time": ksvm_time, "score": ksvm_score}
    print(f"Kernel-SVM score on raw featrues: {ksvm_score:.2f}%")
    
Out:

    
    Kernel-SVM score on raw featrues: 79.77%
    
Finally, plot the resuts of the different methods against their training
times. As we can see, the kernelized SVM achieves a higher accuracy, but its
training time is much larger and, most importantly, will grow much faster if
the number of training samples increases.

    
    N_COMPONENTS = [250, 500, 1000, 2000]
    
    fig, ax = plt.subplots(figsize=(7, 7))
    ax.scatter([results["LSVM"]["time"], ], [results["LSVM"]["score"], ],
               label="Linear SVM", c="green", marker="^")
    
    ax.scatter([results["LSVM + PS(250)"]["time"], ],
               [results["LSVM + PS(250)"]["score"], ],
               label="Linear SVM + PolynomialCountSketch", c="blue")
    for n_components in N_COMPONENTS:
        ax.scatter([results[f"LSVM + PS({n_components})"]["time"], ],
                   [results[f"LSVM + PS({n_components})"]["score"], ],
                   c="blue")
        ax.annotate(f"n_comp.={n_components}",
                    (results[f"LSVM + PS({n_components})"]["time"],
                     results[f"LSVM + PS({n_components})"]["score"]),
                    xytext=(-30, 10), textcoords="offset pixels")
    
    ax.scatter([results["KSVM"]["time"], ], [results["KSVM"]["score"], ],
               label="Kernel SVM", c="red", marker="x")
    
    ax.set_xlabel("Training time (s)")
    ax.set_ylabel("Accurary (%)")
    ax.legend()
    plt.show()
    
![plot scalable poly
kernels](data:image/png;base64,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)

## References

[1] Pham, Ninh and Rasmus Pagh. “Fast and scalable polynomial kernels via
explicit feature maps.” KDD ‘13 (2013).
https://doi.org/10.1145/2487575.2487591

[2] LIBSVM binary datasets repository
https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary.html

Total running time of the script: ( 0 minutes 55.169 seconds)

![Launch
binder](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAG0AAAAUCAMAAACwC0NtAAABWVBMVEW7u7vo6OjCwsLMzMzz8/P4+Pju7u68vLzd3d24uLjx8fHm5ubT09PAwMDJycnPz8+urq7Ly8va2tq5ubnq6uqSkpLBwcH09PS6urrypVmvr6/i4uLDw8O0tLSjo6PX19e9u7pYm8qxsbGrq6u+vr7s7OzZ2dng4OCVlZXk5OTIyMiWlpampqaoqKj6+vrGxsagoKC9vb2ZmZn29vb///+Nq8Kzs7PSspNlnshfnsr2o1HnZYHXc46dnZ2Li4vS0tKPj4+3t7fOtJm2urztpmKGqsTarYFcmsnTjZzkaYXOl6Kqtr7lqnHEqrD1olLMmqW+t7jWsIzGt6hrnsbQk6Gis7/IoavgbIfhcoprlcHYaom+oH2Elq50kLzV1dWHh4fDuK2Xr8GZsMDHtqatsLrglH/sfm60pLHKqqDWnJHJcJDtgWzoknG8dJaLqr/0lVqeo7jlbX7owswW4TTQAAACXklEQVRIx+3V52/iMBgH4DcsBwfCCCkhQICMS4G0AQKUXqFpumh7Pa57l9t7//9fzlRHWeXbCemkvpEs+ZWtR/rZVqAKj/WvK7u+v7m/np2RdpjokG9pNthRIrF0dJjYfDWLGM/ed76dAWx31v923NS0tWXvRCtD90bTN9Sy1Ona3u6Hp1939+Cw04/SRU9bizwTLTbUG9OtoRZGU7Hn5xefEz9/Nz9tJt4ONDOGky7Q52AuCbStYRvKOmZcyENjKjWqPYnFdZSiQbd9vhCkyMyDUBQzBbC7WmhMe7Gyk92+vrm9ud7ODjRKLQZoiKmgakBTRcULdKboZlDVXMtERzWvMU915xhgknwag2auRaook2/JlhqKi+EJ7QR+5NqX7XYNBtq8wtIZYFQoUxAtc2ELsORIYbS4AGpgLEnZqetqHpKOIGLVKwnSIqIKrKkVIm6FG09y9+Jj4/Z789fy8rOBlsddd7enBYlGDt0Cyw+CiDwcmGOaDRC808ix+lRysIKFtG4g4IKIe/JK7qycf7kicW7l3txrQS9fYomWAptoqZ6mu8HEvVsyrmkIomxPCxLNwQVgSZKpkkT7I6HJa3Jw0rxq7h3AVu71veaPMfkkNlmc1PuaEs/HOYSJZo9qOo5pRl8D0aI0DRkeBnedhzSAd5fHpxunjfskw0Xg5YV5w9+qiBUeigrASxD5esXgVgGM1shmg68srDkyT7aAfxUUXuFXuTovSxWQSg++gq3c8nE7VxvqcOE6iA6kRRD6LSecfvgNObIwPBOFu/3y1De3UWvkGrWNx9/T/1B/AFudUABdgF9sAAAAAElFTkSuQmCC)

`Download Python source code: plot_scalable_poly_kernels.py`

`Download Jupyter notebook: plot_scalable_poly_kernels.ipynb`

© 2007–2020 The scikit-learn developers  
Licensed under the 3-clause BSD License.  
https://scikit-
learn.org/0.24/auto_examples/kernel_approximation/plot_scalable_poly_kernels.html

