# L1 Penalty and Sparsity in Logistic Regression

Comparison of the sparsity (percentage of zero coefficients) of solutions when
L1, L2 and Elastic-Net penalty are used for different values of C. We can see
that large values of C give more freedom to the model. Conversely, smaller
values of C constrain the model more. In the L1 penalty case, this leads to
sparser solutions. As expected, the Elastic-Net penalty sparsity is between
that of L1 and L2.

We classify 8x8 images of digits into two classes: 0-4 against 5-9. The
visualization shows coefficients of the models for varying C.

![L1 penalty, Elastic-Net l1_ratio = 0.5, L2
penalty](data:image/png;base64,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)

Out:

    
    C=1.00
    Sparsity with L1 penalty:                6.25%
    Sparsity with Elastic-Net penalty:       4.69%
    Sparsity with L2 penalty:                4.69%
    Score with L1 penalty:                   0.90
    Score with Elastic-Net penalty:          0.90
    Score with L2 penalty:                   0.90
    C=0.10
    Sparsity with L1 penalty:                29.69%
    Sparsity with Elastic-Net penalty:       12.50%
    Sparsity with L2 penalty:                4.69%
    Score with L1 penalty:                   0.90
    Score with Elastic-Net penalty:          0.90
    Score with L2 penalty:                   0.90
    C=0.01
    Sparsity with L1 penalty:                84.38%
    Sparsity with Elastic-Net penalty:       68.75%
    Sparsity with L2 penalty:                4.69%
    Score with L1 penalty:                   0.86
    Score with Elastic-Net penalty:          0.88
    Score with L2 penalty:                   0.89
    
    
    print(__doc__)
    
    # Authors: Alexandre Gramfort <alexandre.gramfort@inria.fr>
    #          Mathieu Blondel <mathieu@mblondel.org>
    #          Andreas Mueller <amueller@ais.uni-bonn.de>
    # License: BSD 3 clause
    
    import numpy as np
    import matplotlib.pyplot as plt
    
    from sklearn.linear_model import LogisticRegression
    from sklearn import datasets
    from sklearn.preprocessing import StandardScaler
    
    X, y = datasets.load_digits(return_X_y=True)
    
    X = StandardScaler().fit_transform(X)
    
    # classify small against large digits
    y = (y > 4).astype(int)
    
    l1_ratio = 0.5  # L1 weight in the Elastic-Net regularization
    
    fig, axes = plt.subplots(3, 3)
    
    # Set regularization parameter
    for i, (C, axes_row) in enumerate(zip((1, 0.1, 0.01), axes)):
        # turn down tolerance for short training time
        clf_l1_LR = LogisticRegression(C=C, penalty='l1', tol=0.01, solver='saga')
        clf_l2_LR = LogisticRegression(C=C, penalty='l2', tol=0.01, solver='saga')
        clf_en_LR = LogisticRegression(C=C, penalty='elasticnet', solver='saga',
                                       l1_ratio=l1_ratio, tol=0.01)
        clf_l1_LR.fit(X, y)
        clf_l2_LR.fit(X, y)
        clf_en_LR.fit(X, y)
    
        coef_l1_LR = clf_l1_LR.coef_.ravel()
        coef_l2_LR = clf_l2_LR.coef_.ravel()
        coef_en_LR = clf_en_LR.coef_.ravel()
    
        # coef_l1_LR contains zeros due to the
        # L1 sparsity inducing norm
    
        sparsity_l1_LR = np.mean(coef_l1_LR == 0) * 100
        sparsity_l2_LR = np.mean(coef_l2_LR == 0) * 100
        sparsity_en_LR = np.mean(coef_en_LR == 0) * 100
    
        print("C=%.2f" % C)
        print("{:<40} {:.2f}%".format("Sparsity with L1 penalty:", sparsity_l1_LR))
        print("{:<40} {:.2f}%".format("Sparsity with Elastic-Net penalty:",
                                      sparsity_en_LR))
        print("{:<40} {:.2f}%".format("Sparsity with L2 penalty:", sparsity_l2_LR))
        print("{:<40} {:.2f}".format("Score with L1 penalty:",
                                     clf_l1_LR.score(X, y)))
        print("{:<40} {:.2f}".format("Score with Elastic-Net penalty:",
                                     clf_en_LR.score(X, y)))
        print("{:<40} {:.2f}".format("Score with L2 penalty:",
                                     clf_l2_LR.score(X, y)))
    
        if i == 0:
            axes_row[0].set_title("L1 penalty")
            axes_row[1].set_title("Elastic-Net\nl1_ratio = %s" % l1_ratio)
            axes_row[2].set_title("L2 penalty")
    
        for ax, coefs in zip(axes_row, [coef_l1_LR, coef_en_LR, coef_l2_LR]):
            ax.imshow(np.abs(coefs.reshape(8, 8)), interpolation='nearest',
                      cmap='binary', vmax=1, vmin=0)
            ax.set_xticks(())
            ax.set_yticks(())
    
        axes_row[0].set_ylabel('C = %s' % C)
    
    plt.show()
    
Total running time of the script: ( 0 minutes 0.723 seconds)

![Launch
binder](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAG0AAAAUCAMAAACwC0NtAAABWVBMVEW7u7vo6OjCwsLMzMzz8/P4+Pju7u68vLzd3d24uLjx8fHm5ubT09PAwMDJycnPz8+urq7Ly8va2tq5ubnq6uqSkpLBwcH09PS6urrypVmvr6/i4uLDw8O0tLSjo6PX19e9u7pYm8qxsbGrq6u+vr7s7OzZ2dng4OCVlZXk5OTIyMiWlpampqaoqKj6+vrGxsagoKC9vb2ZmZn29vb///+Nq8Kzs7PSspNlnshfnsr2o1HnZYHXc46dnZ2Li4vS0tKPj4+3t7fOtJm2urztpmKGqsTarYFcmsnTjZzkaYXOl6Kqtr7lqnHEqrD1olLMmqW+t7jWsIzGt6hrnsbQk6Gis7/IoavgbIfhcoprlcHYaom+oH2Elq50kLzV1dWHh4fDuK2Xr8GZsMDHtqatsLrglH/sfm60pLHKqqDWnJHJcJDtgWzoknG8dJaLqr/0lVqeo7jlbX7owswW4TTQAAACXklEQVRIx+3V52/iMBgH4DcsBwfCCCkhQICMS4G0AQKUXqFpumh7Pa57l9t7//9fzlRHWeXbCemkvpEs+ZWtR/rZVqAKj/WvK7u+v7m/np2RdpjokG9pNthRIrF0dJjYfDWLGM/ed76dAWx31v923NS0tWXvRCtD90bTN9Sy1Ona3u6Hp1939+Cw04/SRU9bizwTLTbUG9OtoRZGU7Hn5xefEz9/Nz9tJt4ONDOGky7Q52AuCbStYRvKOmZcyENjKjWqPYnFdZSiQbd9vhCkyMyDUBQzBbC7WmhMe7Gyk92+vrm9ud7ODjRKLQZoiKmgakBTRcULdKboZlDVXMtERzWvMU915xhgknwag2auRaook2/JlhqKi+EJ7QR+5NqX7XYNBtq8wtIZYFQoUxAtc2ELsORIYbS4AGpgLEnZqetqHpKOIGLVKwnSIqIKrKkVIm6FG09y9+Jj4/Z789fy8rOBlsddd7enBYlGDt0Cyw+CiDwcmGOaDRC808ix+lRysIKFtG4g4IKIe/JK7qycf7kicW7l3txrQS9fYomWAptoqZ6mu8HEvVsyrmkIomxPCxLNwQVgSZKpkkT7I6HJa3Jw0rxq7h3AVu71veaPMfkkNlmc1PuaEs/HOYSJZo9qOo5pRl8D0aI0DRkeBnedhzSAd5fHpxunjfskw0Xg5YV5w9+qiBUeigrASxD5esXgVgGM1shmg68srDkyT7aAfxUUXuFXuTovSxWQSg++gq3c8nE7VxvqcOE6iA6kRRD6LSecfvgNObIwPBOFu/3y1De3UWvkGrWNx9/T/1B/AFudUABdgF9sAAAAAElFTkSuQmCC)

`Download Python source code: plot_logistic_l1_l2_sparsity.py`

`Download Jupyter notebook: plot_logistic_l1_l2_sparsity.ipynb`

© 2007–2020 The scikit-learn developers  
Licensed under the 3-clause BSD License.  
https://scikit-
learn.org/0.24/auto_examples/linear_model/plot_logistic_l1_l2_sparsity.html

