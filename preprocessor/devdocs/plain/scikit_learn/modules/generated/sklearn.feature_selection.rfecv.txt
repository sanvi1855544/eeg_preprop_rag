# sklearn.feature_selection.RFECV

`class sklearn.feature_selection.RFECV(estimator, *, step=1,
min_features_to_select=1, cv=None, scoring=None, verbose=0, n_jobs=None,
importance_getter='auto')` [source]

    
Feature ranking with recursive feature elimination and cross-validated
selection of the best number of features.

See glossary entry for cross-validation estimator.

Read more in the User Guide.

Parameters

    
`estimatorEstimator instance`

    
A supervised learning estimator with a `fit` method that provides information
about feature importance either through a `coef_` attribute or through a
`feature_importances_` attribute.

`stepint or float, default=1`

    
If greater than or equal to 1, then `step` corresponds to the (integer) number
of features to remove at each iteration. If within (0.0, 1.0), then `step`
corresponds to the percentage (rounded down) of features to remove at each
iteration. Note that the last iteration may remove fewer than `step` features
in order to reach `min_features_to_select`.

`min_features_to_selectint, default=1`

    
The minimum number of features to be selected. This number of features will
always be scored, even if the difference between the original feature count
and `min_features_to_select` isn’t divisible by `step`.

New in version 0.20.

`cvint, cross-validation generator or an iterable, default=None`

    
Determines the cross-validation splitting strategy. Possible inputs for cv
are:

  * None, to use the default 5-fold cross-validation,
  * integer, to specify the number of folds.
  * CV splitter,
  * An iterable yielding (train, test) splits as arrays of indices.

For integer/None inputs, if `y` is binary or multiclass, `StratifiedKFold` is
used. If the estimator is a classifier or if `y` is neither binary nor
multiclass, `KFold` is used.

Refer User Guide for the various cross-validation strategies that can be used
here.

Changed in version 0.22: `cv` default value of None changed from 3-fold to
5-fold.

`scoringstring, callable or None, default=None`

    
A string (see model evaluation documentation) or a scorer callable object /
function with signature `scorer(estimator, X, y)`.

`verboseint, default=0`

    
Controls verbosity of output.

`n_jobsint or None, default=None`

    
Number of cores to run in parallel while fitting across folds. `None` means 1
unless in a `joblib.parallel_backend` context. `-1` means using all
processors. See Glossary for more details.

New in version 0.18.

`importance_getterstr or callable, default=’auto’`

    
If ‘auto’, uses the feature importance either through a `coef_` or
`feature_importances_` attributes of estimator.

Also accepts a string that specifies an attribute name/path for extracting
feature importance. For example, give `regressor_.coef_` in case of
`TransformedTargetRegressor` or `named_steps.clf.feature_importances_` in case
of `Pipeline` with its last step named `clf`.

If `callable`, overrides the default feature importance getter. The callable
is passed with the fitted estimator and it should return importance for each
feature.

New in version 0.24.

Attributes

    
`estimator_Estimator instance`

    
The fitted estimator used to select features.

`grid_scores_ndarray of shape (n_subsets_of_features,)`

    
The cross-validation scores such that `grid_scores_[i]` corresponds to the CV
score of the i-th subset of features.

`n_features_int`

    
The number of selected features with cross-validation.

`ranking_narray of shape (n_features,)`

    
The feature ranking, such that `ranking_[i]` corresponds to the ranking
position of the i-th feature. Selected (i.e., estimated best) features are
assigned rank 1.

`support_ndarray of shape (n_features,)`

    
The mask of selected features.

See also

`RFE`

    
Recursive feature elimination.

#### Notes

The size of `grid_scores_` is equal to `ceil((n_features -
min_features_to_select) / step) + 1`, where step is the number of features
removed at each iteration.

Allows NaN/Inf in the input if the underlying estimator does as well.

#### References

`1`

    
Guyon, I., Weston, J., Barnhill, S., & Vapnik, V., “Gene selection for cancer
classification using support vector machines”, Mach. Learn., 46(1-3), 389–422,
2002.

#### Examples

The following example shows how to retrieve the a-priori not known 5
informative features in the Friedman #1 dataset.

    
    >>> from sklearn.datasets import make_friedman1
    >>> from sklearn.feature_selection import RFECV
    >>> from sklearn.svm import SVR
    >>> X, y = make_friedman1(n_samples=50, n_features=10, random_state=0)
    >>> estimator = SVR(kernel="linear")
    >>> selector = RFECV(estimator, step=1, cv=5)
    >>> selector = selector.fit(X, y)
    >>> selector.support_
    array([ True,  True,  True,  True,  True, False, False, False, False,
           False])
    >>> selector.ranking_
    array([1, 1, 1, 1, 1, 6, 4, 3, 2, 5])
    
#### Methods

`decision_function`(X) | Compute the decision function of `X`.  
---|---  
`fit`(X, y[, groups]) | Fit the RFE model and automatically tune the number of selected  
`fit_transform`(X[, y]) | Fit to data, then transform it.  
`get_params`([deep]) | Get parameters for this estimator.  
`get_support`([indices]) | Get a mask, or integer index, of the features selected  
`inverse_transform`(X) | Reverse the transformation operation  
`predict`(X) | Reduce X to the selected features and then predict using the  
`predict_log_proba`(X) | Predict class log-probabilities for X.  
`predict_proba`(X) | Predict class probabilities for X.  
`score`(X, y) | Reduce X to the selected features and then return the score of the  
`set_params`(**params) | Set the parameters of this estimator.  
`transform`(X) | Reduce X to the selected features.  
`decision_function(X)` [source]

    
Compute the decision function of `X`.

Parameters

    
`X{array-like or sparse matrix} of shape (n_samples, n_features)`

    
The input samples. Internally, it will be converted to `dtype=np.float32` and
if a sparse matrix is provided to a sparse `csr_matrix`.

Returns

    
`scorearray, shape = [n_samples, n_classes] or [n_samples]`

    
The decision function of the input samples. The order of the classes
corresponds to that in the attribute classes_. Regression and binary
classification produce an array of shape [n_samples].

`fit(X, y, groups=None)` [source]

    
Fit the RFE model and automatically tune the number of selected

    
features.

Parameters

    
`X{array-like, sparse matrix} of shape (n_samples, n_features)`

    
Training vector, where `n_samples` is the number of samples and `n_features`
is the total number of features.

`yarray-like of shape (n_samples,)`

    
Target values (integers for classification, real numbers for regression).

`groupsarray-like of shape (n_samples,) or None, default=None`

    
Group labels for the samples used while splitting the dataset into train/test
set. Only used in conjunction with a “Group” cv instance (e.g., `GroupKFold`).

New in version 0.20.

`fit_transform(X, y=None, **fit_params)` [source]

    
Fit to data, then transform it.

Fits transformer to `X` and `y` with optional parameters `fit_params` and
returns a transformed version of `X`.

Parameters

    
`Xarray-like of shape (n_samples, n_features)`

    
Input samples.

`yarray-like of shape (n_samples,) or (n_samples, n_outputs), default=None`

    
Target values (None for unsupervised transformations).

`**fit_paramsdict`

    
Additional fit parameters.

Returns

    
`X_newndarray array of shape (n_samples, n_features_new)`

    
Transformed array.

`get_params(deep=True)` [source]

    
Get parameters for this estimator.

Parameters

    
`deepbool, default=True`

    
If True, will return the parameters for this estimator and contained
subobjects that are estimators.

Returns

    
`paramsdict`

    
Parameter names mapped to their values.

`get_support(indices=False)` [source]

    
Get a mask, or integer index, of the features selected

Parameters

    
`indicesbool, default=False`

    
If True, the return value will be an array of integers, rather than a boolean
mask.

Returns

    
`supportarray`

    
An index that selects the retained features from a feature vector. If
`indices` is False, this is a boolean array of shape [# input features], in
which an element is True iff its corresponding feature is selected for
retention. If `indices` is True, this is an integer array of shape [# output
features] whose values are indices into the input feature vector.

`inverse_transform(X)` [source]

    
Reverse the transformation operation

Parameters

    
`Xarray of shape [n_samples, n_selected_features]`

    
The input samples.

Returns

    
`X_rarray of shape [n_samples, n_original_features]`

    
`X` with columns of zeros inserted where features would have been removed by
`transform`.

`predict(X)` [source]

    
Reduce X to the selected features and then predict using the

    
underlying estimator.

Parameters

    
`Xarray of shape [n_samples, n_features]`

    
The input samples.

Returns

    
`yarray of shape [n_samples]`

    
The predicted target values.

`predict_log_proba(X)` [source]

    
Predict class log-probabilities for X.

Parameters

    
`Xarray of shape [n_samples, n_features]`

    
The input samples.

Returns

    
`parray of shape (n_samples, n_classes)`

    
The class log-probabilities of the input samples. The order of the classes
corresponds to that in the attribute classes_.

`predict_proba(X)` [source]

    
Predict class probabilities for X.

Parameters

    
`X{array-like or sparse matrix} of shape (n_samples, n_features)`

    
The input samples. Internally, it will be converted to `dtype=np.float32` and
if a sparse matrix is provided to a sparse `csr_matrix`.

Returns

    
`parray of shape (n_samples, n_classes)`

    
The class probabilities of the input samples. The order of the classes
corresponds to that in the attribute classes_.

`score(X, y)` [source]

    
Reduce X to the selected features and then return the score of the

    
underlying estimator.

Parameters

    
`Xarray of shape [n_samples, n_features]`

    
The input samples.

`yarray of shape [n_samples]`

    
The target values.

`set_params(**params)` [source]

    
Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as
`Pipeline`). The latter have parameters of the form `<component>__<parameter>`
so that it’s possible to update each component of a nested object.

Parameters

    
`**paramsdict`

    
Estimator parameters.

Returns

    
`selfestimator instance`

    
Estimator instance.

`transform(X)` [source]

    
Reduce X to the selected features.

Parameters

    
`Xarray of shape [n_samples, n_features]`

    
The input samples.

Returns

    
`X_rarray of shape [n_samples, n_selected_features]`

    
The input samples with only the selected features.

## Examples using `sklearn.feature_selection.RFECV`

![Recursive feature elimination with cross-
validation](data:image/png;base64,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)

Recursive feature elimination with cross-validation

© 2007–2020 The scikit-learn developers  
Licensed under the 3-clause BSD License.  
https://scikit-
learn.org/0.24/modules/generated/sklearn.feature_selection.RFECV.html

