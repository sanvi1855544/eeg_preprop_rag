# sklearn.linear_model.Lars

`class sklearn.linear_model.Lars(*, fit_intercept=True, verbose=False,
normalize=True, precompute='auto', n_nonzero_coefs=500,
eps=2.220446049250313e-16, copy_X=True, fit_path=True, jitter=None,
random_state=None)` [source]

    
Least Angle Regression model a.k.a. LAR

Read more in the User Guide.

Parameters

    
`fit_interceptbool, default=True`

    
Whether to calculate the intercept for this model. If set to false, no
intercept will be used in calculations (i.e. data is expected to be centered).

`verbosebool or int, default=False`

    
Sets the verbosity amount.

`normalizebool, default=True`

    
This parameter is ignored when `fit_intercept` is set to False. If True, the
regressors X will be normalized before regression by subtracting the mean and
dividing by the l2-norm. If you wish to standardize, please use
`StandardScaler` before calling `fit` on an estimator with `normalize=False`.

`precomputebool, ‘auto’ or array-like , default=’auto’`

    
Whether to use a precomputed Gram matrix to speed up calculations. If set to
`'auto'` let us decide. The Gram matrix can also be passed as argument.

`n_nonzero_coefsint, default=500`

    
Target number of non-zero coefficients. Use `np.inf` for no limit.

`epsfloat, default=np.finfo(float).eps`

    
The machine-precision regularization in the computation of the Cholesky
diagonal factors. Increase this for very ill-conditioned systems. Unlike the
`tol` parameter in some iterative optimization-based algorithms, this
parameter does not control the tolerance of the optimization.

`copy_Xbool, default=True`

    
If `True`, X will be copied; else, it may be overwritten.

`fit_pathbool, default=True`

    
If True the full path is stored in the `coef_path_` attribute. If you compute
the solution for a large problem or many targets, setting `fit_path` to
`False` will lead to a speedup, especially with a small alpha.

`jitterfloat, default=None`

    
Upper bound on a uniform noise parameter to be added to the `y` values, to
satisfy the model’s assumption of one-at-a-time computations. Might help with
stability.

New in version 0.23.

`random_stateint, RandomState instance or None, default=None`

    
Determines random number generation for jittering. Pass an int for
reproducible output across multiple function calls. See Glossary. Ignored if
`jitter` is None.

New in version 0.23.

Attributes

    
`alphas_array-like of shape (n_alphas + 1,) or list of such arrays`

    
Maximum of covariances (in absolute value) at each iteration. `n_alphas` is
either `max_iter`, `n_features` or the number of nodes in the path with `alpha
>= alpha_min`, whichever is smaller. If this is a list of array-like, the
length of the outer list is `n_targets`.

`active_list of shape (n_alphas,) or list of such lists`

    
Indices of active variables at the end of the path. If this is a list of list,
the length of the outer list is `n_targets`.

`coef_path_array-like of shape (n_features, n_alphas + 1) or list of such
arrays`

    
The varying values of the coefficients along the path. It is not present if
the `fit_path` parameter is `False`. If this is a list of array-like, the
length of the outer list is `n_targets`.

`coef_array-like of shape (n_features,) or (n_targets, n_features)`

    
Parameter vector (w in the formulation formula).

`intercept_float or array-like of shape (n_targets,)`

    
Independent term in decision function.

`n_iter_array-like or int`

    
The number of iterations taken by lars_path to find the grid of alphas for
each target.

See also

`lars_path,` `LarsCV`

`sklearn.decomposition.sparse_encode`

#### Examples

    
    >>> from sklearn import linear_model
    >>> reg = linear_model.Lars(n_nonzero_coefs=1)
    >>> reg.fit([[-1, 1], [0, 0], [1, 1]], [-1.1111, 0, -1.1111])
    Lars(n_nonzero_coefs=1)
    >>> print(reg.coef_)
    [ 0. -1.11...]
    
#### Methods

`fit`(X, y[, Xy]) | Fit the model using X, y as training data.  
---|---  
`get_params`([deep]) | Get parameters for this estimator.  
`predict`(X) | Predict using the linear model.  
`score`(X, y[, sample_weight]) | Return the coefficient of determination \\(R^2\\) of the prediction.  
`set_params`(**params) | Set the parameters of this estimator.  
`fit(X, y, Xy=None)` [source]

    
Fit the model using X, y as training data.

Parameters

    
`Xarray-like of shape (n_samples, n_features)`

    
Training data.

`yarray-like of shape (n_samples,) or (n_samples, n_targets)`

    
Target values.

`Xyarray-like of shape (n_samples,) or (n_samples, n_targets), default=None`

    
Xy = np.dot(X.T, y) that can be precomputed. It is useful only when the Gram
matrix is precomputed.

Returns

    
`selfobject`

    
returns an instance of self.

`get_params(deep=True)` [source]

    
Get parameters for this estimator.

Parameters

    
`deepbool, default=True`

    
If True, will return the parameters for this estimator and contained
subobjects that are estimators.

Returns

    
`paramsdict`

    
Parameter names mapped to their values.

`predict(X)` [source]

    
Predict using the linear model.

Parameters

    
`Xarray-like or sparse matrix, shape (n_samples, n_features)`

    
Samples.

Returns

    
`Carray, shape (n_samples,)`

    
Returns predicted values.

`score(X, y, sample_weight=None)` [source]

    
Return the coefficient of determination \\(R^2\\) of the prediction.

The coefficient \\(R^2\\) is defined as \\((1 - \frac{u}{v})\\), where \\(u\\)
is the residual sum of squares `((y_true - y_pred) ** 2).sum()` and \\(v\\) is
the total sum of squares `((y_true - y_true.mean()) ** 2).sum()`. The best
possible score is 1.0 and it can be negative (because the model can be
arbitrarily worse). A constant model that always predicts the expected value
of `y`, disregarding the input features, would get a \\(R^2\\) score of 0.0.

Parameters

    
`Xarray-like of shape (n_samples, n_features)`

    
Test samples. For some estimators this may be a precomputed kernel matrix or a
list of generic objects instead with shape `(n_samples, n_samples_fitted)`,
where `n_samples_fitted` is the number of samples used in the fitting for the
estimator.

`yarray-like of shape (n_samples,) or (n_samples, n_outputs)`

    
True values for `X`.

`sample_weightarray-like of shape (n_samples,), default=None`

    
Sample weights.

Returns

    
`scorefloat`

    
\\(R^2\\) of `self.predict(X)` wrt. `y`.

#### Notes

The \\(R^2\\) score used when calling `score` on a regressor uses
`multioutput='uniform_average'` from version 0.23 to keep consistent with
default value of `r2_score`. This influences the `score` method of all the
multioutput regressors (except for `MultiOutputRegressor`).

`set_params(**params)` [source]

    
Set the parameters of this estimator.

The method works on simple estimators as well as on nested objects (such as
`Pipeline`). The latter have parameters of the form `<component>__<parameter>`
so that it’s possible to update each component of a nested object.

Parameters

    
`**paramsdict`

    
Estimator parameters.

Returns

    
`selfestimator instance`

    
Estimator instance.

© 2007–2020 The scikit-learn developers  
Licensed under the 3-clause BSD License.  
https://scikit-learn.org/0.24/modules/generated/sklearn.linear_model.Lars.html

