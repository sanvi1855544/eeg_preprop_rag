# sklearn.linear_model.PassiveAggressiveRegressor

`sklearn.linear_model.PassiveAggressiveRegressor(*, C=1.0, fit_intercept=True,
max_iter=1000, tol=0.001, early_stopping=False, validation_fraction=0.1,
n_iter_no_change=5, shuffle=True, verbose=0, loss='epsilon_insensitive',
epsilon=0.1, random_state=None, warm_start=False, average=False)` [source]

    
Passive Aggressive Regressor

Read more in the User Guide.

Parameters

    
`Cfloat, default=1.0`

    
Maximum step size (regularization). Defaults to 1.0.

`fit_interceptbool, default=True`

    
Whether the intercept should be estimated or not. If False, the data is
assumed to be already centered. Defaults to True.

`max_iterint, default=1000`

    
The maximum number of passes over the training data (aka epochs). It only
impacts the behavior in the `fit` method, and not the `partial_fit` method.

New in version 0.19.

`tolfloat or None, default=1e-3`

    
The stopping criterion. If it is not None, the iterations will stop when (loss
> previous_loss - tol).

New in version 0.19.

`early_stoppingbool, default=False`

    
Whether to use early stopping to terminate training when validation. score is
not improving. If set to True, it will automatically set aside a fraction of
training data as validation and terminate training when validation score is
not improving by at least tol for n_iter_no_change consecutive epochs.

New in version 0.20.

`validation_fractionfloat, default=0.1`

    
The proportion of training data to set aside as validation set for early
stopping. Must be between 0 and 1. Only used if early_stopping is True.

New in version 0.20.

`n_iter_no_changeint, default=5`

    
Number of iterations with no improvement to wait before early stopping.

New in version 0.20.

`shufflebool, default=True`

    
Whether or not the training data should be shuffled after each epoch.

`verboseinteger, default=0`

    
The verbosity level

`lossstring, default=”epsilon_insensitive”`

    
The loss function to be used: epsilon_insensitive: equivalent to PA-I in the
reference paper. squared_epsilon_insensitive: equivalent to PA-II in the
reference paper.

`epsilonfloat, default=DEFAULT_EPSILON`

    
If the difference between the current prediction and the correct label is
below this threshold, the model is not updated.

`random_stateint, RandomState instance, default=None`

    
Used to shuffle the training data, when `shuffle` is set to `True`. Pass an
int for reproducible output across multiple function calls. See Glossary.

`warm_startbool, default=False`

    
When set to True, reuse the solution of the previous call to fit as
initialization, otherwise, just erase the previous solution. See the Glossary.

Repeatedly calling fit or partial_fit when warm_start is True can result in a
different solution than when calling fit a single time because of the way the
data is shuffled.

`averagebool or int, default=False`

    
When set to True, computes the averaged SGD weights and stores the result in
the `coef_` attribute. If set to an int greater than 1, averaging will begin
once the total number of samples seen reaches average. So average=10 will
begin averaging after seeing 10 samples.

New in version 0.19: parameter average to use weights averaging in SGD

Attributes

    
`coef_array, shape = [1, n_features] if n_classes == 2 else [n_classes,
n_features]`

    
Weights assigned to the features.

`intercept_array, shape = [1] if n_classes == 2 else [n_classes]`

    
Constants in decision function.

`n_iter_int`

    
The actual number of iterations to reach the stopping criterion.

`t_int`

    
Number of weight updates performed during training. Same as `(n_iter_ *
n_samples)`.

See also

`SGDRegressor`

#### References

Online Passive-Aggressive Algorithms
<http://jmlr.csail.mit.edu/papers/volume7/crammer06a/crammer06a.pdf> K.
Crammer, O. Dekel, J. Keshat, S. Shalev-Shwartz, Y. Singer - JMLR (2006)

#### Examples

    
    >>> from sklearn.linear_model import PassiveAggressiveRegressor
    >>> from sklearn.datasets import make_regression
    
    
    >>> X, y = make_regression(n_features=4, random_state=0)
    >>> regr = PassiveAggressiveRegressor(max_iter=100, random_state=0,
    ... tol=1e-3)
    >>> regr.fit(X, y)
    PassiveAggressiveRegressor(max_iter=100, random_state=0)
    >>> print(regr.coef_)
    [20.48736655 34.18818427 67.59122734 87.94731329]
    >>> print(regr.intercept_)
    [-0.02306214]
    >>> print(regr.predict([[0, 0, 0, 0]]))
    [-0.02306214]
    
© 2007–2020 The scikit-learn developers  
Licensed under the 3-clause BSD License.  
https://scikit-
learn.org/0.24/modules/generated/sklearn.linear_model.PassiveAggressiveRegressor.html

