# TransformerEncoderLayer

`class torch.nn.TransformerEncoderLayer(d_model, nhead, dim_feedforward=2048,
dropout=0.1, activation='relu')` [source]

    
TransformerEncoderLayer is made up of self-attn and feedforward network. This
standard encoder layer is based on the paper “Attention Is All You Need”.
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan
N Gomez, Lukasz Kaiser, and Illia Polosukhin. 2017. Attention is all you need.
In Advances in Neural Information Processing Systems, pages 6000-6010. Users
may modify or implement in a different way during application.

Parameters

    
  * d_model – the number of expected features in the input (required).
  * nhead – the number of heads in the multiheadattention models (required).
  * dim_feedforward – the dimension of the feedforward network model (default=2048).
  * dropout – the dropout value (default=0.1).
  * activation – the activation function of intermediate layer, relu or gelu (default=relu).

Examples::

    
    
    >>> encoder_layer = nn.TransformerEncoderLayer(d_model=512, nhead=8)
    >>> src = torch.rand(10, 32, 512)
    >>> out = encoder_layer(src)
    
`forward(src, src_mask=None, src_key_padding_mask=None)` [source]

    
Pass the input through the encoder layer.

Parameters

    
  * src – the sequence to the encoder layer (required).
  * src_mask – the mask for the src sequence (optional).
  * src_key_padding_mask – the mask for the src keys per batch (optional).

Shape:

    
see the docs in Transformer class.

© 2019 Torch Contributors  
Licensed under the 3-clause BSD License.  
https://pytorch.org/docs/1.8.0/generated/torch.nn.TransformerEncoderLayer.html

  *[ISP]: Internet Service Provider
  *[LIFO]: last-in, first-out
  *[FIFO]: first-in, first-out

