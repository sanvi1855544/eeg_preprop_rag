# LSTM

`class torch.nn.LSTM(*args, **kwargs)` [source]

    
Applies a multi-layer long short-term memory (LSTM) RNN to an input sequence.

For each element in the input sequence, each layer computes the following
function:

it=σ(Wiixt+bii+Whiht−1+bhi)ft=σ(Wifxt+bif+Whfht−1+bhf)gt=tanh⁡(Wigxt+big+Whght−1+bhg)ot=σ(Wioxt+bio+Whoht−1+bho)ct=ft⊙ct−1+it⊙gtht=ot⊙tanh⁡(ct)\begin{array}{ll}
\\\ i_t = \sigma(W_{ii} x_t + b_{ii} + W_{hi} h_{t-1} + b_{hi}) \\\ f_t =
\sigma(W_{if} x_t + b_{if} + W_{hf} h_{t-1} + b_{hf}) \\\ g_t = \tanh(W_{ig}
x_t + b_{ig} + W_{hg} h_{t-1} + b_{hg}) \\\ o_t = \sigma(W_{io} x_t + b_{io} +
W_{ho} h_{t-1} + b_{ho}) \\\ c_t = f_t \odot c_{t-1} + i_t \odot g_t \\\ h_t =
o_t \odot \tanh(c_t) \\\ \end{array}

where hth_t is the hidden state at time `t`, ctc_t is the cell state at time
`t`, xtx_t is the input at time `t`, ht−1h_{t-1} is the hidden state of the
layer at time `t-1` or the initial hidden state at time `0`, and iti_t , ftf_t
, gtg_t , oto_t are the input, forget, cell, and output gates, respectively.
σ\sigma is the sigmoid function, and ⊙\odot is the Hadamard product.

In a multilayer LSTM, the input xt(l)x^{(l)}_t of the ll -th layer (l>=2l >= 2
) is the hidden state ht(l−1)h^{(l-1)}_t of the previous layer multiplied by
dropout δt(l−1)\delta^{(l-1)}_t where each δt(l−1)\delta^{(l-1)}_t is a
Bernoulli random variable which is 00 with probability `dropout`.

If `proj_size > 0` is specified, LSTM with projections will be used. This
changes the LSTM cell in the following way. First, the dimension of hth_t will
be changed from `hidden_size` to `proj_size` (dimensions of WhiW_{hi} will be
changed accordingly). Second, the output hidden state of each layer will be
multiplied by a learnable projection matrix: ht=Whrhth_t = W_{hr}h_t . Note
that as a consequence of this, the output of LSTM network will be of different
shape as well. See Inputs/Outputs sections below for exact dimensions of all
variables. You can find more details in https://arxiv.org/abs/1402.1128.

Parameters

    
  * input_size – The number of expected features in the input `x`
  * hidden_size – The number of features in the hidden state `h`
  * num_layers – Number of recurrent layers. E.g., setting `num_layers=2` would mean stacking two LSTMs together to form a `stacked LSTM`, with the second LSTM taking in outputs of the first LSTM and computing the final results. Default: 1
  * bias – If `False`, then the layer does not use bias weights `b_ih` and `b_hh`. Default: `True`
  * batch_first – If `True`, then the input and output tensors are provided as (batch, seq, feature). Default: `False`
  * dropout – If non-zero, introduces a `Dropout` layer on the outputs of each LSTM layer except the last layer, with dropout probability equal to `dropout`. Default: 0
  * bidirectional – If `True`, becomes a bidirectional LSTM. Default: `False`
  * proj_size – If `> 0`, will use LSTM with projections of corresponding size. Default: 0

Inputs: input, (h_0, c_0)

    
  * input of shape `(seq_len, batch, input_size)`: tensor containing the features of the input sequence. The input can also be a packed variable length sequence. See `torch.nn.utils.rnn.pack_padded_sequence()` or `torch.nn.utils.rnn.pack_sequence()` for details.
  * h_0 of shape `(num_layers * num_directions, batch, hidden_size)`: tensor containing the initial hidden state for each element in the batch. If the LSTM is bidirectional, num_directions should be 2, else it should be 1. If `proj_size > 0` was specified, the shape has to be `(num_layers * num_directions, batch, proj_size)`.
  * c_0 of shape `(num_layers * num_directions, batch, hidden_size)`: tensor containing the initial cell state for each element in the batch.
If `(h_0, c_0)` is not provided, both h_0 and c_0 default to zero.

Outputs: output, (h_n, c_n)

    
  * output of shape `(seq_len, batch, num_directions * hidden_size)`: tensor containing the output features `(h_t)` from the last layer of the LSTM, for each `t`. If a `torch.nn.utils.rnn.PackedSequence` has been given as the input, the output will also be a packed sequence. If `proj_size > 0` was specified, output shape will be `(seq_len, batch, num_directions * proj_size)`.
For the unpacked case, the directions can be separated using
`output.view(seq_len, batch, num_directions, hidden_size)`, with forward and
backward being direction `0` and `1` respectively. Similarly, the directions
can be separated in the packed case.

  * h_n of shape `(num_layers * num_directions, batch, hidden_size)`: tensor containing the hidden state for `t = seq_len`. If `proj_size > 0` was specified, `h_n` shape will be `(num_layers * num_directions, batch, proj_size)`.
Like output, the layers can be separated using `h_n.view(num_layers,
num_directions, batch, hidden_size)` and similarly for c_n.

  * c_n of shape `(num_layers * num_directions, batch, hidden_size)`: tensor containing the cell state for `t = seq_len`.

Variables

    
  * ~LSTM.weight_ih_l[k] – the learnable input-hidden weights of the kth\text{k}^{th} layer `(W_ii|W_if|W_ig|W_io)`, of shape `(4*hidden_size, input_size)` for `k = 0`. Otherwise, the shape is `(4*hidden_size, num_directions * hidden_size)`
  * ~LSTM.weight_hh_l[k] – the learnable hidden-hidden weights of the kth\text{k}^{th} layer `(W_hi|W_hf|W_hg|W_ho)`, of shape `(4*hidden_size, hidden_size)`. If `proj_size > 0` was specified, the shape will be `(4*hidden_size, proj_size)`.
  * ~LSTM.bias_ih_l[k] – the learnable input-hidden bias of the kth\text{k}^{th} layer `(b_ii|b_if|b_ig|b_io)`, of shape `(4*hidden_size)`
  * ~LSTM.bias_hh_l[k] – the learnable hidden-hidden bias of the kth\text{k}^{th} layer `(b_hi|b_hf|b_hg|b_ho)`, of shape `(4*hidden_size)`
  * ~LSTM.weight_hr_l[k] – the learnable projection weights of the kth\text{k}^{th} layer of shape `(proj_size, hidden_size)`. Only present when `proj_size > 0` was specified.

Note

All the weights and biases are initialized from U(−k,k)\mathcal{U}(-\sqrt{k},
\sqrt{k}) where k=1hidden_sizek = \frac{1}{\text{hidden\\_size}}

Warning

There are known non-determinism issues for RNN functions on some versions of
cuDNN and CUDA. You can enforce deterministic behavior by setting the
following environment variables:

On CUDA 10.1, set environment variable `CUDA_LAUNCH_BLOCKING=1`. This may
affect performance.

On CUDA 10.2 or later, set environment variable (note the leading colon
symbol) `CUBLAS_WORKSPACE_CONFIG=:16:8` or `CUBLAS_WORKSPACE_CONFIG=:4096:2`.

See the cuDNN 8 Release Notes for more information.

Orphan

Note

If the following conditions are satisfied: 1) cudnn is enabled, 2) input data
is on the GPU 3) input data has dtype `torch.float16` 4) V100 GPU is used, 5)
input data is not in `PackedSequence` format persistent algorithm can be
selected to improve performance.

Examples:

    
    >>> rnn = nn.LSTM(10, 20, 2)
    >>> input = torch.randn(5, 3, 10)
    >>> h0 = torch.randn(2, 3, 20)
    >>> c0 = torch.randn(2, 3, 20)
    >>> output, (hn, cn) = rnn(input, (h0, c0))
    
© 2019 Torch Contributors  
Licensed under the 3-clause BSD License.  
https://pytorch.org/docs/1.8.0/generated/torch.nn.LSTM.html

  *[ISP]: Internet Service Provider
  *[LIFO]: last-in, first-out
  *[FIFO]: first-in, first-out

