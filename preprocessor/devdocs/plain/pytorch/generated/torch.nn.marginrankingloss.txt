# MarginRankingLoss

`class torch.nn.MarginRankingLoss(margin=0.0, size_average=None, reduce=None,
reduction='mean')` [source]

    
Creates a criterion that measures the loss given inputs x1x1 , x2x2 , two 1D
mini-batch `Tensors`, and a label 1D mini-batch tensor yy (containing 1 or
-1).

If y=1y = 1 then it assumed the first input should be ranked higher (have a
larger value) than the second input, and vice-versa for y=−1y = -1 .

The loss function for each pair of samples in the mini-batch is:

loss(x1,x2,y)=max⁡(0,−y∗(x1−x2)+margin)\text{loss}(x1, x2, y) = \max(0, -y *
(x1 - x2) + \text{margin})

Parameters

    
  * margin (float, optional) – Has a default value of 00 .
  * size_average (bool, optional) – Deprecated (see `reduction`). By default, the losses are averaged over each loss element in the batch. Note that for some losses, there are multiple elements per sample. If the field `size_average` is set to `False`, the losses are instead summed for each minibatch. Ignored when `reduce` is `False`. Default: `True`
  * reduce (bool, optional) – Deprecated (see `reduction`). By default, the losses are averaged or summed over observations for each minibatch depending on `size_average`. When `reduce` is `False`, returns a loss per batch element instead and ignores `size_average`. Default: `True`
  * reduction (string, optional) – Specifies the reduction to apply to the output: `'none'` | `'mean'` | `'sum'`. `'none'`: no reduction will be applied, `'mean'`: the sum of the output will be divided by the number of elements in the output, `'sum'`: the output will be summed. Note: `size_average` and `reduce` are in the process of being deprecated, and in the meantime, specifying either of those two args will override `reduction`. Default: `'mean'`

Shape:

    
  * Input1: (N)(N) where `N` is the batch size.
  * Input2: (N)(N) , same shape as the Input1.
  * Target: (N)(N) , same shape as the inputs.
  * Output: scalar. If `reduction` is `'none'`, then (N)(N) .

Examples:

    
    >>> loss = nn.MarginRankingLoss()
    >>> input1 = torch.randn(3, requires_grad=True)
    >>> input2 = torch.randn(3, requires_grad=True)
    >>> target = torch.randn(3).sign()
    >>> output = loss(input1, input2, target)
    >>> output.backward()
    
© 2019 Torch Contributors  
Licensed under the 3-clause BSD License.  
https://pytorch.org/docs/1.8.0/generated/torch.nn.MarginRankingLoss.html

  *[ISP]: Internet Service Provider
  *[LIFO]: last-in, first-out
  *[FIFO]: first-in, first-out

