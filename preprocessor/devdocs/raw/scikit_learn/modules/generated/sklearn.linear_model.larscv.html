<h1>sklearn.linear_model.LarsCV</h1> <dl class="py class"> <dt id="sklearn.linear_model.LarsCV">
<code>class sklearn.linear_model.LarsCV(*, fit_intercept=True, verbose=False, max_iter=500, normalize=True, precompute='auto', cv=None, max_n_alphas=1000, n_jobs=None, eps=2.220446049250313e-16, copy_X=True)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/95119c13a/sklearn/linear_model/_least_angle.py#L1316"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Cross-validated Least Angle Regression model.</p> <p>See glossary entry for <a class="reference internal" href="https://scikit-learn.org/0.24/glossary.html#term-cross-validation-estimator"><span class="xref std std-term">cross-validation estimator</span></a>.</p> <p>Read more in the <a class="reference internal" href="../linear_model#least-angle-regression"><span class="std std-ref">User Guide</span></a>.</p> <dl class="field-list"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<dl> <dt>
<code>fit_interceptbool, default=True</code> </dt>
<dd>
<p>whether to calculate the intercept for this model. If set to false, no intercept will be used in calculations (i.e. data is expected to be centered).</p> </dd> <dt>
<code>verbosebool or int, default=False</code> </dt>
<dd>
<p>Sets the verbosity amount.</p> </dd> <dt>
<code>max_iterint, default=500</code> </dt>
<dd>
<p>Maximum number of iterations to perform.</p> </dd> <dt>
<code>normalizebool, default=True</code> </dt>
<dd>
<p>This parameter is ignored when <code>fit_intercept</code> is set to False. If True, the regressors X will be normalized before regression by subtracting the mean and dividing by the l2-norm. If you wish to standardize, please use <a class="reference internal" href="sklearn.preprocessing.standardscaler#sklearn.preprocessing.StandardScaler" title="sklearn.preprocessing.StandardScaler"><code>StandardScaler</code></a> before calling <code>fit</code> on an estimator with <code>normalize=False</code>.</p> </dd> <dt>
<code>precomputebool, ‘auto’ or array-like , default=’auto’</code> </dt>
<dd>
<p>Whether to use a precomputed Gram matrix to speed up calculations. If set to <code>'auto'</code> let us decide. The Gram matrix cannot be passed as argument since we will use only subsets of X.</p> </dd> <dt>
<code>cvint, cross-validation generator or an iterable, default=None</code> </dt>
<dd>
<p>Determines the cross-validation splitting strategy. Possible inputs for cv are:</p> <ul class="simple"> <li>None, to use the default 5-fold cross-validation,</li> <li>integer, to specify the number of folds.</li> <li>
<a class="reference internal" href="https://scikit-learn.org/0.24/glossary.html#term-CV-splitter"><span class="xref std std-term">CV splitter</span></a>,</li> <li>An iterable yielding (train, test) splits as arrays of indices.</li> </ul> <p>For integer/None inputs, <code>KFold</code> is used.</p> <p>Refer <a class="reference internal" href="../cross_validation#cross-validation"><span class="std std-ref">User Guide</span></a> for the various cross-validation strategies that can be used here.</p> <div class="versionchanged"> <p><span class="versionmodified changed">Changed in version 0.22: </span><code>cv</code> default value if None changed from 3-fold to 5-fold.</p> </div> </dd> <dt>
<code>max_n_alphasint, default=1000</code> </dt>
<dd>
<p>The maximum number of points on the path used to compute the residuals in the cross-validation</p> </dd> <dt>
<code>n_jobsint or None, default=None</code> </dt>
<dd>
<p>Number of CPUs to use during the cross validation. <code>None</code> means 1 unless in a <a class="reference external" href="https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend" title="(in joblib v1.1.0.dev0)"><code>joblib.parallel_backend</code></a> context. <code>-1</code> means using all processors. See <a class="reference internal" href="https://scikit-learn.org/0.24/glossary.html#term-n_jobs"><span class="xref std std-term">Glossary</span></a> for more details.</p> </dd> <dt>
<code>epsfloat, default=np.finfo(float).eps</code> </dt>
<dd>
<p>The machine-precision regularization in the computation of the Cholesky diagonal factors. Increase this for very ill-conditioned systems. Unlike the <code>tol</code> parameter in some iterative optimization-based algorithms, this parameter does not control the tolerance of the optimization.</p> </dd> <dt>
<code>copy_Xbool, default=True</code> </dt>
<dd>
<p>If <code>True</code>, X will be copied; else, it may be overwritten.</p> </dd> </dl> </dd> <dt class="field-even">Attributes</dt> <dd class="field-even">
<dl class="simple"> <dt>
<code>active_list of length n_alphas or list of such lists</code> </dt>
<dd>
<p>Indices of active variables at the end of the path. If this is a list of lists, the outer list length is <code>n_targets</code>.</p> </dd> <dt>
<code>coef_array-like of shape (n_features,)</code> </dt>
<dd>
<p>parameter vector (w in the formulation formula)</p> </dd> <dt>
<code>intercept_float</code> </dt>
<dd>
<p>independent term in decision function</p> </dd> <dt>
<code>coef_path_array-like of shape (n_features, n_alphas)</code> </dt>
<dd>
<p>the varying values of the coefficients along the path</p> </dd> <dt>
<code>alpha_float</code> </dt>
<dd>
<p>the estimated regularization parameter alpha</p> </dd> <dt>
<code>alphas_array-like of shape (n_alphas,)</code> </dt>
<dd>
<p>the different values of alpha along the path</p> </dd> <dt>
<code>cv_alphas_array-like of shape (n_cv_alphas,)</code> </dt>
<dd>
<p>all the values of alpha along the path for the different folds</p> </dd> <dt>
<code>mse_path_array-like of shape (n_folds, n_cv_alphas)</code> </dt>
<dd>
<p>the mean square error on left-out for each fold along the path (alpha values given by <code>cv_alphas</code>)</p> </dd> <dt>
<code>n_iter_array-like or int</code> </dt>
<dd>
<p>the number of iterations run by Lars with the optimal alpha.</p> </dd> </dl> </dd> </dl> <div class="admonition seealso"> <p class="admonition-title">See also</p> <dl class="simple"> <dt>
<code>lars_path, LassoLars,</code> <a class="reference internal" href="sklearn.linear_model.lassolarscv#sklearn.linear_model.LassoLarsCV" title="sklearn.linear_model.LassoLarsCV"><code>LassoLarsCV</code></a>
</dt>
 </dl> </div> <h4 class="rubric">Examples</h4> <pre data-language="python">&gt;&gt;&gt; from sklearn.linear_model import LarsCV
&gt;&gt;&gt; from sklearn.datasets import make_regression
&gt;&gt;&gt; X, y = make_regression(n_samples=200, noise=4.0, random_state=0)
&gt;&gt;&gt; reg = LarsCV(cv=5).fit(X, y)
&gt;&gt;&gt; reg.score(X, y)
0.9996...
&gt;&gt;&gt; reg.alpha_
0.0254...
&gt;&gt;&gt; reg.predict(X[:1,])
array([154.0842...])
</pre> <h4 class="rubric">Methods</h4> <table class="longtable docutils align-default">   <tr>
<td><p><a class="reference internal" href="#sklearn.linear_model.LarsCV.fit" title="sklearn.linear_model.LarsCV.fit"><code>fit</code></a>(X, y)</p></td> <td><p>Fit the model using X, y as training data.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="#sklearn.linear_model.LarsCV.get_params" title="sklearn.linear_model.LarsCV.get_params"><code>get_params</code></a>([deep])</p></td> <td><p>Get parameters for this estimator.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="#sklearn.linear_model.LarsCV.predict" title="sklearn.linear_model.LarsCV.predict"><code>predict</code></a>(X)</p></td> <td><p>Predict using the linear model.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="#sklearn.linear_model.LarsCV.score" title="sklearn.linear_model.LarsCV.score"><code>score</code></a>(X, y[, sample_weight])</p></td> <td><p>Return the coefficient of determination <span class="math notranslate nohighlight">\(R^2\)</span> of the prediction.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="#sklearn.linear_model.LarsCV.set_params" title="sklearn.linear_model.LarsCV.set_params"><code>set_params</code></a>(**params)</p></td> <td><p>Set the parameters of this estimator.</p></td> </tr>  </table> <dl class="py method"> <dt id="sklearn.linear_model.LarsCV.fit">
<code>fit(X, y)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/95119c13a/sklearn/linear_model/_least_angle.py#L1455"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Fit the model using X, y as training data.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<dl class="simple"> <dt>
<code>Xarray-like of shape (n_samples, n_features)</code> </dt>
<dd>
<p>Training data.</p> </dd> <dt>
<code>yarray-like of shape (n_samples,)</code> </dt>
<dd>
<p>Target values.</p> </dd> </dl> </dd> <dt class="field-even">Returns</dt> <dd class="field-even">
<dl class="simple"> <dt>
<code>selfobject</code> </dt>
<dd>
<p>returns an instance of self.</p> </dd> </dl> </dd> </dl> </dd>
</dl> <dl class="py method"> <dt id="sklearn.linear_model.LarsCV.get_params">
<code>get_params(deep=True)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/95119c13a/sklearn/base.py#L178"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Get parameters for this estimator.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<dl class="simple"> <dt>
<code>deepbool, default=True</code> </dt>
<dd>
<p>If True, will return the parameters for this estimator and contained subobjects that are estimators.</p> </dd> </dl> </dd> <dt class="field-even">Returns</dt> <dd class="field-even">
<dl class="simple"> <dt>
<code>paramsdict</code> </dt>
<dd>
<p>Parameter names mapped to their values.</p> </dd> </dl> </dd> </dl> </dd>
</dl> <dl class="py method"> <dt id="sklearn.linear_model.LarsCV.predict">
<code>predict(X)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/95119c13a/sklearn/linear_model/_base.py#L224"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Predict using the linear model.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<dl class="simple"> <dt>
<code>Xarray-like or sparse matrix, shape (n_samples, n_features)</code> </dt>
<dd>
<p>Samples.</p> </dd> </dl> </dd> <dt class="field-even">Returns</dt> <dd class="field-even">
<dl class="simple"> <dt>
<code>Carray, shape (n_samples,)</code> </dt>
<dd>
<p>Returns predicted values.</p> </dd> </dl> </dd> </dl> </dd>
</dl> <dl class="py method"> <dt id="sklearn.linear_model.LarsCV.score">
<code>score(X, y, sample_weight=None)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/95119c13a/sklearn/base.py#L510"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Return the coefficient of determination <span class="math notranslate nohighlight">\(R^2\)</span> of the prediction.</p> <p>The coefficient <span class="math notranslate nohighlight">\(R^2\)</span> is defined as <span class="math notranslate nohighlight">\((1 - \frac{u}{v})\)</span>, where <span class="math notranslate nohighlight">\(u\)</span> is the residual sum of squares <code>((y_true - y_pred)
** 2).sum()</code> and <span class="math notranslate nohighlight">\(v\)</span> is the total sum of squares <code>((y_true -
y_true.mean()) ** 2).sum()</code>. The best possible score is 1.0 and it can be negative (because the model can be arbitrarily worse). A constant model that always predicts the expected value of <code>y</code>, disregarding the input features, would get a <span class="math notranslate nohighlight">\(R^2\)</span> score of 0.0.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<dl class="simple"> <dt>
<code>Xarray-like of shape (n_samples, n_features)</code> </dt>
<dd>
<p>Test samples. For some estimators this may be a precomputed kernel matrix or a list of generic objects instead with shape <code>(n_samples, n_samples_fitted)</code>, where <code>n_samples_fitted</code> is the number of samples used in the fitting for the estimator.</p> </dd> <dt>
<code>yarray-like of shape (n_samples,) or (n_samples, n_outputs)</code> </dt>
<dd>
<p>True values for <code>X</code>.</p> </dd> <dt>
<code>sample_weightarray-like of shape (n_samples,), default=None</code> </dt>
<dd>
<p>Sample weights.</p> </dd> </dl> </dd> <dt class="field-even">Returns</dt> <dd class="field-even">
<dl class="simple"> <dt>
<code>scorefloat</code> </dt>
<dd>
<p><span class="math notranslate nohighlight">\(R^2\)</span> of <code>self.predict(X)</code> wrt. <code>y</code>.</p> </dd> </dl> </dd> </dl> <h4 class="rubric">Notes</h4> <p>The <span class="math notranslate nohighlight">\(R^2\)</span> score used when calling <code>score</code> on a regressor uses <code>multioutput='uniform_average'</code> from version 0.23 to keep consistent with default value of <a class="reference internal" href="sklearn.metrics.r2_score#sklearn.metrics.r2_score" title="sklearn.metrics.r2_score"><code>r2_score</code></a>. This influences the <code>score</code> method of all the multioutput regressors (except for <a class="reference internal" href="sklearn.multioutput.multioutputregressor#sklearn.multioutput.MultiOutputRegressor" title="sklearn.multioutput.MultiOutputRegressor"><code>MultiOutputRegressor</code></a>).</p> </dd>
</dl> <dl class="py method"> <dt id="sklearn.linear_model.LarsCV.set_params">
<code>set_params(**params)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/95119c13a/sklearn/base.py#L202"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Set the parameters of this estimator.</p> <p>The method works on simple estimators as well as on nested objects (such as <a class="reference internal" href="sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline" title="sklearn.pipeline.Pipeline"><code>Pipeline</code></a>). The latter have parameters of the form <code>&lt;component&gt;__&lt;parameter&gt;</code> so that it’s possible to update each component of a nested object.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<dl class="simple"> <dt>
<code>**paramsdict</code> </dt>
<dd>
<p>Estimator parameters.</p> </dd> </dl> </dd> <dt class="field-even">Returns</dt> <dd class="field-even">
<dl class="simple"> <dt>
<code>selfestimator instance</code> </dt>
<dd>
<p>Estimator instance.</p> </dd> </dl> </dd> </dl> </dd>
</dl> </dd>
</dl> <div class="_attribution">
  <p class="_attribution-p">
    &copy; 2007&ndash;2020 The scikit-learn developers<br>Licensed under the 3-clause BSD License.<br>
    <a href="https://scikit-learn.org/0.24/modules/generated/sklearn.linear_model.LarsCV.html" class="_attribution-link">https://scikit-learn.org/0.24/modules/generated/sklearn.linear_model.LarsCV.html</a>
  </p>
</div>
