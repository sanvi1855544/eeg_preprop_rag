<h1>sklearn.tree.export_text</h1> <dl class="py function"> <dt id="sklearn.tree.export_text">
<code>sklearn.tree.export_text(decision_tree, *, feature_names=None, max_depth=10, spacing=3, decimals=2, show_weights=False)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/95119c13a/sklearn/tree/_export.py#L818"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Build a text report showing the rules of a decision tree.</p> <p>Note that backwards compatibility may not be supported.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<dl class="simple"> <dt>
<code>decision_treeobject</code> </dt>
<dd>
<p>The decision tree estimator to be exported. It can be an instance of DecisionTreeClassifier or DecisionTreeRegressor.</p> </dd> <dt>
<code>feature_nameslist of str, default=None</code> </dt>
<dd>
<p>A list of length n_features containing the feature names. If None generic names will be used (“feature_0”, “feature_1”, …).</p> </dd> <dt>
<code>max_depthint, default=10</code> </dt>
<dd>
<p>Only the first max_depth levels of the tree are exported. Truncated branches will be marked with “…”.</p> </dd> <dt>
<code>spacingint, default=3</code> </dt>
<dd>
<p>Number of spaces between edges. The higher it is, the wider the result.</p> </dd> <dt>
<code>decimalsint, default=2</code> </dt>
<dd>
<p>Number of decimal digits to display.</p> </dd> <dt>
<code>show_weightsbool, default=False</code> </dt>
<dd>
<p>If true the classification weights will be exported on each leaf. The classification weights are the number of samples each class.</p> </dd> </dl> </dd> <dt class="field-even">Returns</dt> <dd class="field-even">
<dl class="simple"> <dt>
<code>reportstring</code> </dt>
<dd>
<p>Text summary of all the rules in the decision tree.</p> </dd> </dl> </dd> </dl> <h4 class="rubric">Examples</h4> <pre data-language="python">&gt;&gt;&gt; from sklearn.datasets import load_iris
&gt;&gt;&gt; from sklearn.tree import DecisionTreeClassifier
&gt;&gt;&gt; from sklearn.tree import export_text
&gt;&gt;&gt; iris = load_iris()
&gt;&gt;&gt; X = iris['data']
&gt;&gt;&gt; y = iris['target']
&gt;&gt;&gt; decision_tree = DecisionTreeClassifier(random_state=0, max_depth=2)
&gt;&gt;&gt; decision_tree = decision_tree.fit(X, y)
&gt;&gt;&gt; r = export_text(decision_tree, feature_names=iris['feature_names'])
&gt;&gt;&gt; print(r)
|--- petal width (cm) &lt;= 0.80
|   |--- class: 0
|--- petal width (cm) &gt;  0.80
|   |--- petal width (cm) &lt;= 1.75
|   |   |--- class: 1
|   |--- petal width (cm) &gt;  1.75
|   |   |--- class: 2
</pre> </dd>
</dl> <div class="_attribution">
  <p class="_attribution-p">
    &copy; 2007&ndash;2020 The scikit-learn developers<br>Licensed under the 3-clause BSD License.<br>
    <a href="https://scikit-learn.org/0.24/modules/generated/sklearn.tree.export_text.html" class="_attribution-link">https://scikit-learn.org/0.24/modules/generated/sklearn.tree.export_text.html</a>
  </p>
</div>
