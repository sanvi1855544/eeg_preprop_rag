<h1>sklearn.metrics.hinge_loss</h1> <dl class="py function"> <dt id="sklearn.metrics.hinge_loss">
<code>sklearn.metrics.hinge_loss(y_true, pred_decision, *, labels=None, sample_weight=None)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/95119c13a/sklearn/metrics/_classification.py#L2284"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Average hinge loss (non-regularized).</p> <p>In binary class case, assuming labels in y_true are encoded with +1 and -1, when a prediction mistake is made, <code>margin = y_true * pred_decision</code> is always negative (since the signs disagree), implying <code>1 - margin</code> is always greater than 1. The cumulated hinge loss is therefore an upper bound of the number of mistakes made by the classifier.</p> <p>In multiclass case, the function expects that either all the labels are included in y_true or an optional labels argument is provided which contains all the labels. The multilabel margin is calculated according to Crammer-Singerâ€™s method. As in the binary case, the cumulated hinge loss is an upper bound of the number of mistakes made by the classifier.</p> <p>Read more in the <a class="reference internal" href="../model_evaluation#hinge-loss"><span class="std std-ref">User Guide</span></a>.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<dl class="simple"> <dt>
<code>y_truearray of shape (n_samples,)</code> </dt>
<dd>
<p>True target, consisting of integers of two values. The positive label must be greater than the negative label.</p> </dd> <dt>
<code>pred_decisionarray of shape (n_samples,) or (n_samples, n_classes)</code> </dt>
<dd>
<p>Predicted decisions, as output by decision_function (floats).</p> </dd> <dt>
<code>labelsarray-like, default=None</code> </dt>
<dd>
<p>Contains all the labels for the problem. Used in multiclass hinge loss.</p> </dd> <dt>
<code>sample_weightarray-like of shape (n_samples,), default=None</code> </dt>
<dd>
<p>Sample weights.</p> </dd> </dl> </dd> <dt class="field-even">Returns</dt> <dd class="field-even">
<dl class="simple"> <dt>
<code>lossfloat</code> </dt>
 </dl> </dd> </dl> <h4 class="rubric">References</h4> <dl class="citation"> <dt class="label" id="rf22d8d20ab3d-1">
<code>1</code> </dt> <dd>
<p><a class="reference external" href="https://en.wikipedia.org/wiki/Hinge_loss">Wikipedia entry on the Hinge loss</a>.</p> </dd> <dt class="label" id="rf22d8d20ab3d-2">
<code>2</code> </dt> <dd>
<p>Koby Crammer, Yoram Singer. On the Algorithmic Implementation of Multiclass Kernel-based Vector Machines. Journal of Machine Learning Research 2, (2001), 265-292.</p> </dd> <dt class="label" id="rf22d8d20ab3d-3">
<code>3</code> </dt> <dd>
<p><a class="reference external" href="http://www.ttic.edu/sigml/symposium2011/papers/Moore+DeNero_Regularization.pdf">L1 AND L2 Regularization for Multiclass Hinge Loss Models by Robert C. Moore, John DeNero</a>.</p> </dd> </dl> <h4 class="rubric">Examples</h4> <pre data-language="python">&gt;&gt;&gt; from sklearn import svm
&gt;&gt;&gt; from sklearn.metrics import hinge_loss
&gt;&gt;&gt; X = [[0], [1]]
&gt;&gt;&gt; y = [-1, 1]
&gt;&gt;&gt; est = svm.LinearSVC(random_state=0)
&gt;&gt;&gt; est.fit(X, y)
LinearSVC(random_state=0)
&gt;&gt;&gt; pred_decision = est.decision_function([[-2], [3], [0.5]])
&gt;&gt;&gt; pred_decision
array([-2.18...,  2.36...,  0.09...])
&gt;&gt;&gt; hinge_loss([-1, 1, 1], pred_decision)
0.30...
</pre> <p>In the multiclass case:</p> <pre data-language="python">&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; X = np.array([[0], [1], [2], [3]])
&gt;&gt;&gt; Y = np.array([0, 1, 2, 3])
&gt;&gt;&gt; labels = np.array([0, 1, 2, 3])
&gt;&gt;&gt; est = svm.LinearSVC()
&gt;&gt;&gt; est.fit(X, Y)
LinearSVC()
&gt;&gt;&gt; pred_decision = est.decision_function([[-1], [2], [3]])
&gt;&gt;&gt; y_true = [0, 2, 3]
&gt;&gt;&gt; hinge_loss(y_true, pred_decision, labels=labels)
0.56...
</pre> </dd>
</dl> <div class="_attribution">
  <p class="_attribution-p">
    &copy; 2007&ndash;2020 The scikit-learn developers<br>Licensed under the 3-clause BSD License.<br>
    <a href="https://scikit-learn.org/0.24/modules/generated/sklearn.metrics.hinge_loss.html" class="_attribution-link">https://scikit-learn.org/0.24/modules/generated/sklearn.metrics.hinge_loss.html</a>
  </p>
</div>
