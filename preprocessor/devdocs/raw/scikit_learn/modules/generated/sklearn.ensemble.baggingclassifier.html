<h1>sklearn.ensemble.BaggingClassifier</h1> <dl class="py class"> <dt id="sklearn.ensemble.BaggingClassifier">
<code>class sklearn.ensemble.BaggingClassifier(base_estimator=None, n_estimators=10, *, max_samples=1.0, max_features=1.0, bootstrap=True, bootstrap_features=False, oob_score=False, warm_start=False, n_jobs=None, random_state=None, verbose=0)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/95119c13a/sklearn/ensemble/_bagging.py#L433"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>A Bagging classifier.</p> <p>A Bagging classifier is an ensemble meta-estimator that fits base classifiers each on random subsets of the original dataset and then aggregate their individual predictions (either by voting or by averaging) to form a final prediction. Such a meta-estimator can typically be used as a way to reduce the variance of a black-box estimator (e.g., a decision tree), by introducing randomization into its construction procedure and then making an ensemble out of it.</p> <p>This algorithm encompasses several works from the literature. When random subsets of the dataset are drawn as random subsets of the samples, then this algorithm is known as Pasting <a class="reference internal" href="#rb1846455d0e5-1" id="id1">[1]</a>. If samples are drawn with replacement, then the method is known as Bagging <a class="reference internal" href="#rb1846455d0e5-2" id="id2">[2]</a>. When random subsets of the dataset are drawn as random subsets of the features, then the method is known as Random Subspaces <a class="reference internal" href="#rb1846455d0e5-3" id="id3">[3]</a>. Finally, when base estimators are built on subsets of both samples and features, then the method is known as Random Patches <a class="reference internal" href="#rb1846455d0e5-4" id="id4">[4]</a>.</p> <p>Read more in the <a class="reference internal" href="../ensemble#bagging"><span class="std std-ref">User Guide</span></a>.</p> <div class="versionadded"> <p><span class="versionmodified added">New in version 0.15.</span></p> </div> <dl class="field-list"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<dl> <dt>
<code>base_estimatorobject, default=None</code> </dt>
<dd>
<p>The base estimator to fit on random subsets of the dataset. If None, then the base estimator is a <a class="reference internal" href="sklearn.tree.decisiontreeclassifier#sklearn.tree.DecisionTreeClassifier" title="sklearn.tree.DecisionTreeClassifier"><code>DecisionTreeClassifier</code></a>.</p> </dd> <dt>
<code>n_estimatorsint, default=10</code> </dt>
<dd>
<p>The number of base estimators in the ensemble.</p> </dd> <dt>
<code>max_samplesint or float, default=1.0</code> </dt>
<dd>
<p>The number of samples to draw from X to train each base estimator (with replacement by default, see <code>bootstrap</code> for more details).</p> <ul class="simple"> <li>If int, then draw <code>max_samples</code> samples.</li> <li>If float, then draw <code>max_samples * X.shape[0]</code> samples.</li> </ul> </dd> <dt>
<code>max_featuresint or float, default=1.0</code> </dt>
<dd>
<p>The number of features to draw from X to train each base estimator ( without replacement by default, see <code>bootstrap_features</code> for more details).</p> <ul class="simple"> <li>If int, then draw <code>max_features</code> features.</li> <li>If float, then draw <code>max_features * X.shape[1]</code> features.</li> </ul> </dd> <dt>
<code>bootstrapbool, default=True</code> </dt>
<dd>
<p>Whether samples are drawn with replacement. If False, sampling without replacement is performed.</p> </dd> <dt>
<code>bootstrap_featuresbool, default=False</code> </dt>
<dd>
<p>Whether features are drawn with replacement.</p> </dd> <dt>
<code>oob_scorebool, default=False</code> </dt>
<dd>
<p>Whether to use out-of-bag samples to estimate the generalization error.</p> </dd> <dt>
<code>warm_startbool, default=False</code> </dt>
<dd>
<p>When set to True, reuse the solution of the previous call to fit and add more estimators to the ensemble, otherwise, just fit a whole new ensemble. See <a class="reference internal" href="https://scikit-learn.org/0.24/glossary.html#term-warm_start"><span class="xref std std-term">the Glossary</span></a>.</p> <div class="versionadded"> <p><span class="versionmodified added">New in version 0.17: </span><em>warm_start</em> constructor parameter.</p> </div> </dd> <dt>
<code>n_jobsint, default=None</code> </dt>
<dd>
<p>The number of jobs to run in parallel for both <a class="reference internal" href="#sklearn.ensemble.BaggingClassifier.fit" title="sklearn.ensemble.BaggingClassifier.fit"><code>fit</code></a> and <a class="reference internal" href="#sklearn.ensemble.BaggingClassifier.predict" title="sklearn.ensemble.BaggingClassifier.predict"><code>predict</code></a>. <code>None</code> means 1 unless in a <a class="reference external" href="https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend" title="(in joblib v1.1.0.dev0)"><code>joblib.parallel_backend</code></a> context. <code>-1</code> means using all processors. See <a class="reference internal" href="https://scikit-learn.org/0.24/glossary.html#term-n_jobs"><span class="xref std std-term">Glossary</span></a> for more details.</p> </dd> <dt>
<code>random_stateint, RandomState instance or None, default=None</code> </dt>
<dd>
<p>Controls the random resampling of the original dataset (sample wise and feature wise). If the base estimator accepts a <code>random_state</code> attribute, a different seed is generated for each instance in the ensemble. Pass an int for reproducible output across multiple function calls. See <a class="reference internal" href="https://scikit-learn.org/0.24/glossary.html#term-random_state"><span class="xref std std-term">Glossary</span></a>.</p> </dd> <dt>
<code>verboseint, default=0</code> </dt>
<dd>
<p>Controls the verbosity when fitting and predicting.</p> </dd> </dl> </dd> <dt class="field-even">Attributes</dt> <dd class="field-even">
<dl class="simple"> <dt>
<code>base_estimator_estimator</code> </dt>
<dd>
<p>The base estimator from which the ensemble is grown.</p> </dd> <dt>
<code>n_features_int</code> </dt>
<dd>
<p>The number of features when <a class="reference internal" href="#sklearn.ensemble.BaggingClassifier.fit" title="sklearn.ensemble.BaggingClassifier.fit"><code>fit</code></a> is performed.</p> </dd> <dt>
<code>estimators_list of estimators</code> </dt>
<dd>
<p>The collection of fitted base estimators.</p> </dd> <dt>
<code>estimators_samples_list of arrays</code> </dt>
<dd>
<p>The subset of drawn samples for each base estimator.</p> </dd> <dt>
<code>estimators_features_list of arrays</code> </dt>
<dd>
<p>The subset of drawn features for each base estimator.</p> </dd> <dt>
<code>classes_ndarray of shape (n_classes,)</code> </dt>
<dd>
<p>The classes labels.</p> </dd> <dt>
<code>n_classes_int or list</code> </dt>
<dd>
<p>The number of classes.</p> </dd> <dt>
<code>oob_score_float</code> </dt>
<dd>
<p>Score of the training dataset obtained using an out-of-bag estimate. This attribute exists only when <code>oob_score</code> is True.</p> </dd> <dt>
<code>oob_decision_function_ndarray of shape (n_samples, n_classes)</code> </dt>
<dd>
<p>Decision function computed with out-of-bag estimate on the training set. If n_estimators is small it might be possible that a data point was never left out during the bootstrap. In this case, <code>oob_decision_function_</code> might contain NaN. This attribute exists only when <code>oob_score</code> is True.</p> </dd> </dl> </dd> </dl> <h4 class="rubric">References</h4> <dl class="citation"> <dt class="label" id="rb1846455d0e5-1">
<code>1</code> </dt> <dd>
<p>L. Breiman, “Pasting small votes for classification in large databases and on-line”, Machine Learning, 36(1), 85-103, 1999.</p> </dd> <dt class="label" id="rb1846455d0e5-2">
<code>2</code> </dt> <dd>
<p>L. Breiman, “Bagging predictors”, Machine Learning, 24(2), 123-140, 1996.</p> </dd> <dt class="label" id="rb1846455d0e5-3">
<code>3</code> </dt> <dd>
<p>T. Ho, “The random subspace method for constructing decision forests”, Pattern Analysis and Machine Intelligence, 20(8), 832-844, 1998.</p> </dd> <dt class="label" id="rb1846455d0e5-4">
<code>4</code> </dt> <dd>
<p>G. Louppe and P. Geurts, “Ensembles on Random Patches”, Machine Learning and Knowledge Discovery in Databases, 346-361, 2012.</p> </dd> </dl> <h4 class="rubric">Examples</h4> <pre data-language="python">&gt;&gt;&gt; from sklearn.svm import SVC
&gt;&gt;&gt; from sklearn.ensemble import BaggingClassifier
&gt;&gt;&gt; from sklearn.datasets import make_classification
&gt;&gt;&gt; X, y = make_classification(n_samples=100, n_features=4,
...                            n_informative=2, n_redundant=0,
...                            random_state=0, shuffle=False)
&gt;&gt;&gt; clf = BaggingClassifier(base_estimator=SVC(),
...                         n_estimators=10, random_state=0).fit(X, y)
&gt;&gt;&gt; clf.predict([[0, 0, 0, 0]])
array([1])
</pre> <h4 class="rubric">Methods</h4> <table class="longtable docutils align-default">   <tr>
<td><p><a class="reference internal" href="#sklearn.ensemble.BaggingClassifier.decision_function" title="sklearn.ensemble.BaggingClassifier.decision_function"><code>decision_function</code></a>(X)</p></td> <td><p>Average of the decision functions of the base classifiers.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="#sklearn.ensemble.BaggingClassifier.fit" title="sklearn.ensemble.BaggingClassifier.fit"><code>fit</code></a>(X, y[, sample_weight])</p></td> <td><p>Build a Bagging ensemble of estimators from the training</p></td> </tr> <tr>
<td><p><a class="reference internal" href="#sklearn.ensemble.BaggingClassifier.get_params" title="sklearn.ensemble.BaggingClassifier.get_params"><code>get_params</code></a>([deep])</p></td> <td><p>Get parameters for this estimator.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="#sklearn.ensemble.BaggingClassifier.predict" title="sklearn.ensemble.BaggingClassifier.predict"><code>predict</code></a>(X)</p></td> <td><p>Predict class for X.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="#sklearn.ensemble.BaggingClassifier.predict_log_proba" title="sklearn.ensemble.BaggingClassifier.predict_log_proba"><code>predict_log_proba</code></a>(X)</p></td> <td><p>Predict class log-probabilities for X.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="#sklearn.ensemble.BaggingClassifier.predict_proba" title="sklearn.ensemble.BaggingClassifier.predict_proba"><code>predict_proba</code></a>(X)</p></td> <td><p>Predict class probabilities for X.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="#sklearn.ensemble.BaggingClassifier.score" title="sklearn.ensemble.BaggingClassifier.score"><code>score</code></a>(X, y[, sample_weight])</p></td> <td><p>Return the mean accuracy on the given test data and labels.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="#sklearn.ensemble.BaggingClassifier.set_params" title="sklearn.ensemble.BaggingClassifier.set_params"><code>set_params</code></a>(**params)</p></td> <td><p>Set the parameters of this estimator.</p></td> </tr>  </table> <dl class="py method"> <dt id="sklearn.ensemble.BaggingClassifier.decision_function">
<code>decision_function(X)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/95119c13a/sklearn/ensemble/_bagging.py#L792"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Average of the decision functions of the base classifiers.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<dl class="simple"> <dt>
<code>X{array-like, sparse matrix} of shape (n_samples, n_features)</code> </dt>
<dd>
<p>The training input samples. Sparse matrices are accepted only if they are supported by the base estimator.</p> </dd> </dl> </dd> <dt class="field-even">Returns</dt> <dd class="field-even">
<dl class="simple"> <dt>
<code>scorendarray of shape (n_samples, k)</code> </dt>
<dd>
<p>The decision function of the input samples. The columns correspond to the classes in sorted order, as they appear in the attribute <code>classes_</code>. Regression and binary classification are special cases with <code>k == 1</code>, otherwise <code>k==n_classes</code>.</p> </dd> </dl> </dd> </dl> </dd>
</dl> <dl class="py method"> <dt id="sklearn.ensemble.BaggingClassifier.estimators_samples_">
<code>property estimators_samples_</code> </dt> <dd>
<p>The subset of drawn samples for each base estimator.</p> <p>Returns a dynamically generated list of indices identifying the samples used for fitting each member of the ensemble, i.e., the in-bag samples.</p> <p>Note: the list is re-created at each call to the property in order to reduce the object memory footprint by not storing the sampling data. Thus fetching the property may be slower than expected.</p> </dd>
</dl> <dl class="py method"> <dt id="sklearn.ensemble.BaggingClassifier.fit">
<code>fit(X, y, sample_weight=None)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/95119c13a/sklearn/ensemble/_bagging.py#L221"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<dl class="simple"> <dt>Build a Bagging ensemble of estimators from the training</dt>
<dd>
<p>set (X, y).</p> </dd> </dl> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<dl class="simple"> <dt>
<code>X{array-like, sparse matrix} of shape (n_samples, n_features)</code> </dt>
<dd>
<p>The training input samples. Sparse matrices are accepted only if they are supported by the base estimator.</p> </dd> <dt>
<code>yarray-like of shape (n_samples,)</code> </dt>
<dd>
<p>The target values (class labels in classification, real numbers in regression).</p> </dd> <dt>
<code>sample_weightarray-like of shape (n_samples,), default=None</code> </dt>
<dd>
<p>Sample weights. If None, then samples are equally weighted. Note that this is supported only if the base estimator supports sample weighting.</p> </dd> </dl> </dd> <dt class="field-even">Returns</dt> <dd class="field-even">
<dl class="simple"> <dt>
<code>selfobject</code> </dt>
 </dl> </dd> </dl> </dd>
</dl> <dl class="py method"> <dt id="sklearn.ensemble.BaggingClassifier.get_params">
<code>get_params(deep=True)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/95119c13a/sklearn/base.py#L178"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Get parameters for this estimator.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<dl class="simple"> <dt>
<code>deepbool, default=True</code> </dt>
<dd>
<p>If True, will return the parameters for this estimator and contained subobjects that are estimators.</p> </dd> </dl> </dd> <dt class="field-even">Returns</dt> <dd class="field-even">
<dl class="simple"> <dt>
<code>paramsdict</code> </dt>
<dd>
<p>Parameter names mapped to their values.</p> </dd> </dl> </dd> </dl> </dd>
</dl> <dl class="py method"> <dt id="sklearn.ensemble.BaggingClassifier.predict">
<code>predict(X)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/95119c13a/sklearn/ensemble/_bagging.py#L659"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Predict class for X.</p> <p>The predicted class of an input sample is computed as the class with the highest mean predicted probability. If base estimators do not implement a <code>predict_proba</code> method, then it resorts to voting.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<dl class="simple"> <dt>
<code>X{array-like, sparse matrix} of shape (n_samples, n_features)</code> </dt>
<dd>
<p>The training input samples. Sparse matrices are accepted only if they are supported by the base estimator.</p> </dd> </dl> </dd> <dt class="field-even">Returns</dt> <dd class="field-even">
<dl class="simple"> <dt>
<code>yndarray of shape (n_samples,)</code> </dt>
<dd>
<p>The predicted classes.</p> </dd> </dl> </dd> </dl> </dd>
</dl> <dl class="py method"> <dt id="sklearn.ensemble.BaggingClassifier.predict_log_proba">
<code>predict_log_proba(X)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/95119c13a/sklearn/ensemble/_bagging.py#L734"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Predict class log-probabilities for X.</p> <p>The predicted class log-probabilities of an input sample is computed as the log of the mean predicted class probabilities of the base estimators in the ensemble.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<dl class="simple"> <dt>
<code>X{array-like, sparse matrix} of shape (n_samples, n_features)</code> </dt>
<dd>
<p>The training input samples. Sparse matrices are accepted only if they are supported by the base estimator.</p> </dd> </dl> </dd> <dt class="field-even">Returns</dt> <dd class="field-even">
<dl class="simple"> <dt>
<code>pndarray of shape (n_samples, n_classes)</code> </dt>
<dd>
<p>The class log-probabilities of the input samples. The order of the classes corresponds to that in the attribute <a class="reference internal" href="https://scikit-learn.org/0.24/glossary.html#term-classes_"><span class="xref std std-term">classes_</span></a>.</p> </dd> </dl> </dd> </dl> </dd>
</dl> <dl class="py method"> <dt id="sklearn.ensemble.BaggingClassifier.predict_proba">
<code>predict_proba(X)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/95119c13a/sklearn/ensemble/_bagging.py#L681"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Predict class probabilities for X.</p> <p>The predicted class probabilities of an input sample is computed as the mean predicted class probabilities of the base estimators in the ensemble. If base estimators do not implement a <code>predict_proba</code> method, then it resorts to voting and the predicted class probabilities of an input sample represents the proportion of estimators predicting each class.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<dl class="simple"> <dt>
<code>X{array-like, sparse matrix} of shape (n_samples, n_features)</code> </dt>
<dd>
<p>The training input samples. Sparse matrices are accepted only if they are supported by the base estimator.</p> </dd> </dl> </dd> <dt class="field-even">Returns</dt> <dd class="field-even">
<dl class="simple"> <dt>
<code>pndarray of shape (n_samples, n_classes)</code> </dt>
<dd>
<p>The class probabilities of the input samples. The order of the classes corresponds to that in the attribute <a class="reference internal" href="https://scikit-learn.org/0.24/glossary.html#term-classes_"><span class="xref std std-term">classes_</span></a>.</p> </dd> </dl> </dd> </dl> </dd>
</dl> <dl class="py method"> <dt id="sklearn.ensemble.BaggingClassifier.score">
<code>score(X, y, sample_weight=None)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/95119c13a/sklearn/base.py#L475"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Return the mean accuracy on the given test data and labels.</p> <p>In multi-label classification, this is the subset accuracy which is a harsh metric since you require for each sample that each label set be correctly predicted.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<dl class="simple"> <dt>
<code>Xarray-like of shape (n_samples, n_features)</code> </dt>
<dd>
<p>Test samples.</p> </dd> <dt>
<code>yarray-like of shape (n_samples,) or (n_samples, n_outputs)</code> </dt>
<dd>
<p>True labels for <code>X</code>.</p> </dd> <dt>
<code>sample_weightarray-like of shape (n_samples,), default=None</code> </dt>
<dd>
<p>Sample weights.</p> </dd> </dl> </dd> <dt class="field-even">Returns</dt> <dd class="field-even">
<dl class="simple"> <dt>
<code>scorefloat</code> </dt>
<dd>
<p>Mean accuracy of <code>self.predict(X)</code> wrt. <code>y</code>.</p> </dd> </dl> </dd> </dl> </dd>
</dl> <dl class="py method"> <dt id="sklearn.ensemble.BaggingClassifier.set_params">
<code>set_params(**params)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/95119c13a/sklearn/base.py#L202"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Set the parameters of this estimator.</p> <p>The method works on simple estimators as well as on nested objects (such as <a class="reference internal" href="sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline" title="sklearn.pipeline.Pipeline"><code>Pipeline</code></a>). The latter have parameters of the form <code>&lt;component&gt;__&lt;parameter&gt;</code> so that it’s possible to update each component of a nested object.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<dl class="simple"> <dt>
<code>**paramsdict</code> </dt>
<dd>
<p>Estimator parameters.</p> </dd> </dl> </dd> <dt class="field-even">Returns</dt> <dd class="field-even">
<dl class="simple"> <dt>
<code>selfestimator instance</code> </dt>
<dd>
<p>Estimator instance.</p> </dd> </dl> </dd> </dl> </dd>
</dl> </dd>
</dl> <div class="_attribution">
  <p class="_attribution-p">
    &copy; 2007&ndash;2020 The scikit-learn developers<br>Licensed under the 3-clause BSD License.<br>
    <a href="https://scikit-learn.org/0.24/modules/generated/sklearn.ensemble.BaggingClassifier.html" class="_attribution-link">https://scikit-learn.org/0.24/modules/generated/sklearn.ensemble.BaggingClassifier.html</a>
  </p>
</div>
