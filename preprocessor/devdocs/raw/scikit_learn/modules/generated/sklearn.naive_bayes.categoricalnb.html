<h1>sklearn.naive_bayes.CategoricalNB</h1> <dl class="py class"> <dt id="sklearn.naive_bayes.CategoricalNB">
<code>class sklearn.naive_bayes.CategoricalNB(*, alpha=1.0, fit_prior=True, class_prior=None, min_categories=None)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/95119c13a/sklearn/naive_bayes.py#L1054"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Naive Bayes classifier for categorical features</p> <p>The categorical Naive Bayes classifier is suitable for classification with discrete features that are categorically distributed. The categories of each feature are drawn from a categorical distribution.</p> <p>Read more in the <a class="reference internal" href="../naive_bayes#categorical-naive-bayes"><span class="std std-ref">User Guide</span></a>.</p> <dl class="field-list"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<dl> <dt>
<code>alphafloat, default=1.0</code> </dt>
<dd>
<p>Additive (Laplace/Lidstone) smoothing parameter (0 for no smoothing).</p> </dd> <dt>
<code>fit_priorbool, default=True</code> </dt>
<dd>
<p>Whether to learn class prior probabilities or not. If false, a uniform prior will be used.</p> </dd> <dt>
<code>class_priorarray-like of shape (n_classes,), default=None</code> </dt>
<dd>
<p>Prior probabilities of the classes. If specified the priors are not adjusted according to the data.</p> </dd> <dt>
<code>min_categoriesint or array-like of shape (n_features,), default=None</code> </dt>
<dd>
<p>Minimum number of categories per feature.</p> <ul class="simple"> <li>integer: Sets the minimum number of categories per feature to <code>n_categories</code> for each features.</li> <li>array-like: shape (n_features,) where <code>n_categories[i]</code> holds the minimum number of categories for the ith column of the input.</li> <li>None (default): Determines the number of categories automatically from the training data.</li> </ul> <div class="versionadded"> <p><span class="versionmodified added">New in version 0.24.</span></p> </div> </dd> </dl> </dd> <dt class="field-even">Attributes</dt> <dd class="field-even">
<dl> <dt>
<code>category_count_list of arrays of shape (n_features,)</code> </dt>
<dd>
<p>Holds arrays of shape (n_classes, n_categories of respective feature) for each feature. Each array provides the number of samples encountered for each class and category of the specific feature.</p> </dd> <dt>
<code>class_count_ndarray of shape (n_classes,)</code> </dt>
<dd>
<p>Number of samples encountered for each class during fitting. This value is weighted by the sample weight when provided.</p> </dd> <dt>
<code>class_log_prior_ndarray of shape (n_classes,)</code> </dt>
<dd>
<p>Smoothed empirical log probability for each class.</p> </dd> <dt>
<code>classes_ndarray of shape (n_classes,)</code> </dt>
<dd>
<p>Class labels known to the classifier</p> </dd> <dt>
<code>feature_log_prob_list of arrays of shape (n_features,)</code> </dt>
<dd>
<p>Holds arrays of shape (n_classes, n_categories of respective feature) for each feature. Each array provides the empirical log probability of categories given the respective feature and class, <code>P(x_i|y)</code>.</p> </dd> <dt>
<code>n_features_int</code> </dt>
<dd>
<p>Number of features of each sample.</p> </dd> <dt>
<code>n_categories_ndarray of shape (n_features,), dtype=np.int64</code> </dt>
<dd>
<p>Number of categories for each feature. This value is inferred from the data or set by the minimum number of categories.</p> <div class="versionadded"> <p><span class="versionmodified added">New in version 0.24.</span></p> </div> </dd> </dl> </dd> </dl> <h4 class="rubric">Examples</h4> <pre data-language="python">&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; rng = np.random.RandomState(1)
&gt;&gt;&gt; X = rng.randint(5, size=(6, 100))
&gt;&gt;&gt; y = np.array([1, 2, 3, 4, 5, 6])
&gt;&gt;&gt; from sklearn.naive_bayes import CategoricalNB
&gt;&gt;&gt; clf = CategoricalNB()
&gt;&gt;&gt; clf.fit(X, y)
CategoricalNB()
&gt;&gt;&gt; print(clf.predict(X[2:3]))
[3]
</pre> <h4 class="rubric">Methods</h4> <table class="longtable docutils align-default">   <tr>
<td><p><a class="reference internal" href="#sklearn.naive_bayes.CategoricalNB.fit" title="sklearn.naive_bayes.CategoricalNB.fit"><code>fit</code></a>(X, y[, sample_weight])</p></td> <td><p>Fit Naive Bayes classifier according to X, y</p></td> </tr> <tr>
<td><p><a class="reference internal" href="#sklearn.naive_bayes.CategoricalNB.get_params" title="sklearn.naive_bayes.CategoricalNB.get_params"><code>get_params</code></a>([deep])</p></td> <td><p>Get parameters for this estimator.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="#sklearn.naive_bayes.CategoricalNB.partial_fit" title="sklearn.naive_bayes.CategoricalNB.partial_fit"><code>partial_fit</code></a>(X, y[, classes, sample_weight])</p></td> <td><p>Incremental fit on a batch of samples.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="#sklearn.naive_bayes.CategoricalNB.predict" title="sklearn.naive_bayes.CategoricalNB.predict"><code>predict</code></a>(X)</p></td> <td><p>Perform classification on an array of test vectors X.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="#sklearn.naive_bayes.CategoricalNB.predict_log_proba" title="sklearn.naive_bayes.CategoricalNB.predict_log_proba"><code>predict_log_proba</code></a>(X)</p></td> <td><p>Return log-probability estimates for the test vector X.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="#sklearn.naive_bayes.CategoricalNB.predict_proba" title="sklearn.naive_bayes.CategoricalNB.predict_proba"><code>predict_proba</code></a>(X)</p></td> <td><p>Return probability estimates for the test vector X.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="#sklearn.naive_bayes.CategoricalNB.score" title="sklearn.naive_bayes.CategoricalNB.score"><code>score</code></a>(X, y[, sample_weight])</p></td> <td><p>Return the mean accuracy on the given test data and labels.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="#sklearn.naive_bayes.CategoricalNB.set_params" title="sklearn.naive_bayes.CategoricalNB.set_params"><code>set_params</code></a>(**params)</p></td> <td><p>Set the parameters of this estimator.</p></td> </tr>  </table> <dl class="py method"> <dt id="sklearn.naive_bayes.CategoricalNB.fit">
<code>fit(X, y, sample_weight=None)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/95119c13a/sklearn/naive_bayes.py#L1142"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Fit Naive Bayes classifier according to X, y</p> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<dl class="simple"> <dt>
<code>X{array-like, sparse matrix} of shape (n_samples, n_features)</code> </dt>
<dd>
<p>Training vectors, where n_samples is the number of samples and n_features is the number of features. Here, each feature of X is assumed to be from a different categorical distribution. It is further assumed that all categories of each feature are represented by the numbers 0, …, n - 1, where n refers to the total number of categories for the given feature. This can, for instance, be achieved with the help of OrdinalEncoder.</p> </dd> <dt>
<code>yarray-like of shape (n_samples,)</code> </dt>
<dd>
<p>Target values.</p> </dd> <dt>
<code>sample_weightarray-like of shape (n_samples), default=None</code> </dt>
<dd>
<p>Weights applied to individual samples (1. for unweighted).</p> </dd> </dl> </dd> <dt class="field-even">Returns</dt> <dd class="field-even">
<dl class="simple"> <dt>
<code>selfobject</code> </dt>
 </dl> </dd> </dl> </dd>
</dl> <dl class="py method"> <dt id="sklearn.naive_bayes.CategoricalNB.get_params">
<code>get_params(deep=True)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/95119c13a/sklearn/base.py#L178"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Get parameters for this estimator.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<dl class="simple"> <dt>
<code>deepbool, default=True</code> </dt>
<dd>
<p>If True, will return the parameters for this estimator and contained subobjects that are estimators.</p> </dd> </dl> </dd> <dt class="field-even">Returns</dt> <dd class="field-even">
<dl class="simple"> <dt>
<code>paramsdict</code> </dt>
<dd>
<p>Parameter names mapped to their values.</p> </dd> </dl> </dd> </dl> </dd>
</dl> <dl class="py method"> <dt id="sklearn.naive_bayes.CategoricalNB.partial_fit">
<code>partial_fit(X, y, classes=None, sample_weight=None)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/95119c13a/sklearn/naive_bayes.py#L1168"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Incremental fit on a batch of samples.</p> <p>This method is expected to be called several times consecutively on different chunks of a dataset so as to implement out-of-core or online learning.</p> <p>This is especially useful when the whole dataset is too big to fit in memory at once.</p> <p>This method has some performance overhead hence it is better to call partial_fit on chunks of data that are as large as possible (as long as fitting in the memory budget) to hide the overhead.</p> <dl class="field-list"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<dl> <dt>
<code>X{array-like, sparse matrix} of shape (n_samples, n_features)</code> </dt>
<dd>
<p>Training vectors, where n_samples is the number of samples and n_features is the number of features. Here, each feature of X is assumed to be from a different categorical distribution. It is further assumed that all categories of each feature are represented by the numbers 0, …, n - 1, where n refers to the total number of categories for the given feature. This can, for instance, be achieved with the help of OrdinalEncoder.</p> </dd> <dt>
<code>yarray-like of shape (n_samples)</code> </dt>
<dd>
<p>Target values.</p> </dd> <dt>
<code>classesarray-like of shape (n_classes), default=None</code> </dt>
<dd>
<p>List of all the classes that can possibly appear in the y vector.</p> <p>Must be provided at the first call to partial_fit, can be omitted in subsequent calls.</p> </dd> <dt>
<code>sample_weightarray-like of shape (n_samples), default=None</code> </dt>
<dd>
<p>Weights applied to individual samples (1. for unweighted).</p> </dd> </dl> </dd> <dt class="field-even">Returns</dt> <dd class="field-even">
<dl class="simple"> <dt>
<code>selfobject</code> </dt>
 </dl> </dd> </dl> </dd>
</dl> <dl class="py method"> <dt id="sklearn.naive_bayes.CategoricalNB.predict">
<code>predict(X)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/95119c13a/sklearn/naive_bayes.py#L60"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Perform classification on an array of test vectors X.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<dl class="simple"> <dt>
<code>Xarray-like of shape (n_samples, n_features)</code> </dt>
 </dl> </dd> <dt class="field-even">Returns</dt> <dd class="field-even">
<dl class="simple"> <dt>
<code>Cndarray of shape (n_samples,)</code> </dt>
<dd>
<p>Predicted target values for X</p> </dd> </dl> </dd> </dl> </dd>
</dl> <dl class="py method"> <dt id="sklearn.naive_bayes.CategoricalNB.predict_log_proba">
<code>predict_log_proba(X)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/95119c13a/sklearn/naive_bayes.py#L78"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Return log-probability estimates for the test vector X.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<dl class="simple"> <dt>
<code>Xarray-like of shape (n_samples, n_features)</code> </dt>
 </dl> </dd> <dt class="field-even">Returns</dt> <dd class="field-even">
<dl class="simple"> <dt>
<code>Carray-like of shape (n_samples, n_classes)</code> </dt>
<dd>
<p>Returns the log-probability of the samples for each class in the model. The columns correspond to the classes in sorted order, as they appear in the attribute <a class="reference internal" href="https://scikit-learn.org/0.24/glossary.html#term-classes_"><span class="xref std std-term">classes_</span></a>.</p> </dd> </dl> </dd> </dl> </dd>
</dl> <dl class="py method"> <dt id="sklearn.naive_bayes.CategoricalNB.predict_proba">
<code>predict_proba(X)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/95119c13a/sklearn/naive_bayes.py#L100"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Return probability estimates for the test vector X.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<dl class="simple"> <dt>
<code>Xarray-like of shape (n_samples, n_features)</code> </dt>
 </dl> </dd> <dt class="field-even">Returns</dt> <dd class="field-even">
<dl class="simple"> <dt>
<code>Carray-like of shape (n_samples, n_classes)</code> </dt>
<dd>
<p>Returns the probability of the samples for each class in the model. The columns correspond to the classes in sorted order, as they appear in the attribute <a class="reference internal" href="https://scikit-learn.org/0.24/glossary.html#term-classes_"><span class="xref std std-term">classes_</span></a>.</p> </dd> </dl> </dd> </dl> </dd>
</dl> <dl class="py method"> <dt id="sklearn.naive_bayes.CategoricalNB.score">
<code>score(X, y, sample_weight=None)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/95119c13a/sklearn/base.py#L475"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Return the mean accuracy on the given test data and labels.</p> <p>In multi-label classification, this is the subset accuracy which is a harsh metric since you require for each sample that each label set be correctly predicted.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<dl class="simple"> <dt>
<code>Xarray-like of shape (n_samples, n_features)</code> </dt>
<dd>
<p>Test samples.</p> </dd> <dt>
<code>yarray-like of shape (n_samples,) or (n_samples, n_outputs)</code> </dt>
<dd>
<p>True labels for <code>X</code>.</p> </dd> <dt>
<code>sample_weightarray-like of shape (n_samples,), default=None</code> </dt>
<dd>
<p>Sample weights.</p> </dd> </dl> </dd> <dt class="field-even">Returns</dt> <dd class="field-even">
<dl class="simple"> <dt>
<code>scorefloat</code> </dt>
<dd>
<p>Mean accuracy of <code>self.predict(X)</code> wrt. <code>y</code>.</p> </dd> </dl> </dd> </dl> </dd>
</dl> <dl class="py method"> <dt id="sklearn.naive_bayes.CategoricalNB.set_params">
<code>set_params(**params)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/95119c13a/sklearn/base.py#L202"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Set the parameters of this estimator.</p> <p>The method works on simple estimators as well as on nested objects (such as <a class="reference internal" href="sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline" title="sklearn.pipeline.Pipeline"><code>Pipeline</code></a>). The latter have parameters of the form <code>&lt;component&gt;__&lt;parameter&gt;</code> so that it’s possible to update each component of a nested object.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<dl class="simple"> <dt>
<code>**paramsdict</code> </dt>
<dd>
<p>Estimator parameters.</p> </dd> </dl> </dd> <dt class="field-even">Returns</dt> <dd class="field-even">
<dl class="simple"> <dt>
<code>selfestimator instance</code> </dt>
<dd>
<p>Estimator instance.</p> </dd> </dl> </dd> </dl> </dd>
</dl> </dd>
</dl> <div class="_attribution">
  <p class="_attribution-p">
    &copy; 2007&ndash;2020 The scikit-learn developers<br>Licensed under the 3-clause BSD License.<br>
    <a href="https://scikit-learn.org/0.24/modules/generated/sklearn.naive_bayes.CategoricalNB.html" class="_attribution-link">https://scikit-learn.org/0.24/modules/generated/sklearn.naive_bayes.CategoricalNB.html</a>
  </p>
</div>
