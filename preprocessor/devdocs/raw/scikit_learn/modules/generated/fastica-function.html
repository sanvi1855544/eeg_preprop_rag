<h1>sklearn.decomposition.fastica</h1> <dl class="py function"> <dt id="sklearn.decomposition.fastica">
<code>sklearn.decomposition.fastica(X, n_components=None, *, algorithm='parallel', whiten=True, fun='logcosh', fun_args=None, max_iter=200, tol=0.0001, w_init=None, random_state=None, return_X_mean=False, compute_sources=True, return_n_iter=False)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/95119c13a/sklearn/decomposition/_fastica.py#L150"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Perform Fast Independent Component Analysis.</p> <p>Read more in the <a class="reference internal" href="../decomposition#ica"><span class="std std-ref">User Guide</span></a>.</p> <dl class="field-list"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<dl> <dt>
<code>Xarray-like of shape (n_samples, n_features)</code> </dt>
<dd>
<p>Training vector, where n_samples is the number of samples and n_features is the number of features.</p> </dd> <dt>
<code>n_componentsint, default=None</code> </dt>
<dd>
<p>Number of components to extract. If None no dimension reduction is performed.</p> </dd> <dt>
<code>algorithm{‘parallel’, ‘deflation’}, default=’parallel’</code> </dt>
<dd>
<p>Apply a parallel or deflational FASTICA algorithm.</p> </dd> <dt>
<code>whitenbool, default=True</code> </dt>
<dd>
<p>If True perform an initial whitening of the data. If False, the data is assumed to have already been preprocessed: it should be centered, normed and white. Otherwise you will get incorrect results. In this case the parameter n_components will be ignored.</p> </dd> <dt>
<code>fun{‘logcosh’, ‘exp’, ‘cube’} or callable, default=’logcosh’</code> </dt>
<dd>
<p>The functional form of the G function used in the approximation to neg-entropy. Could be either ‘logcosh’, ‘exp’, or ‘cube’. You can also provide your own function. It should return a tuple containing the value of the function, and of its derivative, in the point. The derivative should be averaged along its last dimension. Example:</p> <dl class="simple"> <dt>def my_g(x):</dt>
<dd>
<p>return x ** 3, np.mean(3 * x ** 2, axis=-1)</p> </dd> </dl> </dd> <dt>
<code>fun_argsdict, default=None</code> </dt>
<dd>
<p>Arguments to send to the functional form. If empty or None and if fun=’logcosh’, fun_args will take value {‘alpha’ : 1.0}</p> </dd> <dt>
<code>max_iterint, default=200</code> </dt>
<dd>
<p>Maximum number of iterations to perform.</p> </dd> <dt>
<code>tolfloat, default=1e-04</code> </dt>
<dd>
<p>A positive scalar giving the tolerance at which the un-mixing matrix is considered to have converged.</p> </dd> <dt>
<code>w_initndarray of shape (n_components, n_components), default=None</code> </dt>
<dd>
<p>Initial un-mixing array of dimension (n.comp,n.comp). If None (default) then an array of normal r.v.’s is used.</p> </dd> <dt>
<code>random_stateint, RandomState instance or None, default=None</code> </dt>
<dd>
<p>Used to initialize <code>w_init</code> when not specified, with a normal distribution. Pass an int, for reproducible results across multiple function calls. See <a class="reference internal" href="https://scikit-learn.org/0.24/glossary.html#term-random_state"><span class="xref std std-term">Glossary</span></a>.</p> </dd> <dt>
<code>return_X_meanbool, default=False</code> </dt>
<dd>
<p>If True, X_mean is returned too.</p> </dd> <dt>
<code>compute_sourcesbool, default=True</code> </dt>
<dd>
<p>If False, sources are not computed, but only the rotation matrix. This can save memory when working with big data. Defaults to True.</p> </dd> <dt>
<code>return_n_iterbool, default=False</code> </dt>
<dd>
<p>Whether or not to return the number of iterations.</p> </dd> </dl> </dd> <dt class="field-even">Returns</dt> <dd class="field-even">
<dl class="simple"> <dt>
<code>Kndarray of shape (n_components, n_features) or None</code> </dt>
<dd>
<p>If whiten is ‘True’, K is the pre-whitening matrix that projects data onto the first n_components principal components. If whiten is ‘False’, K is ‘None’.</p> </dd> <dt>
<code>Wndarray of shape (n_components, n_components)</code> </dt>
<dd>
<p>The square matrix that unmixes the data after whitening. The mixing matrix is the pseudo-inverse of matrix <code>W K</code> if K is not None, else it is the inverse of W.</p> </dd> <dt>
<code>Sndarray of shape (n_samples, n_components) or None</code> </dt>
<dd>
<p>Estimated source matrix</p> </dd> <dt>
<code>X_meanndarray of shape (n_features,)</code> </dt>
<dd>
<p>The mean over features. Returned only if return_X_mean is True.</p> </dd> <dt>
<code>n_iterint</code> </dt>
<dd>
<p>If the algorithm is “deflation”, n_iter is the maximum number of iterations run across all components. Else they are just the number of iterations taken to converge. This is returned only when return_n_iter is set to <code>True</code>.</p> </dd> </dl> </dd> </dl> <h4 class="rubric">Notes</h4> <p>The data matrix X is considered to be a linear combination of non-Gaussian (independent) components i.e. X = AS where columns of S contain the independent components and A is a linear mixing matrix. In short ICA attempts to <code>un-mix' the data by estimating an
un-mixing matrix W where ``S = W K X.`</code> While FastICA was proposed to estimate as many sources as features, it is possible to estimate less by setting n_components &lt; n_features. It this case K is not a square matrix and the estimated A is the pseudo-inverse of <code>W K</code>.</p> <p>This implementation was originally made for data of shape [n_features, n_samples]. Now the input is transposed before the algorithm is applied. This makes it slightly faster for Fortran-ordered input.</p> <p>Implemented using FastICA: <em>A. Hyvarinen and E. Oja, Independent Component Analysis: Algorithms and Applications, Neural Networks, 13(4-5), 2000, pp. 411-430</em></p> </dd>
</dl> <div class="_attribution">
  <p class="_attribution-p">
    &copy; 2007&ndash;2020 The scikit-learn developers<br>Licensed under the 3-clause BSD License.<br>
    <a href="https://scikit-learn.org/0.24/modules/generated/fastica-function.html" class="_attribution-link">https://scikit-learn.org/0.24/modules/generated/fastica-function.html</a>
  </p>
</div>
