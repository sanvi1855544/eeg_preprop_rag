<h1>sklearn.linear_model.LassoLars</h1> <dl class="py class"> <dt id="sklearn.linear_model.LassoLars">
<code>class sklearn.linear_model.LassoLars(alpha=1.0, *, fit_intercept=True, verbose=False, normalize=True, precompute='auto', max_iter=500, eps=2.220446049250313e-16, copy_X=True, fit_path=True, positive=False, jitter=None, random_state=None)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/95119c13a/sklearn/linear_model/_least_angle.py#L1039"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Lasso model fit with Least Angle Regression a.k.a. Lars</p> <p>It is a Linear Model trained with an L1 prior as regularizer.</p> <p>The optimization objective for Lasso is:</p> <pre data-language="python">(1 / (2 * n_samples)) * ||y - Xw||^2_2 + alpha * ||w||_1
</pre> <p>Read more in the <a class="reference internal" href="../linear_model#least-angle-regression"><span class="std std-ref">User Guide</span></a>.</p> <dl class="field-list"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<dl> <dt>
<code>alphafloat, default=1.0</code> </dt>
<dd>
<p>Constant that multiplies the penalty term. Defaults to 1.0. <code>alpha = 0</code> is equivalent to an ordinary least square, solved by <a class="reference internal" href="sklearn.linear_model.linearregression#sklearn.linear_model.LinearRegression" title="sklearn.linear_model.LinearRegression"><code>LinearRegression</code></a>. For numerical reasons, using <code>alpha = 0</code> with the LassoLars object is not advised and you should prefer the LinearRegression object.</p> </dd> <dt>
<code>fit_interceptbool, default=True</code> </dt>
<dd>
<p>whether to calculate the intercept for this model. If set to false, no intercept will be used in calculations (i.e. data is expected to be centered).</p> </dd> <dt>
<code>verbosebool or int, default=False</code> </dt>
<dd>
<p>Sets the verbosity amount.</p> </dd> <dt>
<code>normalizebool, default=True</code> </dt>
<dd>
<p>This parameter is ignored when <code>fit_intercept</code> is set to False. If True, the regressors X will be normalized before regression by subtracting the mean and dividing by the l2-norm. If you wish to standardize, please use <a class="reference internal" href="sklearn.preprocessing.standardscaler#sklearn.preprocessing.StandardScaler" title="sklearn.preprocessing.StandardScaler"><code>StandardScaler</code></a> before calling <code>fit</code> on an estimator with <code>normalize=False</code>.</p> </dd> <dt>
<code>precomputebool, ‘auto’ or array-like, default=’auto’</code> </dt>
<dd>
<p>Whether to use a precomputed Gram matrix to speed up calculations. If set to <code>'auto'</code> let us decide. The Gram matrix can also be passed as argument.</p> </dd> <dt>
<code>max_iterint, default=500</code> </dt>
<dd>
<p>Maximum number of iterations to perform.</p> </dd> <dt>
<code>epsfloat, default=np.finfo(float).eps</code> </dt>
<dd>
<p>The machine-precision regularization in the computation of the Cholesky diagonal factors. Increase this for very ill-conditioned systems. Unlike the <code>tol</code> parameter in some iterative optimization-based algorithms, this parameter does not control the tolerance of the optimization.</p> </dd> <dt>
<code>copy_Xbool, default=True</code> </dt>
<dd>
<p>If True, X will be copied; else, it may be overwritten.</p> </dd> <dt>
<code>fit_pathbool, default=True</code> </dt>
<dd>
<p>If <code>True</code> the full path is stored in the <code>coef_path_</code> attribute. If you compute the solution for a large problem or many targets, setting <code>fit_path</code> to <code>False</code> will lead to a speedup, especially with a small alpha.</p> </dd> <dt>
<code>positivebool, default=False</code> </dt>
<dd>
<p>Restrict coefficients to be &gt;= 0. Be aware that you might want to remove fit_intercept which is set True by default. Under the positive restriction the model coefficients will not converge to the ordinary-least-squares solution for small values of alpha. Only coefficients up to the smallest alpha value (<code>alphas_[alphas_ &gt;
0.].min()</code> when fit_path=True) reached by the stepwise Lars-Lasso algorithm are typically in congruence with the solution of the coordinate descent Lasso estimator.</p> </dd> <dt>
<code>jitterfloat, default=None</code> </dt>
<dd>
<p>Upper bound on a uniform noise parameter to be added to the <code>y</code> values, to satisfy the model’s assumption of one-at-a-time computations. Might help with stability.</p> <div class="versionadded"> <p><span class="versionmodified added">New in version 0.23.</span></p> </div> </dd> <dt>
<code>random_stateint, RandomState instance or None, default=None</code> </dt>
<dd>
<p>Determines random number generation for jittering. Pass an int for reproducible output across multiple function calls. See <a class="reference internal" href="https://scikit-learn.org/0.24/glossary.html#term-random_state"><span class="xref std std-term">Glossary</span></a>. Ignored if <code>jitter</code> is None.</p> <div class="versionadded"> <p><span class="versionmodified added">New in version 0.23.</span></p> </div> </dd> </dl> </dd> <dt class="field-even">Attributes</dt> <dd class="field-even">
<dl class="simple"> <dt>
<code>alphas_array-like of shape (n_alphas + 1,) or list of such arrays</code> </dt>
<dd>
<p>Maximum of covariances (in absolute value) at each iteration. <code>n_alphas</code> is either <code>max_iter</code>, <code>n_features</code> or the number of nodes in the path with <code>alpha &gt;= alpha_min</code>, whichever is smaller. If this is a list of array-like, the length of the outer list is <code>n_targets</code>.</p> </dd> <dt>
<code>active_list of length n_alphas or list of such lists</code> </dt>
<dd>
<p>Indices of active variables at the end of the path. If this is a list of list, the length of the outer list is <code>n_targets</code>.</p> </dd> <dt>
<code>coef_path_array-like of shape (n_features, n_alphas + 1) or list of such arrays</code> </dt>
<dd>
<p>If a list is passed it’s expected to be one of n_targets such arrays. The varying values of the coefficients along the path. It is not present if the <code>fit_path</code> parameter is <code>False</code>. If this is a list of array-like, the length of the outer list is <code>n_targets</code>.</p> </dd> <dt>
<code>coef_array-like of shape (n_features,) or (n_targets, n_features)</code> </dt>
<dd>
<p>Parameter vector (w in the formulation formula).</p> </dd> <dt>
<code>intercept_float or array-like of shape (n_targets,)</code> </dt>
<dd>
<p>Independent term in decision function.</p> </dd> <dt>
<code>n_iter_array-like or int</code> </dt>
<dd>
<p>The number of iterations taken by lars_path to find the grid of alphas for each target.</p> </dd> </dl> </dd> </dl> <div class="admonition seealso"> <p class="admonition-title">See also</p> <dl class="simple"> <dt>
 <a class="reference internal" href="sklearn.linear_model.lars_path#sklearn.linear_model.lars_path" title="sklearn.linear_model.lars_path"><code>lars_path</code></a>
</dt>
 <dt>
 <a class="reference internal" href="sklearn.linear_model.lasso_path#sklearn.linear_model.lasso_path" title="sklearn.linear_model.lasso_path"><code>lasso_path</code></a>
</dt>
 <dt>
 <a class="reference internal" href="sklearn.linear_model.lasso#sklearn.linear_model.Lasso" title="sklearn.linear_model.Lasso"><code>Lasso</code></a>
</dt>
 <dt>
 <a class="reference internal" href="sklearn.linear_model.lassocv#sklearn.linear_model.LassoCV" title="sklearn.linear_model.LassoCV"><code>LassoCV</code></a>
</dt>
 <dt>
 <a class="reference internal" href="sklearn.linear_model.lassolarscv#sklearn.linear_model.LassoLarsCV" title="sklearn.linear_model.LassoLarsCV"><code>LassoLarsCV</code></a>
</dt>
 <dt>
 <a class="reference internal" href="sklearn.linear_model.lassolarsic#sklearn.linear_model.LassoLarsIC" title="sklearn.linear_model.LassoLarsIC"><code>LassoLarsIC</code></a>
</dt>
 <dt>
 <a class="reference internal" href="sklearn.decomposition.sparse_encode#sklearn.decomposition.sparse_encode" title="sklearn.decomposition.sparse_encode"><code>sklearn.decomposition.sparse_encode</code></a>
</dt>
 </dl> </div> <h4 class="rubric">Examples</h4> <pre data-language="python">&gt;&gt;&gt; from sklearn import linear_model
&gt;&gt;&gt; reg = linear_model.LassoLars(alpha=0.01)
&gt;&gt;&gt; reg.fit([[-1, 1], [0, 0], [1, 1]], [-1, 0, -1])
LassoLars(alpha=0.01)
&gt;&gt;&gt; print(reg.coef_)
[ 0.         -0.963257...]
</pre> <h4 class="rubric">Methods</h4> <table class="longtable docutils align-default">   <tr>
<td><p><a class="reference internal" href="#sklearn.linear_model.LassoLars.fit" title="sklearn.linear_model.LassoLars.fit"><code>fit</code></a>(X, y[, Xy])</p></td> <td><p>Fit the model using X, y as training data.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="#sklearn.linear_model.LassoLars.get_params" title="sklearn.linear_model.LassoLars.get_params"><code>get_params</code></a>([deep])</p></td> <td><p>Get parameters for this estimator.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="#sklearn.linear_model.LassoLars.predict" title="sklearn.linear_model.LassoLars.predict"><code>predict</code></a>(X)</p></td> <td><p>Predict using the linear model.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="#sklearn.linear_model.LassoLars.score" title="sklearn.linear_model.LassoLars.score"><code>score</code></a>(X, y[, sample_weight])</p></td> <td><p>Return the coefficient of determination <span class="math notranslate nohighlight">\(R^2\)</span> of the prediction.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="#sklearn.linear_model.LassoLars.set_params" title="sklearn.linear_model.LassoLars.set_params"><code>set_params</code></a>(**params)</p></td> <td><p>Set the parameters of this estimator.</p></td> </tr>  </table> <dl class="py method"> <dt id="sklearn.linear_model.LassoLars.fit">
<code>fit(X, y, Xy=None)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/95119c13a/sklearn/linear_model/_least_angle.py#L997"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Fit the model using X, y as training data.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<dl class="simple"> <dt>
<code>Xarray-like of shape (n_samples, n_features)</code> </dt>
<dd>
<p>Training data.</p> </dd> <dt>
<code>yarray-like of shape (n_samples,) or (n_samples, n_targets)</code> </dt>
<dd>
<p>Target values.</p> </dd> <dt>
<code>Xyarray-like of shape (n_samples,) or (n_samples, n_targets), default=None</code> </dt>
<dd>
<p>Xy = np.dot(X.T, y) that can be precomputed. It is useful only when the Gram matrix is precomputed.</p> </dd> </dl> </dd> <dt class="field-even">Returns</dt> <dd class="field-even">
<dl class="simple"> <dt>
<code>selfobject</code> </dt>
<dd>
<p>returns an instance of self.</p> </dd> </dl> </dd> </dl> </dd>
</dl> <dl class="py method"> <dt id="sklearn.linear_model.LassoLars.get_params">
<code>get_params(deep=True)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/95119c13a/sklearn/base.py#L178"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Get parameters for this estimator.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<dl class="simple"> <dt>
<code>deepbool, default=True</code> </dt>
<dd>
<p>If True, will return the parameters for this estimator and contained subobjects that are estimators.</p> </dd> </dl> </dd> <dt class="field-even">Returns</dt> <dd class="field-even">
<dl class="simple"> <dt>
<code>paramsdict</code> </dt>
<dd>
<p>Parameter names mapped to their values.</p> </dd> </dl> </dd> </dl> </dd>
</dl> <dl class="py method"> <dt id="sklearn.linear_model.LassoLars.predict">
<code>predict(X)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/95119c13a/sklearn/linear_model/_base.py#L224"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Predict using the linear model.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<dl class="simple"> <dt>
<code>Xarray-like or sparse matrix, shape (n_samples, n_features)</code> </dt>
<dd>
<p>Samples.</p> </dd> </dl> </dd> <dt class="field-even">Returns</dt> <dd class="field-even">
<dl class="simple"> <dt>
<code>Carray, shape (n_samples,)</code> </dt>
<dd>
<p>Returns predicted values.</p> </dd> </dl> </dd> </dl> </dd>
</dl> <dl class="py method"> <dt id="sklearn.linear_model.LassoLars.score">
<code>score(X, y, sample_weight=None)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/95119c13a/sklearn/base.py#L510"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Return the coefficient of determination <span class="math notranslate nohighlight">\(R^2\)</span> of the prediction.</p> <p>The coefficient <span class="math notranslate nohighlight">\(R^2\)</span> is defined as <span class="math notranslate nohighlight">\((1 - \frac{u}{v})\)</span>, where <span class="math notranslate nohighlight">\(u\)</span> is the residual sum of squares <code>((y_true - y_pred)
** 2).sum()</code> and <span class="math notranslate nohighlight">\(v\)</span> is the total sum of squares <code>((y_true -
y_true.mean()) ** 2).sum()</code>. The best possible score is 1.0 and it can be negative (because the model can be arbitrarily worse). A constant model that always predicts the expected value of <code>y</code>, disregarding the input features, would get a <span class="math notranslate nohighlight">\(R^2\)</span> score of 0.0.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<dl class="simple"> <dt>
<code>Xarray-like of shape (n_samples, n_features)</code> </dt>
<dd>
<p>Test samples. For some estimators this may be a precomputed kernel matrix or a list of generic objects instead with shape <code>(n_samples, n_samples_fitted)</code>, where <code>n_samples_fitted</code> is the number of samples used in the fitting for the estimator.</p> </dd> <dt>
<code>yarray-like of shape (n_samples,) or (n_samples, n_outputs)</code> </dt>
<dd>
<p>True values for <code>X</code>.</p> </dd> <dt>
<code>sample_weightarray-like of shape (n_samples,), default=None</code> </dt>
<dd>
<p>Sample weights.</p> </dd> </dl> </dd> <dt class="field-even">Returns</dt> <dd class="field-even">
<dl class="simple"> <dt>
<code>scorefloat</code> </dt>
<dd>
<p><span class="math notranslate nohighlight">\(R^2\)</span> of <code>self.predict(X)</code> wrt. <code>y</code>.</p> </dd> </dl> </dd> </dl> <h4 class="rubric">Notes</h4> <p>The <span class="math notranslate nohighlight">\(R^2\)</span> score used when calling <code>score</code> on a regressor uses <code>multioutput='uniform_average'</code> from version 0.23 to keep consistent with default value of <a class="reference internal" href="sklearn.metrics.r2_score#sklearn.metrics.r2_score" title="sklearn.metrics.r2_score"><code>r2_score</code></a>. This influences the <code>score</code> method of all the multioutput regressors (except for <a class="reference internal" href="sklearn.multioutput.multioutputregressor#sklearn.multioutput.MultiOutputRegressor" title="sklearn.multioutput.MultiOutputRegressor"><code>MultiOutputRegressor</code></a>).</p> </dd>
</dl> <dl class="py method"> <dt id="sklearn.linear_model.LassoLars.set_params">
<code>set_params(**params)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/95119c13a/sklearn/base.py#L202"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Set the parameters of this estimator.</p> <p>The method works on simple estimators as well as on nested objects (such as <a class="reference internal" href="sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline" title="sklearn.pipeline.Pipeline"><code>Pipeline</code></a>). The latter have parameters of the form <code>&lt;component&gt;__&lt;parameter&gt;</code> so that it’s possible to update each component of a nested object.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<dl class="simple"> <dt>
<code>**paramsdict</code> </dt>
<dd>
<p>Estimator parameters.</p> </dd> </dl> </dd> <dt class="field-even">Returns</dt> <dd class="field-even">
<dl class="simple"> <dt>
<code>selfestimator instance</code> </dt>
<dd>
<p>Estimator instance.</p> </dd> </dl> </dd> </dl> </dd>
</dl> </dd>
</dl> <div class="_attribution">
  <p class="_attribution-p">
    &copy; 2007&ndash;2020 The scikit-learn developers<br>Licensed under the 3-clause BSD License.<br>
    <a href="https://scikit-learn.org/0.24/modules/generated/sklearn.linear_model.LassoLars.html" class="_attribution-link">https://scikit-learn.org/0.24/modules/generated/sklearn.linear_model.LassoLars.html</a>
  </p>
</div>
