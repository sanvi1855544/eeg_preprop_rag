<h1>sklearn.ensemble.StackingClassifier</h1> <dl class="py class"> <dt id="sklearn.ensemble.StackingClassifier">
<code>class sklearn.ensemble.StackingClassifier(estimators, final_estimator=None, *, cv=None, stack_method='auto', n_jobs=None, passthrough=False, verbose=0)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/95119c13a/sklearn/ensemble/_stacking.py#L258"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Stack of estimators with a final classifier.</p> <p>Stacked generalization consists in stacking the output of individual estimator and use a classifier to compute the final prediction. Stacking allows to use the strength of each individual estimator by using their output as input of a final estimator.</p> <p>Note that <code>estimators_</code> are fitted on the full <code>X</code> while <code>final_estimator_</code> is trained using cross-validated predictions of the base estimators using <code>cross_val_predict</code>.</p> <p>Read more in the <a class="reference internal" href="../ensemble#stacking"><span class="std std-ref">User Guide</span></a>.</p> <div class="versionadded"> <p><span class="versionmodified added">New in version 0.22.</span></p> </div> <dl class="field-list"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<dl> <dt>
<code>estimatorslist of (str, estimator)</code> </dt>
<dd>
<p>Base estimators which will be stacked together. Each element of the list is defined as a tuple of string (i.e. name) and an estimator instance. An estimator can be set to ‘drop’ using <code>set_params</code>.</p> </dd> <dt>
<code>final_estimatorestimator, default=None</code> </dt>
<dd>
<p>A classifier which will be used to combine the base estimators. The default classifier is a <a class="reference internal" href="sklearn.linear_model.logisticregression#sklearn.linear_model.LogisticRegression" title="sklearn.linear_model.LogisticRegression"><code>LogisticRegression</code></a>.</p> </dd> <dt>
<code>cvint, cross-validation generator or an iterable, default=None</code> </dt>
<dd>
<p>Determines the cross-validation splitting strategy used in <code>cross_val_predict</code> to train <code>final_estimator</code>. Possible inputs for cv are:</p> <ul class="simple"> <li>None, to use the default 5-fold cross validation,</li> <li>integer, to specify the number of folds in a (Stratified) KFold,</li> <li>An object to be used as a cross-validation generator,</li> <li>An iterable yielding train, test splits.</li> </ul> <p>For integer/None inputs, if the estimator is a classifier and y is either binary or multiclass, <a class="reference internal" href="sklearn.model_selection.stratifiedkfold#sklearn.model_selection.StratifiedKFold" title="sklearn.model_selection.StratifiedKFold"><code>StratifiedKFold</code></a> is used. In all other cases, <a class="reference internal" href="sklearn.model_selection.kfold#sklearn.model_selection.KFold" title="sklearn.model_selection.KFold"><code>KFold</code></a> is used.</p> <p>Refer <a class="reference internal" href="../cross_validation#cross-validation"><span class="std std-ref">User Guide</span></a> for the various cross-validation strategies that can be used here.</p> <div class="admonition note"> <p class="admonition-title">Note</p> <p>A larger number of split will provide no benefits if the number of training samples is large enough. Indeed, the training time will increase. <code>cv</code> is not used for model evaluation but for prediction.</p> </div> </dd> <dt>
<code>stack_method{‘auto’, ‘predict_proba’, ‘decision_function’, ‘predict’}, default=’auto’</code> </dt>
<dd>
<p>Methods called for each base estimator. It can be:</p> <ul class="simple"> <li>if ‘auto’, it will try to invoke, for each estimator, <code>'predict_proba'</code>, <code>'decision_function'</code> or <code>'predict'</code> in that order.</li> <li>otherwise, one of <code>'predict_proba'</code>, <code>'decision_function'</code> or <code>'predict'</code>. If the method is not implemented by the estimator, it will raise an error.</li> </ul> </dd> <dt>
<code>n_jobsint, default=None</code> </dt>
<dd>
<p>The number of jobs to run in parallel all <code>estimators</code> <code>fit</code>. <code>None</code> means 1 unless in a <code>joblib.parallel_backend</code> context. -1 means using all processors. See Glossary for more details.</p> </dd> <dt>
<code>passthroughbool, default=False</code> </dt>
<dd>
<p>When False, only the predictions of estimators will be used as training data for <code>final_estimator</code>. When True, the <code>final_estimator</code> is trained on the predictions as well as the original training data.</p> </dd> <dt>
<code>verboseint, default=0</code> </dt>
<dd>
<p>Verbosity level.</p> </dd> </dl> </dd> <dt class="field-even">Attributes</dt> <dd class="field-even">
<dl> <dt>
<code>classes_ndarray of shape (n_classes,)</code> </dt>
<dd>
<p>Class labels.</p> </dd> <dt>
<code>estimators_list of estimators</code> </dt>
<dd>
<p>The elements of the estimators parameter, having been fitted on the training data. If an estimator has been set to <code>'drop'</code>, it will not appear in <code>estimators_</code>.</p> </dd> <dt>
<code>named_estimators_Bunch</code> </dt>
<dd>
<p>Attribute to access any fitted sub-estimators by name.</p> </dd> <dt>
<code>final_estimator_estimator</code> </dt>
<dd>
<p>The classifier which predicts given the output of <code>estimators_</code>.</p> </dd> <dt>
<code>stack_method_list of str</code> </dt>
<dd>
<p>The method used by each base estimator.</p> </dd> </dl> </dd> </dl> <h4 class="rubric">Notes</h4> <p>When <code>predict_proba</code> is used by each estimator (i.e. most of the time for <code>stack_method='auto'</code> or specifically for <code>stack_method='predict_proba'</code>), The first column predicted by each estimator will be dropped in the case of a binary classification problem. Indeed, both feature will be perfectly collinear.</p> <h4 class="rubric">References</h4> <dl class="citation"> <dt class="label" id="rb91ed47a817e-1">
<code>1</code> </dt> <dd>
<p>Wolpert, David H. “Stacked generalization.” Neural networks 5.2 (1992): 241-259.</p> </dd> </dl> <h4 class="rubric">Examples</h4> <pre data-language="python">&gt;&gt;&gt; from sklearn.datasets import load_iris
&gt;&gt;&gt; from sklearn.ensemble import RandomForestClassifier
&gt;&gt;&gt; from sklearn.svm import LinearSVC
&gt;&gt;&gt; from sklearn.linear_model import LogisticRegression
&gt;&gt;&gt; from sklearn.preprocessing import StandardScaler
&gt;&gt;&gt; from sklearn.pipeline import make_pipeline
&gt;&gt;&gt; from sklearn.ensemble import StackingClassifier
&gt;&gt;&gt; X, y = load_iris(return_X_y=True)
&gt;&gt;&gt; estimators = [
...     ('rf', RandomForestClassifier(n_estimators=10, random_state=42)),
...     ('svr', make_pipeline(StandardScaler(),
...                           LinearSVC(random_state=42)))
... ]
&gt;&gt;&gt; clf = StackingClassifier(
...     estimators=estimators, final_estimator=LogisticRegression()
... )
&gt;&gt;&gt; from sklearn.model_selection import train_test_split
&gt;&gt;&gt; X_train, X_test, y_train, y_test = train_test_split(
...     X, y, stratify=y, random_state=42
... )
&gt;&gt;&gt; clf.fit(X_train, y_train).score(X_test, y_test)
0.9...
</pre> <h4 class="rubric">Methods</h4> <table class="longtable docutils align-default">   <tr>
<td><p><a class="reference internal" href="#sklearn.ensemble.StackingClassifier.decision_function" title="sklearn.ensemble.StackingClassifier.decision_function"><code>decision_function</code></a>(X)</p></td> <td><p>Predict decision function for samples in X using <code>final_estimator_.decision_function</code>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="#sklearn.ensemble.StackingClassifier.fit" title="sklearn.ensemble.StackingClassifier.fit"><code>fit</code></a>(X, y[, sample_weight])</p></td> <td><p>Fit the estimators.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="#sklearn.ensemble.StackingClassifier.fit_transform" title="sklearn.ensemble.StackingClassifier.fit_transform"><code>fit_transform</code></a>(X[, y])</p></td> <td><p>Fit to data, then transform it.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="#sklearn.ensemble.StackingClassifier.get_params" title="sklearn.ensemble.StackingClassifier.get_params"><code>get_params</code></a>([deep])</p></td> <td><p>Get the parameters of an estimator from the ensemble.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="#sklearn.ensemble.StackingClassifier.predict" title="sklearn.ensemble.StackingClassifier.predict"><code>predict</code></a>(X, **predict_params)</p></td> <td><p>Predict target for X.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="#sklearn.ensemble.StackingClassifier.predict_proba" title="sklearn.ensemble.StackingClassifier.predict_proba"><code>predict_proba</code></a>(X)</p></td> <td><p>Predict class probabilities for X using <code>final_estimator_.predict_proba</code>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="#sklearn.ensemble.StackingClassifier.score" title="sklearn.ensemble.StackingClassifier.score"><code>score</code></a>(X, y[, sample_weight])</p></td> <td><p>Return the mean accuracy on the given test data and labels.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="#sklearn.ensemble.StackingClassifier.set_params" title="sklearn.ensemble.StackingClassifier.set_params"><code>set_params</code></a>(**params)</p></td> <td><p>Set the parameters of an estimator from the ensemble.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="#sklearn.ensemble.StackingClassifier.transform" title="sklearn.ensemble.StackingClassifier.transform"><code>transform</code></a>(X)</p></td> <td><p>Return class labels or probabilities for X for each estimator.</p></td> </tr>  </table> <dl class="py method"> <dt id="sklearn.ensemble.StackingClassifier.decision_function">
<code>decision_function(X)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/95119c13a/sklearn/ensemble/_stacking.py#L485"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Predict decision function for samples in X using <code>final_estimator_.decision_function</code>.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<dl class="simple"> <dt>
<code>X{array-like, sparse matrix} of shape (n_samples, n_features)</code> </dt>
<dd>
<p>Training vectors, where n_samples is the number of samples and n_features is the number of features.</p> </dd> </dl> </dd> <dt class="field-even">Returns</dt> <dd class="field-even">
<dl class="simple"> <dt>
<code>decisionsndarray of shape (n_samples,), (n_samples, n_classes), or (n_samples, n_classes * (n_classes-1) / 2)</code> </dt>
<dd>
<p>The decision function computed the final estimator.</p> </dd> </dl> </dd> </dl> </dd>
</dl> <dl class="py method"> <dt id="sklearn.ensemble.StackingClassifier.fit">
<code>fit(X, y, sample_weight=None)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/95119c13a/sklearn/ensemble/_stacking.py#L415"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Fit the estimators.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<dl class="simple"> <dt>
<code>X{array-like, sparse matrix} of shape (n_samples, n_features)</code> </dt>
<dd>
<p>Training vectors, where <code>n_samples</code> is the number of samples and <code>n_features</code> is the number of features.</p> </dd> <dt>
<code>yarray-like of shape (n_samples,)</code> </dt>
<dd>
<p>Target values.</p> </dd> <dt>
<code>sample_weightarray-like of shape (n_samples,), default=None</code> </dt>
<dd>
<p>Sample weights. If None, then samples are equally weighted. Note that this is supported only if all underlying estimators support sample weights.</p> </dd> </dl> </dd> <dt class="field-even">Returns</dt> <dd class="field-even">
<dl class="simple"> <dt>
<code>selfobject</code> </dt>
 </dl> </dd> </dl> </dd>
</dl> <dl class="py method"> <dt id="sklearn.ensemble.StackingClassifier.fit_transform">
<code>fit_transform(X, y=None, **fit_params)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/95119c13a/sklearn/base.py#L671"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Fit to data, then transform it.</p> <p>Fits transformer to <code>X</code> and <code>y</code> with optional parameters <code>fit_params</code> and returns a transformed version of <code>X</code>.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<dl class="simple"> <dt>
<code>Xarray-like of shape (n_samples, n_features)</code> </dt>
<dd>
<p>Input samples.</p> </dd> <dt>
<code>yarray-like of shape (n_samples,) or (n_samples, n_outputs), default=None</code> </dt>
<dd>
<p>Target values (None for unsupervised transformations).</p> </dd> <dt>
<code>**fit_paramsdict</code> </dt>
<dd>
<p>Additional fit parameters.</p> </dd> </dl> </dd> <dt class="field-even">Returns</dt> <dd class="field-even">
<dl class="simple"> <dt>
<code>X_newndarray array of shape (n_samples, n_features_new)</code> </dt>
<dd>
<p>Transformed array.</p> </dd> </dl> </dd> </dl> </dd>
</dl> <dl class="py method"> <dt id="sklearn.ensemble.StackingClassifier.get_params">
<code>get_params(deep=True)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/95119c13a/sklearn/ensemble/_base.py#L269"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Get the parameters of an estimator from the ensemble.</p> <p>Returns the parameters given in the constructor as well as the estimators contained within the <code>estimators</code> parameter.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<dl class="simple"> <dt>
<code>deepbool, default=True</code> </dt>
<dd>
<p>Setting it to True gets the various estimators and the parameters of the estimators as well.</p> </dd> </dl> </dd> </dl> </dd>
</dl> <dl class="py method"> <dt id="sklearn.ensemble.StackingClassifier.n_features_in_">
<code>property n_features_in_</code> </dt> <dd>
<p>Number of features seen during <a class="reference internal" href="https://scikit-learn.org/0.24/glossary.html#term-fit"><span class="xref std std-term">fit</span></a>.</p> </dd>
</dl> <dl class="py method"> <dt id="sklearn.ensemble.StackingClassifier.predict">
<code>predict(X, **predict_params)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/95119c13a/sklearn/ensemble/_stacking.py#L441"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Predict target for X.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<dl class="simple"> <dt>
<code>X{array-like, sparse matrix} of shape (n_samples, n_features)</code> </dt>
<dd>
<p>Training vectors, where n_samples is the number of samples and n_features is the number of features.</p> </dd> <dt>
<code>**predict_paramsdict of str -&gt; obj</code> </dt>
<dd>
<p>Parameters to the <code>predict</code> called by the <code>final_estimator</code>. Note that this may be used to return uncertainties from some estimators with <code>return_std</code> or <code>return_cov</code>. Be aware that it will only accounts for uncertainty in the final estimator.</p> </dd> </dl> </dd> <dt class="field-even">Returns</dt> <dd class="field-even">
<dl class="simple"> <dt>
<code>y_predndarray of shape (n_samples,) or (n_samples, n_output)</code> </dt>
<dd>
<p>Predicted targets.</p> </dd> </dl> </dd> </dl> </dd>
</dl> <dl class="py method"> <dt id="sklearn.ensemble.StackingClassifier.predict_proba">
<code>predict_proba(X)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/95119c13a/sklearn/ensemble/_stacking.py#L465"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Predict class probabilities for X using <code>final_estimator_.predict_proba</code>.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<dl class="simple"> <dt>
<code>X{array-like, sparse matrix} of shape (n_samples, n_features)</code> </dt>
<dd>
<p>Training vectors, where n_samples is the number of samples and n_features is the number of features.</p> </dd> </dl> </dd> <dt class="field-even">Returns</dt> <dd class="field-even">
<dl class="simple"> <dt>
<code>probabilitiesndarray of shape (n_samples, n_classes) or list of ndarray of shape (n_output,)</code> </dt>
<dd>
<p>The class probabilities of the input samples.</p> </dd> </dl> </dd> </dl> </dd>
</dl> <dl class="py method"> <dt id="sklearn.ensemble.StackingClassifier.score">
<code>score(X, y, sample_weight=None)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/95119c13a/sklearn/base.py#L475"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Return the mean accuracy on the given test data and labels.</p> <p>In multi-label classification, this is the subset accuracy which is a harsh metric since you require for each sample that each label set be correctly predicted.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<dl class="simple"> <dt>
<code>Xarray-like of shape (n_samples, n_features)</code> </dt>
<dd>
<p>Test samples.</p> </dd> <dt>
<code>yarray-like of shape (n_samples,) or (n_samples, n_outputs)</code> </dt>
<dd>
<p>True labels for <code>X</code>.</p> </dd> <dt>
<code>sample_weightarray-like of shape (n_samples,), default=None</code> </dt>
<dd>
<p>Sample weights.</p> </dd> </dl> </dd> <dt class="field-even">Returns</dt> <dd class="field-even">
<dl class="simple"> <dt>
<code>scorefloat</code> </dt>
<dd>
<p>Mean accuracy of <code>self.predict(X)</code> wrt. <code>y</code>.</p> </dd> </dl> </dd> </dl> </dd>
</dl> <dl class="py method"> <dt id="sklearn.ensemble.StackingClassifier.set_params">
<code>set_params(**params)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/95119c13a/sklearn/ensemble/_base.py#L249"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Set the parameters of an estimator from the ensemble.</p> <p>Valid parameter keys can be listed with <code>get_params()</code>. Note that you can directly set the parameters of the estimators contained in <code>estimators</code>.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<dl class="simple"> <dt>
<code>**paramskeyword arguments</code> </dt>
<dd>
<p>Specific parameters using e.g. <code>set_params(parameter_name=new_value)</code>. In addition, to setting the parameters of the estimator, the individual estimator of the estimators can also be set, or can be removed by setting them to ‘drop’.</p> </dd> </dl> </dd> </dl> </dd>
</dl> <dl class="py method"> <dt id="sklearn.ensemble.StackingClassifier.transform">
<code>transform(X)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/95119c13a/sklearn/ensemble/_stacking.py#L505"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Return class labels or probabilities for X for each estimator.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<dl class="simple"> <dt>
<code>X{array-like, sparse matrix} of shape (n_samples, n_features)</code> </dt>
<dd>
<p>Training vectors, where <code>n_samples</code> is the number of samples and <code>n_features</code> is the number of features.</p> </dd> </dl> </dd> <dt class="field-even">Returns</dt> <dd class="field-even">
<dl class="simple"> <dt>
<code>y_predsndarray of shape (n_samples, n_estimators) or (n_samples, n_classes * n_estimators)</code> </dt>
<dd>
<p>Prediction outputs for each estimator.</p> </dd> </dl> </dd> </dl> </dd>
</dl> </dd>
</dl>  <h2 id="examples-using-sklearn-ensemble-stackingclassifier">Examples using <code>sklearn.ensemble.StackingClassifier</code>
</h2> <div class="sphx-glr-thumbcontainer" tooltip="We are pleased to announce the release of scikit-learn 0.22, which comes with many bug fixes an...">
<div class="figure align-default" id="id2"> <img alt="Release Highlights for scikit-learn 0.22" src="data:image/png;base64,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"> <p class="caption"><span class="caption-text"><a class="reference internal" href="../../auto_examples/release_highlights/plot_release_highlights_0_22_0#sphx-glr-auto-examples-release-highlights-plot-release-highlights-0-22-0-py"><span class="std std-ref">Release Highlights for scikit-learn 0.22</span></a></span></p> </div> </div>
<div class="_attribution">
  <p class="_attribution-p">
    &copy; 2007&ndash;2020 The scikit-learn developers<br>Licensed under the 3-clause BSD License.<br>
    <a href="https://scikit-learn.org/0.24/modules/generated/sklearn.ensemble.StackingClassifier.html" class="_attribution-link">https://scikit-learn.org/0.24/modules/generated/sklearn.ensemble.StackingClassifier.html</a>
  </p>
</div>
