<h1>sklearn.preprocessing.maxabs_scale</h1> <dl class="py function"> <dt id="sklearn.preprocessing.maxabs_scale">
<code>sklearn.preprocessing.maxabs_scale(X, *, axis=0, copy=True)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/95119c13a/sklearn/preprocessing/_data.py#L1143"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Scale each feature to the [-1, 1] range without breaking the sparsity.</p> <p>This estimator scales each feature individually such that the maximal absolute value of each feature in the training set will be 1.0.</p> <p>This scaler can also be applied to sparse CSR or CSC matrices.</p> <dl class="field-list"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<dl class="simple"> <dt>
<code>X{array-like, sparse matrix} of shape (n_samples, n_features)</code> </dt>
<dd>
<p>The data.</p> </dd> <dt>
<code>axisint, default=0</code> </dt>
<dd>
<p>axis used to scale along. If 0, independently scale each feature, otherwise (if 1) scale each sample.</p> </dd> <dt>
<code>copybool, default=True</code> </dt>
<dd>
<p>Set to False to perform inplace scaling and avoid a copy (if the input is already a numpy array).</p> </dd> </dl> </dd> <dt class="field-even">Returns</dt> <dd class="field-even">
<dl class="simple"> <dt>
<code>X_tr{ndarray, sparse matrix} of shape (n_samples, n_features)</code> </dt>
<dd>
<p>The transformed data.</p> </dd> </dl> <div class="admonition warning"> <p class="admonition-title">Warning</p> <p>Risk of data leak Do not use <a class="reference internal" href="#sklearn.preprocessing.maxabs_scale" title="sklearn.preprocessing.maxabs_scale"><code>maxabs_scale</code></a> unless you know what you are doing. A common mistake is to apply it to the entire data <em>before</em> splitting into training and test sets. This will bias the model evaluation because information would have leaked from the test set to the training set. In general, we recommend using <a class="reference internal" href="sklearn.preprocessing.maxabsscaler#sklearn.preprocessing.MaxAbsScaler" title="sklearn.preprocessing.MaxAbsScaler"><code>MaxAbsScaler</code></a> within a <a class="reference internal" href="../compose#pipeline"><span class="std std-ref">Pipeline</span></a> in order to prevent most risks of data leaking: <code>pipe = make_pipeline(MaxAbsScaler(), LogisticRegression())</code>.</p> </div> </dd> </dl> <div class="admonition seealso"> <p class="admonition-title">See also</p> <dl class="simple"> <dt>
 <a class="reference internal" href="sklearn.preprocessing.maxabsscaler#sklearn.preprocessing.MaxAbsScaler" title="sklearn.preprocessing.MaxAbsScaler"><code>MaxAbsScaler</code></a>
</dt>
<dd>
<p>Performs scaling to the [-1, 1] range using the Transformer API (e.g. as part of a preprocessing <a class="reference internal" href="sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline" title="sklearn.pipeline.Pipeline"><code>Pipeline</code></a>).</p> </dd> </dl> </div> <h4 class="rubric">Notes</h4> <p>NaNs are treated as missing values: disregarded to compute the statistics, and maintained during the data transformation.</p> <p>For a comparison of the different scalers, transformers, and normalizers, see <a class="reference internal" href="../../auto_examples/preprocessing/plot_all_scaling#sphx-glr-auto-examples-preprocessing-plot-all-scaling-py"><span class="std std-ref">examples/preprocessing/plot_all_scaling.py</span></a>.</p> </dd>
</dl> <div class="_attribution">
  <p class="_attribution-p">
    &copy; 2007&ndash;2020 The scikit-learn developers<br>Licensed under the 3-clause BSD License.<br>
    <a href="https://scikit-learn.org/0.24/modules/generated/sklearn.preprocessing.maxabs_scale.html" class="_attribution-link">https://scikit-learn.org/0.24/modules/generated/sklearn.preprocessing.maxabs_scale.html</a>
  </p>
</div>
