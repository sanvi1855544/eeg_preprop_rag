<h1>sklearn.multiclass.OneVsOneClassifier</h1> <dl class="py class"> <dt id="sklearn.multiclass.OneVsOneClassifier">
<code>class sklearn.multiclass.OneVsOneClassifier(estimator, *, n_jobs=None)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/95119c13a/sklearn/multiclass.py#L548"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>One-vs-one multiclass strategy</p> <p>This strategy consists in fitting one classifier per class pair. At prediction time, the class which received the most votes is selected. Since it requires to fit <code>n_classes * (n_classes - 1) / 2</code> classifiers, this method is usually slower than one-vs-the-rest, due to its O(n_classes^2) complexity. However, this method may be advantageous for algorithms such as kernel algorithms which don’t scale well with <code>n_samples</code>. This is because each individual learning problem only involves a small subset of the data whereas, with one-vs-the-rest, the complete dataset is used <code>n_classes</code> times.</p> <p>Read more in the <a class="reference internal" href="../multiclass#ovo-classification"><span class="std std-ref">User Guide</span></a>.</p> <dl class="field-list"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<dl> <dt>
<code>estimatorestimator object</code> </dt>
<dd>
<p>An estimator object implementing <a class="reference internal" href="https://scikit-learn.org/0.24/glossary.html#term-fit"><span class="xref std std-term">fit</span></a> and one of <a class="reference internal" href="https://scikit-learn.org/0.24/glossary.html#term-decision_function"><span class="xref std std-term">decision_function</span></a> or <a class="reference internal" href="https://scikit-learn.org/0.24/glossary.html#term-predict_proba"><span class="xref std std-term">predict_proba</span></a>.</p> </dd> <dt>
<code>n_jobsint, default=None</code> </dt>
<dd>
<p>The number of jobs to use for the computation: the <code>n_classes * (
n_classes - 1) / 2</code> OVO problems are computed in parallel.</p> <p><code>None</code> means 1 unless in a <a class="reference external" href="https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend" title="(in joblib v1.1.0.dev0)"><code>joblib.parallel_backend</code></a> context. <code>-1</code> means using all processors. See <a class="reference internal" href="https://scikit-learn.org/0.24/glossary.html#term-n_jobs"><span class="xref std std-term">Glossary</span></a> for more details.</p> </dd> </dl> </dd> <dt class="field-even">Attributes</dt> <dd class="field-even">
<dl> <dt>
<code>estimators_list of n_classes * (n_classes - 1) / 2 estimators</code> </dt>
<dd>
<p>Estimators used for predictions.</p> </dd> <dt>
<code>classes_numpy array of shape [n_classes]</code> </dt>
<dd>
<p>Array containing labels.</p> </dd> <dt>
<code>n_classes_int</code> </dt>
<dd>
<p>Number of classes</p> </dd> <dt>
<code>pairwise_indices_list, length = len(estimators_), or None</code> </dt>
<dd>
<p>Indices of samples used when training the estimators. <code>None</code> when <code>estimator</code>’s <code>pairwise</code> tag is False.</p> <div class="deprecated"> <p><span class="versionmodified deprecated">Deprecated since version 0.24: </span>The _pairwise attribute is deprecated in 0.24. From 1.1 (renaming of 0.25) and onward, <code>pairwise_indices_</code> will use the pairwise estimator tag instead.</p> </div> </dd> </dl> </dd> </dl> <h4 class="rubric">Examples</h4> <pre data-language="python">&gt;&gt;&gt; from sklearn.datasets import load_iris
&gt;&gt;&gt; from sklearn.model_selection import train_test_split
&gt;&gt;&gt; from sklearn.multiclass import OneVsOneClassifier
&gt;&gt;&gt; from sklearn.svm import LinearSVC
&gt;&gt;&gt; X, y = load_iris(return_X_y=True)
&gt;&gt;&gt; X_train, X_test, y_train, y_test = train_test_split(
...     X, y, test_size=0.33, shuffle=True, random_state=0)
&gt;&gt;&gt; clf = OneVsOneClassifier(
...     LinearSVC(random_state=0)).fit(X_train, y_train)
&gt;&gt;&gt; clf.predict(X_test[:10])
array([2, 1, 0, 2, 0, 2, 0, 1, 1, 1])
</pre> <h4 class="rubric">Methods</h4> <table class="longtable docutils align-default">   <tr>
<td><p><a class="reference internal" href="#sklearn.multiclass.OneVsOneClassifier.decision_function" title="sklearn.multiclass.OneVsOneClassifier.decision_function"><code>decision_function</code></a>(X)</p></td> <td><p>Decision function for the OneVsOneClassifier.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="#sklearn.multiclass.OneVsOneClassifier.fit" title="sklearn.multiclass.OneVsOneClassifier.fit"><code>fit</code></a>(X, y)</p></td> <td><p>Fit underlying estimators.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="#sklearn.multiclass.OneVsOneClassifier.get_params" title="sklearn.multiclass.OneVsOneClassifier.get_params"><code>get_params</code></a>([deep])</p></td> <td><p>Get parameters for this estimator.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="#sklearn.multiclass.OneVsOneClassifier.partial_fit" title="sklearn.multiclass.OneVsOneClassifier.partial_fit"><code>partial_fit</code></a>(X, y[, classes])</p></td> <td><p>Partially fit underlying estimators</p></td> </tr> <tr>
<td><p><a class="reference internal" href="#sklearn.multiclass.OneVsOneClassifier.predict" title="sklearn.multiclass.OneVsOneClassifier.predict"><code>predict</code></a>(X)</p></td> <td><p>Estimate the best class label for each sample in X.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="#sklearn.multiclass.OneVsOneClassifier.score" title="sklearn.multiclass.OneVsOneClassifier.score"><code>score</code></a>(X, y[, sample_weight])</p></td> <td><p>Return the mean accuracy on the given test data and labels.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="#sklearn.multiclass.OneVsOneClassifier.set_params" title="sklearn.multiclass.OneVsOneClassifier.set_params"><code>set_params</code></a>(**params)</p></td> <td><p>Set the parameters of this estimator.</p></td> </tr>  </table> <dl class="py method"> <dt id="sklearn.multiclass.OneVsOneClassifier.decision_function">
<code>decision_function(X)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/95119c13a/sklearn/multiclass.py#L729"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Decision function for the OneVsOneClassifier.</p> <p>The decision values for the samples are computed by adding the normalized sum of pair-wise classification confidence levels to the votes in order to disambiguate between the decision values when the votes for all the classes are equal leading to a tie.</p> <dl class="field-list"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<dl class="simple"> <dt>
<code>Xarray-like of shape (n_samples, n_features)</code> </dt>
 </dl> </dd> <dt class="field-even">Returns</dt> <dd class="field-even">
<dl> <dt>
<code>Yarray-like of shape (n_samples, n_classes) or (n_samples,) for binary classification.</code> </dt>
<dd>
<div class="versionchanged"> <p><span class="versionmodified changed">Changed in version 0.19: </span>output shape changed to <code>(n_samples,)</code> to conform to scikit-learn conventions for binary classification.</p> </div> </dd> </dl> </dd> </dl> </dd>
</dl> <dl class="py method"> <dt id="sklearn.multiclass.OneVsOneClassifier.fit">
<code>fit(X, y)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/95119c13a/sklearn/multiclass.py#L617"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Fit underlying estimators.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<dl class="simple"> <dt>
<code>X(sparse) array-like of shape (n_samples, n_features)</code> </dt>
<dd>
<p>Data.</p> </dd> <dt>
<code>yarray-like of shape (n_samples,)</code> </dt>
<dd>
<p>Multi-class targets.</p> </dd> </dl> </dd> <dt class="field-even">Returns</dt> <dd class="field-even">
<dl class="simple"> <dt>self</dt>
 </dl> </dd> </dl> </dd>
</dl> <dl class="py method"> <dt id="sklearn.multiclass.OneVsOneClassifier.get_params">
<code>get_params(deep=True)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/95119c13a/sklearn/base.py#L178"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Get parameters for this estimator.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<dl class="simple"> <dt>
<code>deepbool, default=True</code> </dt>
<dd>
<p>If True, will return the parameters for this estimator and contained subobjects that are estimators.</p> </dd> </dl> </dd> <dt class="field-even">Returns</dt> <dd class="field-even">
<dl class="simple"> <dt>
<code>paramsdict</code> </dt>
<dd>
<p>Parameter names mapped to their values.</p> </dd> </dl> </dd> </dl> </dd>
</dl> <dl class="py method"> <dt id="sklearn.multiclass.OneVsOneClassifier.partial_fit">
<code>partial_fit(X, y, classes=None)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/95119c13a/sklearn/multiclass.py#L654"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Partially fit underlying estimators</p> <p>Should be used when memory is inefficient to train all data. Chunks of data can be passed in several iteration, where the first call should have an array of all target variables.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<dl class="simple"> <dt>
<code>X(sparse) array-like of shape (n_samples, n_features)</code> </dt>
<dd>
<p>Data.</p> </dd> <dt>
<code>yarray-like of shape (n_samples,)</code> </dt>
<dd>
<p>Multi-class targets.</p> </dd> <dt>
<code>classesarray, shape (n_classes, )</code> </dt>
<dd>
<p>Classes across all calls to partial_fit. Can be obtained via <code>np.unique(y_all)</code>, where y_all is the target vector of the entire dataset. This argument is only required in the first call of partial_fit and can be omitted in the subsequent calls.</p> </dd> </dl> </dd> <dt class="field-even">Returns</dt> <dd class="field-even">
<dl class="simple"> <dt>self</dt>
 </dl> </dd> </dl> </dd>
</dl> <dl class="py method"> <dt id="sklearn.multiclass.OneVsOneClassifier.predict">
<code>predict(X)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/95119c13a/sklearn/multiclass.py#L707"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Estimate the best class label for each sample in X.</p> <p>This is implemented as <code>argmax(decision_function(X), axis=1)</code> which will return the label of the class with most votes by estimators predicting the outcome of a decision for each possible class pair.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<dl class="simple"> <dt>
<code>X(sparse) array-like of shape (n_samples, n_features)</code> </dt>
<dd>
<p>Data.</p> </dd> </dl> </dd> <dt class="field-even">Returns</dt> <dd class="field-even">
<dl class="simple"> <dt>
<code>ynumpy array of shape [n_samples]</code> </dt>
<dd>
<p>Predicted multi-class targets.</p> </dd> </dl> </dd> </dl> </dd>
</dl> <dl class="py method"> <dt id="sklearn.multiclass.OneVsOneClassifier.score">
<code>score(X, y, sample_weight=None)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/95119c13a/sklearn/base.py#L475"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Return the mean accuracy on the given test data and labels.</p> <p>In multi-label classification, this is the subset accuracy which is a harsh metric since you require for each sample that each label set be correctly predicted.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<dl class="simple"> <dt>
<code>Xarray-like of shape (n_samples, n_features)</code> </dt>
<dd>
<p>Test samples.</p> </dd> <dt>
<code>yarray-like of shape (n_samples,) or (n_samples, n_outputs)</code> </dt>
<dd>
<p>True labels for <code>X</code>.</p> </dd> <dt>
<code>sample_weightarray-like of shape (n_samples,), default=None</code> </dt>
<dd>
<p>Sample weights.</p> </dd> </dl> </dd> <dt class="field-even">Returns</dt> <dd class="field-even">
<dl class="simple"> <dt>
<code>scorefloat</code> </dt>
<dd>
<p>Mean accuracy of <code>self.predict(X)</code> wrt. <code>y</code>.</p> </dd> </dl> </dd> </dl> </dd>
</dl> <dl class="py method"> <dt id="sklearn.multiclass.OneVsOneClassifier.set_params">
<code>set_params(**params)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/95119c13a/sklearn/base.py#L202"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Set the parameters of this estimator.</p> <p>The method works on simple estimators as well as on nested objects (such as <a class="reference internal" href="sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline" title="sklearn.pipeline.Pipeline"><code>Pipeline</code></a>). The latter have parameters of the form <code>&lt;component&gt;__&lt;parameter&gt;</code> so that it’s possible to update each component of a nested object.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<dl class="simple"> <dt>
<code>**paramsdict</code> </dt>
<dd>
<p>Estimator parameters.</p> </dd> </dl> </dd> <dt class="field-even">Returns</dt> <dd class="field-even">
<dl class="simple"> <dt>
<code>selfestimator instance</code> </dt>
<dd>
<p>Estimator instance.</p> </dd> </dl> </dd> </dl> </dd>
</dl> </dd>
</dl> <div class="_attribution">
  <p class="_attribution-p">
    &copy; 2007&ndash;2020 The scikit-learn developers<br>Licensed under the 3-clause BSD License.<br>
    <a href="https://scikit-learn.org/0.24/modules/generated/sklearn.multiclass.OneVsOneClassifier.html" class="_attribution-link">https://scikit-learn.org/0.24/modules/generated/sklearn.multiclass.OneVsOneClassifier.html</a>
  </p>
</div>
