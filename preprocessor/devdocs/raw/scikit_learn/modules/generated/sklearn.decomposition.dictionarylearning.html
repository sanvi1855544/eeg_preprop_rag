<h1>sklearn.decomposition.DictionaryLearning</h1> <dl class="py class"> <dt id="sklearn.decomposition.DictionaryLearning">
<code>class sklearn.decomposition.DictionaryLearning(n_components=None, *, alpha=1, max_iter=1000, tol=1e-08, fit_algorithm='lars', transform_algorithm='omp', transform_n_nonzero_coefs=None, transform_alpha=None, n_jobs=None, code_init=None, dict_init=None, verbose=False, split_sign=False, random_state=None, positive_code=False, positive_dict=False, transform_max_iter=1000)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/95119c13a/sklearn/decomposition/_dict_learning.py#L1129"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Dictionary learning</p> <p>Finds a dictionary (a set of atoms) that can best be used to represent data using a sparse code.</p> <p>Solves the optimization problem:</p> <pre data-language="python">(U^*,V^*) = argmin 0.5 || X - U V ||_2^2 + alpha * || U ||_1
            (U,V)
            with || V_k ||_2 = 1 for all  0 &lt;= k &lt; n_components
</pre> <p>Read more in the <a class="reference internal" href="../decomposition#dictionarylearning"><span class="std std-ref">User Guide</span></a>.</p> <dl class="field-list"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<dl> <dt>
<code>n_componentsint, default=n_features</code> </dt>
<dd>
<p>Number of dictionary elements to extract.</p> </dd> <dt>
<code>alphafloat, default=1.0</code> </dt>
<dd>
<p>Sparsity controlling parameter.</p> </dd> <dt>
<code>max_iterint, default=1000</code> </dt>
<dd>
<p>Maximum number of iterations to perform.</p> </dd> <dt>
<code>tolfloat, default=1e-8</code> </dt>
<dd>
<p>Tolerance for numerical error.</p> </dd> <dt>
<code>fit_algorithm{‘lars’, ‘cd’}, default=’lars’</code> </dt>
<dd>
<ul class="simple"> <li>
<code>'lars'</code>: uses the least angle regression method to solve the lasso problem (<a class="reference internal" href="sklearn.linear_model.lars_path#sklearn.linear_model.lars_path" title="sklearn.linear_model.lars_path"><code>lars_path</code></a>);</li> <li>
<code>'cd'</code>: uses the coordinate descent method to compute the Lasso solution (<a class="reference internal" href="sklearn.linear_model.lasso#sklearn.linear_model.Lasso" title="sklearn.linear_model.Lasso"><code>Lasso</code></a>). Lars will be faster if the estimated components are sparse.</li> </ul> <div class="versionadded"> <p><span class="versionmodified added">New in version 0.17: </span><em>cd</em> coordinate descent method to improve speed.</p> </div> </dd> <dt>
<code>transform_algorithm{‘lasso_lars’, ‘lasso_cd’, ‘lars’, ‘omp’, ‘threshold’}, default=’omp’</code> </dt>
<dd>
<p>Algorithm used to transform the data:</p> <ul class="simple"> <li>
<code>'lars'</code>: uses the least angle regression method (<a class="reference internal" href="sklearn.linear_model.lars_path#sklearn.linear_model.lars_path" title="sklearn.linear_model.lars_path"><code>lars_path</code></a>);</li> <li>
<code>'lasso_lars'</code>: uses Lars to compute the Lasso solution.</li> <li>
<code>'lasso_cd'</code>: uses the coordinate descent method to compute the Lasso solution (<a class="reference internal" href="sklearn.linear_model.lasso#sklearn.linear_model.Lasso" title="sklearn.linear_model.Lasso"><code>Lasso</code></a>). <code>'lasso_lars'</code> will be faster if the estimated components are sparse.</li> <li>
<code>'omp'</code>: uses orthogonal matching pursuit to estimate the sparse solution.</li> <li>
<code>'threshold'</code>: squashes to zero all coefficients less than alpha from the projection <code>dictionary * X'</code>.</li> </ul> <div class="versionadded"> <p><span class="versionmodified added">New in version 0.17: </span><em>lasso_cd</em> coordinate descent method to improve speed.</p> </div> </dd> <dt>
<code>transform_n_nonzero_coefsint, default=None</code> </dt>
<dd>
<p>Number of nonzero coefficients to target in each column of the solution. This is only used by <code>algorithm='lars'</code> and <code>algorithm='omp'</code> and is overridden by <code>alpha</code> in the <code>omp</code> case. If <code>None</code>, then <code>transform_n_nonzero_coefs=int(n_features / 10)</code>.</p> </dd> <dt>
<code>transform_alphafloat, default=None</code> </dt>
<dd>
<p>If <code>algorithm='lasso_lars'</code> or <code>algorithm='lasso_cd'</code>, <code>alpha</code> is the penalty applied to the L1 norm. If <code>algorithm='threshold'</code>, <code>alpha</code> is the absolute value of the threshold below which coefficients will be squashed to zero. If <code>algorithm='omp'</code>, <code>alpha</code> is the tolerance parameter: the value of the reconstruction error targeted. In this case, it overrides <code>n_nonzero_coefs</code>. If <code>None</code>, default to 1.0</p> </dd> <dt>
<code>n_jobsint or None, default=None</code> </dt>
<dd>
<p>Number of parallel jobs to run. <code>None</code> means 1 unless in a <a class="reference external" href="https://joblib.readthedocs.io/en/latest/parallel.html#joblib.parallel_backend" title="(in joblib v1.1.0.dev0)"><code>joblib.parallel_backend</code></a> context. <code>-1</code> means using all processors. See <a class="reference internal" href="https://scikit-learn.org/0.24/glossary.html#term-n_jobs"><span class="xref std std-term">Glossary</span></a> for more details.</p> </dd> <dt>
<code>code_initndarray of shape (n_samples, n_components), default=None</code> </dt>
<dd>
<p>Initial value for the code, for warm restart.</p> </dd> <dt>
<code>dict_initndarray of shape (n_components, n_features), default=None</code> </dt>
<dd>
<p>Initial values for the dictionary, for warm restart.</p> </dd> <dt>
<code>verbosebool, default=False</code> </dt>
<dd>
<p>To control the verbosity of the procedure.</p> </dd> <dt>
<code>split_signbool, default=False</code> </dt>
<dd>
<p>Whether to split the sparse feature vector into the concatenation of its negative part and its positive part. This can improve the performance of downstream classifiers.</p> </dd> <dt>
<code>random_stateint, RandomState instance or None, default=None</code> </dt>
<dd>
<p>Used for initializing the dictionary when <code>dict_init</code> is not specified, randomly shuffling the data when <code>shuffle</code> is set to <code>True</code>, and updating the dictionary. Pass an int for reproducible results across multiple function calls. See <a class="reference internal" href="https://scikit-learn.org/0.24/glossary.html#term-random_state"><span class="xref std std-term">Glossary</span></a>.</p> </dd> <dt>
<code>positive_codebool, default=False</code> </dt>
<dd>
<p>Whether to enforce positivity when finding the code.</p> <div class="versionadded"> <p><span class="versionmodified added">New in version 0.20.</span></p> </div> </dd> <dt>
<code>positive_dictbool, default=False</code> </dt>
<dd>
<p>Whether to enforce positivity when finding the dictionary</p> <div class="versionadded"> <p><span class="versionmodified added">New in version 0.20.</span></p> </div> </dd> <dt>
<code>transform_max_iterint, default=1000</code> </dt>
<dd>
<p>Maximum number of iterations to perform if <code>algorithm='lasso_cd'</code> or <code>'lasso_lars'</code>.</p> <div class="versionadded"> <p><span class="versionmodified added">New in version 0.22.</span></p> </div> </dd> </dl> </dd> <dt class="field-even">Attributes</dt> <dd class="field-even">
<dl class="simple"> <dt>
<code>components_ndarray of shape (n_components, n_features)</code> </dt>
<dd>
<p>dictionary atoms extracted from the data</p> </dd> <dt>
<code>error_array</code> </dt>
<dd>
<p>vector of errors at each iteration</p> </dd> <dt>
<code>n_iter_int</code> </dt>
<dd>
<p>Number of iterations run.</p> </dd> </dl> </dd> </dl> <div class="admonition seealso"> <p class="admonition-title">See also</p> <dl class="simple"> <dt>
 <a class="reference internal" href="sklearn.decomposition.sparsecoder#sklearn.decomposition.SparseCoder" title="sklearn.decomposition.SparseCoder"><code>SparseCoder</code></a>
</dt>
 <dt>
 <a class="reference internal" href="sklearn.decomposition.minibatchdictionarylearning#sklearn.decomposition.MiniBatchDictionaryLearning" title="sklearn.decomposition.MiniBatchDictionaryLearning"><code>MiniBatchDictionaryLearning</code></a>
</dt>
 <dt>
 <a class="reference internal" href="sklearn.decomposition.sparsepca#sklearn.decomposition.SparsePCA" title="sklearn.decomposition.SparsePCA"><code>SparsePCA</code></a>
</dt>
 <dt>
 <a class="reference internal" href="sklearn.decomposition.minibatchsparsepca#sklearn.decomposition.MiniBatchSparsePCA" title="sklearn.decomposition.MiniBatchSparsePCA"><code>MiniBatchSparsePCA</code></a>
</dt>
 </dl> </div> <h4 class="rubric">Notes</h4> <p><strong>References:</strong></p> <p>J. Mairal, F. Bach, J. Ponce, G. Sapiro, 2009: Online dictionary learning for sparse coding (<a class="reference external" href="https://www.di.ens.fr/sierra/pdfs/icml09.pdf">https://www.di.ens.fr/sierra/pdfs/icml09.pdf</a>)</p> <h4 class="rubric">Examples</h4> <pre data-language="python">&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; from sklearn.datasets import make_sparse_coded_signal
&gt;&gt;&gt; from sklearn.decomposition import DictionaryLearning
&gt;&gt;&gt; X, dictionary, code = make_sparse_coded_signal(
...     n_samples=100, n_components=15, n_features=20, n_nonzero_coefs=10,
...     random_state=42,
... )
&gt;&gt;&gt; dict_learner = DictionaryLearning(
...     n_components=15, transform_algorithm='lasso_lars', random_state=42,
... )
&gt;&gt;&gt; X_transformed = dict_learner.fit_transform(X)
</pre> <p>We can check the level of sparsity of <code>X_transformed</code>:</p> <pre data-language="python">&gt;&gt;&gt; np.mean(X_transformed == 0)
0.88...
</pre> <p>We can compare the average squared euclidean norm of the reconstruction error of the sparse coded signal relative to the squared euclidean norm of the original signal:</p> <pre data-language="python">&gt;&gt;&gt; X_hat = X_transformed @ dict_learner.components_
&gt;&gt;&gt; np.mean(np.sum((X_hat - X) ** 2, axis=1) / np.sum(X ** 2, axis=1))
0.07...
</pre> <h4 class="rubric">Methods</h4> <table class="longtable docutils align-default">   <tr>
<td><p><a class="reference internal" href="#sklearn.decomposition.DictionaryLearning.fit" title="sklearn.decomposition.DictionaryLearning.fit"><code>fit</code></a>(X[, y])</p></td> <td><p>Fit the model from data in X.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="#sklearn.decomposition.DictionaryLearning.fit_transform" title="sklearn.decomposition.DictionaryLearning.fit_transform"><code>fit_transform</code></a>(X[, y])</p></td> <td><p>Fit to data, then transform it.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="#sklearn.decomposition.DictionaryLearning.get_params" title="sklearn.decomposition.DictionaryLearning.get_params"><code>get_params</code></a>([deep])</p></td> <td><p>Get parameters for this estimator.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="#sklearn.decomposition.DictionaryLearning.set_params" title="sklearn.decomposition.DictionaryLearning.set_params"><code>set_params</code></a>(**params)</p></td> <td><p>Set the parameters of this estimator.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="#sklearn.decomposition.DictionaryLearning.transform" title="sklearn.decomposition.DictionaryLearning.transform"><code>transform</code></a>(X)</p></td> <td><p>Encode the data as a sparse combination of the dictionary atoms.</p></td> </tr>  </table> <dl class="py method"> <dt id="sklearn.decomposition.DictionaryLearning.fit">
<code>fit(X, y=None)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/95119c13a/sklearn/decomposition/_dict_learning.py#L1320"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Fit the model from data in X.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<dl class="simple"> <dt>
<code>Xarray-like of shape (n_samples, n_features)</code> </dt>
<dd>
<p>Training vector, where <code>n_samples</code> in the number of samples and <code>n_features</code> is the number of features.</p> </dd> <dt>
<code>yIgnored</code> </dt>
 </dl> </dd> <dt class="field-even">Returns</dt> <dd class="field-even">
<dl class="simple"> <dt>
<code>selfobject</code> </dt>
<dd>
<p>Returns the object itself.</p> </dd> </dl> </dd> </dl> </dd>
</dl> <dl class="py method"> <dt id="sklearn.decomposition.DictionaryLearning.fit_transform">
<code>fit_transform(X, y=None, **fit_params)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/95119c13a/sklearn/base.py#L671"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Fit to data, then transform it.</p> <p>Fits transformer to <code>X</code> and <code>y</code> with optional parameters <code>fit_params</code> and returns a transformed version of <code>X</code>.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<dl class="simple"> <dt>
<code>Xarray-like of shape (n_samples, n_features)</code> </dt>
<dd>
<p>Input samples.</p> </dd> <dt>
<code>yarray-like of shape (n_samples,) or (n_samples, n_outputs), default=None</code> </dt>
<dd>
<p>Target values (None for unsupervised transformations).</p> </dd> <dt>
<code>**fit_paramsdict</code> </dt>
<dd>
<p>Additional fit parameters.</p> </dd> </dl> </dd> <dt class="field-even">Returns</dt> <dd class="field-even">
<dl class="simple"> <dt>
<code>X_newndarray array of shape (n_samples, n_features_new)</code> </dt>
<dd>
<p>Transformed array.</p> </dd> </dl> </dd> </dl> </dd>
</dl> <dl class="py method"> <dt id="sklearn.decomposition.DictionaryLearning.get_params">
<code>get_params(deep=True)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/95119c13a/sklearn/base.py#L178"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Get parameters for this estimator.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<dl class="simple"> <dt>
<code>deepbool, default=True</code> </dt>
<dd>
<p>If True, will return the parameters for this estimator and contained subobjects that are estimators.</p> </dd> </dl> </dd> <dt class="field-even">Returns</dt> <dd class="field-even">
<dl class="simple"> <dt>
<code>paramsdict</code> </dt>
<dd>
<p>Parameter names mapped to their values.</p> </dd> </dl> </dd> </dl> </dd>
</dl> <dl class="py method"> <dt id="sklearn.decomposition.DictionaryLearning.set_params">
<code>set_params(**params)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/95119c13a/sklearn/base.py#L202"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Set the parameters of this estimator.</p> <p>The method works on simple estimators as well as on nested objects (such as <a class="reference internal" href="sklearn.pipeline.pipeline#sklearn.pipeline.Pipeline" title="sklearn.pipeline.Pipeline"><code>Pipeline</code></a>). The latter have parameters of the form <code>&lt;component&gt;__&lt;parameter&gt;</code> so that it’s possible to update each component of a nested object.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<dl class="simple"> <dt>
<code>**paramsdict</code> </dt>
<dd>
<p>Estimator parameters.</p> </dd> </dl> </dd> <dt class="field-even">Returns</dt> <dd class="field-even">
<dl class="simple"> <dt>
<code>selfestimator instance</code> </dt>
<dd>
<p>Estimator instance.</p> </dd> </dl> </dd> </dl> </dd>
</dl> <dl class="py method"> <dt id="sklearn.decomposition.DictionaryLearning.transform">
<code>transform(X)</code> <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/95119c13a/sklearn/decomposition/_dict_learning.py#L928"><span class="viewcode-link">[source]</span></a>
</dt> <dd>
<p>Encode the data as a sparse combination of the dictionary atoms.</p> <p>Coding method is determined by the object parameter <code>transform_algorithm</code>.</p> <dl class="field-list simple"> <dt class="field-odd">Parameters</dt> <dd class="field-odd">
<dl class="simple"> <dt>
<code>Xndarray of shape (n_samples, n_features)</code> </dt>
<dd>
<p>Test data to be transformed, must have the same number of features as the data used to train the model.</p> </dd> </dl> </dd> <dt class="field-even">Returns</dt> <dd class="field-even">
<dl class="simple"> <dt>
<code>X_newndarray of shape (n_samples, n_components)</code> </dt>
<dd>
<p>Transformed data.</p> </dd> </dl> </dd> </dl> </dd>
</dl> </dd>
</dl> <div class="_attribution">
  <p class="_attribution-p">
    &copy; 2007&ndash;2020 The scikit-learn developers<br>Licensed under the 3-clause BSD License.<br>
    <a href="https://scikit-learn.org/0.24/modules/generated/sklearn.decomposition.DictionaryLearning.html" class="_attribution-link">https://scikit-learn.org/0.24/modules/generated/sklearn.decomposition.DictionaryLearning.html</a>
  </p>
</div>
