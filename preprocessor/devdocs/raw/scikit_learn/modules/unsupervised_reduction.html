<h1 id="data-reduction">6.5. Unsupervised dimensionality reduction</h1> <p>If your number of features is high, it may be useful to reduce it with an unsupervised step prior to supervised steps. Many of the <a class="reference internal" href="https://scikit-learn.org/0.24/unsupervised_learning.html#unsupervised-learning"><span class="std std-ref">Unsupervised learning</span></a> methods implement a <code>transform</code> method that can be used to reduce the dimensionality. Below we discuss two specific example of this pattern that are heavily used.</p> <div class="topic"> <p class="topic-title"><strong>Pipelining</strong></p> <p>The unsupervised data reduction and the supervised estimator can be chained in one step. See <a class="reference internal" href="compose#pipeline"><span class="std std-ref">Pipeline: chaining estimators</span></a>.</p> </div>  <h2 id="pca-principal-component-analysis">
<span class="section-number">6.5.1. </span>PCA: principal component analysis</h2> <p><a class="reference internal" href="generated/sklearn.decomposition.pca#sklearn.decomposition.PCA" title="sklearn.decomposition.PCA"><code>decomposition.PCA</code></a> looks for a combination of features that capture well the variance of the original features. See <a class="reference internal" href="decomposition#decompositions"><span class="std std-ref">Decomposing signals in components (matrix factorization problems)</span></a>.</p> <div class="topic"> <p class="topic-title"><strong>Examples</strong></p> <ul class="simple"> <li><a class="reference internal" href="../auto_examples/applications/plot_face_recognition#sphx-glr-auto-examples-applications-plot-face-recognition-py"><span class="std std-ref">Faces recognition example using eigenfaces and SVMs</span></a></li> </ul> </div>   <h2 id="random-projections">
<span class="section-number">6.5.2. </span>Random projections</h2> <p>The module: <code>random_projection</code> provides several tools for data reduction by random projections. See the relevant section of the documentation: <a class="reference internal" href="random_projection#random-projection"><span class="std std-ref">Random Projection</span></a>.</p> <div class="topic"> <p class="topic-title"><strong>Examples</strong></p> <ul class="simple"> <li><a class="reference internal" href="../auto_examples/miscellaneous/plot_johnson_lindenstrauss_bound#sphx-glr-auto-examples-miscellaneous-plot-johnson-lindenstrauss-bound-py"><span class="std std-ref">The Johnson-Lindenstrauss bound for embedding with random projections</span></a></li> </ul> </div>   <h2 id="feature-agglomeration">
<span class="section-number">6.5.3. </span>Feature agglomeration</h2> <p><a class="reference internal" href="generated/sklearn.cluster.featureagglomeration#sklearn.cluster.FeatureAgglomeration" title="sklearn.cluster.FeatureAgglomeration"><code>cluster.FeatureAgglomeration</code></a> applies <a class="reference internal" href="clustering#hierarchical-clustering"><span class="std std-ref">Hierarchical clustering</span></a> to group together features that behave similarly.</p> <div class="topic"> <p class="topic-title"><strong>Examples</strong></p> <ul class="simple"> <li><a class="reference internal" href="../auto_examples/cluster/plot_feature_agglomeration_vs_univariate_selection#sphx-glr-auto-examples-cluster-plot-feature-agglomeration-vs-univariate-selection-py"><span class="std std-ref">Feature agglomeration vs. univariate selection</span></a></li> <li><a class="reference internal" href="../auto_examples/cluster/plot_digits_agglomeration#sphx-glr-auto-examples-cluster-plot-digits-agglomeration-py"><span class="std std-ref">Feature agglomeration</span></a></li> </ul> </div> <div class="topic"> <p class="topic-title"><strong>Feature scaling</strong></p> <p>Note that if features have very different scaling or statistical properties, <a class="reference internal" href="generated/sklearn.cluster.featureagglomeration#sklearn.cluster.FeatureAgglomeration" title="sklearn.cluster.FeatureAgglomeration"><code>cluster.FeatureAgglomeration</code></a> may not be able to capture the links between related features. Using a <a class="reference internal" href="generated/sklearn.preprocessing.standardscaler#sklearn.preprocessing.StandardScaler" title="sklearn.preprocessing.StandardScaler"><code>preprocessing.StandardScaler</code></a> can be useful in these settings.</p> </div><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2007&ndash;2020 The scikit-learn developers<br>Licensed under the 3-clause BSD License.<br>
    <a href="https://scikit-learn.org/0.24/modules/unsupervised_reduction.html" class="_attribution-link">https://scikit-learn.org/0.24/modules/unsupervised_reduction.html</a>
  </p>
</div>
