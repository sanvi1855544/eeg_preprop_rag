<h1 id="tensor-doc">torch.Tensor</h1> <p id="torch-tensor">A <a class="reference internal" href="#torch.Tensor" title="torch.Tensor"><code>torch.Tensor</code></a> is a multi-dimensional matrix containing elements of a single data type.</p>  <h2 id="data-types">Data types</h2> <p>Torch defines 10 tensor types with CPU and GPU variants which are as follows:</p> <table class="docutils colwidths-auto align-default"> <thead> <tr>
<th class="head"><p>Data type</p></th> <th class="head"><p>dtype</p></th> <th class="head"><p>CPU tensor</p></th> <th class="head"><p>GPU tensor</p></th> </tr> </thead>  <tr>
<td><p>32-bit floating point</p></td> <td><p><code>torch.float32</code> or <code>torch.float</code></p></td> <td><p><code>torch.FloatTensor</code></p></td> <td><p><code>torch.cuda.FloatTensor</code></p></td> </tr> <tr>
<td><p>64-bit floating point</p></td> <td><p><code>torch.float64</code> or <code>torch.double</code></p></td> <td><p><code>torch.DoubleTensor</code></p></td> <td><p><code>torch.cuda.DoubleTensor</code></p></td> </tr> <tr>
<td><p>16-bit floating point <a class="footnote-reference brackets" href="#id4" id="id1">1</a></p></td> <td><p><code>torch.float16</code> or <code>torch.half</code></p></td> <td><p><code>torch.HalfTensor</code></p></td> <td><p><code>torch.cuda.HalfTensor</code></p></td> </tr> <tr>
<td><p>16-bit floating point <a class="footnote-reference brackets" href="#id5" id="id2">2</a></p></td> <td><p><code>torch.bfloat16</code></p></td> <td><p><code>torch.BFloat16Tensor</code></p></td> <td><p><code>torch.cuda.BFloat16Tensor</code></p></td> </tr> <tr>
<td><p>32-bit complex</p></td> <td><p><code>torch.complex32</code> or <code>torch.chalf</code></p></td> <td></td> <td></td> </tr> <tr>
<td><p>64-bit complex</p></td> <td><p><code>torch.complex64</code> or <code>torch.cfloat</code></p></td> <td></td> <td></td> </tr> <tr>
<td><p>128-bit complex</p></td> <td><p><code>torch.complex128</code> or <code>torch.cdouble</code></p></td> <td></td> <td></td> </tr> <tr>
<td><p>8-bit integer (unsigned)</p></td> <td><p><code>torch.uint8</code></p></td> <td><p><code>torch.ByteTensor</code></p></td> <td><p><code>torch.cuda.ByteTensor</code></p></td> </tr> <tr>
<td><p>8-bit integer (signed)</p></td> <td><p><code>torch.int8</code></p></td> <td><p><code>torch.CharTensor</code></p></td> <td><p><code>torch.cuda.CharTensor</code></p></td> </tr> <tr>
<td><p>16-bit integer (signed)</p></td> <td><p><code>torch.int16</code> or <code>torch.short</code></p></td> <td><p><code>torch.ShortTensor</code></p></td> <td><p><code>torch.cuda.ShortTensor</code></p></td> </tr> <tr>
<td><p>32-bit integer (signed)</p></td> <td><p><code>torch.int32</code> or <code>torch.int</code></p></td> <td><p><code>torch.IntTensor</code></p></td> <td><p><code>torch.cuda.IntTensor</code></p></td> </tr> <tr>
<td><p>64-bit integer (signed)</p></td> <td><p><code>torch.int64</code> or <code>torch.long</code></p></td> <td><p><code>torch.LongTensor</code></p></td> <td><p><code>torch.cuda.LongTensor</code></p></td> </tr> <tr>
<td><p>Boolean</p></td> <td><p><code>torch.bool</code></p></td> <td><p><code>torch.BoolTensor</code></p></td> <td><p><code>torch.cuda.BoolTensor</code></p></td> </tr> <tr>
<td><p>quantized 8-bit integer (unsigned)</p></td> <td><p><code>torch.quint8</code></p></td> <td><p><code>torch.ByteTensor</code></p></td> <td><p>/</p></td> </tr> <tr>
<td><p>quantized 8-bit integer (signed)</p></td> <td><p><code>torch.qint8</code></p></td> <td><p><code>torch.CharTensor</code></p></td> <td><p>/</p></td> </tr> <tr>
<td><p>quantized 32-bit integer (signed)</p></td> <td><p><code>torch.qint32</code></p></td> <td><p><code>torch.IntTensor</code></p></td> <td><p>/</p></td> </tr> <tr>
<td><p>quantized 4-bit integer (unsigned) <a class="footnote-reference brackets" href="#id6" id="id3">3</a></p></td> <td><p><code>torch.quint4x2</code></p></td> <td><p><code>torch.ByteTensor</code></p></td> <td><p>/</p></td> </tr>  </table> <dl class="footnote brackets"> <dt class="label" id="id4">
<code>1</code> </dt> <dd>
<p>Sometimes referred to as binary16: uses 1 sign, 5 exponent, and 10 significand bits. Useful when precision is important at the expense of range.</p> </dd> <dt class="label" id="id5">
<code>2</code> </dt> <dd>
<p>Sometimes referred to as Brain Floating Point: uses 1 sign, 8 exponent, and 7 significand bits. Useful when range is important, since it has the same number of exponent bits as <code>float32</code></p> </dd> <dt class="label" id="id6">
<code>3</code> </dt> <dd>
<p>quantized 4-bit integer is stored as a 8-bit signed integer. Currently it’s only supported in EmbeddingBag operator.</p> </dd> </dl> <p><a class="reference internal" href="#torch.Tensor" title="torch.Tensor"><code>torch.Tensor</code></a> is an alias for the default tensor type (<code>torch.FloatTensor</code>).</p>   <h2 id="initializing-and-basic-operations">Initializing and basic operations</h2> <p>A tensor can be constructed from a Python <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.12)"><code>list</code></a> or sequence using the <a class="reference internal" href="generated/torch.tensor#torch.tensor" title="torch.tensor"><code>torch.tensor()</code></a> constructor:</p> <pre data-language="python">&gt;&gt;&gt; torch.tensor([[1., -1.], [1., -1.]])
tensor([[ 1.0000, -1.0000],
        [ 1.0000, -1.0000]])
&gt;&gt;&gt; torch.tensor(np.array([[1, 2, 3], [4, 5, 6]]))
tensor([[ 1,  2,  3],
        [ 4,  5,  6]])
</pre> <div class="admonition warning"> <p class="admonition-title">Warning</p> <p><a class="reference internal" href="generated/torch.tensor#torch.tensor" title="torch.tensor"><code>torch.tensor()</code></a> always copies <code>data</code>. If you have a Tensor <code>data</code> and just want to change its <code>requires_grad</code> flag, use <a class="reference internal" href="generated/torch.tensor.requires_grad_#torch.Tensor.requires_grad_" title="torch.Tensor.requires_grad_"><code>requires_grad_()</code></a> or <a class="reference internal" href="generated/torch.tensor.detach#torch.Tensor.detach" title="torch.Tensor.detach"><code>detach()</code></a> to avoid a copy. If you have a numpy array and want to avoid a copy, use <a class="reference internal" href="generated/torch.as_tensor#torch.as_tensor" title="torch.as_tensor"><code>torch.as_tensor()</code></a>.</p> </div> <p>A tensor of specific data type can be constructed by passing a <a class="reference internal" href="tensor_attributes#torch.dtype" title="torch.dtype"><code>torch.dtype</code></a> and/or a <a class="reference internal" href="tensor_attributes#torch.device" title="torch.device"><code>torch.device</code></a> to a constructor or tensor creation op:</p> <pre data-language="python">&gt;&gt;&gt; torch.zeros([2, 4], dtype=torch.int32)
tensor([[ 0,  0,  0,  0],
        [ 0,  0,  0,  0]], dtype=torch.int32)
&gt;&gt;&gt; cuda0 = torch.device('cuda:0')
&gt;&gt;&gt; torch.ones([2, 4], dtype=torch.float64, device=cuda0)
tensor([[ 1.0000,  1.0000,  1.0000,  1.0000],
        [ 1.0000,  1.0000,  1.0000,  1.0000]], dtype=torch.float64, device='cuda:0')
</pre> <p>For more information about building Tensors, see <a class="reference internal" href="torch#tensor-creation-ops"><span class="std std-ref">Creation Ops</span></a></p> <p>The contents of a tensor can be accessed and modified using Python’s indexing and slicing notation:</p> <pre data-language="python">&gt;&gt;&gt; x = torch.tensor([[1, 2, 3], [4, 5, 6]])
&gt;&gt;&gt; print(x[1][2])
tensor(6)
&gt;&gt;&gt; x[0][1] = 8
&gt;&gt;&gt; print(x)
tensor([[ 1,  8,  3],
        [ 4,  5,  6]])
</pre> <p>Use <a class="reference internal" href="generated/torch.tensor.item#torch.Tensor.item" title="torch.Tensor.item"><code>torch.Tensor.item()</code></a> to get a Python number from a tensor containing a single value:</p> <pre data-language="python">&gt;&gt;&gt; x = torch.tensor([[1]])
&gt;&gt;&gt; x
tensor([[ 1]])
&gt;&gt;&gt; x.item()
1
&gt;&gt;&gt; x = torch.tensor(2.5)
&gt;&gt;&gt; x
tensor(2.5000)
&gt;&gt;&gt; x.item()
2.5
</pre> <p>For more information about indexing, see <a class="reference internal" href="torch#indexing-slicing-joining"><span class="std std-ref">Indexing, Slicing, Joining, Mutating Ops</span></a></p> <p>A tensor can be created with <code>requires_grad=True</code> so that <a class="reference internal" href="autograd#module-torch.autograd" title="torch.autograd"><code>torch.autograd</code></a> records operations on them for automatic differentiation.</p> <pre data-language="python">&gt;&gt;&gt; x = torch.tensor([[1., -1.], [1., 1.]], requires_grad=True)
&gt;&gt;&gt; out = x.pow(2).sum()
&gt;&gt;&gt; out.backward()
&gt;&gt;&gt; x.grad
tensor([[ 2.0000, -2.0000],
        [ 2.0000,  2.0000]])
</pre> <p>Each tensor has an associated <code>torch.Storage</code>, which holds its data. The tensor class also provides multi-dimensional, <a class="reference external" href="https://en.wikipedia.org/wiki/Stride_of_an_array">strided</a> view of a storage and defines numeric operations on it.</p> <div class="admonition note"> <p class="admonition-title">Note</p> <p>For more information on tensor views, see <a class="reference internal" href="tensor_view#tensor-view-doc"><span class="std std-ref">Tensor Views</span></a>.</p> </div> <div class="admonition note"> <p class="admonition-title">Note</p> <p>For more information on the <a class="reference internal" href="tensor_attributes#torch.dtype" title="torch.dtype"><code>torch.dtype</code></a>, <a class="reference internal" href="tensor_attributes#torch.device" title="torch.device"><code>torch.device</code></a>, and <a class="reference internal" href="tensor_attributes#torch.layout" title="torch.layout"><code>torch.layout</code></a> attributes of a <a class="reference internal" href="#torch.Tensor" title="torch.Tensor"><code>torch.Tensor</code></a>, see <a class="reference internal" href="tensor_attributes#tensor-attributes-doc"><span class="std std-ref">Tensor Attributes</span></a>.</p> </div> <div class="admonition note"> <p class="admonition-title">Note</p> <p>Methods which mutate a tensor are marked with an underscore suffix. For example, <code>torch.FloatTensor.abs_()</code> computes the absolute value in-place and returns the modified tensor, while <code>torch.FloatTensor.abs()</code> computes the result in a new tensor.</p> </div> <div class="admonition note"> <p class="admonition-title">Note</p> <p>To change an existing tensor’s <a class="reference internal" href="tensor_attributes#torch.device" title="torch.device"><code>torch.device</code></a> and/or <a class="reference internal" href="tensor_attributes#torch.dtype" title="torch.dtype"><code>torch.dtype</code></a>, consider using <a class="reference internal" href="generated/torch.tensor.to#torch.Tensor.to" title="torch.Tensor.to"><code>to()</code></a> method on the tensor.</p> </div> <div class="admonition warning"> <p class="admonition-title">Warning</p> <p>Current implementation of <a class="reference internal" href="#torch.Tensor" title="torch.Tensor"><code>torch.Tensor</code></a> introduces memory overhead, thus it might lead to unexpectedly high memory usage in the applications with many tiny tensors. If this is your case, consider using one large structure.</p> </div>   <h2 id="tensor-class-reference">Tensor class reference</h2> <dl class="py class"> <dt class="sig sig-object py" id="torch.Tensor">
<code>class torch.Tensor</code> </dt> <dd>
<p>There are a few main ways to create a tensor, depending on your use case.</p> <ul class="simple"> <li>To create a tensor with pre-existing data, use <a class="reference internal" href="generated/torch.tensor#torch.tensor" title="torch.tensor"><code>torch.tensor()</code></a>.</li> <li>To create a tensor with specific size, use <code>torch.*</code> tensor creation ops (see <a class="reference internal" href="torch#tensor-creation-ops"><span class="std std-ref">Creation Ops</span></a>).</li> <li>To create a tensor with the same size (and similar types) as another tensor, use <code>torch.*_like</code> tensor creation ops (see <a class="reference internal" href="torch#tensor-creation-ops"><span class="std std-ref">Creation Ops</span></a>).</li> <li>To create a tensor with similar type but different size as another tensor, use <code>tensor.new_*</code> creation ops.</li> </ul> </dd>
</dl> <dl class="py attribute"> <dt class="sig sig-object py" id="torch.Tensor.T">
<code>Tensor.T</code> </dt> <dd>
<p>Returns a view of this tensor with its dimensions reversed.</p> <p>If <code>n</code> is the number of dimensions in <code>x</code>, <code>x.T</code> is equivalent to <code>x.permute(n-1, n-2, ..., 0)</code>.</p> <div class="admonition warning"> <p class="admonition-title">Warning</p> <p>The use of <a class="reference internal" href="#torch.Tensor.T" title="torch.Tensor.T"><code>Tensor.T()</code></a> on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider <a class="reference internal" href="#torch.Tensor.mT" title="torch.Tensor.mT"><code>mT</code></a> to transpose batches of matrices or <code>x.permute(*torch.arange(x.ndim - 1, -1, -1))</code> to reverse the dimensions of a tensor.</p> </div> </dd>
</dl> <dl class="py attribute"> <dt class="sig sig-object py" id="torch.Tensor.H">
<code>Tensor.H</code> </dt> <dd>
<p>Returns a view of a matrix (2-D tensor) conjugated and transposed.</p> <p><code>x.H</code> is equivalent to <code>x.transpose(0, 1).conj()</code> for complex matrices and <code>x.transpose(0, 1)</code> for real matrices.</p> <div class="admonition seealso"> <p class="admonition-title">See also</p> <p><a class="reference internal" href="#torch.Tensor.mH" title="torch.Tensor.mH"><code>mH</code></a>: An attribute that also works on batches of matrices.</p> </div> </dd>
</dl> <dl class="py attribute"> <dt class="sig sig-object py" id="torch.Tensor.mT">
<code>Tensor.mT</code> </dt> <dd>
<p>Returns a view of this tensor with the last two dimensions transposed.</p> <p><code>x.mT</code> is equivalent to <code>x.transpose(-2, -1)</code>.</p> </dd>
</dl> <dl class="py attribute"> <dt class="sig sig-object py" id="torch.Tensor.mH">
<code>Tensor.mH</code> </dt> <dd>
<p>Accessing this property is equivalent to calling <a class="reference internal" href="generated/torch.adjoint#torch.adjoint" title="torch.adjoint"><code>adjoint()</code></a>.</p> </dd>
</dl> <table class="autosummary longtable docutils colwidths-auto align-default">  <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.new_tensor#torch.Tensor.new_tensor" title="torch.Tensor.new_tensor"><code>Tensor.new_tensor</code></a></p></td> <td><p>Returns a new Tensor with <code>data</code> as the tensor data.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.new_full#torch.Tensor.new_full" title="torch.Tensor.new_full"><code>Tensor.new_full</code></a></p></td> <td><p>Returns a Tensor of size <code>size</code> filled with <code>fill_value</code>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.new_empty#torch.Tensor.new_empty" title="torch.Tensor.new_empty"><code>Tensor.new_empty</code></a></p></td> <td><p>Returns a Tensor of size <code>size</code> filled with uninitialized data.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.new_ones#torch.Tensor.new_ones" title="torch.Tensor.new_ones"><code>Tensor.new_ones</code></a></p></td> <td><p>Returns a Tensor of size <code>size</code> filled with <code>1</code>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.new_zeros#torch.Tensor.new_zeros" title="torch.Tensor.new_zeros"><code>Tensor.new_zeros</code></a></p></td> <td><p>Returns a Tensor of size <code>size</code> filled with <code>0</code>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.is_cuda#torch.Tensor.is_cuda" title="torch.Tensor.is_cuda"><code>Tensor.is_cuda</code></a></p></td> <td><p>Is <code>True</code> if the Tensor is stored on the GPU, <code>False</code> otherwise.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.is_quantized#torch.Tensor.is_quantized" title="torch.Tensor.is_quantized"><code>Tensor.is_quantized</code></a></p></td> <td><p>Is <code>True</code> if the Tensor is quantized, <code>False</code> otherwise.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.is_meta#torch.Tensor.is_meta" title="torch.Tensor.is_meta"><code>Tensor.is_meta</code></a></p></td> <td><p>Is <code>True</code> if the Tensor is a meta tensor, <code>False</code> otherwise.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.device#torch.Tensor.device" title="torch.Tensor.device"><code>Tensor.device</code></a></p></td> <td><p>Is the <a class="reference internal" href="tensor_attributes#torch.device" title="torch.device"><code>torch.device</code></a> where this Tensor is.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.grad#torch.Tensor.grad" title="torch.Tensor.grad"><code>Tensor.grad</code></a></p></td> <td><p>This attribute is <code>None</code> by default and becomes a Tensor the first time a call to <code>backward()</code> computes gradients for <code>self</code>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.ndim#torch.Tensor.ndim" title="torch.Tensor.ndim"><code>Tensor.ndim</code></a></p></td> <td><p>Alias for <a class="reference internal" href="generated/torch.tensor.dim#torch.Tensor.dim" title="torch.Tensor.dim"><code>dim()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.real#torch.Tensor.real" title="torch.Tensor.real"><code>Tensor.real</code></a></p></td> <td><p>Returns a new tensor containing real values of the <code>self</code> tensor for a complex-valued input tensor.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.imag#torch.Tensor.imag" title="torch.Tensor.imag"><code>Tensor.imag</code></a></p></td> <td><p>Returns a new tensor containing imaginary values of the <code>self</code> tensor.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.nbytes#torch.Tensor.nbytes" title="torch.Tensor.nbytes"><code>Tensor.nbytes</code></a></p></td> <td><p>Returns the number of bytes consumed by the "view" of elements of the Tensor if the Tensor does not use sparse storage layout.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.itemsize#torch.Tensor.itemsize" title="torch.Tensor.itemsize"><code>Tensor.itemsize</code></a></p></td> <td><p>Alias for <a class="reference internal" href="generated/torch.tensor.element_size#torch.Tensor.element_size" title="torch.Tensor.element_size"><code>element_size()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.abs#torch.Tensor.abs" title="torch.Tensor.abs"><code>Tensor.abs</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.abs#torch.abs" title="torch.abs"><code>torch.abs()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.abs_#torch.Tensor.abs_" title="torch.Tensor.abs_"><code>Tensor.abs_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.abs#torch.Tensor.abs" title="torch.Tensor.abs"><code>abs()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.absolute#torch.Tensor.absolute" title="torch.Tensor.absolute"><code>Tensor.absolute</code></a></p></td> <td><p>Alias for <a class="reference internal" href="generated/torch.abs#torch.abs" title="torch.abs"><code>abs()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.absolute_#torch.Tensor.absolute_" title="torch.Tensor.absolute_"><code>Tensor.absolute_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.absolute#torch.Tensor.absolute" title="torch.Tensor.absolute"><code>absolute()</code></a> Alias for <code>abs_()</code></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.acos#torch.Tensor.acos" title="torch.Tensor.acos"><code>Tensor.acos</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.acos#torch.acos" title="torch.acos"><code>torch.acos()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.acos_#torch.Tensor.acos_" title="torch.Tensor.acos_"><code>Tensor.acos_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.acos#torch.Tensor.acos" title="torch.Tensor.acos"><code>acos()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.arccos#torch.Tensor.arccos" title="torch.Tensor.arccos"><code>Tensor.arccos</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.arccos#torch.arccos" title="torch.arccos"><code>torch.arccos()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.arccos_#torch.Tensor.arccos_" title="torch.Tensor.arccos_"><code>Tensor.arccos_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.arccos#torch.Tensor.arccos" title="torch.Tensor.arccos"><code>arccos()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.add#torch.Tensor.add" title="torch.Tensor.add"><code>Tensor.add</code></a></p></td> <td><p>Add a scalar or tensor to <code>self</code> tensor.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.add_#torch.Tensor.add_" title="torch.Tensor.add_"><code>Tensor.add_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.add#torch.Tensor.add" title="torch.Tensor.add"><code>add()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.addbmm#torch.Tensor.addbmm" title="torch.Tensor.addbmm"><code>Tensor.addbmm</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.addbmm#torch.addbmm" title="torch.addbmm"><code>torch.addbmm()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.addbmm_#torch.Tensor.addbmm_" title="torch.Tensor.addbmm_"><code>Tensor.addbmm_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.addbmm#torch.Tensor.addbmm" title="torch.Tensor.addbmm"><code>addbmm()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.addcdiv#torch.Tensor.addcdiv" title="torch.Tensor.addcdiv"><code>Tensor.addcdiv</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.addcdiv#torch.addcdiv" title="torch.addcdiv"><code>torch.addcdiv()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.addcdiv_#torch.Tensor.addcdiv_" title="torch.Tensor.addcdiv_"><code>Tensor.addcdiv_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.addcdiv#torch.Tensor.addcdiv" title="torch.Tensor.addcdiv"><code>addcdiv()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.addcmul#torch.Tensor.addcmul" title="torch.Tensor.addcmul"><code>Tensor.addcmul</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.addcmul#torch.addcmul" title="torch.addcmul"><code>torch.addcmul()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.addcmul_#torch.Tensor.addcmul_" title="torch.Tensor.addcmul_"><code>Tensor.addcmul_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.addcmul#torch.Tensor.addcmul" title="torch.Tensor.addcmul"><code>addcmul()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.addmm#torch.Tensor.addmm" title="torch.Tensor.addmm"><code>Tensor.addmm</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.addmm#torch.addmm" title="torch.addmm"><code>torch.addmm()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.addmm_#torch.Tensor.addmm_" title="torch.Tensor.addmm_"><code>Tensor.addmm_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.addmm#torch.Tensor.addmm" title="torch.Tensor.addmm"><code>addmm()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.sspaddmm#torch.Tensor.sspaddmm" title="torch.Tensor.sspaddmm"><code>Tensor.sspaddmm</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.sspaddmm#torch.sspaddmm" title="torch.sspaddmm"><code>torch.sspaddmm()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.addmv#torch.Tensor.addmv" title="torch.Tensor.addmv"><code>Tensor.addmv</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.addmv#torch.addmv" title="torch.addmv"><code>torch.addmv()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.addmv_#torch.Tensor.addmv_" title="torch.Tensor.addmv_"><code>Tensor.addmv_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.addmv#torch.Tensor.addmv" title="torch.Tensor.addmv"><code>addmv()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.addr#torch.Tensor.addr" title="torch.Tensor.addr"><code>Tensor.addr</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.addr#torch.addr" title="torch.addr"><code>torch.addr()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.addr_#torch.Tensor.addr_" title="torch.Tensor.addr_"><code>Tensor.addr_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.addr#torch.Tensor.addr" title="torch.Tensor.addr"><code>addr()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.adjoint#torch.Tensor.adjoint" title="torch.Tensor.adjoint"><code>Tensor.adjoint</code></a></p></td> <td><p>Alias for <a class="reference internal" href="generated/torch.adjoint#torch.adjoint" title="torch.adjoint"><code>adjoint()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.allclose#torch.Tensor.allclose" title="torch.Tensor.allclose"><code>Tensor.allclose</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.allclose#torch.allclose" title="torch.allclose"><code>torch.allclose()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.amax#torch.Tensor.amax" title="torch.Tensor.amax"><code>Tensor.amax</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.amax#torch.amax" title="torch.amax"><code>torch.amax()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.amin#torch.Tensor.amin" title="torch.Tensor.amin"><code>Tensor.amin</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.amin#torch.amin" title="torch.amin"><code>torch.amin()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.aminmax#torch.Tensor.aminmax" title="torch.Tensor.aminmax"><code>Tensor.aminmax</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.aminmax#torch.aminmax" title="torch.aminmax"><code>torch.aminmax()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.angle#torch.Tensor.angle" title="torch.Tensor.angle"><code>Tensor.angle</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.angle#torch.angle" title="torch.angle"><code>torch.angle()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.apply_#torch.Tensor.apply_" title="torch.Tensor.apply_"><code>Tensor.apply_</code></a></p></td> <td><p>Applies the function <code>callable</code> to each element in the tensor, replacing each element with the value returned by <code>callable</code>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.argmax#torch.Tensor.argmax" title="torch.Tensor.argmax"><code>Tensor.argmax</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.argmax#torch.argmax" title="torch.argmax"><code>torch.argmax()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.argmin#torch.Tensor.argmin" title="torch.Tensor.argmin"><code>Tensor.argmin</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.argmin#torch.argmin" title="torch.argmin"><code>torch.argmin()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.argsort#torch.Tensor.argsort" title="torch.Tensor.argsort"><code>Tensor.argsort</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.argsort#torch.argsort" title="torch.argsort"><code>torch.argsort()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.argwhere#torch.Tensor.argwhere" title="torch.Tensor.argwhere"><code>Tensor.argwhere</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.argwhere#torch.argwhere" title="torch.argwhere"><code>torch.argwhere()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.asin#torch.Tensor.asin" title="torch.Tensor.asin"><code>Tensor.asin</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.asin#torch.asin" title="torch.asin"><code>torch.asin()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.asin_#torch.Tensor.asin_" title="torch.Tensor.asin_"><code>Tensor.asin_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.asin#torch.Tensor.asin" title="torch.Tensor.asin"><code>asin()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.arcsin#torch.Tensor.arcsin" title="torch.Tensor.arcsin"><code>Tensor.arcsin</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.arcsin#torch.arcsin" title="torch.arcsin"><code>torch.arcsin()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.arcsin_#torch.Tensor.arcsin_" title="torch.Tensor.arcsin_"><code>Tensor.arcsin_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.arcsin#torch.Tensor.arcsin" title="torch.Tensor.arcsin"><code>arcsin()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.as_strided#torch.Tensor.as_strided" title="torch.Tensor.as_strided"><code>Tensor.as_strided</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.as_strided#torch.as_strided" title="torch.as_strided"><code>torch.as_strided()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.atan#torch.Tensor.atan" title="torch.Tensor.atan"><code>Tensor.atan</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.atan#torch.atan" title="torch.atan"><code>torch.atan()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.atan_#torch.Tensor.atan_" title="torch.Tensor.atan_"><code>Tensor.atan_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.atan#torch.Tensor.atan" title="torch.Tensor.atan"><code>atan()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.arctan#torch.Tensor.arctan" title="torch.Tensor.arctan"><code>Tensor.arctan</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.arctan#torch.arctan" title="torch.arctan"><code>torch.arctan()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.arctan_#torch.Tensor.arctan_" title="torch.Tensor.arctan_"><code>Tensor.arctan_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.arctan#torch.Tensor.arctan" title="torch.Tensor.arctan"><code>arctan()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.atan2#torch.Tensor.atan2" title="torch.Tensor.atan2"><code>Tensor.atan2</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.atan2#torch.atan2" title="torch.atan2"><code>torch.atan2()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.atan2_#torch.Tensor.atan2_" title="torch.Tensor.atan2_"><code>Tensor.atan2_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.atan2#torch.Tensor.atan2" title="torch.Tensor.atan2"><code>atan2()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.arctan2#torch.Tensor.arctan2" title="torch.Tensor.arctan2"><code>Tensor.arctan2</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.arctan2#torch.arctan2" title="torch.arctan2"><code>torch.arctan2()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.arctan2_#torch.Tensor.arctan2_" title="torch.Tensor.arctan2_"><code>Tensor.arctan2_</code></a></p></td> <td><p>atan2_(other) -&gt; Tensor</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.all#torch.Tensor.all" title="torch.Tensor.all"><code>Tensor.all</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.all#torch.all" title="torch.all"><code>torch.all()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.any#torch.Tensor.any" title="torch.Tensor.any"><code>Tensor.any</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.any#torch.any" title="torch.any"><code>torch.any()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.backward#torch.Tensor.backward" title="torch.Tensor.backward"><code>Tensor.backward</code></a></p></td> <td><p>Computes the gradient of current tensor wrt graph leaves.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.baddbmm#torch.Tensor.baddbmm" title="torch.Tensor.baddbmm"><code>Tensor.baddbmm</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.baddbmm#torch.baddbmm" title="torch.baddbmm"><code>torch.baddbmm()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.baddbmm_#torch.Tensor.baddbmm_" title="torch.Tensor.baddbmm_"><code>Tensor.baddbmm_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.baddbmm#torch.Tensor.baddbmm" title="torch.Tensor.baddbmm"><code>baddbmm()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.bernoulli#torch.Tensor.bernoulli" title="torch.Tensor.bernoulli"><code>Tensor.bernoulli</code></a></p></td> <td><p>Returns a result tensor where each <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext mathvariant="monospace">result[i]</mtext></mrow><annotation encoding="application/x-tex">\texttt{result[i]}</annotation></semantics></math></span></span></span> is independently sampled from <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>Bernoulli</mtext><mo stretchy="false">(</mo><mtext mathvariant="monospace">self[i]</mtext><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\text{Bernoulli}(\texttt{self[i]})</annotation></semantics></math></span></span></span>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.bernoulli_#torch.Tensor.bernoulli_" title="torch.Tensor.bernoulli_"><code>Tensor.bernoulli_</code></a></p></td> <td><p>Fills each location of <code>self</code> with an independent sample from <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>Bernoulli</mtext><mo stretchy="false">(</mo><mtext mathvariant="monospace">p</mtext><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\text{Bernoulli}(\texttt{p})</annotation></semantics></math></span></span></span>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.bfloat16#torch.Tensor.bfloat16" title="torch.Tensor.bfloat16"><code>Tensor.bfloat16</code></a></p></td> <td><p><code>self.bfloat16()</code> is equivalent to <code>self.to(torch.bfloat16)</code>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.bincount#torch.Tensor.bincount" title="torch.Tensor.bincount"><code>Tensor.bincount</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.bincount#torch.bincount" title="torch.bincount"><code>torch.bincount()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.bitwise_not#torch.Tensor.bitwise_not" title="torch.Tensor.bitwise_not"><code>Tensor.bitwise_not</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.bitwise_not#torch.bitwise_not" title="torch.bitwise_not"><code>torch.bitwise_not()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.bitwise_not_#torch.Tensor.bitwise_not_" title="torch.Tensor.bitwise_not_"><code>Tensor.bitwise_not_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.bitwise_not#torch.Tensor.bitwise_not" title="torch.Tensor.bitwise_not"><code>bitwise_not()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.bitwise_and#torch.Tensor.bitwise_and" title="torch.Tensor.bitwise_and"><code>Tensor.bitwise_and</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.bitwise_and#torch.bitwise_and" title="torch.bitwise_and"><code>torch.bitwise_and()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.bitwise_and_#torch.Tensor.bitwise_and_" title="torch.Tensor.bitwise_and_"><code>Tensor.bitwise_and_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.bitwise_and#torch.Tensor.bitwise_and" title="torch.Tensor.bitwise_and"><code>bitwise_and()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.bitwise_or#torch.Tensor.bitwise_or" title="torch.Tensor.bitwise_or"><code>Tensor.bitwise_or</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.bitwise_or#torch.bitwise_or" title="torch.bitwise_or"><code>torch.bitwise_or()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.bitwise_or_#torch.Tensor.bitwise_or_" title="torch.Tensor.bitwise_or_"><code>Tensor.bitwise_or_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.bitwise_or#torch.Tensor.bitwise_or" title="torch.Tensor.bitwise_or"><code>bitwise_or()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.bitwise_xor#torch.Tensor.bitwise_xor" title="torch.Tensor.bitwise_xor"><code>Tensor.bitwise_xor</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.bitwise_xor#torch.bitwise_xor" title="torch.bitwise_xor"><code>torch.bitwise_xor()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.bitwise_xor_#torch.Tensor.bitwise_xor_" title="torch.Tensor.bitwise_xor_"><code>Tensor.bitwise_xor_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.bitwise_xor#torch.Tensor.bitwise_xor" title="torch.Tensor.bitwise_xor"><code>bitwise_xor()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.bitwise_left_shift#torch.Tensor.bitwise_left_shift" title="torch.Tensor.bitwise_left_shift"><code>Tensor.bitwise_left_shift</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.bitwise_left_shift#torch.bitwise_left_shift" title="torch.bitwise_left_shift"><code>torch.bitwise_left_shift()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.bitwise_left_shift_#torch.Tensor.bitwise_left_shift_" title="torch.Tensor.bitwise_left_shift_"><code>Tensor.bitwise_left_shift_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.bitwise_left_shift#torch.Tensor.bitwise_left_shift" title="torch.Tensor.bitwise_left_shift"><code>bitwise_left_shift()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.bitwise_right_shift#torch.Tensor.bitwise_right_shift" title="torch.Tensor.bitwise_right_shift"><code>Tensor.bitwise_right_shift</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.bitwise_right_shift#torch.bitwise_right_shift" title="torch.bitwise_right_shift"><code>torch.bitwise_right_shift()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.bitwise_right_shift_#torch.Tensor.bitwise_right_shift_" title="torch.Tensor.bitwise_right_shift_"><code>Tensor.bitwise_right_shift_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.bitwise_right_shift#torch.Tensor.bitwise_right_shift" title="torch.Tensor.bitwise_right_shift"><code>bitwise_right_shift()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.bmm#torch.Tensor.bmm" title="torch.Tensor.bmm"><code>Tensor.bmm</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.bmm#torch.bmm" title="torch.bmm"><code>torch.bmm()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.bool#torch.Tensor.bool" title="torch.Tensor.bool"><code>Tensor.bool</code></a></p></td> <td><p><code>self.bool()</code> is equivalent to <code>self.to(torch.bool)</code>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.byte#torch.Tensor.byte" title="torch.Tensor.byte"><code>Tensor.byte</code></a></p></td> <td><p><code>self.byte()</code> is equivalent to <code>self.to(torch.uint8)</code>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.broadcast_to#torch.Tensor.broadcast_to" title="torch.Tensor.broadcast_to"><code>Tensor.broadcast_to</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.broadcast_to#torch.broadcast_to" title="torch.broadcast_to"><code>torch.broadcast_to()</code></a>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.cauchy_#torch.Tensor.cauchy_" title="torch.Tensor.cauchy_"><code>Tensor.cauchy_</code></a></p></td> <td><p>Fills the tensor with numbers drawn from the Cauchy distribution:</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.ceil#torch.Tensor.ceil" title="torch.Tensor.ceil"><code>Tensor.ceil</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.ceil#torch.ceil" title="torch.ceil"><code>torch.ceil()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.ceil_#torch.Tensor.ceil_" title="torch.Tensor.ceil_"><code>Tensor.ceil_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.ceil#torch.Tensor.ceil" title="torch.Tensor.ceil"><code>ceil()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.char#torch.Tensor.char" title="torch.Tensor.char"><code>Tensor.char</code></a></p></td> <td><p><code>self.char()</code> is equivalent to <code>self.to(torch.int8)</code>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.cholesky#torch.Tensor.cholesky" title="torch.Tensor.cholesky"><code>Tensor.cholesky</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.cholesky#torch.cholesky" title="torch.cholesky"><code>torch.cholesky()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.cholesky_inverse#torch.Tensor.cholesky_inverse" title="torch.Tensor.cholesky_inverse"><code>Tensor.cholesky_inverse</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.cholesky_inverse#torch.cholesky_inverse" title="torch.cholesky_inverse"><code>torch.cholesky_inverse()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.cholesky_solve#torch.Tensor.cholesky_solve" title="torch.Tensor.cholesky_solve"><code>Tensor.cholesky_solve</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.cholesky_solve#torch.cholesky_solve" title="torch.cholesky_solve"><code>torch.cholesky_solve()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.chunk#torch.Tensor.chunk" title="torch.Tensor.chunk"><code>Tensor.chunk</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.chunk#torch.chunk" title="torch.chunk"><code>torch.chunk()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.clamp#torch.Tensor.clamp" title="torch.Tensor.clamp"><code>Tensor.clamp</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.clamp#torch.clamp" title="torch.clamp"><code>torch.clamp()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.clamp_#torch.Tensor.clamp_" title="torch.Tensor.clamp_"><code>Tensor.clamp_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.clamp#torch.Tensor.clamp" title="torch.Tensor.clamp"><code>clamp()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.clip#torch.Tensor.clip" title="torch.Tensor.clip"><code>Tensor.clip</code></a></p></td> <td><p>Alias for <a class="reference internal" href="generated/torch.tensor.clamp#torch.Tensor.clamp" title="torch.Tensor.clamp"><code>clamp()</code></a>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.clip_#torch.Tensor.clip_" title="torch.Tensor.clip_"><code>Tensor.clip_</code></a></p></td> <td><p>Alias for <a class="reference internal" href="generated/torch.tensor.clamp_#torch.Tensor.clamp_" title="torch.Tensor.clamp_"><code>clamp_()</code></a>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.clone#torch.Tensor.clone" title="torch.Tensor.clone"><code>Tensor.clone</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.clone#torch.clone" title="torch.clone"><code>torch.clone()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.contiguous#torch.Tensor.contiguous" title="torch.Tensor.contiguous"><code>Tensor.contiguous</code></a></p></td> <td><p>Returns a contiguous in memory tensor containing the same data as <code>self</code> tensor.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.copy_#torch.Tensor.copy_" title="torch.Tensor.copy_"><code>Tensor.copy_</code></a></p></td> <td><p>Copies the elements from <code>src</code> into <code>self</code> tensor and returns <code>self</code>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.conj#torch.Tensor.conj" title="torch.Tensor.conj"><code>Tensor.conj</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.conj#torch.conj" title="torch.conj"><code>torch.conj()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.conj_physical#torch.Tensor.conj_physical" title="torch.Tensor.conj_physical"><code>Tensor.conj_physical</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.conj_physical#torch.conj_physical" title="torch.conj_physical"><code>torch.conj_physical()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.conj_physical_#torch.Tensor.conj_physical_" title="torch.Tensor.conj_physical_"><code>Tensor.conj_physical_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.conj_physical#torch.Tensor.conj_physical" title="torch.Tensor.conj_physical"><code>conj_physical()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.resolve_conj#torch.Tensor.resolve_conj" title="torch.Tensor.resolve_conj"><code>Tensor.resolve_conj</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.resolve_conj#torch.resolve_conj" title="torch.resolve_conj"><code>torch.resolve_conj()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.resolve_neg#torch.Tensor.resolve_neg" title="torch.Tensor.resolve_neg"><code>Tensor.resolve_neg</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.resolve_neg#torch.resolve_neg" title="torch.resolve_neg"><code>torch.resolve_neg()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.copysign#torch.Tensor.copysign" title="torch.Tensor.copysign"><code>Tensor.copysign</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.copysign#torch.copysign" title="torch.copysign"><code>torch.copysign()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.copysign_#torch.Tensor.copysign_" title="torch.Tensor.copysign_"><code>Tensor.copysign_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.copysign#torch.Tensor.copysign" title="torch.Tensor.copysign"><code>copysign()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.cos#torch.Tensor.cos" title="torch.Tensor.cos"><code>Tensor.cos</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.cos#torch.cos" title="torch.cos"><code>torch.cos()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.cos_#torch.Tensor.cos_" title="torch.Tensor.cos_"><code>Tensor.cos_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.cos#torch.Tensor.cos" title="torch.Tensor.cos"><code>cos()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.cosh#torch.Tensor.cosh" title="torch.Tensor.cosh"><code>Tensor.cosh</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.cosh#torch.cosh" title="torch.cosh"><code>torch.cosh()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.cosh_#torch.Tensor.cosh_" title="torch.Tensor.cosh_"><code>Tensor.cosh_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.cosh#torch.Tensor.cosh" title="torch.Tensor.cosh"><code>cosh()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.corrcoef#torch.Tensor.corrcoef" title="torch.Tensor.corrcoef"><code>Tensor.corrcoef</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.corrcoef#torch.corrcoef" title="torch.corrcoef"><code>torch.corrcoef()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.count_nonzero#torch.Tensor.count_nonzero" title="torch.Tensor.count_nonzero"><code>Tensor.count_nonzero</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.count_nonzero#torch.count_nonzero" title="torch.count_nonzero"><code>torch.count_nonzero()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.cov#torch.Tensor.cov" title="torch.Tensor.cov"><code>Tensor.cov</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.cov#torch.cov" title="torch.cov"><code>torch.cov()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.acosh#torch.Tensor.acosh" title="torch.Tensor.acosh"><code>Tensor.acosh</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.acosh#torch.acosh" title="torch.acosh"><code>torch.acosh()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.acosh_#torch.Tensor.acosh_" title="torch.Tensor.acosh_"><code>Tensor.acosh_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.acosh#torch.Tensor.acosh" title="torch.Tensor.acosh"><code>acosh()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.arccosh#torch.Tensor.arccosh" title="torch.Tensor.arccosh"><code>Tensor.arccosh</code></a></p></td> <td><p>acosh() -&gt; Tensor</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.arccosh_#torch.Tensor.arccosh_" title="torch.Tensor.arccosh_"><code>Tensor.arccosh_</code></a></p></td> <td><p>acosh_() -&gt; Tensor</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.cpu#torch.Tensor.cpu" title="torch.Tensor.cpu"><code>Tensor.cpu</code></a></p></td> <td><p>Returns a copy of this object in CPU memory.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.cross#torch.Tensor.cross" title="torch.Tensor.cross"><code>Tensor.cross</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.cross#torch.cross" title="torch.cross"><code>torch.cross()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.cuda#torch.Tensor.cuda" title="torch.Tensor.cuda"><code>Tensor.cuda</code></a></p></td> <td><p>Returns a copy of this object in CUDA memory.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.logcumsumexp#torch.Tensor.logcumsumexp" title="torch.Tensor.logcumsumexp"><code>Tensor.logcumsumexp</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.logcumsumexp#torch.logcumsumexp" title="torch.logcumsumexp"><code>torch.logcumsumexp()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.cummax#torch.Tensor.cummax" title="torch.Tensor.cummax"><code>Tensor.cummax</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.cummax#torch.cummax" title="torch.cummax"><code>torch.cummax()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.cummin#torch.Tensor.cummin" title="torch.Tensor.cummin"><code>Tensor.cummin</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.cummin#torch.cummin" title="torch.cummin"><code>torch.cummin()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.cumprod#torch.Tensor.cumprod" title="torch.Tensor.cumprod"><code>Tensor.cumprod</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.cumprod#torch.cumprod" title="torch.cumprod"><code>torch.cumprod()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.cumprod_#torch.Tensor.cumprod_" title="torch.Tensor.cumprod_"><code>Tensor.cumprod_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.cumprod#torch.Tensor.cumprod" title="torch.Tensor.cumprod"><code>cumprod()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.cumsum#torch.Tensor.cumsum" title="torch.Tensor.cumsum"><code>Tensor.cumsum</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.cumsum#torch.cumsum" title="torch.cumsum"><code>torch.cumsum()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.cumsum_#torch.Tensor.cumsum_" title="torch.Tensor.cumsum_"><code>Tensor.cumsum_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.cumsum#torch.Tensor.cumsum" title="torch.Tensor.cumsum"><code>cumsum()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.chalf#torch.Tensor.chalf" title="torch.Tensor.chalf"><code>Tensor.chalf</code></a></p></td> <td><p><code>self.chalf()</code> is equivalent to <code>self.to(torch.complex32)</code>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.cfloat#torch.Tensor.cfloat" title="torch.Tensor.cfloat"><code>Tensor.cfloat</code></a></p></td> <td><p><code>self.cfloat()</code> is equivalent to <code>self.to(torch.complex64)</code>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.cdouble#torch.Tensor.cdouble" title="torch.Tensor.cdouble"><code>Tensor.cdouble</code></a></p></td> <td><p><code>self.cdouble()</code> is equivalent to <code>self.to(torch.complex128)</code>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.data_ptr#torch.Tensor.data_ptr" title="torch.Tensor.data_ptr"><code>Tensor.data_ptr</code></a></p></td> <td><p>Returns the address of the first element of <code>self</code> tensor.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.deg2rad#torch.Tensor.deg2rad" title="torch.Tensor.deg2rad"><code>Tensor.deg2rad</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.deg2rad#torch.deg2rad" title="torch.deg2rad"><code>torch.deg2rad()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.dequantize#torch.Tensor.dequantize" title="torch.Tensor.dequantize"><code>Tensor.dequantize</code></a></p></td> <td><p>Given a quantized Tensor, dequantize it and return the dequantized float Tensor.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.det#torch.Tensor.det" title="torch.Tensor.det"><code>Tensor.det</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.det#torch.det" title="torch.det"><code>torch.det()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.dense_dim#torch.Tensor.dense_dim" title="torch.Tensor.dense_dim"><code>Tensor.dense_dim</code></a></p></td> <td><p>Return the number of dense dimensions in a <a class="reference internal" href="sparse#sparse-docs"><span class="std std-ref">sparse tensor</span></a> <code>self</code>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.detach#torch.Tensor.detach" title="torch.Tensor.detach"><code>Tensor.detach</code></a></p></td> <td><p>Returns a new Tensor, detached from the current graph.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.detach_#torch.Tensor.detach_" title="torch.Tensor.detach_"><code>Tensor.detach_</code></a></p></td> <td><p>Detaches the Tensor from the graph that created it, making it a leaf.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.diag#torch.Tensor.diag" title="torch.Tensor.diag"><code>Tensor.diag</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.diag#torch.diag" title="torch.diag"><code>torch.diag()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.diag_embed#torch.Tensor.diag_embed" title="torch.Tensor.diag_embed"><code>Tensor.diag_embed</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.diag_embed#torch.diag_embed" title="torch.diag_embed"><code>torch.diag_embed()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.diagflat#torch.Tensor.diagflat" title="torch.Tensor.diagflat"><code>Tensor.diagflat</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.diagflat#torch.diagflat" title="torch.diagflat"><code>torch.diagflat()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.diagonal#torch.Tensor.diagonal" title="torch.Tensor.diagonal"><code>Tensor.diagonal</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.diagonal#torch.diagonal" title="torch.diagonal"><code>torch.diagonal()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.diagonal_scatter#torch.Tensor.diagonal_scatter" title="torch.Tensor.diagonal_scatter"><code>Tensor.diagonal_scatter</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.diagonal_scatter#torch.diagonal_scatter" title="torch.diagonal_scatter"><code>torch.diagonal_scatter()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.fill_diagonal_#torch.Tensor.fill_diagonal_" title="torch.Tensor.fill_diagonal_"><code>Tensor.fill_diagonal_</code></a></p></td> <td><p>Fill the main diagonal of a tensor that has at least 2-dimensions.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.fmax#torch.Tensor.fmax" title="torch.Tensor.fmax"><code>Tensor.fmax</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.fmax#torch.fmax" title="torch.fmax"><code>torch.fmax()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.fmin#torch.Tensor.fmin" title="torch.Tensor.fmin"><code>Tensor.fmin</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.fmin#torch.fmin" title="torch.fmin"><code>torch.fmin()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.diff#torch.Tensor.diff" title="torch.Tensor.diff"><code>Tensor.diff</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.diff#torch.diff" title="torch.diff"><code>torch.diff()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.digamma#torch.Tensor.digamma" title="torch.Tensor.digamma"><code>Tensor.digamma</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.digamma#torch.digamma" title="torch.digamma"><code>torch.digamma()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.digamma_#torch.Tensor.digamma_" title="torch.Tensor.digamma_"><code>Tensor.digamma_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.digamma#torch.Tensor.digamma" title="torch.Tensor.digamma"><code>digamma()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.dim#torch.Tensor.dim" title="torch.Tensor.dim"><code>Tensor.dim</code></a></p></td> <td><p>Returns the number of dimensions of <code>self</code> tensor.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.dim_order#torch.Tensor.dim_order" title="torch.Tensor.dim_order"><code>Tensor.dim_order</code></a></p></td> <td><p>Returns a tuple of int describing the dim order or physical layout of <code>self</code>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.dist#torch.Tensor.dist" title="torch.Tensor.dist"><code>Tensor.dist</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.dist#torch.dist" title="torch.dist"><code>torch.dist()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.div#torch.Tensor.div" title="torch.Tensor.div"><code>Tensor.div</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.div#torch.div" title="torch.div"><code>torch.div()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.div_#torch.Tensor.div_" title="torch.Tensor.div_"><code>Tensor.div_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.div#torch.Tensor.div" title="torch.Tensor.div"><code>div()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.divide#torch.Tensor.divide" title="torch.Tensor.divide"><code>Tensor.divide</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.divide#torch.divide" title="torch.divide"><code>torch.divide()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.divide_#torch.Tensor.divide_" title="torch.Tensor.divide_"><code>Tensor.divide_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.divide#torch.Tensor.divide" title="torch.Tensor.divide"><code>divide()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.dot#torch.Tensor.dot" title="torch.Tensor.dot"><code>Tensor.dot</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.dot#torch.dot" title="torch.dot"><code>torch.dot()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.double#torch.Tensor.double" title="torch.Tensor.double"><code>Tensor.double</code></a></p></td> <td><p><code>self.double()</code> is equivalent to <code>self.to(torch.float64)</code>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.dsplit#torch.Tensor.dsplit" title="torch.Tensor.dsplit"><code>Tensor.dsplit</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.dsplit#torch.dsplit" title="torch.dsplit"><code>torch.dsplit()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.element_size#torch.Tensor.element_size" title="torch.Tensor.element_size"><code>Tensor.element_size</code></a></p></td> <td><p>Returns the size in bytes of an individual element.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.eq#torch.Tensor.eq" title="torch.Tensor.eq"><code>Tensor.eq</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.eq#torch.eq" title="torch.eq"><code>torch.eq()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.eq_#torch.Tensor.eq_" title="torch.Tensor.eq_"><code>Tensor.eq_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.eq#torch.Tensor.eq" title="torch.Tensor.eq"><code>eq()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.equal#torch.Tensor.equal" title="torch.Tensor.equal"><code>Tensor.equal</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.equal#torch.equal" title="torch.equal"><code>torch.equal()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.erf#torch.Tensor.erf" title="torch.Tensor.erf"><code>Tensor.erf</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.erf#torch.erf" title="torch.erf"><code>torch.erf()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.erf_#torch.Tensor.erf_" title="torch.Tensor.erf_"><code>Tensor.erf_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.erf#torch.Tensor.erf" title="torch.Tensor.erf"><code>erf()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.erfc#torch.Tensor.erfc" title="torch.Tensor.erfc"><code>Tensor.erfc</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.erfc#torch.erfc" title="torch.erfc"><code>torch.erfc()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.erfc_#torch.Tensor.erfc_" title="torch.Tensor.erfc_"><code>Tensor.erfc_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.erfc#torch.Tensor.erfc" title="torch.Tensor.erfc"><code>erfc()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.erfinv#torch.Tensor.erfinv" title="torch.Tensor.erfinv"><code>Tensor.erfinv</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.erfinv#torch.erfinv" title="torch.erfinv"><code>torch.erfinv()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.erfinv_#torch.Tensor.erfinv_" title="torch.Tensor.erfinv_"><code>Tensor.erfinv_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.erfinv#torch.Tensor.erfinv" title="torch.Tensor.erfinv"><code>erfinv()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.exp#torch.Tensor.exp" title="torch.Tensor.exp"><code>Tensor.exp</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.exp#torch.exp" title="torch.exp"><code>torch.exp()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.exp_#torch.Tensor.exp_" title="torch.Tensor.exp_"><code>Tensor.exp_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.exp#torch.Tensor.exp" title="torch.Tensor.exp"><code>exp()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.expm1#torch.Tensor.expm1" title="torch.Tensor.expm1"><code>Tensor.expm1</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.expm1#torch.expm1" title="torch.expm1"><code>torch.expm1()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.expm1_#torch.Tensor.expm1_" title="torch.Tensor.expm1_"><code>Tensor.expm1_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.expm1#torch.Tensor.expm1" title="torch.Tensor.expm1"><code>expm1()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.expand#torch.Tensor.expand" title="torch.Tensor.expand"><code>Tensor.expand</code></a></p></td> <td><p>Returns a new view of the <code>self</code> tensor with singleton dimensions expanded to a larger size.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.expand_as#torch.Tensor.expand_as" title="torch.Tensor.expand_as"><code>Tensor.expand_as</code></a></p></td> <td><p>Expand this tensor to the same size as <code>other</code>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.exponential_#torch.Tensor.exponential_" title="torch.Tensor.exponential_"><code>Tensor.exponential_</code></a></p></td> <td><p>Fills <code>self</code> tensor with elements drawn from the exponential distribution:</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.fix#torch.Tensor.fix" title="torch.Tensor.fix"><code>Tensor.fix</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.fix#torch.fix" title="torch.fix"><code>torch.fix()</code></a>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.fix_#torch.Tensor.fix_" title="torch.Tensor.fix_"><code>Tensor.fix_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.fix#torch.Tensor.fix" title="torch.Tensor.fix"><code>fix()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.fill_#torch.Tensor.fill_" title="torch.Tensor.fill_"><code>Tensor.fill_</code></a></p></td> <td><p>Fills <code>self</code> tensor with the specified value.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.flatten#torch.Tensor.flatten" title="torch.Tensor.flatten"><code>Tensor.flatten</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.flatten#torch.flatten" title="torch.flatten"><code>torch.flatten()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.flip#torch.Tensor.flip" title="torch.Tensor.flip"><code>Tensor.flip</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.flip#torch.flip" title="torch.flip"><code>torch.flip()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.fliplr#torch.Tensor.fliplr" title="torch.Tensor.fliplr"><code>Tensor.fliplr</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.fliplr#torch.fliplr" title="torch.fliplr"><code>torch.fliplr()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.flipud#torch.Tensor.flipud" title="torch.Tensor.flipud"><code>Tensor.flipud</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.flipud#torch.flipud" title="torch.flipud"><code>torch.flipud()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.float#torch.Tensor.float" title="torch.Tensor.float"><code>Tensor.float</code></a></p></td> <td><p><code>self.float()</code> is equivalent to <code>self.to(torch.float32)</code>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.float_power#torch.Tensor.float_power" title="torch.Tensor.float_power"><code>Tensor.float_power</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.float_power#torch.float_power" title="torch.float_power"><code>torch.float_power()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.float_power_#torch.Tensor.float_power_" title="torch.Tensor.float_power_"><code>Tensor.float_power_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.float_power#torch.Tensor.float_power" title="torch.Tensor.float_power"><code>float_power()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.floor#torch.Tensor.floor" title="torch.Tensor.floor"><code>Tensor.floor</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.floor#torch.floor" title="torch.floor"><code>torch.floor()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.floor_#torch.Tensor.floor_" title="torch.Tensor.floor_"><code>Tensor.floor_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.floor#torch.Tensor.floor" title="torch.Tensor.floor"><code>floor()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.floor_divide#torch.Tensor.floor_divide" title="torch.Tensor.floor_divide"><code>Tensor.floor_divide</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.floor_divide#torch.floor_divide" title="torch.floor_divide"><code>torch.floor_divide()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.floor_divide_#torch.Tensor.floor_divide_" title="torch.Tensor.floor_divide_"><code>Tensor.floor_divide_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.floor_divide#torch.Tensor.floor_divide" title="torch.Tensor.floor_divide"><code>floor_divide()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.fmod#torch.Tensor.fmod" title="torch.Tensor.fmod"><code>Tensor.fmod</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.fmod#torch.fmod" title="torch.fmod"><code>torch.fmod()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.fmod_#torch.Tensor.fmod_" title="torch.Tensor.fmod_"><code>Tensor.fmod_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.fmod#torch.Tensor.fmod" title="torch.Tensor.fmod"><code>fmod()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.frac#torch.Tensor.frac" title="torch.Tensor.frac"><code>Tensor.frac</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.frac#torch.frac" title="torch.frac"><code>torch.frac()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.frac_#torch.Tensor.frac_" title="torch.Tensor.frac_"><code>Tensor.frac_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.frac#torch.Tensor.frac" title="torch.Tensor.frac"><code>frac()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.frexp#torch.Tensor.frexp" title="torch.Tensor.frexp"><code>Tensor.frexp</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.frexp#torch.frexp" title="torch.frexp"><code>torch.frexp()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.gather#torch.Tensor.gather" title="torch.Tensor.gather"><code>Tensor.gather</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.gather#torch.gather" title="torch.gather"><code>torch.gather()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.gcd#torch.Tensor.gcd" title="torch.Tensor.gcd"><code>Tensor.gcd</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.gcd#torch.gcd" title="torch.gcd"><code>torch.gcd()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.gcd_#torch.Tensor.gcd_" title="torch.Tensor.gcd_"><code>Tensor.gcd_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.gcd#torch.Tensor.gcd" title="torch.Tensor.gcd"><code>gcd()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.ge#torch.Tensor.ge" title="torch.Tensor.ge"><code>Tensor.ge</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.ge#torch.ge" title="torch.ge"><code>torch.ge()</code></a>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.ge_#torch.Tensor.ge_" title="torch.Tensor.ge_"><code>Tensor.ge_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.ge#torch.Tensor.ge" title="torch.Tensor.ge"><code>ge()</code></a>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.greater_equal#torch.Tensor.greater_equal" title="torch.Tensor.greater_equal"><code>Tensor.greater_equal</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.greater_equal#torch.greater_equal" title="torch.greater_equal"><code>torch.greater_equal()</code></a>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.greater_equal_#torch.Tensor.greater_equal_" title="torch.Tensor.greater_equal_"><code>Tensor.greater_equal_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.greater_equal#torch.Tensor.greater_equal" title="torch.Tensor.greater_equal"><code>greater_equal()</code></a>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.geometric_#torch.Tensor.geometric_" title="torch.Tensor.geometric_"><code>Tensor.geometric_</code></a></p></td> <td><p>Fills <code>self</code> tensor with elements drawn from the geometric distribution:</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.geqrf#torch.Tensor.geqrf" title="torch.Tensor.geqrf"><code>Tensor.geqrf</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.geqrf#torch.geqrf" title="torch.geqrf"><code>torch.geqrf()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.ger#torch.Tensor.ger" title="torch.Tensor.ger"><code>Tensor.ger</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.ger#torch.ger" title="torch.ger"><code>torch.ger()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.get_device#torch.Tensor.get_device" title="torch.Tensor.get_device"><code>Tensor.get_device</code></a></p></td> <td><p>For CUDA tensors, this function returns the device ordinal of the GPU on which the tensor resides.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.gt#torch.Tensor.gt" title="torch.Tensor.gt"><code>Tensor.gt</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.gt#torch.gt" title="torch.gt"><code>torch.gt()</code></a>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.gt_#torch.Tensor.gt_" title="torch.Tensor.gt_"><code>Tensor.gt_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.gt#torch.Tensor.gt" title="torch.Tensor.gt"><code>gt()</code></a>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.greater#torch.Tensor.greater" title="torch.Tensor.greater"><code>Tensor.greater</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.greater#torch.greater" title="torch.greater"><code>torch.greater()</code></a>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.greater_#torch.Tensor.greater_" title="torch.Tensor.greater_"><code>Tensor.greater_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.greater#torch.Tensor.greater" title="torch.Tensor.greater"><code>greater()</code></a>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.half#torch.Tensor.half" title="torch.Tensor.half"><code>Tensor.half</code></a></p></td> <td><p><code>self.half()</code> is equivalent to <code>self.to(torch.float16)</code>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.hardshrink#torch.Tensor.hardshrink" title="torch.Tensor.hardshrink"><code>Tensor.hardshrink</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.nn.functional.hardshrink#torch.nn.functional.hardshrink" title="torch.nn.functional.hardshrink"><code>torch.nn.functional.hardshrink()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.heaviside#torch.Tensor.heaviside" title="torch.Tensor.heaviside"><code>Tensor.heaviside</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.heaviside#torch.heaviside" title="torch.heaviside"><code>torch.heaviside()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.histc#torch.Tensor.histc" title="torch.Tensor.histc"><code>Tensor.histc</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.histc#torch.histc" title="torch.histc"><code>torch.histc()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.histogram#torch.Tensor.histogram" title="torch.Tensor.histogram"><code>Tensor.histogram</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.histogram#torch.histogram" title="torch.histogram"><code>torch.histogram()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.hsplit#torch.Tensor.hsplit" title="torch.Tensor.hsplit"><code>Tensor.hsplit</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.hsplit#torch.hsplit" title="torch.hsplit"><code>torch.hsplit()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.hypot#torch.Tensor.hypot" title="torch.Tensor.hypot"><code>Tensor.hypot</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.hypot#torch.hypot" title="torch.hypot"><code>torch.hypot()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.hypot_#torch.Tensor.hypot_" title="torch.Tensor.hypot_"><code>Tensor.hypot_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.hypot#torch.Tensor.hypot" title="torch.Tensor.hypot"><code>hypot()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.i0#torch.Tensor.i0" title="torch.Tensor.i0"><code>Tensor.i0</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.i0#torch.i0" title="torch.i0"><code>torch.i0()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.i0_#torch.Tensor.i0_" title="torch.Tensor.i0_"><code>Tensor.i0_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.i0#torch.Tensor.i0" title="torch.Tensor.i0"><code>i0()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.igamma#torch.Tensor.igamma" title="torch.Tensor.igamma"><code>Tensor.igamma</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.igamma#torch.igamma" title="torch.igamma"><code>torch.igamma()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.igamma_#torch.Tensor.igamma_" title="torch.Tensor.igamma_"><code>Tensor.igamma_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.igamma#torch.Tensor.igamma" title="torch.Tensor.igamma"><code>igamma()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.igammac#torch.Tensor.igammac" title="torch.Tensor.igammac"><code>Tensor.igammac</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.igammac#torch.igammac" title="torch.igammac"><code>torch.igammac()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.igammac_#torch.Tensor.igammac_" title="torch.Tensor.igammac_"><code>Tensor.igammac_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.igammac#torch.Tensor.igammac" title="torch.Tensor.igammac"><code>igammac()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.index_add_#torch.Tensor.index_add_" title="torch.Tensor.index_add_"><code>Tensor.index_add_</code></a></p></td> <td><p>Accumulate the elements of <code>alpha</code> times <code>source</code> into the <code>self</code> tensor by adding to the indices in the order given in <code>index</code>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.index_add#torch.Tensor.index_add" title="torch.Tensor.index_add"><code>Tensor.index_add</code></a></p></td> <td><p>Out-of-place version of <a class="reference internal" href="generated/torch.tensor.index_add_#torch.Tensor.index_add_" title="torch.Tensor.index_add_"><code>torch.Tensor.index_add_()</code></a>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.index_copy_#torch.Tensor.index_copy_" title="torch.Tensor.index_copy_"><code>Tensor.index_copy_</code></a></p></td> <td><p>Copies the elements of <a class="reference internal" href="generated/torch.tensor#torch.tensor" title="torch.tensor"><code>tensor</code></a> into the <code>self</code> tensor by selecting the indices in the order given in <code>index</code>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.index_copy#torch.Tensor.index_copy" title="torch.Tensor.index_copy"><code>Tensor.index_copy</code></a></p></td> <td><p>Out-of-place version of <a class="reference internal" href="generated/torch.tensor.index_copy_#torch.Tensor.index_copy_" title="torch.Tensor.index_copy_"><code>torch.Tensor.index_copy_()</code></a>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.index_fill_#torch.Tensor.index_fill_" title="torch.Tensor.index_fill_"><code>Tensor.index_fill_</code></a></p></td> <td><p>Fills the elements of the <code>self</code> tensor with value <code>value</code> by selecting the indices in the order given in <code>index</code>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.index_fill#torch.Tensor.index_fill" title="torch.Tensor.index_fill"><code>Tensor.index_fill</code></a></p></td> <td><p>Out-of-place version of <a class="reference internal" href="generated/torch.tensor.index_fill_#torch.Tensor.index_fill_" title="torch.Tensor.index_fill_"><code>torch.Tensor.index_fill_()</code></a>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.index_put_#torch.Tensor.index_put_" title="torch.Tensor.index_put_"><code>Tensor.index_put_</code></a></p></td> <td><p>Puts values from the tensor <code>values</code> into the tensor <code>self</code> using the indices specified in <code>indices</code> (which is a tuple of Tensors).</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.index_put#torch.Tensor.index_put" title="torch.Tensor.index_put"><code>Tensor.index_put</code></a></p></td> <td><p>Out-place version of <a class="reference internal" href="generated/torch.tensor.index_put_#torch.Tensor.index_put_" title="torch.Tensor.index_put_"><code>index_put_()</code></a>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.index_reduce_#torch.Tensor.index_reduce_" title="torch.Tensor.index_reduce_"><code>Tensor.index_reduce_</code></a></p></td> <td><p>Accumulate the elements of <code>source</code> into the <code>self</code> tensor by accumulating to the indices in the order given in <code>index</code> using the reduction given by the <code>reduce</code> argument.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.index_reduce#torch.Tensor.index_reduce" title="torch.Tensor.index_reduce"><code>Tensor.index_reduce</code></a></p></td> <td></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.index_select#torch.Tensor.index_select" title="torch.Tensor.index_select"><code>Tensor.index_select</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.index_select#torch.index_select" title="torch.index_select"><code>torch.index_select()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.indices#torch.Tensor.indices" title="torch.Tensor.indices"><code>Tensor.indices</code></a></p></td> <td><p>Return the indices tensor of a <a class="reference internal" href="sparse#sparse-coo-docs"><span class="std std-ref">sparse COO tensor</span></a>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.inner#torch.Tensor.inner" title="torch.Tensor.inner"><code>Tensor.inner</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.inner#torch.inner" title="torch.inner"><code>torch.inner()</code></a>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.int#torch.Tensor.int" title="torch.Tensor.int"><code>Tensor.int</code></a></p></td> <td><p><code>self.int()</code> is equivalent to <code>self.to(torch.int32)</code>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.int_repr#torch.Tensor.int_repr" title="torch.Tensor.int_repr"><code>Tensor.int_repr</code></a></p></td> <td><p>Given a quantized Tensor, <code>self.int_repr()</code> returns a CPU Tensor with uint8_t as data type that stores the underlying uint8_t values of the given Tensor.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.inverse#torch.Tensor.inverse" title="torch.Tensor.inverse"><code>Tensor.inverse</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.inverse#torch.inverse" title="torch.inverse"><code>torch.inverse()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.isclose#torch.Tensor.isclose" title="torch.Tensor.isclose"><code>Tensor.isclose</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.isclose#torch.isclose" title="torch.isclose"><code>torch.isclose()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.isfinite#torch.Tensor.isfinite" title="torch.Tensor.isfinite"><code>Tensor.isfinite</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.isfinite#torch.isfinite" title="torch.isfinite"><code>torch.isfinite()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.isinf#torch.Tensor.isinf" title="torch.Tensor.isinf"><code>Tensor.isinf</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.isinf#torch.isinf" title="torch.isinf"><code>torch.isinf()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.isposinf#torch.Tensor.isposinf" title="torch.Tensor.isposinf"><code>Tensor.isposinf</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.isposinf#torch.isposinf" title="torch.isposinf"><code>torch.isposinf()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.isneginf#torch.Tensor.isneginf" title="torch.Tensor.isneginf"><code>Tensor.isneginf</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.isneginf#torch.isneginf" title="torch.isneginf"><code>torch.isneginf()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.isnan#torch.Tensor.isnan" title="torch.Tensor.isnan"><code>Tensor.isnan</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.isnan#torch.isnan" title="torch.isnan"><code>torch.isnan()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.is_contiguous#torch.Tensor.is_contiguous" title="torch.Tensor.is_contiguous"><code>Tensor.is_contiguous</code></a></p></td> <td><p>Returns True if <code>self</code> tensor is contiguous in memory in the order specified by memory format.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.is_complex#torch.Tensor.is_complex" title="torch.Tensor.is_complex"><code>Tensor.is_complex</code></a></p></td> <td><p>Returns True if the data type of <code>self</code> is a complex data type.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.is_conj#torch.Tensor.is_conj" title="torch.Tensor.is_conj"><code>Tensor.is_conj</code></a></p></td> <td><p>Returns True if the conjugate bit of <code>self</code> is set to true.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.is_floating_point#torch.Tensor.is_floating_point" title="torch.Tensor.is_floating_point"><code>Tensor.is_floating_point</code></a></p></td> <td><p>Returns True if the data type of <code>self</code> is a floating point data type.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.is_inference#torch.Tensor.is_inference" title="torch.Tensor.is_inference"><code>Tensor.is_inference</code></a></p></td> <td><p>See <code>torch.is_inference()</code></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.is_leaf#torch.Tensor.is_leaf" title="torch.Tensor.is_leaf"><code>Tensor.is_leaf</code></a></p></td> <td><p>All Tensors that have <code>requires_grad</code> which is <code>False</code> will be leaf Tensors by convention.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.is_pinned#torch.Tensor.is_pinned" title="torch.Tensor.is_pinned"><code>Tensor.is_pinned</code></a></p></td> <td><p>Returns true if this tensor resides in pinned memory.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.is_set_to#torch.Tensor.is_set_to" title="torch.Tensor.is_set_to"><code>Tensor.is_set_to</code></a></p></td> <td><p>Returns True if both tensors are pointing to the exact same memory (same storage, offset, size and stride).</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.is_shared#torch.Tensor.is_shared" title="torch.Tensor.is_shared"><code>Tensor.is_shared</code></a></p></td> <td><p>Checks if tensor is in shared memory.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.is_signed#torch.Tensor.is_signed" title="torch.Tensor.is_signed"><code>Tensor.is_signed</code></a></p></td> <td><p>Returns True if the data type of <code>self</code> is a signed data type.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.is_sparse#torch.Tensor.is_sparse" title="torch.Tensor.is_sparse"><code>Tensor.is_sparse</code></a></p></td> <td><p>Is <code>True</code> if the Tensor uses sparse COO storage layout, <code>False</code> otherwise.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.istft#torch.Tensor.istft" title="torch.Tensor.istft"><code>Tensor.istft</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.istft#torch.istft" title="torch.istft"><code>torch.istft()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.isreal#torch.Tensor.isreal" title="torch.Tensor.isreal"><code>Tensor.isreal</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.isreal#torch.isreal" title="torch.isreal"><code>torch.isreal()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.item#torch.Tensor.item" title="torch.Tensor.item"><code>Tensor.item</code></a></p></td> <td><p>Returns the value of this tensor as a standard Python number.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.kthvalue#torch.Tensor.kthvalue" title="torch.Tensor.kthvalue"><code>Tensor.kthvalue</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.kthvalue#torch.kthvalue" title="torch.kthvalue"><code>torch.kthvalue()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.lcm#torch.Tensor.lcm" title="torch.Tensor.lcm"><code>Tensor.lcm</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.lcm#torch.lcm" title="torch.lcm"><code>torch.lcm()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.lcm_#torch.Tensor.lcm_" title="torch.Tensor.lcm_"><code>Tensor.lcm_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.lcm#torch.Tensor.lcm" title="torch.Tensor.lcm"><code>lcm()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.ldexp#torch.Tensor.ldexp" title="torch.Tensor.ldexp"><code>Tensor.ldexp</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.ldexp#torch.ldexp" title="torch.ldexp"><code>torch.ldexp()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.ldexp_#torch.Tensor.ldexp_" title="torch.Tensor.ldexp_"><code>Tensor.ldexp_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.ldexp#torch.Tensor.ldexp" title="torch.Tensor.ldexp"><code>ldexp()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.le#torch.Tensor.le" title="torch.Tensor.le"><code>Tensor.le</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.le#torch.le" title="torch.le"><code>torch.le()</code></a>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.le_#torch.Tensor.le_" title="torch.Tensor.le_"><code>Tensor.le_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.le#torch.Tensor.le" title="torch.Tensor.le"><code>le()</code></a>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.less_equal#torch.Tensor.less_equal" title="torch.Tensor.less_equal"><code>Tensor.less_equal</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.less_equal#torch.less_equal" title="torch.less_equal"><code>torch.less_equal()</code></a>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.less_equal_#torch.Tensor.less_equal_" title="torch.Tensor.less_equal_"><code>Tensor.less_equal_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.less_equal#torch.Tensor.less_equal" title="torch.Tensor.less_equal"><code>less_equal()</code></a>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.lerp#torch.Tensor.lerp" title="torch.Tensor.lerp"><code>Tensor.lerp</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.lerp#torch.lerp" title="torch.lerp"><code>torch.lerp()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.lerp_#torch.Tensor.lerp_" title="torch.Tensor.lerp_"><code>Tensor.lerp_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.lerp#torch.Tensor.lerp" title="torch.Tensor.lerp"><code>lerp()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.lgamma#torch.Tensor.lgamma" title="torch.Tensor.lgamma"><code>Tensor.lgamma</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.lgamma#torch.lgamma" title="torch.lgamma"><code>torch.lgamma()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.lgamma_#torch.Tensor.lgamma_" title="torch.Tensor.lgamma_"><code>Tensor.lgamma_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.lgamma#torch.Tensor.lgamma" title="torch.Tensor.lgamma"><code>lgamma()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.log#torch.Tensor.log" title="torch.Tensor.log"><code>Tensor.log</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.log#torch.log" title="torch.log"><code>torch.log()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.log_#torch.Tensor.log_" title="torch.Tensor.log_"><code>Tensor.log_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.log#torch.Tensor.log" title="torch.Tensor.log"><code>log()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.logdet#torch.Tensor.logdet" title="torch.Tensor.logdet"><code>Tensor.logdet</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.logdet#torch.logdet" title="torch.logdet"><code>torch.logdet()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.log10#torch.Tensor.log10" title="torch.Tensor.log10"><code>Tensor.log10</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.log10#torch.log10" title="torch.log10"><code>torch.log10()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.log10_#torch.Tensor.log10_" title="torch.Tensor.log10_"><code>Tensor.log10_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.log10#torch.Tensor.log10" title="torch.Tensor.log10"><code>log10()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.log1p#torch.Tensor.log1p" title="torch.Tensor.log1p"><code>Tensor.log1p</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.log1p#torch.log1p" title="torch.log1p"><code>torch.log1p()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.log1p_#torch.Tensor.log1p_" title="torch.Tensor.log1p_"><code>Tensor.log1p_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.log1p#torch.Tensor.log1p" title="torch.Tensor.log1p"><code>log1p()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.log2#torch.Tensor.log2" title="torch.Tensor.log2"><code>Tensor.log2</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.log2#torch.log2" title="torch.log2"><code>torch.log2()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.log2_#torch.Tensor.log2_" title="torch.Tensor.log2_"><code>Tensor.log2_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.log2#torch.Tensor.log2" title="torch.Tensor.log2"><code>log2()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.log_normal_#torch.Tensor.log_normal_" title="torch.Tensor.log_normal_"><code>Tensor.log_normal_</code></a></p></td> <td><p>Fills <code>self</code> tensor with numbers samples from the log-normal distribution parameterized by the given mean <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>μ</mi></mrow><annotation encoding="application/x-tex">\mu</annotation></semantics></math></span></span></span> and standard deviation <span class="math"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>σ</mi></mrow><annotation encoding="application/x-tex">\sigma</annotation></semantics></math></span></span></span>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.logaddexp#torch.Tensor.logaddexp" title="torch.Tensor.logaddexp"><code>Tensor.logaddexp</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.logaddexp#torch.logaddexp" title="torch.logaddexp"><code>torch.logaddexp()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.logaddexp2#torch.Tensor.logaddexp2" title="torch.Tensor.logaddexp2"><code>Tensor.logaddexp2</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.logaddexp2#torch.logaddexp2" title="torch.logaddexp2"><code>torch.logaddexp2()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.logsumexp#torch.Tensor.logsumexp" title="torch.Tensor.logsumexp"><code>Tensor.logsumexp</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.logsumexp#torch.logsumexp" title="torch.logsumexp"><code>torch.logsumexp()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.logical_and#torch.Tensor.logical_and" title="torch.Tensor.logical_and"><code>Tensor.logical_and</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.logical_and#torch.logical_and" title="torch.logical_and"><code>torch.logical_and()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.logical_and_#torch.Tensor.logical_and_" title="torch.Tensor.logical_and_"><code>Tensor.logical_and_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.logical_and#torch.Tensor.logical_and" title="torch.Tensor.logical_and"><code>logical_and()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.logical_not#torch.Tensor.logical_not" title="torch.Tensor.logical_not"><code>Tensor.logical_not</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.logical_not#torch.logical_not" title="torch.logical_not"><code>torch.logical_not()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.logical_not_#torch.Tensor.logical_not_" title="torch.Tensor.logical_not_"><code>Tensor.logical_not_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.logical_not#torch.Tensor.logical_not" title="torch.Tensor.logical_not"><code>logical_not()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.logical_or#torch.Tensor.logical_or" title="torch.Tensor.logical_or"><code>Tensor.logical_or</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.logical_or#torch.logical_or" title="torch.logical_or"><code>torch.logical_or()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.logical_or_#torch.Tensor.logical_or_" title="torch.Tensor.logical_or_"><code>Tensor.logical_or_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.logical_or#torch.Tensor.logical_or" title="torch.Tensor.logical_or"><code>logical_or()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.logical_xor#torch.Tensor.logical_xor" title="torch.Tensor.logical_xor"><code>Tensor.logical_xor</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.logical_xor#torch.logical_xor" title="torch.logical_xor"><code>torch.logical_xor()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.logical_xor_#torch.Tensor.logical_xor_" title="torch.Tensor.logical_xor_"><code>Tensor.logical_xor_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.logical_xor#torch.Tensor.logical_xor" title="torch.Tensor.logical_xor"><code>logical_xor()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.logit#torch.Tensor.logit" title="torch.Tensor.logit"><code>Tensor.logit</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.logit#torch.logit" title="torch.logit"><code>torch.logit()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.logit_#torch.Tensor.logit_" title="torch.Tensor.logit_"><code>Tensor.logit_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.logit#torch.Tensor.logit" title="torch.Tensor.logit"><code>logit()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.long#torch.Tensor.long" title="torch.Tensor.long"><code>Tensor.long</code></a></p></td> <td><p><code>self.long()</code> is equivalent to <code>self.to(torch.int64)</code>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.lt#torch.Tensor.lt" title="torch.Tensor.lt"><code>Tensor.lt</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.lt#torch.lt" title="torch.lt"><code>torch.lt()</code></a>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.lt_#torch.Tensor.lt_" title="torch.Tensor.lt_"><code>Tensor.lt_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.lt#torch.Tensor.lt" title="torch.Tensor.lt"><code>lt()</code></a>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.less#torch.Tensor.less" title="torch.Tensor.less"><code>Tensor.less</code></a></p></td> <td><p>lt(other) -&gt; Tensor</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.less_#torch.Tensor.less_" title="torch.Tensor.less_"><code>Tensor.less_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.less#torch.Tensor.less" title="torch.Tensor.less"><code>less()</code></a>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.lu#torch.Tensor.lu" title="torch.Tensor.lu"><code>Tensor.lu</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.lu#torch.lu" title="torch.lu"><code>torch.lu()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.lu_solve#torch.Tensor.lu_solve" title="torch.Tensor.lu_solve"><code>Tensor.lu_solve</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.lu_solve#torch.lu_solve" title="torch.lu_solve"><code>torch.lu_solve()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.as_subclass#torch.Tensor.as_subclass" title="torch.Tensor.as_subclass"><code>Tensor.as_subclass</code></a></p></td> <td><p>Makes a <code>cls</code> instance with the same data pointer as <code>self</code>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.map_#torch.Tensor.map_" title="torch.Tensor.map_"><code>Tensor.map_</code></a></p></td> <td><p>Applies <code>callable</code> for each element in <code>self</code> tensor and the given <a class="reference internal" href="generated/torch.tensor#torch.tensor" title="torch.tensor"><code>tensor</code></a> and stores the results in <code>self</code> tensor.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.masked_scatter_#torch.Tensor.masked_scatter_" title="torch.Tensor.masked_scatter_"><code>Tensor.masked_scatter_</code></a></p></td> <td><p>Copies elements from <code>source</code> into <code>self</code> tensor at positions where the <code>mask</code> is True.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.masked_scatter#torch.Tensor.masked_scatter" title="torch.Tensor.masked_scatter"><code>Tensor.masked_scatter</code></a></p></td> <td><p>Out-of-place version of <a class="reference internal" href="generated/torch.tensor.masked_scatter_#torch.Tensor.masked_scatter_" title="torch.Tensor.masked_scatter_"><code>torch.Tensor.masked_scatter_()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.masked_fill_#torch.Tensor.masked_fill_" title="torch.Tensor.masked_fill_"><code>Tensor.masked_fill_</code></a></p></td> <td><p>Fills elements of <code>self</code> tensor with <code>value</code> where <code>mask</code> is True.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.masked_fill#torch.Tensor.masked_fill" title="torch.Tensor.masked_fill"><code>Tensor.masked_fill</code></a></p></td> <td><p>Out-of-place version of <a class="reference internal" href="generated/torch.tensor.masked_fill_#torch.Tensor.masked_fill_" title="torch.Tensor.masked_fill_"><code>torch.Tensor.masked_fill_()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.masked_select#torch.Tensor.masked_select" title="torch.Tensor.masked_select"><code>Tensor.masked_select</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.masked_select#torch.masked_select" title="torch.masked_select"><code>torch.masked_select()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.matmul#torch.Tensor.matmul" title="torch.Tensor.matmul"><code>Tensor.matmul</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.matmul#torch.matmul" title="torch.matmul"><code>torch.matmul()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.matrix_power#torch.Tensor.matrix_power" title="torch.Tensor.matrix_power"><code>Tensor.matrix_power</code></a></p></td> <td>

<div class="admonition note"> <p class="admonition-title">Note</p> <p><a class="reference internal" href="generated/torch.tensor.matrix_power#torch.Tensor.matrix_power" title="torch.Tensor.matrix_power"><code>matrix_power()</code></a> is deprecated, use <a class="reference internal" href="generated/torch.linalg.matrix_power#torch.linalg.matrix_power" title="torch.linalg.matrix_power"><code>torch.linalg.matrix_power()</code></a> instead.</p> </div> </td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.matrix_exp#torch.Tensor.matrix_exp" title="torch.Tensor.matrix_exp"><code>Tensor.matrix_exp</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.matrix_exp#torch.matrix_exp" title="torch.matrix_exp"><code>torch.matrix_exp()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.max#torch.Tensor.max" title="torch.Tensor.max"><code>Tensor.max</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.max#torch.max" title="torch.max"><code>torch.max()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.maximum#torch.Tensor.maximum" title="torch.Tensor.maximum"><code>Tensor.maximum</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.maximum#torch.maximum" title="torch.maximum"><code>torch.maximum()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.mean#torch.Tensor.mean" title="torch.Tensor.mean"><code>Tensor.mean</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.mean#torch.mean" title="torch.mean"><code>torch.mean()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.nanmean#torch.Tensor.nanmean" title="torch.Tensor.nanmean"><code>Tensor.nanmean</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.nanmean#torch.nanmean" title="torch.nanmean"><code>torch.nanmean()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.median#torch.Tensor.median" title="torch.Tensor.median"><code>Tensor.median</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.median#torch.median" title="torch.median"><code>torch.median()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.nanmedian#torch.Tensor.nanmedian" title="torch.Tensor.nanmedian"><code>Tensor.nanmedian</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.nanmedian#torch.nanmedian" title="torch.nanmedian"><code>torch.nanmedian()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.min#torch.Tensor.min" title="torch.Tensor.min"><code>Tensor.min</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.min#torch.min" title="torch.min"><code>torch.min()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.minimum#torch.Tensor.minimum" title="torch.Tensor.minimum"><code>Tensor.minimum</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.minimum#torch.minimum" title="torch.minimum"><code>torch.minimum()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.mm#torch.Tensor.mm" title="torch.Tensor.mm"><code>Tensor.mm</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.mm#torch.mm" title="torch.mm"><code>torch.mm()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.smm#torch.Tensor.smm" title="torch.Tensor.smm"><code>Tensor.smm</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.smm#torch.smm" title="torch.smm"><code>torch.smm()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.mode#torch.Tensor.mode" title="torch.Tensor.mode"><code>Tensor.mode</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.mode#torch.mode" title="torch.mode"><code>torch.mode()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.movedim#torch.Tensor.movedim" title="torch.Tensor.movedim"><code>Tensor.movedim</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.movedim#torch.movedim" title="torch.movedim"><code>torch.movedim()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.moveaxis#torch.Tensor.moveaxis" title="torch.Tensor.moveaxis"><code>Tensor.moveaxis</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.moveaxis#torch.moveaxis" title="torch.moveaxis"><code>torch.moveaxis()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.msort#torch.Tensor.msort" title="torch.Tensor.msort"><code>Tensor.msort</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.msort#torch.msort" title="torch.msort"><code>torch.msort()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.mul#torch.Tensor.mul" title="torch.Tensor.mul"><code>Tensor.mul</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.mul#torch.mul" title="torch.mul"><code>torch.mul()</code></a>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.mul_#torch.Tensor.mul_" title="torch.Tensor.mul_"><code>Tensor.mul_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.mul#torch.Tensor.mul" title="torch.Tensor.mul"><code>mul()</code></a>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.multiply#torch.Tensor.multiply" title="torch.Tensor.multiply"><code>Tensor.multiply</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.multiply#torch.multiply" title="torch.multiply"><code>torch.multiply()</code></a>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.multiply_#torch.Tensor.multiply_" title="torch.Tensor.multiply_"><code>Tensor.multiply_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.multiply#torch.Tensor.multiply" title="torch.Tensor.multiply"><code>multiply()</code></a>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.multinomial#torch.Tensor.multinomial" title="torch.Tensor.multinomial"><code>Tensor.multinomial</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.multinomial#torch.multinomial" title="torch.multinomial"><code>torch.multinomial()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.mv#torch.Tensor.mv" title="torch.Tensor.mv"><code>Tensor.mv</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.mv#torch.mv" title="torch.mv"><code>torch.mv()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.mvlgamma#torch.Tensor.mvlgamma" title="torch.Tensor.mvlgamma"><code>Tensor.mvlgamma</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.mvlgamma#torch.mvlgamma" title="torch.mvlgamma"><code>torch.mvlgamma()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.mvlgamma_#torch.Tensor.mvlgamma_" title="torch.Tensor.mvlgamma_"><code>Tensor.mvlgamma_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.mvlgamma#torch.Tensor.mvlgamma" title="torch.Tensor.mvlgamma"><code>mvlgamma()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.nansum#torch.Tensor.nansum" title="torch.Tensor.nansum"><code>Tensor.nansum</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.nansum#torch.nansum" title="torch.nansum"><code>torch.nansum()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.narrow#torch.Tensor.narrow" title="torch.Tensor.narrow"><code>Tensor.narrow</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.narrow#torch.narrow" title="torch.narrow"><code>torch.narrow()</code></a>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.narrow_copy#torch.Tensor.narrow_copy" title="torch.Tensor.narrow_copy"><code>Tensor.narrow_copy</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.narrow_copy#torch.narrow_copy" title="torch.narrow_copy"><code>torch.narrow_copy()</code></a>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.ndimension#torch.Tensor.ndimension" title="torch.Tensor.ndimension"><code>Tensor.ndimension</code></a></p></td> <td><p>Alias for <a class="reference internal" href="generated/torch.tensor.dim#torch.Tensor.dim" title="torch.Tensor.dim"><code>dim()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.nan_to_num#torch.Tensor.nan_to_num" title="torch.Tensor.nan_to_num"><code>Tensor.nan_to_num</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.nan_to_num#torch.nan_to_num" title="torch.nan_to_num"><code>torch.nan_to_num()</code></a>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.nan_to_num_#torch.Tensor.nan_to_num_" title="torch.Tensor.nan_to_num_"><code>Tensor.nan_to_num_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.nan_to_num#torch.Tensor.nan_to_num" title="torch.Tensor.nan_to_num"><code>nan_to_num()</code></a>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.ne#torch.Tensor.ne" title="torch.Tensor.ne"><code>Tensor.ne</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.ne#torch.ne" title="torch.ne"><code>torch.ne()</code></a>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.ne_#torch.Tensor.ne_" title="torch.Tensor.ne_"><code>Tensor.ne_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.ne#torch.Tensor.ne" title="torch.Tensor.ne"><code>ne()</code></a>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.not_equal#torch.Tensor.not_equal" title="torch.Tensor.not_equal"><code>Tensor.not_equal</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.not_equal#torch.not_equal" title="torch.not_equal"><code>torch.not_equal()</code></a>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.not_equal_#torch.Tensor.not_equal_" title="torch.Tensor.not_equal_"><code>Tensor.not_equal_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.not_equal#torch.Tensor.not_equal" title="torch.Tensor.not_equal"><code>not_equal()</code></a>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.neg#torch.Tensor.neg" title="torch.Tensor.neg"><code>Tensor.neg</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.neg#torch.neg" title="torch.neg"><code>torch.neg()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.neg_#torch.Tensor.neg_" title="torch.Tensor.neg_"><code>Tensor.neg_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.neg#torch.Tensor.neg" title="torch.Tensor.neg"><code>neg()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.negative#torch.Tensor.negative" title="torch.Tensor.negative"><code>Tensor.negative</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.negative#torch.negative" title="torch.negative"><code>torch.negative()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.negative_#torch.Tensor.negative_" title="torch.Tensor.negative_"><code>Tensor.negative_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.negative#torch.Tensor.negative" title="torch.Tensor.negative"><code>negative()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.nelement#torch.Tensor.nelement" title="torch.Tensor.nelement"><code>Tensor.nelement</code></a></p></td> <td><p>Alias for <a class="reference internal" href="generated/torch.tensor.numel#torch.Tensor.numel" title="torch.Tensor.numel"><code>numel()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.nextafter#torch.Tensor.nextafter" title="torch.Tensor.nextafter"><code>Tensor.nextafter</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.nextafter#torch.nextafter" title="torch.nextafter"><code>torch.nextafter()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.nextafter_#torch.Tensor.nextafter_" title="torch.Tensor.nextafter_"><code>Tensor.nextafter_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.nextafter#torch.Tensor.nextafter" title="torch.Tensor.nextafter"><code>nextafter()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.nonzero#torch.Tensor.nonzero" title="torch.Tensor.nonzero"><code>Tensor.nonzero</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.nonzero#torch.nonzero" title="torch.nonzero"><code>torch.nonzero()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.norm#torch.Tensor.norm" title="torch.Tensor.norm"><code>Tensor.norm</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.norm#torch.norm" title="torch.norm"><code>torch.norm()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.normal_#torch.Tensor.normal_" title="torch.Tensor.normal_"><code>Tensor.normal_</code></a></p></td> <td><p>Fills <code>self</code> tensor with elements samples from the normal distribution parameterized by <a class="reference internal" href="generated/torch.mean#torch.mean" title="torch.mean"><code>mean</code></a> and <a class="reference internal" href="generated/torch.std#torch.std" title="torch.std"><code>std</code></a>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.numel#torch.Tensor.numel" title="torch.Tensor.numel"><code>Tensor.numel</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.numel#torch.numel" title="torch.numel"><code>torch.numel()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.numpy#torch.Tensor.numpy" title="torch.Tensor.numpy"><code>Tensor.numpy</code></a></p></td> <td><p>Returns the tensor as a NumPy <code>ndarray</code>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.orgqr#torch.Tensor.orgqr" title="torch.Tensor.orgqr"><code>Tensor.orgqr</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.orgqr#torch.orgqr" title="torch.orgqr"><code>torch.orgqr()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.ormqr#torch.Tensor.ormqr" title="torch.Tensor.ormqr"><code>Tensor.ormqr</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.ormqr#torch.ormqr" title="torch.ormqr"><code>torch.ormqr()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.outer#torch.Tensor.outer" title="torch.Tensor.outer"><code>Tensor.outer</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.outer#torch.outer" title="torch.outer"><code>torch.outer()</code></a>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.permute#torch.Tensor.permute" title="torch.Tensor.permute"><code>Tensor.permute</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.permute#torch.permute" title="torch.permute"><code>torch.permute()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.pin_memory#torch.Tensor.pin_memory" title="torch.Tensor.pin_memory"><code>Tensor.pin_memory</code></a></p></td> <td><p>Copies the tensor to pinned memory, if it's not already pinned.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.pinverse#torch.Tensor.pinverse" title="torch.Tensor.pinverse"><code>Tensor.pinverse</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.pinverse#torch.pinverse" title="torch.pinverse"><code>torch.pinverse()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.polygamma#torch.Tensor.polygamma" title="torch.Tensor.polygamma"><code>Tensor.polygamma</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.polygamma#torch.polygamma" title="torch.polygamma"><code>torch.polygamma()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.polygamma_#torch.Tensor.polygamma_" title="torch.Tensor.polygamma_"><code>Tensor.polygamma_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.polygamma#torch.Tensor.polygamma" title="torch.Tensor.polygamma"><code>polygamma()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.positive#torch.Tensor.positive" title="torch.Tensor.positive"><code>Tensor.positive</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.positive#torch.positive" title="torch.positive"><code>torch.positive()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.pow#torch.Tensor.pow" title="torch.Tensor.pow"><code>Tensor.pow</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.pow#torch.pow" title="torch.pow"><code>torch.pow()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.pow_#torch.Tensor.pow_" title="torch.Tensor.pow_"><code>Tensor.pow_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.pow#torch.Tensor.pow" title="torch.Tensor.pow"><code>pow()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.prod#torch.Tensor.prod" title="torch.Tensor.prod"><code>Tensor.prod</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.prod#torch.prod" title="torch.prod"><code>torch.prod()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.put_#torch.Tensor.put_" title="torch.Tensor.put_"><code>Tensor.put_</code></a></p></td> <td><p>Copies the elements from <code>source</code> into the positions specified by <code>index</code>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.qr#torch.Tensor.qr" title="torch.Tensor.qr"><code>Tensor.qr</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.qr#torch.qr" title="torch.qr"><code>torch.qr()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.qscheme#torch.Tensor.qscheme" title="torch.Tensor.qscheme"><code>Tensor.qscheme</code></a></p></td> <td><p>Returns the quantization scheme of a given QTensor.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.quantile#torch.Tensor.quantile" title="torch.Tensor.quantile"><code>Tensor.quantile</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.quantile#torch.quantile" title="torch.quantile"><code>torch.quantile()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.nanquantile#torch.Tensor.nanquantile" title="torch.Tensor.nanquantile"><code>Tensor.nanquantile</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.nanquantile#torch.nanquantile" title="torch.nanquantile"><code>torch.nanquantile()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.q_scale#torch.Tensor.q_scale" title="torch.Tensor.q_scale"><code>Tensor.q_scale</code></a></p></td> <td><p>Given a Tensor quantized by linear(affine) quantization, returns the scale of the underlying quantizer().</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.q_zero_point#torch.Tensor.q_zero_point" title="torch.Tensor.q_zero_point"><code>Tensor.q_zero_point</code></a></p></td> <td><p>Given a Tensor quantized by linear(affine) quantization, returns the zero_point of the underlying quantizer().</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.q_per_channel_scales#torch.Tensor.q_per_channel_scales" title="torch.Tensor.q_per_channel_scales"><code>Tensor.q_per_channel_scales</code></a></p></td> <td><p>Given a Tensor quantized by linear (affine) per-channel quantization, returns a Tensor of scales of the underlying quantizer.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.q_per_channel_zero_points#torch.Tensor.q_per_channel_zero_points" title="torch.Tensor.q_per_channel_zero_points"><code>Tensor.q_per_channel_zero_points</code></a></p></td> <td><p>Given a Tensor quantized by linear (affine) per-channel quantization, returns a tensor of zero_points of the underlying quantizer.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.q_per_channel_axis#torch.Tensor.q_per_channel_axis" title="torch.Tensor.q_per_channel_axis"><code>Tensor.q_per_channel_axis</code></a></p></td> <td><p>Given a Tensor quantized by linear (affine) per-channel quantization, returns the index of dimension on which per-channel quantization is applied.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.rad2deg#torch.Tensor.rad2deg" title="torch.Tensor.rad2deg"><code>Tensor.rad2deg</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.rad2deg#torch.rad2deg" title="torch.rad2deg"><code>torch.rad2deg()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.random_#torch.Tensor.random_" title="torch.Tensor.random_"><code>Tensor.random_</code></a></p></td> <td><p>Fills <code>self</code> tensor with numbers sampled from the discrete uniform distribution over <code>[from, to - 1]</code>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.ravel#torch.Tensor.ravel" title="torch.Tensor.ravel"><code>Tensor.ravel</code></a></p></td> <td><p>see <a class="reference internal" href="generated/torch.ravel#torch.ravel" title="torch.ravel"><code>torch.ravel()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.reciprocal#torch.Tensor.reciprocal" title="torch.Tensor.reciprocal"><code>Tensor.reciprocal</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.reciprocal#torch.reciprocal" title="torch.reciprocal"><code>torch.reciprocal()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.reciprocal_#torch.Tensor.reciprocal_" title="torch.Tensor.reciprocal_"><code>Tensor.reciprocal_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.reciprocal#torch.Tensor.reciprocal" title="torch.Tensor.reciprocal"><code>reciprocal()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.record_stream#torch.Tensor.record_stream" title="torch.Tensor.record_stream"><code>Tensor.record_stream</code></a></p></td> <td><p>Ensures that the tensor memory is not reused for another tensor until all current work queued on <code>stream</code> are complete.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.register_hook#torch.Tensor.register_hook" title="torch.Tensor.register_hook"><code>Tensor.register_hook</code></a></p></td> <td><p>Registers a backward hook.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.register_post_accumulate_grad_hook#torch.Tensor.register_post_accumulate_grad_hook" title="torch.Tensor.register_post_accumulate_grad_hook"><code>Tensor.register_post_accumulate_grad_hook</code></a></p></td> <td><p>Registers a backward hook that runs after grad accumulation.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.remainder#torch.Tensor.remainder" title="torch.Tensor.remainder"><code>Tensor.remainder</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.remainder#torch.remainder" title="torch.remainder"><code>torch.remainder()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.remainder_#torch.Tensor.remainder_" title="torch.Tensor.remainder_"><code>Tensor.remainder_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.remainder#torch.Tensor.remainder" title="torch.Tensor.remainder"><code>remainder()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.renorm#torch.Tensor.renorm" title="torch.Tensor.renorm"><code>Tensor.renorm</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.renorm#torch.renorm" title="torch.renorm"><code>torch.renorm()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.renorm_#torch.Tensor.renorm_" title="torch.Tensor.renorm_"><code>Tensor.renorm_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.renorm#torch.Tensor.renorm" title="torch.Tensor.renorm"><code>renorm()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.repeat#torch.Tensor.repeat" title="torch.Tensor.repeat"><code>Tensor.repeat</code></a></p></td> <td><p>Repeats this tensor along the specified dimensions.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.repeat_interleave#torch.Tensor.repeat_interleave" title="torch.Tensor.repeat_interleave"><code>Tensor.repeat_interleave</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.repeat_interleave#torch.repeat_interleave" title="torch.repeat_interleave"><code>torch.repeat_interleave()</code></a>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.requires_grad#torch.Tensor.requires_grad" title="torch.Tensor.requires_grad"><code>Tensor.requires_grad</code></a></p></td> <td><p>Is <code>True</code> if gradients need to be computed for this Tensor, <code>False</code> otherwise.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.requires_grad_#torch.Tensor.requires_grad_" title="torch.Tensor.requires_grad_"><code>Tensor.requires_grad_</code></a></p></td> <td><p>Change if autograd should record operations on this tensor: sets this tensor's <code>requires_grad</code> attribute in-place.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.reshape#torch.Tensor.reshape" title="torch.Tensor.reshape"><code>Tensor.reshape</code></a></p></td> <td><p>Returns a tensor with the same data and number of elements as <code>self</code> but with the specified shape.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.reshape_as#torch.Tensor.reshape_as" title="torch.Tensor.reshape_as"><code>Tensor.reshape_as</code></a></p></td> <td><p>Returns this tensor as the same shape as <code>other</code>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.resize_#torch.Tensor.resize_" title="torch.Tensor.resize_"><code>Tensor.resize_</code></a></p></td> <td><p>Resizes <code>self</code> tensor to the specified size.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.resize_as_#torch.Tensor.resize_as_" title="torch.Tensor.resize_as_"><code>Tensor.resize_as_</code></a></p></td> <td><p>Resizes the <code>self</code> tensor to be the same size as the specified <a class="reference internal" href="generated/torch.tensor#torch.tensor" title="torch.tensor"><code>tensor</code></a>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.retain_grad#torch.Tensor.retain_grad" title="torch.Tensor.retain_grad"><code>Tensor.retain_grad</code></a></p></td> <td><p>Enables this Tensor to have their <code>grad</code> populated during <code>backward()</code>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.retains_grad#torch.Tensor.retains_grad" title="torch.Tensor.retains_grad"><code>Tensor.retains_grad</code></a></p></td> <td><p>Is <code>True</code> if this Tensor is non-leaf and its <code>grad</code> is enabled to be populated during <code>backward()</code>, <code>False</code> otherwise.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.roll#torch.Tensor.roll" title="torch.Tensor.roll"><code>Tensor.roll</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.roll#torch.roll" title="torch.roll"><code>torch.roll()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.rot90#torch.Tensor.rot90" title="torch.Tensor.rot90"><code>Tensor.rot90</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.rot90#torch.rot90" title="torch.rot90"><code>torch.rot90()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.round#torch.Tensor.round" title="torch.Tensor.round"><code>Tensor.round</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.round#torch.round" title="torch.round"><code>torch.round()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.round_#torch.Tensor.round_" title="torch.Tensor.round_"><code>Tensor.round_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.round#torch.Tensor.round" title="torch.Tensor.round"><code>round()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.rsqrt#torch.Tensor.rsqrt" title="torch.Tensor.rsqrt"><code>Tensor.rsqrt</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.rsqrt#torch.rsqrt" title="torch.rsqrt"><code>torch.rsqrt()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.rsqrt_#torch.Tensor.rsqrt_" title="torch.Tensor.rsqrt_"><code>Tensor.rsqrt_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.rsqrt#torch.Tensor.rsqrt" title="torch.Tensor.rsqrt"><code>rsqrt()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.scatter#torch.Tensor.scatter" title="torch.Tensor.scatter"><code>Tensor.scatter</code></a></p></td> <td><p>Out-of-place version of <a class="reference internal" href="generated/torch.tensor.scatter_#torch.Tensor.scatter_" title="torch.Tensor.scatter_"><code>torch.Tensor.scatter_()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.scatter_#torch.Tensor.scatter_" title="torch.Tensor.scatter_"><code>Tensor.scatter_</code></a></p></td> <td><p>Writes all values from the tensor <code>src</code> into <code>self</code> at the indices specified in the <code>index</code> tensor.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.scatter_add_#torch.Tensor.scatter_add_" title="torch.Tensor.scatter_add_"><code>Tensor.scatter_add_</code></a></p></td> <td><p>Adds all values from the tensor <code>src</code> into <code>self</code> at the indices specified in the <code>index</code> tensor in a similar fashion as <a class="reference internal" href="generated/torch.tensor.scatter_#torch.Tensor.scatter_" title="torch.Tensor.scatter_"><code>scatter_()</code></a>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.scatter_add#torch.Tensor.scatter_add" title="torch.Tensor.scatter_add"><code>Tensor.scatter_add</code></a></p></td> <td><p>Out-of-place version of <a class="reference internal" href="generated/torch.tensor.scatter_add_#torch.Tensor.scatter_add_" title="torch.Tensor.scatter_add_"><code>torch.Tensor.scatter_add_()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.scatter_reduce_#torch.Tensor.scatter_reduce_" title="torch.Tensor.scatter_reduce_"><code>Tensor.scatter_reduce_</code></a></p></td> <td><p>Reduces all values from the <code>src</code> tensor to the indices specified in the <code>index</code> tensor in the <code>self</code> tensor using the applied reduction defined via the <code>reduce</code> argument (<code>"sum"</code>, <code>"prod"</code>, <code>"mean"</code>, <code>"amax"</code>, <code>"amin"</code>).</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.scatter_reduce#torch.Tensor.scatter_reduce" title="torch.Tensor.scatter_reduce"><code>Tensor.scatter_reduce</code></a></p></td> <td><p>Out-of-place version of <a class="reference internal" href="generated/torch.tensor.scatter_reduce_#torch.Tensor.scatter_reduce_" title="torch.Tensor.scatter_reduce_"><code>torch.Tensor.scatter_reduce_()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.select#torch.Tensor.select" title="torch.Tensor.select"><code>Tensor.select</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.select#torch.select" title="torch.select"><code>torch.select()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.select_scatter#torch.Tensor.select_scatter" title="torch.Tensor.select_scatter"><code>Tensor.select_scatter</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.select_scatter#torch.select_scatter" title="torch.select_scatter"><code>torch.select_scatter()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.set_#torch.Tensor.set_" title="torch.Tensor.set_"><code>Tensor.set_</code></a></p></td> <td><p>Sets the underlying storage, size, and strides.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.share_memory_#torch.Tensor.share_memory_" title="torch.Tensor.share_memory_"><code>Tensor.share_memory_</code></a></p></td> <td><p>Moves the underlying storage to shared memory.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.short#torch.Tensor.short" title="torch.Tensor.short"><code>Tensor.short</code></a></p></td> <td><p><code>self.short()</code> is equivalent to <code>self.to(torch.int16)</code>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.sigmoid#torch.Tensor.sigmoid" title="torch.Tensor.sigmoid"><code>Tensor.sigmoid</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.sigmoid#torch.sigmoid" title="torch.sigmoid"><code>torch.sigmoid()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.sigmoid_#torch.Tensor.sigmoid_" title="torch.Tensor.sigmoid_"><code>Tensor.sigmoid_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.sigmoid#torch.Tensor.sigmoid" title="torch.Tensor.sigmoid"><code>sigmoid()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.sign#torch.Tensor.sign" title="torch.Tensor.sign"><code>Tensor.sign</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.sign#torch.sign" title="torch.sign"><code>torch.sign()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.sign_#torch.Tensor.sign_" title="torch.Tensor.sign_"><code>Tensor.sign_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.sign#torch.Tensor.sign" title="torch.Tensor.sign"><code>sign()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.signbit#torch.Tensor.signbit" title="torch.Tensor.signbit"><code>Tensor.signbit</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.signbit#torch.signbit" title="torch.signbit"><code>torch.signbit()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.sgn#torch.Tensor.sgn" title="torch.Tensor.sgn"><code>Tensor.sgn</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.sgn#torch.sgn" title="torch.sgn"><code>torch.sgn()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.sgn_#torch.Tensor.sgn_" title="torch.Tensor.sgn_"><code>Tensor.sgn_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.sgn#torch.Tensor.sgn" title="torch.Tensor.sgn"><code>sgn()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.sin#torch.Tensor.sin" title="torch.Tensor.sin"><code>Tensor.sin</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.sin#torch.sin" title="torch.sin"><code>torch.sin()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.sin_#torch.Tensor.sin_" title="torch.Tensor.sin_"><code>Tensor.sin_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.sin#torch.Tensor.sin" title="torch.Tensor.sin"><code>sin()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.sinc#torch.Tensor.sinc" title="torch.Tensor.sinc"><code>Tensor.sinc</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.sinc#torch.sinc" title="torch.sinc"><code>torch.sinc()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.sinc_#torch.Tensor.sinc_" title="torch.Tensor.sinc_"><code>Tensor.sinc_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.sinc#torch.Tensor.sinc" title="torch.Tensor.sinc"><code>sinc()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.sinh#torch.Tensor.sinh" title="torch.Tensor.sinh"><code>Tensor.sinh</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.sinh#torch.sinh" title="torch.sinh"><code>torch.sinh()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.sinh_#torch.Tensor.sinh_" title="torch.Tensor.sinh_"><code>Tensor.sinh_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.sinh#torch.Tensor.sinh" title="torch.Tensor.sinh"><code>sinh()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.asinh#torch.Tensor.asinh" title="torch.Tensor.asinh"><code>Tensor.asinh</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.asinh#torch.asinh" title="torch.asinh"><code>torch.asinh()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.asinh_#torch.Tensor.asinh_" title="torch.Tensor.asinh_"><code>Tensor.asinh_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.asinh#torch.Tensor.asinh" title="torch.Tensor.asinh"><code>asinh()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.arcsinh#torch.Tensor.arcsinh" title="torch.Tensor.arcsinh"><code>Tensor.arcsinh</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.arcsinh#torch.arcsinh" title="torch.arcsinh"><code>torch.arcsinh()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.arcsinh_#torch.Tensor.arcsinh_" title="torch.Tensor.arcsinh_"><code>Tensor.arcsinh_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.arcsinh#torch.Tensor.arcsinh" title="torch.Tensor.arcsinh"><code>arcsinh()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.shape#torch.Tensor.shape" title="torch.Tensor.shape"><code>Tensor.shape</code></a></p></td> <td><p>Returns the size of the <code>self</code> tensor.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.size#torch.Tensor.size" title="torch.Tensor.size"><code>Tensor.size</code></a></p></td> <td><p>Returns the size of the <code>self</code> tensor.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.slogdet#torch.Tensor.slogdet" title="torch.Tensor.slogdet"><code>Tensor.slogdet</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.slogdet#torch.slogdet" title="torch.slogdet"><code>torch.slogdet()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.slice_scatter#torch.Tensor.slice_scatter" title="torch.Tensor.slice_scatter"><code>Tensor.slice_scatter</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.slice_scatter#torch.slice_scatter" title="torch.slice_scatter"><code>torch.slice_scatter()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.softmax#torch.Tensor.softmax" title="torch.Tensor.softmax"><code>Tensor.softmax</code></a></p></td> <td><p>Alias for <a class="reference internal" href="generated/torch.nn.functional.softmax#torch.nn.functional.softmax" title="torch.nn.functional.softmax"><code>torch.nn.functional.softmax()</code></a>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.sort#torch.Tensor.sort" title="torch.Tensor.sort"><code>Tensor.sort</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.sort#torch.sort" title="torch.sort"><code>torch.sort()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.split#torch.Tensor.split" title="torch.Tensor.split"><code>Tensor.split</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.split#torch.split" title="torch.split"><code>torch.split()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.sparse_mask#torch.Tensor.sparse_mask" title="torch.Tensor.sparse_mask"><code>Tensor.sparse_mask</code></a></p></td> <td><p>Returns a new <a class="reference internal" href="sparse#sparse-docs"><span class="std std-ref">sparse tensor</span></a> with values from a strided tensor <code>self</code> filtered by the indices of the sparse tensor <code>mask</code>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.sparse_dim#torch.Tensor.sparse_dim" title="torch.Tensor.sparse_dim"><code>Tensor.sparse_dim</code></a></p></td> <td><p>Return the number of sparse dimensions in a <a class="reference internal" href="sparse#sparse-docs"><span class="std std-ref">sparse tensor</span></a> <code>self</code>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.sqrt#torch.Tensor.sqrt" title="torch.Tensor.sqrt"><code>Tensor.sqrt</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.sqrt#torch.sqrt" title="torch.sqrt"><code>torch.sqrt()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.sqrt_#torch.Tensor.sqrt_" title="torch.Tensor.sqrt_"><code>Tensor.sqrt_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.sqrt#torch.Tensor.sqrt" title="torch.Tensor.sqrt"><code>sqrt()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.square#torch.Tensor.square" title="torch.Tensor.square"><code>Tensor.square</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.square#torch.square" title="torch.square"><code>torch.square()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.square_#torch.Tensor.square_" title="torch.Tensor.square_"><code>Tensor.square_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.square#torch.Tensor.square" title="torch.Tensor.square"><code>square()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.squeeze#torch.Tensor.squeeze" title="torch.Tensor.squeeze"><code>Tensor.squeeze</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.squeeze#torch.squeeze" title="torch.squeeze"><code>torch.squeeze()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.squeeze_#torch.Tensor.squeeze_" title="torch.Tensor.squeeze_"><code>Tensor.squeeze_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.squeeze#torch.Tensor.squeeze" title="torch.Tensor.squeeze"><code>squeeze()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.std#torch.Tensor.std" title="torch.Tensor.std"><code>Tensor.std</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.std#torch.std" title="torch.std"><code>torch.std()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.stft#torch.Tensor.stft" title="torch.Tensor.stft"><code>Tensor.stft</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.stft#torch.stft" title="torch.stft"><code>torch.stft()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.storage#torch.Tensor.storage" title="torch.Tensor.storage"><code>Tensor.storage</code></a></p></td> <td><p>Returns the underlying <a class="reference internal" href="storage#torch.TypedStorage" title="torch.TypedStorage"><code>TypedStorage</code></a>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.untyped_storage#torch.Tensor.untyped_storage" title="torch.Tensor.untyped_storage"><code>Tensor.untyped_storage</code></a></p></td> <td><p>Returns the underlying <a class="reference internal" href="storage#torch.UntypedStorage" title="torch.UntypedStorage"><code>UntypedStorage</code></a>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.storage_offset#torch.Tensor.storage_offset" title="torch.Tensor.storage_offset"><code>Tensor.storage_offset</code></a></p></td> <td><p>Returns <code>self</code> tensor's offset in the underlying storage in terms of number of storage elements (not bytes).</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.storage_type#torch.Tensor.storage_type" title="torch.Tensor.storage_type"><code>Tensor.storage_type</code></a></p></td> <td><p>Returns the type of the underlying storage.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.stride#torch.Tensor.stride" title="torch.Tensor.stride"><code>Tensor.stride</code></a></p></td> <td><p>Returns the stride of <code>self</code> tensor.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.sub#torch.Tensor.sub" title="torch.Tensor.sub"><code>Tensor.sub</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.sub#torch.sub" title="torch.sub"><code>torch.sub()</code></a>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.sub_#torch.Tensor.sub_" title="torch.Tensor.sub_"><code>Tensor.sub_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.sub#torch.Tensor.sub" title="torch.Tensor.sub"><code>sub()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.subtract#torch.Tensor.subtract" title="torch.Tensor.subtract"><code>Tensor.subtract</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.subtract#torch.subtract" title="torch.subtract"><code>torch.subtract()</code></a>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.subtract_#torch.Tensor.subtract_" title="torch.Tensor.subtract_"><code>Tensor.subtract_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.subtract#torch.Tensor.subtract" title="torch.Tensor.subtract"><code>subtract()</code></a>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.sum#torch.Tensor.sum" title="torch.Tensor.sum"><code>Tensor.sum</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.sum#torch.sum" title="torch.sum"><code>torch.sum()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.sum_to_size#torch.Tensor.sum_to_size" title="torch.Tensor.sum_to_size"><code>Tensor.sum_to_size</code></a></p></td> <td><p>Sum <code>this</code> tensor to <code>size</code>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.svd#torch.Tensor.svd" title="torch.Tensor.svd"><code>Tensor.svd</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.svd#torch.svd" title="torch.svd"><code>torch.svd()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.swapaxes#torch.Tensor.swapaxes" title="torch.Tensor.swapaxes"><code>Tensor.swapaxes</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.swapaxes#torch.swapaxes" title="torch.swapaxes"><code>torch.swapaxes()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.swapdims#torch.Tensor.swapdims" title="torch.Tensor.swapdims"><code>Tensor.swapdims</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.swapdims#torch.swapdims" title="torch.swapdims"><code>torch.swapdims()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.t#torch.Tensor.t" title="torch.Tensor.t"><code>Tensor.t</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.t#torch.t" title="torch.t"><code>torch.t()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.t_#torch.Tensor.t_" title="torch.Tensor.t_"><code>Tensor.t_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.t#torch.Tensor.t" title="torch.Tensor.t"><code>t()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.tensor_split#torch.Tensor.tensor_split" title="torch.Tensor.tensor_split"><code>Tensor.tensor_split</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.tensor_split#torch.tensor_split" title="torch.tensor_split"><code>torch.tensor_split()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.tile#torch.Tensor.tile" title="torch.Tensor.tile"><code>Tensor.tile</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.tile#torch.tile" title="torch.tile"><code>torch.tile()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.to#torch.Tensor.to" title="torch.Tensor.to"><code>Tensor.to</code></a></p></td> <td><p>Performs Tensor dtype and/or device conversion.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.to_mkldnn#torch.Tensor.to_mkldnn" title="torch.Tensor.to_mkldnn"><code>Tensor.to_mkldnn</code></a></p></td> <td><p>Returns a copy of the tensor in <code>torch.mkldnn</code> layout.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.take#torch.Tensor.take" title="torch.Tensor.take"><code>Tensor.take</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.take#torch.take" title="torch.take"><code>torch.take()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.take_along_dim#torch.Tensor.take_along_dim" title="torch.Tensor.take_along_dim"><code>Tensor.take_along_dim</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.take_along_dim#torch.take_along_dim" title="torch.take_along_dim"><code>torch.take_along_dim()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.tan#torch.Tensor.tan" title="torch.Tensor.tan"><code>Tensor.tan</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.tan#torch.tan" title="torch.tan"><code>torch.tan()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.tan_#torch.Tensor.tan_" title="torch.Tensor.tan_"><code>Tensor.tan_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.tan#torch.Tensor.tan" title="torch.Tensor.tan"><code>tan()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.tanh#torch.Tensor.tanh" title="torch.Tensor.tanh"><code>Tensor.tanh</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.tanh#torch.tanh" title="torch.tanh"><code>torch.tanh()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.tanh_#torch.Tensor.tanh_" title="torch.Tensor.tanh_"><code>Tensor.tanh_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.tanh#torch.Tensor.tanh" title="torch.Tensor.tanh"><code>tanh()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.atanh#torch.Tensor.atanh" title="torch.Tensor.atanh"><code>Tensor.atanh</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.atanh#torch.atanh" title="torch.atanh"><code>torch.atanh()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.atanh_#torch.Tensor.atanh_" title="torch.Tensor.atanh_"><code>Tensor.atanh_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.atanh#torch.Tensor.atanh" title="torch.Tensor.atanh"><code>atanh()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.arctanh#torch.Tensor.arctanh" title="torch.Tensor.arctanh"><code>Tensor.arctanh</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.arctanh#torch.arctanh" title="torch.arctanh"><code>torch.arctanh()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.arctanh_#torch.Tensor.arctanh_" title="torch.Tensor.arctanh_"><code>Tensor.arctanh_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.arctanh#torch.Tensor.arctanh" title="torch.Tensor.arctanh"><code>arctanh()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.tolist#torch.Tensor.tolist" title="torch.Tensor.tolist"><code>Tensor.tolist</code></a></p></td> <td><p>Returns the tensor as a (nested) list.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.topk#torch.Tensor.topk" title="torch.Tensor.topk"><code>Tensor.topk</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.topk#torch.topk" title="torch.topk"><code>torch.topk()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.to_dense#torch.Tensor.to_dense" title="torch.Tensor.to_dense"><code>Tensor.to_dense</code></a></p></td> <td><p>Creates a strided copy of <code>self</code> if <code>self</code> is not a strided tensor, otherwise returns <code>self</code>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.to_sparse#torch.Tensor.to_sparse" title="torch.Tensor.to_sparse"><code>Tensor.to_sparse</code></a></p></td> <td><p>Returns a sparse copy of the tensor.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.to_sparse_csr#torch.Tensor.to_sparse_csr" title="torch.Tensor.to_sparse_csr"><code>Tensor.to_sparse_csr</code></a></p></td> <td><p>Convert a tensor to compressed row storage format (CSR).</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.to_sparse_csc#torch.Tensor.to_sparse_csc" title="torch.Tensor.to_sparse_csc"><code>Tensor.to_sparse_csc</code></a></p></td> <td><p>Convert a tensor to compressed column storage (CSC) format.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.to_sparse_bsr#torch.Tensor.to_sparse_bsr" title="torch.Tensor.to_sparse_bsr"><code>Tensor.to_sparse_bsr</code></a></p></td> <td><p>Convert a tensor to a block sparse row (BSR) storage format of given blocksize.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.to_sparse_bsc#torch.Tensor.to_sparse_bsc" title="torch.Tensor.to_sparse_bsc"><code>Tensor.to_sparse_bsc</code></a></p></td> <td><p>Convert a tensor to a block sparse column (BSC) storage format of given blocksize.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.trace#torch.Tensor.trace" title="torch.Tensor.trace"><code>Tensor.trace</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.trace#torch.trace" title="torch.trace"><code>torch.trace()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.transpose#torch.Tensor.transpose" title="torch.Tensor.transpose"><code>Tensor.transpose</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.transpose#torch.transpose" title="torch.transpose"><code>torch.transpose()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.transpose_#torch.Tensor.transpose_" title="torch.Tensor.transpose_"><code>Tensor.transpose_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.transpose#torch.Tensor.transpose" title="torch.Tensor.transpose"><code>transpose()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.triangular_solve#torch.Tensor.triangular_solve" title="torch.Tensor.triangular_solve"><code>Tensor.triangular_solve</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.triangular_solve#torch.triangular_solve" title="torch.triangular_solve"><code>torch.triangular_solve()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.tril#torch.Tensor.tril" title="torch.Tensor.tril"><code>Tensor.tril</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.tril#torch.tril" title="torch.tril"><code>torch.tril()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.tril_#torch.Tensor.tril_" title="torch.Tensor.tril_"><code>Tensor.tril_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.tril#torch.Tensor.tril" title="torch.Tensor.tril"><code>tril()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.triu#torch.Tensor.triu" title="torch.Tensor.triu"><code>Tensor.triu</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.triu#torch.triu" title="torch.triu"><code>torch.triu()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.triu_#torch.Tensor.triu_" title="torch.Tensor.triu_"><code>Tensor.triu_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.triu#torch.Tensor.triu" title="torch.Tensor.triu"><code>triu()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.true_divide#torch.Tensor.true_divide" title="torch.Tensor.true_divide"><code>Tensor.true_divide</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.true_divide#torch.true_divide" title="torch.true_divide"><code>torch.true_divide()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.true_divide_#torch.Tensor.true_divide_" title="torch.Tensor.true_divide_"><code>Tensor.true_divide_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.true_divide_#torch.Tensor.true_divide_" title="torch.Tensor.true_divide_"><code>true_divide_()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.trunc#torch.Tensor.trunc" title="torch.Tensor.trunc"><code>Tensor.trunc</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.trunc#torch.trunc" title="torch.trunc"><code>torch.trunc()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.trunc_#torch.Tensor.trunc_" title="torch.Tensor.trunc_"><code>Tensor.trunc_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.trunc#torch.Tensor.trunc" title="torch.Tensor.trunc"><code>trunc()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.type#torch.Tensor.type" title="torch.Tensor.type"><code>Tensor.type</code></a></p></td> <td><p>Returns the type if <code>dtype</code> is not provided, else casts this object to the specified type.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.type_as#torch.Tensor.type_as" title="torch.Tensor.type_as"><code>Tensor.type_as</code></a></p></td> <td><p>Returns this tensor cast to the type of the given tensor.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.unbind#torch.Tensor.unbind" title="torch.Tensor.unbind"><code>Tensor.unbind</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.unbind#torch.unbind" title="torch.unbind"><code>torch.unbind()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.unflatten#torch.Tensor.unflatten" title="torch.Tensor.unflatten"><code>Tensor.unflatten</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.unflatten#torch.unflatten" title="torch.unflatten"><code>torch.unflatten()</code></a>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.unfold#torch.Tensor.unfold" title="torch.Tensor.unfold"><code>Tensor.unfold</code></a></p></td> <td><p>Returns a view of the original tensor which contains all slices of size <code>size</code> from <code>self</code> tensor in the dimension <code>dimension</code>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.uniform_#torch.Tensor.uniform_" title="torch.Tensor.uniform_"><code>Tensor.uniform_</code></a></p></td> <td><p>Fills <code>self</code> tensor with numbers sampled from the continuous uniform distribution:</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.unique#torch.Tensor.unique" title="torch.Tensor.unique"><code>Tensor.unique</code></a></p></td> <td><p>Returns the unique elements of the input tensor.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.unique_consecutive#torch.Tensor.unique_consecutive" title="torch.Tensor.unique_consecutive"><code>Tensor.unique_consecutive</code></a></p></td> <td><p>Eliminates all but the first element from every consecutive group of equivalent elements.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.unsqueeze#torch.Tensor.unsqueeze" title="torch.Tensor.unsqueeze"><code>Tensor.unsqueeze</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.unsqueeze#torch.unsqueeze" title="torch.unsqueeze"><code>torch.unsqueeze()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.unsqueeze_#torch.Tensor.unsqueeze_" title="torch.Tensor.unsqueeze_"><code>Tensor.unsqueeze_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.unsqueeze#torch.Tensor.unsqueeze" title="torch.Tensor.unsqueeze"><code>unsqueeze()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.values#torch.Tensor.values" title="torch.Tensor.values"><code>Tensor.values</code></a></p></td> <td><p>Return the values tensor of a <a class="reference internal" href="sparse#sparse-coo-docs"><span class="std std-ref">sparse COO tensor</span></a>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.var#torch.Tensor.var" title="torch.Tensor.var"><code>Tensor.var</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.var#torch.var" title="torch.var"><code>torch.var()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.vdot#torch.Tensor.vdot" title="torch.Tensor.vdot"><code>Tensor.vdot</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.vdot#torch.vdot" title="torch.vdot"><code>torch.vdot()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.view#torch.Tensor.view" title="torch.Tensor.view"><code>Tensor.view</code></a></p></td> <td><p>Returns a new tensor with the same data as the <code>self</code> tensor but of a different <code>shape</code>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.view_as#torch.Tensor.view_as" title="torch.Tensor.view_as"><code>Tensor.view_as</code></a></p></td> <td><p>View this tensor as the same size as <code>other</code>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.vsplit#torch.Tensor.vsplit" title="torch.Tensor.vsplit"><code>Tensor.vsplit</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.vsplit#torch.vsplit" title="torch.vsplit"><code>torch.vsplit()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.where#torch.Tensor.where" title="torch.Tensor.where"><code>Tensor.where</code></a></p></td> <td><p><code>self.where(condition, y)</code> is equivalent to <code>torch.where(condition, self, y)</code>.</p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.xlogy#torch.Tensor.xlogy" title="torch.Tensor.xlogy"><code>Tensor.xlogy</code></a></p></td> <td><p>See <a class="reference internal" href="generated/torch.xlogy#torch.xlogy" title="torch.xlogy"><code>torch.xlogy()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.xlogy_#torch.Tensor.xlogy_" title="torch.Tensor.xlogy_"><code>Tensor.xlogy_</code></a></p></td> <td><p>In-place version of <a class="reference internal" href="generated/torch.tensor.xlogy#torch.Tensor.xlogy" title="torch.Tensor.xlogy"><code>xlogy()</code></a></p></td> </tr> <tr>
<td><p><a class="reference internal" href="generated/torch.tensor.zero_#torch.Tensor.zero_" title="torch.Tensor.zero_"><code>Tensor.zero_</code></a></p></td> <td><p>Fills <code>self</code> tensor with zeros.</p></td> </tr>  </table><div class="_attribution">
  <p class="_attribution-p">
    &copy; 2024, PyTorch Contributors<br>PyTorch has a BSD-style license, as found in the <a href="https://github.com/pytorch/pytorch/blob/main/LICENSE">LICENSE</a> file.<br>
    <a href="https://pytorch.org/docs/2.1/tensors.html" class="_attribution-link">https://pytorch.org/docs/2.1/tensors.html</a>
  </p>
</div>
