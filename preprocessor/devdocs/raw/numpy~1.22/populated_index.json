[{"name": "()", "path": "glossary", "type": "Glossary", "text": "\nA parenthesized number followed by a comma denotes a tuple with one element.\nThe trailing comma distinguishes a one-element tuple from a parenthesized `n`.\n\nIn a dimension entry, instructs NumPy to choose the length that will keep the\ntotal number of array elements the same.\n\nAn `Ellipsis`.\n\nWhen indexing an array, shorthand that the missing axes, if they exist, are\nfull slices.\n\nIt can be used at most once; `a[...,0,...]` raises an `IndexError`.\n\nThe Python slice operator. In ndarrays, slicing can be applied to every axis:\n\nTrailing slices can be omitted:\n\nIn contrast to Python, where slicing creates a copy, in NumPy slicing creates\na view.\n\nFor details, see Combining advanced and basic indexing.\n\nIn a dtype declaration, indicates that the data is little-endian (the bracket\nis big on the right).\n\nIn a dtype declaration, indicates that the data is big-endian (the bracket is\nbig on the left).\n\nRather than using a scalar or slice as an index, an axis can be indexed with\nan array, providing fine-grained selection. This is known as advanced indexing\nor \u201cfancy indexing\u201d.\n\nAn operation `along axis n` of array `a` behaves as if its argument were an\narray of slices of `a` where each slice has a successive index of axis `n`.\n\nFor example, if `a` is a 3 x `N` array, an operation along axis 0 behaves as\nif its argument were an array containing slices of each row:\n\nTo make it concrete, we can pick the operation to be the array-reversal\nfunction `numpy.flip`, which accepts an `axis` argument. We construct a 3 x 4\narray `a`:\n\nReversing along axis 0 (the row axis) yields\n\nRecalling the definition of `along an axis`, `flip` along axis 0 is treating\nits argument as if it were\n\nand the result of `np.flip(a,axis=0)` is to reverse the slices:\n\nUsed synonymously in the NumPy docs with ndarray.\n\nAny scalar or sequence that can be interpreted as an ndarray. In addition to\nndarrays and scalars this category includes lists (possibly nested and with\ndifferent element types) and tuples. Any argument accepted by numpy.array is\narray_like.\n\nAn array scalar is an instance of the types/classes float32, float64, etc..\nFor uniformity in handling operands, NumPy treats a scalar as an array of zero\ndimension. In contrast, a 0-dimensional array is an ndarray instance\ncontaining precisely one value.\n\nAnother term for an array dimension. Axes are numbered left to right; axis 0\nis the first element in the shape tuple.\n\nIn a two-dimensional vector, the elements of axis 0 are rows and the elements\nof axis 1 are columns.\n\nIn higher dimensions, the picture changes. NumPy prints higher-dimensional\nvectors as replications of row-by-column building blocks, as in this three-\ndimensional vector:\n\n`a` is depicted as a two-element array whose elements are 2x3 vectors. From\nthis point of view, rows and columns are the final two axes, respectively, in\nany shape.\n\nThis rule helps you anticipate how a vector will be printed, and conversely\nhow to find the index of any of the printed elements. For instance, in the\nexample, the last two values of 8\u2019s index must be 0 and 2. Since 8 appears in\nthe second of the two 2x3\u2019s, the first index must be 1:\n\nA convenient way to count dimensions in a printed vector is to count `[`\nsymbols after the open-parenthesis. This is useful in distinguishing, say, a\n(1,2,3) shape from a (2,3) shape:\n\nIf an array does not own its memory, then its base attribute returns the\nobject whose memory the array is referencing. That object may be referencing\nthe memory from still another object, so the owning object may be\n`a.base.base.base...`. Some writers erroneously claim that testing `base`\ndetermines if arrays are views. For the correct way, see\n`numpy.shares_memory`.\n\nSee Endianness.\n\nBasic Linear Algebra Subprograms\n\nbroadcasting is NumPy\u2019s ability to process ndarrays of different sizes as if\nall were the same size.\n\nIt permits an elegant do-what-I-mean behavior where, for instance, adding a\nscalar to a vector adds the scalar value to every element.\n\nOrdinarly, vector operands must all be the same size, because NumPy works\nelement by element \u2013 for instance, `c = a * b` is\n\nBut in certain useful cases, NumPy can duplicate data along \u201cmissing\u201d axes or\n\u201ctoo-short\u201d dimensions so shapes will match. The duplication costs no memory\nor time. For details, see Broadcasting.\n\nSame as row-major.\n\nSee Row- and column-major order.\n\nSee view.\n\nSee axis.\n\nThe datatype describing the (identically typed) elements in an ndarray. It can\nbe changed to reinterpret the array contents. For details, see Data type\nobjects (dtype).\n\nAnother term for advanced indexing.\n\nIn a structured data type, each subtype is called a `field`. The `field` has a\nname (a string), a type (any valid dtype), and an optional `title`. See Data\ntype objects (dtype).\n\nSame as column-major.\n\nSee ravel.\n\nAll elements of a homogeneous array have the same type. ndarrays, in contrast\nto Python lists, are homogeneous. The type can be complicated, as in a\nstructured array, but all elements have that type.\n\nNumPy object arrays, which contain references to Python objects, fill the role\nof heterogeneous arrays.\n\nThe size of the dtype element in bytes.\n\nSee Endianness.\n\nA boolean array used to select only certain elements for an operation:\n\nBad or missing data can be cleanly ignored by putting it in a masked array,\nwhich has an internal boolean array indicating invalid entries. Operations\nwith masked arrays ignore these entries.\n\nFor details, see Masked arrays.\n\nNumPy\u2019s two-dimensional matrix class should no longer be used; use regular\nndarrays.\n\nNumPy\u2019s basic structure.\n\nAn array whose dtype is `object`; that is, it contains references to Python\nobjects. Indexing the array dereferences the Python objects, so unlike other\nndarrays, an object array has the ability to hold heterogeneous objects.\n\nnumpy.ravel  and numpy.flatten  both flatten an ndarray. `ravel` will return a\nview if possible; `flatten` always returns a copy.\n\nFlattening collapses a multimdimensional array to a single dimension; details\nof how this is done (for instance, whether `a[n+1]` should be the next row or\nnext column) are parameters.\n\nA structured array with allowing access in an attribute style (`a.field`) in\naddition to `a['field']`. For details, see numpy.recarray.\n\nSee Row- and column-major order. NumPy creates arrays in row-major order by\ndefault.\n\nIn NumPy, usually a synonym for array scalar.\n\nA tuple showing the length of each dimension of an ndarray. The length of the\ntuple itself is the number of dimensions (numpy.ndim). The product of the\ntuple elements is the number of elements in the array. For details, see\nnumpy.ndarray.shape.\n\nPhysical memory is one-dimensional; strides provide a mechanism to map a given\nindex to an address in memory. For an N-dimensional array, its `strides`\nattribute is an N-element tuple; advancing from index `i` to index `i+1` on\naxis `n` means adding `a.strides[n]` bytes to the address.\n\nStrides are computed automatically from an array\u2019s dtype and shape, but can be\ndirectly specified using as_strided.\n\nFor details, see numpy.ndarray.strides.\n\nTo see how striding underlies the power of NumPy views, see The NumPy array: a\nstructure for efficient numerical computation.\n\nArray whose dtype is a structured data type.\n\nUsers can create arbitrarily complex dtypes that can include other arrays and\ndtypes. These composite dtypes are called structured data types.\n\nAn array nested in a structured data type, as `b` is here:\n\nAn element of a structured datatype that behaves like an ndarray.\n\nAn alias for a field name in a structured datatype.\n\nIn NumPy, usually a synonym for dtype. For the more general Python meaning,\nsee here.\n\nNumPy\u2019s fast element-by-element computation (vectorization) gives a choice\nwhich function gets applied. The general term for the function is `ufunc`,\nshort for `universal function`. NumPy routines have built-in ufuncs, but users\ncan also write their own.\n\nNumPy hands off array processing to C, where looping and computation are much\nfaster than in Python. To exploit this, programmers using NumPy eliminate\nPython loops in favor of array-to-array operations. vectorization can refer\nboth to the C offloading and to structuring NumPy code to leverage it.\n\nWithout touching underlying data, NumPy can make one array appear to change\nits datatype and shape.\n\nAn array created this way is a `view`, and NumPy often exploits the\nperformance gain of using a view versus making a new array.\n\nA potential drawback is that writing to a view can alter the original as well.\nIf this is a problem, NumPy instead needs to create a physically distinct\narray \u2013 a `copy`.\n\nSome NumPy routines always return views, some always return copies, some may\nreturn one or the other, and for some the choice can be specified.\nResponsibility for managing views and copies falls to the programmer.\n`numpy.shares_memory` will check whether `b` is a view of `a`, but an exact\nanswer isn\u2019t always feasible, as the documentation page explains.\n\n"}, {"name": "--overwrite-signature", "path": "f2py/usage", "type": "Using F2PY", "text": "\nF2PY can be used either as a command line tool `f2py` or as a Python module\n`numpy.f2py`. While we try to provide the command line tool as part of the\nnumpy setup, some platforms like Windows make it difficult to reliably put the\nexecutables on the `PATH`. We will refer to `f2py` in this document but you\nmay have to run it as a module:\n\nIf you run `f2py` with no arguments, and the line `numpy Version` at the end\nmatches the NumPy version printed from `python -m numpy.f2py`, then you can\nuse the shorter version. If not, or if you cannot run `f2py`, you should\nreplace all calls to `f2py` here with the longer version.\n\nWhen used as a command line tool, `f2py` has three major modes, distinguished\nby the usage of `-c` and `-h` switches:\n\nTo scan Fortran sources and generate a signature file, use\n\nNote\n\nA Fortran source file can contain many routines, and it is often not necessary\nto allow all routines be usable from Python. In such cases, either specify\nwhich routines should be wrapped (in the `only: .. :` part) or which routines\nF2PY should ignored (in the `skip: .. :` part).\n\nIf `<filename.pyf>` is specified as `stdout` then signatures are written to\nstandard output instead of a file.\n\nAmong other options (see below), the following can be used in this mode:\n\nOverwrites an existing signature file.\n\nTo construct an extension module, use\n\nThe constructed extension module is saved as `<modulename>module.c` to the\ncurrent directory.\n\nHere `<fortran files>` may also contain signature files. Among other options\n(see below), the following options can be used in this mode:\n\nAdds debugging hooks to the extension module. When using this extension\nmodule, various diagnostic information about the wrapper is written to the\nstandard output, for example, the values of variables, the steps taken, etc.\n\nAdd a CPP `#include` statement to the extension module source. `<includefile>`\nshould be given in one of the following forms\n\nThe include statement is inserted just before the wrapper functions. This\nfeature enables using arbitrary C functions (defined in `<includefile>`) in\nF2PY generated wrappers.\n\nNote\n\nThis option is deprecated. Use `usercode` statement to specify C code snippets\ndirectly in signature files.\n\nCreate Fortran subroutine wrappers to Fortran functions. `--wrap-functions` is\ndefault because it ensures maximum portability and compiler independence.\n\nSearch include files from given directories.\n\nList system resources found by `numpy_distutils/system_info.py`. For example,\ntry `f2py --help-link lapack_opt`.\n\nTo build an extension module, use\n\nIf `<fortran files>` contains a signature file, then the source for an\nextension module is constructed, all Fortran and C sources are compiled, and\nfinally all object and library files are linked to the extension module\n`<modulename>.so` which is saved into the current directory.\n\nIf `<fortran files>` does not contain a signature file, then an extension\nmodule is constructed by scanning all Fortran source codes for routine\nsignatures, before proceeding to build the extension module.\n\nAmong other options (see below) and options described for previous modes, the\nfollowing options can be used in this mode:\n\nList the available Fortran compilers.\n\nList the available Fortran compilers.\n\nSpecify a Fortran compiler type by vendor.\n\nSpecify the path to a F77 compiler\n\nSpecify the path to a F77 compiler\n\nSpecify the path to a F90 compiler\n\nSpecify the path to a F90 compiler\n\nSpecify F77 compiler flags\n\nSpecify F90 compiler flags\n\nSpecify optimization flags\n\nSpecify architecture specific optimization flags\n\nCompile without optimization flags\n\nCompile without arch-dependent optimization flags\n\nCompile with debugging information\n\nUse the library `<libname>` when linking.\n\nDefine macro `<macro>` as `<defn>`.\n\nDefine macro `<macro>`\n\nAppend directory `<dir>` to the list of directories searched for include\nfiles.\n\nAdd directory `<dir>` to the list of directories to be searched for `-l`.\n\nLink the extension module with <resource> as defined by\n`numpy_distutils/system_info.py`. E.g. to link with optimized LAPACK libraries\n(vecLib on MacOSX, ATLAS elsewhere), use `--link-lapack_opt`. See also\n`--help-link` switch.\n\nNote\n\nThe `f2py -c` option must be applied either to an existing `.pyf` file (plus\nthe source/object/library files) or one must specify the `-m <modulename>`\noption (plus the sources/object/library files). Use one of the following\noptions:\n\nor\n\nFor more information, see the Building C and C++ Extensions Python\ndocumentation for details.\n\nWhen building an extension module, a combination of the following macros may\nbe required for non-gcc Fortran compilers:\n\nTo test the performance of F2PY generated interfaces, use\n`-DF2PY_REPORT_ATEXIT`. Then a report of various timings is printed out at the\nexit of Python. This feature may not work on all platforms, currently only\nLinux platform is supported.\n\nTo see whether F2PY generated interface performs copies of array arguments,\nuse `-DF2PY_REPORT_ON_ARRAY_COPY=<int>`. When the size of an array argument is\nlarger than `<int>`, a message about the coping is sent to `stderr`.\n\nName of an extension module. Default is `untitled`.\n\nWarning\n\nDon\u2019t use this option if a signature file (*.pyf) is used.\n\nDo [not] lower the cases in `<fortran files>`. By default, `--lower` is\nassumed with `-h` switch, and `--no-lower` without the `-h` switch.\n\nAll F2PY generated files are created in `<dirname>`. Default is\n`tempfile.mkdtemp()`.\n\nRun quietly.\n\nRun with extra verbosity.\n\nPrint the F2PY version and exit.\n\nExecute `f2py` without any options to get an up-to-date list of available\noptions.\n\nWarning\n\nThe current Python interface to the `f2py` module is not mature and may change\nin the future.\n\nFortran to Python Interface Generator.\n\nBuild extension module from a Fortran 77 source string with f2py.\n\nFortran source of module / subroutine to compile\n\nChanged in version 1.16.0: Accept str as well as bytes\n\nThe name of the compiled python module\n\nAdditional parameters passed to f2py\n\nChanged in version 1.16.0: A list of args may also be provided.\n\nPrint f2py output to screen\n\nName of the file where the fortran source is written. The default is to use a\ntemporary file with the extension provided by the `extension` parameter\n\nFilename extension if `source_fn` is not provided. The extension tells which\nfortran standard is used. The default is `f`, which implies F77 standard.\n\nNew in version 1.11.0.\n\nIf True, return a `subprocess.CompletedProcess` containing the stdout and\nstderr of the compile process, instead of just the status code.\n\nNew in version 1.20.0.\n\n0 on success, or a `subprocess.CompletedProcess` if `full_output=True`\n\nReturn the directory that contains the fortranobject.c and .h files.\n\nNote\n\nThis function is not needed when building an extension with `numpy.distutils`\ndirectly from `.f` and/or `.pyf` files in one go.\n\nPython extension modules built with f2py-generated code need to use\n`fortranobject.c` as a source file, and include the `fortranobject.h` header.\nThis function can be used to obtain the directory containing both of these\nfiles.\n\nAbsolute path to the directory containing `fortranobject.c` and\n`fortranobject.h`.\n\nSee also\n\nfunction that returns the numpy include directory\n\nNew in version 1.22.0.\n\nUnless the build system you are using has specific support for f2py, building\na Python extension using a `.pyf` signature file is a two-step process. For a\nmodule `mymod`:\n\nStep 2: build your Python extension module. This requires the following source\nfiles:\n\nEquivalent to running:\n\nwhere `<args>=string.join(<list>,' ')`, but in Python. Unless `-h` is used,\nthis function returns a dictionary containing information on generated modules\nand their dependencies on source files. For example, the command `f2py -m\nscalar scalar.f` can be executed from Python as follows\n\nYou cannot build extension modules with this function, that is, using `-c` is\nnot allowed. Use `compile` command instead\n\n"}, {"name": "1", "path": "reference/arrays.scalars", "type": "Scalars", "text": "\nPython defines only one type of a particular data class (there is only one\ninteger type, one floating-point type, etc.). This can be convenient in\napplications that don\u2019t need to be concerned with all the ways data can be\nrepresented in a computer. For scientific computing, however, more control is\noften needed.\n\nIn NumPy, there are 24 new fundamental Python types to describe different\ntypes of scalars. These type descriptors are mostly based on the types\navailable in the C language that CPython is written in, with several\nadditional types compatible with Python\u2019s types.\n\nArray scalars have the same attributes and methods as `ndarrays`. 1 This\nallows one to treat items of an array partly on the same footing as arrays,\nsmoothing out rough edges that result when mixing scalar and array operations.\n\nArray scalars live in a hierarchy (see the Figure below) of data types. They\ncan be detected using the hierarchy: For example, `isinstance(val,\nnp.generic)` will return `True` if val is an array scalar object.\nAlternatively, what kind of array scalar is present can be determined using\nother members of the data type hierarchy. Thus, for example `isinstance(val,\nnp.complexfloating)` will return `True` if val is a complex valued type, while\n`isinstance(val, np.flexible)` will return true if val is one of the flexible\nitemsize array types (`str_`, `bytes_`, `void`).\n\nFigure: Hierarchy of type objects representing the array data types. Not shown\nare the two integer types `intp` and `uintp` which just point to the integer\ntype that holds a pointer for the platform. All the number types can be\nobtained using bit-width names as well.\n\nHowever, array scalars are immutable, so none of the array scalar attributes\nare settable.\n\nThe built-in scalar types are shown below. The C-like names are associated\nwith character codes, which are shown in their descriptions. Use of the\ncharacter codes, however, is discouraged.\n\nSome of the scalar types are essentially equivalent to fundamental Python\ntypes and therefore inherit from them as well as from the generic array scalar\ntype:\n\nArray scalar type\n\nRelated Python type\n\nInherits?\n\n`int_`\n\n`int`\n\nPython 2 only\n\n`float_`\n\n`float`\n\nyes\n\n`complex_`\n\n`complex`\n\nyes\n\n`bytes_`\n\n`bytes`\n\nyes\n\n`str_`\n\n`str`\n\nyes\n\n`bool_`\n\n`bool`\n\nno\n\n`datetime64`\n\n`datetime.datetime`\n\nno\n\n`timedelta64`\n\n`datetime.timedelta`\n\nno\n\nThe `bool_` data type is very similar to the Python `bool` but does not\ninherit from it because Python\u2019s `bool` does not allow itself to be inherited\nfrom, and on the C-level the size of the actual bool data is not the same as a\nPython Boolean scalar.\n\nWarning\n\nThe `int_` type does not inherit from the `int` built-in under Python 3,\nbecause type `int` is no longer a fixed-width integer type.\n\nTip\n\nThe default data type in NumPy is `float_`.\n\nBase class for numpy scalar types.\n\nClass from which most (all?) numpy scalar types are derived. For consistency,\nexposes the same API as `ndarray`, despite many consequent attributes being\neither \u201cget-only,\u201d or completely irrelevant. This is the class from which it\nis strongly suggested users should derive custom scalar types.\n\nAbstract base class of all numeric scalar types.\n\nAbstract base class of all integer scalar types.\n\nNote\n\nThe numpy integer types mirror the behavior of C integers, and can therefore\nbe subject to Overflow Errors.\n\nAbstract base class of all signed integer scalar types.\n\nSigned integer type, compatible with C `char`.\n\n`'b'`\n\n`numpy.int8`: 8-bit signed integer (`-128` to `127`).\n\nSigned integer type, compatible with C `short`.\n\n`'h'`\n\n`numpy.int16`: 16-bit signed integer (`-32_768` to `32_767`).\n\nSigned integer type, compatible with C `int`.\n\n`'i'`\n\n`numpy.int32`: 32-bit signed integer (`-2_147_483_648` to `2_147_483_647`).\n\nSigned integer type, compatible with Python `int` and C `long`.\n\n`'l'`\n\n`numpy.int64`: 64-bit signed integer (`-9_223_372_036_854_775_808` to\n`9_223_372_036_854_775_807`).\n\n`numpy.intp`: Signed integer large enough to fit pointer, compatible with C\n`intptr_t`.\n\nSigned integer type, compatible with C `long long`.\n\n`'q'`\n\nAbstract base class of all unsigned integer scalar types.\n\nUnsigned integer type, compatible with C `unsigned char`.\n\n`'B'`\n\n`numpy.uint8`: 8-bit unsigned integer (`0` to `255`).\n\nUnsigned integer type, compatible with C `unsigned short`.\n\n`'H'`\n\n`numpy.uint16`: 16-bit unsigned integer (`0` to `65_535`).\n\nUnsigned integer type, compatible with C `unsigned int`.\n\n`'I'`\n\n`numpy.uint32`: 32-bit unsigned integer (`0` to `4_294_967_295`).\n\nUnsigned integer type, compatible with C `unsigned long`.\n\n`'L'`\n\n`numpy.uint64`: 64-bit unsigned integer (`0` to `18_446_744_073_709_551_615`).\n\n`numpy.uintp`: Unsigned integer large enough to fit pointer, compatible with C\n`uintptr_t`.\n\nSigned integer type, compatible with C `unsigned long long`.\n\n`'Q'`\n\nAbstract base class of all numeric scalar types with a (potentially) inexact\nrepresentation of the values in its range, such as floating-point numbers.\n\nNote\n\nInexact scalars are printed using the fewest decimal digits needed to\ndistinguish their value from other values of the same datatype, by judicious\nrounding. See the `unique` parameter of `format_float_positional` and\n`format_float_scientific`.\n\nThis means that variables with equal binary values but whose datatypes are of\ndifferent precisions may display differently:\n\nNote that none of these floats hold the exact value \\\\(\\frac{1}{10}\\\\); `f16`\nprints as `0.1` because it is as close to that value as possible, whereas the\nother types do not as they have more precision and therefore have closer\nvalues.\n\nConversely, floating-point scalars of different precisions which approximate\nthe same decimal value may compare unequal despite printing identically:\n\nAbstract base class of all floating-point scalar types.\n\nHalf-precision floating-point number type.\n\n`'e'`\n\n`numpy.float16`: 16-bit-precision floating-point number type: sign bit, 5 bits\nexponent, 10 bits mantissa.\n\nSingle-precision floating-point number type, compatible with C `float`.\n\n`'f'`\n\n`numpy.float32`: 32-bit-precision floating-point number type: sign bit, 8 bits\nexponent, 23 bits mantissa.\n\nDouble-precision floating-point number type, compatible with Python `float`\nand C `double`.\n\n`'d'`\n\n`numpy.float_`\n\n`numpy.float64`: 64-bit precision floating-point number type: sign bit, 11\nbits exponent, 52 bits mantissa.\n\nExtended-precision floating-point number type, compatible with C `long double`\nbut not necessarily with IEEE 754 quadruple-precision.\n\n`'g'`\n\n`numpy.longfloat`\n\n`numpy.float128`: 128-bit extended-precision floating-point number type.\n\nAbstract base class of all complex number scalar types that are made up of\nfloating-point numbers.\n\nComplex number type composed of two single-precision floating-point numbers.\n\n`'F'`\n\n`numpy.singlecomplex`\n\n`numpy.complex64`: Complex number type composed of 2 32-bit-precision\nfloating-point numbers.\n\nComplex number type composed of two double-precision floating-point numbers,\ncompatible with Python `complex`.\n\n`'D'`\n\n`numpy.cfloat`\n\n`numpy.complex_`\n\n`numpy.complex128`: Complex number type composed of 2 64-bit-precision\nfloating-point numbers.\n\nComplex number type composed of two extended-precision floating-point numbers.\n\n`'G'`\n\n`numpy.clongfloat`\n\n`numpy.longcomplex`\n\n`numpy.complex256`: Complex number type composed of 2 128-bit extended-\nprecision floating-point numbers.\n\nBoolean type (True or False), stored as a byte.\n\nWarning\n\nThe `bool_` type is not a subclass of the `int_` type (the `bool_` is not even\na number type). This is different than Python\u2019s default implementation of\n`bool` as a sub-class of `int`.\n\n`'?'`\n\n`numpy.bool8`\n\nIf created from a 64-bit integer, it represents an offset from\n`1970-01-01T00:00:00`. If created from string, the string can be in ISO 8601\ndate or datetime format.\n\nSee Datetimes and Timedeltas for more information.\n\n`'M'`\n\nA timedelta stored as a 64-bit integer.\n\nSee Datetimes and Timedeltas for more information.\n\n`'m'`\n\nAny Python object.\n\n`'O'`\n\nNote\n\nThe data actually stored in object arrays (i.e., arrays having dtype\n`object_`) are references to Python objects, not the objects themselves.\nHence, object arrays behave more like usual Python `lists`, in the sense that\ntheir contents need not be of the same Python type.\n\nThe object type is also special because an array containing `object_` items\ndoes not return an `object_` object on item access, but instead returns the\nactual object that the array item refers to.\n\nThe following data types are flexible: they have no predefined size and the\ndata they describe can be of different length in different arrays. (In the\ncharacter codes `#` is an integer denoting how many elements the data type\nconsists of.)\n\nAbstract base class of all scalar types without predefined length. The actual\nsize of these types depends on the specific `np.dtype` instantiation.\n\nA byte string.\n\nWhen used in arrays, this type strips trailing null bytes.\n\n`'S'`\n\n`numpy.string_`\n\nA unicode string.\n\nWhen used in arrays, this type strips trailing null codepoints.\n\nUnlike the builtin `str`, this supports the Buffer Protocol, exposing its\ncontents as UCS4:\n\n`'U'`\n\n`numpy.unicode_`\n\nEither an opaque sequence of bytes, or a structure.\n\nStructured `void` scalars can only be constructed via extraction from\nStructured arrays:\n\n`'V'`\n\nWarning\n\nSee Note on string types.\n\nNumeric Compatibility: If you used old typecode characters in your Numeric\ncode (which was never recommended), you will need to change some of them to\nthe new characters. In particular, the needed changes are `c -> S1`, `b -> B`,\n`1 -> b`, `s -> h`, `w -> H`, and `u -> I`. These changes make the type\ncharacter convention more consistent with other Python modules such as the\n`struct` module.\n\nAlong with their (mostly) C-derived names, the integer, float, and complex\ndata-types are also available using a bit-width convention so that an array of\nthe right size can always be ensured. Two aliases (`numpy.intp` and\n`numpy.uintp`) pointing to the integer type that is sufficiently large to hold\na C pointer are also provided.\n\nalias of `numpy.bool_`\n\nAliases for the signed integer types (one of `numpy.byte`, `numpy.short`,\n`numpy.intc`, `numpy.int_` and `numpy.longlong`) with the specified number of\nbits.\n\nCompatible with the C99 `int8_t`, `int16_t`, `int32_t`, and `int64_t`,\nrespectively.\n\nAlias for the unsigned integer types (one of `numpy.ubyte`, `numpy.ushort`,\n`numpy.uintc`, `numpy.uint` and `numpy.ulonglong`) with the specified number\nof bits.\n\nCompatible with the C99 `uint8_t`, `uint16_t`, `uint32_t`, and `uint64_t`,\nrespectively.\n\nAlias for the signed integer type (one of `numpy.byte`, `numpy.short`,\n`numpy.intc`, `numpy.int_` and `np.longlong`) that is the same size as a\npointer.\n\nCompatible with the C `intptr_t`.\n\n`'p'`\n\nAlias for the unsigned integer type (one of `numpy.ubyte`, `numpy.ushort`,\n`numpy.uintc`, `numpy.uint` and `np.ulonglong`) that is the same size as a\npointer.\n\nCompatible with the C `uintptr_t`.\n\n`'P'`\n\nalias of `numpy.half`\n\nalias of `numpy.single`\n\nalias of `numpy.double`\n\nAlias for `numpy.longdouble`, named after its size in bits. The existence of\nthese aliases depends on the platform.\n\nalias of `numpy.csingle`\n\nalias of `numpy.cdouble`\n\nAlias for `numpy.clongdouble`, named after its size in bits. The existence of\nthese aliases depends on the platform.\n\nThe first two of these are conveniences which resemble the names of the\nbuiltin types, in the same style as `bool_`, `int_`, `str_`, `bytes_`, and\n`object_`:\n\nalias of `numpy.double`\n\nalias of `numpy.cdouble`\n\nSome more use alternate naming conventions for extended-precision floats and\ncomplex numbers:\n\nalias of `numpy.longdouble`\n\nalias of `numpy.csingle`\n\nalias of `numpy.cdouble`\n\nalias of `numpy.clongdouble`\n\nalias of `numpy.clongdouble`\n\nThe following aliases originate from Python 2, and it is recommended that they\nnot be used in new code.\n\nalias of `numpy.bytes_`\n\nalias of `numpy.str_`\n\nThe array scalar objects have an `array priority` of `NPY_SCALAR_PRIORITY`\n(-1,000,000.0). They also do not (yet) have a `ctypes` attribute. Otherwise,\nthey share the same attributes as arrays:\n\n`generic.flags`\n\nThe integer value of flags.\n\n`generic.shape`\n\nTuple of array dimensions.\n\n`generic.strides`\n\nTuple of bytes steps in each dimension.\n\n`generic.ndim`\n\nThe number of array dimensions.\n\n`generic.data`\n\nPointer to start of data.\n\n`generic.size`\n\nThe number of elements in the gentype.\n\n`generic.itemsize`\n\nThe length of one element in bytes.\n\n`generic.base`\n\nScalar attribute identical to the corresponding array attribute.\n\n`generic.dtype`\n\nGet array data-descriptor.\n\n`generic.real`\n\nThe real part of the scalar.\n\n`generic.imag`\n\nThe imaginary part of the scalar.\n\n`generic.flat`\n\nA 1-D view of the scalar.\n\n`generic.T`\n\nScalar attribute identical to the corresponding array attribute.\n\n`generic.__array_interface__`\n\nArray protocol: Python side\n\n`generic.__array_struct__`\n\nArray protocol: struct\n\n`generic.__array_priority__`\n\nArray priority.\n\n`generic.__array_wrap__`\n\nsc.__array_wrap__(obj) return scalar from array\n\nSee also\n\nIndexing routines, Data type objects (dtype)\n\nArray scalars can be indexed like 0-dimensional arrays: if x is an array\nscalar,\n\nArray scalars have exactly the same methods as arrays. The default behavior of\nthese methods is to internally convert the scalar to an equivalent\n0-dimensional array and to call the corresponding array method. In addition,\nmath operations on array scalars are defined so that the same hardware flags\nare set and used to interpret the results as for ufunc, so that the error\nstate used for ufuncs also carries over to the math on array scalars.\n\nThe exceptions to the above rules are given below:\n\n`generic.__array__`\n\nsc.__array__(dtype) return 0-dim array from scalar with specified dtype\n\n`generic.__array_wrap__`\n\nsc.__array_wrap__(obj) return scalar from array\n\n`generic.squeeze`\n\nScalar method identical to the corresponding array attribute.\n\n`generic.byteswap`\n\nScalar method identical to the corresponding array attribute.\n\n`generic.__reduce__`\n\nHelper for pickle.\n\n`generic.__setstate__`\n\n`generic.setflags`\n\nScalar method identical to the corresponding array attribute.\n\nUtility method for typing:\n\n`number.__class_getitem__`(item, /)\n\nReturn a parametrized wrapper around the `number` type.\n\nThere are two ways to effectively define a new array scalar type (apart from\ncomposing structured types dtypes from the built-in scalar types): One way is\nto simply subclass the `ndarray` and overwrite the methods of interest. This\nwill work to a degree, but internally certain behaviors are fixed by the data\ntype of the array. To fully customize the data type of an array you need to\ndefine a new data-type, and register it with NumPy. Such new types can only be\ndefined in C, using the NumPy C-API.\n\n"}, {"name": "1", "path": "reference/random/parallel", "type": "Parallel Applications", "text": "\nThere are three strategies implemented that can be used to produce repeatable\npseudo-random numbers across multiple processes (local or distributed).\n\n`SeedSequence` implements an algorithm to process a user-provided seed,\ntypically as an integer of some size, and to convert it into an initial state\nfor a `BitGenerator`. It uses hashing techniques to ensure that low-quality\nseeds are turned into high quality initial states (at least, with very high\nprobability).\n\nFor example, `MT19937` has a state consisting of 624 `uint32` integers. A\nnaive way to take a 32-bit integer seed would be to just set the last element\nof the state to the 32-bit seed and leave the rest 0s. This is a valid state\nfor `MT19937`, but not a good one. The Mersenne Twister algorithm suffers if\nthere are too many 0s. Similarly, two adjacent 32-bit integer seeds (i.e.\n`12345` and `12346`) would produce very similar streams.\n\n`SeedSequence` avoids these problems by using successions of integer hashes\nwith good avalanche properties to ensure that flipping any bit in the input\ninput has about a 50% chance of flipping any bit in the output. Two input\nseeds that are very close to each other will produce initial states that are\nvery far from each other (with very high probability). It is also constructed\nin such a way that you can provide arbitrary-sized integers or lists of\nintegers. `SeedSequence` will take all of the bits that you provide and mix\nthem together to produce however many bits the consuming `BitGenerator` needs\nto initialize itself.\n\nThese properties together mean that we can safely mix together the usual user-\nprovided seed with simple incrementing counters to get `BitGenerator` states\nthat are (to very high probability) independent of each other. We can wrap\nthis together into an API that is easy to use and difficult to misuse.\n\nChild `SeedSequence` objects can also spawn to make grandchildren, and so on.\nEach `SeedSequence` has its position in the tree of spawned `SeedSequence`\nobjects mixed in with the user-provided seed to generate independent (with\nvery high probability) streams.\n\nThis feature lets you make local decisions about when and how to split up\nstreams without coordination between processes. You do not have to preallocate\nspace to avoid overlapping or request streams from a common global service.\nThis general \u201ctree-hashing\u201d scheme is not unique to numpy but not yet\nwidespread. Python has increasingly-flexible mechanisms for parallelization\navailable, and this scheme fits in very well with that kind of use.\n\nUsing this scheme, an upper bound on the probability of a collision can be\nestimated if one knows the number of streams that you derive. `SeedSequence`\nhashes its inputs, both the seed and the spawn-tree-path, down to a 128-bit\npool by default. The probability that there is a collision in that pool,\npessimistically-estimated (1), will be about \\\\(n^2*2^{-128}\\\\) where `n` is\nthe number of streams spawned. If a program uses an aggressive million\nstreams, about \\\\(2^{20}\\\\), then the probability that at least one pair of\nthem are identical is about \\\\(2^{-88}\\\\), which is in solidly-ignorable\nterritory (2).\n\nThe algorithm is carefully designed to eliminate a number of possible ways to\ncollide. For example, if one only does one level of spawning, it is guaranteed\nthat all states will be unique. But it\u2019s easier to estimate the naive upper\nbound on a napkin and take comfort knowing that the probability is actually\nlower.\n\nIn this calculation, we can mostly ignore the amount of numbers drawn from\neach stream. See Upgrading PCG64 with PCG64DXSM for the technical details\nabout `PCG64`. The other PRNGs we provide have some extra protection built in\nthat avoids overlaps if the `SeedSequence` pools differ in the slightest bit.\n`PCG64DXSM` has \\\\(2^{127}\\\\) separate cycles determined by the seed in\naddition to the position in the \\\\(2^{128}\\\\) long period for each cycle, so\none has to both get on or near the same cycle and seed a nearby position in\nthe cycle. `Philox` has completely independent cycles determined by the seed.\n`SFC64` incorporates a 64-bit counter so every unique seed is at least\n\\\\(2^{64}\\\\) iterations away from any other seed. And finally, `MT19937` has\njust an unimaginably huge period. Getting a collision internal to\n`SeedSequence` is the way a failure would be observed.\n\n`Philox` is a counter-based RNG based which generates values by encrypting an\nincrementing counter using weak cryptographic primitives. The seed determines\nthe key that is used for the encryption. Unique keys create unique,\nindependent streams. `Philox` lets you bypass the seeding algorithm to\ndirectly set the 128-bit key. Similar, but different, keys will still create\nindependent streams.\n\nThis scheme does require that you avoid reusing stream IDs. This may require\ncoordination between the parallel processes.\n\n`jumped` advances the state of the BitGenerator as-if a large number of random\nnumbers have been drawn, and returns a new instance with this state. The\nspecific number of draws varies by BitGenerator, and ranges from \\\\(2^{64}\\\\)\nto \\\\(2^{128}\\\\). Additionally, the as-if draws also depend on the size of the\ndefault random number produced by the specific BitGenerator. The BitGenerators\nthat support `jumped`, along with the period of the BitGenerator, the size of\nthe jump and the bits in the default unsigned random are listed below.\n\nBitGenerator\n\nPeriod\n\nJump Size\n\nBits per Draw\n\nMT19937\n\n\\\\(2^{19937}-1\\\\)\n\n\\\\(2^{128}\\\\)\n\n32\n\nPCG64\n\n\\\\(2^{128}\\\\)\n\n\\\\(~2^{127}\\\\) (3)\n\n64\n\nPCG64DXSM\n\n\\\\(2^{128}\\\\)\n\n\\\\(~2^{127}\\\\) (3)\n\n64\n\nPhilox\n\n\\\\(2^{256}\\\\)\n\n\\\\(2^{128}\\\\)\n\n64\n\nThe jump size is \\\\((\\phi-1)*2^{128}\\\\) where \\\\(\\phi\\\\) is the golden ratio.\nAs the jumps wrap around the period, the actual distances between neighboring\nstreams will slowly grow smaller than the jump size, but using the golden\nratio this way is a classic method of constructing a low-discrepancy sequence\nthat spreads out the states around the period optimally. You will not be able\nto jump enough to make those distances small enough to overlap in your\nlifetime.\n\n`jumped` can be used to produce long blocks which should be long enough to not\noverlap.\n\nWhen using `jumped`, one does have to take care not to jump to a stream that\nwas already used. In the above example, one could not later use\n`blocked_rng[0].jumped()` as it would overlap with `blocked_rng[1]`. Like with\nthe independent streams, if the main process here wants to split off 10 more\nstreams by jumping, then it needs to start with `range(10, 20)`, otherwise it\nwould recreate the same streams. On the other hand, if you carefully construct\nthe streams, then you are guaranteed to have streams that do not overlap.\n\n"}, {"name": "1", "path": "user/basics.broadcasting", "type": "User Guide", "text": "\nSee also\n\n`numpy.broadcast`\n\nThe term broadcasting describes how NumPy treats arrays with different shapes\nduring arithmetic operations. Subject to certain constraints, the smaller\narray is \u201cbroadcast\u201d across the larger array so that they have compatible\nshapes. Broadcasting provides a means of vectorizing array operations so that\nlooping occurs in C instead of Python. It does this without making needless\ncopies of data and usually leads to efficient algorithm implementations. There\nare, however, cases where broadcasting is a bad idea because it leads to\ninefficient use of memory that slows computation.\n\nNumPy operations are usually done on pairs of arrays on an element-by-element\nbasis. In the simplest case, the two arrays must have exactly the same shape,\nas in the following example:\n\nNumPy\u2019s broadcasting rule relaxes this constraint when the arrays\u2019 shapes meet\ncertain constraints. The simplest broadcasting example occurs when an array\nand a scalar value are combined in an operation:\n\nThe result is equivalent to the previous example where `b` was an array. We\ncan think of the scalar `b` being stretched during the arithmetic operation\ninto an array with the same shape as `a`. The new elements in `b`, as shown in\nFigure 1, are simply copies of the original scalar. The stretching analogy is\nonly conceptual. NumPy is smart enough to use the original scalar value\nwithout actually making copies so that broadcasting operations are as memory\nand computationally efficient as possible.\n\nFigure 1\n\nIn the simplest example of broadcasting, the scalar `b` is stretched to become\nan array of same shape as `a` so the shapes are compatible for element-by-\nelement multiplication.\n\nThe code in the second example is more efficient than that in the first\nbecause broadcasting moves less memory around during the multiplication (`b`\nis a scalar rather than an array).\n\nWhen operating on two arrays, NumPy compares their shapes element-wise. It\nstarts with the trailing (i.e. rightmost) dimensions and works its way left.\nTwo dimensions are compatible when\n\nIf these conditions are not met, a `ValueError: operands could not be\nbroadcast together` exception is thrown, indicating that the arrays have\nincompatible shapes. The size of the resulting array is the size that is not 1\nalong each axis of the inputs.\n\nArrays do not need to have the same number of dimensions. For example, if you\nhave a `256x256x3` array of RGB values, and you want to scale each color in\nthe image by a different value, you can multiply the image by a one-\ndimensional array with 3 values. Lining up the sizes of the trailing axes of\nthese arrays according to the broadcast rules, shows that they are compatible:\n\nWhen either of the dimensions compared is one, the other is used. In other\nwords, dimensions with size 1 are stretched or \u201ccopied\u201d to match the other.\n\nIn the following example, both the `A` and `B` arrays have axes with length\none that are expanded to a larger size during the broadcast operation:\n\nA set of arrays is called \u201cbroadcastable\u201d to the same shape if the above rules\nproduce a valid result.\n\nFor example, if `a.shape` is (5,1), `b.shape` is (1,6), `c.shape` is (6,) and\n`d.shape` is () so that d is a scalar, then a, b, c, and d are all\nbroadcastable to dimension (5,6); and\n\nHere are some more examples:\n\nHere are examples of shapes that do not broadcast:\n\nAn example of broadcasting when a 1-d array is added to a 2-d array:\n\nAs shown in Figure 2, `b` is added to each row of `a`. In Figure 3, an\nexception is raised because of the incompatible shapes.\n\nFigure 2\n\nA one dimensional array added to a two dimensional array results in\nbroadcasting if number of 1-d array elements matches the number of 2-d array\ncolumns.\n\nFigure 3\n\nWhen the trailing dimensions of the arrays are unequal, broadcasting fails\nbecause it is impossible to align the values in the rows of the 1st array with\nthe elements of the 2nd arrays for element-by-element addition.\n\nBroadcasting provides a convenient way of taking the outer product (or any\nother outer operation) of two arrays. The following example shows an outer\naddition operation of two 1-d arrays:\n\nFigure 4\n\nIn some cases, broadcasting stretches both arrays to form an output array\nlarger than either of the initial arrays.\n\nHere the `newaxis` index operator inserts a new axis into `a`, making it a\ntwo-dimensional `4x1` array. Combining the `4x1` array with `b`, which has\nshape `(3,)`, yields a `4x3` array.\n\nBroadcasting comes up quite often in real world problems. A typical example\noccurs in the vector quantization (VQ) algorithm used in information theory,\nclassification, and other related areas. The basic operation in VQ finds the\nclosest point in a set of points, called `codes` in VQ jargon, to a given\npoint, called the `observation`. In the very simple, two-dimensional case\nshown below, the values in `observation` describe the weight and height of an\nathlete to be classified. The `codes` represent different classes of athletes.\n1 Finding the closest point requires calculating the distance between\nobservation and each of the codes. The shortest distance provides the best\nmatch. In this example, `codes[0]` is the closest class indicating that the\nathlete is likely a basketball player.\n\nIn this example, the `observation` array is stretched to match the shape of\nthe `codes` array:\n\nFigure 5\n\nThe basic operation of vector quantization calculates the distance between an\nobject to be classified, the dark square, and multiple known codes, the gray\ncircles. In this simple case, the codes represent individual classes. More\ncomplex cases use multiple codes per class.\n\nTypically, a large number of `observations`, perhaps read from a database, are\ncompared to a set of `codes`. Consider this scenario:\n\nThe three-dimensional array, `diff`, is a consequence of broadcasting, not a\nnecessity for the calculation. Large data sets will generate a large\nintermediate array that is computationally inefficient. Instead, if each\nobservation is calculated individually using a Python loop around the code in\nthe two-dimensional example above, a much smaller array is used.\n\nBroadcasting is a powerful tool for writing short and usually intuitive code\nthat does its computations very efficiently in C. However, there are cases\nwhen broadcasting uses unnecessarily large amounts of memory for a particular\nalgorithm. In these cases, it is better to write the algorithm\u2019s outer loop in\nPython. This may also produce more readable code, as algorithms that use\nbroadcasting tend to become more difficult to interpret as the number of\ndimensions in the broadcast increases.\n\nIn this example, weight has more impact on the distance calculation than\nheight because of the larger values. In practice, it is important to normalize\nthe height and weight, often by their standard deviation across the data set,\nso that both have equal influence on the distance calculation.\n\n"}, {"name": "1", "path": "reference/routines.polynomials", "type": "Polynomials", "text": "\nPolynomials in NumPy can be created, manipulated, and even fitted using the\nconvenience classes of the `numpy.polynomial` package, introduced in NumPy\n1.4.\n\nPrior to NumPy 1.4, `numpy.poly1d` was the class of choice and it is still\navailable in order to maintain backward compatibility. However, the newer\n`polynomial package` is more complete and its `convenience classes` provide a\nmore consistent, better-behaved interface for working with polynomial\nexpressions. Therefore `numpy.polynomial` is recommended for new coding.\n\nNote\n\nTerminology\n\nThe term polynomial module refers to the old API defined in\n`numpy.lib.polynomial`, which includes the `numpy.poly1d` class and the\npolynomial functions prefixed with poly accessible from the `numpy` namespace\n(e.g. `numpy.polyadd`, `numpy.polyval`, `numpy.polyfit`, etc.).\n\nThe term polynomial package refers to the new API defined in\n`numpy.polynomial`, which includes the convenience classes for the different\nkinds of polynomials (`numpy.polynomial.Polynomial`,\n`numpy.polynomial.Chebyshev`, etc.).\n\nAs noted above, the `poly1d class` and associated functions defined in\n`numpy.lib.polynomial`, such as `numpy.polyfit` and `numpy.poly`, are\nconsidered legacy and should not be used in new code. Since NumPy version 1.4,\nthe `numpy.polynomial` package is preferred for working with polynomials.\n\nThe following table highlights some of the main differences between the legacy\npolynomial module and the polynomial package for common tasks. The\n`Polynomial` class is imported for brevity:\n\nHow to\u2026\n\nLegacy (`numpy.poly1d`)\n\n`numpy.polynomial`\n\nCreate a polynomial object from coefficients 1\n\n`p = np.poly1d([1, 2, 3])`\n\n`p = Polynomial([3, 2, 1])`\n\nCreate a polynomial object from roots\n\n`r = np.poly([-1, 1])` `p = np.poly1d(r)`\n\n`p = Polynomial.fromroots([-1, 1])`\n\nFit a polynomial of degree `deg` to data\n\n`np.polyfit(x, y, deg)`\n\n`Polynomial.fit(x, y, deg)`\n\nNote the reversed ordering of the coefficients\n\nThere are significant differences between `numpy.lib.polynomial` and\n`numpy.polynomial`. The most significant difference is the ordering of the\ncoefficients for the polynomial expressions. The various routines in\n`numpy.polynomial` all deal with series whose coefficients go from degree zero\nupward, which is the reverse order of the poly1d convention. The easy way to\nremember this is that indices correspond to degree, i.e., `coef[i]` is the\ncoefficient of the term of degree i.\n\nThough the difference in convention may be confusing, it is straightforward to\nconvert from the legacy polynomial API to the new. For example, the following\ndemonstrates how you would convert a `numpy.poly1d` instance representing the\nexpression \\\\(x^{2} + 2x + 3\\\\) to a `Polynomial` instance representing the\nsame expression:\n\nIn addition to the `coef` attribute, polynomials from the polynomial package\nalso have `domain` and `window` attributes. These attributes are most relevant\nwhen fitting polynomials to data, though it should be noted that polynomials\nwith different `domain` and `window` attributes are not considered equal, and\ncan\u2019t be mixed in arithmetic:\n\nSee the documentation for the convenience classes for further details on the\n`domain` and `window` attributes.\n\nAnother major difference between the legacy polynomial module and the\npolynomial package is polynomial fitting. In the old module, fitting was done\nvia the `polyfit` function. In the polynomial package, the `fit` class method\nis preferred. For example, consider a simple linear fit to the following data:\n\nWith the legacy polynomial module, a linear fit (i.e. polynomial of degree 1)\ncould be applied to these data with `polyfit`:\n\nWith the new polynomial API, the `fit` class method is preferred:\n\nNote that the coefficients are given in the scaled domain defined by the\nlinear mapping between the `window` and `domain`. `convert` can be used to get\nthe coefficients in the unscaled data domain.\n\nIn addition to standard power series polynomials, the polynomial package\nprovides several additional kinds of polynomials including Chebyshev, Hermite\n(two subtypes), Laguerre, and Legendre polynomials. Each of these has an\nassociated `convenience class` available from the `numpy.polynomial` namespace\nthat provides a consistent interface for working with polynomials regardless\nof their type.\n\nDocumentation pertaining to specific functions defined for each kind of\npolynomial individually can be found in the corresponding module\ndocumentation:\n\n"}, {"name": "1", "path": "reference/routines.polynomials.chebyshev", "type": "Chebyshev Series ( \n        \n         numpy.polynomial.chebyshev\n        \n        )", "text": "\nThis module provides a number of objects (mostly functions) useful for dealing\nwith Chebyshev series, including a `Chebyshev` class that encapsulates the\nusual arithmetic operations. (General information on how this module\nrepresents and works with such polynomials is in the docstring for its\n\u201cparent\u201d sub-package, `numpy.polynomial`).\n\n`Chebyshev`(coef[, domain, window])\n\nA Chebyshev series class.\n\n`chebdomain`\n\nAn array object represents a multidimensional, homogeneous array of fixed-size\nitems.\n\n`chebzero`\n\nAn array object represents a multidimensional, homogeneous array of fixed-size\nitems.\n\n`chebone`\n\nAn array object represents a multidimensional, homogeneous array of fixed-size\nitems.\n\n`chebx`\n\nAn array object represents a multidimensional, homogeneous array of fixed-size\nitems.\n\n`chebadd`(c1, c2)\n\nAdd one Chebyshev series to another.\n\n`chebsub`(c1, c2)\n\nSubtract one Chebyshev series from another.\n\n`chebmulx`(c)\n\nMultiply a Chebyshev series by x.\n\n`chebmul`(c1, c2)\n\nMultiply one Chebyshev series by another.\n\n`chebdiv`(c1, c2)\n\nDivide one Chebyshev series by another.\n\n`chebpow`(c, pow[, maxpower])\n\nRaise a Chebyshev series to a power.\n\n`chebval`(x, c[, tensor])\n\nEvaluate a Chebyshev series at points x.\n\n`chebval2d`(x, y, c)\n\nEvaluate a 2-D Chebyshev series at points (x, y).\n\n`chebval3d`(x, y, z, c)\n\nEvaluate a 3-D Chebyshev series at points (x, y, z).\n\n`chebgrid2d`(x, y, c)\n\nEvaluate a 2-D Chebyshev series on the Cartesian product of x and y.\n\n`chebgrid3d`(x, y, z, c)\n\nEvaluate a 3-D Chebyshev series on the Cartesian product of x, y, and z.\n\n`chebder`(c[, m, scl, axis])\n\nDifferentiate a Chebyshev series.\n\n`chebint`(c[, m, k, lbnd, scl, axis])\n\nIntegrate a Chebyshev series.\n\n`chebfromroots`(roots)\n\nGenerate a Chebyshev series with given roots.\n\n`chebroots`(c)\n\nCompute the roots of a Chebyshev series.\n\n`chebvander`(x, deg)\n\nPseudo-Vandermonde matrix of given degree.\n\n`chebvander2d`(x, y, deg)\n\nPseudo-Vandermonde matrix of given degrees.\n\n`chebvander3d`(x, y, z, deg)\n\nPseudo-Vandermonde matrix of given degrees.\n\n`chebgauss`(deg)\n\nGauss-Chebyshev quadrature.\n\n`chebweight`(x)\n\nThe weight function of the Chebyshev polynomials.\n\n`chebcompanion`(c)\n\nReturn the scaled companion matrix of c.\n\n`chebfit`(x, y, deg[, rcond, full, w])\n\nLeast squares fit of Chebyshev series to data.\n\n`chebpts1`(npts)\n\nChebyshev points of the first kind.\n\n`chebpts2`(npts)\n\nChebyshev points of the second kind.\n\n`chebtrim`(c[, tol])\n\nRemove \"small\" \"trailing\" coefficients from a polynomial.\n\n`chebline`(off, scl)\n\nChebyshev series whose graph is a straight line.\n\n`cheb2poly`(c)\n\nConvert a Chebyshev series to a polynomial.\n\n`poly2cheb`(pol)\n\nConvert a polynomial to a Chebyshev series.\n\n`chebinterpolate`(func, deg[, args])\n\nInterpolate a function at the Chebyshev points of the first kind.\n\n`numpy.polynomial`\n\nThe implementations of multiplication, division, integration, and\ndifferentiation use the algebraic identities [1]:\n\nwhere\n\nThese identities allow a Chebyshev series to be expressed as a finite,\nsymmetric Laurent series. In this module, this sort of Laurent series is\nreferred to as a \u201cz-series.\u201d\n\nA. T. Benjamin, et al., \u201cCombinatorial Trigonometry with Chebyshev\nPolynomials,\u201d Journal of Statistical Planning and Inference 14, 2008\n(https://web.archive.org/web/20080221202153/https://www.math.hmc.edu/~benjamin/papers/CombTrig.pdf,\npg. 4)\n\n"}, {"name": "add_data_dir()", "path": "reference/distutils#numpy.distutils.misc_util.Configuration.add_data_dir", "type": "Packaging ( \n    \n     numpy.distutils\n    \n    )", "text": "\nRecursively add files under data_path to data_files list.\n\nRecursively add files under data_path to the list of data_files to be\ninstalled (and distributed). The data_path can be either a relative path-name,\nor an absolute path-name, or a 2-tuple where the first argument shows where in\nthe install directory the data directory should be installed to.\n\nArgument can be either\n\nRules for installation paths:\n\nFor example suppose the source directory contains fun/foo.dat and\nfun/bar/car.dat:\n\nWill install data-files to the locations:\n\n"}, {"name": "add_data_files()", "path": "reference/distutils#numpy.distutils.misc_util.Configuration.add_data_files", "type": "Packaging ( \n    \n     numpy.distutils\n    \n    )", "text": "\nAdd data files to configuration data_files.\n\nArgument(s) can be either\n\nThe form of each element of the files sequence is very flexible allowing many\ncombinations of where to get the files from the package and where they should\nultimately be installed on the system. The most basic usage is for an element\nof the files argument sequence to be a simple filename. This will cause that\nfile from the local path to be installed to the installation path of the\nself.name package (package path). The file argument can also be a relative\npath in which case the entire relative path will be installed into the package\ndirectory. Finally, the file can be an absolute path name in which case the\nfile will be found at the absolute path name but installed to the package\npath.\n\nThis basic behavior can be augmented by passing a 2-tuple in as the file\nargument. The first element of the tuple should specify the relative path\n(under the package install directory) where the remaining sequence of files\nshould be installed to (it has nothing to do with the file-names in the source\ndistribution). The second element of the tuple is the sequence of files that\nshould be installed. The files in this sequence can be filenames, relative\npaths, or absolute paths. For absolute paths the file will be installed in the\ntop-level package installation directory (regardless of the first argument).\nFilenames and relative path names will be installed in the package install\ndirectory under the path name given as the first element of the tuple.\n\nRules for installation paths:\n\nAn additional feature is that the path to a data-file can actually be a\nfunction that takes no arguments and returns the actual path(s) to the data-\nfiles. This is useful when the data files are generated while building the\npackage.\n\nAdd files to the list of data_files to be included with the package.\n\nwill install these data files to:\n\nwhere <package install directory> is the package (or sub-package) directory\nsuch as \u2018/usr/lib/python2.4/site-packages/mypackage\u2019 (\u2018C: Python2.4 Lib site-\npackages mypackage\u2019) or \u2018/usr/lib/python2.4/site-\npackages/mypackage/mysubpackage\u2019 (\u2018C: Python2.4 Lib site-packages mypackage\nmysubpackage\u2019).\n\n"}, {"name": "add_extension()", "path": "reference/distutils#numpy.distutils.misc_util.Configuration.add_extension", "type": "Packaging ( \n    \n     numpy.distutils\n    \n    )", "text": "\nAdd extension to configuration.\n\nCreate and add an Extension instance to the ext_modules list. This method also\ntakes the following optional keyword arguments that are passed on to the\nExtension constructor.\n\nname of the extension\n\nlist of the sources. The list of sources may contain functions (called source\ngenerators) which must take an extension instance and a build directory as\ninputs and return a source file or list of source files or None. If None is\nreturned then no sources are generated. If the Extension instance has no\nsources after processing all source generators, then no extension module is\nbuilt.\n\nThe depends list contains paths to files or directories that the sources of\nthe extension module depend on. If any path in the depends list is newer than\nthe extension module, then the module will be rebuilt.\n\ndict or list of dict of keywords to be appended to keywords.\n\nThe self.paths(\u2026) method is applied to all lists that may contain paths.\n\n"}, {"name": "add_headers()", "path": "reference/distutils#numpy.distutils.misc_util.Configuration.add_headers", "type": "Packaging ( \n    \n     numpy.distutils\n    \n    )", "text": "\nAdd installable headers to configuration.\n\nAdd the given sequence of files to the beginning of the headers list. By\ndefault, headers will be installed under <python-\ninclude>/<self.name.replace(\u2018.\u2019,\u2019/\u2019)>/ directory. If an item of files is a\ntuple, then its first argument specifies the actual installation location\nrelative to the <python-include> path.\n\nArgument(s) can be either:\n\n"}, {"name": "add_include_dirs()", "path": "reference/distutils#numpy.distutils.misc_util.Configuration.add_include_dirs", "type": "Packaging ( \n    \n     numpy.distutils\n    \n    )", "text": "\nAdd paths to configuration include directories.\n\nAdd the given sequence of paths to the beginning of the include_dirs list.\nThis list will be visible to all extension modules of the current package.\n\n"}, {"name": "add_installed_library()", "path": "reference/distutils#numpy.distutils.misc_util.Configuration.add_installed_library", "type": "Packaging ( \n    \n     numpy.distutils\n    \n    )", "text": "\nSimilar to add_library, but the specified library is installed.\n\nMost C libraries used with `distutils` are only used to build python\nextensions, but libraries built through this method will be installed so that\nthey can be reused by third-party packages.\n\nName of the installed library.\n\nList of the library\u2019s source files. See `add_library` for details.\n\nPath to install the library, relative to the current sub-package.\n\nThe following keys are allowed:\n\nSee also\n\nThe best way to encode the options required to link against the specified C\nlibraries is to use a \u201clibname.ini\u201d file, and use `get_info` to retrieve the\nrequired options (see `add_npy_pkg_config` for more information).\n\n"}, {"name": "add_library()", "path": "reference/distutils#numpy.distutils.misc_util.Configuration.add_library", "type": "Packaging ( \n    \n     numpy.distutils\n    \n    )", "text": "\nAdd library to configuration.\n\nName of the extension.\n\nList of the sources. The list of sources may contain functions (called source\ngenerators) which must take an extension instance and a build directory as\ninputs and return a source file or list of source files or None. If None is\nreturned then no sources are generated. If the Extension instance has no\nsources after processing all source generators, then no extension module is\nbuilt.\n\nThe following keys are allowed:\n\n"}, {"name": "add_npy_pkg_config()", "path": "reference/distutils#numpy.distutils.misc_util.Configuration.add_npy_pkg_config", "type": "Packaging ( \n    \n     numpy.distutils\n    \n    )", "text": "\nGenerate and install a npy-pkg config file from a template.\n\nThe config file generated from `template` is installed in the given install\ndirectory, using `subst_dict` for variable substitution.\n\nThe path of the template, relatively to the current package path.\n\nWhere to install the npy-pkg config file, relatively to the current package\npath.\n\nIf given, any string of the form `@key@` will be replaced by `subst_dict[key]`\nin the template file when installed. The install prefix is always available\nthrough the variable `@prefix@`, since the install prefix is not easy to get\nreliably from setup.py.\n\nSee also\n\nThis works for both standard installs and in-place builds, i.e. the `@prefix@`\nrefer to the source directory for in-place builds.\n\nAssuming the foo.ini.in file has the following content:\n\nThe generated file will have the following content:\n\nand will be installed as foo.ini in the \u2018lib\u2019 subpath.\n\nWhen cross-compiling with numpy distutils, it might be necessary to use\nmodified npy-pkg-config files. Using the default/generated files will link\nwith the host libraries (i.e. libnpymath.a). For cross-compilation you of-\ncourse need to link with target libraries, while using the host Python\ninstallation.\n\nYou can copy out the numpy/core/lib/npy-pkg-config directory, add a pkgdir\nvalue to the .ini files and set NPY_PKG_CONFIG_PATH environment variable to\npoint to the directory with the modified npy-pkg-config files.\n\nExample npymath.ini modified for cross-compilation:\n\n"}, {"name": "add_scripts()", "path": "reference/distutils#numpy.distutils.misc_util.Configuration.add_scripts", "type": "Packaging ( \n    \n     numpy.distutils\n    \n    )", "text": "\nAdd scripts to configuration.\n\nAdd the sequence of files to the beginning of the scripts list. Scripts will\nbe installed under the <prefix>/bin/ directory.\n\n"}, {"name": "add_subpackage()", "path": "reference/distutils#numpy.distutils.misc_util.Configuration.add_subpackage", "type": "Packaging ( \n    \n     numpy.distutils\n    \n    )", "text": "\nAdd a sub-package to the current Configuration instance.\n\nThis is useful in a setup.py script for adding sub-packages to a package.\n\nname of the subpackage\n\nif given, the subpackage path such as the subpackage is in subpackage_path /\nsubpackage_name. If None,the subpackage is assumed to be located in the local\npath / subpackage_name.\n\n"}, {"name": "Additional Git Resources", "path": "dev/gitwash/git_resources", "type": "Development", "text": "\nThere are many ways of working with git; here are some posts on the rules of\nthumb that other projects have come up with:\n\nYou can get these on your own machine with (e.g) `git help push` or (same\nthing) `git push --help`, but, for convenience, here are the online manual\npages for some common commands:\n\n"}, {"name": "Advanced debugging tools", "path": "dev/development_advanced_debugging", "type": "Development", "text": "\nIf you reached here, you want to dive into, or use, more advanced tooling.\nThis is usually not necessary for first time contributors and most day-to-day\ndevelopment. These are used more rarely, for example close to a new NumPy\nrelease, or when a large or particular complex change was made.\n\nSince not all of these tools are used on a regular bases and only available on\nsome systems, please expect differences, issues, or quirks; we will be happy\nto help if you get stuck and appreciate any improvements or suggestions to\nthese workflows.\n\nMost development will not require more than a typical debugging toolchain as\nshown in Debugging. But for example memory leaks can be particularly subtle or\ndifficult to narrow down.\n\nWe do not expect any of these tools to be run by most contributors. However,\nyou can ensure that we can track down such issues more easily easier:\n\nThis will help us catch any oversights before your change is released and\nmeans you do not have to worry about making reference counting errors, which\ncan be intimidating.\n\nDebug builds of Python are easily available for example on `debian` systems,\nand can be used on all platforms. Running a test or terminal is usually as\neasy as:\n\nand were already mentioned in Debugging.\n\nA Python debug build will help:\n\nPython debug builds allows to check correct reference counting. This works\nusing the additional commands:\n\nRunning the test suite only with a debug python build will not find many\nerrors on its own. An additional advantage of a debug build of Python is that\nit allows detecting memory leaks.\n\nA tool to make this easier is pytest-leaks, which can be installed using\n`pip`. Unfortunately, `pytest` itself may leak memory, but good results can\nusually (currently) be achieved by removing:\n\nfrom `numpy/conftest.py` (This may change with new `pytest-leaks` versions or\n`pytest` updates).\n\nThis allows to run the test suite, or part of it, conveniently:\n\nwhere `-R2:3` is the `pytest-leaks` command (see its documentation), the `-s`\ncauses output to print and may be necessary (in some versions captured output\nwas detected as a leak).\n\nNote that some tests are known (or even designed) to leak references, we try\nto mark them, but expect some false positives.\n\nValgrind is a powerful tool to find certain memory access problems and should\nbe run on complicated C code. Basic use of `valgrind` usually requires no more\nthan:\n\nwhere `PYTHONMALLOC=malloc` is necessary to avoid false positives from python\nitself. Depending on the system and valgrind version, you may see more false\npositives. `valgrind` supports \u201csuppressions\u201d to ignore some of these, and\nPython does have a suppression file (and even a compile time option) which may\nhelp if you find it necessary.\n\nValgrind helps:\n\nFind many memory leaks. Note that for most leaks the python debug build\napproach (and `pytest-leaks`) is much more sensitive. The reason is that\n`valgrind` can only detect if memory is definitely lost. If:\n\nHas incorrect reference counting for `dtype`, this is a bug, but valgrind\ncannot see it because `np.dtype(np.int64)` always returns the same object.\nHowever, not all dtypes are singletons, so this might leak memory for\ndifferent input. In rare cases NumPy uses `malloc` and not the Python memory\nallocators which are invisible to the Python debug build. `malloc` should\nnormally be avoided, but there are some exceptions (e.g. the `PyArray_Dims`\nstructure is public API and cannot use the Python allocators.)\n\nEven though using valgrind for memory leak detection is slow and less\nsensitive it can be a convenient: you can run most programs with valgrind\nwithout modification.\n\nThings to be aware of:\n\nA big advantage of valgrind is that it has no requirements aside from valgrind\nitself (although you probably want to use debug builds for better tracebacks).\n\nYou can run the test suite with valgrind which may be sufficient when you are\nonly interested in a few tests:\n\nNote the `--continue-on-collection-errors`, which is currently necessary due\nto missing `longdouble` support causing failures (this will usually not be\nnecessary if you do not run the full test suite).\n\nIf you wish to detect memory leaks you will also require `--show-leak-\nkinds=definite` and possibly more valgrind options. Just as for `pytest-leaks`\ncertain tests are known to leak cause errors in valgrind and may or may not be\nmarked as such.\n\nWe have developed pytest-valgrind which:\n\nPlease refer to its `README` for more information (it includes an example\ncommand for NumPy).\n\n"}, {"name": "Advanced F2PY use cases", "path": "f2py/advanced", "type": "Advanced F2PY use cases", "text": "\nUser-defined Python C/API functions can be defined inside signature files\nusing `usercode` and `pymethoddef` statements (they must be used inside the\n`python module` block). For example, the following signature file `spam.pyf`\n\nwraps the C library function `system()`:\n\nIn Python this can then be used as:\n\nThe following example illustrates how to add user-defined variables to a F2PY\ngenerated extension module by modifying the dictionary of a F2PY generated\nmodule. Consider the following signature file (compiled with `f2py -c\nvar.pyf`):\n\nNotice that the second `usercode` statement must be defined inside an\n`interface` block and the module dictionary is available through the variable\n`d` (see `varmodule.c` generated by `f2py var.pyf` for additional details).\n\nUsage in Python:\n\nCurrently, F2PY can handle only `<type spec>(kind=<kindselector>)`\ndeclarations where `<kindselector>` is a numeric integer (e.g. 1, 2, 4,\u2026), but\nnot a function call `KIND(..)` or any other expression. F2PY needs to know\nwhat would be the corresponding C type and a general solution for that would\nbe too complicated to implement.\n\nHowever, F2PY provides a hook to overcome this difficulty, namely, users can\ndefine their own <Fortran type> to <C type> maps. For example, if Fortran 90\ncode contains:\n\nthen create a mapping file containing a Python dictionary:\n\nfor instance.\n\nUse the `--f2cmap` command-line option to pass the file name to F2PY. By\ndefault, F2PY assumes file name is `.f2py_f2cmap` in the current working\ndirectory.\n\nMore generally, the f2cmap file must contain a dictionary with items:\n\nthat defines mapping between Fortran type:\n\nand the corresponding <C type>. The <C type> can be one of the following:\n\nFor more information, see the F2Py source code `numpy/f2py/capi_maps.py`.\n\n"}, {"name": "Array creation", "path": "user/basics.creation", "type": "User Guide", "text": "\nSee also\n\nArray creation routines\n\nThere are 6 general mechanisms for creating arrays:\n\nYou can use these methods to create ndarrays or Structured arrays. This\ndocument will cover general methods for ndarray creation.\n\nNumPy arrays can be defined using Python sequences such as lists and tuples.\nLists and tuples are defined using `[...]` and `(...)`, respectively. Lists\nand tuples can define ndarray creation:\n\nWhen you use `numpy.array` to define a new array, you should consider the\ndtype of the elements in the array, which can be specified explicitly. This\nfeature gives you more control over the underlying data structures and how the\nelements are handled in C/C++ functions. If you are not careful with `dtype`\nassignments, you can get unwanted overflow, as such\n\nAn 8-bit signed integer represents integers from -128 to 127. Assigning the\n`int8` array to integers outside of this range results in overflow. This\nfeature can often be misunderstood. If you perform calculations with\nmismatching `dtypes`, you can get unwanted results, for example:\n\nNotice when you perform operations with two arrays of the same `dtype`:\n`uint32`, the resulting array is the same type. When you perform operations\nwith different `dtype`, NumPy will assign a new type that satisfies all of the\narray elements involved in the computation, here `uint32` and `int32` can both\nbe represented in as `int64`.\n\nThe default NumPy behavior is to create arrays in either 64-bit signed\nintegers or double precision floating point numbers, `int64` and `float`,\nrespectively. If you expect your arrays to be a certain type, then you need to\nspecify the `dtype` while you create the array.\n\nNumPy has over 40 built-in functions for creating arrays as laid out in the\nArray creation routines. These functions can be split into roughly three\ncategories, based on the dimension of the array they create:\n\nThe 1D array creation functions e.g. `numpy.linspace` and `numpy.arange`\ngenerally need at least two inputs, `start` and `stop`.\n\n`numpy.arange` creates arrays with regularly incrementing values. Check the\ndocumentation for complete information and examples. A few examples are shown:\n\nNote: best practice for `numpy.arange` is to use integer start, end, and step\nvalues. There are some subtleties regarding `dtype`. In the second example,\nthe `dtype` is defined. In the third example, the array is `dtype=float` to\naccommodate the step size of `0.1`. Due to roundoff error, the `stop` value is\nsometimes included.\n\n`numpy.linspace` will create arrays with a specified number of elements, and\nspaced equally between the specified beginning and end values. For example:\n\nThe advantage of this creation function is that you guarantee the number of\nelements and the starting and end point. The previous `arange(start, stop,\nstep)` will not include the value `stop`.\n\nThe 2D array creation functions e.g. `numpy.eye`, `numpy.diag`, and\n`numpy.vander` define properties of special matrices represented as 2D arrays.\n\n`np.eye(n, m)` defines a 2D identity matrix. The elements where i=j (row index\nand column index are equal) are 1 and the rest are 0, as such:\n\n`numpy.diag` can define either a square 2D array with given values along the\ndiagonal or if given a 2D array returns a 1D array that is only the diagonal\nelements. The two array creation functions can be helpful while doing linear\nalgebra, as such:\n\n`vander(x, n)` defines a Vandermonde matrix as a 2D NumPy array. Each column\nof the Vandermonde matrix is a decreasing power of the input 1D array or list\nor tuple, `x` where the highest polynomial order is `n-1`. This array creation\nroutine is helpful in generating linear least squares models, as such:\n\nThe ndarray creation functions e.g. `numpy.ones`, `numpy.zeros`, and `random`\ndefine arrays based upon the desired shape. The ndarray creation functions can\ncreate arrays with any dimension by specifying how many dimensions and length\nalong that dimension in a tuple or list.\n\n`numpy.zeros` will create an array filled with 0 values with the specified\nshape. The default dtype is `float64`:\n\n`numpy.ones` will create an array filled with 1 values. It is identical to\n`zeros` in all other respects as such:\n\nThe `random` method of the result of `default_rng` will create an array filled\nwith random values between 0 and 1. It is included with the `numpy.random`\nlibrary. Below, two arrays are created with shapes (2,3) and (2,3,2),\nrespectively. The seed is set to 42 so you can reproduce these pseudorandom\nnumbers:\n\n`numpy.indices` will create a set of arrays (stacked as a one-higher\ndimensioned array), one per dimension with each representing variation in that\ndimension:\n\nThis is particularly useful for evaluating functions of multiple dimensions on\na regular grid.\n\nOnce you have created arrays, you can replicate, join, or mutate those\nexisting arrays to create new arrays. When you assign an array or its elements\nto a new variable, you have to explicitly `numpy.copy` the array, otherwise\nthe variable is a view into the original array. Consider the following\nexample:\n\nIn this example, you did not create a new array. You created a variable, `b`\nthat viewed the first 2 elements of `a`. When you added 1 to `b` you would get\nthe same result by adding 1 to `a[:2]`. If you want to create a new array, use\nthe `numpy.copy` array creation routine as such:\n\nFor more information and examples look at Copies and Views.\n\nThere are a number of routines to join existing arrays e.g. `numpy.vstack`,\n`numpy.hstack`, and `numpy.block`. Here is an example of joining four 2-by-2\narrays into a 4-by-4 array using `block`:\n\nOther routines use similar syntax to join ndarrays. Check the routine\u2019s\ndocumentation for further examples and syntax.\n\nThis is the most common case of large array creation. The details depend\ngreatly on the format of data on disk. This section gives general pointers on\nhow to handle various formats. For more detailed examples of IO look at How to\nRead and Write files.\n\nVarious fields have standard formats for array data. The following lists the\nones with known Python libraries to read them and return NumPy arrays (there\nmay be others for which it is possible to read and convert to NumPy arrays so\ncheck the last section as well)\n\nExamples of formats that cannot be read directly but for which it is not hard\nto convert are those formats supported by libraries like PIL (able to read and\nwrite many image formats such as jpg, png, etc).\n\nDelimited files such as comma separated value (csv) and tab separated value\n(tsv) files are used for programs like Excel and LabView. Python functions can\nread and parse these files line-by-line. NumPy has two standard routines for\nimporting a file with delimited data `numpy.loadtxt` and `numpy.genfromtxt`.\nThese functions have more involved use cases in Reading and writing files. A\nsimple example given a `simple.csv`:\n\nImporting `simple.csv` is accomplished using `loadtxt`:\n\nMore generic ASCII files can be read using `scipy.io` and Pandas.\n\nThere are a variety of approaches one can use. If the file has a relatively\nsimple format then one can write a simple I/O library and use the NumPy\n`fromfile()` function and `.tofile()` method to read and write NumPy arrays\ndirectly (mind your byteorder though!) If a good C or C++ library exists that\nread the data, one can wrap that library with a variety of techniques though\nthat certainly is much more work and requires significantly more advanced\nknowledge to interface with C or C++.\n\nNumPy is the fundamental library for array containers in the Python Scientific\nComputing stack. Many Python libraries, including SciPy, Pandas, and OpenCV,\nuse NumPy ndarrays as the common format for data exchange, These libraries can\ncreate, operate on, and work with NumPy arrays.\n\n"}, {"name": "Array creation routines", "path": "reference/routines.array-creation", "type": "Array creation routines", "text": "\nSee also\n\nArray creation\n\n`empty`(shape[, dtype, order, like])\n\nReturn a new array of given shape and type, without initializing entries.\n\n`empty_like`(prototype[, dtype, order, subok, ...])\n\nReturn a new array with the same shape and type as a given array.\n\n`eye`(N[, M, k, dtype, order, like])\n\nReturn a 2-D array with ones on the diagonal and zeros elsewhere.\n\n`identity`(n[, dtype, like])\n\nReturn the identity array.\n\n`ones`(shape[, dtype, order, like])\n\nReturn a new array of given shape and type, filled with ones.\n\n`ones_like`(a[, dtype, order, subok, shape])\n\nReturn an array of ones with the same shape and type as a given array.\n\n`zeros`(shape[, dtype, order, like])\n\nReturn a new array of given shape and type, filled with zeros.\n\n`zeros_like`(a[, dtype, order, subok, shape])\n\nReturn an array of zeros with the same shape and type as a given array.\n\n`full`(shape, fill_value[, dtype, order, like])\n\nReturn a new array of given shape and type, filled with `fill_value`.\n\n`full_like`(a, fill_value[, dtype, order, ...])\n\nReturn a full array with the same shape and type as a given array.\n\n`array`(object[, dtype, copy, order, subok, ...])\n\nCreate an array.\n\n`asarray`(a[, dtype, order, like])\n\nConvert the input to an array.\n\n`asanyarray`(a[, dtype, order, like])\n\nConvert the input to an ndarray, but pass ndarray subclasses through.\n\n`ascontiguousarray`(a[, dtype, like])\n\nReturn a contiguous array (ndim >= 1) in memory (C order).\n\n`asmatrix`(data[, dtype])\n\nInterpret the input as a matrix.\n\n`copy`(a[, order, subok])\n\nReturn an array copy of the given object.\n\n`frombuffer`(buffer[, dtype, count, offset, like])\n\nInterpret a buffer as a 1-dimensional array.\n\n`fromfile`(file[, dtype, count, sep, offset, like])\n\nConstruct an array from data in a text or binary file.\n\n`fromfunction`(function, shape, *[, dtype, like])\n\nConstruct an array by executing a function over each coordinate.\n\n`fromiter`(iter, dtype[, count, like])\n\nCreate a new 1-dimensional array from an iterable object.\n\n`fromstring`(string[, dtype, count, like])\n\nA new 1-D array initialized from text data in a string.\n\n`loadtxt`(fname[, dtype, comments, delimiter, ...])\n\nLoad data from a text file.\n\nNote\n\n`numpy.rec` is the preferred alias for `numpy.core.records`.\n\n`core.records.array`(obj[, dtype, shape, ...])\n\nConstruct a record array from a wide-variety of objects.\n\n`core.records.fromarrays`(arrayList[, dtype, ...])\n\nCreate a record array from a (flat) list of arrays\n\n`core.records.fromrecords`(recList[, dtype, ...])\n\nCreate a recarray from a list of records in text form.\n\n`core.records.fromstring`(datastring[, dtype, ...])\n\nCreate a record array from binary data\n\n`core.records.fromfile`(fd[, dtype, shape, ...])\n\nCreate an array from binary file data\n\nNote\n\n`numpy.char` is the preferred alias for `numpy.core.defchararray`.\n\n`core.defchararray.array`(obj[, itemsize, ...])\n\nCreate a `chararray`.\n\n`core.defchararray.asarray`(obj[, itemsize, ...])\n\nConvert the input to a `chararray`, copying the data only if necessary.\n\n`arange`([start,] stop[, step,][, dtype, like])\n\nReturn evenly spaced values within a given interval.\n\n`linspace`(start, stop[, num, endpoint, ...])\n\nReturn evenly spaced numbers over a specified interval.\n\n`logspace`(start, stop[, num, endpoint, base, ...])\n\nReturn numbers spaced evenly on a log scale.\n\n`geomspace`(start, stop[, num, endpoint, ...])\n\nReturn numbers spaced evenly on a log scale (a geometric progression).\n\n`meshgrid`(*xi[, copy, sparse, indexing])\n\nReturn coordinate matrices from coordinate vectors.\n\n`mgrid`\n\n`nd_grid` instance which returns a dense multi-dimensional \"meshgrid\".\n\n`ogrid`\n\n`nd_grid` instance which returns an open multi-dimensional \"meshgrid\".\n\n`diag`(v[, k])\n\nExtract a diagonal or construct a diagonal array.\n\n`diagflat`(v[, k])\n\nCreate a two-dimensional array with the flattened input as a diagonal.\n\n`tri`(N[, M, k, dtype, like])\n\nAn array with ones at and below the given diagonal and zeros elsewhere.\n\n`tril`(m[, k])\n\nLower triangle of an array.\n\n`triu`(m[, k])\n\nUpper triangle of an array.\n\n`vander`(x[, N, increasing])\n\nGenerate a Vandermonde matrix.\n\n`mat`(data[, dtype])\n\nInterpret the input as a matrix.\n\n`bmat`(obj[, ldict, gdict])\n\nBuild a matrix object from a string, nested sequence, or array.\n\n"}, {"name": "Array manipulation routines", "path": "reference/routines.array-manipulation", "type": "Array manipulation routines", "text": "\n`copyto`(dst, src[, casting, where])\n\nCopies values from one array to another, broadcasting as necessary.\n\n`shape`(a)\n\nReturn the shape of an array.\n\n`reshape`(a, newshape[, order])\n\nGives a new shape to an array without changing its data.\n\n`ravel`(a[, order])\n\nReturn a contiguous flattened array.\n\n`ndarray.flat`\n\nA 1-D iterator over the array.\n\n`ndarray.flatten`([order])\n\nReturn a copy of the array collapsed into one dimension.\n\n`moveaxis`(a, source, destination)\n\nMove axes of an array to new positions.\n\n`rollaxis`(a, axis[, start])\n\nRoll the specified axis backwards, until it lies in a given position.\n\n`swapaxes`(a, axis1, axis2)\n\nInterchange two axes of an array.\n\n`ndarray.T`\n\nThe transposed array.\n\n`transpose`(a[, axes])\n\nReverse or permute the axes of an array; returns the modified array.\n\n`atleast_1d`(*arys)\n\nConvert inputs to arrays with at least one dimension.\n\n`atleast_2d`(*arys)\n\nView inputs as arrays with at least two dimensions.\n\n`atleast_3d`(*arys)\n\nView inputs as arrays with at least three dimensions.\n\n`broadcast`\n\nProduce an object that mimics broadcasting.\n\n`broadcast_to`(array, shape[, subok])\n\nBroadcast an array to a new shape.\n\n`broadcast_arrays`(*args[, subok])\n\nBroadcast any number of arrays against each other.\n\n`expand_dims`(a, axis)\n\nExpand the shape of an array.\n\n`squeeze`(a[, axis])\n\nRemove axes of length one from `a`.\n\n`asarray`(a[, dtype, order, like])\n\nConvert the input to an array.\n\n`asanyarray`(a[, dtype, order, like])\n\nConvert the input to an ndarray, but pass ndarray subclasses through.\n\n`asmatrix`(data[, dtype])\n\nInterpret the input as a matrix.\n\n`asfarray`(a[, dtype])\n\nReturn an array converted to a float type.\n\n`asfortranarray`(a[, dtype, like])\n\nReturn an array (ndim >= 1) laid out in Fortran order in memory.\n\n`ascontiguousarray`(a[, dtype, like])\n\nReturn a contiguous array (ndim >= 1) in memory (C order).\n\n`asarray_chkfinite`(a[, dtype, order])\n\nConvert the input to an array, checking for NaNs or Infs.\n\n`asscalar`(a)\n\nConvert an array of size 1 to its scalar equivalent.\n\n`require`(a[, dtype, requirements, like])\n\nReturn an ndarray of the provided type that satisfies requirements.\n\n`concatenate`([axis, out, dtype, casting])\n\nJoin a sequence of arrays along an existing axis.\n\n`stack`(arrays[, axis, out])\n\nJoin a sequence of arrays along a new axis.\n\n`block`(arrays)\n\nAssemble an nd-array from nested lists of blocks.\n\n`vstack`(tup)\n\nStack arrays in sequence vertically (row wise).\n\n`hstack`(tup)\n\nStack arrays in sequence horizontally (column wise).\n\n`dstack`(tup)\n\nStack arrays in sequence depth wise (along third axis).\n\n`column_stack`(tup)\n\nStack 1-D arrays as columns into a 2-D array.\n\n`row_stack`(tup)\n\nStack arrays in sequence vertically (row wise).\n\n`split`(ary, indices_or_sections[, axis])\n\nSplit an array into multiple sub-arrays as views into `ary`.\n\n`array_split`(ary, indices_or_sections[, axis])\n\nSplit an array into multiple sub-arrays.\n\n`dsplit`(ary, indices_or_sections)\n\nSplit array into multiple sub-arrays along the 3rd axis (depth).\n\n`hsplit`(ary, indices_or_sections)\n\nSplit an array into multiple sub-arrays horizontally (column-wise).\n\n`vsplit`(ary, indices_or_sections)\n\nSplit an array into multiple sub-arrays vertically (row-wise).\n\n`tile`(A, reps)\n\nConstruct an array by repeating A the number of times given by reps.\n\n`repeat`(a, repeats[, axis])\n\nRepeat elements of an array.\n\n`delete`(arr, obj[, axis])\n\nReturn a new array with sub-arrays along an axis deleted.\n\n`insert`(arr, obj, values[, axis])\n\nInsert values along the given axis before the given indices.\n\n`append`(arr, values[, axis])\n\nAppend values to the end of an array.\n\n`resize`(a, new_shape)\n\nReturn a new array with the specified shape.\n\n`trim_zeros`(filt[, trim])\n\nTrim the leading and/or trailing zeros from a 1-D array or sequence.\n\n`unique`(ar[, return_index, return_inverse, ...])\n\nFind the unique elements of an array.\n\n`flip`(m[, axis])\n\nReverse the order of elements in an array along the given axis.\n\n`fliplr`(m)\n\nReverse the order of elements along axis 1 (left/right).\n\n`flipud`(m)\n\nReverse the order of elements along axis 0 (up/down).\n\n`reshape`(a, newshape[, order])\n\nGives a new shape to an array without changing its data.\n\n`roll`(a, shift[, axis])\n\nRoll array elements along a given axis.\n\n`rot90`(m[, k, axes])\n\nRotate an array by 90 degrees in the plane specified by axes.\n\n"}, {"name": "Array objects", "path": "reference/arrays", "type": "Array objects", "text": "\nNumPy provides an N-dimensional array type, the ndarray, which describes a\ncollection of \u201citems\u201d of the same type. The items can be indexed using for\nexample N integers.\n\nAll ndarrays are homogeneous: every item takes up the same size block of\nmemory, and all blocks are interpreted in exactly the same way. How each item\nin the array is to be interpreted is specified by a separate data-type object,\none of which is associated with every array. In addition to basic types\n(integers, floats, etc.), the data type objects can also represent data\nstructures.\n\nAn item extracted from an array, e.g., by indexing, is represented by a Python\nobject whose type is one of the array scalar types built in NumPy. The array\nscalars allow easy manipulation of also more complicated arrangements of data.\n\nFigure Conceptual diagram showing the relationship between the three\nfundamental objects used to describe the data in an array: 1) the ndarray\nitself, 2) the data-type object that describes the layout of a single fixed-\nsize element of the array, 3) the array-scalar Python object that is returned\nwhen a single element of the array is accessed.\n\n"}, {"name": "Binary operations", "path": "reference/routines.bitwise", "type": "Binary operations", "text": "\n`bitwise_and`(x1, x2, /[, out, where, ...])\n\nCompute the bit-wise AND of two arrays element-wise.\n\n`bitwise_or`(x1, x2, /[, out, where, casting, ...])\n\nCompute the bit-wise OR of two arrays element-wise.\n\n`bitwise_xor`(x1, x2, /[, out, where, ...])\n\nCompute the bit-wise XOR of two arrays element-wise.\n\n`invert`(x, /[, out, where, casting, order, ...])\n\nCompute bit-wise inversion, or bit-wise NOT, element-wise.\n\n`left_shift`(x1, x2, /[, out, where, casting, ...])\n\nShift the bits of an integer to the left.\n\n`right_shift`(x1, x2, /[, out, where, ...])\n\nShift the bits of an integer to the right.\n\n`packbits`(a, /[, axis, bitorder])\n\nPacks the elements of a binary-valued array into bits in a uint8 array.\n\n`unpackbits`(a, /[, axis, count, bitorder])\n\nUnpacks elements of a uint8 array into a binary-valued output array.\n\n`binary_repr`(num[, width])\n\nReturn the binary representation of the input number as a string.\n\n"}, {"name": "Bit Generators", "path": "reference/random/bit_generators/index", "type": "Bit Generators", "text": "\nThe random values produced by `Generator` originate in a BitGenerator. The\nBitGenerators do not directly provide random numbers and only contains methods\nused for seeding, getting or setting the state, jumping or advancing the\nstate, and for accessing low-level wrappers for consumption by code that can\nefficiently access the functions provided, e.g., numba.\n\nThe included BitGenerators are:\n\n`BitGenerator`([seed])\n\nBase Class for generic BitGenerators, which provide a stream of random bits\nbased on different algorithms.\n\n"}, {"name": "broadcast.index", "path": "reference/generated/numpy.broadcast.index", "type": "Standard array subclasses", "text": "\nattribute\n\ncurrent index in broadcasted result\n\n"}, {"name": "broadcast.iters", "path": "reference/generated/numpy.broadcast.iters", "type": "Standard array subclasses", "text": "\nattribute\n\ntuple of iterators along `self`\u2019s \u201ccomponents.\u201d\n\nReturns a tuple of `numpy.flatiter` objects, one for each \u201ccomponent\u201d of\n`self`.\n\nSee also\n\n"}, {"name": "broadcast.nd", "path": "reference/generated/numpy.broadcast.nd", "type": "Standard array subclasses", "text": "\nattribute\n\nNumber of dimensions of broadcasted result. For code intended for NumPy 1.12.0\nand later the more consistent `ndim` is preferred.\n\n"}, {"name": "broadcast.ndim", "path": "reference/generated/numpy.broadcast.ndim", "type": "Standard array subclasses", "text": "\nattribute\n\nNumber of dimensions of broadcasted result. Alias for `nd`.\n\nNew in version 1.12.0.\n\n"}, {"name": "broadcast.numiter", "path": "reference/generated/numpy.broadcast.numiter", "type": "Standard array subclasses", "text": "\nattribute\n\nNumber of iterators possessed by the broadcasted result.\n\n"}, {"name": "broadcast.reset()", "path": "reference/generated/numpy.broadcast.reset", "type": "numpy.broadcast.reset", "text": "\nmethod\n\nReset the broadcasted result\u2019s iterator(s).\n\n"}, {"name": "broadcast.size", "path": "reference/generated/numpy.broadcast.size", "type": "Standard array subclasses", "text": "\nattribute\n\nTotal size of broadcasted result.\n\n"}, {"name": "build_src", "path": "f2py/buildtools/distutils", "type": "Using via \n        \n         numpy.distutils", "text": "\n`numpy.distutils` is part of NumPy, and extends the standard Python\n`distutils` module to deal with Fortran sources and F2PY signature files, e.g.\ncompile Fortran sources, call F2PY to construct extension modules, etc.\n\nExample\n\nConsider the following `setup_file.py` for the `fib` and `scalar` examples\nfrom Three ways to wrap - getting started section:\n\nRunning\n\nwill build two extension modules `scalar` and `fib2` to the build directory.\n\n`numpy.distutils` extends `distutils` with the following features:\n\n`Extension` class argument `sources` may contain Fortran source files. In\naddition, the list `sources` may contain at most one F2PY signature file, and\nin this case, the name of an Extension module must match with the\n`<modulename>` used in signature file. It is assumed that an F2PY signature\nfile contains exactly one `python module` block.\n\nIf `sources` do not contain a signature file, then F2PY is used to scan\nFortran source files to construct wrappers to the Fortran codes.\n\nAdditional options to the F2PY executable can be given using the `Extension`\nclass argument `f2py_options`.\n\nThe following new `distutils` commands are defined:\n\nto construct Fortran wrapper extension modules, among many other things.\n\nto change Fortran compiler options.\n\nAdditionally, the `build_ext` and `build_clib` commands are also enhanced to\nsupport Fortran sources.\n\nRun\n\nto see available options for these commands.\n\nWhen building Python packages containing Fortran sources, one can choose\ndifferent Fortran compilers by using the `build_ext` command option\n`--fcompiler=<Vendor>`. Here `<Vendor>` can be one of the following names (on\n`linux` systems):\n\nSee `numpy_distutils/fcompiler.py` for an up-to-date list of supported\ncompilers for different platforms, or run\n\n"}, {"name": "Building from source", "path": "user/building", "type": "User Guide", "text": "\nThere are two options for building NumPy- building with Gitpod or locally from\nsource. Your choice depends on your operating system and familiarity with the\ncommand line.\n\nGitpod is an open-source platform that automatically creates the correct\ndevelopment environment right in your browser, reducing the need to install\nlocal development environments and deal with incompatible dependencies.\n\nIf you are a Windows user, unfamiliar with using the command line or building\nNumPy for the first time, it is often faster to build with Gitpod. Here are\nthe in-depth instructions for building NumPy with building NumPy with Gitpod.\n\nBuilding locally on your machine gives you more granular control. If you are a\nMacOS or Linux user familiar with using the command line, you can continue\nwith building NumPy locally by following the instructions below.\n\nBuilding NumPy requires the following software installed:\n\nPython 3.6.x or newer\n\nPlease note that the Python development headers also need to be installed,\ne.g., on Debian/Ubuntu one needs to install both `python3` and `python3-dev`.\nOn Windows and macOS this is normally not an issue.\n\nCompilers\n\nMuch of NumPy is written in C. You will need a C compiler that complies with\nthe C99 standard.\n\nWhile a FORTRAN 77 compiler is not necessary for building NumPy, it is needed\nto run the `numpy.f2py` tests. These tests are skipped if the compiler is not\nauto-detected.\n\nNote that NumPy is developed mainly using GNU compilers and tested on MSVC and\nClang compilers. Compilers from other vendors such as Intel, Absoft, Sun, NAG,\nCompaq, Vast, Portland, Lahey, HP, IBM are only supported in the form of\ncommunity feedback, and may not work out of the box. GCC 4.x (and later)\ncompilers are recommended. On ARM64 (aarch64) GCC 8.x (and later) are\nrecommended.\n\nLinear Algebra libraries\n\nNumPy does not require any external linear algebra libraries to be installed.\nHowever, if these are available, NumPy\u2019s setup script can detect them and use\nthem for building. A number of different LAPACK library setups can be used,\nincluding optimized LAPACK libraries such as OpenBLAS or MKL. The choice and\nlocation of these libraries as well as include paths and other such build\noptions can be specified in a `site.cfg` file located in the NumPy root\nrepository or a `.numpy-site.cfg` file in your home directory. See the\n`site.cfg.example` example file included in the NumPy repository or sdist for\ndocumentation, and below for specifying search priority from environmental\nvariables.\n\nCython\n\nFor building NumPy, you\u2019ll need a recent version of Cython.\n\nTo install NumPy, run:\n\nTo perform an in-place build that can be run from the source folder run:\n\nNote: for build instructions to do development work on NumPy itself, see\nSetting up and using your development environment.\n\nMake sure to test your builds. To ensure everything stays in shape, see if all\ntests pass:\n\nFor detailed info on testing, see Testing builds.\n\nIt\u2019s possible to do a parallel build with:\n\nThis will compile numpy on 4 CPUs and install it into the specified prefix. to\nperform a parallel in-place build, run:\n\nThe number of build jobs can also be specified via the environment variable\n`NPY_NUM_BUILD_JOBS`.\n\nCompilers are auto-detected; building with a particular compiler can be done\nwith `--fcompiler`. E.g. to select gfortran:\n\nFor more information see:\n\nOne relatively simple and reliable way to check for the compiler used to build\na library is to use ldd on the library. If libg2c.so is a dependency, this\nmeans that g77 has been used (note: g77 is no longer supported for building\nNumPy). If libgfortran.so is a dependency, gfortran has been used. If both are\ndependencies, this means both have been used, which is almost always a very\nbad idea.\n\nNumPy searches for optimized linear algebra libraries such as BLAS and LAPACK.\nThere are specific orders for searching these libraries, as described below\nand in the `site.cfg.example` file.\n\nNote that both BLAS and CBLAS interfaces are needed for a properly optimized\nbuild of NumPy.\n\nThe default order for the libraries are:\n\nThe detection of BLAS libraries may be bypassed by defining the environment\nvariable `NPY_BLAS_LIBS` , which should contain the exact linker flags you\nwant to use (interface is assumed to be Fortran 77). Also define\n`NPY_CBLAS_LIBS` (even empty if CBLAS is contained in your BLAS library) to\ntrigger use of CBLAS and avoid slow fallback code for matrix calculations.\n\nIf you wish to build against OpenBLAS but you also have BLIS available one may\npredefine the order of searching via the environment variable `NPY_BLAS_ORDER`\nwhich is a comma-separated list of the above names which is used to determine\nwhat to search for, for instance:\n\nwill prefer to use ATLAS, then BLIS, then OpenBLAS and as a last resort MKL.\nIf neither of these exists the build will fail (names are compared lower\ncase).\n\nAlternatively one may use `!` or `^` to negate all items:\n\nwill allow using anything but NetLIB BLAS and ATLAS libraries, the order of\nthe above list is retained.\n\nOne cannot mix negation and positives, nor have multiple negations, such cases\nwill raise an error.\n\nThe default order for the libraries are:\n\nThe detection of LAPACK libraries may be bypassed by defining the environment\nvariable `NPY_LAPACK_LIBS`, which should contain the exact linker flags you\nwant to use (language is assumed to be Fortran 77).\n\nIf you wish to build against OpenBLAS but you also have MKL available one may\npredefine the order of searching via the environment variable\n`NPY_LAPACK_ORDER` which is a comma-separated list of the above names, for\ninstance:\n\nwill prefer to use ATLAS, then OpenBLAS and as a last resort MKL. If neither\nof these exists the build will fail (names are compared lower case).\n\nAlternatively one may use `!` or `^` to negate all items:\n\nwill allow using anything but the NetLIB LAPACK library, the order of the\nabove list is retained.\n\nOne cannot mix negation and positives, nor have multiple negations, such cases\nwill raise an error.\n\nDeprecated since version 1.20: The native libraries on macOS, provided by\nAccelerate, are not fit for use in NumPy since they have bugs that cause wrong\noutput under easily reproducible conditions. If the vendor fixes those bugs,\nthe library could be reinstated, but until then users compiling for themselves\nshould use another linear algebra library or use the built-in (but slower)\ndefault, see the next section.\n\nUsage of ATLAS and other accelerated libraries in NumPy can be disabled via:\n\nor:\n\nYou can tell Numpy to use 64-bit BLAS/LAPACK libraries by setting the\nenvironment variable:\n\nwhen building Numpy. The following 64-bit BLAS/LAPACK libraries are supported:\n\nThe order in which they are preferred is determined by `NPY_BLAS_ILP64_ORDER`\nand `NPY_LAPACK_ILP64_ORDER` environment variables. The default value is\n`openblas64_,openblas_ilp64`.\n\nNote\n\nUsing non-symbol-suffixed 64-bit BLAS/LAPACK in a program that also uses\n32-bit BLAS/LAPACK can cause crashes under certain conditions (e.g. with\nembedded Python interpreters on Linux).\n\nThe 64-bit OpenBLAS with `64_` symbol suffix is obtained by compiling OpenBLAS\nwith settings:\n\nThe symbol suffix avoids the symbol name clashes between 32-bit and 64-bit\nBLAS/LAPACK libraries.\n\nAdditional compiler flags can be supplied by setting the `OPT`, `FOPT` (for\nFortran), and `CC` environment variables. When providing options that should\nimprove the performance of the code ensure that you also set `-DNDEBUG` so\nthat debugging code is not executed.\n\n"}, {"name": "Building the NumPy API and reference docs", "path": "dev/howto_build_docs", "type": "Development", "text": "\nIf you only want to get the documentation, note that pre-built versions can be\nfound at\n\nhttps://numpy.org/doc/\n\nin several different formats.\n\nBefore proceeding further it should be noted that the documentation is built\nwith the `make` tool, which is not natively available on Windows. MacOS or\nLinux users can jump to Prerequisites. It is recommended for Windows users to\nset up their development environment on Gitpod or Windows Subsystem for Linux\n(WSL). WSL is a good option for a persistent local set-up.\n\nGitpod is an open-source platform that automatically creates the correct\ndevelopment environment right in your browser, reducing the need to install\nlocal development environments and deal with incompatible dependencies.\n\nIf you have good internet connectivity and want a temporary set-up, it is\noften faster to build with Gitpod. Here are the in-depth instructions for\nbuilding NumPy with Gitpod.\n\nBuilding the NumPy documentation and API reference requires the following:\n\nSince large parts of the main documentation are obtained from NumPy via\n`import numpy` and examining the docstrings, you will need to first build and\ninstall it so that the correct version is imported. NumPy has to be re-built\nand re-installed every time you fetch the latest version of the repository,\nbefore generating the documentation. This ensures that the NumPy version and\nthe git repository version are in sync.\n\nNote that you can e.g. install NumPy to a temporary location and set the\nPYTHONPATH environment variable appropriately. Alternatively, if using Python\nvirtual environments (via e.g. `conda`, `virtualenv` or the `venv` module),\ninstalling NumPy into a new virtual environment is recommended.\n\nAll of the necessary dependencies for building the NumPy docs except for\nDoxygen can be installed with:\n\nWe currently use Sphinx along with Doxygen for generating the API and\nreference documentation for NumPy. In addition, building the documentation\nrequires the Sphinx extension `plot_directive`, which is shipped with\nMatplotlib. We also use numpydoc to render docstrings in the generated API\ndocumentation. SciPy is installed since some parts of the documentation\nrequire SciPy functions.\n\nFor installing Doxygen, please check the official download and installation\npages, or if you are using Linux then you can install it through your\ndistribution package manager.\n\nNote\n\nTry to install a newer version of Doxygen > 1.8.10 otherwise you may get some\nwarnings during the build.\n\nIf you obtained NumPy via git, also get the git submodules that contain\nadditional parts required for building the documentation:\n\nNow you are ready to generate the docs, so write:\n\nIf all goes well, this will generate a `build/html` subdirectory in the `/doc`\ndirectory, containing the built documentation. If you get a message about\n`installed numpy != current repo git version`, you must either override the\ncheck by setting `GITVER` or re-install NumPy.\n\nIf you have built NumPy into a virtual environment and get an error that says\n`numpy not found, cannot build documentation without...`, you need to override\nthe makefile `PYTHON` variable at the command line, so instead of writing\n`make html` write:\n\nTo build the PDF documentation, do instead:\n\nYou will need to have LaTeX installed for this, inclusive of support for Greek\nletters. For example, on Ubuntu xenial `texlive-lang-greek` and `cm-super` are\nneeded. Also, `latexmk` is needed on non-Windows systems.\n\nInstead of the above, you can also do:\n\nwhich will rebuild NumPy, install it to a temporary location, and build the\ndocumentation in all formats. This will most likely again only work on Unix\nplatforms.\n\nThe documentation for NumPy distributed at https://numpy.org/doc in html and\npdf format is also built with `make dist`. See HOWTO RELEASE for details on\nhow to update https://numpy.org/doc.\n\n"}, {"name": "busdaycalendar.holidays", "path": "reference/generated/numpy.busdaycalendar.holidays", "type": "Datetime support functions", "text": "\nattribute\n\nA copy of the holiday array indicating additional invalid days.\n\n"}, {"name": "busdaycalendar.weekmask", "path": "reference/generated/numpy.busdaycalendar.weekmask", "type": "Datetime support functions", "text": "\nattribute\n\nA copy of the seven-element boolean mask indicating valid days.\n\n"}, {"name": "Byte-swapping", "path": "user/basics.byteswapping", "type": "User Guide", "text": "\nThe `ndarray` is an object that provide a python array interface to data in\nmemory.\n\nIt often happens that the memory that you want to view with an array is not of\nthe same byte ordering as the computer on which you are running Python.\n\nFor example, I might be working on a computer with a little-endian CPU - such\nas an Intel Pentium, but I have loaded some data from a file written by a\ncomputer that is big-endian. Let\u2019s say I have loaded 4 bytes from a file\nwritten by a Sun (big-endian) computer. I know that these 4 bytes represent\ntwo 16-bit integers. On a big-endian machine, a two-byte integer is stored\nwith the Most Significant Byte (MSB) first, and then the Least Significant\nByte (LSB). Thus the bytes are, in memory order:\n\nLet\u2019s say the two integers were in fact 1 and 770. Because 770 = 256 * 3 + 2,\nthe 4 bytes in memory would contain respectively: 0, 1, 3, 2. The bytes I have\nloaded from the file would have these contents:\n\nWe might want to use an `ndarray` to access these integers. In that case, we\ncan create an array around this memory, and tell numpy that there are two\nintegers, and that they are 16 bit and big-endian:\n\nNote the array `dtype` above of `>i2`. The `>` means \u2018big-endian\u2019 (`<` is\nlittle-endian) and `i2` means \u2018signed 2-byte integer\u2019. For example, if our\ndata represented a single unsigned 4-byte little-endian integer, the dtype\nstring would be `<u4`.\n\nIn fact, why don\u2019t we try that?\n\nReturning to our `big_end_arr` \\- in this case our underlying data is big-\nendian (data endianness) and we\u2019ve set the dtype to match (the dtype is also\nbig-endian). However, sometimes you need to flip these around.\n\nWarning\n\nScalars currently do not include byte order information, so extracting a\nscalar from an array will return an integer in native byte order. Hence:\n\nAs you can imagine from the introduction, there are two ways you can affect\nthe relationship between the byte ordering of the array and the underlying\nmemory it is looking at:\n\nThe common situations in which you need to change byte ordering are:\n\nWe make something where they don\u2019t match:\n\nThe obvious fix for this situation is to change the dtype so it gives the\ncorrect endianness:\n\nNote the array has not changed in memory:\n\nYou might want to do this if you need the data in memory to be a certain\nordering. For example you might be writing the memory out to a file that needs\na certain byte ordering.\n\nNow the array has changed in memory:\n\nYou may have a correctly specified array dtype, but you need the array to have\nthe opposite byte order in memory, and you want the dtype to match so the\narray values make sense. In this case you just do both of the previous\noperations:\n\nAn easier way of casting the data to a specific dtype and byte ordering can be\nachieved with the ndarray astype method:\n\n"}, {"name": "C API Deprecations", "path": "reference/c-api/deprecations", "type": "C API Deprecations", "text": "\nThe API exposed by NumPy for third-party extensions has grown over years of\nreleases, and has allowed programmers to directly access NumPy functionality\nfrom C. This API can be best described as \u201corganic\u201d. It has emerged from\nmultiple competing desires and from multiple points of view over the years,\nstrongly influenced by the desire to make it easy for users to move to NumPy\nfrom Numeric and Numarray. The core API originated with Numeric in 1995 and\nthere are patterns such as the heavy use of macros written to mimic Python\u2019s\nC-API as well as account for compiler technology of the late 90\u2019s. There is\nalso only a small group of volunteers who have had very little time to spend\non improving this API.\n\nThere is an ongoing effort to improve the API. It is important in this effort\nto ensure that code that compiles for NumPy 1.X continues to compile for NumPy\n1.X. At the same time, certain API\u2019s will be marked as deprecated so that\nfuture-looking code can avoid these API\u2019s and follow better practices.\n\nAnother important role played by deprecation markings in the C API is to move\ntowards hiding internal details of the NumPy implementation. For those needing\ndirect, easy, access to the data of ndarrays, this will not remove this\nability. Rather, there are many potential performance optimizations which\nrequire changing the implementation details, and NumPy developers have been\nunable to try them because of the high value of preserving ABI compatibility.\nBy deprecating this direct access, we will in the future be able to improve\nNumPy\u2019s performance in ways we cannot presently.\n\nIn C, there is no equivalent to the deprecation warnings that Python supports.\nOne way to do deprecations is to flag them in the documentation and release\nnotes, then remove or change the deprecated features in a future major version\n(NumPy 2.0 and beyond). Minor versions of NumPy should not have major C-API\nchanges, however, that prevent code that worked on a previous minor release.\nFor example, we will do our best to ensure that code that compiled and worked\non NumPy 1.4 should continue to work on NumPy 1.7 (but perhaps with compiler\nwarnings).\n\nTo use the NPY_NO_DEPRECATED_API mechanism, you need to #define it to the\ntarget API version of NumPy before #including any NumPy headers. If you want\nto confirm that your code is clean against 1.7, use:\n\nOn compilers which support a #warning mechanism, NumPy issues a compiler\nwarning if you do not define the symbol NPY_NO_DEPRECATED_API. This way, the\nfact that there are deprecations will be flagged for third-party developers\nwho may not have read the release notes closely.\n\n"}, {"name": "char **NpyIter_GetDataPtrArray()", "path": "reference/c-api/iterator#c.NpyIter_GetDataPtrArray", "type": "Array Iterator API", "text": "\nThis gives back a pointer to the `nop` data pointers. If\n`NPY_ITER_EXTERNAL_LOOP` was not specified, each data pointer points to the\ncurrent data item of the iterator. If no inner iteration was specified, it\npoints to the first data item of the inner loop.\n\nThis pointer may be cached before the iteration loop, calling `iternext` will\nnot change it. This function may be safely called without holding the Python\nGIL.\n\n"}, {"name": "char **NpyIter_GetInitialDataPtrArray()", "path": "reference/c-api/iterator#c.NpyIter_GetInitialDataPtrArray", "type": "Array Iterator API", "text": "\nGets the array of data pointers directly into the arrays (never into the\nbuffers), corresponding to iteration index 0.\n\nThese pointers are different from the pointers accepted by\n`NpyIter_ResetBasePointers`, because the direction along some axes may have\nbeen reversed.\n\nThis function may be safely called without holding the Python GIL.\n\n"}, {"name": "char *core_signature", "path": "reference/c-api/types-and-structures#c.PyUFuncObject.core_signature", "type": "Python Types and C-Structures", "text": "\nCore signature string\n\n"}, {"name": "char *data", "path": "reference/c-api/types-and-structures#c.NPY_AO.data", "type": "Python Types and C-Structures", "text": "\nAccessible via `PyArray_DATA`, this data member is a pointer to the first\nelement of the array. This pointer can (and normally should) be recast to the\ndata type of the array.\n\n"}, {"name": "char *dataptr", "path": "reference/c-api/types-and-structures#c.PyArrayIterObject.dataptr", "type": "Python Types and C-Structures", "text": "\nThis member points to an element in the ndarray indicated by the index.\n\n"}, {"name": "char *doc", "path": "reference/c-api/types-and-structures#c.PyUFuncObject.doc", "type": "Python Types and C-Structures", "text": "\nDocumentation for the ufunc. Should not contain the function signature as this\nis generated dynamically when __doc__ is retrieved.\n\n"}, {"name": "char *name", "path": "reference/c-api/types-and-structures#c.PyUFuncObject.name", "type": "Python Types and C-Structures", "text": "\nA string name for the ufunc. This is used dynamically to build the __doc__\nattribute of ufuncs.\n\n"}, {"name": "char *PyArray_BYTES()", "path": "reference/c-api/array#c.PyArray_BYTES", "type": "Array API", "text": "\nThese two macros are similar and obtain the pointer to the data-buffer for the\narray. The first macro can (and should be) assigned to a particular pointer\nwhere the second is for generic processing. If you have not guaranteed a\ncontiguous and/or aligned array then be sure you understand how to access the\ndata in the array to avoid memory and/or alignment problems.\n\n"}, {"name": "char *PyArray_One()", "path": "reference/c-api/array#c.PyArray_One", "type": "Array API", "text": "\nA pointer to newly created memory of size arr ->itemsize that holds the\nrepresentation of 1 for that type. The returned pointer, ret, must be freed\nusing `PyDataMem_FREE` (ret) when it is not needed anymore.\n\n"}, {"name": "char *PyArray_Zero()", "path": "reference/c-api/array#c.PyArray_Zero", "type": "Array API", "text": "\nA pointer to newly created memory of size arr ->itemsize that holds the\nrepresentation of 0 for that type. The returned pointer, ret, must be freed\nusing `PyDataMem_FREE` (ret) when it is not needed anymore.\n\n"}, {"name": "char *PyDataMem_RENEW()", "path": "reference/c-api/array#c.PyDataMem_RENEW", "type": "Array API", "text": "\nMacros to allocate, free, and reallocate memory. These macros are used\ninternally to create arrays.\n\n"}, {"name": "char *types", "path": "reference/c-api/types-and-structures#c.PyUFuncObject.types", "type": "Python Types and C-Structures", "text": "\nAn array of \\\\(nargs \\times ntypes\\\\) 8-bit type_numbers which contains the\ntype signature for the function for each of the supported (builtin) data\ntypes. For each of the ntypes functions, the corresponding set of type numbers\nin this array shows how the args argument should be interpreted in the 1-d\nvector loop. These type numbers do not have to be the same type and mixed-type\nufuncs are supported.\n\n"}, {"name": "char byteorder", "path": "reference/c-api/types-and-structures#c.PyArray_Descr.byteorder", "type": "Python Types and C-Structures", "text": "\nA character indicating the byte-order: \u2018>\u2019 (big-endian), \u2018<\u2019 (little- endian),\n\u2018=\u2019 (native), \u2018|\u2019 (irrelevant, ignore). All builtin data- types have byteorder\n\u2018=\u2019.\n\n"}, {"name": "char flags", "path": "reference/c-api/types-and-structures#c.PyArray_Descr.flags", "type": "Python Types and C-Structures", "text": "\nA data-type bit-flag that determines if the data-type exhibits object- array\nlike behavior. Each bit in this member is a flag which are named as:\n\n"}, {"name": "char kind", "path": "reference/c-api/types-and-structures#c.PyArray_Descr.kind", "type": "Python Types and C-Structures", "text": "\nA character code indicating the kind of array (using the array interface\ntypestring notation). A \u2018b\u2019 represents Boolean, a \u2018i\u2019 represents signed\ninteger, a \u2018u\u2019 represents unsigned integer, \u2018f\u2019 represents floating point, \u2018c\u2019\nrepresents complex floating point, \u2018S\u2019 represents 8-bit zero-terminated bytes,\n\u2018U\u2019 represents 32-bit/character unicode string, and \u2018V\u2019 represents arbitrary.\n\n"}, {"name": "char type", "path": "reference/c-api/types-and-structures#c.PyArray_Descr.type", "type": "Python Types and C-Structures", "text": "\nA traditional character code indicating the data type.\n\n"}, {"name": "char typekind", "path": "reference/c-api/types-and-structures#c.PyArrayInterface.typekind", "type": "Python Types and C-Structures", "text": "\nA character indicating what kind of array is present according to the\ntypestring convention with \u2018t\u2019 -> bitfield, \u2018b\u2019 -> Boolean, \u2018i\u2019 -> signed\ninteger, \u2018u\u2019 -> unsigned integer, \u2018f\u2019 -> floating point, \u2018c\u2019 -> complex\nfloating point, \u2018O\u2019 -> object, \u2018S\u2019 -> (byte-)string, \u2018U\u2019 -> unicode, \u2018V\u2019 ->\nvoid.\n\n"}, {"name": "char.add()", "path": "reference/generated/numpy.char.add", "type": "numpy.char.add", "text": "\nReturn element-wise string concatenation for two arrays of str or unicode.\n\nArrays `x1` and `x2` must have the same shape.\n\nInput array.\n\nInput array.\n\nOutput array of `string_` or `unicode_`, depending on input types of the same\nshape as `x1` and `x2`.\n\n"}, {"name": "char.array()", "path": "reference/generated/numpy.char.array", "type": "numpy.char.array", "text": "\nCreate a `chararray`.\n\nNote\n\nThis class is provided for numarray backward-compatibility. New code (not\nconcerned with numarray compatibility) should use arrays of type `string_` or\n`unicode_` and use the free functions in `numpy.char` for fast vectorized\nstring operations instead.\n\nVersus a regular NumPy array of type `str` or `unicode`, this class adds the\nfollowing functionality:\n\n`itemsize` is the number of characters per scalar in the resulting array. If\n`itemsize` is None, and `obj` is an object array or a Python list, the\n`itemsize` will be automatically determined. If `itemsize` is provided and\n`obj` is of type str or unicode, then the `obj` string will be chunked into\n`itemsize` pieces.\n\nIf true (default), then the object is copied. Otherwise, a copy will only be\nmade if __array__ returns a copy, if obj is a nested sequence, or if a copy is\nneeded to satisfy any of the other requirements (`itemsize`, unicode, `order`,\netc.).\n\nWhen true, the resulting `chararray` can contain Unicode characters, when\nfalse only 8-bit characters. If unicode is None and `obj` is one of the\nfollowing:\n\nthen the unicode setting of the output array will be automatically determined.\n\nSpecify the order of the array. If order is \u2018C\u2019 (default), then the array will\nbe in C-contiguous order (last-index varies the fastest). If order is \u2018F\u2019,\nthen the returned array will be in Fortran-contiguous order (first-index\nvaries the fastest). If order is \u2018A\u2019, then the returned array may be in any\norder (either C-, Fortran-contiguous, or even discontiguous).\n\n"}, {"name": "char.asarray()", "path": "reference/generated/numpy.char.asarray", "type": "numpy.char.asarray", "text": "\nConvert the input to a `chararray`, copying the data only if necessary.\n\nVersus a regular NumPy array of type `str` or `unicode`, this class adds the\nfollowing functionality:\n\n`itemsize` is the number of characters per scalar in the resulting array. If\n`itemsize` is None, and `obj` is an object array or a Python list, the\n`itemsize` will be automatically determined. If `itemsize` is provided and\n`obj` is of type str or unicode, then the `obj` string will be chunked into\n`itemsize` pieces.\n\nWhen true, the resulting `chararray` can contain Unicode characters, when\nfalse only 8-bit characters. If unicode is None and `obj` is one of the\nfollowing:\n\nthen the unicode setting of the output array will be automatically determined.\n\nSpecify the order of the array. If order is \u2018C\u2019 (default), then the array will\nbe in C-contiguous order (last-index varies the fastest). If order is \u2018F\u2019,\nthen the returned array will be in Fortran-contiguous order (first-index\nvaries the fastest).\n\n"}, {"name": "char.capitalize()", "path": "reference/generated/numpy.char.capitalize", "type": "numpy.char.capitalize", "text": "\nReturn a copy of `a` with only the first character of each element\ncapitalized.\n\nCalls `str.capitalize` element-wise.\n\nFor 8-bit strings, this method is locale-dependent.\n\nInput array of strings to capitalize.\n\nOutput array of str or unicode, depending on input types\n\nSee also\n\n"}, {"name": "char.center()", "path": "reference/generated/numpy.char.center", "type": "numpy.char.center", "text": "\nReturn a copy of `a` with its elements centered in a string of length `width`.\n\nCalls `str.center` element-wise.\n\nThe length of the resulting strings\n\nThe padding character to use (default is space).\n\nOutput array of str or unicode, depending on input types\n\nSee also\n\n"}, {"name": "char.chararray.argsort()", "path": "reference/generated/numpy.char.chararray.argsort", "type": "numpy.char.chararray.argsort", "text": "\nmethod\n\nReturns the indices that would sort this array.\n\nRefer to `numpy.argsort` for full documentation.\n\nSee also\n\nequivalent function\n\n"}, {"name": "char.chararray.astype()", "path": "reference/generated/numpy.char.chararray.astype", "type": "numpy.char.chararray.astype", "text": "\nmethod\n\nCopy of the array, cast to a specified type.\n\nTypecode or data-type to which the array is cast.\n\nControls the memory layout order of the result. \u2018C\u2019 means C order, \u2018F\u2019 means\nFortran order, \u2018A\u2019 means \u2018F\u2019 order if all the arrays are Fortran contiguous,\n\u2018C\u2019 order otherwise, and \u2018K\u2019 means as close to the order the array elements\nappear in memory as possible. Default is \u2018K\u2019.\n\nControls what kind of data casting may occur. Defaults to \u2018unsafe\u2019 for\nbackwards compatibility.\n\nIf True, then sub-classes will be passed-through (default), otherwise the\nreturned array will be forced to be a base-class array.\n\nBy default, astype always returns a newly allocated array. If this is set to\nfalse, and the `dtype`, `order`, and `subok` requirements are satisfied, the\ninput array is returned instead of a copy.\n\nUnless `copy` is False and the other conditions for returning the input array\nare satisfied (see description for `copy` input parameter), `arr_t` is a new\narray of the same shape as the input array, with dtype, order given by\n`dtype`, `order`.\n\nWhen casting from complex to float or int. To avoid this, one should use\n`a.real.astype(t)`.\n\nChanged in version 1.17.0: Casting between a simple data type and a structured\none is possible only for \u201cunsafe\u201d casting. Casting to multiple fields is\nallowed, but casting from multiple fields is not.\n\nChanged in version 1.9.0: Casting from numeric to string types in \u2018safe\u2019\ncasting mode requires that the string dtype length is long enough to store the\nmax integer/float value converted.\n\n"}, {"name": "char.chararray.base", "path": "reference/generated/numpy.char.chararray.base", "type": "String operations", "text": "\nattribute\n\nBase object if memory is from some other object.\n\nThe base of an array that owns its memory is None:\n\nSlicing creates a view, whose memory is shared with x:\n\n"}, {"name": "char.chararray.copy()", "path": "reference/generated/numpy.char.chararray.copy", "type": "numpy.char.chararray.copy", "text": "\nmethod\n\nReturn a copy of the array.\n\nControls the memory layout of the copy. \u2018C\u2019 means C-order, \u2018F\u2019 means F-order,\n\u2018A\u2019 means \u2018F\u2019 if `a` is Fortran contiguous, \u2018C\u2019 otherwise. \u2018K\u2019 means match the\nlayout of `a` as closely as possible. (Note that this function and\n`numpy.copy` are very similar but have different default values for their\norder= arguments, and this function always passes sub-classes through.)\n\nSee also\n\nSimilar function with different default behavior\n\nThis function is the preferred method for creating an array copy. The function\n`numpy.copy` is similar, but it defaults to using order \u2018K\u2019, and will not pass\nsub-classes through by default.\n\n"}, {"name": "char.chararray.count()", "path": "reference/generated/numpy.char.chararray.count", "type": "numpy.char.chararray.count", "text": "\nmethod\n\nReturns an array with the number of non-overlapping occurrences of substring\n`sub` in the range [`start`, `end`].\n\nSee also\n\n"}, {"name": "char.chararray.ctypes", "path": "reference/generated/numpy.char.chararray.ctypes", "type": "String operations", "text": "\nattribute\n\nAn object to simplify the interaction of the array with the ctypes module.\n\nThis attribute creates an object that makes it easier to use arrays when\ncalling shared libraries with the ctypes module. The returned object has,\namong others, data, shape, and strides attributes (see Notes below) which\nthemselves return ctypes objects that can be used as arguments to a shared\nlibrary.\n\nPossessing attributes data, shape, strides, etc.\n\nSee also\n\nBelow are the public attributes of this object which were documented in \u201cGuide\nto NumPy\u201d (we have omitted undocumented public attributes, as well as\ndocumented private attributes):\n\nA pointer to the memory area of the array as a Python integer. This memory\narea may contain data that is not aligned, or not in correct byte-order. The\nmemory area may not even be writeable. The array flags and data-type of this\narray should be respected when passing this attribute to arbitrary C-code to\navoid trouble that can include Python crashing. User Beware! The value of this\nattribute is exactly the same as `self._array_interface_['data'][0]`.\n\nNote that unlike `data_as`, a reference will not be kept to the array: code\nlike `ctypes.c_void_p((a + b).ctypes.data)` will result in a pointer to a\ndeallocated array, and should be spelt `(a +\nb).ctypes.data_as(ctypes.c_void_p)`\n\n(c_intp*self.ndim): A ctypes array of length self.ndim where the basetype is\nthe C-integer corresponding to `dtype('p')` on this platform (see `c_intp`).\nThis base-type could be `ctypes.c_int`, `ctypes.c_long`, or\n`ctypes.c_longlong` depending on the platform. The ctypes array contains the\nshape of the underlying array.\n\n(c_intp*self.ndim): A ctypes array of length self.ndim where the basetype is\nthe same as for the shape attribute. This ctypes array contains the strides\ninformation from the underlying array. This strides information is important\nfor showing how many bytes must be jumped to get to the next element in the\narray.\n\nReturn the data pointer cast to a particular c-types object. For example,\ncalling `self._as_parameter_` is equivalent to\n`self.data_as(ctypes.c_void_p)`. Perhaps you want to use the data as a pointer\nto a ctypes array of floating-point data:\n`self.data_as(ctypes.POINTER(ctypes.c_double))`.\n\nThe returned pointer will keep a reference to the array.\n\nReturn the shape tuple as an array of some other c-types type. For example:\n`self.shape_as(ctypes.c_short)`.\n\nReturn the strides tuple as an array of some other c-types type. For example:\n`self.strides_as(ctypes.c_longlong)`.\n\nIf the ctypes module is not available, then the ctypes attribute of array\nobjects still returns something useful, but ctypes objects are not returned\nand errors may be raised instead. In particular, the object will still have\nthe `as_parameter` attribute which will return an integer equal to the data\nattribute.\n\n"}, {"name": "char.chararray.data", "path": "reference/generated/numpy.char.chararray.data", "type": "String operations", "text": "\nattribute\n\nPython buffer object pointing to the start of the array\u2019s data.\n\n"}, {"name": "char.chararray.decode()", "path": "reference/generated/numpy.char.chararray.decode", "type": "numpy.char.chararray.decode", "text": "\nmethod\n\nCalls `str.decode` element-wise.\n\nSee also\n\n"}, {"name": "char.chararray.dtype", "path": "reference/generated/numpy.char.chararray.dtype", "type": "String operations", "text": "\nattribute\n\nData-type of the array\u2019s elements.\n\nSee also\n\n"}, {"name": "char.chararray.dump()", "path": "reference/generated/numpy.char.chararray.dump", "type": "numpy.char.chararray.dump", "text": "\nmethod\n\nDump a pickle of the array to the specified file. The array can be read back\nwith pickle.load or numpy.load.\n\nA string naming the dump file.\n\nChanged in version 1.17.0: `pathlib.Path` objects are now accepted.\n\n"}, {"name": "char.chararray.dumps()", "path": "reference/generated/numpy.char.chararray.dumps", "type": "numpy.char.chararray.dumps", "text": "\nmethod\n\nReturns the pickle of the array as a string. pickle.loads will convert the\nstring back to an array.\n\n"}, {"name": "char.chararray.encode()", "path": "reference/generated/numpy.char.chararray.encode", "type": "numpy.char.chararray.encode", "text": "\nmethod\n\nCalls `str.encode` element-wise.\n\nSee also\n\n"}, {"name": "char.chararray.endswith()", "path": "reference/generated/numpy.char.chararray.endswith", "type": "numpy.char.chararray.endswith", "text": "\nmethod\n\nReturns a boolean array which is `True` where the string element in `self`\nends with `suffix`, otherwise `False`.\n\nSee also\n\n"}, {"name": "char.chararray.expandtabs()", "path": "reference/generated/numpy.char.chararray.expandtabs", "type": "numpy.char.chararray.expandtabs", "text": "\nmethod\n\nReturn a copy of each string element where all tab characters are replaced by\none or more spaces.\n\nSee also\n\n"}, {"name": "char.chararray.fill()", "path": "reference/generated/numpy.char.chararray.fill", "type": "numpy.char.chararray.fill", "text": "\nmethod\n\nFill the array with a scalar value.\n\nAll elements of `a` will be assigned this value.\n\n"}, {"name": "char.chararray.find()", "path": "reference/generated/numpy.char.chararray.find", "type": "numpy.char.chararray.find", "text": "\nmethod\n\nFor each element, return the lowest index in the string where substring `sub`\nis found.\n\nSee also\n\n"}, {"name": "char.chararray.flags", "path": "reference/generated/numpy.char.chararray.flags", "type": "String operations", "text": "\nattribute\n\nInformation about the memory layout of the array.\n\nThe `flags` object can be accessed dictionary-like (as in\n`a.flags['WRITEABLE']`), or by using lowercased attribute names (as in\n`a.flags.writeable`). Short flag names are only supported in dictionary\naccess.\n\nOnly the WRITEBACKIFCOPY, UPDATEIFCOPY, WRITEABLE, and ALIGNED flags can be\nchanged by the user, via direct assignment to the attribute or dictionary\nentry, or by calling `ndarray.setflags`.\n\nThe array flags cannot be set arbitrarily:\n\nArrays can be both C-style and Fortran-style contiguous simultaneously. This\nis clear for 1-dimensional arrays, but can also be true for higher dimensional\narrays.\n\nEven for contiguous arrays a stride for a given dimension `arr.strides[dim]`\nmay be arbitrary if `arr.shape[dim] == 1` or the array has no elements. It\ndoes not generally hold that `self.strides[-1] == self.itemsize` for C-style\ncontiguous arrays or `self.strides[0] == self.itemsize` for Fortran-style\ncontiguous arrays is true.\n\nThe data is in a single, C-style contiguous segment.\n\nThe data is in a single, Fortran-style contiguous segment.\n\nThe array owns the memory it uses or borrows it from another object.\n\nThe data area can be written to. Setting this to False locks the data, making\nit read-only. A view (slice, etc.) inherits WRITEABLE from its base array at\ncreation time, but a view of a writeable array may be subsequently locked\nwhile the base array remains writeable. (The opposite is not true, in that a\nview of a locked array may not be made writeable. However, currently, locking\na base object does not lock any views that already reference it, so under that\ncircumstance it is possible to alter the contents of a locked array via a\npreviously created writeable view onto it.) Attempting to change a non-\nwriteable array raises a RuntimeError exception.\n\nThe data and all elements are aligned appropriately for the hardware.\n\nThis array is a copy of some other array. The C-API function\nPyArray_ResolveWritebackIfCopy must be called before deallocating to the base\narray will be updated with the contents of this array.\n\n(Deprecated, use WRITEBACKIFCOPY) This array is a copy of some other array.\nWhen this array is deallocated, the base array will be updated with the\ncontents of this array.\n\nF_CONTIGUOUS and not C_CONTIGUOUS.\n\nF_CONTIGUOUS or C_CONTIGUOUS (one-segment test).\n\nALIGNED and WRITEABLE.\n\nBEHAVED and C_CONTIGUOUS.\n\nBEHAVED and F_CONTIGUOUS and not C_CONTIGUOUS.\n\n"}, {"name": "char.chararray.flat", "path": "reference/generated/numpy.char.chararray.flat", "type": "String operations", "text": "\nattribute\n\nA 1-D iterator over the array.\n\nThis is a `numpy.flatiter` instance, which acts similarly to, but is not a\nsubclass of, Python\u2019s built-in iterator object.\n\nSee also\n\nReturn a copy of the array collapsed into one dimension.\n\nAn assignment example:\n\n"}, {"name": "char.chararray.flatten()", "path": "reference/generated/numpy.char.chararray.flatten", "type": "numpy.char.chararray.flatten", "text": "\nmethod\n\nReturn a copy of the array collapsed into one dimension.\n\n\u2018C\u2019 means to flatten in row-major (C-style) order. \u2018F\u2019 means to flatten in\ncolumn-major (Fortran- style) order. \u2018A\u2019 means to flatten in column-major\norder if `a` is Fortran contiguous in memory, row-major order otherwise. \u2018K\u2019\nmeans to flatten `a` in the order the elements occur in memory. The default is\n\u2018C\u2019.\n\nA copy of the input array, flattened to one dimension.\n\nSee also\n\nReturn a flattened array.\n\nA 1-D flat iterator over the array.\n\n"}, {"name": "char.chararray.getfield()", "path": "reference/generated/numpy.char.chararray.getfield", "type": "numpy.char.chararray.getfield", "text": "\nmethod\n\nReturns a field of the given array as a certain type.\n\nA field is a view of the array data with a given data-type. The values in the\nview are determined by the given type and the offset into the current array in\nbytes. The offset needs to be such that the view dtype fits in the array\ndtype; for example an array of dtype complex128 has 16-byte elements. If\ntaking a view with a 32-bit integer (4 bytes), the offset needs to be between\n0 and 12 bytes.\n\nThe data type of the view. The dtype size of the view can not be larger than\nthat of the array itself.\n\nNumber of bytes to skip before beginning the element view.\n\nBy choosing an offset of 8 bytes we can select the complex part of the array\nfor our view:\n\n"}, {"name": "char.chararray.imag", "path": "reference/generated/numpy.char.chararray.imag", "type": "String operations", "text": "\nattribute\n\nThe imaginary part of the array.\n\n"}, {"name": "char.chararray.index()", "path": "reference/generated/numpy.char.chararray.index", "type": "numpy.char.chararray.index", "text": "\nmethod\n\nLike `find`, but raises `ValueError` when the substring is not found.\n\nSee also\n\n"}, {"name": "char.chararray.isalnum()", "path": "reference/generated/numpy.char.chararray.isalnum", "type": "numpy.char.chararray.isalnum", "text": "\nmethod\n\nReturns true for each element if all characters in the string are alphanumeric\nand there is at least one character, false otherwise.\n\nSee also\n\n"}, {"name": "char.chararray.isalpha()", "path": "reference/generated/numpy.char.chararray.isalpha", "type": "numpy.char.chararray.isalpha", "text": "\nmethod\n\nReturns true for each element if all characters in the string are alphabetic\nand there is at least one character, false otherwise.\n\nSee also\n\n"}, {"name": "char.chararray.isdecimal()", "path": "reference/generated/numpy.char.chararray.isdecimal", "type": "numpy.char.chararray.isdecimal", "text": "\nmethod\n\nFor each element in `self`, return True if there are only decimal characters\nin the element.\n\nSee also\n\n"}, {"name": "char.chararray.isdigit()", "path": "reference/generated/numpy.char.chararray.isdigit", "type": "numpy.char.chararray.isdigit", "text": "\nmethod\n\nReturns true for each element if all characters in the string are digits and\nthere is at least one character, false otherwise.\n\nSee also\n\n"}, {"name": "char.chararray.islower()", "path": "reference/generated/numpy.char.chararray.islower", "type": "numpy.char.chararray.islower", "text": "\nmethod\n\nReturns true for each element if all cased characters in the string are\nlowercase and there is at least one cased character, false otherwise.\n\nSee also\n\n"}, {"name": "char.chararray.isnumeric()", "path": "reference/generated/numpy.char.chararray.isnumeric", "type": "numpy.char.chararray.isnumeric", "text": "\nmethod\n\nFor each element in `self`, return True if there are only numeric characters\nin the element.\n\nSee also\n\n"}, {"name": "char.chararray.isspace()", "path": "reference/generated/numpy.char.chararray.isspace", "type": "numpy.char.chararray.isspace", "text": "\nmethod\n\nReturns true for each element if there are only whitespace characters in the\nstring and there is at least one character, false otherwise.\n\nSee also\n\n"}, {"name": "char.chararray.istitle()", "path": "reference/generated/numpy.char.chararray.istitle", "type": "numpy.char.chararray.istitle", "text": "\nmethod\n\nReturns true for each element if the element is a titlecased string and there\nis at least one character, false otherwise.\n\nSee also\n\n"}, {"name": "char.chararray.isupper()", "path": "reference/generated/numpy.char.chararray.isupper", "type": "numpy.char.chararray.isupper", "text": "\nmethod\n\nReturns true for each element if all cased characters in the string are\nuppercase and there is at least one character, false otherwise.\n\nSee also\n\n"}, {"name": "char.chararray.item()", "path": "reference/generated/numpy.char.chararray.item", "type": "numpy.char.chararray.item", "text": "\nmethod\n\nCopy an element of an array to a standard Python scalar and return it.\n\nA copy of the specified element of the array as a suitable Python scalar\n\nWhen the data type of `a` is longdouble or clongdouble, item() returns a\nscalar array object because there is no available Python scalar that would not\nlose information. Void arrays return a buffer object for item(), unless fields\nare defined, in which case a tuple is returned.\n\n`item` is very similar to a[args], except, instead of an array scalar, a\nstandard Python scalar is returned. This can be useful for speeding up access\nto elements of the array and doing arithmetic on elements of the array using\nPython\u2019s optimized math.\n\n"}, {"name": "char.chararray.itemsize", "path": "reference/generated/numpy.char.chararray.itemsize", "type": "String operations", "text": "\nattribute\n\nLength of one array element in bytes.\n\n"}, {"name": "char.chararray.join()", "path": "reference/generated/numpy.char.chararray.join", "type": "numpy.char.chararray.join", "text": "\nmethod\n\nReturn a string which is the concatenation of the strings in the sequence\n`seq`.\n\nSee also\n\n"}, {"name": "char.chararray.ljust()", "path": "reference/generated/numpy.char.chararray.ljust", "type": "numpy.char.chararray.ljust", "text": "\nmethod\n\nReturn an array with the elements of `self` left-justified in a string of\nlength `width`.\n\nSee also\n\n"}, {"name": "char.chararray.lower()", "path": "reference/generated/numpy.char.chararray.lower", "type": "numpy.char.chararray.lower", "text": "\nmethod\n\nReturn an array with the elements of `self` converted to lowercase.\n\nSee also\n\n"}, {"name": "char.chararray.lstrip()", "path": "reference/generated/numpy.char.chararray.lstrip", "type": "numpy.char.chararray.lstrip", "text": "\nmethod\n\nFor each element in `self`, return a copy with the leading characters removed.\n\nSee also\n\n"}, {"name": "char.chararray.nbytes", "path": "reference/generated/numpy.char.chararray.nbytes", "type": "String operations", "text": "\nattribute\n\nTotal bytes consumed by the elements of the array.\n\nDoes not include memory consumed by non-element attributes of the array\nobject.\n\n"}, {"name": "char.chararray.ndim", "path": "reference/generated/numpy.char.chararray.ndim", "type": "String operations", "text": "\nattribute\n\nNumber of array dimensions.\n\n"}, {"name": "char.chararray.nonzero()", "path": "reference/generated/numpy.char.chararray.nonzero", "type": "numpy.char.chararray.nonzero", "text": "\nmethod\n\nReturn the indices of the elements that are non-zero.\n\nRefer to `numpy.nonzero` for full documentation.\n\nSee also\n\nequivalent function\n\n"}, {"name": "char.chararray.put()", "path": "reference/generated/numpy.char.chararray.put", "type": "numpy.char.chararray.put", "text": "\nmethod\n\nSet `a.flat[n] = values[n]` for all `n` in indices.\n\nRefer to `numpy.put` for full documentation.\n\nSee also\n\nequivalent function\n\n"}, {"name": "char.chararray.ravel()", "path": "reference/generated/numpy.char.chararray.ravel", "type": "numpy.char.chararray.ravel", "text": "\nmethod\n\nReturn a flattened array.\n\nRefer to `numpy.ravel` for full documentation.\n\nSee also\n\nequivalent function\n\na flat iterator on the array.\n\n"}, {"name": "char.chararray.real", "path": "reference/generated/numpy.char.chararray.real", "type": "String operations", "text": "\nattribute\n\nThe real part of the array.\n\nSee also\n\nequivalent function\n\n"}, {"name": "char.chararray.repeat()", "path": "reference/generated/numpy.char.chararray.repeat", "type": "numpy.char.chararray.repeat", "text": "\nmethod\n\nRepeat elements of an array.\n\nRefer to `numpy.repeat` for full documentation.\n\nSee also\n\nequivalent function\n\n"}, {"name": "char.chararray.replace()", "path": "reference/generated/numpy.char.chararray.replace", "type": "numpy.char.chararray.replace", "text": "\nmethod\n\nFor each element in `self`, return a copy of the string with all occurrences\nof substring `old` replaced by `new`.\n\nSee also\n\n"}, {"name": "char.chararray.reshape()", "path": "reference/generated/numpy.char.chararray.reshape", "type": "numpy.char.chararray.reshape", "text": "\nmethod\n\nReturns an array containing the same data with a new shape.\n\nRefer to `numpy.reshape` for full documentation.\n\nSee also\n\nequivalent function\n\nUnlike the free function `numpy.reshape`, this method on `ndarray` allows the\nelements of the shape parameter to be passed in as separate arguments. For\nexample, `a.reshape(10, 11)` is equivalent to `a.reshape((10, 11))`.\n\n"}, {"name": "char.chararray.resize()", "path": "reference/generated/numpy.char.chararray.resize", "type": "numpy.char.chararray.resize", "text": "\nmethod\n\nChange shape and size of array in-place.\n\nShape of resized array.\n\nIf False, reference count will not be checked. Default is True.\n\nIf `a` does not own its own data or references or views to it exist, and the\ndata memory must be changed. PyPy only: will always raise if the data memory\nmust be changed, since there is no reliable way to determine if references or\nviews to it exist.\n\nIf the `order` keyword argument is specified. This behaviour is a bug in\nNumPy.\n\nSee also\n\nReturn a new array with the specified shape.\n\nThis reallocates space for the data area if necessary.\n\nOnly contiguous arrays (data elements consecutive in memory) can be resized.\n\nThe purpose of the reference count check is to make sure you do not use this\narray as a buffer for another Python object and then reallocate the memory.\nHowever, reference counts can increase in other ways so if you are sure that\nyou have not shared the memory for this array with another Python object, then\nyou may safely set `refcheck` to False.\n\nShrinking an array: array is flattened (in the order that the data are stored\nin memory), resized, and reshaped:\n\nEnlarging an array: as above, but missing entries are filled with zeros:\n\nReferencing an array prevents resizing\u2026\n\nUnless `refcheck` is False:\n\n"}, {"name": "char.chararray.rfind()", "path": "reference/generated/numpy.char.chararray.rfind", "type": "numpy.char.chararray.rfind", "text": "\nmethod\n\nFor each element in `self`, return the highest index in the string where\nsubstring `sub` is found, such that `sub` is contained within [`start`,\n`end`].\n\nSee also\n\n"}, {"name": "char.chararray.rindex()", "path": "reference/generated/numpy.char.chararray.rindex", "type": "numpy.char.chararray.rindex", "text": "\nmethod\n\nLike `rfind`, but raises `ValueError` when the substring `sub` is not found.\n\nSee also\n\n"}, {"name": "char.chararray.rjust()", "path": "reference/generated/numpy.char.chararray.rjust", "type": "numpy.char.chararray.rjust", "text": "\nmethod\n\nReturn an array with the elements of `self` right-justified in a string of\nlength `width`.\n\nSee also\n\n"}, {"name": "char.chararray.rsplit()", "path": "reference/generated/numpy.char.chararray.rsplit", "type": "numpy.char.chararray.rsplit", "text": "\nmethod\n\nFor each element in `self`, return a list of the words in the string, using\n`sep` as the delimiter string.\n\nSee also\n\n"}, {"name": "char.chararray.rstrip()", "path": "reference/generated/numpy.char.chararray.rstrip", "type": "numpy.char.chararray.rstrip", "text": "\nmethod\n\nFor each element in `self`, return a copy with the trailing characters\nremoved.\n\nSee also\n\n"}, {"name": "char.chararray.searchsorted()", "path": "reference/generated/numpy.char.chararray.searchsorted", "type": "numpy.char.chararray.searchsorted", "text": "\nmethod\n\nFind indices where elements of v should be inserted in a to maintain order.\n\nFor full documentation, see `numpy.searchsorted`\n\nSee also\n\nequivalent function\n\n"}, {"name": "char.chararray.setfield()", "path": "reference/generated/numpy.char.chararray.setfield", "type": "numpy.char.chararray.setfield", "text": "\nmethod\n\nPut a value into a specified place in a field defined by a data-type.\n\nPlace `val` into `a`\u2019s field defined by `dtype` and beginning `offset` bytes\ninto the field.\n\nValue to be placed in field.\n\nData-type of the field in which to place `val`.\n\nThe number of bytes into the field at which to place `val`.\n\nSee also\n\n"}, {"name": "char.chararray.setflags()", "path": "reference/generated/numpy.char.chararray.setflags", "type": "numpy.char.chararray.setflags", "text": "\nmethod\n\nSet array flags WRITEABLE, ALIGNED, (WRITEBACKIFCOPY and UPDATEIFCOPY),\nrespectively.\n\nThese Boolean-valued flags affect how numpy interprets the memory area used by\n`a` (see Notes below). The ALIGNED flag can only be set to True if the data is\nactually aligned according to the type. The WRITEBACKIFCOPY and (deprecated)\nUPDATEIFCOPY flags can never be set to True. The flag WRITEABLE can only be\nset to True if the array owns its own memory, or the ultimate owner of the\nmemory exposes a writeable buffer interface, or is a string. (The exception\nfor string is made so that unpickling can be done without copying memory.)\n\nDescribes whether or not `a` can be written to.\n\nDescribes whether or not `a` is aligned properly for its type.\n\nDescribes whether or not `a` is a copy of another \u201cbase\u201d array.\n\nArray flags provide information about how the memory area used for the array\nis to be interpreted. There are 7 Boolean flags in use, only four of which can\nbe changed by the user: WRITEBACKIFCOPY, UPDATEIFCOPY, WRITEABLE, and ALIGNED.\n\nWRITEABLE (W) the data area can be written to;\n\nALIGNED (A) the data and strides are aligned appropriately for the hardware\n(as determined by the compiler);\n\nUPDATEIFCOPY (U) (deprecated), replaced by WRITEBACKIFCOPY;\n\nWRITEBACKIFCOPY (X) this array is a copy of some other array (referenced by\n.base). When the C-API function PyArray_ResolveWritebackIfCopy is called, the\nbase array will be updated with the contents of this array.\n\nAll flags can be accessed using the single (upper case) letter as well as the\nfull name.\n\n"}, {"name": "char.chararray.shape", "path": "reference/generated/numpy.char.chararray.shape", "type": "String operations", "text": "\nattribute\n\nTuple of array dimensions.\n\nThe shape property is usually used to get the current shape of an array, but\nmay also be used to reshape the array in-place by assigning a tuple of array\ndimensions to it. As with `numpy.reshape`, one of the new shape dimensions can\nbe -1, in which case its value is inferred from the size of the array and the\nremaining dimensions. Reshaping an array in-place will fail if a copy is\nrequired.\n\nSee also\n\nsimilar function\n\nsimilar method\n\n"}, {"name": "char.chararray.size", "path": "reference/generated/numpy.char.chararray.size", "type": "String operations", "text": "\nattribute\n\nNumber of elements in the array.\n\nEqual to `np.prod(a.shape)`, i.e., the product of the array\u2019s dimensions.\n\n`a.size` returns a standard arbitrary precision Python integer. This may not\nbe the case with other methods of obtaining the same value (like the suggested\n`np.prod(a.shape)`, which returns an instance of `np.int_`), and may be\nrelevant if the value is used further in calculations that may overflow a\nfixed size integer type.\n\n"}, {"name": "char.chararray.sort()", "path": "reference/generated/numpy.char.chararray.sort", "type": "numpy.char.chararray.sort", "text": "\nmethod\n\nSort an array in-place. Refer to `numpy.sort` for full documentation.\n\nAxis along which to sort. Default is -1, which means sort along the last axis.\n\nSorting algorithm. The default is \u2018quicksort\u2019. Note that both \u2018stable\u2019 and\n\u2018mergesort\u2019 use timsort under the covers and, in general, the actual\nimplementation will vary with datatype. The \u2018mergesort\u2019 option is retained for\nbackwards compatibility.\n\nChanged in version 1.15.0: The \u2018stable\u2019 option was added.\n\nWhen `a` is an array with fields defined, this argument specifies which fields\nto compare first, second, etc. A single field can be specified as a string,\nand not all fields need be specified, but unspecified fields will still be\nused, in the order in which they come up in the dtype, to break ties.\n\nSee also\n\nReturn a sorted copy of an array.\n\nIndirect sort.\n\nIndirect stable sort on multiple keys.\n\nFind elements in sorted array.\n\nPartial sort.\n\nSee `numpy.sort` for notes on the different sorting algorithms.\n\nUse the `order` keyword to specify a field to use when sorting a structured\narray:\n\n"}, {"name": "char.chararray.split()", "path": "reference/generated/numpy.char.chararray.split", "type": "numpy.char.chararray.split", "text": "\nmethod\n\nFor each element in `self`, return a list of the words in the string, using\n`sep` as the delimiter string.\n\nSee also\n\n"}, {"name": "char.chararray.splitlines()", "path": "reference/generated/numpy.char.chararray.splitlines", "type": "numpy.char.chararray.splitlines", "text": "\nmethod\n\nFor each element in `self`, return a list of the lines in the element,\nbreaking at line boundaries.\n\nSee also\n\n"}, {"name": "char.chararray.squeeze()", "path": "reference/generated/numpy.char.chararray.squeeze", "type": "numpy.char.chararray.squeeze", "text": "\nmethod\n\nRemove axes of length one from `a`.\n\nRefer to `numpy.squeeze` for full documentation.\n\nSee also\n\nequivalent function\n\n"}, {"name": "char.chararray.startswith()", "path": "reference/generated/numpy.char.chararray.startswith", "type": "numpy.char.chararray.startswith", "text": "\nmethod\n\nReturns a boolean array which is `True` where the string element in `self`\nstarts with `prefix`, otherwise `False`.\n\nSee also\n\n"}, {"name": "char.chararray.strides", "path": "reference/generated/numpy.char.chararray.strides", "type": "String operations", "text": "\nattribute\n\nTuple of bytes to step in each dimension when traversing an array.\n\nThe byte offset of element `(i[0], i[1], ..., i[n])` in an array `a` is:\n\nA more detailed explanation of strides can be found in the \u201cndarray.rst\u201d file\nin the NumPy reference guide.\n\nSee also\n\nImagine an array of 32-bit integers (each 4 bytes):\n\nThis array is stored in memory as 40 bytes, one after the other (known as a\ncontiguous block of memory). The strides of an array tell us how many bytes we\nhave to skip in memory to move to the next position along a certain axis. For\nexample, we have to skip 4 bytes (1 value) to move to the next column, but 20\nbytes (5 values) to get to the same position in the next row. As such, the\nstrides for the array `x` will be `(20, 4)`.\n\n"}, {"name": "char.chararray.strip()", "path": "reference/generated/numpy.char.chararray.strip", "type": "numpy.char.chararray.strip", "text": "\nmethod\n\nFor each element in `self`, return a copy with the leading and trailing\ncharacters removed.\n\nSee also\n\n"}, {"name": "char.chararray.swapaxes()", "path": "reference/generated/numpy.char.chararray.swapaxes", "type": "numpy.char.chararray.swapaxes", "text": "\nmethod\n\nReturn a view of the array with `axis1` and `axis2` interchanged.\n\nRefer to `numpy.swapaxes` for full documentation.\n\nSee also\n\nequivalent function\n\n"}, {"name": "char.chararray.swapcase()", "path": "reference/generated/numpy.char.chararray.swapcase", "type": "numpy.char.chararray.swapcase", "text": "\nmethod\n\nFor each element in `self`, return a copy of the string with uppercase\ncharacters converted to lowercase and vice versa.\n\nSee also\n\n"}, {"name": "char.chararray.T", "path": "reference/generated/numpy.char.chararray.t", "type": "String operations", "text": "\nattribute\n\nThe transposed array.\n\nSame as `self.transpose()`.\n\nSee also\n\n"}, {"name": "char.chararray.take()", "path": "reference/generated/numpy.char.chararray.take", "type": "numpy.char.chararray.take", "text": "\nmethod\n\nReturn an array formed from the elements of `a` at the given indices.\n\nRefer to `numpy.take` for full documentation.\n\nSee also\n\nequivalent function\n\n"}, {"name": "char.chararray.title()", "path": "reference/generated/numpy.char.chararray.title", "type": "numpy.char.chararray.title", "text": "\nmethod\n\nFor each element in `self`, return a titlecased version of the string: words\nstart with uppercase characters, all remaining cased characters are lowercase.\n\nSee also\n\n"}, {"name": "char.chararray.tobytes()", "path": "reference/generated/numpy.char.chararray.tobytes", "type": "String operations", "text": "\nmethod\n\nConstruct Python bytes containing the raw data bytes in the array.\n\nConstructs Python bytes showing a copy of the raw contents of data memory. The\nbytes object is produced in C-order by default. This behavior is controlled by\nthe `order` parameter.\n\nNew in version 1.9.0.\n\nControls the memory layout of the bytes object. \u2018C\u2019 means C-order, \u2018F\u2019 means\nF-order, \u2018A\u2019 (short for Any) means \u2018F\u2019 if `a` is Fortran contiguous, \u2018C\u2019\notherwise. Default is \u2018C\u2019.\n\nPython bytes exhibiting a copy of `a`\u2019s raw data.\n\n"}, {"name": "char.chararray.tofile()", "path": "reference/generated/numpy.char.chararray.tofile", "type": "numpy.char.chararray.tofile", "text": "\nmethod\n\nWrite array to a file as text or binary (default).\n\nData is always written in \u2018C\u2019 order, independent of the order of `a`. The data\nproduced by this method can be recovered using the function fromfile().\n\nAn open file object, or a string containing a filename.\n\nChanged in version 1.17.0: `pathlib.Path` objects are now accepted.\n\nSeparator between array items for text output. If \u201c\u201d (empty), a binary file is\nwritten, equivalent to `file.write(a.tobytes())`.\n\nFormat string for text file output. Each entry in the array is formatted to\ntext by first converting it to the closest Python type, and then using\n\u201cformat\u201d % item.\n\nThis is a convenience function for quick storage of array data. Information on\nendianness and precision is lost, so this method is not a good choice for\nfiles intended to archive data or transport data between machines with\ndifferent endianness. Some of these problems can be overcome by outputting the\ndata as text files, at the expense of speed and file size.\n\nWhen fid is a file object, array contents are directly written to the file,\nbypassing the file object\u2019s `write` method. As a result, tofile cannot be used\nwith files objects supporting compression (e.g., GzipFile) or file-like\nobjects that do not support `fileno()` (e.g., BytesIO).\n\n"}, {"name": "char.chararray.tolist()", "path": "reference/generated/numpy.char.chararray.tolist", "type": "numpy.char.chararray.tolist", "text": "\nmethod\n\nReturn the array as an `a.ndim`-levels deep nested list of Python scalars.\n\nReturn a copy of the array data as a (nested) Python list. Data items are\nconverted to the nearest compatible builtin Python type, via the `item`\nfunction.\n\nIf `a.ndim` is 0, then since the depth of the nested list is 0, it will not be\na list at all, but a simple Python scalar.\n\nThe possibly nested list of array elements.\n\nThe array may be recreated via `a = np.array(a.tolist())`, although this may\nsometimes lose precision.\n\nFor a 1D array, `a.tolist()` is almost the same as `list(a)`, except that\n`tolist` changes numpy scalars to Python scalars:\n\nAdditionally, for a 2D array, `tolist` applies recursively:\n\nThe base case for this recursion is a 0D array:\n\n"}, {"name": "char.chararray.tostring()", "path": "reference/generated/numpy.char.chararray.tostring", "type": "numpy.char.chararray.tostring", "text": "\nmethod\n\nA compatibility alias for `tobytes`, with exactly the same behavior.\n\nDespite its name, it returns `bytes` not `str`s.\n\nDeprecated since version 1.19.0.\n\n"}, {"name": "char.chararray.translate()", "path": "reference/generated/numpy.char.chararray.translate", "type": "numpy.char.chararray.translate", "text": "\nmethod\n\nFor each element in `self`, return a copy of the string where all characters\noccurring in the optional argument `deletechars` are removed, and the\nremaining characters have been mapped through the given translation table.\n\nSee also\n\n"}, {"name": "char.chararray.transpose()", "path": "reference/generated/numpy.char.chararray.transpose", "type": "numpy.char.chararray.transpose", "text": "\nmethod\n\nReturns a view of the array with axes transposed.\n\nFor a 1-D array this has no effect, as a transposed vector is simply the same\nvector. To convert a 1-D array into a 2D column vector, an additional\ndimension must be added. `np.atleast2d(a).T` achieves this, as does `a[:,\nnp.newaxis]`. For a 2-D array, this is a standard matrix transpose. For an n-D\narray, if axes are given, their order indicates how the axes are permuted (see\nExamples). If axes are not provided and `a.shape = (i[0], i[1], ... i[n-2],\ni[n-1])`, then `a.transpose().shape = (i[n-1], i[n-2], ... i[1], i[0])`.\n\nView of `a`, with axes suitably permuted.\n\nSee also\n\nEquivalent function\n\nArray property returning the array transposed.\n\nGive a new shape to an array without changing its data.\n\n"}, {"name": "char.chararray.upper()", "path": "reference/generated/numpy.char.chararray.upper", "type": "numpy.char.chararray.upper", "text": "\nmethod\n\nReturn an array with the elements of `self` converted to uppercase.\n\nSee also\n\n"}, {"name": "char.chararray.view()", "path": "reference/generated/numpy.char.chararray.view", "type": "numpy.char.chararray.view", "text": "\nmethod\n\nNew view of array with the same data.\n\nNote\n\nPassing None for `dtype` is different from omitting the parameter, since the\nformer invokes `dtype(None)` which is an alias for `dtype('float_')`.\n\nData-type descriptor of the returned view, e.g., float32 or int16. Omitting it\nresults in the view having the same data-type as `a`. This argument can also\nbe specified as an ndarray sub-class, which then specifies the type of the\nreturned object (this is equivalent to setting the `type` parameter).\n\nType of the returned view, e.g., ndarray or matrix. Again, omission of the\nparameter results in type preservation.\n\n`a.view()` is used two different ways:\n\n`a.view(some_dtype)` or `a.view(dtype=some_dtype)` constructs a view of the\narray\u2019s memory with a different data-type. This can cause a reinterpretation\nof the bytes of memory.\n\n`a.view(ndarray_subclass)` or `a.view(type=ndarray_subclass)` just returns an\ninstance of `ndarray_subclass` that looks at the same array (same shape,\ndtype, etc.) This does not cause a reinterpretation of the memory.\n\nFor `a.view(some_dtype)`, if `some_dtype` has a different number of bytes per\nentry than the previous dtype (for example, converting a regular array to a\nstructured array), then the behavior of the view cannot be predicted just from\nthe superficial appearance of `a` (shown by `print(a)`). It also depends on\nexactly how `a` is stored in memory. Therefore if `a` is C-ordered versus\nfortran-ordered, versus defined as a slice or transpose, etc., the view may\ngive different results.\n\nViewing array data using a different type and dtype:\n\nCreating a view on a structured array so it can be used in calculations\n\nMaking changes to the view changes the underlying array\n\nUsing a view to convert an array to a recarray:\n\nViews share data:\n\nViews that change the dtype size (bytes per entry) should normally be avoided\non arrays defined by slices, transposes, fortran-ordering, etc.:\n\n"}, {"name": "char.chararray.zfill()", "path": "reference/generated/numpy.char.chararray.zfill", "type": "numpy.char.chararray.zfill", "text": "\nmethod\n\nReturn the numeric string left-filled with zeros in a string of length\n`width`.\n\nSee also\n\n"}, {"name": "char.compare_chararrays()", "path": "reference/generated/numpy.char.compare_chararrays", "type": "numpy.char.compare_chararrays", "text": "\nPerforms element-wise comparison of two string arrays using the comparison\noperator specified by `cmp_op`.\n\nArrays to be compared.\n\nType of comparison.\n\nIf True, the spaces at the end of Strings are removed before the comparison.\n\nThe output array of type Boolean with the same shape as a and b.\n\nIf `cmp_op` is not valid.\n\nIf at least one of `a` or `b` is a non-string array\n\n"}, {"name": "char.count()", "path": "reference/generated/numpy.char.count", "type": "numpy.char.count", "text": "\nReturns an array with the number of non-overlapping occurrences of substring\n`sub` in the range [`start`, `end`].\n\nCalls `str.count` element-wise.\n\nThe substring to search for.\n\nOptional arguments `start` and `end` are interpreted as slice notation to\nspecify the range in which to count.\n\nOutput array of ints.\n\nSee also\n\n"}, {"name": "char.decode()", "path": "reference/generated/numpy.char.decode", "type": "numpy.char.decode", "text": "\nCalls `str.decode` element-wise.\n\nThe set of available codecs comes from the Python standard library, and may be\nextended at runtime. For more information, see the `codecs` module.\n\nThe name of an encoding\n\nSpecifies how to handle encoding errors\n\nSee also\n\nThe type of the result will depend on the encoding specified.\n\n"}, {"name": "char.encode()", "path": "reference/generated/numpy.char.encode", "type": "numpy.char.encode", "text": "\nCalls `str.encode` element-wise.\n\nThe set of available codecs comes from the Python standard library, and may be\nextended at runtime. For more information, see the codecs module.\n\nThe name of an encoding\n\nSpecifies how to handle encoding errors\n\nSee also\n\nThe type of the result will depend on the encoding specified.\n\n"}, {"name": "char.endswith()", "path": "reference/generated/numpy.char.endswith", "type": "numpy.char.endswith", "text": "\nReturns a boolean array which is `True` where the string element in `a` ends\nwith `suffix`, otherwise `False`.\n\nCalls `str.endswith` element-wise.\n\nWith optional `start`, test beginning at that position. With optional `end`,\nstop comparing at that position.\n\nOutputs an array of bools.\n\nSee also\n\n"}, {"name": "char.equal()", "path": "reference/generated/numpy.char.equal", "type": "numpy.char.equal", "text": "\nReturn (x1 == x2) element-wise.\n\nUnlike `numpy.equal`, this comparison is performed by first stripping\nwhitespace characters from the end of the string. This behavior is provided\nfor backward-compatibility with numarray.\n\nInput arrays of the same shape.\n\nOutput array of bools.\n\nSee also\n\n"}, {"name": "char.expandtabs()", "path": "reference/generated/numpy.char.expandtabs", "type": "numpy.char.expandtabs", "text": "\nReturn a copy of each string element where all tab characters are replaced by\none or more spaces.\n\nCalls `str.expandtabs` element-wise.\n\nReturn a copy of each string element where all tab characters are replaced by\none or more spaces, depending on the current column and the given `tabsize`.\nThe column number is reset to zero after each newline occurring in the string.\nThis doesn\u2019t understand other non-printing characters or escape sequences.\n\nInput array\n\nReplace tabs with `tabsize` number of spaces. If not given defaults to 8\nspaces.\n\nOutput array of str or unicode, depending on input type\n\nSee also\n\n"}, {"name": "char.find()", "path": "reference/generated/numpy.char.find", "type": "numpy.char.find", "text": "\nFor each element, return the lowest index in the string where substring `sub`\nis found.\n\nCalls `str.find` element-wise.\n\nFor each element, return the lowest index in the string where substring `sub`\nis found, such that `sub` is contained in the range [`start`, `end`].\n\nOptional arguments `start` and `end` are interpreted as in slice notation.\n\nOutput array of ints. Returns -1 if `sub` is not found.\n\nSee also\n\n"}, {"name": "char.greater()", "path": "reference/generated/numpy.char.greater", "type": "numpy.char.greater", "text": "\nReturn (x1 > x2) element-wise.\n\nUnlike `numpy.greater`, this comparison is performed by first stripping\nwhitespace characters from the end of the string. This behavior is provided\nfor backward-compatibility with numarray.\n\nInput arrays of the same shape.\n\nOutput array of bools.\n\nSee also\n\n"}, {"name": "char.greater_equal()", "path": "reference/generated/numpy.char.greater_equal", "type": "numpy.char.greater_equal", "text": "\nReturn (x1 >= x2) element-wise.\n\nUnlike `numpy.greater_equal`, this comparison is performed by first stripping\nwhitespace characters from the end of the string. This behavior is provided\nfor backward-compatibility with numarray.\n\nInput arrays of the same shape.\n\nOutput array of bools.\n\nSee also\n\n"}, {"name": "char.index()", "path": "reference/generated/numpy.char.index", "type": "numpy.char.index", "text": "\nLike `find`, but raises `ValueError` when the substring is not found.\n\nCalls `str.index` element-wise.\n\nOutput array of ints. Returns -1 if `sub` is not found.\n\nSee also\n\n"}, {"name": "char.isalnum()", "path": "reference/generated/numpy.char.isalnum", "type": "numpy.char.isalnum", "text": "\nReturns true for each element if all characters in the string are alphanumeric\nand there is at least one character, false otherwise.\n\nCalls `str.isalnum` element-wise.\n\nFor 8-bit strings, this method is locale-dependent.\n\nOutput array of str or unicode, depending on input type\n\nSee also\n\n"}, {"name": "char.isalpha()", "path": "reference/generated/numpy.char.isalpha", "type": "numpy.char.isalpha", "text": "\nReturns true for each element if all characters in the string are alphabetic\nand there is at least one character, false otherwise.\n\nCalls `str.isalpha` element-wise.\n\nFor 8-bit strings, this method is locale-dependent.\n\nOutput array of bools\n\nSee also\n\n"}, {"name": "char.isdecimal()", "path": "reference/generated/numpy.char.isdecimal", "type": "numpy.char.isdecimal", "text": "\nFor each element, return True if there are only decimal characters in the\nelement.\n\nCalls `unicode.isdecimal` element-wise.\n\nDecimal characters include digit characters, and all characters that can be\nused to form decimal-radix numbers, e.g. `U+0660, ARABIC-INDIC DIGIT ZERO`.\n\nInput array.\n\nArray of booleans identical in shape to `a`.\n\nSee also\n\n"}, {"name": "char.isdigit()", "path": "reference/generated/numpy.char.isdigit", "type": "numpy.char.isdigit", "text": "\nReturns true for each element if all characters in the string are digits and\nthere is at least one character, false otherwise.\n\nCalls `str.isdigit` element-wise.\n\nFor 8-bit strings, this method is locale-dependent.\n\nOutput array of bools\n\nSee also\n\n"}, {"name": "char.islower()", "path": "reference/generated/numpy.char.islower", "type": "numpy.char.islower", "text": "\nReturns true for each element if all cased characters in the string are\nlowercase and there is at least one cased character, false otherwise.\n\nCalls `str.islower` element-wise.\n\nFor 8-bit strings, this method is locale-dependent.\n\nOutput array of bools\n\nSee also\n\n"}, {"name": "char.isnumeric()", "path": "reference/generated/numpy.char.isnumeric", "type": "numpy.char.isnumeric", "text": "\nFor each element, return True if there are only numeric characters in the\nelement.\n\nCalls `unicode.isnumeric` element-wise.\n\nNumeric characters include digit characters, and all characters that have the\nUnicode numeric value property, e.g. `U+2155, VULGAR FRACTION ONE FIFTH`.\n\nInput array.\n\nArray of booleans of same shape as `a`.\n\nSee also\n\n"}, {"name": "char.isspace()", "path": "reference/generated/numpy.char.isspace", "type": "numpy.char.isspace", "text": "\nReturns true for each element if there are only whitespace characters in the\nstring and there is at least one character, false otherwise.\n\nCalls `str.isspace` element-wise.\n\nFor 8-bit strings, this method is locale-dependent.\n\nOutput array of bools\n\nSee also\n\n"}, {"name": "char.istitle()", "path": "reference/generated/numpy.char.istitle", "type": "numpy.char.istitle", "text": "\nReturns true for each element if the element is a titlecased string and there\nis at least one character, false otherwise.\n\nCall `str.istitle` element-wise.\n\nFor 8-bit strings, this method is locale-dependent.\n\nOutput array of bools\n\nSee also\n\n"}, {"name": "char.isupper()", "path": "reference/generated/numpy.char.isupper", "type": "numpy.char.isupper", "text": "\nReturns true for each element if all cased characters in the string are\nuppercase and there is at least one character, false otherwise.\n\nCall `str.isupper` element-wise.\n\nFor 8-bit strings, this method is locale-dependent.\n\nOutput array of bools\n\nSee also\n\n"}, {"name": "char.join()", "path": "reference/generated/numpy.char.join", "type": "numpy.char.join", "text": "\nReturn a string which is the concatenation of the strings in the sequence\n`seq`.\n\nCalls `str.join` element-wise.\n\nOutput array of str or unicode, depending on input types\n\nSee also\n\n"}, {"name": "char.less()", "path": "reference/generated/numpy.char.less", "type": "numpy.char.less", "text": "\nReturn (x1 < x2) element-wise.\n\nUnlike `numpy.greater`, this comparison is performed by first stripping\nwhitespace characters from the end of the string. This behavior is provided\nfor backward-compatibility with numarray.\n\nInput arrays of the same shape.\n\nOutput array of bools.\n\nSee also\n\n"}, {"name": "char.less_equal()", "path": "reference/generated/numpy.char.less_equal", "type": "numpy.char.less_equal", "text": "\nReturn (x1 <= x2) element-wise.\n\nUnlike `numpy.less_equal`, this comparison is performed by first stripping\nwhitespace characters from the end of the string. This behavior is provided\nfor backward-compatibility with numarray.\n\nInput arrays of the same shape.\n\nOutput array of bools.\n\nSee also\n\n"}, {"name": "char.ljust()", "path": "reference/generated/numpy.char.ljust", "type": "numpy.char.ljust", "text": "\nReturn an array with the elements of `a` left-justified in a string of length\n`width`.\n\nCalls `str.ljust` element-wise.\n\nThe length of the resulting strings\n\nThe character to use for padding\n\nOutput array of str or unicode, depending on input type\n\nSee also\n\n"}, {"name": "char.lower()", "path": "reference/generated/numpy.char.lower", "type": "numpy.char.lower", "text": "\nReturn an array with the elements converted to lowercase.\n\nCall `str.lower` element-wise.\n\nFor 8-bit strings, this method is locale-dependent.\n\nInput array.\n\nOutput array of str or unicode, depending on input type\n\nSee also\n\n"}, {"name": "char.lstrip()", "path": "reference/generated/numpy.char.lstrip", "type": "numpy.char.lstrip", "text": "\nFor each element in `a`, return a copy with the leading characters removed.\n\nCalls `str.lstrip` element-wise.\n\nInput array.\n\nThe `chars` argument is a string specifying the set of characters to be\nremoved. If omitted or None, the `chars` argument defaults to removing\nwhitespace. The `chars` argument is not a prefix; rather, all combinations of\nits values are stripped.\n\nOutput array of str or unicode, depending on input type\n\nSee also\n\nThe \u2018a\u2019 variable is unstripped from c[1] because whitespace leading.\n\n"}, {"name": "char.mod()", "path": "reference/generated/numpy.char.mod", "type": "numpy.char.mod", "text": "\nReturn (a % i), that is pre-Python 2.6 string formatting (interpolation),\nelement-wise for a pair of array_likes of str or unicode.\n\nThese values will be element-wise interpolated into the string.\n\nOutput array of str or unicode, depending on input types\n\nSee also\n\n"}, {"name": "char.multiply()", "path": "reference/generated/numpy.char.multiply", "type": "numpy.char.multiply", "text": "\nReturn (a * i), that is string multiple concatenation, element-wise.\n\nValues in `i` of less than 0 are treated as 0 (which yields an empty string).\n\nOutput array of str or unicode, depending on input types\n\n"}, {"name": "char.not_equal()", "path": "reference/generated/numpy.char.not_equal", "type": "numpy.char.not_equal", "text": "\nReturn (x1 != x2) element-wise.\n\nUnlike `numpy.not_equal`, this comparison is performed by first stripping\nwhitespace characters from the end of the string. This behavior is provided\nfor backward-compatibility with numarray.\n\nInput arrays of the same shape.\n\nOutput array of bools.\n\nSee also\n\n"}, {"name": "char.partition()", "path": "reference/generated/numpy.char.partition", "type": "numpy.char.partition", "text": "\nPartition each element in `a` around `sep`.\n\nCalls `str.partition` element-wise.\n\nFor each element in `a`, split the element as the first occurrence of `sep`,\nand return 3 strings containing the part before the separator, the separator\nitself, and the part after the separator. If the separator is not found,\nreturn 3 strings containing the string itself, followed by two empty strings.\n\nInput array\n\nSeparator to split each string element in `a`.\n\nOutput array of str or unicode, depending on input type. The output array will\nhave an extra dimension with 3 elements per input element.\n\nSee also\n\n"}, {"name": "char.replace()", "path": "reference/generated/numpy.char.replace", "type": "numpy.char.replace", "text": "\nFor each element in `a`, return a copy of the string with all occurrences of\nsubstring `old` replaced by `new`.\n\nCalls `str.replace` element-wise.\n\nIf the optional argument `count` is given, only the first `count` occurrences\nare replaced.\n\nOutput array of str or unicode, depending on input type\n\nSee also\n\n"}, {"name": "char.rfind()", "path": "reference/generated/numpy.char.rfind", "type": "numpy.char.rfind", "text": "\nFor each element in `a`, return the highest index in the string where\nsubstring `sub` is found, such that `sub` is contained within [`start`,\n`end`].\n\nCalls `str.rfind` element-wise.\n\nOptional arguments `start` and `end` are interpreted as in slice notation.\n\nOutput array of ints. Return -1 on failure.\n\nSee also\n\n"}, {"name": "char.rindex()", "path": "reference/generated/numpy.char.rindex", "type": "numpy.char.rindex", "text": "\nLike `rfind`, but raises `ValueError` when the substring `sub` is not found.\n\nCalls `str.rindex` element-wise.\n\nOutput array of ints.\n\nSee also\n\n"}, {"name": "char.rjust()", "path": "reference/generated/numpy.char.rjust", "type": "numpy.char.rjust", "text": "\nReturn an array with the elements of `a` right-justified in a string of length\n`width`.\n\nCalls `str.rjust` element-wise.\n\nThe length of the resulting strings\n\nThe character to use for padding\n\nOutput array of str or unicode, depending on input type\n\nSee also\n\n"}, {"name": "char.rpartition()", "path": "reference/generated/numpy.char.rpartition", "type": "numpy.char.rpartition", "text": "\nPartition (split) each element around the right-most separator.\n\nCalls `str.rpartition` element-wise.\n\nFor each element in `a`, split the element as the last occurrence of `sep`,\nand return 3 strings containing the part before the separator, the separator\nitself, and the part after the separator. If the separator is not found,\nreturn 3 strings containing the string itself, followed by two empty strings.\n\nInput array\n\nRight-most separator to split each element in array.\n\nOutput array of string or unicode, depending on input type. The output array\nwill have an extra dimension with 3 elements per input element.\n\nSee also\n\n"}, {"name": "char.rsplit()", "path": "reference/generated/numpy.char.rsplit", "type": "numpy.char.rsplit", "text": "\nFor each element in `a`, return a list of the words in the string, using `sep`\nas the delimiter string.\n\nCalls `str.rsplit` element-wise.\n\nExcept for splitting from the right, `rsplit` behaves like `split`.\n\nIf `sep` is not specified or None, any whitespace string is a separator.\n\nIf `maxsplit` is given, at most `maxsplit` splits are done, the rightmost\nones.\n\nArray of list objects\n\nSee also\n\n"}, {"name": "char.rstrip()", "path": "reference/generated/numpy.char.rstrip", "type": "numpy.char.rstrip", "text": "\nFor each element in `a`, return a copy with the trailing characters removed.\n\nCalls `str.rstrip` element-wise.\n\nThe `chars` argument is a string specifying the set of characters to be\nremoved. If omitted or None, the `chars` argument defaults to removing\nwhitespace. The `chars` argument is not a suffix; rather, all combinations of\nits values are stripped.\n\nOutput array of str or unicode, depending on input type\n\nSee also\n\n"}, {"name": "char.split()", "path": "reference/generated/numpy.char.split", "type": "numpy.char.split", "text": "\nFor each element in `a`, return a list of the words in the string, using `sep`\nas the delimiter string.\n\nCalls `str.split` element-wise.\n\nIf `sep` is not specified or None, any whitespace string is a separator.\n\nIf `maxsplit` is given, at most `maxsplit` splits are done.\n\nArray of list objects\n\nSee also\n\n"}, {"name": "char.splitlines()", "path": "reference/generated/numpy.char.splitlines", "type": "numpy.char.splitlines", "text": "\nFor each element in `a`, return a list of the lines in the element, breaking\nat line boundaries.\n\nCalls `str.splitlines` element-wise.\n\nLine breaks are not included in the resulting list unless keepends is given\nand true.\n\nArray of list objects\n\nSee also\n\n"}, {"name": "char.startswith()", "path": "reference/generated/numpy.char.startswith", "type": "numpy.char.startswith", "text": "\nReturns a boolean array which is `True` where the string element in `a` starts\nwith `prefix`, otherwise `False`.\n\nCalls `str.startswith` element-wise.\n\nWith optional `start`, test beginning at that position. With optional `end`,\nstop comparing at that position.\n\nArray of booleans\n\nSee also\n\n"}, {"name": "char.str_len()", "path": "reference/generated/numpy.char.str_len", "type": "numpy.char.str_len", "text": "\nReturn len(a) element-wise.\n\nOutput array of integers\n\nSee also\n\n"}, {"name": "char.strip()", "path": "reference/generated/numpy.char.strip", "type": "numpy.char.strip", "text": "\nFor each element in `a`, return a copy with the leading and trailing\ncharacters removed.\n\nCalls `str.strip` element-wise.\n\nThe `chars` argument is a string specifying the set of characters to be\nremoved. If omitted or None, the `chars` argument defaults to removing\nwhitespace. The `chars` argument is not a prefix or suffix; rather, all\ncombinations of its values are stripped.\n\nOutput array of str or unicode, depending on input type\n\nSee also\n\n"}, {"name": "char.swapcase()", "path": "reference/generated/numpy.char.swapcase", "type": "numpy.char.swapcase", "text": "\nReturn element-wise a copy of the string with uppercase characters converted\nto lowercase and vice versa.\n\nCalls `str.swapcase` element-wise.\n\nFor 8-bit strings, this method is locale-dependent.\n\nInput array.\n\nOutput array of str or unicode, depending on input type\n\nSee also\n\n"}, {"name": "char.title()", "path": "reference/generated/numpy.char.title", "type": "numpy.char.title", "text": "\nReturn element-wise title cased version of string or unicode.\n\nTitle case words start with uppercase characters, all remaining cased\ncharacters are lowercase.\n\nCalls `str.title` element-wise.\n\nFor 8-bit strings, this method is locale-dependent.\n\nInput array.\n\nOutput array of str or unicode, depending on input type\n\nSee also\n\n"}, {"name": "char.translate()", "path": "reference/generated/numpy.char.translate", "type": "numpy.char.translate", "text": "\nFor each element in `a`, return a copy of the string where all characters\noccurring in the optional argument `deletechars` are removed, and the\nremaining characters have been mapped through the given translation table.\n\nCalls `str.translate` element-wise.\n\nOutput array of str or unicode, depending on input type\n\nSee also\n\n"}, {"name": "char.upper()", "path": "reference/generated/numpy.char.upper", "type": "numpy.char.upper", "text": "\nReturn an array with the elements converted to uppercase.\n\nCalls `str.upper` element-wise.\n\nFor 8-bit strings, this method is locale-dependent.\n\nInput array.\n\nOutput array of str or unicode, depending on input type\n\nSee also\n\n"}, {"name": "char.zfill()", "path": "reference/generated/numpy.char.zfill", "type": "numpy.char.zfill", "text": "\nReturn the numeric string left-filled with zeros\n\nCalls `str.zfill` element-wise.\n\nInput array.\n\nWidth of string to left-fill elements in `a`.\n\nOutput array of str or unicode, depending on input type\n\nSee also\n\n"}, {"name": "chararray.argsort()", "path": "reference/generated/numpy.chararray.argsort", "type": "numpy.chararray.argsort", "text": "\nmethod\n\nReturns the indices that would sort this array.\n\nRefer to `numpy.argsort` for full documentation.\n\nSee also\n\nequivalent function\n\n"}, {"name": "chararray.astype()", "path": "reference/generated/numpy.chararray.astype", "type": "numpy.chararray.astype", "text": "\nmethod\n\nCopy of the array, cast to a specified type.\n\nTypecode or data-type to which the array is cast.\n\nControls the memory layout order of the result. \u2018C\u2019 means C order, \u2018F\u2019 means\nFortran order, \u2018A\u2019 means \u2018F\u2019 order if all the arrays are Fortran contiguous,\n\u2018C\u2019 order otherwise, and \u2018K\u2019 means as close to the order the array elements\nappear in memory as possible. Default is \u2018K\u2019.\n\nControls what kind of data casting may occur. Defaults to \u2018unsafe\u2019 for\nbackwards compatibility.\n\nIf True, then sub-classes will be passed-through (default), otherwise the\nreturned array will be forced to be a base-class array.\n\nBy default, astype always returns a newly allocated array. If this is set to\nfalse, and the `dtype`, `order`, and `subok` requirements are satisfied, the\ninput array is returned instead of a copy.\n\nUnless `copy` is False and the other conditions for returning the input array\nare satisfied (see description for `copy` input parameter), `arr_t` is a new\narray of the same shape as the input array, with dtype, order given by\n`dtype`, `order`.\n\nWhen casting from complex to float or int. To avoid this, one should use\n`a.real.astype(t)`.\n\nChanged in version 1.17.0: Casting between a simple data type and a structured\none is possible only for \u201cunsafe\u201d casting. Casting to multiple fields is\nallowed, but casting from multiple fields is not.\n\nChanged in version 1.9.0: Casting from numeric to string types in \u2018safe\u2019\ncasting mode requires that the string dtype length is long enough to store the\nmax integer/float value converted.\n\n"}, {"name": "chararray.base", "path": "reference/generated/numpy.chararray.base", "type": "String operations", "text": "\nattribute\n\nBase object if memory is from some other object.\n\nThe base of an array that owns its memory is None:\n\nSlicing creates a view, whose memory is shared with x:\n\n"}, {"name": "chararray.copy()", "path": "reference/generated/numpy.chararray.copy", "type": "numpy.chararray.copy", "text": "\nmethod\n\nReturn a copy of the array.\n\nControls the memory layout of the copy. \u2018C\u2019 means C-order, \u2018F\u2019 means F-order,\n\u2018A\u2019 means \u2018F\u2019 if `a` is Fortran contiguous, \u2018C\u2019 otherwise. \u2018K\u2019 means match the\nlayout of `a` as closely as possible. (Note that this function and\n`numpy.copy` are very similar but have different default values for their\norder= arguments, and this function always passes sub-classes through.)\n\nSee also\n\nSimilar function with different default behavior\n\nThis function is the preferred method for creating an array copy. The function\n`numpy.copy` is similar, but it defaults to using order \u2018K\u2019, and will not pass\nsub-classes through by default.\n\n"}, {"name": "chararray.count()", "path": "reference/generated/numpy.chararray.count", "type": "numpy.chararray.count", "text": "\nmethod\n\nReturns an array with the number of non-overlapping occurrences of substring\n`sub` in the range [`start`, `end`].\n\nSee also\n\n"}, {"name": "chararray.ctypes", "path": "reference/generated/numpy.chararray.ctypes", "type": "String operations", "text": "\nattribute\n\nAn object to simplify the interaction of the array with the ctypes module.\n\nThis attribute creates an object that makes it easier to use arrays when\ncalling shared libraries with the ctypes module. The returned object has,\namong others, data, shape, and strides attributes (see Notes below) which\nthemselves return ctypes objects that can be used as arguments to a shared\nlibrary.\n\nPossessing attributes data, shape, strides, etc.\n\nSee also\n\nBelow are the public attributes of this object which were documented in \u201cGuide\nto NumPy\u201d (we have omitted undocumented public attributes, as well as\ndocumented private attributes):\n\nA pointer to the memory area of the array as a Python integer. This memory\narea may contain data that is not aligned, or not in correct byte-order. The\nmemory area may not even be writeable. The array flags and data-type of this\narray should be respected when passing this attribute to arbitrary C-code to\navoid trouble that can include Python crashing. User Beware! The value of this\nattribute is exactly the same as `self._array_interface_['data'][0]`.\n\nNote that unlike `data_as`, a reference will not be kept to the array: code\nlike `ctypes.c_void_p((a + b).ctypes.data)` will result in a pointer to a\ndeallocated array, and should be spelt `(a +\nb).ctypes.data_as(ctypes.c_void_p)`\n\n(c_intp*self.ndim): A ctypes array of length self.ndim where the basetype is\nthe C-integer corresponding to `dtype('p')` on this platform (see `c_intp`).\nThis base-type could be `ctypes.c_int`, `ctypes.c_long`, or\n`ctypes.c_longlong` depending on the platform. The ctypes array contains the\nshape of the underlying array.\n\n(c_intp*self.ndim): A ctypes array of length self.ndim where the basetype is\nthe same as for the shape attribute. This ctypes array contains the strides\ninformation from the underlying array. This strides information is important\nfor showing how many bytes must be jumped to get to the next element in the\narray.\n\nReturn the data pointer cast to a particular c-types object. For example,\ncalling `self._as_parameter_` is equivalent to\n`self.data_as(ctypes.c_void_p)`. Perhaps you want to use the data as a pointer\nto a ctypes array of floating-point data:\n`self.data_as(ctypes.POINTER(ctypes.c_double))`.\n\nThe returned pointer will keep a reference to the array.\n\nReturn the shape tuple as an array of some other c-types type. For example:\n`self.shape_as(ctypes.c_short)`.\n\nReturn the strides tuple as an array of some other c-types type. For example:\n`self.strides_as(ctypes.c_longlong)`.\n\nIf the ctypes module is not available, then the ctypes attribute of array\nobjects still returns something useful, but ctypes objects are not returned\nand errors may be raised instead. In particular, the object will still have\nthe `as_parameter` attribute which will return an integer equal to the data\nattribute.\n\n"}, {"name": "chararray.data", "path": "reference/generated/numpy.chararray.data", "type": "String operations", "text": "\nattribute\n\nPython buffer object pointing to the start of the array\u2019s data.\n\n"}, {"name": "chararray.decode()", "path": "reference/generated/numpy.chararray.decode", "type": "numpy.chararray.decode", "text": "\nmethod\n\nCalls `str.decode` element-wise.\n\nSee also\n\n"}, {"name": "chararray.dump()", "path": "reference/generated/numpy.chararray.dump", "type": "numpy.chararray.dump", "text": "\nmethod\n\nDump a pickle of the array to the specified file. The array can be read back\nwith pickle.load or numpy.load.\n\nA string naming the dump file.\n\nChanged in version 1.17.0: `pathlib.Path` objects are now accepted.\n\n"}, {"name": "chararray.dumps()", "path": "reference/generated/numpy.chararray.dumps", "type": "numpy.chararray.dumps", "text": "\nmethod\n\nReturns the pickle of the array as a string. pickle.loads will convert the\nstring back to an array.\n\n"}, {"name": "chararray.encode()", "path": "reference/generated/numpy.chararray.encode", "type": "numpy.chararray.encode", "text": "\nmethod\n\nCalls `str.encode` element-wise.\n\nSee also\n\n"}, {"name": "chararray.endswith()", "path": "reference/generated/numpy.chararray.endswith", "type": "numpy.chararray.endswith", "text": "\nmethod\n\nReturns a boolean array which is `True` where the string element in `self`\nends with `suffix`, otherwise `False`.\n\nSee also\n\n"}, {"name": "chararray.expandtabs()", "path": "reference/generated/numpy.chararray.expandtabs", "type": "numpy.chararray.expandtabs", "text": "\nmethod\n\nReturn a copy of each string element where all tab characters are replaced by\none or more spaces.\n\nSee also\n\n"}, {"name": "chararray.fill()", "path": "reference/generated/numpy.chararray.fill", "type": "numpy.chararray.fill", "text": "\nmethod\n\nFill the array with a scalar value.\n\nAll elements of `a` will be assigned this value.\n\n"}, {"name": "chararray.find()", "path": "reference/generated/numpy.chararray.find", "type": "numpy.chararray.find", "text": "\nmethod\n\nFor each element, return the lowest index in the string where substring `sub`\nis found.\n\nSee also\n\n"}, {"name": "chararray.flags", "path": "reference/generated/numpy.chararray.flags", "type": "String operations", "text": "\nattribute\n\nInformation about the memory layout of the array.\n\nThe `flags` object can be accessed dictionary-like (as in\n`a.flags['WRITEABLE']`), or by using lowercased attribute names (as in\n`a.flags.writeable`). Short flag names are only supported in dictionary\naccess.\n\nOnly the WRITEBACKIFCOPY, UPDATEIFCOPY, WRITEABLE, and ALIGNED flags can be\nchanged by the user, via direct assignment to the attribute or dictionary\nentry, or by calling `ndarray.setflags`.\n\nThe array flags cannot be set arbitrarily:\n\nArrays can be both C-style and Fortran-style contiguous simultaneously. This\nis clear for 1-dimensional arrays, but can also be true for higher dimensional\narrays.\n\nEven for contiguous arrays a stride for a given dimension `arr.strides[dim]`\nmay be arbitrary if `arr.shape[dim] == 1` or the array has no elements. It\ndoes not generally hold that `self.strides[-1] == self.itemsize` for C-style\ncontiguous arrays or `self.strides[0] == self.itemsize` for Fortran-style\ncontiguous arrays is true.\n\nThe data is in a single, C-style contiguous segment.\n\nThe data is in a single, Fortran-style contiguous segment.\n\nThe array owns the memory it uses or borrows it from another object.\n\nThe data area can be written to. Setting this to False locks the data, making\nit read-only. A view (slice, etc.) inherits WRITEABLE from its base array at\ncreation time, but a view of a writeable array may be subsequently locked\nwhile the base array remains writeable. (The opposite is not true, in that a\nview of a locked array may not be made writeable. However, currently, locking\na base object does not lock any views that already reference it, so under that\ncircumstance it is possible to alter the contents of a locked array via a\npreviously created writeable view onto it.) Attempting to change a non-\nwriteable array raises a RuntimeError exception.\n\nThe data and all elements are aligned appropriately for the hardware.\n\nThis array is a copy of some other array. The C-API function\nPyArray_ResolveWritebackIfCopy must be called before deallocating to the base\narray will be updated with the contents of this array.\n\n(Deprecated, use WRITEBACKIFCOPY) This array is a copy of some other array.\nWhen this array is deallocated, the base array will be updated with the\ncontents of this array.\n\nF_CONTIGUOUS and not C_CONTIGUOUS.\n\nF_CONTIGUOUS or C_CONTIGUOUS (one-segment test).\n\nALIGNED and WRITEABLE.\n\nBEHAVED and C_CONTIGUOUS.\n\nBEHAVED and F_CONTIGUOUS and not C_CONTIGUOUS.\n\n"}, {"name": "chararray.flat", "path": "reference/generated/numpy.chararray.flat", "type": "String operations", "text": "\nattribute\n\nA 1-D iterator over the array.\n\nThis is a `numpy.flatiter` instance, which acts similarly to, but is not a\nsubclass of, Python\u2019s built-in iterator object.\n\nSee also\n\nReturn a copy of the array collapsed into one dimension.\n\nAn assignment example:\n\n"}, {"name": "chararray.flatten()", "path": "reference/generated/numpy.chararray.flatten", "type": "numpy.chararray.flatten", "text": "\nmethod\n\nReturn a copy of the array collapsed into one dimension.\n\n\u2018C\u2019 means to flatten in row-major (C-style) order. \u2018F\u2019 means to flatten in\ncolumn-major (Fortran- style) order. \u2018A\u2019 means to flatten in column-major\norder if `a` is Fortran contiguous in memory, row-major order otherwise. \u2018K\u2019\nmeans to flatten `a` in the order the elements occur in memory. The default is\n\u2018C\u2019.\n\nA copy of the input array, flattened to one dimension.\n\nSee also\n\nReturn a flattened array.\n\nA 1-D flat iterator over the array.\n\n"}, {"name": "chararray.getfield()", "path": "reference/generated/numpy.chararray.getfield", "type": "numpy.chararray.getfield", "text": "\nmethod\n\nReturns a field of the given array as a certain type.\n\nA field is a view of the array data with a given data-type. The values in the\nview are determined by the given type and the offset into the current array in\nbytes. The offset needs to be such that the view dtype fits in the array\ndtype; for example an array of dtype complex128 has 16-byte elements. If\ntaking a view with a 32-bit integer (4 bytes), the offset needs to be between\n0 and 12 bytes.\n\nThe data type of the view. The dtype size of the view can not be larger than\nthat of the array itself.\n\nNumber of bytes to skip before beginning the element view.\n\nBy choosing an offset of 8 bytes we can select the complex part of the array\nfor our view:\n\n"}, {"name": "chararray.index()", "path": "reference/generated/numpy.chararray.index", "type": "numpy.chararray.index", "text": "\nmethod\n\nLike `find`, but raises `ValueError` when the substring is not found.\n\nSee also\n\n"}, {"name": "chararray.isalnum()", "path": "reference/generated/numpy.chararray.isalnum", "type": "numpy.chararray.isalnum", "text": "\nmethod\n\nReturns true for each element if all characters in the string are alphanumeric\nand there is at least one character, false otherwise.\n\nSee also\n\n"}, {"name": "chararray.isalpha()", "path": "reference/generated/numpy.chararray.isalpha", "type": "numpy.chararray.isalpha", "text": "\nmethod\n\nReturns true for each element if all characters in the string are alphabetic\nand there is at least one character, false otherwise.\n\nSee also\n\n"}, {"name": "chararray.isdecimal()", "path": "reference/generated/numpy.chararray.isdecimal", "type": "numpy.chararray.isdecimal", "text": "\nmethod\n\nFor each element in `self`, return True if there are only decimal characters\nin the element.\n\nSee also\n\n"}, {"name": "chararray.isdigit()", "path": "reference/generated/numpy.chararray.isdigit", "type": "numpy.chararray.isdigit", "text": "\nmethod\n\nReturns true for each element if all characters in the string are digits and\nthere is at least one character, false otherwise.\n\nSee also\n\n"}, {"name": "chararray.islower()", "path": "reference/generated/numpy.chararray.islower", "type": "numpy.chararray.islower", "text": "\nmethod\n\nReturns true for each element if all cased characters in the string are\nlowercase and there is at least one cased character, false otherwise.\n\nSee also\n\n"}, {"name": "chararray.isnumeric()", "path": "reference/generated/numpy.chararray.isnumeric", "type": "numpy.chararray.isnumeric", "text": "\nmethod\n\nFor each element in `self`, return True if there are only numeric characters\nin the element.\n\nSee also\n\n"}, {"name": "chararray.isspace()", "path": "reference/generated/numpy.chararray.isspace", "type": "numpy.chararray.isspace", "text": "\nmethod\n\nReturns true for each element if there are only whitespace characters in the\nstring and there is at least one character, false otherwise.\n\nSee also\n\n"}, {"name": "chararray.istitle()", "path": "reference/generated/numpy.chararray.istitle", "type": "numpy.chararray.istitle", "text": "\nmethod\n\nReturns true for each element if the element is a titlecased string and there\nis at least one character, false otherwise.\n\nSee also\n\n"}, {"name": "chararray.isupper()", "path": "reference/generated/numpy.chararray.isupper", "type": "numpy.chararray.isupper", "text": "\nmethod\n\nReturns true for each element if all cased characters in the string are\nuppercase and there is at least one character, false otherwise.\n\nSee also\n\n"}, {"name": "chararray.item()", "path": "reference/generated/numpy.chararray.item", "type": "numpy.chararray.item", "text": "\nmethod\n\nCopy an element of an array to a standard Python scalar and return it.\n\nA copy of the specified element of the array as a suitable Python scalar\n\nWhen the data type of `a` is longdouble or clongdouble, item() returns a\nscalar array object because there is no available Python scalar that would not\nlose information. Void arrays return a buffer object for item(), unless fields\nare defined, in which case a tuple is returned.\n\n`item` is very similar to a[args], except, instead of an array scalar, a\nstandard Python scalar is returned. This can be useful for speeding up access\nto elements of the array and doing arithmetic on elements of the array using\nPython\u2019s optimized math.\n\n"}, {"name": "chararray.itemsize", "path": "reference/generated/numpy.chararray.itemsize", "type": "String operations", "text": "\nattribute\n\nLength of one array element in bytes.\n\n"}, {"name": "chararray.join()", "path": "reference/generated/numpy.chararray.join", "type": "numpy.chararray.join", "text": "\nmethod\n\nReturn a string which is the concatenation of the strings in the sequence\n`seq`.\n\nSee also\n\n"}, {"name": "chararray.ljust()", "path": "reference/generated/numpy.chararray.ljust", "type": "numpy.chararray.ljust", "text": "\nmethod\n\nReturn an array with the elements of `self` left-justified in a string of\nlength `width`.\n\nSee also\n\n"}, {"name": "chararray.lower()", "path": "reference/generated/numpy.chararray.lower", "type": "numpy.chararray.lower", "text": "\nmethod\n\nReturn an array with the elements of `self` converted to lowercase.\n\nSee also\n\n"}, {"name": "chararray.lstrip()", "path": "reference/generated/numpy.chararray.lstrip", "type": "numpy.chararray.lstrip", "text": "\nmethod\n\nFor each element in `self`, return a copy with the leading characters removed.\n\nSee also\n\n"}, {"name": "chararray.nbytes", "path": "reference/generated/numpy.chararray.nbytes", "type": "String operations", "text": "\nattribute\n\nTotal bytes consumed by the elements of the array.\n\nDoes not include memory consumed by non-element attributes of the array\nobject.\n\n"}, {"name": "chararray.ndim", "path": "reference/generated/numpy.chararray.ndim", "type": "String operations", "text": "\nattribute\n\nNumber of array dimensions.\n\n"}, {"name": "chararray.nonzero()", "path": "reference/generated/numpy.chararray.nonzero", "type": "numpy.chararray.nonzero", "text": "\nmethod\n\nReturn the indices of the elements that are non-zero.\n\nRefer to `numpy.nonzero` for full documentation.\n\nSee also\n\nequivalent function\n\n"}, {"name": "chararray.put()", "path": "reference/generated/numpy.chararray.put", "type": "numpy.chararray.put", "text": "\nmethod\n\nSet `a.flat[n] = values[n]` for all `n` in indices.\n\nRefer to `numpy.put` for full documentation.\n\nSee also\n\nequivalent function\n\n"}, {"name": "chararray.ravel()", "path": "reference/generated/numpy.chararray.ravel", "type": "numpy.chararray.ravel", "text": "\nmethod\n\nReturn a flattened array.\n\nRefer to `numpy.ravel` for full documentation.\n\nSee also\n\nequivalent function\n\na flat iterator on the array.\n\n"}, {"name": "chararray.repeat()", "path": "reference/generated/numpy.chararray.repeat", "type": "numpy.chararray.repeat", "text": "\nmethod\n\nRepeat elements of an array.\n\nRefer to `numpy.repeat` for full documentation.\n\nSee also\n\nequivalent function\n\n"}, {"name": "chararray.replace()", "path": "reference/generated/numpy.chararray.replace", "type": "numpy.chararray.replace", "text": "\nmethod\n\nFor each element in `self`, return a copy of the string with all occurrences\nof substring `old` replaced by `new`.\n\nSee also\n\n"}, {"name": "chararray.reshape()", "path": "reference/generated/numpy.chararray.reshape", "type": "numpy.chararray.reshape", "text": "\nmethod\n\nReturns an array containing the same data with a new shape.\n\nRefer to `numpy.reshape` for full documentation.\n\nSee also\n\nequivalent function\n\nUnlike the free function `numpy.reshape`, this method on `ndarray` allows the\nelements of the shape parameter to be passed in as separate arguments. For\nexample, `a.reshape(10, 11)` is equivalent to `a.reshape((10, 11))`.\n\n"}, {"name": "chararray.resize()", "path": "reference/generated/numpy.chararray.resize", "type": "numpy.chararray.resize", "text": "\nmethod\n\nChange shape and size of array in-place.\n\nShape of resized array.\n\nIf False, reference count will not be checked. Default is True.\n\nIf `a` does not own its own data or references or views to it exist, and the\ndata memory must be changed. PyPy only: will always raise if the data memory\nmust be changed, since there is no reliable way to determine if references or\nviews to it exist.\n\nIf the `order` keyword argument is specified. This behaviour is a bug in\nNumPy.\n\nSee also\n\nReturn a new array with the specified shape.\n\nThis reallocates space for the data area if necessary.\n\nOnly contiguous arrays (data elements consecutive in memory) can be resized.\n\nThe purpose of the reference count check is to make sure you do not use this\narray as a buffer for another Python object and then reallocate the memory.\nHowever, reference counts can increase in other ways so if you are sure that\nyou have not shared the memory for this array with another Python object, then\nyou may safely set `refcheck` to False.\n\nShrinking an array: array is flattened (in the order that the data are stored\nin memory), resized, and reshaped:\n\nEnlarging an array: as above, but missing entries are filled with zeros:\n\nReferencing an array prevents resizing\u2026\n\nUnless `refcheck` is False:\n\n"}, {"name": "chararray.rfind()", "path": "reference/generated/numpy.chararray.rfind", "type": "numpy.chararray.rfind", "text": "\nmethod\n\nFor each element in `self`, return the highest index in the string where\nsubstring `sub` is found, such that `sub` is contained within [`start`,\n`end`].\n\nSee also\n\n"}, {"name": "chararray.rindex()", "path": "reference/generated/numpy.chararray.rindex", "type": "numpy.chararray.rindex", "text": "\nmethod\n\nLike `rfind`, but raises `ValueError` when the substring `sub` is not found.\n\nSee also\n\n"}, {"name": "chararray.rjust()", "path": "reference/generated/numpy.chararray.rjust", "type": "numpy.chararray.rjust", "text": "\nmethod\n\nReturn an array with the elements of `self` right-justified in a string of\nlength `width`.\n\nSee also\n\n"}, {"name": "chararray.rsplit()", "path": "reference/generated/numpy.chararray.rsplit", "type": "numpy.chararray.rsplit", "text": "\nmethod\n\nFor each element in `self`, return a list of the words in the string, using\n`sep` as the delimiter string.\n\nSee also\n\n"}, {"name": "chararray.rstrip()", "path": "reference/generated/numpy.chararray.rstrip", "type": "numpy.chararray.rstrip", "text": "\nmethod\n\nFor each element in `self`, return a copy with the trailing characters\nremoved.\n\nSee also\n\n"}, {"name": "chararray.searchsorted()", "path": "reference/generated/numpy.chararray.searchsorted", "type": "numpy.chararray.searchsorted", "text": "\nmethod\n\nFind indices where elements of v should be inserted in a to maintain order.\n\nFor full documentation, see `numpy.searchsorted`\n\nSee also\n\nequivalent function\n\n"}, {"name": "chararray.setfield()", "path": "reference/generated/numpy.chararray.setfield", "type": "numpy.chararray.setfield", "text": "\nmethod\n\nPut a value into a specified place in a field defined by a data-type.\n\nPlace `val` into `a`\u2019s field defined by `dtype` and beginning `offset` bytes\ninto the field.\n\nValue to be placed in field.\n\nData-type of the field in which to place `val`.\n\nThe number of bytes into the field at which to place `val`.\n\nSee also\n\n"}, {"name": "chararray.setflags()", "path": "reference/generated/numpy.chararray.setflags", "type": "numpy.chararray.setflags", "text": "\nmethod\n\nSet array flags WRITEABLE, ALIGNED, (WRITEBACKIFCOPY and UPDATEIFCOPY),\nrespectively.\n\nThese Boolean-valued flags affect how numpy interprets the memory area used by\n`a` (see Notes below). The ALIGNED flag can only be set to True if the data is\nactually aligned according to the type. The WRITEBACKIFCOPY and (deprecated)\nUPDATEIFCOPY flags can never be set to True. The flag WRITEABLE can only be\nset to True if the array owns its own memory, or the ultimate owner of the\nmemory exposes a writeable buffer interface, or is a string. (The exception\nfor string is made so that unpickling can be done without copying memory.)\n\nDescribes whether or not `a` can be written to.\n\nDescribes whether or not `a` is aligned properly for its type.\n\nDescribes whether or not `a` is a copy of another \u201cbase\u201d array.\n\nArray flags provide information about how the memory area used for the array\nis to be interpreted. There are 7 Boolean flags in use, only four of which can\nbe changed by the user: WRITEBACKIFCOPY, UPDATEIFCOPY, WRITEABLE, and ALIGNED.\n\nWRITEABLE (W) the data area can be written to;\n\nALIGNED (A) the data and strides are aligned appropriately for the hardware\n(as determined by the compiler);\n\nUPDATEIFCOPY (U) (deprecated), replaced by WRITEBACKIFCOPY;\n\nWRITEBACKIFCOPY (X) this array is a copy of some other array (referenced by\n.base). When the C-API function PyArray_ResolveWritebackIfCopy is called, the\nbase array will be updated with the contents of this array.\n\nAll flags can be accessed using the single (upper case) letter as well as the\nfull name.\n\n"}, {"name": "chararray.size", "path": "reference/generated/numpy.chararray.size", "type": "String operations", "text": "\nattribute\n\nNumber of elements in the array.\n\nEqual to `np.prod(a.shape)`, i.e., the product of the array\u2019s dimensions.\n\n`a.size` returns a standard arbitrary precision Python integer. This may not\nbe the case with other methods of obtaining the same value (like the suggested\n`np.prod(a.shape)`, which returns an instance of `np.int_`), and may be\nrelevant if the value is used further in calculations that may overflow a\nfixed size integer type.\n\n"}, {"name": "chararray.sort()", "path": "reference/generated/numpy.chararray.sort", "type": "numpy.chararray.sort", "text": "\nmethod\n\nSort an array in-place. Refer to `numpy.sort` for full documentation.\n\nAxis along which to sort. Default is -1, which means sort along the last axis.\n\nSorting algorithm. The default is \u2018quicksort\u2019. Note that both \u2018stable\u2019 and\n\u2018mergesort\u2019 use timsort under the covers and, in general, the actual\nimplementation will vary with datatype. The \u2018mergesort\u2019 option is retained for\nbackwards compatibility.\n\nChanged in version 1.15.0: The \u2018stable\u2019 option was added.\n\nWhen `a` is an array with fields defined, this argument specifies which fields\nto compare first, second, etc. A single field can be specified as a string,\nand not all fields need be specified, but unspecified fields will still be\nused, in the order in which they come up in the dtype, to break ties.\n\nSee also\n\nReturn a sorted copy of an array.\n\nIndirect sort.\n\nIndirect stable sort on multiple keys.\n\nFind elements in sorted array.\n\nPartial sort.\n\nSee `numpy.sort` for notes on the different sorting algorithms.\n\nUse the `order` keyword to specify a field to use when sorting a structured\narray:\n\n"}, {"name": "chararray.split()", "path": "reference/generated/numpy.chararray.split", "type": "numpy.chararray.split", "text": "\nmethod\n\nFor each element in `self`, return a list of the words in the string, using\n`sep` as the delimiter string.\n\nSee also\n\n"}, {"name": "chararray.splitlines()", "path": "reference/generated/numpy.chararray.splitlines", "type": "numpy.chararray.splitlines", "text": "\nmethod\n\nFor each element in `self`, return a list of the lines in the element,\nbreaking at line boundaries.\n\nSee also\n\n"}, {"name": "chararray.squeeze()", "path": "reference/generated/numpy.chararray.squeeze", "type": "numpy.chararray.squeeze", "text": "\nmethod\n\nRemove axes of length one from `a`.\n\nRefer to `numpy.squeeze` for full documentation.\n\nSee also\n\nequivalent function\n\n"}, {"name": "chararray.startswith()", "path": "reference/generated/numpy.chararray.startswith", "type": "numpy.chararray.startswith", "text": "\nmethod\n\nReturns a boolean array which is `True` where the string element in `self`\nstarts with `prefix`, otherwise `False`.\n\nSee also\n\n"}, {"name": "chararray.strides", "path": "reference/generated/numpy.chararray.strides", "type": "String operations", "text": "\nattribute\n\nTuple of bytes to step in each dimension when traversing an array.\n\nThe byte offset of element `(i[0], i[1], ..., i[n])` in an array `a` is:\n\nA more detailed explanation of strides can be found in the \u201cndarray.rst\u201d file\nin the NumPy reference guide.\n\nSee also\n\nImagine an array of 32-bit integers (each 4 bytes):\n\nThis array is stored in memory as 40 bytes, one after the other (known as a\ncontiguous block of memory). The strides of an array tell us how many bytes we\nhave to skip in memory to move to the next position along a certain axis. For\nexample, we have to skip 4 bytes (1 value) to move to the next column, but 20\nbytes (5 values) to get to the same position in the next row. As such, the\nstrides for the array `x` will be `(20, 4)`.\n\n"}, {"name": "chararray.strip()", "path": "reference/generated/numpy.chararray.strip", "type": "numpy.chararray.strip", "text": "\nmethod\n\nFor each element in `self`, return a copy with the leading and trailing\ncharacters removed.\n\nSee also\n\n"}, {"name": "chararray.swapaxes()", "path": "reference/generated/numpy.chararray.swapaxes", "type": "numpy.chararray.swapaxes", "text": "\nmethod\n\nReturn a view of the array with `axis1` and `axis2` interchanged.\n\nRefer to `numpy.swapaxes` for full documentation.\n\nSee also\n\nequivalent function\n\n"}, {"name": "chararray.swapcase()", "path": "reference/generated/numpy.chararray.swapcase", "type": "numpy.chararray.swapcase", "text": "\nmethod\n\nFor each element in `self`, return a copy of the string with uppercase\ncharacters converted to lowercase and vice versa.\n\nSee also\n\n"}, {"name": "chararray.T", "path": "reference/generated/numpy.chararray.t", "type": "String operations", "text": "\nattribute\n\nThe transposed array.\n\nSame as `self.transpose()`.\n\nSee also\n\n"}, {"name": "chararray.take()", "path": "reference/generated/numpy.chararray.take", "type": "numpy.chararray.take", "text": "\nmethod\n\nReturn an array formed from the elements of `a` at the given indices.\n\nRefer to `numpy.take` for full documentation.\n\nSee also\n\nequivalent function\n\n"}, {"name": "chararray.title()", "path": "reference/generated/numpy.chararray.title", "type": "numpy.chararray.title", "text": "\nmethod\n\nFor each element in `self`, return a titlecased version of the string: words\nstart with uppercase characters, all remaining cased characters are lowercase.\n\nSee also\n\n"}, {"name": "chararray.tobytes()", "path": "reference/generated/numpy.chararray.tobytes", "type": "String operations", "text": "\nmethod\n\nConstruct Python bytes containing the raw data bytes in the array.\n\nConstructs Python bytes showing a copy of the raw contents of data memory. The\nbytes object is produced in C-order by default. This behavior is controlled by\nthe `order` parameter.\n\nNew in version 1.9.0.\n\nControls the memory layout of the bytes object. \u2018C\u2019 means C-order, \u2018F\u2019 means\nF-order, \u2018A\u2019 (short for Any) means \u2018F\u2019 if `a` is Fortran contiguous, \u2018C\u2019\notherwise. Default is \u2018C\u2019.\n\nPython bytes exhibiting a copy of `a`\u2019s raw data.\n\n"}, {"name": "chararray.tofile()", "path": "reference/generated/numpy.chararray.tofile", "type": "numpy.chararray.tofile", "text": "\nmethod\n\nWrite array to a file as text or binary (default).\n\nData is always written in \u2018C\u2019 order, independent of the order of `a`. The data\nproduced by this method can be recovered using the function fromfile().\n\nAn open file object, or a string containing a filename.\n\nChanged in version 1.17.0: `pathlib.Path` objects are now accepted.\n\nSeparator between array items for text output. If \u201c\u201d (empty), a binary file is\nwritten, equivalent to `file.write(a.tobytes())`.\n\nFormat string for text file output. Each entry in the array is formatted to\ntext by first converting it to the closest Python type, and then using\n\u201cformat\u201d % item.\n\nThis is a convenience function for quick storage of array data. Information on\nendianness and precision is lost, so this method is not a good choice for\nfiles intended to archive data or transport data between machines with\ndifferent endianness. Some of these problems can be overcome by outputting the\ndata as text files, at the expense of speed and file size.\n\nWhen fid is a file object, array contents are directly written to the file,\nbypassing the file object\u2019s `write` method. As a result, tofile cannot be used\nwith files objects supporting compression (e.g., GzipFile) or file-like\nobjects that do not support `fileno()` (e.g., BytesIO).\n\n"}, {"name": "chararray.tolist()", "path": "reference/generated/numpy.chararray.tolist", "type": "numpy.chararray.tolist", "text": "\nmethod\n\nReturn the array as an `a.ndim`-levels deep nested list of Python scalars.\n\nReturn a copy of the array data as a (nested) Python list. Data items are\nconverted to the nearest compatible builtin Python type, via the `item`\nfunction.\n\nIf `a.ndim` is 0, then since the depth of the nested list is 0, it will not be\na list at all, but a simple Python scalar.\n\nThe possibly nested list of array elements.\n\nThe array may be recreated via `a = np.array(a.tolist())`, although this may\nsometimes lose precision.\n\nFor a 1D array, `a.tolist()` is almost the same as `list(a)`, except that\n`tolist` changes numpy scalars to Python scalars:\n\nAdditionally, for a 2D array, `tolist` applies recursively:\n\nThe base case for this recursion is a 0D array:\n\n"}, {"name": "chararray.tostring()", "path": "reference/generated/numpy.chararray.tostring", "type": "numpy.chararray.tostring", "text": "\nmethod\n\nA compatibility alias for `tobytes`, with exactly the same behavior.\n\nDespite its name, it returns `bytes` not `str`s.\n\nDeprecated since version 1.19.0.\n\n"}, {"name": "chararray.translate()", "path": "reference/generated/numpy.chararray.translate", "type": "numpy.chararray.translate", "text": "\nmethod\n\nFor each element in `self`, return a copy of the string where all characters\noccurring in the optional argument `deletechars` are removed, and the\nremaining characters have been mapped through the given translation table.\n\nSee also\n\n"}, {"name": "chararray.transpose()", "path": "reference/generated/numpy.chararray.transpose", "type": "numpy.chararray.transpose", "text": "\nmethod\n\nReturns a view of the array with axes transposed.\n\nFor a 1-D array this has no effect, as a transposed vector is simply the same\nvector. To convert a 1-D array into a 2D column vector, an additional\ndimension must be added. `np.atleast2d(a).T` achieves this, as does `a[:,\nnp.newaxis]`. For a 2-D array, this is a standard matrix transpose. For an n-D\narray, if axes are given, their order indicates how the axes are permuted (see\nExamples). If axes are not provided and `a.shape = (i[0], i[1], ... i[n-2],\ni[n-1])`, then `a.transpose().shape = (i[n-1], i[n-2], ... i[1], i[0])`.\n\nView of `a`, with axes suitably permuted.\n\nSee also\n\nEquivalent function\n\nArray property returning the array transposed.\n\nGive a new shape to an array without changing its data.\n\n"}, {"name": "chararray.upper()", "path": "reference/generated/numpy.chararray.upper", "type": "numpy.chararray.upper", "text": "\nmethod\n\nReturn an array with the elements of `self` converted to uppercase.\n\nSee also\n\n"}, {"name": "chararray.view()", "path": "reference/generated/numpy.chararray.view", "type": "numpy.chararray.view", "text": "\nmethod\n\nNew view of array with the same data.\n\nNote\n\nPassing None for `dtype` is different from omitting the parameter, since the\nformer invokes `dtype(None)` which is an alias for `dtype('float_')`.\n\nData-type descriptor of the returned view, e.g., float32 or int16. Omitting it\nresults in the view having the same data-type as `a`. This argument can also\nbe specified as an ndarray sub-class, which then specifies the type of the\nreturned object (this is equivalent to setting the `type` parameter).\n\nType of the returned view, e.g., ndarray or matrix. Again, omission of the\nparameter results in type preservation.\n\n`a.view()` is used two different ways:\n\n`a.view(some_dtype)` or `a.view(dtype=some_dtype)` constructs a view of the\narray\u2019s memory with a different data-type. This can cause a reinterpretation\nof the bytes of memory.\n\n`a.view(ndarray_subclass)` or `a.view(type=ndarray_subclass)` just returns an\ninstance of `ndarray_subclass` that looks at the same array (same shape,\ndtype, etc.) This does not cause a reinterpretation of the memory.\n\nFor `a.view(some_dtype)`, if `some_dtype` has a different number of bytes per\nentry than the previous dtype (for example, converting a regular array to a\nstructured array), then the behavior of the view cannot be predicted just from\nthe superficial appearance of `a` (shown by `print(a)`). It also depends on\nexactly how `a` is stored in memory. Therefore if `a` is C-ordered versus\nfortran-ordered, versus defined as a slice or transpose, etc., the view may\ngive different results.\n\nViewing array data using a different type and dtype:\n\nCreating a view on a structured array so it can be used in calculations\n\nMaking changes to the view changes the underlying array\n\nUsing a view to convert an array to a recarray:\n\nViews share data:\n\nViews that change the dtype size (bytes per entry) should normally be avoided\non arrays defined by slices, transposes, fortran-ordering, etc.:\n\n"}, {"name": "chararray.zfill()", "path": "reference/generated/numpy.chararray.zfill", "type": "numpy.chararray.zfill", "text": "\nmethod\n\nReturn the numeric string left-filled with zeros in a string of length\n`width`.\n\nSee also\n\n"}, {"name": "class.__array__()", "path": "reference/arrays.classes#numpy.class.__array__", "type": "Standard array subclasses", "text": "\nIf a class (ndarray subclass or not) having the `__array__` method is used as\nthe output object of an ufunc, results will not be written to the object\nreturned by `__array__`. This practice will return `TypeError`.\n\n"}, {"name": "class.__array_finalize__()", "path": "reference/arrays.classes#numpy.class.__array_finalize__", "type": "Standard array subclasses", "text": "\nThis method is called whenever the system internally allocates a new array\nfrom obj, where obj is a subclass (subtype) of the `ndarray`. It can be used\nto change attributes of self after construction (so as to ensure a 2-d matrix\nfor example), or to update meta-information from the \u201cparent.\u201d Subclasses\ninherit a default implementation of this method that does nothing.\n\n"}, {"name": "class.__array_function__()", "path": "reference/arrays.classes#numpy.class.__array_function__", "type": "Standard array subclasses", "text": "\nNew in version 1.16.\n\nNote\n\nAs a convenience for `__array_function__` implementors, `types` provides all\nargument types with an `'__array_function__'` attribute. This allows\nimplementors to quickly identify cases where they should defer to\n`__array_function__` implementations on other arguments. Implementations\nshould not rely on the iteration order of `types`.\n\nMost implementations of `__array_function__` will start with two checks:\n\nIf these conditions hold, `__array_function__` should return the result from\ncalling its implementation for `func(*args, **kwargs)`. Otherwise, it should\nreturn the sentinel value `NotImplemented`, indicating that the function is\nnot implemented by these types.\n\nThere are no general requirements on the return value from\n`__array_function__`, although most sensible implementations should probably\nreturn array(s) with the same type as one of the function\u2019s arguments.\n\nIt may also be convenient to define a custom decorators (`implements` below)\nfor registering `__array_function__` implementations.\n\nNote that it is not required for `__array_function__` implementations to\ninclude all of the corresponding NumPy function\u2019s optional arguments (e.g.,\n`broadcast_to` above omits the irrelevant `subok` argument). Optional\narguments are only passed in to `__array_function__` if they were explicitly\nused in the NumPy function call.\n\nJust like the case for builtin special methods like `__add__`, properly\nwritten `__array_function__` methods should always return `NotImplemented`\nwhen an unknown type is encountered. Otherwise, it will be impossible to\ncorrectly override NumPy functions from another object if the operation also\nincludes one of your objects.\n\nFor the most part, the rules for dispatch with `__array_function__` match\nthose for `__array_ufunc__`. In particular:\n\nIf no `__array_function__` methods exists, NumPy will default to calling its\nown implementation, intended for use on NumPy arrays. This case arises, for\nexample, when all array-like arguments are Python numbers or lists. (NumPy\narrays do have a `__array_function__` method, given below, but it always\nreturns `NotImplemented` if any argument other than a NumPy array subclass\nimplements `__array_function__`.)\n\nOne deviation from the current behavior of `__array_ufunc__` is that NumPy\nwill only call `__array_function__` on the first argument of each unique type.\nThis matches Python\u2019s rule for calling reflected methods, and this ensures\nthat checking overloads has acceptable performance even when there are a large\nnumber of overloaded arguments.\n\n"}, {"name": "class.__array_prepare__()", "path": "reference/arrays.classes#numpy.class.__array_prepare__", "type": "Standard array subclasses", "text": "\nAt the beginning of every ufunc, this method is called on the input object\nwith the highest array priority, or the output object if one was specified.\nThe output array is passed in and whatever is returned is passed to the ufunc.\nSubclasses inherit a default implementation of this method which simply\nreturns the output array unmodified. Subclasses may opt to use this method to\ntransform the output array into an instance of the subclass and update\nmetadata before returning the array to the ufunc for computation.\n\nNote\n\nFor ufuncs, it is hoped to eventually deprecate this method in favour of\n`__array_ufunc__`.\n\n"}, {"name": "class.__array_priority__", "path": "reference/arrays.classes#numpy.class.__array_priority__", "type": "Standard array subclasses", "text": "\nThe value of this attribute is used to determine what type of object to return\nin situations where there is more than one possibility for the Python type of\nthe returned object. Subclasses inherit a default value of 0.0 for this\nattribute.\n\nNote\n\nFor ufuncs, it is hoped to eventually deprecate this method in favour of\n`__array_ufunc__`.\n\n"}, {"name": "class.__array_ufunc__()", "path": "reference/arrays.classes", "type": "Standard array subclasses", "text": "\nNote\n\nSubclassing a `numpy.ndarray` is possible but if your goal is to create an\narray with modified behavior, as do dask arrays for distributed computation\nand cupy arrays for GPU-based computation, subclassing is discouraged.\nInstead, using numpy\u2019s dispatch mechanism is recommended.\n\nThe `ndarray` can be inherited from (in Python or in C) if desired. Therefore,\nit can form a foundation for many useful classes. Often whether to sub-class\nthe array object or to simply use the core array component as an internal part\nof a new class is a difficult decision, and can be simply a matter of choice.\nNumPy has several tools for simplifying how your new object interacts with\nother array objects, and so the choice may not be significant in the end. One\nway to simplify the question is by asking yourself if the object you are\ninterested in can be replaced as a single array or does it really require two\nor more arrays at its core.\n\nNote that `asarray` always returns the base-class ndarray. If you are\nconfident that your use of the array object can handle any subclass of an\nndarray, then `asanyarray` can be used to allow subclasses to propagate more\ncleanly through your subroutine. In principal a subclass could redefine any\naspect of the array and therefore, under strict guidelines, `asanyarray` would\nrarely be useful. However, most subclasses of the array object will not\nredefine certain aspects of the array object such as the buffer interface, or\nthe attributes of the array. One important example, however, of why your\nsubroutine may not be able to handle an arbitrary subclass of an array is that\nmatrices redefine the \u201c*\u201d operator to be matrix-multiplication, rather than\nelement-by-element multiplication.\n\nSee also\n\nSubclassing ndarray\n\nNumPy provides several hooks that classes can customize:\n\nNew in version 1.13.\n\nAny class, ndarray subclass or not, can define this method or set it to None\nin order to override the behavior of NumPy\u2019s ufuncs. This works quite\nsimilarly to Python\u2019s `__mul__` and other binary operation routines.\n\nThe method should return either the result of the operation, or\n`NotImplemented` if the operation requested is not implemented.\n\nIf one of the input or output arguments has a `__array_ufunc__` method, it is\nexecuted instead of the ufunc. If more than one of the arguments implements\n`__array_ufunc__`, they are tried in the order: subclasses before\nsuperclasses, inputs before outputs, otherwise left to right. The first\nroutine returning something other than `NotImplemented` determines the result.\nIf all of the `__array_ufunc__` operations return `NotImplemented`, a\n`TypeError` is raised.\n\nNote\n\nWe intend to re-implement numpy functions as (generalized) Ufunc, in which\ncase it will become possible for them to be overridden by the\n`__array_ufunc__` method. A prime candidate is `matmul`, which currently is\nnot a Ufunc, but could be relatively easily be rewritten as a (set of)\ngeneralized Ufuncs. The same may happen with functions such as `median`,\n`amin`, and `argsort`.\n\nLike with some other special methods in python, such as `__hash__` and\n`__iter__`, it is possible to indicate that your class does not support ufuncs\nby setting `__array_ufunc__ = None`. Ufuncs always raise `TypeError` when\ncalled on an object that sets `__array_ufunc__ = None`.\n\nThe presence of `__array_ufunc__` also influences how `ndarray` handles binary\noperations like `arr + obj` and `arr < obj` when `arr` is an `ndarray` and\n`obj` is an instance of a custom class. There are two possibilities. If\n`obj.__array_ufunc__` is present and not None, then `ndarray.__add__` and\nfriends will delegate to the ufunc machinery, meaning that `arr + obj` becomes\n`np.add(arr, obj)`, and then `add` invokes `obj.__array_ufunc__`. This is\nuseful if you want to define an object that acts like an array.\n\nAlternatively, if `obj.__array_ufunc__` is set to None, then as a special\ncase, special methods like `ndarray.__add__` will notice this and\nunconditionally raise `TypeError`. This is useful if you want to create\nobjects that interact with arrays via binary operations, but are not\nthemselves arrays. For example, a units handling system might have an object\n`m` representing the \u201cmeters\u201d unit, and want to support the syntax `arr * m`\nto represent that the array has units of \u201cmeters\u201d, but not want to otherwise\ninteract with arrays via ufuncs or otherwise. This can be done by setting\n`__array_ufunc__ = None` and defining `__mul__` and `__rmul__` methods. (Note\nthat this means that writing an `__array_ufunc__` that always returns\n`NotImplemented` is not quite the same as setting `__array_ufunc__ = None`: in\nthe former case, `arr + obj` will raise `TypeError`, while in the latter case\nit is possible to define a `__radd__` method to prevent this.)\n\nThe above does not hold for in-place operators, for which `ndarray` never\nreturns `NotImplemented`. Hence, `arr += obj` would always lead to a\n`TypeError`. This is because for arrays in-place operations cannot generically\nbe replaced by a simple reverse operation. (For instance, by default, `arr +=\nobj` would be translated to `arr = arr + obj`, i.e., `arr` would be replaced,\ncontrary to what is expected for in-place array operations.)\n\nNote\n\nIf you define `__array_ufunc__`:\n\nNote\n\nIf a class defines the `__array_ufunc__` method, this disables the\n`__array_wrap__`, `__array_prepare__`, `__array_priority__` mechanism\ndescribed below for ufuncs (which may eventually be deprecated).\n\nNew in version 1.16.\n\nNote\n\nAs a convenience for `__array_function__` implementors, `types` provides all\nargument types with an `'__array_function__'` attribute. This allows\nimplementors to quickly identify cases where they should defer to\n`__array_function__` implementations on other arguments. Implementations\nshould not rely on the iteration order of `types`.\n\nMost implementations of `__array_function__` will start with two checks:\n\nIf these conditions hold, `__array_function__` should return the result from\ncalling its implementation for `func(*args, **kwargs)`. Otherwise, it should\nreturn the sentinel value `NotImplemented`, indicating that the function is\nnot implemented by these types.\n\nThere are no general requirements on the return value from\n`__array_function__`, although most sensible implementations should probably\nreturn array(s) with the same type as one of the function\u2019s arguments.\n\nIt may also be convenient to define a custom decorators (`implements` below)\nfor registering `__array_function__` implementations.\n\nNote that it is not required for `__array_function__` implementations to\ninclude all of the corresponding NumPy function\u2019s optional arguments (e.g.,\n`broadcast_to` above omits the irrelevant `subok` argument). Optional\narguments are only passed in to `__array_function__` if they were explicitly\nused in the NumPy function call.\n\nJust like the case for builtin special methods like `__add__`, properly\nwritten `__array_function__` methods should always return `NotImplemented`\nwhen an unknown type is encountered. Otherwise, it will be impossible to\ncorrectly override NumPy functions from another object if the operation also\nincludes one of your objects.\n\nFor the most part, the rules for dispatch with `__array_function__` match\nthose for `__array_ufunc__`. In particular:\n\nIf no `__array_function__` methods exists, NumPy will default to calling its\nown implementation, intended for use on NumPy arrays. This case arises, for\nexample, when all array-like arguments are Python numbers or lists. (NumPy\narrays do have a `__array_function__` method, given below, but it always\nreturns `NotImplemented` if any argument other than a NumPy array subclass\nimplements `__array_function__`.)\n\nOne deviation from the current behavior of `__array_ufunc__` is that NumPy\nwill only call `__array_function__` on the first argument of each unique type.\nThis matches Python\u2019s rule for calling reflected methods, and this ensures\nthat checking overloads has acceptable performance even when there are a large\nnumber of overloaded arguments.\n\nThis method is called whenever the system internally allocates a new array\nfrom obj, where obj is a subclass (subtype) of the `ndarray`. It can be used\nto change attributes of self after construction (so as to ensure a 2-d matrix\nfor example), or to update meta-information from the \u201cparent.\u201d Subclasses\ninherit a default implementation of this method that does nothing.\n\nAt the beginning of every ufunc, this method is called on the input object\nwith the highest array priority, or the output object if one was specified.\nThe output array is passed in and whatever is returned is passed to the ufunc.\nSubclasses inherit a default implementation of this method which simply\nreturns the output array unmodified. Subclasses may opt to use this method to\ntransform the output array into an instance of the subclass and update\nmetadata before returning the array to the ufunc for computation.\n\nNote\n\nFor ufuncs, it is hoped to eventually deprecate this method in favour of\n`__array_ufunc__`.\n\nAt the end of every ufunc, this method is called on the input object with the\nhighest array priority, or the output object if one was specified. The ufunc-\ncomputed array is passed in and whatever is returned is passed to the user.\nSubclasses inherit a default implementation of this method, which transforms\nthe array into a new instance of the object\u2019s class. Subclasses may opt to use\nthis method to transform the output array into an instance of the subclass and\nupdate metadata before returning the array to the user.\n\nNote\n\nFor ufuncs, it is hoped to eventually deprecate this method in favour of\n`__array_ufunc__`.\n\nThe value of this attribute is used to determine what type of object to return\nin situations where there is more than one possibility for the Python type of\nthe returned object. Subclasses inherit a default value of 0.0 for this\nattribute.\n\nNote\n\nFor ufuncs, it is hoped to eventually deprecate this method in favour of\n`__array_ufunc__`.\n\nIf a class (ndarray subclass or not) having the `__array__` method is used as\nthe output object of an ufunc, results will not be written to the object\nreturned by `__array__`. This practice will return `TypeError`.\n\nNote\n\nIt is strongly advised not to use the matrix subclass. As described below, it\nmakes writing functions that deal consistently with matrices and regular\narrays very difficult. Currently, they are mainly used for interacting with\n`scipy.sparse`. We hope to provide an alternative for this use, however, and\neventually remove the `matrix` subclass.\n\n`matrix` objects inherit from the ndarray and therefore, they have the same\nattributes and methods of ndarrays. There are six important differences of\nmatrix objects, however, that may lead to unexpected results when you use\nmatrices but expect them to act like arrays:\n\nMatrices have special attributes which make calculations easier. These are\n\n`matrix.T`\n\nReturns the transpose of the matrix.\n\n`matrix.H`\n\nReturns the (complex) conjugate transpose of `self`.\n\n`matrix.I`\n\nReturns the (multiplicative) inverse of invertible `self`.\n\n`matrix.A`\n\nReturn `self` as an `ndarray` object.\n\nWarning\n\nMatrix objects over-ride multiplication, \u2018*\u2019, and power, \u2018**\u2019, to be matrix-\nmultiplication and matrix power, respectively. If your subroutine can accept\nsub-classes and you do not convert to base- class arrays, then you must use\nthe ufuncs multiply and power to be sure that you are performing the correct\noperation for all inputs.\n\nThe matrix class is a Python subclass of the ndarray and can be used as a\nreference for how to construct your own subclass of the ndarray. Matrices can\nbe created from other matrices, strings, and anything else that can be\nconverted to an `ndarray` . The name \u201cmat \u201cis an alias for \u201cmatrix \u201cin NumPy.\n\n`matrix`(data[, dtype, copy])\n\nNote\n\nIt is no longer recommended to use this class, even for linear\n\n`asmatrix`(data[, dtype])\n\nInterpret the input as a matrix.\n\n`bmat`(obj[, ldict, gdict])\n\nBuild a matrix object from a string, nested sequence, or array.\n\nExample 1: Matrix creation from a string\n\nExample 2: Matrix creation from nested sequence\n\nExample 3: Matrix creation from an array\n\nMemory-mapped files are useful for reading and/or modifying small segments of\na large file with regular layout, without reading the entire file into memory.\nA simple subclass of the ndarray uses a memory-mapped file for the data buffer\nof the array. For small files, the over-head of reading the entire file into\nmemory is typically not significant, however for large files using memory\nmapping can save considerable resources.\n\nMemory-mapped-file arrays have one additional method (besides those they\ninherit from the ndarray): `.flush()` which must be called manually by the\nuser to ensure that any changes to the array actually get written to disk.\n\n`memmap`(filename[, dtype, mode, offset, ...])\n\nCreate a memory-map to an array stored in a binary file on disk.\n\n`memmap.flush`()\n\nWrite any changes in the array to the file on disk.\n\nExample:\n\nSee also\n\nCreating character arrays (numpy.char)\n\nNote\n\nThe `chararray` class exists for backwards compatibility with Numarray, it is\nnot recommended for new development. Starting from numpy 1.4, if one needs\narrays of strings, it is recommended to use arrays of `dtype` `object_`,\n`bytes_` or `str_`, and use the free functions in the `numpy.char` module for\nfast vectorized string operations.\n\nThese are enhanced arrays of either `str_` type or `bytes_` type. These arrays\ninherit from the `ndarray`, but specially-define the operations `+`, `*`, and\n`%` on a (broadcasting) element-by-element basis. These operations are not\navailable on the standard `ndarray` of character type. In addition, the\n`chararray` has all of the standard `str` (and `bytes`) methods, executing\nthem on an element-by-element basis. Perhaps the easiest way to create a\nchararray is to use `self.view(chararray)` where self is an ndarray of str or\nunicode data-type. However, a chararray can also be created using the\n`numpy.chararray` constructor, or via the `numpy.char.array` function:\n\n`chararray`(shape[, itemsize, unicode, ...])\n\nProvides a convenient view on arrays of string and unicode values.\n\n`core.defchararray.array`(obj[, itemsize, ...])\n\nCreate a `chararray`.\n\nAnother difference with the standard ndarray of str data-type is that the\nchararray inherits the feature introduced by Numarray that white-space at the\nend of any element in the array will be ignored on item retrieval and\ncomparison operations.\n\nSee also\n\nCreating record arrays (numpy.rec), Data type routines, Data type objects\n(dtype).\n\nNumPy provides the `recarray` class which allows accessing the fields of a\nstructured array as attributes, and a corresponding scalar data type object\n`record`.\n\n`recarray`(shape[, dtype, buf, offset, ...])\n\nConstruct an ndarray that allows field access using attributes.\n\n`record`\n\nA data-type scalar that allows field access as attribute lookup.\n\nSee also\n\nMasked arrays\n\nFor backward compatibility and as a standard \u201ccontainer \u201cclass, the UserArray\nfrom Numeric has been brought over to NumPy and named\n`numpy.lib.user_array.container` The container class is a Python class whose\nself.array attribute is an ndarray. Multiple inheritance is probably easier\nwith numpy.lib.user_array.container than with the ndarray itself and so it is\nincluded by default. It is not documented here beyond mentioning its existence\nbecause you are encouraged to use the ndarray class directly if you can.\n\n`numpy.lib.user_array.container`(data[, ...])\n\nStandard container-class for easy multiple-inheritance.\n\nIterators are a powerful concept for array processing. Essentially, iterators\nimplement a generalized for-loop. If myiter is an iterator object, then the\nPython code:\n\ncalls `val = next(myiter)` repeatedly until `StopIteration` is raised by the\niterator. There are several ways to iterate over an array that may be useful:\ndefault iteration, flat iteration, and \\\\(N\\\\)-dimensional enumeration.\n\nThe default iterator of an ndarray object is the default Python iterator of a\nsequence type. Thus, when the array object itself is used as an iterator. The\ndefault behavior is equivalent to:\n\nThis default iterator selects a sub-array of dimension \\\\(N-1\\\\) from the\narray. This can be a useful construct for defining recursive algorithms. To\nloop over the entire array requires \\\\(N\\\\) for-loops.\n\n`ndarray.flat`\n\nA 1-D iterator over the array.\n\nAs mentioned previously, the flat attribute of ndarray objects returns an\niterator that will cycle over the entire array in C-style contiguous order.\n\nHere, I\u2019ve used the built-in enumerate iterator to return the iterator index\nas well as the value.\n\n`ndenumerate`(arr)\n\nMultidimensional index iterator.\n\nSometimes it may be useful to get the N-dimensional index while iterating. The\nndenumerate iterator can achieve this.\n\n`broadcast`\n\nProduce an object that mimics broadcasting.\n\nThe general concept of broadcasting is also available from Python using the\n`broadcast` iterator. This object takes \\\\(N\\\\) objects as inputs and returns\nan iterator that returns tuples providing each of the input sequence elements\nin the broadcasted result.\n\n"}, {"name": "class.__array_wrap__()", "path": "reference/arrays.classes#numpy.class.__array_wrap__", "type": "Standard array subclasses", "text": "\nAt the end of every ufunc, this method is called on the input object with the\nhighest array priority, or the output object if one was specified. The ufunc-\ncomputed array is passed in and whatever is returned is passed to the user.\nSubclasses inherit a default implementation of this method, which transforms\nthe array into a new instance of the object\u2019s class. Subclasses may opt to use\nthis method to transform the output array into an instance of the subclass and\nupdate metadata before returning the array to the user.\n\nNote\n\nFor ufuncs, it is hoped to eventually deprecate this method in favour of\n`__array_ufunc__`.\n\n"}, {"name": "config.add_library()", "path": "reference/distutils_guide", "type": "NumPy Distutils - Users Guide", "text": "\nCurrently SciPy project consists of two packages:\n\nNumPy \u2014 it provides packages like:\n\nThe aim of this document is to describe how to add new tools to SciPy.\n\nSciPy consists of Python packages, called SciPy packages, that are available\nto Python users via the `scipy` namespace. Each SciPy package may contain\nother SciPy packages. And so on. Therefore, the SciPy directory tree is a tree\nof packages with arbitrary depth and width. Any SciPy package may depend on\nNumPy packages but the dependence on other SciPy packages should be kept\nminimal or zero.\n\nA SciPy package contains, in addition to its sources, the following files and\ndirectories:\n\nTheir contents are described below.\n\nIn order to add a Python package to SciPy, its build script (`setup.py`) must\nmeet certain requirements. The most important requirement is that the package\ndefine a `configuration(parent_package='',top_path=None)` function which\nreturns a dictionary suitable for passing to `numpy.distutils.core.setup(..)`.\nTo simplify the construction of this dictionary, `numpy.distutils.misc_util`\nprovides the `Configuration` class, described below.\n\nBelow is an example of a minimal `setup.py` file for a pure SciPy package:\n\nThe arguments of the `configuration` function specify the name of parent SciPy\npackage (`parent_package`) and the directory location of the main `setup.py`\nscript (`top_path`). These arguments, along with the name of the current\npackage, should be passed to the `Configuration` constructor.\n\nThe `Configuration` constructor has a fourth optional argument,\n`package_path`, that can be used when package files are located in a different\nlocation than the directory of the `setup.py` file.\n\nRemaining `Configuration` arguments are all keyword arguments that will be\nused to initialize attributes of `Configuration` instance. Usually, these\nkeywords are the same as the ones that `setup(..)` function would expect, for\nexample, `packages`, `ext_modules`, `data_files`, `include_dirs`, `libraries`,\n`headers`, `scripts`, `package_dir`, etc. However, the direct specification of\nthese keywords is not recommended as the content of these keyword arguments\nwill not be processed or checked for the consistency of SciPy building system.\n\nFinally, `Configuration` has `.todict()` method that returns all the\nconfiguration data as a dictionary suitable for passing on to the `setup(..)`\nfunction.\n\nIn addition to attributes that can be specified via keyword arguments to\n`Configuration` constructor, `Configuration` instance (let us denote as\n`config`) has the following attributes that can be useful in writing setup\nscripts:\n\n`config.add_data_files(*files)` \u2014 prepend `files` to `data_files` list. If\n`files` item is a tuple then its first element defines the suffix of where\ndata files are copied relative to package installation directory and the\nsecond element specifies the path to data files. By default data files are\ncopied under package installation directory. For example,\n\nwill install data files to the following locations\n\nPath to data files can be a function taking no arguments and returning path(s)\nto data files \u2013 this is a useful when data files are generated while building\nthe package. (XXX: explain the step when this function are called exactly)\n\n`config.add_data_dir(data_path)` \u2014 add directory `data_path` recursively to\n`data_files`. The whole directory tree starting at `data_path` will be copied\nunder package installation directory. If `data_path` is a tuple then its first\nelement defines the suffix of where data files are copied relative to package\ninstallation directory and the second element specifies the path to data\ndirectory. By default, data directory are copied under package installation\ndirectory under the basename of `data_path`. For example,\n\nwill install data files to the following locations\n\n`config.add_extension(name,sources,**kw)` \u2014 create and add an `Extension`\ninstance to `ext_modules` list. The first argument `name` defines the name of\nthe extension module that will be installed under `config.name` package. The\nsecond argument is a list of sources. `add_extension` method takes also\nkeyword arguments that are passed on to the `Extension` constructor. The list\nof allowed keywords is the following: `include_dirs`, `define_macros`,\n`undef_macros`, `library_dirs`, `libraries`, `runtime_library_dirs`,\n`extra_objects`, `extra_compile_args`, `extra_link_args`, `export_symbols`,\n`swig_opts`, `depends`, `language`, `f2py_options`, `module_dirs`,\n`extra_info`, `extra_f77_compile_args`, `extra_f90_compile_args`.\n\nNote that `config.paths` method is applied to all lists that may contain\npaths. `extra_info` is a dictionary or a list of dictionaries that content\nwill be appended to keyword arguments. The list `depends` contains paths to\nfiles or directories that the sources of the extension module depend on. If\nany path in the `depends` list is newer than the extension module, then the\nmodule will be rebuilt.\n\nThe list of sources may contain functions (\u2018source generators\u2019) with a pattern\n`def <funcname>(ext, build_dir): return <source(s) or None>`. If `funcname`\nreturns `None`, no sources are generated. And if the `Extension` instance has\nno sources after processing all source generators, no extension module will be\nbuilt. This is the recommended way to conditionally define extension modules.\nSource generator functions are called by the `build_src` sub-command of\n`numpy.distutils`.\n\nFor example, here is a typical source generator function:\n\nThe first argument contains the Extension instance that can be useful to\naccess its attributes like `depends`, `sources`, etc. lists and modify them\nduring the building process. The second argument gives a path to a build\ndirectory that must be used when creating files to a disk.\n\nNumPy distutils supports automatic conversion of source files named\n<somefile>.src. This facility can be used to maintain very similar code blocks\nrequiring only simple changes between blocks. During the build phase of setup,\nif a template file named <somefile>.src is encountered, a new file named\n<somefile> is constructed from the template and placed in the build directory\nto be used instead. Two forms of template conversion are supported. The first\nform occurs for files named <file>.ext.src where ext is a recognized Fortran\nextension (f, f90, f95, f77, for, ftn, pyf). The second form is used for all\nother cases.\n\nThis template converter will replicate all function and subroutine blocks in\nthe file with names that contain \u2018<\u2026>\u2019 according to the rules in \u2018<\u2026>\u2019. The\nnumber of comma-separated words in \u2018<\u2026>\u2019 determines the number of times the\nblock is repeated. What these words are indicates what that repeat rule,\n\u2018<\u2026>\u2019, should be replaced with in each block. All of the repeat rules in a\nblock must contain the same number of comma-separated words indicating the\nnumber of times that block should be repeated. If the word in the repeat rule\nneeds a comma, leftarrow, or rightarrow, then prepend it with a backslash \u2018 '.\nIf a word in the repeat rule matches \u2018 \\<index>\u2019 then it will be replaced with\nthe <index>-th word in the same repeat specification. There are two forms for\nthe repeat rule: named and short.\n\nA named repeat rule is useful when the same set of repeats must be used\nseveral times in a block. It is specified using <rule1=item1, item2, item3,\u2026,\nitemN>, where N is the number of times the block should be repeated. On each\nrepeat of the block, the entire expression, \u2018<\u2026>\u2019 will be replaced first with\nitem1, and then with item2, and so forth until N repeats are accomplished.\nOnce a named repeat specification has been introduced, the same repeat rule\nmay be used in the current block by referring only to the name (i.e. <rule1>).\n\nA short repeat rule looks like <item1, item2, item3, \u2026, itemN>. The rule\nspecifies that the entire expression, \u2018<\u2026>\u2019 should be replaced first with\nitem1, and then with item2, and so forth until N repeats are accomplished.\n\nThe following predefined named repeat rules are available:\n\nNon-Fortran files use a separate syntax for defining template blocks that\nshould be repeated using a variable expansion similar to the named repeat\nrules of the Fortran-specific repeats.\n\nNumPy Distutils preprocesses C source files (extension: `.c.src`) written in a\ncustom templating language to generate C code. The `@` symbol is used to wrap\nmacro-style variables to empower a string substitution mechanism that might\ndescribe (for instance) a set of data types.\n\nThe template language blocks are delimited by `/**begin repeat` and `/**end\nrepeat**/` lines, which may also be nested using consecutively numbered\ndelimiting lines such as `/**begin repeat1` and `/**end repeat1**/`:\n\nThe above rules may be clearer in the following template source example:\n\nThe preprocessing of generically-typed C source files (whether in NumPy proper\nor in any third party package using NumPy Distutils) is performed by\nconv_template.py. The type-specific C files generated (extension: `.c`) by\nthese modules during the build process are ready to be compiled. This form of\ngeneric typing is also supported for C header files (preprocessed to produce\n`.h` files).\n\nThe header of a typical SciPy `__init__.py` is:\n\nIt is possible to specify config_fc options in setup.py scripts. For example,\nusing\n\nsources=[\u2026], config_fc={\u2018noopt\u2019:(__file__,1)})\n\nwill compile the `library` sources without optimization flags.\n\nIt\u2019s recommended to specify only those config_fc options in such a way that\nare compiler independent.\n\nSome old Fortran codes need special compiler options in order to work\ncorrectly. In order to specify compiler options per source file,\n`numpy.distutils` Fortran compiler looks for the following pattern:\n\nin the first 20 lines of the source and use the `f77flags` for specified type\nof the fcompiler (the first character `C` is optional).\n\nTODO: This feature can be easily extended for Fortran 90 codes as well. Let us\nknow if you would need such a feature.\n\n"}, {"name": "const Tp *data()", "path": "dev/howto-docs#_CPPv4N9DoxyLimbo4dataEv", "type": "Development", "text": "\nReturns the raw data for the limbo.\n\n"}, {"name": "Contributing to NumPy", "path": "dev/index", "type": "Development", "text": "\nNot a coder? Not a problem! NumPy is multi-faceted, and we can use a lot of\nhelp. These are all activities we\u2019d like to get help with (they\u2019re all\nimportant, so we list them in alphabetical order):\n\nThe rest of this document discusses working on the NumPy code base and\ndocumentation. We\u2019re in the process of updating our descriptions of other\nactivities and roles. If you are interested in these other activities, please\ncontact us! You can do this via the numpy-discussion mailing list, or on\nGitHub (open an issue or comment on a relevant issue). These are our preferred\ncommunication channels (open source is open by nature!), however if you prefer\nto discuss in private first, please reach out to our community coordinators at\n`numpy-team@googlegroups.com` or `numpy-team.slack.com` (send an email to\n`numpy-team@googlegroups.com` for an invite the first time).\n\nHere\u2019s the short summary, complete TOC links are below:\n\nIf you are a first-time contributor:\n\nClone the project to your local computer:\n\nChange the directory:\n\nAdd the upstream repository:\n\nNow, `git remote -v` will show two remote repositories named:\n\nDevelop your contribution:\n\nPull the latest changes from upstream:\n\nCreate a branch for the feature you want to work on. Since the branch name\nwill appear in the merge message, use a sensible name such as \u2018linspace-\nspeedups\u2019:\n\nTo submit your contribution:\n\nPush your changes back to your fork on GitHub:\n\nReview process:\n\nDocument changes\n\nBeyond changes to a functions docstring and possible description in the\ngeneral documentation, if your change introduces any user-facing modifications\nthey may need to be mentioned in the release notes. To add your change to the\nrelease notes, you need to create a short file with a summary and place it in\n`doc/release/upcoming_changes`. The file\n`doc/release/upcoming_changes/README.rst` details the format and filename\nconventions.\n\nIf your change introduces a deprecation, make sure to discuss this first on\nGitHub or the mailing list first. If agreement on the deprecation is reached,\nfollow NEP 23 deprecation policy to add the deprecation.\n\nCross referencing issues\n\nIf the PR relates to any issues, you can add the text `xref gh-xxxx` where\n`xxxx` is the number of the issue to github comments. Likewise, if the PR\nsolves an issue, replace the `xref` with `closes`, `fixes` or any of the other\nflavors github accepts.\n\nIn the source code, be sure to preface any issue or PR reference with `gh-\nxxxx`.\n\nFor a more detailed discussion, read on and follow the links at the bottom of\nthis page.\n\nIf GitHub indicates that the branch of your Pull Request can no longer be\nmerged automatically, you have to incorporate changes that have been made\nsince you started into your branch. Our recommended way to do this is to\nrebase on main.\n\nUse the following import conventions:\n\nPull requests (PRs) that modify code should either have new tests, or modify\nexisting tests to fail before the PR and pass afterwards. You should run the\ntests before pushing a PR.\n\nRunning NumPy\u2019s test suite locally requires some additional packages, such as\n`pytest` and `hypothesis`. The additional testing dependencies are listed in\n`test_requirements.txt` in the top-level directory, and can conveniently be\ninstalled with:\n\nTests for a module should ideally cover all code in that module, i.e.,\nstatement coverage should be at 100%.\n\nTo measure the test coverage, install pytest-cov and then run:\n\nThis will create a report in `build/coverage`, which can be viewed with:\n\nTo build docs, run `make` from the `doc` directory. `make help` lists all\ntargets. For example, to build the HTML documentation, you can run:\n\nTo get the appropriate dependencies and other requirements, see Building the\nNumPy API and reference docs.\n\nThe rest of the story\n\nNumPy-specific workflow is in numpy-development-workflow.\n\n"}, {"name": "Convenience Classes", "path": "reference/routines.polynomials.package", "type": "Convenience classes", "text": "\nThe following lists the various constants and methods common to all of the\nclasses representing the various kinds of polynomials. In the following, the\nterm `Poly` represents any one of the convenience classes (e.g. `Polynomial`,\n`Chebyshev`, `Hermite`, etc.) while the lowercase `p` represents an instance\nof a polynomial class.\n\nMethods for creating polynomial instances.\n\nMethods for converting a polynomial instance of one kind to another.\n\n"}, {"name": "Copies and views", "path": "user/basics.copies", "type": "User Guide", "text": "\nWhen operating on NumPy arrays, it is possible to access the internal data\nbuffer directly using a view without copying data around. This ensures good\nperformance but can also cause unwanted problems if the user is not aware of\nhow this works. Hence, it is important to know the difference between these\ntwo terms and to know which operations return copies and which return views.\n\nThe NumPy array is a data structure consisting of two parts: the contiguous\ndata buffer with the actual data elements and the metadata that contains\ninformation about the data buffer. The metadata includes data type, strides,\nand other important information that helps manipulate the `ndarray` easily.\nSee the Internal organization of NumPy arrays section for a detailed look.\n\nIt is possible to access the array differently by just changing certain\nmetadata like stride and dtype without changing the data buffer. This creates\na new way of looking at the data and these new arrays are called views. The\ndata buffer remains the same, so any changes made to a view reflects in the\noriginal copy. A view can be forced through the `ndarray.view` method.\n\nWhen a new array is created by duplicating the data buffer as well as the\nmetadata, it is called a copy. Changes made to the copy do not reflect on the\noriginal array. Making a copy is slower and memory-consuming but sometimes\nnecessary. A copy can be forced by using `ndarray.copy`.\n\nSee also\n\nIndexing on ndarrays\n\nViews are created when elements can be addressed with offsets and strides in\nthe original array. Hence, basic indexing always creates views. For example:\n\nHere, `y` gets changed when `x` is changed because it is a view.\n\nAdvanced indexing, on the other hand, always creates copies. For example:\n\nHere, `y` is a copy, as signified by the `base` attribute. We can also confirm\nthis by assigning new values to `x[[1, 2]]` which in turn will not affect `y`\nat all:\n\nIt must be noted here that during the assignment of `x[[1, 2]]` no view or\ncopy is created as the assignment happens in-place.\n\nThe `numpy.reshape` function creates a view where possible or a copy\notherwise. In most cases, the strides can be modified to reshape the array\nwith a view. However, in some cases where the array becomes non-contiguous\n(perhaps after a `ndarray.transpose` operation), the reshaping cannot be done\nby modifying strides and requires a copy. In these cases, we can raise an\nerror by assigning the new shape to the shape attribute of the array. For\nexample:\n\nTaking the example of another operation, `ravel` returns a contiguous\nflattened view of the array wherever possible. On the other hand,\n`ndarray.flatten` always returns a flattened copy of the array. However, to\nguarantee a view in most cases, `x.reshape(-1)` may be preferable.\n\nThe `base` attribute of the ndarray makes it easy to tell if an array is a\nview or a copy. The base attribute of a view returns the original array while\nit returns `None` for a copy.\n\nNote that the `base` attribute should not be used to determine if an ndarray\nobject is new; only if it is a view or a copy of another ndarray.\n\n"}, {"name": "core.defchararray.array()", "path": "reference/generated/numpy.core.defchararray.array", "type": "numpy.core.defchararray.array", "text": "\nCreate a `chararray`.\n\nNote\n\nThis class is provided for numarray backward-compatibility. New code (not\nconcerned with numarray compatibility) should use arrays of type `string_` or\n`unicode_` and use the free functions in `numpy.char` for fast vectorized\nstring operations instead.\n\nVersus a regular NumPy array of type `str` or `unicode`, this class adds the\nfollowing functionality:\n\n`itemsize` is the number of characters per scalar in the resulting array. If\n`itemsize` is None, and `obj` is an object array or a Python list, the\n`itemsize` will be automatically determined. If `itemsize` is provided and\n`obj` is of type str or unicode, then the `obj` string will be chunked into\n`itemsize` pieces.\n\nIf true (default), then the object is copied. Otherwise, a copy will only be\nmade if __array__ returns a copy, if obj is a nested sequence, or if a copy is\nneeded to satisfy any of the other requirements (`itemsize`, unicode, `order`,\netc.).\n\nWhen true, the resulting `chararray` can contain Unicode characters, when\nfalse only 8-bit characters. If unicode is None and `obj` is one of the\nfollowing:\n\nthen the unicode setting of the output array will be automatically determined.\n\nSpecify the order of the array. If order is \u2018C\u2019 (default), then the array will\nbe in C-contiguous order (last-index varies the fastest). If order is \u2018F\u2019,\nthen the returned array will be in Fortran-contiguous order (first-index\nvaries the fastest). If order is \u2018A\u2019, then the returned array may be in any\norder (either C-, Fortran-contiguous, or even discontiguous).\n\n"}, {"name": "core.defchararray.asarray()", "path": "reference/generated/numpy.core.defchararray.asarray", "type": "numpy.core.defchararray.asarray", "text": "\nConvert the input to a `chararray`, copying the data only if necessary.\n\nVersus a regular NumPy array of type `str` or `unicode`, this class adds the\nfollowing functionality:\n\n`itemsize` is the number of characters per scalar in the resulting array. If\n`itemsize` is None, and `obj` is an object array or a Python list, the\n`itemsize` will be automatically determined. If `itemsize` is provided and\n`obj` is of type str or unicode, then the `obj` string will be chunked into\n`itemsize` pieces.\n\nWhen true, the resulting `chararray` can contain Unicode characters, when\nfalse only 8-bit characters. If unicode is None and `obj` is one of the\nfollowing:\n\nthen the unicode setting of the output array will be automatically determined.\n\nSpecify the order of the array. If order is \u2018C\u2019 (default), then the array will\nbe in C-contiguous order (last-index varies the fastest). If order is \u2018F\u2019,\nthen the returned array will be in Fortran-contiguous order (first-index\nvaries the fastest).\n\n"}, {"name": "core.records.array()", "path": "reference/generated/numpy.core.records.array", "type": "numpy.core.records.array", "text": "\nConstruct a record array from a wide-variety of objects.\n\nA general-purpose record array constructor that dispatches to the appropriate\n`recarray` creation function based on the inputs (see Notes).\n\nInput object. See Notes for details on how various input types are treated.\n\nValid dtype for array.\n\nShape of each array.\n\nPosition in the file or buffer to start reading from.\n\nBuffer (`buf`) is interpreted according to these strides (strides define how\nmany bytes each array element, row, column, etc. occupy in memory).\n\nIf `dtype` is `None`, these arguments are passed to `numpy.format_parser` to\nconstruct a dtype. See that function for detailed documentation.\n\nWhether to copy the input object (True), or to use a reference instead. This\noption only applies when the input is an ndarray or recarray. Defaults to\nTrue.\n\nRecord array created from the specified object.\n\nIf `obj` is `None`, then call the `recarray` constructor. If `obj` is a\nstring, then call the `fromstring` constructor. If `obj` is a list or a tuple,\nthen if the first object is an `ndarray`, call `fromarrays`, otherwise call\n`fromrecords`. If `obj` is a `recarray`, then make a copy of the data in the\nrecarray (if `copy=True`) and use the new formats, names, and titles. If `obj`\nis a file, then call `fromfile`. Finally, if obj is an `ndarray`, then return\n`obj.view(recarray)`, making a copy of the data if `copy=True`.\n\n"}, {"name": "core.records.fromarrays()", "path": "reference/generated/numpy.core.records.fromarrays", "type": "numpy.core.records.fromarrays", "text": "\nCreate a record array from a (flat) list of arrays\n\nList of array-like objects (such as lists, tuples, and ndarrays).\n\nvalid dtype for all arrays\n\nShape of the resulting array. If not provided, inferred from `arrayList[0]`.\n\nIf `dtype` is `None`, these arguments are passed to `numpy.format_parser` to\nconstruct a dtype. See that function for detailed documentation.\n\nRecord array consisting of given arrayList columns.\n\n"}, {"name": "core.records.fromfile()", "path": "reference/generated/numpy.core.records.fromfile", "type": "numpy.core.records.fromfile", "text": "\nCreate an array from binary file data\n\nIf file is a string or a path-like object then that file is opened, else it is\nassumed to be a file object. The file object must support random access (i.e.\nit must have tell and seek methods).\n\nvalid dtype for all arrays\n\nshape of each array.\n\nPosition in the file to start reading from.\n\nIf `dtype` is `None`, these arguments are passed to `numpy.format_parser` to\nconstruct a dtype. See that function for detailed documentation\n\nrecord array consisting of data enclosed in file.\n\n"}, {"name": "core.records.fromrecords()", "path": "reference/generated/numpy.core.records.fromrecords", "type": "numpy.core.records.fromrecords", "text": "\nCreate a recarray from a list of records in text form.\n\ndata in the same field may be heterogeneous - they will be promoted to the\nhighest data type.\n\nvalid dtype for all arrays\n\nshape of each array.\n\nIf `dtype` is `None`, these arguments are passed to `numpy.format_parser` to\nconstruct a dtype. See that function for detailed documentation.\n\nIf both `formats` and `dtype` are None, then this will auto-detect formats.\nUse list of tuples rather than list of lists for faster processing.\n\nrecord array consisting of given recList rows.\n\n"}, {"name": "core.records.fromstring()", "path": "reference/generated/numpy.core.records.fromstring", "type": "numpy.core.records.fromstring", "text": "\nCreate a record array from binary data\n\nNote that despite the name of this function it does not accept `str`\ninstances.\n\nBuffer of binary data\n\nValid dtype for all arrays\n\nShape of each array.\n\nPosition in the buffer to start reading from.\n\nIf `dtype` is `None`, these arguments are passed to `numpy.format_parser` to\nconstruct a dtype. See that function for detailed documentation.\n\nRecord array view into the data in datastring. This will be readonly if\n`datastring` is readonly.\n\nSee also\n\n"}, {"name": "CT", "path": "reference/routines.fft", "type": "Discrete Fourier Transform ( \n      \n       numpy.fft\n      \n      )", "text": "\nThe SciPy module `scipy.fft` is a more comprehensive superset of `numpy.fft`,\nwhich includes only a basic set of routines.\n\n`fft`(a[, n, axis, norm])\n\nCompute the one-dimensional discrete Fourier Transform.\n\n`ifft`(a[, n, axis, norm])\n\nCompute the one-dimensional inverse discrete Fourier Transform.\n\n`fft2`(a[, s, axes, norm])\n\nCompute the 2-dimensional discrete Fourier Transform.\n\n`ifft2`(a[, s, axes, norm])\n\nCompute the 2-dimensional inverse discrete Fourier Transform.\n\n`fftn`(a[, s, axes, norm])\n\nCompute the N-dimensional discrete Fourier Transform.\n\n`ifftn`(a[, s, axes, norm])\n\nCompute the N-dimensional inverse discrete Fourier Transform.\n\n`rfft`(a[, n, axis, norm])\n\nCompute the one-dimensional discrete Fourier Transform for real input.\n\n`irfft`(a[, n, axis, norm])\n\nComputes the inverse of `rfft`.\n\n`rfft2`(a[, s, axes, norm])\n\nCompute the 2-dimensional FFT of a real array.\n\n`irfft2`(a[, s, axes, norm])\n\nComputes the inverse of `rfft2`.\n\n`rfftn`(a[, s, axes, norm])\n\nCompute the N-dimensional discrete Fourier Transform for real input.\n\n`irfftn`(a[, s, axes, norm])\n\nComputes the inverse of `rfftn`.\n\n`hfft`(a[, n, axis, norm])\n\nCompute the FFT of a signal that has Hermitian symmetry, i.e., a real\nspectrum.\n\n`ihfft`(a[, n, axis, norm])\n\nCompute the inverse FFT of a signal that has Hermitian symmetry.\n\n`fftfreq`(n[, d])\n\nReturn the Discrete Fourier Transform sample frequencies.\n\n`rfftfreq`(n[, d])\n\nReturn the Discrete Fourier Transform sample frequencies (for usage with rfft,\nirfft).\n\n`fftshift`(x[, axes])\n\nShift the zero-frequency component to the center of the spectrum.\n\n`ifftshift`(x[, axes])\n\nThe inverse of `fftshift`.\n\nFourier analysis is fundamentally a method for expressing a function as a sum\nof periodic components, and for recovering the function from those components.\nWhen both the function and its Fourier transform are replaced with discretized\ncounterparts, it is called the discrete Fourier transform (DFT). The DFT has\nbecome a mainstay of numerical computing in part because of a very fast\nalgorithm for computing it, called the Fast Fourier Transform (FFT), which was\nknown to Gauss (1805) and was brought to light in its current form by Cooley\nand Tukey [CT]. Press et al. [NR] provide an accessible introduction to\nFourier analysis and its applications.\n\nBecause the discrete Fourier transform separates its input into components\nthat contribute at discrete frequencies, it has a great number of applications\nin digital signal processing, e.g., for filtering, and in this context the\ndiscretized input to the transform is customarily referred to as a signal,\nwhich exists in the time domain. The output is called a spectrum or transform\nand exists in the frequency domain.\n\nThere are many ways to define the DFT, varying in the sign of the exponent,\nnormalization, etc. In this implementation, the DFT is defined as\n\nThe DFT is in general defined for complex inputs and outputs, and a single-\nfrequency component at linear frequency \\\\(f\\\\) is represented by a complex\nexponential \\\\(a_m = \\exp\\\\{2\\pi i\\,f m\\Delta t\\\\}\\\\), where \\\\(\\Delta t\\\\) is\nthe sampling interval.\n\nThe values in the result follow so-called \u201cstandard\u201d order: If `A = fft(a,\nn)`, then `A[0]` contains the zero-frequency term (the sum of the signal),\nwhich is always purely real for real inputs. Then `A[1:n/2]` contains the\npositive-frequency terms, and `A[n/2+1:]` contains the negative-frequency\nterms, in order of decreasingly negative frequency. For an even number of\ninput points, `A[n/2]` represents both positive and negative Nyquist\nfrequency, and is also purely real for real input. For an odd number of input\npoints, `A[(n-1)/2]` contains the largest positive frequency, while\n`A[(n+1)/2]` contains the largest negative frequency. The routine\n`np.fft.fftfreq(n)` returns an array giving the frequencies of corresponding\nelements in the output. The routine `np.fft.fftshift(A)` shifts transforms and\ntheir frequencies to put the zero-frequency components in the middle, and\n`np.fft.ifftshift(A)` undoes that shift.\n\nWhen the input `a` is a time-domain signal and `A = fft(a)`, `np.abs(A)` is\nits amplitude spectrum and `np.abs(A)**2` is its power spectrum. The phase\nspectrum is obtained by `np.angle(A)`.\n\nThe inverse DFT is defined as\n\nIt differs from the forward transform by the sign of the exponential argument\nand the default normalization by \\\\(1/n\\\\).\n\n`numpy.fft` promotes `float32` and `complex64` arrays to `float64` and\n`complex128` arrays respectively. For an FFT implementation that does not\npromote input arrays, see `scipy.fftpack`.\n\nThe argument `norm` indicates which direction of the pair of direct/inverse\ntransforms is scaled and with what normalization factor. The default\nnormalization (`\"backward\"`) has the direct (forward) transforms unscaled and\nthe inverse (backward) transforms scaled by \\\\(1/n\\\\). It is possible to\nobtain unitary transforms by setting the keyword argument `norm` to `\"ortho\"`\nso that both direct and inverse transforms are scaled by \\\\(1/\\sqrt{n}\\\\).\nFinally, setting the keyword argument `norm` to `\"forward\"` has the direct\ntransforms scaled by \\\\(1/n\\\\) and the inverse transforms unscaled (i.e.\nexactly opposite to the default `\"backward\"`). `None` is an alias of the\ndefault option `\"backward\"` for backward compatibility.\n\nWhen the input is purely real, its transform is Hermitian, i.e., the component\nat frequency \\\\(f_k\\\\) is the complex conjugate of the component at frequency\n\\\\(-f_k\\\\), which means that for real inputs there is no information in the\nnegative frequency components that is not already available from the positive\nfrequency components. The family of `rfft` functions is designed to operate on\nreal inputs, and exploits this symmetry by computing only the positive\nfrequency components, up to and including the Nyquist frequency. Thus, `n`\ninput points produce `n/2+1` complex output points. The inverses of this\nfamily assumes the same symmetry of its input, and for an output of `n` points\nuses `n/2+1` input points.\n\nCorrespondingly, when the spectrum is purely real, the signal is Hermitian.\nThe `hfft` family of functions exploits this symmetry by using `n/2+1` complex\npoints in the input (time) domain for `n` real points in the frequency domain.\n\nIn higher dimensions, FFTs are used, e.g., for image analysis and filtering.\nThe computational efficiency of the FFT means that it can also be a faster way\nto compute large convolutions, using the property that a convolution in the\ntime domain is equivalent to a point-by-point multiplication in the frequency\ndomain.\n\nIn two dimensions, the DFT is defined as\n\nwhich extends in the obvious way to higher dimensions, and the inverses in\nhigher dimensions also extend in the same way.\n\nCooley, James W., and John W. Tukey, 1965, \u201cAn algorithm for the machine\ncalculation of complex Fourier series,\u201d Math. Comput. 19: 297-301.\n\nPress, W., Teukolsky, S., Vetterline, W.T., and Flannery, B.P., 2007,\nNumerical Recipes: The Art of Scientific Computing, ch. 12-13. Cambridge Univ.\nPress, Cambridge, UK.\n\nFor examples, see the various functions.\n\n"}, {"name": "Data type routines", "path": "reference/routines.dtype", "type": "Data type routines", "text": "\n`can_cast`(from_, to[, casting])\n\nReturns True if cast between data types can occur according to the casting\nrule.\n\n`promote_types`(type1, type2)\n\nReturns the data type with the smallest size and smallest scalar kind to which\nboth `type1` and `type2` may be safely cast.\n\n`min_scalar_type`(a, /)\n\nFor scalar `a`, returns the data type with the smallest size and smallest\nscalar kind which can hold its value.\n\n`result_type`(*arrays_and_dtypes)\n\nReturns the type that results from applying the NumPy type promotion rules to\nthe arguments.\n\n`common_type`(*arrays)\n\nReturn a scalar type which is common to the input arrays.\n\n`obj2sctype`(rep[, default])\n\nReturn the scalar dtype or NumPy equivalent of Python type of an object.\n\n`dtype`(dtype[, align, copy])\n\nCreate a data type object.\n\n`format_parser`(formats, names, titles[, ...])\n\nClass to convert formats, names, titles description to a dtype.\n\n`finfo`(dtype)\n\nMachine limits for floating point types.\n\n`iinfo`(type)\n\nMachine limits for integer types.\n\n`MachAr`([float_conv, int_conv, ...])\n\nDiagnosing machine parameters.\n\n`issctype`(rep)\n\nDetermines whether the given object represents a scalar data-type.\n\n`issubdtype`(arg1, arg2)\n\nReturns True if first argument is a typecode lower/equal in type hierarchy.\n\n`issubsctype`(arg1, arg2)\n\nDetermine if the first argument is a subclass of the second argument.\n\n`issubclass_`(arg1, arg2)\n\nDetermine if a class is a subclass of a second class.\n\n`find_common_type`(array_types, scalar_types)\n\nDetermine common type following standard coercion rules.\n\n`typename`(char)\n\nReturn a description for the given data type code.\n\n`sctype2char`(sctype)\n\nReturn the string representation of a scalar dtype.\n\n`mintypecode`(typechars[, typeset, default])\n\nReturn the character for the minimum-size type to which given types can be\nsafely cast.\n\n`maximum_sctype`(t)\n\nReturn the scalar type of highest precision of the same kind as the input.\n\n"}, {"name": "Data types", "path": "user/basics.types", "type": "User Guide", "text": "\nSee also\n\nData type objects\n\nNumPy supports a much greater variety of numerical types than Python does.\nThis section shows which are available, and how to modify an array\u2019s data-\ntype.\n\nThe primitive types supported are tied closely to those in C:\n\nNumpy type\n\nC type\n\nDescription\n\n`numpy.bool_`\n\n`bool`\n\nBoolean (True or False) stored as a byte\n\n`numpy.byte`\n\n`signed char`\n\nPlatform-defined\n\n`numpy.ubyte`\n\n`unsigned char`\n\nPlatform-defined\n\n`numpy.short`\n\n`short`\n\nPlatform-defined\n\n`numpy.ushort`\n\n`unsigned short`\n\nPlatform-defined\n\n`numpy.intc`\n\n`int`\n\nPlatform-defined\n\n`numpy.uintc`\n\n`unsigned int`\n\nPlatform-defined\n\n`numpy.int_`\n\n`long`\n\nPlatform-defined\n\n`numpy.uint`\n\n`unsigned long`\n\nPlatform-defined\n\n`numpy.longlong`\n\n`long long`\n\nPlatform-defined\n\n`numpy.ulonglong`\n\n`unsigned long long`\n\nPlatform-defined\n\n`numpy.half` / `numpy.float16`\n\nHalf precision float: sign bit, 5 bits exponent, 10 bits mantissa\n\n`numpy.single`\n\n`float`\n\nPlatform-defined single precision float: typically sign bit, 8 bits exponent,\n23 bits mantissa\n\n`numpy.double`\n\n`double`\n\nPlatform-defined double precision float: typically sign bit, 11 bits exponent,\n52 bits mantissa.\n\n`numpy.longdouble`\n\n`long double`\n\nPlatform-defined extended-precision float\n\n`numpy.csingle`\n\n`float complex`\n\nComplex number, represented by two single-precision floats (real and imaginary\ncomponents)\n\n`numpy.cdouble`\n\n`double complex`\n\nComplex number, represented by two double-precision floats (real and imaginary\ncomponents).\n\n`numpy.clongdouble`\n\n`long double complex`\n\nComplex number, represented by two extended-precision floats (real and\nimaginary components).\n\nSince many of these have platform-dependent definitions, a set of fixed-size\naliases are provided (See Sized aliases).\n\nNumPy numerical types are instances of `dtype` (data-type) objects, each\nhaving unique characteristics. Once you have imported NumPy using\n\nthe dtypes are available as `np.bool_`, `np.float32`, etc.\n\nAdvanced types, not listed above, are explored in section Structured arrays.\n\nThere are 5 basic numerical types representing booleans (bool), integers\n(int), unsigned integers (uint) floating point (float) and complex. Those with\nnumbers in their name indicate the bitsize of the type (i.e. how many bits are\nneeded to represent a single value in memory). Some types, such as `int` and\n`intp`, have differing bitsizes, dependent on the platforms (e.g. 32-bit vs.\n64-bit machines). This should be taken into account when interfacing with low-\nlevel code (such as C or Fortran) where the raw memory is addressed.\n\nData-types can be used as functions to convert python numbers to array scalars\n(see the array scalar section for an explanation), python sequences of numbers\nto arrays of that type, or as arguments to the dtype keyword that many numpy\nfunctions or methods accept. Some examples:\n\nArray types can also be referred to by character codes, mostly to retain\nbackward compatibility with older packages such as Numeric. Some documentation\nmay still refer to these, for example:\n\nWe recommend using dtype objects instead.\n\nTo convert the type of an array, use the .astype() method (preferred) or the\ntype itself as a function. For example:\n\nNote that, above, we use the Python float object as a dtype. NumPy knows that\n`int` refers to `np.int_`, `bool` means `np.bool_`, that `float` is\n`np.float_` and `complex` is `np.complex_`. The other data-types do not have\nPython equivalents.\n\nTo determine the type of an array, look at the dtype attribute:\n\ndtype objects also contain information about the type, such as its bit-width\nand its byte-order. The data type can also be used indirectly to query\nproperties of the type, such as whether it is an integer:\n\nNumPy generally returns elements of arrays as array scalars (a scalar with an\nassociated dtype). Array scalars differ from Python scalars, but for the most\npart they can be used interchangeably (the primary exception is for versions\nof Python older than v2.x, where integer array scalars cannot act as indices\nfor lists and tuples). There are some exceptions, such as when code requires\nvery specific attributes of a scalar or when it checks specifically whether a\nvalue is a Python scalar. Generally, problems are easily fixed by explicitly\nconverting array scalars to Python scalars, using the corresponding Python\ntype function (e.g., `int`, `float`, `complex`, `str`, `unicode`).\n\nThe primary advantage of using array scalars is that they preserve the array\ntype (Python may not have a matching scalar type available, e.g. `int16`).\nTherefore, the use of array scalars ensures identical behaviour between arrays\nand scalars, irrespective of whether the value is inside an array or not.\nNumPy scalars also have many of the same methods arrays do.\n\nThe fixed size of NumPy numeric types may cause overflow errors when a value\nrequires more memory than available in the data type. For example,\n`numpy.power` evaluates `100 ** 8` correctly for 64-bit integers, but gives\n1874919424 (incorrect) for a 32-bit integer.\n\nThe behaviour of NumPy and Python integer types differs significantly for\ninteger overflows and may confuse users expecting NumPy integers to behave\nsimilar to Python\u2019s `int`. Unlike NumPy, the size of Python\u2019s `int` is\nflexible. This means Python integers may expand to accommodate any integer and\nwill not overflow.\n\nNumPy provides `numpy.iinfo` and `numpy.finfo` to verify the minimum or\nmaximum values of NumPy integer and floating point values respectively\n\nIf 64-bit integers are still too small the result may be cast to a floating\npoint number. Floating point numbers offer a larger, but inexact, range of\npossible values.\n\nPython\u2019s floating-point numbers are usually 64-bit floating-point numbers,\nnearly equivalent to `np.float64`. In some unusual situations it may be useful\nto use floating-point numbers with more precision. Whether this is possible in\nnumpy depends on the hardware and on the development environment:\nspecifically, x86 machines provide hardware floating-point with 80-bit\nprecision, and while most C compilers provide this as their `long double`\ntype, MSVC (standard for Windows builds) makes `long double` identical to\n`double` (64 bits). NumPy makes the compiler\u2019s `long double` available as\n`np.longdouble` (and `np.clongdouble` for the complex numbers). You can find\nout what your numpy provides with `np.finfo(np.longdouble)`.\n\nNumPy does not provide a dtype with more precision than C\u2019s `long double`\\; in\nparticular, the 128-bit IEEE quad precision data type (FORTRAN\u2019s `REAL*16`\\\\)\nis not available.\n\nFor efficient memory alignment, `np.longdouble` is usually stored padded with\nzero bits, either to 96 or 128 bits. Which is more efficient depends on\nhardware and development environment; typically on 32-bit systems they are\npadded to 96 bits, while on 64-bit systems they are typically padded to 128\nbits. `np.longdouble` is padded to the system default; `np.float96` and\n`np.float128` are provided for users who want specific padding. In spite of\nthe names, `np.float96` and `np.float128` provide only as much precision as\n`np.longdouble`, that is, 80 bits on most x86 machines and 64 bits in standard\nWindows builds.\n\nBe warned that even if `np.longdouble` offers more precision than python\n`float`, it is easy to lose that extra precision, since python often forces\nvalues to pass through `float`. For example, the `%` formatting operator\nrequires its arguments to be converted to standard python types, and it is\ntherefore impossible to preserve extended precision even if many decimal\nplaces are requested. It can be useful to test your code with the value `1 +\nnp.finfo(np.longdouble).eps`.\n\n"}, {"name": "DataSource.abspath()", "path": "reference/generated/numpy.datasource.abspath", "type": "numpy.DataSource.abspath", "text": "\nmethod\n\nReturn absolute path of file in the DataSource directory.\n\nIf `path` is an URL, then `abspath` will return either the location the file\nexists locally or the location it would exist when opened using the `open`\nmethod.\n\nCan be a local file or a remote URL.\n\nComplete path, including the `DataSource` destination directory.\n\nThe functionality is based on `os.path.abspath`.\n\n"}, {"name": "DataSource.exists()", "path": "reference/generated/numpy.datasource.exists", "type": "numpy.DataSource.exists", "text": "\nmethod\n\nTest if path exists.\n\nTest if `path` exists as (and in this order):\n\nCan be a local file or a remote URL.\n\nTrue if `path` exists.\n\nWhen `path` is an URL, `exists` will return True if it\u2019s either stored locally\nin the `DataSource` directory, or is a valid remote URL. `DataSource` does not\ndiscriminate between the two, the file is accessible if it exists in either\nlocation.\n\n"}, {"name": "DataSource.open()", "path": "reference/generated/numpy.datasource.open", "type": "numpy.DataSource.open", "text": "\nmethod\n\nOpen and return file-like object.\n\nIf `path` is an URL, it will be downloaded, stored in the `DataSource`\ndirectory and opened from there.\n\nLocal file path or URL to open.\n\nMode to open `path`. Mode \u2018r\u2019 for reading, \u2018w\u2019 for writing, \u2018a\u2019 to append.\nAvailable modes depend on the type of object specified by `path`. Default is\n\u2018r\u2019.\n\nOpen text file with given encoding. The default encoding will be what\n`io.open` uses.\n\nNewline to use when reading text file.\n\nFile object.\n\n"}, {"name": "Datetime Support Functions", "path": "reference/routines.datetime", "type": "Datetime Support Functions", "text": "\n`datetime_as_string`(arr[, unit, timezone, ...])\n\nConvert an array of datetimes into an array of strings.\n\n`datetime_data`(dtype, /)\n\nGet information about the step size of a date or time type.\n\n`busdaycalendar`([weekmask, holidays])\n\nA business day calendar object that efficiently stores information defining\nvalid days for the busday family of functions.\n\n`is_busday`(dates[, weekmask, holidays, ...])\n\nCalculates which of the given dates are valid days, and which are not.\n\n`busday_offset`(dates, offsets[, roll, ...])\n\nFirst adjusts the date to fall on a valid day according to the `roll` rule,\nthen applies offsets to the given dates counted in valid days.\n\n`busday_count`(begindates, enddates[, ...])\n\nCounts the number of valid days between `begindates` and `enddates`, not\nincluding the day of `enddates`.\n\n"}, {"name": "Datetimes and Timedeltas", "path": "reference/arrays.datetime", "type": "Datetimes and Timedeltas", "text": "\nNew in version 1.7.0.\n\nStarting in NumPy 1.7, there are core array data types which natively support\ndatetime functionality. The data type is called \u201cdatetime64\u201d, so named because\n\u201cdatetime\u201d is already taken by the datetime library included in Python.\n\nThe most basic way to create datetimes is from strings in ISO 8601 date or\ndatetime format. It is also possible to create datetimes from an integer by\noffset relative to the Unix epoch (00:00:00 UTC on 1 January 1970). The unit\nfor internal storage is automatically selected from the form of the string,\nand can be either a date unit or a time unit. The date units are years (\u2018Y\u2019),\nmonths (\u2018M\u2019), weeks (\u2018W\u2019), and days (\u2018D\u2019), while the time units are hours\n(\u2018h\u2019), minutes (\u2018m\u2019), seconds (\u2018s\u2019), milliseconds (\u2018ms\u2019), and some additional\nSI-prefix seconds-based units. The datetime64 data type also accepts the\nstring \u201cNAT\u201d, in any combination of lowercase/uppercase letters, for a \u201cNot A\nTime\u201d value.\n\nA simple ISO date:\n\nFrom an integer and a date unit, 1 year since the UNIX epoch:\n\nUsing months for the unit:\n\nSpecifying just the month, but forcing a \u2018days\u2019 unit:\n\nFrom a date and time:\n\nNAT (not a time):\n\nWhen creating an array of datetimes from a string, it is still possible to\nautomatically select the unit from the inputs, by using the datetime type with\ngeneric units.\n\nAn array of datetimes can be constructed from integers representing POSIX\ntimestamps with the given unit.\n\nThe datetime type works with many common NumPy functions, for example `arange`\ncan be used to generate ranges of dates.\n\nAll the dates for one month:\n\nThe datetime object represents a single moment in time. If two datetimes have\ndifferent units, they may still be representing the same moment of time, and\nconverting from a bigger unit like months to a smaller unit like days is\nconsidered a \u2018safe\u2019 cast because the moment of time is still being represented\nexactly.\n\nDeprecated since version 1.11.0: NumPy does not store timezone information.\nFor backwards compatibility, datetime64 still parses timezone offsets, which\nit handles by converting to UTC. This behaviour is deprecated and will raise\nan error in the future.\n\nNumPy allows the subtraction of two Datetime values, an operation which\nproduces a number with a time unit. Because NumPy doesn\u2019t have a physical\nquantities system in its core, the timedelta64 data type was created to\ncomplement datetime64. The arguments for timedelta64 are a number, to\nrepresent the number of units, and a date/time unit, such as (D)ay, (M)onth,\n(Y)ear, (h)ours, (m)inutes, or (s)econds. The timedelta64 data type also\naccepts the string \u201cNAT\u201d in place of the number for a \u201cNot A Time\u201d value.\n\nDatetimes and Timedeltas work together to provide ways for simple datetime\ncalculations.\n\nThere are two Timedelta units (\u2018Y\u2019, years and \u2018M\u2019, months) which are treated\nspecially, because how much time they represent changes depending on when they\nare used. While a timedelta day unit is equivalent to 24 hours, there is no\nway to convert a month unit into days, because different months have different\nnumbers of days.\n\nThe Datetime and Timedelta data types support a large number of time units, as\nwell as generic units which can be coerced into any of the other units based\non input data.\n\nDatetimes are always stored based on POSIX time (though having a TAI mode\nwhich allows for accounting of leap-seconds is proposed), with an epoch of\n1970-01-01T00:00Z. This means the supported dates are always a symmetric\ninterval around the epoch, called \u201ctime span\u201d in the table below.\n\nThe length of the span is the range of a 64-bit integer times the length of\nthe date or unit. For example, the time span for \u2018W\u2019 (week) is exactly 7 times\nlonger than the time span for \u2018D\u2019 (day), and the time span for \u2018D\u2019 (day) is\nexactly 24 times longer than the time span for \u2018h\u2019 (hour).\n\nHere are the date units:\n\nCode\n\nMeaning\n\nTime span (relative)\n\nTime span (absolute)\n\nY\n\nyear\n\n+/- 9.2e18 years\n\n[9.2e18 BC, 9.2e18 AD]\n\nM\n\nmonth\n\n+/- 7.6e17 years\n\n[7.6e17 BC, 7.6e17 AD]\n\nW\n\nweek\n\n+/- 1.7e17 years\n\n[1.7e17 BC, 1.7e17 AD]\n\nD\n\nday\n\n+/- 2.5e16 years\n\n[2.5e16 BC, 2.5e16 AD]\n\nAnd here are the time units:\n\nCode\n\nMeaning\n\nTime span (relative)\n\nTime span (absolute)\n\nh\n\nhour\n\n+/- 1.0e15 years\n\n[1.0e15 BC, 1.0e15 AD]\n\nm\n\nminute\n\n+/- 1.7e13 years\n\n[1.7e13 BC, 1.7e13 AD]\n\ns\n\nsecond\n\n+/- 2.9e11 years\n\n[2.9e11 BC, 2.9e11 AD]\n\nms\n\nmillisecond\n\n+/- 2.9e8 years\n\n[ 2.9e8 BC, 2.9e8 AD]\n\nus / \u03bcs\n\nmicrosecond\n\n+/- 2.9e5 years\n\n[290301 BC, 294241 AD]\n\nns\n\nnanosecond\n\n+/- 292 years\n\n[ 1678 AD, 2262 AD]\n\nps\n\npicosecond\n\n+/- 106 days\n\n[ 1969 AD, 1970 AD]\n\nfs\n\nfemtosecond\n\n+/- 2.6 hours\n\n[ 1969 AD, 1970 AD]\n\nas\n\nattosecond\n\n+/- 9.2 seconds\n\n[ 1969 AD, 1970 AD]\n\nTo allow the datetime to be used in contexts where only certain days of the\nweek are valid, NumPy includes a set of \u201cbusday\u201d (business day) functions.\n\nThe default for busday functions is that the only valid days are Monday\nthrough Friday (the usual business days). The implementation is based on a\n\u201cweekmask\u201d containing 7 Boolean flags to indicate valid days; custom weekmasks\nare possible that specify other sets of valid days.\n\nThe \u201cbusday\u201d functions can additionally check a list of \u201choliday\u201d dates,\nspecific dates that are not valid days.\n\nThe function `busday_offset` allows you to apply offsets specified in business\ndays to datetimes with a unit of \u2018D\u2019 (day).\n\nWhen an input date falls on the weekend or a holiday, `busday_offset` first\napplies a rule to roll the date to a valid business day, then applies the\noffset. The default rule is \u2018raise\u2019, which simply raises an exception. The\nrules most typically used are \u2018forward\u2019 and \u2018backward\u2019.\n\nIn some cases, an appropriate use of the roll and the offset is necessary to\nget a desired answer.\n\nThe first business day on or after a date:\n\nThe first business day strictly after a date:\n\nThe function is also useful for computing some kinds of days like holidays. In\nCanada and the U.S., Mother\u2019s day is on the second Sunday in May, which can be\ncomputed with a custom weekmask.\n\nWhen performance is important for manipulating many business dates with one\nparticular choice of weekmask and holidays, there is an object\n`busdaycalendar` which stores the data necessary in an optimized form.\n\nTo test a datetime64 value to see if it is a valid day, use `is_busday`.\n\nTo find how many valid days there are in a specified range of datetime64\ndates, use `busday_count`:\n\nIf you have an array of datetime64 day values, and you want a count of how\nmany of them are valid dates, you can do this:\n\nHere are several examples of custom weekmask values. These examples specify\nthe \u201cbusday\u201d default of Monday through Friday being valid days.\n\nSome examples:\n\n"}, {"name": "deletechars", "path": "user/basics.io.genfromtxt", "type": "User Guide", "text": "\nNumPy provides several functions to create arrays from tabular data. We focus\nhere on the `genfromtxt` function.\n\nIn a nutshell, `genfromtxt` runs two main loops. The first loop converts each\nline of the file in a sequence of strings. The second loop converts each\nstring to the appropriate data type. This mechanism is slower than a single\nloop, but gives more flexibility. In particular, `genfromtxt` is able to take\nmissing data into account, when other faster and simpler functions like\n`loadtxt` cannot.\n\nNote\n\nWhen giving examples, we will use the following conventions:\n\nThe only mandatory argument of `genfromtxt` is the source of the data. It can\nbe a string, a list of strings, a generator or an open file-like object with a\n`read` method, for example, a file or `io.StringIO` object. If a single string\nis provided, it is assumed to be the name of a local or remote file. If a list\nof strings or a generator returning strings is provided, each string is\ntreated as one line in a file. When the URL of a remote file is passed, the\nfile is automatically downloaded to the current directory and opened.\n\nRecognized file types are text files and archives. Currently, the function\nrecognizes `gzip` and `bz2` (`bzip2`) archives. The type of the archive is\ndetermined from the extension of the file: if the filename ends with `'.gz'`,\na `gzip` archive is expected; if it ends with `'bz2'`, a `bzip2` archive is\nassumed.\n\nOnce the file is defined and open for reading, `genfromtxt` splits each non-\nempty line into a sequence of strings. Empty or commented lines are just\nskipped. The `delimiter` keyword is used to define how the splitting should\ntake place.\n\nQuite often, a single character marks the separation between columns. For\nexample, comma-separated files (CSV) use a comma (`,`) or a semicolon (`;`) as\ndelimiter:\n\nAnother common separator is `\"\\t\"`, the tabulation character. However, we are\nnot limited to a single character, any string will do. By default,\n`genfromtxt` assumes `delimiter=None`, meaning that the line is split along\nwhite spaces (including tabs) and that consecutive white spaces are considered\nas a single white space.\n\nAlternatively, we may be dealing with a fixed-width file, where columns are\ndefined as a given number of characters. In that case, we need to set\n`delimiter` to a single integer (if all the columns have the same size) or to\na sequence of integers (if columns can have different sizes):\n\nBy default, when a line is decomposed into a series of strings, the individual\nentries are not stripped of leading nor trailing white spaces. This behavior\ncan be overwritten by setting the optional argument `autostrip` to a value of\n`True`:\n\nThe optional argument `comments` is used to define a character string that\nmarks the beginning of a comment. By default, `genfromtxt` assumes\n`comments='#'`. The comment marker may occur anywhere on the line. Any\ncharacter present after the comment marker(s) is simply ignored:\n\nNew in version 1.7.0: When `comments` is set to `None`, no lines are treated\nas comments.\n\nNote\n\nThere is one notable exception to this behavior: if the optional argument\n`names=True`, the first commented line will be examined for names.\n\nThe presence of a header in the file can hinder data processing. In that case,\nwe need to use the `skip_header` optional argument. The values of this\nargument must be an integer which corresponds to the number of lines to skip\nat the beginning of the file, before any other action is performed. Similarly,\nwe can skip the last `n` lines of the file by using the `skip_footer`\nattribute and giving it a value of `n`:\n\nBy default, `skip_header=0` and `skip_footer=0`, meaning that no lines are\nskipped.\n\nIn some cases, we are not interested in all the columns of the data but only a\nfew of them. We can select which columns to import with the `usecols`\nargument. This argument accepts a single integer or a sequence of integers\ncorresponding to the indices of the columns to import. Remember that by\nconvention, the first column has an index of 0. Negative integers behave the\nsame as regular Python negative indexes.\n\nFor example, if we want to import only the first and the last columns, we can\nuse `usecols=(0, -1)`:\n\nIf the columns have names, we can also select which columns to import by\ngiving their name to the `usecols` argument, either as a sequence of strings\nor a comma-separated string:\n\nThe main way to control how the sequences of strings we have read from the\nfile are converted to other types is to set the `dtype` argument. Acceptable\nvalues for this argument are:\n\nIn all the cases but the first one, the output will be a 1D array with a\nstructured dtype. This dtype has as many fields as items in the sequence. The\nfield names are defined with the `names` keyword.\n\nWhen `dtype=None`, the type of each column is determined iteratively from its\ndata. We start by checking whether a string can be converted to a boolean\n(that is, if the string matches `true` or `false` in lower cases); then\nwhether it can be converted to an integer, then to a float, then to a complex\nand eventually to a string. This behavior may be changed by modifying the\ndefault mapper of the `StringConverter` class.\n\nThe option `dtype=None` is provided for convenience. However, it is\nsignificantly slower than setting the dtype explicitly.\n\nA natural approach when dealing with tabular data is to allocate a name to\neach column. A first possibility is to use an explicit structured dtype, as\nmentioned previously:\n\nAnother simpler possibility is to use the `names` keyword with a sequence of\nstrings or a comma-separated string:\n\nIn the example above, we used the fact that by default, `dtype=float`. By\ngiving a sequence of names, we are forcing the output to a structured dtype.\n\nWe may sometimes need to define the column names from the data itself. In that\ncase, we must use the `names` keyword with a value of `True`. The names will\nthen be read from the first line (after the `skip_header` ones), even if the\nline is commented out:\n\nThe default value of `names` is `None`. If we give any other value to the\nkeyword, the new names will overwrite the field names we may have defined with\nthe dtype:\n\nIf `names=None` but a structured dtype is expected, names are defined with the\nstandard NumPy default of `\"f%i\"`, yielding names like `f0`, `f1` and so\nforth:\n\nIn the same way, if we don\u2019t give enough names to match the length of the\ndtype, the missing names will be defined with this default template:\n\nWe can overwrite this default with the `defaultfmt` argument, that takes any\nformat string:\n\nNote\n\nWe need to keep in mind that `defaultfmt` is used only if some names are\nexpected but not defined.\n\nNumPy arrays with a structured dtype can also be viewed as `recarray`, where a\nfield can be accessed as if it were an attribute. For that reason, we may need\nto make sure that the field name doesn\u2019t contain any space or invalid\ncharacter, or that it does not correspond to the name of a standard attribute\n(like `size` or `shape`), which would confuse the interpreter. `genfromtxt`\naccepts three optional arguments that provide a finer control on the names:\n\nGives a string combining all the characters that must be deleted from the\nname. By default, invalid characters are `~!@#$%^&*()-=+~\\|]}[{';: /?.>,<`.\n\nGives a list of the names to exclude, such as `return`, `file`, `print`\u2026 If\none of the input name is part of this list, an underscore character (`'_'`)\nwill be appended to it.\n\nWhether the names should be case-sensitive (`case_sensitive=True`), converted\nto upper case (`case_sensitive=False` or `case_sensitive='upper'`) or to lower\ncase (`case_sensitive='lower'`).\n\nUsually, defining a dtype is sufficient to define how the sequence of strings\nmust be converted. However, some additional control may sometimes be required.\nFor example, we may want to make sure that a date in a format `YYYY/MM/DD` is\nconverted to a `datetime` object, or that a string like `xx%` is properly\nconverted to a float between 0 and 1. In such cases, we should define\nconversion functions with the `converters` arguments.\n\nThe value of this argument is typically a dictionary with column indices or\ncolumn names as keys and a conversion functions as values. These conversion\nfunctions can either be actual functions or lambda functions. In any case,\nthey should accept only a string as input and output only a single element of\nthe wanted type.\n\nIn the following example, the second column is converted from as string\nrepresenting a percentage to a float between 0 and 1:\n\nWe need to keep in mind that by default, `dtype=float`. A float is therefore\nexpected for the second column. However, the strings `' 2.3%'` and `' 78.9%'`\ncannot be converted to float and we end up having `np.nan` instead. Let\u2019s now\nuse a converter:\n\nThe same results can be obtained by using the name of the second column\n(`\"p\"`) as key instead of its index (1):\n\nConverters can also be used to provide a default for missing entries. In the\nfollowing example, the converter `convert` transforms a stripped string into\nthe corresponding float or into -999 if the string is empty. We need to\nexplicitly strip the string from white spaces as it is not done by default:\n\nSome entries may be missing in the dataset we are trying to import. In a\nprevious example, we used a converter to transform an empty string into a\nfloat. However, user-defined converters may rapidly become cumbersome to\nmanage.\n\nThe `genfromtxt` function provides two other complementary mechanisms: the\n`missing_values` argument is used to recognize missing data and a second\nargument, `filling_values`, is used to process these missing data.\n\nBy default, any empty string is marked as missing. We can also consider more\ncomplex strings, such as `\"N/A\"` or `\"???\"` to represent missing or invalid\ndata. The `missing_values` argument accepts three kinds of values:\n\nThis string will be used as the marker for missing data for all the columns\n\nIn that case, each item is associated to a column, in order.\n\nValues of the dictionary are strings or sequence of strings. The corresponding\nkeys can be column indices (integers) or column names (strings). In addition,\nthe special key `None` can be used to define a default applicable to all\ncolumns.\n\nWe know how to recognize missing data, but we still need to provide a value\nfor these missing entries. By default, this value is determined from the\nexpected dtype according to this table:\n\nExpected type\n\nDefault\n\n`bool`\n\n`False`\n\n`int`\n\n`-1`\n\n`float`\n\n`np.nan`\n\n`complex`\n\n`np.nan+0j`\n\n`string`\n\n`'???'`\n\nWe can get a finer control on the conversion of missing values with the\n`filling_values` optional argument. Like `missing_values`, this argument\naccepts different kind of values:\n\nThis will be the default for all columns\n\nEach entry will be the default for the corresponding column\n\nEach key can be a column index or a column name, and the corresponding value\nshould be a single object. We can use the special key `None` to define a\ndefault for all columns.\n\nIn the following example, we suppose that the missing values are flagged with\n`\"N/A\"` in the first column and by `\"???\"` in the third column. We wish to\ntransform these missing values to 0 if they occur in the first and second\ncolumn, and to -999 if they occur in the last column:\n\nWe may also want to keep track of the occurrence of missing data by\nconstructing a boolean mask, with `True` entries where data was missing and\n`False` otherwise. To do that, we just have to set the optional argument\n`usemask` to `True` (the default is `False`). The output array will then be a\n`MaskedArray`.\n\nIn addition to `genfromtxt`, the `numpy.lib.npyio` module provides several\nconvenience functions derived from `genfromtxt`. These functions work the same\nway as the original, but they have different default values.\n\nReturns a standard `numpy.recarray` (if `usemask=False`) or a `MaskedRecords`\narray (if `usemaske=True`). The default dtype is `dtype=None`, meaning that\nthe types of each column will be automatically determined.\n\nLike `recfromtxt`, but with a default `delimiter=\",\"`.\n\n"}, {"name": "Development workflow", "path": "dev/development_workflow", "type": "Development", "text": "\nYou already have your own forked copy of the NumPy repository, by following\nCreate a NumPy fork, Make the local copy, you have configured git by following\nGit configuration, and have linked the upstream repository as explained in\nLinking your repository to the upstream repo.\n\nWhat is described below is a recommended workflow with Git.\n\nIn short:\n\nWhen finished:\n\nThis way of working helps to keep work well organized and the history as clear\nas possible.\n\nSee also\n\nThere are many online tutorials to help you learn git. For discussions of\nspecific git workflows, see these discussions on linux git workflow, and\nipython git workflow.\n\nFirst, fetch new commits from the `upstream` repository:\n\nThen, create a new branch based on the main branch of the upstream repository:\n\nOptional: Check which files have changed with `git status` (see git status).\nYou\u2019ll see a listing like this one:\n\nTo commit the staged files into the local copy of your repo, do `git commit`.\nAt this point, a text editor will open up to allow you to write a commit\nmessage. Read the commit message section to be sure that you are writing a\nproperly formatted and sufficiently detailed commit message. After saving your\nmessage and closing the editor, your commit will be saved. For trivial\ncommits, a short commit message can be passed in through the command line\nusing the `-m` flag. For example, `git commit -am \"ENH: Some message\"`.\n\nIn some cases, you will see this form of the commit command: `git commit -a`.\nThe extra `-a` flag automatically commits all modified files and removes all\ndeleted files. This can save you some typing of numerous `git add` commands;\nhowever, it can add unwanted changes to a commit if you\u2019re not careful. For\nmore information, see why the -a flag? \\- and the helpful use-case description\nin the tangled working copy problem.\n\nPush the changes to your forked repo on github:\n\nFor more information, see git push.\n\nNote\n\nAssuming you have followed the instructions in these pages, git will create a\ndefault link to your github repo called `origin`. In git >= 1.7 you can ensure\nthat the link to origin is permanently set by using the `--set-upstream`\noption:\n\nFrom now on git will know that `my-new-feature` is related to the `my-new-\nfeature` branch in your own github repo. Subsequent push calls are then\nsimplified to the following:\n\nYou have to use `--set-upstream` for each new branch that you create.\n\nIt may be the case that while you were working on your edits, new commits have\nbeen added to `upstream` that affect your work. In this case, follow the\nRebasing on main section of this document to apply those changes to your\nbranch.\n\nCommit messages should be clear and follow a few basic rules. Example:\n\nDescribing the motivation for a change, the nature of a bug for bug fixes or\nsome details on what an enhancement does are also good to include in a commit\nmessage. Messages should be understandable without looking at the code\nchanges. A commit message like `MAINT: fixed another one` is an example of\nwhat not to do; the reader has to go look for context elsewhere.\n\nStandard acronyms to start the commit message with are:\n\nIf you plan a new feature or API change, it\u2019s wisest to first email the NumPy\nmailing list asking for comment. If you haven\u2019t heard back in a week, it\u2019s OK\nto ping the list again.\n\nWhen you feel your work is finished, you can create a pull request (PR).\nGithub has a nice help page that outlines the process for filing pull\nrequests.\n\nIf your changes involve modifications to the API or addition/modification of a\nfunction, add a release note to the `doc/release/upcoming_changes/` directory,\nfollowing the instructions and format in the\n`doc/release/upcoming_changes/README.rst` file.\n\nWe review pull requests as soon as we can, typically within a week. If you get\nno review comments within two weeks, feel free to ask for feedback by adding a\ncomment on your PR (this will notify maintainers).\n\nIf your PR is large or complicated, asking for input on the numpy-discussion\nmailing list may also be useful.\n\nThis updates your feature branch with changes from the upstream NumPy github\nrepo. If you do not absolutely need to do this, try to avoid doing it, except\nperhaps when you are finished. The first step will be to update the remote\nrepository with new commits from upstream:\n\nNext, you need to update the feature branch:\n\nIf you have made changes to files that have changed also upstream, this may\ngenerate merge conflicts that you need to resolve. See below for help in this\ncase.\n\nFinally, remove the backup branch upon a successful rebase:\n\nNote\n\nRebasing on main is preferred over merging upstream back to your branch. Using\n`git merge` and `git pull` is discouraged when working on feature branches.\n\nSometimes, you mess up merges or rebases. Luckily, in Git it is relatively\nstraightforward to recover from such mistakes.\n\nIf you mess up during a rebase:\n\nIf you notice you messed up after the rebase:\n\nIf you forgot to make a backup branch:\n\nIf you didn\u2019t actually mess up but there are merge conflicts, you need to\nresolve those. This can be one of the trickier things to get right. For a good\ndescription of how to do this, see this article on merging conflicts.\n\nNote\n\nDo this only for your own feature branches.\n\nThere\u2019s an embarrassing typo in a commit you made? Or perhaps you made several\nfalse starts you would like the posterity not to see.\n\nThis can be done via interactive rebasing.\n\nSuppose that the commit history looks like this:\n\nand `6ad92e5` is the last commit in the `main` branch. Suppose we want to make\nthe following changes:\n\nWe do as follows:\n\nThis will open an editor with the following text in it:\n\nTo achieve what we want, we will make the following changes to it:\n\nThis means that (i) we want to edit the commit message for `13d7934`, and (ii)\ncollapse the last three commits into one. Now we save and quit the editor.\n\nGit will then immediately bring up an editor for editing the commit message.\nAfter revising it, we get the output:\n\nand the history looks now like this:\n\nIf it went wrong, recovery is again possible as explained above.\n\nSee also: https://stackoverflow.com/questions/2003505/how-do-i-delete-a-git-\nbranch-locally-and-remotely\n\nIf you want to work on some stuff with other people, where you are all\ncommitting into the same repository, or even the same branch, then just share\nit via github.\n\nFirst fork NumPy into your account, as from Create a NumPy fork.\n\nThen, go to your forked repository github page, say `https://github.com/your-\nuser-name/numpy`\n\nClick on the \u2018Admin\u2019 button, and add anyone else to the repo as a\ncollaborator:\n\nNow all those people can do:\n\nRemember that links starting with `git@` use the ssh protocol and are read-\nwrite; links starting with `git://` are read-only.\n\nYour collaborators can then commit directly into that repo with the usual:\n\nTo see a graphical representation of the repository branches and commits:\n\nTo see a linear list of commits for this branch:\n\nYou can also look at the network graph visualizer for your github repo.\n\nBackporting is the process of copying new feature/fixes committed in\nnumpy/main back to stable release branches. To do this you make a branch off\nthe branch you are backporting to, cherry pick the commits you want from\n`numpy/main`, and then submit a pull request for the branch containing the\nbackport.\n\nFirst, you need to make the branch you will work on. This needs to be based on\nthe older version of NumPy (not main):\n\nNow you need to apply the changes from main to this branch using git cherry-\npick:\n\nPush the new branch to your Github repository:\n\nRequires commit rights to the main NumPy repo.\n\nWhen you have a set of \u201cready\u201d changes in a feature branch ready for NumPy\u2019s\n`main` or `maintenance` branches, you can push them to `upstream` as follows:\n\nFirst, merge or rebase on the target branch.\n\nOnly a few, unrelated commits then prefer rebasing:\n\nSee Rebasing on main.\n\nIf all of the commits are related, create a merge commit:\n\nCheck that what you are going to push looks sensible:\n\nPush to upstream:\n\nNote\n\nIt\u2019s usually a good idea to use the `-n` flag to `git push` to check first\nthat you\u2019re about to push the changes you want to the place you want.\n\n"}, {"name": "distutils.ccompiler.CCompiler_compile()", "path": "reference/generated/numpy.distutils.ccompiler.ccompiler_compile", "type": "numpy.distutils.ccompiler.CCompiler_compile", "text": "\nCompile one or more source files.\n\nPlease refer to the Python distutils API reference for more details.\n\nA list of filenames\n\nPath to the output directory.\n\nA list of macro definitions.\n\nThe directories to add to the default include file search path for this\ncompilation only.\n\nWhether or not to output debug symbols in or alongside the object file(s).\n\nExtra pre- and post-arguments.\n\nA list of file names that all targets depend on.\n\nA list of object file names, one per source file `sources`.\n\nIf compilation fails.\n\n"}, {"name": "distutils.ccompiler.CCompiler_customize()", "path": "reference/generated/numpy.distutils.ccompiler.ccompiler_customize", "type": "numpy.distutils.ccompiler.CCompiler_customize", "text": "\nDo any platform-specific customization of a compiler instance.\n\nThis method calls `distutils.sysconfig.customize_compiler` for platform-\nspecific customization, as well as optionally remove a flag to suppress\nspurious warnings in case C++ code is being compiled.\n\nThis parameter is not used for anything.\n\nWhether or not C++ has to be compiled. If so (True), the `\"-Wstrict-\nprototypes\"` option is removed to prevent spurious warnings. Default is False.\n\nAll the default options used by distutils can be extracted with:\n\n"}, {"name": "distutils.ccompiler.CCompiler_customize_cmd()", "path": "reference/generated/numpy.distutils.ccompiler.ccompiler_customize_cmd", "type": "numpy.distutils.ccompiler.CCompiler_customize_cmd", "text": "\nCustomize compiler using distutils command.\n\nAn instance inheriting from `distutils.cmd.Command`.\n\nList of `CCompiler` commands (without `'set_'`) that should not be altered.\nStrings that are checked for are: `('include_dirs', 'define', 'undef',\n'libraries', 'library_dirs', 'rpath', 'link_objects')`.\n\n"}, {"name": "distutils.ccompiler.CCompiler_cxx_compiler()", "path": "reference/generated/numpy.distutils.ccompiler.ccompiler_cxx_compiler", "type": "numpy.distutils.ccompiler.CCompiler_cxx_compiler", "text": "\nReturn the C++ compiler.\n\nThe C++ compiler, as a `CCompiler` instance.\n\n"}, {"name": "distutils.ccompiler.CCompiler_find_executables()", "path": "reference/generated/numpy.distutils.ccompiler.ccompiler_find_executables", "type": "numpy.distutils.ccompiler.CCompiler_find_executables", "text": "\nDoes nothing here, but is called by the get_version method and can be\noverridden by subclasses. In particular it is redefined in the `FCompiler`\nclass where more documentation can be found.\n\n"}, {"name": "distutils.ccompiler.CCompiler_get_version()", "path": "reference/generated/numpy.distutils.ccompiler.ccompiler_get_version", "type": "numpy.distutils.ccompiler.CCompiler_get_version", "text": "\nReturn compiler version, or None if compiler is not available.\n\nIf True, force a new determination of the version, even if the compiler\nalready has a version attribute. Default is False.\n\nThe list of status values returned by the version look-up process for which a\nversion string is returned. If the status value is not in `ok_status`, None is\nreturned. Default is `[0]`.\n\nVersion string, in the format of `distutils.version.LooseVersion`.\n\n"}, {"name": "distutils.ccompiler.CCompiler_object_filenames()", "path": "reference/generated/numpy.distutils.ccompiler.ccompiler_object_filenames", "type": "numpy.distutils.ccompiler.CCompiler_object_filenames", "text": "\nReturn the name of the object files for the given source files.\n\nThe list of paths to source files. Paths can be either relative or absolute,\nthis is handled transparently.\n\nWhether to strip the directory from the returned paths. If True, the file name\nprepended by `output_dir` is returned. Default is False.\n\nIf given, this path is prepended to the returned paths to the object files.\n\nThe list of paths to the object files corresponding to the source files in\n`source_filenames`.\n\n"}, {"name": "distutils.ccompiler.CCompiler_show_customization()", "path": "reference/generated/numpy.distutils.ccompiler.ccompiler_show_customization", "type": "numpy.distutils.ccompiler.CCompiler_show_customization", "text": "\nPrint the compiler customizations to stdout.\n\nPrinting is only done if the distutils log threshold is < 2.\n\n"}, {"name": "distutils.ccompiler.CCompiler_spawn()", "path": "reference/generated/numpy.distutils.ccompiler.ccompiler_spawn", "type": "numpy.distutils.ccompiler.CCompiler_spawn", "text": "\nExecute a command in a sub-process.\n\nThe command to execute.\n\nThe text to add to the log file kept by `numpy.distutils`. If not given,\n`display` is equal to `cmd`.\n\nIf the command failed, i.e. the exit status was not 0.\n\n"}, {"name": "distutils.ccompiler.gen_lib_options()", "path": "reference/generated/numpy.distutils.ccompiler.gen_lib_options", "type": "numpy.distutils.ccompiler.gen_lib_options", "text": "\n\n"}, {"name": "distutils.ccompiler.new_compiler()", "path": "reference/generated/numpy.distutils.ccompiler.new_compiler", "type": "numpy.distutils.ccompiler.new_compiler", "text": "\n\n"}, {"name": "distutils.ccompiler.replace_method()", "path": "reference/generated/numpy.distutils.ccompiler.replace_method", "type": "numpy.distutils.ccompiler.replace_method", "text": "\n\n"}, {"name": "distutils.ccompiler.simple_version_match()", "path": "reference/generated/numpy.distutils.ccompiler.simple_version_match", "type": "numpy.distutils.ccompiler.simple_version_match", "text": "\nSimple matching of version numbers, for use in CCompiler and FCompiler.\n\nA regular expression matching version numbers. Default is `r'[-.\\d]+'`.\n\nA regular expression matching patterns to skip. Default is `''`, in which case\nnothing is skipped.\n\nA regular expression matching the start of where to start looking for version\nnumbers. Default is `''`, in which case searching is started at the beginning\nof the version string given to `matcher`.\n\nA function that is appropriate to use as the `.version_match` attribute of a\n`CCompiler` class. `matcher` takes a single parameter, a version string.\n\n"}, {"name": "distutils.ccompiler_opt.CCompilerOpt.cache_flush()", "path": "reference/generated/numpy.distutils.ccompiler_opt.ccompileropt.cache_flush", "type": "numpy.distutils.ccompiler_opt.CCompilerOpt.cache_flush", "text": "\nmethod\n\nForce update the cache.\n\n"}, {"name": "distutils.ccompiler_opt.CCompilerOpt.cc_normalize_flags()", "path": "reference/generated/numpy.distutils.ccompiler_opt.ccompileropt.cc_normalize_flags", "type": "numpy.distutils.ccompiler_opt.CCompilerOpt.cc_normalize_flags", "text": "\nmethod\n\nRemove the conflicts that caused due gathering implied features flags.\n\nflags should be sorted from the lowest to the highest interest.\n\n"}, {"name": "distutils.ccompiler_opt.CCompilerOpt.conf_features", "path": "reference/generated/numpy.distutils.ccompiler_opt.ccompileropt.conf_features", "type": "NumPy.distutils.ccompiler_opt.ccompileropt.conf_features", "text": "\nattribute\n\n"}, {"name": "distutils.ccompiler_opt.CCompilerOpt.conf_features_partial()", "path": "reference/generated/numpy.distutils.ccompiler_opt.ccompileropt.conf_features_partial", "type": "numpy.distutils.ccompiler_opt.CCompilerOpt.conf_features_partial", "text": "\nmethod\n\nReturn a dictionary of supported CPU features by the platform, and accumulate\nthe rest of undefined options in `conf_features`, the returned dict has same\nrules and notes in class attribute `conf_features`, also its override any\noptions that been set in \u2018conf_features\u2019.\n\n"}, {"name": "distutils.ccompiler_opt.CCompilerOpt.cpu_baseline_flags()", "path": "reference/generated/numpy.distutils.ccompiler_opt.ccompileropt.cpu_baseline_flags", "type": "numpy.distutils.ccompiler_opt.CCompilerOpt.cpu_baseline_flags", "text": "\nmethod\n\nReturns a list of final CPU baseline compiler flags\n\n"}, {"name": "distutils.ccompiler_opt.CCompilerOpt.cpu_baseline_names()", "path": "reference/generated/numpy.distutils.ccompiler_opt.ccompileropt.cpu_baseline_names", "type": "numpy.distutils.ccompiler_opt.CCompilerOpt.cpu_baseline_names", "text": "\nmethod\n\nreturn a list of final CPU baseline feature names\n\n"}, {"name": "distutils.ccompiler_opt.CCompilerOpt.cpu_dispatch_names()", "path": "reference/generated/numpy.distutils.ccompiler_opt.ccompileropt.cpu_dispatch_names", "type": "numpy.distutils.ccompiler_opt.CCompilerOpt.cpu_dispatch_names", "text": "\nmethod\n\nreturn a list of final CPU dispatch feature names\n\n"}, {"name": "distutils.ccompiler_opt.CCompilerOpt.dist_compile()", "path": "reference/generated/numpy.distutils.ccompiler_opt.ccompileropt.dist_compile", "type": "numpy.distutils.ccompiler_opt.CCompilerOpt.dist_compile", "text": "\nmethod\n\nWrap CCompiler.compile()\n\n"}, {"name": "distutils.ccompiler_opt.CCompilerOpt.dist_info()", "path": "reference/generated/numpy.distutils.ccompiler_opt.ccompileropt.dist_info", "type": "numpy.distutils.ccompiler_opt.CCompilerOpt.dist_info", "text": "\nmethod\n\nReturn a tuple containing info about (platform, compiler, extra_args),\nrequired by the abstract class \u2018_CCompiler\u2019 for discovering the platform\nenvironment. This is also used as a cache factor in order to detect any\nchanges happening from outside.\n\n"}, {"name": "distutils.ccompiler_opt.CCompilerOpt.dist_test()", "path": "reference/generated/numpy.distutils.ccompiler_opt.ccompileropt.dist_test", "type": "numpy.distutils.ccompiler_opt.CCompilerOpt.dist_test", "text": "\nmethod\n\nReturn True if \u2018CCompiler.compile()\u2019 able to compile a source file with\ncertain flags.\n\n"}, {"name": "distutils.ccompiler_opt.CCompilerOpt.feature_ahead()", "path": "reference/generated/numpy.distutils.ccompiler_opt.ccompileropt.feature_ahead", "type": "numpy.distutils.ccompiler_opt.CCompilerOpt.feature_ahead", "text": "\nmethod\n\nReturn list of features in \u2018names\u2019 after remove any implied features and keep\nthe origins.\n\nsequence of CPU feature names in uppercase.\n\n"}, {"name": "distutils.ccompiler_opt.CCompilerOpt.feature_c_preprocessor()", "path": "reference/generated/numpy.distutils.ccompiler_opt.ccompileropt.feature_c_preprocessor", "type": "numpy.distutils.ccompiler_opt.CCompilerOpt.feature_c_preprocessor", "text": "\nmethod\n\nGenerate C preprocessor definitions and include headers of a CPU feature.\n\nCPU feature name in uppercase.\n\nif > 0, align the generated strings to the right depend on number of tabs.\n\n"}, {"name": "distutils.ccompiler_opt.CCompilerOpt.feature_detect()", "path": "reference/generated/numpy.distutils.ccompiler_opt.ccompileropt.feature_detect", "type": "numpy.distutils.ccompiler_opt.CCompilerOpt.feature_detect", "text": "\nmethod\n\nReturn a list of CPU features that required to be detected sorted from the\nlowest to highest interest.\n\n"}, {"name": "distutils.ccompiler_opt.CCompilerOpt.feature_get_til()", "path": "reference/generated/numpy.distutils.ccompiler_opt.ccompileropt.feature_get_til", "type": "numpy.distutils.ccompiler_opt.CCompilerOpt.feature_get_til", "text": "\nmethod\n\nsame as `feature_implies_c()` but stop collecting implied features when\nfeature\u2019s option that provided through parameter \u2018keyisfalse\u2019 is False, also\nsorting the returned features.\n\n"}, {"name": "distutils.ccompiler_opt.CCompilerOpt.feature_implies()", "path": "reference/generated/numpy.distutils.ccompiler_opt.ccompileropt.feature_implies", "type": "numpy.distutils.ccompiler_opt.CCompilerOpt.feature_implies", "text": "\nmethod\n\nReturn a set of CPU features that implied by \u2018names\u2019\n\nCPU feature name(s) in uppercase.\n\nif False(default) then the returned set will not contain any features from\n\u2018names\u2019. This case happens only when two features imply each other.\n\n"}, {"name": "distutils.ccompiler_opt.CCompilerOpt.feature_implies_c()", "path": "reference/generated/numpy.distutils.ccompiler_opt.ccompileropt.feature_implies_c", "type": "numpy.distutils.ccompiler_opt.CCompilerOpt.feature_implies_c", "text": "\nmethod\n\nsame as feature_implies() but combining \u2018names\u2019\n\n"}, {"name": "distutils.ccompiler_opt.CCompilerOpt.feature_is_exist()", "path": "reference/generated/numpy.distutils.ccompiler_opt.ccompileropt.feature_is_exist", "type": "numpy.distutils.ccompiler_opt.CCompilerOpt.feature_is_exist", "text": "\nmethod\n\nReturns True if a certain feature is exist and covered within\n`_Config.conf_features`.\n\nfeature name in uppercase.\n\n"}, {"name": "distutils.ccompiler_opt.CCompilerOpt.feature_names()", "path": "reference/generated/numpy.distutils.ccompiler_opt.ccompileropt.feature_names", "type": "numpy.distutils.ccompiler_opt.CCompilerOpt.feature_names", "text": "\nmethod\n\nReturns a set of CPU feature names that supported by platform and the C\ncompiler.\n\nSpecify certain CPU features to test it against the C compiler. if\nNone(default), it will test all current supported features. Note: feature\nnames must be in upper-case.\n\nIf None(default), default compiler flags for every CPU feature will be used\nduring the test.\n\nA list of C macro definitions.\n\n"}, {"name": "distutils.ccompiler_opt.CCompilerOpt.feature_sorted()", "path": "reference/generated/numpy.distutils.ccompiler_opt.ccompileropt.feature_sorted", "type": "numpy.distutils.ccompiler_opt.CCompilerOpt.feature_sorted", "text": "\nmethod\n\nSort a list of CPU features ordered by the lowest interest.\n\nsequence of supported feature names in uppercase.\n\nIf true, the sorted features is reversed. (highest interest)\n\n"}, {"name": "distutils.ccompiler_opt.CCompilerOpt.feature_untied()", "path": "reference/generated/numpy.distutils.ccompiler_opt.ccompileropt.feature_untied", "type": "numpy.distutils.ccompiler_opt.CCompilerOpt.feature_untied", "text": "\nmethod\n\nsame as \u2018feature_ahead()\u2019 but if both features implied each other and keep the\nhighest interest.\n\nsequence of CPU feature names in uppercase.\n\n"}, {"name": "distutils.ccompiler_opt.CCompilerOpt.generate_dispatch_header()", "path": "reference/generated/numpy.distutils.ccompiler_opt.ccompileropt.generate_dispatch_header", "type": "numpy.distutils.ccompiler_opt.CCompilerOpt.generate_dispatch_header", "text": "\nmethod\n\nGenerate the dispatch header which contains the #definitions and headers for\nplatform-specific instruction-sets for the enabled CPU baseline and dispatch-\nable features.\n\nIts highly recommended to take a look at the generated header also the\ngenerated source files via `try_dispatch()` in order to get the full picture.\n\n"}, {"name": "distutils.ccompiler_opt.CCompilerOpt.is_cached()", "path": "reference/generated/numpy.distutils.ccompiler_opt.ccompileropt.is_cached", "type": "numpy.distutils.ccompiler_opt.CCompilerOpt.is_cached", "text": "\nmethod\n\nReturns True if the class loaded from the cache file\n\n"}, {"name": "distutils.ccompiler_opt.CCompilerOpt.parse_targets()", "path": "reference/generated/numpy.distutils.ccompiler_opt.ccompileropt.parse_targets", "type": "numpy.distutils.ccompiler_opt.CCompilerOpt.parse_targets", "text": "\nmethod\n\nFetch and parse configuration statements that required for defining the\ntargeted CPU features, statements should be declared in the top of source in\nbetween C comment and start with a special mark @targets.\n\nConfiguration statements are sort of keywords representing CPU features names,\ngroup of statements and policies, combined together to determine the required\noptimization.\n\nthe path of C source file.\n\n"}, {"name": "distutils.ccompiler_opt.CCompilerOpt.try_dispatch()", "path": "reference/generated/numpy.distutils.ccompiler_opt.ccompileropt.try_dispatch", "type": "numpy.distutils.ccompiler_opt.CCompilerOpt.try_dispatch", "text": "\nmethod\n\nCompile one or more dispatch-able sources and generates object files, also\ngenerates abstract C config headers and macros that used later for the final\nruntime dispatching process.\n\nThe mechanism behind it is to takes each source file that specified in\n\u2018sources\u2019 and branching it into several files depend on special configuration\nstatements that must be declared in the top of each source which contains\ntargeted CPU features, then it compiles every branched source with the proper\ncompiler flags.\n\nMust be a list of dispatch-able sources file paths, and configuration\nstatements must be declared inside each file.\n\nPath of parent directory for the generated headers and wrapped sources. If\nNone(default) the files will generated in-place.\n\nDistutils `CCompiler` instance to be used for compilation. If None (default),\nthe provided instance during the initialization will be used instead.\n\nArguments to pass on to the `CCompiler.compile()`\n\nRaises by `CCompiler.compile()` on compiling failure.\n\nSome errors during checking the sanity of configuration statements.\n\nSee also\n\nParsing the configuration statements of dispatch-able sources.\n\n"}, {"name": "distutils.ccompiler_opt.new_ccompiler_opt()", "path": "reference/generated/numpy.distutils.ccompiler_opt.new_ccompiler_opt", "type": "numpy.distutils.ccompiler_opt.new_ccompiler_opt", "text": "\nCreate a new instance of \u2018CCompilerOpt\u2019 and generate the dispatch header which\ncontains the #definitions and headers of platform-specific instruction-sets\nfor the enabled CPU baseline and dispatch-able features.\n\npath of the dispatch header\n\n"}, {"name": "distutils.cpuinfo.cpu", "path": "reference/generated/numpy.distutils.cpuinfo.cpu", "type": "numpy.distutils.cpuinfo.cpu", "text": "\n\n"}, {"name": "distutils.exec_command.exec_command()", "path": "reference/generated/numpy.distutils.exec_command.exec_command", "type": "numpy.distutils.exec_command.exec_command", "text": "\nReturn (status,output) of executed command.\n\nDeprecated since version 1.17: Use subprocess.Popen instead\n\nA concatenated string of executable and arguments.\n\nBefore running command `cd execute_in` and after `cd -`.\n\nIf True, execute `sh -c command`. Default None (True)\n\nIf True use tee. Default None (True)\n\nBoth stdout and stderr messages.\n\nOn NT, DOS systems the returned status is correct for external commands. Wild\ncards will not work for non-posix systems or when use_shell=0.\n\n"}, {"name": "distutils.exec_command.filepath_from_subprocess_output()", "path": "reference/generated/numpy.distutils.exec_command.filepath_from_subprocess_output", "type": "numpy.distutils.exec_command.filepath_from_subprocess_output", "text": "\nConvert `bytes` in the encoding used by a subprocess into a filesystem-\nappropriate `str`.\n\nInherited from `exec_command`, and possibly incorrect.\n\n"}, {"name": "distutils.exec_command.find_executable()", "path": "reference/generated/numpy.distutils.exec_command.find_executable", "type": "numpy.distutils.exec_command.find_executable", "text": "\nReturn full path of a executable or None.\n\nSymbolic links are not followed.\n\n"}, {"name": "distutils.exec_command.forward_bytes_to_stdout()", "path": "reference/generated/numpy.distutils.exec_command.forward_bytes_to_stdout", "type": "numpy.distutils.exec_command.forward_bytes_to_stdout", "text": "\nForward bytes from a subprocess call to the console, without attempting to\ndecode them.\n\nThe assumption is that the subprocess call already returned bytes in a\nsuitable encoding.\n\n"}, {"name": "distutils.exec_command.get_pythonexe()", "path": "reference/generated/numpy.distutils.exec_command.get_pythonexe", "type": "numpy.distutils.exec_command.get_pythonexe", "text": "\n\n"}, {"name": "distutils.exec_command.temp_file_name()", "path": "reference/generated/numpy.distutils.exec_command.temp_file_name", "type": "numpy.distutils.exec_command.temp_file_name", "text": "\n\n"}, {"name": "distutils.log.set_verbosity()", "path": "reference/generated/numpy.distutils.log.set_verbosity", "type": "numpy.distutils.log.set_verbosity", "text": "\n\n"}, {"name": "distutils.system_info.get_info()", "path": "reference/generated/numpy.distutils.system_info.get_info", "type": "numpy.distutils.system_info.get_info", "text": "\n0 - do nothing 1 - display warning message 2 - raise error\n\n"}, {"name": "distutils.system_info.get_standard_file()", "path": "reference/generated/numpy.distutils.system_info.get_standard_file", "type": "numpy.distutils.system_info.get_standard_file", "text": "\nReturns a list of files named \u2018fname\u2019 from 1) System-wide directory\n(directory-location of this module) 2) Users HOME directory\n(os.environ[\u2018HOME\u2019]) 3) Local directory\n\n"}, {"name": "double npy_half_to_double()", "path": "reference/c-api/coremath#c.npy_half_to_double", "type": "NumPy core libraries", "text": "\nConverts a half-precision float to a double-precision float.\n\n"}, {"name": "double npy_spacing()", "path": "reference/c-api/coremath#c.npy_spacing", "type": "NumPy core libraries", "text": "\nThis is a function equivalent to Fortran intrinsic. Return distance between x\nand next representable floating point value from x, e.g. spacing(1) == eps.\nspacing of nan and +/- inf return nan. Single and extended precisions are\navailable with suffix f and l.\n\nNew in version 1.4.0.\n\n"}, {"name": "double PyArray_GetPriority()", "path": "reference/c-api/array#c.PyArray_GetPriority", "type": "Array API", "text": "\nReturn the `__array_priority__` attribute (converted to a double) of obj or\ndef if no attribute of that name exists. Fast returns that avoid the attribute\nlookup are provided for objects of type `PyArray_Type`.\n\n"}, {"name": "double random_beta()", "path": "reference/random/c-api#c.random_beta", "type": "C API for random", "text": "\n\n"}, {"name": "double random_chisquare()", "path": "reference/random/c-api#c.random_chisquare", "type": "C API for random", "text": "\n\n"}, {"name": "double random_exponential()", "path": "reference/random/c-api#c.random_exponential", "type": "C API for random", "text": "\n\n"}, {"name": "double random_f()", "path": "reference/random/c-api#c.random_f", "type": "C API for random", "text": "\n\n"}, {"name": "double random_gamma()", "path": "reference/random/c-api#c.random_gamma", "type": "C API for random", "text": "\n\n"}, {"name": "double random_gumbel()", "path": "reference/random/c-api#c.random_gumbel", "type": "C API for random", "text": "\n\n"}, {"name": "double random_laplace()", "path": "reference/random/c-api#c.random_laplace", "type": "C API for random", "text": "\n\n"}, {"name": "double random_logistic()", "path": "reference/random/c-api#c.random_logistic", "type": "C API for random", "text": "\n\n"}, {"name": "double random_lognormal()", "path": "reference/random/c-api#c.random_lognormal", "type": "C API for random", "text": "\n\n"}, {"name": "double random_noncentral_chisquare()", "path": "reference/random/c-api#c.random_noncentral_chisquare", "type": "C API for random", "text": "\n\n"}, {"name": "double random_noncentral_f()", "path": "reference/random/c-api#c.random_noncentral_f", "type": "C API for random", "text": "\n\n"}, {"name": "double random_normal()", "path": "reference/random/c-api#c.random_normal", "type": "C API for random", "text": "\n\n"}, {"name": "double random_pareto()", "path": "reference/random/c-api#c.random_pareto", "type": "C API for random", "text": "\n\n"}, {"name": "double random_power()", "path": "reference/random/c-api#c.random_power", "type": "C API for random", "text": "\n\n"}, {"name": "double random_rayleigh()", "path": "reference/random/c-api#c.random_rayleigh", "type": "C API for random", "text": "\n\n"}, {"name": "double random_standard_cauchy()", "path": "reference/random/c-api#c.random_standard_cauchy", "type": "C API for random", "text": "\n\n"}, {"name": "double random_standard_exponential()", "path": "reference/random/c-api#c.random_standard_exponential", "type": "C API for random", "text": "\n\n"}, {"name": "double random_standard_gamma()", "path": "reference/random/c-api#c.random_standard_gamma", "type": "C API for random", "text": "\n\n"}, {"name": "double random_standard_normal()", "path": "reference/random/c-api#c.random_standard_normal", "type": "C API for random", "text": "\n\n"}, {"name": "double random_standard_t()", "path": "reference/random/c-api#c.random_standard_t", "type": "C API for random", "text": "\n\n"}, {"name": "double random_standard_uniform()", "path": "reference/random/c-api#c.random_standard_uniform", "type": "C API for random", "text": "\n\n"}, {"name": "double random_triangular()", "path": "reference/random/c-api#c.random_triangular", "type": "C API for random", "text": "\n\n"}, {"name": "double random_uniform()", "path": "reference/random/c-api#c.random_uniform", "type": "C API for random", "text": "\n\n"}, {"name": "double random_vonmises()", "path": "reference/random/c-api#c.random_vonmises", "type": "C API for random", "text": "\n\n"}, {"name": "double random_wald()", "path": "reference/random/c-api#c.random_wald", "type": "C API for random", "text": "\n\n"}, {"name": "double random_weibull()", "path": "reference/random/c-api#c.random_weibull", "type": "C API for random", "text": "\n\n"}, {"name": "DoxyLimbo()", "path": "dev/howto-docs#_CPPv4N9DoxyLimbo9DoxyLimboERK9DoxyLimboI2Tp1NE", "type": "Development", "text": "\nSet Default behavior for copy the limbo.\n\n"}, {"name": "dtype object", "path": "reference/arrays.dtypes", "type": "Data type objects ( \n      \n       dtype\n      \n      )", "text": "\nA data type object (an instance of `numpy.dtype` class) describes how the\nbytes in the fixed-size block of memory corresponding to an array item should\nbe interpreted. It describes the following aspects of the data:\n\nIf the data type is structured data type, an aggregate of other data types,\n(e.g., describing an array item consisting of an integer and a float),\n\nTo describe the type of scalar data, there are several built-in scalar types\nin NumPy for various precision of integers, floating-point numbers, etc. An\nitem extracted from an array, e.g., by indexing, will be a Python object whose\ntype is the scalar type associated with the data type of the array.\n\nNote that the scalar types are not `dtype` objects, even though they can be\nused in place of one whenever a data type specification is needed in NumPy.\n\nStructured data types are formed by creating a data type whose field contain\nother data types. Each field has a name by which it can be accessed. The\nparent data type should be of sufficient size to contain all its fields; the\nparent is nearly always based on the `void` type which allows an arbitrary\nitem size. Structured data types may also contain nested structured sub-array\ndata types in their fields.\n\nFinally, a data type can describe items that are themselves arrays of items of\nanother data type. These sub-arrays must, however, be of a fixed size.\n\nIf an array is created using a data-type describing a sub-array, the\ndimensions of the sub-array are appended to the shape of the array when the\narray is created. Sub-arrays in a field of a structured type behave\ndifferently, see Field access.\n\nSub-arrays always have a C-contiguous memory layout.\n\nA simple data type containing a 32-bit big-endian integer: (see Specifying and\nconstructing data types for details on construction)\n\nThe corresponding array scalar type is `int32`.\n\nA structured data type containing a 16-character string (in field \u2018name\u2019) and\na sub-array of two 64-bit floating-point number (in field \u2018grades\u2019):\n\nItems of an array of this data type are wrapped in an array scalar type that\nalso has two fields:\n\nWhenever a data-type is required in a NumPy function or method, either a\n`dtype` object or something that can be converted to one can be supplied. Such\nconversions are done by the `dtype` constructor:\n\n`dtype`(dtype[, align, copy])\n\nCreate a data type object.\n\nWhat can be converted to a data-type object is described below:\n\nUsed as-is.\n\nThe default data type: `float_`.\n\nThe 24 built-in array scalar type objects all convert to an associated data-\ntype object. This is true for their sub-classes as well.\n\nNote that not all data-type information can be supplied with a type-object:\nfor example, `flexible` data-types have a default itemsize of 0, and require\nan explicitly given size to be useful.\n\nThe generic hierarchical type objects convert to corresponding type objects\naccording to the associations:\n\n`number`, `inexact`, `floating`\n\n`float`\n\n`complexfloating`\n\n`cfloat`\n\n`integer`, `signedinteger`\n\n`int_`\n\n`unsignedinteger`\n\n`uint`\n\n`character`\n\n`string`\n\n`generic`, `flexible`\n\n`void`\n\nDeprecated since version 1.19: This conversion of generic scalar types is\ndeprecated. This is because it can be unexpected in a context such as\n`arr.astype(dtype=np.floating)`, which casts an array of `float32` to an array\nof `float64`, even though `float32` is a subdtype of `np.floating`.\n\nSeveral python types are equivalent to a corresponding array scalar when used\nto generate a `dtype` object:\n\n`int`\n\n`int_`\n\n`bool`\n\n`bool_`\n\n`float`\n\n`float_`\n\n`complex`\n\n`cfloat`\n\n`bytes`\n\n`bytes_`\n\n`str`\n\n`str_`\n\n`buffer`\n\n`void`\n\n(all others)\n\n`object_`\n\nNote that `str` refers to either null terminated bytes or unicode strings\ndepending on the Python version. In code targeting both Python 2 and 3\n`np.unicode_` should be used as a dtype for strings. See Note on string types.\n\nNote\n\nAll other types map to `object_` for convenience. Code should expect that such\ntypes may map to a specific (new) dtype in the future.\n\nAny type object with a `dtype` attribute: The attribute will be accessed and\nused directly. The attribute must return something that is convertible into a\ndtype object.\n\nSeveral kinds of strings can be converted. Recognized strings can be prepended\nwith `'>'` (big-endian), `'<'` (little-endian), or `'='` (hardware-native, the\ndefault), to specify the byte order.\n\nEach built-in data-type has a character code (the updated Numeric typecodes),\nthat uniquely identifies it.\n\nThe first character specifies the kind of data and the remaining characters\nspecify the number of bytes per item, except for Unicode, where it is\ninterpreted as the number of characters. The item size must correspond to an\nexisting type, or an error will be raised. The supported kinds are\n\n`'?'`\n\nboolean\n\n`'b'`\n\n(signed) byte\n\n`'B'`\n\nunsigned byte\n\n`'i'`\n\n(signed) integer\n\n`'u'`\n\nunsigned integer\n\n`'f'`\n\nfloating-point\n\n`'c'`\n\ncomplex-floating point\n\n`'m'`\n\ntimedelta\n\n`'M'`\n\ndatetime\n\n`'O'`\n\n(Python) objects\n\n`'S'`, `'a'`\n\nzero-terminated bytes (not recommended)\n\n`'U'`\n\nUnicode string\n\n`'V'`\n\nraw data (`void`)\n\nNote on string types\n\nFor backward compatibility with Python 2 the `S` and `a` typestrings remain\nzero-terminated bytes and `numpy.string_` continues to alias `numpy.bytes_`.\nTo use actual strings in Python 3 use `U` or `numpy.str_`. For signed bytes\nthat do not need zero-termination `b` or `i1` can be used.\n\nA short-hand notation for specifying the format of a structured data type is a\ncomma-separated string of basic formats.\n\nA basic format in this context is an optional shape specifier followed by an\narray-protocol type string. Parenthesis are required on the shape if it has\nmore than one dimension. NumPy allows a modification on the format in that any\nstring that can uniquely identify the type can be used to specify the data-\ntype in a field. The generated data-type fields are named `'f0'`, `'f1'`, \u2026,\n`'f<N-1>'` where N (>1) is the number of comma-separated basic formats in the\nstring. If the optional shape specifier is provided, then the data-type for\nthe corresponding field describes a sub-array.\n\nAny string in `numpy.sctypeDict`.keys():\n\nThe first argument must be an object that is converted to a zero-sized\nflexible data-type object, the second argument is an integer providing the\ndesired itemsize.\n\nThe first argument is any object that can be converted into a fixed-size data-\ntype object. The second argument is the desired shape of this type. If the\nshape parameter is 1, then the data-type object used to be equivalent to fixed\ndtype. This behaviour is deprecated since NumPy 1.17 and will raise an error\nin the future. If shape is a tuple, then the new dtype defines a sub-array of\nthe given shape.\n\nobj should be a list of fields where each field is described by a tuple of\nlength 2 or 3. (Equivalent to the `descr` item in the `__array_interface__`\nattribute.)\n\nThe first element, field_name, is the field name (if this is `''` then a\nstandard field name, `'f#'`, is assigned). The field name may also be a\n2-tuple of strings where the first string is either a \u201ctitle\u201d (which may be\nany string or unicode string) or meta-data for the field which can be any\nobject, and the second string is the \u201cname\u201d which must be a valid Python\nidentifier.\n\nThe second element, field_dtype, can be anything that can be interpreted as a\ndata-type.\n\nThe optional third element field_shape contains the shape if this field\nrepresents an array of the data-type in the second element. Note that a\n3-tuple with a third argument equal to 1 is equivalent to a 2-tuple.\n\nThis style does not accept align in the `dtype` constructor as it is assumed\nthat all of the memory is accounted for by the array interface description.\n\nData-type with fields `big` (big-endian 32-bit integer) and `little` (little-\nendian 32-bit integer):\n\nData-type with fields `R`, `G`, `B`, `A`, each being an unsigned 8-bit\ninteger:\n\nThis style has two required and three optional keys. The names and formats\nkeys are required. Their respective values are equal-length lists with the\nfield names and the field formats. The field names must be strings and the\nfield formats can be any object accepted by `dtype` constructor.\n\nWhen the optional keys offsets and titles are provided, their values must each\nbe lists of the same length as the names and formats lists. The offsets value\nis a list of byte offsets (limited to `ctypes.c_int`) for each field, while\nthe titles value is a list of titles for each field (`None` can be used if no\ntitle is desired for that field). The titles can be any object, but when a\n`str` object will add another entry to the fields dictionary keyed by the\ntitle and referencing the same field tuple which will contain the title as an\nadditional tuple member.\n\nThe itemsize key allows the total size of the dtype to be set, and must be an\ninteger large enough so all the fields are within the dtype. If the dtype\nbeing constructed is aligned, the itemsize must also be divisible by the\nstruct alignment. Total dtype itemsize is limited to `ctypes.c_int`.\n\nData type with fields `r`, `g`, `b`, `a`, each being an 8-bit unsigned\ninteger:\n\nData type with fields `r` and `b` (with the given titles), both being 8-bit\nunsigned integers, the first at byte position 0 from the start of the field\nand the second at position 2:\n\nThis usage is discouraged, because it is ambiguous with the other dict-based\nconstruction method. If you have a field called \u2018names\u2019 and a field called\n\u2018formats\u2019 there will be a conflict.\n\nThis style allows passing in the `fields` attribute of a data-type object.\n\nobj should contain string or unicode keys that refer to `(data-type, offset)`\nor `(data-type, offset, title)` tuples.\n\nData type containing field `col1` (10-character string at byte position 0),\n`col2` (32-bit float at byte position 10), and `col3` (integers at byte\nposition 14):\n\nIn NumPy 1.7 and later, this form allows `base_dtype` to be interpreted as a\nstructured dtype. Arrays created with this dtype will have underlying dtype\n`base_dtype` but will have fields and flags taken from `new_dtype`. This is\nuseful for creating custom structured dtypes, as done in record arrays.\n\nThis form also makes it possible to specify struct dtypes with overlapping\nfields, functioning like the \u2018union\u2019 type in C. This usage is discouraged,\nhowever, and the union mechanism is preferred.\n\nBoth arguments must be convertible to data-type objects with the same total\nsize.\n\n32-bit integer, whose first two bytes are interpreted as an integer via field\n`real`, and the following two bytes via field `imag`.\n\n32-bit integer, which is interpreted as consisting of a sub-array of shape\n`(4,)` containing 8-bit integers:\n\n32-bit integer, containing fields `r`, `g`, `b`, `a` that interpret the 4\nbytes in the integer as four unsigned integers:\n\nNumPy data type descriptions are instances of the `dtype` class.\n\nThe type of the data is described by the following `dtype` attributes:\n\n`dtype.type`\n\n`dtype.kind`\n\nA character code (one of 'biufcmMOSUV') identifying the general kind of data.\n\n`dtype.char`\n\nA unique character code for each of the 21 different built-in types.\n\n`dtype.num`\n\nA unique number for each of the 21 different built-in types.\n\n`dtype.str`\n\nThe array-protocol typestring of this data-type object.\n\nSize of the data is in turn described by:\n\n`dtype.name`\n\nA bit-width name for this data-type.\n\n`dtype.itemsize`\n\nThe element size of this data-type object.\n\nEndianness of this data:\n\n`dtype.byteorder`\n\nA character indicating the byte-order of this data-type object.\n\nInformation about sub-data-types in a structured data type:\n\n`dtype.fields`\n\nDictionary of named fields defined for this data type, or `None`.\n\n`dtype.names`\n\nOrdered list of field names, or `None` if there are no fields.\n\nFor data types that describe sub-arrays:\n\n`dtype.subdtype`\n\nTuple `(item_dtype, shape)` if this `dtype` describes a sub-array, and None\notherwise.\n\n`dtype.shape`\n\nShape tuple of the sub-array if this data type describes a sub-array, and `()`\notherwise.\n\nAttributes providing additional information:\n\n`dtype.hasobject`\n\nBoolean indicating whether this dtype contains any reference-counted objects\nin any fields or sub-dtypes.\n\n`dtype.flags`\n\nBit-flags describing how this data type is to be interpreted.\n\n`dtype.isbuiltin`\n\nInteger indicating how this dtype relates to the built-in dtypes.\n\n`dtype.isnative`\n\nBoolean indicating whether the byte order of this dtype is native to the\nplatform.\n\n`dtype.descr`\n\n`__array_interface__` description of the data-type.\n\n`dtype.alignment`\n\nThe required alignment (bytes) of this data-type according to the compiler.\n\n`dtype.base`\n\nReturns dtype for the base element of the subarrays, regardless of their\ndimension or shape.\n\nMetadata attached by the user:\n\n`dtype.metadata`\n\nEither `None` or a readonly dictionary of metadata (mappingproxy).\n\nData types have the following method for changing the byte order:\n\n`dtype.newbyteorder`([new_order])\n\nReturn a new dtype with a different byte order.\n\nThe following methods implement the pickle protocol:\n\n`dtype.__reduce__`\n\nHelper for pickle.\n\n`dtype.__setstate__`\n\nUtility method for typing:\n\n`dtype.__class_getitem__`(item, /)\n\nReturn a parametrized wrapper around the `dtype` type.\n\nComparison operations:\n\n`dtype.__ge__`(value, /)\n\nReturn self>=value.\n\n`dtype.__gt__`(value, /)\n\nReturn self>value.\n\n`dtype.__le__`(value, /)\n\nReturn self<=value.\n\n`dtype.__lt__`(value, /)\n\nReturn self<value.\n\n"}, {"name": "dtype.__class_getitem__()", "path": "reference/generated/numpy.dtype.__class_getitem__", "type": "numpy.dtype.__class_getitem__", "text": "\nmethod\n\nReturn a parametrized wrapper around the `dtype` type.\n\nNew in version 1.22.\n\nA parametrized `dtype` type.\n\nSee also\n\nType hinting generics in standard collections.\n\nThis method is only available for python 3.9 and later.\n\n"}, {"name": "dtype.__ge__()", "path": "reference/generated/numpy.dtype.__ge__", "type": "numpy.dtype.__ge__", "text": "\nmethod\n\nReturn self>=value.\n\n"}, {"name": "dtype.__gt__()", "path": "reference/generated/numpy.dtype.__gt__", "type": "numpy.dtype.__gt__", "text": "\nmethod\n\nReturn self>value.\n\n"}, {"name": "dtype.__le__()", "path": "reference/generated/numpy.dtype.__le__", "type": "numpy.dtype.__le__", "text": "\nmethod\n\nReturn self<=value.\n\n"}, {"name": "dtype.__lt__()", "path": "reference/generated/numpy.dtype.__lt__", "type": "numpy.dtype.__lt__", "text": "\nmethod\n\nReturn self<value.\n\n"}, {"name": "dtype.__reduce__()", "path": "reference/generated/numpy.dtype.__reduce__", "type": "numpy.dtype.__reduce__", "text": "\nmethod\n\nHelper for pickle.\n\n"}, {"name": "dtype.__setstate__()", "path": "reference/generated/numpy.dtype.__setstate__", "type": "numpy.dtype.__setstate__", "text": "\nmethod\n\n"}, {"name": "dtype.alignment", "path": "reference/generated/numpy.dtype.alignment", "type": "numpy.dtype.alignment", "text": "\nattribute\n\nThe required alignment (bytes) of this data-type according to the compiler.\n\nMore information is available in the C-API section of the manual.\n\n"}, {"name": "dtype.base", "path": "reference/generated/numpy.dtype.base", "type": "numpy.dtype.base", "text": "\nattribute\n\nReturns dtype for the base element of the subarrays, regardless of their\ndimension or shape.\n\nSee also\n\n"}, {"name": "dtype.byteorder", "path": "reference/generated/numpy.dtype.byteorder", "type": "numpy.dtype.byteorder", "text": "\nattribute\n\nA character indicating the byte-order of this data-type object.\n\nOne of:\n\n\u2018=\u2019\n\nnative\n\n\u2018<\u2019\n\nlittle-endian\n\n\u2018>\u2019\n\nbig-endian\n\n\u2018|\u2019\n\nnot applicable\n\nAll built-in data-type objects have byteorder either \u2018=\u2019 or \u2018|\u2019.\n\n"}, {"name": "dtype.char", "path": "reference/generated/numpy.dtype.char", "type": "numpy.dtype.char", "text": "\nattribute\n\nA unique character code for each of the 21 different built-in types.\n\n"}, {"name": "dtype.descr", "path": "reference/generated/numpy.dtype.descr", "type": "numpy.dtype.descr", "text": "\nattribute\n\n`__array_interface__` description of the data-type.\n\nThe format is that required by the \u2018descr\u2019 key in the `__array_interface__`\nattribute.\n\nWarning: This attribute exists specifically for `__array_interface__`, and\npassing it directly to `np.dtype` will not accurately reconstruct some dtypes\n(e.g., scalar and subarray dtypes).\n\n"}, {"name": "dtype.fields", "path": "reference/generated/numpy.dtype.fields", "type": "numpy.dtype.fields", "text": "\nattribute\n\nDictionary of named fields defined for this data type, or `None`.\n\nThe dictionary is indexed by keys that are the names of the fields. Each entry\nin the dictionary is a tuple fully describing the field:\n\nOffset is limited to C int, which is signed and usually 32 bits. If present,\nthe optional title can be any object (if it is a string or unicode then it\nwill also be a key in the fields dictionary, otherwise it\u2019s meta-data). Notice\nalso that the first two elements of the tuple can be passed directly as\narguments to the `ndarray.getfield` and `ndarray.setfield` methods.\n\nSee also\n\n"}, {"name": "dtype.flags", "path": "reference/generated/numpy.dtype.flags", "type": "numpy.dtype.flags", "text": "\nattribute\n\nBit-flags describing how this data type is to be interpreted.\n\nBit-masks are in `numpy.core.multiarray` as the constants `ITEM_HASOBJECT`,\n`LIST_PICKLE`, `ITEM_IS_POINTER`, `NEEDS_INIT`, `NEEDS_PYAPI`, `USE_GETITEM`,\n`USE_SETITEM`. A full explanation of these flags is in C-API documentation;\nthey are largely useful for user-defined data-types.\n\nThe following example demonstrates that operations on this particular dtype\nrequires Python C-API.\n\n"}, {"name": "dtype.hasobject", "path": "reference/generated/numpy.dtype.hasobject", "type": "numpy.dtype.hasobject", "text": "\nattribute\n\nBoolean indicating whether this dtype contains any reference-counted objects\nin any fields or sub-dtypes.\n\nRecall that what is actually in the ndarray memory representing the Python\nobject is the memory address of that object (a pointer). Special handling may\nbe required, and this attribute is useful for distinguishing data types that\nmay contain arbitrary Python objects and data-types that won\u2019t.\n\n"}, {"name": "dtype.isalignedstruct", "path": "reference/generated/numpy.dtype.isalignedstruct", "type": "Data type objects", "text": "\nattribute\n\nBoolean indicating whether the dtype is a struct which maintains field\nalignment. This flag is sticky, so when combining multiple structs together,\nit is preserved and produces new dtypes which are also aligned.\n\n"}, {"name": "dtype.isbuiltin", "path": "reference/generated/numpy.dtype.isbuiltin", "type": "numpy.dtype.isbuiltin", "text": "\nattribute\n\nInteger indicating how this dtype relates to the built-in dtypes.\n\nRead-only.\n\n0\n\nif this is a structured array type, with fields\n\n1\n\nif this is a dtype compiled into numpy (such as ints, floats etc)\n\n2\n\nif the dtype is for a user-defined numpy type A user-defined type uses the\nnumpy C-API machinery to extend numpy to handle a new array type. See User-\ndefined data-types in the NumPy manual.\n\n"}, {"name": "dtype.isnative", "path": "reference/generated/numpy.dtype.isnative", "type": "numpy.dtype.isnative", "text": "\nattribute\n\nBoolean indicating whether the byte order of this dtype is native to the\nplatform.\n\n"}, {"name": "dtype.itemsize", "path": "reference/generated/numpy.dtype.itemsize", "type": "numpy.dtype.itemsize", "text": "\nattribute\n\nThe element size of this data-type object.\n\nFor 18 of the 21 types this number is fixed by the data-type. For the flexible\ndata-types, this number can be anything.\n\n"}, {"name": "dtype.kind", "path": "reference/generated/numpy.dtype.kind", "type": "numpy.dtype.kind", "text": "\nattribute\n\nA character code (one of \u2018biufcmMOSUV\u2019) identifying the general kind of data.\n\nb\n\nboolean\n\ni\n\nsigned integer\n\nu\n\nunsigned integer\n\nf\n\nfloating-point\n\nc\n\ncomplex floating-point\n\nm\n\ntimedelta\n\nM\n\ndatetime\n\nO\n\nobject\n\nS\n\n(byte-)string\n\nU\n\nUnicode\n\nV\n\nvoid\n\n"}, {"name": "dtype.metadata", "path": "reference/generated/numpy.dtype.metadata", "type": "numpy.dtype.metadata", "text": "\nattribute\n\nEither `None` or a readonly dictionary of metadata (mappingproxy).\n\nThe metadata field can be set using any dictionary at data-type creation.\nNumPy currently has no uniform approach to propagating metadata; although some\narray operations preserve it, there is no guarantee that others will.\n\nWarning\n\nAlthough used in certain projects, this feature was long undocumented and is\nnot well supported. Some aspects of metadata propagation are expected to\nchange in the future.\n\nAdding arrays with identical datatypes currently preserves the metadata:\n\nBut if the arrays have different dtype metadata, the metadata may be dropped:\n\n"}, {"name": "dtype.name", "path": "reference/generated/numpy.dtype.name", "type": "numpy.dtype.name", "text": "\nattribute\n\nA bit-width name for this data-type.\n\nUn-sized flexible data-type objects do not have this attribute.\n\n"}, {"name": "dtype.names", "path": "reference/generated/numpy.dtype.names", "type": "numpy.dtype.names", "text": "\nattribute\n\nOrdered list of field names, or `None` if there are no fields.\n\nThe names are ordered according to increasing byte offset. This can be used,\nfor example, to walk through all of the named fields in offset order.\n\n"}, {"name": "dtype.ndim", "path": "reference/generated/numpy.dtype.ndim", "type": "Data type objects", "text": "\nattribute\n\nNumber of dimensions of the sub-array if this data type describes a sub-array,\nand `0` otherwise.\n\nNew in version 1.13.0.\n\n"}, {"name": "dtype.newbyteorder()", "path": "reference/generated/numpy.dtype.newbyteorder", "type": "numpy.dtype.newbyteorder", "text": "\nmethod\n\nReturn a new dtype with a different byte order.\n\nChanges are also made in all fields and sub-arrays of the data type.\n\nByte order to force; a value from the byte order specifications below. The\ndefault value (\u2018S\u2019) results in swapping the current byte order. `new_order`\ncodes can be any of:\n\nNew dtype object with the given change to the byte order.\n\nChanges are also made in all fields and sub-arrays of the data type.\n\n"}, {"name": "dtype.num", "path": "reference/generated/numpy.dtype.num", "type": "numpy.dtype.num", "text": "\nattribute\n\nA unique number for each of the 21 different built-in types.\n\nThese are roughly ordered from least-to-most precision.\n\n"}, {"name": "dtype.shape", "path": "reference/generated/numpy.dtype.shape", "type": "numpy.dtype.shape", "text": "\nattribute\n\nShape tuple of the sub-array if this data type describes a sub-array, and `()`\notherwise.\n\n"}, {"name": "dtype.str", "path": "reference/generated/numpy.dtype.str", "type": "numpy.dtype.str", "text": "\nattribute\n\nThe array-protocol typestring of this data-type object.\n\n"}, {"name": "dtype.subdtype", "path": "reference/generated/numpy.dtype.subdtype", "type": "numpy.dtype.subdtype", "text": "\nattribute\n\nTuple `(item_dtype, shape)` if this `dtype` describes a sub-array, and None\notherwise.\n\nThe shape is the fixed shape of the sub-array described by this data type, and\nitem_dtype the data type of the array.\n\nIf a field whose dtype object has this attribute is retrieved, then the extra\ndimensions implied by shape are tacked on to the end of the retrieved array.\n\nSee also\n\n"}, {"name": "dtype.type", "path": "reference/generated/numpy.dtype.type", "type": "numpy.dtype.type", "text": "\nattribute\n\n"}, {"name": "Elementary Function", "path": "reference/c-api/generalized-ufuncs", "type": "Generalized Universal Function API", "text": "\nThere is a general need for looping over not only functions on scalars but\nalso over functions on vectors (or arrays). This concept is realized in NumPy\nby generalizing the universal functions (ufuncs). In regular ufuncs, the\nelementary function is limited to element-by-element operations, whereas the\ngeneralized version (gufuncs) supports \u201csub-array\u201d by \u201csub-array\u201d operations.\nThe Perl vector library PDL provides a similar functionality and its terms are\nre-used in the following.\n\nEach generalized ufunc has information associated with it that states what the\n\u201ccore\u201d dimensionality of the inputs is, as well as the corresponding\ndimensionality of the outputs (the element-wise ufuncs have zero core\ndimensions). The list of the core dimensions for all arguments is called the\n\u201csignature\u201d of a ufunc. For example, the ufunc numpy.add has signature\n`(),()->()` defining two scalar inputs and one scalar output.\n\nAnother example is the function `inner1d(a, b)` with a signature of\n`(i),(i)->()`. This applies the inner product along the last axis of each\ninput, but keeps the remaining indices intact. For example, where `a` is of\nshape `(3, 5, N)` and `b` is of shape `(5, N)`, this will return an output of\nshape `(3,5)`. The underlying elementary function is called `3 * 5` times. In\nthe signature, we specify one core dimension `(i)` for each input and zero\ncore dimensions `()` for the output, since it takes two 1-d arrays and returns\na scalar. By using the same name `i`, we specify that the two corresponding\ndimensions should be of the same size.\n\nThe dimensions beyond the core dimensions are called \u201cloop\u201d dimensions. In the\nabove example, this corresponds to `(3, 5)`.\n\nThe signature determines how the dimensions of each input/output array are\nsplit into core and loop dimensions:\n\nTypically, the size of all core dimensions in an output will be determined by\nthe size of a core dimension with the same label in an input array. This is\nnot a requirement, and it is possible to define a signature where a label\ncomes up for the first time in an output, although some precautions must be\ntaken when calling such a function. An example would be the function\n`euclidean_pdist(a)`, with signature `(n,d)->(p)`, that given an array of `n`\n`d`-dimensional vectors, computes all unique pairwise Euclidean distances\namong them. The output dimension `p` must therefore be equal to `n * (n - 1) /\n2`, but it is the caller\u2019s responsibility to pass in an output array of the\nright size. If the size of a core dimension of an output cannot be determined\nfrom a passed in input or output array, an error will be raised.\n\nNote: Prior to NumPy 1.10.0, less strict checks were in place: missing core\ndimensions were created by prepending 1\u2019s to the shape as necessary, core\ndimensions with the same label were broadcast together, and undetermined\ndimensions were created with size 1.\n\nEach ufunc consists of an elementary function that performs the most basic\noperation on the smallest portion of array arguments (e.g. adding two numbers\nis the most basic operation in adding two arrays). The ufunc applies the\nelementary function multiple times on different parts of the arrays. The\ninput/output of elementary functions can be vectors; e.g., the elementary\nfunction of inner1d takes two vectors as input.\n\nA signature is a string describing the input/output dimensions of the\nelementary function of a ufunc. See section below for more details.\n\nThe dimensionality of each input/output of an elementary function is defined\nby its core dimensions (zero core dimensions correspond to a scalar\ninput/output). The core dimensions are mapped to the last dimensions of the\ninput/output arrays.\n\nA dimension name represents a core dimension in the signature. Different\ndimensions may share a name, indicating that they are of the same size.\n\nA dimension index is an integer representing a dimension name. It enumerates\nthe dimension names according to the order of the first occurrence of each\nname in the signature.\n\nThe signature defines \u201ccore\u201d dimensionality of input and output variables, and\nthereby also defines the contraction of the dimensions. The signature is\nrepresented by a string of the following format:\n\nThe formal syntax of signatures is as follows:\n\nNotes:\n\nHere are some examples of signatures:\n\nname\n\nsignature\n\ncommon usage\n\nadd\n\n`(),()->()`\n\nbinary ufunc\n\nsum1d\n\n`(i)->()`\n\nreduction\n\ninner1d\n\n`(i),(i)->()`\n\nvector-vector multiplication\n\nmatmat\n\n`(m,n),(n,p)->(m,p)`\n\nmatrix multiplication\n\nvecmat\n\n`(n),(n,p)->(p)`\n\nvector-matrix multiplication\n\nmatvec\n\n`(m,n),(n)->(m)`\n\nmatrix-vector multiplication\n\nmatmul\n\n`(m?,n),(n,p?)->(m?,p?)`\n\ncombination of the four above\n\nouter_inner\n\n`(i,t),(j,t)->(i,j)`\n\ninner over the last dimension, outer over the second to last, and\nloop/broadcast over the rest.\n\ncross1d\n\n`(3),(3)->(3)`\n\ncross product where the last dimension is frozen and must be 3\n\nThe last is an instance of freezing a core dimension and can be used to\nimprove ufunc performance\n\nThe current interface remains unchanged, and `PyUFunc_FromFuncAndData` can\nstill be used to implement (specialized) ufuncs, consisting of scalar\nelementary functions.\n\nOne can use `PyUFunc_FromFuncAndDataAndSignature` to declare a more general\nufunc. The argument list is the same as `PyUFunc_FromFuncAndData`, with an\nadditional argument specifying the signature as C string.\n\nFurthermore, the callback function is of the same type as before, `void\n(*foo)(char **args, intp *dimensions, intp *steps, void *func)`. When invoked,\n`args` is a list of length `nargs` containing the data of all input/output\narguments. For a scalar elementary function, `steps` is also of length\n`nargs`, denoting the strides used for the arguments. `dimensions` is a\npointer to a single integer defining the size of the axis to be looped over.\n\nFor a non-trivial signature, `dimensions` will also contain the sizes of the\ncore dimensions as well, starting at the second entry. Only one size is\nprovided for each unique dimension name and the sizes are given according to\nthe first occurrence of a dimension name in the signature.\n\nThe first `nargs` elements of `steps` remain the same as for scalar ufuncs.\nThe following elements contain the strides of all core dimensions for all\narguments in order.\n\nFor example, consider a ufunc with signature `(i,j),(i)->()`. In this case,\n`args` will contain three pointers to the data of the input/output arrays `a`,\n`b`, `c`. Furthermore, `dimensions` will be `[N, I, J]` to define the size of\n`N` of the loop and the sizes `I` and `J` for the core dimensions `i` and `j`.\nFinally, `steps` will be `[a_N, b_N, c_N, a_i, a_j, b_i]`, containing all\nnecessary strides.\n\n"}, {"name": "enum NPY_CASTING", "path": "reference/c-api/array#c.NPY_CASTING", "type": "Array API", "text": "\nNew in version 1.6.\n\nAn enumeration type indicating how permissive data conversions should be. This\nis used by the iterator added in NumPy 1.6, and is intended to be used more\nbroadly in a future version.\n\nOnly allow identical types.\n\nAllow identical and casts involving byte swapping.\n\nOnly allow casts which will not cause values to be rounded, truncated, or\notherwise changed.\n\nAllow any safe casts, and casts between types of the same kind. For example,\nfloat64 -> float32 is permitted with this rule.\n\nAllow any cast, no matter what kind of data loss may occur.\n\n"}, {"name": "enum NPY_CLIPMODE", "path": "reference/c-api/array#c.NPY_CLIPMODE", "type": "Array API", "text": "\nA variable type indicating the kind of clipping that should be applied in\ncertain functions.\n\nThe default for most operations, raises an exception if an index is out of\nbounds.\n\nClips an index to the valid range if it is out of bounds.\n\nWraps an index to the valid range if it is out of bounds.\n\n"}, {"name": "enum NPY_ORDER", "path": "reference/c-api/array#c.NPY_ORDER", "type": "Array API", "text": "\nAn enumeration type indicating the element order that an array should be\ninterpreted in. When a brand new array is created, generally only NPY_CORDER\nand NPY_FORTRANORDER are used, whereas when one or more inputs are provided,\nthe order can be based on them.\n\nFortran order if all the inputs are Fortran, C otherwise.\n\nC order.\n\nFortran order.\n\nAn order as close to the order of the inputs as possible, even if the input is\nin neither C nor Fortran order.\n\n"}, {"name": "enum NPY_SCALARKIND", "path": "reference/c-api/array#c.NPY_SCALARKIND", "type": "Array API", "text": "\nA special variable type indicating the number of \u201ckinds\u201d of scalars\ndistinguished in determining scalar-coercion rules. This variable can take on\nthe values:\n\nDefined to be the number of scalar kinds (not including `NPY_NOSCALAR`).\n\n"}, {"name": "enum NPY_SEARCHSIDE", "path": "reference/c-api/array#c.NPY_SEARCHSIDE", "type": "Array API", "text": "\nA variable type indicating whether the index returned should be that of the\nfirst suitable location (if `NPY_SEARCHLEFT`) or of the last (if\n`NPY_SEARCHRIGHT`).\n\n"}, {"name": "enum NPY_SELECTKIND", "path": "reference/c-api/array#c.NPY_SELECTKIND", "type": "Array API", "text": "\nA variable type indicating the selection algorithm being used.\n\n"}, {"name": "enumerator NPY_BOOL", "path": "reference/c-api/dtype#c.NPY_BOOL", "type": "Data Type API", "text": "\nThe enumeration value for the boolean type, stored as one byte. It may only be\nset to the values 0 and 1.\n\n"}, {"name": "enumerator NPY_BOOL_SCALAR", "path": "reference/c-api/array#c.NPY_SCALARKIND.NPY_BOOL_SCALAR", "type": "Array API", "text": "\n\n"}, {"name": "enumerator NPY_BYTE", "path": "reference/c-api/dtype#c.NPY_BYTE", "type": "Data Type API", "text": "\n\n"}, {"name": "enumerator NPY_CDOUBLE", "path": "reference/c-api/dtype#c.NPY_CDOUBLE", "type": "Data Type API", "text": "\n\n"}, {"name": "enumerator NPY_CFLOAT", "path": "reference/c-api/dtype#c.NPY_CFLOAT", "type": "Data Type API", "text": "\n\n"}, {"name": "enumerator NPY_CLIP", "path": "reference/c-api/array#c.NPY_CLIPMODE.NPY_CLIP", "type": "Array API", "text": "\nClips an index to the valid range if it is out of bounds.\n\n"}, {"name": "enumerator NPY_CLONGDOUBLE", "path": "reference/c-api/dtype#c.NPY_CLONGDOUBLE", "type": "Data Type API", "text": "\nThe enumeration value for a platform-specific complex floating point type\nwhich is made up of two NPY_LONGDOUBLE values.\n\n"}, {"name": "enumerator NPY_COMPLEX128", "path": "reference/c-api/dtype#c.NPY_COMPLEX128", "type": "Data Type API", "text": "\nThe enumeration value for a 128-bit/16-byte complex type made up of two\nNPY_DOUBLE values.\n\n"}, {"name": "enumerator NPY_COMPLEX64", "path": "reference/c-api/dtype#c.NPY_COMPLEX64", "type": "Data Type API", "text": "\nThe enumeration value for a 64-bit/8-byte complex type made up of two\nNPY_FLOAT values.\n\n"}, {"name": "enumerator NPY_COMPLEX_SCALAR", "path": "reference/c-api/array#c.NPY_SCALARKIND.NPY_COMPLEX_SCALAR", "type": "Array API", "text": "\n\n"}, {"name": "enumerator NPY_CORDER", "path": "reference/c-api/array#c.NPY_ORDER.NPY_CORDER", "type": "Array API", "text": "\nC order.\n\n"}, {"name": "enumerator NPY_DATETIME", "path": "reference/c-api/dtype#c.NPY_DATETIME", "type": "Data Type API", "text": "\nThe enumeration value for a data type which holds dates or datetimes with a\nprecision based on selectable date or time units.\n\n"}, {"name": "enumerator NPY_DEFAULT_TYPE", "path": "reference/c-api/dtype#c.NPY_DEFAULT_TYPE", "type": "Data Type API", "text": "\nThe default type to use when no dtype is explicitly specified, for example\nwhen calling np.zero(shape). This is equivalent to `NPY_DOUBLE`.\n\n"}, {"name": "enumerator NPY_DOUBLE", "path": "reference/c-api/dtype#c.NPY_DOUBLE", "type": "Data Type API", "text": "\n\n"}, {"name": "enumerator NPY_EQUIV_CASTING", "path": "reference/c-api/array#c.NPY_CASTING.NPY_EQUIV_CASTING", "type": "Array API", "text": "\nAllow identical and casts involving byte swapping.\n\n"}, {"name": "enumerator NPY_FLOAT", "path": "reference/c-api/dtype#c.NPY_FLOAT", "type": "Data Type API", "text": "\n\n"}, {"name": "enumerator NPY_FLOAT16", "path": "reference/c-api/dtype#c.NPY_FLOAT16", "type": "Data Type API", "text": "\nThe enumeration value for a 16-bit/2-byte IEEE 754-2008 compatible floating\npoint type.\n\n"}, {"name": "enumerator NPY_FLOAT32", "path": "reference/c-api/dtype#c.NPY_FLOAT32", "type": "Data Type API", "text": "\nThe enumeration value for a 32-bit/4-byte IEEE 754 compatible floating point\ntype.\n\n"}, {"name": "enumerator NPY_FLOAT64", "path": "reference/c-api/dtype#c.NPY_FLOAT64", "type": "Data Type API", "text": "\nThe enumeration value for a 64-bit/8-byte IEEE 754 compatible floating point\ntype.\n\n"}, {"name": "enumerator NPY_FLOAT_SCALAR", "path": "reference/c-api/array#c.NPY_SCALARKIND.NPY_FLOAT_SCALAR", "type": "Array API", "text": "\n\n"}, {"name": "enumerator NPY_FORTRANORDER", "path": "reference/c-api/array#c.NPY_ORDER.NPY_FORTRANORDER", "type": "Array API", "text": "\nFortran order.\n\n"}, {"name": "enumerator NPY_HALF", "path": "reference/c-api/dtype#c.NPY_HALF", "type": "Data Type API", "text": "\n\n"}, {"name": "enumerator NPY_HEAPSORT", "path": "reference/c-api/array#c.NPY_SORTKIND.NPY_HEAPSORT", "type": "Array API", "text": "\n\n"}, {"name": "enumerator NPY_INT", "path": "reference/c-api/dtype#c.NPY_INT", "type": "Data Type API", "text": "\n\n"}, {"name": "enumerator NPY_INT16", "path": "reference/c-api/dtype#c.NPY_INT16", "type": "Data Type API", "text": "\nThe enumeration value for a 16-bit/2-byte signed integer.\n\n"}, {"name": "enumerator NPY_INT32", "path": "reference/c-api/dtype#c.NPY_INT32", "type": "Data Type API", "text": "\nThe enumeration value for a 32-bit/4-byte signed integer.\n\n"}, {"name": "enumerator NPY_INT64", "path": "reference/c-api/dtype#c.NPY_INT64", "type": "Data Type API", "text": "\nThe enumeration value for a 64-bit/8-byte signed integer.\n\n"}, {"name": "enumerator NPY_INT8", "path": "reference/c-api/dtype#c.NPY_INT8", "type": "Data Type API", "text": "\nThe enumeration value for an 8-bit/1-byte signed integer.\n\n"}, {"name": "enumerator NPY_INTNEG_SCALAR", "path": "reference/c-api/array#c.NPY_SCALARKIND.NPY_INTNEG_SCALAR", "type": "Array API", "text": "\n\n"}, {"name": "enumerator NPY_INTP", "path": "reference/c-api/dtype#c.NPY_INTP", "type": "Data Type API", "text": "\nThe enumeration value for a signed integer type which is the same size as a\n(void *) pointer. This is the type used by all arrays of indices.\n\n"}, {"name": "enumerator NPY_INTPOS_SCALAR", "path": "reference/c-api/array#c.NPY_SCALARKIND.NPY_INTPOS_SCALAR", "type": "Array API", "text": "\n\n"}, {"name": "enumerator NPY_KEEPORDER", "path": "reference/c-api/array#c.NPY_ORDER.NPY_KEEPORDER", "type": "Array API", "text": "\nAn order as close to the order of the inputs as possible, even if the input is\nin neither C nor Fortran order.\n\n"}, {"name": "enumerator NPY_LONG", "path": "reference/c-api/dtype#c.NPY_LONG", "type": "Data Type API", "text": "\nEquivalent to either NPY_INT or NPY_LONGLONG, depending on the platform.\n\n"}, {"name": "enumerator NPY_LONGDOUBLE", "path": "reference/c-api/dtype#c.NPY_LONGDOUBLE", "type": "Data Type API", "text": "\nThe enumeration value for a platform-specific floating point type which is at\nleast as large as NPY_DOUBLE, but larger on many platforms.\n\n"}, {"name": "enumerator NPY_LONGLONG", "path": "reference/c-api/dtype#c.NPY_LONGLONG", "type": "Data Type API", "text": "\n\n"}, {"name": "enumerator NPY_MASK", "path": "reference/c-api/dtype#c.NPY_MASK", "type": "Data Type API", "text": "\nThe enumeration value of the type used for masks, such as with the\n`NPY_ITER_ARRAYMASK` iterator flag. This is equivalent to `NPY_UINT8`.\n\n"}, {"name": "enumerator NPY_MERGESORT", "path": "reference/c-api/array#c.NPY_SORTKIND.NPY_MERGESORT", "type": "Array API", "text": "\n\n"}, {"name": "enumerator NPY_NSCALARKINDS", "path": "reference/c-api/array#c.NPY_SCALARKIND.NPY_NSCALARKINDS", "type": "Array API", "text": "\nDefined to be the number of scalar kinds (not including `NPY_NOSCALAR`).\n\n"}, {"name": "enumerator NPY_NSORTS", "path": "reference/c-api/array#c.NPY_SORTKIND.NPY_NSORTS", "type": "Array API", "text": "\nDefined to be the number of sorts. It is fixed at three by the need for\nbackwards compatibility, and consequently `NPY_MERGESORT` and `NPY_STABLESORT`\nare aliased to each other and may refer to one of several stable sorting\nalgorithms depending on the data type.\n\n"}, {"name": "enumerator NPY_OBJECT", "path": "reference/c-api/dtype#c.NPY_OBJECT", "type": "Data Type API", "text": "\nThe enumeration value for references to arbitrary Python objects.\n\n"}, {"name": "enumerator NPY_OBJECT_SCALAR", "path": "reference/c-api/array#c.NPY_SCALARKIND.NPY_OBJECT_SCALAR", "type": "Array API", "text": "\n\n"}, {"name": "enumerator NPY_SAFE_CASTING", "path": "reference/c-api/array#c.NPY_CASTING.NPY_SAFE_CASTING", "type": "Array API", "text": "\nOnly allow casts which will not cause values to be rounded, truncated, or\notherwise changed.\n\n"}, {"name": "enumerator NPY_SAME_KIND_CASTING", "path": "reference/c-api/array#c.NPY_CASTING.NPY_SAME_KIND_CASTING", "type": "Array API", "text": "\nAllow any safe casts, and casts between types of the same kind. For example,\nfloat64 -> float32 is permitted with this rule.\n\n"}, {"name": "enumerator NPY_SEARCHRIGHT", "path": "reference/c-api/array#c.NPY_SEARCHSIDE.NPY_SEARCHRIGHT", "type": "Array API", "text": "\n\n"}, {"name": "enumerator NPY_SHORT", "path": "reference/c-api/dtype#c.NPY_SHORT", "type": "Data Type API", "text": "\n\n"}, {"name": "enumerator NPY_STABLESORT", "path": "reference/c-api/array#c.NPY_SORTKIND.NPY_STABLESORT", "type": "Array API", "text": "\nUsed as an alias of `NPY_MERGESORT` and vica versa.\n\n"}, {"name": "enumerator NPY_STRING", "path": "reference/c-api/dtype#c.NPY_STRING", "type": "Data Type API", "text": "\nThe enumeration value for ASCII strings of a selectable size. The strings have\na fixed maximum size within a given array.\n\n"}, {"name": "enumerator NPY_TIMEDELTA", "path": "reference/c-api/dtype#c.NPY_TIMEDELTA", "type": "Data Type API", "text": "\nThe enumeration value for a data type which holds lengths of times in integers\nof selectable date or time units.\n\n"}, {"name": "enumerator NPY_TYPES", "path": "reference/c-api/dtype", "type": "Data Type API", "text": "\nThe standard array can have 24 different data types (and has some support for\nadding your own types). These data types all have an enumerated type, an\nenumerated type-character, and a corresponding array scalar Python type object\n(placed in a hierarchy). There are also standard C typedefs to make it easier\nto manipulate elements of the given data type. For the numeric types, there\nare also bit-width equivalent C typedefs and named typenumbers that make it\neasier to select the precision desired.\n\nWarning\n\nThe names for the types in c code follows c naming conventions more closely.\nThe Python names for these types follow Python conventions. Thus, `NPY_FLOAT`\npicks up a 32-bit float in C, but `numpy.float_` in Python corresponds to a\n64-bit double. The bit-width names can be used in both Python and C for\nclarity.\n\nThere is a list of enumerated types defined providing the basic 24 data types\nplus some useful generic names. Whenever the code requires a type number, one\nof these enumerated types is requested. The types are all called `NPY_{NAME}`:\n\nThe enumeration value for the boolean type, stored as one byte. It may only be\nset to the values 0 and 1.\n\nThe enumeration value for an 8-bit/1-byte signed integer.\n\nThe enumeration value for a 16-bit/2-byte signed integer.\n\nThe enumeration value for a 32-bit/4-byte signed integer.\n\nEquivalent to either NPY_INT or NPY_LONGLONG, depending on the platform.\n\nThe enumeration value for a 64-bit/8-byte signed integer.\n\nThe enumeration value for an 8-bit/1-byte unsigned integer.\n\nThe enumeration value for a 16-bit/2-byte unsigned integer.\n\nThe enumeration value for a 32-bit/4-byte unsigned integer.\n\nEquivalent to either NPY_UINT or NPY_ULONGLONG, depending on the platform.\n\nThe enumeration value for a 64-bit/8-byte unsigned integer.\n\nThe enumeration value for a 16-bit/2-byte IEEE 754-2008 compatible floating\npoint type.\n\nThe enumeration value for a 32-bit/4-byte IEEE 754 compatible floating point\ntype.\n\nThe enumeration value for a 64-bit/8-byte IEEE 754 compatible floating point\ntype.\n\nThe enumeration value for a platform-specific floating point type which is at\nleast as large as NPY_DOUBLE, but larger on many platforms.\n\nThe enumeration value for a 64-bit/8-byte complex type made up of two\nNPY_FLOAT values.\n\nThe enumeration value for a 128-bit/16-byte complex type made up of two\nNPY_DOUBLE values.\n\nThe enumeration value for a platform-specific complex floating point type\nwhich is made up of two NPY_LONGDOUBLE values.\n\nThe enumeration value for a data type which holds dates or datetimes with a\nprecision based on selectable date or time units.\n\nThe enumeration value for a data type which holds lengths of times in integers\nof selectable date or time units.\n\nThe enumeration value for ASCII strings of a selectable size. The strings have\na fixed maximum size within a given array.\n\nThe enumeration value for UCS4 strings of a selectable size. The strings have\na fixed maximum size within a given array.\n\nThe enumeration value for references to arbitrary Python objects.\n\nPrimarily used to hold struct dtypes, but can contain arbitrary binary data.\n\nSome useful aliases of the above types are\n\nThe enumeration value for a signed integer type which is the same size as a\n(void *) pointer. This is the type used by all arrays of indices.\n\nThe enumeration value for an unsigned integer type which is the same size as a\n(void *) pointer.\n\nThe enumeration value of the type used for masks, such as with the\n`NPY_ITER_ARRAYMASK` iterator flag. This is equivalent to `NPY_UINT8`.\n\nThe default type to use when no dtype is explicitly specified, for example\nwhen calling np.zero(shape). This is equivalent to `NPY_DOUBLE`.\n\nOther useful related constants are\n\nThe total number of built-in NumPy types. The enumeration covers the range\nfrom 0 to NPY_NTYPES-1.\n\nA signal value guaranteed not to be a valid type enumeration number.\n\nThe start of type numbers used for Custom Data types.\n\nThe various character codes indicating certain types are also part of an\nenumerated list. References to type characters (should they be needed at all)\nshould always use these enumerations. The form of them is `NPY_{NAME}LTR`\nwhere `{NAME}` can be\n\nBOOL, BYTE, UBYTE, SHORT, USHORT, INT, UINT, LONG, ULONG, LONGLONG, ULONGLONG,\nHALF, FLOAT, DOUBLE, LONGDOUBLE, CFLOAT, CDOUBLE, CLONGDOUBLE, DATETIME,\nTIMEDELTA, OBJECT, STRING, VOID\n\nINTP, UINTP\n\nGENBOOL, SIGNED, UNSIGNED, FLOATING, COMPLEX\n\nThe latter group of `{NAME}s` corresponds to letters used in the array\ninterface typestring specification.\n\nThese are defined for `{bits}` = 8, 16, 32, 64, 128, and 256 and provide the\nmaximum (minimum) value of the corresponding (unsigned) integer type. Note:\nthe actual integer type may not be available on all platforms (i.e. 128-bit\nand 256-bit integers are rare).\n\nThis is defined for `{type}` = BYTE, SHORT, INT, LONG, LONGLONG, INTP\n\nThis is defined for all defined for `{type}` = BYTE, UBYTE, SHORT, USHORT,\nINT, UINT, LONG, ULONG, LONGLONG, ULONGLONG, INTP, UINTP\n\nAll `NPY_SIZEOF_{CTYPE}` constants have corresponding `NPY_BITSOF_{CTYPE}`\nconstants defined. The `NPY_BITSOF_{CTYPE}` constants provide the number of\nbits in the data type. Specifically, the available `{CTYPE}s` are\n\nBOOL, CHAR, SHORT, INT, LONG, LONGLONG, FLOAT, DOUBLE, LONGDOUBLE\n\nAll of the numeric data types (integer, floating point, and complex) have\nconstants that are defined to be a specific enumerated type number. Exactly\nwhich enumerated type a bit-width type refers to is platform dependent. In\nparticular, the constants available are `PyArray_{NAME}{BITS}` where `{NAME}`\nis INT, UINT, FLOAT, COMPLEX and `{BITS}` can be 8, 16, 32, 64, 80, 96, 128,\n160, 192, 256, and 512. Obviously not all bit-widths are available on all\nplatforms for all the kinds of numeric types. Commonly 8-, 16-, 32-, 64-bit\nintegers; 32-, 64-bit floats; and 64-, 128-bit complex types are available.\n\nThe constants NPY_INTP and NPY_UINTP refer to an enumerated integer type that\nis large enough to hold a pointer on the platform. Index arrays should always\nbe converted to NPY_INTP , because the dimension of the array is of type\nnpy_intp.\n\nThere are standard variable types for each of the numeric data types and the\nbool data type. Some of these are already available in the C-specification.\nYou can create variables in extension code with these types.\n\nunsigned char; The constants `NPY_FALSE` and `NPY_TRUE` are also defined.\n\nUnsigned versions of the integers can be defined by pre-pending a \u2018u\u2019 to the\nfront of the integer name.\n\nchar\n\nunsigned char\n\nshort\n\nunsigned short\n\nint\n\nunsigned int\n\n16-bit integer\n\n16-bit unsigned integer\n\n32-bit integer\n\n32-bit unsigned integer\n\n64-bit integer\n\n64-bit unsigned integer\n\nlong int\n\nunsigned long int\n\nlong long int\n\nunsigned long long int\n\nPy_intptr_t (an integer that is the size of a pointer on the platform).\n\nunsigned Py_intptr_t (an integer that is the size of a pointer on the\nplatform).\n\n16-bit float\n\n32-bit float\n\n32-bit complex float\n\n64-bit double\n\n64-bit complex double\n\nlong double\n\nlong complex double\n\ncomplex types are structures with .real and .imag members (in that order).\n\nThere are also typedefs for signed integers, unsigned integers, floating\npoint, and complex floating point types of specific bit- widths. The available\ntype names are\n\n`npy_int{bits}`, `npy_uint{bits}`, `npy_float{bits}`, and `npy_complex{bits}`\n\nwhere `{bits}` is the number of bits in the type and can be 8, 16, 32, 64,\n128, and 256 for integer types; 16, 32 , 64, 80, 96, 128, and 256 for\nfloating-point types; and 32, 64, 128, 160, 192, and 512 for complex-valued\ntypes. Which bit-widths are available is platform dependent. The bolded bit-\nwidths are usually available on all platforms.\n\nFor help in printing, the following strings are defined as the correct format\nspecifier in printf and related commands.\n\n"}, {"name": "enumerator NPY_UBYTE", "path": "reference/c-api/dtype#c.NPY_UBYTE", "type": "Data Type API", "text": "\n\n"}, {"name": "enumerator NPY_UINT", "path": "reference/c-api/dtype#c.NPY_UINT", "type": "Data Type API", "text": "\n\n"}, {"name": "enumerator NPY_UINT16", "path": "reference/c-api/dtype#c.NPY_UINT16", "type": "Data Type API", "text": "\nThe enumeration value for a 16-bit/2-byte unsigned integer.\n\n"}, {"name": "enumerator NPY_UINT32", "path": "reference/c-api/dtype#c.NPY_UINT32", "type": "Data Type API", "text": "\nThe enumeration value for a 32-bit/4-byte unsigned integer.\n\n"}, {"name": "enumerator NPY_UINT64", "path": "reference/c-api/dtype#c.NPY_UINT64", "type": "Data Type API", "text": "\nThe enumeration value for a 64-bit/8-byte unsigned integer.\n\n"}, {"name": "enumerator NPY_UINT8", "path": "reference/c-api/dtype#c.NPY_UINT8", "type": "Data Type API", "text": "\nThe enumeration value for an 8-bit/1-byte unsigned integer.\n\n"}, {"name": "enumerator NPY_UINTP", "path": "reference/c-api/dtype#c.NPY_UINTP", "type": "Data Type API", "text": "\nThe enumeration value for an unsigned integer type which is the same size as a\n(void *) pointer.\n\n"}, {"name": "enumerator NPY_ULONG", "path": "reference/c-api/dtype#c.NPY_ULONG", "type": "Data Type API", "text": "\nEquivalent to either NPY_UINT or NPY_ULONGLONG, depending on the platform.\n\n"}, {"name": "enumerator NPY_ULONGLONG", "path": "reference/c-api/dtype#c.NPY_ULONGLONG", "type": "Data Type API", "text": "\n\n"}, {"name": "enumerator NPY_UNICODE", "path": "reference/c-api/dtype#c.NPY_UNICODE", "type": "Data Type API", "text": "\nThe enumeration value for UCS4 strings of a selectable size. The strings have\na fixed maximum size within a given array.\n\n"}, {"name": "enumerator NPY_UNSAFE_CASTING", "path": "reference/c-api/array#c.NPY_CASTING.NPY_UNSAFE_CASTING", "type": "Array API", "text": "\nAllow any cast, no matter what kind of data loss may occur.\n\n"}, {"name": "enumerator NPY_USHORT", "path": "reference/c-api/dtype#c.NPY_USHORT", "type": "Data Type API", "text": "\n\n"}, {"name": "enumerator NPY_VOID", "path": "reference/c-api/dtype#c.NPY_VOID", "type": "Data Type API", "text": "\nPrimarily used to hold struct dtypes, but can contain arbitrary binary data.\n\n"}, {"name": "enumerator NPY_WRAP", "path": "reference/c-api/array#c.NPY_CLIPMODE.NPY_WRAP", "type": "Array API", "text": "\nWraps an index to the valid range if it is out of bounds.\n\n"}, {"name": "errstate.__call__()", "path": "reference/generated/numpy.errstate.__call__", "type": "numpy.errstate.__call__", "text": "\nmethod\n\nCall self as a function.\n\n"}, {"name": "exec_command", "path": "reference/generated/numpy.distutils.exec_command", "type": "numpy.distutils.exec_command", "text": "\nexec_command\n\nImplements exec_command function that is (almost) equivalent to\ncommands.getstatusoutput function but on NT, DOS systems the returned status\nis actually correct (though, the returned status values may be different by a\nfactor). In addition, exec_command takes keyword arguments for (re-)defining\nenvironment variables.\n\nProvides functions:\n\nin the modified environment.\n\nvariable PATH. Equivalent to posix `which` command.\n\nAuthor: Pearu Peterson <pearu@cens.ioc.ee> Created: 11 January 2003\n\nRequires: Python 2.x\n\nSuccessfully tested on:\n\nos.name\n\nsys.platform\n\ncomments\n\nposix\n\nlinux2\n\nDebian (sid) Linux, Python 2.1.3+, 2.2.3+, 2.3.3 PyCrust 0.9.3, Idle 1.0.2\n\nposix\n\nlinux2\n\nRed Hat 9 Linux, Python 2.1.3, 2.2.2, 2.3.2\n\nposix\n\nsunos5\n\nSunOS 5.9, Python 2.2, 2.3.2\n\nposix\n\ndarwin\n\nDarwin 7.2.0, Python 2.3\n\nnt\n\nwin32\n\nWindows Me Python 2.3(EE), Idle 1.0, PyCrust 0.7.2 Python 2.1.1 Idle 0.8\n\nnt\n\nwin32\n\nWindows 98, Python 2.1.1. Idle 0.8\n\nnt\n\nwin32\n\nCygwin 98-4.10, Python 2.1.1(MSC) - echo tests fail i.e. redefining\nenvironment variables may not work. FIXED: don\u2019t use cygwin echo! Comment:\nalso `cmd /c echo` will not work but redefining environment variables do work.\n\nposix\n\ncygwin\n\nCygwin 98-4.10, Python 2.3.3(cygming special)\n\nnt\n\nwin32\n\nWindows XP, Python 2.3.3\n\nKnown bugs:\n\n`exec_command`(command[, execute_in, ...])\n\nReturn (status,output) of executed command.\n\n`filepath_from_subprocess_output`(output)\n\nConvert `bytes` in the encoding used by a subprocess into a filesystem-\nappropriate `str`.\n\n`find_executable`(exe[, path, _cache])\n\nReturn full path of a executable or None.\n\n`forward_bytes_to_stdout`(val)\n\nForward bytes from a subprocess call to the console, without attempting to\ndecode them.\n\n`get_pythonexe`()\n\n`temp_file_name`()\n\n"}, {"name": "Extending", "path": "reference/random/extending", "type": "Examples of using Numba, Cython, CFFI", "text": "\nThe BitGenerators have been designed to be extendable using standard tools for\nhigh-performance Python \u2013 numba and Cython. The `Generator` object can also be\nused with user-provided BitGenerators as long as these export a small set of\nrequired functions.\n\nNumba can be used with either CTypes or CFFI. The current iteration of the\nBitGenerators all export a small set of functions through both interfaces.\n\nThis example shows how numba can be used to produce gaussian samples using a\npure Python implementation which is then compiled. The random numbers are\nprovided by `ctypes.next_double`.\n\nBoth CTypes and CFFI allow the more complicated distributions to be used\ndirectly in Numba after compiling the file distributions.c into a `DLL` or\n`so`. An example showing the use of a more complicated distribution is in the\n`examples` section below.\n\nCython can be used to unpack the `PyCapsule` provided by a BitGenerator. This\nexample uses `PCG64` and the example from above. The usual caveats for writing\nhigh-performance code using Cython \u2013 removing bounds checks and wrap around,\nproviding array alignment information \u2013 still apply.\n\nThe BitGenerator can also be directly accessed using the members of the\n`bitgen_t` struct.\n\nCython can be used to directly access the functions in\n`numpy/random/c_distributions.pxd`. This requires linking with the `npyrandom`\nlibrary located in `numpy/random/lib`.\n\nSee Extending numpy.random via Cython for the complete listings of these\nexamples and a minimal `setup.py` to build the c-extension modules.\n\nCFFI can be used to directly access the functions in\n`include/numpy/random/distributions.h`. Some \u201cmassaging\u201d of the header file is\nrequired:\n\nOnce the header is parsed by `ffi.cdef`, the functions can be accessed\ndirectly from the `_generator` shared object, using the `BitGenerator.cffi`\ninterface.\n\n`Generator` can be used with user-provided `BitGenerator`s. The simplest way\nto write a new BitGenerator is to examine the pyx file of one of the existing\nBitGenerators. The key structure that must be provided is the `capsule` which\ncontains a `PyCapsule` to a struct pointer of type `bitgen_t`,\n\nwhich provides 5 pointers. The first is an opaque pointer to the data\nstructure used by the BitGenerators. The next three are function pointers\nwhich return the next 64- and 32-bit unsigned integers, the next random double\nand the next raw value. This final function is used for testing and so can be\nset to the next 64-bit unsigned integer function if not needed. Functions\ninside `Generator` use this structure as in\n\n"}, {"name": "Extending numpy.random via Cython", "path": "reference/random/examples/cython/index", "type": "Cython", "text": "\n\n"}, {"name": "Extending via CFFI", "path": "reference/random/examples/cffi", "type": "CFFI", "text": "\n\n"}, {"name": "Extending via Numba", "path": "reference/random/examples/numba", "type": "Numba", "text": "\n\n"}, {"name": "Extending via Numba and CFFI", "path": "reference/random/examples/numba_cffi", "type": "CFFI + Numba", "text": "\n\n"}, {"name": "extending.pyx", "path": "reference/random/examples/cython/extending.pyx", "type": "Cython", "text": "\n\n"}, {"name": "extending_distributions.pyx", "path": "reference/random/examples/cython/extending_distributions.pyx", "type": "Cython", "text": "\n\n"}, {"name": "F2PY user guide and reference manual", "path": "f2py/index", "type": "F2PY user guide and reference manual", "text": "\nThe purpose of the `F2PY` \u2013Fortran to Python interface generator\u2013 utility is\nto provide a connection between Python and Fortran languages. F2PY is a part\nof NumPy (`numpy.f2py`) and also available as a standalone command line tool\n`f2py` when `numpy` is installed that facilitates creating/building Python\nC/API extension modules that make it possible\n\nfrom Python.\n\n"}, {"name": "fft.fft()", "path": "reference/generated/numpy.fft.fft", "type": "numpy.fft.fft", "text": "\nCompute the one-dimensional discrete Fourier Transform.\n\nThis function computes the one-dimensional n-point discrete Fourier Transform\n(DFT) with the efficient Fast Fourier Transform (FFT) algorithm [CT].\n\nInput array, can be complex.\n\nLength of the transformed axis of the output. If `n` is smaller than the\nlength of the input, the input is cropped. If it is larger, the input is\npadded with zeros. If `n` is not given, the length of the input along the axis\nspecified by `axis` is used.\n\nAxis over which to compute the FFT. If not given, the last axis is used.\n\nNew in version 1.10.0.\n\nNormalization mode (see `numpy.fft`). Default is \u201cbackward\u201d. Indicates which\ndirection of the forward/backward pair of transforms is scaled and with what\nnormalization factor.\n\nNew in version 1.20.0: The \u201cbackward\u201d, \u201cforward\u201d values were added.\n\nThe truncated or zero-padded input, transformed along the axis indicated by\n`axis`, or the last one if `axis` is not specified.\n\nIf `axis` is not a valid axis of `a`.\n\nSee also\n\nfor definition of the DFT and conventions used.\n\nThe inverse of `fft`.\n\nThe two-dimensional FFT.\n\nThe n-dimensional FFT.\n\nThe n-dimensional FFT of real input.\n\nFrequency bins for given FFT parameters.\n\nFFT (Fast Fourier Transform) refers to a way the discrete Fourier Transform\n(DFT) can be calculated efficiently, by using symmetries in the calculated\nterms. The symmetry is highest when `n` is a power of 2, and the transform is\ntherefore most efficient for these sizes.\n\nThe DFT is defined, with the conventions used in this implementation, in the\ndocumentation for the `numpy.fft` module.\n\nCooley, James W., and John W. Tukey, 1965, \u201cAn algorithm for the machine\ncalculation of complex Fourier series,\u201d Math. Comput. 19: 297-301.\n\nIn this example, real input has an FFT which is Hermitian, i.e., symmetric in\nthe real part and anti-symmetric in the imaginary part, as described in the\n`numpy.fft` documentation:\n\n"}, {"name": "fft.fft2()", "path": "reference/generated/numpy.fft.fft2", "type": "numpy.fft.fft2", "text": "\nCompute the 2-dimensional discrete Fourier Transform.\n\nThis function computes the n-dimensional discrete Fourier Transform over any\naxes in an M-dimensional array by means of the Fast Fourier Transform (FFT).\nBy default, the transform is computed over the last two axes of the input\narray, i.e., a 2-dimensional FFT.\n\nInput array, can be complex\n\nShape (length of each transformed axis) of the output (`s[0]` refers to axis\n0, `s[1]` to axis 1, etc.). This corresponds to `n` for `fft(x, n)`. Along\neach axis, if the given shape is smaller than that of the input, the input is\ncropped. If it is larger, the input is padded with zeros. if `s` is not given,\nthe shape of the input along the axes specified by `axes` is used.\n\nAxes over which to compute the FFT. If not given, the last two axes are used.\nA repeated index in `axes` means the transform over that axis is performed\nmultiple times. A one-element sequence means that a one-dimensional FFT is\nperformed.\n\nNew in version 1.10.0.\n\nNormalization mode (see `numpy.fft`). Default is \u201cbackward\u201d. Indicates which\ndirection of the forward/backward pair of transforms is scaled and with what\nnormalization factor.\n\nNew in version 1.20.0: The \u201cbackward\u201d, \u201cforward\u201d values were added.\n\nThe truncated or zero-padded input, transformed along the axes indicated by\n`axes`, or the last two axes if `axes` is not given.\n\nIf `s` and `axes` have different length, or `axes` not given and `len(s) !=\n2`.\n\nIf an element of `axes` is larger than than the number of axes of `a`.\n\nSee also\n\nOverall view of discrete Fourier transforms, with definitions and conventions\nused.\n\nThe inverse two-dimensional FFT.\n\nThe one-dimensional FFT.\n\nThe n-dimensional FFT.\n\nShifts zero-frequency terms to the center of the array. For two-dimensional\ninput, swaps first and third quadrants, and second and fourth quadrants.\n\n`fft2` is just `fftn` with a different default for `axes`.\n\nThe output, analogously to `fft`, contains the term for zero frequency in the\nlow-order corner of the transformed axes, the positive frequency terms in the\nfirst half of these axes, the term for the Nyquist frequency in the middle of\nthe axes and the negative frequency terms in the second half of the axes, in\norder of decreasingly negative frequency.\n\nSee `fftn` for details and a plotting example, and `numpy.fft` for definitions\nand conventions used.\n\n"}, {"name": "fft.fftfreq()", "path": "reference/generated/numpy.fft.fftfreq", "type": "numpy.fft.fftfreq", "text": "\nReturn the Discrete Fourier Transform sample frequencies.\n\nThe returned float array `f` contains the frequency bin centers in cycles per\nunit of the sample spacing (with zero at the start). For instance, if the\nsample spacing is in seconds, then the frequency unit is cycles/second.\n\nGiven a window length `n` and a sample spacing `d`:\n\nWindow length.\n\nSample spacing (inverse of the sampling rate). Defaults to 1.\n\nArray of length `n` containing the sample frequencies.\n\n"}, {"name": "fft.fftn()", "path": "reference/generated/numpy.fft.fftn", "type": "numpy.fft.fftn", "text": "\nCompute the N-dimensional discrete Fourier Transform.\n\nThis function computes the N-dimensional discrete Fourier Transform over any\nnumber of axes in an M-dimensional array by means of the Fast Fourier\nTransform (FFT).\n\nInput array, can be complex.\n\nShape (length of each transformed axis) of the output (`s[0]` refers to axis\n0, `s[1]` to axis 1, etc.). This corresponds to `n` for `fft(x, n)`. Along any\naxis, if the given shape is smaller than that of the input, the input is\ncropped. If it is larger, the input is padded with zeros. if `s` is not given,\nthe shape of the input along the axes specified by `axes` is used.\n\nAxes over which to compute the FFT. If not given, the last `len(s)` axes are\nused, or all axes if `s` is also not specified. Repeated indices in `axes`\nmeans that the transform over that axis is performed multiple times.\n\nNew in version 1.10.0.\n\nNormalization mode (see `numpy.fft`). Default is \u201cbackward\u201d. Indicates which\ndirection of the forward/backward pair of transforms is scaled and with what\nnormalization factor.\n\nNew in version 1.20.0: The \u201cbackward\u201d, \u201cforward\u201d values were added.\n\nThe truncated or zero-padded input, transformed along the axes indicated by\n`axes`, or by a combination of `s` and `a`, as explained in the parameters\nsection above.\n\nIf `s` and `axes` have different length.\n\nIf an element of `axes` is larger than than the number of axes of `a`.\n\nSee also\n\nOverall view of discrete Fourier transforms, with definitions and conventions\nused.\n\nThe inverse of `fftn`, the inverse n-dimensional FFT.\n\nThe one-dimensional FFT, with definitions and conventions used.\n\nThe n-dimensional FFT of real input.\n\nThe two-dimensional FFT.\n\nShifts zero-frequency terms to centre of array\n\nThe output, analogously to `fft`, contains the term for zero frequency in the\nlow-order corner of all axes, the positive frequency terms in the first half\nof all axes, the term for the Nyquist frequency in the middle of all axes and\nthe negative frequency terms in the second half of all axes, in order of\ndecreasingly negative frequency.\n\nSee `numpy.fft` for details, definitions and conventions used.\n\n"}, {"name": "fft.fftshift()", "path": "reference/generated/numpy.fft.fftshift", "type": "numpy.fft.fftshift", "text": "\nShift the zero-frequency component to the center of the spectrum.\n\nThis function swaps half-spaces for all axes listed (defaults to all). Note\nthat `y[0]` is the Nyquist component only if `len(x)` is even.\n\nInput array.\n\nAxes over which to shift. Default is None, which shifts all axes.\n\nThe shifted array.\n\nSee also\n\nThe inverse of `fftshift`.\n\nShift the zero-frequency component only along the second axis:\n\n"}, {"name": "fft.hfft()", "path": "reference/generated/numpy.fft.hfft", "type": "numpy.fft.hfft", "text": "\nCompute the FFT of a signal that has Hermitian symmetry, i.e., a real\nspectrum.\n\nThe input array.\n\nLength of the transformed axis of the output. For `n` output points, `n//2 +\n1` input points are necessary. If the input is longer than this, it is\ncropped. If it is shorter than this, it is padded with zeros. If `n` is not\ngiven, it is taken to be `2*(m-1)` where `m` is the length of the input along\nthe axis specified by `axis`.\n\nAxis over which to compute the FFT. If not given, the last axis is used.\n\nNew in version 1.10.0.\n\nNormalization mode (see `numpy.fft`). Default is \u201cbackward\u201d. Indicates which\ndirection of the forward/backward pair of transforms is scaled and with what\nnormalization factor.\n\nNew in version 1.20.0: The \u201cbackward\u201d, \u201cforward\u201d values were added.\n\nThe truncated or zero-padded input, transformed along the axis indicated by\n`axis`, or the last one if `axis` is not specified. The length of the\ntransformed axis is `n`, or, if `n` is not given, `2*m - 2` where `m` is the\nlength of the transformed axis of the input. To get an odd number of output\npoints, `n` must be specified, for instance as `2*m - 1` in the typical case,\n\nIf `axis` is not a valid axis of `a`.\n\nSee also\n\nCompute the one-dimensional FFT for real input.\n\nThe inverse of `hfft`.\n\n`hfft`/`ihfft` are a pair analogous to `rfft`/`irfft`, but for the opposite\ncase: here the signal has Hermitian symmetry in the time domain and is real in\nthe frequency domain. So here it\u2019s `hfft` for which you must supply the length\nof the result if it is to be odd.\n\nThe correct interpretation of the hermitian input depends on the length of the\noriginal data, as given by `n`. This is because each input shape could\ncorrespond to either an odd or even length signal. By default, `hfft` assumes\nan even output length which puts the last entry at the Nyquist frequency;\naliasing with its symmetric counterpart. By Hermitian symmetry, the value is\nthus treated as purely real. To avoid losing information, the shape of the\nfull signal must be given.\n\n"}, {"name": "fft.ifft()", "path": "reference/generated/numpy.fft.ifft", "type": "numpy.fft.ifft", "text": "\nCompute the one-dimensional inverse discrete Fourier Transform.\n\nThis function computes the inverse of the one-dimensional n-point discrete\nFourier transform computed by `fft`. In other words, `ifft(fft(a)) == a` to\nwithin numerical accuracy. For a general description of the algorithm and\ndefinitions, see `numpy.fft`.\n\nThe input should be ordered in the same way as is returned by `fft`, i.e.,\n\nFor an even number of input points, `A[n//2]` represents the sum of the values\nat the positive and negative Nyquist frequencies, as the two are aliased\ntogether. See `numpy.fft` for details.\n\nInput array, can be complex.\n\nLength of the transformed axis of the output. If `n` is smaller than the\nlength of the input, the input is cropped. If it is larger, the input is\npadded with zeros. If `n` is not given, the length of the input along the axis\nspecified by `axis` is used. See notes about padding issues.\n\nAxis over which to compute the inverse DFT. If not given, the last axis is\nused.\n\nNew in version 1.10.0.\n\nNormalization mode (see `numpy.fft`). Default is \u201cbackward\u201d. Indicates which\ndirection of the forward/backward pair of transforms is scaled and with what\nnormalization factor.\n\nNew in version 1.20.0: The \u201cbackward\u201d, \u201cforward\u201d values were added.\n\nThe truncated or zero-padded input, transformed along the axis indicated by\n`axis`, or the last one if `axis` is not specified.\n\nIf `axis` is not a valid axis of `a`.\n\nSee also\n\nAn introduction, with definitions and general explanations.\n\nThe one-dimensional (forward) FFT, of which `ifft` is the inverse\n\nThe two-dimensional inverse FFT.\n\nThe n-dimensional inverse FFT.\n\nIf the input parameter `n` is larger than the size of the input, the input is\npadded by appending zeros at the end. Even though this is the common approach,\nit might lead to surprising results. If a different padding is desired, it\nmust be performed before calling `ifft`.\n\nCreate and plot a band-limited signal with random phases:\n\n"}, {"name": "fft.ifft2()", "path": "reference/generated/numpy.fft.ifft2", "type": "numpy.fft.ifft2", "text": "\nCompute the 2-dimensional inverse discrete Fourier Transform.\n\nThis function computes the inverse of the 2-dimensional discrete Fourier\nTransform over any number of axes in an M-dimensional array by means of the\nFast Fourier Transform (FFT). In other words, `ifft2(fft2(a)) == a` to within\nnumerical accuracy. By default, the inverse transform is computed over the\nlast two axes of the input array.\n\nThe input, analogously to `ifft`, should be ordered in the same way as is\nreturned by `fft2`, i.e. it should have the term for zero frequency in the\nlow-order corner of the two axes, the positive frequency terms in the first\nhalf of these axes, the term for the Nyquist frequency in the middle of the\naxes and the negative frequency terms in the second half of both axes, in\norder of decreasingly negative frequency.\n\nInput array, can be complex.\n\nShape (length of each axis) of the output (`s[0]` refers to axis 0, `s[1]` to\naxis 1, etc.). This corresponds to `n` for `ifft(x, n)`. Along each axis, if\nthe given shape is smaller than that of the input, the input is cropped. If it\nis larger, the input is padded with zeros. if `s` is not given, the shape of\nthe input along the axes specified by `axes` is used. See notes for issue on\n`ifft` zero padding.\n\nAxes over which to compute the FFT. If not given, the last two axes are used.\nA repeated index in `axes` means the transform over that axis is performed\nmultiple times. A one-element sequence means that a one-dimensional FFT is\nperformed.\n\nNew in version 1.10.0.\n\nNormalization mode (see `numpy.fft`). Default is \u201cbackward\u201d. Indicates which\ndirection of the forward/backward pair of transforms is scaled and with what\nnormalization factor.\n\nNew in version 1.20.0: The \u201cbackward\u201d, \u201cforward\u201d values were added.\n\nThe truncated or zero-padded input, transformed along the axes indicated by\n`axes`, or the last two axes if `axes` is not given.\n\nIf `s` and `axes` have different length, or `axes` not given and `len(s) !=\n2`.\n\nIf an element of `axes` is larger than than the number of axes of `a`.\n\nSee also\n\nOverall view of discrete Fourier transforms, with definitions and conventions\nused.\n\nThe forward 2-dimensional FFT, of which `ifft2` is the inverse.\n\nThe inverse of the n-dimensional FFT.\n\nThe one-dimensional FFT.\n\nThe one-dimensional inverse FFT.\n\n`ifft2` is just `ifftn` with a different default for `axes`.\n\nSee `ifftn` for details and a plotting example, and `numpy.fft` for definition\nand conventions used.\n\nZero-padding, analogously with `ifft`, is performed by appending zeros to the\ninput along the specified dimension. Although this is the common approach, it\nmight lead to surprising results. If another form of zero padding is desired,\nit must be performed before `ifft2` is called.\n\n"}, {"name": "fft.ifftn()", "path": "reference/generated/numpy.fft.ifftn", "type": "numpy.fft.ifftn", "text": "\nCompute the N-dimensional inverse discrete Fourier Transform.\n\nThis function computes the inverse of the N-dimensional discrete Fourier\nTransform over any number of axes in an M-dimensional array by means of the\nFast Fourier Transform (FFT). In other words, `ifftn(fftn(a)) == a` to within\nnumerical accuracy. For a description of the definitions and conventions used,\nsee `numpy.fft`.\n\nThe input, analogously to `ifft`, should be ordered in the same way as is\nreturned by `fftn`, i.e. it should have the term for zero frequency in all\naxes in the low-order corner, the positive frequency terms in the first half\nof all axes, the term for the Nyquist frequency in the middle of all axes and\nthe negative frequency terms in the second half of all axes, in order of\ndecreasingly negative frequency.\n\nInput array, can be complex.\n\nShape (length of each transformed axis) of the output (`s[0]` refers to axis\n0, `s[1]` to axis 1, etc.). This corresponds to `n` for `ifft(x, n)`. Along\nany axis, if the given shape is smaller than that of the input, the input is\ncropped. If it is larger, the input is padded with zeros. if `s` is not given,\nthe shape of the input along the axes specified by `axes` is used. See notes\nfor issue on `ifft` zero padding.\n\nAxes over which to compute the IFFT. If not given, the last `len(s)` axes are\nused, or all axes if `s` is also not specified. Repeated indices in `axes`\nmeans that the inverse transform over that axis is performed multiple times.\n\nNew in version 1.10.0.\n\nNormalization mode (see `numpy.fft`). Default is \u201cbackward\u201d. Indicates which\ndirection of the forward/backward pair of transforms is scaled and with what\nnormalization factor.\n\nNew in version 1.20.0: The \u201cbackward\u201d, \u201cforward\u201d values were added.\n\nThe truncated or zero-padded input, transformed along the axes indicated by\n`axes`, or by a combination of `s` or `a`, as explained in the parameters\nsection above.\n\nIf `s` and `axes` have different length.\n\nIf an element of `axes` is larger than than the number of axes of `a`.\n\nSee also\n\nOverall view of discrete Fourier transforms, with definitions and conventions\nused.\n\nThe forward n-dimensional FFT, of which `ifftn` is the inverse.\n\nThe one-dimensional inverse FFT.\n\nThe two-dimensional inverse FFT.\n\nUndoes `fftshift`, shifts zero-frequency terms to beginning of array.\n\nSee `numpy.fft` for definitions and conventions used.\n\nZero-padding, analogously with `ifft`, is performed by appending zeros to the\ninput along the specified dimension. Although this is the common approach, it\nmight lead to surprising results. If another form of zero padding is desired,\nit must be performed before `ifftn` is called.\n\nCreate and plot an image with band-limited frequency content:\n\n"}, {"name": "fft.ifftshift()", "path": "reference/generated/numpy.fft.ifftshift", "type": "numpy.fft.ifftshift", "text": "\nThe inverse of `fftshift`. Although identical for even-length `x`, the\nfunctions differ by one sample for odd-length `x`.\n\nInput array.\n\nAxes over which to calculate. Defaults to None, which shifts all axes.\n\nThe shifted array.\n\nSee also\n\nShift zero-frequency component to the center of the spectrum.\n\n"}, {"name": "fft.ihfft()", "path": "reference/generated/numpy.fft.ihfft", "type": "numpy.fft.ihfft", "text": "\nCompute the inverse FFT of a signal that has Hermitian symmetry.\n\nInput array.\n\nLength of the inverse FFT, the number of points along transformation axis in\nthe input to use. If `n` is smaller than the length of the input, the input is\ncropped. If it is larger, the input is padded with zeros. If `n` is not given,\nthe length of the input along the axis specified by `axis` is used.\n\nAxis over which to compute the inverse FFT. If not given, the last axis is\nused.\n\nNew in version 1.10.0.\n\nNormalization mode (see `numpy.fft`). Default is \u201cbackward\u201d. Indicates which\ndirection of the forward/backward pair of transforms is scaled and with what\nnormalization factor.\n\nNew in version 1.20.0: The \u201cbackward\u201d, \u201cforward\u201d values were added.\n\nThe truncated or zero-padded input, transformed along the axis indicated by\n`axis`, or the last one if `axis` is not specified. The length of the\ntransformed axis is `n//2 + 1`.\n\nSee also\n\n`hfft`/`ihfft` are a pair analogous to `rfft`/`irfft`, but for the opposite\ncase: here the signal has Hermitian symmetry in the time domain and is real in\nthe frequency domain. So here it\u2019s `hfft` for which you must supply the length\nof the result if it is to be odd:\n\n"}, {"name": "fft.irfft()", "path": "reference/generated/numpy.fft.irfft", "type": "numpy.fft.irfft", "text": "\nComputes the inverse of `rfft`.\n\nThis function computes the inverse of the one-dimensional n-point discrete\nFourier Transform of real input computed by `rfft`. In other words,\n`irfft(rfft(a), len(a)) == a` to within numerical accuracy. (See Notes below\nfor why `len(a)` is necessary here.)\n\nThe input is expected to be in the form returned by `rfft`, i.e. the real\nzero-frequency term followed by the complex positive frequency terms in order\nof increasing frequency. Since the discrete Fourier Transform of real input is\nHermitian-symmetric, the negative frequency terms are taken to be the complex\nconjugates of the corresponding positive frequency terms.\n\nThe input array.\n\nLength of the transformed axis of the output. For `n` output points, `n//2+1`\ninput points are necessary. If the input is longer than this, it is cropped.\nIf it is shorter than this, it is padded with zeros. If `n` is not given, it\nis taken to be `2*(m-1)` where `m` is the length of the input along the axis\nspecified by `axis`.\n\nAxis over which to compute the inverse FFT. If not given, the last axis is\nused.\n\nNew in version 1.10.0.\n\nNormalization mode (see `numpy.fft`). Default is \u201cbackward\u201d. Indicates which\ndirection of the forward/backward pair of transforms is scaled and with what\nnormalization factor.\n\nNew in version 1.20.0: The \u201cbackward\u201d, \u201cforward\u201d values were added.\n\nThe truncated or zero-padded input, transformed along the axis indicated by\n`axis`, or the last one if `axis` is not specified. The length of the\ntransformed axis is `n`, or, if `n` is not given, `2*(m-1)` where `m` is the\nlength of the transformed axis of the input. To get an odd number of output\npoints, `n` must be specified.\n\nIf `axis` is not a valid axis of `a`.\n\nSee also\n\nFor definition of the DFT and conventions used.\n\nThe one-dimensional FFT of real input, of which `irfft` is inverse.\n\nThe one-dimensional FFT.\n\nThe inverse of the two-dimensional FFT of real input.\n\nThe inverse of the n-dimensional FFT of real input.\n\nReturns the real valued `n`-point inverse discrete Fourier transform of `a`,\nwhere `a` contains the non-negative frequency terms of a Hermitian-symmetric\nsequence. `n` is the length of the result, not the input.\n\nIf you specify an `n` such that `a` must be zero-padded or truncated, the\nextra/removed values will be added/removed at high frequencies. One can thus\nresample a series to `m` points via Fourier interpolation by: `a_resamp =\nirfft(rfft(a), m)`.\n\nThe correct interpretation of the hermitian input depends on the length of the\noriginal data, as given by `n`. This is because each input shape could\ncorrespond to either an odd or even length signal. By default, `irfft` assumes\nan even output length which puts the last entry at the Nyquist frequency;\naliasing with its symmetric counterpart. By Hermitian symmetry, the value is\nthus treated as purely real. To avoid losing information, the correct length\nof the real input must be given.\n\nNotice how the last term in the input to the ordinary `ifft` is the complex\nconjugate of the second term, and the output has zero imaginary part\neverywhere. When calling `irfft`, the negative frequencies are not specified,\nand the output array is purely real.\n\n"}, {"name": "fft.irfft2()", "path": "reference/generated/numpy.fft.irfft2", "type": "numpy.fft.irfft2", "text": "\nComputes the inverse of `rfft2`.\n\nThe input array\n\nShape of the real output to the inverse FFT.\n\nThe axes over which to compute the inverse fft. Default is the last two axes.\n\nNew in version 1.10.0.\n\nNormalization mode (see `numpy.fft`). Default is \u201cbackward\u201d. Indicates which\ndirection of the forward/backward pair of transforms is scaled and with what\nnormalization factor.\n\nNew in version 1.20.0: The \u201cbackward\u201d, \u201cforward\u201d values were added.\n\nThe result of the inverse real 2-D FFT.\n\nSee also\n\nThe forward two-dimensional FFT of real input, of which `irfft2` is the\ninverse.\n\nThe one-dimensional FFT for real input.\n\nThe inverse of the one-dimensional FFT of real input.\n\nCompute the inverse of the N-dimensional FFT of real input.\n\nThis is really `irfftn` with different defaults. For more details see\n`irfftn`.\n\n"}, {"name": "fft.irfftn()", "path": "reference/generated/numpy.fft.irfftn", "type": "numpy.fft.irfftn", "text": "\nComputes the inverse of `rfftn`.\n\nThis function computes the inverse of the N-dimensional discrete Fourier\nTransform for real input over any number of axes in an M-dimensional array by\nmeans of the Fast Fourier Transform (FFT). In other words, `irfftn(rfftn(a),\na.shape) == a` to within numerical accuracy. (The `a.shape` is necessary like\n`len(a)` is for `irfft`, and for the same reason.)\n\nThe input should be ordered in the same way as is returned by `rfftn`, i.e. as\nfor `irfft` for the final transformation axis, and as for `ifftn` along all\nthe other axes.\n\nInput array.\n\nShape (length of each transformed axis) of the output (`s[0]` refers to axis\n0, `s[1]` to axis 1, etc.). `s` is also the number of input points used along\nthis axis, except for the last axis, where `s[-1]//2+1` points of the input\nare used. Along any axis, if the shape indicated by `s` is smaller than that\nof the input, the input is cropped. If it is larger, the input is padded with\nzeros. If `s` is not given, the shape of the input along the axes specified by\naxes is used. Except for the last axis which is taken to be `2*(m-1)` where\n`m` is the length of the input along that axis.\n\nAxes over which to compute the inverse FFT. If not given, the last `len(s)`\naxes are used, or all axes if `s` is also not specified. Repeated indices in\n`axes` means that the inverse transform over that axis is performed multiple\ntimes.\n\nNew in version 1.10.0.\n\nNormalization mode (see `numpy.fft`). Default is \u201cbackward\u201d. Indicates which\ndirection of the forward/backward pair of transforms is scaled and with what\nnormalization factor.\n\nNew in version 1.20.0: The \u201cbackward\u201d, \u201cforward\u201d values were added.\n\nThe truncated or zero-padded input, transformed along the axes indicated by\n`axes`, or by a combination of `s` or `a`, as explained in the parameters\nsection above. The length of each transformed axis is as given by the\ncorresponding element of `s`, or the length of the input in every axis except\nfor the last one if `s` is not given. In the final transformed axis the length\nof the output when `s` is not given is `2*(m-1)` where `m` is the length of\nthe final transformed axis of the input. To get an odd number of output points\nin the final axis, `s` must be specified.\n\nIf `s` and `axes` have different length.\n\nIf an element of `axes` is larger than than the number of axes of `a`.\n\nSee also\n\nThe forward n-dimensional FFT of real input, of which `ifftn` is the inverse.\n\nThe one-dimensional FFT, with definitions and conventions used.\n\nThe inverse of the one-dimensional FFT of real input.\n\nThe inverse of the two-dimensional FFT of real input.\n\nSee `fft` for definitions and conventions used.\n\nSee `rfft` for definitions and conventions used for real input.\n\nThe correct interpretation of the hermitian input depends on the shape of the\noriginal data, as given by `s`. This is because each input shape could\ncorrespond to either an odd or even length signal. By default, `irfftn`\nassumes an even output length which puts the last entry at the Nyquist\nfrequency; aliasing with its symmetric counterpart. When performing the final\ncomplex to real transform, the last value is thus treated as purely real. To\navoid losing information, the correct shape of the real input must be given.\n\n"}, {"name": "fft.rfft()", "path": "reference/generated/numpy.fft.rfft", "type": "numpy.fft.rfft", "text": "\nCompute the one-dimensional discrete Fourier Transform for real input.\n\nThis function computes the one-dimensional n-point discrete Fourier Transform\n(DFT) of a real-valued array by means of an efficient algorithm called the\nFast Fourier Transform (FFT).\n\nInput array\n\nNumber of points along transformation axis in the input to use. If `n` is\nsmaller than the length of the input, the input is cropped. If it is larger,\nthe input is padded with zeros. If `n` is not given, the length of the input\nalong the axis specified by `axis` is used.\n\nAxis over which to compute the FFT. If not given, the last axis is used.\n\nNew in version 1.10.0.\n\nNormalization mode (see `numpy.fft`). Default is \u201cbackward\u201d. Indicates which\ndirection of the forward/backward pair of transforms is scaled and with what\nnormalization factor.\n\nNew in version 1.20.0: The \u201cbackward\u201d, \u201cforward\u201d values were added.\n\nThe truncated or zero-padded input, transformed along the axis indicated by\n`axis`, or the last one if `axis` is not specified. If `n` is even, the length\nof the transformed axis is `(n/2)+1`. If `n` is odd, the length is `(n+1)/2`.\n\nIf `axis` is not a valid axis of `a`.\n\nSee also\n\nFor definition of the DFT and conventions used.\n\nThe inverse of `rfft`.\n\nThe one-dimensional FFT of general (complex) input.\n\nThe n-dimensional FFT.\n\nThe n-dimensional FFT of real input.\n\nWhen the DFT is computed for purely real input, the output is Hermitian-\nsymmetric, i.e. the negative frequency terms are just the complex conjugates\nof the corresponding positive-frequency terms, and the negative-frequency\nterms are therefore redundant. This function does not compute the negative\nfrequency terms, and the length of the transformed axis of the output is\ntherefore `n//2 + 1`.\n\nWhen `A = rfft(a)` and fs is the sampling frequency, `A[0]` contains the zero-\nfrequency term 0*fs, which is real due to Hermitian symmetry.\n\nIf `n` is even, `A[-1]` contains the term representing both positive and\nnegative Nyquist frequency (+fs/2 and -fs/2), and must also be purely real. If\n`n` is odd, there is no term at fs/2; `A[-1]` contains the largest positive\nfrequency (fs/2*(n-1)/n), and is complex in the general case.\n\nIf the input `a` contains an imaginary part, it is silently discarded.\n\nNotice how the final element of the `fft` output is the complex conjugate of\nthe second element, for real input. For `rfft`, this symmetry is exploited to\ncompute only the non-negative frequency terms.\n\n"}, {"name": "fft.rfft2()", "path": "reference/generated/numpy.fft.rfft2", "type": "numpy.fft.rfft2", "text": "\nCompute the 2-dimensional FFT of a real array.\n\nInput array, taken to be real.\n\nShape of the FFT.\n\nAxes over which to compute the FFT.\n\nNew in version 1.10.0.\n\nNormalization mode (see `numpy.fft`). Default is \u201cbackward\u201d. Indicates which\ndirection of the forward/backward pair of transforms is scaled and with what\nnormalization factor.\n\nNew in version 1.20.0: The \u201cbackward\u201d, \u201cforward\u201d values were added.\n\nThe result of the real 2-D FFT.\n\nSee also\n\nCompute the N-dimensional discrete Fourier Transform for real input.\n\nThis is really just `rfftn` with different default behavior. For more details\nsee `rfftn`.\n\n"}, {"name": "fft.rfftfreq()", "path": "reference/generated/numpy.fft.rfftfreq", "type": "numpy.fft.rfftfreq", "text": "\nReturn the Discrete Fourier Transform sample frequencies (for usage with rfft,\nirfft).\n\nThe returned float array `f` contains the frequency bin centers in cycles per\nunit of the sample spacing (with zero at the start). For instance, if the\nsample spacing is in seconds, then the frequency unit is cycles/second.\n\nGiven a window length `n` and a sample spacing `d`:\n\nUnlike `fftfreq` (but like `scipy.fftpack.rfftfreq`) the Nyquist frequency\ncomponent is considered to be positive.\n\nWindow length.\n\nSample spacing (inverse of the sampling rate). Defaults to 1.\n\nArray of length `n//2 + 1` containing the sample frequencies.\n\n"}, {"name": "fft.rfftn()", "path": "reference/generated/numpy.fft.rfftn", "type": "numpy.fft.rfftn", "text": "\nCompute the N-dimensional discrete Fourier Transform for real input.\n\nThis function computes the N-dimensional discrete Fourier Transform over any\nnumber of axes in an M-dimensional real array by means of the Fast Fourier\nTransform (FFT). By default, all axes are transformed, with the real transform\nperformed over the last axis, while the remaining transforms are complex.\n\nInput array, taken to be real.\n\nShape (length along each transformed axis) to use from the input. (`s[0]`\nrefers to axis 0, `s[1]` to axis 1, etc.). The final element of `s`\ncorresponds to `n` for `rfft(x, n)`, while for the remaining axes, it\ncorresponds to `n` for `fft(x, n)`. Along any axis, if the given shape is\nsmaller than that of the input, the input is cropped. If it is larger, the\ninput is padded with zeros. if `s` is not given, the shape of the input along\nthe axes specified by `axes` is used.\n\nAxes over which to compute the FFT. If not given, the last `len(s)` axes are\nused, or all axes if `s` is also not specified.\n\nNew in version 1.10.0.\n\nNormalization mode (see `numpy.fft`). Default is \u201cbackward\u201d. Indicates which\ndirection of the forward/backward pair of transforms is scaled and with what\nnormalization factor.\n\nNew in version 1.20.0: The \u201cbackward\u201d, \u201cforward\u201d values were added.\n\nThe truncated or zero-padded input, transformed along the axes indicated by\n`axes`, or by a combination of `s` and `a`, as explained in the parameters\nsection above. The length of the last axis transformed will be `s[-1]//2+1`,\nwhile the remaining transformed axes will have lengths according to `s`, or\nunchanged from the input.\n\nIf `s` and `axes` have different length.\n\nIf an element of `axes` is larger than than the number of axes of `a`.\n\nSee also\n\nThe inverse of `rfftn`, i.e. the inverse of the n-dimensional FFT of real\ninput.\n\nThe one-dimensional FFT, with definitions and conventions used.\n\nThe one-dimensional FFT of real input.\n\nThe n-dimensional FFT.\n\nThe two-dimensional FFT of real input.\n\nThe transform for real input is performed over the last transformation axis,\nas by `rfft`, then the transform over the remaining axes is performed as by\n`fftn`. The order of the output is as for `rfft` for the final transformation\naxis, and as for `fftn` for the remaining transformation axes.\n\nSee `fft` for details, definitions and conventions used.\n\n"}, {"name": "final class numpy.typing.NBitBase", "path": "reference/typing#numpy.typing.NBitBase", "type": "Typing ( \n    \n     numpy.typing\n    \n    )", "text": "\nA type representing `numpy.number` precision during static type checking.\n\nUsed exclusively for the purpose static type checking, `NBitBase` represents\nthe base of a hierarchical set of subclasses. Each subsequent subclass is\nherein used for representing a lower level of precision, e.g. `64Bit > 32Bit >\n16Bit`.\n\nNew in version 1.20.\n\nBelow is a typical usage example: `NBitBase` is herein used for annotating a\nfunction that takes a float and integer of arbitrary precision as arguments\nand returns a new float of whichever precision is largest (e.g. `np.float16 +\nnp.int64 -> np.float64`).\n\n"}, {"name": "flatiter.base", "path": "reference/generated/numpy.flatiter.base", "type": "Indexing routines", "text": "\nattribute\n\nA reference to the array that is iterated over.\n\n"}, {"name": "flatiter.coords", "path": "reference/generated/numpy.flatiter.coords", "type": "Indexing routines", "text": "\nattribute\n\nAn N-dimensional tuple of current coordinates.\n\n"}, {"name": "flatiter.copy()", "path": "reference/generated/numpy.flatiter.copy", "type": "numpy.flatiter.copy", "text": "\nmethod\n\nGet a copy of the iterator as a 1-D array.\n\n"}, {"name": "flatiter.index", "path": "reference/generated/numpy.flatiter.index", "type": "Indexing routines", "text": "\nattribute\n\nCurrent flat index into the array.\n\n"}, {"name": "float npy_half_to_float()", "path": "reference/c-api/coremath#c.npy_half_to_float", "type": "NumPy core libraries", "text": "\nConverts a half-precision float to a single-precision float.\n\n"}, {"name": "float random_gamma_f()", "path": "reference/random/c-api#c.random_gamma_f", "type": "C API for random", "text": "\n\n"}, {"name": "float random_standard_exponential_f()", "path": "reference/random/c-api#c.random_standard_exponential_f", "type": "C API for random", "text": "\n\n"}, {"name": "float random_standard_gamma_f()", "path": "reference/random/c-api#c.random_standard_gamma_f", "type": "C API for random", "text": "\n\n"}, {"name": "float random_standard_normal_f()", "path": "reference/random/c-api#c.random_standard_normal_f", "type": "C API for random", "text": "\n\n"}, {"name": "float random_standard_uniform_f()", "path": "reference/random/c-api#c.random_standard_uniform_f", "type": "C API for random", "text": "\n\n"}, {"name": "Floating point error handling", "path": "reference/routines.err", "type": "Floating point error handling", "text": "\n`seterr`([all, divide, over, under, invalid])\n\nSet how floating-point errors are handled.\n\n`geterr`()\n\nGet the current way of handling floating-point errors.\n\n`seterrcall`(func)\n\nSet the floating-point error callback function or log object.\n\n`geterrcall`()\n\nReturn the current callback function used on floating-point errors.\n\n`errstate`(**kwargs)\n\nContext manager for floating-point error handling.\n\n`seterrobj`(errobj, /)\n\nSet the object that defines floating-point error handling.\n\n`geterrobj`()\n\nReturn the current object that defines floating-point error handling.\n\n"}, {"name": "For downstream package authors", "path": "user/depending_on_numpy", "type": "User Guide", "text": "\nThis document aims to explain some best practices for authoring a package that\ndepends on NumPy.\n\nNumPy uses a standard, PEP 440 compliant, versioning scheme:\n`major.minor.bugfix`. A major release is highly unusual (NumPy is still at\nversion `1.xx`) and if it happens it will likely indicate an ABI break. Minor\nversions are released regularly, typically every 6 months. Minor versions\ncontain new features, deprecations, and removals of previously deprecated\ncode. Bugfix releases are made even more frequently; they do not contain any\nnew features or deprecations.\n\nIt is important to know that NumPy, like Python itself and most other well\nknown scientific Python projects, does not use semantic versioning. Instead,\nbackwards incompatible API changes require deprecation warnings for at least\ntwo releases. For more details, see NEP 23 \u2014 Backwards compatibility and\ndeprecation policy.\n\nNumPy has both a Python API and a C API. The C API can be used directly or via\nCython, f2py, or other such tools. If your package uses the C API, then ABI\n(application binary interface) stability of NumPy is important. NumPy\u2019s ABI is\nforward but not backward compatible. This means: binaries compiled against a\ngiven version of NumPy will still run correctly with newer NumPy versions, but\nnot with older versions.\n\nFor large, actively maintained packages that depend on NumPy, we recommend\ntesting against the development version of NumPy in CI. To make this easy,\nnightly builds are provided as wheels at https://anaconda.org/scipy-wheels-\nnightly/. This helps detect regressions in NumPy that need fixing before the\nnext NumPy release. Furthermore, we recommend to raise errors on warnings in\nCI for this job, either all warnings or otherwise at least\n`DeprecationWarning` and `FutureWarning`. This gives you an early warning\nabout changes in NumPy to adapt your code.\n\nIf a package either uses the NumPy C API directly or it uses some other tool\nthat depends on it like Cython or Pythran, NumPy is a build-time dependency of\nthe package. Because the NumPy ABI is only forward compatible, you must build\nyour own binaries (wheels or other package formats) against the lowest NumPy\nversion that you support (or an even older version).\n\nPicking the correct NumPy version to build against for each Python version and\nplatform can get complicated. There are a couple of ways to do this. Build-\ntime dependencies are specified in `pyproject.toml` (see PEP 517), which is\nthe file used to build wheels by PEP 517 compliant tools (e.g., when using\n`pip wheel`).\n\nYou can specify everything manually in `pyproject.toml`, or you can instead\nrely on the oldest-supported-numpy metapackage. `oldest-supported-numpy` will\nspecify the correct NumPy version at build time for wheels, taking into\naccount Python version, Python implementation (CPython or PyPy), operating\nsystem and hardware platform. It will specify the oldest NumPy version that\nsupports that combination of characteristics. Note: for platforms for which\nNumPy provides wheels on PyPI, it will be the first version with wheels (even\nif some older NumPy version happens to build).\n\nFor conda-forge it\u2019s a little less complicated: there\u2019s dedicated handling for\nNumPy in build-time and runtime dependencies, so typically this is enough (see\nhere for docs):\n\nNote\n\n`pip` has `--no-use-pep517` and `--no-build-isolation` flags that may ignore\n`pyproject.toml` or treat it differently - if users use those flags, they are\nresponsible for installing the correct build dependencies themselves.\n\n`conda` will always use `-no-build-isolation`; dependencies for conda builds\nare given in the conda recipe (`meta.yaml`), the ones in `pyproject.toml` have\nno effect.\n\nPlease do not use `setup_requires` (it is deprecated and may invoke\n`easy_install`).\n\nBecause for NumPy you have to care about ABI compatibility, you specify the\nversion with `==` to the lowest supported version. For your other build\ndependencies you can probably be looser, however it\u2019s still important to set\nlower and upper bounds for each dependency. It\u2019s fine to specify either a\nrange or a specific version for a dependency like `wheel` or `setuptools`.\nIt\u2019s recommended to set the upper bound of the range to the latest already\nreleased version of `wheel` and `setuptools` \\- this prevents future releases\nfrom breaking your packages on PyPI.\n\nNumPy itself and many core scientific Python packages have agreed on a\nschedule for dropping support for old Python and NumPy versions: NEP 29 \u2014\nRecommend Python and NumPy version support as a community policy standard. We\nrecommend all packages depending on NumPy to follow the recommendations in NEP\n29.\n\nFor run-time dependencies, you specify the range of versions in\n`install_requires` in `setup.py` (assuming you use `numpy.distutils` or\n`setuptools` to build). Getting the upper bound right for NumPy is slightly\ntricky. If we don\u2019t set any bound, a too-new version will be pulled in a few\nyears down the line, and NumPy may have deprecated and removed some API that\nyour package depended on by then. On the other hand if you set the upper bound\nto the newest already-released version, then as soon as a new NumPy version is\nreleased there will be no matching version of your package that works with it.\n\nWhat to do here depends on your release frequency. Given that NumPy releases\ncome in a 6-monthly cadence and that features that get deprecated in NumPy\nshould stay around for another two releases, a good upper bound is\n`<1.(xx+3).0` \\- where `xx` is the minor version of the latest already-\nreleased NumPy. This is safe to do if you release at least once a year. If\nyour own releases are much less frequent, you may set the upper bound a little\nfurther into the future - this is a trade-off between a future NumPy version\n_maybe_ removing something you rely on, and the upper bound being exceeded\nwhich _may_ lead to your package being hard to install in combination with\nother packages relying on the latest NumPy.\n\nNote\n\nSciPy has more documentation on how it builds wheels and deals with its build-\ntime and runtime dependencies here.\n\nNumPy and SciPy wheel build CI may also be useful as a reference, it can be\nfound here for NumPy and here for SciPy.\n\n"}, {"name": "Fortran 77 programs", "path": "f2py/buildtools/index", "type": "F2PY and Build Systems", "text": "\nIn this section we will cover the various popular build systems and their\nusage with `f2py`.\n\nNote\n\nAs of November 2021\n\nThe default build system for `F2PY` has traditionally been the through the\nenhanced `numpy.distutils` module. This module is based on `distutils` which\nwill be removed in `Python 3.12.0` in October 2023; `setuptools` does not have\nsupport for Fortran or `F2PY` and it is unclear if it will be supported in the\nfuture. Alternative methods are thus increasingly more important.\n\nBuilding an extension module which includes Python and Fortran consists of:\n\nOne or more generated files from `f2py`\n\n`fortranobject.{c,h}`\n\nNumPy headers\n\nBroadly speaking there are three cases which arise when considering the\noutputs of `f2py`:\n\nGenerates\n\nWhen no `COMMON` blocks are present only a `C` wrapper file is generated.\nWrappers are also generated to rewrite assumed shape arrays as automatic\narrays.\n\nGenerates:\n\nThe secondary wrapper is used to handle code which is subdivided into modules.\nIt rewrites assumed shape arrays as automatic arrays.\n\nGenerates:\n\nSignature files `.pyf` do not signal their language standard via the file\nextension, they may generate the F90 and F77 specific wrappers depending on\ntheir contents; which shifts the burden of checking for generated files onto\nthe build system.\n\nNote\n\nThe signature file output situation is being reconsidered in issue 20385 .\n\nIn theory keeping the above requirements in hand, any build system can be\nadapted to generate `f2py` extension modules. Here we will cover a subset of\nthe more popular systems.\n\nNote\n\n`make` has no place in a modern multi-language setup, and so is not discussed\nfurther.\n\n"}, {"name": "Functional programming", "path": "reference/routines.functional", "type": "Functional programming", "text": "\n`apply_along_axis`(func1d, axis, arr, *args, ...)\n\nApply a function to 1-D slices along the given axis.\n\n`apply_over_axes`(func, a, axes)\n\nApply a function repeatedly over multiple axes.\n\n`vectorize`(pyfunc[, otypes, doc, excluded, ...])\n\nGeneralized function class.\n\n`frompyfunc`(func, /, nin, nout, *[, identity])\n\nTakes an arbitrary Python function and returns a NumPy ufunc.\n\n`piecewise`(x, condlist, funclist, *args, **kw)\n\nEvaluate a piecewise-defined function.\n\n"}, {"name": "generic.__array__()", "path": "reference/generated/numpy.generic.__array__", "type": "numpy.generic.__array__", "text": "\nmethod\n\nsc.__array__(dtype) return 0-dim array from scalar with specified dtype\n\n"}, {"name": "generic.__array_interface__", "path": "reference/generated/numpy.generic.__array_interface__", "type": "numpy.generic.__array_interface__", "text": "\nattribute\n\nArray protocol: Python side\n\n"}, {"name": "generic.__array_priority__", "path": "reference/generated/numpy.generic.__array_priority__", "type": "numpy.generic.__array_priority__", "text": "\nattribute\n\nArray priority.\n\n"}, {"name": "generic.__array_struct__", "path": "reference/generated/numpy.generic.__array_struct__", "type": "numpy.generic.__array_struct__", "text": "\nattribute\n\nArray protocol: struct\n\n"}, {"name": "generic.__array_wrap__()", "path": "reference/generated/numpy.generic.__array_wrap__", "type": "numpy.generic.__array_wrap__", "text": "\nmethod\n\nsc.__array_wrap__(obj) return scalar from array\n\n"}, {"name": "generic.__reduce__()", "path": "reference/generated/numpy.generic.__reduce__", "type": "numpy.generic.__reduce__", "text": "\nmethod\n\nHelper for pickle.\n\n"}, {"name": "generic.__setstate__()", "path": "reference/generated/numpy.generic.__setstate__", "type": "numpy.generic.__setstate__", "text": "\nmethod\n\n"}, {"name": "generic.base", "path": "reference/generated/numpy.generic.base", "type": "numpy.generic.base", "text": "\nattribute\n\nScalar attribute identical to the corresponding array attribute.\n\nPlease see `ndarray.base`.\n\n"}, {"name": "generic.byteswap()", "path": "reference/generated/numpy.generic.byteswap", "type": "numpy.generic.byteswap", "text": "\nmethod\n\nScalar method identical to the corresponding array attribute.\n\nPlease see `ndarray.byteswap`.\n\n"}, {"name": "generic.data", "path": "reference/generated/numpy.generic.data", "type": "numpy.generic.data", "text": "\nattribute\n\nPointer to start of data.\n\n"}, {"name": "generic.dtype", "path": "reference/generated/numpy.generic.dtype", "type": "numpy.generic.dtype", "text": "\nattribute\n\nGet array data-descriptor.\n\n"}, {"name": "generic.flags", "path": "reference/generated/numpy.generic.flags", "type": "numpy.generic.flags", "text": "\nattribute\n\nThe integer value of flags.\n\n"}, {"name": "generic.flat", "path": "reference/generated/numpy.generic.flat", "type": "numpy.generic.flat", "text": "\nattribute\n\nA 1-D view of the scalar.\n\n"}, {"name": "generic.imag", "path": "reference/generated/numpy.generic.imag", "type": "numpy.generic.imag", "text": "\nattribute\n\nThe imaginary part of the scalar.\n\n"}, {"name": "generic.itemsize", "path": "reference/generated/numpy.generic.itemsize", "type": "numpy.generic.itemsize", "text": "\nattribute\n\nThe length of one element in bytes.\n\n"}, {"name": "generic.ndim", "path": "reference/generated/numpy.generic.ndim", "type": "numpy.generic.ndim", "text": "\nattribute\n\nThe number of array dimensions.\n\n"}, {"name": "generic.real", "path": "reference/generated/numpy.generic.real", "type": "numpy.generic.real", "text": "\nattribute\n\nThe real part of the scalar.\n\n"}, {"name": "generic.setflags()", "path": "reference/generated/numpy.generic.setflags", "type": "numpy.generic.setflags", "text": "\nmethod\n\nScalar method identical to the corresponding array attribute.\n\nPlease see `ndarray.setflags`.\n\n"}, {"name": "generic.shape", "path": "reference/generated/numpy.generic.shape", "type": "numpy.generic.shape", "text": "\nattribute\n\nTuple of array dimensions.\n\n"}, {"name": "generic.size", "path": "reference/generated/numpy.generic.size", "type": "numpy.generic.size", "text": "\nattribute\n\nThe number of elements in the gentype.\n\n"}, {"name": "generic.squeeze()", "path": "reference/generated/numpy.generic.squeeze", "type": "numpy.generic.squeeze", "text": "\nmethod\n\nScalar method identical to the corresponding array attribute.\n\nPlease see `ndarray.squeeze`.\n\n"}, {"name": "generic.strides", "path": "reference/generated/numpy.generic.strides", "type": "numpy.generic.strides", "text": "\nattribute\n\nTuple of bytes steps in each dimension.\n\n"}, {"name": "generic.T", "path": "reference/generated/numpy.generic.t", "type": "numpy.generic.T", "text": "\nattribute\n\nScalar attribute identical to the corresponding array attribute.\n\nPlease see `ndarray.T`.\n\n"}, {"name": "Get the local copy of the code", "path": "dev/gitwash/following_latest", "type": "Development", "text": "\nFrom the command line:\n\nYou now have a copy of the code tree in the new `numpy` directory. If this\ndoesn\u2019t work you can try the alternative read-only url:\n\n"}, {"name": "get_build_temp_dir()", "path": "reference/distutils#numpy.distutils.misc_util.Configuration.get_build_temp_dir", "type": "Packaging ( \n    \n     numpy.distutils\n    \n    )", "text": "\nReturn a path to a temporary directory where temporary files should be placed.\n\n"}, {"name": "get_config_cmd()", "path": "reference/distutils#numpy.distutils.misc_util.Configuration.get_config_cmd", "type": "Packaging ( \n    \n     numpy.distutils\n    \n    )", "text": "\nReturns the numpy.distutils config command instance.\n\n"}, {"name": "get_distribution()", "path": "reference/distutils#numpy.distutils.misc_util.Configuration.get_distribution", "type": "Packaging ( \n    \n     numpy.distutils\n    \n    )", "text": "\nReturn the distutils distribution object for self.\n\n"}, {"name": "get_info()", "path": "reference/distutils#numpy.distutils.misc_util.Configuration.get_info", "type": "Packaging ( \n    \n     numpy.distutils\n    \n    )", "text": "\nGet resources information.\n\nReturn information (from system_info.get_info) for all of the names in the\nargument list in a single dictionary.\n\n"}, {"name": "get_subpackage()", "path": "reference/distutils#numpy.distutils.misc_util.Configuration.get_subpackage", "type": "Packaging ( \n    \n     numpy.distutils\n    \n    )", "text": "\nReturn list of subpackage configurations.\n\nName of the subpackage to get the configuration. \u2018*\u2019 in subpackage_name is\nhandled as a wildcard.\n\nIf None, then the path is assumed to be the local path plus the\nsubpackage_name. If a setup.py file is not found in the subpackage_path, then\na default configuration is used.\n\nParent name.\n\n"}, {"name": "get_version()", "path": "reference/distutils#numpy.distutils.misc_util.Configuration.get_version", "type": "Packaging ( \n    \n     numpy.distutils\n    \n    )", "text": "\nTry to get version string of a package.\n\nReturn a version string of the current package or None if the version\ninformation could not be detected.\n\nThis method scans files named __version__.py, <packagename>_version.py,\nversion.py, and __svn_version__.py for string variables version, __version__,\nand <packagename>_version, until a version number is found.\n\n"}, {"name": "Git configuration", "path": "dev/gitwash/configure_git", "type": "Development", "text": "\nYour personal git configurations are saved in the `.gitconfig` file in your\nhome directory. Here is an example `.gitconfig` file:\n\nYou can edit this file directly or you can use the `git config --global`\ncommand:\n\nTo set up on another computer, you can copy your `~/.gitconfig` file, or run\nthe commands above.\n\nIt is good practice to tell git who you are, for labeling any changes you make\nto the code. The simplest way to do this is from the command line:\n\nThis will write the settings into your git configuration file, which should\nnow contain a user section with your name and email:\n\nOf course you\u2019ll need to replace `Your Name` and `you@yourdomain.example.com`\nwith your actual name and email address.\n\nYou might well benefit from some aliases to common commands.\n\nFor example, you might well want to be able to shorten `git checkout` to `git\nco`. Or you may want to alias `git diff --color-words` (which gives a nicely\nformatted output of the diff) to `git wdiff`\n\nThe following `git config --global` commands:\n\nwill create an `alias` section in your `.gitconfig` file with contents like\nthis:\n\nYou may also want to make sure that your editor of choice is used\n\nTo enforce summaries when doing merges (`~/.gitconfig` file again):\n\nOr from the command line:\n\n"}, {"name": "Git for development", "path": "dev/gitwash/index", "type": "Development", "text": "\nThese pages describe a general git and github workflow.\n\nThis is not a comprehensive git reference. It\u2019s tailored to the github hosting\nservice. You may well find better or quicker ways of getting stuff done with\ngit, but these should get you started.\n\nFor general resources for learning git see Additional Git Resources.\n\nHave a look at the github install help pages available from github help\n\nContents:\n\n"}, {"name": "Global State", "path": "reference/global_state", "type": "Global State", "text": "\nNumPy has a few import-time, compile-time, or runtime options which change the\nglobal behaviour. Most of these are related to performance or for debugging\npurposes and will not be interesting to the vast majority of users.\n\nNumPy itself is normally intentionally limited to a single thread during\nfunction calls, however it does support multiple Python threads running at the\nsame time. Note that for performant linear algebra NumPy uses a BLAS backend\nsuch as OpenBLAS or MKL, which may use multiple threads that may be controlled\nby environment variables such as `OMP_NUM_THREADS` depending on what is used.\nOne way to control the number of threads is the package threadpoolctl\n\nWhen working with very large arrays on modern Linux kernels, you can\nexperience a significant speedup when transparent hugepage is used. The\ncurrent system policy for transparent hugepages can be seen by:\n\nWhen set to `madvise` NumPy will typically use hugepages for a performance\nboost. This behaviour can be modified by setting the environment variable:\n\nor setting it to `1` to always enable it. When not set, the default is to use\nmadvise on Kernels 4.6 and newer. These kernels presumably experience a large\nspeedup with hugepage support. This flag is checked at import time.\n\nThe array function protocol which allows array-like objects to hook into the\nNumPy API is currently enabled by default. This option exists since NumPy 1.16\nand is enabled by default since NumPy 1.17. It can be disabled using:\n\nSee also `numpy.class.__array_function__` for more information. This flag is\nchecked at import time.\n\nThe compile-time environment variables:\n\ncontrol how NumPy reports contiguity for arrays. The default that it is\nenabled and the debug mode is disabled. This setting should always be enabled.\nSetting the debug option can be interesting for testing code written in C\nwhich iterates through arrays that may or may not be contiguous in memory.\nMost users will have no reason to change these; for details see the memory\nlayout documentation.\n\nSome users might pass ownership of the data pointer to the `ndarray` by\nsetting the `OWNDATA` flag. If they do this without setting (manually) a\nmemory allocation policy, the default will be to call `free`. If\n`NUMPY_WARN_IF_NO_MEM_POLICY` is set to `\"1\"`, a `RuntimeWarning` will be\nemitted. A better alternative is to use a `PyCapsule` with a deallocator and\nset the `ndarray.base`.\n\n"}, {"name": "have_f77c()", "path": "reference/distutils#numpy.distutils.misc_util.Configuration.have_f77c", "type": "Packaging ( \n    \n     numpy.distutils\n    \n    )", "text": "\nCheck for availability of Fortran 77 compiler.\n\nUse it inside source generating function to ensure that setup distribution\ninstance has been initialized.\n\nTrue if a Fortran 77 compiler is available (because a simple Fortran 77 code\nwas able to be compiled successfully).\n\n"}, {"name": "have_f90c()", "path": "reference/distutils#numpy.distutils.misc_util.Configuration.have_f90c", "type": "Packaging ( \n    \n     numpy.distutils\n    \n    )", "text": "\nCheck for availability of Fortran 90 compiler.\n\nUse it inside source generating function to ensure that setup distribution\ninstance has been initialized.\n\nTrue if a Fortran 90 compiler is available (because a simple Fortran 90 code\nwas able to be compiled successfully)\n\n"}, {"name": "Hermite Series, \u201cPhysicists\u201d (numpy.polynomial.hermite)", "path": "reference/routines.polynomials.hermite", "type": "Hermite Series, \u201cPhysicists\u201d ( \n        \n         numpy.polynomial.hermite\n        \n        )", "text": "\nThis module provides a number of objects (mostly functions) useful for dealing\nwith Hermite series, including a `Hermite` class that encapsulates the usual\narithmetic operations. (General information on how this module represents and\nworks with such polynomials is in the docstring for its \u201cparent\u201d sub-package,\n`numpy.polynomial`).\n\n`Hermite`(coef[, domain, window])\n\nAn Hermite series class.\n\n`hermdomain`\n\nAn array object represents a multidimensional, homogeneous array of fixed-size\nitems.\n\n`hermzero`\n\nAn array object represents a multidimensional, homogeneous array of fixed-size\nitems.\n\n`hermone`\n\nAn array object represents a multidimensional, homogeneous array of fixed-size\nitems.\n\n`hermx`\n\nAn array object represents a multidimensional, homogeneous array of fixed-size\nitems.\n\n`hermadd`(c1, c2)\n\nAdd one Hermite series to another.\n\n`hermsub`(c1, c2)\n\nSubtract one Hermite series from another.\n\n`hermmulx`(c)\n\nMultiply a Hermite series by x.\n\n`hermmul`(c1, c2)\n\nMultiply one Hermite series by another.\n\n`hermdiv`(c1, c2)\n\nDivide one Hermite series by another.\n\n`hermpow`(c, pow[, maxpower])\n\nRaise a Hermite series to a power.\n\n`hermval`(x, c[, tensor])\n\nEvaluate an Hermite series at points x.\n\n`hermval2d`(x, y, c)\n\nEvaluate a 2-D Hermite series at points (x, y).\n\n`hermval3d`(x, y, z, c)\n\nEvaluate a 3-D Hermite series at points (x, y, z).\n\n`hermgrid2d`(x, y, c)\n\nEvaluate a 2-D Hermite series on the Cartesian product of x and y.\n\n`hermgrid3d`(x, y, z, c)\n\nEvaluate a 3-D Hermite series on the Cartesian product of x, y, and z.\n\n`hermder`(c[, m, scl, axis])\n\nDifferentiate a Hermite series.\n\n`hermint`(c[, m, k, lbnd, scl, axis])\n\nIntegrate a Hermite series.\n\n`hermfromroots`(roots)\n\nGenerate a Hermite series with given roots.\n\n`hermroots`(c)\n\nCompute the roots of a Hermite series.\n\n`hermvander`(x, deg)\n\nPseudo-Vandermonde matrix of given degree.\n\n`hermvander2d`(x, y, deg)\n\nPseudo-Vandermonde matrix of given degrees.\n\n`hermvander3d`(x, y, z, deg)\n\nPseudo-Vandermonde matrix of given degrees.\n\n`hermgauss`(deg)\n\nGauss-Hermite quadrature.\n\n`hermweight`(x)\n\nWeight function of the Hermite polynomials.\n\n`hermcompanion`(c)\n\nReturn the scaled companion matrix of c.\n\n`hermfit`(x, y, deg[, rcond, full, w])\n\nLeast squares fit of Hermite series to data.\n\n`hermtrim`(c[, tol])\n\nRemove \"small\" \"trailing\" coefficients from a polynomial.\n\n`hermline`(off, scl)\n\nHermite series whose graph is a straight line.\n\n`herm2poly`(c)\n\nConvert a Hermite series to a polynomial.\n\n`poly2herm`(pol)\n\nConvert a polynomial to a Hermite series.\n\n`numpy.polynomial`\n\n"}, {"name": "HermiteE Series, \u201cProbabilists\u201d (numpy.polynomial.hermite_e)", "path": "reference/routines.polynomials.hermite_e", "type": "HermiteE Series, \u201cProbabilists\u201d ( \n        \n         numpy.polynomial.hermite_e\n        \n        )", "text": "\nThis module provides a number of objects (mostly functions) useful for dealing\nwith Hermite_e series, including a `HermiteE` class that encapsulates the\nusual arithmetic operations. (General information on how this module\nrepresents and works with such polynomials is in the docstring for its\n\u201cparent\u201d sub-package, `numpy.polynomial`).\n\n`HermiteE`(coef[, domain, window])\n\nAn HermiteE series class.\n\n`hermedomain`\n\nAn array object represents a multidimensional, homogeneous array of fixed-size\nitems.\n\n`hermezero`\n\nAn array object represents a multidimensional, homogeneous array of fixed-size\nitems.\n\n`hermeone`\n\nAn array object represents a multidimensional, homogeneous array of fixed-size\nitems.\n\n`hermex`\n\nAn array object represents a multidimensional, homogeneous array of fixed-size\nitems.\n\n`hermeadd`(c1, c2)\n\nAdd one Hermite series to another.\n\n`hermesub`(c1, c2)\n\nSubtract one Hermite series from another.\n\n`hermemulx`(c)\n\nMultiply a Hermite series by x.\n\n`hermemul`(c1, c2)\n\nMultiply one Hermite series by another.\n\n`hermediv`(c1, c2)\n\nDivide one Hermite series by another.\n\n`hermepow`(c, pow[, maxpower])\n\nRaise a Hermite series to a power.\n\n`hermeval`(x, c[, tensor])\n\nEvaluate an HermiteE series at points x.\n\n`hermeval2d`(x, y, c)\n\nEvaluate a 2-D HermiteE series at points (x, y).\n\n`hermeval3d`(x, y, z, c)\n\nEvaluate a 3-D Hermite_e series at points (x, y, z).\n\n`hermegrid2d`(x, y, c)\n\nEvaluate a 2-D HermiteE series on the Cartesian product of x and y.\n\n`hermegrid3d`(x, y, z, c)\n\nEvaluate a 3-D HermiteE series on the Cartesian product of x, y, and z.\n\n`hermeder`(c[, m, scl, axis])\n\nDifferentiate a Hermite_e series.\n\n`hermeint`(c[, m, k, lbnd, scl, axis])\n\nIntegrate a Hermite_e series.\n\n`hermefromroots`(roots)\n\nGenerate a HermiteE series with given roots.\n\n`hermeroots`(c)\n\nCompute the roots of a HermiteE series.\n\n`hermevander`(x, deg)\n\nPseudo-Vandermonde matrix of given degree.\n\n`hermevander2d`(x, y, deg)\n\nPseudo-Vandermonde matrix of given degrees.\n\n`hermevander3d`(x, y, z, deg)\n\nPseudo-Vandermonde matrix of given degrees.\n\n`hermegauss`(deg)\n\nGauss-HermiteE quadrature.\n\n`hermeweight`(x)\n\nWeight function of the Hermite_e polynomials.\n\n`hermecompanion`(c)\n\nReturn the scaled companion matrix of c.\n\n`hermefit`(x, y, deg[, rcond, full, w])\n\nLeast squares fit of Hermite series to data.\n\n`hermetrim`(c[, tol])\n\nRemove \"small\" \"trailing\" coefficients from a polynomial.\n\n`hermeline`(off, scl)\n\nHermite series whose graph is a straight line.\n\n`herme2poly`(c)\n\nConvert a Hermite series to a polynomial.\n\n`poly2herme`(pol)\n\nConvert a polynomial to a Hermite series.\n\n`numpy.polynomial`\n\n"}, {"name": "How to write a NumPy how-to", "path": "user/how-to-how-to", "type": "User Guide", "text": "\nHow-tos get straight to the point \u2013 they\n\n\u201cI need to refuel my car.\u201d\n\nAdd helpful details for newcomers (\u201cHayseed Road\u201d, even though it\u2019s the only\nturnoff at three km/mi). But not irrelevant ones:\n\nIf there\u2019s related background (tutorial, explanation, reference, alternative\napproach), bring it to the user\u2019s attention with a link (\u201cDirections from\nRoute 7,\u201d \u201cWhy so few filling stations?\u201d).\n\nIf the information is already documented and succinct enough for a how-to,\njust link to it, possibly after an introduction (\u201cThree km/mi, take a right\u201d).\n\n\u201cI want to see the sights.\u201d\n\nThe `See the sights` how-to should link to a set of narrower how-tos:\n\nand these might in turn link to still narrower how-tos \u2013 so the town center\npage might link to\n\nBy organizing how-tos this way, you not only display the options for people\nwho need to narrow their question, you also have provided answers for users\nwho start with narrower questions (\u201cI want to see historic buildings,\u201d \u201cWhich\nway to city hall?\u201d).\n\nIf a how-to has many steps:\n\nPeople use the terms \u201chow-to\u201d and \u201ctutorial\u201d interchangeably, but we draw a\ndistinction, following Daniele Procida\u2019s taxonomy of documentation.\n\nDocumentation needs to meet users where they are. `How-tos` offer get-it-done\ninformation; the user wants steps to copy and doesn\u2019t necessarily want to\nunderstand NumPy. `Tutorials` are warm-fuzzy information; the user wants a\nfeel for some aspect of NumPy (and again, may or may not care about deeper\nknowledge).\n\nWe distinguish both tutorials and how-tos from `Explanations`, which are deep\ndives intended to give understanding rather than immediate assistance, and\n`References`, which give complete, authoritative data on some concrete part of\nNumPy (like its API) but aren\u2019t obligated to paint a broader picture.\n\nFor more on tutorials, see Learn to write a NumPy tutorial\n\nYes \u2013 until the sections with question-mark headings; they explain rather than\ngiving directions. In a how-to, those would be links.\n\n"}, {"name": "I/O with NumPy", "path": "user/basics.io", "type": "User Guide", "text": "\n\n"}, {"name": "include statements", "path": "f2py/signature-file", "type": "Signature file", "text": "\nThe syntax specification for signature files (.pyf files) is modeled on the\nFortran 90/95 language specification. Almost all Fortran 90/95 standard\nconstructs are understood, both in free and fixed format (recall that Fortran\n77 is a subset of Fortran 90/95). F2PY introduces some extensions to the\nFortran 90/95 language specification that help in the design of the Fortran to\nPython interface, making it more \u201cPythonic\u201d.\n\nSignature files may contain arbitrary Fortran code so that any Fortran 90/95\ncodes can be treated as signature files. F2PY silently ignores Fortran\nconstructs that are irrelevant for creating the interface. However, this also\nmeans that syntax errors are not caught by F2PY and will only be caught when\nthe library is built.\n\nIn general, the contents of the signature files are case-sensitive. When\nscanning Fortran codes to generate a signature file, F2PY lowers all cases\nautomatically except in multi-line blocks or when the `--no-lower` option is\nused.\n\nThe syntax of signature files is presented below.\n\nA signature file may contain one (recommended) or more `python module` blocks.\nThe `python module` block describes the contents of a Python/C extension\nmodule `<modulename>module.c` that F2PY generates.\n\nWarning\n\nException: if `<modulename>` contains a substring `__user__`, then the\ncorresponding `python module` block describes the signatures of call-back\nfunctions (see Call-back arguments).\n\nA `python module` block has the following structure:\n\nHere brackets `[]` indicate an optional section, dots `...` indicate one or\nmore of a previous section. So, `[]...` is to be read as zero or more of a\nprevious section.\n\nThe signature of a Fortran routine has the following structure:\n\nFrom a Fortran routine signature F2PY generates a Python/C extension function\nthat has the following signature:\n\nThe signature of a Fortran block data has the following structure:\n\nThe definition of the `<argument/variable type declaration>` part is\n\nwhere\n\nand\n\nIf an argument has no `<argument type declaration>`, its type is determined by\napplying `implicit` rules to its name.\n\nThe definition of the `<use statement>` part is\n\nwhere\n\nThe definition of the `<common block statement>` part is\n\nwhere\n\nThe `<other statement>` part refers to any other Fortran language constructs\nthat are not described above. F2PY ignores most of them except the following:\n\nIf a file `<filename>` does not exist, the `include` statement is ignored.\nOtherwise, the file `<filename>` is included to a signature file. `include`\nstatements can be used in any part of a signature file, also outside the\nFortran/C routine signature blocks.\n\nwhere\n\nImplicit rules are used to determine the type specification of a variable\n(from the first-letter of its name) if the variable is not defined using\n`<variable type declaration>`. Default implicit rules are given by:\n\nF2PY generates wrappers for all entry names using the signature of the routine\nblock.\n\nNote\n\nThe `entry` statement can be used to describe the signature of an arbitrary\nsubroutine or function allowing F2PY to generate a number of wrappers from\nonly one routine block signature. There are few restrictions while doing this:\n`fortranname` cannot be used, `callstatement` and `callprotoargument` can be\nused only if they are valid for all entry routines, etc.\n\nIn addition, F2PY introduces the following statements:\n\nUses a `Py_BEGIN_ALLOW_THREADS .. Py_END_ALLOW_THREADS` block around the call\nto Fortran/C function.\n\nReplaces the F2PY generated call statement to Fortran/C function with\n`<C-expr|multi-line block>`. The wrapped Fortran/C function is available as\n`(*f2py_func)`.\n\nTo raise an exception, set `f2py_success = 0` in `<C-expr|multi-line block>`.\n\nWhen the `callstatement` statement is used then F2PY may not generate proper\nprototypes for Fortran/C functions (because `<C-expr>` may contain any\nfunction calls and F2PY has no way to determine what should be the proper\nprototype).\n\nWith this statement you can explicitly specify the arguments of the\ncorresponding prototype:\n\nF2PY allows for the use of an arbitrary `<routine name>` for a given Fortran/C\nfunction. Then this statement is used for the `<actual Fortran/C routine\nname>`.\n\nIf `fortranname` statement is used without `<actual Fortran/C routine name>`\nthen a dummy wrapper is generated.\n\nWhen this is used inside a `python module` block, the given C code will be\ninserted to generated C/API source just before wrapper function definitions.\n\nHere you can define arbitrary C functions to be used for the initialization of\noptional arguments.\n\nFor example, if `usercode` is used twice inside `python module` block then the\nsecond multi-line block is inserted after the definition of the external\nroutines.\n\nWhen used inside `<routine signature>`, then the given C code will be inserted\ninto the corresponding wrapper function just after the declaration of\nvariables but before any C statements. So, the `usercode` follow-up can\ncontain both declarations and C statements.\n\nWhen used inside the first `interface` block, then the given C code will be\ninserted at the end of the initialization function of the extension module.\nThis is how the extension modules dictionary can be modified and has many use-\ncases; for example, to define additional variables.\n\nThis is a multi-line block which will be inserted into the definition of a\nmodule methods `PyMethodDef`-array. It must be a comma-separated list of C\narrays (see Extending and Embedding Python documentation for details).\n`pymethoddef` statement can be used only inside `python module` block.\n\nThe following attributes are used by F2PY:\n\nThe corresponding argument is moved to the end of `<optional arguments>` list.\nA default value for an optional argument can be specified via `<init_expr>`,\nsee the `entitydecl` definition.\n\nNote\n\nThe corresponding argument with this attribute considered mandatory. This is\nthe default. `required` should only be specified if there is a need to disable\nthe automatic `optional` setting when `<init_expr>` is used.\n\nIf a Python `None` object is used as a required argument, the argument is\ntreated as optional. That is, in the case of array argument, the memory is\nallocated. If `<init_expr>` is given, then the corresponding initialization is\ncarried out.\n\nThe corresponding variable is considered as an array with dimensions given in\n`<arrayspec>`.\n\nThis specifies the \u201cintention\u201d of the corresponding argument. `<intentspec>`\nis a comma separated list of the following keys:\n\nThe corresponding argument is considered to be input-only. This means that the\nvalue of the argument is passed to a Fortran/C function and that the function\nis expected to not change the value of this argument.\n\nThe corresponding argument is marked for input/output or as an in situ output\nargument. `intent(inout)` arguments can be only \u201ccontiguous\u201d NumPy arrays with\nproper type and size. Here \u201ccontiguous\u201d can be either in the Fortran or C\nsense. The latter coincides with the default contiguous concept used in NumPy\nand is effective only if `intent(c)` is used. F2PY assumes Fortran contiguous\narguments by default.\n\nNote\n\nUsing `intent(inout)` is generally not recommended, use `intent(in,out)`\ninstead.\n\nSee also the `intent(inplace)` attribute.\n\nThe corresponding argument is considered to be an input/output or in situ\noutput argument. `intent(inplace)` arguments must be NumPy arrays of a proper\nsize. If the type of an array is not \u201cproper\u201d or the array is non-contiguous\nthen the array will be modified in-place to fix the type and make it\ncontiguous.\n\nNote\n\nUsing `intent(inplace)` is generally not recommended either.\n\nFor example, when slices have been taken from an `intent(inplace)` argument\nthen after in-place changes, the data pointers for the slices may point to an\nunallocated memory area.\n\nThe corresponding argument is considered to be a return variable. It is\nappended to the `<returned variables>` list. Using `intent(out)` sets\n`intent(hide)` automatically, unless `intent(in)` or `intent(inout)` are\nspecified as well.\n\nBy default, returned multidimensional arrays are Fortran-contiguous. If\n`intent(c)` attribute is used, then the returned multidimensional arrays are\nC-contiguous.\n\nThe corresponding argument is removed from the list of required or optional\narguments. Typically `intent(hide)` is used with `intent(out)` or when\n`<init_expr>` completely determines the value of the argument like in the\nfollowing example:\n\nThe corresponding argument is treated as a C scalar or C array argument. For\nthe case of a scalar argument, its value is passed to a C function as a C\nscalar argument (recall that Fortran scalar arguments are actually C pointer\narguments). For array arguments, the wrapper function is assumed to treat\nmultidimensional arrays as C-contiguous arrays.\n\nThere is no need to use `intent(c)` for one-dimensional arrays, irrespective\nof whether the wrapped function is in Fortran or C. This is because the\nconcepts of Fortran- and C contiguity overlap in one-dimensional cases.\n\nIf `intent(c)` is used as a statement but without an entity declaration list,\nthen F2PY adds the `intent(c)` attribute to all arguments.\n\nAlso, when wrapping C functions, one must use `intent(c)` attribute for\n`<routine name>` in order to disable Fortran specific `F_FUNC(..,..)` macros.\n\nThe corresponding argument is treated as junk memory. No Fortran nor C\ncontiguity checks are carried out. Using `intent(cache)` makes sense only for\narray arguments, also in conjunction with `intent(hide)` or `optional`\nattributes.\n\nEnsures that the original contents of `intent(in)` argument is preserved.\nTypically used with the `intent(in,out)` attribute. F2PY creates an optional\nargument `overwrite_<argument name>` with the default value `0`.\n\nThis indicates that the original contents of the `intent(in)` argument may be\naltered by the Fortran/C function. F2PY creates an optional argument\n`overwrite_<argument name>` with the default value `1`.\n\nReplaces the returned name with `<new name>` in the `__doc__` string of the\nwrapper function.\n\nConstructs an external function suitable for calling Python functions from\nFortran. `intent(callback)` must be specified before the corresponding\n`external` statement. If the \u2018argument\u2019 is not in the argument list then it\nwill be added to Python wrapper but only by initializing an external function.\n\nNote\n\nUse `intent(callback)` in situations where the Fortran/C code assumes that the\nuser implemented a function with a given prototype and linked it to an\nexecutable. Don\u2019t use `intent(callback)` if the function appears in the\nargument list of a Fortran routine.\n\nWith `intent(hide)` or `optional` attributes specified and using a wrapper\nfunction without specifying the callback argument in the argument list; then\nthe call-back function is assumed to be found in the namespace of the F2PY\ngenerated extension module where it can be set as a module attribute by a\nuser.\n\nDefines an auxiliary C variable in the F2PY generated wrapper function. Useful\nto save parameter values so that they can be accessed in initialization\nexpressions for other variables.\n\nNote\n\n`intent(aux)` silently implies `intent(c)`.\n\nThe following rules apply:\n\nIf none of `intent(in | inout | out | hide)` are specified, `intent(in)` is\nassumed.\n\nIf `intent(copy)` or `intent(overwrite)` is used, then an additional optional\nargument is introduced with a name `overwrite_<argument name>` and a default\nvalue 0 or 1, respectively.\n\nPerforms a consistency check on the arguments by evaluating `<C-booleanexpr>`;\nif `<C-booleanexpr>` returns 0, an exception is raised.\n\nNote\n\nIf `check(..)` is not used then F2PY automatically generates a few standard\nchecks (e.g. in a case of an array argument, it checks for the proper shape\nand size). Use `check()` to disable checks generated by F2PY.\n\nThis declares that the corresponding argument depends on the values of\nvariables in the `<names>` list. For example, `<init_expr>` may use the values\nof other arguments. Using information given by `depend(..)` attributes, F2PY\nensures that arguments are initialized in a proper order. If the `depend(..)`\nattribute is not used then F2PY determines dependence relations automatically.\nUse `depend()` to disable the dependence relations generated by F2PY.\n\nWhen you edit dependence relations that were initially generated by F2PY, be\ncareful not to break the dependence relations of other relevant variables.\nAnother thing to watch out for is cyclic dependencies. F2PY is able to detect\ncyclic dependencies when constructing wrappers and it complains if any are\nfound.\n\nThe corresponding variable is a Fortran 90 allocatable array defined as\nFortran 90 module data.\n\nThe corresponding argument is a function provided by user. The signature of\nthis call-back function can be defined\n\nFor example, F2PY generates from:\n\nthe following call-back signatures:\n\nThe corresponding user-provided Python function are then:\n\nSee also the `intent(callback)` attribute.\n\nThis indicates that the corresponding variable is a parameter and it must have\na fixed value. F2PY replaces all parameter occurrences by their corresponding\nvalues.\n\nThe F2PY directives allow using F2PY signature file constructs in Fortran\n77/90 source codes. With this feature one can (almost) completely skip the\nintermediate signature file generation and apply F2PY directly to Fortran\nsource codes.\n\nF2PY directives have the following form:\n\nwhere allowed comment characters for fixed and free format Fortran codes are\n`cC*!#` and `!`, respectively. Everything that follows `<comment char>f2py` is\nignored by a compiler but read by F2PY as a normal non-comment Fortran line:\n\nNote\n\nWhen F2PY finds a line with F2PY directive, the directive is first replaced by\n5 spaces and then the line is reread.\n\nFor fixed format Fortran codes, `<comment char>` must be at the first column\nof a file, of course. For free format Fortran codes, the F2PY directives can\nappear anywhere in a file.\n\nC expressions are used in the following parts of signature files:\n\nA C expression may contain:\n\nthe following CPP macros:\n\nFor initializing an array `<array name>`, F2PY generates a loop over all\nindices and dimensions that executes the following pseudo-statement:\n\nwhere `_i[<i>]` refers to the `<i>`-th index value and that runs from `0` to\n`shape(<array name>,<i>)-1`.\n\nFor example, a function `myrange(n)` generated from the following signature\n\nis equivalent to `numpy.arange(n,dtype=float)`.\n\nWarning\n\nF2PY may lower cases also in C expressions when scanning Fortran codes (see\n`--[no]-lower` option).\n\nA multi-line block starts with `'''` (triple single-quotes) and ends with\n`'''` in some strictly subsequent line. Multi-line blocks can be used only\nwithin .pyf files. The contents of a multi-line block can be arbitrary (except\nthat it cannot contain `'''`) and no transformations (e.g. lowering cases) are\napplied to it.\n\nCurrently, multi-line blocks can be used in the following constructs:\n\n"}, {"name": "Indexing on ndarrays", "path": "user/basics.indexing", "type": "User Guide", "text": "\nSee also\n\nIndexing routines\n\n`ndarrays` can be indexed using the standard Python `x[obj]` syntax, where x\nis the array and obj the selection. There are different kinds of indexing\navailable depending on obj: basic indexing, advanced indexing and field\naccess.\n\nMost of the following examples show the use of indexing when referencing data\nin an array. The examples work just as well when assigning to an array. See\nAssigning values to indexed arrays for specific examples and explanations on\nhow assignments work.\n\nNote that in Python, `x[(exp1, exp2, ..., expN)]` is equivalent to `x[exp1,\nexp2, ..., expN]`; the latter is just syntactic sugar for the former.\n\nSingle element indexing works exactly like that for other standard Python\nsequences. It is 0-based, and accepts negative indices for indexing from the\nend of the array.\n\nIt is not necessary to separate each dimension\u2019s index into its own set of\nsquare brackets.\n\nNote that if one indexes a multidimensional array with fewer indices than\ndimensions, one gets a subdimensional array. For example:\n\nThat is, each index specified selects the array corresponding to the rest of\nthe dimensions selected. In the above example, choosing 0 means that the\nremaining dimension of length 5 is being left unspecified, and that what is\nreturned is an array of that dimensionality and size. It must be noted that\nthe returned array is a view, i.e., it is not a copy of the original, but\npoints to the same values in memory as does the original array. In this case,\nthe 1-D array at the first position (0) is returned. So using a single index\non the returned array, results in a single element being returned. That is:\n\nSo note that `x[0, 2] == x[0][2]` though the second case is more inefficient\nas a new temporary array is created after the first index that is subsequently\nindexed by 2.\n\nNote\n\nNumPy uses C-order indexing. That means that the last index usually represents\nthe most rapidly changing memory location, unlike Fortran or IDL, where the\nfirst index represents the most rapidly changing location in memory. This\ndifference represents a great potential for confusion.\n\nBasic slicing extends Python\u2019s basic concept of slicing to N dimensions. Basic\nslicing occurs when obj is a `slice` object (constructed by `start:stop:step`\nnotation inside of brackets), an integer, or a tuple of slice objects and\nintegers. `Ellipsis` and `newaxis` objects can be interspersed with these as\nwell.\n\nDeprecated since version 1.15.0: In order to remain backward compatible with a\ncommon usage in Numeric, basic slicing is also initiated if the selection\nobject is any non-ndarray and non-tuple sequence (such as a `list`) containing\n`slice` objects, the `Ellipsis` object, or the `newaxis` object, but not for\ninteger arrays or other embedded sequences.\n\nThe simplest case of indexing with N integers returns an array scalar\nrepresenting the corresponding item. As in Python, all indices are zero-based:\nfor the i-th index \\\\(n_i\\\\), the valid range is \\\\(0 \\le n_i < d_i\\\\) where\n\\\\(d_i\\\\) is the i-th element of the shape of the array. Negative indices are\ninterpreted as counting from the end of the array (i.e., if \\\\(n_i < 0\\\\), it\nmeans \\\\(n_i + d_i\\\\)).\n\nAll arrays generated by basic slicing are always views of the original array.\n\nNote\n\nNumPy slicing creates a view instead of a copy as in the case of built-in\nPython sequences such as string, tuple and list. Care must be taken when\nextracting a small portion from a large array which becomes useless after the\nextraction, because the small portion extracted contains a reference to the\nlarge original array whose memory will not be released until all arrays\nderived from it are garbage-collected. In such cases an explicit `copy()` is\nrecommended.\n\nThe standard rules of sequence slicing apply to basic slicing on a per-\ndimension basis (including using a step index). Some useful concepts to\nremember include:\n\nThe basic slice syntax is `i:j:k` where i is the starting index, j is the\nstopping index, and k is the step (\\\\(k\\neq0\\\\)). This selects the m elements\n(in the corresponding dimension) with index values i, i + k, \u2026, i + (m - 1) k\nwhere \\\\(m = q + (r\\neq0)\\\\) and q and r are the quotient and remainder\nobtained by dividing j - i by k: j - i = q k + r, so that i + (m - 1) k < j.\nFor example:\n\nNegative i and j are interpreted as n + i and n + j where n is the number of\nelements in the corresponding dimension. Negative k makes stepping go towards\nsmaller indices. From the above example:\n\nAssume n is the number of elements in the dimension being sliced. Then, if i\nis not given it defaults to 0 for k > 0 and n - 1 for k < 0 . If j is not\ngiven it defaults to n for k > 0 and -n-1 for k < 0 . If k is not given it\ndefaults to 1. Note that `::` is the same as `:` and means select all indices\nalong this axis. From the above example:\n\nIf the number of objects in the selection tuple is less than N, then `:` is\nassumed for any subsequent dimensions. For example:\n\nBasic slicing with more than one non-`:` entry in the slicing tuple, acts like\nrepeated application of slicing using a single non-`:` entry, where the\nnon-`:` entries are successively taken (with all other non-`:` entries\nreplaced by `:`). Thus, `x[ind1, ..., ind2,:]` acts like `x[ind1][..., ind2,\n:]` under basic slicing.\n\nWarning\n\nThe above is not true for advanced indexing.\n\nThere are some tools to facilitate the easy matching of array shapes with\nexpressions and in assignments.\n\n`Ellipsis` expands to the number of `:` objects needed for the selection tuple\nto index all dimensions. In most cases, this means that the length of the\nexpanded selection tuple is `x.ndim`. There may only be a single ellipsis\npresent. From the above example:\n\nThis is equivalent to:\n\nEach `newaxis` object in the selection tuple serves to expand the dimensions\nof the resulting selection by one unit-length dimension. The added dimension\nis the position of the `newaxis` object in the selection tuple. `newaxis` is\nan alias for `None`, and `None` can be used in place of this with the same\nresult. From the above example:\n\nThis can be handy to combine two arrays in a way that otherwise would require\nexplicit reshaping operations. For example:\n\nAdvanced indexing is triggered when the selection object, obj, is a non-tuple\nsequence object, an `ndarray` (of data type integer or bool), or a tuple with\nat least one sequence object or ndarray (of data type integer or bool). There\nare two types of advanced indexing: integer and Boolean.\n\nAdvanced indexing always returns a copy of the data (contrast with basic\nslicing that returns a view).\n\nWarning\n\nThe definition of advanced indexing means that `x[(1, 2, 3),]` is\nfundamentally different than `x[(1, 2, 3)]`. The latter is equivalent to `x[1,\n2, 3]` which will trigger basic selection while the former will trigger\nadvanced indexing. Be sure to understand why this occurs.\n\nAlso recognize that `x[[1, 2, 3]]` will trigger advanced indexing, whereas due\nto the deprecated Numeric compatibility mentioned above, `x[[1, 2,\nslice(None)]]` will trigger basic slicing.\n\nInteger array indexing allows selection of arbitrary items in the array based\non their N-dimensional index. Each integer array represents a number of\nindices into that dimension.\n\nNegative values are permitted in the index arrays and work as they do with\nsingle indices or slices:\n\nIf the index values are out of bounds then an `IndexError` is thrown:\n\nWhen the index consists of as many integer arrays as dimensions of the array\nbeing indexed, the indexing is straightforward, but different from slicing.\n\nAdvanced indices always are broadcast and iterated as one:\n\nNote that the resulting shape is identical to the (broadcast) indexing array\nshapes `ind_1, ..., ind_N`. If the indices cannot be broadcast to the same\nshape, an exception `IndexError: shape mismatch: indexing arrays could not be\nbroadcast together with shapes...` is raised.\n\nIndexing with multidimensional index arrays tend to be more unusual uses, but\nthey are permitted, and they are useful for some problems. We\u2019ll start with\nthe simplest multidimensional case:\n\nIn this case, if the index arrays have a matching shape, and there is an index\narray for each dimension of the array being indexed, the resultant array has\nthe same shape as the index arrays, and the values correspond to the index set\nfor each position in the index arrays. In this example, the first index value\nis 0 for both index arrays, and thus the first value of the resultant array is\n`y[0, 0]`. The next value is `y[2, 1]`, and the last is `y[4, 2]`.\n\nIf the index arrays do not have the same shape, there is an attempt to\nbroadcast them to the same shape. If they cannot be broadcast to the same\nshape, an exception is raised:\n\nThe broadcasting mechanism permits index arrays to be combined with scalars\nfor other indices. The effect is that the scalar value is used for all the\ncorresponding values of the index arrays:\n\nJumping to the next level of complexity, it is possible to only partially\nindex an array with index arrays. It takes a bit of thought to understand what\nhappens in such cases. For example if we just use one index array with y:\n\nIt results in the construction of a new array where each value of the index\narray selects one row from the array being indexed and the resultant array has\nthe resulting shape (number of index elements, size of row).\n\nIn general, the shape of the resultant array will be the concatenation of the\nshape of the index array (or the shape that all the index arrays were\nbroadcast to) with the shape of any unused dimensions (those not indexed) in\nthe array being indexed.\n\nFrom each row, a specific element should be selected. The row index is just\n`[0, 1, 2]` and the column index specifies the element to choose for the\ncorresponding row, here `[0, 1, 0]`. Using both together the task can be\nsolved using advanced indexing:\n\nTo achieve a behaviour similar to the basic slicing above, broadcasting can be\nused. The function `ix_` can help with this broadcasting. This is best\nunderstood with an example.\n\nFrom a 4x3 array the corner elements should be selected using advanced\nindexing. Thus all elements for which the column is one of `[0, 2]` and the\nrow is one of `[0, 3]` need to be selected. To use advanced indexing one needs\nto select all elements explicitly. Using the method explained previously one\ncould write:\n\nHowever, since the indexing arrays above just repeat themselves, broadcasting\ncan be used (compare operations such as `rows[:, np.newaxis] + columns`) to\nsimplify this:\n\nThis broadcasting can also be achieved using the function `ix_`:\n\nNote that without the `np.ix_` call, only the diagonal elements would be\nselected:\n\nThis difference is the most important thing to remember about indexing with\nmultiple advanced indices.\n\nA real-life example of where advanced indexing may be useful is for a color\nlookup table where we want to map the values of an image into RGB triples for\ndisplay. The lookup table could have a shape (nlookup, 3). Indexing such an\narray with an image with shape (ny, nx) with dtype=np.uint8 (or any integer\ntype so long as values are with the bounds of the lookup table) will result in\nan array of shape (ny, nx, 3) where a triple of RGB values is associated with\neach pixel location.\n\nThis advanced indexing occurs when obj is an array object of Boolean type,\nsuch as may be returned from comparison operators. A single boolean index\narray is practically identical to `x[obj.nonzero()]` where, as described\nabove, `obj.nonzero()` returns a tuple (of length `obj.ndim`) of integer index\narrays showing the `True` elements of obj. However, it is faster when\n`obj.shape == x.shape`.\n\nIf `obj.ndim == x.ndim`, `x[obj]` returns a 1-dimensional array filled with\nthe elements of x corresponding to the `True` values of obj. The search order\nwill be row-major, C-style. If obj has `True` values at entries that are\noutside of the bounds of x, then an index error will be raised. If obj is\nsmaller than x it is identical to filling it with `False`.\n\nA common use case for this is filtering for desired element values. For\nexample, one may wish to select all entries from an array which are not `NaN`:\n\nOr wish to add a constant to all negative elements:\n\nIn general if an index includes a Boolean array, the result will be identical\nto inserting `obj.nonzero()` into the same position and using the integer\narray indexing mechanism described above. `x[ind_1, boolean_array, ind_2]` is\nequivalent to `x[(ind_1,) + boolean_array.nonzero() + (ind_2,)]`.\n\nIf there is only one Boolean array and no integer indexing array present, this\nis straightforward. Care must only be taken to make sure that the boolean\nindex has exactly as many dimensions as it is supposed to work with.\n\nIn general, when the boolean array has fewer dimensions than the array being\nindexed, this is equivalent to `x[b, ...]`, which means x is indexed by b\nfollowed by as many `:` as are needed to fill out the rank of x. Thus the\nshape of the result is one dimension containing the number of True elements of\nthe boolean array, followed by the remaining dimensions of the array being\nindexed:\n\nHere the 4th and 5th rows are selected from the indexed array and combined to\nmake a 2-D array.\n\nFrom an array, select all rows which sum up to less or equal two:\n\nCombining multiple Boolean indexing arrays or a Boolean with an integer\nindexing array can best be understood with the `obj.nonzero()` analogy. The\nfunction `ix_` also supports boolean arrays and will work without any\nsurprises.\n\nUse boolean indexing to select all rows adding up to an even number. At the\nsame time columns 0 and 2 should be selected with an advanced integer index.\nUsing the `ix_` function this can be done with:\n\nWithout the `np.ix_` call, only the diagonal elements would be selected.\n\nOr without `np.ix_` (compare the integer array examples):\n\nUse a 2-D boolean array of shape (2, 3) with four True elements to select rows\nfrom a 3-D array of shape (2, 3, 5) results in a 2-D result of shape (4, 5):\n\nWhen there is at least one slice (`:`), ellipsis (`...`) or `newaxis` in the\nindex (or the array has more dimensions than there are advanced indices), then\nthe behaviour can be more complicated. It is like concatenating the indexing\nresult for each advanced index element.\n\nIn the simplest case, there is only a single advanced index combined with a\nslice. For example:\n\nIn effect, the slice and index array operation are independent. The slice\noperation extracts columns with index 1 and 2, (i.e. the 2nd and 3rd columns),\nfollowed by the index array operation which extracts rows with index 0, 2 and\n4 (i.e the first, third and fifth rows). This is equivalent to:\n\nA single advanced index can, for example, replace a slice and the result array\nwill be the same. However, it is a copy and may have a different memory\nlayout. A slice is preferable when it is possible. For example:\n\nThe easiest way to understand a combination of multiple advanced indices may\nbe to think in terms of the resulting shape. There are two parts to the\nindexing operation, the subspace defined by the basic indexing (excluding\nintegers) and the subspace from the advanced indexing part. Two cases of index\ncombination need to be distinguished:\n\nIn the first case, the dimensions resulting from the advanced indexing\noperation come first in the result array, and the subspace dimensions after\nthat. In the second case, the dimensions from the advanced indexing operations\nare inserted into the result array at the same spot as they were in the\ninitial array (the latter logic is what makes simple advanced indexing behave\njust like slicing).\n\nSuppose `x.shape` is (10, 20, 30) and `ind` is a (2, 3, 4)-shaped indexing\n`intp` array, then `result = x[..., ind, :]` has shape (10, 2, 3, 4, 30)\nbecause the (20,)-shaped subspace has been replaced with a (2, 3, 4)-shaped\nbroadcasted indexing subspace. If we let i, j, k loop over the (2, 3,\n4)-shaped subspace then `result[..., i, j, k, :] = x[..., ind[i, j, k], :]`.\nThis example produces the same result as `x.take(ind, axis=-2)`.\n\nLet `x.shape` be (10, 20, 30, 40, 50) and suppose `ind_1` and `ind_2` can be\nbroadcast to the shape (2, 3, 4). Then `x[:, ind_1, ind_2]` has shape (10, 2,\n3, 4, 40, 50) because the (20, 30)-shaped subspace from X has been replaced\nwith the (2, 3, 4) subspace from the indices. However, `x[:, ind_1, :, ind_2]`\nhas shape (2, 3, 4, 10, 30, 50) because there is no unambiguous place to drop\nin the indexing subspace, thus it is tacked-on to the beginning. It is always\npossible to use `.transpose()` to move the subspace anywhere desired. Note\nthat this example cannot be replicated using `take`.\n\nSlicing can be combined with broadcasted boolean indices:\n\nSee also\n\nStructured arrays\n\nIf the `ndarray` object is a structured array the fields of the array can be\naccessed by indexing the array with strings, dictionary-like.\n\nIndexing `x['field-name']` returns a new view to the array, which is of the\nsame shape as x (except when the field is a sub-array) but of data type\n`x.dtype['field-name']` and contains only the part of the data in the\nspecified field. Also, record array scalars can be \u201cindexed\u201d this way.\n\nIndexing into a structured array can also be done with a list of field names,\ne.g. `x[['field-name1', 'field-name2']]`. As of NumPy 1.16, this returns a\nview containing only those fields. In older versions of NumPy, it returned a\ncopy. See the user guide section on Structured arrays for more information on\nmultifield indexing.\n\nIf the accessed field is a sub-array, the dimensions of the sub-array are\nappended to the shape of the result. For example:\n\n`x.flat` returns an iterator that will iterate over the entire array (in\nC-contiguous style with the last index varying the fastest). This iterator\nobject can also be indexed using basic slicing or advanced indexing as long as\nthe selection object is not a tuple. This should be clear from the fact that\n`x.flat` is a 1-dimensional view. It can be used for integer indexing with\n1-dimensional C-style-flat indices. The shape of any returned array is\ntherefore the shape of the integer indexing object.\n\nAs mentioned, one can select a subset of an array to assign to using a single\nindex, slices, and index and mask arrays. The value being assigned to the\nindexed array must be shape consistent (the same shape or broadcastable to the\nshape the index produces). For example, it is permitted to assign a constant\nto a slice:\n\nor an array of the right size:\n\nNote that assignments may result in changes if assigning higher types to lower\ntypes (like floats to ints) or even exceptions (assigning complex to floats or\nints):\n\nUnlike some of the references (such as array and mask indices) assignments are\nalways made to the original data in the array (indeed, nothing else would make\nsense!). Note though, that some actions may not work as one may naively\nexpect. This particular example is often surprising to people:\n\nWhere people expect that the 1st location will be incremented by 3. In fact,\nit will only be incremented by 1. The reason is that a new array is extracted\nfrom the original (as a temporary) containing the values at 1, 1, 3, 1, then\nthe value 1 is added to the temporary, and then the temporary is assigned back\nto the original array. Thus the value of the array at `x[1] + 1` is assigned\nto `x[1]` three times, rather than being incremented 3 times.\n\nThe indexing syntax is very powerful but limiting when dealing with a variable\nnumber of indices. For example, if you want to write a function that can\nhandle arguments with various numbers of dimensions without having to write\nspecial case code for each number of possible dimensions, how can that be\ndone? If one supplies to the index a tuple, the tuple will be interpreted as a\nlist of indices. For example:\n\nSo one can use code to construct tuples of any number of indices and then use\nthese within an index.\n\nSlices can be specified within programs by using the slice() function in\nPython. For example:\n\nLikewise, ellipsis can be specified by code by using the Ellipsis object:\n\nFor this reason, it is possible to use the output from the `np.nonzero()`\nfunction directly as an index since it always returns a tuple of index arrays.\n\nBecause the special treatment of tuples, they are not automatically converted\nto an array as a list would be. As an example:\n\nThese are some detailed notes, which are not of importance for day to day\nindexing (in no particular order):\n\n"}, {"name": "Indexing routines", "path": "reference/arrays.indexing", "type": "Indexing routines", "text": "\nSee also\n\nIndexing on ndarrays\n\n`c_`\n\nTranslates slice objects to concatenation along the second axis.\n\n`r_`\n\nTranslates slice objects to concatenation along the first axis.\n\n`s_`\n\nA nicer way to build up index tuples for arrays.\n\n`nonzero`(a)\n\nReturn the indices of the elements that are non-zero.\n\n`where`(condition, [x, y], /)\n\nReturn elements chosen from `x` or `y` depending on `condition`.\n\n`indices`(dimensions[, dtype, sparse])\n\nReturn an array representing the indices of a grid.\n\n`ix_`(*args)\n\nConstruct an open mesh from multiple sequences.\n\n`ogrid`\n\n`nd_grid` instance which returns an open multi-dimensional \"meshgrid\".\n\n`ravel_multi_index`(multi_index, dims[, mode, ...])\n\nConverts a tuple of index arrays into an array of flat indices, applying\nboundary modes to the multi-index.\n\n`unravel_index`(indices, shape[, order])\n\nConverts a flat index or array of flat indices into a tuple of coordinate\narrays.\n\n`diag_indices`(n[, ndim])\n\nReturn the indices to access the main diagonal of an array.\n\n`diag_indices_from`(arr)\n\nReturn the indices to access the main diagonal of an n-dimensional array.\n\n`mask_indices`(n, mask_func[, k])\n\nReturn the indices to access (n, n) arrays, given a masking function.\n\n`tril_indices`(n[, k, m])\n\nReturn the indices for the lower-triangle of an (n, m) array.\n\n`tril_indices_from`(arr[, k])\n\nReturn the indices for the lower-triangle of arr.\n\n`triu_indices`(n[, k, m])\n\nReturn the indices for the upper-triangle of an (n, m) array.\n\n`triu_indices_from`(arr[, k])\n\nReturn the indices for the upper-triangle of arr.\n\n`take`(a, indices[, axis, out, mode])\n\nTake elements from an array along an axis.\n\n`take_along_axis`(arr, indices, axis)\n\nTake values from the input array by matching 1d index and data slices.\n\n`choose`(a, choices[, out, mode])\n\nConstruct an array from an index array and a list of arrays to choose from.\n\n`compress`(condition, a[, axis, out])\n\nReturn selected slices of an array along given axis.\n\n`diag`(v[, k])\n\nExtract a diagonal or construct a diagonal array.\n\n`diagonal`(a[, offset, axis1, axis2])\n\nReturn specified diagonals.\n\n`select`(condlist, choicelist[, default])\n\nReturn an array drawn from elements in choicelist, depending on conditions.\n\n`lib.stride_tricks.sliding_window_view`(x, ...)\n\nCreate a sliding window view into the array with the given window shape.\n\n`lib.stride_tricks.as_strided`(x[, shape, ...])\n\nCreate a view into the array with the given shape and strides.\n\n`place`(arr, mask, vals)\n\nChange elements of an array based on conditional and input values.\n\n`put`(a, ind, v[, mode])\n\nReplaces specified elements of an array with given values.\n\n`put_along_axis`(arr, indices, values, axis)\n\nPut values into the destination array by matching 1d index and data slices.\n\n`putmask`(a, mask, values)\n\nChanges elements of an array based on conditional and input values.\n\n`fill_diagonal`(a, val[, wrap])\n\nFill the main diagonal of the given array of any dimensionality.\n\n`nditer`(op[, flags, op_flags, op_dtypes, ...])\n\nEfficient multi-dimensional iterator object to iterate over arrays.\n\n`ndenumerate`(arr)\n\nMultidimensional index iterator.\n\n`ndindex`(*shape)\n\nAn N-dimensional iterator object to index arrays.\n\n`nested_iters`(op, axes[, flags, op_flags, ...])\n\nCreate nditers for use in nested loops\n\n`flatiter`()\n\nFlat iterator object to iterate over arrays.\n\n`lib.Arrayterator`(var[, buf_size])\n\nBuffered iterator for big arrays.\n\n"}, {"name": "Input and output", "path": "reference/routines.io", "type": "Input and output", "text": "\n`load`(file[, mmap_mode, allow_pickle, ...])\n\nLoad arrays or pickled objects from `.npy`, `.npz` or pickled files.\n\n`save`(file, arr[, allow_pickle, fix_imports])\n\nSave an array to a binary file in NumPy `.npy` format.\n\n`savez`(file, *args, **kwds)\n\nSave several arrays into a single file in uncompressed `.npz` format.\n\n`savez_compressed`(file, *args, **kwds)\n\nSave several arrays into a single file in compressed `.npz` format.\n\nThe format of these binary file types is documented in `numpy.lib.format`\n\n`loadtxt`(fname[, dtype, comments, delimiter, ...])\n\nLoad data from a text file.\n\n`savetxt`(fname, X[, fmt, delimiter, newline, ...])\n\nSave an array to a text file.\n\n`genfromtxt`(fname[, dtype, comments, ...])\n\nLoad data from a text file, with missing values handled as specified.\n\n`fromregex`(file, regexp, dtype[, encoding])\n\nConstruct an array from a text file, using regular expression parsing.\n\n`fromstring`(string[, dtype, count, like])\n\nA new 1-D array initialized from text data in a string.\n\n`ndarray.tofile`(fid[, sep, format])\n\nWrite array to a file as text or binary (default).\n\n`ndarray.tolist`()\n\nReturn the array as an `a.ndim`-levels deep nested list of Python scalars.\n\n`fromfile`(file[, dtype, count, sep, offset, like])\n\nConstruct an array from data in a text or binary file.\n\n`ndarray.tofile`(fid[, sep, format])\n\nWrite array to a file as text or binary (default).\n\n`array2string`(a[, max_line_width, precision, ...])\n\nReturn a string representation of an array.\n\n`array_repr`(arr[, max_line_width, precision, ...])\n\nReturn the string representation of an array.\n\n`array_str`(a[, max_line_width, precision, ...])\n\nReturn a string representation of the data in an array.\n\n`format_float_positional`(x[, precision, ...])\n\nFormat a floating-point scalar as a decimal string in positional notation.\n\n`format_float_scientific`(x[, precision, ...])\n\nFormat a floating-point scalar as a decimal string in scientific notation.\n\n`memmap`(filename[, dtype, mode, offset, ...])\n\nCreate a memory-map to an array stored in a binary file on disk.\n\n`lib.format.open_memmap`(filename[, mode, ...])\n\nOpen a .npy file as a memory-mapped array.\n\n`set_printoptions`([precision, threshold, ...])\n\nSet printing options.\n\n`get_printoptions`()\n\nReturn the current print options.\n\n`set_string_function`(f[, repr])\n\nSet a Python function to be used when pretty printing arrays.\n\n`printoptions`(*args, **kwargs)\n\nContext manager for setting print options.\n\n`binary_repr`(num[, width])\n\nReturn the binary representation of the input number as a string.\n\n`base_repr`(number[, base, padding])\n\nReturn a string representation of a number in the given base system.\n\n`DataSource`([destpath])\n\nA generic data source file (file, http, ftp, ...).\n\n`lib.format`\n\nBinary serialization\n\n"}, {"name": "Install git", "path": "dev/gitwash/git_intro", "type": "Development", "text": "\nDeveloping with git can be done entirely without github. Git is a distributed\nversion control system. In order to use git on your machine you must install\nit.\n\n"}, {"name": "int **cancastscalarkindto", "path": "reference/c-api/types-and-structures#c.PyArray_ArrFuncs.cancastscalarkindto", "type": "Python Types and C-Structures", "text": "\nEither `NULL` or an array of `NPY_NSCALARKINDS` pointers. These pointers\nshould each be either `NULL` or a pointer to an array of integers (terminated\nby `NPY_NOTYPE`) indicating data-types that a scalar of this data-type of the\nspecified kind can be cast to safely (this usually means without losing\nprecision).\n\n"}, {"name": "int *cancastto", "path": "reference/c-api/types-and-structures#c.PyArray_ArrFuncs.cancastto", "type": "Python Types and C-Structures", "text": "\nEither `NULL` or an array of integers (terminated by `NPY_NOTYPE` ) indicated\ndata-types that this data-type can be cast to safely (this usually means\nwithout losing precision).\n\n"}, {"name": "int *core_dim_ixs", "path": "reference/c-api/types-and-structures#c.PyUFuncObject.core_dim_ixs", "type": "Python Types and C-Structures", "text": "\nDimension indices in a flattened form; indices of argument `k` are stored in\n`core_dim_ixs[core_offsets[k] : core_offsets[k] + core_numdims[k]]`\n\n"}, {"name": "int *core_num_dims", "path": "reference/c-api/types-and-structures#c.PyUFuncObject.core_num_dims", "type": "Python Types and C-Structures", "text": "\nNumber of core dimensions of each argument\n\n"}, {"name": "int *core_offsets", "path": "reference/c-api/types-and-structures#c.PyUFuncObject.core_offsets", "type": "Python Types and C-Structures", "text": "\nPosition of 1st core dimension of each argument in `core_dim_ixs`, equivalent\nto cumsum(`core_num_dims`)\n\n"}, {"name": "int alignment", "path": "reference/c-api/types-and-structures#c.NPY_USE_SETITEM.alignment", "type": "Python Types and C-Structures", "text": "\nA number providing alignment information for this data type. Specifically, it\nshows how far from the start of a 2-element structure (whose first element is\na `char` ), the compiler places an item of this type: `offsetof(struct {char\nc; type v;}, v)`\n\n"}, {"name": "int argmax()", "path": "reference/c-api/types-and-structures#c.PyArray_ArrFuncs.argmax", "type": "Python Types and C-Structures", "text": "\nA pointer to a function that retrieves the index of the largest of `n`\nelements in `arr` beginning at the element pointed to by `data`. This function\nrequires that the memory segment be contiguous and behaved. The return value\nis always 0. The index of the largest element is returned in `max_ind`.\n\n"}, {"name": "int argmin()", "path": "reference/c-api/types-and-structures#c.PyArray_ArrFuncs.argmin", "type": "Python Types and C-Structures", "text": "\nA pointer to a function that retrieves the index of the smallest of `n`\nelements in `arr` beginning at the element pointed to by `data`. This function\nrequires that the memory segment be contiguous and behaved. The return value\nis always 0. The index of the smallest element is returned in `min_ind`.\n\n"}, {"name": "int argsort()", "path": "reference/c-api/types-and-structures#c.PyArray_ArrFuncs.argsort", "type": "Python Types and C-Structures", "text": "\nAn array of function pointers to sorting algorithms for this data type. The\nsame sorting algorithms as for sort are available. The indices producing the\nsort are returned in `result` (which must be initialized with indices 0 to\n`length-1` inclusive).\n\n"}, {"name": "int compare()", "path": "reference/c-api/types-and-structures#c.PyArray_ArrFuncs.compare", "type": "Python Types and C-Structures", "text": "\nA pointer to a function that compares two elements of the array, `arr`,\npointed to by `d1` and `d2`. This function requires behaved (aligned and not\nswapped) arrays. The return value is 1 if * `d1` > * `d2`, 0 if * `d1` == *\n`d2`, and -1 if * `d1` < * `d2`. The array object `arr` is used to retrieve\nitemsize and field information for flexible arrays.\n\n"}, {"name": "int core_enabled", "path": "reference/c-api/types-and-structures#c.PyUFuncObject.core_enabled", "type": "Python Types and C-Structures", "text": "\n0 for scalar ufuncs; 1 for generalized ufuncs\n\n"}, {"name": "int core_num_dim_ix", "path": "reference/c-api/types-and-structures#c.PyUFuncObject.core_num_dim_ix", "type": "Python Types and C-Structures", "text": "\nNumber of distinct core dimension names in the signature\n\n"}, {"name": "int doxy_javadoc_example()", "path": "dev/howto-docs", "type": "Development", "text": "\nThis guide will help you decide what to contribute and how to submit it to the\nofficial NumPy documentation.\n\nThe NumPy community has set a firm goal of improving its documentation. We\nhold regular documentation meetings on Zoom (dates are announced on the numpy-\ndiscussion mailing list), and everyone is welcome. Reach out if you have\nquestions or need someone to guide you through your first steps \u2013 we\u2019re happy\nto help. Minutes are taken on hackmd.io and stored in the NumPy Archive\nrepository.\n\nThe NumPy Documentation has the details covered. API reference documentation\nis generated directly from docstrings in the code when the documentation is\nbuilt. Although we have mostly complete reference documentation for each\nfunction and class exposed to users, there is a lack of usage examples for\nsome of them.\n\nWhat we lack are docs with broader scope \u2013 tutorials, how-tos, and\nexplanations. Reporting defects is another way to contribute. We discuss both.\n\nWe\u2019re eager to hear about and fix doc defects. But to attack the biggest\nproblems we end up having to defer or overlook some bug reports. Here are the\nbest defects to go after.\n\nTop priority goes to technical inaccuracies \u2013 a docstring missing a parameter,\na faulty description of a function/parameter/method, and so on. Other\n\u201cstructural\u201d defects like broken links also get priority. All these fixes are\neasy to confirm and put in place. You can submit a pull request (PR) with the\nfix, if you know how to do that; otherwise please open an issue.\n\nTypos and misspellings fall on a lower rung; we welcome hearing about them but\nmay not be able to fix them promptly. These too can be handled as pull\nrequests or issues.\n\nObvious wording mistakes (like leaving out a \u201cnot\u201d) fall into the typo\ncategory, but other rewordings \u2013 even for grammar \u2013 require a judgment call,\nwhich raises the bar. Test the waters by first presenting the fix as an issue.\n\nSome functions/objects like numpy.ndarray.transpose, numpy.array etc. defined\nin C-extension modules have their docstrings defined separately in\n_add_newdocs.py\n\nYour frustrations using our documents are our best guide to what needs fixing.\n\nIf you write a missing doc you join the front line of open source, but it\u2019s a\nmeaningful contribution just to let us know what\u2019s missing. If you want to\ncompose a doc, run your thoughts by the mailing list for further ideas and\nfeedback. If you want to alert us to a gap, open an issue. See this issue for\nan example.\n\nIf you\u2019re looking for subjects, our formal roadmap for documentation is a\nNumPy Enhancement Proposal (NEP), NEP 44 - Restructuring the NumPy\nDocumentation. It identifies areas where our docs need help and lists several\nadditions we\u2019d like to see, including Jupyter notebooks.\n\nThere are formulas for writing useful documents, and four formulas cover\nnearly everything. There are four formulas because there are four categories\nof document \u2013 `tutorial`, `how-to guide`, `explanation`, and `reference`. The\ninsight that docs divide up this way belongs to Daniele Procida and his\nDi\u00e1taxis Framework. When you begin a document or propose one, have in mind\nwhich of these types it will be.\n\nIn addition to the documentation that is part of the NumPy source tree, you\ncan submit content in Jupyter Notebook format to the NumPy Tutorials page.\nThis set of tutorials and educational materials is meant to provide high-\nquality resources by the NumPy project, both for self-learning and for\nteaching classes with. These resources are developed in a separate GitHub\nrepository, numpy-tutorials, where you can check out existing notebooks, open\nissues to suggest new topics or submit your own tutorials as pull requests.\n\nDon\u2019t worry if English is not your first language, or if you can only come up\nwith a rough draft. Open source is a community effort. Do your best \u2013 we\u2019ll\nhelp fix issues.\n\nImages and real-life data make text more engaging and powerful, but be sure\nwhat you use is appropriately licensed and available. Here again, even a rough\nidea for artwork can be polished by others.\n\nFor now, the only data formats accepted by NumPy are those also used by other\nPython scientific libraries like pandas, SciPy, or Matplotlib. We\u2019re\ndeveloping a package to accept more formats; contact us for details.\n\nNumPy documentation is kept in the source code tree. To get your document into\nthe docbase you must download the tree, build it, and submit a pull request.\nIf GitHub and pull requests are new to you, check our Contributor Guide.\n\nOur markup language is reStructuredText (rST), which is more elaborate than\nMarkdown. Sphinx, the tool many Python projects use to build and link project\ndocumentation, converts the rST into HTML and other formats. For more on rST,\nsee the Quick reStructuredText Guide or the reStructuredText Primer\n\nIf you run across outside material that would be a useful addition to the\nNumPy docs, let us know by opening an issue.\n\nYou don\u2019t have to contribute here to contribute to NumPy. You\u2019ve contributed\nif you write a tutorial on your blog, create a YouTube video, or answer\nquestions on Stack Overflow and other sites.\n\nNumPy style governs cases where:\n\nOur current rules:\n\nWhen using Sphinx in combination with the NumPy conventions, you should use\nthe `numpydoc` extension so that your docstrings will be handled correctly.\nFor example, Sphinx will extract the `Parameters` section from your docstring\nand convert it into a field list. Using `numpydoc` will also avoid the\nreStructuredText errors produced by plain Sphinx when it encounters NumPy\ndocstring conventions like section headers (e.g. `-------------`) that sphinx\ndoes not expect to find in docstrings.\n\nIt is available from:\n\nNote that for documentation within NumPy, it is not necessary to do `import\nnumpy as np` at the beginning of an example.\n\nPlease use the `numpydoc` formatting standard as shown in their example.\n\nNumPy uses Doxygen to parse specially-formatted C/C++ comment blocks. This\ngenerates XML files, which are converted by Breathe into RST, which is used by\nSphinx.\n\nIt takes three steps to complete the documentation process:\n\nAlthough there is still no commenting style set to follow, the Javadoc is more\npreferable than the others due to the similarities with the current existing\nnon-indexed comment blocks.\n\nNote\n\nPlease see \u201cDocumenting the code\u201d.\n\nThis is what Javadoc style looks like:\n\nAnd here is how it is rendered:\n\nThis a simple brief.\n\nAnd the details goes here. Multi lines are welcome.\n\nleave a comment for the returned value.\n\nFor line comment, you can use a triple forward slash. For example:\n\nAnd here is how it is rendered:\n\nTemplate to represent limbo numbers.\n\nSpecializations for integer types that are part of nowhere. It doesn\u2019t support\nwith any real types.\n\nType of the integer. Required to be an integer type.\n\nNumber of elements.\n\nDefault constructor. Initialize nothing.\n\nSet Default behavior for copy the limbo.\n\nReturns the raw data for the limbo.\n\nExample for inline comment.\n\nNote\n\nFor more tags/commands, please take a look at\nhttps://www.doxygen.nl/manual/commands.html\n\n`@brief`\n\nStarts a paragraph that serves as a brief description. By default the first\nsentence of the documentation block is automatically treated as a brief\ndescription, since option JAVADOC_AUTOBRIEF is enabled within doxygen\nconfigurations.\n\n`@details`\n\nJust like `@brief` starts a brief description, `@details` starts the detailed\ndescription. You can also start a new paragraph (blank line) then the\n`@details` command is not needed.\n\n`@param`\n\nStarts a parameter description for a function parameter with name <parameter-\nname>, followed by a description of the parameter. The existence of the\nparameter is checked and a warning is given if the documentation of this (or\nany other) parameter is missing or not present in the function declaration or\ndefinition.\n\n`@return`\n\nStarts a return value description for a function. Multiple adjacent `@return`\ncommands will be joined into a single paragraph. The `@return` description\nends when a blank line or some other sectioning command is encountered.\n\n`@code/@endcode`\n\nStarts/Ends a block of code. A code block is treated differently from ordinary\ntext. It is interpreted as source code.\n\n`@rst/@endrst`\n\nStarts/Ends a block of reST markup.\n\nTake a look at the following example:\n\nAnd here is how it is rendered:\n\nA comment block contains reST markup.\n\nSome code example:\n\nNote\n\nThanks to Breathe, we were able to bring it to Doxygen\n\nNot all headers files are collected automatically. You have to add the desired\nC/C++ header paths within the sub-config files of Doxygen.\n\nSub-config files have the unique name `.doxyfile`, which you can usually find\nnear directories that contain documented headers. You need to create a new\nconfig file if there\u2019s not one located in a path close(2-depth) to the headers\nyou want to add.\n\nSub-config files can accept any of Doxygen configuration options, but do not\noverride or re-initialize any configuration option, rather only use the\nconcatenation operator \u201c+=\u201d. For example:\n\nNote\n\n@CUR_DIR is a template constant returns the current dir path of the sub-config\nfile.\n\nBreathe provides a wide range of custom directives to allow converting the\ndocuments generated by Doxygen into reST files.\n\nNote\n\nFor more information, please check out \u201cDirectives & Config Variables\u201d\n\n`doxygenfunction`\n\nThis directive generates the appropriate output for a single function. The\nfunction name is required to be unique in the project.\n\nCheckout the example to see it in action.\n\n`doxygenclass`\n\nThis directive generates the appropriate output for a single class. It takes\nthe standard project, path, outline and no-link options and additionally the\nmembers, protected-members, private-members, undoc-members, membergroups and\nmembers-only options:\n\nCheckout the `doxygenclass documentation\n<https://breathe.readthedocs.io/en/latest/class.html#class-example>_` for more\ndetails and to see it in action.\n\n`doxygennamespace`\n\nThis directive generates the appropriate output for the contents of a\nnamespace. It takes the standard project, path, outline and no-link options\nand additionally the content-only, members, protected-members, private-members\nand undoc-members options. To reference a nested namespace, the full\nnamespaced path must be provided, e.g. foo::bar for the bar namespace inside\nthe foo namespace.\n\nCheckout the doxygennamespace documentation for more details and to see it in\naction.\n\n`doxygengroup`\n\nThis directive generates the appropriate output for the contents of a doxygen\ngroup. A doxygen group can be declared with specific doxygen markup in the\nsource comments as covered in the doxygen grouping documentation.\n\nIt takes the standard project, path, outline and no-link options and\nadditionally the content-only, members, protected-members, private-members and\nundoc-members options.\n\nCheckout the doxygengroup documentation for more details and to see it in\naction.\n\n"}, {"name": "int elsize", "path": "reference/c-api/types-and-structures#c.NPY_USE_SETITEM.elsize", "type": "Python Types and C-Structures", "text": "\nFor data types that are always the same size (such as long), this holds the\nsize of the data type. For flexible data types where different arrays can have\na different elementsize, this should be 0.\n\n"}, {"name": "int flags", "path": "reference/c-api/types-and-structures#c.PyArray_Chunk.flags", "type": "Python Types and C-Structures", "text": "\nAny data flags (e.g. `NPY_ARRAY_WRITEABLE` ) that should be used to interpret\nthe memory.\n\n"}, {"name": "int flags", "path": "reference/c-api/types-and-structures#c.NPY_AO.flags", "type": "Python Types and C-Structures", "text": "\nPointed to by the macro `PyArray_FLAGS`, this data member represents the flags\nindicating how the memory pointed to by data is to be interpreted. Possible\nflags are `NPY_ARRAY_C_CONTIGUOUS`, `NPY_ARRAY_F_CONTIGUOUS`,\n`NPY_ARRAY_OWNDATA`, `NPY_ARRAY_ALIGNED`, `NPY_ARRAY_WRITEABLE`,\n`NPY_ARRAY_WRITEBACKIFCOPY`, and `NPY_ARRAY_UPDATEIFCOPY`.\n\n"}, {"name": "int flags", "path": "reference/c-api/types-and-structures#c.PyArrayInterface.flags", "type": "Python Types and C-Structures", "text": "\nAny of the bits `NPY_ARRAY_C_CONTIGUOUS` (1), `NPY_ARRAY_F_CONTIGUOUS` (2),\n`NPY_ARRAY_ALIGNED` (0x100), `NPY_ARRAY_NOTSWAPPED` (0x200), or\n`NPY_ARRAY_WRITEABLE` (0x400) to indicate something about the data. The\n`NPY_ARRAY_ALIGNED`, `NPY_ARRAY_C_CONTIGUOUS`, and `NPY_ARRAY_F_CONTIGUOUS`\nflags can actually be determined from the other parameters. The flag\n`NPY_ARR_HAS_DESCR` (0x800) can also be set to indicate to objects consuming\nthe version 3 array interface that the descr member of the structure is\npresent (it will be ignored by objects consuming version 2 of the array\ninterface).\n\n"}, {"name": "int fromstr()", "path": "reference/c-api/types-and-structures#c.PyArray_ArrFuncs.fromstr", "type": "Python Types and C-Structures", "text": "\nA pointer to a function that converts the string pointed to by `str` to one\nelement of the corresponding type and places it in the memory location pointed\nto by `ip`. After the conversion is completed, `*endptr` points to the rest of\nthe string. The last argument `arr` is the array into which ip points (needed\nfor variable-size data- types). Returns 0 on success or -1 on failure.\nRequires a behaved array. This function should be called without holding the\nPython GIL, and has to grab it for error reporting.\n\n"}, {"name": "int identity", "path": "reference/c-api/types-and-structures#c.PyUFuncObject.identity", "type": "Python Types and C-Structures", "text": "\nEither `PyUFunc_One`, `PyUFunc_Zero`, `PyUFunc_MinusOne`, `PyUFunc_None`,\n`PyUFunc_ReorderableNone`, or `PyUFunc_IdentityValue` to indicate the identity\nfor this operation. It is only used for a reduce-like call on an empty array.\n\n"}, {"name": "int itemsize", "path": "reference/c-api/types-and-structures#c.PyArrayInterface.itemsize", "type": "Python Types and C-Structures", "text": "\nThe number of bytes each item in the array requires.\n\n"}, {"name": "int len", "path": "reference/c-api/types-and-structures#c.PyArray_Dims.len", "type": "Python Types and C-Structures", "text": "\nThe length of the list of integers. It is assumed safe to access ptr [0] to\nptr [len-1].\n\n"}, {"name": "int nargs", "path": "reference/c-api/types-and-structures#c.PyUFuncObject.nargs", "type": "Python Types and C-Structures", "text": "\nThe total number of arguments (nin \\+ nout). This must be less than\n`NPY_MAXARGS`.\n\n"}, {"name": "int nd", "path": "reference/c-api/types-and-structures#c.NPY_AO.nd", "type": "Python Types and C-Structures", "text": "\nAn integer providing the number of dimensions for this array. When nd is 0,\nthe array is sometimes called a rank-0 array. Such arrays have undefined\ndimensions and strides and cannot be accessed. Macro `PyArray_NDIM` defined in\n`ndarraytypes.h` points to this data member. `NPY_MAXDIMS` is the largest\nnumber of dimensions for any array.\n\n"}, {"name": "int nd", "path": "reference/c-api/types-and-structures#c.PyArrayMultiIterObject.nd", "type": "Python Types and C-Structures", "text": "\nThe number of dimensions in the broadcasted result.\n\n"}, {"name": "int nd", "path": "reference/c-api/types-and-structures#c.PyArrayInterface.nd", "type": "Python Types and C-Structures", "text": "\nthe number of dimensions in the array.\n\n"}, {"name": "int nout", "path": "reference/c-api/types-and-structures#c.PyUFuncObject.nout", "type": "Python Types and C-Structures", "text": "\nThe number of output arguments.\n\n"}, {"name": "int npy_clear_floatstatus()", "path": "reference/c-api/coremath#c.npy_clear_floatstatus", "type": "NumPy core libraries", "text": "\nClears the floating point status. Returns the previous status mask.\n\nNote that `npy_clear_floatstatus_barrier` is preferable as it prevents\naggressive compiler optimizations reordering the call relative to the code\nsetting the status, which could lead to incorrect results.\n\nNew in version 1.9.0.\n\n"}, {"name": "int npy_clear_floatstatus_barrier()", "path": "reference/c-api/coremath#c.npy_clear_floatstatus_barrier", "type": "NumPy core libraries", "text": "\nClears the floating point status. A pointer to a local variable is passed in\nto prevent aggressive compiler optimizations from reordering this function\ncall. Returns the previous status mask.\n\nNew in version 1.15.0.\n\n"}, {"name": "int npy_get_floatstatus()", "path": "reference/c-api/coremath#c.npy_get_floatstatus", "type": "NumPy core libraries", "text": "\nGet floating point status. Returns a bitmask with following possible flags:\n\nNote that `npy_get_floatstatus_barrier` is preferable as it prevents\naggressive compiler optimizations reordering the call relative to the code\nsetting the status, which could lead to incorrect results.\n\nNew in version 1.9.0.\n\n"}, {"name": "int npy_get_floatstatus_barrier()", "path": "reference/c-api/coremath#c.npy_get_floatstatus_barrier", "type": "NumPy core libraries", "text": "\nGet floating point status. A pointer to a local variable is passed in to\nprevent aggressive compiler optimizations from reordering this function call\nrelative to the code setting the status, which could lead to incorrect\nresults.\n\nReturns a bitmask with following possible flags:\n\nNew in version 1.15.0.\n\n"}, {"name": "int npy_half_eq()", "path": "reference/c-api/coremath#c.npy_half_eq", "type": "NumPy core libraries", "text": "\nCompares two half-precision floats (h1 == h2).\n\n"}, {"name": "int npy_half_eq_nonan()", "path": "reference/c-api/coremath#c.npy_half_eq_nonan", "type": "NumPy core libraries", "text": "\nCompares two half-precision floats that are known to not be NaN (h1 == h2). If\na value is NaN, the result is undefined.\n\n"}, {"name": "int npy_half_ge()", "path": "reference/c-api/coremath#c.npy_half_ge", "type": "NumPy core libraries", "text": "\nCompares two half-precision floats (h1 >= h2).\n\n"}, {"name": "int npy_half_gt()", "path": "reference/c-api/coremath#c.npy_half_gt", "type": "NumPy core libraries", "text": "\nCompares two half-precision floats (h1 > h2).\n\n"}, {"name": "int npy_half_isfinite()", "path": "reference/c-api/coremath#c.npy_half_isfinite", "type": "NumPy core libraries", "text": "\nTests whether the half-precision float is finite (not NaN or Inf).\n\n"}, {"name": "int npy_half_isinf()", "path": "reference/c-api/coremath#c.npy_half_isinf", "type": "NumPy core libraries", "text": "\nTests whether the half-precision float is plus or minus Inf.\n\n"}, {"name": "int npy_half_isnan()", "path": "reference/c-api/coremath#c.npy_half_isnan", "type": "NumPy core libraries", "text": "\nTests whether the half-precision float is a NaN.\n\n"}, {"name": "int npy_half_iszero()", "path": "reference/c-api/coremath#c.npy_half_iszero", "type": "NumPy core libraries", "text": "\nTests whether the half-precision float has a value equal to zero. This may be\nslightly faster than calling npy_half_eq(h, NPY_ZERO).\n\n"}, {"name": "int npy_half_le()", "path": "reference/c-api/coremath#c.npy_half_le", "type": "NumPy core libraries", "text": "\nCompares two half-precision floats (h1 <= h2).\n\n"}, {"name": "int npy_half_le_nonan()", "path": "reference/c-api/coremath#c.npy_half_le_nonan", "type": "NumPy core libraries", "text": "\nCompares two half-precision floats that are known to not be NaN (h1 <= h2). If\na value is NaN, the result is undefined.\n\n"}, {"name": "int npy_half_lt()", "path": "reference/c-api/coremath#c.npy_half_lt", "type": "NumPy core libraries", "text": "\nCompares two half-precision floats (h1 < h2).\n\n"}, {"name": "int npy_half_lt_nonan()", "path": "reference/c-api/coremath#c.npy_half_lt_nonan", "type": "NumPy core libraries", "text": "\nCompares two half-precision floats that are known to not be NaN (h1 < h2). If\na value is NaN, the result is undefined.\n\n"}, {"name": "int npy_half_ne()", "path": "reference/c-api/coremath#c.npy_half_ne", "type": "NumPy core libraries", "text": "\nCompares two half-precision floats (h1 != h2).\n\n"}, {"name": "int npy_half_signbit()", "path": "reference/c-api/coremath#c.npy_half_signbit", "type": "NumPy core libraries", "text": "\nReturns 1 is h is negative, 0 otherwise.\n\n"}, {"name": "int NpyIter_CreateCompatibleStrides()", "path": "reference/c-api/iterator#c.NpyIter_CreateCompatibleStrides", "type": "Array Iterator API", "text": "\nBuilds a set of strides which are the same as the strides of an output array\ncreated using the `NPY_ITER_ALLOCATE` flag, where NULL was passed for op_axes.\nThis is for data packed contiguously, but not necessarily in C or Fortran\norder. This should be used together with `NpyIter_GetShape` and\n`NpyIter_GetNDim` with the flag `NPY_ITER_MULTI_INDEX` passed into the\nconstructor.\n\nA use case for this function is to match the shape and layout of the iterator\nand tack on one or more dimensions. For example, in order to generate a vector\nper input value for a numerical gradient, you pass in ndim*itemsize for\nitemsize, then add another dimension to the end with size ndim and stride\nitemsize. To do the Hessian matrix, you do the same thing but add two\ndimensions, or take advantage of the symmetry and pack it into 1 dimension\nwith a particular encoding.\n\nThis function may only be called if the iterator is tracking a multi-index and\nif `NPY_ITER_DONT_NEGATE_STRIDES` was used to prevent an axis from being\niterated in reverse order.\n\nIf an array is created with this method, simply adding \u2018itemsize\u2019 for each\niteration will traverse the new array matching the iterator.\n\nReturns `NPY_SUCCEED` or `NPY_FAIL`.\n\n"}, {"name": "int NpyIter_Deallocate()", "path": "reference/c-api/iterator#c.NpyIter_Deallocate", "type": "Array Iterator API", "text": "\nDeallocates the iterator object and resolves any needed writebacks.\n\nReturns `NPY_SUCCEED` or `NPY_FAIL`.\n\n"}, {"name": "int NpyIter_EnableExternalLoop()", "path": "reference/c-api/iterator#c.NpyIter_EnableExternalLoop", "type": "Array Iterator API", "text": "\nIf `NpyIter_RemoveMultiIndex` was called, you may want to enable the flag\n`NPY_ITER_EXTERNAL_LOOP`. This flag is not permitted together with\n`NPY_ITER_MULTI_INDEX`, so this function is provided to enable the feature\nafter `NpyIter_RemoveMultiIndex` is called. This function also resets the\niterator to its initial state.\n\nWARNING: This function changes the internal logic of the iterator. Any cached\nfunctions or pointers from the iterator must be retrieved again!\n\nReturns `NPY_SUCCEED` or `NPY_FAIL`.\n\n"}, {"name": "int NpyIter_GetNDim()", "path": "reference/c-api/iterator#c.NpyIter_GetNDim", "type": "Array Iterator API", "text": "\nReturns the number of dimensions being iterated. If a multi-index was not\nrequested in the iterator constructor, this value may be smaller than the\nnumber of dimensions in the original objects.\n\n"}, {"name": "int NpyIter_GetNOp()", "path": "reference/c-api/iterator#c.NpyIter_GetNOp", "type": "Array Iterator API", "text": "\nReturns the number of operands in the iterator.\n\n"}, {"name": "int NpyIter_GetShape()", "path": "reference/c-api/iterator#c.NpyIter_GetShape", "type": "Array Iterator API", "text": "\nReturns the broadcast shape of the iterator in `outshape`. This can only be\ncalled on an iterator which is tracking a multi-index.\n\nReturns `NPY_SUCCEED` or `NPY_FAIL`.\n\n"}, {"name": "int NpyIter_GotoIndex()", "path": "reference/c-api/iterator#c.NpyIter_GotoIndex", "type": "Array Iterator API", "text": "\nAdjusts the iterator to point to the `index` specified. If the iterator was\nconstructed with the flag `NPY_ITER_C_INDEX`, `index` is the C-order index,\nand if the iterator was constructed with the flag `NPY_ITER_F_INDEX`, `index`\nis the Fortran-order index. Returns an error if there is no index being\ntracked, the index is out of bounds, or inner loop iteration is disabled.\n\nReturns `NPY_SUCCEED` or `NPY_FAIL`.\n\n"}, {"name": "int NpyIter_GotoIterIndex()", "path": "reference/c-api/iterator#c.NpyIter_GotoIterIndex", "type": "Array Iterator API", "text": "\nAdjusts the iterator to point to the `iterindex` specified. The IterIndex is\nan index matching the iteration order of the iterator. Returns an error if the\n`iterindex` is out of bounds, buffering is enabled, or inner loop iteration is\ndisabled.\n\nReturns `NPY_SUCCEED` or `NPY_FAIL`.\n\n"}, {"name": "int NpyIter_GotoMultiIndex()", "path": "reference/c-api/iterator#c.NpyIter_GotoMultiIndex", "type": "Array Iterator API", "text": "\nAdjusts the iterator to point to the `ndim` indices pointed to by\n`multi_index`. Returns an error if a multi-index is not being tracked, the\nindices are out of bounds, or inner loop iteration is disabled.\n\nReturns `NPY_SUCCEED` or `NPY_FAIL`.\n\n"}, {"name": "int NpyIter_RemoveAxis()", "path": "reference/c-api/iterator#c.NpyIter_RemoveAxis", "type": "Array Iterator API", "text": "\nRemoves an axis from iteration. This requires that `NPY_ITER_MULTI_INDEX` was\nset for iterator creation, and does not work if buffering is enabled or an\nindex is being tracked. This function also resets the iterator to its initial\nstate.\n\nThis is useful for setting up an accumulation loop, for example. The iterator\ncan first be created with all the dimensions, including the accumulation axis,\nso that the output gets created correctly. Then, the accumulation axis can be\nremoved, and the calculation done in a nested fashion.\n\nWARNING: This function may change the internal memory layout of the iterator.\nAny cached functions or pointers from the iterator must be retrieved again!\nThe iterator range will be reset as well.\n\nReturns `NPY_SUCCEED` or `NPY_FAIL`.\n\n"}, {"name": "int NpyIter_RemoveMultiIndex()", "path": "reference/c-api/iterator#c.NpyIter_RemoveMultiIndex", "type": "Array Iterator API", "text": "\nIf the iterator is tracking a multi-index, this strips support for them, and\ndoes further iterator optimizations that are possible if multi-indices are not\nneeded. This function also resets the iterator to its initial state.\n\nWARNING: This function may change the internal memory layout of the iterator.\nAny cached functions or pointers from the iterator must be retrieved again!\n\nAfter calling this function, NpyIter_HasMultiIndex(iter) will return false.\n\nReturns `NPY_SUCCEED` or `NPY_FAIL`.\n\n"}, {"name": "int NpyIter_Reset()", "path": "reference/c-api/iterator#c.NpyIter_Reset", "type": "Array Iterator API", "text": "\nResets the iterator back to its initial state, at the beginning of the\niteration range.\n\nReturns `NPY_SUCCEED` or `NPY_FAIL`. If errmsg is non-NULL, no Python\nexception is set when `NPY_FAIL` is returned. Instead, *errmsg is set to an\nerror message. When errmsg is non-NULL, the function may be safely called\nwithout holding the Python GIL.\n\n"}, {"name": "int NpyIter_ResetBasePointers()", "path": "reference/c-api/iterator#c.NpyIter_ResetBasePointers", "type": "Array Iterator API", "text": "\nResets the iterator back to its initial state, but using the values in\n`baseptrs` for the data instead of the pointers from the arrays being\niterated. This functions is intended to be used, together with the `op_axes`\nparameter, by nested iteration code with two or more iterators.\n\nReturns `NPY_SUCCEED` or `NPY_FAIL`. If errmsg is non-NULL, no Python\nexception is set when `NPY_FAIL` is returned. Instead, *errmsg is set to an\nerror message. When errmsg is non-NULL, the function may be safely called\nwithout holding the Python GIL.\n\nTODO: Move the following into a special section on nested iterators.\n\nCreating iterators for nested iteration requires some care. All the iterator\noperands must match exactly, or the calls to `NpyIter_ResetBasePointers` will\nbe invalid. This means that automatic copies and output allocation should not\nbe used haphazardly. It is possible to still use the automatic data conversion\nand casting features of the iterator by creating one of the iterators with all\nthe conversion parameters enabled, then grabbing the allocated operands with\nthe `NpyIter_GetOperandArray` function and passing them into the constructors\nfor the rest of the iterators.\n\nWARNING: When creating iterators for nested iteration, the code must not use a\ndimension more than once in the different iterators. If this is done, nested\niteration will produce out-of-bounds pointers during iteration.\n\nWARNING: When creating iterators for nested iteration, buffering can only be\napplied to the innermost iterator. If a buffered iterator is used as the\nsource for `baseptrs`, it will point into a small buffer instead of the array\nand the inner iteration will be invalid.\n\nThe pattern for using nested iterators is as follows.\n\n"}, {"name": "int NpyIter_ResetToIterIndexRange()", "path": "reference/c-api/iterator#c.NpyIter_ResetToIterIndexRange", "type": "Array Iterator API", "text": "\nResets the iterator and restricts it to the `iterindex` range `[istart,\niend)`. See `NpyIter_Copy` for an explanation of how to use this for multi-\nthreaded iteration. This requires that the flag `NPY_ITER_RANGED` was passed\nto the iterator constructor.\n\nIf you want to reset both the `iterindex` range and the base pointers at the\nsame time, you can do the following to avoid extra buffer copying (be sure to\nadd the return code error checks when you copy this code).\n\nReturns `NPY_SUCCEED` or `NPY_FAIL`. If errmsg is non-NULL, no Python\nexception is set when `NPY_FAIL` is returned. Instead, *errmsg is set to an\nerror message. When errmsg is non-NULL, the function may be safely called\nwithout holding the Python GIL.\n\n"}, {"name": "int ntypes", "path": "reference/c-api/types-and-structures#c.PyUFuncObject.ntypes", "type": "Python Types and C-Structures", "text": "\nThe number of supported data types for the ufunc. This number specifies how\nmany different 1-d loops (of the builtin data types) are available.\n\n"}, {"name": "int PyArray_AxisConverter()", "path": "reference/c-api/array#c.PyArray_AxisConverter", "type": "Array API", "text": "\nConvert a Python object, obj, representing an axis argument to the proper\nvalue for passing to the functions that take an integer axis. Specifically, if\nobj is None, axis is set to `NPY_MAXDIMS` which is interpreted correctly by\nthe C-API functions that take axis arguments.\n\n"}, {"name": "int PyArray_BoolConverter()", "path": "reference/c-api/array#c.PyArray_BoolConverter", "type": "Array API", "text": "\nConvert any Python object, obj, to `NPY_TRUE` or `NPY_FALSE`, and place the\nresult in value.\n\n"}, {"name": "int PyArray_Broadcast()", "path": "reference/c-api/array#c.PyArray_Broadcast", "type": "Array API", "text": "\nThis function encapsulates the broadcasting rules. The mit container should\nalready contain iterators for all the arrays that need to be broadcast. On\nreturn, these iterators will be adjusted so that iteration over each\nsimultaneously will accomplish the broadcasting. A negative number is returned\nif an error occurs.\n\n"}, {"name": "int PyArray_BufferConverter()", "path": "reference/c-api/array#c.PyArray_BufferConverter", "type": "Array API", "text": "\nConvert any Python object, obj, with a (single-segment) buffer interface to a\nvariable with members that detail the object\u2019s use of its chunk of memory. The\nbuf variable is a pointer to a structure with base, ptr, len, and flags\nmembers. The `PyArray_Chunk` structure is binary compatible with the Python\u2019s\nbuffer object (through its len member on 32-bit platforms and its ptr member\non 64-bit platforms or in Python 2.5). On return, the base member is set to\nobj (or its base if obj is already a buffer object pointing to another\nobject). If you need to hold on to the memory be sure to INCREF the base\nmember. The chunk of memory is pointed to by buf ->ptr member and has length\nbuf ->len. The flags member of buf is `NPY_ARRAY_ALIGNED` with the\n`NPY_ARRAY_WRITEABLE` flag set if obj has a writeable buffer interface.\n\n"}, {"name": "int PyArray_ByteorderConverter()", "path": "reference/c-api/array#c.PyArray_ByteorderConverter", "type": "Array API", "text": "\nConvert Python strings into the corresponding byte-order character: \u2018>\u2019, \u2018<\u2019,\n\u2018s\u2019, \u2018=\u2019, or \u2018|\u2019.\n\n"}, {"name": "int PyArray_CanCastArrayTo()", "path": "reference/c-api/array#c.PyArray_CanCastArrayTo", "type": "Array API", "text": "\nNew in version 1.6.\n\nReturns non-zero if arr can be cast to totype according to the casting rule\ngiven in casting. If arr is an array scalar, its value is taken into account,\nand non-zero is also returned when the value will not overflow or be truncated\nto an integer when converting to a smaller type.\n\nThis is almost the same as the result of\nPyArray_CanCastTypeTo(PyArray_MinScalarType(arr), totype, casting), but it\nalso handles a special case arising because the set of uint values is not a\nsubset of the int values for types with the same number of bits.\n\n"}, {"name": "int PyArray_CanCastSafely()", "path": "reference/c-api/array#c.PyArray_CanCastSafely", "type": "Array API", "text": "\nReturns non-zero if an array of data type fromtype can be cast to an array of\ndata type totype without losing information. An exception is that 64-bit\nintegers are allowed to be cast to 64-bit floating point values even though\nthis can lose precision on large integers so as not to proliferate the use of\nlong doubles without explicit requests. Flexible array types are not checked\naccording to their lengths with this function.\n\n"}, {"name": "int PyArray_CanCastTo()", "path": "reference/c-api/array#c.PyArray_CanCastTo", "type": "Array API", "text": "\n`PyArray_CanCastTypeTo` supersedes this function in NumPy 1.6 and later.\n\nEquivalent to PyArray_CanCastTypeTo(fromtype, totype, NPY_SAFE_CASTING).\n\n"}, {"name": "int PyArray_CanCastTypeTo()", "path": "reference/c-api/array#c.PyArray_CanCastTypeTo", "type": "Array API", "text": "\nNew in version 1.6.\n\nReturns non-zero if an array of data type fromtype (which can include flexible\ntypes) can be cast safely to an array of data type totype (which can include\nflexible types) according to the casting rule casting. For simple types with\n`NPY_SAFE_CASTING`, this is basically a wrapper around\n`PyArray_CanCastSafely`, but for flexible types such as strings or unicode, it\nproduces results taking into account their sizes. Integer and float types can\nonly be cast to a string or unicode type using `NPY_SAFE_CASTING` if the\nstring or unicode type is big enough to hold the max value of the\ninteger/float type being cast from.\n\n"}, {"name": "int PyArray_CanCoerceScalar()", "path": "reference/c-api/array#c.PyArray_CanCoerceScalar", "type": "Array API", "text": "\nSee the function `PyArray_ResultType` for details of NumPy type promotion,\nupdated in NumPy 1.6.0.\n\nImplements the rules for scalar coercion. Scalars are only silently coerced\nfrom thistype to neededtype if this function returns nonzero. If scalar is\n`NPY_NOSCALAR`, then this function is equivalent to `PyArray_CanCastSafely`.\nThe rule is that scalars of the same KIND can be coerced into arrays of the\nsame KIND. This rule means that high-precision scalars will never cause low-\nprecision arrays of the same KIND to be upcast.\n\n"}, {"name": "int PyArray_CastingConverter()", "path": "reference/c-api/array#c.PyArray_CastingConverter", "type": "Array API", "text": "\nConvert the Python strings \u2018no\u2019, \u2018equiv\u2019, \u2018safe\u2019, \u2018same_kind\u2019, and \u2018unsafe\u2019\ninto the `NPY_CASTING` enumeration `NPY_NO_CASTING`, `NPY_EQUIV_CASTING`,\n`NPY_SAFE_CASTING`, `NPY_SAME_KIND_CASTING`, and `NPY_UNSAFE_CASTING`.\n\n"}, {"name": "int PyArray_CastTo()", "path": "reference/c-api/array#c.PyArray_CastTo", "type": "Array API", "text": "\nAs of 1.6, this function simply calls `PyArray_CopyInto`, which handles the\ncasting.\n\nCast the elements of the array in into the array out. The output array should\nbe writeable, have an integer-multiple of the number of elements in the input\narray (more than one copy can be placed in out), and have a data type that is\none of the builtin types. Returns 0 on success and -1 if an error occurs.\n\n"}, {"name": "int PyArray_CheckAnyScalar()", "path": "reference/c-api/array#c.PyArray_CheckAnyScalar", "type": "Array API", "text": "\nEvaluates true if op is a Python scalar object (see `PyArray_IsPythonScalar`),\nan array scalar (an instance of a sub-type of `PyGenericArr_Type`) or an\ninstance of a sub-type of `PyArray_Type` whose dimensionality is 0.\n\n"}, {"name": "int PyArray_CheckExact()", "path": "reference/c-api/array#c.PyArray_CheckExact", "type": "Array API", "text": "\nEvaluates true if op is a Python object with type `PyArray_Type`.\n\n"}, {"name": "int PyArray_CheckScalar()", "path": "reference/c-api/array#c.PyArray_CheckScalar", "type": "Array API", "text": "\nEvaluates true if op is either an array scalar (an instance of a sub-type of\n`PyGenericArr_Type` ), or an instance of (a sub-class of) `PyArray_Type` whose\ndimensionality is 0.\n\n"}, {"name": "int PyArray_ClipmodeConverter()", "path": "reference/c-api/array#c.PyArray_ClipmodeConverter", "type": "Array API", "text": "\nConvert the Python strings \u2018clip\u2019, \u2018wrap\u2019, and \u2018raise\u2019 into the `NPY_CLIPMODE`\nenumeration `NPY_CLIP`, `NPY_WRAP`, and `NPY_RAISE`.\n\n"}, {"name": "int PyArray_CompareLists()", "path": "reference/c-api/array#c.PyArray_CompareLists", "type": "Array API", "text": "\nGiven two n -length arrays of integers, l1, and l2, return 1 if the lists are\nidentical; otherwise, return 0.\n\n"}, {"name": "int PyArray_ConvertClipmodeSequence()", "path": "reference/c-api/array#c.PyArray_ConvertClipmodeSequence", "type": "Array API", "text": "\nConverts either a sequence of clipmodes or a single clipmode into a C array of\n`NPY_CLIPMODE` values. The number of clipmodes n must be known before calling\nthis function. This function is provided to help functions allow a different\nclipmode for each dimension.\n\n"}, {"name": "int PyArray_CopyInto()", "path": "reference/c-api/array#c.PyArray_CopyInto", "type": "Array API", "text": "\nCopy from the source array, `src`, into the destination array, `dest`,\nperforming a data-type conversion if necessary. If an error occurs return -1\n(otherwise 0). The shape of `src` must be broadcastable to the shape of\n`dest`. The data areas of dest and src must not overlap.\n\n"}, {"name": "int PyArray_CopyObject()", "path": "reference/c-api/array#c.PyArray_CopyObject", "type": "Array API", "text": "\nAssign an object `src` to a NumPy array `dest` according to array-coercion\nrules. This is basically identical to `PyArray_FromAny`, but assigns directly\nto the output array. Returns 0 on success and -1 on failures.\n\n"}, {"name": "int Pyarray_DescrAlignConverter()", "path": "reference/c-api/array#c.Pyarray_DescrAlignConverter", "type": "Array API", "text": "\nLike `PyArray_DescrConverter` except it aligns C-struct-like objects on word-\nboundaries as the compiler would.\n\n"}, {"name": "int Pyarray_DescrAlignConverter2()", "path": "reference/c-api/array#c.Pyarray_DescrAlignConverter2", "type": "Array API", "text": "\nLike `PyArray_DescrConverter2` except it aligns C-struct-like objects on word-\nboundaries as the compiler would.\n\n"}, {"name": "int PyArray_DescrConverter()", "path": "reference/c-api/array#c.PyArray_DescrConverter", "type": "Array API", "text": "\nConvert any compatible Python object, obj, to a data-type object in dtype. A\nlarge number of Python objects can be converted to data-type objects. See Data\ntype objects (dtype) for a complete description. This version of the converter\nconverts None objects to a `NPY_DEFAULT_TYPE` data-type object. This function\ncan be used with the \u201cO&\u201d character code in `PyArg_ParseTuple` processing.\n\n"}, {"name": "int PyArray_DescrConverter2()", "path": "reference/c-api/array#c.PyArray_DescrConverter2", "type": "Array API", "text": "\nConvert any compatible Python object, obj, to a data-type object in dtype.\nThis version of the converter converts None objects so that the returned data-\ntype is `NULL`. This function can also be used with the \u201cO&\u201d character in\nPyArg_ParseTuple processing.\n\n"}, {"name": "int PyArray_Dump()", "path": "reference/c-api/array#c.PyArray_Dump", "type": "Array API", "text": "\nPickle the object in self to the given file (either a string or a Python file\nobject). If file is a Python string it is considered to be the name of a file\nwhich is then opened in binary mode. The given protocol is used (if protocol\nis negative, or the highest available is used). This is a simple wrapper\naround cPickle.dump(self, file, protocol).\n\n"}, {"name": "int PyArray_EquivByteorders()", "path": "reference/c-api/array#c.PyArray_EquivByteorders", "type": "Array API", "text": "\nTrue if byteorder characters b1 and b2 ( `NPY_LITTLE`, `NPY_BIG`,\n`NPY_NATIVE`, `NPY_IGNORE` ) are either equal or equivalent as to their\nspecification of a native byte order. Thus, on a little-endian machine\n`NPY_LITTLE` and `NPY_NATIVE` are equivalent where they are not equivalent on\na big-endian machine.\n\n"}, {"name": "int PyArray_FillWithScalar()", "path": "reference/c-api/array#c.PyArray_FillWithScalar", "type": "Array API", "text": "\nFill the array, arr, with the given scalar object, obj. The object is first\nconverted to the data type of arr, and then copied into every location. A -1\nis returned if an error occurs, otherwise 0 is returned.\n\n"}, {"name": "int PyArray_FinalizeFunc()", "path": "reference/c-api/array#c.PyArray_FinalizeFunc", "type": "Array API", "text": "\nThe function pointed to by the CObject `__array_finalize__`. The first\nargument is the newly created sub-type. The second argument (if not NULL) is\nthe \u201cparent\u201d array (if the array was created using slicing or some other\noperation where a clearly-distinguishable parent is present). This routine can\ndo anything it wants to. It should return a -1 on error and 0 otherwise.\n\n"}, {"name": "int PyArray_FLAGS()", "path": "reference/c-api/array#c.PyArray_FLAGS", "type": "Array API", "text": "\nReturns an integer representing the array-flags.\n\n"}, {"name": "int PyArray_Free()", "path": "reference/c-api/array#c.PyArray_Free", "type": "Array API", "text": "\nMust be called with the same objects and memory locations returned from\n`PyArray_AsCArray` (\u2026). This function cleans up memory that otherwise would\nget leaked.\n\n"}, {"name": "int PyArray_GetArrayParamsFromObject()", "path": "reference/c-api/array#c.PyArray_GetArrayParamsFromObject", "type": "Array API", "text": "\nDeprecated since version NumPy: 1.19\n\nUnless NumPy is made aware of an issue with this, this function is scheduled\nfor rapid removal without replacement.\n\nChanged in version NumPy: 1.19\n\n`context` is never used. Its use results in an error.\n\nNew in version 1.6.\n\n"}, {"name": "int PyArray_GetEndianness()", "path": "reference/c-api/config#c.PyArray_GetEndianness", "type": "System configuration", "text": "\nNew in version 1.3.0.\n\nReturns the endianness of the current platform. One of `NPY_CPU_BIG`,\n`NPY_CPU_LITTLE`, or `NPY_CPU_UNKNOWN_ENDIAN`.\n\n"}, {"name": "int PyArray_HasArrayInterface()", "path": "reference/c-api/array#c.PyArray_HasArrayInterface", "type": "Array API", "text": "\nIf `op` implements any part of the array interface, then `out` will contain a\nnew reference to the newly created ndarray using the interface or `out` will\ncontain `NULL` if an error during conversion occurs. Otherwise, out will\ncontain a borrowed reference to `Py_NotImplemented` and no error condition is\nset.\n\n"}, {"name": "int PyArray_HasArrayInterfaceType()", "path": "reference/c-api/array#c.PyArray_HasArrayInterfaceType", "type": "Array API", "text": "\nIf `op` implements any part of the array interface, then `out` will contain a\nnew reference to the newly created ndarray using the interface or `out` will\ncontain `NULL` if an error during conversion occurs. Otherwise, out will\ncontain a borrowed reference to Py_NotImplemented and no error condition is\nset. This version allows setting of the dtype in the part of the array\ninterface that looks for the `__array__` attribute. `context` is unused.\n\n"}, {"name": "int PyArray_HASFIELDS()", "path": "reference/c-api/array#c.PyArray_HASFIELDS", "type": "Array API", "text": "\nType has fields associated with it.\n\n"}, {"name": "int PyArray_IntpConverter()", "path": "reference/c-api/array#c.PyArray_IntpConverter", "type": "Array API", "text": "\nConvert any Python sequence, obj, smaller than `NPY_MAXDIMS` to a C-array of\n`npy_intp`. The Python object could also be a single number. The seq variable\nis a pointer to a structure with members ptr and len. On successful return,\nseq ->ptr contains a pointer to memory that must be freed, by calling\n`PyDimMem_FREE`, to avoid a memory leak. The restriction on memory size allows\nthis converter to be conveniently used for sequences intended to be\ninterpreted as array shapes.\n\n"}, {"name": "int PyArray_IntpFromSequence()", "path": "reference/c-api/array#c.PyArray_IntpFromSequence", "type": "Array API", "text": "\nConvert any Python sequence (or single Python number) passed in as seq to (up\nto) maxvals pointer-sized integers and place them in the vals array. The\nsequence can be smaller then maxvals as the number of converted objects is\nreturned.\n\n"}, {"name": "int PyArray_IS_C_CONTIGUOUS()", "path": "reference/c-api/array#c.PyArray_IS_C_CONTIGUOUS", "type": "Array API", "text": "\nEvaluates true if arr is C-style contiguous.\n\n"}, {"name": "int PyArray_IS_F_CONTIGUOUS()", "path": "reference/c-api/array#c.PyArray_IS_F_CONTIGUOUS", "type": "Array API", "text": "\nEvaluates true if arr is Fortran-style contiguous.\n\n"}, {"name": "int PyArray_ISALIGNED()", "path": "reference/c-api/array#c.PyArray_ISALIGNED", "type": "Array API", "text": "\nEvaluates true if the data area of arr is properly aligned on the machine.\n\n"}, {"name": "int PyArray_IsAnyScalar()", "path": "reference/c-api/array#c.PyArray_IsAnyScalar", "type": "Array API", "text": "\nEvaluates true if op is either a Python scalar object (see\n`PyArray_IsPythonScalar`) or an array scalar (an instance of a sub- type of\n`PyGenericArr_Type` ).\n\n"}, {"name": "int PyArray_ISBEHAVED()", "path": "reference/c-api/array#c.PyArray_ISBEHAVED", "type": "Array API", "text": "\nEvaluates true if the data area of arr is aligned and writeable and in machine\nbyte-order according to its descriptor.\n\n"}, {"name": "int PyArray_ISBEHAVED_RO()", "path": "reference/c-api/array#c.PyArray_ISBEHAVED_RO", "type": "Array API", "text": "\nEvaluates true if the data area of arr is aligned and in machine byte-order.\n\n"}, {"name": "int PyArray_ISBOOL()", "path": "reference/c-api/array#c.PyArray_ISBOOL", "type": "Array API", "text": "\nType represents Boolean data type.\n\n"}, {"name": "int PyArray_ISBYTESWAPPED()", "path": "reference/c-api/array#c.PyArray_ISBYTESWAPPED", "type": "Array API", "text": "\nEvaluates true if the data area of the ndarray m is not in machine byte-order\naccording to the array\u2019s data-type descriptor.\n\n"}, {"name": "int PyArray_ISCARRAY()", "path": "reference/c-api/array#c.PyArray_ISCARRAY", "type": "Array API", "text": "\nEvaluates true if the data area of arr is C-style contiguous, and\n`PyArray_ISBEHAVED` (arr) is true.\n\n"}, {"name": "int PyArray_ISCARRAY_RO()", "path": "reference/c-api/array#c.PyArray_ISCARRAY_RO", "type": "Array API", "text": "\nEvaluates true if the data area of arr is C-style contiguous, aligned, and in\nmachine byte-order.\n\n"}, {"name": "int PyArray_ISCOMPLEX()", "path": "reference/c-api/array#c.PyArray_ISCOMPLEX", "type": "Array API", "text": "\nType represents any complex floating point number.\n\n"}, {"name": "int PyArray_ISEXTENDED()", "path": "reference/c-api/array#c.PyArray_ISEXTENDED", "type": "Array API", "text": "\nType is either flexible or user-defined.\n\n"}, {"name": "int PyArray_ISFARRAY()", "path": "reference/c-api/array#c.PyArray_ISFARRAY", "type": "Array API", "text": "\nEvaluates true if the data area of arr is Fortran-style contiguous and\n`PyArray_ISBEHAVED` (arr) is true.\n\n"}, {"name": "int PyArray_ISFARRAY_RO()", "path": "reference/c-api/array#c.PyArray_ISFARRAY_RO", "type": "Array API", "text": "\nEvaluates true if the data area of arr is Fortran-style contiguous, aligned,\nand in machine byte-order .\n\n"}, {"name": "int PyArray_ISFLEXIBLE()", "path": "reference/c-api/array#c.PyArray_ISFLEXIBLE", "type": "Array API", "text": "\nType represents one of the flexible array types ( `NPY_STRING`, `NPY_UNICODE`,\nor `NPY_VOID` ).\n\n"}, {"name": "int PyArray_ISFLOAT()", "path": "reference/c-api/array#c.PyArray_ISFLOAT", "type": "Array API", "text": "\nType represents any floating point number.\n\n"}, {"name": "int PyArray_ISFORTRAN()", "path": "reference/c-api/array#c.PyArray_ISFORTRAN", "type": "Array API", "text": "\nEvaluates true if arr is Fortran-style contiguous and not C-style contiguous.\n`PyArray_IS_F_CONTIGUOUS` is the correct way to test for Fortran-style\ncontiguity.\n\n"}, {"name": "int PyArray_ISINTEGER()", "path": "reference/c-api/array#c.PyArray_ISINTEGER", "type": "Array API", "text": "\nType represents any integer.\n\n"}, {"name": "int PyArray_ISNOTSWAPPED()", "path": "reference/c-api/array#c.PyArray_ISNOTSWAPPED", "type": "Array API", "text": "\nEvaluates true if the data area of the ndarray m is in machine byte-order\naccording to the array\u2019s data-type descriptor.\n\n"}, {"name": "int PyArray_ISNUMBER()", "path": "reference/c-api/array#c.PyArray_ISNUMBER", "type": "Array API", "text": "\nType represents any integer, floating point, or complex floating point number.\n\n"}, {"name": "int PyArray_ISOBJECT()", "path": "reference/c-api/array#c.PyArray_ISOBJECT", "type": "Array API", "text": "\nType represents object data type.\n\n"}, {"name": "int PyArray_ISONESEGMENT()", "path": "reference/c-api/array#c.PyArray_ISONESEGMENT", "type": "Array API", "text": "\nEvaluates true if the data area of arr consists of a single (C-style or\nFortran-style) contiguous segment.\n\n"}, {"name": "int PyArray_ISPYTHON()", "path": "reference/c-api/array#c.PyArray_ISPYTHON", "type": "Array API", "text": "\nType represents an enumerated type corresponding to one of the standard Python\nscalar (bool, int, float, or complex).\n\n"}, {"name": "int PyArray_IsPythonNumber()", "path": "reference/c-api/array#c.PyArray_IsPythonNumber", "type": "Array API", "text": "\nEvaluates true if op is an instance of a builtin numeric type (int, float,\ncomplex, long, bool)\n\n"}, {"name": "int PyArray_IsPythonScalar()", "path": "reference/c-api/array#c.PyArray_IsPythonScalar", "type": "Array API", "text": "\nEvaluates true if op is a builtin Python scalar object (int, float, complex,\nbytes, str, long, bool).\n\n"}, {"name": "int PyArray_ISSIGNED()", "path": "reference/c-api/array#c.PyArray_ISSIGNED", "type": "Array API", "text": "\nType represents a signed integer.\n\n"}, {"name": "int PyArray_ISSTRING()", "path": "reference/c-api/array#c.PyArray_ISSTRING", "type": "Array API", "text": "\nType represents a string data type.\n\n"}, {"name": "int PyArray_ISUNSIGNED()", "path": "reference/c-api/array#c.PyArray_ISUNSIGNED", "type": "Array API", "text": "\nType represents an unsigned integer.\n\n"}, {"name": "int PyArray_ISUSERDEF()", "path": "reference/c-api/array#c.PyArray_ISUSERDEF", "type": "Array API", "text": "\nType represents a user-defined type.\n\n"}, {"name": "int PyArray_ISWRITEABLE()", "path": "reference/c-api/array#c.PyArray_ISWRITEABLE", "type": "Array API", "text": "\nEvaluates true if the data area of arr can be written to\n\n"}, {"name": "int PyArray_IsZeroDim()", "path": "reference/c-api/array#c.PyArray_IsZeroDim", "type": "Array API", "text": "\nEvaluates true if op is an instance of (a subclass of) `PyArray_Type` and has\n0 dimensions.\n\n"}, {"name": "int PyArray_ITER_NOTDONE()", "path": "reference/c-api/array#c.PyArray_ITER_NOTDONE", "type": "Array API", "text": "\nEvaluates TRUE as long as the iterator has not looped through all of the\nelements, otherwise it evaluates FALSE.\n\n"}, {"name": "int PyArray_MoveInto()", "path": "reference/c-api/array#c.PyArray_MoveInto", "type": "Array API", "text": "\nMove data from the source array, `src`, into the destination array, `dest`,\nperforming a data-type conversion if necessary. If an error occurs return -1\n(otherwise 0). The shape of `src` must be broadcastable to the shape of\n`dest`. The data areas of dest and src may overlap.\n\n"}, {"name": "int PyArray_MultiIter_NOTDONE()", "path": "reference/c-api/array#c.PyArray_MultiIter_NOTDONE", "type": "Array API", "text": "\nEvaluates TRUE as long as the multi-iterator has not looped through all of the\nelements (of the broadcasted result), otherwise it evaluates FALSE.\n\n"}, {"name": "int PyArray_MultiplyIntList()", "path": "reference/c-api/array#c.PyArray_MultiplyIntList", "type": "Array API", "text": "\nBoth of these routines multiply an n -length array, seq, of integers and\nreturn the result. No overflow checking is performed.\n\n"}, {"name": "int PyArray_NDIM()", "path": "reference/c-api/array", "type": "Array API", "text": "\nThese macros access the `PyArrayObject` structure members and are defined in\n`ndarraytypes.h`. The input argument, arr, can be any PyObject* that is\ndirectly interpretable as a PyArrayObject* (any instance of the `PyArray_Type`\nand its sub-types).\n\nThe number of dimensions in the array.\n\nReturns an integer representing the array-flags.\n\nReturn the (builtin) typenumber for the elements of this array.\n\nConvert obj and place it in the ndarray, arr, at the place pointed to by\nitemptr. Return -1 if an error occurs or 0 on success.\n\nNew in version 1.7.\n\nEnables the specified array flags. This function does no validation, and\nassumes that you know what you\u2019re doing.\n\nNew in version 1.7.\n\nClears the specified array flags. This function does no validation, and\nassumes that you know what you\u2019re doing.\n\nThese two macros are similar and obtain the pointer to the data-buffer for the\narray. The first macro can (and should be) assigned to a particular pointer\nwhere the second is for generic processing. If you have not guaranteed a\ncontiguous and/or aligned array then be sure you understand how to access the\ndata in the array to avoid memory and/or alignment problems.\n\nReturns a pointer to the dimensions/shape of the array. The number of elements\nmatches the number of dimensions of the array. Can return `NULL` for\n0-dimensional arrays.\n\nNew in version 1.7.\n\nA synonym for `PyArray_DIMS`, named to be consistent with the `shape` usage\nwithin Python.\n\nReturns a pointer to the strides of the array. The number of elements matches\nthe number of dimensions of the array.\n\nReturn the shape in the n \\\\(^{\\textrm{th}}\\\\) dimension.\n\nReturn the stride in the n \\\\(^{\\textrm{th}}\\\\) dimension.\n\nReturn the itemsize for the elements of this array.\n\nNote that, in the old API that was deprecated in version 1.7, this function\nhad the return type `int`.\n\nReturns the total size (in number of elements) of the array.\n\nReturns 0 if obj is not a sub-class of ndarray. Otherwise, returns the total\nnumber of elements in the array. Safer version of `PyArray_SIZE` (obj).\n\nReturns the total number of bytes consumed by the array.\n\nThis returns the base object of the array. In most cases, this means the\nobject which owns the memory the array is pointing at.\n\nIf you are constructing an array using the C API, and specifying your own\nmemory, you should use the function `PyArray_SetBaseObject` to set the base to\nan object which owns the memory.\n\nIf the (deprecated) `NPY_ARRAY_UPDATEIFCOPY` or the\n`NPY_ARRAY_WRITEBACKIFCOPY` flags are set, it has a different meaning, namely\nbase is the array into which the current array will be copied upon copy\nresolution. This overloading of the base property for two functions is likely\nto change in a future version of NumPy.\n\nReturns a borrowed reference to the dtype property of the array.\n\nNew in version 1.7.\n\nA synonym for PyArray_DESCR, named to be consistent with the \u2018dtype\u2019 usage\nwithin Python.\n\nGet a Python object of a builtin type from the ndarray, arr, at the location\npointed to by itemptr. Return `NULL` on failure.\n\n`numpy.ndarray.item` is identical to PyArray_GETITEM.\n\nThe function pointed to by the CObject `__array_finalize__`. The first\nargument is the newly created sub-type. The second argument (if not NULL) is\nthe \u201cparent\u201d array (if the array was created using slicing or some other\noperation where a clearly-distinguishable parent is present). This routine can\ndo anything it wants to. It should return a -1 on error and 0 otherwise.\n\nThese functions and macros provide easy access to elements of the ndarray from\nC. These work for all arrays. You may need to take care when accessing the\ndata in the array, however, if it is not in machine byte-order, misaligned, or\nnot writeable. In other words, be sure to respect the state of the flags\nunless you know what you are doing, or have previously guaranteed an array\nthat is writeable, aligned, and in machine byte-order using `PyArray_FromAny`.\nIf you wish to handle all types of arrays, the copyswap function for each type\nis useful for handling misbehaved arrays. Some platforms (e.g. Solaris) do not\nlike misaligned data and will crash if you de-reference a misaligned pointer.\nOther platforms (e.g. x86 Linux) will just work more slowly with misaligned\ndata.\n\nReturn a pointer to the data of the ndarray, aobj, at the N-dimensional index\ngiven by the c-array, ind, (which must be at least aobj ->nd in size). You may\nwant to typecast the returned pointer to the data type of the ndarray.\n\nQuick, inline access to the element at the given coordinates in the ndarray,\nobj, which must have respectively 1, 2, 3, or 4 dimensions (this is not\nchecked). The corresponding i, j, k, and l coordinates can be any integer but\nwill be interpreted as `npy_intp`. You may want to typecast the returned\npointer to the data type of the ndarray.\n\nThis function steals a reference to descr. The easiest way to get one is using\n`PyArray_DescrFromType`.\n\nThis is the main array creation function. Most new arrays are created with\nthis flexible function.\n\nThe returned object is an object of Python-type subtype, which must be a\nsubtype of `PyArray_Type`. The array has nd dimensions, described by dims. The\ndata-type descriptor of the new array is descr.\n\nIf subtype is of an array subclass instead of the base `&PyArray_Type`, then\nobj is the object to pass to the `__array_finalize__` method of the subclass.\n\nIf data is `NULL`, then new unitinialized memory will be allocated and flags\ncan be non-zero to indicate a Fortran-style contiguous array. Use\n`PyArray_FILLWBYTE` to initialize the memory.\n\nIf data is not `NULL`, then it is assumed to point to the memory to be used\nfor the array and the flags argument is used as the new flags for the array\n(except the state of `NPY_ARRAY_OWNDATA`, `NPY_ARRAY_WRITEBACKIFCOPY` and\n`NPY_ARRAY_UPDATEIFCOPY` flags of the new array will be reset).\n\nIn addition, if data is non-NULL, then strides can also be provided. If\nstrides is `NULL`, then the array strides are computed as C-style contiguous\n(default) or Fortran-style contiguous (flags is nonzero for data = `NULL` or\nflags & `NPY_ARRAY_F_CONTIGUOUS` is nonzero non-NULL data). Any provided dims\nand strides are copied into newly allocated dimension and strides arrays for\nthe new array object.\n\n`PyArray_CheckStrides` can help verify non- `NULL` stride information.\n\nIf `data` is provided, it must stay alive for the life of the array. One way\nto manage this is through `PyArray_SetBaseObject`\n\nNew in version 1.6.\n\nThis function steals a reference to descr if it is not NULL. This array\ncreation routine allows for the convenient creation of a new array matching an\nexisting array\u2019s shapes and memory layout, possibly changing the layout and/or\ndata type.\n\nWhen order is `NPY_ANYORDER`, the result order is `NPY_FORTRANORDER` if\nprototype is a fortran array, `NPY_CORDER` otherwise. When order is\n`NPY_KEEPORDER`, the result order matches that of prototype, even when the\naxes of prototype aren\u2019t in C or Fortran order.\n\nIf descr is NULL, the data type of prototype is used.\n\nIf subok is 1, the newly created array will use the sub-type of prototype to\ncreate the new array, otherwise it will create a base-class array.\n\nThis is similar to `PyArray_NewFromDescr` (\u2026) except you specify the data-type\ndescriptor with type_num and itemsize, where type_num corresponds to a builtin\n(or user-defined) type. If the type always has the same number of bytes, then\nitemsize is ignored. Otherwise, itemsize specifies the particular size of this\narray.\n\nWarning\n\nIf data is passed to `PyArray_NewFromDescr` or `PyArray_New`, this memory must\nnot be deallocated until the new array is deleted. If this data came from\nanother Python object, this can be accomplished using `Py_INCREF` on that\nobject and setting the base member of the new array to point to that object.\nIf strides are passed in they must be consistent with the dimensions, the\nitemsize, and the data of the array.\n\nCreate a new uninitialized array of type, typenum, whose size in each of nd\ndimensions is given by the integer array, dims.The memory for the array is\nuninitialized (unless typenum is `NPY_OBJECT` in which case each element in\nthe array is set to NULL). The typenum argument allows specification of any of\nthe builtin data-types such as `NPY_FLOAT` or `NPY_LONG`. The memory for the\narray can be set to zero if desired using `PyArray_FILLWBYTE` (return_object,\n0).This function cannot be used to create a flexible-type array (no itemsize\ngiven).\n\nCreate an array wrapper around data pointed to by the given pointer. The array\nflags will have a default that the data area is well-behaved and C-style\ncontiguous. The shape of the array is given by the dims c-array of length nd.\nThe data-type of the array is indicated by typenum. If data comes from another\nreference-counted Python object, the reference count on this object should be\nincreased after the pointer is passed in, and the base member of the returned\nndarray should point to the Python object that owns the data. This will ensure\nthat the provided memory is not freed while the returned array is in\nexistence.\n\nThis function steals a reference to descr.\n\nCreate a new array with the provided data-type descriptor, descr, of the shape\ndetermined by nd and dims.\n\nFill the array pointed to by obj \u2014which must be a (subclass of) ndarray\u2014with\nthe contents of val (evaluated as a byte). This macro calls memset, so obj\nmust be contiguous.\n\nConstruct a new nd -dimensional array with shape given by dims and data type\ngiven by dtype. If fortran is non-zero, then a Fortran-order array is created,\notherwise a C-order array is created. Fill the memory with zeros (or the 0\nobject if dtype corresponds to `NPY_OBJECT` ).\n\nMacro form of `PyArray_Zeros` which takes a type-number instead of a data-type\nobject.\n\nConstruct a new nd -dimensional array with shape given by dims and data type\ngiven by dtype. If fortran is non-zero, then a Fortran-order array is created,\notherwise a C-order array is created. The array is uninitialized unless the\ndata type corresponds to `NPY_OBJECT` in which case the array is filled with\n`Py_None`.\n\nMacro form of `PyArray_Empty` which takes a type-number, typenum, instead of a\ndata-type object.\n\nConstruct a new 1-dimensional array of data-type, typenum, that ranges from\nstart to stop (exclusive) in increments of step . Equivalent to arange (start,\nstop, step, dtype).\n\nConstruct a new 1-dimensional array of data-type determined by `descr`, that\nranges from `start` to `stop` (exclusive) in increments of `step`. Equivalent\nto arange( `start`, `stop`, `step`, `typenum` ).\n\nNew in version 1.7.\n\nThis function steals a reference to `obj` and sets it as the base property of\n`arr`.\n\nIf you construct an array by passing in your own memory buffer as a parameter,\nyou need to set the array\u2019s `base` property to ensure the lifetime of the\nmemory buffer is appropriate.\n\nThe return value is 0 on success, -1 on failure.\n\nIf the object provided is an array, this function traverses the chain of\n`base` pointers so that each array points to the owner of the memory directly.\nOnce the base is set, it may not be changed to another value.\n\nThis is the main function used to obtain an array from any nested sequence, or\nobject that exposes the array interface, op. The parameters allow\nspecification of the required dtype, the minimum (min_depth) and maximum\n(max_depth) number of dimensions acceptable, and other requirements for the\narray. This function steals a reference to the dtype argument, which needs to\nbe a `PyArray_Descr` structure indicating the desired data-type (including\nrequired byteorder). The dtype argument may be `NULL`, indicating that any\ndata-type (and byteorder) is acceptable. Unless `NPY_ARRAY_FORCECAST` is\npresent in `flags`, this call will generate an error if the data type cannot\nbe safely obtained from the object. If you want to use `NULL` for the dtype\nand ensure the array is notswapped then use `PyArray_CheckFromAny`. A value of\n0 for either of the depth parameters causes the parameter to be ignored. Any\nof the following array flags can be added (e.g. using |) to get the\nrequirements argument. If your code can handle general (e.g. strided, byte-\nswapped, or unaligned arrays) then requirements may be 0. Also, if op is not\nalready an array (or does not expose the array interface), then a new array\nwill be created (and filled from op using the sequence protocol). The new\narray will have `NPY_ARRAY_DEFAULT` as its flags member. The context argument\nis unused.\n\nMake sure the returned array is C-style contiguous\n\nMake sure the returned array is Fortran-style contiguous.\n\nMake sure the returned array is aligned on proper boundaries for its data\ntype. An aligned array has the data pointer and every strides factor as a\nmultiple of the alignment factor for the data-type- descriptor.\n\nMake sure the returned array can be written to.\n\nMake sure a copy is made of op. If this flag is not present, data is not\ncopied if it can be avoided.\n\nMake sure the result is a base-class ndarray. By default, if op is an instance\nof a subclass of ndarray, an instance of that same subclass is returned. If\nthis flag is set, an ndarray object will be returned instead.\n\nForce a cast to the output type even if it cannot be done safely. Without this\nflag, a data cast will occur only if it can be done safely, otherwise an error\nis raised.\n\nIf op is already an array, but does not satisfy the requirements, then a copy\nis made (which will satisfy the requirements). If this flag is present and a\ncopy (of an object that is already an array) must be made, then the\ncorresponding `NPY_ARRAY_WRITEBACKIFCOPY` flag is set in the returned copy and\nop is made to be read-only. You must be sure to call\n`PyArray_ResolveWritebackIfCopy` to copy the contents back into op and the op\narray will be made writeable again. If op is not writeable to begin with, or\nif it is not already an array, then an error is raised.\n\nDeprecated. Use `NPY_ARRAY_WRITEBACKIFCOPY`, which is similar. This flag\n\u201cautomatically\u201d copies the data back when the returned array is deallocated,\nwhich is not supported in all python implementations.\n\n`NPY_ARRAY_ALIGNED` | `NPY_ARRAY_WRITEABLE`\n\n`NPY_ARRAY_C_CONTIGUOUS` | `NPY_ARRAY_BEHAVED`\n\n`NPY_ARRAY_C_CONTIGUOUS` | `NPY_ARRAY_ALIGNED`\n\n`NPY_ARRAY_F_CONTIGUOUS` | `NPY_ARRAY_BEHAVED`\n\n`NPY_ARRAY_F_CONTIGUOUS` | `NPY_ARRAY_ALIGNED`\n\n`NPY_ARRAY_CARRAY`\n\n`NPY_ARRAY_C_CONTIGUOUS` | `NPY_ARRAY_ALIGNED`\n\n`NPY_ARRAY_F_CONTIGUOUS` | `NPY_ARRAY_ALIGNED`\n\n`NPY_ARRAY_C_CONTIGUOUS` | `NPY_ARRAY_WRITEABLE` | `NPY_ARRAY_ALIGNED`\n\n`NPY_ARRAY_C_CONTIGUOUS` | `NPY_ARRAY_ALIGNED` | `NPY_ARRAY_WRITEABLE`\n\n`NPY_ARRAY_F_CONTIGUOUS` | `NPY_ARRAY_WRITEABLE` | `NPY_ARRAY_ALIGNED`\n\n`NPY_ARRAY_C_CONTIGUOUS` | `NPY_ARRAY_WRITEABLE` | `NPY_ARRAY_ALIGNED` |\n`NPY_ARRAY_WRITEBACKIFCOPY` | `NPY_ARRAY_UPDATEIFCOPY`\n\n`NPY_ARRAY_F_CONTIGUOUS` | `NPY_ARRAY_WRITEABLE` | `NPY_ARRAY_ALIGNED` |\n`NPY_ARRAY_WRITEBACKIFCOPY` | `NPY_ARRAY_UPDATEIFCOPY`\n\nDeprecated since version NumPy: 1.19\n\nUnless NumPy is made aware of an issue with this, this function is scheduled\nfor rapid removal without replacement.\n\nChanged in version NumPy: 1.19\n\n`context` is never used. Its use results in an error.\n\nNew in version 1.6.\n\nNearly identical to `PyArray_FromAny` (\u2026) except requirements can contain\n`NPY_ARRAY_NOTSWAPPED` (over-riding the specification in dtype) and\n`NPY_ARRAY_ELEMENTSTRIDES` which indicates that the array should be aligned in\nthe sense that the strides are multiples of the element size.\n\nIn versions 1.6 and earlier of NumPy, the following flags did not have the\n_ARRAY_ macro namespace in them. That form of the constant names is deprecated\nin 1.7.\n\nMake sure the returned array has a data-type descriptor that is in machine\nbyte-order, over-riding any specification in the dtype argument. Normally, the\nbyte-order requirement is determined by the dtype argument. If this flag is\nset and the dtype argument does not indicate a machine byte-order descriptor\n(or is NULL and the object is already an array with a data-type descriptor\nthat is not in machine byte- order), then a new data-type descriptor is\ncreated and used with its byte-order field set to native.\n\n`NPY_ARRAY_ALIGNED` | `NPY_ARRAY_WRITEABLE` | `NPY_ARRAY_NOTSWAPPED`\n\nMake sure the returned array has strides that are multiples of the element\nsize.\n\nSpecial case of `PyArray_FromAny` for when op is already an array but it needs\nto be of a specific newtype (including byte-order) or has certain\nrequirements.\n\nReturns an ndarray object from a Python object that exposes the\n`__array_struct__` attribute and follows the array interface protocol. If the\nobject does not contain this attribute then a borrowed reference to\n`Py_NotImplemented` is returned.\n\nReturns an ndarray object from a Python object that exposes the\n`__array_interface__` attribute following the array interface protocol. If the\nobject does not contain this attribute then a borrowed reference to\n`Py_NotImplemented` is returned.\n\nReturn an ndarray object from a Python object that exposes the `__array__`\nmethod. The `__array__` method can take 0, or 1 argument `([dtype])`.\n`context` is unused.\n\nThis function returns a (C-style) contiguous and behaved function array from\nany nested sequence or array interface exporting object, op, of (non-flexible)\ntype given by the enumerated typenum, of minimum depth min_depth, and of\nmaximum depth max_depth. Equivalent to a call to `PyArray_FromAny` with\nrequirements set to `NPY_ARRAY_DEFAULT` and the type_num member of the type\nargument set to typenum.\n\nThis function returns a well-behaved C-style contiguous array from any nested\nsequence or array-interface exporting object. The minimum number of dimensions\nthe array can have is given by `min_depth` while the maximum is `max_depth`.\nThis is equivalent to call `PyArray_FromAny` with requirements\n`NPY_ARRAY_DEFAULT` and `NPY_ARRAY_ENSUREARRAY`.\n\nReturn an aligned and in native-byteorder array from any nested sequence or\narray-interface exporting object, op, of a type given by the enumerated\ntypenum. The minimum number of dimensions the array can have is given by\nmin_depth while the maximum is max_depth. This is equivalent to a call to\n`PyArray_FromAny` with requirements set to BEHAVED.\n\nThis function steals a reference to `op` and makes sure that `op` is a base-\nclass ndarray. It special cases array scalars, but otherwise calls\n`PyArray_FromAny` ( `op`, NULL, 0, 0, `NPY_ARRAY_ENSUREARRAY`, NULL).\n\nConstruct a one-dimensional ndarray of a single type from a binary or (ASCII)\ntext `string` of length `slen`. The data-type of the array to-be-created is\ngiven by `dtype`. If num is -1, then copy the entire string and return an\nappropriately sized array, otherwise, `num` is the number of items to copy\nfrom the string. If `sep` is NULL (or \u201c\u201d), then interpret the string as bytes\nof binary data, otherwise convert the sub-strings separated by `sep` to items\nof data-type `dtype`. Some data-types may not be readable in text mode and an\nerror will be raised if that occurs. All errors return NULL.\n\nConstruct a one-dimensional ndarray of a single type from a binary or text\nfile. The open file pointer is `fp`, the data-type of the array to be created\nis given by `dtype`. This must match the data in the file. If `num` is -1,\nthen read until the end of the file and return an appropriately sized array,\notherwise, `num` is the number of items to read. If `sep` is NULL (or \u201c\u201d),\nthen read from the file in binary mode, otherwise read from the file in text\nmode with `sep` providing the item separator. Some array types cannot be read\nin text mode in which case an error is raised.\n\nConstruct a one-dimensional ndarray of a single type from an object, `buf`,\nthat exports the (single-segment) buffer protocol (or has an attribute\n__buffer__ that returns an object that exports the buffer protocol). A\nwriteable buffer will be tried first followed by a read- only buffer. The\n`NPY_ARRAY_WRITEABLE` flag of the returned array will reflect which one was\nsuccessful. The data is assumed to start at `offset` bytes from the start of\nthe memory location for the object. The type of the data in the buffer will be\ninterpreted depending on the data- type descriptor, `dtype.` If `count` is\nnegative then it will be determined from the size of the buffer and the\nrequested itemsize, otherwise, `count` represents how many elements should be\nconverted from the buffer.\n\nCopy from the source array, `src`, into the destination array, `dest`,\nperforming a data-type conversion if necessary. If an error occurs return -1\n(otherwise 0). The shape of `src` must be broadcastable to the shape of\n`dest`. The data areas of dest and src must not overlap.\n\nAssign an object `src` to a NumPy array `dest` according to array-coercion\nrules. This is basically identical to `PyArray_FromAny`, but assigns directly\nto the output array. Returns 0 on success and -1 on failures.\n\nMove data from the source array, `src`, into the destination array, `dest`,\nperforming a data-type conversion if necessary. If an error occurs return -1\n(otherwise 0). The shape of `src` must be broadcastable to the shape of\n`dest`. The data areas of dest and src may overlap.\n\nIf `op` is already (C-style) contiguous and well-behaved then just return a\nreference, otherwise return a (contiguous and well-behaved) copy of the array.\nThe parameter op must be a (sub-class of an) ndarray and no checking for that\nis done.\n\nConvert `obj` to an ndarray. The argument can be any nested sequence or object\nthat exports the array interface. This is a macro form of `PyArray_FromAny`\nusing `NULL`, 0, 0, 0 for the other arguments. Your code must be able to\nhandle any data-type descriptor and any combination of data-flags to use this\nmacro.\n\nSimilar to `PyArray_FROM_O` except it can take an argument of requirements\nindicating properties the resulting array must have. Available requirements\nthat can be enforced are `NPY_ARRAY_C_CONTIGUOUS`, `NPY_ARRAY_F_CONTIGUOUS`,\n`NPY_ARRAY_ALIGNED`, `NPY_ARRAY_WRITEABLE`, `NPY_ARRAY_NOTSWAPPED`,\n`NPY_ARRAY_ENSURECOPY`, `NPY_ARRAY_WRITEBACKIFCOPY`, `NPY_ARRAY_UPDATEIFCOPY`,\n`NPY_ARRAY_FORCECAST`, and `NPY_ARRAY_ENSUREARRAY`. Standard combinations of\nflags can also be used:\n\nSimilar to `PyArray_FROM_O` except it can take an argument of typenum\nspecifying the type-number the returned array.\n\nCombination of `PyArray_FROM_OF` and `PyArray_FROM_OT` allowing both a typenum\nand a flags argument to be provided.\n\nSimilar to `PyArray_FromAny` except the data-type is specified using a\ntypenumber. `PyArray_DescrFromType` (typenum) is passed directly to\n`PyArray_FromAny`. This macro also adds `NPY_ARRAY_DEFAULT` to requirements if\n`NPY_ARRAY_ENSURECOPY` is passed in as requirements.\n\nEncapsulate the functionality of functions and methods that take the axis=\nkeyword and work properly with None as the axis argument. The input array is\n`obj`, while `*axis` is a converted integer (so that >=MAXDIMS is the None\nvalue), and `requirements` gives the needed properties of `obj`. The output is\na converted version of the input so that requirements are met and if needed a\nflattening has occurred. On output negative values of `*axis` are converted\nand the new value is checked to ensure consistency with the shape of `obj`.\n\nEvaluates true if op is a Python object whose type is a sub-type of\n`PyArray_Type`.\n\nEvaluates true if op is a Python object with type `PyArray_Type`.\n\nIf `op` implements any part of the array interface, then `out` will contain a\nnew reference to the newly created ndarray using the interface or `out` will\ncontain `NULL` if an error during conversion occurs. Otherwise, out will\ncontain a borrowed reference to `Py_NotImplemented` and no error condition is\nset.\n\nIf `op` implements any part of the array interface, then `out` will contain a\nnew reference to the newly created ndarray using the interface or `out` will\ncontain `NULL` if an error during conversion occurs. Otherwise, out will\ncontain a borrowed reference to Py_NotImplemented and no error condition is\nset. This version allows setting of the dtype in the part of the array\ninterface that looks for the `__array__` attribute. `context` is unused.\n\nEvaluates true if op is an instance of (a subclass of) `PyArray_Type` and has\n0 dimensions.\n\nEvaluates true if op is an instance of `Py{cls}ArrType_Type`.\n\nEvaluates true if op is either an array scalar (an instance of a sub-type of\n`PyGenericArr_Type` ), or an instance of (a sub-class of) `PyArray_Type` whose\ndimensionality is 0.\n\nEvaluates true if op is an instance of a builtin numeric type (int, float,\ncomplex, long, bool)\n\nEvaluates true if op is a builtin Python scalar object (int, float, complex,\nbytes, str, long, bool).\n\nEvaluates true if op is either a Python scalar object (see\n`PyArray_IsPythonScalar`) or an array scalar (an instance of a sub- type of\n`PyGenericArr_Type` ).\n\nEvaluates true if op is a Python scalar object (see `PyArray_IsPythonScalar`),\nan array scalar (an instance of a sub-type of `PyGenericArr_Type`) or an\ninstance of a sub-type of `PyArray_Type` whose dimensionality is 0.\n\nFor the typenum macros, the argument is an integer representing an enumerated\narray data type. For the array type checking macros the argument must be a\nPyObject* that can be directly interpreted as a PyArrayObject*.\n\nType represents an unsigned integer.\n\nType represents a signed integer.\n\nType represents any integer.\n\nType represents any floating point number.\n\nType represents any complex floating point number.\n\nType represents any integer, floating point, or complex floating point number.\n\nType represents a string data type.\n\nType represents an enumerated type corresponding to one of the standard Python\nscalar (bool, int, float, or complex).\n\nType represents one of the flexible array types ( `NPY_STRING`, `NPY_UNICODE`,\nor `NPY_VOID` ).\n\nType has no size information attached, and can be resized. Should only be\ncalled on flexible dtypes. Types that are attached to an array will always be\nsized, hence the array form of this macro not existing.\n\nChanged in version 1.18.\n\nFor structured datatypes with no fields this function now returns False.\n\nType represents a user-defined type.\n\nType is either flexible or user-defined.\n\nType represents object data type.\n\nType represents Boolean data type.\n\nType has fields associated with it.\n\nEvaluates true if the data area of the ndarray m is in machine byte-order\naccording to the array\u2019s data-type descriptor.\n\nEvaluates true if the data area of the ndarray m is not in machine byte-order\naccording to the array\u2019s data-type descriptor.\n\nReturn `NPY_TRUE` if type1 and type2 actually represent equivalent types for\nthis platform (the fortran member of each type is ignored). For example, on\n32-bit platforms, `NPY_LONG` and `NPY_INT` are equivalent. Otherwise return\n`NPY_FALSE`.\n\nReturn `NPY_TRUE` if a1 and a2 are arrays with equivalent types for this\nplatform.\n\nSpecial case of `PyArray_EquivTypes` (\u2026) that does not accept flexible data\ntypes but may be easier to call.\n\nTrue if byteorder characters b1 and b2 ( `NPY_LITTLE`, `NPY_BIG`,\n`NPY_NATIVE`, `NPY_IGNORE` ) are either equal or equivalent as to their\nspecification of a native byte order. Thus, on a little-endian machine\n`NPY_LITTLE` and `NPY_NATIVE` are equivalent where they are not equivalent on\na big-endian machine.\n\nMainly for backwards compatibility to the Numeric C-API and for simple casts\nto non-flexible types. Return a new array object with the elements of arr cast\nto the data-type typenum which must be one of the enumerated types and not a\nflexible type.\n\nReturn a new array of the type specified, casting the elements of arr as\nappropriate. The fortran argument specifies the ordering of the output array.\n\nAs of 1.6, this function simply calls `PyArray_CopyInto`, which handles the\ncasting.\n\nCast the elements of the array in into the array out. The output array should\nbe writeable, have an integer-multiple of the number of elements in the input\narray (more than one copy can be placed in out), and have a data type that is\none of the builtin types. Returns 0 on success and -1 if an error occurs.\n\nReturn the low-level casting function to cast from the given descriptor to the\nbuiltin type number. If no casting function exists return `NULL` and set an\nerror. Using this function instead of direct access to from ->f->cast will\nallow support of any user-defined casting functions added to a descriptors\ncasting dictionary.\n\nReturns non-zero if an array of data type fromtype can be cast to an array of\ndata type totype without losing information. An exception is that 64-bit\nintegers are allowed to be cast to 64-bit floating point values even though\nthis can lose precision on large integers so as not to proliferate the use of\nlong doubles without explicit requests. Flexible array types are not checked\naccording to their lengths with this function.\n\n`PyArray_CanCastTypeTo` supersedes this function in NumPy 1.6 and later.\n\nEquivalent to PyArray_CanCastTypeTo(fromtype, totype, NPY_SAFE_CASTING).\n\nNew in version 1.6.\n\nReturns non-zero if an array of data type fromtype (which can include flexible\ntypes) can be cast safely to an array of data type totype (which can include\nflexible types) according to the casting rule casting. For simple types with\n`NPY_SAFE_CASTING`, this is basically a wrapper around\n`PyArray_CanCastSafely`, but for flexible types such as strings or unicode, it\nproduces results taking into account their sizes. Integer and float types can\nonly be cast to a string or unicode type using `NPY_SAFE_CASTING` if the\nstring or unicode type is big enough to hold the max value of the\ninteger/float type being cast from.\n\nNew in version 1.6.\n\nReturns non-zero if arr can be cast to totype according to the casting rule\ngiven in casting. If arr is an array scalar, its value is taken into account,\nand non-zero is also returned when the value will not overflow or be truncated\nto an integer when converting to a smaller type.\n\nThis is almost the same as the result of\nPyArray_CanCastTypeTo(PyArray_MinScalarType(arr), totype, casting), but it\nalso handles a special case arising because the set of uint values is not a\nsubset of the int values for types with the same number of bits.\n\nNew in version 1.6.\n\nIf arr is an array, returns its data type descriptor, but if arr is an array\nscalar (has 0 dimensions), it finds the data type of smallest size to which\nthe value may be converted without overflow or truncation to an integer.\n\nThis function will not demote complex to float or anything to boolean, but\nwill demote a signed integer to an unsigned integer when the scalar value is\npositive.\n\nNew in version 1.6.\n\nFinds the data type of smallest size and kind to which type1 and type2 may be\nsafely converted. This function is symmetric and associative. A string or\nunicode result will be the proper size for storing the max value of the input\ntypes converted to a string or unicode.\n\nNew in version 1.6.\n\nThis applies type promotion to all the inputs, using the NumPy rules for\ncombining scalars and arrays, to determine the output type of a set of\noperands. This is the same result type that ufuncs produce. The specific\nalgorithm used is as follows.\n\nCategories are determined by first checking which of boolean, integer\n(int/uint), or floating point (float/complex) the maximum kind of all the\narrays and the scalars are.\n\nIf there are only scalars or the maximum category of the scalars is higher\nthan the maximum category of the arrays, the data types are combined with\n`PyArray_PromoteTypes` to produce the return value.\n\nOtherwise, PyArray_MinScalarType is called on each array, and the resulting\ndata types are all combined with `PyArray_PromoteTypes` to produce the return\nvalue.\n\nThe set of int values is not a subset of the uint values for types with the\nsame number of bits, something not reflected in `PyArray_MinScalarType`, but\nhandled as a special case in PyArray_ResultType.\n\nThis function is superseded by `PyArray_MinScalarType` and/or\n`PyArray_ResultType`.\n\nThis function is useful for determining a common type that two or more arrays\ncan be converted to. It only works for non-flexible array types as no itemsize\ninformation is passed. The mintype argument represents the minimum type\nacceptable, and op represents the object that will be converted to an array.\nThe return value is the enumerated typenumber that represents the data-type\nthat op should have.\n\nThis function is superseded by `PyArray_ResultType`.\n\nThis function works similarly to `PyArray_ObjectType` (\u2026) except it handles\nflexible arrays. The mintype argument can have an itemsize member and the\nouttype argument will have an itemsize member at least as big but perhaps\nbigger depending on the object op.\n\nThe functionality this provides is largely superseded by iterator `NpyIter`\nintroduced in 1.6, with flag `NPY_ITER_COMMON_DTYPE` or with the same dtype\nparameter for all operands.\n\nConvert a sequence of Python objects contained in op to an array of ndarrays\neach having the same data type. The type is selected in the same way as\n`PyArray_ResultType`. The length of the sequence is returned in n, and an n\n-length array of `PyArrayObject` pointers is the return value (or `NULL` if an\nerror occurs). The returned array must be freed by the caller of this routine\n(using `PyDataMem_FREE` ) and all the array objects in it `DECREF` \u2018d or a\nmemory-leak will occur. The example template-code below shows a typically\nusage:\n\nChanged in version 1.18.0: A mix of scalars and zero-dimensional arrays now\nproduces a type capable of holding the scalar value. Previously priority was\ngiven to the dtype of the arrays.\n\nA pointer to newly created memory of size arr ->itemsize that holds the\nrepresentation of 0 for that type. The returned pointer, ret, must be freed\nusing `PyDataMem_FREE` (ret) when it is not needed anymore.\n\nA pointer to newly created memory of size arr ->itemsize that holds the\nrepresentation of 1 for that type. The returned pointer, ret, must be freed\nusing `PyDataMem_FREE` (ret) when it is not needed anymore.\n\nReturns `NPY_TRUE` if typenum represents a valid type-number (builtin or user-\ndefined or character code). Otherwise, this function returns `NPY_FALSE`.\n\nInitialize all function pointers and members to `NULL`.\n\nRegister a data-type as a new user-defined data type for arrays. The type must\nhave most of its entries filled in. This is not always checked and errors can\nproduce segfaults. In particular, the typeobj member of the `dtype` structure\nmust be filled with a Python type that has a fixed-size element-size that\ncorresponds to the elsize member of dtype. Also the `f` member must have the\nrequired functions: nonzero, copyswap, copyswapn, getitem, setitem, and cast\n(some of the cast functions may be `NULL` if no support is desired). To avoid\nconfusion, you should choose a unique character typecode but this is not\nenforced and not relied on internally.\n\nA user-defined type number is returned that uniquely identifies the type. A\npointer to the new structure can then be obtained from `PyArray_DescrFromType`\nusing the returned type number. A -1 is returned if an error occurs. If this\ndtype has already been registered (checked only by the address of the\npointer), then return the previously-assigned type-number.\n\nRegister a low-level casting function, castfunc, to convert from the data-\ntype, descr, to the given data-type number, totype. Any old casting function\nis over-written. A `0` is returned on success or a `-1` on failure.\n\nRegister the data-type number, totype, as castable from data-type object,\ndescr, of the given scalar kind. Use scalar = `NPY_NOSCALAR` to register that\nan array of data-type descr can be cast safely to a data-type whose\ntype_number is totype. The return value is 0 on success or -1 on failure.\n\nGiven a string return the type-number for the data-type with that string as\nthe type-object name. Returns `NPY_NOTYPE` without setting an error if no type\ncan be found. Only works for user-defined data-types.\n\nUsed for an array, op, that contains any Python objects. It increments the\nreference count of every object in the array according to the data-type of op.\nA -1 is returned if an error occurs, otherwise 0 is returned.\n\nA function to INCREF all the objects at the location ptr according to the\ndata-type dtype. If ptr is the start of a structured type with an object at\nany offset, then this will (recursively) increment the reference count of all\nobject-like items in the structured type.\n\nUsed for an array, op, that contains any Python objects. It decrements the\nreference count of every object in the array according to the data-type of op.\nNormal return value is 0. A -1 is returned if an error occurs.\n\nA function to XDECREF all the object-like items at the location ptr as\nrecorded in the data-type, dtype. This works recursively so that if `dtype`\nitself has fields with data-types that contain object-like items, all the\nobject-like fields will be XDECREF `'d`.\n\nFill a newly created array with a single value obj at all locations in the\nstructure with object data-types. No checking is performed but arr must be of\ndata-type `NPY_OBJECT` and be single-segment and uninitialized (no previous\nobjects in position). Use `PyArray_XDECREF` (arr) if you need to decrement all\nthe items in the object array prior to calling this function.\n\nPrecondition: `arr` is a copy of `base` (though possibly with different\nstrides, ordering, etc.) Set the UPDATEIFCOPY flag and `arr->base` so that\nwhen `arr` is destructed, it will copy any changes back to `base`. DEPRECATED,\nuse `PyArray_SetWritebackIfCopyBase`.\n\nReturns 0 for success, -1 for failure.\n\nPrecondition: `arr` is a copy of `base` (though possibly with different\nstrides, ordering, etc.) Sets the `NPY_ARRAY_WRITEBACKIFCOPY` flag and\n`arr->base`, and set `base` to READONLY. Call `PyArray_ResolveWritebackIfCopy`\nbefore calling `Py_DECREF` in order copy any changes back to `base` and reset\nthe READONLY flag.\n\nReturns 0 for success, -1 for failure.\n\nThe `flags` attribute of the `PyArrayObject` structure contains important\ninformation about the memory used by the array (pointed to by the data member)\nThis flag information must be kept accurate or strange results and even\nsegfaults may result.\n\nThere are 6 (binary) flags that describe the memory area used by the data\nbuffer. These constants are defined in `arrayobject.h` and determine the bit-\nposition of the flag. Python exposes a nice attribute- based interface as well\nas a dictionary-like interface for getting (and, if appropriate, setting)\nthese flags.\n\nMemory areas of all kinds can be pointed to by an ndarray, necessitating these\nflags. If you get an arbitrary `PyArrayObject` in C-code, you need to be aware\nof the flags that are set. If you need to guarantee a certain kind of array\n(like `NPY_ARRAY_C_CONTIGUOUS` and `NPY_ARRAY_BEHAVED`), then pass these\nrequirements into the PyArray_FromAny function.\n\nAn ndarray can have a data segment that is not a simple contiguous chunk of\nwell-behaved memory you can manipulate. It may not be aligned with word\nboundaries (very important on some platforms). It might have its data in a\ndifferent byte-order than the machine recognizes. It might not be writeable.\nIt might be in Fortran-contiguous order. The array flags are used to indicate\nwhat can be said about data associated with an array.\n\nIn versions 1.6 and earlier of NumPy, the following flags did not have the\n_ARRAY_ macro namespace in them. That form of the constant names is deprecated\nin 1.7.\n\nThe data area is in C-style contiguous order (last index varies the fastest).\n\nThe data area is in Fortran-style contiguous order (first index varies the\nfastest).\n\nNote\n\nArrays can be both C-style and Fortran-style contiguous simultaneously. This\nis clear for 1-dimensional arrays, but can also be true for higher dimensional\narrays.\n\nEven for contiguous arrays a stride for a given dimension `arr.strides[dim]`\nmay be arbitrary if `arr.shape[dim] == 1` or the array has no elements. It\ndoes not generally hold that `self.strides[-1] == self.itemsize` for C-style\ncontiguous arrays or `self.strides[0] == self.itemsize` for Fortran-style\ncontiguous arrays is true. The correct way to access the `itemsize` of an\narray from the C API is `PyArray_ITEMSIZE(arr)`.\n\nSee also\n\nInternal memory layout of an ndarray\n\nThe data area is owned by this array. Should never be set manually, instead\ncreate a `PyObject` wrapping the data and set the array\u2019s base to that object.\nFor an example, see the test in `test_mem_policy`.\n\nThe data area and all array elements are aligned appropriately.\n\nThe data area can be written to.\n\nNotice that the above 3 flags are defined so that a new, well- behaved array\nhas these flags defined as true.\n\nThe data area represents a (well-behaved) copy whose information should be\ntransferred back to the original when `PyArray_ResolveWritebackIfCopy` is\ncalled.\n\nThis is a special flag that is set if this array represents a copy made\nbecause a user required certain flags in `PyArray_FromAny` and a copy had to\nbe made of some other array (and the user asked for this flag to be set in\nsuch a situation). The base attribute then points to the \u201cmisbehaved\u201d array\n(which is set read_only). :c:func`PyArray_ResolveWritebackIfCopy` will copy\nits contents back to the \u201cmisbehaved\u201d array (casting if necessary) and will\nreset the \u201cmisbehaved\u201d array to `NPY_ARRAY_WRITEABLE`. If the \u201cmisbehaved\u201d\narray was not `NPY_ARRAY_WRITEABLE` to begin with then `PyArray_FromAny` would\nhave returned an error because `NPY_ARRAY_WRITEBACKIFCOPY` would not have been\npossible.\n\nA deprecated version of `NPY_ARRAY_WRITEBACKIFCOPY` which depends upon\n`dealloc` to trigger the writeback. For backwards compatibility,\n`PyArray_ResolveWritebackIfCopy` is called at `dealloc` but relying on that\nbehavior is deprecated and not supported in PyPy.\n\n`PyArray_UpdateFlags` (obj, flags) will update the `obj->flags` for `flags`\nwhich can be any of `NPY_ARRAY_C_CONTIGUOUS`, `NPY_ARRAY_F_CONTIGUOUS`,\n`NPY_ARRAY_ALIGNED`, or `NPY_ARRAY_WRITEABLE`.\n\n`NPY_ARRAY_ALIGNED` | `NPY_ARRAY_WRITEABLE`\n\n`NPY_ARRAY_C_CONTIGUOUS` | `NPY_ARRAY_BEHAVED`\n\n`NPY_ARRAY_C_CONTIGUOUS` | `NPY_ARRAY_ALIGNED`\n\n`NPY_ARRAY_F_CONTIGUOUS` | `NPY_ARRAY_BEHAVED`\n\n`NPY_ARRAY_F_CONTIGUOUS` | `NPY_ARRAY_ALIGNED`\n\n`NPY_ARRAY_CARRAY`\n\n`NPY_ARRAY_C_CONTIGUOUS` | `NPY_ARRAY_F_CONTIGUOUS` | `NPY_ARRAY_ALIGNED`\n\nThese constants are used in `PyArray_FromAny` (and its macro forms) to specify\ndesired properties of the new array.\n\nCast to the desired type, even if it can\u2019t be done without losing information.\n\nMake sure the resulting array is a copy of the original.\n\nMake sure the resulting object is an actual ndarray, and not a sub-class.\n\nFor all of these macros arr must be an instance of a (subclass of)\n`PyArray_Type`.\n\nThe first parameter, arr, must be an ndarray or subclass. The parameter,\nflags, should be an integer consisting of bitwise combinations of the possible\nflags an array can have: `NPY_ARRAY_C_CONTIGUOUS`, `NPY_ARRAY_F_CONTIGUOUS`,\n`NPY_ARRAY_OWNDATA`, `NPY_ARRAY_ALIGNED`, `NPY_ARRAY_WRITEABLE`,\n`NPY_ARRAY_WRITEBACKIFCOPY`, `NPY_ARRAY_UPDATEIFCOPY`.\n\nEvaluates true if arr is C-style contiguous.\n\nEvaluates true if arr is Fortran-style contiguous.\n\nEvaluates true if arr is Fortran-style contiguous and not C-style contiguous.\n`PyArray_IS_F_CONTIGUOUS` is the correct way to test for Fortran-style\ncontiguity.\n\nEvaluates true if the data area of arr can be written to\n\nEvaluates true if the data area of arr is properly aligned on the machine.\n\nEvaluates true if the data area of arr is aligned and writeable and in machine\nbyte-order according to its descriptor.\n\nEvaluates true if the data area of arr is aligned and in machine byte-order.\n\nEvaluates true if the data area of arr is C-style contiguous, and\n`PyArray_ISBEHAVED` (arr) is true.\n\nEvaluates true if the data area of arr is Fortran-style contiguous and\n`PyArray_ISBEHAVED` (arr) is true.\n\nEvaluates true if the data area of arr is C-style contiguous, aligned, and in\nmachine byte-order.\n\nEvaluates true if the data area of arr is Fortran-style contiguous, aligned,\nand in machine byte-order .\n\nEvaluates true if the data area of arr consists of a single (C-style or\nFortran-style) contiguous segment.\n\nThe `NPY_ARRAY_C_CONTIGUOUS`, `NPY_ARRAY_ALIGNED`, and\n`NPY_ARRAY_F_CONTIGUOUS` array flags can be \u201ccalculated\u201d from the array object\nitself. This routine updates one or more of these flags of arr as specified in\nflagmask by performing the required calculation.\n\nWarning\n\nIt is important to keep the flags updated (using `PyArray_UpdateFlags` can\nhelp) whenever a manipulation with an array is performed that might cause them\nto change. Later calculations in NumPy that rely on the state of these flags\ndo not repeat the calculation to update them.\n\nEquivalent to `ndarray.getfield` (self, dtype, offset). This function steals a\nreference to `PyArray_Descr` and returns a new array of the given `dtype`\nusing the data in the current array at a specified `offset` in bytes. The\n`offset` plus the itemsize of the new array type must be less than `self\n->descr->elsize` or an error is raised. The same shape and strides as the\noriginal array are used. Therefore, this function has the effect of returning\na field from a structured array. But, it can also be used to select specific\nbytes or groups of bytes from any array type.\n\nEquivalent to `ndarray.setfield` (self, val, dtype, offset ). Set the field\nstarting at offset in bytes and of the given dtype to val. The offset plus\ndtype ->elsize must be less than self ->descr->elsize or an error is raised.\nOtherwise, the val argument is converted to an array and copied into the field\npointed to. If necessary, the elements of val are repeated to fill the\ndestination array, But, the number of elements in the destination must be an\ninteger multiple of the number of elements in val.\n\nEquivalent to `ndarray.byteswap` (self, inplace). Return an array whose data\narea is byteswapped. If inplace is non-zero, then do the byteswap inplace and\nreturn a reference to self. Otherwise, create a byteswapped copy and leave\nself unchanged.\n\nEquivalent to `ndarray.copy` (self, fortran). Make a copy of the old array.\nThe returned array is always aligned and writeable with data interpreted the\nsame as the old array. If order is `NPY_CORDER`, then a C-style contiguous\narray is returned. If order is `NPY_FORTRANORDER`, then a Fortran-style\ncontiguous array is returned. If order is `NPY_ANYORDER`, then the array\nreturned is Fortran-style contiguous only if the old one is; otherwise, it is\nC-style contiguous.\n\nEquivalent to `ndarray.tolist` (self). Return a nested Python list from self.\n\nEquivalent to `ndarray.tobytes` (self, order). Return the bytes of this array\nin a Python string.\n\nWrite the contents of self to the file pointer fp in C-style contiguous\nfashion. Write the data as binary bytes if sep is the string \u201c\u201dor `NULL`.\nOtherwise, write the contents of self as text using the sep string as the item\nseparator. Each item will be printed to the file. If the format string is not\n`NULL` or \u201c\u201d, then it is a Python print statement format string showing how\nthe items are to be written.\n\nPickle the object in self to the given file (either a string or a Python file\nobject). If file is a Python string it is considered to be the name of a file\nwhich is then opened in binary mode. The given protocol is used (if protocol\nis negative, or the highest available is used). This is a simple wrapper\naround cPickle.dump(self, file, protocol).\n\nPickle the object in self to a Python string and return it. Use the Pickle\nprotocol provided (or the highest available if protocol is negative).\n\nFill the array, arr, with the given scalar object, obj. The object is first\nconverted to the data type of arr, and then copied into every location. A -1\nis returned if an error occurs, otherwise 0 is returned.\n\nEquivalent to `ndarray.view` (self, dtype). Return a new view of the array\nself as possibly a different data-type, dtype, and different array subclass\nptype.\n\nIf dtype is `NULL`, then the returned array will have the same data type as\nself. The new data-type must be consistent with the size of self. Either the\nitemsizes must be identical, or self must be single-segment and the total\nnumber of bytes must be the same. In the latter case the dimensions of the\nreturned array will be altered in the last (or first for Fortran-style\ncontiguous arrays) dimension. The data area of the returned array and self is\nexactly the same.\n\nResult will be a new array (pointing to the same memory location as self if\npossible), but having a shape given by newshape. If the new shape is not\ncompatible with the strides of self, then a copy of the array with the new\nspecified shape will be returned.\n\nEquivalent to `ndarray.reshape` (self, shape) where shape is a sequence.\nConverts shape to a `PyArray_Dims` structure and calls `PyArray_Newshape`\ninternally. For back-ward compatibility \u2013 Not recommended\n\nEquivalent to `ndarray.squeeze` (self). Return a new view of self with all of\nthe dimensions of length 1 removed from the shape.\n\nWarning\n\nmatrix objects are always 2-dimensional. Therefore, `PyArray_Squeeze` has no\neffect on arrays of matrix sub-class.\n\nEquivalent to `ndarray.swapaxes` (self, a1, a2). The returned array is a new\nview of the data in self with the given axes, a1 and a2, swapped.\n\nEquivalent to `ndarray.resize` (self, newshape, refcheck `=` refcheck, order=\nfortran ). This function only works on single-segment arrays. It changes the\nshape of self inplace and will reallocate the memory for self if newshape has\na different total number of elements then the old shape. If reallocation is\nnecessary, then self must own its data, have self \\- `>base==NULL`, have self\n\\- `>weakrefs==NULL`, and (unless refcheck is 0) not be referenced by any\nother array. The fortran argument can be `NPY_ANYORDER`, `NPY_CORDER`, or\n`NPY_FORTRANORDER`. It currently has no effect. Eventually it could be used to\ndetermine how the resize operation should view the data when constructing a\ndifferently-dimensioned array. Returns None on success and NULL on error.\n\nEquivalent to `ndarray.transpose` (self, permute). Permute the axes of the\nndarray object self according to the data structure permute and return the\nresult. If permute is `NULL`, then the resulting array has its axes reversed.\nFor example if self has shape \\\\(10\\times20\\times30\\\\), and permute `.ptr` is\n(0,2,1) the shape of the result is \\\\(10\\times30\\times20.\\\\) If permute is\n`NULL`, the shape of the result is \\\\(30\\times20\\times10.\\\\)\n\nEquivalent to `ndarray.flatten` (self, order). Return a 1-d copy of the array.\nIf order is `NPY_FORTRANORDER` the elements are scanned out in Fortran order\n(first-dimension varies the fastest). If order is `NPY_CORDER`, the elements\nof `self` are scanned in C-order (last dimension varies the fastest). If order\n`NPY_ANYORDER`, then the result of `PyArray_ISFORTRAN` (self) is used to\ndetermine which order to flatten.\n\nEquivalent to self.ravel(order). Same basic functionality as `PyArray_Flatten`\n(self, order) except if order is 0 and self is C-style contiguous, the shape\nis altered but no copy is performed.\n\nEquivalent to `ndarray.take` (self, indices, axis, ret, clipmode) except axis\n=None in Python is obtained by setting axis = `NPY_MAXDIMS` in C. Extract the\nitems from self indicated by the integer-valued indices along the given axis.\nThe clipmode argument can be `NPY_RAISE`, `NPY_WRAP`, or `NPY_CLIP` to\nindicate what to do with out-of-bound indices. The ret argument can specify an\noutput array rather than having one created internally.\n\nEquivalent to self.put(values, indices, clipmode ). Put values into self at\nthe corresponding (flattened) indices. If values is too small it will be\nrepeated as necessary.\n\nPlace the values in self wherever corresponding positions (using a flattened\ncontext) in mask are true. The mask and self arrays must have the same total\nnumber of elements. If values is too small, it will be repeated as necessary.\n\nEquivalent to `ndarray.repeat` (self, op, axis). Copy the elements of self, op\ntimes along the given axis. Either op is a scalar integer or a sequence of\nlength self ->dimensions[ axis ] indicating how many times to repeat each item\nalong the axis.\n\nEquivalent to `ndarray.choose` (self, op, ret, clipmode). Create a new array\nby selecting elements from the sequence of arrays in op based on the integer\nvalues in self. The arrays must all be broadcastable to the same shape and the\nentries in self should be between 0 and len(op). The output is placed in ret\nunless it is `NULL` in which case a new output is created. The clipmode\nargument determines behavior for when entries in self are not between 0 and\nlen(op).\n\nraise a ValueError;\n\nwrap values < 0 by adding len(op) and values >=len(op) by subtracting len(op)\nuntil they are in range;\n\nall values are clipped to the region [0, len(op) ).\n\nEquivalent to `ndarray.sort` (self, axis, kind). Return an array with the\nitems of self sorted along axis. The array is sorted using the algorithm\ndenoted by kind, which is an integer/enum pointing to the type of sorting\nalgorithms used.\n\nEquivalent to `ndarray.argsort` (self, axis). Return an array of indices such\nthat selection of these indices along the given `axis` would return a sorted\nversion of self. If self ->descr is a data-type with fields defined, then\nself->descr->names is used to determine the sort order. A comparison where the\nfirst field is equal will use the second field and so on. To alter the sort\norder of a structured array, create a new data-type with a different order of\nnames and construct a view of the array with that new data-type.\n\nGiven a sequence of arrays (sort_keys) of the same shape, return an array of\nindices (similar to `PyArray_ArgSort` (\u2026)) that would sort the arrays\nlexicographically. A lexicographic sort specifies that when two keys are found\nto be equal, the order is based on comparison of subsequent keys. A merge sort\n(which leaves equal entries unmoved) is required to be defined for the types.\nThe sort is accomplished by sorting the indices first using the first sort_key\nand then using the second sort_key and so forth. This is equivalent to the\nlexsort(sort_keys, axis) Python command. Because of the way the merge-sort\nworks, be sure to understand the order the sort_keys must be in (reversed from\nthe order you would use when comparing two elements).\n\nIf these arrays are all collected in a structured array, then `PyArray_Sort`\n(\u2026) can also be used to sort the array directly.\n\nEquivalent to `ndarray.searchsorted` (self, values, side, perm). Assuming self\nis a 1-d array in ascending order, then the output is an array of indices the\nsame shape as values such that, if the elements in values were inserted before\nthe indices, the order of self would be preserved. No checking is done on\nwhether or not self is in ascending order.\n\nThe side argument indicates whether the index returned should be that of the\nfirst suitable location (if `NPY_SEARCHLEFT`) or of the last (if\n`NPY_SEARCHRIGHT`).\n\nThe sorter argument, if not `NULL`, must be a 1D array of integer indices the\nsame length as self, that sorts it into ascending order. This is typically the\nresult of a call to `PyArray_ArgSort` (\u2026) Binary search is used to find the\nrequired insertion points.\n\nEquivalent to `ndarray.partition` (self, ktharray, axis, kind). Partitions the\narray so that the values of the element indexed by ktharray are in the\npositions they would be if the array is fully sorted and places all elements\nsmaller than the kth before and all elements equal or greater after the kth\nelement. The ordering of all elements within the partitions is undefined. If\nself->descr is a data-type with fields defined, then self->descr->names is\nused to determine the sort order. A comparison where the first field is equal\nwill use the second field and so on. To alter the sort order of a structured\narray, create a new data-type with a different order of names and construct a\nview of the array with that new data-type. Returns zero on success and -1 on\nfailure.\n\nEquivalent to `ndarray.argpartition` (self, ktharray, axis, kind). Return an\narray of indices such that selection of these indices along the given `axis`\nwould return a partitioned version of self.\n\nEquivalent to `ndarray.diagonal` (self, offset, axis1, axis2 ). Return the\noffset diagonals of the 2-d arrays defined by axis1 and axis2.\n\nNew in version 1.6.\n\nCounts the number of non-zero elements in the array object self.\n\nEquivalent to `ndarray.nonzero` (self). Returns a tuple of index arrays that\nselect elements of self that are nonzero. If (nd= `PyArray_NDIM` ( `self`\n))==1, then a single index array is returned. The index arrays have data type\n`NPY_INTP`. If a tuple is returned (nd \\\\(\\neq\\\\) 1), then its length is nd.\n\nEquivalent to `ndarray.compress` (self, condition, axis ). Return the elements\nalong axis corresponding to elements of condition that are true.\n\nTip\n\nPass in `NPY_MAXDIMS` for axis in order to achieve the same effect that is\nobtained by passing in `axis=None` in Python (treating the array as a 1-d\narray).\n\nNote\n\nThe out argument specifies where to place the result. If out is NULL, then the\noutput array is created, otherwise the output is placed in out which must be\nthe correct size and type. A new reference to the output array is always\nreturned even when out is not NULL. The caller of the routine has the\nresponsibility to `Py_DECREF` out if not NULL or a memory-leak will occur.\n\nEquivalent to `ndarray.argmax` (self, axis). Return the index of the largest\nelement of self along axis.\n\nEquivalent to `ndarray.argmin` (self, axis). Return the index of the smallest\nelement of self along axis.\n\nEquivalent to `ndarray.max` (self, axis). Returns the largest element of self\nalong the given axis. When the result is a single element, returns a numpy\nscalar instead of an ndarray.\n\nEquivalent to `ndarray.min` (self, axis). Return the smallest element of self\nalong the given axis. When the result is a single element, returns a numpy\nscalar instead of an ndarray.\n\nEquivalent to `ndarray.ptp` (self, axis). Return the difference between the\nlargest element of self along axis and the smallest element of self along\naxis. When the result is a single element, returns a numpy scalar instead of\nan ndarray.\n\nNote\n\nThe rtype argument specifies the data-type the reduction should take place\nover. This is important if the data-type of the array is not \u201clarge\u201d enough to\nhandle the output. By default, all integer data-types are made at least as\nlarge as `NPY_LONG` for the \u201cadd\u201d and \u201cmultiply\u201d ufuncs (which form the basis\nfor mean, sum, cumsum, prod, and cumprod functions).\n\nEquivalent to `ndarray.mean` (self, axis, rtype). Returns the mean of the\nelements along the given axis, using the enumerated type rtype as the data\ntype to sum in. Default sum behavior is obtained using `NPY_NOTYPE` for rtype.\n\nEquivalent to `ndarray.trace` (self, offset, axis1, axis2, rtype). Return the\nsum (using rtype as the data type of summation) over the offset diagonal\nelements of the 2-d arrays defined by axis1 and axis2 variables. A positive\noffset chooses diagonals above the main diagonal. A negative offset selects\ndiagonals below the main diagonal.\n\nEquivalent to `ndarray.clip` (self, min, max). Clip an array, self, so that\nvalues larger than max are fixed to max and values less than min are fixed to\nmin.\n\nEquivalent to `ndarray.conjugate` (self). Return the complex conjugate of\nself. If self is not of complex data type, then return self with a reference.\n\nEquivalent to `ndarray.round` (self, decimals, out). Returns the array with\nelements rounded to the nearest decimal place. The decimal place is defined as\nthe \\\\(10^{-\\textrm{decimals}}\\\\) digit so that negative decimals cause\nrounding to the nearest 10\u2019s, 100\u2019s, etc. If out is `NULL`, then the output\narray is created, otherwise the output is placed in out which must be the\ncorrect size and type.\n\nEquivalent to `ndarray.std` (self, axis, rtype). Return the standard deviation\nusing data along axis converted to data type rtype.\n\nEquivalent to `ndarray.sum` (self, axis, rtype). Return 1-d vector sums of\nelements in self along axis. Perform the sum after converting data to data\ntype rtype.\n\nEquivalent to `ndarray.cumsum` (self, axis, rtype). Return cumulative 1-d sums\nof elements in self along axis. Perform the sum after converting data to data\ntype rtype.\n\nEquivalent to `ndarray.prod` (self, axis, rtype). Return 1-d products of\nelements in self along axis. Perform the product after converting data to data\ntype rtype.\n\nEquivalent to `ndarray.cumprod` (self, axis, rtype). Return 1-d cumulative\nproducts of elements in `self` along `axis`. Perform the product after\nconverting data to data type `rtype`.\n\nEquivalent to `ndarray.all` (self, axis). Return an array with True elements\nfor every 1-d sub-array of `self` defined by `axis` in which all the elements\nare True.\n\nEquivalent to `ndarray.any` (self, axis). Return an array with True elements\nfor every 1-d sub-array of self defined by axis in which any of the elements\nare True.\n\nSometimes it is useful to access a multidimensional array as a C-style multi-\ndimensional array so that algorithms can be implemented using C\u2019s a[i][j][k]\nsyntax. This routine returns a pointer, ptr, that simulates this kind of\nC-style array, for 1-, 2-, and 3-d ndarrays.\n\nNote\n\nThe simulation of a C-style array is not complete for 2-d and 3-d arrays. For\nexample, the simulated arrays of pointers cannot be passed to subroutines\nexpecting specific, statically-defined 2-d and 3-d arrays. To pass to\nfunctions requiring those kind of inputs, you must statically define the\nrequired array and copy data.\n\nMust be called with the same objects and memory locations returned from\n`PyArray_AsCArray` (\u2026). This function cleans up memory that otherwise would\nget leaked.\n\nJoin the sequence of objects in obj together along axis into a single array.\nIf the dimensions or types are not compatible an error is raised.\n\nCompute a product-sum over the last dimensions of obj1 and obj2. Neither array\nis conjugated.\n\nCompute a product-sum over the last dimension of obj1 and the second-to-last\ndimension of obj2. For 2-d arrays this is a matrix-product. Neither array is\nconjugated.\n\nNew in version 1.6.\n\nSame as PyArray_MatrixProduct, but store the result in out. The output array\nmust have the correct shape, type, and be C-contiguous, or an exception is\nraised.\n\nNew in version 1.6.\n\nApplies the Einstein summation convention to the array operands provided,\nreturning a new array or placing the result in out. The string in subscripts\nis a comma separated list of index letters. The number of operands is in nop,\nand op_in is an array containing those operands. The data type of the output\ncan be forced with dtype, the output order can be forced with order\n(`NPY_KEEPORDER` is recommended), and when dtype is specified, casting\nindicates how permissive the data conversion should be.\n\nSee the `einsum` function for more details.\n\nA specialized copy and transpose function that works only for 2-d arrays. The\nreturned array is a transposed copy of op.\n\nCompute the 1-d correlation of the 1-d arrays op1 and op2 . The correlation is\ncomputed at each output point by multiplying op1 by a shifted version of op2\nand summing the result. As a result of the shift, needed values outside of the\ndefined range of op1 and op2 are interpreted as zero. The mode determines how\nmany shifts to return: 0 - return only shifts that did not need to assume\nzero- values; 1 - return an object that is the same size as op1, 2 - return\nall possible shifts (any overlap at all is accepted).\n\nThis does not compute the usual correlation: if op2 is larger than op1, the\narguments are swapped, and the conjugate is never taken for complex arrays.\nSee PyArray_Correlate2 for the usual signal processing correlation.\n\nUpdated version of PyArray_Correlate, which uses the usual definition of\ncorrelation for 1d arrays. The correlation is computed at each output point by\nmultiplying op1 by a shifted version of op2 and summing the result. As a\nresult of the shift, needed values outside of the defined range of op1 and op2\nare interpreted as zero. The mode determines how many shifts to return: 0 -\nreturn only shifts that did not need to assume zero- values; 1 - return an\nobject that is the same size as op1, 2 - return all possible shifts (any\noverlap at all is accepted).\n\nCompute z as follows:\n\nIf both `x` and `y` are `NULL`, then return `PyArray_Nonzero` (condition).\nOtherwise, both x and y must be given and the object returned is shaped like\ncondition and has elements of x and y where condition is respectively True or\nFalse.\n\nDetermine if newstrides is a strides array consistent with the memory of an nd\n-dimensional array with shape `dims` and element-size, elsize. The newstrides\narray is checked to see if jumping by the provided number of bytes in each\ndirection will ever mean jumping more than numbytes which is the assumed size\nof the available memory segment. If numbytes is 0, then an equivalent numbytes\nis computed assuming nd, dims, and elsize refer to a single-segment array.\nReturn `NPY_TRUE` if newstrides is acceptable, otherwise return `NPY_FALSE`.\n\nBoth of these routines multiply an n -length array, seq, of integers and\nreturn the result. No overflow checking is performed.\n\nGiven two n -length arrays of integers, l1, and l2, return 1 if the lists are\nidentical; otherwise, return 0.\n\nNew in version 1.7.0.\n\nWhen working with more complex dtypes which are composed of other dtypes, such\nas the struct dtype, creating inner loops that manipulate the dtypes requires\ncarrying along additional data. NumPy supports this idea through a struct\n`NpyAuxData`, mandating a few conventions so that it is possible to do this.\n\nDefining an `NpyAuxData` is similar to defining a class in C++, but the object\nsemantics have to be tracked manually since the API is in C. Here\u2019s an example\nfor a function which doubles up an element using an element copier function as\na primitive.\n\nThe function pointer type for NpyAuxData free functions.\n\nThe function pointer type for NpyAuxData clone functions. These functions\nshould never set the Python exception on error, because they may be called\nfrom a multi-threaded context.\n\nA macro which calls the auxdata\u2019s free function appropriately, does nothing if\nauxdata is NULL.\n\nA macro which calls the auxdata\u2019s clone function appropriately, returning a\ndeep copy of the auxiliary data.\n\nAs of NumPy 1.6.0, these array iterators are superseded by the new array\niterator, `NpyIter`.\n\nAn array iterator is a simple way to access the elements of an N-dimensional\narray quickly and efficiently. Section 2 provides more description and\nexamples of this useful approach to looping over an array.\n\nReturn an array iterator object from the array, arr. This is equivalent to\narr. flat. The array iterator object makes it easy to loop over an\nN-dimensional non-contiguous array in C-style contiguous fashion.\n\nReturn an array iterator that will iterate over all axes but the one provided\nin *axis. The returned iterator cannot be used with `PyArray_ITER_GOTO1D`.\nThis iterator could be used to write something similar to what ufuncs do\nwherein the loop over the largest axis is done by a separate sub-routine. If\n*axis is negative then *axis will be set to the axis having the smallest\nstride and that axis will be used.\n\nReturn an array iterator that is broadcast to iterate as an array of the shape\nprovided by dimensions and nd.\n\nEvaluates true if op is an array iterator (or instance of a subclass of the\narray iterator type).\n\nReset an iterator to the beginning of the array.\n\nIncremement the index and the dataptr members of the iterator to point to the\nnext element of the array. If the array is not (C-style) contiguous, also\nincrement the N-dimensional coordinates array.\n\nA pointer to the current element of the array.\n\nSet the iterator index, dataptr, and coordinates members to the location in\nthe array indicated by the N-dimensional c-array, destination, which must have\nsize at least iterator ->nd_m1+1.\n\nSet the iterator index and dataptr to the location in the array indicated by\nthe integer index which points to an element in the C-styled flattened array.\n\nEvaluates TRUE as long as the iterator has not looped through all of the\nelements, otherwise it evaluates FALSE.\n\nA simplified interface to broadcasting. This function takes the number of\narrays to broadcast and then num extra ( `PyObject *` ) arguments. These\narguments are converted to arrays and iterators are created.\n`PyArray_Broadcast` is then called on the resulting multi-iterator object. The\nresulting, broadcasted mult-iterator object is then returned. A broadcasted\noperation can then be performed using a single loop and using\n`PyArray_MultiIter_NEXT` (..)\n\nReset all the iterators to the beginning in a multi-iterator object, multi.\n\nAdvance each iterator in a multi-iterator object, multi, to its next\n(broadcasted) element.\n\nReturn the data-pointer of the i \\\\(^{\\textrm{th}}\\\\) iterator in a multi-\niterator object.\n\nAdvance the pointer of only the i \\\\(^{\\textrm{th}}\\\\) iterator.\n\nAdvance each iterator in a multi-iterator object, multi, to the given \\\\(N\\\\)\n-dimensional destination where \\\\(N\\\\) is the number of dimensions in the\nbroadcasted array.\n\nAdvance each iterator in a multi-iterator object, multi, to the corresponding\nlocation of the index into the flattened broadcasted array.\n\nEvaluates TRUE as long as the multi-iterator has not looped through all of the\nelements (of the broadcasted result), otherwise it evaluates FALSE.\n\nThis function encapsulates the broadcasting rules. The mit container should\nalready contain iterators for all the arrays that need to be broadcast. On\nreturn, these iterators will be adjusted so that iteration over each\nsimultaneously will accomplish the broadcasting. A negative number is returned\nif an error occurs.\n\nThis function takes a multi-iterator object that has been previously\n\u201cbroadcasted,\u201d finds the dimension with the smallest \u201csum of strides\u201d in the\nbroadcasted result and adapts all the iterators so as not to iterate over that\ndimension (by effectively making them of length-1 in that dimension). The\ncorresponding dimension is returned unless mit ->nd is 0, then -1 is returned.\nThis function is useful for constructing ufunc-like routines that broadcast\ntheir inputs correctly and then call a strided 1-d version of the routine as\nthe inner-loop. This 1-d version is usually optimized for speed and for this\nreason the loop should be performed over the axis that won\u2019t require large\nstride jumps.\n\nNew in version 1.4.0.\n\nNeighborhood iterators are subclasses of the iterator object, and can be used\nto iter over a neighborhood of a point. For example, you may want to iterate\nover every voxel of a 3d image, and for every such voxel, iterate over an\nhypercube. Neighborhood iterator automatically handle boundaries, thus making\nthis kind of code much easier to write than manual boundaries handling, at the\ncost of a slight overhead.\n\nThis function creates a new neighborhood iterator from an existing iterator.\nThe neighborhood will be computed relatively to the position currently pointed\nby iter, the bounds define the shape of the neighborhood iterator, and the\nmode argument the boundaries handling mode.\n\nThe bounds argument is expected to be a (2 * iter->ao->nd) arrays, such as the\nrange bound[2*i]->bounds[2*i+1] defines the range where to walk for dimension\ni (both bounds are included in the walked coordinates). The bounds should be\nordered for each dimension (bounds[2*i] <= bounds[2*i+1]).\n\nThe mode should be one of:\n\nZero padding. Outside bounds values will be 0.\n\nOne padding, Outside bounds values will be 1.\n\nConstant padding. Outside bounds values will be the same as the first item in\nfill_value.\n\nMirror padding. Outside bounds values will be as if the array items were\nmirrored. For example, for the array [1, 2, 3, 4], x[-2] will be 2, x[-2] will\nbe 1, x[4] will be 4, x[5] will be 1, etc\u2026\n\nCircular padding. Outside bounds values will be as if the array was repeated.\nFor example, for the array [1, 2, 3, 4], x[-2] will be 3, x[-2] will be 4,\nx[4] will be 1, x[5] will be 2, etc\u2026\n\nIf the mode is constant filling (`NPY_NEIGHBORHOOD_ITER_CONSTANT_PADDING`),\nfill_value should point to an array object which holds the filling value (the\nfirst item will be the filling value if the array contains more than one\nitem). For other cases, fill_value may be NULL.\n\nReset the iterator position to the first point of the neighborhood. This\nshould be called whenever the iter argument given at\nPyArray_NeighborhoodIterObject is changed (see example)\n\nAfter this call, iter->dataptr points to the next point of the neighborhood.\nCalling this function after every point of the neighborhood has been visited\nis undefined.\n\nArray mapping is the machinery behind advanced indexing.\n\nUse advanced indexing to iterate an array.\n\nSwap the axes to or from their inserted form. `MapIter` always puts the\nadvanced (array) indices first in the iteration. But if they are consecutive,\nit will insert/transpose them back before returning. This is stored as\n`mit->consec != 0` (the place where they are inserted). For assignments, the\nopposite happens: the values to be assigned are transposed (`getmap=1` instead\nof `getmap=0`). `getmap=0` and `getmap=1` undo the other operation.\n\nThis function needs to update the state of the map iterator and point\n`mit->dataptr` to the memory-location of the next object.\n\nNote that this function never handles an extra operand but provides\ncompatibility for an old (exposed) API.\n\nSimilar to `PyArray_MapIterArray` but with an additional `copy_if_overlap`\nargument. If `copy_if_overlap != 0`, checks if `a` has memory overlap with any\nof the arrays in `index` and with `extra_op`, and make copies as appropriate\nto avoid problems if the input is modified during the iteration. `iter->array`\nmay contain a copied array (UPDATEIFCOPY/WRITEBACKIFCOPY set).\n\nThis function steals a reference to arr.\n\nThis function checks to see if arr is a 0-dimensional array and, if so,\nreturns the appropriate array scalar. It should be used whenever 0-dimensional\narrays could be returned to Python.\n\nReturn an array scalar object of the given dtype by copying from memory\npointed to by data. base is expected to be the array object that is the owner\nof the data. base is required if `dtype` is a `void` scalar, or if the\n`NPY_USE_GETITEM` flag is set and it is known that the `getitem` method uses\nthe `arr` argument without checking if it is `NULL`. Otherwise `base` may be\n`NULL`.\n\nIf the data is not in native byte order (as indicated by `dtype->byteorder`)\nthen this function will byteswap the data, because array scalars are always in\ncorrect machine-byte order.\n\nReturn an array scalar object of the type and itemsize indicated by the array\nobject arr copied from the memory pointed to by data and swapping if the data\nin arr is not in machine byte-order.\n\nReturn a 0-dimensional array of type determined by outcode from scalar which\nshould be an array-scalar object. If outcode is NULL, then the type is\ndetermined from scalar.\n\nReturn in ctypeptr a pointer to the actual value in an array scalar. There is\nno error checking so scalar must be an array-scalar object, and ctypeptr must\nhave enough space to hold the correct type. For flexible-sized types, a\npointer to the data is copied into the memory of ctypeptr, for all other\ntypes, the actual data is copied into the address pointed to by ctypeptr.\n\nReturn the data (cast to the data type indicated by outcode) from the array-\nscalar, scalar, into the memory pointed to by ctypeptr (which must be large\nenough to handle the incoming memory).\n\nReturns a scalar type-object from a type-number, type . Equivalent to\n`PyArray_DescrFromType` (type)->typeobj except for reference counting and\nerror-checking. Returns a new reference to the typeobject on success or `NULL`\non failure.\n\nSee the function `PyArray_MinScalarType` for an alternative mechanism\nintroduced in NumPy 1.6.0.\n\nReturn the kind of scalar represented by typenum and the array in *arr (if arr\nis not `NULL` ). The array is assumed to be rank-0 and only used if typenum\nrepresents a signed integer. If arr is not `NULL` and the first element is\nnegative then `NPY_INTNEG_SCALAR` is returned, otherwise `NPY_INTPOS_SCALAR`\nis returned. The possible return values are the enumerated values in\n`NPY_SCALARKIND`.\n\nSee the function `PyArray_ResultType` for details of NumPy type promotion,\nupdated in NumPy 1.6.0.\n\nImplements the rules for scalar coercion. Scalars are only silently coerced\nfrom thistype to neededtype if this function returns nonzero. If scalar is\n`NPY_NOSCALAR`, then this function is equivalent to `PyArray_CanCastSafely`.\nThe rule is that scalars of the same KIND can be coerced into arrays of the\nsame KIND. This rule means that high-precision scalars will never cause low-\nprecision arrays of the same KIND to be upcast.\n\nWarning\n\nData-type objects must be reference counted so be aware of the action on the\ndata-type reference of different C-API calls. The standard rule is that when a\ndata-type object is returned it is a new reference. Functions that take\nPyArray_Descr* objects and return arrays steal references to the data-type\ntheir inputs unless otherwise noted. Therefore, you must own a reference to\nany data-type object used as input to such a function.\n\nEvaluates as true if obj is a data-type object ( PyArray_Descr* ).\n\nReturn a new data-type object copied from obj (the fields reference is just\nupdated so that the new object points to the same fields dictionary if any).\n\nCreate a new data-type object from the built-in (or user-registered) data-type\nindicated by typenum. All builtin types should not have any of their fields\nchanged. This creates a new copy of the `PyArray_Descr` structure so that you\ncan fill it in as appropriate. This function is especially needed for flexible\ndata-types which need to have a new elsize member in order to be meaningful in\narray construction.\n\nCreate a new data-type object with the byteorder set according to newendian.\nAll referenced data-type objects (in subdescr and fields members of the data-\ntype object) are also changed (recursively).\n\nThe value of newendian is one of these macros:\n\nIf a byteorder of `NPY_IGNORE` is encountered it is left alone. If newendian\nis `NPY_SWAP`, then all byte-orders are swapped. Other valid newendian values\nare `NPY_NATIVE`, `NPY_LITTLE`, and `NPY_BIG` which all cause the returned\ndata-typed descriptor (and all it\u2019s referenced data-type descriptors) to have\nthe corresponding byte- order.\n\nDetermine an appropriate data-type object from the object op (which should be\na \u201cnested\u201d sequence object) and the minimum data-type descriptor mintype\n(which can be `NULL` ). Similar in behavior to array(op).dtype. Don\u2019t confuse\nthis function with `PyArray_DescrConverter`. This function essentially looks\nat all the objects in the (nested) sequence and determines the data-type from\nthe elements it finds.\n\nReturn a data-type object from an array-scalar object. No checking is done to\nbe sure that scalar is an array scalar. If no suitable data-type can be\ndetermined, then a data-type of `NPY_OBJECT` is returned by default.\n\nReturns a data-type object corresponding to typenum. The typenum can be one of\nthe enumerated types, a character code for one of the enumerated types, or a\nuser-defined type. If you want to use a flexible size array, then you need to\n`flexible typenum` and set the results `elsize` parameter to the desired size.\nThe typenum is one of the `NPY_TYPES`.\n\nConvert any compatible Python object, obj, to a data-type object in dtype. A\nlarge number of Python objects can be converted to data-type objects. See Data\ntype objects (dtype) for a complete description. This version of the converter\nconverts None objects to a `NPY_DEFAULT_TYPE` data-type object. This function\ncan be used with the \u201cO&\u201d character code in `PyArg_ParseTuple` processing.\n\nConvert any compatible Python object, obj, to a data-type object in dtype.\nThis version of the converter converts None objects so that the returned data-\ntype is `NULL`. This function can also be used with the \u201cO&\u201d character in\nPyArg_ParseTuple processing.\n\nLike `PyArray_DescrConverter` except it aligns C-struct-like objects on word-\nboundaries as the compiler would.\n\nLike `PyArray_DescrConverter2` except it aligns C-struct-like objects on word-\nboundaries as the compiler would.\n\nTake the fields dictionary, dict, such as the one attached to a data-type\nobject and construct an ordered-list of field names such as is stored in the\nnames field of the `PyArray_Descr` object.\n\nAll of these functions can be used in `PyArg_ParseTuple` (\u2026) with the \u201cO&\u201d\nformat specifier to automatically convert any Python object to the required\nC-object. All of these functions return `NPY_SUCCEED` if successful and\n`NPY_FAIL` if not. The first argument to all of these function is a Python\nobject. The second argument is the address of the C-type to convert the Python\nobject to.\n\nWarning\n\nBe sure to understand what steps you should take to manage the memory when\nusing these conversion functions. These functions can require freeing memory,\nand/or altering the reference counts of specific objects based on your use.\n\nConvert any Python object to a `PyArrayObject`. If `PyArray_Check` (obj) is\nTRUE then its reference count is incremented and a reference placed in\naddress. If obj is not an array, then convert it to an array using\n`PyArray_FromAny` . No matter what is returned, you must DECREF the object\nreturned by this routine in address when you are done with it.\n\nThis is a default converter for output arrays given to functions. If obj is\n`Py_None` or `NULL`, then *address will be `NULL` but the call will succeed.\nIf `PyArray_Check` ( obj) is TRUE then it is returned in *address without\nincrementing its reference count.\n\nConvert any Python sequence, obj, smaller than `NPY_MAXDIMS` to a C-array of\n`npy_intp`. The Python object could also be a single number. The seq variable\nis a pointer to a structure with members ptr and len. On successful return,\nseq ->ptr contains a pointer to memory that must be freed, by calling\n`PyDimMem_FREE`, to avoid a memory leak. The restriction on memory size allows\nthis converter to be conveniently used for sequences intended to be\ninterpreted as array shapes.\n\nConvert any Python object, obj, with a (single-segment) buffer interface to a\nvariable with members that detail the object\u2019s use of its chunk of memory. The\nbuf variable is a pointer to a structure with base, ptr, len, and flags\nmembers. The `PyArray_Chunk` structure is binary compatible with the Python\u2019s\nbuffer object (through its len member on 32-bit platforms and its ptr member\non 64-bit platforms or in Python 2.5). On return, the base member is set to\nobj (or its base if obj is already a buffer object pointing to another\nobject). If you need to hold on to the memory be sure to INCREF the base\nmember. The chunk of memory is pointed to by buf ->ptr member and has length\nbuf ->len. The flags member of buf is `NPY_ARRAY_ALIGNED` with the\n`NPY_ARRAY_WRITEABLE` flag set if obj has a writeable buffer interface.\n\nConvert a Python object, obj, representing an axis argument to the proper\nvalue for passing to the functions that take an integer axis. Specifically, if\nobj is None, axis is set to `NPY_MAXDIMS` which is interpreted correctly by\nthe C-API functions that take axis arguments.\n\nConvert any Python object, obj, to `NPY_TRUE` or `NPY_FALSE`, and place the\nresult in value.\n\nConvert Python strings into the corresponding byte-order character: \u2018>\u2019, \u2018<\u2019,\n\u2018s\u2019, \u2018=\u2019, or \u2018|\u2019.\n\nConvert Python strings into one of `NPY_QUICKSORT` (starts with \u2018q\u2019 or \u2018Q\u2019),\n`NPY_HEAPSORT` (starts with \u2018h\u2019 or \u2018H\u2019), `NPY_MERGESORT` (starts with \u2018m\u2019 or\n\u2018M\u2019) or `NPY_STABLESORT` (starts with \u2018t\u2019 or \u2018T\u2019). `NPY_MERGESORT` and\n`NPY_STABLESORT` are aliased to each other for backwards compatibility and may\nrefer to one of several stable sorting algorithms depending on the data type.\n\nConvert Python strings into one of `NPY_SEARCHLEFT` (starts with \u2018l\u2019 or \u2018L\u2019),\nor `NPY_SEARCHRIGHT` (starts with \u2018r\u2019 or \u2018R\u2019).\n\nConvert the Python strings \u2018C\u2019, \u2018F\u2019, \u2018A\u2019, and \u2018K\u2019 into the `NPY_ORDER`\nenumeration `NPY_CORDER`, `NPY_FORTRANORDER`, `NPY_ANYORDER`, and\n`NPY_KEEPORDER`.\n\nConvert the Python strings \u2018no\u2019, \u2018equiv\u2019, \u2018safe\u2019, \u2018same_kind\u2019, and \u2018unsafe\u2019\ninto the `NPY_CASTING` enumeration `NPY_NO_CASTING`, `NPY_EQUIV_CASTING`,\n`NPY_SAFE_CASTING`, `NPY_SAME_KIND_CASTING`, and `NPY_UNSAFE_CASTING`.\n\nConvert the Python strings \u2018clip\u2019, \u2018wrap\u2019, and \u2018raise\u2019 into the `NPY_CLIPMODE`\nenumeration `NPY_CLIP`, `NPY_WRAP`, and `NPY_RAISE`.\n\nConverts either a sequence of clipmodes or a single clipmode into a C array of\n`NPY_CLIPMODE` values. The number of clipmodes n must be known before calling\nthis function. This function is provided to help functions allow a different\nclipmode for each dimension.\n\nConvert all kinds of Python objects (including arrays and array scalars) to a\nstandard integer. On error, -1 is returned and an exception set. You may find\nuseful the macro:\n\nConvert all kinds of Python objects (including arrays and array scalars) to a\n(platform-pointer-sized) integer. On error, -1 is returned and an exception\nset.\n\nConvert any Python sequence (or single Python number) passed in as seq to (up\nto) maxvals pointer-sized integers and place them in the vals array. The\nsequence can be smaller then maxvals as the number of converted objects is\nreturned.\n\nConvert typestring characters (with itemsize) to basic enumerated data types.\nThe typestring character corresponding to signed and unsigned integers,\nfloating point numbers, and complex-floating point numbers are recognized and\nconverted. Other values of gentype are returned. This function can be used to\nconvert, for example, the string \u2018f4\u2019 to `NPY_FLOAT32`.\n\nIn order to make use of the C-API from another extension module, the\n`import_array` function must be called. If the extension module is self-\ncontained in a single .c file, then that is all that needs to be done. If,\nhowever, the extension module involves multiple files where the C-API is\nneeded then some additional steps must be taken.\n\nThis function must be called in the initialization section of a module that\nwill make use of the C-API. It imports the module where the function-pointer\ntable is stored and points the correct variable to it.\n\nUsing these #defines you can use the C-API in multiple files for a single\nextension module. In each file you must define `PY_ARRAY_UNIQUE_SYMBOL` to\nsome name that will hold the C-API (e.g. myextension_ARRAY_API). This must be\ndone before including the numpy/arrayobject.h file. In the module\ninitialization routine you call `import_array`. In addition, in the files that\ndo not have the module initialization sub_routine define `NO_IMPORT_ARRAY`\nprior to including numpy/arrayobject.h.\n\nSuppose I have two files coolmodule.c and coolhelper.c which need to be\ncompiled and linked into a single extension module. Suppose coolmodule.c\ncontains the required initcool module initialization function (with the\nimport_array() function called). Then, coolmodule.c would have at the top:\n\nOn the other hand, coolhelper.c would contain at the top:\n\nYou can also put the common two last lines into an extension-local header file\nas long as you make sure that NO_IMPORT_ARRAY is #defined before #including\nthat file.\n\nInternally, these #defines work as follows:\n\nBecause python extensions are not used in the same way as usual libraries on\nmost platforms, some errors cannot be automatically detected at build time or\neven runtime. For example, if you build an extension using a function\navailable only for numpy >= 1.3.0, and you import the extension later with\nnumpy 1.2, you will not get an import error (but almost certainly a\nsegmentation fault when calling the function). That\u2019s why several functions\nare provided to check for numpy versions. The macros `NPY_VERSION` and\n`NPY_FEATURE_VERSION` corresponds to the numpy version used to build the\nextension, whereas the versions returned by the functions\n`PyArray_GetNDArrayCVersion` and `PyArray_GetNDArrayCFeatureVersion`\ncorresponds to the runtime numpy\u2019s version.\n\nThe rules for ABI and API compatibilities can be summarized as follows:\n\nABI incompatibility is automatically detected in every numpy\u2019s version. API\nincompatibility detection was added in numpy 1.4.0. If you want to supported\nmany different numpy versions with one extension binary, you have to build\nyour extension with the lowest `NPY_FEATURE_VERSION` as possible.\n\nThe current version of the ndarray object (check to see if this variable is\ndefined to guarantee the `numpy/arrayobject.h` header is being used).\n\nThe current version of the C-API.\n\nThis just returns the value `NPY_VERSION`. `NPY_VERSION` changes whenever a\nbackward incompatible change at the ABI level. Because it is in the C-API,\nhowever, comparing the output of this function from the value defined in the\ncurrent header gives a way to test if the C-API has changed thus requiring a\nre-compilation of extension modules that use the C-API. This is automatically\nchecked in the function `import_array`.\n\nNew in version 1.4.0.\n\nThis just returns the value `NPY_FEATURE_VERSION`. `NPY_FEATURE_VERSION`\nchanges whenever the API changes (e.g. a function is added). A changed value\ndoes not always require a recompile.\n\nNumPy stores an internal table of Python callable objects that are used to\nimplement arithmetic operations for arrays as well as certain array\ncalculation methods. This function allows the user to replace any or all of\nthese Python objects with their own versions. The keys of the dictionary,\ndict, are the named functions to replace and the paired value is the Python\ncallable object to use. Care should be taken that the function used to replace\nan internal array operation does not itself call back to that internal array\noperation (unless you have designed the function to handle that), or an\nunchecked infinite recursion can result (possibly causing program crash). The\nkey names that represent operations that can be replaced are:\n\nadd, subtract, multiply, divide, remainder, power, square, reciprocal,\nones_like, sqrt, negative, positive, absolute, invert, left_shift,\nright_shift, bitwise_and, bitwise_xor, bitwise_or, less, less_equal, equal,\nnot_equal, greater, greater_equal, floor_divide, true_divide, logical_or,\nlogical_and, floor, ceil, maximum, minimum, rint.\n\nThese functions are included here because they are used at least once in the\narray object\u2019s methods. The function returns -1 (without setting a Python\nError) if one of the objects being assigned is not callable.\n\nDeprecated since version 1.16.\n\nReturn a Python dictionary containing the callable Python objects stored in\nthe internal arithmetic operation table. The keys of this dictionary are given\nin the explanation for `PyArray_SetNumericOps`.\n\nDeprecated since version 1.16.\n\nThis function allows you to alter the tp_str and tp_repr methods of the array\nobject to any Python function. Thus you can alter what happens for all arrays\nwhen str(arr) or repr(arr) is called from Python. The function to be called is\npassed in as op. If repr is non-zero, then this function will be called in\nresponse to repr(arr), otherwise the function will be called in response to\nstr(arr). No check on whether or not op is callable is performed. The callable\npassed in to op should expect an array argument and should return a string to\nbe printed.\n\nMacros to allocate, free, and reallocate memory. These macros are used\ninternally to create arrays.\n\nMacros to allocate, free, and reallocate dimension and strides memory.\n\nThese macros use different memory allocators, depending on the constant\n`NPY_USE_PYMEM`. The system malloc is used when `NPY_USE_PYMEM` is 0, if\n`NPY_USE_PYMEM` is 1, then the Python memory allocator is used.\n\nIf `obj.flags` has `NPY_ARRAY_WRITEBACKIFCOPY` or (deprecated)\n`NPY_ARRAY_UPDATEIFCOPY`, this function clears the flags, `DECREF` s\n`obj->base` and makes it writeable, and sets `obj->base` to NULL. It then\ncopies `obj->data` to `obj->base->data`, and returns the error state of the\ncopy operation. This is the opposite of `PyArray_SetWritebackIfCopyBase`.\nUsually this is called once you are finished with `obj`, just before\n`Py_DECREF(obj)`. It may be called multiple times, or with `NULL` input. See\nalso `PyArray_DiscardWritebackIfCopy`.\n\nReturns 0 if nothing was done, -1 on error, and 1 if action was taken.\n\nThese macros are only meaningful if `NPY_ALLOW_THREADS` evaluates True during\ncompilation of the extension module. Otherwise, these macros are equivalent to\nwhitespace. Python uses a single Global Interpreter Lock (GIL) for each Python\nprocess so that only a single thread may execute at a time (even on multi-cpu\nmachines). When calling out to a compiled function that may take time to\ncompute (and does not have side-effects for other threads like updated global\nvariables), the GIL should be released so that other Python threads can run\nwhile the time-consuming calculations are performed. This can be accomplished\nusing two groups of macros. Typically, if one macro in a group is used in a\ncode block, all of them must be used in the same code block. Currently,\n`NPY_ALLOW_THREADS` is defined to the python-defined `WITH_THREADS` constant\nunless the environment variable `NPY_NOSMP` is set in which case\n`NPY_ALLOW_THREADS` is defined to be 0.\n\nThis group is used to call code that may take some time but does not use any\nPython C-API calls. Thus, the GIL should be released during its calculation.\n\nEquivalent to `Py_BEGIN_ALLOW_THREADS` except it uses `NPY_ALLOW_THREADS` to\ndetermine if the macro if replaced with white-space or not.\n\nEquivalent to `Py_END_ALLOW_THREADS` except it uses `NPY_ALLOW_THREADS` to\ndetermine if the macro if replaced with white-space or not.\n\nPlace in the variable declaration area. This macro sets up the variable needed\nfor storing the Python state.\n\nPlace right before code that does not need the Python interpreter (no Python\nC-API calls). This macro saves the Python state and releases the GIL.\n\nPlace right after code that does not need the Python interpreter. This macro\nacquires the GIL and restores the Python state from the saved variable.\n\nUseful to release the GIL only if dtype does not contain arbitrary Python\nobjects which may need the Python interpreter during execution of the loop.\n\nUseful to regain the GIL in situations where it was released using the BEGIN\nform of this macro.\n\nUseful to release the GIL only if loop_size exceeds a minimum threshold,\ncurrently set to 500. Should be matched with a `NPY_END_THREADS` to regain the\nGIL.\n\nThis group is used to re-acquire the Python GIL after it has been released.\nFor example, suppose the GIL has been released (using the previous calls), and\nthen some path in the code (perhaps in a different subroutine) requires use of\nthe Python C-API, then these macros are useful to acquire the GIL. These\nmacros accomplish essentially a reverse of the previous three (acquire the\nLOCK saving what state it had) and then re-release it with the saved state.\n\nPlace in the variable declaration area to set up the necessary variable.\n\nPlace before code that needs to call the Python C-API (when it is known that\nthe GIL has already been released).\n\nPlace after code that needs to call the Python C-API (to re-release the GIL).\n\nTip\n\nNever use semicolons after the threading support macros.\n\nDefault priority for arrays.\n\nDefault subtype priority.\n\nDefault scalar priority (very small)\n\nReturn the `__array_priority__` attribute (converted to a double) of obj or\ndef if no attribute of that name exists. Fast returns that avoid the attribute\nlookup are provided for objects of type `PyArray_Type`.\n\nDefault size of the user-settable internal buffers.\n\nSmallest size of user-settable internal buffers.\n\nLargest size allowed for the user-settable buffers.\n\nThe number of floating-point types\n\nThe maximum number of dimensions allowed in arrays.\n\nThe maximum number of array arguments that can be used in functions.\n\nDefined as 0 for use with Bool.\n\nDefined as 1 for use with Bool.\n\nThe return value of failed converter functions which are called using the \u201cO&\u201d\nsyntax in `PyArg_ParseTuple`-like functions.\n\nThe return value of successful converter functions which are called using the\n\u201cO&\u201d syntax in `PyArg_ParseTuple`-like functions.\n\nEvaluates as True if arrays a1 and a2 have the same shape.\n\nReturns the maximum of a and b. If (a) or (b) are expressions they are\nevaluated twice.\n\nReturns the minimum of a and b. If (a) or (b) are expressions they are\nevaluated twice.\n\nImplements the complex comparisons between two complex numbers (structures\nwith a real and imag member) using NumPy\u2019s definition of the ordering which is\nlexicographic: comparing the real parts first and then the complex parts if\nthe real parts are equal.\n\nReturns the reference count of any Python object.\n\nIf `obj.flags` has `NPY_ARRAY_WRITEBACKIFCOPY` or (deprecated)\n`NPY_ARRAY_UPDATEIFCOPY`, this function clears the flags, `DECREF` s\n`obj->base` and makes it writeable, and sets `obj->base` to NULL. In contrast\nto `PyArray_DiscardWritebackIfCopy` it makes no attempt to copy the data from\n`obj->base` This undoes `PyArray_SetWritebackIfCopyBase`. Usually this is\ncalled after an error when you are finished with `obj`, just before\n`Py_DECREF(obj)`. It may be called multiple times, or with `NULL` input.\n\nDeprecated in 1.14, use `PyArray_DiscardWritebackIfCopy` followed by\n`Py_XDECREF`\n\nDECREF\u2019s an array object which may have the (deprecated)\n`NPY_ARRAY_UPDATEIFCOPY` or `NPY_ARRAY_WRITEBACKIFCOPY` flag set without\ncausing the contents to be copied back into the original array. Resets the\n`NPY_ARRAY_WRITEABLE` flag on the base object. This is useful for recovering\nfrom an error condition when writeback semantics are used, but will lead to\nwrong results.\n\nA special variable-type which can take on different values to indicate the\nsorting algorithm being used.\n\nUsed as an alias of `NPY_MERGESORT` and vica versa.\n\nDefined to be the number of sorts. It is fixed at three by the need for\nbackwards compatibility, and consequently `NPY_MERGESORT` and `NPY_STABLESORT`\nare aliased to each other and may refer to one of several stable sorting\nalgorithms depending on the data type.\n\nA special variable type indicating the number of \u201ckinds\u201d of scalars\ndistinguished in determining scalar-coercion rules. This variable can take on\nthe values:\n\nDefined to be the number of scalar kinds (not including `NPY_NOSCALAR`).\n\nAn enumeration type indicating the element order that an array should be\ninterpreted in. When a brand new array is created, generally only NPY_CORDER\nand NPY_FORTRANORDER are used, whereas when one or more inputs are provided,\nthe order can be based on them.\n\nFortran order if all the inputs are Fortran, C otherwise.\n\nC order.\n\nFortran order.\n\nAn order as close to the order of the inputs as possible, even if the input is\nin neither C nor Fortran order.\n\nA variable type indicating the kind of clipping that should be applied in\ncertain functions.\n\nThe default for most operations, raises an exception if an index is out of\nbounds.\n\nClips an index to the valid range if it is out of bounds.\n\nWraps an index to the valid range if it is out of bounds.\n\nA variable type indicating whether the index returned should be that of the\nfirst suitable location (if `NPY_SEARCHLEFT`) or of the last (if\n`NPY_SEARCHRIGHT`).\n\nA variable type indicating the selection algorithm being used.\n\nNew in version 1.6.\n\nAn enumeration type indicating how permissive data conversions should be. This\nis used by the iterator added in NumPy 1.6, and is intended to be used more\nbroadly in a future version.\n\nOnly allow identical types.\n\nAllow identical and casts involving byte swapping.\n\nOnly allow casts which will not cause values to be rounded, truncated, or\notherwise changed.\n\nAllow any safe casts, and casts between types of the same kind. For example,\nfloat64 -> float32 is permitted with this rule.\n\nAllow any cast, no matter what kind of data loss may occur.\n\n"}, {"name": "int PyArray_ObjectType()", "path": "reference/c-api/array#c.PyArray_ObjectType", "type": "Array API", "text": "\nThis function is superseded by `PyArray_MinScalarType` and/or\n`PyArray_ResultType`.\n\nThis function is useful for determining a common type that two or more arrays\ncan be converted to. It only works for non-flexible array types as no itemsize\ninformation is passed. The mintype argument represents the minimum type\nacceptable, and op represents the object that will be converted to an array.\nThe return value is the enumerated typenumber that represents the data-type\nthat op should have.\n\n"}, {"name": "int PyArray_OrderConverter()", "path": "reference/c-api/array#c.PyArray_OrderConverter", "type": "Array API", "text": "\nConvert the Python strings \u2018C\u2019, \u2018F\u2019, \u2018A\u2019, and \u2018K\u2019 into the `NPY_ORDER`\nenumeration `NPY_CORDER`, `NPY_FORTRANORDER`, `NPY_ANYORDER`, and\n`NPY_KEEPORDER`.\n\n"}, {"name": "int PyArray_OutputConverter()", "path": "reference/c-api/array#c.PyArray_OutputConverter", "type": "Array API", "text": "\nThis is a default converter for output arrays given to functions. If obj is\n`Py_None` or `NULL`, then *address will be `NULL` but the call will succeed.\nIf `PyArray_Check` ( obj) is TRUE then it is returned in *address without\nincrementing its reference count.\n\n"}, {"name": "int PyArray_Partition()", "path": "reference/c-api/array#c.PyArray_Partition", "type": "Array API", "text": "\nEquivalent to `ndarray.partition` (self, ktharray, axis, kind). Partitions the\narray so that the values of the element indexed by ktharray are in the\npositions they would be if the array is fully sorted and places all elements\nsmaller than the kth before and all elements equal or greater after the kth\nelement. The ordering of all elements within the partitions is undefined. If\nself->descr is a data-type with fields defined, then self->descr->names is\nused to determine the sort order. A comparison where the first field is equal\nwill use the second field and so on. To alter the sort order of a structured\narray, create a new data-type with a different order of names and construct a\nview of the array with that new data-type. Returns zero on success and -1 on\nfailure.\n\n"}, {"name": "int PyArray_RegisterCanCast()", "path": "reference/c-api/array#c.PyArray_RegisterCanCast", "type": "Array API", "text": "\nRegister the data-type number, totype, as castable from data-type object,\ndescr, of the given scalar kind. Use scalar = `NPY_NOSCALAR` to register that\nan array of data-type descr can be cast safely to a data-type whose\ntype_number is totype. The return value is 0 on success or -1 on failure.\n\n"}, {"name": "int PyArray_RegisterCastFunc()", "path": "reference/c-api/array#c.PyArray_RegisterCastFunc", "type": "Array API", "text": "\nRegister a low-level casting function, castfunc, to convert from the data-\ntype, descr, to the given data-type number, totype. Any old casting function\nis over-written. A `0` is returned on success or a `-1` on failure.\n\n"}, {"name": "int PyArray_RegisterDataType()", "path": "reference/c-api/array#c.PyArray_RegisterDataType", "type": "Array API", "text": "\nRegister a data-type as a new user-defined data type for arrays. The type must\nhave most of its entries filled in. This is not always checked and errors can\nproduce segfaults. In particular, the typeobj member of the `dtype` structure\nmust be filled with a Python type that has a fixed-size element-size that\ncorresponds to the elsize member of dtype. Also the `f` member must have the\nrequired functions: nonzero, copyswap, copyswapn, getitem, setitem, and cast\n(some of the cast functions may be `NULL` if no support is desired). To avoid\nconfusion, you should choose a unique character typecode but this is not\nenforced and not relied on internally.\n\nA user-defined type number is returned that uniquely identifies the type. A\npointer to the new structure can then be obtained from `PyArray_DescrFromType`\nusing the returned type number. A -1 is returned if an error occurs. If this\ndtype has already been registered (checked only by the address of the\npointer), then return the previously-assigned type-number.\n\n"}, {"name": "int PyArray_RemoveSmallest()", "path": "reference/c-api/array#c.PyArray_RemoveSmallest", "type": "Array API", "text": "\nThis function takes a multi-iterator object that has been previously\n\u201cbroadcasted,\u201d finds the dimension with the smallest \u201csum of strides\u201d in the\nbroadcasted result and adapts all the iterators so as not to iterate over that\ndimension (by effectively making them of length-1 in that dimension). The\ncorresponding dimension is returned unless mit ->nd is 0, then -1 is returned.\nThis function is useful for constructing ufunc-like routines that broadcast\ntheir inputs correctly and then call a strided 1-d version of the routine as\nthe inner-loop. This 1-d version is usually optimized for speed and for this\nreason the loop should be performed over the axis that won\u2019t require large\nstride jumps.\n\n"}, {"name": "int PyArray_ResolveWritebackIfCopy()", "path": "reference/c-api/array#c.PyArray_ResolveWritebackIfCopy", "type": "Array API", "text": "\nIf `obj.flags` has `NPY_ARRAY_WRITEBACKIFCOPY` or (deprecated)\n`NPY_ARRAY_UPDATEIFCOPY`, this function clears the flags, `DECREF` s\n`obj->base` and makes it writeable, and sets `obj->base` to NULL. It then\ncopies `obj->data` to `obj->base->data`, and returns the error state of the\ncopy operation. This is the opposite of `PyArray_SetWritebackIfCopyBase`.\nUsually this is called once you are finished with `obj`, just before\n`Py_DECREF(obj)`. It may be called multiple times, or with `NULL` input. See\nalso `PyArray_DiscardWritebackIfCopy`.\n\nReturns 0 if nothing was done, -1 on error, and 1 if action was taken.\n\n"}, {"name": "int PyArray_SearchsideConverter()", "path": "reference/c-api/array#c.PyArray_SearchsideConverter", "type": "Array API", "text": "\nConvert Python strings into one of `NPY_SEARCHLEFT` (starts with \u2018l\u2019 or \u2018L\u2019),\nor `NPY_SEARCHRIGHT` (starts with \u2018r\u2019 or \u2018R\u2019).\n\n"}, {"name": "int PyArray_SetBaseObject()", "path": "reference/c-api/array#c.PyArray_SetBaseObject", "type": "Array API", "text": "\nNew in version 1.7.\n\nThis function steals a reference to `obj` and sets it as the base property of\n`arr`.\n\nIf you construct an array by passing in your own memory buffer as a parameter,\nyou need to set the array\u2019s `base` property to ensure the lifetime of the\nmemory buffer is appropriate.\n\nThe return value is 0 on success, -1 on failure.\n\nIf the object provided is an array, this function traverses the chain of\n`base` pointers so that each array points to the owner of the memory directly.\nOnce the base is set, it may not be changed to another value.\n\n"}, {"name": "int PyArray_SetField()", "path": "reference/c-api/array#c.PyArray_SetField", "type": "Array API", "text": "\nEquivalent to `ndarray.setfield` (self, val, dtype, offset ). Set the field\nstarting at offset in bytes and of the given dtype to val. The offset plus\ndtype ->elsize must be less than self ->descr->elsize or an error is raised.\nOtherwise, the val argument is converted to an array and copied into the field\npointed to. If necessary, the elements of val are repeated to fill the\ndestination array, But, the number of elements in the destination must be an\ninteger multiple of the number of elements in val.\n\n"}, {"name": "int PyArray_SETITEM()", "path": "reference/c-api/array#c.PyArray_SETITEM", "type": "Array API", "text": "\nConvert obj and place it in the ndarray, arr, at the place pointed to by\nitemptr. Return -1 if an error occurs or 0 on success.\n\n"}, {"name": "int PyArray_SetUpdateIfCopyBase()", "path": "reference/c-api/array#c.PyArray_SetUpdateIfCopyBase", "type": "Array API", "text": "\nPrecondition: `arr` is a copy of `base` (though possibly with different\nstrides, ordering, etc.) Set the UPDATEIFCOPY flag and `arr->base` so that\nwhen `arr` is destructed, it will copy any changes back to `base`. DEPRECATED,\nuse `PyArray_SetWritebackIfCopyBase`.\n\nReturns 0 for success, -1 for failure.\n\n"}, {"name": "int PyArray_SetWritebackIfCopyBase()", "path": "reference/c-api/array#c.PyArray_SetWritebackIfCopyBase", "type": "Array API", "text": "\nPrecondition: `arr` is a copy of `base` (though possibly with different\nstrides, ordering, etc.) Sets the `NPY_ARRAY_WRITEBACKIFCOPY` flag and\n`arr->base`, and set `base` to READONLY. Call `PyArray_ResolveWritebackIfCopy`\nbefore calling `Py_DECREF` in order copy any changes back to `base` and reset\nthe READONLY flag.\n\nReturns 0 for success, -1 for failure.\n\n"}, {"name": "int PyArray_SortkindConverter()", "path": "reference/c-api/array#c.PyArray_SortkindConverter", "type": "Array API", "text": "\nConvert Python strings into one of `NPY_QUICKSORT` (starts with \u2018q\u2019 or \u2018Q\u2019),\n`NPY_HEAPSORT` (starts with \u2018h\u2019 or \u2018H\u2019), `NPY_MERGESORT` (starts with \u2018m\u2019 or\n\u2018M\u2019) or `NPY_STABLESORT` (starts with \u2018t\u2019 or \u2018T\u2019). `NPY_MERGESORT` and\n`NPY_STABLESORT` are aliased to each other for backwards compatibility and may\nrefer to one of several stable sorting algorithms depending on the data type.\n\n"}, {"name": "int PyArray_TYPE()", "path": "reference/c-api/array#c.PyArray_TYPE", "type": "Array API", "text": "\nReturn the (builtin) typenumber for the elements of this array.\n\n"}, {"name": "int PyArray_TypeNumFromName()", "path": "reference/c-api/array#c.PyArray_TypeNumFromName", "type": "Array API", "text": "\nGiven a string return the type-number for the data-type with that string as\nthe type-object name. Returns `NPY_NOTYPE` without setting an error if no type\ncan be found. Only works for user-defined data-types.\n\n"}, {"name": "int PyArray_TypestrConvert()", "path": "reference/c-api/array#c.PyArray_TypestrConvert", "type": "Array API", "text": "\nConvert typestring characters (with itemsize) to basic enumerated data types.\nThe typestring character corresponding to signed and unsigned integers,\nfloating point numbers, and complex-floating point numbers are recognized and\nconverted. Other values of gentype are returned. This function can be used to\nconvert, for example, the string \u2018f4\u2019 to `NPY_FLOAT32`.\n\n"}, {"name": "int PyArray_ValidType()", "path": "reference/c-api/array#c.PyArray_ValidType", "type": "Array API", "text": "\nReturns `NPY_TRUE` if typenum represents a valid type-number (builtin or user-\ndefined or character code). Otherwise, this function returns `NPY_FALSE`.\n\n"}, {"name": "int PyArray_XDECREF()", "path": "reference/c-api/array#c.PyArray_XDECREF", "type": "Array API", "text": "\nUsed for an array, op, that contains any Python objects. It decrements the\nreference count of every object in the array according to the data-type of op.\nNormal return value is 0. A -1 is returned if an error occurs.\n\n"}, {"name": "int PyArrayIter_Check()", "path": "reference/c-api/array#c.PyArrayIter_Check", "type": "Array API", "text": "\nEvaluates true if op is an array iterator (or instance of a subclass of the\narray iterator type).\n\n"}, {"name": "int PyArrayNeighborhoodIter_Next()", "path": "reference/c-api/array#c.PyArrayNeighborhoodIter_Next", "type": "Array API", "text": "\nAfter this call, iter->dataptr points to the next point of the neighborhood.\nCalling this function after every point of the neighborhood has been visited\nis undefined.\n\n"}, {"name": "int PyArrayNeighborhoodIter_Reset()", "path": "reference/c-api/array#c.PyArrayNeighborhoodIter_Reset", "type": "Array API", "text": "\nReset the iterator position to the first point of the neighborhood. This\nshould be called whenever the iter argument given at\nPyArray_NeighborhoodIterObject is changed (see example)\n\n"}, {"name": "int PyDataType_FLAGCHK()", "path": "reference/c-api/types-and-structures#c.NPY_USE_SETITEM.PyDataType_FLAGCHK", "type": "Python Types and C-Structures", "text": "\nReturn true if all the given flags are set for the data-type object.\n\n"}, {"name": "int PyDataType_HASFIELDS()", "path": "reference/c-api/array#c.PyDataType_HASFIELDS", "type": "Array API", "text": "\n\n"}, {"name": "int PyDataType_ISBOOL()", "path": "reference/c-api/array#c.PyDataType_ISBOOL", "type": "Array API", "text": "\n\n"}, {"name": "int PyDataType_ISCOMPLEX()", "path": "reference/c-api/array#c.PyDataType_ISCOMPLEX", "type": "Array API", "text": "\n\n"}, {"name": "int PyDataType_ISEXTENDED()", "path": "reference/c-api/array#c.PyDataType_ISEXTENDED", "type": "Array API", "text": "\n\n"}, {"name": "int PyDataType_ISFLEXIBLE()", "path": "reference/c-api/array#c.PyDataType_ISFLEXIBLE", "type": "Array API", "text": "\n\n"}, {"name": "int PyDataType_ISFLOAT()", "path": "reference/c-api/array#c.PyDataType_ISFLOAT", "type": "Array API", "text": "\n\n"}, {"name": "int PyDataType_ISINTEGER()", "path": "reference/c-api/array#c.PyDataType_ISINTEGER", "type": "Array API", "text": "\n\n"}, {"name": "int PyDataType_ISNUMBER()", "path": "reference/c-api/array#c.PyDataType_ISNUMBER", "type": "Array API", "text": "\n\n"}, {"name": "int PyDataType_ISOBJECT()", "path": "reference/c-api/array#c.PyDataType_ISOBJECT", "type": "Array API", "text": "\n\n"}, {"name": "int PyDataType_ISPYTHON()", "path": "reference/c-api/array#c.PyDataType_ISPYTHON", "type": "Array API", "text": "\n\n"}, {"name": "int PyDataType_ISSIGNED()", "path": "reference/c-api/array#c.PyDataType_ISSIGNED", "type": "Array API", "text": "\n\n"}, {"name": "int PyDataType_ISSTRING()", "path": "reference/c-api/array#c.PyDataType_ISSTRING", "type": "Array API", "text": "\n\n"}, {"name": "int PyDataType_ISUNSIGNED()", "path": "reference/c-api/array#c.PyDataType_ISUNSIGNED", "type": "Array API", "text": "\n\n"}, {"name": "int PyDataType_ISUNSIZED()", "path": "reference/c-api/array#c.PyDataType_ISUNSIZED", "type": "Array API", "text": "\nType has no size information attached, and can be resized. Should only be\ncalled on flexible dtypes. Types that are attached to an array will always be\nsized, hence the array form of this macro not existing.\n\nChanged in version 1.18.\n\nFor structured datatypes with no fields this function now returns False.\n\n"}, {"name": "int PyDataType_ISUSERDEF()", "path": "reference/c-api/array#c.PyDataType_ISUSERDEF", "type": "Array API", "text": "\n\n"}, {"name": "int PyDataType_REFCHK()", "path": "reference/c-api/types-and-structures#c.NPY_USE_SETITEM.PyDataType_REFCHK", "type": "Python Types and C-Structures", "text": "\nEquivalent to `PyDataType_FLAGCHK` (dtype, `NPY_ITEM_REFCOUNT`).\n\n"}, {"name": "int PyModule_AddIntConstant()", "path": "user/c-info.how-to-extend#c.PyModule_AddIntConstant", "type": "User Guide", "text": "\n\n"}, {"name": "int PyModule_AddObject()", "path": "user/c-info.how-to-extend", "type": "User Guide", "text": "\nWhile the ndarray object is designed to allow rapid computation in Python, it\nis also designed to be general-purpose and satisfy a wide- variety of\ncomputational needs. As a result, if absolute speed is essential, there is no\nreplacement for a well-crafted, compiled loop specific to your application and\nhardware. This is one of the reasons that numpy includes f2py so that an easy-\nto-use mechanisms for linking (simple) C/C++ and (arbitrary) Fortran code\ndirectly into Python are available. You are encouraged to use and improve this\nmechanism. The purpose of this section is not to document this tool but to\ndocument the more basic steps to writing an extension module that this tool\ndepends on.\n\nWhen an extension module is written, compiled, and installed to somewhere in\nthe Python path (sys.path), the code can then be imported into Python as if it\nwere a standard python file. It will contain objects and methods that have\nbeen defined and compiled in C code. The basic steps for doing this in Python\nare well-documented and you can find more information in the documentation for\nPython itself available online at www.python.org .\n\nIn addition to the Python C-API, there is a full and rich C-API for NumPy\nallowing sophisticated manipulations on a C-level. However, for most\napplications, only a few API calls will typically be used. For example, if you\nneed to just extract a pointer to memory along with some shape information to\npass to another calculation routine, then you will use very different calls\nthan if you are trying to create a new array-like type or add a new data type\nfor ndarrays. This chapter documents the API calls and macros that are most\ncommonly used.\n\nThere is exactly one function that must be defined in your C-code in order for\nPython to use it as an extension module. The function must be called\ninit{name} where {name} is the name of the module from Python. This function\nmust be declared so that it is visible to code outside of the routine. Besides\nadding the methods and constants you desire, this subroutine must also contain\ncalls like `import_array()` and/or `import_ufunc()` depending on which C-API\nis needed. Forgetting to place these commands will show itself as an ugly\nsegmentation fault (crash) as soon as any C-API subroutine is actually called.\nIt is actually possible to have multiple init{name} functions in a single file\nin which case multiple modules will be defined by that file. However, there\nare some tricks to get that to work correctly and it is not covered here.\n\nA minimal `init{name}` method looks like:\n\nThe mymethods must be an array (usually statically declared) of PyMethodDef\nstructures which contain method names, actual C-functions, a variable\nindicating whether the method uses keyword arguments or not, and docstrings.\nThese are explained in the next section. If you want to add constants to the\nmodule, then you store the returned value from Py_InitModule which is a module\nobject. The most general way to add items to the module is to get the module\ndictionary using PyModule_GetDict(module). With the module dictionary, you can\nadd whatever you like to the module manually. An easier way to add objects to\nthe module is to use one of three additional Python C-API calls that do not\nrequire a separate extraction of the module dictionary. These are documented\nin the Python documentation, but repeated here for convenience:\n\nAll three of these functions require the module object (the return value of\nPy_InitModule). The name is a string that labels the value in the module.\nDepending on which function is called, the value argument is either a general\nobject (`PyModule_AddObject` steals a reference to it), an integer constant,\nor a string constant.\n\nThe second argument passed in to the Py_InitModule function is a structure\nthat makes it easy to to define functions in the module. In the example given\nabove, the mymethods structure would have been defined earlier in the file\n(usually right before the init{name} subroutine) to:\n\nEach entry in the mymethods array is a `PyMethodDef` structure containing 1)\nthe Python name, 2) the C-function that implements the function, 3) flags\nindicating whether or not keywords are accepted for this function, and 4) The\ndocstring for the function. Any number of functions may be defined for a\nsingle module by adding more entries to this table. The last entry must be all\nNULL as shown to act as a sentinel. Python looks for this entry to know that\nall of the functions for the module have been defined.\n\nThe last thing that must be done to finish the extension module is to actually\nwrite the code that performs the desired functions. There are two kinds of\nfunctions: those that don\u2019t accept keyword arguments, and those that do.\n\nFunctions that don\u2019t accept keyword arguments should be written as:\n\nThe dummy argument is not used in this context and can be safely ignored. The\nargs argument contains all of the arguments passed in to the function as a\ntuple. You can do anything you want at this point, but usually the easiest way\nto manage the input arguments is to call `PyArg_ParseTuple` (args,\nformat_string, addresses_to_C_variables\u2026) or `PyArg_UnpackTuple` (tuple,\n\u201cname\u201d, min, max, \u2026). A good description of how to use the first function is\ncontained in the Python C-API reference manual under section 5.5 (Parsing\narguments and building values). You should pay particular attention to the\n\u201cO&\u201d format which uses converter functions to go between the Python object and\nthe C object. All of the other format functions can be (mostly) thought of as\nspecial cases of this general rule. There are several converter functions\ndefined in the NumPy C-API that may be of use. In particular, the\n`PyArray_DescrConverter` function is very useful to support arbitrary data-\ntype specification. This function transforms any valid data-type Python object\ninto a PyArray_Descr* object. Remember to pass in the address of the\nC-variables that should be filled in.\n\nThere are lots of examples of how to use `PyArg_ParseTuple` throughout the\nNumPy source code. The standard usage is like this:\n\nIt is important to keep in mind that you get a borrowed reference to the\nobject when using the \u201cO\u201d format string. However, the converter functions\nusually require some form of memory handling. In this example, if the\nconversion is successful, dtype will hold a new reference to a PyArray_Descr*\nobject, while input will hold a borrowed reference. Therefore, if this\nconversion were mixed with another conversion (say to an integer) and the\ndata-type conversion was successful but the integer conversion failed, then\nyou would need to release the reference count to the data-type object before\nreturning. A typical way to do this is to set dtype to `NULL` before calling\n`PyArg_ParseTuple` and then use `Py_XDECREF` on dtype before returning.\n\nAfter the input arguments are processed, the code that actually does the work\nis written (likely calling other functions as needed). The final step of the\nC-function is to return something. If an error is encountered then `NULL`\nshould be returned (making sure an error has actually been set). If nothing\nshould be returned then increment `Py_None` and return it. If a single object\nshould be returned then it is returned (ensuring that you own a reference to\nit first). If multiple objects should be returned then you need to return a\ntuple. The `Py_BuildValue` (format_string, c_variables\u2026) function makes it\neasy to build tuples of Python objects from C variables. Pay special attention\nto the difference between \u2018N\u2019 and \u2018O\u2019 in the format string or you can easily\ncreate memory leaks. The \u2018O\u2019 format string increments the reference count of\nthe PyObject* C-variable it corresponds to, while the \u2018N\u2019 format string steals\na reference to the corresponding PyObject* C-variable. You should use \u2018N\u2019 if\nyou have already created a reference for the object and just want to give that\nreference to the tuple. You should use \u2018O\u2019 if you only have a borrowed\nreference to an object and need to create one to provide for the tuple.\n\nThese functions are very similar to functions without keyword arguments. The\nonly difference is that the function signature is:\n\nThe kwds argument holds a Python dictionary whose keys are the names of the\nkeyword arguments and whose values are the corresponding keyword-argument\nvalues. This dictionary can be processed however you see fit. The easiest way\nto handle it, however, is to replace the `PyArg_ParseTuple` (args,\nformat_string, addresses\u2026) function with a call to\n`PyArg_ParseTupleAndKeywords` (args, kwds, format_string, char *kwlist[],\naddresses\u2026). The kwlist parameter to this function is a `NULL` -terminated\narray of strings providing the expected keyword arguments. There should be one\nstring for each entry in the format_string. Using this function will raise a\nTypeError if invalid keyword arguments are passed in.\n\nFor more help on this function please see section 1.8 (Keyword Parameters for\nExtension Functions) of the Extending and Embedding tutorial in the Python\ndocumentation.\n\nThe biggest difficulty when writing extension modules is reference counting.\nIt is an important reason for the popularity of f2py, weave, Cython, ctypes,\netc\u2026. If you mis-handle reference counts you can get problems from memory-\nleaks to segmentation faults. The only strategy I know of to handle reference\ncounts correctly is blood, sweat, and tears. First, you force it into your\nhead that every Python variable has a reference count. Then, you understand\nexactly what each function does to the reference count of your objects, so\nthat you can properly use DECREF and INCREF when you need them. Reference\ncounting can really test the amount of patience and diligence you have towards\nyour programming craft. Despite the grim depiction, most cases of reference\ncounting are quite straightforward with the most common difficulty being not\nusing DECREF on objects before exiting early from a routine due to some error.\nIn second place, is the common error of not owning the reference on an object\nthat is passed to a function or macro that is going to steal the reference (\ne.g. `PyTuple_SET_ITEM`, and most functions that take `PyArray_Descr`\nobjects).\n\nTypically you get a new reference to a variable when it is created or is the\nreturn value of some function (there are some prominent exceptions, however \u2014\nsuch as getting an item out of a tuple or a dictionary). When you own the\nreference, you are responsible to make sure that `Py_DECREF` (var) is called\nwhen the variable is no longer necessary (and no other function has \u201cstolen\u201d\nits reference). Also, if you are passing a Python object to a function that\nwill \u201csteal\u201d the reference, then you need to make sure you own it (or use\n`Py_INCREF` to get your own reference). You will also encounter the notion of\nborrowing a reference. A function that borrows a reference does not alter the\nreference count of the object and does not expect to \u201chold on \u201cto the\nreference. It\u2019s just going to use the object temporarily. When you use\n`PyArg_ParseTuple` or `PyArg_UnpackTuple` you receive a borrowed reference to\nthe objects in the tuple and should not alter their reference count inside\nyour function. With practice, you can learn to get reference counting right,\nbut it can be frustrating at first.\n\nOne common source of reference-count errors is the `Py_BuildValue` function.\nPay careful attention to the difference between the \u2018N\u2019 format character and\nthe \u2018O\u2019 format character. If you create a new object in your subroutine (such\nas an output array), and you are passing it back in a tuple of return values,\nthen you should most- likely use the \u2018N\u2019 format character in `Py_BuildValue`.\nThe \u2018O\u2019 character will increase the reference count by one. This will leave\nthe caller with two reference counts for a brand-new array. When the variable\nis deleted and the reference count decremented by one, there will still be\nthat extra reference count, and the array will never be deallocated. You will\nhave a reference-counting induced memory leak. Using the \u2018N\u2019 character will\navoid this situation as it will return to the caller an object (inside the\ntuple) with a single reference count.\n\nMost extension modules for NumPy will need to access the memory for an ndarray\nobject (or one of it\u2019s sub-classes). The easiest way to do this doesn\u2019t\nrequire you to know much about the internals of NumPy. The method is to\n\nEnsure you are dealing with a well-behaved array (aligned, in machine byte-\norder and single-segment) of the correct type and number of dimensions.\n\nEach of these sub-topics is covered in the following sub-sections.\n\nThe main routine for obtaining an array from any Python object that can be\nconverted to an array is `PyArray_FromAny`. This function is very flexible\nwith many input arguments. Several macros make it easier to use the basic\nfunction. `PyArray_FROM_OTF` is arguably the most useful of these macros for\nthe most common uses. It allows you to convert an arbitrary Python object to\nan array of a specific builtin data-type ( e.g. float), while specifying a\nparticular set of requirements ( e.g. contiguous, aligned, and writeable). The\nsyntax is\n\nReturn an ndarray from any Python object, obj, that can be converted to an\narray. The number of dimensions in the returned array is determined by the\nobject. The desired data-type of the returned array is provided in typenum\nwhich should be one of the enumerated types. The requirements for the returned\narray can be any combination of standard array flags. Each of these arguments\nis explained in more detail below. You receive a new reference to the array on\nsuccess. On failure, `NULL` is returned and an exception is set.\n\nThe object can be any Python object convertible to an ndarray. If the object\nis already (a subclass of) the ndarray that satisfies the requirements then a\nnew reference is returned. Otherwise, a new array is constructed. The contents\nof obj are copied to the new array unless the array interface is used so that\ndata does not have to be copied. Objects that can be converted to an array\ninclude: 1) any nested sequence object, 2) any object exposing the array\ninterface, 3) any object with an `__array__` method (which should return an\nndarray), and 4) any scalar object (becomes a zero-dimensional array). Sub-\nclasses of the ndarray that otherwise fit the requirements will be passed\nthrough. If you want to ensure a base-class ndarray, then use\n`NPY_ARRAY_ENSUREARRAY` in the requirements flag. A copy is made only if\nnecessary. If you want to guarantee a copy, then pass in\n`NPY_ARRAY_ENSURECOPY` to the requirements flag.\n\nOne of the enumerated types or `NPY_NOTYPE` if the data-type should be\ndetermined from the object itself. The C-based names can be used:\n\n`NPY_BOOL`, `NPY_BYTE`, `NPY_UBYTE`, `NPY_SHORT`, `NPY_USHORT`, `NPY_INT`,\n`NPY_UINT`, `NPY_LONG`, `NPY_ULONG`, `NPY_LONGLONG`, `NPY_ULONGLONG`,\n`NPY_DOUBLE`, `NPY_LONGDOUBLE`, `NPY_CFLOAT`, `NPY_CDOUBLE`,\n`NPY_CLONGDOUBLE`, `NPY_OBJECT`.\n\nAlternatively, the bit-width names can be used as supported on the platform.\nFor example:\n\n`NPY_INT8`, `NPY_INT16`, `NPY_INT32`, `NPY_INT64`, `NPY_UINT8`, `NPY_UINT16`,\n`NPY_UINT32`, `NPY_UINT64`, `NPY_FLOAT32`, `NPY_FLOAT64`, `NPY_COMPLEX64`,\n`NPY_COMPLEX128`.\n\nThe object will be converted to the desired type only if it can be done\nwithout losing precision. Otherwise `NULL` will be returned and an error\nraised. Use `NPY_ARRAY_FORCECAST` in the requirements flag to override this\nbehavior.\n\nThe memory model for an ndarray admits arbitrary strides in each dimension to\nadvance to the next element of the array. Often, however, you need to\ninterface with code that expects a C-contiguous or a Fortran-contiguous memory\nlayout. In addition, an ndarray can be misaligned (the address of an element\nis not at an integral multiple of the size of the element) which can cause\nyour program to crash (or at least work more slowly) if you try and\ndereference a pointer into the array data. Both of these problems can be\nsolved by converting the Python object into an array that is more \u201cwell-\nbehaved\u201d for your specific usage.\n\nThe requirements flag allows specification of what kind of array is\nacceptable. If the object passed in does not satisfy this requirements then a\ncopy is made so that the returned object will satisfy the requirements. these\nndarray can use a very generic pointer to memory. This flag allows\nspecification of the desired properties of the returned array object. All of\nthe flags are explained in the detailed API chapter. The flags most commonly\nneeded are `NPY_ARRAY_IN_ARRAY`, `NPY_OUT_ARRAY`, and `NPY_ARRAY_INOUT_ARRAY`:\n\nThis flag is useful for arrays that must be in C-contiguous order and aligned.\nThese kinds of arrays are usually input arrays for some algorithm.\n\nThis flag is useful to specify an array that is in C-contiguous order, is\naligned, and can be written to as well. Such an array is usually returned as\noutput (although normally such output arrays are created from scratch).\n\nThis flag is useful to specify an array that will be used for both input and\noutput. `PyArray_ResolveWritebackIfCopy` must be called before `Py_DECREF` at\nthe end of the interface routine to write back the temporary data into the\noriginal array passed in. Use of the `NPY_ARRAY_WRITEBACKIFCOPY` or\n`NPY_ARRAY_UPDATEIFCOPY` flags requires that the input object is already an\narray (because other objects cannot be automatically updated in this fashion).\nIf an error occurs use `PyArray_DiscardWritebackIfCopy` (obj) on an array with\nthese flags set. This will set the underlying base array writable without\ncausing the contents to be copied back into the original array.\n\nOther useful flags that can be OR\u2019d as additional requirements are:\n\nCast to the desired type, even if it can\u2019t be done without losing information.\n\nMake sure the resulting array is a copy of the original.\n\nMake sure the resulting object is an actual ndarray and not a sub- class.\n\nNote\n\nWhether or not an array is byte-swapped is determined by the data-type of the\narray. Native byte-order arrays are always requested by `PyArray_FROM_OTF` and\nso there is no need for a `NPY_ARRAY_NOTSWAPPED` flag in the requirements\nargument. There is also no way to get a byte-swapped array from this routine.\n\nQuite often, new arrays must be created from within extension-module code.\nPerhaps an output array is needed and you don\u2019t want the caller to have to\nsupply it. Perhaps only a temporary array is needed to hold an intermediate\ncalculation. Whatever the need there are simple ways to get an ndarray object\nof whatever data-type is needed. The most general function for doing this is\n`PyArray_NewFromDescr`. All array creation functions go through this heavily\nre-used code. Because of its flexibility, it can be somewhat confusing to use.\nAs a result, simpler forms exist that are easier to use. These forms are part\nof the `PyArray_SimpleNew` family of functions, which simplify the interface\nby providing default values for common use cases.\n\nIf obj is an ndarray (PyArrayObject*), then the data-area of the ndarray is\npointed to by the void* pointer `PyArray_DATA` (obj) or the char* pointer\n`PyArray_BYTES` (obj). Remember that (in general) this data-area may not be\naligned according to the data-type, it may represent byte-swapped data, and/or\nit may not be writeable. If the data area is aligned and in native byte-order,\nthen how to get at a specific element of the array is determined only by the\narray of npy_intp variables, `PyArray_STRIDES` (obj). In particular, this\nc-array of integers shows how many bytes must be added to the current element\npointer to get to the next element in each dimension. For arrays less than\n4-dimensions there are `PyArray_GETPTR{k}` (obj, \u2026) macros where {k} is the\ninteger 1, 2, 3, or 4 that make using the array strides easier. The arguments\n\u2026. represent {k} non- negative integer indices into the array. For example,\nsuppose `E` is a 3-dimensional ndarray. A (void*) pointer to the element\n`E[i,j,k]` is obtained as `PyArray_GETPTR3` (E, i, j, k).\n\nAs explained previously, C-style contiguous arrays and Fortran-style\ncontiguous arrays have particular striding patterns. Two array flags\n(`NPY_ARRAY_C_CONTIGUOUS` and `NPY_ARRAY_F_CONTIGUOUS`) indicate whether or\nnot the striding pattern of a particular array matches the C-style contiguous\nor Fortran-style contiguous or neither. Whether or not the striding pattern\nmatches a standard C or Fortran one can be tested Using\n`PyArray_IS_C_CONTIGUOUS` (obj) and `PyArray_ISFORTRAN` (obj) respectively.\nMost third-party libraries expect contiguous arrays. But, often it is not\ndifficult to support general-purpose striding. I encourage you to use the\nstriding information in your own code whenever possible, and reserve single-\nsegment requirements for wrapping third-party code. Using the striding\ninformation provided with the ndarray rather than requiring a contiguous\nstriding reduces copying that otherwise must be made.\n\nThe following example shows how you might write a wrapper that accepts two\ninput arguments (that will be converted to an array) and an output argument\n(that must be an array). The function returns None and updates the output\narray. Note the updated use of WRITEBACKIFCOPY semantics for NumPy v1.14 and\nabove\n\n"}, {"name": "int PyModule_AddStringConstant()", "path": "user/c-info.how-to-extend#c.PyModule_AddStringConstant", "type": "User Guide", "text": "\nAll three of these functions require the module object (the return value of\nPy_InitModule). The name is a string that labels the value in the module.\nDepending on which function is called, the value argument is either a general\nobject (`PyModule_AddObject` steals a reference to it), an integer constant,\nor a string constant.\n\n"}, {"name": "int PyTypeNum_ISBOOL()", "path": "reference/c-api/array#c.PyTypeNum_ISBOOL", "type": "Array API", "text": "\n\n"}, {"name": "int PyTypeNum_ISCOMPLEX()", "path": "reference/c-api/array#c.PyTypeNum_ISCOMPLEX", "type": "Array API", "text": "\n\n"}, {"name": "int PyTypeNum_ISEXTENDED()", "path": "reference/c-api/array#c.PyTypeNum_ISEXTENDED", "type": "Array API", "text": "\n\n"}, {"name": "int PyTypeNum_ISFLEXIBLE()", "path": "reference/c-api/array#c.PyTypeNum_ISFLEXIBLE", "type": "Array API", "text": "\n\n"}, {"name": "int PyTypeNum_ISFLOAT()", "path": "reference/c-api/array#c.PyTypeNum_ISFLOAT", "type": "Array API", "text": "\n\n"}, {"name": "int PyTypeNum_ISINTEGER()", "path": "reference/c-api/array#c.PyTypeNum_ISINTEGER", "type": "Array API", "text": "\n\n"}, {"name": "int PyTypeNum_ISNUMBER()", "path": "reference/c-api/array#c.PyTypeNum_ISNUMBER", "type": "Array API", "text": "\n\n"}, {"name": "int PyTypeNum_ISOBJECT()", "path": "reference/c-api/array#c.PyTypeNum_ISOBJECT", "type": "Array API", "text": "\n\n"}, {"name": "int PyTypeNum_ISPYTHON()", "path": "reference/c-api/array#c.PyTypeNum_ISPYTHON", "type": "Array API", "text": "\n\n"}, {"name": "int PyTypeNum_ISSIGNED()", "path": "reference/c-api/array#c.PyTypeNum_ISSIGNED", "type": "Array API", "text": "\n\n"}, {"name": "int PyTypeNum_ISSTRING()", "path": "reference/c-api/array#c.PyTypeNum_ISSTRING", "type": "Array API", "text": "\n\n"}, {"name": "int PyTypeNum_ISUSERDEF()", "path": "reference/c-api/array#c.PyTypeNum_ISUSERDEF", "type": "Array API", "text": "\n\n"}, {"name": "int PyUFunc_checkfperr()", "path": "reference/c-api/ufunc#c.PyUFunc_checkfperr", "type": "UFunc API", "text": "\nA simple interface to the IEEE error-flag checking support. The errmask\nargument is a mask of `UFUNC_MASK_{ERR}` bitmasks indicating which errors to\ncheck for (and how to check for them). The errobj must be a Python tuple with\ntwo elements: a string containing the name which will be used in any\ncommunication of error and either a callable Python object (call-back\nfunction) or `Py_None`. The callable object will only be used if\n`UFUNC_ERR_CALL` is set as the desired error checking method. This routine\nmanages the GIL and is safe to call even after releasing the GIL. If an error\nin the IEEE-compatible hardware is determined a -1 is returned, otherwise a 0\nis returned.\n\n"}, {"name": "int PyUFunc_RegisterLoopForDescr()", "path": "reference/c-api/ufunc#c.PyUFunc_RegisterLoopForDescr", "type": "UFunc API", "text": "\nThis function behaves like PyUFunc_RegisterLoopForType above, except that it\nallows the user to register a 1-d loop using PyArray_Descr objects instead of\ndtype type num values. This allows a 1-d loop to be registered for structured\narray data-dtypes and custom data-types instead of scalar data-types.\n\n"}, {"name": "int PyUFunc_RegisterLoopForType()", "path": "reference/c-api/ufunc#c.PyUFunc_RegisterLoopForType", "type": "UFunc API", "text": "\nThis function allows the user to register a 1-d loop with an already- created\nufunc to be used whenever the ufunc is called with any of its input arguments\nas the user-defined data-type. This is needed in order to make ufuncs work\nwith built-in data-types. The data-type must have been previously registered\nwith the numpy system. The loop is passed in as function. This loop can take\narbitrary data which should be passed in as data. The data-types the loop\nrequires are passed in as arg_types which must be a pointer to memory at least\nas large as ufunc->nargs.\n\n"}, {"name": "int PyUFunc_ReplaceLoopBySignature()", "path": "reference/c-api/ufunc#c.PyUFunc_ReplaceLoopBySignature", "type": "UFunc API", "text": "\nReplace a 1-d loop matching the given signature in the already-created ufunc\nwith the new 1-d loop newfunc. Return the old 1-d loop function in oldfunc.\nReturn 0 on success and -1 on failure. This function works only with built-in\ntypes (use `PyUFunc_RegisterLoopForType` for user-defined types). A signature\nis an array of data-type numbers indicating the inputs followed by the outputs\nassumed by the 1-d loop.\n\n"}, {"name": "int random_multivariate_hypergeometric_count()", "path": "reference/random/c-api#c.random_multivariate_hypergeometric_count", "type": "C API for random", "text": "\n\n"}, {"name": "int reserved1", "path": "reference/c-api/types-and-structures#c.PyUFuncObject.reserved1", "type": "Python Types and C-Structures", "text": "\nUnused.\n\n"}, {"name": "int scanfunc()", "path": "reference/c-api/types-and-structures#c.PyArray_ArrFuncs.scanfunc", "type": "Python Types and C-Structures", "text": "\nA pointer to a function that scans (scanf style) one element of the\ncorresponding type from the file descriptor `fd` into the array memory pointed\nto by `ip`. The array is assumed to be behaved. The last argument `arr` is the\narray to be scanned into. Returns number of receiving arguments successfully\nassigned (which may be zero in case a matching failure occurred before the\nfirst receiving argument was assigned), or EOF if input failure occurs before\nthe first receiving argument was assigned. This function should be called\nwithout holding the Python GIL, and has to grab it for error reporting.\n\n"}, {"name": "int setitem()", "path": "reference/c-api/types-and-structures#c.PyArray_ArrFuncs.setitem", "type": "Python Types and C-Structures", "text": "\nA pointer to a function that sets the Python object item into the array, arr,\nat the position pointed to by data . This function deals with \u201cmisbehaved\u201d\narrays. If successful, a zero is returned, otherwise, a negative one is\nreturned (and a Python error set).\n\n"}, {"name": "int sort()", "path": "reference/c-api/types-and-structures#c.PyArray_ArrFuncs.sort", "type": "Python Types and C-Structures", "text": "\nAn array of function pointers to a particular sorting algorithms. A particular\nsorting algorithm is obtained using a key (so far `NPY_QUICKSORT`,\n`NPY_HEAPSORT`, and `NPY_MERGESORT` are defined). These sorts are done in-\nplace assuming contiguous and aligned data.\n\n"}, {"name": "Internal organization of NumPy arrays", "path": "dev/internals", "type": "Development", "text": "\nIt helps to understand a bit about how NumPy arrays are handled under the\ncovers to help understand NumPy better. This section will not go into great\ndetail. Those wishing to understand the full details are requested to refer to\nTravis Oliphant\u2019s book Guide to NumPy.\n\nNumPy arrays consist of two major components: the raw array data (from now on,\nreferred to as the data buffer), and the information about the raw array data.\nThe data buffer is typically what people think of as arrays in C or Fortran, a\ncontiguous (and fixed) block of memory containing fixed-sized data items.\nNumPy also contains a significant set of data that describes how to interpret\nthe data in the data buffer. This extra information contains (among other\nthings):\n\nThis arrangement allows for the very flexible use of arrays. One thing that it\nallows is simple changes to the metadata to change the interpretation of the\narray buffer. Changing the byteorder of the array is a simple change involving\nno rearrangement of the data. The shape of the array can be changed very\neasily without changing anything in the data buffer or any data copying at\nall.\n\nAmong other things that are made possible is one can create a new array\nmetadata object that uses the same data buffer to create a new view of that\ndata buffer that has a different interpretation of the buffer (e.g., different\nshape, offset, byte order, strides, etc) but shares the same data bytes. Many\noperations in NumPy do just this such as slicing. Other operations, such as\ntranspose, don\u2019t move data elements around in the array, but rather change the\ninformation about the shape and strides so that the indexing of the array\nchanges, but the data in the doesn\u2019t move.\n\nTypically these new versions of the array metadata but the same data buffer\nare new views into the data buffer. There is a different `ndarray` object, but\nit uses the same data buffer. This is why it is necessary to force copies\nthrough the use of the `copy` method if one really wants to make a new and\nindependent copy of the data buffer.\n\nNew views into arrays mean the object reference counts for the data buffer\nincrease. Simply doing away with the original array object will not remove the\ndata buffer if other views of it still exist.\n\nSee also\n\nIndexing on ndarrays\n\nWhat is the right way to index multi-dimensional arrays? Before you jump to\nconclusions about the one and true way to index multi-dimensional arrays, it\npays to understand why this is a confusing issue. This section will try to\nexplain in detail how NumPy indexing works and why we adopt the convention we\ndo for images, and when it may be appropriate to adopt other conventions.\n\nThe first thing to understand is that there are two conflicting conventions\nfor indexing 2-dimensional arrays. Matrix notation uses the first index to\nindicate which row is being selected and the second index to indicate which\ncolumn is selected. This is opposite the geometrically oriented-convention for\nimages where people generally think the first index represents x position\n(i.e., column) and the second represents y position (i.e., row). This alone is\nthe source of much confusion; matrix-oriented users and image-oriented users\nexpect two different things with regard to indexing.\n\nThe second issue to understand is how indices correspond to the order in which\nthe array is stored in memory. In Fortran, the first index is the most rapidly\nvarying index when moving through the elements of a two-dimensional array as\nit is stored in memory. If you adopt the matrix convention for indexing, then\nthis means the matrix is stored one column at a time (since the first index\nmoves to the next row as it changes). Thus Fortran is considered a Column-\nmajor language. C has just the opposite convention. In C, the last index\nchanges most rapidly as one moves through the array as stored in memory. Thus\nC is a Row-major language. The matrix is stored by rows. Note that in both\ncases it presumes that the matrix convention for indexing is being used, i.e.,\nfor both Fortran and C, the first index is the row. Note this convention\nimplies that the indexing convention is invariant and that the data order\nchanges to keep that so.\n\nBut that\u2019s not the only way to look at it. Suppose one has large two-\ndimensional arrays (images or matrices) stored in data files. Suppose the data\nare stored by rows rather than by columns. If we are to preserve our index\nconvention (whether matrix or image) that means that depending on the language\nwe use, we may be forced to reorder the data if it is read into memory to\npreserve our indexing convention. For example, if we read row-ordered data\ninto memory without reordering, it will match the matrix indexing convention\nfor C, but not for Fortran. Conversely, it will match the image indexing\nconvention for Fortran, but not for C. For C, if one is using data stored in\nrow order, and one wants to preserve the image index convention, the data must\nbe reordered when reading into memory.\n\nIn the end, what you do for Fortran or C depends on which is more important,\nnot reordering data or preserving the indexing convention. For large images,\nreordering data is potentially expensive, and often the indexing convention is\ninverted to avoid that.\n\nThe situation with NumPy makes this issue yet more complicated. The internal\nmachinery of NumPy arrays is flexible enough to accept any ordering of\nindices. One can simply reorder indices by manipulating the internal stride\ninformation for arrays without reordering the data at all. NumPy will know how\nto map the new index order to the data without moving the data.\n\nSo if this is true, why not choose the index order that matches what you most\nexpect? In particular, why not define row-ordered images to use the image\nconvention? (This is sometimes referred to as the Fortran convention vs the C\nconvention, thus the \u2018C\u2019 and \u2018FORTRAN\u2019 order options for array ordering in\nNumPy.) The drawback of doing this is potential performance penalties. It\u2019s\ncommon to access the data sequentially, either implicitly in array operations\nor explicitly by looping over rows of an image. When that is done, then the\ndata will be accessed in non-optimal order. As the first index is incremented,\nwhat is actually happening is that elements spaced far apart in memory are\nbeing sequentially accessed, with usually poor memory access speeds. For\nexample, for a two-dimensional image `im` defined so that `im[0, 10]`\nrepresents the value at `x = 0`, `y = 10`. To be consistent with usual Python\nbehavior then `im[0]` would represent a column at `x = 0`. Yet that data would\nbe spread over the whole array since the data are stored in row order. Despite\nthe flexibility of NumPy\u2019s indexing, it can\u2019t really paper over the fact basic\noperations are rendered inefficient because of data order or that getting\ncontiguous subarrays is still awkward (e.g., `im[:, 0]` for the first row, vs\n`im[0]`). Thus one can\u2019t use an idiom such as for row in `im`; for col in `im`\ndoes work, but doesn\u2019t yield contiguous column data.\n\nAs it turns out, NumPy is smart enough when dealing with ufuncs to determine\nwhich index is the most rapidly varying one in memory and uses that for the\ninnermost loop. Thus for ufuncs, there is no large intrinsic advantage to\neither approach in most cases. On the other hand, use of `ndarray.flat` with a\nFORTRAN ordered array will lead to non-optimal memory access as adjacent\nelements in the flattened array (iterator, actually) are not contiguous in\nmemory.\n\nIndeed, the fact is that Python indexing on lists and other sequences\nnaturally leads to an outside-to-inside ordering (the first index gets the\nlargest grouping, the next largest, and the last gets the smallest element).\nSince image data are normally stored in rows, this corresponds to the position\nwithin rows being the last item indexed.\n\nIf you do want to use Fortran ordering realize that there are two approaches\nto consider: 1) accept that the first index is just not the most rapidly\nchanging in memory and have all your I/O routines reorder your data when going\nfrom memory to disk or visa versa, or use NumPy\u2019s mechanism for mapping the\nfirst index to the most rapidly varying data. We recommend the former if\npossible. The disadvantage of the latter is that many of NumPy\u2019s functions\nwill yield arrays without Fortran ordering unless you are careful to use the\n`order` keyword. Doing this would be highly inconvenient.\n\nOtherwise, we recommend simply learning to reverse the usual order of indices\nwhen accessing elements of an array. Granted, it goes against the grain, but\nit is more in line with Python semantics and the natural order of the data.\n\n"}, {"name": "Is the intended behavior clear under all conditions? Some things to watch:", "path": "dev/reviewer_guidelines", "type": "Development", "text": "\nReviewing open pull requests (PRs) helps move the project forward. We\nencourage people outside the project to get involved as well; it\u2019s a great way\nto get familiar with the codebase.\n\nReviews can come from outside the NumPy team \u2013 we welcome contributions from\ndomain experts (for instance, `linalg` or `fft`) or maintainers of other\nprojects. You do not need to be a NumPy maintainer (a NumPy team member with\npermission to merge a PR) to review.\n\nIf we do not know you yet, consider introducing yourself in the mailing list\nor Slack before you start reviewing pull requests.\n\nWhen reviewing pull requests, please use workflow tracking features on GitHub\nas appropriate:\n\nIt may be helpful to have a copy of the pull request code checked out on your\nown machine so that you can play with it locally. You can use the GitHub CLI\nto do this by clicking the `Open with` button in the upper right-hand corner\nof the PR page.\n\nAssuming you have your development environment set up, you can now build the\ncode and test it.\n\nIt may be helpful to store some of these in GitHub\u2019s saved replies for\nreviewing:\n\n"}, {"name": "is_array()", "path": "reference/swig.interface-file", "type": "numpy.i: a SWIG Interface File for NumPy", "text": "\nThe Simple Wrapper and Interface Generator (or SWIG) is a powerful tool for\ngenerating wrapper code for interfacing to a wide variety of scripting\nlanguages. SWIG can parse header files, and using only the code prototypes,\ncreate an interface to the target language. But SWIG is not omnipotent. For\nexample, it cannot know from the prototype:\n\nwhat exactly `seq` is. Is it a single value to be altered in-place? Is it an\narray, and if so what is its length? Is it input-only? Output-only? Input-\noutput? SWIG cannot determine these details, and does not attempt to do so.\n\nIf we designed `rms`, we probably made it a routine that takes an input-only\narray of length `n` of `double` values called `seq` and returns the root mean\nsquare. The default behavior of SWIG, however, will be to create a wrapper\nfunction that compiles, but is nearly impossible to use from the scripting\nlanguage in the way the C routine was intended.\n\nFor Python, the preferred way of handling contiguous (or technically, strided)\nblocks of homogeneous data is with NumPy, which provides full object-oriented\naccess to multidimensial arrays of data. Therefore, the most logical Python\ninterface for the `rms` function would be (including doc string):\n\nwhere `seq` would be a NumPy array of `double` values, and its length `n`\nwould be extracted from `seq` internally before being passed to the C routine.\nEven better, since NumPy supports construction of arrays from arbitrary Python\nsequences, `seq` itself could be a nearly arbitrary sequence (so long as each\nelement can be converted to a `double`) and the wrapper code would internally\nconvert it to a NumPy array before extracting its data and length.\n\nSWIG allows these types of conversions to be defined via a mechanism called\ntypemaps. This document provides information on how to use `numpy.i`, a SWIG\ninterface file that defines a series of typemaps intended to make the type of\narray-related conversions described above relatively simple to implement. For\nexample, suppose that the `rms` function prototype defined above was in a\nheader file named `rms.h`. To obtain the Python interface discussed above,\nyour SWIG interface file would need the following:\n\nTypemaps are keyed off a list of one or more function arguments, either by\ntype or by type and name. We will refer to such lists as signatures. One of\nthe many typemaps defined by `numpy.i` is used above and has the signature\n`(double* IN_ARRAY1, int DIM1)`. The argument names are intended to suggest\nthat the `double*` argument is an input array of one dimension and that the\n`int` represents the size of that dimension. This is precisely the pattern in\nthe `rms` prototype.\n\nMost likely, no actual prototypes to be wrapped will have the argument names\n`IN_ARRAY1` and `DIM1`. We use the SWIG `%apply` directive to apply the\ntypemap for one-dimensional input arrays of type `double` to the actual\nprototype used by `rms`. Using `numpy.i` effectively, therefore, requires\nknowing what typemaps are available and what they do.\n\nA SWIG interface file that includes the SWIG directives given above will\nproduce wrapper code that looks something like:\n\nThe typemaps from `numpy.i` are responsible for the following lines of code:\n12\u201320, 25 and 30. Line 10 parses the input to the `rms` function. From the\nformat string `\"O:rms\"`, we can see that the argument list is expected to be a\nsingle Python object (specified by the `O` before the colon) and whose pointer\nis stored in `obj0`. A number of functions, supplied by `numpy.i`, are called\nto make and check the (possible) conversion from a generic Python object to a\nNumPy array. These functions are explained in the section Helper Functions,\nbut hopefully their names are self-explanatory. At line 12 we use `obj0` to\nconstruct a NumPy array. At line 17, we check the validity of the result: that\nit is non-null and that it has a single dimension of arbitrary length. Once\nthese states are verified, we extract the data buffer and length in lines 19\nand 20 so that we can call the underlying C function at line 22. Line 25\nperforms memory management for the case where we have created a new array that\nis no longer needed.\n\nThis code has a significant amount of error handling. Note the `SWIG_fail` is\na macro for `goto fail`, referring to the label at line 28. If the user\nprovides the wrong number of arguments, this will be caught at line 10. If\nconstruction of the NumPy array fails or produces an array with the wrong\nnumber of dimensions, these errors are caught at line 17. And finally, if an\nerror is detected, memory is still managed correctly at line 30.\n\nNote that if the C function signature was in a different order:\n\nthat SWIG would not match the typemap signature given above with the argument\nlist for `rms`. Fortunately, `numpy.i` has a set of typemaps with the data\npointer given last:\n\nThis simply has the effect of switching the definitions of `arg1` and `arg2`\nin lines 3 and 4 of the generated code above, and their assignments in lines\n19 and 20.\n\nThe `numpy.i` file is currently located in the `tools/swig` sub-directory\nunder the `numpy` installation directory. Typically, you will want to copy it\nto the directory where you are developing your wrappers.\n\nA simple module that only uses a single SWIG interface file should include the\nfollowing:\n\nWithin a compiled Python module, `import_array()` should only get called once.\nThis could be in a C/C++ file that you have written and is linked to the\nmodule. If this is the case, then none of your interface files should `#define\nSWIG_FILE_WITH_INIT` or call `import_array()`. Or, this initialization call\ncould be in a wrapper file generated by SWIG from an interface file that has\nthe `%init` block as above. If this is the case, and you have more than one\nSWIG interface file, then only one interface file should `#define\nSWIG_FILE_WITH_INIT` and call `import_array()`.\n\nThe typemap directives provided by `numpy.i` for arrays of different data\ntypes, say `double` and `int`, and dimensions of different types, say `int` or\n`long`, are identical to one another except for the C and NumPy type\nspecifications. The typemaps are therefore implemented (typically behind the\nscenes) via a macro:\n\nthat can be invoked for appropriate `(DATA_TYPE, DATA_TYPECODE, DIM_TYPE)`\ntriplets. For example:\n\nThe `numpy.i` interface file uses the `%numpy_typemaps` macro to implement\ntypemaps for the following C data types and `int` dimension types:\n\nIn the following descriptions, we reference a generic `DATA_TYPE`, which could\nbe any of the C data types listed above, and `DIM_TYPE` which should be one of\nthe many types of integers.\n\nThe typemap signatures are largely differentiated on the name given to the\nbuffer pointer. Names with `FARRAY` are for Fortran-ordered arrays, and names\nwith `ARRAY` are for C-ordered (or 1D arrays).\n\nInput arrays are defined as arrays of data that are passed into a routine but\nare not altered in-place or returned to the user. The Python input array is\ntherefore allowed to be almost any Python sequence (such as a list) that can\nbe converted to the requested type of array. The input array signatures are\n\n1D:\n\n2D:\n\n3D:\n\n4D:\n\nThe first signature listed, `( DATA_TYPE IN_ARRAY[ANY] )` is for one-\ndimensional arrays with hard-coded dimensions. Likewise, `( DATA_TYPE\nIN_ARRAY2[ANY][ANY] )` is for two-dimensional arrays with hard-coded\ndimensions, and similarly for three-dimensional.\n\nIn-place arrays are defined as arrays that are modified in-place. The input\nvalues may or may not be used, but the values at the time the function returns\nare significant. The provided Python argument must therefore be a NumPy array\nof the required type. The in-place signatures are\n\n1D:\n\n2D:\n\n3D:\n\n4D:\n\nThese typemaps now check to make sure that the `INPLACE_ARRAY` arguments use\nnative byte ordering. If not, an exception is raised.\n\nThere is also a \u201cflat\u201d in-place array for situations in which you would like\nto modify or process each element, regardless of the number of dimensions. One\nexample is a \u201cquantization\u201d function that quantizes each element of an array\nin-place, be it 1D, 2D or whatever. This form checks for continuity but allows\neither C or Fortran ordering.\n\nND:\n\nArgout arrays are arrays that appear in the input arguments in C, but are in\nfact output arrays. This pattern occurs often when there is more than one\noutput variable and the single return argument is therefore not sufficient. In\nPython, the conventional way to return multiple arguments is to pack them into\na sequence (tuple, list, etc.) and return the sequence. This is what the\nargout typemaps do. If a wrapped function that uses these argout typemaps has\nmore than one return argument, they are packed into a tuple or list, depending\non the version of Python. The Python user does not pass these arrays in, they\nsimply get returned. For the case where a dimension is specified, the python\nuser must provide that dimension as an argument. The argout signatures are\n\n1D:\n\n2D:\n\n3D:\n\n4D:\n\nThese are typically used in situations where in C/C++, you would allocate a(n)\narray(s) on the heap, and call the function to fill the array(s) values. In\nPython, the arrays are allocated for you and returned as new array objects.\n\nNote that we support `DATA_TYPE*` argout typemaps in 1D, but not 2D or 3D.\nThis is because of a quirk with the SWIG typemap syntax and cannot be avoided.\nNote that for these types of 1D typemaps, the Python function will take a\nsingle argument representing `DIM1`.\n\nArgoutview arrays are for when your C code provides you with a view of its\ninternal data and does not require any memory to be allocated by the user.\nThis can be dangerous. There is almost no way to guarantee that the internal\ndata from the C code will remain in existence for the entire lifetime of the\nNumPy array that encapsulates it. If the user destroys the object that\nprovides the view of the data before destroying the NumPy array, then using\nthat array may result in bad memory references or segmentation faults.\nNevertheless, there are situations, working with large data sets, where you\nsimply have no other choice.\n\nThe C code to be wrapped for argoutview arrays are characterized by pointers:\npointers to the dimensions and double pointers to the data, so that these\nvalues can be passed back to the user. The argoutview typemap signatures are\ntherefore\n\n1D:\n\n2D:\n\n3D:\n\n4D:\n\nNote that arrays with hard-coded dimensions are not supported. These cannot\nfollow the double pointer signatures of these typemaps.\n\nA recent addition to `numpy.i` are typemaps that permit argout arrays with\nviews into memory that is managed. See the discussion here.\n\n1D:\n\n2D:\n\n3D:\n\n4D:\n\nThe `numpy.i` interface file does not support typemaps for output arrays, for\nseveral reasons. First, C/C++ return arguments are limited to a single value.\nThis prevents obtaining dimension information in a general way. Second, arrays\nwith hard-coded lengths are not permitted as return arguments. In other words:\n\nis not legal C/C++ syntax. Therefore, we cannot provide typemaps of the form:\n\nIf you run into a situation where a function or method is returning a pointer\nto an array, your best bet is to write your own version of the function to be\nwrapped, either with `%extend` for the case of class methods or `%ignore` and\n`%rename` for the case of functions.\n\nNote that C++ type `bool` is not supported in the list in the Available\nTypemaps section. NumPy bools are a single byte, while the C++ `bool` is four\nbytes (at least on my system). Therefore:\n\nwill result in typemaps that will produce code that reference improper data\nlengths. You can implement the following macro expansion:\n\nto fix the data length problem, and Input Arrays will work fine, but In-Place\nArrays might fail type-checking.\n\nTypemap conversions for complex floating-point types is also not supported\nautomatically. This is because Python and NumPy are written in C, which does\nnot have native complex types. Both Python and NumPy implement their own\n(essentially equivalent) `struct` definitions for complex variables:\n\nWe could have implemented:\n\nwhich would have provided automatic type conversions for arrays of type\n`Py_complex`, `npy_cfloat` and `npy_cdouble`. However, it seemed unlikely that\nthere would be any independent (non-Python, non-NumPy) application code that\npeople would be using SWIG to generate a Python interface to, that also used\nthese definitions for complex types. More likely, these application codes will\ndefine their own complex types, or in the case of C++, use `std::complex`.\nAssuming these data structures are compatible with Python and NumPy complex\ntypes, `%numpy_typemap` expansions as above (with the user\u2019s complex type\nsubstituted for the first argument) should work.\n\nSWIG has sophisticated type checking for numerical types. For example, if your\nC/C++ routine expects an integer as input, the code generated by SWIG will\ncheck for both Python integers and Python long integers, and raise an overflow\nerror if the provided Python integer is too big to cast down to a C integer.\nWith the introduction of NumPy scalar arrays into your Python code, you might\nconceivably extract an integer from a NumPy array and attempt to pass this to\na SWIG-wrapped C/C++ function that expects an `int`, but the SWIG type\nchecking will not recognize the NumPy array scalar as an integer. (Often, this\ndoes in fact work \u2013 it depends on whether NumPy recognizes the integer type\nyou are using as inheriting from the Python integer type on the platform you\nare using. Sometimes, this means that code that works on a 32-bit machine will\nfail on a 64-bit machine.)\n\nIf you get a Python error that looks like the following:\n\nand the argument you are passing is an integer extracted from a NumPy array,\nthen you have stumbled upon this problem. The solution is to modify the SWIG\ntype conversion system to accept NumPy array scalars in addition to the\nstandard integer types. Fortunately, this capability has been provided for\nyou. Simply copy the file:\n\nto the working build directory for you project, and this problem will be\nfixed. It is suggested that you do this anyway, as it only increases the\ncapabilities of your Python interface.\n\nThe SWIG type checking and conversion system is a complicated combination of C\nmacros, SWIG macros, SWIG typemaps and SWIG fragments. Fragments are a way to\nconditionally insert code into your wrapper file if it is needed, and not\ninsert it if not needed. If multiple typemaps require the same fragment, the\nfragment only gets inserted into your wrapper code once.\n\nThere is a fragment for converting a Python integer to a C `long`. There is a\ndifferent fragment that converts a Python integer to a C `int`, that calls the\nroutine defined in the `long` fragment. We can make the changes we want here\nby changing the definition for the `long` fragment. SWIG determines the active\ndefinition for a fragment using a \u201cfirst come, first served\u201d system. That is,\nwe need to define the fragment for `long` conversions prior to SWIG doing it\ninternally. SWIG allows us to do this by putting our fragment definitions in\nthe file `pyfragments.swg`. If we were to put the new fragment definitions in\n`numpy.i`, they would be ignored.\n\nThe `numpy.i` file contains several macros and routines that it uses\ninternally to build its typemaps. However, these functions may be useful\nelsewhere in your interface file. These macros and routines are implemented as\nfragments, which are described briefly in the previous section. If you try to\nuse one or more of the following macros or functions, but your compiler\ncomplains that it does not recognize the symbol, then you need to force these\nfragments to appear in your code using:\n\nin your SWIG interface file.\n\nEvaluates as true if `a` is non-`NULL` and can be cast to a `PyArrayObject*`.\n\nEvaluates to the integer data type code of `a`, assuming `a` can be cast to a\n`PyArrayObject*`.\n\nEvaluates to the integer number of dimensions of `a`, assuming `a` can be cast\nto a `PyArrayObject*`.\n\nEvaluates to an array of type `npy_intp` and length `array_numdims(a)`, giving\nthe lengths of all of the dimensions of `a`, assuming `a` can be cast to a\n`PyArrayObject*`.\n\nEvaluates to the `i`-th dimension size of `a`, assuming `a` can be cast to a\n`PyArrayObject*`.\n\nEvaluates to an array of type `npy_intp` and length `array_numdims(a)`, giving\nthe stridess of all of the dimensions of `a`, assuming `a` can be cast to a\n`PyArrayObject*`. A stride is the distance in bytes between an element and its\nimmediate neighbor along the same axis.\n\nEvaluates to the `i`-th stride of `a`, assuming `a` can be cast to a\n`PyArrayObject*`.\n\nEvaluates to a pointer of type `void*` that points to the data buffer of `a`,\nassuming `a` can be cast to a `PyArrayObject*`.\n\nReturns a borrowed reference to the dtype property (`PyArray_Descr*`) of `a`,\nassuming `a` can be cast to a `PyArrayObject*`.\n\nReturns an integer representing the flags of `a`, assuming `a` can be cast to\na `PyArrayObject*`.\n\nSets the flag represented by `f` of `a`, assuming `a` can be cast to a\n`PyArrayObject*`.\n\nEvaluates as true if `a` is a contiguous array. Equivalent to\n`(PyArray_ISCONTIGUOUS(a))`.\n\nEvaluates as true if the data buffer of `a` uses native byte order. Equivalent\nto `(PyArray_ISNOTSWAPPED(a))`.\n\nEvaluates as true if `a` is FORTRAN ordered.\n\npytype_string()\n\nReturn type: `const char*`\n\nArguments:\n\nReturn a string describing the type of `py_obj`.\n\ntypecode_string()\n\nReturn type: `const char*`\n\nArguments:\n\nReturn a string describing the type corresponding to the NumPy `typecode`.\n\ntype_match()\n\nReturn type: `int`\n\nArguments:\n\nMake sure that `actual_type` is compatible with `desired_type`. For example,\nthis allows character and byte types, or int and long types, to match. This is\nnow equivalent to `PyArray_EquivTypenums()`.\n\nobj_to_array_no_conversion()\n\nReturn type: `PyArrayObject*`\n\nArguments:\n\nCast `input` to a `PyArrayObject*` if legal, and ensure that it is of type\n`typecode`. If `input` cannot be cast, or the `typecode` is wrong, set a\nPython error and return `NULL`.\n\nobj_to_array_allow_conversion()\n\nReturn type: `PyArrayObject*`\n\nArguments:\n\nConvert `input` to a NumPy array with the given `typecode`. On success, return\na valid `PyArrayObject*` with the correct type. On failure, the Python error\nstring will be set and the routine returns `NULL`.\n\nmake_contiguous()\n\nReturn type: `PyArrayObject*`\n\nArguments:\n\nCheck to see if `ary` is contiguous. If so, return the input pointer and flag\nit as not a new object. If it is not contiguous, create a new `PyArrayObject*`\nusing the original data, flag it as a new object and return the pointer.\n\nmake_fortran()\n\nReturn type: `PyArrayObject*`\n\nArguments\n\nCheck to see if `ary` is Fortran contiguous. If so, return the input pointer\nand flag it as not a new object. If it is not Fortran contiguous, create a new\n`PyArrayObject*` using the original data, flag it as a new object and return\nthe pointer.\n\nobj_to_array_contiguous_allow_conversion()\n\nReturn type: `PyArrayObject*`\n\nArguments:\n\nConvert `input` to a contiguous `PyArrayObject*` of the specified type. If the\ninput object is not a contiguous `PyArrayObject*`, a new one will be created\nand the new object flag will be set.\n\nobj_to_array_fortran_allow_conversion()\n\nReturn type: `PyArrayObject*`\n\nArguments:\n\nConvert `input` to a Fortran contiguous `PyArrayObject*` of the specified\ntype. If the input object is not a Fortran contiguous `PyArrayObject*`, a new\none will be created and the new object flag will be set.\n\nrequire_contiguous()\n\nReturn type: `int`\n\nArguments:\n\nTest whether `ary` is contiguous. If so, return 1. Otherwise, set a Python\nerror and return 0.\n\nrequire_native()\n\nReturn type: `int`\n\nArguments:\n\nRequire that `ary` is not byte-swapped. If the array is not byte-swapped,\nreturn 1. Otherwise, set a Python error and return 0.\n\nrequire_dimensions()\n\nReturn type: `int`\n\nArguments:\n\nRequire `ary` to have a specified number of dimensions. If the array has the\nspecified number of dimensions, return 1. Otherwise, set a Python error and\nreturn 0.\n\nrequire_dimensions_n()\n\nReturn type: `int`\n\nArguments:\n\nRequire `ary` to have one of a list of specified number of dimensions. If the\narray has one of the specified number of dimensions, return 1. Otherwise, set\nthe Python error string and return 0.\n\nrequire_size()\n\nReturn type: `int`\n\nArguments:\n\nRequire `ary` to have a specified shape. If the array has the specified shape,\nreturn 1. Otherwise, set the Python error string and return 0.\n\nrequire_fortran()\n\nReturn type: `int`\n\nArguments:\n\nRequire the given `PyArrayObject` to to be Fortran ordered. If the\n`PyArrayObject` is already Fortran ordered, do nothing. Else, set the Fortran\nordering flag and recompute the strides.\n\nThere are many C or C++ array/NumPy array situations not covered by a simple\n`%include \"numpy.i\"` and subsequent `%apply` directives.\n\nConsider a reasonable prototype for a dot product function:\n\nThe Python interface that we want is:\n\nThe problem here is that there is one dimension argument and two array\narguments, and our typemaps are set up for dimensions that apply to a single\narray (in fact, SWIG does not provide a mechanism for associating `len` with\n`vec2` that takes two Python input arguments). The recommended solution is the\nfollowing:\n\nIf the header file that contains the prototype for `double dot()` also\ncontains other prototypes that you want to wrap, so that you need to\n`%include` this header file, then you will also need a `%ignore dot;`\ndirective, placed after the `%rename` and before the `%include` directives.\nOr, if the function in question is a class method, you will want to use\n`%extend` rather than `%inline` in addition to `%ignore`.\n\nA note on error handling: Note that `my_dot` returns a `double` but that it\ncan also raise a Python error. The resulting wrapper function will return a\nPython float representation of 0.0 when the vector lengths do not match. Since\nthis is not `NULL`, the Python interpreter will not know to check for an\nerror. For this reason, we add the `%exception` directive above for `my_dot`\nto get the behavior we want (note that `$action` is a macro that gets expanded\nto a valid call to `my_dot`). In general, you will probably want to write a\nSWIG macro to perform this task.\n\nThere are other wrapping situations in which `numpy.i` may be helpful when you\nencounter them.\n\nIn some situations, it is possible that you could use the `%numpy_typemaps`\nmacro to implement typemaps for your own types. See the Other Common Types:\nbool or Other Common Types: complex sections for examples. Another situation\nis if your dimensions are of a type other than `int` (say `long` for example):\n\nWhen you use the `%apply` directive, as is usually necessary to use `numpy.i`,\nit will remain in effect until you tell SWIG that it shouldn\u2019t be. If the\narguments to the functions or methods that you are wrapping have common names,\nsuch as `length` or `vector`, these typemaps may get applied in situations you\ndo not expect or want. Therefore, it is always a good idea to add a `%clear`\ndirective after you are done with a specific typemap:\n\nIn general, you should target these typemap signatures specifically where you\nwant them, and then clear them after you are done.\n\nOut of the box, `numpy.i` provides typemaps that support conversion between\nNumPy arrays and C arrays:\n\nThat support 74 different argument signatures for each data type, including:\n\nThe `numpy.i` interface file also provides additional tools for wrapper\ndevelopers, including:\n\n"}, {"name": "Iterating Over Arrays", "path": "reference/arrays.nditer", "type": "Iterating Over Arrays", "text": "\nNote\n\nArrays support the iterator protocol and can be iterated over like Python\nlists. See the Indexing, Slicing and Iterating section in the Quickstart guide\nfor basic usage and examples. The remainder of this document presents the\n`nditer` object and covers more advanced usage.\n\nThe iterator object `nditer`, introduced in NumPy 1.6, provides many flexible\nways to visit all the elements of one or more arrays in a systematic fashion.\nThis page introduces some basic ways to use the object for computations on\narrays in Python, then concludes with how one can accelerate the inner loop in\nCython. Since the Python exposure of `nditer` is a relatively straightforward\nmapping of the C array iterator API, these ideas will also provide help\nworking with array iteration from C or C++.\n\nThe most basic task that can be done with the `nditer` is to visit every\nelement of an array. Each element is provided one by one using the standard\nPython iterator interface.\n\nAn important thing to be aware of for this iteration is that the order is\nchosen to match the memory layout of the array instead of using a standard C\nor Fortran ordering. This is done for access efficiency, reflecting the idea\nthat by default one simply wants to visit each element without concern for a\nparticular ordering. We can see this by iterating over the transpose of our\nprevious array, compared to taking a copy of that transpose in C order.\n\nThe elements of both `a` and `a.T` get traversed in the same order, namely the\norder they are stored in memory, whereas the elements of `a.T.copy(order=\u2019C\u2019)`\nget visited in a different order because they have been put into a different\nmemory layout.\n\nThere are times when it is important to visit the elements of an array in a\nspecific order, irrespective of the layout of the elements in memory. The\n`nditer` object provides an `order` parameter to control this aspect of\niteration. The default, having the behavior described above, is order=\u2019K\u2019 to\nkeep the existing order. This can be overridden with order=\u2019C\u2019 for C order and\norder=\u2019F\u2019 for Fortran order.\n\nBy default, the `nditer` treats the input operand as a read-only object. To be\nable to modify the array elements, you must specify either read-write or\nwrite-only mode using the `\u2018readwrite\u2019` or `\u2018writeonly\u2019` per-operand flags.\n\nThe nditer will then yield writeable buffer arrays which you may modify.\nHowever, because the nditer must copy this buffer data back to the original\narray once iteration is finished, you must signal when the iteration is ended,\nby one of two methods. You may either:\n\nThe nditer can no longer be iterated once either `close` is called or its\ncontext is exited.\n\nIf you are writing code that needs to support older versions of numpy, note\nthat prior to 1.15, `nditer` was not a context manager and did not have a\n`close` method. Instead it relied on the destructor to initiate the writeback\nof the buffer.\n\nIn all the examples so far, the elements of `a` are provided by the iterator\none at a time, because all the looping logic is internal to the iterator.\nWhile this is simple and convenient, it is not very efficient. A better\napproach is to move the one-dimensional innermost loop into your code,\nexternal to the iterator. This way, NumPy\u2019s vectorized operations can be used\non larger chunks of the elements being visited.\n\nThe `nditer` will try to provide chunks that are as large as possible to the\ninner loop. By forcing \u2018C\u2019 and \u2018F\u2019 order, we get different external loop\nsizes. This mode is enabled by specifying an iterator flag.\n\nObserve that with the default of keeping native memory order, the iterator is\nable to provide a single one-dimensional chunk, whereas when forcing Fortran\norder, it has to provide three chunks of two elements each.\n\nDuring iteration, you may want to use the index of the current element in a\ncomputation. For example, you may want to visit the elements of an array in\nmemory order, but use a C-order, Fortran-order, or multidimensional index to\nlook up values in a different array.\n\nThe index is tracked by the iterator object itself, and accessible through the\n`index` or `multi_index` properties, depending on what was requested. The\nexamples below show printouts demonstrating the progression of the index:\n\nTracking an index or multi-index is incompatible with using an external loop,\nbecause it requires a different index value per element. If you try to combine\nthese flags, the `nditer` object will raise an exception.\n\nTo make its properties more readily accessible during iteration, `nditer` has\nan alternative syntax for iterating, which works explicitly with the iterator\nobject itself. With this looping construct, the current value is accessible by\nindexing into the iterator. Other properties, such as tracked indices remain\nas before. The examples below produce identical results to the ones in the\nprevious section.\n\nWhen forcing an iteration order, we observed that the external loop option may\nprovide the elements in smaller chunks because the elements can\u2019t be visited\nin the appropriate order with a constant stride. When writing C code, this is\ngenerally fine, however in pure Python code this can cause a significant\nreduction in performance.\n\nBy enabling buffering mode, the chunks provided by the iterator to the inner\nloop can be made larger, significantly reducing the overhead of the Python\ninterpreter. In the example forcing Fortran iteration order, the inner loop\ngets to see all the elements in one go when buffering is enabled.\n\nThere are times when it is necessary to treat an array as a different data\ntype than it is stored as. For instance, one may want to do all computations\non 64-bit floats, even if the arrays being manipulated are 32-bit floats.\nExcept when writing low-level C code, it\u2019s generally better to let the\niterator handle the copying or buffering instead of casting the data type\nyourself in the inner loop.\n\nThere are two mechanisms which allow this to be done, temporary copies and\nbuffering mode. With temporary copies, a copy of the entire array is made with\nthe new data type, then iteration is done in the copy. Write access is\npermitted through a mode which updates the original array after all the\niteration is complete. The major drawback of temporary copies is that the\ntemporary copy may consume a large amount of memory, particularly if the\niteration data type has a larger itemsize than the original one.\n\nBuffering mode mitigates the memory usage issue and is more cache-friendly\nthan making temporary copies. Except for special cases, where the whole array\nis needed at once outside the iterator, buffering is recommended over\ntemporary copying. Within NumPy, buffering is used by the ufuncs and other\nfunctions to support flexible inputs with minimal memory overhead.\n\nIn our examples, we will treat the input array with a complex data type, so\nthat we can take square roots of negative numbers. Without enabling copies or\nbuffering mode, the iterator will raise an exception if the data type doesn\u2019t\nmatch precisely.\n\nIn copying mode, \u2018copy\u2019 is specified as a per-operand flag. This is done to\nprovide control in a per-operand fashion. Buffering mode is specified as an\niterator flag.\n\nThe iterator uses NumPy\u2019s casting rules to determine whether a specific\nconversion is permitted. By default, it enforces \u2018safe\u2019 casting. This means,\nfor example, that it will raise an exception if you try to treat a 64-bit\nfloat array as a 32-bit float array. In many cases, the rule \u2018same_kind\u2019 is\nthe most reasonable rule to use, since it will allow conversion from 64 to\n32-bit float, but not from float to int or from complex to float.\n\nOne thing to watch out for is conversions back to the original data type when\nusing a read-write or write-only operand. A common case is to implement the\ninner loop in terms of 64-bit floats, and use \u2018same_kind\u2019 casting to allow the\nother floating-point types to be processed as well. While in read-only mode,\nan integer array could be provided, read-write mode will raise an exception\nbecause conversion back to the array would violate the casting rule.\n\nNumPy has a set of rules for dealing with arrays that have differing shapes\nwhich are applied whenever functions take multiple operands which combine\nelement-wise. This is called broadcasting. The `nditer` object can apply these\nrules for you when you need to write such a function.\n\nAs an example, we print out the result of broadcasting a one and a two\ndimensional array together.\n\nWhen a broadcasting error occurs, the iterator raises an exception which\nincludes the input shapes to help diagnose the problem.\n\nA common case in NumPy functions is to have outputs allocated based on the\nbroadcasting of the input, and additionally have an optional parameter called\n\u2018out\u2019 where the result will be placed when it is provided. The `nditer` object\nprovides a convenient idiom that makes it very easy to support this mechanism.\n\nWe\u2019ll show how this works by creating a function `square` which squares its\ninput. Let\u2019s start with a minimal function definition excluding \u2018out\u2019\nparameter support.\n\nBy default, the `nditer` uses the flags \u2018allocate\u2019 and \u2018writeonly\u2019 for\noperands that are passed in as None. This means we were able to provide just\nthe two operands to the iterator, and it handled the rest.\n\nWhen adding the \u2018out\u2019 parameter, we have to explicitly provide those flags,\nbecause if someone passes in an array as \u2018out\u2019, the iterator will default to\n\u2018readonly\u2019, and our inner loop would fail. The reason \u2018readonly\u2019 is the\ndefault for input arrays is to prevent confusion about unintentionally\ntriggering a reduction operation. If the default were \u2018readwrite\u2019, any\nbroadcasting operation would also trigger a reduction, a topic which is\ncovered later in this document.\n\nWhile we\u2019re at it, let\u2019s also introduce the \u2018no_broadcast\u2019 flag, which will\nprevent the output from being broadcast. This is important, because we only\nwant one input value for each output. Aggregating more than one input value is\na reduction operation which requires special handling. It would already raise\nan error because reductions must be explicitly enabled in an iterator flag,\nbut the error message that results from disabling broadcasting is much more\nunderstandable for end-users. To see how to generalize the square function to\na reduction, look at the sum of squares function in the section about Cython.\n\nFor completeness, we\u2019ll also add the \u2018external_loop\u2019 and \u2018buffered\u2019 flags, as\nthese are what you will typically want for performance reasons.\n\nAny binary operation can be extended to an array operation in an outer product\nfashion like in `outer`, and the `nditer` object provides a way to accomplish\nthis by explicitly mapping the axes of the operands. It is also possible to do\nthis with `newaxis` indexing, but we will show you how to directly use the\nnditer `op_axes` parameter to accomplish this with no intermediate views.\n\nWe\u2019ll do a simple outer product, placing the dimensions of the first operand\nbefore the dimensions of the second operand. The `op_axes` parameter needs one\nlist of axes for each operand, and provides a mapping from the iterator\u2019s axes\nto the axes of the operand.\n\nSuppose the first operand is one dimensional and the second operand is two\ndimensional. The iterator will have three dimensions, so `op_axes` will have\ntwo 3-element lists. The first list picks out the one axis of the first\noperand, and is -1 for the rest of the iterator axes, with a final result of\n[0, -1, -1]. The second list picks out the two axes of the second operand, but\nshouldn\u2019t overlap with the axes picked out in the first operand. Its list is\n[-1, 0, 1]. The output operand maps onto the iterator axes in the standard\nmanner, so we can provide None instead of constructing another list.\n\nThe operation in the inner loop is a straightforward multiplication.\nEverything to do with the outer product is handled by the iterator setup.\n\nNote that once the iterator is closed we can not access `operands` and must\nuse a reference created inside the context manager.\n\nWhenever a writeable operand has fewer elements than the full iteration space,\nthat operand is undergoing a reduction. The `nditer` object requires that any\nreduction operand be flagged as read-write, and only allows reductions when\n\u2018reduce_ok\u2019 is provided as an iterator flag.\n\nFor a simple example, consider taking the sum of all elements in an array.\n\nThings are a little bit more tricky when combining reduction and allocated\noperands. Before iteration is started, any reduction operand must be\ninitialized to its starting values. Here\u2019s how we can do this, taking sums\nalong the last axis of `a`.\n\nTo do buffered reduction requires yet another adjustment during the setup.\nNormally the iterator construction involves copying the first buffer of data\nfrom the readable arrays into the buffer. Any reduction operand is readable,\nso it may be read into a buffer. Unfortunately, initialization of the operand\nafter this buffering operation is complete will not be reflected in the buffer\nthat the iteration starts with, and garbage results will be produced.\n\nThe iterator flag \u201cdelay_bufalloc\u201d is there to allow iterator-allocated\nreduction operands to exist together with buffering. When this flag is set,\nthe iterator will leave its buffers uninitialized until it receives a reset,\nafter which it will be ready for regular iteration. Here\u2019s how the previous\nexample looks if we also enable buffering.\n\nThose who want really good performance out of their low level operations\nshould strongly consider directly using the iteration API provided in C, but\nfor those who are not comfortable with C or C++, Cython is a good middle\nground with reasonable performance tradeoffs. For the `nditer` object, this\nmeans letting the iterator take care of broadcasting, dtype conversion, and\nbuffering, while giving the inner loop to Cython.\n\nFor our example, we\u2019ll create a sum of squares function. To start, let\u2019s\nimplement this function in straightforward Python. We want to support an\n\u2018axis\u2019 parameter similar to the numpy `sum` function, so we will need to\nconstruct a list for the `op_axes` parameter. Here\u2019s how this looks.\n\nTo Cython-ize this function, we replace the inner loop (y[\u2026] += x*x) with\nCython code that\u2019s specialized for the float64 dtype. With the \u2018external_loop\u2019\nflag enabled, the arrays provided to the inner loop will always be one-\ndimensional, so very little checking needs to be done.\n\nHere\u2019s the listing of sum_squares.pyx:\n\nOn this machine, building the .pyx file into a module looked like the\nfollowing, but you may have to find some Cython tutorials to tell you the\nspecifics for your system configuration.:\n\nRunning this from the Python interpreter produces the same answers as our\nnative Python/NumPy code did.\n\nDoing a little timing in IPython shows that the reduced overhead and memory\nallocation of the Cython inner loop is providing a very nice speedup over both\nthe straightforward Python code and an expression using NumPy\u2019s built-in sum\nfunction.:\n\n"}, {"name": "Laguerre Series (numpy.polynomial.laguerre)", "path": "reference/routines.polynomials.laguerre", "type": "Laguerre Series ( \n        \n         numpy.polynomial.laguerre\n        \n        )", "text": "\nThis module provides a number of objects (mostly functions) useful for dealing\nwith Laguerre series, including a `Laguerre` class that encapsulates the usual\narithmetic operations. (General information on how this module represents and\nworks with such polynomials is in the docstring for its \u201cparent\u201d sub-package,\n`numpy.polynomial`).\n\n`Laguerre`(coef[, domain, window])\n\nA Laguerre series class.\n\n`lagdomain`\n\nAn array object represents a multidimensional, homogeneous array of fixed-size\nitems.\n\n`lagzero`\n\nAn array object represents a multidimensional, homogeneous array of fixed-size\nitems.\n\n`lagone`\n\nAn array object represents a multidimensional, homogeneous array of fixed-size\nitems.\n\n`lagx`\n\nAn array object represents a multidimensional, homogeneous array of fixed-size\nitems.\n\n`lagadd`(c1, c2)\n\nAdd one Laguerre series to another.\n\n`lagsub`(c1, c2)\n\nSubtract one Laguerre series from another.\n\n`lagmulx`(c)\n\nMultiply a Laguerre series by x.\n\n`lagmul`(c1, c2)\n\nMultiply one Laguerre series by another.\n\n`lagdiv`(c1, c2)\n\nDivide one Laguerre series by another.\n\n`lagpow`(c, pow[, maxpower])\n\nRaise a Laguerre series to a power.\n\n`lagval`(x, c[, tensor])\n\nEvaluate a Laguerre series at points x.\n\n`lagval2d`(x, y, c)\n\nEvaluate a 2-D Laguerre series at points (x, y).\n\n`lagval3d`(x, y, z, c)\n\nEvaluate a 3-D Laguerre series at points (x, y, z).\n\n`laggrid2d`(x, y, c)\n\nEvaluate a 2-D Laguerre series on the Cartesian product of x and y.\n\n`laggrid3d`(x, y, z, c)\n\nEvaluate a 3-D Laguerre series on the Cartesian product of x, y, and z.\n\n`lagder`(c[, m, scl, axis])\n\nDifferentiate a Laguerre series.\n\n`lagint`(c[, m, k, lbnd, scl, axis])\n\nIntegrate a Laguerre series.\n\n`lagfromroots`(roots)\n\nGenerate a Laguerre series with given roots.\n\n`lagroots`(c)\n\nCompute the roots of a Laguerre series.\n\n`lagvander`(x, deg)\n\nPseudo-Vandermonde matrix of given degree.\n\n`lagvander2d`(x, y, deg)\n\nPseudo-Vandermonde matrix of given degrees.\n\n`lagvander3d`(x, y, z, deg)\n\nPseudo-Vandermonde matrix of given degrees.\n\n`laggauss`(deg)\n\nGauss-Laguerre quadrature.\n\n`lagweight`(x)\n\nWeight function of the Laguerre polynomials.\n\n`lagcompanion`(c)\n\nReturn the companion matrix of c.\n\n`lagfit`(x, y, deg[, rcond, full, w])\n\nLeast squares fit of Laguerre series to data.\n\n`lagtrim`(c[, tol])\n\nRemove \"small\" \"trailing\" coefficients from a polynomial.\n\n`lagline`(off, scl)\n\nLaguerre series whose graph is a straight line.\n\n`lag2poly`(c)\n\nConvert a Laguerre series to a polynomial.\n\n`poly2lag`(pol)\n\nConvert a polynomial to a Laguerre series.\n\n`numpy.polynomial`\n\n"}, {"name": "Legendre Series (numpy.polynomial.legendre)", "path": "reference/routines.polynomials.legendre", "type": "Legendre Series ( \n        \n         numpy.polynomial.legendre\n        \n        )", "text": "\nThis module provides a number of objects (mostly functions) useful for dealing\nwith Legendre series, including a `Legendre` class that encapsulates the usual\narithmetic operations. (General information on how this module represents and\nworks with such polynomials is in the docstring for its \u201cparent\u201d sub-package,\n`numpy.polynomial`).\n\n`Legendre`(coef[, domain, window])\n\nA Legendre series class.\n\n`legdomain`\n\nAn array object represents a multidimensional, homogeneous array of fixed-size\nitems.\n\n`legzero`\n\nAn array object represents a multidimensional, homogeneous array of fixed-size\nitems.\n\n`legone`\n\nAn array object represents a multidimensional, homogeneous array of fixed-size\nitems.\n\n`legx`\n\nAn array object represents a multidimensional, homogeneous array of fixed-size\nitems.\n\n`legadd`(c1, c2)\n\nAdd one Legendre series to another.\n\n`legsub`(c1, c2)\n\nSubtract one Legendre series from another.\n\n`legmulx`(c)\n\nMultiply a Legendre series by x.\n\n`legmul`(c1, c2)\n\nMultiply one Legendre series by another.\n\n`legdiv`(c1, c2)\n\nDivide one Legendre series by another.\n\n`legpow`(c, pow[, maxpower])\n\nRaise a Legendre series to a power.\n\n`legval`(x, c[, tensor])\n\nEvaluate a Legendre series at points x.\n\n`legval2d`(x, y, c)\n\nEvaluate a 2-D Legendre series at points (x, y).\n\n`legval3d`(x, y, z, c)\n\nEvaluate a 3-D Legendre series at points (x, y, z).\n\n`leggrid2d`(x, y, c)\n\nEvaluate a 2-D Legendre series on the Cartesian product of x and y.\n\n`leggrid3d`(x, y, z, c)\n\nEvaluate a 3-D Legendre series on the Cartesian product of x, y, and z.\n\n`legder`(c[, m, scl, axis])\n\nDifferentiate a Legendre series.\n\n`legint`(c[, m, k, lbnd, scl, axis])\n\nIntegrate a Legendre series.\n\n`legfromroots`(roots)\n\nGenerate a Legendre series with given roots.\n\n`legroots`(c)\n\nCompute the roots of a Legendre series.\n\n`legvander`(x, deg)\n\nPseudo-Vandermonde matrix of given degree.\n\n`legvander2d`(x, y, deg)\n\nPseudo-Vandermonde matrix of given degrees.\n\n`legvander3d`(x, y, z, deg)\n\nPseudo-Vandermonde matrix of given degrees.\n\n`leggauss`(deg)\n\nGauss-Legendre quadrature.\n\n`legweight`(x)\n\nWeight function of the Legendre polynomials.\n\n`legcompanion`(c)\n\nReturn the scaled companion matrix of c.\n\n`legfit`(x, y, deg[, rcond, full, w])\n\nLeast squares fit of Legendre series to data.\n\n`legtrim`(c[, tol])\n\nRemove \"small\" \"trailing\" coefficients from a polynomial.\n\n`legline`(off, scl)\n\nLegendre series whose graph is a straight line.\n\n`leg2poly`(c)\n\nConvert a Legendre series to a polynomial.\n\n`poly2leg`(pol)\n\nConvert a polynomial to a Legendre series.\n\nnumpy.polynomial\n\n"}, {"name": "lib.format.descr_to_dtype()", "path": "reference/generated/numpy.lib.format.descr_to_dtype", "type": "numpy.lib.format.descr_to_dtype", "text": "\nReturns a dtype based off the given description.\n\nThis is essentially the reverse of `dtype_to_descr()`. It will remove the\nvalueless padding fields created by, i.e. simple fields like dtype(\u2018float32\u2019),\nand then convert the description to its corresponding dtype.\n\nThe object retrieved by dtype.descr. Can be passed to `numpy.dtype()` in order\nto replicate the input dtype.\n\nThe dtype constructed by the description.\n\n"}, {"name": "lib.format.dtype_to_descr()", "path": "reference/generated/numpy.lib.format.dtype_to_descr", "type": "numpy.lib.format.dtype_to_descr", "text": "\nGet a serializable descriptor from the dtype.\n\nThe .descr attribute of a dtype object cannot be round-tripped through the\ndtype() constructor. Simple types, like dtype(\u2018float32\u2019), have a descr which\nlooks like a record array with one field with \u2018\u2019 as a name. The dtype()\nconstructor interprets this as a request to give a default name. Instead, we\nconstruct descriptor that can be passed to dtype().\n\nThe dtype of the array that will be written to disk.\n\nAn object that can be passed to `numpy.dtype()` in order to replicate the\ninput dtype.\n\n"}, {"name": "lib.format.header_data_from_array_1_0()", "path": "reference/generated/numpy.lib.format.header_data_from_array_1_0", "type": "numpy.lib.format.header_data_from_array_1_0", "text": "\nGet the dictionary of header metadata from a numpy.ndarray.\n\nThis has the appropriate entries for writing its string representation to the\nheader of the file.\n\n"}, {"name": "lib.format.magic()", "path": "reference/generated/numpy.lib.format.magic", "type": "numpy.lib.format.magic", "text": "\nReturn the magic string for the given file format version.\n\n"}, {"name": "lib.format.open_memmap()", "path": "reference/generated/numpy.lib.format.open_memmap", "type": "numpy.lib.format.open_memmap", "text": "\nOpen a .npy file as a memory-mapped array.\n\nThis may be used to read an existing file or create a new one.\n\nThe name of the file on disk. This may not be a file-like object.\n\nThe mode in which to open the file; the default is \u2018r+\u2019. In addition to the\nstandard file modes, \u2018c\u2019 is also accepted to mean \u201ccopy on write.\u201d See\n`memmap` for the available mode strings.\n\nThe data type of the array if we are creating a new file in \u201cwrite\u201d mode, if\nnot, `dtype` is ignored. The default value is None, which results in a data-\ntype of `float64`.\n\nThe shape of the array if we are creating a new file in \u201cwrite\u201d mode, in which\ncase this parameter is required. Otherwise, this parameter is ignored and is\nthus optional.\n\nWhether the array should be Fortran-contiguous (True) or C-contiguous (False,\nthe default) if we are creating a new file in \u201cwrite\u201d mode.\n\nIf the mode is a \u201cwrite\u201d mode, then this is the version of the file format\nused to create the file. None means use the oldest supported version that is\nable to store the data. Default: None\n\nThe memory-mapped array.\n\nIf the data or the mode is invalid.\n\nIf the file is not found or cannot be opened correctly.\n\nSee also\n\n"}, {"name": "lib.format.read_array()", "path": "reference/generated/numpy.lib.format.read_array", "type": "numpy.lib.format.read_array", "text": "\nRead an array from an NPY file.\n\nIf this is not a real file object, then this may take extra memory and time.\n\nWhether to allow writing pickled data. Default: False\n\nChanged in version 1.16.3: Made default False in response to CVE-2019-6446.\n\nAdditional keyword arguments to pass to pickle.load. These are only useful\nwhen loading object arrays saved on Python 2 when using Python 3.\n\nThe array from the data on disk.\n\nIf the data is invalid, or allow_pickle=False and the file contains an object\narray.\n\n"}, {"name": "lib.format.read_array_header_1_0()", "path": "reference/generated/numpy.lib.format.read_array_header_1_0", "type": "numpy.lib.format.read_array_header_1_0", "text": "\nRead an array header from a filelike object using the 1.0 file format version.\n\nThis will leave the file object located just after the header.\n\nA file object or something with a `read()` method like a file.\n\nThe shape of the array.\n\nThe array data will be written out directly if it is either C-contiguous or\nFortran-contiguous. Otherwise, it will be made contiguous before writing it\nout.\n\nThe dtype of the file\u2019s data.\n\nIf the data is invalid.\n\n"}, {"name": "lib.format.read_array_header_2_0()", "path": "reference/generated/numpy.lib.format.read_array_header_2_0", "type": "numpy.lib.format.read_array_header_2_0", "text": "\nRead an array header from a filelike object using the 2.0 file format version.\n\nThis will leave the file object located just after the header.\n\nNew in version 1.9.0.\n\nA file object or something with a `read()` method like a file.\n\nThe shape of the array.\n\nThe array data will be written out directly if it is either C-contiguous or\nFortran-contiguous. Otherwise, it will be made contiguous before writing it\nout.\n\nThe dtype of the file\u2019s data.\n\nIf the data is invalid.\n\n"}, {"name": "lib.format.read_magic()", "path": "reference/generated/numpy.lib.format.read_magic", "type": "numpy.lib.format.read_magic", "text": "\nRead the magic string to get the version of the file format.\n\n"}, {"name": "lib.format.write_array()", "path": "reference/generated/numpy.lib.format.write_array", "type": "numpy.lib.format.write_array", "text": "\nWrite an array to an NPY file, including a header.\n\nIf the array is neither C-contiguous nor Fortran-contiguous AND the file_like\nobject is not a real file object, this function will have to copy data in\nmemory.\n\nAn open, writable file object, or similar object with a `.write()` method.\n\nThe array to write to disk.\n\nThe version number of the format. None means use the oldest supported version\nthat is able to store the data. Default: None\n\nWhether to allow writing pickled data. Default: True\n\nAdditional keyword arguments to pass to pickle.dump, excluding \u2018protocol\u2019.\nThese are only useful when pickling objects in object arrays on Python 3 to\nPython 2 compatible format.\n\nIf the array cannot be persisted. This includes the case of allow_pickle=False\nand array being an object array.\n\nIf the array contains Python objects as part of its dtype, the process of\npickling them may raise various errors if the objects are not picklable.\n\n"}, {"name": "lib.format.write_array_header_1_0()", "path": "reference/generated/numpy.lib.format.write_array_header_1_0", "type": "numpy.lib.format.write_array_header_1_0", "text": "\nWrite the header for an array using the 1.0 format.\n\nThis has the appropriate entries for writing its string representation to the\nheader of the file.\n\n"}, {"name": "lib.format.write_array_header_2_0()", "path": "reference/generated/numpy.lib.format.write_array_header_2_0", "type": "numpy.lib.format.write_array_header_2_0", "text": "\nThe 2.0 format allows storing very large structured arrays.\n\nNew in version 1.9.0.\n\nThis has the appropriate entries for writing its string representation to the\nheader of the file.\n\n"}, {"name": "lib.scimath.arccos()", "path": "reference/generated/numpy.lib.scimath.arccos", "type": "numpy.lib.scimath.arccos", "text": "\nCompute the inverse cosine of x.\n\nReturn the \u201cprincipal value\u201d (for a description of this, see `numpy.arccos`)\nof the inverse cosine of `x`. For real `x` such that `abs(x) <= 1`, this is a\nreal number in the closed interval \\\\([0, \\pi]\\\\). Otherwise, the complex\nprinciple value is returned.\n\nThe value(s) whose arccos is (are) required.\n\nThe inverse cosine(s) of the `x` value(s). If `x` was a scalar, so is `out`,\notherwise an array object is returned.\n\nSee also\n\nFor an arccos() that returns `NAN` when real `x` is not in the interval\n`[-1,1]`, use `numpy.arccos`.\n\n"}, {"name": "lib.scimath.arcsin()", "path": "reference/generated/numpy.lib.scimath.arcsin", "type": "numpy.lib.scimath.arcsin", "text": "\nCompute the inverse sine of x.\n\nReturn the \u201cprincipal value\u201d (for a description of this, see `numpy.arcsin`)\nof the inverse sine of `x`. For real `x` such that `abs(x) <= 1`, this is a\nreal number in the closed interval \\\\([-\\pi/2, \\pi/2]\\\\). Otherwise, the\ncomplex principle value is returned.\n\nThe value(s) whose arcsin is (are) required.\n\nThe inverse sine(s) of the `x` value(s). If `x` was a scalar, so is `out`,\notherwise an array object is returned.\n\nSee also\n\nFor an arcsin() that returns `NAN` when real `x` is not in the interval\n`[-1,1]`, use `numpy.arcsin`.\n\n"}, {"name": "lib.scimath.arctanh()", "path": "reference/generated/numpy.lib.scimath.arctanh", "type": "numpy.lib.scimath.arctanh", "text": "\nCompute the inverse hyperbolic tangent of `x`.\n\nReturn the \u201cprincipal value\u201d (for a description of this, see `numpy.arctanh`)\nof `arctanh(x)`. For real `x` such that `abs(x) < 1`, this is a real number.\nIf `abs(x) > 1`, or if `x` is complex, the result is complex. Finally, `x = 1`\nreturns``inf`` and `x=-1` returns `-inf`.\n\nThe value(s) whose arctanh is (are) required.\n\nThe inverse hyperbolic tangent(s) of the `x` value(s). If `x` was a scalar so\nis `out`, otherwise an array is returned.\n\nSee also\n\nFor an arctanh() that returns `NAN` when real `x` is not in the interval\n`(-1,1)`, use `numpy.arctanh` (this latter, however, does return +/-inf for `x\n= +/-1`).\n\n"}, {"name": "lib.scimath.log()", "path": "reference/generated/numpy.lib.scimath.log", "type": "numpy.lib.scimath.log", "text": "\nCompute the natural logarithm of `x`.\n\nReturn the \u201cprincipal value\u201d (for a description of this, see `numpy.log`) of\n\\\\(log_e(x)\\\\). For real `x > 0`, this is a real number (`log(0)` returns\n`-inf` and `log(np.inf)` returns `inf`). Otherwise, the complex principle\nvalue is returned.\n\nThe value(s) whose log is (are) required.\n\nThe log of the `x` value(s). If `x` was a scalar, so is `out`, otherwise an\narray is returned.\n\nSee also\n\nFor a log() that returns `NAN` when real `x < 0`, use `numpy.log` (note,\nhowever, that otherwise `numpy.log` and this `log` are identical, i.e., both\nreturn `-inf` for `x = 0`, `inf` for `x = inf`, and, notably, the complex\nprinciple value if `x.imag != 0`).\n\nNegative arguments are handled \u201ccorrectly\u201d (recall that `exp(log(x)) == x`\ndoes not hold for real `x < 0`):\n\n"}, {"name": "lib.scimath.log10()", "path": "reference/generated/numpy.lib.scimath.log10", "type": "numpy.lib.scimath.log10", "text": "\nCompute the logarithm base 10 of `x`.\n\nReturn the \u201cprincipal value\u201d (for a description of this, see `numpy.log10`) of\n\\\\(log_{10}(x)\\\\). For real `x > 0`, this is a real number (`log10(0)` returns\n`-inf` and `log10(np.inf)` returns `inf`). Otherwise, the complex principle\nvalue is returned.\n\nThe value(s) whose log base 10 is (are) required.\n\nThe log base 10 of the `x` value(s). If `x` was a scalar, so is `out`,\notherwise an array object is returned.\n\nSee also\n\nFor a log10() that returns `NAN` when real `x < 0`, use `numpy.log10` (note,\nhowever, that otherwise `numpy.log10` and this `log10` are identical, i.e.,\nboth return `-inf` for `x = 0`, `inf` for `x = inf`, and, notably, the complex\nprinciple value if `x.imag != 0`).\n\n(We set the printing precision so the example can be auto-tested)\n\n"}, {"name": "lib.scimath.log2()", "path": "reference/generated/numpy.lib.scimath.log2", "type": "numpy.lib.scimath.log2", "text": "\nCompute the logarithm base 2 of `x`.\n\nReturn the \u201cprincipal value\u201d (for a description of this, see `numpy.log2`) of\n\\\\(log_2(x)\\\\). For real `x > 0`, this is a real number (`log2(0)` returns\n`-inf` and `log2(np.inf)` returns `inf`). Otherwise, the complex principle\nvalue is returned.\n\nThe value(s) whose log base 2 is (are) required.\n\nThe log base 2 of the `x` value(s). If `x` was a scalar, so is `out`,\notherwise an array is returned.\n\nSee also\n\nFor a log2() that returns `NAN` when real `x < 0`, use `numpy.log2` (note,\nhowever, that otherwise `numpy.log2` and this `log2` are identical, i.e., both\nreturn `-inf` for `x = 0`, `inf` for `x = inf`, and, notably, the complex\nprinciple value if `x.imag != 0`).\n\nWe set the printing precision so the example can be auto-tested:\n\n"}, {"name": "lib.scimath.logn()", "path": "reference/generated/numpy.lib.scimath.logn", "type": "numpy.lib.scimath.logn", "text": "\nTake log base n of x.\n\nIf `x` contains negative inputs, the answer is computed and returned in the\ncomplex domain.\n\nThe integer base(s) in which the log is taken.\n\nThe value(s) whose log base `n` is (are) required.\n\nThe log base `n` of the `x` value(s). If `x` was a scalar, so is `out`,\notherwise an array is returned.\n\n"}, {"name": "lib.scimath.power()", "path": "reference/generated/numpy.lib.scimath.power", "type": "numpy.lib.scimath.power", "text": "\nReturn x to the power p, (x**p).\n\nIf `x` contains negative values, the output is converted to the complex\ndomain.\n\nThe input value(s).\n\nThe power(s) to which `x` is raised. If `x` contains multiple values, `p` has\nto either be a scalar, or contain the same number of values as `x`. In the\nlatter case, the result is `x[0]**p[0], x[1]**p[1], ...`.\n\nThe result of `x**p`. If `x` and `p` are scalars, so is `out`, otherwise an\narray is returned.\n\nSee also\n\n"}, {"name": "lib.scimath.sqrt()", "path": "reference/generated/numpy.lib.scimath.sqrt", "type": "numpy.lib.scimath.sqrt", "text": "\nCompute the square root of x.\n\nFor negative input elements, a complex value is returned (unlike `numpy.sqrt`\nwhich returns NaN).\n\nThe input value(s).\n\nThe square root of `x`. If `x` was a scalar, so is `out`, otherwise an array\nis returned.\n\nSee also\n\nFor real, non-negative inputs this works just like `numpy.sqrt`:\n\nBut it automatically handles negative inputs:\n\n"}, {"name": "lib.stride_tricks.as_strided()", "path": "reference/generated/numpy.lib.stride_tricks.as_strided", "type": "numpy.lib.stride_tricks.as_strided", "text": "\nCreate a view into the array with the given shape and strides.\n\nWarning\n\nThis function has to be used with extreme care, see notes.\n\nArray to create a new.\n\nThe shape of the new array. Defaults to `x.shape`.\n\nThe strides of the new array. Defaults to `x.strides`.\n\nNew in version 1.10.\n\nIf True, subclasses are preserved.\n\nNew in version 1.12.\n\nIf set to False, the returned array will always be readonly. Otherwise it will\nbe writable if the original array was. It is advisable to set this to False if\npossible (see Notes).\n\nSee also\n\nbroadcast an array to a given shape.\n\nreshape an array.\n\nuserfriendly and safe function for the creation of sliding window views.\n\n`as_strided` creates a view into the array given the exact strides and shape.\nThis means it manipulates the internal data structure of ndarray and, if done\nincorrectly, the array elements can point to invalid memory and can corrupt\nresults or crash your program. It is advisable to always use the original\n`x.strides` when calculating new strides to avoid reliance on a contiguous\nmemory layout.\n\nFurthermore, arrays created with this function often contain self overlapping\nmemory, so that two elements are identical. Vectorized write operations on\nsuch arrays will typically be unpredictable. They may even give different\nresults for small, large, or transposed arrays. Since writing to these arrays\nhas to be tested and done with great care, you may want to use\n`writeable=False` to avoid accidental write operations.\n\nFor these reasons it is advisable to avoid `as_strided` when possible.\n\n"}, {"name": "lib.stride_tricks.sliding_window_view()", "path": "reference/generated/numpy.lib.stride_tricks.sliding_window_view", "type": "numpy.lib.stride_tricks.sliding_window_view", "text": "\nCreate a sliding window view into the array with the given window shape.\n\nAlso known as rolling or moving window, the window slides across all\ndimensions of the array and extracts subsets of the array at all window\npositions.\n\nNew in version 1.20.0.\n\nArray to create the sliding window view from.\n\nSize of window over each axis that takes part in the sliding window. If `axis`\nis not present, must have same length as the number of input array dimensions.\nSingle integers `i` are treated as if they were the tuple `(i,)`.\n\nAxis or axes along which the sliding window is applied. By default, the\nsliding window is applied to all axes and `window_shape[i]` will refer to axis\n`i` of `x`. If `axis` is given as a `tuple of int`, `window_shape[i]` will\nrefer to the axis `axis[i]` of `x`. Single integers `i` are treated as if they\nwere the tuple `(i,)`.\n\nIf True, sub-classes will be passed-through, otherwise the returned array will\nbe forced to be a base-class array (default).\n\nWhen true, allow writing to the returned view. The default is false, as this\nshould be used with caution: the returned view contains the same memory\nlocation multiple times, so writing to one location will cause others to\nchange.\n\nSliding window view of the array. The sliding window dimensions are inserted\nat the end, and the original dimensions are trimmed as required by the size of\nthe sliding window. That is, `view.shape = x_shape_trimmed + window_shape`,\nwhere `x_shape_trimmed` is `x.shape` with every entry reduced by one less than\nthe corresponding window size.\n\nSee also\n\nA lower-level and less safe routine for creating arbitrary views from custom\nshape and strides.\n\nbroadcast an array to a given shape.\n\nFor many applications using a sliding window view can be convenient, but\npotentially very slow. Often specialized solutions exist, for example:\n\nAs a rough estimate, a sliding window approach with an input size of `N` and a\nwindow size of `W` will scale as `O(N*W)` where frequently a special algorithm\ncan achieve `O(N)`. That means that the sliding window variant for a window\nsize of 100 can be a 100 times slower than a more specialized version.\n\nNevertheless, for small window sizes, when no custom algorithm exists, or as a\nprototyping and developing tool, this function can be a good solution.\n\nThis also works in more dimensions, e.g.\n\nThe axis can be specified explicitly:\n\nThe same axis can be used several times. In that case, every use reduces the\ncorresponding original dimension:\n\nCombining with stepped slicing (`::step`), this can be used to take sliding\nviews which skip elements:\n\nor views which move by multiple elements\n\nA common application of `sliding_window_view` is the calculation of running\nstatistics. The simplest example is the moving average:\n\nNote that a sliding window approach is often not optimal (see Notes).\n\n"}, {"name": "linalg.cholesky()", "path": "reference/generated/numpy.linalg.cholesky", "type": "numpy.linalg.cholesky", "text": "\nCholesky decomposition.\n\nReturn the Cholesky decomposition, `L * L.H`, of the square matrix `a`, where\n`L` is lower-triangular and .H is the conjugate transpose operator (which is\nthe ordinary transpose if `a` is real-valued). `a` must be Hermitian\n(symmetric if real-valued) and positive-definite. No checking is performed to\nverify whether `a` is Hermitian or not. In addition, only the lower-triangular\nand diagonal elements of `a` are used. Only `L` is actually returned.\n\nHermitian (symmetric if all elements are real), positive-definite input\nmatrix.\n\nUpper or lower-triangular Cholesky factor of `a`. Returns a matrix object if\n`a` is a matrix object.\n\nIf the decomposition fails, for example, if `a` is not positive-definite.\n\nSee also\n\nSimilar function in SciPy.\n\nCholesky decompose a banded Hermitian positive-definite matrix.\n\nCholesky decomposition of a matrix, to use in `scipy.linalg.cho_solve`.\n\nNew in version 1.8.0.\n\nBroadcasting rules apply, see the `numpy.linalg` documentation for details.\n\nThe Cholesky decomposition is often used as a fast way of solving\n\n(when `A` is both Hermitian/symmetric and positive-definite).\n\nFirst, we solve for \\\\(\\mathbf{y}\\\\) in\n\nand then for \\\\(\\mathbf{x}\\\\) in\n\n"}, {"name": "linalg.cond()", "path": "reference/generated/numpy.linalg.cond", "type": "numpy.linalg.cond", "text": "\nCompute the condition number of a matrix.\n\nThis function is capable of returning the condition number using one of seven\ndifferent norms, depending on the value of `p` (see Parameters below).\n\nThe matrix whose condition number is sought.\n\nOrder of the norm used in the condition number computation:\n\np\n\nnorm for matrices\n\nNone\n\n2-norm, computed directly using the `SVD`\n\n\u2018fro\u2019\n\nFrobenius norm\n\ninf\n\nmax(sum(abs(x), axis=1))\n\n-inf\nmin(sum(abs(x), axis=1))\n\n1\n\nmax(sum(abs(x), axis=0))\n\n-1\nmin(sum(abs(x), axis=0))\n\n2\n\n2-norm (largest sing. value)\n\n-2\nsmallest singular value\n\ninf means the `numpy.inf` object, and the Frobenius norm is the root-of-sum-\nof-squares norm.\n\nThe condition number of the matrix. May be infinite.\n\nSee also\n\nThe condition number of `x` is defined as the norm of `x` times the norm of\nthe inverse of `x` [1]; the norm can be the usual L2-norm (root-of-sum-of-\nsquares) or one of a number of other matrix norms.\n\nG. Strang, Linear Algebra and Its Applications, Orlando, FL, Academic Press,\nInc., 1980, pg. 285.\n\n"}, {"name": "linalg.det()", "path": "reference/generated/numpy.linalg.det", "type": "numpy.linalg.det", "text": "\nCompute the determinant of an array.\n\nInput array to compute determinants for.\n\nDeterminant of `a`.\n\nSee also\n\nAnother way to represent the determinant, more suitable for large matrices\nwhere underflow/overflow may occur.\n\nSimilar function in SciPy.\n\nNew in version 1.8.0.\n\nBroadcasting rules apply, see the `numpy.linalg` documentation for details.\n\nThe determinant is computed via LU factorization using the LAPACK routine\n`z/dgetrf`.\n\nThe determinant of a 2-D array [[a, b], [c, d]] is ad - bc:\n\nComputing determinants for a stack of matrices:\n\n"}, {"name": "linalg.eig()", "path": "reference/generated/numpy.linalg.eig", "type": "numpy.linalg.eig", "text": "\nCompute the eigenvalues and right eigenvectors of a square array.\n\nMatrices for which the eigenvalues and right eigenvectors will be computed\n\nThe eigenvalues, each repeated according to its multiplicity. The eigenvalues\nare not necessarily ordered. The resulting array will be of complex type,\nunless the imaginary part is zero in which case it will be cast to a real\ntype. When `a` is real the resulting eigenvalues will be real (0 imaginary\npart) or occur in conjugate pairs\n\nThe normalized (unit \u201clength\u201d) eigenvectors, such that the column `v[:,i]` is\nthe eigenvector corresponding to the eigenvalue `w[i]`.\n\nIf the eigenvalue computation does not converge.\n\nSee also\n\neigenvalues of a non-symmetric array.\n\neigenvalues and eigenvectors of a real symmetric or complex Hermitian\n(conjugate symmetric) array.\n\neigenvalues of a real symmetric or complex Hermitian (conjugate symmetric)\narray.\n\nSimilar function in SciPy that also solves the generalized eigenvalue problem.\n\nBest choice for unitary and other non-Hermitian normal matrices.\n\nNew in version 1.8.0.\n\nBroadcasting rules apply, see the `numpy.linalg` documentation for details.\n\nThis is implemented using the `_geev` LAPACK routines which compute the\neigenvalues and eigenvectors of general square arrays.\n\nThe number `w` is an eigenvalue of `a` if there exists a vector `v` such that\n`a @ v = w * v`. Thus, the arrays `a`, `w`, and `v` satisfy the equations `a @\nv[:,i] = w[i] * v[:,i]` for \\\\(i \\in \\\\{0,...,M-1\\\\}\\\\).\n\nThe array `v` of eigenvectors may not be of maximum rank, that is, some of the\ncolumns may be linearly dependent, although round-off error may obscure that\nfact. If the eigenvalues are all different, then theoretically the\neigenvectors are linearly independent and `a` can be diagonalized by a\nsimilarity transformation using `v`, i.e, `inv(v) @ a @ v` is diagonal.\n\nFor non-Hermitian normal matrices the SciPy function `scipy.linalg.schur` is\npreferred because the matrix `v` is guaranteed to be unitary, which is not the\ncase when using `eig`. The Schur factorization produces an upper triangular\nmatrix rather than a diagonal matrix, but for normal matrices only the\ndiagonal of the upper triangular matrix is needed, the rest is roundoff error.\n\nFinally, it is emphasized that `v` consists of the right (as in right-hand\nside) eigenvectors of `a`. A vector `y` satisfying `y.T @ a = z * y.T` for\nsome number `z` is called a left eigenvector of `a`, and, in general, the left\nand right eigenvectors of a matrix are not necessarily the (perhaps conjugate)\ntransposes of each other.\n\nG. Strang, Linear Algebra and Its Applications, 2nd Ed., Orlando, FL, Academic\nPress, Inc., 1980, Various pp.\n\n(Almost) trivial example with real e-values and e-vectors.\n\nReal matrix possessing complex e-values and e-vectors; note that the e-values\nare complex conjugates of each other.\n\nComplex-valued matrix with real e-values (but complex-valued e-vectors); note\nthat `a.conj().T == a`, i.e., `a` is Hermitian.\n\nBe careful about round-off error!\n\n"}, {"name": "linalg.eigh()", "path": "reference/generated/numpy.linalg.eigh", "type": "numpy.linalg.eigh", "text": "\nReturn the eigenvalues and eigenvectors of a complex Hermitian (conjugate\nsymmetric) or a real symmetric matrix.\n\nReturns two objects, a 1-D array containing the eigenvalues of `a`, and a 2-D\nsquare array or matrix (depending on the input type) of the corresponding\neigenvectors (in columns).\n\nHermitian or real symmetric matrices whose eigenvalues and eigenvectors are to\nbe computed.\n\nSpecifies whether the calculation is done with the lower triangular part of\n`a` (\u2018L\u2019, default) or the upper triangular part (\u2018U\u2019). Irrespective of this\nvalue only the real parts of the diagonal will be considered in the\ncomputation to preserve the notion of a Hermitian matrix. It therefore follows\nthat the imaginary part of the diagonal will always be treated as zero.\n\nThe eigenvalues in ascending order, each repeated according to its\nmultiplicity.\n\nThe column `v[:, i]` is the normalized eigenvector corresponding to the\neigenvalue `w[i]`. Will return a matrix object if `a` is a matrix object.\n\nIf the eigenvalue computation does not converge.\n\nSee also\n\neigenvalues of real symmetric or complex Hermitian (conjugate symmetric)\narrays.\n\neigenvalues and right eigenvectors for non-symmetric arrays.\n\neigenvalues of non-symmetric arrays.\n\nSimilar function in SciPy (but also solves the generalized eigenvalue\nproblem).\n\nNew in version 1.8.0.\n\nBroadcasting rules apply, see the `numpy.linalg` documentation for details.\n\nThe eigenvalues/eigenvectors are computed using LAPACK routines `_syevd`,\n`_heevd`.\n\nThe eigenvalues of real symmetric or complex Hermitian matrices are always\nreal. [1] The array `v` of (column) eigenvectors is unitary and `a`, `w`, and\n`v` satisfy the equations `dot(a, v[:, i]) = w[i] * v[:, i]`.\n\nG. Strang, Linear Algebra and Its Applications, 2nd Ed., Orlando, FL, Academic\nPress, Inc., 1980, pg. 222.\n\n"}, {"name": "linalg.eigvals()", "path": "reference/generated/numpy.linalg.eigvals", "type": "numpy.linalg.eigvals", "text": "\nCompute the eigenvalues of a general matrix.\n\nMain difference between `eigvals` and `eig`: the eigenvectors aren\u2019t returned.\n\nA complex- or real-valued matrix whose eigenvalues will be computed.\n\nThe eigenvalues, each repeated according to its multiplicity. They are not\nnecessarily ordered, nor are they necessarily real for real matrices.\n\nIf the eigenvalue computation does not converge.\n\nSee also\n\neigenvalues and right eigenvectors of general arrays\n\neigenvalues of real symmetric or complex Hermitian (conjugate symmetric)\narrays.\n\neigenvalues and eigenvectors of real symmetric or complex Hermitian (conjugate\nsymmetric) arrays.\n\nSimilar function in SciPy.\n\nNew in version 1.8.0.\n\nBroadcasting rules apply, see the `numpy.linalg` documentation for details.\n\nThis is implemented using the `_geev` LAPACK routines which compute the\neigenvalues and eigenvectors of general square arrays.\n\nIllustration, using the fact that the eigenvalues of a diagonal matrix are its\ndiagonal elements, that multiplying a matrix on the left by an orthogonal\nmatrix, `Q`, and on the right by `Q.T` (the transpose of `Q`), preserves the\neigenvalues of the \u201cmiddle\u201d matrix. In other words, if `Q` is orthogonal, then\n`Q * A * Q.T` has the same eigenvalues as `A`:\n\nNow multiply a diagonal matrix by `Q` on one side and by `Q.T` on the other:\n\n"}, {"name": "linalg.eigvalsh()", "path": "reference/generated/numpy.linalg.eigvalsh", "type": "numpy.linalg.eigvalsh", "text": "\nCompute the eigenvalues of a complex Hermitian or real symmetric matrix.\n\nMain difference from eigh: the eigenvectors are not computed.\n\nA complex- or real-valued matrix whose eigenvalues are to be computed.\n\nSpecifies whether the calculation is done with the lower triangular part of\n`a` (\u2018L\u2019, default) or the upper triangular part (\u2018U\u2019). Irrespective of this\nvalue only the real parts of the diagonal will be considered in the\ncomputation to preserve the notion of a Hermitian matrix. It therefore follows\nthat the imaginary part of the diagonal will always be treated as zero.\n\nThe eigenvalues in ascending order, each repeated according to its\nmultiplicity.\n\nIf the eigenvalue computation does not converge.\n\nSee also\n\neigenvalues and eigenvectors of real symmetric or complex Hermitian (conjugate\nsymmetric) arrays.\n\neigenvalues of general real or complex arrays.\n\neigenvalues and right eigenvectors of general real or complex arrays.\n\nSimilar function in SciPy.\n\nNew in version 1.8.0.\n\nBroadcasting rules apply, see the `numpy.linalg` documentation for details.\n\nThe eigenvalues are computed using LAPACK routines `_syevd`, `_heevd`.\n\n"}, {"name": "linalg.inv()", "path": "reference/generated/numpy.linalg.inv", "type": "numpy.linalg.inv", "text": "\nCompute the (multiplicative) inverse of a matrix.\n\nGiven a square matrix `a`, return the matrix `ainv` satisfying `dot(a, ainv) =\ndot(ainv, a) = eye(a.shape[0])`.\n\nMatrix to be inverted.\n\n(Multiplicative) inverse of the matrix `a`.\n\nIf `a` is not square or inversion fails.\n\nSee also\n\nSimilar function in SciPy.\n\nNew in version 1.8.0.\n\nBroadcasting rules apply, see the `numpy.linalg` documentation for details.\n\nIf a is a matrix object, then the return value is a matrix as well:\n\nInverses of several matrices can be computed at once:\n\n"}, {"name": "linalg.LinAlgError", "path": "reference/generated/numpy.linalg.linalgerror", "type": "numpy.linalg.LinAlgError", "text": "\nGeneric Python-exception-derived object raised by linalg functions.\n\nGeneral purpose exception class, derived from Python\u2019s exception.Exception\nclass, programmatically raised in linalg functions when a Linear Algebra-\nrelated condition would prevent further correct execution of the function.\n\n"}, {"name": "linalg.lstsq()", "path": "reference/generated/numpy.linalg.lstsq", "type": "numpy.linalg.lstsq", "text": "\nReturn the least-squares solution to a linear matrix equation.\n\nComputes the vector `x` that approximately solves the equation `a @ x = b`.\nThe equation may be under-, well-, or over-determined (i.e., the number of\nlinearly independent rows of `a` can be less than, equal to, or greater than\nits number of linearly independent columns). If `a` is square and of full\nrank, then `x` (but for round-off error) is the \u201cexact\u201d solution of the\nequation. Else, `x` minimizes the Euclidean 2-norm \\\\(||b - ax||\\\\). If there\nare multiple minimizing solutions, the one with the smallest 2-norm\n\\\\(||x||\\\\) is returned.\n\n\u201cCoefficient\u201d matrix.\n\nOrdinate or \u201cdependent variable\u201d values. If `b` is two-dimensional, the least-\nsquares solution is calculated for each of the `K` columns of `b`.\n\nCut-off ratio for small singular values of `a`. For the purposes of rank\ndetermination, singular values are treated as zero if they are smaller than\n`rcond` times the largest singular value of `a`.\n\nChanged in version 1.14.0: If not set, a FutureWarning is given. The previous\ndefault of `-1` will use the machine precision as `rcond` parameter, the new\ndefault will use the machine precision times `max(M, N)`. To silence the\nwarning and use the new default, use `rcond=None`, to keep using the old\nbehavior, use `rcond=-1`.\n\nLeast-squares solution. If `b` is two-dimensional, the solutions are in the\n`K` columns of `x`.\n\nSums of squared residuals: Squared Euclidean 2-norm for each column in `b - a\n@ x`. If the rank of `a` is < N or M <= N, this is an empty array. If `b` is\n1-dimensional, this is a (1,) shape array. Otherwise the shape is (K,).\n\nRank of matrix `a`.\n\nSingular values of `a`.\n\nIf computation does not converge.\n\nSee also\n\nSimilar function in SciPy.\n\nIf `b` is a matrix, then all array results are returned as matrices.\n\nFit a line, `y = mx + c`, through some noisy data-points:\n\nBy examining the coefficients, we see that the line should have a gradient of\nroughly 1 and cut the y-axis at, more or less, -1.\n\nWe can rewrite the line equation as `y = Ap`, where `A = [[x 1]]` and `p =\n[[m], [c]]`. Now use `lstsq` to solve for `p`:\n\nPlot the data along with the fitted line:\n\n"}, {"name": "linalg.matrix_power()", "path": "reference/generated/numpy.linalg.matrix_power", "type": "numpy.linalg.matrix_power", "text": "\nRaise a square matrix to the (integer) power `n`.\n\nFor positive integers `n`, the power is computed by repeated matrix squarings\nand matrix multiplications. If `n == 0`, the identity matrix of the same shape\nas M is returned. If `n < 0`, the inverse is computed and then raised to the\n`abs(n)`.\n\nNote\n\nStacks of object matrices are not currently supported.\n\nMatrix to be \u201cpowered\u201d.\n\nThe exponent can be any integer or long integer, positive, negative, or zero.\n\nThe return value is the same shape and type as `M`; if the exponent is\npositive or zero then the type of the elements is the same as those of `M`. If\nthe exponent is negative the elements are floating-point.\n\nFor matrices that are not square or that (for negative powers) cannot be\ninverted numerically.\n\nSomewhat more sophisticated example\n\n"}, {"name": "linalg.matrix_rank()", "path": "reference/generated/numpy.linalg.matrix_rank", "type": "numpy.linalg.matrix_rank", "text": "\nReturn matrix rank of array using SVD method\n\nRank of the array is the number of singular values of the array that are\ngreater than `tol`.\n\nChanged in version 1.14: Can now operate on stacks of matrices\n\nInput vector or stack of matrices.\n\nThreshold below which SVD values are considered zero. If `tol` is None, and\n`S` is an array with singular values for `M`, and `eps` is the epsilon value\nfor datatype of `S`, then `tol` is set to `S.max() * max(M, N) * eps`.\n\nChanged in version 1.14: Broadcasted against the stack of matrices\n\nIf True, `A` is assumed to be Hermitian (symmetric if real-valued), enabling a\nmore efficient method for finding singular values. Defaults to False.\n\nNew in version 1.14.\n\nRank of A.\n\nThe default threshold to detect rank deficiency is a test on the magnitude of\nthe singular values of `A`. By default, we identify singular values less than\n`S.max() * max(M, N) * eps` as indicating rank deficiency (with the symbols\ndefined above). This is the algorithm MATLAB uses [1]. It also appears in\nNumerical recipes in the discussion of SVD solutions for linear least squares\n[2].\n\nThis default threshold is designed to detect rank deficiency accounting for\nthe numerical errors of the SVD computation. Imagine that there is a column in\n`A` that is an exact (in floating point) linear combination of other columns\nin `A`. Computing the SVD on `A` will not produce a singular value exactly\nequal to 0 in general: any difference of the smallest SVD value from 0 will be\ncaused by numerical imprecision in the calculation of the SVD. Our threshold\nfor small SVD values takes this numerical imprecision into account, and the\ndefault threshold will detect such numerical rank deficiency. The threshold\nmay declare a matrix `A` rank deficient even if the linear combination of some\ncolumns of `A` is not exactly equal to another column of `A` but only\nnumerically very close to another column of `A`.\n\nWe chose our default threshold because it is in wide use. Other thresholds are\npossible. For example, elsewhere in the 2007 edition of Numerical recipes\nthere is an alternative threshold of `S.max() * np.finfo(A.dtype).eps / 2. *\nnp.sqrt(m + n + 1.)`. The authors describe this threshold as being based on\n\u201cexpected roundoff error\u201d (p 71).\n\nThe thresholds above deal with floating point roundoff error in the\ncalculation of the SVD. However, you may have more information about the\nsources of error in `A` that would make you consider other tolerance values to\ndetect effective rank deficiency. The most useful measure of the tolerance\ndepends on the operations you intend to use on your matrix. For example, if\nyour data come from uncertain measurements with uncertainties greater than\nfloating point epsilon, choosing a tolerance near that uncertainty may be\npreferable. The tolerance may be absolute if the uncertainties are absolute\nrather than relative.\n\nMATLAB reference documentation, \u201cRank\u201d\nhttps://www.mathworks.com/help/techdoc/ref/rank.html\n\nW. H. Press, S. A. Teukolsky, W. T. Vetterling and B. P. Flannery, \u201cNumerical\nRecipes (3rd edition)\u201d, Cambridge University Press, 2007, page 795.\n\n"}, {"name": "linalg.multi_dot()", "path": "reference/generated/numpy.linalg.multi_dot", "type": "numpy.linalg.multi_dot", "text": "\nCompute the dot product of two or more arrays in a single function call, while\nautomatically selecting the fastest evaluation order.\n\n`multi_dot` chains `numpy.dot` and uses optimal parenthesization of the\nmatrices [1] [2]. Depending on the shapes of the matrices, this can speed up\nthe multiplication a lot.\n\nIf the first argument is 1-D it is treated as a row vector. If the last\nargument is 1-D it is treated as a column vector. The other arguments must be\n2-D.\n\nThink of `multi_dot` as:\n\nIf the first argument is 1-D it is treated as row vector. If the last argument\nis 1-D it is treated as column vector. The other arguments must be 2-D.\n\nOutput argument. This must have the exact kind that would be returned if it\nwas not used. In particular, it must have the right type, must be\nC-contiguous, and its dtype must be the dtype that would be returned for\n`dot(a, b)`. This is a performance feature. Therefore, if these conditions are\nnot met, an exception is raised, instead of attempting to be flexible.\n\nNew in version 1.19.0.\n\nReturns the dot product of the supplied arrays.\n\nSee also\n\ndot multiplication with two arguments.\n\nThe cost for a matrix multiplication can be calculated with the following\nfunction:\n\nAssume we have three matrices \\\\(A_{10x100}, B_{100x5}, C_{5x50}\\\\).\n\nThe costs for the two different parenthesizations are as follows:\n\nCormen, \u201cIntroduction to Algorithms\u201d, Chapter 15.2, p. 370-378\n\nhttps://en.wikipedia.org/wiki/Matrix_chain_multiplication\n\n`multi_dot` allows you to write:\n\ninstead of:\n\n"}, {"name": "linalg.norm()", "path": "reference/generated/numpy.linalg.norm", "type": "numpy.linalg.norm", "text": "\nMatrix or vector norm.\n\nThis function is able to return one of eight different matrix norms, or one of\nan infinite number of vector norms (described below), depending on the value\nof the `ord` parameter.\n\nInput array. If `axis` is None, `x` must be 1-D or 2-D, unless `ord` is None.\nIf both `axis` and `ord` are None, the 2-norm of `x.ravel` will be returned.\n\nOrder of the norm (see table under `Notes`). inf means numpy\u2019s `inf` object.\nThe default is None.\n\nIf `axis` is an integer, it specifies the axis of `x` along which to compute\nthe vector norms. If `axis` is a 2-tuple, it specifies the axes that hold 2-D\nmatrices, and the matrix norms of these matrices are computed. If `axis` is\nNone then either a vector norm (when `x` is 1-D) or a matrix norm (when `x` is\n2-D) is returned. The default is None.\n\nNew in version 1.8.0.\n\nIf this is set to True, the axes which are normed over are left in the result\nas dimensions with size one. With this option the result will broadcast\ncorrectly against the original `x`.\n\nNew in version 1.10.0.\n\nNorm of the matrix or vector(s).\n\nSee also\n\nSimilar function in SciPy.\n\nFor values of `ord < 1`, the result is, strictly speaking, not a mathematical\n\u2018norm\u2019, but it may still be useful for various numerical purposes.\n\nThe following norms can be calculated:\n\nord\n\nnorm for matrices\n\nnorm for vectors\n\nNone\n\nFrobenius norm\n\n2-norm\n\n\u2018fro\u2019\n\nFrobenius norm\n\n\u2013\n\n\u2018nuc\u2019\n\nnuclear norm\n\n\u2013\n\ninf\n\nmax(sum(abs(x), axis=1))\n\nmax(abs(x))\n\n-inf\nmin(sum(abs(x), axis=1))\n\nmin(abs(x))\n\n0\n\n\u2013\n\nsum(x != 0)\n\n1\n\nmax(sum(abs(x), axis=0))\n\nas below\n\n-1\nmin(sum(abs(x), axis=0))\n\nas below\n\n2\n\n2-norm (largest sing. value)\n\nas below\n\n-2\nsmallest singular value\n\nas below\n\nother\n\n\u2013\n\nsum(abs(x)**ord)**(1./ord)\n\nThe Frobenius norm is given by [1]:\n\n\\\\(||A||_F = [\\sum_{i,j} abs(a_{i,j})^2]^{1/2}\\\\)\n\nThe nuclear norm is the sum of the singular values.\n\nBoth the Frobenius and nuclear norm orders are only defined for matrices and\nraise a ValueError when `x.ndim != 2`.\n\nG. H. Golub and C. F. Van Loan, Matrix Computations, Baltimore, MD, Johns\nHopkins University Press, 1985, pg. 15\n\nUsing the `axis` argument to compute vector norms:\n\nUsing the `axis` argument to compute matrix norms:\n\n"}, {"name": "linalg.pinv()", "path": "reference/generated/numpy.linalg.pinv", "type": "numpy.linalg.pinv", "text": "\nCompute the (Moore-Penrose) pseudo-inverse of a matrix.\n\nCalculate the generalized inverse of a matrix using its singular-value\ndecomposition (SVD) and including all large singular values.\n\nChanged in version 1.14: Can now operate on stacks of matrices\n\nMatrix or stack of matrices to be pseudo-inverted.\n\nCutoff for small singular values. Singular values less than or equal to `rcond\n* largest_singular_value` are set to zero. Broadcasts against the stack of\nmatrices.\n\nIf True, `a` is assumed to be Hermitian (symmetric if real-valued), enabling a\nmore efficient method for finding singular values. Defaults to False.\n\nNew in version 1.17.0.\n\nThe pseudo-inverse of `a`. If `a` is a `matrix` instance, then so is `B`.\n\nIf the SVD computation does not converge.\n\nSee also\n\nSimilar function in SciPy.\n\nSimilar function in SciPy (SVD-based).\n\nCompute the (Moore-Penrose) pseudo-inverse of a Hermitian matrix.\n\nThe pseudo-inverse of a matrix A, denoted \\\\(A^+\\\\), is defined as: \u201cthe\nmatrix that \u2018solves\u2019 [the least-squares problem] \\\\(Ax = b\\\\),\u201d i.e., if\n\\\\(\\bar{x}\\\\) is said solution, then \\\\(A^+\\\\) is that matrix such that\n\\\\(\\bar{x} = A^+b\\\\).\n\nIt can be shown that if \\\\(Q_1 \\Sigma Q_2^T = A\\\\) is the singular value\ndecomposition of A, then \\\\(A^+ = Q_2 \\Sigma^+ Q_1^T\\\\), where \\\\(Q_{1,2}\\\\)\nare orthogonal matrices, \\\\(\\Sigma\\\\) is a diagonal matrix consisting of A\u2019s\nso-called singular values, (followed, typically, by zeros), and then\n\\\\(\\Sigma^+\\\\) is simply the diagonal matrix consisting of the reciprocals of\nA\u2019s singular values (again, followed by zeros). [1]\n\nG. Strang, Linear Algebra and Its Applications, 2nd Ed., Orlando, FL, Academic\nPress, Inc., 1980, pp. 139-142.\n\nThe following example checks that `a * a+ * a == a` and `a+ * a * a+ == a+`:\n\n"}, {"name": "linalg.qr()", "path": "reference/generated/numpy.linalg.qr", "type": "numpy.linalg.qr", "text": "\nCompute the qr factorization of a matrix.\n\nFactor the matrix `a` as qr, where `q` is orthonormal and `r` is upper-\ntriangular.\n\nAn array-like object with the dimensionality of at least 2.\n\nIf K = min(M, N), then\n\n(\u2026, M, K), (\u2026, K, N) (default)\n\nThe options \u2018reduced\u2019, \u2018complete, and \u2018raw\u2019 are new in numpy 1.8, see the\nnotes for more information. The default is \u2018reduced\u2019, and to maintain backward\ncompatibility with earlier versions of numpy both it and the old default\n\u2018full\u2019 can be omitted. Note that array h returned in \u2018raw\u2019 mode is transposed\nfor calling Fortran. The \u2018economic\u2019 mode is deprecated. The modes \u2018full\u2019 and\n\u2018economic\u2019 may be passed using only the first letter for backwards\ncompatibility, but all others must be spelled out. See the Notes for more\nexplanation.\n\nA matrix with orthonormal columns. When mode = \u2018complete\u2019 the result is an\northogonal/unitary matrix depending on whether or not a is real/complex. The\ndeterminant may be either +/- 1 in that case. In case the number of dimensions\nin the input array is greater than 2 then a stack of the matrices with above\nproperties is returned.\n\nThe upper-triangular matrix or a stack of upper-triangular matrices if the\nnumber of dimensions in the input array is greater than 2.\n\nThe array h contains the Householder reflectors that generate q along with r.\nThe tau array contains scaling factors for the reflectors. In the deprecated\n\u2018economic\u2019 mode only h is returned.\n\nIf factoring fails.\n\nSee also\n\nSimilar function in SciPy.\n\nCompute RQ decomposition of a matrix.\n\nThis is an interface to the LAPACK routines `dgeqrf`, `zgeqrf`, `dorgqr`, and\n`zungqr`.\n\nFor more information on the qr factorization, see for example:\nhttps://en.wikipedia.org/wiki/QR_factorization\n\nSubclasses of `ndarray` are preserved except for the \u2018raw\u2019 mode. So if `a` is\nof type `matrix`, all the return values will be matrices too.\n\nNew \u2018reduced\u2019, \u2018complete\u2019, and \u2018raw\u2019 options for mode were added in NumPy\n1.8.0 and the old option \u2018full\u2019 was made an alias of \u2018reduced\u2019. In addition\nthe options \u2018full\u2019 and \u2018economic\u2019 were deprecated. Because \u2018full\u2019 was the\nprevious default and \u2018reduced\u2019 is the new default, backward compatibility can\nbe maintained by letting `mode` default. The \u2018raw\u2019 option was added so that\nLAPACK routines that can multiply arrays by q using the Householder reflectors\ncan be used. Note that in this case the returned arrays are of type np.double\nor np.cdouble and the h array is transposed to be FORTRAN compatible. No\nroutines using the \u2018raw\u2019 return are currently exposed by numpy, but some are\navailable in lapack_lite and just await the necessary work.\n\nExample illustrating a common use of `qr`: solving of least squares problems\n\nWhat are the least-squares-best `m` and `y0` in `y = y0 + mx` for the\nfollowing data: {(0,1), (1,0), (1,2), (2,1)}. (Graph the points and you\u2019ll see\nthat it should be y0 = 0, m = 1.) The answer is provided by solving the over-\ndetermined matrix equation `Ax = b`, where:\n\nIf A = qr such that q is orthonormal (which is always possible via Gram-\nSchmidt), then `x = inv(r) * (q.T) * b`. (In numpy practice, however, we\nsimply use `lstsq`.)\n\n"}, {"name": "linalg.slogdet()", "path": "reference/generated/numpy.linalg.slogdet", "type": "numpy.linalg.slogdet", "text": "\nCompute the sign and (natural) logarithm of the determinant of an array.\n\nIf an array has a very small or very large determinant, then a call to `det`\nmay overflow or underflow. This routine is more robust against such issues,\nbecause it computes the logarithm of the determinant rather than the\ndeterminant itself.\n\nInput array, has to be a square 2-D array.\n\nA number representing the sign of the determinant. For a real matrix, this is\n1, 0, or -1. For a complex matrix, this is a complex number with absolute\nvalue 1 (i.e., it is on the unit circle), or else 0.\n\nThe natural log of the absolute value of the determinant.\n\nSee also\n\nNew in version 1.8.0.\n\nBroadcasting rules apply, see the `numpy.linalg` documentation for details.\n\nNew in version 1.6.0.\n\nThe determinant is computed via LU factorization using the LAPACK routine\n`z/dgetrf`.\n\nThe determinant of a 2-D array `[[a, b], [c, d]]` is `ad - bc`:\n\nComputing log-determinants for a stack of matrices:\n\nThis routine succeeds where ordinary `det` does not:\n\n"}, {"name": "linalg.solve()", "path": "reference/generated/numpy.linalg.solve", "type": "numpy.linalg.solve", "text": "\nSolve a linear matrix equation, or system of linear scalar equations.\n\nComputes the \u201cexact\u201d solution, `x`, of the well-determined, i.e., full rank,\nlinear matrix equation `ax = b`.\n\nCoefficient matrix.\n\nOrdinate or \u201cdependent variable\u201d values.\n\nSolution to the system a x = b. Returned shape is identical to `b`.\n\nIf `a` is singular or not square.\n\nSee also\n\nSimilar function in SciPy.\n\nNew in version 1.8.0.\n\nBroadcasting rules apply, see the `numpy.linalg` documentation for details.\n\nThe solutions are computed using LAPACK routine `_gesv`.\n\n`a` must be square and of full-rank, i.e., all rows (or, equivalently,\ncolumns) must be linearly independent; if either is not true, use `lstsq` for\nthe least-squares best \u201csolution\u201d of the system/equation.\n\nG. Strang, Linear Algebra and Its Applications, 2nd Ed., Orlando, FL, Academic\nPress, Inc., 1980, pg. 22.\n\nSolve the system of equations `x0 + 2 * x1 = 1` and `3 * x0 + 5 * x1 = 2`:\n\nCheck that the solution is correct:\n\n"}, {"name": "linalg.svd()", "path": "reference/generated/numpy.linalg.svd", "type": "numpy.linalg.svd", "text": "\nSingular Value Decomposition.\n\nWhen `a` is a 2D array, it is factorized as `u @ np.diag(s) @ vh = (u * s) @\nvh`, where `u` and `vh` are 2D unitary arrays and `s` is a 1D array of `a`\u2019s\nsingular values. When `a` is higher-dimensional, SVD is applied in stacked\nmode as explained below.\n\nA real or complex array with `a.ndim >= 2`.\n\nIf True (default), `u` and `vh` have the shapes `(..., M, M)` and `(..., N,\nN)`, respectively. Otherwise, the shapes are `(..., M, K)` and `(..., K, N)`,\nrespectively, where `K = min(M, N)`.\n\nWhether or not to compute `u` and `vh` in addition to `s`. True by default.\n\nIf True, `a` is assumed to be Hermitian (symmetric if real-valued), enabling a\nmore efficient method for finding singular values. Defaults to False.\n\nNew in version 1.17.0.\n\nUnitary array(s). The first `a.ndim - 2` dimensions have the same size as\nthose of the input `a`. The size of the last two dimensions depends on the\nvalue of `full_matrices`. Only returned when `compute_uv` is True.\n\nVector(s) with the singular values, within each vector sorted in descending\norder. The first `a.ndim - 2` dimensions have the same size as those of the\ninput `a`.\n\nUnitary array(s). The first `a.ndim - 2` dimensions have the same size as\nthose of the input `a`. The size of the last two dimensions depends on the\nvalue of `full_matrices`. Only returned when `compute_uv` is True.\n\nIf SVD computation does not converge.\n\nSee also\n\nSimilar function in SciPy.\n\nCompute singular values of a matrix.\n\nChanged in version 1.8.0: Broadcasting rules apply, see the `numpy.linalg`\ndocumentation for details.\n\nThe decomposition is performed using LAPACK routine `_gesdd`.\n\nSVD is usually described for the factorization of a 2D matrix \\\\(A\\\\). The\nhigher-dimensional case will be discussed below. In the 2D case, SVD is\nwritten as \\\\(A = U S V^H\\\\), where \\\\(A = a\\\\), \\\\(U= u\\\\), \\\\(S=\n\\mathtt{np.diag}(s)\\\\) and \\\\(V^H = vh\\\\). The 1D array `s` contains the\nsingular values of `a` and `u` and `vh` are unitary. The rows of `vh` are the\neigenvectors of \\\\(A^H A\\\\) and the columns of `u` are the eigenvectors of\n\\\\(A A^H\\\\). In both cases the corresponding (possibly non-zero) eigenvalues\nare given by `s**2`.\n\nIf `a` has more than two dimensions, then broadcasting rules apply, as\nexplained in Linear algebra on several matrices at once. This means that SVD\nis working in \u201cstacked\u201d mode: it iterates over all indices of the first\n`a.ndim - 2` dimensions and for each combination SVD is applied to the last\ntwo indices. The matrix `a` can be reconstructed from the decomposition with\neither `(u * s[..., None, :]) @ vh` or `u @ (s[..., None] * vh)`. (The `@`\noperator can be replaced by the function `np.matmul` for python versions below\n3.5.)\n\nIf `a` is a `matrix` object (as opposed to an `ndarray`), then so are all the\nreturn values.\n\nReconstruction based on full SVD, 2D case:\n\nReconstruction based on reduced SVD, 2D case:\n\nReconstruction based on full SVD, 4D case:\n\nReconstruction based on reduced SVD, 4D case:\n\n"}, {"name": "linalg.tensorinv()", "path": "reference/generated/numpy.linalg.tensorinv", "type": "numpy.linalg.tensorinv", "text": "\nCompute the \u2018inverse\u2019 of an N-dimensional array.\n\nThe result is an inverse for `a` relative to the tensordot operation\n`tensordot(a, b, ind)`, i. e., up to floating-point accuracy,\n`tensordot(tensorinv(a), a, ind)` is the \u201cidentity\u201d tensor for the tensordot\noperation.\n\nTensor to \u2018invert\u2019. Its shape must be \u2018square\u2019, i. e., `prod(a.shape[:ind]) ==\nprod(a.shape[ind:])`.\n\nNumber of first indices that are involved in the inverse sum. Must be a\npositive integer, default is 2.\n\n`a`\u2019s tensordot inverse, shape `a.shape[ind:] + a.shape[:ind]`.\n\nIf `a` is singular or not \u2018square\u2019 (in the above sense).\n\nSee also\n\n"}, {"name": "linalg.tensorsolve()", "path": "reference/generated/numpy.linalg.tensorsolve", "type": "numpy.linalg.tensorsolve", "text": "\nSolve the tensor equation `a x = b` for x.\n\nIt is assumed that all indices of `x` are summed over in the product, together\nwith the rightmost indices of `a`, as is done in, for example, `tensordot(a,\nx, axes=b.ndim)`.\n\nCoefficient tensor, of shape `b.shape + Q`. `Q`, a tuple, equals the shape of\nthat sub-tensor of `a` consisting of the appropriate number of its rightmost\nindices, and must be such that `prod(Q) == prod(b.shape)` (in which sense `a`\nis said to be \u2018square\u2019).\n\nRight-hand tensor, which can be of any shape.\n\nAxes in `a` to reorder to the right, before inversion. If None (default), no\nreordering is done.\n\nIf `a` is singular or not \u2018square\u2019 (in the above sense).\n\nSee also\n\n"}, {"name": "Linear algebra (numpy.linalg)", "path": "reference/routines.linalg", "type": "Linear algebra ( \n      \n       numpy.linalg\n      \n      )", "text": "\nThe NumPy linear algebra functions rely on BLAS and LAPACK to provide\nefficient low level implementations of standard linear algebra algorithms.\nThose libraries may be provided by NumPy itself using C versions of a subset\nof their reference implementations but, when possible, highly optimized\nlibraries that take advantage of specialized processor functionality are\npreferred. Examples of such libraries are OpenBLAS, MKL (TM), and ATLAS.\nBecause those libraries are multithreaded and processor dependent,\nenvironmental variables and external packages such as threadpoolctl may be\nneeded to control the number of threads or specify the processor architecture.\n\nThe SciPy library also contains a `linalg` submodule, and there is overlap in\nthe functionality provided by the SciPy and NumPy submodules. SciPy contains\nfunctions not found in `numpy.linalg`, such as functions related to LU\ndecomposition and the Schur decomposition, multiple ways of calculating the\npseudoinverse, and matrix transcendentals such as the matrix logarithm. Some\nfunctions that exist in both have augmented functionality in `scipy.linalg`.\nFor example, `scipy.linalg.eig` can take a second matrix argument for solving\ngeneralized eigenvalue problems. Some functions in NumPy, however, have more\nflexible broadcasting options. For example, `numpy.linalg.solve` can handle\n\u201cstacked\u201d arrays, while `scipy.linalg.solve` accepts only a single square\narray as its first argument.\n\nNote\n\nThe term matrix as it is used on this page indicates a 2d `numpy.array`\nobject, and not a `numpy.matrix` object. The latter is no longer recommended,\neven for linear algebra. See the matrix object documentation for more\ninformation.\n\nIntroduced in NumPy 1.10.0, the `@` operator is preferable to other methods\nwhen computing the matrix product between 2d arrays. The `numpy.matmul`\nfunction implements the `@` operator.\n\n`dot`(a, b[, out])\n\nDot product of two arrays.\n\n`linalg.multi_dot`(arrays, *[, out])\n\nCompute the dot product of two or more arrays in a single function call, while\nautomatically selecting the fastest evaluation order.\n\n`vdot`(a, b, /)\n\nReturn the dot product of two vectors.\n\n`inner`(a, b, /)\n\nInner product of two arrays.\n\n`outer`(a, b[, out])\n\nCompute the outer product of two vectors.\n\n`matmul`(x1, x2, /[, out, casting, order, ...])\n\nMatrix product of two arrays.\n\n`tensordot`(a, b[, axes])\n\nCompute tensor dot product along specified axes.\n\n`einsum`(subscripts, *operands[, out, dtype, ...])\n\nEvaluates the Einstein summation convention on the operands.\n\n`einsum_path`(subscripts, *operands[, optimize])\n\nEvaluates the lowest cost contraction order for an einsum expression by\nconsidering the creation of intermediate arrays.\n\n`linalg.matrix_power`(a, n)\n\nRaise a square matrix to the (integer) power `n`.\n\n`kron`(a, b)\n\nKronecker product of two arrays.\n\n`linalg.cholesky`(a)\n\nCholesky decomposition.\n\n`linalg.qr`(a[, mode])\n\nCompute the qr factorization of a matrix.\n\n`linalg.svd`(a[, full_matrices, compute_uv, ...])\n\nSingular Value Decomposition.\n\n`linalg.eig`(a)\n\nCompute the eigenvalues and right eigenvectors of a square array.\n\n`linalg.eigh`(a[, UPLO])\n\nReturn the eigenvalues and eigenvectors of a complex Hermitian (conjugate\nsymmetric) or a real symmetric matrix.\n\n`linalg.eigvals`(a)\n\nCompute the eigenvalues of a general matrix.\n\n`linalg.eigvalsh`(a[, UPLO])\n\nCompute the eigenvalues of a complex Hermitian or real symmetric matrix.\n\n`linalg.norm`(x[, ord, axis, keepdims])\n\nMatrix or vector norm.\n\n`linalg.cond`(x[, p])\n\nCompute the condition number of a matrix.\n\n`linalg.det`(a)\n\nCompute the determinant of an array.\n\n`linalg.matrix_rank`(A[, tol, hermitian])\n\nReturn matrix rank of array using SVD method\n\n`linalg.slogdet`(a)\n\nCompute the sign and (natural) logarithm of the determinant of an array.\n\n`trace`(a[, offset, axis1, axis2, dtype, out])\n\nReturn the sum along diagonals of the array.\n\n`linalg.solve`(a, b)\n\nSolve a linear matrix equation, or system of linear scalar equations.\n\n`linalg.tensorsolve`(a, b[, axes])\n\nSolve the tensor equation `a x = b` for x.\n\n`linalg.lstsq`(a, b[, rcond])\n\nReturn the least-squares solution to a linear matrix equation.\n\n`linalg.inv`(a)\n\nCompute the (multiplicative) inverse of a matrix.\n\n`linalg.pinv`(a[, rcond, hermitian])\n\nCompute the (Moore-Penrose) pseudo-inverse of a matrix.\n\n`linalg.tensorinv`(a[, ind])\n\nCompute the 'inverse' of an N-dimensional array.\n\n`linalg.LinAlgError`\n\nGeneric Python-exception-derived object raised by linalg functions.\n\nNew in version 1.8.0.\n\nSeveral of the linear algebra routines listed above are able to compute\nresults for several matrices at once, if they are stacked into the same array.\n\nThis is indicated in the documentation via input parameter specifications such\nas `a : (..., M, M) array_like`. This means that if for instance given an\ninput array `a.shape == (N, M, M)`, it is interpreted as a \u201cstack\u201d of N\nmatrices, each of size M-by-M. Similar specification applies to return values,\nfor instance the determinant has `det : (...)` and will in this case return an\narray of shape `det(a).shape == (N,)`. This generalizes to linear algebra\noperations on higher-dimensional arrays: the last 1 or 2 dimensions of a\nmultidimensional array are interpreted as vectors or matrices, as appropriate\nfor each operation.\n\n"}, {"name": "Logic functions", "path": "reference/routines.logic", "type": "Logic functions", "text": "\n`all`(a[, axis, out, keepdims, where])\n\nTest whether all array elements along a given axis evaluate to True.\n\n`any`(a[, axis, out, keepdims, where])\n\nTest whether any array element along a given axis evaluates to True.\n\n`isfinite`(x, /[, out, where, casting, order, ...])\n\nTest element-wise for finiteness (not infinity and not Not a Number).\n\n`isinf`(x, /[, out, where, casting, order, ...])\n\nTest element-wise for positive or negative infinity.\n\n`isnan`(x, /[, out, where, casting, order, ...])\n\nTest element-wise for NaN and return result as a boolean array.\n\n`isnat`(x, /[, out, where, casting, order, ...])\n\nTest element-wise for NaT (not a time) and return result as a boolean array.\n\n`isneginf`(x[, out])\n\nTest element-wise for negative infinity, return result as bool array.\n\n`isposinf`(x[, out])\n\nTest element-wise for positive infinity, return result as bool array.\n\n`iscomplex`(x)\n\nReturns a bool array, where True if input element is complex.\n\n`iscomplexobj`(x)\n\nCheck for a complex type or an array of complex numbers.\n\n`isfortran`(a)\n\nCheck if the array is Fortran contiguous but not C contiguous.\n\n`isreal`(x)\n\nReturns a bool array, where True if input element is real.\n\n`isrealobj`(x)\n\nReturn True if x is a not complex type or an array of complex numbers.\n\n`isscalar`(element)\n\nReturns True if the type of `element` is a scalar type.\n\n`logical_and`(x1, x2, /[, out, where, ...])\n\nCompute the truth value of x1 AND x2 element-wise.\n\n`logical_or`(x1, x2, /[, out, where, casting, ...])\n\nCompute the truth value of x1 OR x2 element-wise.\n\n`logical_not`(x, /[, out, where, casting, ...])\n\nCompute the truth value of NOT x element-wise.\n\n`logical_xor`(x1, x2, /[, out, where, ...])\n\nCompute the truth value of x1 XOR x2, element-wise.\n\n`allclose`(a, b[, rtol, atol, equal_nan])\n\nReturns True if two arrays are element-wise equal within a tolerance.\n\n`isclose`(a, b[, rtol, atol, equal_nan])\n\nReturns a boolean array where two arrays are element-wise equal within a\ntolerance.\n\n`array_equal`(a1, a2[, equal_nan])\n\nTrue if two arrays have the same shape and elements, False otherwise.\n\n`array_equiv`(a1, a2)\n\nReturns True if input arrays are shape consistent and all elements equal.\n\n`greater`(x1, x2, /[, out, where, casting, ...])\n\nReturn the truth value of (x1 > x2) element-wise.\n\n`greater_equal`(x1, x2, /[, out, where, ...])\n\nReturn the truth value of (x1 >= x2) element-wise.\n\n`less`(x1, x2, /[, out, where, casting, ...])\n\nReturn the truth value of (x1 < x2) element-wise.\n\n`less_equal`(x1, x2, /[, out, where, casting, ...])\n\nReturn the truth value of (x1 <= x2) element-wise.\n\n`equal`(x1, x2, /[, out, where, casting, ...])\n\nReturn (x1 == x2) element-wise.\n\n`not_equal`(x1, x2, /[, out, where, casting, ...])\n\nReturn (x1 != x2) element-wise.\n\n"}, {"name": "ma.all()", "path": "reference/generated/numpy.ma.all", "type": "numpy.ma.all", "text": "\nReturns True if all elements evaluate to True.\n\nThe output array is masked where all the values along the given axis are\nmasked: if the output would have been a scalar and that all the values are\nmasked, then the output is `masked`.\n\nRefer to `numpy.all` for full documentation.\n\nSee also\n\ncorresponding function for ndarrays\n\nequivalent function\n\n"}, {"name": "ma.allclose()", "path": "reference/generated/numpy.ma.allclose", "type": "numpy.ma.allclose", "text": "\nReturns True if two arrays are element-wise equal within a tolerance.\n\nThis function is equivalent to `allclose` except that masked values are\ntreated as equal (default) or unequal, depending on the `masked_equal`\nargument.\n\nInput arrays to compare.\n\nWhether masked values in `a` and `b` are considered equal (True) or not\n(False). They are considered equal by default.\n\nRelative tolerance. The relative difference is equal to `rtol * b`. Default is\n1e-5.\n\nAbsolute tolerance. The absolute difference is equal to `atol`. Default is\n1e-8.\n\nReturns True if the two arrays are equal within the given tolerance, False\notherwise. If either array contains NaN, then False is returned.\n\nSee also\n\nthe non-masked `allclose`.\n\nIf the following equation is element-wise True, then `allclose` returns True:\n\nReturn True if all elements of `a` and `b` are equal subject to given\ntolerances.\n\nMasked values are not compared directly.\n\n"}, {"name": "ma.allequal()", "path": "reference/generated/numpy.ma.allequal", "type": "numpy.ma.allequal", "text": "\nReturn True if all entries of a and b are equal, using fill_value as a truth\nvalue where either or both are masked.\n\nInput arrays to compare.\n\nWhether masked values in a or b are considered equal (True) or not (False).\n\nReturns True if the two arrays are equal within the given tolerance, False\notherwise. If either array contains NaN, then False is returned.\n\nSee also\n\n"}, {"name": "ma.anom()", "path": "reference/generated/numpy.ma.anom", "type": "numpy.ma.anom", "text": "\nCompute the anomalies (deviations from the arithmetic mean) along the given\naxis.\n\nReturns an array of anomalies, with the same shape as the input and where the\narithmetic mean is computed along the given axis.\n\nAxis over which the anomalies are taken. The default is to use the mean of the\nflattened array as reference.\n\nthe default is float32; for arrays of float types it is the same as the array\ntype.\n\nSee also\n\nCompute the mean of the array.\n\n"}, {"name": "ma.anomalies()", "path": "reference/generated/numpy.ma.anomalies", "type": "numpy.ma.anomalies", "text": "\nCompute the anomalies (deviations from the arithmetic mean) along the given\naxis.\n\nReturns an array of anomalies, with the same shape as the input and where the\narithmetic mean is computed along the given axis.\n\nAxis over which the anomalies are taken. The default is to use the mean of the\nflattened array as reference.\n\nthe default is float32; for arrays of float types it is the same as the array\ntype.\n\nSee also\n\nCompute the mean of the array.\n\n"}, {"name": "ma.any()", "path": "reference/generated/numpy.ma.any", "type": "numpy.ma.any", "text": "\nReturns True if any of the elements of `a` evaluate to True.\n\nMasked values are considered as False during computation.\n\nRefer to `numpy.any` for full documentation.\n\nSee also\n\ncorresponding function for ndarrays\n\nequivalent function\n\n"}, {"name": "ma.append()", "path": "reference/generated/numpy.ma.append", "type": "numpy.ma.append", "text": "\nAppend values to the end of an array.\n\nNew in version 1.9.0.\n\nValues are appended to a copy of this array.\n\nThese values are appended to a copy of `a`. It must be of the correct shape\n(the same shape as `a`, excluding `axis`). If `axis` is not specified, `b` can\nbe any shape and will be flattened before use.\n\nThe axis along which `v` are appended. If `axis` is not given, both `a` and\n`b` are flattened before use.\n\nA copy of `a` with `b` appended to `axis`. Note that `append` does not occur\nin-place: a new array is allocated and filled. If `axis` is None, the result\nis a flattened array.\n\nSee also\n\nEquivalent function in the top-level NumPy module.\n\n"}, {"name": "ma.apply_along_axis()", "path": "reference/generated/numpy.ma.apply_along_axis", "type": "numpy.ma.apply_along_axis", "text": "\nApply a function to 1-D slices along the given axis.\n\nExecute `func1d(a, *args, **kwargs)` where `func1d` operates on 1-D arrays and\n`a` is a 1-D slice of `arr` along `axis`.\n\nThis is equivalent to (but faster than) the following use of `ndindex` and\n`s_`, which sets each of `ii`, `jj`, and `kk` to a tuple of indices:\n\nEquivalently, eliminating the inner loop, this can be expressed as:\n\nThis function should accept 1-D arrays. It is applied to 1-D slices of `arr`\nalong the specified axis.\n\nAxis along which `arr` is sliced.\n\nInput array.\n\nAdditional arguments to `func1d`.\n\nAdditional named arguments to `func1d`.\n\nNew in version 1.9.0.\n\nThe output array. The shape of `out` is identical to the shape of `arr`,\nexcept along the `axis` dimension. This axis is removed, and replaced with new\ndimensions equal to the shape of the return value of `func1d`. So if `func1d`\nreturns a scalar `out` will have one fewer dimensions than `arr`.\n\nSee also\n\nApply a function repeatedly over multiple axes.\n\nFor a function that returns a 1D array, the number of dimensions in `outarr`\nis the same as `arr`.\n\nFor a function that returns a higher dimensional array, those dimensions are\ninserted in place of the `axis` dimension.\n\n"}, {"name": "ma.apply_over_axes()", "path": "reference/generated/numpy.ma.apply_over_axes", "type": "numpy.ma.apply_over_axes", "text": "\nApply a function repeatedly over multiple axes.\n\n`func` is called as `res = func(a, axis)`, where `axis` is the first element\nof `axes`. The result `res` of the function call must have either the same\ndimensions as `a` or one less dimension. If `res` has one less dimension than\n`a`, a dimension is inserted before `axis`. The call to `func` is then\nrepeated for each axis in `axes`, with `res` as the first argument.\n\nThis function must take two arguments, `func(a, axis)`.\n\nInput array.\n\nAxes over which `func` is applied; the elements must be integers.\n\nThe output array. The number of dimensions is the same as `a`, but the shape\ncan be different. This depends on whether `func` changes the shape of its\noutput with respect to its input.\n\nSee also\n\nApply a function to 1-D slices of an array along the given axis.\n\nTuple axis arguments to ufuncs are equivalent:\n\n"}, {"name": "ma.arange()", "path": "reference/generated/numpy.ma.arange", "type": "numpy.ma.arange", "text": "\nReturn evenly spaced values within a given interval.\n\nValues are generated within the half-open interval `[start, stop)` (in other\nwords, the interval including `start` but excluding `stop`). For integer\narguments the function is equivalent to the Python built-in `range` function,\nbut returns an ndarray rather than a list.\n\nWhen using a non-integer step, such as 0.1, it is often better to use\n`numpy.linspace`. See the warnings section below for more information.\n\nStart of interval. The interval includes this value. The default start value\nis 0.\n\nEnd of interval. The interval does not include this value, except in some\ncases where `step` is not an integer and floating point round-off affects the\nlength of `out`.\n\nSpacing between values. For any output `out`, this is the distance between two\nadjacent values, `out[i+1] - out[i]`. The default step size is 1. If `step` is\nspecified as a position argument, `start` must also be given.\n\nThe type of the output array. If `dtype` is not given, infer the data type\nfrom the other input arguments.\n\nReference object to allow the creation of arrays which are not NumPy arrays.\nIf an array-like passed in as `like` supports the `__array_function__`\nprotocol, the result will be defined by it. In this case, it ensures the\ncreation of an array object compatible with that passed in via this argument.\n\nNew in version 1.20.0.\n\nArray of evenly spaced values.\n\nFor floating point arguments, the length of the result is `ceil((stop -\nstart)/step)`. Because of floating point overflow, this rule may result in the\nlast element of `out` being greater than `stop`.\n\nWarning\n\nThe length of the output might not be numerically stable.\n\nAnother stability issue is due to the internal implementation of\n`numpy.arange`. The actual step value used to populate the array is\n`dtype(start + step) - dtype(start)` and not `step`. Precision loss can occur\nhere, due to casting or due to using floating points when `start` is much\nlarger than `step`. This can lead to unexpected behaviour. For example:\n\nIn such cases, the use of `numpy.linspace` should be preferred.\n\nSee also\n\nEvenly spaced numbers with careful handling of endpoints.\n\nArrays of evenly spaced numbers in N-dimensions.\n\nGrid-shaped arrays of evenly spaced numbers in N-dimensions.\n\n"}, {"name": "ma.argmax()", "path": "reference/generated/numpy.ma.argmax", "type": "numpy.ma.argmax", "text": "\nReturns array of indices of the maximum values along the given axis. Masked\nvalues are treated as if they had the value fill_value.\n\nIf None, the index is into the flattened array, otherwise along the specified\naxis\n\nValue used to fill in the masked values. If None, the output of\nmaximum_fill_value(self._data) is used instead.\n\nArray into which the result can be placed. Its type is preserved and it must\nbe of the right shape to hold the output.\n\n"}, {"name": "ma.argmin()", "path": "reference/generated/numpy.ma.argmin", "type": "numpy.ma.argmin", "text": "\nReturn array of indices to the minimum values along the given axis.\n\nIf None, the index is into the flattened array, otherwise along the specified\naxis\n\nValue used to fill in the masked values. If None, the output of\nminimum_fill_value(self._data) is used instead.\n\nArray into which the result can be placed. Its type is preserved and it must\nbe of the right shape to hold the output.\n\nIf multi-dimension input, returns a new ndarray of indices to the minimum\nvalues along the given axis. Otherwise, returns a scalar of index to the\nminimum values along the given axis.\n\n"}, {"name": "ma.argsort()", "path": "reference/generated/numpy.ma.argsort", "type": "numpy.ma.argsort", "text": "\nReturn an ndarray of indices that sort the array along the specified axis.\nMasked values are filled beforehand to `fill_value`.\n\nAxis along which to sort. If None, the default, the flattened array is used.\n\nChanged in version 1.13.0: Previously, the default was documented to be -1,\nbut that was in error. At some future date, the default will change to -1, as\noriginally intended. Until then, the axis should be given explicitly when\n`arr.ndim > 1`, to avoid a FutureWarning.\n\nThe sorting algorithm used.\n\nWhen `a` is an array with fields defined, this argument specifies which fields\nto compare first, second, etc. Not all fields need be specified.\n\nWhether missing values (if any) should be treated as the largest values (True)\nor the smallest values (False) When the array contains unmasked values at the\nsame extremes of the datatype, the ordering of these values and the masked\nvalues is undefined.\n\nValue used internally for the masked values. If `fill_value` is not None, it\nsupersedes `endwith`.\n\nArray of indices that sort `a` along the specified axis. In other words,\n`a[index_array]` yields a sorted `a`.\n\nSee also\n\nDescribes sorting algorithms used.\n\nIndirect stable sort with multiple keys.\n\nInplace sort.\n\nSee `sort` for notes on the different sorting algorithms.\n\n"}, {"name": "ma.around", "path": "reference/generated/numpy.ma.around", "type": "numpy.ma.around", "text": "\nRound an array to the given number of decimals.\n\nSee also\n\nequivalent function; see for details.\n\n"}, {"name": "ma.array()", "path": "reference/generated/numpy.ma.array", "type": "numpy.ma.array", "text": "\nAn array class with possibly masked values.\n\nMasked values of True exclude the corresponding element from any computation.\n\nConstruction:\n\nInput data.\n\nMask. Must be convertible to an array of booleans with the same shape as\n`data`. True indicates a masked (i.e. invalid) data.\n\nData type of the output. If `dtype` is None, the type of the data argument\n(`data.dtype`) is used. If `dtype` is not None and different from\n`data.dtype`, a copy is performed.\n\nWhether to copy the input data (True), or to use a reference instead. Default\nis False.\n\nWhether to return a subclass of `MaskedArray` if possible (True) or a plain\n`MaskedArray`. Default is True.\n\nMinimum number of dimensions. Default is 0.\n\nValue used to fill in the masked values when necessary. If None, a default\nbased on the data-type is used.\n\nWhether to combine `mask` with the mask of the input data, if any (True), or\nto use only `mask` for the output (False). Default is True.\n\nWhether to use a hard mask or not. With a hard mask, masked values cannot be\nunmasked. Default is False.\n\nWhether to force compression of an empty mask. Default is True.\n\nSpecify the order of the array. If order is \u2018C\u2019, then the array will be in\nC-contiguous order (last-index varies the fastest). If order is \u2018F\u2019, then the\nreturned array will be in Fortran-contiguous order (first-index varies the\nfastest). If order is \u2018A\u2019 (default), then the returned array may be in any\norder (either C-, Fortran-contiguous, or even discontiguous), unless a copy is\nrequired, in which case it will be C-contiguous.\n\nThe `mask` can be initialized with an array of boolean values with the same\nshape as `data`.\n\nAlternatively, the `mask` can be initialized to homogeneous boolean array with\nthe same shape as `data` by passing in a scalar boolean value:\n\nNote\n\nThe recommended practice for initializing `mask` with a scalar boolean value\nis to use `True`/`False` rather than `np.True_`/`np.False_`. The reason is\n`nomask` is represented internally as `np.False_`.\n\n"}, {"name": "ma.asanyarray()", "path": "reference/generated/numpy.ma.asanyarray", "type": "numpy.ma.asanyarray", "text": "\nConvert the input to a masked array, conserving subclasses.\n\nIf `a` is a subclass of `MaskedArray`, its class is conserved. No copy is\nperformed if the input is already an `ndarray`.\n\nInput data, in any form that can be converted to an array.\n\nBy default, the data-type is inferred from the input data.\n\nWhether to use row-major (\u2018C\u2019) or column-major (\u2018FORTRAN\u2019) memory\nrepresentation. Default is \u2018C\u2019.\n\nMaskedArray interpretation of `a`.\n\nSee also\n\nSimilar to `asanyarray`, but does not conserve subclass.\n\n"}, {"name": "ma.asarray()", "path": "reference/generated/numpy.ma.asarray", "type": "numpy.ma.asarray", "text": "\nConvert the input to a masked array of the given data-type.\n\nNo copy is performed if the input is already an `ndarray`. If `a` is a\nsubclass of `MaskedArray`, a base class `MaskedArray` is returned.\n\nInput data, in any form that can be converted to a masked array. This includes\nlists, lists of tuples, tuples, tuples of tuples, tuples of lists, ndarrays\nand masked arrays.\n\nBy default, the data-type is inferred from the input data.\n\nWhether to use row-major (\u2018C\u2019) or column-major (\u2018FORTRAN\u2019) memory\nrepresentation. Default is \u2018C\u2019.\n\nMasked array interpretation of `a`.\n\nSee also\n\nSimilar to `asarray`, but conserves subclasses.\n\n"}, {"name": "ma.atleast_1d()", "path": "reference/generated/numpy.ma.atleast_1d", "type": "numpy.ma.atleast_1d", "text": "\nConvert inputs to arrays with at least one dimension.\n\nScalar inputs are converted to 1-dimensional arrays, whilst higher-dimensional\ninputs are preserved.\n\nOne or more input arrays.\n\nAn array, or list of arrays, each with `a.ndim >= 1`. Copies are made only if\nnecessary.\n\nSee also\n\nThe function is applied to both the _data and the _mask, if any.\n\n"}, {"name": "ma.atleast_2d()", "path": "reference/generated/numpy.ma.atleast_2d", "type": "numpy.ma.atleast_2d", "text": "\nView inputs as arrays with at least two dimensions.\n\nOne or more array-like sequences. Non-array inputs are converted to arrays.\nArrays that already have two or more dimensions are preserved.\n\nAn array, or list of arrays, each with `a.ndim >= 2`. Copies are avoided where\npossible, and views with two or more dimensions are returned.\n\nSee also\n\nThe function is applied to both the _data and the _mask, if any.\n\n"}, {"name": "ma.atleast_3d()", "path": "reference/generated/numpy.ma.atleast_3d", "type": "numpy.ma.atleast_3d", "text": "\nView inputs as arrays with at least three dimensions.\n\nOne or more array-like sequences. Non-array inputs are converted to arrays.\nArrays that already have three or more dimensions are preserved.\n\nAn array, or list of arrays, each with `a.ndim >= 3`. Copies are avoided where\npossible, and views with three or more dimensions are returned. For example, a\n1-D array of shape `(N,)` becomes a view of shape `(1, N, 1)`, and a 2-D array\nof shape `(M, N)` becomes a view of shape `(M, N, 1)`.\n\nSee also\n\nThe function is applied to both the _data and the _mask, if any.\n\n"}, {"name": "ma.average()", "path": "reference/generated/numpy.ma.average", "type": "numpy.ma.average", "text": "\nReturn the weighted average of array over the given axis.\n\nData to be averaged. Masked entries are not taken into account in the\ncomputation.\n\nAxis along which to average `a`. If None, averaging is done over the flattened\narray.\n\nThe importance that each element has in the computation of the average. The\nweights array can either be 1-D (in which case its length must be the size of\n`a` along the given axis) or of the same shape as `a`. If `weights=None`, then\nall data in `a` are assumed to have a weight equal to one. The 1-D calculation\nis:\n\nThe only constraint on `weights` is that `sum(weights)` must not be 0.\n\nFlag indicating whether a tuple `(result, sum of weights)` should be returned\nas output (True), or just the result (False). Default is False.\n\nThe average along the specified axis. When returned is `True`, return a tuple\nwith the average as the first element and the sum of the weights as the second\nelement. The return type is `np.float64` if `a` is of integer type and floats\nsmaller than `float64`, or the input data-type, otherwise. If returned,\n`sum_of_weights` is always `float64`.\n\n"}, {"name": "ma.choose()", "path": "reference/generated/numpy.ma.choose", "type": "numpy.ma.choose", "text": "\nUse an index array to construct a new array from a list of choices.\n\nGiven an array of integers and a list of n choice arrays, this method will\ncreate a new array that merges each of the choice arrays. Where a value in\n`index` is i, the new array will have the value that choices[i] contains in\nthe same place.\n\nThis array must contain integers in `[0, n-1]`, where n is the number of\nchoices.\n\nChoice arrays. The index array and all of the choices should be broadcastable\nto the same shape.\n\nIf provided, the result will be inserted into this array. It should be of the\nappropriate shape and `dtype`.\n\nSpecifies how out-of-bounds indices will behave.\n\nSee also\n\nequivalent function\n\n"}, {"name": "ma.clip()", "path": "reference/generated/numpy.ma.clip", "type": "numpy.ma.clip", "text": "\nClip (limit) the values in an array.\n\nGiven an interval, values outside the interval are clipped to the interval\nedges. For example, if an interval of `[0, 1]` is specified, values smaller\nthan 0 become 0, and values larger than 1 become 1.\n\nEquivalent to but faster than `np.minimum(a_max, np.maximum(a, a_min))`.\n\nNo check is performed to ensure `a_min < a_max`.\n\nArray containing elements to clip.\n\nMinimum and maximum value. If `None`, clipping is not performed on the\ncorresponding edge. Only one of `a_min` and `a_max` may be `None`. Both are\nbroadcast against `a`.\n\nThe results will be placed in this array. It may be the input array for in-\nplace clipping. `out` must be of the right shape to hold the output. Its type\nis preserved.\n\nFor other keyword-only arguments, see the ufunc docs.\n\nNew in version 1.17.0.\n\nAn array with the elements of `a`, but where values < `a_min` are replaced\nwith `a_min`, and those > `a_max` with `a_max`.\n\nSee also\n\nWhen `a_min` is greater than `a_max`, `clip` returns an array in which all\nvalues are equal to `a_max`, as shown in the second example.\n\n"}, {"name": "ma.clump_masked()", "path": "reference/generated/numpy.ma.clump_masked", "type": "numpy.ma.clump_masked", "text": "\nReturns a list of slices corresponding to the masked clumps of a 1-D array. (A\n\u201cclump\u201d is defined as a contiguous region of the array).\n\nA one-dimensional masked array.\n\nThe list of slices, one for each continuous region of masked elements in `a`.\n\nSee also\n\nNew in version 1.4.0.\n\n"}, {"name": "ma.clump_unmasked()", "path": "reference/generated/numpy.ma.clump_unmasked", "type": "numpy.ma.clump_unmasked", "text": "\nReturn list of slices corresponding to the unmasked clumps of a 1-D array. (A\n\u201cclump\u201d is defined as a contiguous region of the array).\n\nA one-dimensional masked array.\n\nThe list of slices, one for each continuous region of unmasked elements in\n`a`.\n\nSee also\n\nNew in version 1.4.0.\n\n"}, {"name": "ma.column_stack()", "path": "reference/generated/numpy.ma.column_stack", "type": "numpy.ma.column_stack", "text": "\nStack 1-D arrays as columns into a 2-D array.\n\nTake a sequence of 1-D arrays and stack them as columns to make a single 2-D\narray. 2-D arrays are stacked as-is, just like with `hstack`. 1-D arrays are\nturned into 2-D columns first.\n\nArrays to stack. All of them must have the same first dimension.\n\nThe array formed by stacking the given arrays.\n\nSee also\n\nThe function is applied to both the _data and the _mask, if any.\n\n"}, {"name": "ma.common_fill_value()", "path": "reference/generated/numpy.ma.common_fill_value", "type": "numpy.ma.common_fill_value", "text": "\nReturn the common filling value of two masked arrays, if any.\n\nIf `a.fill_value == b.fill_value`, return the fill value, otherwise return\nNone.\n\nThe masked arrays for which to compare fill values.\n\nThe common fill value, or None.\n\n"}, {"name": "ma.compress_cols()", "path": "reference/generated/numpy.ma.compress_cols", "type": "numpy.ma.compress_cols", "text": "\nSuppress whole columns of a 2-D array that contain masked values.\n\nThis is equivalent to `np.ma.compress_rowcols(a, 1)`, see `compress_rowcols`\nfor details.\n\nSee also\n\n"}, {"name": "ma.compress_rowcols()", "path": "reference/generated/numpy.ma.compress_rowcols", "type": "numpy.ma.compress_rowcols", "text": "\nSuppress the rows and/or columns of a 2-D array that contain masked values.\n\nThe suppression behavior is selected with the `axis` parameter.\n\nThe array to operate on. If not a MaskedArray instance (or if no array\nelements are masked), `x` is interpreted as a MaskedArray with `mask` set to\n`nomask`. Must be a 2D array.\n\nAxis along which to perform the operation. Default is None.\n\nThe compressed array.\n\n"}, {"name": "ma.compress_rows()", "path": "reference/generated/numpy.ma.compress_rows", "type": "numpy.ma.compress_rows", "text": "\nSuppress whole rows of a 2-D array that contain masked values.\n\nThis is equivalent to `np.ma.compress_rowcols(a, 0)`, see `compress_rowcols`\nfor details.\n\nSee also\n\n"}, {"name": "ma.compressed()", "path": "reference/generated/numpy.ma.compressed", "type": "numpy.ma.compressed", "text": "\nReturn all the non-masked data as a 1-D array.\n\nThis function is equivalent to calling the \u201ccompressed\u201d method of a\n`ma.MaskedArray`, see `ma.MaskedArray.compressed` for details.\n\nSee also\n\nEquivalent method.\n\n"}, {"name": "ma.concatenate()", "path": "reference/generated/numpy.ma.concatenate", "type": "numpy.ma.concatenate", "text": "\nConcatenate a sequence of arrays along the given axis.\n\nThe arrays must have the same shape, except in the dimension corresponding to\n`axis` (the first, by default).\n\nThe axis along which the arrays will be joined. Default is 0.\n\nThe concatenated array with any masked entries preserved.\n\nSee also\n\nEquivalent function in the top-level NumPy module.\n\n"}, {"name": "ma.conjugate()", "path": "reference/generated/numpy.ma.conjugate", "type": "numpy.ma.conjugate", "text": "\nReturn the complex conjugate, element-wise.\n\nThe complex conjugate of a complex number is obtained by changing the sign of\nits imaginary part.\n\nInput value.\n\nA location into which the result is stored. If provided, it must have a shape\nthat the inputs broadcast to. If not provided or None, a freshly-allocated\narray is returned. A tuple (possible only as a keyword argument) must have\nlength equal to the number of outputs.\n\nThis condition is broadcast over the input. At locations where the condition\nis True, the `out` array will be set to the ufunc result. Elsewhere, the `out`\narray will retain its original value. Note that if an uninitialized `out`\narray is created via the default `out=None`, locations within it where the\ncondition is False will remain uninitialized.\n\nFor other keyword-only arguments, see the ufunc docs.\n\nThe complex conjugate of `x`, with same dtype as `y`. This is a scalar if `x`\nis a scalar.\n\n`conj` is an alias for `conjugate`:\n\n"}, {"name": "ma.copy()", "path": "reference/generated/numpy.ma.copy", "type": "numpy.ma.copy", "text": "\nReturn a copy of the array.\n\nControls the memory layout of the copy. \u2018C\u2019 means C-order, \u2018F\u2019 means F-order,\n\u2018A\u2019 means \u2018F\u2019 if `a` is Fortran contiguous, \u2018C\u2019 otherwise. \u2018K\u2019 means match the\nlayout of `a` as closely as possible. (Note that this function and\n`numpy.copy` are very similar but have different default values for their\norder= arguments, and this function always passes sub-classes through.)\n\nSee also\n\nSimilar function with different default behavior numpy.copyto\n\nThis function is the preferred method for creating an array copy. The function\n`numpy.copy` is similar, but it defaults to using order \u2018K\u2019, and will not pass\nsub-classes through by default.\n\n"}, {"name": "ma.corrcoef()", "path": "reference/generated/numpy.ma.corrcoef", "type": "numpy.ma.corrcoef", "text": "\nReturn Pearson product-moment correlation coefficients.\n\nExcept for the handling of missing data this function does the same as\n`numpy.corrcoef`. For more details and examples, see `numpy.corrcoef`.\n\nA 1-D or 2-D array containing multiple variables and observations. Each row of\n`x` represents a variable, and each column a single observation of all those\nvariables. Also see `rowvar` below.\n\nAn additional set of variables and observations. `y` has the same shape as\n`x`.\n\nIf `rowvar` is True (default), then each row represents a variable, with\nobservations in the columns. Otherwise, the relationship is transposed: each\ncolumn represents a variable, while the rows contain observations.\n\nHas no effect, do not use.\n\nDeprecated since version 1.10.0.\n\nIf True, masked values are propagated pair-wise: if a value is masked in `x`,\nthe corresponding value is masked in `y`. If False, raises an exception.\nBecause `bias` is deprecated, this argument needs to be treated as keyword\nonly to avoid a warning.\n\nHas no effect, do not use.\n\nDeprecated since version 1.10.0.\n\nSee also\n\nEquivalent function in top-level NumPy module.\n\nEstimate the covariance matrix.\n\nThis function accepts but discards arguments `bias` and `ddof`. This is for\nbackwards compatibility with previous versions of this function. These\narguments had no effect on the return values of the function and can be safely\nignored in this and previous versions of numpy.\n\n"}, {"name": "ma.count()", "path": "reference/generated/numpy.ma.count", "type": "numpy.ma.count", "text": "\nCount the non-masked elements of the array along the given axis.\n\nAxis or axes along which the count is performed. The default, None, performs\nthe count over all the dimensions of the input array. `axis` may be negative,\nin which case it counts from the last to the first axis.\n\nNew in version 1.10.0.\n\nIf this is a tuple of ints, the count is performed on multiple axes, instead\nof a single axis or all the axes as before.\n\nIf this is set to True, the axes which are reduced are left in the result as\ndimensions with size one. With this option, the result will broadcast\ncorrectly against the array.\n\nAn array with the same shape as the input array, with the specified axis\nremoved. If the array is a 0-d array, or if `axis` is None, a scalar is\nreturned.\n\nSee also\n\nCount masked elements in array or along a given axis.\n\nWhen the `axis` keyword is specified an array of appropriate size is returned.\n\n"}, {"name": "ma.count_masked()", "path": "reference/generated/numpy.ma.count_masked", "type": "numpy.ma.count_masked", "text": "\nCount the number of masked elements along the given axis.\n\nAn array with (possibly) masked elements.\n\nAxis along which to count. If None (default), a flattened version of the array\nis used.\n\nThe total number of masked elements (axis=None) or the number of masked\nelements along each slice of the given axis.\n\nSee also\n\nCount non-masked elements.\n\nWhen the `axis` keyword is used an array is returned.\n\n"}, {"name": "ma.cov()", "path": "reference/generated/numpy.ma.cov", "type": "numpy.ma.cov", "text": "\nEstimate the covariance matrix.\n\nExcept for the handling of missing data this function does the same as\n`numpy.cov`. For more details and examples, see `numpy.cov`.\n\nBy default, masked values are recognized as such. If `x` and `y` have the same\nshape, a common mask is allocated: if `x[i,j]` is masked, then `y[i,j]` will\nalso be masked. Setting `allow_masked` to False will raise an exception if\nvalues are missing in either of the input arrays.\n\nA 1-D or 2-D array containing multiple variables and observations. Each row of\n`x` represents a variable, and each column a single observation of all those\nvariables. Also see `rowvar` below.\n\nAn additional set of variables and observations. `y` has the same shape as\n`x`.\n\nIf `rowvar` is True (default), then each row represents a variable, with\nobservations in the columns. Otherwise, the relationship is transposed: each\ncolumn represents a variable, while the rows contain observations.\n\nDefault normalization (False) is by `(N-1)`, where `N` is the number of\nobservations given (unbiased estimate). If `bias` is True, then normalization\nis by `N`. This keyword can be overridden by the keyword `ddof` in numpy\nversions >= 1.5.\n\nIf True, masked values are propagated pair-wise: if a value is masked in `x`,\nthe corresponding value is masked in `y`. If False, raises a `ValueError`\nexception when some values are missing.\n\nIf not `None` normalization is by `(N - ddof)`, where `N` is the number of\nobservations; this overrides the value implied by `bias`. The default value is\n`None`.\n\nNew in version 1.5.\n\nRaised if some values are missing and `allow_masked` is False.\n\nSee also\n\n"}, {"name": "ma.cumprod()", "path": "reference/generated/numpy.ma.cumprod", "type": "numpy.ma.cumprod", "text": "\nReturn the cumulative product of the array elements over the given axis.\n\nMasked values are set to 1 internally during the computation. However, their\nposition is saved, and the result will be masked at the same locations.\n\nRefer to `numpy.cumprod` for full documentation.\n\nSee also\n\ncorresponding function for ndarrays\n\nequivalent function\n\nThe mask is lost if `out` is not a valid MaskedArray !\n\nArithmetic is modular when using integer types, and no error is raised on\noverflow.\n\n"}, {"name": "ma.cumsum()", "path": "reference/generated/numpy.ma.cumsum", "type": "numpy.ma.cumsum", "text": "\nReturn the cumulative sum of the array elements over the given axis.\n\nMasked values are set to 0 internally during the computation. However, their\nposition is saved, and the result will be masked at the same locations.\n\nRefer to `numpy.cumsum` for full documentation.\n\nSee also\n\ncorresponding function for ndarrays\n\nequivalent function\n\nThe mask is lost if `out` is not a valid `ma.MaskedArray` !\n\nArithmetic is modular when using integer types, and no error is raised on\noverflow.\n\n"}, {"name": "ma.default_fill_value()", "path": "reference/generated/numpy.ma.default_fill_value", "type": "numpy.ma.default_fill_value", "text": "\nReturn the default fill value for the argument object.\n\nThe default filling value depends on the datatype of the input array or the\ntype of the input scalar:\n\ndatatype\n\ndefault\n\nbool\n\nTrue\n\nint\n\n999999\n\nfloat\n\n1.e20\n\ncomplex\n\n1.e20+0j\n\nobject\n\n\u2018?\u2019\n\nstring\n\n\u2018N/A\u2019\n\nFor structured types, a structured scalar is returned, with each field the\ndefault fill value for its type.\n\nFor subarray types, the fill value is an array of the same size containing the\ndefault scalar fill value.\n\nThe array data-type or scalar for which the default fill value is returned.\n\nThe default fill value.\n\n"}, {"name": "ma.diag()", "path": "reference/generated/numpy.ma.diag", "type": "numpy.ma.diag", "text": "\nExtract a diagonal or construct a diagonal array.\n\nThis function is the equivalent of `numpy.diag` that takes masked values into\naccount, see `numpy.diag` for details.\n\nSee also\n\nEquivalent function for ndarrays.\n\n"}, {"name": "ma.diff()", "path": "reference/generated/numpy.ma.diff", "type": "numpy.ma.diff", "text": "\nCalculate the n-th discrete difference along the given axis.\n\nThe first difference is given by `out[i] = a[i+1] - a[i]` along the given\naxis, higher differences are calculated by using `diff` recursively.\n\nInput array\n\nThe number of times values are differenced. If zero, the input is returned as-\nis.\n\nThe axis along which the difference is taken, default is the last axis.\n\nValues to prepend or append to `a` along axis prior to performing the\ndifference. Scalar values are expanded to arrays with length 1 in the\ndirection of axis and the shape of the input array in along all other axes.\nOtherwise the dimension and shape must match `a` except along axis.\n\nNew in version 1.16.0.\n\nThe n-th differences. The shape of the output is the same as `a` except along\n`axis` where the dimension is smaller by `n`. The type of the output is the\nsame as the type of the difference between any two elements of `a`. This is\nthe same as the type of `a` in most cases. A notable exception is\n`datetime64`, which results in a `timedelta64` output array.\n\nSee also\n\nType is preserved for boolean arrays, so the result will contain `False` when\nconsecutive elements are the same and `True` when they differ.\n\nFor unsigned integer arrays, the results will also be unsigned. This should\nnot be surprising, as the result is consistent with calculating the difference\ndirectly:\n\nIf this is not desirable, then the array should be cast to a larger integer\ntype first:\n\n"}, {"name": "ma.dot()", "path": "reference/generated/numpy.ma.dot", "type": "numpy.ma.dot", "text": "\nReturn the dot product of two arrays.\n\nThis function is the equivalent of `numpy.dot` that takes masked values into\naccount. Note that `strict` and `out` are in different position than in the\nmethod version. In order to maintain compatibility with the corresponding\nmethod, it is recommended that the optional arguments be treated as keyword\nonly. At some point that may be mandatory.\n\nNote\n\nWorks only with 2-D arrays at the moment.\n\nInputs arrays.\n\nWhether masked data are propagated (True) or set to 0 (False) for the\ncomputation. Default is False. Propagating the mask means that if a masked\nvalue appears in a row or column, the whole row or column is considered\nmasked.\n\nOutput argument. This must have the exact kind that would be returned if it\nwas not used. In particular, it must have the right type, must be\nC-contiguous, and its dtype must be the dtype that would be returned for\n`dot(a,b)`. This is a performance feature. Therefore, if these conditions are\nnot met, an exception is raised, instead of attempting to be flexible.\n\nNew in version 1.10.2.\n\nSee also\n\nEquivalent function for ndarrays.\n\n"}, {"name": "ma.dstack()", "path": "reference/generated/numpy.ma.dstack", "type": "numpy.ma.dstack", "text": "\nStack arrays in sequence depth wise (along third axis).\n\nThis is equivalent to concatenation along the third axis after 2-D arrays of\nshape `(M,N)` have been reshaped to `(M,N,1)` and 1-D arrays of shape `(N,)`\nhave been reshaped to `(1,N,1)`. Rebuilds arrays divided by `dsplit`.\n\nThis function makes most sense for arrays with up to 3 dimensions. For\ninstance, for pixel-data with a height (first axis), width (second axis), and\nr/g/b channels (third axis). The functions `concatenate`, `stack` and `block`\nprovide more general stacking and concatenation operations.\n\nThe arrays must have the same shape along all but the third axis. 1-D or 2-D\narrays must have the same shape.\n\nThe array formed by stacking the given arrays, will be at least 3-D.\n\nSee also\n\nJoin a sequence of arrays along an existing axis.\n\nJoin a sequence of arrays along a new axis.\n\nAssemble an nd-array from nested lists of blocks.\n\nStack arrays in sequence vertically (row wise).\n\nStack arrays in sequence horizontally (column wise).\n\nStack 1-D arrays as columns into a 2-D array.\n\nSplit array along third axis.\n\nThe function is applied to both the _data and the _mask, if any.\n\n"}, {"name": "ma.ediff1d()", "path": "reference/generated/numpy.ma.ediff1d", "type": "numpy.ma.ediff1d", "text": "\nCompute the differences between consecutive elements of an array.\n\nThis function is the equivalent of `numpy.ediff1d` that takes masked values\ninto account, see `numpy.ediff1d` for details.\n\nSee also\n\nEquivalent function for ndarrays.\n\n"}, {"name": "ma.empty()", "path": "reference/generated/numpy.ma.empty", "type": "numpy.ma.empty", "text": "\nReturn a new array of given shape and type, without initializing entries.\n\nShape of the empty array, e.g., `(2, 3)` or `2`.\n\nDesired output data-type for the array, e.g, `numpy.int8`. Default is\n`numpy.float64`.\n\nWhether to store multi-dimensional data in row-major (C-style) or column-major\n(Fortran-style) order in memory.\n\nReference object to allow the creation of arrays which are not NumPy arrays.\nIf an array-like passed in as `like` supports the `__array_function__`\nprotocol, the result will be defined by it. In this case, it ensures the\ncreation of an array object compatible with that passed in via this argument.\n\nNew in version 1.20.0.\n\nArray of uninitialized (arbitrary) data of the given shape, dtype, and order.\nObject arrays will be initialized to None.\n\nSee also\n\nReturn an empty array with shape and type of input.\n\nReturn a new array setting values to one.\n\nReturn a new array setting values to zero.\n\nReturn a new array of given shape filled with value.\n\n`empty`, unlike `zeros`, does not set the array values to zero, and may\ntherefore be marginally faster. On the other hand, it requires the user to\nmanually set all the values in the array, and should be used with caution.\n\n"}, {"name": "ma.empty_like()", "path": "reference/generated/numpy.ma.empty_like", "type": "numpy.ma.empty_like", "text": "\nReturn a new array with the same shape and type as a given array.\n\nThe shape and data-type of `prototype` define these same attributes of the\nreturned array.\n\nOverrides the data type of the result.\n\nNew in version 1.6.0.\n\nOverrides the memory layout of the result. \u2018C\u2019 means C-order, \u2018F\u2019 means\nF-order, \u2018A\u2019 means \u2018F\u2019 if `prototype` is Fortran contiguous, \u2018C\u2019 otherwise.\n\u2018K\u2019 means match the layout of `prototype` as closely as possible.\n\nNew in version 1.6.0.\n\nIf True, then the newly created array will use the sub-class type of\n`prototype`, otherwise it will be a base-class array. Defaults to True.\n\nOverrides the shape of the result. If order=\u2019K\u2019 and the number of dimensions\nis unchanged, will try to keep order, otherwise, order=\u2019C\u2019 is implied.\n\nNew in version 1.17.0.\n\nArray of uninitialized (arbitrary) data with the same shape and type as\n`prototype`.\n\nSee also\n\nReturn an array of ones with shape and type of input.\n\nReturn an array of zeros with shape and type of input.\n\nReturn a new array with shape of input filled with value.\n\nReturn a new uninitialized array.\n\nThis function does not initialize the returned array; to do that use\n`zeros_like` or `ones_like` instead. It may be marginally faster than the\nfunctions that do set the array values.\n\n"}, {"name": "ma.expand_dims()", "path": "reference/generated/numpy.ma.expand_dims", "type": "numpy.ma.expand_dims", "text": "\nExpand the shape of an array.\n\nInsert a new axis that will appear at the `axis` position in the expanded\narray shape.\n\nInput array.\n\nPosition in the expanded axes where the new axis (or axes) is placed.\n\nDeprecated since version 1.13.0: Passing an axis where `axis > a.ndim` will be\ntreated as `axis == a.ndim`, and passing `axis < -a.ndim - 1` will be treated\nas `axis == 0`. This behavior is deprecated.\n\nChanged in version 1.18.0: A tuple of axes is now supported. Out of range axes\nas described above are now forbidden and raise an `AxisError`.\n\nView of `a` with the number of dimensions increased.\n\nSee also\n\nThe inverse operation, removing singleton dimensions\n\nInsert, remove, and combine dimensions, and resize existing ones\n\nThe following is equivalent to `x[np.newaxis, :]` or `x[np.newaxis]`:\n\nThe following is equivalent to `x[:, np.newaxis]`:\n\n`axis` may also be a tuple:\n\nNote that some examples may use `None` instead of `np.newaxis`. These are the\nsame objects:\n\n"}, {"name": "ma.filled()", "path": "reference/generated/numpy.ma.filled", "type": "numpy.ma.filled", "text": "\nReturn input as an array with masked data replaced by a fill value.\n\nIf `a` is not a `MaskedArray`, `a` itself is returned. If `a` is a\n`MaskedArray` and `fill_value` is None, `fill_value` is set to `a.fill_value`.\n\nAn input object.\n\nCan be scalar or non-scalar. If non-scalar, the resulting filled array should\nbe broadcastable over input array. Default is None.\n\nThe filled array.\n\nSee also\n\n"}, {"name": "ma.fix_invalid()", "path": "reference/generated/numpy.ma.fix_invalid", "type": "numpy.ma.fix_invalid", "text": "\nReturn input with invalid data masked and replaced by a fill value.\n\nInvalid data means values of `nan`, `inf`, etc.\n\nInput array, a (subclass of) ndarray.\n\nMask. Must be convertible to an array of booleans with the same shape as\n`data`. True indicates a masked (i.e. invalid) data.\n\nWhether to use a copy of `a` (True) or to fix `a` in place (False). Default is\nTrue.\n\nValue used for fixing invalid data. Default is None, in which case the\n`a.fill_value` is used.\n\nThe input array with invalid entries fixed.\n\nA copy is performed by default.\n\n"}, {"name": "ma.flatnotmasked_contiguous()", "path": "reference/generated/numpy.ma.flatnotmasked_contiguous", "type": "numpy.ma.flatnotmasked_contiguous", "text": "\nFind contiguous unmasked data in a masked array along the given axis.\n\nThe input array.\n\nA sorted sequence of `slice` objects (start index, end index).\n\nChanged in version 1.15.0: Now returns an empty list instead of None for a\nfully masked array\n\nSee also\n\nOnly accepts 2-D arrays at most.\n\n"}, {"name": "ma.flatnotmasked_edges()", "path": "reference/generated/numpy.ma.flatnotmasked_edges", "type": "numpy.ma.flatnotmasked_edges", "text": "\nFind the indices of the first and last unmasked values.\n\nExpects a 1-D `MaskedArray`, returns None if all values are masked.\n\nInput 1-D `MaskedArray`\n\nThe indices of first and last non-masked value in the array. Returns None if\nall values are masked.\n\nSee also\n\nOnly accepts 1-D arrays.\n\n"}, {"name": "ma.frombuffer()", "path": "reference/generated/numpy.ma.frombuffer", "type": "numpy.ma.frombuffer", "text": "\nInterpret a buffer as a 1-dimensional array.\n\nAn object that exposes the buffer interface.\n\nData-type of the returned array; default: float.\n\nNumber of items to read. `-1` means all data in the buffer.\n\nStart reading the buffer from this offset (in bytes); default: 0.\n\nReference object to allow the creation of arrays which are not NumPy arrays.\nIf an array-like passed in as `like` supports the `__array_function__`\nprotocol, the result will be defined by it. In this case, it ensures the\ncreation of an array object compatible with that passed in via this argument.\n\nNew in version 1.20.0.\n\nIf the buffer has data that is not in machine byte-order, this should be\nspecified as part of the data-type, e.g.:\n\nThe data of the resulting array will not be byteswapped, but will be\ninterpreted correctly.\n\n"}, {"name": "ma.fromfunction()", "path": "reference/generated/numpy.ma.fromfunction", "type": "numpy.ma.fromfunction", "text": "\nConstruct an array by executing a function over each coordinate.\n\nThe resulting array therefore has a value `fn(x, y, z)` at coordinate `(x, y,\nz)`.\n\nThe function is called with N parameters, where N is the rank of `shape`. Each\nparameter represents the coordinates of the array varying along a specific\naxis. For example, if `shape` were `(2, 2)`, then the parameters would be\n`array([[0, 0], [1, 1]])` and `array([[0, 1], [0, 1]])`\n\nShape of the output array, which also determines the shape of the coordinate\narrays passed to `function`.\n\nData-type of the coordinate arrays passed to `function`. By default, `dtype`\nis float.\n\nReference object to allow the creation of arrays which are not NumPy arrays.\nIf an array-like passed in as `like` supports the `__array_function__`\nprotocol, the result will be defined by it. In this case, it ensures the\ncreation of an array object compatible with that passed in via this argument.\n\nNew in version 1.20.0.\n\nThe result of the call to `function` is passed back directly. Therefore the\nshape of `fromfunction` is completely determined by `function`. If `function`\nreturns a scalar value, the shape of `fromfunction` would not match the\n`shape` parameter.\n\nSee also\n\nKeywords other than `dtype` are passed to `function`.\n\n"}, {"name": "ma.getdata()", "path": "reference/generated/numpy.ma.getdata", "type": "numpy.ma.getdata", "text": "\nReturn the data of a masked array as an ndarray.\n\nReturn the data of `a` (if any) as an ndarray if `a` is a `MaskedArray`, else\nreturn `a` as a ndarray or subclass (depending on `subok`) if not.\n\nInput `MaskedArray`, alternatively a ndarray or a subclass thereof.\n\nWhether to force the output to be a `pure` ndarray (False) or to return a\nsubclass of ndarray if appropriate (True, default).\n\nSee also\n\nReturn the mask of a masked array, or nomask.\n\nReturn the mask of a masked array, or full array of False.\n\nEquivalently use the `MaskedArray` `data` attribute.\n\n"}, {"name": "ma.getmask()", "path": "reference/generated/numpy.ma.getmask", "type": "numpy.ma.getmask", "text": "\nReturn the mask of a masked array, or nomask.\n\nReturn the mask of `a` as an ndarray if `a` is a `MaskedArray` and the mask is\nnot `nomask`, else return `nomask`. To guarantee a full array of booleans of\nthe same shape as a, use `getmaskarray`.\n\nInput `MaskedArray` for which the mask is required.\n\nSee also\n\nReturn the data of a masked array as an ndarray.\n\nReturn the mask of a masked array, or full array of False.\n\nEquivalently use the `MaskedArray` `mask` attribute.\n\nResult when mask == `nomask`\n\n"}, {"name": "ma.getmaskarray()", "path": "reference/generated/numpy.ma.getmaskarray", "type": "numpy.ma.getmaskarray", "text": "\nReturn the mask of a masked array, or full boolean array of False.\n\nReturn the mask of `arr` as an ndarray if `arr` is a `MaskedArray` and the\nmask is not `nomask`, else return a full boolean array of False of the same\nshape as `arr`.\n\nInput `MaskedArray` for which the mask is required.\n\nSee also\n\nReturn the mask of a masked array, or nomask.\n\nReturn the data of a masked array as an ndarray.\n\nResult when mask == `nomask`\n\n"}, {"name": "ma.harden_mask()", "path": "reference/generated/numpy.ma.harden_mask", "type": "numpy.ma.harden_mask", "text": "\nForce the mask to hard.\n\nWhether the mask of a masked array is hard or soft is determined by its\n`hardmask` property. `harden_mask` sets `hardmask` to `True`.\n\nSee also\n\n"}, {"name": "ma.hsplit()", "path": "reference/generated/numpy.ma.hsplit", "type": "numpy.ma.hsplit", "text": "\nSplit an array into multiple sub-arrays horizontally (column-wise).\n\nPlease refer to the `split` documentation. `hsplit` is equivalent to `split`\nwith `axis=1`, the array is always split along the second axis regardless of\nthe array dimension.\n\nSee also\n\nSplit an array into multiple sub-arrays of equal size.\n\nThe function is applied to both the _data and the _mask, if any.\n\nWith a higher dimensional array the split is still along the second axis.\n\n"}, {"name": "ma.hstack()", "path": "reference/generated/numpy.ma.hstack", "type": "numpy.ma.hstack", "text": "\nStack arrays in sequence horizontally (column wise).\n\nThis is equivalent to concatenation along the second axis, except for 1-D\narrays where it concatenates along the first axis. Rebuilds arrays divided by\n`hsplit`.\n\nThis function makes most sense for arrays with up to 3 dimensions. For\ninstance, for pixel-data with a height (first axis), width (second axis), and\nr/g/b channels (third axis). The functions `concatenate`, `stack` and `block`\nprovide more general stacking and concatenation operations.\n\nThe arrays must have the same shape along all but the second axis, except 1-D\narrays which can be any length.\n\nThe array formed by stacking the given arrays.\n\nSee also\n\nJoin a sequence of arrays along an existing axis.\n\nJoin a sequence of arrays along a new axis.\n\nAssemble an nd-array from nested lists of blocks.\n\nStack arrays in sequence vertically (row wise).\n\nStack arrays in sequence depth wise (along third axis).\n\nStack 1-D arrays as columns into a 2-D array.\n\nSplit an array into multiple sub-arrays horizontally (column-wise).\n\nThe function is applied to both the _data and the _mask, if any.\n\n"}, {"name": "ma.identity()", "path": "reference/generated/numpy.ma.identity", "type": "numpy.ma.identity", "text": "\nReturn the identity array.\n\nThe identity array is a square array with ones on the main diagonal.\n\nNumber of rows (and columns) in `n` x `n` output.\n\nData-type of the output. Defaults to `float`.\n\nReference object to allow the creation of arrays which are not NumPy arrays.\nIf an array-like passed in as `like` supports the `__array_function__`\nprotocol, the result will be defined by it. In this case, it ensures the\ncreation of an array object compatible with that passed in via this argument.\n\nNew in version 1.20.0.\n\n`n` x `n` array with its main diagonal set to one, and all other elements 0.\n\n"}, {"name": "ma.indices()", "path": "reference/generated/numpy.ma.indices", "type": "numpy.ma.indices", "text": "\nReturn an array representing the indices of a grid.\n\nCompute an array where the subarrays contain index values 0, 1, \u2026 varying only\nalong the corresponding axis.\n\nThe shape of the grid.\n\nData type of the result.\n\nReturn a sparse representation of the grid instead of a dense representation.\nDefault is False.\n\nNew in version 1.17.\n\nReturns one array of grid indices, `grid.shape = (len(dimensions),) +\ntuple(dimensions)`.\n\nReturns a tuple of arrays, with `grid[i].shape = (1, ..., 1, dimensions[i], 1,\n..., 1)` with dimensions[i] in the ith place\n\nSee also\n\nThe output shape in the dense case is obtained by prepending the number of\ndimensions in front of the tuple of dimensions, i.e. if `dimensions` is a\ntuple `(r0, ..., rN-1)` of length `N`, the output shape is `(N, r0, ...,\nrN-1)`.\n\nThe subarrays `grid[k]` contains the N-D array of indices along the `k-th`\naxis. Explicitly:\n\nThe indices can be used as an index into an array.\n\nNote that it would be more straightforward in the above example to extract the\nrequired elements directly with `x[:2, :3]`.\n\nIf sparse is set to true, the grid will be returned in a sparse\nrepresentation.\n\n"}, {"name": "ma.inner()", "path": "reference/generated/numpy.ma.inner", "type": "numpy.ma.inner", "text": "\nInner product of two arrays.\n\nOrdinary inner product of vectors for 1-D arrays (without complex\nconjugation), in higher dimensions a sum product over the last axes.\n\nIf `a` and `b` are nonscalar, their last dimensions must match.\n\nIf `a` and `b` are both scalars or both 1-D arrays then a scalar is returned;\notherwise an array is returned. `out.shape = (*a.shape[:-1], *b.shape[:-1])`\n\nIf both `a` and `b` are nonscalar and their last dimensions have different\nsizes.\n\nSee also\n\nSum products over arbitrary axes.\n\nGeneralised matrix product, using second last dimension of `b`.\n\nEinstein summation convention.\n\nMasked values are replaced by 0.\n\nFor vectors (1-D arrays) it computes the ordinary inner-product:\n\nMore generally, if `ndim(a) = r > 0` and `ndim(b) = s > 0`:\n\nor explicitly:\n\nIn addition `a` or `b` may be scalars, in which case:\n\nOrdinary inner product for vectors:\n\nSome multidimensional examples:\n\nAn example where `b` is a scalar:\n\n"}, {"name": "ma.innerproduct()", "path": "reference/generated/numpy.ma.innerproduct", "type": "numpy.ma.innerproduct", "text": "\nInner product of two arrays.\n\nOrdinary inner product of vectors for 1-D arrays (without complex\nconjugation), in higher dimensions a sum product over the last axes.\n\nIf `a` and `b` are nonscalar, their last dimensions must match.\n\nIf `a` and `b` are both scalars or both 1-D arrays then a scalar is returned;\notherwise an array is returned. `out.shape = (*a.shape[:-1], *b.shape[:-1])`\n\nIf both `a` and `b` are nonscalar and their last dimensions have different\nsizes.\n\nSee also\n\nSum products over arbitrary axes.\n\nGeneralised matrix product, using second last dimension of `b`.\n\nEinstein summation convention.\n\nMasked values are replaced by 0.\n\nFor vectors (1-D arrays) it computes the ordinary inner-product:\n\nMore generally, if `ndim(a) = r > 0` and `ndim(b) = s > 0`:\n\nor explicitly:\n\nIn addition `a` or `b` may be scalars, in which case:\n\nOrdinary inner product for vectors:\n\nSome multidimensional examples:\n\nAn example where `b` is a scalar:\n\n"}, {"name": "ma.is_mask()", "path": "reference/generated/numpy.ma.is_mask", "type": "numpy.ma.is_mask", "text": "\nReturn True if m is a valid, standard mask.\n\nThis function does not check the contents of the input, only that the type is\nMaskType. In particular, this function returns False if the mask has a\nflexible dtype.\n\nArray to test.\n\nTrue if `m.dtype.type` is MaskType, False otherwise.\n\nSee also\n\nTest whether input is an instance of MaskedArray.\n\nInput must be an ndarray (or have similar attributes) for it to be considered\na valid mask.\n\nArrays with complex dtypes don\u2019t return True.\n\n"}, {"name": "ma.is_masked()", "path": "reference/generated/numpy.ma.is_masked", "type": "numpy.ma.is_masked", "text": "\nDetermine whether input has masked values.\n\nAccepts any object as input, but always returns False unless the input is a\nMaskedArray containing masked values.\n\nArray to check for masked values.\n\nTrue if `x` is a MaskedArray with masked values, False otherwise.\n\nAlways returns False if `x` isn\u2019t a MaskedArray.\n\n"}, {"name": "ma.isarray()", "path": "reference/generated/numpy.ma.isarray", "type": "numpy.ma.isarray", "text": "\nTest whether input is an instance of MaskedArray.\n\nThis function returns True if `x` is an instance of MaskedArray and returns\nFalse otherwise. Any object is accepted as input.\n\nObject to test.\n\nTrue if `x` is a MaskedArray.\n\nSee also\n\nAlias to isMaskedArray.\n\nAlias to isMaskedArray.\n\n"}, {"name": "ma.isMA()", "path": "reference/generated/numpy.ma.isma", "type": "numpy.ma.isMA", "text": "\nTest whether input is an instance of MaskedArray.\n\nThis function returns True if `x` is an instance of MaskedArray and returns\nFalse otherwise. Any object is accepted as input.\n\nObject to test.\n\nTrue if `x` is a MaskedArray.\n\nSee also\n\nAlias to isMaskedArray.\n\nAlias to isMaskedArray.\n\n"}, {"name": "ma.isMaskedArray()", "path": "reference/generated/numpy.ma.ismaskedarray", "type": "numpy.ma.isMaskedArray", "text": "\nTest whether input is an instance of MaskedArray.\n\nThis function returns True if `x` is an instance of MaskedArray and returns\nFalse otherwise. Any object is accepted as input.\n\nObject to test.\n\nTrue if `x` is a MaskedArray.\n\nSee also\n\nAlias to isMaskedArray.\n\nAlias to isMaskedArray.\n\n"}, {"name": "ma.make_mask()", "path": "reference/generated/numpy.ma.make_mask", "type": "numpy.ma.make_mask", "text": "\nCreate a boolean mask from an array.\n\nReturn `m` as a boolean mask, creating a copy if necessary or requested. The\nfunction can accept any sequence that is convertible to integers, or `nomask`.\nDoes not require that contents must be 0s and 1s, values of 0 are interpreted\nas False, everything else as True.\n\nPotential mask.\n\nWhether to return a copy of `m` (True) or `m` itself (False).\n\nWhether to shrink `m` to `nomask` if all its values are False.\n\nData-type of the output mask. By default, the output mask has a dtype of\nMaskType (bool). If the dtype is flexible, each field has a boolean dtype.\nThis is ignored when `m` is `nomask`, in which case `nomask` is always\nreturned.\n\nA boolean mask derived from `m`.\n\nEffect of the `shrink` parameter.\n\nUsing a flexible `dtype`.\n\n"}, {"name": "ma.make_mask_descr()", "path": "reference/generated/numpy.ma.make_mask_descr", "type": "numpy.ma.make_mask_descr", "text": "\nConstruct a dtype description list from a given dtype.\n\nReturns a new dtype object, with the type of all fields in `ndtype` to a\nboolean type. Field names are not altered.\n\nThe dtype to convert.\n\nA dtype that looks like `ndtype`, the type of all fields is boolean.\n\n"}, {"name": "ma.make_mask_none()", "path": "reference/generated/numpy.ma.make_mask_none", "type": "numpy.ma.make_mask_none", "text": "\nReturn a boolean mask of the given shape, filled with False.\n\nThis function returns a boolean ndarray with all entries False, that can be\nused in common mask manipulations. If a complex dtype is specified, the type\nof each field is converted to a boolean type.\n\nA tuple indicating the shape of the mask.\n\nIf None, use a MaskType instance. Otherwise, use a new datatype with the same\nfields as `dtype`, converted to boolean types.\n\nAn ndarray of appropriate shape and dtype, filled with False.\n\nSee also\n\nCreate a boolean mask from an array.\n\nConstruct a dtype description list from a given dtype.\n\nDefining a more complex dtype.\n\n"}, {"name": "ma.mask_cols()", "path": "reference/generated/numpy.ma.mask_cols", "type": "numpy.ma.mask_cols", "text": "\nMask columns of a 2D array that contain masked values.\n\nThis function is a shortcut to `mask_rowcols` with `axis` equal to 1.\n\nSee also\n\nMask rows and/or columns of a 2D array.\n\nMask where a condition is met.\n\n"}, {"name": "ma.mask_or()", "path": "reference/generated/numpy.ma.mask_or", "type": "numpy.ma.mask_or", "text": "\nCombine two masks with the `logical_or` operator.\n\nThe result may be a view on `m1` or `m2` if the other is `nomask` (i.e.\nFalse).\n\nInput masks.\n\nIf copy is False and one of the inputs is `nomask`, return a view of the other\ninput mask. Defaults to False.\n\nWhether to shrink the output to `nomask` if all its values are False. Defaults\nto True.\n\nThe result masks values that are masked in either `m1` or `m2`.\n\nIf `m1` and `m2` have different flexible dtypes.\n\n"}, {"name": "ma.mask_rowcols()", "path": "reference/generated/numpy.ma.mask_rowcols", "type": "numpy.ma.mask_rowcols", "text": "\nMask rows and/or columns of a 2D array that contain masked values.\n\nMask whole rows and/or columns of a 2D array that contain masked values. The\nmasking behavior is selected using the `axis` parameter.\n\nThe array to mask. If not a MaskedArray instance (or if no array elements are\nmasked). The result is a MaskedArray with `mask` set to `nomask` (False). Must\nbe a 2D array.\n\nAxis along which to perform the operation. If None, applies to a flattened\nversion of the array.\n\nA modified version of the input array, masked depending on the value of the\n`axis` parameter.\n\nIf input array `a` is not 2D.\n\nSee also\n\nMask rows of a 2D array that contain masked values.\n\nMask cols of a 2D array that contain masked values.\n\nMask where a condition is met.\n\nThe input array\u2019s mask is modified by this function.\n\n"}, {"name": "ma.mask_rows()", "path": "reference/generated/numpy.ma.mask_rows", "type": "numpy.ma.mask_rows", "text": "\nMask rows of a 2D array that contain masked values.\n\nThis function is a shortcut to `mask_rowcols` with `axis` equal to 0.\n\nSee also\n\nMask rows and/or columns of a 2D array.\n\nMask where a condition is met.\n\n"}, {"name": "ma.masked_all()", "path": "reference/generated/numpy.ma.masked_all", "type": "numpy.ma.masked_all", "text": "\nEmpty masked array with all elements masked.\n\nReturn an empty masked array of the given shape and dtype, where all the data\nare masked.\n\nShape of the required MaskedArray.\n\nData type of the output.\n\nA masked array with all data masked.\n\nSee also\n\nEmpty masked array modelled on an existing array.\n\nThe `dtype` parameter defines the underlying data type.\n\n"}, {"name": "ma.masked_all_like()", "path": "reference/generated/numpy.ma.masked_all_like", "type": "numpy.ma.masked_all_like", "text": "\nEmpty masked array with the properties of an existing array.\n\nReturn an empty masked array of the same shape and dtype as the array `arr`,\nwhere all the data are masked.\n\nAn array describing the shape and dtype of the required MaskedArray.\n\nA masked array with all data masked.\n\nIf `arr` doesn\u2019t have a shape attribute (i.e. not an ndarray)\n\nSee also\n\nEmpty masked array with all elements masked.\n\nThe dtype of the masked array matches the dtype of `arr`.\n\n"}, {"name": "ma.masked_equal()", "path": "reference/generated/numpy.ma.masked_equal", "type": "numpy.ma.masked_equal", "text": "\nMask an array where equal to a given value.\n\nThis function is a shortcut to `masked_where`, with `condition` = (x ==\nvalue). For floating point arrays, consider using `masked_values(x, value)`.\n\nSee also\n\nMask where a condition is met.\n\nMask using floating point equality.\n\n"}, {"name": "ma.masked_greater()", "path": "reference/generated/numpy.ma.masked_greater", "type": "numpy.ma.masked_greater", "text": "\nMask an array where greater than a given value.\n\nThis function is a shortcut to `masked_where`, with `condition` = (x > value).\n\nSee also\n\nMask where a condition is met.\n\n"}, {"name": "ma.masked_greater_equal()", "path": "reference/generated/numpy.ma.masked_greater_equal", "type": "numpy.ma.masked_greater_equal", "text": "\nMask an array where greater than or equal to a given value.\n\nThis function is a shortcut to `masked_where`, with `condition` = (x >=\nvalue).\n\nSee also\n\nMask where a condition is met.\n\n"}, {"name": "ma.masked_inside()", "path": "reference/generated/numpy.ma.masked_inside", "type": "numpy.ma.masked_inside", "text": "\nMask an array inside a given interval.\n\nShortcut to `masked_where`, where `condition` is True for `x` inside the\ninterval [v1,v2] (v1 <= x <= v2). The boundaries `v1` and `v2` can be given in\neither order.\n\nSee also\n\nMask where a condition is met.\n\nThe array `x` is prefilled with its filling value.\n\nThe order of `v1` and `v2` doesn\u2019t matter.\n\n"}, {"name": "ma.masked_invalid()", "path": "reference/generated/numpy.ma.masked_invalid", "type": "numpy.ma.masked_invalid", "text": "\nMask an array where invalid values occur (NaNs or infs).\n\nThis function is a shortcut to `masked_where`, with `condition` =\n~(np.isfinite(a)). Any pre-existing mask is conserved. Only applies to arrays\nwith a dtype where NaNs or infs make sense (i.e. floating point types), but\naccepts any array_like object.\n\nSee also\n\nMask where a condition is met.\n\n"}, {"name": "ma.masked_less()", "path": "reference/generated/numpy.ma.masked_less", "type": "numpy.ma.masked_less", "text": "\nMask an array where less than a given value.\n\nThis function is a shortcut to `masked_where`, with `condition` = (x < value).\n\nSee also\n\nMask where a condition is met.\n\n"}, {"name": "ma.masked_less_equal()", "path": "reference/generated/numpy.ma.masked_less_equal", "type": "numpy.ma.masked_less_equal", "text": "\nMask an array where less than or equal to a given value.\n\nThis function is a shortcut to `masked_where`, with `condition` = (x <=\nvalue).\n\nSee also\n\nMask where a condition is met.\n\n"}, {"name": "ma.masked_not_equal()", "path": "reference/generated/numpy.ma.masked_not_equal", "type": "numpy.ma.masked_not_equal", "text": "\nMask an array where `not` equal to a given value.\n\nThis function is a shortcut to `masked_where`, with `condition` = (x !=\nvalue).\n\nSee also\n\nMask where a condition is met.\n\n"}, {"name": "ma.masked_object()", "path": "reference/generated/numpy.ma.masked_object", "type": "numpy.ma.masked_object", "text": "\nMask the array `x` where the data are exactly equal to value.\n\nThis function is similar to `masked_values`, but only suitable for object\narrays: for floating point, use `masked_values` instead.\n\nArray to mask\n\nComparison value\n\nWhether to return a copy of `x`.\n\nWhether to collapse a mask full of False to nomask\n\nThe result of masking `x` where equal to `value`.\n\nSee also\n\nMask where a condition is met.\n\nMask where equal to a given value (integers).\n\nMask using floating point equality.\n\nNote that `mask` is set to `nomask` if possible.\n\n"}, {"name": "ma.masked_outside()", "path": "reference/generated/numpy.ma.masked_outside", "type": "numpy.ma.masked_outside", "text": "\nMask an array outside a given interval.\n\nShortcut to `masked_where`, where `condition` is True for `x` outside the\ninterval [v1,v2] (x < v1)|(x > v2). The boundaries `v1` and `v2` can be given\nin either order.\n\nSee also\n\nMask where a condition is met.\n\nThe array `x` is prefilled with its filling value.\n\nThe order of `v1` and `v2` doesn\u2019t matter.\n\n"}, {"name": "ma.masked_values()", "path": "reference/generated/numpy.ma.masked_values", "type": "numpy.ma.masked_values", "text": "\nMask using floating point equality.\n\nReturn a MaskedArray, masked where the data in array `x` are approximately\nequal to `value`, determined using `isclose`. The default tolerances for\n`masked_values` are the same as those for `isclose`.\n\nFor integer types, exact equality is used, in the same way as `masked_equal`.\n\nThe fill_value is set to `value` and the mask is set to `nomask` if possible.\n\nArray to mask.\n\nMasking value.\n\nTolerance parameters passed on to `isclose`\n\nWhether to return a copy of `x`.\n\nWhether to collapse a mask full of False to `nomask`.\n\nThe result of masking `x` where approximately equal to `value`.\n\nSee also\n\nMask where a condition is met.\n\nMask where equal to a given value (integers).\n\nNote that `mask` is set to `nomask` if possible.\n\nFor integers, the fill value will be different in general to the result of\n`masked_equal`.\n\n"}, {"name": "ma.masked_where()", "path": "reference/generated/numpy.ma.masked_where", "type": "numpy.ma.masked_where", "text": "\nMask an array where a condition is met.\n\nReturn `a` as an array masked where `condition` is True. Any masked values of\n`a` or `condition` are also masked in the output.\n\nMasking condition. When `condition` tests floating point values for equality,\nconsider using `masked_values` instead.\n\nArray to mask.\n\nIf True (default) make a copy of `a` in the result. If False modify `a` in\nplace and return a view.\n\nThe result of masking `a` where `condition` is True.\n\nSee also\n\nMask using floating point equality.\n\nMask where equal to a given value.\n\nMask where `not` equal to a given value.\n\nMask where less than or equal to a given value.\n\nMask where greater than or equal to a given value.\n\nMask where less than a given value.\n\nMask where greater than a given value.\n\nMask inside a given interval.\n\nMask outside a given interval.\n\nMask invalid values (NaNs or infs).\n\nMask array `b` conditional on `a`.\n\nEffect of the `copy` argument.\n\nWhen `condition` or `a` contain masked values.\n\n"}, {"name": "ma.MaskedArray.__abs__()", "path": "reference/generated/numpy.ma.maskedarray.__abs__", "type": "Masked arrays", "text": "\nmethod\n\n"}, {"name": "ma.MaskedArray.__add__()", "path": "reference/generated/numpy.ma.maskedarray.__add__", "type": "Masked arrays", "text": "\nmethod\n\nAdd self to other, and return a new masked array.\n\n"}, {"name": "ma.MaskedArray.__and__()", "path": "reference/generated/numpy.ma.maskedarray.__and__", "type": "Masked arrays", "text": "\nmethod\n\nReturn self&value.\n\n"}, {"name": "ma.MaskedArray.__array__()", "path": "reference/generated/numpy.ma.maskedarray.__array__", "type": "Masked arrays", "text": "\nmethod\n\nReturns either a new reference to self if dtype is not given or a new array of\nprovided data type if dtype is different from the current dtype of the array.\n\n"}, {"name": "ma.MaskedArray.__array_priority__", "path": "reference/generated/numpy.ma.maskedarray.__array_priority__", "type": "Masked arrays", "text": "\nattribute\n\n"}, {"name": "ma.MaskedArray.__array_wrap__()", "path": "reference/generated/numpy.ma.maskedarray.__array_wrap__", "type": "Masked arrays", "text": "\nmethod\n\nSpecial hook for ufuncs.\n\nWraps the numpy array and sets the mask according to context.\n\n"}, {"name": "ma.MaskedArray.__bool__()", "path": "reference/generated/numpy.ma.maskedarray.__bool__", "type": "Masked arrays", "text": "\nmethod\n\nself != 0\n\n"}, {"name": "ma.MaskedArray.__contains__()", "path": "reference/generated/numpy.ma.maskedarray.__contains__", "type": "Masked arrays", "text": "\nmethod\n\nReturn key in self.\n\n"}, {"name": "ma.MaskedArray.__copy__()", "path": "reference/generated/numpy.ma.maskedarray.__copy__", "type": "Masked arrays", "text": "\nmethod\n\nUsed if `copy.copy` is called on an array. Returns a copy of the array.\n\nEquivalent to `a.copy(order='K')`.\n\n"}, {"name": "ma.MaskedArray.__deepcopy__()", "path": "reference/generated/numpy.ma.maskedarray.__deepcopy__", "type": "Masked arrays", "text": "\nmethod\n\nUsed if `copy.deepcopy` is called on an array.\n\n"}, {"name": "ma.MaskedArray.__delitem__()", "path": "reference/generated/numpy.ma.maskedarray.__delitem__", "type": "Masked arrays", "text": "\nmethod\n\nDelete self[key].\n\n"}, {"name": "ma.MaskedArray.__div__()", "path": "reference/generated/numpy.ma.maskedarray.__div__", "type": "Masked arrays", "text": "\nmethod\n\nDivide other into self, and return a new masked array.\n\n"}, {"name": "ma.MaskedArray.__divmod__()", "path": "reference/generated/numpy.ma.maskedarray.__divmod__", "type": "Masked arrays", "text": "\nmethod\n\nReturn divmod(self, value).\n\n"}, {"name": "ma.MaskedArray.__eq__()", "path": "reference/generated/numpy.ma.maskedarray.__eq__", "type": "Masked arrays", "text": "\nmethod\n\nCheck whether other equals self elementwise.\n\nWhen either of the elements is masked, the result is masked as well, but the\nunderlying boolean data are still set, with self and other considered equal if\nboth are masked, and unequal otherwise.\n\nFor structured arrays, all fields are combined, with masked values ignored.\nThe result is masked if all fields were masked, with self and other considered\nequal only if both were fully masked.\n\n"}, {"name": "ma.MaskedArray.__float__()", "path": "reference/generated/numpy.ma.maskedarray.__float__", "type": "Masked arrays", "text": "\nmethod\n\nConvert to float.\n\n"}, {"name": "ma.MaskedArray.__floordiv__()", "path": "reference/generated/numpy.ma.maskedarray.__floordiv__", "type": "Masked arrays", "text": "\nmethod\n\nDivide other into self, and return a new masked array.\n\n"}, {"name": "ma.MaskedArray.__ge__()", "path": "reference/generated/numpy.ma.maskedarray.__ge__", "type": "Masked arrays", "text": "\nmethod\n\nReturn self>=value.\n\n"}, {"name": "ma.MaskedArray.__getitem__()", "path": "reference/generated/numpy.ma.maskedarray.__getitem__", "type": "Masked arrays", "text": "\nmethod\n\nx.__getitem__(y) <==> x[y]\n\nReturn the item described by i, as a masked array.\n\n"}, {"name": "ma.MaskedArray.__getstate__()", "path": "reference/generated/numpy.ma.maskedarray.__getstate__", "type": "Masked arrays", "text": "\nmethod\n\nReturn the internal state of the masked array, for pickling purposes.\n\n"}, {"name": "ma.MaskedArray.__gt__()", "path": "reference/generated/numpy.ma.maskedarray.__gt__", "type": "Masked arrays", "text": "\nmethod\n\nReturn self>value.\n\n"}, {"name": "ma.MaskedArray.__iadd__()", "path": "reference/generated/numpy.ma.maskedarray.__iadd__", "type": "Masked arrays", "text": "\nmethod\n\nAdd other to self in-place.\n\n"}, {"name": "ma.MaskedArray.__iand__()", "path": "reference/generated/numpy.ma.maskedarray.__iand__", "type": "Masked arrays", "text": "\nmethod\n\nReturn self&=value.\n\n"}, {"name": "ma.MaskedArray.__idiv__()", "path": "reference/generated/numpy.ma.maskedarray.__idiv__", "type": "Masked arrays", "text": "\nmethod\n\nDivide self by other in-place.\n\n"}, {"name": "ma.MaskedArray.__ifloordiv__()", "path": "reference/generated/numpy.ma.maskedarray.__ifloordiv__", "type": "Masked arrays", "text": "\nmethod\n\nFloor divide self by other in-place.\n\n"}, {"name": "ma.MaskedArray.__ilshift__()", "path": "reference/generated/numpy.ma.maskedarray.__ilshift__", "type": "Masked arrays", "text": "\nmethod\n\nReturn self<<=value.\n\n"}, {"name": "ma.MaskedArray.__imod__()", "path": "reference/generated/numpy.ma.maskedarray.__imod__", "type": "Masked arrays", "text": "\nmethod\n\nReturn self%=value.\n\n"}, {"name": "ma.MaskedArray.__imul__()", "path": "reference/generated/numpy.ma.maskedarray.__imul__", "type": "Masked arrays", "text": "\nmethod\n\nMultiply self by other in-place.\n\n"}, {"name": "ma.MaskedArray.__int__()", "path": "reference/generated/numpy.ma.maskedarray.__int__", "type": "Masked arrays", "text": "\nmethod\n\nConvert to int.\n\n"}, {"name": "ma.MaskedArray.__ior__()", "path": "reference/generated/numpy.ma.maskedarray.__ior__", "type": "Masked arrays", "text": "\nmethod\n\nReturn self|=value.\n\n"}, {"name": "ma.MaskedArray.__ipow__()", "path": "reference/generated/numpy.ma.maskedarray.__ipow__", "type": "Masked arrays", "text": "\nmethod\n\nRaise self to the power other, in place.\n\n"}, {"name": "ma.MaskedArray.__irshift__()", "path": "reference/generated/numpy.ma.maskedarray.__irshift__", "type": "Masked arrays", "text": "\nmethod\n\nReturn self>>=value.\n\n"}, {"name": "ma.MaskedArray.__isub__()", "path": "reference/generated/numpy.ma.maskedarray.__isub__", "type": "Masked arrays", "text": "\nmethod\n\nSubtract other from self in-place.\n\n"}, {"name": "ma.MaskedArray.__itruediv__()", "path": "reference/generated/numpy.ma.maskedarray.__itruediv__", "type": "Masked arrays", "text": "\nmethod\n\nTrue divide self by other in-place.\n\n"}, {"name": "ma.MaskedArray.__ixor__()", "path": "reference/generated/numpy.ma.maskedarray.__ixor__", "type": "Masked arrays", "text": "\nmethod\n\nReturn self^=value.\n\n"}, {"name": "ma.MaskedArray.__le__()", "path": "reference/generated/numpy.ma.maskedarray.__le__", "type": "Masked arrays", "text": "\nmethod\n\nReturn self<=value.\n\n"}, {"name": "ma.MaskedArray.__len__()", "path": "reference/generated/numpy.ma.maskedarray.__len__", "type": "Masked arrays", "text": "\nmethod\n\nReturn len(self).\n\n"}, {"name": "ma.MaskedArray.__lshift__()", "path": "reference/generated/numpy.ma.maskedarray.__lshift__", "type": "Masked arrays", "text": "\nmethod\n\nReturn self<<value.\n\n"}, {"name": "ma.MaskedArray.__lt__()", "path": "reference/generated/numpy.ma.maskedarray.__lt__", "type": "Masked arrays", "text": "\nmethod\n\nReturn self<value.\n\n"}, {"name": "ma.MaskedArray.__mod__()", "path": "reference/generated/numpy.ma.maskedarray.__mod__", "type": "Masked arrays", "text": "\nmethod\n\nReturn self%value.\n\n"}, {"name": "ma.MaskedArray.__mul__()", "path": "reference/generated/numpy.ma.maskedarray.__mul__", "type": "Masked arrays", "text": "\nmethod\n\nMultiply self by other, and return a new masked array.\n\n"}, {"name": "ma.MaskedArray.__ne__()", "path": "reference/generated/numpy.ma.maskedarray.__ne__", "type": "Masked arrays", "text": "\nmethod\n\nCheck whether other does not equal self elementwise.\n\nWhen either of the elements is masked, the result is masked as well, but the\nunderlying boolean data are still set, with self and other considered equal if\nboth are masked, and unequal otherwise.\n\nFor structured arrays, all fields are combined, with masked values ignored.\nThe result is masked if all fields were masked, with self and other considered\nequal only if both were fully masked.\n\n"}, {"name": "ma.MaskedArray.__or__()", "path": "reference/generated/numpy.ma.maskedarray.__or__", "type": "Masked arrays", "text": "\nmethod\n\nReturn self|value.\n\n"}, {"name": "ma.MaskedArray.__pow__()", "path": "reference/generated/numpy.ma.maskedarray.__pow__", "type": "Masked arrays", "text": "\nmethod\n\nRaise self to the power other, masking the potential NaNs/Infs\n\n"}, {"name": "ma.MaskedArray.__radd__()", "path": "reference/generated/numpy.ma.maskedarray.__radd__", "type": "Masked arrays", "text": "\nmethod\n\nAdd other to self, and return a new masked array.\n\n"}, {"name": "ma.MaskedArray.__rand__()", "path": "reference/generated/numpy.ma.maskedarray.__rand__", "type": "Masked arrays", "text": "\nmethod\n\nReturn value&self.\n\n"}, {"name": "ma.MaskedArray.__rdivmod__()", "path": "reference/generated/numpy.ma.maskedarray.__rdivmod__", "type": "Masked arrays", "text": "\nmethod\n\nReturn divmod(value, self).\n\n"}, {"name": "ma.MaskedArray.__reduce__()", "path": "reference/generated/numpy.ma.maskedarray.__reduce__", "type": "Masked arrays", "text": "\nmethod\n\nReturn a 3-tuple for pickling a MaskedArray.\n\n"}, {"name": "ma.MaskedArray.__repr__()", "path": "reference/generated/numpy.ma.maskedarray.__repr__", "type": "Masked arrays", "text": "\nmethod\n\nLiteral string representation.\n\n"}, {"name": "ma.MaskedArray.__rfloordiv__()", "path": "reference/generated/numpy.ma.maskedarray.__rfloordiv__", "type": "Masked arrays", "text": "\nmethod\n\nDivide self into other, and return a new masked array.\n\n"}, {"name": "ma.MaskedArray.__rlshift__()", "path": "reference/generated/numpy.ma.maskedarray.__rlshift__", "type": "Masked arrays", "text": "\nmethod\n\nReturn value<<self.\n\n"}, {"name": "ma.MaskedArray.__rmod__()", "path": "reference/generated/numpy.ma.maskedarray.__rmod__", "type": "Masked arrays", "text": "\nmethod\n\nReturn value%self.\n\n"}, {"name": "ma.MaskedArray.__rmul__()", "path": "reference/generated/numpy.ma.maskedarray.__rmul__", "type": "Masked arrays", "text": "\nmethod\n\nMultiply other by self, and return a new masked array.\n\n"}, {"name": "ma.MaskedArray.__ror__()", "path": "reference/generated/numpy.ma.maskedarray.__ror__", "type": "Masked arrays", "text": "\nmethod\n\nReturn value|self.\n\n"}, {"name": "ma.MaskedArray.__rpow__()", "path": "reference/generated/numpy.ma.maskedarray.__rpow__", "type": "Masked arrays", "text": "\nmethod\n\nRaise other to the power self, masking the potential NaNs/Infs\n\n"}, {"name": "ma.MaskedArray.__rrshift__()", "path": "reference/generated/numpy.ma.maskedarray.__rrshift__", "type": "Masked arrays", "text": "\nmethod\n\nReturn value>>self.\n\n"}, {"name": "ma.MaskedArray.__rshift__()", "path": "reference/generated/numpy.ma.maskedarray.__rshift__", "type": "Masked arrays", "text": "\nmethod\n\nReturn self>>value.\n\n"}, {"name": "ma.MaskedArray.__rsub__()", "path": "reference/generated/numpy.ma.maskedarray.__rsub__", "type": "Masked arrays", "text": "\nmethod\n\nSubtract self from other, and return a new masked array.\n\n"}, {"name": "ma.MaskedArray.__rtruediv__()", "path": "reference/generated/numpy.ma.maskedarray.__rtruediv__", "type": "Masked arrays", "text": "\nmethod\n\nDivide self into other, and return a new masked array.\n\n"}, {"name": "ma.MaskedArray.__rxor__()", "path": "reference/generated/numpy.ma.maskedarray.__rxor__", "type": "Masked arrays", "text": "\nmethod\n\nReturn value^self.\n\n"}, {"name": "ma.MaskedArray.__setitem__()", "path": "reference/generated/numpy.ma.maskedarray.__setitem__", "type": "Masked arrays", "text": "\nmethod\n\nx.__setitem__(i, y) <==> x[i]=y\n\nSet item described by index. If value is masked, masks those locations.\n\n"}, {"name": "ma.MaskedArray.__setmask__()", "path": "reference/generated/numpy.ma.maskedarray.__setmask__", "type": "Masked arrays", "text": "\nmethod\n\nSet the mask.\n\n"}, {"name": "ma.MaskedArray.__setstate__()", "path": "reference/generated/numpy.ma.maskedarray.__setstate__", "type": "Masked arrays", "text": "\nmethod\n\nRestore the internal state of the masked array, for pickling purposes. `state`\nis typically the output of the `__getstate__` output, and is a 5-tuple:\n\n"}, {"name": "ma.MaskedArray.__str__()", "path": "reference/generated/numpy.ma.maskedarray.__str__", "type": "Masked arrays", "text": "\nmethod\n\nReturn str(self).\n\n"}, {"name": "ma.MaskedArray.__sub__()", "path": "reference/generated/numpy.ma.maskedarray.__sub__", "type": "Masked arrays", "text": "\nmethod\n\nSubtract other from self, and return a new masked array.\n\n"}, {"name": "ma.MaskedArray.__truediv__()", "path": "reference/generated/numpy.ma.maskedarray.__truediv__", "type": "Masked arrays", "text": "\nmethod\n\nDivide other into self, and return a new masked array.\n\n"}, {"name": "ma.MaskedArray.__xor__()", "path": "reference/generated/numpy.ma.maskedarray.__xor__", "type": "Masked arrays", "text": "\nmethod\n\nReturn self^value.\n\n"}, {"name": "ma.MaskedArray.all()", "path": "reference/generated/numpy.ma.maskedarray.all", "type": "numpy.ma.MaskedArray.all", "text": "\nmethod\n\nReturns True if all elements evaluate to True.\n\nThe output array is masked where all the values along the given axis are\nmasked: if the output would have been a scalar and that all the values are\nmasked, then the output is `masked`.\n\nRefer to `numpy.all` for full documentation.\n\nSee also\n\ncorresponding function for ndarrays\n\nequivalent function\n\n"}, {"name": "ma.MaskedArray.anom()", "path": "reference/generated/numpy.ma.maskedarray.anom", "type": "numpy.ma.MaskedArray.anom", "text": "\nmethod\n\nCompute the anomalies (deviations from the arithmetic mean) along the given\naxis.\n\nReturns an array of anomalies, with the same shape as the input and where the\narithmetic mean is computed along the given axis.\n\nAxis over which the anomalies are taken. The default is to use the mean of the\nflattened array as reference.\n\nthe default is float32; for arrays of float types it is the same as the array\ntype.\n\nSee also\n\nCompute the mean of the array.\n\n"}, {"name": "ma.MaskedArray.any()", "path": "reference/generated/numpy.ma.maskedarray.any", "type": "numpy.ma.MaskedArray.any", "text": "\nmethod\n\nReturns True if any of the elements of `a` evaluate to True.\n\nMasked values are considered as False during computation.\n\nRefer to `numpy.any` for full documentation.\n\nSee also\n\ncorresponding function for ndarrays\n\nequivalent function\n\n"}, {"name": "ma.MaskedArray.argmax()", "path": "reference/generated/numpy.ma.maskedarray.argmax", "type": "numpy.ma.MaskedArray.argmax", "text": "\nmethod\n\nReturns array of indices of the maximum values along the given axis. Masked\nvalues are treated as if they had the value fill_value.\n\nIf None, the index is into the flattened array, otherwise along the specified\naxis\n\nValue used to fill in the masked values. If None, the output of\nmaximum_fill_value(self._data) is used instead.\n\nArray into which the result can be placed. Its type is preserved and it must\nbe of the right shape to hold the output.\n\n"}, {"name": "ma.MaskedArray.argmin()", "path": "reference/generated/numpy.ma.maskedarray.argmin", "type": "numpy.ma.MaskedArray.argmin", "text": "\nmethod\n\nReturn array of indices to the minimum values along the given axis.\n\nIf None, the index is into the flattened array, otherwise along the specified\naxis\n\nValue used to fill in the masked values. If None, the output of\nminimum_fill_value(self._data) is used instead.\n\nArray into which the result can be placed. Its type is preserved and it must\nbe of the right shape to hold the output.\n\nIf multi-dimension input, returns a new ndarray of indices to the minimum\nvalues along the given axis. Otherwise, returns a scalar of index to the\nminimum values along the given axis.\n\n"}, {"name": "ma.MaskedArray.argsort()", "path": "reference/generated/numpy.ma.maskedarray.argsort", "type": "numpy.ma.MaskedArray.argsort", "text": "\nmethod\n\nReturn an ndarray of indices that sort the array along the specified axis.\nMasked values are filled beforehand to `fill_value`.\n\nAxis along which to sort. If None, the default, the flattened array is used.\n\nChanged in version 1.13.0: Previously, the default was documented to be -1,\nbut that was in error. At some future date, the default will change to -1, as\noriginally intended. Until then, the axis should be given explicitly when\n`arr.ndim > 1`, to avoid a FutureWarning.\n\nThe sorting algorithm used.\n\nWhen `a` is an array with fields defined, this argument specifies which fields\nto compare first, second, etc. Not all fields need be specified.\n\nWhether missing values (if any) should be treated as the largest values (True)\nor the smallest values (False) When the array contains unmasked values at the\nsame extremes of the datatype, the ordering of these values and the masked\nvalues is undefined.\n\nValue used internally for the masked values. If `fill_value` is not None, it\nsupersedes `endwith`.\n\nArray of indices that sort `a` along the specified axis. In other words,\n`a[index_array]` yields a sorted `a`.\n\nSee also\n\nDescribes sorting algorithms used.\n\nIndirect stable sort with multiple keys.\n\nInplace sort.\n\nSee `sort` for notes on the different sorting algorithms.\n\n"}, {"name": "ma.MaskedArray.astype()", "path": "reference/generated/numpy.ma.maskedarray.astype", "type": "Masked arrays", "text": "\nmethod\n\nCopy of the array, cast to a specified type.\n\nTypecode or data-type to which the array is cast.\n\nControls the memory layout order of the result. \u2018C\u2019 means C order, \u2018F\u2019 means\nFortran order, \u2018A\u2019 means \u2018F\u2019 order if all the arrays are Fortran contiguous,\n\u2018C\u2019 order otherwise, and \u2018K\u2019 means as close to the order the array elements\nappear in memory as possible. Default is \u2018K\u2019.\n\nControls what kind of data casting may occur. Defaults to \u2018unsafe\u2019 for\nbackwards compatibility.\n\nIf True, then sub-classes will be passed-through (default), otherwise the\nreturned array will be forced to be a base-class array.\n\nBy default, astype always returns a newly allocated array. If this is set to\nfalse, and the `dtype`, `order`, and `subok` requirements are satisfied, the\ninput array is returned instead of a copy.\n\nUnless `copy` is False and the other conditions for returning the input array\nare satisfied (see description for `copy` input parameter), `arr_t` is a new\narray of the same shape as the input array, with dtype, order given by\n`dtype`, `order`.\n\nWhen casting from complex to float or int. To avoid this, one should use\n`a.real.astype(t)`.\n\nChanged in version 1.17.0: Casting between a simple data type and a structured\none is possible only for \u201cunsafe\u201d casting. Casting to multiple fields is\nallowed, but casting from multiple fields is not.\n\nChanged in version 1.9.0: Casting from numeric to string types in \u2018safe\u2019\ncasting mode requires that the string dtype length is long enough to store the\nmax integer/float value converted.\n\n"}, {"name": "ma.MaskedArray.base", "path": "reference/generated/numpy.ma.maskedarray.base", "type": "Masked arrays", "text": "\nattribute\n\nBase object if memory is from some other object.\n\nThe base of an array that owns its memory is None:\n\nSlicing creates a view, whose memory is shared with x:\n\n"}, {"name": "ma.MaskedArray.byteswap()", "path": "reference/generated/numpy.ma.maskedarray.byteswap", "type": "Masked arrays", "text": "\nmethod\n\nSwap the bytes of the array elements\n\nToggle between low-endian and big-endian data representation by returning a\nbyteswapped array, optionally swapped in-place. Arrays of byte-strings are not\nswapped. The real and imaginary parts of a complex number are swapped\nindividually.\n\nIf `True`, swap bytes in-place, default is `False`.\n\nThe byteswapped array. If `inplace` is `True`, this is a view to self.\n\nArrays of byte-strings are not swapped\n\nbut different representation in memory\n\n"}, {"name": "ma.MaskedArray.choose()", "path": "reference/generated/numpy.ma.maskedarray.choose", "type": "Masked arrays", "text": "\nmethod\n\nUse an index array to construct a new array from a set of choices.\n\nRefer to `numpy.choose` for full documentation.\n\nSee also\n\nequivalent function\n\n"}, {"name": "ma.MaskedArray.clip()", "path": "reference/generated/numpy.ma.maskedarray.clip", "type": "numpy.ma.MaskedArray.clip", "text": "\nmethod\n\nReturn an array whose values are limited to `[min, max]`. One of max or min\nmust be given.\n\nRefer to `numpy.clip` for full documentation.\n\nSee also\n\nequivalent function\n\n"}, {"name": "ma.MaskedArray.compress()", "path": "reference/generated/numpy.ma.maskedarray.compress", "type": "Masked arrays", "text": "\nmethod\n\nReturn `a` where condition is `True`.\n\nIf condition is a `MaskedArray`, missing values are considered as `False`.\n\nBoolean 1-d array selecting which entries to return. If len(condition) is less\nthan the size of a along the axis, then output is truncated to length of\ncondition array.\n\nAxis along which the operation must be performed.\n\nAlternative output array in which to place the result. It must have the same\nshape as the expected output but the type will be cast if necessary.\n\nA `MaskedArray` object.\n\nPlease note the difference with `compressed` ! The output of `compress` has a\nmask, the output of `compressed` does not.\n\n"}, {"name": "ma.MaskedArray.compressed()", "path": "reference/generated/numpy.ma.maskedarray.compressed", "type": "numpy.ma.MaskedArray.compressed", "text": "\nmethod\n\nReturn all the non-masked data as a 1-D array.\n\nA new `ndarray` holding the non-masked data is returned.\n\nThe result is not a MaskedArray!\n\n"}, {"name": "ma.MaskedArray.conj()", "path": "reference/generated/numpy.ma.maskedarray.conj", "type": "Masked arrays", "text": "\nmethod\n\nComplex-conjugate all elements.\n\nRefer to `numpy.conjugate` for full documentation.\n\nSee also\n\nequivalent function\n\n"}, {"name": "ma.MaskedArray.conjugate()", "path": "reference/generated/numpy.ma.maskedarray.conjugate", "type": "Masked arrays", "text": "\nmethod\n\nReturn the complex conjugate, element-wise.\n\nRefer to `numpy.conjugate` for full documentation.\n\nSee also\n\nequivalent function\n\n"}, {"name": "ma.MaskedArray.copy()", "path": "reference/generated/numpy.ma.maskedarray.copy", "type": "numpy.ma.MaskedArray.copy", "text": "\nmethod\n\nReturn a copy of the array.\n\nControls the memory layout of the copy. \u2018C\u2019 means C-order, \u2018F\u2019 means F-order,\n\u2018A\u2019 means \u2018F\u2019 if `a` is Fortran contiguous, \u2018C\u2019 otherwise. \u2018K\u2019 means match the\nlayout of `a` as closely as possible. (Note that this function and\n`numpy.copy` are very similar but have different default values for their\norder= arguments, and this function always passes sub-classes through.)\n\nSee also\n\nSimilar function with different default behavior\n\nThis function is the preferred method for creating an array copy. The function\n`numpy.copy` is similar, but it defaults to using order \u2018K\u2019, and will not pass\nsub-classes through by default.\n\n"}, {"name": "ma.MaskedArray.count()", "path": "reference/generated/numpy.ma.maskedarray.count", "type": "numpy.ma.MaskedArray.count", "text": "\nmethod\n\nCount the non-masked elements of the array along the given axis.\n\nAxis or axes along which the count is performed. The default, None, performs\nthe count over all the dimensions of the input array. `axis` may be negative,\nin which case it counts from the last to the first axis.\n\nNew in version 1.10.0.\n\nIf this is a tuple of ints, the count is performed on multiple axes, instead\nof a single axis or all the axes as before.\n\nIf this is set to True, the axes which are reduced are left in the result as\ndimensions with size one. With this option, the result will broadcast\ncorrectly against the array.\n\nAn array with the same shape as the input array, with the specified axis\nremoved. If the array is a 0-d array, or if `axis` is None, a scalar is\nreturned.\n\nSee also\n\nCount masked elements in array or along a given axis.\n\nWhen the `axis` keyword is specified an array of appropriate size is returned.\n\n"}, {"name": "ma.MaskedArray.ctypes", "path": "reference/generated/numpy.ma.maskedarray.ctypes", "type": "Masked arrays", "text": "\nattribute\n\nAn object to simplify the interaction of the array with the ctypes module.\n\nThis attribute creates an object that makes it easier to use arrays when\ncalling shared libraries with the ctypes module. The returned object has,\namong others, data, shape, and strides attributes (see Notes below) which\nthemselves return ctypes objects that can be used as arguments to a shared\nlibrary.\n\nPossessing attributes data, shape, strides, etc.\n\nSee also\n\nBelow are the public attributes of this object which were documented in \u201cGuide\nto NumPy\u201d (we have omitted undocumented public attributes, as well as\ndocumented private attributes):\n\nA pointer to the memory area of the array as a Python integer. This memory\narea may contain data that is not aligned, or not in correct byte-order. The\nmemory area may not even be writeable. The array flags and data-type of this\narray should be respected when passing this attribute to arbitrary C-code to\navoid trouble that can include Python crashing. User Beware! The value of this\nattribute is exactly the same as `self._array_interface_['data'][0]`.\n\nNote that unlike `data_as`, a reference will not be kept to the array: code\nlike `ctypes.c_void_p((a + b).ctypes.data)` will result in a pointer to a\ndeallocated array, and should be spelt `(a +\nb).ctypes.data_as(ctypes.c_void_p)`\n\n(c_intp*self.ndim): A ctypes array of length self.ndim where the basetype is\nthe C-integer corresponding to `dtype('p')` on this platform (see `c_intp`).\nThis base-type could be `ctypes.c_int`, `ctypes.c_long`, or\n`ctypes.c_longlong` depending on the platform. The ctypes array contains the\nshape of the underlying array.\n\n(c_intp*self.ndim): A ctypes array of length self.ndim where the basetype is\nthe same as for the shape attribute. This ctypes array contains the strides\ninformation from the underlying array. This strides information is important\nfor showing how many bytes must be jumped to get to the next element in the\narray.\n\nReturn the data pointer cast to a particular c-types object. For example,\ncalling `self._as_parameter_` is equivalent to\n`self.data_as(ctypes.c_void_p)`. Perhaps you want to use the data as a pointer\nto a ctypes array of floating-point data:\n`self.data_as(ctypes.POINTER(ctypes.c_double))`.\n\nThe returned pointer will keep a reference to the array.\n\nReturn the shape tuple as an array of some other c-types type. For example:\n`self.shape_as(ctypes.c_short)`.\n\nReturn the strides tuple as an array of some other c-types type. For example:\n`self.strides_as(ctypes.c_longlong)`.\n\nIf the ctypes module is not available, then the ctypes attribute of array\nobjects still returns something useful, but ctypes objects are not returned\nand errors may be raised instead. In particular, the object will still have\nthe `as_parameter` attribute which will return an integer equal to the data\nattribute.\n\n"}, {"name": "ma.MaskedArray.cumprod()", "path": "reference/generated/numpy.ma.maskedarray.cumprod", "type": "numpy.ma.MaskedArray.cumprod", "text": "\nmethod\n\nReturn the cumulative product of the array elements over the given axis.\n\nMasked values are set to 1 internally during the computation. However, their\nposition is saved, and the result will be masked at the same locations.\n\nRefer to `numpy.cumprod` for full documentation.\n\nSee also\n\ncorresponding function for ndarrays\n\nequivalent function\n\nThe mask is lost if `out` is not a valid MaskedArray !\n\nArithmetic is modular when using integer types, and no error is raised on\noverflow.\n\n"}, {"name": "ma.MaskedArray.cumsum()", "path": "reference/generated/numpy.ma.maskedarray.cumsum", "type": "numpy.ma.MaskedArray.cumsum", "text": "\nmethod\n\nReturn the cumulative sum of the array elements over the given axis.\n\nMasked values are set to 0 internally during the computation. However, their\nposition is saved, and the result will be masked at the same locations.\n\nRefer to `numpy.cumsum` for full documentation.\n\nSee also\n\ncorresponding function for ndarrays\n\nequivalent function\n\nThe mask is lost if `out` is not a valid `ma.MaskedArray` !\n\nArithmetic is modular when using integer types, and no error is raised on\noverflow.\n\n"}, {"name": "ma.MaskedArray.diagonal()", "path": "reference/generated/numpy.ma.maskedarray.diagonal", "type": "Masked arrays", "text": "\nmethod\n\nReturn specified diagonals. In NumPy 1.9 the returned array is a read-only\nview instead of a copy as in previous NumPy versions. In a future version the\nread-only restriction will be removed.\n\nRefer to `numpy.diagonal` for full documentation.\n\nSee also\n\nequivalent function\n\n"}, {"name": "ma.MaskedArray.dump()", "path": "reference/generated/numpy.ma.maskedarray.dump", "type": "Masked arrays", "text": "\nmethod\n\nDump a pickle of the array to the specified file. The array can be read back\nwith pickle.load or numpy.load.\n\nA string naming the dump file.\n\nChanged in version 1.17.0: `pathlib.Path` objects are now accepted.\n\n"}, {"name": "ma.MaskedArray.dumps()", "path": "reference/generated/numpy.ma.maskedarray.dumps", "type": "Masked arrays", "text": "\nmethod\n\nReturns the pickle of the array as a string. pickle.loads will convert the\nstring back to an array.\n\n"}, {"name": "ma.MaskedArray.fill()", "path": "reference/generated/numpy.ma.maskedarray.fill", "type": "Masked arrays", "text": "\nmethod\n\nFill the array with a scalar value.\n\nAll elements of `a` will be assigned this value.\n\n"}, {"name": "ma.MaskedArray.filled()", "path": "reference/generated/numpy.ma.maskedarray.filled", "type": "numpy.ma.MaskedArray.filled", "text": "\nmethod\n\nReturn a copy of self, with masked values filled with a given value. However,\nif there are no masked values to fill, self will be returned instead as an\nndarray.\n\nThe value to use for invalid entries. Can be scalar or non-scalar. If non-\nscalar, the resulting ndarray must be broadcastable over input array. Default\nis None, in which case, the `fill_value` attribute of the array is used\ninstead.\n\nA copy of `self` with invalid entries replaced by fill_value (be it the\nfunction argument or the attribute of `self`), or `self` itself as an ndarray\nif there are no invalid entries to be replaced.\n\nThe result is not a MaskedArray!\n\nSubclassing is preserved. This means that if, e.g., the data part of the\nmasked array is a recarray, `filled` returns a recarray:\n\n"}, {"name": "ma.MaskedArray.flags", "path": "reference/generated/numpy.ma.maskedarray.flags", "type": "Masked arrays", "text": "\nattribute\n\nInformation about the memory layout of the array.\n\nThe `flags` object can be accessed dictionary-like (as in\n`a.flags['WRITEABLE']`), or by using lowercased attribute names (as in\n`a.flags.writeable`). Short flag names are only supported in dictionary\naccess.\n\nOnly the WRITEBACKIFCOPY, UPDATEIFCOPY, WRITEABLE, and ALIGNED flags can be\nchanged by the user, via direct assignment to the attribute or dictionary\nentry, or by calling `ndarray.setflags`.\n\nThe array flags cannot be set arbitrarily:\n\nArrays can be both C-style and Fortran-style contiguous simultaneously. This\nis clear for 1-dimensional arrays, but can also be true for higher dimensional\narrays.\n\nEven for contiguous arrays a stride for a given dimension `arr.strides[dim]`\nmay be arbitrary if `arr.shape[dim] == 1` or the array has no elements. It\ndoes not generally hold that `self.strides[-1] == self.itemsize` for C-style\ncontiguous arrays or `self.strides[0] == self.itemsize` for Fortran-style\ncontiguous arrays is true.\n\nThe data is in a single, C-style contiguous segment.\n\nThe data is in a single, Fortran-style contiguous segment.\n\nThe array owns the memory it uses or borrows it from another object.\n\nThe data area can be written to. Setting this to False locks the data, making\nit read-only. A view (slice, etc.) inherits WRITEABLE from its base array at\ncreation time, but a view of a writeable array may be subsequently locked\nwhile the base array remains writeable. (The opposite is not true, in that a\nview of a locked array may not be made writeable. However, currently, locking\na base object does not lock any views that already reference it, so under that\ncircumstance it is possible to alter the contents of a locked array via a\npreviously created writeable view onto it.) Attempting to change a non-\nwriteable array raises a RuntimeError exception.\n\nThe data and all elements are aligned appropriately for the hardware.\n\nThis array is a copy of some other array. The C-API function\nPyArray_ResolveWritebackIfCopy must be called before deallocating to the base\narray will be updated with the contents of this array.\n\n(Deprecated, use WRITEBACKIFCOPY) This array is a copy of some other array.\nWhen this array is deallocated, the base array will be updated with the\ncontents of this array.\n\nF_CONTIGUOUS and not C_CONTIGUOUS.\n\nF_CONTIGUOUS or C_CONTIGUOUS (one-segment test).\n\nALIGNED and WRITEABLE.\n\nBEHAVED and C_CONTIGUOUS.\n\nBEHAVED and F_CONTIGUOUS and not C_CONTIGUOUS.\n\n"}, {"name": "ma.MaskedArray.flatten()", "path": "reference/generated/numpy.ma.maskedarray.flatten", "type": "numpy.ma.MaskedArray.flatten", "text": "\nmethod\n\nReturn a copy of the array collapsed into one dimension.\n\n\u2018C\u2019 means to flatten in row-major (C-style) order. \u2018F\u2019 means to flatten in\ncolumn-major (Fortran- style) order. \u2018A\u2019 means to flatten in column-major\norder if `a` is Fortran contiguous in memory, row-major order otherwise. \u2018K\u2019\nmeans to flatten `a` in the order the elements occur in memory. The default is\n\u2018C\u2019.\n\nA copy of the input array, flattened to one dimension.\n\nSee also\n\nReturn a flattened array.\n\nA 1-D flat iterator over the array.\n\n"}, {"name": "ma.MaskedArray.get_fill_value()", "path": "reference/generated/numpy.ma.maskedarray.get_fill_value", "type": "numpy.ma.MaskedArray.get_fill_value", "text": "\nmethod\n\nThe filling value of the masked array is a scalar. When setting, None will set\nto a default based on the data type.\n\nReset to default:\n\n"}, {"name": "ma.MaskedArray.harden_mask()", "path": "reference/generated/numpy.ma.maskedarray.harden_mask", "type": "numpy.ma.MaskedArray.harden_mask", "text": "\nmethod\n\nForce the mask to hard.\n\nWhether the mask of a masked array is hard or soft is determined by its\n`hardmask` property. `harden_mask` sets `hardmask` to `True`.\n\nSee also\n\n"}, {"name": "ma.MaskedArray.ids()", "path": "reference/generated/numpy.ma.maskedarray.ids", "type": "Masked arrays", "text": "\nmethod\n\nReturn the addresses of the data and mask areas.\n\nIf the array has no mask, the address of `nomask` is returned. This address is\ntypically not close to the data in memory:\n\n"}, {"name": "ma.MaskedArray.iscontiguous()", "path": "reference/generated/numpy.ma.maskedarray.iscontiguous", "type": "Masked arrays", "text": "\nmethod\n\nReturn a boolean indicating whether the data is contiguous.\n\n`iscontiguous` returns one of the flags of the masked array:\n\n"}, {"name": "ma.MaskedArray.item()", "path": "reference/generated/numpy.ma.maskedarray.item", "type": "Masked arrays", "text": "\nmethod\n\nCopy an element of an array to a standard Python scalar and return it.\n\nA copy of the specified element of the array as a suitable Python scalar\n\nWhen the data type of `a` is longdouble or clongdouble, item() returns a\nscalar array object because there is no available Python scalar that would not\nlose information. Void arrays return a buffer object for item(), unless fields\nare defined, in which case a tuple is returned.\n\n`item` is very similar to a[args], except, instead of an array scalar, a\nstandard Python scalar is returned. This can be useful for speeding up access\nto elements of the array and doing arithmetic on elements of the array using\nPython\u2019s optimized math.\n\n"}, {"name": "ma.MaskedArray.itemsize", "path": "reference/generated/numpy.ma.maskedarray.itemsize", "type": "Masked arrays", "text": "\nattribute\n\nLength of one array element in bytes.\n\n"}, {"name": "ma.MaskedArray.max()", "path": "reference/generated/numpy.ma.maskedarray.max", "type": "numpy.ma.MaskedArray.max", "text": "\nmethod\n\nReturn the maximum along a given axis.\n\nAxis along which to operate. By default, `axis` is None and the flattened\ninput is used.\n\nAlternative output array in which to place the result. Must be of the same\nshape and buffer length as the expected output.\n\nValue used to fill in the masked values. If None, use the output of\nmaximum_fill_value().\n\nIf this is set to True, the axes which are reduced are left in the result as\ndimensions with size one. With this option, the result will broadcast\ncorrectly against the array.\n\nNew array holding the result. If `out` was specified, `out` is returned.\n\nSee also\n\nReturns the maximum filling value for a given datatype.\n\n"}, {"name": "ma.MaskedArray.mean()", "path": "reference/generated/numpy.ma.maskedarray.mean", "type": "numpy.ma.MaskedArray.mean", "text": "\nmethod\n\nReturns the average of the array elements along given axis.\n\nMasked entries are ignored, and result elements which are not finite will be\nmasked.\n\nRefer to `numpy.mean` for full documentation.\n\nSee also\n\ncorresponding function for ndarrays\n\nEquivalent function\n\nWeighted average.\n\n"}, {"name": "ma.MaskedArray.min()", "path": "reference/generated/numpy.ma.maskedarray.min", "type": "numpy.ma.MaskedArray.min", "text": "\nmethod\n\nReturn the minimum along a given axis.\n\nAxis along which to operate. By default, `axis` is None and the flattened\ninput is used.\n\nAlternative output array in which to place the result. Must be of the same\nshape and buffer length as the expected output.\n\nValue used to fill in the masked values. If None, use the output of\n`minimum_fill_value`.\n\nIf this is set to True, the axes which are reduced are left in the result as\ndimensions with size one. With this option, the result will broadcast\ncorrectly against the array.\n\nNew array holding the result. If `out` was specified, `out` is returned.\n\nSee also\n\nReturns the minimum filling value for a given datatype.\n\n"}, {"name": "ma.MaskedArray.nbytes", "path": "reference/generated/numpy.ma.maskedarray.nbytes", "type": "Masked arrays", "text": "\nattribute\n\nTotal bytes consumed by the elements of the array.\n\nDoes not include memory consumed by non-element attributes of the array\nobject.\n\n"}, {"name": "ma.MaskedArray.ndim", "path": "reference/generated/numpy.ma.maskedarray.ndim", "type": "Masked arrays", "text": "\nattribute\n\nNumber of array dimensions.\n\n"}, {"name": "ma.MaskedArray.nonzero()", "path": "reference/generated/numpy.ma.maskedarray.nonzero", "type": "numpy.ma.MaskedArray.nonzero", "text": "\nmethod\n\nReturn the indices of unmasked elements that are not zero.\n\nReturns a tuple of arrays, one for each dimension, containing the indices of\nthe non-zero elements in that dimension. The corresponding non-zero values can\nbe obtained with:\n\nTo group the indices by element, rather than dimension, use instead:\n\nThe result of this is always a 2d array, with a row for each non-zero element.\n\nIndices of elements that are non-zero.\n\nSee also\n\nFunction operating on ndarrays.\n\nReturn indices that are non-zero in the flattened version of the input array.\n\nEquivalent ndarray method.\n\nCounts the number of non-zero elements in the input array.\n\nMasked elements are ignored.\n\nIndices can also be grouped by element.\n\nA common use for `nonzero` is to find the indices of an array, where a\ncondition is True. Given an array `a`, the condition `a` > 3 is a boolean\narray and since False is interpreted as 0, ma.nonzero(a > 3) yields the\nindices of the `a` where the condition is true.\n\nThe `nonzero` method of the condition array can also be called.\n\n"}, {"name": "ma.MaskedArray.prod()", "path": "reference/generated/numpy.ma.maskedarray.prod", "type": "numpy.ma.MaskedArray.prod", "text": "\nmethod\n\nReturn the product of the array elements over the given axis.\n\nMasked elements are set to 1 internally for computation.\n\nRefer to `numpy.prod` for full documentation.\n\nSee also\n\ncorresponding function for ndarrays\n\nequivalent function\n\nArithmetic is modular when using integer types, and no error is raised on\noverflow.\n\n"}, {"name": "ma.MaskedArray.product()", "path": "reference/generated/numpy.ma.maskedarray.product", "type": "Masked arrays", "text": "\nmethod\n\nReturn the product of the array elements over the given axis.\n\nMasked elements are set to 1 internally for computation.\n\nRefer to `numpy.prod` for full documentation.\n\nSee also\n\ncorresponding function for ndarrays\n\nequivalent function\n\nArithmetic is modular when using integer types, and no error is raised on\noverflow.\n\n"}, {"name": "ma.MaskedArray.ptp()", "path": "reference/generated/numpy.ma.maskedarray.ptp", "type": "numpy.ma.MaskedArray.ptp", "text": "\nmethod\n\nReturn (maximum - minimum) along the given dimension (i.e. peak-to-peak\nvalue).\n\nWarning\n\n`ptp` preserves the data type of the array. This means the return value for an\ninput of signed integers with n bits (e.g. `np.int8`, `np.int16`, etc) is also\na signed integer with n bits. In that case, peak-to-peak values greater than\n`2**(n-1)-1` will be returned as negative values. An example with a work-\naround is shown below.\n\nAxis along which to find the peaks. If None (default) the flattened array is\nused.\n\nAlternative output array in which to place the result. It must have the same\nshape and buffer length as the expected output but the type will be cast if\nnecessary.\n\nValue used to fill in the masked values.\n\nIf this is set to True, the axes which are reduced are left in the result as\ndimensions with size one. With this option, the result will broadcast\ncorrectly against the array.\n\nA new array holding the result, unless `out` was specified, in which case a\nreference to `out` is returned.\n\nThis example shows that a negative value can be returned when the input is an\narray of signed integers.\n\nA work-around is to use the `view()` method to view the result as unsigned\nintegers with the same bit width:\n\n"}, {"name": "ma.MaskedArray.put()", "path": "reference/generated/numpy.ma.maskedarray.put", "type": "Masked arrays", "text": "\nmethod\n\nSet storage-indexed locations to corresponding values.\n\nSets self._data.flat[n] = values[n] for each n in indices. If `values` is\nshorter than `indices` then it will repeat. If `values` has some masked\nvalues, the initial mask is updated in consequence, else the corresponding\nvalues are unmasked.\n\nTarget indices, interpreted as integers.\n\nValues to place in self._data copy at target indices.\n\nSpecifies how out-of-bounds indices will behave. \u2018raise\u2019 : raise an error.\n\u2018wrap\u2019 : wrap around. \u2018clip\u2019 : clip to the range.\n\n`values` can be a scalar or length 1 array.\n\n"}, {"name": "ma.MaskedArray.ravel()", "path": "reference/generated/numpy.ma.maskedarray.ravel", "type": "numpy.ma.MaskedArray.ravel", "text": "\nmethod\n\nReturns a 1D version of self, as a view.\n\nThe elements of `a` are read using this index order. \u2018C\u2019 means to index the\nelements in C-like order, with the last axis index changing fastest, back to\nthe first axis index changing slowest. \u2018F\u2019 means to index the elements in\nFortran-like index order, with the first index changing fastest, and the last\nindex changing slowest. Note that the \u2018C\u2019 and \u2018F\u2019 options take no account of\nthe memory layout of the underlying array, and only refer to the order of axis\nindexing. \u2018A\u2019 means to read the elements in Fortran-like index order if `m` is\nFortran contiguous in memory, C-like order otherwise. \u2018K\u2019 means to read the\nelements in the order they occur in memory, except for reversing the data when\nstrides are negative. By default, \u2018C\u2019 index order is used.\n\nOutput view is of shape `(self.size,)` (or `(np.ma.product(self.shape),)`).\n\n"}, {"name": "ma.MaskedArray.repeat()", "path": "reference/generated/numpy.ma.maskedarray.repeat", "type": "Masked arrays", "text": "\nmethod\n\nRepeat elements of an array.\n\nRefer to `numpy.repeat` for full documentation.\n\nSee also\n\nequivalent function\n\n"}, {"name": "ma.MaskedArray.reshape()", "path": "reference/generated/numpy.ma.maskedarray.reshape", "type": "numpy.ma.MaskedArray.reshape", "text": "\nmethod\n\nGive a new shape to the array without changing its data.\n\nReturns a masked array containing the same data, but with a new shape. The\nresult is a view on the original array; if this is not possible, a ValueError\nis raised.\n\nThe new shape should be compatible with the original shape. If an integer is\nsupplied, then the result will be a 1-D array of that length.\n\nDetermines whether the array data should be viewed as in C (row-major) or\nFORTRAN (column-major) order.\n\nA new view on the array.\n\nSee also\n\nEquivalent function in the masked array module.\n\nEquivalent method on ndarray object.\n\nEquivalent function in the NumPy module.\n\nThe reshaping operation cannot guarantee that a copy will not be made, to\nmodify the shape in place, use `a.shape = s`\n\n"}, {"name": "ma.MaskedArray.resize()", "path": "reference/generated/numpy.ma.maskedarray.resize", "type": "numpy.ma.MaskedArray.resize", "text": "\nmethod\n\nWarning\n\nThis method does nothing, except raise a ValueError exception. A masked array\ndoes not own its data and therefore cannot safely be resized in place. Use the\n`numpy.ma.resize` function instead.\n\nThis method is difficult to implement safely and may be deprecated in future\nreleases of NumPy.\n\n"}, {"name": "ma.MaskedArray.round()", "path": "reference/generated/numpy.ma.maskedarray.round", "type": "numpy.ma.MaskedArray.round", "text": "\nmethod\n\nReturn each element rounded to the given number of decimals.\n\nRefer to `numpy.around` for full documentation.\n\nSee also\n\ncorresponding function for ndarrays\n\nequivalent function\n\n"}, {"name": "ma.MaskedArray.searchsorted()", "path": "reference/generated/numpy.ma.maskedarray.searchsorted", "type": "Masked arrays", "text": "\nmethod\n\nFind indices where elements of v should be inserted in a to maintain order.\n\nFor full documentation, see `numpy.searchsorted`\n\nSee also\n\nequivalent function\n\n"}, {"name": "ma.MaskedArray.set_fill_value()", "path": "reference/generated/numpy.ma.maskedarray.set_fill_value", "type": "numpy.ma.MaskedArray.set_fill_value", "text": "\nmethod\n\n"}, {"name": "ma.MaskedArray.shrink_mask()", "path": "reference/generated/numpy.ma.maskedarray.shrink_mask", "type": "numpy.ma.MaskedArray.shrink_mask", "text": "\nmethod\n\nReduce a mask to nomask when possible.\n\n"}, {"name": "ma.MaskedArray.size", "path": "reference/generated/numpy.ma.maskedarray.size", "type": "Masked arrays", "text": "\nattribute\n\nNumber of elements in the array.\n\nEqual to `np.prod(a.shape)`, i.e., the product of the array\u2019s dimensions.\n\n`a.size` returns a standard arbitrary precision Python integer. This may not\nbe the case with other methods of obtaining the same value (like the suggested\n`np.prod(a.shape)`, which returns an instance of `np.int_`), and may be\nrelevant if the value is used further in calculations that may overflow a\nfixed size integer type.\n\n"}, {"name": "ma.MaskedArray.soften_mask()", "path": "reference/generated/numpy.ma.maskedarray.soften_mask", "type": "numpy.ma.MaskedArray.soften_mask", "text": "\nmethod\n\nForce the mask to soft.\n\nWhether the mask of a masked array is hard or soft is determined by its\n`hardmask` property. `soften_mask` sets `hardmask` to `False`.\n\nSee also\n\n"}, {"name": "ma.MaskedArray.sort()", "path": "reference/generated/numpy.ma.maskedarray.sort", "type": "numpy.ma.MaskedArray.sort", "text": "\nmethod\n\nSort the array, in-place\n\nArray to be sorted.\n\nAxis along which to sort. If None, the array is flattened before sorting. The\ndefault is -1, which sorts along the last axis.\n\nThe sorting algorithm used.\n\nWhen `a` is a structured array, this argument specifies which fields to\ncompare first, second, and so on. This list does not need to include all of\nthe fields.\n\nWhether missing values (if any) should be treated as the largest values (True)\nor the smallest values (False) When the array contains unmasked values sorting\nat the same extremes of the datatype, the ordering of these values and the\nmasked values is undefined.\n\nValue used internally for the masked values. If `fill_value` is not None, it\nsupersedes `endwith`.\n\nArray of the same type and shape as `a`.\n\nSee also\n\nMethod to sort an array in-place.\n\nIndirect sort.\n\nIndirect stable sort on multiple keys.\n\nFind elements in a sorted array.\n\nSee `sort` for notes on the different sorting algorithms.\n\n"}, {"name": "ma.MaskedArray.squeeze()", "path": "reference/generated/numpy.ma.maskedarray.squeeze", "type": "numpy.ma.MaskedArray.squeeze", "text": "\nmethod\n\nRemove axes of length one from `a`.\n\nRefer to `numpy.squeeze` for full documentation.\n\nSee also\n\nequivalent function\n\n"}, {"name": "ma.MaskedArray.std()", "path": "reference/generated/numpy.ma.maskedarray.std", "type": "numpy.ma.MaskedArray.std", "text": "\nmethod\n\nReturns the standard deviation of the array elements along given axis.\n\nMasked entries are ignored.\n\nRefer to `numpy.std` for full documentation.\n\nSee also\n\ncorresponding function for ndarrays\n\nEquivalent function\n\n"}, {"name": "ma.MaskedArray.strides", "path": "reference/generated/numpy.ma.maskedarray.strides", "type": "Masked arrays", "text": "\nattribute\n\nTuple of bytes to step in each dimension when traversing an array.\n\nThe byte offset of element `(i[0], i[1], ..., i[n])` in an array `a` is:\n\nA more detailed explanation of strides can be found in the \u201cndarray.rst\u201d file\nin the NumPy reference guide.\n\nSee also\n\nImagine an array of 32-bit integers (each 4 bytes):\n\nThis array is stored in memory as 40 bytes, one after the other (known as a\ncontiguous block of memory). The strides of an array tell us how many bytes we\nhave to skip in memory to move to the next position along a certain axis. For\nexample, we have to skip 4 bytes (1 value) to move to the next column, but 20\nbytes (5 values) to get to the same position in the next row. As such, the\nstrides for the array `x` will be `(20, 4)`.\n\n"}, {"name": "ma.MaskedArray.sum()", "path": "reference/generated/numpy.ma.maskedarray.sum", "type": "numpy.ma.MaskedArray.sum", "text": "\nmethod\n\nReturn the sum of the array elements over the given axis.\n\nMasked elements are set to 0 internally.\n\nRefer to `numpy.sum` for full documentation.\n\nSee also\n\ncorresponding function for ndarrays\n\nequivalent function\n\n"}, {"name": "ma.MaskedArray.swapaxes()", "path": "reference/generated/numpy.ma.maskedarray.swapaxes", "type": "numpy.ma.MaskedArray.swapaxes", "text": "\nmethod\n\nReturn a view of the array with `axis1` and `axis2` interchanged.\n\nRefer to `numpy.swapaxes` for full documentation.\n\nSee also\n\nequivalent function\n\n"}, {"name": "ma.MaskedArray.take()", "path": "reference/generated/numpy.ma.maskedarray.take", "type": "Masked arrays", "text": "\nmethod\n\n"}, {"name": "ma.MaskedArray.tobytes()", "path": "reference/generated/numpy.ma.maskedarray.tobytes", "type": "numpy.ma.MaskedArray.tobytes", "text": "\nmethod\n\nReturn the array data as a string containing the raw bytes in the array.\n\nThe array is filled with a fill value before the string conversion.\n\nNew in version 1.9.0.\n\nValue used to fill in the masked values. Default is None, in which case\n`MaskedArray.fill_value` is used.\n\nOrder of the data item in the copy. Default is \u2018C\u2019.\n\nSee also\n\nAs for `ndarray.tobytes`, information about the shape, dtype, etc., but also\nabout `fill_value`, will be lost.\n\n"}, {"name": "ma.MaskedArray.tofile()", "path": "reference/generated/numpy.ma.maskedarray.tofile", "type": "numpy.ma.MaskedArray.tofile", "text": "\nmethod\n\nSave a masked array to a file in binary format.\n\nWarning\n\nThis function is not implemented yet.\n\nWhen `tofile` is called.\n\n"}, {"name": "ma.MaskedArray.toflex()", "path": "reference/generated/numpy.ma.maskedarray.toflex", "type": "Masked arrays", "text": "\nmethod\n\nTransforms a masked array into a flexible-type array.\n\nThe flexible type array that is returned will have two fields:\n\nA new flexible-type `ndarray` with two fields: the first element containing a\nvalue, the second element containing the corresponding mask boolean. The\nreturned record shape matches self.shape.\n\nA side-effect of transforming a masked array into a flexible `ndarray` is that\nmeta information (`fill_value`, \u2026) will be lost.\n\n"}, {"name": "ma.MaskedArray.tolist()", "path": "reference/generated/numpy.ma.maskedarray.tolist", "type": "numpy.ma.MaskedArray.tolist", "text": "\nmethod\n\nReturn the data portion of the masked array as a hierarchical Python list.\n\nData items are converted to the nearest compatible Python type. Masked values\nare converted to `fill_value`. If `fill_value` is None, the corresponding\nentries in the output list will be `None`.\n\nThe value to use for invalid entries. Default is None.\n\nThe Python list representation of the masked array.\n\n"}, {"name": "ma.MaskedArray.torecords()", "path": "reference/generated/numpy.ma.maskedarray.torecords", "type": "numpy.ma.MaskedArray.torecords", "text": "\nmethod\n\nTransforms a masked array into a flexible-type array.\n\nThe flexible type array that is returned will have two fields:\n\nA new flexible-type `ndarray` with two fields: the first element containing a\nvalue, the second element containing the corresponding mask boolean. The\nreturned record shape matches self.shape.\n\nA side-effect of transforming a masked array into a flexible `ndarray` is that\nmeta information (`fill_value`, \u2026) will be lost.\n\n"}, {"name": "ma.MaskedArray.tostring()", "path": "reference/generated/numpy.ma.maskedarray.tostring", "type": "Masked arrays", "text": "\nmethod\n\nA compatibility alias for `tobytes`, with exactly the same behavior.\n\nDespite its name, it returns `bytes` not `str`s.\n\nDeprecated since version 1.19.0.\n\n"}, {"name": "ma.MaskedArray.trace()", "path": "reference/generated/numpy.ma.maskedarray.trace", "type": "numpy.ma.MaskedArray.trace", "text": "\nmethod\n\nReturn the sum along diagonals of the array.\n\nRefer to `numpy.trace` for full documentation.\n\nSee also\n\nequivalent function\n\n"}, {"name": "ma.MaskedArray.transpose()", "path": "reference/generated/numpy.ma.maskedarray.transpose", "type": "numpy.ma.MaskedArray.transpose", "text": "\nmethod\n\nReturns a view of the array with axes transposed.\n\nFor a 1-D array this has no effect, as a transposed vector is simply the same\nvector. To convert a 1-D array into a 2D column vector, an additional\ndimension must be added. `np.atleast2d(a).T` achieves this, as does `a[:,\nnp.newaxis]`. For a 2-D array, this is a standard matrix transpose. For an n-D\narray, if axes are given, their order indicates how the axes are permuted (see\nExamples). If axes are not provided and `a.shape = (i[0], i[1], ... i[n-2],\ni[n-1])`, then `a.transpose().shape = (i[n-1], i[n-2], ... i[1], i[0])`.\n\nView of `a`, with axes suitably permuted.\n\nSee also\n\nEquivalent function\n\nArray property returning the array transposed.\n\nGive a new shape to an array without changing its data.\n\n"}, {"name": "ma.MaskedArray.unshare_mask()", "path": "reference/generated/numpy.ma.maskedarray.unshare_mask", "type": "numpy.ma.MaskedArray.unshare_mask", "text": "\nmethod\n\nCopy the mask and set the sharedmask flag to False.\n\nWhether the mask is shared between masked arrays can be seen from the\n`sharedmask` property. `unshare_mask` ensures the mask is not shared. A copy\nof the mask is only made if it was shared.\n\nSee also\n\n"}, {"name": "ma.MaskedArray.var()", "path": "reference/generated/numpy.ma.maskedarray.var", "type": "numpy.ma.MaskedArray.var", "text": "\nmethod\n\nCompute the variance along the specified axis.\n\nReturns the variance of the array elements, a measure of the spread of a\ndistribution. The variance is computed for the flattened array by default,\notherwise over the specified axis.\n\nArray containing numbers whose variance is desired. If `a` is not an array, a\nconversion is attempted.\n\nAxis or axes along which the variance is computed. The default is to compute\nthe variance of the flattened array.\n\nNew in version 1.7.0.\n\nIf this is a tuple of ints, a variance is performed over multiple axes,\ninstead of a single axis or all the axes as before.\n\nType to use in computing the variance. For arrays of integer type the default\nis `float64`; for arrays of float types it is the same as the array type.\n\nAlternate output array in which to place the result. It must have the same\nshape as the expected output, but the type is cast if necessary.\n\n\u201cDelta Degrees of Freedom\u201d: the divisor used in the calculation is `N - ddof`,\nwhere `N` represents the number of elements. By default `ddof` is zero.\n\nIf this is set to True, the axes which are reduced are left in the result as\ndimensions with size one. With this option, the result will broadcast\ncorrectly against the input array.\n\nIf the default value is passed, then `keepdims` will not be passed through to\nthe `var` method of sub-classes of `ndarray`, however any non-default value\nwill be. If the sub-class\u2019 method does not implement `keepdims` any exceptions\nwill be raised.\n\nElements to include in the variance. See `reduce` for details.\n\nNew in version 1.20.0.\n\nIf `out=None`, returns a new array containing the variance; otherwise, a\nreference to the output array is returned.\n\nSee also\n\nThe variance is the average of the squared deviations from the mean, i.e.,\n`var = mean(x)`, where `x = abs(a - a.mean())**2`.\n\nThe mean is typically calculated as `x.sum() / N`, where `N = len(x)`. If,\nhowever, `ddof` is specified, the divisor `N - ddof` is used instead. In\nstandard statistical practice, `ddof=1` provides an unbiased estimator of the\nvariance of a hypothetical infinite population. `ddof=0` provides a maximum\nlikelihood estimate of the variance for normally distributed variables.\n\nNote that for complex numbers, the absolute value is taken before squaring, so\nthat the result is always real and nonnegative.\n\nFor floating-point input, the variance is computed using the same precision\nthe input has. Depending on the input data, this can cause the results to be\ninaccurate, especially for `float32` (see example below). Specifying a higher-\naccuracy accumulator using the `dtype` keyword can alleviate this issue.\n\nIn single precision, var() can be inaccurate:\n\nComputing the variance in float64 is more accurate:\n\nSpecifying a where argument:\n\n"}, {"name": "ma.MaskedArray.view()", "path": "reference/generated/numpy.ma.maskedarray.view", "type": "Masked arrays", "text": "\nmethod\n\nReturn a view of the MaskedArray data.\n\nData-type descriptor of the returned view, e.g., float32 or int16. The\ndefault, None, results in the view having the same data-type as `a`. As with\n`ndarray.view`, dtype can also be specified as an ndarray sub-class, which\nthen specifies the type of the returned object (this is equivalent to setting\nthe `type` parameter).\n\nType of the returned view, either ndarray or a subclass. The default None\nresults in type preservation.\n\nThe value to use for invalid entries (None by default). If None, then this\nargument is inferred from the passed `dtype`, or in its absence the original\narray, as discussed in the notes below.\n\nSee also\n\nEquivalent method on ndarray object.\n\n`a.view()` is used two different ways:\n\n`a.view(some_dtype)` or `a.view(dtype=some_dtype)` constructs a view of the\narray\u2019s memory with a different data-type. This can cause a reinterpretation\nof the bytes of memory.\n\n`a.view(ndarray_subclass)` or `a.view(type=ndarray_subclass)` just returns an\ninstance of `ndarray_subclass` that looks at the same array (same shape,\ndtype, etc.) This does not cause a reinterpretation of the memory.\n\nIf `fill_value` is not specified, but `dtype` is specified (and is not an\nndarray sub-class), the `fill_value` of the MaskedArray will be reset. If\nneither `fill_value` nor `dtype` are specified (or if `dtype` is an ndarray\nsub-class), then the fill value is preserved. Finally, if `fill_value` is\nspecified, but `dtype` is not, the fill value is set to the specified value.\n\nFor `a.view(some_dtype)`, if `some_dtype` has a different number of bytes per\nentry than the previous dtype (for example, converting a regular array to a\nstructured array), then the behavior of the view cannot be predicted just from\nthe superficial appearance of `a` (shown by `print(a)`). It also depends on\nexactly how `a` is stored in memory. Therefore if `a` is C-ordered versus\nfortran-ordered, versus defined as a slice or transpose, etc., the view may\ngive different results.\n\n"}, {"name": "ma.max()", "path": "reference/generated/numpy.ma.max", "type": "numpy.ma.max", "text": "\nReturn the maximum along a given axis.\n\nAxis along which to operate. By default, `axis` is None and the flattened\ninput is used.\n\nAlternative output array in which to place the result. Must be of the same\nshape and buffer length as the expected output.\n\nValue used to fill in the masked values. If None, use the output of\nmaximum_fill_value().\n\nIf this is set to True, the axes which are reduced are left in the result as\ndimensions with size one. With this option, the result will broadcast\ncorrectly against the array.\n\nNew array holding the result. If `out` was specified, `out` is returned.\n\nSee also\n\nReturns the maximum filling value for a given datatype.\n\n"}, {"name": "ma.maximum_fill_value()", "path": "reference/generated/numpy.ma.maximum_fill_value", "type": "numpy.ma.maximum_fill_value", "text": "\nReturn the minimum value that can be represented by the dtype of an object.\n\nThis function is useful for calculating a fill value suitable for taking the\nmaximum of an array with a given dtype.\n\nAn object that can be queried for it\u2019s numeric type.\n\nThe minimum representable value.\n\nIf `obj` isn\u2019t a suitable numeric type.\n\nSee also\n\nThe inverse function.\n\nSet the filling value of a masked array.\n\nReturn current fill value.\n\nAn array of numeric data can also be passed.\n\n"}, {"name": "ma.mean()", "path": "reference/generated/numpy.ma.mean", "type": "numpy.ma.mean", "text": "\nReturns the average of the array elements along given axis.\n\nMasked entries are ignored, and result elements which are not finite will be\nmasked.\n\nRefer to `numpy.mean` for full documentation.\n\nSee also\n\ncorresponding function for ndarrays\n\nEquivalent function\n\nWeighted average.\n\n"}, {"name": "ma.median()", "path": "reference/generated/numpy.ma.median", "type": "numpy.ma.median", "text": "\nCompute the median along the specified axis.\n\nReturns the median of the array elements.\n\nInput array or object that can be converted to an array.\n\nAxis along which the medians are computed. The default (None) is to compute\nthe median along a flattened version of the array.\n\nAlternative output array in which to place the result. It must have the same\nshape and buffer length as the expected output but the type will be cast if\nnecessary.\n\nIf True, then allow use of memory of input array (a) for calculations. The\ninput array will be modified by the call to median. This will save memory when\nyou do not need to preserve the contents of the input array. Treat the input\nas undefined, but it will probably be fully or partially sorted. Default is\nFalse. Note that, if `overwrite_input` is True, and the input is not already\nan `ndarray`, an error will be raised.\n\nIf this is set to True, the axes which are reduced are left in the result as\ndimensions with size one. With this option, the result will broadcast\ncorrectly against the input array.\n\nNew in version 1.10.0.\n\nA new array holding the result is returned unless out is specified, in which\ncase a reference to out is returned. Return data-type is `float64` for\nintegers and floats smaller than `float64`, or the input data-type, otherwise.\n\nSee also\n\nGiven a vector `V` with `N` non masked values, the median of `V` is the middle\nvalue of a sorted copy of `V` (`Vs`) - i.e. `Vs[(N-1)/2]`, when `N` is odd, or\n`{Vs[N/2 - 1] + Vs[N/2]}/2` when `N` is even.\n\n"}, {"name": "ma.min()", "path": "reference/generated/numpy.ma.min", "type": "numpy.ma.min", "text": "\nReturn the minimum along a given axis.\n\nAxis along which to operate. By default, `axis` is None and the flattened\ninput is used.\n\nAlternative output array in which to place the result. Must be of the same\nshape and buffer length as the expected output.\n\nValue used to fill in the masked values. If None, use the output of\n`minimum_fill_value`.\n\nIf this is set to True, the axes which are reduced are left in the result as\ndimensions with size one. With this option, the result will broadcast\ncorrectly against the array.\n\nNew array holding the result. If `out` was specified, `out` is returned.\n\nSee also\n\nReturns the minimum filling value for a given datatype.\n\n"}, {"name": "ma.minimum_fill_value()", "path": "reference/generated/numpy.ma.minimum_fill_value", "type": "numpy.ma.minimum_fill_value", "text": "\nReturn the maximum value that can be represented by the dtype of an object.\n\nThis function is useful for calculating a fill value suitable for taking the\nminimum of an array with a given dtype.\n\nAn object that can be queried for it\u2019s numeric type.\n\nThe maximum representable value.\n\nIf `obj` isn\u2019t a suitable numeric type.\n\nSee also\n\nThe inverse function.\n\nSet the filling value of a masked array.\n\nReturn current fill value.\n\nAn array of numeric data can also be passed.\n\n"}, {"name": "ma.mr_", "path": "reference/generated/numpy.ma.mr_", "type": "numpy.ma.mr_", "text": "\nTranslate slice objects to concatenation along the first axis.\n\nThis is the masked array version of `lib.index_tricks.RClass`.\n\nSee also\n\n"}, {"name": "ma.nonzero()", "path": "reference/generated/numpy.ma.nonzero", "type": "numpy.ma.nonzero", "text": "\nReturn the indices of unmasked elements that are not zero.\n\nReturns a tuple of arrays, one for each dimension, containing the indices of\nthe non-zero elements in that dimension. The corresponding non-zero values can\nbe obtained with:\n\nTo group the indices by element, rather than dimension, use instead:\n\nThe result of this is always a 2d array, with a row for each non-zero element.\n\nIndices of elements that are non-zero.\n\nSee also\n\nFunction operating on ndarrays.\n\nReturn indices that are non-zero in the flattened version of the input array.\n\nEquivalent ndarray method.\n\nCounts the number of non-zero elements in the input array.\n\nMasked elements are ignored.\n\nIndices can also be grouped by element.\n\nA common use for `nonzero` is to find the indices of an array, where a\ncondition is True. Given an array `a`, the condition `a` > 3 is a boolean\narray and since False is interpreted as 0, ma.nonzero(a > 3) yields the\nindices of the `a` where the condition is true.\n\nThe `nonzero` method of the condition array can also be called.\n\n"}, {"name": "ma.notmasked_contiguous()", "path": "reference/generated/numpy.ma.notmasked_contiguous", "type": "numpy.ma.notmasked_contiguous", "text": "\nFind contiguous unmasked data in a masked array along the given axis.\n\nThe input array.\n\nAxis along which to perform the operation. If None (default), applies to a\nflattened version of the array, and this is the same as\n`flatnotmasked_contiguous`.\n\nA list of slices (start and end indexes) of unmasked indexes in the array.\n\nIf the input is 2d and axis is specified, the result is a list of lists.\n\nSee also\n\nOnly accepts 2-D arrays at most.\n\n"}, {"name": "ma.notmasked_edges()", "path": "reference/generated/numpy.ma.notmasked_edges", "type": "numpy.ma.notmasked_edges", "text": "\nFind the indices of the first and last unmasked values along an axis.\n\nIf all values are masked, return None. Otherwise, return a list of two tuples,\ncorresponding to the indices of the first and last unmasked values\nrespectively.\n\nThe input array.\n\nAxis along which to perform the operation. If None (default), applies to a\nflattened version of the array.\n\nAn array of start and end indexes if there are any masked data in the array.\nIf there are no masked data in the array, `edges` is a list of the first and\nlast index.\n\nSee also\n\n"}, {"name": "ma.ones()", "path": "reference/generated/numpy.ma.ones", "type": "numpy.ma.ones", "text": "\nReturn a new array of given shape and type, filled with ones.\n\nShape of the new array, e.g., `(2, 3)` or `2`.\n\nThe desired data-type for the array, e.g., `numpy.int8`. Default is\n`numpy.float64`.\n\nWhether to store multi-dimensional data in row-major (C-style) or column-major\n(Fortran-style) order in memory.\n\nReference object to allow the creation of arrays which are not NumPy arrays.\nIf an array-like passed in as `like` supports the `__array_function__`\nprotocol, the result will be defined by it. In this case, it ensures the\ncreation of an array object compatible with that passed in via this argument.\n\nNew in version 1.20.0.\n\nArray of ones with the given shape, dtype, and order.\n\nSee also\n\nReturn an array of ones with shape and type of input.\n\nReturn a new uninitialized array.\n\nReturn a new array setting values to zero.\n\nReturn a new array of given shape filled with value.\n\n"}, {"name": "ma.ones_like()", "path": "reference/generated/numpy.ma.ones_like", "type": "numpy.ma.ones_like", "text": "\nReturn an array of ones with the same shape and type as a given array.\n\nThe shape and data-type of `a` define these same attributes of the returned\narray.\n\nOverrides the data type of the result.\n\nNew in version 1.6.0.\n\nOverrides the memory layout of the result. \u2018C\u2019 means C-order, \u2018F\u2019 means\nF-order, \u2018A\u2019 means \u2018F\u2019 if `a` is Fortran contiguous, \u2018C\u2019 otherwise. \u2018K\u2019 means\nmatch the layout of `a` as closely as possible.\n\nNew in version 1.6.0.\n\nIf True, then the newly created array will use the sub-class type of `a`,\notherwise it will be a base-class array. Defaults to True.\n\nOverrides the shape of the result. If order=\u2019K\u2019 and the number of dimensions\nis unchanged, will try to keep order, otherwise, order=\u2019C\u2019 is implied.\n\nNew in version 1.17.0.\n\nArray of ones with the same shape and type as `a`.\n\nSee also\n\nReturn an empty array with shape and type of input.\n\nReturn an array of zeros with shape and type of input.\n\nReturn a new array with shape of input filled with value.\n\nReturn a new array setting values to one.\n\n"}, {"name": "ma.outer()", "path": "reference/generated/numpy.ma.outer", "type": "numpy.ma.outer", "text": "\nCompute the outer product of two vectors.\n\nGiven two vectors, `a = [a0, a1, ..., aM]` and `b = [b0, b1, ..., bN]`, the\nouter product [1] is:\n\nFirst input vector. Input is flattened if not already 1-dimensional.\n\nSecond input vector. Input is flattened if not already 1-dimensional.\n\nA location where the result is stored\n\nNew in version 1.9.0.\n\n`out[i, j] = a[i] * b[j]`\n\nSee also\n\n`einsum('i,j->ij', a.ravel(), b.ravel())` is the equivalent.\n\nA generalization to dimensions other than 1D and other operations.\n`np.multiply.outer(a.ravel(), b.ravel())` is the equivalent.\n\n`np.tensordot(a.ravel(), b.ravel(), axes=((), ()))` is the equivalent.\n\nMasked values are replaced by 0.\n\n: G. H. Golub and C. F. Van Loan, Matrix Computations, 3rd ed., Baltimore, MD,\nJohns Hopkins University Press, 1996, pg. 8.\n\nMake a (very coarse) grid for computing a Mandelbrot set:\n\nAn example using a \u201cvector\u201d of letters:\n\n"}, {"name": "ma.outerproduct()", "path": "reference/generated/numpy.ma.outerproduct", "type": "numpy.ma.outerproduct", "text": "\nCompute the outer product of two vectors.\n\nGiven two vectors, `a = [a0, a1, ..., aM]` and `b = [b0, b1, ..., bN]`, the\nouter product [1] is:\n\nFirst input vector. Input is flattened if not already 1-dimensional.\n\nSecond input vector. Input is flattened if not already 1-dimensional.\n\nA location where the result is stored\n\nNew in version 1.9.0.\n\n`out[i, j] = a[i] * b[j]`\n\nSee also\n\n`einsum('i,j->ij', a.ravel(), b.ravel())` is the equivalent.\n\nA generalization to dimensions other than 1D and other operations.\n`np.multiply.outer(a.ravel(), b.ravel())` is the equivalent.\n\n`np.tensordot(a.ravel(), b.ravel(), axes=((), ()))` is the equivalent.\n\nMasked values are replaced by 0.\n\n: G. H. Golub and C. F. Van Loan, Matrix Computations, 3rd ed., Baltimore, MD,\nJohns Hopkins University Press, 1996, pg. 8.\n\nMake a (very coarse) grid for computing a Mandelbrot set:\n\nAn example using a \u201cvector\u201d of letters:\n\n"}, {"name": "ma.polyfit()", "path": "reference/generated/numpy.ma.polyfit", "type": "numpy.ma.polyfit", "text": "\nLeast squares polynomial fit.\n\nNote\n\nThis forms part of the old polynomial API. Since version 1.4, the new\npolynomial API defined in `numpy.polynomial` is preferred. A summary of the\ndifferences can be found in the transition guide.\n\nFit a polynomial `p(x) = p[0] * x**deg + ... + p[deg]` of degree `deg` to\npoints `(x, y)`. Returns a vector of coefficients `p` that minimises the\nsquared error in the order `deg`, `deg-1`, \u2026 `0`.\n\nThe `Polynomial.fit` class method is recommended for new code as it is more\nstable numerically. See the documentation of the method for more information.\n\nx-coordinates of the M sample points `(x[i], y[i])`.\n\ny-coordinates of the sample points. Several data sets of sample points sharing\nthe same x-coordinates can be fitted at once by passing in a 2D-array that\ncontains one dataset per column.\n\nDegree of the fitting polynomial\n\nRelative condition number of the fit. Singular values smaller than this\nrelative to the largest singular value will be ignored. The default value is\nlen(x)*eps, where eps is the relative precision of the float type, about 2e-16\nin most cases.\n\nSwitch determining nature of return value. When it is False (the default) just\nthe coefficients are returned, when True diagnostic information from the\nsingular value decomposition is also returned.\n\nWeights. If not None, the weight `w[i]` applies to the unsquared residual\n`y[i] - y_hat[i]` at `x[i]`. Ideally the weights are chosen so that the errors\nof the products `w[i]*y[i]` all have the same variance. When using inverse-\nvariance weighting, use `w[i] = 1/sigma(y[i])`. The default value is None.\n\nIf given and not `False`, return not just the estimate but also its covariance\nmatrix. By default, the covariance are scaled by chi2/dof, where dof = M -\n(deg + 1), i.e., the weights are presumed to be unreliable except in a\nrelative sense and everything is scaled such that the reduced chi2 is unity.\nThis scaling is omitted if `cov='unscaled'`, as is relevant for the case that\nthe weights are w = 1/sigma, with sigma known to be a reliable estimate of the\nuncertainty.\n\nPolynomial coefficients, highest power first. If `y` was 2-D, the coefficients\nfor `k`-th data set are in `p[:,k]`.\n\nThese values are only returned if `full == True`\n\ncoefficient matrix\n\ncoefficient matrix\n\nFor more details, see `numpy.linalg.lstsq`.\n\nPresent only if `full == False` and `cov == True`. The covariance matrix of\nthe polynomial coefficient estimates. The diagonal of this matrix are the\nvariance estimates for each coefficient. If y is a 2-D array, then the\ncovariance matrix for the `k`-th data set are in `V[:,:,k]`\n\nThe rank of the coefficient matrix in the least-squares fit is deficient. The\nwarning is only raised if `full == False`.\n\nThe warnings can be turned off by\n\nSee also\n\nCompute polynomial values.\n\nComputes a least-squares fit.\n\nComputes spline fits.\n\nAny masked values in x is propagated in y, and vice-versa.\n\nThe solution minimizes the squared error\n\nin the equations:\n\nThe coefficient matrix of the coefficients `p` is a Vandermonde matrix.\n\n`polyfit` issues a `RankWarning` when the least-squares fit is badly\nconditioned. This implies that the best fit is not well-defined due to\nnumerical error. The results may be improved by lowering the polynomial degree\nor by replacing `x` by `x` \\- `x`.mean(). The `rcond` parameter can also be\nset to a value smaller than its default, but the resulting fit may be\nspurious: including contributions from the small singular values can add\nnumerical noise to the result.\n\nNote that fitting polynomial coefficients is inherently badly conditioned when\nthe degree of the polynomial is large or the interval of sample points is\nbadly centered. The quality of the fit should always be checked in these\ncases. When polynomial fits are not satisfactory, splines may be a good\nalternative.\n\nWikipedia, \u201cCurve fitting\u201d, https://en.wikipedia.org/wiki/Curve_fitting\n\nWikipedia, \u201cPolynomial interpolation\u201d,\nhttps://en.wikipedia.org/wiki/Polynomial_interpolation\n\nIt is convenient to use `poly1d` objects for dealing with polynomials:\n\nHigh-order polynomials may oscillate wildly:\n\nIllustration:\n\n"}, {"name": "ma.power()", "path": "reference/generated/numpy.ma.power", "type": "numpy.ma.power", "text": "\nReturns element-wise base array raised to power from second array.\n\nThis is the masked array version of `numpy.power`. For details see\n`numpy.power`.\n\nSee also\n\nThe out argument to `numpy.power` is not supported, `third` has to be None.\n\n"}, {"name": "ma.prod()", "path": "reference/generated/numpy.ma.prod", "type": "numpy.ma.prod", "text": "\nReturn the product of the array elements over the given axis.\n\nMasked elements are set to 1 internally for computation.\n\nRefer to `numpy.prod` for full documentation.\n\nSee also\n\ncorresponding function for ndarrays\n\nequivalent function\n\nArithmetic is modular when using integer types, and no error is raised on\noverflow.\n\n"}, {"name": "ma.ptp()", "path": "reference/generated/numpy.ma.ptp", "type": "numpy.ma.ptp", "text": "\nReturn (maximum - minimum) along the given dimension (i.e. peak-to-peak\nvalue).\n\nWarning\n\n`ptp` preserves the data type of the array. This means the return value for an\ninput of signed integers with n bits (e.g. `np.int8`, `np.int16`, etc) is also\na signed integer with n bits. In that case, peak-to-peak values greater than\n`2**(n-1)-1` will be returned as negative values. An example with a work-\naround is shown below.\n\nAxis along which to find the peaks. If None (default) the flattened array is\nused.\n\nAlternative output array in which to place the result. It must have the same\nshape and buffer length as the expected output but the type will be cast if\nnecessary.\n\nValue used to fill in the masked values.\n\nIf this is set to True, the axes which are reduced are left in the result as\ndimensions with size one. With this option, the result will broadcast\ncorrectly against the array.\n\nA new array holding the result, unless `out` was specified, in which case a\nreference to `out` is returned.\n\nThis example shows that a negative value can be returned when the input is an\narray of signed integers.\n\nA work-around is to use the `view()` method to view the result as unsigned\nintegers with the same bit width:\n\n"}, {"name": "ma.ravel()", "path": "reference/generated/numpy.ma.ravel", "type": "numpy.ma.ravel", "text": "\nReturns a 1D version of self, as a view.\n\nThe elements of `a` are read using this index order. \u2018C\u2019 means to index the\nelements in C-like order, with the last axis index changing fastest, back to\nthe first axis index changing slowest. \u2018F\u2019 means to index the elements in\nFortran-like index order, with the first index changing fastest, and the last\nindex changing slowest. Note that the \u2018C\u2019 and \u2018F\u2019 options take no account of\nthe memory layout of the underlying array, and only refer to the order of axis\nindexing. \u2018A\u2019 means to read the elements in Fortran-like index order if `m` is\nFortran contiguous in memory, C-like order otherwise. \u2018K\u2019 means to read the\nelements in the order they occur in memory, except for reversing the data when\nstrides are negative. By default, \u2018C\u2019 index order is used.\n\nOutput view is of shape `(self.size,)` (or `(np.ma.product(self.shape),)`).\n\n"}, {"name": "ma.reshape()", "path": "reference/generated/numpy.ma.reshape", "type": "numpy.ma.reshape", "text": "\nReturns an array containing the same data with a new shape.\n\nRefer to `MaskedArray.reshape` for full documentation.\n\nSee also\n\nequivalent function\n\n"}, {"name": "ma.resize()", "path": "reference/generated/numpy.ma.resize", "type": "numpy.ma.resize", "text": "\nReturn a new masked array with the specified size and shape.\n\nThis is the masked equivalent of the `numpy.resize` function. The new array is\nfilled with repeated copies of `x` (in the order that the data are stored in\nmemory). If `x` is masked, the new array will be masked, and the new mask will\nbe a repetition of the old one.\n\nSee also\n\nEquivalent function in the top level NumPy module.\n\nA MaskedArray is always returned, regardless of the input type.\n\n"}, {"name": "ma.round()", "path": "reference/generated/numpy.ma.round", "type": "numpy.ma.round", "text": "\nReturn a copy of a, rounded to \u2018decimals\u2019 places.\n\nWhen \u2018decimals\u2019 is negative, it specifies the number of positions to the left\nof the decimal point. The real and imaginary parts of complex numbers are\nrounded separately. Nothing is done if the array is not of float type and\n\u2018decimals\u2019 is greater than or equal to 0.\n\nNumber of decimals to round to. May be negative.\n\nExisting array to use for output. If not given, returns a default copy of a.\n\nIf out is given and does not have a mask attribute, the mask of a is lost!\n\n"}, {"name": "ma.row_stack()", "path": "reference/generated/numpy.ma.row_stack", "type": "numpy.ma.row_stack", "text": "\nStack arrays in sequence vertically (row wise).\n\nThis is equivalent to concatenation along the first axis after 1-D arrays of\nshape `(N,)` have been reshaped to `(1,N)`. Rebuilds arrays divided by\n`vsplit`.\n\nThis function makes most sense for arrays with up to 3 dimensions. For\ninstance, for pixel-data with a height (first axis), width (second axis), and\nr/g/b channels (third axis). The functions `concatenate`, `stack` and `block`\nprovide more general stacking and concatenation operations.\n\nThe arrays must have the same shape along all but the first axis. 1-D arrays\nmust have the same length.\n\nThe array formed by stacking the given arrays, will be at least 2-D.\n\nSee also\n\nJoin a sequence of arrays along an existing axis.\n\nJoin a sequence of arrays along a new axis.\n\nAssemble an nd-array from nested lists of blocks.\n\nStack arrays in sequence horizontally (column wise).\n\nStack arrays in sequence depth wise (along third axis).\n\nStack 1-D arrays as columns into a 2-D array.\n\nSplit an array into multiple sub-arrays vertically (row-wise).\n\nThe function is applied to both the _data and the _mask, if any.\n\n"}, {"name": "ma.set_fill_value()", "path": "reference/generated/numpy.ma.set_fill_value", "type": "numpy.ma.set_fill_value", "text": "\nSet the filling value of a, if a is a masked array.\n\nThis function changes the fill value of the masked array `a` in place. If `a`\nis not a masked array, the function returns silently, without doing anything.\n\nInput array.\n\nFilling value. A consistency test is performed to make sure the value is\ncompatible with the dtype of `a`.\n\nNothing returned by this function.\n\nSee also\n\nReturn the default fill value for a dtype.\n\nReturn current fill value.\n\nEquivalent method.\n\nNothing happens if `a` is not a masked array.\n\n"}, {"name": "ma.shape()", "path": "reference/generated/numpy.ma.shape", "type": "numpy.ma.shape", "text": "\nReturn the shape of an array.\n\nInput array.\n\nThe elements of the shape tuple give the lengths of the corresponding array\ndimensions.\n\nSee also\n\nEquivalent array method.\n\n"}, {"name": "ma.size()", "path": "reference/generated/numpy.ma.size", "type": "numpy.ma.size", "text": "\nReturn the number of elements along a given axis.\n\nInput data.\n\nAxis along which the elements are counted. By default, give the total number\nof elements.\n\nNumber of elements along the specified axis.\n\nSee also\n\ndimensions of array\n\ndimensions of array\n\nnumber of elements in array\n\n"}, {"name": "ma.soften_mask()", "path": "reference/generated/numpy.ma.soften_mask", "type": "numpy.ma.soften_mask", "text": "\nForce the mask to soft.\n\nWhether the mask of a masked array is hard or soft is determined by its\n`hardmask` property. `soften_mask` sets `hardmask` to `False`.\n\nSee also\n\n"}, {"name": "ma.sort()", "path": "reference/generated/numpy.ma.sort", "type": "numpy.ma.sort", "text": "\nReturn a sorted copy of the masked array.\n\nEquivalent to creating a copy of the array and applying the MaskedArray\n`sort()` method.\n\nRefer to `MaskedArray.sort` for the full documentation\n\nSee also\n\nequivalent method\n\n"}, {"name": "ma.squeeze()", "path": "reference/generated/numpy.ma.squeeze", "type": "numpy.ma.squeeze", "text": "\nRemove axes of length one from `a`.\n\nInput data.\n\nNew in version 1.7.0.\n\nSelects a subset of the entries of length one in the shape. If an axis is\nselected with shape entry greater than one, an error is raised.\n\nThe input array, but with all or a subset of the dimensions of length 1\nremoved. This is always `a` itself or a view into `a`. Note that if all axes\nare squeezed, the result is a 0d array and not a scalar.\n\nIf `axis` is not None, and an axis being squeezed is not of length 1\n\nSee also\n\nThe inverse operation, adding entries of length one\n\nInsert, remove, and combine dimensions, and resize existing ones\n\n"}, {"name": "ma.stack()", "path": "reference/generated/numpy.ma.stack", "type": "numpy.ma.stack", "text": "\nJoin a sequence of arrays along a new axis.\n\nThe `axis` parameter specifies the index of the new axis in the dimensions of\nthe result. For example, if `axis=0` it will be the first dimension and if\n`axis=-1` it will be the last dimension.\n\nNew in version 1.10.0.\n\nEach array must have the same shape.\n\nThe axis in the result array along which the input arrays are stacked.\n\nIf provided, the destination to place the result. The shape must be correct,\nmatching that of what stack would have returned if no out argument were\nspecified.\n\nThe stacked array has one more dimension than the input arrays.\n\nSee also\n\nJoin a sequence of arrays along an existing axis.\n\nAssemble an nd-array from nested lists of blocks.\n\nSplit array into a list of multiple sub-arrays of equal size.\n\nThe function is applied to both the _data and the _mask, if any.\n\n"}, {"name": "ma.std()", "path": "reference/generated/numpy.ma.std", "type": "numpy.ma.std", "text": "\nReturns the standard deviation of the array elements along given axis.\n\nMasked entries are ignored.\n\nRefer to `numpy.std` for full documentation.\n\nSee also\n\ncorresponding function for ndarrays\n\nEquivalent function\n\n"}, {"name": "ma.sum()", "path": "reference/generated/numpy.ma.sum", "type": "numpy.ma.sum", "text": "\nReturn the sum of the array elements over the given axis.\n\nMasked elements are set to 0 internally.\n\nRefer to `numpy.sum` for full documentation.\n\nSee also\n\ncorresponding function for ndarrays\n\nequivalent function\n\n"}, {"name": "ma.swapaxes()", "path": "reference/generated/numpy.ma.swapaxes", "type": "numpy.ma.swapaxes", "text": "\nReturn a view of the array with `axis1` and `axis2` interchanged.\n\nRefer to `numpy.swapaxes` for full documentation.\n\nSee also\n\nequivalent function\n\n"}, {"name": "ma.trace()", "path": "reference/generated/numpy.ma.trace", "type": "numpy.ma.trace", "text": "\nReturn the sum along diagonals of the array.\n\nRefer to `numpy.trace` for full documentation.\n\nSee also\n\nequivalent function\n\n"}, {"name": "ma.transpose()", "path": "reference/generated/numpy.ma.transpose", "type": "numpy.ma.transpose", "text": "\nPermute the dimensions of an array.\n\nThis function is exactly equivalent to `numpy.transpose`.\n\nSee also\n\nEquivalent function in top-level NumPy module.\n\n"}, {"name": "ma.vander()", "path": "reference/generated/numpy.ma.vander", "type": "numpy.ma.vander", "text": "\nGenerate a Vandermonde matrix.\n\nThe columns of the output matrix are powers of the input vector. The order of\nthe powers is determined by the `increasing` boolean argument. Specifically,\nwhen `increasing` is False, the `i`-th output column is the input vector\nraised element-wise to the power of `N - i - 1`. Such a matrix with a\ngeometric progression in each row is named for Alexandre- Theophile\nVandermonde.\n\n1-D input array.\n\nNumber of columns in the output. If `N` is not specified, a square array is\nreturned (`N = len(x)`).\n\nOrder of the powers of the columns. If True, the powers increase from left to\nright, if False (the default) they are reversed.\n\nNew in version 1.9.0.\n\nVandermonde matrix. If `increasing` is False, the first column is `x^(N-1)`,\nthe second `x^(N-2)` and so forth. If `increasing` is True, the columns are\n`x^0, x^1, ..., x^(N-1)`.\n\nSee also\n\nMasked values in the input array result in rows of zeros.\n\nThe determinant of a square Vandermonde matrix is the product of the\ndifferences between the values of the input vector:\n\n"}, {"name": "ma.var()", "path": "reference/generated/numpy.ma.var", "type": "numpy.ma.var", "text": "\nCompute the variance along the specified axis.\n\nReturns the variance of the array elements, a measure of the spread of a\ndistribution. The variance is computed for the flattened array by default,\notherwise over the specified axis.\n\nArray containing numbers whose variance is desired. If `a` is not an array, a\nconversion is attempted.\n\nAxis or axes along which the variance is computed. The default is to compute\nthe variance of the flattened array.\n\nNew in version 1.7.0.\n\nIf this is a tuple of ints, a variance is performed over multiple axes,\ninstead of a single axis or all the axes as before.\n\nType to use in computing the variance. For arrays of integer type the default\nis `float64`; for arrays of float types it is the same as the array type.\n\nAlternate output array in which to place the result. It must have the same\nshape as the expected output, but the type is cast if necessary.\n\n\u201cDelta Degrees of Freedom\u201d: the divisor used in the calculation is `N - ddof`,\nwhere `N` represents the number of elements. By default `ddof` is zero.\n\nIf this is set to True, the axes which are reduced are left in the result as\ndimensions with size one. With this option, the result will broadcast\ncorrectly against the input array.\n\nIf the default value is passed, then `keepdims` will not be passed through to\nthe `var` method of sub-classes of `ndarray`, however any non-default value\nwill be. If the sub-class\u2019 method does not implement `keepdims` any exceptions\nwill be raised.\n\nElements to include in the variance. See `reduce` for details.\n\nNew in version 1.20.0.\n\nIf `out=None`, returns a new array containing the variance; otherwise, a\nreference to the output array is returned.\n\nSee also\n\nThe variance is the average of the squared deviations from the mean, i.e.,\n`var = mean(x)`, where `x = abs(a - a.mean())**2`.\n\nThe mean is typically calculated as `x.sum() / N`, where `N = len(x)`. If,\nhowever, `ddof` is specified, the divisor `N - ddof` is used instead. In\nstandard statistical practice, `ddof=1` provides an unbiased estimator of the\nvariance of a hypothetical infinite population. `ddof=0` provides a maximum\nlikelihood estimate of the variance for normally distributed variables.\n\nNote that for complex numbers, the absolute value is taken before squaring, so\nthat the result is always real and nonnegative.\n\nFor floating-point input, the variance is computed using the same precision\nthe input has. Depending on the input data, this can cause the results to be\ninaccurate, especially for `float32` (see example below). Specifying a higher-\naccuracy accumulator using the `dtype` keyword can alleviate this issue.\n\nIn single precision, var() can be inaccurate:\n\nComputing the variance in float64 is more accurate:\n\nSpecifying a where argument:\n\n"}, {"name": "ma.vstack()", "path": "reference/generated/numpy.ma.vstack", "type": "numpy.ma.vstack", "text": "\nStack arrays in sequence vertically (row wise).\n\nThis is equivalent to concatenation along the first axis after 1-D arrays of\nshape `(N,)` have been reshaped to `(1,N)`. Rebuilds arrays divided by\n`vsplit`.\n\nThis function makes most sense for arrays with up to 3 dimensions. For\ninstance, for pixel-data with a height (first axis), width (second axis), and\nr/g/b channels (third axis). The functions `concatenate`, `stack` and `block`\nprovide more general stacking and concatenation operations.\n\nThe arrays must have the same shape along all but the first axis. 1-D arrays\nmust have the same length.\n\nThe array formed by stacking the given arrays, will be at least 2-D.\n\nSee also\n\nJoin a sequence of arrays along an existing axis.\n\nJoin a sequence of arrays along a new axis.\n\nAssemble an nd-array from nested lists of blocks.\n\nStack arrays in sequence horizontally (column wise).\n\nStack arrays in sequence depth wise (along third axis).\n\nStack 1-D arrays as columns into a 2-D array.\n\nSplit an array into multiple sub-arrays vertically (row-wise).\n\nThe function is applied to both the _data and the _mask, if any.\n\n"}, {"name": "ma.where()", "path": "reference/generated/numpy.ma.where", "type": "numpy.ma.where", "text": "\nReturn a masked array with elements from `x` or `y`, depending on condition.\n\nNote\n\nWhen only `condition` is provided, this function is identical to `nonzero`.\nThe rest of this documentation covers only the case where all three arguments\nare provided.\n\nWhere True, yield `x`, otherwise yield `y`.\n\nValues from which to choose. `x`, `y` and `condition` need to be broadcastable\nto some shape.\n\nAn masked array with `masked` elements where the condition is masked, elements\nfrom `x` where `condition` is True, and elements from `y` elsewhere.\n\nSee also\n\nEquivalent function in the top-level NumPy module.\n\nThe function that is called when x and y are omitted\n\n"}, {"name": "ma.zeros()", "path": "reference/generated/numpy.ma.zeros", "type": "numpy.ma.zeros", "text": "\nReturn a new array of given shape and type, filled with zeros.\n\nShape of the new array, e.g., `(2, 3)` or `2`.\n\nThe desired data-type for the array, e.g., `numpy.int8`. Default is\n`numpy.float64`.\n\nWhether to store multi-dimensional data in row-major (C-style) or column-major\n(Fortran-style) order in memory.\n\nReference object to allow the creation of arrays which are not NumPy arrays.\nIf an array-like passed in as `like` supports the `__array_function__`\nprotocol, the result will be defined by it. In this case, it ensures the\ncreation of an array object compatible with that passed in via this argument.\n\nNew in version 1.20.0.\n\nArray of zeros with the given shape, dtype, and order.\n\nSee also\n\nReturn an array of zeros with shape and type of input.\n\nReturn a new uninitialized array.\n\nReturn a new array setting values to one.\n\nReturn a new array of given shape filled with value.\n\n"}, {"name": "ma.zeros_like()", "path": "reference/generated/numpy.ma.zeros_like", "type": "numpy.ma.zeros_like", "text": "\nReturn an array of zeros with the same shape and type as a given array.\n\nThe shape and data-type of `a` define these same attributes of the returned\narray.\n\nOverrides the data type of the result.\n\nNew in version 1.6.0.\n\nOverrides the memory layout of the result. \u2018C\u2019 means C-order, \u2018F\u2019 means\nF-order, \u2018A\u2019 means \u2018F\u2019 if `a` is Fortran contiguous, \u2018C\u2019 otherwise. \u2018K\u2019 means\nmatch the layout of `a` as closely as possible.\n\nNew in version 1.6.0.\n\nIf True, then the newly created array will use the sub-class type of `a`,\notherwise it will be a base-class array. Defaults to True.\n\nOverrides the shape of the result. If order=\u2019K\u2019 and the number of dimensions\nis unchanged, will try to keep order, otherwise, order=\u2019C\u2019 is implied.\n\nNew in version 1.17.0.\n\nArray of zeros with the same shape and type as `a`.\n\nSee also\n\nReturn an empty array with shape and type of input.\n\nReturn an array of ones with shape and type of input.\n\nReturn a new array with shape of input filled with value.\n\nReturn a new array setting values to zero.\n\n"}, {"name": "make_config_py()", "path": "reference/distutils#numpy.distutils.misc_util.Configuration.make_config_py", "type": "Packaging ( \n    \n     numpy.distutils\n    \n    )", "text": "\nGenerate package __config__.py file containing system_info information used\nduring building the package.\n\nThis file is installed to the package installation directory.\n\n"}, {"name": "make_svn_version_py()", "path": "reference/distutils#numpy.distutils.misc_util.Configuration.make_svn_version_py", "type": "Packaging ( \n    \n     numpy.distutils\n    \n    )", "text": "\nAppends a data function to the data_files list that will generate\n__svn_version__.py file to the current package directory.\n\nGenerate package __svn_version__.py file from SVN revision number, it will be\nremoved after python exits but will be available when sdist, etc commands are\nexecuted.\n\nIf __svn_version__.py existed before, nothing is done.\n\nThis is intended for working with source directories that are in an SVN\nrepository.\n\n"}, {"name": "Masked array operations", "path": "reference/routines.ma", "type": "Masked array operations", "text": "\n`ma.MaskType`\n\nalias of `numpy.bool_`\n\n`ma.masked_array`\n\nalias of `numpy.ma.core.MaskedArray`\n\n`ma.array`(data[, dtype, copy, order, mask, ...])\n\nAn array class with possibly masked values.\n\n`ma.copy`(self, *args, **params) a.copy(order=)\n\nReturn a copy of the array.\n\n`ma.frombuffer`(buffer[, dtype, count, ...])\n\nInterpret a buffer as a 1-dimensional array.\n\n`ma.fromfunction`(function, shape, **dtype)\n\nConstruct an array by executing a function over each coordinate.\n\n`ma.MaskedArray.copy`([order])\n\nReturn a copy of the array.\n\n`ma.empty`(shape[, dtype, order, like])\n\nReturn a new array of given shape and type, without initializing entries.\n\n`ma.empty_like`(prototype[, dtype, order, ...])\n\nReturn a new array with the same shape and type as a given array.\n\n`ma.masked_all`(shape[, dtype])\n\nEmpty masked array with all elements masked.\n\n`ma.masked_all_like`(arr)\n\nEmpty masked array with the properties of an existing array.\n\n`ma.ones`(shape[, dtype, order])\n\nReturn a new array of given shape and type, filled with ones.\n\n`ma.ones_like`(*args, **kwargs)\n\nReturn an array of ones with the same shape and type as a given array.\n\n`ma.zeros`(shape[, dtype, order, like])\n\nReturn a new array of given shape and type, filled with zeros.\n\n`ma.zeros_like`(*args, **kwargs)\n\nReturn an array of zeros with the same shape and type as a given array.\n\n`ma.all`(self[, axis, out, keepdims])\n\nReturns True if all elements evaluate to True.\n\n`ma.any`(self[, axis, out, keepdims])\n\nReturns True if any of the elements of `a` evaluate to True.\n\n`ma.count`(self[, axis, keepdims])\n\nCount the non-masked elements of the array along the given axis.\n\n`ma.count_masked`(arr[, axis])\n\nCount the number of masked elements along the given axis.\n\n`ma.getmask`(a)\n\nReturn the mask of a masked array, or nomask.\n\n`ma.getmaskarray`(arr)\n\nReturn the mask of a masked array, or full boolean array of False.\n\n`ma.getdata`(a[, subok])\n\nReturn the data of a masked array as an ndarray.\n\n`ma.nonzero`(self)\n\nReturn the indices of unmasked elements that are not zero.\n\n`ma.shape`(obj)\n\nReturn the shape of an array.\n\n`ma.size`(obj[, axis])\n\nReturn the number of elements along a given axis.\n\n`ma.is_masked`(x)\n\nDetermine whether input has masked values.\n\n`ma.is_mask`(m)\n\nReturn True if m is a valid, standard mask.\n\n`ma.isMaskedArray`(x)\n\nTest whether input is an instance of MaskedArray.\n\n`ma.isMA`(x)\n\nTest whether input is an instance of MaskedArray.\n\n`ma.isarray`(x)\n\nTest whether input is an instance of MaskedArray.\n\n`ma.MaskedArray.all`([axis, out, keepdims])\n\nReturns True if all elements evaluate to True.\n\n`ma.MaskedArray.any`([axis, out, keepdims])\n\nReturns True if any of the elements of `a` evaluate to True.\n\n`ma.MaskedArray.count`([axis, keepdims])\n\nCount the non-masked elements of the array along the given axis.\n\n`ma.MaskedArray.nonzero`()\n\nReturn the indices of unmasked elements that are not zero.\n\n`ma.shape`(obj)\n\nReturn the shape of an array.\n\n`ma.size`(obj[, axis])\n\nReturn the number of elements along a given axis.\n\n`ma.MaskedArray.data`\n\nReturns the underlying data, as a view of the masked array.\n\n`ma.MaskedArray.mask`\n\nCurrent mask.\n\n`ma.MaskedArray.recordmask`\n\nGet or set the mask of the array if it has no named fields.\n\n`ma.ravel`(self[, order])\n\nReturns a 1D version of self, as a view.\n\n`ma.reshape`(a, new_shape[, order])\n\nReturns an array containing the same data with a new shape.\n\n`ma.resize`(x, new_shape)\n\nReturn a new masked array with the specified size and shape.\n\n`ma.MaskedArray.flatten`([order])\n\nReturn a copy of the array collapsed into one dimension.\n\n`ma.MaskedArray.ravel`([order])\n\nReturns a 1D version of self, as a view.\n\n`ma.MaskedArray.reshape`(*s, **kwargs)\n\nGive a new shape to the array without changing its data.\n\n`ma.MaskedArray.resize`(newshape[, refcheck, ...])\n\n`ma.swapaxes`(self, *args, ...)\n\nReturn a view of the array with `axis1` and `axis2` interchanged.\n\n`ma.transpose`(a[, axes])\n\nPermute the dimensions of an array.\n\n`ma.MaskedArray.swapaxes`(axis1, axis2)\n\nReturn a view of the array with `axis1` and `axis2` interchanged.\n\n`ma.MaskedArray.transpose`(*axes)\n\nReturns a view of the array with axes transposed.\n\n`ma.atleast_1d`(*args, **kwargs)\n\nConvert inputs to arrays with at least one dimension.\n\n`ma.atleast_2d`(*args, **kwargs)\n\nView inputs as arrays with at least two dimensions.\n\n`ma.atleast_3d`(*args, **kwargs)\n\nView inputs as arrays with at least three dimensions.\n\n`ma.expand_dims`(a, axis)\n\nExpand the shape of an array.\n\n`ma.squeeze`(*args, **kwargs)\n\nRemove axes of length one from `a`.\n\n`ma.MaskedArray.squeeze`([axis])\n\nRemove axes of length one from `a`.\n\n`ma.stack`(*args, **kwargs)\n\nJoin a sequence of arrays along a new axis.\n\n`ma.column_stack`(*args, **kwargs)\n\nStack 1-D arrays as columns into a 2-D array.\n\n`ma.concatenate`(arrays[, axis])\n\nConcatenate a sequence of arrays along the given axis.\n\n`ma.dstack`(*args, **kwargs)\n\nStack arrays in sequence depth wise (along third axis).\n\n`ma.hstack`(*args, **kwargs)\n\nStack arrays in sequence horizontally (column wise).\n\n`ma.hsplit`(*args, **kwargs)\n\nSplit an array into multiple sub-arrays horizontally (column-wise).\n\n`ma.mr_`\n\nTranslate slice objects to concatenation along the first axis.\n\n`ma.row_stack`(*args, **kwargs)\n\nStack arrays in sequence vertically (row wise).\n\n`ma.vstack`(*args, **kwargs)\n\nStack arrays in sequence vertically (row wise).\n\n`ma.concatenate`(arrays[, axis])\n\nConcatenate a sequence of arrays along the given axis.\n\n`ma.stack`(*args, **kwargs)\n\nJoin a sequence of arrays along a new axis.\n\n`ma.vstack`(*args, **kwargs)\n\nStack arrays in sequence vertically (row wise).\n\n`ma.hstack`(*args, **kwargs)\n\nStack arrays in sequence horizontally (column wise).\n\n`ma.dstack`(*args, **kwargs)\n\nStack arrays in sequence depth wise (along third axis).\n\n`ma.column_stack`(*args, **kwargs)\n\nStack 1-D arrays as columns into a 2-D array.\n\n`ma.append`(a, b[, axis])\n\nAppend values to the end of an array.\n\n`ma.make_mask`(m[, copy, shrink, dtype])\n\nCreate a boolean mask from an array.\n\n`ma.make_mask_none`(newshape[, dtype])\n\nReturn a boolean mask of the given shape, filled with False.\n\n`ma.mask_or`(m1, m2[, copy, shrink])\n\nCombine two masks with the `logical_or` operator.\n\n`ma.make_mask_descr`(ndtype)\n\nConstruct a dtype description list from a given dtype.\n\n`ma.getmask`(a)\n\nReturn the mask of a masked array, or nomask.\n\n`ma.getmaskarray`(arr)\n\nReturn the mask of a masked array, or full boolean array of False.\n\n`ma.masked_array.mask`\n\nCurrent mask.\n\n`ma.flatnotmasked_contiguous`(a)\n\nFind contiguous unmasked data in a masked array along the given axis.\n\n`ma.flatnotmasked_edges`(a)\n\nFind the indices of the first and last unmasked values.\n\n`ma.notmasked_contiguous`(a[, axis])\n\nFind contiguous unmasked data in a masked array along the given axis.\n\n`ma.notmasked_edges`(a[, axis])\n\nFind the indices of the first and last unmasked values along an axis.\n\n`ma.clump_masked`(a)\n\nReturns a list of slices corresponding to the masked clumps of a 1-D array.\n\n`ma.clump_unmasked`(a)\n\nReturn list of slices corresponding to the unmasked clumps of a 1-D array.\n\n`ma.mask_cols`(a[, axis])\n\nMask columns of a 2D array that contain masked values.\n\n`ma.mask_or`(m1, m2[, copy, shrink])\n\nCombine two masks with the `logical_or` operator.\n\n`ma.mask_rowcols`(a[, axis])\n\nMask rows and/or columns of a 2D array that contain masked values.\n\n`ma.mask_rows`(a[, axis])\n\nMask rows of a 2D array that contain masked values.\n\n`ma.harden_mask`(self)\n\nForce the mask to hard.\n\n`ma.soften_mask`(self)\n\nForce the mask to soft.\n\n`ma.MaskedArray.harden_mask`()\n\nForce the mask to hard.\n\n`ma.MaskedArray.soften_mask`()\n\nForce the mask to soft.\n\n`ma.MaskedArray.shrink_mask`()\n\nReduce a mask to nomask when possible.\n\n`ma.MaskedArray.unshare_mask`()\n\nCopy the mask and set the sharedmask flag to False.\n\n`ma.asarray`(a[, dtype, order])\n\nConvert the input to a masked array of the given data-type.\n\n`ma.asanyarray`(a[, dtype])\n\nConvert the input to a masked array, conserving subclasses.\n\n`ma.fix_invalid`(a[, mask, copy, fill_value])\n\nReturn input with invalid data masked and replaced by a fill value.\n\n`ma.masked_equal`(x, value[, copy])\n\nMask an array where equal to a given value.\n\n`ma.masked_greater`(x, value[, copy])\n\nMask an array where greater than a given value.\n\n`ma.masked_greater_equal`(x, value[, copy])\n\nMask an array where greater than or equal to a given value.\n\n`ma.masked_inside`(x, v1, v2[, copy])\n\nMask an array inside a given interval.\n\n`ma.masked_invalid`(a[, copy])\n\nMask an array where invalid values occur (NaNs or infs).\n\n`ma.masked_less`(x, value[, copy])\n\nMask an array where less than a given value.\n\n`ma.masked_less_equal`(x, value[, copy])\n\nMask an array where less than or equal to a given value.\n\n`ma.masked_not_equal`(x, value[, copy])\n\nMask an array where `not` equal to a given value.\n\n`ma.masked_object`(x, value[, copy, shrink])\n\nMask the array `x` where the data are exactly equal to value.\n\n`ma.masked_outside`(x, v1, v2[, copy])\n\nMask an array outside a given interval.\n\n`ma.masked_values`(x, value[, rtol, atol, ...])\n\nMask using floating point equality.\n\n`ma.masked_where`(condition, a[, copy])\n\nMask an array where a condition is met.\n\n`ma.compress_cols`(a)\n\nSuppress whole columns of a 2-D array that contain masked values.\n\n`ma.compress_rowcols`(x[, axis])\n\nSuppress the rows and/or columns of a 2-D array that contain masked values.\n\n`ma.compress_rows`(a)\n\nSuppress whole rows of a 2-D array that contain masked values.\n\n`ma.compressed`(x)\n\nReturn all the non-masked data as a 1-D array.\n\n`ma.filled`(a[, fill_value])\n\nReturn input as an array with masked data replaced by a fill value.\n\n`ma.MaskedArray.compressed`()\n\nReturn all the non-masked data as a 1-D array.\n\n`ma.MaskedArray.filled`([fill_value])\n\nReturn a copy of self, with masked values filled with a given value.\n\n`ma.MaskedArray.tofile`(fid[, sep, format])\n\nSave a masked array to a file in binary format.\n\n`ma.MaskedArray.tolist`([fill_value])\n\nReturn the data portion of the masked array as a hierarchical Python list.\n\n`ma.MaskedArray.torecords`()\n\nTransforms a masked array into a flexible-type array.\n\n`ma.MaskedArray.tobytes`([fill_value, order])\n\nReturn the array data as a string containing the raw bytes in the array.\n\n`ma.common_fill_value`(a, b)\n\nReturn the common filling value of two masked arrays, if any.\n\n`ma.default_fill_value`(obj)\n\nReturn the default fill value for the argument object.\n\n`ma.maximum_fill_value`(obj)\n\nReturn the minimum value that can be represented by the dtype of an object.\n\n`ma.minimum_fill_value`(obj)\n\nReturn the maximum value that can be represented by the dtype of an object.\n\n`ma.set_fill_value`(a, fill_value)\n\nSet the filling value of a, if a is a masked array.\n\n`ma.MaskedArray.get_fill_value`()\n\nThe filling value of the masked array is a scalar.\n\n`ma.MaskedArray.set_fill_value`([value])\n\n`ma.MaskedArray.fill_value`\n\nThe filling value of the masked array is a scalar.\n\n`ma.anom`(self[, axis, dtype])\n\nCompute the anomalies (deviations from the arithmetic mean) along the given\naxis.\n\n`ma.anomalies`(self[, axis, dtype])\n\nCompute the anomalies (deviations from the arithmetic mean) along the given\naxis.\n\n`ma.average`(a[, axis, weights, returned])\n\nReturn the weighted average of array over the given axis.\n\n`ma.conjugate`(x, /[, out, where, casting, ...])\n\nReturn the complex conjugate, element-wise.\n\n`ma.corrcoef`(x[, y, rowvar, bias, ...])\n\nReturn Pearson product-moment correlation coefficients.\n\n`ma.cov`(x[, y, rowvar, bias, allow_masked, ddof])\n\nEstimate the covariance matrix.\n\n`ma.cumsum`(self[, axis, dtype, out])\n\nReturn the cumulative sum of the array elements over the given axis.\n\n`ma.cumprod`(self[, axis, dtype, out])\n\nReturn the cumulative product of the array elements over the given axis.\n\n`ma.mean`(self[, axis, dtype, out, keepdims])\n\nReturns the average of the array elements along given axis.\n\n`ma.median`(a[, axis, out, overwrite_input, ...])\n\nCompute the median along the specified axis.\n\n`ma.power`(a, b[, third])\n\nReturns element-wise base array raised to power from second array.\n\n`ma.prod`(self[, axis, dtype, out, keepdims])\n\nReturn the product of the array elements over the given axis.\n\n`ma.std`(self[, axis, dtype, out, ddof, keepdims])\n\nReturns the standard deviation of the array elements along given axis.\n\n`ma.sum`(self[, axis, dtype, out, keepdims])\n\nReturn the sum of the array elements over the given axis.\n\n`ma.var`(self[, axis, dtype, out, ddof, keepdims])\n\nCompute the variance along the specified axis.\n\n`ma.MaskedArray.anom`([axis, dtype])\n\nCompute the anomalies (deviations from the arithmetic mean) along the given\naxis.\n\n`ma.MaskedArray.cumprod`([axis, dtype, out])\n\nReturn the cumulative product of the array elements over the given axis.\n\n`ma.MaskedArray.cumsum`([axis, dtype, out])\n\nReturn the cumulative sum of the array elements over the given axis.\n\n`ma.MaskedArray.mean`([axis, dtype, out, keepdims])\n\nReturns the average of the array elements along given axis.\n\n`ma.MaskedArray.prod`([axis, dtype, out, keepdims])\n\nReturn the product of the array elements over the given axis.\n\n`ma.MaskedArray.std`([axis, dtype, out, ddof, ...])\n\nReturns the standard deviation of the array elements along given axis.\n\n`ma.MaskedArray.sum`([axis, dtype, out, keepdims])\n\nReturn the sum of the array elements over the given axis.\n\n`ma.MaskedArray.var`([axis, dtype, out, ddof, ...])\n\nCompute the variance along the specified axis.\n\n`ma.argmax`(self[, axis, fill_value, out])\n\nReturns array of indices of the maximum values along the given axis.\n\n`ma.argmin`(self[, axis, fill_value, out])\n\nReturn array of indices to the minimum values along the given axis.\n\n`ma.max`(obj[, axis, out, fill_value, keepdims])\n\nReturn the maximum along a given axis.\n\n`ma.min`(obj[, axis, out, fill_value, keepdims])\n\nReturn the minimum along a given axis.\n\n`ma.ptp`(obj[, axis, out, fill_value, keepdims])\n\nReturn (maximum - minimum) along the given dimension (i.e.\n\n`ma.diff`(*args, **kwargs)\n\nCalculate the n-th discrete difference along the given axis.\n\n`ma.MaskedArray.argmax`([axis, fill_value, ...])\n\nReturns array of indices of the maximum values along the given axis.\n\n`ma.MaskedArray.argmin`([axis, fill_value, ...])\n\nReturn array of indices to the minimum values along the given axis.\n\n`ma.MaskedArray.max`([axis, out, fill_value, ...])\n\nReturn the maximum along a given axis.\n\n`ma.MaskedArray.min`([axis, out, fill_value, ...])\n\nReturn the minimum along a given axis.\n\n`ma.MaskedArray.ptp`([axis, out, fill_value, ...])\n\nReturn (maximum - minimum) along the given dimension (i.e.\n\n`ma.argsort`(a[, axis, kind, order, endwith, ...])\n\nReturn an ndarray of indices that sort the array along the specified axis.\n\n`ma.sort`(a[, axis, kind, order, endwith, ...])\n\nReturn a sorted copy of the masked array.\n\n`ma.MaskedArray.argsort`([axis, kind, order, ...])\n\nReturn an ndarray of indices that sort the array along the specified axis.\n\n`ma.MaskedArray.sort`([axis, kind, order, ...])\n\nSort the array, in-place\n\n`ma.diag`(v[, k])\n\nExtract a diagonal or construct a diagonal array.\n\n`ma.dot`(a, b[, strict, out])\n\nReturn the dot product of two arrays.\n\n`ma.identity`(n[, dtype])\n\nReturn the identity array.\n\n`ma.inner`(a, b, /)\n\nInner product of two arrays.\n\n`ma.innerproduct`(a, b, /)\n\nInner product of two arrays.\n\n`ma.outer`(a, b)\n\nCompute the outer product of two vectors.\n\n`ma.outerproduct`(a, b)\n\nCompute the outer product of two vectors.\n\n`ma.trace`(self[, offset, axis1, axis2, ...])\n\nReturn the sum along diagonals of the array.\n\n`ma.transpose`(a[, axes])\n\nPermute the dimensions of an array.\n\n`ma.MaskedArray.trace`([offset, axis1, axis2, ...])\n\nReturn the sum along diagonals of the array.\n\n`ma.MaskedArray.transpose`(*axes)\n\nReturns a view of the array with axes transposed.\n\n`ma.vander`(x[, n])\n\nGenerate a Vandermonde matrix.\n\n`ma.polyfit`(x, y, deg[, rcond, full, w, cov])\n\nLeast squares polynomial fit.\n\n`ma.around`\n\nRound an array to the given number of decimals.\n\n`ma.clip`(*args, **kwargs)\n\nClip (limit) the values in an array.\n\n`ma.round`(a[, decimals, out])\n\nReturn a copy of a, rounded to 'decimals' places.\n\n`ma.MaskedArray.clip`([min, max, out])\n\nReturn an array whose values are limited to `[min, max]`.\n\n`ma.MaskedArray.round`([decimals, out])\n\nReturn each element rounded to the given number of decimals.\n\n`ma.allequal`(a, b[, fill_value])\n\nReturn True if all entries of a and b are equal, using fill_value as a truth\nvalue where either or both are masked.\n\n`ma.allclose`(a, b[, masked_equal, rtol, atol])\n\nReturns True if two arrays are element-wise equal within a tolerance.\n\n`ma.apply_along_axis`(func1d, axis, arr, ...)\n\nApply a function to 1-D slices along the given axis.\n\n`ma.apply_over_axes`(func, a, axes)\n\nApply a function repeatedly over multiple axes.\n\n`ma.arange`([start,] stop[, step,][, dtype, like])\n\nReturn evenly spaced values within a given interval.\n\n`ma.choose`(indices, choices[, out, mode])\n\nUse an index array to construct a new array from a list of choices.\n\n`ma.ediff1d`(arr[, to_end, to_begin])\n\nCompute the differences between consecutive elements of an array.\n\n`ma.indices`(dimensions[, dtype, sparse])\n\nReturn an array representing the indices of a grid.\n\n`ma.where`(condition[, x, y])\n\nReturn a masked array with elements from `x` or `y`, depending on condition.\n\n"}, {"name": "Masked arrays", "path": "reference/maskedarray", "type": "Masked arrays", "text": "\nMasked arrays are arrays that may have missing or invalid entries. The\n`numpy.ma` module provides a nearly work-alike replacement for numpy that\nsupports data arrays with masks.\n\n"}, {"name": "MaskedArray.baseclass", "path": "reference/maskedarray.baseclass#numpy.ma.MaskedArray.baseclass", "type": "Constants of the \n        \n         numpy.ma\n        \n        module", "text": "\nIn addition to the `MaskedArray` class, the `numpy.ma` module defines several\nconstants.\n\nThe `masked` constant is a special case of `MaskedArray`, with a float\ndatatype and a null shape. It is used to test whether a specific entry of a\nmasked array is masked, or to mask one or several entries of a masked array:\n\nValue indicating that a masked array has no invalid entry. `nomask` is used\ninternally to speed up computations when the mask is not needed. It is\nrepresented internally as `np.False_`.\n\nString used in lieu of missing data when a masked array is printed. By\ndefault, this string is `'--'`.\n\n"}, {"name": "MaskedArray.fill_value", "path": "reference/maskedarray.baseclass#numpy.ma.MaskedArray.fill_value", "type": "Constants of the \n        \n         numpy.ma\n        \n        module", "text": "\nIn addition to the `MaskedArray` class, the `numpy.ma` module defines several\nconstants.\n\nThe `masked` constant is a special case of `MaskedArray`, with a float\ndatatype and a null shape. It is used to test whether a specific entry of a\nmasked array is masked, or to mask one or several entries of a masked array:\n\nValue indicating that a masked array has no invalid entry. `nomask` is used\ninternally to speed up computations when the mask is not needed. It is\nrepresented internally as `np.False_`.\n\nString used in lieu of missing data when a masked array is printed. By\ndefault, this string is `'--'`.\n\n"}, {"name": "MaskedArray.hardmask", "path": "reference/maskedarray.baseclass#numpy.ma.MaskedArray.hardmask", "type": "Constants of the \n        \n         numpy.ma\n        \n        module", "text": "\nIn addition to the `MaskedArray` class, the `numpy.ma` module defines several\nconstants.\n\nThe `masked` constant is a special case of `MaskedArray`, with a float\ndatatype and a null shape. It is used to test whether a specific entry of a\nmasked array is masked, or to mask one or several entries of a masked array:\n\nValue indicating that a masked array has no invalid entry. `nomask` is used\ninternally to speed up computations when the mask is not needed. It is\nrepresented internally as `np.False_`.\n\nString used in lieu of missing data when a masked array is printed. By\ndefault, this string is `'--'`.\n\n"}, {"name": "MaskedArray.mask", "path": "reference/maskedarray.baseclass#numpy.ma.MaskedArray.mask", "type": "Constants of the \n        \n         numpy.ma\n        \n        module", "text": "\nIn addition to the `MaskedArray` class, the `numpy.ma` module defines several\nconstants.\n\nThe `masked` constant is a special case of `MaskedArray`, with a float\ndatatype and a null shape. It is used to test whether a specific entry of a\nmasked array is masked, or to mask one or several entries of a masked array:\n\nValue indicating that a masked array has no invalid entry. `nomask` is used\ninternally to speed up computations when the mask is not needed. It is\nrepresented internally as `np.False_`.\n\nString used in lieu of missing data when a masked array is printed. By\ndefault, this string is `'--'`.\n\n"}, {"name": "MaskedArray.recordmask", "path": "reference/maskedarray.baseclass#numpy.ma.MaskedArray.recordmask", "type": "Constants of the \n        \n         numpy.ma\n        \n        module", "text": "\nIn addition to the `MaskedArray` class, the `numpy.ma` module defines several\nconstants.\n\nThe `masked` constant is a special case of `MaskedArray`, with a float\ndatatype and a null shape. It is used to test whether a specific entry of a\nmasked array is masked, or to mask one or several entries of a masked array:\n\nValue indicating that a masked array has no invalid entry. `nomask` is used\ninternally to speed up computations when the mask is not needed. It is\nrepresented internally as `np.False_`.\n\nString used in lieu of missing data when a masked array is printed. By\ndefault, this string is `'--'`.\n\n"}, {"name": "MaskedArray.sharedmask", "path": "reference/maskedarray.baseclass#numpy.ma.MaskedArray.sharedmask", "type": "Constants of the \n        \n         numpy.ma\n        \n        module", "text": "\nIn addition to the `MaskedArray` class, the `numpy.ma` module defines several\nconstants.\n\nThe `masked` constant is a special case of `MaskedArray`, with a float\ndatatype and a null shape. It is used to test whether a specific entry of a\nmasked array is masked, or to mask one or several entries of a masked array:\n\nValue indicating that a masked array has no invalid entry. `nomask` is used\ninternally to speed up computations when the mask is not needed. It is\nrepresented internally as `np.False_`.\n\nString used in lieu of missing data when a masked array is printed. By\ndefault, this string is `'--'`.\n\n"}, {"name": "Mathematical functions", "path": "reference/routines.math", "type": "Mathematical functions", "text": "\n`sin`(x, /[, out, where, casting, order, ...])\n\nTrigonometric sine, element-wise.\n\n`cos`(x, /[, out, where, casting, order, ...])\n\nCosine element-wise.\n\n`tan`(x, /[, out, where, casting, order, ...])\n\nCompute tangent element-wise.\n\n`arcsin`(x, /[, out, where, casting, order, ...])\n\nInverse sine, element-wise.\n\n`arccos`(x, /[, out, where, casting, order, ...])\n\nTrigonometric inverse cosine, element-wise.\n\n`arctan`(x, /[, out, where, casting, order, ...])\n\nTrigonometric inverse tangent, element-wise.\n\n`hypot`(x1, x2, /[, out, where, casting, ...])\n\nGiven the \"legs\" of a right triangle, return its hypotenuse.\n\n`arctan2`(x1, x2, /[, out, where, casting, ...])\n\nElement-wise arc tangent of `x1/x2` choosing the quadrant correctly.\n\n`degrees`(x, /[, out, where, casting, order, ...])\n\nConvert angles from radians to degrees.\n\n`radians`(x, /[, out, where, casting, order, ...])\n\nConvert angles from degrees to radians.\n\n`unwrap`(p[, discont, axis, period])\n\nUnwrap by taking the complement of large deltas with respect to the period.\n\n`deg2rad`(x, /[, out, where, casting, order, ...])\n\nConvert angles from degrees to radians.\n\n`rad2deg`(x, /[, out, where, casting, order, ...])\n\nConvert angles from radians to degrees.\n\n`sinh`(x, /[, out, where, casting, order, ...])\n\nHyperbolic sine, element-wise.\n\n`cosh`(x, /[, out, where, casting, order, ...])\n\nHyperbolic cosine, element-wise.\n\n`tanh`(x, /[, out, where, casting, order, ...])\n\nCompute hyperbolic tangent element-wise.\n\n`arcsinh`(x, /[, out, where, casting, order, ...])\n\nInverse hyperbolic sine element-wise.\n\n`arccosh`(x, /[, out, where, casting, order, ...])\n\nInverse hyperbolic cosine, element-wise.\n\n`arctanh`(x, /[, out, where, casting, order, ...])\n\nInverse hyperbolic tangent element-wise.\n\n`around`(a[, decimals, out])\n\nEvenly round to the given number of decimals.\n\n`round_`(a[, decimals, out])\n\nRound an array to the given number of decimals.\n\n`rint`(x, /[, out, where, casting, order, ...])\n\nRound elements of the array to the nearest integer.\n\n`fix`(x[, out])\n\nRound to nearest integer towards zero.\n\n`floor`(x, /[, out, where, casting, order, ...])\n\nReturn the floor of the input, element-wise.\n\n`ceil`(x, /[, out, where, casting, order, ...])\n\nReturn the ceiling of the input, element-wise.\n\n`trunc`(x, /[, out, where, casting, order, ...])\n\nReturn the truncated value of the input, element-wise.\n\n`prod`(a[, axis, dtype, out, keepdims, ...])\n\nReturn the product of array elements over a given axis.\n\n`sum`(a[, axis, dtype, out, keepdims, ...])\n\nSum of array elements over a given axis.\n\n`nanprod`(a[, axis, dtype, out, keepdims, ...])\n\nReturn the product of array elements over a given axis treating Not a Numbers\n(NaNs) as ones.\n\n`nansum`(a[, axis, dtype, out, keepdims, ...])\n\nReturn the sum of array elements over a given axis treating Not a Numbers\n(NaNs) as zero.\n\n`cumprod`(a[, axis, dtype, out])\n\nReturn the cumulative product of elements along a given axis.\n\n`cumsum`(a[, axis, dtype, out])\n\nReturn the cumulative sum of the elements along a given axis.\n\n`nancumprod`(a[, axis, dtype, out])\n\nReturn the cumulative product of array elements over a given axis treating Not\na Numbers (NaNs) as one.\n\n`nancumsum`(a[, axis, dtype, out])\n\nReturn the cumulative sum of array elements over a given axis treating Not a\nNumbers (NaNs) as zero.\n\n`diff`(a[, n, axis, prepend, append])\n\nCalculate the n-th discrete difference along the given axis.\n\n`ediff1d`(ary[, to_end, to_begin])\n\nThe differences between consecutive elements of an array.\n\n`gradient`(f, *varargs[, axis, edge_order])\n\nReturn the gradient of an N-dimensional array.\n\n`cross`(a, b[, axisa, axisb, axisc, axis])\n\nReturn the cross product of two (arrays of) vectors.\n\n`trapz`(y[, x, dx, axis])\n\nIntegrate along the given axis using the composite trapezoidal rule.\n\n`exp`(x, /[, out, where, casting, order, ...])\n\nCalculate the exponential of all elements in the input array.\n\n`expm1`(x, /[, out, where, casting, order, ...])\n\nCalculate `exp(x) - 1` for all elements in the array.\n\n`exp2`(x, /[, out, where, casting, order, ...])\n\nCalculate `2**p` for all `p` in the input array.\n\n`log`(x, /[, out, where, casting, order, ...])\n\nNatural logarithm, element-wise.\n\n`log10`(x, /[, out, where, casting, order, ...])\n\nReturn the base 10 logarithm of the input array, element-wise.\n\n`log2`(x, /[, out, where, casting, order, ...])\n\nBase-2 logarithm of `x`.\n\n`log1p`(x, /[, out, where, casting, order, ...])\n\nReturn the natural logarithm of one plus the input array, element-wise.\n\n`logaddexp`(x1, x2, /[, out, where, casting, ...])\n\nLogarithm of the sum of exponentiations of the inputs.\n\n`logaddexp2`(x1, x2, /[, out, where, casting, ...])\n\nLogarithm of the sum of exponentiations of the inputs in base-2.\n\n`i0`(x)\n\nModified Bessel function of the first kind, order 0.\n\n`sinc`(x)\n\nReturn the normalized sinc function.\n\n`signbit`(x, /[, out, where, casting, order, ...])\n\nReturns element-wise True where signbit is set (less than zero).\n\n`copysign`(x1, x2, /[, out, where, casting, ...])\n\nChange the sign of x1 to that of x2, element-wise.\n\n`frexp`(x[, out1, out2], / [[, out, where, ...])\n\nDecompose the elements of x into mantissa and twos exponent.\n\n`ldexp`(x1, x2, /[, out, where, casting, ...])\n\nReturns x1 * 2**x2, element-wise.\n\n`nextafter`(x1, x2, /[, out, where, casting, ...])\n\nReturn the next floating-point value after x1 towards x2, element-wise.\n\n`spacing`(x, /[, out, where, casting, order, ...])\n\nReturn the distance between x and the nearest adjacent number.\n\n`lcm`(x1, x2, /[, out, where, casting, order, ...])\n\nReturns the lowest common multiple of `|x1|` and `|x2|`\n\n`gcd`(x1, x2, /[, out, where, casting, order, ...])\n\nReturns the greatest common divisor of `|x1|` and `|x2|`\n\n`add`(x1, x2, /[, out, where, casting, order, ...])\n\nAdd arguments element-wise.\n\n`reciprocal`(x, /[, out, where, casting, ...])\n\nReturn the reciprocal of the argument, element-wise.\n\n`positive`(x, /[, out, where, casting, order, ...])\n\nNumerical positive, element-wise.\n\n`negative`(x, /[, out, where, casting, order, ...])\n\nNumerical negative, element-wise.\n\n`multiply`(x1, x2, /[, out, where, casting, ...])\n\nMultiply arguments element-wise.\n\n`divide`(x1, x2, /[, out, where, casting, ...])\n\nReturns a true division of the inputs, element-wise.\n\n`power`(x1, x2, /[, out, where, casting, ...])\n\nFirst array elements raised to powers from second array, element-wise.\n\n`subtract`(x1, x2, /[, out, where, casting, ...])\n\nSubtract arguments, element-wise.\n\n`true_divide`(x1, x2, /[, out, where, ...])\n\nReturns a true division of the inputs, element-wise.\n\n`floor_divide`(x1, x2, /[, out, where, ...])\n\nReturn the largest integer smaller or equal to the division of the inputs.\n\n`float_power`(x1, x2, /[, out, where, ...])\n\nFirst array elements raised to powers from second array, element-wise.\n\n`fmod`(x1, x2, /[, out, where, casting, ...])\n\nReturns the element-wise remainder of division.\n\n`mod`(x1, x2, /[, out, where, casting, order, ...])\n\nReturns the element-wise remainder of division.\n\n`modf`(x[, out1, out2], / [[, out, where, ...])\n\nReturn the fractional and integral parts of an array, element-wise.\n\n`remainder`(x1, x2, /[, out, where, casting, ...])\n\nReturns the element-wise remainder of division.\n\n`divmod`(x1, x2[, out1, out2], / [[, out, ...])\n\nReturn element-wise quotient and remainder simultaneously.\n\n`angle`(z[, deg])\n\nReturn the angle of the complex argument.\n\n`real`(val)\n\nReturn the real part of the complex argument.\n\n`imag`(val)\n\nReturn the imaginary part of the complex argument.\n\n`conj`(x, /[, out, where, casting, order, ...])\n\nReturn the complex conjugate, element-wise.\n\n`conjugate`(x, /[, out, where, casting, ...])\n\nReturn the complex conjugate, element-wise.\n\n`maximum`(x1, x2, /[, out, where, casting, ...])\n\nElement-wise maximum of array elements.\n\n`fmax`(x1, x2, /[, out, where, casting, ...])\n\nElement-wise maximum of array elements.\n\n`amax`(a[, axis, out, keepdims, initial, where])\n\nReturn the maximum of an array or maximum along an axis.\n\n`nanmax`(a[, axis, out, keepdims, initial, where])\n\nReturn the maximum of an array or maximum along an axis, ignoring any NaNs.\n\n`minimum`(x1, x2, /[, out, where, casting, ...])\n\nElement-wise minimum of array elements.\n\n`fmin`(x1, x2, /[, out, where, casting, ...])\n\nElement-wise minimum of array elements.\n\n`amin`(a[, axis, out, keepdims, initial, where])\n\nReturn the minimum of an array or minimum along an axis.\n\n`nanmin`(a[, axis, out, keepdims, initial, where])\n\nReturn minimum of an array or minimum along an axis, ignoring any NaNs.\n\n`convolve`(a, v[, mode])\n\nReturns the discrete, linear convolution of two one-dimensional sequences.\n\n`clip`(a, a_min, a_max[, out])\n\nClip (limit) the values in an array.\n\n`sqrt`(x, /[, out, where, casting, order, ...])\n\nReturn the non-negative square-root of an array, element-wise.\n\n`cbrt`(x, /[, out, where, casting, order, ...])\n\nReturn the cube-root of an array, element-wise.\n\n`square`(x, /[, out, where, casting, order, ...])\n\nReturn the element-wise square of the input.\n\n`absolute`(x, /[, out, where, casting, order, ...])\n\nCalculate the absolute value element-wise.\n\n`fabs`(x, /[, out, where, casting, order, ...])\n\nCompute the absolute values element-wise.\n\n`sign`(x, /[, out, where, casting, order, ...])\n\nReturns an element-wise indication of the sign of a number.\n\n`heaviside`(x1, x2, /[, out, where, casting, ...])\n\nCompute the Heaviside step function.\n\n`nan_to_num`(x[, copy, nan, posinf, neginf])\n\nReplace NaN with zero and infinity with large finite numbers (default\nbehaviour) or with the numbers defined by the user using the `nan`, `posinf`\nand/or `neginf` keywords.\n\n`real_if_close`(a[, tol])\n\nIf input is complex with all imaginary parts close to zero, return real parts.\n\n`interp`(x, xp, fp[, left, right, period])\n\nOne-dimensional linear interpolation for monotonically increasing sample\npoints.\n\n"}, {"name": "Mathematical functions with automatic domain (numpy.emath)", "path": "reference/routines.emath", "type": "Mathematical functions with automatic domain ( \n      \n       numpy.emath\n      \n      )", "text": "\nNote\n\n`numpy.emath` is a preferred alias for `numpy.lib.scimath`, available after\n`numpy` is imported.\n\nWrapper functions to more user-friendly calling of certain math functions\nwhose output data-type is different than the input data-type in certain\ndomains of the input.\n\nFor example, for functions like `log` with branch cuts, the versions in this\nmodule provide the mathematically valid answers in the complex plane:\n\nSimilarly, `sqrt`, other base logarithms, `power` and trig functions are\ncorrectly handled. See their respective docstrings for specific examples.\n\n`sqrt`(x)\n\nCompute the square root of x.\n\n`log`(x)\n\nCompute the natural logarithm of `x`.\n\n`log2`(x)\n\nCompute the logarithm base 2 of `x`.\n\n`logn`(n, x)\n\nTake log base n of x.\n\n`log10`(x)\n\nCompute the logarithm base 10 of `x`.\n\n`power`(x, p)\n\nReturn x to the power p, (x**p).\n\n`arccos`(x)\n\nCompute the inverse cosine of x.\n\n`arcsin`(x)\n\nCompute the inverse sine of x.\n\n`arctanh`(x)\n\nCompute the inverse hyperbolic tangent of `x`.\n\n"}, {"name": "matlib.empty()", "path": "reference/generated/numpy.matlib.empty", "type": "numpy.matlib.empty", "text": "\nReturn a new matrix of given shape and type, without initializing entries.\n\nShape of the empty matrix.\n\nDesired output data-type.\n\nWhether to store multi-dimensional data in row-major (C-style) or column-major\n(Fortran-style) order in memory.\n\nSee also\n\n`empty`, unlike `zeros`, does not set the matrix values to zero, and may\ntherefore be marginally faster. On the other hand, it requires the user to\nmanually set all the values in the array, and should be used with caution.\n\n"}, {"name": "matlib.eye()", "path": "reference/generated/numpy.matlib.eye", "type": "numpy.matlib.eye", "text": "\nReturn a matrix with ones on the diagonal and zeros elsewhere.\n\nNumber of rows in the output.\n\nNumber of columns in the output, defaults to `n`.\n\nIndex of the diagonal: 0 refers to the main diagonal, a positive value refers\nto an upper diagonal, and a negative value to a lower diagonal.\n\nData-type of the returned matrix.\n\nWhether the output should be stored in row-major (C-style) or column-major\n(Fortran-style) order in memory.\n\nNew in version 1.14.0.\n\nA `n` x `M` matrix where all elements are equal to zero, except for the `k`-th\ndiagonal, whose values are equal to one.\n\nSee also\n\nEquivalent array function.\n\nSquare identity matrix.\n\n"}, {"name": "matlib.identity()", "path": "reference/generated/numpy.matlib.identity", "type": "numpy.matlib.identity", "text": "\nReturns the square identity matrix of given size.\n\nSize of the returned identity matrix.\n\nData-type of the output. Defaults to `float`.\n\n`n` x `n` matrix with its main diagonal set to one, and all other elements\nzero.\n\nSee also\n\nEquivalent array function.\n\nMore general matrix identity function.\n\n"}, {"name": "matlib.ones()", "path": "reference/generated/numpy.matlib.ones", "type": "numpy.matlib.ones", "text": "\nMatrix of ones.\n\nReturn a matrix of given shape and type, filled with ones.\n\nShape of the matrix\n\nThe desired data-type for the matrix, default is np.float64.\n\nWhether to store matrix in C- or Fortran-contiguous order, default is \u2018C\u2019.\n\nMatrix of ones of given shape, dtype, and order.\n\nSee also\n\nArray of ones.\n\nZero matrix.\n\nIf `shape` has length one i.e. `(N,)`, or is a scalar `N`, `out` becomes a\nsingle row matrix of shape `(1,N)`.\n\n"}, {"name": "matlib.rand()", "path": "reference/generated/numpy.matlib.rand", "type": "numpy.matlib.rand", "text": "\nReturn a matrix of random values with given shape.\n\nCreate a matrix of the given shape and propagate it with random samples from a\nuniform distribution over `[0, 1)`.\n\nShape of the output. If given as N integers, each integer specifies the size\nof one dimension. If given as a tuple, this tuple gives the complete shape.\n\nThe matrix of random values with shape given by `*args`.\n\nSee also\n\nIf the first argument is a tuple, other arguments are ignored:\n\n"}, {"name": "matlib.randn()", "path": "reference/generated/numpy.matlib.randn", "type": "numpy.matlib.randn", "text": "\nReturn a random matrix with data from the \u201cstandard normal\u201d distribution.\n\n`randn` generates a matrix filled with random floats sampled from a univariate\n\u201cnormal\u201d (Gaussian) distribution of mean 0 and variance 1.\n\nShape of the output. If given as N integers, each integer specifies the size\nof one dimension. If given as a tuple, this tuple gives the complete shape.\n\nA matrix of floating-point samples drawn from the standard normal\ndistribution.\n\nSee also\n\nFor random samples from \\\\(N(\\mu, \\sigma^2)\\\\), use:\n\n`sigma * np.matlib.randn(...) + mu`\n\nTwo-by-four matrix of samples from \\\\(N(3, 6.25)\\\\):\n\n"}, {"name": "matlib.repmat()", "path": "reference/generated/numpy.matlib.repmat", "type": "numpy.matlib.repmat", "text": "\nRepeat a 0-D to 2-D array or matrix MxN times.\n\nThe array or matrix to be repeated.\n\nThe number of times `a` is repeated along the first and second axes.\n\nThe result of repeating `a`.\n\n"}, {"name": "matlib.zeros()", "path": "reference/generated/numpy.matlib.zeros", "type": "numpy.matlib.zeros", "text": "\nReturn a matrix of given shape and type, filled with zeros.\n\nShape of the matrix\n\nThe desired data-type for the matrix, default is float.\n\nWhether to store the result in C- or Fortran-contiguous order, default is \u2018C\u2019.\n\nZero matrix of given shape, dtype, and order.\n\nSee also\n\nEquivalent array function.\n\nReturn a matrix of ones.\n\nIf `shape` has length one i.e. `(N,)`, or is a scalar `N`, `out` becomes a\nsingle row matrix of shape `(1,N)`.\n\n"}, {"name": "Matrix library (numpy.matlib)", "path": "reference/routines.matlib", "type": "Matrix library ( \n      \n       numpy.matlib\n      \n      )", "text": "\nThis module contains all functions in the `numpy` namespace, with the\nfollowing replacement functions that return `matrices` instead of `ndarrays`.\n\nFunctions that are also in the numpy namespace and return matrices\n\n`mat`(data[, dtype])\n\nInterpret the input as a matrix.\n\n`matrix`(data[, dtype, copy])\n\nNote\n\nIt is no longer recommended to use this class, even for linear\n\n`asmatrix`(data[, dtype])\n\nInterpret the input as a matrix.\n\n`bmat`(obj[, ldict, gdict])\n\nBuild a matrix object from a string, nested sequence, or array.\n\nReplacement functions in `matlib`\n\n`empty`(shape[, dtype, order])\n\nReturn a new matrix of given shape and type, without initializing entries.\n\n`zeros`(shape[, dtype, order])\n\nReturn a matrix of given shape and type, filled with zeros.\n\n`ones`(shape[, dtype, order])\n\nMatrix of ones.\n\n`eye`(n[, M, k, dtype, order])\n\nReturn a matrix with ones on the diagonal and zeros elsewhere.\n\n`identity`(n[, dtype])\n\nReturns the square identity matrix of given size.\n\n`repmat`(a, m, n)\n\nRepeat a 0-D to 2-D array or matrix MxN times.\n\n`rand`(*args)\n\nReturn a matrix of random values with given shape.\n\n`randn`(*args)\n\nReturn a random matrix with data from the \"standard normal\" distribution.\n\n"}, {"name": "matrix.all()", "path": "reference/generated/numpy.matrix.all", "type": "numpy.matrix.all", "text": "\nmethod\n\nTest whether all matrix elements along a given axis evaluate to True.\n\nSee also\n\nThis is the same as `ndarray.all`, but it returns a `matrix` object.\n\n"}, {"name": "matrix.any()", "path": "reference/generated/numpy.matrix.any", "type": "numpy.matrix.any", "text": "\nmethod\n\nTest whether any array element along a given axis evaluates to True.\n\nRefer to `numpy.any` for full documentation.\n\nAxis along which logical OR is performed\n\nOutput to existing array instead of creating new one, must have same shape as\nexpected output\n\nReturns a single bool if `axis` is `None`; otherwise, returns `ndarray`\n\n"}, {"name": "matrix.argmax()", "path": "reference/generated/numpy.matrix.argmax", "type": "numpy.matrix.argmax", "text": "\nmethod\n\nIndexes of the maximum values along an axis.\n\nReturn the indexes of the first occurrences of the maximum values along the\nspecified axis. If axis is None, the index is for the flattened matrix.\n\nSee also\n\nThis is the same as `ndarray.argmax`, but returns a `matrix` object where\n`ndarray.argmax` would return an `ndarray`.\n\n"}, {"name": "matrix.argmin()", "path": "reference/generated/numpy.matrix.argmin", "type": "numpy.matrix.argmin", "text": "\nmethod\n\nIndexes of the minimum values along an axis.\n\nReturn the indexes of the first occurrences of the minimum values along the\nspecified axis. If axis is None, the index is for the flattened matrix.\n\nSee also\n\nThis is the same as `ndarray.argmin`, but returns a `matrix` object where\n`ndarray.argmin` would return an `ndarray`.\n\n"}, {"name": "matrix.argpartition()", "path": "reference/generated/numpy.matrix.argpartition", "type": "numpy.matrix.argpartition", "text": "\nmethod\n\nReturns the indices that would partition this array.\n\nRefer to `numpy.argpartition` for full documentation.\n\nNew in version 1.8.0.\n\nSee also\n\nequivalent function\n\n"}, {"name": "matrix.argsort()", "path": "reference/generated/numpy.matrix.argsort", "type": "numpy.matrix.argsort", "text": "\nmethod\n\nReturns the indices that would sort this array.\n\nRefer to `numpy.argsort` for full documentation.\n\nSee also\n\nequivalent function\n\n"}, {"name": "matrix.astype()", "path": "reference/generated/numpy.matrix.astype", "type": "numpy.matrix.astype", "text": "\nmethod\n\nCopy of the array, cast to a specified type.\n\nTypecode or data-type to which the array is cast.\n\nControls the memory layout order of the result. \u2018C\u2019 means C order, \u2018F\u2019 means\nFortran order, \u2018A\u2019 means \u2018F\u2019 order if all the arrays are Fortran contiguous,\n\u2018C\u2019 order otherwise, and \u2018K\u2019 means as close to the order the array elements\nappear in memory as possible. Default is \u2018K\u2019.\n\nControls what kind of data casting may occur. Defaults to \u2018unsafe\u2019 for\nbackwards compatibility.\n\nIf True, then sub-classes will be passed-through (default), otherwise the\nreturned array will be forced to be a base-class array.\n\nBy default, astype always returns a newly allocated array. If this is set to\nfalse, and the `dtype`, `order`, and `subok` requirements are satisfied, the\ninput array is returned instead of a copy.\n\nUnless `copy` is False and the other conditions for returning the input array\nare satisfied (see description for `copy` input parameter), `arr_t` is a new\narray of the same shape as the input array, with dtype, order given by\n`dtype`, `order`.\n\nWhen casting from complex to float or int. To avoid this, one should use\n`a.real.astype(t)`.\n\nChanged in version 1.17.0: Casting between a simple data type and a structured\none is possible only for \u201cunsafe\u201d casting. Casting to multiple fields is\nallowed, but casting from multiple fields is not.\n\nChanged in version 1.9.0: Casting from numeric to string types in \u2018safe\u2019\ncasting mode requires that the string dtype length is long enough to store the\nmax integer/float value converted.\n\n"}, {"name": "matrix.base", "path": "reference/generated/numpy.matrix.base", "type": "Standard array subclasses", "text": "\nattribute\n\nBase object if memory is from some other object.\n\nThe base of an array that owns its memory is None:\n\nSlicing creates a view, whose memory is shared with x:\n\n"}, {"name": "matrix.byteswap()", "path": "reference/generated/numpy.matrix.byteswap", "type": "numpy.matrix.byteswap", "text": "\nmethod\n\nSwap the bytes of the array elements\n\nToggle between low-endian and big-endian data representation by returning a\nbyteswapped array, optionally swapped in-place. Arrays of byte-strings are not\nswapped. The real and imaginary parts of a complex number are swapped\nindividually.\n\nIf `True`, swap bytes in-place, default is `False`.\n\nThe byteswapped array. If `inplace` is `True`, this is a view to self.\n\nArrays of byte-strings are not swapped\n\nbut different representation in memory\n\n"}, {"name": "matrix.choose()", "path": "reference/generated/numpy.matrix.choose", "type": "numpy.matrix.choose", "text": "\nmethod\n\nUse an index array to construct a new array from a set of choices.\n\nRefer to `numpy.choose` for full documentation.\n\nSee also\n\nequivalent function\n\n"}, {"name": "matrix.clip()", "path": "reference/generated/numpy.matrix.clip", "type": "numpy.matrix.clip", "text": "\nmethod\n\nReturn an array whose values are limited to `[min, max]`. One of max or min\nmust be given.\n\nRefer to `numpy.clip` for full documentation.\n\nSee also\n\nequivalent function\n\n"}, {"name": "matrix.compress()", "path": "reference/generated/numpy.matrix.compress", "type": "numpy.matrix.compress", "text": "\nmethod\n\nReturn selected slices of this array along given axis.\n\nRefer to `numpy.compress` for full documentation.\n\nSee also\n\nequivalent function\n\n"}, {"name": "matrix.conj()", "path": "reference/generated/numpy.matrix.conj", "type": "numpy.matrix.conj", "text": "\nmethod\n\nComplex-conjugate all elements.\n\nRefer to `numpy.conjugate` for full documentation.\n\nSee also\n\nequivalent function\n\n"}, {"name": "matrix.conjugate()", "path": "reference/generated/numpy.matrix.conjugate", "type": "numpy.matrix.conjugate", "text": "\nmethod\n\nReturn the complex conjugate, element-wise.\n\nRefer to `numpy.conjugate` for full documentation.\n\nSee also\n\nequivalent function\n\n"}, {"name": "matrix.copy()", "path": "reference/generated/numpy.matrix.copy", "type": "numpy.matrix.copy", "text": "\nmethod\n\nReturn a copy of the array.\n\nControls the memory layout of the copy. \u2018C\u2019 means C-order, \u2018F\u2019 means F-order,\n\u2018A\u2019 means \u2018F\u2019 if `a` is Fortran contiguous, \u2018C\u2019 otherwise. \u2018K\u2019 means match the\nlayout of `a` as closely as possible. (Note that this function and\n`numpy.copy` are very similar but have different default values for their\norder= arguments, and this function always passes sub-classes through.)\n\nSee also\n\nSimilar function with different default behavior\n\nThis function is the preferred method for creating an array copy. The function\n`numpy.copy` is similar, but it defaults to using order \u2018K\u2019, and will not pass\nsub-classes through by default.\n\n"}, {"name": "matrix.ctypes", "path": "reference/generated/numpy.matrix.ctypes", "type": "Standard array subclasses", "text": "\nattribute\n\nAn object to simplify the interaction of the array with the ctypes module.\n\nThis attribute creates an object that makes it easier to use arrays when\ncalling shared libraries with the ctypes module. The returned object has,\namong others, data, shape, and strides attributes (see Notes below) which\nthemselves return ctypes objects that can be used as arguments to a shared\nlibrary.\n\nPossessing attributes data, shape, strides, etc.\n\nSee also\n\nBelow are the public attributes of this object which were documented in \u201cGuide\nto NumPy\u201d (we have omitted undocumented public attributes, as well as\ndocumented private attributes):\n\nA pointer to the memory area of the array as a Python integer. This memory\narea may contain data that is not aligned, or not in correct byte-order. The\nmemory area may not even be writeable. The array flags and data-type of this\narray should be respected when passing this attribute to arbitrary C-code to\navoid trouble that can include Python crashing. User Beware! The value of this\nattribute is exactly the same as `self._array_interface_['data'][0]`.\n\nNote that unlike `data_as`, a reference will not be kept to the array: code\nlike `ctypes.c_void_p((a + b).ctypes.data)` will result in a pointer to a\ndeallocated array, and should be spelt `(a +\nb).ctypes.data_as(ctypes.c_void_p)`\n\n(c_intp*self.ndim): A ctypes array of length self.ndim where the basetype is\nthe C-integer corresponding to `dtype('p')` on this platform (see `c_intp`).\nThis base-type could be `ctypes.c_int`, `ctypes.c_long`, or\n`ctypes.c_longlong` depending on the platform. The ctypes array contains the\nshape of the underlying array.\n\n(c_intp*self.ndim): A ctypes array of length self.ndim where the basetype is\nthe same as for the shape attribute. This ctypes array contains the strides\ninformation from the underlying array. This strides information is important\nfor showing how many bytes must be jumped to get to the next element in the\narray.\n\nReturn the data pointer cast to a particular c-types object. For example,\ncalling `self._as_parameter_` is equivalent to\n`self.data_as(ctypes.c_void_p)`. Perhaps you want to use the data as a pointer\nto a ctypes array of floating-point data:\n`self.data_as(ctypes.POINTER(ctypes.c_double))`.\n\nThe returned pointer will keep a reference to the array.\n\nReturn the shape tuple as an array of some other c-types type. For example:\n`self.shape_as(ctypes.c_short)`.\n\nReturn the strides tuple as an array of some other c-types type. For example:\n`self.strides_as(ctypes.c_longlong)`.\n\nIf the ctypes module is not available, then the ctypes attribute of array\nobjects still returns something useful, but ctypes objects are not returned\nand errors may be raised instead. In particular, the object will still have\nthe `as_parameter` attribute which will return an integer equal to the data\nattribute.\n\n"}, {"name": "matrix.cumprod()", "path": "reference/generated/numpy.matrix.cumprod", "type": "numpy.matrix.cumprod", "text": "\nmethod\n\nReturn the cumulative product of the elements along the given axis.\n\nRefer to `numpy.cumprod` for full documentation.\n\nSee also\n\nequivalent function\n\n"}, {"name": "matrix.cumsum()", "path": "reference/generated/numpy.matrix.cumsum", "type": "numpy.matrix.cumsum", "text": "\nmethod\n\nReturn the cumulative sum of the elements along the given axis.\n\nRefer to `numpy.cumsum` for full documentation.\n\nSee also\n\nequivalent function\n\n"}, {"name": "matrix.data", "path": "reference/generated/numpy.matrix.data", "type": "Standard array subclasses", "text": "\nattribute\n\nPython buffer object pointing to the start of the array\u2019s data.\n\n"}, {"name": "matrix.diagonal()", "path": "reference/generated/numpy.matrix.diagonal", "type": "numpy.matrix.diagonal", "text": "\nmethod\n\nReturn specified diagonals. In NumPy 1.9 the returned array is a read-only\nview instead of a copy as in previous NumPy versions. In a future version the\nread-only restriction will be removed.\n\nRefer to `numpy.diagonal` for full documentation.\n\nSee also\n\nequivalent function\n\n"}, {"name": "matrix.dump()", "path": "reference/generated/numpy.matrix.dump", "type": "numpy.matrix.dump", "text": "\nmethod\n\nDump a pickle of the array to the specified file. The array can be read back\nwith pickle.load or numpy.load.\n\nA string naming the dump file.\n\nChanged in version 1.17.0: `pathlib.Path` objects are now accepted.\n\n"}, {"name": "matrix.dumps()", "path": "reference/generated/numpy.matrix.dumps", "type": "numpy.matrix.dumps", "text": "\nmethod\n\nReturns the pickle of the array as a string. pickle.loads will convert the\nstring back to an array.\n\n"}, {"name": "matrix.fill()", "path": "reference/generated/numpy.matrix.fill", "type": "numpy.matrix.fill", "text": "\nmethod\n\nFill the array with a scalar value.\n\nAll elements of `a` will be assigned this value.\n\n"}, {"name": "matrix.flags", "path": "reference/generated/numpy.matrix.flags", "type": "Standard array subclasses", "text": "\nattribute\n\nInformation about the memory layout of the array.\n\nThe `flags` object can be accessed dictionary-like (as in\n`a.flags['WRITEABLE']`), or by using lowercased attribute names (as in\n`a.flags.writeable`). Short flag names are only supported in dictionary\naccess.\n\nOnly the WRITEBACKIFCOPY, UPDATEIFCOPY, WRITEABLE, and ALIGNED flags can be\nchanged by the user, via direct assignment to the attribute or dictionary\nentry, or by calling `ndarray.setflags`.\n\nThe array flags cannot be set arbitrarily:\n\nArrays can be both C-style and Fortran-style contiguous simultaneously. This\nis clear for 1-dimensional arrays, but can also be true for higher dimensional\narrays.\n\nEven for contiguous arrays a stride for a given dimension `arr.strides[dim]`\nmay be arbitrary if `arr.shape[dim] == 1` or the array has no elements. It\ndoes not generally hold that `self.strides[-1] == self.itemsize` for C-style\ncontiguous arrays or `self.strides[0] == self.itemsize` for Fortran-style\ncontiguous arrays is true.\n\nThe data is in a single, C-style contiguous segment.\n\nThe data is in a single, Fortran-style contiguous segment.\n\nThe array owns the memory it uses or borrows it from another object.\n\nThe data area can be written to. Setting this to False locks the data, making\nit read-only. A view (slice, etc.) inherits WRITEABLE from its base array at\ncreation time, but a view of a writeable array may be subsequently locked\nwhile the base array remains writeable. (The opposite is not true, in that a\nview of a locked array may not be made writeable. However, currently, locking\na base object does not lock any views that already reference it, so under that\ncircumstance it is possible to alter the contents of a locked array via a\npreviously created writeable view onto it.) Attempting to change a non-\nwriteable array raises a RuntimeError exception.\n\nThe data and all elements are aligned appropriately for the hardware.\n\nThis array is a copy of some other array. The C-API function\nPyArray_ResolveWritebackIfCopy must be called before deallocating to the base\narray will be updated with the contents of this array.\n\n(Deprecated, use WRITEBACKIFCOPY) This array is a copy of some other array.\nWhen this array is deallocated, the base array will be updated with the\ncontents of this array.\n\nF_CONTIGUOUS and not C_CONTIGUOUS.\n\nF_CONTIGUOUS or C_CONTIGUOUS (one-segment test).\n\nALIGNED and WRITEABLE.\n\nBEHAVED and C_CONTIGUOUS.\n\nBEHAVED and F_CONTIGUOUS and not C_CONTIGUOUS.\n\n"}, {"name": "matrix.flat", "path": "reference/generated/numpy.matrix.flat", "type": "Standard array subclasses", "text": "\nattribute\n\nA 1-D iterator over the array.\n\nThis is a `numpy.flatiter` instance, which acts similarly to, but is not a\nsubclass of, Python\u2019s built-in iterator object.\n\nSee also\n\nReturn a copy of the array collapsed into one dimension.\n\nAn assignment example:\n\n"}, {"name": "matrix.flatten()", "path": "reference/generated/numpy.matrix.flatten", "type": "numpy.matrix.flatten", "text": "\nmethod\n\nReturn a flattened copy of the matrix.\n\nAll `N` elements of the matrix are placed into a single row.\n\n\u2018C\u2019 means to flatten in row-major (C-style) order. \u2018F\u2019 means to flatten in\ncolumn-major (Fortran-style) order. \u2018A\u2019 means to flatten in column-major order\nif `m` is Fortran contiguous in memory, row-major order otherwise. \u2018K\u2019 means\nto flatten `m` in the order the elements occur in memory. The default is \u2018C\u2019.\n\nA copy of the matrix, flattened to a `(1, N)` matrix where `N` is the number\nof elements in the original matrix.\n\nSee also\n\nReturn a flattened array.\n\nA 1-D flat iterator over the matrix.\n\n"}, {"name": "matrix.getA()", "path": "reference/generated/numpy.matrix.geta", "type": "numpy.matrix.getA", "text": "\nmethod\n\nReturn `self` as an `ndarray` object.\n\nEquivalent to `np.asarray(self)`.\n\n`self` as an `ndarray`\n\n"}, {"name": "matrix.getA1()", "path": "reference/generated/numpy.matrix.geta1", "type": "numpy.matrix.getA1", "text": "\nmethod\n\nReturn `self` as a flattened `ndarray`.\n\nEquivalent to `np.asarray(x).ravel()`\n\n`self`, 1-D, as an `ndarray`\n\n"}, {"name": "matrix.getfield()", "path": "reference/generated/numpy.matrix.getfield", "type": "numpy.matrix.getfield", "text": "\nmethod\n\nReturns a field of the given array as a certain type.\n\nA field is a view of the array data with a given data-type. The values in the\nview are determined by the given type and the offset into the current array in\nbytes. The offset needs to be such that the view dtype fits in the array\ndtype; for example an array of dtype complex128 has 16-byte elements. If\ntaking a view with a 32-bit integer (4 bytes), the offset needs to be between\n0 and 12 bytes.\n\nThe data type of the view. The dtype size of the view can not be larger than\nthat of the array itself.\n\nNumber of bytes to skip before beginning the element view.\n\nBy choosing an offset of 8 bytes we can select the complex part of the array\nfor our view:\n\n"}, {"name": "matrix.getH()", "path": "reference/generated/numpy.matrix.geth", "type": "numpy.matrix.getH", "text": "\nmethod\n\nReturns the (complex) conjugate transpose of `self`.\n\nEquivalent to `np.transpose(self)` if `self` is real-valued.\n\ncomplex conjugate transpose of `self`\n\n"}, {"name": "matrix.getI()", "path": "reference/generated/numpy.matrix.geti", "type": "numpy.matrix.getI", "text": "\nmethod\n\nReturns the (multiplicative) inverse of invertible `self`.\n\nIf `self` is non-singular, `ret` is such that `ret * self` == `self * ret` ==\n`np.matrix(np.eye(self[0,:].size))` all return `True`.\n\nIf `self` is singular.\n\nSee also\n\n"}, {"name": "matrix.getT()", "path": "reference/generated/numpy.matrix.gett", "type": "numpy.matrix.getT", "text": "\nmethod\n\nReturns the transpose of the matrix.\n\nDoes not conjugate! For the complex conjugate transpose, use `.H`.\n\nThe (non-conjugated) transpose of the matrix.\n\nSee also\n\n"}, {"name": "matrix.item()", "path": "reference/generated/numpy.matrix.item", "type": "numpy.matrix.item", "text": "\nmethod\n\nCopy an element of an array to a standard Python scalar and return it.\n\nA copy of the specified element of the array as a suitable Python scalar\n\nWhen the data type of `a` is longdouble or clongdouble, item() returns a\nscalar array object because there is no available Python scalar that would not\nlose information. Void arrays return a buffer object for item(), unless fields\nare defined, in which case a tuple is returned.\n\n`item` is very similar to a[args], except, instead of an array scalar, a\nstandard Python scalar is returned. This can be useful for speeding up access\nto elements of the array and doing arithmetic on elements of the array using\nPython\u2019s optimized math.\n\n"}, {"name": "matrix.itemset()", "path": "reference/generated/numpy.matrix.itemset", "type": "numpy.matrix.itemset", "text": "\nmethod\n\nInsert scalar into an array (scalar is cast to array\u2019s dtype, if possible)\n\nThere must be at least 1 argument, and define the last argument as item. Then,\n`a.itemset(*args)` is equivalent to but faster than `a[args] = item`. The item\nshould be a scalar value and `args` must select a single item in the array\n`a`.\n\nIf one argument: a scalar, only used in case `a` is of size 1. If two\narguments: the last argument is the value to be set and must be a scalar, the\nfirst argument specifies a single array element location. It is either an int\nor a tuple.\n\nCompared to indexing syntax, `itemset` provides some speed increase for\nplacing a scalar into a particular location in an `ndarray`, if you must do\nthis. However, generally this is discouraged: among other problems, it\ncomplicates the appearance of the code. Also, when using `itemset` (and\n`item`) inside a loop, be sure to assign the methods to a local variable to\navoid the attribute look-up at each loop iteration.\n\n"}, {"name": "matrix.itemsize", "path": "reference/generated/numpy.matrix.itemsize", "type": "Standard array subclasses", "text": "\nattribute\n\nLength of one array element in bytes.\n\n"}, {"name": "matrix.max()", "path": "reference/generated/numpy.matrix.max", "type": "numpy.matrix.max", "text": "\nmethod\n\nReturn the maximum value along an axis.\n\nSee also\n\nThis is the same as `ndarray.max`, but returns a `matrix` object where\n`ndarray.max` would return an ndarray.\n\n"}, {"name": "matrix.mean()", "path": "reference/generated/numpy.matrix.mean", "type": "numpy.matrix.mean", "text": "\nmethod\n\nReturns the average of the matrix elements along the given axis.\n\nRefer to `numpy.mean` for full documentation.\n\nSee also\n\nSame as `ndarray.mean` except that, where that returns an `ndarray`, this\nreturns a `matrix` object.\n\n"}, {"name": "matrix.min()", "path": "reference/generated/numpy.matrix.min", "type": "numpy.matrix.min", "text": "\nmethod\n\nReturn the minimum value along an axis.\n\nSee also\n\nThis is the same as `ndarray.min`, but returns a `matrix` object where\n`ndarray.min` would return an ndarray.\n\n"}, {"name": "matrix.nbytes", "path": "reference/generated/numpy.matrix.nbytes", "type": "Standard array subclasses", "text": "\nattribute\n\nTotal bytes consumed by the elements of the array.\n\nDoes not include memory consumed by non-element attributes of the array\nobject.\n\n"}, {"name": "matrix.ndim", "path": "reference/generated/numpy.matrix.ndim", "type": "Standard array subclasses", "text": "\nattribute\n\nNumber of array dimensions.\n\n"}, {"name": "matrix.newbyteorder()", "path": "reference/generated/numpy.matrix.newbyteorder", "type": "numpy.matrix.newbyteorder", "text": "\nmethod\n\nReturn the array with the same data viewed with a different byte order.\n\nEquivalent to:\n\nChanges are also made in all fields and sub-arrays of the array data type.\n\nByte order to force; a value from the byte order specifications below.\n`new_order` codes can be any of:\n\nThe default value (\u2018S\u2019) results in swapping the current byte order.\n\nNew array object with the dtype reflecting given change to the byte order.\n\n"}, {"name": "matrix.nonzero()", "path": "reference/generated/numpy.matrix.nonzero", "type": "numpy.matrix.nonzero", "text": "\nmethod\n\nReturn the indices of the elements that are non-zero.\n\nRefer to `numpy.nonzero` for full documentation.\n\nSee also\n\nequivalent function\n\n"}, {"name": "matrix.partition()", "path": "reference/generated/numpy.matrix.partition", "type": "numpy.matrix.partition", "text": "\nmethod\n\nRearranges the elements in the array in such a way that the value of the\nelement in kth position is in the position it would be in a sorted array. All\nelements smaller than the kth element are moved before this element and all\nequal or greater are moved behind it. The ordering of the elements in the two\npartitions is undefined.\n\nNew in version 1.8.0.\n\nElement index to partition by. The kth element value will be in its final\nsorted position and all smaller elements will be moved before it and all equal\nor greater elements behind it. The order of all elements in the partitions is\nundefined. If provided with a sequence of kth it will partition all elements\nindexed by kth of them into their sorted position at once.\n\nDeprecated since version 1.22.0: Passing booleans as index is deprecated.\n\nAxis along which to sort. Default is -1, which means sort along the last axis.\n\nSelection algorithm. Default is \u2018introselect\u2019.\n\nWhen `a` is an array with fields defined, this argument specifies which fields\nto compare first, second, etc. A single field can be specified as a string,\nand not all fields need to be specified, but unspecified fields will still be\nused, in the order in which they come up in the dtype, to break ties.\n\nSee also\n\nReturn a parititioned copy of an array.\n\nIndirect partition.\n\nFull sort.\n\nSee `np.partition` for notes on the different algorithms.\n\n"}, {"name": "matrix.prod()", "path": "reference/generated/numpy.matrix.prod", "type": "numpy.matrix.prod", "text": "\nmethod\n\nReturn the product of the array elements over the given axis.\n\nRefer to `prod` for full documentation.\n\nSee also\n\nSame as `ndarray.prod`, except, where that returns an `ndarray`, this returns\na `matrix` object instead.\n\n"}, {"name": "matrix.ptp()", "path": "reference/generated/numpy.matrix.ptp", "type": "numpy.matrix.ptp", "text": "\nmethod\n\nPeak-to-peak (maximum - minimum) value along the given axis.\n\nRefer to `numpy.ptp` for full documentation.\n\nSee also\n\nSame as `ndarray.ptp`, except, where that would return an `ndarray` object,\nthis returns a `matrix` object.\n\n"}, {"name": "matrix.put()", "path": "reference/generated/numpy.matrix.put", "type": "numpy.matrix.put", "text": "\nmethod\n\nSet `a.flat[n] = values[n]` for all `n` in indices.\n\nRefer to `numpy.put` for full documentation.\n\nSee also\n\nequivalent function\n\n"}, {"name": "matrix.ravel()", "path": "reference/generated/numpy.matrix.ravel", "type": "numpy.matrix.ravel", "text": "\nmethod\n\nReturn a flattened matrix.\n\nRefer to `numpy.ravel` for more documentation.\n\nThe elements of `m` are read using this index order. \u2018C\u2019 means to index the\nelements in C-like order, with the last axis index changing fastest, back to\nthe first axis index changing slowest. \u2018F\u2019 means to index the elements in\nFortran-like index order, with the first index changing fastest, and the last\nindex changing slowest. Note that the \u2018C\u2019 and \u2018F\u2019 options take no account of\nthe memory layout of the underlying array, and only refer to the order of axis\nindexing. \u2018A\u2019 means to read the elements in Fortran-like index order if `m` is\nFortran contiguous in memory, C-like order otherwise. \u2018K\u2019 means to read the\nelements in the order they occur in memory, except for reversing the data when\nstrides are negative. By default, \u2018C\u2019 index order is used.\n\nReturn the matrix flattened to shape `(1, N)` where `N` is the number of\nelements in the original matrix. A copy is made only if necessary.\n\nSee also\n\nreturns a similar output matrix but always a copy\n\na flat iterator on the array.\n\nrelated function which returns an ndarray\n\n"}, {"name": "matrix.repeat()", "path": "reference/generated/numpy.matrix.repeat", "type": "numpy.matrix.repeat", "text": "\nmethod\n\nRepeat elements of an array.\n\nRefer to `numpy.repeat` for full documentation.\n\nSee also\n\nequivalent function\n\n"}, {"name": "matrix.reshape()", "path": "reference/generated/numpy.matrix.reshape", "type": "numpy.matrix.reshape", "text": "\nmethod\n\nReturns an array containing the same data with a new shape.\n\nRefer to `numpy.reshape` for full documentation.\n\nSee also\n\nequivalent function\n\nUnlike the free function `numpy.reshape`, this method on `ndarray` allows the\nelements of the shape parameter to be passed in as separate arguments. For\nexample, `a.reshape(10, 11)` is equivalent to `a.reshape((10, 11))`.\n\n"}, {"name": "matrix.resize()", "path": "reference/generated/numpy.matrix.resize", "type": "numpy.matrix.resize", "text": "\nmethod\n\nChange shape and size of array in-place.\n\nShape of resized array.\n\nIf False, reference count will not be checked. Default is True.\n\nIf `a` does not own its own data or references or views to it exist, and the\ndata memory must be changed. PyPy only: will always raise if the data memory\nmust be changed, since there is no reliable way to determine if references or\nviews to it exist.\n\nIf the `order` keyword argument is specified. This behaviour is a bug in\nNumPy.\n\nSee also\n\nReturn a new array with the specified shape.\n\nThis reallocates space for the data area if necessary.\n\nOnly contiguous arrays (data elements consecutive in memory) can be resized.\n\nThe purpose of the reference count check is to make sure you do not use this\narray as a buffer for another Python object and then reallocate the memory.\nHowever, reference counts can increase in other ways so if you are sure that\nyou have not shared the memory for this array with another Python object, then\nyou may safely set `refcheck` to False.\n\nShrinking an array: array is flattened (in the order that the data are stored\nin memory), resized, and reshaped:\n\nEnlarging an array: as above, but missing entries are filled with zeros:\n\nReferencing an array prevents resizing\u2026\n\nUnless `refcheck` is False:\n\n"}, {"name": "matrix.round()", "path": "reference/generated/numpy.matrix.round", "type": "numpy.matrix.round", "text": "\nmethod\n\nReturn `a` with each element rounded to the given number of decimals.\n\nRefer to `numpy.around` for full documentation.\n\nSee also\n\nequivalent function\n\n"}, {"name": "matrix.searchsorted()", "path": "reference/generated/numpy.matrix.searchsorted", "type": "numpy.matrix.searchsorted", "text": "\nmethod\n\nFind indices where elements of v should be inserted in a to maintain order.\n\nFor full documentation, see `numpy.searchsorted`\n\nSee also\n\nequivalent function\n\n"}, {"name": "matrix.setfield()", "path": "reference/generated/numpy.matrix.setfield", "type": "numpy.matrix.setfield", "text": "\nmethod\n\nPut a value into a specified place in a field defined by a data-type.\n\nPlace `val` into `a`\u2019s field defined by `dtype` and beginning `offset` bytes\ninto the field.\n\nValue to be placed in field.\n\nData-type of the field in which to place `val`.\n\nThe number of bytes into the field at which to place `val`.\n\nSee also\n\n"}, {"name": "matrix.setflags()", "path": "reference/generated/numpy.matrix.setflags", "type": "numpy.matrix.setflags", "text": "\nmethod\n\nSet array flags WRITEABLE, ALIGNED, (WRITEBACKIFCOPY and UPDATEIFCOPY),\nrespectively.\n\nThese Boolean-valued flags affect how numpy interprets the memory area used by\n`a` (see Notes below). The ALIGNED flag can only be set to True if the data is\nactually aligned according to the type. The WRITEBACKIFCOPY and (deprecated)\nUPDATEIFCOPY flags can never be set to True. The flag WRITEABLE can only be\nset to True if the array owns its own memory, or the ultimate owner of the\nmemory exposes a writeable buffer interface, or is a string. (The exception\nfor string is made so that unpickling can be done without copying memory.)\n\nDescribes whether or not `a` can be written to.\n\nDescribes whether or not `a` is aligned properly for its type.\n\nDescribes whether or not `a` is a copy of another \u201cbase\u201d array.\n\nArray flags provide information about how the memory area used for the array\nis to be interpreted. There are 7 Boolean flags in use, only four of which can\nbe changed by the user: WRITEBACKIFCOPY, UPDATEIFCOPY, WRITEABLE, and ALIGNED.\n\nWRITEABLE (W) the data area can be written to;\n\nALIGNED (A) the data and strides are aligned appropriately for the hardware\n(as determined by the compiler);\n\nUPDATEIFCOPY (U) (deprecated), replaced by WRITEBACKIFCOPY;\n\nWRITEBACKIFCOPY (X) this array is a copy of some other array (referenced by\n.base). When the C-API function PyArray_ResolveWritebackIfCopy is called, the\nbase array will be updated with the contents of this array.\n\nAll flags can be accessed using the single (upper case) letter as well as the\nfull name.\n\n"}, {"name": "matrix.size", "path": "reference/generated/numpy.matrix.size", "type": "Standard array subclasses", "text": "\nattribute\n\nNumber of elements in the array.\n\nEqual to `np.prod(a.shape)`, i.e., the product of the array\u2019s dimensions.\n\n`a.size` returns a standard arbitrary precision Python integer. This may not\nbe the case with other methods of obtaining the same value (like the suggested\n`np.prod(a.shape)`, which returns an instance of `np.int_`), and may be\nrelevant if the value is used further in calculations that may overflow a\nfixed size integer type.\n\n"}, {"name": "matrix.sort()", "path": "reference/generated/numpy.matrix.sort", "type": "numpy.matrix.sort", "text": "\nmethod\n\nSort an array in-place. Refer to `numpy.sort` for full documentation.\n\nAxis along which to sort. Default is -1, which means sort along the last axis.\n\nSorting algorithm. The default is \u2018quicksort\u2019. Note that both \u2018stable\u2019 and\n\u2018mergesort\u2019 use timsort under the covers and, in general, the actual\nimplementation will vary with datatype. The \u2018mergesort\u2019 option is retained for\nbackwards compatibility.\n\nChanged in version 1.15.0: The \u2018stable\u2019 option was added.\n\nWhen `a` is an array with fields defined, this argument specifies which fields\nto compare first, second, etc. A single field can be specified as a string,\nand not all fields need be specified, but unspecified fields will still be\nused, in the order in which they come up in the dtype, to break ties.\n\nSee also\n\nReturn a sorted copy of an array.\n\nIndirect sort.\n\nIndirect stable sort on multiple keys.\n\nFind elements in sorted array.\n\nPartial sort.\n\nSee `numpy.sort` for notes on the different sorting algorithms.\n\nUse the `order` keyword to specify a field to use when sorting a structured\narray:\n\n"}, {"name": "matrix.squeeze()", "path": "reference/generated/numpy.matrix.squeeze", "type": "numpy.matrix.squeeze", "text": "\nmethod\n\nReturn a possibly reshaped matrix.\n\nRefer to `numpy.squeeze` for more documentation.\n\nSelects a subset of the axes of length one in the shape. If an axis is\nselected with shape entry greater than one, an error is raised.\n\nThe matrix, but as a (1, N) matrix if it had shape (N, 1).\n\nSee also\n\nrelated function\n\nIf `m` has a single column then that column is returned as the single row of a\nmatrix. Otherwise `m` is returned. The returned matrix is always either `m`\nitself or a view into `m`. Supplying an axis keyword argument will not affect\nthe returned matrix but it may cause an error to be raised.\n\n"}, {"name": "matrix.std()", "path": "reference/generated/numpy.matrix.std", "type": "numpy.matrix.std", "text": "\nmethod\n\nReturn the standard deviation of the array elements along the given axis.\n\nRefer to `numpy.std` for full documentation.\n\nSee also\n\nThis is the same as `ndarray.std`, except that where an `ndarray` would be\nreturned, a `matrix` object is returned instead.\n\n"}, {"name": "matrix.strides", "path": "reference/generated/numpy.matrix.strides", "type": "Standard array subclasses", "text": "\nattribute\n\nTuple of bytes to step in each dimension when traversing an array.\n\nThe byte offset of element `(i[0], i[1], ..., i[n])` in an array `a` is:\n\nA more detailed explanation of strides can be found in the \u201cndarray.rst\u201d file\nin the NumPy reference guide.\n\nSee also\n\nImagine an array of 32-bit integers (each 4 bytes):\n\nThis array is stored in memory as 40 bytes, one after the other (known as a\ncontiguous block of memory). The strides of an array tell us how many bytes we\nhave to skip in memory to move to the next position along a certain axis. For\nexample, we have to skip 4 bytes (1 value) to move to the next column, but 20\nbytes (5 values) to get to the same position in the next row. As such, the\nstrides for the array `x` will be `(20, 4)`.\n\n"}, {"name": "matrix.sum()", "path": "reference/generated/numpy.matrix.sum", "type": "numpy.matrix.sum", "text": "\nmethod\n\nReturns the sum of the matrix elements, along the given axis.\n\nRefer to `numpy.sum` for full documentation.\n\nSee also\n\nThis is the same as `ndarray.sum`, except that where an `ndarray` would be\nreturned, a `matrix` object is returned instead.\n\n"}, {"name": "matrix.swapaxes()", "path": "reference/generated/numpy.matrix.swapaxes", "type": "numpy.matrix.swapaxes", "text": "\nmethod\n\nReturn a view of the array with `axis1` and `axis2` interchanged.\n\nRefer to `numpy.swapaxes` for full documentation.\n\nSee also\n\nequivalent function\n\n"}, {"name": "matrix.take()", "path": "reference/generated/numpy.matrix.take", "type": "numpy.matrix.take", "text": "\nmethod\n\nReturn an array formed from the elements of `a` at the given indices.\n\nRefer to `numpy.take` for full documentation.\n\nSee also\n\nequivalent function\n\n"}, {"name": "matrix.tobytes()", "path": "reference/generated/numpy.matrix.tobytes", "type": "numpy.matrix.tobytes", "text": "\nmethod\n\nConstruct Python bytes containing the raw data bytes in the array.\n\nConstructs Python bytes showing a copy of the raw contents of data memory. The\nbytes object is produced in C-order by default. This behavior is controlled by\nthe `order` parameter.\n\nNew in version 1.9.0.\n\nControls the memory layout of the bytes object. \u2018C\u2019 means C-order, \u2018F\u2019 means\nF-order, \u2018A\u2019 (short for Any) means \u2018F\u2019 if `a` is Fortran contiguous, \u2018C\u2019\notherwise. Default is \u2018C\u2019.\n\nPython bytes exhibiting a copy of `a`\u2019s raw data.\n\n"}, {"name": "matrix.tofile()", "path": "reference/generated/numpy.matrix.tofile", "type": "numpy.matrix.tofile", "text": "\nmethod\n\nWrite array to a file as text or binary (default).\n\nData is always written in \u2018C\u2019 order, independent of the order of `a`. The data\nproduced by this method can be recovered using the function fromfile().\n\nAn open file object, or a string containing a filename.\n\nChanged in version 1.17.0: `pathlib.Path` objects are now accepted.\n\nSeparator between array items for text output. If \u201c\u201d (empty), a binary file is\nwritten, equivalent to `file.write(a.tobytes())`.\n\nFormat string for text file output. Each entry in the array is formatted to\ntext by first converting it to the closest Python type, and then using\n\u201cformat\u201d % item.\n\nThis is a convenience function for quick storage of array data. Information on\nendianness and precision is lost, so this method is not a good choice for\nfiles intended to archive data or transport data between machines with\ndifferent endianness. Some of these problems can be overcome by outputting the\ndata as text files, at the expense of speed and file size.\n\nWhen fid is a file object, array contents are directly written to the file,\nbypassing the file object\u2019s `write` method. As a result, tofile cannot be used\nwith files objects supporting compression (e.g., GzipFile) or file-like\nobjects that do not support `fileno()` (e.g., BytesIO).\n\n"}, {"name": "matrix.tolist()", "path": "reference/generated/numpy.matrix.tolist", "type": "numpy.matrix.tolist", "text": "\nmethod\n\nReturn the matrix as a (possibly nested) list.\n\nSee `ndarray.tolist` for full documentation.\n\nSee also\n\n"}, {"name": "matrix.tostring()", "path": "reference/generated/numpy.matrix.tostring", "type": "numpy.matrix.tostring", "text": "\nmethod\n\nA compatibility alias for `tobytes`, with exactly the same behavior.\n\nDespite its name, it returns `bytes` not `str`s.\n\nDeprecated since version 1.19.0.\n\n"}, {"name": "matrix.trace()", "path": "reference/generated/numpy.matrix.trace", "type": "numpy.matrix.trace", "text": "\nmethod\n\nReturn the sum along diagonals of the array.\n\nRefer to `numpy.trace` for full documentation.\n\nSee also\n\nequivalent function\n\n"}, {"name": "matrix.transpose()", "path": "reference/generated/numpy.matrix.transpose", "type": "numpy.matrix.transpose", "text": "\nmethod\n\nReturns a view of the array with axes transposed.\n\nFor a 1-D array this has no effect, as a transposed vector is simply the same\nvector. To convert a 1-D array into a 2D column vector, an additional\ndimension must be added. `np.atleast2d(a).T` achieves this, as does `a[:,\nnp.newaxis]`. For a 2-D array, this is a standard matrix transpose. For an n-D\narray, if axes are given, their order indicates how the axes are permuted (see\nExamples). If axes are not provided and `a.shape = (i[0], i[1], ... i[n-2],\ni[n-1])`, then `a.transpose().shape = (i[n-1], i[n-2], ... i[1], i[0])`.\n\nView of `a`, with axes suitably permuted.\n\nSee also\n\nEquivalent function\n\nArray property returning the array transposed.\n\nGive a new shape to an array without changing its data.\n\n"}, {"name": "matrix.var()", "path": "reference/generated/numpy.matrix.var", "type": "numpy.matrix.var", "text": "\nmethod\n\nReturns the variance of the matrix elements, along the given axis.\n\nRefer to `numpy.var` for full documentation.\n\nSee also\n\nThis is the same as `ndarray.var`, except that where an `ndarray` would be\nreturned, a `matrix` object is returned instead.\n\n"}, {"name": "matrix.view()", "path": "reference/generated/numpy.matrix.view", "type": "numpy.matrix.view", "text": "\nmethod\n\nNew view of array with the same data.\n\nNote\n\nPassing None for `dtype` is different from omitting the parameter, since the\nformer invokes `dtype(None)` which is an alias for `dtype('float_')`.\n\nData-type descriptor of the returned view, e.g., float32 or int16. Omitting it\nresults in the view having the same data-type as `a`. This argument can also\nbe specified as an ndarray sub-class, which then specifies the type of the\nreturned object (this is equivalent to setting the `type` parameter).\n\nType of the returned view, e.g., ndarray or matrix. Again, omission of the\nparameter results in type preservation.\n\n`a.view()` is used two different ways:\n\n`a.view(some_dtype)` or `a.view(dtype=some_dtype)` constructs a view of the\narray\u2019s memory with a different data-type. This can cause a reinterpretation\nof the bytes of memory.\n\n`a.view(ndarray_subclass)` or `a.view(type=ndarray_subclass)` just returns an\ninstance of `ndarray_subclass` that looks at the same array (same shape,\ndtype, etc.) This does not cause a reinterpretation of the memory.\n\nFor `a.view(some_dtype)`, if `some_dtype` has a different number of bytes per\nentry than the previous dtype (for example, converting a regular array to a\nstructured array), then the behavior of the view cannot be predicted just from\nthe superficial appearance of `a` (shown by `print(a)`). It also depends on\nexactly how `a` is stored in memory. Therefore if `a` is C-ordered versus\nfortran-ordered, versus defined as a slice or transpose, etc., the view may\ngive different results.\n\nViewing array data using a different type and dtype:\n\nCreating a view on a structured array so it can be used in calculations\n\nMaking changes to the view changes the underlying array\n\nUsing a view to convert an array to a recarray:\n\nViews share data:\n\nViews that change the dtype size (bytes per entry) should normally be avoided\non arrays defined by slices, transposes, fortran-ordering, etc.:\n\n"}, {"name": "memmap.flush()", "path": "reference/generated/numpy.memmap.flush", "type": "numpy.memmap.flush", "text": "\nmethod\n\nWrite any changes in the array to the file on disk.\n\nFor further information, see `memmap`.\n\nSee also\n\n"}, {"name": "Miscellaneous", "path": "user/misc", "type": "User Guide", "text": "\nSpecial values defined in numpy: nan, inf,\n\nNaNs can be used as a poor-man\u2019s mask (if you don\u2019t care what the original\nvalue was)\n\nNote: cannot use equality to test NaNs. E.g.:\n\nOther related special value functions:\n\nThe following corresponds to the usual functions except that nans are excluded\nfrom the results:\n\nThe default is to `'warn'` for `invalid`, `divide`, and `overflow` and\n`'ignore'` for `underflow`. But this can be changed, and it can be set\nindividually for different kinds of exceptions. The different behaviors are:\n\nThese behaviors can be set for all kinds of errors or specific ones:\n\nNote that integer divide-by-zero is handled by the same machinery. These\nbehaviors are set on a per-thread basis.\n\nOnly a survey of the choices. Little detail on how each works.\n\nPlusses:\n\nMinuses:\n\nLots of learning overhead:\n\nReference counting often difficult to get right.\n\nPlusses:\n\nMinuses:\n\nPlusses:\n\ngood numpy support: arrays have all these in their ctypes attribute:\n\nMinuses:\n\nPlusses:\n\nMinuses:\n\nPlusses:\n\nMinuses:\n\nPlusses:\n\nMinuses:\n\nThe clear choice to wrap Fortran code is f2py.\n\nPyfort is an older alternative, but not supported any longer. Fwrap is a newer\nproject that looked promising but isn\u2019t being developed any longer.\n\n"}, {"name": "Miscellaneous routines", "path": "reference/routines.other", "type": "Miscellaneous routines", "text": "\n`setbufsize`(size)\n\nSet the size of the buffer used in ufuncs.\n\n`getbufsize`()\n\nReturn the size of the buffer used in ufuncs.\n\n`shares_memory`(a, b, /[, max_work])\n\nDetermine if two arrays share memory.\n\n`may_share_memory`(a, b, /[, max_work])\n\nDetermine if two arrays might share memory\n\n`byte_bounds`(a)\n\nReturns pointers to the end-points of an array.\n\n`lib.mixins.NDArrayOperatorsMixin`()\n\nMixin defining all operator special methods using __array_ufunc__.\n\n`lib.NumpyVersion`(vstring)\n\nParse and compare numpy version strings.\n\n`get_include`()\n\nReturn the directory that contains the NumPy *.h header files.\n\n`show_config`()\n\nShow libraries in the system on which NumPy was built.\n\n`deprecate`(*args, **kwargs)\n\nIssues a DeprecationWarning, adds warning to `old_name`'s docstring, rebinds\n`old_name.__name__` and returns the new function object.\n\n`deprecate_with_doc`(msg)\n\nDeprecates a function and includes the deprecation in its docstring.\n\n`broadcast_shapes`(*args)\n\nBroadcast the input shapes into a single shape.\n\n`who`([vardict])\n\nPrint the NumPy arrays in the given dictionary.\n\n`disp`(mesg[, device, linefeed])\n\nDisplay a message on a device.\n\n`AxisError`(axis[, ndim, msg_prefix])\n\nAxis supplied was invalid.\n\n"}, {"name": "Multithreaded Generation", "path": "reference/random/multithreading", "type": "Multithreaded Generation", "text": "\nThe four core distributions (`random`, `standard_normal`,\n`standard_exponential`, and `standard_gamma`) all allow existing arrays to be\nfilled using the `out` keyword argument. Existing arrays need to be contiguous\nand well-behaved (writable and aligned). Under normal circumstances, arrays\ncreated using the common constructors such as `numpy.empty` will satisfy these\nrequirements.\n\nThis example makes use of Python 3 `concurrent.futures` to fill an array using\nmultiple threads. Threads are long-lived so that repeated calls do not require\nany additional overheads from thread creation.\n\nThe random numbers generated are reproducible in the sense that the same seed\nwill produce the same outputs, given that the number of threads does not\nchange.\n\nThe multithreaded random number generator can be used to fill an array. The\n`values` attributes shows the zero-value before the fill and the random value\nafter.\n\nThe time required to produce using multiple threads can be compared to the\ntime required to generate using a single thread.\n\nThe single threaded call directly uses the BitGenerator.\n\nThe gains are substantial and the scaling is reasonable even for arrays that\nare only moderately large. The gains are even larger when compared to a call\nthat does not use an existing array due to array creation overhead.\n\nNote that if `threads` is not set by the user, it will be determined by\n`multiprocessing.cpu_count()`.\n\n"}, {"name": "NATIVE: Enables all CPU features that supported by the current", "path": "reference/simd/simd-optimizations", "type": "SIMD Optimizations", "text": "\nNumPy provides a set of macros that define Universal Intrinsics to abstract\nout typical platform-specific intrinsics so SIMD code needs to be written only\nonce. There are three layers:\n\nThe command arguments are available in `build`, `build_clib`, and `build_ext`.\nif `build_clib` or `build_ext` are not specified by the user, the arguments of\n`build` will be used instead, which also holds the default values.\n\nOptimization names can be CPU features or groups of features that gather\nseveral features or special options to perform a series of procedures.\n\nThe following tables show the current supported optimizations sorted from the\nlowest to the highest interest.\n\nName\n\nImplies\n\n`SSE`\n\n`SSE2`\n\n`SSE2`\n\n`SSE`\n\n`SSE3`\n\n`SSE` `SSE2`\n\n`SSSE3`\n\n`SSE` `SSE2` `SSE3`\n\n`SSE41`\n\n`SSE` `SSE2` `SSE3` `SSSE3`\n\n`POPCNT`\n\n`SSE` `SSE2` `SSE3` `SSSE3` `SSE41`\n\n`SSE42`\n\n`SSE` `SSE2` `SSE3` `SSSE3` `SSE41` `POPCNT`\n\n`AVX`\n\n`SSE` `SSE2` `SSE3` `SSSE3` `SSE41` `POPCNT` `SSE42`\n\n`XOP`\n\n`SSE` `SSE2` `SSE3` `SSSE3` `SSE41` `POPCNT` `SSE42` `AVX`\n\n`FMA4`\n\n`SSE` `SSE2` `SSE3` `SSSE3` `SSE41` `POPCNT` `SSE42` `AVX`\n\n`F16C`\n\n`SSE` `SSE2` `SSE3` `SSSE3` `SSE41` `POPCNT` `SSE42` `AVX`\n\n`FMA3`\n\n`SSE` `SSE2` `SSE3` `SSSE3` `SSE41` `POPCNT` `SSE42` `AVX` `F16C`\n\n`AVX2`\n\n`SSE` `SSE2` `SSE3` `SSSE3` `SSE41` `POPCNT` `SSE42` `AVX` `F16C`\n\n`AVX512F`\n\n`SSE` `SSE2` `SSE3` `SSSE3` `SSE41` `POPCNT` `SSE42` `AVX` `F16C` `FMA3`\n`AVX2`\n\n`AVX512CD`\n\n`SSE` `SSE2` `SSE3` `SSSE3` `SSE41` `POPCNT` `SSE42` `AVX` `F16C` `FMA3`\n`AVX2` `AVX512F`\n\nName\n\nGather\n\nImplies\n\n`AVX512_KNL`\n\n`AVX512ER` `AVX512PF`\n\n`SSE` `SSE2` `SSE3` `SSSE3` `SSE41` `POPCNT` `SSE42` `AVX` `F16C` `FMA3`\n`AVX2` `AVX512F` `AVX512CD`\n\n`AVX512_KNM`\n\n`AVX5124FMAPS` `AVX5124VNNIW` `AVX512VPOPCNTDQ`\n\n`SSE` `SSE2` `SSE3` `SSSE3` `SSE41` `POPCNT` `SSE42` `AVX` `F16C` `FMA3`\n`AVX2` `AVX512F` `AVX512CD` `AVX512_KNL`\n\n`AVX512_SKX`\n\n`AVX512VL` `AVX512BW` `AVX512DQ`\n\n`SSE` `SSE2` `SSE3` `SSSE3` `SSE41` `POPCNT` `SSE42` `AVX` `F16C` `FMA3`\n`AVX2` `AVX512F` `AVX512CD`\n\n`AVX512_CLX`\n\n`AVX512VNNI`\n\n`SSE` `SSE2` `SSE3` `SSSE3` `SSE41` `POPCNT` `SSE42` `AVX` `F16C` `FMA3`\n`AVX2` `AVX512F` `AVX512CD` `AVX512_SKX`\n\n`AVX512_CNL`\n\n`AVX512IFMA` `AVX512VBMI`\n\n`SSE` `SSE2` `SSE3` `SSSE3` `SSE41` `POPCNT` `SSE42` `AVX` `F16C` `FMA3`\n`AVX2` `AVX512F` `AVX512CD` `AVX512_SKX`\n\n`AVX512_ICL`\n\n`AVX512VBMI2` `AVX512BITALG` `AVX512VPOPCNTDQ`\n\n`SSE` `SSE2` `SSE3` `SSSE3` `SSE41` `POPCNT` `SSE42` `AVX` `F16C` `FMA3`\n`AVX2` `AVX512F` `AVX512CD` `AVX512_SKX` `AVX512_CLX` `AVX512_CNL`\n\nName\n\nImplies\n\n`VSX`\n\n`VSX2`\n\n`VSX`\n\n`VSX3`\n\n`VSX` `VSX2`\n\nName\n\nImplies\n\n`VSX`\n\n`VSX2`\n\n`VSX2`\n\n`VSX`\n\n`VSX3`\n\n`VSX` `VSX2`\n\nName\n\nImplies\n\n`NEON`\n\n`NEON_FP16`\n\n`NEON`\n\n`NEON_VFPV4`\n\n`NEON` `NEON_FP16`\n\n`ASIMD`\n\n`NEON` `NEON_FP16` `NEON_VFPV4`\n\n`ASIMDHP`\n\n`NEON` `NEON_FP16` `NEON_VFPV4` `ASIMD`\n\n`ASIMDDP`\n\n`NEON` `NEON_FP16` `NEON_VFPV4` `ASIMD`\n\n`ASIMDFHM`\n\n`NEON` `NEON_FP16` `NEON_VFPV4` `ASIMD` `ASIMDHP`\n\nName\n\nImplies\n\n`NEON`\n\n`NEON_FP16` `NEON_VFPV4` `ASIMD`\n\n`NEON_FP16`\n\n`NEON` `NEON_VFPV4` `ASIMD`\n\n`NEON_VFPV4`\n\n`NEON` `NEON_FP16` `ASIMD`\n\n`ASIMD`\n\n`NEON` `NEON_FP16` `NEON_VFPV4`\n\n`ASIMDHP`\n\n`NEON` `NEON_FP16` `NEON_VFPV4` `ASIMD`\n\n`ASIMDDP`\n\n`NEON` `NEON_FP16` `NEON_VFPV4` `ASIMD`\n\n`ASIMDFHM`\n\n`NEON` `NEON_FP16` `NEON_VFPV4` `ASIMD` `ASIMDHP`\n\nWhile the above tables are based on the GCC Compiler, the following tables\nshowing the differences in the other compilers:\n\nName\n\nImplies\n\n`FMA3`\n\n`SSE` `SSE2` `SSE3` `SSSE3` `SSE41` `POPCNT` `SSE42` `AVX` `F16C` AVX2\n\n`AVX2`\n\n`SSE` `SSE2` `SSE3` `SSSE3` `SSE41` `POPCNT` `SSE42` `AVX` `F16C` FMA3\n\n`AVX512F`\n\n`SSE` `SSE2` `SSE3` `SSSE3` `SSE41` `POPCNT` `SSE42` `AVX` `F16C` `FMA3`\n`AVX2` AVX512CD\n\nNote\n\nThe following features aren\u2019t supported by x86::Intel Compiler: XOP FMA4\n\nName\n\nImplies\n\n`FMA3`\n\n`SSE` `SSE2` `SSE3` `SSSE3` `SSE41` `POPCNT` `SSE42` `AVX` `F16C` AVX2\n\n`AVX2`\n\n`SSE` `SSE2` `SSE3` `SSSE3` `SSE41` `POPCNT` `SSE42` `AVX` `F16C` FMA3\n\n`AVX512F`\n\n`SSE` `SSE2` `SSE3` `SSSE3` `SSE41` `POPCNT` `SSE42` `AVX` `F16C` `FMA3`\n`AVX2` AVX512CD AVX512_SKX\n\n`AVX512CD`\n\n`SSE` `SSE2` `SSE3` `SSSE3` `SSE41` `POPCNT` `SSE42` `AVX` `F16C` `FMA3`\n`AVX2` `AVX512F` AVX512_SKX\n\nNote\n\nThe following features aren\u2019t supported by x86::Microsoft Visual C/C++:\nAVX512_KNL AVX512_KNM\n\nmachine, this operation is based on the compiler flags (`-march=native,\n-xHost, /QxHost`)\n\n`MIN`: Enables the minimum CPU features that can safely run on a wide range of\nplatforms:\n\nFor Arch\n\nReturns\n\n`x86`\n\n`SSE` `SSE2`\n\n`x86` `64-bit mode`\n\n`SSE` `SSE2` `SSE3`\n\n`IBM/POWER` `big-endian mode`\n\n`NONE`\n\n`IBM/POWER` `little-endian mode`\n\n`VSX` `VSX2`\n\n`ARMHF`\n\n`NONE`\n\n`ARM64` `AARCH64`\n\n`NEON` `NEON_FP16` `NEON_VFPV4` `ASIMD`\n\nInterrelated CPU features: Some exceptional conditions force us to link some\nfeatures together when it come to certain compilers or architectures,\nresulting in the impossibility of building them separately. These conditions\ncan be divided into two parts, as follows:\n\nArchitectural compatibility: The need to align certain CPU features that are\nassured to be supported by successive generations of the same architecture,\nfor example:\n\nNumPy dispatcher is based on multi-source compiling, which means taking a\ncertain source and compiling it multiple times with different compiler flags\nand also with different C definitions that affect the code paths to enable\ncertain instruction-sets for each compiled object depending on the required\noptimizations, then combining the returned objects together.\n\nThis mechanism should support all compilers and it doesn\u2019t require any\ncompiler-specific extension, but at the same time it is adds a few steps to\nnormal compilation that are explained as follows:\n\nConfiguring the required optimization by the user before starting to build the\nsource files via the two command arguments as explained above:\n\nIn this part, we check the compiler and platform architecture and cache some\nof the intermediary results to speed up rebuilding.\n\nBy testing them against the compiler, and seeing what the compiler can support\naccording to the requested optimizations.\n\nThe generated header `_cpu_dispatch.h` contains all the definitions and\nheaders of instruction-sets for the required optimizations that have been\nvalidated during the previous step.\n\nIt also contains extra C definitions that are used for defining NumPy\u2019s\nPython-level module attributes `__cpu_baseline__` and `__cpu_dispa\u064dtch__`.\n\nWhat is in this header?\n\nThe example header was dynamically generated by gcc on an X86 machine. The\ncompiler supports `--cpu-baseline=\"sse sse2 sse3\"` and `--cpu-dispatch=\"ssse3\nsse41\"`, and the result is below.\n\nBaseline features are the minimal set of required optimizations configured via\n`--cpu-baseline`. They have no preprocessor guards and they\u2019re always on,\nwhich means they can be used in any source.\n\nDoes this mean NumPy\u2019s infrastructure passes the compiler\u2019s flags of baseline\nfeatures to all sources?\n\nDefinitely, yes. But the dispatch-able sources are treated differently.\n\nWhat if the user specifies certain baseline features during the build but at\nruntime the machine doesn\u2019t support even these features? Will the compiled\ncode be called via one of these definitions, or maybe the compiler itself\nauto-generated/vectorized certain piece of code based on the provided command\nline compiler flags?\n\nDuring the loading of the NumPy module, there\u2019s a validation step which\ndetects this behavior. It will raise a Python runtime error to inform the\nuser. This is to prevent the CPU reaching an illegal instruction error causing\na segfault.\n\nDispatch-able features are our dispatched set of additional optimizations that\nwere configured via `--cpu-dispatch`. They are not activated by default and\nare always guarded by other C definitions prefixed with `NPY__CPU_TARGET_`. C\ndefinitions `NPY__CPU_TARGET_` are only enabled within dispatch-able sources.\n\nDispatch-able sources are special C files that can be compiled multiple times\nwith different compiler flags and also with different C definitions. These\naffect code paths to enable certain instruction-sets for each compiled object\naccording to \u201cthe configuration statements\u201d that must be declared between a C\ncomment`(/**/)` and start with a special mark @targets at the top of each\ndispatch-able source. At the same time, dispatch-able sources will be treated\nas normal C sources if the optimization was disabled by the command argument\n`--disable-optimization` .\n\nWhat are configuration statements?\n\nConfiguration statements are sort of keywords combined together to determine\nthe required optimization for the dispatch-able source.\n\nExample:\n\nThe keywords mainly represent the additional optimizations configured through\n`--cpu-dispatch`, but it can also represent other options such as:\n\nNumpy\u2019s infrastructure handles dispatch-able sources in four steps:\n\n(C) Wrapping: This is the approach taken by NumPy\u2019s infrastructure, which has\nproved to be sufficiently flexible in order to compile a single source\nmultiple times with different C definitions and flags that affect the code\npaths. The process is achieved by creating a temporary C source for each\nrequired optimization that related to the additional optimization, which\ncontains the declarations of the C definitions and includes the involved\nsource via the C directive #include. For more clarification take a look at the\nfollowing code for AVX512F :\n\n(D) Dispatch-able configuration header: The infrastructure generates a config\nheader for each dispatch-able source, this header mainly contains two abstract\nC macros used for identifying the generated objects, so they can be used for\nruntime dispatching certain symbols from the generated objects by any C\nsource. It is also used for forward declarations.\n\nThe generated header takes the name of the dispatch-able source after\nexcluding the extension and replace it with \u2018.h\u2019, for example assume we have a\ndispatch-able source called hello.dispatch.c and contains the following:\n\nNow assume you attached hello.dispatch.c to the source tree, then the\ninfrastructure should generate a temporary config header called\nhello.dispatch.h that can be reached by any source in the source tree, and it\nshould contain the following code :\n\nAn example of using the config header in light of the above:\n\n"}, {"name": "ndarray.__abs__()", "path": "reference/generated/numpy.ndarray.__abs__", "type": "numpy.ndarray.__abs__", "text": "\nmethod\n\n"}, {"name": "ndarray.__add__()", "path": "reference/generated/numpy.ndarray.__add__", "type": "numpy.ndarray.__add__", "text": "\nmethod\n\nReturn self+value.\n\n"}, {"name": "ndarray.__and__()", "path": "reference/generated/numpy.ndarray.__and__", "type": "numpy.ndarray.__and__", "text": "\nmethod\n\nReturn self&value.\n\n"}, {"name": "ndarray.__array__()", "path": "reference/generated/numpy.ndarray.__array__", "type": "numpy.ndarray.__array__", "text": "\nmethod\n\nReturns either a new reference to self if dtype is not given or a new array of\nprovided data type if dtype is different from the current dtype of the array.\n\n"}, {"name": "ndarray.__array_wrap__()", "path": "reference/generated/numpy.ndarray.__array_wrap__", "type": "numpy.ndarray.__array_wrap__", "text": "\nmethod\n\nReturns a view of `array` with the same type as self.\n\n"}, {"name": "ndarray.__bool__()", "path": "reference/generated/numpy.ndarray.__bool__", "type": "numpy.ndarray.__bool__", "text": "\nmethod\n\nself != 0\n\n"}, {"name": "ndarray.__class_getitem__()", "path": "reference/generated/numpy.ndarray.__class_getitem__", "type": "numpy.ndarray.__class_getitem__", "text": "\nmethod\n\nReturn a parametrized wrapper around the `ndarray` type.\n\nNew in version 1.22.\n\nA parametrized `ndarray` type.\n\nSee also\n\nType hinting generics in standard collections.\n\nAn ndarray alias generic w.r.t. its `dtype.type`.\n\nThis method is only available for python 3.9 and later.\n\n"}, {"name": "ndarray.__complex__()", "path": "reference/generated/numpy.ndarray.__complex__", "type": "numpy.ndarray.__complex__", "text": "\nmethod\n\n"}, {"name": "ndarray.__contains__()", "path": "reference/generated/numpy.ndarray.__contains__", "type": "numpy.ndarray.__contains__", "text": "\nmethod\n\nReturn key in self.\n\n"}, {"name": "ndarray.__copy__()", "path": "reference/generated/numpy.ndarray.__copy__", "type": "numpy.ndarray.__copy__", "text": "\nmethod\n\nUsed if `copy.copy` is called on an array. Returns a copy of the array.\n\nEquivalent to `a.copy(order='K')`.\n\n"}, {"name": "ndarray.__deepcopy__()", "path": "reference/generated/numpy.ndarray.__deepcopy__", "type": "numpy.ndarray.__deepcopy__", "text": "\nmethod\n\nUsed if `copy.deepcopy` is called on an array.\n\n"}, {"name": "ndarray.__divmod__()", "path": "reference/generated/numpy.ndarray.__divmod__", "type": "numpy.ndarray.__divmod__", "text": "\nmethod\n\nReturn divmod(self, value).\n\n"}, {"name": "ndarray.__eq__()", "path": "reference/generated/numpy.ndarray.__eq__", "type": "numpy.ndarray.__eq__", "text": "\nmethod\n\nReturn self==value.\n\n"}, {"name": "ndarray.__float__()", "path": "reference/generated/numpy.ndarray.__float__", "type": "numpy.ndarray.__float__", "text": "\nmethod\n\n"}, {"name": "ndarray.__floordiv__()", "path": "reference/generated/numpy.ndarray.__floordiv__", "type": "numpy.ndarray.__floordiv__", "text": "\nmethod\n\nReturn self//value.\n\n"}, {"name": "ndarray.__ge__()", "path": "reference/generated/numpy.ndarray.__ge__", "type": "numpy.ndarray.__ge__", "text": "\nmethod\n\nReturn self>=value.\n\n"}, {"name": "ndarray.__getitem__()", "path": "reference/generated/numpy.ndarray.__getitem__", "type": "numpy.ndarray.__getitem__", "text": "\nmethod\n\nReturn self[key].\n\n"}, {"name": "ndarray.__gt__()", "path": "reference/generated/numpy.ndarray.__gt__", "type": "numpy.ndarray.__gt__", "text": "\nmethod\n\nReturn self>value.\n\n"}, {"name": "ndarray.__iadd__()", "path": "reference/generated/numpy.ndarray.__iadd__", "type": "numpy.ndarray.__iadd__", "text": "\nmethod\n\nReturn self+=value.\n\n"}, {"name": "ndarray.__iand__()", "path": "reference/generated/numpy.ndarray.__iand__", "type": "numpy.ndarray.__iand__", "text": "\nmethod\n\nReturn self&=value.\n\n"}, {"name": "ndarray.__ifloordiv__()", "path": "reference/generated/numpy.ndarray.__ifloordiv__", "type": "numpy.ndarray.__ifloordiv__", "text": "\nmethod\n\nReturn self//=value.\n\n"}, {"name": "ndarray.__ilshift__()", "path": "reference/generated/numpy.ndarray.__ilshift__", "type": "numpy.ndarray.__ilshift__", "text": "\nmethod\n\nReturn self<<=value.\n\n"}, {"name": "ndarray.__imod__()", "path": "reference/generated/numpy.ndarray.__imod__", "type": "numpy.ndarray.__imod__", "text": "\nmethod\n\nReturn self%=value.\n\n"}, {"name": "ndarray.__imul__()", "path": "reference/generated/numpy.ndarray.__imul__", "type": "numpy.ndarray.__imul__", "text": "\nmethod\n\nReturn self*=value.\n\n"}, {"name": "ndarray.__int__()", "path": "reference/generated/numpy.ndarray.__int__", "type": "numpy.ndarray.__int__", "text": "\nmethod\n\n"}, {"name": "ndarray.__invert__()", "path": "reference/generated/numpy.ndarray.__invert__", "type": "numpy.ndarray.__invert__", "text": "\nmethod\n\n~self\n\n"}, {"name": "ndarray.__ior__()", "path": "reference/generated/numpy.ndarray.__ior__", "type": "numpy.ndarray.__ior__", "text": "\nmethod\n\nReturn self|=value.\n\n"}, {"name": "ndarray.__ipow__()", "path": "reference/generated/numpy.ndarray.__ipow__", "type": "numpy.ndarray.__ipow__", "text": "\nmethod\n\nReturn self**=value.\n\n"}, {"name": "ndarray.__irshift__()", "path": "reference/generated/numpy.ndarray.__irshift__", "type": "numpy.ndarray.__irshift__", "text": "\nmethod\n\nReturn self>>=value.\n\n"}, {"name": "ndarray.__isub__()", "path": "reference/generated/numpy.ndarray.__isub__", "type": "numpy.ndarray.__isub__", "text": "\nmethod\n\nReturn self-=value.\n\n"}, {"name": "ndarray.__itruediv__()", "path": "reference/generated/numpy.ndarray.__itruediv__", "type": "numpy.ndarray.__itruediv__", "text": "\nmethod\n\nReturn self/=value.\n\n"}, {"name": "ndarray.__ixor__()", "path": "reference/generated/numpy.ndarray.__ixor__", "type": "numpy.ndarray.__ixor__", "text": "\nmethod\n\nReturn self^=value.\n\n"}, {"name": "ndarray.__le__()", "path": "reference/generated/numpy.ndarray.__le__", "type": "numpy.ndarray.__le__", "text": "\nmethod\n\nReturn self<=value.\n\n"}, {"name": "ndarray.__len__()", "path": "reference/generated/numpy.ndarray.__len__", "type": "numpy.ndarray.__len__", "text": "\nmethod\n\nReturn len(self).\n\n"}, {"name": "ndarray.__lshift__()", "path": "reference/generated/numpy.ndarray.__lshift__", "type": "numpy.ndarray.__lshift__", "text": "\nmethod\n\nReturn self<<value.\n\n"}, {"name": "ndarray.__lt__()", "path": "reference/generated/numpy.ndarray.__lt__", "type": "numpy.ndarray.__lt__", "text": "\nmethod\n\nReturn self<value.\n\n"}, {"name": "ndarray.__matmul__()", "path": "reference/generated/numpy.ndarray.__matmul__", "type": "numpy.ndarray.__matmul__", "text": "\nmethod\n\nReturn self@value.\n\n"}, {"name": "ndarray.__mod__()", "path": "reference/generated/numpy.ndarray.__mod__", "type": "numpy.ndarray.__mod__", "text": "\nmethod\n\nReturn self%value.\n\n"}, {"name": "ndarray.__mul__()", "path": "reference/generated/numpy.ndarray.__mul__", "type": "numpy.ndarray.__mul__", "text": "\nmethod\n\nReturn self*value.\n\n"}, {"name": "ndarray.__ne__()", "path": "reference/generated/numpy.ndarray.__ne__", "type": "numpy.ndarray.__ne__", "text": "\nmethod\n\nReturn self!=value.\n\n"}, {"name": "ndarray.__neg__()", "path": "reference/generated/numpy.ndarray.__neg__", "type": "numpy.ndarray.__neg__", "text": "\nmethod\n\n-self\n\n"}, {"name": "ndarray.__new__()", "path": "reference/generated/numpy.ndarray.__new__", "type": "numpy.ndarray.__new__", "text": "\nmethod\n\n"}, {"name": "ndarray.__or__()", "path": "reference/generated/numpy.ndarray.__or__", "type": "numpy.ndarray.__or__", "text": "\nmethod\n\nReturn self|value.\n\n"}, {"name": "ndarray.__pos__()", "path": "reference/generated/numpy.ndarray.__pos__", "type": "numpy.ndarray.__pos__", "text": "\nmethod\n\n+self\n\n"}, {"name": "ndarray.__pow__()", "path": "reference/generated/numpy.ndarray.__pow__", "type": "numpy.ndarray.__pow__", "text": "\nmethod\n\nReturn pow(self, value, mod).\n\n"}, {"name": "ndarray.__reduce__()", "path": "reference/generated/numpy.ndarray.__reduce__", "type": "numpy.ndarray.__reduce__", "text": "\nmethod\n\nFor pickling.\n\n"}, {"name": "ndarray.__repr__()", "path": "reference/generated/numpy.ndarray.__repr__", "type": "numpy.ndarray.__repr__", "text": "\nmethod\n\nReturn repr(self).\n\n"}, {"name": "ndarray.__rshift__()", "path": "reference/generated/numpy.ndarray.__rshift__", "type": "numpy.ndarray.__rshift__", "text": "\nmethod\n\nReturn self>>value.\n\n"}, {"name": "ndarray.__setitem__()", "path": "reference/generated/numpy.ndarray.__setitem__", "type": "numpy.ndarray.__setitem__", "text": "\nmethod\n\nSet self[key] to value.\n\n"}, {"name": "ndarray.__setstate__()", "path": "reference/generated/numpy.ndarray.__setstate__", "type": "numpy.ndarray.__setstate__", "text": "\nmethod\n\nFor unpickling.\n\nThe `state` argument must be a sequence that contains the following elements:\n\noptional pickle version. If omitted defaults to 0.\n\na binary string with the data (or a list if \u2018a\u2019 is an object array)\n\n"}, {"name": "ndarray.__str__()", "path": "reference/generated/numpy.ndarray.__str__", "type": "numpy.ndarray.__str__", "text": "\nmethod\n\nReturn str(self).\n\n"}, {"name": "ndarray.__sub__()", "path": "reference/generated/numpy.ndarray.__sub__", "type": "numpy.ndarray.__sub__", "text": "\nmethod\n\nReturn self-value.\n\n"}, {"name": "ndarray.__truediv__()", "path": "reference/generated/numpy.ndarray.__truediv__", "type": "numpy.ndarray.__truediv__", "text": "\nmethod\n\nReturn self/value.\n\n"}, {"name": "ndarray.__xor__()", "path": "reference/generated/numpy.ndarray.__xor__", "type": "numpy.ndarray.__xor__", "text": "\nmethod\n\nReturn self^value.\n\n"}, {"name": "ndarray.all()", "path": "reference/generated/numpy.ndarray.all", "type": "numpy.ndarray.all", "text": "\nmethod\n\nReturns True if all elements evaluate to True.\n\nRefer to `numpy.all` for full documentation.\n\nSee also\n\nequivalent function\n\n"}, {"name": "ndarray.any()", "path": "reference/generated/numpy.ndarray.any", "type": "numpy.ndarray.any", "text": "\nmethod\n\nReturns True if any of the elements of `a` evaluate to True.\n\nRefer to `numpy.any` for full documentation.\n\nSee also\n\nequivalent function\n\n"}, {"name": "ndarray.argmax()", "path": "reference/generated/numpy.ndarray.argmax", "type": "numpy.ndarray.argmax", "text": "\nmethod\n\nReturn indices of the maximum values along the given axis.\n\nRefer to `numpy.argmax` for full documentation.\n\nSee also\n\nequivalent function\n\n"}, {"name": "ndarray.argmin()", "path": "reference/generated/numpy.ndarray.argmin", "type": "numpy.ndarray.argmin", "text": "\nmethod\n\nReturn indices of the minimum values along the given axis.\n\nRefer to `numpy.argmin` for detailed documentation.\n\nSee also\n\nequivalent function\n\n"}, {"name": "ndarray.argpartition()", "path": "reference/generated/numpy.ndarray.argpartition", "type": "numpy.ndarray.argpartition", "text": "\nmethod\n\nReturns the indices that would partition this array.\n\nRefer to `numpy.argpartition` for full documentation.\n\nNew in version 1.8.0.\n\nSee also\n\nequivalent function\n\n"}, {"name": "ndarray.argsort()", "path": "reference/generated/numpy.ndarray.argsort", "type": "numpy.ndarray.argsort", "text": "\nmethod\n\nReturns the indices that would sort this array.\n\nRefer to `numpy.argsort` for full documentation.\n\nSee also\n\nequivalent function\n\n"}, {"name": "ndarray.astype()", "path": "reference/generated/numpy.ndarray.astype", "type": "numpy.ndarray.astype", "text": "\nmethod\n\nCopy of the array, cast to a specified type.\n\nTypecode or data-type to which the array is cast.\n\nControls the memory layout order of the result. \u2018C\u2019 means C order, \u2018F\u2019 means\nFortran order, \u2018A\u2019 means \u2018F\u2019 order if all the arrays are Fortran contiguous,\n\u2018C\u2019 order otherwise, and \u2018K\u2019 means as close to the order the array elements\nappear in memory as possible. Default is \u2018K\u2019.\n\nControls what kind of data casting may occur. Defaults to \u2018unsafe\u2019 for\nbackwards compatibility.\n\nIf True, then sub-classes will be passed-through (default), otherwise the\nreturned array will be forced to be a base-class array.\n\nBy default, astype always returns a newly allocated array. If this is set to\nfalse, and the `dtype`, `order`, and `subok` requirements are satisfied, the\ninput array is returned instead of a copy.\n\nUnless `copy` is False and the other conditions for returning the input array\nare satisfied (see description for `copy` input parameter), `arr_t` is a new\narray of the same shape as the input array, with dtype, order given by\n`dtype`, `order`.\n\nWhen casting from complex to float or int. To avoid this, one should use\n`a.real.astype(t)`.\n\nChanged in version 1.17.0: Casting between a simple data type and a structured\none is possible only for \u201cunsafe\u201d casting. Casting to multiple fields is\nallowed, but casting from multiple fields is not.\n\nChanged in version 1.9.0: Casting from numeric to string types in \u2018safe\u2019\ncasting mode requires that the string dtype length is long enough to store the\nmax integer/float value converted.\n\n"}, {"name": "ndarray.base", "path": "reference/generated/numpy.ndarray.base", "type": "numpy.ndarray.base", "text": "\nattribute\n\nBase object if memory is from some other object.\n\nThe base of an array that owns its memory is None:\n\nSlicing creates a view, whose memory is shared with x:\n\n"}, {"name": "ndarray.byteswap()", "path": "reference/generated/numpy.ndarray.byteswap", "type": "numpy.ndarray.byteswap", "text": "\nmethod\n\nSwap the bytes of the array elements\n\nToggle between low-endian and big-endian data representation by returning a\nbyteswapped array, optionally swapped in-place. Arrays of byte-strings are not\nswapped. The real and imaginary parts of a complex number are swapped\nindividually.\n\nIf `True`, swap bytes in-place, default is `False`.\n\nThe byteswapped array. If `inplace` is `True`, this is a view to self.\n\nArrays of byte-strings are not swapped\n\nbut different representation in memory\n\n"}, {"name": "ndarray.choose()", "path": "reference/generated/numpy.ndarray.choose", "type": "numpy.ndarray.choose", "text": "\nmethod\n\nUse an index array to construct a new array from a set of choices.\n\nRefer to `numpy.choose` for full documentation.\n\nSee also\n\nequivalent function\n\n"}, {"name": "ndarray.clip()", "path": "reference/generated/numpy.ndarray.clip", "type": "numpy.ndarray.clip", "text": "\nmethod\n\nReturn an array whose values are limited to `[min, max]`. One of max or min\nmust be given.\n\nRefer to `numpy.clip` for full documentation.\n\nSee also\n\nequivalent function\n\n"}, {"name": "ndarray.compress()", "path": "reference/generated/numpy.ndarray.compress", "type": "numpy.ndarray.compress", "text": "\nmethod\n\nReturn selected slices of this array along given axis.\n\nRefer to `numpy.compress` for full documentation.\n\nSee also\n\nequivalent function\n\n"}, {"name": "ndarray.conj()", "path": "reference/generated/numpy.ndarray.conj", "type": "numpy.ndarray.conj", "text": "\nmethod\n\nComplex-conjugate all elements.\n\nRefer to `numpy.conjugate` for full documentation.\n\nSee also\n\nequivalent function\n\n"}, {"name": "ndarray.conjugate()", "path": "reference/generated/numpy.ndarray.conjugate", "type": "numpy.ndarray.conjugate", "text": "\nmethod\n\nReturn the complex conjugate, element-wise.\n\nRefer to `numpy.conjugate` for full documentation.\n\nSee also\n\nequivalent function\n\n"}, {"name": "ndarray.copy()", "path": "reference/generated/numpy.ndarray.copy", "type": "numpy.ndarray.copy", "text": "\nmethod\n\nReturn a copy of the array.\n\nControls the memory layout of the copy. \u2018C\u2019 means C-order, \u2018F\u2019 means F-order,\n\u2018A\u2019 means \u2018F\u2019 if `a` is Fortran contiguous, \u2018C\u2019 otherwise. \u2018K\u2019 means match the\nlayout of `a` as closely as possible. (Note that this function and\n`numpy.copy` are very similar but have different default values for their\norder= arguments, and this function always passes sub-classes through.)\n\nSee also\n\nSimilar function with different default behavior\n\nThis function is the preferred method for creating an array copy. The function\n`numpy.copy` is similar, but it defaults to using order \u2018K\u2019, and will not pass\nsub-classes through by default.\n\n"}, {"name": "ndarray.ctypes", "path": "reference/generated/numpy.ndarray.ctypes", "type": "numpy.ndarray.ctypes", "text": "\nattribute\n\nAn object to simplify the interaction of the array with the ctypes module.\n\nThis attribute creates an object that makes it easier to use arrays when\ncalling shared libraries with the ctypes module. The returned object has,\namong others, data, shape, and strides attributes (see Notes below) which\nthemselves return ctypes objects that can be used as arguments to a shared\nlibrary.\n\nPossessing attributes data, shape, strides, etc.\n\nSee also\n\nBelow are the public attributes of this object which were documented in \u201cGuide\nto NumPy\u201d (we have omitted undocumented public attributes, as well as\ndocumented private attributes):\n\nA pointer to the memory area of the array as a Python integer. This memory\narea may contain data that is not aligned, or not in correct byte-order. The\nmemory area may not even be writeable. The array flags and data-type of this\narray should be respected when passing this attribute to arbitrary C-code to\navoid trouble that can include Python crashing. User Beware! The value of this\nattribute is exactly the same as `self._array_interface_['data'][0]`.\n\nNote that unlike `data_as`, a reference will not be kept to the array: code\nlike `ctypes.c_void_p((a + b).ctypes.data)` will result in a pointer to a\ndeallocated array, and should be spelt `(a +\nb).ctypes.data_as(ctypes.c_void_p)`\n\n(c_intp*self.ndim): A ctypes array of length self.ndim where the basetype is\nthe C-integer corresponding to `dtype('p')` on this platform (see `c_intp`).\nThis base-type could be `ctypes.c_int`, `ctypes.c_long`, or\n`ctypes.c_longlong` depending on the platform. The ctypes array contains the\nshape of the underlying array.\n\n(c_intp*self.ndim): A ctypes array of length self.ndim where the basetype is\nthe same as for the shape attribute. This ctypes array contains the strides\ninformation from the underlying array. This strides information is important\nfor showing how many bytes must be jumped to get to the next element in the\narray.\n\nReturn the data pointer cast to a particular c-types object. For example,\ncalling `self._as_parameter_` is equivalent to\n`self.data_as(ctypes.c_void_p)`. Perhaps you want to use the data as a pointer\nto a ctypes array of floating-point data:\n`self.data_as(ctypes.POINTER(ctypes.c_double))`.\n\nThe returned pointer will keep a reference to the array.\n\nReturn the shape tuple as an array of some other c-types type. For example:\n`self.shape_as(ctypes.c_short)`.\n\nReturn the strides tuple as an array of some other c-types type. For example:\n`self.strides_as(ctypes.c_longlong)`.\n\nIf the ctypes module is not available, then the ctypes attribute of array\nobjects still returns something useful, but ctypes objects are not returned\nand errors may be raised instead. In particular, the object will still have\nthe `as_parameter` attribute which will return an integer equal to the data\nattribute.\n\n"}, {"name": "ndarray.cumprod()", "path": "reference/generated/numpy.ndarray.cumprod", "type": "numpy.ndarray.cumprod", "text": "\nmethod\n\nReturn the cumulative product of the elements along the given axis.\n\nRefer to `numpy.cumprod` for full documentation.\n\nSee also\n\nequivalent function\n\n"}, {"name": "ndarray.cumsum()", "path": "reference/generated/numpy.ndarray.cumsum", "type": "numpy.ndarray.cumsum", "text": "\nmethod\n\nReturn the cumulative sum of the elements along the given axis.\n\nRefer to `numpy.cumsum` for full documentation.\n\nSee also\n\nequivalent function\n\n"}, {"name": "ndarray.data", "path": "reference/generated/numpy.ndarray.data", "type": "numpy.ndarray.data", "text": "\nattribute\n\nPython buffer object pointing to the start of the array\u2019s data.\n\n"}, {"name": "ndarray.diagonal()", "path": "reference/generated/numpy.ndarray.diagonal", "type": "numpy.ndarray.diagonal", "text": "\nmethod\n\nReturn specified diagonals. In NumPy 1.9 the returned array is a read-only\nview instead of a copy as in previous NumPy versions. In a future version the\nread-only restriction will be removed.\n\nRefer to `numpy.diagonal` for full documentation.\n\nSee also\n\nequivalent function\n\n"}, {"name": "ndarray.dtype", "path": "reference/generated/numpy.ndarray.dtype", "type": "numpy.ndarray.dtype", "text": "\nattribute\n\nData-type of the array\u2019s elements.\n\nSee also\n\n"}, {"name": "ndarray.dump()", "path": "reference/generated/numpy.ndarray.dump", "type": "numpy.ndarray.dump", "text": "\nmethod\n\nDump a pickle of the array to the specified file. The array can be read back\nwith pickle.load or numpy.load.\n\nA string naming the dump file.\n\nChanged in version 1.17.0: `pathlib.Path` objects are now accepted.\n\n"}, {"name": "ndarray.dumps()", "path": "reference/generated/numpy.ndarray.dumps", "type": "numpy.ndarray.dumps", "text": "\nmethod\n\nReturns the pickle of the array as a string. pickle.loads will convert the\nstring back to an array.\n\n"}, {"name": "ndarray.fill()", "path": "reference/generated/numpy.ndarray.fill", "type": "numpy.ndarray.fill", "text": "\nmethod\n\nFill the array with a scalar value.\n\nAll elements of `a` will be assigned this value.\n\n"}, {"name": "ndarray.flags", "path": "reference/generated/numpy.ndarray.flags", "type": "numpy.ndarray.flags", "text": "\nattribute\n\nInformation about the memory layout of the array.\n\nThe `flags` object can be accessed dictionary-like (as in\n`a.flags['WRITEABLE']`), or by using lowercased attribute names (as in\n`a.flags.writeable`). Short flag names are only supported in dictionary\naccess.\n\nOnly the WRITEBACKIFCOPY, UPDATEIFCOPY, WRITEABLE, and ALIGNED flags can be\nchanged by the user, via direct assignment to the attribute or dictionary\nentry, or by calling `ndarray.setflags`.\n\nThe array flags cannot be set arbitrarily:\n\nArrays can be both C-style and Fortran-style contiguous simultaneously. This\nis clear for 1-dimensional arrays, but can also be true for higher dimensional\narrays.\n\nEven for contiguous arrays a stride for a given dimension `arr.strides[dim]`\nmay be arbitrary if `arr.shape[dim] == 1` or the array has no elements. It\ndoes not generally hold that `self.strides[-1] == self.itemsize` for C-style\ncontiguous arrays or `self.strides[0] == self.itemsize` for Fortran-style\ncontiguous arrays is true.\n\nThe data is in a single, C-style contiguous segment.\n\nThe data is in a single, Fortran-style contiguous segment.\n\nThe array owns the memory it uses or borrows it from another object.\n\nThe data area can be written to. Setting this to False locks the data, making\nit read-only. A view (slice, etc.) inherits WRITEABLE from its base array at\ncreation time, but a view of a writeable array may be subsequently locked\nwhile the base array remains writeable. (The opposite is not true, in that a\nview of a locked array may not be made writeable. However, currently, locking\na base object does not lock any views that already reference it, so under that\ncircumstance it is possible to alter the contents of a locked array via a\npreviously created writeable view onto it.) Attempting to change a non-\nwriteable array raises a RuntimeError exception.\n\nThe data and all elements are aligned appropriately for the hardware.\n\nThis array is a copy of some other array. The C-API function\nPyArray_ResolveWritebackIfCopy must be called before deallocating to the base\narray will be updated with the contents of this array.\n\n(Deprecated, use WRITEBACKIFCOPY) This array is a copy of some other array.\nWhen this array is deallocated, the base array will be updated with the\ncontents of this array.\n\nF_CONTIGUOUS and not C_CONTIGUOUS.\n\nF_CONTIGUOUS or C_CONTIGUOUS (one-segment test).\n\nALIGNED and WRITEABLE.\n\nBEHAVED and C_CONTIGUOUS.\n\nBEHAVED and F_CONTIGUOUS and not C_CONTIGUOUS.\n\n"}, {"name": "ndarray.flat", "path": "reference/generated/numpy.ndarray.flat", "type": "numpy.ndarray.flat", "text": "\nattribute\n\nA 1-D iterator over the array.\n\nThis is a `numpy.flatiter` instance, which acts similarly to, but is not a\nsubclass of, Python\u2019s built-in iterator object.\n\nSee also\n\nReturn a copy of the array collapsed into one dimension.\n\nAn assignment example:\n\n"}, {"name": "ndarray.flatten()", "path": "reference/generated/numpy.ndarray.flatten", "type": "numpy.ndarray.flatten", "text": "\nmethod\n\nReturn a copy of the array collapsed into one dimension.\n\n\u2018C\u2019 means to flatten in row-major (C-style) order. \u2018F\u2019 means to flatten in\ncolumn-major (Fortran- style) order. \u2018A\u2019 means to flatten in column-major\norder if `a` is Fortran contiguous in memory, row-major order otherwise. \u2018K\u2019\nmeans to flatten `a` in the order the elements occur in memory. The default is\n\u2018C\u2019.\n\nA copy of the input array, flattened to one dimension.\n\nSee also\n\nReturn a flattened array.\n\nA 1-D flat iterator over the array.\n\n"}, {"name": "ndarray.getfield()", "path": "reference/generated/numpy.ndarray.getfield", "type": "numpy.ndarray.getfield", "text": "\nmethod\n\nReturns a field of the given array as a certain type.\n\nA field is a view of the array data with a given data-type. The values in the\nview are determined by the given type and the offset into the current array in\nbytes. The offset needs to be such that the view dtype fits in the array\ndtype; for example an array of dtype complex128 has 16-byte elements. If\ntaking a view with a 32-bit integer (4 bytes), the offset needs to be between\n0 and 12 bytes.\n\nThe data type of the view. The dtype size of the view can not be larger than\nthat of the array itself.\n\nNumber of bytes to skip before beginning the element view.\n\nBy choosing an offset of 8 bytes we can select the complex part of the array\nfor our view:\n\n"}, {"name": "ndarray.imag", "path": "reference/generated/numpy.ndarray.imag", "type": "numpy.ndarray.imag", "text": "\nattribute\n\nThe imaginary part of the array.\n\n"}, {"name": "ndarray.item()", "path": "reference/generated/numpy.ndarray.item", "type": "numpy.ndarray.item", "text": "\nmethod\n\nCopy an element of an array to a standard Python scalar and return it.\n\nA copy of the specified element of the array as a suitable Python scalar\n\nWhen the data type of `a` is longdouble or clongdouble, item() returns a\nscalar array object because there is no available Python scalar that would not\nlose information. Void arrays return a buffer object for item(), unless fields\nare defined, in which case a tuple is returned.\n\n`item` is very similar to a[args], except, instead of an array scalar, a\nstandard Python scalar is returned. This can be useful for speeding up access\nto elements of the array and doing arithmetic on elements of the array using\nPython\u2019s optimized math.\n\n"}, {"name": "ndarray.itemset()", "path": "reference/generated/numpy.ndarray.itemset", "type": "numpy.ndarray.itemset", "text": "\nmethod\n\nInsert scalar into an array (scalar is cast to array\u2019s dtype, if possible)\n\nThere must be at least 1 argument, and define the last argument as item. Then,\n`a.itemset(*args)` is equivalent to but faster than `a[args] = item`. The item\nshould be a scalar value and `args` must select a single item in the array\n`a`.\n\nIf one argument: a scalar, only used in case `a` is of size 1. If two\narguments: the last argument is the value to be set and must be a scalar, the\nfirst argument specifies a single array element location. It is either an int\nor a tuple.\n\nCompared to indexing syntax, `itemset` provides some speed increase for\nplacing a scalar into a particular location in an `ndarray`, if you must do\nthis. However, generally this is discouraged: among other problems, it\ncomplicates the appearance of the code. Also, when using `itemset` (and\n`item`) inside a loop, be sure to assign the methods to a local variable to\navoid the attribute look-up at each loop iteration.\n\n"}, {"name": "ndarray.itemsize", "path": "reference/generated/numpy.ndarray.itemsize", "type": "numpy.ndarray.itemsize", "text": "\nattribute\n\nLength of one array element in bytes.\n\n"}, {"name": "ndarray.max()", "path": "reference/generated/numpy.ndarray.max", "type": "numpy.ndarray.max", "text": "\nmethod\n\nReturn the maximum along a given axis.\n\nRefer to `numpy.amax` for full documentation.\n\nSee also\n\nequivalent function\n\n"}, {"name": "ndarray.mean()", "path": "reference/generated/numpy.ndarray.mean", "type": "numpy.ndarray.mean", "text": "\nmethod\n\nReturns the average of the array elements along given axis.\n\nRefer to `numpy.mean` for full documentation.\n\nSee also\n\nequivalent function\n\n"}, {"name": "ndarray.min()", "path": "reference/generated/numpy.ndarray.min", "type": "numpy.ndarray.min", "text": "\nmethod\n\nReturn the minimum along a given axis.\n\nRefer to `numpy.amin` for full documentation.\n\nSee also\n\nequivalent function\n\n"}, {"name": "ndarray.nbytes", "path": "reference/generated/numpy.ndarray.nbytes", "type": "numpy.ndarray.nbytes", "text": "\nattribute\n\nTotal bytes consumed by the elements of the array.\n\nDoes not include memory consumed by non-element attributes of the array\nobject.\n\n"}, {"name": "ndarray.ndim", "path": "reference/generated/numpy.ndarray.ndim", "type": "numpy.ndarray.ndim", "text": "\nattribute\n\nNumber of array dimensions.\n\n"}, {"name": "ndarray.ndim", "path": "user/quickstart", "type": "User Guide", "text": "\nYou\u2019ll need to know a bit of Python. For a refresher, see the Python tutorial.\n\nTo work the examples, you\u2019ll need `matplotlib` installed in addition to NumPy.\n\nLearner profile\n\nThis is a quick overview of arrays in NumPy. It demonstrates how n-dimensional\n(\\\\(n>=2\\\\)) arrays are represented and can be manipulated. In particular, if\nyou don\u2019t know how to apply common functions to n-dimensional arrays (without\nusing for-loops), or if you want to understand axis and shape properties for\nn-dimensional arrays, this article might be of help.\n\nLearning Objectives\n\nAfter reading, you should be able to:\n\nNumPy\u2019s main object is the homogeneous multidimensional array. It is a table\nof elements (usually numbers), all of the same type, indexed by a tuple of\nnon-negative integers. In NumPy dimensions are called axes.\n\nFor example, the array for the coordinates of a point in 3D space, `[1, 2,\n1]`, has one axis. That axis has 3 elements in it, so we say it has a length\nof 3. In the example pictured below, the array has 2 axes. The first axis has\na length of 2, the second axis has a length of 3.\n\nNumPy\u2019s array class is called `ndarray`. It is also known by the alias\n`array`. Note that `numpy.array` is not the same as the Standard Python\nLibrary class `array.array`, which only handles one-dimensional arrays and\noffers less functionality. The more important attributes of an `ndarray`\nobject are:\n\nthe number of axes (dimensions) of the array.\n\nthe dimensions of the array. This is a tuple of integers indicating the size\nof the array in each dimension. For a matrix with n rows and m columns,\n`shape` will be `(n,m)`. The length of the `shape` tuple is therefore the\nnumber of axes, `ndim`.\n\nthe total number of elements of the array. This is equal to the product of the\nelements of `shape`.\n\nan object describing the type of the elements in the array. One can create or\nspecify dtype\u2019s using standard Python types. Additionally NumPy provides types\nof its own. numpy.int32, numpy.int16, and numpy.float64 are some examples.\n\nthe size in bytes of each element of the array. For example, an array of\nelements of type `float64` has `itemsize` 8 (=64/8), while one of type\n`complex32` has `itemsize` 4 (=32/8). It is equivalent to\n`ndarray.dtype.itemsize`.\n\nthe buffer containing the actual elements of the array. Normally, we won\u2019t\nneed to use this attribute because we will access the elements in an array\nusing indexing facilities.\n\nThere are several ways to create arrays.\n\nFor example, you can create an array from a regular Python list or tuple using\nthe `array` function. The type of the resulting array is deduced from the type\nof the elements in the sequences.\n\nA frequent error consists in calling `array` with multiple arguments, rather\nthan providing a single sequence as an argument.\n\n`array` transforms sequences of sequences into two-dimensional arrays,\nsequences of sequences of sequences into three-dimensional arrays, and so on.\n\nThe type of the array can also be explicitly specified at creation time:\n\nOften, the elements of an array are originally unknown, but its size is known.\nHence, NumPy offers several functions to create arrays with initial\nplaceholder content. These minimize the necessity of growing arrays, an\nexpensive operation.\n\nThe function `zeros` creates an array full of zeros, the function `ones`\ncreates an array full of ones, and the function `empty` creates an array whose\ninitial content is random and depends on the state of the memory. By default,\nthe dtype of the created array is `float64`, but it can be specified via the\nkey word argument `dtype`.\n\nTo create sequences of numbers, NumPy provides the `arange` function which is\nanalogous to the Python built-in `range`, but returns an array.\n\nWhen `arange` is used with floating point arguments, it is generally not\npossible to predict the number of elements obtained, due to the finite\nfloating point precision. For this reason, it is usually better to use the\nfunction `linspace` that receives as an argument the number of elements that\nwe want, instead of the step:\n\nSee also\n\n`array`, `zeros`, `zeros_like`, `ones`, `ones_like`, `empty`, `empty_like`,\n`arange`, `linspace`, `numpy.random.Generator.rand`,\n`numpy.random.Generator.randn`, `fromfunction`, `fromfile`\n\nWhen you print an array, NumPy displays it in a similar way to nested lists,\nbut with the following layout:\n\nOne-dimensional arrays are then printed as rows, bidimensionals as matrices\nand tridimensionals as lists of matrices.\n\nSee below to get more details on `reshape`.\n\nIf an array is too large to be printed, NumPy automatically skips the central\npart of the array and only prints the corners:\n\nTo disable this behaviour and force NumPy to print the entire array, you can\nchange the printing options using `set_printoptions`.\n\nArithmetic operators on arrays apply elementwise. A new array is created and\nfilled with the result.\n\nUnlike in many matrix languages, the product operator `*` operates elementwise\nin NumPy arrays. The matrix product can be performed using the `@` operator\n(in python >=3.5) or the `dot` function or method:\n\nSome operations, such as `+=` and `*=`, act in place to modify an existing\narray rather than create a new one.\n\nWhen operating with arrays of different types, the type of the resulting array\ncorresponds to the more general or precise one (a behavior known as\nupcasting).\n\nMany unary operations, such as computing the sum of all the elements in the\narray, are implemented as methods of the `ndarray` class.\n\nBy default, these operations apply to the array as though it were a list of\nnumbers, regardless of its shape. However, by specifying the `axis` parameter\nyou can apply an operation along the specified axis of an array:\n\nNumPy provides familiar mathematical functions such as sin, cos, and exp. In\nNumPy, these are called \u201cuniversal functions\u201d (`ufunc`). Within NumPy, these\nfunctions operate elementwise on an array, producing an array as output.\n\nSee also\n\n`all`, `any`, `apply_along_axis`, `argmax`, `argmin`, `argsort`, `average`,\n`bincount`, `ceil`, `clip`, `conj`, `corrcoef`, `cov`, `cross`, `cumprod`,\n`cumsum`, `diff`, `dot`, `floor`, `inner`, `invert`, `lexsort`, `max`,\n`maximum`, `mean`, `median`, `min`, `minimum`, `nonzero`, `outer`, `prod`,\n`re`, `round`, `sort`, `std`, `sum`, `trace`, `transpose`, `var`, `vdot`,\n`vectorize`, `where`\n\nOne-dimensional arrays can be indexed, sliced and iterated over, much like\nlists and other Python sequences.\n\nMultidimensional arrays can have one index per axis. These indices are given\nin a tuple separated by commas:\n\nWhen fewer indices are provided than the number of axes, the missing indices\nare considered complete slices`:`\n\nThe expression within brackets in `b[i]` is treated as an `i` followed by as\nmany instances of `:` as needed to represent the remaining axes. NumPy also\nallows you to write this using dots as `b[i, ...]`.\n\nThe dots (`...`) represent as many colons as needed to produce a complete\nindexing tuple. For example, if `x` is an array with 5 axes, then\n\nIterating over multidimensional arrays is done with respect to the first axis:\n\nHowever, if one wants to perform an operation on each element in the array,\none can use the `flat` attribute which is an iterator over all the elements of\nthe array:\n\nSee also\n\nIndexing on ndarrays, Indexing routines (reference), `newaxis`, `ndenumerate`,\n`indices`\n\nAn array has a shape given by the number of elements along each axis:\n\nThe shape of an array can be changed with various commands. Note that the\nfollowing three commands all return a modified array, but do not change the\noriginal array:\n\nThe order of the elements in the array resulting from `ravel` is normally\n\u201cC-style\u201d, that is, the rightmost index \u201cchanges the fastest\u201d, so the element\nafter `a[0, 0]` is `a[0, 1]`. If the array is reshaped to some other shape,\nagain the array is treated as \u201cC-style\u201d. NumPy normally creates arrays stored\nin this order, so `ravel` will usually not need to copy its argument, but if\nthe array was made by taking slices of another array or created with unusual\noptions, it may need to be copied. The functions `ravel` and `reshape` can\nalso be instructed, using an optional argument, to use FORTRAN-style arrays,\nin which the leftmost index changes the fastest.\n\nThe `reshape` function returns its argument with a modified shape, whereas the\n`ndarray.resize` method modifies the array itself:\n\nIf a dimension is given as `-1` in a reshaping operation, the other dimensions\nare automatically calculated:\n\nSee also\n\n`ndarray.shape`, `reshape`, `resize`, `ravel`\n\nSeveral arrays can be stacked together along different axes:\n\nThe function `column_stack` stacks 1D arrays as columns into a 2D array. It is\nequivalent to `hstack` only for 2D arrays:\n\nOn the other hand, the function `row_stack` is equivalent to `vstack` for any\ninput arrays. In fact, `row_stack` is an alias for `vstack`:\n\nIn general, for arrays with more than two dimensions, `hstack` stacks along\ntheir second axes, `vstack` stacks along their first axes, and `concatenate`\nallows for an optional arguments giving the number of the axis along which the\nconcatenation should happen.\n\nNote\n\nIn complex cases, `r_` and `c_` are useful for creating arrays by stacking\nnumbers along one axis. They allow the use of range literals `:`.\n\nWhen used with arrays as arguments, `r_` and `c_` are similar to `vstack` and\n`hstack` in their default behavior, but allow for an optional argument giving\nthe number of the axis along which to concatenate.\n\nSee also\n\n`hstack`, `vstack`, `column_stack`, `concatenate`, `c_`, `r_`\n\nUsing `hsplit`, you can split an array along its horizontal axis, either by\nspecifying the number of equally shaped arrays to return, or by specifying the\ncolumns after which the division should occur:\n\n`vsplit` splits along the vertical axis, and `array_split` allows one to\nspecify along which axis to split.\n\nWhen operating and manipulating arrays, their data is sometimes copied into a\nnew array and sometimes not. This is often a source of confusion for\nbeginners. There are three cases:\n\nSimple assignments make no copy of objects or their data.\n\nPython passes mutable objects as references, so function calls make no copy.\n\nDifferent array objects can share the same data. The `view` method creates a\nnew array object that looks at the same data.\n\nSlicing an array returns a view of it:\n\nThe `copy` method makes a complete copy of the array and its data.\n\nSometimes `copy` should be called after slicing if the original array is not\nrequired anymore. For example, suppose `a` is a huge intermediate result and\nthe final result `b` only contains a small fraction of `a`, a deep copy should\nbe made when constructing `b` with slicing:\n\nIf `b = a[:100]` is used instead, `a` is referenced by `b` and will persist in\nmemory even if `del a` is executed.\n\nHere is a list of some useful NumPy functions and methods names ordered in\ncategories. See Routines for the full list.\n\n`arange`, `array`, `copy`, `empty`, `empty_like`, `eye`, `fromfile`,\n`fromfunction`, `identity`, `linspace`, `logspace`, `mgrid`, `ogrid`, `ones`,\n`ones_like`, `r_`, `zeros`, `zeros_like`\n\n`ndarray.astype`, `atleast_1d`, `atleast_2d`, `atleast_3d`, `mat`\n\n`array_split`, `column_stack`, `concatenate`, `diagonal`, `dsplit`, `dstack`,\n`hsplit`, `hstack`, `ndarray.item`, `newaxis`, `ravel`, `repeat`, `reshape`,\n`resize`, `squeeze`, `swapaxes`, `take`, `transpose`, `vsplit`, `vstack`\n\n`all`, `any`, `nonzero`, `where`\n\n`argmax`, `argmin`, `argsort`, `max`, `min`, `ptp`, `searchsorted`, `sort`\n\n`choose`, `compress`, `cumprod`, `cumsum`, `inner`, `ndarray.fill`, `imag`,\n`prod`, `put`, `putmask`, `real`, `sum`\n\n`cov`, `mean`, `std`, `var`\n\n`cross`, `dot`, `outer`, `linalg.svd`, `vdot`\n\nBroadcasting allows universal functions to deal in a meaningful way with\ninputs that do not have exactly the same shape.\n\nThe first rule of broadcasting is that if all input arrays do not have the\nsame number of dimensions, a \u201c1\u201d will be repeatedly prepended to the shapes of\nthe smaller arrays until all the arrays have the same number of dimensions.\n\nThe second rule of broadcasting ensures that arrays with a size of 1 along a\nparticular dimension act as if they had the size of the array with the largest\nshape along that dimension. The value of the array element is assumed to be\nthe same along that dimension for the \u201cbroadcast\u201d array.\n\nAfter application of the broadcasting rules, the sizes of all arrays must\nmatch. More details can be found in Broadcasting.\n\nNumPy offers more indexing facilities than regular Python sequences. In\naddition to indexing by integers and slices, as we saw before, arrays can be\nindexed by arrays of integers and arrays of booleans.\n\nWhen the indexed array `a` is multidimensional, a single array of indices\nrefers to the first dimension of `a`. The following example shows this\nbehavior by converting an image of labels into a color image using a palette.\n\nWe can also give indexes for more than one dimension. The arrays of indices\nfor each dimension must have the same shape.\n\nIn Python, `arr[i, j]` is exactly the same as `arr[(i, j)]`\u2014so we can put `i`\nand `j` in a `tuple` and then do the indexing with that.\n\nHowever, we can not do this by putting `i` and `j` into an array, because this\narray will be interpreted as indexing the first dimension of `a`.\n\nAnother common use of indexing with arrays is the search of the maximum value\nof time-dependent series:\n\nYou can also use indexing with arrays as a target to assign to:\n\nHowever, when the list of indices contains repetitions, the assignment is done\nseveral times, leaving behind the last value:\n\nThis is reasonable enough, but watch out if you want to use Python\u2019s `+=`\nconstruct, as it may not do what you expect:\n\nEven though 0 occurs twice in the list of indices, the 0th element is only\nincremented once. This is because Python requires `a += 1` to be equivalent to\n`a = a + 1`.\n\nWhen we index arrays with arrays of (integer) indices we are providing the\nlist of indices to pick. With boolean indices the approach is different; we\nexplicitly choose which items in the array we want and which ones we don\u2019t.\n\nThe most natural way one can think of for boolean indexing is to use boolean\narrays that have the same shape as the original array:\n\nThis property can be very useful in assignments:\n\nYou can look at the following example to see how to use boolean indexing to\ngenerate an image of the Mandelbrot set:\n\nThe second way of indexing with booleans is more similar to integer indexing;\nfor each dimension of the array we give a 1D boolean array selecting the\nslices we want:\n\nNote that the length of the 1D boolean array must coincide with the length of\nthe dimension (or axis) you want to slice. In the previous example, `b1` has\nlength 3 (the number of rows in `a`), and `b2` (of length 4) is suitable to\nindex the 2nd axis (columns) of `a`.\n\nThe `ix_` function can be used to combine different vectors so as to obtain\nthe result for each n-uplet. For example, if you want to compute all the a+b*c\nfor all the triplets taken from each of the vectors a, b and c:\n\nYou could also implement the reduce as follows:\n\nand then use it as:\n\nThe advantage of this version of reduce compared to the normal ufunc.reduce is\nthat it makes use of the broadcasting rules in order to avoid creating an\nargument array the size of the output times the number of vectors.\n\nSee Structured arrays.\n\nHere we give a list of short and useful tips.\n\nTo change the dimensions of an array, you can omit one of the sizes which will\nthen be deduced automatically:\n\nHow do we construct a 2D array from a list of equally-sized row vectors? In\nMATLAB this is quite easy: if `x` and `y` are two vectors of the same length\nyou only need do `m=[x;y]`. In NumPy this works via the functions\n`column_stack`, `dstack`, `hstack` and `vstack`, depending on the dimension in\nwhich the stacking is to be done. For example:\n\nThe logic behind those functions in more than two dimensions can be strange.\n\nSee also\n\nNumPy for MATLAB users\n\nThe NumPy `histogram` function applied to an array returns a pair of vectors:\nthe histogram of the array and a vector of the bin edges. Beware: `matplotlib`\nalso has a function to build histograms (called `hist`, as in Matlab) that\ndiffers from the one in NumPy. The main difference is that `pylab.hist` plots\nthe histogram automatically, while `numpy.histogram` only generates the data.\n\nWith Matplotlib >=3.4 you can also use `plt.stairs(n, bins)`.\n\n"}, {"name": "ndarray.newbyteorder()", "path": "reference/generated/numpy.ndarray.newbyteorder", "type": "numpy.ndarray.newbyteorder", "text": "\nmethod\n\nReturn the array with the same data viewed with a different byte order.\n\nEquivalent to:\n\nChanges are also made in all fields and sub-arrays of the array data type.\n\nByte order to force; a value from the byte order specifications below.\n`new_order` codes can be any of:\n\nThe default value (\u2018S\u2019) results in swapping the current byte order.\n\nNew array object with the dtype reflecting given change to the byte order.\n\n"}, {"name": "ndarray.nonzero()", "path": "reference/generated/numpy.ndarray.nonzero", "type": "numpy.ndarray.nonzero", "text": "\nmethod\n\nReturn the indices of the elements that are non-zero.\n\nRefer to `numpy.nonzero` for full documentation.\n\nSee also\n\nequivalent function\n\n"}, {"name": "ndarray.partition()", "path": "reference/generated/numpy.ndarray.partition", "type": "numpy.ndarray.partition", "text": "\nmethod\n\nRearranges the elements in the array in such a way that the value of the\nelement in kth position is in the position it would be in a sorted array. All\nelements smaller than the kth element are moved before this element and all\nequal or greater are moved behind it. The ordering of the elements in the two\npartitions is undefined.\n\nNew in version 1.8.0.\n\nElement index to partition by. The kth element value will be in its final\nsorted position and all smaller elements will be moved before it and all equal\nor greater elements behind it. The order of all elements in the partitions is\nundefined. If provided with a sequence of kth it will partition all elements\nindexed by kth of them into their sorted position at once.\n\nDeprecated since version 1.22.0: Passing booleans as index is deprecated.\n\nAxis along which to sort. Default is -1, which means sort along the last axis.\n\nSelection algorithm. Default is \u2018introselect\u2019.\n\nWhen `a` is an array with fields defined, this argument specifies which fields\nto compare first, second, etc. A single field can be specified as a string,\nand not all fields need to be specified, but unspecified fields will still be\nused, in the order in which they come up in the dtype, to break ties.\n\nSee also\n\nReturn a parititioned copy of an array.\n\nIndirect partition.\n\nFull sort.\n\nSee `np.partition` for notes on the different algorithms.\n\n"}, {"name": "ndarray.prod()", "path": "reference/generated/numpy.ndarray.prod", "type": "numpy.ndarray.prod", "text": "\nmethod\n\nReturn the product of the array elements over the given axis\n\nRefer to `numpy.prod` for full documentation.\n\nSee also\n\nequivalent function\n\n"}, {"name": "ndarray.ptp()", "path": "reference/generated/numpy.ndarray.ptp", "type": "numpy.ndarray.ptp", "text": "\nmethod\n\nPeak to peak (maximum - minimum) value along a given axis.\n\nRefer to `numpy.ptp` for full documentation.\n\nSee also\n\nequivalent function\n\n"}, {"name": "ndarray.put()", "path": "reference/generated/numpy.ndarray.put", "type": "numpy.ndarray.put", "text": "\nmethod\n\nSet `a.flat[n] = values[n]` for all `n` in indices.\n\nRefer to `numpy.put` for full documentation.\n\nSee also\n\nequivalent function\n\n"}, {"name": "ndarray.ravel()", "path": "reference/generated/numpy.ndarray.ravel", "type": "numpy.ndarray.ravel", "text": "\nmethod\n\nReturn a flattened array.\n\nRefer to `numpy.ravel` for full documentation.\n\nSee also\n\nequivalent function\n\na flat iterator on the array.\n\n"}, {"name": "ndarray.real", "path": "reference/generated/numpy.ndarray.real", "type": "numpy.ndarray.real", "text": "\nattribute\n\nThe real part of the array.\n\nSee also\n\nequivalent function\n\n"}, {"name": "ndarray.repeat()", "path": "reference/generated/numpy.ndarray.repeat", "type": "numpy.ndarray.repeat", "text": "\nmethod\n\nRepeat elements of an array.\n\nRefer to `numpy.repeat` for full documentation.\n\nSee also\n\nequivalent function\n\n"}, {"name": "ndarray.reshape()", "path": "reference/generated/numpy.ndarray.reshape", "type": "numpy.ndarray.reshape", "text": "\nmethod\n\nReturns an array containing the same data with a new shape.\n\nRefer to `numpy.reshape` for full documentation.\n\nSee also\n\nequivalent function\n\nUnlike the free function `numpy.reshape`, this method on `ndarray` allows the\nelements of the shape parameter to be passed in as separate arguments. For\nexample, `a.reshape(10, 11)` is equivalent to `a.reshape((10, 11))`.\n\n"}, {"name": "ndarray.resize()", "path": "reference/generated/numpy.ndarray.resize", "type": "numpy.ndarray.resize", "text": "\nmethod\n\nChange shape and size of array in-place.\n\nShape of resized array.\n\nIf False, reference count will not be checked. Default is True.\n\nIf `a` does not own its own data or references or views to it exist, and the\ndata memory must be changed. PyPy only: will always raise if the data memory\nmust be changed, since there is no reliable way to determine if references or\nviews to it exist.\n\nIf the `order` keyword argument is specified. This behaviour is a bug in\nNumPy.\n\nSee also\n\nReturn a new array with the specified shape.\n\nThis reallocates space for the data area if necessary.\n\nOnly contiguous arrays (data elements consecutive in memory) can be resized.\n\nThe purpose of the reference count check is to make sure you do not use this\narray as a buffer for another Python object and then reallocate the memory.\nHowever, reference counts can increase in other ways so if you are sure that\nyou have not shared the memory for this array with another Python object, then\nyou may safely set `refcheck` to False.\n\nShrinking an array: array is flattened (in the order that the data are stored\nin memory), resized, and reshaped:\n\nEnlarging an array: as above, but missing entries are filled with zeros:\n\nReferencing an array prevents resizing\u2026\n\nUnless `refcheck` is False:\n\n"}, {"name": "ndarray.round()", "path": "reference/generated/numpy.ndarray.round", "type": "numpy.ndarray.round", "text": "\nmethod\n\nReturn `a` with each element rounded to the given number of decimals.\n\nRefer to `numpy.around` for full documentation.\n\nSee also\n\nequivalent function\n\n"}, {"name": "ndarray.searchsorted()", "path": "reference/generated/numpy.ndarray.searchsorted", "type": "numpy.ndarray.searchsorted", "text": "\nmethod\n\nFind indices where elements of v should be inserted in a to maintain order.\n\nFor full documentation, see `numpy.searchsorted`\n\nSee also\n\nequivalent function\n\n"}, {"name": "ndarray.setfield()", "path": "reference/generated/numpy.ndarray.setfield", "type": "numpy.ndarray.setfield", "text": "\nmethod\n\nPut a value into a specified place in a field defined by a data-type.\n\nPlace `val` into `a`\u2019s field defined by `dtype` and beginning `offset` bytes\ninto the field.\n\nValue to be placed in field.\n\nData-type of the field in which to place `val`.\n\nThe number of bytes into the field at which to place `val`.\n\nSee also\n\n"}, {"name": "ndarray.setflags()", "path": "reference/generated/numpy.ndarray.setflags", "type": "numpy.ndarray.setflags", "text": "\nmethod\n\nSet array flags WRITEABLE, ALIGNED, (WRITEBACKIFCOPY and UPDATEIFCOPY),\nrespectively.\n\nThese Boolean-valued flags affect how numpy interprets the memory area used by\n`a` (see Notes below). The ALIGNED flag can only be set to True if the data is\nactually aligned according to the type. The WRITEBACKIFCOPY and (deprecated)\nUPDATEIFCOPY flags can never be set to True. The flag WRITEABLE can only be\nset to True if the array owns its own memory, or the ultimate owner of the\nmemory exposes a writeable buffer interface, or is a string. (The exception\nfor string is made so that unpickling can be done without copying memory.)\n\nDescribes whether or not `a` can be written to.\n\nDescribes whether or not `a` is aligned properly for its type.\n\nDescribes whether or not `a` is a copy of another \u201cbase\u201d array.\n\nArray flags provide information about how the memory area used for the array\nis to be interpreted. There are 7 Boolean flags in use, only four of which can\nbe changed by the user: WRITEBACKIFCOPY, UPDATEIFCOPY, WRITEABLE, and ALIGNED.\n\nWRITEABLE (W) the data area can be written to;\n\nALIGNED (A) the data and strides are aligned appropriately for the hardware\n(as determined by the compiler);\n\nUPDATEIFCOPY (U) (deprecated), replaced by WRITEBACKIFCOPY;\n\nWRITEBACKIFCOPY (X) this array is a copy of some other array (referenced by\n.base). When the C-API function PyArray_ResolveWritebackIfCopy is called, the\nbase array will be updated with the contents of this array.\n\nAll flags can be accessed using the single (upper case) letter as well as the\nfull name.\n\n"}, {"name": "ndarray.shape", "path": "reference/generated/numpy.ndarray.shape", "type": "numpy.ndarray.shape", "text": "\nattribute\n\nTuple of array dimensions.\n\nThe shape property is usually used to get the current shape of an array, but\nmay also be used to reshape the array in-place by assigning a tuple of array\ndimensions to it. As with `numpy.reshape`, one of the new shape dimensions can\nbe -1, in which case its value is inferred from the size of the array and the\nremaining dimensions. Reshaping an array in-place will fail if a copy is\nrequired.\n\nSee also\n\nsimilar function\n\nsimilar method\n\n"}, {"name": "ndarray.size", "path": "reference/generated/numpy.ndarray.size", "type": "numpy.ndarray.size", "text": "\nattribute\n\nNumber of elements in the array.\n\nEqual to `np.prod(a.shape)`, i.e., the product of the array\u2019s dimensions.\n\n`a.size` returns a standard arbitrary precision Python integer. This may not\nbe the case with other methods of obtaining the same value (like the suggested\n`np.prod(a.shape)`, which returns an instance of `np.int_`), and may be\nrelevant if the value is used further in calculations that may overflow a\nfixed size integer type.\n\n"}, {"name": "ndarray.sort()", "path": "reference/generated/numpy.ndarray.sort", "type": "numpy.ndarray.sort", "text": "\nmethod\n\nSort an array in-place. Refer to `numpy.sort` for full documentation.\n\nAxis along which to sort. Default is -1, which means sort along the last axis.\n\nSorting algorithm. The default is \u2018quicksort\u2019. Note that both \u2018stable\u2019 and\n\u2018mergesort\u2019 use timsort under the covers and, in general, the actual\nimplementation will vary with datatype. The \u2018mergesort\u2019 option is retained for\nbackwards compatibility.\n\nChanged in version 1.15.0: The \u2018stable\u2019 option was added.\n\nWhen `a` is an array with fields defined, this argument specifies which fields\nto compare first, second, etc. A single field can be specified as a string,\nand not all fields need be specified, but unspecified fields will still be\nused, in the order in which they come up in the dtype, to break ties.\n\nSee also\n\nReturn a sorted copy of an array.\n\nIndirect sort.\n\nIndirect stable sort on multiple keys.\n\nFind elements in sorted array.\n\nPartial sort.\n\nSee `numpy.sort` for notes on the different sorting algorithms.\n\nUse the `order` keyword to specify a field to use when sorting a structured\narray:\n\n"}, {"name": "ndarray.squeeze()", "path": "reference/generated/numpy.ndarray.squeeze", "type": "numpy.ndarray.squeeze", "text": "\nmethod\n\nRemove axes of length one from `a`.\n\nRefer to `numpy.squeeze` for full documentation.\n\nSee also\n\nequivalent function\n\n"}, {"name": "ndarray.std()", "path": "reference/generated/numpy.ndarray.std", "type": "numpy.ndarray.std", "text": "\nmethod\n\nReturns the standard deviation of the array elements along given axis.\n\nRefer to `numpy.std` for full documentation.\n\nSee also\n\nequivalent function\n\n"}, {"name": "ndarray.strides", "path": "reference/generated/numpy.ndarray.strides", "type": "numpy.ndarray.strides", "text": "\nattribute\n\nTuple of bytes to step in each dimension when traversing an array.\n\nThe byte offset of element `(i[0], i[1], ..., i[n])` in an array `a` is:\n\nA more detailed explanation of strides can be found in the \u201cndarray.rst\u201d file\nin the NumPy reference guide.\n\nSee also\n\nImagine an array of 32-bit integers (each 4 bytes):\n\nThis array is stored in memory as 40 bytes, one after the other (known as a\ncontiguous block of memory). The strides of an array tell us how many bytes we\nhave to skip in memory to move to the next position along a certain axis. For\nexample, we have to skip 4 bytes (1 value) to move to the next column, but 20\nbytes (5 values) to get to the same position in the next row. As such, the\nstrides for the array `x` will be `(20, 4)`.\n\n"}, {"name": "ndarray.sum()", "path": "reference/generated/numpy.ndarray.sum", "type": "numpy.ndarray.sum", "text": "\nmethod\n\nReturn the sum of the array elements over the given axis.\n\nRefer to `numpy.sum` for full documentation.\n\nSee also\n\nequivalent function\n\n"}, {"name": "ndarray.swapaxes()", "path": "reference/generated/numpy.ndarray.swapaxes", "type": "numpy.ndarray.swapaxes", "text": "\nmethod\n\nReturn a view of the array with `axis1` and `axis2` interchanged.\n\nRefer to `numpy.swapaxes` for full documentation.\n\nSee also\n\nequivalent function\n\n"}, {"name": "ndarray.T", "path": "reference/generated/numpy.ndarray.t", "type": "numpy.ndarray.T", "text": "\nattribute\n\nThe transposed array.\n\nSame as `self.transpose()`.\n\nSee also\n\n"}, {"name": "ndarray.take()", "path": "reference/generated/numpy.ndarray.take", "type": "numpy.ndarray.take", "text": "\nmethod\n\nReturn an array formed from the elements of `a` at the given indices.\n\nRefer to `numpy.take` for full documentation.\n\nSee also\n\nequivalent function\n\n"}, {"name": "ndarray.tobytes()", "path": "reference/generated/numpy.ndarray.tobytes", "type": "numpy.ndarray.tobytes", "text": "\nmethod\n\nConstruct Python bytes containing the raw data bytes in the array.\n\nConstructs Python bytes showing a copy of the raw contents of data memory. The\nbytes object is produced in C-order by default. This behavior is controlled by\nthe `order` parameter.\n\nNew in version 1.9.0.\n\nControls the memory layout of the bytes object. \u2018C\u2019 means C-order, \u2018F\u2019 means\nF-order, \u2018A\u2019 (short for Any) means \u2018F\u2019 if `a` is Fortran contiguous, \u2018C\u2019\notherwise. Default is \u2018C\u2019.\n\nPython bytes exhibiting a copy of `a`\u2019s raw data.\n\n"}, {"name": "ndarray.tofile()", "path": "reference/generated/numpy.ndarray.tofile", "type": "numpy.ndarray.tofile", "text": "\nmethod\n\nWrite array to a file as text or binary (default).\n\nData is always written in \u2018C\u2019 order, independent of the order of `a`. The data\nproduced by this method can be recovered using the function fromfile().\n\nAn open file object, or a string containing a filename.\n\nChanged in version 1.17.0: `pathlib.Path` objects are now accepted.\n\nSeparator between array items for text output. If \u201c\u201d (empty), a binary file is\nwritten, equivalent to `file.write(a.tobytes())`.\n\nFormat string for text file output. Each entry in the array is formatted to\ntext by first converting it to the closest Python type, and then using\n\u201cformat\u201d % item.\n\nThis is a convenience function for quick storage of array data. Information on\nendianness and precision is lost, so this method is not a good choice for\nfiles intended to archive data or transport data between machines with\ndifferent endianness. Some of these problems can be overcome by outputting the\ndata as text files, at the expense of speed and file size.\n\nWhen fid is a file object, array contents are directly written to the file,\nbypassing the file object\u2019s `write` method. As a result, tofile cannot be used\nwith files objects supporting compression (e.g., GzipFile) or file-like\nobjects that do not support `fileno()` (e.g., BytesIO).\n\n"}, {"name": "ndarray.tolist()", "path": "reference/generated/numpy.ndarray.tolist", "type": "numpy.ndarray.tolist", "text": "\nmethod\n\nReturn the array as an `a.ndim`-levels deep nested list of Python scalars.\n\nReturn a copy of the array data as a (nested) Python list. Data items are\nconverted to the nearest compatible builtin Python type, via the `item`\nfunction.\n\nIf `a.ndim` is 0, then since the depth of the nested list is 0, it will not be\na list at all, but a simple Python scalar.\n\nThe possibly nested list of array elements.\n\nThe array may be recreated via `a = np.array(a.tolist())`, although this may\nsometimes lose precision.\n\nFor a 1D array, `a.tolist()` is almost the same as `list(a)`, except that\n`tolist` changes numpy scalars to Python scalars:\n\nAdditionally, for a 2D array, `tolist` applies recursively:\n\nThe base case for this recursion is a 0D array:\n\n"}, {"name": "ndarray.tostring()", "path": "reference/generated/numpy.ndarray.tostring", "type": "numpy.ndarray.tostring", "text": "\nmethod\n\nA compatibility alias for `tobytes`, with exactly the same behavior.\n\nDespite its name, it returns `bytes` not `str`s.\n\nDeprecated since version 1.19.0.\n\n"}, {"name": "ndarray.trace()", "path": "reference/generated/numpy.ndarray.trace", "type": "numpy.ndarray.trace", "text": "\nmethod\n\nReturn the sum along diagonals of the array.\n\nRefer to `numpy.trace` for full documentation.\n\nSee also\n\nequivalent function\n\n"}, {"name": "ndarray.transpose()", "path": "reference/generated/numpy.ndarray.transpose", "type": "numpy.ndarray.transpose", "text": "\nmethod\n\nReturns a view of the array with axes transposed.\n\nFor a 1-D array this has no effect, as a transposed vector is simply the same\nvector. To convert a 1-D array into a 2D column vector, an additional\ndimension must be added. `np.atleast2d(a).T` achieves this, as does `a[:,\nnp.newaxis]`. For a 2-D array, this is a standard matrix transpose. For an n-D\narray, if axes are given, their order indicates how the axes are permuted (see\nExamples). If axes are not provided and `a.shape = (i[0], i[1], ... i[n-2],\ni[n-1])`, then `a.transpose().shape = (i[n-1], i[n-2], ... i[1], i[0])`.\n\nView of `a`, with axes suitably permuted.\n\nSee also\n\nEquivalent function\n\nArray property returning the array transposed.\n\nGive a new shape to an array without changing its data.\n\n"}, {"name": "ndarray.var()", "path": "reference/generated/numpy.ndarray.var", "type": "numpy.ndarray.var", "text": "\nmethod\n\nReturns the variance of the array elements, along given axis.\n\nRefer to `numpy.var` for full documentation.\n\nSee also\n\nequivalent function\n\n"}, {"name": "ndarray.view()", "path": "reference/generated/numpy.ndarray.view", "type": "numpy.ndarray.view", "text": "\nmethod\n\nNew view of array with the same data.\n\nNote\n\nPassing None for `dtype` is different from omitting the parameter, since the\nformer invokes `dtype(None)` which is an alias for `dtype('float_')`.\n\nData-type descriptor of the returned view, e.g., float32 or int16. Omitting it\nresults in the view having the same data-type as `a`. This argument can also\nbe specified as an ndarray sub-class, which then specifies the type of the\nreturned object (this is equivalent to setting the `type` parameter).\n\nType of the returned view, e.g., ndarray or matrix. Again, omission of the\nparameter results in type preservation.\n\n`a.view()` is used two different ways:\n\n`a.view(some_dtype)` or `a.view(dtype=some_dtype)` constructs a view of the\narray\u2019s memory with a different data-type. This can cause a reinterpretation\nof the bytes of memory.\n\n`a.view(ndarray_subclass)` or `a.view(type=ndarray_subclass)` just returns an\ninstance of `ndarray_subclass` that looks at the same array (same shape,\ndtype, etc.) This does not cause a reinterpretation of the memory.\n\nFor `a.view(some_dtype)`, if `some_dtype` has a different number of bytes per\nentry than the previous dtype (for example, converting a regular array to a\nstructured array), then the behavior of the view cannot be predicted just from\nthe superficial appearance of `a` (shown by `print(a)`). It also depends on\nexactly how `a` is stored in memory. Therefore if `a` is C-ordered versus\nfortran-ordered, versus defined as a slice or transpose, etc., the view may\ngive different results.\n\nViewing array data using a different type and dtype:\n\nCreating a view on a structured array so it can be used in calculations\n\nMaking changes to the view changes the underlying array\n\nUsing a view to convert an array to a recarray:\n\nViews share data:\n\nViews that change the dtype size (bytes per entry) should normally be avoided\non arrays defined by slices, transposes, fortran-ordering, etc.:\n\n"}, {"name": "ndindex.ndincr()", "path": "reference/generated/numpy.ndindex.ndincr", "type": "numpy.ndindex.ndincr", "text": "\nmethod\n\nIncrement the multi-dimensional index by one.\n\nThis method is for backward compatibility only: do not use.\n\nDeprecated since version 1.20.0: This method has been advised against since\nnumpy 1.8.0, but only started emitting DeprecationWarning as of this version.\n\n"}, {"name": "nditer.close()", "path": "reference/generated/numpy.nditer.close", "type": "numpy.nditer.close", "text": "\nmethod\n\nResolve all writeback semantics in writeable operands.\n\nNew in version 1.15.0.\n\nSee also\n\n"}, {"name": "nditer.copy()", "path": "reference/generated/numpy.nditer.copy", "type": "numpy.nditer.copy", "text": "\nmethod\n\nGet a copy of the iterator in its current state.\n\n"}, {"name": "nditer.debug_print()", "path": "reference/generated/numpy.nditer.debug_print", "type": "numpy.nditer.debug_print", "text": "\nmethod\n\nPrint the current state of the `nditer` instance and debug info to stdout.\n\n"}, {"name": "nditer.enable_external_loop()", "path": "reference/generated/numpy.nditer.enable_external_loop", "type": "numpy.nditer.enable_external_loop", "text": "\nmethod\n\nWhen the \u201cexternal_loop\u201d was not used during construction, but is desired,\nthis modifies the iterator to behave as if the flag was specified.\n\n"}, {"name": "nditer.index", "path": "reference/generated/numpy.nditer.index", "type": "Indexing routines", "text": "\nattribute\n\n"}, {"name": "nditer.iternext()", "path": "reference/generated/numpy.nditer.iternext", "type": "numpy.nditer.iternext", "text": "\nmethod\n\nCheck whether iterations are left, and perform a single internal iteration\nwithout returning the result. Used in the C-style pattern do-while pattern.\nFor an example, see `nditer`.\n\nWhether or not there are iterations left.\n\n"}, {"name": "nditer.itersize", "path": "reference/generated/numpy.nditer.itersize", "type": "Indexing routines", "text": "\nattribute\n\n"}, {"name": "nditer.multi_index", "path": "reference/generated/numpy.nditer.multi_index", "type": "Indexing routines", "text": "\nattribute\n\n"}, {"name": "nditer.operands", "path": "reference/generated/numpy.nditer.operands", "type": "Indexing routines", "text": "\nattribute\n\noperands[`Slice`]\n\nThe array(s) to be iterated over. Valid only before the iterator is closed.\n\n"}, {"name": "nditer.remove_axis()", "path": "reference/generated/numpy.nditer.remove_axis", "type": "numpy.nditer.remove_axis", "text": "\nmethod\n\nRemoves axis `i` from the iterator. Requires that the flag \u201cmulti_index\u201d be\nenabled.\n\n"}, {"name": "nditer.remove_multi_index()", "path": "reference/generated/numpy.nditer.remove_multi_index", "type": "numpy.nditer.remove_multi_index", "text": "\nmethod\n\nWhen the \u201cmulti_index\u201d flag was specified, this removes it, allowing the\ninternal iteration structure to be optimized further.\n\n"}, {"name": "nditer.reset()", "path": "reference/generated/numpy.nditer.reset", "type": "numpy.nditer.reset", "text": "\nmethod\n\nReset the iterator to its initial state.\n\n"}, {"name": "nditer.value", "path": "reference/generated/numpy.nditer.value", "type": "Indexing routines", "text": "\nattribute\n\n"}, {"name": "ndpointer()", "path": "user/c-info.python-as-glue", "type": "User Guide", "text": "\nMany people like to say that Python is a fantastic glue language. Hopefully,\nthis Chapter will convince you that this is true. The first adopters of Python\nfor science were typically people who used it to glue together large\napplication codes running on super-computers. Not only was it much nicer to\ncode in Python than in a shell script or Perl, in addition, the ability to\neasily extend Python made it relatively easy to create new classes and types\nspecifically adapted to the problems being solved. From the interactions of\nthese early contributors, Numeric emerged as an array-like object that could\nbe used to pass data between these applications.\n\nAs Numeric has matured and developed into NumPy, people have been able to\nwrite more code directly in NumPy. Often this code is fast-enough for\nproduction use, but there are still times that there is a need to access\ncompiled code. Either to get that last bit of efficiency out of the algorithm\nor to make it easier to access widely-available codes written in C/C++ or\nFortran.\n\nThis chapter will review many of the tools that are available for the purpose\nof accessing code written in other compiled languages. There are many\nresources available for learning to call other compiled libraries from Python\nand the purpose of this Chapter is not to make you an expert. The main goal is\nto make you aware of some of the possibilities so that you will know what to\n\u201cGoogle\u201d in order to learn more.\n\nWhile Python is a great language and a pleasure to code in, its dynamic nature\nresults in overhead that can cause some code ( i.e. raw computations inside of\nfor loops) to be up 10-100 times slower than equivalent code written in a\nstatic compiled language. In addition, it can cause memory usage to be larger\nthan necessary as temporary arrays are created and destroyed during\ncomputation. For many types of computing needs, the extra slow-down and memory\nconsumption can often not be spared (at least for time- or memory- critical\nportions of your code). Therefore one of the most common needs is to call out\nfrom Python code to a fast, machine-code routine (e.g. compiled using C/C++ or\nFortran). The fact that this is relatively easy to do is a big reason why\nPython is such an excellent high-level language for scientific and engineering\nprogramming.\n\nTheir are two basic approaches to calling compiled code: writing an extension\nmodule that is then imported to Python using the import command, or calling a\nshared-library subroutine directly from Python using the ctypes module.\nWriting an extension module is the most common method.\n\nWarning\n\nCalling C-code from Python can result in Python crashes if you are not\ncareful. None of the approaches in this chapter are immune. You have to know\nsomething about the way data is handled by both NumPy and by the third-party\nlibrary being used.\n\nExtension modules were discussed in Writing an extension module. The most\nbasic way to interface with compiled code is to write an extension module and\nconstruct a module method that calls the compiled code. For improved\nreadability, your method should take advantage of the `PyArg_ParseTuple` call\nto convert between Python objects and C data-types. For standard C data-types\nthere is probably already a built-in converter. For others you may need to\nwrite your own converter and use the `\"O&\"` format string which allows you to\nspecify a function that will be used to perform the conversion from the Python\nobject to whatever C-structures are needed.\n\nOnce the conversions to the appropriate C-structures and C data-types have\nbeen performed, the next step in the wrapper is to call the underlying\nfunction. This is straightforward if the underlying function is in C or C++.\nHowever, in order to call Fortran code you must be familiar with how Fortran\nsubroutines are called from C/C++ using your compiler and platform. This can\nvary somewhat platforms and compilers (which is another reason f2py makes life\nmuch simpler for interfacing Fortran code) but generally involves underscore\nmangling of the name and the fact that all variables are passed by reference\n(i.e. all arguments are pointers).\n\nThe advantage of the hand-generated wrapper is that you have complete control\nover how the C-library gets used and called which can lead to a lean and tight\ninterface with minimal over-head. The disadvantage is that you have to write,\ndebug, and maintain C-code, although most of it can be adapted using the time-\nhonored technique of \u201ccutting-pasting-and-modifying\u201d from other extension\nmodules. Because, the procedure of calling out to additional C-code is fairly\nregimented, code-generation procedures have been developed to make this\nprocess easier. One of these code-generation techniques is distributed with\nNumPy and allows easy integration with Fortran and (simple) C code. This\npackage, f2py, will be covered briefly in the next section.\n\nF2py allows you to automatically construct an extension module that interfaces\nto routines in Fortran 77/90/95 code. It has the ability to parse Fortran\n77/90/95 code and automatically generate Python signatures for the subroutines\nit encounters, or you can guide how the subroutine interfaces with Python by\nconstructing an interface-definition-file (or modifying the f2py-produced\none).\n\nProbably the easiest way to introduce f2py is to offer a simple example. Here\nis one of the subroutines contained in a file named `add.f`\n\nThis routine simply adds the elements in two contiguous arrays and places the\nresult in a third. The memory for all three arrays must be provided by the\ncalling routine. A very basic interface to this routine can be automatically\ngenerated by f2py:\n\nYou should be able to run this command assuming your search-path is set-up\nproperly. This command will produce an extension module named `addmodule.c` in\nthe current directory. This extension module can now be compiled and used from\nPython just like any other extension module.\n\nYou can also get f2py to both compile `add.f` along with the produced\nextension module leaving only a shared-library extension file that can be\nimported from Python:\n\nThis command leaves a file named add.{ext} in the current directory (where\n{ext} is the appropriate extension for a Python extension module on your\nplatform \u2014 so, pyd, etc. ). This module may then be imported from Python. It\nwill contain a method for each subroutine in add (zadd, cadd, dadd, sadd). The\ndocstring of each method contains information about how the module method may\nbe called:\n\nThe default interface is a very literal translation of the Fortran code into\nPython. The Fortran array arguments must now be NumPy arrays and the integer\nargument should be an integer. The interface will attempt to convert all\narguments to their required types (and shapes) and issue an error if\nunsuccessful. However, because it knows nothing about the semantics of the\narguments (such that C is an output and n should really match the array\nsizes), it is possible to abuse this function in ways that can cause Python to\ncrash. For example:\n\nwill cause a program crash on most systems. Under the covers, the lists are\nbeing converted to proper arrays but then the underlying add loop is told to\ncycle way beyond the borders of the allocated memory.\n\nIn order to improve the interface, directives should be provided. This is\naccomplished by constructing an interface definition file. It is usually best\nto start from the interface file that f2py can produce (where it gets its\ndefault behavior from). To get f2py to generate the interface file use the -h\noption:\n\nThis command leaves the file add.pyf in the current directory. The section of\nthis file corresponding to zadd is:\n\nBy placing intent directives and checking code, the interface can be cleaned\nup quite a bit until the Python module method is both easier to use and more\nrobust.\n\nThe intent directive, intent(out) is used to tell f2py that `c` is an output\nvariable and should be created by the interface before being passed to the\nunderlying code. The intent(hide) directive tells f2py to not allow the user\nto specify the variable, `n`, but instead to get it from the size of `a`. The\ndepend( `a` ) directive is necessary to tell f2py that the value of n depends\non the input a (so that it won\u2019t try to create the variable n until the\nvariable a is created).\n\nAfter modifying `add.pyf`, the new Python module file can be generated by\ncompiling both `add.f` and `add.pyf`:\n\nThe new interface has docstring:\n\nNow, the function can be called in a much more robust way:\n\nNotice the automatic conversion to the correct format that occurred.\n\nThe nice interface can also be generated automatically by placing the variable\ndirectives as special comments in the original Fortran code. Thus, if the\nsource code is modified to contain:\n\nThen, one can compile the extension module using:\n\nThe resulting signature for the function add.zadd is exactly the same one that\nwas created previously. If the original source code had contained `A(N)`\ninstead of `A(*)` and so forth with `B` and `C`, then nearly the same\ninterface can be obtained by placing the `INTENT(OUT) :: C` comment line in\nthe source code. The only difference is that `N` would be an optional input\nthat would default to the length of `A`.\n\nFor comparison with the other methods to be discussed. Here is another example\nof a function that filters a two-dimensional array of double precision\nfloating-point numbers using a fixed averaging filter. The advantage of using\nFortran to index into multi-dimensional arrays should be clear from this\nexample.\n\nThis code can be compiled and linked into an extension module named filter\nusing:\n\nThis will produce an extension module named filter.so in the current directory\nwith a method named dfilter2d that returns a filtered version of the input.\n\nThe f2py program is written in Python and can be run from inside your code to\ncompile Fortran code at runtime, as follows:\n\nThe source string can be any valid Fortran code. If you want to save the\nextension-module source code then a suitable file-name can be provided by the\n`source_fn` keyword to the compile function.\n\nIf you want to distribute your f2py extension module, then you only need to\ninclude the .pyf file and the Fortran code. The distutils extensions in NumPy\nallow you to define an extension module entirely in terms of this interface\nfile. A valid `setup.py` file allowing distribution of the `add.f` module (as\npart of the package `f2py_examples` so that it would be loaded as\n`f2py_examples.add`) is:\n\nInstallation of the new package is easy using:\n\nassuming you have the proper permissions to write to the main site- packages\ndirectory for the version of Python you are using. For the resulting package\nto work, you need to create a file named `__init__.py` (in the same directory\nas `add.pyf`). Notice the extension module is defined entirely in terms of the\n`add.pyf` and `add.f` files. The conversion of the .pyf file to a .c file is\nhandled by `numpy.disutils`.\n\nThe interface definition file (.pyf) is how you can fine-tune the interface\nbetween Python and Fortran. There is decent documentation for f2py at F2PY\nuser guide and reference manual. There is also more information on using f2py\n(including how to use it to wrap C codes) at the \u201cInterfacing With Other\nLanguages\u201d heading of the SciPy Cookbook.\n\nThe f2py method of linking compiled code is currently the most sophisticated\nand integrated approach. It allows clean separation of Python with compiled\ncode while still allowing for separate distribution of the extension module.\nThe only draw-back is that it requires the existence of a Fortran compiler in\norder for a user to install the code. However, with the existence of the free-\ncompilers g77, gfortran, and g95, as well as high-quality commercial\ncompilers, this restriction is not particularly onerous. In our opinion,\nFortran is still the easiest way to write fast and clear code for scientific\ncomputing. It handles complex numbers, and multi-dimensional indexing in the\nmost straightforward way. Be aware, however, that some Fortran compilers will\nnot be able to optimize code as well as good hand- written C-code.\n\nCython is a compiler for a Python dialect that adds (optional) static typing\nfor speed, and allows mixing C or C++ code into your modules. It produces C or\nC++ extensions that can be compiled and imported in Python code.\n\nIf you are writing an extension module that will include quite a bit of your\nown algorithmic code as well, then Cython is a good match. Among its features\nis the ability to easily and quickly work with multidimensional arrays.\n\nNotice that Cython is an extension-module generator only. Unlike f2py, it\nincludes no automatic facility for compiling and linking the extension module\n(which must be done in the usual fashion). It does provide a modified\ndistutils class called `build_ext` which lets you build an extension module\nfrom a `.pyx` source. Thus, you could write in a `setup.py` file:\n\nAdding the NumPy include directory is, of course, only necessary if you are\nusing NumPy arrays in the extension module (which is what we assume you are\nusing Cython for). The distutils extensions in NumPy also include support for\nautomatically producing the extension-module and linking it from a `.pyx`\nfile. It works so that if the user does not have Cython installed, then it\nlooks for a file with the same file-name but a `.c` extension which it then\nuses instead of trying to produce the `.c` file again.\n\nIf you just use Cython to compile a standard Python module, then you will get\na C extension module that typically runs a bit faster than the equivalent\nPython module. Further speed increases can be gained by using the `cdef`\nkeyword to statically define C variables.\n\nLet\u2019s look at two examples we\u2019ve seen before to see how they might be\nimplemented using Cython. These examples were compiled into extension modules\nusing Cython 0.21.1.\n\nHere is part of a Cython module named `add.pyx` which implements the complex\naddition functions we previously implemented using f2py:\n\nThis module shows use of the `cimport` statement to load the definitions from\nthe `numpy.pxd` header that ships with Cython. It looks like NumPy is imported\ntwice; `cimport` only makes the NumPy C-API available, while the regular\n`import` causes a Python-style import at runtime and makes it possible to call\ninto the familiar NumPy Python API.\n\nThe example also demonstrates Cython\u2019s \u201ctyped memoryviews\u201d, which are like\nNumPy arrays at the C level, in the sense that they are shaped and strided\narrays that know their own extent (unlike a C array addressed through a bare\npointer). The syntax `double complex[:]` denotes a one-dimensional array\n(vector) of doubles, with arbitrary strides. A contiguous array of ints would\nbe `int[::1]`, while a matrix of floats would be `float[:, :]`.\n\nShown commented is the `cython.boundscheck` decorator, which turns bounds-\nchecking for memory view accesses on or off on a per-function basis. We can\nuse this to further speed up our code, at the expense of safety (or a manual\ncheck prior to entering the loop).\n\nOther than the view syntax, the function is immediately readable to a Python\nprogrammer. Static typing of the variable `i` is implicit. Instead of the view\nsyntax, we could also have used Cython\u2019s special NumPy array syntax, but the\nview syntax is preferred.\n\nThe two-dimensional example we created using Fortran is just as easy to write\nin Cython:\n\nThis 2-d averaging filter runs quickly because the loop is in C and the\npointer computations are done only as needed. If the code above is compiled as\na module `image`, then a 2-d image, `img`, can be filtered using this code\nvery quickly using:\n\nRegarding the code, two things are of note: firstly, it is impossible to\nreturn a memory view to Python. Instead, a NumPy array `out` is first created,\nand then a view `b` onto this array is used for the computation. Secondly, the\nview `b` is typed `double[:, ::1]`. This means 2-d array with contiguous rows,\ni.e., C matrix order. Specifying the order explicitly can speed up some\nalgorithms since they can skip stride computations.\n\nCython is the extension mechanism of choice for several scientific Python\nlibraries, including Scipy, Pandas, SAGE, scikit-image and scikit-learn, as\nwell as the XML processing library LXML. The language and compiler are well-\nmaintained.\n\nThere are several disadvantages of using Cython:\n\nOne big advantage of Cython-generated extension modules is that they are easy\nto distribute. In summary, Cython is a very capable tool for either gluing C\ncode or generating an extension module quickly and should not be over-looked.\nIt is especially useful for people that can\u2019t or won\u2019t write C or Fortran\ncode.\n\nCtypes is a Python extension module, included in the stdlib, that allows you\nto call an arbitrary function in a shared library directly from Python. This\napproach allows you to interface with C-code directly from Python. This opens\nup an enormous number of libraries for use from Python. The drawback, however,\nis that coding mistakes can lead to ugly program crashes very easily (just as\ncan happen in C) because there is little type or bounds checking done on the\nparameters. This is especially true when array data is passed in as a pointer\nto a raw memory location. The responsibility is then on you that the\nsubroutine will not access memory outside the actual array area. But, if you\ndon\u2019t mind living a little dangerously ctypes can be an effective tool for\nquickly taking advantage of a large shared library (or writing extended\nfunctionality in your own shared library).\n\nBecause the ctypes approach exposes a raw interface to the compiled code it is\nnot always tolerant of user mistakes. Robust use of the ctypes module\ntypically involves an additional layer of Python code in order to check the\ndata types and array bounds of objects passed to the underlying subroutine.\nThis additional layer of checking (not to mention the conversion from ctypes\nobjects to C-data-types that ctypes itself performs), will make the interface\nslower than a hand-written extension-module interface. However, this overhead\nshould be negligible if the C-routine being called is doing any significant\namount of work. If you are a great Python programmer with weak C skills,\nctypes is an easy way to write a useful interface to a (shared) library of\ncompiled code.\n\nTo use ctypes you must\n\nThere are several requirements for a shared library that can be used with\nctypes that are platform specific. This guide assumes you have some\nfamiliarity with making a shared library on your system (or simply have a\nshared library available to you). Items to remember are:\n\nOn some platforms (e.g. Windows), a shared library requires a .def file that\nspecifies the functions to be exported. For example a mylib.def file might\ncontain:\n\nAlternatively, you may be able to use the storage-class specifier\n`__declspec(dllexport)` in the C-definition of the function to avoid the need\nfor this `.def` file.\n\nThere is no standard way in Python distutils to create a standard shared\nlibrary (an extension module is a \u201cspecial\u201d shared library Python understands)\nin a cross-platform manner. Thus, a big disadvantage of ctypes at the time of\nwriting this book is that it is difficult to distribute in a cross-platform\nmanner a Python extension that uses ctypes and includes your own code which\nshould be compiled as a shared library on the users system.\n\nA simple, but robust way to load the shared library is to get the absolute\npath name and load it using the cdll object of ctypes:\n\nHowever, on Windows accessing an attribute of the `cdll` method will load the\nfirst DLL by that name found in the current directory or on the PATH. Loading\nthe absolute path name requires a little finesse for cross-platform work since\nthe extension of shared libraries varies. There is a\n`ctypes.util.find_library` utility available that can simplify the process of\nfinding the library to load but it is not foolproof. Complicating matters,\ndifferent platforms have different default extensions used by shared libraries\n(e.g. .dll \u2013 Windows, .so \u2013 Linux, .dylib \u2013 Mac OS X). This must also be taken\ninto account if you are using ctypes to wrap code that needs to work on\nseveral platforms.\n\nNumPy provides a convenience function called `ctypeslib.load_library` (name,\npath). This function takes the name of the shared library (including any\nprefix like \u2018lib\u2019 but excluding the extension) and a path where the shared\nlibrary can be located. It returns a ctypes library object or raises an\n`OSError` if the library cannot be found or raises an `ImportError` if the\nctypes module is not available. (Windows users: the ctypes library object\nloaded using `load_library` is always loaded assuming cdecl calling\nconvention. See the ctypes documentation under `ctypes.windll` and/or\n`ctypes.oledll` for ways to load libraries under other calling conventions).\n\nThe functions in the shared library are available as attributes of the ctypes\nlibrary object (returned from `ctypeslib.load_library`) or as items using\n`lib['func_name']` syntax. The latter method for retrieving a function name is\nparticularly useful if the function name contains characters that are not\nallowable in Python variable names.\n\nPython ints/longs, strings, and unicode objects are automatically converted as\nneeded to equivalent ctypes arguments The None object is also converted\nautomatically to a NULL pointer. All other Python objects must be converted to\nctypes-specific types. There are two ways around this restriction that allow\nctypes to integrate with other objects.\n\nNumPy uses both methods with a preference for the second method because it can\nbe safer. The ctypes attribute of the ndarray returns an object that has an\n`_as_parameter_` attribute which returns an integer representing the address\nof the ndarray to which it is associated. As a result, one can pass this\nctypes attribute object directly to a function expecting a pointer to the data\nin your ndarray. The caller must be sure that the ndarray object is of the\ncorrect type, shape, and has the correct flags set or risk nasty crashes if\nthe data-pointer to inappropriate arrays are passed in.\n\nTo implement the second method, NumPy provides the class-factory function\n`ndpointer` in the `numpy.ctypeslib` module. This class-factory function\nproduces an appropriate class that can be placed in an argtypes attribute\nentry of a ctypes function. The class will contain a from_param method which\nctypes will use to convert any ndarray passed in to the function to a ctypes-\nrecognized object. In the process, the conversion will perform checking on any\nproperties of the ndarray that were specified by the user in the call to\n`ndpointer`. Aspects of the ndarray that can be checked include the data-type,\nthe number-of-dimensions, the shape, and/or the state of the flags on any\narray passed. The return value of the from_param method is the ctypes\nattribute of the array which (because it contains the `_as_parameter_`\nattribute pointing to the array data area) can be used by ctypes directly.\n\nThe ctypes attribute of an ndarray is also endowed with additional attributes\nthat may be convenient when passing additional information about the array\ninto a ctypes function. The attributes data, shape, and strides can provide\nctypes compatible types corresponding to the data-area, the shape, and the\nstrides of the array. The data attribute returns a `c_void_p` representing a\npointer to the data area. The shape and strides attributes each return an\narray of ctypes integers (or None representing a NULL pointer, if a 0-d\narray). The base ctype of the array is a ctype integer of the same size as a\npointer on the platform. There are also methods `data_as({ctype})`,\n`shape_as(<base ctype>)`, and `strides_as(<base ctype>)`. These return the\ndata as a ctype object of your choice and the shape/strides arrays using an\nunderlying base type of your choice. For convenience, the `ctypeslib` module\nalso contains `c_intp` as a ctypes integer data-type whose size is the same as\nthe size of `c_void_p` on the platform (its value is None if ctypes is not\ninstalled).\n\nThe function is accessed as an attribute of or an item from the loaded shared-\nlibrary. Thus, if `./mylib.so` has a function named `cool_function1`, it may\nbe accessed either as:\n\nIn ctypes, the return-value of a function is set to be \u2018int\u2019 by default. This\nbehavior can be changed by setting the restype attribute of the function. Use\nNone for the restype if the function has no return value (\u2018void\u2019):\n\nAs previously discussed, you can also set the argtypes attribute of the\nfunction in order to have ctypes check the types of the input arguments when\nthe function is called. Use the `ndpointer` factory function to generate a\nready-made class for data-type, shape, and flags checking on your new\nfunction. The `ndpointer` function has the signature\n\nKeyword arguments with the value `None` are not checked. Specifying a keyword\nenforces checking of that aspect of the ndarray on conversion to a ctypes-\ncompatible object. The dtype keyword can be any object understood as a data-\ntype object. The ndim keyword should be an integer, and the shape keyword\nshould be an integer or a sequence of integers. The flags keyword specifies\nthe minimal flags that are required on any array passed in. This can be\nspecified as a string of comma separated requirements, an integer indicating\nthe requirement bits OR\u2019d together, or a flags object returned from the flags\nattribute of an array with the necessary requirements.\n\nUsing an ndpointer class in the argtypes method can make it significantly\nsafer to call a C function using ctypes and the data- area of an ndarray. You\nmay still want to wrap the function in an additional Python wrapper to make it\nuser-friendly (hiding some obvious arguments and making some arguments output\narguments). In this process, the `requires` function in NumPy may be useful to\nreturn the right kind of array from a given input.\n\nIn this example, we will demonstrate how the addition function and the filter\nfunction implemented previously using the other approaches can be implemented\nusing ctypes. First, the C code which implements the algorithms contains the\nfunctions `zadd`, `dadd`, `sadd`, `cadd`, and `dfilter2d`. The `zadd` function\nis:\n\nwith similar code for `cadd`, `dadd`, and `sadd` that handles complex float,\ndouble, and float data-types, respectively:\n\nThe `code.c` file also contains the function `dfilter2d`:\n\nA possible advantage this code has over the Fortran-equivalent code is that it\ntakes arbitrarily strided (i.e. non-contiguous arrays) and may also run faster\ndepending on the optimization capability of your compiler. But, it is an\nobviously more complicated than the simple code in `filter.f`. This code must\nbe compiled into a shared library. On my Linux system this is accomplished\nusing:\n\nWhich creates a shared_library named code.so in the current directory. On\nWindows don\u2019t forget to either add `__declspec(dllexport)` in front of void on\nthe line preceding each function definition, or write a `code.def` file that\nlists the names of the functions to be exported.\n\nA suitable Python interface to this shared library should be constructed. To\ndo this create a file named interface.py with the following lines at the top:\n\nThis code loads the shared library named `code.{ext}` located in the same path\nas this file. It then adds a return type of void to the functions contained in\nthe library. It also adds argument checking to the functions in the library so\nthat ndarrays can be passed as the first three arguments along with an integer\n(large enough to hold a pointer on the platform) as the fourth argument.\n\nSetting up the filtering function is similar and allows the filtering function\nto be called with ndarray arguments as the first two arguments and with\npointers to integers (large enough to handle the strides and shape of an\nndarray) as the last two arguments.:\n\nNext, define a simple selection function that chooses which addition function\nto call in the shared library based on the data-type:\n\nFinally, the two functions to be exported by the interface can be written\nsimply as:\n\nand:\n\nUsing ctypes is a powerful way to connect Python with arbitrary C-code. Its\nadvantages for extending Python include\n\nclean separation of C code from Python code\n\nIts disadvantages include\n\nBecause of the difficulty in distributing an extension module made using\nctypes, f2py and Cython are still the easiest ways to extend Python for\npackage creation. However, ctypes is in some cases a useful alternative. This\nshould bring more features to ctypes that should eliminate the difficulty in\nextending Python and distributing the extension using ctypes.\n\nThese tools have been found useful by others using Python and so are included\nhere. They are discussed separately because they are either older ways to do\nthings now handled by f2py, Cython, or ctypes (SWIG, PyFort) or because of a\nlack of reasonable documentation (SIP, Boost). Links to these methods are not\nincluded since the most relevant can be found using Google or some other\nsearch engine, and any links provided here would be quickly dated. Do not\nassume that inclusion in this list means that the package deserves attention.\nInformation about these packages are collected here because many people have\nfound them useful and we\u2019d like to give you as many options as possible for\ntackling the problem of easily integrating your code.\n\nSimplified Wrapper and Interface Generator (SWIG) is an old and fairly stable\nmethod for wrapping C/C++-libraries to a large variety of other languages. It\ndoes not specifically understand NumPy arrays but can be made usable with\nNumPy through the use of typemaps. There are some sample typemaps in the\nnumpy/tools/swig directory under numpy.i together with an example module that\nmakes use of them. SWIG excels at wrapping large C/C++ libraries because it\ncan (almost) parse their headers and auto-produce an interface. Technically,\nyou need to generate a `.i` file that defines the interface. Often, however,\nthis `.i` file can be parts of the header itself. The interface usually needs\na bit of tweaking to be very useful. This ability to parse C/C++ headers and\nauto-generate the interface still makes SWIG a useful approach to adding\nfunctionalilty from C/C++ into Python, despite the other methods that have\nemerged that are more targeted to Python. SWIG can actually target extensions\nfor several languages, but the typemaps usually have to be language-specific.\nNonetheless, with modifications to the Python-specific typemaps, SWIG can be\nused to interface a library with other languages such as Perl, Tcl, and Ruby.\n\nMy experience with SWIG has been generally positive in that it is relatively\neasy to use and quite powerful. It has been used often before becoming more\nproficient at writing C-extensions. However, writing custom interfaces with\nSWIG is often troublesome because it must be done using the concept of\ntypemaps which are not Python specific and are written in a C-like syntax.\nTherefore, other gluing strategies are preferred and SWIG would be probably\nconsidered only to wrap a very-large C/C++ library. Nonetheless, there are\nothers who use SWIG quite happily.\n\nSIP is another tool for wrapping C/C++ libraries that is Python specific and\nappears to have very good support for C++. Riverbank Computing developed SIP\nin order to create Python bindings to the QT library. An interface file must\nbe written to generate the binding, but the interface file looks a lot like a\nC/C++ header file. While SIP is not a full C++ parser, it understands quite a\nbit of C++ syntax as well as its own special directives that allow\nmodification of how the Python binding is accomplished. It also allows the\nuser to define mappings between Python types and C/C++ structures and classes.\n\nBoost is a repository of C++ libraries and Boost.Python is one of those\nlibraries which provides a concise interface for binding C++ classes and\nfunctions to Python. The amazing part of the Boost.Python approach is that it\nworks entirely in pure C++ without introducing a new syntax. Many users of C++\nreport that Boost.Python makes it possible to combine the best of both worlds\nin a seamless fashion. Using Boost to wrap simple C-subroutines is usually\nover-kill. Its primary purpose is to make C++ classes available in Python. So,\nif you have a set of C++ classes that need to be integrated cleanly into\nPython, consider learning about and using Boost.Python.\n\nPyFort is a nice tool for wrapping Fortran and Fortran-like C-code into Python\nwith support for Numeric arrays. It was written by Paul Dubois, a\ndistinguished computer scientist and the very first maintainer of Numeric (now\nretired). It is worth mentioning in the hopes that somebody will update PyFort\nto work with NumPy arrays as well which now support either Fortran or C-style\ncontiguous arrays.\n\n"}, {"name": "NO_IMPORT_ARRAY", "path": "reference/c-api/array#c.NO_IMPORT_ARRAY", "type": "Array API", "text": "\nUsing these #defines you can use the C-API in multiple files for a single\nextension module. In each file you must define `PY_ARRAY_UNIQUE_SYMBOL` to\nsome name that will hold the C-API (e.g. myextension_ARRAY_API). This must be\ndone before including the numpy/arrayobject.h file. In the module\ninitialization routine you call `import_array`. In addition, in the files that\ndo not have the module initialization sub_routine define `NO_IMPORT_ARRAY`\nprior to including numpy/arrayobject.h.\n\nSuppose I have two files coolmodule.c and coolhelper.c which need to be\ncompiled and linked into a single extension module. Suppose coolmodule.c\ncontains the required initcool module initialization function (with the\nimport_array() function called). Then, coolmodule.c would have at the top:\n\nOn the other hand, coolhelper.c would contain at the top:\n\nYou can also put the common two last lines into an extension-local header file\nas long as you make sure that NO_IMPORT_ARRAY is #defined before #including\nthat file.\n\nInternally, these #defines work as follows:\n\n"}, {"name": "NO_IMPORT_UFUNC", "path": "reference/c-api/ufunc#c.NO_IMPORT_UFUNC", "type": "UFunc API", "text": "\n\n"}, {"name": "NPY_1_PI", "path": "reference/c-api/coremath#c.NPY_1_PI", "type": "NumPy core libraries", "text": "\nReciprocal of pi (\\\\(\\frac{1}{\\pi}\\\\))\n\n"}, {"name": "NPY_2_PI", "path": "reference/c-api/coremath#c.NPY_2_PI", "type": "NumPy core libraries", "text": "\nTwo times the reciprocal of pi (\\\\(\\frac{2}{\\pi}\\\\))\n\n"}, {"name": "NPY_ALLOW_C_API", "path": "reference/c-api/array#c.NPY_ALLOW_C_API", "type": "Array API", "text": "\nPlace before code that needs to call the Python C-API (when it is known that\nthe GIL has already been released).\n\n"}, {"name": "NPY_ARRAY_ALIGNED", "path": "reference/c-api/array#c.NPY_ARRAY_ALIGNED", "type": "Array API", "text": "\nThe data area and all array elements are aligned appropriately.\n\n"}, {"name": "NPY_ARRAY_ALIGNED", "path": "reference/c-api/array#c.PyArray_FromAny.NPY_ARRAY_ALIGNED", "type": "Array API", "text": "\nMake sure the returned array is aligned on proper boundaries for its data\ntype. An aligned array has the data pointer and every strides factor as a\nmultiple of the alignment factor for the data-type- descriptor.\n\n"}, {"name": "NPY_ARRAY_BEHAVED", "path": "reference/c-api/array#c.PyArray_FromAny.NPY_ARRAY_BEHAVED", "type": "Array API", "text": "\n`NPY_ARRAY_ALIGNED` | `NPY_ARRAY_WRITEABLE`\n\n"}, {"name": "NPY_ARRAY_CARRAY", "path": "reference/c-api/array#c.PyArray_FromAny.NPY_ARRAY_CARRAY", "type": "Array API", "text": "\n`NPY_ARRAY_C_CONTIGUOUS` | `NPY_ARRAY_BEHAVED`\n\n"}, {"name": "NPY_ARRAY_CARRAY", "path": "reference/c-api/array#c.NPY_ARRAY_CARRAY", "type": "Array API", "text": "\n`NPY_ARRAY_C_CONTIGUOUS` | `NPY_ARRAY_BEHAVED`\n\n"}, {"name": "NPY_ARRAY_CARRAY_RO", "path": "reference/c-api/array#c.PyArray_FromAny.NPY_ARRAY_CARRAY_RO", "type": "Array API", "text": "\n`NPY_ARRAY_C_CONTIGUOUS` | `NPY_ARRAY_ALIGNED`\n\n"}, {"name": "NPY_ARRAY_CARRAY_RO", "path": "reference/c-api/array#c.NPY_ARRAY_CARRAY_RO", "type": "Array API", "text": "\n`NPY_ARRAY_C_CONTIGUOUS` | `NPY_ARRAY_ALIGNED`\n\n"}, {"name": "NPY_ARRAY_DEFAULT", "path": "reference/c-api/array#c.PyArray_FromAny.NPY_ARRAY_DEFAULT", "type": "Array API", "text": "\n`NPY_ARRAY_CARRAY`\n\n"}, {"name": "NPY_ARRAY_DEFAULT", "path": "reference/c-api/array#c.NPY_ARRAY_DEFAULT", "type": "Array API", "text": "\n`NPY_ARRAY_CARRAY`\n\n"}, {"name": "NPY_ARRAY_ELEMENTSTRIDES", "path": "reference/c-api/array#c.NPY_ARRAY_ELEMENTSTRIDES", "type": "Array API", "text": "\nMake sure the returned array has strides that are multiples of the element\nsize.\n\n"}, {"name": "NPY_ARRAY_ENSUREARRAY", "path": "reference/c-api/array#c.PyArray_FromAny.NPY_ARRAY_ENSUREARRAY", "type": "Array API", "text": "\nMake sure the result is a base-class ndarray. By default, if op is an instance\nof a subclass of ndarray, an instance of that same subclass is returned. If\nthis flag is set, an ndarray object will be returned instead.\n\n"}, {"name": "NPY_ARRAY_ENSUREARRAY", "path": "reference/c-api/array#c.NPY_ARRAY_ENSUREARRAY", "type": "Array API", "text": "\nMake sure the resulting object is an actual ndarray, and not a sub-class.\n\n"}, {"name": "NPY_ARRAY_ENSURECOPY", "path": "reference/c-api/array#c.NPY_ARRAY_ENSURECOPY", "type": "Array API", "text": "\nMake sure the resulting array is a copy of the original.\n\n"}, {"name": "NPY_ARRAY_ENSURECOPY", "path": "reference/c-api/array#c.PyArray_FromAny.NPY_ARRAY_ENSURECOPY", "type": "Array API", "text": "\nMake sure a copy is made of op. If this flag is not present, data is not\ncopied if it can be avoided.\n\n"}, {"name": "NPY_ARRAY_F_CONTIGUOUS", "path": "reference/c-api/array#c.PyArray_FromAny.NPY_ARRAY_F_CONTIGUOUS", "type": "Array API", "text": "\nMake sure the returned array is Fortran-style contiguous.\n\n"}, {"name": "NPY_ARRAY_F_CONTIGUOUS", "path": "reference/c-api/array#c.NPY_ARRAY_F_CONTIGUOUS", "type": "Array API", "text": "\nThe data area is in Fortran-style contiguous order (first index varies the\nfastest).\n\n"}, {"name": "NPY_ARRAY_FARRAY", "path": "reference/c-api/array#c.PyArray_FromAny.NPY_ARRAY_FARRAY", "type": "Array API", "text": "\n`NPY_ARRAY_F_CONTIGUOUS` | `NPY_ARRAY_BEHAVED`\n\n"}, {"name": "NPY_ARRAY_FARRAY", "path": "reference/c-api/array#c.NPY_ARRAY_FARRAY", "type": "Array API", "text": "\n`NPY_ARRAY_F_CONTIGUOUS` | `NPY_ARRAY_BEHAVED`\n\n"}, {"name": "NPY_ARRAY_FARRAY_RO", "path": "reference/c-api/array#c.PyArray_FromAny.NPY_ARRAY_FARRAY_RO", "type": "Array API", "text": "\n`NPY_ARRAY_F_CONTIGUOUS` | `NPY_ARRAY_ALIGNED`\n\n"}, {"name": "NPY_ARRAY_FARRAY_RO", "path": "reference/c-api/array#c.NPY_ARRAY_FARRAY_RO", "type": "Array API", "text": "\n`NPY_ARRAY_F_CONTIGUOUS` | `NPY_ARRAY_ALIGNED`\n\n"}, {"name": "NPY_ARRAY_FORCECAST", "path": "reference/c-api/array#c.PyArray_FromAny.NPY_ARRAY_FORCECAST", "type": "Array API", "text": "\nForce a cast to the output type even if it cannot be done safely. Without this\nflag, a data cast will occur only if it can be done safely, otherwise an error\nis raised.\n\n"}, {"name": "NPY_ARRAY_IN_ARRAY", "path": "reference/c-api/array#c.NPY_ARRAY_IN_ARRAY", "type": "Array API", "text": "\n`NPY_ARRAY_C_CONTIGUOUS` | `NPY_ARRAY_ALIGNED`\n\n`NPY_ARRAY_F_CONTIGUOUS` | `NPY_ARRAY_ALIGNED`\n\n"}, {"name": "NPY_ARRAY_INOUT_ARRAY", "path": "reference/c-api/array#c.NPY_ARRAY_INOUT_ARRAY", "type": "Array API", "text": "\n`NPY_ARRAY_C_CONTIGUOUS` | `NPY_ARRAY_WRITEABLE` | `NPY_ARRAY_ALIGNED` |\n`NPY_ARRAY_WRITEBACKIFCOPY` | `NPY_ARRAY_UPDATEIFCOPY`\n\n`NPY_ARRAY_F_CONTIGUOUS` | `NPY_ARRAY_WRITEABLE` | `NPY_ARRAY_ALIGNED` |\n`NPY_ARRAY_WRITEBACKIFCOPY` | `NPY_ARRAY_UPDATEIFCOPY`\n\n"}, {"name": "NPY_ARRAY_NOTSWAPPED", "path": "reference/c-api/array#c.NPY_ARRAY_NOTSWAPPED", "type": "Array API", "text": "\nMake sure the returned array has a data-type descriptor that is in machine\nbyte-order, over-riding any specification in the dtype argument. Normally, the\nbyte-order requirement is determined by the dtype argument. If this flag is\nset and the dtype argument does not indicate a machine byte-order descriptor\n(or is NULL and the object is already an array with a data-type descriptor\nthat is not in machine byte- order), then a new data-type descriptor is\ncreated and used with its byte-order field set to native.\n\n`NPY_ARRAY_ALIGNED` | `NPY_ARRAY_WRITEABLE` | `NPY_ARRAY_NOTSWAPPED`\n\n"}, {"name": "NPY_ARRAY_OUT_ARRAY", "path": "reference/c-api/array#c.NPY_ARRAY_OUT_ARRAY", "type": "Array API", "text": "\n`NPY_ARRAY_C_CONTIGUOUS` | `NPY_ARRAY_ALIGNED` | `NPY_ARRAY_WRITEABLE`\n\n`NPY_ARRAY_F_CONTIGUOUS` | `NPY_ARRAY_WRITEABLE` | `NPY_ARRAY_ALIGNED`\n\n"}, {"name": "NPY_ARRAY_OWNDATA", "path": "reference/c-api/array#c.NPY_ARRAY_OWNDATA", "type": "Array API", "text": "\nThe data area is owned by this array. Should never be set manually, instead\ncreate a `PyObject` wrapping the data and set the array\u2019s base to that object.\nFor an example, see the test in `test_mem_policy`.\n\n"}, {"name": "NPY_ARRAY_UPDATE_ALL", "path": "reference/c-api/array#c.NPY_ARRAY_UPDATE_ALL", "type": "Array API", "text": "\n`NPY_ARRAY_C_CONTIGUOUS` | `NPY_ARRAY_F_CONTIGUOUS` | `NPY_ARRAY_ALIGNED`\n\n"}, {"name": "NPY_ARRAY_UPDATEIFCOPY", "path": "reference/c-api/array#c.NPY_ARRAY_UPDATEIFCOPY", "type": "Array API", "text": "\nA deprecated version of `NPY_ARRAY_WRITEBACKIFCOPY` which depends upon\n`dealloc` to trigger the writeback. For backwards compatibility,\n`PyArray_ResolveWritebackIfCopy` is called at `dealloc` but relying on that\nbehavior is deprecated and not supported in PyPy.\n\n"}, {"name": "NPY_ARRAY_UPDATEIFCOPY", "path": "reference/c-api/array#c.PyArray_FromAny.NPY_ARRAY_UPDATEIFCOPY", "type": "Array API", "text": "\nDeprecated. Use `NPY_ARRAY_WRITEBACKIFCOPY`, which is similar. This flag\n\u201cautomatically\u201d copies the data back when the returned array is deallocated,\nwhich is not supported in all python implementations.\n\n"}, {"name": "NPY_ARRAY_WRITEABLE", "path": "reference/c-api/array#c.PyArray_FromAny.NPY_ARRAY_WRITEABLE", "type": "Array API", "text": "\nMake sure the returned array can be written to.\n\n"}, {"name": "NPY_ARRAY_WRITEABLE", "path": "reference/c-api/array#c.NPY_ARRAY_WRITEABLE", "type": "Array API", "text": "\nThe data area can be written to.\n\nNotice that the above 3 flags are defined so that a new, well- behaved array\nhas these flags defined as true.\n\n"}, {"name": "NPY_ARRAY_WRITEBACKIFCOPY", "path": "reference/c-api/array#c.NPY_ARRAY_WRITEBACKIFCOPY", "type": "Array API", "text": "\nThe data area represents a (well-behaved) copy whose information should be\ntransferred back to the original when `PyArray_ResolveWritebackIfCopy` is\ncalled.\n\nThis is a special flag that is set if this array represents a copy made\nbecause a user required certain flags in `PyArray_FromAny` and a copy had to\nbe made of some other array (and the user asked for this flag to be set in\nsuch a situation). The base attribute then points to the \u201cmisbehaved\u201d array\n(which is set read_only). :c:func`PyArray_ResolveWritebackIfCopy` will copy\nits contents back to the \u201cmisbehaved\u201d array (casting if necessary) and will\nreset the \u201cmisbehaved\u201d array to `NPY_ARRAY_WRITEABLE`. If the \u201cmisbehaved\u201d\narray was not `NPY_ARRAY_WRITEABLE` to begin with then `PyArray_FromAny` would\nhave returned an error because `NPY_ARRAY_WRITEBACKIFCOPY` would not have been\npossible.\n\n"}, {"name": "NPY_ARRAY_WRITEBACKIFCOPY", "path": "reference/c-api/array#c.PyArray_FromAny.NPY_ARRAY_WRITEBACKIFCOPY", "type": "Array API", "text": "\nIf op is already an array, but does not satisfy the requirements, then a copy\nis made (which will satisfy the requirements). If this flag is present and a\ncopy (of an object that is already an array) must be made, then the\ncorresponding `NPY_ARRAY_WRITEBACKIFCOPY` flag is set in the returned copy and\nop is made to be read-only. You must be sure to call\n`PyArray_ResolveWritebackIfCopy` to copy the contents back into op and the op\narray will be made writeable again. If op is not writeable to begin with, or\nif it is not already an array, then an error is raised.\n\n"}, {"name": "NPY_BEGIN_THREADS", "path": "reference/c-api/array#c.NPY_BEGIN_THREADS", "type": "Array API", "text": "\nPlace right before code that does not need the Python interpreter (no Python\nC-API calls). This macro saves the Python state and releases the GIL.\n\n"}, {"name": "NPY_BEGIN_THREADS_DEF", "path": "reference/c-api/array#c.NPY_BEGIN_THREADS_DEF", "type": "Array API", "text": "\nPlace in the variable declaration area. This macro sets up the variable needed\nfor storing the Python state.\n\n"}, {"name": "NPY_BIG", "path": "reference/c-api/array#c.NPY_BIG", "type": "Array API", "text": "\nIf a byteorder of `NPY_IGNORE` is encountered it is left alone. If newendian\nis `NPY_SWAP`, then all byte-orders are swapped. Other valid newendian values\nare `NPY_NATIVE`, `NPY_LITTLE`, and `NPY_BIG` which all cause the returned\ndata-typed descriptor (and all it\u2019s referenced data-type descriptors) to have\nthe corresponding byte- order.\n\n"}, {"name": "NPY_BIG_ENDIAN", "path": "reference/c-api/config#c.NPY_BIG_ENDIAN", "type": "System configuration", "text": "\n\n"}, {"name": "npy_bool contiguous", "path": "reference/c-api/types-and-structures#c.PyArrayIterObject.contiguous", "type": "Python Types and C-Structures", "text": "\nThis flag is true if the underlying array is `NPY_ARRAY_C_CONTIGUOUS`. It is\nused to simplify calculations when possible.\n\n"}, {"name": "npy_bool nonzero()", "path": "reference/c-api/types-and-structures#c.PyArray_ArrFuncs.nonzero", "type": "Python Types and C-Structures", "text": "\nA pointer to a function that returns TRUE if the item of `arr` pointed to by\n`data` is nonzero. This function can deal with misbehaved arrays.\n\n"}, {"name": "npy_bool NpyIter_HasDelayedBufAlloc()", "path": "reference/c-api/iterator#c.NpyIter_HasDelayedBufAlloc", "type": "Array Iterator API", "text": "\nReturns 1 if the flag `NPY_ITER_DELAY_BUFALLOC` was passed to the iterator\nconstructor, and no call to one of the Reset functions has been done yet, 0\notherwise.\n\n"}, {"name": "npy_bool NpyIter_HasExternalLoop()", "path": "reference/c-api/iterator#c.NpyIter_HasExternalLoop", "type": "Array Iterator API", "text": "\nReturns 1 if the caller needs to handle the inner-most 1-dimensional loop, or\n0 if the iterator handles all looping. This is controlled by the constructor\nflag `NPY_ITER_EXTERNAL_LOOP` or `NpyIter_EnableExternalLoop`.\n\n"}, {"name": "npy_bool NpyIter_HasIndex()", "path": "reference/c-api/iterator#c.NpyIter_HasIndex", "type": "Array Iterator API", "text": "\nReturns 1 if the iterator was created with the `NPY_ITER_C_INDEX` or\n`NPY_ITER_F_INDEX` flag, 0 otherwise.\n\n"}, {"name": "npy_bool NpyIter_HasMultiIndex()", "path": "reference/c-api/iterator#c.NpyIter_HasMultiIndex", "type": "Array Iterator API", "text": "\nReturns 1 if the iterator was created with the `NPY_ITER_MULTI_INDEX` flag, 0\notherwise.\n\n"}, {"name": "npy_bool NpyIter_IsBuffered()", "path": "reference/c-api/iterator#c.NpyIter_IsBuffered", "type": "Array Iterator API", "text": "\nReturns 1 if the iterator was created with the `NPY_ITER_BUFFERED` flag, 0\notherwise.\n\n"}, {"name": "npy_bool NpyIter_IsFirstVisit()", "path": "reference/c-api/iterator#c.NpyIter_IsFirstVisit", "type": "Array Iterator API", "text": "\nNew in version 1.7.\n\nChecks to see whether this is the first time the elements of the specified\nreduction operand which the iterator points at are being seen for the first\ntime. The function returns a reasonable answer for reduction operands and when\nbuffering is disabled. The answer may be incorrect for buffered non-reduction\noperands.\n\nThis function is intended to be used in EXTERNAL_LOOP mode only, and will\nproduce some wrong answers when that mode is not enabled.\n\nIf this function returns true, the caller should also check the inner loop\nstride of the operand, because if that stride is 0, then only the first\nelement of the innermost external loop is being visited for the first time.\n\nWARNING: For performance reasons, \u2018iop\u2019 is not bounds-checked, it is not\nconfirmed that \u2018iop\u2019 is actually a reduction operand, and it is not confirmed\nthat EXTERNAL_LOOP mode is enabled. These checks are the responsibility of the\ncaller, and should be done outside of any inner loops.\n\n"}, {"name": "npy_bool NpyIter_IsGrowInner()", "path": "reference/c-api/iterator#c.NpyIter_IsGrowInner", "type": "Array Iterator API", "text": "\nReturns 1 if the iterator was created with the `NPY_ITER_GROWINNER` flag, 0\notherwise.\n\n"}, {"name": "npy_bool NpyIter_RequiresBuffering()", "path": "reference/c-api/iterator#c.NpyIter_RequiresBuffering", "type": "Array Iterator API", "text": "\nReturns 1 if the iterator requires buffering, which occurs when an operand\nneeds conversion or alignment and so cannot be used directly.\n\n"}, {"name": "npy_bool PyArray_EquivArrTypes()", "path": "reference/c-api/array#c.PyArray_EquivArrTypes", "type": "Array API", "text": "\nReturn `NPY_TRUE` if a1 and a2 are arrays with equivalent types for this\nplatform.\n\n"}, {"name": "npy_bool PyArray_EquivTypenums()", "path": "reference/c-api/array#c.PyArray_EquivTypenums", "type": "Array API", "text": "\nSpecial case of `PyArray_EquivTypes` (\u2026) that does not accept flexible data\ntypes but may be easier to call.\n\n"}, {"name": "npy_bool PyArray_EquivTypes()", "path": "reference/c-api/array#c.PyArray_EquivTypes", "type": "Array API", "text": "\nReturn `NPY_TRUE` if type1 and type2 actually represent equivalent types for\nthis platform (the fortran member of each type is ignored). For example, on\n32-bit platforms, `NPY_LONG` and `NPY_INT` are equivalent. Otherwise return\n`NPY_FALSE`.\n\n"}, {"name": "NPY_BYTE_ORDER", "path": "reference/c-api/config#c.NPY_BYTE_ORDER", "type": "System configuration", "text": "\nNew in version 1.3.0.\n\nPortable alternatives to the `endian.h` macros of GNU Libc. If big endian,\n`NPY_BYTE_ORDER` == `NPY_BIG_ENDIAN`, and similarly for little endian\narchitectures.\n\nDefined in `numpy/npy_endian.h`.\n\n"}, {"name": "NPY_CLIP", "path": "reference/c-api/array#c.PyArray_Choose.NPY_CLIP", "type": "Array API", "text": "\nall values are clipped to the region [0, len(op) ).\n\n"}, {"name": "npy_copysign()", "path": "reference/c-api/coremath#c.npy_copysign", "type": "NumPy core libraries", "text": "\nThis is a function equivalent to C99 copysign: return x with the same sign as\ny. Works for any value, including inf and nan. Single and extended precisions\nare available with suffix f and l.\n\nNew in version 1.4.0.\n\n"}, {"name": "NPY_CPU_AMD64", "path": "reference/c-api/config#c.NPY_CPU_AMD64", "type": "System configuration", "text": "\n\n"}, {"name": "NPY_CPU_IA64", "path": "reference/c-api/config#c.NPY_CPU_IA64", "type": "System configuration", "text": "\n\n"}, {"name": "NPY_CPU_LITTLE", "path": "reference/c-api/config#c.PyArray_GetEndianness.NPY_CPU_LITTLE", "type": "System configuration", "text": "\n\n"}, {"name": "NPY_CPU_PARISC", "path": "reference/c-api/config#c.NPY_CPU_PARISC", "type": "System configuration", "text": "\nNew in version 1.3.0.\n\nCPU architecture of the platform; only one of the above is defined.\n\nDefined in `numpy/npy_cpu.h`\n\n"}, {"name": "NPY_CPU_PPC", "path": "reference/c-api/config#c.NPY_CPU_PPC", "type": "System configuration", "text": "\n\n"}, {"name": "NPY_CPU_PPC64", "path": "reference/c-api/config#c.NPY_CPU_PPC64", "type": "System configuration", "text": "\n\n"}, {"name": "NPY_CPU_S390", "path": "reference/c-api/config#c.NPY_CPU_S390", "type": "System configuration", "text": "\n\n"}, {"name": "NPY_CPU_SPARC", "path": "reference/c-api/config#c.NPY_CPU_SPARC", "type": "System configuration", "text": "\n\n"}, {"name": "NPY_CPU_SPARC64", "path": "reference/c-api/config#c.NPY_CPU_SPARC64", "type": "System configuration", "text": "\n\n"}, {"name": "NPY_CPU_UNKNOWN_ENDIAN", "path": "reference/c-api/config#c.PyArray_GetEndianness.NPY_CPU_UNKNOWN_ENDIAN", "type": "System configuration", "text": "\n\n"}, {"name": "NPY_DISABLE_C_API", "path": "reference/c-api/array#c.NPY_DISABLE_C_API", "type": "Array API", "text": "\nPlace after code that needs to call the Python C-API (to re-release the GIL).\n\n"}, {"name": "NPY_END_ALLOW_THREADS", "path": "reference/c-api/array#c.NPY_END_ALLOW_THREADS", "type": "Array API", "text": "\nEquivalent to `Py_END_ALLOW_THREADS` except it uses `NPY_ALLOW_THREADS` to\ndetermine if the macro if replaced with white-space or not.\n\n"}, {"name": "NPY_END_THREADS", "path": "reference/c-api/array#c.NPY_END_THREADS", "type": "Array API", "text": "\nPlace right after code that does not need the Python interpreter. This macro\nacquires the GIL and restores the Python state from the saved variable.\n\n"}, {"name": "NPY_EULER", "path": "reference/c-api/coremath#c.NPY_EULER", "type": "NumPy core libraries", "text": "\n\\\\(\\lim_{n\\rightarrow\\infty}({\\sum_{k=1}^n{\\frac{1}{k}}-\\ln n})\\\\)\n\n"}, {"name": "NPY_FAIL", "path": "reference/c-api/array#c.NPY_FAIL", "type": "Array API", "text": "\nThe return value of failed converter functions which are called using the \u201cO&\u201d\nsyntax in `PyArg_ParseTuple`-like functions.\n\n"}, {"name": "NPY_FALSE", "path": "reference/c-api/array#c.NPY_FALSE", "type": "Array API", "text": "\nDefined as 0 for use with Bool.\n\n"}, {"name": "NPY_FEATURE_VERSION", "path": "reference/c-api/array#c.NPY_FEATURE_VERSION", "type": "Array API", "text": "\nThe current version of the C-API.\n\n"}, {"name": "npy_half npy_double_to_half()", "path": "reference/c-api/coremath#c.npy_double_to_half", "type": "NumPy core libraries", "text": "\nConverts a double-precision float to a half-precision float. The value is\nrounded to the nearest representable half, with ties going to the nearest\neven. If the value is too small or too big, the system\u2019s floating point\nunderflow or overflow bit will be set.\n\n"}, {"name": "npy_half npy_float_to_half()", "path": "reference/c-api/coremath#c.npy_float_to_half", "type": "NumPy core libraries", "text": "\nConverts a single-precision float to a half-precision float. The value is\nrounded to the nearest representable half, with ties going to the nearest\neven. If the value is too small or too big, the system\u2019s floating point\nunderflow or overflow bit will be set.\n\n"}, {"name": "npy_half npy_half_copysign()", "path": "reference/c-api/coremath#c.npy_half_copysign", "type": "NumPy core libraries", "text": "\nReturns the value of x with the sign bit copied from y. Works for any value,\nincluding Inf and NaN.\n\n"}, {"name": "npy_half npy_half_nextafter()", "path": "reference/c-api/coremath#c.npy_half_nextafter", "type": "NumPy core libraries", "text": "\nThis is the same for half-precision float as npy_nextafter and npy_nextafterf\ndescribed in the low-level floating point section.\n\n"}, {"name": "npy_half npy_half_spacing()", "path": "reference/c-api/coremath#c.npy_half_spacing", "type": "NumPy core libraries", "text": "\nThis is the same for half-precision float as npy_spacing and npy_spacingf\ndescribed in the low-level floating point section.\n\n"}, {"name": "NPY_HALF_NAN", "path": "reference/c-api/coremath#c.NPY_HALF_NAN", "type": "NumPy core libraries", "text": "\nThis macro is defined to a NaN value, guaranteed to have its sign bit unset.\n\n"}, {"name": "NPY_HALF_NEGONE", "path": "reference/c-api/coremath#c.NPY_HALF_NEGONE", "type": "NumPy core libraries", "text": "\nThis macro is defined to -1.0.\n\n"}, {"name": "NPY_HALF_NINF", "path": "reference/c-api/coremath#c.NPY_HALF_NINF", "type": "NumPy core libraries", "text": "\nThis macro is defined to -inf.\n\n"}, {"name": "NPY_HALF_NZERO", "path": "reference/c-api/coremath#c.NPY_HALF_NZERO", "type": "NumPy core libraries", "text": "\nThis macro is defined to negative zero.\n\n"}, {"name": "NPY_HALF_ONE", "path": "reference/c-api/coremath#c.NPY_HALF_ONE", "type": "NumPy core libraries", "text": "\nThis macro is defined to 1.0.\n\n"}, {"name": "NPY_HALF_PINF", "path": "reference/c-api/coremath#c.NPY_HALF_PINF", "type": "NumPy core libraries", "text": "\nThis macro is defined to +inf.\n\n"}, {"name": "NPY_HALF_PZERO", "path": "reference/c-api/coremath#c.NPY_HALF_PZERO", "type": "NumPy core libraries", "text": "\nThis macro is defined to positive zero.\n\n"}, {"name": "npy_hash_t *hash", "path": "reference/c-api/types-and-structures#c.NPY_USE_SETITEM.hash", "type": "Python Types and C-Structures", "text": "\nCurrently unused. Reserved for future use in caching hash values.\n\n"}, {"name": "NPY_IGNORE", "path": "reference/c-api/array#c.NPY_IGNORE", "type": "Array API", "text": "\nIf a byteorder of `NPY_IGNORE` is encountered it is left alone. If newendian\nis `NPY_SWAP`, then all byte-orders are swapped. Other valid newendian values\nare `NPY_NATIVE`, `NPY_LITTLE`, and `NPY_BIG` which all cause the returned\ndata-typed descriptor (and all it\u2019s referenced data-type descriptors) to have\nthe corresponding byte- order.\n\n"}, {"name": "NPY_INFINITY", "path": "reference/c-api/coremath#c.NPY_INFINITY", "type": "NumPy core libraries", "text": "\nThis macro is defined to a positive inf. The corresponding single and\nextension precision macro are available with the suffix F and L.\n\n"}, {"name": "npy_int32 random_positive_int32()", "path": "reference/random/c-api#c.random_positive_int32", "type": "C API for random", "text": "\n\n"}, {"name": "npy_int64 random_binomial()", "path": "reference/random/c-api#c.random_binomial", "type": "C API for random", "text": "\n\n"}, {"name": "npy_int64 random_geometric()", "path": "reference/random/c-api#c.random_geometric", "type": "C API for random", "text": "\n\n"}, {"name": "npy_int64 random_geometric_inversion()", "path": "reference/random/c-api#c.random_geometric_inversion", "type": "C API for random", "text": "\n\n"}, {"name": "npy_int64 random_geometric_search()", "path": "reference/random/c-api#c.random_geometric_search", "type": "C API for random", "text": "\n\n"}, {"name": "npy_int64 random_hypergeometric()", "path": "reference/random/c-api#c.random_hypergeometric", "type": "C API for random", "text": "\n\n"}, {"name": "npy_int64 random_logseries()", "path": "reference/random/c-api#c.random_logseries", "type": "C API for random", "text": "\n\n"}, {"name": "npy_int64 random_negative_binomial()", "path": "reference/random/c-api#c.random_negative_binomial", "type": "C API for random", "text": "\n\n"}, {"name": "npy_int64 random_poisson()", "path": "reference/random/c-api#c.random_poisson", "type": "C API for random", "text": "\n\n"}, {"name": "npy_int64 random_positive_int()", "path": "reference/random/c-api#c.random_positive_int", "type": "C API for random", "text": "\n\n"}, {"name": "npy_int64 random_positive_int64()", "path": "reference/random/c-api#c.random_positive_int64", "type": "C API for random", "text": "\n\n"}, {"name": "npy_int64 random_zipf()", "path": "reference/random/c-api#c.random_zipf", "type": "C API for random", "text": "\n\n"}, {"name": "npy_intp *backstrides", "path": "reference/c-api/types-and-structures#c.PyArrayIterObject.backstrides", "type": "Python Types and C-Structures", "text": "\nHow many bytes needed to jump from the end of a dimension back to its\nbeginning. Note that `backstrides[k] == strides[k] * dims_m1[k]`, but it is\nstored here as an optimization.\n\n"}, {"name": "npy_intp *coordinates", "path": "reference/c-api/types-and-structures#c.PyArrayIterObject.coordinates", "type": "Python Types and C-Structures", "text": "\nAn \\\\(N\\\\) -dimensional index into the array.\n\n"}, {"name": "npy_intp *core_dim_sizes", "path": "reference/c-api/types-and-structures#c.PyUFuncObject.core_dim_sizes", "type": "Python Types and C-Structures", "text": "\nFor each distinct core dimension, the possible frozen size if\n`UFUNC_CORE_DIM_SIZE_INFERRED` is `0`\n\n"}, {"name": "npy_intp *dimensions", "path": "reference/c-api/types-and-structures#c.PyArrayMultiIterObject.dimensions", "type": "Python Types and C-Structures", "text": "\nThe shape of the broadcasted result (only `nd` slots are used).\n\n"}, {"name": "npy_intp *dims_m1", "path": "reference/c-api/types-and-structures#c.PyArrayIterObject.dims_m1", "type": "Python Types and C-Structures", "text": "\nThe size of the array minus 1 in each dimension.\n\n"}, {"name": "npy_intp *factors", "path": "reference/c-api/types-and-structures#c.PyArrayIterObject.factors", "type": "Python Types and C-Structures", "text": "\nThis array is used in computing an N-d index from a 1-d index. It contains\nneeded products of the dimensions.\n\n"}, {"name": "npy_intp *NpyIter_GetAxisStrideArray()", "path": "reference/c-api/iterator#c.NpyIter_GetAxisStrideArray", "type": "Array Iterator API", "text": "\nGets the array of strides for the specified axis. Requires that the iterator\nbe tracking a multi-index, and that buffering not be enabled.\n\nThis may be used when you want to match up operand axes in some fashion, then\nremove them with `NpyIter_RemoveAxis` to handle their processing manually. By\ncalling this function before removing the axes, you can get the strides for\nthe manual processing.\n\nReturns `NULL` on error.\n\n"}, {"name": "npy_intp *NpyIter_GetIndexPtr()", "path": "reference/c-api/iterator#c.NpyIter_GetIndexPtr", "type": "Array Iterator API", "text": "\nThis gives back a pointer to the index being tracked, or NULL if no index is\nbeing tracked. It is only usable if one of the flags `NPY_ITER_C_INDEX` or\n`NPY_ITER_F_INDEX` were specified during construction.\n\n"}, {"name": "npy_intp *NpyIter_GetInnerLoopSizePtr()", "path": "reference/c-api/iterator#c.NpyIter_GetInnerLoopSizePtr", "type": "Array Iterator API", "text": "\nReturns a pointer to the number of iterations the inner loop should execute.\n\nThis address may be cached before the iteration loop, calling `iternext` will\nnot change it. The value itself may change during iteration, in particular if\nbuffering is enabled. This function may be safely called without holding the\nPython GIL.\n\n"}, {"name": "npy_intp *NpyIter_GetInnerStrideArray()", "path": "reference/c-api/iterator#c.NpyIter_GetInnerStrideArray", "type": "Array Iterator API", "text": "\nReturns a pointer to an array of the `nop` strides, one for each iterated\nobject, to be used by the inner loop.\n\nThis pointer may be cached before the iteration loop, calling `iternext` will\nnot change it. This function may be safely called without holding the Python\nGIL.\n\nWARNING: While the pointer may be cached, its values may change if the\niterator is buffered.\n\n"}, {"name": "npy_intp *PyArray_DIMS()", "path": "reference/c-api/array#c.PyArray_DIMS", "type": "Array API", "text": "\nReturns a pointer to the dimensions/shape of the array. The number of elements\nmatches the number of dimensions of the array. Can return `NULL` for\n0-dimensional arrays.\n\n"}, {"name": "npy_intp *PyArray_SHAPE()", "path": "reference/c-api/array#c.PyArray_SHAPE", "type": "Array API", "text": "\nNew in version 1.7.\n\nA synonym for `PyArray_DIMS`, named to be consistent with the `shape` usage\nwithin Python.\n\n"}, {"name": "npy_intp *PyArray_STRIDES()", "path": "reference/c-api/array#c.PyArray_STRIDES", "type": "Array API", "text": "\nReturns a pointer to the strides of the array. The number of elements matches\nthe number of dimensions of the array.\n\n"}, {"name": "npy_intp *PyDimMem_NEW()", "path": "reference/c-api/array#c.PyDimMem_NEW", "type": "Array API", "text": "\n\n"}, {"name": "npy_intp *PyDimMem_RENEW()", "path": "reference/c-api/array#c.PyDimMem_RENEW", "type": "Array API", "text": "\nMacros to allocate, free, and reallocate dimension and strides memory.\n\n"}, {"name": "npy_intp *shape", "path": "reference/c-api/types-and-structures#c.PyArrayInterface.shape", "type": "Python Types and C-Structures", "text": "\nAn array containing the size of the array in each dimension.\n\n"}, {"name": "npy_intp *strides", "path": "reference/c-api/types-and-structures#c.NPY_AO.strides", "type": "Python Types and C-Structures", "text": "\nAn array of integers providing for each dimension the number of bytes that\nmust be skipped to get to the next element in that dimension. Associated with\nmacro `PyArray_STRIDES`.\n\n"}, {"name": "npy_intp *strides", "path": "reference/c-api/types-and-structures#c.PyArrayIterObject.strides", "type": "Python Types and C-Structures", "text": "\nThe strides of the array. How many bytes needed to jump to the next element in\neach dimension.\n\n"}, {"name": "npy_intp *strides", "path": "reference/c-api/types-and-structures#c.PyArrayInterface.strides", "type": "Python Types and C-Structures", "text": "\nAn array containing the number of bytes to jump to get to the next element in\neach dimension.\n\n"}, {"name": "npy_intp dimensions", "path": "reference/c-api/types-and-structures#c.NPY_AO.dimensions", "type": "Python Types and C-Structures", "text": "\nAn array of integers providing the shape in each dimension as long as nd\n\\\\(\\geq\\\\) 1\\. The integer is always large enough to hold a pointer on the\nplatform, so the dimension size is only limited by memory. `PyArray_DIMS` is\nthe macro associated with this data member.\n\n"}, {"name": "npy_intp index", "path": "reference/c-api/types-and-structures#c.PyArrayIterObject.index", "type": "Python Types and C-Structures", "text": "\nThe current 1-d index into the array.\n\n"}, {"name": "npy_intp index", "path": "reference/c-api/types-and-structures#c.PyArrayMultiIterObject.index", "type": "Python Types and C-Structures", "text": "\nThe current (1-d) index into the broadcasted result.\n\n"}, {"name": "npy_intp len", "path": "reference/c-api/types-and-structures#c.PyArray_Chunk.len", "type": "Python Types and C-Structures", "text": "\nThe length of the segment in bytes.\n\n"}, {"name": "npy_intp NpyIter_GetBufferSize()", "path": "reference/c-api/iterator#c.NpyIter_GetBufferSize", "type": "Array Iterator API", "text": "\nIf the iterator is buffered, returns the size of the buffer being used,\notherwise returns 0.\n\n"}, {"name": "npy_intp NpyIter_GetIterIndex()", "path": "reference/c-api/iterator#c.NpyIter_GetIterIndex", "type": "Array Iterator API", "text": "\nGets the `iterindex` of the iterator, which is an index matching the iteration\norder of the iterator.\n\n"}, {"name": "npy_intp NpyIter_GetIterSize()", "path": "reference/c-api/iterator#c.NpyIter_GetIterSize", "type": "Array Iterator API", "text": "\nReturns the number of elements being iterated. This is the product of all the\ndimensions in the shape. When a multi index is being tracked (and\n`NpyIter_RemoveAxis` may be called) the size may be `-1` to indicate an\niterator is too large. Such an iterator is invalid, but may become valid after\n`NpyIter_RemoveAxis` is called. It is not necessary to check for this case.\n\n"}, {"name": "npy_intp PyArray_CountNonzero()", "path": "reference/c-api/array#c.PyArray_CountNonzero", "type": "Array API", "text": "\nNew in version 1.6.\n\nCounts the number of non-zero elements in the array object self.\n\n"}, {"name": "npy_intp PyArray_DIM()", "path": "reference/c-api/array#c.PyArray_DIM", "type": "Array API", "text": "\nReturn the shape in the n \\\\(^{\\textrm{th}}\\\\) dimension.\n\n"}, {"name": "npy_intp PyArray_ITEMSIZE()", "path": "reference/c-api/array#c.PyArray_ITEMSIZE", "type": "Array API", "text": "\nReturn the itemsize for the elements of this array.\n\nNote that, in the old API that was deprecated in version 1.7, this function\nhad the return type `int`.\n\n"}, {"name": "npy_intp PyArray_MultiplyList()", "path": "reference/c-api/array#c.PyArray_MultiplyList", "type": "Array API", "text": "\n\n"}, {"name": "npy_intp PyArray_NBYTES()", "path": "reference/c-api/array#c.PyArray_NBYTES", "type": "Array API", "text": "\nReturns the total number of bytes consumed by the array.\n\n"}, {"name": "npy_intp PyArray_PyIntAsIntp()", "path": "reference/c-api/array#c.PyArray_PyIntAsIntp", "type": "Array API", "text": "\nConvert all kinds of Python objects (including arrays and array scalars) to a\n(platform-pointer-sized) integer. On error, -1 is returned and an exception\nset.\n\n"}, {"name": "npy_intp PyArray_REFCOUNT()", "path": "reference/c-api/array#c.PyArray_REFCOUNT", "type": "Array API", "text": "\nReturns the reference count of any Python object.\n\n"}, {"name": "npy_intp PyArray_Size()", "path": "reference/c-api/array#c.PyArray_Size", "type": "Array API", "text": "\nReturns 0 if obj is not a sub-class of ndarray. Otherwise, returns the total\nnumber of elements in the array. Safer version of `PyArray_SIZE` (obj).\n\n"}, {"name": "npy_intp PyArray_SIZE()", "path": "reference/c-api/array#c.PyArray_SIZE", "type": "Array API", "text": "\nReturns the total size (in number of elements) of the array.\n\n"}, {"name": "npy_intp PyArray_STRIDE()", "path": "reference/c-api/array#c.PyArray_STRIDE", "type": "Array API", "text": "\nReturn the stride in the n \\\\(^{\\textrm{th}}\\\\) dimension.\n\n"}, {"name": "npy_intp size", "path": "reference/c-api/types-and-structures#c.PyArrayIterObject.size", "type": "Python Types and C-Structures", "text": "\nThe total size of the underlying array.\n\n"}, {"name": "npy_intp size", "path": "reference/c-api/types-and-structures#c.PyArrayMultiIterObject.size", "type": "Python Types and C-Structures", "text": "\nThe total broadcasted size.\n\n"}, {"name": "NPY_INTP_FMT", "path": "reference/c-api/dtype#c.NPY_INTP_FMT", "type": "Data Type API", "text": "\n\n"}, {"name": "npy_isfinite()", "path": "reference/c-api/coremath#c.npy_isfinite", "type": "NumPy core libraries", "text": "\nThis is a macro, and is equivalent to C99 isfinite: works for single, double\nand extended precision, and return a non 0 value if x is neither a NaN nor an\ninfinity.\n\n"}, {"name": "npy_isinf()", "path": "reference/c-api/coremath#c.npy_isinf", "type": "NumPy core libraries", "text": "\nThis is a macro, and is equivalent to C99 isinf: works for single, double and\nextended precision, and return a non 0 value if x is infinite (positive and\nnegative).\n\n"}, {"name": "npy_isnan()", "path": "reference/c-api/coremath#c.npy_isnan", "type": "NumPy core libraries", "text": "\nThis is a macro, and is equivalent to C99 isnan: works for single, double and\nextended precision, and return a non 0 value if x is a NaN.\n\n"}, {"name": "NPY_ITEM_IS_POINTER", "path": "reference/c-api/types-and-structures#c.NPY_ITEM_IS_POINTER", "type": "Python Types and C-Structures", "text": "\nIndicates the item is a pointer to some other data-type\n\n"}, {"name": "NPY_ITEM_REFCOUNT", "path": "reference/c-api/types-and-structures#c.NPY_ITEM_REFCOUNT", "type": "Python Types and C-Structures", "text": "\nIndicates that items of this data-type must be reference counted (using\n`Py_INCREF` and `Py_DECREF` ).\n\nSame as `NPY_ITEM_REFCOUNT`.\n\n"}, {"name": "NPY_ITER_ALIGNED", "path": "reference/c-api/iterator#c.NPY_ITER_ALIGNED", "type": "Array Iterator API", "text": "\n\n"}, {"name": "NPY_ITER_ALLOCATE", "path": "reference/c-api/iterator#c.NPY_ITER_ALLOCATE", "type": "Array Iterator API", "text": "\nThis is for output arrays, and requires that the flag `NPY_ITER_WRITEONLY` or\n`NPY_ITER_READWRITE` be set. If `op[i]` is NULL, creates a new array with the\nfinal broadcast dimensions, and a layout matching the iteration order of the\niterator.\n\nWhen `op[i]` is NULL, the requested data type `op_dtypes[i]` may be NULL as\nwell, in which case it is automatically generated from the dtypes of the\narrays which are flagged as readable. The rules for generating the dtype are\nthe same is for UFuncs. Of special note is handling of byte order in the\nselected dtype. If there is exactly one input, the input\u2019s dtype is used as\nis. Otherwise, if more than one input dtypes are combined together, the output\nwill be in native byte order.\n\nAfter being allocated with this flag, the caller may retrieve the new array by\ncalling `NpyIter_GetOperandArray` and getting the i-th object in the returned\nC array. The caller must call Py_INCREF on it to claim a reference to the\narray.\n\n"}, {"name": "NPY_ITER_ARRAYMASK", "path": "reference/c-api/iterator#c.NPY_ITER_ARRAYMASK", "type": "Array Iterator API", "text": "\nNew in version 1.7.\n\nIndicates that this operand is the mask to use for selecting elements when\nwriting to operands which have the `NPY_ITER_WRITEMASKED` flag applied to\nthem. Only one operand may have `NPY_ITER_ARRAYMASK` flag applied to it.\n\nThe data type of an operand with this flag should be either `NPY_BOOL`,\n`NPY_MASK`, or a struct dtype whose fields are all valid mask dtypes. In the\nlatter case, it must match up with a struct operand being WRITEMASKED, as it\nis specifying a mask for each field of that array.\n\nThis flag only affects writing from the buffer back to the array. This means\nthat if the operand is also `NPY_ITER_READWRITE` or `NPY_ITER_WRITEONLY`, code\ndoing iteration can write to this operand to control which elements will be\nuntouched and which ones will be modified. This is useful when the mask should\nbe a combination of input masks.\n\n"}, {"name": "NPY_ITER_BUFFERED", "path": "reference/c-api/iterator#c.NPY_ITER_BUFFERED", "type": "Array Iterator API", "text": "\nCauses the iterator to store buffering data, and use buffering to satisfy data\ntype, alignment, and byte-order requirements. To buffer an operand, do not\nspecify the `NPY_ITER_COPY` or `NPY_ITER_UPDATEIFCOPY` flags, because they\nwill override buffering. Buffering is especially useful for Python code using\nthe iterator, allowing for larger chunks of data at once to amortize the\nPython interpreter overhead.\n\nIf used with `NPY_ITER_EXTERNAL_LOOP`, the inner loop for the caller may get\nlarger chunks than would be possible without buffering, because of how the\nstrides are laid out.\n\nNote that if an operand is given the flag `NPY_ITER_COPY` or\n`NPY_ITER_UPDATEIFCOPY`, a copy will be made in preference to buffering.\nBuffering will still occur when the array was broadcast so elements need to be\nduplicated to get a constant stride.\n\nIn normal buffering, the size of each inner loop is equal to the buffer size,\nor possibly larger if `NPY_ITER_GROWINNER` is specified. If\n`NPY_ITER_REDUCE_OK` is enabled and a reduction occurs, the inner loops may\nbecome smaller depending on the structure of the reduction.\n\n"}, {"name": "NPY_ITER_C_INDEX", "path": "reference/c-api/iterator#c.NPY_ITER_C_INDEX", "type": "Array Iterator API", "text": "\nCauses the iterator to track a raveled flat index matching C order. This\noption cannot be used with `NPY_ITER_F_INDEX`.\n\n"}, {"name": "NPY_ITER_COMMON_DTYPE", "path": "reference/c-api/iterator#c.NPY_ITER_COMMON_DTYPE", "type": "Array Iterator API", "text": "\nCauses the iterator to convert all the operands to a common data type,\ncalculated based on the ufunc type promotion rules. Copying or buffering must\nbe enabled.\n\nIf the common data type is known ahead of time, don\u2019t use this flag. Instead,\nset the requested dtype for all the operands.\n\n"}, {"name": "NPY_ITER_CONTIG", "path": "reference/c-api/iterator#c.NPY_ITER_CONTIG", "type": "Array Iterator API", "text": "\nCauses the iterator to provide data for `op[i]` that is in native byte order,\naligned according to the dtype requirements, contiguous, or any combination.\n\nBy default, the iterator produces pointers into the arrays provided, which may\nbe aligned or unaligned, and with any byte order. If copying or buffering is\nnot enabled and the operand data doesn\u2019t satisfy the constraints, an error\nwill be raised.\n\nThe contiguous constraint applies only to the inner loop, successive inner\nloops may have arbitrary pointer changes.\n\nIf the requested data type is in non-native byte order, the NBO flag overrides\nit and the requested data type is converted to be in native byte order.\n\n"}, {"name": "NPY_ITER_COPY", "path": "reference/c-api/iterator#c.NPY_ITER_COPY", "type": "Array Iterator API", "text": "\nAllow a copy of `op[i]` to be made if it does not meet the data type or\nalignment requirements as specified by the constructor flags and parameters.\n\n"}, {"name": "NPY_ITER_COPY_IF_OVERLAP", "path": "reference/c-api/iterator#c.NPY_ITER_COPY_IF_OVERLAP", "type": "Array Iterator API", "text": "\nIf any write operand has overlap with any read operand, eliminate all overlap\nby making temporary copies (enabling UPDATEIFCOPY for write operands, if\nnecessary). A pair of operands has overlap if there is a memory address that\ncontains data common to both arrays.\n\nBecause exact overlap detection has exponential runtime in the number of\ndimensions, the decision is made based on heuristics, which has false\npositives (needless copies in unusual cases) but has no false negatives.\n\nIf any read/write overlap exists, this flag ensures the result of the\noperation is the same as if all operands were copied. In cases where copies\nwould need to be made, the result of the computation may be undefined without\nthis flag!\n\nFlags that may be passed in `op_flags[i]`, where `0 <= i < nop`:\n\n"}, {"name": "NPY_ITER_DELAY_BUFALLOC", "path": "reference/c-api/iterator#c.NPY_ITER_DELAY_BUFALLOC", "type": "Array Iterator API", "text": "\nWhen buffering is enabled, this delays allocation of the buffers until\n`NpyIter_Reset` or another reset function is called. This flag exists to avoid\nwasteful copying of buffer data when making multiple copies of a buffered\niterator for multi-threaded iteration.\n\nAnother use of this flag is for setting up reduction operations. After the\niterator is created, and a reduction output is allocated automatically by the\niterator (be sure to use READWRITE access), its value may be initialized to\nthe reduction unit. Use `NpyIter_GetOperandArray` to get the object. Then,\ncall `NpyIter_Reset` to allocate and fill the buffers with their initial\nvalues.\n\n"}, {"name": "NPY_ITER_DONT_NEGATE_STRIDES", "path": "reference/c-api/iterator#c.NPY_ITER_DONT_NEGATE_STRIDES", "type": "Array Iterator API", "text": "\nThis only affects the iterator when `NPY_KEEPORDER` is specified for the order\nparameter. By default with `NPY_KEEPORDER`, the iterator reverses axes which\nhave negative strides, so that memory is traversed in a forward direction.\nThis disables this step. Use this flag if you want to use the underlying\nmemory-ordering of the axes, but don\u2019t want an axis reversed. This is the\nbehavior of `numpy.ravel(a, order='K')`, for instance.\n\n"}, {"name": "NPY_ITER_EXTERNAL_LOOP", "path": "reference/c-api/iterator#c.NPY_ITER_EXTERNAL_LOOP", "type": "Array Iterator API", "text": "\nCauses the iterator to skip iteration of the innermost loop, requiring the\nuser of the iterator to handle it.\n\nThis flag is incompatible with `NPY_ITER_C_INDEX`, `NPY_ITER_F_INDEX`, and\n`NPY_ITER_MULTI_INDEX`.\n\n"}, {"name": "NPY_ITER_F_INDEX", "path": "reference/c-api/iterator#c.NPY_ITER_F_INDEX", "type": "Array Iterator API", "text": "\nCauses the iterator to track a raveled flat index matching Fortran order. This\noption cannot be used with `NPY_ITER_C_INDEX`.\n\n"}, {"name": "NPY_ITER_GROWINNER", "path": "reference/c-api/iterator#c.NPY_ITER_GROWINNER", "type": "Array Iterator API", "text": "\nWhen buffering is enabled, this allows the size of the inner loop to grow when\nbuffering isn\u2019t necessary. This option is best used if you\u2019re doing a straight\npass through all the data, rather than anything with small cache-friendly\narrays of temporary values for each inner loop.\n\n"}, {"name": "NPY_ITER_MULTI_INDEX", "path": "reference/c-api/iterator#c.NPY_ITER_MULTI_INDEX", "type": "Array Iterator API", "text": "\nCauses the iterator to track a multi-index. This prevents the iterator from\ncoalescing axes to produce bigger inner loops. If the loop is also not\nbuffered and no index is being tracked (`NpyIter_RemoveAxis` can be called),\nthen the iterator size can be `-1` to indicate that the iterator is too large.\nThis can happen due to complex broadcasting and will result in errors being\ncreated when the setting the iterator range, removing the multi index, or\ngetting the next function. However, it is possible to remove axes again and\nuse the iterator normally if the size is small enough after removal.\n\n"}, {"name": "NPY_ITER_NBO", "path": "reference/c-api/iterator#c.NPY_ITER_NBO", "type": "Array Iterator API", "text": "\n\n"}, {"name": "NPY_ITER_NO_BROADCAST", "path": "reference/c-api/iterator#c.NPY_ITER_NO_BROADCAST", "type": "Array Iterator API", "text": "\nEnsures that the input or output matches the iteration dimensions exactly.\n\n"}, {"name": "NPY_ITER_NO_SUBTYPE", "path": "reference/c-api/iterator#c.NPY_ITER_NO_SUBTYPE", "type": "Array Iterator API", "text": "\nFor use with `NPY_ITER_ALLOCATE`, this flag disables allocating an array\nsubtype for the output, forcing it to be a straight ndarray.\n\nTODO: Maybe it would be better to introduce a function\n`NpyIter_GetWrappedOutput` and remove this flag?\n\n"}, {"name": "NPY_ITER_OVERLAP_ASSUME_ELEMENTWISE", "path": "reference/c-api/iterator#c.NPY_ITER_OVERLAP_ASSUME_ELEMENTWISE", "type": "Array Iterator API", "text": "\nIn memory overlap checks, assume that operands with\n`NPY_ITER_OVERLAP_ASSUME_ELEMENTWISE` enabled are accessed only in the\niterator order.\n\nThis enables the iterator to reason about data dependency, possibly avoiding\nunnecessary copies.\n\nThis flag has effect only if `NPY_ITER_COPY_IF_OVERLAP` is enabled on the\niterator.\n\n"}, {"name": "NPY_ITER_RANGED", "path": "reference/c-api/iterator#c.NPY_ITER_RANGED", "type": "Array Iterator API", "text": "\nEnables support for iteration of sub-ranges of the full `iterindex` range `[0,\nNpyIter_IterSize(iter))`. Use the function `NpyIter_ResetToIterIndexRange` to\nspecify a range for iteration.\n\nThis flag can only be used with `NPY_ITER_EXTERNAL_LOOP` when\n`NPY_ITER_BUFFERED` is enabled. This is because without buffering, the inner\nloop is always the size of the innermost iteration dimension, and allowing it\nto get cut up would require special handling, effectively making it more like\nthe buffered version.\n\n"}, {"name": "NPY_ITER_READONLY", "path": "reference/c-api/iterator#c.NPY_ITER_READONLY", "type": "Array Iterator API", "text": "\n\n"}, {"name": "NPY_ITER_READWRITE", "path": "reference/c-api/iterator#c.NPY_ITER_READWRITE", "type": "Array Iterator API", "text": "\n\n"}, {"name": "NPY_ITER_REDUCE_OK", "path": "reference/c-api/iterator#c.NPY_ITER_REDUCE_OK", "type": "Array Iterator API", "text": "\nPermits writeable operands with a dimension with zero stride and size greater\nthan one. Note that such operands must be read/write.\n\nWhen buffering is enabled, this also switches to a special buffering mode\nwhich reduces the loop length as necessary to not trample on values being\nreduced.\n\nNote that if you want to do a reduction on an automatically allocated output,\nyou must use `NpyIter_GetOperandArray` to get its reference, then set every\nvalue to the reduction unit before doing the iteration loop. In the case of a\nbuffered reduction, this means you must also specify the flag\n`NPY_ITER_DELAY_BUFALLOC`, then reset the iterator after initializing the\nallocated operand to prepare the buffers.\n\n"}, {"name": "NPY_ITER_REFS_OK", "path": "reference/c-api/iterator#c.NPY_ITER_REFS_OK", "type": "Array Iterator API", "text": "\nIndicates that arrays with reference types (object arrays or structured arrays\ncontaining an object type) may be accepted and used in the iterator. If this\nflag is enabled, the caller must be sure to check whether\nNpyIter_IterationNeedsAPI(iter) is true, in which case it may not release the\nGIL during iteration.\n\n"}, {"name": "NPY_ITER_UPDATEIFCOPY", "path": "reference/c-api/iterator#c.NPY_ITER_UPDATEIFCOPY", "type": "Array Iterator API", "text": "\nTriggers `NPY_ITER_COPY`, and when an array operand is flagged for writing and\nis copied, causes the data in a copy to be copied back to `op[i]` when\n`NpyIter_Deallocate` is called.\n\nIf the operand is flagged as write-only and a copy is needed, an uninitialized\ntemporary array will be created and then copied to back to `op[i]` on calling\n`NpyIter_Deallocate`, instead of doing the unnecessary copy operation.\n\n"}, {"name": "NPY_ITER_WRITEMASKED", "path": "reference/c-api/iterator#c.NPY_ITER_WRITEMASKED", "type": "Array Iterator API", "text": "\nNew in version 1.7.\n\nThis array is the mask for all `writemasked` operands. Code uses the\n`writemasked` flag which indicates that only elements where the chosen\nARRAYMASK operand is True will be written to. In general, the iterator does\nnot enforce this, it is up to the code doing the iteration to follow that\npromise.\n\nWhen `writemasked` flag is used, and this operand is buffered, this changes\nhow data is copied from the buffer into the array. A masked copying routine is\nused, which only copies the elements in the buffer for which `writemasked`\nreturns true from the corresponding element in the ARRAYMASK operand.\n\n"}, {"name": "NPY_ITER_WRITEONLY", "path": "reference/c-api/iterator#c.NPY_ITER_WRITEONLY", "type": "Array Iterator API", "text": "\nIndicate how the user of the iterator will read or write to `op[i]`. Exactly\none of these flags must be specified per operand. Using `NPY_ITER_READWRITE`\nor `NPY_ITER_WRITEONLY` for a user-provided operand may trigger\n`WRITEBACKIFCOPY`` semantics. The data will be written back to the original\narray when `NpyIter_Deallocate` is called.\n\n"}, {"name": "NPY_ITER_ZEROSIZE_OK", "path": "reference/c-api/iterator#c.NPY_ITER_ZEROSIZE_OK", "type": "Array Iterator API", "text": "\nIndicates that arrays with a size of zero should be permitted. Since the\ntypical iteration loop does not naturally work with zero-sized arrays, you\nmust check that the IterSize is larger than zero before entering the iteration\nloop. Currently only the operands are checked, not a forced shape.\n\n"}, {"name": "NPY_LIST_PICKLE", "path": "reference/c-api/types-and-structures#c.NPY_LIST_PICKLE", "type": "Python Types and C-Structures", "text": "\nIndicates arrays of this data-type must be converted to a list before\npickling.\n\n"}, {"name": "NPY_LITTLE", "path": "reference/c-api/array#c.NPY_LITTLE", "type": "Array API", "text": "\nIf a byteorder of `NPY_IGNORE` is encountered it is left alone. If newendian\nis `NPY_SWAP`, then all byte-orders are swapped. Other valid newendian values\nare `NPY_NATIVE`, `NPY_LITTLE`, and `NPY_BIG` which all cause the returned\ndata-typed descriptor (and all it\u2019s referenced data-type descriptors) to have\nthe corresponding byte- order.\n\n"}, {"name": "NPY_LITTLE_ENDIAN", "path": "reference/c-api/config#c.NPY_LITTLE_ENDIAN", "type": "System configuration", "text": "\n\n"}, {"name": "NPY_LOG10E", "path": "reference/c-api/coremath#c.NPY_LOG10E", "type": "NumPy core libraries", "text": "\nLogarithm to base 10 of the Euler constant (\\\\(\\frac{\\ln(e)}{\\ln(10)}\\\\))\n\n"}, {"name": "NPY_LOG2E", "path": "reference/c-api/coremath#c.NPY_LOG2E", "type": "NumPy core libraries", "text": "\nLogarithm to base 2 of the Euler constant (\\\\(\\frac{\\ln(e)}{\\ln(2)}\\\\))\n\n"}, {"name": "NPY_LOGE10", "path": "reference/c-api/coremath#c.NPY_LOGE10", "type": "NumPy core libraries", "text": "\nNatural logarithm of 10 (\\\\(\\ln(10)\\\\))\n\n"}, {"name": "NPY_LOGE2", "path": "reference/c-api/coremath#c.NPY_LOGE2", "type": "NumPy core libraries", "text": "\nNatural logarithm of 2 (\\\\(\\ln(2)\\\\))\n\n"}, {"name": "NPY_LONGDOUBLE_FMT", "path": "reference/c-api/dtype#c.NPY_LONGDOUBLE_FMT", "type": "Data Type API", "text": "\n\n"}, {"name": "NPY_LOOP_END_THREADS", "path": "reference/c-api/ufunc#c.NPY_LOOP_END_THREADS", "type": "UFunc API", "text": "\nUsed in universal function code to re-acquire the Python GIL if it was\nreleased (because loop->obj was not true).\n\n"}, {"name": "NPY_MAX_BUFSIZE", "path": "reference/c-api/array#c.NPY_MAX_BUFSIZE", "type": "Array API", "text": "\nLargest size allowed for the user-settable buffers.\n\n"}, {"name": "NPY_MAXARGS", "path": "reference/c-api/array#c.NPY_MAXARGS", "type": "Array API", "text": "\nThe maximum number of array arguments that can be used in functions.\n\n"}, {"name": "NPY_MAXDIMS", "path": "reference/c-api/array#c.NPY_MAXDIMS", "type": "Array API", "text": "\nThe maximum number of dimensions allowed in arrays.\n\n"}, {"name": "NPY_MIN_BUFSIZE", "path": "reference/c-api/array#c.NPY_MIN_BUFSIZE", "type": "Array API", "text": "\nSmallest size of user-settable internal buffers.\n\n"}, {"name": "NPY_NAN", "path": "reference/c-api/coremath", "type": "NumPy core libraries", "text": "\nNew in version 1.3.0.\n\nStarting from numpy 1.3.0, we are working on separating the pure C,\n\u201ccomputational\u201d code from the python dependent code. The goal is twofolds:\nmaking the code cleaner, and enabling code reuse by other extensions outside\nnumpy (scipy, etc\u2026).\n\nThe numpy core math library (\u2018npymath\u2019) is a first step in this direction.\nThis library contains most math-related C99 functionality, which can be used\non platforms where C99 is not well supported. The core math functions have the\nsame API as the C99 ones, except for the npy_* prefix.\n\nThe available functions are defined in <numpy/npy_math.h> \\- please refer to\nthis header when in doubt.\n\nThis macro is defined to a NaN (Not a Number), and is guaranteed to have the\nsignbit unset (\u2018positive\u2019 NaN). The corresponding single and extension\nprecision macro are available with the suffix F and L.\n\nThis macro is defined to a positive inf. The corresponding single and\nextension precision macro are available with the suffix F and L.\n\nThis macro is defined to positive zero. The corresponding single and extension\nprecision macro are available with the suffix F and L.\n\nThis macro is defined to negative zero (that is with the sign bit set). The\ncorresponding single and extension precision macro are available with the\nsuffix F and L.\n\nThis is a macro, and is equivalent to C99 isnan: works for single, double and\nextended precision, and return a non 0 value if x is a NaN.\n\nThis is a macro, and is equivalent to C99 isfinite: works for single, double\nand extended precision, and return a non 0 value if x is neither a NaN nor an\ninfinity.\n\nThis is a macro, and is equivalent to C99 isinf: works for single, double and\nextended precision, and return a non 0 value if x is infinite (positive and\nnegative).\n\nThis is a macro, and is equivalent to C99 signbit: works for single, double\nand extended precision, and return a non 0 value if x has the signbit set\n(that is the number is negative).\n\nThis is a function equivalent to C99 copysign: return x with the same sign as\ny. Works for any value, including inf and nan. Single and extended precisions\nare available with suffix f and l.\n\nNew in version 1.4.0.\n\nThe following math constants are available in `npy_math.h`. Single and\nextended precision are also available by adding the `f` and `l` suffixes\nrespectively.\n\nBase of natural logarithm (\\\\(e\\\\))\n\nLogarithm to base 2 of the Euler constant (\\\\(\\frac{\\ln(e)}{\\ln(2)}\\\\))\n\nLogarithm to base 10 of the Euler constant (\\\\(\\frac{\\ln(e)}{\\ln(10)}\\\\))\n\nNatural logarithm of 2 (\\\\(\\ln(2)\\\\))\n\nNatural logarithm of 10 (\\\\(\\ln(10)\\\\))\n\nPi (\\\\(\\pi\\\\))\n\nPi divided by 2 (\\\\(\\frac{\\pi}{2}\\\\))\n\nPi divided by 4 (\\\\(\\frac{\\pi}{4}\\\\))\n\nReciprocal of pi (\\\\(\\frac{1}{\\pi}\\\\))\n\nTwo times the reciprocal of pi (\\\\(\\frac{2}{\\pi}\\\\))\n\n\\\\(\\lim_{n\\rightarrow\\infty}({\\sum_{k=1}^n{\\frac{1}{k}}-\\ln n})\\\\)\n\nThose can be useful for precise floating point comparison.\n\nThis is a function equivalent to C99 nextafter: return next representable\nfloating point value from x in the direction of y. Single and extended\nprecisions are available with suffix f and l.\n\nNew in version 1.4.0.\n\nThis is a function equivalent to Fortran intrinsic. Return distance between x\nand next representable floating point value from x, e.g. spacing(1) == eps.\nspacing of nan and +/- inf return nan. Single and extended precisions are\navailable with suffix f and l.\n\nNew in version 1.4.0.\n\nSet the divide by zero floating point exception\n\nNew in version 1.6.0.\n\nSet the overflow floating point exception\n\nNew in version 1.6.0.\n\nSet the underflow floating point exception\n\nNew in version 1.6.0.\n\nSet the invalid floating point exception\n\nNew in version 1.6.0.\n\nGet floating point status. Returns a bitmask with following possible flags:\n\nNote that `npy_get_floatstatus_barrier` is preferable as it prevents\naggressive compiler optimizations reordering the call relative to the code\nsetting the status, which could lead to incorrect results.\n\nNew in version 1.9.0.\n\nGet floating point status. A pointer to a local variable is passed in to\nprevent aggressive compiler optimizations from reordering this function call\nrelative to the code setting the status, which could lead to incorrect\nresults.\n\nReturns a bitmask with following possible flags:\n\nNew in version 1.15.0.\n\nClears the floating point status. Returns the previous status mask.\n\nNote that `npy_clear_floatstatus_barrier` is preferable as it prevents\naggressive compiler optimizations reordering the call relative to the code\nsetting the status, which could lead to incorrect results.\n\nNew in version 1.9.0.\n\nClears the floating point status. A pointer to a local variable is passed in\nto prevent aggressive compiler optimizations from reordering this function\ncall. Returns the previous status mask.\n\nNew in version 1.15.0.\n\nNew in version 1.4.0.\n\nC99-like complex functions have been added. Those can be used if you wish to\nimplement portable C extensions. Since we still support platforms without C99\ncomplex type, you need to restrict to C90-compatible syntax, e.g.:\n\nNew in version 1.4.0.\n\nTo use the core math library in your own extension, you need to add the\nnpymath compile and link options to your extension in your setup.py:\n\nIn other words, the usage of info is exactly the same as when using blas_info\nand co.\n\nNew in version 1.6.0.\n\nThe header file <numpy/halffloat.h> provides functions to work with IEEE\n754-2008 16-bit floating point values. While this format is not typically used\nfor numerical computations, it is useful for storing values which require\nfloating point but do not need much precision. It can also be used as an\neducational tool to understand the nature of floating point round-off error.\n\nLike for other types, NumPy includes a typedef npy_half for the 16 bit float.\nUnlike for most of the other types, you cannot use this as a normal type in C,\nsince it is a typedef for npy_uint16. For example, 1.0 looks like 0x3c00 to C,\nand if you do an equality comparison between the different signed zeros, you\nwill get -0.0 != 0.0 (0x8000 != 0x0000), which is incorrect.\n\nFor these reasons, NumPy provides an API to work with npy_half values\naccessible by including <numpy/halffloat.h> and linking to \u2018npymath\u2019. For\nfunctions that are not provided directly, such as the arithmetic operations,\nthe preferred method is to convert to float or double and back again, as in\nthe following example.\n\nExternal Links:\n\nThis macro is defined to positive zero.\n\nThis macro is defined to positive zero.\n\nThis macro is defined to negative zero.\n\nThis macro is defined to 1.0.\n\nThis macro is defined to -1.0.\n\nThis macro is defined to +inf.\n\nThis macro is defined to -inf.\n\nThis macro is defined to a NaN value, guaranteed to have its sign bit unset.\n\nConverts a half-precision float to a single-precision float.\n\nConverts a half-precision float to a double-precision float.\n\nConverts a single-precision float to a half-precision float. The value is\nrounded to the nearest representable half, with ties going to the nearest\neven. If the value is too small or too big, the system\u2019s floating point\nunderflow or overflow bit will be set.\n\nConverts a double-precision float to a half-precision float. The value is\nrounded to the nearest representable half, with ties going to the nearest\neven. If the value is too small or too big, the system\u2019s floating point\nunderflow or overflow bit will be set.\n\nCompares two half-precision floats (h1 == h2).\n\nCompares two half-precision floats (h1 != h2).\n\nCompares two half-precision floats (h1 <= h2).\n\nCompares two half-precision floats (h1 < h2).\n\nCompares two half-precision floats (h1 >= h2).\n\nCompares two half-precision floats (h1 > h2).\n\nCompares two half-precision floats that are known to not be NaN (h1 == h2). If\na value is NaN, the result is undefined.\n\nCompares two half-precision floats that are known to not be NaN (h1 < h2). If\na value is NaN, the result is undefined.\n\nCompares two half-precision floats that are known to not be NaN (h1 <= h2). If\na value is NaN, the result is undefined.\n\nTests whether the half-precision float has a value equal to zero. This may be\nslightly faster than calling npy_half_eq(h, NPY_ZERO).\n\nTests whether the half-precision float is a NaN.\n\nTests whether the half-precision float is plus or minus Inf.\n\nTests whether the half-precision float is finite (not NaN or Inf).\n\nReturns 1 is h is negative, 0 otherwise.\n\nReturns the value of x with the sign bit copied from y. Works for any value,\nincluding Inf and NaN.\n\nThis is the same for half-precision float as npy_spacing and npy_spacingf\ndescribed in the low-level floating point section.\n\nThis is the same for half-precision float as npy_nextafter and npy_nextafterf\ndescribed in the low-level floating point section.\n\nLow-level function which converts a 32-bit single-precision float, stored as a\nuint32, into a 16-bit half-precision float.\n\nLow-level function which converts a 64-bit double-precision float, stored as a\nuint64, into a 16-bit half-precision float.\n\nLow-level function which converts a 16-bit half-precision float into a 32-bit\nsingle-precision float, stored as a uint32.\n\nLow-level function which converts a 16-bit half-precision float into a 64-bit\ndouble-precision float, stored as a uint64.\n\n"}, {"name": "NPY_NATIVE", "path": "reference/c-api/array#c.NPY_NATIVE", "type": "Array API", "text": "\nIf a byteorder of `NPY_IGNORE` is encountered it is left alone. If newendian\nis `NPY_SWAP`, then all byte-orders are swapped. Other valid newendian values\nare `NPY_NATIVE`, `NPY_LITTLE`, and `NPY_BIG` which all cause the returned\ndata-typed descriptor (and all it\u2019s referenced data-type descriptors) to have\nthe corresponding byte- order.\n\n"}, {"name": "NPY_NEEDS_INIT", "path": "reference/c-api/types-and-structures#c.NPY_NEEDS_INIT", "type": "Python Types and C-Structures", "text": "\nIndicates memory for this data-type must be initialized (set to 0) on\ncreation.\n\n"}, {"name": "NPY_NEEDS_PYAPI", "path": "reference/c-api/types-and-structures#c.NPY_NEEDS_PYAPI", "type": "Python Types and C-Structures", "text": "\nIndicates this data-type requires the Python C-API during access (so don\u2019t\ngive up the GIL if array access is going to be needed).\n\n"}, {"name": "NPY_NEIGHBORHOOD_ITER_CIRCULAR_PADDING", "path": "reference/c-api/array#c.PyArray_NeighborhoodIterNew.NPY_NEIGHBORHOOD_ITER_CIRCULAR_PADDING", "type": "Array API", "text": "\nCircular padding. Outside bounds values will be as if the array was repeated.\nFor example, for the array [1, 2, 3, 4], x[-2] will be 3, x[-2] will be 4,\nx[4] will be 1, x[5] will be 2, etc\u2026\n\n"}, {"name": "NPY_NEIGHBORHOOD_ITER_CONSTANT_PADDING", "path": "reference/c-api/array#c.PyArray_NeighborhoodIterNew.NPY_NEIGHBORHOOD_ITER_CONSTANT_PADDING", "type": "Array API", "text": "\nConstant padding. Outside bounds values will be the same as the first item in\nfill_value.\n\n"}, {"name": "NPY_NEIGHBORHOOD_ITER_MIRROR_PADDING", "path": "reference/c-api/array#c.PyArray_NeighborhoodIterNew.NPY_NEIGHBORHOOD_ITER_MIRROR_PADDING", "type": "Array API", "text": "\nMirror padding. Outside bounds values will be as if the array items were\nmirrored. For example, for the array [1, 2, 3, 4], x[-2] will be 2, x[-2] will\nbe 1, x[4] will be 4, x[5] will be 1, etc\u2026\n\n"}, {"name": "NPY_NEIGHBORHOOD_ITER_ONE_PADDING", "path": "reference/c-api/array#c.PyArray_NeighborhoodIterNew.NPY_NEIGHBORHOOD_ITER_ONE_PADDING", "type": "Array API", "text": "\nOne padding, Outside bounds values will be 1.\n\n"}, {"name": "NPY_NOTYPE", "path": "reference/c-api/dtype#c.NPY_NOTYPE", "type": "Data Type API", "text": "\nA signal value guaranteed not to be a valid type enumeration number.\n\n"}, {"name": "NPY_NTYPES", "path": "reference/c-api/dtype#c.NPY_NTYPES", "type": "Data Type API", "text": "\nThe total number of built-in NumPy types. The enumeration covers the range\nfrom 0 to NPY_NTYPES-1.\n\n"}, {"name": "NPY_NZERO", "path": "reference/c-api/coremath#c.NPY_NZERO", "type": "NumPy core libraries", "text": "\nThis macro is defined to negative zero (that is with the sign bit set). The\ncorresponding single and extension precision macro are available with the\nsuffix F and L.\n\n"}, {"name": "NPY_OBJECT_DTYPE_FLAGS", "path": "reference/c-api/types-and-structures#c.NPY_USE_SETITEM.NPY_OBJECT_DTYPE_FLAGS", "type": "Python Types and C-Structures", "text": "\nBits set for the object data-type: ( `NPY_LIST_PICKLE` | `NPY_USE_GETITEM` |\n`NPY_ITEM_IS_POINTER` | `NPY_ITEM_REFCOUNT` | `NPY_NEEDS_INIT` |\n`NPY_NEEDS_PYAPI`).\n\n"}, {"name": "NPY_OUT_ARRAY", "path": "reference/c-api/array#c.NPY_OUT_ARRAY", "type": "Array API", "text": "\n`NPY_ARRAY_C_CONTIGUOUS` | `NPY_ARRAY_WRITEABLE` | `NPY_ARRAY_ALIGNED`\n\n"}, {"name": "NPY_PI", "path": "reference/c-api/coremath#c.NPY_PI", "type": "NumPy core libraries", "text": "\nPi (\\\\(\\pi\\\\))\n\n"}, {"name": "NPY_PI_2", "path": "reference/c-api/coremath#c.NPY_PI_2", "type": "NumPy core libraries", "text": "\nPi divided by 2 (\\\\(\\frac{\\pi}{2}\\\\))\n\n"}, {"name": "NPY_PI_4", "path": "reference/c-api/coremath#c.NPY_PI_4", "type": "NumPy core libraries", "text": "\nPi divided by 4 (\\\\(\\frac{\\pi}{4}\\\\))\n\n"}, {"name": "NPY_PZERO", "path": "reference/c-api/coremath#c.NPY_PZERO", "type": "NumPy core libraries", "text": "\nThis macro is defined to positive zero. The corresponding single and extension\nprecision macro are available with the suffix F and L.\n\n"}, {"name": "NPY_SCALAR_PRIORITY", "path": "reference/c-api/array#c.NPY_SCALAR_PRIORITY", "type": "Array API", "text": "\nDefault scalar priority (very small)\n\n"}, {"name": "NPY_SCALARKIND PyArray_ScalarKind()", "path": "reference/c-api/array#c.PyArray_ScalarKind", "type": "Array API", "text": "\nSee the function `PyArray_MinScalarType` for an alternative mechanism\nintroduced in NumPy 1.6.0.\n\nReturn the kind of scalar represented by typenum and the array in *arr (if arr\nis not `NULL` ). The array is assumed to be rank-0 and only used if typenum\nrepresents a signed integer. If arr is not `NULL` and the first element is\nnegative then `NPY_INTNEG_SCALAR` is returned, otherwise `NPY_INTPOS_SCALAR`\nis returned. The possible return values are the enumerated values in\n`NPY_SCALARKIND`.\n\n"}, {"name": "NPY_SCALARKIND scalarkind()", "path": "reference/c-api/types-and-structures#c.PyArray_ArrFuncs.scalarkind", "type": "Python Types and C-Structures", "text": "\nA function to determine how scalars of this type should be interpreted. The\nargument is `NULL` or a 0-dimensional array containing the data (if that is\nneeded to determine the kind of scalar). The return value must be of type\n`NPY_SCALARKIND`.\n\n"}, {"name": "NPY_SIGINT_OFF", "path": "reference/c-api/config#c.NPY_SIGINT_OFF", "type": "System configuration", "text": "\n\n"}, {"name": "NPY_SIGINT_ON", "path": "reference/c-api/config#c.NPY_SIGINT_ON", "type": "System configuration", "text": "\n\n"}, {"name": "NPY_SIGJMP_BUF", "path": "reference/c-api/config#c.NPY_SIGJMP_BUF", "type": "System configuration", "text": "\n\n"}, {"name": "NPY_SIGLONGJMP", "path": "reference/c-api/config#c.NPY_SIGLONGJMP", "type": "System configuration", "text": "\n\n"}, {"name": "npy_signbit()", "path": "reference/c-api/coremath#c.npy_signbit", "type": "NumPy core libraries", "text": "\nThis is a macro, and is equivalent to C99 signbit: works for single, double\nand extended precision, and return a non 0 value if x has the signbit set\n(that is the number is negative).\n\n"}, {"name": "NPY_SIGSETJMP", "path": "reference/c-api/config#c.NPY_SIGSETJMP", "type": "System configuration", "text": "\n\n"}, {"name": "NPY_SIZEOF_DOUBLE", "path": "reference/c-api/config#c.NPY_SIZEOF_DOUBLE", "type": "System configuration", "text": "\nsizeof(double)\n\n"}, {"name": "NPY_SIZEOF_FLOAT", "path": "reference/c-api/config#c.NPY_SIZEOF_FLOAT", "type": "System configuration", "text": "\nsizeof(float)\n\n"}, {"name": "NPY_SIZEOF_INT", "path": "reference/c-api/config#c.NPY_SIZEOF_INT", "type": "System configuration", "text": "\nsizeof(int)\n\n"}, {"name": "NPY_SIZEOF_INTP", "path": "reference/c-api/config#c.NPY_SIZEOF_INTP", "type": "System configuration", "text": "\nSize of a pointer on this platform (sizeof(void *))\n\n"}, {"name": "NPY_SIZEOF_LONG", "path": "reference/c-api/config#c.NPY_SIZEOF_LONG", "type": "System configuration", "text": "\nsizeof(long)\n\n"}, {"name": "NPY_SIZEOF_LONG_DOUBLE", "path": "reference/c-api/config#c.NPY_SIZEOF_LONG_DOUBLE", "type": "System configuration", "text": "\n\n"}, {"name": "NPY_SIZEOF_LONGDOUBLE", "path": "reference/c-api/config#c.NPY_SIZEOF_LONGDOUBLE", "type": "System configuration", "text": "\nsizeof(longdouble)\n\n"}, {"name": "NPY_SIZEOF_LONGLONG", "path": "reference/c-api/config#c.NPY_SIZEOF_LONGLONG", "type": "System configuration", "text": "\nsizeof(longlong) where longlong is defined appropriately on the platform.\n\n"}, {"name": "NPY_SIZEOF_PY_INTPTR_T", "path": "reference/c-api/config#c.NPY_SIZEOF_PY_INTPTR_T", "type": "System configuration", "text": "\n\n"}, {"name": "NPY_SIZEOF_PY_LONG_LONG", "path": "reference/c-api/config#c.NPY_SIZEOF_PY_LONG_LONG", "type": "System configuration", "text": "\n\n"}, {"name": "NPY_SIZEOF_SHORT", "path": "reference/c-api/config", "type": "System configuration", "text": "\nWhen NumPy is built, information about system configuration is recorded, and\nis made available for extension modules using NumPy\u2019s C API. These are mostly\ndefined in `numpyconfig.h` (included in `ndarrayobject.h`). The public symbols\nare prefixed by `NPY_*`. NumPy also offers some functions for querying\ninformation about the platform in use.\n\nFor private use, NumPy also constructs a `config.h` in the NumPy include\ndirectory, which is not exported by NumPy (that is a python extension which\nuse the numpy C API will not see those symbols), to avoid namespace pollution.\n\nThe `NPY_SIZEOF_{CTYPE}` constants are defined so that sizeof information is\navailable to the pre-processor.\n\nsizeof(short)\n\nsizeof(int)\n\nsizeof(long)\n\nsizeof(longlong) where longlong is defined appropriately on the platform.\n\nsizeof(float)\n\nsizeof(double)\n\nsizeof(longdouble)\n\nSize of a pointer on this platform (sizeof(void *))\n\nNew in version 1.3.0.\n\nCPU architecture of the platform; only one of the above is defined.\n\nDefined in `numpy/npy_cpu.h`\n\nNew in version 1.3.0.\n\nPortable alternatives to the `endian.h` macros of GNU Libc. If big endian,\n`NPY_BYTE_ORDER` == `NPY_BIG_ENDIAN`, and similarly for little endian\narchitectures.\n\nDefined in `numpy/npy_endian.h`.\n\nNew in version 1.3.0.\n\nReturns the endianness of the current platform. One of `NPY_CPU_BIG`,\n`NPY_CPU_LITTLE`, or `NPY_CPU_UNKNOWN_ENDIAN`.\n\n"}, {"name": "NPY_SUBTYPE_PRIORITY", "path": "reference/c-api/array#c.NPY_SUBTYPE_PRIORITY", "type": "Array API", "text": "\nDefault subtype priority.\n\n"}, {"name": "NPY_SUCCEED", "path": "reference/c-api/array#c.NPY_SUCCEED", "type": "Array API", "text": "\nThe return value of successful converter functions which are called using the\n\u201cO&\u201d syntax in `PyArg_ParseTuple`-like functions.\n\n"}, {"name": "NPY_SWAP", "path": "reference/c-api/array#c.NPY_SWAP", "type": "Array API", "text": "\nIf a byteorder of `NPY_IGNORE` is encountered it is left alone. If newendian\nis `NPY_SWAP`, then all byte-orders are swapped. Other valid newendian values\nare `NPY_NATIVE`, `NPY_LITTLE`, and `NPY_BIG` which all cause the returned\ndata-typed descriptor (and all it\u2019s referenced data-type descriptors) to have\nthe corresponding byte- order.\n\n"}, {"name": "NPY_TRUE", "path": "reference/c-api/array#c.NPY_TRUE", "type": "Array API", "text": "\nDefined as 1 for use with Bool.\n\n"}, {"name": "npy_uint16 npy_doublebits_to_halfbits()", "path": "reference/c-api/coremath#c.npy_doublebits_to_halfbits", "type": "NumPy core libraries", "text": "\nLow-level function which converts a 64-bit double-precision float, stored as a\nuint64, into a 16-bit half-precision float.\n\n"}, {"name": "npy_uint16 npy_floatbits_to_halfbits()", "path": "reference/c-api/coremath#c.npy_floatbits_to_halfbits", "type": "NumPy core libraries", "text": "\nLow-level function which converts a 32-bit single-precision float, stored as a\nuint32, into a 16-bit half-precision float.\n\n"}, {"name": "npy_uint32 *core_dim_flags", "path": "reference/c-api/types-and-structures#c.PyUFuncObject.core_dim_flags", "type": "Python Types and C-Structures", "text": "\nFor each distinct core dimension, a set of `UFUNC_CORE_DIM*` flags\n\n"}, {"name": "npy_uint32 iter_flags", "path": "reference/c-api/types-and-structures#c.PyUFuncObject.iter_flags", "type": "Python Types and C-Structures", "text": "\nOverride the default nditer flags for the ufunc.\n\n"}, {"name": "npy_uint32 npy_halfbits_to_floatbits()", "path": "reference/c-api/coremath#c.npy_halfbits_to_floatbits", "type": "NumPy core libraries", "text": "\nLow-level function which converts a 16-bit half-precision float into a 32-bit\nsingle-precision float, stored as a uint32.\n\n"}, {"name": "npy_uint32 op_flags", "path": "reference/c-api/types-and-structures#c.PyUFuncObject.op_flags", "type": "Python Types and C-Structures", "text": "\nOverride the default operand flags for each ufunc operand.\n\n"}, {"name": "npy_uint64 npy_halfbits_to_doublebits()", "path": "reference/c-api/coremath#c.npy_halfbits_to_doublebits", "type": "NumPy core libraries", "text": "\nLow-level function which converts a 16-bit half-precision float into a 64-bit\ndouble-precision float, stored as a uint64.\n\n"}, {"name": "npy_uint64 random_bounded_uint64()", "path": "reference/random/c-api#c.random_bounded_uint64", "type": "C API for random", "text": "\n\n"}, {"name": "npy_uint64 random_interval()", "path": "reference/random/c-api#c.random_interval", "type": "C API for random", "text": "\n\n"}, {"name": "npy_uint64 random_uint()", "path": "reference/random/c-api#c.random_uint", "type": "C API for random", "text": "\n\n"}, {"name": "NPY_UINTP_FMT", "path": "reference/c-api/dtype#c.NPY_UINTP_FMT", "type": "Data Type API", "text": "\n\n"}, {"name": "NPY_ULONGLONG_FMT", "path": "reference/c-api/dtype#c.NPY_ULONGLONG_FMT", "type": "Data Type API", "text": "\n\n"}, {"name": "NPY_UNLIKELY", "path": "reference/c-api/config#c.NPY_UNLIKELY", "type": "System configuration", "text": "\n\n"}, {"name": "NPY_UNUSED", "path": "reference/c-api/config#c.NPY_UNUSED", "type": "System configuration", "text": "\n\n"}, {"name": "NPY_USE_GETITEM", "path": "reference/c-api/types-and-structures#c.NPY_USE_GETITEM", "type": "Python Types and C-Structures", "text": "\nOn array access use the `f->getitem` function pointer instead of the standard\nconversion to an array scalar. Must use if you don\u2019t define an array scalar to\ngo along with the data-type.\n\n"}, {"name": "NPY_USE_SETITEM", "path": "reference/c-api/types-and-structures#c.NPY_USE_SETITEM", "type": "Python Types and C-Structures", "text": "\nWhen creating a 0-d array from an array scalar use `f->setitem` instead of the\nstandard copy from an array scalar. Must use if you don\u2019t define an array\nscalar to go along with the data-type.\n\nThe bits that are inherited for the parent data-type if these bits are set in\nany field of the data-type. Currently ( `NPY_NEEDS_INIT` | `NPY_LIST_PICKLE` |\n`NPY_ITEM_REFCOUNT` | `NPY_NEEDS_PYAPI` ).\n\nBits set for the object data-type: ( `NPY_LIST_PICKLE` | `NPY_USE_GETITEM` |\n`NPY_ITEM_IS_POINTER` | `NPY_ITEM_REFCOUNT` | `NPY_NEEDS_INIT` |\n`NPY_NEEDS_PYAPI`).\n\nReturn true if all the given flags are set for the data-type object.\n\nEquivalent to `PyDataType_FLAGCHK` (dtype, `NPY_ITEM_REFCOUNT`).\n\nA number that uniquely identifies the data type. For new data-types, this\nnumber is assigned when the data-type is registered.\n\nFor data types that are always the same size (such as long), this holds the\nsize of the data type. For flexible data types where different arrays can have\na different elementsize, this should be 0.\n\nA number providing alignment information for this data type. Specifically, it\nshows how far from the start of a 2-element structure (whose first element is\na `char` ), the compiler places an item of this type: `offsetof(struct {char\nc; type v;}, v)`\n\nIf this is non- `NULL`, then this data-type descriptor is a C-style contiguous\narray of another data-type descriptor. In other-words, each element that this\ndescriptor describes is actually an array of some other base descriptor. This\nis most useful as the data-type descriptor for a field in another data-type\ndescriptor. The fields member should be `NULL` if this is non- `NULL` (the\nfields member of the base descriptor can be non- `NULL` however).\n\nThe data-type-descriptor object of the base-type.\n\nThe shape (always C-style contiguous) of the sub-array as a Python tuple.\n\nIf this is non-NULL, then this data-type-descriptor has fields described by a\nPython dictionary whose keys are names (and also titles if given) and whose\nvalues are tuples that describe the fields. Recall that a data-type-descriptor\nalways describes a fixed-length set of bytes. A field is a named sub-region of\nthat total, fixed-length collection. A field is described by a tuple composed\nof another data- type-descriptor and a byte offset. Optionally, the tuple may\ncontain a title which is normally a Python string. These tuples are placed in\nthis dictionary keyed by name (and also title if given).\n\nAn ordered tuple of field names. It is NULL if no field is defined.\n\nA pointer to a structure containing functions that the type needs to implement\ninternal features. These functions are not the same thing as the universal\nfunctions (ufuncs) described later. Their signatures can vary arbitrarily.\n\nMetadata about this dtype.\n\nMetadata specific to the C implementation of the particular dtype. Added for\nNumPy 1.7.0.\n\nCurrently unused. Reserved for future use in caching hash values.\n\n"}, {"name": "NPY_USERDEF", "path": "reference/c-api/dtype#c.NPY_USERDEF", "type": "Data Type API", "text": "\nThe start of type numbers used for Custom Data types.\n\n"}, {"name": "NPY_WRAP", "path": "reference/c-api/array#c.PyArray_Choose.NPY_WRAP", "type": "Array API", "text": "\nwrap values < 0 by adding len(op) and values >=len(op) by subtracting len(op)\nuntil they are in range;\n\n"}, {"name": "NpyAuxData *c_metadata", "path": "reference/c-api/types-and-structures#c.NPY_USE_SETITEM.c_metadata", "type": "Python Types and C-Structures", "text": "\nMetadata specific to the C implementation of the particular dtype. Added for\nNumPy 1.7.0.\n\n"}, {"name": "NpyAuxData *NPY_AUXDATA_CLONE()", "path": "reference/c-api/array#c.NPY_AUXDATA_CLONE", "type": "Array API", "text": "\nA macro which calls the auxdata\u2019s clone function appropriately, returning a\ndeep copy of the auxiliary data.\n\n"}, {"name": "NpyIter *NpyIter_AdvancedNew()", "path": "reference/c-api/iterator#c.NpyIter_AdvancedNew", "type": "Array Iterator API", "text": "\nExtends `NpyIter_MultiNew` with several advanced options providing more\ncontrol over broadcasting and buffering.\n\nIf -1/NULL values are passed to `oa_ndim`, `op_axes`, `itershape`, and\n`buffersize`, it is equivalent to `NpyIter_MultiNew`.\n\nThe parameter `oa_ndim`, when not zero or -1, specifies the number of\ndimensions that will be iterated with customized broadcasting. If it is\nprovided, `op_axes` must and `itershape` can also be provided. The `op_axes`\nparameter let you control in detail how the axes of the operand arrays get\nmatched together and iterated. In `op_axes`, you must provide an array of\n`nop` pointers to `oa_ndim`-sized arrays of type `npy_intp`. If an entry in\n`op_axes` is NULL, normal broadcasting rules will apply. In `op_axes[j][i]` is\nstored either a valid axis of `op[j]`, or -1 which means `newaxis`. Within\neach `op_axes[j]` array, axes may not be repeated. The following example is\nhow normal broadcasting applies to a 3-D array, a 2-D array, a 1-D array and a\nscalar.\n\nNote: Before NumPy 1.8 `oa_ndim == 0` was used for signalling that that\n``op_axes` and `itershape` are unused. This is deprecated and should be\nreplaced with -1. Better backward compatibility may be achieved by using\n`NpyIter_MultiNew` for this case.\n\nThe `itershape` parameter allows you to force the iterator to have a specific\niteration shape. It is an array of length `oa_ndim`. When an entry is\nnegative, its value is determined from the operands. This parameter allows\nautomatically allocated outputs to get additional dimensions which don\u2019t match\nup with any dimension of an input.\n\nIf `buffersize` is zero, a default buffer size is used, otherwise it specifies\nhow big of a buffer to use. Buffers which are powers of 2 such as 4096 or 8192\nare recommended.\n\nReturns NULL if there is an error, otherwise returns the allocated iterator.\n\n"}, {"name": "NpyIter *NpyIter_Copy()", "path": "reference/c-api/iterator#c.NpyIter_Copy", "type": "Array Iterator API", "text": "\nMakes a copy of the given iterator. This function is provided primarily to\nenable multi-threaded iteration of the data.\n\nTODO: Move this to a section about multithreaded iteration.\n\nThe recommended approach to multithreaded iteration is to first create an\niterator with the flags `NPY_ITER_EXTERNAL_LOOP`, `NPY_ITER_RANGED`,\n`NPY_ITER_BUFFERED`, `NPY_ITER_DELAY_BUFALLOC`, and possibly\n`NPY_ITER_GROWINNER`. Create a copy of this iterator for each thread (minus\none for the first iterator). Then, take the iteration index range `[0,\nNpyIter_GetIterSize(iter))` and split it up into tasks, for example using a\nTBB parallel_for loop. When a thread gets a task to execute, it then uses its\ncopy of the iterator by calling `NpyIter_ResetToIterIndexRange` and iterating\nover the full range.\n\nWhen using the iterator in multi-threaded code or in code not holding the\nPython GIL, care must be taken to only call functions which are safe in that\ncontext. `NpyIter_Copy` cannot be safely called without the Python GIL,\nbecause it increments Python references. The `Reset*` and some other functions\nmay be safely called by passing in the `errmsg` parameter as non-NULL, so that\nthe functions will pass back errors through it instead of setting a Python\nexception.\n\n`NpyIter_Deallocate` must be called for each copy.\n\n"}, {"name": "NpyIter *NpyIter_MultiNew()", "path": "reference/c-api/iterator#c.NpyIter_MultiNew", "type": "Array Iterator API", "text": "\nCreates an iterator for broadcasting the `nop` array objects provided in `op`,\nusing regular NumPy broadcasting rules.\n\nAny of the `NPY_ORDER` enum values may be passed to `order`. For efficient\niteration, `NPY_KEEPORDER` is the best option, and the other orders enforce\nthe particular iteration pattern. When using `NPY_KEEPORDER`, if you also want\nto ensure that the iteration is not reversed along an axis, you should pass\nthe flag `NPY_ITER_DONT_NEGATE_STRIDES`.\n\nAny of the `NPY_CASTING` enum values may be passed to `casting`. The values\ninclude `NPY_NO_CASTING`, `NPY_EQUIV_CASTING`, `NPY_SAFE_CASTING`,\n`NPY_SAME_KIND_CASTING`, and `NPY_UNSAFE_CASTING`. To allow the casts to\noccur, copying or buffering must also be enabled.\n\nIf `op_dtypes` isn\u2019t `NULL`, it specifies a data type or `NULL` for each\n`op[i]`.\n\nReturns NULL if there is an error, otherwise returns the allocated iterator.\n\nFlags that may be passed in `flags`, applying to the whole iterator, are:\n\n"}, {"name": "NpyIter_GetMultiIndexFunc *NpyIter_GetGetMultiIndex()", "path": "reference/c-api/iterator#c.NpyIter_GetGetMultiIndex", "type": "Array Iterator API", "text": "\nReturns a function pointer for getting the current multi-index of the\niterator. Returns NULL if the iterator is not tracking a multi-index. It is\nrecommended that this function pointer be cached in a local variable before\nthe iteration loop.\n\nReturns NULL if there is an error. If errmsg is non-NULL, no Python exception\nis set when `NPY_FAIL` is returned. Instead, *errmsg is set to an error\nmessage. When errmsg is non-NULL, the function may be safely called without\nholding the Python GIL.\n\n"}, {"name": "number.__class_getitem__()", "path": "reference/generated/numpy.number.__class_getitem__", "type": "numpy.number.__class_getitem__", "text": "\nmethod\n\nReturn a parametrized wrapper around the `number` type.\n\nNew in version 1.22.\n\nA parametrized `number` type.\n\nSee also\n\nType hinting generics in standard collections.\n\nThis method is only available for python 3.9 and later.\n\n"}, {"name": "NumPy and SWIG", "path": "reference/swig", "type": "NumPy and SWIG", "text": "\n\n"}, {"name": "NumPy benchmarks", "path": "benchmarking", "type": "NumPy benchmarks", "text": "\nBenchmarking NumPy with Airspeed Velocity.\n\nAirspeed Velocity manages building and Python virtualenvs by itself, unless\ntold otherwise. Some of the benchmarking features in `runtests.py` also tell\nASV to use the NumPy compiled by `runtests.py`. To run the benchmarks, you do\nnot need to install a development version of NumPy to your current Python\nenvironment.\n\nBefore beginning, ensure that airspeed velocity is installed. By default,\n`asv` ships with support for anaconda and virtualenv:\n\nAfter contributing new benchmarks, you should test them locally before\nsubmitting a pull request.\n\nTo run all benchmarks, navigate to the root NumPy directory at the command\nline and execute:\n\nwhere `--bench` activates the benchmark suite instead of the test suite. This\nbuilds NumPy and runs all available benchmarks defined in `benchmarks/`.\n(Note: this could take a while. Each benchmark is run multiple times to\nmeasure the distribution in execution times.)\n\nTo run benchmarks from a particular benchmark module, such as `bench_core.py`,\nsimply append the filename without the extension:\n\nTo run a benchmark defined in a class, such as `Mandelbrot` from\n`bench_avx.py`:\n\nCompare change in benchmark results to another version/commit/branch:\n\nAll of the commands above display the results in plain text in the console,\nand the results are not saved for comparison with future commits. For greater\ncontrol, a graphical view, and to have results saved for future comparison you\ncan run ASV commands (record results and generate HTML):\n\nMore on how to use `asv` can be found in ASV documentation Command-line help\nis available as usual via `asv --help` and `asv run --help`.\n\nSee ASV documentation for basics on how to write benchmarks.\n\nSome things to consider:\n\n"}, {"name": "NumPy C code explanations", "path": "dev/internals.code-explanations", "type": "Development", "text": "\nFanaticism consists of redoubling your efforts when you have forgotten your\naim. \u2014 George Santayana\n\nAn authority is a person who can tell you more about something than you really\ncare to know. \u2014 Unknown\n\nThis page attempts to explain the logic behind some of the new pieces of code.\nThe purpose behind these explanations is to enable somebody to be able to\nunderstand the ideas behind the implementation somewhat more easily than just\nstaring at the code. Perhaps in this way, the algorithms can be improved on,\nborrowed from, and/or optimized by more people.\n\nOne fundamental aspect of the `ndarray` is that an array is seen as a \u201cchunk\u201d\nof memory starting at some location. The interpretation of this memory depends\non the stride information. For each dimension in an \\\\(N\\\\)-dimensional array,\nan integer (stride) dictates how many bytes must be skipped to get to the next\nelement in that dimension. Unless you have a single-segment array, this stride\ninformation must be consulted when traversing through an array. It is not\ndifficult to write code that accepts strides, you just have to use `char*`\npointers because strides are in units of bytes. Keep in mind also that strides\ndo not have to be unit-multiples of the element size. Also, remember that if\nthe number of dimensions of the array is 0 (sometimes called a `rank-0`\narray), then the strides and dimensions variables are `NULL`.\n\nBesides the structural information contained in the strides and dimensions\nmembers of the `PyArrayObject`, the flags contain important information about\nhow the data may be accessed. In particular, the `NPY_ARRAY_ALIGNED` flag is\nset when the memory is on a suitable boundary according to the datatype array.\nEven if you have a contiguous chunk of memory, you cannot just assume it is\nsafe to dereference a datatype-specific pointer to an element. Only if the\n`NPY_ARRAY_ALIGNED` flag is set, this is a safe operation. On some platforms\nit will work but on others, like Solaris, it will cause a bus error. The\n`NPY_ARRAY_WRITEABLE` should also be ensured if you plan on writing to the\nmemory area of the array. It is also possible to obtain a pointer to an\nunwritable memory area. Sometimes, writing to the memory area when the\n`NPY_ARRAY_WRITEABLE` flag is not set will just be rude. Other times it can\ncause program crashes (e.g. a data-area that is a read-only memory-mapped\nfile).\n\nSee also\n\nData type objects (dtype)\n\nThe datatype is an important abstraction of the `ndarray`. Operations will\nlook to the datatype to provide the key functionality that is needed to\noperate on the array. This functionality is provided in the list of function\npointers pointed to by the `f` member of the `PyArray_Descr` structure. In\nthis way, the number of datatypes can be extended simply by providing a\n`PyArray_Descr` structure with suitable function pointers in the `f` member.\nFor built-in types, there are some optimizations that bypass this mechanism,\nbut the point of the datatype abstraction is to allow new datatypes to be\nadded.\n\nOne of the built-in datatypes, the `void` datatype allows for arbitrary\nstructured types containing 1 or more fields as elements of the array. A field\nis simply another datatype object along with an offset into the current\nstructured type. In order to support arbitrarily nested fields, several\nrecursive implementations of datatype access are implemented for the void\ntype. A common idiom is to cycle through the elements of the dictionary and\nperform a specific operation based on the datatype object stored at the given\noffset. These offsets can be arbitrary numbers. Therefore, the possibility of\nencountering misaligned data must be recognized and taken into account if\nnecessary.\n\nSee also\n\nIterating Over Arrays\n\nA very common operation in much of NumPy code is the need to iterate over all\nthe elements of a general, strided, N-dimensional array. This operation of a\ngeneral-purpose N-dimensional loop is abstracted in the notion of an iterator\nobject. To write an N-dimensional loop, you only have to create an iterator\nobject from an ndarray, work with the `dataptr` member of the iterator object\nstructure and call the macro `PyArray_ITER_NEXT` on the iterator object to\nmove to the next element. The `next` element is always in C-contiguous order.\nThe macro works by first special-casing the C-contiguous, 1-D, and 2-D cases\nwhich work very simply.\n\nFor the general case, the iteration works by keeping track of a list of\ncoordinate counters in the iterator object. At each iteration, the last\ncoordinate counter is increased (starting from 0). If this counter is smaller\nthan one less than the size of the array in that dimension (a pre-computed and\nstored value), then the counter is increased and the `dataptr` member is\nincreased by the strides in that dimension and the macro ends. If the end of a\ndimension is reached, the counter for the last dimension is reset to zero and\nthe `dataptr` is moved back to the beginning of that dimension by subtracting\nthe strides value times one less than the number of elements in that dimension\n(this is also pre-computed and stored in the `backstrides` member of the\niterator object). In this case, the macro does not end, but a local dimension\ncounter is decremented so that the next-to-last dimension replaces the role\nthat the last dimension played and the previously-described tests are executed\nagain on the next-to-last dimension. In this way, the `dataptr` is adjusted\nappropriately for arbitrary striding.\n\nThe `coordinates` member of the `PyArrayIterObject` structure maintains the\ncurrent N-d counter unless the underlying array is C-contiguous in which case\nthe coordinate counting is bypassed. The `index` member of the\n`PyArrayIterObject` keeps track of the current flat index of the iterator. It\nis updated by the `PyArray_ITER_NEXT` macro.\n\nSee also\n\nBroadcasting\n\nIn Numeric, the ancestor of NumPy, broadcasting was implemented in several\nlines of code buried deep in `ufuncobject.c`. In NumPy, the notion of\nbroadcasting has been abstracted so that it can be performed in multiple\nplaces. Broadcasting is handled by the function `PyArray_Broadcast`. This\nfunction requires a `PyArrayMultiIterObject` (or something that is a binary\nequivalent) to be passed in. The `PyArrayMultiIterObject` keeps track of the\nbroadcast number of dimensions and size in each dimension along with the total\nsize of the broadcast result. It also keeps track of the number of arrays\nbeing broadcast and a pointer to an iterator for each of the arrays being\nbroadcast.\n\nThe `PyArray_Broadcast` function takes the iterators that have already been\ndefined and uses them to determine the broadcast shape in each dimension (to\ncreate the iterators at the same time that broadcasting occurs then use the\n`PyArray_MultiIterNew` function). Then, the iterators are adjusted so that\neach iterator thinks it is iterating over an array with the broadcast size.\nThis is done by adjusting the iterators number of dimensions, and the shape in\neach dimension. This works because the iterator strides are also adjusted.\nBroadcasting only adjusts (or adds) length-1 dimensions. For these dimensions,\nthe strides variable is simply set to 0 so that the data-pointer for the\niterator over that array doesn\u2019t move as the broadcasting operation operates\nover the extended dimension.\n\nBroadcasting was always implemented in Numeric using 0-valued strides for the\nextended dimensions. It is done in exactly the same way in NumPy. The big\ndifference is that now the array of strides is kept track of in a\n`PyArrayIterObject`, the iterators involved in a broadcast result are kept\ntrack of in a `PyArrayMultiIterObject`, and the `PyArray_Broadcast` call\nimplements the General Broadcasting Rules.\n\nSee also\n\nScalars\n\nThe array scalars offer a hierarchy of Python types that allow a one-to-one\ncorrespondence between the datatype stored in an array and the Python-type\nthat is returned when an element is extracted from the array. An exception to\nthis rule was made with object arrays. Object arrays are heterogeneous\ncollections of arbitrary Python objects. When you select an item from an\nobject array, you get back the original Python object (and not an object array\nscalar which does exist but is rarely used for practical purposes).\n\nThe array scalars also offer the same methods and attributes as arrays with\nthe intent that the same code can be used to support arbitrary dimensions\n(including 0-dimensions). The array scalars are read-only (immutable) with the\nexception of the void scalar which can also be written to so that structured\narray field setting works more naturally (`a[0]['f1'] = value`).\n\nSee also\n\nIndexing on ndarrays, Indexing routines\n\nAll Python indexing operations `arr[index]` are organized by first preparing\nthe index and finding the index type. The supported index types are:\n\nAs well as the scalar array special case signaling that an integer array was\ninterpreted as an integer index, which is important because an integer array\nindex forces a copy but is ignored if a scalar is returned (full integer\nindex). The prepared index is guaranteed to be valid with the exception of out\nof bound values and broadcasting errors for advanced indexing. This includes\nthat an `Ellipsis` is added for incomplete indices for example when a two-\ndimensional array is indexed with a single integer.\n\nThe next step depends on the type of index which was found. If all dimensions\nare indexed with an integer a scalar is returned or set. A single boolean\nindexing array will call specialized boolean functions. Indices containing an\n`Ellipsis` or slice but no advanced indexing will always create a view into\nthe old array by calculating the new strides and memory offset. This view can\nthen either be returned or, for assignments, filled using\n`PyArray_CopyObject`. Note that `PyArray_CopyObject` may also be called on\ntemporary arrays in other branches to support complicated assignments when the\narray is of object `dtype`.\n\nBy far the most complex case is advanced indexing, which may or may not be\ncombined with typical view-based indexing. Here integer indices are\ninterpreted as view-based. Before trying to understand this, you may want to\nmake yourself familiar with its subtleties. The advanced indexing code has\nthree different branches and one special case:\n\nDeciding what case applies, checking broadcasting, and determining the kind of\ntransposition needed are all done in `PyArray_MapIterNew`. After setting up,\nthere are two cases. If there is no subarray or it only has one element, no\nsubarray iteration is necessary and an iterator is prepared which iterates all\nindexing arrays as well as the result or value array. If there is a subarray,\nthere are three iterators prepared. One for the indexing arrays, one for the\nresult or value array (minus its subarray), and one for the subarrays of the\noriginal and the result/assignment array. The first two iterators give (or\nallow calculation) of the pointers into the start of the subarray, which then\nallows restarting the subarray iteration.\n\nWhen advanced indices are next to each other transposing may be necessary. All\nnecessary transposing is handled by `PyArray_MapIterSwapAxes` and has to be\nhandled by the caller unless `PyArray_MapIterNew` is asked to allocate the\nresult.\n\nAfter preparation, getting and setting are relatively straightforward,\nalthough the different modes of iteration need to be considered. Unless there\nis only a single indexing array during item getting, the validity of the\nindices is checked beforehand. Otherwise, it is handled in the inner loop\nitself for optimization.\n\nSee also\n\nUniversal functions (ufunc), Universal functions (ufunc) basics\n\nUniversal functions are callable objects that take \\\\(N\\\\) inputs and produce\n\\\\(M\\\\) outputs by wrapping basic 1-D loops that work element-by-element into\nfull easy-to-use functions that seamlessly implement broadcasting, type-\nchecking, buffered coercion, and output-argument handling. New universal\nfunctions are normally created in C, although there is a mechanism for\ncreating ufuncs from Python functions (`frompyfunc`). The user must supply a\n1-D loop that implements the basic function taking the input scalar values and\nplacing the resulting scalars into the appropriate output slots as explained\nin implementation.\n\nEvery `ufunc` calculation involves some overhead related to setting up the\ncalculation. The practical significance of this overhead is that even though\nthe actual calculation of the ufunc is very fast, you will be able to write\narray and type-specific code that will work faster for small arrays than the\nufunc. In particular, using ufuncs to perform many calculations on 0-D arrays\nwill be slower than other Python-based solutions (the silently-imported\n`scalarmath` module exists precisely to give array scalars the look-and-feel\nof ufunc based calculations with significantly reduced overhead).\n\nWhen a `ufunc` is called, many things must be done. The information collected\nfrom these setup operations is stored in a loop object. This loop object is a\nC-structure (that could become a Python object but is not initialized as such\nbecause it is only used internally). This loop object has the layout needed to\nbe used with `PyArray_Broadcast` so that the broadcasting can be handled in\nthe same way as it is handled in other sections of code.\n\nThe first thing done is to look up in the thread-specific global dictionary\nthe current values for the buffer-size, the error mask, and the associated\nerror object. The state of the error mask controls what happens when an error\ncondition is found. It should be noted that checking of the hardware error\nflags is only performed after each 1-D loop is executed. This means that if\nthe input and output arrays are contiguous and of the correct type so that a\nsingle 1-D loop is performed, then the flags may not be checked until all\nelements of the array have been calculated. Looking up these values in a\nthread-specific dictionary takes time which is easily ignored for all but very\nsmall arrays.\n\nAfter checking, the thread-specific global variables, the inputs are evaluated\nto determine how the ufunc should proceed and the input and output arrays are\nconstructed if necessary. Any inputs which are not arrays are converted to\narrays (using context if necessary). Which of the inputs are scalars (and\ntherefore converted to 0-D arrays) is noted.\n\nNext, an appropriate 1-D loop is selected from the 1-D loops available to the\n`ufunc` based on the input array types. This 1-D loop is selected by trying to\nmatch the signature of the datatypes of the inputs against the available\nsignatures. The signatures corresponding to built-in types are stored in the\n`ufunc.types` member of the ufunc structure. The signatures corresponding to\nuser-defined types are stored in a linked list of function information with\nthe head element stored as a `CObject` in the `userloops` dictionary keyed by\nthe datatype number (the first user-defined type in the argument list is used\nas the key). The signatures are searched until a signature is found to which\nthe input arrays can all be cast safely (ignoring any scalar arguments which\nare not allowed to determine the type of the result). The implication of this\nsearch procedure is that \u201clesser types\u201d should be placed below \u201clarger types\u201d\nwhen the signatures are stored. If no 1-D loop is found, then an error is\nreported. Otherwise, the `argument_list` is updated with the stored signature\n\u2014 in case casting is necessary and to fix the output types assumed by the 1-D\nloop.\n\nIf the ufunc has 2 inputs and 1 output and the second input is an `Object`\narray then a special-case check is performed so that `NotImplemented` is\nreturned if the second input is not an ndarray, has the `__array_priority__`\nattribute, and has an `__r{op}__` special method. In this way, Python is\nsignaled to give the other object a chance to complete the operation instead\nof using generic object-array calculations. This allows (for example) sparse\nmatrices to override the multiplication operator 1-D loop.\n\nFor input arrays that are smaller than the specified buffer size, copies are\nmade of all non-contiguous, misaligned, or out-of-byteorder arrays to ensure\nthat for small arrays, a single loop is used. Then, array iterators are\ncreated for all the input arrays and the resulting collection of iterators is\nbroadcast to a single shape.\n\nThe output arguments (if any) are then processed and any missing return arrays\nare constructed. If any provided output array doesn\u2019t have the correct type\n(or is misaligned) and is smaller than the buffer size, then a new output\narray is constructed with the special `NPY_ARRAY_WRITEBACKIFCOPY` flag set. At\nthe end of the function, `PyArray_ResolveWritebackIfCopy` is called so that\nits contents will be copied back into the output array. Iterators for the\noutput arguments are then processed.\n\nFinally, the decision is made about how to execute the looping mechanism to\nensure that all elements of the input arrays are combined to produce the\noutput arrays of the correct type. The options for loop execution are one-loop\n(for :term`contiguous`, aligned, and correct data type), strided-loop (for\nnon-contiguous but still aligned and correct data type), and a buffered loop\n(for misaligned or incorrect data type situations). Depending on which\nexecution method is called for, the loop is then set up and computed.\n\nThis section describes how the basic universal function computation loop is\nset up and executed for each of the three different kinds of execution. If\n`NPY_ALLOW_THREADS` is defined during compilation, then as long as no object\narrays are involved, the Python Global Interpreter Lock (GIL) is released\nprior to calling the loops. It is re-acquired if necessary to handle error\nconditions. The hardware error flags are checked only after the 1-D loop is\ncompleted.\n\nThis is the simplest case of all. The ufunc is executed by calling the\nunderlying 1-D loop exactly once. This is possible only when we have aligned\ndata of the correct type (including byteorder) for both input and output and\nall arrays have uniform strides (either contiguous, 0-D, or 1-D). In this\ncase, the 1-D computational loop is called once to compute the calculation for\nthe entire array. Note that the hardware error flags are only checked after\nthe entire calculation is complete.\n\nWhen the input and output arrays are aligned and of the correct type, but the\nstriding is not uniform (non-contiguous and 2-D or larger), then a second\nlooping structure is employed for the calculation. This approach converts all\nof the iterators for the input and output arguments to iterate over all but\nthe largest dimension. The inner loop is then handled by the underlying 1-D\ncomputational loop. The outer loop is a standard iterator loop on the\nconverted iterators. The hardware error flags are checked after each 1-D loop\nis completed.\n\nThis is the code that handles the situation whenever the input and/or output\narrays are either misaligned or of the wrong datatype (including being\nbyteswapped) from what the underlying 1-D loop expects. The arrays are also\nassumed to be non-contiguous. The code works very much like the strided-loop\nexcept for the inner 1-D loop is modified so that pre-processing is performed\non the inputs and post-processing is performed on the outputs in `bufsize`\nchunks (where `bufsize` is a user-settable parameter). The underlying 1-D\ncomputational loop is called on data that is copied over (if it needs to be).\nThe setup code and the loop code is considerably more complicated in this case\nbecause it has to handle:\n\nAgain, the hardware error flags are checked at the end of each 1-D loop.\n\nUfuncs allow other array-like classes to be passed seamlessly through the\ninterface in that inputs of a particular class will induce the outputs to be\nof that same class. The mechanism by which this works is the following. If any\nof the inputs are not ndarrays and define the `__array_wrap__` method, then\nthe class with the largest `__array_priority__` attribute determines the type\nof all the outputs (with the exception of any output arrays passed in). The\n`__array_wrap__` method of the input array will be called with the ndarray\nbeing returned from the ufunc as its input. There are two calling styles of\nthe `__array_wrap__` function supported. The first takes the ndarray as the\nfirst argument and a tuple of \u201ccontext\u201d as the second argument. The context is\n(ufunc, arguments, output argument number). This is the first call tried. If a\n`TypeError` occurs, then the function is called with just the ndarray as the\nfirst argument.\n\nThere are three methods of ufuncs that require calculation similar to the\ngeneral-purpose ufuncs. These are `ufunc.reduce`, `ufunc.accumulate`, and\n`ufunc.reduceat`. Each of these methods requires a setup command followed by a\nloop. There are four loop styles possible for the methods corresponding to no-\nelements, one-element, strided-loop, and buffered-loop. These are the same\nbasic loop styles as implemented for the general-purpose function call except\nfor the no-element and one-element cases which are special-cases occurring\nwhen the input array objects have 0 and 1 elements respectively.\n\nThe setup function for all three methods is `construct_reduce`. This function\ncreates a reducing loop object and fills it with the parameters needed to\ncomplete the loop. All of the methods only work on ufuncs that take 2-inputs\nand return 1 output. Therefore, the underlying 1-D loop is selected assuming a\nsignature of `[otype, otype, otype]` where `otype` is the requested reduction\ndatatype. The buffer size and error handling are then retrieved from (per-\nthread) global storage. For small arrays that are misaligned or have incorrect\ndatatype, a copy is made so that the un-buffered section of code is used.\nThen, the looping strategy is selected. If there is 1 element or 0 elements in\nthe array, then a simple looping method is selected. If the array is not\nmisaligned and has the correct datatype, then strided looping is selected.\nOtherwise, buffered looping must be performed. Looping parameters are then\nestablished, and the return array is constructed. The output array is of a\ndifferent shape depending on whether the method is `reduce`, `accumulate`, or\n`reduceat`. If an output array is already provided, then its shape is checked.\nIf the output array is not C-contiguous, aligned, and of the correct data\ntype, then a temporary copy is made with the `NPY_ARRAY_WRITEBACKIFCOPY` flag\nset. In this way, the methods will be able to work with a well-behaved output\narray but the result will be copied back into the true output array when\n`PyArray_ResolveWritebackIfCopy` is called at function completion. Finally,\niterators are set up to loop over the correct axis (depending on the value of\naxis provided to the method) and the setup routine returns to the actual\ncomputation routine.\n\nAll of the ufunc methods use the same underlying 1-D computational loops with\ninput and output arguments adjusted so that the appropriate reduction takes\nplace. For example, the key to the functioning of `reduce` is that the 1-D\nloop is called with the output and the second input pointing to the same\nposition in memory and both having a step-size of 0. The first input is\npointing to the input array with a step-size given by the appropriate stride\nfor the selected axis. In this way, the operation performed is\n\nwhere \\\\(N+1\\\\) is the number of elements in the input, \\\\(i\\\\), \\\\(o\\\\) is\nthe output, and \\\\(i[k]\\\\) is the \\\\(k^{\\textrm{th}}\\\\) element of \\\\(i\\\\)\nalong the selected axis. This basic operation is repeated for arrays with\ngreater than 1 dimension so that the reduction takes place for every 1-D sub-\narray along the selected axis. An iterator with the selected dimension removed\nhandles this looping.\n\nFor buffered loops, care must be taken to copy and cast data before the loop\nfunction is called because the underlying loop expects aligned data of the\ncorrect datatype (including byteorder). The buffered loop must handle this\ncopying and casting prior to calling the loop function on chunks no greater\nthan the user-specified `bufsize`.\n\nThe `accumulate` method is very similar to the `reduce` method in that the\noutput and the second input both point to the output. The difference is that\nthe second input points to memory one stride behind the current output\npointer. Thus, the operation performed is\n\nThe output has the same shape as the input and each 1-D loop operates over\n\\\\(N\\\\) elements when the shape in the selected axis is \\\\(N+1\\\\). Again,\nbuffered loops take care to copy and cast the data before calling the\nunderlying 1-D computational loop.\n\nThe `reduceat` function is a generalization of both the `reduce` and\n`accumulate` functions. It implements a `reduce` over ranges of the input\narray specified by indices. The extra indices argument is checked to be sure\nthat every input is not too large for the input array along the selected\ndimension before the loop calculations take place. The loop implementation is\nhandled using code that is very similar to the `reduce` code repeated as many\ntimes as there are elements in the indices input. In particular: the first\ninput pointer passed to the underlying 1-D computational loop points to the\ninput array at the correct location indicated by the index array. In addition,\nthe output pointer and the second input pointer passed to the underlying 1-D\nloop point to the same position in memory. The size of the 1-D computational\nloop is fixed to be the difference between the current index and the next\nindex (when the current index is the last index, then the next index is\nassumed to be the length of the array along the selected dimension). In this\nway, the 1-D loop will implement a `reduce` over the specified indices.\n\nMisaligned or a loop datatype that does not match the input and/or output\ndatatype is handled using buffered code wherein data is copied to a temporary\nbuffer and cast to the correct datatype if necessary prior to calling the\nunderlying 1-D function. The temporary buffers are created in (element) sizes\nno bigger than the user settable buffer-size value. Thus, the loop must be\nflexible enough to call the underlying 1-D computational loop enough times to\ncomplete the total calculation in chunks no bigger than the buffer-size.\n\n"}, {"name": "NumPy C-API", "path": "reference/c-api/index", "type": "NumPy C-API", "text": "\nNumPy provides a C-API to enable users to extend the system and get access to\nthe array object for use in other routines. The best way to truly understand\nthe C-API is to read the source code. If you are unfamiliar with (C) source\ncode, however, this can be a daunting experience at first. Be assured that the\ntask becomes easier with practice, and you may be surprised at how simple the\nC-code can be to understand. Even if you don\u2019t think you can write C-code from\nscratch, it is much easier to understand and modify already-written source\ncode than create it de novo.\n\nPython extensions are especially straightforward to understand because they\nall have a very similar structure. Admittedly, NumPy is not a trivial\nextension to Python, and may take a little more snooping to grasp. This is\nespecially true because of the code-generation techniques, which simplify\nmaintenance of very similar code, but can make the code a little less readable\nto beginners. Still, with a little persistence, the code can be opened to your\nunderstanding. It is my hope, that this guide to the C-API can assist in the\nprocess of becoming familiar with the compiled-level work that can be done\nwith NumPy in order to squeeze that last bit of necessary speed out of your\ncode.\n\n"}, {"name": "NumPy for MATLAB users", "path": "user/numpy-for-matlab-users", "type": "User Guide", "text": "\nMATLAB\u00ae and NumPy have a lot in common, but NumPy was created to work with\nPython, not to be a MATLAB clone. This guide will help MATLAB users get\nstarted with NumPy.\n\nIn MATLAB, the basic type, even for scalars, is a multidimensional array.\nArray assignments in MATLAB are stored as 2D arrays of double precision\nfloating point numbers, unless you specify the number of dimensions and type.\nOperations on the 2D instances of these arrays are modeled on matrix\noperations in linear algebra.\n\nIn NumPy, the basic type is a multidimensional `array`. Array assignments in\nNumPy are usually stored as n-dimensional arrays with the minimum type\nrequired to hold the objects in sequence, unless you specify the number of\ndimensions and type. NumPy performs operations element-by-element, so\nmultiplying 2D arrays with `*` is not a matrix multiplication \u2013 it\u2019s an\nelement-by-element multiplication. (The `@` operator, available since Python\n3.5, can be used for conventional matrix multiplication.)\n\nMATLAB numbers indices from 1; `a(1)` is the first element. See note INDEXING\n\nNumPy, like Python, numbers indices from 0; `a[0]` is the first element.\n\nMATLAB\u2019s scripting language was created for linear algebra so the syntax for\nsome array manipulations is more compact than NumPy\u2019s. On the other hand, the\nAPI for adding GUIs and creating full-fledged applications is more or less an\nafterthought.\n\nNumPy is based on Python, a general-purpose language. The advantage to NumPy\nis access to Python libraries including: SciPy, Matplotlib, Pandas, OpenCV,\nand more. In addition, Python is often embedded as a scripting language in\nother software, allowing NumPy to be used there too.\n\nMATLAB array slicing uses pass-by-value semantics, with a lazy copy-on-write\nscheme to prevent creating copies until they are needed. Slicing operations\ncopy parts of the array.\n\nNumPy array slicing uses pass-by-reference, that does not copy the arguments.\nSlicing operations are views into an array.\n\nThe table below gives rough equivalents for some common MATLAB expressions.\nThese are similar expressions, not equivalents. For details, see the\ndocumentation.\n\nIn the table below, it is assumed that you have executed the following\ncommands in Python:\n\nAlso assume below that if the Notes talk about \u201cmatrix\u201d that the arguments are\ntwo-dimensional entities.\n\nMATLAB\n\nNumPy\n\nNotes\n\n`help func`\n\n`info(func)` or `help(func)` or `func?` (in IPython)\n\nget help on the function func\n\n`which func`\n\nsee note HELP\n\nfind out where func is defined\n\n`type func`\n\n`np.source(func)` or `func??` (in IPython)\n\nprint source for func (if not a native function)\n\n`% comment`\n\n`# comment`\n\ncomment a line of code with the text `comment`\n\nuse a for-loop to print the numbers 1, 2, and 3 using `range`\n\n`a && b`\n\n`a and b`\n\nshort-circuiting logical AND operator (Python native operator); scalar\narguments only\n\n`a || b`\n\n`a or b`\n\nshort-circuiting logical OR operator (Python native operator); scalar\narguments only\n\nThe boolean objects in Python are `True` and `False`, as opposed to MATLAB\nlogical types of `1` and `0`.\n\ncreate an if-else statement to check if `a` is 4 or 5 and print result\n\n`1*i`, `1*j`, `1i`, `1j`\n\n`1j`\n\ncomplex numbers\n\n`eps`\n\n`np.finfo(float).eps` or `np.spacing(1)`\n\nUpper bound to relative error due to rounding in 64-bit floating point\narithmetic.\n\n`load data.mat`\n\n`io.loadmat('data.mat')`\n\nLoad MATLAB variables saved to the file `data.mat`. (Note: When saving arrays\nto `data.mat` in MATLAB/Octave, use a recent binary format. `scipy.io.loadmat`\nwill create a dictionary with the saved arrays and further information.)\n\n`ode45`\n\n`integrate.solve_ivp(f)`\n\nintegrate an ODE with Runge-Kutta 4,5\n\n`ode15s`\n\n`integrate.solve_ivp(f, method='BDF')`\n\nintegrate an ODE with BDF method\n\nMATLAB\n\nNumPy\n\nNotes\n\n`ndims(a)`\n\n`np.ndim(a)` or `a.ndim`\n\nnumber of dimensions of array `a`\n\n`numel(a)`\n\n`np.size(a)` or `a.size`\n\nnumber of elements of array `a`\n\n`size(a)`\n\n`np.shape(a)` or `a.shape`\n\n\u201csize\u201d of array `a`\n\n`size(a,n)`\n\n`a.shape[n-1]`\n\nget the number of elements of the n-th dimension of array `a`. (Note that\nMATLAB uses 1 based indexing while Python uses 0 based indexing, See note\nINDEXING)\n\n`[ 1 2 3; 4 5 6 ]`\n\n`np.array([[1. ,2. ,3.], [4. ,5. ,6.]])`\n\ndefine a 2x3 2D array\n\n`[ a b; c d ]`\n\n`np.block([[a, b], [c, d]])`\n\nconstruct a matrix from blocks `a`, `b`, `c`, and `d`\n\n`a(end)`\n\n`a[-1]`\n\naccess last element in MATLAB vector (1xn or nx1) or 1D NumPy array `a`\n(length n)\n\n`a(2,5)`\n\n`a[1, 4]`\n\naccess element in second row, fifth column in 2D array `a`\n\n`a(2,:)`\n\n`a[1]` or `a[1, :]`\n\nentire second row of 2D array `a`\n\n`a(1:5,:)`\n\n`a[0:5]` or `a[:5]` or `a[0:5, :]`\n\nfirst 5 rows of 2D array `a`\n\n`a(end-4:end,:)`\n\n`a[-5:]`\n\nlast 5 rows of 2D array `a`\n\n`a(1:3,5:9)`\n\n`a[0:3, 4:9]`\n\nThe first through third rows and fifth through ninth columns of a 2D array,\n`a`.\n\n`a([2,4,5],[1,3])`\n\n`a[np.ix_([1, 3, 4], [0, 2])]`\n\nrows 2,4 and 5 and columns 1 and 3. This allows the matrix to be modified, and\ndoesn\u2019t require a regular slice.\n\n`a(3:2:21,:)`\n\n`a[2:21:2,:]`\n\nevery other row of `a`, starting with the third and going to the twenty-first\n\n`a(1:2:end,:)`\n\n`a[ ::2,:]`\n\nevery other row of `a`, starting with the first\n\n`a(end:-1:1,:)` or `flipud(a)`\n\n`a[::-1,:]`\n\n`a` with rows in reverse order\n\n`a([1:end 1],:)`\n\n`a[np.r_[:len(a),0]]`\n\n`a` with copy of the first row appended to the end\n\n`a.'`\n\n`a.transpose()` or `a.T`\n\ntranspose of `a`\n\n`a'`\n\n`a.conj().transpose()` or `a.conj().T`\n\nconjugate transpose of `a`\n\n`a * b`\n\n`a @ b`\n\nmatrix multiply\n\n`a .* b`\n\n`a * b`\n\nelement-wise multiply\n\n`a./b`\n\n`a/b`\n\nelement-wise divide\n\n`a.^3`\n\n`a**3`\n\nelement-wise exponentiation\n\n`(a > 0.5)`\n\n`(a > 0.5)`\n\nmatrix whose i,jth element is (a_ij > 0.5). The MATLAB result is an array of\nlogical values 0 and 1. The NumPy result is an array of the boolean values\n`False` and `True`.\n\n`find(a > 0.5)`\n\n`np.nonzero(a > 0.5)`\n\nfind the indices where (`a` > 0.5)\n\n`a(:,find(v > 0.5))`\n\n`a[:,np.nonzero(v > 0.5)[0]]`\n\nextract the columns of `a` where vector v > 0.5\n\n`a(:,find(v>0.5))`\n\n`a[:, v.T > 0.5]`\n\nextract the columns of `a` where column vector v > 0.5\n\n`a(a<0.5)=0`\n\n`a[a < 0.5]=0`\n\n`a` with elements less than 0.5 zeroed out\n\n`a .* (a>0.5)`\n\n`a * (a > 0.5)`\n\n`a` with elements less than 0.5 zeroed out\n\n`a(:) = 3`\n\n`a[:] = 3`\n\nset all values to the same scalar value\n\n`y=x`\n\n`y = x.copy()`\n\nNumPy assigns by reference\n\n`y=x(2,:)`\n\n`y = x[1, :].copy()`\n\nNumPy slices are by reference\n\n`y=x(:)`\n\n`y = x.flatten()`\n\nturn array into vector (note that this forces a copy). To obtain the same data\nordering as in MATLAB, use `x.flatten('F')`.\n\n`1:10`\n\n`np.arange(1., 11.)` or `np.r_[1.:11.]` or `np.r_[1:10:10j]`\n\ncreate an increasing vector (see note RANGES)\n\n`0:9`\n\n`np.arange(10.)` or `np.r_[:10.]` or `np.r_[:9:10j]`\n\ncreate an increasing vector (see note RANGES)\n\n`[1:10]'`\n\n`np.arange(1.,11.)[:, np.newaxis]`\n\ncreate a column vector\n\n`zeros(3,4)`\n\n`np.zeros((3, 4))`\n\n3x4 two-dimensional array full of 64-bit floating point zeros\n\n`zeros(3,4,5)`\n\n`np.zeros((3, 4, 5))`\n\n3x4x5 three-dimensional array full of 64-bit floating point zeros\n\n`ones(3,4)`\n\n`np.ones((3, 4))`\n\n3x4 two-dimensional array full of 64-bit floating point ones\n\n`eye(3)`\n\n`np.eye(3)`\n\n3x3 identity matrix\n\n`diag(a)`\n\n`np.diag(a)`\n\nreturns a vector of the diagonal elements of 2D array, `a`\n\n`diag(v,0)`\n\n`np.diag(v, 0)`\n\nreturns a square diagonal matrix whose nonzero values are the elements of\nvector, `v`\n\nor older version: `random.rand((3, 4))`\n\ngenerate a random 3x4 array with default random number generator and seed = 42\n\n`linspace(1,3,4)`\n\n`np.linspace(1,3,4)`\n\n4 equally spaced samples between 1 and 3, inclusive\n\n`[x,y]=meshgrid(0:8,0:5)`\n\n`np.mgrid[0:9.,0:6.]` or `np.meshgrid(r_[0:9.],r_[0:6.]`\n\ntwo 2D arrays: one of x values, the other of y values\n\n`ogrid[0:9.,0:6.]` or `np.ix_(np.r_[0:9.],np.r_[0:6.]`\n\nthe best way to eval functions on a grid\n\n`[x,y]=meshgrid([1,2,4],[2,4,5])`\n\n`np.meshgrid([1,2,4],[2,4,5])`\n\n`ix_([1,2,4],[2,4,5])`\n\nthe best way to eval functions on a grid\n\n`repmat(a, m, n)`\n\n`np.tile(a, (m, n))`\n\ncreate m by n copies of `a`\n\n`[a b]`\n\n`np.concatenate((a,b),1)` or `np.hstack((a,b))` or `np.column_stack((a,b))` or\n`np.c_[a,b]`\n\nconcatenate columns of `a` and `b`\n\n`[a; b]`\n\n`np.concatenate((a,b))` or `np.vstack((a,b))` or `np.r_[a,b]`\n\nconcatenate rows of `a` and `b`\n\n`max(max(a))`\n\n`a.max()` or `np.nanmax(a)`\n\nmaximum element of `a` (with ndims(a)<=2 for MATLAB, if there are NaN\u2019s,\n`nanmax` will ignore these and return largest value)\n\n`max(a)`\n\n`a.max(0)`\n\nmaximum element of each column of array `a`\n\n`max(a,[],2)`\n\n`a.max(1)`\n\nmaximum element of each row of array `a`\n\n`max(a,b)`\n\n`np.maximum(a, b)`\n\ncompares `a` and `b` element-wise, and returns the maximum value from each\npair\n\n`norm(v)`\n\n`np.sqrt(v @ v)` or `np.linalg.norm(v)`\n\nL2 norm of vector `v`\n\n`a & b`\n\n`logical_and(a,b)`\n\nelement-by-element AND operator (NumPy ufunc) See note LOGICOPS\n\n`a | b`\n\n`np.logical_or(a,b)`\n\nelement-by-element OR operator (NumPy ufunc) See note LOGICOPS\n\n`bitand(a,b)`\n\n`a & b`\n\nbitwise AND operator (Python native and NumPy ufunc)\n\n`bitor(a,b)`\n\n`a | b`\n\nbitwise OR operator (Python native and NumPy ufunc)\n\n`inv(a)`\n\n`linalg.inv(a)`\n\ninverse of square 2D array `a`\n\n`pinv(a)`\n\n`linalg.pinv(a)`\n\npseudo-inverse of 2D array `a`\n\n`rank(a)`\n\n`linalg.matrix_rank(a)`\n\nmatrix rank of a 2D array `a`\n\n`a\\b`\n\n`linalg.solve(a, b)` if `a` is square; `linalg.lstsq(a, b)` otherwise\n\nsolution of a x = b for x\n\n`b/a`\n\nSolve `a.T x.T = b.T` instead\n\nsolution of x a = b for x\n\n`[U,S,V]=svd(a)`\n\n`U, S, Vh = linalg.svd(a), V = Vh.T`\n\nsingular value decomposition of `a`\n\n`c=chol(a)` where `a==c'*c`\n\n`c = linalg.cholesky(a)` where `a == c@c.T`\n\nCholesky factorization of a 2D array (`chol(a)` in MATLAB returns an upper\ntriangular 2D array, but `cholesky` returns a lower triangular 2D array)\n\n`[V,D]=eig(a)`\n\n`D,V = linalg.eig(a)`\n\neigenvalues \\\\(\\lambda\\\\) and eigenvectors \\\\(\\bar{v}\\\\) of `a`, where\n\\\\(\\lambda\\bar{v}=\\mathbf{a}\\bar{v}\\\\)\n\n`[V,D]=eig(a,b)`\n\n`D,V = linalg.eig(a, b)`\n\neigenvalues \\\\(\\lambda\\\\) and eigenvectors \\\\(\\bar{v}\\\\) of `a`, `b` where\n\\\\(\\lambda\\mathbf{b}\\bar{v}=\\mathbf{a}\\bar{v}\\\\)\n\n`[V,D]=eigs(a,3)`\n\n`D,V = eigs(a, k = 3)`\n\nfind the `k=3` largest eigenvalues and eigenvectors of 2D array, `a`\n\n`[Q,R,P]=qr(a,0)`\n\n`Q,R = linalg.qr(a)`\n\nQR decomposition\n\n`[L,U,P]=lu(a)` where `a==P'*L*U`\n\n`P,L,U = linalg.lu(a)` where `a == P@L@U`\n\nLU decomposition (note: P(MATLAB) == transpose(P(NumPy)))\n\n`conjgrad`\n\n`cg`\n\nConjugate gradients solver\n\n`fft(a)`\n\n`np.fft(a)`\n\nFourier transform of `a`\n\n`ifft(a)`\n\n`np.ifft(a)`\n\ninverse Fourier transform of `a`\n\n`sort(a)`\n\n`np.sort(a)` or `a.sort(axis=0)`\n\nsort each column of a 2D array, `a`\n\n`sort(a, 2)`\n\n`np.sort(a, axis = 1)` or `a.sort(axis = 1)`\n\nsort the each row of 2D array, `a`\n\n`[b,I]=sortrows(a,1)`\n\n`I = np.argsort(a[:, 0]); b = a[I,:]`\n\nsave the array `a` as array `b` with rows sorted by the first column\n\n`x = Z\\y`\n\n`x = linalg.lstsq(Z, y)`\n\nperform a linear regression of the form \\\\(\\mathbf{Zx}=\\mathbf{y}\\\\)\n\n`decimate(x, q)`\n\n`signal.resample(x, np.ceil(len(x)/q))`\n\ndownsample with low-pass filtering\n\n`unique(a)`\n\n`np.unique(a)`\n\na vector of unique values in array `a`\n\n`squeeze(a)`\n\n`a.squeeze()`\n\nremove singleton dimensions of array `a`. Note that MATLAB will always return\narrays of 2D or higher while NumPy will return arrays of 0D or higher\n\nSubmatrix: Assignment to a submatrix can be done with lists of indices using\nthe `ix_` command. E.g., for 2D array `a`, one might do: `ind=[1, 3];\na[np.ix_(ind, ind)] += 100`.\n\nHELP: There is no direct equivalent of MATLAB\u2019s `which` command, but the\ncommands `help` and `numpy.source` will usually list the filename where the\nfunction is located. Python also has an `inspect` module (do `import inspect`)\nwhich provides a `getfile` that often works.\n\nINDEXING: MATLAB uses one based indexing, so the initial element of a sequence\nhas index 1. Python uses zero based indexing, so the initial element of a\nsequence has index 0. Confusion and flamewars arise because each has\nadvantages and disadvantages. One based indexing is consistent with common\nhuman language usage, where the \u201cfirst\u201d element of a sequence has index 1.\nZero based indexing simplifies indexing. See also a text by prof.dr. Edsger W.\nDijkstra.\n\nRANGES: In MATLAB, `0:5` can be used as both a range literal and a \u2018slice\u2019\nindex (inside parentheses); however, in Python, constructs like `0:5` can only\nbe used as a slice index (inside square brackets). Thus the somewhat quirky\n`r_` object was created to allow NumPy to have a similarly terse range\nconstruction mechanism. Note that `r_` is not called like a function or a\nconstructor, but rather indexed using square brackets, which allows the use of\nPython\u2019s slice syntax in the arguments.\n\nLOGICOPS: `&` or `|` in NumPy is bitwise AND/OR, while in MATLAB & and `|` are\nlogical AND/OR. The two can appear to work the same, but there are important\ndifferences. If you would have used MATLAB\u2019s `&` or `|` operators, you should\nuse the NumPy ufuncs `logical_and`/`logical_or`. The notable differences\nbetween MATLAB\u2019s and NumPy\u2019s `&` and `|` operators are:\n\nIf you know you have boolean arguments, you can get away with using NumPy\u2019s\nbitwise operators, but be careful with parentheses, like this: `z = (x > 1) &\n(x < 2)`. The absence of NumPy operator forms of `logical_and` and\n`logical_or` is an unfortunate consequence of Python\u2019s design.\n\nRESHAPE and LINEAR INDEXING: MATLAB always allows multi-dimensional arrays to\nbe accessed using scalar or linear indices, NumPy does not. Linear indices are\ncommon in MATLAB programs, e.g. `find()` on a matrix returns them, whereas\nNumPy\u2019s find behaves differently. When converting MATLAB code it might be\nnecessary to first reshape a matrix to a linear sequence, perform some\nindexing operations and then reshape back. As reshape (usually) produces views\nonto the same storage, it should be possible to do this fairly efficiently.\nNote that the scan order used by reshape in NumPy defaults to the \u2018C\u2019 order,\nwhereas MATLAB uses the Fortran order. If you are simply converting to a\nlinear sequence and back this doesn\u2019t matter. But if you are converting\nreshapes from MATLAB code which relies on the scan order, then this MATLAB\ncode: `z = reshape(x,3,4);` should become `z =\nx.reshape(3,4,order='F').copy()` in NumPy.\n\nHistorically, NumPy has provided a special matrix type, `np.matrix`, which is\na subclass of ndarray which makes binary operations linear algebra operations.\nYou may see it used in some existing code instead of `np.array`. So, which one\nto use?\n\nUse arrays.\n\nUntil Python 3.5 the only disadvantage of using the array type was that you\nhad to use `dot` instead of `*` to multiply (reduce) two tensors (scalar\nproduct, matrix vector multiplication etc.). Since Python 3.5 you can use the\nmatrix multiplication `@` operator.\n\nGiven the above, we intend to deprecate `matrix` eventually.\n\nNumPy contains both an `array` class and a `matrix` class. The `array` class\nis intended to be a general-purpose n-dimensional array for many kinds of\nnumerical computing, while `matrix` is intended to facilitate linear algebra\ncomputations specifically. In practice there are only a handful of key\ndifferences between the two.\n\nOperators `*` and `@`, functions `dot()`, and `multiply()`:\n\nHandling of vectors (one-dimensional arrays)\n\nHandling of higher-dimensional arrays (ndim > 2)\n\nConvenience attributes\n\nConvenience constructor\n\nThere are pros and cons to using both:\n\n`array`\n\n`matrix`\n\nThe `array` is thus much more advisable to use. Indeed, we intend to deprecate\n`matrix` eventually.\n\nIn MATLAB the main tool available to you for customizing the environment is to\nmodify the search path with the locations of your favorite functions. You can\nput such customizations into a startup script that MATLAB will run on startup.\n\nNumPy, or rather Python, has similar facilities.\n\nUnlike MATLAB, where anything on your path can be called immediately, with\nPython you need to first do an \u2018import\u2019 statement to make functions in a\nparticular file accessible.\n\nFor example you might make a startup script that looks like this (Note: this\nis just an example, not a statement of \u201cbest practices\u201d):\n\nTo use the deprecated `matrix` and other `matlib` functions:\n\nAnother somewhat outdated MATLAB/NumPy cross-reference can be found at\nhttp://mathesaurus.sf.net/\n\nAn extensive list of tools for scientific work with Python can be found in the\ntopical software page.\n\nSee List of Python software: scripting for a list of software that use Python\nas a scripting language\n\nMATLAB\u00ae and SimuLink\u00ae are registered trademarks of The MathWorks, Inc.\n\n"}, {"name": "NumPy fundamentals", "path": "user/basics", "type": "User Guide", "text": "\nThese documents clarify concepts, design decisions, and technical constraints\nin NumPy. This is a great place to understand the fundamental NumPy ideas and\nphilosophy.\n\n"}, {"name": "NumPy governance", "path": "dev/governance/index", "type": "Development", "text": "\n\n"}, {"name": "NumPy How Tos", "path": "user/howtos_index", "type": "User Guide", "text": "\nThese documents are intended as recipes to common tasks using NumPy. For\ndetailed reference documentation of the functions and classes contained in the\npackage, see the API reference.\n\n"}, {"name": "NumPy license", "path": "license", "type": "NumPy license", "text": "\n\n"}, {"name": "NumPy project governance and decision-making", "path": "dev/governance/governance", "type": "Development", "text": "\nThe purpose of this document is to formalize the governance process used by\nthe NumPy project in both ordinary and extraordinary situations, and to\nclarify how decisions are made and how the various elements of our community\ninteract, including the relationship between open source collaborative\ndevelopment and work that may be funded by for-profit or non-profit entities.\n\nNumPy is a community-owned and community-run project. To the maximum extent\npossible, decisions about project direction are made by community consensus\n(but note that \u201cconsensus\u201d here has a somewhat technical meaning that might\nnot match everyone\u2019s expectations \u2013 see below). Some members of the community\nadditionally contribute by serving on the NumPy steering council, where they\nare responsible for facilitating the establishment of community consensus, for\nstewarding project resources, and \u2013 in extreme cases \u2013 for making project\ndecisions if the normal community-based process breaks down.\n\nThe NumPy Project (The Project) is an open source software project affiliated\nwith the 501(c)3 NumFOCUS Foundation. The goal of The Project is to develop\nopen source software for array-based computing in Python, and in particular\nthe `numpy` package, along with related software such as `f2py` and the NumPy\nSphinx extensions. The Software developed by The Project is released under the\nBSD (or similar) open source license, developed openly and hosted on public\nGitHub repositories under the `numpy` GitHub organization.\n\nThe Project is developed by a team of distributed developers, called\nContributors. Contributors are individuals who have contributed code,\ndocumentation, designs or other work to the Project. Anyone can be a\nContributor. Contributors can be affiliated with any legal entity or none.\nContributors participate in the project by submitting, reviewing and\ndiscussing GitHub Pull Requests and Issues and participating in open and\npublic Project discussions on GitHub, mailing lists, and other channels. The\nfoundation of Project participation is openness and transparency.\n\nThe Project Community consists of all Contributors and Users of the Project.\nContributors work on behalf of and are responsible to the larger Project\nCommunity and we strive to keep the barrier between Contributors and Users as\nlow as possible.\n\nThe Project is formally affiliated with the 501(c)3 NumFOCUS Foundation\n(http://numfocus.org), which serves as its fiscal sponsor, may hold project\ntrademarks and other intellectual property, helps manage project donations and\nacts as a parent legal entity. NumFOCUS is the only legal entity that has a\nformal relationship with the project (see Institutional Partners section\nbelow).\n\nThis section describes the governance and leadership model of The Project.\n\nThe foundations of Project governance are:\n\nNormally, all project decisions will be made by consensus of all interested\nContributors. The primary goal of this approach is to ensure that the people\nwho are most affected by and involved in any given change can contribute their\nknowledge in the confidence that their voices will be heard, because\nthoughtful review from a broad community is the best mechanism we know of for\ncreating high-quality software.\n\nThe mechanism we use to accomplish this goal may be unfamiliar for those who\nare not experienced with the cultural norms around free/open-source software\ndevelopment. We provide a summary here, and highly recommend that all\nContributors additionally read Chapter 4: Social and Political Infrastructure\nof Karl Fogel\u2019s classic Producing Open Source Software, and in particular the\nsection on Consensus-based Democracy, for a more detailed discussion.\n\nIn this context, consensus does not require:\n\nFor us, what consensus means is that we entrust everyone with the right to\nveto any change if they feel it necessary. While this may sound like a recipe\nfor obstruction and pain, this is not what happens. Instead, we find that most\npeople take this responsibility seriously, and only invoke their veto when\nthey judge that a serious problem is being ignored, and that their veto is\nnecessary to protect the project. And in practice, it turns out that such\nvetoes are almost never formally invoked, because their mere possibility\nensures that Contributors are motivated from the start to find some solution\nthat everyone can live with \u2013 thus accomplishing our goal of ensuring that all\ninterested perspectives are taken into account.\n\nHow do we know when consensus has been achieved? In principle, this is rather\ndifficult, since consensus is defined by the absence of vetos, which requires\nus to somehow prove a negative. In practice, we use a combination of our best\njudgement (e.g., a simple and uncontroversial bug fix posted on GitHub and\nreviewed by a core developer is probably fine) and best efforts (e.g., all\nsubstantive API changes must be posted to the mailing list in order to give\nthe broader community a chance to catch any problems and suggest improvements;\nwe assume that anyone who cares enough about NumPy to invoke their veto right\nshould be on the mailing list). If no-one bothers to comment on the mailing\nlist after a few days, then it\u2019s probably fine. And worst case, if a change is\nmore controversial than expected, or a crucial critique is delayed because\nsomeone was on vacation, then it\u2019s no big deal: we apologize for misjudging\nthe situation, back up, and sort things out.\n\nIf one does need to invoke a formal veto, then it should consist of:\n\nIf all proposals for resolving some issue are vetoed, then the status quo wins\nby default.\n\nIn the worst case, if a Contributor is genuinely misusing their veto in an\nobstructive fashion to the detriment of the project, then they can be ejected\nfrom the project by consensus of the Steering Council \u2013 see below.\n\nThe Project will have a Steering Council that consists of Project Contributors\nwho have produced contributions that are substantial in quality and quantity,\nand sustained over at least one year. The overall role of the Council is to\nensure, with input from the Community, the long-term well-being of the\nproject, both technically and as a community.\n\nDuring the everyday project activities, council members participate in all\ndiscussions, code review and other project activities as peers with all other\nContributors and the Community. In these everyday activities, Council Members\ndo not have any special power or privilege through their membership on the\nCouncil. However, it is expected that because of the quality and quantity of\ntheir contributions and their expert knowledge of the Project Software and\nServices that Council Members will provide useful guidance, both technical and\nin terms of project direction, to potentially less experienced contributors.\n\nThe Steering Council and its Members play a special role in certain\nsituations. In particular, the Council may, if necessary:\n\nHowever, the Council\u2019s primary responsibility is to facilitate the ordinary\ncommunity-based decision making procedure described above. If we ever have to\nstep in and formally override the community for the health of the Project,\nthen we will do so, but we will consider reaching this point to indicate a\nfailure in our leadership.\n\nIf it becomes necessary for the Steering Council to produce a formal decision,\nthen they will use a form of the Apache Foundation voting process. This is a\nformalized version of consensus, in which +1 votes indicate agreement, -1\nvotes are vetoes (and must be accompanied with a rationale, as above), and one\ncan also vote fractionally (e.g. -0.5, +0.5) if one wishes to express an\nopinion without registering a full veto. These numeric votes are also often\nused informally as a way of getting a general sense of people\u2019s feelings on\nsome issue, and should not normally be taken as formal votes. A formal vote\nonly occurs if explicitly declared, and if this does occur then the vote\nshould be held open for long enough to give all interested Council Members a\nchance to respond \u2013 at least one week.\n\nIn practice, we anticipate that for most Steering Council decisions (e.g.,\nvoting in new members) a more informal process will suffice.\n\nA list of current Steering Council Members is maintained at the page About Us.\n\nTo become eligible to join the Steering Council, an individual must be a\nProject Contributor who has produced contributions that are substantial in\nquality and quantity, and sustained over at least one year. Potential Council\nMembers are nominated by existing Council members, and become members\nfollowing consensus of the existing Council members, and confirmation that the\npotential Member is interested and willing to serve in that capacity. The\nCouncil will be initially formed from the set of existing Core Developers who,\nas of late 2015, have been significantly active over the last year.\n\nWhen considering potential Members, the Council will look at candidates with a\ncomprehensive view of their contributions. This will include but is not\nlimited to code, code review, infrastructure work, mailing list and chat\nparticipation, community help/building, education and outreach, design work,\netc. We are deliberately not setting arbitrary quantitative metrics (like \u201c100\ncommits in this repo\u201d) to avoid encouraging behavior that plays to the metrics\nrather than the project\u2019s overall well-being. We want to encourage a diverse\narray of backgrounds, viewpoints and talents in our team, which is why we\nexplicitly do not define code as the sole metric on which council membership\nwill be evaluated.\n\nIf a Council member becomes inactive in the project for a period of one year,\nthey will be considered for removal from the Council. Before removal, inactive\nMember will be approached to see if they plan on returning to active\nparticipation. If not they will be removed immediately upon a Council vote. If\nthey plan on returning to active participation soon, they will be given a\ngrace period of one year. If they don\u2019t return to active participation within\nthat time period they will be removed by vote of the Council without further\ngrace period. All former Council members can be considered for membership\nagain at any time in the future, like any other Project Contributor. Retired\nCouncil members will be listed on the project website, acknowledging the\nperiod during which they were active in the Council.\n\nThe Council reserves the right to eject current Members, if they are deemed to\nbe actively harmful to the project\u2019s well-being, and attempts at communication\nand conflict resolution have failed. This requires the consensus of the\nremaining Members.\n\nIt is expected that the Council Members will be employed at a wide range of\ncompanies, universities and non-profit organizations. Because of this, it is\npossible that Members will have conflict of interests. Such conflict of\ninterests include, but are not limited to:\n\nAll members of the Council shall disclose to the rest of the Council any\nconflict of interest they may have. Members with a conflict of interest in a\nparticular issue may participate in Council discussions on that issue, but\nmust recuse themselves from voting on the issue.\n\nTo the maximum extent possible, Council discussions and activities will be\npublic and done in collaboration and discussion with the Project Contributors\nand Community. The Council will have a private mailing list that will be used\nsparingly and only when a specific matter requires privacy. When private\ncommunications and decisions are needed, the Council will do its best to\nsummarize those to the Community after eliding personal/private/sensitive\ninformation that should not be posted to the public internet.\n\nThe Council can create subcommittees that provide leadership and guidance for\nspecific aspects of the project. Like the Council as a whole, subcommittees\nshould conduct their business in an open and public manner unless privacy is\nspecifically called for. Private subcommittee communications should happen on\nthe main private mailing list of the Council unless specifically called for.\n\nThe Council will maintain one narrowly focused subcommittee to manage its\ninteractions with NumFOCUS.\n\nThe current membership of the NumFOCUS Subcommittee is listed at the page\nAbout Us.\n\nThe Steering Council are the primary leadership for the project. No outside\ninstitution, individual or legal entity has the ability to own, control, usurp\nor influence the project other than by participating in the Project as\nContributors and Council Members. However, because institutions can be an\nimportant funding mechanism for the project, it is important to formally\nacknowledge institutional participation in the project. These are\nInstitutional Partners.\n\nAn Institutional Contributor is any individual Project Contributor who\ncontributes to the project as part of their official duties at an\nInstitutional Partner. Likewise, an Institutional Council Member is any\nProject Steering Council Member who contributes to the project as part of\ntheir official duties at an Institutional Partner.\n\nWith these definitions, an Institutional Partner is any recognized legal\nentity in the United States or elsewhere that employs at least 1 Institutional\nContributor of Institutional Council Member. Institutional Partners can be\nfor-profit or non-profit entities.\n\nInstitutions become eligible to become an Institutional Partner by employing\nindividuals who actively contribute to The Project as part of their official\nduties. To state this another way, the only way for a Partner to influence the\nproject is by actively contributing to the open development of the project, in\nequal terms to any other member of the community of Contributors and Council\nMembers. Merely using Project Software in institutional context does not allow\nan entity to become an Institutional Partner. Financial gifts do not enable an\nentity to become an Institutional Partner. Once an institution becomes\neligible for Institutional Partnership, the Steering Council must nominate and\napprove the Partnership.\n\nIf at some point an existing Institutional Partner stops having any\ncontributing employees, then a one year grace period commences. If at the end\nof this one year period they continue not to have any contributing employees,\nthen their Institutional Partnership will lapse, and resuming it will require\ngoing through the normal process for new Partnerships.\n\nAn Institutional Partner is free to pursue funding for their work on The\nProject through any legal means. This could involve a non-profit organization\nraising money from private foundations and donors or a for-profit company\nbuilding proprietary products and services that leverage Project Software and\nServices. Funding acquired by Institutional Partners to work on The Project is\ncalled Institutional Funding. However, no funding obtained by an Institutional\nPartner can override the Steering Council. If a Partner has funding to do\nNumPy work and the Council decides to not pursue that work as a project, the\nPartner is free to pursue it on their own. However in this situation, that\npart of the Partner\u2019s work will not be under the NumPy umbrella and cannot use\nthe Project trademarks in a way that suggests a formal relationship.\n\nInstitutional Partner benefits are:\n\nA list of current Institutional Partners is maintained at the page About Us.\n\nhttps://github.com/numpy/numpy/commits/main/doc/source/dev/governance/governance.rst\n\nSubstantial portions of this document were adapted from the Jupyter/IPython\nproject\u2019s governance document\n\nTo the extent possible under law, the authors have waived all copyright and\nrelated or neighboring rights to the NumPy project governance and decision-\nmaking document, as per the CC-0 public domain dedication / license.\n\n"}, {"name": "NumPy user guide", "path": "user/index", "type": "User Guide", "text": "\nThis guide is an overview and explains the important features; details are\nfound in Command Reference.\n\n"}, {"name": "NumPy-specific help functions", "path": "reference/routines.help", "type": "NumPy-specific help functions", "text": "\n`lookfor`(what[, module, import_modules, ...])\n\nDo a keyword search on docstrings.\n\n`info`([object, maxwidth, output, toplevel])\n\nGet help information for a function, class, or module.\n\n`source`(object[, output])\n\nPrint or write to a file the source code for a NumPy object.\n\n"}, {"name": "numpy.absolute()", "path": "reference/generated/numpy.absolute", "type": "numpy.absolute", "text": "\nCalculate the absolute value element-wise.\n\n`np.abs` is a shorthand for this function.\n\nInput array.\n\nA location into which the result is stored. If provided, it must have a shape\nthat the inputs broadcast to. If not provided or None, a freshly-allocated\narray is returned. A tuple (possible only as a keyword argument) must have\nlength equal to the number of outputs.\n\nThis condition is broadcast over the input. At locations where the condition\nis True, the `out` array will be set to the ufunc result. Elsewhere, the `out`\narray will retain its original value. Note that if an uninitialized `out`\narray is created via the default `out=None`, locations within it where the\ncondition is False will remain uninitialized.\n\nFor other keyword-only arguments, see the ufunc docs.\n\nAn ndarray containing the absolute value of each element in `x`. For complex\ninput, `a + ib`, the absolute value is \\\\(\\sqrt{ a^2 + b^2 }\\\\). This is a\nscalar if `x` is a scalar.\n\nPlot the function over `[-10, 10]`:\n\nPlot the function over the complex plane:\n\nThe `abs` function can be used as a shorthand for `np.absolute` on ndarrays.\n\n"}, {"name": "numpy.add()", "path": "reference/generated/numpy.add", "type": "numpy.add", "text": "\nAdd arguments element-wise.\n\nThe arrays to be added. If `x1.shape != x2.shape`, they must be broadcastable\nto a common shape (which becomes the shape of the output).\n\nA location into which the result is stored. If provided, it must have a shape\nthat the inputs broadcast to. If not provided or None, a freshly-allocated\narray is returned. A tuple (possible only as a keyword argument) must have\nlength equal to the number of outputs.\n\nThis condition is broadcast over the input. At locations where the condition\nis True, the `out` array will be set to the ufunc result. Elsewhere, the `out`\narray will retain its original value. Note that if an uninitialized `out`\narray is created via the default `out=None`, locations within it where the\ncondition is False will remain uninitialized.\n\nFor other keyword-only arguments, see the ufunc docs.\n\nThe sum of `x1` and `x2`, element-wise. This is a scalar if both `x1` and `x2`\nare scalars.\n\nEquivalent to `x1` \\+ `x2` in terms of array broadcasting.\n\nThe `+` operator can be used as a shorthand for `np.add` on ndarrays.\n\n"}, {"name": "numpy.all()", "path": "reference/generated/numpy.all", "type": "numpy.all", "text": "\nTest whether all array elements along a given axis evaluate to True.\n\nInput array or object that can be converted to an array.\n\nAxis or axes along which a logical AND reduction is performed. The default\n(`axis=None`) is to perform a logical AND over all the dimensions of the input\narray. `axis` may be negative, in which case it counts from the last to the\nfirst axis.\n\nNew in version 1.7.0.\n\nIf this is a tuple of ints, a reduction is performed on multiple axes, instead\nof a single axis or all the axes as before.\n\nAlternate output array in which to place the result. It must have the same\nshape as the expected output and its type is preserved (e.g., if `dtype(out)`\nis float, the result will consist of 0.0\u2019s and 1.0\u2019s). See Output type\ndetermination for more details.\n\nIf this is set to True, the axes which are reduced are left in the result as\ndimensions with size one. With this option, the result will broadcast\ncorrectly against the input array.\n\nIf the default value is passed, then `keepdims` will not be passed through to\nthe `all` method of sub-classes of `ndarray`, however any non-default value\nwill be. If the sub-class\u2019 method does not implement `keepdims` any exceptions\nwill be raised.\n\nElements to include in checking for all `True` values. See `reduce` for\ndetails.\n\nNew in version 1.20.0.\n\nA new boolean or array is returned unless `out` is specified, in which case a\nreference to `out` is returned.\n\nSee also\n\nequivalent method\n\nTest whether any element along a given axis evaluates to True.\n\nNot a Number (NaN), positive infinity and negative infinity evaluate to `True`\nbecause these are not equal to zero.\n\n"}, {"name": "numpy.allclose()", "path": "reference/generated/numpy.allclose", "type": "numpy.allclose", "text": "\nReturns True if two arrays are element-wise equal within a tolerance.\n\nThe tolerance values are positive, typically very small numbers. The relative\ndifference (`rtol` * abs(`b`)) and the absolute difference `atol` are added\ntogether to compare against the absolute difference between `a` and `b`.\n\nNaNs are treated as equal if they are in the same place and if\n`equal_nan=True`. Infs are treated as equal if they are in the same place and\nof the same sign in both arrays.\n\nInput arrays to compare.\n\nThe relative tolerance parameter (see Notes).\n\nThe absolute tolerance parameter (see Notes).\n\nWhether to compare NaN\u2019s as equal. If True, NaN\u2019s in `a` will be considered\nequal to NaN\u2019s in `b` in the output array.\n\nNew in version 1.10.0.\n\nReturns True if the two arrays are equal within the given tolerance; False\notherwise.\n\nSee also\n\nIf the following equation is element-wise True, then allclose returns True.\n\nabsolute(`a` \\- `b`) <= (`atol` \\+ `rtol` * absolute(`b`))\n\nThe above equation is not symmetric in `a` and `b`, so that `allclose(a, b)`\nmight be different from `allclose(b, a)` in some rare cases.\n\nThe comparison of `a` and `b` uses standard broadcasting, which means that `a`\nand `b` need not have the same shape in order for `allclose(a, b)` to evaluate\nto True. The same is true for `equal` but not `array_equal`.\n\n`allclose` is not defined for non-numeric data types. `bool` is considered a\nnumeric data-type for this purpose.\n\n"}, {"name": "numpy.amax()", "path": "reference/generated/numpy.amax", "type": "numpy.amax", "text": "\nReturn the maximum of an array or maximum along an axis.\n\nInput data.\n\nAxis or axes along which to operate. By default, flattened input is used.\n\nNew in version 1.7.0.\n\nIf this is a tuple of ints, the maximum is selected over multiple axes,\ninstead of a single axis or all the axes as before.\n\nAlternative output array in which to place the result. Must be of the same\nshape and buffer length as the expected output. See Output type determination\nfor more details.\n\nIf this is set to True, the axes which are reduced are left in the result as\ndimensions with size one. With this option, the result will broadcast\ncorrectly against the input array.\n\nIf the default value is passed, then `keepdims` will not be passed through to\nthe `amax` method of sub-classes of `ndarray`, however any non-default value\nwill be. If the sub-class\u2019 method does not implement `keepdims` any exceptions\nwill be raised.\n\nThe minimum value of an output element. Must be present to allow computation\non empty slice. See `reduce` for details.\n\nNew in version 1.15.0.\n\nElements to compare for the maximum. See `reduce` for details.\n\nNew in version 1.17.0.\n\nMaximum of `a`. If `axis` is None, the result is a scalar value. If `axis` is\ngiven, the result is an array of dimension `a.ndim - 1`.\n\nSee also\n\nThe minimum value of an array along a given axis, propagating any NaNs.\n\nThe maximum value of an array along a given axis, ignoring any NaNs.\n\nElement-wise maximum of two arrays, propagating any NaNs.\n\nElement-wise maximum of two arrays, ignoring any NaNs.\n\nReturn the indices of the maximum values.\n\nNaN values are propagated, that is if at least one item is NaN, the\ncorresponding max value will be NaN as well. To ignore NaN values (MATLAB\nbehavior), please use nanmax.\n\nDon\u2019t use `amax` for element-wise comparison of 2 arrays; when `a.shape[0]` is\n2, `maximum(a[0], a[1])` is faster than `amax(a, axis=0)`.\n\nYou can use an initial value to compute the maximum of an empty slice, or to\ninitialize it to a different value:\n\nNotice that the initial value is used as one of the elements for which the\nmaximum is determined, unlike for the default argument Python\u2019s max function,\nwhich is only used for empty iterables.\n\n"}, {"name": "numpy.amin()", "path": "reference/generated/numpy.amin", "type": "numpy.amin", "text": "\nReturn the minimum of an array or minimum along an axis.\n\nInput data.\n\nAxis or axes along which to operate. By default, flattened input is used.\n\nNew in version 1.7.0.\n\nIf this is a tuple of ints, the minimum is selected over multiple axes,\ninstead of a single axis or all the axes as before.\n\nAlternative output array in which to place the result. Must be of the same\nshape and buffer length as the expected output. See Output type determination\nfor more details.\n\nIf this is set to True, the axes which are reduced are left in the result as\ndimensions with size one. With this option, the result will broadcast\ncorrectly against the input array.\n\nIf the default value is passed, then `keepdims` will not be passed through to\nthe `amin` method of sub-classes of `ndarray`, however any non-default value\nwill be. If the sub-class\u2019 method does not implement `keepdims` any exceptions\nwill be raised.\n\nThe maximum value of an output element. Must be present to allow computation\non empty slice. See `reduce` for details.\n\nNew in version 1.15.0.\n\nElements to compare for the minimum. See `reduce` for details.\n\nNew in version 1.17.0.\n\nMinimum of `a`. If `axis` is None, the result is a scalar value. If `axis` is\ngiven, the result is an array of dimension `a.ndim - 1`.\n\nSee also\n\nThe maximum value of an array along a given axis, propagating any NaNs.\n\nThe minimum value of an array along a given axis, ignoring any NaNs.\n\nElement-wise minimum of two arrays, propagating any NaNs.\n\nElement-wise minimum of two arrays, ignoring any NaNs.\n\nReturn the indices of the minimum values.\n\nNaN values are propagated, that is if at least one item is NaN, the\ncorresponding min value will be NaN as well. To ignore NaN values (MATLAB\nbehavior), please use nanmin.\n\nDon\u2019t use `amin` for element-wise comparison of 2 arrays; when `a.shape[0]` is\n2, `minimum(a[0], a[1])` is faster than `amin(a, axis=0)`.\n\nNotice that the initial value is used as one of the elements for which the\nminimum is determined, unlike for the default argument Python\u2019s max function,\nwhich is only used for empty iterables.\n\nNotice that this isn\u2019t the same as Python\u2019s `default` argument.\n\n"}, {"name": "numpy.angle()", "path": "reference/generated/numpy.angle", "type": "numpy.angle", "text": "\nReturn the angle of the complex argument.\n\nA complex number or sequence of complex numbers.\n\nReturn angle in degrees if True, radians if False (default).\n\nThe counterclockwise angle from the positive real axis on the complex plane in\nthe range `(-pi, pi]`, with dtype as numpy.float64.\n\nChanged in version 1.16.0: This function works on subclasses of ndarray like\n`ma.array`.\n\nSee also\n\nAlthough the angle of the complex number 0 is undefined, `numpy.angle(0)`\nreturns the value 0.\n\n"}, {"name": "numpy.any()", "path": "reference/generated/numpy.any", "type": "numpy.any", "text": "\nTest whether any array element along a given axis evaluates to True.\n\nReturns single boolean unless `axis` is not `None`\n\nInput array or object that can be converted to an array.\n\nAxis or axes along which a logical OR reduction is performed. The default\n(`axis=None`) is to perform a logical OR over all the dimensions of the input\narray. `axis` may be negative, in which case it counts from the last to the\nfirst axis.\n\nNew in version 1.7.0.\n\nIf this is a tuple of ints, a reduction is performed on multiple axes, instead\nof a single axis or all the axes as before.\n\nAlternate output array in which to place the result. It must have the same\nshape as the expected output and its type is preserved (e.g., if it is of type\nfloat, then it will remain so, returning 1.0 for True and 0.0 for False,\nregardless of the type of `a`). See Output type determination for more\ndetails.\n\nIf this is set to True, the axes which are reduced are left in the result as\ndimensions with size one. With this option, the result will broadcast\ncorrectly against the input array.\n\nIf the default value is passed, then `keepdims` will not be passed through to\nthe `any` method of sub-classes of `ndarray`, however any non-default value\nwill be. If the sub-class\u2019 method does not implement `keepdims` any exceptions\nwill be raised.\n\nElements to include in checking for any `True` values. See `reduce` for\ndetails.\n\nNew in version 1.20.0.\n\nA new boolean or `ndarray` is returned unless `out` is specified, in which\ncase a reference to `out` is returned.\n\nSee also\n\nequivalent method\n\nTest whether all elements along a given axis evaluate to True.\n\nNot a Number (NaN), positive infinity and negative infinity evaluate to `True`\nbecause these are not equal to zero.\n\n"}, {"name": "numpy.append()", "path": "reference/generated/numpy.append", "type": "numpy.append", "text": "\nAppend values to the end of an array.\n\nValues are appended to a copy of this array.\n\nThese values are appended to a copy of `arr`. It must be of the correct shape\n(the same shape as `arr`, excluding `axis`). If `axis` is not specified,\n`values` can be any shape and will be flattened before use.\n\nThe axis along which `values` are appended. If `axis` is not given, both `arr`\nand `values` are flattened before use.\n\nA copy of `arr` with `values` appended to `axis`. Note that `append` does not\noccur in-place: a new array is allocated and filled. If `axis` is None, `out`\nis a flattened array.\n\nSee also\n\nInsert elements into an array.\n\nDelete elements from an array.\n\nWhen `axis` is specified, `values` must have the correct shape.\n\n"}, {"name": "numpy.apply_along_axis()", "path": "reference/generated/numpy.apply_along_axis", "type": "numpy.apply_along_axis", "text": "\nApply a function to 1-D slices along the given axis.\n\nExecute `func1d(a, *args, **kwargs)` where `func1d` operates on 1-D arrays and\n`a` is a 1-D slice of `arr` along `axis`.\n\nThis is equivalent to (but faster than) the following use of `ndindex` and\n`s_`, which sets each of `ii`, `jj`, and `kk` to a tuple of indices:\n\nEquivalently, eliminating the inner loop, this can be expressed as:\n\nThis function should accept 1-D arrays. It is applied to 1-D slices of `arr`\nalong the specified axis.\n\nAxis along which `arr` is sliced.\n\nInput array.\n\nAdditional arguments to `func1d`.\n\nAdditional named arguments to `func1d`.\n\nNew in version 1.9.0.\n\nThe output array. The shape of `out` is identical to the shape of `arr`,\nexcept along the `axis` dimension. This axis is removed, and replaced with new\ndimensions equal to the shape of the return value of `func1d`. So if `func1d`\nreturns a scalar `out` will have one fewer dimensions than `arr`.\n\nSee also\n\nApply a function repeatedly over multiple axes.\n\nFor a function that returns a 1D array, the number of dimensions in `outarr`\nis the same as `arr`.\n\nFor a function that returns a higher dimensional array, those dimensions are\ninserted in place of the `axis` dimension.\n\n"}, {"name": "numpy.apply_over_axes()", "path": "reference/generated/numpy.apply_over_axes", "type": "numpy.apply_over_axes", "text": "\nApply a function repeatedly over multiple axes.\n\n`func` is called as `res = func(a, axis)`, where `axis` is the first element\nof `axes`. The result `res` of the function call must have either the same\ndimensions as `a` or one less dimension. If `res` has one less dimension than\n`a`, a dimension is inserted before `axis`. The call to `func` is then\nrepeated for each axis in `axes`, with `res` as the first argument.\n\nThis function must take two arguments, `func(a, axis)`.\n\nInput array.\n\nAxes over which `func` is applied; the elements must be integers.\n\nThe output array. The number of dimensions is the same as `a`, but the shape\ncan be different. This depends on whether `func` changes the shape of its\noutput with respect to its input.\n\nSee also\n\nApply a function to 1-D slices of an array along the given axis.\n\nThis function is equivalent to tuple axis arguments to reorderable ufuncs with\nkeepdims=True. Tuple axis arguments to ufuncs have been available since\nversion 1.7.0.\n\nSum over axes 0 and 2. The result has same number of dimensions as the\noriginal array:\n\nTuple axis arguments to ufuncs are equivalent:\n\n"}, {"name": "numpy.arange()", "path": "reference/generated/numpy.arange", "type": "numpy.arange", "text": "\nReturn evenly spaced values within a given interval.\n\nValues are generated within the half-open interval `[start, stop)` (in other\nwords, the interval including `start` but excluding `stop`). For integer\narguments the function is equivalent to the Python built-in `range` function,\nbut returns an ndarray rather than a list.\n\nWhen using a non-integer step, such as 0.1, it is often better to use\n`numpy.linspace`. See the warnings section below for more information.\n\nStart of interval. The interval includes this value. The default start value\nis 0.\n\nEnd of interval. The interval does not include this value, except in some\ncases where `step` is not an integer and floating point round-off affects the\nlength of `out`.\n\nSpacing between values. For any output `out`, this is the distance between two\nadjacent values, `out[i+1] - out[i]`. The default step size is 1. If `step` is\nspecified as a position argument, `start` must also be given.\n\nThe type of the output array. If `dtype` is not given, infer the data type\nfrom the other input arguments.\n\nReference object to allow the creation of arrays which are not NumPy arrays.\nIf an array-like passed in as `like` supports the `__array_function__`\nprotocol, the result will be defined by it. In this case, it ensures the\ncreation of an array object compatible with that passed in via this argument.\n\nNew in version 1.20.0.\n\nArray of evenly spaced values.\n\nFor floating point arguments, the length of the result is `ceil((stop -\nstart)/step)`. Because of floating point overflow, this rule may result in the\nlast element of `out` being greater than `stop`.\n\nWarning\n\nThe length of the output might not be numerically stable.\n\nAnother stability issue is due to the internal implementation of\n`numpy.arange`. The actual step value used to populate the array is\n`dtype(start + step) - dtype(start)` and not `step`. Precision loss can occur\nhere, due to casting or due to using floating points when `start` is much\nlarger than `step`. This can lead to unexpected behaviour. For example:\n\nIn such cases, the use of `numpy.linspace` should be preferred.\n\nSee also\n\nEvenly spaced numbers with careful handling of endpoints.\n\nArrays of evenly spaced numbers in N-dimensions.\n\nGrid-shaped arrays of evenly spaced numbers in N-dimensions.\n\n"}, {"name": "numpy.arccos()", "path": "reference/generated/numpy.arccos", "type": "numpy.arccos", "text": "\nTrigonometric inverse cosine, element-wise.\n\nThe inverse of `cos` so that, if `y = cos(x)`, then `x = arccos(y)`.\n\n`x`-coordinate on the unit circle. For real arguments, the domain is [-1, 1].\n\nA location into which the result is stored. If provided, it must have a shape\nthat the inputs broadcast to. If not provided or None, a freshly-allocated\narray is returned. A tuple (possible only as a keyword argument) must have\nlength equal to the number of outputs.\n\nThis condition is broadcast over the input. At locations where the condition\nis True, the `out` array will be set to the ufunc result. Elsewhere, the `out`\narray will retain its original value. Note that if an uninitialized `out`\narray is created via the default `out=None`, locations within it where the\ncondition is False will remain uninitialized.\n\nFor other keyword-only arguments, see the ufunc docs.\n\nThe angle of the ray intersecting the unit circle at the given `x`-coordinate\nin radians [0, pi]. This is a scalar if `x` is a scalar.\n\nSee also\n\n`arccos` is a multivalued function: for each `x` there are infinitely many\nnumbers `z` such that `cos(z) = x`. The convention is to return the angle `z`\nwhose real part lies in `[0, pi]`.\n\nFor real-valued input data types, `arccos` always returns real output. For\neach value that cannot be expressed as a real number or infinity, it yields\n`nan` and sets the `invalid` floating point error flag.\n\nFor complex-valued input, `arccos` is a complex analytic function that has\nbranch cuts `[-inf, -1]` and `[1, inf]` and is continuous from above on the\nformer and from below on the latter.\n\nThe inverse `cos` is also known as `acos` or cos^-1.\n\nM. Abramowitz and I.A. Stegun, \u201cHandbook of Mathematical Functions\u201d, 10th\nprinting, 1964, pp. 79. https://personal.math.ubc.ca/~cbm/aands/page_79.htm\n\nWe expect the arccos of 1 to be 0, and of -1 to be pi:\n\nPlot arccos:\n\n"}, {"name": "numpy.arccosh()", "path": "reference/generated/numpy.arccosh", "type": "numpy.arccosh", "text": "\nInverse hyperbolic cosine, element-wise.\n\nInput array.\n\nA location into which the result is stored. If provided, it must have a shape\nthat the inputs broadcast to. If not provided or None, a freshly-allocated\narray is returned. A tuple (possible only as a keyword argument) must have\nlength equal to the number of outputs.\n\nThis condition is broadcast over the input. At locations where the condition\nis True, the `out` array will be set to the ufunc result. Elsewhere, the `out`\narray will retain its original value. Note that if an uninitialized `out`\narray is created via the default `out=None`, locations within it where the\ncondition is False will remain uninitialized.\n\nFor other keyword-only arguments, see the ufunc docs.\n\nArray of the same shape as `x`. This is a scalar if `x` is a scalar.\n\nSee also\n\n`arccosh` is a multivalued function: for each `x` there are infinitely many\nnumbers `z` such that `cosh(z) = x`. The convention is to return the `z` whose\nimaginary part lies in `[-pi, pi]` and the real part in `[0, inf]`.\n\nFor real-valued input data types, `arccosh` always returns real output. For\neach value that cannot be expressed as a real number or infinity, it yields\n`nan` and sets the `invalid` floating point error flag.\n\nFor complex-valued input, `arccosh` is a complex analytical function that has\na branch cut `[-inf, 1]` and is continuous from above on it.\n\nM. Abramowitz and I.A. Stegun, \u201cHandbook of Mathematical Functions\u201d, 10th\nprinting, 1964, pp. 86. https://personal.math.ubc.ca/~cbm/aands/page_86.htm\n\nWikipedia, \u201cInverse hyperbolic function\u201d,\nhttps://en.wikipedia.org/wiki/Arccosh\n\n"}, {"name": "numpy.arcsin()", "path": "reference/generated/numpy.arcsin", "type": "numpy.arcsin", "text": "\nInverse sine, element-wise.\n\n`y`-coordinate on the unit circle.\n\nA location into which the result is stored. If provided, it must have a shape\nthat the inputs broadcast to. If not provided or None, a freshly-allocated\narray is returned. A tuple (possible only as a keyword argument) must have\nlength equal to the number of outputs.\n\nThis condition is broadcast over the input. At locations where the condition\nis True, the `out` array will be set to the ufunc result. Elsewhere, the `out`\narray will retain its original value. Note that if an uninitialized `out`\narray is created via the default `out=None`, locations within it where the\ncondition is False will remain uninitialized.\n\nFor other keyword-only arguments, see the ufunc docs.\n\nThe inverse sine of each element in `x`, in radians and in the closed interval\n`[-pi/2, pi/2]`. This is a scalar if `x` is a scalar.\n\nSee also\n\n`arcsin` is a multivalued function: for each `x` there are infinitely many\nnumbers `z` such that \\\\(sin(z) = x\\\\). The convention is to return the angle\n`z` whose real part lies in [-pi/2, pi/2].\n\nFor real-valued input data types, arcsin always returns real output. For each\nvalue that cannot be expressed as a real number or infinity, it yields `nan`\nand sets the `invalid` floating point error flag.\n\nFor complex-valued input, `arcsin` is a complex analytic function that has, by\nconvention, the branch cuts [-inf, -1] and [1, inf] and is continuous from\nabove on the former and from below on the latter.\n\nThe inverse sine is also known as `asin` or sin^{-1}.\n\nAbramowitz, M. and Stegun, I. A., Handbook of Mathematical Functions, 10th\nprinting, New York: Dover, 1964, pp. 79ff.\nhttps://personal.math.ubc.ca/~cbm/aands/page_79.htm\n\n"}, {"name": "numpy.arcsinh()", "path": "reference/generated/numpy.arcsinh", "type": "numpy.arcsinh", "text": "\nInverse hyperbolic sine element-wise.\n\nInput array.\n\nA location into which the result is stored. If provided, it must have a shape\nthat the inputs broadcast to. If not provided or None, a freshly-allocated\narray is returned. A tuple (possible only as a keyword argument) must have\nlength equal to the number of outputs.\n\nThis condition is broadcast over the input. At locations where the condition\nis True, the `out` array will be set to the ufunc result. Elsewhere, the `out`\narray will retain its original value. Note that if an uninitialized `out`\narray is created via the default `out=None`, locations within it where the\ncondition is False will remain uninitialized.\n\nFor other keyword-only arguments, see the ufunc docs.\n\nArray of the same shape as `x`. This is a scalar if `x` is a scalar.\n\n`arcsinh` is a multivalued function: for each `x` there are infinitely many\nnumbers `z` such that `sinh(z) = x`. The convention is to return the `z` whose\nimaginary part lies in `[-pi/2, pi/2]`.\n\nFor real-valued input data types, `arcsinh` always returns real output. For\neach value that cannot be expressed as a real number or infinity, it returns\n`nan` and sets the `invalid` floating point error flag.\n\nFor complex-valued input, `arccos` is a complex analytical function that has\nbranch cuts `[1j, infj]` and `[-1j, -infj]` and is continuous from the right\non the former and from the left on the latter.\n\nThe inverse hyperbolic sine is also known as `asinh` or `sinh^-1`.\n\nM. Abramowitz and I.A. Stegun, \u201cHandbook of Mathematical Functions\u201d, 10th\nprinting, 1964, pp. 86. https://personal.math.ubc.ca/~cbm/aands/page_86.htm\n\nWikipedia, \u201cInverse hyperbolic function\u201d,\nhttps://en.wikipedia.org/wiki/Arcsinh\n\n"}, {"name": "numpy.arctan()", "path": "reference/generated/numpy.arctan", "type": "numpy.arctan", "text": "\nTrigonometric inverse tangent, element-wise.\n\nThe inverse of tan, so that if `y = tan(x)` then `x = arctan(y)`.\n\nA location into which the result is stored. If provided, it must have a shape\nthat the inputs broadcast to. If not provided or None, a freshly-allocated\narray is returned. A tuple (possible only as a keyword argument) must have\nlength equal to the number of outputs.\n\nThis condition is broadcast over the input. At locations where the condition\nis True, the `out` array will be set to the ufunc result. Elsewhere, the `out`\narray will retain its original value. Note that if an uninitialized `out`\narray is created via the default `out=None`, locations within it where the\ncondition is False will remain uninitialized.\n\nFor other keyword-only arguments, see the ufunc docs.\n\nOut has the same shape as `x`. Its real part is in `[-pi/2, pi/2]`\n(`arctan(+/-inf)` returns `+/-pi/2`). This is a scalar if `x` is a scalar.\n\nSee also\n\nThe \u201cfour quadrant\u201d arctan of the angle formed by (`x`, `y`) and the positive\n`x`-axis.\n\nArgument of complex values.\n\n`arctan` is a multi-valued function: for each `x` there are infinitely many\nnumbers `z` such that tan(`z`) = `x`. The convention is to return the angle\n`z` whose real part lies in [-pi/2, pi/2].\n\nFor real-valued input data types, `arctan` always returns real output. For\neach value that cannot be expressed as a real number or infinity, it yields\n`nan` and sets the `invalid` floating point error flag.\n\nFor complex-valued input, `arctan` is a complex analytic function that has\n[`1j, infj`] and [`-1j, -infj`] as branch cuts, and is continuous from the\nleft on the former and from the right on the latter.\n\nThe inverse tangent is also known as `atan` or tan^{-1}.\n\nAbramowitz, M. and Stegun, I. A., Handbook of Mathematical Functions, 10th\nprinting, New York: Dover, 1964, pp. 79.\nhttps://personal.math.ubc.ca/~cbm/aands/page_79.htm\n\nWe expect the arctan of 0 to be 0, and of 1 to be pi/4:\n\nPlot arctan:\n\n"}, {"name": "numpy.arctan2()", "path": "reference/generated/numpy.arctan2", "type": "numpy.arctan2", "text": "\nElement-wise arc tangent of `x1/x2` choosing the quadrant correctly.\n\nThe quadrant (i.e., branch) is chosen so that `arctan2(x1, x2)` is the signed\nangle in radians between the ray ending at the origin and passing through the\npoint (1,0), and the ray ending at the origin and passing through the point\n(`x2`, `x1`). (Note the role reversal: the \u201c`y`-coordinate\u201d is the first\nfunction parameter, the \u201c`x`-coordinate\u201d is the second.) By IEEE convention,\nthis function is defined for `x2` = +/-0 and for either or both of `x1` and\n`x2` = +/-inf (see Notes for specific values).\n\nThis function is not defined for complex-valued arguments; for the so-called\nargument of complex values, use `angle`.\n\n`y`-coordinates.\n\n`x`-coordinates. If `x1.shape != x2.shape`, they must be broadcastable to a\ncommon shape (which becomes the shape of the output).\n\nA location into which the result is stored. If provided, it must have a shape\nthat the inputs broadcast to. If not provided or None, a freshly-allocated\narray is returned. A tuple (possible only as a keyword argument) must have\nlength equal to the number of outputs.\n\nThis condition is broadcast over the input. At locations where the condition\nis True, the `out` array will be set to the ufunc result. Elsewhere, the `out`\narray will retain its original value. Note that if an uninitialized `out`\narray is created via the default `out=None`, locations within it where the\ncondition is False will remain uninitialized.\n\nFor other keyword-only arguments, see the ufunc docs.\n\nArray of angles in radians, in the range `[-pi, pi]`. This is a scalar if both\n`x1` and `x2` are scalars.\n\nSee also\n\narctan2 is identical to the `atan2` function of the underlying C library. The\nfollowing special values are defined in the C standard: [1]\n\n`x1`\n\n`x2`\n\n`arctan2(x1,x2)`\n\n+/- 0\n\n+0\n\n+/- 0\n\n+/- 0\n\n-0\n+/- pi\n\n> 0\n+/-inf\n\n+0 / +pi\n\n< 0\n\n+/-inf\n\n-0 / -pi\n+/-inf\n\n+inf\n\n+/- (pi/4)\n\n+/-inf\n\n-inf\n+/- (3*pi/4)\n\nNote that +0 and -0 are distinct floating point numbers, as are +inf and -inf.\n\nISO/IEC standard 9899:1999, \u201cProgramming language C.\u201d\n\nConsider four points in different quadrants:\n\nNote the order of the parameters. `arctan2` is defined also when `x2` = 0 and\nat several other special points, obtaining values in the range `[-pi, pi]`:\n\n"}, {"name": "numpy.arctanh()", "path": "reference/generated/numpy.arctanh", "type": "numpy.arctanh", "text": "\nInverse hyperbolic tangent element-wise.\n\nInput array.\n\nA location into which the result is stored. If provided, it must have a shape\nthat the inputs broadcast to. If not provided or None, a freshly-allocated\narray is returned. A tuple (possible only as a keyword argument) must have\nlength equal to the number of outputs.\n\nThis condition is broadcast over the input. At locations where the condition\nis True, the `out` array will be set to the ufunc result. Elsewhere, the `out`\narray will retain its original value. Note that if an uninitialized `out`\narray is created via the default `out=None`, locations within it where the\ncondition is False will remain uninitialized.\n\nFor other keyword-only arguments, see the ufunc docs.\n\nArray of the same shape as `x`. This is a scalar if `x` is a scalar.\n\nSee also\n\n`arctanh` is a multivalued function: for each `x` there are infinitely many\nnumbers `z` such that `tanh(z) = x`. The convention is to return the `z` whose\nimaginary part lies in `[-pi/2, pi/2]`.\n\nFor real-valued input data types, `arctanh` always returns real output. For\neach value that cannot be expressed as a real number or infinity, it yields\n`nan` and sets the `invalid` floating point error flag.\n\nFor complex-valued input, `arctanh` is a complex analytical function that has\nbranch cuts `[-1, -inf]` and `[1, inf]` and is continuous from above on the\nformer and from below on the latter.\n\nThe inverse hyperbolic tangent is also known as `atanh` or `tanh^-1`.\n\nM. Abramowitz and I.A. Stegun, \u201cHandbook of Mathematical Functions\u201d, 10th\nprinting, 1964, pp. 86. https://personal.math.ubc.ca/~cbm/aands/page_86.htm\n\nWikipedia, \u201cInverse hyperbolic function\u201d,\nhttps://en.wikipedia.org/wiki/Arctanh\n\n"}, {"name": "numpy.argmax()", "path": "reference/generated/numpy.argmax", "type": "numpy.argmax", "text": "\nReturns the indices of the maximum values along an axis.\n\nInput array.\n\nBy default, the index is into the flattened array, otherwise along the\nspecified axis.\n\nIf provided, the result will be inserted into this array. It should be of the\nappropriate shape and dtype.\n\nIf this is set to True, the axes which are reduced are left in the result as\ndimensions with size one. With this option, the result will broadcast\ncorrectly against the array.\n\nNew in version 1.22.0.\n\nArray of indices into the array. It has the same shape as `a.shape` with the\ndimension along `axis` removed. If `keepdims` is set to True, then the size of\n`axis` will be 1 with the resulting array having same shape as `a.shape`.\n\nSee also\n\nThe maximum value along a given axis.\n\nConvert a flat index into an index tuple.\n\nApply `np.expand_dims(index_array, axis)` from argmax to an array as if by\ncalling max.\n\nIn case of multiple occurrences of the maximum values, the indices\ncorresponding to the first occurrence are returned.\n\nIndexes of the maximal elements of a N-dimensional array:\n\nSetting `keepdims` to `True`,\n\n"}, {"name": "numpy.argmin()", "path": "reference/generated/numpy.argmin", "type": "numpy.argmin", "text": "\nReturns the indices of the minimum values along an axis.\n\nInput array.\n\nBy default, the index is into the flattened array, otherwise along the\nspecified axis.\n\nIf provided, the result will be inserted into this array. It should be of the\nappropriate shape and dtype.\n\nIf this is set to True, the axes which are reduced are left in the result as\ndimensions with size one. With this option, the result will broadcast\ncorrectly against the array.\n\nNew in version 1.22.0.\n\nArray of indices into the array. It has the same shape as `a.shape` with the\ndimension along `axis` removed. If `keepdims` is set to True, then the size of\n`axis` will be 1 with the resulting array having same shape as `a.shape`.\n\nSee also\n\nThe minimum value along a given axis.\n\nConvert a flat index into an index tuple.\n\nApply `np.expand_dims(index_array, axis)` from argmin to an array as if by\ncalling min.\n\nIn case of multiple occurrences of the minimum values, the indices\ncorresponding to the first occurrence are returned.\n\nIndices of the minimum elements of a N-dimensional array:\n\nSetting `keepdims` to `True`,\n\n"}, {"name": "numpy.argpartition()", "path": "reference/generated/numpy.argpartition", "type": "numpy.argpartition", "text": "\nPerform an indirect partition along the given axis using the algorithm\nspecified by the `kind` keyword. It returns an array of indices of the same\nshape as `a` that index data along the given axis in partitioned order.\n\nNew in version 1.8.0.\n\nArray to sort.\n\nElement index to partition by. The k-th element will be in its final sorted\nposition and all smaller elements will be moved before it and all larger\nelements behind it. The order all elements in the partitions is undefined. If\nprovided with a sequence of k-th it will partition all of them into their\nsorted position at once.\n\nDeprecated since version 1.22.0: Passing booleans as index is deprecated.\n\nAxis along which to sort. The default is -1 (the last axis). If None, the\nflattened array is used.\n\nSelection algorithm. Default is \u2018introselect\u2019\n\nWhen `a` is an array with fields defined, this argument specifies which fields\nto compare first, second, etc. A single field can be specified as a string,\nand not all fields need be specified, but unspecified fields will still be\nused, in the order in which they come up in the dtype, to break ties.\n\nArray of indices that partition `a` along the specified axis. If `a` is one-\ndimensional, `a[index_array]` yields a partitioned `a`. More generally,\n`np.take_along_axis(a, index_array, axis=a)` always yields the partitioned\n`a`, irrespective of dimensionality.\n\nSee also\n\nDescribes partition algorithms used.\n\nInplace partition.\n\nFull indirect sort.\n\nApply `index_array` from argpartition to an array as if by calling partition.\n\nSee `partition` for notes on the different selection algorithms.\n\nOne dimensional array:\n\nMulti-dimensional array:\n\n"}, {"name": "numpy.argsort()", "path": "reference/generated/numpy.argsort", "type": "numpy.argsort", "text": "\nReturns the indices that would sort an array.\n\nPerform an indirect sort along the given axis using the algorithm specified by\nthe `kind` keyword. It returns an array of indices of the same shape as `a`\nthat index data along the given axis in sorted order.\n\nArray to sort.\n\nAxis along which to sort. The default is -1 (the last axis). If None, the\nflattened array is used.\n\nSorting algorithm. The default is \u2018quicksort\u2019. Note that both \u2018stable\u2019 and\n\u2018mergesort\u2019 use timsort under the covers and, in general, the actual\nimplementation will vary with data type. The \u2018mergesort\u2019 option is retained\nfor backwards compatibility.\n\nChanged in version 1.15.0.: The \u2018stable\u2019 option was added.\n\nWhen `a` is an array with fields defined, this argument specifies which fields\nto compare first, second, etc. A single field can be specified as a string,\nand not all fields need be specified, but unspecified fields will still be\nused, in the order in which they come up in the dtype, to break ties.\n\nArray of indices that sort `a` along the specified `axis`. If `a` is one-\ndimensional, `a[index_array]` yields a sorted `a`. More generally,\n`np.take_along_axis(a, index_array, axis=axis)` always yields the sorted `a`,\nirrespective of dimensionality.\n\nSee also\n\nDescribes sorting algorithms used.\n\nIndirect stable sort with multiple keys.\n\nInplace sort.\n\nIndirect partial sort.\n\nApply `index_array` from argsort to an array as if by calling sort.\n\nSee `sort` for notes on the different sorting algorithms.\n\nAs of NumPy 1.4.0 `argsort` works with real/complex arrays containing nan\nvalues. The enhanced sort order is documented in `sort`.\n\nOne dimensional array:\n\nTwo-dimensional array:\n\nIndices of the sorted elements of a N-dimensional array:\n\nSorting with keys:\n\n"}, {"name": "numpy.argwhere()", "path": "reference/generated/numpy.argwhere", "type": "numpy.argwhere", "text": "\nFind the indices of array elements that are non-zero, grouped by element.\n\nInput data.\n\nIndices of elements that are non-zero. Indices are grouped by element. This\narray will have shape `(N, a.ndim)` where `N` is the number of non-zero items.\n\nSee also\n\n`np.argwhere(a)` is almost the same as `np.transpose(np.nonzero(a))`, but\nproduces a result of the correct shape for a 0D array.\n\nThe output of `argwhere` is not suitable for indexing arrays. For this purpose\nuse `nonzero(a)` instead.\n\n"}, {"name": "numpy.around()", "path": "reference/generated/numpy.around", "type": "numpy.around", "text": "\nEvenly round to the given number of decimals.\n\nInput data.\n\nNumber of decimal places to round to (default: 0). If decimals is negative, it\nspecifies the number of positions to the left of the decimal point.\n\nAlternative output array in which to place the result. It must have the same\nshape as the expected output, but the type of the output values will be cast\nif necessary. See Output type determination for more details.\n\nAn array of the same type as `a`, containing the rounded values. Unless `out`\nwas specified, a new array is created. A reference to the result is returned.\n\nThe real and imaginary parts of complex numbers are rounded separately. The\nresult of rounding a float is a float.\n\nSee also\n\nequivalent method\n\nFor values exactly halfway between rounded decimal values, NumPy rounds to the\nnearest even value. Thus 1.5 and 2.5 round to 2.0, -0.5 and 0.5 round to 0.0,\netc.\n\n`np.around` uses a fast but sometimes inexact algorithm to round floating-\npoint datatypes. For positive `decimals` it is equivalent to\n`np.true_divide(np.rint(a * 10**decimals), 10**decimals)`, which has error due\nto the inexact representation of decimal fractions in the IEEE floating point\nstandard [1] and errors introduced when scaling by powers of ten. For\ninstance, note the extra \u201c1\u201d in the following:\n\nIf your goal is to print such values with a fixed number of decimals, it is\npreferable to use numpy\u2019s float printing routines to limit the number of\nprinted decimals:\n\nThe float printing routines use an accurate but much more computationally\ndemanding algorithm to compute the number of digits after the decimal point.\n\nAlternatively, Python\u2019s builtin `round` function uses a more accurate but\nslower algorithm for 64-bit floating point values:\n\n\u201cLecture Notes on the Status of IEEE 754\u201d, William Kahan,\nhttps://people.eecs.berkeley.edu/~wkahan/ieee754status/IEEE754.PDF\n\n"}, {"name": "numpy.array()", "path": "reference/generated/numpy.array", "type": "numpy.array", "text": "\nCreate an array.\n\nAn array, any object exposing the array interface, an object whose __array__\nmethod returns an array, or any (nested) sequence. If object is a scalar, a\n0-dimensional array containing object is returned.\n\nThe desired data-type for the array. If not given, then the type will be\ndetermined as the minimum type required to hold the objects in the sequence.\n\nIf true (default), then the object is copied. Otherwise, a copy will only be\nmade if __array__ returns a copy, if obj is a nested sequence, or if a copy is\nneeded to satisfy any of the other requirements (`dtype`, `order`, etc.).\n\nSpecify the memory layout of the array. If object is not an array, the newly\ncreated array will be in C order (row major) unless \u2018F\u2019 is specified, in which\ncase it will be in Fortran order (column major). If object is an array the\nfollowing holds.\n\norder\n\nno copy\n\ncopy=True\n\n\u2018K\u2019\n\nunchanged\n\nF & C order preserved, otherwise most similar order\n\n\u2018A\u2019\n\nunchanged\n\nF order if input is F and not C, otherwise C order\n\n\u2018C\u2019\n\nC order\n\nC order\n\n\u2018F\u2019\n\nF order\n\nF order\n\nWhen `copy=False` and a copy is made for other reasons, the result is the same\nas if `copy=True`, with some exceptions for \u2018A\u2019, see the Notes section. The\ndefault order is \u2018K\u2019.\n\nIf True, then sub-classes will be passed-through, otherwise the returned array\nwill be forced to be a base-class array (default).\n\nSpecifies the minimum number of dimensions that the resulting array should\nhave. Ones will be pre-pended to the shape as needed to meet this requirement.\n\nReference object to allow the creation of arrays which are not NumPy arrays.\nIf an array-like passed in as `like` supports the `__array_function__`\nprotocol, the result will be defined by it. In this case, it ensures the\ncreation of an array object compatible with that passed in via this argument.\n\nNew in version 1.20.0.\n\nAn array object satisfying the specified requirements.\n\nSee also\n\nReturn an empty array with shape and type of input.\n\nReturn an array of ones with shape and type of input.\n\nReturn an array of zeros with shape and type of input.\n\nReturn a new array with shape of input filled with value.\n\nReturn a new uninitialized array.\n\nReturn a new array setting values to one.\n\nReturn a new array setting values to zero.\n\nReturn a new array of given shape filled with value.\n\nWhen order is \u2018A\u2019 and `object` is an array in neither \u2018C\u2019 nor \u2018F\u2019 order, and a\ncopy is forced by a change in dtype, then the order of the result is not\nnecessarily \u2018C\u2019 as expected. This is likely a bug.\n\nUpcasting:\n\nMore than one dimension:\n\nMinimum dimensions 2:\n\nType provided:\n\nData-type consisting of more than one element:\n\nCreating an array from sub-classes:\n\n"}, {"name": "numpy.array2string()", "path": "reference/generated/numpy.array2string", "type": "numpy.array2string", "text": "\nReturn a string representation of an array.\n\nInput array.\n\nInserts newlines if text is longer than `max_line_width`. Defaults to\n`numpy.get_printoptions()['linewidth']`.\n\nFloating point precision. Defaults to `numpy.get_printoptions()['precision']`.\n\nRepresent numbers \u201cvery close\u201d to zero as zero; default is False. Very close\nis defined by precision: if the precision is 8, e.g., numbers smaller (in\nabsolute value) than 5e-9 are represented as zero. Defaults to\n`numpy.get_printoptions()['suppress']`.\n\nInserted between elements.\n\nThe length of the prefix and suffix strings are used to respectively align and\nwrap the output. An array is typically printed as:\n\nThe output is left-padded by the length of the prefix string, and wrapping is\nforced at the column `max_line_width - len(suffix)`. It should be noted that\nthe content of prefix and suffix strings are not included in the output.\n\nHas no effect, do not use.\n\nDeprecated since version 1.14.0.\n\nIf not None, the keys should indicate the type(s) that the respective\nformatting function applies to. Callables should return a string. Types that\nare not specified (by their corresponding keys) are handled by the default\nformatters. Individual types for which a formatter can be set are:\n\nOther keys that can be used to set a group of types at once are:\n\nTotal number of array elements which trigger summarization rather than full\nrepr. Defaults to `numpy.get_printoptions()['threshold']`.\n\nNumber of array items in summary at beginning and end of each dimension.\nDefaults to `numpy.get_printoptions()['edgeitems']`.\n\nControls printing of the sign of floating-point types. If \u2018+\u2019, always print\nthe sign of positive values. If \u2018 \u2018, always prints a space (whitespace\ncharacter) in the sign position of positive values. If \u2018-\u2019, omit the sign\ncharacter of positive values. Defaults to `numpy.get_printoptions()['sign']`.\n\nControls the interpretation of the `precision` option for floating-point\ntypes. Defaults to `numpy.get_printoptions()['floatmode']`. Can take the\nfollowing values:\n\nIf set to the string `\u20181.13\u2019` enables 1.13 legacy printing mode. This\napproximates numpy 1.13 print output by including a space in the sign position\nof floats and different behavior for 0d arrays. If set to `False`, disables\nlegacy mode. Unrecognized strings will be ignored with a warning for forward\ncompatibility.\n\nNew in version 1.14.0.\n\nString representation of the array.\n\nif a callable in `formatter` does not return a string.\n\nSee also\n\nIf a formatter is specified for a certain type, the `precision` keyword is\nignored for that type.\n\nThis is a very flexible function; `array_repr` and `array_str` are using\n`array2string` internally so keywords with the same name should work\nidentically in all three functions.\n\n"}, {"name": "numpy.array_equal()", "path": "reference/generated/numpy.array_equal", "type": "numpy.array_equal", "text": "\nTrue if two arrays have the same shape and elements, False otherwise.\n\nInput arrays.\n\nWhether to compare NaN\u2019s as equal. If the dtype of a1 and a2 is complex,\nvalues will be considered equal if either the real or the imaginary component\nof a given value is `nan`.\n\nNew in version 1.19.0.\n\nReturns True if the arrays are equal.\n\nSee also\n\nReturns True if two arrays are element-wise equal within a tolerance.\n\nReturns True if input arrays are shape consistent and all elements equal.\n\nWhen `equal_nan` is True, complex values with nan components are considered\nequal if either the real or the imaginary components are nan.\n\n"}, {"name": "numpy.array_equiv()", "path": "reference/generated/numpy.array_equiv", "type": "numpy.array_equiv", "text": "\nReturns True if input arrays are shape consistent and all elements equal.\n\nShape consistent means they are either the same shape, or one input array can\nbe broadcasted to create the same shape as the other one.\n\nInput arrays.\n\nTrue if equivalent, False otherwise.\n\nShowing the shape equivalence:\n\n"}, {"name": "numpy.array_repr()", "path": "reference/generated/numpy.array_repr", "type": "numpy.array_repr", "text": "\nReturn the string representation of an array.\n\nInput array.\n\nInserts newlines if text is longer than `max_line_width`. Defaults to\n`numpy.get_printoptions()['linewidth']`.\n\nFloating point precision. Defaults to `numpy.get_printoptions()['precision']`.\n\nRepresent numbers \u201cvery close\u201d to zero as zero; default is False. Very close\nis defined by precision: if the precision is 8, e.g., numbers smaller (in\nabsolute value) than 5e-9 are represented as zero. Defaults to\n`numpy.get_printoptions()['suppress']`.\n\nThe string representation of an array.\n\nSee also\n\n"}, {"name": "numpy.array_split()", "path": "reference/generated/numpy.array_split", "type": "numpy.array_split", "text": "\nSplit an array into multiple sub-arrays.\n\nPlease refer to the `split` documentation. The only difference between these\nfunctions is that `array_split` allows `indices_or_sections` to be an integer\nthat does not equally divide the axis. For an array of length l that should be\nsplit into n sections, it returns l % n sub-arrays of size l//n + 1 and the\nrest of size l//n.\n\nSee also\n\nSplit array into multiple sub-arrays of equal size.\n\n"}, {"name": "numpy.array_str()", "path": "reference/generated/numpy.array_str", "type": "numpy.array_str", "text": "\nReturn a string representation of the data in an array.\n\nThe data in the array is returned as a single string. This function is similar\nto `array_repr`, the difference being that `array_repr` also returns\ninformation on the kind of array and its data type.\n\nInput array.\n\nInserts newlines if text is longer than `max_line_width`. Defaults to\n`numpy.get_printoptions()['linewidth']`.\n\nFloating point precision. Defaults to `numpy.get_printoptions()['precision']`.\n\nRepresent numbers \u201cvery close\u201d to zero as zero; default is False. Very close\nis defined by precision: if the precision is 8, e.g., numbers smaller (in\nabsolute value) than 5e-9 are represented as zero. Defaults to\n`numpy.get_printoptions()['suppress']`.\n\nSee also\n\n"}, {"name": "numpy.asanyarray()", "path": "reference/generated/numpy.asanyarray", "type": "numpy.asanyarray", "text": "\nConvert the input to an ndarray, but pass ndarray subclasses through.\n\nInput data, in any form that can be converted to an array. This includes\nscalars, lists, lists of tuples, tuples, tuples of tuples, tuples of lists,\nand ndarrays.\n\nBy default, the data-type is inferred from the input data.\n\nMemory layout. \u2018A\u2019 and \u2018K\u2019 depend on the order of input array a. \u2018C\u2019 row-major\n(C-style), \u2018F\u2019 column-major (Fortran-style) memory representation. \u2018A\u2019 (any)\nmeans \u2018F\u2019 if `a` is Fortran contiguous, \u2018C\u2019 otherwise \u2018K\u2019 (keep) preserve\ninput order Defaults to \u2018C\u2019.\n\nReference object to allow the creation of arrays which are not NumPy arrays.\nIf an array-like passed in as `like` supports the `__array_function__`\nprotocol, the result will be defined by it. In this case, it ensures the\ncreation of an array object compatible with that passed in via this argument.\n\nNew in version 1.20.0.\n\nArray interpretation of `a`. If `a` is an ndarray or a subclass of ndarray, it\nis returned as-is and no copy is performed.\n\nSee also\n\nSimilar function which always returns ndarrays.\n\nConvert input to a contiguous array.\n\nConvert input to a floating point ndarray.\n\nConvert input to an ndarray with column-major memory order.\n\nSimilar function which checks input for NaNs and Infs.\n\nCreate an array from an iterator.\n\nConstruct an array by executing a function on grid positions.\n\nConvert a list into an array:\n\nInstances of `ndarray` subclasses are passed through as-is:\n\n"}, {"name": "numpy.asarray()", "path": "reference/generated/numpy.asarray", "type": "numpy.asarray", "text": "\nConvert the input to an array.\n\nInput data, in any form that can be converted to an array. This includes\nlists, lists of tuples, tuples, tuples of tuples, tuples of lists and\nndarrays.\n\nBy default, the data-type is inferred from the input data.\n\nMemory layout. \u2018A\u2019 and \u2018K\u2019 depend on the order of input array a. \u2018C\u2019 row-major\n(C-style), \u2018F\u2019 column-major (Fortran-style) memory representation. \u2018A\u2019 (any)\nmeans \u2018F\u2019 if `a` is Fortran contiguous, \u2018C\u2019 otherwise \u2018K\u2019 (keep) preserve\ninput order Defaults to \u2018K\u2019.\n\nReference object to allow the creation of arrays which are not NumPy arrays.\nIf an array-like passed in as `like` supports the `__array_function__`\nprotocol, the result will be defined by it. In this case, it ensures the\ncreation of an array object compatible with that passed in via this argument.\n\nNew in version 1.20.0.\n\nArray interpretation of `a`. No copy is performed if the input is already an\nndarray with matching dtype and order. If `a` is a subclass of ndarray, a base\nclass ndarray is returned.\n\nSee also\n\nSimilar function which passes through subclasses.\n\nConvert input to a contiguous array.\n\nConvert input to a floating point ndarray.\n\nConvert input to an ndarray with column-major memory order.\n\nSimilar function which checks input for NaNs and Infs.\n\nCreate an array from an iterator.\n\nConstruct an array by executing a function on grid positions.\n\nConvert a list into an array:\n\nExisting arrays are not copied:\n\nIf `dtype` is set, array is copied only if dtype does not match:\n\nContrary to `asanyarray`, ndarray subclasses are not passed through:\n\n"}, {"name": "numpy.asarray_chkfinite()", "path": "reference/generated/numpy.asarray_chkfinite", "type": "numpy.asarray_chkfinite", "text": "\nConvert the input to an array, checking for NaNs or Infs.\n\nInput data, in any form that can be converted to an array. This includes\nlists, lists of tuples, tuples, tuples of tuples, tuples of lists and\nndarrays. Success requires no NaNs or Infs.\n\nBy default, the data-type is inferred from the input data.\n\nMemory layout. \u2018A\u2019 and \u2018K\u2019 depend on the order of input array a. \u2018C\u2019 row-major\n(C-style), \u2018F\u2019 column-major (Fortran-style) memory representation. \u2018A\u2019 (any)\nmeans \u2018F\u2019 if `a` is Fortran contiguous, \u2018C\u2019 otherwise \u2018K\u2019 (keep) preserve\ninput order Defaults to \u2018C\u2019.\n\nArray interpretation of `a`. No copy is performed if the input is already an\nndarray. If `a` is a subclass of ndarray, a base class ndarray is returned.\n\nRaises ValueError if `a` contains NaN (Not a Number) or Inf (Infinity).\n\nSee also\n\nCreate and array.\n\nSimilar function which passes through subclasses.\n\nConvert input to a contiguous array.\n\nConvert input to a floating point ndarray.\n\nConvert input to an ndarray with column-major memory order.\n\nCreate an array from an iterator.\n\nConstruct an array by executing a function on grid positions.\n\nConvert a list into an array. If all elements are finite `asarray_chkfinite`\nis identical to `asarray`.\n\nRaises ValueError if array_like contains Nans or Infs.\n\n"}, {"name": "numpy.ascontiguousarray()", "path": "reference/generated/numpy.ascontiguousarray", "type": "numpy.ascontiguousarray", "text": "\nReturn a contiguous array (ndim >= 1) in memory (C order).\n\nInput array.\n\nData-type of returned array.\n\nReference object to allow the creation of arrays which are not NumPy arrays.\nIf an array-like passed in as `like` supports the `__array_function__`\nprotocol, the result will be defined by it. In this case, it ensures the\ncreation of an array object compatible with that passed in via this argument.\n\nNew in version 1.20.0.\n\nContiguous array of same shape and content as `a`, with type `dtype` if\nspecified.\n\nSee also\n\nConvert input to an ndarray with column-major memory order.\n\nReturn an ndarray that satisfies requirements.\n\nInformation about the memory layout of the array.\n\nNote: This function returns an array with at least one-dimension (1-d) so it\nwill not preserve 0-d arrays.\n\n"}, {"name": "numpy.asfarray()", "path": "reference/generated/numpy.asfarray", "type": "numpy.asfarray", "text": "\nReturn an array converted to a float type.\n\nThe input array.\n\nFloat type code to coerce input array `a`. If `dtype` is one of the \u2018int\u2019\ndtypes, it is replaced with float64.\n\nThe input `a` as a float ndarray.\n\n"}, {"name": "numpy.asfortranarray()", "path": "reference/generated/numpy.asfortranarray", "type": "numpy.asfortranarray", "text": "\nReturn an array (ndim >= 1) laid out in Fortran order in memory.\n\nInput array.\n\nBy default, the data-type is inferred from the input data.\n\nReference object to allow the creation of arrays which are not NumPy arrays.\nIf an array-like passed in as `like` supports the `__array_function__`\nprotocol, the result will be defined by it. In this case, it ensures the\ncreation of an array object compatible with that passed in via this argument.\n\nNew in version 1.20.0.\n\nThe input `a` in Fortran, or column-major, order.\n\nSee also\n\nConvert input to a contiguous (C order) array.\n\nConvert input to an ndarray with either row or column-major memory order.\n\nReturn an ndarray that satisfies requirements.\n\nInformation about the memory layout of the array.\n\nNote: This function returns an array with at least one-dimension (1-d) so it\nwill not preserve 0-d arrays.\n\n"}, {"name": "numpy.asmatrix()", "path": "reference/generated/numpy.asmatrix", "type": "numpy.asmatrix", "text": "\nInterpret the input as a matrix.\n\nUnlike `matrix`, `asmatrix` does not make a copy if the input is already a\nmatrix or an ndarray. Equivalent to `matrix(data, copy=False)`.\n\nInput data.\n\nData-type of the output matrix.\n\n`data` interpreted as a matrix.\n\n"}, {"name": "numpy.asscalar()", "path": "reference/generated/numpy.asscalar", "type": "numpy.asscalar", "text": "\nConvert an array of size 1 to its scalar equivalent.\n\nDeprecated since version 1.16: Deprecated, use `numpy.ndarray.item()` instead.\n\nInput array of size 1.\n\nScalar representation of `a`. The output data type is the same type returned\nby the input\u2019s `item` method.\n\n"}, {"name": "numpy.atleast_1d()", "path": "reference/generated/numpy.atleast_1d", "type": "numpy.atleast_1d", "text": "\nConvert inputs to arrays with at least one dimension.\n\nScalar inputs are converted to 1-dimensional arrays, whilst higher-dimensional\ninputs are preserved.\n\nOne or more input arrays.\n\nAn array, or list of arrays, each with `a.ndim >= 1`. Copies are made only if\nnecessary.\n\nSee also\n\n"}, {"name": "numpy.atleast_2d()", "path": "reference/generated/numpy.atleast_2d", "type": "numpy.atleast_2d", "text": "\nView inputs as arrays with at least two dimensions.\n\nOne or more array-like sequences. Non-array inputs are converted to arrays.\nArrays that already have two or more dimensions are preserved.\n\nAn array, or list of arrays, each with `a.ndim >= 2`. Copies are avoided where\npossible, and views with two or more dimensions are returned.\n\nSee also\n\n"}, {"name": "numpy.atleast_3d()", "path": "reference/generated/numpy.atleast_3d", "type": "numpy.atleast_3d", "text": "\nView inputs as arrays with at least three dimensions.\n\nOne or more array-like sequences. Non-array inputs are converted to arrays.\nArrays that already have three or more dimensions are preserved.\n\nAn array, or list of arrays, each with `a.ndim >= 3`. Copies are avoided where\npossible, and views with three or more dimensions are returned. For example, a\n1-D array of shape `(N,)` becomes a view of shape `(1, N, 1)`, and a 2-D array\nof shape `(M, N)` becomes a view of shape `(M, N, 1)`.\n\nSee also\n\n"}, {"name": "numpy.average()", "path": "reference/generated/numpy.average", "type": "numpy.average", "text": "\nCompute the weighted average along the specified axis.\n\nArray containing data to be averaged. If `a` is not an array, a conversion is\nattempted.\n\nAxis or axes along which to average `a`. The default, axis=None, will average\nover all of the elements of the input array. If axis is negative it counts\nfrom the last to the first axis.\n\nNew in version 1.7.0.\n\nIf axis is a tuple of ints, averaging is performed on all of the axes\nspecified in the tuple instead of a single axis or all the axes as before.\n\nAn array of weights associated with the values in `a`. Each value in `a`\ncontributes to the average according to its associated weight. The weights\narray can either be 1-D (in which case its length must be the size of `a`\nalong the given axis) or of the same shape as `a`. If `weights=None`, then all\ndata in `a` are assumed to have a weight equal to one. The 1-D calculation is:\n\nThe only constraint on `weights` is that `sum(weights)` must not be 0.\n\nDefault is `False`. If `True`, the tuple (`average`, `sum_of_weights`) is\nreturned, otherwise only the average is returned. If `weights=None`,\n`sum_of_weights` is equivalent to the number of elements over which the\naverage is taken.\n\nReturn the average along the specified axis. When `returned` is `True`, return\na tuple with the average as the first element and the sum of the weights as\nthe second element. `sum_of_weights` is of the same type as `retval`. The\nresult dtype follows a genereal pattern. If `weights` is None, the result\ndtype will be that of `a` , or `float64` if `a` is integral. Otherwise, if\n`weights` is not None and `a` is non- integral, the result type will be the\ntype of lowest precision capable of representing values of both `a` and\n`weights`. If `a` happens to be integral, the previous rules still applies but\nthe result dtype will at least be `float64`.\n\nWhen all weights along axis are zero. See `numpy.ma.average` for a version\nrobust to this type of error.\n\nWhen the length of 1D `weights` is not the same as the shape of `a` along\naxis.\n\nSee also\n\naverage for masked arrays \u2013 useful if your data contains \u201cmissing\u201d values\n\nReturns the type that results from applying the numpy type promotion rules to\nthe arguments.\n\n"}, {"name": "numpy.AxisError()", "path": "reference/generated/numpy.axiserror", "type": "numpy.AxisError", "text": "\nAxis supplied was invalid.\n\nThis is raised whenever an `axis` parameter is specified that is larger than\nthe number of array dimensions. For compatibility with code written against\nolder numpy versions, which raised a mixture of `ValueError` and `IndexError`\nfor this situation, this exception subclasses both to ensure that `except\nValueError` and `except IndexError` statements continue to catch `AxisError`.\n\nNew in version 1.13.\n\nThe out of bounds axis or a custom exception message. If an axis is provided,\nthen `ndim` should be specified as well.\n\nThe number of array dimensions.\n\nA prefix for the exception message.\n\nNegative axes are preserved:\n\nThe class constructor generally takes the axis and arrays\u2019 dimensionality as\narguments:\n\nAlternatively, a custom exception message can be passed:\n\nThe out of bounds axis or `None` if a custom exception message was provided.\nThis should be the axis as passed by the user, before any normalization to\nresolve negative indices.\n\nNew in version 1.22.\n\nThe number of array dimensions or `None` if a custom exception message was\nprovided.\n\nNew in version 1.22.\n\n"}, {"name": "numpy.bartlett()", "path": "reference/generated/numpy.bartlett", "type": "numpy.bartlett", "text": "\nReturn the Bartlett window.\n\nThe Bartlett window is very similar to a triangular window, except that the\nend points are at zero. It is often used in signal processing for tapering a\nsignal, without generating too much ripple in the frequency domain.\n\nNumber of points in the output window. If zero or less, an empty array is\nreturned.\n\nThe triangular window, with the maximum value normalized to one (the value one\nappears only if the number of samples is odd), with the first and last samples\nequal to zero.\n\nSee also\n\nThe Bartlett window is defined as\n\nMost references to the Bartlett window come from the signal processing\nliterature, where it is used as one of many windowing functions for smoothing\nvalues. Note that convolution with this window produces linear interpolation.\nIt is also known as an apodization (which means\u201dremoving the foot\u201d, i.e.\nsmoothing discontinuities at the beginning and end of the sampled signal) or\ntapering function. The fourier transform of the Bartlett is the product of two\nsinc functions. Note the excellent discussion in Kanasewich.\n\nM.S. Bartlett, \u201cPeriodogram Analysis and Continuous Spectra\u201d, Biometrika 37,\n1-16, 1950.\n\nE.R. Kanasewich, \u201cTime Sequence Analysis in Geophysics\u201d, The University of\nAlberta Press, 1975, pp. 109-110.\n\nA.V. Oppenheim and R.W. Schafer, \u201cDiscrete-Time Signal Processing\u201d, Prentice-\nHall, 1999, pp. 468-471.\n\nWikipedia, \u201cWindow function\u201d, https://en.wikipedia.org/wiki/Window_function\n\nW.H. Press, B.P. Flannery, S.A. Teukolsky, and W.T. Vetterling, \u201cNumerical\nRecipes\u201d, Cambridge University Press, 1986, page 429.\n\nPlot the window and its frequency response (requires SciPy and matplotlib):\n\n"}, {"name": "numpy.base_repr()", "path": "reference/generated/numpy.base_repr", "type": "numpy.base_repr", "text": "\nReturn a string representation of a number in the given base system.\n\nThe value to convert. Positive and negative values are handled.\n\nConvert `number` to the `base` number system. The valid range is 2-36, the\ndefault value is 2.\n\nNumber of zeros padded on the left. Default is 0 (no padding).\n\nString representation of `number` in `base` system.\n\nSee also\n\nFaster version of `base_repr` for base 2.\n\n"}, {"name": "numpy.binary_repr()", "path": "reference/generated/numpy.binary_repr", "type": "numpy.binary_repr", "text": "\nReturn the binary representation of the input number as a string.\n\nFor negative numbers, if width is not given, a minus sign is added to the\nfront. If width is given, the two\u2019s complement of the number is returned, with\nrespect to that width.\n\nIn a two\u2019s-complement system negative numbers are represented by the two\u2019s\ncomplement of the absolute value. This is the most common method of\nrepresenting signed integers on computers [1]. A N-bit two\u2019s-complement system\ncan represent every integer in the range \\\\(-2^{N-1}\\\\) to \\\\(+2^{N-1}-1\\\\).\n\nOnly an integer decimal number can be used.\n\nThe length of the returned string if `num` is positive, or the length of the\ntwo\u2019s complement if `num` is negative, provided that `width` is at least a\nsufficient number of bits for `num` to be represented in the designated form.\n\nIf the `width` value is insufficient, it will be ignored, and `num` will be\nreturned in binary (`num` > 0) or two\u2019s complement (`num` < 0) form with its\nwidth equal to the minimum number of bits needed to represent the number in\nthe designated form. This behavior is deprecated and will later raise an\nerror.\n\nDeprecated since version 1.12.0.\n\nBinary representation of `num` or two\u2019s complement of `num`.\n\nSee also\n\nReturn a string representation of a number in the given base system.\n\nPython\u2019s built-in binary representation generator of an integer.\n\n`binary_repr` is equivalent to using `base_repr` with base 2, but about 25x\nfaster.\n\nWikipedia, \u201cTwo\u2019s complement\u201d, https://en.wikipedia.org/wiki/Two\u2019s_complement\n\nThe two\u2019s complement is returned when the input number is negative and width\nis specified:\n\n"}, {"name": "numpy.bincount()", "path": "reference/generated/numpy.bincount", "type": "numpy.bincount", "text": "\nCount number of occurrences of each value in array of non-negative ints.\n\nThe number of bins (of size 1) is one larger than the largest value in `x`. If\n`minlength` is specified, there will be at least this number of bins in the\noutput array (though it will be longer if necessary, depending on the contents\nof `x`). Each bin gives the number of occurrences of its index value in `x`.\nIf `weights` is specified the input array is weighted by it, i.e. if a value\n`n` is found at position `i`, `out[n] += weight[i]` instead of `out[n] += 1`.\n\nInput array.\n\nWeights, array of the same shape as `x`.\n\nA minimum number of bins for the output array.\n\nNew in version 1.6.0.\n\nThe result of binning the input array. The length of `out` is equal to\n`np.amax(x)+1`.\n\nIf the input is not 1-dimensional, or contains elements with negative values,\nor if `minlength` is negative.\n\nIf the type of the input is float or complex.\n\nSee also\n\nThe input array needs to be of integer dtype, otherwise a TypeError is raised:\n\nA possible use of `bincount` is to perform sums over variable-size chunks of\nan array, using the `weights` keyword.\n\n"}, {"name": "numpy.bitwise_and()", "path": "reference/generated/numpy.bitwise_and", "type": "numpy.bitwise_and", "text": "\nCompute the bit-wise AND of two arrays element-wise.\n\nComputes the bit-wise AND of the underlying binary representation of the\nintegers in the input arrays. This ufunc implements the C/Python operator `&`.\n\nOnly integer and boolean types are handled. If `x1.shape != x2.shape`, they\nmust be broadcastable to a common shape (which becomes the shape of the\noutput).\n\nA location into which the result is stored. If provided, it must have a shape\nthat the inputs broadcast to. If not provided or None, a freshly-allocated\narray is returned. A tuple (possible only as a keyword argument) must have\nlength equal to the number of outputs.\n\nThis condition is broadcast over the input. At locations where the condition\nis True, the `out` array will be set to the ufunc result. Elsewhere, the `out`\narray will retain its original value. Note that if an uninitialized `out`\narray is created via the default `out=None`, locations within it where the\ncondition is False will remain uninitialized.\n\nFor other keyword-only arguments, see the ufunc docs.\n\nResult. This is a scalar if both `x1` and `x2` are scalars.\n\nSee also\n\nReturn the binary representation of the input number as a string.\n\nThe number 13 is represented by `00001101`. Likewise, 17 is represented by\n`00010001`. The bit-wise AND of 13 and 17 is therefore `000000001`, or 1:\n\nThe `&` operator can be used as a shorthand for `np.bitwise_and` on ndarrays.\n\n"}, {"name": "numpy.bitwise_or()", "path": "reference/generated/numpy.bitwise_or", "type": "numpy.bitwise_or", "text": "\nCompute the bit-wise OR of two arrays element-wise.\n\nComputes the bit-wise OR of the underlying binary representation of the\nintegers in the input arrays. This ufunc implements the C/Python operator `|`.\n\nOnly integer and boolean types are handled. If `x1.shape != x2.shape`, they\nmust be broadcastable to a common shape (which becomes the shape of the\noutput).\n\nA location into which the result is stored. If provided, it must have a shape\nthat the inputs broadcast to. If not provided or None, a freshly-allocated\narray is returned. A tuple (possible only as a keyword argument) must have\nlength equal to the number of outputs.\n\nThis condition is broadcast over the input. At locations where the condition\nis True, the `out` array will be set to the ufunc result. Elsewhere, the `out`\narray will retain its original value. Note that if an uninitialized `out`\narray is created via the default `out=None`, locations within it where the\ncondition is False will remain uninitialized.\n\nFor other keyword-only arguments, see the ufunc docs.\n\nResult. This is a scalar if both `x1` and `x2` are scalars.\n\nSee also\n\nReturn the binary representation of the input number as a string.\n\nThe number 13 has the binary representation `00001101`. Likewise, 16 is\nrepresented by `00010000`. The bit-wise OR of 13 and 16 is then `000111011`,\nor 29:\n\nThe `|` operator can be used as a shorthand for `np.bitwise_or` on ndarrays.\n\n"}, {"name": "numpy.bitwise_xor()", "path": "reference/generated/numpy.bitwise_xor", "type": "numpy.bitwise_xor", "text": "\nCompute the bit-wise XOR of two arrays element-wise.\n\nComputes the bit-wise XOR of the underlying binary representation of the\nintegers in the input arrays. This ufunc implements the C/Python operator `^`.\n\nOnly integer and boolean types are handled. If `x1.shape != x2.shape`, they\nmust be broadcastable to a common shape (which becomes the shape of the\noutput).\n\nA location into which the result is stored. If provided, it must have a shape\nthat the inputs broadcast to. If not provided or None, a freshly-allocated\narray is returned. A tuple (possible only as a keyword argument) must have\nlength equal to the number of outputs.\n\nThis condition is broadcast over the input. At locations where the condition\nis True, the `out` array will be set to the ufunc result. Elsewhere, the `out`\narray will retain its original value. Note that if an uninitialized `out`\narray is created via the default `out=None`, locations within it where the\ncondition is False will remain uninitialized.\n\nFor other keyword-only arguments, see the ufunc docs.\n\nResult. This is a scalar if both `x1` and `x2` are scalars.\n\nSee also\n\nReturn the binary representation of the input number as a string.\n\nThe number 13 is represented by `00001101`. Likewise, 17 is represented by\n`00010001`. The bit-wise XOR of 13 and 17 is therefore `00011100`, or 28:\n\nThe `^` operator can be used as a shorthand for `np.bitwise_xor` on ndarrays.\n\n"}, {"name": "numpy.blackman()", "path": "reference/generated/numpy.blackman", "type": "numpy.blackman", "text": "\nReturn the Blackman window.\n\nThe Blackman window is a taper formed by using the first three terms of a\nsummation of cosines. It was designed to have close to the minimal leakage\npossible. It is close to optimal, only slightly worse than a Kaiser window.\n\nNumber of points in the output window. If zero or less, an empty array is\nreturned.\n\nThe window, with the maximum value normalized to one (the value one appears\nonly if the number of samples is odd).\n\nSee also\n\nThe Blackman window is defined as\n\nMost references to the Blackman window come from the signal processing\nliterature, where it is used as one of many windowing functions for smoothing\nvalues. It is also known as an apodization (which means \u201cremoving the foot\u201d,\ni.e. smoothing discontinuities at the beginning and end of the sampled signal)\nor tapering function. It is known as a \u201cnear optimal\u201d tapering function,\nalmost as good (by some measures) as the kaiser window.\n\nBlackman, R.B. and Tukey, J.W., (1958) The measurement of power spectra, Dover\nPublications, New York.\n\nOppenheim, A.V., and R.W. Schafer. Discrete-Time Signal Processing. Upper\nSaddle River, NJ: Prentice-Hall, 1999, pp. 468-471.\n\nPlot the window and the frequency response:\n\n"}, {"name": "numpy.block()", "path": "reference/generated/numpy.block", "type": "numpy.block", "text": "\nAssemble an nd-array from nested lists of blocks.\n\nBlocks in the innermost lists are concatenated (see `concatenate`) along the\nlast dimension (-1), then these are concatenated along the second-last\ndimension (-2), and so on until the outermost list is reached.\n\nBlocks can be of any dimension, but will not be broadcasted using the normal\nrules. Instead, leading axes of size 1 are inserted, to make `block.ndim` the\nsame for all blocks. This is primarily useful for working with scalars, and\nmeans that code like `np.block([v, 1])` is valid, where `v.ndim == 1`.\n\nWhen the nested list is two levels deep, this allows block matrices to be\nconstructed from their components.\n\nNew in version 1.13.0.\n\nIf passed a single ndarray or scalar (a nested list of depth 0), this is\nreturned unmodified (and not copied).\n\nElements shapes must match along the appropriate axes (without broadcasting),\nbut leading 1s will be prepended to the shape as necessary to make the\ndimensions match.\n\nThe array assembled from the given blocks.\n\nThe dimensionality of the output is equal to the greatest of: * the\ndimensionality of all the inputs * the depth to which the input list is nested\n\nSee also\n\nJoin a sequence of arrays along an existing axis.\n\nJoin a sequence of arrays along a new axis.\n\nStack arrays in sequence vertically (row wise).\n\nStack arrays in sequence horizontally (column wise).\n\nStack arrays in sequence depth wise (along third axis).\n\nStack 1-D arrays as columns into a 2-D array.\n\nSplit an array into multiple sub-arrays vertically (row-wise).\n\nWhen called with only scalars, `np.block` is equivalent to an ndarray call. So\n`np.block([[1, 2], [3, 4]])` is equivalent to `np.array([[1, 2], [3, 4]])`.\n\nThis function does not enforce that the blocks lie on a fixed grid.\n`np.block([[a, b], [c, d]])` is not restricted to arrays of the form:\n\nBut is also allowed to produce, for some `a, b, c, d`:\n\nSince concatenation happens along the last axis first, `block` is _not_\ncapable of producing the following directly:\n\nMatlab\u2019s \u201csquare bracket stacking\u201d, `[A, B, ...; p, q, ...]`, is equivalent to\n`np.block([[A, B, ...], [p, q, ...]])`.\n\nThe most common use of this function is to build a block matrix\n\nWith a list of depth 1, `block` can be used as `hstack`\n\nWith a list of depth 2, `block` can be used in place of `vstack`:\n\nIt can also be used in places of `atleast_1d` and `atleast_2d`\n\n"}, {"name": "numpy.bmat()", "path": "reference/generated/numpy.bmat", "type": "numpy.bmat", "text": "\nBuild a matrix object from a string, nested sequence, or array.\n\nInput data. If a string, variables in the current scope may be referenced by\nname.\n\nA dictionary that replaces local operands in current frame. Ignored if `obj`\nis not a string or `gdict` is None.\n\nA dictionary that replaces global operands in current frame. Ignored if `obj`\nis not a string.\n\nReturns a matrix object, which is a specialized 2-D array.\n\nSee also\n\nA generalization of this function for N-d arrays, that returns normal\nndarrays.\n\nAll the following expressions construct the same block matrix:\n\n"}, {"name": "numpy.broadcast", "path": "reference/generated/numpy.broadcast", "type": "numpy.broadcast", "text": "\nProduce an object that mimics broadcasting.\n\nInput parameters.\n\nBroadcast the input parameters against one another, and return an object that\nencapsulates the result. Amongst others, it has `shape` and `nd` properties,\nand may be used as an iterator.\n\nSee also\n\nManually adding two vectors, using broadcasting:\n\nCompare against built-in broadcasting:\n\ncurrent index in broadcasted result\n\ntuple of iterators along `self`\u2019s \u201ccomponents.\u201d\n\nNumber of dimensions of broadcasted result.\n\nNumber of dimensions of broadcasted result.\n\nNumber of iterators possessed by the broadcasted result.\n\nShape of broadcasted result.\n\nTotal size of broadcasted result.\n\n`reset`()\n\nReset the broadcasted result's iterator(s).\n\n"}, {"name": "numpy.broadcast_arrays()", "path": "reference/generated/numpy.broadcast_arrays", "type": "numpy.broadcast_arrays", "text": "\nBroadcast any number of arrays against each other.\n\nThe arrays to broadcast.\n\nIf True, then sub-classes will be passed-through, otherwise the returned\narrays will be forced to be a base-class array (default).\n\nThese arrays are views on the original arrays. They are typically not\ncontiguous. Furthermore, more than one element of a broadcasted array may\nrefer to a single memory location. If you need to write to the arrays, make\ncopies first. While you can set the `writable` flag True, writing to a single\noutput value may end up changing more than one location in the output array.\n\nDeprecated since version 1.17: The output is currently marked so that if\nwritten to, a deprecation warning will be emitted. A future version will set\nthe `writable` flag False so writing to it will raise an error.\n\nSee also\n\nHere is a useful idiom for getting contiguous copies instead of non-contiguous\nviews.\n\n"}, {"name": "numpy.broadcast_shapes()", "path": "reference/generated/numpy.broadcast_shapes", "type": "numpy.broadcast_shapes", "text": "\nBroadcast the input shapes into a single shape.\n\nLearn more about broadcasting here.\n\nNew in version 1.20.0.\n\nThe shapes to be broadcast against each other.\n\nBroadcasted shape.\n\nIf the shapes are not compatible and cannot be broadcast according to NumPy\u2019s\nbroadcasting rules.\n\nSee also\n\n"}, {"name": "numpy.broadcast_to()", "path": "reference/generated/numpy.broadcast_to", "type": "numpy.broadcast_to", "text": "\nBroadcast an array to a new shape.\n\nThe array to broadcast.\n\nThe shape of the desired array. A single integer `i` is interpreted as `(i,)`.\n\nIf True, then sub-classes will be passed-through, otherwise the returned array\nwill be forced to be a base-class array (default).\n\nA readonly view on the original array with the given shape. It is typically\nnot contiguous. Furthermore, more than one element of a broadcasted array may\nrefer to a single memory location.\n\nIf the array is not compatible with the new shape according to NumPy\u2019s\nbroadcasting rules.\n\nSee also\n\nNew in version 1.10.0.\n\n"}, {"name": "numpy.busday_count()", "path": "reference/generated/numpy.busday_count", "type": "numpy.busday_count", "text": "\nCounts the number of valid days between `begindates` and `enddates`, not\nincluding the day of `enddates`.\n\nIf `enddates` specifies a date value that is earlier than the corresponding\n`begindates` date value, the count will be negative.\n\nNew in version 1.7.0.\n\nThe array of the first dates for counting.\n\nThe array of the end dates for counting, which are excluded from the count\nthemselves.\n\nA seven-element array indicating which of Monday through Sunday are valid\ndays. May be specified as a length-seven list or array, like [1,1,1,1,1,0,0];\na length-seven string, like \u20181111100\u2019; or a string like \u201cMon Tue Wed Thu Fri\u201d,\nmade up of 3-character abbreviations for weekdays, optionally separated by\nwhite space. Valid abbreviations are: Mon Tue Wed Thu Fri Sat Sun\n\nAn array of dates to consider as invalid dates. They may be specified in any\norder, and NaT (not-a-time) dates are ignored. This list is saved in a\nnormalized form that is suited for fast calculations of valid days.\n\nA `busdaycalendar` object which specifies the valid days. If this parameter is\nprovided, neither weekmask nor holidays may be provided.\n\nIf provided, this array is filled with the result.\n\nAn array with a shape from broadcasting `begindates` and `enddates` together,\ncontaining the number of valid days between the begin and end dates.\n\nSee also\n\nAn object that specifies a custom set of valid days.\n\nReturns a boolean array indicating valid days.\n\nApplies an offset counted in valid days.\n\n"}, {"name": "numpy.busday_offset()", "path": "reference/generated/numpy.busday_offset", "type": "numpy.busday_offset", "text": "\nFirst adjusts the date to fall on a valid day according to the `roll` rule,\nthen applies offsets to the given dates counted in valid days.\n\nNew in version 1.7.0.\n\nThe array of dates to process.\n\nThe array of offsets, which is broadcast with `dates`.\n\nHow to treat dates that do not fall on a valid day. The default is \u2018raise\u2019.\n\nA seven-element array indicating which of Monday through Sunday are valid\ndays. May be specified as a length-seven list or array, like [1,1,1,1,1,0,0];\na length-seven string, like \u20181111100\u2019; or a string like \u201cMon Tue Wed Thu Fri\u201d,\nmade up of 3-character abbreviations for weekdays, optionally separated by\nwhite space. Valid abbreviations are: Mon Tue Wed Thu Fri Sat Sun\n\nAn array of dates to consider as invalid dates. They may be specified in any\norder, and NaT (not-a-time) dates are ignored. This list is saved in a\nnormalized form that is suited for fast calculations of valid days.\n\nA `busdaycalendar` object which specifies the valid days. If this parameter is\nprovided, neither weekmask nor holidays may be provided.\n\nIf provided, this array is filled with the result.\n\nAn array with a shape from broadcasting `dates` and `offsets` together,\ncontaining the dates with offsets applied.\n\nSee also\n\nAn object that specifies a custom set of valid days.\n\nReturns a boolean array indicating valid days.\n\nCounts how many valid days are in a half-open date range.\n\n"}, {"name": "numpy.busdaycalendar()", "path": "reference/generated/numpy.busdaycalendar", "type": "numpy.busdaycalendar", "text": "\nA business day calendar object that efficiently stores information defining\nvalid days for the busday family of functions.\n\nThe default valid days are Monday through Friday (\u201cbusiness days\u201d). A\nbusdaycalendar object can be specified with any set of weekly valid days, plus\nan optional \u201choliday\u201d dates that always will be invalid.\n\nOnce a busdaycalendar object is created, the weekmask and holidays cannot be\nmodified.\n\nNew in version 1.7.0.\n\nA seven-element array indicating which of Monday through Sunday are valid\ndays. May be specified as a length-seven list or array, like [1,1,1,1,1,0,0];\na length-seven string, like \u20181111100\u2019; or a string like \u201cMon Tue Wed Thu Fri\u201d,\nmade up of 3-character abbreviations for weekdays, optionally separated by\nwhite space. Valid abbreviations are: Mon Tue Wed Thu Fri Sat Sun\n\nAn array of dates to consider as invalid dates, no matter which weekday they\nfall upon. Holiday dates may be specified in any order, and NaT (not-a-time)\ndates are ignored. This list is saved in a normalized form that is suited for\nfast calculations of valid days.\n\nA business day calendar object containing the specified weekmask and holidays\nvalues.\n\nSee also\n\nReturns a boolean array indicating valid days.\n\nApplies an offset counted in valid days.\n\nCounts how many valid days are in a half-open date range.\n\nA copy of the seven-element boolean mask indicating valid days.\n\nA copy of the holiday array indicating additional invalid days.\n\n"}, {"name": "numpy.byte", "path": "reference/arrays.scalars#numpy.byte", "type": "Scalars", "text": "\nSigned integer type, compatible with C `char`.\n\n`'b'`\n\n`numpy.int8`: 8-bit signed integer (`-128` to `127`).\n\n"}, {"name": "numpy.byte_bounds()", "path": "reference/generated/numpy.byte_bounds", "type": "numpy.byte_bounds", "text": "\nReturns pointers to the end-points of an array.\n\nInput array. It must conform to the Python-side of the array interface.\n\nThe first integer is the first byte of the array, the second integer is just\npast the last byte of the array. If `a` is not contiguous it will not use\nevery byte between the (`low`, `high`) values.\n\n"}, {"name": "numpy.bytes_", "path": "reference/arrays.scalars#numpy.bytes_", "type": "Scalars", "text": "\nA byte string.\n\nWhen used in arrays, this type strips trailing null bytes.\n\n`'S'`\n\n`numpy.string_`\n\n"}, {"name": "numpy.c_", "path": "reference/generated/numpy.c_", "type": "numpy.c_", "text": "\nTranslates slice objects to concatenation along the second axis.\n\nThis is short-hand for `np.r_['-1,2,0', index expression]`, which is useful\nbecause of its common occurrence. In particular, arrays will be stacked along\ntheir last axis after being upgraded to at least 2-D with 1\u2019s post-pended to\nthe shape (column vectors made out of 1-D arrays).\n\nSee also\n\nStack 1-D arrays as columns into a 2-D array.\n\nFor more detailed documentation.\n\n"}, {"name": "numpy.can_cast()", "path": "reference/generated/numpy.can_cast", "type": "numpy.can_cast", "text": "\nReturns True if cast between data types can occur according to the casting\nrule. If from is a scalar or array scalar, also returns True if the scalar\nvalue can be cast without overflow or truncation to an integer.\n\nData type, scalar, or array to cast from.\n\nData type to cast to.\n\nControls what kind of data casting may occur.\n\nTrue if cast can occur according to the casting rule.\n\nSee also\n\nChanged in version 1.17.0: Casting between a simple data type and a structured\none is possible only for \u201cunsafe\u201d casting. Casting to multiple fields is\nallowed, but casting from multiple fields is not.\n\nChanged in version 1.9.0: Casting from numeric to string types in \u2018safe\u2019\ncasting mode requires that the string dtype length is long enough to store the\nmaximum integer/float value converted.\n\nBasic examples\n\nCasting scalars\n\nArray scalar checks the value, array does not\n\nUsing the casting rules\n\n"}, {"name": "numpy.cbrt()", "path": "reference/generated/numpy.cbrt", "type": "numpy.cbrt", "text": "\nReturn the cube-root of an array, element-wise.\n\nNew in version 1.10.0.\n\nThe values whose cube-roots are required.\n\nA location into which the result is stored. If provided, it must have a shape\nthat the inputs broadcast to. If not provided or None, a freshly-allocated\narray is returned. A tuple (possible only as a keyword argument) must have\nlength equal to the number of outputs.\n\nThis condition is broadcast over the input. At locations where the condition\nis True, the `out` array will be set to the ufunc result. Elsewhere, the `out`\narray will retain its original value. Note that if an uninitialized `out`\narray is created via the default `out=None`, locations within it where the\ncondition is False will remain uninitialized.\n\nFor other keyword-only arguments, see the ufunc docs.\n\nAn array of the same shape as `x`, containing the cube cube-root of each\nelement in `x`. If `out` was provided, `y` is a reference to it. This is a\nscalar if `x` is a scalar.\n\n"}, {"name": "numpy.cdouble()", "path": "reference/arrays.scalars#numpy.cdouble", "type": "Scalars", "text": "\nComplex number type composed of two double-precision floating-point numbers,\ncompatible with Python `complex`.\n\n`'D'`\n\n`numpy.cfloat`\n\n`numpy.complex_`\n\n`numpy.complex128`: Complex number type composed of 2 64-bit-precision\nfloating-point numbers.\n\n"}, {"name": "numpy.ceil()", "path": "reference/generated/numpy.ceil", "type": "numpy.ceil", "text": "\nReturn the ceiling of the input, element-wise.\n\nThe ceil of the scalar `x` is the smallest integer `i`, such that `i >= x`. It\nis often denoted as \\\\(\\lceil x \\rceil\\\\).\n\nInput data.\n\nA location into which the result is stored. If provided, it must have a shape\nthat the inputs broadcast to. If not provided or None, a freshly-allocated\narray is returned. A tuple (possible only as a keyword argument) must have\nlength equal to the number of outputs.\n\nThis condition is broadcast over the input. At locations where the condition\nis True, the `out` array will be set to the ufunc result. Elsewhere, the `out`\narray will retain its original value. Note that if an uninitialized `out`\narray is created via the default `out=None`, locations within it where the\ncondition is False will remain uninitialized.\n\nFor other keyword-only arguments, see the ufunc docs.\n\nThe ceiling of each element in `x`, with `float` dtype. This is a scalar if\n`x` is a scalar.\n\nSee also\n\n"}, {"name": "numpy.cfloat", "path": "reference/arrays.scalars#numpy.cfloat", "type": "Scalars", "text": "\nalias of `numpy.cdouble`\n\n"}, {"name": "numpy.char.chararray()", "path": "reference/generated/numpy.char.chararray", "type": "numpy.char.chararray", "text": "\nProvides a convenient view on arrays of string and unicode values.\n\nNote\n\nThe `chararray` class exists for backwards compatibility with Numarray, it is\nnot recommended for new development. Starting from numpy 1.4, if one needs\narrays of strings, it is recommended to use arrays of `dtype` `object_`,\n`string_` or `unicode_`, and use the free functions in the `numpy.char` module\nfor fast vectorized string operations.\n\nVersus a regular NumPy array of type `str` or `unicode`, this class adds the\nfollowing functionality:\n\nchararrays should be created using `numpy.char.array` or `numpy.char.asarray`,\nrather than this constructor directly.\n\nThis constructor creates the array, using `buffer` (with `offset` and\n`strides`) if it is not `None`. If `buffer` is `None`, then constructs a new\narray with `strides` in \u201cC order\u201d, unless both `len(shape) >= 2` and\n`order='F'`, in which case `strides` is in \u201cFortran order\u201d.\n\nShape of the array.\n\nLength of each array element, in number of characters. Default is 1.\n\nAre the array elements of type unicode (True) or string (False). Default is\nFalse.\n\nMemory address of the start of the array data. Default is None, in which case\na new array is created.\n\nFixed stride displacement from the beginning of an axis? Default is 0. Needs\nto be >=0.\n\nStrides for the array (see `ndarray.strides` for full description). Default is\nNone.\n\nThe order in which the array data is stored in memory: \u2018C\u2019 -> \u201crow major\u201d\norder (the default), \u2018F\u2019 -> \u201ccolumn major\u201d (Fortran) order.\n\nThe transposed array.\n\nBase object if memory is from some other object.\n\nAn object to simplify the interaction of the array with the ctypes module.\n\nPython buffer object pointing to the start of the array\u2019s data.\n\nData-type of the array\u2019s elements.\n\nInformation about the memory layout of the array.\n\nA 1-D iterator over the array.\n\nThe imaginary part of the array.\n\nLength of one array element in bytes.\n\nTotal bytes consumed by the elements of the array.\n\nNumber of array dimensions.\n\nThe real part of the array.\n\nTuple of array dimensions.\n\nNumber of elements in the array.\n\nTuple of bytes to step in each dimension when traversing an array.\n\n`astype`(dtype[, order, casting, subok, copy])\n\nCopy of the array, cast to a specified type.\n\n`argsort`([axis, kind, order])\n\nReturns the indices that would sort this array.\n\n`copy`([order])\n\nReturn a copy of the array.\n\n`count`(sub[, start, end])\n\nReturns an array with the number of non-overlapping occurrences of substring\n`sub` in the range [`start`, `end`].\n\n`decode`([encoding, errors])\n\nCalls `str.decode` element-wise.\n\n`dump`(file)\n\nDump a pickle of the array to the specified file.\n\n`dumps`()\n\nReturns the pickle of the array as a string.\n\n`encode`([encoding, errors])\n\nCalls `str.encode` element-wise.\n\n`endswith`(suffix[, start, end])\n\nReturns a boolean array which is `True` where the string element in `self`\nends with `suffix`, otherwise `False`.\n\n`expandtabs`([tabsize])\n\nReturn a copy of each string element where all tab characters are replaced by\none or more spaces.\n\n`fill`(value)\n\nFill the array with a scalar value.\n\n`find`(sub[, start, end])\n\nFor each element, return the lowest index in the string where substring `sub`\nis found.\n\n`flatten`([order])\n\nReturn a copy of the array collapsed into one dimension.\n\n`getfield`(dtype[, offset])\n\nReturns a field of the given array as a certain type.\n\n`index`(sub[, start, end])\n\nLike `find`, but raises `ValueError` when the substring is not found.\n\n`isalnum`()\n\nReturns true for each element if all characters in the string are alphanumeric\nand there is at least one character, false otherwise.\n\n`isalpha`()\n\nReturns true for each element if all characters in the string are alphabetic\nand there is at least one character, false otherwise.\n\n`isdecimal`()\n\nFor each element in `self`, return True if there are only decimal characters\nin the element.\n\n`isdigit`()\n\nReturns true for each element if all characters in the string are digits and\nthere is at least one character, false otherwise.\n\n`islower`()\n\nReturns true for each element if all cased characters in the string are\nlowercase and there is at least one cased character, false otherwise.\n\n`isnumeric`()\n\nFor each element in `self`, return True if there are only numeric characters\nin the element.\n\n`isspace`()\n\nReturns true for each element if there are only whitespace characters in the\nstring and there is at least one character, false otherwise.\n\n`istitle`()\n\nReturns true for each element if the element is a titlecased string and there\nis at least one character, false otherwise.\n\n`isupper`()\n\nReturns true for each element if all cased characters in the string are\nuppercase and there is at least one character, false otherwise.\n\n`item`(*args)\n\nCopy an element of an array to a standard Python scalar and return it.\n\n`join`(seq)\n\nReturn a string which is the concatenation of the strings in the sequence\n`seq`.\n\n`ljust`(width[, fillchar])\n\nReturn an array with the elements of `self` left-justified in a string of\nlength `width`.\n\n`lower`()\n\nReturn an array with the elements of `self` converted to lowercase.\n\n`lstrip`([chars])\n\nFor each element in `self`, return a copy with the leading characters removed.\n\n`nonzero`()\n\nReturn the indices of the elements that are non-zero.\n\n`put`(indices, values[, mode])\n\nSet `a.flat[n] = values[n]` for all `n` in indices.\n\n`ravel`([order])\n\nReturn a flattened array.\n\n`repeat`(repeats[, axis])\n\nRepeat elements of an array.\n\n`replace`(old, new[, count])\n\nFor each element in `self`, return a copy of the string with all occurrences\nof substring `old` replaced by `new`.\n\n`reshape`(shape[, order])\n\nReturns an array containing the same data with a new shape.\n\n`resize`(new_shape[, refcheck])\n\nChange shape and size of array in-place.\n\n`rfind`(sub[, start, end])\n\nFor each element in `self`, return the highest index in the string where\nsubstring `sub` is found, such that `sub` is contained within [`start`,\n`end`].\n\n`rindex`(sub[, start, end])\n\nLike `rfind`, but raises `ValueError` when the substring `sub` is not found.\n\n`rjust`(width[, fillchar])\n\nReturn an array with the elements of `self` right-justified in a string of\nlength `width`.\n\n`rsplit`([sep, maxsplit])\n\nFor each element in `self`, return a list of the words in the string, using\n`sep` as the delimiter string.\n\n`rstrip`([chars])\n\nFor each element in `self`, return a copy with the trailing characters\nremoved.\n\n`searchsorted`(v[, side, sorter])\n\nFind indices where elements of v should be inserted in a to maintain order.\n\n`setfield`(val, dtype[, offset])\n\nPut a value into a specified place in a field defined by a data-type.\n\n`setflags`([write, align, uic])\n\nSet array flags WRITEABLE, ALIGNED, (WRITEBACKIFCOPY and UPDATEIFCOPY),\nrespectively.\n\n`sort`([axis, kind, order])\n\nSort an array in-place.\n\n`split`([sep, maxsplit])\n\nFor each element in `self`, return a list of the words in the string, using\n`sep` as the delimiter string.\n\n`splitlines`([keepends])\n\nFor each element in `self`, return a list of the lines in the element,\nbreaking at line boundaries.\n\n`squeeze`([axis])\n\nRemove axes of length one from `a`.\n\n`startswith`(prefix[, start, end])\n\nReturns a boolean array which is `True` where the string element in `self`\nstarts with `prefix`, otherwise `False`.\n\n`strip`([chars])\n\nFor each element in `self`, return a copy with the leading and trailing\ncharacters removed.\n\n`swapaxes`(axis1, axis2)\n\nReturn a view of the array with `axis1` and `axis2` interchanged.\n\n`swapcase`()\n\nFor each element in `self`, return a copy of the string with uppercase\ncharacters converted to lowercase and vice versa.\n\n`take`(indices[, axis, out, mode])\n\nReturn an array formed from the elements of `a` at the given indices.\n\n`title`()\n\nFor each element in `self`, return a titlecased version of the string: words\nstart with uppercase characters, all remaining cased characters are lowercase.\n\n`tofile`(fid[, sep, format])\n\nWrite array to a file as text or binary (default).\n\n`tolist`()\n\nReturn the array as an `a.ndim`-levels deep nested list of Python scalars.\n\n`tostring`([order])\n\nA compatibility alias for `tobytes`, with exactly the same behavior.\n\n`translate`(table[, deletechars])\n\nFor each element in `self`, return a copy of the string where all characters\noccurring in the optional argument `deletechars` are removed, and the\nremaining characters have been mapped through the given translation table.\n\n`transpose`(*axes)\n\nReturns a view of the array with axes transposed.\n\n`upper`()\n\nReturn an array with the elements of `self` converted to uppercase.\n\n`view`([dtype][, type])\n\nNew view of array with the same data.\n\n`zfill`(width)\n\nReturn the numeric string left-filled with zeros in a string of length\n`width`.\n\n"}, {"name": "numpy.chararray()", "path": "reference/generated/numpy.chararray", "type": "numpy.chararray", "text": "\nProvides a convenient view on arrays of string and unicode values.\n\nNote\n\nThe `chararray` class exists for backwards compatibility with Numarray, it is\nnot recommended for new development. Starting from numpy 1.4, if one needs\narrays of strings, it is recommended to use arrays of `dtype` `object_`,\n`string_` or `unicode_`, and use the free functions in the `numpy.char` module\nfor fast vectorized string operations.\n\nVersus a regular NumPy array of type `str` or `unicode`, this class adds the\nfollowing functionality:\n\nchararrays should be created using `numpy.char.array` or `numpy.char.asarray`,\nrather than this constructor directly.\n\nThis constructor creates the array, using `buffer` (with `offset` and\n`strides`) if it is not `None`. If `buffer` is `None`, then constructs a new\narray with `strides` in \u201cC order\u201d, unless both `len(shape) >= 2` and\n`order='F'`, in which case `strides` is in \u201cFortran order\u201d.\n\nShape of the array.\n\nLength of each array element, in number of characters. Default is 1.\n\nAre the array elements of type unicode (True) or string (False). Default is\nFalse.\n\nMemory address of the start of the array data. Default is None, in which case\na new array is created.\n\nFixed stride displacement from the beginning of an axis? Default is 0. Needs\nto be >=0.\n\nStrides for the array (see `ndarray.strides` for full description). Default is\nNone.\n\nThe order in which the array data is stored in memory: \u2018C\u2019 -> \u201crow major\u201d\norder (the default), \u2018F\u2019 -> \u201ccolumn major\u201d (Fortran) order.\n\nThe transposed array.\n\nBase object if memory is from some other object.\n\nAn object to simplify the interaction of the array with the ctypes module.\n\nPython buffer object pointing to the start of the array\u2019s data.\n\nData-type of the array\u2019s elements.\n\nInformation about the memory layout of the array.\n\nA 1-D iterator over the array.\n\nThe imaginary part of the array.\n\nLength of one array element in bytes.\n\nTotal bytes consumed by the elements of the array.\n\nNumber of array dimensions.\n\nThe real part of the array.\n\nTuple of array dimensions.\n\nNumber of elements in the array.\n\nTuple of bytes to step in each dimension when traversing an array.\n\n`astype`(dtype[, order, casting, subok, copy])\n\nCopy of the array, cast to a specified type.\n\n`argsort`([axis, kind, order])\n\nReturns the indices that would sort this array.\n\n`copy`([order])\n\nReturn a copy of the array.\n\n`count`(sub[, start, end])\n\nReturns an array with the number of non-overlapping occurrences of substring\n`sub` in the range [`start`, `end`].\n\n`decode`([encoding, errors])\n\nCalls `str.decode` element-wise.\n\n`dump`(file)\n\nDump a pickle of the array to the specified file.\n\n`dumps`()\n\nReturns the pickle of the array as a string.\n\n`encode`([encoding, errors])\n\nCalls `str.encode` element-wise.\n\n`endswith`(suffix[, start, end])\n\nReturns a boolean array which is `True` where the string element in `self`\nends with `suffix`, otherwise `False`.\n\n`expandtabs`([tabsize])\n\nReturn a copy of each string element where all tab characters are replaced by\none or more spaces.\n\n`fill`(value)\n\nFill the array with a scalar value.\n\n`find`(sub[, start, end])\n\nFor each element, return the lowest index in the string where substring `sub`\nis found.\n\n`flatten`([order])\n\nReturn a copy of the array collapsed into one dimension.\n\n`getfield`(dtype[, offset])\n\nReturns a field of the given array as a certain type.\n\n`index`(sub[, start, end])\n\nLike `find`, but raises `ValueError` when the substring is not found.\n\n`isalnum`()\n\nReturns true for each element if all characters in the string are alphanumeric\nand there is at least one character, false otherwise.\n\n`isalpha`()\n\nReturns true for each element if all characters in the string are alphabetic\nand there is at least one character, false otherwise.\n\n`isdecimal`()\n\nFor each element in `self`, return True if there are only decimal characters\nin the element.\n\n`isdigit`()\n\nReturns true for each element if all characters in the string are digits and\nthere is at least one character, false otherwise.\n\n`islower`()\n\nReturns true for each element if all cased characters in the string are\nlowercase and there is at least one cased character, false otherwise.\n\n`isnumeric`()\n\nFor each element in `self`, return True if there are only numeric characters\nin the element.\n\n`isspace`()\n\nReturns true for each element if there are only whitespace characters in the\nstring and there is at least one character, false otherwise.\n\n`istitle`()\n\nReturns true for each element if the element is a titlecased string and there\nis at least one character, false otherwise.\n\n`isupper`()\n\nReturns true for each element if all cased characters in the string are\nuppercase and there is at least one character, false otherwise.\n\n`item`(*args)\n\nCopy an element of an array to a standard Python scalar and return it.\n\n`join`(seq)\n\nReturn a string which is the concatenation of the strings in the sequence\n`seq`.\n\n`ljust`(width[, fillchar])\n\nReturn an array with the elements of `self` left-justified in a string of\nlength `width`.\n\n`lower`()\n\nReturn an array with the elements of `self` converted to lowercase.\n\n`lstrip`([chars])\n\nFor each element in `self`, return a copy with the leading characters removed.\n\n`nonzero`()\n\nReturn the indices of the elements that are non-zero.\n\n`put`(indices, values[, mode])\n\nSet `a.flat[n] = values[n]` for all `n` in indices.\n\n`ravel`([order])\n\nReturn a flattened array.\n\n`repeat`(repeats[, axis])\n\nRepeat elements of an array.\n\n`replace`(old, new[, count])\n\nFor each element in `self`, return a copy of the string with all occurrences\nof substring `old` replaced by `new`.\n\n`reshape`(shape[, order])\n\nReturns an array containing the same data with a new shape.\n\n`resize`(new_shape[, refcheck])\n\nChange shape and size of array in-place.\n\n`rfind`(sub[, start, end])\n\nFor each element in `self`, return the highest index in the string where\nsubstring `sub` is found, such that `sub` is contained within [`start`,\n`end`].\n\n`rindex`(sub[, start, end])\n\nLike `rfind`, but raises `ValueError` when the substring `sub` is not found.\n\n`rjust`(width[, fillchar])\n\nReturn an array with the elements of `self` right-justified in a string of\nlength `width`.\n\n`rsplit`([sep, maxsplit])\n\nFor each element in `self`, return a list of the words in the string, using\n`sep` as the delimiter string.\n\n`rstrip`([chars])\n\nFor each element in `self`, return a copy with the trailing characters\nremoved.\n\n`searchsorted`(v[, side, sorter])\n\nFind indices where elements of v should be inserted in a to maintain order.\n\n`setfield`(val, dtype[, offset])\n\nPut a value into a specified place in a field defined by a data-type.\n\n`setflags`([write, align, uic])\n\nSet array flags WRITEABLE, ALIGNED, (WRITEBACKIFCOPY and UPDATEIFCOPY),\nrespectively.\n\n`sort`([axis, kind, order])\n\nSort an array in-place.\n\n`split`([sep, maxsplit])\n\nFor each element in `self`, return a list of the words in the string, using\n`sep` as the delimiter string.\n\n`splitlines`([keepends])\n\nFor each element in `self`, return a list of the lines in the element,\nbreaking at line boundaries.\n\n`squeeze`([axis])\n\nRemove axes of length one from `a`.\n\n`startswith`(prefix[, start, end])\n\nReturns a boolean array which is `True` where the string element in `self`\nstarts with `prefix`, otherwise `False`.\n\n`strip`([chars])\n\nFor each element in `self`, return a copy with the leading and trailing\ncharacters removed.\n\n`swapaxes`(axis1, axis2)\n\nReturn a view of the array with `axis1` and `axis2` interchanged.\n\n`swapcase`()\n\nFor each element in `self`, return a copy of the string with uppercase\ncharacters converted to lowercase and vice versa.\n\n`take`(indices[, axis, out, mode])\n\nReturn an array formed from the elements of `a` at the given indices.\n\n`title`()\n\nFor each element in `self`, return a titlecased version of the string: words\nstart with uppercase characters, all remaining cased characters are lowercase.\n\n`tofile`(fid[, sep, format])\n\nWrite array to a file as text or binary (default).\n\n`tolist`()\n\nReturn the array as an `a.ndim`-levels deep nested list of Python scalars.\n\n`tostring`([order])\n\nA compatibility alias for `tobytes`, with exactly the same behavior.\n\n`translate`(table[, deletechars])\n\nFor each element in `self`, return a copy of the string where all characters\noccurring in the optional argument `deletechars` are removed, and the\nremaining characters have been mapped through the given translation table.\n\n`transpose`(*axes)\n\nReturns a view of the array with axes transposed.\n\n`upper`()\n\nReturn an array with the elements of `self` converted to uppercase.\n\n`view`([dtype][, type])\n\nNew view of array with the same data.\n\n`zfill`(width)\n\nReturn the numeric string left-filled with zeros in a string of length\n`width`.\n\n"}, {"name": "numpy.choose()", "path": "reference/generated/numpy.choose", "type": "numpy.choose", "text": "\nConstruct an array from an index array and a list of arrays to choose from.\n\nFirst of all, if confused or uncertain, definitely look at the Examples - in\nits full generality, this function is less simple than it might seem from the\nfollowing code description (below ndi = `numpy.lib.index_tricks`):\n\n`np.choose(a,c) == np.array([c[a[I]][I] for I in ndi.ndindex(a.shape)])`.\n\nBut this omits some subtleties. Here is a fully general summary:\n\nGiven an \u201cindex\u201d array (`a`) of integers and a sequence of `n` arrays\n(`choices`), `a` and each choice array are first broadcast, as necessary, to\narrays of a common shape; calling these Ba and Bchoices[i], i = 0,\u2026,n-1 we\nhave that, necessarily, `Ba.shape == Bchoices[i].shape` for each `i`. Then, a\nnew array with shape `Ba.shape` is created as follows:\n\nThis array must contain integers in `[0, n-1]`, where `n` is the number of\nchoices, unless `mode=wrap` or `mode=clip`, in which cases any integers are\npermissible.\n\nChoice arrays. `a` and all of the choices must be broadcastable to the same\nshape. If `choices` is itself an array (not recommended), then its outermost\ndimension (i.e., the one corresponding to `choices.shape[0]`) is taken as\ndefining the \u201csequence\u201d.\n\nIf provided, the result will be inserted into this array. It should be of the\nappropriate shape and dtype. Note that `out` is always buffered if\n`mode='raise'`; use other modes for better performance.\n\nSpecifies how indices outside `[0, n-1]` will be treated:\n\nThe merged result.\n\nIf `a` and each choice array are not all broadcastable to the same shape.\n\nSee also\n\nequivalent method\n\nPreferable if `choices` is an array\n\nTo reduce the chance of misinterpretation, even though the following \u201cabuse\u201d\nis nominally supported, `choices` should neither be, nor be thought of as, a\nsingle array, i.e., the outermost sequence-like container should be either a\nlist or a tuple.\n\nA couple examples illustrating how choose broadcasts:\n\n"}, {"name": "numpy.clip()", "path": "reference/generated/numpy.clip", "type": "numpy.clip", "text": "\nClip (limit) the values in an array.\n\nGiven an interval, values outside the interval are clipped to the interval\nedges. For example, if an interval of `[0, 1]` is specified, values smaller\nthan 0 become 0, and values larger than 1 become 1.\n\nEquivalent to but faster than `np.minimum(a_max, np.maximum(a, a_min))`.\n\nNo check is performed to ensure `a_min < a_max`.\n\nArray containing elements to clip.\n\nMinimum and maximum value. If `None`, clipping is not performed on the\ncorresponding edge. Only one of `a_min` and `a_max` may be `None`. Both are\nbroadcast against `a`.\n\nThe results will be placed in this array. It may be the input array for in-\nplace clipping. `out` must be of the right shape to hold the output. Its type\nis preserved.\n\nFor other keyword-only arguments, see the ufunc docs.\n\nNew in version 1.17.0.\n\nAn array with the elements of `a`, but where values < `a_min` are replaced\nwith `a_min`, and those > `a_max` with `a_max`.\n\nSee also\n\nWhen `a_min` is greater than `a_max`, `clip` returns an array in which all\nvalues are equal to `a_max`, as shown in the second example.\n\n"}, {"name": "numpy.clongdouble", "path": "reference/arrays.scalars#numpy.clongdouble", "type": "Scalars", "text": "\nComplex number type composed of two extended-precision floating-point numbers.\n\n`'G'`\n\n`numpy.clongfloat`\n\n`numpy.longcomplex`\n\n`numpy.complex256`: Complex number type composed of 2 128-bit extended-\nprecision floating-point numbers.\n\n"}, {"name": "numpy.clongfloat", "path": "reference/arrays.scalars#numpy.clongfloat", "type": "Scalars", "text": "\nalias of `numpy.clongdouble`\n\n"}, {"name": "numpy.column_stack()", "path": "reference/generated/numpy.column_stack", "type": "numpy.column_stack", "text": "\nStack 1-D arrays as columns into a 2-D array.\n\nTake a sequence of 1-D arrays and stack them as columns to make a single 2-D\narray. 2-D arrays are stacked as-is, just like with `hstack`. 1-D arrays are\nturned into 2-D columns first.\n\nArrays to stack. All of them must have the same first dimension.\n\nThe array formed by stacking the given arrays.\n\nSee also\n\n"}, {"name": "numpy.common_type()", "path": "reference/generated/numpy.common_type", "type": "numpy.common_type", "text": "\nReturn a scalar type which is common to the input arrays.\n\nThe return type will always be an inexact (i.e. floating point) scalar type,\neven if all the arrays are integer arrays. If one of the inputs is an integer\narray, the minimum precision type that is returned is a 64-bit floating point\ndtype.\n\nAll input arrays except int64 and uint64 can be safely cast to the returned\ndtype without loss of information.\n\nInput arrays.\n\nData type code.\n\nSee also\n\n"}, {"name": "numpy.complex128", "path": "reference/arrays.scalars#numpy.complex128", "type": "Scalars", "text": "\nalias of `numpy.cdouble`\n\n"}, {"name": "numpy.complex192", "path": "reference/arrays.scalars#numpy.complex192", "type": "Scalars", "text": "\nAlias for `numpy.clongdouble`, named after its size in bits. The existence of\nthese aliases depends on the platform.\n\n"}, {"name": "numpy.complex256", "path": "reference/arrays.scalars#numpy.complex256", "type": "Scalars", "text": "\nAlias for `numpy.clongdouble`, named after its size in bits. The existence of\nthese aliases depends on the platform.\n\n"}, {"name": "numpy.complex64", "path": "reference/arrays.scalars#numpy.complex64", "type": "Scalars", "text": "\nalias of `numpy.csingle`\n\n"}, {"name": "numpy.complex_", "path": "reference/arrays.scalars#numpy.complex_", "type": "Scalars", "text": "\nalias of `numpy.cdouble`\n\n"}, {"name": "numpy.compress()", "path": "reference/generated/numpy.compress", "type": "numpy.compress", "text": "\nReturn selected slices of an array along given axis.\n\nWhen working along a given axis, a slice along that axis is returned in\n`output` for each index where `condition` evaluates to True. When working on a\n1-D array, `compress` is equivalent to `extract`.\n\nArray that selects which entries to return. If len(condition) is less than the\nsize of `a` along the given axis, then output is truncated to the length of\nthe condition array.\n\nArray from which to extract a part.\n\nAxis along which to take slices. If None (default), work on the flattened\narray.\n\nOutput array. Its type is preserved and it must be of the right shape to hold\nthe output.\n\nA copy of `a` without the slices along axis for which `condition` is false.\n\nSee also\n\nEquivalent method in ndarray\n\nEquivalent method when working on 1-D arrays\n\nWorking on the flattened array does not return slices along an axis but\nselects elements.\n\n"}, {"name": "numpy.concatenate()", "path": "reference/generated/numpy.concatenate", "type": "numpy.concatenate", "text": "\nJoin a sequence of arrays along an existing axis.\n\nThe arrays must have the same shape, except in the dimension corresponding to\n`axis` (the first, by default).\n\nThe axis along which the arrays will be joined. If axis is None, arrays are\nflattened before use. Default is 0.\n\nIf provided, the destination to place the result. The shape must be correct,\nmatching that of what concatenate would have returned if no out argument were\nspecified.\n\nIf provided, the destination array will have this dtype. Cannot be provided\ntogether with `out`.\n\nNew in version 1.20.0.\n\nControls what kind of data casting may occur. Defaults to \u2018same_kind\u2019.\n\nNew in version 1.20.0.\n\nThe concatenated array.\n\nSee also\n\nConcatenate function that preserves input masks.\n\nSplit an array into multiple sub-arrays of equal or near-equal size.\n\nSplit array into a list of multiple sub-arrays of equal size.\n\nSplit array into multiple sub-arrays horizontally (column wise).\n\nSplit array into multiple sub-arrays vertically (row wise).\n\nSplit array into multiple sub-arrays along the 3rd axis (depth).\n\nStack a sequence of arrays along a new axis.\n\nAssemble arrays from blocks.\n\nStack arrays in sequence horizontally (column wise).\n\nStack arrays in sequence vertically (row wise).\n\nStack arrays in sequence depth wise (along third dimension).\n\nStack 1-D arrays as columns into a 2-D array.\n\nWhen one or more of the arrays to be concatenated is a MaskedArray, this\nfunction will return a MaskedArray object instead of an ndarray, but the input\nmasks are not preserved. In cases where a MaskedArray is expected as input,\nuse the ma.concatenate function from the masked array module instead.\n\nThis function will not preserve masking of MaskedArray inputs.\n\n"}, {"name": "numpy.conj()", "path": "reference/generated/numpy.conj", "type": "numpy.conj", "text": "\nReturn the complex conjugate, element-wise.\n\nThe complex conjugate of a complex number is obtained by changing the sign of\nits imaginary part.\n\nInput value.\n\nA location into which the result is stored. If provided, it must have a shape\nthat the inputs broadcast to. If not provided or None, a freshly-allocated\narray is returned. A tuple (possible only as a keyword argument) must have\nlength equal to the number of outputs.\n\nThis condition is broadcast over the input. At locations where the condition\nis True, the `out` array will be set to the ufunc result. Elsewhere, the `out`\narray will retain its original value. Note that if an uninitialized `out`\narray is created via the default `out=None`, locations within it where the\ncondition is False will remain uninitialized.\n\nFor other keyword-only arguments, see the ufunc docs.\n\nThe complex conjugate of `x`, with same dtype as `y`. This is a scalar if `x`\nis a scalar.\n\n`conj` is an alias for `conjugate`:\n\n"}, {"name": "numpy.conjugate()", "path": "reference/generated/numpy.conjugate", "type": "numpy.conjugate", "text": "\nReturn the complex conjugate, element-wise.\n\nThe complex conjugate of a complex number is obtained by changing the sign of\nits imaginary part.\n\nInput value.\n\nA location into which the result is stored. If provided, it must have a shape\nthat the inputs broadcast to. If not provided or None, a freshly-allocated\narray is returned. A tuple (possible only as a keyword argument) must have\nlength equal to the number of outputs.\n\nThis condition is broadcast over the input. At locations where the condition\nis True, the `out` array will be set to the ufunc result. Elsewhere, the `out`\narray will retain its original value. Note that if an uninitialized `out`\narray is created via the default `out=None`, locations within it where the\ncondition is False will remain uninitialized.\n\nFor other keyword-only arguments, see the ufunc docs.\n\nThe complex conjugate of `x`, with same dtype as `y`. This is a scalar if `x`\nis a scalar.\n\n`conj` is an alias for `conjugate`:\n\n"}, {"name": "numpy.convolve()", "path": "reference/generated/numpy.convolve", "type": "numpy.convolve", "text": "\nReturns the discrete, linear convolution of two one-dimensional sequences.\n\nThe convolution operator is often seen in signal processing, where it models\nthe effect of a linear time-invariant system on a signal [1]. In probability\ntheory, the sum of two independent random variables is distributed according\nto the convolution of their individual distributions.\n\nIf `v` is longer than `a`, the arrays are swapped before computation.\n\nFirst one-dimensional input array.\n\nSecond one-dimensional input array.\n\nBy default, mode is \u2018full\u2019. This returns the convolution at each point of\noverlap, with an output shape of (N+M-1,). At the end-points of the\nconvolution, the signals do not overlap completely, and boundary effects may\nbe seen.\n\nMode \u2018same\u2019 returns output of length `max(M, N)`. Boundary effects are still\nvisible.\n\nMode \u2018valid\u2019 returns output of length `max(M, N) - min(M, N) + 1`. The\nconvolution product is only given for points where the signals overlap\ncompletely. Values outside the signal boundary have no effect.\n\nDiscrete, linear convolution of `a` and `v`.\n\nSee also\n\nConvolve two arrays using the Fast Fourier Transform.\n\nUsed to construct the convolution operator.\n\nPolynomial multiplication. Same output as convolve, but also accepts poly1d\nobjects as input.\n\nThe discrete convolution operation is defined as\n\nIt can be shown that a convolution \\\\(x(t) * y(t)\\\\) in time/space is\nequivalent to the multiplication \\\\(X(f) Y(f)\\\\) in the Fourier domain, after\nappropriate padding (padding is necessary to prevent circular convolution).\nSince multiplication is more efficient (faster) than convolution, the function\n`scipy.signal.fftconvolve` exploits the FFT to calculate the convolution of\nlarge data-sets.\n\nWikipedia, \u201cConvolution\u201d, https://en.wikipedia.org/wiki/Convolution\n\nNote how the convolution operator flips the second array before \u201csliding\u201d the\ntwo across one another:\n\nOnly return the middle values of the convolution. Contains boundary effects,\nwhere zeros are taken into account:\n\nThe two arrays are of the same length, so there is only one position where\nthey completely overlap:\n\n"}, {"name": "numpy.copy()", "path": "reference/generated/numpy.copy", "type": "numpy.copy", "text": "\nReturn an array copy of the given object.\n\nInput data.\n\nControls the memory layout of the copy. \u2018C\u2019 means C-order, \u2018F\u2019 means F-order,\n\u2018A\u2019 means \u2018F\u2019 if `a` is Fortran contiguous, \u2018C\u2019 otherwise. \u2018K\u2019 means match the\nlayout of `a` as closely as possible. (Note that this function and\n`ndarray.copy` are very similar, but have different default values for their\norder= arguments.)\n\nIf True, then sub-classes will be passed-through, otherwise the returned array\nwill be forced to be a base-class array (defaults to False).\n\nNew in version 1.19.0.\n\nArray interpretation of `a`.\n\nSee also\n\nPreferred method for creating an array copy\n\nThis is equivalent to:\n\nCreate an array x, with a reference y and a copy z:\n\nNote that, when we modify x, y changes, but not z:\n\nNote that, np.copy clears previously set WRITEABLE=False flag.\n\nNote that np.copy is a shallow copy and will not copy object elements within\narrays. This is mainly important for arrays containing Python objects. The new\narray will contain the same object which may lead to surprises if that object\ncan be modified (is mutable):\n\nTo ensure all elements within an `object` array are copied, use\n`copy.deepcopy`:\n\n"}, {"name": "numpy.copysign()", "path": "reference/generated/numpy.copysign", "type": "numpy.copysign", "text": "\nChange the sign of x1 to that of x2, element-wise.\n\nIf `x2` is a scalar, its sign will be copied to all elements of `x1`.\n\nValues to change the sign of.\n\nThe sign of `x2` is copied to `x1`. If `x1.shape != x2.shape`, they must be\nbroadcastable to a common shape (which becomes the shape of the output).\n\nA location into which the result is stored. If provided, it must have a shape\nthat the inputs broadcast to. If not provided or None, a freshly-allocated\narray is returned. A tuple (possible only as a keyword argument) must have\nlength equal to the number of outputs.\n\nThis condition is broadcast over the input. At locations where the condition\nis True, the `out` array will be set to the ufunc result. Elsewhere, the `out`\narray will retain its original value. Note that if an uninitialized `out`\narray is created via the default `out=None`, locations within it where the\ncondition is False will remain uninitialized.\n\nFor other keyword-only arguments, see the ufunc docs.\n\nThe values of `x1` with the sign of `x2`. This is a scalar if both `x1` and\n`x2` are scalars.\n\n"}, {"name": "numpy.copyto()", "path": "reference/generated/numpy.copyto", "type": "numpy.copyto", "text": "\nCopies values from one array to another, broadcasting as necessary.\n\nRaises a TypeError if the `casting` rule is violated, and if `where` is\nprovided, it selects which elements to copy.\n\nNew in version 1.7.0.\n\nThe array into which values are copied.\n\nThe array from which values are copied.\n\nControls what kind of data casting may occur when copying.\n\nA boolean array which is broadcasted to match the dimensions of `dst`, and\nselects elements to copy from `src` to `dst` wherever it contains the value\nTrue.\n\n"}, {"name": "numpy.corrcoef()", "path": "reference/generated/numpy.corrcoef", "type": "numpy.corrcoef", "text": "\nReturn Pearson product-moment correlation coefficients.\n\nPlease refer to the documentation for `cov` for more detail. The relationship\nbetween the correlation coefficient matrix, `R`, and the covariance matrix,\n`C`, is\n\nThe values of `R` are between -1 and 1, inclusive.\n\nA 1-D or 2-D array containing multiple variables and observations. Each row of\n`x` represents a variable, and each column a single observation of all those\nvariables. Also see `rowvar` below.\n\nAn additional set of variables and observations. `y` has the same shape as\n`x`.\n\nIf `rowvar` is True (default), then each row represents a variable, with\nobservations in the columns. Otherwise, the relationship is transposed: each\ncolumn represents a variable, while the rows contain observations.\n\nHas no effect, do not use.\n\nDeprecated since version 1.10.0.\n\nHas no effect, do not use.\n\nDeprecated since version 1.10.0.\n\nData-type of the result. By default, the return data-type will have at least\n`numpy.float64` precision.\n\nNew in version 1.20.\n\nThe correlation coefficient matrix of the variables.\n\nSee also\n\nCovariance matrix\n\nDue to floating point rounding the resulting array may not be Hermitian, the\ndiagonal elements may not be 1, and the elements may not satisfy the\ninequality abs(a) <= 1. The real and imaginary parts are clipped to the\ninterval [-1, 1] in an attempt to improve on that situation but is not much\nhelp in the complex case.\n\nThis function accepts but discards arguments `bias` and `ddof`. This is for\nbackwards compatibility with previous versions of this function. These\narguments had no effect on the return values of the function and can be safely\nignored in this and previous versions of numpy.\n\nIn this example we generate two random arrays, `xarr` and `yarr`, and compute\nthe row-wise and column-wise Pearson correlation coefficients, `R`. Since\n`rowvar` is true by default, we first find the row-wise Pearson correlation\ncoefficients between the variables of `xarr`.\n\nIf we add another set of variables and observations `yarr`, we can compute the\nrow-wise Pearson correlation coefficients between the variables in `xarr` and\n`yarr`.\n\nFinally if we use the option `rowvar=False`, the columns are now being treated\nas the variables and we will find the column-wise Pearson correlation\ncoefficients between variables in `xarr` and `yarr`.\n\n"}, {"name": "numpy.correlate()", "path": "reference/generated/numpy.correlate", "type": "numpy.correlate", "text": "\nCross-correlation of two 1-dimensional sequences.\n\nThis function computes the correlation as generally defined in signal\nprocessing texts:\n\nwith a and v sequences being zero-padded where necessary and conj being the\nconjugate.\n\nInput sequences.\n\nRefer to the `convolve` docstring. Note that the default is \u2018valid\u2019, unlike\n`convolve`, which uses \u2018full\u2019.\n\n`old_behavior` was removed in NumPy 1.10. If you need the old behavior, use\n`multiarray.correlate`.\n\nDiscrete cross-correlation of `a` and `v`.\n\nSee also\n\nDiscrete, linear convolution of two one-dimensional sequences.\n\nOld, no conjugate, version of correlate.\n\nuses FFT which has superior performance on large arrays.\n\nThe definition of correlation above is not unique and sometimes correlation\nmay be defined differently. Another common definition is:\n\nwhich is related to `c_{av}[k]` by `c'_{av}[k] = c_{av}[-k]`.\n\n`numpy.correlate` may perform slowly in large arrays (i.e. n = 1e5) because it\ndoes not use the FFT to compute the convolution; in that case,\n`scipy.signal.correlate` might be preferable.\n\nUsing complex sequences:\n\nNote that you get the time reversed, complex conjugated result when the two\ninput sequences change places, i.e., `c_{va}[k] = c^{*}_{av}[-k]`:\n\n"}, {"name": "numpy.cos()", "path": "reference/generated/numpy.cos", "type": "numpy.cos", "text": "\nCosine element-wise.\n\nInput array in radians.\n\nA location into which the result is stored. If provided, it must have a shape\nthat the inputs broadcast to. If not provided or None, a freshly-allocated\narray is returned. A tuple (possible only as a keyword argument) must have\nlength equal to the number of outputs.\n\nThis condition is broadcast over the input. At locations where the condition\nis True, the `out` array will be set to the ufunc result. Elsewhere, the `out`\narray will retain its original value. Note that if an uninitialized `out`\narray is created via the default `out=None`, locations within it where the\ncondition is False will remain uninitialized.\n\nFor other keyword-only arguments, see the ufunc docs.\n\nThe corresponding cosine values. This is a scalar if `x` is a scalar.\n\nIf `out` is provided, the function writes the result into it, and returns a\nreference to `out`. (See Examples)\n\nM. Abramowitz and I. A. Stegun, Handbook of Mathematical Functions. New York,\nNY: Dover, 1972.\n\n"}, {"name": "numpy.cosh()", "path": "reference/generated/numpy.cosh", "type": "numpy.cosh", "text": "\nHyperbolic cosine, element-wise.\n\nEquivalent to `1/2 * (np.exp(x) + np.exp(-x))` and `np.cos(1j*x)`.\n\nInput array.\n\nA location into which the result is stored. If provided, it must have a shape\nthat the inputs broadcast to. If not provided or None, a freshly-allocated\narray is returned. A tuple (possible only as a keyword argument) must have\nlength equal to the number of outputs.\n\nThis condition is broadcast over the input. At locations where the condition\nis True, the `out` array will be set to the ufunc result. Elsewhere, the `out`\narray will retain its original value. Note that if an uninitialized `out`\narray is created via the default `out=None`, locations within it where the\ncondition is False will remain uninitialized.\n\nFor other keyword-only arguments, see the ufunc docs.\n\nOutput array of same shape as `x`. This is a scalar if `x` is a scalar.\n\nThe hyperbolic cosine describes the shape of a hanging cable:\n\n"}, {"name": "numpy.count_nonzero()", "path": "reference/generated/numpy.count_nonzero", "type": "numpy.count_nonzero", "text": "\nCounts the number of non-zero values in the array `a`.\n\nThe word \u201cnon-zero\u201d is in reference to the Python 2.x built-in method\n`__nonzero__()` (renamed `__bool__()` in Python 3.x) of Python objects that\ntests an object\u2019s \u201ctruthfulness\u201d. For example, any number is considered\ntruthful if it is nonzero, whereas any string is considered truthful if it is\nnot the empty string. Thus, this function (recursively) counts how many\nelements in `a` (and in sub-arrays thereof) have their `__nonzero__()` or\n`__bool__()` method evaluated to `True`.\n\nThe array for which to count non-zeros.\n\nAxis or tuple of axes along which to count non-zeros. Default is None, meaning\nthat non-zeros will be counted along a flattened version of `a`.\n\nNew in version 1.12.0.\n\nIf this is set to True, the axes that are counted are left in the result as\ndimensions with size one. With this option, the result will broadcast\ncorrectly against the input array.\n\nNew in version 1.19.0.\n\nNumber of non-zero values in the array along a given axis. Otherwise, the\ntotal number of non-zero values in the array is returned.\n\nSee also\n\nReturn the coordinates of all the non-zero values.\n\n"}, {"name": "numpy.cov()", "path": "reference/generated/numpy.cov", "type": "numpy.cov", "text": "\nEstimate a covariance matrix, given data and weights.\n\nCovariance indicates the level to which two variables vary together. If we\nexamine N-dimensional samples, \\\\(X = [x_1, x_2, ... x_N]^T\\\\), then the\ncovariance matrix element \\\\(C_{ij}\\\\) is the covariance of \\\\(x_i\\\\) and\n\\\\(x_j\\\\). The element \\\\(C_{ii}\\\\) is the variance of \\\\(x_i\\\\).\n\nSee the notes for an outline of the algorithm.\n\nA 1-D or 2-D array containing multiple variables and observations. Each row of\n`m` represents a variable, and each column a single observation of all those\nvariables. Also see `rowvar` below.\n\nAn additional set of variables and observations. `y` has the same form as that\nof `m`.\n\nIf `rowvar` is True (default), then each row represents a variable, with\nobservations in the columns. Otherwise, the relationship is transposed: each\ncolumn represents a variable, while the rows contain observations.\n\nDefault normalization (False) is by `(N - 1)`, where `N` is the number of\nobservations given (unbiased estimate). If `bias` is True, then normalization\nis by `N`. These values can be overridden by using the keyword `ddof` in numpy\nversions >= 1.5.\n\nIf not `None` the default value implied by `bias` is overridden. Note that\n`ddof=1` will return the unbiased estimate, even if both `fweights` and\n`aweights` are specified, and `ddof=0` will return the simple average. See the\nnotes for the details. The default value is `None`.\n\nNew in version 1.5.\n\n1-D array of integer frequency weights; the number of times each observation\nvector should be repeated.\n\nNew in version 1.10.\n\n1-D array of observation vector weights. These relative weights are typically\nlarge for observations considered \u201cimportant\u201d and smaller for observations\nconsidered less \u201cimportant\u201d. If `ddof=0` the array of weights can be used to\nassign probabilities to observation vectors.\n\nNew in version 1.10.\n\nData-type of the result. By default, the return data-type will have at least\n`numpy.float64` precision.\n\nNew in version 1.20.\n\nThe covariance matrix of the variables.\n\nSee also\n\nNormalized covariance matrix\n\nAssume that the observations are in the columns of the observation array `m`\nand let `f = fweights` and `a = aweights` for brevity. The steps to compute\nthe weighted covariance are as follows:\n\nNote that when `a == 1`, the normalization factor `v1 / (v1**2 - ddof * v2)`\ngoes over to `1 / (np.sum(f) - ddof)` as it should.\n\nConsider two variables, \\\\(x_0\\\\) and \\\\(x_1\\\\), which correlate perfectly,\nbut in opposite directions:\n\nNote how \\\\(x_0\\\\) increases while \\\\(x_1\\\\) decreases. The covariance matrix\nshows this clearly:\n\nNote that element \\\\(C_{0,1}\\\\), which shows the correlation between \\\\(x_0\\\\)\nand \\\\(x_1\\\\), is negative.\n\nFurther, note how `x` and `y` are combined:\n\n"}, {"name": "numpy.cross()", "path": "reference/generated/numpy.cross", "type": "numpy.cross", "text": "\nReturn the cross product of two (arrays of) vectors.\n\nThe cross product of `a` and `b` in \\\\(R^3\\\\) is a vector perpendicular to\nboth `a` and `b`. If `a` and `b` are arrays of vectors, the vectors are\ndefined by the last axis of `a` and `b` by default, and these axes can have\ndimensions 2 or 3. Where the dimension of either `a` or `b` is 2, the third\ncomponent of the input vector is assumed to be zero and the cross product\ncalculated accordingly. In cases where both input vectors have dimension 2,\nthe z-component of the cross product is returned.\n\nComponents of the first vector(s).\n\nComponents of the second vector(s).\n\nAxis of `a` that defines the vector(s). By default, the last axis.\n\nAxis of `b` that defines the vector(s). By default, the last axis.\n\nAxis of `c` containing the cross product vector(s). Ignored if both input\nvectors have dimension 2, as the return is scalar. By default, the last axis.\n\nIf defined, the axis of `a`, `b` and `c` that defines the vector(s) and cross\nproduct(s). Overrides `axisa`, `axisb` and `axisc`.\n\nVector cross product(s).\n\nWhen the dimension of the vector(s) in `a` and/or `b` does not equal 2 or 3.\n\nSee also\n\nInner product\n\nOuter product.\n\nConstruct index arrays.\n\nNew in version 1.9.0.\n\nSupports full broadcasting of the inputs.\n\nVector cross-product.\n\nOne vector with dimension 2.\n\nEquivalently:\n\nBoth vectors with dimension 2.\n\nMultiple vector cross-products. Note that the direction of the cross product\nvector is defined by the `right-hand rule`.\n\nThe orientation of `c` can be changed using the `axisc` keyword.\n\nChange the vector definition of `x` and `y` using `axisa` and `axisb`.\n\n"}, {"name": "numpy.csingle", "path": "reference/arrays.scalars#numpy.csingle", "type": "Scalars", "text": "\nComplex number type composed of two single-precision floating-point numbers.\n\n`'F'`\n\n`numpy.singlecomplex`\n\n`numpy.complex64`: Complex number type composed of 2 32-bit-precision\nfloating-point numbers.\n\n"}, {"name": "numpy.ctypeslib.as_array()", "path": "reference/routines.ctypeslib", "type": "C-Types Foreign Function Interface ( \n      \n       numpy.ctypeslib\n      \n      )", "text": "\nCreate a numpy array from a ctypes array or POINTER.\n\nThe numpy array shares the memory with the ctypes object.\n\nThe shape parameter must be given if converting from a ctypes POINTER. The\nshape parameter is ignored if converting from a ctypes array\n\nCreate and return a ctypes object from a numpy array. Actually anything that\nexposes the __array_interface__ is accepted.\n\nConvert a dtype into a ctypes type.\n\nThe dtype to convert\n\nA ctype scalar, union, array, or struct\n\nIf the conversion is not possible\n\nThis function does not losslessly round-trip in either direction.\n\n`np.dtype(as_ctypes_type(dt))` will:\n\n`as_ctypes_type(np.dtype(ctype))` will:\n\nIt is possible to load a library using\n\nBut there are cross-platform considerations, such as library file extensions,\nplus the fact Windows will just load the first library it finds with that\nname. NumPy supplies the load_library function as a convenience.\n\nChanged in version 1.20.0: Allow libname and loader_path to take any path-like\nobject.\n\nName of the library, which can have \u2018lib\u2019 as a prefix, but without an\nextension.\n\nWhere the library can be found.\n\nA ctypes library object\n\nIf there is no library with the expected extension, or the library is\ndefective and cannot be loaded.\n\nArray-checking restype/argtypes.\n\nAn ndpointer instance is used to describe an ndarray in restypes and argtypes\nspecifications. This approach is more flexible than using, for example,\n`POINTER(c_double)`, since several restrictions can be specified, which are\nverified upon calling the ctypes function. These include data type, number of\ndimensions, shape and flags. If a given array does not satisfy the specified\nrestrictions, a `TypeError` is raised.\n\nArray data-type.\n\nNumber of array dimensions.\n\nArray shape.\n\nArray flags; may be one or more of:\n\nA type object, which is an `_ndtpr` instance containing dtype, ndim, shape and\nflags information.\n\nIf a given array does not satisfy the specified restrictions.\n\nA `ctypes` signed integer type of the same size as `numpy.intp`.\n\nDepending on the platform, it can be an alias for either `c_int`, `c_long` or\n`c_longlong`.\n\n"}, {"name": "numpy.ctypeslib.as_ctypes()", "path": "reference/routines.ctypeslib#numpy.ctypeslib.as_ctypes", "type": "C-Types Foreign Function Interface ( \n      \n       numpy.ctypeslib\n      \n      )", "text": "\nCreate and return a ctypes object from a numpy array. Actually anything that\nexposes the __array_interface__ is accepted.\n\n"}, {"name": "numpy.ctypeslib.as_ctypes_type()", "path": "reference/routines.ctypeslib#numpy.ctypeslib.as_ctypes_type", "type": "C-Types Foreign Function Interface ( \n      \n       numpy.ctypeslib\n      \n      )", "text": "\nConvert a dtype into a ctypes type.\n\nThe dtype to convert\n\nA ctype scalar, union, array, or struct\n\nIf the conversion is not possible\n\nThis function does not losslessly round-trip in either direction.\n\n`np.dtype(as_ctypes_type(dt))` will:\n\n`as_ctypes_type(np.dtype(ctype))` will:\n\n"}, {"name": "numpy.ctypeslib.c_intp", "path": "reference/routines.ctypeslib#numpy.ctypeslib.c_intp", "type": "C-Types Foreign Function Interface ( \n      \n       numpy.ctypeslib\n      \n      )", "text": "\nA `ctypes` signed integer type of the same size as `numpy.intp`.\n\nDepending on the platform, it can be an alias for either `c_int`, `c_long` or\n`c_longlong`.\n\n"}, {"name": "numpy.ctypeslib.load_library()", "path": "reference/routines.ctypeslib#numpy.ctypeslib.load_library", "type": "C-Types Foreign Function Interface ( \n      \n       numpy.ctypeslib\n      \n      )", "text": "\nIt is possible to load a library using\n\nBut there are cross-platform considerations, such as library file extensions,\nplus the fact Windows will just load the first library it finds with that\nname. NumPy supplies the load_library function as a convenience.\n\nChanged in version 1.20.0: Allow libname and loader_path to take any path-like\nobject.\n\nName of the library, which can have \u2018lib\u2019 as a prefix, but without an\nextension.\n\nWhere the library can be found.\n\nA ctypes library object\n\nIf there is no library with the expected extension, or the library is\ndefective and cannot be loaded.\n\n"}, {"name": "numpy.ctypeslib.ndpointer()", "path": "reference/routines.ctypeslib#numpy.ctypeslib.ndpointer", "type": "C-Types Foreign Function Interface ( \n      \n       numpy.ctypeslib\n      \n      )", "text": "\nArray-checking restype/argtypes.\n\nAn ndpointer instance is used to describe an ndarray in restypes and argtypes\nspecifications. This approach is more flexible than using, for example,\n`POINTER(c_double)`, since several restrictions can be specified, which are\nverified upon calling the ctypes function. These include data type, number of\ndimensions, shape and flags. If a given array does not satisfy the specified\nrestrictions, a `TypeError` is raised.\n\nArray data-type.\n\nNumber of array dimensions.\n\nArray shape.\n\nArray flags; may be one or more of:\n\nA type object, which is an `_ndtpr` instance containing dtype, ndim, shape and\nflags information.\n\nIf a given array does not satisfy the specified restrictions.\n\n"}, {"name": "numpy.cumprod()", "path": "reference/generated/numpy.cumprod", "type": "numpy.cumprod", "text": "\nReturn the cumulative product of elements along a given axis.\n\nInput array.\n\nAxis along which the cumulative product is computed. By default the input is\nflattened.\n\nType of the returned array, as well as of the accumulator in which the\nelements are multiplied. If dtype is not specified, it defaults to the dtype\nof `a`, unless `a` has an integer dtype with a precision less than that of the\ndefault platform integer. In that case, the default platform integer is used\ninstead.\n\nAlternative output array in which to place the result. It must have the same\nshape and buffer length as the expected output but the type of the resulting\nvalues will be cast if necessary.\n\nA new array holding the result is returned unless `out` is specified, in which\ncase a reference to out is returned.\n\nSee also\n\nArithmetic is modular when using integer types, and no error is raised on\noverflow.\n\nThe cumulative product for each column (i.e., over the rows) of `a`:\n\nThe cumulative product for each row (i.e. over the columns) of `a`:\n\n"}, {"name": "numpy.cumsum()", "path": "reference/generated/numpy.cumsum", "type": "numpy.cumsum", "text": "\nReturn the cumulative sum of the elements along a given axis.\n\nInput array.\n\nAxis along which the cumulative sum is computed. The default (None) is to\ncompute the cumsum over the flattened array.\n\nType of the returned array and of the accumulator in which the elements are\nsummed. If `dtype` is not specified, it defaults to the dtype of `a`, unless\n`a` has an integer dtype with a precision less than that of the default\nplatform integer. In that case, the default platform integer is used.\n\nAlternative output array in which to place the result. It must have the same\nshape and buffer length as the expected output but the type will be cast if\nnecessary. See Output type determination for more details.\n\nA new array holding the result is returned unless `out` is specified, in which\ncase a reference to `out` is returned. The result has the same size as `a`,\nand the same shape as `a` if `axis` is not None or `a` is a 1-d array.\n\nSee also\n\nSum array elements.\n\nIntegration of array values using the composite trapezoidal rule.\n\nCalculate the n-th discrete difference along given axis.\n\nArithmetic is modular when using integer types, and no error is raised on\noverflow.\n\n`cumsum(a)[-1]` may not be equal to `sum(a)` for floating-point values since\n`sum` may use a pairwise summation routine, reducing the roundoff-error. See\n`sum` for more information.\n\n`cumsum(b)[-1]` may not be equal to `sum(b)`\n\n"}, {"name": "numpy.DataSource()", "path": "reference/generated/numpy.datasource", "type": "numpy.DataSource", "text": "\nA generic data source file (file, http, ftp, \u2026).\n\nDataSources can be local files or remote files/URLs. The files may also be\ncompressed or uncompressed. DataSource hides some of the low-level details of\ndownloading the file, allowing you to simply pass in a valid file path (or\nURL) and obtain a file object.\n\nPath to the directory where the source file gets downloaded to for use. If\n`destpath` is None, a temporary directory will be created. The default path is\nthe current directory.\n\nURLs require a scheme string (`http://`) to be used, without it they will\nfail:\n\nTemporary directories are deleted when the DataSource is deleted.\n\n`abspath`(path)\n\nReturn absolute path of file in the DataSource directory.\n\n`exists`(path)\n\nTest if path exists.\n\n`open`(path[, mode, encoding, newline])\n\nOpen and return file-like object.\n\n"}, {"name": "numpy.datetime64", "path": "reference/arrays.scalars#numpy.datetime64", "type": "Scalars", "text": "\nIf created from a 64-bit integer, it represents an offset from\n`1970-01-01T00:00:00`. If created from string, the string can be in ISO 8601\ndate or datetime format.\n\nSee Datetimes and Timedeltas for more information.\n\n`'M'`\n\n"}, {"name": "numpy.datetime_as_string()", "path": "reference/generated/numpy.datetime_as_string", "type": "numpy.datetime_as_string", "text": "\nConvert an array of datetimes into an array of strings.\n\nThe array of UTC timestamps to format.\n\nOne of None, \u2018auto\u2019, or a datetime unit.\n\nTimezone information to use when displaying the datetime. If \u2018UTC\u2019, end with a\nZ to indicate UTC time. If \u2018local\u2019, convert to the local timezone first, and\nsuffix with a +-#### timezone offset. If a tzinfo object, then do as with\n\u2018local\u2019, but use the specified timezone.\n\nCasting to allow when changing between datetime units.\n\nAn array of strings the same shape as `arr`.\n\nSetting the timezone to UTC shows the same information, but with a Z suffix\n\nNote that we picked datetimes that cross a DST boundary. Passing in a `pytz`\ntimezone object will print the appropriate offset\n\nPassing in a unit will change the precision\n\n\u2018casting\u2019 can be used to specify whether precision can be changed\n\n"}, {"name": "numpy.datetime_data()", "path": "reference/generated/numpy.datetime_data", "type": "numpy.datetime_data", "text": "\nGet information about the step size of a date or time type.\n\nThe returned tuple can be passed as the second argument of `numpy.datetime64`\nand `numpy.timedelta64`.\n\nThe dtype object, which must be a `datetime64` or `timedelta64` type.\n\nThe datetime unit on which this dtype is based.\n\nThe number of base units in a step.\n\nThe result can be used to construct a datetime that uses the same units as a\ntimedelta\n\n"}, {"name": "numpy.deg2rad()", "path": "reference/generated/numpy.deg2rad", "type": "numpy.deg2rad", "text": "\nConvert angles from degrees to radians.\n\nAngles in degrees.\n\nA location into which the result is stored. If provided, it must have a shape\nthat the inputs broadcast to. If not provided or None, a freshly-allocated\narray is returned. A tuple (possible only as a keyword argument) must have\nlength equal to the number of outputs.\n\nThis condition is broadcast over the input. At locations where the condition\nis True, the `out` array will be set to the ufunc result. Elsewhere, the `out`\narray will retain its original value. Note that if an uninitialized `out`\narray is created via the default `out=None`, locations within it where the\ncondition is False will remain uninitialized.\n\nFor other keyword-only arguments, see the ufunc docs.\n\nThe corresponding angle in radians. This is a scalar if `x` is a scalar.\n\nSee also\n\nConvert angles from radians to degrees.\n\nRemove large jumps in angle by wrapping.\n\nNew in version 1.3.0.\n\n`deg2rad(x)` is `x * pi / 180`.\n\n"}, {"name": "numpy.degrees()", "path": "reference/generated/numpy.degrees", "type": "numpy.degrees", "text": "\nConvert angles from radians to degrees.\n\nInput array in radians.\n\nA location into which the result is stored. If provided, it must have a shape\nthat the inputs broadcast to. If not provided or None, a freshly-allocated\narray is returned. A tuple (possible only as a keyword argument) must have\nlength equal to the number of outputs.\n\nThis condition is broadcast over the input. At locations where the condition\nis True, the `out` array will be set to the ufunc result. Elsewhere, the `out`\narray will retain its original value. Note that if an uninitialized `out`\narray is created via the default `out=None`, locations within it where the\ncondition is False will remain uninitialized.\n\nFor other keyword-only arguments, see the ufunc docs.\n\nThe corresponding degree values; if `out` was supplied this is a reference to\nit. This is a scalar if `x` is a scalar.\n\nSee also\n\nequivalent function\n\nConvert a radian array to degrees\n\n"}, {"name": "numpy.delete()", "path": "reference/generated/numpy.delete", "type": "numpy.delete", "text": "\nReturn a new array with sub-arrays along an axis deleted. For a one\ndimensional array, this returns those entries not returned by `arr[obj]`.\n\nInput array.\n\nIndicate indices of sub-arrays to remove along the specified axis.\n\nChanged in version 1.19.0: Boolean indices are now treated as a mask of\nelements to remove, rather than being cast to the integers 0 and 1.\n\nThe axis along which to delete the subarray defined by `obj`. If `axis` is\nNone, `obj` is applied to the flattened array.\n\nA copy of `arr` with the elements specified by `obj` removed. Note that\n`delete` does not occur in-place. If `axis` is None, `out` is a flattened\narray.\n\nSee also\n\nInsert elements into an array.\n\nAppend elements at the end of an array.\n\nOften it is preferable to use a boolean mask. For example:\n\nIs equivalent to `np.delete(arr, [0,2,4], axis=0)`, but allows further use of\n`mask`.\n\n"}, {"name": "numpy.deprecate()", "path": "reference/generated/numpy.deprecate", "type": "numpy.deprecate", "text": "\nIssues a DeprecationWarning, adds warning to `old_name`\u2019s docstring, rebinds\n`old_name.__name__` and returns the new function object.\n\nThis function may also be used as a decorator.\n\nThe function to be deprecated.\n\nThe name of the function to be deprecated. Default is None, in which case the\nname of `func` is used.\n\nThe new name for the function. Default is None, in which case the deprecation\nmessage is that `old_name` is deprecated. If given, the deprecation message is\nthat `old_name` is deprecated and `new_name` should be used instead.\n\nAdditional explanation of the deprecation. Displayed in the docstring after\nthe warning.\n\nThe deprecated function.\n\nNote that `olduint` returns a value after printing Deprecation Warning:\n\n"}, {"name": "numpy.deprecate_with_doc()", "path": "reference/generated/numpy.deprecate_with_doc", "type": "numpy.deprecate_with_doc", "text": "\nDeprecates a function and includes the deprecation in its docstring.\n\nThis function is used as a decorator. It returns an object that can be used to\nissue a DeprecationWarning, by passing the to-be decorated function as\nargument, this adds warning to the to-be decorated function\u2019s docstring and\nreturns the new function object.\n\nAdditional explanation of the deprecation. Displayed in the docstring after\nthe warning.\n\nSee also\n\nDecorate a function such that it issues a `DeprecationWarning`\n\n"}, {"name": "numpy.diag()", "path": "reference/generated/numpy.diag", "type": "numpy.diag", "text": "\nExtract a diagonal or construct a diagonal array.\n\nSee the more detailed documentation for `numpy.diagonal` if you use this\nfunction to extract a diagonal and wish to write to the resulting array;\nwhether it returns a copy or a view depends on what version of numpy you are\nusing.\n\nIf `v` is a 2-D array, return a copy of its `k`-th diagonal. If `v` is a 1-D\narray, return a 2-D array with `v` on the `k`-th diagonal.\n\nDiagonal in question. The default is 0. Use `k>0` for diagonals above the main\ndiagonal, and `k<0` for diagonals below the main diagonal.\n\nThe extracted diagonal or constructed diagonal array.\n\nSee also\n\nReturn specified diagonals.\n\nCreate a 2-D array with the flattened input as a diagonal.\n\nSum along diagonals.\n\nUpper triangle of an array.\n\nLower triangle of an array.\n\n"}, {"name": "numpy.diag_indices()", "path": "reference/generated/numpy.diag_indices", "type": "numpy.diag_indices", "text": "\nReturn the indices to access the main diagonal of an array.\n\nThis returns a tuple of indices that can be used to access the main diagonal\nof an array `a` with `a.ndim >= 2` dimensions and shape (n, n, \u2026, n). For\n`a.ndim = 2` this is the usual diagonal, for `a.ndim > 2` this is the set of\nindices to access `a[i, i, ..., i]` for `i = [0..n-1]`.\n\nThe size, along each dimension, of the arrays for which the returned indices\ncan be used.\n\nThe number of dimensions.\n\nSee also\n\nNew in version 1.4.0.\n\nCreate a set of indices to access the diagonal of a (4, 4) array:\n\nNow, we create indices to manipulate a 3-D array:\n\nAnd use it to set the diagonal of an array of zeros to 1:\n\n"}, {"name": "numpy.diag_indices_from()", "path": "reference/generated/numpy.diag_indices_from", "type": "numpy.diag_indices_from", "text": "\nReturn the indices to access the main diagonal of an n-dimensional array.\n\nSee `diag_indices` for full details.\n\nSee also\n\nNew in version 1.4.0.\n\n"}, {"name": "numpy.diagflat()", "path": "reference/generated/numpy.diagflat", "type": "numpy.diagflat", "text": "\nCreate a two-dimensional array with the flattened input as a diagonal.\n\nInput data, which is flattened and set as the `k`-th diagonal of the output.\n\nDiagonal to set; 0, the default, corresponds to the \u201cmain\u201d diagonal, a\npositive (negative) `k` giving the number of the diagonal above (below) the\nmain.\n\nThe 2-D output array.\n\nSee also\n\nMATLAB work-alike for 1-D and 2-D arrays.\n\nReturn specified diagonals.\n\nSum along diagonals.\n\n"}, {"name": "numpy.diagonal()", "path": "reference/generated/numpy.diagonal", "type": "numpy.diagonal", "text": "\nReturn specified diagonals.\n\nIf `a` is 2-D, returns the diagonal of `a` with the given offset, i.e., the\ncollection of elements of the form `a[i, i+offset]`. If `a` has more than two\ndimensions, then the axes specified by `axis1` and `axis2` are used to\ndetermine the 2-D sub-array whose diagonal is returned. The shape of the\nresulting array can be determined by removing `axis1` and `axis2` and\nappending an index to the right equal to the size of the resulting diagonals.\n\nIn versions of NumPy prior to 1.7, this function always returned a new,\nindependent array containing a copy of the values in the diagonal.\n\nIn NumPy 1.7 and 1.8, it continues to return a copy of the diagonal, but\ndepending on this fact is deprecated. Writing to the resulting array continues\nto work as it used to, but a FutureWarning is issued.\n\nStarting in NumPy 1.9 it returns a read-only view on the original array.\nAttempting to write to the resulting array will produce an error.\n\nIn some future release, it will return a read/write view and writing to the\nreturned array will alter your original array. The returned array will have\nthe same type as the input array.\n\nIf you don\u2019t write to the array returned by this function, then you can just\nignore all of the above.\n\nIf you depend on the current behavior, then we suggest copying the returned\narray explicitly, i.e., use `np.diagonal(a).copy()` instead of just\n`np.diagonal(a)`. This will work with both past and future versions of NumPy.\n\nArray from which the diagonals are taken.\n\nOffset of the diagonal from the main diagonal. Can be positive or negative.\nDefaults to main diagonal (0).\n\nAxis to be used as the first axis of the 2-D sub-arrays from which the\ndiagonals should be taken. Defaults to first axis (0).\n\nAxis to be used as the second axis of the 2-D sub-arrays from which the\ndiagonals should be taken. Defaults to second axis (1).\n\nIf `a` is 2-D, then a 1-D array containing the diagonal and of the same type\nas `a` is returned unless `a` is a `matrix`, in which case a 1-D array rather\nthan a (2-D) `matrix` is returned in order to maintain backward compatibility.\n\nIf `a.ndim > 2`, then the dimensions specified by `axis1` and `axis2` are\nremoved, and a new axis inserted at the end corresponding to the diagonal.\n\nIf the dimension of `a` is less than 2.\n\nSee also\n\nMATLAB work-a-like for 1-D and 2-D arrays.\n\nCreate diagonal arrays.\n\nSum along diagonals.\n\nA 3-D example:\n\nThe sub-arrays whose main diagonals we just obtained; note that each\ncorresponds to fixing the right-most (column) axis, and that the diagonals are\n\u201cpacked\u201d in rows.\n\nThe anti-diagonal can be obtained by reversing the order of elements using\neither `numpy.flipud` or `numpy.fliplr`.\n\nNote that the order in which the diagonal is retrieved varies depending on the\nflip function.\n\n"}, {"name": "numpy.diff()", "path": "reference/generated/numpy.diff", "type": "numpy.diff", "text": "\nCalculate the n-th discrete difference along the given axis.\n\nThe first difference is given by `out[i] = a[i+1] - a[i]` along the given\naxis, higher differences are calculated by using `diff` recursively.\n\nInput array\n\nThe number of times values are differenced. If zero, the input is returned as-\nis.\n\nThe axis along which the difference is taken, default is the last axis.\n\nValues to prepend or append to `a` along axis prior to performing the\ndifference. Scalar values are expanded to arrays with length 1 in the\ndirection of axis and the shape of the input array in along all other axes.\nOtherwise the dimension and shape must match `a` except along axis.\n\nNew in version 1.16.0.\n\nThe n-th differences. The shape of the output is the same as `a` except along\n`axis` where the dimension is smaller by `n`. The type of the output is the\nsame as the type of the difference between any two elements of `a`. This is\nthe same as the type of `a` in most cases. A notable exception is\n`datetime64`, which results in a `timedelta64` output array.\n\nSee also\n\nType is preserved for boolean arrays, so the result will contain `False` when\nconsecutive elements are the same and `True` when they differ.\n\nFor unsigned integer arrays, the results will also be unsigned. This should\nnot be surprising, as the result is consistent with calculating the difference\ndirectly:\n\nIf this is not desirable, then the array should be cast to a larger integer\ntype first:\n\n"}, {"name": "numpy.digitize()", "path": "reference/generated/numpy.digitize", "type": "numpy.digitize", "text": "\nReturn the indices of the bins to which each value in input array belongs.\n\n`right`\n\norder of bins\n\nreturned index `i` satisfies\n\n`False`\n\nincreasing\n\n`bins[i-1] <= x < bins[i]`\n\n`True`\n\nincreasing\n\n`bins[i-1] < x <= bins[i]`\n\n`False`\n\ndecreasing\n\n`bins[i-1] > x >= bins[i]`\n\n`True`\n\ndecreasing\n\n`bins[i-1] >= x > bins[i]`\n\nIf values in `x` are beyond the bounds of `bins`, 0 or `len(bins)` is returned\nas appropriate.\n\nInput array to be binned. Prior to NumPy 1.10.0, this array had to be\n1-dimensional, but can now have any shape.\n\nArray of bins. It has to be 1-dimensional and monotonic.\n\nIndicating whether the intervals include the right or the left bin edge.\nDefault behavior is (right==False) indicating that the interval does not\ninclude the right edge. The left bin end is open in this case, i.e., bins[i-1]\n<= x < bins[i] is the default behavior for monotonically increasing bins.\n\nOutput array of indices, of same shape as `x`.\n\nIf `bins` is not monotonic.\n\nIf the type of the input is complex.\n\nSee also\n\nIf values in `x` are such that they fall outside the bin range, attempting to\nindex `bins` with the indices that `digitize` returns will result in an\nIndexError.\n\nNew in version 1.10.0.\n\n`np.digitize` is implemented in terms of `np.searchsorted`. This means that a\nbinary search is used to bin the values, which scales much better for larger\nnumber of bins than the previous linear search. It also removes the\nrequirement for the input array to be 1-dimensional.\n\nFor monotonically _increasing_ `bins`, the following are equivalent:\n\nNote that as the order of the arguments are reversed, the side must be too.\nThe `searchsorted` call is marginally faster, as it does not do any\nmonotonicity checks. Perhaps more importantly, it supports all dtypes.\n\n"}, {"name": "numpy.disp()", "path": "reference/generated/numpy.disp", "type": "numpy.disp", "text": "\nDisplay a message on a device.\n\nMessage to display.\n\nDevice to write message. If None, defaults to `sys.stdout` which is very\nsimilar to `print`. `device` needs to have `write()` and `flush()` methods.\n\nOption whether to print a line feed or not. Defaults to True.\n\nIf `device` does not have a `write()` or `flush()` method.\n\nBesides `sys.stdout`, a file-like object can also be used as it has both\nrequired methods:\n\n"}, {"name": "numpy.distutils.ccompiler", "path": "reference/generated/numpy.distutils.ccompiler", "type": "numpy.distutils.ccompiler", "text": "\n`CCompiler_compile`(self, sources[, ...])\n\nCompile one or more source files.\n\n`CCompiler_customize`(self, dist[, need_cxx])\n\nDo any platform-specific customization of a compiler instance.\n\n`CCompiler_customize_cmd`(self, cmd[, ignore])\n\nCustomize compiler using distutils command.\n\n`CCompiler_cxx_compiler`(self)\n\nReturn the C++ compiler.\n\n`CCompiler_find_executables`(self)\n\nDoes nothing here, but is called by the get_version method and can be\noverridden by subclasses.\n\n`CCompiler_get_version`(self[, force, ok_status])\n\nReturn compiler version, or None if compiler is not available.\n\n`CCompiler_object_filenames`(self, ...[, ...])\n\nReturn the name of the object files for the given source files.\n\n`CCompiler_show_customization`(self)\n\nPrint the compiler customizations to stdout.\n\n`CCompiler_spawn`(self, cmd[, display, env])\n\nExecute a command in a sub-process.\n\n`gen_lib_options`(compiler, library_dirs, ...)\n\n`new_compiler`([plat, compiler, verbose, ...])\n\n`replace_method`(klass, method_name, func)\n\n`simple_version_match`([pat, ignore, start])\n\nSimple matching of version numbers, for use in CCompiler and FCompiler.\n\n"}, {"name": "numpy.distutils.ccompiler_opt", "path": "reference/generated/numpy.distutils.ccompiler_opt", "type": "numpy.distutils.ccompiler_opt", "text": "\nProvides the `CCompilerOpt` class, used for handling the CPU/hardware\noptimization, starting from parsing the command arguments, to managing the\nrelation between the CPU baseline and dispatch-able features, also generating\nthe required C headers and ending with compiling the sources with proper\ncompiler\u2019s flags.\n\n`CCompilerOpt` doesn\u2019t provide runtime detection for the CPU features, instead\nonly focuses on the compiler side, but it creates abstract C headers that can\nbe used later for the final runtime dispatching process.\n\n`new_ccompiler_opt`(compiler, dispatch_hpath, ...)\n\nCreate a new instance of 'CCompilerOpt' and generate the dispatch header which\ncontains the #definitions and headers of platform-specific instruction-sets\nfor the enabled CPU baseline and dispatch-able features.\n\n`CCompilerOpt`(ccompiler[, cpu_baseline, ...])\n\nA helper class for `CCompiler` aims to provide extra build options to\neffectively control of compiler optimizations that are directly related to CPU\nfeatures.\n\n"}, {"name": "numpy.distutils.ccompiler_opt.CCompilerOpt()", "path": "reference/generated/numpy.distutils.ccompiler_opt.ccompileropt", "type": "numpy.distutils.ccompiler_opt.CCompilerOpt", "text": "\nA helper class for `CCompiler` aims to provide extra build options to\neffectively control of compiler optimizations that are directly related to CPU\nfeatures.\n\n`cache_flush`()\n\nForce update the cache.\n\n`cc_normalize_flags`(flags)\n\nRemove the conflicts that caused due gathering implied features flags.\n\n`conf_features_partial`()\n\nReturn a dictionary of supported CPU features by the platform, and accumulate\nthe rest of undefined options in `conf_features`, the returned dict has same\nrules and notes in class attribute `conf_features`, also its override any\noptions that been set in 'conf_features'.\n\n`cpu_baseline_flags`()\n\nReturns a list of final CPU baseline compiler flags\n\n`cpu_baseline_names`()\n\nreturn a list of final CPU baseline feature names\n\n`cpu_dispatch_names`()\n\nreturn a list of final CPU dispatch feature names\n\n`dist_compile`(sources, flags[, ccompiler])\n\nWrap CCompiler.compile()\n\n`dist_error`(*args)\n\nRaise a compiler error\n\n`dist_fatal`(*args)\n\nRaise a distutils error\n\n`dist_info`()\n\nReturn a tuple containing info about (platform, compiler, extra_args),\nrequired by the abstract class '_CCompiler' for discovering the platform\nenvironment.\n\n`dist_load_module`(name, path)\n\nLoad a module from file, required by the abstract class '_Cache'.\n\n`dist_log`(*args[, stderr])\n\nPrint a console message\n\n`dist_test`(source, flags[, macros])\n\nReturn True if 'CCompiler.compile()' able to compile a source file with\ncertain flags.\n\n`feature_ahead`(names)\n\nReturn list of features in 'names' after remove any implied features and keep\nthe origins.\n\n`feature_c_preprocessor`(feature_name[, tabs])\n\nGenerate C preprocessor definitions and include headers of a CPU feature.\n\n`feature_detect`(names)\n\nReturn a list of CPU features that required to be detected sorted from the\nlowest to highest interest.\n\n`feature_get_til`(names, keyisfalse)\n\nsame as `feature_implies_c()` but stop collecting implied features when\nfeature's option that provided through parameter 'keyisfalse' is False, also\nsorting the returned features.\n\n`feature_implies`(names[, keep_origins])\n\nReturn a set of CPU features that implied by 'names'\n\n`feature_implies_c`(names)\n\nsame as feature_implies() but combining 'names'\n\n`feature_is_exist`(name)\n\nReturns True if a certain feature is exist and covered within\n`_Config.conf_features`.\n\n`feature_names`([names, force_flags, macros])\n\nReturns a set of CPU feature names that supported by platform and the C\ncompiler.\n\n`feature_sorted`(names[, reverse])\n\nSort a list of CPU features ordered by the lowest interest.\n\n`feature_untied`(names)\n\nsame as 'feature_ahead()' but if both features implied each other and keep the\nhighest interest.\n\n`generate_dispatch_header`(header_path)\n\nGenerate the dispatch header which contains the #definitions and headers for\nplatform-specific instruction-sets for the enabled CPU baseline and dispatch-\nable features.\n\n`is_cached`()\n\nReturns True if the class loaded from the cache file\n\n`me`(cb)\n\nA static method that can be treated as a decorator to dynamically cache\ncertain methods.\n\n`parse_targets`(source)\n\nFetch and parse configuration statements that required for defining the\ntargeted CPU features, statements should be declared in the top of source in\nbetween C comment and start with a special mark @targets.\n\n`try_dispatch`(sources[, src_dir, ccompiler])\n\nCompile one or more dispatch-able sources and generates object files, also\ngenerates abstract C config headers and macros that used later for the final\nruntime dispatching process.\n\ncache_hash\n\ncc_test_flags\n\nfeature_can_autovec\n\nfeature_extra_checks\n\nfeature_flags\n\nfeature_is_supported\n\nfeature_test\n\nreport\n\n"}, {"name": "numpy.distutils.core.Extension()", "path": "reference/generated/numpy.distutils.core.extension", "type": "numpy.distutils.core.Extension", "text": "\nExtension name.\n\nList of source file locations relative to the top directory of the package.\n\nExtra command line arguments to pass to the compiler.\n\nExtra command line arguments to pass to the fortran77 compiler.\n\nExtra command line arguments to pass to the fortran90 compiler.\n\nhas_cxx_sources\n\nhas_f2py_sources\n\n"}, {"name": "numpy.distutils.misc_util.all_strings()", "path": "reference/distutils/misc_util", "type": "distutils.misc_util", "text": "\nReturn True if all items in lst are string objects.\n\nConvert a /-separated pathname to one using the OS\u2019s path separator.\n\nConvert a path from Cygwin-native to Windows-native.\n\nUses the cygpath utility (part of the Base install) to do the actual\nconversion. Falls back to returning the original path if this fails.\n\nHandles the default `/cygdrive` mount prefix as well as the `/proc/cygdrive`\nportable prefix, custom cygdrive prefixes such as `/` or `/mnt`, and absolute\npaths such as `/usr/src/` or `/home/username`\n\nThe path to convert\n\nThe converted path\n\nDocumentation for cygpath utility: https://cygwin.com/cygwin-ug-\nnet/cygpath.html Documentation for the C function it wraps:\nhttps://cygwin.com/cygwin-api/func-cygwin-conv-path.html\n\nReturn a configuration dictionary for usage in configuration() function\ndefined in file setup_<name>.py.\n\nUse importlib machinery to import a module `modname` from the file `modfile`.\nDepending on the `spec.loader`, the module may not be registered in\nsys.modules.\n\nReturn four lists of filenames containing C, C++, Fortran, and Fortran 90\nmodule sources, respectively.\n\nGenerate config.py file containing system_info information used during\nbuilding the package.\n\nconfig[\u2018py_modules\u2019].append((packagename, \u2018__config__\u2019,generate_config_py))\n\nReturn frame object from call stack with given level.\n\nReturn an info dict for a given C library.\n\nThe info dict contains the necessary options to use the C library.\n\nName of the package (should match the name of the .ini file, without the\nextension, e.g. foo for the file foo.ini).\n\nIf given, should be a sequence of additional directories where to look for\nnpy-pkg-config files. Those directories are searched prior to the NumPy\ndirectory.\n\nThe dictionary with build information.\n\nIf the package is not found.\n\nSee also\n\nTo get the necessary information for the npymath library from NumPy:\n\nThis info dict can then be used as input to a `Configuration` instance:\n\nDetermine language value (c,f77,f90) from sources\n\nReturn the MATHLIB line from numpyconfig.h\n\nGet number of parallel build jobs set by the \u2013parallel command line argument\nof setup.py If the command did not receive a setting the environment variable\nNPY_NUM_BUILD_JOBS is checked. If that is unset, return the number of\nprocessors on the system, with a maximum of 8 (to prevent overloading the\nsystem if there a lot of CPUs).\n\nnumber of parallel jobs that can be run\n\nReturn library info for the given package.\n\nName of the package (should match the name of the .ini file, without the\nextension, e.g. foo for the file foo.ini).\n\nIf given, should be a sequence of additional directories where to look for\nnpy-pkg-config files. Those directories are searched prior to the NumPy\ndirectory.\n\nThe `LibraryInfo` instance containing the build information.\n\nIf the package is not found.\n\nSee also\n\nApply glob to paths and prepend local_path if needed.\n\nReturn True if sources contains C++ files\n\nReturn True if sources contains Fortran files\n\nReturn true if directory is local directory.\n\nReturn true when using mingw32 environment.\n\nResolve and \u2018.\u2019 from path.\n\nJoin two or more pathname components + - convert a /-separated pathname to one\nusing the OS\u2019s path separator. - resolve and from path.\n\nEither passing n arguments as in njoin(\u2018a\u2019,\u2019b\u2019), or a sequence of n names as\nin njoin([\u2018a\u2019,\u2019b\u2019]) is handled, or a mixture of such arguments.\n\nSome flags are valid for C but not C++. Prune them.\n\n"}, {"name": "numpy.distutils.misc_util.allpath()", "path": "reference/distutils/misc_util#numpy.distutils.misc_util.allpath", "type": "distutils.misc_util", "text": "\nConvert a /-separated pathname to one using the OS\u2019s path separator.\n\n"}, {"name": "numpy.distutils.misc_util.appendpath()", "path": "reference/distutils/misc_util#numpy.distutils.misc_util.appendpath", "type": "distutils.misc_util", "text": "\n\n"}, {"name": "numpy.distutils.misc_util.as_list()", "path": "reference/distutils/misc_util#numpy.distutils.misc_util.as_list", "type": "distutils.misc_util", "text": "\n\n"}, {"name": "numpy.distutils.misc_util.blue_text()", "path": "reference/distutils/misc_util#numpy.distutils.misc_util.blue_text", "type": "distutils.misc_util", "text": "\n\n"}, {"name": "numpy.distutils.misc_util.cyan_text()", "path": "reference/distutils/misc_util#numpy.distutils.misc_util.cyan_text", "type": "distutils.misc_util", "text": "\n\n"}, {"name": "numpy.distutils.misc_util.cyg2win32()", "path": "reference/distutils/misc_util#numpy.distutils.misc_util.cyg2win32", "type": "distutils.misc_util", "text": "\nConvert a path from Cygwin-native to Windows-native.\n\nUses the cygpath utility (part of the Base install) to do the actual\nconversion. Falls back to returning the original path if this fails.\n\nHandles the default `/cygdrive` mount prefix as well as the `/proc/cygdrive`\nportable prefix, custom cygdrive prefixes such as `/` or `/mnt`, and absolute\npaths such as `/usr/src/` or `/home/username`\n\nThe path to convert\n\nThe converted path\n\nDocumentation for cygpath utility: https://cygwin.com/cygwin-ug-\nnet/cygpath.html Documentation for the C function it wraps:\nhttps://cygwin.com/cygwin-api/func-cygwin-conv-path.html\n\n"}, {"name": "numpy.distutils.misc_util.default_config_dict()", "path": "reference/distutils/misc_util#numpy.distutils.misc_util.default_config_dict", "type": "distutils.misc_util", "text": "\nReturn a configuration dictionary for usage in configuration() function\ndefined in file setup_<name>.py.\n\n"}, {"name": "numpy.distutils.misc_util.dict_append()", "path": "reference/distutils/misc_util#numpy.distutils.misc_util.dict_append", "type": "distutils.misc_util", "text": "\n\n"}, {"name": "numpy.distutils.misc_util.dot_join()", "path": "reference/distutils/misc_util#numpy.distutils.misc_util.dot_join", "type": "distutils.misc_util", "text": "\n\n"}, {"name": "numpy.distutils.misc_util.exec_mod_from_location()", "path": "reference/distutils/misc_util#numpy.distutils.misc_util.exec_mod_from_location", "type": "distutils.misc_util", "text": "\nUse importlib machinery to import a module `modname` from the file `modfile`.\nDepending on the `spec.loader`, the module may not be registered in\nsys.modules.\n\n"}, {"name": "numpy.distutils.misc_util.filter_sources()", "path": "reference/distutils/misc_util#numpy.distutils.misc_util.filter_sources", "type": "distutils.misc_util", "text": "\nReturn four lists of filenames containing C, C++, Fortran, and Fortran 90\nmodule sources, respectively.\n\n"}, {"name": "numpy.distutils.misc_util.generate_config_py()", "path": "reference/distutils/misc_util#numpy.distutils.misc_util.generate_config_py", "type": "distutils.misc_util", "text": "\nGenerate config.py file containing system_info information used during\nbuilding the package.\n\nconfig[\u2018py_modules\u2019].append((packagename, \u2018__config__\u2019,generate_config_py))\n\n"}, {"name": "numpy.distutils.misc_util.get_build_architecture()", "path": "reference/distutils/misc_util#numpy.distutils.misc_util.get_build_architecture", "type": "distutils.misc_util", "text": "\n\n"}, {"name": "numpy.distutils.misc_util.get_cmd()", "path": "reference/distutils/misc_util#numpy.distutils.misc_util.get_cmd", "type": "distutils.misc_util", "text": "\n\n"}, {"name": "numpy.distutils.misc_util.get_data_files()", "path": "reference/distutils/misc_util#numpy.distutils.misc_util.get_data_files", "type": "distutils.misc_util", "text": "\n\n"}, {"name": "numpy.distutils.misc_util.get_dependencies()", "path": "reference/distutils/misc_util#numpy.distutils.misc_util.get_dependencies", "type": "distutils.misc_util", "text": "\n\n"}, {"name": "numpy.distutils.misc_util.get_ext_source_files()", "path": "reference/distutils/misc_util#numpy.distutils.misc_util.get_ext_source_files", "type": "distutils.misc_util", "text": "\n\n"}, {"name": "numpy.distutils.misc_util.get_frame()", "path": "reference/distutils/misc_util#numpy.distutils.misc_util.get_frame", "type": "distutils.misc_util", "text": "\nReturn frame object from call stack with given level.\n\n"}, {"name": "numpy.distutils.misc_util.get_info()", "path": "reference/distutils/misc_util#numpy.distutils.misc_util.get_info", "type": "distutils.misc_util", "text": "\nReturn an info dict for a given C library.\n\nThe info dict contains the necessary options to use the C library.\n\nName of the package (should match the name of the .ini file, without the\nextension, e.g. foo for the file foo.ini).\n\nIf given, should be a sequence of additional directories where to look for\nnpy-pkg-config files. Those directories are searched prior to the NumPy\ndirectory.\n\nThe dictionary with build information.\n\nIf the package is not found.\n\nSee also\n\nTo get the necessary information for the npymath library from NumPy:\n\nThis info dict can then be used as input to a `Configuration` instance:\n\n"}, {"name": "numpy.distutils.misc_util.get_language()", "path": "reference/distutils/misc_util#numpy.distutils.misc_util.get_language", "type": "distutils.misc_util", "text": "\nDetermine language value (c,f77,f90) from sources\n\n"}, {"name": "numpy.distutils.misc_util.get_lib_source_files()", "path": "reference/distutils/misc_util#numpy.distutils.misc_util.get_lib_source_files", "type": "distutils.misc_util", "text": "\n\n"}, {"name": "numpy.distutils.misc_util.get_mathlibs()", "path": "reference/distutils/misc_util#numpy.distutils.misc_util.get_mathlibs", "type": "distutils.misc_util", "text": "\nReturn the MATHLIB line from numpyconfig.h\n\n"}, {"name": "numpy.distutils.misc_util.get_num_build_jobs()", "path": "reference/distutils/misc_util#numpy.distutils.misc_util.get_num_build_jobs", "type": "distutils.misc_util", "text": "\nGet number of parallel build jobs set by the \u2013parallel command line argument\nof setup.py If the command did not receive a setting the environment variable\nNPY_NUM_BUILD_JOBS is checked. If that is unset, return the number of\nprocessors on the system, with a maximum of 8 (to prevent overloading the\nsystem if there a lot of CPUs).\n\nnumber of parallel jobs that can be run\n\n"}, {"name": "numpy.distutils.misc_util.get_numpy_include_dirs()", "path": "reference/distutils/misc_util#numpy.distutils.misc_util.get_numpy_include_dirs", "type": "distutils.misc_util", "text": "\n\n"}, {"name": "numpy.distutils.misc_util.get_pkg_info()", "path": "reference/distutils/misc_util#numpy.distutils.misc_util.get_pkg_info", "type": "distutils.misc_util", "text": "\nReturn library info for the given package.\n\nName of the package (should match the name of the .ini file, without the\nextension, e.g. foo for the file foo.ini).\n\nIf given, should be a sequence of additional directories where to look for\nnpy-pkg-config files. Those directories are searched prior to the NumPy\ndirectory.\n\nThe `LibraryInfo` instance containing the build information.\n\nIf the package is not found.\n\nSee also\n\n"}, {"name": "numpy.distutils.misc_util.get_script_files()", "path": "reference/distutils/misc_util#numpy.distutils.misc_util.get_script_files", "type": "distutils.misc_util", "text": "\n\n"}, {"name": "numpy.distutils.misc_util.gpaths()", "path": "reference/distutils/misc_util#numpy.distutils.misc_util.gpaths", "type": "distutils.misc_util", "text": "\nApply glob to paths and prepend local_path if needed.\n\n"}, {"name": "numpy.distutils.misc_util.green_text()", "path": "reference/distutils/misc_util#numpy.distutils.misc_util.green_text", "type": "distutils.misc_util", "text": "\n\n"}, {"name": "numpy.distutils.misc_util.has_cxx_sources()", "path": "reference/distutils/misc_util#numpy.distutils.misc_util.has_cxx_sources", "type": "distutils.misc_util", "text": "\nReturn True if sources contains C++ files\n\n"}, {"name": "numpy.distutils.misc_util.has_f_sources()", "path": "reference/distutils/misc_util#numpy.distutils.misc_util.has_f_sources", "type": "distutils.misc_util", "text": "\nReturn True if sources contains Fortran files\n\n"}, {"name": "numpy.distutils.misc_util.is_local_src_dir()", "path": "reference/distutils/misc_util#numpy.distutils.misc_util.is_local_src_dir", "type": "distutils.misc_util", "text": "\nReturn true if directory is local directory.\n\n"}, {"name": "numpy.distutils.misc_util.is_sequence()", "path": "reference/distutils/misc_util#numpy.distutils.misc_util.is_sequence", "type": "distutils.misc_util", "text": "\n\n"}, {"name": "numpy.distutils.misc_util.is_string()", "path": "reference/distutils/misc_util#numpy.distutils.misc_util.is_string", "type": "distutils.misc_util", "text": "\n\n"}, {"name": "numpy.distutils.misc_util.mingw32()", "path": "reference/distutils/misc_util#numpy.distutils.misc_util.mingw32", "type": "distutils.misc_util", "text": "\nReturn true when using mingw32 environment.\n\n"}, {"name": "numpy.distutils.misc_util.minrelpath()", "path": "reference/distutils/misc_util#numpy.distutils.misc_util.minrelpath", "type": "distutils.misc_util", "text": "\nResolve and \u2018.\u2019 from path.\n\n"}, {"name": "numpy.distutils.misc_util.njoin()", "path": "reference/distutils/misc_util#numpy.distutils.misc_util.njoin", "type": "distutils.misc_util", "text": "\nJoin two or more pathname components + - convert a /-separated pathname to one\nusing the OS\u2019s path separator. - resolve and from path.\n\nEither passing n arguments as in njoin(\u2018a\u2019,\u2019b\u2019), or a sequence of n names as\nin njoin([\u2018a\u2019,\u2019b\u2019]) is handled, or a mixture of such arguments.\n\n"}, {"name": "numpy.distutils.misc_util.red_text()", "path": "reference/distutils/misc_util#numpy.distutils.misc_util.red_text", "type": "distutils.misc_util", "text": "\n\n"}, {"name": "numpy.distutils.misc_util.sanitize_cxx_flags()", "path": "reference/distutils/misc_util#numpy.distutils.misc_util.sanitize_cxx_flags", "type": "distutils.misc_util", "text": "\nSome flags are valid for C but not C++. Prune them.\n\n"}, {"name": "numpy.distutils.misc_util.terminal_has_colors()", "path": "reference/distutils/misc_util#numpy.distutils.misc_util.terminal_has_colors", "type": "distutils.misc_util", "text": "\n\n"}, {"name": "numpy.distutils.misc_util.yellow_text()", "path": "reference/distutils/misc_util#numpy.distutils.misc_util.yellow_text", "type": "distutils.misc_util", "text": "\n\n"}, {"name": "numpy.divide()", "path": "reference/generated/numpy.divide", "type": "numpy.divide", "text": "\nReturns a true division of the inputs, element-wise.\n\nUnlike \u2018floor division\u2019, true division adjusts the output type to present the\nbest answer, regardless of input types.\n\nDividend array.\n\nDivisor array. If `x1.shape != x2.shape`, they must be broadcastable to a\ncommon shape (which becomes the shape of the output).\n\nA location into which the result is stored. If provided, it must have a shape\nthat the inputs broadcast to. If not provided or None, a freshly-allocated\narray is returned. A tuple (possible only as a keyword argument) must have\nlength equal to the number of outputs.\n\nThis condition is broadcast over the input. At locations where the condition\nis True, the `out` array will be set to the ufunc result. Elsewhere, the `out`\narray will retain its original value. Note that if an uninitialized `out`\narray is created via the default `out=None`, locations within it where the\ncondition is False will remain uninitialized.\n\nFor other keyword-only arguments, see the ufunc docs.\n\nThis is a scalar if both `x1` and `x2` are scalars.\n\nIn Python, `//` is the floor division operator and `/` the true division\noperator. The `true_divide(x1, x2)` function is equivalent to true division in\nPython.\n\nThe `/` operator can be used as a shorthand for `np.true_divide` on ndarrays.\n\n"}, {"name": "numpy.divmod()", "path": "reference/generated/numpy.divmod", "type": "numpy.divmod", "text": "\nReturn element-wise quotient and remainder simultaneously.\n\nNew in version 1.13.0.\n\n`np.divmod(x, y)` is equivalent to `(x // y, x % y)`, but faster because it\navoids redundant work. It is used to implement the Python built-in function\n`divmod` on NumPy arrays.\n\nDividend array.\n\nDivisor array. If `x1.shape != x2.shape`, they must be broadcastable to a\ncommon shape (which becomes the shape of the output).\n\nA location into which the result is stored. If provided, it must have a shape\nthat the inputs broadcast to. If not provided or None, a freshly-allocated\narray is returned. A tuple (possible only as a keyword argument) must have\nlength equal to the number of outputs.\n\nThis condition is broadcast over the input. At locations where the condition\nis True, the `out` array will be set to the ufunc result. Elsewhere, the `out`\narray will retain its original value. Note that if an uninitialized `out`\narray is created via the default `out=None`, locations within it where the\ncondition is False will remain uninitialized.\n\nFor other keyword-only arguments, see the ufunc docs.\n\nElement-wise quotient resulting from floor division. This is a scalar if both\n`x1` and `x2` are scalars.\n\nElement-wise remainder from floor division. This is a scalar if both `x1` and\n`x2` are scalars.\n\nSee also\n\nEquivalent to Python\u2019s `//` operator.\n\nEquivalent to Python\u2019s `%` operator.\n\nEquivalent to `divmod(x, 1)` for positive `x` with the return values switched.\n\nThe `divmod` function can be used as a shorthand for `np.divmod` on ndarrays.\n\n"}, {"name": "numpy.dot()", "path": "reference/generated/numpy.dot", "type": "numpy.dot", "text": "\nDot product of two arrays. Specifically,\n\nIf `a` is an N-D array and `b` is an M-D array (where `M>=2`), it is a sum\nproduct over the last axis of `a` and the second-to-last axis of `b`:\n\nFirst argument.\n\nSecond argument.\n\nOutput argument. This must have the exact kind that would be returned if it\nwas not used. In particular, it must have the right type, must be\nC-contiguous, and its dtype must be the dtype that would be returned for\n`dot(a,b)`. This is a performance feature. Therefore, if these conditions are\nnot met, an exception is raised, instead of attempting to be flexible.\n\nReturns the dot product of `a` and `b`. If `a` and `b` are both scalars or\nboth 1-D arrays then a scalar is returned; otherwise an array is returned. If\n`out` is given, then it is returned.\n\nIf the last dimension of `a` is not the same size as the second-to-last\ndimension of `b`.\n\nSee also\n\nComplex-conjugating dot product.\n\nSum products over arbitrary axes.\n\nEinstein summation convention.\n\n\u2018@\u2019 operator as method with out parameter.\n\nChained dot product.\n\nNeither argument is complex-conjugated:\n\nFor 2-D arrays it is the matrix product:\n\n"}, {"name": "numpy.double()", "path": "reference/arrays.scalars#numpy.double", "type": "Scalars", "text": "\nDouble-precision floating-point number type, compatible with Python `float`\nand C `double`.\n\n`'d'`\n\n`numpy.float_`\n\n`numpy.float64`: 64-bit precision floating-point number type: sign bit, 11\nbits exponent, 52 bits mantissa.\n\n"}, {"name": "numpy.dsplit()", "path": "reference/generated/numpy.dsplit", "type": "numpy.dsplit", "text": "\nSplit array into multiple sub-arrays along the 3rd axis (depth).\n\nPlease refer to the `split` documentation. `dsplit` is equivalent to `split`\nwith `axis=2`, the array is always split along the third axis provided the\narray dimension is greater than or equal to 3.\n\nSee also\n\nSplit an array into multiple sub-arrays of equal size.\n\n"}, {"name": "numpy.dstack()", "path": "reference/generated/numpy.dstack", "type": "numpy.dstack", "text": "\nStack arrays in sequence depth wise (along third axis).\n\nThis is equivalent to concatenation along the third axis after 2-D arrays of\nshape `(M,N)` have been reshaped to `(M,N,1)` and 1-D arrays of shape `(N,)`\nhave been reshaped to `(1,N,1)`. Rebuilds arrays divided by `dsplit`.\n\nThis function makes most sense for arrays with up to 3 dimensions. For\ninstance, for pixel-data with a height (first axis), width (second axis), and\nr/g/b channels (third axis). The functions `concatenate`, `stack` and `block`\nprovide more general stacking and concatenation operations.\n\nThe arrays must have the same shape along all but the third axis. 1-D or 2-D\narrays must have the same shape.\n\nThe array formed by stacking the given arrays, will be at least 3-D.\n\nSee also\n\nJoin a sequence of arrays along an existing axis.\n\nJoin a sequence of arrays along a new axis.\n\nAssemble an nd-array from nested lists of blocks.\n\nStack arrays in sequence vertically (row wise).\n\nStack arrays in sequence horizontally (column wise).\n\nStack 1-D arrays as columns into a 2-D array.\n\nSplit array along third axis.\n\n"}, {"name": "numpy.dtype()", "path": "reference/generated/numpy.dtype", "type": "numpy.dtype", "text": "\nCreate a data type object.\n\nA numpy array is homogeneous, and contains elements described by a dtype\nobject. A dtype object can be constructed from different combinations of\nfundamental numeric types.\n\nObject to be converted to a data type object.\n\nAdd padding to the fields to match what a C compiler would output for a\nsimilar C-struct. Can be `True` only if `obj` is a dictionary or a comma-\nseparated string. If a struct dtype is being created, this also sets a sticky\nalignment flag `isalignedstruct`.\n\nMake a new copy of the data-type object. If `False`, the result may just be a\nreference to a built-in data-type object.\n\nSee also\n\nUsing array-scalar type:\n\nStructured type, one field name \u2018f1\u2019, containing int16:\n\nStructured type, one field named \u2018f1\u2019, in itself containing a structured type\nwith one field:\n\nStructured type, two fields: the first field contains an unsigned int, the\nsecond an int32:\n\nUsing array-protocol type strings:\n\nUsing comma-separated field formats. The shape is (2,3):\n\nUsing tuples. `int` is a fixed type, 3 the field\u2019s shape. `void` is a flexible\ntype, here of size 10:\n\nSubdivide `int16` into 2 `int8`\u2019s, called x and y. 0 and 1 are the offsets in\nbytes:\n\nUsing dictionaries. Two fields named \u2018gender\u2019 and \u2018age\u2019:\n\nOffsets in bytes, here 0 and 25:\n\nThe required alignment (bytes) of this data-type according to the compiler.\n\nReturns dtype for the base element of the subarrays, regardless of their\ndimension or shape.\n\nA character indicating the byte-order of this data-type object.\n\nA unique character code for each of the 21 different built-in types.\n\n`__array_interface__` description of the data-type.\n\nDictionary of named fields defined for this data type, or `None`.\n\nBit-flags describing how this data type is to be interpreted.\n\nBoolean indicating whether this dtype contains any reference-counted objects\nin any fields or sub-dtypes.\n\nBoolean indicating whether the dtype is a struct which maintains field\nalignment.\n\nInteger indicating how this dtype relates to the built-in dtypes.\n\nBoolean indicating whether the byte order of this dtype is native to the\nplatform.\n\nThe element size of this data-type object.\n\nA character code (one of \u2018biufcmMOSUV\u2019) identifying the general kind of data.\n\nEither `None` or a readonly dictionary of metadata (mappingproxy).\n\nA bit-width name for this data-type.\n\nOrdered list of field names, or `None` if there are no fields.\n\nNumber of dimensions of the sub-array if this data type describes a sub-array,\nand `0` otherwise.\n\nA unique number for each of the 21 different built-in types.\n\nShape tuple of the sub-array if this data type describes a sub-array, and `()`\notherwise.\n\nThe array-protocol typestring of this data-type object.\n\nTuple `(item_dtype, shape)` if this `dtype` describes a sub-array, and None\notherwise.\n\n`newbyteorder`([new_order])\n\nReturn a new dtype with a different byte order.\n\n"}, {"name": "numpy.e", "path": "reference/constants#numpy.e", "type": "Constants", "text": "\nEuler\u2019s constant, base of natural logarithms, Napier\u2019s constant.\n\n`e = 2.71828182845904523536028747135266249775724709369995...`\n\nexp : Exponential function log : Natural logarithm\n\nhttps://en.wikipedia.org/wiki/E_%28mathematical_constant%29\n\n"}, {"name": "numpy.ediff1d()", "path": "reference/generated/numpy.ediff1d", "type": "numpy.ediff1d", "text": "\nThe differences between consecutive elements of an array.\n\nIf necessary, will be flattened before the differences are taken.\n\nNumber(s) to append at the end of the returned differences.\n\nNumber(s) to prepend at the beginning of the returned differences.\n\nThe differences. Loosely, this is `ary.flat[1:] - ary.flat[:-1]`.\n\nSee also\n\nWhen applied to masked arrays, this function drops the mask information if the\n`to_begin` and/or `to_end` parameters are used.\n\nThe returned array is always 1D.\n\n"}, {"name": "numpy.einsum()", "path": "reference/generated/numpy.einsum", "type": "numpy.einsum", "text": "\nEvaluates the Einstein summation convention on the operands.\n\nUsing the Einstein summation convention, many common multi-dimensional, linear\nalgebraic array operations can be represented in a simple fashion. In implicit\nmode `einsum` computes these values.\n\nIn explicit mode, `einsum` provides further flexibility to compute other array\noperations that might not be considered classical Einstein summation\noperations, by disabling, or forcing summation over specified subscript\nlabels.\n\nSee the notes and examples for clarification.\n\nSpecifies the subscripts for summation as comma separated list of subscript\nlabels. An implicit (classical Einstein summation) calculation is performed\nunless the explicit indicator \u2018->\u2019 is included as well as subscript labels of\nthe precise output form.\n\nThese are the arrays for the operation.\n\nIf provided, the calculation is done into this array.\n\nIf provided, forces the calculation to use the data type specified. Note that\nyou may have to also give a more liberal `casting` parameter to allow the\nconversions. Default is None.\n\nControls the memory layout of the output. \u2018C\u2019 means it should be C contiguous.\n\u2018F\u2019 means it should be Fortran contiguous, \u2018A\u2019 means it should be \u2018F\u2019 if the\ninputs are all \u2018F\u2019, \u2018C\u2019 otherwise. \u2018K\u2019 means it should be as close to the\nlayout as the inputs as is possible, including arbitrarily permuted axes.\nDefault is \u2018K\u2019.\n\nControls what kind of data casting may occur. Setting this to \u2018unsafe\u2019 is not\nrecommended, as it can adversely affect accumulations.\n\nDefault is \u2018safe\u2019.\n\nControls if intermediate optimization should occur. No optimization will occur\nif False and True will default to the \u2018greedy\u2019 algorithm. Also accepts an\nexplicit contraction list from the `np.einsum_path` function. See\n`np.einsum_path` for more details. Defaults to False.\n\nThe calculation based on the Einstein summation convention.\n\nSee also\n\nsimilar verbose interface is provided by einops package to cover additional\noperations: transpose, reshape/flatten, repeat/tile, squeeze/unsqueeze and\nreductions.\n\nopt_einsum optimizes contraction order for einsum-like expressions in backend-\nagnostic manner.\n\nNew in version 1.6.0.\n\nThe Einstein summation convention can be used to compute many multi-\ndimensional, linear algebraic array operations. `einsum` provides a succinct\nway of representing these.\n\nA non-exhaustive list of these operations, which can be computed by `einsum`,\nis shown below along with examples:\n\nThe subscripts string is a comma-separated list of subscript labels, where\neach label refers to a dimension of the corresponding operand. Whenever a\nlabel is repeated it is summed, so `np.einsum('i,i', a, b)` is equivalent to\n`np.inner(a,b)`. If a label appears only once, it is not summed, so\n`np.einsum('i', a)` produces a view of `a` with no changes. A further example\n`np.einsum('ij,jk', a, b)` describes traditional matrix multiplication and is\nequivalent to `np.matmul(a,b)`. Repeated subscript labels in one operand take\nthe diagonal. For example, `np.einsum('ii', a)` is equivalent to\n`np.trace(a)`.\n\nIn implicit mode, the chosen subscripts are important since the axes of the\noutput are reordered alphabetically. This means that `np.einsum('ij', a)`\ndoesn\u2019t affect a 2D array, while `np.einsum('ji', a)` takes its transpose.\nAdditionally, `np.einsum('ij,jk', a, b)` returns a matrix multiplication,\nwhile, `np.einsum('ij,jh', a, b)` returns the transpose of the multiplication\nsince subscript \u2018h\u2019 precedes subscript \u2018i\u2019.\n\nIn explicit mode the output can be directly controlled by specifying output\nsubscript labels. This requires the identifier \u2018->\u2019 as well as the list of\noutput subscript labels. This feature increases the flexibility of the\nfunction since summing can be disabled or forced when required. The call\n`np.einsum('i->', a)` is like `np.sum(a, axis=-1)`, and `np.einsum('ii->i',\na)` is like `np.diag(a)`. The difference is that `einsum` does not allow\nbroadcasting by default. Additionally `np.einsum('ij,jh->ih', a, b)` directly\nspecifies the order of the output subscript labels and therefore returns\nmatrix multiplication, unlike the example above in implicit mode.\n\nTo enable and control broadcasting, use an ellipsis. Default NumPy-style\nbroadcasting is done by adding an ellipsis to the left of each term, like\n`np.einsum('...ii->...i', a)`. To take the trace along the first and last\naxes, you can do `np.einsum('i...i', a)`, or to do a matrix-matrix product\nwith the left-most indices instead of rightmost, one can do\n`np.einsum('ij...,jk...->ik...', a, b)`.\n\nWhen there is only one operand, no axes are summed, and no output parameter is\nprovided, a view into the operand is returned instead of a new array. Thus,\ntaking the diagonal as `np.einsum('ii->i', a)` produces a view (changed in\nversion 1.10.0).\n\n`einsum` also provides an alternative way to provide the subscripts and\noperands as `einsum(op0, sublist0, op1, sublist1, ..., [sublistout])`. If the\noutput shape is not provided in this format `einsum` will be calculated in\nimplicit mode, otherwise it will be performed explicitly. The examples below\nhave corresponding `einsum` calls with the two parameter methods.\n\nNew in version 1.10.0.\n\nViews returned from einsum are now writeable whenever the input array is\nwriteable. For example, `np.einsum('ijk...->kji...', a)` will now have the\nsame effect as `np.swapaxes(a, 0, 2)` and `np.einsum('ii->i', a)` will return\na writeable view of the diagonal of a 2D array.\n\nNew in version 1.12.0.\n\nAdded the `optimize` argument which will optimize the contraction order of an\neinsum expression. For a contraction with three or more operands this can\ngreatly increase the computational efficiency at the cost of a larger memory\nfootprint during computation.\n\nTypically a \u2018greedy\u2019 algorithm is applied which empirical tests have shown\nreturns the optimal path in the majority of cases. In some cases \u2018optimal\u2019\nwill return the superlative path through a more expensive, exhaustive search.\nFor iterative calculations it may be advisable to calculate the optimal path\nonce and reuse that path by supplying it as an argument. An example is given\nbelow.\n\nSee `numpy.einsum_path` for more details.\n\nTrace of a matrix:\n\nExtract the diagonal (requires explicit form):\n\nSum over an axis (requires explicit form):\n\nFor higher dimensional arrays summing a single axis can be done with ellipsis:\n\nCompute a matrix transpose, or reorder any number of axes:\n\nVector inner products:\n\nMatrix vector multiplication:\n\nBroadcasting and scalar multiplication:\n\nVector outer product:\n\nTensor contraction:\n\nWriteable returned arrays (since version 1.10.0):\n\nExample of ellipsis use:\n\nChained array operations. For more complicated contractions, speed ups might\nbe achieved by repeatedly computing a \u2018greedy\u2019 path or pre-computing the\n\u2018optimal\u2019 path and repeatedly applying it, using an `einsum_path` insertion\n(since version 1.12.0). Performance improvements can be particularly\nsignificant with larger arrays:\n\nBasic `einsum`: ~1520ms (benchmarked on 3.1GHz Intel i5.)\n\nSub-optimal `einsum` (due to repeated path calculation time): ~330ms\n\nGreedy `einsum` (faster optimal path approximation): ~160ms\n\nOptimal `einsum` (best usage pattern in some use cases): ~110ms\n\n"}, {"name": "numpy.einsum_path()", "path": "reference/generated/numpy.einsum_path", "type": "numpy.einsum_path", "text": "\nEvaluates the lowest cost contraction order for an einsum expression by\nconsidering the creation of intermediate arrays.\n\nSpecifies the subscripts for summation.\n\nThese are the arrays for the operation.\n\nChoose the type of path. If a tuple is provided, the second argument is\nassumed to be the maximum intermediate size created. If only a single argument\nis provided the largest input or output array size is used as a maximum\nintermediate size.\n\nDefault is \u2018greedy\u2019.\n\nA list representation of the einsum path.\n\nA printable representation of the einsum path.\n\nSee also\n\nThe resulting path indicates which terms of the input contraction should be\ncontracted first, the result of this contraction is then appended to the end\nof the contraction list. This list can then be iterated over until all\nintermediate contractions are complete.\n\nWe can begin with a chain dot example. In this case, it is optimal to contract\nthe `b` and `c` tensors first as represented by the first element of the path\n`(1, 2)`. The resulting tensor is added to the end of the contraction and the\nremaining contraction `(0, 1)` is then completed.\n\nA more complex index transformation example.\n\n"}, {"name": "numpy.empty()", "path": "reference/generated/numpy.empty", "type": "numpy.empty", "text": "\nReturn a new array of given shape and type, without initializing entries.\n\nShape of the empty array, e.g., `(2, 3)` or `2`.\n\nDesired output data-type for the array, e.g, `numpy.int8`. Default is\n`numpy.float64`.\n\nWhether to store multi-dimensional data in row-major (C-style) or column-major\n(Fortran-style) order in memory.\n\nReference object to allow the creation of arrays which are not NumPy arrays.\nIf an array-like passed in as `like` supports the `__array_function__`\nprotocol, the result will be defined by it. In this case, it ensures the\ncreation of an array object compatible with that passed in via this argument.\n\nNew in version 1.20.0.\n\nArray of uninitialized (arbitrary) data of the given shape, dtype, and order.\nObject arrays will be initialized to None.\n\nSee also\n\nReturn an empty array with shape and type of input.\n\nReturn a new array setting values to one.\n\nReturn a new array setting values to zero.\n\nReturn a new array of given shape filled with value.\n\n`empty`, unlike `zeros`, does not set the array values to zero, and may\ntherefore be marginally faster. On the other hand, it requires the user to\nmanually set all the values in the array, and should be used with caution.\n\n"}, {"name": "numpy.empty_like()", "path": "reference/generated/numpy.empty_like", "type": "numpy.empty_like", "text": "\nReturn a new array with the same shape and type as a given array.\n\nThe shape and data-type of `prototype` define these same attributes of the\nreturned array.\n\nOverrides the data type of the result.\n\nNew in version 1.6.0.\n\nOverrides the memory layout of the result. \u2018C\u2019 means C-order, \u2018F\u2019 means\nF-order, \u2018A\u2019 means \u2018F\u2019 if `prototype` is Fortran contiguous, \u2018C\u2019 otherwise.\n\u2018K\u2019 means match the layout of `prototype` as closely as possible.\n\nNew in version 1.6.0.\n\nIf True, then the newly created array will use the sub-class type of\n`prototype`, otherwise it will be a base-class array. Defaults to True.\n\nOverrides the shape of the result. If order=\u2019K\u2019 and the number of dimensions\nis unchanged, will try to keep order, otherwise, order=\u2019C\u2019 is implied.\n\nNew in version 1.17.0.\n\nArray of uninitialized (arbitrary) data with the same shape and type as\n`prototype`.\n\nSee also\n\nReturn an array of ones with shape and type of input.\n\nReturn an array of zeros with shape and type of input.\n\nReturn a new array with shape of input filled with value.\n\nReturn a new uninitialized array.\n\nThis function does not initialize the returned array; to do that use\n`zeros_like` or `ones_like` instead. It may be marginally faster than the\nfunctions that do set the array values.\n\n"}, {"name": "numpy.equal()", "path": "reference/generated/numpy.equal", "type": "numpy.equal", "text": "\nReturn (x1 == x2) element-wise.\n\nInput arrays. If `x1.shape != x2.shape`, they must be broadcastable to a\ncommon shape (which becomes the shape of the output).\n\nA location into which the result is stored. If provided, it must have a shape\nthat the inputs broadcast to. If not provided or None, a freshly-allocated\narray is returned. A tuple (possible only as a keyword argument) must have\nlength equal to the number of outputs.\n\nThis condition is broadcast over the input. At locations where the condition\nis True, the `out` array will be set to the ufunc result. Elsewhere, the `out`\narray will retain its original value. Note that if an uninitialized `out`\narray is created via the default `out=None`, locations within it where the\ncondition is False will remain uninitialized.\n\nFor other keyword-only arguments, see the ufunc docs.\n\nOutput array, element-wise comparison of `x1` and `x2`. Typically of type\nbool, unless `dtype=object` is passed. This is a scalar if both `x1` and `x2`\nare scalars.\n\nSee also\n\nWhat is compared are values, not types. So an int (1) and an array of length\none can evaluate as True:\n\nThe `==` operator can be used as a shorthand for `np.equal` on ndarrays.\n\n"}, {"name": "numpy.errstate()", "path": "reference/generated/numpy.errstate", "type": "numpy.errstate", "text": "\nContext manager for floating-point error handling.\n\nUsing an instance of `errstate` as a context manager allows statements in that\ncontext to execute with a known error handling behavior. Upon entering the\ncontext the error handling is set with `seterr` and `seterrcall`, and upon\nexiting it is reset to what it was before.\n\nChanged in version 1.17.0: `errstate` is also usable as a function decorator,\nsaving a level of indentation if an entire function is wrapped. See\n`contextlib.ContextDecorator` for more information.\n\nKeyword arguments. The valid keywords are the possible floating-point\nexceptions. Each keyword should have a string value that defines the treatment\nfor the particular error. Possible values are {\u2018ignore\u2019, \u2018warn\u2019, \u2018raise\u2019,\n\u2018call\u2019, \u2018print\u2019, \u2018log\u2019}.\n\nSee also\n\nFor complete documentation of the types of floating-point exceptions and\ntreatment options, see `seterr`.\n\nOutside the context the error handling behavior has not changed:\n\n`__call__`(func)\n\nCall self as a function.\n\n"}, {"name": "numpy.euler_gamma", "path": "reference/constants#numpy.euler_gamma", "type": "Constants", "text": "\n`\u03b3 = 0.5772156649015328606065120900824024310421...`\n\nhttps://en.wikipedia.org/wiki/Euler-Mascheroni_constant\n\n"}, {"name": "numpy.exp()", "path": "reference/generated/numpy.exp", "type": "numpy.exp", "text": "\nCalculate the exponential of all elements in the input array.\n\nInput values.\n\nA location into which the result is stored. If provided, it must have a shape\nthat the inputs broadcast to. If not provided or None, a freshly-allocated\narray is returned. A tuple (possible only as a keyword argument) must have\nlength equal to the number of outputs.\n\nThis condition is broadcast over the input. At locations where the condition\nis True, the `out` array will be set to the ufunc result. Elsewhere, the `out`\narray will retain its original value. Note that if an uninitialized `out`\narray is created via the default `out=None`, locations within it where the\ncondition is False will remain uninitialized.\n\nFor other keyword-only arguments, see the ufunc docs.\n\nOutput array, element-wise exponential of `x`. This is a scalar if `x` is a\nscalar.\n\nSee also\n\nCalculate `exp(x) - 1` for all elements in the array.\n\nCalculate `2**x` for all elements in the array.\n\nThe irrational number `e` is also known as Euler\u2019s number. It is approximately\n2.718281, and is the base of the natural logarithm, `ln` (this means that, if\n\\\\(x = \\ln y = \\log_e y\\\\), then \\\\(e^x = y\\\\). For real input, `exp(x)` is\nalways positive.\n\nFor complex arguments, `x = a + ib`, we can write \\\\(e^x = e^a e^{ib}\\\\). The\nfirst term, \\\\(e^a\\\\), is already known (it is the real argument, described\nabove). The second term, \\\\(e^{ib}\\\\), is \\\\(\\cos b + i \\sin b\\\\), a function\nwith magnitude 1 and a periodic phase.\n\nWikipedia, \u201cExponential function\u201d,\nhttps://en.wikipedia.org/wiki/Exponential_function\n\nM. Abramovitz and I. A. Stegun, \u201cHandbook of Mathematical Functions with\nFormulas, Graphs, and Mathematical Tables,\u201d Dover, 1964, p. 69,\nhttps://personal.math.ubc.ca/~cbm/aands/page_69.htm\n\nPlot the magnitude and phase of `exp(x)` in the complex plane:\n\n"}, {"name": "numpy.exp2()", "path": "reference/generated/numpy.exp2", "type": "numpy.exp2", "text": "\nCalculate `2**p` for all `p` in the input array.\n\nInput values.\n\nA location into which the result is stored. If provided, it must have a shape\nthat the inputs broadcast to. If not provided or None, a freshly-allocated\narray is returned. A tuple (possible only as a keyword argument) must have\nlength equal to the number of outputs.\n\nThis condition is broadcast over the input. At locations where the condition\nis True, the `out` array will be set to the ufunc result. Elsewhere, the `out`\narray will retain its original value. Note that if an uninitialized `out`\narray is created via the default `out=None`, locations within it where the\ncondition is False will remain uninitialized.\n\nFor other keyword-only arguments, see the ufunc docs.\n\nElement-wise 2 to the power `x`. This is a scalar if `x` is a scalar.\n\nSee also\n\nNew in version 1.3.0.\n\n"}, {"name": "numpy.expand_dims()", "path": "reference/generated/numpy.expand_dims", "type": "numpy.expand_dims", "text": "\nExpand the shape of an array.\n\nInsert a new axis that will appear at the `axis` position in the expanded\narray shape.\n\nInput array.\n\nPosition in the expanded axes where the new axis (or axes) is placed.\n\nDeprecated since version 1.13.0: Passing an axis where `axis > a.ndim` will be\ntreated as `axis == a.ndim`, and passing `axis < -a.ndim - 1` will be treated\nas `axis == 0`. This behavior is deprecated.\n\nChanged in version 1.18.0: A tuple of axes is now supported. Out of range axes\nas described above are now forbidden and raise an `AxisError`.\n\nView of `a` with the number of dimensions increased.\n\nSee also\n\nThe inverse operation, removing singleton dimensions\n\nInsert, remove, and combine dimensions, and resize existing ones\n\nThe following is equivalent to `x[np.newaxis, :]` or `x[np.newaxis]`:\n\nThe following is equivalent to `x[:, np.newaxis]`:\n\n`axis` may also be a tuple:\n\nNote that some examples may use `None` instead of `np.newaxis`. These are the\nsame objects:\n\n"}, {"name": "numpy.expm1()", "path": "reference/generated/numpy.expm1", "type": "numpy.expm1", "text": "\nCalculate `exp(x) - 1` for all elements in the array.\n\nInput values.\n\nA location into which the result is stored. If provided, it must have a shape\nthat the inputs broadcast to. If not provided or None, a freshly-allocated\narray is returned. A tuple (possible only as a keyword argument) must have\nlength equal to the number of outputs.\n\nThis condition is broadcast over the input. At locations where the condition\nis True, the `out` array will be set to the ufunc result. Elsewhere, the `out`\narray will retain its original value. Note that if an uninitialized `out`\narray is created via the default `out=None`, locations within it where the\ncondition is False will remain uninitialized.\n\nFor other keyword-only arguments, see the ufunc docs.\n\nElement-wise exponential minus one: `out = exp(x) - 1`. This is a scalar if\n`x` is a scalar.\n\nSee also\n\n`log(1 + x)`, the inverse of expm1.\n\nThis function provides greater precision than `exp(x) - 1` for small values of\n`x`.\n\nThe true value of `exp(1e-10) - 1` is `1.00000000005e-10` to about 32\nsignificant digits. This example shows the superiority of expm1 in this case.\n\n"}, {"name": "numpy.extract()", "path": "reference/generated/numpy.extract", "type": "numpy.extract", "text": "\nReturn the elements of an array that satisfy some condition.\n\nThis is equivalent to `np.compress(ravel(condition), ravel(arr))`. If\n`condition` is boolean `np.extract` is equivalent to `arr[condition]`.\n\nNote that `place` does the exact opposite of `extract`.\n\nAn array whose nonzero or True entries indicate the elements of `arr` to\nextract.\n\nInput array of the same size as `condition`.\n\nRank 1 array of values from `arr` where `condition` is True.\n\nSee also\n\nIf `condition` is boolean:\n\n"}, {"name": "numpy.eye()", "path": "reference/generated/numpy.eye", "type": "numpy.eye", "text": "\nReturn a 2-D array with ones on the diagonal and zeros elsewhere.\n\nNumber of rows in the output.\n\nNumber of columns in the output. If None, defaults to `N`.\n\nIndex of the diagonal: 0 (the default) refers to the main diagonal, a positive\nvalue refers to an upper diagonal, and a negative value to a lower diagonal.\n\nData-type of the returned array.\n\nWhether the output should be stored in row-major (C-style) or column-major\n(Fortran-style) order in memory.\n\nNew in version 1.14.0.\n\nReference object to allow the creation of arrays which are not NumPy arrays.\nIf an array-like passed in as `like` supports the `__array_function__`\nprotocol, the result will be defined by it. In this case, it ensures the\ncreation of an array object compatible with that passed in via this argument.\n\nNew in version 1.20.0.\n\nAn array where all elements are equal to zero, except for the `k`-th diagonal,\nwhose values are equal to one.\n\nSee also\n\n(almost) equivalent function\n\ndiagonal 2-D array from a 1-D array specified by the user.\n\n"}, {"name": "numpy.f2py.get_include()", "path": "f2py/usage#numpy.f2py.get_include", "type": "Using F2PY", "text": "\nReturn the directory that contains the fortranobject.c and .h files.\n\nNote\n\nThis function is not needed when building an extension with `numpy.distutils`\ndirectly from `.f` and/or `.pyf` files in one go.\n\nPython extension modules built with f2py-generated code need to use\n`fortranobject.c` as a source file, and include the `fortranobject.h` header.\nThis function can be used to obtain the directory containing both of these\nfiles.\n\nAbsolute path to the directory containing `fortranobject.c` and\n`fortranobject.h`.\n\nSee also\n\nfunction that returns the numpy include directory\n\nNew in version 1.22.0.\n\nUnless the build system you are using has specific support for f2py, building\na Python extension using a `.pyf` signature file is a two-step process. For a\nmodule `mymod`:\n\nStep 2: build your Python extension module. This requires the following source\nfiles:\n\n"}, {"name": "numpy.f2py.run_main()", "path": "f2py/usage#numpy.f2py.run_main", "type": "Using F2PY", "text": "\nEquivalent to running:\n\nwhere `<args>=string.join(<list>,' ')`, but in Python. Unless `-h` is used,\nthis function returns a dictionary containing information on generated modules\nand their dependencies on source files. For example, the command `f2py -m\nscalar scalar.f` can be executed from Python as follows\n\nYou cannot build extension modules with this function, that is, using `-c` is\nnot allowed. Use `compile` command instead\n\n"}, {"name": "numpy.fabs()", "path": "reference/generated/numpy.fabs", "type": "numpy.fabs", "text": "\nCompute the absolute values element-wise.\n\nThis function returns the absolute values (positive magnitude) of the data in\n`x`. Complex values are not handled, use `absolute` to find the absolute\nvalues of complex data.\n\nThe array of numbers for which the absolute values are required. If `x` is a\nscalar, the result `y` will also be a scalar.\n\nA location into which the result is stored. If provided, it must have a shape\nthat the inputs broadcast to. If not provided or None, a freshly-allocated\narray is returned. A tuple (possible only as a keyword argument) must have\nlength equal to the number of outputs.\n\nThis condition is broadcast over the input. At locations where the condition\nis True, the `out` array will be set to the ufunc result. Elsewhere, the `out`\narray will retain its original value. Note that if an uninitialized `out`\narray is created via the default `out=None`, locations within it where the\ncondition is False will remain uninitialized.\n\nFor other keyword-only arguments, see the ufunc docs.\n\nThe absolute values of `x`, the returned values are always floats. This is a\nscalar if `x` is a scalar.\n\nSee also\n\nAbsolute values including `complex` types.\n\n"}, {"name": "numpy.fill_diagonal()", "path": "reference/generated/numpy.fill_diagonal", "type": "numpy.fill_diagonal", "text": "\nFill the main diagonal of the given array of any dimensionality.\n\nFor an array `a` with `a.ndim >= 2`, the diagonal is the list of locations\nwith indices `a[i, ..., i]` all identical. This function modifies the input\narray in-place, it does not return a value.\n\nArray whose diagonal is to be filled, it gets modified in-place.\n\nValue(s) to write on the diagonal. If `val` is scalar, the value is written\nalong the diagonal. If array-like, the flattened `val` is written along the\ndiagonal, repeating if necessary to fill all diagonal entries.\n\nFor tall matrices in NumPy version up to 1.6.2, the diagonal \u201cwrapped\u201d after N\ncolumns. You can have this behavior with this option. This affects only tall\nmatrices.\n\nSee also\n\nNew in version 1.4.0.\n\nThis functionality can be obtained via `diag_indices`, but internally this\nversion uses a much faster implementation that never constructs the indices\nand uses simple slicing.\n\nThe same function can operate on a 4-D array:\n\nWe only show a few blocks for clarity:\n\nThe wrap option affects only tall matrices:\n\nThe anti-diagonal can be filled by reversing the order of elements using\neither `numpy.flipud` or `numpy.fliplr`.\n\nNote that the order in which the diagonal is filled varies depending on the\nflip function.\n\n"}, {"name": "numpy.find_common_type()", "path": "reference/generated/numpy.find_common_type", "type": "numpy.find_common_type", "text": "\nDetermine common type following standard coercion rules.\n\nA list of dtypes or dtype convertible objects representing arrays.\n\nA list of dtypes or dtype convertible objects representing scalars.\n\nThe common data type, which is the maximum of `array_types` ignoring\n`scalar_types`, unless the maximum of `scalar_types` is of a different kind\n(`dtype.kind`). If the kind is not understood, then None is returned.\n\nSee also\n\nThe standard casting rules ensure that a scalar cannot up-cast an array unless\nthe scalar is of a fundamentally different kind of data (i.e. under a\ndifferent hierarchy in the data type hierarchy) then the array:\n\nComplex is of a different type, so it up-casts the float in the `array_types`\nargument:\n\nType specifier strings are convertible to dtypes and can therefore be used\ninstead of dtypes:\n\n"}, {"name": "numpy.finfo()", "path": "reference/generated/numpy.finfo", "type": "numpy.finfo", "text": "\nMachine limits for floating point types.\n\nKind of floating point data-type about which to get information.\n\nSee also\n\nThe implementation of the tests that produce this information.\n\nThe equivalent for integer data types.\n\nThe distance between a value and the nearest adjacent number\n\nThe next floating point value after x1 towards x2\n\nFor developers of NumPy: do not instantiate this at the module level. The\ninitial calculation of these parameters is expensive and negatively impacts\nimport times. These objects are cached, so calling `finfo()` repeatedly inside\nyour functions is not a problem.\n\nNote that `smallest_normal` is not actually the smallest positive\nrepresentable value in a NumPy floating point type. As in the IEEE-754\nstandard [1], NumPy floating point types make use of subnormal numbers to fill\nthe gap between 0 and `smallest_normal`. However, subnormal numbers may have\nsignificantly reduced precision [2].\n\nIEEE Standard for Floating-Point Arithmetic, IEEE Std 754-2008, pp.1-70, 2008,\nhttp://www.doi.org/10.1109/IEEESTD.2008.4610935\n\nWikipedia, \u201cDenormal Numbers\u201d, https://en.wikipedia.org/wiki/Denormal_number\n\nThe number of bits occupied by the type.\n\nThe difference between 1.0 and the next smallest representable float larger\nthan 1.0. For example, for 64-bit binary floats in the IEEE-754 standard, `eps\n= 2**-52`, approximately 2.22e-16.\n\nThe difference between 1.0 and the next smallest representable float less than\n1.0. For example, for 64-bit binary floats in the IEEE-754 standard, `epsneg =\n2**-53`, approximately 1.11e-16.\n\nThe number of bits in the exponent portion of the floating point\nrepresentation.\n\nThe object which calculated these parameters and holds more detailed\ninformation.\n\nThe exponent that yields `eps`.\n\nThe largest representable number.\n\nThe smallest positive power of the base (2) that causes overflow.\n\nThe smallest representable number, typically `-max`.\n\nThe most negative power of the base (2) consistent with there being no leading\n0\u2019s in the mantissa.\n\nThe exponent that yields `epsneg`.\n\nThe number of bits in the exponent including its sign and bias.\n\nThe number of bits in the mantissa.\n\nThe approximate number of decimal digits to which this kind of float is\nprecise.\n\nThe approximate decimal resolution of this type, i.e., `10**-precision`.\n\nReturn the value for tiny, alias of smallest_normal.\n\nReturn the value for the smallest normal.\n\nThe smallest positive floating point number with 0 as leading bit in the\nmantissa following IEEE-754.\n\n"}, {"name": "numpy.fix()", "path": "reference/generated/numpy.fix", "type": "numpy.fix", "text": "\nRound to nearest integer towards zero.\n\nRound an array of floats element-wise to nearest integer towards zero. The\nrounded values are returned as floats.\n\nAn array of floats to be rounded\n\nA location into which the result is stored. If provided, it must have a shape\nthat the input broadcasts to. If not provided or None, a freshly-allocated\narray is returned.\n\nA float array with the same dimensions as the input. If second argument is not\nsupplied then a float array is returned with the rounded values.\n\nIf a second argument is supplied the result is stored there. The return value\n`out` is then a reference to that array.\n\nSee also\n\nRound to given number of decimals\n\n"}, {"name": "numpy.flatiter", "path": "reference/generated/numpy.flatiter", "type": "numpy.flatiter", "text": "\nFlat iterator object to iterate over arrays.\n\nA `flatiter` iterator is returned by `x.flat` for any array `x`. It allows\niterating over the array as if it were a 1-D array, either in a for-loop or by\ncalling its `next` method.\n\nIteration is done in row-major, C-style order (the last index varying the\nfastest). The iterator can also be indexed using basic slicing or advanced\nindexing.\n\nSee also\n\nReturn a flat iterator over an array.\n\nReturns a flattened copy of an array.\n\nA `flatiter` iterator can not be constructed directly from Python code by\ncalling the `flatiter` constructor.\n\nA reference to the array that is iterated over.\n\nAn N-dimensional tuple of current coordinates.\n\nCurrent flat index into the array.\n\n`copy`()\n\nGet a copy of the iterator as a 1-D array.\n\n"}, {"name": "numpy.flatnonzero()", "path": "reference/generated/numpy.flatnonzero", "type": "numpy.flatnonzero", "text": "\nReturn indices that are non-zero in the flattened version of a.\n\nThis is equivalent to np.nonzero(np.ravel(a))[0].\n\nInput data.\n\nOutput array, containing the indices of the elements of `a.ravel()` that are\nnon-zero.\n\nSee also\n\nReturn the indices of the non-zero elements of the input array.\n\nReturn a 1-D array containing the elements of the input array.\n\nUse the indices of the non-zero elements as an index array to extract these\nelements:\n\n"}, {"name": "numpy.flexible", "path": "reference/arrays.scalars#numpy.flexible", "type": "Scalars", "text": "\nAbstract base class of all scalar types without predefined length. The actual\nsize of these types depends on the specific `np.dtype` instantiation.\n\n"}, {"name": "numpy.flip()", "path": "reference/generated/numpy.flip", "type": "numpy.flip", "text": "\nReverse the order of elements in an array along the given axis.\n\nThe shape of the array is preserved, but the elements are reordered.\n\nNew in version 1.12.0.\n\nInput array.\n\nAxis or axes along which to flip over. The default, axis=None, will flip over\nall of the axes of the input array. If axis is negative it counts from the\nlast to the first axis.\n\nIf axis is a tuple of ints, flipping is performed on all of the axes specified\nin the tuple.\n\nChanged in version 1.15.0: None and tuples of axes are supported\n\nA view of `m` with the entries of axis reversed. Since a view is returned,\nthis operation is done in constant time.\n\nSee also\n\nFlip an array vertically (axis=0).\n\nFlip an array horizontally (axis=1).\n\nflip(m, 0) is equivalent to flipud(m).\n\nflip(m, 1) is equivalent to fliplr(m).\n\nflip(m, n) corresponds to `m[...,::-1,...]` with `::-1` at position n.\n\nflip(m) corresponds to `m[::-1,::-1,...,::-1]` with `::-1` at all positions.\n\nflip(m, (0, 1)) corresponds to `m[::-1,::-1,...]` with `::-1` at position 0\nand position 1.\n\n"}, {"name": "numpy.fliplr()", "path": "reference/generated/numpy.fliplr", "type": "numpy.fliplr", "text": "\nReverse the order of elements along axis 1 (left/right).\n\nFor a 2-D array, this flips the entries in each row in the left/right\ndirection. Columns are preserved, but appear in a different order than before.\n\nInput array, must be at least 2-D.\n\nA view of `m` with the columns reversed. Since a view is returned, this\noperation is \\\\(\\mathcal O(1)\\\\).\n\nSee also\n\nFlip array in the up/down direction.\n\nFlip array in one or more dimensions.\n\nRotate array counterclockwise.\n\nEquivalent to `m[:,::-1]` or `np.flip(m, axis=1)`. Requires the array to be at\nleast 2-D.\n\n"}, {"name": "numpy.flipud()", "path": "reference/generated/numpy.flipud", "type": "numpy.flipud", "text": "\nReverse the order of elements along axis 0 (up/down).\n\nFor a 2-D array, this flips the entries in each column in the up/down\ndirection. Rows are preserved, but appear in a different order than before.\n\nInput array.\n\nA view of `m` with the rows reversed. Since a view is returned, this operation\nis \\\\(\\mathcal O(1)\\\\).\n\nSee also\n\nFlip array in the left/right direction.\n\nFlip array in one or more dimensions.\n\nRotate array counterclockwise.\n\nEquivalent to `m[::-1, ...]` or `np.flip(m, axis=0)`. Requires the array to be\nat least 1-D.\n\n"}, {"name": "numpy.float128", "path": "reference/arrays.scalars#numpy.float128", "type": "Scalars", "text": "\nAlias for `numpy.longdouble`, named after its size in bits. The existence of\nthese aliases depends on the platform.\n\n"}, {"name": "numpy.float16", "path": "reference/arrays.scalars#numpy.float16", "type": "Scalars", "text": "\nalias of `numpy.half`\n\n"}, {"name": "numpy.float32", "path": "reference/arrays.scalars#numpy.float32", "type": "Scalars", "text": "\nalias of `numpy.single`\n\n"}, {"name": "numpy.float64", "path": "reference/arrays.scalars#numpy.float64", "type": "Scalars", "text": "\nalias of `numpy.double`\n\n"}, {"name": "numpy.float96", "path": "reference/arrays.scalars#numpy.float96", "type": "Scalars", "text": "\nAlias for `numpy.longdouble`, named after its size in bits. The existence of\nthese aliases depends on the platform.\n\n"}, {"name": "numpy.float_power()", "path": "reference/generated/numpy.float_power", "type": "numpy.float_power", "text": "\nFirst array elements raised to powers from second array, element-wise.\n\nRaise each base in `x1` to the positionally-corresponding power in `x2`. `x1`\nand `x2` must be broadcastable to the same shape. This differs from the power\nfunction in that integers, float16, and float32 are promoted to floats with a\nminimum precision of float64 so that the result is always inexact. The intent\nis that the function will return a usable result for negative powers and\nseldom overflow for positive powers.\n\nNegative values raised to a non-integral value will return `nan`. To get\ncomplex results, cast the input to complex, or specify the `dtype` to be\n`complex` (see the example below).\n\nNew in version 1.12.0.\n\nThe bases.\n\nThe exponents. If `x1.shape != x2.shape`, they must be broadcastable to a\ncommon shape (which becomes the shape of the output).\n\nA location into which the result is stored. If provided, it must have a shape\nthat the inputs broadcast to. If not provided or None, a freshly-allocated\narray is returned. A tuple (possible only as a keyword argument) must have\nlength equal to the number of outputs.\n\nThis condition is broadcast over the input. At locations where the condition\nis True, the `out` array will be set to the ufunc result. Elsewhere, the `out`\narray will retain its original value. Note that if an uninitialized `out`\narray is created via the default `out=None`, locations within it where the\ncondition is False will remain uninitialized.\n\nFor other keyword-only arguments, see the ufunc docs.\n\nThe bases in `x1` raised to the exponents in `x2`. This is a scalar if both\n`x1` and `x2` are scalars.\n\nSee also\n\npower function that preserves type\n\nCube each element in a list.\n\nRaise the bases to different exponents.\n\nThe effect of broadcasting.\n\nNegative values raised to a non-integral value will result in `nan` (and a\nwarning will be generated).\n\nTo get complex results, give the argument `dtype=complex`.\n\n"}, {"name": "numpy.floor()", "path": "reference/generated/numpy.floor", "type": "numpy.floor", "text": "\nReturn the floor of the input, element-wise.\n\nThe floor of the scalar `x` is the largest integer `i`, such that `i <= x`. It\nis often denoted as \\\\(\\lfloor x \\rfloor\\\\).\n\nInput data.\n\nA location into which the result is stored. If provided, it must have a shape\nthat the inputs broadcast to. If not provided or None, a freshly-allocated\narray is returned. A tuple (possible only as a keyword argument) must have\nlength equal to the number of outputs.\n\nThis condition is broadcast over the input. At locations where the condition\nis True, the `out` array will be set to the ufunc result. Elsewhere, the `out`\narray will retain its original value. Note that if an uninitialized `out`\narray is created via the default `out=None`, locations within it where the\ncondition is False will remain uninitialized.\n\nFor other keyword-only arguments, see the ufunc docs.\n\nThe floor of each element in `x`. This is a scalar if `x` is a scalar.\n\nSee also\n\nSome spreadsheet programs calculate the \u201cfloor-towards-zero\u201d, where\n`floor(-2.5) == -2`. NumPy instead uses the definition of `floor` where\n`floor(-2.5) == -3`. The \u201cfloor-towards-zero\u201d function is called `fix` in\nNumPy.\n\n"}, {"name": "numpy.floor_divide()", "path": "reference/generated/numpy.floor_divide", "type": "numpy.floor_divide", "text": "\nReturn the largest integer smaller or equal to the division of the inputs. It\nis equivalent to the Python `//` operator and pairs with the Python `%`\n(`remainder`), function so that `a = a % b + b * (a // b)` up to roundoff.\n\nNumerator.\n\nDenominator. If `x1.shape != x2.shape`, they must be broadcastable to a common\nshape (which becomes the shape of the output).\n\nA location into which the result is stored. If provided, it must have a shape\nthat the inputs broadcast to. If not provided or None, a freshly-allocated\narray is returned. A tuple (possible only as a keyword argument) must have\nlength equal to the number of outputs.\n\nThis condition is broadcast over the input. At locations where the condition\nis True, the `out` array will be set to the ufunc result. Elsewhere, the `out`\narray will retain its original value. Note that if an uninitialized `out`\narray is created via the default `out=None`, locations within it where the\ncondition is False will remain uninitialized.\n\nFor other keyword-only arguments, see the ufunc docs.\n\ny = floor(`x1`/`x2`) This is a scalar if both `x1` and `x2` are scalars.\n\nSee also\n\nRemainder complementary to floor_divide.\n\nSimultaneous floor division and remainder.\n\nStandard division.\n\nRound a number to the nearest integer toward minus infinity.\n\nRound a number to the nearest integer toward infinity.\n\nThe `//` operator can be used as a shorthand for `np.floor_divide` on\nndarrays.\n\n"}, {"name": "numpy.fmax()", "path": "reference/generated/numpy.fmax", "type": "numpy.fmax", "text": "\nElement-wise maximum of array elements.\n\nCompare two arrays and returns a new array containing the element-wise maxima.\nIf one of the elements being compared is a NaN, then the non-nan element is\nreturned. If both elements are NaNs then the first is returned. The latter\ndistinction is important for complex NaNs, which are defined as at least one\nof the real or imaginary parts being a NaN. The net effect is that NaNs are\nignored when possible.\n\nThe arrays holding the elements to be compared. If `x1.shape != x2.shape`,\nthey must be broadcastable to a common shape (which becomes the shape of the\noutput).\n\nA location into which the result is stored. If provided, it must have a shape\nthat the inputs broadcast to. If not provided or None, a freshly-allocated\narray is returned. A tuple (possible only as a keyword argument) must have\nlength equal to the number of outputs.\n\nThis condition is broadcast over the input. At locations where the condition\nis True, the `out` array will be set to the ufunc result. Elsewhere, the `out`\narray will retain its original value. Note that if an uninitialized `out`\narray is created via the default `out=None`, locations within it where the\ncondition is False will remain uninitialized.\n\nFor other keyword-only arguments, see the ufunc docs.\n\nThe maximum of `x1` and `x2`, element-wise. This is a scalar if both `x1` and\n`x2` are scalars.\n\nSee also\n\nElement-wise minimum of two arrays, ignores NaNs.\n\nElement-wise maximum of two arrays, propagates NaNs.\n\nThe maximum value of an array along a given axis, propagates NaNs.\n\nThe maximum value of an array along a given axis, ignores NaNs.\n\nNew in version 1.3.0.\n\nThe fmax is equivalent to `np.where(x1 >= x2, x1, x2)` when neither x1 nor x2\nare NaNs, but it is faster and does proper broadcasting.\n\n"}, {"name": "numpy.fmin()", "path": "reference/generated/numpy.fmin", "type": "numpy.fmin", "text": "\nElement-wise minimum of array elements.\n\nCompare two arrays and returns a new array containing the element-wise minima.\nIf one of the elements being compared is a NaN, then the non-nan element is\nreturned. If both elements are NaNs then the first is returned. The latter\ndistinction is important for complex NaNs, which are defined as at least one\nof the real or imaginary parts being a NaN. The net effect is that NaNs are\nignored when possible.\n\nThe arrays holding the elements to be compared. If `x1.shape != x2.shape`,\nthey must be broadcastable to a common shape (which becomes the shape of the\noutput).\n\nA location into which the result is stored. If provided, it must have a shape\nthat the inputs broadcast to. If not provided or None, a freshly-allocated\narray is returned. A tuple (possible only as a keyword argument) must have\nlength equal to the number of outputs.\n\nThis condition is broadcast over the input. At locations where the condition\nis True, the `out` array will be set to the ufunc result. Elsewhere, the `out`\narray will retain its original value. Note that if an uninitialized `out`\narray is created via the default `out=None`, locations within it where the\ncondition is False will remain uninitialized.\n\nFor other keyword-only arguments, see the ufunc docs.\n\nThe minimum of `x1` and `x2`, element-wise. This is a scalar if both `x1` and\n`x2` are scalars.\n\nSee also\n\nElement-wise maximum of two arrays, ignores NaNs.\n\nElement-wise minimum of two arrays, propagates NaNs.\n\nThe minimum value of an array along a given axis, propagates NaNs.\n\nThe minimum value of an array along a given axis, ignores NaNs.\n\nNew in version 1.3.0.\n\nThe fmin is equivalent to `np.where(x1 <= x2, x1, x2)` when neither x1 nor x2\nare NaNs, but it is faster and does proper broadcasting.\n\n"}, {"name": "numpy.fmod()", "path": "reference/generated/numpy.fmod", "type": "numpy.fmod", "text": "\nReturns the element-wise remainder of division.\n\nThis is the NumPy implementation of the C library function fmod, the remainder\nhas the same sign as the dividend `x1`. It is equivalent to the Matlab(TM)\n`rem` function and should not be confused with the Python modulus operator `x1\n% x2`.\n\nDividend.\n\nDivisor. If `x1.shape != x2.shape`, they must be broadcastable to a common\nshape (which becomes the shape of the output).\n\nA location into which the result is stored. If provided, it must have a shape\nthat the inputs broadcast to. If not provided or None, a freshly-allocated\narray is returned. A tuple (possible only as a keyword argument) must have\nlength equal to the number of outputs.\n\nThis condition is broadcast over the input. At locations where the condition\nis True, the `out` array will be set to the ufunc result. Elsewhere, the `out`\narray will retain its original value. Note that if an uninitialized `out`\narray is created via the default `out=None`, locations within it where the\ncondition is False will remain uninitialized.\n\nFor other keyword-only arguments, see the ufunc docs.\n\nThe remainder of the division of `x1` by `x2`. This is a scalar if both `x1`\nand `x2` are scalars.\n\nSee also\n\nEquivalent to the Python `%` operator.\n\nThe result of the modulo operation for negative dividend and divisors is bound\nby conventions. For `fmod`, the sign of result is the sign of the dividend,\nwhile for `remainder` the sign of the result is the sign of the divisor. The\n`fmod` function is equivalent to the Matlab(TM) `rem` function.\n\n"}, {"name": "numpy.format_float_positional()", "path": "reference/generated/numpy.format_float_positional", "type": "numpy.format_float_positional", "text": "\nFormat a floating-point scalar as a decimal string in positional notation.\n\nProvides control over rounding, trimming and padding. Uses and assumes IEEE\nunbiased rounding. Uses the \u201cDragon4\u201d algorithm.\n\nValue to format.\n\nMaximum number of digits to print. May be None if `unique` is `True`, but must\nbe an integer if unique is `False`.\n\nIf `True`, use a digit-generation strategy which gives the shortest\nrepresentation which uniquely identifies the floating-point number from other\nvalues of the same type, by judicious rounding. If `precision` is given fewer\ndigits than necessary can be printed, or if `min_digits` is given more can be\nprinted, in which cases the last digit is rounded with unbiased rounding. If\n`False`, digits are generated as if printing an infinite-precision value and\nstopping after `precision` digits, rounding the remaining value with unbiased\nrounding\n\nIf `True`, the cutoffs of `precision` and `min_digits` refer to the total\nnumber of digits after the decimal point, including leading zeros. If `False`,\n`precision` and `min_digits` refer to the total number of significant digits,\nbefore or after the decimal point, ignoring leading zeros.\n\nControls post-processing trimming of trailing digits, as follows:\n\nWhether to show the sign for positive values.\n\nPad the left side of the string with whitespace until at least that many\ncharacters are to the left of the decimal point.\n\nPad the right side of the string with whitespace until at least that many\ncharacters are to the right of the decimal point.\n\nMinimum number of digits to print. Only has an effect if `unique=True` in\nwhich case additional digits past those necessary to uniquely identify the\nvalue may be printed, rounding the last additional digit.\n\n\u2013 versionadded:: 1.21.0\n\nThe string representation of the floating point value\n\nSee also\n\n"}, {"name": "numpy.format_float_scientific()", "path": "reference/generated/numpy.format_float_scientific", "type": "numpy.format_float_scientific", "text": "\nFormat a floating-point scalar as a decimal string in scientific notation.\n\nProvides control over rounding, trimming and padding. Uses and assumes IEEE\nunbiased rounding. Uses the \u201cDragon4\u201d algorithm.\n\nValue to format.\n\nMaximum number of digits to print. May be None if `unique` is `True`, but must\nbe an integer if unique is `False`.\n\nIf `True`, use a digit-generation strategy which gives the shortest\nrepresentation which uniquely identifies the floating-point number from other\nvalues of the same type, by judicious rounding. If `precision` is given fewer\ndigits than necessary can be printed. If `min_digits` is given more can be\nprinted, in which cases the last digit is rounded with unbiased rounding. If\n`False`, digits are generated as if printing an infinite-precision value and\nstopping after `precision` digits, rounding the remaining value with unbiased\nrounding\n\nControls post-processing trimming of trailing digits, as follows:\n\nWhether to show the sign for positive values.\n\nPad the left side of the string with whitespace until at least that many\ncharacters are to the left of the decimal point.\n\nPad the exponent with zeros until it contains at least this many digits. If\nomitted, the exponent will be at least 2 digits.\n\nMinimum number of digits to print. This only has an effect for `unique=True`.\nIn that case more digits than necessary to uniquely identify the value may be\nprinted and rounded unbiased.\n\n\u2013 versionadded:: 1.21.0\n\nThe string representation of the floating point value\n\nSee also\n\n"}, {"name": "numpy.format_parser()", "path": "reference/generated/numpy.format_parser", "type": "numpy.format_parser", "text": "\nClass to convert formats, names, titles description to a dtype.\n\nAfter constructing the format_parser object, the dtype attribute is the\nconverted data-type: `dtype = format_parser(formats, names, titles).dtype`\n\nThe format description, either specified as a string with comma-separated\nformat descriptions in the form `'f8, i4, a5'`, or a list of format\ndescription strings in the form `['f8', 'i4', 'a5']`.\n\nThe field names, either specified as a comma-separated string in the form\n`'col1, col2, col3'`, or as a list or tuple of strings in the form `['col1',\n'col2', 'col3']`. An empty list can be used, in that case default field names\n(\u2018f0\u2019, \u2018f1\u2019, \u2026) are used.\n\nSequence of title strings. An empty list can be used to leave titles out.\n\nIf True, align the fields by padding as the C-compiler would. Default is\nFalse.\n\nIf specified, all the fields will be changed to the provided byte-order.\nOtherwise, the default byte-order is used. For all available string\nspecifiers, see `dtype.newbyteorder`.\n\nSee also\n\n`names` and/or `titles` can be empty lists. If `titles` is an empty list,\ntitles will simply not appear. If `names` is empty, default field names will\nbe used.\n\nThe converted data-type.\n\n"}, {"name": "numpy.frexp()", "path": "reference/generated/numpy.frexp", "type": "numpy.frexp", "text": "\nDecompose the elements of x into mantissa and twos exponent.\n\nReturns (`mantissa`, `exponent`), where `x = mantissa * 2**exponent``. The\nmantissa lies in the open interval(-1, 1), while the twos exponent is a signed\ninteger.\n\nArray of numbers to be decomposed.\n\nOutput array for the mantissa. Must have the same shape as `x`.\n\nOutput array for the exponent. Must have the same shape as `x`.\n\nA location into which the result is stored. If provided, it must have a shape\nthat the inputs broadcast to. If not provided or None, a freshly-allocated\narray is returned. A tuple (possible only as a keyword argument) must have\nlength equal to the number of outputs.\n\nThis condition is broadcast over the input. At locations where the condition\nis True, the `out` array will be set to the ufunc result. Elsewhere, the `out`\narray will retain its original value. Note that if an uninitialized `out`\narray is created via the default `out=None`, locations within it where the\ncondition is False will remain uninitialized.\n\nFor other keyword-only arguments, see the ufunc docs.\n\nFloating values between -1 and 1. This is a scalar if `x` is a scalar.\n\nInteger exponents of 2. This is a scalar if `x` is a scalar.\n\nSee also\n\nCompute `y = x1 * 2**x2`, the inverse of `frexp`.\n\nComplex dtypes are not supported, they will raise a TypeError.\n\n"}, {"name": "numpy.frombuffer()", "path": "reference/generated/numpy.frombuffer", "type": "numpy.frombuffer", "text": "\nInterpret a buffer as a 1-dimensional array.\n\nAn object that exposes the buffer interface.\n\nData-type of the returned array; default: float.\n\nNumber of items to read. `-1` means all data in the buffer.\n\nStart reading the buffer from this offset (in bytes); default: 0.\n\nReference object to allow the creation of arrays which are not NumPy arrays.\nIf an array-like passed in as `like` supports the `__array_function__`\nprotocol, the result will be defined by it. In this case, it ensures the\ncreation of an array object compatible with that passed in via this argument.\n\nNew in version 1.20.0.\n\nIf the buffer has data that is not in machine byte-order, this should be\nspecified as part of the data-type, e.g.:\n\nThe data of the resulting array will not be byteswapped, but will be\ninterpreted correctly.\n\n"}, {"name": "numpy.fromfile()", "path": "reference/generated/numpy.fromfile", "type": "numpy.fromfile", "text": "\nConstruct an array from data in a text or binary file.\n\nA highly efficient way of reading binary data with a known data-type, as well\nas parsing simply formatted text files. Data written using the `tofile` method\ncan be read using this function.\n\nOpen file object or filename.\n\nChanged in version 1.17.0: `pathlib.Path` objects are now accepted.\n\nData type of the returned array. For binary files, it is used to determine the\nsize and byte-order of the items in the file. Most builtin numeric types are\nsupported and extension types may be supported.\n\nNew in version 1.18.0: Complex dtypes.\n\nNumber of items to read. `-1` means all items (i.e., the complete file).\n\nSeparator between items if file is a text file. Empty (\u201c\u201d) separator means the\nfile should be treated as binary. Spaces (\u201d \u201c) in the separator match zero or\nmore whitespace characters. A separator consisting only of spaces must match\nat least one whitespace.\n\nThe offset (in bytes) from the file\u2019s current position. Defaults to 0. Only\npermitted for binary files.\n\nNew in version 1.17.0.\n\nReference object to allow the creation of arrays which are not NumPy arrays.\nIf an array-like passed in as `like` supports the `__array_function__`\nprotocol, the result will be defined by it. In this case, it ensures the\ncreation of an array object compatible with that passed in via this argument.\n\nNew in version 1.20.0.\n\nSee also\n\nMore flexible way of loading data from a text file.\n\nDo not rely on the combination of `tofile` and `fromfile` for data storage, as\nthe binary files generated are not platform independent. In particular, no\nbyte-order or data-type information is saved. Data can be stored in the\nplatform independent `.npy` format using `save` and `load` instead.\n\nConstruct an ndarray:\n\nSave the raw data to disk:\n\nRead the raw data from disk:\n\nThe recommended way to store and load data:\n\n"}, {"name": "numpy.fromfunction()", "path": "reference/generated/numpy.fromfunction", "type": "numpy.fromfunction", "text": "\nConstruct an array by executing a function over each coordinate.\n\nThe resulting array therefore has a value `fn(x, y, z)` at coordinate `(x, y,\nz)`.\n\nThe function is called with N parameters, where N is the rank of `shape`. Each\nparameter represents the coordinates of the array varying along a specific\naxis. For example, if `shape` were `(2, 2)`, then the parameters would be\n`array([[0, 0], [1, 1]])` and `array([[0, 1], [0, 1]])`\n\nShape of the output array, which also determines the shape of the coordinate\narrays passed to `function`.\n\nData-type of the coordinate arrays passed to `function`. By default, `dtype`\nis float.\n\nReference object to allow the creation of arrays which are not NumPy arrays.\nIf an array-like passed in as `like` supports the `__array_function__`\nprotocol, the result will be defined by it. In this case, it ensures the\ncreation of an array object compatible with that passed in via this argument.\n\nNew in version 1.20.0.\n\nThe result of the call to `function` is passed back directly. Therefore the\nshape of `fromfunction` is completely determined by `function`. If `function`\nreturns a scalar value, the shape of `fromfunction` would not match the\n`shape` parameter.\n\nSee also\n\nKeywords other than `dtype` are passed to `function`.\n\n"}, {"name": "numpy.fromiter()", "path": "reference/generated/numpy.fromiter", "type": "numpy.fromiter", "text": "\nCreate a new 1-dimensional array from an iterable object.\n\nAn iterable object providing data for the array.\n\nThe data-type of the returned array.\n\nThe number of items to read from iterable. The default is -1, which means all\ndata is read.\n\nReference object to allow the creation of arrays which are not NumPy arrays.\nIf an array-like passed in as `like` supports the `__array_function__`\nprotocol, the result will be defined by it. In this case, it ensures the\ncreation of an array object compatible with that passed in via this argument.\n\nNew in version 1.20.0.\n\nThe output array.\n\nSpecify `count` to improve performance. It allows `fromiter` to pre-allocate\nthe output array, instead of resizing it on demand.\n\n"}, {"name": "numpy.frompyfunc()", "path": "reference/generated/numpy.frompyfunc", "type": "numpy.frompyfunc", "text": "\nTakes an arbitrary Python function and returns a NumPy ufunc.\n\nCan be used, for example, to add broadcasting to a built-in Python function\n(see Examples section).\n\nAn arbitrary Python function.\n\nThe number of input arguments.\n\nThe number of objects returned by `func`.\n\nThe value to use for the `identity` attribute of the resulting object. If\nspecified, this is equivalent to setting the underlying C `identity` field to\n`PyUFunc_IdentityValue`. If omitted, the identity is set to `PyUFunc_None`.\nNote that this is _not_ equivalent to setting the identity to `None`, which\nimplies the operation is reorderable.\n\nReturns a NumPy universal function (`ufunc`) object.\n\nSee also\n\nEvaluates pyfunc over input arrays using broadcasting rules of numpy.\n\nThe returned ufunc always returns PyObject arrays.\n\nUse frompyfunc to add broadcasting to the Python function `oct`:\n\n"}, {"name": "numpy.fromregex()", "path": "reference/generated/numpy.fromregex", "type": "numpy.fromregex", "text": "\nConstruct an array from a text file, using regular expression parsing.\n\nThe returned array is always a structured array, and is constructed from all\nmatches of the regular expression in the file. Groups in the regular\nexpression are converted to fields of the structured array.\n\nFilename or file object to read.\n\nChanged in version 1.22.0: Now accepts `os.PathLike` implementations.\n\nRegular expression used to parse the file. Groups in the regular expression\ncorrespond to fields in the dtype.\n\nDtype for the structured array; must be a structured datatype.\n\nEncoding used to decode the inputfile. Does not apply to input streams.\n\nNew in version 1.14.0.\n\nThe output array, containing the part of the content of `file` that was\nmatched by `regexp`. `output` is always a structured array.\n\nWhen `dtype` is not a valid dtype for a structured array.\n\nSee also\n\nDtypes for structured arrays can be specified in several forms, but all forms\nspecify at least the data type and field name. For details see `basics.rec`.\n\n"}, {"name": "numpy.fromstring()", "path": "reference/generated/numpy.fromstring", "type": "numpy.fromstring", "text": "\nA new 1-D array initialized from text data in a string.\n\nA string containing the data.\n\nThe data type of the array; default: float. For binary input data, the data\nmust be in exactly this format. Most builtin numeric types are supported and\nextension types may be supported.\n\nNew in version 1.18.0: Complex dtypes.\n\nRead this number of `dtype` elements from the data. If this is negative (the\ndefault), the count will be determined from the length of the data.\n\nThe string separating numbers in the data; extra whitespace between elements\nis also ignored.\n\nDeprecated since version 1.14: Passing `sep=''`, the default, is deprecated\nsince it will trigger the deprecated binary mode of this function. This mode\ninterprets `string` as binary bytes, rather than ASCII text with decimal\nnumbers, an operation which is better spelt `frombuffer(string, dtype,\ncount)`. If `string` contains unicode text, the binary mode of `fromstring`\nwill first encode it into bytes using either utf-8 (python 3) or the default\nencoding (python 2), neither of which produce sane results.\n\nReference object to allow the creation of arrays which are not NumPy arrays.\nIf an array-like passed in as `like` supports the `__array_function__`\nprotocol, the result will be defined by it. In this case, it ensures the\ncreation of an array object compatible with that passed in via this argument.\n\nNew in version 1.20.0.\n\nThe constructed array.\n\nIf the string is not the correct size to satisfy the requested `dtype` and\n`count`.\n\nSee also\n\n"}, {"name": "numpy.full()", "path": "reference/generated/numpy.full", "type": "numpy.full", "text": "\nReturn a new array of given shape and type, filled with `fill_value`.\n\nShape of the new array, e.g., `(2, 3)` or `2`.\n\nFill value.\n\n`np.array(fill_value).dtype`.\n\nWhether to store multidimensional data in C- or Fortran-contiguous (row- or\ncolumn-wise) order in memory.\n\nReference object to allow the creation of arrays which are not NumPy arrays.\nIf an array-like passed in as `like` supports the `__array_function__`\nprotocol, the result will be defined by it. In this case, it ensures the\ncreation of an array object compatible with that passed in via this argument.\n\nNew in version 1.20.0.\n\nArray of `fill_value` with the given shape, dtype, and order.\n\nSee also\n\nReturn a new array with shape of input filled with value.\n\nReturn a new uninitialized array.\n\nReturn a new array setting values to one.\n\nReturn a new array setting values to zero.\n\n"}, {"name": "numpy.full_like()", "path": "reference/generated/numpy.full_like", "type": "numpy.full_like", "text": "\nReturn a full array with the same shape and type as a given array.\n\nThe shape and data-type of `a` define these same attributes of the returned\narray.\n\nFill value.\n\nOverrides the data type of the result.\n\nOverrides the memory layout of the result. \u2018C\u2019 means C-order, \u2018F\u2019 means\nF-order, \u2018A\u2019 means \u2018F\u2019 if `a` is Fortran contiguous, \u2018C\u2019 otherwise. \u2018K\u2019 means\nmatch the layout of `a` as closely as possible.\n\nIf True, then the newly created array will use the sub-class type of `a`,\notherwise it will be a base-class array. Defaults to True.\n\nOverrides the shape of the result. If order=\u2019K\u2019 and the number of dimensions\nis unchanged, will try to keep order, otherwise, order=\u2019C\u2019 is implied.\n\nNew in version 1.17.0.\n\nArray of `fill_value` with the same shape and type as `a`.\n\nSee also\n\nReturn an empty array with shape and type of input.\n\nReturn an array of ones with shape and type of input.\n\nReturn an array of zeros with shape and type of input.\n\nReturn a new array of given shape filled with value.\n\n"}, {"name": "numpy.gcd()", "path": "reference/generated/numpy.gcd", "type": "numpy.gcd", "text": "\nReturns the greatest common divisor of `|x1|` and `|x2|`\n\nArrays of values. If `x1.shape != x2.shape`, they must be broadcastable to a\ncommon shape (which becomes the shape of the output).\n\nThe greatest common divisor of the absolute value of the inputs This is a\nscalar if both `x1` and `x2` are scalars.\n\nSee also\n\nThe lowest common multiple\n\n"}, {"name": "numpy.genfromtxt()", "path": "reference/generated/numpy.genfromtxt", "type": "numpy.genfromtxt", "text": "\nLoad data from a text file, with missing values handled as specified.\n\nEach line past the first `skip_header` lines is split at the `delimiter`\ncharacter, and characters following the `comments` character are discarded.\n\nFile, filename, list, or generator to read. If the filename extension is `.gz`\nor `.bz2`, the file is first decompressed. Note that generators must return\nbytes or strings. The strings in a list or produced by a generator are treated\nas lines.\n\nData type of the resulting array. If None, the dtypes will be determined by\nthe contents of each column, individually.\n\nThe character used to indicate the start of a comment. All the characters\noccurring on a line after a comment are discarded.\n\nThe string used to separate values. By default, any consecutive whitespaces\nact as delimiter. An integer or sequence of integers can also be provided as\nwidth(s) of each field.\n\n`skiprows` was removed in numpy 1.10. Please use `skip_header` instead.\n\nThe number of lines to skip at the beginning of the file.\n\nThe number of lines to skip at the end of the file.\n\nThe set of functions that convert the data of a column to a value. The\nconverters can also be used to provide a default value for missing data:\n`converters = {3: lambda s: float(s or 0)}`.\n\n`missing` was removed in numpy 1.10. Please use `missing_values` instead.\n\nThe set of strings corresponding to missing data.\n\nThe set of values to be used as default when the data are missing.\n\nWhich columns to read, with 0 being the first. For example, `usecols = (1, 4,\n5)` will extract the 2nd, 5th and 6th columns.\n\nIf `names` is True, the field names are read from the first line after the\nfirst `skip_header` lines. This line can optionally be preceded by a comment\ndelimiter. If `names` is a sequence or a single-string of comma-separated\nnames, the names will be used to define the field names in a structured dtype.\nIf `names` is None, the names of the dtype fields will be used, if any.\n\nA list of names to exclude. This list is appended to the default list\n[\u2018return\u2019,\u2019file\u2019,\u2019print\u2019]. Excluded names are appended with an underscore: for\nexample, `file` would become `file_`.\n\nA string combining invalid characters that must be deleted from the names.\n\nA format used to define default field names, such as \u201cf%i\u201d or \u201cf_%02i\u201d.\n\nWhether to automatically strip white spaces from the variables.\n\nCharacter(s) used in replacement of white spaces in the variable names. By\ndefault, use a \u2018_\u2019.\n\nIf True, field names are case sensitive. If False or \u2018upper\u2019, field names are\nconverted to upper case. If \u2018lower\u2019, field names are converted to lower case.\n\nIf True, the returned array is transposed, so that arguments may be unpacked\nusing `x, y, z = genfromtxt(...)`. When used with a structured data-type,\narrays are returned for each field. Default is False.\n\nIf True, return a masked array. If False, return a regular array.\n\nIf True, do not raise errors for invalid values.\n\nIf True, an exception is raised if an inconsistency is detected in the number\nof columns. If False, a warning is emitted and the offending lines are\nskipped.\n\nThe maximum number of rows to read. Must not be used with skip_footer at the\nsame time. If given, the value must be at least 1. Default is to read the\nentire file.\n\nNew in version 1.10.0.\n\nEncoding used to decode the inputfile. Does not apply when `fname` is a file\nobject. The special value \u2018bytes\u2019 enables backward compatibility workarounds\nthat ensure that you receive byte arrays when possible and passes latin1\nencoded strings to converters. Override this value to receive unicode arrays\nand pass strings as input to converters. If set to None the system default is\nused. The default value is \u2018bytes\u2019.\n\nNew in version 1.14.0.\n\nReference object to allow the creation of arrays which are not NumPy arrays.\nIf an array-like passed in as `like` supports the `__array_function__`\nprotocol, the result will be defined by it. In this case, it ensures the\ncreation of an array object compatible with that passed in via this argument.\n\nNew in version 1.20.0.\n\nData read from the text file. If `usemask` is True, this is a masked array.\n\nSee also\n\nequivalent function when no data is missing.\n\nNumPy User Guide, section I/O with NumPy.\n\nComma delimited file with mixed dtype\n\nUsing dtype = None\n\nSpecifying dtype and names\n\nAn example with fixed-width columns\n\nAn example to show comments\n\n"}, {"name": "numpy.geomspace()", "path": "reference/generated/numpy.geomspace", "type": "numpy.geomspace", "text": "\nReturn numbers spaced evenly on a log scale (a geometric progression).\n\nThis is similar to `logspace`, but with endpoints specified directly. Each\noutput sample is a constant multiple of the previous.\n\nChanged in version 1.16.0: Non-scalar `start` and `stop` are now supported.\n\nThe starting value of the sequence.\n\nThe final value of the sequence, unless `endpoint` is False. In that case,\n`num + 1` values are spaced over the interval in log-space, of which all but\nthe last (a sequence of length `num`) are returned.\n\nNumber of samples to generate. Default is 50.\n\nIf true, `stop` is the last sample. Otherwise, it is not included. Default is\nTrue.\n\nThe type of the output array. If `dtype` is not given, the data type is\ninferred from `start` and `stop`. The inferred dtype will never be an integer;\n`float` is chosen even if the arguments would produce an array of integers.\n\nThe axis in the result to store the samples. Relevant only if start or stop\nare array-like. By default (0), the samples will be along a new axis inserted\nat the beginning. Use -1 to get an axis at the end.\n\nNew in version 1.16.0.\n\n`num` samples, equally spaced on a log scale.\n\nSee also\n\nSimilar to geomspace, but with endpoints specified using log and base.\n\nSimilar to geomspace, but with arithmetic instead of geometric progression.\n\nSimilar to linspace, with the step size specified instead of the number of\nsamples.\n\nIf the inputs or dtype are complex, the output will follow a logarithmic\nspiral in the complex plane. (There are an infinite number of spirals passing\nthrough two points; the output will follow the shortest such path.)\n\nNote that the above may not produce exact integers:\n\nNegative, decreasing, and complex inputs are allowed:\n\nGraphical illustration of `endpoint` parameter:\n\n"}, {"name": "numpy.get_include()", "path": "reference/generated/numpy.get_include", "type": "numpy.get_include", "text": "\nReturn the directory that contains the NumPy *.h header files.\n\nExtension modules that need to compile against NumPy should use this function\nto locate the appropriate include directory.\n\nWhen using `distutils`, for example in `setup.py`.\n\n"}, {"name": "numpy.get_printoptions()", "path": "reference/generated/numpy.get_printoptions", "type": "numpy.get_printoptions", "text": "\nReturn the current print options.\n\nDictionary of current print options with keys\n\nFor a full description of these options, see `set_printoptions`.\n\nSee also\n\n"}, {"name": "numpy.getbufsize()", "path": "reference/generated/numpy.getbufsize", "type": "numpy.getbufsize", "text": "\nReturn the size of the buffer used in ufuncs.\n\nSize of ufunc buffer in bytes.\n\n"}, {"name": "numpy.geterr()", "path": "reference/generated/numpy.geterr", "type": "numpy.geterr", "text": "\nGet the current way of handling floating-point errors.\n\nA dictionary with keys \u201cdivide\u201d, \u201cover\u201d, \u201cunder\u201d, and \u201cinvalid\u201d, whose values\nare from the strings \u201cignore\u201d, \u201cprint\u201d, \u201clog\u201d, \u201cwarn\u201d, \u201craise\u201d, and \u201ccall\u201d.\nThe keys represent possible floating-point exceptions, and the values define\nhow these exceptions are handled.\n\nSee also\n\nFor complete documentation of the types of floating-point exceptions and\ntreatment options, see `seterr`.\n\n"}, {"name": "numpy.geterrcall()", "path": "reference/generated/numpy.geterrcall", "type": "numpy.geterrcall", "text": "\nReturn the current callback function used on floating-point errors.\n\nWhen the error handling for a floating-point error (one of \u201cdivide\u201d, \u201cover\u201d,\n\u201cunder\u201d, or \u201cinvalid\u201d) is set to \u2018call\u2019 or \u2018log\u2019, the function that is called\nor the log instance that is written to is returned by `geterrcall`. This\nfunction or log instance has been set with `seterrcall`.\n\nThe current error handler. If no handler was set through `seterrcall`, `None`\nis returned.\n\nSee also\n\nFor complete documentation of the types of floating-point exceptions and\ntreatment options, see `seterr`.\n\n"}, {"name": "numpy.geterrobj()", "path": "reference/generated/numpy.geterrobj", "type": "numpy.geterrobj", "text": "\nReturn the current object that defines floating-point error handling.\n\nThe error object contains all information that defines the error handling\nbehavior in NumPy. `geterrobj` is used internally by the other functions that\nget and set error handling behavior (`geterr`, `seterr`, `geterrcall`,\n`seterrcall`).\n\nThe error object, a list containing three elements: [internal numpy buffer\nsize, error mask, error callback function].\n\nThe error mask is a single integer that holds the treatment information on all\nfour floating point errors. The information for each error type is contained\nin three bits of the integer. If we print it in base 8, we can see what\ntreatment is set for \u201cinvalid\u201d, \u201cunder\u201d, \u201cover\u201d, and \u201cdivide\u201d (in that order).\nThe printed string can be interpreted with\n\nSee also\n\nFor complete documentation of the types of floating-point exceptions and\ntreatment options, see `seterr`.\n\n"}, {"name": "numpy.gradient()", "path": "reference/generated/numpy.gradient", "type": "numpy.gradient", "text": "\nReturn the gradient of an N-dimensional array.\n\nThe gradient is computed using second order accurate central differences in\nthe interior points and either first or second order accurate one-sides\n(forward or backwards) differences at the boundaries. The returned gradient\nhence has the same shape as the input array.\n\nAn N-dimensional array containing samples of a scalar function.\n\nSpacing between f values. Default unitary spacing for all dimensions. Spacing\ncan be specified using:\n\nIf `axis` is given, the number of varargs must equal the number of axes.\nDefault: 1.\n\nGradient is calculated using N-th order accurate differences at the\nboundaries. Default: 1.\n\nNew in version 1.9.1.\n\nGradient is calculated only along the given axis or axes The default (axis =\nNone) is to calculate the gradient for all the axes of the input array. axis\nmay be negative, in which case it counts from the last to the first axis.\n\nNew in version 1.11.0.\n\nA list of ndarrays (or a single ndarray if there is only one dimension)\ncorresponding to the derivatives of f with respect to each dimension. Each\nderivative has the same shape as f.\n\nAssuming that \\\\(f\\in C^{3}\\\\) (i.e., \\\\(f\\\\) has at least 3 continuous\nderivatives) and let \\\\(h_{*}\\\\) be a non-homogeneous stepsize, we minimize\nthe \u201cconsistency error\u201d \\\\(\\eta_{i}\\\\) between the true gradient and its\nestimate from a linear combination of the neighboring grid-points:\n\nBy substituting \\\\(f(x_{i} + h_{d})\\\\) and \\\\(f(x_{i} - h_{s})\\\\) with their\nTaylor series expansion, this translates into solving the following the linear\nsystem:\n\nThe resulting approximation of \\\\(f_{i}^{(1)}\\\\) is the following:\n\nIt is worth noting that if \\\\(h_{s}=h_{d}\\\\) (i.e., data are evenly spaced) we\nfind the standard second order approximation:\n\nWith a similar procedure the forward/backward approximations used for\nboundaries can be derived.\n\nQuarteroni A., Sacco R., Saleri F. (2007) Numerical Mathematics (Texts in\nApplied Mathematics). New York: Springer.\n\nDurran D. R. (1999) Numerical Methods for Wave Equations in Geophysical Fluid\nDynamics. New York: Springer.\n\nFornberg B. (1988) Generation of Finite Difference Formulas on Arbitrarily\nSpaced Grids, Mathematics of Computation 51, no. 184 : 699-706. PDF.\n\nSpacing can be also specified with an array that represents the coordinates of\nthe values F along the dimensions. For instance a uniform spacing:\n\nOr a non uniform one:\n\nFor two dimensional arrays, the return will be two arrays ordered by axis. In\nthis example the first array stands for the gradient in rows and the second\none in columns direction:\n\nIn this example the spacing is also specified: uniform for axis=0 and non\nuniform for axis=1\n\nIt is possible to specify how boundaries are treated using `edge_order`\n\nThe `axis` keyword can be used to specify a subset of axes of which the\ngradient is calculated\n\n"}, {"name": "numpy.greater()", "path": "reference/generated/numpy.greater", "type": "numpy.greater", "text": "\nReturn the truth value of (x1 > x2) element-wise.\n\nInput arrays. If `x1.shape != x2.shape`, they must be broadcastable to a\ncommon shape (which becomes the shape of the output).\n\nA location into which the result is stored. If provided, it must have a shape\nthat the inputs broadcast to. If not provided or None, a freshly-allocated\narray is returned. A tuple (possible only as a keyword argument) must have\nlength equal to the number of outputs.\n\nThis condition is broadcast over the input. At locations where the condition\nis True, the `out` array will be set to the ufunc result. Elsewhere, the `out`\narray will retain its original value. Note that if an uninitialized `out`\narray is created via the default `out=None`, locations within it where the\ncondition is False will remain uninitialized.\n\nFor other keyword-only arguments, see the ufunc docs.\n\nOutput array, element-wise comparison of `x1` and `x2`. Typically of type\nbool, unless `dtype=object` is passed. This is a scalar if both `x1` and `x2`\nare scalars.\n\nSee also\n\nThe `>` operator can be used as a shorthand for `np.greater` on ndarrays.\n\n"}, {"name": "numpy.greater_equal()", "path": "reference/generated/numpy.greater_equal", "type": "numpy.greater_equal", "text": "\nReturn the truth value of (x1 >= x2) element-wise.\n\nInput arrays. If `x1.shape != x2.shape`, they must be broadcastable to a\ncommon shape (which becomes the shape of the output).\n\nA location into which the result is stored. If provided, it must have a shape\nthat the inputs broadcast to. If not provided or None, a freshly-allocated\narray is returned. A tuple (possible only as a keyword argument) must have\nlength equal to the number of outputs.\n\nThis condition is broadcast over the input. At locations where the condition\nis True, the `out` array will be set to the ufunc result. Elsewhere, the `out`\narray will retain its original value. Note that if an uninitialized `out`\narray is created via the default `out=None`, locations within it where the\ncondition is False will remain uninitialized.\n\nFor other keyword-only arguments, see the ufunc docs.\n\nOutput array, element-wise comparison of `x1` and `x2`. Typically of type\nbool, unless `dtype=object` is passed. This is a scalar if both `x1` and `x2`\nare scalars.\n\nSee also\n\nThe `>=` operator can be used as a shorthand for `np.greater_equal` on\nndarrays.\n\n"}, {"name": "numpy.half", "path": "reference/arrays.scalars#numpy.half", "type": "Scalars", "text": "\nHalf-precision floating-point number type.\n\n`'e'`\n\n`numpy.float16`: 16-bit-precision floating-point number type: sign bit, 5 bits\nexponent, 10 bits mantissa.\n\n"}, {"name": "numpy.hamming()", "path": "reference/generated/numpy.hamming", "type": "numpy.hamming", "text": "\nReturn the Hamming window.\n\nThe Hamming window is a taper formed by using a weighted cosine.\n\nNumber of points in the output window. If zero or less, an empty array is\nreturned.\n\nThe window, with the maximum value normalized to one (the value one appears\nonly if the number of samples is odd).\n\nSee also\n\nThe Hamming window is defined as\n\nThe Hamming was named for R. W. Hamming, an associate of J. W. Tukey and is\ndescribed in Blackman and Tukey. It was recommended for smoothing the\ntruncated autocovariance function in the time domain. Most references to the\nHamming window come from the signal processing literature, where it is used as\none of many windowing functions for smoothing values. It is also known as an\napodization (which means \u201cremoving the foot\u201d, i.e. smoothing discontinuities\nat the beginning and end of the sampled signal) or tapering function.\n\nBlackman, R.B. and Tukey, J.W., (1958) The measurement of power spectra, Dover\nPublications, New York.\n\nE.R. Kanasewich, \u201cTime Sequence Analysis in Geophysics\u201d, The University of\nAlberta Press, 1975, pp. 109-110.\n\nWikipedia, \u201cWindow function\u201d, https://en.wikipedia.org/wiki/Window_function\n\nW.H. Press, B.P. Flannery, S.A. Teukolsky, and W.T. Vetterling, \u201cNumerical\nRecipes\u201d, Cambridge University Press, 1986, page 425.\n\nPlot the window and the frequency response:\n\n"}, {"name": "numpy.hanning()", "path": "reference/generated/numpy.hanning", "type": "numpy.hanning", "text": "\nReturn the Hanning window.\n\nThe Hanning window is a taper formed by using a weighted cosine.\n\nNumber of points in the output window. If zero or less, an empty array is\nreturned.\n\nThe window, with the maximum value normalized to one (the value one appears\nonly if `M` is odd).\n\nSee also\n\nThe Hanning window is defined as\n\nThe Hanning was named for Julius von Hann, an Austrian meteorologist. It is\nalso known as the Cosine Bell. Some authors prefer that it be called a Hann\nwindow, to help avoid confusion with the very similar Hamming window.\n\nMost references to the Hanning window come from the signal processing\nliterature, where it is used as one of many windowing functions for smoothing\nvalues. It is also known as an apodization (which means \u201cremoving the foot\u201d,\ni.e. smoothing discontinuities at the beginning and end of the sampled signal)\nor tapering function.\n\nBlackman, R.B. and Tukey, J.W., (1958) The measurement of power spectra, Dover\nPublications, New York.\n\nE.R. Kanasewich, \u201cTime Sequence Analysis in Geophysics\u201d, The University of\nAlberta Press, 1975, pp. 106-108.\n\nWikipedia, \u201cWindow function\u201d, https://en.wikipedia.org/wiki/Window_function\n\nW.H. Press, B.P. Flannery, S.A. Teukolsky, and W.T. Vetterling, \u201cNumerical\nRecipes\u201d, Cambridge University Press, 1986, page 425.\n\nPlot the window and its frequency response:\n\n"}, {"name": "numpy.heaviside()", "path": "reference/generated/numpy.heaviside", "type": "numpy.heaviside", "text": "\nCompute the Heaviside step function.\n\nThe Heaviside step function is defined as:\n\nwhere `x2` is often taken to be 0.5, but 0 and 1 are also sometimes used.\n\nInput values.\n\nThe value of the function when x1 is 0. If `x1.shape != x2.shape`, they must\nbe broadcastable to a common shape (which becomes the shape of the output).\n\nA location into which the result is stored. If provided, it must have a shape\nthat the inputs broadcast to. If not provided or None, a freshly-allocated\narray is returned. A tuple (possible only as a keyword argument) must have\nlength equal to the number of outputs.\n\nThis condition is broadcast over the input. At locations where the condition\nis True, the `out` array will be set to the ufunc result. Elsewhere, the `out`\narray will retain its original value. Note that if an uninitialized `out`\narray is created via the default `out=None`, locations within it where the\ncondition is False will remain uninitialized.\n\nFor other keyword-only arguments, see the ufunc docs.\n\nThe output array, element-wise Heaviside step function of `x1`. This is a\nscalar if both `x1` and `x2` are scalars.\n\nNew in version 1.13.0.\n\n"}, {"name": "numpy.histogram()", "path": "reference/generated/numpy.histogram", "type": "numpy.histogram", "text": "\nCompute the histogram of a dataset.\n\nInput data. The histogram is computed over the flattened array.\n\nIf `bins` is an int, it defines the number of equal-width bins in the given\nrange (10, by default). If `bins` is a sequence, it defines a monotonically\nincreasing array of bin edges, including the rightmost edge, allowing for non-\nuniform bin widths.\n\nNew in version 1.11.0.\n\nIf `bins` is a string, it defines the method used to calculate the optimal bin\nwidth, as defined by `histogram_bin_edges`.\n\nThe lower and upper range of the bins. If not provided, range is simply\n`(a.min(), a.max())`. Values outside the range are ignored. The first element\nof the range must be less than or equal to the second. `range` affects the\nautomatic bin computation as well. While bin width is computed to be optimal\nbased on the actual data within `range`, the bin count will fill the entire\nrange including portions containing no data.\n\nDeprecated since version 1.6.0.\n\nThis is equivalent to the `density` argument, but produces incorrect results\nfor unequal bin widths. It should not be used.\n\nChanged in version 1.15.0: DeprecationWarnings are actually emitted.\n\nAn array of weights, of the same shape as `a`. Each value in `a` only\ncontributes its associated weight towards the bin count (instead of 1). If\n`density` is True, the weights are normalized, so that the integral of the\ndensity over the range remains 1.\n\nIf `False`, the result will contain the number of samples in each bin. If\n`True`, the result is the value of the probability density function at the\nbin, normalized such that the integral over the range is 1. Note that the sum\nof the histogram values will not be equal to 1 unless bins of unity width are\nchosen; it is not a probability mass function.\n\nOverrides the `normed` keyword if given.\n\nThe values of the histogram. See `density` and `weights` for a description of\nthe possible semantics.\n\nReturn the bin edges `(length(hist)+1)`.\n\nSee also\n\nAll but the last (righthand-most) bin is half-open. In other words, if `bins`\nis:\n\nthen the first bin is `[1, 2)` (including 1, but excluding 2) and the second\n`[2, 3)`. The last bin, however, is `[3, 4]`, which includes 4.\n\nNew in version 1.11.0.\n\nAutomated Bin Selection Methods example, using 2 peak random data with 2000\npoints:\n\n"}, {"name": "numpy.histogram2d()", "path": "reference/generated/numpy.histogram2d", "type": "numpy.histogram2d", "text": "\nCompute the bi-dimensional histogram of two data samples.\n\nAn array containing the x coordinates of the points to be histogrammed.\n\nAn array containing the y coordinates of the points to be histogrammed.\n\nThe bin specification:\n\nThe leftmost and rightmost edges of the bins along each dimension (if not\nspecified explicitly in the `bins` parameters): `[[xmin, xmax], [ymin,\nymax]]`. All values outside of this range will be considered outliers and not\ntallied in the histogram.\n\nIf False, the default, returns the number of samples in each bin. If True,\nreturns the probability density function at the bin, `bin_count / sample_count\n/ bin_area`.\n\nAn alias for the density argument that behaves identically. To avoid confusion\nwith the broken normed argument to `histogram`, `density` should be preferred.\n\nAn array of values `w_i` weighing each sample `(x_i, y_i)`. Weights are\nnormalized to 1 if `normed` is True. If `normed` is False, the values of the\nreturned histogram are equal to the sum of the weights belonging to the\nsamples falling into each bin.\n\nThe bi-dimensional histogram of samples `x` and `y`. Values in `x` are\nhistogrammed along the first dimension and values in `y` are histogrammed\nalong the second dimension.\n\nThe bin edges along the first dimension.\n\nThe bin edges along the second dimension.\n\nSee also\n\n1D histogram\n\nMultidimensional histogram\n\nWhen `normed` is True, then the returned histogram is the sample density,\ndefined such that the sum over bins of the product `bin_value * bin_area` is\n1.\n\nPlease note that the histogram does not follow the Cartesian convention where\n`x` values are on the abscissa and `y` values on the ordinate axis. Rather,\n`x` is histogrammed along the first dimension of the array (vertical), and `y`\nalong the second dimension of the array (horizontal). This ensures\ncompatibility with `histogramdd`.\n\nConstruct a 2-D histogram with variable bin width. First define the bin edges:\n\nNext we create a histogram H with random bin content:\n\n`imshow` can only display square bins:\n\n`pcolormesh` can display actual edges:\n\n`NonUniformImage` can be used to display actual bin edges with interpolation:\n\nIt is also possible to construct a 2-D histogram without specifying bin edges:\n\nNow we can plot the histogram using `pcolormesh`, and a `hexbin` for\ncomparison.\n\n"}, {"name": "numpy.histogram_bin_edges()", "path": "reference/generated/numpy.histogram_bin_edges", "type": "numpy.histogram_bin_edges", "text": "\nFunction to calculate only the edges of the bins used by the `histogram`\nfunction.\n\nInput data. The histogram is computed over the flattened array.\n\nIf `bins` is an int, it defines the number of equal-width bins in the given\nrange (10, by default). If `bins` is a sequence, it defines the bin edges,\nincluding the rightmost edge, allowing for non-uniform bin widths.\n\nIf `bins` is a string from the list below, `histogram_bin_edges` will use the\nmethod chosen to calculate the optimal bin width and consequently the number\nof bins (see `Notes` for more detail on the estimators) from the data that\nfalls within the requested range. While the bin width will be optimal for the\nactual data in the range, the number of bins will be computed to fill the\nentire range, including the empty portions. For visualisation, using the\n\u2018auto\u2019 option is suggested. Weighted data is not supported for automated bin\nsize selection.\n\nMaximum of the \u2018sturges\u2019 and \u2018fd\u2019 estimators. Provides good all around\nperformance.\n\nRobust (resilient to outliers) estimator that takes into account data\nvariability and data size.\n\nAn improved version of Sturges\u2019 estimator that works better with non-normal\ndatasets.\n\nLess robust estimator that that takes into account data variability and data\nsize.\n\nEstimator based on leave-one-out cross-validation estimate of the integrated\nsquared error. Can be regarded as a generalization of Scott\u2019s rule.\n\nEstimator does not take variability into account, only data size. Commonly\noverestimates number of bins required.\n\nR\u2019s default method, only accounts for data size. Only optimal for gaussian\ndata and underestimates number of bins for large non-gaussian datasets.\n\nSquare root (of data size) estimator, used by Excel and other programs for its\nspeed and simplicity.\n\nThe lower and upper range of the bins. If not provided, range is simply\n`(a.min(), a.max())`. Values outside the range are ignored. The first element\nof the range must be less than or equal to the second. `range` affects the\nautomatic bin computation as well. While bin width is computed to be optimal\nbased on the actual data within `range`, the bin count will fill the entire\nrange including portions containing no data.\n\nAn array of weights, of the same shape as `a`. Each value in `a` only\ncontributes its associated weight towards the bin count (instead of 1). This\nis currently not used by any of the bin estimators, but may be in the future.\n\nThe edges to pass into `histogram`\n\nSee also\n\nThe methods to estimate the optimal number of bins are well founded in\nliterature, and are inspired by the choices R provides for histogram\nvisualisation. Note that having the number of bins proportional to\n\\\\(n^{1/3}\\\\) is asymptotically optimal, which is why it appears in most\nestimators. These are simply plug-in methods that give good starting points\nfor number of bins. In the equations below, \\\\(h\\\\) is the binwidth and\n\\\\(n_h\\\\) is the number of bins. All estimators that compute bin counts are\nrecast to bin width using the `ptp` of the data. The final bin count is\nobtained from `np.round(np.ceil(range / h))`. The final bin width is often\nless than what is returned by the estimators below.\n\nA compromise to get a good value. For small datasets the Sturges value will\nusually be chosen, while larger datasets will usually default to FD. Avoids\nthe overly conservative behaviour of FD and Sturges for small and large\ndatasets respectively. Switchover point is usually \\\\(a.size \\approx 1000\\\\).\n\nThe binwidth is proportional to the interquartile range (IQR) and inversely\nproportional to cube root of a.size. Can be too conservative for small\ndatasets, but is quite good for large datasets. The IQR is very robust to\noutliers.\n\nThe binwidth is proportional to the standard deviation of the data and\ninversely proportional to cube root of `x.size`. Can be too conservative for\nsmall datasets, but is quite good for large datasets. The standard deviation\nis not very robust to outliers. Values are very similar to the Freedman-\nDiaconis estimator in the absence of outliers.\n\nThe number of bins is only proportional to cube root of `a.size`. It tends to\noverestimate the number of bins and it does not take into account data\nvariability.\n\nThe number of bins is the base 2 log of `a.size`. This estimator assumes\nnormality of data and is too conservative for larger, non-normal datasets.\nThis is the default method in R\u2019s `hist` method.\n\nAn improved version of Sturges\u2019 formula that produces better estimates for\nnon-normal datasets. This estimator attempts to account for the skew of the\ndata.\n\nThe simplest and fastest estimator. Only takes into account the data size.\n\nFor consistency with histogram, an array of pre-computed bins is passed\nthrough unmodified:\n\nThis function allows one set of bins to be computed, and reused across\nmultiple histograms:\n\nWhich gives more easily comparable results than using separate bins for each\nhistogram:\n\n"}, {"name": "numpy.histogramdd()", "path": "reference/generated/numpy.histogramdd", "type": "numpy.histogramdd", "text": "\nCompute the multidimensional histogram of some data.\n\nThe data to be histogrammed.\n\nNote the unusual interpretation of sample when an array_like:\n\nThe first form should be preferred.\n\nThe bin specification:\n\nA sequence of length D, each an optional (lower, upper) tuple giving the outer\nbin edges to be used if the edges are not given explicitly in `bins`. An entry\nof None in the sequence results in the minimum and maximum values being used\nfor the corresponding dimension. The default, None, is equivalent to passing a\ntuple of D None values.\n\nIf False, the default, returns the number of samples in each bin. If True,\nreturns the probability density function at the bin, `bin_count / sample_count\n/ bin_volume`.\n\nAn alias for the density argument that behaves identically. To avoid confusion\nwith the broken normed argument to `histogram`, `density` should be preferred.\n\nAn array of values `w_i` weighing each sample `(x_i, y_i, z_i, \u2026)`. Weights\nare normalized to 1 if normed is True. If normed is False, the values of the\nreturned histogram are equal to the sum of the weights belonging to the\nsamples falling into each bin.\n\nThe multidimensional histogram of sample x. See normed and weights for the\ndifferent possible semantics.\n\nA list of D arrays describing the bin edges for each dimension.\n\nSee also\n\n1-D histogram\n\n2-D histogram\n\n"}, {"name": "numpy.hsplit()", "path": "reference/generated/numpy.hsplit", "type": "numpy.hsplit", "text": "\nSplit an array into multiple sub-arrays horizontally (column-wise).\n\nPlease refer to the `split` documentation. `hsplit` is equivalent to `split`\nwith `axis=1`, the array is always split along the second axis regardless of\nthe array dimension.\n\nSee also\n\nSplit an array into multiple sub-arrays of equal size.\n\nWith a higher dimensional array the split is still along the second axis.\n\n"}, {"name": "numpy.hstack()", "path": "reference/generated/numpy.hstack", "type": "numpy.hstack", "text": "\nStack arrays in sequence horizontally (column wise).\n\nThis is equivalent to concatenation along the second axis, except for 1-D\narrays where it concatenates along the first axis. Rebuilds arrays divided by\n`hsplit`.\n\nThis function makes most sense for arrays with up to 3 dimensions. For\ninstance, for pixel-data with a height (first axis), width (second axis), and\nr/g/b channels (third axis). The functions `concatenate`, `stack` and `block`\nprovide more general stacking and concatenation operations.\n\nThe arrays must have the same shape along all but the second axis, except 1-D\narrays which can be any length.\n\nThe array formed by stacking the given arrays.\n\nSee also\n\nJoin a sequence of arrays along an existing axis.\n\nJoin a sequence of arrays along a new axis.\n\nAssemble an nd-array from nested lists of blocks.\n\nStack arrays in sequence vertically (row wise).\n\nStack arrays in sequence depth wise (along third axis).\n\nStack 1-D arrays as columns into a 2-D array.\n\nSplit an array into multiple sub-arrays horizontally (column-wise).\n\n"}, {"name": "numpy.hypot()", "path": "reference/generated/numpy.hypot", "type": "numpy.hypot", "text": "\nGiven the \u201clegs\u201d of a right triangle, return its hypotenuse.\n\nEquivalent to `sqrt(x1**2 + x2**2)`, element-wise. If `x1` or `x2` is\nscalar_like (i.e., unambiguously cast-able to a scalar type), it is broadcast\nfor use with each element of the other argument. (See Examples)\n\nLeg of the triangle(s). If `x1.shape != x2.shape`, they must be broadcastable\nto a common shape (which becomes the shape of the output).\n\nA location into which the result is stored. If provided, it must have a shape\nthat the inputs broadcast to. If not provided or None, a freshly-allocated\narray is returned. A tuple (possible only as a keyword argument) must have\nlength equal to the number of outputs.\n\nThis condition is broadcast over the input. At locations where the condition\nis True, the `out` array will be set to the ufunc result. Elsewhere, the `out`\narray will retain its original value. Note that if an uninitialized `out`\narray is created via the default `out=None`, locations within it where the\ncondition is False will remain uninitialized.\n\nFor other keyword-only arguments, see the ufunc docs.\n\nThe hypotenuse of the triangle(s). This is a scalar if both `x1` and `x2` are\nscalars.\n\nExample showing broadcast of scalar_like argument:\n\n"}, {"name": "numpy.i0()", "path": "reference/generated/numpy.i0", "type": "numpy.i0", "text": "\nModified Bessel function of the first kind, order 0.\n\nUsually denoted \\\\(I_0\\\\).\n\nArgument of the Bessel function.\n\nThe modified Bessel function evaluated at each of the elements of `x`.\n\nSee also\n\nThe scipy implementation is recommended over this function: it is a proper\nufunc written in C, and more than an order of magnitude faster.\n\nWe use the algorithm published by Clenshaw [1] and referenced by Abramowitz\nand Stegun [2], for which the function domain is partitioned into the two\nintervals [0,8] and (8,inf), and Chebyshev polynomial expansions are employed\nin each interval. Relative error on the domain [0,30] using IEEE arithmetic is\ndocumented [3] as having a peak of 5.8e-16 with an rms of 1.4e-16 (n = 30000).\n\nC. W. Clenshaw, \u201cChebyshev series for mathematical functions\u201d, in National\nPhysical Laboratory Mathematical Tables, vol. 5, London: Her Majesty\u2019s\nStationery Office, 1962.\n\nM. Abramowitz and I. A. Stegun, Handbook of Mathematical Functions, 10th\nprinting, New York: Dover, 1964, pp. 379.\nhttps://personal.math.ubc.ca/~cbm/aands/page_379.htm\n\nhttps://metacpan.org/pod/distribution/Math-\nCephes/lib/Math/Cephes.pod#i0:-Modified-Bessel-function-of-order-zero\n\n"}, {"name": "numpy.identity()", "path": "reference/generated/numpy.identity", "type": "numpy.identity", "text": "\nReturn the identity array.\n\nThe identity array is a square array with ones on the main diagonal.\n\nNumber of rows (and columns) in `n` x `n` output.\n\nData-type of the output. Defaults to `float`.\n\nReference object to allow the creation of arrays which are not NumPy arrays.\nIf an array-like passed in as `like` supports the `__array_function__`\nprotocol, the result will be defined by it. In this case, it ensures the\ncreation of an array object compatible with that passed in via this argument.\n\nNew in version 1.20.0.\n\n`n` x `n` array with its main diagonal set to one, and all other elements 0.\n\n"}, {"name": "numpy.iinfo()", "path": "reference/generated/numpy.iinfo", "type": "numpy.iinfo", "text": "\nMachine limits for integer types.\n\nThe kind of integer data type to get information about.\n\nSee also\n\nThe equivalent for floating point data types.\n\nWith types:\n\nWith instances:\n\nThe number of bits occupied by the type.\n\nMinimum value of given dtype.\n\nMaximum value of given dtype.\n\n"}, {"name": "numpy.imag()", "path": "reference/generated/numpy.imag", "type": "numpy.imag", "text": "\nReturn the imaginary part of the complex argument.\n\nInput array.\n\nThe imaginary component of the complex argument. If `val` is real, the type of\n`val` is used for the output. If `val` has complex elements, the returned type\nis float.\n\nSee also\n\n"}, {"name": "numpy.in1d()", "path": "reference/generated/numpy.in1d", "type": "numpy.in1d", "text": "\nTest whether each element of a 1-D array is also present in a second array.\n\nReturns a boolean array the same length as `ar1` that is True where an element\nof `ar1` is in `ar2` and False otherwise.\n\nWe recommend using `isin` instead of `in1d` for new code.\n\nInput array.\n\nThe values against which to test each value of `ar1`.\n\nIf True, the input arrays are both assumed to be unique, which can speed up\nthe calculation. Default is False.\n\nIf True, the values in the returned array are inverted (that is, False where\nan element of `ar1` is in `ar2` and True otherwise). Default is False.\n`np.in1d(a, b, invert=True)` is equivalent to (but is faster than)\n`np.invert(in1d(a, b))`.\n\nNew in version 1.8.0.\n\nThe values `ar1[in1d]` are in `ar2`.\n\nSee also\n\nVersion of this function that preserves the shape of ar1.\n\nModule with a number of other functions for performing set operations on\narrays.\n\n`in1d` can be considered as an element-wise function version of the python\nkeyword `in`, for 1-D sequences. `in1d(a, b)` is roughly equivalent to\n`np.array([item in b for item in a])`. However, this idea fails if `ar2` is a\nset, or similar (non-sequence) container: As `ar2` is converted to an array,\nin those cases `asarray(ar2)` is an object array rather than the expected\narray of contained values.\n\nNew in version 1.4.0.\n\n"}, {"name": "numpy.indices()", "path": "reference/generated/numpy.indices", "type": "numpy.indices", "text": "\nReturn an array representing the indices of a grid.\n\nCompute an array where the subarrays contain index values 0, 1, \u2026 varying only\nalong the corresponding axis.\n\nThe shape of the grid.\n\nData type of the result.\n\nReturn a sparse representation of the grid instead of a dense representation.\nDefault is False.\n\nNew in version 1.17.\n\nReturns one array of grid indices, `grid.shape = (len(dimensions),) +\ntuple(dimensions)`.\n\nReturns a tuple of arrays, with `grid[i].shape = (1, ..., 1, dimensions[i], 1,\n..., 1)` with dimensions[i] in the ith place\n\nSee also\n\nThe output shape in the dense case is obtained by prepending the number of\ndimensions in front of the tuple of dimensions, i.e. if `dimensions` is a\ntuple `(r0, ..., rN-1)` of length `N`, the output shape is `(N, r0, ...,\nrN-1)`.\n\nThe subarrays `grid[k]` contains the N-D array of indices along the `k-th`\naxis. Explicitly:\n\nThe indices can be used as an index into an array.\n\nNote that it would be more straightforward in the above example to extract the\nrequired elements directly with `x[:2, :3]`.\n\nIf sparse is set to true, the grid will be returned in a sparse\nrepresentation.\n\n"}, {"name": "numpy.Inf", "path": "reference/constants", "type": "Constants", "text": "\nNumPy includes several constants:\n\nIEEE 754 floating point representation of (positive) infinity.\n\nUse `inf` because `Inf`, `Infinity`, `PINF` and `infty` are aliases for `inf`.\nFor more details, see `inf`.\n\ninf\n\nIEEE 754 floating point representation of (positive) infinity.\n\nUse `inf` because `Inf`, `Infinity`, `PINF` and `infty` are aliases for `inf`.\nFor more details, see `inf`.\n\ninf\n\nIEEE 754 floating point representation of Not a Number (NaN).\n\n`NaN` and `NAN` are equivalent definitions of `nan`. Please use `nan` instead\nof `NAN`.\n\nnan\n\nIEEE 754 floating point representation of negative infinity.\n\nA floating point representation of negative infinity.\n\nisinf : Shows which elements are positive or negative infinity\n\nisposinf : Shows which elements are positive infinity\n\nisneginf : Shows which elements are negative infinity\n\nisnan : Shows which elements are Not a Number\n\nisfinite : Shows which elements are finite (not one of Not a Number, positive\ninfinity and negative infinity)\n\nNumPy uses the IEEE Standard for Binary Floating-Point for Arithmetic (IEEE\n754). This means that Not a Number is not equivalent to infinity. Also that\npositive infinity is not equivalent to negative infinity. But infinity is\nequivalent to positive infinity.\n\nIEEE 754 floating point representation of negative zero.\n\nA floating point representation of negative zero.\n\nPZERO : Defines positive zero.\n\nisinf : Shows which elements are positive or negative infinity.\n\nisposinf : Shows which elements are positive infinity.\n\nisneginf : Shows which elements are negative infinity.\n\nisnan : Shows which elements are Not a Number.\n\nNot a Number, positive infinity and negative infinity.\n\nNumPy uses the IEEE Standard for Binary Floating-Point for Arithmetic (IEEE\n754). Negative zero is considered to be a finite number.\n\nIEEE 754 floating point representation of Not a Number (NaN).\n\n`NaN` and `NAN` are equivalent definitions of `nan`. Please use `nan` instead\nof `NaN`.\n\nnan\n\nIEEE 754 floating point representation of (positive) infinity.\n\nUse `inf` because `Inf`, `Infinity`, `PINF` and `infty` are aliases for `inf`.\nFor more details, see `inf`.\n\ninf\n\nIEEE 754 floating point representation of positive zero.\n\nA floating point representation of positive zero.\n\nNZERO : Defines negative zero.\n\nisinf : Shows which elements are positive or negative infinity.\n\nisposinf : Shows which elements are positive infinity.\n\nisneginf : Shows which elements are negative infinity.\n\nisnan : Shows which elements are Not a Number.\n\nNot a Number, positive infinity and negative infinity.\n\nNumPy uses the IEEE Standard for Binary Floating-Point for Arithmetic (IEEE\n754). Positive zero is considered to be a finite number.\n\nEuler\u2019s constant, base of natural logarithms, Napier\u2019s constant.\n\n`e = 2.71828182845904523536028747135266249775724709369995...`\n\nexp : Exponential function log : Natural logarithm\n\nhttps://en.wikipedia.org/wiki/E_%28mathematical_constant%29\n\n`\u03b3 = 0.5772156649015328606065120900824024310421...`\n\nhttps://en.wikipedia.org/wiki/Euler-Mascheroni_constant\n\nIEEE 754 floating point representation of (positive) infinity.\n\nA floating point representation of positive infinity.\n\nisinf : Shows which elements are positive or negative infinity\n\nisposinf : Shows which elements are positive infinity\n\nisneginf : Shows which elements are negative infinity\n\nisnan : Shows which elements are Not a Number\n\nisfinite : Shows which elements are finite (not one of Not a Number, positive\ninfinity and negative infinity)\n\nNumPy uses the IEEE Standard for Binary Floating-Point for Arithmetic (IEEE\n754). This means that Not a Number is not equivalent to infinity. Also that\npositive infinity is not equivalent to negative infinity. But infinity is\nequivalent to positive infinity.\n\n`Inf`, `Infinity`, `PINF` and `infty` are aliases for `inf`.\n\nIEEE 754 floating point representation of (positive) infinity.\n\nUse `inf` because `Inf`, `Infinity`, `PINF` and `infty` are aliases for `inf`.\nFor more details, see `inf`.\n\ninf\n\nIEEE 754 floating point representation of Not a Number (NaN).\n\ny : A floating point representation of Not a Number.\n\nisnan : Shows which elements are Not a Number.\n\nisfinite : Shows which elements are finite (not one of Not a Number, positive\ninfinity and negative infinity)\n\nNumPy uses the IEEE Standard for Binary Floating-Point for Arithmetic (IEEE\n754). This means that Not a Number is not equivalent to infinity.\n\n`NaN` and `NAN` are aliases of `nan`.\n\nA convenient alias for None, useful for indexing arrays.\n\nOuter product, same as `outer(x, y)`:\n\n`x[newaxis, :]` is equivalent to `x[newaxis]` and `x[None]`:\n\n`pi = 3.1415926535897932384626433...`\n\nhttps://en.wikipedia.org/wiki/Pi\n\n"}, {"name": "numpy.inf", "path": "reference/constants#numpy.inf", "type": "Constants", "text": "\nIEEE 754 floating point representation of (positive) infinity.\n\nA floating point representation of positive infinity.\n\nisinf : Shows which elements are positive or negative infinity\n\nisposinf : Shows which elements are positive infinity\n\nisneginf : Shows which elements are negative infinity\n\nisnan : Shows which elements are Not a Number\n\nisfinite : Shows which elements are finite (not one of Not a Number, positive\ninfinity and negative infinity)\n\nNumPy uses the IEEE Standard for Binary Floating-Point for Arithmetic (IEEE\n754). This means that Not a Number is not equivalent to infinity. Also that\npositive infinity is not equivalent to negative infinity. But infinity is\nequivalent to positive infinity.\n\n`Inf`, `Infinity`, `PINF` and `infty` are aliases for `inf`.\n\n"}, {"name": "numpy.Infinity", "path": "reference/constants#numpy.Infinity", "type": "Constants", "text": "\nIEEE 754 floating point representation of (positive) infinity.\n\nUse `inf` because `Inf`, `Infinity`, `PINF` and `infty` are aliases for `inf`.\nFor more details, see `inf`.\n\ninf\n\n"}, {"name": "numpy.info()", "path": "reference/generated/numpy.info", "type": "numpy.info", "text": "\nGet help information for a function, class, or module.\n\nInput object or name to get information about. If `object` is a numpy object,\nits docstring is given. If it is a string, available modules are searched for\nmatching objects. If None, information about `info` itself is returned.\n\nPrinting width.\n\nFile like object that the output is written to, default is `stdout`. The\nobject has to be opened in \u2018w\u2019 or \u2018a\u2019 mode.\n\nStart search at this level.\n\nSee also\n\nWhen used interactively with an object, `np.info(obj)` is equivalent to\n`help(obj)` on the Python prompt or `obj?` on the IPython prompt.\n\nWhen using a string for `object` it is possible to get multiple results.\n\n"}, {"name": "numpy.infty", "path": "reference/constants#numpy.infty", "type": "Constants", "text": "\nIEEE 754 floating point representation of (positive) infinity.\n\nUse `inf` because `Inf`, `Infinity`, `PINF` and `infty` are aliases for `inf`.\nFor more details, see `inf`.\n\ninf\n\n"}, {"name": "numpy.inner()", "path": "reference/generated/numpy.inner", "type": "numpy.inner", "text": "\nInner product of two arrays.\n\nOrdinary inner product of vectors for 1-D arrays (without complex\nconjugation), in higher dimensions a sum product over the last axes.\n\nIf `a` and `b` are nonscalar, their last dimensions must match.\n\nIf `a` and `b` are both scalars or both 1-D arrays then a scalar is returned;\notherwise an array is returned. `out.shape = (*a.shape[:-1], *b.shape[:-1])`\n\nIf both `a` and `b` are nonscalar and their last dimensions have different\nsizes.\n\nSee also\n\nSum products over arbitrary axes.\n\nGeneralised matrix product, using second last dimension of `b`.\n\nEinstein summation convention.\n\nFor vectors (1-D arrays) it computes the ordinary inner-product:\n\nMore generally, if `ndim(a) = r > 0` and `ndim(b) = s > 0`:\n\nor explicitly:\n\nIn addition `a` or `b` may be scalars, in which case:\n\nOrdinary inner product for vectors:\n\nSome multidimensional examples:\n\nAn example where `b` is a scalar:\n\n"}, {"name": "numpy.insert()", "path": "reference/generated/numpy.insert", "type": "numpy.insert", "text": "\nInsert values along the given axis before the given indices.\n\nInput array.\n\nObject that defines the index or indices before which `values` is inserted.\n\nNew in version 1.8.0.\n\nSupport for multiple insertions when `obj` is a single scalar or a sequence\nwith one element (similar to calling insert multiple times).\n\nValues to insert into `arr`. If the type of `values` is different from that of\n`arr`, `values` is converted to the type of `arr`. `values` should be shaped\nso that `arr[...,obj,...] = values` is legal.\n\nAxis along which to insert `values`. If `axis` is None then `arr` is flattened\nfirst.\n\nA copy of `arr` with `values` inserted. Note that `insert` does not occur in-\nplace: a new array is returned. If `axis` is None, `out` is a flattened array.\n\nSee also\n\nAppend elements at the end of an array.\n\nJoin a sequence of arrays along an existing axis.\n\nDelete elements from an array.\n\nNote that for higher dimensional inserts `obj=0` behaves very different from\n`obj=[0]` just like `arr[:,0,:] = values` is different from `arr[:,[0],:] =\nvalues`.\n\nDifference between sequence and scalars:\n\n"}, {"name": "numpy.int16", "path": "reference/arrays.scalars#numpy.int16", "type": "Scalars", "text": "\nAliases for the signed integer types (one of `numpy.byte`, `numpy.short`,\n`numpy.intc`, `numpy.int_` and `numpy.longlong`) with the specified number of\nbits.\n\nCompatible with the C99 `int8_t`, `int16_t`, `int32_t`, and `int64_t`,\nrespectively.\n\n"}, {"name": "numpy.int32", "path": "reference/arrays.scalars#numpy.int32", "type": "Scalars", "text": "\nAliases for the signed integer types (one of `numpy.byte`, `numpy.short`,\n`numpy.intc`, `numpy.int_` and `numpy.longlong`) with the specified number of\nbits.\n\nCompatible with the C99 `int8_t`, `int16_t`, `int32_t`, and `int64_t`,\nrespectively.\n\n"}, {"name": "numpy.int64", "path": "reference/arrays.scalars#numpy.int64", "type": "Scalars", "text": "\nAliases for the signed integer types (one of `numpy.byte`, `numpy.short`,\n`numpy.intc`, `numpy.int_` and `numpy.longlong`) with the specified number of\nbits.\n\nCompatible with the C99 `int8_t`, `int16_t`, `int32_t`, and `int64_t`,\nrespectively.\n\n"}, {"name": "numpy.int8", "path": "reference/arrays.scalars#numpy.int8", "type": "Scalars", "text": "\nAliases for the signed integer types (one of `numpy.byte`, `numpy.short`,\n`numpy.intc`, `numpy.int_` and `numpy.longlong`) with the specified number of\nbits.\n\nCompatible with the C99 `int8_t`, `int16_t`, `int32_t`, and `int64_t`,\nrespectively.\n\n"}, {"name": "numpy.int_", "path": "reference/arrays.scalars#numpy.int_", "type": "Scalars", "text": "\nSigned integer type, compatible with Python `int` and C `long`.\n\n`'l'`\n\n`numpy.int64`: 64-bit signed integer (`-9_223_372_036_854_775_808` to\n`9_223_372_036_854_775_807`).\n\n`numpy.intp`: Signed integer large enough to fit pointer, compatible with C\n`intptr_t`.\n\n"}, {"name": "numpy.intc", "path": "reference/arrays.scalars#numpy.intc", "type": "Scalars", "text": "\nSigned integer type, compatible with C `int`.\n\n`'i'`\n\n`numpy.int32`: 32-bit signed integer (`-2_147_483_648` to `2_147_483_647`).\n\n"}, {"name": "numpy.interp()", "path": "reference/generated/numpy.interp", "type": "numpy.interp", "text": "\nOne-dimensional linear interpolation for monotonically increasing sample\npoints.\n\nReturns the one-dimensional piecewise linear interpolant to a function with\ngiven discrete data points (`xp`, `fp`), evaluated at `x`.\n\nThe x-coordinates at which to evaluate the interpolated values.\n\nThe x-coordinates of the data points, must be increasing if argument `period`\nis not specified. Otherwise, `xp` is internally sorted after normalizing the\nperiodic boundaries with `xp = xp % period`.\n\nThe y-coordinates of the data points, same length as `xp`.\n\nValue to return for `x < xp[0]`, default is `fp[0]`.\n\nValue to return for `x > xp[-1]`, default is `fp[-1]`.\n\nA period for the x-coordinates. This parameter allows the proper interpolation\nof angular x-coordinates. Parameters `left` and `right` are ignored if\n`period` is specified.\n\nNew in version 1.10.0.\n\nThe interpolated values, same shape as `x`.\n\nIf `xp` and `fp` have different length If `xp` or `fp` are not 1-D sequences\nIf `period == 0`\n\nWarning\n\nThe x-coordinate sequence is expected to be increasing, but this is not\nexplicitly enforced. However, if the sequence `xp` is non-increasing,\ninterpolation results are meaningless.\n\nNote that, since NaN is unsortable, `xp` also cannot contain NaNs.\n\nA simple check for `xp` being strictly increasing is:\n\nSee also\n\nPlot an interpolant to the sine function:\n\nInterpolation with periodic x-coordinates:\n\nComplex interpolation:\n\n"}, {"name": "numpy.intersect1d()", "path": "reference/generated/numpy.intersect1d", "type": "numpy.intersect1d", "text": "\nFind the intersection of two arrays.\n\nReturn the sorted, unique values that are in both of the input arrays.\n\nInput arrays. Will be flattened if not already 1D.\n\nIf True, the input arrays are both assumed to be unique, which can speed up\nthe calculation. If True but `ar1` or `ar2` are not unique, incorrect results\nand out-of-bounds indices could result. Default is False.\n\nIf True, the indices which correspond to the intersection of the two arrays\nare returned. The first instance of a value is used if there are multiple.\nDefault is False.\n\nNew in version 1.15.0.\n\nSorted 1D array of common and unique elements.\n\nThe indices of the first occurrences of the common values in `ar1`. Only\nprovided if `return_indices` is True.\n\nThe indices of the first occurrences of the common values in `ar2`. Only\nprovided if `return_indices` is True.\n\nSee also\n\nModule with a number of other functions for performing set operations on\narrays.\n\nTo intersect more than two arrays, use functools.reduce:\n\nTo return the indices of the values common to the input arrays along with the\nintersected values:\n\n"}, {"name": "numpy.intp", "path": "reference/arrays.scalars#numpy.intp", "type": "Scalars", "text": "\nAlias for the signed integer type (one of `numpy.byte`, `numpy.short`,\n`numpy.intc`, `numpy.int_` and `np.longlong`) that is the same size as a\npointer.\n\nCompatible with the C `intptr_t`.\n\n`'p'`\n\n"}, {"name": "numpy.invert()", "path": "reference/generated/numpy.invert", "type": "numpy.invert", "text": "\nCompute bit-wise inversion, or bit-wise NOT, element-wise.\n\nComputes the bit-wise NOT of the underlying binary representation of the\nintegers in the input arrays. This ufunc implements the C/Python operator `~`.\n\nFor signed integer inputs, the two\u2019s complement is returned. In a\ntwo\u2019s-complement system negative numbers are represented by the two\u2019s\ncomplement of the absolute value. This is the most common method of\nrepresenting signed integers on computers [1]. A N-bit two\u2019s-complement system\ncan represent every integer in the range \\\\(-2^{N-1}\\\\) to \\\\(+2^{N-1}-1\\\\).\n\nOnly integer and boolean types are handled.\n\nA location into which the result is stored. If provided, it must have a shape\nthat the inputs broadcast to. If not provided or None, a freshly-allocated\narray is returned. A tuple (possible only as a keyword argument) must have\nlength equal to the number of outputs.\n\nThis condition is broadcast over the input. At locations where the condition\nis True, the `out` array will be set to the ufunc result. Elsewhere, the `out`\narray will retain its original value. Note that if an uninitialized `out`\narray is created via the default `out=None`, locations within it where the\ncondition is False will remain uninitialized.\n\nFor other keyword-only arguments, see the ufunc docs.\n\nResult. This is a scalar if `x` is a scalar.\n\nSee also\n\nReturn the binary representation of the input number as a string.\n\n`bitwise_not` is an alias for `invert`:\n\nWikipedia, \u201cTwo\u2019s complement\u201d, https://en.wikipedia.org/wiki/Two\u2019s_complement\n\nWe\u2019ve seen that 13 is represented by `00001101`. The invert or bit-wise NOT of\n13 is then:\n\nThe result depends on the bit-width:\n\nWhen using signed integer types the result is the two\u2019s complement of the\nresult for the unsigned type:\n\nBooleans are accepted as well:\n\nThe `~` operator can be used as a shorthand for `np.invert` on ndarrays.\n\n"}, {"name": "numpy.is_busday()", "path": "reference/generated/numpy.is_busday", "type": "numpy.is_busday", "text": "\nCalculates which of the given dates are valid days, and which are not.\n\nNew in version 1.7.0.\n\nThe array of dates to process.\n\nA seven-element array indicating which of Monday through Sunday are valid\ndays. May be specified as a length-seven list or array, like [1,1,1,1,1,0,0];\na length-seven string, like \u20181111100\u2019; or a string like \u201cMon Tue Wed Thu Fri\u201d,\nmade up of 3-character abbreviations for weekdays, optionally separated by\nwhite space. Valid abbreviations are: Mon Tue Wed Thu Fri Sat Sun\n\nAn array of dates to consider as invalid dates. They may be specified in any\norder, and NaT (not-a-time) dates are ignored. This list is saved in a\nnormalized form that is suited for fast calculations of valid days.\n\nA `busdaycalendar` object which specifies the valid days. If this parameter is\nprovided, neither weekmask nor holidays may be provided.\n\nIf provided, this array is filled with the result.\n\nAn array with the same shape as `dates`, containing True for each valid day,\nand False for each invalid day.\n\nSee also\n\nAn object that specifies a custom set of valid days.\n\nApplies an offset counted in valid days.\n\nCounts how many valid days are in a half-open date range.\n\n"}, {"name": "numpy.isclose()", "path": "reference/generated/numpy.isclose", "type": "numpy.isclose", "text": "\nReturns a boolean array where two arrays are element-wise equal within a\ntolerance.\n\nThe tolerance values are positive, typically very small numbers. The relative\ndifference (`rtol` * abs(`b`)) and the absolute difference `atol` are added\ntogether to compare against the absolute difference between `a` and `b`.\n\nWarning\n\nThe default `atol` is not appropriate for comparing numbers that are much\nsmaller than one (see Notes).\n\nInput arrays to compare.\n\nThe relative tolerance parameter (see Notes).\n\nThe absolute tolerance parameter (see Notes).\n\nWhether to compare NaN\u2019s as equal. If True, NaN\u2019s in `a` will be considered\nequal to NaN\u2019s in `b` in the output array.\n\nReturns a boolean array of where `a` and `b` are equal within the given\ntolerance. If both `a` and `b` are scalars, returns a single boolean value.\n\nSee also\n\nNew in version 1.7.0.\n\nFor finite values, isclose uses the following equation to test whether two\nfloating point values are equivalent.\n\nabsolute(`a` \\- `b`) <= (`atol` \\+ `rtol` * absolute(`b`))\n\nUnlike the built-in `math.isclose`, the above equation is not symmetric in `a`\nand `b` \u2013 it assumes `b` is the reference value \u2013 so that `isclose(a, b)`\nmight be different from `isclose(b, a)`. Furthermore, the default value of\natol is not zero, and is used to determine what small values should be\nconsidered close to zero. The default value is appropriate for expected values\nof order unity: if the expected values are significantly smaller than one, it\ncan result in false positives. `atol` should be carefully selected for the use\ncase at hand. A zero value for `atol` will result in `False` if either `a` or\n`b` is zero.\n\n`isclose` is not defined for non-numeric data types. `bool` is considered a\nnumeric data-type for this purpose.\n\n"}, {"name": "numpy.iscomplex()", "path": "reference/generated/numpy.iscomplex", "type": "numpy.iscomplex", "text": "\nReturns a bool array, where True if input element is complex.\n\nWhat is tested is whether the input has a non-zero imaginary part, not if the\ninput type is complex.\n\nInput array.\n\nOutput array.\n\nSee also\n\nReturn True if x is a complex type or an array of complex numbers.\n\n"}, {"name": "numpy.iscomplexobj()", "path": "reference/generated/numpy.iscomplexobj", "type": "numpy.iscomplexobj", "text": "\nCheck for a complex type or an array of complex numbers.\n\nThe type of the input is checked, not the value. Even if the input has an\nimaginary part equal to zero, `iscomplexobj` evaluates to True.\n\nThe input can be of any type and shape.\n\nThe return value, True if `x` is of a complex type or has at least one complex\nelement.\n\nSee also\n\n"}, {"name": "numpy.isfinite()", "path": "reference/generated/numpy.isfinite", "type": "numpy.isfinite", "text": "\nTest element-wise for finiteness (not infinity and not Not a Number).\n\nThe result is returned as a boolean array.\n\nInput values.\n\nA location into which the result is stored. If provided, it must have a shape\nthat the inputs broadcast to. If not provided or None, a freshly-allocated\narray is returned. A tuple (possible only as a keyword argument) must have\nlength equal to the number of outputs.\n\nThis condition is broadcast over the input. At locations where the condition\nis True, the `out` array will be set to the ufunc result. Elsewhere, the `out`\narray will retain its original value. Note that if an uninitialized `out`\narray is created via the default `out=None`, locations within it where the\ncondition is False will remain uninitialized.\n\nFor other keyword-only arguments, see the ufunc docs.\n\nTrue where `x` is not positive infinity, negative infinity, or NaN; false\notherwise. This is a scalar if `x` is a scalar.\n\nSee also\n\nNot a Number, positive infinity and negative infinity are considered to be\nnon-finite.\n\nNumPy uses the IEEE Standard for Binary Floating-Point for Arithmetic (IEEE\n754). This means that Not a Number is not equivalent to infinity. Also that\npositive infinity is not equivalent to negative infinity. But infinity is\nequivalent to positive infinity. Errors result if the second argument is also\nsupplied when `x` is a scalar input, or if first and second arguments have\ndifferent shapes.\n\n"}, {"name": "numpy.isfortran()", "path": "reference/generated/numpy.isfortran", "type": "numpy.isfortran", "text": "\nCheck if the array is Fortran contiguous but not C contiguous.\n\nThis function is obsolete and, because of changes due to relaxed stride\nchecking, its return value for the same array may differ for versions of NumPy\n>= 1.10.0 and previous versions. If you only want to check if an array is\nFortran contiguous use `a.flags.f_contiguous` instead.\n\nInput array.\n\nReturns True if the array is Fortran contiguous but not C contiguous.\n\nnp.array allows to specify whether the array is written in C-contiguous order\n(last index varies the fastest), or FORTRAN-contiguous order in memory (first\nindex varies the fastest).\n\nThe transpose of a C-ordered array is a FORTRAN-ordered array.\n\nC-ordered arrays evaluate as False even if they are also FORTRAN-ordered.\n\n"}, {"name": "numpy.isin()", "path": "reference/generated/numpy.isin", "type": "numpy.isin", "text": "\nCalculates `element in test_elements`, broadcasting over `element` only.\nReturns a boolean array of the same shape as `element` that is True where an\nelement of `element` is in `test_elements` and False otherwise.\n\nInput array.\n\nThe values against which to test each value of `element`. This argument is\nflattened if it is an array or array_like. See notes for behavior with non-\narray-like parameters.\n\nIf True, the input arrays are both assumed to be unique, which can speed up\nthe calculation. Default is False.\n\nIf True, the values in the returned array are inverted, as if calculating\n`element not in test_elements`. Default is False. `np.isin(a, b, invert=True)`\nis equivalent to (but faster than) `np.invert(np.isin(a, b))`.\n\nHas the same shape as `element`. The values `element[isin]` are in\n`test_elements`.\n\nSee also\n\nFlattened version of this function.\n\nModule with a number of other functions for performing set operations on\narrays.\n\n`isin` is an element-wise function version of the python keyword `in`.\n`isin(a, b)` is roughly equivalent to `np.array([item in b for item in a])` if\n`a` and `b` are 1-D sequences.\n\n`element` and `test_elements` are converted to arrays if they are not already.\nIf `test_elements` is a set (or other non-sequence collection) it will be\nconverted to an object array with one element, rather than an array of the\nvalues contained in `test_elements`. This is a consequence of the `array`\nconstructor\u2019s way of handling non-sequence collections. Converting the set to\na list usually gives the desired behavior.\n\nNew in version 1.13.0.\n\nThe indices of the matched values can be obtained with `nonzero`:\n\nThe test can also be inverted:\n\nBecause of how `array` handles sets, the following does not work as expected:\n\nCasting the set to a list gives the expected result:\n\n"}, {"name": "numpy.isinf()", "path": "reference/generated/numpy.isinf", "type": "numpy.isinf", "text": "\nTest element-wise for positive or negative infinity.\n\nReturns a boolean array of the same shape as `x`, True where `x == +/-inf`,\notherwise False.\n\nInput values\n\nA location into which the result is stored. If provided, it must have a shape\nthat the inputs broadcast to. If not provided or None, a freshly-allocated\narray is returned. A tuple (possible only as a keyword argument) must have\nlength equal to the number of outputs.\n\nThis condition is broadcast over the input. At locations where the condition\nis True, the `out` array will be set to the ufunc result. Elsewhere, the `out`\narray will retain its original value. Note that if an uninitialized `out`\narray is created via the default `out=None`, locations within it where the\ncondition is False will remain uninitialized.\n\nFor other keyword-only arguments, see the ufunc docs.\n\nTrue where `x` is positive or negative infinity, false otherwise. This is a\nscalar if `x` is a scalar.\n\nSee also\n\nNumPy uses the IEEE Standard for Binary Floating-Point for Arithmetic (IEEE\n754).\n\nErrors result if the second argument is supplied when the first argument is a\nscalar, or if the first and second arguments have different shapes.\n\n"}, {"name": "numpy.isnan()", "path": "reference/generated/numpy.isnan", "type": "numpy.isnan", "text": "\nTest element-wise for NaN and return result as a boolean array.\n\nInput array.\n\nA location into which the result is stored. If provided, it must have a shape\nthat the inputs broadcast to. If not provided or None, a freshly-allocated\narray is returned. A tuple (possible only as a keyword argument) must have\nlength equal to the number of outputs.\n\nThis condition is broadcast over the input. At locations where the condition\nis True, the `out` array will be set to the ufunc result. Elsewhere, the `out`\narray will retain its original value. Note that if an uninitialized `out`\narray is created via the default `out=None`, locations within it where the\ncondition is False will remain uninitialized.\n\nFor other keyword-only arguments, see the ufunc docs.\n\nTrue where `x` is NaN, false otherwise. This is a scalar if `x` is a scalar.\n\nSee also\n\nNumPy uses the IEEE Standard for Binary Floating-Point for Arithmetic (IEEE\n754). This means that Not a Number is not equivalent to infinity.\n\n"}, {"name": "numpy.isnat()", "path": "reference/generated/numpy.isnat", "type": "numpy.isnat", "text": "\nTest element-wise for NaT (not a time) and return result as a boolean array.\n\nNew in version 1.13.0.\n\nInput array with datetime or timedelta data type.\n\nA location into which the result is stored. If provided, it must have a shape\nthat the inputs broadcast to. If not provided or None, a freshly-allocated\narray is returned. A tuple (possible only as a keyword argument) must have\nlength equal to the number of outputs.\n\nThis condition is broadcast over the input. At locations where the condition\nis True, the `out` array will be set to the ufunc result. Elsewhere, the `out`\narray will retain its original value. Note that if an uninitialized `out`\narray is created via the default `out=None`, locations within it where the\ncondition is False will remain uninitialized.\n\nFor other keyword-only arguments, see the ufunc docs.\n\nTrue where `x` is NaT, false otherwise. This is a scalar if `x` is a scalar.\n\nSee also\n\n"}, {"name": "numpy.isneginf()", "path": "reference/generated/numpy.isneginf", "type": "numpy.isneginf", "text": "\nTest element-wise for negative infinity, return result as bool array.\n\nThe input array.\n\nA location into which the result is stored. If provided, it must have a shape\nthat the input broadcasts to. If not provided or None, a freshly-allocated\nboolean array is returned.\n\nA boolean array with the same dimensions as the input. If second argument is\nnot supplied then a numpy boolean array is returned with values True where the\ncorresponding element of the input is negative infinity and values False where\nthe element of the input is not negative infinity.\n\nIf a second argument is supplied the result is stored there. If the type of\nthat array is a numeric type the result is represented as zeros and ones, if\nthe type is boolean then as False and True. The return value `out` is then a\nreference to that array.\n\nSee also\n\nNumPy uses the IEEE Standard for Binary Floating-Point for Arithmetic (IEEE\n754).\n\nErrors result if the second argument is also supplied when x is a scalar\ninput, if first and second arguments have different shapes, or if the first\nargument has complex values.\n\n"}, {"name": "numpy.isposinf()", "path": "reference/generated/numpy.isposinf", "type": "numpy.isposinf", "text": "\nTest element-wise for positive infinity, return result as bool array.\n\nThe input array.\n\nA location into which the result is stored. If provided, it must have a shape\nthat the input broadcasts to. If not provided or None, a freshly-allocated\nboolean array is returned.\n\nA boolean array with the same dimensions as the input. If second argument is\nnot supplied then a boolean array is returned with values True where the\ncorresponding element of the input is positive infinity and values False where\nthe element of the input is not positive infinity.\n\nIf a second argument is supplied the result is stored there. If the type of\nthat array is a numeric type the result is represented as zeros and ones, if\nthe type is boolean then as False and True. The return value `out` is then a\nreference to that array.\n\nSee also\n\nNumPy uses the IEEE Standard for Binary Floating-Point for Arithmetic (IEEE\n754).\n\nErrors result if the second argument is also supplied when x is a scalar\ninput, if first and second arguments have different shapes, or if the first\nargument has complex values\n\n"}, {"name": "numpy.isreal()", "path": "reference/generated/numpy.isreal", "type": "numpy.isreal", "text": "\nReturns a bool array, where True if input element is real.\n\nIf element has complex type with zero complex part, the return value for that\nelement is True.\n\nInput array.\n\nBoolean array of same shape as `x`.\n\nSee also\n\nReturn True if x is not a complex type.\n\n`isreal` may behave unexpectedly for string or object arrays (see examples)\n\nThe function does not work on string arrays.\n\nReturns True for all elements in input array of `dtype=object` even if any of\nthe elements is complex.\n\nisreal should not be used with object arrays\n\n"}, {"name": "numpy.isrealobj()", "path": "reference/generated/numpy.isrealobj", "type": "numpy.isrealobj", "text": "\nReturn True if x is a not complex type or an array of complex numbers.\n\nThe type of the input is checked, not the value. So even if the input has an\nimaginary part equal to zero, `isrealobj` evaluates to False if the data type\nis complex.\n\nThe input can be of any type and shape.\n\nThe return value, False if `x` is of a complex type.\n\nSee also\n\nThe function is only meant for arrays with numerical values but it accepts all\nother objects. Since it assumes array input, the return value of other objects\nmay be True.\n\n"}, {"name": "numpy.isscalar()", "path": "reference/generated/numpy.isscalar", "type": "numpy.isscalar", "text": "\nReturns True if the type of `element` is a scalar type.\n\nInput argument, can be of any type and shape.\n\nTrue if `element` is a scalar type, False if it is not.\n\nSee also\n\nGet the number of dimensions of an array\n\nIf you need a stricter way to identify a numerical scalar, use `isinstance(x,\nnumbers.Number)`, as that returns `False` for most non-numerical elements such\nas strings.\n\nIn most cases `np.ndim(x) == 0` should be used instead of this function, as\nthat will also return true for 0d arrays. This is how numpy overloads\nfunctions in the style of the `dx` arguments to `gradient` and the `bins`\nargument to `histogram`. Some key differences:\n\nx\n\n`isscalar(x)`\n\n`np.ndim(x) == 0`\n\nPEP 3141 numeric objects (including builtins)\n\n`True`\n\n`True`\n\nbuiltin string and buffer objects\n\n`True`\n\n`True`\n\nother builtin objects, like `pathlib.Path`, `Exception`, the result of\n`re.compile`\n\n`False`\n\n`True`\n\nthird-party objects like `matplotlib.figure.Figure`\n\n`False`\n\n`True`\n\nzero-dimensional numpy arrays\n\n`False`\n\n`True`\n\nother numpy arrays\n\n`False`\n\n`False`\n\n`list`, `tuple`, and other sequence objects\n\n`False`\n\n`False`\n\nNumPy supports PEP 3141 numbers:\n\n"}, {"name": "numpy.issctype()", "path": "reference/generated/numpy.issctype", "type": "numpy.issctype", "text": "\nDetermines whether the given object represents a scalar data-type.\n\nIf `rep` is an instance of a scalar dtype, True is returned. If not, False is\nreturned.\n\nBoolean result of check whether `rep` is a scalar dtype.\n\nSee also\n\nStrings are also a scalar type:\n\n"}, {"name": "numpy.issubclass_()", "path": "reference/generated/numpy.issubclass_", "type": "numpy.issubclass_", "text": "\nDetermine if a class is a subclass of a second class.\n\n`issubclass_` is equivalent to the Python built-in `issubclass`, except that\nit returns False instead of raising a TypeError if one of the arguments is not\na class.\n\nInput class. True is returned if `arg1` is a subclass of `arg2`.\n\nInput class. If a tuple of classes, True is returned if `arg1` is a subclass\nof any of the tuple elements.\n\nWhether `arg1` is a subclass of `arg2` or not.\n\nSee also\n\n"}, {"name": "numpy.issubdtype()", "path": "reference/generated/numpy.issubdtype", "type": "numpy.issubdtype", "text": "\nReturns True if first argument is a typecode lower/equal in type hierarchy.\n\nThis is like the builtin `issubclass`, but for `dtype`s.\n\n`dtype` or object coercible to one\n\nSee also\n\nOverview of the numpy type hierarchy.\n\n`issubdtype` can be used to check the type of arrays:\n\nSimilar types of different sizes are not subdtypes of each other:\n\nbut both are subtypes of `floating`:\n\nFor convenience, dtype-like objects are allowed too:\n\n"}, {"name": "numpy.issubsctype()", "path": "reference/generated/numpy.issubsctype", "type": "numpy.issubsctype", "text": "\nDetermine if the first argument is a subclass of the second argument.\n\nData-types.\n\nThe result.\n\nSee also\n\n"}, {"name": "numpy.ix_()", "path": "reference/generated/numpy.ix_", "type": "numpy.ix_", "text": "\nConstruct an open mesh from multiple sequences.\n\nThis function takes N 1-D sequences and returns N outputs with N dimensions\neach, such that the shape is 1 in all but one dimension and the dimension with\nthe non-unit shape value cycles through all N dimensions.\n\nUsing `ix_` one can quickly construct index arrays that will index the cross\nproduct. `a[np.ix_([1,3],[2,5])]` returns the array `[[a[1,2] a[1,5]], [a[3,2]\na[3,5]]]`.\n\nEach sequence should be of integer or boolean type. Boolean sequences will be\ninterpreted as boolean masks for the corresponding dimension (equivalent to\npassing in `np.nonzero(boolean_sequence)`).\n\nN arrays with N dimensions each, with N the number of input sequences.\nTogether these arrays form an open mesh.\n\nSee also\n\n"}, {"name": "numpy.kaiser()", "path": "reference/generated/numpy.kaiser", "type": "numpy.kaiser", "text": "\nReturn the Kaiser window.\n\nThe Kaiser window is a taper formed by using a Bessel function.\n\nNumber of points in the output window. If zero or less, an empty array is\nreturned.\n\nShape parameter for window.\n\nThe window, with the maximum value normalized to one (the value one appears\nonly if the number of samples is odd).\n\nSee also\n\nThe Kaiser window is defined as\n\nwith\n\nwhere \\\\(I_0\\\\) is the modified zeroth-order Bessel function.\n\nThe Kaiser was named for Jim Kaiser, who discovered a simple approximation to\nthe DPSS window based on Bessel functions. The Kaiser window is a very good\napproximation to the Digital Prolate Spheroidal Sequence, or Slepian window,\nwhich is the transform which maximizes the energy in the main lobe of the\nwindow relative to total energy.\n\nThe Kaiser can approximate many other windows by varying the beta parameter.\n\nbeta\n\nWindow shape\n\n0\n\nRectangular\n\n5\n\nSimilar to a Hamming\n\n6\n\nSimilar to a Hanning\n\n8.6\n\nSimilar to a Blackman\n\nA beta value of 14 is probably a good starting point. Note that as beta gets\nlarge, the window narrows, and so the number of samples needs to be large\nenough to sample the increasingly narrow spike, otherwise NaNs will get\nreturned.\n\nMost references to the Kaiser window come from the signal processing\nliterature, where it is used as one of many windowing functions for smoothing\nvalues. It is also known as an apodization (which means \u201cremoving the foot\u201d,\ni.e. smoothing discontinuities at the beginning and end of the sampled signal)\nor tapering function.\n\nJ. F. Kaiser, \u201cDigital Filters\u201d - Ch 7 in \u201cSystems analysis by digital\ncomputer\u201d, Editors: F.F. Kuo and J.F. Kaiser, p 218-285. John Wiley and Sons,\nNew York, (1966).\n\nE.R. Kanasewich, \u201cTime Sequence Analysis in Geophysics\u201d, The University of\nAlberta Press, 1975, pp. 177-178.\n\nWikipedia, \u201cWindow function\u201d, https://en.wikipedia.org/wiki/Window_function\n\nPlot the window and the frequency response:\n\n"}, {"name": "numpy.kron()", "path": "reference/generated/numpy.kron", "type": "numpy.kron", "text": "\nKronecker product of two arrays.\n\nComputes the Kronecker product, a composite array made of blocks of the second\narray scaled by the first.\n\nSee also\n\nThe outer product\n\nThe function assumes that the number of dimensions of `a` and `b` are the\nsame, if necessary prepending the smallest with ones. If `a.shape =\n(r0,r1,..,rN)` and `b.shape = (s0,s1,...,sN)`, the Kronecker product has shape\n`(r0*s0, r1*s1, ..., rN*SN)`. The elements are products of elements from `a`\nand `b`, organized explicitly by:\n\nwhere:\n\nIn the common 2-D case (N=1), the block structure can be visualized:\n\n"}, {"name": "numpy.lcm()", "path": "reference/generated/numpy.lcm", "type": "numpy.lcm", "text": "\nReturns the lowest common multiple of `|x1|` and `|x2|`\n\nArrays of values. If `x1.shape != x2.shape`, they must be broadcastable to a\ncommon shape (which becomes the shape of the output).\n\nThe lowest common multiple of the absolute value of the inputs This is a\nscalar if both `x1` and `x2` are scalars.\n\nSee also\n\nThe greatest common divisor\n\n"}, {"name": "numpy.ldexp()", "path": "reference/generated/numpy.ldexp", "type": "numpy.ldexp", "text": "\nReturns x1 * 2**x2, element-wise.\n\nThe mantissas `x1` and twos exponents `x2` are used to construct floating\npoint numbers `x1 * 2**x2`.\n\nArray of multipliers.\n\nArray of twos exponents. If `x1.shape != x2.shape`, they must be broadcastable\nto a common shape (which becomes the shape of the output).\n\nA location into which the result is stored. If provided, it must have a shape\nthat the inputs broadcast to. If not provided or None, a freshly-allocated\narray is returned. A tuple (possible only as a keyword argument) must have\nlength equal to the number of outputs.\n\nThis condition is broadcast over the input. At locations where the condition\nis True, the `out` array will be set to the ufunc result. Elsewhere, the `out`\narray will retain its original value. Note that if an uninitialized `out`\narray is created via the default `out=None`, locations within it where the\ncondition is False will remain uninitialized.\n\nFor other keyword-only arguments, see the ufunc docs.\n\nThe result of `x1 * 2**x2`. This is a scalar if both `x1` and `x2` are\nscalars.\n\nSee also\n\nReturn (y1, y2) from `x = y1 * 2**y2`, inverse to `ldexp`.\n\nComplex dtypes are not supported, they will raise a TypeError.\n\n`ldexp` is useful as the inverse of `frexp`, if used by itself it is more\nclear to simply use the expression `x1 * 2**x2`.\n\n"}, {"name": "numpy.left_shift()", "path": "reference/generated/numpy.left_shift", "type": "numpy.left_shift", "text": "\nShift the bits of an integer to the left.\n\nBits are shifted to the left by appending `x2` 0s at the right of `x1`. Since\nthe internal representation of numbers is in binary format, this operation is\nequivalent to multiplying `x1` by `2**x2`.\n\nInput values.\n\nNumber of zeros to append to `x1`. Has to be non-negative. If `x1.shape !=\nx2.shape`, they must be broadcastable to a common shape (which becomes the\nshape of the output).\n\nA location into which the result is stored. If provided, it must have a shape\nthat the inputs broadcast to. If not provided or None, a freshly-allocated\narray is returned. A tuple (possible only as a keyword argument) must have\nlength equal to the number of outputs.\n\nThis condition is broadcast over the input. At locations where the condition\nis True, the `out` array will be set to the ufunc result. Elsewhere, the `out`\narray will retain its original value. Note that if an uninitialized `out`\narray is created via the default `out=None`, locations within it where the\ncondition is False will remain uninitialized.\n\nFor other keyword-only arguments, see the ufunc docs.\n\nReturn `x1` with bits shifted `x2` times to the left. This is a scalar if both\n`x1` and `x2` are scalars.\n\nSee also\n\nShift the bits of an integer to the right.\n\nReturn the binary representation of the input number as a string.\n\nNote that the dtype of the second argument may change the dtype of the result\nand can lead to unexpected results in some cases (see Casting Rules):\n\nThe `<<` operator can be used as a shorthand for `np.left_shift` on ndarrays.\n\n"}, {"name": "numpy.less()", "path": "reference/generated/numpy.less", "type": "numpy.less", "text": "\nReturn the truth value of (x1 < x2) element-wise.\n\nInput arrays. If `x1.shape != x2.shape`, they must be broadcastable to a\ncommon shape (which becomes the shape of the output).\n\nA location into which the result is stored. If provided, it must have a shape\nthat the inputs broadcast to. If not provided or None, a freshly-allocated\narray is returned. A tuple (possible only as a keyword argument) must have\nlength equal to the number of outputs.\n\nThis condition is broadcast over the input. At locations where the condition\nis True, the `out` array will be set to the ufunc result. Elsewhere, the `out`\narray will retain its original value. Note that if an uninitialized `out`\narray is created via the default `out=None`, locations within it where the\ncondition is False will remain uninitialized.\n\nFor other keyword-only arguments, see the ufunc docs.\n\nOutput array, element-wise comparison of `x1` and `x2`. Typically of type\nbool, unless `dtype=object` is passed. This is a scalar if both `x1` and `x2`\nare scalars.\n\nSee also\n\nThe `<` operator can be used as a shorthand for `np.less` on ndarrays.\n\n"}, {"name": "numpy.less_equal()", "path": "reference/generated/numpy.less_equal", "type": "numpy.less_equal", "text": "\nReturn the truth value of (x1 <= x2) element-wise.\n\nInput arrays. If `x1.shape != x2.shape`, they must be broadcastable to a\ncommon shape (which becomes the shape of the output).\n\nA location into which the result is stored. If provided, it must have a shape\nthat the inputs broadcast to. If not provided or None, a freshly-allocated\narray is returned. A tuple (possible only as a keyword argument) must have\nlength equal to the number of outputs.\n\nThis condition is broadcast over the input. At locations where the condition\nis True, the `out` array will be set to the ufunc result. Elsewhere, the `out`\narray will retain its original value. Note that if an uninitialized `out`\narray is created via the default `out=None`, locations within it where the\ncondition is False will remain uninitialized.\n\nFor other keyword-only arguments, see the ufunc docs.\n\nOutput array, element-wise comparison of `x1` and `x2`. Typically of type\nbool, unless `dtype=object` is passed. This is a scalar if both `x1` and `x2`\nare scalars.\n\nSee also\n\nThe `<=` operator can be used as a shorthand for `np.less_equal` on ndarrays.\n\n"}, {"name": "numpy.lexsort()", "path": "reference/generated/numpy.lexsort", "type": "numpy.lexsort", "text": "\nPerform an indirect stable sort using a sequence of keys.\n\nGiven multiple sorting keys, which can be interpreted as columns in a\nspreadsheet, lexsort returns an array of integer indices that describes the\nsort order by multiple columns. The last key in the sequence is used for the\nprimary sort order, the second-to-last key for the secondary sort order, and\nso on. The keys argument must be a sequence of objects that can be converted\nto arrays of the same shape. If a 2D array is provided for the keys argument,\nits rows are interpreted as the sorting keys and sorting is according to the\nlast row, second last row etc.\n\nThe `k` different \u201ccolumns\u201d to be sorted. The last column (or row if `keys` is\na 2D array) is the primary sort key.\n\nAxis to be indirectly sorted. By default, sort over the last axis.\n\nArray of indices that sort the keys along the specified axis.\n\nSee also\n\nIndirect sort.\n\nIn-place sort.\n\nReturn a sorted copy of an array.\n\nSort names: first by surname, then by name.\n\nSort two columns of numbers:\n\nNote that sorting is first according to the elements of `a`. Secondary sorting\nis according to the elements of `b`.\n\nA normal `argsort` would have yielded:\n\nStructured arrays are sorted lexically by `argsort`:\n\n"}, {"name": "numpy.lib.arraysetops", "path": "reference/generated/numpy.lib.arraysetops", "type": "numpy.lib.arraysetops", "text": "\nSet operations for arrays based on sorting.\n\nFor floating point arrays, inaccurate results may appear due to usual round-\noff and floating point comparison issues.\n\nSpeed could be gained in some operations by an implementation of `numpy.sort`,\nthat can provide directly the permutation vectors, thus avoiding calls to\n`numpy.argsort`.\n\nOriginal author: Robert Cimrman\n\n"}, {"name": "numpy.lib.Arrayterator()", "path": "reference/generated/numpy.lib.arrayterator", "type": "numpy.lib.Arrayterator", "text": "\nBuffered iterator for big arrays.\n\n`Arrayterator` creates a buffered iterator for reading big arrays in small\ncontiguous blocks. The class is useful for objects stored in the file system.\nIt allows iteration over the object without reading everything in memory;\ninstead, small blocks are read and iterated over.\n\n`Arrayterator` can be used with any object that supports multidimensional\nslices. This includes NumPy arrays, but also variables from\nScientific.IO.NetCDF or pynetcdf for example.\n\nThe object to iterate over.\n\nThe buffer size. If `buf_size` is supplied, the maximum amount of data that\nwill be read into memory is `buf_size` elements. Default is None, which will\nread as many element as possible into memory.\n\nSee also\n\nMultidimensional array iterator.\n\nFlat array iterator.\n\nCreate a memory-map to an array stored in a binary file on disk.\n\nThe algorithm works by first finding a \u201crunning dimension\u201d, along which the\nblocks will be extracted. Given an array of dimensions `(d1, d2, ..., dn)`,\ne.g. if `buf_size` is smaller than `d1`, the first dimension will be used. If,\non the other hand, `d1 < buf_size < d1*d2` the second dimension will be used,\nand so on. Blocks are extracted along this dimension, and when the last block\nis returned the process continues from the next dimension, until all elements\nhave been read.\n\nNow we can iterate over `a_itor`, and it will return arrays of size two. Since\n`buf_size` was smaller than any dimension, the first dimension will be\niterated over first:\n\nThe shape of the array to be iterated over.\n\nA 1-D flat iterator for Arrayterator objects.\n\n"}, {"name": "numpy.lib.mixins.NDArrayOperatorsMixin", "path": "reference/generated/numpy.lib.mixins.ndarrayoperatorsmixin", "type": "numpy.lib.mixins.NDArrayOperatorsMixin", "text": "\nMixin defining all operator special methods using __array_ufunc__.\n\nThis class implements the special methods for almost all of Python\u2019s builtin\noperators defined in the `operator` module, including comparisons (`==`, `>`,\netc.) and arithmetic (`+`, `*`, `-`, etc.), by deferring to the\n`__array_ufunc__` method, which subclasses must implement.\n\nIt is useful for writing classes that do not inherit from `numpy.ndarray`, but\nthat should support arithmetic and numpy universal functions like arrays as\ndescribed in A Mechanism for Overriding Ufuncs.\n\nAs an trivial example, consider this implementation of an `ArrayLike` class\nthat simply wraps a NumPy array and ensures that the result of any arithmetic\noperation is also an `ArrayLike` object:\n\nIn interactions between `ArrayLike` objects and numbers or numpy arrays, the\nresult is always another `ArrayLike`:\n\nNote that unlike `numpy.ndarray`, `ArrayLike` does not allow operations with\narbitrary, unrecognized types. This ensures that interactions with ArrayLike\npreserve a well-defined casting hierarchy.\n\nNew in version 1.13.\n\n"}, {"name": "numpy.lib.NumpyVersion()", "path": "reference/generated/numpy.lib.numpyversion", "type": "numpy.lib.NumpyVersion", "text": "\nParse and compare numpy version strings.\n\nNumPy has the following versioning scheme (numbers given are examples; they\ncan be > 9 in principle):\n\n\u20181.8.0b2.dev-f1234afa\u2019, \u20181.8.1rc1.dev-f1234afa\u2019, etc.\n\nComparing needs to be done against a valid version string or other\n`NumpyVersion` instance. Note that all development versions of the same\n(pre-)release compare equal.\n\nNew in version 1.9.0.\n\nNumPy version string (`np.__version__`).\n\n"}, {"name": "numpy.lib.recfunctions.append_fields()", "path": "user/basics.rec", "type": "User Guide", "text": "\nStructured arrays are ndarrays whose datatype is a composition of simpler\ndatatypes organized as a sequence of named fields. For example,\n\nHere `x` is a one-dimensional array of length two whose datatype is a\nstructure with three fields: 1. A string of length 10 or less named \u2018name\u2019, 2.\na 32-bit integer named \u2018age\u2019, and 3. a 32-bit float named \u2018weight\u2019.\n\nIf you index `x` at position 1 you get a structure:\n\nYou can access and modify individual fields of a structured array by indexing\nwith the field name:\n\nStructured datatypes are designed to be able to mimic \u2018structs\u2019 in the C\nlanguage, and share a similar memory layout. They are meant for interfacing\nwith C code and for low-level manipulation of structured buffers, for example\nfor interpreting binary blobs. For these purposes they support specialized\nfeatures such as subarrays, nested datatypes, and unions, and allow control\nover the memory layout of the structure.\n\nUsers looking to manipulate tabular data, such as stored in csv files, may\nfind other pydata projects more suitable, such as xarray, pandas, or\nDataArray. These provide a high-level interface for tabular data analysis and\nare better optimized for that use. For instance, the C-struct-like memory\nlayout of structured arrays in numpy can lead to poor cache behavior in\ncomparison.\n\nA structured datatype can be thought of as a sequence of bytes of a certain\nlength (the structure\u2019s itemsize) which is interpreted as a collection of\nfields. Each field has a name, a datatype, and a byte offset within the\nstructure. The datatype of a field may be any numpy datatype including other\nstructured datatypes, and it may also be a subarray data type which behaves\nlike an ndarray of a specified shape. The offsets of the fields are arbitrary,\nand fields may even overlap. These offsets are usually determined\nautomatically by numpy, but can also be specified.\n\nStructured datatypes may be created using the function `numpy.dtype`. There\nare 4 alternative forms of specification which vary in flexibility and\nconciseness. These are further documented in the Data Type Objects reference\npage, and in summary they are:\n\nA list of tuples, one tuple per field\n\nEach tuple has the form `(fieldname, datatype, shape)` where shape is\noptional. `fieldname` is a string (or tuple if titles are used, see Field\nTitles below), `datatype` may be any object convertible to a datatype, and\n`shape` is a tuple of integers specifying subarray shape.\n\nIf `fieldname` is the empty string `''`, the field will be given a default\nname of the form `f#`, where `#` is the integer index of the field, counting\nfrom 0 from the left:\n\nThe byte offsets of the fields within the structure and the total structure\nitemsize are determined automatically.\n\nA string of comma-separated dtype specifications\n\nIn this shorthand notation any of the string dtype specifications may be used\nin a string and separated by commas. The itemsize and byte offsets of the\nfields are determined automatically, and the field names are given the default\nnames `f0`, `f1`, etc.\n\nA dictionary of field parameter arrays\n\nThis is the most flexible form of specification since it allows control over\nthe byte-offsets of the fields and the itemsize of the structure.\n\nThe dictionary has two required keys, \u2018names\u2019 and \u2018formats\u2019, and four optional\nkeys, \u2018offsets\u2019, \u2018itemsize\u2019, \u2018aligned\u2019 and \u2018titles\u2019. The values for \u2018names\u2019\nand \u2018formats\u2019 should respectively be a list of field names and a list of dtype\nspecifications, of the same length. The optional \u2018offsets\u2019 value should be a\nlist of integer byte-offsets, one for each field within the structure. If\n\u2018offsets\u2019 is not given the offsets are determined automatically. The optional\n\u2018itemsize\u2019 value should be an integer describing the total size in bytes of\nthe dtype, which must be large enough to contain all the fields.\n\nOffsets may be chosen such that the fields overlap, though this will mean that\nassigning to one field may clobber any overlapping field\u2019s data. As an\nexception, fields of `numpy.object_` type cannot overlap with other fields,\nbecause of the risk of clobbering the internal object pointer and then\ndereferencing it.\n\nThe optional \u2018aligned\u2019 value can be set to `True` to make the automatic offset\ncomputation use aligned offsets (see Automatic Byte Offsets and Alignment), as\nif the \u2018align\u2019 keyword argument of `numpy.dtype` had been set to True.\n\nThe optional \u2018titles\u2019 value should be a list of titles of the same length as\n\u2018names\u2019, see Field Titles below.\n\nA dictionary of field names\n\nThe use of this form of specification is discouraged, but documented here\nbecause older numpy code may use it. The keys of the dictionary are the field\nnames and the values are tuples specifying type and offset:\n\nThis form is discouraged because Python dictionaries do not preserve order in\nPython versions before Python 3.6, and the order of the fields in a structured\ndtype has meaning. Field Titles may be specified by using a 3-tuple, see\nbelow.\n\nThe list of field names of a structured datatype can be found in the `names`\nattribute of the dtype object:\n\nThe field names may be modified by assigning to the `names` attribute using a\nsequence of strings of the same length.\n\nThe dtype object also has a dictionary-like attribute, `fields`, whose keys\nare the field names (and Field Titles, see below) and whose values are tuples\ncontaining the dtype and byte offset of each field.\n\nBoth the `names` and `fields` attributes will equal `None` for unstructured\narrays. The recommended way to test if a dtype is structured is with `if\ndt.names is not None` rather than `if dt.names`, to account for dtypes with 0\nfields.\n\nThe string representation of a structured datatype is shown in the \u201clist of\ntuples\u201d form if possible, otherwise numpy falls back to using the more general\ndictionary form.\n\nNumpy uses one of two methods to automatically determine the field byte\noffsets and the overall itemsize of a structured datatype, depending on\nwhether `align=True` was specified as a keyword argument to `numpy.dtype`.\n\nBy default (`align=False`), numpy will pack the fields together such that each\nfield starts at the byte offset the previous field ended, and the fields are\ncontiguous in memory.\n\nIf `align=True` is set, numpy will pad the structure in the same way many C\ncompilers would pad a C-struct. Aligned structures can give a performance\nimprovement in some cases, at the cost of increased datatype size. Padding\nbytes are inserted between fields such that each field\u2019s byte offset will be a\nmultiple of that field\u2019s alignment, which is usually equal to the field\u2019s size\nin bytes for simple datatypes, see `PyArray_Descr.alignment`. The structure\nwill also have trailing padding added so that its itemsize is a multiple of\nthe largest field\u2019s alignment.\n\nNote that although almost all modern C compilers pad in this way by default,\npadding in C structs is C-implementation-dependent so this memory layout is\nnot guaranteed to exactly match that of a corresponding struct in a C program.\nSome work may be needed, either on the numpy side or the C side, to obtain\nexact correspondence.\n\nIf offsets were specified using the optional `offsets` key in the dictionary-\nbased dtype specification, setting `align=True` will check that each field\u2019s\noffset is a multiple of its size and that the itemsize is a multiple of the\nlargest field size, and raise an exception if not.\n\nIf the offsets of the fields and itemsize of a structured array satisfy the\nalignment conditions, the array will have the `ALIGNED` `flag` set.\n\nA convenience function `numpy.lib.recfunctions.repack_fields` converts an\naligned dtype or array to a packed one and vice versa. It takes either a dtype\nor structured ndarray as an argument, and returns a copy with fields re-\npacked, with or without padding bytes.\n\nIn addition to field names, fields may also have an associated title, an\nalternate name, which is sometimes used as an additional description or alias\nfor the field. The title may be used to index an array, just like a field\nname.\n\nTo add titles when using the list-of-tuples form of dtype specification, the\nfield name may be specified as a tuple of two strings instead of a single\nstring, which will be the field\u2019s title and field name respectively. For\nexample:\n\nWhen using the first form of dictionary-based specification, the titles may be\nsupplied as an extra `'titles'` key as described above. When using the second\n(discouraged) dictionary-based specification, the title can be supplied by\nproviding a 3-element tuple `(datatype, offset, title)` instead of the usual\n2-element tuple:\n\nThe `dtype.fields` dictionary will contain titles as keys, if any titles are\nused. This means effectively that a field with a title will be represented\ntwice in the fields dictionary. The tuple values for these fields will also\nhave a third element, the field title. Because of this, and because the\n`names` attribute preserves the field order while the `fields` attribute may\nnot, it is recommended to iterate through the fields of a dtype using the\n`names` attribute of the dtype, which will not list titles, as in:\n\nStructured datatypes are implemented in numpy to have base type `numpy.void`\nby default, but it is possible to interpret other numpy types as structured\ntypes using the `(base_dtype, dtype)` form of dtype specification described in\nData Type Objects. Here, `base_dtype` is the desired underlying dtype, and\nfields and flags will be copied from `dtype`. This dtype is similar to a\n\u2018union\u2019 in C.\n\nThere are a number of ways to assign values to a structured array: Using\npython tuples, using scalar values, or using other structured arrays.\n\nThe simplest way to assign values to a structured array is using python\ntuples. Each assigned value should be a tuple of length equal to the number of\nfields in the array, and not a list or array as these will trigger numpy\u2019s\nbroadcasting rules. The tuple\u2019s elements are assigned to the successive fields\nof the array, from left to right:\n\nA scalar assigned to a structured element will be assigned to all fields. This\nhappens when a scalar is assigned to a structured array, or when an\nunstructured array is assigned to a structured array:\n\nStructured arrays can also be assigned to unstructured arrays, but only if the\nstructured datatype has just a single field:\n\nAssignment between two structured arrays occurs as if the source elements had\nbeen converted to tuples and then assigned to the destination elements. That\nis, the first field of the source array is assigned to the first field of the\ndestination array, and the second field likewise, and so on, regardless of\nfield names. Structured arrays with a different number of fields cannot be\nassigned to each other. Bytes of the destination structure which are not\nincluded in any of the fields are unaffected.\n\nWhen assigning to fields which are subarrays, the assigned value will first be\nbroadcast to the shape of the subarray.\n\nIndividual fields of a structured array may be accessed and modified by\nindexing the array with the field name.\n\nThe resulting array is a view into the original array. It shares the same\nmemory locations and writing to the view will modify the original array.\n\nThis view has the same dtype and itemsize as the indexed field, so it is\ntypically a non-structured array, except in the case of nested structures.\n\nIf the accessed field is a subarray, the dimensions of the subarray are\nappended to the shape of the result:\n\nOne can index and assign to a structured array with a multi-field index, where\nthe index is a list of field names.\n\nWarning\n\nThe behavior of multi-field indexes changed from Numpy 1.15 to Numpy 1.16.\n\nThe result of indexing with a multi-field index is a view into the original\narray, as follows:\n\nAssignment to the view modifies the original array. The view\u2019s fields will be\nin the order they were indexed. Note that unlike for single-field indexing,\nthe dtype of the view has the same itemsize as the original array, and has\nfields at the same offsets as in the original array, and unindexed fields are\nmerely missing.\n\nWarning\n\nIn Numpy 1.15, indexing an array with a multi-field index returned a copy of\nthe result above, but with fields packed together in memory as if passed\nthrough `numpy.lib.recfunctions.repack_fields`.\n\nThe new behavior as of Numpy 1.16 leads to extra \u201cpadding\u201d bytes at the\nlocation of unindexed fields compared to 1.15. You will need to update any\ncode which depends on the data having a \u201cpacked\u201d layout. For instance code\nsuch as:\n\nwill need to be changed. This code has raised a `FutureWarning` since Numpy\n1.12, and similar code has raised `FutureWarning` since 1.7.\n\nIn 1.16 a number of functions have been introduced in the\n`numpy.lib.recfunctions` module to help users account for this change. These\nare `numpy.lib.recfunctions.repack_fields`.\n`numpy.lib.recfunctions.structured_to_unstructured`,\n`numpy.lib.recfunctions.unstructured_to_structured`,\n`numpy.lib.recfunctions.apply_along_fields`,\n`numpy.lib.recfunctions.assign_fields_by_name`, and\n`numpy.lib.recfunctions.require_fields`.\n\nThe function `numpy.lib.recfunctions.repack_fields` can always be used to\nreproduce the old behavior, as it will return a packed copy of the structured\narray. The code above, for example, can be replaced with:\n\nFurthermore, numpy now provides a new function\n`numpy.lib.recfunctions.structured_to_unstructured` which is a safer and more\nefficient alternative for users who wish to convert structured arrays to\nunstructured arrays, as the view above is often indeded to do. This function\nallows safe conversion to an unstructured type taking into account padding,\noften avoids a copy, and also casts the datatypes as needed, unlike the view.\nCode such as:\n\ncan be made safer by replacing with:\n\nAssignment to an array with a multi-field index modifies the original array:\n\nThis obeys the structured array assignment rules described above. For example,\nthis means that one can swap the values of two fields using appropriate multi-\nfield indexes:\n\nIndexing a single element of a structured array (with an integer index)\nreturns a structured scalar:\n\nUnlike other numpy scalars, structured scalars are mutable and act like views\ninto the original array, such that modifying the scalar will modify the\noriginal array. Structured scalars also support access and assignment by field\nname:\n\nSimilarly to tuples, structured scalars can also be indexed with an integer:\n\nThus, tuples might be thought of as the native Python equivalent to numpy\u2019s\nstructured types, much like native python integers are the equivalent to\nnumpy\u2019s integer types. Structured scalars may be converted to a tuple by\ncalling `numpy.ndarray.item`:\n\nIn order to prevent clobbering object pointers in fields of `object` type,\nnumpy currently does not allow views of structured arrays containing objects.\n\nIf the dtypes of two void structured arrays are equal, testing the equality of\nthe arrays will result in a boolean array with the dimensions of the original\narrays, with elements set to `True` where all fields of the corresponding\nstructures are equal. Structured dtypes are equal if the field names, dtypes\nand titles are the same, ignoring endianness, and the fields are in the same\norder:\n\nCurrently, if the dtypes of two void structured arrays are not equivalent the\ncomparison fails, returning the scalar value `False`. This behavior is\ndeprecated as of numpy 1.10 and will raise an error or perform elementwise\ncomparison in the future.\n\nThe `<` and `>` operators always return `False` when comparing void structured\narrays, and arithmetic and bitwise operations are not supported.\n\nAs an optional convenience numpy provides an ndarray subclass,\n`numpy.recarray` that allows access to fields of structured arrays by\nattribute instead of only by index. Record arrays use a special datatype,\n`numpy.record`, that allows field access by attribute on the structured\nscalars obtained from the array. The `numpy.rec` module provides functions for\ncreating recarrays from various objects. Additional helper functions for\ncreating and manipulating structured arrays can be found in\n`numpy.lib.recfunctions`.\n\nThe simplest way to create a record array is with `numpy.rec.array`:\n\n`numpy.rec.array` can convert a wide variety of arguments into record arrays,\nincluding structured arrays:\n\nThe `numpy.rec` module provides a number of other convenience functions for\ncreating record arrays, see record array creation routines.\n\nA record array representation of a structured array can be obtained using the\nappropriate view:\n\nFor convenience, viewing an ndarray as type `numpy.recarray` will\nautomatically convert to `numpy.record` datatype, so the dtype can be left out\nof the view:\n\nTo get back to a plain ndarray both the dtype and type must be reset. The\nfollowing view does so, taking into account the unusual case that the\nrecordarr was not a structured type:\n\nRecord array fields accessed by index or by attribute are returned as a record\narray if the field has a structured type but as a plain ndarray otherwise.\n\nNote that if a field has the same name as an ndarray attribute, the ndarray\nattribute takes precedence. Such fields will be inaccessible by attribute but\nwill still be accessible by index.\n\nCollection of utilities to manipulate structured arrays.\n\nMost of these functions were initially implemented by John Hunter for\nmatplotlib. They have been rewritten and extended for convenience.\n\nAdd new fields to an existing array.\n\nThe names of the fields are given with the `names` arguments, the\ncorresponding values with the `data` arguments. If a single field is appended,\n`names`, `data` and `dtypes` do not have to be lists but just values.\n\nInput array to extend.\n\nString or sequence of strings corresponding to the names of the new fields.\n\nArray or sequence of arrays storing the fields to add to the base.\n\nDatatype or sequence of datatypes. If None, the datatypes are estimated from\nthe `data`.\n\nFilling value used to pad missing data on the shorter arrays.\n\nWhether to return a masked array or not.\n\nWhether to return a recarray (MaskedRecords) or not.\n\nApply function \u2018func\u2019 as a reduction across fields of a structured array.\n\nThis is similar to `apply_along_axis`, but treats the fields of a structured\narray as an extra axis. The fields are all first cast to a common type\nfollowing the type-promotion rules from `numpy.result_type` applied to the\nfield\u2019s dtypes.\n\nFunction to apply on the \u201cfield\u201d dimension. This function must support an\n`axis` argument, like np.mean, np.sum, etc.\n\nStructured array for which to apply func.\n\nResult of the recution operation\n\nAssigns values from one structured array to another by field name.\n\nNormally in numpy >= 1.14, assignment of one structured array to another\ncopies fields \u201cby position\u201d, meaning that the first field from the src is\ncopied to the first field of the dst, and so on, regardless of field name.\n\nThis function instead copies \u201cby field name\u201d, such that fields in the dst are\nassigned from the identically named field in the src. This applies recursively\nfor nested structures. This is how structure assignment worked in numpy >= 1.6\nto <= 1.13.\n\nThe source and destination arrays during assignment.\n\nIf True, fields in the dst for which there was no matching field in the src\nare filled with the value 0 (zero). This was the behavior of numpy <= 1.13. If\nFalse, those fields are not modified.\n\nReturn a new array with fields in `drop_names` dropped.\n\nNested fields are supported.\n\nChanged in version 1.18.0: `drop_fields` returns an array with 0 fields if all\nfields are dropped, rather than returning `None` as it did previously.\n\nInput array\n\nString or sequence of strings corresponding to the names of the fields to\ndrop.\n\nWhether to return a masked array or not.\n\nWhether to return a recarray or a mrecarray (`asrecarray=True`) or a plain\nndarray or masked array with flexible dtype. The default is False.\n\nFind the duplicates in a structured array along a given key\n\nInput array\n\nName of the fields along which to check the duplicates. If None, the search is\nperformed by records\n\nWhether masked data should be discarded or considered as duplicates.\n\nWhether to return the indices of the duplicated values.\n\nFlatten a structured data-type description.\n\nReturns a dictionary with fields indexing lists of their parent fields.\n\nThis function is used to simplify access to fields nested in other fields.\n\nInput datatype\n\nLast processed field name (used internally during recursion).\n\nDictionary of parent fields (used interbally during recursion).\n\nReturns the field names of the input datatype as a tuple.\n\nInput datatype\n\nReturns the field names of the input datatype as a tuple. Nested structure are\nflattened beforehand.\n\nInput datatype\n\nJoin arrays `r1` and `r2` on key `key`.\n\nThe key should be either a string or a sequence of string corresponding to the\nfields used to join the array. An exception is raised if the `key` field\ncannot be found in the two input arrays. Neither `r1` nor `r2` should have any\nduplicates along `key`: the presence of duplicates will make the output quite\nunreliable. Note that duplicates are not looked for by the algorithm.\n\nA string or a sequence of strings corresponding to the fields used for\ncomparison.\n\nStructured arrays.\n\nIf \u2018inner\u2019, returns the elements common to both r1 and r2. If \u2018outer\u2019, returns\nthe common elements as well as the elements of r1 not in r2 and the elements\nof not in r2. If \u2018leftouter\u2019, returns the common elements and the elements of\nr1 not in r2.\n\nString appended to the names of the fields of r1 that are present in r2 but\nabsent of the key.\n\nString appended to the names of the fields of r2 that are present in r1 but\nabsent of the key.\n\nDictionary mapping field names to the corresponding default values.\n\nWhether to return a MaskedArray (or MaskedRecords is `asrecarray==True`) or a\nndarray.\n\nWhether to return a recarray (or MaskedRecords if `usemask==True`) or just a\nflexible-type ndarray.\n\nMerge arrays field by field.\n\nSequence of arrays\n\nFilling value used to pad missing data on the shorter arrays.\n\nWhether to collapse nested fields.\n\nWhether to return a masked array or not.\n\nWhether to return a recarray (MaskedRecords) or not.\n\nWithout a mask, the missing value will be filled with something, depending on\nwhat its corresponding type:\n\nAdd new fields to an existing array.\n\nThe names of the fields are given with the `names` arguments, the\ncorresponding values with the `data` arguments. If a single field is appended,\n`names`, `data` and `dtypes` do not have to be lists but just values.\n\nInput array to extend.\n\nString or sequence of strings corresponding to the names of the new fields.\n\nArray or sequence of arrays storing the fields to add to the base.\n\nDatatype or sequence of datatypes. If None, the datatypes are estimated from\nthe `data`.\n\nSee also\n\nReturns a new numpy.recarray with fields in `drop_names` dropped.\n\nJoin arrays `r1` and `r2` on keys. Alternative to join_by, that always returns\na np.recarray.\n\nSee also\n\nequivalent function\n\nFills fields from output with fields from input, with support for nested\nstructures.\n\nInput array.\n\nOutput array.\n\nRename the fields from a flexible-datatype ndarray or recarray.\n\nNested fields are supported.\n\nInput array whose fields must be modified.\n\nDictionary mapping old field names to their new version.\n\nRe-pack the fields of a structured array or dtype in memory.\n\nThe memory layout of structured datatypes allows fields at arbitrary byte\noffsets. This means the fields can be separated by padding bytes, their\noffsets can be non-monotonically increasing, and they can overlap.\n\nThis method removes any overlaps and reorders the fields in memory so they\nhave increasing byte offsets, and adds or removes padding bytes depending on\nthe `align` option, which behaves like the `align` option to `np.dtype`.\n\nIf `align=False`, this method produces a \u201cpacked\u201d memory layout in which each\nfield starts at the byte the previous field ended, and any padding bytes are\nremoved.\n\nIf `align=True`, this methods produces an \u201caligned\u201d memory layout in which\neach field\u2019s offset is a multiple of its alignment, and the total itemsize is\na multiple of the largest alignment, by adding padding bytes as needed.\n\narray or dtype for which to repack the fields.\n\nIf true, use an \u201caligned\u201d memory layout, otherwise use a \u201cpacked\u201d layout.\n\nIf True, also repack nested structures.\n\nCopy of `a` with fields repacked, or `a` itself if no repacking was needed.\n\nCasts a structured array to a new dtype using assignment by field-name.\n\nThis function assigns from the old to the new array by name, so the value of a\nfield in the output array is the value of the field with the same name in the\nsource array. This has the effect of creating a new ndarray containing only\nthe fields \u201crequired\u201d by the required_dtype.\n\nIf a field name in the required_dtype does not exist in the input array, that\nfield is created and set to 0 in the output array.\n\narray to cast\n\ndatatype for output array\n\narray with the new dtype, with field values copied from the fields in the\ninput array with the same name\n\nSuperposes arrays fields by fields\n\nSequence of input arrays.\n\nDictionary mapping field names to the corresponding default values.\n\nWhether to return a MaskedArray (or MaskedRecords is `asrecarray==True`) or a\nndarray.\n\nWhether to return a recarray (or MaskedRecords if `usemask==True`) or just a\nflexible-type ndarray.\n\nWhether automatically cast the type of the field to the maximum.\n\nConverts an n-D structured array into an (n+1)-D unstructured array.\n\nThe new array will have a new last dimension equal in size to the number of\nfield-elements of the input array. If not supplied, the output datatype is\ndetermined from the numpy type promotion rules applied to all the field\ndatatypes.\n\nNested fields, as well as each element of any subarray fields, all count as a\nsingle field-elements.\n\nStructured array or dtype to convert. Cannot contain object datatype.\n\nThe dtype of the output unstructured array.\n\nSee copy argument to `ndarray.astype`. If true, always return a copy. If\nfalse, and `dtype` requirements are satisfied, a view is returned.\n\nSee casting argument of `ndarray.astype`. Controls what kind of data casting\nmay occur.\n\nUnstructured array with one more dimension.\n\nConverts an n-D unstructured array into an (n-1)-D structured array.\n\nThe last dimension of the input array is converted into a structure, with\nnumber of field-elements equal to the size of the last dimension of the input\narray. By default all output fields have the input array\u2019s dtype, but an\noutput structured dtype with an equal number of fields-elements can be\nsupplied instead.\n\nNested fields, as well as each element of any subarray fields, all count\ntowards the number of field-elements.\n\nUnstructured array or dtype to convert.\n\nThe structured dtype of the output array\n\nIf dtype is not supplied, this specifies the field names for the output dtype,\nin order. The field dtypes will be the same as the input array.\n\nWhether to create an aligned memory layout.\n\nSee copy argument to `ndarray.astype`. If true, always return a copy. If\nfalse, and `dtype` requirements are satisfied, a view is returned.\n\nSee casting argument of `ndarray.astype`. Controls what kind of data casting\nmay occur.\n\nStructured array with fewer dimensions.\n\n"}, {"name": "numpy.lib.recfunctions.apply_along_fields()", "path": "user/basics.rec#numpy.lib.recfunctions.apply_along_fields", "type": "User Guide", "text": "\nApply function \u2018func\u2019 as a reduction across fields of a structured array.\n\nThis is similar to `apply_along_axis`, but treats the fields of a structured\narray as an extra axis. The fields are all first cast to a common type\nfollowing the type-promotion rules from `numpy.result_type` applied to the\nfield\u2019s dtypes.\n\nFunction to apply on the \u201cfield\u201d dimension. This function must support an\n`axis` argument, like np.mean, np.sum, etc.\n\nStructured array for which to apply func.\n\nResult of the recution operation\n\n"}, {"name": "numpy.lib.recfunctions.assign_fields_by_name()", "path": "user/basics.rec#numpy.lib.recfunctions.assign_fields_by_name", "type": "User Guide", "text": "\nAssigns values from one structured array to another by field name.\n\nNormally in numpy >= 1.14, assignment of one structured array to another\ncopies fields \u201cby position\u201d, meaning that the first field from the src is\ncopied to the first field of the dst, and so on, regardless of field name.\n\nThis function instead copies \u201cby field name\u201d, such that fields in the dst are\nassigned from the identically named field in the src. This applies recursively\nfor nested structures. This is how structure assignment worked in numpy >= 1.6\nto <= 1.13.\n\nThe source and destination arrays during assignment.\n\nIf True, fields in the dst for which there was no matching field in the src\nare filled with the value 0 (zero). This was the behavior of numpy <= 1.13. If\nFalse, those fields are not modified.\n\n"}, {"name": "numpy.lib.recfunctions.drop_fields()", "path": "user/basics.rec#numpy.lib.recfunctions.drop_fields", "type": "User Guide", "text": "\nReturn a new array with fields in `drop_names` dropped.\n\nNested fields are supported.\n\nChanged in version 1.18.0: `drop_fields` returns an array with 0 fields if all\nfields are dropped, rather than returning `None` as it did previously.\n\nInput array\n\nString or sequence of strings corresponding to the names of the fields to\ndrop.\n\nWhether to return a masked array or not.\n\nWhether to return a recarray or a mrecarray (`asrecarray=True`) or a plain\nndarray or masked array with flexible dtype. The default is False.\n\n"}, {"name": "numpy.lib.recfunctions.find_duplicates()", "path": "user/basics.rec#numpy.lib.recfunctions.find_duplicates", "type": "User Guide", "text": "\nFind the duplicates in a structured array along a given key\n\nInput array\n\nName of the fields along which to check the duplicates. If None, the search is\nperformed by records\n\nWhether masked data should be discarded or considered as duplicates.\n\nWhether to return the indices of the duplicated values.\n\n"}, {"name": "numpy.lib.recfunctions.flatten_descr()", "path": "user/basics.rec#numpy.lib.recfunctions.flatten_descr", "type": "User Guide", "text": "\nFlatten a structured data-type description.\n\n"}, {"name": "numpy.lib.recfunctions.get_fieldstructure()", "path": "user/basics.rec#numpy.lib.recfunctions.get_fieldstructure", "type": "User Guide", "text": "\nReturns a dictionary with fields indexing lists of their parent fields.\n\nThis function is used to simplify access to fields nested in other fields.\n\nInput datatype\n\nLast processed field name (used internally during recursion).\n\nDictionary of parent fields (used interbally during recursion).\n\n"}, {"name": "numpy.lib.recfunctions.get_names()", "path": "user/basics.rec#numpy.lib.recfunctions.get_names", "type": "User Guide", "text": "\nReturns the field names of the input datatype as a tuple.\n\nInput datatype\n\n"}, {"name": "numpy.lib.recfunctions.get_names_flat()", "path": "user/basics.rec#numpy.lib.recfunctions.get_names_flat", "type": "User Guide", "text": "\nReturns the field names of the input datatype as a tuple. Nested structure are\nflattened beforehand.\n\nInput datatype\n\n"}, {"name": "numpy.lib.recfunctions.join_by()", "path": "user/basics.rec#numpy.lib.recfunctions.join_by", "type": "User Guide", "text": "\nJoin arrays `r1` and `r2` on key `key`.\n\nThe key should be either a string or a sequence of string corresponding to the\nfields used to join the array. An exception is raised if the `key` field\ncannot be found in the two input arrays. Neither `r1` nor `r2` should have any\nduplicates along `key`: the presence of duplicates will make the output quite\nunreliable. Note that duplicates are not looked for by the algorithm.\n\nA string or a sequence of strings corresponding to the fields used for\ncomparison.\n\nStructured arrays.\n\nIf \u2018inner\u2019, returns the elements common to both r1 and r2. If \u2018outer\u2019, returns\nthe common elements as well as the elements of r1 not in r2 and the elements\nof not in r2. If \u2018leftouter\u2019, returns the common elements and the elements of\nr1 not in r2.\n\nString appended to the names of the fields of r1 that are present in r2 but\nabsent of the key.\n\nString appended to the names of the fields of r2 that are present in r1 but\nabsent of the key.\n\nDictionary mapping field names to the corresponding default values.\n\nWhether to return a MaskedArray (or MaskedRecords is `asrecarray==True`) or a\nndarray.\n\nWhether to return a recarray (or MaskedRecords if `usemask==True`) or just a\nflexible-type ndarray.\n\n"}, {"name": "numpy.lib.recfunctions.merge_arrays()", "path": "user/basics.rec#numpy.lib.recfunctions.merge_arrays", "type": "User Guide", "text": "\nMerge arrays field by field.\n\nSequence of arrays\n\nFilling value used to pad missing data on the shorter arrays.\n\nWhether to collapse nested fields.\n\nWhether to return a masked array or not.\n\nWhether to return a recarray (MaskedRecords) or not.\n\nWithout a mask, the missing value will be filled with something, depending on\nwhat its corresponding type:\n\n"}, {"name": "numpy.lib.recfunctions.rec_append_fields()", "path": "user/basics.rec#numpy.lib.recfunctions.rec_append_fields", "type": "User Guide", "text": "\nAdd new fields to an existing array.\n\nThe names of the fields are given with the `names` arguments, the\ncorresponding values with the `data` arguments. If a single field is appended,\n`names`, `data` and `dtypes` do not have to be lists but just values.\n\nInput array to extend.\n\nString or sequence of strings corresponding to the names of the new fields.\n\nArray or sequence of arrays storing the fields to add to the base.\n\nDatatype or sequence of datatypes. If None, the datatypes are estimated from\nthe `data`.\n\nSee also\n\n"}, {"name": "numpy.lib.recfunctions.rec_drop_fields()", "path": "user/basics.rec#numpy.lib.recfunctions.rec_drop_fields", "type": "User Guide", "text": "\nReturns a new numpy.recarray with fields in `drop_names` dropped.\n\n"}, {"name": "numpy.lib.recfunctions.rec_join()", "path": "user/basics.rec#numpy.lib.recfunctions.rec_join", "type": "User Guide", "text": "\nJoin arrays `r1` and `r2` on keys. Alternative to join_by, that always returns\na np.recarray.\n\nSee also\n\nequivalent function\n\n"}, {"name": "numpy.lib.recfunctions.recursive_fill_fields()", "path": "user/basics.rec#numpy.lib.recfunctions.recursive_fill_fields", "type": "User Guide", "text": "\nFills fields from output with fields from input, with support for nested\nstructures.\n\nInput array.\n\nOutput array.\n\n"}, {"name": "numpy.lib.recfunctions.rename_fields()", "path": "user/basics.rec#numpy.lib.recfunctions.rename_fields", "type": "User Guide", "text": "\nRename the fields from a flexible-datatype ndarray or recarray.\n\nNested fields are supported.\n\nInput array whose fields must be modified.\n\nDictionary mapping old field names to their new version.\n\n"}, {"name": "numpy.lib.recfunctions.repack_fields()", "path": "user/basics.rec#numpy.lib.recfunctions.repack_fields", "type": "User Guide", "text": "\nRe-pack the fields of a structured array or dtype in memory.\n\nThe memory layout of structured datatypes allows fields at arbitrary byte\noffsets. This means the fields can be separated by padding bytes, their\noffsets can be non-monotonically increasing, and they can overlap.\n\nThis method removes any overlaps and reorders the fields in memory so they\nhave increasing byte offsets, and adds or removes padding bytes depending on\nthe `align` option, which behaves like the `align` option to `np.dtype`.\n\nIf `align=False`, this method produces a \u201cpacked\u201d memory layout in which each\nfield starts at the byte the previous field ended, and any padding bytes are\nremoved.\n\nIf `align=True`, this methods produces an \u201caligned\u201d memory layout in which\neach field\u2019s offset is a multiple of its alignment, and the total itemsize is\na multiple of the largest alignment, by adding padding bytes as needed.\n\narray or dtype for which to repack the fields.\n\nIf true, use an \u201caligned\u201d memory layout, otherwise use a \u201cpacked\u201d layout.\n\nIf True, also repack nested structures.\n\nCopy of `a` with fields repacked, or `a` itself if no repacking was needed.\n\n"}, {"name": "numpy.lib.recfunctions.require_fields()", "path": "user/basics.rec#numpy.lib.recfunctions.require_fields", "type": "User Guide", "text": "\nCasts a structured array to a new dtype using assignment by field-name.\n\nThis function assigns from the old to the new array by name, so the value of a\nfield in the output array is the value of the field with the same name in the\nsource array. This has the effect of creating a new ndarray containing only\nthe fields \u201crequired\u201d by the required_dtype.\n\nIf a field name in the required_dtype does not exist in the input array, that\nfield is created and set to 0 in the output array.\n\narray to cast\n\ndatatype for output array\n\narray with the new dtype, with field values copied from the fields in the\ninput array with the same name\n\n"}, {"name": "numpy.lib.recfunctions.stack_arrays()", "path": "user/basics.rec#numpy.lib.recfunctions.stack_arrays", "type": "User Guide", "text": "\nSuperposes arrays fields by fields\n\nSequence of input arrays.\n\nDictionary mapping field names to the corresponding default values.\n\nWhether to return a MaskedArray (or MaskedRecords is `asrecarray==True`) or a\nndarray.\n\nWhether to return a recarray (or MaskedRecords if `usemask==True`) or just a\nflexible-type ndarray.\n\nWhether automatically cast the type of the field to the maximum.\n\n"}, {"name": "numpy.lib.recfunctions.structured_to_unstructured()", "path": "user/basics.rec#numpy.lib.recfunctions.structured_to_unstructured", "type": "User Guide", "text": "\nConverts an n-D structured array into an (n+1)-D unstructured array.\n\nThe new array will have a new last dimension equal in size to the number of\nfield-elements of the input array. If not supplied, the output datatype is\ndetermined from the numpy type promotion rules applied to all the field\ndatatypes.\n\nNested fields, as well as each element of any subarray fields, all count as a\nsingle field-elements.\n\nStructured array or dtype to convert. Cannot contain object datatype.\n\nThe dtype of the output unstructured array.\n\nSee copy argument to `ndarray.astype`. If true, always return a copy. If\nfalse, and `dtype` requirements are satisfied, a view is returned.\n\nSee casting argument of `ndarray.astype`. Controls what kind of data casting\nmay occur.\n\nUnstructured array with one more dimension.\n\n"}, {"name": "numpy.lib.recfunctions.unstructured_to_structured()", "path": "user/basics.rec#numpy.lib.recfunctions.unstructured_to_structured", "type": "User Guide", "text": "\nConverts an n-D unstructured array into an (n-1)-D structured array.\n\nThe last dimension of the input array is converted into a structure, with\nnumber of field-elements equal to the size of the last dimension of the input\narray. By default all output fields have the input array\u2019s dtype, but an\noutput structured dtype with an equal number of fields-elements can be\nsupplied instead.\n\nNested fields, as well as each element of any subarray fields, all count\ntowards the number of field-elements.\n\nUnstructured array or dtype to convert.\n\nThe structured dtype of the output array\n\nIf dtype is not supplied, this specifies the field names for the output dtype,\nin order. The field dtypes will be the same as the input array.\n\nWhether to create an aligned memory layout.\n\nSee copy argument to `ndarray.astype`. If true, always return a copy. If\nfalse, and `dtype` requirements are satisfied, a view is returned.\n\nSee casting argument of `ndarray.astype`. Controls what kind of data casting\nmay occur.\n\nStructured array with fewer dimensions.\n\n"}, {"name": "numpy.lib.user_array.container()", "path": "reference/generated/numpy.lib.user_array.container", "type": "numpy.lib.user_array.container", "text": "\nStandard container-class for easy multiple-inheritance.\n\ncopy\n\ntostring\n\nbyteswap\n\nastype\n\n"}, {"name": "numpy.linspace()", "path": "reference/generated/numpy.linspace", "type": "numpy.linspace", "text": "\nReturn evenly spaced numbers over a specified interval.\n\nReturns `num` evenly spaced samples, calculated over the interval [`start`,\n`stop`].\n\nThe endpoint of the interval can optionally be excluded.\n\nChanged in version 1.16.0: Non-scalar `start` and `stop` are now supported.\n\nChanged in version 1.20.0: Values are rounded towards `-inf` instead of `0`\nwhen an integer `dtype` is specified. The old behavior can still be obtained\nwith `np.linspace(start, stop, num).astype(int)`\n\nThe starting value of the sequence.\n\nThe end value of the sequence, unless `endpoint` is set to False. In that\ncase, the sequence consists of all but the last of `num + 1` evenly spaced\nsamples, so that `stop` is excluded. Note that the step size changes when\n`endpoint` is False.\n\nNumber of samples to generate. Default is 50. Must be non-negative.\n\nIf True, `stop` is the last sample. Otherwise, it is not included. Default is\nTrue.\n\nIf True, return (`samples`, `step`), where `step` is the spacing between\nsamples.\n\nThe type of the output array. If `dtype` is not given, the data type is\ninferred from `start` and `stop`. The inferred dtype will never be an integer;\n`float` is chosen even if the arguments would produce an array of integers.\n\nNew in version 1.9.0.\n\nThe axis in the result to store the samples. Relevant only if start or stop\nare array-like. By default (0), the samples will be along a new axis inserted\nat the beginning. Use -1 to get an axis at the end.\n\nNew in version 1.16.0.\n\nThere are `num` equally spaced samples in the closed interval `[start, stop]`\nor the half-open interval `[start, stop)` (depending on whether `endpoint` is\nTrue or False).\n\nOnly returned if `retstep` is True\n\nSize of spacing between samples.\n\nSee also\n\nSimilar to `linspace`, but uses a step size (instead of the number of\nsamples).\n\nSimilar to `linspace`, but with numbers spaced evenly on a log scale (a\ngeometric progression).\n\nSimilar to `geomspace`, but with the end points specified as logarithms.\n\nGraphical illustration:\n\n"}, {"name": "numpy.load()", "path": "reference/generated/numpy.load", "type": "numpy.load", "text": "\nLoad arrays or pickled objects from `.npy`, `.npz` or pickled files.\n\nWarning\n\nLoading files that contain object arrays uses the `pickle` module, which is\nnot secure against erroneous or maliciously constructed data. Consider passing\n`allow_pickle=False` to load data that is known not to contain object arrays\nfor the safer handling of untrusted sources.\n\nThe file to read. File-like objects must support the `seek()` and `read()`\nmethods. Pickled files require that the file-like object support the\n`readline()` method as well.\n\nIf not None, then memory-map the file, using the given mode (see\n`numpy.memmap` for a detailed description of the modes). A memory-mapped array\nis kept on disk. However, it can be accessed and sliced like any ndarray.\nMemory mapping is especially useful for accessing small fragments of large\nfiles without reading the entire file into memory.\n\nAllow loading pickled object arrays stored in npy files. Reasons for\ndisallowing pickles include security, as loading pickled data can execute\narbitrary code. If pickles are disallowed, loading object arrays will fail.\nDefault: False\n\nChanged in version 1.16.3: Made default False in response to CVE-2019-6446.\n\nOnly useful when loading Python 2 generated pickled files on Python 3, which\nincludes npy/npz files containing object arrays. If `fix_imports` is True,\npickle will try to map the old Python 2 names to the new names used in Python\n3.\n\nWhat encoding to use when reading Python 2 strings. Only useful when loading\nPython 2 generated pickled files in Python 3, which includes npy/npz files\ncontaining object arrays. Values other than \u2018latin1\u2019, \u2018ASCII\u2019, and \u2018bytes\u2019 are\nnot allowed, as they can corrupt numerical data. Default: \u2018ASCII\u2019\n\nData stored in the file. For `.npz` files, the returned instance of NpzFile\nclass must be closed to avoid leaking file descriptors.\n\nIf the input file does not exist or cannot be read.\n\nIf `allow_pickle=True`, but the file cannot be loaded as a pickle.\n\nThe file contains an object array, but `allow_pickle=False` given.\n\nSee also\n\nCreate a memory-map to an array stored in a file on disk.\n\nCreate or load a memory-mapped `.npy` file.\n\nIf the file is a `.npz` file, the returned value supports the context manager\nprotocol in a similar fashion to the open function:\n\nThe underlying file descriptor is closed when exiting the \u2018with\u2019 block.\n\nStore data to disk, and load it again:\n\nStore compressed data to disk, and load it again:\n\nMem-map the stored array, and then access the second row directly from disk:\n\n"}, {"name": "numpy.loadtxt()", "path": "reference/generated/numpy.loadtxt", "type": "numpy.loadtxt", "text": "\nLoad data from a text file.\n\nEach row in the text file must have the same number of values.\n\nFile, filename, list, or generator to read. If the filename extension is `.gz`\nor `.bz2`, the file is first decompressed. Note that generators must return\nbytes or strings. The strings in a list or produced by a generator are treated\nas lines.\n\nData-type of the resulting array; default: float. If this is a structured\ndata-type, the resulting array will be 1-dimensional, and each row will be\ninterpreted as an element of the array. In this case, the number of columns\nused must match the number of fields in the data-type.\n\nThe characters or list of characters used to indicate the start of a comment.\nNone implies no comments. For backwards compatibility, byte strings will be\ndecoded as \u2018latin1\u2019. The default is \u2018#\u2019.\n\nThe string used to separate values. For backwards compatibility, byte strings\nwill be decoded as \u2018latin1\u2019. The default is whitespace.\n\nA dictionary mapping column number to a function that will parse the column\nstring into the desired value. E.g., if column 0 is a date string: `converters\n= {0: datestr2num}`. Converters can also be used to provide a default value\nfor missing data (but see also `genfromtxt`): `converters = {3: lambda s:\nfloat(s.strip() or 0)}`. Default: None.\n\nSkip the first `skiprows` lines, including comments; default: 0.\n\nWhich columns to read, with 0 being the first. For example, `usecols =\n(1,4,5)` will extract the 2nd, 5th and 6th columns. The default, None, results\nin all columns being read.\n\nChanged in version 1.11.0: When a single column has to be read it is possible\nto use an integer instead of a tuple. E.g `usecols = 3` reads the fourth\ncolumn the same way as `usecols = (3,)` would.\n\nIf True, the returned array is transposed, so that arguments may be unpacked\nusing `x, y, z = loadtxt(...)`. When used with a structured data-type, arrays\nare returned for each field. Default is False.\n\nThe returned array will have at least `ndmin` dimensions. Otherwise mono-\ndimensional axes will be squeezed. Legal values: 0 (default), 1 or 2.\n\nNew in version 1.6.0.\n\nEncoding used to decode the inputfile. Does not apply to input streams. The\nspecial value \u2018bytes\u2019 enables backward compatibility workarounds that ensures\nyou receive byte arrays as results if possible and passes \u2018latin1\u2019 encoded\nstrings to converters. Override this value to receive unicode arrays and pass\nstrings as input to converters. If set to None the system default is used. The\ndefault value is \u2018bytes\u2019.\n\nNew in version 1.14.0.\n\nRead `max_rows` lines of content after `skiprows` lines. The default is to\nread all the lines.\n\nNew in version 1.16.0.\n\nReference object to allow the creation of arrays which are not NumPy arrays.\nIf an array-like passed in as `like` supports the `__array_function__`\nprotocol, the result will be defined by it. In this case, it ensures the\ncreation of an array object compatible with that passed in via this argument.\n\nNew in version 1.20.0.\n\nData read from the text file.\n\nSee also\n\nLoad data with missing values handled as specified.\n\nreads MATLAB data files\n\nThis function aims to be a fast reader for simply formatted files. The\n`genfromtxt` function provides more sophisticated handling of, e.g., lines\nwith missing values.\n\nNew in version 1.10.0.\n\nThe strings produced by the Python float.hex method can be used as input for\nfloats.\n\nThis example shows how `converters` can be used to convert a field with a\ntrailing minus sign into a negative number.\n\n"}, {"name": "numpy.log()", "path": "reference/generated/numpy.log", "type": "numpy.log", "text": "\nNatural logarithm, element-wise.\n\nThe natural logarithm `log` is the inverse of the exponential function, so\nthat `log(exp(x)) = x`. The natural logarithm is logarithm in base `e`.\n\nInput value.\n\nA location into which the result is stored. If provided, it must have a shape\nthat the inputs broadcast to. If not provided or None, a freshly-allocated\narray is returned. A tuple (possible only as a keyword argument) must have\nlength equal to the number of outputs.\n\nThis condition is broadcast over the input. At locations where the condition\nis True, the `out` array will be set to the ufunc result. Elsewhere, the `out`\narray will retain its original value. Note that if an uninitialized `out`\narray is created via the default `out=None`, locations within it where the\ncondition is False will remain uninitialized.\n\nFor other keyword-only arguments, see the ufunc docs.\n\nThe natural logarithm of `x`, element-wise. This is a scalar if `x` is a\nscalar.\n\nSee also\n\nLogarithm is a multivalued function: for each `x` there is an infinite number\nof `z` such that `exp(z) = x`. The convention is to return the `z` whose\nimaginary part lies in `[-pi, pi]`.\n\nFor real-valued input data types, `log` always returns real output. For each\nvalue that cannot be expressed as a real number or infinity, it yields `nan`\nand sets the `invalid` floating point error flag.\n\nFor complex-valued input, `log` is a complex analytical function that has a\nbranch cut `[-inf, 0]` and is continuous from above on it. `log` handles the\nfloating-point negative zero as an infinitesimal negative number, conforming\nto the C99 standard.\n\nM. Abramowitz and I.A. Stegun, \u201cHandbook of Mathematical Functions\u201d, 10th\nprinting, 1964, pp. 67. https://personal.math.ubc.ca/~cbm/aands/page_67.htm\n\nWikipedia, \u201cLogarithm\u201d. https://en.wikipedia.org/wiki/Logarithm\n\n"}, {"name": "numpy.log10()", "path": "reference/generated/numpy.log10", "type": "numpy.log10", "text": "\nReturn the base 10 logarithm of the input array, element-wise.\n\nInput values.\n\nA location into which the result is stored. If provided, it must have a shape\nthat the inputs broadcast to. If not provided or None, a freshly-allocated\narray is returned. A tuple (possible only as a keyword argument) must have\nlength equal to the number of outputs.\n\nThis condition is broadcast over the input. At locations where the condition\nis True, the `out` array will be set to the ufunc result. Elsewhere, the `out`\narray will retain its original value. Note that if an uninitialized `out`\narray is created via the default `out=None`, locations within it where the\ncondition is False will remain uninitialized.\n\nFor other keyword-only arguments, see the ufunc docs.\n\nThe logarithm to the base 10 of `x`, element-wise. NaNs are returned where x\nis negative. This is a scalar if `x` is a scalar.\n\nSee also\n\nLogarithm is a multivalued function: for each `x` there is an infinite number\nof `z` such that `10**z = x`. The convention is to return the `z` whose\nimaginary part lies in `[-pi, pi]`.\n\nFor real-valued input data types, `log10` always returns real output. For each\nvalue that cannot be expressed as a real number or infinity, it yields `nan`\nand sets the `invalid` floating point error flag.\n\nFor complex-valued input, `log10` is a complex analytical function that has a\nbranch cut `[-inf, 0]` and is continuous from above on it. `log10` handles the\nfloating-point negative zero as an infinitesimal negative number, conforming\nto the C99 standard.\n\nM. Abramowitz and I.A. Stegun, \u201cHandbook of Mathematical Functions\u201d, 10th\nprinting, 1964, pp. 67. https://personal.math.ubc.ca/~cbm/aands/page_67.htm\n\nWikipedia, \u201cLogarithm\u201d. https://en.wikipedia.org/wiki/Logarithm\n\n"}, {"name": "numpy.log1p()", "path": "reference/generated/numpy.log1p", "type": "numpy.log1p", "text": "\nReturn the natural logarithm of one plus the input array, element-wise.\n\nCalculates `log(1 + x)`.\n\nInput values.\n\nA location into which the result is stored. If provided, it must have a shape\nthat the inputs broadcast to. If not provided or None, a freshly-allocated\narray is returned. A tuple (possible only as a keyword argument) must have\nlength equal to the number of outputs.\n\nThis condition is broadcast over the input. At locations where the condition\nis True, the `out` array will be set to the ufunc result. Elsewhere, the `out`\narray will retain its original value. Note that if an uninitialized `out`\narray is created via the default `out=None`, locations within it where the\ncondition is False will remain uninitialized.\n\nFor other keyword-only arguments, see the ufunc docs.\n\nNatural logarithm of `1 + x`, element-wise. This is a scalar if `x` is a\nscalar.\n\nSee also\n\n`exp(x) - 1`, the inverse of `log1p`.\n\nFor real-valued input, `log1p` is accurate also for `x` so small that `1 + x\n== 1` in floating-point accuracy.\n\nLogarithm is a multivalued function: for each `x` there is an infinite number\nof `z` such that `exp(z) = 1 + x`. The convention is to return the `z` whose\nimaginary part lies in `[-pi, pi]`.\n\nFor real-valued input data types, `log1p` always returns real output. For each\nvalue that cannot be expressed as a real number or infinity, it yields `nan`\nand sets the `invalid` floating point error flag.\n\nFor complex-valued input, `log1p` is a complex analytical function that has a\nbranch cut `[-inf, -1]` and is continuous from above on it. `log1p` handles\nthe floating-point negative zero as an infinitesimal negative number,\nconforming to the C99 standard.\n\nM. Abramowitz and I.A. Stegun, \u201cHandbook of Mathematical Functions\u201d, 10th\nprinting, 1964, pp. 67. https://personal.math.ubc.ca/~cbm/aands/page_67.htm\n\nWikipedia, \u201cLogarithm\u201d. https://en.wikipedia.org/wiki/Logarithm\n\n"}, {"name": "numpy.log2()", "path": "reference/generated/numpy.log2", "type": "numpy.log2", "text": "\nBase-2 logarithm of `x`.\n\nInput values.\n\nA location into which the result is stored. If provided, it must have a shape\nthat the inputs broadcast to. If not provided or None, a freshly-allocated\narray is returned. A tuple (possible only as a keyword argument) must have\nlength equal to the number of outputs.\n\nThis condition is broadcast over the input. At locations where the condition\nis True, the `out` array will be set to the ufunc result. Elsewhere, the `out`\narray will retain its original value. Note that if an uninitialized `out`\narray is created via the default `out=None`, locations within it where the\ncondition is False will remain uninitialized.\n\nFor other keyword-only arguments, see the ufunc docs.\n\nBase-2 logarithm of `x`. This is a scalar if `x` is a scalar.\n\nSee also\n\nNew in version 1.3.0.\n\nLogarithm is a multivalued function: for each `x` there is an infinite number\nof `z` such that `2**z = x`. The convention is to return the `z` whose\nimaginary part lies in `[-pi, pi]`.\n\nFor real-valued input data types, `log2` always returns real output. For each\nvalue that cannot be expressed as a real number or infinity, it yields `nan`\nand sets the `invalid` floating point error flag.\n\nFor complex-valued input, `log2` is a complex analytical function that has a\nbranch cut `[-inf, 0]` and is continuous from above on it. `log2` handles the\nfloating-point negative zero as an infinitesimal negative number, conforming\nto the C99 standard.\n\n"}, {"name": "numpy.logaddexp()", "path": "reference/generated/numpy.logaddexp", "type": "numpy.logaddexp", "text": "\nLogarithm of the sum of exponentiations of the inputs.\n\nCalculates `log(exp(x1) + exp(x2))`. This function is useful in statistics\nwhere the calculated probabilities of events may be so small as to exceed the\nrange of normal floating point numbers. In such cases the logarithm of the\ncalculated probability is stored. This function allows adding probabilities\nstored in such a fashion.\n\nInput values. If `x1.shape != x2.shape`, they must be broadcastable to a\ncommon shape (which becomes the shape of the output).\n\nA location into which the result is stored. If provided, it must have a shape\nthat the inputs broadcast to. If not provided or None, a freshly-allocated\narray is returned. A tuple (possible only as a keyword argument) must have\nlength equal to the number of outputs.\n\nThis condition is broadcast over the input. At locations where the condition\nis True, the `out` array will be set to the ufunc result. Elsewhere, the `out`\narray will retain its original value. Note that if an uninitialized `out`\narray is created via the default `out=None`, locations within it where the\ncondition is False will remain uninitialized.\n\nFor other keyword-only arguments, see the ufunc docs.\n\nLogarithm of `exp(x1) + exp(x2)`. This is a scalar if both `x1` and `x2` are\nscalars.\n\nSee also\n\nLogarithm of the sum of exponentiations of inputs in base 2.\n\nNew in version 1.3.0.\n\n"}, {"name": "numpy.logaddexp2()", "path": "reference/generated/numpy.logaddexp2", "type": "numpy.logaddexp2", "text": "\nLogarithm of the sum of exponentiations of the inputs in base-2.\n\nCalculates `log2(2**x1 + 2**x2)`. This function is useful in machine learning\nwhen the calculated probabilities of events may be so small as to exceed the\nrange of normal floating point numbers. In such cases the base-2 logarithm of\nthe calculated probability can be used instead. This function allows adding\nprobabilities stored in such a fashion.\n\nInput values. If `x1.shape != x2.shape`, they must be broadcastable to a\ncommon shape (which becomes the shape of the output).\n\nA location into which the result is stored. If provided, it must have a shape\nthat the inputs broadcast to. If not provided or None, a freshly-allocated\narray is returned. A tuple (possible only as a keyword argument) must have\nlength equal to the number of outputs.\n\nThis condition is broadcast over the input. At locations where the condition\nis True, the `out` array will be set to the ufunc result. Elsewhere, the `out`\narray will retain its original value. Note that if an uninitialized `out`\narray is created via the default `out=None`, locations within it where the\ncondition is False will remain uninitialized.\n\nFor other keyword-only arguments, see the ufunc docs.\n\nBase-2 logarithm of `2**x1 + 2**x2`. This is a scalar if both `x1` and `x2`\nare scalars.\n\nSee also\n\nLogarithm of the sum of exponentiations of the inputs.\n\nNew in version 1.3.0.\n\n"}, {"name": "numpy.logical_and()", "path": "reference/generated/numpy.logical_and", "type": "numpy.logical_and", "text": "\nCompute the truth value of x1 AND x2 element-wise.\n\nInput arrays. If `x1.shape != x2.shape`, they must be broadcastable to a\ncommon shape (which becomes the shape of the output).\n\nA location into which the result is stored. If provided, it must have a shape\nthat the inputs broadcast to. If not provided or None, a freshly-allocated\narray is returned. A tuple (possible only as a keyword argument) must have\nlength equal to the number of outputs.\n\nThis condition is broadcast over the input. At locations where the condition\nis True, the `out` array will be set to the ufunc result. Elsewhere, the `out`\narray will retain its original value. Note that if an uninitialized `out`\narray is created via the default `out=None`, locations within it where the\ncondition is False will remain uninitialized.\n\nFor other keyword-only arguments, see the ufunc docs.\n\nBoolean result of the logical AND operation applied to the elements of `x1`\nand `x2`; the shape is determined by broadcasting. This is a scalar if both\n`x1` and `x2` are scalars.\n\nSee also\n\nThe `&` operator can be used as a shorthand for `np.logical_and` on boolean\nndarrays.\n\n"}, {"name": "numpy.logical_not()", "path": "reference/generated/numpy.logical_not", "type": "numpy.logical_not", "text": "\nCompute the truth value of NOT x element-wise.\n\nLogical NOT is applied to the elements of `x`.\n\nA location into which the result is stored. If provided, it must have a shape\nthat the inputs broadcast to. If not provided or None, a freshly-allocated\narray is returned. A tuple (possible only as a keyword argument) must have\nlength equal to the number of outputs.\n\nThis condition is broadcast over the input. At locations where the condition\nis True, the `out` array will be set to the ufunc result. Elsewhere, the `out`\narray will retain its original value. Note that if an uninitialized `out`\narray is created via the default `out=None`, locations within it where the\ncondition is False will remain uninitialized.\n\nFor other keyword-only arguments, see the ufunc docs.\n\nBoolean result with the same shape as `x` of the NOT operation on elements of\n`x`. This is a scalar if `x` is a scalar.\n\nSee also\n\n"}, {"name": "numpy.logical_or()", "path": "reference/generated/numpy.logical_or", "type": "numpy.logical_or", "text": "\nCompute the truth value of x1 OR x2 element-wise.\n\nLogical OR is applied to the elements of `x1` and `x2`. If `x1.shape !=\nx2.shape`, they must be broadcastable to a common shape (which becomes the\nshape of the output).\n\nA location into which the result is stored. If provided, it must have a shape\nthat the inputs broadcast to. If not provided or None, a freshly-allocated\narray is returned. A tuple (possible only as a keyword argument) must have\nlength equal to the number of outputs.\n\nThis condition is broadcast over the input. At locations where the condition\nis True, the `out` array will be set to the ufunc result. Elsewhere, the `out`\narray will retain its original value. Note that if an uninitialized `out`\narray is created via the default `out=None`, locations within it where the\ncondition is False will remain uninitialized.\n\nFor other keyword-only arguments, see the ufunc docs.\n\nBoolean result of the logical OR operation applied to the elements of `x1` and\n`x2`; the shape is determined by broadcasting. This is a scalar if both `x1`\nand `x2` are scalars.\n\nSee also\n\nThe `|` operator can be used as a shorthand for `np.logical_or` on boolean\nndarrays.\n\n"}, {"name": "numpy.logical_xor()", "path": "reference/generated/numpy.logical_xor", "type": "numpy.logical_xor", "text": "\nCompute the truth value of x1 XOR x2, element-wise.\n\nLogical XOR is applied to the elements of `x1` and `x2`. If `x1.shape !=\nx2.shape`, they must be broadcastable to a common shape (which becomes the\nshape of the output).\n\nA location into which the result is stored. If provided, it must have a shape\nthat the inputs broadcast to. If not provided or None, a freshly-allocated\narray is returned. A tuple (possible only as a keyword argument) must have\nlength equal to the number of outputs.\n\nThis condition is broadcast over the input. At locations where the condition\nis True, the `out` array will be set to the ufunc result. Elsewhere, the `out`\narray will retain its original value. Note that if an uninitialized `out`\narray is created via the default `out=None`, locations within it where the\ncondition is False will remain uninitialized.\n\nFor other keyword-only arguments, see the ufunc docs.\n\nBoolean result of the logical XOR operation applied to the elements of `x1`\nand `x2`; the shape is determined by broadcasting. This is a scalar if both\n`x1` and `x2` are scalars.\n\nSee also\n\nSimple example showing support of broadcasting\n\n"}, {"name": "numpy.logspace()", "path": "reference/generated/numpy.logspace", "type": "numpy.logspace", "text": "\nReturn numbers spaced evenly on a log scale.\n\nIn linear space, the sequence starts at `base ** start` (`base` to the power\nof `start`) and ends with `base ** stop` (see `endpoint` below).\n\nChanged in version 1.16.0: Non-scalar `start` and `stop` are now supported.\n\n`base ** start` is the starting value of the sequence.\n\n`base ** stop` is the final value of the sequence, unless `endpoint` is False.\nIn that case, `num + 1` values are spaced over the interval in log-space, of\nwhich all but the last (a sequence of length `num`) are returned.\n\nNumber of samples to generate. Default is 50.\n\nIf true, `stop` is the last sample. Otherwise, it is not included. Default is\nTrue.\n\nThe base of the log space. The step size between the elements in `ln(samples)\n/ ln(base)` (or `log_base(samples)`) is uniform. Default is 10.0.\n\nThe type of the output array. If `dtype` is not given, the data type is\ninferred from `start` and `stop`. The inferred type will never be an integer;\n`float` is chosen even if the arguments would produce an array of integers.\n\nThe axis in the result to store the samples. Relevant only if start or stop\nare array-like. By default (0), the samples will be along a new axis inserted\nat the beginning. Use -1 to get an axis at the end.\n\nNew in version 1.16.0.\n\n`num` samples, equally spaced on a log scale.\n\nSee also\n\nSimilar to linspace, with the step size specified instead of the number of\nsamples. Note that, when used with a float endpoint, the endpoint may or may\nnot be included.\n\nSimilar to logspace, but with the samples uniformly distributed in linear\nspace, instead of log space.\n\nSimilar to logspace, but with endpoints specified directly.\n\nLogspace is equivalent to the code\n\nGraphical illustration:\n\n"}, {"name": "numpy.longcomplex", "path": "reference/arrays.scalars#numpy.longcomplex", "type": "Scalars", "text": "\nalias of `numpy.clongdouble`\n\n"}, {"name": "numpy.longdouble", "path": "reference/arrays.scalars#numpy.longdouble", "type": "Scalars", "text": "\nExtended-precision floating-point number type, compatible with C `long double`\nbut not necessarily with IEEE 754 quadruple-precision.\n\n`'g'`\n\n`numpy.longfloat`\n\n`numpy.float128`: 128-bit extended-precision floating-point number type.\n\n"}, {"name": "numpy.longfloat", "path": "reference/arrays.scalars#numpy.longfloat", "type": "Scalars", "text": "\nalias of `numpy.longdouble`\n\n"}, {"name": "numpy.longlong", "path": "reference/arrays.scalars#numpy.longlong", "type": "Scalars", "text": "\nSigned integer type, compatible with C `long long`.\n\n`'q'`\n\n"}, {"name": "numpy.lookfor()", "path": "reference/generated/numpy.lookfor", "type": "numpy.lookfor", "text": "\nDo a keyword search on docstrings.\n\nA list of objects that matched the search is displayed, sorted by relevance.\nAll given keywords need to be found in the docstring for it to be returned as\na result, but the order does not matter.\n\nString containing words to look for.\n\nName of module(s) whose docstrings to go through.\n\nWhether to import sub-modules in packages. Default is True.\n\nWhether to re-generate the docstring cache. Default is False.\n\nFile-like object to write the output to. If omitted, use a pager.\n\nSee also\n\nRelevance is determined only roughly, by checking if the keywords occur in the\nfunction name, at the start of a docstring, etc.\n\n"}, {"name": "numpy.ma.masked", "path": "reference/maskedarray.baseclass", "type": "Constants of the \n        \n         numpy.ma\n        \n        module", "text": "\nIn addition to the `MaskedArray` class, the `numpy.ma` module defines several\nconstants.\n\nThe `masked` constant is a special case of `MaskedArray`, with a float\ndatatype and a null shape. It is used to test whether a specific entry of a\nmasked array is masked, or to mask one or several entries of a masked array:\n\nValue indicating that a masked array has no invalid entry. `nomask` is used\ninternally to speed up computations when the mask is not needed. It is\nrepresented internally as `np.False_`.\n\nString used in lieu of missing data when a masked array is printed. By\ndefault, this string is `'--'`.\n\n"}, {"name": "numpy.ma.masked_array", "path": "reference/generated/numpy.ma.masked_array", "type": "numpy.ma.masked_array", "text": "\nalias of `numpy.ma.core.MaskedArray`\n\n"}, {"name": "numpy.ma.masked_print_options", "path": "reference/maskedarray.baseclass#numpy.ma.masked_print_options", "type": "Constants of the \n        \n         numpy.ma\n        \n        module", "text": "\nString used in lieu of missing data when a masked array is printed. By\ndefault, this string is `'--'`.\n\n"}, {"name": "numpy.ma.MaskType", "path": "reference/generated/numpy.ma.masktype", "type": "numpy.ma.MaskType", "text": "\nalias of `numpy.bool_`\n\n"}, {"name": "numpy.ma.nomask", "path": "reference/maskedarray.baseclass#numpy.ma.nomask", "type": "Constants of the \n        \n         numpy.ma\n        \n        module", "text": "\nValue indicating that a masked array has no invalid entry. `nomask` is used\ninternally to speed up computations when the mask is not needed. It is\nrepresented internally as `np.False_`.\n\n"}, {"name": "numpy.MachAr()", "path": "reference/generated/numpy.machar", "type": "numpy.MachAr", "text": "\nDiagnosing machine parameters.\n\nFunction that converts an integer or integer array to a float or float array.\nDefault is `float`.\n\nFunction that converts a float or float array to an integer or integer array.\nDefault is `int`.\n\nFunction that converts a float array to float. Default is `float`. Note that\nthis does not seem to do anything useful in the current implementation.\n\nFunction that converts a single float to a string. Default is `lambda\nv:'%24.16e' %v`.\n\nTitle that is printed in the string representation of `MachAr`.\n\nSee also\n\nMachine limits for floating point types.\n\nMachine limits for integer types.\n\nPress, Teukolsky, Vetterling and Flannery, \u201cNumerical Recipes in C++,\u201d 2nd ed,\nCambridge University Press, 2002, p. 31.\n\nRadix in which numbers are represented.\n\nNumber of base-`ibeta` digits in the floating point mantissa M.\n\nExponent of the smallest (most negative) power of `ibeta` that, added to 1.0,\ngives something different from 1.0\n\nFloating-point number `beta**machep` (floating point precision)\n\nExponent of the smallest power of `ibeta` that, subtracted from 1.0, gives\nsomething different from 1.0.\n\nFloating-point number `beta**negep`.\n\nNumber of bits in the exponent (including its sign and bias).\n\nSmallest (most negative) power of `ibeta` consistent with there being no\nleading zeros in the mantissa.\n\nFloating-point number `beta**minexp` (the smallest [in magnitude] positive\nfloating point number with full precision).\n\nSmallest (positive) power of `ibeta` that causes overflow.\n\n`(1-epsneg) * beta**maxexp` (the largest [in magnitude] usable floating\nvalue).\n\nIn `range(6)`, information on what kind of rounding is done in addition, and\non how underflow is handled.\n\nNumber of \u2018guard digits\u2019 used when truncating the product of two mantissas to\nfit the representation.\n\nSame as `eps`.\n\nAn alias for `smallest_normal`, kept for backwards compatibility.\n\nSame as `xmax`.\n\n`- int(-log10(eps))`\n\n`- 10**(-precision)`\n\nThe smallest positive floating point number with 1 as leading bit in the\nmantissa following IEEE-754. Same as `xmin`.\n\nThe smallest positive floating point number with 0 as leading bit in the\nmantissa following IEEE-754.\n\n"}, {"name": "numpy.mask_indices()", "path": "reference/generated/numpy.mask_indices", "type": "numpy.mask_indices", "text": "\nReturn the indices to access (n, n) arrays, given a masking function.\n\nAssume `mask_func` is a function that, for a square array a of size `(n, n)`\nwith a possible offset argument `k`, when called as `mask_func(a, k)` returns\na new array with zeros in certain locations (functions like `triu` or `tril`\ndo precisely this). Then this function returns the indices where the non-zero\nvalues would be located.\n\nThe returned indices will be valid to access arrays of shape (n, n).\n\nA function whose call signature is similar to that of `triu`, `tril`. That is,\n`mask_func(x, k)` returns a boolean array, shaped like `x`. `k` is an optional\nargument to the function.\n\nAn optional argument which is passed through to `mask_func`. Functions like\n`triu`, `tril` take a second argument that is interpreted as an offset.\n\nThe `n` arrays of indices corresponding to the locations where\n`mask_func(np.ones((n, n)), k)` is True.\n\nSee also\n\nNew in version 1.4.0.\n\nThese are the indices that would allow you to access the upper triangular part\nof any 3x3 array:\n\nFor example, if `a` is a 3x3 array:\n\nAn offset can be passed also to the masking function. This gets us the indices\nstarting on the first diagonal right of the main one:\n\nwith which we now extract only three elements:\n\n"}, {"name": "numpy.mat()", "path": "reference/generated/numpy.mat", "type": "numpy.mat", "text": "\nInterpret the input as a matrix.\n\nUnlike `matrix`, `asmatrix` does not make a copy if the input is already a\nmatrix or an ndarray. Equivalent to `matrix(data, copy=False)`.\n\nInput data.\n\nData-type of the output matrix.\n\n`data` interpreted as a matrix.\n\n"}, {"name": "numpy.matmul()", "path": "reference/generated/numpy.matmul", "type": "numpy.matmul", "text": "\nMatrix product of two arrays.\n\nInput arrays, scalars not allowed.\n\nA location into which the result is stored. If provided, it must have a shape\nthat matches the signature `(n,k),(k,m)->(n,m)`. If not provided or None, a\nfreshly-allocated array is returned.\n\nFor other keyword-only arguments, see the ufunc docs.\n\nNew in version 1.16: Now handles ufunc kwargs\n\nThe matrix product of the inputs. This is a scalar only when both x1, x2 are\n1-d vectors.\n\nIf the last dimension of `x1` is not the same size as the second-to-last\ndimension of `x2`.\n\nIf a scalar value is passed in.\n\nSee also\n\nComplex-conjugating dot product.\n\nSum products over arbitrary axes.\n\nEinstein summation convention.\n\nalternative matrix product with different broadcasting rules.\n\nThe behavior depends on the arguments in the following way.\n\n`matmul` differs from `dot` in two important ways:\n\nStacks of matrices are broadcast together as if the matrices were elements,\nrespecting the signature `(n,k),(k,m)->(n,m)`:\n\nThe matmul function implements the semantics of the `@` operator introduced in\nPython 3.5 following PEP 465.\n\nFor 2-D arrays it is the matrix product:\n\nFor 2-D mixed with 1-D, the result is the usual.\n\nBroadcasting is conventional for stacks of arrays\n\nVector, vector returns the scalar inner product, but neither argument is\ncomplex-conjugated:\n\nScalar multiplication raises an error.\n\nThe `@` operator can be used as a shorthand for `np.matmul` on ndarrays.\n\nNew in version 1.10.0.\n\n"}, {"name": "numpy.matrix()", "path": "reference/generated/numpy.matrix", "type": "numpy.matrix", "text": "\nNote\n\nIt is no longer recommended to use this class, even for linear algebra.\nInstead use regular arrays. The class may be removed in the future.\n\nReturns a matrix from an array-like object, or from a string of data. A matrix\nis a specialized 2-D array that retains its 2-D nature through operations. It\nhas certain special operators, such as `*` (matrix multiplication) and `**`\n(matrix power).\n\nIf `data` is a string, it is interpreted as a matrix with commas or spaces\nseparating columns, and semicolons separating rows.\n\nData-type of the output matrix.\n\nIf `data` is already an `ndarray`, then this flag determines whether the data\nis copied (the default), or whether a view is constructed.\n\nSee also\n\nReturn `self` as an `ndarray` object.\n\nReturn `self` as a flattened `ndarray`.\n\nReturns the (complex) conjugate transpose of `self`.\n\nReturns the (multiplicative) inverse of invertible `self`.\n\nReturns the transpose of the matrix.\n\nBase object if memory is from some other object.\n\nAn object to simplify the interaction of the array with the ctypes module.\n\nPython buffer object pointing to the start of the array\u2019s data.\n\nData-type of the array\u2019s elements.\n\nInformation about the memory layout of the array.\n\nA 1-D iterator over the array.\n\nThe imaginary part of the array.\n\nLength of one array element in bytes.\n\nTotal bytes consumed by the elements of the array.\n\nNumber of array dimensions.\n\nThe real part of the array.\n\nTuple of array dimensions.\n\nNumber of elements in the array.\n\nTuple of bytes to step in each dimension when traversing an array.\n\n`all`([axis, out])\n\nTest whether all matrix elements along a given axis evaluate to True.\n\n`any`([axis, out])\n\nTest whether any array element along a given axis evaluates to True.\n\n`argmax`([axis, out])\n\nIndexes of the maximum values along an axis.\n\n`argmin`([axis, out])\n\nIndexes of the minimum values along an axis.\n\n`argpartition`(kth[, axis, kind, order])\n\nReturns the indices that would partition this array.\n\n`argsort`([axis, kind, order])\n\nReturns the indices that would sort this array.\n\n`astype`(dtype[, order, casting, subok, copy])\n\nCopy of the array, cast to a specified type.\n\n`byteswap`([inplace])\n\nSwap the bytes of the array elements\n\n`choose`(choices[, out, mode])\n\nUse an index array to construct a new array from a set of choices.\n\n`clip`([min, max, out])\n\nReturn an array whose values are limited to `[min, max]`.\n\n`compress`(condition[, axis, out])\n\nReturn selected slices of this array along given axis.\n\n`conj`()\n\nComplex-conjugate all elements.\n\n`conjugate`()\n\nReturn the complex conjugate, element-wise.\n\n`copy`([order])\n\nReturn a copy of the array.\n\n`cumprod`([axis, dtype, out])\n\nReturn the cumulative product of the elements along the given axis.\n\n`cumsum`([axis, dtype, out])\n\nReturn the cumulative sum of the elements along the given axis.\n\n`diagonal`([offset, axis1, axis2])\n\nReturn specified diagonals.\n\n`dump`(file)\n\nDump a pickle of the array to the specified file.\n\n`dumps`()\n\nReturns the pickle of the array as a string.\n\n`fill`(value)\n\nFill the array with a scalar value.\n\n`flatten`([order])\n\nReturn a flattened copy of the matrix.\n\n`getA`()\n\nReturn `self` as an `ndarray` object.\n\n`getA1`()\n\nReturn `self` as a flattened `ndarray`.\n\n`getH`()\n\nReturns the (complex) conjugate transpose of `self`.\n\n`getI`()\n\nReturns the (multiplicative) inverse of invertible `self`.\n\n`getT`()\n\nReturns the transpose of the matrix.\n\n`getfield`(dtype[, offset])\n\nReturns a field of the given array as a certain type.\n\n`item`(*args)\n\nCopy an element of an array to a standard Python scalar and return it.\n\n`itemset`(*args)\n\nInsert scalar into an array (scalar is cast to array's dtype, if possible)\n\n`max`([axis, out])\n\nReturn the maximum value along an axis.\n\n`mean`([axis, dtype, out])\n\nReturns the average of the matrix elements along the given axis.\n\n`min`([axis, out])\n\nReturn the minimum value along an axis.\n\n`newbyteorder`([new_order])\n\nReturn the array with the same data viewed with a different byte order.\n\n`nonzero`()\n\nReturn the indices of the elements that are non-zero.\n\n`partition`(kth[, axis, kind, order])\n\nRearranges the elements in the array in such a way that the value of the\nelement in kth position is in the position it would be in a sorted array.\n\n`prod`([axis, dtype, out])\n\nReturn the product of the array elements over the given axis.\n\n`ptp`([axis, out])\n\nPeak-to-peak (maximum - minimum) value along the given axis.\n\n`put`(indices, values[, mode])\n\nSet `a.flat[n] = values[n]` for all `n` in indices.\n\n`ravel`([order])\n\nReturn a flattened matrix.\n\n`repeat`(repeats[, axis])\n\nRepeat elements of an array.\n\n`reshape`(shape[, order])\n\nReturns an array containing the same data with a new shape.\n\n`resize`(new_shape[, refcheck])\n\nChange shape and size of array in-place.\n\n`round`([decimals, out])\n\nReturn `a` with each element rounded to the given number of decimals.\n\n`searchsorted`(v[, side, sorter])\n\nFind indices where elements of v should be inserted in a to maintain order.\n\n`setfield`(val, dtype[, offset])\n\nPut a value into a specified place in a field defined by a data-type.\n\n`setflags`([write, align, uic])\n\nSet array flags WRITEABLE, ALIGNED, (WRITEBACKIFCOPY and UPDATEIFCOPY),\nrespectively.\n\n`sort`([axis, kind, order])\n\nSort an array in-place.\n\n`squeeze`([axis])\n\nReturn a possibly reshaped matrix.\n\n`std`([axis, dtype, out, ddof])\n\nReturn the standard deviation of the array elements along the given axis.\n\n`sum`([axis, dtype, out])\n\nReturns the sum of the matrix elements, along the given axis.\n\n`swapaxes`(axis1, axis2)\n\nReturn a view of the array with `axis1` and `axis2` interchanged.\n\n`take`(indices[, axis, out, mode])\n\nReturn an array formed from the elements of `a` at the given indices.\n\n`tobytes`([order])\n\nConstruct Python bytes containing the raw data bytes in the array.\n\n`tofile`(fid[, sep, format])\n\nWrite array to a file as text or binary (default).\n\n`tolist`()\n\nReturn the matrix as a (possibly nested) list.\n\n`tostring`([order])\n\nA compatibility alias for `tobytes`, with exactly the same behavior.\n\n`trace`([offset, axis1, axis2, dtype, out])\n\nReturn the sum along diagonals of the array.\n\n`transpose`(*axes)\n\nReturns a view of the array with axes transposed.\n\n`var`([axis, dtype, out, ddof])\n\nReturns the variance of the matrix elements, along the given axis.\n\n`view`([dtype][, type])\n\nNew view of array with the same data.\n\ndot\n\n"}, {"name": "numpy.maximum()", "path": "reference/generated/numpy.maximum", "type": "numpy.maximum", "text": "\nElement-wise maximum of array elements.\n\nCompare two arrays and returns a new array containing the element-wise maxima.\nIf one of the elements being compared is a NaN, then that element is returned.\nIf both elements are NaNs then the first is returned. The latter distinction\nis important for complex NaNs, which are defined as at least one of the real\nor imaginary parts being a NaN. The net effect is that NaNs are propagated.\n\nThe arrays holding the elements to be compared. If `x1.shape != x2.shape`,\nthey must be broadcastable to a common shape (which becomes the shape of the\noutput).\n\nA location into which the result is stored. If provided, it must have a shape\nthat the inputs broadcast to. If not provided or None, a freshly-allocated\narray is returned. A tuple (possible only as a keyword argument) must have\nlength equal to the number of outputs.\n\nThis condition is broadcast over the input. At locations where the condition\nis True, the `out` array will be set to the ufunc result. Elsewhere, the `out`\narray will retain its original value. Note that if an uninitialized `out`\narray is created via the default `out=None`, locations within it where the\ncondition is False will remain uninitialized.\n\nFor other keyword-only arguments, see the ufunc docs.\n\nThe maximum of `x1` and `x2`, element-wise. This is a scalar if both `x1` and\n`x2` are scalars.\n\nSee also\n\nElement-wise minimum of two arrays, propagates NaNs.\n\nElement-wise maximum of two arrays, ignores NaNs.\n\nThe maximum value of an array along a given axis, propagates NaNs.\n\nThe maximum value of an array along a given axis, ignores NaNs.\n\nThe maximum is equivalent to `np.where(x1 >= x2, x1, x2)` when neither x1 nor\nx2 are nans, but it is faster and does proper broadcasting.\n\n"}, {"name": "numpy.maximum_sctype()", "path": "reference/generated/numpy.maximum_sctype", "type": "numpy.maximum_sctype", "text": "\nReturn the scalar type of highest precision of the same kind as the input.\n\nThe input data type. This can be a `dtype` object or an object that is\nconvertible to a `dtype`.\n\nThe highest precision data type of the same kind (`dtype.kind`) as `t`.\n\nSee also\n\n"}, {"name": "numpy.may_share_memory()", "path": "reference/generated/numpy.may_share_memory", "type": "numpy.may_share_memory", "text": "\nDetermine if two arrays might share memory\n\nA return of True does not necessarily mean that the two arrays share any\nelement. It just means that they might.\n\nOnly the memory bounds of a and b are checked by default.\n\nInput arrays\n\nEffort to spend on solving the overlap problem. See `shares_memory` for\ndetails. Default for `may_share_memory` is to do a bounds check.\n\nSee also\n\n"}, {"name": "numpy.mean()", "path": "reference/generated/numpy.mean", "type": "numpy.mean", "text": "\nCompute the arithmetic mean along the specified axis.\n\nReturns the average of the array elements. The average is taken over the\nflattened array by default, otherwise over the specified axis. `float64`\nintermediate and return values are used for integer inputs.\n\nArray containing numbers whose mean is desired. If `a` is not an array, a\nconversion is attempted.\n\nAxis or axes along which the means are computed. The default is to compute the\nmean of the flattened array.\n\nNew in version 1.7.0.\n\nIf this is a tuple of ints, a mean is performed over multiple axes, instead of\na single axis or all the axes as before.\n\nType to use in computing the mean. For integer inputs, the default is\n`float64`; for floating point inputs, it is the same as the input dtype.\n\nAlternate output array in which to place the result. The default is `None`; if\nprovided, it must have the same shape as the expected output, but the type\nwill be cast if necessary. See Output type determination for more details.\n\nIf this is set to True, the axes which are reduced are left in the result as\ndimensions with size one. With this option, the result will broadcast\ncorrectly against the input array.\n\nIf the default value is passed, then `keepdims` will not be passed through to\nthe `mean` method of sub-classes of `ndarray`, however any non-default value\nwill be. If the sub-class\u2019 method does not implement `keepdims` any exceptions\nwill be raised.\n\nElements to include in the mean. See `reduce` for details.\n\nNew in version 1.20.0.\n\nIf `out=None`, returns a new array containing the mean values, otherwise a\nreference to the output array is returned.\n\nSee also\n\nWeighted average\n\nThe arithmetic mean is the sum of the elements along the axis divided by the\nnumber of elements.\n\nNote that for floating-point input, the mean is computed using the same\nprecision the input has. Depending on the input data, this can cause the\nresults to be inaccurate, especially for `float32` (see example below).\nSpecifying a higher-precision accumulator using the `dtype` keyword can\nalleviate this issue.\n\nBy default, `float16` results are computed using `float32` intermediates for\nextra precision.\n\nIn single precision, `mean` can be inaccurate:\n\nComputing the mean in float64 is more accurate:\n\nSpecifying a where argument: >>> a = np.array([[5, 9, 13], [14, 10, 12], [11,\n15, 19]]) >>> np.mean(a) 12.0 >>> np.mean(a, where=[[True], [False], [False]])\n9.0\n\n"}, {"name": "numpy.median()", "path": "reference/generated/numpy.median", "type": "numpy.median", "text": "\nCompute the median along the specified axis.\n\nReturns the median of the array elements.\n\nInput array or object that can be converted to an array.\n\nAxis or axes along which the medians are computed. The default is to compute\nthe median along a flattened version of the array. A sequence of axes is\nsupported since version 1.9.0.\n\nAlternative output array in which to place the result. It must have the same\nshape and buffer length as the expected output, but the type (of the output)\nwill be cast if necessary.\n\nIf True, then allow use of memory of input array `a` for calculations. The\ninput array will be modified by the call to `median`. This will save memory\nwhen you do not need to preserve the contents of the input array. Treat the\ninput as undefined, but it will probably be fully or partially sorted. Default\nis False. If `overwrite_input` is `True` and `a` is not already an `ndarray`,\nan error will be raised.\n\nIf this is set to True, the axes which are reduced are left in the result as\ndimensions with size one. With this option, the result will broadcast\ncorrectly against the original `arr`.\n\nNew in version 1.9.0.\n\nA new array holding the result. If the input contains integers or floats\nsmaller than `float64`, then the output data-type is `np.float64`. Otherwise,\nthe data-type of the output is the same as that of the input. If `out` is\nspecified, that array is returned instead.\n\nSee also\n\nGiven a vector `V` of length `N`, the median of `V` is the middle value of a\nsorted copy of `V`, `V_sorted` \\- i e., `V_sorted[(N-1)/2]`, when `N` is odd,\nand the average of the two middle values of `V_sorted` when `N` is even.\n\n"}, {"name": "numpy.memmap()", "path": "reference/generated/numpy.memmap", "type": "numpy.memmap", "text": "\nCreate a memory-map to an array stored in a binary file on disk.\n\nMemory-mapped files are used for accessing small segments of large files on\ndisk, without reading the entire file into memory. NumPy\u2019s memmap\u2019s are array-\nlike objects. This differs from Python\u2019s `mmap` module, which uses file-like\nobjects.\n\nThis subclass of ndarray has some unpleasant interactions with some\noperations, because it doesn\u2019t quite fit properly as a subclass. An\nalternative to using this subclass is to create the `mmap` object yourself,\nthen create an ndarray with ndarray.__new__ directly, passing the object\ncreated in its \u2018buffer=\u2019 parameter.\n\nThis class may at some point be turned into a factory function which returns a\nview into an mmap buffer.\n\nFlush the memmap instance to write the changes to the file. Currently there is\nno API to close the underlying `mmap`. It is tricky to ensure the resource is\nactually closed, since it may be shared between different memmap instances.\n\nThe file name or file object to be used as the array data buffer.\n\nThe data-type used to interpret the file contents. Default is `uint8`.\n\nThe file is opened in this mode:\n\n\u2018r\u2019\n\nOpen existing file for reading only.\n\n\u2018r+\u2019\n\nOpen existing file for reading and writing.\n\n\u2018w+\u2019\n\nCreate or overwrite existing file for reading and writing.\n\n\u2018c\u2019\n\nCopy-on-write: assignments affect data in memory, but changes are not saved to\ndisk. The file on disk is read-only.\n\nDefault is \u2018r+\u2019.\n\nIn the file, array data starts at this offset. Since `offset` is measured in\nbytes, it should normally be a multiple of the byte-size of `dtype`. When\n`mode != 'r'`, even positive offsets beyond end of file are valid; The file\nwill be extended to accommodate the additional data. By default, `memmap` will\nstart at the beginning of the file, even if `filename` is a file pointer `fp`\nand `fp.tell() != 0`.\n\nThe desired shape of the array. If `mode == 'r'` and the number of remaining\nbytes after `offset` is not a multiple of the byte-size of `dtype`, you must\nspecify `shape`. By default, the returned array will be 1-D with the number of\nelements determined by file size and data-type.\n\nSpecify the order of the ndarray memory layout: row-major, C-style or column-\nmajor, Fortran-style. This only has an effect if the shape is greater than\n1-D. The default order is \u2018C\u2019.\n\nSee also\n\nCreate or load a memory-mapped `.npy` file.\n\nThe memmap object can be used anywhere an ndarray is accepted. Given a memmap\n`fp`, `isinstance(fp, numpy.ndarray)` returns `True`.\n\nMemory-mapped files cannot be larger than 2GB on 32-bit systems.\n\nWhen a memmap causes a file to be created or extended beyond its current size\nin the filesystem, the contents of the new part are unspecified. On systems\nwith POSIX filesystem semantics, the extended part will be filled with zero\nbytes.\n\nThis example uses a temporary file so that doctest doesn\u2019t write files to your\ndirectory. You would use a \u2018normal\u2019 filename.\n\nCreate a memmap with dtype and shape that matches our data:\n\nWrite data to memmap array:\n\nFlushes memory changes to disk in order to read them back\n\nLoad the memmap and verify data was stored:\n\nRead-only memmap:\n\nCopy-on-write memmap:\n\nIt\u2019s possible to assign to copy-on-write array, but values are only written\ninto the memory copy of the array, and not written to disk:\n\nFile on disk is unchanged:\n\nOffset into a memmap:\n\nPath to the mapped file.\n\nOffset position in the file.\n\nFile mode.\n\n`flush`()\n\nWrite any changes in the array to the file on disk.\n\n"}, {"name": "numpy.meshgrid()", "path": "reference/generated/numpy.meshgrid", "type": "numpy.meshgrid", "text": "\nReturn coordinate matrices from coordinate vectors.\n\nMake N-D coordinate arrays for vectorized evaluations of N-D scalar/vector\nfields over N-D grids, given one-dimensional coordinate arrays x1, x2,\u2026, xn.\n\nChanged in version 1.9: 1-D and 0-D cases are allowed.\n\n1-D arrays representing the coordinates of a grid.\n\nCartesian (\u2018xy\u2019, default) or matrix (\u2018ij\u2019) indexing of output. See Notes for\nmore details.\n\nNew in version 1.7.0.\n\nIf True the shape of the returned coordinate array for dimension i is reduced\nfrom `(N1, ..., Ni, ... Nn)` to `(1, ..., 1, Ni, 1, ..., 1)`. These sparse\ncoordinate grids are intended to be use with Broadcasting. When all\ncoordinates are used in an expression, broadcasting still leads to a fully-\ndimensonal result array.\n\nDefault is False.\n\nNew in version 1.7.0.\n\nIf False, a view into the original arrays are returned in order to conserve\nmemory. Default is True. Please note that `sparse=False, copy=False` will\nlikely return non-contiguous arrays. Furthermore, more than one element of a\nbroadcast array may refer to a single memory location. If you need to write to\nthe arrays, make copies first.\n\nNew in version 1.7.0.\n\nFor vectors `x1`, `x2`,\u2026, \u2018xn\u2019 with lengths `Ni=len(xi)` , return `(N1, N2,\nN3,...Nn)` shaped arrays if indexing=\u2019ij\u2019 or `(N2, N1, N3,...Nn)` shaped\narrays if indexing=\u2019xy\u2019 with the elements of `xi` repeated to fill the matrix\nalong the first dimension for `x1`, the second for `x2` and so on.\n\nSee also\n\nConstruct a multi-dimensional \u201cmeshgrid\u201d using indexing notation.\n\nConstruct an open multi-dimensional \u201cmeshgrid\u201d using indexing notation.\n\nThis function supports both indexing conventions through the indexing keyword\nargument. Giving the string \u2018ij\u2019 returns a meshgrid with matrix indexing,\nwhile \u2018xy\u2019 returns a meshgrid with Cartesian indexing. In the 2-D case with\ninputs of length M and N, the outputs are of shape (N, M) for \u2018xy\u2019 indexing\nand (M, N) for \u2018ij\u2019 indexing. In the 3-D case with inputs of length M, N and\nP, outputs are of shape (N, M, P) for \u2018xy\u2019 indexing and (M, N, P) for \u2018ij\u2019\nindexing. The difference is illustrated by the following code snippet:\n\nIn the 1-D and 0-D case, the indexing and sparse keywords have no effect.\n\n`meshgrid` is very useful to evaluate functions on a grid. If the function\ndepends on all coordinates, you can use the parameter `sparse=True` to save\nmemory and computation time.\n\n"}, {"name": "numpy.mgrid", "path": "reference/generated/numpy.mgrid", "type": "numpy.mgrid", "text": "\n`nd_grid` instance which returns a dense multi-dimensional \u201cmeshgrid\u201d.\n\nAn instance of `numpy.lib.index_tricks.nd_grid` which returns an dense (or\nfleshed out) mesh-grid when indexed, so that each returned argument has the\nsame shape. The dimensions and number of the output arrays are equal to the\nnumber of indexing dimensions. If the step length is not a complex number,\nthen the stop is not inclusive.\n\nHowever, if the step length is a complex number (e.g. 5j), then the integer\npart of its magnitude is interpreted as specifying the number of points to\ncreate between the start and stop values, where the stop value is inclusive.\n\nSee also\n\nclass of `ogrid` and `mgrid` objects\n\nlike mgrid but returns open (not fleshed out) mesh grids\n\narray concatenator\n\n"}, {"name": "numpy.min_scalar_type()", "path": "reference/generated/numpy.min_scalar_type", "type": "numpy.min_scalar_type", "text": "\nFor scalar `a`, returns the data type with the smallest size and smallest\nscalar kind which can hold its value. For non-scalar array `a`, returns the\nvector\u2019s dtype unmodified.\n\nFloating point values are not demoted to integers, and complex values are not\ndemoted to floats.\n\nThe value whose minimal data type is to be found.\n\nThe minimal data type.\n\nSee also\n\nNew in version 1.6.0.\n\n"}, {"name": "numpy.minimum()", "path": "reference/generated/numpy.minimum", "type": "numpy.minimum", "text": "\nElement-wise minimum of array elements.\n\nCompare two arrays and returns a new array containing the element-wise minima.\nIf one of the elements being compared is a NaN, then that element is returned.\nIf both elements are NaNs then the first is returned. The latter distinction\nis important for complex NaNs, which are defined as at least one of the real\nor imaginary parts being a NaN. The net effect is that NaNs are propagated.\n\nThe arrays holding the elements to be compared. If `x1.shape != x2.shape`,\nthey must be broadcastable to a common shape (which becomes the shape of the\noutput).\n\nA location into which the result is stored. If provided, it must have a shape\nthat the inputs broadcast to. If not provided or None, a freshly-allocated\narray is returned. A tuple (possible only as a keyword argument) must have\nlength equal to the number of outputs.\n\nThis condition is broadcast over the input. At locations where the condition\nis True, the `out` array will be set to the ufunc result. Elsewhere, the `out`\narray will retain its original value. Note that if an uninitialized `out`\narray is created via the default `out=None`, locations within it where the\ncondition is False will remain uninitialized.\n\nFor other keyword-only arguments, see the ufunc docs.\n\nThe minimum of `x1` and `x2`, element-wise. This is a scalar if both `x1` and\n`x2` are scalars.\n\nSee also\n\nElement-wise maximum of two arrays, propagates NaNs.\n\nElement-wise minimum of two arrays, ignores NaNs.\n\nThe minimum value of an array along a given axis, propagates NaNs.\n\nThe minimum value of an array along a given axis, ignores NaNs.\n\nThe minimum is equivalent to `np.where(x1 <= x2, x1, x2)` when neither x1 nor\nx2 are NaNs, but it is faster and does proper broadcasting.\n\n"}, {"name": "numpy.mintypecode()", "path": "reference/generated/numpy.mintypecode", "type": "numpy.mintypecode", "text": "\nReturn the character for the minimum-size type to which given types can be\nsafely cast.\n\nThe returned type character must represent the smallest size dtype such that\nan array of the returned type can handle the data from an array of all types\nin `typechars` (or if `typechars` is an array, then its dtype.char).\n\nIf a list of strings, each string should represent a dtype. If array_like, the\ncharacter representation of the array dtype is used.\n\nThe set of characters that the returned character is chosen from. The default\nset is \u2018GDFgdf\u2019.\n\nThe default character, this is returned if none of the characters in\n`typechars` matches a character in `typeset`.\n\nThe character representing the minimum-size type that was found.\n\nSee also\n\n"}, {"name": "numpy.mod()", "path": "reference/generated/numpy.mod", "type": "numpy.mod", "text": "\nReturns the element-wise remainder of division.\n\nComputes the remainder complementary to the `floor_divide` function. It is\nequivalent to the Python modulus operator``x1 % x2`` and has the same sign as\nthe divisor `x2`. The MATLAB function equivalent to `np.remainder` is `mod`.\n\nWarning\n\nThis should not be confused with:\n\nDividend array.\n\nDivisor array. If `x1.shape != x2.shape`, they must be broadcastable to a\ncommon shape (which becomes the shape of the output).\n\nA location into which the result is stored. If provided, it must have a shape\nthat the inputs broadcast to. If not provided or None, a freshly-allocated\narray is returned. A tuple (possible only as a keyword argument) must have\nlength equal to the number of outputs.\n\nThis condition is broadcast over the input. At locations where the condition\nis True, the `out` array will be set to the ufunc result. Elsewhere, the `out`\narray will retain its original value. Note that if an uninitialized `out`\narray is created via the default `out=None`, locations within it where the\ncondition is False will remain uninitialized.\n\nFor other keyword-only arguments, see the ufunc docs.\n\nThe element-wise remainder of the quotient `floor_divide(x1, x2)`. This is a\nscalar if both `x1` and `x2` are scalars.\n\nSee also\n\nEquivalent of Python `//` operator.\n\nSimultaneous floor division and remainder.\n\nEquivalent of the MATLAB `rem` function.\n\nReturns 0 when `x2` is 0 and both `x1` and `x2` are (arrays of) integers.\n`mod` is an alias of `remainder`.\n\nThe `%` operator can be used as a shorthand for `np.remainder` on ndarrays.\n\n"}, {"name": "numpy.modf()", "path": "reference/generated/numpy.modf", "type": "numpy.modf", "text": "\nReturn the fractional and integral parts of an array, element-wise.\n\nThe fractional and integral parts are negative if the given number is\nnegative.\n\nInput array.\n\nA location into which the result is stored. If provided, it must have a shape\nthat the inputs broadcast to. If not provided or None, a freshly-allocated\narray is returned. A tuple (possible only as a keyword argument) must have\nlength equal to the number of outputs.\n\nThis condition is broadcast over the input. At locations where the condition\nis True, the `out` array will be set to the ufunc result. Elsewhere, the `out`\narray will retain its original value. Note that if an uninitialized `out`\narray is created via the default `out=None`, locations within it where the\ncondition is False will remain uninitialized.\n\nFor other keyword-only arguments, see the ufunc docs.\n\nFractional part of `x`. This is a scalar if `x` is a scalar.\n\nIntegral part of `x`. This is a scalar if `x` is a scalar.\n\nSee also\n\n`divmod(x, 1)` is equivalent to `modf` with the return values switched, except\nit always has a positive remainder.\n\nFor integer input the return values are floats.\n\n"}, {"name": "numpy.moveaxis()", "path": "reference/generated/numpy.moveaxis", "type": "numpy.moveaxis", "text": "\nMove axes of an array to new positions.\n\nOther axes remain in their original order.\n\nNew in version 1.11.0.\n\nThe array whose axes should be reordered.\n\nOriginal positions of the axes to move. These must be unique.\n\nDestination positions for each of the original axes. These must also be\nunique.\n\nArray with moved axes. This array is a view of the input array.\n\nSee also\n\nPermute the dimensions of an array.\n\nInterchange two axes of an array.\n\nThese all achieve the same result:\n\n"}, {"name": "numpy.msort()", "path": "reference/generated/numpy.msort", "type": "numpy.msort", "text": "\nReturn a copy of an array sorted along the first axis.\n\nArray to be sorted.\n\nArray of the same type and shape as `a`.\n\nSee also\n\n`np.msort(a)` is equivalent to `np.sort(a, axis=0)`.\n\n"}, {"name": "numpy.multiply()", "path": "reference/generated/numpy.multiply", "type": "numpy.multiply", "text": "\nMultiply arguments element-wise.\n\nInput arrays to be multiplied. If `x1.shape != x2.shape`, they must be\nbroadcastable to a common shape (which becomes the shape of the output).\n\nA location into which the result is stored. If provided, it must have a shape\nthat the inputs broadcast to. If not provided or None, a freshly-allocated\narray is returned. A tuple (possible only as a keyword argument) must have\nlength equal to the number of outputs.\n\nThis condition is broadcast over the input. At locations where the condition\nis True, the `out` array will be set to the ufunc result. Elsewhere, the `out`\narray will retain its original value. Note that if an uninitialized `out`\narray is created via the default `out=None`, locations within it where the\ncondition is False will remain uninitialized.\n\nFor other keyword-only arguments, see the ufunc docs.\n\nThe product of `x1` and `x2`, element-wise. This is a scalar if both `x1` and\n`x2` are scalars.\n\nEquivalent to `x1` * `x2` in terms of array broadcasting.\n\nThe `*` operator can be used as a shorthand for `np.multiply` on ndarrays.\n\n"}, {"name": "numpy.NAN", "path": "reference/constants#numpy.NAN", "type": "Constants", "text": "\nIEEE 754 floating point representation of Not a Number (NaN).\n\n`NaN` and `NAN` are equivalent definitions of `nan`. Please use `nan` instead\nof `NAN`.\n\nnan\n\n"}, {"name": "numpy.NaN", "path": "reference/constants#numpy.NaN", "type": "Constants", "text": "\nIEEE 754 floating point representation of Not a Number (NaN).\n\n`NaN` and `NAN` are equivalent definitions of `nan`. Please use `nan` instead\nof `NaN`.\n\nnan\n\n"}, {"name": "numpy.nan", "path": "reference/constants#numpy.nan", "type": "Constants", "text": "\nIEEE 754 floating point representation of Not a Number (NaN).\n\ny : A floating point representation of Not a Number.\n\nisnan : Shows which elements are Not a Number.\n\nisfinite : Shows which elements are finite (not one of Not a Number, positive\ninfinity and negative infinity)\n\nNumPy uses the IEEE Standard for Binary Floating-Point for Arithmetic (IEEE\n754). This means that Not a Number is not equivalent to infinity.\n\n`NaN` and `NAN` are aliases of `nan`.\n\n"}, {"name": "numpy.nan_to_num()", "path": "reference/generated/numpy.nan_to_num", "type": "numpy.nan_to_num", "text": "\nReplace NaN with zero and infinity with large finite numbers (default\nbehaviour) or with the numbers defined by the user using the `nan`, `posinf`\nand/or `neginf` keywords.\n\nIf `x` is inexact, NaN is replaced by zero or by the user defined value in\n`nan` keyword, infinity is replaced by the largest finite floating point\nvalues representable by `x.dtype` or by the user defined value in `posinf`\nkeyword and -infinity is replaced by the most negative finite floating point\nvalues representable by `x.dtype` or by the user defined value in `neginf`\nkeyword.\n\nFor complex dtypes, the above is applied to each of the real and imaginary\ncomponents of `x` separately.\n\nIf `x` is not inexact, then no replacements are made.\n\nInput data.\n\nWhether to create a copy of `x` (True) or to replace values in-place (False).\nThe in-place operation only occurs if casting to an array does not require a\ncopy. Default is True.\n\nNew in version 1.13.\n\nValue to be used to fill NaN values. If no value is passed then NaN values\nwill be replaced with 0.0.\n\nNew in version 1.17.\n\nValue to be used to fill positive infinity values. If no value is passed then\npositive infinity values will be replaced with a very large number.\n\nNew in version 1.17.\n\nValue to be used to fill negative infinity values. If no value is passed then\nnegative infinity values will be replaced with a very small (or negative)\nnumber.\n\nNew in version 1.17.\n\n`x`, with the non-finite values replaced. If `copy` is False, this may be `x`\nitself.\n\nSee also\n\nShows which elements are positive or negative infinity.\n\nShows which elements are negative infinity.\n\nShows which elements are positive infinity.\n\nShows which elements are Not a Number (NaN).\n\nShows which elements are finite (not NaN, not infinity)\n\nNumPy uses the IEEE Standard for Binary Floating-Point for Arithmetic (IEEE\n754). This means that Not a Number is not equivalent to infinity.\n\n"}, {"name": "numpy.nanargmax()", "path": "reference/generated/numpy.nanargmax", "type": "numpy.nanargmax", "text": "\nReturn the indices of the maximum values in the specified axis ignoring NaNs.\nFor all-NaN slices `ValueError` is raised. Warning: the results cannot be\ntrusted if a slice contains only NaNs and -Infs.\n\nInput data.\n\nAxis along which to operate. By default flattened input is used.\n\nIf provided, the result will be inserted into this array. It should be of the\nappropriate shape and dtype.\n\nNew in version 1.22.0.\n\nIf this is set to True, the axes which are reduced are left in the result as\ndimensions with size one. With this option, the result will broadcast\ncorrectly against the array.\n\nNew in version 1.22.0.\n\nAn array of indices or a single index value.\n\nSee also\n\n"}, {"name": "numpy.nanargmin()", "path": "reference/generated/numpy.nanargmin", "type": "numpy.nanargmin", "text": "\nReturn the indices of the minimum values in the specified axis ignoring NaNs.\nFor all-NaN slices `ValueError` is raised. Warning: the results cannot be\ntrusted if a slice contains only NaNs and Infs.\n\nInput data.\n\nAxis along which to operate. By default flattened input is used.\n\nIf provided, the result will be inserted into this array. It should be of the\nappropriate shape and dtype.\n\nNew in version 1.22.0.\n\nIf this is set to True, the axes which are reduced are left in the result as\ndimensions with size one. With this option, the result will broadcast\ncorrectly against the array.\n\nNew in version 1.22.0.\n\nAn array of indices or a single index value.\n\nSee also\n\n"}, {"name": "numpy.nancumprod()", "path": "reference/generated/numpy.nancumprod", "type": "numpy.nancumprod", "text": "\nReturn the cumulative product of array elements over a given axis treating Not\na Numbers (NaNs) as one. The cumulative product does not change when NaNs are\nencountered and leading NaNs are replaced by ones.\n\nOnes are returned for slices that are all-NaN or empty.\n\nNew in version 1.12.0.\n\nInput array.\n\nAxis along which the cumulative product is computed. By default the input is\nflattened.\n\nType of the returned array, as well as of the accumulator in which the\nelements are multiplied. If dtype is not specified, it defaults to the dtype\nof `a`, unless `a` has an integer dtype with a precision less than that of the\ndefault platform integer. In that case, the default platform integer is used\ninstead.\n\nAlternative output array in which to place the result. It must have the same\nshape and buffer length as the expected output but the type of the resulting\nvalues will be cast if necessary.\n\nA new array holding the result is returned unless `out` is specified, in which\ncase it is returned.\n\nSee also\n\nCumulative product across array propagating NaNs.\n\nShow which elements are NaN.\n\n"}, {"name": "numpy.nancumsum()", "path": "reference/generated/numpy.nancumsum", "type": "numpy.nancumsum", "text": "\nReturn the cumulative sum of array elements over a given axis treating Not a\nNumbers (NaNs) as zero. The cumulative sum does not change when NaNs are\nencountered and leading NaNs are replaced by zeros.\n\nZeros are returned for slices that are all-NaN or empty.\n\nNew in version 1.12.0.\n\nInput array.\n\nAxis along which the cumulative sum is computed. The default (None) is to\ncompute the cumsum over the flattened array.\n\nType of the returned array and of the accumulator in which the elements are\nsummed. If `dtype` is not specified, it defaults to the dtype of `a`, unless\n`a` has an integer dtype with a precision less than that of the default\nplatform integer. In that case, the default platform integer is used.\n\nAlternative output array in which to place the result. It must have the same\nshape and buffer length as the expected output but the type will be cast if\nnecessary. See Output type determination for more details.\n\nA new array holding the result is returned unless `out` is specified, in which\nit is returned. The result has the same size as `a`, and the same shape as `a`\nif `axis` is not None or `a` is a 1-d array.\n\nSee also\n\nCumulative sum across array propagating NaNs.\n\nShow which elements are NaN.\n\n"}, {"name": "numpy.nanmax()", "path": "reference/generated/numpy.nanmax", "type": "numpy.nanmax", "text": "\nReturn the maximum of an array or maximum along an axis, ignoring any NaNs.\nWhen all-NaN slices are encountered a `RuntimeWarning` is raised and NaN is\nreturned for that slice.\n\nArray containing numbers whose maximum is desired. If `a` is not an array, a\nconversion is attempted.\n\nAxis or axes along which the maximum is computed. The default is to compute\nthe maximum of the flattened array.\n\nAlternate output array in which to place the result. The default is `None`; if\nprovided, it must have the same shape as the expected output, but the type\nwill be cast if necessary. See Output type determination for more details.\n\nNew in version 1.8.0.\n\nIf this is set to True, the axes which are reduced are left in the result as\ndimensions with size one. With this option, the result will broadcast\ncorrectly against the original `a`.\n\nIf the value is anything but the default, then `keepdims` will be passed\nthrough to the `max` method of sub-classes of `ndarray`. If the sub-classes\nmethods does not implement `keepdims` any exceptions will be raised.\n\nNew in version 1.8.0.\n\nThe minimum value of an output element. Must be present to allow computation\non empty slice. See `reduce` for details.\n\nNew in version 1.22.0.\n\nElements to compare for the maximum. See `reduce` for details.\n\nNew in version 1.22.0.\n\nAn array with the same shape as `a`, with the specified axis removed. If `a`\nis a 0-d array, or if axis is None, an ndarray scalar is returned. The same\ndtype as `a` is returned.\n\nSee also\n\nThe minimum value of an array along a given axis, ignoring any NaNs.\n\nThe maximum value of an array along a given axis, propagating any NaNs.\n\nElement-wise maximum of two arrays, ignoring any NaNs.\n\nElement-wise maximum of two arrays, propagating any NaNs.\n\nShows which elements are Not a Number (NaN).\n\nShows which elements are neither NaN nor infinity.\n\nNumPy uses the IEEE Standard for Binary Floating-Point for Arithmetic (IEEE\n754). This means that Not a Number is not equivalent to infinity. Positive\ninfinity is treated as a very large number and negative infinity is treated as\na very small (i.e. negative) number.\n\nIf the input has a integer type the function is equivalent to np.max.\n\nWhen positive infinity and negative infinity are present:\n\n"}, {"name": "numpy.nanmean()", "path": "reference/generated/numpy.nanmean", "type": "numpy.nanmean", "text": "\nCompute the arithmetic mean along the specified axis, ignoring NaNs.\n\nReturns the average of the array elements. The average is taken over the\nflattened array by default, otherwise over the specified axis. `float64`\nintermediate and return values are used for integer inputs.\n\nFor all-NaN slices, NaN is returned and a `RuntimeWarning` is raised.\n\nNew in version 1.8.0.\n\nArray containing numbers whose mean is desired. If `a` is not an array, a\nconversion is attempted.\n\nAxis or axes along which the means are computed. The default is to compute the\nmean of the flattened array.\n\nType to use in computing the mean. For integer inputs, the default is\n`float64`; for inexact inputs, it is the same as the input dtype.\n\nAlternate output array in which to place the result. The default is `None`; if\nprovided, it must have the same shape as the expected output, but the type\nwill be cast if necessary. See Output type determination for more details.\n\nIf this is set to True, the axes which are reduced are left in the result as\ndimensions with size one. With this option, the result will broadcast\ncorrectly against the original `a`.\n\nIf the value is anything but the default, then `keepdims` will be passed\nthrough to the `mean` or `sum` methods of sub-classes of `ndarray`. If the\nsub-classes methods does not implement `keepdims` any exceptions will be\nraised.\n\nElements to include in the mean. See `reduce` for details.\n\nNew in version 1.22.0.\n\nIf `out=None`, returns a new array containing the mean values, otherwise a\nreference to the output array is returned. Nan is returned for slices that\ncontain only NaNs.\n\nSee also\n\nWeighted average\n\nArithmetic mean taken while not ignoring NaNs\n\nThe arithmetic mean is the sum of the non-NaN elements along the axis divided\nby the number of non-NaN elements.\n\nNote that for floating-point input, the mean is computed using the same\nprecision the input has. Depending on the input data, this can cause the\nresults to be inaccurate, especially for `float32`. Specifying a higher-\nprecision accumulator using the `dtype` keyword can alleviate this issue.\n\n"}, {"name": "numpy.nanmedian()", "path": "reference/generated/numpy.nanmedian", "type": "numpy.nanmedian", "text": "\nCompute the median along the specified axis, while ignoring NaNs.\n\nReturns the median of the array elements.\n\nNew in version 1.9.0.\n\nInput array or object that can be converted to an array.\n\nAxis or axes along which the medians are computed. The default is to compute\nthe median along a flattened version of the array. A sequence of axes is\nsupported since version 1.9.0.\n\nAlternative output array in which to place the result. It must have the same\nshape and buffer length as the expected output, but the type (of the output)\nwill be cast if necessary.\n\nIf True, then allow use of memory of input array `a` for calculations. The\ninput array will be modified by the call to `median`. This will save memory\nwhen you do not need to preserve the contents of the input array. Treat the\ninput as undefined, but it will probably be fully or partially sorted. Default\nis False. If `overwrite_input` is `True` and `a` is not already an `ndarray`,\nan error will be raised.\n\nIf this is set to True, the axes which are reduced are left in the result as\ndimensions with size one. With this option, the result will broadcast\ncorrectly against the original `a`.\n\nIf this is anything but the default value it will be passed through (in the\nspecial case of an empty array) to the `mean` function of the underlying\narray. If the array is a sub-class and `mean` does not have the kwarg\n`keepdims` this will raise a RuntimeError.\n\nA new array holding the result. If the input contains integers or floats\nsmaller than `float64`, then the output data-type is `np.float64`. Otherwise,\nthe data-type of the output is the same as that of the input. If `out` is\nspecified, that array is returned instead.\n\nSee also\n\nGiven a vector `V` of length `N`, the median of `V` is the middle value of a\nsorted copy of `V`, `V_sorted` \\- i.e., `V_sorted[(N-1)/2]`, when `N` is odd\nand the average of the two middle values of `V_sorted` when `N` is even.\n\n"}, {"name": "numpy.nanmin()", "path": "reference/generated/numpy.nanmin", "type": "numpy.nanmin", "text": "\nReturn minimum of an array or minimum along an axis, ignoring any NaNs. When\nall-NaN slices are encountered a `RuntimeWarning` is raised and Nan is\nreturned for that slice.\n\nArray containing numbers whose minimum is desired. If `a` is not an array, a\nconversion is attempted.\n\nAxis or axes along which the minimum is computed. The default is to compute\nthe minimum of the flattened array.\n\nAlternate output array in which to place the result. The default is `None`; if\nprovided, it must have the same shape as the expected output, but the type\nwill be cast if necessary. See Output type determination for more details.\n\nNew in version 1.8.0.\n\nIf this is set to True, the axes which are reduced are left in the result as\ndimensions with size one. With this option, the result will broadcast\ncorrectly against the original `a`.\n\nIf the value is anything but the default, then `keepdims` will be passed\nthrough to the `min` method of sub-classes of `ndarray`. If the sub-classes\nmethods does not implement `keepdims` any exceptions will be raised.\n\nNew in version 1.8.0.\n\nThe maximum value of an output element. Must be present to allow computation\non empty slice. See `reduce` for details.\n\nNew in version 1.22.0.\n\nElements to compare for the minimum. See `reduce` for details.\n\nNew in version 1.22.0.\n\nAn array with the same shape as `a`, with the specified axis removed. If `a`\nis a 0-d array, or if axis is None, an ndarray scalar is returned. The same\ndtype as `a` is returned.\n\nSee also\n\nThe maximum value of an array along a given axis, ignoring any NaNs.\n\nThe minimum value of an array along a given axis, propagating any NaNs.\n\nElement-wise minimum of two arrays, ignoring any NaNs.\n\nElement-wise minimum of two arrays, propagating any NaNs.\n\nShows which elements are Not a Number (NaN).\n\nShows which elements are neither NaN nor infinity.\n\nNumPy uses the IEEE Standard for Binary Floating-Point for Arithmetic (IEEE\n754). This means that Not a Number is not equivalent to infinity. Positive\ninfinity is treated as a very large number and negative infinity is treated as\na very small (i.e. negative) number.\n\nIf the input has a integer type the function is equivalent to np.min.\n\nWhen positive infinity and negative infinity are present:\n\n"}, {"name": "numpy.nanpercentile()", "path": "reference/generated/numpy.nanpercentile", "type": "numpy.nanpercentile", "text": "\nCompute the qth percentile of the data along the specified axis, while\nignoring nan values.\n\nReturns the qth percentile(s) of the array elements.\n\nNew in version 1.9.0.\n\nInput array or object that can be converted to an array, containing nan values\nto be ignored.\n\nPercentile or sequence of percentiles to compute, which must be between 0 and\n100 inclusive.\n\nAxis or axes along which the percentiles are computed. The default is to\ncompute the percentile(s) along a flattened version of the array.\n\nAlternative output array in which to place the result. It must have the same\nshape and buffer length as the expected output, but the type (of the output)\nwill be cast if necessary.\n\nIf True, then allow the input array `a` to be modified by intermediate\ncalculations, to save memory. In this case, the contents of the input `a`\nafter this function completes is undefined.\n\nThis parameter specifies the method to use for estimating the percentile.\nThere are many different methods, some unique to NumPy. See the notes for\nexplanation. The options sorted by their R type as summarized in the H&F paper\n[1] are:\n\nThe first three methods are discontiuous. NumPy further defines the following\ndiscontinuous variations of the default \u2018linear\u2019 (7.) option:\n\nChanged in version 1.22.0: This argument was previously called \u201cinterpolation\u201d\nand only offered the \u201clinear\u201d default and last four options.\n\nIf this is set to True, the axes which are reduced are left in the result as\ndimensions with size one. With this option, the result will broadcast\ncorrectly against the original array `a`.\n\nIf this is anything but the default value it will be passed through (in the\nspecial case of an empty array) to the `mean` function of the underlying\narray. If the array is a sub-class and `mean` does not have the kwarg\n`keepdims` this will raise a RuntimeError.\n\nDeprecated name for the method keyword argument.\n\nDeprecated since version 1.22.0.\n\nIf `q` is a single percentile and `axis=None`, then the result is a scalar. If\nmultiple percentiles are given, first axis of the result corresponds to the\npercentiles. The other axes are the axes that remain after the reduction of\n`a`. If the input contains integers or floats smaller than `float64`, the\noutput data-type is `float64`. Otherwise, the output data-type is the same as\nthat of the input. If `out` is specified, that array is returned instead.\n\nSee also\n\nequivalent to `nanpercentile(..., 50)`\n\nequivalent to nanpercentile, except q in range [0, 1].\n\nFor more information please see `numpy.percentile`\n\nR. J. Hyndman and Y. Fan, \u201cSample quantiles in statistical packages,\u201d The\nAmerican Statistician, 50(4), pp. 361-365, 1996\n\n"}, {"name": "numpy.nanprod()", "path": "reference/generated/numpy.nanprod", "type": "numpy.nanprod", "text": "\nReturn the product of array elements over a given axis treating Not a Numbers\n(NaNs) as ones.\n\nOne is returned for slices that are all-NaN or empty.\n\nNew in version 1.10.0.\n\nArray containing numbers whose product is desired. If `a` is not an array, a\nconversion is attempted.\n\nAxis or axes along which the product is computed. The default is to compute\nthe product of the flattened array.\n\nThe type of the returned array and of the accumulator in which the elements\nare summed. By default, the dtype of `a` is used. An exception is when `a` has\nan integer type with less precision than the platform (u)intp. In that case,\nthe default will be either (u)int32 or (u)int64 depending on whether the\nplatform is 32 or 64 bits. For inexact inputs, dtype must be inexact.\n\nAlternate output array in which to place the result. The default is `None`. If\nprovided, it must have the same shape as the expected output, but the type\nwill be cast if necessary. See Output type determination for more details. The\ncasting of NaN to integer can yield unexpected results.\n\nIf True, the axes which are reduced are left in the result as dimensions with\nsize one. With this option, the result will broadcast correctly against the\noriginal `arr`.\n\nThe starting value for this product. See `reduce` for details.\n\nNew in version 1.22.0.\n\nElements to include in the product. See `reduce` for details.\n\nNew in version 1.22.0.\n\nA new array holding the result is returned unless `out` is specified, in which\ncase it is returned.\n\nSee also\n\nProduct across array propagating NaNs.\n\nShow which elements are NaN.\n\n"}, {"name": "numpy.nanquantile()", "path": "reference/generated/numpy.nanquantile", "type": "numpy.nanquantile", "text": "\nCompute the qth quantile of the data along the specified axis, while ignoring\nnan values. Returns the qth quantile(s) of the array elements.\n\nNew in version 1.15.0.\n\nInput array or object that can be converted to an array, containing nan values\nto be ignored\n\nQuantile or sequence of quantiles to compute, which must be between 0 and 1\ninclusive.\n\nAxis or axes along which the quantiles are computed. The default is to compute\nthe quantile(s) along a flattened version of the array.\n\nAlternative output array in which to place the result. It must have the same\nshape and buffer length as the expected output, but the type (of the output)\nwill be cast if necessary.\n\nIf True, then allow the input array `a` to be modified by intermediate\ncalculations, to save memory. In this case, the contents of the input `a`\nafter this function completes is undefined.\n\nThis parameter specifies the method to use for estimating the quantile. There\nare many different methods, some unique to NumPy. See the notes for\nexplanation. The options sorted by their R type as summarized in the H&F paper\n[1] are:\n\nThe first three methods are discontiuous. NumPy further defines the following\ndiscontinuous variations of the default \u2018linear\u2019 (7.) option:\n\nChanged in version 1.22.0: This argument was previously called \u201cinterpolation\u201d\nand only offered the \u201clinear\u201d default and last four options.\n\nIf this is set to True, the axes which are reduced are left in the result as\ndimensions with size one. With this option, the result will broadcast\ncorrectly against the original array `a`.\n\nIf this is anything but the default value it will be passed through (in the\nspecial case of an empty array) to the `mean` function of the underlying\narray. If the array is a sub-class and `mean` does not have the kwarg\n`keepdims` this will raise a RuntimeError.\n\nDeprecated name for the method keyword argument.\n\nDeprecated since version 1.22.0.\n\nIf `q` is a single percentile and `axis=None`, then the result is a scalar. If\nmultiple quantiles are given, first axis of the result corresponds to the\nquantiles. The other axes are the axes that remain after the reduction of `a`.\nIf the input contains integers or floats smaller than `float64`, the output\ndata-type is `float64`. Otherwise, the output data-type is the same as that of\nthe input. If `out` is specified, that array is returned instead.\n\nSee also\n\nequivalent to `nanquantile(..., 0.5)`\n\nsame as nanquantile, but with q in the range [0, 100].\n\nFor more information please see `numpy.quantile`\n\nR. J. Hyndman and Y. Fan, \u201cSample quantiles in statistical packages,\u201d The\nAmerican Statistician, 50(4), pp. 361-365, 1996\n\n"}, {"name": "numpy.nanstd()", "path": "reference/generated/numpy.nanstd", "type": "numpy.nanstd", "text": "\nCompute the standard deviation along the specified axis, while ignoring NaNs.\n\nReturns the standard deviation, a measure of the spread of a distribution, of\nthe non-NaN array elements. The standard deviation is computed for the\nflattened array by default, otherwise over the specified axis.\n\nFor all-NaN slices or slices with zero degrees of freedom, NaN is returned and\na `RuntimeWarning` is raised.\n\nNew in version 1.8.0.\n\nCalculate the standard deviation of the non-NaN values.\n\nAxis or axes along which the standard deviation is computed. The default is to\ncompute the standard deviation of the flattened array.\n\nType to use in computing the standard deviation. For arrays of integer type\nthe default is float64, for arrays of float types it is the same as the array\ntype.\n\nAlternative output array in which to place the result. It must have the same\nshape as the expected output but the type (of the calculated values) will be\ncast if necessary.\n\nMeans Delta Degrees of Freedom. The divisor used in calculations is `N -\nddof`, where `N` represents the number of non-NaN elements. By default `ddof`\nis zero.\n\nIf this is set to True, the axes which are reduced are left in the result as\ndimensions with size one. With this option, the result will broadcast\ncorrectly against the original `a`.\n\nIf this value is anything but the default it is passed through as-is to the\nrelevant functions of the sub-classes. If these functions do not have a\n`keepdims` kwarg, a RuntimeError will be raised.\n\nElements to include in the standard deviation. See `reduce` for details.\n\nNew in version 1.22.0.\n\nIf `out` is None, return a new array containing the standard deviation,\notherwise return a reference to the output array. If ddof is >= the number of\nnon-NaN elements in a slice or the slice contains only NaNs, then the result\nfor that slice is NaN.\n\nSee also\n\nThe standard deviation is the square root of the average of the squared\ndeviations from the mean: `std = sqrt(mean(abs(x - x.mean())**2))`.\n\nThe average squared deviation is normally calculated as `x.sum() / N`, where\n`N = len(x)`. If, however, `ddof` is specified, the divisor `N - ddof` is used\ninstead. In standard statistical practice, `ddof=1` provides an unbiased\nestimator of the variance of the infinite population. `ddof=0` provides a\nmaximum likelihood estimate of the variance for normally distributed\nvariables. The standard deviation computed in this function is the square root\nof the estimated variance, so even with `ddof=1`, it will not be an unbiased\nestimate of the standard deviation per se.\n\nNote that, for complex numbers, `std` takes the absolute value before\nsquaring, so that the result is always real and nonnegative.\n\nFor floating-point input, the std is computed using the same precision the\ninput has. Depending on the input data, this can cause the results to be\ninaccurate, especially for float32 (see example below). Specifying a higher-\naccuracy accumulator using the `dtype` keyword can alleviate this issue.\n\n"}, {"name": "numpy.nansum()", "path": "reference/generated/numpy.nansum", "type": "numpy.nansum", "text": "\nReturn the sum of array elements over a given axis treating Not a Numbers\n(NaNs) as zero.\n\nIn NumPy versions <= 1.9.0 Nan is returned for slices that are all-NaN or\nempty. In later versions zero is returned.\n\nArray containing numbers whose sum is desired. If `a` is not an array, a\nconversion is attempted.\n\nAxis or axes along which the sum is computed. The default is to compute the\nsum of the flattened array.\n\nThe type of the returned array and of the accumulator in which the elements\nare summed. By default, the dtype of `a` is used. An exception is when `a` has\nan integer type with less precision than the platform (u)intp. In that case,\nthe default will be either (u)int32 or (u)int64 depending on whether the\nplatform is 32 or 64 bits. For inexact inputs, dtype must be inexact.\n\nNew in version 1.8.0.\n\nAlternate output array in which to place the result. The default is `None`. If\nprovided, it must have the same shape as the expected output, but the type\nwill be cast if necessary. See Output type determination for more details. The\ncasting of NaN to integer can yield unexpected results.\n\nNew in version 1.8.0.\n\nIf this is set to True, the axes which are reduced are left in the result as\ndimensions with size one. With this option, the result will broadcast\ncorrectly against the original `a`.\n\nIf the value is anything but the default, then `keepdims` will be passed\nthrough to the `mean` or `sum` methods of sub-classes of `ndarray`. If the\nsub-classes methods does not implement `keepdims` any exceptions will be\nraised.\n\nNew in version 1.8.0.\n\nStarting value for the sum. See `reduce` for details.\n\nNew in version 1.22.0.\n\nElements to include in the sum. See `reduce` for details.\n\nNew in version 1.22.0.\n\nA new array holding the result is returned unless `out` is specified, in which\nit is returned. The result has the same size as `a`, and the same shape as `a`\nif `axis` is not None or `a` is a 1-d array.\n\nSee also\n\nSum across array propagating NaNs.\n\nShow which elements are NaN.\n\nShow which elements are not NaN or +/-inf.\n\nIf both positive and negative infinity are present, the sum will be Not A\nNumber (NaN).\n\n"}, {"name": "numpy.nanvar()", "path": "reference/generated/numpy.nanvar", "type": "numpy.nanvar", "text": "\nCompute the variance along the specified axis, while ignoring NaNs.\n\nReturns the variance of the array elements, a measure of the spread of a\ndistribution. The variance is computed for the flattened array by default,\notherwise over the specified axis.\n\nFor all-NaN slices or slices with zero degrees of freedom, NaN is returned and\na `RuntimeWarning` is raised.\n\nNew in version 1.8.0.\n\nArray containing numbers whose variance is desired. If `a` is not an array, a\nconversion is attempted.\n\nAxis or axes along which the variance is computed. The default is to compute\nthe variance of the flattened array.\n\nType to use in computing the variance. For arrays of integer type the default\nis `float64`; for arrays of float types it is the same as the array type.\n\nAlternate output array in which to place the result. It must have the same\nshape as the expected output, but the type is cast if necessary.\n\n\u201cDelta Degrees of Freedom\u201d: the divisor used in the calculation is `N - ddof`,\nwhere `N` represents the number of non-NaN elements. By default `ddof` is\nzero.\n\nIf this is set to True, the axes which are reduced are left in the result as\ndimensions with size one. With this option, the result will broadcast\ncorrectly against the original `a`.\n\nElements to include in the variance. See `reduce` for details.\n\nNew in version 1.22.0.\n\nIf `out` is None, return a new array containing the variance, otherwise return\na reference to the output array. If ddof is >= the number of non-NaN elements\nin a slice or the slice contains only NaNs, then the result for that slice is\nNaN.\n\nSee also\n\nStandard deviation\n\nAverage\n\nVariance while not ignoring NaNs\n\nThe variance is the average of the squared deviations from the mean, i.e.,\n`var = mean(abs(x - x.mean())**2)`.\n\nThe mean is normally calculated as `x.sum() / N`, where `N = len(x)`. If,\nhowever, `ddof` is specified, the divisor `N - ddof` is used instead. In\nstandard statistical practice, `ddof=1` provides an unbiased estimator of the\nvariance of a hypothetical infinite population. `ddof=0` provides a maximum\nlikelihood estimate of the variance for normally distributed variables.\n\nNote that for complex numbers, the absolute value is taken before squaring, so\nthat the result is always real and nonnegative.\n\nFor floating-point input, the variance is computed using the same precision\nthe input has. Depending on the input data, this can cause the results to be\ninaccurate, especially for `float32` (see example below). Specifying a higher-\naccuracy accumulator using the `dtype` keyword can alleviate this issue.\n\nFor this function to work on sub-classes of ndarray, they must define `sum`\nwith the kwarg `keepdims`\n\n"}, {"name": "numpy.ndarray()", "path": "reference/generated/numpy.ndarray", "type": "numpy.ndarray", "text": "\nAn array object represents a multidimensional, homogeneous array of fixed-size\nitems. An associated data-type object describes the format of each element in\nthe array (its byte-order, how many bytes it occupies in memory, whether it is\nan integer, a floating point number, or something else, etc.)\n\nArrays should be constructed using `array`, `zeros` or `empty` (refer to the\nSee Also section below). The parameters given here refer to a low-level method\n(`ndarray(\u2026)`) for instantiating an array.\n\nFor more information, refer to the `numpy` module and examine the methods and\nattributes of an array.\n\nShape of created array.\n\nAny object that can be interpreted as a numpy data type.\n\nUsed to fill the array with data.\n\nOffset of array data in buffer.\n\nStrides of data in memory.\n\nRow-major (C-style) or column-major (Fortran-style) order.\n\nSee also\n\nConstruct an array.\n\nCreate an array, each element of which is zero.\n\nCreate an array, but leave its allocated memory unchanged (i.e., it contains\n\u201cgarbage\u201d).\n\nCreate a data-type.\n\nAn ndarray alias generic w.r.t. its `dtype.type`.\n\nThere are two modes of creating an array using `__new__`:\n\nNo `__init__` method is needed because the array is fully initialized after\nthe `__new__` method.\n\nThese examples illustrate the low-level `ndarray` constructor. Refer to the\n`See Also` section above for easier ways of constructing an ndarray.\n\nFirst mode, `buffer` is None:\n\nSecond mode:\n\nThe transposed array.\n\nPython buffer object pointing to the start of the array\u2019s data.\n\nData-type of the array\u2019s elements.\n\nInformation about the memory layout of the array.\n\nA 1-D iterator over the array.\n\nThe imaginary part of the array.\n\nThe real part of the array.\n\nNumber of elements in the array.\n\nLength of one array element in bytes.\n\nTotal bytes consumed by the elements of the array.\n\nNumber of array dimensions.\n\nTuple of array dimensions.\n\nTuple of bytes to step in each dimension when traversing an array.\n\nAn object to simplify the interaction of the array with the ctypes module.\n\nBase object if memory is from some other object.\n\n`all`([axis, out, keepdims, where])\n\nReturns True if all elements evaluate to True.\n\n`any`([axis, out, keepdims, where])\n\nReturns True if any of the elements of `a` evaluate to True.\n\n`argmax`([axis, out])\n\nReturn indices of the maximum values along the given axis.\n\n`argmin`([axis, out])\n\nReturn indices of the minimum values along the given axis.\n\n`argpartition`(kth[, axis, kind, order])\n\nReturns the indices that would partition this array.\n\n`argsort`([axis, kind, order])\n\nReturns the indices that would sort this array.\n\n`astype`(dtype[, order, casting, subok, copy])\n\nCopy of the array, cast to a specified type.\n\n`byteswap`([inplace])\n\nSwap the bytes of the array elements\n\n`choose`(choices[, out, mode])\n\nUse an index array to construct a new array from a set of choices.\n\n`clip`([min, max, out])\n\nReturn an array whose values are limited to `[min, max]`.\n\n`compress`(condition[, axis, out])\n\nReturn selected slices of this array along given axis.\n\n`conj`()\n\nComplex-conjugate all elements.\n\n`conjugate`()\n\nReturn the complex conjugate, element-wise.\n\n`copy`([order])\n\nReturn a copy of the array.\n\n`cumprod`([axis, dtype, out])\n\nReturn the cumulative product of the elements along the given axis.\n\n`cumsum`([axis, dtype, out])\n\nReturn the cumulative sum of the elements along the given axis.\n\n`diagonal`([offset, axis1, axis2])\n\nReturn specified diagonals.\n\n`dump`(file)\n\nDump a pickle of the array to the specified file.\n\n`dumps`()\n\nReturns the pickle of the array as a string.\n\n`fill`(value)\n\nFill the array with a scalar value.\n\n`flatten`([order])\n\nReturn a copy of the array collapsed into one dimension.\n\n`getfield`(dtype[, offset])\n\nReturns a field of the given array as a certain type.\n\n`item`(*args)\n\nCopy an element of an array to a standard Python scalar and return it.\n\n`itemset`(*args)\n\nInsert scalar into an array (scalar is cast to array's dtype, if possible)\n\n`max`([axis, out, keepdims, initial, where])\n\nReturn the maximum along a given axis.\n\n`mean`([axis, dtype, out, keepdims, where])\n\nReturns the average of the array elements along given axis.\n\n`min`([axis, out, keepdims, initial, where])\n\nReturn the minimum along a given axis.\n\n`newbyteorder`([new_order])\n\nReturn the array with the same data viewed with a different byte order.\n\n`nonzero`()\n\nReturn the indices of the elements that are non-zero.\n\n`partition`(kth[, axis, kind, order])\n\nRearranges the elements in the array in such a way that the value of the\nelement in kth position is in the position it would be in a sorted array.\n\n`prod`([axis, dtype, out, keepdims, initial, ...])\n\nReturn the product of the array elements over the given axis\n\n`ptp`([axis, out, keepdims])\n\nPeak to peak (maximum - minimum) value along a given axis.\n\n`put`(indices, values[, mode])\n\nSet `a.flat[n] = values[n]` for all `n` in indices.\n\n`ravel`([order])\n\nReturn a flattened array.\n\n`repeat`(repeats[, axis])\n\nRepeat elements of an array.\n\n`reshape`(shape[, order])\n\nReturns an array containing the same data with a new shape.\n\n`resize`(new_shape[, refcheck])\n\nChange shape and size of array in-place.\n\n`round`([decimals, out])\n\nReturn `a` with each element rounded to the given number of decimals.\n\n`searchsorted`(v[, side, sorter])\n\nFind indices where elements of v should be inserted in a to maintain order.\n\n`setfield`(val, dtype[, offset])\n\nPut a value into a specified place in a field defined by a data-type.\n\n`setflags`([write, align, uic])\n\nSet array flags WRITEABLE, ALIGNED, (WRITEBACKIFCOPY and UPDATEIFCOPY),\nrespectively.\n\n`sort`([axis, kind, order])\n\nSort an array in-place.\n\n`squeeze`([axis])\n\nRemove axes of length one from `a`.\n\n`std`([axis, dtype, out, ddof, keepdims, where])\n\nReturns the standard deviation of the array elements along given axis.\n\n`sum`([axis, dtype, out, keepdims, initial, where])\n\nReturn the sum of the array elements over the given axis.\n\n`swapaxes`(axis1, axis2)\n\nReturn a view of the array with `axis1` and `axis2` interchanged.\n\n`take`(indices[, axis, out, mode])\n\nReturn an array formed from the elements of `a` at the given indices.\n\n`tobytes`([order])\n\nConstruct Python bytes containing the raw data bytes in the array.\n\n`tofile`(fid[, sep, format])\n\nWrite array to a file as text or binary (default).\n\n`tolist`()\n\nReturn the array as an `a.ndim`-levels deep nested list of Python scalars.\n\n`tostring`([order])\n\nA compatibility alias for `tobytes`, with exactly the same behavior.\n\n`trace`([offset, axis1, axis2, dtype, out])\n\nReturn the sum along diagonals of the array.\n\n`transpose`(*axes)\n\nReturns a view of the array with axes transposed.\n\n`var`([axis, dtype, out, ddof, keepdims, where])\n\nReturns the variance of the array elements, along given axis.\n\n`view`([dtype][, type])\n\nNew view of array with the same data.\n\ndot\n\n"}, {"name": "numpy.ndenumerate()", "path": "reference/generated/numpy.ndenumerate", "type": "numpy.ndenumerate", "text": "\nMultidimensional index iterator.\n\nReturn an iterator yielding pairs of array coordinates and values.\n\nInput array.\n\nSee also\n\n"}, {"name": "numpy.ndindex()", "path": "reference/generated/numpy.ndindex", "type": "numpy.ndindex", "text": "\nAn N-dimensional iterator object to index arrays.\n\nGiven the shape of an array, an `ndindex` instance iterates over the\nN-dimensional index of the array. At each iteration a tuple of indices is\nreturned, the last dimension is iterated over first.\n\nThe size of each dimension of the array can be passed as individual parameters\nor as the elements of a tuple.\n\nSee also\n\nDimensions as individual arguments\n\nSame dimensions - but in a tuple `(3, 2, 1)`\n\n`ndincr`()\n\nIncrement the multi-dimensional index by one.\n\n"}, {"name": "numpy.nditer()", "path": "reference/generated/numpy.nditer", "type": "numpy.nditer", "text": "\nEfficient multi-dimensional iterator object to iterate over arrays. To get\nstarted using this object, see the introductory guide to array iteration.\n\nThe array(s) to iterate over.\n\nFlags to control the behavior of the iterator.\n\nThis is a list of flags for each operand. At minimum, one of `readonly`,\n`readwrite`, or `writeonly` must be specified.\n\nThe required data type(s) of the operands. If copying or buffering is enabled,\nthe data will be converted to/from their original types.\n\nControls the iteration order. \u2018C\u2019 means C order, \u2018F\u2019 means Fortran order, \u2018A\u2019\nmeans \u2018F\u2019 order if all the arrays are Fortran contiguous, \u2018C\u2019 order otherwise,\nand \u2018K\u2019 means as close to the order the array elements appear in memory as\npossible. This also affects the element memory order of `allocate` operands,\nas they are allocated to be compatible with iteration order. Default is \u2018K\u2019.\n\nControls what kind of data casting may occur when making a copy or buffering.\nSetting this to \u2018unsafe\u2019 is not recommended, as it can adversely affect\naccumulations.\n\nIf provided, is a list of ints or None for each operands. The list of axes for\nan operand is a mapping from the dimensions of the iterator to the dimensions\nof the operand. A value of -1 can be placed for entries, causing that\ndimension to be treated as `newaxis`.\n\nThe desired shape of the iterator. This allows `allocate` operands with a\ndimension mapped by op_axes not corresponding to a dimension of a different\noperand to get a value not equal to 1 for that dimension.\n\nWhen buffering is enabled, controls the size of the temporary buffers. Set to\n0 for the default value.\n\n`nditer` supersedes `flatiter`. The iterator implementation behind `nditer` is\nalso exposed by the NumPy C API.\n\nThe Python exposure supplies two iteration interfaces, one which follows the\nPython iterator protocol, and another which mirrors the C-style do-while\npattern. The native Python approach is better in most cases, but if you need\nthe coordinates or index of an iterator, use the C-style pattern.\n\nHere is how we might write an `iter_add` function, using the Python iterator\nprotocol:\n\nHere is the same function, but following the C-style pattern:\n\nHere is an example outer product function:\n\nHere is an example function which operates like a \u201clambda\u201d ufunc:\n\nIf operand flags `\u201cwriteonly\u201d` or `\u201creadwrite\u201d` are used the operands may be\nviews into the original data with the `WRITEBACKIFCOPY` flag. In this case\n`nditer` must be used as a context manager or the `nditer.close` method must\nbe called before using the result. The temporary data will be written back to\nthe original data when the `__exit__` function is called but not before:\n\nIt is important to note that once the iterator is exited, dangling references\n(like `x` in the example) may or may not share data with the original data\n`a`. If writeback semantics were active, i.e. if\n`x.base.flags.writebackifcopy` is `True`, then exiting the iterator will sever\nthe connection between `x` and `a`, writing to `x` will no longer write to\n`a`. If writeback semantics are not active, then `x.data` will still point at\nsome part of `a.data`, and writing to one will affect the other.\n\nContext management and the `close` method appeared in version 1.15.0.\n\nThe data types of the values provided in `value`. This may be different from\nthe operand data types if buffering is enabled. Valid only before the iterator\nis closed.\n\nWhether the iteration over the operands is finished or not.\n\nIf True, the iterator was created with the `delay_bufalloc` flag, and no\nreset() function was called on it yet.\n\nIf True, the iterator was created with either the `c_index` or the `f_index`\nflag, and the property `index` can be used to retrieve it.\n\nIf True, the iterator was created with the `multi_index` flag, and the\nproperty `multi_index` can be used to retrieve it.\n\nWhen the `c_index` or `f_index` flag was used, this property provides access\nto the index. Raises a ValueError if accessed and `has_index` is False.\n\nWhether iteration requires access to the Python API, for example if one of the\noperands is an object array.\n\nAn index which matches the order of iteration.\n\nSize of the iterator.\n\nStructured view(s) of `operands` in memory, matching the reordered and\noptimized iterator access pattern. Valid only before the iterator is closed.\n\nWhen the `multi_index` flag was used, this property provides access to the\nindex. Raises a ValueError if accessed accessed and `has_multi_index` is\nFalse.\n\nThe dimensions of the iterator.\n\nThe number of iterator operands.\n\noperands[`Slice`]\n\nShape tuple, the shape of the iterator.\n\nValue of `operands` at current iteration. Normally, this is a tuple of array\nscalars, but if the flag `external_loop` is used, it is a tuple of one\ndimensional arrays.\n\n`close`()\n\nResolve all writeback semantics in writeable operands.\n\n`copy`()\n\nGet a copy of the iterator in its current state.\n\n`debug_print`()\n\nPrint the current state of the `nditer` instance and debug info to stdout.\n\n`enable_external_loop`()\n\nWhen the \"external_loop\" was not used during construction, but is desired,\nthis modifies the iterator to behave as if the flag was specified.\n\n`iternext`()\n\nCheck whether iterations are left, and perform a single internal iteration\nwithout returning the result.\n\n`remove_axis`(i, /)\n\nRemoves axis `i` from the iterator.\n\n`remove_multi_index`()\n\nWhen the \"multi_index\" flag was specified, this removes it, allowing the\ninternal iteration structure to be optimized further.\n\n`reset`()\n\nReset the iterator to its initial state.\n\n"}, {"name": "numpy.negative()", "path": "reference/generated/numpy.negative", "type": "numpy.negative", "text": "\nNumerical negative, element-wise.\n\nInput array.\n\nA location into which the result is stored. If provided, it must have a shape\nthat the inputs broadcast to. If not provided or None, a freshly-allocated\narray is returned. A tuple (possible only as a keyword argument) must have\nlength equal to the number of outputs.\n\nThis condition is broadcast over the input. At locations where the condition\nis True, the `out` array will be set to the ufunc result. Elsewhere, the `out`\narray will retain its original value. Note that if an uninitialized `out`\narray is created via the default `out=None`, locations within it where the\ncondition is False will remain uninitialized.\n\nFor other keyword-only arguments, see the ufunc docs.\n\nReturned array or scalar: `y = -x`. This is a scalar if `x` is a scalar.\n\nThe unary `-` operator can be used as a shorthand for `np.negative` on\nndarrays.\n\n"}, {"name": "numpy.nested_iters()", "path": "reference/generated/numpy.nested_iters", "type": "numpy.nested_iters", "text": "\nCreate nditers for use in nested loops\n\nCreate a tuple of `nditer` objects which iterate in nested loops over\ndifferent axes of the op argument. The first iterator is used in the outermost\nloop, the last in the innermost loop. Advancing one will change the subsequent\niterators to point at its new element.\n\nThe array(s) to iterate over.\n\nEach item is used as an \u201cop_axes\u201d argument to an nditer\n\nSee `nditer` parameters of the same name\n\nAn nditer for each item in `axes`, outermost first\n\nSee also\n\nBasic usage. Note how y is the \u201cflattened\u201d version of [a[:, 0, :], a[:, 1, 0],\na[:, 2, :]] since we specified the first iter\u2019s axes as [1]\n\n"}, {"name": "numpy.newaxis", "path": "reference/constants#numpy.newaxis", "type": "Constants", "text": "\nA convenient alias for None, useful for indexing arrays.\n\nOuter product, same as `outer(x, y)`:\n\n`x[newaxis, :]` is equivalent to `x[newaxis]` and `x[None]`:\n\n"}, {"name": "numpy.nextafter()", "path": "reference/generated/numpy.nextafter", "type": "numpy.nextafter", "text": "\nReturn the next floating-point value after x1 towards x2, element-wise.\n\nValues to find the next representable value of.\n\nThe direction where to look for the next representable value of `x1`. If\n`x1.shape != x2.shape`, they must be broadcastable to a common shape (which\nbecomes the shape of the output).\n\nA location into which the result is stored. If provided, it must have a shape\nthat the inputs broadcast to. If not provided or None, a freshly-allocated\narray is returned. A tuple (possible only as a keyword argument) must have\nlength equal to the number of outputs.\n\nThis condition is broadcast over the input. At locations where the condition\nis True, the `out` array will be set to the ufunc result. Elsewhere, the `out`\narray will retain its original value. Note that if an uninitialized `out`\narray is created via the default `out=None`, locations within it where the\ncondition is False will remain uninitialized.\n\nFor other keyword-only arguments, see the ufunc docs.\n\nThe next representable values of `x1` in the direction of `x2`. This is a\nscalar if both `x1` and `x2` are scalars.\n\n"}, {"name": "numpy.NINF", "path": "reference/constants#numpy.NINF", "type": "Constants", "text": "\nIEEE 754 floating point representation of negative infinity.\n\nA floating point representation of negative infinity.\n\nisinf : Shows which elements are positive or negative infinity\n\nisposinf : Shows which elements are positive infinity\n\nisneginf : Shows which elements are negative infinity\n\nisnan : Shows which elements are Not a Number\n\nisfinite : Shows which elements are finite (not one of Not a Number, positive\ninfinity and negative infinity)\n\nNumPy uses the IEEE Standard for Binary Floating-Point for Arithmetic (IEEE\n754). This means that Not a Number is not equivalent to infinity. Also that\npositive infinity is not equivalent to negative infinity. But infinity is\nequivalent to positive infinity.\n\n"}, {"name": "numpy.nonzero()", "path": "reference/generated/numpy.nonzero", "type": "numpy.nonzero", "text": "\nReturn the indices of the elements that are non-zero.\n\nReturns a tuple of arrays, one for each dimension of `a`, containing the\nindices of the non-zero elements in that dimension. The values in `a` are\nalways tested and returned in row-major, C-style order.\n\nTo group the indices by element, rather than dimension, use `argwhere`, which\nreturns a row for each non-zero element.\n\nNote\n\nWhen called on a zero-d array or scalar, `nonzero(a)` is treated as\n`nonzero(atleast_1d(a))`.\n\nDeprecated since version 1.17.0: Use `atleast_1d` explicitly if this behavior\nis deliberate.\n\nInput array.\n\nIndices of elements that are non-zero.\n\nSee also\n\nReturn indices that are non-zero in the flattened version of the input array.\n\nEquivalent ndarray method.\n\nCounts the number of non-zero elements in the input array.\n\nWhile the nonzero values can be obtained with `a[nonzero(a)]`, it is\nrecommended to use `x[x.astype(bool)]` or `x[x != 0]` instead, which will\ncorrectly handle 0-d arrays.\n\nA common use for `nonzero` is to find the indices of an array, where a\ncondition is True. Given an array `a`, the condition `a` > 3 is a boolean\narray and since False is interpreted as 0, np.nonzero(a > 3) yields the\nindices of the `a` where the condition is true.\n\nUsing this result to index `a` is equivalent to using the mask directly:\n\n`nonzero` can also be called as a method of the array.\n\n"}, {"name": "numpy.not_equal()", "path": "reference/generated/numpy.not_equal", "type": "numpy.not_equal", "text": "\nReturn (x1 != x2) element-wise.\n\nInput arrays. If `x1.shape != x2.shape`, they must be broadcastable to a\ncommon shape (which becomes the shape of the output).\n\nA location into which the result is stored. If provided, it must have a shape\nthat the inputs broadcast to. If not provided or None, a freshly-allocated\narray is returned. A tuple (possible only as a keyword argument) must have\nlength equal to the number of outputs.\n\nThis condition is broadcast over the input. At locations where the condition\nis True, the `out` array will be set to the ufunc result. Elsewhere, the `out`\narray will retain its original value. Note that if an uninitialized `out`\narray is created via the default `out=None`, locations within it where the\ncondition is False will remain uninitialized.\n\nFor other keyword-only arguments, see the ufunc docs.\n\nOutput array, element-wise comparison of `x1` and `x2`. Typically of type\nbool, unless `dtype=object` is passed. This is a scalar if both `x1` and `x2`\nare scalars.\n\nSee also\n\nThe `!=` operator can be used as a shorthand for `np.not_equal` on ndarrays.\n\n"}, {"name": "numpy.number", "path": "reference/arrays.scalars#numpy.number", "type": "Scalars", "text": "\nAbstract base class of all numeric scalar types.\n\n"}, {"name": "numpy.NZERO", "path": "reference/constants#numpy.NZERO", "type": "Constants", "text": "\nIEEE 754 floating point representation of negative zero.\n\nA floating point representation of negative zero.\n\nPZERO : Defines positive zero.\n\nisinf : Shows which elements are positive or negative infinity.\n\nisposinf : Shows which elements are positive infinity.\n\nisneginf : Shows which elements are negative infinity.\n\nisnan : Shows which elements are Not a Number.\n\nNot a Number, positive infinity and negative infinity.\n\nNumPy uses the IEEE Standard for Binary Floating-Point for Arithmetic (IEEE\n754). Negative zero is considered to be a finite number.\n\n"}, {"name": "numpy.obj2sctype()", "path": "reference/generated/numpy.obj2sctype", "type": "numpy.obj2sctype", "text": "\nReturn the scalar dtype or NumPy equivalent of Python type of an object.\n\nThe object of which the type is returned.\n\nIf given, this is returned for objects whose types can not be determined. If\nnot given, None is returned for those objects.\n\nThe data type of `rep`.\n\nSee also\n\n"}, {"name": "numpy.object_", "path": "reference/arrays.scalars#numpy.object_", "type": "Scalars", "text": "\nAny Python object.\n\n`'O'`\n\n"}, {"name": "numpy.ogrid", "path": "reference/generated/numpy.ogrid", "type": "numpy.ogrid", "text": "\n`nd_grid` instance which returns an open multi-dimensional \u201cmeshgrid\u201d.\n\nAn instance of `numpy.lib.index_tricks.nd_grid` which returns an open (i.e.\nnot fleshed out) mesh-grid when indexed, so that only one dimension of each\nreturned array is greater than 1. The dimension and number of the output\narrays are equal to the number of indexing dimensions. If the step length is\nnot a complex number, then the stop is not inclusive.\n\nHowever, if the step length is a complex number (e.g. 5j), then the integer\npart of its magnitude is interpreted as specifying the number of points to\ncreate between the start and stop values, where the stop value is inclusive.\n\n`ndarrays` with only one dimension not equal to 1\n\nSee also\n\nclass of `ogrid` and `mgrid` objects\n\nlike `ogrid` but returns dense (or fleshed out) mesh grids\n\narray concatenator\n\n"}, {"name": "numpy.ones()", "path": "reference/generated/numpy.ones", "type": "numpy.ones", "text": "\nReturn a new array of given shape and type, filled with ones.\n\nShape of the new array, e.g., `(2, 3)` or `2`.\n\nThe desired data-type for the array, e.g., `numpy.int8`. Default is\n`numpy.float64`.\n\nWhether to store multi-dimensional data in row-major (C-style) or column-major\n(Fortran-style) order in memory.\n\nReference object to allow the creation of arrays which are not NumPy arrays.\nIf an array-like passed in as `like` supports the `__array_function__`\nprotocol, the result will be defined by it. In this case, it ensures the\ncreation of an array object compatible with that passed in via this argument.\n\nNew in version 1.20.0.\n\nArray of ones with the given shape, dtype, and order.\n\nSee also\n\nReturn an array of ones with shape and type of input.\n\nReturn a new uninitialized array.\n\nReturn a new array setting values to zero.\n\nReturn a new array of given shape filled with value.\n\n"}, {"name": "numpy.ones_like()", "path": "reference/generated/numpy.ones_like", "type": "numpy.ones_like", "text": "\nReturn an array of ones with the same shape and type as a given array.\n\nThe shape and data-type of `a` define these same attributes of the returned\narray.\n\nOverrides the data type of the result.\n\nNew in version 1.6.0.\n\nOverrides the memory layout of the result. \u2018C\u2019 means C-order, \u2018F\u2019 means\nF-order, \u2018A\u2019 means \u2018F\u2019 if `a` is Fortran contiguous, \u2018C\u2019 otherwise. \u2018K\u2019 means\nmatch the layout of `a` as closely as possible.\n\nNew in version 1.6.0.\n\nIf True, then the newly created array will use the sub-class type of `a`,\notherwise it will be a base-class array. Defaults to True.\n\nOverrides the shape of the result. If order=\u2019K\u2019 and the number of dimensions\nis unchanged, will try to keep order, otherwise, order=\u2019C\u2019 is implied.\n\nNew in version 1.17.0.\n\nArray of ones with the same shape and type as `a`.\n\nSee also\n\nReturn an empty array with shape and type of input.\n\nReturn an array of zeros with shape and type of input.\n\nReturn a new array with shape of input filled with value.\n\nReturn a new array setting values to one.\n\n"}, {"name": "numpy.outer()", "path": "reference/generated/numpy.outer", "type": "numpy.outer", "text": "\nCompute the outer product of two vectors.\n\nGiven two vectors, `a = [a0, a1, ..., aM]` and `b = [b0, b1, ..., bN]`, the\nouter product [1] is:\n\nFirst input vector. Input is flattened if not already 1-dimensional.\n\nSecond input vector. Input is flattened if not already 1-dimensional.\n\nA location where the result is stored\n\nNew in version 1.9.0.\n\n`out[i, j] = a[i] * b[j]`\n\nSee also\n\n`einsum('i,j->ij', a.ravel(), b.ravel())` is the equivalent.\n\nA generalization to dimensions other than 1D and other operations.\n`np.multiply.outer(a.ravel(), b.ravel())` is the equivalent.\n\n`np.tensordot(a.ravel(), b.ravel(), axes=((), ()))` is the equivalent.\n\n: G. H. Golub and C. F. Van Loan, Matrix Computations, 3rd ed., Baltimore, MD,\nJohns Hopkins University Press, 1996, pg. 8.\n\nMake a (very coarse) grid for computing a Mandelbrot set:\n\nAn example using a \u201cvector\u201d of letters:\n\n"}, {"name": "numpy.packbits()", "path": "reference/generated/numpy.packbits", "type": "numpy.packbits", "text": "\nPacks the elements of a binary-valued array into bits in a uint8 array.\n\nThe result is padded to full bytes by inserting zero bits at the end.\n\nAn array of integers or booleans whose elements should be packed to bits.\n\nThe dimension over which bit-packing is done. `None` implies packing the\nflattened array.\n\nThe order of the input bits. \u2018big\u2019 will mimic bin(val), `[0, 0, 0, 0, 0, 0, 1,\n1] => 3 = 0b00000011`, \u2018little\u2019 will reverse the order so `[1, 1, 0, 0, 0, 0,\n0, 0] => 3`. Defaults to \u2018big\u2019.\n\nNew in version 1.17.0.\n\nArray of type uint8 whose elements represent bits corresponding to the logical\n(0 or nonzero) value of the input elements. The shape of `packed` has the same\nnumber of dimensions as the input (unless `axis` is None, in which case the\noutput is 1-D).\n\nSee also\n\nUnpacks elements of a uint8 array into a binary-valued output array.\n\nNote that in binary 160 = 1010 0000, 64 = 0100 0000, 192 = 1100 0000, and 32 =\n0010 0000.\n\n"}, {"name": "numpy.pad()", "path": "reference/generated/numpy.pad", "type": "numpy.pad", "text": "\nPad an array.\n\nThe array to pad.\n\nNumber of values padded to the edges of each axis. ((before_1, after_1), \u2026\n(before_N, after_N)) unique pad widths for each axis. ((before, after),)\nyields same before and after pad for each axis. (pad,) or int is a shortcut\nfor before = after = pad width for all axes.\n\nOne of the following string values or a user supplied function.\n\nPads with a constant value.\n\nPads with the edge values of array.\n\nPads with the linear ramp between end_value and the array edge value.\n\nPads with the maximum value of all or part of the vector along each axis.\n\nPads with the mean value of all or part of the vector along each axis.\n\nPads with the median value of all or part of the vector along each axis.\n\nPads with the minimum value of all or part of the vector along each axis.\n\nPads with the reflection of the vector mirrored on the first and last values\nof the vector along each axis.\n\nPads with the reflection of the vector mirrored along the edge of the array.\n\nPads with the wrap of the vector along the axis. The first values are used to\npad the end and the end values are used to pad the beginning.\n\nPads with undefined values.\n\nNew in version 1.17.\n\nPadding function, see Notes.\n\nUsed in \u2018maximum\u2019, \u2018mean\u2019, \u2018median\u2019, and \u2018minimum\u2019. Number of values at edge\nof each axis used to calculate the statistic value.\n\n((before_1, after_1), \u2026 (before_N, after_N)) unique statistic lengths for each\naxis.\n\n((before, after),) yields same before and after statistic lengths for each\naxis.\n\n(stat_length,) or int is a shortcut for before = after = statistic length for\nall axes.\n\nDefault is `None`, to use the entire axis.\n\nUsed in \u2018constant\u2019. The values to set the padded values for each axis.\n\n`((before_1, after_1), ... (before_N, after_N))` unique pad constants for each\naxis.\n\n`((before, after),)` yields same before and after constants for each axis.\n\n`(constant,)` or `constant` is a shortcut for `before = after = constant` for\nall axes.\n\nDefault is 0.\n\nUsed in \u2018linear_ramp\u2019. The values used for the ending value of the linear_ramp\nand that will form the edge of the padded array.\n\n`((before_1, after_1), ... (before_N, after_N))` unique end values for each\naxis.\n\n`((before, after),)` yields same before and after end values for each axis.\n\n`(constant,)` or `constant` is a shortcut for `before = after = constant` for\nall axes.\n\nDefault is 0.\n\nUsed in \u2018reflect\u2019, and \u2018symmetric\u2019. The \u2018even\u2019 style is the default with an\nunaltered reflection around the edge value. For the \u2018odd\u2019 style, the extended\npart of the array is created by subtracting the reflected values from two\ntimes the edge value.\n\nPadded array of rank equal to `array` with shape increased according to\n`pad_width`.\n\nNew in version 1.7.0.\n\nFor an array with rank greater than 1, some of the padding of later axes is\ncalculated from padding of previous axes. This is easiest to think about with\na rank 2 array where the corners of the padded array are calculated by using\npadded values from the first axis.\n\nThe padding function, if used, should modify a rank 1 array in-place. It has\nthe following signature:\n\nwhere\n\nA rank 1 array already padded with zeros. Padded values are\nvector[:iaxis_pad_width[0]] and vector[-iaxis_pad_width[1]:].\n\nA 2-tuple of ints, iaxis_pad_width[0] represents the number of values padded\nat the beginning of vector where iaxis_pad_width[1] represents the number of\nvalues padded at the end of vector.\n\nThe axis currently being calculated.\n\nAny keyword arguments the function requires.\n\n"}, {"name": "numpy.partition()", "path": "reference/generated/numpy.partition", "type": "numpy.partition", "text": "\nReturn a partitioned copy of an array.\n\nCreates a copy of the array with its elements rearranged in such a way that\nthe value of the element in k-th position is in the position it would be in a\nsorted array. All elements smaller than the k-th element are moved before this\nelement and all equal or greater are moved behind it. The ordering of the\nelements in the two partitions is undefined.\n\nNew in version 1.8.0.\n\nArray to be sorted.\n\nElement index to partition by. The k-th value of the element will be in its\nfinal sorted position and all smaller elements will be moved before it and all\nequal or greater elements behind it. The order of all elements in the\npartitions is undefined. If provided with a sequence of k-th it will partition\nall elements indexed by k-th of them into their sorted position at once.\n\nDeprecated since version 1.22.0: Passing booleans as index is deprecated.\n\nAxis along which to sort. If None, the array is flattened before sorting. The\ndefault is -1, which sorts along the last axis.\n\nSelection algorithm. Default is \u2018introselect\u2019.\n\nWhen `a` is an array with fields defined, this argument specifies which fields\nto compare first, second, etc. A single field can be specified as a string.\nNot all fields need be specified, but unspecified fields will still be used,\nin the order in which they come up in the dtype, to break ties.\n\nArray of the same type and shape as `a`.\n\nSee also\n\nMethod to sort an array in-place.\n\nIndirect partition.\n\nFull sorting\n\nThe various selection algorithms are characterized by their average speed,\nworst case performance, work space size, and whether they are stable. A stable\nsort keeps items with the same key in the same relative order. The available\nalgorithms have the following properties:\n\nkind\n\nspeed\n\nworst case\n\nwork space\n\nstable\n\n\u2018introselect\u2019\n\n1\n\nO(n)\n\n0\n\nno\n\nAll the partition algorithms make temporary copies of the data when\npartitioning along any but the last axis. Consequently, partitioning along the\nlast axis is faster and uses less space than partitioning along any other\naxis.\n\nThe sort order for complex numbers is lexicographic. If both the real and\nimaginary parts are non-nan then the order is determined by the real parts\nexcept when they are equal, in which case the order is determined by the\nimaginary parts.\n\n"}, {"name": "numpy.percentile()", "path": "reference/generated/numpy.percentile", "type": "numpy.percentile", "text": "\nCompute the q-th percentile of the data along the specified axis.\n\nReturns the q-th percentile(s) of the array elements.\n\nInput array or object that can be converted to an array.\n\nPercentile or sequence of percentiles to compute, which must be between 0 and\n100 inclusive.\n\nAxis or axes along which the percentiles are computed. The default is to\ncompute the percentile(s) along a flattened version of the array.\n\nChanged in version 1.9.0: A tuple of axes is supported\n\nAlternative output array in which to place the result. It must have the same\nshape and buffer length as the expected output, but the type (of the output)\nwill be cast if necessary.\n\nIf True, then allow the input array `a` to be modified by intermediate\ncalculations, to save memory. In this case, the contents of the input `a`\nafter this function completes is undefined.\n\nThis parameter specifies the method to use for estimating the percentile.\nThere are many different methods, some unique to NumPy. See the notes for\nexplanation. The options sorted by their R type as summarized in the H&F paper\n[1] are:\n\nThe first three methods are discontiuous. NumPy further defines the following\ndiscontinuous variations of the default \u2018linear\u2019 (7.) option:\n\nChanged in version 1.22.0: This argument was previously called \u201cinterpolation\u201d\nand only offered the \u201clinear\u201d default and last four options.\n\nIf this is set to True, the axes which are reduced are left in the result as\ndimensions with size one. With this option, the result will broadcast\ncorrectly against the original array `a`.\n\nNew in version 1.9.0.\n\nDeprecated name for the method keyword argument.\n\nDeprecated since version 1.22.0.\n\nIf `q` is a single percentile and `axis=None`, then the result is a scalar. If\nmultiple percentiles are given, first axis of the result corresponds to the\npercentiles. The other axes are the axes that remain after the reduction of\n`a`. If the input contains integers or floats smaller than `float64`, the\noutput data-type is `float64`. Otherwise, the output data-type is the same as\nthat of the input. If `out` is specified, that array is returned instead.\n\nSee also\n\nequivalent to `percentile(..., 50)`\n\nequivalent to percentile, except q in the range [0, 1].\n\nGiven a vector `V` of length `N`, the q-th percentile of `V` is the value\n`q/100` of the way from the minimum to the maximum in a sorted copy of `V`.\nThe values and distances of the two nearest neighbors as well as the `method`\nparameter will determine the percentile if the normalized ranking does not\nmatch the location of `q` exactly. This function is the same as the median if\n`q=50`, the same as the minimum if `q=0` and the same as the maximum if\n`q=100`.\n\nThis optional `method` parameter specifies the method to use when the desired\nquantile lies between two data points `i < j`. If `g` is the fractional part\nof the index surrounded by `i` and alpha and beta are correction constants\nmodifying i and j.\n\nBelow, \u2018q\u2019 is the quantile value, \u2018n\u2019 is the sample size and alpha and beta\nare constants. The following formula gives an interpolation \u201ci + g\u201d of where\nthe quantile would be in the sorted sample. With \u2018i\u2019 being the floor and \u2018g\u2019\nthe fractional part of the result.\n\nThe different methods then work as follows\n\nmethod 1 of H&F [1]. This method gives discontinuous results: * if g > 0 ;\nthen take j * if g = 0 ; then take i\n\nmethod 2 of H&F [1]. This method give discontinuous results: * if g > 0 ; then\ntake j * if g = 0 ; then average between bounds\n\nmethod 3 of H&F [1]. This method give discontinuous results: * if g > 0 ; then\ntake j * if g = 0 and index is odd ; then take j * if g = 0 and index is even\n; then take i\n\nmethod 4 of H&F [1]. This method give continuous results using: * alpha = 0 *\nbeta = 1\n\nmethod 5 of H&F [1]. This method give continuous results using: * alpha = 1/2\n* beta = 1/2\n\nmethod 6 of H&F [1]. This method give continuous results using: * alpha = 0 *\nbeta = 0\n\nmethod 7 of H&F [1]. This method give continuous results using: * alpha = 1 *\nbeta = 1\n\nmethod 8 of H&F [1]. This method is probably the best method if the sample\ndistribution function is unknown (see reference). This method give continuous\nresults using: * alpha = 1/3 * beta = 1/3\n\nmethod 9 of H&F [1]. This method is probably the best method if the sample\ndistribution function is known to be normal. This method give continuous\nresults using: * alpha = 3/8 * beta = 3/8\n\nNumPy method kept for backwards compatibility. Takes `i` as the interpolation\npoint.\n\nNumPy method kept for backwards compatibility. Takes `j` as the interpolation\npoint.\n\nNumPy method kept for backwards compatibility. Takes `i` or `j`, whichever is\nnearest.\n\nNumPy method kept for backwards compatibility. Uses `(i + j) / 2`.\n\nR. J. Hyndman and Y. Fan, \u201cSample quantiles in statistical packages,\u201d The\nAmerican Statistician, 50(4), pp. 361-365, 1996\n\nThe different methods can be visualized graphically:\n\n"}, {"name": "numpy.pi", "path": "reference/constants#numpy.pi", "type": "Constants", "text": "\n`pi = 3.1415926535897932384626433...`\n\nhttps://en.wikipedia.org/wiki/Pi\n\n"}, {"name": "numpy.piecewise()", "path": "reference/generated/numpy.piecewise", "type": "numpy.piecewise", "text": "\nEvaluate a piecewise-defined function.\n\nGiven a set of conditions and corresponding functions, evaluate each function\non the input data wherever its condition is true.\n\nThe input domain.\n\nEach boolean array corresponds to a function in `funclist`. Wherever\n`condlist[i]` is True, `funclist[i](x)` is used as the output value.\n\nEach boolean array in `condlist` selects a piece of `x`, and should therefore\nbe of the same shape as `x`.\n\nThe length of `condlist` must correspond to that of `funclist`. If one extra\nfunction is given, i.e. if `len(funclist) == len(condlist) + 1`, then that\nextra function is the default value, used wherever all conditions are false.\n\nEach function is evaluated over `x` wherever its corresponding condition is\nTrue. It should take a 1d array as input and give an 1d array or a scalar\nvalue as output. If, instead of a callable, a scalar is provided then a\nconstant function (`lambda x: scalar`) is assumed.\n\nAny further arguments given to `piecewise` are passed to the functions upon\nexecution, i.e., if called `piecewise(..., ..., 1, 'a')`, then each function\nis called as `f(x, 1, 'a')`.\n\nKeyword arguments used in calling `piecewise` are passed to the functions upon\nexecution, i.e., if called `piecewise(..., ..., alpha=1)`, then each function\nis called as `f(x, alpha=1)`.\n\nThe output is the same shape and type as x and is found by calling the\nfunctions in `funclist` on the appropriate portions of `x`, as defined by the\nboolean arrays in `condlist`. Portions not covered by any condition have a\ndefault value of 0.\n\nSee also\n\nThis is similar to choose or select, except that functions are evaluated on\nelements of `x` that satisfy the corresponding condition from `condlist`.\n\nThe result is:\n\nDefine the sigma function, which is -1 for `x < 0` and +1 for `x >= 0`.\n\nDefine the absolute value, which is `-x` for `x <0` and `x` for `x >= 0`.\n\nApply the same function to a scalar value.\n\n"}, {"name": "numpy.PINF", "path": "reference/constants#numpy.PINF", "type": "Constants", "text": "\nIEEE 754 floating point representation of (positive) infinity.\n\nUse `inf` because `Inf`, `Infinity`, `PINF` and `infty` are aliases for `inf`.\nFor more details, see `inf`.\n\ninf\n\n"}, {"name": "numpy.place()", "path": "reference/generated/numpy.place", "type": "numpy.place", "text": "\nChange elements of an array based on conditional and input values.\n\nSimilar to `np.copyto(arr, vals, where=mask)`, the difference is that `place`\nuses the first N elements of `vals`, where N is the number of True values in\n`mask`, while `copyto` uses the elements where `mask` is True.\n\nNote that `extract` does the exact opposite of `place`.\n\nArray to put data into.\n\nBoolean mask array. Must have the same size as `a`.\n\nValues to put into `a`. Only the first N elements are used, where N is the\nnumber of True values in `mask`. If `vals` is smaller than N, it will be\nrepeated, and if elements of `a` are to be masked, this sequence must be non-\nempty.\n\nSee also\n\n"}, {"name": "numpy.poly()", "path": "reference/generated/numpy.poly", "type": "numpy.poly", "text": "\nFind the coefficients of a polynomial with the given sequence of roots.\n\nNote\n\nThis forms part of the old polynomial API. Since version 1.4, the new\npolynomial API defined in `numpy.polynomial` is preferred. A summary of the\ndifferences can be found in the transition guide.\n\nReturns the coefficients of the polynomial whose leading coefficient is one\nfor the given sequence of zeros (multiple roots must be included in the\nsequence as many times as their multiplicity; see Examples). A square matrix\n(or array, which will be treated as a matrix) can also be given, in which case\nthe coefficients of the characteristic polynomial of the matrix are returned.\n\nA sequence of polynomial roots, or a square array or matrix object.\n\n1D array of polynomial coefficients from highest to lowest degree:\n\n`c[0] * x**(N) + c[1] * x**(N-1) + ... + c[N-1] * x + c[N]` where c[0] always\nequals 1.\n\nIf input is the wrong shape (the input must be a 1-D or square 2-D array).\n\nSee also\n\nCompute polynomial values.\n\nReturn the roots of a polynomial.\n\nLeast squares polynomial fit.\n\nA one-dimensional polynomial class.\n\nSpecifying the roots of a polynomial still leaves one degree of freedom,\ntypically represented by an undetermined leading coefficient. [1] In the case\nof this function, that coefficient - the first one in the returned array - is\nalways taken as one. (If for some reason you have one other point, the only\nautomatic way presently to leverage that information is to use `polyfit`.)\n\nThe characteristic polynomial, \\\\(p_a(t)\\\\), of an `n`-by-`n` matrix A is\ngiven by\n\n\\\\(p_a(t) = \\mathrm{det}(t\\, \\mathbf{I} - \\mathbf{A})\\\\),\n\nwhere I is the `n`-by-`n` identity matrix. [2]\n\nM. Sullivan and M. Sullivan, III, \u201cAlgebra and Trignometry, Enhanced With\nGraphing Utilities,\u201d Prentice-Hall, pg. 318, 1996.\n\nG. Strang, \u201cLinear Algebra and Its Applications, 2nd Edition,\u201d Academic Press,\npg. 182, 1980.\n\nGiven a sequence of a polynomial\u2019s zeros:\n\nThe line above represents z**3 + 0*z**2 + 0*z + 0.\n\nThe line above represents z**3 - z/4\n\nGiven a square array object:\n\nNote how in all cases the leading coefficient is always 1.\n\n"}, {"name": "numpy.poly1d()", "path": "reference/generated/numpy.poly1d", "type": "numpy.poly1d", "text": "\nA one-dimensional polynomial class.\n\nNote\n\nThis forms part of the old polynomial API. Since version 1.4, the new\npolynomial API defined in `numpy.polynomial` is preferred. A summary of the\ndifferences can be found in the transition guide.\n\nA convenience class, used to encapsulate \u201cnatural\u201d operations on polynomials\nso that said operations may take on their customary form in code (see\nExamples).\n\nThe polynomial\u2019s coefficients, in decreasing powers, or if the value of the\nsecond parameter is True, the polynomial\u2019s roots (values where the polynomial\nevaluates to 0). For example, `poly1d([1, 2, 3])` returns an object that\nrepresents \\\\(x^2 + 2x + 3\\\\), whereas `poly1d([1, 2, 3], True)` returns one\nthat represents \\\\((x-1)(x-2)(x-3) = x^3 - 6x^2 + 11x -6\\\\).\n\nIf True, `c_or_r` specifies the polynomial\u2019s roots; the default is False.\n\nChanges the variable used when printing `p` from `x` to `variable` (see\nExamples).\n\nConstruct the polynomial \\\\(x^2 + 2x + 3\\\\):\n\nEvaluate the polynomial at \\\\(x = 0.5\\\\):\n\nFind the roots:\n\nThese numbers in the previous line represent (0, 0) to machine precision\n\nShow the coefficients:\n\nDisplay the order (the leading zero-coefficients are removed):\n\nShow the coefficient of the k-th power in the polynomial (which is equivalent\nto `p.c[-(i+1)]`):\n\nPolynomials can be added, subtracted, multiplied, and divided (returns\nquotient and remainder):\n\n`asarray(p)` gives the coefficient array, so polynomials can be used in all\nfunctions that accept arrays:\n\nThe variable used in the string representation of `p` can be modified, using\nthe `variable` parameter:\n\nConstruct a polynomial from its roots:\n\nThis is the same polynomial as obtained by:\n\nThe polynomial coefficients\n\nThe polynomial coefficients\n\nThe polynomial coefficients\n\nThe polynomial coefficients\n\nThe order or degree of the polynomial\n\nThe order or degree of the polynomial\n\nThe roots of the polynomial, where self(x) == 0\n\nThe roots of the polynomial, where self(x) == 0\n\nThe name of the polynomial variable\n\n`__call__`(val)\n\nCall self as a function.\n\n`deriv`([m])\n\nReturn a derivative of this polynomial.\n\n`integ`([m, k])\n\nReturn an antiderivative (indefinite integral) of this polynomial.\n\n"}, {"name": "numpy.polyadd()", "path": "reference/generated/numpy.polyadd", "type": "numpy.polyadd", "text": "\nFind the sum of two polynomials.\n\nNote\n\nThis forms part of the old polynomial API. Since version 1.4, the new\npolynomial API defined in `numpy.polynomial` is preferred. A summary of the\ndifferences can be found in the transition guide.\n\nReturns the polynomial resulting from the sum of two input polynomials. Each\ninput must be either a poly1d object or a 1D sequence of polynomial\ncoefficients, from highest to lowest degree.\n\nInput polynomials.\n\nThe sum of the inputs. If either input is a poly1d object, then the output is\nalso a poly1d object. Otherwise, it is a 1D array of polynomial coefficients\nfrom highest to lowest degree.\n\nSee also\n\nA one-dimensional polynomial class.\n\nUsing poly1d objects:\n\n"}, {"name": "numpy.polyder()", "path": "reference/generated/numpy.polyder", "type": "numpy.polyder", "text": "\nReturn the derivative of the specified order of a polynomial.\n\nNote\n\nThis forms part of the old polynomial API. Since version 1.4, the new\npolynomial API defined in `numpy.polynomial` is preferred. A summary of the\ndifferences can be found in the transition guide.\n\nPolynomial to differentiate. A sequence is interpreted as polynomial\ncoefficients, see `poly1d`.\n\nOrder of differentiation (default: 1)\n\nA new polynomial representing the derivative.\n\nSee also\n\nAnti-derivative of a polynomial.\n\nClass for one-dimensional polynomials.\n\nThe derivative of the polynomial \\\\(x^3 + x^2 + x^1 + 1\\\\) is:\n\nwhich evaluates to:\n\nWe can verify this, approximating the derivative with `(f(x + h) - f(x))/h`:\n\nThe fourth-order derivative of a 3rd-order polynomial is zero:\n\n"}, {"name": "numpy.polydiv()", "path": "reference/generated/numpy.polydiv", "type": "numpy.polydiv", "text": "\nReturns the quotient and remainder of polynomial division.\n\nNote\n\nThis forms part of the old polynomial API. Since version 1.4, the new\npolynomial API defined in `numpy.polynomial` is preferred. A summary of the\ndifferences can be found in the transition guide.\n\nThe input arrays are the coefficients (including any coefficients equal to\nzero) of the \u201cnumerator\u201d (dividend) and \u201cdenominator\u201d (divisor) polynomials,\nrespectively.\n\nDividend polynomial\u2019s coefficients.\n\nDivisor polynomial\u2019s coefficients.\n\nCoefficients, including those equal to zero, of the quotient.\n\nCoefficients, including those equal to zero, of the remainder.\n\nSee also\n\nBoth `u` and `v` must be 0-d or 1-d (ndim = 0 or 1), but `u.ndim` need not\nequal `v.ndim`. In other words, all four possible combinations - `u.ndim =\nv.ndim = 0`, `u.ndim = v.ndim = 1`, `u.ndim = 1, v.ndim = 0`, and `u.ndim = 0,\nv.ndim = 1` \\- work.\n\n"}, {"name": "numpy.polyfit()", "path": "reference/generated/numpy.polyfit", "type": "numpy.polyfit", "text": "\nLeast squares polynomial fit.\n\nNote\n\nThis forms part of the old polynomial API. Since version 1.4, the new\npolynomial API defined in `numpy.polynomial` is preferred. A summary of the\ndifferences can be found in the transition guide.\n\nFit a polynomial `p(x) = p[0] * x**deg + ... + p[deg]` of degree `deg` to\npoints `(x, y)`. Returns a vector of coefficients `p` that minimises the\nsquared error in the order `deg`, `deg-1`, \u2026 `0`.\n\nThe `Polynomial.fit` class method is recommended for new code as it is more\nstable numerically. See the documentation of the method for more information.\n\nx-coordinates of the M sample points `(x[i], y[i])`.\n\ny-coordinates of the sample points. Several data sets of sample points sharing\nthe same x-coordinates can be fitted at once by passing in a 2D-array that\ncontains one dataset per column.\n\nDegree of the fitting polynomial\n\nRelative condition number of the fit. Singular values smaller than this\nrelative to the largest singular value will be ignored. The default value is\nlen(x)*eps, where eps is the relative precision of the float type, about 2e-16\nin most cases.\n\nSwitch determining nature of return value. When it is False (the default) just\nthe coefficients are returned, when True diagnostic information from the\nsingular value decomposition is also returned.\n\nWeights. If not None, the weight `w[i]` applies to the unsquared residual\n`y[i] - y_hat[i]` at `x[i]`. Ideally the weights are chosen so that the errors\nof the products `w[i]*y[i]` all have the same variance. When using inverse-\nvariance weighting, use `w[i] = 1/sigma(y[i])`. The default value is None.\n\nIf given and not `False`, return not just the estimate but also its covariance\nmatrix. By default, the covariance are scaled by chi2/dof, where dof = M -\n(deg + 1), i.e., the weights are presumed to be unreliable except in a\nrelative sense and everything is scaled such that the reduced chi2 is unity.\nThis scaling is omitted if `cov='unscaled'`, as is relevant for the case that\nthe weights are w = 1/sigma, with sigma known to be a reliable estimate of the\nuncertainty.\n\nPolynomial coefficients, highest power first. If `y` was 2-D, the coefficients\nfor `k`-th data set are in `p[:,k]`.\n\nThese values are only returned if `full == True`\n\ncoefficient matrix\n\ncoefficient matrix\n\nFor more details, see `numpy.linalg.lstsq`.\n\nPresent only if `full == False` and `cov == True`. The covariance matrix of\nthe polynomial coefficient estimates. The diagonal of this matrix are the\nvariance estimates for each coefficient. If y is a 2-D array, then the\ncovariance matrix for the `k`-th data set are in `V[:,:,k]`\n\nThe rank of the coefficient matrix in the least-squares fit is deficient. The\nwarning is only raised if `full == False`.\n\nThe warnings can be turned off by\n\nSee also\n\nCompute polynomial values.\n\nComputes a least-squares fit.\n\nComputes spline fits.\n\nThe solution minimizes the squared error\n\nin the equations:\n\nThe coefficient matrix of the coefficients `p` is a Vandermonde matrix.\n\n`polyfit` issues a `RankWarning` when the least-squares fit is badly\nconditioned. This implies that the best fit is not well-defined due to\nnumerical error. The results may be improved by lowering the polynomial degree\nor by replacing `x` by `x` \\- `x`.mean(). The `rcond` parameter can also be\nset to a value smaller than its default, but the resulting fit may be\nspurious: including contributions from the small singular values can add\nnumerical noise to the result.\n\nNote that fitting polynomial coefficients is inherently badly conditioned when\nthe degree of the polynomial is large or the interval of sample points is\nbadly centered. The quality of the fit should always be checked in these\ncases. When polynomial fits are not satisfactory, splines may be a good\nalternative.\n\nWikipedia, \u201cCurve fitting\u201d, https://en.wikipedia.org/wiki/Curve_fitting\n\nWikipedia, \u201cPolynomial interpolation\u201d,\nhttps://en.wikipedia.org/wiki/Polynomial_interpolation\n\nIt is convenient to use `poly1d` objects for dealing with polynomials:\n\nHigh-order polynomials may oscillate wildly:\n\nIllustration:\n\n"}, {"name": "numpy.polyint()", "path": "reference/generated/numpy.polyint", "type": "numpy.polyint", "text": "\nReturn an antiderivative (indefinite integral) of a polynomial.\n\nNote\n\nThis forms part of the old polynomial API. Since version 1.4, the new\npolynomial API defined in `numpy.polynomial` is preferred. A summary of the\ndifferences can be found in the transition guide.\n\nThe returned order `m` antiderivative `P` of polynomial `p` satisfies\n\\\\(\\frac{d^m}{dx^m}P(x) = p(x)\\\\) and is defined up to `m - 1` integration\nconstants `k`. The constants determine the low-order polynomial part\n\nof `P` so that \\\\(P^{(j)}(0) = k_{m-j-1}\\\\).\n\nPolynomial to integrate. A sequence is interpreted as polynomial coefficients,\nsee `poly1d`.\n\nOrder of the antiderivative. (Default: 1)\n\nIntegration constants. They are given in the order of integration: those\ncorresponding to highest-order terms come first.\n\nIf `None` (default), all constants are assumed to be zero. If `m = 1`, a\nsingle scalar can be given instead of a list.\n\nSee also\n\nderivative of a polynomial\n\nequivalent method\n\nThe defining property of the antiderivative:\n\nThe integration constants default to zero, but can be specified:\n\nNote that 3 = 6 / 2!, and that the constants are given in the order of\nintegrations. Constant of the highest-order polynomial term comes first:\n\n"}, {"name": "numpy.polymul()", "path": "reference/generated/numpy.polymul", "type": "numpy.polymul", "text": "\nFind the product of two polynomials.\n\nNote\n\nThis forms part of the old polynomial API. Since version 1.4, the new\npolynomial API defined in `numpy.polynomial` is preferred. A summary of the\ndifferences can be found in the transition guide.\n\nFinds the polynomial resulting from the multiplication of the two input\npolynomials. Each input must be either a poly1d object or a 1D sequence of\npolynomial coefficients, from highest to lowest degree.\n\nInput polynomials.\n\nThe polynomial resulting from the multiplication of the inputs. If either\ninputs is a poly1d object, then the output is also a poly1d object. Otherwise,\nit is a 1D array of polynomial coefficients from highest to lowest degree.\n\nSee also\n\nA one-dimensional polynomial class.\n\nArray convolution. Same output as polymul, but has parameter for overlap mode.\n\nUsing poly1d objects:\n\n"}, {"name": "numpy.polynomial.chebyshev.Chebyshev()", "path": "reference/generated/numpy.polynomial.chebyshev.chebyshev", "type": "numpy.polynomial.chebyshev.Chebyshev", "text": "\nA Chebyshev series class.\n\nThe Chebyshev class provides the standard Python numerical methods \u2018+\u2019, \u2018-\u2019,\n\u2018*\u2019, \u2018//\u2019, \u2018%\u2019, \u2018divmod\u2019, \u2018**\u2019, and \u2018()\u2019 as well as the methods listed below.\n\nChebyshev coefficients in order of increasing degree, i.e., `(1, 2, 3)` gives\n`1*T_0(x) + 2*T_1(x) + 3*T_2(x)`.\n\nDomain to use. The interval `[domain[0], domain[1]]` is mapped to the interval\n`[window[0], window[1]]` by shifting and scaling. The default value is [-1,\n1].\n\nWindow, see `domain` for its use. The default value is [-1, 1].\n\nNew in version 1.6.0.\n\n`__call__`(arg)\n\nCall self as a function.\n\n`basis`(deg[, domain, window])\n\nSeries basis polynomial of degree `deg`.\n\n`cast`(series[, domain, window])\n\nConvert series to series of this class.\n\n`convert`([domain, kind, window])\n\nConvert series to a different kind and/or domain and/or window.\n\n`copy`()\n\nReturn a copy.\n\n`cutdeg`(deg)\n\nTruncate series to the given degree.\n\n`degree`()\n\nThe degree of the series.\n\n`deriv`([m])\n\nDifferentiate.\n\n`fit`(x, y, deg[, domain, rcond, full, w, window])\n\nLeast squares fit to data.\n\n`fromroots`(roots[, domain, window])\n\nReturn series instance that has the specified roots.\n\n`has_samecoef`(other)\n\nCheck if coefficients match.\n\n`has_samedomain`(other)\n\nCheck if domains match.\n\n`has_sametype`(other)\n\nCheck if types match.\n\n`has_samewindow`(other)\n\nCheck if windows match.\n\n`identity`([domain, window])\n\nIdentity function.\n\n`integ`([m, k, lbnd])\n\nIntegrate.\n\n`interpolate`(func, deg[, domain, args])\n\nInterpolate a function at the Chebyshev points of the first kind.\n\n`linspace`([n, domain])\n\nReturn x, y values at equally spaced points in domain.\n\n`mapparms`()\n\nReturn the mapping parameters.\n\n`roots`()\n\nReturn the roots of the series polynomial.\n\n`trim`([tol])\n\nRemove trailing coefficients\n\n`truncate`(size)\n\nTruncate series to length `size`.\n\n"}, {"name": "numpy.polynomial.hermite.Hermite()", "path": "reference/generated/numpy.polynomial.hermite.hermite", "type": "numpy.polynomial.hermite.Hermite", "text": "\nAn Hermite series class.\n\nThe Hermite class provides the standard Python numerical methods \u2018+\u2019, \u2018-\u2019,\n\u2018*\u2019, \u2018//\u2019, \u2018%\u2019, \u2018divmod\u2019, \u2018**\u2019, and \u2018()\u2019 as well as the attributes and methods\nlisted in the `ABCPolyBase` documentation.\n\nHermite coefficients in order of increasing degree, i.e, `(1, 2, 3)` gives\n`1*H_0(x) + 2*H_1(X) + 3*H_2(x)`.\n\nDomain to use. The interval `[domain[0], domain[1]]` is mapped to the interval\n`[window[0], window[1]]` by shifting and scaling. The default value is [-1,\n1].\n\nWindow, see `domain` for its use. The default value is [-1, 1].\n\nNew in version 1.6.0.\n\n`__call__`(arg)\n\nCall self as a function.\n\n`basis`(deg[, domain, window])\n\nSeries basis polynomial of degree `deg`.\n\n`cast`(series[, domain, window])\n\nConvert series to series of this class.\n\n`convert`([domain, kind, window])\n\nConvert series to a different kind and/or domain and/or window.\n\n`copy`()\n\nReturn a copy.\n\n`cutdeg`(deg)\n\nTruncate series to the given degree.\n\n`degree`()\n\nThe degree of the series.\n\n`deriv`([m])\n\nDifferentiate.\n\n`fit`(x, y, deg[, domain, rcond, full, w, window])\n\nLeast squares fit to data.\n\n`fromroots`(roots[, domain, window])\n\nReturn series instance that has the specified roots.\n\n`has_samecoef`(other)\n\nCheck if coefficients match.\n\n`has_samedomain`(other)\n\nCheck if domains match.\n\n`has_sametype`(other)\n\nCheck if types match.\n\n`has_samewindow`(other)\n\nCheck if windows match.\n\n`identity`([domain, window])\n\nIdentity function.\n\n`integ`([m, k, lbnd])\n\nIntegrate.\n\n`linspace`([n, domain])\n\nReturn x, y values at equally spaced points in domain.\n\n`mapparms`()\n\nReturn the mapping parameters.\n\n`roots`()\n\nReturn the roots of the series polynomial.\n\n`trim`([tol])\n\nRemove trailing coefficients\n\n`truncate`(size)\n\nTruncate series to length `size`.\n\n"}, {"name": "numpy.polynomial.hermite_e.HermiteE()", "path": "reference/generated/numpy.polynomial.hermite_e.hermitee", "type": "numpy.polynomial.hermite_e.HermiteE", "text": "\nAn HermiteE series class.\n\nThe HermiteE class provides the standard Python numerical methods \u2018+\u2019, \u2018-\u2019,\n\u2018*\u2019, \u2018//\u2019, \u2018%\u2019, \u2018divmod\u2019, \u2018**\u2019, and \u2018()\u2019 as well as the attributes and methods\nlisted in the `ABCPolyBase` documentation.\n\nHermiteE coefficients in order of increasing degree, i.e, `(1, 2, 3)` gives\n`1*He_0(x) + 2*He_1(X) + 3*He_2(x)`.\n\nDomain to use. The interval `[domain[0], domain[1]]` is mapped to the interval\n`[window[0], window[1]]` by shifting and scaling. The default value is [-1,\n1].\n\nWindow, see `domain` for its use. The default value is [-1, 1].\n\nNew in version 1.6.0.\n\n`__call__`(arg)\n\nCall self as a function.\n\n`basis`(deg[, domain, window])\n\nSeries basis polynomial of degree `deg`.\n\n`cast`(series[, domain, window])\n\nConvert series to series of this class.\n\n`convert`([domain, kind, window])\n\nConvert series to a different kind and/or domain and/or window.\n\n`copy`()\n\nReturn a copy.\n\n`cutdeg`(deg)\n\nTruncate series to the given degree.\n\n`degree`()\n\nThe degree of the series.\n\n`deriv`([m])\n\nDifferentiate.\n\n`fit`(x, y, deg[, domain, rcond, full, w, window])\n\nLeast squares fit to data.\n\n`fromroots`(roots[, domain, window])\n\nReturn series instance that has the specified roots.\n\n`has_samecoef`(other)\n\nCheck if coefficients match.\n\n`has_samedomain`(other)\n\nCheck if domains match.\n\n`has_sametype`(other)\n\nCheck if types match.\n\n`has_samewindow`(other)\n\nCheck if windows match.\n\n`identity`([domain, window])\n\nIdentity function.\n\n`integ`([m, k, lbnd])\n\nIntegrate.\n\n`linspace`([n, domain])\n\nReturn x, y values at equally spaced points in domain.\n\n`mapparms`()\n\nReturn the mapping parameters.\n\n`roots`()\n\nReturn the roots of the series polynomial.\n\n`trim`([tol])\n\nRemove trailing coefficients\n\n`truncate`(size)\n\nTruncate series to length `size`.\n\n"}, {"name": "numpy.polynomial.laguerre.Laguerre()", "path": "reference/generated/numpy.polynomial.laguerre.laguerre", "type": "numpy.polynomial.laguerre.Laguerre", "text": "\nA Laguerre series class.\n\nThe Laguerre class provides the standard Python numerical methods \u2018+\u2019, \u2018-\u2019,\n\u2018*\u2019, \u2018//\u2019, \u2018%\u2019, \u2018divmod\u2019, \u2018**\u2019, and \u2018()\u2019 as well as the attributes and methods\nlisted in the `ABCPolyBase` documentation.\n\nLaguerre coefficients in order of increasing degree, i.e, `(1, 2, 3)` gives\n`1*L_0(x) + 2*L_1(X) + 3*L_2(x)`.\n\nDomain to use. The interval `[domain[0], domain[1]]` is mapped to the interval\n`[window[0], window[1]]` by shifting and scaling. The default value is [0, 1].\n\nWindow, see `domain` for its use. The default value is [0, 1].\n\nNew in version 1.6.0.\n\n`__call__`(arg)\n\nCall self as a function.\n\n`basis`(deg[, domain, window])\n\nSeries basis polynomial of degree `deg`.\n\n`cast`(series[, domain, window])\n\nConvert series to series of this class.\n\n`convert`([domain, kind, window])\n\nConvert series to a different kind and/or domain and/or window.\n\n`copy`()\n\nReturn a copy.\n\n`cutdeg`(deg)\n\nTruncate series to the given degree.\n\n`degree`()\n\nThe degree of the series.\n\n`deriv`([m])\n\nDifferentiate.\n\n`fit`(x, y, deg[, domain, rcond, full, w, window])\n\nLeast squares fit to data.\n\n`fromroots`(roots[, domain, window])\n\nReturn series instance that has the specified roots.\n\n`has_samecoef`(other)\n\nCheck if coefficients match.\n\n`has_samedomain`(other)\n\nCheck if domains match.\n\n`has_sametype`(other)\n\nCheck if types match.\n\n`has_samewindow`(other)\n\nCheck if windows match.\n\n`identity`([domain, window])\n\nIdentity function.\n\n`integ`([m, k, lbnd])\n\nIntegrate.\n\n`linspace`([n, domain])\n\nReturn x, y values at equally spaced points in domain.\n\n`mapparms`()\n\nReturn the mapping parameters.\n\n`roots`()\n\nReturn the roots of the series polynomial.\n\n`trim`([tol])\n\nRemove trailing coefficients\n\n`truncate`(size)\n\nTruncate series to length `size`.\n\n"}, {"name": "numpy.polynomial.legendre.Legendre()", "path": "reference/generated/numpy.polynomial.legendre.legendre", "type": "numpy.polynomial.legendre.Legendre", "text": "\nA Legendre series class.\n\nThe Legendre class provides the standard Python numerical methods \u2018+\u2019, \u2018-\u2019,\n\u2018*\u2019, \u2018//\u2019, \u2018%\u2019, \u2018divmod\u2019, \u2018**\u2019, and \u2018()\u2019 as well as the attributes and methods\nlisted in the `ABCPolyBase` documentation.\n\nLegendre coefficients in order of increasing degree, i.e., `(1, 2, 3)` gives\n`1*P_0(x) + 2*P_1(x) + 3*P_2(x)`.\n\nDomain to use. The interval `[domain[0], domain[1]]` is mapped to the interval\n`[window[0], window[1]]` by shifting and scaling. The default value is [-1,\n1].\n\nWindow, see `domain` for its use. The default value is [-1, 1].\n\nNew in version 1.6.0.\n\n`__call__`(arg)\n\nCall self as a function.\n\n`basis`(deg[, domain, window])\n\nSeries basis polynomial of degree `deg`.\n\n`cast`(series[, domain, window])\n\nConvert series to series of this class.\n\n`convert`([domain, kind, window])\n\nConvert series to a different kind and/or domain and/or window.\n\n`copy`()\n\nReturn a copy.\n\n`cutdeg`(deg)\n\nTruncate series to the given degree.\n\n`degree`()\n\nThe degree of the series.\n\n`deriv`([m])\n\nDifferentiate.\n\n`fit`(x, y, deg[, domain, rcond, full, w, window])\n\nLeast squares fit to data.\n\n`fromroots`(roots[, domain, window])\n\nReturn series instance that has the specified roots.\n\n`has_samecoef`(other)\n\nCheck if coefficients match.\n\n`has_samedomain`(other)\n\nCheck if domains match.\n\n`has_sametype`(other)\n\nCheck if types match.\n\n`has_samewindow`(other)\n\nCheck if windows match.\n\n`identity`([domain, window])\n\nIdentity function.\n\n`integ`([m, k, lbnd])\n\nIntegrate.\n\n`linspace`([n, domain])\n\nReturn x, y values at equally spaced points in domain.\n\n`mapparms`()\n\nReturn the mapping parameters.\n\n`roots`()\n\nReturn the roots of the series polynomial.\n\n`trim`([tol])\n\nRemove trailing coefficients\n\n`truncate`(size)\n\nTruncate series to length `size`.\n\n"}, {"name": "numpy.polynomial.polynomial.Polynomial()", "path": "reference/generated/numpy.polynomial.polynomial.polynomial", "type": "numpy.polynomial.polynomial.Polynomial", "text": "\nA power series class.\n\nThe Polynomial class provides the standard Python numerical methods \u2018+\u2019, \u2018-\u2019,\n\u2018*\u2019, \u2018//\u2019, \u2018%\u2019, \u2018divmod\u2019, \u2018**\u2019, and \u2018()\u2019 as well as the attributes and methods\nlisted in the `ABCPolyBase` documentation.\n\nPolynomial coefficients in order of increasing degree, i.e., `(1, 2, 3)` give\n`1 + 2*x + 3*x**2`.\n\nDomain to use. The interval `[domain[0], domain[1]]` is mapped to the interval\n`[window[0], window[1]]` by shifting and scaling. The default value is [-1,\n1].\n\nWindow, see `domain` for its use. The default value is [-1, 1].\n\nNew in version 1.6.0.\n\n`__call__`(arg)\n\nCall self as a function.\n\n`basis`(deg[, domain, window])\n\nSeries basis polynomial of degree `deg`.\n\n`cast`(series[, domain, window])\n\nConvert series to series of this class.\n\n`convert`([domain, kind, window])\n\nConvert series to a different kind and/or domain and/or window.\n\n`copy`()\n\nReturn a copy.\n\n`cutdeg`(deg)\n\nTruncate series to the given degree.\n\n`degree`()\n\nThe degree of the series.\n\n`deriv`([m])\n\nDifferentiate.\n\n`fit`(x, y, deg[, domain, rcond, full, w, window])\n\nLeast squares fit to data.\n\n`fromroots`(roots[, domain, window])\n\nReturn series instance that has the specified roots.\n\n`has_samecoef`(other)\n\nCheck if coefficients match.\n\n`has_samedomain`(other)\n\nCheck if domains match.\n\n`has_sametype`(other)\n\nCheck if types match.\n\n`has_samewindow`(other)\n\nCheck if windows match.\n\n`identity`([domain, window])\n\nIdentity function.\n\n`integ`([m, k, lbnd])\n\nIntegrate.\n\n`linspace`([n, domain])\n\nReturn x, y values at equally spaced points in domain.\n\n`mapparms`()\n\nReturn the mapping parameters.\n\n`roots`()\n\nReturn the roots of the series polynomial.\n\n`trim`([tol])\n\nRemove trailing coefficients\n\n`truncate`(size)\n\nTruncate series to length `size`.\n\n"}, {"name": "numpy.polysub()", "path": "reference/generated/numpy.polysub", "type": "numpy.polysub", "text": "\nDifference (subtraction) of two polynomials.\n\nNote\n\nThis forms part of the old polynomial API. Since version 1.4, the new\npolynomial API defined in `numpy.polynomial` is preferred. A summary of the\ndifferences can be found in the transition guide.\n\nGiven two polynomials `a1` and `a2`, returns `a1 - a2`. `a1` and `a2` can be\neither array_like sequences of the polynomials\u2019 coefficients (including\ncoefficients equal to zero), or `poly1d` objects.\n\nMinuend and subtrahend polynomials, respectively.\n\nArray or `poly1d` object of the difference polynomial\u2019s coefficients.\n\nSee also\n\n"}, {"name": "numpy.polyval()", "path": "reference/generated/numpy.polyval", "type": "numpy.polyval", "text": "\nEvaluate a polynomial at specific values.\n\nNote\n\nThis forms part of the old polynomial API. Since version 1.4, the new\npolynomial API defined in `numpy.polynomial` is preferred. A summary of the\ndifferences can be found in the transition guide.\n\nIf `p` is of length N, this function returns the value:\n\n`p[0]*x**(N-1) + p[1]*x**(N-2) + ... + p[N-2]*x + p[N-1]`\n\nIf `x` is a sequence, then `p(x)` is returned for each element of `x`. If `x`\nis another polynomial then the composite polynomial `p(x(t))` is returned.\n\n1D array of polynomial coefficients (including coefficients equal to zero)\nfrom highest degree to the constant term, or an instance of poly1d.\n\nA number, an array of numbers, or an instance of poly1d, at which to evaluate\n`p`.\n\nIf `x` is a poly1d instance, the result is the composition of the two\npolynomials, i.e., `x` is \u201csubstituted\u201d in `p` and the simplified result is\nreturned. In addition, the type of `x` \\- array_like or poly1d - governs the\ntype of the output: `x` array_like => `values` array_like, `x` a poly1d object\n=> `values` is also.\n\nSee also\n\nA polynomial class.\n\nHorner\u2019s scheme [1] is used to evaluate the polynomial. Even so, for\npolynomials of high degree the values may be inaccurate due to rounding\nerrors. Use carefully.\n\nIf `x` is a subtype of `ndarray` the return value will be of the same type.\n\nI. N. Bronshtein, K. A. Semendyayev, and K. A. Hirsch (Eng. trans. Ed.),\nHandbook of Mathematics, New York, Van Nostrand Reinhold Co., 1985, pg. 720.\n\n"}, {"name": "numpy.positive()", "path": "reference/generated/numpy.positive", "type": "numpy.positive", "text": "\nNumerical positive, element-wise.\n\nNew in version 1.13.0.\n\nInput array.\n\nReturned array or scalar: `y = +x`. This is a scalar if `x` is a scalar.\n\nEquivalent to `x.copy()`, but only defined for types that support arithmetic.\n\nThe unary `+` operator can be used as a shorthand for `np.positive` on\nndarrays.\n\n"}, {"name": "numpy.power()", "path": "reference/generated/numpy.power", "type": "numpy.power", "text": "\nFirst array elements raised to powers from second array, element-wise.\n\nRaise each base in `x1` to the positionally-corresponding power in `x2`. `x1`\nand `x2` must be broadcastable to the same shape.\n\nAn integer type raised to a negative integer power will raise a `ValueError`.\n\nNegative values raised to a non-integral value will return `nan`. To get\ncomplex results, cast the input to complex, or specify the `dtype` to be\n`complex` (see the example below).\n\nThe bases.\n\nThe exponents. If `x1.shape != x2.shape`, they must be broadcastable to a\ncommon shape (which becomes the shape of the output).\n\nA location into which the result is stored. If provided, it must have a shape\nthat the inputs broadcast to. If not provided or None, a freshly-allocated\narray is returned. A tuple (possible only as a keyword argument) must have\nlength equal to the number of outputs.\n\nThis condition is broadcast over the input. At locations where the condition\nis True, the `out` array will be set to the ufunc result. Elsewhere, the `out`\narray will retain its original value. Note that if an uninitialized `out`\narray is created via the default `out=None`, locations within it where the\ncondition is False will remain uninitialized.\n\nFor other keyword-only arguments, see the ufunc docs.\n\nThe bases in `x1` raised to the exponents in `x2`. This is a scalar if both\n`x1` and `x2` are scalars.\n\nSee also\n\npower function that promotes integers to float\n\nCube each element in an array.\n\nRaise the bases to different exponents.\n\nThe effect of broadcasting.\n\nThe `**` operator can be used as a shorthand for `np.power` on ndarrays.\n\nNegative values raised to a non-integral value will result in `nan` (and a\nwarning will be generated).\n\nTo get complex results, give the argument `dtype=complex`.\n\n"}, {"name": "numpy.printoptions()", "path": "reference/generated/numpy.printoptions", "type": "numpy.printoptions", "text": "\nContext manager for setting print options.\n\nSet print options for the scope of the `with` block, and restore the old\noptions at the end. See `set_printoptions` for the full description of\navailable options.\n\nSee also\n\nThe `as`-clause of the `with`-statement gives the current print options:\n\n"}, {"name": "numpy.prod()", "path": "reference/generated/numpy.prod", "type": "numpy.prod", "text": "\nReturn the product of array elements over a given axis.\n\nInput data.\n\nAxis or axes along which a product is performed. The default, axis=None, will\ncalculate the product of all the elements in the input array. If axis is\nnegative it counts from the last to the first axis.\n\nNew in version 1.7.0.\n\nIf axis is a tuple of ints, a product is performed on all of the axes\nspecified in the tuple instead of a single axis or all the axes as before.\n\nThe type of the returned array, as well as of the accumulator in which the\nelements are multiplied. The dtype of `a` is used by default unless `a` has an\ninteger dtype of less precision than the default platform integer. In that\ncase, if `a` is signed then the platform integer is used while if `a` is\nunsigned then an unsigned integer of the same precision as the platform\ninteger is used.\n\nAlternative output array in which to place the result. It must have the same\nshape as the expected output, but the type of the output values will be cast\nif necessary.\n\nIf this is set to True, the axes which are reduced are left in the result as\ndimensions with size one. With this option, the result will broadcast\ncorrectly against the input array.\n\nIf the default value is passed, then `keepdims` will not be passed through to\nthe `prod` method of sub-classes of `ndarray`, however any non-default value\nwill be. If the sub-class\u2019 method does not implement `keepdims` any exceptions\nwill be raised.\n\nThe starting value for this product. See `reduce` for details.\n\nNew in version 1.15.0.\n\nElements to include in the product. See `reduce` for details.\n\nNew in version 1.17.0.\n\nAn array shaped as `a` but with the specified axis removed. Returns a\nreference to `out` if specified.\n\nSee also\n\nequivalent method\n\nArithmetic is modular when using integer types, and no error is raised on\noverflow. That means that, on a 32-bit platform:\n\nThe product of an empty array is the neutral element 1:\n\nBy default, calculate the product of all elements:\n\nEven when the input array is two-dimensional:\n\nBut we can also specify the axis over which to multiply:\n\nOr select specific elements to include:\n\nIf the type of `x` is unsigned, then the output type is the unsigned platform\ninteger:\n\nIf `x` is of a signed integer type, then the output type is the default\nplatform integer:\n\nYou can also start the product with a value other than one:\n\n"}, {"name": "numpy.promote_types()", "path": "reference/generated/numpy.promote_types", "type": "numpy.promote_types", "text": "\nReturns the data type with the smallest size and smallest scalar kind to which\nboth `type1` and `type2` may be safely cast. The returned data type is always\nin native byte order.\n\nThis function is symmetric, but rarely associative.\n\nFirst data type.\n\nSecond data type.\n\nThe promoted data type.\n\nSee also\n\nNew in version 1.6.0.\n\nStarting in NumPy 1.9, promote_types function now returns a valid string\nlength when given an integer or float dtype as one argument and a string dtype\nas another argument. Previously it always returned the input string dtype,\neven if it wasn\u2019t long enough to store the max integer/float value converted\nto a string.\n\nAn example of a non-associative case:\n\n"}, {"name": "numpy.ptp()", "path": "reference/generated/numpy.ptp", "type": "numpy.ptp", "text": "\nRange of values (maximum - minimum) along an axis.\n\nThe name of the function comes from the acronym for \u2018peak to peak\u2019.\n\nWarning\n\n`ptp` preserves the data type of the array. This means the return value for an\ninput of signed integers with n bits (e.g. `np.int8`, `np.int16`, etc) is also\na signed integer with n bits. In that case, peak-to-peak values greater than\n`2**(n-1)-1` will be returned as negative values. An example with a work-\naround is shown below.\n\nInput values.\n\nAxis along which to find the peaks. By default, flatten the array. `axis` may\nbe negative, in which case it counts from the last to the first axis.\n\nNew in version 1.15.0.\n\nIf this is a tuple of ints, a reduction is performed on multiple axes, instead\nof a single axis or all the axes as before.\n\nAlternative output array in which to place the result. It must have the same\nshape and buffer length as the expected output, but the type of the output\nvalues will be cast if necessary.\n\nIf this is set to True, the axes which are reduced are left in the result as\ndimensions with size one. With this option, the result will broadcast\ncorrectly against the input array.\n\nIf the default value is passed, then `keepdims` will not be passed through to\nthe `ptp` method of sub-classes of `ndarray`, however any non-default value\nwill be. If the sub-class\u2019 method does not implement `keepdims` any exceptions\nwill be raised.\n\nA new array holding the result, unless `out` was specified, in which case a\nreference to `out` is returned.\n\nThis example shows that a negative value can be returned when the input is an\narray of signed integers.\n\nA work-around is to use the `view()` method to view the result as unsigned\nintegers with the same bit width:\n\n"}, {"name": "numpy.put()", "path": "reference/generated/numpy.put", "type": "numpy.put", "text": "\nReplaces specified elements of an array with given values.\n\nThe indexing works on the flattened target array. `put` is roughly equivalent\nto:\n\nTarget array.\n\nTarget indices, interpreted as integers.\n\nValues to place in `a` at target indices. If `v` is shorter than `ind` it will\nbe repeated as necessary.\n\nSpecifies how out-of-bounds indices will behave.\n\n\u2018clip\u2019 mode means that all indices that are too large are replaced by the\nindex that addresses the last element along that axis. Note that this disables\nindexing with negative numbers. In \u2018raise\u2019 mode, if an exception occurs the\ntarget array may still be modified.\n\nSee also\n\nPut elements by matching the array and the index arrays\n\n"}, {"name": "numpy.put_along_axis()", "path": "reference/generated/numpy.put_along_axis", "type": "numpy.put_along_axis", "text": "\nPut values into the destination array by matching 1d index and data slices.\n\nThis iterates over matching 1d slices oriented along the specified axis in the\nindex and data arrays, and uses the former to place values into the latter.\nThese slices can be different lengths.\n\nFunctions returning an index along an axis, like `argsort` and `argpartition`,\nproduce suitable indices for this function.\n\nNew in version 1.15.0.\n\nDestination array.\n\nIndices to change along each 1d slice of `arr`. This must match the dimension\nof arr, but dimensions in Ni and Nj may be 1 to broadcast against `arr`.\n\nvalues to insert at those indices. Its shape and dimension are broadcast to\nmatch that of `indices`.\n\nThe axis to take 1d slices along. If axis is None, the destination array is\ntreated as if a flattened 1d view had been created of it.\n\nSee also\n\nTake values from the input array by matching 1d index and data slices\n\nThis is equivalent to (but faster than) the following use of `ndindex` and\n`s_`, which sets each of `ii` and `kk` to a tuple of indices:\n\nEquivalently, eliminating the inner loop, the last two lines would be:\n\nFor this sample array\n\nWe can replace the maximum values with:\n\n"}, {"name": "numpy.putmask()", "path": "reference/generated/numpy.putmask", "type": "numpy.putmask", "text": "\nChanges elements of an array based on conditional and input values.\n\nSets `a.flat[n] = values[n]` for each n where `mask.flat[n]==True`.\n\nIf `values` is not the same size as `a` and `mask` then it will repeat. This\ngives behavior different from `a[mask] = values`.\n\nTarget array.\n\nBoolean mask array. It has to be the same shape as `a`.\n\nValues to put into `a` where `mask` is True. If `values` is smaller than `a`\nit will be repeated.\n\nSee also\n\nIf `values` is smaller than `a` it is repeated:\n\n"}, {"name": "numpy.PZERO", "path": "reference/constants#numpy.PZERO", "type": "Constants", "text": "\nIEEE 754 floating point representation of positive zero.\n\nA floating point representation of positive zero.\n\nNZERO : Defines negative zero.\n\nisinf : Shows which elements are positive or negative infinity.\n\nisposinf : Shows which elements are positive infinity.\n\nisneginf : Shows which elements are negative infinity.\n\nisnan : Shows which elements are Not a Number.\n\nNot a Number, positive infinity and negative infinity.\n\nNumPy uses the IEEE Standard for Binary Floating-Point for Arithmetic (IEEE\n754). Positive zero is considered to be a finite number.\n\n"}, {"name": "numpy.quantile()", "path": "reference/generated/numpy.quantile", "type": "numpy.quantile", "text": "\nCompute the q-th quantile of the data along the specified axis.\n\nNew in version 1.15.0.\n\nInput array or object that can be converted to an array.\n\nQuantile or sequence of quantiles to compute, which must be between 0 and 1\ninclusive.\n\nAxis or axes along which the quantiles are computed. The default is to compute\nthe quantile(s) along a flattened version of the array.\n\nAlternative output array in which to place the result. It must have the same\nshape and buffer length as the expected output, but the type (of the output)\nwill be cast if necessary.\n\nIf True, then allow the input array `a` to be modified by intermediate\ncalculations, to save memory. In this case, the contents of the input `a`\nafter this function completes is undefined.\n\nThis parameter specifies the method to use for estimating the quantile. There\nare many different methods, some unique to NumPy. See the notes for\nexplanation. The options sorted by their R type as summarized in the H&F paper\n[1] are:\n\nThe first three methods are discontiuous. NumPy further defines the following\ndiscontinuous variations of the default \u2018linear\u2019 (7.) option:\n\nChanged in version 1.22.0: This argument was previously called \u201cinterpolation\u201d\nand only offered the \u201clinear\u201d default and last four options.\n\nIf this is set to True, the axes which are reduced are left in the result as\ndimensions with size one. With this option, the result will broadcast\ncorrectly against the original array `a`.\n\nDeprecated name for the method keyword argument.\n\nDeprecated since version 1.22.0.\n\nIf `q` is a single quantile and `axis=None`, then the result is a scalar. If\nmultiple quantiles are given, first axis of the result corresponds to the\nquantiles. The other axes are the axes that remain after the reduction of `a`.\nIf the input contains integers or floats smaller than `float64`, the output\ndata-type is `float64`. Otherwise, the output data-type is the same as that of\nthe input. If `out` is specified, that array is returned instead.\n\nSee also\n\nequivalent to quantile, but with q in the range [0, 100].\n\nequivalent to `quantile(..., 0.5)`\n\nGiven a vector `V` of length `N`, the q-th quantile of `V` is the value `q` of\nthe way from the minimum to the maximum in a sorted copy of `V`. The values\nand distances of the two nearest neighbors as well as the `method` parameter\nwill determine the quantile if the normalized ranking does not match the\nlocation of `q` exactly. This function is the same as the median if `q=0.5`,\nthe same as the minimum if `q=0.0` and the same as the maximum if `q=1.0`.\n\nThis optional `method` parameter specifies the method to use when the desired\nquantile lies between two data points `i < j`. If `g` is the fractional part\nof the index surrounded by `i` and alpha and beta are correction constants\nmodifying i and j.\n\nThe different methods then work as follows\n\nmethod 1 of H&F [1]. This method gives discontinuous results: * if g > 0 ;\nthen take j * if g = 0 ; then take i\n\nmethod 2 of H&F [1]. This method give discontinuous results: * if g > 0 ; then\ntake j * if g = 0 ; then average between bounds\n\nmethod 3 of H&F [1]. This method give discontinuous results: * if g > 0 ; then\ntake j * if g = 0 and index is odd ; then take j * if g = 0 and index is even\n; then take i\n\nmethod 4 of H&F [1]. This method give continuous results using: * alpha = 0 *\nbeta = 1\n\nmethod 5 of H&F [1]. This method give continuous results using: * alpha = 1/2\n* beta = 1/2\n\nmethod 6 of H&F [1]. This method give continuous results using: * alpha = 0 *\nbeta = 0\n\nmethod 7 of H&F [1]. This method give continuous results using: * alpha = 1 *\nbeta = 1\n\nmethod 8 of H&F [1]. This method is probably the best method if the sample\ndistribution function is unknown (see reference). This method give continuous\nresults using: * alpha = 1/3 * beta = 1/3\n\nmethod 9 of H&F [1]. This method is probably the best method if the sample\ndistribution function is known to be normal. This method give continuous\nresults using: * alpha = 3/8 * beta = 3/8\n\nNumPy method kept for backwards compatibility. Takes `i` as the interpolation\npoint.\n\nNumPy method kept for backwards compatibility. Takes `j` as the interpolation\npoint.\n\nNumPy method kept for backwards compatibility. Takes `i` or `j`, whichever is\nnearest.\n\nNumPy method kept for backwards compatibility. Uses `(i + j) / 2`.\n\nR. J. Hyndman and Y. Fan, \u201cSample quantiles in statistical packages,\u201d The\nAmerican Statistician, 50(4), pp. 361-365, 1996\n\nSee also `numpy.percentile` for a visualization of most methods.\n\n"}, {"name": "numpy.r_", "path": "reference/generated/numpy.r_", "type": "numpy.r_", "text": "\nTranslates slice objects to concatenation along the first axis.\n\nThis is a simple way to build up arrays quickly. There are two use cases.\n\nIf slice notation is used, the syntax `start:stop:step` is equivalent to\n`np.arange(start, stop, step)` inside of the brackets. However, if `step` is\nan imaginary number (i.e. 100j) then its integer portion is interpreted as a\nnumber-of-points desired and the start and stop are inclusive. In other words\n`start:stop:stepj` is interpreted as `np.linspace(start, stop, step,\nendpoint=1)` inside of the brackets. After expansion of slice notation, all\ncomma separated sequences are concatenated together.\n\nOptional character strings placed as the first element of the index expression\ncan be used to change the output. The strings \u2018r\u2019 or \u2018c\u2019 result in matrix\noutput. If the result is 1-D and \u2018r\u2019 is specified a 1 x N (row) matrix is\nproduced. If the result is 1-D and \u2018c\u2019 is specified, then a N x 1 (column)\nmatrix is produced. If the result is 2-D then both provide the same matrix\nresult.\n\nA string integer specifies which axis to stack multiple comma separated arrays\nalong. A string of two comma-separated integers allows indication of the\nminimum number of dimensions to force each entry into as the second integer\n(the axis to concatenate along is still the first integer).\n\nA string with three comma-separated integers allows specification of the axis\nto concatenate along, the minimum number of dimensions to force the entries\nto, and which axis should contain the start of the arrays which are less than\nthe specified number of dimensions. In other words the third integer allows\nyou to specify where the 1\u2019s should be placed in the shape of the arrays that\nhave their shapes upgraded. By default, they are placed in the front of the\nshape tuple. The third argument allows you to specify where the start of the\narray should be instead. Thus, a third argument of \u20180\u2019 would place the 1\u2019s at\nthe end of the array shape. Negative integers specify where in the new shape\ntuple the last dimension of upgraded arrays should be placed, so the default\nis \u2018-1\u2019.\n\nSee also\n\nJoin a sequence of arrays along an existing axis.\n\nTranslates slice objects to concatenation along the second axis.\n\nString integers specify the axis to concatenate along or the minimum number of\ndimensions to force entries into.\n\nUsing \u2018r\u2019 or \u2018c\u2019 as a first string argument creates a matrix.\n\n"}, {"name": "numpy.rad2deg()", "path": "reference/generated/numpy.rad2deg", "type": "numpy.rad2deg", "text": "\nConvert angles from radians to degrees.\n\nAngle in radians.\n\nA location into which the result is stored. If provided, it must have a shape\nthat the inputs broadcast to. If not provided or None, a freshly-allocated\narray is returned. A tuple (possible only as a keyword argument) must have\nlength equal to the number of outputs.\n\nThis condition is broadcast over the input. At locations where the condition\nis True, the `out` array will be set to the ufunc result. Elsewhere, the `out`\narray will retain its original value. Note that if an uninitialized `out`\narray is created via the default `out=None`, locations within it where the\ncondition is False will remain uninitialized.\n\nFor other keyword-only arguments, see the ufunc docs.\n\nThe corresponding angle in degrees. This is a scalar if `x` is a scalar.\n\nSee also\n\nConvert angles from degrees to radians.\n\nRemove large jumps in angle by wrapping.\n\nNew in version 1.3.0.\n\nrad2deg(x) is `180 * x / pi`.\n\n"}, {"name": "numpy.radians()", "path": "reference/generated/numpy.radians", "type": "numpy.radians", "text": "\nConvert angles from degrees to radians.\n\nInput array in degrees.\n\nA location into which the result is stored. If provided, it must have a shape\nthat the inputs broadcast to. If not provided or None, a freshly-allocated\narray is returned. A tuple (possible only as a keyword argument) must have\nlength equal to the number of outputs.\n\nThis condition is broadcast over the input. At locations where the condition\nis True, the `out` array will be set to the ufunc result. Elsewhere, the `out`\narray will retain its original value. Note that if an uninitialized `out`\narray is created via the default `out=None`, locations within it where the\ncondition is False will remain uninitialized.\n\nFor other keyword-only arguments, see the ufunc docs.\n\nThe corresponding radian values. This is a scalar if `x` is a scalar.\n\nSee also\n\nequivalent function\n\nConvert a degree array to radians\n\n"}, {"name": "numpy.random.BitGenerator()", "path": "reference/random/bit_generators/generated/numpy.random.bitgenerator", "type": "numpy.random.BitGenerator", "text": "\nBase Class for generic BitGenerators, which provide a stream of random bits\nbased on different algorithms. Must be overridden.\n\nA seed to initialize the `BitGenerator`. If None, then fresh, unpredictable\nentropy will be pulled from the OS. If an `int` or `array_like[ints]` is\npassed, then it will be passed to ~`numpy.random.SeedSequence` to derive the\ninitial `BitGenerator` state. One may also pass in a `SeedSequence` instance.\n\nSee also\n\nLock instance that is shared so that the same BitGenerator can be used in\nmultiple Generators without corrupting the state. Code that generates values\nfrom a bit generator should hold the bit generator\u2019s lock.\n\n`random_raw`(self[, size])\n\nReturn randoms as generated by the underlying BitGenerator\n\n"}, {"name": "numpy.random.default_rng()", "path": "reference/random/generator", "type": "Random Generator", "text": "\nThe `Generator` provides access to a wide range of distributions, and served\nas a replacement for `RandomState`. The main difference between the two is\nthat `Generator` relies on an additional BitGenerator to manage state and\ngenerate the random bits, which are then transformed into random values from\nuseful distributions. The default BitGenerator used by `Generator` is `PCG64`.\nThe BitGenerator can be changed by passing an instantized BitGenerator to\n`Generator`.\n\nConstruct a new Generator with the default BitGenerator (PCG64).\n\nA seed to initialize the `BitGenerator`. If None, then fresh, unpredictable\nentropy will be pulled from the OS. If an `int` or `array_like[ints]` is\npassed, then it will be passed to `SeedSequence` to derive the initial\n`BitGenerator` state. One may also pass in a `SeedSequence` instance.\nAdditionally, when passed a `BitGenerator`, it will be wrapped by `Generator`.\nIf passed a `Generator`, it will be returned unaltered.\n\nThe initialized generator object.\n\nIf `seed` is not a `BitGenerator` or a `Generator`, a new `BitGenerator` is\ninstantiated. This function does not manage a default global instance.\n\n`default_rng` is the recommended constructor for the random number class\n`Generator`. Here are several ways we can construct a random number generator\nusing `default_rng` and the `Generator` class.\n\nHere we use `default_rng` to generate a random float:\n\nHere we use `default_rng` to generate 3 random integers between 0 (inclusive)\nand 10 (exclusive):\n\nHere we specify a seed so that we have reproducible results:\n\nIf we exit and restart our Python interpreter, we\u2019ll see that we generate the\nsame random numbers again:\n\nContainer for the BitGenerators.\n\n`Generator` exposes a number of methods for generating random numbers drawn\nfrom a variety of probability distributions. In addition to the distribution-\nspecific arguments, each method takes a keyword argument `size` that defaults\nto `None`. If `size` is `None`, then a single value is generated and returned.\nIf `size` is an integer, then a 1-D array filled with generated values is\nreturned. If `size` is a tuple, then an array with that shape is filled and\nreturned.\n\nThe function `numpy.random.default_rng` will instantiate a `Generator` with\nnumpy\u2019s default `BitGenerator`.\n\nNo Compatibility Guarantee\n\n`Generator` does not provide a version compatibility guarantee. In particular,\nas better algorithms evolve the bit stream may change.\n\nBitGenerator to use as the core generator.\n\nSee also\n\nRecommended constructor for `Generator`.\n\nThe Python stdlib module `random` contains pseudo-random number generator with\na number of methods that are similar to the ones available in `Generator`. It\nuses Mersenne Twister, and this bit generator can be accessed using `MT19937`.\n`Generator`, besides being NumPy-aware, has the advantage that it provides a\nmuch larger number of probability distributions to choose from.\n\n`bit_generator`\n\nGets the bit generator instance used by the generator\n\n`integers`(low[, high, size, dtype, endpoint])\n\nReturn random integers from `low` (inclusive) to `high` (exclusive), or if\nendpoint=True, `low` (inclusive) to `high` (inclusive).\n\n`random`([size, dtype, out])\n\nReturn random floats in the half-open interval [0.0, 1.0).\n\n`choice`(a[, size, replace, p, axis, shuffle])\n\nGenerates a random sample from a given array\n\n`bytes`(length)\n\nReturn random bytes.\n\nThe methods for randomly permuting a sequence are\n\n`shuffle`(x[, axis])\n\nModify an array or sequence in-place by shuffling its contents.\n\n`permutation`(x[, axis])\n\nRandomly permute a sequence, or return a permuted range.\n\n`permuted`(x[, axis, out])\n\nRandomly permute `x` along axis `axis`.\n\nThe following table summarizes the behaviors of the methods.\n\nmethod\n\ncopy/in-place\n\naxis handling\n\nshuffle\n\nin-place\n\nas if 1d\n\npermutation\n\ncopy\n\nas if 1d\n\npermuted\n\neither (use \u2018out\u2019 for in-place)\n\naxis independent\n\nThe following subsections provide more details about the differences.\n\nThe main difference between `Generator.shuffle` and `Generator.permutation` is\nthat `Generator.shuffle` operates in-place, while `Generator.permutation`\nreturns a copy.\n\nBy default, `Generator.permuted` returns a copy. To operate in-place with\n`Generator.permuted`, pass the same array as the first argument and as the\nvalue of the `out` parameter. For example,\n\nNote that when `out` is given, the return value is `out`:\n\nAn important distinction for these methods is how they handle the `axis`\nparameter. Both `Generator.shuffle` and `Generator.permutation` treat the\ninput as a one-dimensional sequence, and the `axis` parameter determines which\ndimension of the input array to use as the sequence. In the case of a two-\ndimensional array, `axis=0` will, in effect, rearrange the rows of the array,\nand `axis=1` will rearrange the columns. For example\n\nNote that the columns have been rearranged \u201cin bulk\u201d: the values within each\ncolumn have not changed.\n\nThe method `Generator.permuted` treats the `axis` parameter similar to how\n`numpy.sort` treats it. Each slice along the given axis is shuffled\nindependently of the others. Compare the following example of the use of\n`Generator.permuted` to the above example of `Generator.permutation`:\n\nIn this example, the values within each row (i.e. the values along `axis=1`)\nhave been shuffled independently. This is not a \u201cbulk\u201d shuffle of the columns.\n\n`Generator.shuffle` works on non-NumPy sequences. That is, if it is given a\nsequence that is not a NumPy array, it shuffles that sequence in-place. For\nexample,\n\n`beta`(a, b[, size])\n\nDraw samples from a Beta distribution.\n\n`binomial`(n, p[, size])\n\nDraw samples from a binomial distribution.\n\n`chisquare`(df[, size])\n\nDraw samples from a chi-square distribution.\n\n`dirichlet`(alpha[, size])\n\nDraw samples from the Dirichlet distribution.\n\n`exponential`([scale, size])\n\nDraw samples from an exponential distribution.\n\n`f`(dfnum, dfden[, size])\n\nDraw samples from an F distribution.\n\n`gamma`(shape[, scale, size])\n\nDraw samples from a Gamma distribution.\n\n`geometric`(p[, size])\n\nDraw samples from the geometric distribution.\n\n`gumbel`([loc, scale, size])\n\nDraw samples from a Gumbel distribution.\n\n`hypergeometric`(ngood, nbad, nsample[, size])\n\nDraw samples from a Hypergeometric distribution.\n\n`laplace`([loc, scale, size])\n\nDraw samples from the Laplace or double exponential distribution with\nspecified location (or mean) and scale (decay).\n\n`logistic`([loc, scale, size])\n\nDraw samples from a logistic distribution.\n\n`lognormal`([mean, sigma, size])\n\nDraw samples from a log-normal distribution.\n\n`logseries`(p[, size])\n\nDraw samples from a logarithmic series distribution.\n\n`multinomial`(n, pvals[, size])\n\nDraw samples from a multinomial distribution.\n\n`multivariate_hypergeometric`(colors, nsample)\n\nGenerate variates from a multivariate hypergeometric distribution.\n\n`multivariate_normal`(mean, cov[, size, ...])\n\nDraw random samples from a multivariate normal distribution.\n\n`negative_binomial`(n, p[, size])\n\nDraw samples from a negative binomial distribution.\n\n`noncentral_chisquare`(df, nonc[, size])\n\nDraw samples from a noncentral chi-square distribution.\n\n`noncentral_f`(dfnum, dfden, nonc[, size])\n\nDraw samples from the noncentral F distribution.\n\n`normal`([loc, scale, size])\n\nDraw random samples from a normal (Gaussian) distribution.\n\n`pareto`(a[, size])\n\nDraw samples from a Pareto II or Lomax distribution with specified shape.\n\n`poisson`([lam, size])\n\nDraw samples from a Poisson distribution.\n\n`power`(a[, size])\n\nDraws samples in [0, 1] from a power distribution with positive exponent a -\n1.\n\n`rayleigh`([scale, size])\n\nDraw samples from a Rayleigh distribution.\n\n`standard_cauchy`([size])\n\nDraw samples from a standard Cauchy distribution with mode = 0.\n\n`standard_exponential`([size, dtype, method, out])\n\nDraw samples from the standard exponential distribution.\n\n`standard_gamma`(shape[, size, dtype, out])\n\nDraw samples from a standard Gamma distribution.\n\n`standard_normal`([size, dtype, out])\n\nDraw samples from a standard Normal distribution (mean=0, stdev=1).\n\n`standard_t`(df[, size])\n\nDraw samples from a standard Student's t distribution with `df` degrees of\nfreedom.\n\n`triangular`(left, mode, right[, size])\n\nDraw samples from the triangular distribution over the interval `[left,\nright]`.\n\n`uniform`([low, high, size])\n\nDraw samples from a uniform distribution.\n\n`vonmises`(mu, kappa[, size])\n\nDraw samples from a von Mises distribution.\n\n`wald`(mean, scale[, size])\n\nDraw samples from a Wald, or inverse Gaussian, distribution.\n\n`weibull`(a[, size])\n\nDraw samples from a Weibull distribution.\n\n`zipf`(a[, size])\n\nDraw samples from a Zipf distribution.\n\n"}, {"name": "numpy.random.Generator()", "path": "reference/random/generator#numpy.random.Generator", "type": "Random Generator", "text": "\nContainer for the BitGenerators.\n\n`Generator` exposes a number of methods for generating random numbers drawn\nfrom a variety of probability distributions. In addition to the distribution-\nspecific arguments, each method takes a keyword argument `size` that defaults\nto `None`. If `size` is `None`, then a single value is generated and returned.\nIf `size` is an integer, then a 1-D array filled with generated values is\nreturned. If `size` is a tuple, then an array with that shape is filled and\nreturned.\n\nThe function `numpy.random.default_rng` will instantiate a `Generator` with\nnumpy\u2019s default `BitGenerator`.\n\nNo Compatibility Guarantee\n\n`Generator` does not provide a version compatibility guarantee. In particular,\nas better algorithms evolve the bit stream may change.\n\nBitGenerator to use as the core generator.\n\nSee also\n\nRecommended constructor for `Generator`.\n\nThe Python stdlib module `random` contains pseudo-random number generator with\na number of methods that are similar to the ones available in `Generator`. It\nuses Mersenne Twister, and this bit generator can be accessed using `MT19937`.\n`Generator`, besides being NumPy-aware, has the advantage that it provides a\nmuch larger number of probability distributions to choose from.\n\n"}, {"name": "numpy.random.MT19937()", "path": "reference/random/bit_generators/mt19937", "type": "MT19937", "text": "\nContainer for the Mersenne Twister pseudo-random number generator.\n\nA seed to initialize the `BitGenerator`. If None, then fresh, unpredictable\nentropy will be pulled from the OS. If an `int` or `array_like[ints]` is\npassed, then it will be passed to `SeedSequence` to derive the initial\n`BitGenerator` state. One may also pass in a `SeedSequence` instance.\n\n`MT19937` provides a capsule containing function pointers that produce\ndoubles, and unsigned 32 and 64- bit integers [1]. These are not directly\nconsumable in Python and must be consumed by a `Generator` or similar object\nthat supports low-level access.\n\nThe Python stdlib module \u201crandom\u201d also contains a Mersenne Twister pseudo-\nrandom number generator.\n\nState and Seeding\n\nThe `MT19937` state vector consists of a 624-element array of 32-bit unsigned\nintegers plus a single integer value between 0 and 624 that indexes the\ncurrent position within the main array.\n\nThe input seed is processed by `SeedSequence` to fill the whole state. The\nfirst element is reset such that only its most significant bit is set.\n\nParallel Features\n\nThe preferred way to use a BitGenerator in parallel applications is to use the\n`SeedSequence.spawn` method to obtain entropy values, and to use these to\ngenerate new BitGenerators:\n\nAnother method is to use `MT19937.jumped` which advances the state as-if\n\\\\(2^{128}\\\\) random numbers have been generated ([1], [2]). This allows the\noriginal sequence to be split so that distinct segments can be used in each\nworker process. All generators should be chained to ensure that the segments\ncome from the same sequence.\n\nCompatibility Guarantee\n\n`MT19937` makes a guarantee that a fixed seed and will always produce the same\nrandom integer stream.\n\nHiroshi Haramoto, Makoto Matsumoto, and Pierre L\u2019Ecuyer, \u201cA Fast Jump Ahead\nAlgorithm for Linear Recurrences in a Polynomial Space\u201d, Sequences and Their\nApplications - SETA, 290\u2013298, 2008.\n\nHiroshi Haramoto, Makoto Matsumoto, Takuji Nishimura, Fran\u00e7ois Panneton,\nPierre L\u2019Ecuyer, \u201cEfficient Jump Ahead for F2-Linear Random Number\nGenerators\u201d, INFORMS JOURNAL ON COMPUTING, Vol. 20, No. 3, Summer 2008, pp.\n385-390.\n\nLock instance that is shared so that the same bit git generator can be used in\nmultiple Generators without corrupting the state. Code that generates values\nfrom a bit generator should hold the bit generator\u2019s lock.\n\n`state`\n\nGet or set the PRNG state\n\n`jumped`([jumps])\n\nReturns a new bit generator with the state jumped\n\n`cffi`\n\nCFFI interface\n\n`ctypes`\n\nctypes interface\n\n"}, {"name": "numpy.random.PCG64()", "path": "reference/random/bit_generators/pcg64", "type": "PCG64", "text": "\nBitGenerator for the PCG-64 pseudo-random number generator.\n\nA seed to initialize the `BitGenerator`. If None, then fresh, unpredictable\nentropy will be pulled from the OS. If an `int` or `array_like[ints]` is\npassed, then it will be passed to `SeedSequence` to derive the initial\n`BitGenerator` state. One may also pass in a `SeedSequence` instance.\n\nPCG-64 is a 128-bit implementation of O\u2019Neill\u2019s permutation congruential\ngenerator ([1], [2]). PCG-64 has a period of \\\\(2^{128}\\\\) and supports\nadvancing an arbitrary number of steps as well as \\\\(2^{127}\\\\) streams. The\nspecific member of the PCG family that we use is PCG XSL RR 128/64 as\ndescribed in the paper ([2]).\n\n`PCG64` provides a capsule containing function pointers that produce doubles,\nand unsigned 32 and 64- bit integers. These are not directly consumable in\nPython and must be consumed by a `Generator` or similar object that supports\nlow-level access.\n\nSupports the method `advance` to advance the RNG an arbitrary number of steps.\nThe state of the PCG-64 RNG is represented by 2 128-bit unsigned integers.\n\nState and Seeding\n\nThe `PCG64` state vector consists of 2 unsigned 128-bit values, which are\nrepresented externally as Python ints. One is the state of the PRNG, which is\nadvanced by a linear congruential generator (LCG). The second is a fixed odd\nincrement used in the LCG.\n\nThe input seed is processed by `SeedSequence` to generate both values. The\nincrement is not independently settable.\n\nParallel Features\n\nThe preferred way to use a BitGenerator in parallel applications is to use the\n`SeedSequence.spawn` method to obtain entropy values, and to use these to\ngenerate new BitGenerators:\n\nCompatibility Guarantee\n\n`PCG64` makes a guarantee that a fixed seed will always produce the same\nrandom integer stream.\n\n\u201cPCG, A Family of Better Random Number Generators\u201d\n\nO\u2019Neill, Melissa E. \u201cPCG: A Family of Simple Fast Space-Efficient\nStatistically Good Algorithms for Random Number Generation\u201d\n\n`state`\n\nGet or set the PRNG state\n\n`advance`(delta)\n\nAdvance the underlying RNG as-if delta draws have occurred.\n\n`jumped`([jumps])\n\nReturns a new bit generator with the state jumped.\n\n`cffi`\n\nCFFI interface\n\n`ctypes`\n\nctypes interface\n\n"}, {"name": "numpy.random.PCG64DXSM()", "path": "reference/random/bit_generators/pcg64dxsm", "type": "PCG64DXSM", "text": "\nBitGenerator for the PCG-64 DXSM pseudo-random number generator.\n\nA seed to initialize the `BitGenerator`. If None, then fresh, unpredictable\nentropy will be pulled from the OS. If an `int` or `array_like[ints]` is\npassed, then it will be passed to `SeedSequence` to derive the initial\n`BitGenerator` state. One may also pass in a `SeedSequence` instance.\n\nPCG-64 DXSM is a 128-bit implementation of O\u2019Neill\u2019s permutation congruential\ngenerator ([1], [2]). PCG-64 DXSM has a period of \\\\(2^{128}\\\\) and supports\nadvancing an arbitrary number of steps as well as \\\\(2^{127}\\\\) streams. The\nspecific member of the PCG family that we use is PCG CM DXSM 128/64. It\ndiffers from `PCG64` in that it uses the stronger DXSM output function, a\n64-bit \u201ccheap multiplier\u201d in the LCG, and outputs from the state before\nadvancing it rather than advance-then-output.\n\n`PCG64DXSM` provides a capsule containing function pointers that produce\ndoubles, and unsigned 32 and 64- bit integers. These are not directly\nconsumable in Python and must be consumed by a `Generator` or similar object\nthat supports low-level access.\n\nSupports the method `advance` to advance the RNG an arbitrary number of steps.\nThe state of the PCG-64 DXSM RNG is represented by 2 128-bit unsigned\nintegers.\n\nState and Seeding\n\nThe `PCG64DXSM` state vector consists of 2 unsigned 128-bit values, which are\nrepresented externally as Python ints. One is the state of the PRNG, which is\nadvanced by a linear congruential generator (LCG). The second is a fixed odd\nincrement used in the LCG.\n\nThe input seed is processed by `SeedSequence` to generate both values. The\nincrement is not independently settable.\n\nParallel Features\n\nThe preferred way to use a BitGenerator in parallel applications is to use the\n`SeedSequence.spawn` method to obtain entropy values, and to use these to\ngenerate new BitGenerators:\n\nCompatibility Guarantee\n\n`PCG64DXSM` makes a guarantee that a fixed seed will always produce the same\nrandom integer stream.\n\n\u201cPCG, A Family of Better Random Number Generators\u201d\n\nO\u2019Neill, Melissa E. \u201cPCG: A Family of Simple Fast Space-Efficient\nStatistically Good Algorithms for Random Number Generation\u201d\n\n`state`\n\nGet or set the PRNG state\n\n`advance`(delta)\n\nAdvance the underlying RNG as-if delta draws have occurred.\n\n`jumped`([jumps])\n\nReturns a new bit generator with the state jumped.\n\n`cffi`\n\nCFFI interface\n\n`ctypes`\n\nctypes interface\n\n"}, {"name": "numpy.random.Philox()", "path": "reference/random/bit_generators/philox", "type": "Philox", "text": "\nContainer for the Philox (4x64) pseudo-random number generator.\n\nA seed to initialize the `BitGenerator`. If None, then fresh, unpredictable\nentropy will be pulled from the OS. If an `int` or `array_like[ints]` is\npassed, then it will be passed to `SeedSequence` to derive the initial\n`BitGenerator` state. One may also pass in a `SeedSequence` instance.\n\nCounter to use in the Philox state. Can be either a Python int (long in 2.x)\nin [0, 2**256) or a 4-element uint64 array. If not provided, the RNG is\ninitialized at 0.\n\nKey to use in the Philox state. Unlike `seed`, the value in key is directly\nset. Can be either a Python int in [0, 2**128) or a 2-element uint64 array.\n`key` and `seed` cannot both be used.\n\nPhilox is a 64-bit PRNG that uses a counter-based design based on weaker (and\nfaster) versions of cryptographic functions [1]. Instances using different\nvalues of the key produce independent sequences. Philox has a period of\n\\\\(2^{256} - 1\\\\) and supports arbitrary advancing and jumping the sequence in\nincrements of \\\\(2^{128}\\\\). These features allow multiple non-overlapping\nsequences to be generated.\n\n`Philox` provides a capsule containing function pointers that produce doubles,\nand unsigned 32 and 64- bit integers. These are not directly consumable in\nPython and must be consumed by a `Generator` or similar object that supports\nlow-level access.\n\nState and Seeding\n\nThe `Philox` state vector consists of a 256-bit value encoded as a 4-element\nuint64 array and a 128-bit value encoded as a 2-element uint64 array. The\nformer is a counter which is incremented by 1 for every 4 64-bit randoms\nproduced. The second is a key which determined the sequence produced. Using\ndifferent keys produces independent sequences.\n\nThe input `seed` is processed by `SeedSequence` to generate the key. The\ncounter is set to 0.\n\nAlternately, one can omit the `seed` parameter and set the `key` and `counter`\ndirectly.\n\nParallel Features\n\nThe preferred way to use a BitGenerator in parallel applications is to use the\n`SeedSequence.spawn` method to obtain entropy values, and to use these to\ngenerate new BitGenerators:\n\n`Philox` can be used in parallel applications by calling the `jumped` method\nto advances the state as-if \\\\(2^{128}\\\\) random numbers have been generated.\nAlternatively, `advance` can be used to advance the counter for any positive\nstep in [0, 2**256). When using `jumped`, all generators should be chained to\nensure that the segments come from the same sequence.\n\nAlternatively, `Philox` can be used in parallel applications by using a\nsequence of distinct keys where each instance uses different key.\n\nCompatibility Guarantee\n\n`Philox` makes a guarantee that a fixed `seed` will always produce the same\nrandom integer stream.\n\nJohn K. Salmon, Mark A. Moraes, Ron O. Dror, and David E. Shaw, \u201cParallel\nRandom Numbers: As Easy as 1, 2, 3,\u201d Proceedings of the International\nConference for High Performance Computing, Networking, Storage and Analysis\n(SC11), New York, NY: ACM, 2011.\n\nLock instance that is shared so that the same bit git generator can be used in\nmultiple Generators without corrupting the state. Code that generates values\nfrom a bit generator should hold the bit generator\u2019s lock.\n\n`state`\n\nGet or set the PRNG state\n\n`advance`(delta)\n\nAdvance the underlying RNG as-if delta draws have occurred.\n\n`jumped`([jumps])\n\nReturns a new bit generator with the state jumped\n\n`cffi`\n\nCFFI interface\n\n`ctypes`\n\nctypes interface\n\n"}, {"name": "numpy.random.RandomState()", "path": "reference/random/legacy", "type": "Legacy Generator (RandomState)", "text": "\nThe `RandomState` provides access to legacy generators. This generator is\nconsidered frozen and will have no further improvements. It is guaranteed to\nproduce the same values as the final point release of NumPy v1.16. These all\ndepend on Box-Muller normals or inverse CDF exponentials or gammas. This class\nshould only be used if it is essential to have randoms that are identical to\nwhat would have been produced by previous versions of NumPy.\n\n`RandomState` adds additional information to the state which is required when\nusing Box-Muller normals since these are produced in pairs. It is important to\nuse `RandomState.get_state`, and not the underlying bit generators `state`,\nwhen accessing the state so that these extra values are saved.\n\nAlthough we provide the `MT19937` BitGenerator for use independent of\n`RandomState`, note that its default seeding uses `SeedSequence` rather than\nthe legacy seeding algorithm. `RandomState` will use the legacy seeding\nalgorithm. The methods to use the legacy seeding algorithm are currently\nprivate as the main reason to use them is just to implement `RandomState`.\nHowever, one can reset the state of `MT19937` using the state of the\n`RandomState`:\n\nContainer for the slow Mersenne Twister pseudo-random number generator.\nConsider using a different BitGenerator with the Generator container instead.\n\n`RandomState` and `Generator` expose a number of methods for generating random\nnumbers drawn from a variety of probability distributions. In addition to the\ndistribution-specific arguments, each method takes a keyword argument `size`\nthat defaults to `None`. If `size` is `None`, then a single value is generated\nand returned. If `size` is an integer, then a 1-D array filled with generated\nvalues is returned. If `size` is a tuple, then an array with that shape is\nfilled and returned.\n\nCompatibility Guarantee\n\nA fixed bit generator using a fixed seed and a fixed series of calls to\n\u2018RandomState\u2019 methods using the same parameters will always produce the same\nresults up to roundoff error except when the values were incorrect.\n`RandomState` is effectively frozen and will only receive updates that are\nrequired by changes in the the internals of Numpy. More substantial changes,\nincluding algorithmic improvements, are reserved for `Generator`.\n\nRandom seed used to initialize the pseudo-random number generator or an\ninstantized BitGenerator. If an integer or array, used as a seed for the\nMT19937 BitGenerator. Values can be any integer between 0 and 2**32 - 1\ninclusive, an array (or other sequence) of such integers, or `None` (the\ndefault). If `seed` is `None`, then the `MT19937` BitGenerator is initialized\nby reading data from `/dev/urandom` (or the Windows analogue) if available or\nseed from the clock otherwise.\n\nSee also\n\nThe Python stdlib module \u201crandom\u201d also contains a Mersenne Twister pseudo-\nrandom number generator with a number of methods that are similar to the ones\navailable in `RandomState`. `RandomState`, besides being NumPy-aware, has the\nadvantage that it provides a much larger number of probability distributions\nto choose from.\n\n`get_state`()\n\nReturn a tuple representing the internal state of the generator.\n\n`set_state`(state)\n\nSet the internal state of the generator from a tuple.\n\n`seed`(self[, seed])\n\nReseed a legacy MT19937 BitGenerator\n\n`rand`(d0, d1, ..., dn)\n\nRandom values in a given shape.\n\n`randn`(d0, d1, ..., dn)\n\nReturn a sample (or samples) from the \"standard normal\" distribution.\n\n`randint`(low[, high, size, dtype])\n\nReturn random integers from `low` (inclusive) to `high` (exclusive).\n\n`random_integers`(low[, high, size])\n\nRandom integers of type `np.int_` between `low` and `high`, inclusive.\n\n`random_sample`([size])\n\nReturn random floats in the half-open interval [0.0, 1.0).\n\n`choice`(a[, size, replace, p])\n\nGenerates a random sample from a given 1-D array\n\n`bytes`(length)\n\nReturn random bytes.\n\n`shuffle`(x)\n\nModify a sequence in-place by shuffling its contents.\n\n`permutation`(x)\n\nRandomly permute a sequence, or return a permuted range.\n\n`beta`(a, b[, size])\n\nDraw samples from a Beta distribution.\n\n`binomial`(n, p[, size])\n\nDraw samples from a binomial distribution.\n\n`chisquare`(df[, size])\n\nDraw samples from a chi-square distribution.\n\n`dirichlet`(alpha[, size])\n\nDraw samples from the Dirichlet distribution.\n\n`exponential`([scale, size])\n\nDraw samples from an exponential distribution.\n\n`f`(dfnum, dfden[, size])\n\nDraw samples from an F distribution.\n\n`gamma`(shape[, scale, size])\n\nDraw samples from a Gamma distribution.\n\n`geometric`(p[, size])\n\nDraw samples from the geometric distribution.\n\n`gumbel`([loc, scale, size])\n\nDraw samples from a Gumbel distribution.\n\n`hypergeometric`(ngood, nbad, nsample[, size])\n\nDraw samples from a Hypergeometric distribution.\n\n`laplace`([loc, scale, size])\n\nDraw samples from the Laplace or double exponential distribution with\nspecified location (or mean) and scale (decay).\n\n`logistic`([loc, scale, size])\n\nDraw samples from a logistic distribution.\n\n`lognormal`([mean, sigma, size])\n\nDraw samples from a log-normal distribution.\n\n`logseries`(p[, size])\n\nDraw samples from a logarithmic series distribution.\n\n`multinomial`(n, pvals[, size])\n\nDraw samples from a multinomial distribution.\n\n`multivariate_normal`(mean, cov[, size, ...])\n\nDraw random samples from a multivariate normal distribution.\n\n`negative_binomial`(n, p[, size])\n\nDraw samples from a negative binomial distribution.\n\n`noncentral_chisquare`(df, nonc[, size])\n\nDraw samples from a noncentral chi-square distribution.\n\n`noncentral_f`(dfnum, dfden, nonc[, size])\n\nDraw samples from the noncentral F distribution.\n\n`normal`([loc, scale, size])\n\nDraw random samples from a normal (Gaussian) distribution.\n\n`pareto`(a[, size])\n\nDraw samples from a Pareto II or Lomax distribution with specified shape.\n\n`poisson`([lam, size])\n\nDraw samples from a Poisson distribution.\n\n`power`(a[, size])\n\nDraws samples in [0, 1] from a power distribution with positive exponent a -\n1.\n\n`rayleigh`([scale, size])\n\nDraw samples from a Rayleigh distribution.\n\n`standard_cauchy`([size])\n\nDraw samples from a standard Cauchy distribution with mode = 0.\n\n`standard_exponential`([size])\n\nDraw samples from the standard exponential distribution.\n\n`standard_gamma`(shape[, size])\n\nDraw samples from a standard Gamma distribution.\n\n`standard_normal`([size])\n\nDraw samples from a standard Normal distribution (mean=0, stdev=1).\n\n`standard_t`(df[, size])\n\nDraw samples from a standard Student's t distribution with `df` degrees of\nfreedom.\n\n`triangular`(left, mode, right[, size])\n\nDraw samples from the triangular distribution over the interval `[left,\nright]`.\n\n`uniform`([low, high, size])\n\nDraw samples from a uniform distribution.\n\n`vonmises`(mu, kappa[, size])\n\nDraw samples from a von Mises distribution.\n\n`wald`(mean, scale[, size])\n\nDraw samples from a Wald, or inverse Gaussian, distribution.\n\n`weibull`(a[, size])\n\nDraw samples from a Weibull distribution.\n\n`zipf`(a[, size])\n\nDraw samples from a Zipf distribution.\n\nMany of the RandomState methods above are exported as functions in\n`numpy.random` This usage is discouraged, as it is implemented via a global\n`RandomState` instance which is not advised on two counts:\n\nFor backward compatible legacy reasons, we cannot change this. See Quick\nStart.\n\n`beta`(a, b[, size])\n\nDraw samples from a Beta distribution.\n\n`binomial`(n, p[, size])\n\nDraw samples from a binomial distribution.\n\n`bytes`(length)\n\nReturn random bytes.\n\n`chisquare`(df[, size])\n\nDraw samples from a chi-square distribution.\n\n`choice`(a[, size, replace, p])\n\nGenerates a random sample from a given 1-D array\n\n`dirichlet`(alpha[, size])\n\nDraw samples from the Dirichlet distribution.\n\n`exponential`([scale, size])\n\nDraw samples from an exponential distribution.\n\n`f`(dfnum, dfden[, size])\n\nDraw samples from an F distribution.\n\n`gamma`(shape[, scale, size])\n\nDraw samples from a Gamma distribution.\n\n`geometric`(p[, size])\n\nDraw samples from the geometric distribution.\n\n`get_state`()\n\nReturn a tuple representing the internal state of the generator.\n\n`gumbel`([loc, scale, size])\n\nDraw samples from a Gumbel distribution.\n\n`hypergeometric`(ngood, nbad, nsample[, size])\n\nDraw samples from a Hypergeometric distribution.\n\n`laplace`([loc, scale, size])\n\nDraw samples from the Laplace or double exponential distribution with\nspecified location (or mean) and scale (decay).\n\n`logistic`([loc, scale, size])\n\nDraw samples from a logistic distribution.\n\n`lognormal`([mean, sigma, size])\n\nDraw samples from a log-normal distribution.\n\n`logseries`(p[, size])\n\nDraw samples from a logarithmic series distribution.\n\n`multinomial`(n, pvals[, size])\n\nDraw samples from a multinomial distribution.\n\n`multivariate_normal`(mean, cov[, size, ...])\n\nDraw random samples from a multivariate normal distribution.\n\n`negative_binomial`(n, p[, size])\n\nDraw samples from a negative binomial distribution.\n\n`noncentral_chisquare`(df, nonc[, size])\n\nDraw samples from a noncentral chi-square distribution.\n\n`noncentral_f`(dfnum, dfden, nonc[, size])\n\nDraw samples from the noncentral F distribution.\n\n`normal`([loc, scale, size])\n\nDraw random samples from a normal (Gaussian) distribution.\n\n`pareto`(a[, size])\n\nDraw samples from a Pareto II or Lomax distribution with specified shape.\n\n`permutation`(x)\n\nRandomly permute a sequence, or return a permuted range.\n\n`poisson`([lam, size])\n\nDraw samples from a Poisson distribution.\n\n`power`(a[, size])\n\nDraws samples in [0, 1] from a power distribution with positive exponent a -\n1.\n\n`rand`(d0, d1, ..., dn)\n\nRandom values in a given shape.\n\n`randint`(low[, high, size, dtype])\n\nReturn random integers from `low` (inclusive) to `high` (exclusive).\n\n`randn`(d0, d1, ..., dn)\n\nReturn a sample (or samples) from the \"standard normal\" distribution.\n\n`random`([size])\n\nReturn random floats in the half-open interval [0.0, 1.0).\n\n`random_integers`(low[, high, size])\n\nRandom integers of type `np.int_` between `low` and `high`, inclusive.\n\n`random_sample`([size])\n\nReturn random floats in the half-open interval [0.0, 1.0).\n\n`ranf`\n\nThis is an alias of `random_sample`.\n\n`rayleigh`([scale, size])\n\nDraw samples from a Rayleigh distribution.\n\n`sample`\n\nThis is an alias of `random_sample`.\n\n`seed`(self[, seed])\n\nReseed a legacy MT19937 BitGenerator\n\n`set_state`(state)\n\nSet the internal state of the generator from a tuple.\n\n`shuffle`(x)\n\nModify a sequence in-place by shuffling its contents.\n\n`standard_cauchy`([size])\n\nDraw samples from a standard Cauchy distribution with mode = 0.\n\n`standard_exponential`([size])\n\nDraw samples from the standard exponential distribution.\n\n`standard_gamma`(shape[, size])\n\nDraw samples from a standard Gamma distribution.\n\n`standard_normal`([size])\n\nDraw samples from a standard Normal distribution (mean=0, stdev=1).\n\n`standard_t`(df[, size])\n\nDraw samples from a standard Student's t distribution with `df` degrees of\nfreedom.\n\n`triangular`(left, mode, right[, size])\n\nDraw samples from the triangular distribution over the interval `[left,\nright]`.\n\n`uniform`([low, high, size])\n\nDraw samples from a uniform distribution.\n\n`vonmises`(mu, kappa[, size])\n\nDraw samples from a von Mises distribution.\n\n`wald`(mean, scale[, size])\n\nDraw samples from a Wald, or inverse Gaussian, distribution.\n\n`weibull`(a[, size])\n\nDraw samples from a Weibull distribution.\n\n`zipf`(a[, size])\n\nDraw samples from a Zipf distribution.\n\n"}, {"name": "numpy.random.SeedSequence()", "path": "reference/random/bit_generators/generated/numpy.random.seedsequence", "type": "Random sampling ( \n      \n       numpy.random\n      \n      )", "text": "\nSeedSequence mixes sources of entropy in a reproducible way to set the initial\nstate for independent and very probably non-overlapping BitGenerators.\n\nOnce the SeedSequence is instantiated, you can call the `generate_state`\nmethod to get an appropriately sized seed. Calling `spawn(n)` will create `n`\nSeedSequences that can be used to seed independent BitGenerators, i.e. for\ndifferent threads.\n\nThe entropy for creating a `SeedSequence`.\n\nA third source of entropy, used internally when calling `SeedSequence.spawn`\n\nSize of the pooled entropy to store. Default is 4 to give a 128-bit entropy\npool. 8 (for 256 bits) is another reasonable choice if working with larger\nPRNGs, but there is very little to be gained by selecting another value.\n\nThe number of children already spawned. Only pass this if reconstructing a\n`SeedSequence` from a serialized form.\n\nBest practice for achieving reproducible bit streams is to use the default\n`None` for the initial entropy, and then use `SeedSequence.entropy` to\nlog/pickle the `entropy` for reproducibility:\n\n`generate_state`(n_words[, dtype])\n\nReturn the requested number of words for PRNG seeding.\n\n`spawn`(n_children)\n\nSpawn a number of child `SeedSequence` s by extending the `spawn_key`.\n\n"}, {"name": "numpy.random.SFC64()", "path": "reference/random/bit_generators/sfc64", "type": "SFC64", "text": "\nBitGenerator for Chris Doty-Humphrey\u2019s Small Fast Chaotic PRNG.\n\nA seed to initialize the `BitGenerator`. If None, then fresh, unpredictable\nentropy will be pulled from the OS. If an `int` or `array_like[ints]` is\npassed, then it will be passed to `SeedSequence` to derive the initial\n`BitGenerator` state. One may also pass in a `SeedSequence` instance.\n\n`SFC64` is a 256-bit implementation of Chris Doty-Humphrey\u2019s Small Fast\nChaotic PRNG ([1]). `SFC64` has a few different cycles that one might be on,\ndepending on the seed; the expected period will be about \\\\(2^{255}\\\\) ([2]).\n`SFC64` incorporates a 64-bit counter which means that the absolute minimum\ncycle length is \\\\(2^{64}\\\\) and that distinct seeds will not run into each\nother for at least \\\\(2^{64}\\\\) iterations.\n\n`SFC64` provides a capsule containing function pointers that produce doubles,\nand unsigned 32 and 64- bit integers. These are not directly consumable in\nPython and must be consumed by a `Generator` or similar object that supports\nlow-level access.\n\nState and Seeding\n\nThe `SFC64` state vector consists of 4 unsigned 64-bit values. The last is a\n64-bit counter that increments by 1 each iteration.\n\nThe input seed is processed by `SeedSequence` to generate the first 3 values,\nthen the `SFC64` algorithm is iterated a small number of times to mix.\n\nCompatibility Guarantee\n\n`SFC64` makes a guarantee that a fixed seed will always produce the same\nrandom integer stream.\n\n\u201cPractRand\u201d\n\n\u201cRandom Invertible Mapping Statistics\u201d\n\n`state`\n\nGet or set the PRNG state\n\n`cffi`\n\nCFFI interface\n\n`ctypes`\n\nctypes interface\n\n"}, {"name": "numpy.RankWarning", "path": "reference/generated/numpy.rankwarning", "type": "numpy.RankWarning", "text": "\nIssued by `polyfit` when the Vandermonde matrix is rank deficient.\n\nFor more information, a way to suppress the warning, and an example of\n`RankWarning` being issued, see `polyfit`.\n\n"}, {"name": "numpy.ravel()", "path": "reference/generated/numpy.ravel", "type": "numpy.ravel", "text": "\nReturn a contiguous flattened array.\n\nA 1-D array, containing the elements of the input, is returned. A copy is made\nonly if needed.\n\nAs of NumPy 1.10, the returned array will have the same type as the input\narray. (for example, a masked array will be returned for a masked array input)\n\nInput array. The elements in `a` are read in the order specified by `order`,\nand packed as a 1-D array.\n\nThe elements of `a` are read using this index order. \u2018C\u2019 means to index the\nelements in row-major, C-style order, with the last axis index changing\nfastest, back to the first axis index changing slowest. \u2018F\u2019 means to index the\nelements in column-major, Fortran-style order, with the first index changing\nfastest, and the last index changing slowest. Note that the \u2018C\u2019 and \u2018F\u2019\noptions take no account of the memory layout of the underlying array, and only\nrefer to the order of axis indexing. \u2018A\u2019 means to read the elements in\nFortran-like index order if `a` is Fortran contiguous in memory, C-like order\notherwise. \u2018K\u2019 means to read the elements in the order they occur in memory,\nexcept for reversing the data when strides are negative. By default, \u2018C\u2019 index\norder is used.\n\ny is an array of the same subtype as `a`, with shape `(a.size,)`. Note that\nmatrices are special cased for backward compatibility, if `a` is a matrix,\nthen y is a 1-D ndarray.\n\nSee also\n\n1-D iterator over an array.\n\n1-D array copy of the elements of an array in row-major order.\n\nChange the shape of an array without changing its data.\n\nIn row-major, C-style order, in two dimensions, the row index varies the\nslowest, and the column index the quickest. This can be generalized to\nmultiple dimensions, where row-major order implies that the index along the\nfirst axis varies slowest, and the index along the last quickest. The opposite\nholds for column-major, Fortran-style index ordering.\n\nWhen a view is desired in as many cases as possible, `arr.reshape(-1)` may be\npreferable.\n\nIt is equivalent to `reshape(-1, order=order)`.\n\nWhen `order` is \u2018A\u2019, it will preserve the array\u2019s \u2018C\u2019 or \u2018F\u2019 ordering:\n\nWhen `order` is \u2018K\u2019, it will preserve orderings that are neither \u2018C\u2019 nor \u2018F\u2019,\nbut won\u2019t reverse axes:\n\n"}, {"name": "numpy.ravel_multi_index()", "path": "reference/generated/numpy.ravel_multi_index", "type": "numpy.ravel_multi_index", "text": "\nConverts a tuple of index arrays into an array of flat indices, applying\nboundary modes to the multi-index.\n\nA tuple of integer arrays, one array for each dimension.\n\nThe shape of array into which the indices from `multi_index` apply.\n\nSpecifies how out-of-bounds indices are handled. Can specify either one mode\nor a tuple of modes, one mode per index.\n\nIn \u2018clip\u2019 mode, a negative index which would normally wrap will clip to 0\ninstead.\n\nDetermines whether the multi-index should be viewed as indexing in row-major\n(C-style) or column-major (Fortran-style) order.\n\nAn array of indices into the flattened version of an array of dimensions\n`dims`.\n\nSee also\n\nNew in version 1.6.0.\n\n"}, {"name": "numpy.real()", "path": "reference/generated/numpy.real", "type": "numpy.real", "text": "\nReturn the real part of the complex argument.\n\nInput array.\n\nThe real component of the complex argument. If `val` is real, the type of\n`val` is used for the output. If `val` has complex elements, the returned type\nis float.\n\nSee also\n\n"}, {"name": "numpy.real_if_close()", "path": "reference/generated/numpy.real_if_close", "type": "numpy.real_if_close", "text": "\nIf input is complex with all imaginary parts close to zero, return real parts.\n\n\u201cClose to zero\u201d is defined as `tol` * (machine epsilon of the type for `a`).\n\nInput array.\n\nTolerance in machine epsilons for the complex part of the elements in the\narray.\n\nIf `a` is real, the type of `a` is used for the output. If `a` has complex\nelements, the returned type is float.\n\nSee also\n\nMachine epsilon varies from machine to machine and between data types but\nPython floats on most platforms have a machine epsilon equal to\n2.2204460492503131e-16. You can use \u2018np.finfo(float).eps\u2019 to print out the\nmachine epsilon for floats.\n\n"}, {"name": "numpy.recarray()", "path": "reference/generated/numpy.recarray", "type": "numpy.recarray", "text": "\nConstruct an ndarray that allows field access using attributes.\n\nArrays may have a data-types containing fields, analogous to columns in a\nspread sheet. An example is `[(x, int), (y, float)]`, where each entry in the\narray is a pair of `(int, float)`. Normally, these attributes are accessed\nusing dictionary lookups such as `arr['x']` and `arr['y']`. Record arrays\nallow the fields to be accessed as members of the array, using `arr.x` and\n`arr.y`.\n\nShape of output array.\n\nThe desired data-type. By default, the data-type is determined from `formats`,\n`names`, `titles`, `aligned` and `byteorder`.\n\nA list containing the data-types for the different columns, e.g. `['i4', 'f8',\n'i4']`. `formats` does not support the new convention of using types directly,\ni.e. `(int, float, int)`. Note that `formats` must be a list, not a tuple.\nGiven that `formats` is somewhat limited, we recommend specifying `dtype`\ninstead.\n\nThe name of each column, e.g. `('x', 'y', 'z')`.\n\nBy default, a new array is created of the given shape and data-type. If `buf`\nis specified and is an object exposing the buffer interface, the array will\nuse the memory from the existing buffer. In this case, the `offset` and\n`strides` keywords are available.\n\nEmpty array of the given shape and type.\n\nAliases for column names. For example, if `names` were `('x', 'y', 'z')` and\n`titles` is `('x_coordinate', 'y_coordinate', 'z_coordinate')`, then\n`arr['x']` is equivalent to both `arr.x` and `arr.x_coordinate`.\n\nByte-order for all fields.\n\nAlign the fields in memory as the C-compiler would.\n\nBuffer (`buf`) is interpreted according to these strides (strides define how\nmany bytes each array element, row, column, etc. occupy in memory).\n\nStart reading buffer (`buf`) from this offset onwards.\n\nRow-major (C-style) or column-major (Fortran-style) order.\n\nSee also\n\nConstruct a record array from data.\n\nfundamental data-type for `recarray`.\n\ndetermine a data-type from formats, names, titles.\n\nThis constructor can be compared to `empty`: it creates a new record array but\ndoes not fill it with data. To create a record array from data, use one of the\nfollowing methods:\n\nCreate an array with two fields, `x` and `y`:\n\nView the array as a record array:\n\nCreate a new, empty record array:\n\nThe transposed array.\n\nBase object if memory is from some other object.\n\nAn object to simplify the interaction of the array with the ctypes module.\n\nPython buffer object pointing to the start of the array\u2019s data.\n\nData-type of the array\u2019s elements.\n\nInformation about the memory layout of the array.\n\nA 1-D iterator over the array.\n\nThe imaginary part of the array.\n\nLength of one array element in bytes.\n\nTotal bytes consumed by the elements of the array.\n\nNumber of array dimensions.\n\nThe real part of the array.\n\nTuple of array dimensions.\n\nNumber of elements in the array.\n\nTuple of bytes to step in each dimension when traversing an array.\n\n`all`([axis, out, keepdims, where])\n\nReturns True if all elements evaluate to True.\n\n`any`([axis, out, keepdims, where])\n\nReturns True if any of the elements of `a` evaluate to True.\n\n`argmax`([axis, out])\n\nReturn indices of the maximum values along the given axis.\n\n`argmin`([axis, out])\n\nReturn indices of the minimum values along the given axis.\n\n`argpartition`(kth[, axis, kind, order])\n\nReturns the indices that would partition this array.\n\n`argsort`([axis, kind, order])\n\nReturns the indices that would sort this array.\n\n`astype`(dtype[, order, casting, subok, copy])\n\nCopy of the array, cast to a specified type.\n\n`byteswap`([inplace])\n\nSwap the bytes of the array elements\n\n`choose`(choices[, out, mode])\n\nUse an index array to construct a new array from a set of choices.\n\n`clip`([min, max, out])\n\nReturn an array whose values are limited to `[min, max]`.\n\n`compress`(condition[, axis, out])\n\nReturn selected slices of this array along given axis.\n\n`conj`()\n\nComplex-conjugate all elements.\n\n`conjugate`()\n\nReturn the complex conjugate, element-wise.\n\n`copy`([order])\n\nReturn a copy of the array.\n\n`cumprod`([axis, dtype, out])\n\nReturn the cumulative product of the elements along the given axis.\n\n`cumsum`([axis, dtype, out])\n\nReturn the cumulative sum of the elements along the given axis.\n\n`diagonal`([offset, axis1, axis2])\n\nReturn specified diagonals.\n\n`dump`(file)\n\nDump a pickle of the array to the specified file.\n\n`dumps`()\n\nReturns the pickle of the array as a string.\n\n`fill`(value)\n\nFill the array with a scalar value.\n\n`flatten`([order])\n\nReturn a copy of the array collapsed into one dimension.\n\n`getfield`(dtype[, offset])\n\nReturns a field of the given array as a certain type.\n\n`item`(*args)\n\nCopy an element of an array to a standard Python scalar and return it.\n\n`itemset`(*args)\n\nInsert scalar into an array (scalar is cast to array's dtype, if possible)\n\n`max`([axis, out, keepdims, initial, where])\n\nReturn the maximum along a given axis.\n\n`mean`([axis, dtype, out, keepdims, where])\n\nReturns the average of the array elements along given axis.\n\n`min`([axis, out, keepdims, initial, where])\n\nReturn the minimum along a given axis.\n\n`newbyteorder`([new_order])\n\nReturn the array with the same data viewed with a different byte order.\n\n`nonzero`()\n\nReturn the indices of the elements that are non-zero.\n\n`partition`(kth[, axis, kind, order])\n\nRearranges the elements in the array in such a way that the value of the\nelement in kth position is in the position it would be in a sorted array.\n\n`prod`([axis, dtype, out, keepdims, initial, ...])\n\nReturn the product of the array elements over the given axis\n\n`ptp`([axis, out, keepdims])\n\nPeak to peak (maximum - minimum) value along a given axis.\n\n`put`(indices, values[, mode])\n\nSet `a.flat[n] = values[n]` for all `n` in indices.\n\n`ravel`([order])\n\nReturn a flattened array.\n\n`repeat`(repeats[, axis])\n\nRepeat elements of an array.\n\n`reshape`(shape[, order])\n\nReturns an array containing the same data with a new shape.\n\n`resize`(new_shape[, refcheck])\n\nChange shape and size of array in-place.\n\n`round`([decimals, out])\n\nReturn `a` with each element rounded to the given number of decimals.\n\n`searchsorted`(v[, side, sorter])\n\nFind indices where elements of v should be inserted in a to maintain order.\n\n`setfield`(val, dtype[, offset])\n\nPut a value into a specified place in a field defined by a data-type.\n\n`setflags`([write, align, uic])\n\nSet array flags WRITEABLE, ALIGNED, (WRITEBACKIFCOPY and UPDATEIFCOPY),\nrespectively.\n\n`sort`([axis, kind, order])\n\nSort an array in-place.\n\n`squeeze`([axis])\n\nRemove axes of length one from `a`.\n\n`std`([axis, dtype, out, ddof, keepdims, where])\n\nReturns the standard deviation of the array elements along given axis.\n\n`sum`([axis, dtype, out, keepdims, initial, where])\n\nReturn the sum of the array elements over the given axis.\n\n`swapaxes`(axis1, axis2)\n\nReturn a view of the array with `axis1` and `axis2` interchanged.\n\n`take`(indices[, axis, out, mode])\n\nReturn an array formed from the elements of `a` at the given indices.\n\n`tobytes`([order])\n\nConstruct Python bytes containing the raw data bytes in the array.\n\n`tofile`(fid[, sep, format])\n\nWrite array to a file as text or binary (default).\n\n`tolist`()\n\nReturn the array as an `a.ndim`-levels deep nested list of Python scalars.\n\n`tostring`([order])\n\nA compatibility alias for `tobytes`, with exactly the same behavior.\n\n`trace`([offset, axis1, axis2, dtype, out])\n\nReturn the sum along diagonals of the array.\n\n`transpose`(*axes)\n\nReturns a view of the array with axes transposed.\n\n`var`([axis, dtype, out, ddof, keepdims, where])\n\nReturns the variance of the array elements, along given axis.\n\n`view`([dtype][, type])\n\nNew view of array with the same data.\n\ndot\n\nfield\n\n"}, {"name": "numpy.reciprocal()", "path": "reference/generated/numpy.reciprocal", "type": "numpy.reciprocal", "text": "\nReturn the reciprocal of the argument, element-wise.\n\nCalculates `1/x`.\n\nInput array.\n\nA location into which the result is stored. If provided, it must have a shape\nthat the inputs broadcast to. If not provided or None, a freshly-allocated\narray is returned. A tuple (possible only as a keyword argument) must have\nlength equal to the number of outputs.\n\nThis condition is broadcast over the input. At locations where the condition\nis True, the `out` array will be set to the ufunc result. Elsewhere, the `out`\narray will retain its original value. Note that if an uninitialized `out`\narray is created via the default `out=None`, locations within it where the\ncondition is False will remain uninitialized.\n\nFor other keyword-only arguments, see the ufunc docs.\n\nReturn array. This is a scalar if `x` is a scalar.\n\nNote\n\nThis function is not designed to work with integers.\n\nFor integer arguments with absolute value larger than 1 the result is always\nzero because of the way Python handles integer division. For integer zero the\nresult is an overflow.\n\n"}, {"name": "numpy.record", "path": "reference/generated/numpy.record", "type": "numpy.record", "text": "\nA data-type scalar that allows field access as attribute lookup.\n\nScalar attribute identical to the corresponding array attribute.\n\nbase object\n\nPointer to start of data.\n\ndtype object\n\ninteger value of flags\n\nA 1-D view of the scalar.\n\nThe imaginary part of the scalar.\n\nThe length of one element in bytes.\n\nThe length of the scalar in bytes.\n\nThe number of array dimensions.\n\nThe real part of the scalar.\n\nTuple of array dimensions.\n\nThe number of elements in the gentype.\n\nTuple of bytes steps in each dimension.\n\n`all`\n\nScalar method identical to the corresponding array attribute.\n\n`any`\n\nScalar method identical to the corresponding array attribute.\n\n`argmax`\n\nScalar method identical to the corresponding array attribute.\n\n`argmin`\n\nScalar method identical to the corresponding array attribute.\n\n`argsort`\n\nScalar method identical to the corresponding array attribute.\n\n`astype`\n\nScalar method identical to the corresponding array attribute.\n\n`byteswap`\n\nScalar method identical to the corresponding array attribute.\n\n`choose`\n\nScalar method identical to the corresponding array attribute.\n\n`clip`\n\nScalar method identical to the corresponding array attribute.\n\n`compress`\n\nScalar method identical to the corresponding array attribute.\n\n`conjugate`\n\nScalar method identical to the corresponding array attribute.\n\n`copy`\n\nScalar method identical to the corresponding array attribute.\n\n`cumprod`\n\nScalar method identical to the corresponding array attribute.\n\n`cumsum`\n\nScalar method identical to the corresponding array attribute.\n\n`diagonal`\n\nScalar method identical to the corresponding array attribute.\n\n`dump`\n\nScalar method identical to the corresponding array attribute.\n\n`dumps`\n\nScalar method identical to the corresponding array attribute.\n\n`fill`\n\nScalar method identical to the corresponding array attribute.\n\n`flatten`\n\nScalar method identical to the corresponding array attribute.\n\n`getfield`\n\nScalar method identical to the corresponding array attribute.\n\n`item`\n\nScalar method identical to the corresponding array attribute.\n\n`itemset`\n\nScalar method identical to the corresponding array attribute.\n\n`max`\n\nScalar method identical to the corresponding array attribute.\n\n`mean`\n\nScalar method identical to the corresponding array attribute.\n\n`min`\n\nScalar method identical to the corresponding array attribute.\n\n`newbyteorder`([new_order])\n\nReturn a new `dtype` with a different byte order.\n\n`nonzero`\n\nScalar method identical to the corresponding array attribute.\n\n`pprint`()\n\nPretty-print all fields.\n\n`prod`\n\nScalar method identical to the corresponding array attribute.\n\n`ptp`\n\nScalar method identical to the corresponding array attribute.\n\n`put`\n\nScalar method identical to the corresponding array attribute.\n\n`ravel`\n\nScalar method identical to the corresponding array attribute.\n\n`repeat`\n\nScalar method identical to the corresponding array attribute.\n\n`reshape`\n\nScalar method identical to the corresponding array attribute.\n\n`resize`\n\nScalar method identical to the corresponding array attribute.\n\n`round`\n\nScalar method identical to the corresponding array attribute.\n\n`searchsorted`\n\nScalar method identical to the corresponding array attribute.\n\n`setfield`\n\nScalar method identical to the corresponding array attribute.\n\n`setflags`\n\nScalar method identical to the corresponding array attribute.\n\n`sort`\n\nScalar method identical to the corresponding array attribute.\n\n`squeeze`\n\nScalar method identical to the corresponding array attribute.\n\n`std`\n\nScalar method identical to the corresponding array attribute.\n\n`sum`\n\nScalar method identical to the corresponding array attribute.\n\n`swapaxes`\n\nScalar method identical to the corresponding array attribute.\n\n`take`\n\nScalar method identical to the corresponding array attribute.\n\n`tofile`\n\nScalar method identical to the corresponding array attribute.\n\n`tolist`\n\nScalar method identical to the corresponding array attribute.\n\n`tostring`\n\nScalar method identical to the corresponding array attribute.\n\n`trace`\n\nScalar method identical to the corresponding array attribute.\n\n`transpose`\n\nScalar method identical to the corresponding array attribute.\n\n`var`\n\nScalar method identical to the corresponding array attribute.\n\n`view`\n\nScalar method identical to the corresponding array attribute.\n\nconj\n\ntobytes\n\n"}, {"name": "numpy.remainder()", "path": "reference/generated/numpy.remainder", "type": "numpy.remainder", "text": "\nReturns the element-wise remainder of division.\n\nComputes the remainder complementary to the `floor_divide` function. It is\nequivalent to the Python modulus operator``x1 % x2`` and has the same sign as\nthe divisor `x2`. The MATLAB function equivalent to `np.remainder` is `mod`.\n\nWarning\n\nThis should not be confused with:\n\nDividend array.\n\nDivisor array. If `x1.shape != x2.shape`, they must be broadcastable to a\ncommon shape (which becomes the shape of the output).\n\nA location into which the result is stored. If provided, it must have a shape\nthat the inputs broadcast to. If not provided or None, a freshly-allocated\narray is returned. A tuple (possible only as a keyword argument) must have\nlength equal to the number of outputs.\n\nThis condition is broadcast over the input. At locations where the condition\nis True, the `out` array will be set to the ufunc result. Elsewhere, the `out`\narray will retain its original value. Note that if an uninitialized `out`\narray is created via the default `out=None`, locations within it where the\ncondition is False will remain uninitialized.\n\nFor other keyword-only arguments, see the ufunc docs.\n\nThe element-wise remainder of the quotient `floor_divide(x1, x2)`. This is a\nscalar if both `x1` and `x2` are scalars.\n\nSee also\n\nEquivalent of Python `//` operator.\n\nSimultaneous floor division and remainder.\n\nEquivalent of the MATLAB `rem` function.\n\nReturns 0 when `x2` is 0 and both `x1` and `x2` are (arrays of) integers.\n`mod` is an alias of `remainder`.\n\nThe `%` operator can be used as a shorthand for `np.remainder` on ndarrays.\n\n"}, {"name": "numpy.repeat()", "path": "reference/generated/numpy.repeat", "type": "numpy.repeat", "text": "\nRepeat elements of an array.\n\nInput array.\n\nThe number of repetitions for each element. `repeats` is broadcasted to fit\nthe shape of the given axis.\n\nThe axis along which to repeat values. By default, use the flattened input\narray, and return a flat output array.\n\nOutput array which has the same shape as `a`, except along the given axis.\n\nSee also\n\nTile an array.\n\nFind the unique elements of an array.\n\n"}, {"name": "numpy.require()", "path": "reference/generated/numpy.require", "type": "numpy.require", "text": "\nReturn an ndarray of the provided type that satisfies requirements.\n\nThis function is useful to be sure that an array with the correct flags is\nreturned for passing to compiled code (perhaps through ctypes).\n\nThe object to be converted to a type-and-requirement-satisfying array.\n\nThe required data-type. If None preserve the current dtype. If your\napplication requires the data to be in native byteorder, include a byteorder\nspecification as a part of the dtype specification.\n\nThe requirements list can be any of the following\n\nReference object to allow the creation of arrays which are not NumPy arrays.\nIf an array-like passed in as `like` supports the `__array_function__`\nprotocol, the result will be defined by it. In this case, it ensures the\ncreation of an array object compatible with that passed in via this argument.\n\nNew in version 1.20.0.\n\nArray with specified requirements and type if given.\n\nSee also\n\nConvert input to an ndarray.\n\nConvert to an ndarray, but pass through ndarray subclasses.\n\nConvert input to a contiguous array.\n\nConvert input to an ndarray with column-major memory order.\n\nInformation about the memory layout of the array.\n\nThe returned array will be guaranteed to have the listed requirements by\nmaking a copy if needed.\n\n"}, {"name": "numpy.reshape()", "path": "reference/generated/numpy.reshape", "type": "numpy.reshape", "text": "\nGives a new shape to an array without changing its data.\n\nArray to be reshaped.\n\nThe new shape should be compatible with the original shape. If an integer,\nthen the result will be a 1-D array of that length. One shape dimension can be\n-1. In this case, the value is inferred from the length of the array and\nremaining dimensions.\n\nRead the elements of `a` using this index order, and place the elements into\nthe reshaped array using this index order. \u2018C\u2019 means to read / write the\nelements using C-like index order, with the last axis index changing fastest,\nback to the first axis index changing slowest. \u2018F\u2019 means to read / write the\nelements using Fortran-like index order, with the first index changing\nfastest, and the last index changing slowest. Note that the \u2018C\u2019 and \u2018F\u2019\noptions take no account of the memory layout of the underlying array, and only\nrefer to the order of indexing. \u2018A\u2019 means to read / write the elements in\nFortran-like index order if `a` is Fortran contiguous in memory, C-like order\notherwise.\n\nThis will be a new view object if possible; otherwise, it will be a copy. Note\nthere is no guarantee of the memory layout (C- or Fortran- contiguous) of the\nreturned array.\n\nSee also\n\nEquivalent method.\n\nIt is not always possible to change the shape of an array without copying the\ndata. If you want an error to be raised when the data is copied, you should\nassign the new shape to the shape attribute of the array:\n\nThe `order` keyword gives the index ordering both for fetching the values from\n`a`, and then placing the values into the output array. For example, let\u2019s say\nyou have an array:\n\nYou can think of reshaping as first raveling the array (using the given index\norder), then inserting the elements from the raveled array into the new array\nusing the same kind of index ordering as was used for the raveling.\n\n"}, {"name": "numpy.resize()", "path": "reference/generated/numpy.resize", "type": "numpy.resize", "text": "\nReturn a new array with the specified shape.\n\nIf the new array is larger than the original array, then the new array is\nfilled with repeated copies of `a`. Note that this behavior is different from\na.resize(new_shape) which fills with zeros instead of repeated copies of `a`.\n\nArray to be resized.\n\nShape of resized array.\n\nThe new array is formed from the data in the old array, repeated if necessary\nto fill out the required number of elements. The data are repeated iterating\nover the array in C-order.\n\nSee also\n\nReshape an array without changing the total size.\n\nEnlarge and pad an array.\n\nRepeat elements of an array.\n\nresize an array in-place.\n\nWhen the total size of the array does not change `reshape` should be used. In\nmost other cases either indexing (to reduce the size) or padding (to increase\nthe size) may be a more appropriate solution.\n\nWarning: This functionality does not consider axes separately, i.e. it does\nnot apply interpolation/extrapolation. It fills the return array with the\nrequired number of elements, iterating over `a` in C-order, disregarding axes\n(and cycling back from the start if the new shape is larger). This\nfunctionality is therefore not suitable to resize images, or data where each\naxis represents a separate and distinct entity.\n\n"}, {"name": "numpy.result_type()", "path": "reference/generated/numpy.result_type", "type": "numpy.result_type", "text": "\nReturns the type that results from applying the NumPy type promotion rules to\nthe arguments.\n\nType promotion in NumPy works similarly to the rules in languages like C++,\nwith some slight differences. When both scalars and arrays are used, the\narray\u2019s type takes precedence and the actual value of the scalar is taken into\naccount.\n\nFor example, calculating 3*a, where a is an array of 32-bit floats,\nintuitively should result in a 32-bit float output. If the 3 is a 32-bit\ninteger, the NumPy rules indicate it can\u2019t convert losslessly into a 32-bit\nfloat, so a 64-bit float should be the result type. By examining the value of\nthe constant, \u20183\u2019, we see that it fits in an 8-bit integer, which can be cast\nlosslessly into the 32-bit float.\n\nThe operands of some operation whose result type is needed.\n\nThe result type.\n\nSee also\n\nNew in version 1.6.0.\n\nThe specific algorithm used is as follows.\n\nCategories are determined by first checking which of boolean, integer\n(int/uint), or floating point (float/complex) the maximum kind of all the\narrays and the scalars are.\n\nIf there are only scalars or the maximum category of the scalars is higher\nthan the maximum category of the arrays, the data types are combined with\n`promote_types` to produce the return value.\n\nOtherwise, `min_scalar_type` is called on each array, and the resulting data\ntypes are all combined with `promote_types` to produce the return value.\n\nThe set of int values is not a subset of the uint values for types with the\nsame number of bits, something not reflected in `min_scalar_type`, but handled\nas a special case in `result_type`.\n\n"}, {"name": "numpy.right_shift()", "path": "reference/generated/numpy.right_shift", "type": "numpy.right_shift", "text": "\nShift the bits of an integer to the right.\n\nBits are shifted to the right `x2`. Because the internal representation of\nnumbers is in binary format, this operation is equivalent to dividing `x1` by\n`2**x2`.\n\nInput values.\n\nNumber of bits to remove at the right of `x1`. If `x1.shape != x2.shape`, they\nmust be broadcastable to a common shape (which becomes the shape of the\noutput).\n\nA location into which the result is stored. If provided, it must have a shape\nthat the inputs broadcast to. If not provided or None, a freshly-allocated\narray is returned. A tuple (possible only as a keyword argument) must have\nlength equal to the number of outputs.\n\nThis condition is broadcast over the input. At locations where the condition\nis True, the `out` array will be set to the ufunc result. Elsewhere, the `out`\narray will retain its original value. Note that if an uninitialized `out`\narray is created via the default `out=None`, locations within it where the\ncondition is False will remain uninitialized.\n\nFor other keyword-only arguments, see the ufunc docs.\n\nReturn `x1` with bits shifted `x2` times to the right. This is a scalar if\nboth `x1` and `x2` are scalars.\n\nSee also\n\nShift the bits of an integer to the left.\n\nReturn the binary representation of the input number as a string.\n\nThe `>>` operator can be used as a shorthand for `np.right_shift` on ndarrays.\n\n"}, {"name": "numpy.rint()", "path": "reference/generated/numpy.rint", "type": "numpy.rint", "text": "\nRound elements of the array to the nearest integer.\n\nInput array.\n\nA location into which the result is stored. If provided, it must have a shape\nthat the inputs broadcast to. If not provided or None, a freshly-allocated\narray is returned. A tuple (possible only as a keyword argument) must have\nlength equal to the number of outputs.\n\nThis condition is broadcast over the input. At locations where the condition\nis True, the `out` array will be set to the ufunc result. Elsewhere, the `out`\narray will retain its original value. Note that if an uninitialized `out`\narray is created via the default `out=None`, locations within it where the\ncondition is False will remain uninitialized.\n\nFor other keyword-only arguments, see the ufunc docs.\n\nOutput array is same shape and type as `x`. This is a scalar if `x` is a\nscalar.\n\nSee also\n\nFor values exactly halfway between rounded decimal values, NumPy rounds to the\nnearest even value. Thus 1.5 and 2.5 round to 2.0, -0.5 and 0.5 round to 0.0,\netc.\n\n"}, {"name": "numpy.roll()", "path": "reference/generated/numpy.roll", "type": "numpy.roll", "text": "\nRoll array elements along a given axis.\n\nElements that roll beyond the last position are re-introduced at the first.\n\nInput array.\n\nThe number of places by which elements are shifted. If a tuple, then `axis`\nmust be a tuple of the same size, and each of the given axes is shifted by the\ncorresponding number. If an int while `axis` is a tuple of ints, then the same\nvalue is used for all given axes.\n\nAxis or axes along which elements are shifted. By default, the array is\nflattened before shifting, after which the original shape is restored.\n\nOutput array, with the same shape as `a`.\n\nSee also\n\nRoll the specified axis backwards, until it lies in a given position.\n\nNew in version 1.12.0.\n\nSupports rolling over multiple dimensions simultaneously.\n\n"}, {"name": "numpy.rollaxis()", "path": "reference/generated/numpy.rollaxis", "type": "numpy.rollaxis", "text": "\nRoll the specified axis backwards, until it lies in a given position.\n\nThis function continues to be supported for backward compatibility, but you\nshould prefer `moveaxis`. The `moveaxis` function was added in NumPy 1.11.\n\nInput array.\n\nThe axis to be rolled. The positions of the other axes do not change relative\nto one another.\n\nWhen `start <= axis`, the axis is rolled back until it lies in this position.\nWhen `start > axis`, the axis is rolled until it lies before this position.\nThe default, 0, results in a \u201ccomplete\u201d roll. The following table describes\nhow negative values of `start` are interpreted:\n\n`start`\n\nNormalized `start`\n\n`-(arr.ndim+1)`\n\nraise `AxisError`\n\n`-arr.ndim`\n\n0\n\n\u22ee\n\n\u22ee\n\n`-1`\n\n`arr.ndim-1`\n\n`0`\n\n`0`\n\n\u22ee\n\n\u22ee\n\n`arr.ndim`\n\n`arr.ndim`\n\n`arr.ndim + 1`\n\nraise `AxisError`\n\nFor NumPy >= 1.10.0 a view of `a` is always returned. For earlier NumPy\nversions a view of `a` is returned only if the order of the axes is changed,\notherwise the input array is returned.\n\nSee also\n\nMove array axes to new positions.\n\nRoll the elements of an array by a number of positions along a given axis.\n\n"}, {"name": "numpy.roots()", "path": "reference/generated/numpy.roots", "type": "numpy.roots", "text": "\nReturn the roots of a polynomial with coefficients given in p.\n\nNote\n\nThis forms part of the old polynomial API. Since version 1.4, the new\npolynomial API defined in `numpy.polynomial` is preferred. A summary of the\ndifferences can be found in the transition guide.\n\nThe values in the rank-1 array `p` are coefficients of a polynomial. If the\nlength of `p` is n+1 then the polynomial is described by:\n\nRank-1 array of polynomial coefficients.\n\nAn array containing the roots of the polynomial.\n\nWhen `p` cannot be converted to a rank-1 array.\n\nSee also\n\nFind the coefficients of a polynomial with a given sequence of roots.\n\nCompute polynomial values.\n\nLeast squares polynomial fit.\n\nA one-dimensional polynomial class.\n\nThe algorithm relies on computing the eigenvalues of the companion matrix [1].\n\nR. A. Horn & C. R. Johnson, Matrix Analysis. Cambridge, UK: Cambridge\nUniversity Press, 1999, pp. 146-7.\n\n"}, {"name": "numpy.rot90()", "path": "reference/generated/numpy.rot90", "type": "numpy.rot90", "text": "\nRotate an array by 90 degrees in the plane specified by axes.\n\nRotation direction is from the first towards the second axis.\n\nArray of two or more dimensions.\n\nNumber of times the array is rotated by 90 degrees.\n\nThe array is rotated in the plane defined by the axes. Axes must be different.\n\nNew in version 1.12.0.\n\nA rotated view of `m`.\n\nSee also\n\nReverse the order of elements in an array along the given axis.\n\nFlip an array horizontally.\n\nFlip an array vertically.\n\n`rot90(m, k=1, axes=(1,0))` is the reverse of `rot90(m, k=1, axes=(0,1))`\n\n`rot90(m, k=1, axes=(1,0))` is equivalent to `rot90(m, k=-1, axes=(0,1))`\n\n"}, {"name": "numpy.round_()", "path": "reference/generated/numpy.round_", "type": "numpy.round_", "text": "\nRound an array to the given number of decimals.\n\nSee also\n\nequivalent function; see for details.\n\n"}, {"name": "numpy.row_stack()", "path": "reference/generated/numpy.row_stack", "type": "numpy.row_stack", "text": "\nStack arrays in sequence vertically (row wise).\n\nThis is equivalent to concatenation along the first axis after 1-D arrays of\nshape `(N,)` have been reshaped to `(1,N)`. Rebuilds arrays divided by\n`vsplit`.\n\nThis function makes most sense for arrays with up to 3 dimensions. For\ninstance, for pixel-data with a height (first axis), width (second axis), and\nr/g/b channels (third axis). The functions `concatenate`, `stack` and `block`\nprovide more general stacking and concatenation operations.\n\nThe arrays must have the same shape along all but the first axis. 1-D arrays\nmust have the same length.\n\nThe array formed by stacking the given arrays, will be at least 2-D.\n\nSee also\n\nJoin a sequence of arrays along an existing axis.\n\nJoin a sequence of arrays along a new axis.\n\nAssemble an nd-array from nested lists of blocks.\n\nStack arrays in sequence horizontally (column wise).\n\nStack arrays in sequence depth wise (along third axis).\n\nStack 1-D arrays as columns into a 2-D array.\n\nSplit an array into multiple sub-arrays vertically (row-wise).\n\n"}, {"name": "numpy.s_", "path": "reference/generated/numpy.s_", "type": "numpy.s_", "text": "\nA nicer way to build up index tuples for arrays.\n\nNote\n\nUse one of the two predefined instances `index_exp` or `s_` rather than\ndirectly using `IndexExpression`.\n\nFor any index combination, including slicing and axis insertion, `a[indices]`\nis the same as `a[np.index_exp[indices]]` for any array `a`. However,\n`np.index_exp[indices]` can be used anywhere in Python code and returns a\ntuple of slice objects that can be used in the construction of complex index\nexpressions.\n\nIf True, always returns a tuple.\n\nSee also\n\nPredefined instance that always returns a tuple: `index_exp =\nIndexExpression(maketuple=True)`.\n\nPredefined instance without tuple conversion: `s_ =\nIndexExpression(maketuple=False)`.\n\nYou can do all this with `slice()` plus a few special objects, but there\u2019s a\nlot to remember and this version is simpler because it uses the standard array\nindexing syntax.\n\n"}, {"name": "numpy.save()", "path": "reference/generated/numpy.save", "type": "numpy.save", "text": "\nSave an array to a binary file in NumPy `.npy` format.\n\nFile or filename to which the data is saved. If file is a file-object, then\nthe filename is unchanged. If file is a string or Path, a `.npy` extension\nwill be appended to the filename if it does not already have one.\n\nArray data to be saved.\n\nAllow saving object arrays using Python pickles. Reasons for disallowing\npickles include security (loading pickled data can execute arbitrary code) and\nportability (pickled objects may not be loadable on different Python\ninstallations, for example if the stored objects require libraries that are\nnot available, and not all pickled data is compatible between Python 2 and\nPython 3). Default: True\n\nOnly useful in forcing objects in object arrays on Python 3 to be pickled in a\nPython 2 compatible way. If `fix_imports` is True, pickle will try to map the\nnew Python 3 names to the old module names used in Python 2, so that the\npickle data stream is readable with Python 2.\n\nSee also\n\nSave several arrays into a `.npz` archive\n\nFor a description of the `.npy` format, see `numpy.lib.format`.\n\nAny data saved to the file is appended to the end of the file.\n\n"}, {"name": "numpy.savetxt()", "path": "reference/generated/numpy.savetxt", "type": "numpy.savetxt", "text": "\nSave an array to a text file.\n\nIf the filename ends in `.gz`, the file is automatically saved in compressed\ngzip format. `loadtxt` understands gzipped files transparently.\n\nData to be saved to a text file.\n\nA single format (%10.5f), a sequence of formats, or a multi-format string,\ne.g. \u2018Iteration %d \u2013 %10.5f\u2019, in which case `delimiter` is ignored. For\ncomplex `X`, the legal options for `fmt` are:\n\nString or character separating columns.\n\nString or character separating lines.\n\nNew in version 1.5.0.\n\nString that will be written at the beginning of the file.\n\nNew in version 1.7.0.\n\nString that will be written at the end of the file.\n\nNew in version 1.7.0.\n\nString that will be prepended to the `header` and `footer` strings, to mark\nthem as comments. Default: \u2018# \u2018, as expected by e.g. `numpy.loadtxt`.\n\nNew in version 1.7.0.\n\nEncoding used to encode the outputfile. Does not apply to output streams. If\nthe encoding is something other than \u2018bytes\u2019 or \u2018latin1\u2019 you will not be able\nto load the file in NumPy versions < 1.14. Default is \u2018latin1\u2019.\n\nNew in version 1.14.0.\n\nSee also\n\nSave an array to a binary file in NumPy `.npy` format\n\nSave several arrays into an uncompressed `.npz` archive\n\nSave several arrays into a compressed `.npz` archive\n\nFurther explanation of the `fmt` parameter\n(`%[flag]width[.precision]specifier`):\n\n`-` : left justify\n\n`+` : Forces to precede result with + or -.\n\n`0` : Left pad the number with zeros instead of space (see width).\n\nMinimum number of characters to be printed. The value is not truncated if it\nhas more characters.\n\n`c` : character\n\n`d` or `i` : signed decimal integer\n\n`e` or `E` : scientific notation with `e` or `E`.\n\n`f` : decimal floating point\n\n`g,G` : use the shorter of `e,E` or `f`\n\n`o` : signed octal\n\n`s` : string of characters\n\n`u` : unsigned decimal integer\n\n`x,X` : unsigned hexadecimal integer\n\nThis explanation of `fmt` is not complete, for an exhaustive specification see\n[1].\n\nFormat Specification Mini-Language, Python Documentation.\n\n"}, {"name": "numpy.savez()", "path": "reference/generated/numpy.savez", "type": "numpy.savez", "text": "\nSave several arrays into a single file in uncompressed `.npz` format.\n\nProvide arrays as keyword arguments to store them under the corresponding name\nin the output file: `savez(fn, x=x, y=y)`.\n\nIf arrays are specified as positional arguments, i.e., `savez(fn, x, y)`,\ntheir names will be `arr_0`, `arr_1`, etc.\n\nEither the filename (string) or an open file (file-like object) where the data\nwill be saved. If file is a string or a Path, the `.npz` extension will be\nappended to the filename if it is not already there.\n\nArrays to save to the file. Please use keyword arguments (see `kwds` below) to\nassign names to arrays. Arrays specified as args will be named \u201carr_0\u201d,\n\u201carr_1\u201d, and so on.\n\nArrays to save to the file. Each array will be saved to the output file with\nits corresponding keyword name.\n\nSee also\n\nSave a single array to a binary file in NumPy format.\n\nSave an array to a file as plain text.\n\nSave several arrays into a compressed `.npz` archive\n\nThe `.npz` file format is a zipped archive of files named after the variables\nthey contain. The archive is not compressed and each file in the archive\ncontains one variable in `.npy` format. For a description of the `.npy`\nformat, see `numpy.lib.format`.\n\nWhen opening the saved `.npz` file with `load` a `NpzFile` object is returned.\nThis is a dictionary-like object which can be queried for its list of arrays\n(with the `.files` attribute), and for the arrays themselves.\n\nKeys passed in `kwds` are used as filenames inside the ZIP archive. Therefore,\nkeys should be valid filenames; e.g., avoid keys that begin with `/` or\ncontain `.`.\n\nWhen naming variables with keyword arguments, it is not possible to name a\nvariable `file`, as this would cause the `file` argument to be defined twice\nin the call to `savez`.\n\nUsing `savez` with *args, the arrays are saved with default names.\n\nUsing `savez` with **kwds, the arrays are saved with the keyword names.\n\n"}, {"name": "numpy.savez_compressed()", "path": "reference/generated/numpy.savez_compressed", "type": "numpy.savez_compressed", "text": "\nSave several arrays into a single file in compressed `.npz` format.\n\nProvide arrays as keyword arguments to store them under the corresponding name\nin the output file: `savez(fn, x=x, y=y)`.\n\nIf arrays are specified as positional arguments, i.e., `savez(fn, x, y)`,\ntheir names will be `arr_0`, `arr_1`, etc.\n\nEither the filename (string) or an open file (file-like object) where the data\nwill be saved. If file is a string or a Path, the `.npz` extension will be\nappended to the filename if it is not already there.\n\nArrays to save to the file. Please use keyword arguments (see `kwds` below) to\nassign names to arrays. Arrays specified as args will be named \u201carr_0\u201d,\n\u201carr_1\u201d, and so on.\n\nArrays to save to the file. Each array will be saved to the output file with\nits corresponding keyword name.\n\nSee also\n\nSave a single array to a binary file in NumPy format.\n\nSave an array to a file as plain text.\n\nSave several arrays into an uncompressed `.npz` file format\n\nLoad the files created by savez_compressed.\n\nThe `.npz` file format is a zipped archive of files named after the variables\nthey contain. The archive is compressed with `zipfile.ZIP_DEFLATED` and each\nfile in the archive contains one variable in `.npy` format. For a description\nof the `.npy` format, see `numpy.lib.format`.\n\nWhen opening the saved `.npz` file with `load` a `NpzFile` object is returned.\nThis is a dictionary-like object which can be queried for its list of arrays\n(with the `.files` attribute), and for the arrays themselves.\n\n"}, {"name": "numpy.sctype2char()", "path": "reference/generated/numpy.sctype2char", "type": "numpy.sctype2char", "text": "\nReturn the string representation of a scalar dtype.\n\nIf a scalar dtype, the corresponding string character is returned. If an\nobject, `sctype2char` tries to infer its scalar type and then return the\ncorresponding string character.\n\nThe string character corresponding to the scalar type.\n\nIf `sctype` is an object for which the type can not be inferred.\n\nSee also\n\n"}, {"name": "numpy.searchsorted()", "path": "reference/generated/numpy.searchsorted", "type": "numpy.searchsorted", "text": "\nFind indices where elements should be inserted to maintain order.\n\nFind the indices into a sorted array `a` such that, if the corresponding\nelements in `v` were inserted before the indices, the order of `a` would be\npreserved.\n\nAssuming that `a` is sorted:\n\n`side`\n\nreturned index `i` satisfies\n\nleft\n\n`a[i-1] < v <= a[i]`\n\nright\n\n`a[i-1] <= v < a[i]`\n\nInput array. If `sorter` is None, then it must be sorted in ascending order,\notherwise `sorter` must be an array of indices that sort it.\n\nValues to insert into `a`.\n\nIf \u2018left\u2019, the index of the first suitable location found is given. If\n\u2018right\u2019, return the last such index. If there is no suitable index, return\neither 0 or N (where N is the length of `a`).\n\nOptional array of integer indices that sort array a into ascending order. They\nare typically the result of argsort.\n\nNew in version 1.7.0.\n\nArray of insertion points with the same shape as `v`, or an integer if `v` is\na scalar.\n\nSee also\n\nReturn a sorted copy of an array.\n\nProduce histogram from 1-D data.\n\nBinary search is used to find the required insertion points.\n\nAs of NumPy 1.4.0 `searchsorted` works with real/complex arrays containing\n`nan` values. The enhanced sort order is documented in `sort`.\n\nThis function uses the same algorithm as the builtin python\n`bisect.bisect_left` (`side='left'`) and `bisect.bisect_right`\n(`side='right'`) functions, which is also vectorized in the `v` argument.\n\n"}, {"name": "numpy.select()", "path": "reference/generated/numpy.select", "type": "numpy.select", "text": "\nReturn an array drawn from elements in choicelist, depending on conditions.\n\nThe list of conditions which determine from which array in `choicelist` the\noutput elements are taken. When multiple conditions are satisfied, the first\none encountered in `condlist` is used.\n\nThe list of arrays from which the output elements are taken. It has to be of\nthe same length as `condlist`.\n\nThe element inserted in `output` when all conditions evaluate to False.\n\nThe output at position m is the m-th element of the array in `choicelist`\nwhere the m-th element of the corresponding array in `condlist` is True.\n\nSee also\n\nReturn elements from one of two arrays depending on condition.\n\n"}, {"name": "numpy.set_printoptions()", "path": "reference/generated/numpy.set_printoptions", "type": "numpy.set_printoptions", "text": "\nSet printing options.\n\nThese options determine the way floating point numbers, arrays and other NumPy\nobjects are displayed.\n\nNumber of digits of precision for floating point output (default 8). May be\nNone if `floatmode` is not `fixed`, to print as many digits as necessary to\nuniquely specify the value.\n\nTotal number of array elements which trigger summarization rather than full\nrepr (default 1000). To always use the full repr without summarization, pass\n`sys.maxsize`.\n\nNumber of array items in summary at beginning and end of each dimension\n(default 3).\n\nThe number of characters per line for the purpose of inserting line breaks\n(default 75).\n\nIf True, always print floating point numbers using fixed point notation, in\nwhich case numbers equal to zero in the current precision will print as zero.\nIf False, then scientific notation is used when absolute value of the smallest\nnumber is < 1e-4 or the ratio of the maximum absolute value to the minimum is\n> 1e3. The default is False.\n\nString representation of floating point not-a-number (default nan).\n\nString representation of floating point infinity (default inf).\n\nControls printing of the sign of floating-point types. If \u2018+\u2019, always print\nthe sign of positive values. If \u2018 \u2018, always prints a space (whitespace\ncharacter) in the sign position of positive values. If \u2018-\u2019, omit the sign\ncharacter of positive values. (default \u2018-\u2018)\n\nIf not None, the keys should indicate the type(s) that the respective\nformatting function applies to. Callables should return a string. Types that\nare not specified (by their corresponding keys) are handled by the default\nformatters. Individual types for which a formatter can be set are:\n\nOther keys that can be used to set a group of types at once are:\n\nControls the interpretation of the `precision` option for floating-point\ntypes. Can take the following values (default maxprec_equal):\n\neven if this would print more or fewer digits than necessary to specify the\nvalue uniquely.\n\nto represent each value uniquely. Different elements may have a different\nnumber of digits. The value of the `precision` option is ignored.\n\nan element can be uniquely represented with fewer digits only print it with\nthat many.\n\nbut if every element in the array can be uniquely represented with an equal\nnumber of fewer digits, use that many digits for all elements.\n\nIf set to the string `\u20181.13\u2019` enables 1.13 legacy printing mode. This\napproximates numpy 1.13 print output by including a space in the sign position\nof floats and different behavior for 0d arrays. This also enables 1.21 legacy\nprinting mode (described below).\n\nIf set to the string `\u20181.21\u2019` enables 1.21 legacy printing mode. This\napproximates numpy 1.21 print output of complex structured dtypes by not\ninserting spaces after commas that separate fields and after colons.\n\nIf set to `False`, disables legacy mode.\n\nUnrecognized strings will be ignored with a warning for forward compatibility.\n\nNew in version 1.14.0.\n\nChanged in version 1.22.0.\n\nSee also\n\n`formatter` is always reset with a call to `set_printoptions`.\n\nUse `printoptions` as a context manager to set the values temporarily.\n\nFloating point precision can be set:\n\nLong arrays can be summarised:\n\nSmall results can be suppressed:\n\nA custom formatter can be used to display array elements as desired:\n\nTo put back the default options, you can use:\n\nAlso to temporarily override options, use `printoptions` as a context manager:\n\n"}, {"name": "numpy.set_string_function()", "path": "reference/generated/numpy.set_string_function", "type": "numpy.set_string_function", "text": "\nSet a Python function to be used when pretty printing arrays.\n\nFunction to be used to pretty print arrays. The function should expect a\nsingle array argument and return a string of the representation of the array.\nIf None, the function is reset to the default NumPy function to print arrays.\n\nIf True (default), the function for pretty printing (`__repr__`) is set, if\nFalse the function that returns the default string representation (`__str__`)\nis set.\n\nSee also\n\nWe can reset the function to the default:\n\n`repr` affects either pretty printing or normal string representation. Note\nthat `__repr__` is still affected by setting `__str__` because the width of\neach array element in the returned string becomes equal to the length of the\nresult of `__str__()`.\n\n"}, {"name": "numpy.setbufsize()", "path": "reference/generated/numpy.setbufsize", "type": "numpy.setbufsize", "text": "\nSet the size of the buffer used in ufuncs.\n\nSize of buffer.\n\n"}, {"name": "numpy.setdiff1d()", "path": "reference/generated/numpy.setdiff1d", "type": "numpy.setdiff1d", "text": "\nFind the set difference of two arrays.\n\nReturn the unique values in `ar1` that are not in `ar2`.\n\nInput array.\n\nInput comparison array.\n\nIf True, the input arrays are both assumed to be unique, which can speed up\nthe calculation. Default is False.\n\n1D array of values in `ar1` that are not in `ar2`. The result is sorted when\n`assume_unique=False`, but otherwise only sorted if the input is sorted.\n\nSee also\n\nModule with a number of other functions for performing set operations on\narrays.\n\n"}, {"name": "numpy.seterr()", "path": "reference/generated/numpy.seterr", "type": "numpy.seterr", "text": "\nSet how floating-point errors are handled.\n\nNote that operations on integer scalar types (such as `int16`) are handled\nlike floating point, and are affected by these settings.\n\nSet treatment for all types of floating-point errors at once:\n\nThe default is not to change the current behavior.\n\nTreatment for division by zero.\n\nTreatment for floating-point overflow.\n\nTreatment for floating-point underflow.\n\nTreatment for invalid floating-point operation.\n\nDictionary containing the old settings.\n\nSee also\n\nSet a callback function for the \u2018call\u2019 mode.\n\nThe floating-point exceptions are defined in the IEEE 754 standard [1]:\n\nhttps://en.wikipedia.org/wiki/IEEE_754\n\n"}, {"name": "numpy.seterrcall()", "path": "reference/generated/numpy.seterrcall", "type": "numpy.seterrcall", "text": "\nSet the floating-point error callback function or log object.\n\nThere are two ways to capture floating-point error messages. The first is to\nset the error-handler to \u2018call\u2019, using `seterr`. Then, set the function to\ncall using this function.\n\nThe second is to set the error-handler to \u2018log\u2019, using `seterr`. Floating-\npoint errors then trigger a call to the \u2018write\u2019 method of the provided object.\n\nFunction to call upon floating-point errors (\u2018call\u2019-mode) or object whose\n\u2018write\u2019 method is used to log such message (\u2018log\u2019-mode).\n\nThe call function takes two arguments. The first is a string describing the\ntype of error (such as \u201cdivide by zero\u201d, \u201coverflow\u201d, \u201cunderflow\u201d, or \u201cinvalid\nvalue\u201d), and the second is the status flag. The flag is a byte, whose four\nleast-significant bits indicate the type of error, one of \u201cdivide\u201d, \u201cover\u201d,\n\u201cunder\u201d, \u201cinvalid\u201d:\n\nIn other words, `flags = divide + 2*over + 4*under + 8*invalid`.\n\nIf an object is provided, its write method should take one argument, a string.\n\nThe old error handler.\n\nSee also\n\nCallback upon error:\n\nLog error message:\n\n"}, {"name": "numpy.seterrobj()", "path": "reference/generated/numpy.seterrobj", "type": "numpy.seterrobj", "text": "\nSet the object that defines floating-point error handling.\n\nThe error object contains all information that defines the error handling\nbehavior in NumPy. `seterrobj` is used internally by the other functions that\nset error handling behavior (`seterr`, `seterrcall`).\n\nThe error object, a list containing three elements: [internal numpy buffer\nsize, error mask, error callback function].\n\nThe error mask is a single integer that holds the treatment information on all\nfour floating point errors. The information for each error type is contained\nin three bits of the integer. If we print it in base 8, we can see what\ntreatment is set for \u201cinvalid\u201d, \u201cunder\u201d, \u201cover\u201d, and \u201cdivide\u201d (in that order).\nThe printed string can be interpreted with\n\nSee also\n\nFor complete documentation of the types of floating-point exceptions and\ntreatment options, see `seterr`.\n\n"}, {"name": "numpy.setxor1d()", "path": "reference/generated/numpy.setxor1d", "type": "numpy.setxor1d", "text": "\nFind the set exclusive-or of two arrays.\n\nReturn the sorted, unique values that are in only one (not both) of the input\narrays.\n\nInput arrays.\n\nIf True, the input arrays are both assumed to be unique, which can speed up\nthe calculation. Default is False.\n\nSorted 1D array of unique values that are in only one of the input arrays.\n\n"}, {"name": "numpy.shape()", "path": "reference/generated/numpy.shape", "type": "numpy.shape", "text": "\nReturn the shape of an array.\n\nInput array.\n\nThe elements of the shape tuple give the lengths of the corresponding array\ndimensions.\n\nSee also\n\nEquivalent array method.\n\n"}, {"name": "numpy.shares_memory()", "path": "reference/generated/numpy.shares_memory", "type": "numpy.shares_memory", "text": "\nDetermine if two arrays share memory.\n\nWarning\n\nThis function can be exponentially slow for some inputs, unless `max_work` is\nset to a finite number or `MAY_SHARE_BOUNDS`. If in doubt, use\n`numpy.may_share_memory` instead.\n\nInput arrays\n\nEffort to spend on solving the overlap problem (maximum number of candidate\nsolutions to consider). The following special values are recognized:\n\nThe problem is solved exactly. In this case, the function returns True only if\nthere is an element shared between the arrays. Finding the exact solution may\ntake extremely long in some cases.\n\nOnly the memory bounds of a and b are checked.\n\nExceeded max_work.\n\nSee also\n\nChecking whether two arrays share memory is NP-complete, and runtime may\nincrease exponentially in the number of dimensions. Hence, `max_work` should\ngenerally be set to a finite number, as it is possible to construct examples\nthat take extremely long to run:\n\nRunning `np.shares_memory(x1, x2)` without `max_work` set takes around 1\nminute for this case. It is possible to find problems that take still\nsignificantly longer.\n\n"}, {"name": "numpy.short", "path": "reference/arrays.scalars#numpy.short", "type": "Scalars", "text": "\nSigned integer type, compatible with C `short`.\n\n`'h'`\n\n`numpy.int16`: 16-bit signed integer (`-32_768` to `32_767`).\n\n"}, {"name": "numpy.show_config()", "path": "reference/generated/numpy.show_config", "type": "numpy.show_config", "text": "\nShow libraries in the system on which NumPy was built.\n\nPrint information about various resources (libraries, library directories,\ninclude directories, etc.) in the system on which NumPy was built.\n\nSee also\n\nReturns the directory containing NumPy C header files.\n\nClasses specifying the information to be printed are defined in the\n`numpy.distutils.system_info` module.\n\nInformation may include:\n\nNumPy BLAS/LAPACK Installation Notes\n\nInstalling a numpy wheel (`pip install numpy` or force it via `pip install\nnumpy --only-binary :numpy: numpy`) includes an OpenBLAS implementation of the\nBLAS and LAPACK linear algebra APIs. In this case, `library_dirs` reports the\noriginal build time configuration as compiled with gcc/gfortran; at run time\nthe OpenBLAS library is in `site-packages/numpy.libs/` (linux), or `site-\npackages/numpy/.dylibs/` (macOS), or `site-packages/numpy/.libs/` (windows).\n\nInstalling numpy from source (`pip install numpy --no-binary numpy`) searches\nfor BLAS and LAPACK dynamic link libraries at build time as influenced by\nenvironment variables NPY_BLAS_LIBS, NPY_CBLAS_LIBS, and NPY_LAPACK_LIBS; or\nNPY_BLAS_ORDER and NPY_LAPACK_ORDER; or the optional file `~/.numpy-site.cfg`.\nNumPy remembers those locations and expects to load the same libraries at run-\ntime. In NumPy 1.21+ on macOS, \u2018accelerate\u2019 (Apple\u2019s Accelerate BLAS library)\nis in the default build-time search order after \u2018openblas\u2019.\n\n"}, {"name": "numpy.sign()", "path": "reference/generated/numpy.sign", "type": "numpy.sign", "text": "\nReturns an element-wise indication of the sign of a number.\n\nThe `sign` function returns `-1 if x < 0, 0 if x==0, 1 if x > 0`. nan is\nreturned for nan inputs.\n\nFor complex inputs, the `sign` function returns `sign(x.real) + 0j if x.real\n!= 0 else sign(x.imag) + 0j`.\n\ncomplex(nan, 0) is returned for complex nan inputs.\n\nInput values.\n\nA location into which the result is stored. If provided, it must have a shape\nthat the inputs broadcast to. If not provided or None, a freshly-allocated\narray is returned. A tuple (possible only as a keyword argument) must have\nlength equal to the number of outputs.\n\nThis condition is broadcast over the input. At locations where the condition\nis True, the `out` array will be set to the ufunc result. Elsewhere, the `out`\narray will retain its original value. Note that if an uninitialized `out`\narray is created via the default `out=None`, locations within it where the\ncondition is False will remain uninitialized.\n\nFor other keyword-only arguments, see the ufunc docs.\n\nThe sign of `x`. This is a scalar if `x` is a scalar.\n\nThere is more than one definition of sign in common use for complex numbers.\nThe definition used here is equivalent to \\\\(x/\\sqrt{x*x}\\\\) which is\ndifferent from a common alternative, \\\\(x/|x|\\\\).\n\n"}, {"name": "numpy.signbit()", "path": "reference/generated/numpy.signbit", "type": "numpy.signbit", "text": "\nReturns element-wise True where signbit is set (less than zero).\n\nThe input value(s).\n\nA location into which the result is stored. If provided, it must have a shape\nthat the inputs broadcast to. If not provided or None, a freshly-allocated\narray is returned. A tuple (possible only as a keyword argument) must have\nlength equal to the number of outputs.\n\nThis condition is broadcast over the input. At locations where the condition\nis True, the `out` array will be set to the ufunc result. Elsewhere, the `out`\narray will retain its original value. Note that if an uninitialized `out`\narray is created via the default `out=None`, locations within it where the\ncondition is False will remain uninitialized.\n\nFor other keyword-only arguments, see the ufunc docs.\n\nOutput array, or reference to `out` if that was supplied. This is a scalar if\n`x` is a scalar.\n\n"}, {"name": "numpy.sin()", "path": "reference/generated/numpy.sin", "type": "numpy.sin", "text": "\nTrigonometric sine, element-wise.\n\nAngle, in radians (\\\\(2 \\pi\\\\) rad equals 360 degrees).\n\nA location into which the result is stored. If provided, it must have a shape\nthat the inputs broadcast to. If not provided or None, a freshly-allocated\narray is returned. A tuple (possible only as a keyword argument) must have\nlength equal to the number of outputs.\n\nThis condition is broadcast over the input. At locations where the condition\nis True, the `out` array will be set to the ufunc result. Elsewhere, the `out`\narray will retain its original value. Note that if an uninitialized `out`\narray is created via the default `out=None`, locations within it where the\ncondition is False will remain uninitialized.\n\nFor other keyword-only arguments, see the ufunc docs.\n\nThe sine of each element of x. This is a scalar if `x` is a scalar.\n\nSee also\n\nThe sine is one of the fundamental functions of trigonometry (the mathematical\nstudy of triangles). Consider a circle of radius 1 centered on the origin. A\nray comes in from the \\\\(+x\\\\) axis, makes an angle at the origin (measured\ncounter-clockwise from that axis), and departs from the origin. The \\\\(y\\\\)\ncoordinate of the outgoing ray\u2019s intersection with the unit circle is the sine\nof that angle. It ranges from -1 for \\\\(x=3\\pi / 2\\\\) to +1 for \\\\(\\pi / 2.\\\\)\nThe function has zeroes where the angle is a multiple of \\\\(\\pi\\\\). Sines of\nangles between \\\\(\\pi\\\\) and \\\\(2\\pi\\\\) are negative. The numerous properties\nof the sine and related functions are included in any standard trigonometry\ntext.\n\nPrint sine of one angle:\n\nPrint sines of an array of angles given in degrees:\n\nPlot the sine function:\n\n"}, {"name": "numpy.sinc()", "path": "reference/generated/numpy.sinc", "type": "numpy.sinc", "text": "\nReturn the normalized sinc function.\n\nThe sinc function is \\\\(\\sin(\\pi x)/(\\pi x)\\\\).\n\nNote\n\nNote the normalization factor of `pi` used in the definition. This is the most\ncommonly used definition in signal processing. Use `sinc(x / np.pi)` to obtain\nthe unnormalized sinc function \\\\(\\sin(x)/(x)\\\\) that is more common in\nmathematics.\n\nArray (possibly multi-dimensional) of values for which to to calculate\n`sinc(x)`.\n\n`sinc(x)`, which has the same shape as the input.\n\n`sinc(0)` is the limit value 1.\n\nThe name sinc is short for \u201csine cardinal\u201d or \u201csinus cardinalis\u201d.\n\nThe sinc function is used in various signal processing applications, including\nin anti-aliasing, in the construction of a Lanczos resampling filter, and in\ninterpolation.\n\nFor bandlimited interpolation of discrete-time signals, the ideal\ninterpolation kernel is proportional to the sinc function.\n\nWeisstein, Eric W. \u201cSinc Function.\u201d From MathWorld\u2013A Wolfram Web Resource.\nhttp://mathworld.wolfram.com/SincFunction.html\n\nWikipedia, \u201cSinc function\u201d, https://en.wikipedia.org/wiki/Sinc_function\n\n"}, {"name": "numpy.single", "path": "reference/arrays.scalars#numpy.single", "type": "Scalars", "text": "\nSingle-precision floating-point number type, compatible with C `float`.\n\n`'f'`\n\n`numpy.float32`: 32-bit-precision floating-point number type: sign bit, 8 bits\nexponent, 23 bits mantissa.\n\n"}, {"name": "numpy.singlecomplex", "path": "reference/arrays.scalars#numpy.singlecomplex", "type": "Scalars", "text": "\nalias of `numpy.csingle`\n\n"}, {"name": "numpy.sinh()", "path": "reference/generated/numpy.sinh", "type": "numpy.sinh", "text": "\nHyperbolic sine, element-wise.\n\nEquivalent to `1/2 * (np.exp(x) - np.exp(-x))` or `-1j * np.sin(1j*x)`.\n\nInput array.\n\nA location into which the result is stored. If provided, it must have a shape\nthat the inputs broadcast to. If not provided or None, a freshly-allocated\narray is returned. A tuple (possible only as a keyword argument) must have\nlength equal to the number of outputs.\n\nThis condition is broadcast over the input. At locations where the condition\nis True, the `out` array will be set to the ufunc result. Elsewhere, the `out`\narray will retain its original value. Note that if an uninitialized `out`\narray is created via the default `out=None`, locations within it where the\ncondition is False will remain uninitialized.\n\nFor other keyword-only arguments, see the ufunc docs.\n\nThe corresponding hyperbolic sine values. This is a scalar if `x` is a scalar.\n\nIf `out` is provided, the function writes the result into it, and returns a\nreference to `out`. (See Examples)\n\nM. Abramowitz and I. A. Stegun, Handbook of Mathematical Functions. New York,\nNY: Dover, 1972, pg. 83.\n\n"}, {"name": "numpy.sort()", "path": "reference/generated/numpy.sort", "type": "numpy.sort", "text": "\nReturn a sorted copy of an array.\n\nArray to be sorted.\n\nAxis along which to sort. If None, the array is flattened before sorting. The\ndefault is -1, which sorts along the last axis.\n\nSorting algorithm. The default is \u2018quicksort\u2019. Note that both \u2018stable\u2019 and\n\u2018mergesort\u2019 use timsort or radix sort under the covers and, in general, the\nactual implementation will vary with data type. The \u2018mergesort\u2019 option is\nretained for backwards compatibility.\n\nChanged in version 1.15.0.: The \u2018stable\u2019 option was added.\n\nWhen `a` is an array with fields defined, this argument specifies which fields\nto compare first, second, etc. A single field can be specified as a string,\nand not all fields need be specified, but unspecified fields will still be\nused, in the order in which they come up in the dtype, to break ties.\n\nArray of the same type and shape as `a`.\n\nSee also\n\nMethod to sort an array in-place.\n\nIndirect sort.\n\nIndirect stable sort on multiple keys.\n\nFind elements in a sorted array.\n\nPartial sort.\n\nThe various sorting algorithms are characterized by their average speed, worst\ncase performance, work space size, and whether they are stable. A stable sort\nkeeps items with the same key in the same relative order. The four algorithms\nimplemented in NumPy have the following properties:\n\nkind\n\nspeed\n\nworst case\n\nwork space\n\nstable\n\n\u2018quicksort\u2019\n\n1\n\nO(n^2)\n\n0\n\nno\n\n\u2018heapsort\u2019\n\n3\n\nO(n*log(n))\n\n0\n\nno\n\n\u2018mergesort\u2019\n\n2\n\nO(n*log(n))\n\n~n/2\n\nyes\n\n\u2018timsort\u2019\n\n2\n\nO(n*log(n))\n\n~n/2\n\nyes\n\nNote\n\nThe datatype determines which of \u2018mergesort\u2019 or \u2018timsort\u2019 is actually used,\neven if \u2018mergesort\u2019 is specified. User selection at a finer scale is not\ncurrently available.\n\nAll the sort algorithms make temporary copies of the data when sorting along\nany but the last axis. Consequently, sorting along the last axis is faster and\nuses less space than sorting along any other axis.\n\nThe sort order for complex numbers is lexicographic. If both the real and\nimaginary parts are non-nan then the order is determined by the real parts\nexcept when they are equal, in which case the order is determined by the\nimaginary parts.\n\nPrevious to numpy 1.4.0 sorting real and complex arrays containing nan values\nled to undefined behaviour. In numpy versions >= 1.4.0 nan values are sorted\nto the end. The extended sort order is:\n\nwhere R is a non-nan real value. Complex values with the same nan placements\nare sorted according to the non-nan part if it exists. Non-nan values are\nsorted as before.\n\nNew in version 1.12.0.\n\nquicksort has been changed to introsort. When sorting does not make enough\nprogress it switches to heapsort. This implementation makes quicksort\nO(n*log(n)) in the worst case.\n\n\u2018stable\u2019 automatically chooses the best stable sorting algorithm for the data\ntype being sorted. It, along with \u2018mergesort\u2019 is currently mapped to timsort\nor radix sort depending on the data type. API forward compatibility currently\nlimits the ability to select the implementation and it is hardwired for the\ndifferent data types.\n\nNew in version 1.17.0.\n\nTimsort is added for better performance on already or nearly sorted data. On\nrandom data timsort is almost identical to mergesort. It is now used for\nstable sort while quicksort is still the default sort if none is chosen. For\ntimsort details, refer to CPython listsort.txt. \u2018mergesort\u2019 and \u2018stable\u2019 are\nmapped to radix sort for integer data types. Radix sort is an O(n) sort\ninstead of O(n log n).\n\nChanged in version 1.18.0.\n\nNaT now sorts to the end of arrays for consistency with NaN.\n\nUse the `order` keyword to specify a field to use when sorting a structured\narray:\n\nSort by age, then height if ages are equal:\n\n"}, {"name": "numpy.sort_complex()", "path": "reference/generated/numpy.sort_complex", "type": "numpy.sort_complex", "text": "\nSort a complex array using the real part first, then the imaginary part.\n\nInput array\n\nAlways returns a sorted complex array.\n\n"}, {"name": "numpy.source()", "path": "reference/generated/numpy.source", "type": "numpy.source", "text": "\nPrint or write to a file the source code for a NumPy object.\n\nThe source code is only returned for objects written in Python. Many functions\nand classes are defined in C and will therefore not return useful information.\n\nInput object. This can be any object (function, class, module, \u2026).\n\nIf `output` not supplied then source code is printed to screen (sys.stdout).\nFile object must be created with either write \u2018w\u2019 or append \u2018a\u2019 modes.\n\nSee also\n\nThe source code is only returned for objects written in Python.\n\n"}, {"name": "numpy.spacing()", "path": "reference/generated/numpy.spacing", "type": "numpy.spacing", "text": "\nReturn the distance between x and the nearest adjacent number.\n\nValues to find the spacing of.\n\nA location into which the result is stored. If provided, it must have a shape\nthat the inputs broadcast to. If not provided or None, a freshly-allocated\narray is returned. A tuple (possible only as a keyword argument) must have\nlength equal to the number of outputs.\n\nThis condition is broadcast over the input. At locations where the condition\nis True, the `out` array will be set to the ufunc result. Elsewhere, the `out`\narray will retain its original value. Note that if an uninitialized `out`\narray is created via the default `out=None`, locations within it where the\ncondition is False will remain uninitialized.\n\nFor other keyword-only arguments, see the ufunc docs.\n\nThe spacing of values of `x`. This is a scalar if `x` is a scalar.\n\nIt can be considered as a generalization of EPS: `spacing(np.float64(1)) ==\nnp.finfo(np.float64).eps`, and there should not be any representable number\nbetween `x + spacing(x)` and x for any finite x.\n\nSpacing of +- inf and NaN is NaN.\n\n"}, {"name": "numpy.split()", "path": "reference/generated/numpy.split", "type": "numpy.split", "text": "\nSplit an array into multiple sub-arrays as views into `ary`.\n\nArray to be divided into sub-arrays.\n\nIf `indices_or_sections` is an integer, N, the array will be divided into N\nequal arrays along `axis`. If such a split is not possible, an error is\nraised.\n\nIf `indices_or_sections` is a 1-D array of sorted integers, the entries\nindicate where along `axis` the array is split. For example, `[2, 3]` would,\nfor `axis=0`, result in\n\nIf an index exceeds the dimension of the array along `axis`, an empty sub-\narray is returned correspondingly.\n\nThe axis along which to split, default is 0.\n\nA list of sub-arrays as views into `ary`.\n\nIf `indices_or_sections` is given as an integer, but a split does not result\nin equal division.\n\nSee also\n\nSplit an array into multiple sub-arrays of equal or near-equal size. Does not\nraise an exception if an equal division cannot be made.\n\nSplit array into multiple sub-arrays horizontally (column-wise).\n\nSplit array into multiple sub-arrays vertically (row wise).\n\nSplit array into multiple sub-arrays along the 3rd axis (depth).\n\nJoin a sequence of arrays along an existing axis.\n\nJoin a sequence of arrays along a new axis.\n\nStack arrays in sequence horizontally (column wise).\n\nStack arrays in sequence vertically (row wise).\n\nStack arrays in sequence depth wise (along third dimension).\n\n"}, {"name": "numpy.sqrt()", "path": "reference/generated/numpy.sqrt", "type": "numpy.sqrt", "text": "\nReturn the non-negative square-root of an array, element-wise.\n\nThe values whose square-roots are required.\n\nA location into which the result is stored. If provided, it must have a shape\nthat the inputs broadcast to. If not provided or None, a freshly-allocated\narray is returned. A tuple (possible only as a keyword argument) must have\nlength equal to the number of outputs.\n\nThis condition is broadcast over the input. At locations where the condition\nis True, the `out` array will be set to the ufunc result. Elsewhere, the `out`\narray will retain its original value. Note that if an uninitialized `out`\narray is created via the default `out=None`, locations within it where the\ncondition is False will remain uninitialized.\n\nFor other keyword-only arguments, see the ufunc docs.\n\nAn array of the same shape as `x`, containing the positive square-root of each\nelement in `x`. If any element in `x` is complex, a complex array is returned\n(and the square-roots of negative reals are calculated). If all of the\nelements in `x` are real, so is `y`, with negative elements returning `nan`.\nIf `out` was provided, `y` is a reference to it. This is a scalar if `x` is a\nscalar.\n\nSee also\n\nA version which returns complex numbers when given negative reals.\n\nsqrt has\u2013consistent with common convention\u2013as its branch cut the real\n\u201cinterval\u201d [`-inf`, 0), and is continuous from above on it. A branch cut is a\ncurve in the complex plane across which a given complex function fails to be\ncontinuous.\n\n"}, {"name": "numpy.square()", "path": "reference/generated/numpy.square", "type": "numpy.square", "text": "\nReturn the element-wise square of the input.\n\nInput data.\n\nA location into which the result is stored. If provided, it must have a shape\nthat the inputs broadcast to. If not provided or None, a freshly-allocated\narray is returned. A tuple (possible only as a keyword argument) must have\nlength equal to the number of outputs.\n\nThis condition is broadcast over the input. At locations where the condition\nis True, the `out` array will be set to the ufunc result. Elsewhere, the `out`\narray will retain its original value. Note that if an uninitialized `out`\narray is created via the default `out=None`, locations within it where the\ncondition is False will remain uninitialized.\n\nFor other keyword-only arguments, see the ufunc docs.\n\nElement-wise `x*x`, of the same shape and dtype as `x`. This is a scalar if\n`x` is a scalar.\n\nSee also\n\n"}, {"name": "numpy.squeeze()", "path": "reference/generated/numpy.squeeze", "type": "numpy.squeeze", "text": "\nRemove axes of length one from `a`.\n\nInput data.\n\nNew in version 1.7.0.\n\nSelects a subset of the entries of length one in the shape. If an axis is\nselected with shape entry greater than one, an error is raised.\n\nThe input array, but with all or a subset of the dimensions of length 1\nremoved. This is always `a` itself or a view into `a`. Note that if all axes\nare squeezed, the result is a 0d array and not a scalar.\n\nIf `axis` is not None, and an axis being squeezed is not of length 1\n\nSee also\n\nThe inverse operation, adding entries of length one\n\nInsert, remove, and combine dimensions, and resize existing ones\n\n"}, {"name": "numpy.stack()", "path": "reference/generated/numpy.stack", "type": "numpy.stack", "text": "\nJoin a sequence of arrays along a new axis.\n\nThe `axis` parameter specifies the index of the new axis in the dimensions of\nthe result. For example, if `axis=0` it will be the first dimension and if\n`axis=-1` it will be the last dimension.\n\nNew in version 1.10.0.\n\nEach array must have the same shape.\n\nThe axis in the result array along which the input arrays are stacked.\n\nIf provided, the destination to place the result. The shape must be correct,\nmatching that of what stack would have returned if no out argument were\nspecified.\n\nThe stacked array has one more dimension than the input arrays.\n\nSee also\n\nJoin a sequence of arrays along an existing axis.\n\nAssemble an nd-array from nested lists of blocks.\n\nSplit array into a list of multiple sub-arrays of equal size.\n\n"}, {"name": "numpy.std()", "path": "reference/generated/numpy.std", "type": "numpy.std", "text": "\nCompute the standard deviation along the specified axis.\n\nReturns the standard deviation, a measure of the spread of a distribution, of\nthe array elements. The standard deviation is computed for the flattened array\nby default, otherwise over the specified axis.\n\nCalculate the standard deviation of these values.\n\nAxis or axes along which the standard deviation is computed. The default is to\ncompute the standard deviation of the flattened array.\n\nNew in version 1.7.0.\n\nIf this is a tuple of ints, a standard deviation is performed over multiple\naxes, instead of a single axis or all the axes as before.\n\nType to use in computing the standard deviation. For arrays of integer type\nthe default is float64, for arrays of float types it is the same as the array\ntype.\n\nAlternative output array in which to place the result. It must have the same\nshape as the expected output but the type (of the calculated values) will be\ncast if necessary.\n\nMeans Delta Degrees of Freedom. The divisor used in calculations is `N -\nddof`, where `N` represents the number of elements. By default `ddof` is zero.\n\nIf this is set to True, the axes which are reduced are left in the result as\ndimensions with size one. With this option, the result will broadcast\ncorrectly against the input array.\n\nIf the default value is passed, then `keepdims` will not be passed through to\nthe `std` method of sub-classes of `ndarray`, however any non-default value\nwill be. If the sub-class\u2019 method does not implement `keepdims` any exceptions\nwill be raised.\n\nElements to include in the standard deviation. See `reduce` for details.\n\nNew in version 1.20.0.\n\nIf `out` is None, return a new array containing the standard deviation,\notherwise return a reference to the output array.\n\nSee also\n\nThe standard deviation is the square root of the average of the squared\ndeviations from the mean, i.e., `std = sqrt(mean(x))`, where `x = abs(a -\na.mean())**2`.\n\nThe average squared deviation is typically calculated as `x.sum() / N`, where\n`N = len(x)`. If, however, `ddof` is specified, the divisor `N - ddof` is used\ninstead. In standard statistical practice, `ddof=1` provides an unbiased\nestimator of the variance of the infinite population. `ddof=0` provides a\nmaximum likelihood estimate of the variance for normally distributed\nvariables. The standard deviation computed in this function is the square root\nof the estimated variance, so even with `ddof=1`, it will not be an unbiased\nestimate of the standard deviation per se.\n\nNote that, for complex numbers, `std` takes the absolute value before\nsquaring, so that the result is always real and nonnegative.\n\nFor floating-point input, the std is computed using the same precision the\ninput has. Depending on the input data, this can cause the results to be\ninaccurate, especially for float32 (see example below). Specifying a higher-\naccuracy accumulator using the `dtype` keyword can alleviate this issue.\n\nIn single precision, std() can be inaccurate:\n\nComputing the standard deviation in float64 is more accurate:\n\nSpecifying a where argument:\n\n"}, {"name": "numpy.str_", "path": "reference/arrays.scalars#numpy.str_", "type": "Scalars", "text": "\nA unicode string.\n\nWhen used in arrays, this type strips trailing null codepoints.\n\nUnlike the builtin `str`, this supports the Buffer Protocol, exposing its\ncontents as UCS4:\n\n`'U'`\n\n`numpy.unicode_`\n\n"}, {"name": "numpy.string_", "path": "reference/arrays.scalars#numpy.string_", "type": "Scalars", "text": "\nalias of `numpy.bytes_`\n\n"}, {"name": "numpy.subtract()", "path": "reference/generated/numpy.subtract", "type": "numpy.subtract", "text": "\nSubtract arguments, element-wise.\n\nThe arrays to be subtracted from each other. If `x1.shape != x2.shape`, they\nmust be broadcastable to a common shape (which becomes the shape of the\noutput).\n\nA location into which the result is stored. If provided, it must have a shape\nthat the inputs broadcast to. If not provided or None, a freshly-allocated\narray is returned. A tuple (possible only as a keyword argument) must have\nlength equal to the number of outputs.\n\nThis condition is broadcast over the input. At locations where the condition\nis True, the `out` array will be set to the ufunc result. Elsewhere, the `out`\narray will retain its original value. Note that if an uninitialized `out`\narray is created via the default `out=None`, locations within it where the\ncondition is False will remain uninitialized.\n\nFor other keyword-only arguments, see the ufunc docs.\n\nThe difference of `x1` and `x2`, element-wise. This is a scalar if both `x1`\nand `x2` are scalars.\n\nEquivalent to `x1 - x2` in terms of array broadcasting.\n\nThe `-` operator can be used as a shorthand for `np.subtract` on ndarrays.\n\n"}, {"name": "numpy.sum()", "path": "reference/generated/numpy.sum", "type": "numpy.sum", "text": "\nSum of array elements over a given axis.\n\nElements to sum.\n\nAxis or axes along which a sum is performed. The default, axis=None, will sum\nall of the elements of the input array. If axis is negative it counts from the\nlast to the first axis.\n\nNew in version 1.7.0.\n\nIf axis is a tuple of ints, a sum is performed on all of the axes specified in\nthe tuple instead of a single axis or all the axes as before.\n\nThe type of the returned array and of the accumulator in which the elements\nare summed. The dtype of `a` is used by default unless `a` has an integer\ndtype of less precision than the default platform integer. In that case, if\n`a` is signed then the platform integer is used while if `a` is unsigned then\nan unsigned integer of the same precision as the platform integer is used.\n\nAlternative output array in which to place the result. It must have the same\nshape as the expected output, but the type of the output values will be cast\nif necessary.\n\nIf this is set to True, the axes which are reduced are left in the result as\ndimensions with size one. With this option, the result will broadcast\ncorrectly against the input array.\n\nIf the default value is passed, then `keepdims` will not be passed through to\nthe `sum` method of sub-classes of `ndarray`, however any non-default value\nwill be. If the sub-class\u2019 method does not implement `keepdims` any exceptions\nwill be raised.\n\nStarting value for the sum. See `reduce` for details.\n\nNew in version 1.15.0.\n\nElements to include in the sum. See `reduce` for details.\n\nNew in version 1.17.0.\n\nAn array with the same shape as `a`, with the specified axis removed. If `a`\nis a 0-d array, or if `axis` is None, a scalar is returned. If an output array\nis specified, a reference to `out` is returned.\n\nSee also\n\nEquivalent method.\n\nEquivalent functionality of `add`.\n\nCumulative sum of array elements.\n\nIntegration of array values using the composite trapezoidal rule.\n\nArithmetic is modular when using integer types, and no error is raised on\noverflow.\n\nThe sum of an empty array is the neutral element 0:\n\nFor floating point numbers the numerical precision of sum (and\n`np.add.reduce`) is in general limited by directly adding each number\nindividually to the result causing rounding errors in every step. However,\noften numpy will use a numerically better approach (partial pairwise\nsummation) leading to improved precision in many use-cases. This improved\nprecision is always provided when no `axis` is given. When `axis` is given, it\nwill depend on which axis is summed. Technically, to provide the best speed\npossible, the improved precision is only used when the summation is along the\nfast axis in memory. Note that the exact precision may vary depending on other\nparameters. In contrast to NumPy, Python\u2019s `math.fsum` function uses a slower\nbut more precise approach to summation. Especially when summing a large number\nof lower precision floating point numbers, such as `float32`, numerical errors\ncan become significant. In such cases it can be advisable to use\n`dtype=\u201dfloat64\u201d` to use a higher precision for the output.\n\nIf the accumulator is too small, overflow occurs:\n\nYou can also start the sum with a value other than zero:\n\n"}, {"name": "numpy.swapaxes()", "path": "reference/generated/numpy.swapaxes", "type": "numpy.swapaxes", "text": "\nInterchange two axes of an array.\n\nInput array.\n\nFirst axis.\n\nSecond axis.\n\nFor NumPy >= 1.10.0, if `a` is an ndarray, then a view of `a` is returned;\notherwise a new array is created. For earlier NumPy versions a view of `a` is\nreturned only if the order of the axes is changed, otherwise the input array\nis returned.\n\n"}, {"name": "numpy.take()", "path": "reference/generated/numpy.take", "type": "numpy.take", "text": "\nTake elements from an array along an axis.\n\nWhen axis is not None, this function does the same thing as \u201cfancy\u201d indexing\n(indexing arrays using arrays); however, it can be easier to use if you need\nelements along a given axis. A call such as `np.take(arr, indices, axis=3)` is\nequivalent to `arr[:,:,:,indices,...]`.\n\nExplained without fancy indexing, this is equivalent to the following use of\n`ndindex`, which sets each of `ii`, `jj`, and `kk` to a tuple of indices:\n\nThe source array.\n\nThe indices of the values to extract.\n\nNew in version 1.8.0.\n\nAlso allow scalars for indices.\n\nThe axis over which to select values. By default, the flattened input array is\nused.\n\nIf provided, the result will be placed in this array. It should be of the\nappropriate shape and dtype. Note that `out` is always buffered if\n`mode=\u2019raise\u2019`; use other modes for better performance.\n\nSpecifies how out-of-bounds indices will behave.\n\n\u2018clip\u2019 mode means that all indices that are too large are replaced by the\nindex that addresses the last element along that axis. Note that this disables\nindexing with negative numbers.\n\nThe returned array has the same type as `a`.\n\nSee also\n\nTake elements using a boolean mask\n\nequivalent method\n\nTake elements by matching the array and the index arrays\n\nBy eliminating the inner loop in the description above, and using `s_` to\nbuild simple slice objects, `take` can be expressed in terms of applying fancy\nindexing to each 1-d slice:\n\nFor this reason, it is equivalent to (but faster than) the following use of\n`apply_along_axis`:\n\nIn this example if `a` is an ndarray, \u201cfancy\u201d indexing can be used.\n\nIf `indices` is not one dimensional, the output also has these dimensions.\n\n"}, {"name": "numpy.take_along_axis()", "path": "reference/generated/numpy.take_along_axis", "type": "numpy.take_along_axis", "text": "\nTake values from the input array by matching 1d index and data slices.\n\nThis iterates over matching 1d slices oriented along the specified axis in the\nindex and data arrays, and uses the former to look up values in the latter.\nThese slices can be different lengths.\n\nFunctions returning an index along an axis, like `argsort` and `argpartition`,\nproduce suitable indices for this function.\n\nNew in version 1.15.0.\n\nSource array\n\nIndices to take along each 1d slice of `arr`. This must match the dimension of\narr, but dimensions Ni and Nj only need to broadcast against `arr`.\n\nThe axis to take 1d slices along. If axis is None, the input array is treated\nas if it had first been flattened to 1d, for consistency with `sort` and\n`argsort`.\n\nThe indexed result.\n\nSee also\n\nTake along an axis, using the same indices for every 1d slice\n\nPut values into the destination array by matching 1d index and data slices\n\nThis is equivalent to (but faster than) the following use of `ndindex` and\n`s_`, which sets each of `ii` and `kk` to a tuple of indices:\n\nEquivalently, eliminating the inner loop, the last two lines would be:\n\nFor this sample array\n\nWe can sort either by using sort directly, or argsort and this function\n\nThe same works for max and min, if you expand the dimensions:\n\nIf we want to get the max and min at the same time, we can stack the indices\nfirst\n\n"}, {"name": "numpy.tan()", "path": "reference/generated/numpy.tan", "type": "numpy.tan", "text": "\nCompute tangent element-wise.\n\nEquivalent to `np.sin(x)/np.cos(x)` element-wise.\n\nInput array.\n\nA location into which the result is stored. If provided, it must have a shape\nthat the inputs broadcast to. If not provided or None, a freshly-allocated\narray is returned. A tuple (possible only as a keyword argument) must have\nlength equal to the number of outputs.\n\nThis condition is broadcast over the input. At locations where the condition\nis True, the `out` array will be set to the ufunc result. Elsewhere, the `out`\narray will retain its original value. Note that if an uninitialized `out`\narray is created via the default `out=None`, locations within it where the\ncondition is False will remain uninitialized.\n\nFor other keyword-only arguments, see the ufunc docs.\n\nThe corresponding tangent values. This is a scalar if `x` is a scalar.\n\nIf `out` is provided, the function writes the result into it, and returns a\nreference to `out`. (See Examples)\n\nM. Abramowitz and I. A. Stegun, Handbook of Mathematical Functions. New York,\nNY: Dover, 1972.\n\n"}, {"name": "numpy.tanh()", "path": "reference/generated/numpy.tanh", "type": "numpy.tanh", "text": "\nCompute hyperbolic tangent element-wise.\n\nEquivalent to `np.sinh(x)/np.cosh(x)` or `-1j * np.tan(1j*x)`.\n\nInput array.\n\nA location into which the result is stored. If provided, it must have a shape\nthat the inputs broadcast to. If not provided or None, a freshly-allocated\narray is returned. A tuple (possible only as a keyword argument) must have\nlength equal to the number of outputs.\n\nThis condition is broadcast over the input. At locations where the condition\nis True, the `out` array will be set to the ufunc result. Elsewhere, the `out`\narray will retain its original value. Note that if an uninitialized `out`\narray is created via the default `out=None`, locations within it where the\ncondition is False will remain uninitialized.\n\nFor other keyword-only arguments, see the ufunc docs.\n\nThe corresponding hyperbolic tangent values. This is a scalar if `x` is a\nscalar.\n\nIf `out` is provided, the function writes the result into it, and returns a\nreference to `out`. (See Examples)\n\nM. Abramowitz and I. A. Stegun, Handbook of Mathematical Functions. New York,\nNY: Dover, 1972, pg. 83. https://personal.math.ubc.ca/~cbm/aands/page_83.htm\n\nWikipedia, \u201cHyperbolic function\u201d,\nhttps://en.wikipedia.org/wiki/Hyperbolic_function\n\n"}, {"name": "numpy.tensordot()", "path": "reference/generated/numpy.tensordot", "type": "numpy.tensordot", "text": "\nCompute tensor dot product along specified axes.\n\nGiven two tensors, `a` and `b`, and an array_like object containing two\narray_like objects, `(a_axes, b_axes)`, sum the products of `a`\u2019s and `b`\u2019s\nelements (components) over the axes specified by `a_axes` and `b_axes`. The\nthird argument can be a single non-negative integer_like scalar, `N`; if it is\nsuch, then the last `N` dimensions of `a` and the first `N` dimensions of `b`\nare summed over.\n\nTensors to \u201cdot\u201d.\n\nThe tensor dot product of the input.\n\nSee also\n\nWhen `axes` is integer_like, the sequence for evaluation will be: first the\n-Nth axis in `a` and 0th axis in `b`, and the -1th axis in `a` and Nth axis in\n`b` last.\n\nWhen there is more than one axis to sum over - and they are not the last\n(first) axes of `a` (`b`) - the argument `axes` should consist of two\nsequences of the same length, with the first axis to sum over given first in\nboth sequences, the second axis second, and so forth.\n\nThe shape of the result consists of the non-contracted axes of the first\ntensor, followed by the non-contracted axes of the second.\n\nA \u201ctraditional\u201d example:\n\nAn extended example taking advantage of the overloading of + and *:\n\n"}, {"name": "numpy.testing.extbuild.build_and_import_extension()", "path": "reference/testing", "type": "Testing Guidelines", "text": "\nUntil the 1.15 release, NumPy used the nose testing framework, it now uses the\npytest framework. The older framework is still maintained in order to support\ndownstream projects that use the old numpy framework, but all tests for NumPy\nshould use pytest.\n\nOur goal is that every module and package in NumPy should have a thorough set\nof unit tests. These tests should exercise the full functionality of a given\nroutine as well as its robustness to erroneous or unexpected input arguments.\nWell-designed tests with good coverage make an enormous difference to the ease\nof refactoring. Whenever a new bug is found in a routine, you should write a\nnew test for that specific case and add it to the test suite to prevent that\nbug from creeping back in unnoticed.\n\nNote\n\nSciPy uses the testing framework from `numpy.testing`, so all of the NumPy\nexamples shown below are also applicable to SciPy\n\nNumPy can be tested in a number of ways, choose any way you feel comfortable.\n\nYou can test an installed NumPy by `numpy.test`, for example, To run NumPy\u2019s\nfull test suite, use the following:\n\nThe test method may take two or more arguments; the first `label` is a string\nspecifying what should be tested and the second `verbose` is an integer giving\nthe level of output verbosity. See the docstring `numpy.test` for details. The\ndefault value for `label` is \u2018fast\u2019 - which will run the standard tests. The\nstring \u2018full\u2019 will run the full battery of tests, including those identified\nas being slow to run. If `verbose` is 1 or less, the tests will just show\ninformation messages about the tests that are run; but if it is greater than\n1, then the tests will also provide warnings on missing tests. So if you want\nto run every test and get messages about which modules don\u2019t have tests:\n\nFinally, if you are only interested in testing a subset of NumPy, for example,\nthe `core` module, use the following:\n\nIf you want to build NumPy in order to work on NumPy itself, use\n`runtests.py`.To run NumPy\u2019s full test suite:\n\nTesting a subset of NumPy:\n\nFor detailed info on testing, see Testing builds\n\nRun tests using your favourite IDE such as vscode or pycharm\n\nIf you are writing a package that you\u2019d like to become part of NumPy, please\nwrite the tests as you develop the package. Every Python module, extension\nmodule, or subpackage in the NumPy package directory should have a\ncorresponding `test_<name>.py` file. Pytest examines these files for test\nmethods (named `test*`) and test classes (named `Test*`).\n\nSuppose you have a NumPy module `numpy/xxx/yyy.py` containing a function\n`zzz()`. To test this function you would create a test module called\n`test_yyy.py`. If you only need to test one aspect of `zzz`, you can simply\nadd a test function:\n\nMore often, we need to group a number of tests together, so we create a test\nclass:\n\nWithin these test methods, `assert` and related functions are used to test\nwhether a certain assumption is valid. If the assertion fails, the test fails.\n`pytest` internally rewrites the `assert` statement to give informative output\nwhen it fails, so should be preferred over the legacy variant\n`numpy.testing.assert_`. Whereas plain `assert` statements are ignored when\nrunning Python in optimized mode with `-O`, this is not an issue when running\ntests with pytest.\n\nSimilarly, the pytest functions `pytest.raises` and `pytest.warns` should be\npreferred over their legacy counterparts `numpy.testing.assert_raises` and\n`numpy.testing.assert_warns`, since the pytest variants are more broadly used\nand allow more explicit targeting of warnings and errors when used with the\n`match` regex.\n\nNote that `test_` functions or methods should not have a docstring, because\nthat makes it hard to identify the test from the output of running the test\nsuite with `verbose=2` (or similar verbosity setting). Use plain comments\n(`#`) if necessary.\n\nAlso since much of NumPy is legacy code that was originally written without\nunit tests, there are still several modules that don\u2019t have tests yet. Please\nfeel free to choose one of these modules and develop tests for it.\n\nNumPy exposes a rich C-API . These are tested using c-extension modules\nwritten \u201cas-if\u201d they know nothing about the internals of NumPy, rather using\nthe official C-API interfaces only. Examples of such modules are tests for a\nuser-defined `rational` dtype in `_rational_tests` or the ufunc machinery\ntests in `_umath_tests` which are part of the binary distribution. Starting\nfrom version 1.21, you can also write snippets of C code in tests that will be\ncompiled locally into c-extension modules and loaded into python.\n\nBuild and imports a c-extension module `modname` from a list of function\nfragments `functions`.\n\nEach fragment is a sequence of func_name, calling convention, snippet.\n\nCode to preceed the rest, usually extra `#include` or `#define` macros.\n\nWhere to build the module, usually a temporary directory\n\nExtra directories to find include files when compiling\n\nCode to appear in the module PyMODINIT_FUNC\n\nThe module will have been loaded and is ready for use\n\nUnlabeled tests like the ones above are run in the default `numpy.test()` run.\nIf you want to label your test as slow - and therefore reserved for a full\n`numpy.test(label='full')` run, you can label it with `pytest.mark.slow`:\n\nSimilarly for methods:\n\nTesting looks for module-level or class-level setup and teardown functions by\nname; thus:\n\nSetup and teardown functions to functions and methods are known as \u201cfixtures\u201d,\nand their use is not encouraged.\n\nOne very nice feature of testing is allowing easy testing across a range of\nparameters - a nasty problem for standard unit tests. Use the\n`pytest.mark.parametrize` decorator.\n\nDoctests are a convenient way of documenting the behavior of a function and\nallowing that behavior to be tested at the same time. The output of an\ninteractive Python session can be included in the docstring of a function, and\nthe test framework can run the example and compare the actual output to the\nexpected output.\n\nThe doctests can be run by adding the `doctests` argument to the `test()`\ncall; for example, to run all tests (including doctests) for numpy.lib:\n\nThe doctests are run as if they are in a fresh Python instance which has\nexecuted `import numpy as np`. Tests that are part of a NumPy subpackage will\nhave that subpackage already imported. E.g. for a test in\n`numpy/linalg/tests/`, the namespace will be created such that `from numpy\nimport linalg` has already executed.\n\nRather than keeping the code and the tests in the same directory, we put all\nthe tests for a given subpackage in a `tests/` subdirectory. For our example,\nif it doesn\u2019t already exist you will need to create a `tests/` directory in\n`numpy/xxx/`. So the path for `test_yyy.py` is `numpy/xxx/tests/test_yyy.py`.\n\nOnce the `numpy/xxx/tests/test_yyy.py` is written, its possible to run the\ntests by going to the `tests/` directory and typing:\n\nOr if you add `numpy/xxx/tests/` to the Python path, you could run the tests\ninteractively in the interpreter like this:\n\nUsually, however, adding the `tests/` directory to the python path isn\u2019t\ndesirable. Instead it would better to invoke the test straight from the module\n`xxx`. To this end, simply place the following lines at the end of your\npackage\u2019s `__init__.py` file:\n\nYou will also need to add the tests directory in the configuration section of\nyour setup.py:\n\nNow you can do the following to test your module:\n\nAlso, when invoking the entire NumPy test suite, your tests will be found and\nrun:\n\nIf you have a collection of tests that must be run multiple times with minor\nvariations, it can be helpful to create a base class containing all the common\ntests, and then create a subclass for each variation. Several examples of this\ntechnique exist in NumPy; below are excerpts from one in\nnumpy/linalg/tests/test_linalg.py:\n\nIn this case, we wanted to test solving a linear algebra problem using\nmatrices of several data types, using `linalg.solve` and `linalg.inv`. The\ncommon test cases (for single-precision, double-precision, etc. matrices) are\ncollected in `LinalgTestCase`.\n\nSometimes you might want to skip a test or mark it as a known failure, such as\nwhen the test suite is being written before the code it\u2019s meant to test, or if\na test only fails on a particular architecture.\n\nTo skip a test, simply use `skipif`:\n\nThe test is marked as skipped if `SkipMyTest` evaluates to nonzero, and the\nmessage in verbose test output is the second argument given to `skipif`.\nSimilarly, a test can be marked as a known failure by using `xfail`:\n\nOf course, a test can be unconditionally skipped or marked as a known failure\nby using `skip` or `xfail` without argument, respectively.\n\nA total of the number of skipped and known failing tests is displayed at the\nend of the test run. Skipped tests are marked as `'S'` in the test results (or\n`'SKIPPED'` for `verbose > 1`), and known failing tests are marked as `'x'`\n(or `'XFAIL'` if `verbose > 1`).\n\nTests on random data are good, but since test failures are meant to expose new\nbugs or regressions, a test that passes most of the time but fails\noccasionally with no code changes is not helpful. Make the random data\ndeterministic by setting the random number seed before generating it. Use\neither Python\u2019s `random.seed(some_number)` or NumPy\u2019s\n`numpy.random.seed(some_number)`, depending on the source of random numbers.\n\nAlternatively, you can use Hypothesis to generate arbitrary data. Hypothesis\nmanages both Python\u2019s and Numpy\u2019s random seeds for you, and provides a very\nconcise and powerful way to describe data (including `hypothesis.extra.numpy`,\ne.g. for a set of mutually-broadcastable shapes).\n\nThe advantages over random generation include tools to replay and share\nfailures without requiring a fixed seed, reporting minimal examples for each\nfailure, and better-than-naive-random techniques for triggering bugs.\n\nPytest test runner.\n\nA test function is typically added to a package\u2019s __init__.py like so:\n\nCalling this test function finds and runs all tests associated with the module\nand all its sub-modules.\n\nThe name of the module to test.\n\nUnlike the previous `nose`-based implementation, this class is not publicly\nexposed as it performs some `numpy`-specific warning suppression.\n\nFull path to the package to test.\n\n"}, {"name": "numpy.testing.suppress_warnings()", "path": "reference/generated/numpy.testing.suppress_warnings", "type": "numpy.testing.suppress_warnings", "text": "\nContext manager and decorator doing much the same as\n`warnings.catch_warnings`.\n\nHowever, it also provides a filter mechanism to work around\nhttps://bugs.python.org/issue4180.\n\nThis bug causes Python before 3.4 to not reliably show warnings again after\nthey have been ignored once (even within catch_warnings). It means that no\n\u201cignore\u201d filter can be used easily, since following tests might need to see\nthe warning. Additionally it allows easier specificity for testing warnings\nand can be nested.\n\nOne of \u201calways\u201d, \u201conce\u201d, \u201cmodule\u201d, or \u201clocation\u201d. Analogous to the usual\nwarnings module filter mode, it is useful to reduce noise mostly on the\noutmost level. Unsuppressed and unrecorded warnings will be forwarded based on\nthis rule. Defaults to \u201calways\u201d. \u201clocation\u201d is equivalent to the warnings\n\u201cdefault\u201d, match by exact location the warning warning originated from.\n\nFilters added inside the context manager will be discarded again when leaving\nit. Upon entering all filters defined outside a context will be applied\nautomatically.\n\nWhen a recording filter is added, matching warnings are stored in the `log`\nattribute as well as in the list returned by `record`.\n\nIf filters are added and the `module` keyword is given, the warning registry\nof this module will additionally be cleared when applying it, entering the\ncontext, or exiting it. This could cause warnings to appear a second time\nafter leaving the context if they were configured to be printed once (default)\nand were already printed before the context was entered.\n\nNesting this context manager will work as expected when the forwarding rule is\n\u201calways\u201d (default). Unfiltered and unrecorded warnings will be passed out and\nbe matched by the outer level. On the outmost level they will be printed (or\ncaught by another warnings context). The forwarding rule argument can modify\nthis behaviour.\n\nLike `catch_warnings` this context manager is not threadsafe.\n\nWith a context manager:\n\nOr as a decorator:\n\n`__call__`(func)\n\nFunction decorator to apply certain suppressions to a whole function.\n\n`filter`([category, message, module])\n\nAdd a new suppressing filter or apply it if the state is entered.\n\n`record`([category, message, module])\n\nAppend a new recording filter or apply it if the state is entered.\n\n"}, {"name": "numpy.testing.Tester", "path": "reference/generated/numpy.testing.tester", "type": "numpy.testing.Tester", "text": "\nalias of `numpy.testing._private.nosetester.NoseTester`\n\n"}, {"name": "numpy.tile()", "path": "reference/generated/numpy.tile", "type": "numpy.tile", "text": "\nConstruct an array by repeating A the number of times given by reps.\n\nIf `reps` has length `d`, the result will have dimension of `max(d, A.ndim)`.\n\nIf `A.ndim < d`, `A` is promoted to be d-dimensional by prepending new axes.\nSo a shape (3,) array is promoted to (1, 3) for 2-D replication, or shape (1,\n1, 3) for 3-D replication. If this is not the desired behavior, promote `A` to\nd-dimensions manually before calling this function.\n\nIf `A.ndim > d`, `reps` is promoted to `A`.ndim by pre-pending 1\u2019s to it. Thus\nfor an `A` of shape (2, 3, 4, 5), a `reps` of (2, 2) is treated as (1, 1, 2,\n2).\n\nNote : Although tile may be used for broadcasting, it is strongly recommended\nto use numpy\u2019s broadcasting operations and functions.\n\nThe input array.\n\nThe number of repetitions of `A` along each axis.\n\nThe tiled output array.\n\nSee also\n\nRepeat elements of an array.\n\nBroadcast an array to a new shape\n\n"}, {"name": "numpy.timedelta64", "path": "reference/arrays.scalars#numpy.timedelta64", "type": "Scalars", "text": "\nA timedelta stored as a 64-bit integer.\n\nSee Datetimes and Timedeltas for more information.\n\n`'m'`\n\n"}, {"name": "numpy.trace()", "path": "reference/generated/numpy.trace", "type": "numpy.trace", "text": "\nReturn the sum along diagonals of the array.\n\nIf `a` is 2-D, the sum along its diagonal with the given offset is returned,\ni.e., the sum of elements `a[i,i+offset]` for all i.\n\nIf `a` has more than two dimensions, then the axes specified by axis1 and\naxis2 are used to determine the 2-D sub-arrays whose traces are returned. The\nshape of the resulting array is the same as that of `a` with `axis1` and\n`axis2` removed.\n\nInput array, from which the diagonals are taken.\n\nOffset of the diagonal from the main diagonal. Can be both positive and\nnegative. Defaults to 0.\n\nAxes to be used as the first and second axis of the 2-D sub-arrays from which\nthe diagonals should be taken. Defaults are the first two axes of `a`.\n\nDetermines the data-type of the returned array and of the accumulator where\nthe elements are summed. If dtype has the value None and `a` is of integer\ntype of precision less than the default integer precision, then the default\ninteger precision is used. Otherwise, the precision is the same as that of\n`a`.\n\nArray into which the output is placed. Its type is preserved and it must be of\nthe right shape to hold the output.\n\nIf `a` is 2-D, the sum along the diagonal is returned. If `a` has larger\ndimensions, then an array of sums along diagonals is returned.\n\nSee also\n\n"}, {"name": "numpy.transpose()", "path": "reference/generated/numpy.transpose", "type": "numpy.transpose", "text": "\nReverse or permute the axes of an array; returns the modified array.\n\nFor an array a with two axes, transpose(a) gives the matrix transpose.\n\nRefer to `numpy.ndarray.transpose` for full documentation.\n\nInput array.\n\nIf specified, it must be a tuple or list which contains a permutation of\n[0,1,..,N-1] where N is the number of axes of a. The i\u2019th axis of the returned\narray will correspond to the axis numbered `axes[i]` of the input. If not\nspecified, defaults to `range(a.ndim)[::-1]`, which reverses the order of the\naxes.\n\n`a` with its axes permuted. A view is returned whenever possible.\n\nSee also\n\nEquivalent method\n\nUse `transpose(a, argsort(axes))` to invert the transposition of tensors when\nusing the `axes` keyword argument.\n\nTransposing a 1-D array returns an unchanged view of the original array.\n\n"}, {"name": "numpy.trapz()", "path": "reference/generated/numpy.trapz", "type": "numpy.trapz", "text": "\nIntegrate along the given axis using the composite trapezoidal rule.\n\nIf `x` is provided, the integration happens in sequence along its elements -\nthey are not sorted.\n\nIntegrate `y` (`x`) along each 1d slice on the given axis, compute \\\\(\\int\ny(x) dx\\\\). When `x` is specified, this integrates along the parametric curve,\ncomputing \\\\(\\int_t y(t) dt = \\int_t y(t) \\left.\\frac{dx}{dt}\\right|_{x=x(t)}\ndt\\\\).\n\nInput array to integrate.\n\nThe sample points corresponding to the `y` values. If `x` is None, the sample\npoints are assumed to be evenly spaced `dx` apart. The default is None.\n\nThe spacing between sample points when `x` is None. The default is 1.\n\nThe axis along which to integrate.\n\nDefinite integral of \u2018y\u2019 = n-dimensional array as approximated along a single\naxis by the trapezoidal rule. If \u2018y\u2019 is a 1-dimensional array, then the result\nis a float. If \u2018n\u2019 is greater than 1, then the result is an \u2018n-1\u2019 dimensional\narray.\n\nSee also\n\nImage [2] illustrates trapezoidal rule \u2013 y-axis locations of points will be\ntaken from `y` array, by default x-axis distances between points will be 1.0,\nalternatively they can be provided with `x` array or with `dx` scalar. Return\nvalue will be equal to combined area under the red lines.\n\nWikipedia page: https://en.wikipedia.org/wiki/Trapezoidal_rule\n\nIllustration image:\nhttps://en.wikipedia.org/wiki/File:Composite_trapezoidal_rule_illustration.png\n\nUsing a decreasing `x` corresponds to integrating in reverse:\n\nMore generally `x` is used to integrate along a parametric curve. This finds\nthe area of a circle, noting we repeat the sample which closes the curve:\n\n"}, {"name": "numpy.tri()", "path": "reference/generated/numpy.tri", "type": "numpy.tri", "text": "\nAn array with ones at and below the given diagonal and zeros elsewhere.\n\nNumber of rows in the array.\n\nNumber of columns in the array. By default, `M` is taken equal to `N`.\n\nThe sub-diagonal at and below which the array is filled. `k` = 0 is the main\ndiagonal, while `k` < 0 is below it, and `k` > 0 is above. The default is 0.\n\nData type of the returned array. The default is float.\n\nReference object to allow the creation of arrays which are not NumPy arrays.\nIf an array-like passed in as `like` supports the `__array_function__`\nprotocol, the result will be defined by it. In this case, it ensures the\ncreation of an array object compatible with that passed in via this argument.\n\nNew in version 1.20.0.\n\nArray with its lower triangle filled with ones and zero elsewhere; in other\nwords `T[i,j] == 1` for `j <= i + k`, 0 otherwise.\n\n"}, {"name": "numpy.tril()", "path": "reference/generated/numpy.tril", "type": "numpy.tril", "text": "\nLower triangle of an array.\n\nReturn a copy of an array with elements above the `k`-th diagonal zeroed. For\narrays with `ndim` exceeding 2, `tril` will apply to the final two axes.\n\nInput array.\n\nDiagonal above which to zero elements. `k = 0` (the default) is the main\ndiagonal, `k < 0` is below it and `k > 0` is above.\n\nLower triangle of `m`, of same shape and data-type as `m`.\n\nSee also\n\nsame thing, only for the upper triangle\n\n"}, {"name": "numpy.tril_indices()", "path": "reference/generated/numpy.tril_indices", "type": "numpy.tril_indices", "text": "\nReturn the indices for the lower-triangle of an (n, m) array.\n\nThe row dimension of the arrays for which the returned indices will be valid.\n\nDiagonal offset (see `tril` for details).\n\nNew in version 1.9.0.\n\nThe column dimension of the arrays for which the returned arrays will be\nvalid. By default `m` is taken equal to `n`.\n\nThe indices for the triangle. The returned tuple contains two arrays, each\nwith the indices along one dimension of the array.\n\nSee also\n\nsimilar function, for upper-triangular.\n\ngeneric function accepting an arbitrary mask function.\n\nNew in version 1.4.0.\n\nCompute two different sets of indices to access 4x4 arrays, one for the lower\ntriangular part starting at the main diagonal, and one starting two diagonals\nfurther right:\n\nHere is how they can be used with a sample array:\n\nBoth for indexing:\n\nAnd for assigning values:\n\nThese cover almost the whole array (two diagonals right of the main one):\n\n"}, {"name": "numpy.tril_indices_from()", "path": "reference/generated/numpy.tril_indices_from", "type": "numpy.tril_indices_from", "text": "\nReturn the indices for the lower-triangle of arr.\n\nSee `tril_indices` for full details.\n\nThe indices will be valid for square arrays whose dimensions are the same as\narr.\n\nDiagonal offset (see `tril` for details).\n\nSee also\n\nNew in version 1.4.0.\n\n"}, {"name": "numpy.trim_zeros()", "path": "reference/generated/numpy.trim_zeros", "type": "numpy.trim_zeros", "text": "\nTrim the leading and/or trailing zeros from a 1-D array or sequence.\n\nInput array.\n\nA string with \u2018f\u2019 representing trim from front and \u2018b\u2019 to trim from back.\nDefault is \u2018fb\u2019, trim zeros from both front and back of the array.\n\nThe result of trimming the input. The input data type is preserved.\n\nThe input data type is preserved, list/tuple in means list/tuple out.\n\n"}, {"name": "numpy.triu()", "path": "reference/generated/numpy.triu", "type": "numpy.triu", "text": "\nUpper triangle of an array.\n\nReturn a copy of an array with the elements below the `k`-th diagonal zeroed.\nFor arrays with `ndim` exceeding 2, `triu` will apply to the final two axes.\n\nPlease refer to the documentation for `tril` for further details.\n\nSee also\n\nlower triangle of an array\n\n"}, {"name": "numpy.triu_indices()", "path": "reference/generated/numpy.triu_indices", "type": "numpy.triu_indices", "text": "\nReturn the indices for the upper-triangle of an (n, m) array.\n\nThe size of the arrays for which the returned indices will be valid.\n\nDiagonal offset (see `triu` for details).\n\nNew in version 1.9.0.\n\nThe column dimension of the arrays for which the returned arrays will be\nvalid. By default `m` is taken equal to `n`.\n\nThe indices for the triangle. The returned tuple contains two arrays, each\nwith the indices along one dimension of the array. Can be used to slice a\nndarray of shape(`n`, `n`).\n\nSee also\n\nsimilar function, for lower-triangular.\n\ngeneric function accepting an arbitrary mask function.\n\nNew in version 1.4.0.\n\nCompute two different sets of indices to access 4x4 arrays, one for the upper\ntriangular part starting at the main diagonal, and one starting two diagonals\nfurther right:\n\nHere is how they can be used with a sample array:\n\nBoth for indexing:\n\nAnd for assigning values:\n\nThese cover only a small part of the whole array (two diagonals right of the\nmain one):\n\n"}, {"name": "numpy.triu_indices_from()", "path": "reference/generated/numpy.triu_indices_from", "type": "numpy.triu_indices_from", "text": "\nReturn the indices for the upper-triangle of arr.\n\nSee `triu_indices` for full details.\n\nThe indices will be valid for square arrays.\n\nDiagonal offset (see `triu` for details).\n\nIndices for the upper-triangle of `arr`.\n\nSee also\n\nNew in version 1.4.0.\n\n"}, {"name": "numpy.true_divide()", "path": "reference/generated/numpy.true_divide", "type": "numpy.true_divide", "text": "\nReturns a true division of the inputs, element-wise.\n\nUnlike \u2018floor division\u2019, true division adjusts the output type to present the\nbest answer, regardless of input types.\n\nDividend array.\n\nDivisor array. If `x1.shape != x2.shape`, they must be broadcastable to a\ncommon shape (which becomes the shape of the output).\n\nA location into which the result is stored. If provided, it must have a shape\nthat the inputs broadcast to. If not provided or None, a freshly-allocated\narray is returned. A tuple (possible only as a keyword argument) must have\nlength equal to the number of outputs.\n\nThis condition is broadcast over the input. At locations where the condition\nis True, the `out` array will be set to the ufunc result. Elsewhere, the `out`\narray will retain its original value. Note that if an uninitialized `out`\narray is created via the default `out=None`, locations within it where the\ncondition is False will remain uninitialized.\n\nFor other keyword-only arguments, see the ufunc docs.\n\nThis is a scalar if both `x1` and `x2` are scalars.\n\nIn Python, `//` is the floor division operator and `/` the true division\noperator. The `true_divide(x1, x2)` function is equivalent to true division in\nPython.\n\nThe `/` operator can be used as a shorthand for `np.true_divide` on ndarrays.\n\n"}, {"name": "numpy.trunc()", "path": "reference/generated/numpy.trunc", "type": "numpy.trunc", "text": "\nReturn the truncated value of the input, element-wise.\n\nThe truncated value of the scalar `x` is the nearest integer `i` which is\ncloser to zero than `x` is. In short, the fractional part of the signed number\n`x` is discarded.\n\nInput data.\n\nA location into which the result is stored. If provided, it must have a shape\nthat the inputs broadcast to. If not provided or None, a freshly-allocated\narray is returned. A tuple (possible only as a keyword argument) must have\nlength equal to the number of outputs.\n\nThis condition is broadcast over the input. At locations where the condition\nis True, the `out` array will be set to the ufunc result. Elsewhere, the `out`\narray will retain its original value. Note that if an uninitialized `out`\narray is created via the default `out=None`, locations within it where the\ncondition is False will remain uninitialized.\n\nFor other keyword-only arguments, see the ufunc docs.\n\nThe truncated value of each element in `x`. This is a scalar if `x` is a\nscalar.\n\nSee also\n\nNew in version 1.3.0.\n\n"}, {"name": "numpy.typename()", "path": "reference/generated/numpy.typename", "type": "numpy.typename", "text": "\nReturn a description for the given data type code.\n\nData type code.\n\nDescription of the input data type code.\n\nSee also\n\n"}, {"name": "numpy.typing.ArrayLike", "path": "reference/typing", "type": "Typing ( \n    \n     numpy.typing\n    \n    )", "text": "\nNew in version 1.20.\n\nLarge parts of the NumPy API have PEP-484-style type annotations. In addition\na number of type aliases are available to users, most prominently the two\nbelow:\n\nNew in version 1.21.\n\nA mypy plugin for managing a number of platform-specific annotations. Its\nfunctionality can be split into three distinct parts:\n\nAssigning the (platform-dependent) precision of `c_intp`. Without the plugin\nthe type will default to `ctypes.c_int64`.\n\nNew in version 1.22.\n\nTo enable the plugin, one must add it to their mypy configuration file:\n\nNumPy is very flexible. Trying to describe the full range of possibilities\nstatically would result in types that are not very helpful. For that reason,\nthe typed NumPy API is often stricter than the runtime NumPy API. This section\ndescribes some notable differences.\n\nThe `ArrayLike` type tries to avoid creating object arrays. For example,\n\nis valid NumPy code which will create a 0-dimensional object array. Type\ncheckers will complain about the above example when using the NumPy types\nhowever. If you really intended to do the above, then you can either use a `#\ntype: ignore` comment:\n\nor explicitly type the array like object as `Any`:\n\nIt\u2019s possible to mutate the dtype of an array at runtime. For example, the\nfollowing code is valid:\n\nThis sort of mutation is not allowed by the types. Users who want to write\nstatically typed code should instead use the `numpy.ndarray.view` method to\ncreate a view of the array with a different dtype.\n\nThe `DTypeLike` type tries to avoid creation of dtype objects using dictionary\nof fields like below:\n\nAlthough this is valid NumPy code, the type checker will complain about it,\nsince its usage is discouraged. Please see : Data type objects\n\nThe precision of `numpy.number` subclasses is treated as a covariant generic\nparameter (see `NBitBase`), simplifying the annotating of processes involving\nprecision-based casting.\n\nConsequently, the likes of `float16`, `float32` and `float64` are still sub-\ntypes of `floating`, but, contrary to runtime, they\u2019re not necessarily\nconsidered as sub-classes.\n\nThe `timedelta64` class is not considered a subclass of `signedinteger`, the\nformer only inheriting from `generic` while static type checking.\n\nDuring runtime numpy aggressively casts any passed 0D arrays into their\ncorresponding `generic` instance. Until the introduction of shape typing (see\nPEP 646) it is unfortunately not possible to make the necessary distinction\nbetween 0D and >0D arrays. While thus not strictly correct, all operations are\nthat can potentially perform a 0D-array -> scalar cast are currently annotated\nas exclusively returning an `ndarray`.\n\nIf it is known in advance that an operation _will_ perform a 0D-array ->\nscalar cast, then one can consider manually remedying the situation with\neither `typing.cast` or a `# type: ignore` comment.\n\nThe dtype of `numpy.recarray`, and the `numpy.rec` functions in general, can\nbe specified in one of two ways:\n\nThese two approaches are currently typed as being mutually exclusive, i.e. if\n`dtype` is specified than one may not specify `formats`. While this mutual\nexclusivity is not (strictly) enforced during runtime, combining both dtype\nspecifiers can lead to unexpected or even downright buggy behavior.\n\nA `Union` representing objects that can be coerced into an `ndarray`.\n\nAmong others this includes the likes of:\n\nNew in version 1.20.\n\nSee Also\n\nAny scalar or sequence that can be interpreted as an ndarray.\n\nA `Union` representing objects that can be coerced into a `dtype`.\n\nAmong others this includes the likes of:\n\nNew in version 1.20.\n\nSee Also\n\nA comprehensive overview of all objects that can be coerced into data types.\n\nA generic version of `np.ndarray[Any, np.dtype[+ScalarType]]`.\n\nCan be used during runtime for typing arrays with a given dtype and\nunspecified shape.\n\nNew in version 1.21.\n\nA type representing `numpy.number` precision during static type checking.\n\nUsed exclusively for the purpose static type checking, `NBitBase` represents\nthe base of a hierarchical set of subclasses. Each subsequent subclass is\nherein used for representing a lower level of precision, e.g. `64Bit > 32Bit >\n16Bit`.\n\nNew in version 1.20.\n\nBelow is a typical usage example: `NBitBase` is herein used for annotating a\nfunction that takes a float and integer of arbitrary precision as arguments\nand returns a new float of whichever precision is largest (e.g. `np.float16 +\nnp.int64 -> np.float64`).\n\n"}, {"name": "numpy.typing.DTypeLike", "path": "reference/typing#numpy.typing.DTypeLike", "type": "Typing ( \n    \n     numpy.typing\n    \n    )", "text": "\nA `Union` representing objects that can be coerced into a `dtype`.\n\nAmong others this includes the likes of:\n\nNew in version 1.20.\n\nSee Also\n\nA comprehensive overview of all objects that can be coerced into data types.\n\n"}, {"name": "numpy.typing.NDArray", "path": "reference/typing#numpy.typing.NDArray", "type": "Typing ( \n    \n     numpy.typing\n    \n    )", "text": "\nA generic version of `np.ndarray[Any, np.dtype[+ScalarType]]`.\n\nCan be used during runtime for typing arrays with a given dtype and\nunspecified shape.\n\nNew in version 1.21.\n\n"}, {"name": "numpy.ubyte", "path": "reference/arrays.scalars#numpy.ubyte", "type": "Scalars", "text": "\nUnsigned integer type, compatible with C `unsigned char`.\n\n`'B'`\n\n`numpy.uint8`: 8-bit unsigned integer (`0` to `255`).\n\n"}, {"name": "numpy.ufunc", "path": "reference/generated/numpy.ufunc", "type": "numpy.ufunc", "text": "\nFunctions that operate element by element on whole arrays.\n\nTo see the documentation for a specific ufunc, use `info`. For example,\n`np.info(np.sin)`. Because ufuncs are written in C (for speed) and linked into\nPython with NumPy\u2019s ufunc facility, Python\u2019s help() function finds this page\nwhenever help() is called on a ufunc.\n\nA detailed explanation of ufuncs can be found in the docs for Universal\nfunctions (ufunc).\n\nCalling ufuncs: `op(*x[, out], where=True, **kwargs)`\n\nApply `op` to the arguments `*x` elementwise, broadcasting the arguments.\n\nThe broadcasting rules are:\n\nInput arrays.\n\nAlternate array object(s) in which to put the result; if provided, it must\nhave a shape that the inputs broadcast to. A tuple of arrays (possible only as\na keyword argument) must have length equal to the number of outputs; use None\nfor uninitialized outputs to be allocated by the ufunc.\n\nThis condition is broadcast over the input. At locations where the condition\nis True, the `out` array will be set to the ufunc result. Elsewhere, the `out`\narray will retain its original value. Note that if an uninitialized `out`\narray is created via the default `out=None`, locations within it where the\ncondition is False will remain uninitialized.\n\nFor other keyword-only arguments, see the ufunc docs.\n\n`r` will have the shape that the arrays in `x` broadcast to; if `out` is\nprovided, it will be returned. If not, `r` will be allocated and may contain\nuninitialized values. If the function has more than one output, then the\nresult will be a tuple of arrays.\n\nThe identity value.\n\nThe number of arguments.\n\nThe number of inputs.\n\nThe number of outputs.\n\nThe number of types.\n\nDefinition of the core elements a generalized ufunc operates on.\n\nReturns a list with types grouped input->output.\n\n`__call__`(*args, **kwargs)\n\nCall self as a function.\n\n`accumulate`(array[, axis, dtype, out])\n\nAccumulate the result of applying the operator to all elements.\n\n`at`(a, indices[, b])\n\nPerforms unbuffered in place operation on operand 'a' for elements specified\nby 'indices'.\n\n`outer`(A, B, /, **kwargs)\n\nApply the ufunc `op` to all pairs (a, b) with a in `A` and b in `B`.\n\n`reduce`(array[, axis, dtype, out, keepdims, ...])\n\nReduces `array`'s dimension by one, by applying ufunc along one axis.\n\n`reduceat`(array, indices[, axis, dtype, out])\n\nPerforms a (local) reduce with specified slices over a single axis.\n\n"}, {"name": "numpy.uint", "path": "reference/arrays.scalars#numpy.uint", "type": "Scalars", "text": "\nUnsigned integer type, compatible with C `unsigned long`.\n\n`'L'`\n\n`numpy.uint64`: 64-bit unsigned integer (`0` to `18_446_744_073_709_551_615`).\n\n`numpy.uintp`: Unsigned integer large enough to fit pointer, compatible with C\n`uintptr_t`.\n\n"}, {"name": "numpy.uint16", "path": "reference/arrays.scalars#numpy.uint16", "type": "Scalars", "text": "\nAlias for the unsigned integer types (one of `numpy.ubyte`, `numpy.ushort`,\n`numpy.uintc`, `numpy.uint` and `numpy.ulonglong`) with the specified number\nof bits.\n\nCompatible with the C99 `uint8_t`, `uint16_t`, `uint32_t`, and `uint64_t`,\nrespectively.\n\n"}, {"name": "numpy.uint32", "path": "reference/arrays.scalars#numpy.uint32", "type": "Scalars", "text": "\nAlias for the unsigned integer types (one of `numpy.ubyte`, `numpy.ushort`,\n`numpy.uintc`, `numpy.uint` and `numpy.ulonglong`) with the specified number\nof bits.\n\nCompatible with the C99 `uint8_t`, `uint16_t`, `uint32_t`, and `uint64_t`,\nrespectively.\n\n"}, {"name": "numpy.uint64", "path": "reference/arrays.scalars#numpy.uint64", "type": "Scalars", "text": "\nAlias for the unsigned integer types (one of `numpy.ubyte`, `numpy.ushort`,\n`numpy.uintc`, `numpy.uint` and `numpy.ulonglong`) with the specified number\nof bits.\n\nCompatible with the C99 `uint8_t`, `uint16_t`, `uint32_t`, and `uint64_t`,\nrespectively.\n\n"}, {"name": "numpy.uint8", "path": "reference/arrays.scalars#numpy.uint8", "type": "Scalars", "text": "\nAlias for the unsigned integer types (one of `numpy.ubyte`, `numpy.ushort`,\n`numpy.uintc`, `numpy.uint` and `numpy.ulonglong`) with the specified number\nof bits.\n\nCompatible with the C99 `uint8_t`, `uint16_t`, `uint32_t`, and `uint64_t`,\nrespectively.\n\n"}, {"name": "numpy.uintc", "path": "reference/arrays.scalars#numpy.uintc", "type": "Scalars", "text": "\nUnsigned integer type, compatible with C `unsigned int`.\n\n`'I'`\n\n`numpy.uint32`: 32-bit unsigned integer (`0` to `4_294_967_295`).\n\n"}, {"name": "numpy.uintp", "path": "reference/arrays.scalars#numpy.uintp", "type": "Scalars", "text": "\nAlias for the unsigned integer type (one of `numpy.ubyte`, `numpy.ushort`,\n`numpy.uintc`, `numpy.uint` and `np.ulonglong`) that is the same size as a\npointer.\n\nCompatible with the C `uintptr_t`.\n\n`'P'`\n\n"}, {"name": "numpy.ulonglong", "path": "reference/arrays.scalars#numpy.ulonglong", "type": "Scalars", "text": "\nSigned integer type, compatible with C `unsigned long long`.\n\n`'Q'`\n\n"}, {"name": "numpy.unicode_", "path": "reference/arrays.scalars#numpy.unicode_", "type": "Scalars", "text": "\nalias of `numpy.str_`\n\n"}, {"name": "numpy.union1d()", "path": "reference/generated/numpy.union1d", "type": "numpy.union1d", "text": "\nFind the union of two arrays.\n\nReturn the unique, sorted array of values that are in either of the two input\narrays.\n\nInput arrays. They are flattened if they are not already 1D.\n\nUnique, sorted union of the input arrays.\n\nSee also\n\nModule with a number of other functions for performing set operations on\narrays.\n\nTo find the union of more than two arrays, use functools.reduce:\n\n"}, {"name": "numpy.unique()", "path": "reference/generated/numpy.unique", "type": "numpy.unique", "text": "\nFind the unique elements of an array.\n\nReturns the sorted unique elements of an array. There are three optional\noutputs in addition to the unique elements:\n\nInput array. Unless `axis` is specified, this will be flattened if it is not\nalready 1-D.\n\nIf True, also return the indices of `ar` (along the specified axis, if\nprovided, or in the flattened array) that result in the unique array.\n\nIf True, also return the indices of the unique array (for the specified axis,\nif provided) that can be used to reconstruct `ar`.\n\nIf True, also return the number of times each unique item appears in `ar`.\n\nNew in version 1.9.0.\n\nThe axis to operate on. If None, `ar` will be flattened. If an integer, the\nsubarrays indexed by the given axis will be flattened and treated as the\nelements of a 1-D array with the dimension of the given axis, see the notes\nfor more details. Object arrays or structured arrays that contain objects are\nnot supported if the `axis` kwarg is used. The default is None.\n\nNew in version 1.13.0.\n\nThe sorted unique values.\n\nThe indices of the first occurrences of the unique values in the original\narray. Only provided if `return_index` is True.\n\nThe indices to reconstruct the original array from the unique array. Only\nprovided if `return_inverse` is True.\n\nThe number of times each of the unique values comes up in the original array.\nOnly provided if `return_counts` is True.\n\nNew in version 1.9.0.\n\nSee also\n\nModule with a number of other functions for performing set operations on\narrays.\n\nRepeat elements of an array.\n\nWhen an axis is specified the subarrays indexed by the axis are sorted. This\nis done by making the specified axis the first dimension of the array (move\nthe axis to the first dimension to keep the order of the other axes) and then\nflattening the subarrays in C order. The flattened subarrays are then viewed\nas a structured type with each element given a label, with the effect that we\nend up with a 1-D array of structured types that can be treated in the same\nway as any other 1-D array. The result is that the flattened subarrays are\nsorted in lexicographic order starting with the first element.\n\nReturn the unique rows of a 2D array\n\nReturn the indices of the original array that give the unique values:\n\nReconstruct the input array from the unique values and inverse:\n\nReconstruct the input values from the unique values and counts:\n\n"}, {"name": "numpy.unpackbits()", "path": "reference/generated/numpy.unpackbits", "type": "numpy.unpackbits", "text": "\nUnpacks elements of a uint8 array into a binary-valued output array.\n\nEach element of `a` represents a bit-field that should be unpacked into a\nbinary-valued output array. The shape of the output array is either 1-D (if\n`axis` is `None`) or the same shape as the input array with unpacking done\nalong the axis specified.\n\nInput array.\n\nThe dimension over which bit-unpacking is done. `None` implies unpacking the\nflattened array.\n\nThe number of elements to unpack along `axis`, provided as a way of undoing\nthe effect of packing a size that is not a multiple of eight. A non-negative\nnumber means to only unpack `count` bits. A negative number means to trim off\nthat many bits from the end. `None` means to unpack the entire array (the\ndefault). Counts larger than the available number of bits will add zero\npadding to the output. Negative counts must not exceed the available number of\nbits.\n\nNew in version 1.17.0.\n\nThe order of the returned bits. \u2018big\u2019 will mimic bin(val), `3 = 0b00000011 =>\n[0, 0, 0, 0, 0, 0, 1, 1]`, \u2018little\u2019 will reverse the order to `[1, 1, 0, 0, 0,\n0, 0, 0]`. Defaults to \u2018big\u2019.\n\nNew in version 1.17.0.\n\nThe elements are binary-valued (0 or 1).\n\nSee also\n\nPacks the elements of a binary-valued array into bits in a uint8 array.\n\n"}, {"name": "numpy.unravel_index()", "path": "reference/generated/numpy.unravel_index", "type": "numpy.unravel_index", "text": "\nConverts a flat index or array of flat indices into a tuple of coordinate\narrays.\n\nAn integer array whose elements are indices into the flattened version of an\narray of dimensions `shape`. Before version 1.6.0, this function accepted just\none index value.\n\nThe shape of the array to use for unraveling `indices`.\n\nChanged in version 1.16.0: Renamed from `dims` to `shape`.\n\nDetermines whether the indices should be viewed as indexing in row-major\n(C-style) or column-major (Fortran-style) order.\n\nNew in version 1.6.0.\n\nEach array in the tuple has the same shape as the `indices` array.\n\nSee also\n\n"}, {"name": "numpy.unwrap()", "path": "reference/generated/numpy.unwrap", "type": "numpy.unwrap", "text": "\nUnwrap by taking the complement of large deltas with respect to the period.\n\nThis unwraps a signal `p` by changing elements which have an absolute\ndifference from their predecessor of more than `max(discont, period/2)` to\ntheir `period`-complementary values.\n\nFor the default case where `period` is \\\\(2\\pi\\\\) and `discont` is \\\\(\\pi\\\\),\nthis unwraps a radian phase `p` such that adjacent differences are never\ngreater than \\\\(\\pi\\\\) by adding \\\\(2k\\pi\\\\) for some integer \\\\(k\\\\).\n\nInput array.\n\nMaximum discontinuity between values, default is `period/2`. Values below\n`period/2` are treated as if they were `period/2`. To have an effect different\nfrom the default, `discont` should be larger than `period/2`.\n\nAxis along which unwrap will operate, default is the last axis.\n\nSize of the range over which the input wraps. By default, it is `2 pi`.\n\nNew in version 1.21.0.\n\nOutput array.\n\nSee also\n\nIf the discontinuity in `p` is smaller than `period/2`, but larger than\n`discont`, no unwrapping is done because taking the complement would only make\nthe discontinuity larger.\n\n"}, {"name": "numpy.ushort", "path": "reference/arrays.scalars#numpy.ushort", "type": "Scalars", "text": "\nUnsigned integer type, compatible with C `unsigned short`.\n\n`'H'`\n\n`numpy.uint16`: 16-bit unsigned integer (`0` to `65_535`).\n\n"}, {"name": "numpy.vander()", "path": "reference/generated/numpy.vander", "type": "numpy.vander", "text": "\nGenerate a Vandermonde matrix.\n\nThe columns of the output matrix are powers of the input vector. The order of\nthe powers is determined by the `increasing` boolean argument. Specifically,\nwhen `increasing` is False, the `i`-th output column is the input vector\nraised element-wise to the power of `N - i - 1`. Such a matrix with a\ngeometric progression in each row is named for Alexandre- Theophile\nVandermonde.\n\n1-D input array.\n\nNumber of columns in the output. If `N` is not specified, a square array is\nreturned (`N = len(x)`).\n\nOrder of the powers of the columns. If True, the powers increase from left to\nright, if False (the default) they are reversed.\n\nNew in version 1.9.0.\n\nVandermonde matrix. If `increasing` is False, the first column is `x^(N-1)`,\nthe second `x^(N-2)` and so forth. If `increasing` is True, the columns are\n`x^0, x^1, ..., x^(N-1)`.\n\nSee also\n\nThe determinant of a square Vandermonde matrix is the product of the\ndifferences between the values of the input vector:\n\n"}, {"name": "numpy.var()", "path": "reference/generated/numpy.var", "type": "numpy.var", "text": "\nCompute the variance along the specified axis.\n\nReturns the variance of the array elements, a measure of the spread of a\ndistribution. The variance is computed for the flattened array by default,\notherwise over the specified axis.\n\nArray containing numbers whose variance is desired. If `a` is not an array, a\nconversion is attempted.\n\nAxis or axes along which the variance is computed. The default is to compute\nthe variance of the flattened array.\n\nNew in version 1.7.0.\n\nIf this is a tuple of ints, a variance is performed over multiple axes,\ninstead of a single axis or all the axes as before.\n\nType to use in computing the variance. For arrays of integer type the default\nis `float64`; for arrays of float types it is the same as the array type.\n\nAlternate output array in which to place the result. It must have the same\nshape as the expected output, but the type is cast if necessary.\n\n\u201cDelta Degrees of Freedom\u201d: the divisor used in the calculation is `N - ddof`,\nwhere `N` represents the number of elements. By default `ddof` is zero.\n\nIf this is set to True, the axes which are reduced are left in the result as\ndimensions with size one. With this option, the result will broadcast\ncorrectly against the input array.\n\nIf the default value is passed, then `keepdims` will not be passed through to\nthe `var` method of sub-classes of `ndarray`, however any non-default value\nwill be. If the sub-class\u2019 method does not implement `keepdims` any exceptions\nwill be raised.\n\nElements to include in the variance. See `reduce` for details.\n\nNew in version 1.20.0.\n\nIf `out=None`, returns a new array containing the variance; otherwise, a\nreference to the output array is returned.\n\nSee also\n\nThe variance is the average of the squared deviations from the mean, i.e.,\n`var = mean(x)`, where `x = abs(a - a.mean())**2`.\n\nThe mean is typically calculated as `x.sum() / N`, where `N = len(x)`. If,\nhowever, `ddof` is specified, the divisor `N - ddof` is used instead. In\nstandard statistical practice, `ddof=1` provides an unbiased estimator of the\nvariance of a hypothetical infinite population. `ddof=0` provides a maximum\nlikelihood estimate of the variance for normally distributed variables.\n\nNote that for complex numbers, the absolute value is taken before squaring, so\nthat the result is always real and nonnegative.\n\nFor floating-point input, the variance is computed using the same precision\nthe input has. Depending on the input data, this can cause the results to be\ninaccurate, especially for `float32` (see example below). Specifying a higher-\naccuracy accumulator using the `dtype` keyword can alleviate this issue.\n\nIn single precision, var() can be inaccurate:\n\nComputing the variance in float64 is more accurate:\n\nSpecifying a where argument:\n\n"}, {"name": "numpy.vdot()", "path": "reference/generated/numpy.vdot", "type": "numpy.vdot", "text": "\nReturn the dot product of two vectors.\n\nThe vdot(`a`, `b`) function handles complex numbers differently than dot(`a`,\n`b`). If the first argument is complex the complex conjugate of the first\nargument is used for the calculation of the dot product.\n\nNote that `vdot` handles multidimensional arrays differently than `dot`: it\ndoes not perform a matrix product, but flattens input arguments to 1-D vectors\nfirst. Consequently, it should only be used for vectors.\n\nIf `a` is complex the complex conjugate is taken before calculation of the dot\nproduct.\n\nSecond argument to the dot product.\n\nDot product of `a` and `b`. Can be an int, float, or complex depending on the\ntypes of `a` and `b`.\n\nSee also\n\nReturn the dot product without using the complex conjugate of the first\nargument.\n\nNote that higher-dimensional arrays are flattened!\n\n"}, {"name": "numpy.vectorize()", "path": "reference/generated/numpy.vectorize", "type": "numpy.vectorize", "text": "\nGeneralized function class.\n\nDefine a vectorized function which takes a nested sequence of objects or numpy\narrays as inputs and returns a single numpy array or a tuple of numpy arrays.\nThe vectorized function evaluates `pyfunc` over successive tuples of the input\narrays like the python map function, except it uses the broadcasting rules of\nnumpy.\n\nThe data type of the output of `vectorized` is determined by calling the\nfunction with the first element of the input. This can be avoided by\nspecifying the `otypes` argument.\n\nA python function or method.\n\nThe output data type. It must be specified as either a string of typecode\ncharacters or a list of data type specifiers. There should be one data type\nspecifier for each output.\n\nThe docstring for the function. If None, the docstring will be the\n`pyfunc.__doc__`.\n\nSet of strings or integers representing the positional or keyword arguments\nfor which the function will not be vectorized. These will be passed directly\nto `pyfunc` unmodified.\n\nNew in version 1.7.0.\n\nIf `True`, then cache the first function call that determines the number of\noutputs if `otypes` is not provided.\n\nNew in version 1.7.0.\n\nGeneralized universal function signature, e.g., `(m,n),(n)->(m)` for\nvectorized matrix-vector multiplication. If provided, `pyfunc` will be called\nwith (and expected to return) arrays with shapes given by the size of\ncorresponding core dimensions. By default, `pyfunc` is assumed to take scalars\nas input and output.\n\nNew in version 1.12.0.\n\nVectorized function.\n\nSee also\n\nTakes an arbitrary Python function and returns a ufunc\n\nThe `vectorize` function is provided primarily for convenience, not for\nperformance. The implementation is essentially a for loop.\n\nIf `otypes` is not specified, then a call to the function with the first\nargument will be used to determine the number of outputs. The results of this\ncall will be cached if `cache` is `True` to prevent calling the function\ntwice. However, to implement the cache, the original function must be wrapped\nwhich will slow down subsequent calls, so only do this if your function is\nexpensive.\n\nThe new keyword argument interface and `excluded` argument support further\ndegrades performance.\n\nGeneralized Universal Function API\n\nThe docstring is taken from the input function to `vectorize` unless it is\nspecified:\n\nThe output type is determined by evaluating the first element of the input,\nunless it is specified:\n\nThe `excluded` argument can be used to prevent vectorizing over certain\narguments. This can be useful for array-like arguments of a fixed length such\nas the coefficients for a polynomial as in `polyval`:\n\nPositional arguments may also be excluded by specifying their position:\n\nThe `signature` argument allows for vectorizing functions that act on non-\nscalar arrays of fixed length. For example, you can use it for a vectorized\ncalculation of Pearson correlation coefficient and its p-value:\n\nOr for a vectorized convolution:\n\n`__call__`(*args, **kwargs)\n\nReturn arrays with the results of `pyfunc` broadcast (vectorized) over `args`\nand `kwargs` not in `excluded`.\n\n"}, {"name": "numpy.void", "path": "reference/arrays.scalars#numpy.void", "type": "Scalars", "text": "\nEither an opaque sequence of bytes, or a structure.\n\nStructured `void` scalars can only be constructed via extraction from\nStructured arrays:\n\n`'V'`\n\n"}, {"name": "numpy.vsplit()", "path": "reference/generated/numpy.vsplit", "type": "numpy.vsplit", "text": "\nSplit an array into multiple sub-arrays vertically (row-wise).\n\nPlease refer to the `split` documentation. `vsplit` is equivalent to `split`\nwith `axis=0` (default), the array is always split along the first axis\nregardless of the array dimension.\n\nSee also\n\nSplit an array into multiple sub-arrays of equal size.\n\nWith a higher dimensional array the split is still along the first axis.\n\n"}, {"name": "numpy.vstack()", "path": "reference/generated/numpy.vstack", "type": "numpy.vstack", "text": "\nStack arrays in sequence vertically (row wise).\n\nThis is equivalent to concatenation along the first axis after 1-D arrays of\nshape `(N,)` have been reshaped to `(1,N)`. Rebuilds arrays divided by\n`vsplit`.\n\nThis function makes most sense for arrays with up to 3 dimensions. For\ninstance, for pixel-data with a height (first axis), width (second axis), and\nr/g/b channels (third axis). The functions `concatenate`, `stack` and `block`\nprovide more general stacking and concatenation operations.\n\nThe arrays must have the same shape along all but the first axis. 1-D arrays\nmust have the same length.\n\nThe array formed by stacking the given arrays, will be at least 2-D.\n\nSee also\n\nJoin a sequence of arrays along an existing axis.\n\nJoin a sequence of arrays along a new axis.\n\nAssemble an nd-array from nested lists of blocks.\n\nStack arrays in sequence horizontally (column wise).\n\nStack arrays in sequence depth wise (along third axis).\n\nStack 1-D arrays as columns into a 2-D array.\n\nSplit an array into multiple sub-arrays vertically (row-wise).\n\n"}, {"name": "numpy.where()", "path": "reference/generated/numpy.where", "type": "numpy.where", "text": "\nReturn elements chosen from `x` or `y` depending on `condition`.\n\nNote\n\nWhen only `condition` is provided, this function is a shorthand for\n`np.asarray(condition).nonzero()`. Using `nonzero` directly should be\npreferred, as it behaves correctly for subclasses. The rest of this\ndocumentation covers only the case where all three arguments are provided.\n\nWhere True, yield `x`, otherwise yield `y`.\n\nValues from which to choose. `x`, `y` and `condition` need to be broadcastable\nto some shape.\n\nAn array with elements from `x` where `condition` is True, and elements from\n`y` elsewhere.\n\nSee also\n\nThe function that is called when x and y are omitted\n\nIf all the arrays are 1-D, `where` is equivalent to:\n\nThis can be used on multidimensional arrays too:\n\nThe shapes of x, y, and the condition are broadcast together:\n\n"}, {"name": "numpy.who()", "path": "reference/generated/numpy.who", "type": "numpy.who", "text": "\nPrint the NumPy arrays in the given dictionary.\n\nIf there is no dictionary passed in or `vardict` is None then returns NumPy\narrays in the globals() dictionary (all NumPy arrays in the namespace).\n\nA dictionary possibly containing ndarrays. Default is globals().\n\nReturns \u2018None\u2019.\n\nPrints out the name, shape, bytes and type of all of the ndarrays present in\n`vardict`.\n\n"}, {"name": "numpy.zeros()", "path": "reference/generated/numpy.zeros", "type": "numpy.zeros", "text": "\nReturn a new array of given shape and type, filled with zeros.\n\nShape of the new array, e.g., `(2, 3)` or `2`.\n\nThe desired data-type for the array, e.g., `numpy.int8`. Default is\n`numpy.float64`.\n\nWhether to store multi-dimensional data in row-major (C-style) or column-major\n(Fortran-style) order in memory.\n\nReference object to allow the creation of arrays which are not NumPy arrays.\nIf an array-like passed in as `like` supports the `__array_function__`\nprotocol, the result will be defined by it. In this case, it ensures the\ncreation of an array object compatible with that passed in via this argument.\n\nNew in version 1.20.0.\n\nArray of zeros with the given shape, dtype, and order.\n\nSee also\n\nReturn an array of zeros with shape and type of input.\n\nReturn a new uninitialized array.\n\nReturn a new array setting values to one.\n\nReturn a new array of given shape filled with value.\n\n"}, {"name": "numpy.zeros_like()", "path": "reference/generated/numpy.zeros_like", "type": "numpy.zeros_like", "text": "\nReturn an array of zeros with the same shape and type as a given array.\n\nThe shape and data-type of `a` define these same attributes of the returned\narray.\n\nOverrides the data type of the result.\n\nNew in version 1.6.0.\n\nOverrides the memory layout of the result. \u2018C\u2019 means C-order, \u2018F\u2019 means\nF-order, \u2018A\u2019 means \u2018F\u2019 if `a` is Fortran contiguous, \u2018C\u2019 otherwise. \u2018K\u2019 means\nmatch the layout of `a` as closely as possible.\n\nNew in version 1.6.0.\n\nIf True, then the newly created array will use the sub-class type of `a`,\notherwise it will be a base-class array. Defaults to True.\n\nOverrides the shape of the result. If order=\u2019K\u2019 and the number of dimensions\nis unchanged, will try to keep order, otherwise, order=\u2019C\u2019 is implied.\n\nNew in version 1.17.0.\n\nArray of zeros with the same shape and type as `a`.\n\nSee also\n\nReturn an empty array with shape and type of input.\n\nReturn an array of ones with shape and type of input.\n\nReturn a new array with shape of input filled with value.\n\nReturn a new array setting values to zero.\n\n"}, {"name": "NumPy: the absolute basics for beginners", "path": "user/absolute_beginners", "type": "User Guide", "text": "\nWelcome to the absolute beginner\u2019s guide to NumPy! If you have comments or\nsuggestions, please don\u2019t hesitate to reach out!\n\nNumPy (Numerical Python) is an open source Python library that\u2019s used in\nalmost every field of science and engineering. It\u2019s the universal standard for\nworking with numerical data in Python, and it\u2019s at the core of the scientific\nPython and PyData ecosystems. NumPy users include everyone from beginning\ncoders to experienced researchers doing state-of-the-art scientific and\nindustrial research and development. The NumPy API is used extensively in\nPandas, SciPy, Matplotlib, scikit-learn, scikit-image and most other data\nscience and scientific Python packages.\n\nThe NumPy library contains multidimensional array and matrix data structures\n(you\u2019ll find more information about this in later sections). It provides\nndarray, a homogeneous n-dimensional array object, with methods to efficiently\noperate on it. NumPy can be used to perform a wide variety of mathematical\noperations on arrays. It adds powerful data structures to Python that\nguarantee efficient calculations with arrays and matrices and it supplies an\nenormous library of high-level mathematical functions that operate on these\narrays and matrices.\n\nLearn more about NumPy here!\n\nTo install NumPy, we strongly recommend using a scientific Python\ndistribution. If you\u2019re looking for the full instructions for installing NumPy\non your operating system, see Installing NumPy.\n\nIf you already have Python, you can install NumPy with:\n\nor\n\nIf you don\u2019t have Python yet, you might want to consider using Anaconda. It\u2019s\nthe easiest way to get started. The good thing about getting this distribution\nis the fact that you don\u2019t need to worry too much about separately installing\nNumPy or any of the major packages that you\u2019ll be using for your data\nanalyses, like pandas, Scikit-Learn, etc.\n\nTo access NumPy and its functions import it in your Python code like this:\n\nWe shorten the imported name to `np` for better readability of code using\nNumPy. This is a widely adopted convention that you should follow so that\nanyone working with your code can easily understand it.\n\nIf you aren\u2019t already comfortable with reading tutorials that contain a lot of\ncode, you might not know how to interpret a code block that looks like this:\n\nIf you aren\u2019t familiar with this style, it\u2019s very easy to understand. If you\nsee `>>>`, you\u2019re looking at input, or the code that you would enter.\nEverything that doesn\u2019t have `>>>` in front of it is output, or the results of\nrunning your code. This is the style you see when you run `python` on the\ncommand line, but if you\u2019re using IPython, you might see a different style.\nNote that it is not part of the code and will cause an error if typed or\npasted into the Python shell. It can be safely typed or pasted into the\nIPython shell; the `>>>` is ignored.\n\nNumPy gives you an enormous range of fast and efficient ways of creating\narrays and manipulating numerical data inside them. While a Python list can\ncontain different data types within a single list, all of the elements in a\nNumPy array should be homogeneous. The mathematical operations that are meant\nto be performed on arrays would be extremely inefficient if the arrays weren\u2019t\nhomogeneous.\n\nWhy use NumPy?\n\nNumPy arrays are faster and more compact than Python lists. An array consumes\nless memory and is convenient to use. NumPy uses much less memory to store\ndata and it provides a mechanism of specifying the data types. This allows the\ncode to be optimized even further.\n\nAn array is a central data structure of the NumPy library. An array is a grid\nof values and it contains information about the raw data, how to locate an\nelement, and how to interpret an element. It has a grid of elements that can\nbe indexed in various ways. The elements are all of the same type, referred to\nas the array `dtype`.\n\nAn array can be indexed by a tuple of nonnegative integers, by booleans, by\nanother array, or by integers. The `rank` of the array is the number of\ndimensions. The `shape` of the array is a tuple of integers giving the size of\nthe array along each dimension.\n\nOne way we can initialize NumPy arrays is from Python lists, using nested\nlists for two- or higher-dimensional data.\n\nFor example:\n\nor:\n\nWe can access the elements in the array using square brackets. When you\u2019re\naccessing elements, remember that indexing in NumPy starts at 0. That means\nthat if you want to access the first element in your array, you\u2019ll be\naccessing element \u201c0\u201d.\n\nThis section covers `1D array`, `2D array`, `ndarray`, `vector`, `matrix`\n\nYou might occasionally hear an array referred to as a \u201cndarray,\u201d which is\nshorthand for \u201cN-dimensional array.\u201d An N-dimensional array is simply an array\nwith any number of dimensions. You might also hear 1-D, or one-dimensional\narray, 2-D, or two-dimensional array, and so on. The NumPy `ndarray` class is\nused to represent both matrices and vectors. A vector is an array with a\nsingle dimension (there\u2019s no difference between row and column vectors), while\na matrix refers to an array with two dimensions. For 3-D or higher dimensional\narrays, the term tensor is also commonly used.\n\nWhat are the attributes of an array?\n\nAn array is usually a fixed-size container of items of the same type and size.\nThe number of dimensions and items in an array is defined by its shape. The\nshape of an array is a tuple of non-negative integers that specify the sizes\nof each dimension.\n\nIn NumPy, dimensions are called axes. This means that if you have a 2D array\nthat looks like this:\n\nYour array has 2 axes. The first axis has a length of 2 and the second axis\nhas a length of 3.\n\nJust like in other Python container objects, the contents of an array can be\naccessed and modified by indexing or slicing the array. Unlike the typical\ncontainer objects, different arrays can share the same data, so changes made\non one array might be visible in another.\n\nArray attributes reflect information intrinsic to the array itself. If you\nneed to get, or even set, properties of an array without creating a new array,\nyou can often access an array through its attributes.\n\nRead more about array attributes here and learn about array objects here.\n\nThis section covers `np.array()`, `np.zeros()`, `np.ones()`, `np.empty()`,\n`np.arange()`, `np.linspace()`, `dtype`\n\nTo create a NumPy array, you can use the function `np.array()`.\n\nAll you need to do to create a simple array is pass a list to it. If you\nchoose to, you can also specify the type of data in your list. You can find\nmore information about data types here.\n\nYou can visualize your array this way:\n\nBe aware that these visualizations are meant to simplify ideas and give you a\nbasic understanding of NumPy concepts and mechanics. Arrays and array\noperations are much more complicated than are captured here!\n\nBesides creating an array from a sequence of elements, you can easily create\nan array filled with `0`\u2019s:\n\nOr an array filled with `1`\u2019s:\n\nOr even an empty array! The function `empty` creates an array whose initial\ncontent is random and depends on the state of the memory. The reason to use\n`empty` over `zeros` (or something similar) is speed - just make sure to fill\nevery element afterwards!\n\nYou can create an array with a range of elements:\n\nAnd even an array that contains a range of evenly spaced intervals. To do\nthis, you will specify the first number, last number, and the step size.\n\nYou can also use `np.linspace()` to create an array with values that are\nspaced linearly in a specified interval:\n\nSpecifying your data type\n\nWhile the default data type is floating point (`np.float64`), you can\nexplicitly specify which data type you want using the `dtype` keyword.\n\nLearn more about creating arrays here\n\nThis section covers `np.sort()`, `np.concatenate()`\n\nSorting an element is simple with `np.sort()`. You can specify the axis, kind,\nand order when you call the function.\n\nIf you start with this array:\n\nYou can quickly sort the numbers in ascending order with:\n\nIn addition to sort, which returns a sorted copy of an array, you can use:\n\nTo read more about sorting an array, see: `sort`.\n\nIf you start with these arrays:\n\nYou can concatenate them with `np.concatenate()`.\n\nOr, if you start with these arrays:\n\nYou can concatenate them with:\n\nIn order to remove elements from an array, it\u2019s simple to use indexing to\nselect the elements that you want to keep.\n\nTo read more about concatenate, see: `concatenate`.\n\nThis section covers `ndarray.ndim`, `ndarray.size`, `ndarray.shape`\n\n`ndarray.ndim` will tell you the number of axes, or dimensions, of the array.\n\n`ndarray.size` will tell you the total number of elements of the array. This\nis the product of the elements of the array\u2019s shape.\n\n`ndarray.shape` will display a tuple of integers that indicate the number of\nelements stored along each dimension of the array. If, for example, you have a\n2-D array with 2 rows and 3 columns, the shape of your array is `(2, 3)`.\n\nFor example, if you create this array:\n\nTo find the number of dimensions of the array, run:\n\nTo find the total number of elements in the array, run:\n\nAnd to find the shape of your array, run:\n\nThis section covers `arr.reshape()`\n\nYes!\n\nUsing `arr.reshape()` will give a new shape to an array without changing the\ndata. Just remember that when you use the reshape method, the array you want\nto produce needs to have the same number of elements as the original array. If\nyou start with an array with 12 elements, you\u2019ll need to make sure that your\nnew array also has a total of 12 elements.\n\nIf you start with this array:\n\nYou can use `reshape()` to reshape your array. For example, you can reshape\nthis array to an array with three rows and two columns:\n\nWith `np.reshape`, you can specify a few optional parameters:\n\n`a` is the array to be reshaped.\n\n`newshape` is the new shape you want. You can specify an integer or a tuple of\nintegers. If you specify an integer, the result will be an array of that\nlength. The shape should be compatible with the original shape.\n\n`order:` `C` means to read/write the elements using C-like index order, `F`\nmeans to read/write the elements using Fortran-like index order, `A` means to\nread/write the elements in Fortran-like index order if a is Fortran contiguous\nin memory, C-like order otherwise. (This is an optional parameter and doesn\u2019t\nneed to be specified.)\n\nIf you want to learn more about C and Fortran order, you can read more about\nthe internal organization of NumPy arrays here. Essentially, C and Fortran\norders have to do with how indices correspond to the order the array is stored\nin memory. In Fortran, when moving through the elements of a two-dimensional\narray as it is stored in memory, the first index is the most rapidly varying\nindex. As the first index moves to the next row as it changes, the matrix is\nstored one column at a time. This is why Fortran is thought of as a Column-\nmajor language. In C on the other hand, the last index changes the most\nrapidly. The matrix is stored by rows, making it a Row-major language. What\nyou do for C or Fortran depends on whether it\u2019s more important to preserve the\nindexing convention or not reorder the data.\n\nLearn more about shape manipulation here.\n\nThis section covers `np.newaxis`, `np.expand_dims`\n\nYou can use `np.newaxis` and `np.expand_dims` to increase the dimensions of\nyour existing array.\n\nUsing `np.newaxis` will increase the dimensions of your array by one dimension\nwhen used once. This means that a 1D array will become a 2D array, a 2D array\nwill become a 3D array, and so on.\n\nFor example, if you start with this array:\n\nYou can use `np.newaxis` to add a new axis:\n\nYou can explicitly convert a 1D array with either a row vector or a column\nvector using `np.newaxis`. For example, you can convert a 1D array to a row\nvector by inserting an axis along the first dimension:\n\nOr, for a column vector, you can insert an axis along the second dimension:\n\nYou can also expand an array by inserting a new axis at a specified position\nwith `np.expand_dims`.\n\nFor example, if you start with this array:\n\nYou can use `np.expand_dims` to add an axis at index position 1 with:\n\nYou can add an axis at index position 0 with:\n\nFind more information about newaxis here and `expand_dims` at `expand_dims`.\n\nYou can index and slice NumPy arrays in the same ways you can slice Python\nlists.\n\nYou can visualize it this way:\n\nYou may want to take a section of your array or specific array elements to use\nin further analysis or additional operations. To do that, you\u2019ll need to\nsubset, slice, and/or index your arrays.\n\nIf you want to select values from your array that fulfill certain conditions,\nit\u2019s straightforward with NumPy.\n\nFor example, if you start with this array:\n\nYou can easily print all of the values in the array that are less than 5.\n\nYou can also select, for example, numbers that are equal to or greater than 5,\nand use that condition to index an array.\n\nYou can select elements that are divisible by 2:\n\nOr you can select elements that satisfy two conditions using the `&` and `|`\noperators:\n\nYou can also make use of the logical operators & and | in order to return\nboolean values that specify whether or not the values in an array fulfill a\ncertain condition. This can be useful with arrays that contain names or other\ncategorical values.\n\nYou can also use `np.nonzero()` to select elements or indices from an array.\n\nStarting with this array:\n\nYou can use `np.nonzero()` to print the indices of elements that are, for\nexample, less than 5:\n\nIn this example, a tuple of arrays was returned: one for each dimension. The\nfirst array represents the row indices where these values are found, and the\nsecond array represents the column indices where the values are found.\n\nIf you want to generate a list of coordinates where the elements exist, you\ncan zip the arrays, iterate over the list of coordinates, and print them. For\nexample:\n\nYou can also use `np.nonzero()` to print the elements in an array that are\nless than 5 with:\n\nIf the element you\u2019re looking for doesn\u2019t exist in the array, then the\nreturned array of indices will be empty. For example:\n\nLearn more about indexing and slicing here and here.\n\nRead more about using the nonzero function at: `nonzero`.\n\nThis section covers `slicing and indexing`, `np.vstack()`, `np.hstack()`,\n`np.hsplit()`, `.view()`, `copy()`\n\nYou can easily create a new array from a section of an existing array.\n\nLet\u2019s say you have this array:\n\nYou can create a new array from a section of your array any time by specifying\nwhere you want to slice your array.\n\nHere, you grabbed a section of your array from index position 3 through index\nposition 8.\n\nYou can also stack two existing arrays, both vertically and horizontally.\nLet\u2019s say you have two arrays, `a1` and `a2`:\n\nYou can stack them vertically with `vstack`:\n\nOr stack them horizontally with `hstack`:\n\nYou can split an array into several smaller arrays using `hsplit`. You can\nspecify either the number of equally shaped arrays to return or the columns\nafter which the division should occur.\n\nLet\u2019s say you have this array:\n\nIf you wanted to split this array into three equally shaped arrays, you would\nrun:\n\nIf you wanted to split your array after the third and fourth column, you\u2019d\nrun:\n\nLearn more about stacking and splitting arrays here.\n\nYou can use the `view` method to create a new array object that looks at the\nsame data as the original array (a shallow copy).\n\nViews are an important NumPy concept! NumPy functions, as well as operations\nlike indexing and slicing, will return views whenever possible. This saves\nmemory and is faster (no copy of the data has to be made). However it\u2019s\nimportant to be aware of this - modifying data in a view also modifies the\noriginal array!\n\nLet\u2019s say you create this array:\n\nNow we create an array `b1` by slicing `a` and modify the first element of\n`b1`. This will modify the corresponding element in `a` as well!\n\nUsing the `copy` method will make a complete copy of the array and its data (a\ndeep copy). To use this on your array, you could run:\n\nLearn more about copies and views here.\n\nThis section covers addition, subtraction, multiplication, division, and more\n\nOnce you\u2019ve created your arrays, you can start to work with them. Let\u2019s say,\nfor example, that you\u2019ve created two arrays, one called \u201cdata\u201d and one called\n\u201cones\u201d\n\nYou can add the arrays together with the plus sign.\n\nYou can, of course, do more than just addition!\n\nBasic operations are simple with NumPy. If you want to find the sum of the\nelements in an array, you\u2019d use `sum()`. This works for 1D arrays, 2D arrays,\nand arrays in higher dimensions.\n\nTo add the rows or the columns in a 2D array, you would specify the axis.\n\nIf you start with this array:\n\nYou can sum over the axis of rows with:\n\nYou can sum over the axis of columns with:\n\nLearn more about basic operations here.\n\nThere are times when you might want to carry out an operation between an array\nand a single number (also called an operation between a vector and a scalar)\nor between arrays of two different sizes. For example, your array (we\u2019ll call\nit \u201cdata\u201d) might contain information about distance in miles but you want to\nconvert the information to kilometers. You can perform this operation with:\n\nNumPy understands that the multiplication should happen with each cell. That\nconcept is called broadcasting. Broadcasting is a mechanism that allows NumPy\nto perform operations on arrays of different shapes. The dimensions of your\narray must be compatible, for example, when the dimensions of both arrays are\nequal or when one of them is 1. If the dimensions are not compatible, you will\nget a `ValueError`.\n\nLearn more about broadcasting here.\n\nThis section covers maximum, minimum, sum, mean, product, standard deviation,\nand more\n\nNumPy also performs aggregation functions. In addition to `min`, `max`, and\n`sum`, you can easily run `mean` to get the average, `prod` to get the result\nof multiplying the elements together, `std` to get the standard deviation, and\nmore.\n\nLet\u2019s start with this array, called \u201ca\u201d\n\nIt\u2019s very common to want to aggregate along a row or column. By default, every\nNumPy aggregation function will return the aggregate of the entire array. To\nfind the sum or the minimum of the elements in your array, run:\n\nOr:\n\nYou can specify on which axis you want the aggregation function to be\ncomputed. For example, you can find the minimum value within each column by\nspecifying `axis=0`.\n\nThe four values listed above correspond to the number of columns in your\narray. With a four-column array, you will get four values as your result.\n\nRead more about array methods here.\n\nYou can pass Python lists of lists to create a 2-D array (or \u201cmatrix\u201d) to\nrepresent them in NumPy.\n\nIndexing and slicing operations are useful when you\u2019re manipulating matrices:\n\nYou can aggregate matrices the same way you aggregated vectors:\n\nYou can aggregate all the values in a matrix and you can aggregate them across\ncolumns or rows using the `axis` parameter. To illustrate this point, let\u2019s\nlook at a slightly modified dataset:\n\nOnce you\u2019ve created your matrices, you can add and multiply them using\narithmetic operators if you have two matrices that are the same size.\n\nYou can do these arithmetic operations on matrices of different sizes, but\nonly if one matrix has only one column or one row. In this case, NumPy will\nuse its broadcast rules for the operation.\n\nBe aware that when NumPy prints N-dimensional arrays, the last axis is looped\nover the fastest while the first axis is the slowest. For instance:\n\nThere are often instances where we want NumPy to initialize the values of an\narray. NumPy offers functions like `ones()` and `zeros()`, and the\n`random.Generator` class for random number generation for that. All you need\nto do is pass in the number of elements you want it to generate:\n\nYou can also use `ones()`, `zeros()`, and `random()` to create a 2D array if\nyou give them a tuple describing the dimensions of the matrix:\n\nRead more about creating arrays, filled with `0`\u2019s, `1`\u2019s, other values or\nuninitialized, at array creation routines.\n\nThe use of random number generation is an important part of the configuration\nand evaluation of many numerical and machine learning algorithms. Whether you\nneed to randomly initialize weights in an artificial neural network, split\ndata into random sets, or randomly shuffle your dataset, being able to\ngenerate random numbers (actually, repeatable pseudo-random numbers) is\nessential.\n\nWith `Generator.integers`, you can generate random integers from low (remember\nthat this is inclusive with NumPy) to high (exclusive). You can set\n`endpoint=True` to make the high number inclusive.\n\nYou can generate a 2 x 4 array of random integers between 0 and 4 with:\n\nRead more about random number generation here.\n\nThis section covers `np.unique()`\n\nYou can find the unique elements in an array easily with `np.unique`.\n\nFor example, if you start with this array:\n\nyou can use `np.unique` to print the unique values in your array:\n\nTo get the indices of unique values in a NumPy array (an array of first index\npositions of unique values in the array), just pass the `return_index`\nargument in `np.unique()` as well as your array.\n\nYou can pass the `return_counts` argument in `np.unique()` along with your\narray to get the frequency count of unique values in a NumPy array.\n\nThis also works with 2D arrays! If you start with this array:\n\nYou can find unique values with:\n\nIf the axis argument isn\u2019t passed, your 2D array will be flattened.\n\nIf you want to get the unique rows or columns, make sure to pass the `axis`\nargument. To find the unique rows, specify `axis=0` and for columns, specify\n`axis=1`.\n\nTo get the unique rows, index position, and occurrence count, you can use:\n\nTo learn more about finding the unique elements in an array, see `unique`.\n\nThis section covers `arr.reshape()`, `arr.transpose()`, `arr.T`\n\nIt\u2019s common to need to transpose your matrices. NumPy arrays have the property\n`T` that allows you to transpose a matrix.\n\nYou may also need to switch the dimensions of a matrix. This can happen when,\nfor example, you have a model that expects a certain input shape that is\ndifferent from your dataset. This is where the `reshape` method can be useful.\nYou simply need to pass in the new dimensions that you want for the matrix.\n\nYou can also use `.transpose()` to reverse or change the axes of an array\naccording to the values you specify.\n\nIf you start with this array:\n\nYou can transpose your array with `arr.transpose()`.\n\nYou can also use `arr.T`:\n\nTo learn more about transposing and reshaping arrays, see `transpose` and\n`reshape`.\n\nThis section covers `np.flip()`\n\nNumPy\u2019s `np.flip()` function allows you to flip, or reverse, the contents of\nan array along an axis. When using `np.flip()`, specify the array you would\nlike to reverse and the axis. If you don\u2019t specify the axis, NumPy will\nreverse the contents along all of the axes of your input array.\n\nReversing a 1D array\n\nIf you begin with a 1D array like this one:\n\nYou can reverse it with:\n\nIf you want to print your reversed array, you can run:\n\nReversing a 2D array\n\nA 2D array works much the same way.\n\nIf you start with this array:\n\nYou can reverse the content in all of the rows and all of the columns with:\n\nYou can easily reverse only the rows with:\n\nOr reverse only the columns with:\n\nYou can also reverse the contents of only one column or row. For example, you\ncan reverse the contents of the row at index position 1 (the second row):\n\nYou can also reverse the column at index position 1 (the second column):\n\nRead more about reversing arrays at `flip`.\n\nThis section covers `.flatten()`, `ravel()`\n\nThere are two popular ways to flatten an array: `.flatten()` and `.ravel()`.\nThe primary difference between the two is that the new array created using\n`ravel()` is actually a reference to the parent array (i.e., a \u201cview\u201d). This\nmeans that any changes to the new array will affect the parent array as well.\nSince `ravel` does not create a copy, it\u2019s memory efficient.\n\nIf you start with this array:\n\nYou can use `flatten` to flatten your array into a 1D array.\n\nWhen you use `flatten`, changes to your new array won\u2019t change the parent\narray.\n\nFor example:\n\nBut when you use `ravel`, the changes you make to the new array will affect\nthe parent array.\n\nFor example:\n\nRead more about `flatten` at `ndarray.flatten` and `ravel` at `ravel`.\n\nThis section covers `help()`, `?`, `??`\n\nWhen it comes to the data science ecosystem, Python and NumPy are built with\nthe user in mind. One of the best examples of this is the built-in access to\ndocumentation. Every object contains the reference to a string, which is known\nas the docstring. In most cases, this docstring contains a quick and concise\nsummary of the object and how to use it. Python has a built-in `help()`\nfunction that can help you access this information. This means that nearly any\ntime you need more information, you can use `help()` to quickly find the\ninformation that you need.\n\nFor example:\n\nBecause access to additional information is so useful, IPython uses the `?`\ncharacter as a shorthand for accessing this documentation along with other\nrelevant information. IPython is a command shell for interactive computing in\nmultiple languages. You can find more information about IPython here.\n\nFor example:\n\nYou can even use this notation for object methods and objects themselves.\n\nLet\u2019s say you create this array:\n\nThen you can obtain a lot of useful information (first details about `a`\nitself, followed by the docstring of `ndarray` of which `a` is an instance):\n\nThis also works for functions and other objects that you create. Just remember\nto include a docstring with your function using a string literal (`\"\"\" \"\"\"` or\n`''' '''` around your documentation).\n\nFor example, if you create this function:\n\nYou can obtain information about the function:\n\nYou can reach another level of information by reading the source code of the\nobject you\u2019re interested in. Using a double question mark (`??`) allows you to\naccess the source code.\n\nFor example:\n\nIf the object in question is compiled in a language other than Python, using\n`??` will return the same information as `?`. You\u2019ll find this with a lot of\nbuilt-in objects and types, for example:\n\nand :\n\nhave the same output because they were compiled in a programming language\nother than Python.\n\nThe ease of implementing mathematical formulas that work on arrays is one of\nthe things that make NumPy so widely used in the scientific Python community.\n\nFor example, this is the mean square error formula (a central formula used in\nsupervised machine learning models that deal with regression):\n\nImplementing this formula is simple and straightforward in NumPy:\n\nWhat makes this work so well is that `predictions` and `labels` can contain\none or a thousand values. They only need to be the same size.\n\nYou can visualize it this way:\n\nIn this example, both the predictions and labels vectors contain three values,\nmeaning `n` has a value of three. After we carry out subtractions the values\nin the vector are squared. Then NumPy sums the values, and your result is the\nerror value for that prediction and a score for the quality of the model.\n\nThis section covers `np.save`, `np.savez`, `np.savetxt`, `np.load`,\n`np.loadtxt`\n\nYou will, at some point, want to save your arrays to disk and load them back\nwithout having to re-run the code. Fortunately, there are several ways to save\nand load objects with NumPy. The ndarray objects can be saved to and loaded\nfrom the disk files with `loadtxt` and `savetxt` functions that handle normal\ntext files, `load` and `save` functions that handle NumPy binary files with a\n.npy file extension, and a `savez` function that handles NumPy files with a\n.npz file extension.\n\nThe .npy and .npz files store data, shape, dtype, and other information\nrequired to reconstruct the ndarray in a way that allows the array to be\ncorrectly retrieved, even when the file is on another machine with different\narchitecture.\n\nIf you want to store a single ndarray object, store it as a .npy file using\n`np.save`. If you want to store more than one ndarray object in a single file,\nsave it as a .npz file using `np.savez`. You can also save several arrays into\na single file in compressed npz format with `savez_compressed`.\n\nIt\u2019s easy to save and load and array with `np.save()`. Just make sure to\nspecify the array you want to save and a file name. For example, if you create\nthis array:\n\nYou can save it as \u201cfilename.npy\u201d with:\n\nYou can use `np.load()` to reconstruct your array.\n\nIf you want to check your array, you can run::\n\nYou can save a NumPy array as a plain text file like a .csv or .txt file with\n`np.savetxt`.\n\nFor example, if you create this array:\n\nYou can easily save it as a .csv file with the name \u201cnew_file.csv\u201d like this:\n\nYou can quickly and easily load your saved text file using `loadtxt()`:\n\nThe `savetxt()` and `loadtxt()` functions accept additional optional\nparameters such as header, footer, and delimiter. While text files can be\neasier for sharing, .npy and .npz files are smaller and faster to read. If you\nneed more sophisticated handling of your text file (for example, if you need\nto work with lines that contain missing values), you will want to use the\n`genfromtxt` function.\n\nWith `savetxt`, you can specify headers, footers, comments, and more.\n\nLearn more about input and output routines here.\n\nIt\u2019s simple to read in a CSV that contains existing information. The best and\neasiest way to do this is to use Pandas.\n\nIt\u2019s simple to use Pandas in order to export your array as well. If you are\nnew to NumPy, you may want to create a Pandas dataframe from the values in\nyour array and then write the data frame to a CSV file with Pandas.\n\nIf you created this array \u201ca\u201d\n\nYou could create a Pandas dataframe\n\nYou can easily save your dataframe with:\n\nAnd read your CSV with:\n\nYou can also save your array with the NumPy `savetxt` method.\n\nIf you\u2019re using the command line, you can read your saved CSV any time with a\ncommand such as:\n\nOr you can open the file any time with a text editor!\n\nIf you\u2019re interested in learning more about Pandas, take a look at the\nofficial Pandas documentation. Learn how to install Pandas with the official\nPandas installation information.\n\nIf you need to generate a plot for your values, it\u2019s very simple with\nMatplotlib.\n\nFor example, you may have an array like this one:\n\nIf you already have Matplotlib installed, you can import it with:\n\nAll you need to do to plot your values is run:\n\nFor example, you can plot a 1D array like this:\n\nWith Matplotlib, you have access to an enormous number of visualization\noptions.\n\nTo read more about Matplotlib and what it can do, take a look at the official\ndocumentation. For directions regarding installing Matplotlib, see the\nofficial installation section.\n\nImage credits: Jay Alammar http://jalammar.github.io/\n\n"}, {"name": "Optionally SciPy-accelerated routines (numpy.dual)", "path": "reference/routines.dual", "type": "Optionally SciPy-accelerated routines ( \n      \n       numpy.dual\n      \n      )", "text": "\nDeprecated since version 1.20.\n\nThis module is deprecated. Instead of importing functions from `numpy.dual`,\nthe functions should be imported directly from NumPy or SciPy.\n\nAliases for functions which may be accelerated by SciPy.\n\nSciPy can be built to use accelerated or otherwise improved libraries for\nFFTs, linear algebra, and special functions. This module allows developers to\ntransparently support these accelerated functions when SciPy is available but\nstill support users who have only installed NumPy.\n\n`cholesky`(a)\n\nCholesky decomposition.\n\n`det`(a)\n\nCompute the determinant of an array.\n\n`eig`(a)\n\nCompute the eigenvalues and right eigenvectors of a square array.\n\n`eigh`(a[, UPLO])\n\nReturn the eigenvalues and eigenvectors of a complex Hermitian (conjugate\nsymmetric) or a real symmetric matrix.\n\n`eigvals`(a)\n\nCompute the eigenvalues of a general matrix.\n\n`eigvalsh`(a[, UPLO])\n\nCompute the eigenvalues of a complex Hermitian or real symmetric matrix.\n\n`inv`(a)\n\nCompute the (multiplicative) inverse of a matrix.\n\n`lstsq`(a, b[, rcond])\n\nReturn the least-squares solution to a linear matrix equation.\n\n`norm`(x[, ord, axis, keepdims])\n\nMatrix or vector norm.\n\n`pinv`(a[, rcond, hermitian])\n\nCompute the (Moore-Penrose) pseudo-inverse of a matrix.\n\n`solve`(a, b)\n\nSolve a linear matrix equation, or system of linear scalar equations.\n\n`svd`(a[, full_matrices, compute_uv, hermitian])\n\nSingular Value Decomposition.\n\n`fft`(a[, n, axis, norm])\n\nCompute the one-dimensional discrete Fourier Transform.\n\n`fft2`(a[, s, axes, norm])\n\nCompute the 2-dimensional discrete Fourier Transform.\n\n`fftn`(a[, s, axes, norm])\n\nCompute the N-dimensional discrete Fourier Transform.\n\n`ifft`(a[, n, axis, norm])\n\nCompute the one-dimensional inverse discrete Fourier Transform.\n\n`ifft2`(a[, s, axes, norm])\n\nCompute the 2-dimensional inverse discrete Fourier Transform.\n\n`ifftn`(a[, s, axes, norm])\n\nCompute the N-dimensional inverse discrete Fourier Transform.\n\n`i0`(x)\n\nModified Bessel function of the first kind, order 0.\n\n"}, {"name": "Padding Arrays", "path": "reference/routines.padding", "type": "Padding Arrays", "text": "\n`pad`(array, pad_width[, mode])\n\nPad an array.\n\n"}, {"name": "Parameters", "path": "reference/distutils", "type": "Packaging ( \n    \n     numpy.distutils\n    \n    )", "text": "\nNumPy provides enhanced distutils functionality to make it easier to build and\ninstall sub-packages, auto-generate code, and extension modules that use\nFortran-compiled libraries. To use features of NumPy distutils, use the\n`setup` command from `numpy.distutils.core`. A useful `Configuration` class is\nalso provided in `numpy.distutils.misc_util` that can make it easier to\nconstruct keyword arguments to pass to the setup function (by passing the\ndictionary obtained from the todict() method of the class). More information\nis available in the NumPy Distutils - Users Guide.\n\nThe choice and location of linked libraries such as BLAS and LAPACK as well as\ninclude paths and other such build options can be specified in a `site.cfg`\nfile located in the NumPy root repository or a `.numpy-site.cfg` file in your\nhome directory. See the `site.cfg.example` example file included in the NumPy\nrepository or sdist for documentation.\n\n`ccompiler`\n\n`ccompiler_opt`\n\nProvides the `CCompilerOpt` class, used for handling the CPU/hardware\noptimization, starting from parsing the command arguments, to managing the\nrelation between the CPU baseline and dispatch-able features, also generating\nthe required C headers and ending with compiling the sources with proper\ncompiler's flags.\n\n`cpuinfo.cpu`\n\n`core.Extension`(name, sources[, ...])\n\n`exec_command`\n\nexec_command\n\n`log.set_verbosity`(v[, force])\n\n`system_info.get_info`(name[, notfound_action])\n\nnotfound_action:\n\n`system_info.get_standard_file`(fname)\n\nReturns a list of files named 'fname' from 1) System-wide directory\n(directory-location of this module) 2) Users HOME directory\n(os.environ['HOME']) 3) Local directory\n\nConstruct a configuration instance for the given package name. If parent_name\nis not None, then construct the package as a sub-package of the parent_name\npackage. If top_path and package_path are None then they are assumed equal to\nthe path of the file this instance was created in. The setup.py files in the\nnumpy distribution are good examples of how to use the `Configuration`\ninstance.\n\nReturn a dictionary compatible with the keyword arguments of distutils setup\nfunction.\n\nReturn the distutils distribution object for self.\n\nReturn list of subpackage configurations.\n\nName of the subpackage to get the configuration. \u2018*\u2019 in subpackage_name is\nhandled as a wildcard.\n\nIf None, then the path is assumed to be the local path plus the\nsubpackage_name. If a setup.py file is not found in the subpackage_path, then\na default configuration is used.\n\nParent name.\n\nAdd a sub-package to the current Configuration instance.\n\nThis is useful in a setup.py script for adding sub-packages to a package.\n\nname of the subpackage\n\nif given, the subpackage path such as the subpackage is in subpackage_path /\nsubpackage_name. If None,the subpackage is assumed to be located in the local\npath / subpackage_name.\n\nAdd data files to configuration data_files.\n\nArgument(s) can be either\n\nThe form of each element of the files sequence is very flexible allowing many\ncombinations of where to get the files from the package and where they should\nultimately be installed on the system. The most basic usage is for an element\nof the files argument sequence to be a simple filename. This will cause that\nfile from the local path to be installed to the installation path of the\nself.name package (package path). The file argument can also be a relative\npath in which case the entire relative path will be installed into the package\ndirectory. Finally, the file can be an absolute path name in which case the\nfile will be found at the absolute path name but installed to the package\npath.\n\nThis basic behavior can be augmented by passing a 2-tuple in as the file\nargument. The first element of the tuple should specify the relative path\n(under the package install directory) where the remaining sequence of files\nshould be installed to (it has nothing to do with the file-names in the source\ndistribution). The second element of the tuple is the sequence of files that\nshould be installed. The files in this sequence can be filenames, relative\npaths, or absolute paths. For absolute paths the file will be installed in the\ntop-level package installation directory (regardless of the first argument).\nFilenames and relative path names will be installed in the package install\ndirectory under the path name given as the first element of the tuple.\n\nRules for installation paths:\n\nAn additional feature is that the path to a data-file can actually be a\nfunction that takes no arguments and returns the actual path(s) to the data-\nfiles. This is useful when the data files are generated while building the\npackage.\n\nAdd files to the list of data_files to be included with the package.\n\nwill install these data files to:\n\nwhere <package install directory> is the package (or sub-package) directory\nsuch as \u2018/usr/lib/python2.4/site-packages/mypackage\u2019 (\u2018C: Python2.4 Lib site-\npackages mypackage\u2019) or \u2018/usr/lib/python2.4/site-\npackages/mypackage/mysubpackage\u2019 (\u2018C: Python2.4 Lib site-packages mypackage\nmysubpackage\u2019).\n\nRecursively add files under data_path to data_files list.\n\nRecursively add files under data_path to the list of data_files to be\ninstalled (and distributed). The data_path can be either a relative path-name,\nor an absolute path-name, or a 2-tuple where the first argument shows where in\nthe install directory the data directory should be installed to.\n\nArgument can be either\n\nRules for installation paths:\n\nFor example suppose the source directory contains fun/foo.dat and\nfun/bar/car.dat:\n\nWill install data-files to the locations:\n\nAdd paths to configuration include directories.\n\nAdd the given sequence of paths to the beginning of the include_dirs list.\nThis list will be visible to all extension modules of the current package.\n\nAdd installable headers to configuration.\n\nAdd the given sequence of files to the beginning of the headers list. By\ndefault, headers will be installed under <python-\ninclude>/<self.name.replace(\u2018.\u2019,\u2019/\u2019)>/ directory. If an item of files is a\ntuple, then its first argument specifies the actual installation location\nrelative to the <python-include> path.\n\nArgument(s) can be either:\n\nAdd extension to configuration.\n\nCreate and add an Extension instance to the ext_modules list. This method also\ntakes the following optional keyword arguments that are passed on to the\nExtension constructor.\n\nname of the extension\n\nlist of the sources. The list of sources may contain functions (called source\ngenerators) which must take an extension instance and a build directory as\ninputs and return a source file or list of source files or None. If None is\nreturned then no sources are generated. If the Extension instance has no\nsources after processing all source generators, then no extension module is\nbuilt.\n\nThe depends list contains paths to files or directories that the sources of\nthe extension module depend on. If any path in the depends list is newer than\nthe extension module, then the module will be rebuilt.\n\ndict or list of dict of keywords to be appended to keywords.\n\nThe self.paths(\u2026) method is applied to all lists that may contain paths.\n\nAdd library to configuration.\n\nName of the extension.\n\nList of the sources. The list of sources may contain functions (called source\ngenerators) which must take an extension instance and a build directory as\ninputs and return a source file or list of source files or None. If None is\nreturned then no sources are generated. If the Extension instance has no\nsources after processing all source generators, then no extension module is\nbuilt.\n\nThe following keys are allowed:\n\nAdd scripts to configuration.\n\nAdd the sequence of files to the beginning of the scripts list. Scripts will\nbe installed under the <prefix>/bin/ directory.\n\nSimilar to add_library, but the specified library is installed.\n\nMost C libraries used with `distutils` are only used to build python\nextensions, but libraries built through this method will be installed so that\nthey can be reused by third-party packages.\n\nName of the installed library.\n\nList of the library\u2019s source files. See `add_library` for details.\n\nPath to install the library, relative to the current sub-package.\n\nThe following keys are allowed:\n\nSee also\n\nThe best way to encode the options required to link against the specified C\nlibraries is to use a \u201clibname.ini\u201d file, and use `get_info` to retrieve the\nrequired options (see `add_npy_pkg_config` for more information).\n\nGenerate and install a npy-pkg config file from a template.\n\nThe config file generated from `template` is installed in the given install\ndirectory, using `subst_dict` for variable substitution.\n\nThe path of the template, relatively to the current package path.\n\nWhere to install the npy-pkg config file, relatively to the current package\npath.\n\nIf given, any string of the form `@key@` will be replaced by `subst_dict[key]`\nin the template file when installed. The install prefix is always available\nthrough the variable `@prefix@`, since the install prefix is not easy to get\nreliably from setup.py.\n\nSee also\n\nThis works for both standard installs and in-place builds, i.e. the `@prefix@`\nrefer to the source directory for in-place builds.\n\nAssuming the foo.ini.in file has the following content:\n\nThe generated file will have the following content:\n\nand will be installed as foo.ini in the \u2018lib\u2019 subpath.\n\nWhen cross-compiling with numpy distutils, it might be necessary to use\nmodified npy-pkg-config files. Using the default/generated files will link\nwith the host libraries (i.e. libnpymath.a). For cross-compilation you of-\ncourse need to link with target libraries, while using the host Python\ninstallation.\n\nYou can copy out the numpy/core/lib/npy-pkg-config directory, add a pkgdir\nvalue to the .ini files and set NPY_PKG_CONFIG_PATH environment variable to\npoint to the directory with the modified npy-pkg-config files.\n\nExample npymath.ini modified for cross-compilation:\n\nApply glob to paths and prepend local_path if needed.\n\nApplies glob.glob(\u2026) to each path in the sequence (if needed) and pre-pends\nthe local_path if needed. Because this is called on all source lists, this\nallows wildcard characters to be specified in lists of sources for extension\nmodules and libraries and scripts and allows path-names be relative to the\nsource directory.\n\nReturns the numpy.distutils config command instance.\n\nReturn a path to a temporary directory where temporary files should be placed.\n\nCheck for availability of Fortran 77 compiler.\n\nUse it inside source generating function to ensure that setup distribution\ninstance has been initialized.\n\nTrue if a Fortran 77 compiler is available (because a simple Fortran 77 code\nwas able to be compiled successfully).\n\nCheck for availability of Fortran 90 compiler.\n\nUse it inside source generating function to ensure that setup distribution\ninstance has been initialized.\n\nTrue if a Fortran 90 compiler is available (because a simple Fortran 90 code\nwas able to be compiled successfully)\n\nTry to get version string of a package.\n\nReturn a version string of the current package or None if the version\ninformation could not be detected.\n\nThis method scans files named __version__.py, <packagename>_version.py,\nversion.py, and __svn_version__.py for string variables version, __version__,\nand <packagename>_version, until a version number is found.\n\nAppends a data function to the data_files list that will generate\n__svn_version__.py file to the current package directory.\n\nGenerate package __svn_version__.py file from SVN revision number, it will be\nremoved after python exits but will be available when sdist, etc commands are\nexecuted.\n\nIf __svn_version__.py existed before, nothing is done.\n\nThis is intended for working with source directories that are in an SVN\nrepository.\n\nGenerate package __config__.py file containing system_info information used\nduring building the package.\n\nThis file is installed to the package installation directory.\n\nGet resources information.\n\nReturn information (from system_info.get_info) for all of the names in the\nargument list in a single dictionary.\n\nConventional C libraries (installed through `add_library`) are not installed,\nand are just used during the build (they are statically linked). An\ninstallable C library is a pure C library, which does not depend on the python\nC runtime, and is installed such that it may be used by third-party packages.\nTo build and install the C library, you just use the method\n`add_installed_library` instead of `add_library`, which takes the same\narguments except for an additional `install_dir` argument:\n\nTo make the necessary build options available to third parties, you could use\nthe `npy-pkg-config` mechanism implemented in `numpy.distutils`. This\nmechanism is based on a .ini file which contains all the options. A .ini file\nis very similar to .pc files as used by the pkg-config unix utility:\n\nGenerally, the file needs to be generated during the build, since it needs\nsome information known at build time only (e.g. prefix). This is mostly\nautomatic if one uses the `Configuration` method `add_npy_pkg_config`.\nAssuming we have a template file foo.ini.in as follows:\n\nand the following code in setup.py:\n\nThis will install the file foo.ini into the directory package_dir/lib, and the\nfoo.ini file will be generated from foo.ini.in, where each `@version@` will be\nreplaced by `subst_dict['version']`. The dictionary has an additional prefix\nsubstitution rule automatically added, which contains the install prefix\n(since this is not easy to get from setup.py). npy-pkg-config files can also\nbe installed at the same location as used for numpy, using the path returned\nfrom `get_npy_pkg_dir` function.\n\nInfo are easily retrieved from the `get_info` function in\n`numpy.distutils.misc_util`:\n\nAn additional list of paths to look for .ini files can be given to `get_info`.\n\nNumPy distutils supports automatic conversion of source files named\n<somefile>.src. This facility can be used to maintain very similar code blocks\nrequiring only simple changes between blocks. During the build phase of setup,\nif a template file named <somefile>.src is encountered, a new file named\n<somefile> is constructed from the template and placed in the build directory\nto be used instead. Two forms of template conversion are supported. The first\nform occurs for files named <file>.ext.src where ext is a recognized Fortran\nextension (f, f90, f95, f77, for, ftn, pyf). The second form is used for all\nother cases. See Conversion of .src files using Templates.\n\n"}, {"name": "paths()", "path": "reference/distutils#numpy.distutils.misc_util.Configuration.paths", "type": "Packaging ( \n    \n     numpy.distutils\n    \n    )", "text": "\nApply glob to paths and prepend local_path if needed.\n\nApplies glob.glob(\u2026) to each path in the sequence (if needed) and pre-pends\nthe local_path if needed. Because this is called on all source lists, this\nallows wildcard characters to be specified in lists of sources for extension\nmodules and libraries and scripts and allows path-names be relative to the\nsource directory.\n\n"}, {"name": "Performance", "path": "reference/random/performance", "type": "Comparing Performance", "text": "\nThe recommended generator for general use is `PCG64` or its upgraded variant\n`PCG64DXSM` for heavily-parallel use cases. They are statistically high\nquality, full-featured, and fast on most platforms, but somewhat slow when\ncompiled for 32-bit processes. See Upgrading PCG64 with PCG64DXSM for details\non when heavy parallelism would indicate using `PCG64DXSM`.\n\n`Philox` is fairly slow, but its statistical properties have very high\nquality, and it is easy to get an assuredly-independent stream by using unique\nkeys. If that is the style you wish to use for parallel streams, or you are\nporting from another system that uses that style, then `Philox` is your\nchoice.\n\n`SFC64` is statistically high quality and very fast. However, it lacks\njumpability. If you are not using that capability and want lots of speed, even\non 32-bit processes, this is your choice.\n\n`MT19937` fails some statistical tests and is not especially fast compared to\nmodern PRNGs. For these reasons, we mostly do not recommend using it on its\nown, only through the legacy `RandomState` for reproducing old results. That\nsaid, it has a very long history as a default in many systems.\n\nThe timings below are the time in ns to produce 1 random value from a specific\ndistribution. The original `MT19937` generator is much slower since it\nrequires 2 32-bit values to equal the output of the faster generators.\n\nInteger performance has a similar ordering.\n\nThe pattern is similar for other, more complex generators. The normal\nperformance of the legacy `RandomState` generator is much lower than the other\nsince it uses the Box-Muller transform rather than the Ziggurat method. The\nperformance gap for Exponentials is also large due to the cost of computing\nthe log function to invert the CDF. The column labeled MT19973 uses the same\n32-bit generator as `RandomState` but produces random variates using\n`Generator`.\n\nMT19937\n\nPCG64\n\nPCG64DXSM\n\nPhilox\n\nSFC64\n\nRandomState\n\n32-bit Unsigned Ints\n\n3.3\n\n1.9\n\n2.0\n\n3.3\n\n1.8\n\n3.1\n\n64-bit Unsigned Ints\n\n5.6\n\n3.2\n\n2.9\n\n4.9\n\n2.5\n\n5.5\n\nUniforms\n\n5.9\n\n3.1\n\n2.9\n\n5.0\n\n2.6\n\n6.0\n\nNormals\n\n13.9\n\n10.8\n\n10.5\n\n12.0\n\n8.3\n\n56.8\n\nExponentials\n\n9.1\n\n6.0\n\n5.8\n\n8.1\n\n5.4\n\n63.9\n\nGammas\n\n37.2\n\n30.8\n\n28.9\n\n34.0\n\n27.5\n\n77.0\n\nBinomials\n\n21.3\n\n17.4\n\n17.6\n\n19.3\n\n15.6\n\n21.4\n\nLaplaces\n\n73.2\n\n72.3\n\n76.1\n\n73.0\n\n72.3\n\n82.5\n\nPoissons\n\n111.7\n\n103.4\n\n100.5\n\n109.4\n\n90.7\n\n115.2\n\nThe next table presents the performance in percentage relative to values\ngenerated by the legacy generator, `RandomState(MT19937())`. The overall\nperformance was computed using a geometric mean.\n\nMT19937\n\nPCG64\n\nPCG64DXSM\n\nPhilox\n\nSFC64\n\n32-bit Unsigned Ints\n\n96\n\n162\n\n160\n\n96\n\n175\n\n64-bit Unsigned Ints\n\n97\n\n171\n\n188\n\n113\n\n218\n\nUniforms\n\n102\n\n192\n\n206\n\n121\n\n233\n\nNormals\n\n409\n\n526\n\n541\n\n471\n\n684\n\nExponentials\n\n701\n\n1071\n\n1101\n\n784\n\n1179\n\nGammas\n\n207\n\n250\n\n266\n\n227\n\n281\n\nBinomials\n\n100\n\n123\n\n122\n\n111\n\n138\n\nLaplaces\n\n113\n\n114\n\n108\n\n113\n\n114\n\nPoissons\n\n103\n\n111\n\n115\n\n105\n\n127\n\nOverall\n\n159\n\n219\n\n225\n\n174\n\n251\n\nNote\n\nAll timings were taken using Linux on an AMD Ryzen 9 3900X processor.\n\nPerformance differs across platforms due to compiler and hardware availability\n(e.g., register width) differences. The default bit generator has been chosen\nto perform well on 64-bit platforms. Performance on 32-bit operating systems\nis very different.\n\nThe values reported are normalized relative to the speed of MT19937 in each\ntable. A value of 100 indicates that the performance matches the MT19937.\nHigher values indicate improved performance. These values cannot be compared\nacross tables.\n\nDistribution\n\nMT19937\n\nPCG64\n\nPCG64DXSM\n\nPhilox\n\nSFC64\n\n32-bit Unsigned Ints\n\n100\n\n168\n\n166\n\n100\n\n182\n\n64-bit Unsigned Ints\n\n100\n\n176\n\n193\n\n116\n\n224\n\nUniforms\n\n100\n\n188\n\n202\n\n118\n\n228\n\nNormals\n\n100\n\n128\n\n132\n\n115\n\n167\n\nExponentials\n\n100\n\n152\n\n157\n\n111\n\n168\n\nOverall\n\n100\n\n161\n\n168\n\n112\n\n192\n\nThe relative performance on 64-bit Linux and 64-bit Windows is broadly similar\nwith the notable exception of the Philox generator.\n\nDistribution\n\nMT19937\n\nPCG64\n\nPCG64DXSM\n\nPhilox\n\nSFC64\n\n32-bit Unsigned Ints\n\n100\n\n155\n\n131\n\n29\n\n150\n\n64-bit Unsigned Ints\n\n100\n\n157\n\n143\n\n25\n\n154\n\nUniforms\n\n100\n\n151\n\n144\n\n24\n\n155\n\nNormals\n\n100\n\n129\n\n128\n\n37\n\n150\n\nExponentials\n\n100\n\n150\n\n145\n\n28\n\n159\n\nOverall\n\n100\n\n148\n\n138\n\n28\n\n154\n\nThe performance of 64-bit generators on 32-bit Windows is much lower than on\n64-bit operating systems due to register width. MT19937, the generator that\nhas been in NumPy since 2005, operates on 32-bit integers.\n\nDistribution\n\nMT19937\n\nPCG64\n\nPCG64DXSM\n\nPhilox\n\nSFC64\n\n32-bit Unsigned Ints\n\n100\n\n24\n\n34\n\n14\n\n57\n\n64-bit Unsigned Ints\n\n100\n\n21\n\n32\n\n14\n\n74\n\nUniforms\n\n100\n\n21\n\n34\n\n16\n\n73\n\nNormals\n\n100\n\n36\n\n57\n\n28\n\n101\n\nExponentials\n\n100\n\n28\n\n44\n\n20\n\n88\n\nOverall\n\n100\n\n25\n\n39\n\n18\n\n77\n\nNote\n\nLinux timings used Ubuntu 20.04 and GCC 9.3.0. Windows timings were made on\nWindows 10 using Microsoft C/C++ Optimizing Compiler Version 19 (Visual Studio\n2019). All timings were produced on an AMD Ryzen 9 3900X processor.\n\n"}, {"name": "Poly1d", "path": "reference/routines.polynomials.poly1d", "type": "Poly1d", "text": "\n`poly1d`(c_or_r[, r, variable])\n\nA one-dimensional polynomial class.\n\n`polyval`(p, x)\n\nEvaluate a polynomial at specific values.\n\n`poly`(seq_of_zeros)\n\nFind the coefficients of a polynomial with the given sequence of roots.\n\n`roots`(p)\n\nReturn the roots of a polynomial with coefficients given in p.\n\n`polyfit`(x, y, deg[, rcond, full, w, cov])\n\nLeast squares polynomial fit.\n\n`polyder`(p[, m])\n\nReturn the derivative of the specified order of a polynomial.\n\n`polyint`(p[, m, k])\n\nReturn an antiderivative (indefinite integral) of a polynomial.\n\n`polyadd`(a1, a2)\n\nFind the sum of two polynomials.\n\n`polydiv`(u, v)\n\nReturns the quotient and remainder of polynomial division.\n\n`polymul`(a1, a2)\n\nFind the product of two polynomials.\n\n`polysub`(a1, a2)\n\nDifference (subtraction) of two polynomials.\n\n`RankWarning`\n\nIssued by `polyfit` when the Vandermonde matrix is rank deficient.\n\n"}, {"name": "poly1d.__call__()", "path": "reference/generated/numpy.poly1d.__call__", "type": "numpy.poly1d", "text": "\nmethod\n\nCall self as a function.\n\n"}, {"name": "poly1d.deriv()", "path": "reference/generated/numpy.poly1d.deriv", "type": "numpy.poly1d", "text": "\nmethod\n\nReturn a derivative of this polynomial.\n\nRefer to `polyder` for full documentation.\n\nSee also\n\nequivalent function\n\n"}, {"name": "poly1d.integ()", "path": "reference/generated/numpy.poly1d.integ", "type": "numpy.poly1d", "text": "\nmethod\n\nReturn an antiderivative (indefinite integral) of this polynomial.\n\nRefer to `polyint` for full documentation.\n\nSee also\n\nequivalent function\n\n"}, {"name": "polynomial.chebyshev.cheb2poly()", "path": "reference/generated/numpy.polynomial.chebyshev.cheb2poly", "type": "numpy.polynomial.chebyshev.cheb2poly", "text": "\nConvert a Chebyshev series to a polynomial.\n\nConvert an array representing the coefficients of a Chebyshev series, ordered\nfrom lowest degree to highest, to an array of the coefficients of the\nequivalent polynomial (relative to the \u201cstandard\u201d basis) ordered from lowest\nto highest degree.\n\n1-D array containing the Chebyshev series coefficients, ordered from lowest\norder term to highest.\n\n1-D array containing the coefficients of the equivalent polynomial (relative\nto the \u201cstandard\u201d basis) ordered from lowest order term to highest.\n\nSee also\n\nThe easy way to do conversions between polynomial basis sets is to use the\nconvert method of a class instance.\n\n"}, {"name": "polynomial.chebyshev.chebadd()", "path": "reference/generated/numpy.polynomial.chebyshev.chebadd", "type": "numpy.polynomial.chebyshev.chebadd", "text": "\nAdd one Chebyshev series to another.\n\nReturns the sum of two Chebyshev series `c1` \\+ `c2`. The arguments are\nsequences of coefficients ordered from lowest order term to highest, i.e.,\n[1,2,3] represents the series `T_0 + 2*T_1 + 3*T_2`.\n\n1-D arrays of Chebyshev series coefficients ordered from low to high.\n\nArray representing the Chebyshev series of their sum.\n\nSee also\n\nUnlike multiplication, division, etc., the sum of two Chebyshev series is a\nChebyshev series (without having to \u201creproject\u201d the result onto the basis set)\nso addition, just like that of \u201cstandard\u201d polynomials, is simply \u201ccomponent-\nwise.\u201d\n\n"}, {"name": "polynomial.chebyshev.chebcompanion()", "path": "reference/generated/numpy.polynomial.chebyshev.chebcompanion", "type": "numpy.polynomial.chebyshev.chebcompanion", "text": "\nReturn the scaled companion matrix of c.\n\nThe basis polynomials are scaled so that the companion matrix is symmetric\nwhen `c` is a Chebyshev basis polynomial. This provides better eigenvalue\nestimates than the unscaled case and for basis polynomials the eigenvalues are\nguaranteed to be real if `numpy.linalg.eigvalsh` is used to obtain them.\n\n1-D array of Chebyshev series coefficients ordered from low to high degree.\n\nScaled companion matrix of dimensions (deg, deg).\n\nNew in version 1.7.0.\n\n"}, {"name": "polynomial.chebyshev.chebder()", "path": "reference/generated/numpy.polynomial.chebyshev.chebder", "type": "numpy.polynomial.chebyshev.chebder", "text": "\nDifferentiate a Chebyshev series.\n\nReturns the Chebyshev series coefficients `c` differentiated `m` times along\n`axis`. At each iteration the result is multiplied by `scl` (the scaling\nfactor is for use in a linear change of variable). The argument `c` is an\narray of coefficients from low to high degree along each axis, e.g., [1,2,3]\nrepresents the series `1*T_0 + 2*T_1 + 3*T_2` while [[1,2],[1,2]] represents\n`1*T_0(x)*T_0(y) + 1*T_1(x)*T_0(y) + 2*T_0(x)*T_1(y) + 2*T_1(x)*T_1(y)` if\naxis=0 is `x` and axis=1 is `y`.\n\nArray of Chebyshev series coefficients. If c is multidimensional the different\naxis correspond to different variables with the degree in each axis given by\nthe corresponding index.\n\nNumber of derivatives taken, must be non-negative. (Default: 1)\n\nEach differentiation is multiplied by `scl`. The end result is multiplication\nby `scl**m`. This is for use in a linear change of variable. (Default: 1)\n\nAxis over which the derivative is taken. (Default: 0).\n\nNew in version 1.7.0.\n\nChebyshev series of the derivative.\n\nSee also\n\nIn general, the result of differentiating a C-series needs to be \u201creprojected\u201d\nonto the C-series basis set. Thus, typically, the result of this function is\n\u201cunintuitive,\u201d albeit correct; see Examples section below.\n\n"}, {"name": "polynomial.chebyshev.chebdiv()", "path": "reference/generated/numpy.polynomial.chebyshev.chebdiv", "type": "numpy.polynomial.chebyshev.chebdiv", "text": "\nDivide one Chebyshev series by another.\n\nReturns the quotient-with-remainder of two Chebyshev series `c1` / `c2`. The\narguments are sequences of coefficients from lowest order \u201cterm\u201d to highest,\ne.g., [1,2,3] represents the series `T_0 + 2*T_1 + 3*T_2`.\n\n1-D arrays of Chebyshev series coefficients ordered from low to high.\n\nOf Chebyshev series coefficients representing the quotient and remainder.\n\nSee also\n\nIn general, the (polynomial) division of one C-series by another results in\nquotient and remainder terms that are not in the Chebyshev polynomial basis\nset. Thus, to express these results as C-series, it is typically necessary to\n\u201creproject\u201d the results onto said basis set, which typically produces\n\u201cunintuitive\u201d (but correct) results; see Examples section below.\n\n"}, {"name": "polynomial.chebyshev.chebdomain", "path": "reference/generated/numpy.polynomial.chebyshev.chebdomain", "type": "numpy.polynomial.chebyshev.chebdomain", "text": "\nAn array object represents a multidimensional, homogeneous array of fixed-size\nitems. An associated data-type object describes the format of each element in\nthe array (its byte-order, how many bytes it occupies in memory, whether it is\nan integer, a floating point number, or something else, etc.)\n\nArrays should be constructed using `array`, `zeros` or `empty` (refer to the\nSee Also section below). The parameters given here refer to a low-level method\n(`ndarray(\u2026)`) for instantiating an array.\n\nFor more information, refer to the `numpy` module and examine the methods and\nattributes of an array.\n\nShape of created array.\n\nAny object that can be interpreted as a numpy data type.\n\nUsed to fill the array with data.\n\nOffset of array data in buffer.\n\nStrides of data in memory.\n\nRow-major (C-style) or column-major (Fortran-style) order.\n\nSee also\n\nConstruct an array.\n\nCreate an array, each element of which is zero.\n\nCreate an array, but leave its allocated memory unchanged (i.e., it contains\n\u201cgarbage\u201d).\n\nCreate a data-type.\n\nAn ndarray alias generic w.r.t. its `dtype.type`.\n\nThere are two modes of creating an array using `__new__`:\n\nNo `__init__` method is needed because the array is fully initialized after\nthe `__new__` method.\n\nThese examples illustrate the low-level `ndarray` constructor. Refer to the\n`See Also` section above for easier ways of constructing an ndarray.\n\nFirst mode, `buffer` is None:\n\nSecond mode:\n\nTranspose of the array.\n\nThe array\u2019s elements, in memory.\n\nDescribes the format of the elements in the array.\n\nDictionary containing information related to memory use, e.g., \u2018C_CONTIGUOUS\u2019,\n\u2018OWNDATA\u2019, \u2018WRITEABLE\u2019, etc.\n\nFlattened version of the array as an iterator. The iterator allows\nassignments, e.g., `x.flat = 3` (See `ndarray.flat` for assignment examples;\nTODO).\n\nImaginary part of the array.\n\nReal part of the array.\n\nNumber of elements in the array.\n\nThe memory use of each array element in bytes.\n\nThe total number of bytes required to store the array data, i.e., `itemsize *\nsize`.\n\nThe array\u2019s number of dimensions.\n\nShape of the array.\n\nThe step-size required to move from one element to the next in memory. For\nexample, a contiguous `(3, 4)` array of type `int16` in C-order has strides\n`(8, 2)`. This implies that to move from element to element in memory requires\njumps of 2 bytes. To move from row-to-row, one needs to jump 8 bytes at a time\n(`2 * 4`).\n\nClass containing properties of the array needed for interaction with ctypes.\n\nIf the array is a view into another array, that array is its `base` (unless\nthat array is also a view). The `base` array is where the array data is\nactually stored.\n\n"}, {"name": "polynomial.chebyshev.chebfit()", "path": "reference/generated/numpy.polynomial.chebyshev.chebfit", "type": "numpy.polynomial.chebyshev.chebfit", "text": "\nLeast squares fit of Chebyshev series to data.\n\nReturn the coefficients of a Chebyshev series of degree `deg` that is the\nleast squares fit to the data values `y` given at points `x`. If `y` is 1-D\nthe returned coefficients will also be 1-D. If `y` is 2-D multiple fits are\ndone, one for each column of `y`, and the resulting coefficients are stored in\nthe corresponding columns of a 2-D return. The fitted polynomial(s) are in the\nform\n\nwhere `n` is `deg`.\n\nx-coordinates of the M sample points `(x[i], y[i])`.\n\ny-coordinates of the sample points. Several data sets of sample points sharing\nthe same x-coordinates can be fitted at once by passing in a 2D-array that\ncontains one dataset per column.\n\nDegree(s) of the fitting polynomials. If `deg` is a single integer, all terms\nup to and including the `deg`\u2019th term are included in the fit. For NumPy\nversions >= 1.11.0 a list of integers specifying the degrees of the terms to\ninclude may be used instead.\n\nRelative condition number of the fit. Singular values smaller than this\nrelative to the largest singular value will be ignored. The default value is\nlen(x)*eps, where eps is the relative precision of the float type, about 2e-16\nin most cases.\n\nSwitch determining nature of return value. When it is False (the default) just\nthe coefficients are returned, when True diagnostic information from the\nsingular value decomposition is also returned.\n\nWeights. If not None, the weight `w[i]` applies to the unsquared residual\n`y[i] - y_hat[i]` at `x[i]`. Ideally the weights are chosen so that the errors\nof the products `w[i]*y[i]` all have the same variance. When using inverse-\nvariance weighting, use `w[i] = 1/sigma(y[i])`. The default value is None.\n\nNew in version 1.5.0.\n\nChebyshev coefficients ordered from low to high. If `y` was 2-D, the\ncoefficients for the data in column k of `y` are in column `k`.\n\nThese values are only returned if `full == True`\n\nFor more details, see `numpy.linalg.lstsq`.\n\nThe rank of the coefficient matrix in the least-squares fit is deficient. The\nwarning is only raised if `full == False`. The warnings can be turned off by\n\nSee also\n\nEvaluates a Chebyshev series.\n\nVandermonde matrix of Chebyshev series.\n\nChebyshev weight function.\n\nComputes a least-squares fit from the matrix.\n\nComputes spline fits.\n\nThe solution is the coefficients of the Chebyshev series `p` that minimizes\nthe sum of the weighted squared errors\n\nwhere \\\\(w_j\\\\) are the weights. This problem is solved by setting up as the\n(typically) overdetermined matrix equation\n\nwhere `V` is the weighted pseudo Vandermonde matrix of `x`, `c` are the\ncoefficients to be solved for, `w` are the weights, and `y` are the observed\nvalues. This equation is then solved using the singular value decomposition of\n`V`.\n\nIf some of the singular values of `V` are so small that they are neglected,\nthen a `RankWarning` will be issued. This means that the coefficient values\nmay be poorly determined. Using a lower order fit will usually get rid of the\nwarning. The `rcond` parameter can also be set to a value smaller than its\ndefault, but the resulting fit may be spurious and have large contributions\nfrom roundoff error.\n\nFits using Chebyshev series are usually better conditioned than fits using\npower series, but much can depend on the distribution of the sample points and\nthe smoothness of the data. If the quality of the fit is inadequate splines\nmay be a good alternative.\n\nWikipedia, \u201cCurve fitting\u201d, https://en.wikipedia.org/wiki/Curve_fitting\n\n"}, {"name": "polynomial.chebyshev.chebfromroots()", "path": "reference/generated/numpy.polynomial.chebyshev.chebfromroots", "type": "numpy.polynomial.chebyshev.chebfromroots", "text": "\nGenerate a Chebyshev series with given roots.\n\nThe function returns the coefficients of the polynomial\n\nin Chebyshev form, where the `r_n` are the roots specified in `roots`. If a\nzero has multiplicity n, then it must appear in `roots` n times. For instance,\nif 2 is a root of multiplicity three and 3 is a root of multiplicity 2, then\n`roots` looks something like [2, 2, 2, 3, 3]. The roots can appear in any\norder.\n\nIf the returned coefficients are `c`, then\n\nThe coefficient of the last term is not generally 1 for monic polynomials in\nChebyshev form.\n\nSequence containing the roots.\n\n1-D array of coefficients. If all roots are real then `out` is a real array,\nif some of the roots are complex, then `out` is complex even if all the\ncoefficients in the result are real (see Examples below).\n\nSee also\n\n"}, {"name": "polynomial.chebyshev.chebgauss()", "path": "reference/generated/numpy.polynomial.chebyshev.chebgauss", "type": "numpy.polynomial.chebyshev.chebgauss", "text": "\nGauss-Chebyshev quadrature.\n\nComputes the sample points and weights for Gauss-Chebyshev quadrature. These\nsample points and weights will correctly integrate polynomials of degree\n\\\\(2*deg - 1\\\\) or less over the interval \\\\([-1, 1]\\\\) with the weight\nfunction \\\\(f(x) = 1/\\sqrt{1 - x^2}\\\\).\n\nNumber of sample points and weights. It must be >= 1.\n\n1-D ndarray containing the sample points.\n\n1-D ndarray containing the weights.\n\nNew in version 1.7.0.\n\nThe results have only been tested up to degree 100, higher degrees may be\nproblematic. For Gauss-Chebyshev there are closed form solutions for the\nsample points and weights. If n = `deg`, then\n\n"}, {"name": "polynomial.chebyshev.chebgrid2d()", "path": "reference/generated/numpy.polynomial.chebyshev.chebgrid2d", "type": "numpy.polynomial.chebyshev.chebgrid2d", "text": "\nEvaluate a 2-D Chebyshev series on the Cartesian product of x and y.\n\nThis function returns the values:\n\nwhere the points `(a, b)` consist of all pairs formed by taking `a` from `x`\nand `b` from `y`. The resulting points form a grid with `x` in the first\ndimension and `y` in the second.\n\nThe parameters `x` and `y` are converted to arrays only if they are tuples or\na lists, otherwise they are treated as a scalars. In either case, either `x`\nand `y` or their elements must support multiplication and addition both with\nthemselves and with the elements of `c`.\n\nIf `c` has fewer than two dimensions, ones are implicitly appended to its\nshape to make it 2-D. The shape of the result will be c.shape[2:] + x.shape +\ny.shape.\n\nThe two dimensional series is evaluated at the points in the Cartesian product\nof `x` and `y`. If `x` or `y` is a list or tuple, it is first converted to an\nndarray, otherwise it is left unchanged and, if it isn\u2019t an ndarray, it is\ntreated as a scalar.\n\nArray of coefficients ordered so that the coefficient of the term of multi-\ndegree i,j is contained in `c[i,j]`. If `c` has dimension greater than two the\nremaining indices enumerate multiple sets of coefficients.\n\nThe values of the two dimensional Chebyshev series at points in the Cartesian\nproduct of `x` and `y`.\n\nSee also\n\nNew in version 1.7.0.\n\n"}, {"name": "polynomial.chebyshev.chebgrid3d()", "path": "reference/generated/numpy.polynomial.chebyshev.chebgrid3d", "type": "numpy.polynomial.chebyshev.chebgrid3d", "text": "\nEvaluate a 3-D Chebyshev series on the Cartesian product of x, y, and z.\n\nThis function returns the values:\n\nwhere the points `(a, b, c)` consist of all triples formed by taking `a` from\n`x`, `b` from `y`, and `c` from `z`. The resulting points form a grid with `x`\nin the first dimension, `y` in the second, and `z` in the third.\n\nThe parameters `x`, `y`, and `z` are converted to arrays only if they are\ntuples or a lists, otherwise they are treated as a scalars. In either case,\neither `x`, `y`, and `z` or their elements must support multiplication and\naddition both with themselves and with the elements of `c`.\n\nIf `c` has fewer than three dimensions, ones are implicitly appended to its\nshape to make it 3-D. The shape of the result will be c.shape[3:] + x.shape +\ny.shape + z.shape.\n\nThe three dimensional series is evaluated at the points in the Cartesian\nproduct of `x`, `y`, and `z`. If `x`,`y`, or `z` is a list or tuple, it is\nfirst converted to an ndarray, otherwise it is left unchanged and, if it isn\u2019t\nan ndarray, it is treated as a scalar.\n\nArray of coefficients ordered so that the coefficients for terms of degree i,j\nare contained in `c[i,j]`. If `c` has dimension greater than two the remaining\nindices enumerate multiple sets of coefficients.\n\nThe values of the two dimensional polynomial at points in the Cartesian\nproduct of `x` and `y`.\n\nSee also\n\nNew in version 1.7.0.\n\n"}, {"name": "polynomial.chebyshev.chebint()", "path": "reference/generated/numpy.polynomial.chebyshev.chebint", "type": "numpy.polynomial.chebyshev.chebint", "text": "\nIntegrate a Chebyshev series.\n\nReturns the Chebyshev series coefficients `c` integrated `m` times from `lbnd`\nalong `axis`. At each iteration the resulting series is multiplied by `scl`\nand an integration constant, `k`, is added. The scaling factor is for use in a\nlinear change of variable. (\u201cBuyer beware\u201d: note that, depending on what one\nis doing, one may want `scl` to be the reciprocal of what one might expect;\nfor more information, see the Notes section below.) The argument `c` is an\narray of coefficients from low to high degree along each axis, e.g., [1,2,3]\nrepresents the series `T_0 + 2*T_1 + 3*T_2` while [[1,2],[1,2]] represents\n`1*T_0(x)*T_0(y) + 1*T_1(x)*T_0(y) + 2*T_0(x)*T_1(y) + 2*T_1(x)*T_1(y)` if\naxis=0 is `x` and axis=1 is `y`.\n\nArray of Chebyshev series coefficients. If c is multidimensional the different\naxis correspond to different variables with the degree in each axis given by\nthe corresponding index.\n\nOrder of integration, must be positive. (Default: 1)\n\nIntegration constant(s). The value of the first integral at zero is the first\nvalue in the list, the value of the second integral at zero is the second\nvalue, etc. If `k == []` (the default), all constants are set to zero. If `m\n== 1`, a single scalar can be given instead of a list.\n\nThe lower bound of the integral. (Default: 0)\n\nFollowing each integration the result is multiplied by `scl` before the\nintegration constant is added. (Default: 1)\n\nAxis over which the integral is taken. (Default: 0).\n\nNew in version 1.7.0.\n\nC-series coefficients of the integral.\n\nIf `m < 1`, `len(k) > m`, `np.ndim(lbnd) != 0`, or `np.ndim(scl) != 0`.\n\nSee also\n\nNote that the result of each integration is multiplied by `scl`. Why is this\nimportant to note? Say one is making a linear change of variable \\\\(u = ax +\nb\\\\) in an integral relative to `x`. Then \\\\(dx = du/a\\\\), so one will need to\nset `scl` equal to \\\\(1/a\\\\)\\- perhaps not what one would have first thought.\n\nAlso note that, in general, the result of integrating a C-series needs to be\n\u201creprojected\u201d onto the C-series basis set. Thus, typically, the result of this\nfunction is \u201cunintuitive,\u201d albeit correct; see Examples section below.\n\n"}, {"name": "polynomial.chebyshev.chebinterpolate()", "path": "reference/generated/numpy.polynomial.chebyshev.chebinterpolate", "type": "numpy.polynomial.chebyshev.chebinterpolate", "text": "\nInterpolate a function at the Chebyshev points of the first kind.\n\nReturns the Chebyshev series that interpolates `func` at the Chebyshev points\nof the first kind in the interval [-1, 1]. The interpolating series tends to a\nminmax approximation to `func` with increasing `deg` if the function is\ncontinuous in the interval.\n\nNew in version 1.14.0.\n\nThe function to be approximated. It must be a function of a single variable of\nthe form `f(x, a, b, c...)`, where `a, b, c...` are extra arguments passed in\nthe `args` parameter.\n\nDegree of the interpolating polynomial\n\nExtra arguments to be used in the function call. Default is no extra\narguments.\n\nChebyshev coefficients of the interpolating series ordered from low to high.\n\nThe Chebyshev polynomials used in the interpolation are orthogonal when\nsampled at the Chebyshev points of the first kind. If it is desired to\nconstrain some of the coefficients they can simply be set to the desired value\nafter the interpolation, no new interpolation or fit is needed. This is\nespecially useful if it is known apriori that some of coefficients are zero.\nFor instance, if the function is even then the coefficients of the terms of\nodd degree in the result can be set to zero.\n\n"}, {"name": "polynomial.chebyshev.chebline()", "path": "reference/generated/numpy.polynomial.chebyshev.chebline", "type": "numpy.polynomial.chebyshev.chebline", "text": "\nChebyshev series whose graph is a straight line.\n\nThe specified line is given by `off + scl*x`.\n\nThis module\u2019s representation of the Chebyshev series for `off + scl*x`.\n\nSee also\n\n"}, {"name": "polynomial.chebyshev.chebmul()", "path": "reference/generated/numpy.polynomial.chebyshev.chebmul", "type": "numpy.polynomial.chebyshev.chebmul", "text": "\nMultiply one Chebyshev series by another.\n\nReturns the product of two Chebyshev series `c1` * `c2`. The arguments are\nsequences of coefficients, from lowest order \u201cterm\u201d to highest, e.g., [1,2,3]\nrepresents the series `T_0 + 2*T_1 + 3*T_2`.\n\n1-D arrays of Chebyshev series coefficients ordered from low to high.\n\nOf Chebyshev series coefficients representing their product.\n\nSee also\n\nIn general, the (polynomial) product of two C-series results in terms that are\nnot in the Chebyshev polynomial basis set. Thus, to express the product as a\nC-series, it is typically necessary to \u201creproject\u201d the product onto said basis\nset, which typically produces \u201cunintuitive live\u201d (but correct) results; see\nExamples section below.\n\n"}, {"name": "polynomial.chebyshev.chebmulx()", "path": "reference/generated/numpy.polynomial.chebyshev.chebmulx", "type": "numpy.polynomial.chebyshev.chebmulx", "text": "\nMultiply a Chebyshev series by x.\n\nMultiply the polynomial `c` by x, where x is the independent variable.\n\n1-D array of Chebyshev series coefficients ordered from low to high.\n\nArray representing the result of the multiplication.\n\nNew in version 1.5.0.\n\n"}, {"name": "polynomial.chebyshev.chebone", "path": "reference/generated/numpy.polynomial.chebyshev.chebone", "type": "numpy.polynomial.chebyshev.chebone", "text": "\nAn array object represents a multidimensional, homogeneous array of fixed-size\nitems. An associated data-type object describes the format of each element in\nthe array (its byte-order, how many bytes it occupies in memory, whether it is\nan integer, a floating point number, or something else, etc.)\n\nArrays should be constructed using `array`, `zeros` or `empty` (refer to the\nSee Also section below). The parameters given here refer to a low-level method\n(`ndarray(\u2026)`) for instantiating an array.\n\nFor more information, refer to the `numpy` module and examine the methods and\nattributes of an array.\n\nShape of created array.\n\nAny object that can be interpreted as a numpy data type.\n\nUsed to fill the array with data.\n\nOffset of array data in buffer.\n\nStrides of data in memory.\n\nRow-major (C-style) or column-major (Fortran-style) order.\n\nSee also\n\nConstruct an array.\n\nCreate an array, each element of which is zero.\n\nCreate an array, but leave its allocated memory unchanged (i.e., it contains\n\u201cgarbage\u201d).\n\nCreate a data-type.\n\nAn ndarray alias generic w.r.t. its `dtype.type`.\n\nThere are two modes of creating an array using `__new__`:\n\nNo `__init__` method is needed because the array is fully initialized after\nthe `__new__` method.\n\nThese examples illustrate the low-level `ndarray` constructor. Refer to the\n`See Also` section above for easier ways of constructing an ndarray.\n\nFirst mode, `buffer` is None:\n\nSecond mode:\n\nTranspose of the array.\n\nThe array\u2019s elements, in memory.\n\nDescribes the format of the elements in the array.\n\nDictionary containing information related to memory use, e.g., \u2018C_CONTIGUOUS\u2019,\n\u2018OWNDATA\u2019, \u2018WRITEABLE\u2019, etc.\n\nFlattened version of the array as an iterator. The iterator allows\nassignments, e.g., `x.flat = 3` (See `ndarray.flat` for assignment examples;\nTODO).\n\nImaginary part of the array.\n\nReal part of the array.\n\nNumber of elements in the array.\n\nThe memory use of each array element in bytes.\n\nThe total number of bytes required to store the array data, i.e., `itemsize *\nsize`.\n\nThe array\u2019s number of dimensions.\n\nShape of the array.\n\nThe step-size required to move from one element to the next in memory. For\nexample, a contiguous `(3, 4)` array of type `int16` in C-order has strides\n`(8, 2)`. This implies that to move from element to element in memory requires\njumps of 2 bytes. To move from row-to-row, one needs to jump 8 bytes at a time\n(`2 * 4`).\n\nClass containing properties of the array needed for interaction with ctypes.\n\nIf the array is a view into another array, that array is its `base` (unless\nthat array is also a view). The `base` array is where the array data is\nactually stored.\n\n"}, {"name": "polynomial.chebyshev.chebpow()", "path": "reference/generated/numpy.polynomial.chebyshev.chebpow", "type": "numpy.polynomial.chebyshev.chebpow", "text": "\nRaise a Chebyshev series to a power.\n\nReturns the Chebyshev series `c` raised to the power `pow`. The argument `c`\nis a sequence of coefficients ordered from low to high. i.e., [1,2,3] is the\nseries `T_0 + 2*T_1 + 3*T_2.`\n\n1-D array of Chebyshev series coefficients ordered from low to high.\n\nPower to which the series will be raised\n\nMaximum power allowed. This is mainly to limit growth of the series to\nunmanageable size. Default is 16\n\nChebyshev series of power.\n\nSee also\n\n"}, {"name": "polynomial.chebyshev.chebpts1()", "path": "reference/generated/numpy.polynomial.chebyshev.chebpts1", "type": "numpy.polynomial.chebyshev.chebpts1", "text": "\nChebyshev points of the first kind.\n\nThe Chebyshev points of the first kind are the points `cos(x)`, where `x =\n[pi*(k + .5)/npts for k in range(npts)]`.\n\nNumber of sample points desired.\n\nThe Chebyshev points of the first kind.\n\nSee also\n\nNew in version 1.5.0.\n\n"}, {"name": "polynomial.chebyshev.chebpts2()", "path": "reference/generated/numpy.polynomial.chebyshev.chebpts2", "type": "numpy.polynomial.chebyshev.chebpts2", "text": "\nChebyshev points of the second kind.\n\nThe Chebyshev points of the second kind are the points `cos(x)`, where `x =\n[pi*k/(npts - 1) for k in range(npts)]`.\n\nNumber of sample points desired.\n\nThe Chebyshev points of the second kind.\n\nNew in version 1.5.0.\n\n"}, {"name": "polynomial.chebyshev.chebroots()", "path": "reference/generated/numpy.polynomial.chebyshev.chebroots", "type": "numpy.polynomial.chebyshev.chebroots", "text": "\nCompute the roots of a Chebyshev series.\n\nReturn the roots (a.k.a. \u201czeros\u201d) of the polynomial\n\n1-D array of coefficients.\n\nArray of the roots of the series. If all the roots are real, then `out` is\nalso real, otherwise it is complex.\n\nSee also\n\nThe root estimates are obtained as the eigenvalues of the companion matrix,\nRoots far from the origin of the complex plane may have large errors due to\nthe numerical instability of the series for such values. Roots with\nmultiplicity greater than 1 will also show larger errors as the value of the\nseries near such points is relatively insensitive to errors in the roots.\nIsolated roots near the origin can be improved by a few iterations of Newton\u2019s\nmethod.\n\nThe Chebyshev series basis polynomials aren\u2019t powers of `x` so the results of\nthis function may seem unintuitive.\n\n"}, {"name": "polynomial.chebyshev.chebsub()", "path": "reference/generated/numpy.polynomial.chebyshev.chebsub", "type": "numpy.polynomial.chebyshev.chebsub", "text": "\nSubtract one Chebyshev series from another.\n\nReturns the difference of two Chebyshev series `c1` \\- `c2`. The sequences of\ncoefficients are from lowest order term to highest, i.e., [1,2,3] represents\nthe series `T_0 + 2*T_1 + 3*T_2`.\n\n1-D arrays of Chebyshev series coefficients ordered from low to high.\n\nOf Chebyshev series coefficients representing their difference.\n\nSee also\n\nUnlike multiplication, division, etc., the difference of two Chebyshev series\nis a Chebyshev series (without having to \u201creproject\u201d the result onto the basis\nset) so subtraction, just like that of \u201cstandard\u201d polynomials, is simply\n\u201ccomponent-wise.\u201d\n\n"}, {"name": "polynomial.chebyshev.chebtrim()", "path": "reference/generated/numpy.polynomial.chebyshev.chebtrim", "type": "numpy.polynomial.chebyshev.chebtrim", "text": "\nRemove \u201csmall\u201d \u201ctrailing\u201d coefficients from a polynomial.\n\n\u201cSmall\u201d means \u201csmall in absolute value\u201d and is controlled by the parameter\n`tol`; \u201ctrailing\u201d means highest order coefficient(s), e.g., in `[0, 1, 1, 0,\n0]` (which represents `0 + x + x**2 + 0*x**3 + 0*x**4`) both the 3-rd and 4-th\norder coefficients would be \u201ctrimmed.\u201d\n\n1-d array of coefficients, ordered from lowest order to highest.\n\nTrailing (i.e., highest order) elements with absolute value less than or equal\nto `tol` (default value is zero) are removed.\n\n1-d array with trailing zeros removed. If the resulting series would be empty,\na series containing a single zero is returned.\n\nIf `tol` < 0\n\nSee also\n\n"}, {"name": "polynomial.chebyshev.chebval()", "path": "reference/generated/numpy.polynomial.chebyshev.chebval", "type": "numpy.polynomial.chebyshev.chebval", "text": "\nEvaluate a Chebyshev series at points x.\n\nIf `c` is of length `n + 1`, this function returns the value:\n\nThe parameter `x` is converted to an array only if it is a tuple or a list,\notherwise it is treated as a scalar. In either case, either `x` or its\nelements must support multiplication and addition both with themselves and\nwith the elements of `c`.\n\nIf `c` is a 1-D array, then `p(x)` will have the same shape as `x`. If `c` is\nmultidimensional, then the shape of the result depends on the value of\n`tensor`. If `tensor` is true the shape will be c.shape[1:] + x.shape. If\n`tensor` is false the shape will be c.shape[1:]. Note that scalars have shape\n(,).\n\nTrailing zeros in the coefficients will be used in the evaluation, so they\nshould be avoided if efficiency is a concern.\n\nIf `x` is a list or tuple, it is converted to an ndarray, otherwise it is left\nunchanged and treated as a scalar. In either case, `x` or its elements must\nsupport addition and multiplication with with themselves and with the elements\nof `c`.\n\nArray of coefficients ordered so that the coefficients for terms of degree n\nare contained in c[n]. If `c` is multidimensional the remaining indices\nenumerate multiple polynomials. In the two dimensional case the coefficients\nmay be thought of as stored in the columns of `c`.\n\nIf True, the shape of the coefficient array is extended with ones on the\nright, one for each dimension of `x`. Scalars have dimension 0 for this\naction. The result is that every column of coefficients in `c` is evaluated\nfor every element of `x`. If False, `x` is broadcast over the columns of `c`\nfor the evaluation. This keyword is useful when `c` is multidimensional. The\ndefault value is True.\n\nNew in version 1.7.0.\n\nThe shape of the return value is described above.\n\nSee also\n\nThe evaluation uses Clenshaw recursion, aka synthetic division.\n\n"}, {"name": "polynomial.chebyshev.chebval2d()", "path": "reference/generated/numpy.polynomial.chebyshev.chebval2d", "type": "numpy.polynomial.chebyshev.chebval2d", "text": "\nEvaluate a 2-D Chebyshev series at points (x, y).\n\nThis function returns the values:\n\nThe parameters `x` and `y` are converted to arrays only if they are tuples or\na lists, otherwise they are treated as a scalars and they must have the same\nshape after conversion. In either case, either `x` and `y` or their elements\nmust support multiplication and addition both with themselves and with the\nelements of `c`.\n\nIf `c` is a 1-D array a one is implicitly appended to its shape to make it\n2-D. The shape of the result will be c.shape[2:] + x.shape.\n\nThe two dimensional series is evaluated at the points `(x, y)`, where `x` and\n`y` must have the same shape. If `x` or `y` is a list or tuple, it is first\nconverted to an ndarray, otherwise it is left unchanged and if it isn\u2019t an\nndarray it is treated as a scalar.\n\nArray of coefficients ordered so that the coefficient of the term of multi-\ndegree i,j is contained in `c[i,j]`. If `c` has dimension greater than 2 the\nremaining indices enumerate multiple sets of coefficients.\n\nThe values of the two dimensional Chebyshev series at points formed from pairs\nof corresponding values from `x` and `y`.\n\nSee also\n\nNew in version 1.7.0.\n\n"}, {"name": "polynomial.chebyshev.chebval3d()", "path": "reference/generated/numpy.polynomial.chebyshev.chebval3d", "type": "numpy.polynomial.chebyshev.chebval3d", "text": "\nEvaluate a 3-D Chebyshev series at points (x, y, z).\n\nThis function returns the values:\n\nThe parameters `x`, `y`, and `z` are converted to arrays only if they are\ntuples or a lists, otherwise they are treated as a scalars and they must have\nthe same shape after conversion. In either case, either `x`, `y`, and `z` or\ntheir elements must support multiplication and addition both with themselves\nand with the elements of `c`.\n\nIf `c` has fewer than 3 dimensions, ones are implicitly appended to its shape\nto make it 3-D. The shape of the result will be c.shape[3:] + x.shape.\n\nThe three dimensional series is evaluated at the points `(x, y, z)`, where\n`x`, `y`, and `z` must have the same shape. If any of `x`, `y`, or `z` is a\nlist or tuple, it is first converted to an ndarray, otherwise it is left\nunchanged and if it isn\u2019t an ndarray it is treated as a scalar.\n\nArray of coefficients ordered so that the coefficient of the term of multi-\ndegree i,j,k is contained in `c[i,j,k]`. If `c` has dimension greater than 3\nthe remaining indices enumerate multiple sets of coefficients.\n\nThe values of the multidimensional polynomial on points formed with triples of\ncorresponding values from `x`, `y`, and `z`.\n\nSee also\n\nNew in version 1.7.0.\n\n"}, {"name": "polynomial.chebyshev.chebvander()", "path": "reference/generated/numpy.polynomial.chebyshev.chebvander", "type": "numpy.polynomial.chebyshev.chebvander", "text": "\nPseudo-Vandermonde matrix of given degree.\n\nReturns the pseudo-Vandermonde matrix of degree `deg` and sample points `x`.\nThe pseudo-Vandermonde matrix is defined by\n\nwhere `0 <= i <= deg`. The leading indices of `V` index the elements of `x`\nand the last index is the degree of the Chebyshev polynomial.\n\nIf `c` is a 1-D array of coefficients of length `n + 1` and `V` is the matrix\n`V = chebvander(x, n)`, then `np.dot(V, c)` and `chebval(x, c)` are the same\nup to roundoff. This equivalence is useful both for least squares fitting and\nfor the evaluation of a large number of Chebyshev series of the same degree\nand sample points.\n\nArray of points. The dtype is converted to float64 or complex128 depending on\nwhether any of the elements are complex. If `x` is scalar it is converted to a\n1-D array.\n\nDegree of the resulting matrix.\n\nThe pseudo Vandermonde matrix. The shape of the returned matrix is `x.shape +\n(deg + 1,)`, where The last index is the degree of the corresponding Chebyshev\npolynomial. The dtype will be the same as the converted `x`.\n\n"}, {"name": "polynomial.chebyshev.chebvander2d()", "path": "reference/generated/numpy.polynomial.chebyshev.chebvander2d", "type": "numpy.polynomial.chebyshev.chebvander2d", "text": "\nPseudo-Vandermonde matrix of given degrees.\n\nReturns the pseudo-Vandermonde matrix of degrees `deg` and sample points `(x,\ny)`. The pseudo-Vandermonde matrix is defined by\n\nwhere `0 <= i <= deg[0]` and `0 <= j <= deg[1]`. The leading indices of `V`\nindex the points `(x, y)` and the last index encodes the degrees of the\nChebyshev polynomials.\n\nIf `V = chebvander2d(x, y, [xdeg, ydeg])`, then the columns of `V` correspond\nto the elements of a 2-D coefficient array `c` of shape (xdeg + 1, ydeg + 1)\nin the order\n\nand `np.dot(V, c.flat)` and `chebval2d(x, y, c)` will be the same up to\nroundoff. This equivalence is useful both for least squares fitting and for\nthe evaluation of a large number of 2-D Chebyshev series of the same degrees\nand sample points.\n\nArrays of point coordinates, all of the same shape. The dtypes will be\nconverted to either float64 or complex128 depending on whether any of the\nelements are complex. Scalars are converted to 1-D arrays.\n\nList of maximum degrees of the form [x_deg, y_deg].\n\nThe shape of the returned matrix is `x.shape + (order,)`, where \\\\(order =\n(deg[0]+1)*(deg[1]+1)\\\\). The dtype will be the same as the converted `x` and\n`y`.\n\nSee also\n\nNew in version 1.7.0.\n\n"}, {"name": "polynomial.chebyshev.chebvander3d()", "path": "reference/generated/numpy.polynomial.chebyshev.chebvander3d", "type": "numpy.polynomial.chebyshev.chebvander3d", "text": "\nPseudo-Vandermonde matrix of given degrees.\n\nReturns the pseudo-Vandermonde matrix of degrees `deg` and sample points `(x,\ny, z)`. If `l, m, n` are the given degrees in `x, y, z`, then The pseudo-\nVandermonde matrix is defined by\n\nwhere `0 <= i <= l`, `0 <= j <= m`, and `0 <= j <= n`. The leading indices of\n`V` index the points `(x, y, z)` and the last index encodes the degrees of the\nChebyshev polynomials.\n\nIf `V = chebvander3d(x, y, z, [xdeg, ydeg, zdeg])`, then the columns of `V`\ncorrespond to the elements of a 3-D coefficient array `c` of shape (xdeg + 1,\nydeg + 1, zdeg + 1) in the order\n\nand `np.dot(V, c.flat)` and `chebval3d(x, y, z, c)` will be the same up to\nroundoff. This equivalence is useful both for least squares fitting and for\nthe evaluation of a large number of 3-D Chebyshev series of the same degrees\nand sample points.\n\nArrays of point coordinates, all of the same shape. The dtypes will be\nconverted to either float64 or complex128 depending on whether any of the\nelements are complex. Scalars are converted to 1-D arrays.\n\nList of maximum degrees of the form [x_deg, y_deg, z_deg].\n\nThe shape of the returned matrix is `x.shape + (order,)`, where \\\\(order =\n(deg[0]+1)*(deg[1]+1)*(deg[2]+1)\\\\). The dtype will be the same as the\nconverted `x`, `y`, and `z`.\n\nSee also\n\nNew in version 1.7.0.\n\n"}, {"name": "polynomial.chebyshev.chebweight()", "path": "reference/generated/numpy.polynomial.chebyshev.chebweight", "type": "numpy.polynomial.chebyshev.chebweight", "text": "\nThe weight function of the Chebyshev polynomials.\n\nThe weight function is \\\\(1/\\sqrt{1 - x^2}\\\\) and the interval of integration\nis \\\\([-1, 1]\\\\). The Chebyshev polynomials are orthogonal, but not\nnormalized, with respect to this weight function.\n\nValues at which the weight function will be computed.\n\nThe weight function at `x`.\n\nNew in version 1.7.0.\n\n"}, {"name": "polynomial.chebyshev.chebx", "path": "reference/generated/numpy.polynomial.chebyshev.chebx", "type": "numpy.polynomial.chebyshev.chebx", "text": "\nAn array object represents a multidimensional, homogeneous array of fixed-size\nitems. An associated data-type object describes the format of each element in\nthe array (its byte-order, how many bytes it occupies in memory, whether it is\nan integer, a floating point number, or something else, etc.)\n\nArrays should be constructed using `array`, `zeros` or `empty` (refer to the\nSee Also section below). The parameters given here refer to a low-level method\n(`ndarray(\u2026)`) for instantiating an array.\n\nFor more information, refer to the `numpy` module and examine the methods and\nattributes of an array.\n\nShape of created array.\n\nAny object that can be interpreted as a numpy data type.\n\nUsed to fill the array with data.\n\nOffset of array data in buffer.\n\nStrides of data in memory.\n\nRow-major (C-style) or column-major (Fortran-style) order.\n\nSee also\n\nConstruct an array.\n\nCreate an array, each element of which is zero.\n\nCreate an array, but leave its allocated memory unchanged (i.e., it contains\n\u201cgarbage\u201d).\n\nCreate a data-type.\n\nAn ndarray alias generic w.r.t. its `dtype.type`.\n\nThere are two modes of creating an array using `__new__`:\n\nNo `__init__` method is needed because the array is fully initialized after\nthe `__new__` method.\n\nThese examples illustrate the low-level `ndarray` constructor. Refer to the\n`See Also` section above for easier ways of constructing an ndarray.\n\nFirst mode, `buffer` is None:\n\nSecond mode:\n\nTranspose of the array.\n\nThe array\u2019s elements, in memory.\n\nDescribes the format of the elements in the array.\n\nDictionary containing information related to memory use, e.g., \u2018C_CONTIGUOUS\u2019,\n\u2018OWNDATA\u2019, \u2018WRITEABLE\u2019, etc.\n\nFlattened version of the array as an iterator. The iterator allows\nassignments, e.g., `x.flat = 3` (See `ndarray.flat` for assignment examples;\nTODO).\n\nImaginary part of the array.\n\nReal part of the array.\n\nNumber of elements in the array.\n\nThe memory use of each array element in bytes.\n\nThe total number of bytes required to store the array data, i.e., `itemsize *\nsize`.\n\nThe array\u2019s number of dimensions.\n\nShape of the array.\n\nThe step-size required to move from one element to the next in memory. For\nexample, a contiguous `(3, 4)` array of type `int16` in C-order has strides\n`(8, 2)`. This implies that to move from element to element in memory requires\njumps of 2 bytes. To move from row-to-row, one needs to jump 8 bytes at a time\n(`2 * 4`).\n\nClass containing properties of the array needed for interaction with ctypes.\n\nIf the array is a view into another array, that array is its `base` (unless\nthat array is also a view). The `base` array is where the array data is\nactually stored.\n\n"}, {"name": "polynomial.chebyshev.Chebyshev.__call__()", "path": "reference/generated/numpy.polynomial.chebyshev.chebyshev.__call__", "type": "numpy.polynomial.chebyshev.Chebyshev", "text": "\nmethod\n\nCall self as a function.\n\n"}, {"name": "polynomial.chebyshev.Chebyshev.basis()", "path": "reference/generated/numpy.polynomial.chebyshev.chebyshev.basis", "type": "numpy.polynomial.chebyshev.Chebyshev", "text": "\nmethod\n\nSeries basis polynomial of degree `deg`.\n\nReturns the series representing the basis polynomial of degree `deg`.\n\nNew in version 1.7.0.\n\nDegree of the basis polynomial for the series. Must be >= 0.\n\nIf given, the array must be of the form `[beg, end]`, where `beg` and `end`\nare the endpoints of the domain. If None is given then the class domain is\nused. The default is None.\n\nIf given, the resulting array must be if the form `[beg, end]`, where `beg`\nand `end` are the endpoints of the window. If None is given then the class\nwindow is used. The default is None.\n\nA series with the coefficient of the `deg` term set to one and all others\nzero.\n\n"}, {"name": "polynomial.chebyshev.Chebyshev.cast()", "path": "reference/generated/numpy.polynomial.chebyshev.chebyshev.cast", "type": "numpy.polynomial.chebyshev.Chebyshev", "text": "\nmethod\n\nConvert series to series of this class.\n\nThe `series` is expected to be an instance of some polynomial series of one of\nthe types supported by by the numpy.polynomial module, but could be some other\nclass that supports the convert method.\n\nNew in version 1.7.0.\n\nThe series instance to be converted.\n\nIf given, the array must be of the form `[beg, end]`, where `beg` and `end`\nare the endpoints of the domain. If None is given then the class domain is\nused. The default is None.\n\nIf given, the resulting array must be if the form `[beg, end]`, where `beg`\nand `end` are the endpoints of the window. If None is given then the class\nwindow is used. The default is None.\n\nA series of the same kind as the calling class and equal to `series` when\nevaluated.\n\nSee also\n\nsimilar instance method\n\n"}, {"name": "polynomial.chebyshev.Chebyshev.convert()", "path": "reference/generated/numpy.polynomial.chebyshev.chebyshev.convert", "type": "numpy.polynomial.chebyshev.Chebyshev", "text": "\nmethod\n\nConvert series to a different kind and/or domain and/or window.\n\nThe domain of the converted series. If the value is None, the default domain\nof `kind` is used.\n\nThe polynomial series type class to which the current instance should be\nconverted. If kind is None, then the class of the current instance is used.\n\nThe window of the converted series. If the value is None, the default window\nof `kind` is used.\n\nThe returned class can be of different type than the current instance and/or\nhave a different domain and/or different window.\n\nConversion between domains and class types can result in numerically ill\ndefined series.\n\n"}, {"name": "polynomial.chebyshev.Chebyshev.copy()", "path": "reference/generated/numpy.polynomial.chebyshev.chebyshev.copy", "type": "numpy.polynomial.chebyshev.Chebyshev", "text": "\nmethod\n\nReturn a copy.\n\nCopy of self.\n\n"}, {"name": "polynomial.chebyshev.Chebyshev.cutdeg()", "path": "reference/generated/numpy.polynomial.chebyshev.chebyshev.cutdeg", "type": "numpy.polynomial.chebyshev.Chebyshev", "text": "\nmethod\n\nTruncate series to the given degree.\n\nReduce the degree of the series to `deg` by discarding the high order terms.\nIf `deg` is greater than the current degree a copy of the current series is\nreturned. This can be useful in least squares where the coefficients of the\nhigh degree terms may be very small.\n\nNew in version 1.5.0.\n\nThe series is reduced to degree `deg` by discarding the high order terms. The\nvalue of `deg` must be a non-negative integer.\n\nNew instance of series with reduced degree.\n\n"}, {"name": "polynomial.chebyshev.Chebyshev.degree()", "path": "reference/generated/numpy.polynomial.chebyshev.chebyshev.degree", "type": "numpy.polynomial.chebyshev.Chebyshev", "text": "\nmethod\n\nThe degree of the series.\n\nNew in version 1.5.0.\n\nDegree of the series, one less than the number of coefficients.\n\n"}, {"name": "polynomial.chebyshev.Chebyshev.deriv()", "path": "reference/generated/numpy.polynomial.chebyshev.chebyshev.deriv", "type": "numpy.polynomial.chebyshev.Chebyshev", "text": "\nmethod\n\nDifferentiate.\n\nReturn a series instance of that is the derivative of the current series.\n\nFind the derivative of order `m`.\n\nA new series representing the derivative. The domain is the same as the domain\nof the differentiated series.\n\n"}, {"name": "polynomial.chebyshev.Chebyshev.domain", "path": "reference/generated/numpy.polynomial.chebyshev.chebyshev.domain", "type": "Polynomials", "text": "\nattribute\n\n"}, {"name": "polynomial.chebyshev.Chebyshev.fit()", "path": "reference/generated/numpy.polynomial.chebyshev.chebyshev.fit", "type": "numpy.polynomial.chebyshev.Chebyshev", "text": "\nmethod\n\nLeast squares fit to data.\n\nReturn a series instance that is the least squares fit to the data `y` sampled\nat `x`. The domain of the returned instance can be specified and this will\noften result in a superior fit with less chance of ill conditioning.\n\nx-coordinates of the M sample points `(x[i], y[i])`.\n\ny-coordinates of the M sample points `(x[i], y[i])`.\n\nDegree(s) of the fitting polynomials. If `deg` is a single integer all terms\nup to and including the `deg`\u2019th term are included in the fit. For NumPy\nversions >= 1.11.0 a list of integers specifying the degrees of the terms to\ninclude may be used instead.\n\nDomain to use for the returned series. If `None`, then a minimal domain that\ncovers the points `x` is chosen. If `[]` the class domain is used. The default\nvalue was the class domain in NumPy 1.4 and `None` in later versions. The `[]`\noption was added in numpy 1.5.0.\n\nRelative condition number of the fit. Singular values smaller than this\nrelative to the largest singular value will be ignored. The default value is\nlen(x)*eps, where eps is the relative precision of the float type, about 2e-16\nin most cases.\n\nSwitch determining nature of return value. When it is False (the default) just\nthe coefficients are returned, when True diagnostic information from the\nsingular value decomposition is also returned.\n\nWeights. If not None, the weight `w[i]` applies to the unsquared residual\n`y[i] - y_hat[i]` at `x[i]`. Ideally the weights are chosen so that the errors\nof the products `w[i]*y[i]` all have the same variance. When using inverse-\nvariance weighting, use `w[i] = 1/sigma(y[i])`. The default value is None.\n\nNew in version 1.5.0.\n\nWindow to use for the returned series. The default value is the default class\ndomain\n\nNew in version 1.6.0.\n\nA series that represents the least squares fit to the data and has the domain\nand window specified in the call. If the coefficients for the unscaled and\nunshifted basis polynomials are of interest, do `new_series.convert().coef`.\n\nThese values are only returned if `full == True`\n\nFor more details, see `linalg.lstsq`.\n\n"}, {"name": "polynomial.chebyshev.Chebyshev.fromroots()", "path": "reference/generated/numpy.polynomial.chebyshev.chebyshev.fromroots", "type": "numpy.polynomial.chebyshev.Chebyshev", "text": "\nmethod\n\nReturn series instance that has the specified roots.\n\nReturns a series representing the product `(x - r[0])*(x - r[1])*...*(x -\nr[n-1])`, where `r` is a list of roots.\n\nList of roots.\n\nDomain for the resulting series. If None the domain is the interval from the\nsmallest root to the largest. If [] the domain is the class domain. The\ndefault is [].\n\nWindow for the returned series. If None the class window is used. The default\nis None.\n\nSeries with the specified roots.\n\n"}, {"name": "polynomial.chebyshev.Chebyshev.has_samecoef()", "path": "reference/generated/numpy.polynomial.chebyshev.chebyshev.has_samecoef", "type": "numpy.polynomial.chebyshev.Chebyshev", "text": "\nmethod\n\nCheck if coefficients match.\n\nNew in version 1.6.0.\n\nThe other class must have the `coef` attribute.\n\nTrue if the coefficients are the same, False otherwise.\n\n"}, {"name": "polynomial.chebyshev.Chebyshev.has_samedomain()", "path": "reference/generated/numpy.polynomial.chebyshev.chebyshev.has_samedomain", "type": "numpy.polynomial.chebyshev.Chebyshev", "text": "\nmethod\n\nCheck if domains match.\n\nNew in version 1.6.0.\n\nThe other class must have the `domain` attribute.\n\nTrue if the domains are the same, False otherwise.\n\n"}, {"name": "polynomial.chebyshev.Chebyshev.has_sametype()", "path": "reference/generated/numpy.polynomial.chebyshev.chebyshev.has_sametype", "type": "numpy.polynomial.chebyshev.Chebyshev", "text": "\nmethod\n\nCheck if types match.\n\nNew in version 1.7.0.\n\nClass instance.\n\nTrue if other is same class as self\n\n"}, {"name": "polynomial.chebyshev.Chebyshev.has_samewindow()", "path": "reference/generated/numpy.polynomial.chebyshev.chebyshev.has_samewindow", "type": "numpy.polynomial.chebyshev.Chebyshev", "text": "\nmethod\n\nCheck if windows match.\n\nNew in version 1.6.0.\n\nThe other class must have the `window` attribute.\n\nTrue if the windows are the same, False otherwise.\n\n"}, {"name": "polynomial.chebyshev.Chebyshev.identity()", "path": "reference/generated/numpy.polynomial.chebyshev.chebyshev.identity", "type": "numpy.polynomial.chebyshev.Chebyshev", "text": "\nmethod\n\nIdentity function.\n\nIf `p` is the returned series, then `p(x) == x` for all values of x.\n\nIf given, the array must be of the form `[beg, end]`, where `beg` and `end`\nare the endpoints of the domain. If None is given then the class domain is\nused. The default is None.\n\nIf given, the resulting array must be if the form `[beg, end]`, where `beg`\nand `end` are the endpoints of the window. If None is given then the class\nwindow is used. The default is None.\n\nSeries of representing the identity.\n\n"}, {"name": "polynomial.chebyshev.Chebyshev.integ()", "path": "reference/generated/numpy.polynomial.chebyshev.chebyshev.integ", "type": "numpy.polynomial.chebyshev.Chebyshev", "text": "\nmethod\n\nIntegrate.\n\nReturn a series instance that is the definite integral of the current series.\n\nThe number of integrations to perform.\n\nIntegration constants. The first constant is applied to the first integration,\nthe second to the second, and so on. The list of values must less than or\nequal to `m` in length and any missing values are set to zero.\n\nThe lower bound of the definite integral.\n\nA new series representing the integral. The domain is the same as the domain\nof the integrated series.\n\n"}, {"name": "polynomial.chebyshev.Chebyshev.interpolate()", "path": "reference/generated/numpy.polynomial.chebyshev.chebyshev.interpolate", "type": "numpy.polynomial.chebyshev.Chebyshev", "text": "\nmethod\n\nInterpolate a function at the Chebyshev points of the first kind.\n\nReturns the series that interpolates `func` at the Chebyshev points of the\nfirst kind scaled and shifted to the `domain`. The resulting series tends to a\nminmax approximation of `func` when the function is continuous in the domain.\n\nNew in version 1.14.0.\n\nThe function to be interpolated. It must be a function of a single variable of\nthe form `f(x, a, b, c...)`, where `a, b, c...` are extra arguments passed in\nthe `args` parameter.\n\nDegree of the interpolating polynomial.\n\nDomain over which `func` is interpolated. The default is None, in which case\nthe domain is [-1, 1].\n\nExtra arguments to be used in the function call. Default is no extra\narguments.\n\nInterpolating Chebyshev instance.\n\nSee `numpy.polynomial.chebfromfunction` for more details.\n\n"}, {"name": "polynomial.chebyshev.Chebyshev.linspace()", "path": "reference/generated/numpy.polynomial.chebyshev.chebyshev.linspace", "type": "numpy.polynomial.chebyshev.Chebyshev", "text": "\nmethod\n\nReturn x, y values at equally spaced points in domain.\n\nReturns the x, y values at `n` linearly spaced points across the domain. Here\ny is the value of the polynomial at the points x. By default the domain is the\nsame as that of the series instance. This method is intended mostly as a\nplotting aid.\n\nNew in version 1.5.0.\n\nNumber of point pairs to return. The default value is 100.\n\nIf not None, the specified domain is used instead of that of the calling\ninstance. It should be of the form `[beg,end]`. The default is None which case\nthe class domain is used.\n\nx is equal to linspace(self.domain[0], self.domain[1], n) and y is the series\nevaluated at element of x.\n\n"}, {"name": "polynomial.chebyshev.Chebyshev.mapparms()", "path": "reference/generated/numpy.polynomial.chebyshev.chebyshev.mapparms", "type": "numpy.polynomial.chebyshev.Chebyshev", "text": "\nmethod\n\nReturn the mapping parameters.\n\nThe returned values define a linear map `off + scl*x` that is applied to the\ninput arguments before the series is evaluated. The map depends on the\n`domain` and `window`; if the current `domain` is equal to the `window` the\nresulting map is the identity. If the coefficients of the series instance are\nto be used by themselves outside this class, then the linear function must be\nsubstituted for the `x` in the standard representation of the base\npolynomials.\n\nThe mapping function is defined by `off + scl*x`.\n\nIf the current domain is the interval `[l1, r1]` and the window is `[l2, r2]`,\nthen the linear mapping function `L` is defined by the equations:\n\n"}, {"name": "polynomial.chebyshev.Chebyshev.roots()", "path": "reference/generated/numpy.polynomial.chebyshev.chebyshev.roots", "type": "numpy.polynomial.chebyshev.Chebyshev", "text": "\nmethod\n\nReturn the roots of the series polynomial.\n\nCompute the roots for the series. Note that the accuracy of the roots decrease\nthe further outside the domain they lie.\n\nArray containing the roots of the series.\n\n"}, {"name": "polynomial.chebyshev.Chebyshev.trim()", "path": "reference/generated/numpy.polynomial.chebyshev.chebyshev.trim", "type": "numpy.polynomial.chebyshev.Chebyshev", "text": "\nmethod\n\nRemove trailing coefficients\n\nRemove trailing coefficients until a coefficient is reached whose absolute\nvalue greater than `tol` or the beginning of the series is reached. If all the\ncoefficients would be removed the series is set to `[0]`. A new series\ninstance is returned with the new coefficients. The current instance remains\nunchanged.\n\nAll trailing coefficients less than `tol` will be removed.\n\nNew instance of series with trimmed coefficients.\n\n"}, {"name": "polynomial.chebyshev.Chebyshev.truncate()", "path": "reference/generated/numpy.polynomial.chebyshev.chebyshev.truncate", "type": "numpy.polynomial.chebyshev.Chebyshev", "text": "\nmethod\n\nTruncate series to length `size`.\n\nReduce the series to length `size` by discarding the high degree terms. The\nvalue of `size` must be a positive integer. This can be useful in least\nsquares where the coefficients of the high degree terms may be very small.\n\nThe series is reduced to length `size` by discarding the high degree terms.\nThe value of `size` must be a positive integer.\n\nNew instance of series with truncated coefficients.\n\n"}, {"name": "polynomial.chebyshev.chebzero", "path": "reference/generated/numpy.polynomial.chebyshev.chebzero", "type": "numpy.polynomial.chebyshev.chebzero", "text": "\nAn array object represents a multidimensional, homogeneous array of fixed-size\nitems. An associated data-type object describes the format of each element in\nthe array (its byte-order, how many bytes it occupies in memory, whether it is\nan integer, a floating point number, or something else, etc.)\n\nArrays should be constructed using `array`, `zeros` or `empty` (refer to the\nSee Also section below). The parameters given here refer to a low-level method\n(`ndarray(\u2026)`) for instantiating an array.\n\nFor more information, refer to the `numpy` module and examine the methods and\nattributes of an array.\n\nShape of created array.\n\nAny object that can be interpreted as a numpy data type.\n\nUsed to fill the array with data.\n\nOffset of array data in buffer.\n\nStrides of data in memory.\n\nRow-major (C-style) or column-major (Fortran-style) order.\n\nSee also\n\nConstruct an array.\n\nCreate an array, each element of which is zero.\n\nCreate an array, but leave its allocated memory unchanged (i.e., it contains\n\u201cgarbage\u201d).\n\nCreate a data-type.\n\nAn ndarray alias generic w.r.t. its `dtype.type`.\n\nThere are two modes of creating an array using `__new__`:\n\nNo `__init__` method is needed because the array is fully initialized after\nthe `__new__` method.\n\nThese examples illustrate the low-level `ndarray` constructor. Refer to the\n`See Also` section above for easier ways of constructing an ndarray.\n\nFirst mode, `buffer` is None:\n\nSecond mode:\n\nTranspose of the array.\n\nThe array\u2019s elements, in memory.\n\nDescribes the format of the elements in the array.\n\nDictionary containing information related to memory use, e.g., \u2018C_CONTIGUOUS\u2019,\n\u2018OWNDATA\u2019, \u2018WRITEABLE\u2019, etc.\n\nFlattened version of the array as an iterator. The iterator allows\nassignments, e.g., `x.flat = 3` (See `ndarray.flat` for assignment examples;\nTODO).\n\nImaginary part of the array.\n\nReal part of the array.\n\nNumber of elements in the array.\n\nThe memory use of each array element in bytes.\n\nThe total number of bytes required to store the array data, i.e., `itemsize *\nsize`.\n\nThe array\u2019s number of dimensions.\n\nShape of the array.\n\nThe step-size required to move from one element to the next in memory. For\nexample, a contiguous `(3, 4)` array of type `int16` in C-order has strides\n`(8, 2)`. This implies that to move from element to element in memory requires\njumps of 2 bytes. To move from row-to-row, one needs to jump 8 bytes at a time\n(`2 * 4`).\n\nClass containing properties of the array needed for interaction with ctypes.\n\nIf the array is a view into another array, that array is its `base` (unless\nthat array is also a view). The `base` array is where the array data is\nactually stored.\n\n"}, {"name": "polynomial.chebyshev.poly2cheb()", "path": "reference/generated/numpy.polynomial.chebyshev.poly2cheb", "type": "numpy.polynomial.chebyshev.poly2cheb", "text": "\nConvert a polynomial to a Chebyshev series.\n\nConvert an array representing the coefficients of a polynomial (relative to\nthe \u201cstandard\u201d basis) ordered from lowest degree to highest, to an array of\nthe coefficients of the equivalent Chebyshev series, ordered from lowest to\nhighest degree.\n\n1-D array containing the polynomial coefficients\n\n1-D array containing the coefficients of the equivalent Chebyshev series.\n\nSee also\n\nThe easy way to do conversions between polynomial basis sets is to use the\nconvert method of a class instance.\n\n"}, {"name": "polynomial.hermite.herm2poly()", "path": "reference/generated/numpy.polynomial.hermite.herm2poly", "type": "numpy.polynomial.hermite.herm2poly", "text": "\nConvert a Hermite series to a polynomial.\n\nConvert an array representing the coefficients of a Hermite series, ordered\nfrom lowest degree to highest, to an array of the coefficients of the\nequivalent polynomial (relative to the \u201cstandard\u201d basis) ordered from lowest\nto highest degree.\n\n1-D array containing the Hermite series coefficients, ordered from lowest\norder term to highest.\n\n1-D array containing the coefficients of the equivalent polynomial (relative\nto the \u201cstandard\u201d basis) ordered from lowest order term to highest.\n\nSee also\n\nThe easy way to do conversions between polynomial basis sets is to use the\nconvert method of a class instance.\n\n"}, {"name": "polynomial.hermite.hermadd()", "path": "reference/generated/numpy.polynomial.hermite.hermadd", "type": "numpy.polynomial.hermite.hermadd", "text": "\nAdd one Hermite series to another.\n\nReturns the sum of two Hermite series `c1` \\+ `c2`. The arguments are\nsequences of coefficients ordered from lowest order term to highest, i.e.,\n[1,2,3] represents the series `P_0 + 2*P_1 + 3*P_2`.\n\n1-D arrays of Hermite series coefficients ordered from low to high.\n\nArray representing the Hermite series of their sum.\n\nSee also\n\nUnlike multiplication, division, etc., the sum of two Hermite series is a\nHermite series (without having to \u201creproject\u201d the result onto the basis set)\nso addition, just like that of \u201cstandard\u201d polynomials, is simply \u201ccomponent-\nwise.\u201d\n\n"}, {"name": "polynomial.hermite.hermcompanion()", "path": "reference/generated/numpy.polynomial.hermite.hermcompanion", "type": "numpy.polynomial.hermite.hermcompanion", "text": "\nReturn the scaled companion matrix of c.\n\nThe basis polynomials are scaled so that the companion matrix is symmetric\nwhen `c` is an Hermite basis polynomial. This provides better eigenvalue\nestimates than the unscaled case and for basis polynomials the eigenvalues are\nguaranteed to be real if `numpy.linalg.eigvalsh` is used to obtain them.\n\n1-D array of Hermite series coefficients ordered from low to high degree.\n\nScaled companion matrix of dimensions (deg, deg).\n\nNew in version 1.7.0.\n\n"}, {"name": "polynomial.hermite.hermder()", "path": "reference/generated/numpy.polynomial.hermite.hermder", "type": "numpy.polynomial.hermite.hermder", "text": "\nDifferentiate a Hermite series.\n\nReturns the Hermite series coefficients `c` differentiated `m` times along\n`axis`. At each iteration the result is multiplied by `scl` (the scaling\nfactor is for use in a linear change of variable). The argument `c` is an\narray of coefficients from low to high degree along each axis, e.g., [1,2,3]\nrepresents the series `1*H_0 + 2*H_1 + 3*H_2` while [[1,2],[1,2]] represents\n`1*H_0(x)*H_0(y) + 1*H_1(x)*H_0(y) + 2*H_0(x)*H_1(y) + 2*H_1(x)*H_1(y)` if\naxis=0 is `x` and axis=1 is `y`.\n\nArray of Hermite series coefficients. If `c` is multidimensional the different\naxis correspond to different variables with the degree in each axis given by\nthe corresponding index.\n\nNumber of derivatives taken, must be non-negative. (Default: 1)\n\nEach differentiation is multiplied by `scl`. The end result is multiplication\nby `scl**m`. This is for use in a linear change of variable. (Default: 1)\n\nAxis over which the derivative is taken. (Default: 0).\n\nNew in version 1.7.0.\n\nHermite series of the derivative.\n\nSee also\n\nIn general, the result of differentiating a Hermite series does not resemble\nthe same operation on a power series. Thus the result of this function may be\n\u201cunintuitive,\u201d albeit correct; see Examples section below.\n\n"}, {"name": "polynomial.hermite.hermdiv()", "path": "reference/generated/numpy.polynomial.hermite.hermdiv", "type": "numpy.polynomial.hermite.hermdiv", "text": "\nDivide one Hermite series by another.\n\nReturns the quotient-with-remainder of two Hermite series `c1` / `c2`. The\narguments are sequences of coefficients from lowest order \u201cterm\u201d to highest,\ne.g., [1,2,3] represents the series `P_0 + 2*P_1 + 3*P_2`.\n\n1-D arrays of Hermite series coefficients ordered from low to high.\n\nOf Hermite series coefficients representing the quotient and remainder.\n\nSee also\n\nIn general, the (polynomial) division of one Hermite series by another results\nin quotient and remainder terms that are not in the Hermite polynomial basis\nset. Thus, to express these results as a Hermite series, it is necessary to\n\u201creproject\u201d the results onto the Hermite basis set, which may produce\n\u201cunintuitive\u201d (but correct) results; see Examples section below.\n\n"}, {"name": "polynomial.hermite.hermdomain", "path": "reference/generated/numpy.polynomial.hermite.hermdomain", "type": "numpy.polynomial.hermite.hermdomain", "text": "\nAn array object represents a multidimensional, homogeneous array of fixed-size\nitems. An associated data-type object describes the format of each element in\nthe array (its byte-order, how many bytes it occupies in memory, whether it is\nan integer, a floating point number, or something else, etc.)\n\nArrays should be constructed using `array`, `zeros` or `empty` (refer to the\nSee Also section below). The parameters given here refer to a low-level method\n(`ndarray(\u2026)`) for instantiating an array.\n\nFor more information, refer to the `numpy` module and examine the methods and\nattributes of an array.\n\nShape of created array.\n\nAny object that can be interpreted as a numpy data type.\n\nUsed to fill the array with data.\n\nOffset of array data in buffer.\n\nStrides of data in memory.\n\nRow-major (C-style) or column-major (Fortran-style) order.\n\nSee also\n\nConstruct an array.\n\nCreate an array, each element of which is zero.\n\nCreate an array, but leave its allocated memory unchanged (i.e., it contains\n\u201cgarbage\u201d).\n\nCreate a data-type.\n\nAn ndarray alias generic w.r.t. its `dtype.type`.\n\nThere are two modes of creating an array using `__new__`:\n\nNo `__init__` method is needed because the array is fully initialized after\nthe `__new__` method.\n\nThese examples illustrate the low-level `ndarray` constructor. Refer to the\n`See Also` section above for easier ways of constructing an ndarray.\n\nFirst mode, `buffer` is None:\n\nSecond mode:\n\nTranspose of the array.\n\nThe array\u2019s elements, in memory.\n\nDescribes the format of the elements in the array.\n\nDictionary containing information related to memory use, e.g., \u2018C_CONTIGUOUS\u2019,\n\u2018OWNDATA\u2019, \u2018WRITEABLE\u2019, etc.\n\nFlattened version of the array as an iterator. The iterator allows\nassignments, e.g., `x.flat = 3` (See `ndarray.flat` for assignment examples;\nTODO).\n\nImaginary part of the array.\n\nReal part of the array.\n\nNumber of elements in the array.\n\nThe memory use of each array element in bytes.\n\nThe total number of bytes required to store the array data, i.e., `itemsize *\nsize`.\n\nThe array\u2019s number of dimensions.\n\nShape of the array.\n\nThe step-size required to move from one element to the next in memory. For\nexample, a contiguous `(3, 4)` array of type `int16` in C-order has strides\n`(8, 2)`. This implies that to move from element to element in memory requires\njumps of 2 bytes. To move from row-to-row, one needs to jump 8 bytes at a time\n(`2 * 4`).\n\nClass containing properties of the array needed for interaction with ctypes.\n\nIf the array is a view into another array, that array is its `base` (unless\nthat array is also a view). The `base` array is where the array data is\nactually stored.\n\n"}, {"name": "polynomial.hermite.hermfit()", "path": "reference/generated/numpy.polynomial.hermite.hermfit", "type": "numpy.polynomial.hermite.hermfit", "text": "\nLeast squares fit of Hermite series to data.\n\nReturn the coefficients of a Hermite series of degree `deg` that is the least\nsquares fit to the data values `y` given at points `x`. If `y` is 1-D the\nreturned coefficients will also be 1-D. If `y` is 2-D multiple fits are done,\none for each column of `y`, and the resulting coefficients are stored in the\ncorresponding columns of a 2-D return. The fitted polynomial(s) are in the\nform\n\nwhere `n` is `deg`.\n\nx-coordinates of the M sample points `(x[i], y[i])`.\n\ny-coordinates of the sample points. Several data sets of sample points sharing\nthe same x-coordinates can be fitted at once by passing in a 2D-array that\ncontains one dataset per column.\n\nDegree(s) of the fitting polynomials. If `deg` is a single integer all terms\nup to and including the `deg`\u2019th term are included in the fit. For NumPy\nversions >= 1.11.0 a list of integers specifying the degrees of the terms to\ninclude may be used instead.\n\nRelative condition number of the fit. Singular values smaller than this\nrelative to the largest singular value will be ignored. The default value is\nlen(x)*eps, where eps is the relative precision of the float type, about 2e-16\nin most cases.\n\nSwitch determining nature of return value. When it is False (the default) just\nthe coefficients are returned, when True diagnostic information from the\nsingular value decomposition is also returned.\n\nWeights. If not None, the weight `w[i]` applies to the unsquared residual\n`y[i] - y_hat[i]` at `x[i]`. Ideally the weights are chosen so that the errors\nof the products `w[i]*y[i]` all have the same variance. When using inverse-\nvariance weighting, use `w[i] = 1/sigma(y[i])`. The default value is None.\n\nHermite coefficients ordered from low to high. If `y` was 2-D, the\ncoefficients for the data in column k of `y` are in column `k`.\n\nThese values are only returned if `full == True`\n\nFor more details, see `numpy.linalg.lstsq`.\n\nThe rank of the coefficient matrix in the least-squares fit is deficient. The\nwarning is only raised if `full == False`. The warnings can be turned off by\n\nSee also\n\nEvaluates a Hermite series.\n\nVandermonde matrix of Hermite series.\n\nHermite weight function\n\nComputes a least-squares fit from the matrix.\n\nComputes spline fits.\n\nThe solution is the coefficients of the Hermite series `p` that minimizes the\nsum of the weighted squared errors\n\nwhere the \\\\(w_j\\\\) are the weights. This problem is solved by setting up the\n(typically) overdetermined matrix equation\n\nwhere `V` is the weighted pseudo Vandermonde matrix of `x`, `c` are the\ncoefficients to be solved for, `w` are the weights, `y` are the observed\nvalues. This equation is then solved using the singular value decomposition of\n`V`.\n\nIf some of the singular values of `V` are so small that they are neglected,\nthen a `RankWarning` will be issued. This means that the coefficient values\nmay be poorly determined. Using a lower order fit will usually get rid of the\nwarning. The `rcond` parameter can also be set to a value smaller than its\ndefault, but the resulting fit may be spurious and have large contributions\nfrom roundoff error.\n\nFits using Hermite series are probably most useful when the data can be\napproximated by `sqrt(w(x)) * p(x)`, where `w(x)` is the Hermite weight. In\nthat case the weight `sqrt(w(x[i]))` should be used together with data values\n`y[i]/sqrt(w(x[i]))`. The weight function is available as `hermweight`.\n\nWikipedia, \u201cCurve fitting\u201d, https://en.wikipedia.org/wiki/Curve_fitting\n\n"}, {"name": "polynomial.hermite.hermfromroots()", "path": "reference/generated/numpy.polynomial.hermite.hermfromroots", "type": "numpy.polynomial.hermite.hermfromroots", "text": "\nGenerate a Hermite series with given roots.\n\nThe function returns the coefficients of the polynomial\n\nin Hermite form, where the `r_n` are the roots specified in `roots`. If a zero\nhas multiplicity n, then it must appear in `roots` n times. For instance, if 2\nis a root of multiplicity three and 3 is a root of multiplicity 2, then\n`roots` looks something like [2, 2, 2, 3, 3]. The roots can appear in any\norder.\n\nIf the returned coefficients are `c`, then\n\nThe coefficient of the last term is not generally 1 for monic polynomials in\nHermite form.\n\nSequence containing the roots.\n\n1-D array of coefficients. If all roots are real then `out` is a real array,\nif some of the roots are complex, then `out` is complex even if all the\ncoefficients in the result are real (see Examples below).\n\nSee also\n\n"}, {"name": "polynomial.hermite.hermgauss()", "path": "reference/generated/numpy.polynomial.hermite.hermgauss", "type": "numpy.polynomial.hermite.hermgauss", "text": "\nGauss-Hermite quadrature.\n\nComputes the sample points and weights for Gauss-Hermite quadrature. These\nsample points and weights will correctly integrate polynomials of degree\n\\\\(2*deg - 1\\\\) or less over the interval \\\\([-\\inf, \\inf]\\\\) with the weight\nfunction \\\\(f(x) = \\exp(-x^2)\\\\).\n\nNumber of sample points and weights. It must be >= 1.\n\n1-D ndarray containing the sample points.\n\n1-D ndarray containing the weights.\n\nNew in version 1.7.0.\n\nThe results have only been tested up to degree 100, higher degrees may be\nproblematic. The weights are determined by using the fact that\n\nwhere \\\\(c\\\\) is a constant independent of \\\\(k\\\\) and \\\\(x_k\\\\) is the k\u2019th\nroot of \\\\(H_n\\\\), and then scaling the results to get the right value when\nintegrating 1.\n\n"}, {"name": "polynomial.hermite.hermgrid2d()", "path": "reference/generated/numpy.polynomial.hermite.hermgrid2d", "type": "numpy.polynomial.hermite.hermgrid2d", "text": "\nEvaluate a 2-D Hermite series on the Cartesian product of x and y.\n\nThis function returns the values:\n\nwhere the points `(a, b)` consist of all pairs formed by taking `a` from `x`\nand `b` from `y`. The resulting points form a grid with `x` in the first\ndimension and `y` in the second.\n\nThe parameters `x` and `y` are converted to arrays only if they are tuples or\na lists, otherwise they are treated as a scalars. In either case, either `x`\nand `y` or their elements must support multiplication and addition both with\nthemselves and with the elements of `c`.\n\nIf `c` has fewer than two dimensions, ones are implicitly appended to its\nshape to make it 2-D. The shape of the result will be c.shape[2:] + x.shape.\n\nThe two dimensional series is evaluated at the points in the Cartesian product\nof `x` and `y`. If `x` or `y` is a list or tuple, it is first converted to an\nndarray, otherwise it is left unchanged and, if it isn\u2019t an ndarray, it is\ntreated as a scalar.\n\nArray of coefficients ordered so that the coefficients for terms of degree i,j\nare contained in `c[i,j]`. If `c` has dimension greater than two the remaining\nindices enumerate multiple sets of coefficients.\n\nThe values of the two dimensional polynomial at points in the Cartesian\nproduct of `x` and `y`.\n\nSee also\n\nNew in version 1.7.0.\n\n"}, {"name": "polynomial.hermite.hermgrid3d()", "path": "reference/generated/numpy.polynomial.hermite.hermgrid3d", "type": "numpy.polynomial.hermite.hermgrid3d", "text": "\nEvaluate a 3-D Hermite series on the Cartesian product of x, y, and z.\n\nThis function returns the values:\n\nwhere the points `(a, b, c)` consist of all triples formed by taking `a` from\n`x`, `b` from `y`, and `c` from `z`. The resulting points form a grid with `x`\nin the first dimension, `y` in the second, and `z` in the third.\n\nThe parameters `x`, `y`, and `z` are converted to arrays only if they are\ntuples or a lists, otherwise they are treated as a scalars. In either case,\neither `x`, `y`, and `z` or their elements must support multiplication and\naddition both with themselves and with the elements of `c`.\n\nIf `c` has fewer than three dimensions, ones are implicitly appended to its\nshape to make it 3-D. The shape of the result will be c.shape[3:] + x.shape +\ny.shape + z.shape.\n\nThe three dimensional series is evaluated at the points in the Cartesian\nproduct of `x`, `y`, and `z`. If `x`,`y`, or `z` is a list or tuple, it is\nfirst converted to an ndarray, otherwise it is left unchanged and, if it isn\u2019t\nan ndarray, it is treated as a scalar.\n\nArray of coefficients ordered so that the coefficients for terms of degree i,j\nare contained in `c[i,j]`. If `c` has dimension greater than two the remaining\nindices enumerate multiple sets of coefficients.\n\nThe values of the two dimensional polynomial at points in the Cartesian\nproduct of `x` and `y`.\n\nSee also\n\nNew in version 1.7.0.\n\n"}, {"name": "polynomial.hermite.hermint()", "path": "reference/generated/numpy.polynomial.hermite.hermint", "type": "numpy.polynomial.hermite.hermint", "text": "\nIntegrate a Hermite series.\n\nReturns the Hermite series coefficients `c` integrated `m` times from `lbnd`\nalong `axis`. At each iteration the resulting series is multiplied by `scl`\nand an integration constant, `k`, is added. The scaling factor is for use in a\nlinear change of variable. (\u201cBuyer beware\u201d: note that, depending on what one\nis doing, one may want `scl` to be the reciprocal of what one might expect;\nfor more information, see the Notes section below.) The argument `c` is an\narray of coefficients from low to high degree along each axis, e.g., [1,2,3]\nrepresents the series `H_0 + 2*H_1 + 3*H_2` while [[1,2],[1,2]] represents\n`1*H_0(x)*H_0(y) + 1*H_1(x)*H_0(y) + 2*H_0(x)*H_1(y) + 2*H_1(x)*H_1(y)` if\naxis=0 is `x` and axis=1 is `y`.\n\nArray of Hermite series coefficients. If c is multidimensional the different\naxis correspond to different variables with the degree in each axis given by\nthe corresponding index.\n\nOrder of integration, must be positive. (Default: 1)\n\nIntegration constant(s). The value of the first integral at `lbnd` is the\nfirst value in the list, the value of the second integral at `lbnd` is the\nsecond value, etc. If `k == []` (the default), all constants are set to zero.\nIf `m == 1`, a single scalar can be given instead of a list.\n\nThe lower bound of the integral. (Default: 0)\n\nFollowing each integration the result is multiplied by `scl` before the\nintegration constant is added. (Default: 1)\n\nAxis over which the integral is taken. (Default: 0).\n\nNew in version 1.7.0.\n\nHermite series coefficients of the integral.\n\nIf `m < 0`, `len(k) > m`, `np.ndim(lbnd) != 0`, or `np.ndim(scl) != 0`.\n\nSee also\n\nNote that the result of each integration is multiplied by `scl`. Why is this\nimportant to note? Say one is making a linear change of variable \\\\(u = ax +\nb\\\\) in an integral relative to `x`. Then \\\\(dx = du/a\\\\), so one will need to\nset `scl` equal to \\\\(1/a\\\\) \\- perhaps not what one would have first thought.\n\nAlso note that, in general, the result of integrating a C-series needs to be\n\u201creprojected\u201d onto the C-series basis set. Thus, typically, the result of this\nfunction is \u201cunintuitive,\u201d albeit correct; see Examples section below.\n\n"}, {"name": "polynomial.hermite.Hermite.__call__()", "path": "reference/generated/numpy.polynomial.hermite.hermite.__call__", "type": "numpy.polynomial.hermite.Hermite", "text": "\nmethod\n\nCall self as a function.\n\n"}, {"name": "polynomial.hermite.Hermite.basis()", "path": "reference/generated/numpy.polynomial.hermite.hermite.basis", "type": "numpy.polynomial.hermite.Hermite", "text": "\nmethod\n\nSeries basis polynomial of degree `deg`.\n\nReturns the series representing the basis polynomial of degree `deg`.\n\nNew in version 1.7.0.\n\nDegree of the basis polynomial for the series. Must be >= 0.\n\nIf given, the array must be of the form `[beg, end]`, where `beg` and `end`\nare the endpoints of the domain. If None is given then the class domain is\nused. The default is None.\n\nIf given, the resulting array must be if the form `[beg, end]`, where `beg`\nand `end` are the endpoints of the window. If None is given then the class\nwindow is used. The default is None.\n\nA series with the coefficient of the `deg` term set to one and all others\nzero.\n\n"}, {"name": "polynomial.hermite.Hermite.cast()", "path": "reference/generated/numpy.polynomial.hermite.hermite.cast", "type": "numpy.polynomial.hermite.Hermite", "text": "\nmethod\n\nConvert series to series of this class.\n\nThe `series` is expected to be an instance of some polynomial series of one of\nthe types supported by by the numpy.polynomial module, but could be some other\nclass that supports the convert method.\n\nNew in version 1.7.0.\n\nThe series instance to be converted.\n\nIf given, the array must be of the form `[beg, end]`, where `beg` and `end`\nare the endpoints of the domain. If None is given then the class domain is\nused. The default is None.\n\nIf given, the resulting array must be if the form `[beg, end]`, where `beg`\nand `end` are the endpoints of the window. If None is given then the class\nwindow is used. The default is None.\n\nA series of the same kind as the calling class and equal to `series` when\nevaluated.\n\nSee also\n\nsimilar instance method\n\n"}, {"name": "polynomial.hermite.Hermite.convert()", "path": "reference/generated/numpy.polynomial.hermite.hermite.convert", "type": "numpy.polynomial.hermite.Hermite", "text": "\nmethod\n\nConvert series to a different kind and/or domain and/or window.\n\nThe domain of the converted series. If the value is None, the default domain\nof `kind` is used.\n\nThe polynomial series type class to which the current instance should be\nconverted. If kind is None, then the class of the current instance is used.\n\nThe window of the converted series. If the value is None, the default window\nof `kind` is used.\n\nThe returned class can be of different type than the current instance and/or\nhave a different domain and/or different window.\n\nConversion between domains and class types can result in numerically ill\ndefined series.\n\n"}, {"name": "polynomial.hermite.Hermite.copy()", "path": "reference/generated/numpy.polynomial.hermite.hermite.copy", "type": "numpy.polynomial.hermite.Hermite", "text": "\nmethod\n\nReturn a copy.\n\nCopy of self.\n\n"}, {"name": "polynomial.hermite.Hermite.cutdeg()", "path": "reference/generated/numpy.polynomial.hermite.hermite.cutdeg", "type": "numpy.polynomial.hermite.Hermite", "text": "\nmethod\n\nTruncate series to the given degree.\n\nReduce the degree of the series to `deg` by discarding the high order terms.\nIf `deg` is greater than the current degree a copy of the current series is\nreturned. This can be useful in least squares where the coefficients of the\nhigh degree terms may be very small.\n\nNew in version 1.5.0.\n\nThe series is reduced to degree `deg` by discarding the high order terms. The\nvalue of `deg` must be a non-negative integer.\n\nNew instance of series with reduced degree.\n\n"}, {"name": "polynomial.hermite.Hermite.degree()", "path": "reference/generated/numpy.polynomial.hermite.hermite.degree", "type": "numpy.polynomial.hermite.Hermite", "text": "\nmethod\n\nThe degree of the series.\n\nNew in version 1.5.0.\n\nDegree of the series, one less than the number of coefficients.\n\n"}, {"name": "polynomial.hermite.Hermite.deriv()", "path": "reference/generated/numpy.polynomial.hermite.hermite.deriv", "type": "numpy.polynomial.hermite.Hermite", "text": "\nmethod\n\nDifferentiate.\n\nReturn a series instance of that is the derivative of the current series.\n\nFind the derivative of order `m`.\n\nA new series representing the derivative. The domain is the same as the domain\nof the differentiated series.\n\n"}, {"name": "polynomial.hermite.Hermite.domain", "path": "reference/generated/numpy.polynomial.hermite.hermite.domain", "type": "Polynomials", "text": "\nattribute\n\n"}, {"name": "polynomial.hermite.Hermite.fit()", "path": "reference/generated/numpy.polynomial.hermite.hermite.fit", "type": "numpy.polynomial.hermite.Hermite", "text": "\nmethod\n\nLeast squares fit to data.\n\nReturn a series instance that is the least squares fit to the data `y` sampled\nat `x`. The domain of the returned instance can be specified and this will\noften result in a superior fit with less chance of ill conditioning.\n\nx-coordinates of the M sample points `(x[i], y[i])`.\n\ny-coordinates of the M sample points `(x[i], y[i])`.\n\nDegree(s) of the fitting polynomials. If `deg` is a single integer all terms\nup to and including the `deg`\u2019th term are included in the fit. For NumPy\nversions >= 1.11.0 a list of integers specifying the degrees of the terms to\ninclude may be used instead.\n\nDomain to use for the returned series. If `None`, then a minimal domain that\ncovers the points `x` is chosen. If `[]` the class domain is used. The default\nvalue was the class domain in NumPy 1.4 and `None` in later versions. The `[]`\noption was added in numpy 1.5.0.\n\nRelative condition number of the fit. Singular values smaller than this\nrelative to the largest singular value will be ignored. The default value is\nlen(x)*eps, where eps is the relative precision of the float type, about 2e-16\nin most cases.\n\nSwitch determining nature of return value. When it is False (the default) just\nthe coefficients are returned, when True diagnostic information from the\nsingular value decomposition is also returned.\n\nWeights. If not None, the weight `w[i]` applies to the unsquared residual\n`y[i] - y_hat[i]` at `x[i]`. Ideally the weights are chosen so that the errors\nof the products `w[i]*y[i]` all have the same variance. When using inverse-\nvariance weighting, use `w[i] = 1/sigma(y[i])`. The default value is None.\n\nNew in version 1.5.0.\n\nWindow to use for the returned series. The default value is the default class\ndomain\n\nNew in version 1.6.0.\n\nA series that represents the least squares fit to the data and has the domain\nand window specified in the call. If the coefficients for the unscaled and\nunshifted basis polynomials are of interest, do `new_series.convert().coef`.\n\nThese values are only returned if `full == True`\n\nFor more details, see `linalg.lstsq`.\n\n"}, {"name": "polynomial.hermite.Hermite.fromroots()", "path": "reference/generated/numpy.polynomial.hermite.hermite.fromroots", "type": "numpy.polynomial.hermite.Hermite", "text": "\nmethod\n\nReturn series instance that has the specified roots.\n\nReturns a series representing the product `(x - r[0])*(x - r[1])*...*(x -\nr[n-1])`, where `r` is a list of roots.\n\nList of roots.\n\nDomain for the resulting series. If None the domain is the interval from the\nsmallest root to the largest. If [] the domain is the class domain. The\ndefault is [].\n\nWindow for the returned series. If None the class window is used. The default\nis None.\n\nSeries with the specified roots.\n\n"}, {"name": "polynomial.hermite.Hermite.has_samecoef()", "path": "reference/generated/numpy.polynomial.hermite.hermite.has_samecoef", "type": "numpy.polynomial.hermite.Hermite", "text": "\nmethod\n\nCheck if coefficients match.\n\nNew in version 1.6.0.\n\nThe other class must have the `coef` attribute.\n\nTrue if the coefficients are the same, False otherwise.\n\n"}, {"name": "polynomial.hermite.Hermite.has_samedomain()", "path": "reference/generated/numpy.polynomial.hermite.hermite.has_samedomain", "type": "numpy.polynomial.hermite.Hermite", "text": "\nmethod\n\nCheck if domains match.\n\nNew in version 1.6.0.\n\nThe other class must have the `domain` attribute.\n\nTrue if the domains are the same, False otherwise.\n\n"}, {"name": "polynomial.hermite.Hermite.has_sametype()", "path": "reference/generated/numpy.polynomial.hermite.hermite.has_sametype", "type": "numpy.polynomial.hermite.Hermite", "text": "\nmethod\n\nCheck if types match.\n\nNew in version 1.7.0.\n\nClass instance.\n\nTrue if other is same class as self\n\n"}, {"name": "polynomial.hermite.Hermite.has_samewindow()", "path": "reference/generated/numpy.polynomial.hermite.hermite.has_samewindow", "type": "numpy.polynomial.hermite.Hermite", "text": "\nmethod\n\nCheck if windows match.\n\nNew in version 1.6.0.\n\nThe other class must have the `window` attribute.\n\nTrue if the windows are the same, False otherwise.\n\n"}, {"name": "polynomial.hermite.Hermite.identity()", "path": "reference/generated/numpy.polynomial.hermite.hermite.identity", "type": "numpy.polynomial.hermite.Hermite", "text": "\nmethod\n\nIdentity function.\n\nIf `p` is the returned series, then `p(x) == x` for all values of x.\n\nIf given, the array must be of the form `[beg, end]`, where `beg` and `end`\nare the endpoints of the domain. If None is given then the class domain is\nused. The default is None.\n\nIf given, the resulting array must be if the form `[beg, end]`, where `beg`\nand `end` are the endpoints of the window. If None is given then the class\nwindow is used. The default is None.\n\nSeries of representing the identity.\n\n"}, {"name": "polynomial.hermite.Hermite.integ()", "path": "reference/generated/numpy.polynomial.hermite.hermite.integ", "type": "numpy.polynomial.hermite.Hermite", "text": "\nmethod\n\nIntegrate.\n\nReturn a series instance that is the definite integral of the current series.\n\nThe number of integrations to perform.\n\nIntegration constants. The first constant is applied to the first integration,\nthe second to the second, and so on. The list of values must less than or\nequal to `m` in length and any missing values are set to zero.\n\nThe lower bound of the definite integral.\n\nA new series representing the integral. The domain is the same as the domain\nof the integrated series.\n\n"}, {"name": "polynomial.hermite.Hermite.linspace()", "path": "reference/generated/numpy.polynomial.hermite.hermite.linspace", "type": "numpy.polynomial.hermite.Hermite", "text": "\nmethod\n\nReturn x, y values at equally spaced points in domain.\n\nReturns the x, y values at `n` linearly spaced points across the domain. Here\ny is the value of the polynomial at the points x. By default the domain is the\nsame as that of the series instance. This method is intended mostly as a\nplotting aid.\n\nNew in version 1.5.0.\n\nNumber of point pairs to return. The default value is 100.\n\nIf not None, the specified domain is used instead of that of the calling\ninstance. It should be of the form `[beg,end]`. The default is None which case\nthe class domain is used.\n\nx is equal to linspace(self.domain[0], self.domain[1], n) and y is the series\nevaluated at element of x.\n\n"}, {"name": "polynomial.hermite.Hermite.mapparms()", "path": "reference/generated/numpy.polynomial.hermite.hermite.mapparms", "type": "numpy.polynomial.hermite.Hermite", "text": "\nmethod\n\nReturn the mapping parameters.\n\nThe returned values define a linear map `off + scl*x` that is applied to the\ninput arguments before the series is evaluated. The map depends on the\n`domain` and `window`; if the current `domain` is equal to the `window` the\nresulting map is the identity. If the coefficients of the series instance are\nto be used by themselves outside this class, then the linear function must be\nsubstituted for the `x` in the standard representation of the base\npolynomials.\n\nThe mapping function is defined by `off + scl*x`.\n\nIf the current domain is the interval `[l1, r1]` and the window is `[l2, r2]`,\nthen the linear mapping function `L` is defined by the equations:\n\n"}, {"name": "polynomial.hermite.Hermite.roots()", "path": "reference/generated/numpy.polynomial.hermite.hermite.roots", "type": "numpy.polynomial.hermite.Hermite", "text": "\nmethod\n\nReturn the roots of the series polynomial.\n\nCompute the roots for the series. Note that the accuracy of the roots decrease\nthe further outside the domain they lie.\n\nArray containing the roots of the series.\n\n"}, {"name": "polynomial.hermite.Hermite.trim()", "path": "reference/generated/numpy.polynomial.hermite.hermite.trim", "type": "numpy.polynomial.hermite.Hermite", "text": "\nmethod\n\nRemove trailing coefficients\n\nRemove trailing coefficients until a coefficient is reached whose absolute\nvalue greater than `tol` or the beginning of the series is reached. If all the\ncoefficients would be removed the series is set to `[0]`. A new series\ninstance is returned with the new coefficients. The current instance remains\nunchanged.\n\nAll trailing coefficients less than `tol` will be removed.\n\nNew instance of series with trimmed coefficients.\n\n"}, {"name": "polynomial.hermite.Hermite.truncate()", "path": "reference/generated/numpy.polynomial.hermite.hermite.truncate", "type": "numpy.polynomial.hermite.Hermite", "text": "\nmethod\n\nTruncate series to length `size`.\n\nReduce the series to length `size` by discarding the high degree terms. The\nvalue of `size` must be a positive integer. This can be useful in least\nsquares where the coefficients of the high degree terms may be very small.\n\nThe series is reduced to length `size` by discarding the high degree terms.\nThe value of `size` must be a positive integer.\n\nNew instance of series with truncated coefficients.\n\n"}, {"name": "polynomial.hermite.hermline()", "path": "reference/generated/numpy.polynomial.hermite.hermline", "type": "numpy.polynomial.hermite.hermline", "text": "\nHermite series whose graph is a straight line.\n\nThe specified line is given by `off + scl*x`.\n\nThis module\u2019s representation of the Hermite series for `off + scl*x`.\n\nSee also\n\n"}, {"name": "polynomial.hermite.hermmul()", "path": "reference/generated/numpy.polynomial.hermite.hermmul", "type": "numpy.polynomial.hermite.hermmul", "text": "\nMultiply one Hermite series by another.\n\nReturns the product of two Hermite series `c1` * `c2`. The arguments are\nsequences of coefficients, from lowest order \u201cterm\u201d to highest, e.g., [1,2,3]\nrepresents the series `P_0 + 2*P_1 + 3*P_2`.\n\n1-D arrays of Hermite series coefficients ordered from low to high.\n\nOf Hermite series coefficients representing their product.\n\nSee also\n\nIn general, the (polynomial) product of two C-series results in terms that are\nnot in the Hermite polynomial basis set. Thus, to express the product as a\nHermite series, it is necessary to \u201creproject\u201d the product onto said basis\nset, which may produce \u201cunintuitive\u201d (but correct) results; see Examples\nsection below.\n\n"}, {"name": "polynomial.hermite.hermmulx()", "path": "reference/generated/numpy.polynomial.hermite.hermmulx", "type": "numpy.polynomial.hermite.hermmulx", "text": "\nMultiply a Hermite series by x.\n\nMultiply the Hermite series `c` by x, where x is the independent variable.\n\n1-D array of Hermite series coefficients ordered from low to high.\n\nArray representing the result of the multiplication.\n\nSee also\n\nThe multiplication uses the recursion relationship for Hermite polynomials in\nthe form\n\n"}, {"name": "polynomial.hermite.hermone", "path": "reference/generated/numpy.polynomial.hermite.hermone", "type": "numpy.polynomial.hermite.hermone", "text": "\nAn array object represents a multidimensional, homogeneous array of fixed-size\nitems. An associated data-type object describes the format of each element in\nthe array (its byte-order, how many bytes it occupies in memory, whether it is\nan integer, a floating point number, or something else, etc.)\n\nArrays should be constructed using `array`, `zeros` or `empty` (refer to the\nSee Also section below). The parameters given here refer to a low-level method\n(`ndarray(\u2026)`) for instantiating an array.\n\nFor more information, refer to the `numpy` module and examine the methods and\nattributes of an array.\n\nShape of created array.\n\nAny object that can be interpreted as a numpy data type.\n\nUsed to fill the array with data.\n\nOffset of array data in buffer.\n\nStrides of data in memory.\n\nRow-major (C-style) or column-major (Fortran-style) order.\n\nSee also\n\nConstruct an array.\n\nCreate an array, each element of which is zero.\n\nCreate an array, but leave its allocated memory unchanged (i.e., it contains\n\u201cgarbage\u201d).\n\nCreate a data-type.\n\nAn ndarray alias generic w.r.t. its `dtype.type`.\n\nThere are two modes of creating an array using `__new__`:\n\nNo `__init__` method is needed because the array is fully initialized after\nthe `__new__` method.\n\nThese examples illustrate the low-level `ndarray` constructor. Refer to the\n`See Also` section above for easier ways of constructing an ndarray.\n\nFirst mode, `buffer` is None:\n\nSecond mode:\n\nTranspose of the array.\n\nThe array\u2019s elements, in memory.\n\nDescribes the format of the elements in the array.\n\nDictionary containing information related to memory use, e.g., \u2018C_CONTIGUOUS\u2019,\n\u2018OWNDATA\u2019, \u2018WRITEABLE\u2019, etc.\n\nFlattened version of the array as an iterator. The iterator allows\nassignments, e.g., `x.flat = 3` (See `ndarray.flat` for assignment examples;\nTODO).\n\nImaginary part of the array.\n\nReal part of the array.\n\nNumber of elements in the array.\n\nThe memory use of each array element in bytes.\n\nThe total number of bytes required to store the array data, i.e., `itemsize *\nsize`.\n\nThe array\u2019s number of dimensions.\n\nShape of the array.\n\nThe step-size required to move from one element to the next in memory. For\nexample, a contiguous `(3, 4)` array of type `int16` in C-order has strides\n`(8, 2)`. This implies that to move from element to element in memory requires\njumps of 2 bytes. To move from row-to-row, one needs to jump 8 bytes at a time\n(`2 * 4`).\n\nClass containing properties of the array needed for interaction with ctypes.\n\nIf the array is a view into another array, that array is its `base` (unless\nthat array is also a view). The `base` array is where the array data is\nactually stored.\n\n"}, {"name": "polynomial.hermite.hermpow()", "path": "reference/generated/numpy.polynomial.hermite.hermpow", "type": "numpy.polynomial.hermite.hermpow", "text": "\nRaise a Hermite series to a power.\n\nReturns the Hermite series `c` raised to the power `pow`. The argument `c` is\na sequence of coefficients ordered from low to high. i.e., [1,2,3] is the\nseries `P_0 + 2*P_1 + 3*P_2.`\n\n1-D array of Hermite series coefficients ordered from low to high.\n\nPower to which the series will be raised\n\nMaximum power allowed. This is mainly to limit growth of the series to\nunmanageable size. Default is 16\n\nHermite series of power.\n\nSee also\n\n"}, {"name": "polynomial.hermite.hermroots()", "path": "reference/generated/numpy.polynomial.hermite.hermroots", "type": "numpy.polynomial.hermite.hermroots", "text": "\nCompute the roots of a Hermite series.\n\nReturn the roots (a.k.a. \u201czeros\u201d) of the polynomial\n\n1-D array of coefficients.\n\nArray of the roots of the series. If all the roots are real, then `out` is\nalso real, otherwise it is complex.\n\nSee also\n\nThe root estimates are obtained as the eigenvalues of the companion matrix,\nRoots far from the origin of the complex plane may have large errors due to\nthe numerical instability of the series for such values. Roots with\nmultiplicity greater than 1 will also show larger errors as the value of the\nseries near such points is relatively insensitive to errors in the roots.\nIsolated roots near the origin can be improved by a few iterations of Newton\u2019s\nmethod.\n\nThe Hermite series basis polynomials aren\u2019t powers of `x` so the results of\nthis function may seem unintuitive.\n\n"}, {"name": "polynomial.hermite.hermsub()", "path": "reference/generated/numpy.polynomial.hermite.hermsub", "type": "numpy.polynomial.hermite.hermsub", "text": "\nSubtract one Hermite series from another.\n\nReturns the difference of two Hermite series `c1` \\- `c2`. The sequences of\ncoefficients are from lowest order term to highest, i.e., [1,2,3] represents\nthe series `P_0 + 2*P_1 + 3*P_2`.\n\n1-D arrays of Hermite series coefficients ordered from low to high.\n\nOf Hermite series coefficients representing their difference.\n\nSee also\n\nUnlike multiplication, division, etc., the difference of two Hermite series is\na Hermite series (without having to \u201creproject\u201d the result onto the basis set)\nso subtraction, just like that of \u201cstandard\u201d polynomials, is simply\n\u201ccomponent-wise.\u201d\n\n"}, {"name": "polynomial.hermite.hermtrim()", "path": "reference/generated/numpy.polynomial.hermite.hermtrim", "type": "numpy.polynomial.hermite.hermtrim", "text": "\nRemove \u201csmall\u201d \u201ctrailing\u201d coefficients from a polynomial.\n\n\u201cSmall\u201d means \u201csmall in absolute value\u201d and is controlled by the parameter\n`tol`; \u201ctrailing\u201d means highest order coefficient(s), e.g., in `[0, 1, 1, 0,\n0]` (which represents `0 + x + x**2 + 0*x**3 + 0*x**4`) both the 3-rd and 4-th\norder coefficients would be \u201ctrimmed.\u201d\n\n1-d array of coefficients, ordered from lowest order to highest.\n\nTrailing (i.e., highest order) elements with absolute value less than or equal\nto `tol` (default value is zero) are removed.\n\n1-d array with trailing zeros removed. If the resulting series would be empty,\na series containing a single zero is returned.\n\nIf `tol` < 0\n\nSee also\n\n"}, {"name": "polynomial.hermite.hermval()", "path": "reference/generated/numpy.polynomial.hermite.hermval", "type": "numpy.polynomial.hermite.hermval", "text": "\nEvaluate an Hermite series at points x.\n\nIf `c` is of length `n + 1`, this function returns the value:\n\nThe parameter `x` is converted to an array only if it is a tuple or a list,\notherwise it is treated as a scalar. In either case, either `x` or its\nelements must support multiplication and addition both with themselves and\nwith the elements of `c`.\n\nIf `c` is a 1-D array, then `p(x)` will have the same shape as `x`. If `c` is\nmultidimensional, then the shape of the result depends on the value of\n`tensor`. If `tensor` is true the shape will be c.shape[1:] + x.shape. If\n`tensor` is false the shape will be c.shape[1:]. Note that scalars have shape\n(,).\n\nTrailing zeros in the coefficients will be used in the evaluation, so they\nshould be avoided if efficiency is a concern.\n\nIf `x` is a list or tuple, it is converted to an ndarray, otherwise it is left\nunchanged and treated as a scalar. In either case, `x` or its elements must\nsupport addition and multiplication with with themselves and with the elements\nof `c`.\n\nArray of coefficients ordered so that the coefficients for terms of degree n\nare contained in c[n]. If `c` is multidimensional the remaining indices\nenumerate multiple polynomials. In the two dimensional case the coefficients\nmay be thought of as stored in the columns of `c`.\n\nIf True, the shape of the coefficient array is extended with ones on the\nright, one for each dimension of `x`. Scalars have dimension 0 for this\naction. The result is that every column of coefficients in `c` is evaluated\nfor every element of `x`. If False, `x` is broadcast over the columns of `c`\nfor the evaluation. This keyword is useful when `c` is multidimensional. The\ndefault value is True.\n\nNew in version 1.7.0.\n\nThe shape of the return value is described above.\n\nSee also\n\nThe evaluation uses Clenshaw recursion, aka synthetic division.\n\n"}, {"name": "polynomial.hermite.hermval2d()", "path": "reference/generated/numpy.polynomial.hermite.hermval2d", "type": "numpy.polynomial.hermite.hermval2d", "text": "\nEvaluate a 2-D Hermite series at points (x, y).\n\nThis function returns the values:\n\nThe parameters `x` and `y` are converted to arrays only if they are tuples or\na lists, otherwise they are treated as a scalars and they must have the same\nshape after conversion. In either case, either `x` and `y` or their elements\nmust support multiplication and addition both with themselves and with the\nelements of `c`.\n\nIf `c` is a 1-D array a one is implicitly appended to its shape to make it\n2-D. The shape of the result will be c.shape[2:] + x.shape.\n\nThe two dimensional series is evaluated at the points `(x, y)`, where `x` and\n`y` must have the same shape. If `x` or `y` is a list or tuple, it is first\nconverted to an ndarray, otherwise it is left unchanged and if it isn\u2019t an\nndarray it is treated as a scalar.\n\nArray of coefficients ordered so that the coefficient of the term of multi-\ndegree i,j is contained in `c[i,j]`. If `c` has dimension greater than two the\nremaining indices enumerate multiple sets of coefficients.\n\nThe values of the two dimensional polynomial at points formed with pairs of\ncorresponding values from `x` and `y`.\n\nSee also\n\nNew in version 1.7.0.\n\n"}, {"name": "polynomial.hermite.hermval3d()", "path": "reference/generated/numpy.polynomial.hermite.hermval3d", "type": "numpy.polynomial.hermite.hermval3d", "text": "\nEvaluate a 3-D Hermite series at points (x, y, z).\n\nThis function returns the values:\n\nThe parameters `x`, `y`, and `z` are converted to arrays only if they are\ntuples or a lists, otherwise they are treated as a scalars and they must have\nthe same shape after conversion. In either case, either `x`, `y`, and `z` or\ntheir elements must support multiplication and addition both with themselves\nand with the elements of `c`.\n\nIf `c` has fewer than 3 dimensions, ones are implicitly appended to its shape\nto make it 3-D. The shape of the result will be c.shape[3:] + x.shape.\n\nThe three dimensional series is evaluated at the points `(x, y, z)`, where\n`x`, `y`, and `z` must have the same shape. If any of `x`, `y`, or `z` is a\nlist or tuple, it is first converted to an ndarray, otherwise it is left\nunchanged and if it isn\u2019t an ndarray it is treated as a scalar.\n\nArray of coefficients ordered so that the coefficient of the term of multi-\ndegree i,j,k is contained in `c[i,j,k]`. If `c` has dimension greater than 3\nthe remaining indices enumerate multiple sets of coefficients.\n\nThe values of the multidimensional polynomial on points formed with triples of\ncorresponding values from `x`, `y`, and `z`.\n\nSee also\n\nNew in version 1.7.0.\n\n"}, {"name": "polynomial.hermite.hermvander()", "path": "reference/generated/numpy.polynomial.hermite.hermvander", "type": "numpy.polynomial.hermite.hermvander", "text": "\nPseudo-Vandermonde matrix of given degree.\n\nReturns the pseudo-Vandermonde matrix of degree `deg` and sample points `x`.\nThe pseudo-Vandermonde matrix is defined by\n\nwhere `0 <= i <= deg`. The leading indices of `V` index the elements of `x`\nand the last index is the degree of the Hermite polynomial.\n\nIf `c` is a 1-D array of coefficients of length `n + 1` and `V` is the array\n`V = hermvander(x, n)`, then `np.dot(V, c)` and `hermval(x, c)` are the same\nup to roundoff. This equivalence is useful both for least squares fitting and\nfor the evaluation of a large number of Hermite series of the same degree and\nsample points.\n\nArray of points. The dtype is converted to float64 or complex128 depending on\nwhether any of the elements are complex. If `x` is scalar it is converted to a\n1-D array.\n\nDegree of the resulting matrix.\n\nThe pseudo-Vandermonde matrix. The shape of the returned matrix is `x.shape +\n(deg + 1,)`, where The last index is the degree of the corresponding Hermite\npolynomial. The dtype will be the same as the converted `x`.\n\n"}, {"name": "polynomial.hermite.hermvander2d()", "path": "reference/generated/numpy.polynomial.hermite.hermvander2d", "type": "numpy.polynomial.hermite.hermvander2d", "text": "\nPseudo-Vandermonde matrix of given degrees.\n\nReturns the pseudo-Vandermonde matrix of degrees `deg` and sample points `(x,\ny)`. The pseudo-Vandermonde matrix is defined by\n\nwhere `0 <= i <= deg[0]` and `0 <= j <= deg[1]`. The leading indices of `V`\nindex the points `(x, y)` and the last index encodes the degrees of the\nHermite polynomials.\n\nIf `V = hermvander2d(x, y, [xdeg, ydeg])`, then the columns of `V` correspond\nto the elements of a 2-D coefficient array `c` of shape (xdeg + 1, ydeg + 1)\nin the order\n\nand `np.dot(V, c.flat)` and `hermval2d(x, y, c)` will be the same up to\nroundoff. This equivalence is useful both for least squares fitting and for\nthe evaluation of a large number of 2-D Hermite series of the same degrees and\nsample points.\n\nArrays of point coordinates, all of the same shape. The dtypes will be\nconverted to either float64 or complex128 depending on whether any of the\nelements are complex. Scalars are converted to 1-D arrays.\n\nList of maximum degrees of the form [x_deg, y_deg].\n\nThe shape of the returned matrix is `x.shape + (order,)`, where \\\\(order =\n(deg[0]+1)*(deg[1]+1)\\\\). The dtype will be the same as the converted `x` and\n`y`.\n\nSee also\n\nNew in version 1.7.0.\n\n"}, {"name": "polynomial.hermite.hermvander3d()", "path": "reference/generated/numpy.polynomial.hermite.hermvander3d", "type": "numpy.polynomial.hermite.hermvander3d", "text": "\nPseudo-Vandermonde matrix of given degrees.\n\nReturns the pseudo-Vandermonde matrix of degrees `deg` and sample points `(x,\ny, z)`. If `l, m, n` are the given degrees in `x, y, z`, then The pseudo-\nVandermonde matrix is defined by\n\nwhere `0 <= i <= l`, `0 <= j <= m`, and `0 <= j <= n`. The leading indices of\n`V` index the points `(x, y, z)` and the last index encodes the degrees of the\nHermite polynomials.\n\nIf `V = hermvander3d(x, y, z, [xdeg, ydeg, zdeg])`, then the columns of `V`\ncorrespond to the elements of a 3-D coefficient array `c` of shape (xdeg + 1,\nydeg + 1, zdeg + 1) in the order\n\nand `np.dot(V, c.flat)` and `hermval3d(x, y, z, c)` will be the same up to\nroundoff. This equivalence is useful both for least squares fitting and for\nthe evaluation of a large number of 3-D Hermite series of the same degrees and\nsample points.\n\nArrays of point coordinates, all of the same shape. The dtypes will be\nconverted to either float64 or complex128 depending on whether any of the\nelements are complex. Scalars are converted to 1-D arrays.\n\nList of maximum degrees of the form [x_deg, y_deg, z_deg].\n\nThe shape of the returned matrix is `x.shape + (order,)`, where \\\\(order =\n(deg[0]+1)*(deg[1]+1)*(deg[2]+1)\\\\). The dtype will be the same as the\nconverted `x`, `y`, and `z`.\n\nSee also\n\nNew in version 1.7.0.\n\n"}, {"name": "polynomial.hermite.hermweight()", "path": "reference/generated/numpy.polynomial.hermite.hermweight", "type": "numpy.polynomial.hermite.hermweight", "text": "\nWeight function of the Hermite polynomials.\n\nThe weight function is \\\\(\\exp(-x^2)\\\\) and the interval of integration is\n\\\\([-\\inf, \\inf]\\\\). the Hermite polynomials are orthogonal, but not\nnormalized, with respect to this weight function.\n\nValues at which the weight function will be computed.\n\nThe weight function at `x`.\n\nNew in version 1.7.0.\n\n"}, {"name": "polynomial.hermite.hermx", "path": "reference/generated/numpy.polynomial.hermite.hermx", "type": "numpy.polynomial.hermite.hermx", "text": "\nAn array object represents a multidimensional, homogeneous array of fixed-size\nitems. An associated data-type object describes the format of each element in\nthe array (its byte-order, how many bytes it occupies in memory, whether it is\nan integer, a floating point number, or something else, etc.)\n\nArrays should be constructed using `array`, `zeros` or `empty` (refer to the\nSee Also section below). The parameters given here refer to a low-level method\n(`ndarray(\u2026)`) for instantiating an array.\n\nFor more information, refer to the `numpy` module and examine the methods and\nattributes of an array.\n\nShape of created array.\n\nAny object that can be interpreted as a numpy data type.\n\nUsed to fill the array with data.\n\nOffset of array data in buffer.\n\nStrides of data in memory.\n\nRow-major (C-style) or column-major (Fortran-style) order.\n\nSee also\n\nConstruct an array.\n\nCreate an array, each element of which is zero.\n\nCreate an array, but leave its allocated memory unchanged (i.e., it contains\n\u201cgarbage\u201d).\n\nCreate a data-type.\n\nAn ndarray alias generic w.r.t. its `dtype.type`.\n\nThere are two modes of creating an array using `__new__`:\n\nNo `__init__` method is needed because the array is fully initialized after\nthe `__new__` method.\n\nThese examples illustrate the low-level `ndarray` constructor. Refer to the\n`See Also` section above for easier ways of constructing an ndarray.\n\nFirst mode, `buffer` is None:\n\nSecond mode:\n\nTranspose of the array.\n\nThe array\u2019s elements, in memory.\n\nDescribes the format of the elements in the array.\n\nDictionary containing information related to memory use, e.g., \u2018C_CONTIGUOUS\u2019,\n\u2018OWNDATA\u2019, \u2018WRITEABLE\u2019, etc.\n\nFlattened version of the array as an iterator. The iterator allows\nassignments, e.g., `x.flat = 3` (See `ndarray.flat` for assignment examples;\nTODO).\n\nImaginary part of the array.\n\nReal part of the array.\n\nNumber of elements in the array.\n\nThe memory use of each array element in bytes.\n\nThe total number of bytes required to store the array data, i.e., `itemsize *\nsize`.\n\nThe array\u2019s number of dimensions.\n\nShape of the array.\n\nThe step-size required to move from one element to the next in memory. For\nexample, a contiguous `(3, 4)` array of type `int16` in C-order has strides\n`(8, 2)`. This implies that to move from element to element in memory requires\njumps of 2 bytes. To move from row-to-row, one needs to jump 8 bytes at a time\n(`2 * 4`).\n\nClass containing properties of the array needed for interaction with ctypes.\n\nIf the array is a view into another array, that array is its `base` (unless\nthat array is also a view). The `base` array is where the array data is\nactually stored.\n\n"}, {"name": "polynomial.hermite.hermzero", "path": "reference/generated/numpy.polynomial.hermite.hermzero", "type": "numpy.polynomial.hermite.hermzero", "text": "\nAn array object represents a multidimensional, homogeneous array of fixed-size\nitems. An associated data-type object describes the format of each element in\nthe array (its byte-order, how many bytes it occupies in memory, whether it is\nan integer, a floating point number, or something else, etc.)\n\nArrays should be constructed using `array`, `zeros` or `empty` (refer to the\nSee Also section below). The parameters given here refer to a low-level method\n(`ndarray(\u2026)`) for instantiating an array.\n\nFor more information, refer to the `numpy` module and examine the methods and\nattributes of an array.\n\nShape of created array.\n\nAny object that can be interpreted as a numpy data type.\n\nUsed to fill the array with data.\n\nOffset of array data in buffer.\n\nStrides of data in memory.\n\nRow-major (C-style) or column-major (Fortran-style) order.\n\nSee also\n\nConstruct an array.\n\nCreate an array, each element of which is zero.\n\nCreate an array, but leave its allocated memory unchanged (i.e., it contains\n\u201cgarbage\u201d).\n\nCreate a data-type.\n\nAn ndarray alias generic w.r.t. its `dtype.type`.\n\nThere are two modes of creating an array using `__new__`:\n\nNo `__init__` method is needed because the array is fully initialized after\nthe `__new__` method.\n\nThese examples illustrate the low-level `ndarray` constructor. Refer to the\n`See Also` section above for easier ways of constructing an ndarray.\n\nFirst mode, `buffer` is None:\n\nSecond mode:\n\nTranspose of the array.\n\nThe array\u2019s elements, in memory.\n\nDescribes the format of the elements in the array.\n\nDictionary containing information related to memory use, e.g., \u2018C_CONTIGUOUS\u2019,\n\u2018OWNDATA\u2019, \u2018WRITEABLE\u2019, etc.\n\nFlattened version of the array as an iterator. The iterator allows\nassignments, e.g., `x.flat = 3` (See `ndarray.flat` for assignment examples;\nTODO).\n\nImaginary part of the array.\n\nReal part of the array.\n\nNumber of elements in the array.\n\nThe memory use of each array element in bytes.\n\nThe total number of bytes required to store the array data, i.e., `itemsize *\nsize`.\n\nThe array\u2019s number of dimensions.\n\nShape of the array.\n\nThe step-size required to move from one element to the next in memory. For\nexample, a contiguous `(3, 4)` array of type `int16` in C-order has strides\n`(8, 2)`. This implies that to move from element to element in memory requires\njumps of 2 bytes. To move from row-to-row, one needs to jump 8 bytes at a time\n(`2 * 4`).\n\nClass containing properties of the array needed for interaction with ctypes.\n\nIf the array is a view into another array, that array is its `base` (unless\nthat array is also a view). The `base` array is where the array data is\nactually stored.\n\n"}, {"name": "polynomial.hermite.poly2herm()", "path": "reference/generated/numpy.polynomial.hermite.poly2herm", "type": "numpy.polynomial.hermite.poly2herm", "text": "\nConvert a polynomial to a Hermite series.\n\nConvert an array representing the coefficients of a polynomial (relative to\nthe \u201cstandard\u201d basis) ordered from lowest degree to highest, to an array of\nthe coefficients of the equivalent Hermite series, ordered from lowest to\nhighest degree.\n\n1-D array containing the polynomial coefficients\n\n1-D array containing the coefficients of the equivalent Hermite series.\n\nSee also\n\nThe easy way to do conversions between polynomial basis sets is to use the\nconvert method of a class instance.\n\n"}, {"name": "polynomial.hermite_e.herme2poly()", "path": "reference/generated/numpy.polynomial.hermite_e.herme2poly", "type": "numpy.polynomial.hermite_e.herme2poly", "text": "\nConvert a Hermite series to a polynomial.\n\nConvert an array representing the coefficients of a Hermite series, ordered\nfrom lowest degree to highest, to an array of the coefficients of the\nequivalent polynomial (relative to the \u201cstandard\u201d basis) ordered from lowest\nto highest degree.\n\n1-D array containing the Hermite series coefficients, ordered from lowest\norder term to highest.\n\n1-D array containing the coefficients of the equivalent polynomial (relative\nto the \u201cstandard\u201d basis) ordered from lowest order term to highest.\n\nSee also\n\nThe easy way to do conversions between polynomial basis sets is to use the\nconvert method of a class instance.\n\n"}, {"name": "polynomial.hermite_e.hermeadd()", "path": "reference/generated/numpy.polynomial.hermite_e.hermeadd", "type": "numpy.polynomial.hermite_e.hermeadd", "text": "\nAdd one Hermite series to another.\n\nReturns the sum of two Hermite series `c1` \\+ `c2`. The arguments are\nsequences of coefficients ordered from lowest order term to highest, i.e.,\n[1,2,3] represents the series `P_0 + 2*P_1 + 3*P_2`.\n\n1-D arrays of Hermite series coefficients ordered from low to high.\n\nArray representing the Hermite series of their sum.\n\nSee also\n\nUnlike multiplication, division, etc., the sum of two Hermite series is a\nHermite series (without having to \u201creproject\u201d the result onto the basis set)\nso addition, just like that of \u201cstandard\u201d polynomials, is simply \u201ccomponent-\nwise.\u201d\n\n"}, {"name": "polynomial.hermite_e.hermecompanion()", "path": "reference/generated/numpy.polynomial.hermite_e.hermecompanion", "type": "numpy.polynomial.hermite_e.hermecompanion", "text": "\nReturn the scaled companion matrix of c.\n\nThe basis polynomials are scaled so that the companion matrix is symmetric\nwhen `c` is an HermiteE basis polynomial. This provides better eigenvalue\nestimates than the unscaled case and for basis polynomials the eigenvalues are\nguaranteed to be real if `numpy.linalg.eigvalsh` is used to obtain them.\n\n1-D array of HermiteE series coefficients ordered from low to high degree.\n\nScaled companion matrix of dimensions (deg, deg).\n\nNew in version 1.7.0.\n\n"}, {"name": "polynomial.hermite_e.hermeder()", "path": "reference/generated/numpy.polynomial.hermite_e.hermeder", "type": "numpy.polynomial.hermite_e.hermeder", "text": "\nDifferentiate a Hermite_e series.\n\nReturns the series coefficients `c` differentiated `m` times along `axis`. At\neach iteration the result is multiplied by `scl` (the scaling factor is for\nuse in a linear change of variable). The argument `c` is an array of\ncoefficients from low to high degree along each axis, e.g., [1,2,3] represents\nthe series `1*He_0 + 2*He_1 + 3*He_2` while [[1,2],[1,2]] represents\n`1*He_0(x)*He_0(y) + 1*He_1(x)*He_0(y) + 2*He_0(x)*He_1(y) +\n2*He_1(x)*He_1(y)` if axis=0 is `x` and axis=1 is `y`.\n\nArray of Hermite_e series coefficients. If `c` is multidimensional the\ndifferent axis correspond to different variables with the degree in each axis\ngiven by the corresponding index.\n\nNumber of derivatives taken, must be non-negative. (Default: 1)\n\nEach differentiation is multiplied by `scl`. The end result is multiplication\nby `scl**m`. This is for use in a linear change of variable. (Default: 1)\n\nAxis over which the derivative is taken. (Default: 0).\n\nNew in version 1.7.0.\n\nHermite series of the derivative.\n\nSee also\n\nIn general, the result of differentiating a Hermite series does not resemble\nthe same operation on a power series. Thus the result of this function may be\n\u201cunintuitive,\u201d albeit correct; see Examples section below.\n\n"}, {"name": "polynomial.hermite_e.hermediv()", "path": "reference/generated/numpy.polynomial.hermite_e.hermediv", "type": "numpy.polynomial.hermite_e.hermediv", "text": "\nDivide one Hermite series by another.\n\nReturns the quotient-with-remainder of two Hermite series `c1` / `c2`. The\narguments are sequences of coefficients from lowest order \u201cterm\u201d to highest,\ne.g., [1,2,3] represents the series `P_0 + 2*P_1 + 3*P_2`.\n\n1-D arrays of Hermite series coefficients ordered from low to high.\n\nOf Hermite series coefficients representing the quotient and remainder.\n\nSee also\n\nIn general, the (polynomial) division of one Hermite series by another results\nin quotient and remainder terms that are not in the Hermite polynomial basis\nset. Thus, to express these results as a Hermite series, it is necessary to\n\u201creproject\u201d the results onto the Hermite basis set, which may produce\n\u201cunintuitive\u201d (but correct) results; see Examples section below.\n\n"}, {"name": "polynomial.hermite_e.hermedomain", "path": "reference/generated/numpy.polynomial.hermite_e.hermedomain", "type": "numpy.polynomial.hermite_e.hermedomain", "text": "\nAn array object represents a multidimensional, homogeneous array of fixed-size\nitems. An associated data-type object describes the format of each element in\nthe array (its byte-order, how many bytes it occupies in memory, whether it is\nan integer, a floating point number, or something else, etc.)\n\nArrays should be constructed using `array`, `zeros` or `empty` (refer to the\nSee Also section below). The parameters given here refer to a low-level method\n(`ndarray(\u2026)`) for instantiating an array.\n\nFor more information, refer to the `numpy` module and examine the methods and\nattributes of an array.\n\nShape of created array.\n\nAny object that can be interpreted as a numpy data type.\n\nUsed to fill the array with data.\n\nOffset of array data in buffer.\n\nStrides of data in memory.\n\nRow-major (C-style) or column-major (Fortran-style) order.\n\nSee also\n\nConstruct an array.\n\nCreate an array, each element of which is zero.\n\nCreate an array, but leave its allocated memory unchanged (i.e., it contains\n\u201cgarbage\u201d).\n\nCreate a data-type.\n\nAn ndarray alias generic w.r.t. its `dtype.type`.\n\nThere are two modes of creating an array using `__new__`:\n\nNo `__init__` method is needed because the array is fully initialized after\nthe `__new__` method.\n\nThese examples illustrate the low-level `ndarray` constructor. Refer to the\n`See Also` section above for easier ways of constructing an ndarray.\n\nFirst mode, `buffer` is None:\n\nSecond mode:\n\nTranspose of the array.\n\nThe array\u2019s elements, in memory.\n\nDescribes the format of the elements in the array.\n\nDictionary containing information related to memory use, e.g., \u2018C_CONTIGUOUS\u2019,\n\u2018OWNDATA\u2019, \u2018WRITEABLE\u2019, etc.\n\nFlattened version of the array as an iterator. The iterator allows\nassignments, e.g., `x.flat = 3` (See `ndarray.flat` for assignment examples;\nTODO).\n\nImaginary part of the array.\n\nReal part of the array.\n\nNumber of elements in the array.\n\nThe memory use of each array element in bytes.\n\nThe total number of bytes required to store the array data, i.e., `itemsize *\nsize`.\n\nThe array\u2019s number of dimensions.\n\nShape of the array.\n\nThe step-size required to move from one element to the next in memory. For\nexample, a contiguous `(3, 4)` array of type `int16` in C-order has strides\n`(8, 2)`. This implies that to move from element to element in memory requires\njumps of 2 bytes. To move from row-to-row, one needs to jump 8 bytes at a time\n(`2 * 4`).\n\nClass containing properties of the array needed for interaction with ctypes.\n\nIf the array is a view into another array, that array is its `base` (unless\nthat array is also a view). The `base` array is where the array data is\nactually stored.\n\n"}, {"name": "polynomial.hermite_e.hermefit()", "path": "reference/generated/numpy.polynomial.hermite_e.hermefit", "type": "numpy.polynomial.hermite_e.hermefit", "text": "\nLeast squares fit of Hermite series to data.\n\nReturn the coefficients of a HermiteE series of degree `deg` that is the least\nsquares fit to the data values `y` given at points `x`. If `y` is 1-D the\nreturned coefficients will also be 1-D. If `y` is 2-D multiple fits are done,\none for each column of `y`, and the resulting coefficients are stored in the\ncorresponding columns of a 2-D return. The fitted polynomial(s) are in the\nform\n\nwhere `n` is `deg`.\n\nx-coordinates of the M sample points `(x[i], y[i])`.\n\ny-coordinates of the sample points. Several data sets of sample points sharing\nthe same x-coordinates can be fitted at once by passing in a 2D-array that\ncontains one dataset per column.\n\nDegree(s) of the fitting polynomials. If `deg` is a single integer all terms\nup to and including the `deg`\u2019th term are included in the fit. For NumPy\nversions >= 1.11.0 a list of integers specifying the degrees of the terms to\ninclude may be used instead.\n\nRelative condition number of the fit. Singular values smaller than this\nrelative to the largest singular value will be ignored. The default value is\nlen(x)*eps, where eps is the relative precision of the float type, about 2e-16\nin most cases.\n\nSwitch determining nature of return value. When it is False (the default) just\nthe coefficients are returned, when True diagnostic information from the\nsingular value decomposition is also returned.\n\nWeights. If not None, the weight `w[i]` applies to the unsquared residual\n`y[i] - y_hat[i]` at `x[i]`. Ideally the weights are chosen so that the errors\nof the products `w[i]*y[i]` all have the same variance. When using inverse-\nvariance weighting, use `w[i] = 1/sigma(y[i])`. The default value is None.\n\nHermite coefficients ordered from low to high. If `y` was 2-D, the\ncoefficients for the data in column k of `y` are in column `k`.\n\nThese values are only returned if `full == True`\n\nFor more details, see `numpy.linalg.lstsq`.\n\nThe rank of the coefficient matrix in the least-squares fit is deficient. The\nwarning is only raised if `full = False`. The warnings can be turned off by\n\nSee also\n\nEvaluates a Hermite series.\n\npseudo Vandermonde matrix of Hermite series.\n\nHermiteE weight function.\n\nComputes a least-squares fit from the matrix.\n\nComputes spline fits.\n\nThe solution is the coefficients of the HermiteE series `p` that minimizes the\nsum of the weighted squared errors\n\nwhere the \\\\(w_j\\\\) are the weights. This problem is solved by setting up the\n(typically) overdetermined matrix equation\n\nwhere `V` is the pseudo Vandermonde matrix of `x`, the elements of `c` are the\ncoefficients to be solved for, and the elements of `y` are the observed\nvalues. This equation is then solved using the singular value decomposition of\n`V`.\n\nIf some of the singular values of `V` are so small that they are neglected,\nthen a `RankWarning` will be issued. This means that the coefficient values\nmay be poorly determined. Using a lower order fit will usually get rid of the\nwarning. The `rcond` parameter can also be set to a value smaller than its\ndefault, but the resulting fit may be spurious and have large contributions\nfrom roundoff error.\n\nFits using HermiteE series are probably most useful when the data can be\napproximated by `sqrt(w(x)) * p(x)`, where `w(x)` is the HermiteE weight. In\nthat case the weight `sqrt(w(x[i]))` should be used together with data values\n`y[i]/sqrt(w(x[i]))`. The weight function is available as `hermeweight`.\n\nWikipedia, \u201cCurve fitting\u201d, https://en.wikipedia.org/wiki/Curve_fitting\n\n"}, {"name": "polynomial.hermite_e.hermefromroots()", "path": "reference/generated/numpy.polynomial.hermite_e.hermefromroots", "type": "numpy.polynomial.hermite_e.hermefromroots", "text": "\nGenerate a HermiteE series with given roots.\n\nThe function returns the coefficients of the polynomial\n\nin HermiteE form, where the `r_n` are the roots specified in `roots`. If a\nzero has multiplicity n, then it must appear in `roots` n times. For instance,\nif 2 is a root of multiplicity three and 3 is a root of multiplicity 2, then\n`roots` looks something like [2, 2, 2, 3, 3]. The roots can appear in any\norder.\n\nIf the returned coefficients are `c`, then\n\nThe coefficient of the last term is not generally 1 for monic polynomials in\nHermiteE form.\n\nSequence containing the roots.\n\n1-D array of coefficients. If all roots are real then `out` is a real array,\nif some of the roots are complex, then `out` is complex even if all the\ncoefficients in the result are real (see Examples below).\n\nSee also\n\n"}, {"name": "polynomial.hermite_e.hermegauss()", "path": "reference/generated/numpy.polynomial.hermite_e.hermegauss", "type": "numpy.polynomial.hermite_e.hermegauss", "text": "\nGauss-HermiteE quadrature.\n\nComputes the sample points and weights for Gauss-HermiteE quadrature. These\nsample points and weights will correctly integrate polynomials of degree\n\\\\(2*deg - 1\\\\) or less over the interval \\\\([-\\inf, \\inf]\\\\) with the weight\nfunction \\\\(f(x) = \\exp(-x^2/2)\\\\).\n\nNumber of sample points and weights. It must be >= 1.\n\n1-D ndarray containing the sample points.\n\n1-D ndarray containing the weights.\n\nNew in version 1.7.0.\n\nThe results have only been tested up to degree 100, higher degrees may be\nproblematic. The weights are determined by using the fact that\n\nwhere \\\\(c\\\\) is a constant independent of \\\\(k\\\\) and \\\\(x_k\\\\) is the k\u2019th\nroot of \\\\(He_n\\\\), and then scaling the results to get the right value when\nintegrating 1.\n\n"}, {"name": "polynomial.hermite_e.hermegrid2d()", "path": "reference/generated/numpy.polynomial.hermite_e.hermegrid2d", "type": "numpy.polynomial.hermite_e.hermegrid2d", "text": "\nEvaluate a 2-D HermiteE series on the Cartesian product of x and y.\n\nThis function returns the values:\n\nwhere the points `(a, b)` consist of all pairs formed by taking `a` from `x`\nand `b` from `y`. The resulting points form a grid with `x` in the first\ndimension and `y` in the second.\n\nThe parameters `x` and `y` are converted to arrays only if they are tuples or\na lists, otherwise they are treated as a scalars. In either case, either `x`\nand `y` or their elements must support multiplication and addition both with\nthemselves and with the elements of `c`.\n\nIf `c` has fewer than two dimensions, ones are implicitly appended to its\nshape to make it 2-D. The shape of the result will be c.shape[2:] + x.shape.\n\nThe two dimensional series is evaluated at the points in the Cartesian product\nof `x` and `y`. If `x` or `y` is a list or tuple, it is first converted to an\nndarray, otherwise it is left unchanged and, if it isn\u2019t an ndarray, it is\ntreated as a scalar.\n\nArray of coefficients ordered so that the coefficients for terms of degree i,j\nare contained in `c[i,j]`. If `c` has dimension greater than two the remaining\nindices enumerate multiple sets of coefficients.\n\nThe values of the two dimensional polynomial at points in the Cartesian\nproduct of `x` and `y`.\n\nSee also\n\nNew in version 1.7.0.\n\n"}, {"name": "polynomial.hermite_e.hermegrid3d()", "path": "reference/generated/numpy.polynomial.hermite_e.hermegrid3d", "type": "numpy.polynomial.hermite_e.hermegrid3d", "text": "\nEvaluate a 3-D HermiteE series on the Cartesian product of x, y, and z.\n\nThis function returns the values:\n\nwhere the points `(a, b, c)` consist of all triples formed by taking `a` from\n`x`, `b` from `y`, and `c` from `z`. The resulting points form a grid with `x`\nin the first dimension, `y` in the second, and `z` in the third.\n\nThe parameters `x`, `y`, and `z` are converted to arrays only if they are\ntuples or a lists, otherwise they are treated as a scalars. In either case,\neither `x`, `y`, and `z` or their elements must support multiplication and\naddition both with themselves and with the elements of `c`.\n\nIf `c` has fewer than three dimensions, ones are implicitly appended to its\nshape to make it 3-D. The shape of the result will be c.shape[3:] + x.shape +\ny.shape + z.shape.\n\nThe three dimensional series is evaluated at the points in the Cartesian\nproduct of `x`, `y`, and `z`. If `x`,`y`, or `z` is a list or tuple, it is\nfirst converted to an ndarray, otherwise it is left unchanged and, if it isn\u2019t\nan ndarray, it is treated as a scalar.\n\nArray of coefficients ordered so that the coefficients for terms of degree i,j\nare contained in `c[i,j]`. If `c` has dimension greater than two the remaining\nindices enumerate multiple sets of coefficients.\n\nThe values of the two dimensional polynomial at points in the Cartesian\nproduct of `x` and `y`.\n\nSee also\n\nNew in version 1.7.0.\n\n"}, {"name": "polynomial.hermite_e.hermeint()", "path": "reference/generated/numpy.polynomial.hermite_e.hermeint", "type": "numpy.polynomial.hermite_e.hermeint", "text": "\nIntegrate a Hermite_e series.\n\nReturns the Hermite_e series coefficients `c` integrated `m` times from `lbnd`\nalong `axis`. At each iteration the resulting series is multiplied by `scl`\nand an integration constant, `k`, is added. The scaling factor is for use in a\nlinear change of variable. (\u201cBuyer beware\u201d: note that, depending on what one\nis doing, one may want `scl` to be the reciprocal of what one might expect;\nfor more information, see the Notes section below.) The argument `c` is an\narray of coefficients from low to high degree along each axis, e.g., [1,2,3]\nrepresents the series `H_0 + 2*H_1 + 3*H_2` while [[1,2],[1,2]] represents\n`1*H_0(x)*H_0(y) + 1*H_1(x)*H_0(y) + 2*H_0(x)*H_1(y) + 2*H_1(x)*H_1(y)` if\naxis=0 is `x` and axis=1 is `y`.\n\nArray of Hermite_e series coefficients. If c is multidimensional the different\naxis correspond to different variables with the degree in each axis given by\nthe corresponding index.\n\nOrder of integration, must be positive. (Default: 1)\n\nIntegration constant(s). The value of the first integral at `lbnd` is the\nfirst value in the list, the value of the second integral at `lbnd` is the\nsecond value, etc. If `k == []` (the default), all constants are set to zero.\nIf `m == 1`, a single scalar can be given instead of a list.\n\nThe lower bound of the integral. (Default: 0)\n\nFollowing each integration the result is multiplied by `scl` before the\nintegration constant is added. (Default: 1)\n\nAxis over which the integral is taken. (Default: 0).\n\nNew in version 1.7.0.\n\nHermite_e series coefficients of the integral.\n\nIf `m < 0`, `len(k) > m`, `np.ndim(lbnd) != 0`, or `np.ndim(scl) != 0`.\n\nSee also\n\nNote that the result of each integration is multiplied by `scl`. Why is this\nimportant to note? Say one is making a linear change of variable \\\\(u = ax +\nb\\\\) in an integral relative to `x`. Then \\\\(dx = du/a\\\\), so one will need to\nset `scl` equal to \\\\(1/a\\\\) \\- perhaps not what one would have first thought.\n\nAlso note that, in general, the result of integrating a C-series needs to be\n\u201creprojected\u201d onto the C-series basis set. Thus, typically, the result of this\nfunction is \u201cunintuitive,\u201d albeit correct; see Examples section below.\n\n"}, {"name": "polynomial.hermite_e.hermeline()", "path": "reference/generated/numpy.polynomial.hermite_e.hermeline", "type": "numpy.polynomial.hermite_e.hermeline", "text": "\nHermite series whose graph is a straight line.\n\nThe specified line is given by `off + scl*x`.\n\nThis module\u2019s representation of the Hermite series for `off + scl*x`.\n\nSee also\n\n"}, {"name": "polynomial.hermite_e.hermemul()", "path": "reference/generated/numpy.polynomial.hermite_e.hermemul", "type": "numpy.polynomial.hermite_e.hermemul", "text": "\nMultiply one Hermite series by another.\n\nReturns the product of two Hermite series `c1` * `c2`. The arguments are\nsequences of coefficients, from lowest order \u201cterm\u201d to highest, e.g., [1,2,3]\nrepresents the series `P_0 + 2*P_1 + 3*P_2`.\n\n1-D arrays of Hermite series coefficients ordered from low to high.\n\nOf Hermite series coefficients representing their product.\n\nSee also\n\nIn general, the (polynomial) product of two C-series results in terms that are\nnot in the Hermite polynomial basis set. Thus, to express the product as a\nHermite series, it is necessary to \u201creproject\u201d the product onto said basis\nset, which may produce \u201cunintuitive\u201d (but correct) results; see Examples\nsection below.\n\n"}, {"name": "polynomial.hermite_e.hermemulx()", "path": "reference/generated/numpy.polynomial.hermite_e.hermemulx", "type": "numpy.polynomial.hermite_e.hermemulx", "text": "\nMultiply a Hermite series by x.\n\nMultiply the Hermite series `c` by x, where x is the independent variable.\n\n1-D array of Hermite series coefficients ordered from low to high.\n\nArray representing the result of the multiplication.\n\nThe multiplication uses the recursion relationship for Hermite polynomials in\nthe form\n\n"}, {"name": "polynomial.hermite_e.hermeone", "path": "reference/generated/numpy.polynomial.hermite_e.hermeone", "type": "numpy.polynomial.hermite_e.hermeone", "text": "\nAn array object represents a multidimensional, homogeneous array of fixed-size\nitems. An associated data-type object describes the format of each element in\nthe array (its byte-order, how many bytes it occupies in memory, whether it is\nan integer, a floating point number, or something else, etc.)\n\nArrays should be constructed using `array`, `zeros` or `empty` (refer to the\nSee Also section below). The parameters given here refer to a low-level method\n(`ndarray(\u2026)`) for instantiating an array.\n\nFor more information, refer to the `numpy` module and examine the methods and\nattributes of an array.\n\nShape of created array.\n\nAny object that can be interpreted as a numpy data type.\n\nUsed to fill the array with data.\n\nOffset of array data in buffer.\n\nStrides of data in memory.\n\nRow-major (C-style) or column-major (Fortran-style) order.\n\nSee also\n\nConstruct an array.\n\nCreate an array, each element of which is zero.\n\nCreate an array, but leave its allocated memory unchanged (i.e., it contains\n\u201cgarbage\u201d).\n\nCreate a data-type.\n\nAn ndarray alias generic w.r.t. its `dtype.type`.\n\nThere are two modes of creating an array using `__new__`:\n\nNo `__init__` method is needed because the array is fully initialized after\nthe `__new__` method.\n\nThese examples illustrate the low-level `ndarray` constructor. Refer to the\n`See Also` section above for easier ways of constructing an ndarray.\n\nFirst mode, `buffer` is None:\n\nSecond mode:\n\nTranspose of the array.\n\nThe array\u2019s elements, in memory.\n\nDescribes the format of the elements in the array.\n\nDictionary containing information related to memory use, e.g., \u2018C_CONTIGUOUS\u2019,\n\u2018OWNDATA\u2019, \u2018WRITEABLE\u2019, etc.\n\nFlattened version of the array as an iterator. The iterator allows\nassignments, e.g., `x.flat = 3` (See `ndarray.flat` for assignment examples;\nTODO).\n\nImaginary part of the array.\n\nReal part of the array.\n\nNumber of elements in the array.\n\nThe memory use of each array element in bytes.\n\nThe total number of bytes required to store the array data, i.e., `itemsize *\nsize`.\n\nThe array\u2019s number of dimensions.\n\nShape of the array.\n\nThe step-size required to move from one element to the next in memory. For\nexample, a contiguous `(3, 4)` array of type `int16` in C-order has strides\n`(8, 2)`. This implies that to move from element to element in memory requires\njumps of 2 bytes. To move from row-to-row, one needs to jump 8 bytes at a time\n(`2 * 4`).\n\nClass containing properties of the array needed for interaction with ctypes.\n\nIf the array is a view into another array, that array is its `base` (unless\nthat array is also a view). The `base` array is where the array data is\nactually stored.\n\n"}, {"name": "polynomial.hermite_e.hermepow()", "path": "reference/generated/numpy.polynomial.hermite_e.hermepow", "type": "numpy.polynomial.hermite_e.hermepow", "text": "\nRaise a Hermite series to a power.\n\nReturns the Hermite series `c` raised to the power `pow`. The argument `c` is\na sequence of coefficients ordered from low to high. i.e., [1,2,3] is the\nseries `P_0 + 2*P_1 + 3*P_2.`\n\n1-D array of Hermite series coefficients ordered from low to high.\n\nPower to which the series will be raised\n\nMaximum power allowed. This is mainly to limit growth of the series to\nunmanageable size. Default is 16\n\nHermite series of power.\n\nSee also\n\n"}, {"name": "polynomial.hermite_e.hermeroots()", "path": "reference/generated/numpy.polynomial.hermite_e.hermeroots", "type": "numpy.polynomial.hermite_e.hermeroots", "text": "\nCompute the roots of a HermiteE series.\n\nReturn the roots (a.k.a. \u201czeros\u201d) of the polynomial\n\n1-D array of coefficients.\n\nArray of the roots of the series. If all the roots are real, then `out` is\nalso real, otherwise it is complex.\n\nSee also\n\nThe root estimates are obtained as the eigenvalues of the companion matrix,\nRoots far from the origin of the complex plane may have large errors due to\nthe numerical instability of the series for such values. Roots with\nmultiplicity greater than 1 will also show larger errors as the value of the\nseries near such points is relatively insensitive to errors in the roots.\nIsolated roots near the origin can be improved by a few iterations of Newton\u2019s\nmethod.\n\nThe HermiteE series basis polynomials aren\u2019t powers of `x` so the results of\nthis function may seem unintuitive.\n\n"}, {"name": "polynomial.hermite_e.hermesub()", "path": "reference/generated/numpy.polynomial.hermite_e.hermesub", "type": "numpy.polynomial.hermite_e.hermesub", "text": "\nSubtract one Hermite series from another.\n\nReturns the difference of two Hermite series `c1` \\- `c2`. The sequences of\ncoefficients are from lowest order term to highest, i.e., [1,2,3] represents\nthe series `P_0 + 2*P_1 + 3*P_2`.\n\n1-D arrays of Hermite series coefficients ordered from low to high.\n\nOf Hermite series coefficients representing their difference.\n\nSee also\n\nUnlike multiplication, division, etc., the difference of two Hermite series is\na Hermite series (without having to \u201creproject\u201d the result onto the basis set)\nso subtraction, just like that of \u201cstandard\u201d polynomials, is simply\n\u201ccomponent-wise.\u201d\n\n"}, {"name": "polynomial.hermite_e.hermetrim()", "path": "reference/generated/numpy.polynomial.hermite_e.hermetrim", "type": "numpy.polynomial.hermite_e.hermetrim", "text": "\nRemove \u201csmall\u201d \u201ctrailing\u201d coefficients from a polynomial.\n\n\u201cSmall\u201d means \u201csmall in absolute value\u201d and is controlled by the parameter\n`tol`; \u201ctrailing\u201d means highest order coefficient(s), e.g., in `[0, 1, 1, 0,\n0]` (which represents `0 + x + x**2 + 0*x**3 + 0*x**4`) both the 3-rd and 4-th\norder coefficients would be \u201ctrimmed.\u201d\n\n1-d array of coefficients, ordered from lowest order to highest.\n\nTrailing (i.e., highest order) elements with absolute value less than or equal\nto `tol` (default value is zero) are removed.\n\n1-d array with trailing zeros removed. If the resulting series would be empty,\na series containing a single zero is returned.\n\nIf `tol` < 0\n\nSee also\n\n"}, {"name": "polynomial.hermite_e.hermeval()", "path": "reference/generated/numpy.polynomial.hermite_e.hermeval", "type": "numpy.polynomial.hermite_e.hermeval", "text": "\nEvaluate an HermiteE series at points x.\n\nIf `c` is of length `n + 1`, this function returns the value:\n\nThe parameter `x` is converted to an array only if it is a tuple or a list,\notherwise it is treated as a scalar. In either case, either `x` or its\nelements must support multiplication and addition both with themselves and\nwith the elements of `c`.\n\nIf `c` is a 1-D array, then `p(x)` will have the same shape as `x`. If `c` is\nmultidimensional, then the shape of the result depends on the value of\n`tensor`. If `tensor` is true the shape will be c.shape[1:] + x.shape. If\n`tensor` is false the shape will be c.shape[1:]. Note that scalars have shape\n(,).\n\nTrailing zeros in the coefficients will be used in the evaluation, so they\nshould be avoided if efficiency is a concern.\n\nIf `x` is a list or tuple, it is converted to an ndarray, otherwise it is left\nunchanged and treated as a scalar. In either case, `x` or its elements must\nsupport addition and multiplication with with themselves and with the elements\nof `c`.\n\nArray of coefficients ordered so that the coefficients for terms of degree n\nare contained in c[n]. If `c` is multidimensional the remaining indices\nenumerate multiple polynomials. In the two dimensional case the coefficients\nmay be thought of as stored in the columns of `c`.\n\nIf True, the shape of the coefficient array is extended with ones on the\nright, one for each dimension of `x`. Scalars have dimension 0 for this\naction. The result is that every column of coefficients in `c` is evaluated\nfor every element of `x`. If False, `x` is broadcast over the columns of `c`\nfor the evaluation. This keyword is useful when `c` is multidimensional. The\ndefault value is True.\n\nNew in version 1.7.0.\n\nThe shape of the return value is described above.\n\nSee also\n\nThe evaluation uses Clenshaw recursion, aka synthetic division.\n\n"}, {"name": "polynomial.hermite_e.hermeval2d()", "path": "reference/generated/numpy.polynomial.hermite_e.hermeval2d", "type": "numpy.polynomial.hermite_e.hermeval2d", "text": "\nEvaluate a 2-D HermiteE series at points (x, y).\n\nThis function returns the values:\n\nThe parameters `x` and `y` are converted to arrays only if they are tuples or\na lists, otherwise they are treated as a scalars and they must have the same\nshape after conversion. In either case, either `x` and `y` or their elements\nmust support multiplication and addition both with themselves and with the\nelements of `c`.\n\nIf `c` is a 1-D array a one is implicitly appended to its shape to make it\n2-D. The shape of the result will be c.shape[2:] + x.shape.\n\nThe two dimensional series is evaluated at the points `(x, y)`, where `x` and\n`y` must have the same shape. If `x` or `y` is a list or tuple, it is first\nconverted to an ndarray, otherwise it is left unchanged and if it isn\u2019t an\nndarray it is treated as a scalar.\n\nArray of coefficients ordered so that the coefficient of the term of multi-\ndegree i,j is contained in `c[i,j]`. If `c` has dimension greater than two the\nremaining indices enumerate multiple sets of coefficients.\n\nThe values of the two dimensional polynomial at points formed with pairs of\ncorresponding values from `x` and `y`.\n\nSee also\n\nNew in version 1.7.0.\n\n"}, {"name": "polynomial.hermite_e.hermeval3d()", "path": "reference/generated/numpy.polynomial.hermite_e.hermeval3d", "type": "numpy.polynomial.hermite_e.hermeval3d", "text": "\nEvaluate a 3-D Hermite_e series at points (x, y, z).\n\nThis function returns the values:\n\nThe parameters `x`, `y`, and `z` are converted to arrays only if they are\ntuples or a lists, otherwise they are treated as a scalars and they must have\nthe same shape after conversion. In either case, either `x`, `y`, and `z` or\ntheir elements must support multiplication and addition both with themselves\nand with the elements of `c`.\n\nIf `c` has fewer than 3 dimensions, ones are implicitly appended to its shape\nto make it 3-D. The shape of the result will be c.shape[3:] + x.shape.\n\nThe three dimensional series is evaluated at the points `(x, y, z)`, where\n`x`, `y`, and `z` must have the same shape. If any of `x`, `y`, or `z` is a\nlist or tuple, it is first converted to an ndarray, otherwise it is left\nunchanged and if it isn\u2019t an ndarray it is treated as a scalar.\n\nArray of coefficients ordered so that the coefficient of the term of multi-\ndegree i,j,k is contained in `c[i,j,k]`. If `c` has dimension greater than 3\nthe remaining indices enumerate multiple sets of coefficients.\n\nThe values of the multidimensional polynomial on points formed with triples of\ncorresponding values from `x`, `y`, and `z`.\n\nSee also\n\nNew in version 1.7.0.\n\n"}, {"name": "polynomial.hermite_e.hermevander()", "path": "reference/generated/numpy.polynomial.hermite_e.hermevander", "type": "numpy.polynomial.hermite_e.hermevander", "text": "\nPseudo-Vandermonde matrix of given degree.\n\nReturns the pseudo-Vandermonde matrix of degree `deg` and sample points `x`.\nThe pseudo-Vandermonde matrix is defined by\n\nwhere `0 <= i <= deg`. The leading indices of `V` index the elements of `x`\nand the last index is the degree of the HermiteE polynomial.\n\nIf `c` is a 1-D array of coefficients of length `n + 1` and `V` is the array\n`V = hermevander(x, n)`, then `np.dot(V, c)` and `hermeval(x, c)` are the same\nup to roundoff. This equivalence is useful both for least squares fitting and\nfor the evaluation of a large number of HermiteE series of the same degree and\nsample points.\n\nArray of points. The dtype is converted to float64 or complex128 depending on\nwhether any of the elements are complex. If `x` is scalar it is converted to a\n1-D array.\n\nDegree of the resulting matrix.\n\nThe pseudo-Vandermonde matrix. The shape of the returned matrix is `x.shape +\n(deg + 1,)`, where The last index is the degree of the corresponding HermiteE\npolynomial. The dtype will be the same as the converted `x`.\n\n"}, {"name": "polynomial.hermite_e.hermevander2d()", "path": "reference/generated/numpy.polynomial.hermite_e.hermevander2d", "type": "numpy.polynomial.hermite_e.hermevander2d", "text": "\nPseudo-Vandermonde matrix of given degrees.\n\nReturns the pseudo-Vandermonde matrix of degrees `deg` and sample points `(x,\ny)`. The pseudo-Vandermonde matrix is defined by\n\nwhere `0 <= i <= deg[0]` and `0 <= j <= deg[1]`. The leading indices of `V`\nindex the points `(x, y)` and the last index encodes the degrees of the\nHermiteE polynomials.\n\nIf `V = hermevander2d(x, y, [xdeg, ydeg])`, then the columns of `V` correspond\nto the elements of a 2-D coefficient array `c` of shape (xdeg + 1, ydeg + 1)\nin the order\n\nand `np.dot(V, c.flat)` and `hermeval2d(x, y, c)` will be the same up to\nroundoff. This equivalence is useful both for least squares fitting and for\nthe evaluation of a large number of 2-D HermiteE series of the same degrees\nand sample points.\n\nArrays of point coordinates, all of the same shape. The dtypes will be\nconverted to either float64 or complex128 depending on whether any of the\nelements are complex. Scalars are converted to 1-D arrays.\n\nList of maximum degrees of the form [x_deg, y_deg].\n\nThe shape of the returned matrix is `x.shape + (order,)`, where \\\\(order =\n(deg[0]+1)*(deg[1]+1)\\\\). The dtype will be the same as the converted `x` and\n`y`.\n\nSee also\n\nNew in version 1.7.0.\n\n"}, {"name": "polynomial.hermite_e.hermevander3d()", "path": "reference/generated/numpy.polynomial.hermite_e.hermevander3d", "type": "numpy.polynomial.hermite_e.hermevander3d", "text": "\nPseudo-Vandermonde matrix of given degrees.\n\nReturns the pseudo-Vandermonde matrix of degrees `deg` and sample points `(x,\ny, z)`. If `l, m, n` are the given degrees in `x, y, z`, then Hehe pseudo-\nVandermonde matrix is defined by\n\nwhere `0 <= i <= l`, `0 <= j <= m`, and `0 <= j <= n`. The leading indices of\n`V` index the points `(x, y, z)` and the last index encodes the degrees of the\nHermiteE polynomials.\n\nIf `V = hermevander3d(x, y, z, [xdeg, ydeg, zdeg])`, then the columns of `V`\ncorrespond to the elements of a 3-D coefficient array `c` of shape (xdeg + 1,\nydeg + 1, zdeg + 1) in the order\n\nand `np.dot(V, c.flat)` and `hermeval3d(x, y, z, c)` will be the same up to\nroundoff. This equivalence is useful both for least squares fitting and for\nthe evaluation of a large number of 3-D HermiteE series of the same degrees\nand sample points.\n\nArrays of point coordinates, all of the same shape. The dtypes will be\nconverted to either float64 or complex128 depending on whether any of the\nelements are complex. Scalars are converted to 1-D arrays.\n\nList of maximum degrees of the form [x_deg, y_deg, z_deg].\n\nThe shape of the returned matrix is `x.shape + (order,)`, where \\\\(order =\n(deg[0]+1)*(deg[1]+1)*(deg[2]+1)\\\\). The dtype will be the same as the\nconverted `x`, `y`, and `z`.\n\nSee also\n\nNew in version 1.7.0.\n\n"}, {"name": "polynomial.hermite_e.hermeweight()", "path": "reference/generated/numpy.polynomial.hermite_e.hermeweight", "type": "numpy.polynomial.hermite_e.hermeweight", "text": "\nWeight function of the Hermite_e polynomials.\n\nThe weight function is \\\\(\\exp(-x^2/2)\\\\) and the interval of integration is\n\\\\([-\\inf, \\inf]\\\\). the HermiteE polynomials are orthogonal, but not\nnormalized, with respect to this weight function.\n\nValues at which the weight function will be computed.\n\nThe weight function at `x`.\n\nNew in version 1.7.0.\n\n"}, {"name": "polynomial.hermite_e.hermex", "path": "reference/generated/numpy.polynomial.hermite_e.hermex", "type": "numpy.polynomial.hermite_e.hermex", "text": "\nAn array object represents a multidimensional, homogeneous array of fixed-size\nitems. An associated data-type object describes the format of each element in\nthe array (its byte-order, how many bytes it occupies in memory, whether it is\nan integer, a floating point number, or something else, etc.)\n\nArrays should be constructed using `array`, `zeros` or `empty` (refer to the\nSee Also section below). The parameters given here refer to a low-level method\n(`ndarray(\u2026)`) for instantiating an array.\n\nFor more information, refer to the `numpy` module and examine the methods and\nattributes of an array.\n\nShape of created array.\n\nAny object that can be interpreted as a numpy data type.\n\nUsed to fill the array with data.\n\nOffset of array data in buffer.\n\nStrides of data in memory.\n\nRow-major (C-style) or column-major (Fortran-style) order.\n\nSee also\n\nConstruct an array.\n\nCreate an array, each element of which is zero.\n\nCreate an array, but leave its allocated memory unchanged (i.e., it contains\n\u201cgarbage\u201d).\n\nCreate a data-type.\n\nAn ndarray alias generic w.r.t. its `dtype.type`.\n\nThere are two modes of creating an array using `__new__`:\n\nNo `__init__` method is needed because the array is fully initialized after\nthe `__new__` method.\n\nThese examples illustrate the low-level `ndarray` constructor. Refer to the\n`See Also` section above for easier ways of constructing an ndarray.\n\nFirst mode, `buffer` is None:\n\nSecond mode:\n\nTranspose of the array.\n\nThe array\u2019s elements, in memory.\n\nDescribes the format of the elements in the array.\n\nDictionary containing information related to memory use, e.g., \u2018C_CONTIGUOUS\u2019,\n\u2018OWNDATA\u2019, \u2018WRITEABLE\u2019, etc.\n\nFlattened version of the array as an iterator. The iterator allows\nassignments, e.g., `x.flat = 3` (See `ndarray.flat` for assignment examples;\nTODO).\n\nImaginary part of the array.\n\nReal part of the array.\n\nNumber of elements in the array.\n\nThe memory use of each array element in bytes.\n\nThe total number of bytes required to store the array data, i.e., `itemsize *\nsize`.\n\nThe array\u2019s number of dimensions.\n\nShape of the array.\n\nThe step-size required to move from one element to the next in memory. For\nexample, a contiguous `(3, 4)` array of type `int16` in C-order has strides\n`(8, 2)`. This implies that to move from element to element in memory requires\njumps of 2 bytes. To move from row-to-row, one needs to jump 8 bytes at a time\n(`2 * 4`).\n\nClass containing properties of the array needed for interaction with ctypes.\n\nIf the array is a view into another array, that array is its `base` (unless\nthat array is also a view). The `base` array is where the array data is\nactually stored.\n\n"}, {"name": "polynomial.hermite_e.hermezero", "path": "reference/generated/numpy.polynomial.hermite_e.hermezero", "type": "numpy.polynomial.hermite_e.hermezero", "text": "\nAn array object represents a multidimensional, homogeneous array of fixed-size\nitems. An associated data-type object describes the format of each element in\nthe array (its byte-order, how many bytes it occupies in memory, whether it is\nan integer, a floating point number, or something else, etc.)\n\nArrays should be constructed using `array`, `zeros` or `empty` (refer to the\nSee Also section below). The parameters given here refer to a low-level method\n(`ndarray(\u2026)`) for instantiating an array.\n\nFor more information, refer to the `numpy` module and examine the methods and\nattributes of an array.\n\nShape of created array.\n\nAny object that can be interpreted as a numpy data type.\n\nUsed to fill the array with data.\n\nOffset of array data in buffer.\n\nStrides of data in memory.\n\nRow-major (C-style) or column-major (Fortran-style) order.\n\nSee also\n\nConstruct an array.\n\nCreate an array, each element of which is zero.\n\nCreate an array, but leave its allocated memory unchanged (i.e., it contains\n\u201cgarbage\u201d).\n\nCreate a data-type.\n\nAn ndarray alias generic w.r.t. its `dtype.type`.\n\nThere are two modes of creating an array using `__new__`:\n\nNo `__init__` method is needed because the array is fully initialized after\nthe `__new__` method.\n\nThese examples illustrate the low-level `ndarray` constructor. Refer to the\n`See Also` section above for easier ways of constructing an ndarray.\n\nFirst mode, `buffer` is None:\n\nSecond mode:\n\nTranspose of the array.\n\nThe array\u2019s elements, in memory.\n\nDescribes the format of the elements in the array.\n\nDictionary containing information related to memory use, e.g., \u2018C_CONTIGUOUS\u2019,\n\u2018OWNDATA\u2019, \u2018WRITEABLE\u2019, etc.\n\nFlattened version of the array as an iterator. The iterator allows\nassignments, e.g., `x.flat = 3` (See `ndarray.flat` for assignment examples;\nTODO).\n\nImaginary part of the array.\n\nReal part of the array.\n\nNumber of elements in the array.\n\nThe memory use of each array element in bytes.\n\nThe total number of bytes required to store the array data, i.e., `itemsize *\nsize`.\n\nThe array\u2019s number of dimensions.\n\nShape of the array.\n\nThe step-size required to move from one element to the next in memory. For\nexample, a contiguous `(3, 4)` array of type `int16` in C-order has strides\n`(8, 2)`. This implies that to move from element to element in memory requires\njumps of 2 bytes. To move from row-to-row, one needs to jump 8 bytes at a time\n(`2 * 4`).\n\nClass containing properties of the array needed for interaction with ctypes.\n\nIf the array is a view into another array, that array is its `base` (unless\nthat array is also a view). The `base` array is where the array data is\nactually stored.\n\n"}, {"name": "polynomial.hermite_e.HermiteE.__call__()", "path": "reference/generated/numpy.polynomial.hermite_e.hermitee.__call__", "type": "numpy.polynomial.hermite_e.HermiteE", "text": "\nmethod\n\nCall self as a function.\n\n"}, {"name": "polynomial.hermite_e.HermiteE.basis()", "path": "reference/generated/numpy.polynomial.hermite_e.hermitee.basis", "type": "numpy.polynomial.hermite_e.HermiteE", "text": "\nmethod\n\nSeries basis polynomial of degree `deg`.\n\nReturns the series representing the basis polynomial of degree `deg`.\n\nNew in version 1.7.0.\n\nDegree of the basis polynomial for the series. Must be >= 0.\n\nIf given, the array must be of the form `[beg, end]`, where `beg` and `end`\nare the endpoints of the domain. If None is given then the class domain is\nused. The default is None.\n\nIf given, the resulting array must be if the form `[beg, end]`, where `beg`\nand `end` are the endpoints of the window. If None is given then the class\nwindow is used. The default is None.\n\nA series with the coefficient of the `deg` term set to one and all others\nzero.\n\n"}, {"name": "polynomial.hermite_e.HermiteE.cast()", "path": "reference/generated/numpy.polynomial.hermite_e.hermitee.cast", "type": "numpy.polynomial.hermite_e.HermiteE", "text": "\nmethod\n\nConvert series to series of this class.\n\nThe `series` is expected to be an instance of some polynomial series of one of\nthe types supported by by the numpy.polynomial module, but could be some other\nclass that supports the convert method.\n\nNew in version 1.7.0.\n\nThe series instance to be converted.\n\nIf given, the array must be of the form `[beg, end]`, where `beg` and `end`\nare the endpoints of the domain. If None is given then the class domain is\nused. The default is None.\n\nIf given, the resulting array must be if the form `[beg, end]`, where `beg`\nand `end` are the endpoints of the window. If None is given then the class\nwindow is used. The default is None.\n\nA series of the same kind as the calling class and equal to `series` when\nevaluated.\n\nSee also\n\nsimilar instance method\n\n"}, {"name": "polynomial.hermite_e.HermiteE.convert()", "path": "reference/generated/numpy.polynomial.hermite_e.hermitee.convert", "type": "numpy.polynomial.hermite_e.HermiteE", "text": "\nmethod\n\nConvert series to a different kind and/or domain and/or window.\n\nThe domain of the converted series. If the value is None, the default domain\nof `kind` is used.\n\nThe polynomial series type class to which the current instance should be\nconverted. If kind is None, then the class of the current instance is used.\n\nThe window of the converted series. If the value is None, the default window\nof `kind` is used.\n\nThe returned class can be of different type than the current instance and/or\nhave a different domain and/or different window.\n\nConversion between domains and class types can result in numerically ill\ndefined series.\n\n"}, {"name": "polynomial.hermite_e.HermiteE.copy()", "path": "reference/generated/numpy.polynomial.hermite_e.hermitee.copy", "type": "numpy.polynomial.hermite_e.HermiteE", "text": "\nmethod\n\nReturn a copy.\n\nCopy of self.\n\n"}, {"name": "polynomial.hermite_e.HermiteE.cutdeg()", "path": "reference/generated/numpy.polynomial.hermite_e.hermitee.cutdeg", "type": "numpy.polynomial.hermite_e.HermiteE", "text": "\nmethod\n\nTruncate series to the given degree.\n\nReduce the degree of the series to `deg` by discarding the high order terms.\nIf `deg` is greater than the current degree a copy of the current series is\nreturned. This can be useful in least squares where the coefficients of the\nhigh degree terms may be very small.\n\nNew in version 1.5.0.\n\nThe series is reduced to degree `deg` by discarding the high order terms. The\nvalue of `deg` must be a non-negative integer.\n\nNew instance of series with reduced degree.\n\n"}, {"name": "polynomial.hermite_e.HermiteE.degree()", "path": "reference/generated/numpy.polynomial.hermite_e.hermitee.degree", "type": "numpy.polynomial.hermite_e.HermiteE", "text": "\nmethod\n\nThe degree of the series.\n\nNew in version 1.5.0.\n\nDegree of the series, one less than the number of coefficients.\n\n"}, {"name": "polynomial.hermite_e.HermiteE.deriv()", "path": "reference/generated/numpy.polynomial.hermite_e.hermitee.deriv", "type": "numpy.polynomial.hermite_e.HermiteE", "text": "\nmethod\n\nDifferentiate.\n\nReturn a series instance of that is the derivative of the current series.\n\nFind the derivative of order `m`.\n\nA new series representing the derivative. The domain is the same as the domain\nof the differentiated series.\n\n"}, {"name": "polynomial.hermite_e.HermiteE.domain", "path": "reference/generated/numpy.polynomial.hermite_e.hermitee.domain", "type": "Polynomials", "text": "\nattribute\n\n"}, {"name": "polynomial.hermite_e.HermiteE.fit()", "path": "reference/generated/numpy.polynomial.hermite_e.hermitee.fit", "type": "numpy.polynomial.hermite_e.HermiteE", "text": "\nmethod\n\nLeast squares fit to data.\n\nReturn a series instance that is the least squares fit to the data `y` sampled\nat `x`. The domain of the returned instance can be specified and this will\noften result in a superior fit with less chance of ill conditioning.\n\nx-coordinates of the M sample points `(x[i], y[i])`.\n\ny-coordinates of the M sample points `(x[i], y[i])`.\n\nDegree(s) of the fitting polynomials. If `deg` is a single integer all terms\nup to and including the `deg`\u2019th term are included in the fit. For NumPy\nversions >= 1.11.0 a list of integers specifying the degrees of the terms to\ninclude may be used instead.\n\nDomain to use for the returned series. If `None`, then a minimal domain that\ncovers the points `x` is chosen. If `[]` the class domain is used. The default\nvalue was the class domain in NumPy 1.4 and `None` in later versions. The `[]`\noption was added in numpy 1.5.0.\n\nRelative condition number of the fit. Singular values smaller than this\nrelative to the largest singular value will be ignored. The default value is\nlen(x)*eps, where eps is the relative precision of the float type, about 2e-16\nin most cases.\n\nSwitch determining nature of return value. When it is False (the default) just\nthe coefficients are returned, when True diagnostic information from the\nsingular value decomposition is also returned.\n\nWeights. If not None, the weight `w[i]` applies to the unsquared residual\n`y[i] - y_hat[i]` at `x[i]`. Ideally the weights are chosen so that the errors\nof the products `w[i]*y[i]` all have the same variance. When using inverse-\nvariance weighting, use `w[i] = 1/sigma(y[i])`. The default value is None.\n\nNew in version 1.5.0.\n\nWindow to use for the returned series. The default value is the default class\ndomain\n\nNew in version 1.6.0.\n\nA series that represents the least squares fit to the data and has the domain\nand window specified in the call. If the coefficients for the unscaled and\nunshifted basis polynomials are of interest, do `new_series.convert().coef`.\n\nThese values are only returned if `full == True`\n\nFor more details, see `linalg.lstsq`.\n\n"}, {"name": "polynomial.hermite_e.HermiteE.fromroots()", "path": "reference/generated/numpy.polynomial.hermite_e.hermitee.fromroots", "type": "numpy.polynomial.hermite_e.HermiteE", "text": "\nmethod\n\nReturn series instance that has the specified roots.\n\nReturns a series representing the product `(x - r[0])*(x - r[1])*...*(x -\nr[n-1])`, where `r` is a list of roots.\n\nList of roots.\n\nDomain for the resulting series. If None the domain is the interval from the\nsmallest root to the largest. If [] the domain is the class domain. The\ndefault is [].\n\nWindow for the returned series. If None the class window is used. The default\nis None.\n\nSeries with the specified roots.\n\n"}, {"name": "polynomial.hermite_e.HermiteE.has_samecoef()", "path": "reference/generated/numpy.polynomial.hermite_e.hermitee.has_samecoef", "type": "numpy.polynomial.hermite_e.HermiteE", "text": "\nmethod\n\nCheck if coefficients match.\n\nNew in version 1.6.0.\n\nThe other class must have the `coef` attribute.\n\nTrue if the coefficients are the same, False otherwise.\n\n"}, {"name": "polynomial.hermite_e.HermiteE.has_samedomain()", "path": "reference/generated/numpy.polynomial.hermite_e.hermitee.has_samedomain", "type": "numpy.polynomial.hermite_e.HermiteE", "text": "\nmethod\n\nCheck if domains match.\n\nNew in version 1.6.0.\n\nThe other class must have the `domain` attribute.\n\nTrue if the domains are the same, False otherwise.\n\n"}, {"name": "polynomial.hermite_e.HermiteE.has_sametype()", "path": "reference/generated/numpy.polynomial.hermite_e.hermitee.has_sametype", "type": "numpy.polynomial.hermite_e.HermiteE", "text": "\nmethod\n\nCheck if types match.\n\nNew in version 1.7.0.\n\nClass instance.\n\nTrue if other is same class as self\n\n"}, {"name": "polynomial.hermite_e.HermiteE.has_samewindow()", "path": "reference/generated/numpy.polynomial.hermite_e.hermitee.has_samewindow", "type": "numpy.polynomial.hermite_e.HermiteE", "text": "\nmethod\n\nCheck if windows match.\n\nNew in version 1.6.0.\n\nThe other class must have the `window` attribute.\n\nTrue if the windows are the same, False otherwise.\n\n"}, {"name": "polynomial.hermite_e.HermiteE.identity()", "path": "reference/generated/numpy.polynomial.hermite_e.hermitee.identity", "type": "numpy.polynomial.hermite_e.HermiteE", "text": "\nmethod\n\nIdentity function.\n\nIf `p` is the returned series, then `p(x) == x` for all values of x.\n\nIf given, the array must be of the form `[beg, end]`, where `beg` and `end`\nare the endpoints of the domain. If None is given then the class domain is\nused. The default is None.\n\nIf given, the resulting array must be if the form `[beg, end]`, where `beg`\nand `end` are the endpoints of the window. If None is given then the class\nwindow is used. The default is None.\n\nSeries of representing the identity.\n\n"}, {"name": "polynomial.hermite_e.HermiteE.integ()", "path": "reference/generated/numpy.polynomial.hermite_e.hermitee.integ", "type": "numpy.polynomial.hermite_e.HermiteE", "text": "\nmethod\n\nIntegrate.\n\nReturn a series instance that is the definite integral of the current series.\n\nThe number of integrations to perform.\n\nIntegration constants. The first constant is applied to the first integration,\nthe second to the second, and so on. The list of values must less than or\nequal to `m` in length and any missing values are set to zero.\n\nThe lower bound of the definite integral.\n\nA new series representing the integral. The domain is the same as the domain\nof the integrated series.\n\n"}, {"name": "polynomial.hermite_e.HermiteE.linspace()", "path": "reference/generated/numpy.polynomial.hermite_e.hermitee.linspace", "type": "numpy.polynomial.hermite_e.HermiteE", "text": "\nmethod\n\nReturn x, y values at equally spaced points in domain.\n\nReturns the x, y values at `n` linearly spaced points across the domain. Here\ny is the value of the polynomial at the points x. By default the domain is the\nsame as that of the series instance. This method is intended mostly as a\nplotting aid.\n\nNew in version 1.5.0.\n\nNumber of point pairs to return. The default value is 100.\n\nIf not None, the specified domain is used instead of that of the calling\ninstance. It should be of the form `[beg,end]`. The default is None which case\nthe class domain is used.\n\nx is equal to linspace(self.domain[0], self.domain[1], n) and y is the series\nevaluated at element of x.\n\n"}, {"name": "polynomial.hermite_e.HermiteE.mapparms()", "path": "reference/generated/numpy.polynomial.hermite_e.hermitee.mapparms", "type": "numpy.polynomial.hermite_e.HermiteE", "text": "\nmethod\n\nReturn the mapping parameters.\n\nThe returned values define a linear map `off + scl*x` that is applied to the\ninput arguments before the series is evaluated. The map depends on the\n`domain` and `window`; if the current `domain` is equal to the `window` the\nresulting map is the identity. If the coefficients of the series instance are\nto be used by themselves outside this class, then the linear function must be\nsubstituted for the `x` in the standard representation of the base\npolynomials.\n\nThe mapping function is defined by `off + scl*x`.\n\nIf the current domain is the interval `[l1, r1]` and the window is `[l2, r2]`,\nthen the linear mapping function `L` is defined by the equations:\n\n"}, {"name": "polynomial.hermite_e.HermiteE.roots()", "path": "reference/generated/numpy.polynomial.hermite_e.hermitee.roots", "type": "numpy.polynomial.hermite_e.HermiteE", "text": "\nmethod\n\nReturn the roots of the series polynomial.\n\nCompute the roots for the series. Note that the accuracy of the roots decrease\nthe further outside the domain they lie.\n\nArray containing the roots of the series.\n\n"}, {"name": "polynomial.hermite_e.HermiteE.trim()", "path": "reference/generated/numpy.polynomial.hermite_e.hermitee.trim", "type": "numpy.polynomial.hermite_e.HermiteE", "text": "\nmethod\n\nRemove trailing coefficients\n\nRemove trailing coefficients until a coefficient is reached whose absolute\nvalue greater than `tol` or the beginning of the series is reached. If all the\ncoefficients would be removed the series is set to `[0]`. A new series\ninstance is returned with the new coefficients. The current instance remains\nunchanged.\n\nAll trailing coefficients less than `tol` will be removed.\n\nNew instance of series with trimmed coefficients.\n\n"}, {"name": "polynomial.hermite_e.HermiteE.truncate()", "path": "reference/generated/numpy.polynomial.hermite_e.hermitee.truncate", "type": "numpy.polynomial.hermite_e.HermiteE", "text": "\nmethod\n\nTruncate series to length `size`.\n\nReduce the series to length `size` by discarding the high degree terms. The\nvalue of `size` must be a positive integer. This can be useful in least\nsquares where the coefficients of the high degree terms may be very small.\n\nThe series is reduced to length `size` by discarding the high degree terms.\nThe value of `size` must be a positive integer.\n\nNew instance of series with truncated coefficients.\n\n"}, {"name": "polynomial.hermite_e.poly2herme()", "path": "reference/generated/numpy.polynomial.hermite_e.poly2herme", "type": "numpy.polynomial.hermite_e.poly2herme", "text": "\nConvert a polynomial to a Hermite series.\n\nConvert an array representing the coefficients of a polynomial (relative to\nthe \u201cstandard\u201d basis) ordered from lowest degree to highest, to an array of\nthe coefficients of the equivalent Hermite series, ordered from lowest to\nhighest degree.\n\n1-D array containing the polynomial coefficients\n\n1-D array containing the coefficients of the equivalent Hermite series.\n\nSee also\n\nThe easy way to do conversions between polynomial basis sets is to use the\nconvert method of a class instance.\n\n"}, {"name": "polynomial.laguerre.lag2poly()", "path": "reference/generated/numpy.polynomial.laguerre.lag2poly", "type": "numpy.polynomial.laguerre.lag2poly", "text": "\nConvert a Laguerre series to a polynomial.\n\nConvert an array representing the coefficients of a Laguerre series, ordered\nfrom lowest degree to highest, to an array of the coefficients of the\nequivalent polynomial (relative to the \u201cstandard\u201d basis) ordered from lowest\nto highest degree.\n\n1-D array containing the Laguerre series coefficients, ordered from lowest\norder term to highest.\n\n1-D array containing the coefficients of the equivalent polynomial (relative\nto the \u201cstandard\u201d basis) ordered from lowest order term to highest.\n\nSee also\n\nThe easy way to do conversions between polynomial basis sets is to use the\nconvert method of a class instance.\n\n"}, {"name": "polynomial.laguerre.lagadd()", "path": "reference/generated/numpy.polynomial.laguerre.lagadd", "type": "numpy.polynomial.laguerre.lagadd", "text": "\nAdd one Laguerre series to another.\n\nReturns the sum of two Laguerre series `c1` \\+ `c2`. The arguments are\nsequences of coefficients ordered from lowest order term to highest, i.e.,\n[1,2,3] represents the series `P_0 + 2*P_1 + 3*P_2`.\n\n1-D arrays of Laguerre series coefficients ordered from low to high.\n\nArray representing the Laguerre series of their sum.\n\nSee also\n\nUnlike multiplication, division, etc., the sum of two Laguerre series is a\nLaguerre series (without having to \u201creproject\u201d the result onto the basis set)\nso addition, just like that of \u201cstandard\u201d polynomials, is simply \u201ccomponent-\nwise.\u201d\n\n"}, {"name": "polynomial.laguerre.lagcompanion()", "path": "reference/generated/numpy.polynomial.laguerre.lagcompanion", "type": "numpy.polynomial.laguerre.lagcompanion", "text": "\nReturn the companion matrix of c.\n\nThe usual companion matrix of the Laguerre polynomials is already symmetric\nwhen `c` is a basis Laguerre polynomial, so no scaling is applied.\n\n1-D array of Laguerre series coefficients ordered from low to high degree.\n\nCompanion matrix of dimensions (deg, deg).\n\nNew in version 1.7.0.\n\n"}, {"name": "polynomial.laguerre.lagder()", "path": "reference/generated/numpy.polynomial.laguerre.lagder", "type": "numpy.polynomial.laguerre.lagder", "text": "\nDifferentiate a Laguerre series.\n\nReturns the Laguerre series coefficients `c` differentiated `m` times along\n`axis`. At each iteration the result is multiplied by `scl` (the scaling\nfactor is for use in a linear change of variable). The argument `c` is an\narray of coefficients from low to high degree along each axis, e.g., [1,2,3]\nrepresents the series `1*L_0 + 2*L_1 + 3*L_2` while [[1,2],[1,2]] represents\n`1*L_0(x)*L_0(y) + 1*L_1(x)*L_0(y) + 2*L_0(x)*L_1(y) + 2*L_1(x)*L_1(y)` if\naxis=0 is `x` and axis=1 is `y`.\n\nArray of Laguerre series coefficients. If `c` is multidimensional the\ndifferent axis correspond to different variables with the degree in each axis\ngiven by the corresponding index.\n\nNumber of derivatives taken, must be non-negative. (Default: 1)\n\nEach differentiation is multiplied by `scl`. The end result is multiplication\nby `scl**m`. This is for use in a linear change of variable. (Default: 1)\n\nAxis over which the derivative is taken. (Default: 0).\n\nNew in version 1.7.0.\n\nLaguerre series of the derivative.\n\nSee also\n\nIn general, the result of differentiating a Laguerre series does not resemble\nthe same operation on a power series. Thus the result of this function may be\n\u201cunintuitive,\u201d albeit correct; see Examples section below.\n\n"}, {"name": "polynomial.laguerre.lagdiv()", "path": "reference/generated/numpy.polynomial.laguerre.lagdiv", "type": "numpy.polynomial.laguerre.lagdiv", "text": "\nDivide one Laguerre series by another.\n\nReturns the quotient-with-remainder of two Laguerre series `c1` / `c2`. The\narguments are sequences of coefficients from lowest order \u201cterm\u201d to highest,\ne.g., [1,2,3] represents the series `P_0 + 2*P_1 + 3*P_2`.\n\n1-D arrays of Laguerre series coefficients ordered from low to high.\n\nOf Laguerre series coefficients representing the quotient and remainder.\n\nSee also\n\nIn general, the (polynomial) division of one Laguerre series by another\nresults in quotient and remainder terms that are not in the Laguerre\npolynomial basis set. Thus, to express these results as a Laguerre series, it\nis necessary to \u201creproject\u201d the results onto the Laguerre basis set, which may\nproduce \u201cunintuitive\u201d (but correct) results; see Examples section below.\n\n"}, {"name": "polynomial.laguerre.lagdomain", "path": "reference/generated/numpy.polynomial.laguerre.lagdomain", "type": "numpy.polynomial.laguerre.lagdomain", "text": "\nAn array object represents a multidimensional, homogeneous array of fixed-size\nitems. An associated data-type object describes the format of each element in\nthe array (its byte-order, how many bytes it occupies in memory, whether it is\nan integer, a floating point number, or something else, etc.)\n\nArrays should be constructed using `array`, `zeros` or `empty` (refer to the\nSee Also section below). The parameters given here refer to a low-level method\n(`ndarray(\u2026)`) for instantiating an array.\n\nFor more information, refer to the `numpy` module and examine the methods and\nattributes of an array.\n\nShape of created array.\n\nAny object that can be interpreted as a numpy data type.\n\nUsed to fill the array with data.\n\nOffset of array data in buffer.\n\nStrides of data in memory.\n\nRow-major (C-style) or column-major (Fortran-style) order.\n\nSee also\n\nConstruct an array.\n\nCreate an array, each element of which is zero.\n\nCreate an array, but leave its allocated memory unchanged (i.e., it contains\n\u201cgarbage\u201d).\n\nCreate a data-type.\n\nAn ndarray alias generic w.r.t. its `dtype.type`.\n\nThere are two modes of creating an array using `__new__`:\n\nNo `__init__` method is needed because the array is fully initialized after\nthe `__new__` method.\n\nThese examples illustrate the low-level `ndarray` constructor. Refer to the\n`See Also` section above for easier ways of constructing an ndarray.\n\nFirst mode, `buffer` is None:\n\nSecond mode:\n\nTranspose of the array.\n\nThe array\u2019s elements, in memory.\n\nDescribes the format of the elements in the array.\n\nDictionary containing information related to memory use, e.g., \u2018C_CONTIGUOUS\u2019,\n\u2018OWNDATA\u2019, \u2018WRITEABLE\u2019, etc.\n\nFlattened version of the array as an iterator. The iterator allows\nassignments, e.g., `x.flat = 3` (See `ndarray.flat` for assignment examples;\nTODO).\n\nImaginary part of the array.\n\nReal part of the array.\n\nNumber of elements in the array.\n\nThe memory use of each array element in bytes.\n\nThe total number of bytes required to store the array data, i.e., `itemsize *\nsize`.\n\nThe array\u2019s number of dimensions.\n\nShape of the array.\n\nThe step-size required to move from one element to the next in memory. For\nexample, a contiguous `(3, 4)` array of type `int16` in C-order has strides\n`(8, 2)`. This implies that to move from element to element in memory requires\njumps of 2 bytes. To move from row-to-row, one needs to jump 8 bytes at a time\n(`2 * 4`).\n\nClass containing properties of the array needed for interaction with ctypes.\n\nIf the array is a view into another array, that array is its `base` (unless\nthat array is also a view). The `base` array is where the array data is\nactually stored.\n\n"}, {"name": "polynomial.laguerre.lagfit()", "path": "reference/generated/numpy.polynomial.laguerre.lagfit", "type": "numpy.polynomial.laguerre.lagfit", "text": "\nLeast squares fit of Laguerre series to data.\n\nReturn the coefficients of a Laguerre series of degree `deg` that is the least\nsquares fit to the data values `y` given at points `x`. If `y` is 1-D the\nreturned coefficients will also be 1-D. If `y` is 2-D multiple fits are done,\none for each column of `y`, and the resulting coefficients are stored in the\ncorresponding columns of a 2-D return. The fitted polynomial(s) are in the\nform\n\nwhere `n` is `deg`.\n\nx-coordinates of the M sample points `(x[i], y[i])`.\n\ny-coordinates of the sample points. Several data sets of sample points sharing\nthe same x-coordinates can be fitted at once by passing in a 2D-array that\ncontains one dataset per column.\n\nDegree(s) of the fitting polynomials. If `deg` is a single integer all terms\nup to and including the `deg`\u2019th term are included in the fit. For NumPy\nversions >= 1.11.0 a list of integers specifying the degrees of the terms to\ninclude may be used instead.\n\nRelative condition number of the fit. Singular values smaller than this\nrelative to the largest singular value will be ignored. The default value is\nlen(x)*eps, where eps is the relative precision of the float type, about 2e-16\nin most cases.\n\nSwitch determining nature of return value. When it is False (the default) just\nthe coefficients are returned, when True diagnostic information from the\nsingular value decomposition is also returned.\n\nWeights. If not None, the weight `w[i]` applies to the unsquared residual\n`y[i] - y_hat[i]` at `x[i]`. Ideally the weights are chosen so that the errors\nof the products `w[i]*y[i]` all have the same variance. When using inverse-\nvariance weighting, use `w[i] = 1/sigma(y[i])`. The default value is None.\n\nLaguerre coefficients ordered from low to high. If `y` was 2-D, the\ncoefficients for the data in column k of `y` are in column `k`.\n\nThese values are only returned if `full == True`\n\nFor more details, see `numpy.linalg.lstsq`.\n\nThe rank of the coefficient matrix in the least-squares fit is deficient. The\nwarning is only raised if `full == False`. The warnings can be turned off by\n\nSee also\n\nEvaluates a Laguerre series.\n\npseudo Vandermonde matrix of Laguerre series.\n\nLaguerre weight function.\n\nComputes a least-squares fit from the matrix.\n\nComputes spline fits.\n\nThe solution is the coefficients of the Laguerre series `p` that minimizes the\nsum of the weighted squared errors\n\nwhere the \\\\(w_j\\\\) are the weights. This problem is solved by setting up as\nthe (typically) overdetermined matrix equation\n\nwhere `V` is the weighted pseudo Vandermonde matrix of `x`, `c` are the\ncoefficients to be solved for, `w` are the weights, and `y` are the observed\nvalues. This equation is then solved using the singular value decomposition of\n`V`.\n\nIf some of the singular values of `V` are so small that they are neglected,\nthen a `RankWarning` will be issued. This means that the coefficient values\nmay be poorly determined. Using a lower order fit will usually get rid of the\nwarning. The `rcond` parameter can also be set to a value smaller than its\ndefault, but the resulting fit may be spurious and have large contributions\nfrom roundoff error.\n\nFits using Laguerre series are probably most useful when the data can be\napproximated by `sqrt(w(x)) * p(x)`, where `w(x)` is the Laguerre weight. In\nthat case the weight `sqrt(w(x[i]))` should be used together with data values\n`y[i]/sqrt(w(x[i]))`. The weight function is available as `lagweight`.\n\nWikipedia, \u201cCurve fitting\u201d, https://en.wikipedia.org/wiki/Curve_fitting\n\n"}, {"name": "polynomial.laguerre.lagfromroots()", "path": "reference/generated/numpy.polynomial.laguerre.lagfromroots", "type": "numpy.polynomial.laguerre.lagfromroots", "text": "\nGenerate a Laguerre series with given roots.\n\nThe function returns the coefficients of the polynomial\n\nin Laguerre form, where the `r_n` are the roots specified in `roots`. If a\nzero has multiplicity n, then it must appear in `roots` n times. For instance,\nif 2 is a root of multiplicity three and 3 is a root of multiplicity 2, then\n`roots` looks something like [2, 2, 2, 3, 3]. The roots can appear in any\norder.\n\nIf the returned coefficients are `c`, then\n\nThe coefficient of the last term is not generally 1 for monic polynomials in\nLaguerre form.\n\nSequence containing the roots.\n\n1-D array of coefficients. If all roots are real then `out` is a real array,\nif some of the roots are complex, then `out` is complex even if all the\ncoefficients in the result are real (see Examples below).\n\nSee also\n\n"}, {"name": "polynomial.laguerre.laggauss()", "path": "reference/generated/numpy.polynomial.laguerre.laggauss", "type": "numpy.polynomial.laguerre.laggauss", "text": "\nGauss-Laguerre quadrature.\n\nComputes the sample points and weights for Gauss-Laguerre quadrature. These\nsample points and weights will correctly integrate polynomials of degree\n\\\\(2*deg - 1\\\\) or less over the interval \\\\([0, \\inf]\\\\) with the weight\nfunction \\\\(f(x) = \\exp(-x)\\\\).\n\nNumber of sample points and weights. It must be >= 1.\n\n1-D ndarray containing the sample points.\n\n1-D ndarray containing the weights.\n\nNew in version 1.7.0.\n\nThe results have only been tested up to degree 100 higher degrees may be\nproblematic. The weights are determined by using the fact that\n\nwhere \\\\(c\\\\) is a constant independent of \\\\(k\\\\) and \\\\(x_k\\\\) is the k\u2019th\nroot of \\\\(L_n\\\\), and then scaling the results to get the right value when\nintegrating 1.\n\n"}, {"name": "polynomial.laguerre.laggrid2d()", "path": "reference/generated/numpy.polynomial.laguerre.laggrid2d", "type": "numpy.polynomial.laguerre.laggrid2d", "text": "\nEvaluate a 2-D Laguerre series on the Cartesian product of x and y.\n\nThis function returns the values:\n\nwhere the points `(a, b)` consist of all pairs formed by taking `a` from `x`\nand `b` from `y`. The resulting points form a grid with `x` in the first\ndimension and `y` in the second.\n\nThe parameters `x` and `y` are converted to arrays only if they are tuples or\na lists, otherwise they are treated as a scalars. In either case, either `x`\nand `y` or their elements must support multiplication and addition both with\nthemselves and with the elements of `c`.\n\nIf `c` has fewer than two dimensions, ones are implicitly appended to its\nshape to make it 2-D. The shape of the result will be c.shape[2:] + x.shape +\ny.shape.\n\nThe two dimensional series is evaluated at the points in the Cartesian product\nof `x` and `y`. If `x` or `y` is a list or tuple, it is first converted to an\nndarray, otherwise it is left unchanged and, if it isn\u2019t an ndarray, it is\ntreated as a scalar.\n\nArray of coefficients ordered so that the coefficient of the term of multi-\ndegree i,j is contained in `c[i,j]`. If `c` has dimension greater than two the\nremaining indices enumerate multiple sets of coefficients.\n\nThe values of the two dimensional Chebyshev series at points in the Cartesian\nproduct of `x` and `y`.\n\nSee also\n\nNew in version 1.7.0.\n\n"}, {"name": "polynomial.laguerre.laggrid3d()", "path": "reference/generated/numpy.polynomial.laguerre.laggrid3d", "type": "numpy.polynomial.laguerre.laggrid3d", "text": "\nEvaluate a 3-D Laguerre series on the Cartesian product of x, y, and z.\n\nThis function returns the values:\n\nwhere the points `(a, b, c)` consist of all triples formed by taking `a` from\n`x`, `b` from `y`, and `c` from `z`. The resulting points form a grid with `x`\nin the first dimension, `y` in the second, and `z` in the third.\n\nThe parameters `x`, `y`, and `z` are converted to arrays only if they are\ntuples or a lists, otherwise they are treated as a scalars. In either case,\neither `x`, `y`, and `z` or their elements must support multiplication and\naddition both with themselves and with the elements of `c`.\n\nIf `c` has fewer than three dimensions, ones are implicitly appended to its\nshape to make it 3-D. The shape of the result will be c.shape[3:] + x.shape +\ny.shape + z.shape.\n\nThe three dimensional series is evaluated at the points in the Cartesian\nproduct of `x`, `y`, and `z`. If `x`,`y`, or `z` is a list or tuple, it is\nfirst converted to an ndarray, otherwise it is left unchanged and, if it isn\u2019t\nan ndarray, it is treated as a scalar.\n\nArray of coefficients ordered so that the coefficients for terms of degree i,j\nare contained in `c[i,j]`. If `c` has dimension greater than two the remaining\nindices enumerate multiple sets of coefficients.\n\nThe values of the two dimensional polynomial at points in the Cartesian\nproduct of `x` and `y`.\n\nSee also\n\nNew in version 1.7.0.\n\n"}, {"name": "polynomial.laguerre.lagint()", "path": "reference/generated/numpy.polynomial.laguerre.lagint", "type": "numpy.polynomial.laguerre.lagint", "text": "\nIntegrate a Laguerre series.\n\nReturns the Laguerre series coefficients `c` integrated `m` times from `lbnd`\nalong `axis`. At each iteration the resulting series is multiplied by `scl`\nand an integration constant, `k`, is added. The scaling factor is for use in a\nlinear change of variable. (\u201cBuyer beware\u201d: note that, depending on what one\nis doing, one may want `scl` to be the reciprocal of what one might expect;\nfor more information, see the Notes section below.) The argument `c` is an\narray of coefficients from low to high degree along each axis, e.g., [1,2,3]\nrepresents the series `L_0 + 2*L_1 + 3*L_2` while [[1,2],[1,2]] represents\n`1*L_0(x)*L_0(y) + 1*L_1(x)*L_0(y) + 2*L_0(x)*L_1(y) + 2*L_1(x)*L_1(y)` if\naxis=0 is `x` and axis=1 is `y`.\n\nArray of Laguerre series coefficients. If `c` is multidimensional the\ndifferent axis correspond to different variables with the degree in each axis\ngiven by the corresponding index.\n\nOrder of integration, must be positive. (Default: 1)\n\nIntegration constant(s). The value of the first integral at `lbnd` is the\nfirst value in the list, the value of the second integral at `lbnd` is the\nsecond value, etc. If `k == []` (the default), all constants are set to zero.\nIf `m == 1`, a single scalar can be given instead of a list.\n\nThe lower bound of the integral. (Default: 0)\n\nFollowing each integration the result is multiplied by `scl` before the\nintegration constant is added. (Default: 1)\n\nAxis over which the integral is taken. (Default: 0).\n\nNew in version 1.7.0.\n\nLaguerre series coefficients of the integral.\n\nIf `m < 0`, `len(k) > m`, `np.ndim(lbnd) != 0`, or `np.ndim(scl) != 0`.\n\nSee also\n\nNote that the result of each integration is multiplied by `scl`. Why is this\nimportant to note? Say one is making a linear change of variable \\\\(u = ax +\nb\\\\) in an integral relative to `x`. Then \\\\(dx = du/a\\\\), so one will need to\nset `scl` equal to \\\\(1/a\\\\) \\- perhaps not what one would have first thought.\n\nAlso note that, in general, the result of integrating a C-series needs to be\n\u201creprojected\u201d onto the C-series basis set. Thus, typically, the result of this\nfunction is \u201cunintuitive,\u201d albeit correct; see Examples section below.\n\n"}, {"name": "polynomial.laguerre.lagline()", "path": "reference/generated/numpy.polynomial.laguerre.lagline", "type": "numpy.polynomial.laguerre.lagline", "text": "\nLaguerre series whose graph is a straight line.\n\nThe specified line is given by `off + scl*x`.\n\nThis module\u2019s representation of the Laguerre series for `off + scl*x`.\n\nSee also\n\n"}, {"name": "polynomial.laguerre.lagmul()", "path": "reference/generated/numpy.polynomial.laguerre.lagmul", "type": "numpy.polynomial.laguerre.lagmul", "text": "\nMultiply one Laguerre series by another.\n\nReturns the product of two Laguerre series `c1` * `c2`. The arguments are\nsequences of coefficients, from lowest order \u201cterm\u201d to highest, e.g., [1,2,3]\nrepresents the series `P_0 + 2*P_1 + 3*P_2`.\n\n1-D arrays of Laguerre series coefficients ordered from low to high.\n\nOf Laguerre series coefficients representing their product.\n\nSee also\n\nIn general, the (polynomial) product of two C-series results in terms that are\nnot in the Laguerre polynomial basis set. Thus, to express the product as a\nLaguerre series, it is necessary to \u201creproject\u201d the product onto said basis\nset, which may produce \u201cunintuitive\u201d (but correct) results; see Examples\nsection below.\n\n"}, {"name": "polynomial.laguerre.lagmulx()", "path": "reference/generated/numpy.polynomial.laguerre.lagmulx", "type": "numpy.polynomial.laguerre.lagmulx", "text": "\nMultiply a Laguerre series by x.\n\nMultiply the Laguerre series `c` by x, where x is the independent variable.\n\n1-D array of Laguerre series coefficients ordered from low to high.\n\nArray representing the result of the multiplication.\n\nSee also\n\nThe multiplication uses the recursion relationship for Laguerre polynomials in\nthe form\n\n"}, {"name": "polynomial.laguerre.lagone", "path": "reference/generated/numpy.polynomial.laguerre.lagone", "type": "numpy.polynomial.laguerre.lagone", "text": "\nAn array object represents a multidimensional, homogeneous array of fixed-size\nitems. An associated data-type object describes the format of each element in\nthe array (its byte-order, how many bytes it occupies in memory, whether it is\nan integer, a floating point number, or something else, etc.)\n\nArrays should be constructed using `array`, `zeros` or `empty` (refer to the\nSee Also section below). The parameters given here refer to a low-level method\n(`ndarray(\u2026)`) for instantiating an array.\n\nFor more information, refer to the `numpy` module and examine the methods and\nattributes of an array.\n\nShape of created array.\n\nAny object that can be interpreted as a numpy data type.\n\nUsed to fill the array with data.\n\nOffset of array data in buffer.\n\nStrides of data in memory.\n\nRow-major (C-style) or column-major (Fortran-style) order.\n\nSee also\n\nConstruct an array.\n\nCreate an array, each element of which is zero.\n\nCreate an array, but leave its allocated memory unchanged (i.e., it contains\n\u201cgarbage\u201d).\n\nCreate a data-type.\n\nAn ndarray alias generic w.r.t. its `dtype.type`.\n\nThere are two modes of creating an array using `__new__`:\n\nNo `__init__` method is needed because the array is fully initialized after\nthe `__new__` method.\n\nThese examples illustrate the low-level `ndarray` constructor. Refer to the\n`See Also` section above for easier ways of constructing an ndarray.\n\nFirst mode, `buffer` is None:\n\nSecond mode:\n\nTranspose of the array.\n\nThe array\u2019s elements, in memory.\n\nDescribes the format of the elements in the array.\n\nDictionary containing information related to memory use, e.g., \u2018C_CONTIGUOUS\u2019,\n\u2018OWNDATA\u2019, \u2018WRITEABLE\u2019, etc.\n\nFlattened version of the array as an iterator. The iterator allows\nassignments, e.g., `x.flat = 3` (See `ndarray.flat` for assignment examples;\nTODO).\n\nImaginary part of the array.\n\nReal part of the array.\n\nNumber of elements in the array.\n\nThe memory use of each array element in bytes.\n\nThe total number of bytes required to store the array data, i.e., `itemsize *\nsize`.\n\nThe array\u2019s number of dimensions.\n\nShape of the array.\n\nThe step-size required to move from one element to the next in memory. For\nexample, a contiguous `(3, 4)` array of type `int16` in C-order has strides\n`(8, 2)`. This implies that to move from element to element in memory requires\njumps of 2 bytes. To move from row-to-row, one needs to jump 8 bytes at a time\n(`2 * 4`).\n\nClass containing properties of the array needed for interaction with ctypes.\n\nIf the array is a view into another array, that array is its `base` (unless\nthat array is also a view). The `base` array is where the array data is\nactually stored.\n\n"}, {"name": "polynomial.laguerre.lagpow()", "path": "reference/generated/numpy.polynomial.laguerre.lagpow", "type": "numpy.polynomial.laguerre.lagpow", "text": "\nRaise a Laguerre series to a power.\n\nReturns the Laguerre series `c` raised to the power `pow`. The argument `c` is\na sequence of coefficients ordered from low to high. i.e., [1,2,3] is the\nseries `P_0 + 2*P_1 + 3*P_2.`\n\n1-D array of Laguerre series coefficients ordered from low to high.\n\nPower to which the series will be raised\n\nMaximum power allowed. This is mainly to limit growth of the series to\nunmanageable size. Default is 16\n\nLaguerre series of power.\n\nSee also\n\n"}, {"name": "polynomial.laguerre.lagroots()", "path": "reference/generated/numpy.polynomial.laguerre.lagroots", "type": "numpy.polynomial.laguerre.lagroots", "text": "\nCompute the roots of a Laguerre series.\n\nReturn the roots (a.k.a. \u201czeros\u201d) of the polynomial\n\n1-D array of coefficients.\n\nArray of the roots of the series. If all the roots are real, then `out` is\nalso real, otherwise it is complex.\n\nSee also\n\nThe root estimates are obtained as the eigenvalues of the companion matrix,\nRoots far from the origin of the complex plane may have large errors due to\nthe numerical instability of the series for such values. Roots with\nmultiplicity greater than 1 will also show larger errors as the value of the\nseries near such points is relatively insensitive to errors in the roots.\nIsolated roots near the origin can be improved by a few iterations of Newton\u2019s\nmethod.\n\nThe Laguerre series basis polynomials aren\u2019t powers of `x` so the results of\nthis function may seem unintuitive.\n\n"}, {"name": "polynomial.laguerre.lagsub()", "path": "reference/generated/numpy.polynomial.laguerre.lagsub", "type": "numpy.polynomial.laguerre.lagsub", "text": "\nSubtract one Laguerre series from another.\n\nReturns the difference of two Laguerre series `c1` \\- `c2`. The sequences of\ncoefficients are from lowest order term to highest, i.e., [1,2,3] represents\nthe series `P_0 + 2*P_1 + 3*P_2`.\n\n1-D arrays of Laguerre series coefficients ordered from low to high.\n\nOf Laguerre series coefficients representing their difference.\n\nSee also\n\nUnlike multiplication, division, etc., the difference of two Laguerre series\nis a Laguerre series (without having to \u201creproject\u201d the result onto the basis\nset) so subtraction, just like that of \u201cstandard\u201d polynomials, is simply\n\u201ccomponent-wise.\u201d\n\n"}, {"name": "polynomial.laguerre.lagtrim()", "path": "reference/generated/numpy.polynomial.laguerre.lagtrim", "type": "numpy.polynomial.laguerre.lagtrim", "text": "\nRemove \u201csmall\u201d \u201ctrailing\u201d coefficients from a polynomial.\n\n\u201cSmall\u201d means \u201csmall in absolute value\u201d and is controlled by the parameter\n`tol`; \u201ctrailing\u201d means highest order coefficient(s), e.g., in `[0, 1, 1, 0,\n0]` (which represents `0 + x + x**2 + 0*x**3 + 0*x**4`) both the 3-rd and 4-th\norder coefficients would be \u201ctrimmed.\u201d\n\n1-d array of coefficients, ordered from lowest order to highest.\n\nTrailing (i.e., highest order) elements with absolute value less than or equal\nto `tol` (default value is zero) are removed.\n\n1-d array with trailing zeros removed. If the resulting series would be empty,\na series containing a single zero is returned.\n\nIf `tol` < 0\n\nSee also\n\n"}, {"name": "polynomial.laguerre.Laguerre.__call__()", "path": "reference/generated/numpy.polynomial.laguerre.laguerre.__call__", "type": "numpy.polynomial.laguerre.Laguerre", "text": "\nmethod\n\nCall self as a function.\n\n"}, {"name": "polynomial.laguerre.Laguerre.basis()", "path": "reference/generated/numpy.polynomial.laguerre.laguerre.basis", "type": "numpy.polynomial.laguerre.Laguerre", "text": "\nmethod\n\nSeries basis polynomial of degree `deg`.\n\nReturns the series representing the basis polynomial of degree `deg`.\n\nNew in version 1.7.0.\n\nDegree of the basis polynomial for the series. Must be >= 0.\n\nIf given, the array must be of the form `[beg, end]`, where `beg` and `end`\nare the endpoints of the domain. If None is given then the class domain is\nused. The default is None.\n\nIf given, the resulting array must be if the form `[beg, end]`, where `beg`\nand `end` are the endpoints of the window. If None is given then the class\nwindow is used. The default is None.\n\nA series with the coefficient of the `deg` term set to one and all others\nzero.\n\n"}, {"name": "polynomial.laguerre.Laguerre.cast()", "path": "reference/generated/numpy.polynomial.laguerre.laguerre.cast", "type": "numpy.polynomial.laguerre.Laguerre", "text": "\nmethod\n\nConvert series to series of this class.\n\nThe `series` is expected to be an instance of some polynomial series of one of\nthe types supported by by the numpy.polynomial module, but could be some other\nclass that supports the convert method.\n\nNew in version 1.7.0.\n\nThe series instance to be converted.\n\nIf given, the array must be of the form `[beg, end]`, where `beg` and `end`\nare the endpoints of the domain. If None is given then the class domain is\nused. The default is None.\n\nIf given, the resulting array must be if the form `[beg, end]`, where `beg`\nand `end` are the endpoints of the window. If None is given then the class\nwindow is used. The default is None.\n\nA series of the same kind as the calling class and equal to `series` when\nevaluated.\n\nSee also\n\nsimilar instance method\n\n"}, {"name": "polynomial.laguerre.Laguerre.convert()", "path": "reference/generated/numpy.polynomial.laguerre.laguerre.convert", "type": "numpy.polynomial.laguerre.Laguerre", "text": "\nmethod\n\nConvert series to a different kind and/or domain and/or window.\n\nThe domain of the converted series. If the value is None, the default domain\nof `kind` is used.\n\nThe polynomial series type class to which the current instance should be\nconverted. If kind is None, then the class of the current instance is used.\n\nThe window of the converted series. If the value is None, the default window\nof `kind` is used.\n\nThe returned class can be of different type than the current instance and/or\nhave a different domain and/or different window.\n\nConversion between domains and class types can result in numerically ill\ndefined series.\n\n"}, {"name": "polynomial.laguerre.Laguerre.copy()", "path": "reference/generated/numpy.polynomial.laguerre.laguerre.copy", "type": "numpy.polynomial.laguerre.Laguerre", "text": "\nmethod\n\nReturn a copy.\n\nCopy of self.\n\n"}, {"name": "polynomial.laguerre.Laguerre.cutdeg()", "path": "reference/generated/numpy.polynomial.laguerre.laguerre.cutdeg", "type": "numpy.polynomial.laguerre.Laguerre", "text": "\nmethod\n\nTruncate series to the given degree.\n\nReduce the degree of the series to `deg` by discarding the high order terms.\nIf `deg` is greater than the current degree a copy of the current series is\nreturned. This can be useful in least squares where the coefficients of the\nhigh degree terms may be very small.\n\nNew in version 1.5.0.\n\nThe series is reduced to degree `deg` by discarding the high order terms. The\nvalue of `deg` must be a non-negative integer.\n\nNew instance of series with reduced degree.\n\n"}, {"name": "polynomial.laguerre.Laguerre.degree()", "path": "reference/generated/numpy.polynomial.laguerre.laguerre.degree", "type": "numpy.polynomial.laguerre.Laguerre", "text": "\nmethod\n\nThe degree of the series.\n\nNew in version 1.5.0.\n\nDegree of the series, one less than the number of coefficients.\n\n"}, {"name": "polynomial.laguerre.Laguerre.deriv()", "path": "reference/generated/numpy.polynomial.laguerre.laguerre.deriv", "type": "numpy.polynomial.laguerre.Laguerre", "text": "\nmethod\n\nDifferentiate.\n\nReturn a series instance of that is the derivative of the current series.\n\nFind the derivative of order `m`.\n\nA new series representing the derivative. The domain is the same as the domain\nof the differentiated series.\n\n"}, {"name": "polynomial.laguerre.Laguerre.domain", "path": "reference/generated/numpy.polynomial.laguerre.laguerre.domain", "type": "Polynomials", "text": "\nattribute\n\n"}, {"name": "polynomial.laguerre.Laguerre.fit()", "path": "reference/generated/numpy.polynomial.laguerre.laguerre.fit", "type": "numpy.polynomial.laguerre.Laguerre", "text": "\nmethod\n\nLeast squares fit to data.\n\nReturn a series instance that is the least squares fit to the data `y` sampled\nat `x`. The domain of the returned instance can be specified and this will\noften result in a superior fit with less chance of ill conditioning.\n\nx-coordinates of the M sample points `(x[i], y[i])`.\n\ny-coordinates of the M sample points `(x[i], y[i])`.\n\nDegree(s) of the fitting polynomials. If `deg` is a single integer all terms\nup to and including the `deg`\u2019th term are included in the fit. For NumPy\nversions >= 1.11.0 a list of integers specifying the degrees of the terms to\ninclude may be used instead.\n\nDomain to use for the returned series. If `None`, then a minimal domain that\ncovers the points `x` is chosen. If `[]` the class domain is used. The default\nvalue was the class domain in NumPy 1.4 and `None` in later versions. The `[]`\noption was added in numpy 1.5.0.\n\nRelative condition number of the fit. Singular values smaller than this\nrelative to the largest singular value will be ignored. The default value is\nlen(x)*eps, where eps is the relative precision of the float type, about 2e-16\nin most cases.\n\nSwitch determining nature of return value. When it is False (the default) just\nthe coefficients are returned, when True diagnostic information from the\nsingular value decomposition is also returned.\n\nWeights. If not None, the weight `w[i]` applies to the unsquared residual\n`y[i] - y_hat[i]` at `x[i]`. Ideally the weights are chosen so that the errors\nof the products `w[i]*y[i]` all have the same variance. When using inverse-\nvariance weighting, use `w[i] = 1/sigma(y[i])`. The default value is None.\n\nNew in version 1.5.0.\n\nWindow to use for the returned series. The default value is the default class\ndomain\n\nNew in version 1.6.0.\n\nA series that represents the least squares fit to the data and has the domain\nand window specified in the call. If the coefficients for the unscaled and\nunshifted basis polynomials are of interest, do `new_series.convert().coef`.\n\nThese values are only returned if `full == True`\n\nFor more details, see `linalg.lstsq`.\n\n"}, {"name": "polynomial.laguerre.Laguerre.fromroots()", "path": "reference/generated/numpy.polynomial.laguerre.laguerre.fromroots", "type": "numpy.polynomial.laguerre.Laguerre", "text": "\nmethod\n\nReturn series instance that has the specified roots.\n\nReturns a series representing the product `(x - r[0])*(x - r[1])*...*(x -\nr[n-1])`, where `r` is a list of roots.\n\nList of roots.\n\nDomain for the resulting series. If None the domain is the interval from the\nsmallest root to the largest. If [] the domain is the class domain. The\ndefault is [].\n\nWindow for the returned series. If None the class window is used. The default\nis None.\n\nSeries with the specified roots.\n\n"}, {"name": "polynomial.laguerre.Laguerre.has_samecoef()", "path": "reference/generated/numpy.polynomial.laguerre.laguerre.has_samecoef", "type": "numpy.polynomial.laguerre.Laguerre", "text": "\nmethod\n\nCheck if coefficients match.\n\nNew in version 1.6.0.\n\nThe other class must have the `coef` attribute.\n\nTrue if the coefficients are the same, False otherwise.\n\n"}, {"name": "polynomial.laguerre.Laguerre.has_samedomain()", "path": "reference/generated/numpy.polynomial.laguerre.laguerre.has_samedomain", "type": "numpy.polynomial.laguerre.Laguerre", "text": "\nmethod\n\nCheck if domains match.\n\nNew in version 1.6.0.\n\nThe other class must have the `domain` attribute.\n\nTrue if the domains are the same, False otherwise.\n\n"}, {"name": "polynomial.laguerre.Laguerre.has_sametype()", "path": "reference/generated/numpy.polynomial.laguerre.laguerre.has_sametype", "type": "numpy.polynomial.laguerre.Laguerre", "text": "\nmethod\n\nCheck if types match.\n\nNew in version 1.7.0.\n\nClass instance.\n\nTrue if other is same class as self\n\n"}, {"name": "polynomial.laguerre.Laguerre.has_samewindow()", "path": "reference/generated/numpy.polynomial.laguerre.laguerre.has_samewindow", "type": "numpy.polynomial.laguerre.Laguerre", "text": "\nmethod\n\nCheck if windows match.\n\nNew in version 1.6.0.\n\nThe other class must have the `window` attribute.\n\nTrue if the windows are the same, False otherwise.\n\n"}, {"name": "polynomial.laguerre.Laguerre.identity()", "path": "reference/generated/numpy.polynomial.laguerre.laguerre.identity", "type": "numpy.polynomial.laguerre.Laguerre", "text": "\nmethod\n\nIdentity function.\n\nIf `p` is the returned series, then `p(x) == x` for all values of x.\n\nIf given, the array must be of the form `[beg, end]`, where `beg` and `end`\nare the endpoints of the domain. If None is given then the class domain is\nused. The default is None.\n\nIf given, the resulting array must be if the form `[beg, end]`, where `beg`\nand `end` are the endpoints of the window. If None is given then the class\nwindow is used. The default is None.\n\nSeries of representing the identity.\n\n"}, {"name": "polynomial.laguerre.Laguerre.integ()", "path": "reference/generated/numpy.polynomial.laguerre.laguerre.integ", "type": "numpy.polynomial.laguerre.Laguerre", "text": "\nmethod\n\nIntegrate.\n\nReturn a series instance that is the definite integral of the current series.\n\nThe number of integrations to perform.\n\nIntegration constants. The first constant is applied to the first integration,\nthe second to the second, and so on. The list of values must less than or\nequal to `m` in length and any missing values are set to zero.\n\nThe lower bound of the definite integral.\n\nA new series representing the integral. The domain is the same as the domain\nof the integrated series.\n\n"}, {"name": "polynomial.laguerre.Laguerre.linspace()", "path": "reference/generated/numpy.polynomial.laguerre.laguerre.linspace", "type": "numpy.polynomial.laguerre.Laguerre", "text": "\nmethod\n\nReturn x, y values at equally spaced points in domain.\n\nReturns the x, y values at `n` linearly spaced points across the domain. Here\ny is the value of the polynomial at the points x. By default the domain is the\nsame as that of the series instance. This method is intended mostly as a\nplotting aid.\n\nNew in version 1.5.0.\n\nNumber of point pairs to return. The default value is 100.\n\nIf not None, the specified domain is used instead of that of the calling\ninstance. It should be of the form `[beg,end]`. The default is None which case\nthe class domain is used.\n\nx is equal to linspace(self.domain[0], self.domain[1], n) and y is the series\nevaluated at element of x.\n\n"}, {"name": "polynomial.laguerre.Laguerre.mapparms()", "path": "reference/generated/numpy.polynomial.laguerre.laguerre.mapparms", "type": "numpy.polynomial.laguerre.Laguerre", "text": "\nmethod\n\nReturn the mapping parameters.\n\nThe returned values define a linear map `off + scl*x` that is applied to the\ninput arguments before the series is evaluated. The map depends on the\n`domain` and `window`; if the current `domain` is equal to the `window` the\nresulting map is the identity. If the coefficients of the series instance are\nto be used by themselves outside this class, then the linear function must be\nsubstituted for the `x` in the standard representation of the base\npolynomials.\n\nThe mapping function is defined by `off + scl*x`.\n\nIf the current domain is the interval `[l1, r1]` and the window is `[l2, r2]`,\nthen the linear mapping function `L` is defined by the equations:\n\n"}, {"name": "polynomial.laguerre.Laguerre.roots()", "path": "reference/generated/numpy.polynomial.laguerre.laguerre.roots", "type": "numpy.polynomial.laguerre.Laguerre", "text": "\nmethod\n\nReturn the roots of the series polynomial.\n\nCompute the roots for the series. Note that the accuracy of the roots decrease\nthe further outside the domain they lie.\n\nArray containing the roots of the series.\n\n"}, {"name": "polynomial.laguerre.Laguerre.trim()", "path": "reference/generated/numpy.polynomial.laguerre.laguerre.trim", "type": "numpy.polynomial.laguerre.Laguerre", "text": "\nmethod\n\nRemove trailing coefficients\n\nRemove trailing coefficients until a coefficient is reached whose absolute\nvalue greater than `tol` or the beginning of the series is reached. If all the\ncoefficients would be removed the series is set to `[0]`. A new series\ninstance is returned with the new coefficients. The current instance remains\nunchanged.\n\nAll trailing coefficients less than `tol` will be removed.\n\nNew instance of series with trimmed coefficients.\n\n"}, {"name": "polynomial.laguerre.Laguerre.truncate()", "path": "reference/generated/numpy.polynomial.laguerre.laguerre.truncate", "type": "numpy.polynomial.laguerre.Laguerre", "text": "\nmethod\n\nTruncate series to length `size`.\n\nReduce the series to length `size` by discarding the high degree terms. The\nvalue of `size` must be a positive integer. This can be useful in least\nsquares where the coefficients of the high degree terms may be very small.\n\nThe series is reduced to length `size` by discarding the high degree terms.\nThe value of `size` must be a positive integer.\n\nNew instance of series with truncated coefficients.\n\n"}, {"name": "polynomial.laguerre.lagval()", "path": "reference/generated/numpy.polynomial.laguerre.lagval", "type": "numpy.polynomial.laguerre.lagval", "text": "\nEvaluate a Laguerre series at points x.\n\nIf `c` is of length `n + 1`, this function returns the value:\n\nThe parameter `x` is converted to an array only if it is a tuple or a list,\notherwise it is treated as a scalar. In either case, either `x` or its\nelements must support multiplication and addition both with themselves and\nwith the elements of `c`.\n\nIf `c` is a 1-D array, then `p(x)` will have the same shape as `x`. If `c` is\nmultidimensional, then the shape of the result depends on the value of\n`tensor`. If `tensor` is true the shape will be c.shape[1:] + x.shape. If\n`tensor` is false the shape will be c.shape[1:]. Note that scalars have shape\n(,).\n\nTrailing zeros in the coefficients will be used in the evaluation, so they\nshould be avoided if efficiency is a concern.\n\nIf `x` is a list or tuple, it is converted to an ndarray, otherwise it is left\nunchanged and treated as a scalar. In either case, `x` or its elements must\nsupport addition and multiplication with with themselves and with the elements\nof `c`.\n\nArray of coefficients ordered so that the coefficients for terms of degree n\nare contained in c[n]. If `c` is multidimensional the remaining indices\nenumerate multiple polynomials. In the two dimensional case the coefficients\nmay be thought of as stored in the columns of `c`.\n\nIf True, the shape of the coefficient array is extended with ones on the\nright, one for each dimension of `x`. Scalars have dimension 0 for this\naction. The result is that every column of coefficients in `c` is evaluated\nfor every element of `x`. If False, `x` is broadcast over the columns of `c`\nfor the evaluation. This keyword is useful when `c` is multidimensional. The\ndefault value is True.\n\nNew in version 1.7.0.\n\nThe shape of the return value is described above.\n\nSee also\n\nThe evaluation uses Clenshaw recursion, aka synthetic division.\n\n"}, {"name": "polynomial.laguerre.lagval2d()", "path": "reference/generated/numpy.polynomial.laguerre.lagval2d", "type": "numpy.polynomial.laguerre.lagval2d", "text": "\nEvaluate a 2-D Laguerre series at points (x, y).\n\nThis function returns the values:\n\nThe parameters `x` and `y` are converted to arrays only if they are tuples or\na lists, otherwise they are treated as a scalars and they must have the same\nshape after conversion. In either case, either `x` and `y` or their elements\nmust support multiplication and addition both with themselves and with the\nelements of `c`.\n\nIf `c` is a 1-D array a one is implicitly appended to its shape to make it\n2-D. The shape of the result will be c.shape[2:] + x.shape.\n\nThe two dimensional series is evaluated at the points `(x, y)`, where `x` and\n`y` must have the same shape. If `x` or `y` is a list or tuple, it is first\nconverted to an ndarray, otherwise it is left unchanged and if it isn\u2019t an\nndarray it is treated as a scalar.\n\nArray of coefficients ordered so that the coefficient of the term of multi-\ndegree i,j is contained in `c[i,j]`. If `c` has dimension greater than two the\nremaining indices enumerate multiple sets of coefficients.\n\nThe values of the two dimensional polynomial at points formed with pairs of\ncorresponding values from `x` and `y`.\n\nSee also\n\nNew in version 1.7.0.\n\n"}, {"name": "polynomial.laguerre.lagval3d()", "path": "reference/generated/numpy.polynomial.laguerre.lagval3d", "type": "numpy.polynomial.laguerre.lagval3d", "text": "\nEvaluate a 3-D Laguerre series at points (x, y, z).\n\nThis function returns the values:\n\nThe parameters `x`, `y`, and `z` are converted to arrays only if they are\ntuples or a lists, otherwise they are treated as a scalars and they must have\nthe same shape after conversion. In either case, either `x`, `y`, and `z` or\ntheir elements must support multiplication and addition both with themselves\nand with the elements of `c`.\n\nIf `c` has fewer than 3 dimensions, ones are implicitly appended to its shape\nto make it 3-D. The shape of the result will be c.shape[3:] + x.shape.\n\nThe three dimensional series is evaluated at the points `(x, y, z)`, where\n`x`, `y`, and `z` must have the same shape. If any of `x`, `y`, or `z` is a\nlist or tuple, it is first converted to an ndarray, otherwise it is left\nunchanged and if it isn\u2019t an ndarray it is treated as a scalar.\n\nArray of coefficients ordered so that the coefficient of the term of multi-\ndegree i,j,k is contained in `c[i,j,k]`. If `c` has dimension greater than 3\nthe remaining indices enumerate multiple sets of coefficients.\n\nThe values of the multidimensional polynomial on points formed with triples of\ncorresponding values from `x`, `y`, and `z`.\n\nSee also\n\nNew in version 1.7.0.\n\n"}, {"name": "polynomial.laguerre.lagvander()", "path": "reference/generated/numpy.polynomial.laguerre.lagvander", "type": "numpy.polynomial.laguerre.lagvander", "text": "\nPseudo-Vandermonde matrix of given degree.\n\nReturns the pseudo-Vandermonde matrix of degree `deg` and sample points `x`.\nThe pseudo-Vandermonde matrix is defined by\n\nwhere `0 <= i <= deg`. The leading indices of `V` index the elements of `x`\nand the last index is the degree of the Laguerre polynomial.\n\nIf `c` is a 1-D array of coefficients of length `n + 1` and `V` is the array\n`V = lagvander(x, n)`, then `np.dot(V, c)` and `lagval(x, c)` are the same up\nto roundoff. This equivalence is useful both for least squares fitting and for\nthe evaluation of a large number of Laguerre series of the same degree and\nsample points.\n\nArray of points. The dtype is converted to float64 or complex128 depending on\nwhether any of the elements are complex. If `x` is scalar it is converted to a\n1-D array.\n\nDegree of the resulting matrix.\n\nThe pseudo-Vandermonde matrix. The shape of the returned matrix is `x.shape +\n(deg + 1,)`, where The last index is the degree of the corresponding Laguerre\npolynomial. The dtype will be the same as the converted `x`.\n\n"}, {"name": "polynomial.laguerre.lagvander2d()", "path": "reference/generated/numpy.polynomial.laguerre.lagvander2d", "type": "numpy.polynomial.laguerre.lagvander2d", "text": "\nPseudo-Vandermonde matrix of given degrees.\n\nReturns the pseudo-Vandermonde matrix of degrees `deg` and sample points `(x,\ny)`. The pseudo-Vandermonde matrix is defined by\n\nwhere `0 <= i <= deg[0]` and `0 <= j <= deg[1]`. The leading indices of `V`\nindex the points `(x, y)` and the last index encodes the degrees of the\nLaguerre polynomials.\n\nIf `V = lagvander2d(x, y, [xdeg, ydeg])`, then the columns of `V` correspond\nto the elements of a 2-D coefficient array `c` of shape (xdeg + 1, ydeg + 1)\nin the order\n\nand `np.dot(V, c.flat)` and `lagval2d(x, y, c)` will be the same up to\nroundoff. This equivalence is useful both for least squares fitting and for\nthe evaluation of a large number of 2-D Laguerre series of the same degrees\nand sample points.\n\nArrays of point coordinates, all of the same shape. The dtypes will be\nconverted to either float64 or complex128 depending on whether any of the\nelements are complex. Scalars are converted to 1-D arrays.\n\nList of maximum degrees of the form [x_deg, y_deg].\n\nThe shape of the returned matrix is `x.shape + (order,)`, where \\\\(order =\n(deg[0]+1)*(deg[1]+1)\\\\). The dtype will be the same as the converted `x` and\n`y`.\n\nSee also\n\nNew in version 1.7.0.\n\n"}, {"name": "polynomial.laguerre.lagvander3d()", "path": "reference/generated/numpy.polynomial.laguerre.lagvander3d", "type": "numpy.polynomial.laguerre.lagvander3d", "text": "\nPseudo-Vandermonde matrix of given degrees.\n\nReturns the pseudo-Vandermonde matrix of degrees `deg` and sample points `(x,\ny, z)`. If `l, m, n` are the given degrees in `x, y, z`, then The pseudo-\nVandermonde matrix is defined by\n\nwhere `0 <= i <= l`, `0 <= j <= m`, and `0 <= j <= n`. The leading indices of\n`V` index the points `(x, y, z)` and the last index encodes the degrees of the\nLaguerre polynomials.\n\nIf `V = lagvander3d(x, y, z, [xdeg, ydeg, zdeg])`, then the columns of `V`\ncorrespond to the elements of a 3-D coefficient array `c` of shape (xdeg + 1,\nydeg + 1, zdeg + 1) in the order\n\nand `np.dot(V, c.flat)` and `lagval3d(x, y, z, c)` will be the same up to\nroundoff. This equivalence is useful both for least squares fitting and for\nthe evaluation of a large number of 3-D Laguerre series of the same degrees\nand sample points.\n\nArrays of point coordinates, all of the same shape. The dtypes will be\nconverted to either float64 or complex128 depending on whether any of the\nelements are complex. Scalars are converted to 1-D arrays.\n\nList of maximum degrees of the form [x_deg, y_deg, z_deg].\n\nThe shape of the returned matrix is `x.shape + (order,)`, where \\\\(order =\n(deg[0]+1)*(deg[1]+1)*(deg[2]+1)\\\\). The dtype will be the same as the\nconverted `x`, `y`, and `z`.\n\nSee also\n\nNew in version 1.7.0.\n\n"}, {"name": "polynomial.laguerre.lagweight()", "path": "reference/generated/numpy.polynomial.laguerre.lagweight", "type": "numpy.polynomial.laguerre.lagweight", "text": "\nWeight function of the Laguerre polynomials.\n\nThe weight function is \\\\(exp(-x)\\\\) and the interval of integration is \\\\([0,\n\\inf]\\\\). The Laguerre polynomials are orthogonal, but not normalized, with\nrespect to this weight function.\n\nValues at which the weight function will be computed.\n\nThe weight function at `x`.\n\nNew in version 1.7.0.\n\n"}, {"name": "polynomial.laguerre.lagx", "path": "reference/generated/numpy.polynomial.laguerre.lagx", "type": "numpy.polynomial.laguerre.lagx", "text": "\nAn array object represents a multidimensional, homogeneous array of fixed-size\nitems. An associated data-type object describes the format of each element in\nthe array (its byte-order, how many bytes it occupies in memory, whether it is\nan integer, a floating point number, or something else, etc.)\n\nArrays should be constructed using `array`, `zeros` or `empty` (refer to the\nSee Also section below). The parameters given here refer to a low-level method\n(`ndarray(\u2026)`) for instantiating an array.\n\nFor more information, refer to the `numpy` module and examine the methods and\nattributes of an array.\n\nShape of created array.\n\nAny object that can be interpreted as a numpy data type.\n\nUsed to fill the array with data.\n\nOffset of array data in buffer.\n\nStrides of data in memory.\n\nRow-major (C-style) or column-major (Fortran-style) order.\n\nSee also\n\nConstruct an array.\n\nCreate an array, each element of which is zero.\n\nCreate an array, but leave its allocated memory unchanged (i.e., it contains\n\u201cgarbage\u201d).\n\nCreate a data-type.\n\nAn ndarray alias generic w.r.t. its `dtype.type`.\n\nThere are two modes of creating an array using `__new__`:\n\nNo `__init__` method is needed because the array is fully initialized after\nthe `__new__` method.\n\nThese examples illustrate the low-level `ndarray` constructor. Refer to the\n`See Also` section above for easier ways of constructing an ndarray.\n\nFirst mode, `buffer` is None:\n\nSecond mode:\n\nTranspose of the array.\n\nThe array\u2019s elements, in memory.\n\nDescribes the format of the elements in the array.\n\nDictionary containing information related to memory use, e.g., \u2018C_CONTIGUOUS\u2019,\n\u2018OWNDATA\u2019, \u2018WRITEABLE\u2019, etc.\n\nFlattened version of the array as an iterator. The iterator allows\nassignments, e.g., `x.flat = 3` (See `ndarray.flat` for assignment examples;\nTODO).\n\nImaginary part of the array.\n\nReal part of the array.\n\nNumber of elements in the array.\n\nThe memory use of each array element in bytes.\n\nThe total number of bytes required to store the array data, i.e., `itemsize *\nsize`.\n\nThe array\u2019s number of dimensions.\n\nShape of the array.\n\nThe step-size required to move from one element to the next in memory. For\nexample, a contiguous `(3, 4)` array of type `int16` in C-order has strides\n`(8, 2)`. This implies that to move from element to element in memory requires\njumps of 2 bytes. To move from row-to-row, one needs to jump 8 bytes at a time\n(`2 * 4`).\n\nClass containing properties of the array needed for interaction with ctypes.\n\nIf the array is a view into another array, that array is its `base` (unless\nthat array is also a view). The `base` array is where the array data is\nactually stored.\n\n"}, {"name": "polynomial.laguerre.lagzero", "path": "reference/generated/numpy.polynomial.laguerre.lagzero", "type": "numpy.polynomial.laguerre.lagzero", "text": "\nAn array object represents a multidimensional, homogeneous array of fixed-size\nitems. An associated data-type object describes the format of each element in\nthe array (its byte-order, how many bytes it occupies in memory, whether it is\nan integer, a floating point number, or something else, etc.)\n\nArrays should be constructed using `array`, `zeros` or `empty` (refer to the\nSee Also section below). The parameters given here refer to a low-level method\n(`ndarray(\u2026)`) for instantiating an array.\n\nFor more information, refer to the `numpy` module and examine the methods and\nattributes of an array.\n\nShape of created array.\n\nAny object that can be interpreted as a numpy data type.\n\nUsed to fill the array with data.\n\nOffset of array data in buffer.\n\nStrides of data in memory.\n\nRow-major (C-style) or column-major (Fortran-style) order.\n\nSee also\n\nConstruct an array.\n\nCreate an array, each element of which is zero.\n\nCreate an array, but leave its allocated memory unchanged (i.e., it contains\n\u201cgarbage\u201d).\n\nCreate a data-type.\n\nAn ndarray alias generic w.r.t. its `dtype.type`.\n\nThere are two modes of creating an array using `__new__`:\n\nNo `__init__` method is needed because the array is fully initialized after\nthe `__new__` method.\n\nThese examples illustrate the low-level `ndarray` constructor. Refer to the\n`See Also` section above for easier ways of constructing an ndarray.\n\nFirst mode, `buffer` is None:\n\nSecond mode:\n\nTranspose of the array.\n\nThe array\u2019s elements, in memory.\n\nDescribes the format of the elements in the array.\n\nDictionary containing information related to memory use, e.g., \u2018C_CONTIGUOUS\u2019,\n\u2018OWNDATA\u2019, \u2018WRITEABLE\u2019, etc.\n\nFlattened version of the array as an iterator. The iterator allows\nassignments, e.g., `x.flat = 3` (See `ndarray.flat` for assignment examples;\nTODO).\n\nImaginary part of the array.\n\nReal part of the array.\n\nNumber of elements in the array.\n\nThe memory use of each array element in bytes.\n\nThe total number of bytes required to store the array data, i.e., `itemsize *\nsize`.\n\nThe array\u2019s number of dimensions.\n\nShape of the array.\n\nThe step-size required to move from one element to the next in memory. For\nexample, a contiguous `(3, 4)` array of type `int16` in C-order has strides\n`(8, 2)`. This implies that to move from element to element in memory requires\njumps of 2 bytes. To move from row-to-row, one needs to jump 8 bytes at a time\n(`2 * 4`).\n\nClass containing properties of the array needed for interaction with ctypes.\n\nIf the array is a view into another array, that array is its `base` (unless\nthat array is also a view). The `base` array is where the array data is\nactually stored.\n\n"}, {"name": "polynomial.laguerre.poly2lag()", "path": "reference/generated/numpy.polynomial.laguerre.poly2lag", "type": "numpy.polynomial.laguerre.poly2lag", "text": "\nConvert a polynomial to a Laguerre series.\n\nConvert an array representing the coefficients of a polynomial (relative to\nthe \u201cstandard\u201d basis) ordered from lowest degree to highest, to an array of\nthe coefficients of the equivalent Laguerre series, ordered from lowest to\nhighest degree.\n\n1-D array containing the polynomial coefficients\n\n1-D array containing the coefficients of the equivalent Laguerre series.\n\nSee also\n\nThe easy way to do conversions between polynomial basis sets is to use the\nconvert method of a class instance.\n\n"}, {"name": "polynomial.legendre.leg2poly()", "path": "reference/generated/numpy.polynomial.legendre.leg2poly", "type": "numpy.polynomial.legendre.leg2poly", "text": "\nConvert a Legendre series to a polynomial.\n\nConvert an array representing the coefficients of a Legendre series, ordered\nfrom lowest degree to highest, to an array of the coefficients of the\nequivalent polynomial (relative to the \u201cstandard\u201d basis) ordered from lowest\nto highest degree.\n\n1-D array containing the Legendre series coefficients, ordered from lowest\norder term to highest.\n\n1-D array containing the coefficients of the equivalent polynomial (relative\nto the \u201cstandard\u201d basis) ordered from lowest order term to highest.\n\nSee also\n\nThe easy way to do conversions between polynomial basis sets is to use the\nconvert method of a class instance.\n\n"}, {"name": "polynomial.legendre.legadd()", "path": "reference/generated/numpy.polynomial.legendre.legadd", "type": "numpy.polynomial.legendre.legadd", "text": "\nAdd one Legendre series to another.\n\nReturns the sum of two Legendre series `c1` \\+ `c2`. The arguments are\nsequences of coefficients ordered from lowest order term to highest, i.e.,\n[1,2,3] represents the series `P_0 + 2*P_1 + 3*P_2`.\n\n1-D arrays of Legendre series coefficients ordered from low to high.\n\nArray representing the Legendre series of their sum.\n\nSee also\n\nUnlike multiplication, division, etc., the sum of two Legendre series is a\nLegendre series (without having to \u201creproject\u201d the result onto the basis set)\nso addition, just like that of \u201cstandard\u201d polynomials, is simply \u201ccomponent-\nwise.\u201d\n\n"}, {"name": "polynomial.legendre.legcompanion()", "path": "reference/generated/numpy.polynomial.legendre.legcompanion", "type": "numpy.polynomial.legendre.legcompanion", "text": "\nReturn the scaled companion matrix of c.\n\nThe basis polynomials are scaled so that the companion matrix is symmetric\nwhen `c` is an Legendre basis polynomial. This provides better eigenvalue\nestimates than the unscaled case and for basis polynomials the eigenvalues are\nguaranteed to be real if `numpy.linalg.eigvalsh` is used to obtain them.\n\n1-D array of Legendre series coefficients ordered from low to high degree.\n\nScaled companion matrix of dimensions (deg, deg).\n\nNew in version 1.7.0.\n\n"}, {"name": "polynomial.legendre.legder()", "path": "reference/generated/numpy.polynomial.legendre.legder", "type": "numpy.polynomial.legendre.legder", "text": "\nDifferentiate a Legendre series.\n\nReturns the Legendre series coefficients `c` differentiated `m` times along\n`axis`. At each iteration the result is multiplied by `scl` (the scaling\nfactor is for use in a linear change of variable). The argument `c` is an\narray of coefficients from low to high degree along each axis, e.g., [1,2,3]\nrepresents the series `1*L_0 + 2*L_1 + 3*L_2` while [[1,2],[1,2]] represents\n`1*L_0(x)*L_0(y) + 1*L_1(x)*L_0(y) + 2*L_0(x)*L_1(y) + 2*L_1(x)*L_1(y)` if\naxis=0 is `x` and axis=1 is `y`.\n\nArray of Legendre series coefficients. If c is multidimensional the different\naxis correspond to different variables with the degree in each axis given by\nthe corresponding index.\n\nNumber of derivatives taken, must be non-negative. (Default: 1)\n\nEach differentiation is multiplied by `scl`. The end result is multiplication\nby `scl**m`. This is for use in a linear change of variable. (Default: 1)\n\nAxis over which the derivative is taken. (Default: 0).\n\nNew in version 1.7.0.\n\nLegendre series of the derivative.\n\nSee also\n\nIn general, the result of differentiating a Legendre series does not resemble\nthe same operation on a power series. Thus the result of this function may be\n\u201cunintuitive,\u201d albeit correct; see Examples section below.\n\n"}, {"name": "polynomial.legendre.legdiv()", "path": "reference/generated/numpy.polynomial.legendre.legdiv", "type": "numpy.polynomial.legendre.legdiv", "text": "\nDivide one Legendre series by another.\n\nReturns the quotient-with-remainder of two Legendre series `c1` / `c2`. The\narguments are sequences of coefficients from lowest order \u201cterm\u201d to highest,\ne.g., [1,2,3] represents the series `P_0 + 2*P_1 + 3*P_2`.\n\n1-D arrays of Legendre series coefficients ordered from low to high.\n\nOf Legendre series coefficients representing the quotient and remainder.\n\nSee also\n\nIn general, the (polynomial) division of one Legendre series by another\nresults in quotient and remainder terms that are not in the Legendre\npolynomial basis set. Thus, to express these results as a Legendre series, it\nis necessary to \u201creproject\u201d the results onto the Legendre basis set, which may\nproduce \u201cunintuitive\u201d (but correct) results; see Examples section below.\n\n"}, {"name": "polynomial.legendre.legdomain", "path": "reference/generated/numpy.polynomial.legendre.legdomain", "type": "numpy.polynomial.legendre.legdomain", "text": "\nAn array object represents a multidimensional, homogeneous array of fixed-size\nitems. An associated data-type object describes the format of each element in\nthe array (its byte-order, how many bytes it occupies in memory, whether it is\nan integer, a floating point number, or something else, etc.)\n\nArrays should be constructed using `array`, `zeros` or `empty` (refer to the\nSee Also section below). The parameters given here refer to a low-level method\n(`ndarray(\u2026)`) for instantiating an array.\n\nFor more information, refer to the `numpy` module and examine the methods and\nattributes of an array.\n\nShape of created array.\n\nAny object that can be interpreted as a numpy data type.\n\nUsed to fill the array with data.\n\nOffset of array data in buffer.\n\nStrides of data in memory.\n\nRow-major (C-style) or column-major (Fortran-style) order.\n\nSee also\n\nConstruct an array.\n\nCreate an array, each element of which is zero.\n\nCreate an array, but leave its allocated memory unchanged (i.e., it contains\n\u201cgarbage\u201d).\n\nCreate a data-type.\n\nAn ndarray alias generic w.r.t. its `dtype.type`.\n\nThere are two modes of creating an array using `__new__`:\n\nNo `__init__` method is needed because the array is fully initialized after\nthe `__new__` method.\n\nThese examples illustrate the low-level `ndarray` constructor. Refer to the\n`See Also` section above for easier ways of constructing an ndarray.\n\nFirst mode, `buffer` is None:\n\nSecond mode:\n\nTranspose of the array.\n\nThe array\u2019s elements, in memory.\n\nDescribes the format of the elements in the array.\n\nDictionary containing information related to memory use, e.g., \u2018C_CONTIGUOUS\u2019,\n\u2018OWNDATA\u2019, \u2018WRITEABLE\u2019, etc.\n\nFlattened version of the array as an iterator. The iterator allows\nassignments, e.g., `x.flat = 3` (See `ndarray.flat` for assignment examples;\nTODO).\n\nImaginary part of the array.\n\nReal part of the array.\n\nNumber of elements in the array.\n\nThe memory use of each array element in bytes.\n\nThe total number of bytes required to store the array data, i.e., `itemsize *\nsize`.\n\nThe array\u2019s number of dimensions.\n\nShape of the array.\n\nThe step-size required to move from one element to the next in memory. For\nexample, a contiguous `(3, 4)` array of type `int16` in C-order has strides\n`(8, 2)`. This implies that to move from element to element in memory requires\njumps of 2 bytes. To move from row-to-row, one needs to jump 8 bytes at a time\n(`2 * 4`).\n\nClass containing properties of the array needed for interaction with ctypes.\n\nIf the array is a view into another array, that array is its `base` (unless\nthat array is also a view). The `base` array is where the array data is\nactually stored.\n\n"}, {"name": "polynomial.legendre.Legendre.__call__()", "path": "reference/generated/numpy.polynomial.legendre.legendre.__call__", "type": "numpy.polynomial.legendre.Legendre", "text": "\nmethod\n\nCall self as a function.\n\n"}, {"name": "polynomial.legendre.Legendre.basis()", "path": "reference/generated/numpy.polynomial.legendre.legendre.basis", "type": "numpy.polynomial.legendre.Legendre", "text": "\nmethod\n\nSeries basis polynomial of degree `deg`.\n\nReturns the series representing the basis polynomial of degree `deg`.\n\nNew in version 1.7.0.\n\nDegree of the basis polynomial for the series. Must be >= 0.\n\nIf given, the array must be of the form `[beg, end]`, where `beg` and `end`\nare the endpoints of the domain. If None is given then the class domain is\nused. The default is None.\n\nIf given, the resulting array must be if the form `[beg, end]`, where `beg`\nand `end` are the endpoints of the window. If None is given then the class\nwindow is used. The default is None.\n\nA series with the coefficient of the `deg` term set to one and all others\nzero.\n\n"}, {"name": "polynomial.legendre.Legendre.cast()", "path": "reference/generated/numpy.polynomial.legendre.legendre.cast", "type": "numpy.polynomial.legendre.Legendre", "text": "\nmethod\n\nConvert series to series of this class.\n\nThe `series` is expected to be an instance of some polynomial series of one of\nthe types supported by by the numpy.polynomial module, but could be some other\nclass that supports the convert method.\n\nNew in version 1.7.0.\n\nThe series instance to be converted.\n\nIf given, the array must be of the form `[beg, end]`, where `beg` and `end`\nare the endpoints of the domain. If None is given then the class domain is\nused. The default is None.\n\nIf given, the resulting array must be if the form `[beg, end]`, where `beg`\nand `end` are the endpoints of the window. If None is given then the class\nwindow is used. The default is None.\n\nA series of the same kind as the calling class and equal to `series` when\nevaluated.\n\nSee also\n\nsimilar instance method\n\n"}, {"name": "polynomial.legendre.Legendre.convert()", "path": "reference/generated/numpy.polynomial.legendre.legendre.convert", "type": "numpy.polynomial.legendre.Legendre", "text": "\nmethod\n\nConvert series to a different kind and/or domain and/or window.\n\nThe domain of the converted series. If the value is None, the default domain\nof `kind` is used.\n\nThe polynomial series type class to which the current instance should be\nconverted. If kind is None, then the class of the current instance is used.\n\nThe window of the converted series. If the value is None, the default window\nof `kind` is used.\n\nThe returned class can be of different type than the current instance and/or\nhave a different domain and/or different window.\n\nConversion between domains and class types can result in numerically ill\ndefined series.\n\n"}, {"name": "polynomial.legendre.Legendre.copy()", "path": "reference/generated/numpy.polynomial.legendre.legendre.copy", "type": "numpy.polynomial.legendre.Legendre", "text": "\nmethod\n\nReturn a copy.\n\nCopy of self.\n\n"}, {"name": "polynomial.legendre.Legendre.cutdeg()", "path": "reference/generated/numpy.polynomial.legendre.legendre.cutdeg", "type": "numpy.polynomial.legendre.Legendre", "text": "\nmethod\n\nTruncate series to the given degree.\n\nReduce the degree of the series to `deg` by discarding the high order terms.\nIf `deg` is greater than the current degree a copy of the current series is\nreturned. This can be useful in least squares where the coefficients of the\nhigh degree terms may be very small.\n\nNew in version 1.5.0.\n\nThe series is reduced to degree `deg` by discarding the high order terms. The\nvalue of `deg` must be a non-negative integer.\n\nNew instance of series with reduced degree.\n\n"}, {"name": "polynomial.legendre.Legendre.degree()", "path": "reference/generated/numpy.polynomial.legendre.legendre.degree", "type": "numpy.polynomial.legendre.Legendre", "text": "\nmethod\n\nThe degree of the series.\n\nNew in version 1.5.0.\n\nDegree of the series, one less than the number of coefficients.\n\n"}, {"name": "polynomial.legendre.Legendre.deriv()", "path": "reference/generated/numpy.polynomial.legendre.legendre.deriv", "type": "numpy.polynomial.legendre.Legendre", "text": "\nmethod\n\nDifferentiate.\n\nReturn a series instance of that is the derivative of the current series.\n\nFind the derivative of order `m`.\n\nA new series representing the derivative. The domain is the same as the domain\nof the differentiated series.\n\n"}, {"name": "polynomial.legendre.Legendre.domain", "path": "reference/generated/numpy.polynomial.legendre.legendre.domain", "type": "Polynomials", "text": "\nattribute\n\n"}, {"name": "polynomial.legendre.Legendre.fit()", "path": "reference/generated/numpy.polynomial.legendre.legendre.fit", "type": "numpy.polynomial.legendre.Legendre", "text": "\nmethod\n\nLeast squares fit to data.\n\nReturn a series instance that is the least squares fit to the data `y` sampled\nat `x`. The domain of the returned instance can be specified and this will\noften result in a superior fit with less chance of ill conditioning.\n\nx-coordinates of the M sample points `(x[i], y[i])`.\n\ny-coordinates of the M sample points `(x[i], y[i])`.\n\nDegree(s) of the fitting polynomials. If `deg` is a single integer all terms\nup to and including the `deg`\u2019th term are included in the fit. For NumPy\nversions >= 1.11.0 a list of integers specifying the degrees of the terms to\ninclude may be used instead.\n\nDomain to use for the returned series. If `None`, then a minimal domain that\ncovers the points `x` is chosen. If `[]` the class domain is used. The default\nvalue was the class domain in NumPy 1.4 and `None` in later versions. The `[]`\noption was added in numpy 1.5.0.\n\nRelative condition number of the fit. Singular values smaller than this\nrelative to the largest singular value will be ignored. The default value is\nlen(x)*eps, where eps is the relative precision of the float type, about 2e-16\nin most cases.\n\nSwitch determining nature of return value. When it is False (the default) just\nthe coefficients are returned, when True diagnostic information from the\nsingular value decomposition is also returned.\n\nWeights. If not None, the weight `w[i]` applies to the unsquared residual\n`y[i] - y_hat[i]` at `x[i]`. Ideally the weights are chosen so that the errors\nof the products `w[i]*y[i]` all have the same variance. When using inverse-\nvariance weighting, use `w[i] = 1/sigma(y[i])`. The default value is None.\n\nNew in version 1.5.0.\n\nWindow to use for the returned series. The default value is the default class\ndomain\n\nNew in version 1.6.0.\n\nA series that represents the least squares fit to the data and has the domain\nand window specified in the call. If the coefficients for the unscaled and\nunshifted basis polynomials are of interest, do `new_series.convert().coef`.\n\nThese values are only returned if `full == True`\n\nFor more details, see `linalg.lstsq`.\n\n"}, {"name": "polynomial.legendre.Legendre.fromroots()", "path": "reference/generated/numpy.polynomial.legendre.legendre.fromroots", "type": "numpy.polynomial.legendre.Legendre", "text": "\nmethod\n\nReturn series instance that has the specified roots.\n\nReturns a series representing the product `(x - r[0])*(x - r[1])*...*(x -\nr[n-1])`, where `r` is a list of roots.\n\nList of roots.\n\nDomain for the resulting series. If None the domain is the interval from the\nsmallest root to the largest. If [] the domain is the class domain. The\ndefault is [].\n\nWindow for the returned series. If None the class window is used. The default\nis None.\n\nSeries with the specified roots.\n\n"}, {"name": "polynomial.legendre.Legendre.has_samecoef()", "path": "reference/generated/numpy.polynomial.legendre.legendre.has_samecoef", "type": "numpy.polynomial.legendre.Legendre", "text": "\nmethod\n\nCheck if coefficients match.\n\nNew in version 1.6.0.\n\nThe other class must have the `coef` attribute.\n\nTrue if the coefficients are the same, False otherwise.\n\n"}, {"name": "polynomial.legendre.Legendre.has_samedomain()", "path": "reference/generated/numpy.polynomial.legendre.legendre.has_samedomain", "type": "numpy.polynomial.legendre.Legendre", "text": "\nmethod\n\nCheck if domains match.\n\nNew in version 1.6.0.\n\nThe other class must have the `domain` attribute.\n\nTrue if the domains are the same, False otherwise.\n\n"}, {"name": "polynomial.legendre.Legendre.has_sametype()", "path": "reference/generated/numpy.polynomial.legendre.legendre.has_sametype", "type": "numpy.polynomial.legendre.Legendre", "text": "\nmethod\n\nCheck if types match.\n\nNew in version 1.7.0.\n\nClass instance.\n\nTrue if other is same class as self\n\n"}, {"name": "polynomial.legendre.Legendre.has_samewindow()", "path": "reference/generated/numpy.polynomial.legendre.legendre.has_samewindow", "type": "numpy.polynomial.legendre.Legendre", "text": "\nmethod\n\nCheck if windows match.\n\nNew in version 1.6.0.\n\nThe other class must have the `window` attribute.\n\nTrue if the windows are the same, False otherwise.\n\n"}, {"name": "polynomial.legendre.Legendre.identity()", "path": "reference/generated/numpy.polynomial.legendre.legendre.identity", "type": "numpy.polynomial.legendre.Legendre", "text": "\nmethod\n\nIdentity function.\n\nIf `p` is the returned series, then `p(x) == x` for all values of x.\n\nIf given, the array must be of the form `[beg, end]`, where `beg` and `end`\nare the endpoints of the domain. If None is given then the class domain is\nused. The default is None.\n\nIf given, the resulting array must be if the form `[beg, end]`, where `beg`\nand `end` are the endpoints of the window. If None is given then the class\nwindow is used. The default is None.\n\nSeries of representing the identity.\n\n"}, {"name": "polynomial.legendre.Legendre.integ()", "path": "reference/generated/numpy.polynomial.legendre.legendre.integ", "type": "numpy.polynomial.legendre.Legendre", "text": "\nmethod\n\nIntegrate.\n\nReturn a series instance that is the definite integral of the current series.\n\nThe number of integrations to perform.\n\nIntegration constants. The first constant is applied to the first integration,\nthe second to the second, and so on. The list of values must less than or\nequal to `m` in length and any missing values are set to zero.\n\nThe lower bound of the definite integral.\n\nA new series representing the integral. The domain is the same as the domain\nof the integrated series.\n\n"}, {"name": "polynomial.legendre.Legendre.linspace()", "path": "reference/generated/numpy.polynomial.legendre.legendre.linspace", "type": "numpy.polynomial.legendre.Legendre", "text": "\nmethod\n\nReturn x, y values at equally spaced points in domain.\n\nReturns the x, y values at `n` linearly spaced points across the domain. Here\ny is the value of the polynomial at the points x. By default the domain is the\nsame as that of the series instance. This method is intended mostly as a\nplotting aid.\n\nNew in version 1.5.0.\n\nNumber of point pairs to return. The default value is 100.\n\nIf not None, the specified domain is used instead of that of the calling\ninstance. It should be of the form `[beg,end]`. The default is None which case\nthe class domain is used.\n\nx is equal to linspace(self.domain[0], self.domain[1], n) and y is the series\nevaluated at element of x.\n\n"}, {"name": "polynomial.legendre.Legendre.mapparms()", "path": "reference/generated/numpy.polynomial.legendre.legendre.mapparms", "type": "numpy.polynomial.legendre.Legendre", "text": "\nmethod\n\nReturn the mapping parameters.\n\nThe returned values define a linear map `off + scl*x` that is applied to the\ninput arguments before the series is evaluated. The map depends on the\n`domain` and `window`; if the current `domain` is equal to the `window` the\nresulting map is the identity. If the coefficients of the series instance are\nto be used by themselves outside this class, then the linear function must be\nsubstituted for the `x` in the standard representation of the base\npolynomials.\n\nThe mapping function is defined by `off + scl*x`.\n\nIf the current domain is the interval `[l1, r1]` and the window is `[l2, r2]`,\nthen the linear mapping function `L` is defined by the equations:\n\n"}, {"name": "polynomial.legendre.Legendre.roots()", "path": "reference/generated/numpy.polynomial.legendre.legendre.roots", "type": "numpy.polynomial.legendre.Legendre", "text": "\nmethod\n\nReturn the roots of the series polynomial.\n\nCompute the roots for the series. Note that the accuracy of the roots decrease\nthe further outside the domain they lie.\n\nArray containing the roots of the series.\n\n"}, {"name": "polynomial.legendre.Legendre.trim()", "path": "reference/generated/numpy.polynomial.legendre.legendre.trim", "type": "numpy.polynomial.legendre.Legendre", "text": "\nmethod\n\nRemove trailing coefficients\n\nRemove trailing coefficients until a coefficient is reached whose absolute\nvalue greater than `tol` or the beginning of the series is reached. If all the\ncoefficients would be removed the series is set to `[0]`. A new series\ninstance is returned with the new coefficients. The current instance remains\nunchanged.\n\nAll trailing coefficients less than `tol` will be removed.\n\nNew instance of series with trimmed coefficients.\n\n"}, {"name": "polynomial.legendre.Legendre.truncate()", "path": "reference/generated/numpy.polynomial.legendre.legendre.truncate", "type": "numpy.polynomial.legendre.Legendre", "text": "\nmethod\n\nTruncate series to length `size`.\n\nReduce the series to length `size` by discarding the high degree terms. The\nvalue of `size` must be a positive integer. This can be useful in least\nsquares where the coefficients of the high degree terms may be very small.\n\nThe series is reduced to length `size` by discarding the high degree terms.\nThe value of `size` must be a positive integer.\n\nNew instance of series with truncated coefficients.\n\n"}, {"name": "polynomial.legendre.legfit()", "path": "reference/generated/numpy.polynomial.legendre.legfit", "type": "numpy.polynomial.legendre.legfit", "text": "\nLeast squares fit of Legendre series to data.\n\nReturn the coefficients of a Legendre series of degree `deg` that is the least\nsquares fit to the data values `y` given at points `x`. If `y` is 1-D the\nreturned coefficients will also be 1-D. If `y` is 2-D multiple fits are done,\none for each column of `y`, and the resulting coefficients are stored in the\ncorresponding columns of a 2-D return. The fitted polynomial(s) are in the\nform\n\nwhere `n` is `deg`.\n\nx-coordinates of the M sample points `(x[i], y[i])`.\n\ny-coordinates of the sample points. Several data sets of sample points sharing\nthe same x-coordinates can be fitted at once by passing in a 2D-array that\ncontains one dataset per column.\n\nDegree(s) of the fitting polynomials. If `deg` is a single integer all terms\nup to and including the `deg`\u2019th term are included in the fit. For NumPy\nversions >= 1.11.0 a list of integers specifying the degrees of the terms to\ninclude may be used instead.\n\nRelative condition number of the fit. Singular values smaller than this\nrelative to the largest singular value will be ignored. The default value is\nlen(x)*eps, where eps is the relative precision of the float type, about 2e-16\nin most cases.\n\nSwitch determining nature of return value. When it is False (the default) just\nthe coefficients are returned, when True diagnostic information from the\nsingular value decomposition is also returned.\n\nWeights. If not None, the weight `w[i]` applies to the unsquared residual\n`y[i] - y_hat[i]` at `x[i]`. Ideally the weights are chosen so that the errors\nof the products `w[i]*y[i]` all have the same variance. When using inverse-\nvariance weighting, use `w[i] = 1/sigma(y[i])`. The default value is None.\n\nNew in version 1.5.0.\n\nLegendre coefficients ordered from low to high. If `y` was 2-D, the\ncoefficients for the data in column k of `y` are in column `k`. If `deg` is\nspecified as a list, coefficients for terms not included in the fit are set\nequal to zero in the returned `coef`.\n\nThese values are only returned if `full == True`\n\nFor more details, see `numpy.linalg.lstsq`.\n\nThe rank of the coefficient matrix in the least-squares fit is deficient. The\nwarning is only raised if `full == False`. The warnings can be turned off by\n\nSee also\n\nEvaluates a Legendre series.\n\nVandermonde matrix of Legendre series.\n\nLegendre weight function (= 1).\n\nComputes a least-squares fit from the matrix.\n\nComputes spline fits.\n\nThe solution is the coefficients of the Legendre series `p` that minimizes the\nsum of the weighted squared errors\n\nwhere \\\\(w_j\\\\) are the weights. This problem is solved by setting up as the\n(typically) overdetermined matrix equation\n\nwhere `V` is the weighted pseudo Vandermonde matrix of `x`, `c` are the\ncoefficients to be solved for, `w` are the weights, and `y` are the observed\nvalues. This equation is then solved using the singular value decomposition of\n`V`.\n\nIf some of the singular values of `V` are so small that they are neglected,\nthen a `RankWarning` will be issued. This means that the coefficient values\nmay be poorly determined. Using a lower order fit will usually get rid of the\nwarning. The `rcond` parameter can also be set to a value smaller than its\ndefault, but the resulting fit may be spurious and have large contributions\nfrom roundoff error.\n\nFits using Legendre series are usually better conditioned than fits using\npower series, but much can depend on the distribution of the sample points and\nthe smoothness of the data. If the quality of the fit is inadequate splines\nmay be a good alternative.\n\nWikipedia, \u201cCurve fitting\u201d, https://en.wikipedia.org/wiki/Curve_fitting\n\n"}, {"name": "polynomial.legendre.legfromroots()", "path": "reference/generated/numpy.polynomial.legendre.legfromroots", "type": "numpy.polynomial.legendre.legfromroots", "text": "\nGenerate a Legendre series with given roots.\n\nThe function returns the coefficients of the polynomial\n\nin Legendre form, where the `r_n` are the roots specified in `roots`. If a\nzero has multiplicity n, then it must appear in `roots` n times. For instance,\nif 2 is a root of multiplicity three and 3 is a root of multiplicity 2, then\n`roots` looks something like [2, 2, 2, 3, 3]. The roots can appear in any\norder.\n\nIf the returned coefficients are `c`, then\n\nThe coefficient of the last term is not generally 1 for monic polynomials in\nLegendre form.\n\nSequence containing the roots.\n\n1-D array of coefficients. If all roots are real then `out` is a real array,\nif some of the roots are complex, then `out` is complex even if all the\ncoefficients in the result are real (see Examples below).\n\nSee also\n\n"}, {"name": "polynomial.legendre.leggauss()", "path": "reference/generated/numpy.polynomial.legendre.leggauss", "type": "numpy.polynomial.legendre.leggauss", "text": "\nGauss-Legendre quadrature.\n\nComputes the sample points and weights for Gauss-Legendre quadrature. These\nsample points and weights will correctly integrate polynomials of degree\n\\\\(2*deg - 1\\\\) or less over the interval \\\\([-1, 1]\\\\) with the weight\nfunction \\\\(f(x) = 1\\\\).\n\nNumber of sample points and weights. It must be >= 1.\n\n1-D ndarray containing the sample points.\n\n1-D ndarray containing the weights.\n\nNew in version 1.7.0.\n\nThe results have only been tested up to degree 100, higher degrees may be\nproblematic. The weights are determined by using the fact that\n\nwhere \\\\(c\\\\) is a constant independent of \\\\(k\\\\) and \\\\(x_k\\\\) is the k\u2019th\nroot of \\\\(L_n\\\\), and then scaling the results to get the right value when\nintegrating 1.\n\n"}, {"name": "polynomial.legendre.leggrid2d()", "path": "reference/generated/numpy.polynomial.legendre.leggrid2d", "type": "numpy.polynomial.legendre.leggrid2d", "text": "\nEvaluate a 2-D Legendre series on the Cartesian product of x and y.\n\nThis function returns the values:\n\nwhere the points `(a, b)` consist of all pairs formed by taking `a` from `x`\nand `b` from `y`. The resulting points form a grid with `x` in the first\ndimension and `y` in the second.\n\nThe parameters `x` and `y` are converted to arrays only if they are tuples or\na lists, otherwise they are treated as a scalars. In either case, either `x`\nand `y` or their elements must support multiplication and addition both with\nthemselves and with the elements of `c`.\n\nIf `c` has fewer than two dimensions, ones are implicitly appended to its\nshape to make it 2-D. The shape of the result will be c.shape[2:] + x.shape +\ny.shape.\n\nThe two dimensional series is evaluated at the points in the Cartesian product\nof `x` and `y`. If `x` or `y` is a list or tuple, it is first converted to an\nndarray, otherwise it is left unchanged and, if it isn\u2019t an ndarray, it is\ntreated as a scalar.\n\nArray of coefficients ordered so that the coefficient of the term of multi-\ndegree i,j is contained in `c[i,j]`. If `c` has dimension greater than two the\nremaining indices enumerate multiple sets of coefficients.\n\nThe values of the two dimensional Chebyshev series at points in the Cartesian\nproduct of `x` and `y`.\n\nSee also\n\nNew in version 1.7.0.\n\n"}, {"name": "polynomial.legendre.leggrid3d()", "path": "reference/generated/numpy.polynomial.legendre.leggrid3d", "type": "numpy.polynomial.legendre.leggrid3d", "text": "\nEvaluate a 3-D Legendre series on the Cartesian product of x, y, and z.\n\nThis function returns the values:\n\nwhere the points `(a, b, c)` consist of all triples formed by taking `a` from\n`x`, `b` from `y`, and `c` from `z`. The resulting points form a grid with `x`\nin the first dimension, `y` in the second, and `z` in the third.\n\nThe parameters `x`, `y`, and `z` are converted to arrays only if they are\ntuples or a lists, otherwise they are treated as a scalars. In either case,\neither `x`, `y`, and `z` or their elements must support multiplication and\naddition both with themselves and with the elements of `c`.\n\nIf `c` has fewer than three dimensions, ones are implicitly appended to its\nshape to make it 3-D. The shape of the result will be c.shape[3:] + x.shape +\ny.shape + z.shape.\n\nThe three dimensional series is evaluated at the points in the Cartesian\nproduct of `x`, `y`, and `z`. If `x`,`y`, or `z` is a list or tuple, it is\nfirst converted to an ndarray, otherwise it is left unchanged and, if it isn\u2019t\nan ndarray, it is treated as a scalar.\n\nArray of coefficients ordered so that the coefficients for terms of degree i,j\nare contained in `c[i,j]`. If `c` has dimension greater than two the remaining\nindices enumerate multiple sets of coefficients.\n\nThe values of the two dimensional polynomial at points in the Cartesian\nproduct of `x` and `y`.\n\nSee also\n\nNew in version 1.7.0.\n\n"}, {"name": "polynomial.legendre.legint()", "path": "reference/generated/numpy.polynomial.legendre.legint", "type": "numpy.polynomial.legendre.legint", "text": "\nIntegrate a Legendre series.\n\nReturns the Legendre series coefficients `c` integrated `m` times from `lbnd`\nalong `axis`. At each iteration the resulting series is multiplied by `scl`\nand an integration constant, `k`, is added. The scaling factor is for use in a\nlinear change of variable. (\u201cBuyer beware\u201d: note that, depending on what one\nis doing, one may want `scl` to be the reciprocal of what one might expect;\nfor more information, see the Notes section below.) The argument `c` is an\narray of coefficients from low to high degree along each axis, e.g., [1,2,3]\nrepresents the series `L_0 + 2*L_1 + 3*L_2` while [[1,2],[1,2]] represents\n`1*L_0(x)*L_0(y) + 1*L_1(x)*L_0(y) + 2*L_0(x)*L_1(y) + 2*L_1(x)*L_1(y)` if\naxis=0 is `x` and axis=1 is `y`.\n\nArray of Legendre series coefficients. If c is multidimensional the different\naxis correspond to different variables with the degree in each axis given by\nthe corresponding index.\n\nOrder of integration, must be positive. (Default: 1)\n\nIntegration constant(s). The value of the first integral at `lbnd` is the\nfirst value in the list, the value of the second integral at `lbnd` is the\nsecond value, etc. If `k == []` (the default), all constants are set to zero.\nIf `m == 1`, a single scalar can be given instead of a list.\n\nThe lower bound of the integral. (Default: 0)\n\nFollowing each integration the result is multiplied by `scl` before the\nintegration constant is added. (Default: 1)\n\nAxis over which the integral is taken. (Default: 0).\n\nNew in version 1.7.0.\n\nLegendre series coefficient array of the integral.\n\nIf `m < 0`, `len(k) > m`, `np.ndim(lbnd) != 0`, or `np.ndim(scl) != 0`.\n\nSee also\n\nNote that the result of each integration is multiplied by `scl`. Why is this\nimportant to note? Say one is making a linear change of variable \\\\(u = ax +\nb\\\\) in an integral relative to `x`. Then \\\\(dx = du/a\\\\), so one will need to\nset `scl` equal to \\\\(1/a\\\\) \\- perhaps not what one would have first thought.\n\nAlso note that, in general, the result of integrating a C-series needs to be\n\u201creprojected\u201d onto the C-series basis set. Thus, typically, the result of this\nfunction is \u201cunintuitive,\u201d albeit correct; see Examples section below.\n\n"}, {"name": "polynomial.legendre.legline()", "path": "reference/generated/numpy.polynomial.legendre.legline", "type": "numpy.polynomial.legendre.legline", "text": "\nLegendre series whose graph is a straight line.\n\nThe specified line is given by `off + scl*x`.\n\nThis module\u2019s representation of the Legendre series for `off + scl*x`.\n\nSee also\n\n"}, {"name": "polynomial.legendre.legmul()", "path": "reference/generated/numpy.polynomial.legendre.legmul", "type": "numpy.polynomial.legendre.legmul", "text": "\nMultiply one Legendre series by another.\n\nReturns the product of two Legendre series `c1` * `c2`. The arguments are\nsequences of coefficients, from lowest order \u201cterm\u201d to highest, e.g., [1,2,3]\nrepresents the series `P_0 + 2*P_1 + 3*P_2`.\n\n1-D arrays of Legendre series coefficients ordered from low to high.\n\nOf Legendre series coefficients representing their product.\n\nSee also\n\nIn general, the (polynomial) product of two C-series results in terms that are\nnot in the Legendre polynomial basis set. Thus, to express the product as a\nLegendre series, it is necessary to \u201creproject\u201d the product onto said basis\nset, which may produce \u201cunintuitive\u201d (but correct) results; see Examples\nsection below.\n\n"}, {"name": "polynomial.legendre.legmulx()", "path": "reference/generated/numpy.polynomial.legendre.legmulx", "type": "numpy.polynomial.legendre.legmulx", "text": "\nMultiply a Legendre series by x.\n\nMultiply the Legendre series `c` by x, where x is the independent variable.\n\n1-D array of Legendre series coefficients ordered from low to high.\n\nArray representing the result of the multiplication.\n\nSee also\n\nThe multiplication uses the recursion relationship for Legendre polynomials in\nthe form\n\n"}, {"name": "polynomial.legendre.legone", "path": "reference/generated/numpy.polynomial.legendre.legone", "type": "numpy.polynomial.legendre.legone", "text": "\nAn array object represents a multidimensional, homogeneous array of fixed-size\nitems. An associated data-type object describes the format of each element in\nthe array (its byte-order, how many bytes it occupies in memory, whether it is\nan integer, a floating point number, or something else, etc.)\n\nArrays should be constructed using `array`, `zeros` or `empty` (refer to the\nSee Also section below). The parameters given here refer to a low-level method\n(`ndarray(\u2026)`) for instantiating an array.\n\nFor more information, refer to the `numpy` module and examine the methods and\nattributes of an array.\n\nShape of created array.\n\nAny object that can be interpreted as a numpy data type.\n\nUsed to fill the array with data.\n\nOffset of array data in buffer.\n\nStrides of data in memory.\n\nRow-major (C-style) or column-major (Fortran-style) order.\n\nSee also\n\nConstruct an array.\n\nCreate an array, each element of which is zero.\n\nCreate an array, but leave its allocated memory unchanged (i.e., it contains\n\u201cgarbage\u201d).\n\nCreate a data-type.\n\nAn ndarray alias generic w.r.t. its `dtype.type`.\n\nThere are two modes of creating an array using `__new__`:\n\nNo `__init__` method is needed because the array is fully initialized after\nthe `__new__` method.\n\nThese examples illustrate the low-level `ndarray` constructor. Refer to the\n`See Also` section above for easier ways of constructing an ndarray.\n\nFirst mode, `buffer` is None:\n\nSecond mode:\n\nTranspose of the array.\n\nThe array\u2019s elements, in memory.\n\nDescribes the format of the elements in the array.\n\nDictionary containing information related to memory use, e.g., \u2018C_CONTIGUOUS\u2019,\n\u2018OWNDATA\u2019, \u2018WRITEABLE\u2019, etc.\n\nFlattened version of the array as an iterator. The iterator allows\nassignments, e.g., `x.flat = 3` (See `ndarray.flat` for assignment examples;\nTODO).\n\nImaginary part of the array.\n\nReal part of the array.\n\nNumber of elements in the array.\n\nThe memory use of each array element in bytes.\n\nThe total number of bytes required to store the array data, i.e., `itemsize *\nsize`.\n\nThe array\u2019s number of dimensions.\n\nShape of the array.\n\nThe step-size required to move from one element to the next in memory. For\nexample, a contiguous `(3, 4)` array of type `int16` in C-order has strides\n`(8, 2)`. This implies that to move from element to element in memory requires\njumps of 2 bytes. To move from row-to-row, one needs to jump 8 bytes at a time\n(`2 * 4`).\n\nClass containing properties of the array needed for interaction with ctypes.\n\nIf the array is a view into another array, that array is its `base` (unless\nthat array is also a view). The `base` array is where the array data is\nactually stored.\n\n"}, {"name": "polynomial.legendre.legpow()", "path": "reference/generated/numpy.polynomial.legendre.legpow", "type": "numpy.polynomial.legendre.legpow", "text": "\nRaise a Legendre series to a power.\n\nReturns the Legendre series `c` raised to the power `pow`. The argument `c` is\na sequence of coefficients ordered from low to high. i.e., [1,2,3] is the\nseries `P_0 + 2*P_1 + 3*P_2.`\n\n1-D array of Legendre series coefficients ordered from low to high.\n\nPower to which the series will be raised\n\nMaximum power allowed. This is mainly to limit growth of the series to\nunmanageable size. Default is 16\n\nLegendre series of power.\n\nSee also\n\n"}, {"name": "polynomial.legendre.legroots()", "path": "reference/generated/numpy.polynomial.legendre.legroots", "type": "numpy.polynomial.legendre.legroots", "text": "\nCompute the roots of a Legendre series.\n\nReturn the roots (a.k.a. \u201czeros\u201d) of the polynomial\n\n1-D array of coefficients.\n\nArray of the roots of the series. If all the roots are real, then `out` is\nalso real, otherwise it is complex.\n\nSee also\n\nThe root estimates are obtained as the eigenvalues of the companion matrix,\nRoots far from the origin of the complex plane may have large errors due to\nthe numerical instability of the series for such values. Roots with\nmultiplicity greater than 1 will also show larger errors as the value of the\nseries near such points is relatively insensitive to errors in the roots.\nIsolated roots near the origin can be improved by a few iterations of Newton\u2019s\nmethod.\n\nThe Legendre series basis polynomials aren\u2019t powers of `x` so the results of\nthis function may seem unintuitive.\n\n"}, {"name": "polynomial.legendre.legsub()", "path": "reference/generated/numpy.polynomial.legendre.legsub", "type": "numpy.polynomial.legendre.legsub", "text": "\nSubtract one Legendre series from another.\n\nReturns the difference of two Legendre series `c1` \\- `c2`. The sequences of\ncoefficients are from lowest order term to highest, i.e., [1,2,3] represents\nthe series `P_0 + 2*P_1 + 3*P_2`.\n\n1-D arrays of Legendre series coefficients ordered from low to high.\n\nOf Legendre series coefficients representing their difference.\n\nSee also\n\nUnlike multiplication, division, etc., the difference of two Legendre series\nis a Legendre series (without having to \u201creproject\u201d the result onto the basis\nset) so subtraction, just like that of \u201cstandard\u201d polynomials, is simply\n\u201ccomponent-wise.\u201d\n\n"}, {"name": "polynomial.legendre.legtrim()", "path": "reference/generated/numpy.polynomial.legendre.legtrim", "type": "numpy.polynomial.legendre.legtrim", "text": "\nRemove \u201csmall\u201d \u201ctrailing\u201d coefficients from a polynomial.\n\n\u201cSmall\u201d means \u201csmall in absolute value\u201d and is controlled by the parameter\n`tol`; \u201ctrailing\u201d means highest order coefficient(s), e.g., in `[0, 1, 1, 0,\n0]` (which represents `0 + x + x**2 + 0*x**3 + 0*x**4`) both the 3-rd and 4-th\norder coefficients would be \u201ctrimmed.\u201d\n\n1-d array of coefficients, ordered from lowest order to highest.\n\nTrailing (i.e., highest order) elements with absolute value less than or equal\nto `tol` (default value is zero) are removed.\n\n1-d array with trailing zeros removed. If the resulting series would be empty,\na series containing a single zero is returned.\n\nIf `tol` < 0\n\nSee also\n\n"}, {"name": "polynomial.legendre.legval()", "path": "reference/generated/numpy.polynomial.legendre.legval", "type": "numpy.polynomial.legendre.legval", "text": "\nEvaluate a Legendre series at points x.\n\nIf `c` is of length `n + 1`, this function returns the value:\n\nThe parameter `x` is converted to an array only if it is a tuple or a list,\notherwise it is treated as a scalar. In either case, either `x` or its\nelements must support multiplication and addition both with themselves and\nwith the elements of `c`.\n\nIf `c` is a 1-D array, then `p(x)` will have the same shape as `x`. If `c` is\nmultidimensional, then the shape of the result depends on the value of\n`tensor`. If `tensor` is true the shape will be c.shape[1:] + x.shape. If\n`tensor` is false the shape will be c.shape[1:]. Note that scalars have shape\n(,).\n\nTrailing zeros in the coefficients will be used in the evaluation, so they\nshould be avoided if efficiency is a concern.\n\nIf `x` is a list or tuple, it is converted to an ndarray, otherwise it is left\nunchanged and treated as a scalar. In either case, `x` or its elements must\nsupport addition and multiplication with with themselves and with the elements\nof `c`.\n\nArray of coefficients ordered so that the coefficients for terms of degree n\nare contained in c[n]. If `c` is multidimensional the remaining indices\nenumerate multiple polynomials. In the two dimensional case the coefficients\nmay be thought of as stored in the columns of `c`.\n\nIf True, the shape of the coefficient array is extended with ones on the\nright, one for each dimension of `x`. Scalars have dimension 0 for this\naction. The result is that every column of coefficients in `c` is evaluated\nfor every element of `x`. If False, `x` is broadcast over the columns of `c`\nfor the evaluation. This keyword is useful when `c` is multidimensional. The\ndefault value is True.\n\nNew in version 1.7.0.\n\nThe shape of the return value is described above.\n\nSee also\n\nThe evaluation uses Clenshaw recursion, aka synthetic division.\n\n"}, {"name": "polynomial.legendre.legval2d()", "path": "reference/generated/numpy.polynomial.legendre.legval2d", "type": "numpy.polynomial.legendre.legval2d", "text": "\nEvaluate a 2-D Legendre series at points (x, y).\n\nThis function returns the values:\n\nThe parameters `x` and `y` are converted to arrays only if they are tuples or\na lists, otherwise they are treated as a scalars and they must have the same\nshape after conversion. In either case, either `x` and `y` or their elements\nmust support multiplication and addition both with themselves and with the\nelements of `c`.\n\nIf `c` is a 1-D array a one is implicitly appended to its shape to make it\n2-D. The shape of the result will be c.shape[2:] + x.shape.\n\nThe two dimensional series is evaluated at the points `(x, y)`, where `x` and\n`y` must have the same shape. If `x` or `y` is a list or tuple, it is first\nconverted to an ndarray, otherwise it is left unchanged and if it isn\u2019t an\nndarray it is treated as a scalar.\n\nArray of coefficients ordered so that the coefficient of the term of multi-\ndegree i,j is contained in `c[i,j]`. If `c` has dimension greater than two the\nremaining indices enumerate multiple sets of coefficients.\n\nThe values of the two dimensional Legendre series at points formed from pairs\nof corresponding values from `x` and `y`.\n\nSee also\n\nNew in version 1.7.0.\n\n"}, {"name": "polynomial.legendre.legval3d()", "path": "reference/generated/numpy.polynomial.legendre.legval3d", "type": "numpy.polynomial.legendre.legval3d", "text": "\nEvaluate a 3-D Legendre series at points (x, y, z).\n\nThis function returns the values:\n\nThe parameters `x`, `y`, and `z` are converted to arrays only if they are\ntuples or a lists, otherwise they are treated as a scalars and they must have\nthe same shape after conversion. In either case, either `x`, `y`, and `z` or\ntheir elements must support multiplication and addition both with themselves\nand with the elements of `c`.\n\nIf `c` has fewer than 3 dimensions, ones are implicitly appended to its shape\nto make it 3-D. The shape of the result will be c.shape[3:] + x.shape.\n\nThe three dimensional series is evaluated at the points `(x, y, z)`, where\n`x`, `y`, and `z` must have the same shape. If any of `x`, `y`, or `z` is a\nlist or tuple, it is first converted to an ndarray, otherwise it is left\nunchanged and if it isn\u2019t an ndarray it is treated as a scalar.\n\nArray of coefficients ordered so that the coefficient of the term of multi-\ndegree i,j,k is contained in `c[i,j,k]`. If `c` has dimension greater than 3\nthe remaining indices enumerate multiple sets of coefficients.\n\nThe values of the multidimensional polynomial on points formed with triples of\ncorresponding values from `x`, `y`, and `z`.\n\nSee also\n\nNew in version 1.7.0.\n\n"}, {"name": "polynomial.legendre.legvander()", "path": "reference/generated/numpy.polynomial.legendre.legvander", "type": "numpy.polynomial.legendre.legvander", "text": "\nPseudo-Vandermonde matrix of given degree.\n\nReturns the pseudo-Vandermonde matrix of degree `deg` and sample points `x`.\nThe pseudo-Vandermonde matrix is defined by\n\nwhere `0 <= i <= deg`. The leading indices of `V` index the elements of `x`\nand the last index is the degree of the Legendre polynomial.\n\nIf `c` is a 1-D array of coefficients of length `n + 1` and `V` is the array\n`V = legvander(x, n)`, then `np.dot(V, c)` and `legval(x, c)` are the same up\nto roundoff. This equivalence is useful both for least squares fitting and for\nthe evaluation of a large number of Legendre series of the same degree and\nsample points.\n\nArray of points. The dtype is converted to float64 or complex128 depending on\nwhether any of the elements are complex. If `x` is scalar it is converted to a\n1-D array.\n\nDegree of the resulting matrix.\n\nThe pseudo-Vandermonde matrix. The shape of the returned matrix is `x.shape +\n(deg + 1,)`, where The last index is the degree of the corresponding Legendre\npolynomial. The dtype will be the same as the converted `x`.\n\n"}, {"name": "polynomial.legendre.legvander2d()", "path": "reference/generated/numpy.polynomial.legendre.legvander2d", "type": "numpy.polynomial.legendre.legvander2d", "text": "\nPseudo-Vandermonde matrix of given degrees.\n\nReturns the pseudo-Vandermonde matrix of degrees `deg` and sample points `(x,\ny)`. The pseudo-Vandermonde matrix is defined by\n\nwhere `0 <= i <= deg[0]` and `0 <= j <= deg[1]`. The leading indices of `V`\nindex the points `(x, y)` and the last index encodes the degrees of the\nLegendre polynomials.\n\nIf `V = legvander2d(x, y, [xdeg, ydeg])`, then the columns of `V` correspond\nto the elements of a 2-D coefficient array `c` of shape (xdeg + 1, ydeg + 1)\nin the order\n\nand `np.dot(V, c.flat)` and `legval2d(x, y, c)` will be the same up to\nroundoff. This equivalence is useful both for least squares fitting and for\nthe evaluation of a large number of 2-D Legendre series of the same degrees\nand sample points.\n\nArrays of point coordinates, all of the same shape. The dtypes will be\nconverted to either float64 or complex128 depending on whether any of the\nelements are complex. Scalars are converted to 1-D arrays.\n\nList of maximum degrees of the form [x_deg, y_deg].\n\nThe shape of the returned matrix is `x.shape + (order,)`, where \\\\(order =\n(deg[0]+1)*(deg[1]+1)\\\\). The dtype will be the same as the converted `x` and\n`y`.\n\nSee also\n\nNew in version 1.7.0.\n\n"}, {"name": "polynomial.legendre.legvander3d()", "path": "reference/generated/numpy.polynomial.legendre.legvander3d", "type": "numpy.polynomial.legendre.legvander3d", "text": "\nPseudo-Vandermonde matrix of given degrees.\n\nReturns the pseudo-Vandermonde matrix of degrees `deg` and sample points `(x,\ny, z)`. If `l, m, n` are the given degrees in `x, y, z`, then The pseudo-\nVandermonde matrix is defined by\n\nwhere `0 <= i <= l`, `0 <= j <= m`, and `0 <= j <= n`. The leading indices of\n`V` index the points `(x, y, z)` and the last index encodes the degrees of the\nLegendre polynomials.\n\nIf `V = legvander3d(x, y, z, [xdeg, ydeg, zdeg])`, then the columns of `V`\ncorrespond to the elements of a 3-D coefficient array `c` of shape (xdeg + 1,\nydeg + 1, zdeg + 1) in the order\n\nand `np.dot(V, c.flat)` and `legval3d(x, y, z, c)` will be the same up to\nroundoff. This equivalence is useful both for least squares fitting and for\nthe evaluation of a large number of 3-D Legendre series of the same degrees\nand sample points.\n\nArrays of point coordinates, all of the same shape. The dtypes will be\nconverted to either float64 or complex128 depending on whether any of the\nelements are complex. Scalars are converted to 1-D arrays.\n\nList of maximum degrees of the form [x_deg, y_deg, z_deg].\n\nThe shape of the returned matrix is `x.shape + (order,)`, where \\\\(order =\n(deg[0]+1)*(deg[1]+1)*(deg[2]+1)\\\\). The dtype will be the same as the\nconverted `x`, `y`, and `z`.\n\nSee also\n\nNew in version 1.7.0.\n\n"}, {"name": "polynomial.legendre.legweight()", "path": "reference/generated/numpy.polynomial.legendre.legweight", "type": "numpy.polynomial.legendre.legweight", "text": "\nWeight function of the Legendre polynomials.\n\nThe weight function is \\\\(1\\\\) and the interval of integration is \\\\([-1,\n1]\\\\). The Legendre polynomials are orthogonal, but not normalized, with\nrespect to this weight function.\n\nValues at which the weight function will be computed.\n\nThe weight function at `x`.\n\nNew in version 1.7.0.\n\n"}, {"name": "polynomial.legendre.legx", "path": "reference/generated/numpy.polynomial.legendre.legx", "type": "numpy.polynomial.legendre.legx", "text": "\nAn array object represents a multidimensional, homogeneous array of fixed-size\nitems. An associated data-type object describes the format of each element in\nthe array (its byte-order, how many bytes it occupies in memory, whether it is\nan integer, a floating point number, or something else, etc.)\n\nArrays should be constructed using `array`, `zeros` or `empty` (refer to the\nSee Also section below). The parameters given here refer to a low-level method\n(`ndarray(\u2026)`) for instantiating an array.\n\nFor more information, refer to the `numpy` module and examine the methods and\nattributes of an array.\n\nShape of created array.\n\nAny object that can be interpreted as a numpy data type.\n\nUsed to fill the array with data.\n\nOffset of array data in buffer.\n\nStrides of data in memory.\n\nRow-major (C-style) or column-major (Fortran-style) order.\n\nSee also\n\nConstruct an array.\n\nCreate an array, each element of which is zero.\n\nCreate an array, but leave its allocated memory unchanged (i.e., it contains\n\u201cgarbage\u201d).\n\nCreate a data-type.\n\nAn ndarray alias generic w.r.t. its `dtype.type`.\n\nThere are two modes of creating an array using `__new__`:\n\nNo `__init__` method is needed because the array is fully initialized after\nthe `__new__` method.\n\nThese examples illustrate the low-level `ndarray` constructor. Refer to the\n`See Also` section above for easier ways of constructing an ndarray.\n\nFirst mode, `buffer` is None:\n\nSecond mode:\n\nTranspose of the array.\n\nThe array\u2019s elements, in memory.\n\nDescribes the format of the elements in the array.\n\nDictionary containing information related to memory use, e.g., \u2018C_CONTIGUOUS\u2019,\n\u2018OWNDATA\u2019, \u2018WRITEABLE\u2019, etc.\n\nFlattened version of the array as an iterator. The iterator allows\nassignments, e.g., `x.flat = 3` (See `ndarray.flat` for assignment examples;\nTODO).\n\nImaginary part of the array.\n\nReal part of the array.\n\nNumber of elements in the array.\n\nThe memory use of each array element in bytes.\n\nThe total number of bytes required to store the array data, i.e., `itemsize *\nsize`.\n\nThe array\u2019s number of dimensions.\n\nShape of the array.\n\nThe step-size required to move from one element to the next in memory. For\nexample, a contiguous `(3, 4)` array of type `int16` in C-order has strides\n`(8, 2)`. This implies that to move from element to element in memory requires\njumps of 2 bytes. To move from row-to-row, one needs to jump 8 bytes at a time\n(`2 * 4`).\n\nClass containing properties of the array needed for interaction with ctypes.\n\nIf the array is a view into another array, that array is its `base` (unless\nthat array is also a view). The `base` array is where the array data is\nactually stored.\n\n"}, {"name": "polynomial.legendre.legzero", "path": "reference/generated/numpy.polynomial.legendre.legzero", "type": "numpy.polynomial.legendre.legzero", "text": "\nAn array object represents a multidimensional, homogeneous array of fixed-size\nitems. An associated data-type object describes the format of each element in\nthe array (its byte-order, how many bytes it occupies in memory, whether it is\nan integer, a floating point number, or something else, etc.)\n\nArrays should be constructed using `array`, `zeros` or `empty` (refer to the\nSee Also section below). The parameters given here refer to a low-level method\n(`ndarray(\u2026)`) for instantiating an array.\n\nFor more information, refer to the `numpy` module and examine the methods and\nattributes of an array.\n\nShape of created array.\n\nAny object that can be interpreted as a numpy data type.\n\nUsed to fill the array with data.\n\nOffset of array data in buffer.\n\nStrides of data in memory.\n\nRow-major (C-style) or column-major (Fortran-style) order.\n\nSee also\n\nConstruct an array.\n\nCreate an array, each element of which is zero.\n\nCreate an array, but leave its allocated memory unchanged (i.e., it contains\n\u201cgarbage\u201d).\n\nCreate a data-type.\n\nAn ndarray alias generic w.r.t. its `dtype.type`.\n\nThere are two modes of creating an array using `__new__`:\n\nNo `__init__` method is needed because the array is fully initialized after\nthe `__new__` method.\n\nThese examples illustrate the low-level `ndarray` constructor. Refer to the\n`See Also` section above for easier ways of constructing an ndarray.\n\nFirst mode, `buffer` is None:\n\nSecond mode:\n\nTranspose of the array.\n\nThe array\u2019s elements, in memory.\n\nDescribes the format of the elements in the array.\n\nDictionary containing information related to memory use, e.g., \u2018C_CONTIGUOUS\u2019,\n\u2018OWNDATA\u2019, \u2018WRITEABLE\u2019, etc.\n\nFlattened version of the array as an iterator. The iterator allows\nassignments, e.g., `x.flat = 3` (See `ndarray.flat` for assignment examples;\nTODO).\n\nImaginary part of the array.\n\nReal part of the array.\n\nNumber of elements in the array.\n\nThe memory use of each array element in bytes.\n\nThe total number of bytes required to store the array data, i.e., `itemsize *\nsize`.\n\nThe array\u2019s number of dimensions.\n\nShape of the array.\n\nThe step-size required to move from one element to the next in memory. For\nexample, a contiguous `(3, 4)` array of type `int16` in C-order has strides\n`(8, 2)`. This implies that to move from element to element in memory requires\njumps of 2 bytes. To move from row-to-row, one needs to jump 8 bytes at a time\n(`2 * 4`).\n\nClass containing properties of the array needed for interaction with ctypes.\n\nIf the array is a view into another array, that array is its `base` (unless\nthat array is also a view). The `base` array is where the array data is\nactually stored.\n\n"}, {"name": "polynomial.legendre.poly2leg()", "path": "reference/generated/numpy.polynomial.legendre.poly2leg", "type": "numpy.polynomial.legendre.poly2leg", "text": "\nConvert a polynomial to a Legendre series.\n\nConvert an array representing the coefficients of a polynomial (relative to\nthe \u201cstandard\u201d basis) ordered from lowest degree to highest, to an array of\nthe coefficients of the equivalent Legendre series, ordered from lowest to\nhighest degree.\n\n1-D array containing the polynomial coefficients\n\n1-D array containing the coefficients of the equivalent Legendre series.\n\nSee also\n\nThe easy way to do conversions between polynomial basis sets is to use the\nconvert method of a class instance.\n\n"}, {"name": "polynomial.polynomial.polyadd()", "path": "reference/generated/numpy.polynomial.polynomial.polyadd", "type": "numpy.polynomial.polynomial.polyadd", "text": "\nAdd one polynomial to another.\n\nReturns the sum of two polynomials `c1` \\+ `c2`. The arguments are sequences\nof coefficients from lowest order term to highest, i.e., [1,2,3] represents\nthe polynomial `1 + 2*x + 3*x**2`.\n\n1-D arrays of polynomial coefficients ordered from low to high.\n\nThe coefficient array representing their sum.\n\nSee also\n\n"}, {"name": "polynomial.polynomial.polycompanion()", "path": "reference/generated/numpy.polynomial.polynomial.polycompanion", "type": "numpy.polynomial.polynomial.polycompanion", "text": "\nReturn the companion matrix of c.\n\nThe companion matrix for power series cannot be made symmetric by scaling the\nbasis, so this function differs from those for the orthogonal polynomials.\n\n1-D array of polynomial coefficients ordered from low to high degree.\n\nCompanion matrix of dimensions (deg, deg).\n\nNew in version 1.7.0.\n\n"}, {"name": "polynomial.polynomial.polyder()", "path": "reference/generated/numpy.polynomial.polynomial.polyder", "type": "numpy.polynomial.polynomial.polyder", "text": "\nDifferentiate a polynomial.\n\nReturns the polynomial coefficients `c` differentiated `m` times along `axis`.\nAt each iteration the result is multiplied by `scl` (the scaling factor is for\nuse in a linear change of variable). The argument `c` is an array of\ncoefficients from low to high degree along each axis, e.g., [1,2,3] represents\nthe polynomial `1 + 2*x + 3*x**2` while [[1,2],[1,2]] represents `1 + 1*x +\n2*y + 2*x*y` if axis=0 is `x` and axis=1 is `y`.\n\nArray of polynomial coefficients. If c is multidimensional the different axis\ncorrespond to different variables with the degree in each axis given by the\ncorresponding index.\n\nNumber of derivatives taken, must be non-negative. (Default: 1)\n\nEach differentiation is multiplied by `scl`. The end result is multiplication\nby `scl**m`. This is for use in a linear change of variable. (Default: 1)\n\nAxis over which the derivative is taken. (Default: 0).\n\nNew in version 1.7.0.\n\nPolynomial coefficients of the derivative.\n\nSee also\n\n"}, {"name": "polynomial.polynomial.polydiv()", "path": "reference/generated/numpy.polynomial.polynomial.polydiv", "type": "numpy.polynomial.polynomial.polydiv", "text": "\nDivide one polynomial by another.\n\nReturns the quotient-with-remainder of two polynomials `c1` / `c2`. The\narguments are sequences of coefficients, from lowest order term to highest,\ne.g., [1,2,3] represents `1 + 2*x + 3*x**2`.\n\n1-D arrays of polynomial coefficients ordered from low to high.\n\nOf coefficient series representing the quotient and remainder.\n\nSee also\n\n"}, {"name": "polynomial.polynomial.polydomain", "path": "reference/generated/numpy.polynomial.polynomial.polydomain", "type": "numpy.polynomial.polynomial.polydomain", "text": "\nAn array object represents a multidimensional, homogeneous array of fixed-size\nitems. An associated data-type object describes the format of each element in\nthe array (its byte-order, how many bytes it occupies in memory, whether it is\nan integer, a floating point number, or something else, etc.)\n\nArrays should be constructed using `array`, `zeros` or `empty` (refer to the\nSee Also section below). The parameters given here refer to a low-level method\n(`ndarray(\u2026)`) for instantiating an array.\n\nFor more information, refer to the `numpy` module and examine the methods and\nattributes of an array.\n\nShape of created array.\n\nAny object that can be interpreted as a numpy data type.\n\nUsed to fill the array with data.\n\nOffset of array data in buffer.\n\nStrides of data in memory.\n\nRow-major (C-style) or column-major (Fortran-style) order.\n\nSee also\n\nConstruct an array.\n\nCreate an array, each element of which is zero.\n\nCreate an array, but leave its allocated memory unchanged (i.e., it contains\n\u201cgarbage\u201d).\n\nCreate a data-type.\n\nAn ndarray alias generic w.r.t. its `dtype.type`.\n\nThere are two modes of creating an array using `__new__`:\n\nNo `__init__` method is needed because the array is fully initialized after\nthe `__new__` method.\n\nThese examples illustrate the low-level `ndarray` constructor. Refer to the\n`See Also` section above for easier ways of constructing an ndarray.\n\nFirst mode, `buffer` is None:\n\nSecond mode:\n\nTranspose of the array.\n\nThe array\u2019s elements, in memory.\n\nDescribes the format of the elements in the array.\n\nDictionary containing information related to memory use, e.g., \u2018C_CONTIGUOUS\u2019,\n\u2018OWNDATA\u2019, \u2018WRITEABLE\u2019, etc.\n\nFlattened version of the array as an iterator. The iterator allows\nassignments, e.g., `x.flat = 3` (See `ndarray.flat` for assignment examples;\nTODO).\n\nImaginary part of the array.\n\nReal part of the array.\n\nNumber of elements in the array.\n\nThe memory use of each array element in bytes.\n\nThe total number of bytes required to store the array data, i.e., `itemsize *\nsize`.\n\nThe array\u2019s number of dimensions.\n\nShape of the array.\n\nThe step-size required to move from one element to the next in memory. For\nexample, a contiguous `(3, 4)` array of type `int16` in C-order has strides\n`(8, 2)`. This implies that to move from element to element in memory requires\njumps of 2 bytes. To move from row-to-row, one needs to jump 8 bytes at a time\n(`2 * 4`).\n\nClass containing properties of the array needed for interaction with ctypes.\n\nIf the array is a view into another array, that array is its `base` (unless\nthat array is also a view). The `base` array is where the array data is\nactually stored.\n\n"}, {"name": "polynomial.polynomial.polyfit()", "path": "reference/generated/numpy.polynomial.polynomial.polyfit", "type": "numpy.polynomial.polynomial.polyfit", "text": "\nLeast-squares fit of a polynomial to data.\n\nReturn the coefficients of a polynomial of degree `deg` that is the least\nsquares fit to the data values `y` given at points `x`. If `y` is 1-D the\nreturned coefficients will also be 1-D. If `y` is 2-D multiple fits are done,\none for each column of `y`, and the resulting coefficients are stored in the\ncorresponding columns of a 2-D return. The fitted polynomial(s) are in the\nform\n\nwhere `n` is `deg`.\n\nx-coordinates of the `M` sample (data) points `(x[i], y[i])`.\n\ny-coordinates of the sample points. Several sets of sample points sharing the\nsame x-coordinates can be (independently) fit with one call to `polyfit` by\npassing in for `y` a 2-D array that contains one data set per column.\n\nDegree(s) of the fitting polynomials. If `deg` is a single integer all terms\nup to and including the `deg`\u2019th term are included in the fit. For NumPy\nversions >= 1.11.0 a list of integers specifying the degrees of the terms to\ninclude may be used instead.\n\nRelative condition number of the fit. Singular values smaller than `rcond`,\nrelative to the largest singular value, will be ignored. The default value is\n`len(x)*eps`, where `eps` is the relative precision of the platform\u2019s float\ntype, about 2e-16 in most cases.\n\nSwitch determining the nature of the return value. When `False` (the default)\njust the coefficients are returned; when `True`, diagnostic information from\nthe singular value decomposition (used to solve the fit\u2019s matrix equation) is\nalso returned.\n\nWeights. If not None, the weight `w[i]` applies to the unsquared residual\n`y[i] - y_hat[i]` at `x[i]`. Ideally the weights are chosen so that the errors\nof the products `w[i]*y[i]` all have the same variance. When using inverse-\nvariance weighting, use `w[i] = 1/sigma(y[i])`. The default value is None.\n\nNew in version 1.5.0.\n\nPolynomial coefficients ordered from low to high. If `y` was 2-D, the\ncoefficients in column `k` of `coef` represent the polynomial fit to the data\nin `y`\u2019s `k`-th column.\n\nThese values are only returned if `full == True`\n\nFor more details, see `numpy.linalg.lstsq`.\n\nRaised if the matrix in the least-squares fit is rank deficient. The warning\nis only raised if `full == False`. The warnings can be turned off by:\n\nSee also\n\nEvaluates a polynomial.\n\nVandermonde matrix for powers.\n\nComputes a least-squares fit from the matrix.\n\nComputes spline fits.\n\nThe solution is the coefficients of the polynomial `p` that minimizes the sum\nof the weighted squared errors\n\nwhere the \\\\(w_j\\\\) are the weights. This problem is solved by setting up the\n(typically) over-determined matrix equation:\n\nwhere `V` is the weighted pseudo Vandermonde matrix of `x`, `c` are the\ncoefficients to be solved for, `w` are the weights, and `y` are the observed\nvalues. This equation is then solved using the singular value decomposition of\n`V`.\n\nIf some of the singular values of `V` are so small that they are neglected\n(and `full` == `False`), a `RankWarning` will be raised. This means that the\ncoefficient values may be poorly determined. Fitting to a lower order\npolynomial will usually get rid of the warning (but may not be what you want,\nof course; if you have independent reason(s) for choosing the degree which\nisn\u2019t working, you may have to: a) reconsider those reasons, and/or b)\nreconsider the quality of your data). The `rcond` parameter can also be set to\na value smaller than its default, but the resulting fit may be spurious and\nhave large contributions from roundoff error.\n\nPolynomial fits using double precision tend to \u201cfail\u201d at about (polynomial)\ndegree 20. Fits using Chebyshev or Legendre series are generally better\nconditioned, but much can still depend on the distribution of the sample\npoints and the smoothness of the data. If the quality of the fit is\ninadequate, splines may be a good alternative.\n\nSame thing without the added noise\n\n"}, {"name": "polynomial.polynomial.polyfromroots()", "path": "reference/generated/numpy.polynomial.polynomial.polyfromroots", "type": "numpy.polynomial.polynomial.polyfromroots", "text": "\nGenerate a monic polynomial with given roots.\n\nReturn the coefficients of the polynomial\n\nwhere the `r_n` are the roots specified in `roots`. If a zero has multiplicity\nn, then it must appear in `roots` n times. For instance, if 2 is a root of\nmultiplicity three and 3 is a root of multiplicity 2, then `roots` looks\nsomething like [2, 2, 2, 3, 3]. The roots can appear in any order.\n\nIf the returned coefficients are `c`, then\n\nThe coefficient of the last term is 1 for monic polynomials in this form.\n\nSequence containing the roots.\n\n1-D array of the polynomial\u2019s coefficients If all the roots are real, then\n`out` is also real, otherwise it is complex. (see Examples below).\n\nSee also\n\nThe coefficients are determined by multiplying together linear factors of the\nform `(x - r_i)`, i.e.\n\nwhere `n == len(roots) - 1`; note that this implies that `1` is always\nreturned for \\\\(a_n\\\\).\n\n"}, {"name": "polynomial.polynomial.polygrid2d()", "path": "reference/generated/numpy.polynomial.polynomial.polygrid2d", "type": "numpy.polynomial.polynomial.polygrid2d", "text": "\nEvaluate a 2-D polynomial on the Cartesian product of x and y.\n\nThis function returns the values:\n\nwhere the points `(a, b)` consist of all pairs formed by taking `a` from `x`\nand `b` from `y`. The resulting points form a grid with `x` in the first\ndimension and `y` in the second.\n\nThe parameters `x` and `y` are converted to arrays only if they are tuples or\na lists, otherwise they are treated as a scalars. In either case, either `x`\nand `y` or their elements must support multiplication and addition both with\nthemselves and with the elements of `c`.\n\nIf `c` has fewer than two dimensions, ones are implicitly appended to its\nshape to make it 2-D. The shape of the result will be c.shape[2:] + x.shape +\ny.shape.\n\nThe two dimensional series is evaluated at the points in the Cartesian product\nof `x` and `y`. If `x` or `y` is a list or tuple, it is first converted to an\nndarray, otherwise it is left unchanged and, if it isn\u2019t an ndarray, it is\ntreated as a scalar.\n\nArray of coefficients ordered so that the coefficients for terms of degree i,j\nare contained in `c[i,j]`. If `c` has dimension greater than two the remaining\nindices enumerate multiple sets of coefficients.\n\nThe values of the two dimensional polynomial at points in the Cartesian\nproduct of `x` and `y`.\n\nSee also\n\nNew in version 1.7.0.\n\n"}, {"name": "polynomial.polynomial.polygrid3d()", "path": "reference/generated/numpy.polynomial.polynomial.polygrid3d", "type": "numpy.polynomial.polynomial.polygrid3d", "text": "\nEvaluate a 3-D polynomial on the Cartesian product of x, y and z.\n\nThis function returns the values:\n\nwhere the points `(a, b, c)` consist of all triples formed by taking `a` from\n`x`, `b` from `y`, and `c` from `z`. The resulting points form a grid with `x`\nin the first dimension, `y` in the second, and `z` in the third.\n\nThe parameters `x`, `y`, and `z` are converted to arrays only if they are\ntuples or a lists, otherwise they are treated as a scalars. In either case,\neither `x`, `y`, and `z` or their elements must support multiplication and\naddition both with themselves and with the elements of `c`.\n\nIf `c` has fewer than three dimensions, ones are implicitly appended to its\nshape to make it 3-D. The shape of the result will be c.shape[3:] + x.shape +\ny.shape + z.shape.\n\nThe three dimensional series is evaluated at the points in the Cartesian\nproduct of `x`, `y`, and `z`. If `x`,`y`, or `z` is a list or tuple, it is\nfirst converted to an ndarray, otherwise it is left unchanged and, if it isn\u2019t\nan ndarray, it is treated as a scalar.\n\nArray of coefficients ordered so that the coefficients for terms of degree i,j\nare contained in `c[i,j]`. If `c` has dimension greater than two the remaining\nindices enumerate multiple sets of coefficients.\n\nThe values of the two dimensional polynomial at points in the Cartesian\nproduct of `x` and `y`.\n\nSee also\n\nNew in version 1.7.0.\n\n"}, {"name": "polynomial.polynomial.polyint()", "path": "reference/generated/numpy.polynomial.polynomial.polyint", "type": "numpy.polynomial.polynomial.polyint", "text": "\nIntegrate a polynomial.\n\nReturns the polynomial coefficients `c` integrated `m` times from `lbnd` along\n`axis`. At each iteration the resulting series is multiplied by `scl` and an\nintegration constant, `k`, is added. The scaling factor is for use in a linear\nchange of variable. (\u201cBuyer beware\u201d: note that, depending on what one is\ndoing, one may want `scl` to be the reciprocal of what one might expect; for\nmore information, see the Notes section below.) The argument `c` is an array\nof coefficients, from low to high degree along each axis, e.g., [1,2,3]\nrepresents the polynomial `1 + 2*x + 3*x**2` while [[1,2],[1,2]] represents `1\n+ 1*x + 2*y + 2*x*y` if axis=0 is `x` and axis=1 is `y`.\n\n1-D array of polynomial coefficients, ordered from low to high.\n\nOrder of integration, must be positive. (Default: 1)\n\nIntegration constant(s). The value of the first integral at zero is the first\nvalue in the list, the value of the second integral at zero is the second\nvalue, etc. If `k == []` (the default), all constants are set to zero. If `m\n== 1`, a single scalar can be given instead of a list.\n\nThe lower bound of the integral. (Default: 0)\n\nFollowing each integration the result is multiplied by `scl` before the\nintegration constant is added. (Default: 1)\n\nAxis over which the integral is taken. (Default: 0).\n\nNew in version 1.7.0.\n\nCoefficient array of the integral.\n\nIf `m < 1`, `len(k) > m`, `np.ndim(lbnd) != 0`, or `np.ndim(scl) != 0`.\n\nSee also\n\nNote that the result of each integration is multiplied by `scl`. Why is this\nimportant to note? Say one is making a linear change of variable \\\\(u = ax +\nb\\\\) in an integral relative to `x`. Then \\\\(dx = du/a\\\\), so one will need to\nset `scl` equal to \\\\(1/a\\\\) \\- perhaps not what one would have first thought.\n\n"}, {"name": "polynomial.polynomial.polyline()", "path": "reference/generated/numpy.polynomial.polynomial.polyline", "type": "numpy.polynomial.polynomial.polyline", "text": "\nReturns an array representing a linear polynomial.\n\nThe \u201cy-intercept\u201d and \u201cslope\u201d of the line, respectively.\n\nThis module\u2019s representation of the linear polynomial `off + scl*x`.\n\nSee also\n\n"}, {"name": "polynomial.polynomial.polymul()", "path": "reference/generated/numpy.polynomial.polynomial.polymul", "type": "numpy.polynomial.polynomial.polymul", "text": "\nMultiply one polynomial by another.\n\nReturns the product of two polynomials `c1` * `c2`. The arguments are\nsequences of coefficients, from lowest order term to highest, e.g., [1,2,3]\nrepresents the polynomial `1 + 2*x + 3*x**2.`\n\n1-D arrays of coefficients representing a polynomial, relative to the\n\u201cstandard\u201d basis, and ordered from lowest order term to highest.\n\nOf the coefficients of their product.\n\nSee also\n\n"}, {"name": "polynomial.polynomial.polymulx()", "path": "reference/generated/numpy.polynomial.polynomial.polymulx", "type": "numpy.polynomial.polynomial.polymulx", "text": "\nMultiply a polynomial by x.\n\nMultiply the polynomial `c` by x, where x is the independent variable.\n\n1-D array of polynomial coefficients ordered from low to high.\n\nArray representing the result of the multiplication.\n\nSee also\n\nNew in version 1.5.0.\n\n"}, {"name": "polynomial.polynomial.Polynomial.__call__()", "path": "reference/generated/numpy.polynomial.polynomial.polynomial.__call__", "type": "numpy.polynomial.polynomial.Polynomial", "text": "\nmethod\n\nCall self as a function.\n\n"}, {"name": "polynomial.polynomial.Polynomial.basis()", "path": "reference/generated/numpy.polynomial.polynomial.polynomial.basis", "type": "numpy.polynomial.polynomial.Polynomial", "text": "\nmethod\n\nSeries basis polynomial of degree `deg`.\n\nReturns the series representing the basis polynomial of degree `deg`.\n\nNew in version 1.7.0.\n\nDegree of the basis polynomial for the series. Must be >= 0.\n\nIf given, the array must be of the form `[beg, end]`, where `beg` and `end`\nare the endpoints of the domain. If None is given then the class domain is\nused. The default is None.\n\nIf given, the resulting array must be if the form `[beg, end]`, where `beg`\nand `end` are the endpoints of the window. If None is given then the class\nwindow is used. The default is None.\n\nA series with the coefficient of the `deg` term set to one and all others\nzero.\n\n"}, {"name": "polynomial.polynomial.Polynomial.cast()", "path": "reference/generated/numpy.polynomial.polynomial.polynomial.cast", "type": "numpy.polynomial.polynomial.Polynomial", "text": "\nmethod\n\nConvert series to series of this class.\n\nThe `series` is expected to be an instance of some polynomial series of one of\nthe types supported by by the numpy.polynomial module, but could be some other\nclass that supports the convert method.\n\nNew in version 1.7.0.\n\nThe series instance to be converted.\n\nIf given, the array must be of the form `[beg, end]`, where `beg` and `end`\nare the endpoints of the domain. If None is given then the class domain is\nused. The default is None.\n\nIf given, the resulting array must be if the form `[beg, end]`, where `beg`\nand `end` are the endpoints of the window. If None is given then the class\nwindow is used. The default is None.\n\nA series of the same kind as the calling class and equal to `series` when\nevaluated.\n\nSee also\n\nsimilar instance method\n\n"}, {"name": "polynomial.polynomial.Polynomial.convert()", "path": "reference/generated/numpy.polynomial.polynomial.polynomial.convert", "type": "numpy.polynomial.polynomial.Polynomial", "text": "\nmethod\n\nConvert series to a different kind and/or domain and/or window.\n\nThe domain of the converted series. If the value is None, the default domain\nof `kind` is used.\n\nThe polynomial series type class to which the current instance should be\nconverted. If kind is None, then the class of the current instance is used.\n\nThe window of the converted series. If the value is None, the default window\nof `kind` is used.\n\nThe returned class can be of different type than the current instance and/or\nhave a different domain and/or different window.\n\nConversion between domains and class types can result in numerically ill\ndefined series.\n\n"}, {"name": "polynomial.polynomial.Polynomial.copy()", "path": "reference/generated/numpy.polynomial.polynomial.polynomial.copy", "type": "numpy.polynomial.polynomial.Polynomial", "text": "\nmethod\n\nReturn a copy.\n\nCopy of self.\n\n"}, {"name": "polynomial.polynomial.Polynomial.cutdeg()", "path": "reference/generated/numpy.polynomial.polynomial.polynomial.cutdeg", "type": "numpy.polynomial.polynomial.Polynomial", "text": "\nmethod\n\nTruncate series to the given degree.\n\nReduce the degree of the series to `deg` by discarding the high order terms.\nIf `deg` is greater than the current degree a copy of the current series is\nreturned. This can be useful in least squares where the coefficients of the\nhigh degree terms may be very small.\n\nNew in version 1.5.0.\n\nThe series is reduced to degree `deg` by discarding the high order terms. The\nvalue of `deg` must be a non-negative integer.\n\nNew instance of series with reduced degree.\n\n"}, {"name": "polynomial.polynomial.Polynomial.degree()", "path": "reference/generated/numpy.polynomial.polynomial.polynomial.degree", "type": "numpy.polynomial.polynomial.Polynomial", "text": "\nmethod\n\nThe degree of the series.\n\nNew in version 1.5.0.\n\nDegree of the series, one less than the number of coefficients.\n\n"}, {"name": "polynomial.polynomial.Polynomial.deriv()", "path": "reference/generated/numpy.polynomial.polynomial.polynomial.deriv", "type": "numpy.polynomial.polynomial.Polynomial", "text": "\nmethod\n\nDifferentiate.\n\nReturn a series instance of that is the derivative of the current series.\n\nFind the derivative of order `m`.\n\nA new series representing the derivative. The domain is the same as the domain\nof the differentiated series.\n\n"}, {"name": "polynomial.polynomial.Polynomial.domain", "path": "reference/generated/numpy.polynomial.polynomial.polynomial.domain", "type": "Polynomials", "text": "\nattribute\n\n"}, {"name": "polynomial.polynomial.Polynomial.fit()", "path": "reference/generated/numpy.polynomial.polynomial.polynomial.fit", "type": "numpy.polynomial.polynomial.Polynomial", "text": "\nmethod\n\nLeast squares fit to data.\n\nReturn a series instance that is the least squares fit to the data `y` sampled\nat `x`. The domain of the returned instance can be specified and this will\noften result in a superior fit with less chance of ill conditioning.\n\nx-coordinates of the M sample points `(x[i], y[i])`.\n\ny-coordinates of the M sample points `(x[i], y[i])`.\n\nDegree(s) of the fitting polynomials. If `deg` is a single integer all terms\nup to and including the `deg`\u2019th term are included in the fit. For NumPy\nversions >= 1.11.0 a list of integers specifying the degrees of the terms to\ninclude may be used instead.\n\nDomain to use for the returned series. If `None`, then a minimal domain that\ncovers the points `x` is chosen. If `[]` the class domain is used. The default\nvalue was the class domain in NumPy 1.4 and `None` in later versions. The `[]`\noption was added in numpy 1.5.0.\n\nRelative condition number of the fit. Singular values smaller than this\nrelative to the largest singular value will be ignored. The default value is\nlen(x)*eps, where eps is the relative precision of the float type, about 2e-16\nin most cases.\n\nSwitch determining nature of return value. When it is False (the default) just\nthe coefficients are returned, when True diagnostic information from the\nsingular value decomposition is also returned.\n\nWeights. If not None, the weight `w[i]` applies to the unsquared residual\n`y[i] - y_hat[i]` at `x[i]`. Ideally the weights are chosen so that the errors\nof the products `w[i]*y[i]` all have the same variance. When using inverse-\nvariance weighting, use `w[i] = 1/sigma(y[i])`. The default value is None.\n\nNew in version 1.5.0.\n\nWindow to use for the returned series. The default value is the default class\ndomain\n\nNew in version 1.6.0.\n\nA series that represents the least squares fit to the data and has the domain\nand window specified in the call. If the coefficients for the unscaled and\nunshifted basis polynomials are of interest, do `new_series.convert().coef`.\n\nThese values are only returned if `full == True`\n\nFor more details, see `linalg.lstsq`.\n\n"}, {"name": "polynomial.polynomial.Polynomial.fromroots()", "path": "reference/generated/numpy.polynomial.polynomial.polynomial.fromroots", "type": "numpy.polynomial.polynomial.Polynomial", "text": "\nmethod\n\nReturn series instance that has the specified roots.\n\nReturns a series representing the product `(x - r[0])*(x - r[1])*...*(x -\nr[n-1])`, where `r` is a list of roots.\n\nList of roots.\n\nDomain for the resulting series. If None the domain is the interval from the\nsmallest root to the largest. If [] the domain is the class domain. The\ndefault is [].\n\nWindow for the returned series. If None the class window is used. The default\nis None.\n\nSeries with the specified roots.\n\n"}, {"name": "polynomial.polynomial.Polynomial.has_samecoef()", "path": "reference/generated/numpy.polynomial.polynomial.polynomial.has_samecoef", "type": "numpy.polynomial.polynomial.Polynomial", "text": "\nmethod\n\nCheck if coefficients match.\n\nNew in version 1.6.0.\n\nThe other class must have the `coef` attribute.\n\nTrue if the coefficients are the same, False otherwise.\n\n"}, {"name": "polynomial.polynomial.Polynomial.has_samedomain()", "path": "reference/generated/numpy.polynomial.polynomial.polynomial.has_samedomain", "type": "numpy.polynomial.polynomial.Polynomial", "text": "\nmethod\n\nCheck if domains match.\n\nNew in version 1.6.0.\n\nThe other class must have the `domain` attribute.\n\nTrue if the domains are the same, False otherwise.\n\n"}, {"name": "polynomial.polynomial.Polynomial.has_sametype()", "path": "reference/generated/numpy.polynomial.polynomial.polynomial.has_sametype", "type": "numpy.polynomial.polynomial.Polynomial", "text": "\nmethod\n\nCheck if types match.\n\nNew in version 1.7.0.\n\nClass instance.\n\nTrue if other is same class as self\n\n"}, {"name": "polynomial.polynomial.Polynomial.has_samewindow()", "path": "reference/generated/numpy.polynomial.polynomial.polynomial.has_samewindow", "type": "numpy.polynomial.polynomial.Polynomial", "text": "\nmethod\n\nCheck if windows match.\n\nNew in version 1.6.0.\n\nThe other class must have the `window` attribute.\n\nTrue if the windows are the same, False otherwise.\n\n"}, {"name": "polynomial.polynomial.Polynomial.identity()", "path": "reference/generated/numpy.polynomial.polynomial.polynomial.identity", "type": "numpy.polynomial.polynomial.Polynomial", "text": "\nmethod\n\nIdentity function.\n\nIf `p` is the returned series, then `p(x) == x` for all values of x.\n\nIf given, the array must be of the form `[beg, end]`, where `beg` and `end`\nare the endpoints of the domain. If None is given then the class domain is\nused. The default is None.\n\nIf given, the resulting array must be if the form `[beg, end]`, where `beg`\nand `end` are the endpoints of the window. If None is given then the class\nwindow is used. The default is None.\n\nSeries of representing the identity.\n\n"}, {"name": "polynomial.polynomial.Polynomial.integ()", "path": "reference/generated/numpy.polynomial.polynomial.polynomial.integ", "type": "numpy.polynomial.polynomial.Polynomial", "text": "\nmethod\n\nIntegrate.\n\nReturn a series instance that is the definite integral of the current series.\n\nThe number of integrations to perform.\n\nIntegration constants. The first constant is applied to the first integration,\nthe second to the second, and so on. The list of values must less than or\nequal to `m` in length and any missing values are set to zero.\n\nThe lower bound of the definite integral.\n\nA new series representing the integral. The domain is the same as the domain\nof the integrated series.\n\n"}, {"name": "polynomial.polynomial.Polynomial.linspace()", "path": "reference/generated/numpy.polynomial.polynomial.polynomial.linspace", "type": "numpy.polynomial.polynomial.Polynomial", "text": "\nmethod\n\nReturn x, y values at equally spaced points in domain.\n\nReturns the x, y values at `n` linearly spaced points across the domain. Here\ny is the value of the polynomial at the points x. By default the domain is the\nsame as that of the series instance. This method is intended mostly as a\nplotting aid.\n\nNew in version 1.5.0.\n\nNumber of point pairs to return. The default value is 100.\n\nIf not None, the specified domain is used instead of that of the calling\ninstance. It should be of the form `[beg,end]`. The default is None which case\nthe class domain is used.\n\nx is equal to linspace(self.domain[0], self.domain[1], n) and y is the series\nevaluated at element of x.\n\n"}, {"name": "polynomial.polynomial.Polynomial.mapparms()", "path": "reference/generated/numpy.polynomial.polynomial.polynomial.mapparms", "type": "numpy.polynomial.polynomial.Polynomial", "text": "\nmethod\n\nReturn the mapping parameters.\n\nThe returned values define a linear map `off + scl*x` that is applied to the\ninput arguments before the series is evaluated. The map depends on the\n`domain` and `window`; if the current `domain` is equal to the `window` the\nresulting map is the identity. If the coefficients of the series instance are\nto be used by themselves outside this class, then the linear function must be\nsubstituted for the `x` in the standard representation of the base\npolynomials.\n\nThe mapping function is defined by `off + scl*x`.\n\nIf the current domain is the interval `[l1, r1]` and the window is `[l2, r2]`,\nthen the linear mapping function `L` is defined by the equations:\n\n"}, {"name": "polynomial.polynomial.Polynomial.roots()", "path": "reference/generated/numpy.polynomial.polynomial.polynomial.roots", "type": "numpy.polynomial.polynomial.Polynomial", "text": "\nmethod\n\nReturn the roots of the series polynomial.\n\nCompute the roots for the series. Note that the accuracy of the roots decrease\nthe further outside the domain they lie.\n\nArray containing the roots of the series.\n\n"}, {"name": "polynomial.polynomial.Polynomial.trim()", "path": "reference/generated/numpy.polynomial.polynomial.polynomial.trim", "type": "numpy.polynomial.polynomial.Polynomial", "text": "\nmethod\n\nRemove trailing coefficients\n\nRemove trailing coefficients until a coefficient is reached whose absolute\nvalue greater than `tol` or the beginning of the series is reached. If all the\ncoefficients would be removed the series is set to `[0]`. A new series\ninstance is returned with the new coefficients. The current instance remains\nunchanged.\n\nAll trailing coefficients less than `tol` will be removed.\n\nNew instance of series with trimmed coefficients.\n\n"}, {"name": "polynomial.polynomial.Polynomial.truncate()", "path": "reference/generated/numpy.polynomial.polynomial.polynomial.truncate", "type": "numpy.polynomial.polynomial.Polynomial", "text": "\nmethod\n\nTruncate series to length `size`.\n\nReduce the series to length `size` by discarding the high degree terms. The\nvalue of `size` must be a positive integer. This can be useful in least\nsquares where the coefficients of the high degree terms may be very small.\n\nThe series is reduced to length `size` by discarding the high degree terms.\nThe value of `size` must be a positive integer.\n\nNew instance of series with truncated coefficients.\n\n"}, {"name": "polynomial.polynomial.polyone", "path": "reference/generated/numpy.polynomial.polynomial.polyone", "type": "numpy.polynomial.polynomial.polyone", "text": "\nAn array object represents a multidimensional, homogeneous array of fixed-size\nitems. An associated data-type object describes the format of each element in\nthe array (its byte-order, how many bytes it occupies in memory, whether it is\nan integer, a floating point number, or something else, etc.)\n\nArrays should be constructed using `array`, `zeros` or `empty` (refer to the\nSee Also section below). The parameters given here refer to a low-level method\n(`ndarray(\u2026)`) for instantiating an array.\n\nFor more information, refer to the `numpy` module and examine the methods and\nattributes of an array.\n\nShape of created array.\n\nAny object that can be interpreted as a numpy data type.\n\nUsed to fill the array with data.\n\nOffset of array data in buffer.\n\nStrides of data in memory.\n\nRow-major (C-style) or column-major (Fortran-style) order.\n\nSee also\n\nConstruct an array.\n\nCreate an array, each element of which is zero.\n\nCreate an array, but leave its allocated memory unchanged (i.e., it contains\n\u201cgarbage\u201d).\n\nCreate a data-type.\n\nAn ndarray alias generic w.r.t. its `dtype.type`.\n\nThere are two modes of creating an array using `__new__`:\n\nNo `__init__` method is needed because the array is fully initialized after\nthe `__new__` method.\n\nThese examples illustrate the low-level `ndarray` constructor. Refer to the\n`See Also` section above for easier ways of constructing an ndarray.\n\nFirst mode, `buffer` is None:\n\nSecond mode:\n\nTranspose of the array.\n\nThe array\u2019s elements, in memory.\n\nDescribes the format of the elements in the array.\n\nDictionary containing information related to memory use, e.g., \u2018C_CONTIGUOUS\u2019,\n\u2018OWNDATA\u2019, \u2018WRITEABLE\u2019, etc.\n\nFlattened version of the array as an iterator. The iterator allows\nassignments, e.g., `x.flat = 3` (See `ndarray.flat` for assignment examples;\nTODO).\n\nImaginary part of the array.\n\nReal part of the array.\n\nNumber of elements in the array.\n\nThe memory use of each array element in bytes.\n\nThe total number of bytes required to store the array data, i.e., `itemsize *\nsize`.\n\nThe array\u2019s number of dimensions.\n\nShape of the array.\n\nThe step-size required to move from one element to the next in memory. For\nexample, a contiguous `(3, 4)` array of type `int16` in C-order has strides\n`(8, 2)`. This implies that to move from element to element in memory requires\njumps of 2 bytes. To move from row-to-row, one needs to jump 8 bytes at a time\n(`2 * 4`).\n\nClass containing properties of the array needed for interaction with ctypes.\n\nIf the array is a view into another array, that array is its `base` (unless\nthat array is also a view). The `base` array is where the array data is\nactually stored.\n\n"}, {"name": "polynomial.polynomial.polypow()", "path": "reference/generated/numpy.polynomial.polynomial.polypow", "type": "numpy.polynomial.polynomial.polypow", "text": "\nRaise a polynomial to a power.\n\nReturns the polynomial `c` raised to the power `pow`. The argument `c` is a\nsequence of coefficients ordered from low to high. i.e., [1,2,3] is the series\n`1 + 2*x + 3*x**2.`\n\n1-D array of array of series coefficients ordered from low to high degree.\n\nPower to which the series will be raised\n\nMaximum power allowed. This is mainly to limit growth of the series to\nunmanageable size. Default is 16\n\nPower series of power.\n\nSee also\n\n"}, {"name": "polynomial.polynomial.polyroots()", "path": "reference/generated/numpy.polynomial.polynomial.polyroots", "type": "numpy.polynomial.polynomial.polyroots", "text": "\nCompute the roots of a polynomial.\n\nReturn the roots (a.k.a. \u201czeros\u201d) of the polynomial\n\n1-D array of polynomial coefficients.\n\nArray of the roots of the polynomial. If all the roots are real, then `out` is\nalso real, otherwise it is complex.\n\nSee also\n\nThe root estimates are obtained as the eigenvalues of the companion matrix,\nRoots far from the origin of the complex plane may have large errors due to\nthe numerical instability of the power series for such values. Roots with\nmultiplicity greater than 1 will also show larger errors as the value of the\nseries near such points is relatively insensitive to errors in the roots.\nIsolated roots near the origin can be improved by a few iterations of Newton\u2019s\nmethod.\n\n"}, {"name": "polynomial.polynomial.polysub()", "path": "reference/generated/numpy.polynomial.polynomial.polysub", "type": "numpy.polynomial.polynomial.polysub", "text": "\nSubtract one polynomial from another.\n\nReturns the difference of two polynomials `c1` \\- `c2`. The arguments are\nsequences of coefficients from lowest order term to highest, i.e., [1,2,3]\nrepresents the polynomial `1 + 2*x + 3*x**2`.\n\n1-D arrays of polynomial coefficients ordered from low to high.\n\nOf coefficients representing their difference.\n\nSee also\n\n"}, {"name": "polynomial.polynomial.polytrim()", "path": "reference/generated/numpy.polynomial.polynomial.polytrim", "type": "numpy.polynomial.polynomial.polytrim", "text": "\nRemove \u201csmall\u201d \u201ctrailing\u201d coefficients from a polynomial.\n\n\u201cSmall\u201d means \u201csmall in absolute value\u201d and is controlled by the parameter\n`tol`; \u201ctrailing\u201d means highest order coefficient(s), e.g., in `[0, 1, 1, 0,\n0]` (which represents `0 + x + x**2 + 0*x**3 + 0*x**4`) both the 3-rd and 4-th\norder coefficients would be \u201ctrimmed.\u201d\n\n1-d array of coefficients, ordered from lowest order to highest.\n\nTrailing (i.e., highest order) elements with absolute value less than or equal\nto `tol` (default value is zero) are removed.\n\n1-d array with trailing zeros removed. If the resulting series would be empty,\na series containing a single zero is returned.\n\nIf `tol` < 0\n\nSee also\n\n"}, {"name": "polynomial.polynomial.polyval()", "path": "reference/generated/numpy.polynomial.polynomial.polyval", "type": "numpy.polynomial.polynomial.polyval", "text": "\nEvaluate a polynomial at points x.\n\nIf `c` is of length `n + 1`, this function returns the value\n\nThe parameter `x` is converted to an array only if it is a tuple or a list,\notherwise it is treated as a scalar. In either case, either `x` or its\nelements must support multiplication and addition both with themselves and\nwith the elements of `c`.\n\nIf `c` is a 1-D array, then `p(x)` will have the same shape as `x`. If `c` is\nmultidimensional, then the shape of the result depends on the value of\n`tensor`. If `tensor` is true the shape will be c.shape[1:] + x.shape. If\n`tensor` is false the shape will be c.shape[1:]. Note that scalars have shape\n(,).\n\nTrailing zeros in the coefficients will be used in the evaluation, so they\nshould be avoided if efficiency is a concern.\n\nIf `x` is a list or tuple, it is converted to an ndarray, otherwise it is left\nunchanged and treated as a scalar. In either case, `x` or its elements must\nsupport addition and multiplication with with themselves and with the elements\nof `c`.\n\nArray of coefficients ordered so that the coefficients for terms of degree n\nare contained in c[n]. If `c` is multidimensional the remaining indices\nenumerate multiple polynomials. In the two dimensional case the coefficients\nmay be thought of as stored in the columns of `c`.\n\nIf True, the shape of the coefficient array is extended with ones on the\nright, one for each dimension of `x`. Scalars have dimension 0 for this\naction. The result is that every column of coefficients in `c` is evaluated\nfor every element of `x`. If False, `x` is broadcast over the columns of `c`\nfor the evaluation. This keyword is useful when `c` is multidimensional. The\ndefault value is True.\n\nNew in version 1.7.0.\n\nThe shape of the returned array is described above.\n\nSee also\n\nThe evaluation uses Horner\u2019s method.\n\n"}, {"name": "polynomial.polynomial.polyval2d()", "path": "reference/generated/numpy.polynomial.polynomial.polyval2d", "type": "numpy.polynomial.polynomial.polyval2d", "text": "\nEvaluate a 2-D polynomial at points (x, y).\n\nThis function returns the value\n\nThe parameters `x` and `y` are converted to arrays only if they are tuples or\na lists, otherwise they are treated as a scalars and they must have the same\nshape after conversion. In either case, either `x` and `y` or their elements\nmust support multiplication and addition both with themselves and with the\nelements of `c`.\n\nIf `c` has fewer than two dimensions, ones are implicitly appended to its\nshape to make it 2-D. The shape of the result will be c.shape[2:] + x.shape.\n\nThe two dimensional series is evaluated at the points `(x, y)`, where `x` and\n`y` must have the same shape. If `x` or `y` is a list or tuple, it is first\nconverted to an ndarray, otherwise it is left unchanged and, if it isn\u2019t an\nndarray, it is treated as a scalar.\n\nArray of coefficients ordered so that the coefficient of the term of multi-\ndegree i,j is contained in `c[i,j]`. If `c` has dimension greater than two the\nremaining indices enumerate multiple sets of coefficients.\n\nThe values of the two dimensional polynomial at points formed with pairs of\ncorresponding values from `x` and `y`.\n\nSee also\n\nNew in version 1.7.0.\n\n"}, {"name": "polynomial.polynomial.polyval3d()", "path": "reference/generated/numpy.polynomial.polynomial.polyval3d", "type": "numpy.polynomial.polynomial.polyval3d", "text": "\nEvaluate a 3-D polynomial at points (x, y, z).\n\nThis function returns the values:\n\nThe parameters `x`, `y`, and `z` are converted to arrays only if they are\ntuples or a lists, otherwise they are treated as a scalars and they must have\nthe same shape after conversion. In either case, either `x`, `y`, and `z` or\ntheir elements must support multiplication and addition both with themselves\nand with the elements of `c`.\n\nIf `c` has fewer than 3 dimensions, ones are implicitly appended to its shape\nto make it 3-D. The shape of the result will be c.shape[3:] + x.shape.\n\nThe three dimensional series is evaluated at the points `(x, y, z)`, where\n`x`, `y`, and `z` must have the same shape. If any of `x`, `y`, or `z` is a\nlist or tuple, it is first converted to an ndarray, otherwise it is left\nunchanged and if it isn\u2019t an ndarray it is treated as a scalar.\n\nArray of coefficients ordered so that the coefficient of the term of multi-\ndegree i,j,k is contained in `c[i,j,k]`. If `c` has dimension greater than 3\nthe remaining indices enumerate multiple sets of coefficients.\n\nThe values of the multidimensional polynomial on points formed with triples of\ncorresponding values from `x`, `y`, and `z`.\n\nSee also\n\nNew in version 1.7.0.\n\n"}, {"name": "polynomial.polynomial.polyvalfromroots()", "path": "reference/generated/numpy.polynomial.polynomial.polyvalfromroots", "type": "numpy.polynomial.polynomial.polyvalfromroots", "text": "\nEvaluate a polynomial specified by its roots at points x.\n\nIf `r` is of length `N`, this function returns the value\n\nThe parameter `x` is converted to an array only if it is a tuple or a list,\notherwise it is treated as a scalar. In either case, either `x` or its\nelements must support multiplication and addition both with themselves and\nwith the elements of `r`.\n\nIf `r` is a 1-D array, then `p(x)` will have the same shape as `x`. If `r` is\nmultidimensional, then the shape of the result depends on the value of\n`tensor`. If `tensor is ``True`` the shape will be r.shape[1:] + x.shape; that\nis, each polynomial is evaluated at every value of `x`. If `tensor` is\n`False`, the shape will be r.shape[1:]; that is, each polynomial is evaluated\nonly for the corresponding broadcast value of `x`. Note that scalars have\nshape (,).\n\nNew in version 1.12.\n\nIf `x` is a list or tuple, it is converted to an ndarray, otherwise it is left\nunchanged and treated as a scalar. In either case, `x` or its elements must\nsupport addition and multiplication with with themselves and with the elements\nof `r`.\n\nArray of roots. If `r` is multidimensional the first index is the root index,\nwhile the remaining indices enumerate multiple polynomials. For instance, in\nthe two dimensional case the roots of each polynomial may be thought of as\nstored in the columns of `r`.\n\nIf True, the shape of the roots array is extended with ones on the right, one\nfor each dimension of `x`. Scalars have dimension 0 for this action. The\nresult is that every column of coefficients in `r` is evaluated for every\nelement of `x`. If False, `x` is broadcast over the columns of `r` for the\nevaluation. This keyword is useful when `r` is multidimensional. The default\nvalue is True.\n\nThe shape of the returned array is described above.\n\nSee also\n\n"}, {"name": "polynomial.polynomial.polyvander()", "path": "reference/generated/numpy.polynomial.polynomial.polyvander", "type": "numpy.polynomial.polynomial.polyvander", "text": "\nVandermonde matrix of given degree.\n\nReturns the Vandermonde matrix of degree `deg` and sample points `x`. The\nVandermonde matrix is defined by\n\nwhere `0 <= i <= deg`. The leading indices of `V` index the elements of `x`\nand the last index is the power of `x`.\n\nIf `c` is a 1-D array of coefficients of length `n + 1` and `V` is the matrix\n`V = polyvander(x, n)`, then `np.dot(V, c)` and `polyval(x, c)` are the same\nup to roundoff. This equivalence is useful both for least squares fitting and\nfor the evaluation of a large number of polynomials of the same degree and\nsample points.\n\nArray of points. The dtype is converted to float64 or complex128 depending on\nwhether any of the elements are complex. If `x` is scalar it is converted to a\n1-D array.\n\nDegree of the resulting matrix.\n\nThe Vandermonde matrix. The shape of the returned matrix is `x.shape + (deg +\n1,)`, where the last index is the power of `x`. The dtype will be the same as\nthe converted `x`.\n\nSee also\n\n"}, {"name": "polynomial.polynomial.polyvander2d()", "path": "reference/generated/numpy.polynomial.polynomial.polyvander2d", "type": "numpy.polynomial.polynomial.polyvander2d", "text": "\nPseudo-Vandermonde matrix of given degrees.\n\nReturns the pseudo-Vandermonde matrix of degrees `deg` and sample points `(x,\ny)`. The pseudo-Vandermonde matrix is defined by\n\nwhere `0 <= i <= deg[0]` and `0 <= j <= deg[1]`. The leading indices of `V`\nindex the points `(x, y)` and the last index encodes the powers of `x` and\n`y`.\n\nIf `V = polyvander2d(x, y, [xdeg, ydeg])`, then the columns of `V` correspond\nto the elements of a 2-D coefficient array `c` of shape (xdeg + 1, ydeg + 1)\nin the order\n\nand `np.dot(V, c.flat)` and `polyval2d(x, y, c)` will be the same up to\nroundoff. This equivalence is useful both for least squares fitting and for\nthe evaluation of a large number of 2-D polynomials of the same degrees and\nsample points.\n\nArrays of point coordinates, all of the same shape. The dtypes will be\nconverted to either float64 or complex128 depending on whether any of the\nelements are complex. Scalars are converted to 1-D arrays.\n\nList of maximum degrees of the form [x_deg, y_deg].\n\nThe shape of the returned matrix is `x.shape + (order,)`, where \\\\(order =\n(deg[0]+1)*(deg([1]+1)\\\\). The dtype will be the same as the converted `x` and\n`y`.\n\nSee also\n\n"}, {"name": "polynomial.polynomial.polyvander3d()", "path": "reference/generated/numpy.polynomial.polynomial.polyvander3d", "type": "numpy.polynomial.polynomial.polyvander3d", "text": "\nPseudo-Vandermonde matrix of given degrees.\n\nReturns the pseudo-Vandermonde matrix of degrees `deg` and sample points `(x,\ny, z)`. If `l, m, n` are the given degrees in `x, y, z`, then The pseudo-\nVandermonde matrix is defined by\n\nwhere `0 <= i <= l`, `0 <= j <= m`, and `0 <= j <= n`. The leading indices of\n`V` index the points `(x, y, z)` and the last index encodes the powers of `x`,\n`y`, and `z`.\n\nIf `V = polyvander3d(x, y, z, [xdeg, ydeg, zdeg])`, then the columns of `V`\ncorrespond to the elements of a 3-D coefficient array `c` of shape (xdeg + 1,\nydeg + 1, zdeg + 1) in the order\n\nand `np.dot(V, c.flat)` and `polyval3d(x, y, z, c)` will be the same up to\nroundoff. This equivalence is useful both for least squares fitting and for\nthe evaluation of a large number of 3-D polynomials of the same degrees and\nsample points.\n\nArrays of point coordinates, all of the same shape. The dtypes will be\nconverted to either float64 or complex128 depending on whether any of the\nelements are complex. Scalars are converted to 1-D arrays.\n\nList of maximum degrees of the form [x_deg, y_deg, z_deg].\n\nThe shape of the returned matrix is `x.shape + (order,)`, where \\\\(order =\n(deg[0]+1)*(deg([1]+1)*(deg[2]+1)\\\\). The dtype will be the same as the\nconverted `x`, `y`, and `z`.\n\nSee also\n\nNew in version 1.7.0.\n\n"}, {"name": "polynomial.polynomial.polyx", "path": "reference/generated/numpy.polynomial.polynomial.polyx", "type": "numpy.polynomial.polynomial.polyx", "text": "\nAn array object represents a multidimensional, homogeneous array of fixed-size\nitems. An associated data-type object describes the format of each element in\nthe array (its byte-order, how many bytes it occupies in memory, whether it is\nan integer, a floating point number, or something else, etc.)\n\nArrays should be constructed using `array`, `zeros` or `empty` (refer to the\nSee Also section below). The parameters given here refer to a low-level method\n(`ndarray(\u2026)`) for instantiating an array.\n\nFor more information, refer to the `numpy` module and examine the methods and\nattributes of an array.\n\nShape of created array.\n\nAny object that can be interpreted as a numpy data type.\n\nUsed to fill the array with data.\n\nOffset of array data in buffer.\n\nStrides of data in memory.\n\nRow-major (C-style) or column-major (Fortran-style) order.\n\nSee also\n\nConstruct an array.\n\nCreate an array, each element of which is zero.\n\nCreate an array, but leave its allocated memory unchanged (i.e., it contains\n\u201cgarbage\u201d).\n\nCreate a data-type.\n\nAn ndarray alias generic w.r.t. its `dtype.type`.\n\nThere are two modes of creating an array using `__new__`:\n\nNo `__init__` method is needed because the array is fully initialized after\nthe `__new__` method.\n\nThese examples illustrate the low-level `ndarray` constructor. Refer to the\n`See Also` section above for easier ways of constructing an ndarray.\n\nFirst mode, `buffer` is None:\n\nSecond mode:\n\nTranspose of the array.\n\nThe array\u2019s elements, in memory.\n\nDescribes the format of the elements in the array.\n\nDictionary containing information related to memory use, e.g., \u2018C_CONTIGUOUS\u2019,\n\u2018OWNDATA\u2019, \u2018WRITEABLE\u2019, etc.\n\nFlattened version of the array as an iterator. The iterator allows\nassignments, e.g., `x.flat = 3` (See `ndarray.flat` for assignment examples;\nTODO).\n\nImaginary part of the array.\n\nReal part of the array.\n\nNumber of elements in the array.\n\nThe memory use of each array element in bytes.\n\nThe total number of bytes required to store the array data, i.e., `itemsize *\nsize`.\n\nThe array\u2019s number of dimensions.\n\nShape of the array.\n\nThe step-size required to move from one element to the next in memory. For\nexample, a contiguous `(3, 4)` array of type `int16` in C-order has strides\n`(8, 2)`. This implies that to move from element to element in memory requires\njumps of 2 bytes. To move from row-to-row, one needs to jump 8 bytes at a time\n(`2 * 4`).\n\nClass containing properties of the array needed for interaction with ctypes.\n\nIf the array is a view into another array, that array is its `base` (unless\nthat array is also a view). The `base` array is where the array data is\nactually stored.\n\n"}, {"name": "polynomial.polynomial.polyzero", "path": "reference/generated/numpy.polynomial.polynomial.polyzero", "type": "numpy.polynomial.polynomial.polyzero", "text": "\nAn array object represents a multidimensional, homogeneous array of fixed-size\nitems. An associated data-type object describes the format of each element in\nthe array (its byte-order, how many bytes it occupies in memory, whether it is\nan integer, a floating point number, or something else, etc.)\n\nArrays should be constructed using `array`, `zeros` or `empty` (refer to the\nSee Also section below). The parameters given here refer to a low-level method\n(`ndarray(\u2026)`) for instantiating an array.\n\nFor more information, refer to the `numpy` module and examine the methods and\nattributes of an array.\n\nShape of created array.\n\nAny object that can be interpreted as a numpy data type.\n\nUsed to fill the array with data.\n\nOffset of array data in buffer.\n\nStrides of data in memory.\n\nRow-major (C-style) or column-major (Fortran-style) order.\n\nSee also\n\nConstruct an array.\n\nCreate an array, each element of which is zero.\n\nCreate an array, but leave its allocated memory unchanged (i.e., it contains\n\u201cgarbage\u201d).\n\nCreate a data-type.\n\nAn ndarray alias generic w.r.t. its `dtype.type`.\n\nThere are two modes of creating an array using `__new__`:\n\nNo `__init__` method is needed because the array is fully initialized after\nthe `__new__` method.\n\nThese examples illustrate the low-level `ndarray` constructor. Refer to the\n`See Also` section above for easier ways of constructing an ndarray.\n\nFirst mode, `buffer` is None:\n\nSecond mode:\n\nTranspose of the array.\n\nThe array\u2019s elements, in memory.\n\nDescribes the format of the elements in the array.\n\nDictionary containing information related to memory use, e.g., \u2018C_CONTIGUOUS\u2019,\n\u2018OWNDATA\u2019, \u2018WRITEABLE\u2019, etc.\n\nFlattened version of the array as an iterator. The iterator allows\nassignments, e.g., `x.flat = 3` (See `ndarray.flat` for assignment examples;\nTODO).\n\nImaginary part of the array.\n\nReal part of the array.\n\nNumber of elements in the array.\n\nThe memory use of each array element in bytes.\n\nThe total number of bytes required to store the array data, i.e., `itemsize *\nsize`.\n\nThe array\u2019s number of dimensions.\n\nShape of the array.\n\nThe step-size required to move from one element to the next in memory. For\nexample, a contiguous `(3, 4)` array of type `int16` in C-order has strides\n`(8, 2)`. This implies that to move from element to element in memory requires\njumps of 2 bytes. To move from row-to-row, one needs to jump 8 bytes at a time\n(`2 * 4`).\n\nClass containing properties of the array needed for interaction with ctypes.\n\nIf the array is a view into another array, that array is its `base` (unless\nthat array is also a view). The `base` array is where the array data is\nactually stored.\n\n"}, {"name": "polynomial.polyutils.as_series()", "path": "reference/generated/numpy.polynomial.polyutils.as_series", "type": "numpy.polynomial.polyutils.as_series", "text": "\nReturn argument as a list of 1-d arrays.\n\nThe returned list contains array(s) of dtype double, complex double, or\nobject. A 1-d argument of shape `(N,)` is parsed into `N` arrays of size one;\na 2-d argument of shape `(M,N)` is parsed into `M` arrays of size `N` (i.e.,\nis \u201cparsed by row\u201d); and a higher dimensional array raises a Value Error if it\nis not first reshaped into either a 1-d or 2-d array.\n\nA 1- or 2-d array_like\n\nWhen True, trailing zeros are removed from the inputs. When False, the inputs\nare passed through intact.\n\nA copy of the input data as a list of 1-d arrays.\n\nRaised when `as_series` cannot convert its input to 1-d arrays, or at least\none of the resulting arrays is empty.\n\n"}, {"name": "polynomial.polyutils.getdomain()", "path": "reference/generated/numpy.polynomial.polyutils.getdomain", "type": "numpy.polynomial.polyutils.getdomain", "text": "\nReturn a domain suitable for given abscissae.\n\nFind a domain suitable for a polynomial or Chebyshev series defined at the\nvalues supplied.\n\n1-d array of abscissae whose domain will be determined.\n\n1-d array containing two values. If the inputs are complex, then the two\nreturned points are the lower left and upper right corners of the smallest\nrectangle (aligned with the axes) in the complex plane containing the points\n`x`. If the inputs are real, then the two points are the ends of the smallest\ninterval containing the points `x`.\n\nSee also\n\n"}, {"name": "polynomial.polyutils.mapdomain()", "path": "reference/generated/numpy.polynomial.polyutils.mapdomain", "type": "numpy.polynomial.polyutils.mapdomain", "text": "\nApply linear map to input points.\n\nThe linear map `offset + scale*x` that maps the domain `old` to the domain\n`new` is applied to the points `x`.\n\nPoints to be mapped. If `x` is a subtype of ndarray the subtype will be\npreserved.\n\nThe two domains that determine the map. Each must (successfully) convert to\n1-d arrays containing precisely two values.\n\nArray of points of the same shape as `x`, after application of the linear map\nbetween the two domains.\n\nSee also\n\nEffectively, this implements:\n\nwhere\n\nAlso works for complex numbers (and thus can be used to map any line in the\ncomplex plane to any other line therein).\n\n"}, {"name": "polynomial.polyutils.mapparms()", "path": "reference/generated/numpy.polynomial.polyutils.mapparms", "type": "numpy.polynomial.polyutils.mapparms", "text": "\nLinear map parameters between domains.\n\nReturn the parameters of the linear map `offset + scale*x` that maps `old` to\n`new` such that `old[i] -> new[i]`, `i = 0, 1`.\n\nDomains. Each domain must (successfully) convert to a 1-d array containing\nprecisely two values.\n\nThe map `L(x) = offset + scale*x` maps the first domain to the second.\n\nSee also\n\nAlso works for complex numbers, and thus can be used to calculate the\nparameters required to map any line in the complex plane to any other line\ntherein.\n\n"}, {"name": "polynomial.polyutils.RankWarning", "path": "reference/generated/numpy.polynomial.polyutils.rankwarning", "type": "numpy.polynomial.polyutils.RankWarning", "text": "\nIssued by chebfit when the design matrix is rank deficient.\n\n"}, {"name": "polynomial.polyutils.trimcoef()", "path": "reference/generated/numpy.polynomial.polyutils.trimcoef", "type": "numpy.polynomial.polyutils.trimcoef", "text": "\nRemove \u201csmall\u201d \u201ctrailing\u201d coefficients from a polynomial.\n\n\u201cSmall\u201d means \u201csmall in absolute value\u201d and is controlled by the parameter\n`tol`; \u201ctrailing\u201d means highest order coefficient(s), e.g., in `[0, 1, 1, 0,\n0]` (which represents `0 + x + x**2 + 0*x**3 + 0*x**4`) both the 3-rd and 4-th\norder coefficients would be \u201ctrimmed.\u201d\n\n1-d array of coefficients, ordered from lowest order to highest.\n\nTrailing (i.e., highest order) elements with absolute value less than or equal\nto `tol` (default value is zero) are removed.\n\n1-d array with trailing zeros removed. If the resulting series would be empty,\na series containing a single zero is returned.\n\nIf `tol` < 0\n\nSee also\n\n"}, {"name": "polynomial.polyutils.trimseq()", "path": "reference/generated/numpy.polynomial.polyutils.trimseq", "type": "numpy.polynomial.polyutils.trimseq", "text": "\nRemove small Poly series coefficients.\n\nSequence of Poly series coefficients. This routine fails for empty sequences.\n\nSubsequence with trailing zeros removed. If the resulting sequence would be\nempty, return the first element. The returned sequence may or may not be a\nview.\n\nDo not lose the type info if the sequence contains unknown objects.\n\n"}, {"name": "polynomial.set_default_printstyle()", "path": "reference/generated/numpy.polynomial.set_default_printstyle", "type": "Polynomials", "text": "\nSet the default format for the string representation of polynomials.\n\nValues for `style` must be valid inputs to `__format__`, i.e. \u2018ascii\u2019 or\n\u2018unicode\u2019.\n\nFormat string for default printing style. Must be either \u2018ascii\u2019 or \u2018unicode\u2019.\n\nThe default format depends on the platform: \u2018unicode\u2019 is used on Unix-based\nsystems and \u2018ascii\u2019 on Windows. This determination is based on default font\nsupport for the unicode superscript and subscript ranges.\n\n"}, {"name": "Polyutils", "path": "reference/routines.polynomials.polyutils", "type": "Polyutils", "text": "\nUtility classes and functions for the polynomial modules.\n\nThis module provides: error and warning objects; a polynomial base class; and\nsome routines used in both the `polynomial` and `chebyshev` modules.\n\n`RankWarning`\n\nIssued by chebfit when the design matrix is rank deficient.\n\n`as_series`(alist[, trim])\n\nReturn argument as a list of 1-d arrays.\n\n`trimseq`(seq)\n\nRemove small Poly series coefficients.\n\n`trimcoef`(c[, tol])\n\nRemove \"small\" \"trailing\" coefficients from a polynomial.\n\n`getdomain`(x)\n\nReturn a domain suitable for given abscissae.\n\n`mapdomain`(x, old, new)\n\nApply linear map to input points.\n\n`mapparms`(old, new)\n\nLinear map parameters between domains.\n\n"}, {"name": "Power Series (numpy.polynomial.polynomial)", "path": "reference/routines.polynomials.polynomial", "type": "Power Series ( \n        \n         numpy.polynomial.polynomial\n        \n        )", "text": "\nThis module provides a number of objects (mostly functions) useful for dealing\nwith polynomials, including a `Polynomial` class that encapsulates the usual\narithmetic operations. (General information on how this module represents and\nworks with polynomial objects is in the docstring for its \u201cparent\u201d sub-\npackage, `numpy.polynomial`).\n\n`Polynomial`(coef[, domain, window])\n\nA power series class.\n\n`polydomain`\n\nAn array object represents a multidimensional, homogeneous array of fixed-size\nitems.\n\n`polyzero`\n\nAn array object represents a multidimensional, homogeneous array of fixed-size\nitems.\n\n`polyone`\n\nAn array object represents a multidimensional, homogeneous array of fixed-size\nitems.\n\n`polyx`\n\nAn array object represents a multidimensional, homogeneous array of fixed-size\nitems.\n\n`polyadd`(c1, c2)\n\nAdd one polynomial to another.\n\n`polysub`(c1, c2)\n\nSubtract one polynomial from another.\n\n`polymulx`(c)\n\nMultiply a polynomial by x.\n\n`polymul`(c1, c2)\n\nMultiply one polynomial by another.\n\n`polydiv`(c1, c2)\n\nDivide one polynomial by another.\n\n`polypow`(c, pow[, maxpower])\n\nRaise a polynomial to a power.\n\n`polyval`(x, c[, tensor])\n\nEvaluate a polynomial at points x.\n\n`polyval2d`(x, y, c)\n\nEvaluate a 2-D polynomial at points (x, y).\n\n`polyval3d`(x, y, z, c)\n\nEvaluate a 3-D polynomial at points (x, y, z).\n\n`polygrid2d`(x, y, c)\n\nEvaluate a 2-D polynomial on the Cartesian product of x and y.\n\n`polygrid3d`(x, y, z, c)\n\nEvaluate a 3-D polynomial on the Cartesian product of x, y and z.\n\n`polyder`(c[, m, scl, axis])\n\nDifferentiate a polynomial.\n\n`polyint`(c[, m, k, lbnd, scl, axis])\n\nIntegrate a polynomial.\n\n`polyfromroots`(roots)\n\nGenerate a monic polynomial with given roots.\n\n`polyroots`(c)\n\nCompute the roots of a polynomial.\n\n`polyvalfromroots`(x, r[, tensor])\n\nEvaluate a polynomial specified by its roots at points x.\n\n`polyvander`(x, deg)\n\nVandermonde matrix of given degree.\n\n`polyvander2d`(x, y, deg)\n\nPseudo-Vandermonde matrix of given degrees.\n\n`polyvander3d`(x, y, z, deg)\n\nPseudo-Vandermonde matrix of given degrees.\n\n`polycompanion`(c)\n\nReturn the companion matrix of c.\n\n`polyfit`(x, y, deg[, rcond, full, w])\n\nLeast-squares fit of a polynomial to data.\n\n`polytrim`(c[, tol])\n\nRemove \"small\" \"trailing\" coefficients from a polynomial.\n\n`polyline`(off, scl)\n\nReturns an array representing a linear polynomial.\n\n`numpy.polynomial`\n\n"}, {"name": "property finfo.machar", "path": "reference/generated/numpy.finfo.machar", "type": "NumPy.finfo.machar", "text": "\nproperty\n\nThe object which calculated these parameters and holds more detailed\ninformation.\n\nDeprecated since version 1.22.\n\n"}, {"name": "property finfo.smallest_normal", "path": "reference/generated/numpy.finfo.smallest_normal", "type": "NumPy.finfo.smallest_normal", "text": "\nproperty\n\nReturn the value for the smallest normal.\n\nValue for the smallest normal.\n\nIf the calculated value for the smallest normal is requested for double-\ndouble.\n\n"}, {"name": "property finfo.tiny", "path": "reference/generated/numpy.finfo.tiny", "type": "NumPy.finfo.tiny", "text": "\nproperty\n\nReturn the value for tiny, alias of smallest_normal.\n\nValue for the smallest normal, alias of smallest_normal.\n\nIf the calculated value for the smallest normal is requested for double-\ndouble.\n\n"}, {"name": "property iinfo.max", "path": "reference/generated/numpy.iinfo.max", "type": "Data type routines", "text": "\nproperty\n\nMaximum value of given dtype.\n\n"}, {"name": "property iinfo.min", "path": "reference/generated/numpy.iinfo.min", "type": "Data type routines", "text": "\nproperty\n\nMinimum value of given dtype.\n\n"}, {"name": "property lib.Arrayterator.flat", "path": "reference/generated/numpy.lib.arrayterator.flat", "type": "Indexing routines", "text": "\nproperty\n\nA 1-D flat iterator for Arrayterator objects.\n\nThis iterator returns elements of the array to be iterated over in\n`Arrayterator` one by one. It is similar to `flatiter`.\n\nSee also\n\n"}, {"name": "property lib.Arrayterator.shape", "path": "reference/generated/numpy.lib.arrayterator.shape", "type": "Indexing routines", "text": "\nproperty\n\nThe shape of the array to be iterated over.\n\nFor an example, see `Arrayterator`.\n\n"}, {"name": "property ma.masked_array.mask", "path": "reference/generated/numpy.ma.masked_array.mask", "type": "numpy.ma.masked_array.mask", "text": "\nproperty\n\nCurrent mask.\n\n"}, {"name": "property ma.MaskedArray.dtype", "path": "reference/generated/numpy.ma.maskedarray.dtype", "type": "Masked arrays", "text": "\nproperty\n\nData-type of the array\u2019s elements.\n\nSee also\n\n"}, {"name": "property ma.MaskedArray.flat", "path": "reference/generated/numpy.ma.maskedarray.flat", "type": "Masked arrays", "text": "\nproperty\n\nReturn a flat iterator, or set a flattened version of self to value.\n\n"}, {"name": "property ma.MaskedArray.imag", "path": "reference/generated/numpy.ma.maskedarray.imag", "type": "Masked arrays", "text": "\nproperty\n\nThe imaginary part of the masked array.\n\nThis property is a view on the imaginary part of this `MaskedArray`.\n\nSee also\n\n"}, {"name": "property ma.MaskedArray.real", "path": "reference/generated/numpy.ma.maskedarray.real", "type": "Masked arrays", "text": "\nproperty\n\nThe real part of the masked array.\n\nThis property is a view on the real part of this `MaskedArray`.\n\nSee also\n\n"}, {"name": "property ma.MaskedArray.shape", "path": "reference/generated/numpy.ma.maskedarray.shape", "type": "Masked arrays", "text": "\nproperty\n\nTuple of array dimensions.\n\nThe shape property is usually used to get the current shape of an array, but\nmay also be used to reshape the array in-place by assigning a tuple of array\ndimensions to it. As with `numpy.reshape`, one of the new shape dimensions can\nbe -1, in which case its value is inferred from the size of the array and the\nremaining dimensions. Reshaping an array in-place will fail if a copy is\nrequired.\n\nSee also\n\nsimilar function\n\nsimilar method\n\n"}, {"name": "property ma.MaskedArray.T", "path": "reference/generated/numpy.ma.maskedarray.t", "type": "Masked arrays", "text": "\nproperty\n\nThe transposed array.\n\nSame as `self.transpose()`.\n\nSee also\n\n"}, {"name": "property matrix.A", "path": "reference/generated/numpy.matrix.a", "type": "numpy.matrix.A", "text": "\nproperty\n\nReturn `self` as an `ndarray` object.\n\nEquivalent to `np.asarray(self)`.\n\n`self` as an `ndarray`\n\n"}, {"name": "property matrix.A1", "path": "reference/generated/numpy.matrix.a1", "type": "Standard array subclasses", "text": "\nproperty\n\nReturn `self` as a flattened `ndarray`.\n\nEquivalent to `np.asarray(x).ravel()`\n\n`self`, 1-D, as an `ndarray`\n\n"}, {"name": "property matrix.H", "path": "reference/generated/numpy.matrix.h", "type": "numpy.matrix.H", "text": "\nproperty\n\nReturns the (complex) conjugate transpose of `self`.\n\nEquivalent to `np.transpose(self)` if `self` is real-valued.\n\ncomplex conjugate transpose of `self`\n\n"}, {"name": "property matrix.I", "path": "reference/generated/numpy.matrix.i", "type": "numpy.matrix.I", "text": "\nproperty\n\nReturns the (multiplicative) inverse of invertible `self`.\n\nIf `self` is non-singular, `ret` is such that `ret * self` == `self * ret` ==\n`np.matrix(np.eye(self[0,:].size))` all return `True`.\n\nIf `self` is singular.\n\nSee also\n\n"}, {"name": "property matrix.T", "path": "reference/generated/numpy.matrix.t", "type": "numpy.matrix.T", "text": "\nproperty\n\nReturns the transpose of the matrix.\n\nDoes not conjugate! For the complex conjugate transpose, use `.H`.\n\nThe (non-conjugated) transpose of the matrix.\n\nSee also\n\n"}, {"name": "property poly1d.c", "path": "reference/generated/numpy.poly1d.c", "type": "Polynomials", "text": "\nproperty\n\nThe polynomial coefficients\n\n"}, {"name": "property poly1d.coef", "path": "reference/generated/numpy.poly1d.coef", "type": "Polynomials", "text": "\nproperty\n\nThe polynomial coefficients\n\n"}, {"name": "property poly1d.coefficients", "path": "reference/generated/numpy.poly1d.coefficients", "type": "Polynomials", "text": "\nproperty\n\nThe polynomial coefficients\n\n"}, {"name": "property poly1d.coeffs", "path": "reference/generated/numpy.poly1d.coeffs", "type": "Polynomials", "text": "\nproperty\n\nThe polynomial coefficients\n\n"}, {"name": "property poly1d.o", "path": "reference/generated/numpy.poly1d.o", "type": "Polynomials", "text": "\nproperty\n\nThe order or degree of the polynomial\n\n"}, {"name": "property poly1d.order", "path": "reference/generated/numpy.poly1d.order", "type": "Polynomials", "text": "\nproperty\n\nThe order or degree of the polynomial\n\n"}, {"name": "property poly1d.r", "path": "reference/generated/numpy.poly1d.r", "type": "Polynomials", "text": "\nproperty\n\nThe roots of the polynomial, where self(x) == 0\n\n"}, {"name": "property poly1d.variable", "path": "reference/generated/numpy.poly1d.variable", "type": "Polynomials", "text": "\nproperty\n\nThe name of the polynomial variable\n\n"}, {"name": "PY_ARRAY_UNIQUE_SYMBOL", "path": "reference/c-api/array#c.PY_ARRAY_UNIQUE_SYMBOL", "type": "Array API", "text": "\n\n"}, {"name": "PyArray_ArrayDescr *subarray", "path": "reference/c-api/types-and-structures#c.NPY_USE_SETITEM.subarray", "type": "Python Types and C-Structures", "text": "\nIf this is non- `NULL`, then this data-type descriptor is a C-style contiguous\narray of another data-type descriptor. In other-words, each element that this\ndescriptor describes is actually an array of some other base descriptor. This\nis most useful as the data-type descriptor for a field in another data-type\ndescriptor. The fields member should be `NULL` if this is non- `NULL` (the\nfields member of the base descriptor can be non- `NULL` however).\n\nThe data-type-descriptor object of the base-type.\n\nThe shape (always C-style contiguous) of the sub-array as a Python tuple.\n\n"}, {"name": "PyArray_ArrFuncs *f", "path": "reference/c-api/types-and-structures#c.NPY_USE_SETITEM.f", "type": "Python Types and C-Structures", "text": "\nA pointer to a structure containing functions that the type needs to implement\ninternal features. These functions are not the same thing as the universal\nfunctions (ufuncs) described later. Their signatures can vary arbitrarily.\n\n"}, {"name": "PyArray_CEQ()", "path": "reference/c-api/array#c.PyArray_CEQ", "type": "Array API", "text": "\n\n"}, {"name": "PyArray_CGE()", "path": "reference/c-api/array#c.PyArray_CGE", "type": "Array API", "text": "\n\n"}, {"name": "PyArray_CGT()", "path": "reference/c-api/array#c.PyArray_CGT", "type": "Array API", "text": "\n\n"}, {"name": "PyArray_CLE()", "path": "reference/c-api/array#c.PyArray_CLE", "type": "Array API", "text": "\n\n"}, {"name": "PyArray_CLT()", "path": "reference/c-api/array#c.PyArray_CLT", "type": "Array API", "text": "\n\n"}, {"name": "PyArray_CNE()", "path": "reference/c-api/array#c.PyArray_CNE", "type": "Array API", "text": "\nImplements the complex comparisons between two complex numbers (structures\nwith a real and imag member) using NumPy\u2019s definition of the ordering which is\nlexicographic: comparing the real parts first and then the complex parts if\nthe real parts are equal.\n\n"}, {"name": "PyArray_Descr **NpyIter_GetDescrArray()", "path": "reference/c-api/iterator#c.NpyIter_GetDescrArray", "type": "Array Iterator API", "text": "\nThis gives back a pointer to the `nop` data type Descrs for the objects being\niterated. The result points into `iter`, so the caller does not gain any\nreferences to the Descrs.\n\nThis pointer may be cached before the iteration loop, calling `iternext` will\nnot change it.\n\n"}, {"name": "PyArray_Descr *descr", "path": "reference/c-api/types-and-structures#c.NPY_AO.descr", "type": "Python Types and C-Structures", "text": "\nA pointer to a data-type descriptor object (see below). The data-type\ndescriptor object is an instance of a new built-in type which allows a generic\ndescription of memory. There is a descriptor structure for each data type\nsupported. This descriptor structure contains useful information about the\ntype as well as a pointer to a table of function pointers to implement\nspecific functionality. As the name suggests, it is associated with the macro\n`PyArray_DESCR`.\n\n"}, {"name": "PyArray_Descr *PyArray_DESCR()", "path": "reference/c-api/array#c.PyArray_DESCR", "type": "Array API", "text": "\nReturns a borrowed reference to the dtype property of the array.\n\n"}, {"name": "PyArray_Descr *PyArray_DescrFromObject()", "path": "reference/c-api/array#c.PyArray_DescrFromObject", "type": "Array API", "text": "\nDetermine an appropriate data-type object from the object op (which should be\na \u201cnested\u201d sequence object) and the minimum data-type descriptor mintype\n(which can be `NULL` ). Similar in behavior to array(op).dtype. Don\u2019t confuse\nthis function with `PyArray_DescrConverter`. This function essentially looks\nat all the objects in the (nested) sequence and determines the data-type from\nthe elements it finds.\n\n"}, {"name": "PyArray_Descr *PyArray_DescrFromScalar()", "path": "reference/c-api/array#c.PyArray_DescrFromScalar", "type": "Array API", "text": "\nReturn a data-type object from an array-scalar object. No checking is done to\nbe sure that scalar is an array scalar. If no suitable data-type can be\ndetermined, then a data-type of `NPY_OBJECT` is returned by default.\n\n"}, {"name": "PyArray_Descr *PyArray_DescrFromType()", "path": "reference/c-api/array#c.PyArray_DescrFromType", "type": "Array API", "text": "\nReturns a data-type object corresponding to typenum. The typenum can be one of\nthe enumerated types, a character code for one of the enumerated types, or a\nuser-defined type. If you want to use a flexible size array, then you need to\n`flexible typenum` and set the results `elsize` parameter to the desired size.\nThe typenum is one of the `NPY_TYPES`.\n\n"}, {"name": "PyArray_Descr *PyArray_DescrNew()", "path": "reference/c-api/array#c.PyArray_DescrNew", "type": "Array API", "text": "\nReturn a new data-type object copied from obj (the fields reference is just\nupdated so that the new object points to the same fields dictionary if any).\n\n"}, {"name": "PyArray_Descr *PyArray_DescrNewByteorder()", "path": "reference/c-api/array#c.PyArray_DescrNewByteorder", "type": "Array API", "text": "\nCreate a new data-type object with the byteorder set according to newendian.\nAll referenced data-type objects (in subdescr and fields members of the data-\ntype object) are also changed (recursively).\n\nThe value of newendian is one of these macros:\n\n"}, {"name": "PyArray_Descr *PyArray_DescrNewFromType()", "path": "reference/c-api/array#c.PyArray_DescrNewFromType", "type": "Array API", "text": "\nCreate a new data-type object from the built-in (or user-registered) data-type\nindicated by typenum. All builtin types should not have any of their fields\nchanged. This creates a new copy of the `PyArray_Descr` structure so that you\ncan fill it in as appropriate. This function is especially needed for flexible\ndata-types which need to have a new elsize member in order to be meaningful in\narray construction.\n\n"}, {"name": "PyArray_Descr *PyArray_DTYPE()", "path": "reference/c-api/array#c.PyArray_DTYPE", "type": "Array API", "text": "\nNew in version 1.7.\n\nA synonym for PyArray_DESCR, named to be consistent with the \u2018dtype\u2019 usage\nwithin Python.\n\n"}, {"name": "PyArray_Descr *PyArray_MinScalarType()", "path": "reference/c-api/array#c.PyArray_MinScalarType", "type": "Array API", "text": "\nNew in version 1.6.\n\nIf arr is an array, returns its data type descriptor, but if arr is an array\nscalar (has 0 dimensions), it finds the data type of smallest size to which\nthe value may be converted without overflow or truncation to an integer.\n\nThis function will not demote complex to float or anything to boolean, but\nwill demote a signed integer to an unsigned integer when the scalar value is\npositive.\n\n"}, {"name": "PyArray_Descr *PyArray_PromoteTypes()", "path": "reference/c-api/array#c.PyArray_PromoteTypes", "type": "Array API", "text": "\nNew in version 1.6.\n\nFinds the data type of smallest size and kind to which type1 and type2 may be\nsafely converted. This function is symmetric and associative. A string or\nunicode result will be the proper size for storing the max value of the input\ntypes converted to a string or unicode.\n\n"}, {"name": "PyArray_Descr *PyArray_ResultType()", "path": "reference/c-api/array#c.PyArray_ResultType", "type": "Array API", "text": "\nNew in version 1.6.\n\nThis applies type promotion to all the inputs, using the NumPy rules for\ncombining scalars and arrays, to determine the output type of a set of\noperands. This is the same result type that ufuncs produce. The specific\nalgorithm used is as follows.\n\nCategories are determined by first checking which of boolean, integer\n(int/uint), or floating point (float/complex) the maximum kind of all the\narrays and the scalars are.\n\nIf there are only scalars or the maximum category of the scalars is higher\nthan the maximum category of the arrays, the data types are combined with\n`PyArray_PromoteTypes` to produce the return value.\n\nOtherwise, PyArray_MinScalarType is called on each array, and the resulting\ndata types are all combined with `PyArray_PromoteTypes` to produce the return\nvalue.\n\nThe set of int values is not a subset of the uint values for types with the\nsame number of bits, something not reflected in `PyArray_MinScalarType`, but\nhandled as a special case in PyArray_ResultType.\n\n"}, {"name": "PyArray_IsScalar()", "path": "reference/c-api/array#c.PyArray_IsScalar", "type": "Array API", "text": "\nEvaluates true if op is an instance of `Py{cls}ArrType_Type`.\n\n"}, {"name": "PyArray_MAX()", "path": "reference/c-api/array#c.PyArray_MAX", "type": "Array API", "text": "\nReturns the maximum of a and b. If (a) or (b) are expressions they are\nevaluated twice.\n\n"}, {"name": "PyArray_MIN()", "path": "reference/c-api/array#c.PyArray_MIN", "type": "Array API", "text": "\nReturns the minimum of a and b. If (a) or (b) are expressions they are\nevaluated twice.\n\n"}, {"name": "PyArray_VectorUnaryFunc *PyArray_GetCastFunc()", "path": "reference/c-api/array#c.PyArray_GetCastFunc", "type": "Array API", "text": "\nReturn the low-level casting function to cast from the given descriptor to the\nbuiltin type number. If no casting function exists return `NULL` and set an\nerror. Using this function instead of direct access to from ->f->cast will\nallow support of any user-defined casting functions added to a descriptors\ncasting dictionary.\n\n"}, {"name": "PyArrayIterObject **iters", "path": "reference/c-api/types-and-structures#c.PyArrayMultiIterObject.iters", "type": "Python Types and C-Structures", "text": "\nAn array of iterator objects that holds the iterators for the arrays to be\nbroadcast together. On return, the iterators are adjusted for broadcasting.\n\n"}, {"name": "PyArrayObject **PyArray_ConvertToCommonType()", "path": "reference/c-api/array#c.PyArray_ConvertToCommonType", "type": "Array API", "text": "\nThe functionality this provides is largely superseded by iterator `NpyIter`\nintroduced in 1.6, with flag `NPY_ITER_COMMON_DTYPE` or with the same dtype\nparameter for all operands.\n\nConvert a sequence of Python objects contained in op to an array of ndarrays\neach having the same data type. The type is selected in the same way as\n`PyArray_ResultType`. The length of the sequence is returned in n, and an n\n-length array of `PyArrayObject` pointers is the return value (or `NULL` if an\nerror occurs). The returned array must be freed by the caller of this routine\n(using `PyDataMem_FREE` ) and all the array objects in it `DECREF` \u2018d or a\nmemory-leak will occur. The example template-code below shows a typically\nusage:\n\nChanged in version 1.18.0: A mix of scalars and zero-dimensional arrays now\nproduces a type capable of holding the scalar value. Previously priority was\ngiven to the dtype of the arrays.\n\n"}, {"name": "PyArrayObject *ao", "path": "reference/c-api/types-and-structures#c.PyArrayIterObject.ao", "type": "Python Types and C-Structures", "text": "\nA pointer to the underlying ndarray this iterator was created to represent.\n\n"}, {"name": "PyArrayObject *PyArray_GETCONTIGUOUS()", "path": "reference/c-api/array#c.PyArray_GETCONTIGUOUS", "type": "Array API", "text": "\nIf `op` is already (C-style) contiguous and well-behaved then just return a\nreference, otherwise return a (contiguous and well-behaved) copy of the array.\nThe parameter op must be a (sub-class of an) ndarray and no checking for that\nis done.\n\n"}, {"name": "PyDataMem_EventHookFunc *PyDataMem_SetEventHook()", "path": "reference/c-api/data_memory#c.PyDataMem_SetEventHook", "type": "Memory management in NumPy", "text": "\nSets the allocation event hook for numpy array data.\n\nReturns a pointer to the previous hook or `NULL`. If old_data is non-`NULL`,\nthe previous user_data pointer will be copied to it.\n\nIf not `NULL`, hook will be called at the end of each\n`PyDataMem_NEW/FREE/RENEW`:\n\nWhen the hook is called, the GIL will be held by the calling thread. The hook\nshould be written to be reentrant, if it performs operations that might cause\nnew allocation events (such as the creation/destruction numpy objects, or\ncreating/destroying Python objects which might cause a gc)\n\n"}, {"name": "PyObject **NpyIter_GetOperandArray()", "path": "reference/c-api/iterator#c.NpyIter_GetOperandArray", "type": "Array Iterator API", "text": "\nThis gives back a pointer to the `nop` operand PyObjects that are being\niterated. The result points into `iter`, so the caller does not gain any\nreferences to the PyObjects.\n\n"}, {"name": "PyObject *base", "path": "reference/c-api/types-and-structures#c.NPY_AO.base", "type": "Python Types and C-Structures", "text": "\nPointed to by `PyArray_BASE`, this member is used to hold a pointer to another\nPython object that is related to this array. There are two use cases:\n\nWhen `PyArray_ResolveWritebackIfCopy` is called, the array pointed to by base\nwill be updated with the contents of this array.\n\n"}, {"name": "PyObject *castdict", "path": "reference/c-api/types-and-structures#c.PyArray_ArrFuncs.castdict", "type": "Python Types and C-Structures", "text": "\nEither `NULL` or a dictionary containing low-level casting functions for user-\ndefined data-types. Each function is wrapped in a PyCapsule* and keyed by the\ndata-type number.\n\n"}, {"name": "PyObject *descr", "path": "reference/c-api/types-and-structures#c.PyArrayInterface.descr", "type": "Python Types and C-Structures", "text": "\nA Python object describing the data-type in more detail (same as the descr key\nin `__array_interface__`). This can be `NULL` if typekind and itemsize provide\nenough information. This field is also ignored unless `NPY_ARR_HAS_DESCR` flag\nis on in flags.\n\n"}, {"name": "PyObject *fields", "path": "reference/c-api/types-and-structures#c.NPY_USE_SETITEM.fields", "type": "Python Types and C-Structures", "text": "\nIf this is non-NULL, then this data-type-descriptor has fields described by a\nPython dictionary whose keys are names (and also titles if given) and whose\nvalues are tuples that describe the fields. Recall that a data-type-descriptor\nalways describes a fixed-length set of bytes. A field is a named sub-region of\nthat total, fixed-length collection. A field is described by a tuple composed\nof another data- type-descriptor and a byte offset. Optionally, the tuple may\ncontain a title which is normally a Python string. These tuples are placed in\nthis dictionary keyed by name (and also title if given).\n\n"}, {"name": "PyObject *getitem()", "path": "reference/c-api/types-and-structures#c.PyArray_ArrFuncs.getitem", "type": "Python Types and C-Structures", "text": "\nA pointer to a function that returns a standard Python object from a single\nelement of the array object arr pointed to by data. This function must be able\nto deal with \u201cmisbehaved \u201c(misaligned and/or swapped) arrays correctly.\n\n"}, {"name": "PyObject *metadata", "path": "reference/c-api/types-and-structures#c.NPY_USE_SETITEM.metadata", "type": "Python Types and C-Structures", "text": "\nMetadata about this dtype.\n\n"}, {"name": "PyObject *names", "path": "reference/c-api/types-and-structures#c.NPY_USE_SETITEM.names", "type": "Python Types and C-Structures", "text": "\nAn ordered tuple of field names. It is NULL if no field is defined.\n\n"}, {"name": "PyObject *NpyIter_GetIterView()", "path": "reference/c-api/iterator#c.NpyIter_GetIterView", "type": "Array Iterator API", "text": "\nThis gives back a reference to a new ndarray view, which is a view into the\ni-th object in the array `NpyIter_GetOperandArray`, whose dimensions and\nstrides match the internal optimized iteration pattern. A C-order iteration of\nthis view is equivalent to the iterator\u2019s iteration order.\n\nFor example, if an iterator was created with a single array as its input, and\nit was possible to rearrange all its axes and then collapse it into a single\nstrided iteration, this would return a view that is a one-dimensional array.\n\n"}, {"name": "PyObject *obj", "path": "reference/c-api/types-and-structures#c.PyUFuncObject.obj", "type": "Python Types and C-Structures", "text": "\nFor ufuncs dynamically created from python functions, this member holds a\nreference to the underlying Python function.\n\n"}, {"name": "PyObject *PyArray_All()", "path": "reference/c-api/array#c.PyArray_All", "type": "Array API", "text": "\nEquivalent to `ndarray.all` (self, axis). Return an array with True elements\nfor every 1-d sub-array of `self` defined by `axis` in which all the elements\nare True.\n\n"}, {"name": "PyObject *PyArray_Any()", "path": "reference/c-api/array#c.PyArray_Any", "type": "Array API", "text": "\nEquivalent to `ndarray.any` (self, axis). Return an array with True elements\nfor every 1-d sub-array of self defined by axis in which any of the elements\nare True.\n\n"}, {"name": "PyObject *PyArray_Arange()", "path": "reference/c-api/array#c.PyArray_Arange", "type": "Array API", "text": "\nConstruct a new 1-dimensional array of data-type, typenum, that ranges from\nstart to stop (exclusive) in increments of step . Equivalent to arange (start,\nstop, step, dtype).\n\n"}, {"name": "PyObject *PyArray_ArangeObj()", "path": "reference/c-api/array#c.PyArray_ArangeObj", "type": "Array API", "text": "\nConstruct a new 1-dimensional array of data-type determined by `descr`, that\nranges from `start` to `stop` (exclusive) in increments of `step`. Equivalent\nto arange( `start`, `stop`, `step`, `typenum` ).\n\n"}, {"name": "PyObject *PyArray_ArgMin()", "path": "reference/c-api/array#c.PyArray_ArgMin", "type": "Array API", "text": "\nEquivalent to `ndarray.argmin` (self, axis). Return the index of the smallest\nelement of self along axis.\n\n"}, {"name": "PyObject *PyArray_ArgPartition()", "path": "reference/c-api/array#c.PyArray_ArgPartition", "type": "Array API", "text": "\nEquivalent to `ndarray.argpartition` (self, ktharray, axis, kind). Return an\narray of indices such that selection of these indices along the given `axis`\nwould return a partitioned version of self.\n\n"}, {"name": "PyObject *PyArray_ArgSort()", "path": "reference/c-api/array#c.PyArray_ArgSort", "type": "Array API", "text": "\nEquivalent to `ndarray.argsort` (self, axis). Return an array of indices such\nthat selection of these indices along the given `axis` would return a sorted\nversion of self. If self ->descr is a data-type with fields defined, then\nself->descr->names is used to determine the sort order. A comparison where the\nfirst field is equal will use the second field and so on. To alter the sort\norder of a structured array, create a new data-type with a different order of\nnames and construct a view of the array with that new data-type.\n\n"}, {"name": "PyObject *PyArray_BASE()", "path": "reference/c-api/array#c.PyArray_BASE", "type": "Array API", "text": "\nThis returns the base object of the array. In most cases, this means the\nobject which owns the memory the array is pointing at.\n\nIf you are constructing an array using the C API, and specifying your own\nmemory, you should use the function `PyArray_SetBaseObject` to set the base to\nan object which owns the memory.\n\nIf the (deprecated) `NPY_ARRAY_UPDATEIFCOPY` or the\n`NPY_ARRAY_WRITEBACKIFCOPY` flags are set, it has a different meaning, namely\nbase is the array into which the current array will be copied upon copy\nresolution. This overloading of the base property for two functions is likely\nto change in a future version of NumPy.\n\n"}, {"name": "PyObject *PyArray_BroadcastToShape()", "path": "reference/c-api/array#c.PyArray_BroadcastToShape", "type": "Array API", "text": "\nReturn an array iterator that is broadcast to iterate as an array of the shape\nprovided by dimensions and nd.\n\n"}, {"name": "PyObject *PyArray_Byteswap()", "path": "reference/c-api/array#c.PyArray_Byteswap", "type": "Array API", "text": "\nEquivalent to `ndarray.byteswap` (self, inplace). Return an array whose data\narea is byteswapped. If inplace is non-zero, then do the byteswap inplace and\nreturn a reference to self. Otherwise, create a byteswapped copy and leave\nself unchanged.\n\n"}, {"name": "PyObject *PyArray_CastToType()", "path": "reference/c-api/array#c.PyArray_CastToType", "type": "Array API", "text": "\nReturn a new array of the type specified, casting the elements of arr as\nappropriate. The fortran argument specifies the ordering of the output array.\n\n"}, {"name": "PyObject *PyArray_CheckAxis()", "path": "reference/c-api/array#c.PyArray_CheckAxis", "type": "Array API", "text": "\nEncapsulate the functionality of functions and methods that take the axis=\nkeyword and work properly with None as the axis argument. The input array is\n`obj`, while `*axis` is a converted integer (so that >=MAXDIMS is the None\nvalue), and `requirements` gives the needed properties of `obj`. The output is\na converted version of the input so that requirements are met and if needed a\nflattening has occurred. On output negative values of `*axis` are converted\nand the new value is checked to ensure consistency with the shape of `obj`.\n\n"}, {"name": "PyObject *PyArray_CheckFromAny()", "path": "reference/c-api/array#c.PyArray_CheckFromAny", "type": "Array API", "text": "\nNearly identical to `PyArray_FromAny` (\u2026) except requirements can contain\n`NPY_ARRAY_NOTSWAPPED` (over-riding the specification in dtype) and\n`NPY_ARRAY_ELEMENTSTRIDES` which indicates that the array should be aligned in\nthe sense that the strides are multiples of the element size.\n\nIn versions 1.6 and earlier of NumPy, the following flags did not have the\n_ARRAY_ macro namespace in them. That form of the constant names is deprecated\nin 1.7.\n\n"}, {"name": "PyObject *PyArray_Choose()", "path": "reference/c-api/array#c.PyArray_Choose", "type": "Array API", "text": "\nEquivalent to `ndarray.choose` (self, op, ret, clipmode). Create a new array\nby selecting elements from the sequence of arrays in op based on the integer\nvalues in self. The arrays must all be broadcastable to the same shape and the\nentries in self should be between 0 and len(op). The output is placed in ret\nunless it is `NULL` in which case a new output is created. The clipmode\nargument determines behavior for when entries in self are not between 0 and\nlen(op).\n\nraise a ValueError;\n\nwrap values < 0 by adding len(op) and values >=len(op) by subtracting len(op)\nuntil they are in range;\n\nall values are clipped to the region [0, len(op) ).\n\n"}, {"name": "PyObject *PyArray_Clip()", "path": "reference/c-api/array#c.PyArray_Clip", "type": "Array API", "text": "\nEquivalent to `ndarray.clip` (self, min, max). Clip an array, self, so that\nvalues larger than max are fixed to max and values less than min are fixed to\nmin.\n\n"}, {"name": "PyObject *PyArray_Compress()", "path": "reference/c-api/array#c.PyArray_Compress", "type": "Array API", "text": "\nEquivalent to `ndarray.compress` (self, condition, axis ). Return the elements\nalong axis corresponding to elements of condition that are true.\n\n"}, {"name": "PyObject *PyArray_Concatenate()", "path": "reference/c-api/array#c.PyArray_Concatenate", "type": "Array API", "text": "\nJoin the sequence of objects in obj together along axis into a single array.\nIf the dimensions or types are not compatible an error is raised.\n\n"}, {"name": "PyObject *PyArray_Conjugate()", "path": "reference/c-api/array#c.PyArray_Conjugate", "type": "Array API", "text": "\nEquivalent to `ndarray.conjugate` (self). Return the complex conjugate of\nself. If self is not of complex data type, then return self with a reference.\n\n"}, {"name": "PyObject *PyArray_ContiguousFromAny()", "path": "reference/c-api/array#c.PyArray_ContiguousFromAny", "type": "Array API", "text": "\nThis function returns a (C-style) contiguous and behaved function array from\nany nested sequence or array interface exporting object, op, of (non-flexible)\ntype given by the enumerated typenum, of minimum depth min_depth, and of\nmaximum depth max_depth. Equivalent to a call to `PyArray_FromAny` with\nrequirements set to `NPY_ARRAY_DEFAULT` and the type_num member of the type\nargument set to typenum.\n\n"}, {"name": "PyObject *PyArray_ContiguousFromObject()", "path": "reference/c-api/array#c.PyArray_ContiguousFromObject", "type": "Array API", "text": "\nThis function returns a well-behaved C-style contiguous array from any nested\nsequence or array-interface exporting object. The minimum number of dimensions\nthe array can have is given by `min_depth` while the maximum is `max_depth`.\nThis is equivalent to call `PyArray_FromAny` with requirements\n`NPY_ARRAY_DEFAULT` and `NPY_ARRAY_ENSUREARRAY`.\n\n"}, {"name": "PyObject *PyArray_CopyAndTranspose()", "path": "reference/c-api/array#c.PyArray_CopyAndTranspose", "type": "Array API", "text": "\nA specialized copy and transpose function that works only for 2-d arrays. The\nreturned array is a transposed copy of op.\n\n"}, {"name": "PyObject *PyArray_Correlate()", "path": "reference/c-api/array#c.PyArray_Correlate", "type": "Array API", "text": "\nCompute the 1-d correlation of the 1-d arrays op1 and op2 . The correlation is\ncomputed at each output point by multiplying op1 by a shifted version of op2\nand summing the result. As a result of the shift, needed values outside of the\ndefined range of op1 and op2 are interpreted as zero. The mode determines how\nmany shifts to return: 0 - return only shifts that did not need to assume\nzero- values; 1 - return an object that is the same size as op1, 2 - return\nall possible shifts (any overlap at all is accepted).\n\nThis does not compute the usual correlation: if op2 is larger than op1, the\narguments are swapped, and the conjugate is never taken for complex arrays.\nSee PyArray_Correlate2 for the usual signal processing correlation.\n\n"}, {"name": "PyObject *PyArray_Correlate2()", "path": "reference/c-api/array#c.PyArray_Correlate2", "type": "Array API", "text": "\nUpdated version of PyArray_Correlate, which uses the usual definition of\ncorrelation for 1d arrays. The correlation is computed at each output point by\nmultiplying op1 by a shifted version of op2 and summing the result. As a\nresult of the shift, needed values outside of the defined range of op1 and op2\nare interpreted as zero. The mode determines how many shifts to return: 0 -\nreturn only shifts that did not need to assume zero- values; 1 - return an\nobject that is the same size as op1, 2 - return all possible shifts (any\noverlap at all is accepted).\n\nCompute z as follows:\n\n"}, {"name": "PyObject *PyArray_CumProd()", "path": "reference/c-api/array#c.PyArray_CumProd", "type": "Array API", "text": "\nEquivalent to `ndarray.cumprod` (self, axis, rtype). Return 1-d cumulative\nproducts of elements in `self` along `axis`. Perform the product after\nconverting data to data type `rtype`.\n\n"}, {"name": "PyObject *PyArray_CumSum()", "path": "reference/c-api/array#c.PyArray_CumSum", "type": "Array API", "text": "\nEquivalent to `ndarray.cumsum` (self, axis, rtype). Return cumulative 1-d sums\nof elements in self along axis. Perform the sum after converting data to data\ntype rtype.\n\n"}, {"name": "PyObject *PyArray_Diagonal()", "path": "reference/c-api/array#c.PyArray_Diagonal", "type": "Array API", "text": "\nEquivalent to `ndarray.diagonal` (self, offset, axis1, axis2 ). Return the\noffset diagonals of the 2-d arrays defined by axis1 and axis2.\n\n"}, {"name": "PyObject *PyArray_Dumps()", "path": "reference/c-api/array#c.PyArray_Dumps", "type": "Array API", "text": "\nPickle the object in self to a Python string and return it. Use the Pickle\nprotocol provided (or the highest available if protocol is negative).\n\n"}, {"name": "PyObject *PyArray_EinsteinSum()", "path": "reference/c-api/array#c.PyArray_EinsteinSum", "type": "Array API", "text": "\nNew in version 1.6.\n\nApplies the Einstein summation convention to the array operands provided,\nreturning a new array or placing the result in out. The string in subscripts\nis a comma separated list of index letters. The number of operands is in nop,\nand op_in is an array containing those operands. The data type of the output\ncan be forced with dtype, the output order can be forced with order\n(`NPY_KEEPORDER` is recommended), and when dtype is specified, casting\nindicates how permissive the data conversion should be.\n\nSee the `einsum` function for more details.\n\n"}, {"name": "PyObject *PyArray_EMPTY()", "path": "reference/c-api/array#c.PyArray_EMPTY", "type": "Array API", "text": "\nMacro form of `PyArray_Empty` which takes a type-number, typenum, instead of a\ndata-type object.\n\n"}, {"name": "PyObject *PyArray_Empty()", "path": "reference/c-api/array#c.PyArray_Empty", "type": "Array API", "text": "\nConstruct a new nd -dimensional array with shape given by dims and data type\ngiven by dtype. If fortran is non-zero, then a Fortran-order array is created,\notherwise a C-order array is created. The array is uninitialized unless the\ndata type corresponds to `NPY_OBJECT` in which case the array is filled with\n`Py_None`.\n\n"}, {"name": "PyObject *PyArray_EnsureArray()", "path": "reference/c-api/array#c.PyArray_EnsureArray", "type": "Array API", "text": "\nThis function steals a reference to `op` and makes sure that `op` is a base-\nclass ndarray. It special cases array scalars, but otherwise calls\n`PyArray_FromAny` ( `op`, NULL, 0, 0, `NPY_ARRAY_ENSUREARRAY`, NULL).\n\n"}, {"name": "PyObject *PyArray_FieldNames()", "path": "reference/c-api/array#c.PyArray_FieldNames", "type": "Array API", "text": "\nTake the fields dictionary, dict, such as the one attached to a data-type\nobject and construct an ordered-list of field names such as is stored in the\nnames field of the `PyArray_Descr` object.\n\n"}, {"name": "PyObject *PyArray_Flatten()", "path": "reference/c-api/array#c.PyArray_Flatten", "type": "Array API", "text": "\nEquivalent to `ndarray.flatten` (self, order). Return a 1-d copy of the array.\nIf order is `NPY_FORTRANORDER` the elements are scanned out in Fortran order\n(first-dimension varies the fastest). If order is `NPY_CORDER`, the elements\nof `self` are scanned in C-order (last dimension varies the fastest). If order\n`NPY_ANYORDER`, then the result of `PyArray_ISFORTRAN` (self) is used to\ndetermine which order to flatten.\n\n"}, {"name": "PyObject *PyArray_FROM_O()", "path": "reference/c-api/array#c.PyArray_FROM_O", "type": "Array API", "text": "\nConvert `obj` to an ndarray. The argument can be any nested sequence or object\nthat exports the array interface. This is a macro form of `PyArray_FromAny`\nusing `NULL`, 0, 0, 0 for the other arguments. Your code must be able to\nhandle any data-type descriptor and any combination of data-flags to use this\nmacro.\n\n"}, {"name": "PyObject *PyArray_FROM_OF()", "path": "reference/c-api/array#c.PyArray_FROM_OF", "type": "Array API", "text": "\nSimilar to `PyArray_FROM_O` except it can take an argument of requirements\nindicating properties the resulting array must have. Available requirements\nthat can be enforced are `NPY_ARRAY_C_CONTIGUOUS`, `NPY_ARRAY_F_CONTIGUOUS`,\n`NPY_ARRAY_ALIGNED`, `NPY_ARRAY_WRITEABLE`, `NPY_ARRAY_NOTSWAPPED`,\n`NPY_ARRAY_ENSURECOPY`, `NPY_ARRAY_WRITEBACKIFCOPY`, `NPY_ARRAY_UPDATEIFCOPY`,\n`NPY_ARRAY_FORCECAST`, and `NPY_ARRAY_ENSUREARRAY`. Standard combinations of\nflags can also be used:\n\n"}, {"name": "PyObject *PyArray_FROM_OT()", "path": "reference/c-api/array#c.PyArray_FROM_OT", "type": "Array API", "text": "\nSimilar to `PyArray_FROM_O` except it can take an argument of typenum\nspecifying the type-number the returned array.\n\n"}, {"name": "PyObject *PyArray_FROM_OTF()", "path": "reference/c-api/array#c.PyArray_FROM_OTF", "type": "Array API", "text": "\nCombination of `PyArray_FROM_OF` and `PyArray_FROM_OT` allowing both a typenum\nand a flags argument to be provided.\n\n"}, {"name": "PyObject *PyArray_FROMANY()", "path": "reference/c-api/array#c.PyArray_FROMANY", "type": "Array API", "text": "\nSimilar to `PyArray_FromAny` except the data-type is specified using a\ntypenumber. `PyArray_DescrFromType` (typenum) is passed directly to\n`PyArray_FromAny`. This macro also adds `NPY_ARRAY_DEFAULT` to requirements if\n`NPY_ARRAY_ENSURECOPY` is passed in as requirements.\n\n"}, {"name": "PyObject *PyArray_FromArray()", "path": "reference/c-api/array#c.PyArray_FromArray", "type": "Array API", "text": "\nSpecial case of `PyArray_FromAny` for when op is already an array but it needs\nto be of a specific newtype (including byte-order) or has certain\nrequirements.\n\n"}, {"name": "PyObject *PyArray_FromArrayAttr()", "path": "reference/c-api/array#c.PyArray_FromArrayAttr", "type": "Array API", "text": "\nReturn an ndarray object from a Python object that exposes the `__array__`\nmethod. The `__array__` method can take 0, or 1 argument `([dtype])`.\n`context` is unused.\n\n"}, {"name": "PyObject *PyArray_FromBuffer()", "path": "reference/c-api/array#c.PyArray_FromBuffer", "type": "Array API", "text": "\nConstruct a one-dimensional ndarray of a single type from an object, `buf`,\nthat exports the (single-segment) buffer protocol (or has an attribute\n__buffer__ that returns an object that exports the buffer protocol). A\nwriteable buffer will be tried first followed by a read- only buffer. The\n`NPY_ARRAY_WRITEABLE` flag of the returned array will reflect which one was\nsuccessful. The data is assumed to start at `offset` bytes from the start of\nthe memory location for the object. The type of the data in the buffer will be\ninterpreted depending on the data- type descriptor, `dtype.` If `count` is\nnegative then it will be determined from the size of the buffer and the\nrequested itemsize, otherwise, `count` represents how many elements should be\nconverted from the buffer.\n\n"}, {"name": "PyObject *PyArray_FromFile()", "path": "reference/c-api/array#c.PyArray_FromFile", "type": "Array API", "text": "\nConstruct a one-dimensional ndarray of a single type from a binary or text\nfile. The open file pointer is `fp`, the data-type of the array to be created\nis given by `dtype`. This must match the data in the file. If `num` is -1,\nthen read until the end of the file and return an appropriately sized array,\notherwise, `num` is the number of items to read. If `sep` is NULL (or \u201c\u201d),\nthen read from the file in binary mode, otherwise read from the file in text\nmode with `sep` providing the item separator. Some array types cannot be read\nin text mode in which case an error is raised.\n\n"}, {"name": "PyObject *PyArray_FromInterface()", "path": "reference/c-api/array#c.PyArray_FromInterface", "type": "Array API", "text": "\nReturns an ndarray object from a Python object that exposes the\n`__array_interface__` attribute following the array interface protocol. If the\nobject does not contain this attribute then a borrowed reference to\n`Py_NotImplemented` is returned.\n\n"}, {"name": "PyObject *PyArray_FromObject()", "path": "reference/c-api/array#c.PyArray_FromObject", "type": "Array API", "text": "\nReturn an aligned and in native-byteorder array from any nested sequence or\narray-interface exporting object, op, of a type given by the enumerated\ntypenum. The minimum number of dimensions the array can have is given by\nmin_depth while the maximum is max_depth. This is equivalent to a call to\n`PyArray_FromAny` with requirements set to BEHAVED.\n\n"}, {"name": "PyObject *PyArray_FromScalar()", "path": "reference/c-api/array#c.PyArray_FromScalar", "type": "Array API", "text": "\nReturn a 0-dimensional array of type determined by outcode from scalar which\nshould be an array-scalar object. If outcode is NULL, then the type is\ndetermined from scalar.\n\n"}, {"name": "PyObject *PyArray_FromString()", "path": "reference/c-api/array#c.PyArray_FromString", "type": "Array API", "text": "\nConstruct a one-dimensional ndarray of a single type from a binary or (ASCII)\ntext `string` of length `slen`. The data-type of the array to-be-created is\ngiven by `dtype`. If num is -1, then copy the entire string and return an\nappropriately sized array, otherwise, `num` is the number of items to copy\nfrom the string. If `sep` is NULL (or \u201c\u201d), then interpret the string as bytes\nof binary data, otherwise convert the sub-strings separated by `sep` to items\nof data-type `dtype`. Some data-types may not be readable in text mode and an\nerror will be raised if that occurs. All errors return NULL.\n\n"}, {"name": "PyObject *PyArray_FromStructInterface()", "path": "reference/c-api/array#c.PyArray_FromStructInterface", "type": "Array API", "text": "\nReturns an ndarray object from a Python object that exposes the\n`__array_struct__` attribute and follows the array interface protocol. If the\nobject does not contain this attribute then a borrowed reference to\n`Py_NotImplemented` is returned.\n\n"}, {"name": "PyObject *PyArray_GETITEM()", "path": "reference/c-api/array#c.PyArray_GETITEM", "type": "Array API", "text": "\nGet a Python object of a builtin type from the ndarray, arr, at the location\npointed to by itemptr. Return `NULL` on failure.\n\n`numpy.ndarray.item` is identical to PyArray_GETITEM.\n\n"}, {"name": "PyObject *PyArray_GetNumericOps()", "path": "reference/c-api/array#c.PyArray_GetNumericOps", "type": "Array API", "text": "\nReturn a Python dictionary containing the callable Python objects stored in\nthe internal arithmetic operation table. The keys of this dictionary are given\nin the explanation for `PyArray_SetNumericOps`.\n\nDeprecated since version 1.16.\n\n"}, {"name": "PyObject *PyArray_InnerProduct()", "path": "reference/c-api/array#c.PyArray_InnerProduct", "type": "Array API", "text": "\nCompute a product-sum over the last dimensions of obj1 and obj2. Neither array\nis conjugated.\n\n"}, {"name": "PyObject *PyArray_IterAllButAxis()", "path": "reference/c-api/array#c.PyArray_IterAllButAxis", "type": "Array API", "text": "\nReturn an array iterator that will iterate over all axes but the one provided\nin *axis. The returned iterator cannot be used with `PyArray_ITER_GOTO1D`.\nThis iterator could be used to write something similar to what ufuncs do\nwherein the loop over the largest axis is done by a separate sub-routine. If\n*axis is negative then *axis will be set to the axis having the smallest\nstride and that axis will be used.\n\n"}, {"name": "PyObject *PyArray_LexSort()", "path": "reference/c-api/array#c.PyArray_LexSort", "type": "Array API", "text": "\nGiven a sequence of arrays (sort_keys) of the same shape, return an array of\nindices (similar to `PyArray_ArgSort` (\u2026)) that would sort the arrays\nlexicographically. A lexicographic sort specifies that when two keys are found\nto be equal, the order is based on comparison of subsequent keys. A merge sort\n(which leaves equal entries unmoved) is required to be defined for the types.\nThe sort is accomplished by sorting the indices first using the first sort_key\nand then using the second sort_key and so forth. This is equivalent to the\nlexsort(sort_keys, axis) Python command. Because of the way the merge-sort\nworks, be sure to understand the order the sort_keys must be in (reversed from\nthe order you would use when comparing two elements).\n\nIf these arrays are all collected in a structured array, then `PyArray_Sort`\n(\u2026) can also be used to sort the array directly.\n\n"}, {"name": "PyObject *PyArray_MapIterArrayCopyIfOverlap()", "path": "reference/c-api/array#c.PyArray_MapIterArrayCopyIfOverlap", "type": "Array API", "text": "\nSimilar to `PyArray_MapIterArray` but with an additional `copy_if_overlap`\nargument. If `copy_if_overlap != 0`, checks if `a` has memory overlap with any\nof the arrays in `index` and with `extra_op`, and make copies as appropriate\nto avoid problems if the input is modified during the iteration. `iter->array`\nmay contain a copied array (UPDATEIFCOPY/WRITEBACKIFCOPY set).\n\n"}, {"name": "PyObject *PyArray_MatrixProduct()", "path": "reference/c-api/array#c.PyArray_MatrixProduct", "type": "Array API", "text": "\nCompute a product-sum over the last dimension of obj1 and the second-to-last\ndimension of obj2. For 2-d arrays this is a matrix-product. Neither array is\nconjugated.\n\n"}, {"name": "PyObject *PyArray_MatrixProduct2()", "path": "reference/c-api/array#c.PyArray_MatrixProduct2", "type": "Array API", "text": "\nNew in version 1.6.\n\nSame as PyArray_MatrixProduct, but store the result in out. The output array\nmust have the correct shape, type, and be C-contiguous, or an exception is\nraised.\n\n"}, {"name": "PyObject *PyArray_Max()", "path": "reference/c-api/array#c.PyArray_Max", "type": "Array API", "text": "\nEquivalent to `ndarray.max` (self, axis). Returns the largest element of self\nalong the given axis. When the result is a single element, returns a numpy\nscalar instead of an ndarray.\n\n"}, {"name": "PyObject *PyArray_Mean()", "path": "reference/c-api/array#c.PyArray_Mean", "type": "Array API", "text": "\nEquivalent to `ndarray.mean` (self, axis, rtype). Returns the mean of the\nelements along the given axis, using the enumerated type rtype as the data\ntype to sum in. Default sum behavior is obtained using `NPY_NOTYPE` for rtype.\n\n"}, {"name": "PyObject *PyArray_Min()", "path": "reference/c-api/array#c.PyArray_Min", "type": "Array API", "text": "\nEquivalent to `ndarray.min` (self, axis). Return the smallest element of self\nalong the given axis. When the result is a single element, returns a numpy\nscalar instead of an ndarray.\n\n"}, {"name": "PyObject *PyArray_New()", "path": "reference/c-api/array#c.PyArray_New", "type": "Array API", "text": "\nThis is similar to `PyArray_NewFromDescr` (\u2026) except you specify the data-type\ndescriptor with type_num and itemsize, where type_num corresponds to a builtin\n(or user-defined) type. If the type always has the same number of bytes, then\nitemsize is ignored. Otherwise, itemsize specifies the particular size of this\narray.\n\n"}, {"name": "PyObject *PyArray_NewCopy()", "path": "reference/c-api/array#c.PyArray_NewCopy", "type": "Array API", "text": "\nEquivalent to `ndarray.copy` (self, fortran). Make a copy of the old array.\nThe returned array is always aligned and writeable with data interpreted the\nsame as the old array. If order is `NPY_CORDER`, then a C-style contiguous\narray is returned. If order is `NPY_FORTRANORDER`, then a Fortran-style\ncontiguous array is returned. If order is `NPY_ANYORDER`, then the array\nreturned is Fortran-style contiguous only if the old one is; otherwise, it is\nC-style contiguous.\n\n"}, {"name": "PyObject *PyArray_NewLikeArray()", "path": "reference/c-api/array#c.PyArray_NewLikeArray", "type": "Array API", "text": "\nNew in version 1.6.\n\nThis function steals a reference to descr if it is not NULL. This array\ncreation routine allows for the convenient creation of a new array matching an\nexisting array\u2019s shapes and memory layout, possibly changing the layout and/or\ndata type.\n\nWhen order is `NPY_ANYORDER`, the result order is `NPY_FORTRANORDER` if\nprototype is a fortran array, `NPY_CORDER` otherwise. When order is\n`NPY_KEEPORDER`, the result order matches that of prototype, even when the\naxes of prototype aren\u2019t in C or Fortran order.\n\nIf descr is NULL, the data type of prototype is used.\n\nIf subok is 1, the newly created array will use the sub-type of prototype to\ncreate the new array, otherwise it will create a base-class array.\n\n"}, {"name": "PyObject *PyArray_Nonzero()", "path": "reference/c-api/array#c.PyArray_Nonzero", "type": "Array API", "text": "\nEquivalent to `ndarray.nonzero` (self). Returns a tuple of index arrays that\nselect elements of self that are nonzero. If (nd= `PyArray_NDIM` ( `self`\n))==1, then a single index array is returned. The index arrays have data type\n`NPY_INTP`. If a tuple is returned (nd \\\\(\\neq\\\\) 1), then its length is nd.\n\n"}, {"name": "PyObject *PyArray_Prod()", "path": "reference/c-api/array#c.PyArray_Prod", "type": "Array API", "text": "\nEquivalent to `ndarray.prod` (self, axis, rtype). Return 1-d products of\nelements in self along axis. Perform the product after converting data to data\ntype rtype.\n\n"}, {"name": "PyObject *PyArray_Ptp()", "path": "reference/c-api/array#c.PyArray_Ptp", "type": "Array API", "text": "\nEquivalent to `ndarray.ptp` (self, axis). Return the difference between the\nlargest element of self along axis and the smallest element of self along\naxis. When the result is a single element, returns a numpy scalar instead of\nan ndarray.\n\n"}, {"name": "PyObject *PyArray_PutMask()", "path": "reference/c-api/array#c.PyArray_PutMask", "type": "Array API", "text": "\nPlace the values in self wherever corresponding positions (using a flattened\ncontext) in mask are true. The mask and self arrays must have the same total\nnumber of elements. If values is too small, it will be repeated as necessary.\n\n"}, {"name": "PyObject *PyArray_PutTo()", "path": "reference/c-api/array#c.PyArray_PutTo", "type": "Array API", "text": "\nEquivalent to self.put(values, indices, clipmode ). Put values into self at\nthe corresponding (flattened) indices. If values is too small it will be\nrepeated as necessary.\n\n"}, {"name": "PyObject *PyArray_Ravel()", "path": "reference/c-api/array#c.PyArray_Ravel", "type": "Array API", "text": "\nEquivalent to self.ravel(order). Same basic functionality as `PyArray_Flatten`\n(self, order) except if order is 0 and self is C-style contiguous, the shape\nis altered but no copy is performed.\n\n"}, {"name": "PyObject *PyArray_Repeat()", "path": "reference/c-api/array#c.PyArray_Repeat", "type": "Array API", "text": "\nEquivalent to `ndarray.repeat` (self, op, axis). Copy the elements of self, op\ntimes along the given axis. Either op is a scalar integer or a sequence of\nlength self ->dimensions[ axis ] indicating how many times to repeat each item\nalong the axis.\n\n"}, {"name": "PyObject *PyArray_Reshape()", "path": "reference/c-api/array#c.PyArray_Reshape", "type": "Array API", "text": "\nEquivalent to `ndarray.reshape` (self, shape) where shape is a sequence.\nConverts shape to a `PyArray_Dims` structure and calls `PyArray_Newshape`\ninternally. For back-ward compatibility \u2013 Not recommended\n\n"}, {"name": "PyObject *PyArray_Resize()", "path": "reference/c-api/array#c.PyArray_Resize", "type": "Array API", "text": "\nEquivalent to `ndarray.resize` (self, newshape, refcheck `=` refcheck, order=\nfortran ). This function only works on single-segment arrays. It changes the\nshape of self inplace and will reallocate the memory for self if newshape has\na different total number of elements then the old shape. If reallocation is\nnecessary, then self must own its data, have self \\- `>base==NULL`, have self\n\\- `>weakrefs==NULL`, and (unless refcheck is 0) not be referenced by any\nother array. The fortran argument can be `NPY_ANYORDER`, `NPY_CORDER`, or\n`NPY_FORTRANORDER`. It currently has no effect. Eventually it could be used to\ndetermine how the resize operation should view the data when constructing a\ndifferently-dimensioned array. Returns None on success and NULL on error.\n\n"}, {"name": "PyObject *PyArray_Round()", "path": "reference/c-api/array#c.PyArray_Round", "type": "Array API", "text": "\nEquivalent to `ndarray.round` (self, decimals, out). Returns the array with\nelements rounded to the nearest decimal place. The decimal place is defined as\nthe \\\\(10^{-\\textrm{decimals}}\\\\) digit so that negative decimals cause\nrounding to the nearest 10\u2019s, 100\u2019s, etc. If out is `NULL`, then the output\narray is created, otherwise the output is placed in out which must be the\ncorrect size and type.\n\n"}, {"name": "PyObject *PyArray_Scalar()", "path": "reference/c-api/array#c.PyArray_Scalar", "type": "Array API", "text": "\nReturn an array scalar object of the given dtype by copying from memory\npointed to by data. base is expected to be the array object that is the owner\nof the data. base is required if `dtype` is a `void` scalar, or if the\n`NPY_USE_GETITEM` flag is set and it is known that the `getitem` method uses\nthe `arr` argument without checking if it is `NULL`. Otherwise `base` may be\n`NULL`.\n\nIf the data is not in native byte order (as indicated by `dtype->byteorder`)\nthen this function will byteswap the data, because array scalars are always in\ncorrect machine-byte order.\n\n"}, {"name": "PyObject *PyArray_SearchSorted()", "path": "reference/c-api/array#c.PyArray_SearchSorted", "type": "Array API", "text": "\nEquivalent to `ndarray.searchsorted` (self, values, side, perm). Assuming self\nis a 1-d array in ascending order, then the output is an array of indices the\nsame shape as values such that, if the elements in values were inserted before\nthe indices, the order of self would be preserved. No checking is done on\nwhether or not self is in ascending order.\n\nThe side argument indicates whether the index returned should be that of the\nfirst suitable location (if `NPY_SEARCHLEFT`) or of the last (if\n`NPY_SEARCHRIGHT`).\n\nThe sorter argument, if not `NULL`, must be a 1D array of integer indices the\nsame length as self, that sorts it into ascending order. This is typically the\nresult of a call to `PyArray_ArgSort` (\u2026) Binary search is used to find the\nrequired insertion points.\n\n"}, {"name": "PyObject *PyArray_SimpleNew()", "path": "reference/c-api/array#c.PyArray_SimpleNew", "type": "Array API", "text": "\nCreate a new uninitialized array of type, typenum, whose size in each of nd\ndimensions is given by the integer array, dims.The memory for the array is\nuninitialized (unless typenum is `NPY_OBJECT` in which case each element in\nthe array is set to NULL). The typenum argument allows specification of any of\nthe builtin data-types such as `NPY_FLOAT` or `NPY_LONG`. The memory for the\narray can be set to zero if desired using `PyArray_FILLWBYTE` (return_object,\n0).This function cannot be used to create a flexible-type array (no itemsize\ngiven).\n\n"}, {"name": "PyObject *PyArray_SimpleNewFromData()", "path": "reference/c-api/array#c.PyArray_SimpleNewFromData", "type": "Array API", "text": "\nCreate an array wrapper around data pointed to by the given pointer. The array\nflags will have a default that the data area is well-behaved and C-style\ncontiguous. The shape of the array is given by the dims c-array of length nd.\nThe data-type of the array is indicated by typenum. If data comes from another\nreference-counted Python object, the reference count on this object should be\nincreased after the pointer is passed in, and the base member of the returned\nndarray should point to the Python object that owns the data. This will ensure\nthat the provided memory is not freed while the returned array is in\nexistence.\n\n"}, {"name": "PyObject *PyArray_SimpleNewFromDescr()", "path": "reference/c-api/array#c.PyArray_SimpleNewFromDescr", "type": "Array API", "text": "\nThis function steals a reference to descr.\n\nCreate a new array with the provided data-type descriptor, descr, of the shape\ndetermined by nd and dims.\n\n"}, {"name": "PyObject *PyArray_Sort()", "path": "reference/c-api/array#c.PyArray_Sort", "type": "Array API", "text": "\nEquivalent to `ndarray.sort` (self, axis, kind). Return an array with the\nitems of self sorted along axis. The array is sorted using the algorithm\ndenoted by kind, which is an integer/enum pointing to the type of sorting\nalgorithms used.\n\n"}, {"name": "PyObject *PyArray_Squeeze()", "path": "reference/c-api/array#c.PyArray_Squeeze", "type": "Array API", "text": "\nEquivalent to `ndarray.squeeze` (self). Return a new view of self with all of\nthe dimensions of length 1 removed from the shape.\n\n"}, {"name": "PyObject *PyArray_Std()", "path": "reference/c-api/array#c.PyArray_Std", "type": "Array API", "text": "\nEquivalent to `ndarray.std` (self, axis, rtype). Return the standard deviation\nusing data along axis converted to data type rtype.\n\n"}, {"name": "PyObject *PyArray_Sum()", "path": "reference/c-api/array#c.PyArray_Sum", "type": "Array API", "text": "\nEquivalent to `ndarray.sum` (self, axis, rtype). Return 1-d vector sums of\nelements in self along axis. Perform the sum after converting data to data\ntype rtype.\n\n"}, {"name": "PyObject *PyArray_SwapAxes()", "path": "reference/c-api/array#c.PyArray_SwapAxes", "type": "Array API", "text": "\nEquivalent to `ndarray.swapaxes` (self, a1, a2). The returned array is a new\nview of the data in self with the given axes, a1 and a2, swapped.\n\n"}, {"name": "PyObject *PyArray_ToFile()", "path": "reference/c-api/array#c.PyArray_ToFile", "type": "Array API", "text": "\nWrite the contents of self to the file pointer fp in C-style contiguous\nfashion. Write the data as binary bytes if sep is the string \u201c\u201dor `NULL`.\nOtherwise, write the contents of self as text using the sep string as the item\nseparator. Each item will be printed to the file. If the format string is not\n`NULL` or \u201c\u201d, then it is a Python print statement format string showing how\nthe items are to be written.\n\n"}, {"name": "PyObject *PyArray_ToList()", "path": "reference/c-api/array#c.PyArray_ToList", "type": "Array API", "text": "\nEquivalent to `ndarray.tolist` (self). Return a nested Python list from self.\n\n"}, {"name": "PyObject *PyArray_ToScalar()", "path": "reference/c-api/array#c.PyArray_ToScalar", "type": "Array API", "text": "\nReturn an array scalar object of the type and itemsize indicated by the array\nobject arr copied from the memory pointed to by data and swapping if the data\nin arr is not in machine byte-order.\n\n"}, {"name": "PyObject *PyArray_ToString()", "path": "reference/c-api/array#c.PyArray_ToString", "type": "Array API", "text": "\nEquivalent to `ndarray.tobytes` (self, order). Return the bytes of this array\nin a Python string.\n\n"}, {"name": "PyObject *PyArray_Trace()", "path": "reference/c-api/array#c.PyArray_Trace", "type": "Array API", "text": "\nEquivalent to `ndarray.trace` (self, offset, axis1, axis2, rtype). Return the\nsum (using rtype as the data type of summation) over the offset diagonal\nelements of the 2-d arrays defined by axis1 and axis2 variables. A positive\noffset chooses diagonals above the main diagonal. A negative offset selects\ndiagonals below the main diagonal.\n\n"}, {"name": "PyObject *PyArray_Transpose()", "path": "reference/c-api/array#c.PyArray_Transpose", "type": "Array API", "text": "\nEquivalent to `ndarray.transpose` (self, permute). Permute the axes of the\nndarray object self according to the data structure permute and return the\nresult. If permute is `NULL`, then the resulting array has its axes reversed.\nFor example if self has shape \\\\(10\\times20\\times30\\\\), and permute `.ptr` is\n(0,2,1) the shape of the result is \\\\(10\\times30\\times20.\\\\) If permute is\n`NULL`, the shape of the result is \\\\(30\\times20\\times10.\\\\)\n\n"}, {"name": "PyObject *PyArray_TypeObjectFromType()", "path": "reference/c-api/array#c.PyArray_TypeObjectFromType", "type": "Array API", "text": "\nReturns a scalar type-object from a type-number, type . Equivalent to\n`PyArray_DescrFromType` (type)->typeobj except for reference counting and\nerror-checking. Returns a new reference to the typeobject on success or `NULL`\non failure.\n\n"}, {"name": "PyObject *PyArray_View()", "path": "reference/c-api/array#c.PyArray_View", "type": "Array API", "text": "\nEquivalent to `ndarray.view` (self, dtype). Return a new view of the array\nself as possibly a different data-type, dtype, and different array subclass\nptype.\n\nIf dtype is `NULL`, then the returned array will have the same data type as\nself. The new data-type must be consistent with the size of self. Either the\nitemsizes must be identical, or self must be single-segment and the total\nnumber of bytes must be the same. In the latter case the dimensions of the\nreturned array will be altered in the last (or first for Fortran-style\ncontiguous arrays) dimension. The data area of the returned array and self is\nexactly the same.\n\n"}, {"name": "PyObject *PyArray_Where()", "path": "reference/c-api/array#c.PyArray_Where", "type": "Array API", "text": "\nIf both `x` and `y` are `NULL`, then return `PyArray_Nonzero` (condition).\nOtherwise, both x and y must be given and the object returned is shaped like\ncondition and has elements of x and y where condition is respectively True or\nFalse.\n\n"}, {"name": "PyObject *PyArray_Zeros()", "path": "reference/c-api/array#c.PyArray_Zeros", "type": "Array API", "text": "\nConstruct a new nd -dimensional array with shape given by dims and data type\ngiven by dtype. If fortran is non-zero, then a Fortran-order array is created,\notherwise a C-order array is created. Fill the memory with zeros (or the 0\nobject if dtype corresponds to `NPY_OBJECT` ).\n\n"}, {"name": "PyObject *PyArray_ZEROS()", "path": "reference/c-api/array#c.PyArray_ZEROS", "type": "Array API", "text": "\nMacro form of `PyArray_Zeros` which takes a type-number instead of a data-type\nobject.\n\n"}, {"name": "PyObject *PyDataMem_GetHandler()", "path": "reference/c-api/data_memory#c.PyDataMem_GetHandler", "type": "Memory management in NumPy", "text": "\nReturn the current policy that will be used to allocate data for the next\n`PyArrayObject`. On failure, return `NULL`.\n\n"}, {"name": "PyObject *PyDataMem_SetHandler()", "path": "reference/c-api/data_memory#c.PyDataMem_SetHandler", "type": "Memory management in NumPy", "text": "\nSet a new allocation policy. If the input value is `NULL`, will reset the\npolicy to the default. Return the previous policy, or return `NULL` if an\nerror has occurred. We wrap the user-provided functions so they will still\ncall the python and numpy memory management callback hooks.\n\n"}, {"name": "PyObject *PyUFunc_FromFuncAndDataAndSignature()", "path": "reference/c-api/ufunc#c.PyUFunc_FromFuncAndDataAndSignature", "type": "UFunc API", "text": "\nThis function is very similar to PyUFunc_FromFuncAndData above, but has an\nextra signature argument, to define a generalized universal functions.\nSimilarly to how ufuncs are built around an element-by-element operation,\ngufuncs are around subarray-by-subarray operations, the signature defining the\nsubarrays to operate on.\n\n"}, {"name": "PyObject *PyUFunc_FromFuncAndDataAndSignatureAndIdentity()", "path": "reference/c-api/ufunc#c.PyUFunc_FromFuncAndDataAndSignatureAndIdentity", "type": "UFunc API", "text": "\nThis function is very similar to `PyUFunc_FromFuncAndDataAndSignature` above,\nbut has an extra identity_value argument, to define an arbitrary identity for\nthe ufunc when `identity` is passed as `PyUFunc_IdentityValue`.\n\n"}, {"name": "PyObject *shape", "path": "reference/c-api/types-and-structures#c.NPY_USE_SETITEM.subarray.PyArray_ArrayDescr.shape", "type": "Python Types and C-Structures", "text": "\nThe shape (always C-style contiguous) of the sub-array as a Python tuple.\n\n"}, {"name": "PyObject *userloops", "path": "reference/c-api/types-and-structures#c.PyUFuncObject.userloops", "type": "Python Types and C-Structures", "text": "\nA dictionary of user-defined 1-d vector loops (stored as CObject ptrs) for\nuser-defined types. A loop may be registered by the user for any user-defined\ntype. It is retrieved by type number. User defined type numbers are always\nlarger than `NPY_USERDEF`.\n\n"}, {"name": "PyObject *weakreflist", "path": "reference/c-api/types-and-structures#c.NPY_AO.weakreflist", "type": "Python Types and C-Structures", "text": "\nThis member allows array objects to have weak references (using the weakref\nmodule).\n\n"}, {"name": "PyTypeObject PyArray_Type", "path": "reference/c-api/types-and-structures", "type": "Python Types and C-Structures", "text": "\nSeveral new types are defined in the C-code. Most of these are accessible from\nPython, but a few are not exposed due to their limited use. Every new Python\ntype has an associated PyObject* with an internal structure that includes a\npointer to a \u201cmethod table\u201d that defines how the new object behaves in Python.\nWhen you receive a Python object into C code, you always get a pointer to a\n`PyObject` structure. Because a `PyObject` structure is very generic and\ndefines only `PyObject_HEAD`, by itself it is not very interesting. However,\ndifferent objects contain more details after the `PyObject_HEAD` (but you have\nto cast to the correct type to access them \u2014 or use accessor functions or\nmacros).\n\nPython types are the functional equivalent in C of classes in Python. By\nconstructing a new Python type you make available a new object for Python. The\nndarray object is an example of a new type defined in C. New types are defined\nin C by two basic steps:\n\nInstead of special method names which define behavior for Python classes,\nthere are \u201cfunction tables\u201d which point to functions that implement the\ndesired results. Since Python 2.2, the PyTypeObject itself has become dynamic\nwhich allows C types that can be \u201csub-typed \u201cfrom other C-types in C, and sub-\nclassed in Python. The children types inherit the attributes and methods from\ntheir parent(s).\n\nThere are two major new types: the ndarray ( `PyArray_Type` ) and the ufunc (\n`PyUFunc_Type` ). Additional types play a supportive role: the\n`PyArrayIter_Type`, the `PyArrayMultiIter_Type`, and the `PyArrayDescr_Type` .\nThe `PyArrayIter_Type` is the type for a flat iterator for an ndarray (the\nobject that is returned when getting the flat attribute). The\n`PyArrayMultiIter_Type` is the type of the object returned when calling\n`broadcast` (). It handles iteration and broadcasting over a collection of\nnested sequences. Also, the `PyArrayDescr_Type` is the data-type-descriptor\ntype whose instances describe the data. Finally, there are 21 new scalar-array\ntypes which are new Python scalars corresponding to each of the fundamental\ndata types available for arrays. An additional 10 other types are place\nholders that allow the array scalars to fit into a hierarchy of actual Python\ntypes.\n\nThe Python type of the ndarray is `PyArray_Type`. In C, every ndarray is a\npointer to a `PyArrayObject` structure. The ob_type member of this structure\ncontains a pointer to the `PyArray_Type` typeobject.\n\nThe `PyArrayObject` C-structure contains all of the required information for\nan array. All instances of an ndarray (and its subclasses) will have this\nstructure. For future compatibility, these structure members should normally\nbe accessed using the provided macros. If you need a shorter name, then you\ncan make use of `NPY_AO` (deprecated) which is defined to be equivalent to\n`PyArrayObject`. Direct access to the struct fields are deprecated. Use the\n`PyArray_*(arr)` form instead. As of NumPy 1.20, the size of this struct is\nnot considered part of the NumPy ABI (see note at the end of the member list).\n\nThis is needed by all Python objects. It consists of (at least) a reference\ncount member ( `ob_refcnt` ) and a pointer to the typeobject ( `ob_type` ).\n(Other elements may also be present if Python was compiled with special\noptions see Include/object.h in the Python source tree for more information).\nThe ob_type member points to a Python type object.\n\nAccessible via `PyArray_DATA`, this data member is a pointer to the first\nelement of the array. This pointer can (and normally should) be recast to the\ndata type of the array.\n\nAn integer providing the number of dimensions for this array. When nd is 0,\nthe array is sometimes called a rank-0 array. Such arrays have undefined\ndimensions and strides and cannot be accessed. Macro `PyArray_NDIM` defined in\n`ndarraytypes.h` points to this data member. `NPY_MAXDIMS` is the largest\nnumber of dimensions for any array.\n\nAn array of integers providing the shape in each dimension as long as nd\n\\\\(\\geq\\\\) 1\\. The integer is always large enough to hold a pointer on the\nplatform, so the dimension size is only limited by memory. `PyArray_DIMS` is\nthe macro associated with this data member.\n\nAn array of integers providing for each dimension the number of bytes that\nmust be skipped to get to the next element in that dimension. Associated with\nmacro `PyArray_STRIDES`.\n\nPointed to by `PyArray_BASE`, this member is used to hold a pointer to another\nPython object that is related to this array. There are two use cases:\n\nWhen `PyArray_ResolveWritebackIfCopy` is called, the array pointed to by base\nwill be updated with the contents of this array.\n\nA pointer to a data-type descriptor object (see below). The data-type\ndescriptor object is an instance of a new built-in type which allows a generic\ndescription of memory. There is a descriptor structure for each data type\nsupported. This descriptor structure contains useful information about the\ntype as well as a pointer to a table of function pointers to implement\nspecific functionality. As the name suggests, it is associated with the macro\n`PyArray_DESCR`.\n\nPointed to by the macro `PyArray_FLAGS`, this data member represents the flags\nindicating how the memory pointed to by data is to be interpreted. Possible\nflags are `NPY_ARRAY_C_CONTIGUOUS`, `NPY_ARRAY_F_CONTIGUOUS`,\n`NPY_ARRAY_OWNDATA`, `NPY_ARRAY_ALIGNED`, `NPY_ARRAY_WRITEABLE`,\n`NPY_ARRAY_WRITEBACKIFCOPY`, and `NPY_ARRAY_UPDATEIFCOPY`.\n\nThis member allows array objects to have weak references (using the weakref\nmodule).\n\nNote\n\nFurther members are considered private and version dependent. If the size of\nthe struct is important for your code, special care must be taken. A possible\nuse-case when this is relevant is subclassing in C. If your code relies on\n`sizeof(PyArrayObject)` to be constant, you must add the following check at\nimport time:\n\nTo ensure that your code does not have to be compiled for a specific NumPy\nversion, you may add a constant, leaving room for changes in NumPy. A solution\nguaranteed to be compatible with any future NumPy version requires the use of\na runtime calculate offset and allocation size.\n\nThe `PyArrayDescr_Type` is the built-in type of the data-type-descriptor\nobjects used to describe how the bytes comprising the array are to be\ninterpreted. There are 21 statically-defined `PyArray_Descr` objects for the\nbuilt-in data-types. While these participate in reference counting, their\nreference count should never reach zero. There is also a dynamic table of\nuser-defined `PyArray_Descr` objects that is also maintained. Once a data-\ntype-descriptor object is \u201cregistered\u201d it should never be deallocated either.\nThe function `PyArray_DescrFromType` (\u2026) can be used to retrieve a\n`PyArray_Descr` object from an enumerated type-number (either built-in or\nuser- defined).\n\nThe `PyArray_Descr` structure lies at the heart of the `PyArrayDescr_Type`.\nWhile it is described here for completeness, it should be considered internal\nto NumPy and manipulated via `PyArrayDescr_*` or `PyDataType*` functions and\nmacros. The size of this structure is subject to change across versions of\nNumPy. To ensure compatibility:\n\nIt has the following structure:\n\nPointer to a typeobject that is the corresponding Python type for the elements\nof this array. For the builtin types, this points to the corresponding array\nscalar. For user-defined types, this should point to a user-defined\ntypeobject. This typeobject can either inherit from array scalars or not. If\nit does not inherit from array scalars, then the `NPY_USE_GETITEM` and\n`NPY_USE_SETITEM` flags should be set in the `flags` member.\n\nA character code indicating the kind of array (using the array interface\ntypestring notation). A \u2018b\u2019 represents Boolean, a \u2018i\u2019 represents signed\ninteger, a \u2018u\u2019 represents unsigned integer, \u2018f\u2019 represents floating point, \u2018c\u2019\nrepresents complex floating point, \u2018S\u2019 represents 8-bit zero-terminated bytes,\n\u2018U\u2019 represents 32-bit/character unicode string, and \u2018V\u2019 represents arbitrary.\n\nA traditional character code indicating the data type.\n\nA character indicating the byte-order: \u2018>\u2019 (big-endian), \u2018<\u2019 (little- endian),\n\u2018=\u2019 (native), \u2018|\u2019 (irrelevant, ignore). All builtin data- types have byteorder\n\u2018=\u2019.\n\nA data-type bit-flag that determines if the data-type exhibits object- array\nlike behavior. Each bit in this member is a flag which are named as:\n\nIndicates that items of this data-type must be reference counted (using\n`Py_INCREF` and `Py_DECREF` ).\n\nSame as `NPY_ITEM_REFCOUNT`.\n\nIndicates arrays of this data-type must be converted to a list before\npickling.\n\nIndicates the item is a pointer to some other data-type\n\nIndicates memory for this data-type must be initialized (set to 0) on\ncreation.\n\nIndicates this data-type requires the Python C-API during access (so don\u2019t\ngive up the GIL if array access is going to be needed).\n\nOn array access use the `f->getitem` function pointer instead of the standard\nconversion to an array scalar. Must use if you don\u2019t define an array scalar to\ngo along with the data-type.\n\nWhen creating a 0-d array from an array scalar use `f->setitem` instead of the\nstandard copy from an array scalar. Must use if you don\u2019t define an array\nscalar to go along with the data-type.\n\nThe bits that are inherited for the parent data-type if these bits are set in\nany field of the data-type. Currently ( `NPY_NEEDS_INIT` | `NPY_LIST_PICKLE` |\n`NPY_ITEM_REFCOUNT` | `NPY_NEEDS_PYAPI` ).\n\nBits set for the object data-type: ( `NPY_LIST_PICKLE` | `NPY_USE_GETITEM` |\n`NPY_ITEM_IS_POINTER` | `NPY_ITEM_REFCOUNT` | `NPY_NEEDS_INIT` |\n`NPY_NEEDS_PYAPI`).\n\nReturn true if all the given flags are set for the data-type object.\n\nEquivalent to `PyDataType_FLAGCHK` (dtype, `NPY_ITEM_REFCOUNT`).\n\nA number that uniquely identifies the data type. For new data-types, this\nnumber is assigned when the data-type is registered.\n\nFor data types that are always the same size (such as long), this holds the\nsize of the data type. For flexible data types where different arrays can have\na different elementsize, this should be 0.\n\nA number providing alignment information for this data type. Specifically, it\nshows how far from the start of a 2-element structure (whose first element is\na `char` ), the compiler places an item of this type: `offsetof(struct {char\nc; type v;}, v)`\n\nIf this is non- `NULL`, then this data-type descriptor is a C-style contiguous\narray of another data-type descriptor. In other-words, each element that this\ndescriptor describes is actually an array of some other base descriptor. This\nis most useful as the data-type descriptor for a field in another data-type\ndescriptor. The fields member should be `NULL` if this is non- `NULL` (the\nfields member of the base descriptor can be non- `NULL` however).\n\nThe data-type-descriptor object of the base-type.\n\nThe shape (always C-style contiguous) of the sub-array as a Python tuple.\n\nIf this is non-NULL, then this data-type-descriptor has fields described by a\nPython dictionary whose keys are names (and also titles if given) and whose\nvalues are tuples that describe the fields. Recall that a data-type-descriptor\nalways describes a fixed-length set of bytes. A field is a named sub-region of\nthat total, fixed-length collection. A field is described by a tuple composed\nof another data- type-descriptor and a byte offset. Optionally, the tuple may\ncontain a title which is normally a Python string. These tuples are placed in\nthis dictionary keyed by name (and also title if given).\n\nAn ordered tuple of field names. It is NULL if no field is defined.\n\nA pointer to a structure containing functions that the type needs to implement\ninternal features. These functions are not the same thing as the universal\nfunctions (ufuncs) described later. Their signatures can vary arbitrarily.\n\nMetadata about this dtype.\n\nMetadata specific to the C implementation of the particular dtype. Added for\nNumPy 1.7.0.\n\nCurrently unused. Reserved for future use in caching hash values.\n\nFunctions implementing internal features. Not all of these function pointers\nmust be defined for a given type. The required members are `nonzero`,\n`copyswap`, `copyswapn`, `setitem`, `getitem`, and `cast`. These are assumed\nto be non- `NULL` and `NULL` entries will cause a program crash. The other\nfunctions may be `NULL` which will just mean reduced functionality for that\ndata-type. (Also, the nonzero function will be filled in with a default\nfunction if it is `NULL` when you register a user-defined data-type).\n\nThe concept of a behaved segment is used in the description of the function\npointers. A behaved segment is one that is aligned and in native machine byte-\norder for the data-type. The `nonzero`, `copyswap`, `copyswapn`, `getitem`,\nand `setitem` functions can (and must) deal with mis-behaved arrays. The other\nfunctions require behaved memory segments.\n\nAn array of function pointers to cast from the current type to all of the\nother builtin types. Each function casts a contiguous, aligned, and notswapped\nbuffer pointed at by from to a contiguous, aligned, and notswapped buffer\npointed at by to The number of items to cast is given by n, and the arguments\nfromarr and toarr are interpreted as PyArrayObjects for flexible arrays to get\nitemsize information.\n\nA pointer to a function that returns a standard Python object from a single\nelement of the array object arr pointed to by data. This function must be able\nto deal with \u201cmisbehaved \u201c(misaligned and/or swapped) arrays correctly.\n\nA pointer to a function that sets the Python object item into the array, arr,\nat the position pointed to by data . This function deals with \u201cmisbehaved\u201d\narrays. If successful, a zero is returned, otherwise, a negative one is\nreturned (and a Python error set).\n\nThese members are both pointers to functions to copy data from src to dest and\nswap if indicated. The value of arr is only used for flexible ( `NPY_STRING`,\n`NPY_UNICODE`, and `NPY_VOID` ) arrays (and is obtained from\n`arr->descr->elsize` ). The second function copies a single value, while the\nfirst loops over n values with the provided strides. These functions can deal\nwith misbehaved src data. If src is NULL then no copy is performed. If swap is\n0, then no byteswapping occurs. It is assumed that dest and src do not\noverlap. If they overlap, then use `memmove` (\u2026) first followed by\n`copyswap(n)` with NULL valued `src`.\n\nA pointer to a function that compares two elements of the array, `arr`,\npointed to by `d1` and `d2`. This function requires behaved (aligned and not\nswapped) arrays. The return value is 1 if * `d1` > * `d2`, 0 if * `d1` == *\n`d2`, and -1 if * `d1` < * `d2`. The array object `arr` is used to retrieve\nitemsize and field information for flexible arrays.\n\nA pointer to a function that retrieves the index of the largest of `n`\nelements in `arr` beginning at the element pointed to by `data`. This function\nrequires that the memory segment be contiguous and behaved. The return value\nis always 0. The index of the largest element is returned in `max_ind`.\n\nA pointer to a function that multiplies two `n` -length sequences together,\nadds them, and places the result in element pointed to by `op` of `arr`. The\nstart of the two sequences are pointed to by `ip1` and `ip2`. To get to the\nnext element in each sequence requires a jump of `is1` and `is2` bytes,\nrespectively. This function requires behaved (though not necessarily\ncontiguous) memory.\n\nA pointer to a function that scans (scanf style) one element of the\ncorresponding type from the file descriptor `fd` into the array memory pointed\nto by `ip`. The array is assumed to be behaved. The last argument `arr` is the\narray to be scanned into. Returns number of receiving arguments successfully\nassigned (which may be zero in case a matching failure occurred before the\nfirst receiving argument was assigned), or EOF if input failure occurs before\nthe first receiving argument was assigned. This function should be called\nwithout holding the Python GIL, and has to grab it for error reporting.\n\nA pointer to a function that converts the string pointed to by `str` to one\nelement of the corresponding type and places it in the memory location pointed\nto by `ip`. After the conversion is completed, `*endptr` points to the rest of\nthe string. The last argument `arr` is the array into which ip points (needed\nfor variable-size data- types). Returns 0 on success or -1 on failure.\nRequires a behaved array. This function should be called without holding the\nPython GIL, and has to grab it for error reporting.\n\nA pointer to a function that returns TRUE if the item of `arr` pointed to by\n`data` is nonzero. This function can deal with misbehaved arrays.\n\nA pointer to a function that fills a contiguous array of given length with\ndata. The first two elements of the array must already be filled- in. From\nthese two values, a delta will be computed and the values from item 3 to the\nend will be computed by repeatedly adding this computed delta. The data buffer\nmust be well-behaved.\n\nA pointer to a function that fills a contiguous `buffer` of the given `length`\nwith a single scalar `value` whose address is given. The final argument is the\narray which is needed to get the itemsize for variable-length arrays.\n\nAn array of function pointers to a particular sorting algorithms. A particular\nsorting algorithm is obtained using a key (so far `NPY_QUICKSORT`,\n`NPY_HEAPSORT`, and `NPY_MERGESORT` are defined). These sorts are done in-\nplace assuming contiguous and aligned data.\n\nAn array of function pointers to sorting algorithms for this data type. The\nsame sorting algorithms as for sort are available. The indices producing the\nsort are returned in `result` (which must be initialized with indices 0 to\n`length-1` inclusive).\n\nEither `NULL` or a dictionary containing low-level casting functions for user-\ndefined data-types. Each function is wrapped in a PyCapsule* and keyed by the\ndata-type number.\n\nA function to determine how scalars of this type should be interpreted. The\nargument is `NULL` or a 0-dimensional array containing the data (if that is\nneeded to determine the kind of scalar). The return value must be of type\n`NPY_SCALARKIND`.\n\nEither `NULL` or an array of `NPY_NSCALARKINDS` pointers. These pointers\nshould each be either `NULL` or a pointer to an array of integers (terminated\nby `NPY_NOTYPE`) indicating data-types that a scalar of this data-type of the\nspecified kind can be cast to safely (this usually means without losing\nprecision).\n\nEither `NULL` or an array of integers (terminated by `NPY_NOTYPE` ) indicated\ndata-types that this data-type can be cast to safely (this usually means\nwithout losing precision).\n\nDeprecated since version 1.17: The use of this function will give a\ndeprecation warning when `np.clip`. Instead of this function, the datatype\nmust instead use `PyUFunc_RegisterLoopForDescr` to attach a custom loop to\n`np.core.umath.clip`, `np.minimum`, and `np.maximum`.\n\nDeprecated since version 1.19: Setting this function is deprecated and should\nalways be `NULL`, if set, it will be ignored.\n\nA function that reads `n_in` items from `in`, and writes to `out` the read\nvalue if it is within the limits pointed to by `min` and `max`, or the\ncorresponding limit if outside. The memory segments must be contiguous and\nbehaved, and either `min` or `max` may be `NULL`, but not both.\n\nDeprecated since version 1.19: Setting this function is deprecated and should\nalways be `NULL`, if set, it will be ignored.\n\nA function that takes a pointer `in` to an array of `n_in` items, a pointer\n`mask` to an array of `n_in` boolean values, and a pointer `vals` to an array\nof `nv` items. Items from `vals` are copied into `in` wherever the value in\n`mask` is non-zero, tiling `vals` as needed if `nv < n_in`. All arrays must be\ncontiguous and behaved.\n\nDeprecated since version 1.19: Setting this function is deprecated and should\nalways be `NULL`, if set, it will be ignored.\n\nA function that takes a pointer `src` to a C contiguous, behaved segment,\ninterpreted as a 3-dimensional array of shape `(n_outer, nindarray, nelem)`, a\npointer `indarray` to a contiguous, behaved segment of `m_middle` integer\nindices, and a pointer `dest` to a C contiguous, behaved segment, interpreted\nas a 3-dimensional array of shape `(n_outer, m_middle, nelem)`. The indices in\n`indarray` are used to index `src` along the second dimension, and copy the\ncorresponding chunks of `nelem` items into `dest`. `clipmode` (which can take\non the values `NPY_RAISE`, `NPY_WRAP` or `NPY_CLIP`) determines how will\nindices smaller than 0 or larger than `nindarray` will be handled.\n\nA pointer to a function that retrieves the index of the smallest of `n`\nelements in `arr` beginning at the element pointed to by `data`. This function\nrequires that the memory segment be contiguous and behaved. The return value\nis always 0. The index of the smallest element is returned in `min_ind`.\n\nThe `PyArray_Type` typeobject implements many of the features of `Python\nobjects` including the `tp_as_number`, `tp_as_sequence`, `tp_as_mapping`, and\n`tp_as_buffer` interfaces. The `rich comparison`) is also used along with new-\nstyle attribute lookup for member (`tp_members`) and properties (`tp_getset`).\nThe `PyArray_Type` can also be sub-typed.\n\nTip\n\nThe `tp_as_number` methods use a generic approach to call whatever function\nhas been registered for handling the operation. When the `_multiarray_umath\nmodule` is imported, it sets the numeric operations for all arrays to the\ncorresponding ufuncs. This choice can be changed with\n`PyUFunc_ReplaceLoopBySignature` The `tp_str` and `tp_repr` methods can also\nbe altered using `PyArray_SetStringFunction`.\n\nThe ufunc object is implemented by creation of the `PyUFunc_Type`. It is a\nvery simple type that implements only basic getattribute behavior, printing\nbehavior, and has call behavior which allows these objects to act like\nfunctions. The basic idea behind the ufunc is to hold a reference to fast\n1-dimensional (vector) loops for each data type that supports the operation.\nThese one-dimensional loops all have the same signature and are the key to\ncreating a new ufunc. They are called by the generic looping code as\nappropriate to implement the N-dimensional function. There are also some\ngeneric 1-d loops defined for floating and complexfloating arrays that allow\nyou to define a ufunc using a single scalar function (e.g. atanh).\n\nThe core of the ufunc is the `PyUFuncObject` which contains all the\ninformation needed to call the underlying C-code loops that perform the actual\nwork. While it is described here for completeness, it should be considered\ninternal to NumPy and manipulated via `PyUFunc_*` functions. The size of this\nstructure is subject to change across versions of NumPy. To ensure\ncompatibility:\n\nIt has the following structure:\n\nThe number of input arguments.\n\nThe number of output arguments.\n\nThe total number of arguments (nin \\+ nout). This must be less than\n`NPY_MAXARGS`.\n\nEither `PyUFunc_One`, `PyUFunc_Zero`, `PyUFunc_MinusOne`, `PyUFunc_None`,\n`PyUFunc_ReorderableNone`, or `PyUFunc_IdentityValue` to indicate the identity\nfor this operation. It is only used for a reduce-like call on an empty array.\n\nAn array of function pointers \u2014 one for each data type supported by the ufunc.\nThis is the vector loop that is called to implement the underlying function\ndims [0] times. The first argument, args, is an array of nargs pointers to\nbehaved memory. Pointers to the data for the input arguments are first,\nfollowed by the pointers to the data for the output arguments. How many bytes\nmust be skipped to get to the next element in the sequence is specified by the\ncorresponding entry in the steps array. The last argument allows the loop to\nreceive extra information. This is commonly used so that a single, generic\nvector loop can be used for multiple functions. In this case, the actual\nscalar function to call is passed in as extradata. The size of this function\npointer array is ntypes.\n\nExtra data to be passed to the 1-d vector loops or `NULL` if no extra-data is\nneeded. This C-array must be the same size ( i.e. ntypes) as the functions\narray. `NULL` is used if extra_data is not needed. Several C-API calls for\nUFuncs are just 1-d vector loops that make use of this extra data to receive a\npointer to the actual function to call.\n\nThe number of supported data types for the ufunc. This number specifies how\nmany different 1-d loops (of the builtin data types) are available.\n\nUnused.\n\nA string name for the ufunc. This is used dynamically to build the __doc__\nattribute of ufuncs.\n\nAn array of \\\\(nargs \\times ntypes\\\\) 8-bit type_numbers which contains the\ntype signature for the function for each of the supported (builtin) data\ntypes. For each of the ntypes functions, the corresponding set of type numbers\nin this array shows how the args argument should be interpreted in the 1-d\nvector loop. These type numbers do not have to be the same type and mixed-type\nufuncs are supported.\n\nDocumentation for the ufunc. Should not contain the function signature as this\nis generated dynamically when __doc__ is retrieved.\n\nAny dynamically allocated memory. Currently, this is used for dynamic ufuncs\ncreated from a python function to store room for the types, data, and name\nmembers.\n\nFor ufuncs dynamically created from python functions, this member holds a\nreference to the underlying Python function.\n\nA dictionary of user-defined 1-d vector loops (stored as CObject ptrs) for\nuser-defined types. A loop may be registered by the user for any user-defined\ntype. It is retrieved by type number. User defined type numbers are always\nlarger than `NPY_USERDEF`.\n\n0 for scalar ufuncs; 1 for generalized ufuncs\n\nNumber of distinct core dimension names in the signature\n\nNumber of core dimensions of each argument\n\nDimension indices in a flattened form; indices of argument `k` are stored in\n`core_dim_ixs[core_offsets[k] : core_offsets[k] + core_numdims[k]]`\n\nPosition of 1st core dimension of each argument in `core_dim_ixs`, equivalent\nto cumsum(`core_num_dims`)\n\nCore signature string\n\nA function which resolves the types and fills an array with the dtypes for the\ninputs and outputs\n\nDeprecated since version 1.22: Some fallback support for this slot exists, but\nwill be removed eventually. A universal function that relied on this will have\nto be ported eventually. See ref:`NEP 41` and ref:`NEP 43`\n\nFor a possible future loop selector with a different signature.\n\nOverride the default operand flags for each ufunc operand.\n\nOverride the default nditer flags for the ufunc.\n\nAdded in API version 0x0000000D\n\nFor each distinct core dimension, the possible frozen size if\n`UFUNC_CORE_DIM_SIZE_INFERRED` is `0`\n\nFor each distinct core dimension, a set of `UFUNC_CORE_DIM*` flags\n\nif the dim name ends in `?`\n\nif the dim size will be determined from the operands and not from a frozen\nsignature\n\nIdentity for reduction, when `PyUFuncObject.identity` is equal to\n`PyUFunc_IdentityValue`.\n\nThis is an iterator object that makes it easy to loop over an N-dimensional\narray. It is the object returned from the flat attribute of an ndarray. It is\nalso used extensively throughout the implementation internals to loop over an\nN-dimensional array. The tp_as_mapping interface is implemented so that the\niterator object can be indexed (using 1-d indexing), and a few methods are\nimplemented through the tp_methods table. This object implements the next\nmethod and can be used anywhere an iterator can be used in Python.\n\nThe C-structure corresponding to an object of `PyArrayIter_Type` is the\n`PyArrayIterObject`. The `PyArrayIterObject` is used to keep track of a\npointer into an N-dimensional array. It contains associated information used\nto quickly march through the array. The pointer can be adjusted in three basic\nways: 1) advance to the \u201cnext\u201d position in the array in a C-style contiguous\nfashion, 2) advance to an arbitrary N-dimensional coordinate in the array, and\n3) advance to an arbitrary one-dimensional index into the array. The members\nof the `PyArrayIterObject` structure are used in these calculations. Iterator\nobjects keep their own dimension and strides information about an array. This\ncan be adjusted as needed for \u201cbroadcasting,\u201d or to loop over only specific\ndimensions.\n\n\\\\(N-1\\\\) where \\\\(N\\\\) is the number of dimensions in the underlying array.\n\nThe current 1-d index into the array.\n\nThe total size of the underlying array.\n\nAn \\\\(N\\\\) -dimensional index into the array.\n\nThe size of the array minus 1 in each dimension.\n\nThe strides of the array. How many bytes needed to jump to the next element in\neach dimension.\n\nHow many bytes needed to jump from the end of a dimension back to its\nbeginning. Note that `backstrides[k] == strides[k] * dims_m1[k]`, but it is\nstored here as an optimization.\n\nThis array is used in computing an N-d index from a 1-d index. It contains\nneeded products of the dimensions.\n\nA pointer to the underlying ndarray this iterator was created to represent.\n\nThis member points to an element in the ndarray indicated by the index.\n\nThis flag is true if the underlying array is `NPY_ARRAY_C_CONTIGUOUS`. It is\nused to simplify calculations when possible.\n\nHow to use an array iterator on a C-level is explained more fully in later\nsections. Typically, you do not need to concern yourself with the internal\nstructure of the iterator object, and merely interact with it through the use\nof the macros `PyArray_ITER_NEXT` (it), `PyArray_ITER_GOTO` (it, dest), or\n`PyArray_ITER_GOTO1D` (it, index). All of these macros require the argument it\nto be a PyArrayIterObject*.\n\nThis type provides an iterator that encapsulates the concept of broadcasting.\nIt allows \\\\(N\\\\) arrays to be broadcast together so that the loop progresses\nin C-style contiguous fashion over the broadcasted array. The corresponding\nC-structure is the `PyArrayMultiIterObject` whose memory layout must begin any\nobject, obj, passed in to the `PyArray_Broadcast` (obj) function. Broadcasting\nis performed by adjusting array iterators so that each iterator represents the\nbroadcasted shape and size, but has its strides adjusted so that the correct\nelement from the array is used at each iteration.\n\nThe number of arrays that need to be broadcast to the same shape.\n\nThe total broadcasted size.\n\nThe current (1-d) index into the broadcasted result.\n\nThe number of dimensions in the broadcasted result.\n\nThe shape of the broadcasted result (only `nd` slots are used).\n\nAn array of iterator objects that holds the iterators for the arrays to be\nbroadcast together. On return, the iterators are adjusted for broadcasting.\n\nThis is an iterator object that makes it easy to loop over an N-dimensional\nneighborhood.\n\nThe C-structure corresponding to an object of `PyArrayNeighborhoodIter_Type`\nis the `PyArrayNeighborhoodIterObject`.\n\nWhen the flags attribute is retrieved from Python, a special builtin object of\nthis type is constructed. This special type makes it easier to work with the\ndifferent flags by accessing them as attributes or by accessing them as if the\nobject were a dictionary with the flag names as entries.\n\nThere is a Python type for each of the different built-in data types that can\nbe present in the array Most of these are simple wrappers around the\ncorresponding data type in C. The C-names for these types are\n`Py{TYPE}ArrType_Type` where `{TYPE}` can be\n\nBool, Byte, Short, Int, Long, LongLong, UByte, UShort, UInt, ULong, ULongLong,\nHalf, Float, Double, LongDouble, CFloat, CDouble, CLongDouble, String,\nUnicode, Void, and Object.\n\nThese type names are part of the C-API and can therefore be created in\nextension C-code. There is also a `PyIntpArrType_Type` and a\n`PyUIntpArrType_Type` that are simple substitutes for one of the integer types\nthat can hold a pointer on the platform. The structure of these scalar objects\nis not exposed to C-code. The function `PyArray_ScalarAsCtype` (..) can be\nused to extract the C-type value from the array scalar and the function\n`PyArray_Scalar` (\u2026) can be used to construct an array scalar from a C-value.\n\nA few new C-structures were found to be useful in the development of NumPy.\nThese C-structures are used in at least one C-API call and are therefore\ndocumented here. The main reason these structures were defined is to make it\neasy to use the Python ParseTuple C-API to convert from Python objects to a\nuseful C-Object.\n\nThis structure is very useful when shape and/or strides information is\nsupposed to be interpreted. The structure is:\n\nThe members of this structure are\n\nA pointer to a list of (`npy_intp`) integers which usually represent array\nshape or array strides.\n\nThe length of the list of integers. It is assumed safe to access ptr [0] to\nptr [len-1].\n\nThis is equivalent to the buffer object structure in Python up to the ptr\nmember. On 32-bit platforms (i.e. if `NPY_SIZEOF_INT` == `NPY_SIZEOF_INTP`),\nthe len member also matches an equivalent member of the buffer object. It is\nuseful to represent a generic single-segment chunk of memory.\n\nThe members are\n\nThe Python object this chunk of memory comes from. Needed so that memory can\nbe accounted for properly.\n\nA pointer to the start of the single-segment chunk of memory.\n\nThe length of the segment in bytes.\n\nAny data flags (e.g. `NPY_ARRAY_WRITEABLE` ) that should be used to interpret\nthe memory.\n\nSee also\n\nThe Array Interface\n\nThe `PyArrayInterface` structure is defined so that NumPy and other extension\nmodules can use the rapid array interface protocol. The `__array_struct__`\nmethod of an object that supports the rapid array interface protocol should\nreturn a `PyCapsule` that contains a pointer to a `PyArrayInterface` structure\nwith the relevant details of the array. After the new array is created, the\nattribute should be `DECREF`\u2019d which will free the `PyArrayInterface`\nstructure. Remember to `INCREF` the object (whose `__array_struct__` attribute\nwas retrieved) and point the base member of the new `PyArrayObject` to this\nsame object. In this way the memory for the array will be managed correctly.\n\nthe integer 2 as a sanity check.\n\nthe number of dimensions in the array.\n\nA character indicating what kind of array is present according to the\ntypestring convention with \u2018t\u2019 -> bitfield, \u2018b\u2019 -> Boolean, \u2018i\u2019 -> signed\ninteger, \u2018u\u2019 -> unsigned integer, \u2018f\u2019 -> floating point, \u2018c\u2019 -> complex\nfloating point, \u2018O\u2019 -> object, \u2018S\u2019 -> (byte-)string, \u2018U\u2019 -> unicode, \u2018V\u2019 ->\nvoid.\n\nThe number of bytes each item in the array requires.\n\nAny of the bits `NPY_ARRAY_C_CONTIGUOUS` (1), `NPY_ARRAY_F_CONTIGUOUS` (2),\n`NPY_ARRAY_ALIGNED` (0x100), `NPY_ARRAY_NOTSWAPPED` (0x200), or\n`NPY_ARRAY_WRITEABLE` (0x400) to indicate something about the data. The\n`NPY_ARRAY_ALIGNED`, `NPY_ARRAY_C_CONTIGUOUS`, and `NPY_ARRAY_F_CONTIGUOUS`\nflags can actually be determined from the other parameters. The flag\n`NPY_ARR_HAS_DESCR` (0x800) can also be set to indicate to objects consuming\nthe version 3 array interface that the descr member of the structure is\npresent (it will be ignored by objects consuming version 2 of the array\ninterface).\n\nAn array containing the size of the array in each dimension.\n\nAn array containing the number of bytes to jump to get to the next element in\neach dimension.\n\nA pointer to the first element of the array.\n\nA Python object describing the data-type in more detail (same as the descr key\nin `__array_interface__`). This can be `NULL` if typekind and itemsize provide\nenough information. This field is also ignored unless `NPY_ARR_HAS_DESCR` flag\nis on in flags.\n\nInternally, the code uses some additional Python objects primarily for memory\nmanagement. These types are not accessible directly from Python, and are not\nexposed to the C-API. They are included here only for completeness and\nassistance in understanding the code.\n\nA loose wrapper for a C-structure that contains the information needed for\nlooping. This is useful if you are trying to understand the ufunc looping\ncode. The `PyUFuncLoopObject` is the associated C-structure. It is defined in\nthe `ufuncobject.h` header.\n\nA loose wrapper for the C-structure that contains the information needed for\nreduce-like methods of ufuncs. This is useful if you are trying to understand\nthe reduce, accumulate, and reduce-at code. The `PyUFuncReduceObject` is the\nassociated C-structure. It is defined in the `ufuncobject.h` header.\n\nA simple linked-list of C-structures containing the information needed to\ndefine a 1-d loop for a ufunc for every defined signature of a user-defined\ndata-type.\n\nAdvanced indexing is handled with this Python type. It is simply a loose\nwrapper around the C-structure containing the variables needed for advanced\narray indexing. The associated C-structure, `PyArrayMapIterObject`, is useful\nif you are trying to understand the advanced-index mapping code. It is defined\nin the `arrayobject.h` header. This type is not exposed to Python and could be\nreplaced with a C-structure. As a Python type it takes advantage of reference-\ncounted memory management.\n\n"}, {"name": "PyTypeObject PyArrayMapIter_Type", "path": "reference/c-api/types-and-structures#c.PyArrayMapIter_Type", "type": "Python Types and C-Structures", "text": "\nAdvanced indexing is handled with this Python type. It is simply a loose\nwrapper around the C-structure containing the variables needed for advanced\narray indexing. The associated C-structure, `PyArrayMapIterObject`, is useful\nif you are trying to understand the advanced-index mapping code. It is defined\nin the `arrayobject.h` header. This type is not exposed to Python and could be\nreplaced with a C-structure. As a Python type it takes advantage of reference-\ncounted memory management.\n\n"}, {"name": "PyUFunc_IdentityValue", "path": "reference/c-api/ufunc#c.PyUFunc_IdentityValue", "type": "UFunc API", "text": "\n\n"}, {"name": "PyUFunc_LegacyInnerLoopSelectionFunc *legacy_inner_loop_selector", "path": "reference/c-api/types-and-structures#c.PyUFuncObject.legacy_inner_loop_selector", "type": "Python Types and C-Structures", "text": "\nDeprecated since version 1.22: Some fallback support for this slot exists, but\nwill be removed eventually. A universal function that relied on this will have\nto be ported eventually. See ref:`NEP 41` and ref:`NEP 43`\n\n"}, {"name": "PyUFunc_MinusOne", "path": "reference/c-api/ufunc#c.PyUFunc_MinusOne", "type": "UFunc API", "text": "\n\n"}, {"name": "PyUFunc_None", "path": "reference/c-api/ufunc#c.PyUFunc_None", "type": "UFunc API", "text": "\n\n"}, {"name": "PyUFunc_ReorderableNone", "path": "reference/c-api/ufunc#c.PyUFunc_ReorderableNone", "type": "UFunc API", "text": "\n\n"}, {"name": "PyUFunc_TypeResolutionFunc *type_resolver", "path": "reference/c-api/types-and-structures#c.PyUFuncObject.type_resolver", "type": "Python Types and C-Structures", "text": "\nA function which resolves the types and fills an array with the dtypes for the\ninputs and outputs\n\n"}, {"name": "PyUFunc_Zero", "path": "reference/c-api/ufunc#c.PyUFunc_Zero", "type": "UFunc API", "text": "\n\n"}, {"name": "Random sampling (numpy.random)", "path": "reference/random/index", "type": "Random sampling ( \n      \n       numpy.random\n      \n      )", "text": "\nNumpy\u2019s random number routines produce pseudo random numbers using\ncombinations of a `BitGenerator` to create sequences and a `Generator` to use\nthose sequences to sample from different statistical distributions:\n\nSince Numpy version 1.17.0 the Generator can be initialized with a number of\ndifferent BitGenerators. It exposes many different probability distributions.\nSee NEP 19 for context on the updated random Numpy number routines. The legacy\n`RandomState` random number routines are still available, but limited to a\nsingle BitGenerator. See What\u2019s New or Different for a complete list of\nimprovements and differences from the legacy `RandomState`.\n\nFor convenience and backward compatibility, a single `RandomState` instance\u2019s\nmethods are imported into the numpy.random namespace, see Legacy Random\nGeneration for the complete list.\n\nCall `default_rng` to get a new instance of a `Generator`, then call its\nmethods to obtain samples from different distributions. By default,\n`Generator` uses bits provided by `PCG64` which has better statistical\nproperties than the legacy `MT19937` used in `RandomState`.\n\n`Generator` can be used as a replacement for `RandomState`. Both class\ninstances hold an internal `BitGenerator` instance to provide the bit stream,\nit is accessible as `gen.bit_generator`. Some long-overdue API cleanup means\nthat legacy and compatibility methods have been removed from `Generator`\n\n`RandomState`\n\n`Generator`\n\nNotes\n\n`random_sample`,\n\n`random`\n\nCompatible with `random.random`\n\n`rand`\n\n`randint`,\n\n`integers`\n\nAdd an `endpoint` kwarg\n\n`random_integers`\n\n`tomaxint`\n\nremoved\n\nUse `integers(0, np.iinfo(np.int_).max,` `endpoint=False)`\n\n`seed`\n\nremoved\n\nUse `SeedSequence.spawn`\n\nSee What\u2019s New or Different for more information.\n\nSomething like the following code can be used to support both `RandomState`\nand `Generator`, with the understanding that the interfaces are slightly\ndifferent\n\nSeeds can be passed to any of the BitGenerators. The provided value is mixed\nvia `SeedSequence` to spread a possible sequence of seeds across a wider range\nof initialization states for the BitGenerator. Here `PCG64` is used and is\nwrapped with a `Generator`.\n\nHere we use `default_rng` to create an instance of `Generator` to generate a\nrandom float:\n\nHere we use `default_rng` to create an instance of `Generator` to generate 3\nrandom integers between 0 (inclusive) and 10 (exclusive):\n\nThe new infrastructure takes a different approach to producing random numbers\nfrom the `RandomState` object. Random number generation is separated into two\ncomponents, a bit generator and a random generator.\n\nThe `BitGenerator` has a limited set of responsibilities. It manages state and\nprovides functions to produce random doubles and random unsigned 32- and\n64-bit values.\n\nThe `random generator` takes the bit generator-provided stream and transforms\nthem into more useful distributions, e.g., simulated normal random values.\nThis structure allows alternative bit generators to be used with little code\nduplication.\n\nThe `Generator` is the user-facing object that is nearly identical to the\nlegacy `RandomState`. It accepts a bit generator instance as an argument. The\ndefault is currently `PCG64` but this may change in future versions. As a\nconvenience NumPy provides the `default_rng` function to hide these details:\n\nOne can also instantiate `Generator` directly with a `BitGenerator` instance.\n\nTo use the default `PCG64` bit generator, one can instantiate it directly and\npass it to `Generator`:\n\nSimilarly to use the older `MT19937` bit generator (not recommended), one can\ninstantiate it directly and pass it to `Generator`:\n\nWarning\n\nThe Box-Muller method used to produce NumPy\u2019s normals is no longer available\nin `Generator`. It is not possible to reproduce the exact random values using\nGenerator for the normal distribution or any other distribution that relies on\nthe normal such as the `RandomState.gamma` or `RandomState.standard_t`. If you\nrequire bitwise backward compatible streams, use `RandomState`.\n\nSee What\u2019s New or Different for a complete list of improvements and\ndifferences from the traditional `Randomstate`.\n\nThe included generators can be used in parallel, distributed applications in\none of three ways:\n\nUsers with a very large amount of parallelism will want to consult Upgrading\nPCG64 with PCG64DXSM.\n\nThis package was developed independently of NumPy and was integrated in\nversion 1.17.0. The original repo is at https://github.com/bashtage/randomgen.\n\n"}, {"name": "random.beta()", "path": "reference/random/generated/numpy.random.beta", "type": "numpy.random.beta", "text": "\nDraw samples from a Beta distribution.\n\nThe Beta distribution is a special case of the Dirichlet distribution, and is\nrelated to the Gamma distribution. It has the probability distribution\nfunction\n\nwhere the normalization, B, is the beta function,\n\nIt is often seen in Bayesian inference and order statistics.\n\nNote\n\nNew code should use the `beta` method of a `default_rng()` instance instead;\nplease see the Quick Start.\n\nAlpha, positive (>0).\n\nBeta, positive (>0).\n\nOutput shape. If the given shape is, e.g., `(m, n, k)`, then `m * n * k`\nsamples are drawn. If size is `None` (default), a single value is returned if\n`a` and `b` are both scalars. Otherwise, `np.broadcast(a, b).size` samples are\ndrawn.\n\nDrawn samples from the parameterized beta distribution.\n\nSee also\n\nwhich should be used for new code.\n\n"}, {"name": "random.binomial()", "path": "reference/random/generated/numpy.random.binomial", "type": "numpy.random.binomial", "text": "\nDraw samples from a binomial distribution.\n\nSamples are drawn from a binomial distribution with specified parameters, n\ntrials and p probability of success where n an integer >= 0 and p is in the\ninterval [0,1]. (n may be input as a float, but it is truncated to an integer\nin use)\n\nNote\n\nNew code should use the `binomial` method of a `default_rng()` instance\ninstead; please see the Quick Start.\n\nParameter of the distribution, >= 0. Floats are also accepted, but they will\nbe truncated to integers.\n\nParameter of the distribution, >= 0 and <=1.\n\nOutput shape. If the given shape is, e.g., `(m, n, k)`, then `m * n * k`\nsamples are drawn. If size is `None` (default), a single value is returned if\n`n` and `p` are both scalars. Otherwise, `np.broadcast(n, p).size` samples are\ndrawn.\n\nDrawn samples from the parameterized binomial distribution, where each sample\nis equal to the number of successes over the n trials.\n\nSee also\n\nprobability density function, distribution or cumulative density function,\netc.\n\nwhich should be used for new code.\n\nThe probability density for the binomial distribution is\n\nwhere \\\\(n\\\\) is the number of trials, \\\\(p\\\\) is the probability of success,\nand \\\\(N\\\\) is the number of successes.\n\nWhen estimating the standard error of a proportion in a population by using a\nrandom sample, the normal distribution works well unless the product p*n <=5,\nwhere p = population proportion estimate, and n = number of samples, in which\ncase the binomial distribution is used instead. For example, a sample of 15\npeople shows 4 who are left handed, and 11 who are right handed. Then p = 4/15\n= 27%. 0.27*15 = 4, so the binomial distribution should be used in this case.\n\nDalgaard, Peter, \u201cIntroductory Statistics with R\u201d, Springer-Verlag, 2002.\n\nGlantz, Stanton A. \u201cPrimer of Biostatistics.\u201d, McGraw-Hill, Fifth Edition,\n2002.\n\nLentner, Marvin, \u201cElementary Applied Statistics\u201d, Bogden and Quigley, 1972.\n\nWeisstein, Eric W. \u201cBinomial Distribution.\u201d From MathWorld\u2013A Wolfram Web\nResource. http://mathworld.wolfram.com/BinomialDistribution.html\n\nWikipedia, \u201cBinomial distribution\u201d,\nhttps://en.wikipedia.org/wiki/Binomial_distribution\n\nDraw samples from the distribution:\n\nA real world example. A company drills 9 wild-cat oil exploration wells, each\nwith an estimated probability of success of 0.1. All nine wells fail. What is\nthe probability of that happening?\n\nLet\u2019s do 20,000 trials of the model, and count the number that generate zero\npositive results.\n\n"}, {"name": "random.BitGenerator.cffi", "path": "reference/random/bit_generators/generated/numpy.random.bitgenerator.cffi", "type": "Random sampling", "text": "\nattribute\n\nCFFI interface\n\nNamed tuple containing CFFI wrapper\n\n"}, {"name": "random.BitGenerator.random_raw()", "path": "reference/random/bit_generators/generated/numpy.random.bitgenerator.random_raw", "type": "numpy.random.BitGenerator", "text": "\nmethod\n\nReturn randoms as generated by the underlying BitGenerator\n\nOutput shape. If the given shape is, e.g., `(m, n, k)`, then `m * n * k`\nsamples are drawn. Default is None, in which case a single value is returned.\n\nOutput values. Used for performance testing since the generated values are not\nreturned.\n\nDrawn samples.\n\nThis method directly exposes the the raw underlying pseudo-random number\ngenerator. All values are returned as unsigned 64-bit values irrespective of\nthe number of bits produced by the PRNG.\n\nSee the class docstring for the number of bits returned.\n\n"}, {"name": "random.bytes()", "path": "reference/random/generated/numpy.random.bytes", "type": "numpy.random.bytes", "text": "\nReturn random bytes.\n\nNote\n\nNew code should use the `bytes` method of a `default_rng()` instance instead;\nplease see the Quick Start.\n\nNumber of random bytes.\n\nString of length `length`.\n\nSee also\n\nwhich should be used for new code.\n\n"}, {"name": "random.chisquare()", "path": "reference/random/generated/numpy.random.chisquare", "type": "numpy.random.chisquare", "text": "\nDraw samples from a chi-square distribution.\n\nWhen `df` independent random variables, each with standard normal\ndistributions (mean 0, variance 1), are squared and summed, the resulting\ndistribution is chi-square (see Notes). This distribution is often used in\nhypothesis testing.\n\nNote\n\nNew code should use the `chisquare` method of a `default_rng()` instance\ninstead; please see the Quick Start.\n\nNumber of degrees of freedom, must be > 0.\n\nOutput shape. If the given shape is, e.g., `(m, n, k)`, then `m * n * k`\nsamples are drawn. If size is `None` (default), a single value is returned if\n`df` is a scalar. Otherwise, `np.array(df).size` samples are drawn.\n\nDrawn samples from the parameterized chi-square distribution.\n\nWhen `df` <= 0 or when an inappropriate `size` (e.g. `size=-1`) is given.\n\nSee also\n\nwhich should be used for new code.\n\nThe variable obtained by summing the squares of `df` independent, standard\nnormally distributed random variables:\n\nis chi-square distributed, denoted\n\nThe probability density function of the chi-squared distribution is\n\nwhere \\\\(\\Gamma\\\\) is the gamma function,\n\nNIST \u201cEngineering Statistics Handbook\u201d\nhttps://www.itl.nist.gov/div898/handbook/eda/section3/eda3666.htm\n\n"}, {"name": "random.choice()", "path": "reference/random/generated/numpy.random.choice", "type": "numpy.random.choice", "text": "\nGenerates a random sample from a given 1-D array\n\nNew in version 1.7.0.\n\nNote\n\nNew code should use the `choice` method of a `default_rng()` instance instead;\nplease see the Quick Start.\n\nIf an ndarray, a random sample is generated from its elements. If an int, the\nrandom sample is generated as if it were `np.arange(a)`\n\nOutput shape. If the given shape is, e.g., `(m, n, k)`, then `m * n * k`\nsamples are drawn. Default is None, in which case a single value is returned.\n\nWhether the sample is with or without replacement. Default is True, meaning\nthat a value of `a` can be selected multiple times.\n\nThe probabilities associated with each entry in a. If not given, the sample\nassumes a uniform distribution over all entries in `a`.\n\nThe generated random samples\n\nIf a is an int and less than zero, if a or p are not 1-dimensional, if a is an\narray-like of size 0, if p is not a vector of probabilities, if a and p have\ndifferent lengths, or if replace=False and the sample size is greater than the\npopulation size\n\nSee also\n\nwhich should be used in new code\n\nSetting user-specified probabilities through `p` uses a more general but less\nefficient sampler than the default. The general sampler produces a different\nsample than the optimized sampler even if each element of `p` is 1 / len(a).\n\nSampling random rows from a 2-D array is not possible with this function, but\nis possible with `Generator.choice` through its `axis` keyword.\n\nGenerate a uniform random sample from np.arange(5) of size 3:\n\nGenerate a non-uniform random sample from np.arange(5) of size 3:\n\nGenerate a uniform random sample from np.arange(5) of size 3 without\nreplacement:\n\nGenerate a non-uniform random sample from np.arange(5) of size 3 without\nreplacement:\n\nAny of the above can be repeated with an arbitrary array-like instead of just\nintegers. For instance:\n\n"}, {"name": "random.dirichlet()", "path": "reference/random/generated/numpy.random.dirichlet", "type": "numpy.random.dirichlet", "text": "\nDraw samples from the Dirichlet distribution.\n\nDraw `size` samples of dimension k from a Dirichlet distribution. A Dirichlet-\ndistributed random variable can be seen as a multivariate generalization of a\nBeta distribution. The Dirichlet distribution is a conjugate prior of a\nmultinomial distribution in Bayesian inference.\n\nNote\n\nNew code should use the `dirichlet` method of a `default_rng()` instance\ninstead; please see the Quick Start.\n\nParameter of the distribution (length `k` for sample of length `k`).\n\nOutput shape. If the given shape is, e.g., `(m, n)`, then `m * n * k` samples\nare drawn. Default is None, in which case a vector of length `k` is returned.\n\nThe drawn samples, of shape `(size, k)`.\n\nIf any value in `alpha` is less than or equal to zero\n\nSee also\n\nwhich should be used for new code.\n\nThe Dirichlet distribution is a distribution over vectors \\\\(x\\\\) that fulfil\nthe conditions \\\\(x_i>0\\\\) and \\\\(\\sum_{i=1}^k x_i = 1\\\\).\n\nThe probability density function \\\\(p\\\\) of a Dirichlet-distributed random\nvector \\\\(X\\\\) is proportional to\n\nwhere \\\\(\\alpha\\\\) is a vector containing the positive concentration\nparameters.\n\nThe method uses the following property for computation: let \\\\(Y\\\\) be a\nrandom vector which has components that follow a standard gamma distribution,\nthen \\\\(X = \\frac{1}{\\sum_{i=1}^k{Y_i}} Y\\\\) is Dirichlet-distributed\n\nDavid McKay, \u201cInformation Theory, Inference and Learning Algorithms,\u201d chapter\n23, http://www.inference.org.uk/mackay/itila/\n\nWikipedia, \u201cDirichlet distribution\u201d,\nhttps://en.wikipedia.org/wiki/Dirichlet_distribution\n\nTaking an example cited in Wikipedia, this distribution can be used if one\nwanted to cut strings (each of initial length 1.0) into K pieces with\ndifferent lengths, where each piece had, on average, a designated average\nlength, but allowing some variation in the relative sizes of the pieces.\n\n"}, {"name": "random.exponential()", "path": "reference/random/generated/numpy.random.exponential", "type": "numpy.random.exponential", "text": "\nDraw samples from an exponential distribution.\n\nIts probability density function is\n\nfor `x > 0` and 0 elsewhere. \\\\(\\beta\\\\) is the scale parameter, which is the\ninverse of the rate parameter \\\\(\\lambda = 1/\\beta\\\\). The rate parameter is\nan alternative, widely used parameterization of the exponential distribution\n[3].\n\nThe exponential distribution is a continuous analogue of the geometric\ndistribution. It describes many common situations, such as the size of\nraindrops measured over many rainstorms [1], or the time between page requests\nto Wikipedia [2].\n\nNote\n\nNew code should use the `exponential` method of a `default_rng()` instance\ninstead; please see the Quick Start.\n\nThe scale parameter, \\\\(\\beta = 1/\\lambda\\\\). Must be non-negative.\n\nOutput shape. If the given shape is, e.g., `(m, n, k)`, then `m * n * k`\nsamples are drawn. If size is `None` (default), a single value is returned if\n`scale` is a scalar. Otherwise, `np.array(scale).size` samples are drawn.\n\nDrawn samples from the parameterized exponential distribution.\n\nSee also\n\nwhich should be used for new code.\n\nPeyton Z. Peebles Jr., \u201cProbability, Random Variables and Random Signal\nPrinciples\u201d, 4th ed, 2001, p. 57.\n\nWikipedia, \u201cPoisson process\u201d, https://en.wikipedia.org/wiki/Poisson_process\n\nWikipedia, \u201cExponential distribution\u201d,\nhttps://en.wikipedia.org/wiki/Exponential_distribution\n\n"}, {"name": "random.f()", "path": "reference/random/generated/numpy.random.f", "type": "numpy.random.f", "text": "\nDraw samples from an F distribution.\n\nSamples are drawn from an F distribution with specified parameters, `dfnum`\n(degrees of freedom in numerator) and `dfden` (degrees of freedom in\ndenominator), where both parameters must be greater than zero.\n\nThe random variate of the F distribution (also known as the Fisher\ndistribution) is a continuous probability distribution that arises in ANOVA\ntests, and is the ratio of two chi-square variates.\n\nNote\n\nNew code should use the `f` method of a `default_rng()` instance instead;\nplease see the Quick Start.\n\nDegrees of freedom in numerator, must be > 0.\n\nDegrees of freedom in denominator, must be > 0.\n\nOutput shape. If the given shape is, e.g., `(m, n, k)`, then `m * n * k`\nsamples are drawn. If size is `None` (default), a single value is returned if\n`dfnum` and `dfden` are both scalars. Otherwise, `np.broadcast(dfnum,\ndfden).size` samples are drawn.\n\nDrawn samples from the parameterized Fisher distribution.\n\nSee also\n\nprobability density function, distribution or cumulative density function,\netc.\n\nwhich should be used for new code.\n\nThe F statistic is used to compare in-group variances to between-group\nvariances. Calculating the distribution depends on the sampling, and so it is\na function of the respective degrees of freedom in the problem. The variable\n`dfnum` is the number of samples minus one, the between-groups degrees of\nfreedom, while `dfden` is the within-groups degrees of freedom, the sum of the\nnumber of samples in each group minus the number of groups.\n\nGlantz, Stanton A. \u201cPrimer of Biostatistics.\u201d, McGraw-Hill, Fifth Edition,\n2002.\n\nWikipedia, \u201cF-distribution\u201d, https://en.wikipedia.org/wiki/F-distribution\n\nAn example from Glantz[1], pp 47-40:\n\nTwo groups, children of diabetics (25 people) and children from people without\ndiabetes (25 controls). Fasting blood glucose was measured, case group had a\nmean value of 86.1, controls had a mean value of 82.2. Standard deviations\nwere 2.09 and 2.49 respectively. Are these data consistent with the null\nhypothesis that the parents diabetic status does not affect their children\u2019s\nblood glucose levels? Calculating the F statistic from the data gives a value\nof 36.01.\n\nDraw samples from the distribution:\n\nThe lower bound for the top 1% of the samples is :\n\nSo there is about a 1% chance that the F statistic will exceed 7.62, the\nmeasured value is 36, so the null hypothesis is rejected at the 1% level.\n\n"}, {"name": "random.gamma()", "path": "reference/random/generated/numpy.random.gamma", "type": "numpy.random.gamma", "text": "\nDraw samples from a Gamma distribution.\n\nSamples are drawn from a Gamma distribution with specified parameters, `shape`\n(sometimes designated \u201ck\u201d) and `scale` (sometimes designated \u201ctheta\u201d), where\nboth parameters are > 0.\n\nNote\n\nNew code should use the `gamma` method of a `default_rng()` instance instead;\nplease see the Quick Start.\n\nThe shape of the gamma distribution. Must be non-negative.\n\nThe scale of the gamma distribution. Must be non-negative. Default is equal to\n1.\n\nOutput shape. If the given shape is, e.g., `(m, n, k)`, then `m * n * k`\nsamples are drawn. If size is `None` (default), a single value is returned if\n`shape` and `scale` are both scalars. Otherwise, `np.broadcast(shape,\nscale).size` samples are drawn.\n\nDrawn samples from the parameterized gamma distribution.\n\nSee also\n\nprobability density function, distribution or cumulative density function,\netc.\n\nwhich should be used for new code.\n\nThe probability density for the Gamma distribution is\n\nwhere \\\\(k\\\\) is the shape and \\\\(\\theta\\\\) the scale, and \\\\(\\Gamma\\\\) is the\nGamma function.\n\nThe Gamma distribution is often used to model the times to failure of\nelectronic components, and arises naturally in processes for which the waiting\ntimes between Poisson distributed events are relevant.\n\nWeisstein, Eric W. \u201cGamma Distribution.\u201d From MathWorld\u2013A Wolfram Web\nResource. http://mathworld.wolfram.com/GammaDistribution.html\n\nWikipedia, \u201cGamma distribution\u201d,\nhttps://en.wikipedia.org/wiki/Gamma_distribution\n\nDraw samples from the distribution:\n\nDisplay the histogram of the samples, along with the probability density\nfunction:\n\n"}, {"name": "random.Generator.beta()", "path": "reference/random/generated/numpy.random.generator.beta", "type": "numpy.random.Generator.beta", "text": "\nmethod\n\nDraw samples from a Beta distribution.\n\nThe Beta distribution is a special case of the Dirichlet distribution, and is\nrelated to the Gamma distribution. It has the probability distribution\nfunction\n\nwhere the normalization, B, is the beta function,\n\nIt is often seen in Bayesian inference and order statistics.\n\nAlpha, positive (>0).\n\nBeta, positive (>0).\n\nOutput shape. If the given shape is, e.g., `(m, n, k)`, then `m * n * k`\nsamples are drawn. If size is `None` (default), a single value is returned if\n`a` and `b` are both scalars. Otherwise, `np.broadcast(a, b).size` samples are\ndrawn.\n\nDrawn samples from the parameterized beta distribution.\n\n"}, {"name": "random.Generator.binomial()", "path": "reference/random/generated/numpy.random.generator.binomial", "type": "numpy.random.Generator.binomial", "text": "\nmethod\n\nDraw samples from a binomial distribution.\n\nSamples are drawn from a binomial distribution with specified parameters, n\ntrials and p probability of success where n an integer >= 0 and p is in the\ninterval [0,1]. (n may be input as a float, but it is truncated to an integer\nin use)\n\nParameter of the distribution, >= 0. Floats are also accepted, but they will\nbe truncated to integers.\n\nParameter of the distribution, >= 0 and <=1.\n\nOutput shape. If the given shape is, e.g., `(m, n, k)`, then `m * n * k`\nsamples are drawn. If size is `None` (default), a single value is returned if\n`n` and `p` are both scalars. Otherwise, `np.broadcast(n, p).size` samples are\ndrawn.\n\nDrawn samples from the parameterized binomial distribution, where each sample\nis equal to the number of successes over the n trials.\n\nSee also\n\nprobability density function, distribution or cumulative density function,\netc.\n\nThe probability density for the binomial distribution is\n\nwhere \\\\(n\\\\) is the number of trials, \\\\(p\\\\) is the probability of success,\nand \\\\(N\\\\) is the number of successes.\n\nWhen estimating the standard error of a proportion in a population by using a\nrandom sample, the normal distribution works well unless the product p*n <=5,\nwhere p = population proportion estimate, and n = number of samples, in which\ncase the binomial distribution is used instead. For example, a sample of 15\npeople shows 4 who are left handed, and 11 who are right handed. Then p = 4/15\n= 27%. 0.27*15 = 4, so the binomial distribution should be used in this case.\n\nDalgaard, Peter, \u201cIntroductory Statistics with R\u201d, Springer-Verlag, 2002.\n\nGlantz, Stanton A. \u201cPrimer of Biostatistics.\u201d, McGraw-Hill, Fifth Edition,\n2002.\n\nLentner, Marvin, \u201cElementary Applied Statistics\u201d, Bogden and Quigley, 1972.\n\nWeisstein, Eric W. \u201cBinomial Distribution.\u201d From MathWorld\u2013A Wolfram Web\nResource. http://mathworld.wolfram.com/BinomialDistribution.html\n\nWikipedia, \u201cBinomial distribution\u201d,\nhttps://en.wikipedia.org/wiki/Binomial_distribution\n\nDraw samples from the distribution:\n\nA real world example. A company drills 9 wild-cat oil exploration wells, each\nwith an estimated probability of success of 0.1. All nine wells fail. What is\nthe probability of that happening?\n\nLet\u2019s do 20,000 trials of the model, and count the number that generate zero\npositive results.\n\n"}, {"name": "random.Generator.bit_generator", "path": "reference/random/generated/numpy.random.generator.bit_generator", "type": "numpy.random.Generator.bit_generator", "text": "\nattribute\n\nGets the bit generator instance used by the generator\n\nThe bit generator instance used by the generator\n\n"}, {"name": "random.Generator.bytes()", "path": "reference/random/generated/numpy.random.generator.bytes", "type": "numpy.random.Generator.bytes", "text": "\nmethod\n\nReturn random bytes.\n\nNumber of random bytes.\n\nString of length `length`.\n\n"}, {"name": "random.Generator.chisquare()", "path": "reference/random/generated/numpy.random.generator.chisquare", "type": "numpy.random.Generator.chisquare", "text": "\nmethod\n\nDraw samples from a chi-square distribution.\n\nWhen `df` independent random variables, each with standard normal\ndistributions (mean 0, variance 1), are squared and summed, the resulting\ndistribution is chi-square (see Notes). This distribution is often used in\nhypothesis testing.\n\nNumber of degrees of freedom, must be > 0.\n\nOutput shape. If the given shape is, e.g., `(m, n, k)`, then `m * n * k`\nsamples are drawn. If size is `None` (default), a single value is returned if\n`df` is a scalar. Otherwise, `np.array(df).size` samples are drawn.\n\nDrawn samples from the parameterized chi-square distribution.\n\nWhen `df` <= 0 or when an inappropriate `size` (e.g. `size=-1`) is given.\n\nThe variable obtained by summing the squares of `df` independent, standard\nnormally distributed random variables:\n\nis chi-square distributed, denoted\n\nThe probability density function of the chi-squared distribution is\n\nwhere \\\\(\\Gamma\\\\) is the gamma function,\n\nNIST \u201cEngineering Statistics Handbook\u201d\nhttps://www.itl.nist.gov/div898/handbook/eda/section3/eda3666.htm\n\n"}, {"name": "random.Generator.choice()", "path": "reference/random/generated/numpy.random.generator.choice", "type": "numpy.random.Generator.choice", "text": "\nmethod\n\nGenerates a random sample from a given array\n\nIf an ndarray, a random sample is generated from its elements. If an int, the\nrandom sample is generated from np.arange(a).\n\nOutput shape. If the given shape is, e.g., `(m, n, k)`, then `m * n * k`\nsamples are drawn from the 1-d `a`. If `a` has more than one dimension, the\n`size` shape will be inserted into the `axis` dimension, so the output `ndim`\nwill be `a.ndim - 1 + len(size)`. Default is None, in which case a single\nvalue is returned.\n\nWhether the sample is with or without replacement. Default is True, meaning\nthat a value of `a` can be selected multiple times.\n\nThe probabilities associated with each entry in a. If not given, the sample\nassumes a uniform distribution over all entries in `a`.\n\nThe axis along which the selection is performed. The default, 0, selects by\nrow.\n\nWhether the sample is shuffled when sampling without replacement. Default is\nTrue, False provides a speedup.\n\nThe generated random samples\n\nIf a is an int and less than zero, if p is not 1-dimensional, if a is array-\nlike with a size 0, if p is not a vector of probabilities, if a and p have\ndifferent lengths, or if replace=False and the sample size is greater than the\npopulation size.\n\nSee also\n\nSetting user-specified probabilities through `p` uses a more general but less\nefficient sampler than the default. The general sampler produces a different\nsample than the optimized sampler even if each element of `p` is 1 / len(a).\n\nGenerate a uniform random sample from np.arange(5) of size 3:\n\nGenerate a non-uniform random sample from np.arange(5) of size 3:\n\nGenerate a uniform random sample from np.arange(5) of size 3 without\nreplacement:\n\nGenerate a uniform random sample from a 2-D array along the first axis (the\ndefault), without replacement:\n\nGenerate a non-uniform random sample from np.arange(5) of size 3 without\nreplacement:\n\nAny of the above can be repeated with an arbitrary array-like instead of just\nintegers. For instance:\n\n"}, {"name": "random.Generator.dirichlet()", "path": "reference/random/generated/numpy.random.generator.dirichlet", "type": "numpy.random.Generator.dirichlet", "text": "\nmethod\n\nDraw samples from the Dirichlet distribution.\n\nDraw `size` samples of dimension k from a Dirichlet distribution. A Dirichlet-\ndistributed random variable can be seen as a multivariate generalization of a\nBeta distribution. The Dirichlet distribution is a conjugate prior of a\nmultinomial distribution in Bayesian inference.\n\nParameter of the distribution (length `k` for sample of length `k`).\n\nOutput shape. If the given shape is, e.g., `(m, n)`, then `m * n * k` samples\nare drawn. Default is None, in which case a vector of length `k` is returned.\n\nThe drawn samples, of shape `(size, k)`.\n\nIf any value in `alpha` is less than or equal to zero\n\nThe Dirichlet distribution is a distribution over vectors \\\\(x\\\\) that fulfil\nthe conditions \\\\(x_i>0\\\\) and \\\\(\\sum_{i=1}^k x_i = 1\\\\).\n\nThe probability density function \\\\(p\\\\) of a Dirichlet-distributed random\nvector \\\\(X\\\\) is proportional to\n\nwhere \\\\(\\alpha\\\\) is a vector containing the positive concentration\nparameters.\n\nThe method uses the following property for computation: let \\\\(Y\\\\) be a\nrandom vector which has components that follow a standard gamma distribution,\nthen \\\\(X = \\frac{1}{\\sum_{i=1}^k{Y_i}} Y\\\\) is Dirichlet-distributed\n\nDavid McKay, \u201cInformation Theory, Inference and Learning Algorithms,\u201d chapter\n23, http://www.inference.org.uk/mackay/itila/\n\nWikipedia, \u201cDirichlet distribution\u201d,\nhttps://en.wikipedia.org/wiki/Dirichlet_distribution\n\nTaking an example cited in Wikipedia, this distribution can be used if one\nwanted to cut strings (each of initial length 1.0) into K pieces with\ndifferent lengths, where each piece had, on average, a designated average\nlength, but allowing some variation in the relative sizes of the pieces.\n\n"}, {"name": "random.Generator.exponential()", "path": "reference/random/generated/numpy.random.generator.exponential", "type": "numpy.random.Generator.exponential", "text": "\nmethod\n\nDraw samples from an exponential distribution.\n\nIts probability density function is\n\nfor `x > 0` and 0 elsewhere. \\\\(\\beta\\\\) is the scale parameter, which is the\ninverse of the rate parameter \\\\(\\lambda = 1/\\beta\\\\). The rate parameter is\nan alternative, widely used parameterization of the exponential distribution\n[3].\n\nThe exponential distribution is a continuous analogue of the geometric\ndistribution. It describes many common situations, such as the size of\nraindrops measured over many rainstorms [1], or the time between page requests\nto Wikipedia [2].\n\nThe scale parameter, \\\\(\\beta = 1/\\lambda\\\\). Must be non-negative.\n\nOutput shape. If the given shape is, e.g., `(m, n, k)`, then `m * n * k`\nsamples are drawn. If size is `None` (default), a single value is returned if\n`scale` is a scalar. Otherwise, `np.array(scale).size` samples are drawn.\n\nDrawn samples from the parameterized exponential distribution.\n\nPeyton Z. Peebles Jr., \u201cProbability, Random Variables and Random Signal\nPrinciples\u201d, 4th ed, 2001, p. 57.\n\nWikipedia, \u201cPoisson process\u201d, https://en.wikipedia.org/wiki/Poisson_process\n\nWikipedia, \u201cExponential distribution\u201d,\nhttps://en.wikipedia.org/wiki/Exponential_distribution\n\n"}, {"name": "random.Generator.f()", "path": "reference/random/generated/numpy.random.generator.f", "type": "numpy.random.Generator.f", "text": "\nmethod\n\nDraw samples from an F distribution.\n\nSamples are drawn from an F distribution with specified parameters, `dfnum`\n(degrees of freedom in numerator) and `dfden` (degrees of freedom in\ndenominator), where both parameters must be greater than zero.\n\nThe random variate of the F distribution (also known as the Fisher\ndistribution) is a continuous probability distribution that arises in ANOVA\ntests, and is the ratio of two chi-square variates.\n\nDegrees of freedom in numerator, must be > 0.\n\nDegrees of freedom in denominator, must be > 0.\n\nOutput shape. If the given shape is, e.g., `(m, n, k)`, then `m * n * k`\nsamples are drawn. If size is `None` (default), a single value is returned if\n`dfnum` and `dfden` are both scalars. Otherwise, `np.broadcast(dfnum,\ndfden).size` samples are drawn.\n\nDrawn samples from the parameterized Fisher distribution.\n\nSee also\n\nprobability density function, distribution or cumulative density function,\netc.\n\nThe F statistic is used to compare in-group variances to between-group\nvariances. Calculating the distribution depends on the sampling, and so it is\na function of the respective degrees of freedom in the problem. The variable\n`dfnum` is the number of samples minus one, the between-groups degrees of\nfreedom, while `dfden` is the within-groups degrees of freedom, the sum of the\nnumber of samples in each group minus the number of groups.\n\nGlantz, Stanton A. \u201cPrimer of Biostatistics.\u201d, McGraw-Hill, Fifth Edition,\n2002.\n\nWikipedia, \u201cF-distribution\u201d, https://en.wikipedia.org/wiki/F-distribution\n\nAn example from Glantz[1], pp 47-40:\n\nTwo groups, children of diabetics (25 people) and children from people without\ndiabetes (25 controls). Fasting blood glucose was measured, case group had a\nmean value of 86.1, controls had a mean value of 82.2. Standard deviations\nwere 2.09 and 2.49 respectively. Are these data consistent with the null\nhypothesis that the parents diabetic status does not affect their children\u2019s\nblood glucose levels? Calculating the F statistic from the data gives a value\nof 36.01.\n\nDraw samples from the distribution:\n\nThe lower bound for the top 1% of the samples is :\n\nSo there is about a 1% chance that the F statistic will exceed 7.62, the\nmeasured value is 36, so the null hypothesis is rejected at the 1% level.\n\n"}, {"name": "random.Generator.gamma()", "path": "reference/random/generated/numpy.random.generator.gamma", "type": "numpy.random.Generator.gamma", "text": "\nmethod\n\nDraw samples from a Gamma distribution.\n\nSamples are drawn from a Gamma distribution with specified parameters, `shape`\n(sometimes designated \u201ck\u201d) and `scale` (sometimes designated \u201ctheta\u201d), where\nboth parameters are > 0.\n\nThe shape of the gamma distribution. Must be non-negative.\n\nThe scale of the gamma distribution. Must be non-negative. Default is equal to\n1.\n\nOutput shape. If the given shape is, e.g., `(m, n, k)`, then `m * n * k`\nsamples are drawn. If size is `None` (default), a single value is returned if\n`shape` and `scale` are both scalars. Otherwise, `np.broadcast(shape,\nscale).size` samples are drawn.\n\nDrawn samples from the parameterized gamma distribution.\n\nSee also\n\nprobability density function, distribution or cumulative density function,\netc.\n\nThe probability density for the Gamma distribution is\n\nwhere \\\\(k\\\\) is the shape and \\\\(\\theta\\\\) the scale, and \\\\(\\Gamma\\\\) is the\nGamma function.\n\nThe Gamma distribution is often used to model the times to failure of\nelectronic components, and arises naturally in processes for which the waiting\ntimes between Poisson distributed events are relevant.\n\nWeisstein, Eric W. \u201cGamma Distribution.\u201d From MathWorld\u2013A Wolfram Web\nResource. http://mathworld.wolfram.com/GammaDistribution.html\n\nWikipedia, \u201cGamma distribution\u201d,\nhttps://en.wikipedia.org/wiki/Gamma_distribution\n\nDraw samples from the distribution:\n\nDisplay the histogram of the samples, along with the probability density\nfunction:\n\n"}, {"name": "random.Generator.geometric()", "path": "reference/random/generated/numpy.random.generator.geometric", "type": "numpy.random.Generator.geometric", "text": "\nmethod\n\nDraw samples from the geometric distribution.\n\nBernoulli trials are experiments with one of two outcomes: success or failure\n(an example of such an experiment is flipping a coin). The geometric\ndistribution models the number of trials that must be run in order to achieve\nsuccess. It is therefore supported on the positive integers, `k = 1, 2, ...`.\n\nThe probability mass function of the geometric distribution is\n\nwhere `p` is the probability of success of an individual trial.\n\nThe probability of success of an individual trial.\n\nOutput shape. If the given shape is, e.g., `(m, n, k)`, then `m * n * k`\nsamples are drawn. If size is `None` (default), a single value is returned if\n`p` is a scalar. Otherwise, `np.array(p).size` samples are drawn.\n\nDrawn samples from the parameterized geometric distribution.\n\nDraw ten thousand values from the geometric distribution, with the probability\nof an individual success equal to 0.35:\n\nHow many trials succeeded after a single run?\n\n"}, {"name": "random.Generator.gumbel()", "path": "reference/random/generated/numpy.random.generator.gumbel", "type": "numpy.random.Generator.gumbel", "text": "\nmethod\n\nDraw samples from a Gumbel distribution.\n\nDraw samples from a Gumbel distribution with specified location and scale. For\nmore information on the Gumbel distribution, see Notes and References below.\n\nThe location of the mode of the distribution. Default is 0.\n\nThe scale parameter of the distribution. Default is 1. Must be non- negative.\n\nOutput shape. If the given shape is, e.g., `(m, n, k)`, then `m * n * k`\nsamples are drawn. If size is `None` (default), a single value is returned if\n`loc` and `scale` are both scalars. Otherwise, `np.broadcast(loc, scale).size`\nsamples are drawn.\n\nDrawn samples from the parameterized Gumbel distribution.\n\nSee also\n\nThe Gumbel (or Smallest Extreme Value (SEV) or the Smallest Extreme Value Type\nI) distribution is one of a class of Generalized Extreme Value (GEV)\ndistributions used in modeling extreme value problems. The Gumbel is a special\ncase of the Extreme Value Type I distribution for maximums from distributions\nwith \u201cexponential-like\u201d tails.\n\nThe probability density for the Gumbel distribution is\n\nwhere \\\\(\\mu\\\\) is the mode, a location parameter, and \\\\(\\beta\\\\) is the\nscale parameter.\n\nThe Gumbel (named for German mathematician Emil Julius Gumbel) was used very\nearly in the hydrology literature, for modeling the occurrence of flood\nevents. It is also used for modeling maximum wind speed and rainfall rates. It\nis a \u201cfat-tailed\u201d distribution - the probability of an event in the tail of\nthe distribution is larger than if one used a Gaussian, hence the surprisingly\nfrequent occurrence of 100-year floods. Floods were initially modeled as a\nGaussian process, which underestimated the frequency of extreme events.\n\nIt is one of a class of extreme value distributions, the Generalized Extreme\nValue (GEV) distributions, which also includes the Weibull and Frechet.\n\nThe function has a mean of \\\\(\\mu + 0.57721\\beta\\\\) and a variance of\n\\\\(\\frac{\\pi^2}{6}\\beta^2\\\\).\n\nGumbel, E. J., \u201cStatistics of Extremes,\u201d New York: Columbia University Press,\n1958.\n\nReiss, R.-D. and Thomas, M., \u201cStatistical Analysis of Extreme Values from\nInsurance, Finance, Hydrology and Other Fields,\u201d Basel: Birkhauser Verlag,\n2001.\n\nDraw samples from the distribution:\n\nDisplay the histogram of the samples, along with the probability density\nfunction:\n\nShow how an extreme value distribution can arise from a Gaussian process and\ncompare to a Gaussian:\n\n"}, {"name": "random.Generator.hypergeometric()", "path": "reference/random/generated/numpy.random.generator.hypergeometric", "type": "numpy.random.Generator.hypergeometric", "text": "\nmethod\n\nDraw samples from a Hypergeometric distribution.\n\nSamples are drawn from a hypergeometric distribution with specified\nparameters, `ngood` (ways to make a good selection), `nbad` (ways to make a\nbad selection), and `nsample` (number of items sampled, which is less than or\nequal to the sum `ngood + nbad`).\n\nNumber of ways to make a good selection. Must be nonnegative and less than\n10**9.\n\nNumber of ways to make a bad selection. Must be nonnegative and less than\n10**9.\n\nNumber of items sampled. Must be nonnegative and less than `ngood + nbad`.\n\nOutput shape. If the given shape is, e.g., `(m, n, k)`, then `m * n * k`\nsamples are drawn. If size is `None` (default), a single value is returned if\n`ngood`, `nbad`, and `nsample` are all scalars. Otherwise,\n`np.broadcast(ngood, nbad, nsample).size` samples are drawn.\n\nDrawn samples from the parameterized hypergeometric distribution. Each sample\nis the number of good items within a randomly selected subset of size\n`nsample` taken from a set of `ngood` good items and `nbad` bad items.\n\nSee also\n\nDraw samples from the multivariate hypergeometric distribution.\n\nprobability density function, distribution or cumulative density function,\netc.\n\nThe probability density for the Hypergeometric distribution is\n\nwhere \\\\(0 \\le x \\le n\\\\) and \\\\(n-b \\le x \\le g\\\\)\n\nfor P(x) the probability of `x` good results in the drawn sample, g = `ngood`,\nb = `nbad`, and n = `nsample`.\n\nConsider an urn with black and white marbles in it, `ngood` of them are black\nand `nbad` are white. If you draw `nsample` balls without replacement, then\nthe hypergeometric distribution describes the distribution of black balls in\nthe drawn sample.\n\nNote that this distribution is very similar to the binomial distribution,\nexcept that in this case, samples are drawn without replacement, whereas in\nthe Binomial case samples are drawn with replacement (or the sample space is\ninfinite). As the sample space becomes large, this distribution approaches the\nbinomial.\n\nThe arguments `ngood` and `nbad` each must be less than `10**9`. For extremely\nlarge arguments, the algorithm that is used to compute the samples [4] breaks\ndown because of loss of precision in floating point calculations. For such\nlarge values, if `nsample` is not also large, the distribution can be\napproximated with the binomial distribution, `binomial(n=nsample,\np=ngood/(ngood + nbad))`.\n\nLentner, Marvin, \u201cElementary Applied Statistics\u201d, Bogden and Quigley, 1972.\n\nWeisstein, Eric W. \u201cHypergeometric Distribution.\u201d From MathWorld\u2013A Wolfram Web\nResource. http://mathworld.wolfram.com/HypergeometricDistribution.html\n\nWikipedia, \u201cHypergeometric distribution\u201d,\nhttps://en.wikipedia.org/wiki/Hypergeometric_distribution\n\nStadlober, Ernst, \u201cThe ratio of uniforms approach for generating discrete\nrandom variates\u201d, Journal of Computational and Applied Mathematics, 31, pp.\n181-189 (1990).\n\nDraw samples from the distribution:\n\nSuppose you have an urn with 15 white and 15 black marbles. If you pull 15\nmarbles at random, how likely is it that 12 or more of them are one color?\n\n"}, {"name": "random.Generator.integers()", "path": "reference/random/generated/numpy.random.generator.integers", "type": "numpy.random.Generator.integers", "text": "\nmethod\n\nReturn random integers from `low` (inclusive) to `high` (exclusive), or if\nendpoint=True, `low` (inclusive) to `high` (inclusive). Replaces\n`RandomState.randint` (with endpoint=False) and `RandomState.random_integers`\n(with endpoint=True)\n\nReturn random integers from the \u201cdiscrete uniform\u201d distribution of the\nspecified dtype. If `high` is None (the default), then results are from 0 to\n`low`.\n\nLowest (signed) integers to be drawn from the distribution (unless\n`high=None`, in which case this parameter is 0 and this value is used for\n`high`).\n\nIf provided, one above the largest (signed) integer to be drawn from the\ndistribution (see above for behavior if `high=None`). If array-like, must\ncontain integer values\n\nOutput shape. If the given shape is, e.g., `(m, n, k)`, then `m * n * k`\nsamples are drawn. Default is None, in which case a single value is returned.\n\nDesired dtype of the result. Byteorder must be native. The default value is\nnp.int64.\n\nIf true, sample from the interval [low, high] instead of the default [low,\nhigh) Defaults to False\n\n`size`-shaped array of random integers from the appropriate distribution, or a\nsingle such random int if `size` not provided.\n\nWhen using broadcasting with uint64 dtypes, the maximum value (2**64) cannot\nbe represented as a standard integer type. The high array (or low if high is\nNone) must have object dtype, e.g., array([2**64]).\n\nDaniel Lemire., \u201cFast Random Integer Generation in an Interval\u201d, ACM\nTransactions on Modeling and Computer Simulation 29 (1), 2019,\nhttp://arxiv.org/abs/1805.10941.\n\nGenerate a 2 x 4 array of ints between 0 and 4, inclusive:\n\nGenerate a 1 x 3 array with 3 different upper bounds\n\nGenerate a 1 by 3 array with 3 different lower bounds\n\nGenerate a 2 by 4 array using broadcasting with dtype of uint8\n\n"}, {"name": "random.Generator.laplace()", "path": "reference/random/generated/numpy.random.generator.laplace", "type": "numpy.random.Generator.laplace", "text": "\nmethod\n\nDraw samples from the Laplace or double exponential distribution with\nspecified location (or mean) and scale (decay).\n\nThe Laplace distribution is similar to the Gaussian/normal distribution, but\nis sharper at the peak and has fatter tails. It represents the difference\nbetween two independent, identically distributed exponential random variables.\n\nThe position, \\\\(\\mu\\\\), of the distribution peak. Default is 0.\n\n\\\\(\\lambda\\\\), the exponential decay. Default is 1. Must be non- negative.\n\nOutput shape. If the given shape is, e.g., `(m, n, k)`, then `m * n * k`\nsamples are drawn. If size is `None` (default), a single value is returned if\n`loc` and `scale` are both scalars. Otherwise, `np.broadcast(loc, scale).size`\nsamples are drawn.\n\nDrawn samples from the parameterized Laplace distribution.\n\nIt has the probability density function\n\nThe first law of Laplace, from 1774, states that the frequency of an error can\nbe expressed as an exponential function of the absolute magnitude of the\nerror, which leads to the Laplace distribution. For many problems in economics\nand health sciences, this distribution seems to model the data better than the\nstandard Gaussian distribution.\n\nAbramowitz, M. and Stegun, I. A. (Eds.). \u201cHandbook of Mathematical Functions\nwith Formulas, Graphs, and Mathematical Tables, 9th printing,\u201d New York:\nDover, 1972.\n\nKotz, Samuel, et. al. \u201cThe Laplace Distribution and Generalizations, \u201d\nBirkhauser, 2001.\n\nWeisstein, Eric W. \u201cLaplace Distribution.\u201d From MathWorld\u2013A Wolfram Web\nResource. http://mathworld.wolfram.com/LaplaceDistribution.html\n\nWikipedia, \u201cLaplace distribution\u201d,\nhttps://en.wikipedia.org/wiki/Laplace_distribution\n\nDraw samples from the distribution\n\nDisplay the histogram of the samples, along with the probability density\nfunction:\n\nPlot Gaussian for comparison:\n\n"}, {"name": "random.Generator.logistic()", "path": "reference/random/generated/numpy.random.generator.logistic", "type": "numpy.random.Generator.logistic", "text": "\nmethod\n\nDraw samples from a logistic distribution.\n\nSamples are drawn from a logistic distribution with specified parameters, loc\n(location or mean, also median), and scale (>0).\n\nParameter of the distribution. Default is 0.\n\nParameter of the distribution. Must be non-negative. Default is 1.\n\nOutput shape. If the given shape is, e.g., `(m, n, k)`, then `m * n * k`\nsamples are drawn. If size is `None` (default), a single value is returned if\n`loc` and `scale` are both scalars. Otherwise, `np.broadcast(loc, scale).size`\nsamples are drawn.\n\nDrawn samples from the parameterized logistic distribution.\n\nSee also\n\nprobability density function, distribution or cumulative density function,\netc.\n\nThe probability density for the Logistic distribution is\n\nwhere \\\\(\\mu\\\\) = location and \\\\(s\\\\) = scale.\n\nThe Logistic distribution is used in Extreme Value problems where it can act\nas a mixture of Gumbel distributions, in Epidemiology, and by the World Chess\nFederation (FIDE) where it is used in the Elo ranking system, assuming the\nperformance of each player is a logistically distributed random variable.\n\nReiss, R.-D. and Thomas M. (2001), \u201cStatistical Analysis of Extreme Values,\nfrom Insurance, Finance, Hydrology and Other Fields,\u201d Birkhauser Verlag,\nBasel, pp 132-133.\n\nWeisstein, Eric W. \u201cLogistic Distribution.\u201d From MathWorld\u2013A Wolfram Web\nResource. http://mathworld.wolfram.com/LogisticDistribution.html\n\nWikipedia, \u201cLogistic-distribution\u201d,\nhttps://en.wikipedia.org/wiki/Logistic_distribution\n\nDraw samples from the distribution:\n\n# plot against distribution\n\n"}, {"name": "random.Generator.lognormal()", "path": "reference/random/generated/numpy.random.generator.lognormal", "type": "numpy.random.Generator.lognormal", "text": "\nmethod\n\nDraw samples from a log-normal distribution.\n\nDraw samples from a log-normal distribution with specified mean, standard\ndeviation, and array shape. Note that the mean and standard deviation are not\nthe values for the distribution itself, but of the underlying normal\ndistribution it is derived from.\n\nMean value of the underlying normal distribution. Default is 0.\n\nStandard deviation of the underlying normal distribution. Must be non-\nnegative. Default is 1.\n\nOutput shape. If the given shape is, e.g., `(m, n, k)`, then `m * n * k`\nsamples are drawn. If size is `None` (default), a single value is returned if\n`mean` and `sigma` are both scalars. Otherwise, `np.broadcast(mean,\nsigma).size` samples are drawn.\n\nDrawn samples from the parameterized log-normal distribution.\n\nSee also\n\nprobability density function, distribution, cumulative density function, etc.\n\nA variable `x` has a log-normal distribution if `log(x)` is normally\ndistributed. The probability density function for the log-normal distribution\nis:\n\nwhere \\\\(\\mu\\\\) is the mean and \\\\(\\sigma\\\\) is the standard deviation of the\nnormally distributed logarithm of the variable. A log-normal distribution\nresults if a random variable is the product of a large number of independent,\nidentically-distributed variables in the same way that a normal distribution\nresults if the variable is the sum of a large number of independent,\nidentically-distributed variables.\n\nLimpert, E., Stahel, W. A., and Abbt, M., \u201cLog-normal Distributions across the\nSciences: Keys and Clues,\u201d BioScience, Vol. 51, No. 5, May, 2001.\nhttps://stat.ethz.ch/~stahel/lognormal/bioscience.pdf\n\nReiss, R.D. and Thomas, M., \u201cStatistical Analysis of Extreme Values,\u201d Basel:\nBirkhauser Verlag, 2001, pp. 31-32.\n\nDraw samples from the distribution:\n\nDisplay the histogram of the samples, along with the probability density\nfunction:\n\nDemonstrate that taking the products of random samples from a uniform\ndistribution can be fit well by a log-normal probability density function.\n\n"}, {"name": "random.Generator.logseries()", "path": "reference/random/generated/numpy.random.generator.logseries", "type": "numpy.random.Generator.logseries", "text": "\nmethod\n\nDraw samples from a logarithmic series distribution.\n\nSamples are drawn from a log series distribution with specified shape\nparameter, 0 < `p` < 1.\n\nShape parameter for the distribution. Must be in the range (0, 1).\n\nOutput shape. If the given shape is, e.g., `(m, n, k)`, then `m * n * k`\nsamples are drawn. If size is `None` (default), a single value is returned if\n`p` is a scalar. Otherwise, `np.array(p).size` samples are drawn.\n\nDrawn samples from the parameterized logarithmic series distribution.\n\nSee also\n\nprobability density function, distribution or cumulative density function,\netc.\n\nThe probability mass function for the Log Series distribution is\n\nwhere p = probability.\n\nThe log series distribution is frequently used to represent species richness\nand occurrence, first proposed by Fisher, Corbet, and Williams in 1943 [2]. It\nmay also be used to model the numbers of occupants seen in cars [3].\n\nBuzas, Martin A.; Culver, Stephen J., Understanding regional species diversity\nthrough the log series distribution of occurrences: BIODIVERSITY RESEARCH\nDiversity & Distributions, Volume 5, Number 5, September 1999 , pp.\n187-195(9).\n\nFisher, R.A,, A.S. Corbet, and C.B. Williams. 1943. The relation between the\nnumber of species and the number of individuals in a random sample of an\nanimal population. Journal of Animal Ecology, 12:42-58.\n\nD. J. Hand, F. Daly, D. Lunn, E. Ostrowski, A Handbook of Small Data Sets, CRC\nPress, 1994.\n\nWikipedia, \u201cLogarithmic distribution\u201d,\nhttps://en.wikipedia.org/wiki/Logarithmic_distribution\n\nDraw samples from the distribution:\n\n# plot against distribution\n\n"}, {"name": "random.Generator.multinomial()", "path": "reference/random/generated/numpy.random.generator.multinomial", "type": "numpy.random.Generator.multinomial", "text": "\nmethod\n\nDraw samples from a multinomial distribution.\n\nThe multinomial distribution is a multivariate generalization of the binomial\ndistribution. Take an experiment with one of `p` possible outcomes. An example\nof such an experiment is throwing a dice, where the outcome can be 1 through\n6. Each sample drawn from the distribution represents `n` such experiments.\nIts values, `X_i = [X_0, X_1, ..., X_p]`, represent the number of times the\noutcome was `i`.\n\nNumber of experiments.\n\nProbabilities of each of the `p` different outcomes with shape `(k0, k1, ...,\nkn, p)`. Each element `pvals[i,j,...,:]` must sum to 1 (however, the last\nelement is always assumed to account for the remaining probability, as long as\n`sum(pvals[..., :-1], axis=-1) <= 1.0`. Must have at least 1 dimension where\npvals.shape[-1] > 0.\n\nOutput shape. If the given shape is, e.g., `(m, n, k)`, then `m * n * k`\nsamples are drawn each with `p` elements. Default is None where the output\nsize is determined by the broadcast shape of `n` and all by the final\ndimension of `pvals`, which is denoted as `b=(b0, b1, ..., bq)`. If size is\nnot None, then it must be compatible with the broadcast shape `b`.\nSpecifically, size must have `q` or more elements and size[-(q-j):] must equal\n`bj`.\n\nThe drawn samples, of shape size, if provided. When size is provided, the\noutput shape is size + (p,) If not specified, the shape is determined by the\nbroadcast shape of `n` and `pvals`, `(b0, b1, ..., bq)` augmented with the\ndimension of the multinomial, `p`, so that that output shape is `(b0, b1, ...,\nbq, p)`.\n\nEach entry `out[i,j,...,:]` is a `p`-dimensional value drawn from the\ndistribution.\n\nThrow a dice 20 times:\n\nIt landed 4 times on 1, once on 2, etc.\n\nNow, throw the dice 20 times, and 20 times again:\n\nFor the first run, we threw 3 times 1, 4 times 2, etc. For the second, we\nthrew 2 times 1, 4 times 2, etc.\n\nNow, do one experiment throwing the dice 10 time, and 10 times again, and\nanother throwing the dice 20 times, and 20 times again:\n\nThe first array shows the outcomes of throwing the dice 10 times, and the\nsecond shows the outcomes from throwing the dice 20 times.\n\nA loaded die is more likely to land on number 6:\n\nSimulate 10 throws of a 4-sided die and 20 throws of a 6-sided die\n\nGenerate categorical random variates from two categories where the first has 3\noutcomes and the second has 2.\n\n`argmax(axis=-1)` is then used to return the categories.\n\nThe same output dimension can be produced using broadcasting.\n\nThe probability inputs should be normalized. As an implementation detail, the\nvalue of the last entry is ignored and assumed to take up any leftover\nprobability mass, but this should not be relied on. A biased coin which has\ntwice as much weight on one side as on the other should be sampled like so:\n\nnot like:\n\n"}, {"name": "random.Generator.multivariate_hypergeometric()", "path": "reference/random/generated/numpy.random.generator.multivariate_hypergeometric", "type": "numpy.random.Generator.multivariate_hypergeometric", "text": "\nmethod\n\nGenerate variates from a multivariate hypergeometric distribution.\n\nThe multivariate hypergeometric distribution is a generalization of the\nhypergeometric distribution.\n\nChoose `nsample` items at random without replacement from a collection with\n`N` distinct types. `N` is the length of `colors`, and the values in `colors`\nare the number of occurrences of that type in the collection. The total number\nof items in the collection is `sum(colors)`. Each random variate generated by\nthis function is a vector of length `N` holding the counts of the different\ntypes that occurred in the `nsample` items.\n\nThe name `colors` comes from a common description of the distribution: it is\nthe probability distribution of the number of marbles of each color selected\nwithout replacement from an urn containing marbles of different colors;\n`colors[i]` is the number of marbles in the urn with color `i`.\n\nThe number of each type of item in the collection from which a sample is\ndrawn. The values in `colors` must be nonnegative. To avoid loss of precision\nin the algorithm, `sum(colors)` must be less than `10**9` when `method` is\n\u201cmarginals\u201d.\n\nThe number of items selected. `nsample` must not be greater than\n`sum(colors)`.\n\nThe number of variates to generate, either an integer or a tuple holding the\nshape of the array of variates. If the given size is, e.g., `(k, m)`, then `k\n* m` variates are drawn, where one variate is a vector of length\n`len(colors)`, and the return value has shape `(k, m, len(colors))`. If `size`\nis an integer, the output has shape `(size, len(colors))`. Default is None, in\nwhich case a single variate is returned as an array with shape\n`(len(colors),)`.\n\nSpecify the algorithm that is used to generate the variates. Must be \u2018count\u2019\nor \u2018marginals\u2019 (the default). See the Notes for a description of the methods.\n\nArray of variates drawn from the multivariate hypergeometric distribution.\n\nSee also\n\nDraw samples from the (univariate) hypergeometric distribution.\n\nThe two methods do not return the same sequence of variates.\n\nThe \u201ccount\u201d algorithm is roughly equivalent to the following numpy code:\n\nThe \u201ccount\u201d algorithm uses a temporary array of integers with length\n`sum(colors)`.\n\nThe \u201cmarginals\u201d algorithm generates a variate by using repeated calls to the\nunivariate hypergeometric sampler. It is roughly equivalent to:\n\nThe default method is \u201cmarginals\u201d. For some cases (e.g. when `colors` contains\nrelatively small integers), the \u201ccount\u201d method can be significantly faster\nthan the \u201cmarginals\u201d method. If performance of the algorithm is important,\ntest the two methods with typical inputs to decide which works best.\n\nNew in version 1.18.0.\n\n"}, {"name": "random.Generator.multivariate_normal()", "path": "reference/random/generated/numpy.random.generator.multivariate_normal", "type": "numpy.random.Generator.multivariate_normal", "text": "\nmethod\n\nDraw random samples from a multivariate normal distribution.\n\nThe multivariate normal, multinormal or Gaussian distribution is a\ngeneralization of the one-dimensional normal distribution to higher\ndimensions. Such a distribution is specified by its mean and covariance\nmatrix. These parameters are analogous to the mean (average or \u201ccenter\u201d) and\nvariance (standard deviation, or \u201cwidth,\u201d squared) of the one-dimensional\nnormal distribution.\n\nMean of the N-dimensional distribution.\n\nCovariance matrix of the distribution. It must be symmetric and positive-\nsemidefinite for proper sampling.\n\nGiven a shape of, for example, `(m,n,k)`, `m*n*k` samples are generated, and\npacked in an `m`-by-`n`-by-`k` arrangement. Because each sample is\n`N`-dimensional, the output shape is `(m,n,k,N)`. If no shape is specified, a\nsingle (`N`-D) sample is returned.\n\nBehavior when the covariance matrix is not positive semidefinite.\n\nTolerance when checking the singular values in covariance matrix. cov is cast\nto double before the check.\n\nThe cov input is used to compute a factor matrix A such that `A @ A.T = cov`.\nThis argument is used to select the method used to compute the factor matrix\nA. The default method \u2018svd\u2019 is the slowest, while \u2018cholesky\u2019 is the fastest\nbut less robust than the slowest method. The method `eigh` uses eigen\ndecomposition to compute A and is faster than svd but slower than cholesky.\n\nNew in version 1.18.0.\n\nThe drawn samples, of shape size, if that was provided. If not, the shape is\n`(N,)`.\n\nIn other words, each entry `out[i,j,...,:]` is an N-dimensional value drawn\nfrom the distribution.\n\nThe mean is a coordinate in N-dimensional space, which represents the location\nwhere samples are most likely to be generated. This is analogous to the peak\nof the bell curve for the one-dimensional or univariate normal distribution.\n\nCovariance indicates the level to which two variables vary together. From the\nmultivariate normal distribution, we draw N-dimensional samples, \\\\(X = [x_1,\nx_2, ... x_N]\\\\). The covariance matrix element \\\\(C_{ij}\\\\) is the covariance\nof \\\\(x_i\\\\) and \\\\(x_j\\\\). The element \\\\(C_{ii}\\\\) is the variance of\n\\\\(x_i\\\\) (i.e. its \u201cspread\u201d).\n\nInstead of specifying the full covariance matrix, popular approximations\ninclude:\n\nThis geometrical property can be seen in two dimensions by plotting generated\ndata-points:\n\nDiagonal covariance means that points are oriented along x or y-axis:\n\nNote that the covariance matrix must be positive semidefinite (a.k.a.\nnonnegative-definite). Otherwise, the behavior of this method is undefined and\nbackwards compatibility is not guaranteed.\n\nPapoulis, A., \u201cProbability, Random Variables, and Stochastic Processes,\u201d 3rd\ned., New York: McGraw-Hill, 1991.\n\nDuda, R. O., Hart, P. E., and Stork, D. G., \u201cPattern Classification,\u201d 2nd ed.,\nNew York: Wiley, 2001.\n\nWe can use a different method other than the default to factorize cov:\n\nThe following is probably true, given that 0.6 is roughly twice the standard\ndeviation:\n\n"}, {"name": "random.Generator.negative_binomial()", "path": "reference/random/generated/numpy.random.generator.negative_binomial", "type": "numpy.random.Generator.negative_binomial", "text": "\nmethod\n\nDraw samples from a negative binomial distribution.\n\nSamples are drawn from a negative binomial distribution with specified\nparameters, `n` successes and `p` probability of success where `n` is > 0 and\n`p` is in the interval (0, 1].\n\nParameter of the distribution, > 0.\n\nParameter of the distribution. Must satisfy 0 < p <= 1.\n\nOutput shape. If the given shape is, e.g., `(m, n, k)`, then `m * n * k`\nsamples are drawn. If size is `None` (default), a single value is returned if\n`n` and `p` are both scalars. Otherwise, `np.broadcast(n, p).size` samples are\ndrawn.\n\nDrawn samples from the parameterized negative binomial distribution, where\neach sample is equal to N, the number of failures that occurred before a total\nof n successes was reached.\n\nThe probability mass function of the negative binomial distribution is\n\nwhere \\\\(n\\\\) is the number of successes, \\\\(p\\\\) is the probability of\nsuccess, \\\\(N+n\\\\) is the number of trials, and \\\\(\\Gamma\\\\) is the gamma\nfunction. When \\\\(n\\\\) is an integer, \\\\(\\frac{\\Gamma(N+n)}{N!\\Gamma(n)} =\n\\binom{N+n-1}{N}\\\\), which is the more common form of this term in the the\npmf. The negative binomial distribution gives the probability of N failures\ngiven n successes, with a success on the last trial.\n\nIf one throws a die repeatedly until the third time a \u201c1\u201d appears, then the\nprobability distribution of the number of non-\u201c1\u201ds that appear before the\nthird \u201c1\u201d is a negative binomial distribution.\n\nWeisstein, Eric W. \u201cNegative Binomial Distribution.\u201d From MathWorld\u2013A Wolfram\nWeb Resource. http://mathworld.wolfram.com/NegativeBinomialDistribution.html\n\nWikipedia, \u201cNegative binomial distribution\u201d,\nhttps://en.wikipedia.org/wiki/Negative_binomial_distribution\n\nDraw samples from the distribution:\n\nA real world example. A company drills wild-cat oil exploration wells, each\nwith an estimated probability of success of 0.1. What is the probability of\nhaving one success for each successive well, that is what is the probability\nof a single success after drilling 5 wells, after 6 wells, etc.?\n\n"}, {"name": "random.Generator.noncentral_chisquare()", "path": "reference/random/generated/numpy.random.generator.noncentral_chisquare", "type": "numpy.random.Generator.noncentral_chisquare", "text": "\nmethod\n\nDraw samples from a noncentral chi-square distribution.\n\nThe noncentral \\\\(\\chi^2\\\\) distribution is a generalization of the\n\\\\(\\chi^2\\\\) distribution.\n\nDegrees of freedom, must be > 0.\n\nChanged in version 1.10.0: Earlier NumPy versions required dfnum > 1.\n\nNon-centrality, must be non-negative.\n\nOutput shape. If the given shape is, e.g., `(m, n, k)`, then `m * n * k`\nsamples are drawn. If size is `None` (default), a single value is returned if\n`df` and `nonc` are both scalars. Otherwise, `np.broadcast(df, nonc).size`\nsamples are drawn.\n\nDrawn samples from the parameterized noncentral chi-square distribution.\n\nThe probability density function for the noncentral Chi-square distribution is\n\nwhere \\\\(Y_{q}\\\\) is the Chi-square with q degrees of freedom.\n\nWikipedia, \u201cNoncentral chi-squared distribution\u201d\nhttps://en.wikipedia.org/wiki/Noncentral_chi-squared_distribution\n\nDraw values from the distribution and plot the histogram\n\nDraw values from a noncentral chisquare with very small noncentrality, and\ncompare to a chisquare.\n\nDemonstrate how large values of non-centrality lead to a more symmetric\ndistribution.\n\n"}, {"name": "random.Generator.noncentral_f()", "path": "reference/random/generated/numpy.random.generator.noncentral_f", "type": "numpy.random.Generator.noncentral_f", "text": "\nmethod\n\nDraw samples from the noncentral F distribution.\n\nSamples are drawn from an F distribution with specified parameters, `dfnum`\n(degrees of freedom in numerator) and `dfden` (degrees of freedom in\ndenominator), where both parameters > 1\\. `nonc` is the non-centrality\nparameter.\n\nNumerator degrees of freedom, must be > 0.\n\nChanged in version 1.14.0: Earlier NumPy versions required dfnum > 1.\n\nDenominator degrees of freedom, must be > 0.\n\nNon-centrality parameter, the sum of the squares of the numerator means, must\nbe >= 0.\n\nOutput shape. If the given shape is, e.g., `(m, n, k)`, then `m * n * k`\nsamples are drawn. If size is `None` (default), a single value is returned if\n`dfnum`, `dfden`, and `nonc` are all scalars. Otherwise, `np.broadcast(dfnum,\ndfden, nonc).size` samples are drawn.\n\nDrawn samples from the parameterized noncentral Fisher distribution.\n\nWhen calculating the power of an experiment (power = probability of rejecting\nthe null hypothesis when a specific alternative is true) the non-central F\nstatistic becomes important. When the null hypothesis is true, the F statistic\nfollows a central F distribution. When the null hypothesis is not true, then\nit follows a non-central F statistic.\n\nWeisstein, Eric W. \u201cNoncentral F-Distribution.\u201d From MathWorld\u2013A Wolfram Web\nResource. http://mathworld.wolfram.com/NoncentralF-Distribution.html\n\nWikipedia, \u201cNoncentral F-distribution\u201d,\nhttps://en.wikipedia.org/wiki/Noncentral_F-distribution\n\nIn a study, testing for a specific alternative to the null hypothesis requires\nuse of the Noncentral F distribution. We need to calculate the area in the\ntail of the distribution that exceeds the value of the F distribution for the\nnull hypothesis. We\u2019ll plot the two probability distributions for comparison.\n\n"}, {"name": "random.Generator.normal()", "path": "reference/random/generated/numpy.random.generator.normal", "type": "numpy.random.Generator.normal", "text": "\nmethod\n\nDraw random samples from a normal (Gaussian) distribution.\n\nThe probability density function of the normal distribution, first derived by\nDe Moivre and 200 years later by both Gauss and Laplace independently [2], is\noften called the bell curve because of its characteristic shape (see the\nexample below).\n\nThe normal distributions occurs often in nature. For example, it describes the\ncommonly occurring distribution of samples influenced by a large number of\ntiny, random disturbances, each with its own unique distribution [2].\n\nMean (\u201ccentre\u201d) of the distribution.\n\nStandard deviation (spread or \u201cwidth\u201d) of the distribution. Must be non-\nnegative.\n\nOutput shape. If the given shape is, e.g., `(m, n, k)`, then `m * n * k`\nsamples are drawn. If size is `None` (default), a single value is returned if\n`loc` and `scale` are both scalars. Otherwise, `np.broadcast(loc, scale).size`\nsamples are drawn.\n\nDrawn samples from the parameterized normal distribution.\n\nSee also\n\nprobability density function, distribution or cumulative density function,\netc.\n\nThe probability density for the Gaussian distribution is\n\nwhere \\\\(\\mu\\\\) is the mean and \\\\(\\sigma\\\\) the standard deviation. The\nsquare of the standard deviation, \\\\(\\sigma^2\\\\), is called the variance.\n\nThe function has its peak at the mean, and its \u201cspread\u201d increases with the\nstandard deviation (the function reaches 0.607 times its maximum at \\\\(x +\n\\sigma\\\\) and \\\\(x - \\sigma\\\\) [2]). This implies that `normal` is more likely\nto return samples lying close to the mean, rather than those far away.\n\nWikipedia, \u201cNormal distribution\u201d,\nhttps://en.wikipedia.org/wiki/Normal_distribution\n\nP. R. Peebles Jr., \u201cCentral Limit Theorem\u201d in \u201cProbability, Random Variables\nand Random Signal Principles\u201d, 4th ed., 2001, pp. 51, 51, 125.\n\nDraw samples from the distribution:\n\nVerify the mean and the variance:\n\nDisplay the histogram of the samples, along with the probability density\nfunction:\n\nTwo-by-four array of samples from N(3, 6.25):\n\n"}, {"name": "random.Generator.pareto()", "path": "reference/random/generated/numpy.random.generator.pareto", "type": "numpy.random.Generator.pareto", "text": "\nmethod\n\nDraw samples from a Pareto II or Lomax distribution with specified shape.\n\nThe Lomax or Pareto II distribution is a shifted Pareto distribution. The\nclassical Pareto distribution can be obtained from the Lomax distribution by\nadding 1 and multiplying by the scale parameter `m` (see Notes). The smallest\nvalue of the Lomax distribution is zero while for the classical Pareto\ndistribution it is `mu`, where the standard Pareto distribution has location\n`mu = 1`. Lomax can also be considered as a simplified version of the\nGeneralized Pareto distribution (available in SciPy), with the scale set to\none and the location set to zero.\n\nThe Pareto distribution must be greater than zero, and is unbounded above. It\nis also known as the \u201c80-20 rule\u201d. In this distribution, 80 percent of the\nweights are in the lowest 20 percent of the range, while the other 20 percent\nfill the remaining 80 percent of the range.\n\nShape of the distribution. Must be positive.\n\nOutput shape. If the given shape is, e.g., `(m, n, k)`, then `m * n * k`\nsamples are drawn. If size is `None` (default), a single value is returned if\n`a` is a scalar. Otherwise, `np.array(a).size` samples are drawn.\n\nDrawn samples from the parameterized Pareto distribution.\n\nSee also\n\nprobability density function, distribution or cumulative density function,\netc.\n\nprobability density function, distribution or cumulative density function,\netc.\n\nThe probability density for the Pareto distribution is\n\nwhere \\\\(a\\\\) is the shape and \\\\(m\\\\) the scale.\n\nThe Pareto distribution, named after the Italian economist Vilfredo Pareto, is\na power law probability distribution useful in many real world problems.\nOutside the field of economics it is generally referred to as the Bradford\ndistribution. Pareto developed the distribution to describe the distribution\nof wealth in an economy. It has also found use in insurance, web page access\nstatistics, oil field sizes, and many other problems, including the download\nfrequency for projects in Sourceforge [1]. It is one of the so-called \u201cfat-\ntailed\u201d distributions.\n\nFrancis Hunt and Paul Johnson, On the Pareto Distribution of Sourceforge\nprojects.\n\nPareto, V. (1896). Course of Political Economy. Lausanne.\n\nReiss, R.D., Thomas, M.(2001), Statistical Analysis of Extreme Values,\nBirkhauser Verlag, Basel, pp 23-30.\n\nWikipedia, \u201cPareto distribution\u201d,\nhttps://en.wikipedia.org/wiki/Pareto_distribution\n\nDraw samples from the distribution:\n\nDisplay the histogram of the samples, along with the probability density\nfunction:\n\n"}, {"name": "random.Generator.permutation()", "path": "reference/random/generated/numpy.random.generator.permutation", "type": "numpy.random.Generator.permutation", "text": "\nmethod\n\nRandomly permute a sequence, or return a permuted range.\n\nIf `x` is an integer, randomly permute `np.arange(x)`. If `x` is an array,\nmake a copy and shuffle the elements randomly.\n\nThe axis which `x` is shuffled along. Default is 0.\n\nPermuted sequence or array range.\n\n"}, {"name": "random.Generator.permuted()", "path": "reference/random/generated/numpy.random.generator.permuted", "type": "numpy.random.Generator.permuted", "text": "\nmethod\n\nRandomly permute `x` along axis `axis`.\n\nUnlike `shuffle`, each slice along the given axis is shuffled independently of\nthe others.\n\nArray to be shuffled.\n\nSlices of `x` in this axis are shuffled. Each slice is shuffled independently\nof the others. If `axis` is None, the flattened array is shuffled.\n\nIf given, this is the destinaton of the shuffled array. If `out` is None, a\nshuffled copy of the array is returned.\n\nIf `out` is None, a shuffled copy of `x` is returned. Otherwise, the shuffled\narray is stored in `out`, and `out` is returned\n\nSee also\n\nCreate a `numpy.random.Generator` instance:\n\nCreate a test array:\n\nShuffle the rows of `x`:\n\n`x` has not been modified:\n\nTo shuffle the rows of `x` in-place, pass `x` as the `out` parameter:\n\nNote that when the `out` parameter is given, the return value is `out`:\n\n"}, {"name": "random.Generator.poisson()", "path": "reference/random/generated/numpy.random.generator.poisson", "type": "numpy.random.Generator.poisson", "text": "\nmethod\n\nDraw samples from a Poisson distribution.\n\nThe Poisson distribution is the limit of the binomial distribution for large\nN.\n\nExpected number of events occurring in a fixed-time interval, must be >= 0. A\nsequence must be broadcastable over the requested size.\n\nOutput shape. If the given shape is, e.g., `(m, n, k)`, then `m * n * k`\nsamples are drawn. If size is `None` (default), a single value is returned if\n`lam` is a scalar. Otherwise, `np.array(lam).size` samples are drawn.\n\nDrawn samples from the parameterized Poisson distribution.\n\nThe Poisson distribution\n\nFor events with an expected separation \\\\(\\lambda\\\\) the Poisson distribution\n\\\\(f(k; \\lambda)\\\\) describes the probability of \\\\(k\\\\) events occurring\nwithin the observed interval \\\\(\\lambda\\\\).\n\nBecause the output is limited to the range of the C int64 type, a ValueError\nis raised when `lam` is within 10 sigma of the maximum representable value.\n\nWeisstein, Eric W. \u201cPoisson Distribution.\u201d From MathWorld\u2013A Wolfram Web\nResource. http://mathworld.wolfram.com/PoissonDistribution.html\n\nWikipedia, \u201cPoisson distribution\u201d,\nhttps://en.wikipedia.org/wiki/Poisson_distribution\n\nDraw samples from the distribution:\n\nDisplay histogram of the sample:\n\nDraw each 100 values for lambda 100 and 500:\n\n"}, {"name": "random.Generator.power()", "path": "reference/random/generated/numpy.random.generator.power", "type": "numpy.random.Generator.power", "text": "\nmethod\n\nDraws samples in [0, 1] from a power distribution with positive exponent a -\n1.\n\nAlso known as the power function distribution.\n\nParameter of the distribution. Must be non-negative.\n\nOutput shape. If the given shape is, e.g., `(m, n, k)`, then `m * n * k`\nsamples are drawn. If size is `None` (default), a single value is returned if\n`a` is a scalar. Otherwise, `np.array(a).size` samples are drawn.\n\nDrawn samples from the parameterized power distribution.\n\nIf a <= 0.\n\nThe probability density function is\n\nThe power function distribution is just the inverse of the Pareto\ndistribution. It may also be seen as a special case of the Beta distribution.\n\nIt is used, for example, in modeling the over-reporting of insurance claims.\n\nChristian Kleiber, Samuel Kotz, \u201cStatistical size distributions in economics\nand actuarial sciences\u201d, Wiley, 2003.\n\nHeckert, N. A. and Filliben, James J. \u201cNIST Handbook 148: Dataplot Reference\nManual, Volume 2: Let Subcommands and Library Functions\u201d, National Institute\nof Standards and Technology Handbook Series, June 2003.\nhttps://www.itl.nist.gov/div898/software/dataplot/refman2/auxillar/powpdf.pdf\n\nDraw samples from the distribution:\n\nDisplay the histogram of the samples, along with the probability density\nfunction:\n\nCompare the power function distribution to the inverse of the Pareto.\n\n"}, {"name": "random.Generator.random()", "path": "reference/random/generated/numpy.random.generator.random", "type": "numpy.random.Generator.random", "text": "\nmethod\n\nReturn random floats in the half-open interval [0.0, 1.0).\n\nResults are from the \u201ccontinuous uniform\u201d distribution over the stated\ninterval. To sample \\\\(Unif[a, b), b > a\\\\) multiply the output of `random` by\n`(b-a)` and add `a`:\n\nOutput shape. If the given shape is, e.g., `(m, n, k)`, then `m * n * k`\nsamples are drawn. Default is None, in which case a single value is returned.\n\nDesired dtype of the result, only `float64` and `float32` are supported.\nByteorder must be native. The default value is np.float64.\n\nAlternative output array in which to place the result. If size is not None, it\nmust have the same shape as the provided size and must match the type of the\noutput values.\n\nArray of random floats of shape `size` (unless `size=None`, in which case a\nsingle float is returned).\n\nThree-by-two array of random numbers from [-5, 0):\n\n"}, {"name": "random.Generator.rayleigh()", "path": "reference/random/generated/numpy.random.generator.rayleigh", "type": "numpy.random.Generator.rayleigh", "text": "\nmethod\n\nDraw samples from a Rayleigh distribution.\n\nThe \\\\(\\chi\\\\) and Weibull distributions are generalizations of the Rayleigh.\n\nScale, also equals the mode. Must be non-negative. Default is 1.\n\nOutput shape. If the given shape is, e.g., `(m, n, k)`, then `m * n * k`\nsamples are drawn. If size is `None` (default), a single value is returned if\n`scale` is a scalar. Otherwise, `np.array(scale).size` samples are drawn.\n\nDrawn samples from the parameterized Rayleigh distribution.\n\nThe probability density function for the Rayleigh distribution is\n\nThe Rayleigh distribution would arise, for example, if the East and North\ncomponents of the wind velocity had identical zero-mean Gaussian\ndistributions. Then the wind speed would have a Rayleigh distribution.\n\nBrighton Webs Ltd., \u201cRayleigh Distribution,\u201d\nhttps://web.archive.org/web/20090514091424/http://brighton-\nwebs.co.uk:80/distributions/rayleigh.asp\n\nWikipedia, \u201cRayleigh distribution\u201d\nhttps://en.wikipedia.org/wiki/Rayleigh_distribution\n\nDraw values from the distribution and plot the histogram\n\nWave heights tend to follow a Rayleigh distribution. If the mean wave height\nis 1 meter, what fraction of waves are likely to be larger than 3 meters?\n\nThe percentage of waves larger than 3 meters is:\n\n"}, {"name": "random.Generator.shuffle()", "path": "reference/random/generated/numpy.random.generator.shuffle", "type": "numpy.random.Generator.shuffle", "text": "\nmethod\n\nModify an array or sequence in-place by shuffling its contents.\n\nThe order of sub-arrays is changed but their contents remains the same.\n\nThe array, list or mutable sequence to be shuffled.\n\nThe axis which `x` is shuffled along. Default is 0. It is only supported on\n`ndarray` objects.\n\n"}, {"name": "random.Generator.standard_cauchy()", "path": "reference/random/generated/numpy.random.generator.standard_cauchy", "type": "numpy.random.Generator.standard_cauchy", "text": "\nmethod\n\nDraw samples from a standard Cauchy distribution with mode = 0.\n\nAlso known as the Lorentz distribution.\n\nOutput shape. If the given shape is, e.g., `(m, n, k)`, then `m * n * k`\nsamples are drawn. Default is None, in which case a single value is returned.\n\nThe drawn samples.\n\nThe probability density function for the full Cauchy distribution is\n\nand the Standard Cauchy distribution just sets \\\\(x_0=0\\\\) and \\\\(\\gamma=1\\\\)\n\nThe Cauchy distribution arises in the solution to the driven harmonic\noscillator problem, and also describes spectral line broadening. It also\ndescribes the distribution of values at which a line tilted at a random angle\nwill cut the x axis.\n\nWhen studying hypothesis tests that assume normality, seeing how the tests\nperform on data from a Cauchy distribution is a good indicator of their\nsensitivity to a heavy-tailed distribution, since the Cauchy looks very much\nlike a Gaussian distribution, but with heavier tails.\n\nNIST/SEMATECH e-Handbook of Statistical Methods, \u201cCauchy Distribution\u201d,\nhttps://www.itl.nist.gov/div898/handbook/eda/section3/eda3663.htm\n\nWeisstein, Eric W. \u201cCauchy Distribution.\u201d From MathWorld\u2013A Wolfram Web\nResource. http://mathworld.wolfram.com/CauchyDistribution.html\n\nWikipedia, \u201cCauchy distribution\u201d\nhttps://en.wikipedia.org/wiki/Cauchy_distribution\n\nDraw samples and plot the distribution:\n\n"}, {"name": "random.Generator.standard_exponential()", "path": "reference/random/generated/numpy.random.generator.standard_exponential", "type": "numpy.random.Generator.standard_exponential", "text": "\nmethod\n\nDraw samples from the standard exponential distribution.\n\n`standard_exponential` is identical to the exponential distribution with a\nscale parameter of 1.\n\nOutput shape. If the given shape is, e.g., `(m, n, k)`, then `m * n * k`\nsamples are drawn. Default is None, in which case a single value is returned.\n\nDesired dtype of the result, only `float64` and `float32` are supported.\nByteorder must be native. The default value is np.float64.\n\nEither \u2018inv\u2019 or \u2018zig\u2019. \u2018inv\u2019 uses the default inverse CDF method. \u2018zig\u2019 uses\nthe much faster Ziggurat method of Marsaglia and Tsang.\n\nAlternative output array in which to place the result. If size is not None, it\nmust have the same shape as the provided size and must match the type of the\noutput values.\n\nDrawn samples.\n\nOutput a 3x8000 array:\n\n"}, {"name": "random.Generator.standard_gamma()", "path": "reference/random/generated/numpy.random.generator.standard_gamma", "type": "numpy.random.Generator.standard_gamma", "text": "\nmethod\n\nDraw samples from a standard Gamma distribution.\n\nSamples are drawn from a Gamma distribution with specified parameters, shape\n(sometimes designated \u201ck\u201d) and scale=1.\n\nParameter, must be non-negative.\n\nOutput shape. If the given shape is, e.g., `(m, n, k)`, then `m * n * k`\nsamples are drawn. If size is `None` (default), a single value is returned if\n`shape` is a scalar. Otherwise, `np.array(shape).size` samples are drawn.\n\nDesired dtype of the result, only `float64` and `float32` are supported.\nByteorder must be native. The default value is np.float64.\n\nAlternative output array in which to place the result. If size is not None, it\nmust have the same shape as the provided size and must match the type of the\noutput values.\n\nDrawn samples from the parameterized standard gamma distribution.\n\nSee also\n\nprobability density function, distribution or cumulative density function,\netc.\n\nThe probability density for the Gamma distribution is\n\nwhere \\\\(k\\\\) is the shape and \\\\(\\theta\\\\) the scale, and \\\\(\\Gamma\\\\) is the\nGamma function.\n\nThe Gamma distribution is often used to model the times to failure of\nelectronic components, and arises naturally in processes for which the waiting\ntimes between Poisson distributed events are relevant.\n\nWeisstein, Eric W. \u201cGamma Distribution.\u201d From MathWorld\u2013A Wolfram Web\nResource. http://mathworld.wolfram.com/GammaDistribution.html\n\nWikipedia, \u201cGamma distribution\u201d,\nhttps://en.wikipedia.org/wiki/Gamma_distribution\n\nDraw samples from the distribution:\n\nDisplay the histogram of the samples, along with the probability density\nfunction:\n\n"}, {"name": "random.Generator.standard_normal()", "path": "reference/random/generated/numpy.random.generator.standard_normal", "type": "numpy.random.Generator.standard_normal", "text": "\nmethod\n\nDraw samples from a standard Normal distribution (mean=0, stdev=1).\n\nOutput shape. If the given shape is, e.g., `(m, n, k)`, then `m * n * k`\nsamples are drawn. Default is None, in which case a single value is returned.\n\nDesired dtype of the result, only `float64` and `float32` are supported.\nByteorder must be native. The default value is np.float64.\n\nAlternative output array in which to place the result. If size is not None, it\nmust have the same shape as the provided size and must match the type of the\noutput values.\n\nA floating-point array of shape `size` of drawn samples, or a single sample if\n`size` was not specified.\n\nSee also\n\nEquivalent function with additional `loc` and `scale` arguments for setting\nthe mean and standard deviation.\n\nFor random samples from \\\\(N(\\mu, \\sigma^2)\\\\), use one of:\n\nTwo-by-four array of samples from \\\\(N(3, 6.25)\\\\):\n\n"}, {"name": "random.Generator.standard_t()", "path": "reference/random/generated/numpy.random.generator.standard_t", "type": "numpy.random.Generator.standard_t", "text": "\nmethod\n\nDraw samples from a standard Student\u2019s t distribution with `df` degrees of\nfreedom.\n\nA special case of the hyperbolic distribution. As `df` gets large, the result\nresembles that of the standard normal distribution (`standard_normal`).\n\nDegrees of freedom, must be > 0.\n\nOutput shape. If the given shape is, e.g., `(m, n, k)`, then `m * n * k`\nsamples are drawn. If size is `None` (default), a single value is returned if\n`df` is a scalar. Otherwise, `np.array(df).size` samples are drawn.\n\nDrawn samples from the parameterized standard Student\u2019s t distribution.\n\nThe probability density function for the t distribution is\n\nThe t test is based on an assumption that the data come from a Normal\ndistribution. The t test provides a way to test whether the sample mean (that\nis the mean calculated from the data) is a good estimate of the true mean.\n\nThe derivation of the t-distribution was first published in 1908 by William\nGosset while working for the Guinness Brewery in Dublin. Due to proprietary\nissues, he had to publish under a pseudonym, and so he used the name Student.\n\nDalgaard, Peter, \u201cIntroductory Statistics With R\u201d, Springer, 2002.\n\nWikipedia, \u201cStudent\u2019s t-distribution\u201d\nhttps://en.wikipedia.org/wiki/Student\u2019s_t-distribution\n\nFrom Dalgaard page 83 [1], suppose the daily energy intake for 11 women in\nkilojoules (kJ) is:\n\nDoes their energy intake deviate systematically from the recommended value of\n7725 kJ? Our null hypothesis will be the absence of deviation, and the\nalternate hypothesis will be the presence of an effect that could be either\npositive or negative, hence making our test 2-tailed.\n\nBecause we are estimating the mean and we have N=11 values in our sample, we\nhave N-1=10 degrees of freedom. We set our significance level to 95% and\ncompute the t statistic using the empirical mean and empirical standard\ndeviation of our intake. We use a ddof of 1 to base the computation of our\nempirical standard deviation on an unbiased estimate of the variance (note:\nthe final estimate is not unbiased due to the concave nature of the square\nroot).\n\nWe draw 1000000 samples from Student\u2019s t distribution with the adequate\ndegrees of freedom.\n\nDoes our t statistic land in one of the two critical regions found at both\ntails of the distribution?\n\nThe probability value for this 2-tailed test is about 1.83%, which is lower\nthan the 5% pre-determined significance threshold.\n\nTherefore, the probability of observing values as extreme as our intake\nconditionally on the null hypothesis being true is too low, and we reject the\nnull hypothesis of no deviation.\n\n"}, {"name": "random.Generator.triangular()", "path": "reference/random/generated/numpy.random.generator.triangular", "type": "numpy.random.Generator.triangular", "text": "\nmethod\n\nDraw samples from the triangular distribution over the interval `[left,\nright]`.\n\nThe triangular distribution is a continuous probability distribution with\nlower limit left, peak at mode, and upper limit right. Unlike the other\ndistributions, these parameters directly define the shape of the pdf.\n\nLower limit.\n\nThe value where the peak of the distribution occurs. The value must fulfill\nthe condition `left <= mode <= right`.\n\nUpper limit, must be larger than `left`.\n\nOutput shape. If the given shape is, e.g., `(m, n, k)`, then `m * n * k`\nsamples are drawn. If size is `None` (default), a single value is returned if\n`left`, `mode`, and `right` are all scalars. Otherwise, `np.broadcast(left,\nmode, right).size` samples are drawn.\n\nDrawn samples from the parameterized triangular distribution.\n\nThe probability density function for the triangular distribution is\n\nThe triangular distribution is often used in ill-defined problems where the\nunderlying distribution is not known, but some knowledge of the limits and\nmode exists. Often it is used in simulations.\n\nWikipedia, \u201cTriangular distribution\u201d\nhttps://en.wikipedia.org/wiki/Triangular_distribution\n\nDraw values from the distribution and plot the histogram:\n\n"}, {"name": "random.Generator.uniform()", "path": "reference/random/generated/numpy.random.generator.uniform", "type": "numpy.random.Generator.uniform", "text": "\nmethod\n\nDraw samples from a uniform distribution.\n\nSamples are uniformly distributed over the half-open interval `[low, high)`\n(includes low, but excludes high). In other words, any value within the given\ninterval is equally likely to be drawn by `uniform`.\n\nLower boundary of the output interval. All values generated will be greater\nthan or equal to low. The default value is 0.\n\nUpper boundary of the output interval. All values generated will be less than\nhigh. The high limit may be included in the returned array of floats due to\nfloating-point rounding in the equation `low + (high-low) * random_sample()`.\nhigh - low must be non-negative. The default value is 1.0.\n\nOutput shape. If the given shape is, e.g., `(m, n, k)`, then `m * n * k`\nsamples are drawn. If size is `None` (default), a single value is returned if\n`low` and `high` are both scalars. Otherwise, `np.broadcast(low, high).size`\nsamples are drawn.\n\nDrawn samples from the parameterized uniform distribution.\n\nSee also\n\nDiscrete uniform distribution, yielding integers.\n\nFloats uniformly distributed over `[0, 1)`.\n\nThe probability density function of the uniform distribution is\n\nanywhere within the interval `[a, b)`, and zero elsewhere.\n\nWhen `high` == `low`, values of `low` will be returned.\n\nDraw samples from the distribution:\n\nAll values are within the given interval:\n\nDisplay the histogram of the samples, along with the probability density\nfunction:\n\n"}, {"name": "random.Generator.vonmises()", "path": "reference/random/generated/numpy.random.generator.vonmises", "type": "numpy.random.Generator.vonmises", "text": "\nmethod\n\nDraw samples from a von Mises distribution.\n\nSamples are drawn from a von Mises distribution with specified mode (mu) and\ndispersion (kappa), on the interval [-pi, pi].\n\nThe von Mises distribution (also known as the circular normal distribution) is\na continuous probability distribution on the unit circle. It may be thought of\nas the circular analogue of the normal distribution.\n\nMode (\u201ccenter\u201d) of the distribution.\n\nDispersion of the distribution, has to be >=0.\n\nOutput shape. If the given shape is, e.g., `(m, n, k)`, then `m * n * k`\nsamples are drawn. If size is `None` (default), a single value is returned if\n`mu` and `kappa` are both scalars. Otherwise, `np.broadcast(mu, kappa).size`\nsamples are drawn.\n\nDrawn samples from the parameterized von Mises distribution.\n\nSee also\n\nprobability density function, distribution, or cumulative density function,\netc.\n\nThe probability density for the von Mises distribution is\n\nwhere \\\\(\\mu\\\\) is the mode and \\\\(\\kappa\\\\) the dispersion, and\n\\\\(I_0(\\kappa)\\\\) is the modified Bessel function of order 0.\n\nThe von Mises is named for Richard Edler von Mises, who was born in Austria-\nHungary, in what is now the Ukraine. He fled to the United States in 1939 and\nbecame a professor at Harvard. He worked in probability theory, aerodynamics,\nfluid mechanics, and philosophy of science.\n\nAbramowitz, M. and Stegun, I. A. (Eds.). \u201cHandbook of Mathematical Functions\nwith Formulas, Graphs, and Mathematical Tables, 9th printing,\u201d New York:\nDover, 1972.\n\nvon Mises, R., \u201cMathematical Theory of Probability and Statistics\u201d, New York:\nAcademic Press, 1964.\n\nDraw samples from the distribution:\n\nDisplay the histogram of the samples, along with the probability density\nfunction:\n\n"}, {"name": "random.Generator.wald()", "path": "reference/random/generated/numpy.random.generator.wald", "type": "numpy.random.Generator.wald", "text": "\nmethod\n\nDraw samples from a Wald, or inverse Gaussian, distribution.\n\nAs the scale approaches infinity, the distribution becomes more like a\nGaussian. Some references claim that the Wald is an inverse Gaussian with mean\nequal to 1, but this is by no means universal.\n\nThe inverse Gaussian distribution was first studied in relationship to\nBrownian motion. In 1956 M.C.K. Tweedie used the name inverse Gaussian because\nthere is an inverse relationship between the time to cover a unit distance and\ndistance covered in unit time.\n\nDistribution mean, must be > 0.\n\nScale parameter, must be > 0.\n\nOutput shape. If the given shape is, e.g., `(m, n, k)`, then `m * n * k`\nsamples are drawn. If size is `None` (default), a single value is returned if\n`mean` and `scale` are both scalars. Otherwise, `np.broadcast(mean,\nscale).size` samples are drawn.\n\nDrawn samples from the parameterized Wald distribution.\n\nThe probability density function for the Wald distribution is\n\nAs noted above the inverse Gaussian distribution first arise from attempts to\nmodel Brownian motion. It is also a competitor to the Weibull for use in\nreliability modeling and modeling stock returns and interest rate processes.\n\nBrighton Webs Ltd., Wald Distribution,\nhttps://web.archive.org/web/20090423014010/http://www.brighton-\nwebs.co.uk:80/distributions/wald.asp\n\nChhikara, Raj S., and Folks, J. Leroy, \u201cThe Inverse Gaussian Distribution:\nTheory : Methodology, and Applications\u201d, CRC Press, 1988.\n\nWikipedia, \u201cInverse Gaussian distribution\u201d\nhttps://en.wikipedia.org/wiki/Inverse_Gaussian_distribution\n\nDraw values from the distribution and plot the histogram:\n\n"}, {"name": "random.Generator.weibull()", "path": "reference/random/generated/numpy.random.generator.weibull", "type": "numpy.random.Generator.weibull", "text": "\nmethod\n\nDraw samples from a Weibull distribution.\n\nDraw samples from a 1-parameter Weibull distribution with the given shape\nparameter `a`.\n\nHere, U is drawn from the uniform distribution over (0,1].\n\nThe more common 2-parameter Weibull, including a scale parameter \\\\(\\lambda\\\\)\nis just \\\\(X = \\lambda(-ln(U))^{1/a}\\\\).\n\nShape parameter of the distribution. Must be nonnegative.\n\nOutput shape. If the given shape is, e.g., `(m, n, k)`, then `m * n * k`\nsamples are drawn. If size is `None` (default), a single value is returned if\n`a` is a scalar. Otherwise, `np.array(a).size` samples are drawn.\n\nDrawn samples from the parameterized Weibull distribution.\n\nSee also\n\nThe Weibull (or Type III asymptotic extreme value distribution for smallest\nvalues, SEV Type III, or Rosin-Rammler distribution) is one of a class of\nGeneralized Extreme Value (GEV) distributions used in modeling extreme value\nproblems. This class includes the Gumbel and Frechet distributions.\n\nThe probability density for the Weibull distribution is\n\nwhere \\\\(a\\\\) is the shape and \\\\(\\lambda\\\\) the scale.\n\nThe function has its peak (the mode) at \\\\(\\lambda(\\frac{a-1}{a})^{1/a}\\\\).\n\nWhen `a = 1`, the Weibull distribution reduces to the exponential\ndistribution.\n\nWaloddi Weibull, Royal Technical University, Stockholm, 1939 \u201cA Statistical\nTheory Of The Strength Of Materials\u201d, Ingeniorsvetenskapsakademiens Handlingar\nNr 151, 1939, Generalstabens Litografiska Anstalts Forlag, Stockholm.\n\nWaloddi Weibull, \u201cA Statistical Distribution Function of Wide Applicability\u201d,\nJournal Of Applied Mechanics ASME Paper 1951.\n\nWikipedia, \u201cWeibull distribution\u201d,\nhttps://en.wikipedia.org/wiki/Weibull_distribution\n\nDraw samples from the distribution:\n\nDisplay the histogram of the samples, along with the probability density\nfunction:\n\n"}, {"name": "random.Generator.zipf()", "path": "reference/random/generated/numpy.random.generator.zipf", "type": "numpy.random.Generator.zipf", "text": "\nmethod\n\nDraw samples from a Zipf distribution.\n\nSamples are drawn from a Zipf distribution with specified parameter `a` > 1.\n\nThe Zipf distribution (also known as the zeta distribution) is a discrete\nprobability distribution that satisfies Zipf\u2019s law: the frequency of an item\nis inversely proportional to its rank in a frequency table.\n\nDistribution parameter. Must be greater than 1.\n\nOutput shape. If the given shape is, e.g., `(m, n, k)`, then `m * n * k`\nsamples are drawn. If size is `None` (default), a single value is returned if\n`a` is a scalar. Otherwise, `np.array(a).size` samples are drawn.\n\nDrawn samples from the parameterized Zipf distribution.\n\nSee also\n\nprobability density function, distribution, or cumulative density function,\netc.\n\nThe probability density for the Zipf distribution is\n\nfor integers \\\\(k \\geq 1\\\\), where \\\\(\\zeta\\\\) is the Riemann Zeta function.\n\nIt is named for the American linguist George Kingsley Zipf, who noted that the\nfrequency of any word in a sample of a language is inversely proportional to\nits rank in the frequency table.\n\nZipf, G. K., \u201cSelected Studies of the Principle of Relative Frequency in\nLanguage,\u201d Cambridge, MA: Harvard Univ. Press, 1932.\n\nDraw samples from the distribution:\n\nDisplay the histogram of the samples, along with the expected histogram based\non the probability density function:\n\n`bincount` provides a fast histogram for small integers.\n\n"}, {"name": "random.geometric()", "path": "reference/random/generated/numpy.random.geometric", "type": "numpy.random.geometric", "text": "\nDraw samples from the geometric distribution.\n\nBernoulli trials are experiments with one of two outcomes: success or failure\n(an example of such an experiment is flipping a coin). The geometric\ndistribution models the number of trials that must be run in order to achieve\nsuccess. It is therefore supported on the positive integers, `k = 1, 2, ...`.\n\nThe probability mass function of the geometric distribution is\n\nwhere `p` is the probability of success of an individual trial.\n\nNote\n\nNew code should use the `geometric` method of a `default_rng()` instance\ninstead; please see the Quick Start.\n\nThe probability of success of an individual trial.\n\nOutput shape. If the given shape is, e.g., `(m, n, k)`, then `m * n * k`\nsamples are drawn. If size is `None` (default), a single value is returned if\n`p` is a scalar. Otherwise, `np.array(p).size` samples are drawn.\n\nDrawn samples from the parameterized geometric distribution.\n\nSee also\n\nwhich should be used for new code.\n\nDraw ten thousand values from the geometric distribution, with the probability\nof an individual success equal to 0.35:\n\nHow many trials succeeded after a single run?\n\n"}, {"name": "random.get_state()", "path": "reference/random/generated/numpy.random.get_state", "type": "numpy.random.get_state", "text": "\nReturn a tuple representing the internal state of the generator.\n\nFor more details, see `set_state`.\n\nFlag indicating to return a legacy tuple state when the BitGenerator is\nMT19937, instead of a dict.\n\nThe returned tuple has the following items:\n\nIf `legacy` is False, or the BitGenerator is not MT19937, then state is\nreturned as a dictionary.\n\nSee also\n\n`set_state` and `get_state` are not needed to work with any of the random\ndistributions in NumPy. If the internal state is manually altered, the user\nshould know exactly what he/she is doing.\n\n"}, {"name": "random.gumbel()", "path": "reference/random/generated/numpy.random.gumbel", "type": "numpy.random.gumbel", "text": "\nDraw samples from a Gumbel distribution.\n\nDraw samples from a Gumbel distribution with specified location and scale. For\nmore information on the Gumbel distribution, see Notes and References below.\n\nNote\n\nNew code should use the `gumbel` method of a `default_rng()` instance instead;\nplease see the Quick Start.\n\nThe location of the mode of the distribution. Default is 0.\n\nThe scale parameter of the distribution. Default is 1. Must be non- negative.\n\nOutput shape. If the given shape is, e.g., `(m, n, k)`, then `m * n * k`\nsamples are drawn. If size is `None` (default), a single value is returned if\n`loc` and `scale` are both scalars. Otherwise, `np.broadcast(loc, scale).size`\nsamples are drawn.\n\nDrawn samples from the parameterized Gumbel distribution.\n\nSee also\n\nwhich should be used for new code.\n\nThe Gumbel (or Smallest Extreme Value (SEV) or the Smallest Extreme Value Type\nI) distribution is one of a class of Generalized Extreme Value (GEV)\ndistributions used in modeling extreme value problems. The Gumbel is a special\ncase of the Extreme Value Type I distribution for maximums from distributions\nwith \u201cexponential-like\u201d tails.\n\nThe probability density for the Gumbel distribution is\n\nwhere \\\\(\\mu\\\\) is the mode, a location parameter, and \\\\(\\beta\\\\) is the\nscale parameter.\n\nThe Gumbel (named for German mathematician Emil Julius Gumbel) was used very\nearly in the hydrology literature, for modeling the occurrence of flood\nevents. It is also used for modeling maximum wind speed and rainfall rates. It\nis a \u201cfat-tailed\u201d distribution - the probability of an event in the tail of\nthe distribution is larger than if one used a Gaussian, hence the surprisingly\nfrequent occurrence of 100-year floods. Floods were initially modeled as a\nGaussian process, which underestimated the frequency of extreme events.\n\nIt is one of a class of extreme value distributions, the Generalized Extreme\nValue (GEV) distributions, which also includes the Weibull and Frechet.\n\nThe function has a mean of \\\\(\\mu + 0.57721\\beta\\\\) and a variance of\n\\\\(\\frac{\\pi^2}{6}\\beta^2\\\\).\n\nGumbel, E. J., \u201cStatistics of Extremes,\u201d New York: Columbia University Press,\n1958.\n\nReiss, R.-D. and Thomas, M., \u201cStatistical Analysis of Extreme Values from\nInsurance, Finance, Hydrology and Other Fields,\u201d Basel: Birkhauser Verlag,\n2001.\n\nDraw samples from the distribution:\n\nDisplay the histogram of the samples, along with the probability density\nfunction:\n\nShow how an extreme value distribution can arise from a Gaussian process and\ncompare to a Gaussian:\n\n"}, {"name": "random.hypergeometric()", "path": "reference/random/generated/numpy.random.hypergeometric", "type": "numpy.random.hypergeometric", "text": "\nDraw samples from a Hypergeometric distribution.\n\nSamples are drawn from a hypergeometric distribution with specified\nparameters, `ngood` (ways to make a good selection), `nbad` (ways to make a\nbad selection), and `nsample` (number of items sampled, which is less than or\nequal to the sum `ngood + nbad`).\n\nNote\n\nNew code should use the `hypergeometric` method of a `default_rng()` instance\ninstead; please see the Quick Start.\n\nNumber of ways to make a good selection. Must be nonnegative.\n\nNumber of ways to make a bad selection. Must be nonnegative.\n\nNumber of items sampled. Must be at least 1 and at most `ngood + nbad`.\n\nOutput shape. If the given shape is, e.g., `(m, n, k)`, then `m * n * k`\nsamples are drawn. If size is `None` (default), a single value is returned if\n`ngood`, `nbad`, and `nsample` are all scalars. Otherwise,\n`np.broadcast(ngood, nbad, nsample).size` samples are drawn.\n\nDrawn samples from the parameterized hypergeometric distribution. Each sample\nis the number of good items within a randomly selected subset of size\n`nsample` taken from a set of `ngood` good items and `nbad` bad items.\n\nSee also\n\nprobability density function, distribution or cumulative density function,\netc.\n\nwhich should be used for new code.\n\nThe probability density for the Hypergeometric distribution is\n\nwhere \\\\(0 \\le x \\le n\\\\) and \\\\(n-b \\le x \\le g\\\\)\n\nfor P(x) the probability of `x` good results in the drawn sample, g = `ngood`,\nb = `nbad`, and n = `nsample`.\n\nConsider an urn with black and white marbles in it, `ngood` of them are black\nand `nbad` are white. If you draw `nsample` balls without replacement, then\nthe hypergeometric distribution describes the distribution of black balls in\nthe drawn sample.\n\nNote that this distribution is very similar to the binomial distribution,\nexcept that in this case, samples are drawn without replacement, whereas in\nthe Binomial case samples are drawn with replacement (or the sample space is\ninfinite). As the sample space becomes large, this distribution approaches the\nbinomial.\n\nLentner, Marvin, \u201cElementary Applied Statistics\u201d, Bogden and Quigley, 1972.\n\nWeisstein, Eric W. \u201cHypergeometric Distribution.\u201d From MathWorld\u2013A Wolfram Web\nResource. http://mathworld.wolfram.com/HypergeometricDistribution.html\n\nWikipedia, \u201cHypergeometric distribution\u201d,\nhttps://en.wikipedia.org/wiki/Hypergeometric_distribution\n\nDraw samples from the distribution:\n\nSuppose you have an urn with 15 white and 15 black marbles. If you pull 15\nmarbles at random, how likely is it that 12 or more of them are one color?\n\n"}, {"name": "random.laplace()", "path": "reference/random/generated/numpy.random.laplace", "type": "numpy.random.laplace", "text": "\nDraw samples from the Laplace or double exponential distribution with\nspecified location (or mean) and scale (decay).\n\nThe Laplace distribution is similar to the Gaussian/normal distribution, but\nis sharper at the peak and has fatter tails. It represents the difference\nbetween two independent, identically distributed exponential random variables.\n\nNote\n\nNew code should use the `laplace` method of a `default_rng()` instance\ninstead; please see the Quick Start.\n\nThe position, \\\\(\\mu\\\\), of the distribution peak. Default is 0.\n\n\\\\(\\lambda\\\\), the exponential decay. Default is 1. Must be non- negative.\n\nOutput shape. If the given shape is, e.g., `(m, n, k)`, then `m * n * k`\nsamples are drawn. If size is `None` (default), a single value is returned if\n`loc` and `scale` are both scalars. Otherwise, `np.broadcast(loc, scale).size`\nsamples are drawn.\n\nDrawn samples from the parameterized Laplace distribution.\n\nSee also\n\nwhich should be used for new code.\n\nIt has the probability density function\n\nThe first law of Laplace, from 1774, states that the frequency of an error can\nbe expressed as an exponential function of the absolute magnitude of the\nerror, which leads to the Laplace distribution. For many problems in economics\nand health sciences, this distribution seems to model the data better than the\nstandard Gaussian distribution.\n\nAbramowitz, M. and Stegun, I. A. (Eds.). \u201cHandbook of Mathematical Functions\nwith Formulas, Graphs, and Mathematical Tables, 9th printing,\u201d New York:\nDover, 1972.\n\nKotz, Samuel, et. al. \u201cThe Laplace Distribution and Generalizations, \u201d\nBirkhauser, 2001.\n\nWeisstein, Eric W. \u201cLaplace Distribution.\u201d From MathWorld\u2013A Wolfram Web\nResource. http://mathworld.wolfram.com/LaplaceDistribution.html\n\nWikipedia, \u201cLaplace distribution\u201d,\nhttps://en.wikipedia.org/wiki/Laplace_distribution\n\nDraw samples from the distribution\n\nDisplay the histogram of the samples, along with the probability density\nfunction:\n\nPlot Gaussian for comparison:\n\n"}, {"name": "random.logistic()", "path": "reference/random/generated/numpy.random.logistic", "type": "numpy.random.logistic", "text": "\nDraw samples from a logistic distribution.\n\nSamples are drawn from a logistic distribution with specified parameters, loc\n(location or mean, also median), and scale (>0).\n\nNote\n\nNew code should use the `logistic` method of a `default_rng()` instance\ninstead; please see the Quick Start.\n\nParameter of the distribution. Default is 0.\n\nParameter of the distribution. Must be non-negative. Default is 1.\n\nOutput shape. If the given shape is, e.g., `(m, n, k)`, then `m * n * k`\nsamples are drawn. If size is `None` (default), a single value is returned if\n`loc` and `scale` are both scalars. Otherwise, `np.broadcast(loc, scale).size`\nsamples are drawn.\n\nDrawn samples from the parameterized logistic distribution.\n\nSee also\n\nprobability density function, distribution or cumulative density function,\netc.\n\nwhich should be used for new code.\n\nThe probability density for the Logistic distribution is\n\nwhere \\\\(\\mu\\\\) = location and \\\\(s\\\\) = scale.\n\nThe Logistic distribution is used in Extreme Value problems where it can act\nas a mixture of Gumbel distributions, in Epidemiology, and by the World Chess\nFederation (FIDE) where it is used in the Elo ranking system, assuming the\nperformance of each player is a logistically distributed random variable.\n\nReiss, R.-D. and Thomas M. (2001), \u201cStatistical Analysis of Extreme Values,\nfrom Insurance, Finance, Hydrology and Other Fields,\u201d Birkhauser Verlag,\nBasel, pp 132-133.\n\nWeisstein, Eric W. \u201cLogistic Distribution.\u201d From MathWorld\u2013A Wolfram Web\nResource. http://mathworld.wolfram.com/LogisticDistribution.html\n\nWikipedia, \u201cLogistic-distribution\u201d,\nhttps://en.wikipedia.org/wiki/Logistic_distribution\n\nDraw samples from the distribution:\n\n# plot against distribution\n\n"}, {"name": "random.lognormal()", "path": "reference/random/generated/numpy.random.lognormal", "type": "numpy.random.lognormal", "text": "\nDraw samples from a log-normal distribution.\n\nDraw samples from a log-normal distribution with specified mean, standard\ndeviation, and array shape. Note that the mean and standard deviation are not\nthe values for the distribution itself, but of the underlying normal\ndistribution it is derived from.\n\nNote\n\nNew code should use the `lognormal` method of a `default_rng()` instance\ninstead; please see the Quick Start.\n\nMean value of the underlying normal distribution. Default is 0.\n\nStandard deviation of the underlying normal distribution. Must be non-\nnegative. Default is 1.\n\nOutput shape. If the given shape is, e.g., `(m, n, k)`, then `m * n * k`\nsamples are drawn. If size is `None` (default), a single value is returned if\n`mean` and `sigma` are both scalars. Otherwise, `np.broadcast(mean,\nsigma).size` samples are drawn.\n\nDrawn samples from the parameterized log-normal distribution.\n\nSee also\n\nprobability density function, distribution, cumulative density function, etc.\n\nwhich should be used for new code.\n\nA variable `x` has a log-normal distribution if `log(x)` is normally\ndistributed. The probability density function for the log-normal distribution\nis:\n\nwhere \\\\(\\mu\\\\) is the mean and \\\\(\\sigma\\\\) is the standard deviation of the\nnormally distributed logarithm of the variable. A log-normal distribution\nresults if a random variable is the product of a large number of independent,\nidentically-distributed variables in the same way that a normal distribution\nresults if the variable is the sum of a large number of independent,\nidentically-distributed variables.\n\nLimpert, E., Stahel, W. A., and Abbt, M., \u201cLog-normal Distributions across the\nSciences: Keys and Clues,\u201d BioScience, Vol. 51, No. 5, May, 2001.\nhttps://stat.ethz.ch/~stahel/lognormal/bioscience.pdf\n\nReiss, R.D. and Thomas, M., \u201cStatistical Analysis of Extreme Values,\u201d Basel:\nBirkhauser Verlag, 2001, pp. 31-32.\n\nDraw samples from the distribution:\n\nDisplay the histogram of the samples, along with the probability density\nfunction:\n\nDemonstrate that taking the products of random samples from a uniform\ndistribution can be fit well by a log-normal probability density function.\n\n"}, {"name": "random.logseries()", "path": "reference/random/generated/numpy.random.logseries", "type": "numpy.random.logseries", "text": "\nDraw samples from a logarithmic series distribution.\n\nSamples are drawn from a log series distribution with specified shape\nparameter, 0 < `p` < 1.\n\nNote\n\nNew code should use the `logseries` method of a `default_rng()` instance\ninstead; please see the Quick Start.\n\nShape parameter for the distribution. Must be in the range (0, 1).\n\nOutput shape. If the given shape is, e.g., `(m, n, k)`, then `m * n * k`\nsamples are drawn. If size is `None` (default), a single value is returned if\n`p` is a scalar. Otherwise, `np.array(p).size` samples are drawn.\n\nDrawn samples from the parameterized logarithmic series distribution.\n\nSee also\n\nprobability density function, distribution or cumulative density function,\netc.\n\nwhich should be used for new code.\n\nThe probability density for the Log Series distribution is\n\nwhere p = probability.\n\nThe log series distribution is frequently used to represent species richness\nand occurrence, first proposed by Fisher, Corbet, and Williams in 1943 [2]. It\nmay also be used to model the numbers of occupants seen in cars [3].\n\nBuzas, Martin A.; Culver, Stephen J., Understanding regional species diversity\nthrough the log series distribution of occurrences: BIODIVERSITY RESEARCH\nDiversity & Distributions, Volume 5, Number 5, September 1999 , pp.\n187-195(9).\n\nFisher, R.A,, A.S. Corbet, and C.B. Williams. 1943. The relation between the\nnumber of species and the number of individuals in a random sample of an\nanimal population. Journal of Animal Ecology, 12:42-58.\n\nD. J. Hand, F. Daly, D. Lunn, E. Ostrowski, A Handbook of Small Data Sets, CRC\nPress, 1994.\n\nWikipedia, \u201cLogarithmic distribution\u201d,\nhttps://en.wikipedia.org/wiki/Logarithmic_distribution\n\nDraw samples from the distribution:\n\n# plot against distribution\n\n"}, {"name": "random.MT19937.cffi", "path": "reference/random/bit_generators/generated/numpy.random.mt19937.cffi", "type": "MT19937", "text": "\nattribute\n\nCFFI interface\n\nNamed tuple containing CFFI wrapper\n\n"}, {"name": "random.MT19937.ctypes", "path": "reference/random/bit_generators/generated/numpy.random.mt19937.ctypes", "type": "MT19937", "text": "\nattribute\n\nctypes interface\n\nNamed tuple containing ctypes wrapper\n\n"}, {"name": "random.MT19937.jumped()", "path": "reference/random/bit_generators/generated/numpy.random.mt19937.jumped", "type": "MT19937", "text": "\nmethod\n\nReturns a new bit generator with the state jumped\n\nThe state of the returned big generator is jumped as-if 2**(128 * jumps)\nrandom numbers have been generated.\n\nNumber of times to jump the state of the bit generator returned\n\nNew instance of generator jumped iter times\n\nThe jump step is computed using a modified version of Matsumoto\u2019s\nimplementation of Horner\u2019s method. The step polynomial is precomputed to\nperform 2**128 steps. The jumped state has been verified to match the state\nproduced using Matsumoto\u2019s original code.\n\nMatsumoto, M, Generating multiple disjoint streams of pseudorandom number\nsequences. Accessed on: May 6, 2020.\nhttp://www.math.sci.hiroshima-u.ac.jp/~m-mat/MT/JUMP/\n\nHiroshi Haramoto, Makoto Matsumoto, Takuji Nishimura, Fran\u00e7ois Panneton,\nPierre L\u2019Ecuyer, \u201cEfficient Jump Ahead for F2-Linear Random Number\nGenerators\u201d, INFORMS JOURNAL ON COMPUTING, Vol. 20, No. 3, Summer 2008, pp.\n385-390.\n\n"}, {"name": "random.MT19937.state", "path": "reference/random/bit_generators/generated/numpy.random.mt19937.state", "type": "MT19937", "text": "\nattribute\n\nGet or set the PRNG state\n\nDictionary containing the information required to describe the state of the\nPRNG\n\n"}, {"name": "random.multinomial()", "path": "reference/random/generated/numpy.random.multinomial", "type": "numpy.random.multinomial", "text": "\nDraw samples from a multinomial distribution.\n\nThe multinomial distribution is a multivariate generalization of the binomial\ndistribution. Take an experiment with one of `p` possible outcomes. An example\nof such an experiment is throwing a dice, where the outcome can be 1 through\n6. Each sample drawn from the distribution represents `n` such experiments.\nIts values, `X_i = [X_0, X_1, ..., X_p]`, represent the number of times the\noutcome was `i`.\n\nNote\n\nNew code should use the `multinomial` method of a `default_rng()` instance\ninstead; please see the Quick Start.\n\nNumber of experiments.\n\nProbabilities of each of the `p` different outcomes. These must sum to 1\n(however, the last element is always assumed to account for the remaining\nprobability, as long as `sum(pvals[:-1]) <= 1)`.\n\nOutput shape. If the given shape is, e.g., `(m, n, k)`, then `m * n * k`\nsamples are drawn. Default is None, in which case a single value is returned.\n\nThe drawn samples, of shape size, if that was provided. If not, the shape is\n`(N,)`.\n\nIn other words, each entry `out[i,j,...,:]` is an N-dimensional value drawn\nfrom the distribution.\n\nSee also\n\nwhich should be used for new code.\n\nThrow a dice 20 times:\n\nIt landed 4 times on 1, once on 2, etc.\n\nNow, throw the dice 20 times, and 20 times again:\n\nFor the first run, we threw 3 times 1, 4 times 2, etc. For the second, we\nthrew 2 times 1, 4 times 2, etc.\n\nA loaded die is more likely to land on number 6:\n\nThe probability inputs should be normalized. As an implementation detail, the\nvalue of the last entry is ignored and assumed to take up any leftover\nprobability mass, but this should not be relied on. A biased coin which has\ntwice as much weight on one side as on the other should be sampled like so:\n\nnot like:\n\n"}, {"name": "random.multivariate_normal()", "path": "reference/random/generated/numpy.random.multivariate_normal", "type": "numpy.random.multivariate_normal", "text": "\nDraw random samples from a multivariate normal distribution.\n\nThe multivariate normal, multinormal or Gaussian distribution is a\ngeneralization of the one-dimensional normal distribution to higher\ndimensions. Such a distribution is specified by its mean and covariance\nmatrix. These parameters are analogous to the mean (average or \u201ccenter\u201d) and\nvariance (standard deviation, or \u201cwidth,\u201d squared) of the one-dimensional\nnormal distribution.\n\nNote\n\nNew code should use the `multivariate_normal` method of a `default_rng()`\ninstance instead; please see the Quick Start.\n\nMean of the N-dimensional distribution.\n\nCovariance matrix of the distribution. It must be symmetric and positive-\nsemidefinite for proper sampling.\n\nGiven a shape of, for example, `(m,n,k)`, `m*n*k` samples are generated, and\npacked in an `m`-by-`n`-by-`k` arrangement. Because each sample is\n`N`-dimensional, the output shape is `(m,n,k,N)`. If no shape is specified, a\nsingle (`N`-D) sample is returned.\n\nBehavior when the covariance matrix is not positive semidefinite.\n\nTolerance when checking the singular values in covariance matrix. cov is cast\nto double before the check.\n\nThe drawn samples, of shape size, if that was provided. If not, the shape is\n`(N,)`.\n\nIn other words, each entry `out[i,j,...,:]` is an N-dimensional value drawn\nfrom the distribution.\n\nSee also\n\nwhich should be used for new code.\n\nThe mean is a coordinate in N-dimensional space, which represents the location\nwhere samples are most likely to be generated. This is analogous to the peak\nof the bell curve for the one-dimensional or univariate normal distribution.\n\nCovariance indicates the level to which two variables vary together. From the\nmultivariate normal distribution, we draw N-dimensional samples, \\\\(X = [x_1,\nx_2, ... x_N]\\\\). The covariance matrix element \\\\(C_{ij}\\\\) is the covariance\nof \\\\(x_i\\\\) and \\\\(x_j\\\\). The element \\\\(C_{ii}\\\\) is the variance of\n\\\\(x_i\\\\) (i.e. its \u201cspread\u201d).\n\nInstead of specifying the full covariance matrix, popular approximations\ninclude:\n\nThis geometrical property can be seen in two dimensions by plotting generated\ndata-points:\n\nDiagonal covariance means that points are oriented along x or y-axis:\n\nNote that the covariance matrix must be positive semidefinite (a.k.a.\nnonnegative-definite). Otherwise, the behavior of this method is undefined and\nbackwards compatibility is not guaranteed.\n\nPapoulis, A., \u201cProbability, Random Variables, and Stochastic Processes,\u201d 3rd\ned., New York: McGraw-Hill, 1991.\n\nDuda, R. O., Hart, P. E., and Stork, D. G., \u201cPattern Classification,\u201d 2nd ed.,\nNew York: Wiley, 2001.\n\nThe following is probably true, given that 0.6 is roughly twice the standard\ndeviation:\n\n"}, {"name": "random.negative_binomial()", "path": "reference/random/generated/numpy.random.negative_binomial", "type": "numpy.random.negative_binomial", "text": "\nDraw samples from a negative binomial distribution.\n\nSamples are drawn from a negative binomial distribution with specified\nparameters, `n` successes and `p` probability of success where `n` is > 0 and\n`p` is in the interval [0, 1].\n\nNote\n\nNew code should use the `negative_binomial` method of a `default_rng()`\ninstance instead; please see the Quick Start.\n\nParameter of the distribution, > 0.\n\nParameter of the distribution, >= 0 and <=1.\n\nOutput shape. If the given shape is, e.g., `(m, n, k)`, then `m * n * k`\nsamples are drawn. If size is `None` (default), a single value is returned if\n`n` and `p` are both scalars. Otherwise, `np.broadcast(n, p).size` samples are\ndrawn.\n\nDrawn samples from the parameterized negative binomial distribution, where\neach sample is equal to N, the number of failures that occurred before a total\nof n successes was reached.\n\nSee also\n\nwhich should be used for new code.\n\nThe probability mass function of the negative binomial distribution is\n\nwhere \\\\(n\\\\) is the number of successes, \\\\(p\\\\) is the probability of\nsuccess, \\\\(N+n\\\\) is the number of trials, and \\\\(\\Gamma\\\\) is the gamma\nfunction. When \\\\(n\\\\) is an integer, \\\\(\\frac{\\Gamma(N+n)}{N!\\Gamma(n)} =\n\\binom{N+n-1}{N}\\\\), which is the more common form of this term in the the\npmf. The negative binomial distribution gives the probability of N failures\ngiven n successes, with a success on the last trial.\n\nIf one throws a die repeatedly until the third time a \u201c1\u201d appears, then the\nprobability distribution of the number of non-\u201c1\u201ds that appear before the\nthird \u201c1\u201d is a negative binomial distribution.\n\nWeisstein, Eric W. \u201cNegative Binomial Distribution.\u201d From MathWorld\u2013A Wolfram\nWeb Resource. http://mathworld.wolfram.com/NegativeBinomialDistribution.html\n\nWikipedia, \u201cNegative binomial distribution\u201d,\nhttps://en.wikipedia.org/wiki/Negative_binomial_distribution\n\nDraw samples from the distribution:\n\nA real world example. A company drills wild-cat oil exploration wells, each\nwith an estimated probability of success of 0.1. What is the probability of\nhaving one success for each successive well, that is what is the probability\nof a single success after drilling 5 wells, after 6 wells, etc.?\n\n"}, {"name": "random.noncentral_chisquare()", "path": "reference/random/generated/numpy.random.noncentral_chisquare", "type": "numpy.random.noncentral_chisquare", "text": "\nDraw samples from a noncentral chi-square distribution.\n\nThe noncentral \\\\(\\chi^2\\\\) distribution is a generalization of the\n\\\\(\\chi^2\\\\) distribution.\n\nNote\n\nNew code should use the `noncentral_chisquare` method of a `default_rng()`\ninstance instead; please see the Quick Start.\n\nDegrees of freedom, must be > 0.\n\nChanged in version 1.10.0: Earlier NumPy versions required dfnum > 1.\n\nNon-centrality, must be non-negative.\n\nOutput shape. If the given shape is, e.g., `(m, n, k)`, then `m * n * k`\nsamples are drawn. If size is `None` (default), a single value is returned if\n`df` and `nonc` are both scalars. Otherwise, `np.broadcast(df, nonc).size`\nsamples are drawn.\n\nDrawn samples from the parameterized noncentral chi-square distribution.\n\nSee also\n\nwhich should be used for new code.\n\nThe probability density function for the noncentral Chi-square distribution is\n\nwhere \\\\(Y_{q}\\\\) is the Chi-square with q degrees of freedom.\n\nWikipedia, \u201cNoncentral chi-squared distribution\u201d\nhttps://en.wikipedia.org/wiki/Noncentral_chi-squared_distribution\n\nDraw values from the distribution and plot the histogram\n\nDraw values from a noncentral chisquare with very small noncentrality, and\ncompare to a chisquare.\n\nDemonstrate how large values of non-centrality lead to a more symmetric\ndistribution.\n\n"}, {"name": "random.noncentral_f()", "path": "reference/random/generated/numpy.random.noncentral_f", "type": "numpy.random.noncentral_f", "text": "\nDraw samples from the noncentral F distribution.\n\nSamples are drawn from an F distribution with specified parameters, `dfnum`\n(degrees of freedom in numerator) and `dfden` (degrees of freedom in\ndenominator), where both parameters > 1\\. `nonc` is the non-centrality\nparameter.\n\nNote\n\nNew code should use the `noncentral_f` method of a `default_rng()` instance\ninstead; please see the Quick Start.\n\nNumerator degrees of freedom, must be > 0.\n\nChanged in version 1.14.0: Earlier NumPy versions required dfnum > 1.\n\nDenominator degrees of freedom, must be > 0.\n\nNon-centrality parameter, the sum of the squares of the numerator means, must\nbe >= 0.\n\nOutput shape. If the given shape is, e.g., `(m, n, k)`, then `m * n * k`\nsamples are drawn. If size is `None` (default), a single value is returned if\n`dfnum`, `dfden`, and `nonc` are all scalars. Otherwise, `np.broadcast(dfnum,\ndfden, nonc).size` samples are drawn.\n\nDrawn samples from the parameterized noncentral Fisher distribution.\n\nSee also\n\nwhich should be used for new code.\n\nWhen calculating the power of an experiment (power = probability of rejecting\nthe null hypothesis when a specific alternative is true) the non-central F\nstatistic becomes important. When the null hypothesis is true, the F statistic\nfollows a central F distribution. When the null hypothesis is not true, then\nit follows a non-central F statistic.\n\nWeisstein, Eric W. \u201cNoncentral F-Distribution.\u201d From MathWorld\u2013A Wolfram Web\nResource. http://mathworld.wolfram.com/NoncentralF-Distribution.html\n\nWikipedia, \u201cNoncentral F-distribution\u201d,\nhttps://en.wikipedia.org/wiki/Noncentral_F-distribution\n\nIn a study, testing for a specific alternative to the null hypothesis requires\nuse of the Noncentral F distribution. We need to calculate the area in the\ntail of the distribution that exceeds the value of the F distribution for the\nnull hypothesis. We\u2019ll plot the two probability distributions for comparison.\n\n"}, {"name": "random.normal()", "path": "reference/random/generated/numpy.random.normal", "type": "numpy.random.normal", "text": "\nDraw random samples from a normal (Gaussian) distribution.\n\nThe probability density function of the normal distribution, first derived by\nDe Moivre and 200 years later by both Gauss and Laplace independently [2], is\noften called the bell curve because of its characteristic shape (see the\nexample below).\n\nThe normal distributions occurs often in nature. For example, it describes the\ncommonly occurring distribution of samples influenced by a large number of\ntiny, random disturbances, each with its own unique distribution [2].\n\nNote\n\nNew code should use the `normal` method of a `default_rng()` instance instead;\nplease see the Quick Start.\n\nMean (\u201ccentre\u201d) of the distribution.\n\nStandard deviation (spread or \u201cwidth\u201d) of the distribution. Must be non-\nnegative.\n\nOutput shape. If the given shape is, e.g., `(m, n, k)`, then `m * n * k`\nsamples are drawn. If size is `None` (default), a single value is returned if\n`loc` and `scale` are both scalars. Otherwise, `np.broadcast(loc, scale).size`\nsamples are drawn.\n\nDrawn samples from the parameterized normal distribution.\n\nSee also\n\nprobability density function, distribution or cumulative density function,\netc.\n\nwhich should be used for new code.\n\nThe probability density for the Gaussian distribution is\n\nwhere \\\\(\\mu\\\\) is the mean and \\\\(\\sigma\\\\) the standard deviation. The\nsquare of the standard deviation, \\\\(\\sigma^2\\\\), is called the variance.\n\nThe function has its peak at the mean, and its \u201cspread\u201d increases with the\nstandard deviation (the function reaches 0.607 times its maximum at \\\\(x +\n\\sigma\\\\) and \\\\(x - \\sigma\\\\) [2]). This implies that normal is more likely\nto return samples lying close to the mean, rather than those far away.\n\nWikipedia, \u201cNormal distribution\u201d,\nhttps://en.wikipedia.org/wiki/Normal_distribution\n\nP. R. Peebles Jr., \u201cCentral Limit Theorem\u201d in \u201cProbability, Random Variables\nand Random Signal Principles\u201d, 4th ed., 2001, pp. 51, 51, 125.\n\nDraw samples from the distribution:\n\nVerify the mean and the variance:\n\nDisplay the histogram of the samples, along with the probability density\nfunction:\n\nTwo-by-four array of samples from N(3, 6.25):\n\n"}, {"name": "random.pareto()", "path": "reference/random/generated/numpy.random.pareto", "type": "numpy.random.pareto", "text": "\nDraw samples from a Pareto II or Lomax distribution with specified shape.\n\nThe Lomax or Pareto II distribution is a shifted Pareto distribution. The\nclassical Pareto distribution can be obtained from the Lomax distribution by\nadding 1 and multiplying by the scale parameter `m` (see Notes). The smallest\nvalue of the Lomax distribution is zero while for the classical Pareto\ndistribution it is `mu`, where the standard Pareto distribution has location\n`mu = 1`. Lomax can also be considered as a simplified version of the\nGeneralized Pareto distribution (available in SciPy), with the scale set to\none and the location set to zero.\n\nThe Pareto distribution must be greater than zero, and is unbounded above. It\nis also known as the \u201c80-20 rule\u201d. In this distribution, 80 percent of the\nweights are in the lowest 20 percent of the range, while the other 20 percent\nfill the remaining 80 percent of the range.\n\nNote\n\nNew code should use the `pareto` method of a `default_rng()` instance instead;\nplease see the Quick Start.\n\nShape of the distribution. Must be positive.\n\nOutput shape. If the given shape is, e.g., `(m, n, k)`, then `m * n * k`\nsamples are drawn. If size is `None` (default), a single value is returned if\n`a` is a scalar. Otherwise, `np.array(a).size` samples are drawn.\n\nDrawn samples from the parameterized Pareto distribution.\n\nSee also\n\nprobability density function, distribution or cumulative density function,\netc.\n\nprobability density function, distribution or cumulative density function,\netc.\n\nwhich should be used for new code.\n\nThe probability density for the Pareto distribution is\n\nwhere \\\\(a\\\\) is the shape and \\\\(m\\\\) the scale.\n\nThe Pareto distribution, named after the Italian economist Vilfredo Pareto, is\na power law probability distribution useful in many real world problems.\nOutside the field of economics it is generally referred to as the Bradford\ndistribution. Pareto developed the distribution to describe the distribution\nof wealth in an economy. It has also found use in insurance, web page access\nstatistics, oil field sizes, and many other problems, including the download\nfrequency for projects in Sourceforge [1]. It is one of the so-called \u201cfat-\ntailed\u201d distributions.\n\nFrancis Hunt and Paul Johnson, On the Pareto Distribution of Sourceforge\nprojects.\n\nPareto, V. (1896). Course of Political Economy. Lausanne.\n\nReiss, R.D., Thomas, M.(2001), Statistical Analysis of Extreme Values,\nBirkhauser Verlag, Basel, pp 23-30.\n\nWikipedia, \u201cPareto distribution\u201d,\nhttps://en.wikipedia.org/wiki/Pareto_distribution\n\nDraw samples from the distribution:\n\nDisplay the histogram of the samples, along with the probability density\nfunction:\n\n"}, {"name": "random.PCG64.advance()", "path": "reference/random/bit_generators/generated/numpy.random.pcg64.advance", "type": "PCG64", "text": "\nmethod\n\nAdvance the underlying RNG as-if delta draws have occurred.\n\nNumber of draws to advance the RNG. Must be less than the size state variable\nin the underlying RNG.\n\nRNG advanced delta steps\n\nAdvancing a RNG updates the underlying RNG state as-if a given number of calls\nto the underlying RNG have been made. In general there is not a one-to-one\nrelationship between the number output random values from a particular\ndistribution and the number of draws from the core RNG. This occurs for two\nreasons:\n\nAdvancing the RNG state resets any pre-computed random numbers. This is\nrequired to ensure exact reproducibility.\n\n"}, {"name": "random.PCG64.cffi", "path": "reference/random/bit_generators/generated/numpy.random.pcg64.cffi", "type": "PCG64", "text": "\nattribute\n\nCFFI interface\n\nNamed tuple containing CFFI wrapper\n\n"}, {"name": "random.PCG64.ctypes", "path": "reference/random/bit_generators/generated/numpy.random.pcg64.ctypes", "type": "PCG64", "text": "\nattribute\n\nctypes interface\n\nNamed tuple containing ctypes wrapper\n\n"}, {"name": "random.PCG64.jumped()", "path": "reference/random/bit_generators/generated/numpy.random.pcg64.jumped", "type": "PCG64", "text": "\nmethod\n\nReturns a new bit generator with the state jumped.\n\nJumps the state as-if jumps * 210306068529402873165736369884012333109 random\nnumbers have been generated.\n\nNumber of times to jump the state of the bit generator returned\n\nNew instance of generator jumped iter times\n\nThe step size is phi-1 when multiplied by 2**128 where phi is the golden\nratio.\n\n"}, {"name": "random.PCG64.state", "path": "reference/random/bit_generators/generated/numpy.random.pcg64.state", "type": "PCG64", "text": "\nattribute\n\nGet or set the PRNG state\n\nDictionary containing the information required to describe the state of the\nPRNG\n\n"}, {"name": "random.PCG64DXSM.advance()", "path": "reference/random/bit_generators/generated/numpy.random.pcg64dxsm.advance", "type": "PCG64DXSM", "text": "\nmethod\n\nAdvance the underlying RNG as-if delta draws have occurred.\n\nNumber of draws to advance the RNG. Must be less than the size state variable\nin the underlying RNG.\n\nRNG advanced delta steps\n\nAdvancing a RNG updates the underlying RNG state as-if a given number of calls\nto the underlying RNG have been made. In general there is not a one-to-one\nrelationship between the number output random values from a particular\ndistribution and the number of draws from the core RNG. This occurs for two\nreasons:\n\nAdvancing the RNG state resets any pre-computed random numbers. This is\nrequired to ensure exact reproducibility.\n\n"}, {"name": "random.PCG64DXSM.cffi", "path": "reference/random/bit_generators/generated/numpy.random.pcg64dxsm.cffi", "type": "PCG64DXSM", "text": "\nattribute\n\nCFFI interface\n\nNamed tuple containing CFFI wrapper\n\n"}, {"name": "random.PCG64DXSM.ctypes", "path": "reference/random/bit_generators/generated/numpy.random.pcg64dxsm.ctypes", "type": "PCG64DXSM", "text": "\nattribute\n\nctypes interface\n\nNamed tuple containing ctypes wrapper\n\n"}, {"name": "random.PCG64DXSM.jumped()", "path": "reference/random/bit_generators/generated/numpy.random.pcg64dxsm.jumped", "type": "PCG64DXSM", "text": "\nmethod\n\nReturns a new bit generator with the state jumped.\n\nJumps the state as-if jumps * 210306068529402873165736369884012333109 random\nnumbers have been generated.\n\nNumber of times to jump the state of the bit generator returned\n\nNew instance of generator jumped iter times\n\nThe step size is phi-1 when multiplied by 2**128 where phi is the golden\nratio.\n\n"}, {"name": "random.PCG64DXSM.state", "path": "reference/random/bit_generators/generated/numpy.random.pcg64dxsm.state", "type": "PCG64DXSM", "text": "\nattribute\n\nGet or set the PRNG state\n\nDictionary containing the information required to describe the state of the\nPRNG\n\n"}, {"name": "random.permutation()", "path": "reference/random/generated/numpy.random.permutation", "type": "numpy.random.permutation", "text": "\nRandomly permute a sequence, or return a permuted range.\n\nIf `x` is a multi-dimensional array, it is only shuffled along its first\nindex.\n\nNote\n\nNew code should use the `permutation` method of a `default_rng()` instance\ninstead; please see the Quick Start.\n\nIf `x` is an integer, randomly permute `np.arange(x)`. If `x` is an array,\nmake a copy and shuffle the elements randomly.\n\nPermuted sequence or array range.\n\nSee also\n\nwhich should be used for new code.\n\n"}, {"name": "random.Philox.advance()", "path": "reference/random/bit_generators/generated/numpy.random.philox.advance", "type": "Philox", "text": "\nmethod\n\nAdvance the underlying RNG as-if delta draws have occurred.\n\nNumber of draws to advance the RNG. Must be less than the size state variable\nin the underlying RNG.\n\nRNG advanced delta steps\n\nAdvancing a RNG updates the underlying RNG state as-if a given number of calls\nto the underlying RNG have been made. In general there is not a one-to-one\nrelationship between the number output random values from a particular\ndistribution and the number of draws from the core RNG. This occurs for two\nreasons:\n\nAdvancing the RNG state resets any pre-computed random numbers. This is\nrequired to ensure exact reproducibility.\n\n"}, {"name": "random.Philox.cffi", "path": "reference/random/bit_generators/generated/numpy.random.philox.cffi", "type": "Philox", "text": "\nattribute\n\nCFFI interface\n\nNamed tuple containing CFFI wrapper\n\n"}, {"name": "random.Philox.ctypes", "path": "reference/random/bit_generators/generated/numpy.random.philox.ctypes", "type": "Philox", "text": "\nattribute\n\nctypes interface\n\nNamed tuple containing ctypes wrapper\n\n"}, {"name": "random.Philox.jumped()", "path": "reference/random/bit_generators/generated/numpy.random.philox.jumped", "type": "Philox", "text": "\nmethod\n\nReturns a new bit generator with the state jumped\n\nThe state of the returned big generator is jumped as-if 2**(128 * jumps)\nrandom numbers have been generated.\n\nNumber of times to jump the state of the bit generator returned\n\nNew instance of generator jumped iter times\n\n"}, {"name": "random.Philox.state", "path": "reference/random/bit_generators/generated/numpy.random.philox.state", "type": "Philox", "text": "\nattribute\n\nGet or set the PRNG state\n\nDictionary containing the information required to describe the state of the\nPRNG\n\n"}, {"name": "random.poisson()", "path": "reference/random/generated/numpy.random.poisson", "type": "numpy.random.poisson", "text": "\nDraw samples from a Poisson distribution.\n\nThe Poisson distribution is the limit of the binomial distribution for large\nN.\n\nNote\n\nNew code should use the `poisson` method of a `default_rng()` instance\ninstead; please see the Quick Start.\n\nExpected number of events occurring in a fixed-time interval, must be >= 0. A\nsequence must be broadcastable over the requested size.\n\nOutput shape. If the given shape is, e.g., `(m, n, k)`, then `m * n * k`\nsamples are drawn. If size is `None` (default), a single value is returned if\n`lam` is a scalar. Otherwise, `np.array(lam).size` samples are drawn.\n\nDrawn samples from the parameterized Poisson distribution.\n\nSee also\n\nwhich should be used for new code.\n\nThe Poisson distribution\n\nFor events with an expected separation \\\\(\\lambda\\\\) the Poisson distribution\n\\\\(f(k; \\lambda)\\\\) describes the probability of \\\\(k\\\\) events occurring\nwithin the observed interval \\\\(\\lambda\\\\).\n\nBecause the output is limited to the range of the C int64 type, a ValueError\nis raised when `lam` is within 10 sigma of the maximum representable value.\n\nWeisstein, Eric W. \u201cPoisson Distribution.\u201d From MathWorld\u2013A Wolfram Web\nResource. http://mathworld.wolfram.com/PoissonDistribution.html\n\nWikipedia, \u201cPoisson distribution\u201d,\nhttps://en.wikipedia.org/wiki/Poisson_distribution\n\nDraw samples from the distribution:\n\nDisplay histogram of the sample:\n\nDraw each 100 values for lambda 100 and 500:\n\n"}, {"name": "random.power()", "path": "reference/random/generated/numpy.random.power", "type": "numpy.random.power", "text": "\nDraws samples in [0, 1] from a power distribution with positive exponent a -\n1.\n\nAlso known as the power function distribution.\n\nNote\n\nNew code should use the `power` method of a `default_rng()` instance instead;\nplease see the Quick Start.\n\nParameter of the distribution. Must be non-negative.\n\nOutput shape. If the given shape is, e.g., `(m, n, k)`, then `m * n * k`\nsamples are drawn. If size is `None` (default), a single value is returned if\n`a` is a scalar. Otherwise, `np.array(a).size` samples are drawn.\n\nDrawn samples from the parameterized power distribution.\n\nIf a <= 0.\n\nSee also\n\nwhich should be used for new code.\n\nThe probability density function is\n\nThe power function distribution is just the inverse of the Pareto\ndistribution. It may also be seen as a special case of the Beta distribution.\n\nIt is used, for example, in modeling the over-reporting of insurance claims.\n\nChristian Kleiber, Samuel Kotz, \u201cStatistical size distributions in economics\nand actuarial sciences\u201d, Wiley, 2003.\n\nHeckert, N. A. and Filliben, James J. \u201cNIST Handbook 148: Dataplot Reference\nManual, Volume 2: Let Subcommands and Library Functions\u201d, National Institute\nof Standards and Technology Handbook Series, June 2003.\nhttps://www.itl.nist.gov/div898/software/dataplot/refman2/auxillar/powpdf.pdf\n\nDraw samples from the distribution:\n\nDisplay the histogram of the samples, along with the probability density\nfunction:\n\nCompare the power function distribution to the inverse of the Pareto.\n\n"}, {"name": "random.rand()", "path": "reference/random/generated/numpy.random.rand", "type": "numpy.random.rand", "text": "\nRandom values in a given shape.\n\nNote\n\nThis is a convenience function for users porting code from Matlab, and wraps\n`random_sample`. That function takes a tuple to specify the size of the\noutput, which is consistent with other NumPy functions like `numpy.zeros` and\n`numpy.ones`.\n\nCreate an array of the given shape and populate it with random samples from a\nuniform distribution over `[0, 1)`.\n\nThe dimensions of the returned array, must be non-negative. If no argument is\ngiven a single Python float is returned.\n\nRandom values.\n\nSee also\n\n"}, {"name": "random.randint()", "path": "reference/random/generated/numpy.random.randint", "type": "numpy.random.randint", "text": "\nReturn random integers from `low` (inclusive) to `high` (exclusive).\n\nReturn random integers from the \u201cdiscrete uniform\u201d distribution of the\nspecified dtype in the \u201chalf-open\u201d interval [`low`, `high`). If `high` is None\n(the default), then results are from [0, `low`).\n\nNote\n\nNew code should use the `integers` method of a `default_rng()` instance\ninstead; please see the Quick Start.\n\nLowest (signed) integers to be drawn from the distribution (unless\n`high=None`, in which case this parameter is one above the highest such\ninteger).\n\nIf provided, one above the largest (signed) integer to be drawn from the\ndistribution (see above for behavior if `high=None`). If array-like, must\ncontain integer values\n\nOutput shape. If the given shape is, e.g., `(m, n, k)`, then `m * n * k`\nsamples are drawn. Default is None, in which case a single value is returned.\n\nDesired dtype of the result. Byteorder must be native. The default value is\nint.\n\nNew in version 1.11.0.\n\n`size`-shaped array of random integers from the appropriate distribution, or a\nsingle such random int if `size` not provided.\n\nSee also\n\nsimilar to `randint`, only for the closed interval [`low`, `high`], and 1 is\nthe lowest value if `high` is omitted.\n\nwhich should be used for new code.\n\nGenerate a 2 x 4 array of ints between 0 and 4, inclusive:\n\nGenerate a 1 x 3 array with 3 different upper bounds\n\nGenerate a 1 by 3 array with 3 different lower bounds\n\nGenerate a 2 by 4 array using broadcasting with dtype of uint8\n\n"}, {"name": "random.randn()", "path": "reference/random/generated/numpy.random.randn", "type": "numpy.random.randn", "text": "\nReturn a sample (or samples) from the \u201cstandard normal\u201d distribution.\n\nNote\n\nThis is a convenience function for users porting code from Matlab, and wraps\n`standard_normal`. That function takes a tuple to specify the size of the\noutput, which is consistent with other NumPy functions like `numpy.zeros` and\n`numpy.ones`.\n\nNote\n\nNew code should use the `standard_normal` method of a `default_rng()` instance\ninstead; please see the Quick Start.\n\nIf positive int_like arguments are provided, `randn` generates an array of\nshape `(d0, d1, ..., dn)`, filled with random floats sampled from a univariate\n\u201cnormal\u201d (Gaussian) distribution of mean 0 and variance 1. A single float\nrandomly sampled from the distribution is returned if no argument is provided.\n\nThe dimensions of the returned array, must be non-negative. If no argument is\ngiven a single Python float is returned.\n\nA `(d0, d1, ..., dn)`-shaped array of floating-point samples from the standard\nnormal distribution, or a single such float if no parameters were supplied.\n\nSee also\n\nSimilar, but takes a tuple as its argument.\n\nAlso accepts mu and sigma arguments.\n\nwhich should be used for new code.\n\nFor random samples from \\\\(N(\\mu, \\sigma^2)\\\\), use:\n\n`sigma * np.random.randn(...) + mu`\n\nTwo-by-four array of samples from N(3, 6.25):\n\n"}, {"name": "random.random()", "path": "reference/random/generated/numpy.random.random", "type": "numpy.random.random", "text": "\nReturn random floats in the half-open interval [0.0, 1.0). Alias for\n`random_sample` to ease forward-porting to the new random API.\n\n"}, {"name": "random.random_integers()", "path": "reference/random/generated/numpy.random.random_integers", "type": "numpy.random.random_integers", "text": "\nRandom integers of type `np.int_` between `low` and `high`, inclusive.\n\nReturn random integers of type `np.int_` from the \u201cdiscrete uniform\u201d\ndistribution in the closed interval [`low`, `high`]. If `high` is None (the\ndefault), then results are from [1, `low`]. The `np.int_` type translates to\nthe C long integer type and its precision is platform dependent.\n\nThis function has been deprecated. Use randint instead.\n\nDeprecated since version 1.11.0.\n\nLowest (signed) integer to be drawn from the distribution (unless `high=None`,\nin which case this parameter is the highest such integer).\n\nIf provided, the largest (signed) integer to be drawn from the distribution\n(see above for behavior if `high=None`).\n\nOutput shape. If the given shape is, e.g., `(m, n, k)`, then `m * n * k`\nsamples are drawn. Default is None, in which case a single value is returned.\n\n`size`-shaped array of random integers from the appropriate distribution, or a\nsingle such random int if `size` not provided.\n\nSee also\n\nSimilar to `random_integers`, only for the half-open interval [`low`, `high`),\nand 0 is the lowest value if `high` is omitted.\n\nTo sample from N evenly spaced floating-point numbers between a and b, use:\n\nChoose five random numbers from the set of five evenly-spaced numbers between\n0 and 2.5, inclusive (i.e., from the set \\\\({0, 5/8, 10/8, 15/8, 20/8}\\\\)):\n\nRoll two six sided dice 1000 times and sum the results:\n\nDisplay results as a histogram:\n\n"}, {"name": "random.random_sample()", "path": "reference/random/generated/numpy.random.random_sample", "type": "numpy.random.random_sample", "text": "\nReturn random floats in the half-open interval [0.0, 1.0).\n\nResults are from the \u201ccontinuous uniform\u201d distribution over the stated\ninterval. To sample \\\\(Unif[a, b), b > a\\\\) multiply the output of\n`random_sample` by `(b-a)` and add `a`:\n\nNote\n\nNew code should use the `random` method of a `default_rng()` instance instead;\nplease see the Quick Start.\n\nOutput shape. If the given shape is, e.g., `(m, n, k)`, then `m * n * k`\nsamples are drawn. Default is None, in which case a single value is returned.\n\nArray of random floats of shape `size` (unless `size=None`, in which case a\nsingle float is returned).\n\nSee also\n\nwhich should be used for new code.\n\nThree-by-two array of random numbers from [-5, 0):\n\n"}, {"name": "random.RandomState.beta()", "path": "reference/random/generated/numpy.random.randomstate.beta", "type": "numpy.random.RandomState.beta", "text": "\nmethod\n\nDraw samples from a Beta distribution.\n\nThe Beta distribution is a special case of the Dirichlet distribution, and is\nrelated to the Gamma distribution. It has the probability distribution\nfunction\n\nwhere the normalization, B, is the beta function,\n\nIt is often seen in Bayesian inference and order statistics.\n\nNote\n\nNew code should use the `beta` method of a `default_rng()` instance instead;\nplease see the Quick Start.\n\nAlpha, positive (>0).\n\nBeta, positive (>0).\n\nOutput shape. If the given shape is, e.g., `(m, n, k)`, then `m * n * k`\nsamples are drawn. If size is `None` (default), a single value is returned if\n`a` and `b` are both scalars. Otherwise, `np.broadcast(a, b).size` samples are\ndrawn.\n\nDrawn samples from the parameterized beta distribution.\n\nSee also\n\nwhich should be used for new code.\n\n"}, {"name": "random.RandomState.binomial()", "path": "reference/random/generated/numpy.random.randomstate.binomial", "type": "numpy.random.RandomState.binomial", "text": "\nmethod\n\nDraw samples from a binomial distribution.\n\nSamples are drawn from a binomial distribution with specified parameters, n\ntrials and p probability of success where n an integer >= 0 and p is in the\ninterval [0,1]. (n may be input as a float, but it is truncated to an integer\nin use)\n\nNote\n\nNew code should use the `binomial` method of a `default_rng()` instance\ninstead; please see the Quick Start.\n\nParameter of the distribution, >= 0. Floats are also accepted, but they will\nbe truncated to integers.\n\nParameter of the distribution, >= 0 and <=1.\n\nOutput shape. If the given shape is, e.g., `(m, n, k)`, then `m * n * k`\nsamples are drawn. If size is `None` (default), a single value is returned if\n`n` and `p` are both scalars. Otherwise, `np.broadcast(n, p).size` samples are\ndrawn.\n\nDrawn samples from the parameterized binomial distribution, where each sample\nis equal to the number of successes over the n trials.\n\nSee also\n\nprobability density function, distribution or cumulative density function,\netc.\n\nwhich should be used for new code.\n\nThe probability density for the binomial distribution is\n\nwhere \\\\(n\\\\) is the number of trials, \\\\(p\\\\) is the probability of success,\nand \\\\(N\\\\) is the number of successes.\n\nWhen estimating the standard error of a proportion in a population by using a\nrandom sample, the normal distribution works well unless the product p*n <=5,\nwhere p = population proportion estimate, and n = number of samples, in which\ncase the binomial distribution is used instead. For example, a sample of 15\npeople shows 4 who are left handed, and 11 who are right handed. Then p = 4/15\n= 27%. 0.27*15 = 4, so the binomial distribution should be used in this case.\n\nDalgaard, Peter, \u201cIntroductory Statistics with R\u201d, Springer-Verlag, 2002.\n\nGlantz, Stanton A. \u201cPrimer of Biostatistics.\u201d, McGraw-Hill, Fifth Edition,\n2002.\n\nLentner, Marvin, \u201cElementary Applied Statistics\u201d, Bogden and Quigley, 1972.\n\nWeisstein, Eric W. \u201cBinomial Distribution.\u201d From MathWorld\u2013A Wolfram Web\nResource. http://mathworld.wolfram.com/BinomialDistribution.html\n\nWikipedia, \u201cBinomial distribution\u201d,\nhttps://en.wikipedia.org/wiki/Binomial_distribution\n\nDraw samples from the distribution:\n\nA real world example. A company drills 9 wild-cat oil exploration wells, each\nwith an estimated probability of success of 0.1. All nine wells fail. What is\nthe probability of that happening?\n\nLet\u2019s do 20,000 trials of the model, and count the number that generate zero\npositive results.\n\n"}, {"name": "random.RandomState.bytes()", "path": "reference/random/generated/numpy.random.randomstate.bytes", "type": "numpy.random.RandomState.bytes", "text": "\nmethod\n\nReturn random bytes.\n\nNote\n\nNew code should use the `bytes` method of a `default_rng()` instance instead;\nplease see the Quick Start.\n\nNumber of random bytes.\n\nString of length `length`.\n\nSee also\n\nwhich should be used for new code.\n\n"}, {"name": "random.RandomState.chisquare()", "path": "reference/random/generated/numpy.random.randomstate.chisquare", "type": "numpy.random.RandomState.chisquare", "text": "\nmethod\n\nDraw samples from a chi-square distribution.\n\nWhen `df` independent random variables, each with standard normal\ndistributions (mean 0, variance 1), are squared and summed, the resulting\ndistribution is chi-square (see Notes). This distribution is often used in\nhypothesis testing.\n\nNote\n\nNew code should use the `chisquare` method of a `default_rng()` instance\ninstead; please see the Quick Start.\n\nNumber of degrees of freedom, must be > 0.\n\nOutput shape. If the given shape is, e.g., `(m, n, k)`, then `m * n * k`\nsamples are drawn. If size is `None` (default), a single value is returned if\n`df` is a scalar. Otherwise, `np.array(df).size` samples are drawn.\n\nDrawn samples from the parameterized chi-square distribution.\n\nWhen `df` <= 0 or when an inappropriate `size` (e.g. `size=-1`) is given.\n\nSee also\n\nwhich should be used for new code.\n\nThe variable obtained by summing the squares of `df` independent, standard\nnormally distributed random variables:\n\nis chi-square distributed, denoted\n\nThe probability density function of the chi-squared distribution is\n\nwhere \\\\(\\Gamma\\\\) is the gamma function,\n\nNIST \u201cEngineering Statistics Handbook\u201d\nhttps://www.itl.nist.gov/div898/handbook/eda/section3/eda3666.htm\n\n"}, {"name": "random.RandomState.choice()", "path": "reference/random/generated/numpy.random.randomstate.choice", "type": "numpy.random.RandomState.choice", "text": "\nmethod\n\nGenerates a random sample from a given 1-D array\n\nNew in version 1.7.0.\n\nNote\n\nNew code should use the `choice` method of a `default_rng()` instance instead;\nplease see the Quick Start.\n\nIf an ndarray, a random sample is generated from its elements. If an int, the\nrandom sample is generated as if it were `np.arange(a)`\n\nOutput shape. If the given shape is, e.g., `(m, n, k)`, then `m * n * k`\nsamples are drawn. Default is None, in which case a single value is returned.\n\nWhether the sample is with or without replacement. Default is True, meaning\nthat a value of `a` can be selected multiple times.\n\nThe probabilities associated with each entry in a. If not given, the sample\nassumes a uniform distribution over all entries in `a`.\n\nThe generated random samples\n\nIf a is an int and less than zero, if a or p are not 1-dimensional, if a is an\narray-like of size 0, if p is not a vector of probabilities, if a and p have\ndifferent lengths, or if replace=False and the sample size is greater than the\npopulation size\n\nSee also\n\nwhich should be used in new code\n\nSetting user-specified probabilities through `p` uses a more general but less\nefficient sampler than the default. The general sampler produces a different\nsample than the optimized sampler even if each element of `p` is 1 / len(a).\n\nSampling random rows from a 2-D array is not possible with this function, but\nis possible with `Generator.choice` through its `axis` keyword.\n\nGenerate a uniform random sample from np.arange(5) of size 3:\n\nGenerate a non-uniform random sample from np.arange(5) of size 3:\n\nGenerate a uniform random sample from np.arange(5) of size 3 without\nreplacement:\n\nGenerate a non-uniform random sample from np.arange(5) of size 3 without\nreplacement:\n\nAny of the above can be repeated with an arbitrary array-like instead of just\nintegers. For instance:\n\n"}, {"name": "random.RandomState.dirichlet()", "path": "reference/random/generated/numpy.random.randomstate.dirichlet", "type": "numpy.random.RandomState.dirichlet", "text": "\nmethod\n\nDraw samples from the Dirichlet distribution.\n\nDraw `size` samples of dimension k from a Dirichlet distribution. A Dirichlet-\ndistributed random variable can be seen as a multivariate generalization of a\nBeta distribution. The Dirichlet distribution is a conjugate prior of a\nmultinomial distribution in Bayesian inference.\n\nNote\n\nNew code should use the `dirichlet` method of a `default_rng()` instance\ninstead; please see the Quick Start.\n\nParameter of the distribution (length `k` for sample of length `k`).\n\nOutput shape. If the given shape is, e.g., `(m, n)`, then `m * n * k` samples\nare drawn. Default is None, in which case a vector of length `k` is returned.\n\nThe drawn samples, of shape `(size, k)`.\n\nIf any value in `alpha` is less than or equal to zero\n\nSee also\n\nwhich should be used for new code.\n\nThe Dirichlet distribution is a distribution over vectors \\\\(x\\\\) that fulfil\nthe conditions \\\\(x_i>0\\\\) and \\\\(\\sum_{i=1}^k x_i = 1\\\\).\n\nThe probability density function \\\\(p\\\\) of a Dirichlet-distributed random\nvector \\\\(X\\\\) is proportional to\n\nwhere \\\\(\\alpha\\\\) is a vector containing the positive concentration\nparameters.\n\nThe method uses the following property for computation: let \\\\(Y\\\\) be a\nrandom vector which has components that follow a standard gamma distribution,\nthen \\\\(X = \\frac{1}{\\sum_{i=1}^k{Y_i}} Y\\\\) is Dirichlet-distributed\n\nDavid McKay, \u201cInformation Theory, Inference and Learning Algorithms,\u201d chapter\n23, http://www.inference.org.uk/mackay/itila/\n\nWikipedia, \u201cDirichlet distribution\u201d,\nhttps://en.wikipedia.org/wiki/Dirichlet_distribution\n\nTaking an example cited in Wikipedia, this distribution can be used if one\nwanted to cut strings (each of initial length 1.0) into K pieces with\ndifferent lengths, where each piece had, on average, a designated average\nlength, but allowing some variation in the relative sizes of the pieces.\n\n"}, {"name": "random.RandomState.exponential()", "path": "reference/random/generated/numpy.random.randomstate.exponential", "type": "numpy.random.RandomState.exponential", "text": "\nmethod\n\nDraw samples from an exponential distribution.\n\nIts probability density function is\n\nfor `x > 0` and 0 elsewhere. \\\\(\\beta\\\\) is the scale parameter, which is the\ninverse of the rate parameter \\\\(\\lambda = 1/\\beta\\\\). The rate parameter is\nan alternative, widely used parameterization of the exponential distribution\n[3].\n\nThe exponential distribution is a continuous analogue of the geometric\ndistribution. It describes many common situations, such as the size of\nraindrops measured over many rainstorms [1], or the time between page requests\nto Wikipedia [2].\n\nNote\n\nNew code should use the `exponential` method of a `default_rng()` instance\ninstead; please see the Quick Start.\n\nThe scale parameter, \\\\(\\beta = 1/\\lambda\\\\). Must be non-negative.\n\nOutput shape. If the given shape is, e.g., `(m, n, k)`, then `m * n * k`\nsamples are drawn. If size is `None` (default), a single value is returned if\n`scale` is a scalar. Otherwise, `np.array(scale).size` samples are drawn.\n\nDrawn samples from the parameterized exponential distribution.\n\nSee also\n\nwhich should be used for new code.\n\nPeyton Z. Peebles Jr., \u201cProbability, Random Variables and Random Signal\nPrinciples\u201d, 4th ed, 2001, p. 57.\n\nWikipedia, \u201cPoisson process\u201d, https://en.wikipedia.org/wiki/Poisson_process\n\nWikipedia, \u201cExponential distribution\u201d,\nhttps://en.wikipedia.org/wiki/Exponential_distribution\n\n"}, {"name": "random.RandomState.f()", "path": "reference/random/generated/numpy.random.randomstate.f", "type": "numpy.random.RandomState.f", "text": "\nmethod\n\nDraw samples from an F distribution.\n\nSamples are drawn from an F distribution with specified parameters, `dfnum`\n(degrees of freedom in numerator) and `dfden` (degrees of freedom in\ndenominator), where both parameters must be greater than zero.\n\nThe random variate of the F distribution (also known as the Fisher\ndistribution) is a continuous probability distribution that arises in ANOVA\ntests, and is the ratio of two chi-square variates.\n\nNote\n\nNew code should use the `f` method of a `default_rng()` instance instead;\nplease see the Quick Start.\n\nDegrees of freedom in numerator, must be > 0.\n\nDegrees of freedom in denominator, must be > 0.\n\nOutput shape. If the given shape is, e.g., `(m, n, k)`, then `m * n * k`\nsamples are drawn. If size is `None` (default), a single value is returned if\n`dfnum` and `dfden` are both scalars. Otherwise, `np.broadcast(dfnum,\ndfden).size` samples are drawn.\n\nDrawn samples from the parameterized Fisher distribution.\n\nSee also\n\nprobability density function, distribution or cumulative density function,\netc.\n\nwhich should be used for new code.\n\nThe F statistic is used to compare in-group variances to between-group\nvariances. Calculating the distribution depends on the sampling, and so it is\na function of the respective degrees of freedom in the problem. The variable\n`dfnum` is the number of samples minus one, the between-groups degrees of\nfreedom, while `dfden` is the within-groups degrees of freedom, the sum of the\nnumber of samples in each group minus the number of groups.\n\nGlantz, Stanton A. \u201cPrimer of Biostatistics.\u201d, McGraw-Hill, Fifth Edition,\n2002.\n\nWikipedia, \u201cF-distribution\u201d, https://en.wikipedia.org/wiki/F-distribution\n\nAn example from Glantz[1], pp 47-40:\n\nTwo groups, children of diabetics (25 people) and children from people without\ndiabetes (25 controls). Fasting blood glucose was measured, case group had a\nmean value of 86.1, controls had a mean value of 82.2. Standard deviations\nwere 2.09 and 2.49 respectively. Are these data consistent with the null\nhypothesis that the parents diabetic status does not affect their children\u2019s\nblood glucose levels? Calculating the F statistic from the data gives a value\nof 36.01.\n\nDraw samples from the distribution:\n\nThe lower bound for the top 1% of the samples is :\n\nSo there is about a 1% chance that the F statistic will exceed 7.62, the\nmeasured value is 36, so the null hypothesis is rejected at the 1% level.\n\n"}, {"name": "random.RandomState.gamma()", "path": "reference/random/generated/numpy.random.randomstate.gamma", "type": "numpy.random.RandomState.gamma", "text": "\nmethod\n\nDraw samples from a Gamma distribution.\n\nSamples are drawn from a Gamma distribution with specified parameters, `shape`\n(sometimes designated \u201ck\u201d) and `scale` (sometimes designated \u201ctheta\u201d), where\nboth parameters are > 0.\n\nNote\n\nNew code should use the `gamma` method of a `default_rng()` instance instead;\nplease see the Quick Start.\n\nThe shape of the gamma distribution. Must be non-negative.\n\nThe scale of the gamma distribution. Must be non-negative. Default is equal to\n1.\n\nOutput shape. If the given shape is, e.g., `(m, n, k)`, then `m * n * k`\nsamples are drawn. If size is `None` (default), a single value is returned if\n`shape` and `scale` are both scalars. Otherwise, `np.broadcast(shape,\nscale).size` samples are drawn.\n\nDrawn samples from the parameterized gamma distribution.\n\nSee also\n\nprobability density function, distribution or cumulative density function,\netc.\n\nwhich should be used for new code.\n\nThe probability density for the Gamma distribution is\n\nwhere \\\\(k\\\\) is the shape and \\\\(\\theta\\\\) the scale, and \\\\(\\Gamma\\\\) is the\nGamma function.\n\nThe Gamma distribution is often used to model the times to failure of\nelectronic components, and arises naturally in processes for which the waiting\ntimes between Poisson distributed events are relevant.\n\nWeisstein, Eric W. \u201cGamma Distribution.\u201d From MathWorld\u2013A Wolfram Web\nResource. http://mathworld.wolfram.com/GammaDistribution.html\n\nWikipedia, \u201cGamma distribution\u201d,\nhttps://en.wikipedia.org/wiki/Gamma_distribution\n\nDraw samples from the distribution:\n\nDisplay the histogram of the samples, along with the probability density\nfunction:\n\n"}, {"name": "random.RandomState.geometric()", "path": "reference/random/generated/numpy.random.randomstate.geometric", "type": "numpy.random.RandomState.geometric", "text": "\nmethod\n\nDraw samples from the geometric distribution.\n\nBernoulli trials are experiments with one of two outcomes: success or failure\n(an example of such an experiment is flipping a coin). The geometric\ndistribution models the number of trials that must be run in order to achieve\nsuccess. It is therefore supported on the positive integers, `k = 1, 2, ...`.\n\nThe probability mass function of the geometric distribution is\n\nwhere `p` is the probability of success of an individual trial.\n\nNote\n\nNew code should use the `geometric` method of a `default_rng()` instance\ninstead; please see the Quick Start.\n\nThe probability of success of an individual trial.\n\nOutput shape. If the given shape is, e.g., `(m, n, k)`, then `m * n * k`\nsamples are drawn. If size is `None` (default), a single value is returned if\n`p` is a scalar. Otherwise, `np.array(p).size` samples are drawn.\n\nDrawn samples from the parameterized geometric distribution.\n\nSee also\n\nwhich should be used for new code.\n\nDraw ten thousand values from the geometric distribution, with the probability\nof an individual success equal to 0.35:\n\nHow many trials succeeded after a single run?\n\n"}, {"name": "random.RandomState.get_state()", "path": "reference/random/generated/numpy.random.randomstate.get_state", "type": "numpy.random.RandomState.get_state", "text": "\nmethod\n\nReturn a tuple representing the internal state of the generator.\n\nFor more details, see `set_state`.\n\nFlag indicating to return a legacy tuple state when the BitGenerator is\nMT19937, instead of a dict.\n\nThe returned tuple has the following items:\n\nIf `legacy` is False, or the BitGenerator is not MT19937, then state is\nreturned as a dictionary.\n\nSee also\n\n`set_state` and `get_state` are not needed to work with any of the random\ndistributions in NumPy. If the internal state is manually altered, the user\nshould know exactly what he/she is doing.\n\n"}, {"name": "random.RandomState.gumbel()", "path": "reference/random/generated/numpy.random.randomstate.gumbel", "type": "numpy.random.RandomState.gumbel", "text": "\nmethod\n\nDraw samples from a Gumbel distribution.\n\nDraw samples from a Gumbel distribution with specified location and scale. For\nmore information on the Gumbel distribution, see Notes and References below.\n\nNote\n\nNew code should use the `gumbel` method of a `default_rng()` instance instead;\nplease see the Quick Start.\n\nThe location of the mode of the distribution. Default is 0.\n\nThe scale parameter of the distribution. Default is 1. Must be non- negative.\n\nOutput shape. If the given shape is, e.g., `(m, n, k)`, then `m * n * k`\nsamples are drawn. If size is `None` (default), a single value is returned if\n`loc` and `scale` are both scalars. Otherwise, `np.broadcast(loc, scale).size`\nsamples are drawn.\n\nDrawn samples from the parameterized Gumbel distribution.\n\nSee also\n\nwhich should be used for new code.\n\nThe Gumbel (or Smallest Extreme Value (SEV) or the Smallest Extreme Value Type\nI) distribution is one of a class of Generalized Extreme Value (GEV)\ndistributions used in modeling extreme value problems. The Gumbel is a special\ncase of the Extreme Value Type I distribution for maximums from distributions\nwith \u201cexponential-like\u201d tails.\n\nThe probability density for the Gumbel distribution is\n\nwhere \\\\(\\mu\\\\) is the mode, a location parameter, and \\\\(\\beta\\\\) is the\nscale parameter.\n\nThe Gumbel (named for German mathematician Emil Julius Gumbel) was used very\nearly in the hydrology literature, for modeling the occurrence of flood\nevents. It is also used for modeling maximum wind speed and rainfall rates. It\nis a \u201cfat-tailed\u201d distribution - the probability of an event in the tail of\nthe distribution is larger than if one used a Gaussian, hence the surprisingly\nfrequent occurrence of 100-year floods. Floods were initially modeled as a\nGaussian process, which underestimated the frequency of extreme events.\n\nIt is one of a class of extreme value distributions, the Generalized Extreme\nValue (GEV) distributions, which also includes the Weibull and Frechet.\n\nThe function has a mean of \\\\(\\mu + 0.57721\\beta\\\\) and a variance of\n\\\\(\\frac{\\pi^2}{6}\\beta^2\\\\).\n\nGumbel, E. J., \u201cStatistics of Extremes,\u201d New York: Columbia University Press,\n1958.\n\nReiss, R.-D. and Thomas, M., \u201cStatistical Analysis of Extreme Values from\nInsurance, Finance, Hydrology and Other Fields,\u201d Basel: Birkhauser Verlag,\n2001.\n\nDraw samples from the distribution:\n\nDisplay the histogram of the samples, along with the probability density\nfunction:\n\nShow how an extreme value distribution can arise from a Gaussian process and\ncompare to a Gaussian:\n\n"}, {"name": "random.RandomState.hypergeometric()", "path": "reference/random/generated/numpy.random.randomstate.hypergeometric", "type": "numpy.random.RandomState.hypergeometric", "text": "\nmethod\n\nDraw samples from a Hypergeometric distribution.\n\nSamples are drawn from a hypergeometric distribution with specified\nparameters, `ngood` (ways to make a good selection), `nbad` (ways to make a\nbad selection), and `nsample` (number of items sampled, which is less than or\nequal to the sum `ngood + nbad`).\n\nNote\n\nNew code should use the `hypergeometric` method of a `default_rng()` instance\ninstead; please see the Quick Start.\n\nNumber of ways to make a good selection. Must be nonnegative.\n\nNumber of ways to make a bad selection. Must be nonnegative.\n\nNumber of items sampled. Must be at least 1 and at most `ngood + nbad`.\n\nOutput shape. If the given shape is, e.g., `(m, n, k)`, then `m * n * k`\nsamples are drawn. If size is `None` (default), a single value is returned if\n`ngood`, `nbad`, and `nsample` are all scalars. Otherwise,\n`np.broadcast(ngood, nbad, nsample).size` samples are drawn.\n\nDrawn samples from the parameterized hypergeometric distribution. Each sample\nis the number of good items within a randomly selected subset of size\n`nsample` taken from a set of `ngood` good items and `nbad` bad items.\n\nSee also\n\nprobability density function, distribution or cumulative density function,\netc.\n\nwhich should be used for new code.\n\nThe probability density for the Hypergeometric distribution is\n\nwhere \\\\(0 \\le x \\le n\\\\) and \\\\(n-b \\le x \\le g\\\\)\n\nfor P(x) the probability of `x` good results in the drawn sample, g = `ngood`,\nb = `nbad`, and n = `nsample`.\n\nConsider an urn with black and white marbles in it, `ngood` of them are black\nand `nbad` are white. If you draw `nsample` balls without replacement, then\nthe hypergeometric distribution describes the distribution of black balls in\nthe drawn sample.\n\nNote that this distribution is very similar to the binomial distribution,\nexcept that in this case, samples are drawn without replacement, whereas in\nthe Binomial case samples are drawn with replacement (or the sample space is\ninfinite). As the sample space becomes large, this distribution approaches the\nbinomial.\n\nLentner, Marvin, \u201cElementary Applied Statistics\u201d, Bogden and Quigley, 1972.\n\nWeisstein, Eric W. \u201cHypergeometric Distribution.\u201d From MathWorld\u2013A Wolfram Web\nResource. http://mathworld.wolfram.com/HypergeometricDistribution.html\n\nWikipedia, \u201cHypergeometric distribution\u201d,\nhttps://en.wikipedia.org/wiki/Hypergeometric_distribution\n\nDraw samples from the distribution:\n\nSuppose you have an urn with 15 white and 15 black marbles. If you pull 15\nmarbles at random, how likely is it that 12 or more of them are one color?\n\n"}, {"name": "random.RandomState.laplace()", "path": "reference/random/generated/numpy.random.randomstate.laplace", "type": "numpy.random.RandomState.laplace", "text": "\nmethod\n\nDraw samples from the Laplace or double exponential distribution with\nspecified location (or mean) and scale (decay).\n\nThe Laplace distribution is similar to the Gaussian/normal distribution, but\nis sharper at the peak and has fatter tails. It represents the difference\nbetween two independent, identically distributed exponential random variables.\n\nNote\n\nNew code should use the `laplace` method of a `default_rng()` instance\ninstead; please see the Quick Start.\n\nThe position, \\\\(\\mu\\\\), of the distribution peak. Default is 0.\n\n\\\\(\\lambda\\\\), the exponential decay. Default is 1. Must be non- negative.\n\nOutput shape. If the given shape is, e.g., `(m, n, k)`, then `m * n * k`\nsamples are drawn. If size is `None` (default), a single value is returned if\n`loc` and `scale` are both scalars. Otherwise, `np.broadcast(loc, scale).size`\nsamples are drawn.\n\nDrawn samples from the parameterized Laplace distribution.\n\nSee also\n\nwhich should be used for new code.\n\nIt has the probability density function\n\nThe first law of Laplace, from 1774, states that the frequency of an error can\nbe expressed as an exponential function of the absolute magnitude of the\nerror, which leads to the Laplace distribution. For many problems in economics\nand health sciences, this distribution seems to model the data better than the\nstandard Gaussian distribution.\n\nAbramowitz, M. and Stegun, I. A. (Eds.). \u201cHandbook of Mathematical Functions\nwith Formulas, Graphs, and Mathematical Tables, 9th printing,\u201d New York:\nDover, 1972.\n\nKotz, Samuel, et. al. \u201cThe Laplace Distribution and Generalizations, \u201d\nBirkhauser, 2001.\n\nWeisstein, Eric W. \u201cLaplace Distribution.\u201d From MathWorld\u2013A Wolfram Web\nResource. http://mathworld.wolfram.com/LaplaceDistribution.html\n\nWikipedia, \u201cLaplace distribution\u201d,\nhttps://en.wikipedia.org/wiki/Laplace_distribution\n\nDraw samples from the distribution\n\nDisplay the histogram of the samples, along with the probability density\nfunction:\n\nPlot Gaussian for comparison:\n\n"}, {"name": "random.RandomState.logistic()", "path": "reference/random/generated/numpy.random.randomstate.logistic", "type": "numpy.random.RandomState.logistic", "text": "\nmethod\n\nDraw samples from a logistic distribution.\n\nSamples are drawn from a logistic distribution with specified parameters, loc\n(location or mean, also median), and scale (>0).\n\nNote\n\nNew code should use the `logistic` method of a `default_rng()` instance\ninstead; please see the Quick Start.\n\nParameter of the distribution. Default is 0.\n\nParameter of the distribution. Must be non-negative. Default is 1.\n\nOutput shape. If the given shape is, e.g., `(m, n, k)`, then `m * n * k`\nsamples are drawn. If size is `None` (default), a single value is returned if\n`loc` and `scale` are both scalars. Otherwise, `np.broadcast(loc, scale).size`\nsamples are drawn.\n\nDrawn samples from the parameterized logistic distribution.\n\nSee also\n\nprobability density function, distribution or cumulative density function,\netc.\n\nwhich should be used for new code.\n\nThe probability density for the Logistic distribution is\n\nwhere \\\\(\\mu\\\\) = location and \\\\(s\\\\) = scale.\n\nThe Logistic distribution is used in Extreme Value problems where it can act\nas a mixture of Gumbel distributions, in Epidemiology, and by the World Chess\nFederation (FIDE) where it is used in the Elo ranking system, assuming the\nperformance of each player is a logistically distributed random variable.\n\nReiss, R.-D. and Thomas M. (2001), \u201cStatistical Analysis of Extreme Values,\nfrom Insurance, Finance, Hydrology and Other Fields,\u201d Birkhauser Verlag,\nBasel, pp 132-133.\n\nWeisstein, Eric W. \u201cLogistic Distribution.\u201d From MathWorld\u2013A Wolfram Web\nResource. http://mathworld.wolfram.com/LogisticDistribution.html\n\nWikipedia, \u201cLogistic-distribution\u201d,\nhttps://en.wikipedia.org/wiki/Logistic_distribution\n\nDraw samples from the distribution:\n\n# plot against distribution\n\n"}, {"name": "random.RandomState.lognormal()", "path": "reference/random/generated/numpy.random.randomstate.lognormal", "type": "numpy.random.RandomState.lognormal", "text": "\nmethod\n\nDraw samples from a log-normal distribution.\n\nDraw samples from a log-normal distribution with specified mean, standard\ndeviation, and array shape. Note that the mean and standard deviation are not\nthe values for the distribution itself, but of the underlying normal\ndistribution it is derived from.\n\nNote\n\nNew code should use the `lognormal` method of a `default_rng()` instance\ninstead; please see the Quick Start.\n\nMean value of the underlying normal distribution. Default is 0.\n\nStandard deviation of the underlying normal distribution. Must be non-\nnegative. Default is 1.\n\nOutput shape. If the given shape is, e.g., `(m, n, k)`, then `m * n * k`\nsamples are drawn. If size is `None` (default), a single value is returned if\n`mean` and `sigma` are both scalars. Otherwise, `np.broadcast(mean,\nsigma).size` samples are drawn.\n\nDrawn samples from the parameterized log-normal distribution.\n\nSee also\n\nprobability density function, distribution, cumulative density function, etc.\n\nwhich should be used for new code.\n\nA variable `x` has a log-normal distribution if `log(x)` is normally\ndistributed. The probability density function for the log-normal distribution\nis:\n\nwhere \\\\(\\mu\\\\) is the mean and \\\\(\\sigma\\\\) is the standard deviation of the\nnormally distributed logarithm of the variable. A log-normal distribution\nresults if a random variable is the product of a large number of independent,\nidentically-distributed variables in the same way that a normal distribution\nresults if the variable is the sum of a large number of independent,\nidentically-distributed variables.\n\nLimpert, E., Stahel, W. A., and Abbt, M., \u201cLog-normal Distributions across the\nSciences: Keys and Clues,\u201d BioScience, Vol. 51, No. 5, May, 2001.\nhttps://stat.ethz.ch/~stahel/lognormal/bioscience.pdf\n\nReiss, R.D. and Thomas, M., \u201cStatistical Analysis of Extreme Values,\u201d Basel:\nBirkhauser Verlag, 2001, pp. 31-32.\n\nDraw samples from the distribution:\n\nDisplay the histogram of the samples, along with the probability density\nfunction:\n\nDemonstrate that taking the products of random samples from a uniform\ndistribution can be fit well by a log-normal probability density function.\n\n"}, {"name": "random.RandomState.logseries()", "path": "reference/random/generated/numpy.random.randomstate.logseries", "type": "numpy.random.RandomState.logseries", "text": "\nmethod\n\nDraw samples from a logarithmic series distribution.\n\nSamples are drawn from a log series distribution with specified shape\nparameter, 0 < `p` < 1.\n\nNote\n\nNew code should use the `logseries` method of a `default_rng()` instance\ninstead; please see the Quick Start.\n\nShape parameter for the distribution. Must be in the range (0, 1).\n\nOutput shape. If the given shape is, e.g., `(m, n, k)`, then `m * n * k`\nsamples are drawn. If size is `None` (default), a single value is returned if\n`p` is a scalar. Otherwise, `np.array(p).size` samples are drawn.\n\nDrawn samples from the parameterized logarithmic series distribution.\n\nSee also\n\nprobability density function, distribution or cumulative density function,\netc.\n\nwhich should be used for new code.\n\nThe probability density for the Log Series distribution is\n\nwhere p = probability.\n\nThe log series distribution is frequently used to represent species richness\nand occurrence, first proposed by Fisher, Corbet, and Williams in 1943 [2]. It\nmay also be used to model the numbers of occupants seen in cars [3].\n\nBuzas, Martin A.; Culver, Stephen J., Understanding regional species diversity\nthrough the log series distribution of occurrences: BIODIVERSITY RESEARCH\nDiversity & Distributions, Volume 5, Number 5, September 1999 , pp.\n187-195(9).\n\nFisher, R.A,, A.S. Corbet, and C.B. Williams. 1943. The relation between the\nnumber of species and the number of individuals in a random sample of an\nanimal population. Journal of Animal Ecology, 12:42-58.\n\nD. J. Hand, F. Daly, D. Lunn, E. Ostrowski, A Handbook of Small Data Sets, CRC\nPress, 1994.\n\nWikipedia, \u201cLogarithmic distribution\u201d,\nhttps://en.wikipedia.org/wiki/Logarithmic_distribution\n\nDraw samples from the distribution:\n\n# plot against distribution\n\n"}, {"name": "random.RandomState.multinomial()", "path": "reference/random/generated/numpy.random.randomstate.multinomial", "type": "numpy.random.RandomState.multinomial", "text": "\nmethod\n\nDraw samples from a multinomial distribution.\n\nThe multinomial distribution is a multivariate generalization of the binomial\ndistribution. Take an experiment with one of `p` possible outcomes. An example\nof such an experiment is throwing a dice, where the outcome can be 1 through\n6. Each sample drawn from the distribution represents `n` such experiments.\nIts values, `X_i = [X_0, X_1, ..., X_p]`, represent the number of times the\noutcome was `i`.\n\nNote\n\nNew code should use the `multinomial` method of a `default_rng()` instance\ninstead; please see the Quick Start.\n\nNumber of experiments.\n\nProbabilities of each of the `p` different outcomes. These must sum to 1\n(however, the last element is always assumed to account for the remaining\nprobability, as long as `sum(pvals[:-1]) <= 1)`.\n\nOutput shape. If the given shape is, e.g., `(m, n, k)`, then `m * n * k`\nsamples are drawn. Default is None, in which case a single value is returned.\n\nThe drawn samples, of shape size, if that was provided. If not, the shape is\n`(N,)`.\n\nIn other words, each entry `out[i,j,...,:]` is an N-dimensional value drawn\nfrom the distribution.\n\nSee also\n\nwhich should be used for new code.\n\nThrow a dice 20 times:\n\nIt landed 4 times on 1, once on 2, etc.\n\nNow, throw the dice 20 times, and 20 times again:\n\nFor the first run, we threw 3 times 1, 4 times 2, etc. For the second, we\nthrew 2 times 1, 4 times 2, etc.\n\nA loaded die is more likely to land on number 6:\n\nThe probability inputs should be normalized. As an implementation detail, the\nvalue of the last entry is ignored and assumed to take up any leftover\nprobability mass, but this should not be relied on. A biased coin which has\ntwice as much weight on one side as on the other should be sampled like so:\n\nnot like:\n\n"}, {"name": "random.RandomState.multivariate_normal()", "path": "reference/random/generated/numpy.random.randomstate.multivariate_normal", "type": "numpy.random.RandomState.multivariate_normal", "text": "\nmethod\n\nDraw random samples from a multivariate normal distribution.\n\nThe multivariate normal, multinormal or Gaussian distribution is a\ngeneralization of the one-dimensional normal distribution to higher\ndimensions. Such a distribution is specified by its mean and covariance\nmatrix. These parameters are analogous to the mean (average or \u201ccenter\u201d) and\nvariance (standard deviation, or \u201cwidth,\u201d squared) of the one-dimensional\nnormal distribution.\n\nNote\n\nNew code should use the `multivariate_normal` method of a `default_rng()`\ninstance instead; please see the Quick Start.\n\nMean of the N-dimensional distribution.\n\nCovariance matrix of the distribution. It must be symmetric and positive-\nsemidefinite for proper sampling.\n\nGiven a shape of, for example, `(m,n,k)`, `m*n*k` samples are generated, and\npacked in an `m`-by-`n`-by-`k` arrangement. Because each sample is\n`N`-dimensional, the output shape is `(m,n,k,N)`. If no shape is specified, a\nsingle (`N`-D) sample is returned.\n\nBehavior when the covariance matrix is not positive semidefinite.\n\nTolerance when checking the singular values in covariance matrix. cov is cast\nto double before the check.\n\nThe drawn samples, of shape size, if that was provided. If not, the shape is\n`(N,)`.\n\nIn other words, each entry `out[i,j,...,:]` is an N-dimensional value drawn\nfrom the distribution.\n\nSee also\n\nwhich should be used for new code.\n\nThe mean is a coordinate in N-dimensional space, which represents the location\nwhere samples are most likely to be generated. This is analogous to the peak\nof the bell curve for the one-dimensional or univariate normal distribution.\n\nCovariance indicates the level to which two variables vary together. From the\nmultivariate normal distribution, we draw N-dimensional samples, \\\\(X = [x_1,\nx_2, ... x_N]\\\\). The covariance matrix element \\\\(C_{ij}\\\\) is the covariance\nof \\\\(x_i\\\\) and \\\\(x_j\\\\). The element \\\\(C_{ii}\\\\) is the variance of\n\\\\(x_i\\\\) (i.e. its \u201cspread\u201d).\n\nInstead of specifying the full covariance matrix, popular approximations\ninclude:\n\nThis geometrical property can be seen in two dimensions by plotting generated\ndata-points:\n\nDiagonal covariance means that points are oriented along x or y-axis:\n\nNote that the covariance matrix must be positive semidefinite (a.k.a.\nnonnegative-definite). Otherwise, the behavior of this method is undefined and\nbackwards compatibility is not guaranteed.\n\nPapoulis, A., \u201cProbability, Random Variables, and Stochastic Processes,\u201d 3rd\ned., New York: McGraw-Hill, 1991.\n\nDuda, R. O., Hart, P. E., and Stork, D. G., \u201cPattern Classification,\u201d 2nd ed.,\nNew York: Wiley, 2001.\n\nThe following is probably true, given that 0.6 is roughly twice the standard\ndeviation:\n\n"}, {"name": "random.RandomState.negative_binomial()", "path": "reference/random/generated/numpy.random.randomstate.negative_binomial", "type": "numpy.random.RandomState.negative_binomial", "text": "\nmethod\n\nDraw samples from a negative binomial distribution.\n\nSamples are drawn from a negative binomial distribution with specified\nparameters, `n` successes and `p` probability of success where `n` is > 0 and\n`p` is in the interval [0, 1].\n\nNote\n\nNew code should use the `negative_binomial` method of a `default_rng()`\ninstance instead; please see the Quick Start.\n\nParameter of the distribution, > 0.\n\nParameter of the distribution, >= 0 and <=1.\n\nOutput shape. If the given shape is, e.g., `(m, n, k)`, then `m * n * k`\nsamples are drawn. If size is `None` (default), a single value is returned if\n`n` and `p` are both scalars. Otherwise, `np.broadcast(n, p).size` samples are\ndrawn.\n\nDrawn samples from the parameterized negative binomial distribution, where\neach sample is equal to N, the number of failures that occurred before a total\nof n successes was reached.\n\nSee also\n\nwhich should be used for new code.\n\nThe probability mass function of the negative binomial distribution is\n\nwhere \\\\(n\\\\) is the number of successes, \\\\(p\\\\) is the probability of\nsuccess, \\\\(N+n\\\\) is the number of trials, and \\\\(\\Gamma\\\\) is the gamma\nfunction. When \\\\(n\\\\) is an integer, \\\\(\\frac{\\Gamma(N+n)}{N!\\Gamma(n)} =\n\\binom{N+n-1}{N}\\\\), which is the more common form of this term in the the\npmf. The negative binomial distribution gives the probability of N failures\ngiven n successes, with a success on the last trial.\n\nIf one throws a die repeatedly until the third time a \u201c1\u201d appears, then the\nprobability distribution of the number of non-\u201c1\u201ds that appear before the\nthird \u201c1\u201d is a negative binomial distribution.\n\nWeisstein, Eric W. \u201cNegative Binomial Distribution.\u201d From MathWorld\u2013A Wolfram\nWeb Resource. http://mathworld.wolfram.com/NegativeBinomialDistribution.html\n\nWikipedia, \u201cNegative binomial distribution\u201d,\nhttps://en.wikipedia.org/wiki/Negative_binomial_distribution\n\nDraw samples from the distribution:\n\nA real world example. A company drills wild-cat oil exploration wells, each\nwith an estimated probability of success of 0.1. What is the probability of\nhaving one success for each successive well, that is what is the probability\nof a single success after drilling 5 wells, after 6 wells, etc.?\n\n"}, {"name": "random.RandomState.noncentral_chisquare()", "path": "reference/random/generated/numpy.random.randomstate.noncentral_chisquare", "type": "numpy.random.RandomState.noncentral_chisquare", "text": "\nmethod\n\nDraw samples from a noncentral chi-square distribution.\n\nThe noncentral \\\\(\\chi^2\\\\) distribution is a generalization of the\n\\\\(\\chi^2\\\\) distribution.\n\nNote\n\nNew code should use the `noncentral_chisquare` method of a `default_rng()`\ninstance instead; please see the Quick Start.\n\nDegrees of freedom, must be > 0.\n\nChanged in version 1.10.0: Earlier NumPy versions required dfnum > 1.\n\nNon-centrality, must be non-negative.\n\nOutput shape. If the given shape is, e.g., `(m, n, k)`, then `m * n * k`\nsamples are drawn. If size is `None` (default), a single value is returned if\n`df` and `nonc` are both scalars. Otherwise, `np.broadcast(df, nonc).size`\nsamples are drawn.\n\nDrawn samples from the parameterized noncentral chi-square distribution.\n\nSee also\n\nwhich should be used for new code.\n\nThe probability density function for the noncentral Chi-square distribution is\n\nwhere \\\\(Y_{q}\\\\) is the Chi-square with q degrees of freedom.\n\nWikipedia, \u201cNoncentral chi-squared distribution\u201d\nhttps://en.wikipedia.org/wiki/Noncentral_chi-squared_distribution\n\nDraw values from the distribution and plot the histogram\n\nDraw values from a noncentral chisquare with very small noncentrality, and\ncompare to a chisquare.\n\nDemonstrate how large values of non-centrality lead to a more symmetric\ndistribution.\n\n"}, {"name": "random.RandomState.noncentral_f()", "path": "reference/random/generated/numpy.random.randomstate.noncentral_f", "type": "numpy.random.RandomState.noncentral_f", "text": "\nmethod\n\nDraw samples from the noncentral F distribution.\n\nSamples are drawn from an F distribution with specified parameters, `dfnum`\n(degrees of freedom in numerator) and `dfden` (degrees of freedom in\ndenominator), where both parameters > 1\\. `nonc` is the non-centrality\nparameter.\n\nNote\n\nNew code should use the `noncentral_f` method of a `default_rng()` instance\ninstead; please see the Quick Start.\n\nNumerator degrees of freedom, must be > 0.\n\nChanged in version 1.14.0: Earlier NumPy versions required dfnum > 1.\n\nDenominator degrees of freedom, must be > 0.\n\nNon-centrality parameter, the sum of the squares of the numerator means, must\nbe >= 0.\n\nOutput shape. If the given shape is, e.g., `(m, n, k)`, then `m * n * k`\nsamples are drawn. If size is `None` (default), a single value is returned if\n`dfnum`, `dfden`, and `nonc` are all scalars. Otherwise, `np.broadcast(dfnum,\ndfden, nonc).size` samples are drawn.\n\nDrawn samples from the parameterized noncentral Fisher distribution.\n\nSee also\n\nwhich should be used for new code.\n\nWhen calculating the power of an experiment (power = probability of rejecting\nthe null hypothesis when a specific alternative is true) the non-central F\nstatistic becomes important. When the null hypothesis is true, the F statistic\nfollows a central F distribution. When the null hypothesis is not true, then\nit follows a non-central F statistic.\n\nWeisstein, Eric W. \u201cNoncentral F-Distribution.\u201d From MathWorld\u2013A Wolfram Web\nResource. http://mathworld.wolfram.com/NoncentralF-Distribution.html\n\nWikipedia, \u201cNoncentral F-distribution\u201d,\nhttps://en.wikipedia.org/wiki/Noncentral_F-distribution\n\nIn a study, testing for a specific alternative to the null hypothesis requires\nuse of the Noncentral F distribution. We need to calculate the area in the\ntail of the distribution that exceeds the value of the F distribution for the\nnull hypothesis. We\u2019ll plot the two probability distributions for comparison.\n\n"}, {"name": "random.RandomState.normal()", "path": "reference/random/generated/numpy.random.randomstate.normal", "type": "numpy.random.RandomState.normal", "text": "\nmethod\n\nDraw random samples from a normal (Gaussian) distribution.\n\nThe probability density function of the normal distribution, first derived by\nDe Moivre and 200 years later by both Gauss and Laplace independently [2], is\noften called the bell curve because of its characteristic shape (see the\nexample below).\n\nThe normal distributions occurs often in nature. For example, it describes the\ncommonly occurring distribution of samples influenced by a large number of\ntiny, random disturbances, each with its own unique distribution [2].\n\nNote\n\nNew code should use the `normal` method of a `default_rng()` instance instead;\nplease see the Quick Start.\n\nMean (\u201ccentre\u201d) of the distribution.\n\nStandard deviation (spread or \u201cwidth\u201d) of the distribution. Must be non-\nnegative.\n\nOutput shape. If the given shape is, e.g., `(m, n, k)`, then `m * n * k`\nsamples are drawn. If size is `None` (default), a single value is returned if\n`loc` and `scale` are both scalars. Otherwise, `np.broadcast(loc, scale).size`\nsamples are drawn.\n\nDrawn samples from the parameterized normal distribution.\n\nSee also\n\nprobability density function, distribution or cumulative density function,\netc.\n\nwhich should be used for new code.\n\nThe probability density for the Gaussian distribution is\n\nwhere \\\\(\\mu\\\\) is the mean and \\\\(\\sigma\\\\) the standard deviation. The\nsquare of the standard deviation, \\\\(\\sigma^2\\\\), is called the variance.\n\nThe function has its peak at the mean, and its \u201cspread\u201d increases with the\nstandard deviation (the function reaches 0.607 times its maximum at \\\\(x +\n\\sigma\\\\) and \\\\(x - \\sigma\\\\) [2]). This implies that normal is more likely\nto return samples lying close to the mean, rather than those far away.\n\nWikipedia, \u201cNormal distribution\u201d,\nhttps://en.wikipedia.org/wiki/Normal_distribution\n\nP. R. Peebles Jr., \u201cCentral Limit Theorem\u201d in \u201cProbability, Random Variables\nand Random Signal Principles\u201d, 4th ed., 2001, pp. 51, 51, 125.\n\nDraw samples from the distribution:\n\nVerify the mean and the variance:\n\nDisplay the histogram of the samples, along with the probability density\nfunction:\n\nTwo-by-four array of samples from N(3, 6.25):\n\n"}, {"name": "random.RandomState.pareto()", "path": "reference/random/generated/numpy.random.randomstate.pareto", "type": "numpy.random.RandomState.pareto", "text": "\nmethod\n\nDraw samples from a Pareto II or Lomax distribution with specified shape.\n\nThe Lomax or Pareto II distribution is a shifted Pareto distribution. The\nclassical Pareto distribution can be obtained from the Lomax distribution by\nadding 1 and multiplying by the scale parameter `m` (see Notes). The smallest\nvalue of the Lomax distribution is zero while for the classical Pareto\ndistribution it is `mu`, where the standard Pareto distribution has location\n`mu = 1`. Lomax can also be considered as a simplified version of the\nGeneralized Pareto distribution (available in SciPy), with the scale set to\none and the location set to zero.\n\nThe Pareto distribution must be greater than zero, and is unbounded above. It\nis also known as the \u201c80-20 rule\u201d. In this distribution, 80 percent of the\nweights are in the lowest 20 percent of the range, while the other 20 percent\nfill the remaining 80 percent of the range.\n\nNote\n\nNew code should use the `pareto` method of a `default_rng()` instance instead;\nplease see the Quick Start.\n\nShape of the distribution. Must be positive.\n\nOutput shape. If the given shape is, e.g., `(m, n, k)`, then `m * n * k`\nsamples are drawn. If size is `None` (default), a single value is returned if\n`a` is a scalar. Otherwise, `np.array(a).size` samples are drawn.\n\nDrawn samples from the parameterized Pareto distribution.\n\nSee also\n\nprobability density function, distribution or cumulative density function,\netc.\n\nprobability density function, distribution or cumulative density function,\netc.\n\nwhich should be used for new code.\n\nThe probability density for the Pareto distribution is\n\nwhere \\\\(a\\\\) is the shape and \\\\(m\\\\) the scale.\n\nThe Pareto distribution, named after the Italian economist Vilfredo Pareto, is\na power law probability distribution useful in many real world problems.\nOutside the field of economics it is generally referred to as the Bradford\ndistribution. Pareto developed the distribution to describe the distribution\nof wealth in an economy. It has also found use in insurance, web page access\nstatistics, oil field sizes, and many other problems, including the download\nfrequency for projects in Sourceforge [1]. It is one of the so-called \u201cfat-\ntailed\u201d distributions.\n\nFrancis Hunt and Paul Johnson, On the Pareto Distribution of Sourceforge\nprojects.\n\nPareto, V. (1896). Course of Political Economy. Lausanne.\n\nReiss, R.D., Thomas, M.(2001), Statistical Analysis of Extreme Values,\nBirkhauser Verlag, Basel, pp 23-30.\n\nWikipedia, \u201cPareto distribution\u201d,\nhttps://en.wikipedia.org/wiki/Pareto_distribution\n\nDraw samples from the distribution:\n\nDisplay the histogram of the samples, along with the probability density\nfunction:\n\n"}, {"name": "random.RandomState.permutation()", "path": "reference/random/generated/numpy.random.randomstate.permutation", "type": "numpy.random.RandomState.permutation", "text": "\nmethod\n\nRandomly permute a sequence, or return a permuted range.\n\nIf `x` is a multi-dimensional array, it is only shuffled along its first\nindex.\n\nNote\n\nNew code should use the `permutation` method of a `default_rng()` instance\ninstead; please see the Quick Start.\n\nIf `x` is an integer, randomly permute `np.arange(x)`. If `x` is an array,\nmake a copy and shuffle the elements randomly.\n\nPermuted sequence or array range.\n\nSee also\n\nwhich should be used for new code.\n\n"}, {"name": "random.RandomState.poisson()", "path": "reference/random/generated/numpy.random.randomstate.poisson", "type": "numpy.random.RandomState.poisson", "text": "\nmethod\n\nDraw samples from a Poisson distribution.\n\nThe Poisson distribution is the limit of the binomial distribution for large\nN.\n\nNote\n\nNew code should use the `poisson` method of a `default_rng()` instance\ninstead; please see the Quick Start.\n\nExpected number of events occurring in a fixed-time interval, must be >= 0. A\nsequence must be broadcastable over the requested size.\n\nOutput shape. If the given shape is, e.g., `(m, n, k)`, then `m * n * k`\nsamples are drawn. If size is `None` (default), a single value is returned if\n`lam` is a scalar. Otherwise, `np.array(lam).size` samples are drawn.\n\nDrawn samples from the parameterized Poisson distribution.\n\nSee also\n\nwhich should be used for new code.\n\nThe Poisson distribution\n\nFor events with an expected separation \\\\(\\lambda\\\\) the Poisson distribution\n\\\\(f(k; \\lambda)\\\\) describes the probability of \\\\(k\\\\) events occurring\nwithin the observed interval \\\\(\\lambda\\\\).\n\nBecause the output is limited to the range of the C int64 type, a ValueError\nis raised when `lam` is within 10 sigma of the maximum representable value.\n\nWeisstein, Eric W. \u201cPoisson Distribution.\u201d From MathWorld\u2013A Wolfram Web\nResource. http://mathworld.wolfram.com/PoissonDistribution.html\n\nWikipedia, \u201cPoisson distribution\u201d,\nhttps://en.wikipedia.org/wiki/Poisson_distribution\n\nDraw samples from the distribution:\n\nDisplay histogram of the sample:\n\nDraw each 100 values for lambda 100 and 500:\n\n"}, {"name": "random.RandomState.power()", "path": "reference/random/generated/numpy.random.randomstate.power", "type": "numpy.random.RandomState.power", "text": "\nmethod\n\nDraws samples in [0, 1] from a power distribution with positive exponent a -\n1.\n\nAlso known as the power function distribution.\n\nNote\n\nNew code should use the `power` method of a `default_rng()` instance instead;\nplease see the Quick Start.\n\nParameter of the distribution. Must be non-negative.\n\nOutput shape. If the given shape is, e.g., `(m, n, k)`, then `m * n * k`\nsamples are drawn. If size is `None` (default), a single value is returned if\n`a` is a scalar. Otherwise, `np.array(a).size` samples are drawn.\n\nDrawn samples from the parameterized power distribution.\n\nIf a <= 0.\n\nSee also\n\nwhich should be used for new code.\n\nThe probability density function is\n\nThe power function distribution is just the inverse of the Pareto\ndistribution. It may also be seen as a special case of the Beta distribution.\n\nIt is used, for example, in modeling the over-reporting of insurance claims.\n\nChristian Kleiber, Samuel Kotz, \u201cStatistical size distributions in economics\nand actuarial sciences\u201d, Wiley, 2003.\n\nHeckert, N. A. and Filliben, James J. \u201cNIST Handbook 148: Dataplot Reference\nManual, Volume 2: Let Subcommands and Library Functions\u201d, National Institute\nof Standards and Technology Handbook Series, June 2003.\nhttps://www.itl.nist.gov/div898/software/dataplot/refman2/auxillar/powpdf.pdf\n\nDraw samples from the distribution:\n\nDisplay the histogram of the samples, along with the probability density\nfunction:\n\nCompare the power function distribution to the inverse of the Pareto.\n\n"}, {"name": "random.RandomState.rand()", "path": "reference/random/generated/numpy.random.randomstate.rand", "type": "numpy.random.RandomState.rand", "text": "\nmethod\n\nRandom values in a given shape.\n\nNote\n\nThis is a convenience function for users porting code from Matlab, and wraps\n`random_sample`. That function takes a tuple to specify the size of the\noutput, which is consistent with other NumPy functions like `numpy.zeros` and\n`numpy.ones`.\n\nCreate an array of the given shape and populate it with random samples from a\nuniform distribution over `[0, 1)`.\n\nThe dimensions of the returned array, must be non-negative. If no argument is\ngiven a single Python float is returned.\n\nRandom values.\n\nSee also\n\n"}, {"name": "random.RandomState.randint()", "path": "reference/random/generated/numpy.random.randomstate.randint", "type": "numpy.random.RandomState.randint", "text": "\nmethod\n\nReturn random integers from `low` (inclusive) to `high` (exclusive).\n\nReturn random integers from the \u201cdiscrete uniform\u201d distribution of the\nspecified dtype in the \u201chalf-open\u201d interval [`low`, `high`). If `high` is None\n(the default), then results are from [0, `low`).\n\nNote\n\nNew code should use the `integers` method of a `default_rng()` instance\ninstead; please see the Quick Start.\n\nLowest (signed) integers to be drawn from the distribution (unless\n`high=None`, in which case this parameter is one above the highest such\ninteger).\n\nIf provided, one above the largest (signed) integer to be drawn from the\ndistribution (see above for behavior if `high=None`). If array-like, must\ncontain integer values\n\nOutput shape. If the given shape is, e.g., `(m, n, k)`, then `m * n * k`\nsamples are drawn. Default is None, in which case a single value is returned.\n\nDesired dtype of the result. Byteorder must be native. The default value is\nint.\n\nNew in version 1.11.0.\n\n`size`-shaped array of random integers from the appropriate distribution, or a\nsingle such random int if `size` not provided.\n\nSee also\n\nsimilar to `randint`, only for the closed interval [`low`, `high`], and 1 is\nthe lowest value if `high` is omitted.\n\nwhich should be used for new code.\n\nGenerate a 2 x 4 array of ints between 0 and 4, inclusive:\n\nGenerate a 1 x 3 array with 3 different upper bounds\n\nGenerate a 1 by 3 array with 3 different lower bounds\n\nGenerate a 2 by 4 array using broadcasting with dtype of uint8\n\n"}, {"name": "random.RandomState.randn()", "path": "reference/random/generated/numpy.random.randomstate.randn", "type": "numpy.random.RandomState.randn", "text": "\nmethod\n\nReturn a sample (or samples) from the \u201cstandard normal\u201d distribution.\n\nNote\n\nThis is a convenience function for users porting code from Matlab, and wraps\n`standard_normal`. That function takes a tuple to specify the size of the\noutput, which is consistent with other NumPy functions like `numpy.zeros` and\n`numpy.ones`.\n\nNote\n\nNew code should use the `standard_normal` method of a `default_rng()` instance\ninstead; please see the Quick Start.\n\nIf positive int_like arguments are provided, `randn` generates an array of\nshape `(d0, d1, ..., dn)`, filled with random floats sampled from a univariate\n\u201cnormal\u201d (Gaussian) distribution of mean 0 and variance 1. A single float\nrandomly sampled from the distribution is returned if no argument is provided.\n\nThe dimensions of the returned array, must be non-negative. If no argument is\ngiven a single Python float is returned.\n\nA `(d0, d1, ..., dn)`-shaped array of floating-point samples from the standard\nnormal distribution, or a single such float if no parameters were supplied.\n\nSee also\n\nSimilar, but takes a tuple as its argument.\n\nAlso accepts mu and sigma arguments.\n\nwhich should be used for new code.\n\nFor random samples from \\\\(N(\\mu, \\sigma^2)\\\\), use:\n\n`sigma * np.random.randn(...) + mu`\n\nTwo-by-four array of samples from N(3, 6.25):\n\n"}, {"name": "random.RandomState.random_integers()", "path": "reference/random/generated/numpy.random.randomstate.random_integers", "type": "numpy.random.RandomState.random_integers", "text": "\nmethod\n\nRandom integers of type `np.int_` between `low` and `high`, inclusive.\n\nReturn random integers of type `np.int_` from the \u201cdiscrete uniform\u201d\ndistribution in the closed interval [`low`, `high`]. If `high` is None (the\ndefault), then results are from [1, `low`]. The `np.int_` type translates to\nthe C long integer type and its precision is platform dependent.\n\nThis function has been deprecated. Use randint instead.\n\nDeprecated since version 1.11.0.\n\nLowest (signed) integer to be drawn from the distribution (unless `high=None`,\nin which case this parameter is the highest such integer).\n\nIf provided, the largest (signed) integer to be drawn from the distribution\n(see above for behavior if `high=None`).\n\nOutput shape. If the given shape is, e.g., `(m, n, k)`, then `m * n * k`\nsamples are drawn. Default is None, in which case a single value is returned.\n\n`size`-shaped array of random integers from the appropriate distribution, or a\nsingle such random int if `size` not provided.\n\nSee also\n\nSimilar to `random_integers`, only for the half-open interval [`low`, `high`),\nand 0 is the lowest value if `high` is omitted.\n\nTo sample from N evenly spaced floating-point numbers between a and b, use:\n\nChoose five random numbers from the set of five evenly-spaced numbers between\n0 and 2.5, inclusive (i.e., from the set \\\\({0, 5/8, 10/8, 15/8, 20/8}\\\\)):\n\nRoll two six sided dice 1000 times and sum the results:\n\nDisplay results as a histogram:\n\n"}, {"name": "random.RandomState.random_sample()", "path": "reference/random/generated/numpy.random.randomstate.random_sample", "type": "numpy.random.RandomState.random_sample", "text": "\nmethod\n\nReturn random floats in the half-open interval [0.0, 1.0).\n\nResults are from the \u201ccontinuous uniform\u201d distribution over the stated\ninterval. To sample \\\\(Unif[a, b), b > a\\\\) multiply the output of\n`random_sample` by `(b-a)` and add `a`:\n\nNote\n\nNew code should use the `random` method of a `default_rng()` instance instead;\nplease see the Quick Start.\n\nOutput shape. If the given shape is, e.g., `(m, n, k)`, then `m * n * k`\nsamples are drawn. Default is None, in which case a single value is returned.\n\nArray of random floats of shape `size` (unless `size=None`, in which case a\nsingle float is returned).\n\nSee also\n\nwhich should be used for new code.\n\nThree-by-two array of random numbers from [-5, 0):\n\n"}, {"name": "random.RandomState.rayleigh()", "path": "reference/random/generated/numpy.random.randomstate.rayleigh", "type": "numpy.random.RandomState.rayleigh", "text": "\nmethod\n\nDraw samples from a Rayleigh distribution.\n\nThe \\\\(\\chi\\\\) and Weibull distributions are generalizations of the Rayleigh.\n\nNote\n\nNew code should use the `rayleigh` method of a `default_rng()` instance\ninstead; please see the Quick Start.\n\nScale, also equals the mode. Must be non-negative. Default is 1.\n\nOutput shape. If the given shape is, e.g., `(m, n, k)`, then `m * n * k`\nsamples are drawn. If size is `None` (default), a single value is returned if\n`scale` is a scalar. Otherwise, `np.array(scale).size` samples are drawn.\n\nDrawn samples from the parameterized Rayleigh distribution.\n\nSee also\n\nwhich should be used for new code.\n\nThe probability density function for the Rayleigh distribution is\n\nThe Rayleigh distribution would arise, for example, if the East and North\ncomponents of the wind velocity had identical zero-mean Gaussian\ndistributions. Then the wind speed would have a Rayleigh distribution.\n\nBrighton Webs Ltd., \u201cRayleigh Distribution,\u201d\nhttps://web.archive.org/web/20090514091424/http://brighton-\nwebs.co.uk:80/distributions/rayleigh.asp\n\nWikipedia, \u201cRayleigh distribution\u201d\nhttps://en.wikipedia.org/wiki/Rayleigh_distribution\n\nDraw values from the distribution and plot the histogram\n\nWave heights tend to follow a Rayleigh distribution. If the mean wave height\nis 1 meter, what fraction of waves are likely to be larger than 3 meters?\n\nThe percentage of waves larger than 3 meters is:\n\n"}, {"name": "random.RandomState.seed()", "path": "reference/random/generated/numpy.random.randomstate.seed", "type": "numpy.random.RandomState.seed", "text": "\nmethod\n\nReseed a legacy MT19937 BitGenerator\n\nThis is a convenience, legacy function.\n\nThe best practice is to not reseed a BitGenerator, rather to recreate a new\none. This method is here for legacy reasons. This example demonstrates best\npractice.\n\n"}, {"name": "random.RandomState.set_state()", "path": "reference/random/generated/numpy.random.randomstate.set_state", "type": "numpy.random.RandomState.set_state", "text": "\nmethod\n\nSet the internal state of the generator from a tuple.\n\nFor use if one has reason to manually (re-)set the internal state of the bit\ngenerator used by the RandomState instance. By default, RandomState uses the\n\u201cMersenne Twister\u201d[1] pseudo-random number generating algorithm.\n\nThe `state` tuple has the following items:\n\nIf state is a dictionary, it is directly set using the BitGenerators `state`\nproperty.\n\nReturns \u2018None\u2019 on success.\n\nSee also\n\n`set_state` and `get_state` are not needed to work with any of the random\ndistributions in NumPy. If the internal state is manually altered, the user\nshould know exactly what he/she is doing.\n\nFor backwards compatibility, the form (str, array of 624 uints, int) is also\naccepted although it is missing some information about the cached Gaussian\nvalue: `state = ('MT19937', keys, pos)`.\n\nM. Matsumoto and T. Nishimura, \u201cMersenne Twister: A 623-dimensionally\nequidistributed uniform pseudorandom number generator,\u201d ACM Trans. on Modeling\nand Computer Simulation, Vol. 8, No. 1, pp. 3-30, Jan. 1998.\n\n"}, {"name": "random.RandomState.shuffle()", "path": "reference/random/generated/numpy.random.randomstate.shuffle", "type": "numpy.random.RandomState.shuffle", "text": "\nmethod\n\nModify a sequence in-place by shuffling its contents.\n\nThis function only shuffles the array along the first axis of a multi-\ndimensional array. The order of sub-arrays is changed but their contents\nremains the same.\n\nNote\n\nNew code should use the `shuffle` method of a `default_rng()` instance\ninstead; please see the Quick Start.\n\nThe array, list or mutable sequence to be shuffled.\n\nSee also\n\nwhich should be used for new code.\n\nMulti-dimensional arrays are only shuffled along the first axis:\n\n"}, {"name": "random.RandomState.standard_cauchy()", "path": "reference/random/generated/numpy.random.randomstate.standard_cauchy", "type": "numpy.random.RandomState.standard_cauchy", "text": "\nmethod\n\nDraw samples from a standard Cauchy distribution with mode = 0.\n\nAlso known as the Lorentz distribution.\n\nNote\n\nNew code should use the `standard_cauchy` method of a `default_rng()` instance\ninstead; please see the Quick Start.\n\nOutput shape. If the given shape is, e.g., `(m, n, k)`, then `m * n * k`\nsamples are drawn. Default is None, in which case a single value is returned.\n\nThe drawn samples.\n\nSee also\n\nwhich should be used for new code.\n\nThe probability density function for the full Cauchy distribution is\n\nand the Standard Cauchy distribution just sets \\\\(x_0=0\\\\) and \\\\(\\gamma=1\\\\)\n\nThe Cauchy distribution arises in the solution to the driven harmonic\noscillator problem, and also describes spectral line broadening. It also\ndescribes the distribution of values at which a line tilted at a random angle\nwill cut the x axis.\n\nWhen studying hypothesis tests that assume normality, seeing how the tests\nperform on data from a Cauchy distribution is a good indicator of their\nsensitivity to a heavy-tailed distribution, since the Cauchy looks very much\nlike a Gaussian distribution, but with heavier tails.\n\nNIST/SEMATECH e-Handbook of Statistical Methods, \u201cCauchy Distribution\u201d,\nhttps://www.itl.nist.gov/div898/handbook/eda/section3/eda3663.htm\n\nWeisstein, Eric W. \u201cCauchy Distribution.\u201d From MathWorld\u2013A Wolfram Web\nResource. http://mathworld.wolfram.com/CauchyDistribution.html\n\nWikipedia, \u201cCauchy distribution\u201d\nhttps://en.wikipedia.org/wiki/Cauchy_distribution\n\nDraw samples and plot the distribution:\n\n"}, {"name": "random.RandomState.standard_exponential()", "path": "reference/random/generated/numpy.random.randomstate.standard_exponential", "type": "numpy.random.RandomState.standard_exponential", "text": "\nmethod\n\nDraw samples from the standard exponential distribution.\n\n`standard_exponential` is identical to the exponential distribution with a\nscale parameter of 1.\n\nNote\n\nNew code should use the `standard_exponential` method of a `default_rng()`\ninstance instead; please see the Quick Start.\n\nOutput shape. If the given shape is, e.g., `(m, n, k)`, then `m * n * k`\nsamples are drawn. Default is None, in which case a single value is returned.\n\nDrawn samples.\n\nSee also\n\nwhich should be used for new code.\n\nOutput a 3x8000 array:\n\n"}, {"name": "random.RandomState.standard_gamma()", "path": "reference/random/generated/numpy.random.randomstate.standard_gamma", "type": "numpy.random.RandomState.standard_gamma", "text": "\nmethod\n\nDraw samples from a standard Gamma distribution.\n\nSamples are drawn from a Gamma distribution with specified parameters, shape\n(sometimes designated \u201ck\u201d) and scale=1.\n\nNote\n\nNew code should use the `standard_gamma` method of a `default_rng()` instance\ninstead; please see the Quick Start.\n\nParameter, must be non-negative.\n\nOutput shape. If the given shape is, e.g., `(m, n, k)`, then `m * n * k`\nsamples are drawn. If size is `None` (default), a single value is returned if\n`shape` is a scalar. Otherwise, `np.array(shape).size` samples are drawn.\n\nDrawn samples from the parameterized standard gamma distribution.\n\nSee also\n\nprobability density function, distribution or cumulative density function,\netc.\n\nwhich should be used for new code.\n\nThe probability density for the Gamma distribution is\n\nwhere \\\\(k\\\\) is the shape and \\\\(\\theta\\\\) the scale, and \\\\(\\Gamma\\\\) is the\nGamma function.\n\nThe Gamma distribution is often used to model the times to failure of\nelectronic components, and arises naturally in processes for which the waiting\ntimes between Poisson distributed events are relevant.\n\nWeisstein, Eric W. \u201cGamma Distribution.\u201d From MathWorld\u2013A Wolfram Web\nResource. http://mathworld.wolfram.com/GammaDistribution.html\n\nWikipedia, \u201cGamma distribution\u201d,\nhttps://en.wikipedia.org/wiki/Gamma_distribution\n\nDraw samples from the distribution:\n\nDisplay the histogram of the samples, along with the probability density\nfunction:\n\n"}, {"name": "random.RandomState.standard_normal()", "path": "reference/random/generated/numpy.random.randomstate.standard_normal", "type": "numpy.random.RandomState.standard_normal", "text": "\nmethod\n\nDraw samples from a standard Normal distribution (mean=0, stdev=1).\n\nNote\n\nNew code should use the `standard_normal` method of a `default_rng()` instance\ninstead; please see the Quick Start.\n\nOutput shape. If the given shape is, e.g., `(m, n, k)`, then `m * n * k`\nsamples are drawn. Default is None, in which case a single value is returned.\n\nA floating-point array of shape `size` of drawn samples, or a single sample if\n`size` was not specified.\n\nSee also\n\nEquivalent function with additional `loc` and `scale` arguments for setting\nthe mean and standard deviation.\n\nwhich should be used for new code.\n\nFor random samples from \\\\(N(\\mu, \\sigma^2)\\\\), use one of:\n\nTwo-by-four array of samples from \\\\(N(3, 6.25)\\\\):\n\n"}, {"name": "random.RandomState.standard_t()", "path": "reference/random/generated/numpy.random.randomstate.standard_t", "type": "numpy.random.RandomState.standard_t", "text": "\nmethod\n\nDraw samples from a standard Student\u2019s t distribution with `df` degrees of\nfreedom.\n\nA special case of the hyperbolic distribution. As `df` gets large, the result\nresembles that of the standard normal distribution (`standard_normal`).\n\nNote\n\nNew code should use the `standard_t` method of a `default_rng()` instance\ninstead; please see the Quick Start.\n\nDegrees of freedom, must be > 0.\n\nOutput shape. If the given shape is, e.g., `(m, n, k)`, then `m * n * k`\nsamples are drawn. If size is `None` (default), a single value is returned if\n`df` is a scalar. Otherwise, `np.array(df).size` samples are drawn.\n\nDrawn samples from the parameterized standard Student\u2019s t distribution.\n\nSee also\n\nwhich should be used for new code.\n\nThe probability density function for the t distribution is\n\nThe t test is based on an assumption that the data come from a Normal\ndistribution. The t test provides a way to test whether the sample mean (that\nis the mean calculated from the data) is a good estimate of the true mean.\n\nThe derivation of the t-distribution was first published in 1908 by William\nGosset while working for the Guinness Brewery in Dublin. Due to proprietary\nissues, he had to publish under a pseudonym, and so he used the name Student.\n\nDalgaard, Peter, \u201cIntroductory Statistics With R\u201d, Springer, 2002.\n\nWikipedia, \u201cStudent\u2019s t-distribution\u201d\nhttps://en.wikipedia.org/wiki/Student\u2019s_t-distribution\n\nFrom Dalgaard page 83 [1], suppose the daily energy intake for 11 women in\nkilojoules (kJ) is:\n\nDoes their energy intake deviate systematically from the recommended value of\n7725 kJ? Our null hypothesis will be the absence of deviation, and the\nalternate hypothesis will be the presence of an effect that could be either\npositive or negative, hence making our test 2-tailed.\n\nBecause we are estimating the mean and we have N=11 values in our sample, we\nhave N-1=10 degrees of freedom. We set our significance level to 95% and\ncompute the t statistic using the empirical mean and empirical standard\ndeviation of our intake. We use a ddof of 1 to base the computation of our\nempirical standard deviation on an unbiased estimate of the variance (note:\nthe final estimate is not unbiased due to the concave nature of the square\nroot).\n\nWe draw 1000000 samples from Student\u2019s t distribution with the adequate\ndegrees of freedom.\n\nDoes our t statistic land in one of the two critical regions found at both\ntails of the distribution?\n\nThe probability value for this 2-tailed test is about 1.83%, which is lower\nthan the 5% pre-determined significance threshold.\n\nTherefore, the probability of observing values as extreme as our intake\nconditionally on the null hypothesis being true is too low, and we reject the\nnull hypothesis of no deviation.\n\n"}, {"name": "random.RandomState.triangular()", "path": "reference/random/generated/numpy.random.randomstate.triangular", "type": "numpy.random.RandomState.triangular", "text": "\nmethod\n\nDraw samples from the triangular distribution over the interval `[left,\nright]`.\n\nThe triangular distribution is a continuous probability distribution with\nlower limit left, peak at mode, and upper limit right. Unlike the other\ndistributions, these parameters directly define the shape of the pdf.\n\nNote\n\nNew code should use the `triangular` method of a `default_rng()` instance\ninstead; please see the Quick Start.\n\nLower limit.\n\nThe value where the peak of the distribution occurs. The value must fulfill\nthe condition `left <= mode <= right`.\n\nUpper limit, must be larger than `left`.\n\nOutput shape. If the given shape is, e.g., `(m, n, k)`, then `m * n * k`\nsamples are drawn. If size is `None` (default), a single value is returned if\n`left`, `mode`, and `right` are all scalars. Otherwise, `np.broadcast(left,\nmode, right).size` samples are drawn.\n\nDrawn samples from the parameterized triangular distribution.\n\nSee also\n\nwhich should be used for new code.\n\nThe probability density function for the triangular distribution is\n\nThe triangular distribution is often used in ill-defined problems where the\nunderlying distribution is not known, but some knowledge of the limits and\nmode exists. Often it is used in simulations.\n\nWikipedia, \u201cTriangular distribution\u201d\nhttps://en.wikipedia.org/wiki/Triangular_distribution\n\nDraw values from the distribution and plot the histogram:\n\n"}, {"name": "random.RandomState.uniform()", "path": "reference/random/generated/numpy.random.randomstate.uniform", "type": "numpy.random.RandomState.uniform", "text": "\nmethod\n\nDraw samples from a uniform distribution.\n\nSamples are uniformly distributed over the half-open interval `[low, high)`\n(includes low, but excludes high). In other words, any value within the given\ninterval is equally likely to be drawn by `uniform`.\n\nNote\n\nNew code should use the `uniform` method of a `default_rng()` instance\ninstead; please see the Quick Start.\n\nLower boundary of the output interval. All values generated will be greater\nthan or equal to low. The default value is 0.\n\nUpper boundary of the output interval. All values generated will be less than\nor equal to high. The high limit may be included in the returned array of\nfloats due to floating-point rounding in the equation `low + (high-low) *\nrandom_sample()`. The default value is 1.0.\n\nOutput shape. If the given shape is, e.g., `(m, n, k)`, then `m * n * k`\nsamples are drawn. If size is `None` (default), a single value is returned if\n`low` and `high` are both scalars. Otherwise, `np.broadcast(low, high).size`\nsamples are drawn.\n\nDrawn samples from the parameterized uniform distribution.\n\nSee also\n\nDiscrete uniform distribution, yielding integers.\n\nDiscrete uniform distribution over the closed interval `[low, high]`.\n\nFloats uniformly distributed over `[0, 1)`.\n\nAlias for `random_sample`.\n\nConvenience function that accepts dimensions as input, e.g., `rand(2,2)` would\ngenerate a 2-by-2 array of floats, uniformly distributed over `[0, 1)`.\n\nwhich should be used for new code.\n\nThe probability density function of the uniform distribution is\n\nanywhere within the interval `[a, b)`, and zero elsewhere.\n\nWhen `high` == `low`, values of `low` will be returned. If `high` < `low`, the\nresults are officially undefined and may eventually raise an error, i.e. do\nnot rely on this function to behave when passed arguments satisfying that\ninequality condition. The `high` limit may be included in the returned array\nof floats due to floating-point rounding in the equation `low + (high-low) *\nrandom_sample()`. For example:\n\nDraw samples from the distribution:\n\nAll values are within the given interval:\n\nDisplay the histogram of the samples, along with the probability density\nfunction:\n\n"}, {"name": "random.RandomState.vonmises()", "path": "reference/random/generated/numpy.random.randomstate.vonmises", "type": "numpy.random.RandomState.vonmises", "text": "\nmethod\n\nDraw samples from a von Mises distribution.\n\nSamples are drawn from a von Mises distribution with specified mode (mu) and\ndispersion (kappa), on the interval [-pi, pi].\n\nThe von Mises distribution (also known as the circular normal distribution) is\na continuous probability distribution on the unit circle. It may be thought of\nas the circular analogue of the normal distribution.\n\nNote\n\nNew code should use the `vonmises` method of a `default_rng()` instance\ninstead; please see the Quick Start.\n\nMode (\u201ccenter\u201d) of the distribution.\n\nDispersion of the distribution, has to be >=0.\n\nOutput shape. If the given shape is, e.g., `(m, n, k)`, then `m * n * k`\nsamples are drawn. If size is `None` (default), a single value is returned if\n`mu` and `kappa` are both scalars. Otherwise, `np.broadcast(mu, kappa).size`\nsamples are drawn.\n\nDrawn samples from the parameterized von Mises distribution.\n\nSee also\n\nprobability density function, distribution, or cumulative density function,\netc.\n\nwhich should be used for new code.\n\nThe probability density for the von Mises distribution is\n\nwhere \\\\(\\mu\\\\) is the mode and \\\\(\\kappa\\\\) the dispersion, and\n\\\\(I_0(\\kappa)\\\\) is the modified Bessel function of order 0.\n\nThe von Mises is named for Richard Edler von Mises, who was born in Austria-\nHungary, in what is now the Ukraine. He fled to the United States in 1939 and\nbecame a professor at Harvard. He worked in probability theory, aerodynamics,\nfluid mechanics, and philosophy of science.\n\nAbramowitz, M. and Stegun, I. A. (Eds.). \u201cHandbook of Mathematical Functions\nwith Formulas, Graphs, and Mathematical Tables, 9th printing,\u201d New York:\nDover, 1972.\n\nvon Mises, R., \u201cMathematical Theory of Probability and Statistics\u201d, New York:\nAcademic Press, 1964.\n\nDraw samples from the distribution:\n\nDisplay the histogram of the samples, along with the probability density\nfunction:\n\n"}, {"name": "random.RandomState.wald()", "path": "reference/random/generated/numpy.random.randomstate.wald", "type": "numpy.random.RandomState.wald", "text": "\nmethod\n\nDraw samples from a Wald, or inverse Gaussian, distribution.\n\nAs the scale approaches infinity, the distribution becomes more like a\nGaussian. Some references claim that the Wald is an inverse Gaussian with mean\nequal to 1, but this is by no means universal.\n\nThe inverse Gaussian distribution was first studied in relationship to\nBrownian motion. In 1956 M.C.K. Tweedie used the name inverse Gaussian because\nthere is an inverse relationship between the time to cover a unit distance and\ndistance covered in unit time.\n\nNote\n\nNew code should use the `wald` method of a `default_rng()` instance instead;\nplease see the Quick Start.\n\nDistribution mean, must be > 0.\n\nScale parameter, must be > 0.\n\nOutput shape. If the given shape is, e.g., `(m, n, k)`, then `m * n * k`\nsamples are drawn. If size is `None` (default), a single value is returned if\n`mean` and `scale` are both scalars. Otherwise, `np.broadcast(mean,\nscale).size` samples are drawn.\n\nDrawn samples from the parameterized Wald distribution.\n\nSee also\n\nwhich should be used for new code.\n\nThe probability density function for the Wald distribution is\n\nAs noted above the inverse Gaussian distribution first arise from attempts to\nmodel Brownian motion. It is also a competitor to the Weibull for use in\nreliability modeling and modeling stock returns and interest rate processes.\n\nBrighton Webs Ltd., Wald Distribution,\nhttps://web.archive.org/web/20090423014010/http://www.brighton-\nwebs.co.uk:80/distributions/wald.asp\n\nChhikara, Raj S., and Folks, J. Leroy, \u201cThe Inverse Gaussian Distribution:\nTheory : Methodology, and Applications\u201d, CRC Press, 1988.\n\nWikipedia, \u201cInverse Gaussian distribution\u201d\nhttps://en.wikipedia.org/wiki/Inverse_Gaussian_distribution\n\nDraw values from the distribution and plot the histogram:\n\n"}, {"name": "random.RandomState.weibull()", "path": "reference/random/generated/numpy.random.randomstate.weibull", "type": "numpy.random.RandomState.weibull", "text": "\nmethod\n\nDraw samples from a Weibull distribution.\n\nDraw samples from a 1-parameter Weibull distribution with the given shape\nparameter `a`.\n\nHere, U is drawn from the uniform distribution over (0,1].\n\nThe more common 2-parameter Weibull, including a scale parameter \\\\(\\lambda\\\\)\nis just \\\\(X = \\lambda(-ln(U))^{1/a}\\\\).\n\nNote\n\nNew code should use the `weibull` method of a `default_rng()` instance\ninstead; please see the Quick Start.\n\nShape parameter of the distribution. Must be nonnegative.\n\nOutput shape. If the given shape is, e.g., `(m, n, k)`, then `m * n * k`\nsamples are drawn. If size is `None` (default), a single value is returned if\n`a` is a scalar. Otherwise, `np.array(a).size` samples are drawn.\n\nDrawn samples from the parameterized Weibull distribution.\n\nSee also\n\nwhich should be used for new code.\n\nThe Weibull (or Type III asymptotic extreme value distribution for smallest\nvalues, SEV Type III, or Rosin-Rammler distribution) is one of a class of\nGeneralized Extreme Value (GEV) distributions used in modeling extreme value\nproblems. This class includes the Gumbel and Frechet distributions.\n\nThe probability density for the Weibull distribution is\n\nwhere \\\\(a\\\\) is the shape and \\\\(\\lambda\\\\) the scale.\n\nThe function has its peak (the mode) at \\\\(\\lambda(\\frac{a-1}{a})^{1/a}\\\\).\n\nWhen `a = 1`, the Weibull distribution reduces to the exponential\ndistribution.\n\nWaloddi Weibull, Royal Technical University, Stockholm, 1939 \u201cA Statistical\nTheory Of The Strength Of Materials\u201d, Ingeniorsvetenskapsakademiens Handlingar\nNr 151, 1939, Generalstabens Litografiska Anstalts Forlag, Stockholm.\n\nWaloddi Weibull, \u201cA Statistical Distribution Function of Wide Applicability\u201d,\nJournal Of Applied Mechanics ASME Paper 1951.\n\nWikipedia, \u201cWeibull distribution\u201d,\nhttps://en.wikipedia.org/wiki/Weibull_distribution\n\nDraw samples from the distribution:\n\nDisplay the histogram of the samples, along with the probability density\nfunction:\n\n"}, {"name": "random.RandomState.zipf()", "path": "reference/random/generated/numpy.random.randomstate.zipf", "type": "numpy.random.RandomState.zipf", "text": "\nmethod\n\nDraw samples from a Zipf distribution.\n\nSamples are drawn from a Zipf distribution with specified parameter `a` > 1.\n\nThe Zipf distribution (also known as the zeta distribution) is a discrete\nprobability distribution that satisfies Zipf\u2019s law: the frequency of an item\nis inversely proportional to its rank in a frequency table.\n\nNote\n\nNew code should use the `zipf` method of a `default_rng()` instance instead;\nplease see the Quick Start.\n\nDistribution parameter. Must be greater than 1.\n\nOutput shape. If the given shape is, e.g., `(m, n, k)`, then `m * n * k`\nsamples are drawn. If size is `None` (default), a single value is returned if\n`a` is a scalar. Otherwise, `np.array(a).size` samples are drawn.\n\nDrawn samples from the parameterized Zipf distribution.\n\nSee also\n\nprobability density function, distribution, or cumulative density function,\netc.\n\nwhich should be used for new code.\n\nThe probability density for the Zipf distribution is\n\nfor integers \\\\(k \\geq 1\\\\), where \\\\(\\zeta\\\\) is the Riemann Zeta function.\n\nIt is named for the American linguist George Kingsley Zipf, who noted that the\nfrequency of any word in a sample of a language is inversely proportional to\nits rank in the frequency table.\n\nZipf, G. K., \u201cSelected Studies of the Principle of Relative Frequency in\nLanguage,\u201d Cambridge, MA: Harvard Univ. Press, 1932.\n\nDraw samples from the distribution:\n\nDisplay the histogram of the samples, along with the expected histogram based\non the probability density function:\n\n`bincount` provides a fast histogram for small integers.\n\n"}, {"name": "random.ranf()", "path": "reference/random/generated/numpy.random.ranf", "type": "numpy.random.ranf", "text": "\nThis is an alias of `random_sample`. See `random_sample` for the complete\ndocumentation.\n\n"}, {"name": "random.rayleigh()", "path": "reference/random/generated/numpy.random.rayleigh", "type": "numpy.random.rayleigh", "text": "\nDraw samples from a Rayleigh distribution.\n\nThe \\\\(\\chi\\\\) and Weibull distributions are generalizations of the Rayleigh.\n\nNote\n\nNew code should use the `rayleigh` method of a `default_rng()` instance\ninstead; please see the Quick Start.\n\nScale, also equals the mode. Must be non-negative. Default is 1.\n\nOutput shape. If the given shape is, e.g., `(m, n, k)`, then `m * n * k`\nsamples are drawn. If size is `None` (default), a single value is returned if\n`scale` is a scalar. Otherwise, `np.array(scale).size` samples are drawn.\n\nDrawn samples from the parameterized Rayleigh distribution.\n\nSee also\n\nwhich should be used for new code.\n\nThe probability density function for the Rayleigh distribution is\n\nThe Rayleigh distribution would arise, for example, if the East and North\ncomponents of the wind velocity had identical zero-mean Gaussian\ndistributions. Then the wind speed would have a Rayleigh distribution.\n\nBrighton Webs Ltd., \u201cRayleigh Distribution,\u201d\nhttps://web.archive.org/web/20090514091424/http://brighton-\nwebs.co.uk:80/distributions/rayleigh.asp\n\nWikipedia, \u201cRayleigh distribution\u201d\nhttps://en.wikipedia.org/wiki/Rayleigh_distribution\n\nDraw values from the distribution and plot the histogram\n\nWave heights tend to follow a Rayleigh distribution. If the mean wave height\nis 1 meter, what fraction of waves are likely to be larger than 3 meters?\n\nThe percentage of waves larger than 3 meters is:\n\n"}, {"name": "random.sample()", "path": "reference/random/generated/numpy.random.sample", "type": "numpy.random.sample", "text": "\nThis is an alias of `random_sample`. See `random_sample` for the complete\ndocumentation.\n\n"}, {"name": "random.seed()", "path": "reference/random/generated/numpy.random.seed", "type": "numpy.random.seed", "text": "\nReseed a legacy MT19937 BitGenerator\n\nThis is a convenience, legacy function.\n\nThe best practice is to not reseed a BitGenerator, rather to recreate a new\none. This method is here for legacy reasons. This example demonstrates best\npractice.\n\n"}, {"name": "random.SeedSequence.entropy", "path": "reference/random/bit_generators/generated/numpy.random.seedsequence.entropy", "type": "Random sampling", "text": "\nattribute\n\n"}, {"name": "random.SeedSequence.generate_state()", "path": "reference/random/bit_generators/generated/numpy.random.seedsequence.generate_state", "type": "Random sampling ( \n      \n       numpy.random\n      \n      )", "text": "\nmethod\n\nReturn the requested number of words for PRNG seeding.\n\nA BitGenerator should call this method in its constructor with an appropriate\n`n_words` parameter to properly seed itself.\n\nThe size of each word. This should only be either `uint32` or `uint64`.\nStrings (`\u2018uint32\u2019`, `\u2018uint64\u2019`) are fine. Note that requesting `uint64` will\ndraw twice as many bits as `uint32` for the same `n_words`. This is a\nconvenience for `BitGenerator`s that express their states as `uint64` arrays.\n\n"}, {"name": "random.SeedSequence.spawn()", "path": "reference/random/bit_generators/generated/numpy.random.seedsequence.spawn", "type": "Random sampling ( \n      \n       numpy.random\n      \n      )", "text": "\nmethod\n\nSpawn a number of child `SeedSequence` s by extending the `spawn_key`.\n\n"}, {"name": "random.SeedSequence.spawn_key", "path": "reference/random/bit_generators/generated/numpy.random.seedsequence.spawn_key", "type": "Random sampling", "text": "\nattribute\n\n"}, {"name": "random.set_state()", "path": "reference/random/generated/numpy.random.set_state", "type": "numpy.random.set_state", "text": "\nSet the internal state of the generator from a tuple.\n\nFor use if one has reason to manually (re-)set the internal state of the bit\ngenerator used by the RandomState instance. By default, RandomState uses the\n\u201cMersenne Twister\u201d[1] pseudo-random number generating algorithm.\n\nThe `state` tuple has the following items:\n\nIf state is a dictionary, it is directly set using the BitGenerators `state`\nproperty.\n\nReturns \u2018None\u2019 on success.\n\nSee also\n\n`set_state` and `get_state` are not needed to work with any of the random\ndistributions in NumPy. If the internal state is manually altered, the user\nshould know exactly what he/she is doing.\n\nFor backwards compatibility, the form (str, array of 624 uints, int) is also\naccepted although it is missing some information about the cached Gaussian\nvalue: `state = ('MT19937', keys, pos)`.\n\nM. Matsumoto and T. Nishimura, \u201cMersenne Twister: A 623-dimensionally\nequidistributed uniform pseudorandom number generator,\u201d ACM Trans. on Modeling\nand Computer Simulation, Vol. 8, No. 1, pp. 3-30, Jan. 1998.\n\n"}, {"name": "random.SFC64.cffi", "path": "reference/random/bit_generators/generated/numpy.random.sfc64.cffi", "type": "SFC64", "text": "\nattribute\n\nCFFI interface\n\nNamed tuple containing CFFI wrapper\n\n"}, {"name": "random.SFC64.ctypes", "path": "reference/random/bit_generators/generated/numpy.random.sfc64.ctypes", "type": "SFC64", "text": "\nattribute\n\nctypes interface\n\nNamed tuple containing ctypes wrapper\n\n"}, {"name": "random.SFC64.state", "path": "reference/random/bit_generators/generated/numpy.random.sfc64.state", "type": "SFC64", "text": "\nattribute\n\nGet or set the PRNG state\n\nDictionary containing the information required to describe the state of the\nPRNG\n\n"}, {"name": "random.shuffle()", "path": "reference/random/generated/numpy.random.shuffle", "type": "numpy.random.shuffle", "text": "\nModify a sequence in-place by shuffling its contents.\n\nThis function only shuffles the array along the first axis of a multi-\ndimensional array. The order of sub-arrays is changed but their contents\nremains the same.\n\nNote\n\nNew code should use the `shuffle` method of a `default_rng()` instance\ninstead; please see the Quick Start.\n\nThe array, list or mutable sequence to be shuffled.\n\nSee also\n\nwhich should be used for new code.\n\nMulti-dimensional arrays are only shuffled along the first axis:\n\n"}, {"name": "random.standard_cauchy()", "path": "reference/random/generated/numpy.random.standard_cauchy", "type": "numpy.random.standard_cauchy", "text": "\nDraw samples from a standard Cauchy distribution with mode = 0.\n\nAlso known as the Lorentz distribution.\n\nNote\n\nNew code should use the `standard_cauchy` method of a `default_rng()` instance\ninstead; please see the Quick Start.\n\nOutput shape. If the given shape is, e.g., `(m, n, k)`, then `m * n * k`\nsamples are drawn. Default is None, in which case a single value is returned.\n\nThe drawn samples.\n\nSee also\n\nwhich should be used for new code.\n\nThe probability density function for the full Cauchy distribution is\n\nand the Standard Cauchy distribution just sets \\\\(x_0=0\\\\) and \\\\(\\gamma=1\\\\)\n\nThe Cauchy distribution arises in the solution to the driven harmonic\noscillator problem, and also describes spectral line broadening. It also\ndescribes the distribution of values at which a line tilted at a random angle\nwill cut the x axis.\n\nWhen studying hypothesis tests that assume normality, seeing how the tests\nperform on data from a Cauchy distribution is a good indicator of their\nsensitivity to a heavy-tailed distribution, since the Cauchy looks very much\nlike a Gaussian distribution, but with heavier tails.\n\nNIST/SEMATECH e-Handbook of Statistical Methods, \u201cCauchy Distribution\u201d,\nhttps://www.itl.nist.gov/div898/handbook/eda/section3/eda3663.htm\n\nWeisstein, Eric W. \u201cCauchy Distribution.\u201d From MathWorld\u2013A Wolfram Web\nResource. http://mathworld.wolfram.com/CauchyDistribution.html\n\nWikipedia, \u201cCauchy distribution\u201d\nhttps://en.wikipedia.org/wiki/Cauchy_distribution\n\nDraw samples and plot the distribution:\n\n"}, {"name": "random.standard_exponential()", "path": "reference/random/generated/numpy.random.standard_exponential", "type": "numpy.random.standard_exponential", "text": "\nDraw samples from the standard exponential distribution.\n\n`standard_exponential` is identical to the exponential distribution with a\nscale parameter of 1.\n\nNote\n\nNew code should use the `standard_exponential` method of a `default_rng()`\ninstance instead; please see the Quick Start.\n\nOutput shape. If the given shape is, e.g., `(m, n, k)`, then `m * n * k`\nsamples are drawn. Default is None, in which case a single value is returned.\n\nDrawn samples.\n\nSee also\n\nwhich should be used for new code.\n\nOutput a 3x8000 array:\n\n"}, {"name": "random.standard_gamma()", "path": "reference/random/generated/numpy.random.standard_gamma", "type": "numpy.random.standard_gamma", "text": "\nDraw samples from a standard Gamma distribution.\n\nSamples are drawn from a Gamma distribution with specified parameters, shape\n(sometimes designated \u201ck\u201d) and scale=1.\n\nNote\n\nNew code should use the `standard_gamma` method of a `default_rng()` instance\ninstead; please see the Quick Start.\n\nParameter, must be non-negative.\n\nOutput shape. If the given shape is, e.g., `(m, n, k)`, then `m * n * k`\nsamples are drawn. If size is `None` (default), a single value is returned if\n`shape` is a scalar. Otherwise, `np.array(shape).size` samples are drawn.\n\nDrawn samples from the parameterized standard gamma distribution.\n\nSee also\n\nprobability density function, distribution or cumulative density function,\netc.\n\nwhich should be used for new code.\n\nThe probability density for the Gamma distribution is\n\nwhere \\\\(k\\\\) is the shape and \\\\(\\theta\\\\) the scale, and \\\\(\\Gamma\\\\) is the\nGamma function.\n\nThe Gamma distribution is often used to model the times to failure of\nelectronic components, and arises naturally in processes for which the waiting\ntimes between Poisson distributed events are relevant.\n\nWeisstein, Eric W. \u201cGamma Distribution.\u201d From MathWorld\u2013A Wolfram Web\nResource. http://mathworld.wolfram.com/GammaDistribution.html\n\nWikipedia, \u201cGamma distribution\u201d,\nhttps://en.wikipedia.org/wiki/Gamma_distribution\n\nDraw samples from the distribution:\n\nDisplay the histogram of the samples, along with the probability density\nfunction:\n\n"}, {"name": "random.standard_normal()", "path": "reference/random/generated/numpy.random.standard_normal", "type": "numpy.random.standard_normal", "text": "\nDraw samples from a standard Normal distribution (mean=0, stdev=1).\n\nNote\n\nNew code should use the `standard_normal` method of a `default_rng()` instance\ninstead; please see the Quick Start.\n\nOutput shape. If the given shape is, e.g., `(m, n, k)`, then `m * n * k`\nsamples are drawn. Default is None, in which case a single value is returned.\n\nA floating-point array of shape `size` of drawn samples, or a single sample if\n`size` was not specified.\n\nSee also\n\nEquivalent function with additional `loc` and `scale` arguments for setting\nthe mean and standard deviation.\n\nwhich should be used for new code.\n\nFor random samples from \\\\(N(\\mu, \\sigma^2)\\\\), use one of:\n\nTwo-by-four array of samples from \\\\(N(3, 6.25)\\\\):\n\n"}, {"name": "random.standard_t()", "path": "reference/random/generated/numpy.random.standard_t", "type": "numpy.random.standard_t", "text": "\nDraw samples from a standard Student\u2019s t distribution with `df` degrees of\nfreedom.\n\nA special case of the hyperbolic distribution. As `df` gets large, the result\nresembles that of the standard normal distribution (`standard_normal`).\n\nNote\n\nNew code should use the `standard_t` method of a `default_rng()` instance\ninstead; please see the Quick Start.\n\nDegrees of freedom, must be > 0.\n\nOutput shape. If the given shape is, e.g., `(m, n, k)`, then `m * n * k`\nsamples are drawn. If size is `None` (default), a single value is returned if\n`df` is a scalar. Otherwise, `np.array(df).size` samples are drawn.\n\nDrawn samples from the parameterized standard Student\u2019s t distribution.\n\nSee also\n\nwhich should be used for new code.\n\nThe probability density function for the t distribution is\n\nThe t test is based on an assumption that the data come from a Normal\ndistribution. The t test provides a way to test whether the sample mean (that\nis the mean calculated from the data) is a good estimate of the true mean.\n\nThe derivation of the t-distribution was first published in 1908 by William\nGosset while working for the Guinness Brewery in Dublin. Due to proprietary\nissues, he had to publish under a pseudonym, and so he used the name Student.\n\nDalgaard, Peter, \u201cIntroductory Statistics With R\u201d, Springer, 2002.\n\nWikipedia, \u201cStudent\u2019s t-distribution\u201d\nhttps://en.wikipedia.org/wiki/Student\u2019s_t-distribution\n\nFrom Dalgaard page 83 [1], suppose the daily energy intake for 11 women in\nkilojoules (kJ) is:\n\nDoes their energy intake deviate systematically from the recommended value of\n7725 kJ? Our null hypothesis will be the absence of deviation, and the\nalternate hypothesis will be the presence of an effect that could be either\npositive or negative, hence making our test 2-tailed.\n\nBecause we are estimating the mean and we have N=11 values in our sample, we\nhave N-1=10 degrees of freedom. We set our significance level to 95% and\ncompute the t statistic using the empirical mean and empirical standard\ndeviation of our intake. We use a ddof of 1 to base the computation of our\nempirical standard deviation on an unbiased estimate of the variance (note:\nthe final estimate is not unbiased due to the concave nature of the square\nroot).\n\nWe draw 1000000 samples from Student\u2019s t distribution with the adequate\ndegrees of freedom.\n\nDoes our t statistic land in one of the two critical regions found at both\ntails of the distribution?\n\nThe probability value for this 2-tailed test is about 1.83%, which is lower\nthan the 5% pre-determined significance threshold.\n\nTherefore, the probability of observing values as extreme as our intake\nconditionally on the null hypothesis being true is too low, and we reject the\nnull hypothesis of no deviation.\n\n"}, {"name": "random.triangular()", "path": "reference/random/generated/numpy.random.triangular", "type": "numpy.random.triangular", "text": "\nDraw samples from the triangular distribution over the interval `[left,\nright]`.\n\nThe triangular distribution is a continuous probability distribution with\nlower limit left, peak at mode, and upper limit right. Unlike the other\ndistributions, these parameters directly define the shape of the pdf.\n\nNote\n\nNew code should use the `triangular` method of a `default_rng()` instance\ninstead; please see the Quick Start.\n\nLower limit.\n\nThe value where the peak of the distribution occurs. The value must fulfill\nthe condition `left <= mode <= right`.\n\nUpper limit, must be larger than `left`.\n\nOutput shape. If the given shape is, e.g., `(m, n, k)`, then `m * n * k`\nsamples are drawn. If size is `None` (default), a single value is returned if\n`left`, `mode`, and `right` are all scalars. Otherwise, `np.broadcast(left,\nmode, right).size` samples are drawn.\n\nDrawn samples from the parameterized triangular distribution.\n\nSee also\n\nwhich should be used for new code.\n\nThe probability density function for the triangular distribution is\n\nThe triangular distribution is often used in ill-defined problems where the\nunderlying distribution is not known, but some knowledge of the limits and\nmode exists. Often it is used in simulations.\n\nWikipedia, \u201cTriangular distribution\u201d\nhttps://en.wikipedia.org/wiki/Triangular_distribution\n\nDraw values from the distribution and plot the histogram:\n\n"}, {"name": "random.uniform()", "path": "reference/random/generated/numpy.random.uniform", "type": "numpy.random.uniform", "text": "\nDraw samples from a uniform distribution.\n\nSamples are uniformly distributed over the half-open interval `[low, high)`\n(includes low, but excludes high). In other words, any value within the given\ninterval is equally likely to be drawn by `uniform`.\n\nNote\n\nNew code should use the `uniform` method of a `default_rng()` instance\ninstead; please see the Quick Start.\n\nLower boundary of the output interval. All values generated will be greater\nthan or equal to low. The default value is 0.\n\nUpper boundary of the output interval. All values generated will be less than\nor equal to high. The high limit may be included in the returned array of\nfloats due to floating-point rounding in the equation `low + (high-low) *\nrandom_sample()`. The default value is 1.0.\n\nOutput shape. If the given shape is, e.g., `(m, n, k)`, then `m * n * k`\nsamples are drawn. If size is `None` (default), a single value is returned if\n`low` and `high` are both scalars. Otherwise, `np.broadcast(low, high).size`\nsamples are drawn.\n\nDrawn samples from the parameterized uniform distribution.\n\nSee also\n\nDiscrete uniform distribution, yielding integers.\n\nDiscrete uniform distribution over the closed interval `[low, high]`.\n\nFloats uniformly distributed over `[0, 1)`.\n\nAlias for `random_sample`.\n\nConvenience function that accepts dimensions as input, e.g., `rand(2,2)` would\ngenerate a 2-by-2 array of floats, uniformly distributed over `[0, 1)`.\n\nwhich should be used for new code.\n\nThe probability density function of the uniform distribution is\n\nanywhere within the interval `[a, b)`, and zero elsewhere.\n\nWhen `high` == `low`, values of `low` will be returned. If `high` < `low`, the\nresults are officially undefined and may eventually raise an error, i.e. do\nnot rely on this function to behave when passed arguments satisfying that\ninequality condition. The `high` limit may be included in the returned array\nof floats due to floating-point rounding in the equation `low + (high-low) *\nrandom_sample()`. For example:\n\nDraw samples from the distribution:\n\nAll values are within the given interval:\n\nDisplay the histogram of the samples, along with the probability density\nfunction:\n\n"}, {"name": "random.vonmises()", "path": "reference/random/generated/numpy.random.vonmises", "type": "numpy.random.vonmises", "text": "\nDraw samples from a von Mises distribution.\n\nSamples are drawn from a von Mises distribution with specified mode (mu) and\ndispersion (kappa), on the interval [-pi, pi].\n\nThe von Mises distribution (also known as the circular normal distribution) is\na continuous probability distribution on the unit circle. It may be thought of\nas the circular analogue of the normal distribution.\n\nNote\n\nNew code should use the `vonmises` method of a `default_rng()` instance\ninstead; please see the Quick Start.\n\nMode (\u201ccenter\u201d) of the distribution.\n\nDispersion of the distribution, has to be >=0.\n\nOutput shape. If the given shape is, e.g., `(m, n, k)`, then `m * n * k`\nsamples are drawn. If size is `None` (default), a single value is returned if\n`mu` and `kappa` are both scalars. Otherwise, `np.broadcast(mu, kappa).size`\nsamples are drawn.\n\nDrawn samples from the parameterized von Mises distribution.\n\nSee also\n\nprobability density function, distribution, or cumulative density function,\netc.\n\nwhich should be used for new code.\n\nThe probability density for the von Mises distribution is\n\nwhere \\\\(\\mu\\\\) is the mode and \\\\(\\kappa\\\\) the dispersion, and\n\\\\(I_0(\\kappa)\\\\) is the modified Bessel function of order 0.\n\nThe von Mises is named for Richard Edler von Mises, who was born in Austria-\nHungary, in what is now the Ukraine. He fled to the United States in 1939 and\nbecame a professor at Harvard. He worked in probability theory, aerodynamics,\nfluid mechanics, and philosophy of science.\n\nAbramowitz, M. and Stegun, I. A. (Eds.). \u201cHandbook of Mathematical Functions\nwith Formulas, Graphs, and Mathematical Tables, 9th printing,\u201d New York:\nDover, 1972.\n\nvon Mises, R., \u201cMathematical Theory of Probability and Statistics\u201d, New York:\nAcademic Press, 1964.\n\nDraw samples from the distribution:\n\nDisplay the histogram of the samples, along with the probability density\nfunction:\n\n"}, {"name": "random.wald()", "path": "reference/random/generated/numpy.random.wald", "type": "numpy.random.wald", "text": "\nDraw samples from a Wald, or inverse Gaussian, distribution.\n\nAs the scale approaches infinity, the distribution becomes more like a\nGaussian. Some references claim that the Wald is an inverse Gaussian with mean\nequal to 1, but this is by no means universal.\n\nThe inverse Gaussian distribution was first studied in relationship to\nBrownian motion. In 1956 M.C.K. Tweedie used the name inverse Gaussian because\nthere is an inverse relationship between the time to cover a unit distance and\ndistance covered in unit time.\n\nNote\n\nNew code should use the `wald` method of a `default_rng()` instance instead;\nplease see the Quick Start.\n\nDistribution mean, must be > 0.\n\nScale parameter, must be > 0.\n\nOutput shape. If the given shape is, e.g., `(m, n, k)`, then `m * n * k`\nsamples are drawn. If size is `None` (default), a single value is returned if\n`mean` and `scale` are both scalars. Otherwise, `np.broadcast(mean,\nscale).size` samples are drawn.\n\nDrawn samples from the parameterized Wald distribution.\n\nSee also\n\nwhich should be used for new code.\n\nThe probability density function for the Wald distribution is\n\nAs noted above the inverse Gaussian distribution first arise from attempts to\nmodel Brownian motion. It is also a competitor to the Weibull for use in\nreliability modeling and modeling stock returns and interest rate processes.\n\nBrighton Webs Ltd., Wald Distribution,\nhttps://web.archive.org/web/20090423014010/http://www.brighton-\nwebs.co.uk:80/distributions/wald.asp\n\nChhikara, Raj S., and Folks, J. Leroy, \u201cThe Inverse Gaussian Distribution:\nTheory : Methodology, and Applications\u201d, CRC Press, 1988.\n\nWikipedia, \u201cInverse Gaussian distribution\u201d\nhttps://en.wikipedia.org/wiki/Inverse_Gaussian_distribution\n\nDraw values from the distribution and plot the histogram:\n\n"}, {"name": "random.weibull()", "path": "reference/random/generated/numpy.random.weibull", "type": "numpy.random.weibull", "text": "\nDraw samples from a Weibull distribution.\n\nDraw samples from a 1-parameter Weibull distribution with the given shape\nparameter `a`.\n\nHere, U is drawn from the uniform distribution over (0,1].\n\nThe more common 2-parameter Weibull, including a scale parameter \\\\(\\lambda\\\\)\nis just \\\\(X = \\lambda(-ln(U))^{1/a}\\\\).\n\nNote\n\nNew code should use the `weibull` method of a `default_rng()` instance\ninstead; please see the Quick Start.\n\nShape parameter of the distribution. Must be nonnegative.\n\nOutput shape. If the given shape is, e.g., `(m, n, k)`, then `m * n * k`\nsamples are drawn. If size is `None` (default), a single value is returned if\n`a` is a scalar. Otherwise, `np.array(a).size` samples are drawn.\n\nDrawn samples from the parameterized Weibull distribution.\n\nSee also\n\nwhich should be used for new code.\n\nThe Weibull (or Type III asymptotic extreme value distribution for smallest\nvalues, SEV Type III, or Rosin-Rammler distribution) is one of a class of\nGeneralized Extreme Value (GEV) distributions used in modeling extreme value\nproblems. This class includes the Gumbel and Frechet distributions.\n\nThe probability density for the Weibull distribution is\n\nwhere \\\\(a\\\\) is the shape and \\\\(\\lambda\\\\) the scale.\n\nThe function has its peak (the mode) at \\\\(\\lambda(\\frac{a-1}{a})^{1/a}\\\\).\n\nWhen `a = 1`, the Weibull distribution reduces to the exponential\ndistribution.\n\nWaloddi Weibull, Royal Technical University, Stockholm, 1939 \u201cA Statistical\nTheory Of The Strength Of Materials\u201d, Ingeniorsvetenskapsakademiens Handlingar\nNr 151, 1939, Generalstabens Litografiska Anstalts Forlag, Stockholm.\n\nWaloddi Weibull, \u201cA Statistical Distribution Function of Wide Applicability\u201d,\nJournal Of Applied Mechanics ASME Paper 1951.\n\nWikipedia, \u201cWeibull distribution\u201d,\nhttps://en.wikipedia.org/wiki/Weibull_distribution\n\nDraw samples from the distribution:\n\nDisplay the histogram of the samples, along with the probability density\nfunction:\n\n"}, {"name": "random.zipf()", "path": "reference/random/generated/numpy.random.zipf", "type": "numpy.random.zipf", "text": "\nDraw samples from a Zipf distribution.\n\nSamples are drawn from a Zipf distribution with specified parameter `a` > 1.\n\nThe Zipf distribution (also known as the zeta distribution) is a discrete\nprobability distribution that satisfies Zipf\u2019s law: the frequency of an item\nis inversely proportional to its rank in a frequency table.\n\nNote\n\nNew code should use the `zipf` method of a `default_rng()` instance instead;\nplease see the Quick Start.\n\nDistribution parameter. Must be greater than 1.\n\nOutput shape. If the given shape is, e.g., `(m, n, k)`, then `m * n * k`\nsamples are drawn. If size is `None` (default), a single value is returned if\n`a` is a scalar. Otherwise, `np.array(a).size` samples are drawn.\n\nDrawn samples from the parameterized Zipf distribution.\n\nSee also\n\nprobability density function, distribution, or cumulative density function,\netc.\n\nwhich should be used for new code.\n\nThe probability density for the Zipf distribution is\n\nfor integers \\\\(k \\geq 1\\\\), where \\\\(\\zeta\\\\) is the Riemann Zeta function.\n\nIt is named for the American linguist George Kingsley Zipf, who noted that the\nfrequency of any word in a sample of a language is inversely proportional to\nits rank in the frequency table.\n\nZipf, G. K., \u201cSelected Studies of the Principle of Relative Frequency in\nLanguage,\u201d Cambridge, MA: Harvard Univ. Press, 1932.\n\nDraw samples from the distribution:\n\nDisplay the histogram of the samples, along with the expected histogram based\non the probability density function:\n\n`bincount` provides a fast histogram for small integers.\n\n"}, {"name": "Reading and writing files", "path": "user/how-to-io", "type": "User Guide", "text": "\nThis page tackles common applications; for the full collection of I/O\nroutines, see Input and output.\n\nUse `numpy.loadtxt`.\n\nUse `numpy.genfromtxt`.\n\n`numpy.genfromtxt` will either\n\n`numpy.genfromtxt` can also parse whitespace-delimited data files that have\nmissing values if\n\nEach field has a fixed width: Use the width as the `delimiter` argument.\n\nA special value (e.g. \u201cx\u201d) indicates a missing field: Use it as the\n`missing_values` argument.\n\nYou want to skip the rows with missing values: Set `invalid_raise=False`.\n\nThe delimiter whitespace character is different from the whitespace that\nindicates missing data. For instance, if columns are delimited by `\\t`, then\nmissing data will be recognized if it consists of one or more spaces.\n\nChoices:\n\nUse `numpy.save`, or to store multiple arrays `numpy.savez` or\n`numpy.savez_compressed`.\n\nFor security and portability, set `allow_pickle=False` unless the dtype\ncontains Python objects, which requires pickling.\n\nMasked arrays `can't currently be saved`, nor can other arbitrary array\nsubclasses.\n\n`numpy.save` and `numpy.savez` create binary files. To write a human-readable\nfile, use `numpy.savetxt`. The array can only be 1- or 2-dimensional, and\nthere\u2019s no ` savetxtz` for multiple files.\n\nSee Write or read large arrays.\n\nUse a structured array.\n\nExample:\n\nThe `.wav` file header is a 44-byte block preceding `data_size` bytes of the\nactual sound data:\n\nThe `.wav` file header as a NumPy structured dtype:\n\nThis `.wav` example is for illustration; to read a `.wav` file in real life,\nuse Python\u2019s built-in module `wave`.\n\n(Adapted from Pauli Virtanen, Advanced NumPy, licensed under CC BY 4.0.)\n\nArrays too large to fit in memory can be treated like ordinary in-memory\narrays using memory mapping.\n\nRaw array data written with `numpy.ndarray.tofile` or `numpy.ndarray.tobytes`\ncan be read with `numpy.memmap`:\n\nFiles output by `numpy.save` (that is, using the numpy format) can be read\nusing `numpy.load` with the `mmap_mode` keyword argument:\n\nMemory mapping lacks features like data chunking and compression; more full-\nfeatured formats and libraries usable with NumPy include:\n\nFor tradeoffs among memmap, Zarr, and HDF5, see pythonspeed.com.\n\nFormats for exchanging data with other tools include HDF5, Zarr, and NetCDF\n(see Write or read large arrays).\n\nNumPy arrays are not directly JSON serializable.\n\nAvoid when possible; pickles are not secure against erroneous or maliciously\nconstructed data.\n\nUse `numpy.save` and `numpy.load`. Set `allow_pickle=False`, unless the array\ndtype includes Python objects, in which case pickling is required.\n\nSee `pandas.DataFrame.to_numpy`.\n\nIn general, prefer `numpy.save` and `numpy.load`.\n\n`numpy.ndarray.tofile` and `numpy.fromfile` lose information on endianness and\nprecision and so are unsuitable for anything but scratch storage.\n\n"}, {"name": "recarray.all()", "path": "reference/generated/numpy.recarray.all", "type": "numpy.recarray.all", "text": "\nmethod\n\nReturns True if all elements evaluate to True.\n\nRefer to `numpy.all` for full documentation.\n\nSee also\n\nequivalent function\n\n"}, {"name": "recarray.any()", "path": "reference/generated/numpy.recarray.any", "type": "numpy.recarray.any", "text": "\nmethod\n\nReturns True if any of the elements of `a` evaluate to True.\n\nRefer to `numpy.any` for full documentation.\n\nSee also\n\nequivalent function\n\n"}, {"name": "recarray.argmax()", "path": "reference/generated/numpy.recarray.argmax", "type": "numpy.recarray.argmax", "text": "\nmethod\n\nReturn indices of the maximum values along the given axis.\n\nRefer to `numpy.argmax` for full documentation.\n\nSee also\n\nequivalent function\n\n"}, {"name": "recarray.argmin()", "path": "reference/generated/numpy.recarray.argmin", "type": "numpy.recarray.argmin", "text": "\nmethod\n\nReturn indices of the minimum values along the given axis.\n\nRefer to `numpy.argmin` for detailed documentation.\n\nSee also\n\nequivalent function\n\n"}, {"name": "recarray.argpartition()", "path": "reference/generated/numpy.recarray.argpartition", "type": "numpy.recarray.argpartition", "text": "\nmethod\n\nReturns the indices that would partition this array.\n\nRefer to `numpy.argpartition` for full documentation.\n\nNew in version 1.8.0.\n\nSee also\n\nequivalent function\n\n"}, {"name": "recarray.argsort()", "path": "reference/generated/numpy.recarray.argsort", "type": "numpy.recarray.argsort", "text": "\nmethod\n\nReturns the indices that would sort this array.\n\nRefer to `numpy.argsort` for full documentation.\n\nSee also\n\nequivalent function\n\n"}, {"name": "recarray.astype()", "path": "reference/generated/numpy.recarray.astype", "type": "numpy.recarray.astype", "text": "\nmethod\n\nCopy of the array, cast to a specified type.\n\nTypecode or data-type to which the array is cast.\n\nControls the memory layout order of the result. \u2018C\u2019 means C order, \u2018F\u2019 means\nFortran order, \u2018A\u2019 means \u2018F\u2019 order if all the arrays are Fortran contiguous,\n\u2018C\u2019 order otherwise, and \u2018K\u2019 means as close to the order the array elements\nappear in memory as possible. Default is \u2018K\u2019.\n\nControls what kind of data casting may occur. Defaults to \u2018unsafe\u2019 for\nbackwards compatibility.\n\nIf True, then sub-classes will be passed-through (default), otherwise the\nreturned array will be forced to be a base-class array.\n\nBy default, astype always returns a newly allocated array. If this is set to\nfalse, and the `dtype`, `order`, and `subok` requirements are satisfied, the\ninput array is returned instead of a copy.\n\nUnless `copy` is False and the other conditions for returning the input array\nare satisfied (see description for `copy` input parameter), `arr_t` is a new\narray of the same shape as the input array, with dtype, order given by\n`dtype`, `order`.\n\nWhen casting from complex to float or int. To avoid this, one should use\n`a.real.astype(t)`.\n\nChanged in version 1.17.0: Casting between a simple data type and a structured\none is possible only for \u201cunsafe\u201d casting. Casting to multiple fields is\nallowed, but casting from multiple fields is not.\n\nChanged in version 1.9.0: Casting from numeric to string types in \u2018safe\u2019\ncasting mode requires that the string dtype length is long enough to store the\nmax integer/float value converted.\n\n"}, {"name": "recarray.base", "path": "reference/generated/numpy.recarray.base", "type": "Standard array subclasses", "text": "\nattribute\n\nBase object if memory is from some other object.\n\nThe base of an array that owns its memory is None:\n\nSlicing creates a view, whose memory is shared with x:\n\n"}, {"name": "recarray.byteswap()", "path": "reference/generated/numpy.recarray.byteswap", "type": "numpy.recarray.byteswap", "text": "\nmethod\n\nSwap the bytes of the array elements\n\nToggle between low-endian and big-endian data representation by returning a\nbyteswapped array, optionally swapped in-place. Arrays of byte-strings are not\nswapped. The real and imaginary parts of a complex number are swapped\nindividually.\n\nIf `True`, swap bytes in-place, default is `False`.\n\nThe byteswapped array. If `inplace` is `True`, this is a view to self.\n\nArrays of byte-strings are not swapped\n\nbut different representation in memory\n\n"}, {"name": "recarray.choose()", "path": "reference/generated/numpy.recarray.choose", "type": "numpy.recarray.choose", "text": "\nmethod\n\nUse an index array to construct a new array from a set of choices.\n\nRefer to `numpy.choose` for full documentation.\n\nSee also\n\nequivalent function\n\n"}, {"name": "recarray.clip()", "path": "reference/generated/numpy.recarray.clip", "type": "numpy.recarray.clip", "text": "\nmethod\n\nReturn an array whose values are limited to `[min, max]`. One of max or min\nmust be given.\n\nRefer to `numpy.clip` for full documentation.\n\nSee also\n\nequivalent function\n\n"}, {"name": "recarray.compress()", "path": "reference/generated/numpy.recarray.compress", "type": "numpy.recarray.compress", "text": "\nmethod\n\nReturn selected slices of this array along given axis.\n\nRefer to `numpy.compress` for full documentation.\n\nSee also\n\nequivalent function\n\n"}, {"name": "recarray.conj()", "path": "reference/generated/numpy.recarray.conj", "type": "numpy.recarray.conj", "text": "\nmethod\n\nComplex-conjugate all elements.\n\nRefer to `numpy.conjugate` for full documentation.\n\nSee also\n\nequivalent function\n\n"}, {"name": "recarray.conjugate()", "path": "reference/generated/numpy.recarray.conjugate", "type": "numpy.recarray.conjugate", "text": "\nmethod\n\nReturn the complex conjugate, element-wise.\n\nRefer to `numpy.conjugate` for full documentation.\n\nSee also\n\nequivalent function\n\n"}, {"name": "recarray.copy()", "path": "reference/generated/numpy.recarray.copy", "type": "numpy.recarray.copy", "text": "\nmethod\n\nReturn a copy of the array.\n\nControls the memory layout of the copy. \u2018C\u2019 means C-order, \u2018F\u2019 means F-order,\n\u2018A\u2019 means \u2018F\u2019 if `a` is Fortran contiguous, \u2018C\u2019 otherwise. \u2018K\u2019 means match the\nlayout of `a` as closely as possible. (Note that this function and\n`numpy.copy` are very similar but have different default values for their\norder= arguments, and this function always passes sub-classes through.)\n\nSee also\n\nSimilar function with different default behavior\n\nThis function is the preferred method for creating an array copy. The function\n`numpy.copy` is similar, but it defaults to using order \u2018K\u2019, and will not pass\nsub-classes through by default.\n\n"}, {"name": "recarray.ctypes", "path": "reference/generated/numpy.recarray.ctypes", "type": "Standard array subclasses", "text": "\nattribute\n\nAn object to simplify the interaction of the array with the ctypes module.\n\nThis attribute creates an object that makes it easier to use arrays when\ncalling shared libraries with the ctypes module. The returned object has,\namong others, data, shape, and strides attributes (see Notes below) which\nthemselves return ctypes objects that can be used as arguments to a shared\nlibrary.\n\nPossessing attributes data, shape, strides, etc.\n\nSee also\n\nBelow are the public attributes of this object which were documented in \u201cGuide\nto NumPy\u201d (we have omitted undocumented public attributes, as well as\ndocumented private attributes):\n\nA pointer to the memory area of the array as a Python integer. This memory\narea may contain data that is not aligned, or not in correct byte-order. The\nmemory area may not even be writeable. The array flags and data-type of this\narray should be respected when passing this attribute to arbitrary C-code to\navoid trouble that can include Python crashing. User Beware! The value of this\nattribute is exactly the same as `self._array_interface_['data'][0]`.\n\nNote that unlike `data_as`, a reference will not be kept to the array: code\nlike `ctypes.c_void_p((a + b).ctypes.data)` will result in a pointer to a\ndeallocated array, and should be spelt `(a +\nb).ctypes.data_as(ctypes.c_void_p)`\n\n(c_intp*self.ndim): A ctypes array of length self.ndim where the basetype is\nthe C-integer corresponding to `dtype('p')` on this platform (see `c_intp`).\nThis base-type could be `ctypes.c_int`, `ctypes.c_long`, or\n`ctypes.c_longlong` depending on the platform. The ctypes array contains the\nshape of the underlying array.\n\n(c_intp*self.ndim): A ctypes array of length self.ndim where the basetype is\nthe same as for the shape attribute. This ctypes array contains the strides\ninformation from the underlying array. This strides information is important\nfor showing how many bytes must be jumped to get to the next element in the\narray.\n\nReturn the data pointer cast to a particular c-types object. For example,\ncalling `self._as_parameter_` is equivalent to\n`self.data_as(ctypes.c_void_p)`. Perhaps you want to use the data as a pointer\nto a ctypes array of floating-point data:\n`self.data_as(ctypes.POINTER(ctypes.c_double))`.\n\nThe returned pointer will keep a reference to the array.\n\nReturn the shape tuple as an array of some other c-types type. For example:\n`self.shape_as(ctypes.c_short)`.\n\nReturn the strides tuple as an array of some other c-types type. For example:\n`self.strides_as(ctypes.c_longlong)`.\n\nIf the ctypes module is not available, then the ctypes attribute of array\nobjects still returns something useful, but ctypes objects are not returned\nand errors may be raised instead. In particular, the object will still have\nthe `as_parameter` attribute which will return an integer equal to the data\nattribute.\n\n"}, {"name": "recarray.cumprod()", "path": "reference/generated/numpy.recarray.cumprod", "type": "numpy.recarray.cumprod", "text": "\nmethod\n\nReturn the cumulative product of the elements along the given axis.\n\nRefer to `numpy.cumprod` for full documentation.\n\nSee also\n\nequivalent function\n\n"}, {"name": "recarray.cumsum()", "path": "reference/generated/numpy.recarray.cumsum", "type": "numpy.recarray.cumsum", "text": "\nmethod\n\nReturn the cumulative sum of the elements along the given axis.\n\nRefer to `numpy.cumsum` for full documentation.\n\nSee also\n\nequivalent function\n\n"}, {"name": "recarray.data", "path": "reference/generated/numpy.recarray.data", "type": "Standard array subclasses", "text": "\nattribute\n\nPython buffer object pointing to the start of the array\u2019s data.\n\n"}, {"name": "recarray.diagonal()", "path": "reference/generated/numpy.recarray.diagonal", "type": "numpy.recarray.diagonal", "text": "\nmethod\n\nReturn specified diagonals. In NumPy 1.9 the returned array is a read-only\nview instead of a copy as in previous NumPy versions. In a future version the\nread-only restriction will be removed.\n\nRefer to `numpy.diagonal` for full documentation.\n\nSee also\n\nequivalent function\n\n"}, {"name": "recarray.dump()", "path": "reference/generated/numpy.recarray.dump", "type": "numpy.recarray.dump", "text": "\nmethod\n\nDump a pickle of the array to the specified file. The array can be read back\nwith pickle.load or numpy.load.\n\nA string naming the dump file.\n\nChanged in version 1.17.0: `pathlib.Path` objects are now accepted.\n\n"}, {"name": "recarray.dumps()", "path": "reference/generated/numpy.recarray.dumps", "type": "numpy.recarray.dumps", "text": "\nmethod\n\nReturns the pickle of the array as a string. pickle.loads will convert the\nstring back to an array.\n\n"}, {"name": "recarray.fill()", "path": "reference/generated/numpy.recarray.fill", "type": "numpy.recarray.fill", "text": "\nmethod\n\nFill the array with a scalar value.\n\nAll elements of `a` will be assigned this value.\n\n"}, {"name": "recarray.flags", "path": "reference/generated/numpy.recarray.flags", "type": "Standard array subclasses", "text": "\nattribute\n\nInformation about the memory layout of the array.\n\nThe `flags` object can be accessed dictionary-like (as in\n`a.flags['WRITEABLE']`), or by using lowercased attribute names (as in\n`a.flags.writeable`). Short flag names are only supported in dictionary\naccess.\n\nOnly the WRITEBACKIFCOPY, UPDATEIFCOPY, WRITEABLE, and ALIGNED flags can be\nchanged by the user, via direct assignment to the attribute or dictionary\nentry, or by calling `ndarray.setflags`.\n\nThe array flags cannot be set arbitrarily:\n\nArrays can be both C-style and Fortran-style contiguous simultaneously. This\nis clear for 1-dimensional arrays, but can also be true for higher dimensional\narrays.\n\nEven for contiguous arrays a stride for a given dimension `arr.strides[dim]`\nmay be arbitrary if `arr.shape[dim] == 1` or the array has no elements. It\ndoes not generally hold that `self.strides[-1] == self.itemsize` for C-style\ncontiguous arrays or `self.strides[0] == self.itemsize` for Fortran-style\ncontiguous arrays is true.\n\nThe data is in a single, C-style contiguous segment.\n\nThe data is in a single, Fortran-style contiguous segment.\n\nThe array owns the memory it uses or borrows it from another object.\n\nThe data area can be written to. Setting this to False locks the data, making\nit read-only. A view (slice, etc.) inherits WRITEABLE from its base array at\ncreation time, but a view of a writeable array may be subsequently locked\nwhile the base array remains writeable. (The opposite is not true, in that a\nview of a locked array may not be made writeable. However, currently, locking\na base object does not lock any views that already reference it, so under that\ncircumstance it is possible to alter the contents of a locked array via a\npreviously created writeable view onto it.) Attempting to change a non-\nwriteable array raises a RuntimeError exception.\n\nThe data and all elements are aligned appropriately for the hardware.\n\nThis array is a copy of some other array. The C-API function\nPyArray_ResolveWritebackIfCopy must be called before deallocating to the base\narray will be updated with the contents of this array.\n\n(Deprecated, use WRITEBACKIFCOPY) This array is a copy of some other array.\nWhen this array is deallocated, the base array will be updated with the\ncontents of this array.\n\nF_CONTIGUOUS and not C_CONTIGUOUS.\n\nF_CONTIGUOUS or C_CONTIGUOUS (one-segment test).\n\nALIGNED and WRITEABLE.\n\nBEHAVED and C_CONTIGUOUS.\n\nBEHAVED and F_CONTIGUOUS and not C_CONTIGUOUS.\n\n"}, {"name": "recarray.flat", "path": "reference/generated/numpy.recarray.flat", "type": "Standard array subclasses", "text": "\nattribute\n\nA 1-D iterator over the array.\n\nThis is a `numpy.flatiter` instance, which acts similarly to, but is not a\nsubclass of, Python\u2019s built-in iterator object.\n\nSee also\n\nReturn a copy of the array collapsed into one dimension.\n\nAn assignment example:\n\n"}, {"name": "recarray.flatten()", "path": "reference/generated/numpy.recarray.flatten", "type": "numpy.recarray.flatten", "text": "\nmethod\n\nReturn a copy of the array collapsed into one dimension.\n\n\u2018C\u2019 means to flatten in row-major (C-style) order. \u2018F\u2019 means to flatten in\ncolumn-major (Fortran- style) order. \u2018A\u2019 means to flatten in column-major\norder if `a` is Fortran contiguous in memory, row-major order otherwise. \u2018K\u2019\nmeans to flatten `a` in the order the elements occur in memory. The default is\n\u2018C\u2019.\n\nA copy of the input array, flattened to one dimension.\n\nSee also\n\nReturn a flattened array.\n\nA 1-D flat iterator over the array.\n\n"}, {"name": "recarray.getfield()", "path": "reference/generated/numpy.recarray.getfield", "type": "numpy.recarray.getfield", "text": "\nmethod\n\nReturns a field of the given array as a certain type.\n\nA field is a view of the array data with a given data-type. The values in the\nview are determined by the given type and the offset into the current array in\nbytes. The offset needs to be such that the view dtype fits in the array\ndtype; for example an array of dtype complex128 has 16-byte elements. If\ntaking a view with a 32-bit integer (4 bytes), the offset needs to be between\n0 and 12 bytes.\n\nThe data type of the view. The dtype size of the view can not be larger than\nthat of the array itself.\n\nNumber of bytes to skip before beginning the element view.\n\nBy choosing an offset of 8 bytes we can select the complex part of the array\nfor our view:\n\n"}, {"name": "recarray.item()", "path": "reference/generated/numpy.recarray.item", "type": "numpy.recarray.item", "text": "\nmethod\n\nCopy an element of an array to a standard Python scalar and return it.\n\nA copy of the specified element of the array as a suitable Python scalar\n\nWhen the data type of `a` is longdouble or clongdouble, item() returns a\nscalar array object because there is no available Python scalar that would not\nlose information. Void arrays return a buffer object for item(), unless fields\nare defined, in which case a tuple is returned.\n\n`item` is very similar to a[args], except, instead of an array scalar, a\nstandard Python scalar is returned. This can be useful for speeding up access\nto elements of the array and doing arithmetic on elements of the array using\nPython\u2019s optimized math.\n\n"}, {"name": "recarray.itemset()", "path": "reference/generated/numpy.recarray.itemset", "type": "numpy.recarray.itemset", "text": "\nmethod\n\nInsert scalar into an array (scalar is cast to array\u2019s dtype, if possible)\n\nThere must be at least 1 argument, and define the last argument as item. Then,\n`a.itemset(*args)` is equivalent to but faster than `a[args] = item`. The item\nshould be a scalar value and `args` must select a single item in the array\n`a`.\n\nIf one argument: a scalar, only used in case `a` is of size 1. If two\narguments: the last argument is the value to be set and must be a scalar, the\nfirst argument specifies a single array element location. It is either an int\nor a tuple.\n\nCompared to indexing syntax, `itemset` provides some speed increase for\nplacing a scalar into a particular location in an `ndarray`, if you must do\nthis. However, generally this is discouraged: among other problems, it\ncomplicates the appearance of the code. Also, when using `itemset` (and\n`item`) inside a loop, be sure to assign the methods to a local variable to\navoid the attribute look-up at each loop iteration.\n\n"}, {"name": "recarray.itemsize", "path": "reference/generated/numpy.recarray.itemsize", "type": "Standard array subclasses", "text": "\nattribute\n\nLength of one array element in bytes.\n\n"}, {"name": "recarray.max()", "path": "reference/generated/numpy.recarray.max", "type": "numpy.recarray.max", "text": "\nmethod\n\nReturn the maximum along a given axis.\n\nRefer to `numpy.amax` for full documentation.\n\nSee also\n\nequivalent function\n\n"}, {"name": "recarray.mean()", "path": "reference/generated/numpy.recarray.mean", "type": "numpy.recarray.mean", "text": "\nmethod\n\nReturns the average of the array elements along given axis.\n\nRefer to `numpy.mean` for full documentation.\n\nSee also\n\nequivalent function\n\n"}, {"name": "recarray.min()", "path": "reference/generated/numpy.recarray.min", "type": "numpy.recarray.min", "text": "\nmethod\n\nReturn the minimum along a given axis.\n\nRefer to `numpy.amin` for full documentation.\n\nSee also\n\nequivalent function\n\n"}, {"name": "recarray.nbytes", "path": "reference/generated/numpy.recarray.nbytes", "type": "Standard array subclasses", "text": "\nattribute\n\nTotal bytes consumed by the elements of the array.\n\nDoes not include memory consumed by non-element attributes of the array\nobject.\n\n"}, {"name": "recarray.ndim", "path": "reference/generated/numpy.recarray.ndim", "type": "Standard array subclasses", "text": "\nattribute\n\nNumber of array dimensions.\n\n"}, {"name": "recarray.newbyteorder()", "path": "reference/generated/numpy.recarray.newbyteorder", "type": "numpy.recarray.newbyteorder", "text": "\nmethod\n\nReturn the array with the same data viewed with a different byte order.\n\nEquivalent to:\n\nChanges are also made in all fields and sub-arrays of the array data type.\n\nByte order to force; a value from the byte order specifications below.\n`new_order` codes can be any of:\n\nThe default value (\u2018S\u2019) results in swapping the current byte order.\n\nNew array object with the dtype reflecting given change to the byte order.\n\n"}, {"name": "recarray.nonzero()", "path": "reference/generated/numpy.recarray.nonzero", "type": "numpy.recarray.nonzero", "text": "\nmethod\n\nReturn the indices of the elements that are non-zero.\n\nRefer to `numpy.nonzero` for full documentation.\n\nSee also\n\nequivalent function\n\n"}, {"name": "recarray.partition()", "path": "reference/generated/numpy.recarray.partition", "type": "numpy.recarray.partition", "text": "\nmethod\n\nRearranges the elements in the array in such a way that the value of the\nelement in kth position is in the position it would be in a sorted array. All\nelements smaller than the kth element are moved before this element and all\nequal or greater are moved behind it. The ordering of the elements in the two\npartitions is undefined.\n\nNew in version 1.8.0.\n\nElement index to partition by. The kth element value will be in its final\nsorted position and all smaller elements will be moved before it and all equal\nor greater elements behind it. The order of all elements in the partitions is\nundefined. If provided with a sequence of kth it will partition all elements\nindexed by kth of them into their sorted position at once.\n\nDeprecated since version 1.22.0: Passing booleans as index is deprecated.\n\nAxis along which to sort. Default is -1, which means sort along the last axis.\n\nSelection algorithm. Default is \u2018introselect\u2019.\n\nWhen `a` is an array with fields defined, this argument specifies which fields\nto compare first, second, etc. A single field can be specified as a string,\nand not all fields need to be specified, but unspecified fields will still be\nused, in the order in which they come up in the dtype, to break ties.\n\nSee also\n\nReturn a parititioned copy of an array.\n\nIndirect partition.\n\nFull sort.\n\nSee `np.partition` for notes on the different algorithms.\n\n"}, {"name": "recarray.prod()", "path": "reference/generated/numpy.recarray.prod", "type": "numpy.recarray.prod", "text": "\nmethod\n\nReturn the product of the array elements over the given axis\n\nRefer to `numpy.prod` for full documentation.\n\nSee also\n\nequivalent function\n\n"}, {"name": "recarray.ptp()", "path": "reference/generated/numpy.recarray.ptp", "type": "numpy.recarray.ptp", "text": "\nmethod\n\nPeak to peak (maximum - minimum) value along a given axis.\n\nRefer to `numpy.ptp` for full documentation.\n\nSee also\n\nequivalent function\n\n"}, {"name": "recarray.put()", "path": "reference/generated/numpy.recarray.put", "type": "numpy.recarray.put", "text": "\nmethod\n\nSet `a.flat[n] = values[n]` for all `n` in indices.\n\nRefer to `numpy.put` for full documentation.\n\nSee also\n\nequivalent function\n\n"}, {"name": "recarray.ravel()", "path": "reference/generated/numpy.recarray.ravel", "type": "numpy.recarray.ravel", "text": "\nmethod\n\nReturn a flattened array.\n\nRefer to `numpy.ravel` for full documentation.\n\nSee also\n\nequivalent function\n\na flat iterator on the array.\n\n"}, {"name": "recarray.repeat()", "path": "reference/generated/numpy.recarray.repeat", "type": "numpy.recarray.repeat", "text": "\nmethod\n\nRepeat elements of an array.\n\nRefer to `numpy.repeat` for full documentation.\n\nSee also\n\nequivalent function\n\n"}, {"name": "recarray.reshape()", "path": "reference/generated/numpy.recarray.reshape", "type": "numpy.recarray.reshape", "text": "\nmethod\n\nReturns an array containing the same data with a new shape.\n\nRefer to `numpy.reshape` for full documentation.\n\nSee also\n\nequivalent function\n\nUnlike the free function `numpy.reshape`, this method on `ndarray` allows the\nelements of the shape parameter to be passed in as separate arguments. For\nexample, `a.reshape(10, 11)` is equivalent to `a.reshape((10, 11))`.\n\n"}, {"name": "recarray.resize()", "path": "reference/generated/numpy.recarray.resize", "type": "numpy.recarray.resize", "text": "\nmethod\n\nChange shape and size of array in-place.\n\nShape of resized array.\n\nIf False, reference count will not be checked. Default is True.\n\nIf `a` does not own its own data or references or views to it exist, and the\ndata memory must be changed. PyPy only: will always raise if the data memory\nmust be changed, since there is no reliable way to determine if references or\nviews to it exist.\n\nIf the `order` keyword argument is specified. This behaviour is a bug in\nNumPy.\n\nSee also\n\nReturn a new array with the specified shape.\n\nThis reallocates space for the data area if necessary.\n\nOnly contiguous arrays (data elements consecutive in memory) can be resized.\n\nThe purpose of the reference count check is to make sure you do not use this\narray as a buffer for another Python object and then reallocate the memory.\nHowever, reference counts can increase in other ways so if you are sure that\nyou have not shared the memory for this array with another Python object, then\nyou may safely set `refcheck` to False.\n\nShrinking an array: array is flattened (in the order that the data are stored\nin memory), resized, and reshaped:\n\nEnlarging an array: as above, but missing entries are filled with zeros:\n\nReferencing an array prevents resizing\u2026\n\nUnless `refcheck` is False:\n\n"}, {"name": "recarray.round()", "path": "reference/generated/numpy.recarray.round", "type": "numpy.recarray.round", "text": "\nmethod\n\nReturn `a` with each element rounded to the given number of decimals.\n\nRefer to `numpy.around` for full documentation.\n\nSee also\n\nequivalent function\n\n"}, {"name": "recarray.searchsorted()", "path": "reference/generated/numpy.recarray.searchsorted", "type": "numpy.recarray.searchsorted", "text": "\nmethod\n\nFind indices where elements of v should be inserted in a to maintain order.\n\nFor full documentation, see `numpy.searchsorted`\n\nSee also\n\nequivalent function\n\n"}, {"name": "recarray.setfield()", "path": "reference/generated/numpy.recarray.setfield", "type": "numpy.recarray.setfield", "text": "\nmethod\n\nPut a value into a specified place in a field defined by a data-type.\n\nPlace `val` into `a`\u2019s field defined by `dtype` and beginning `offset` bytes\ninto the field.\n\nValue to be placed in field.\n\nData-type of the field in which to place `val`.\n\nThe number of bytes into the field at which to place `val`.\n\nSee also\n\n"}, {"name": "recarray.setflags()", "path": "reference/generated/numpy.recarray.setflags", "type": "numpy.recarray.setflags", "text": "\nmethod\n\nSet array flags WRITEABLE, ALIGNED, (WRITEBACKIFCOPY and UPDATEIFCOPY),\nrespectively.\n\nThese Boolean-valued flags affect how numpy interprets the memory area used by\n`a` (see Notes below). The ALIGNED flag can only be set to True if the data is\nactually aligned according to the type. The WRITEBACKIFCOPY and (deprecated)\nUPDATEIFCOPY flags can never be set to True. The flag WRITEABLE can only be\nset to True if the array owns its own memory, or the ultimate owner of the\nmemory exposes a writeable buffer interface, or is a string. (The exception\nfor string is made so that unpickling can be done without copying memory.)\n\nDescribes whether or not `a` can be written to.\n\nDescribes whether or not `a` is aligned properly for its type.\n\nDescribes whether or not `a` is a copy of another \u201cbase\u201d array.\n\nArray flags provide information about how the memory area used for the array\nis to be interpreted. There are 7 Boolean flags in use, only four of which can\nbe changed by the user: WRITEBACKIFCOPY, UPDATEIFCOPY, WRITEABLE, and ALIGNED.\n\nWRITEABLE (W) the data area can be written to;\n\nALIGNED (A) the data and strides are aligned appropriately for the hardware\n(as determined by the compiler);\n\nUPDATEIFCOPY (U) (deprecated), replaced by WRITEBACKIFCOPY;\n\nWRITEBACKIFCOPY (X) this array is a copy of some other array (referenced by\n.base). When the C-API function PyArray_ResolveWritebackIfCopy is called, the\nbase array will be updated with the contents of this array.\n\nAll flags can be accessed using the single (upper case) letter as well as the\nfull name.\n\n"}, {"name": "recarray.size", "path": "reference/generated/numpy.recarray.size", "type": "Standard array subclasses", "text": "\nattribute\n\nNumber of elements in the array.\n\nEqual to `np.prod(a.shape)`, i.e., the product of the array\u2019s dimensions.\n\n`a.size` returns a standard arbitrary precision Python integer. This may not\nbe the case with other methods of obtaining the same value (like the suggested\n`np.prod(a.shape)`, which returns an instance of `np.int_`), and may be\nrelevant if the value is used further in calculations that may overflow a\nfixed size integer type.\n\n"}, {"name": "recarray.sort()", "path": "reference/generated/numpy.recarray.sort", "type": "numpy.recarray.sort", "text": "\nmethod\n\nSort an array in-place. Refer to `numpy.sort` for full documentation.\n\nAxis along which to sort. Default is -1, which means sort along the last axis.\n\nSorting algorithm. The default is \u2018quicksort\u2019. Note that both \u2018stable\u2019 and\n\u2018mergesort\u2019 use timsort under the covers and, in general, the actual\nimplementation will vary with datatype. The \u2018mergesort\u2019 option is retained for\nbackwards compatibility.\n\nChanged in version 1.15.0: The \u2018stable\u2019 option was added.\n\nWhen `a` is an array with fields defined, this argument specifies which fields\nto compare first, second, etc. A single field can be specified as a string,\nand not all fields need be specified, but unspecified fields will still be\nused, in the order in which they come up in the dtype, to break ties.\n\nSee also\n\nReturn a sorted copy of an array.\n\nIndirect sort.\n\nIndirect stable sort on multiple keys.\n\nFind elements in sorted array.\n\nPartial sort.\n\nSee `numpy.sort` for notes on the different sorting algorithms.\n\nUse the `order` keyword to specify a field to use when sorting a structured\narray:\n\n"}, {"name": "recarray.squeeze()", "path": "reference/generated/numpy.recarray.squeeze", "type": "numpy.recarray.squeeze", "text": "\nmethod\n\nRemove axes of length one from `a`.\n\nRefer to `numpy.squeeze` for full documentation.\n\nSee also\n\nequivalent function\n\n"}, {"name": "recarray.std()", "path": "reference/generated/numpy.recarray.std", "type": "numpy.recarray.std", "text": "\nmethod\n\nReturns the standard deviation of the array elements along given axis.\n\nRefer to `numpy.std` for full documentation.\n\nSee also\n\nequivalent function\n\n"}, {"name": "recarray.strides", "path": "reference/generated/numpy.recarray.strides", "type": "Standard array subclasses", "text": "\nattribute\n\nTuple of bytes to step in each dimension when traversing an array.\n\nThe byte offset of element `(i[0], i[1], ..., i[n])` in an array `a` is:\n\nA more detailed explanation of strides can be found in the \u201cndarray.rst\u201d file\nin the NumPy reference guide.\n\nSee also\n\nImagine an array of 32-bit integers (each 4 bytes):\n\nThis array is stored in memory as 40 bytes, one after the other (known as a\ncontiguous block of memory). The strides of an array tell us how many bytes we\nhave to skip in memory to move to the next position along a certain axis. For\nexample, we have to skip 4 bytes (1 value) to move to the next column, but 20\nbytes (5 values) to get to the same position in the next row. As such, the\nstrides for the array `x` will be `(20, 4)`.\n\n"}, {"name": "recarray.sum()", "path": "reference/generated/numpy.recarray.sum", "type": "numpy.recarray.sum", "text": "\nmethod\n\nReturn the sum of the array elements over the given axis.\n\nRefer to `numpy.sum` for full documentation.\n\nSee also\n\nequivalent function\n\n"}, {"name": "recarray.swapaxes()", "path": "reference/generated/numpy.recarray.swapaxes", "type": "numpy.recarray.swapaxes", "text": "\nmethod\n\nReturn a view of the array with `axis1` and `axis2` interchanged.\n\nRefer to `numpy.swapaxes` for full documentation.\n\nSee also\n\nequivalent function\n\n"}, {"name": "recarray.T", "path": "reference/generated/numpy.recarray.t", "type": "Standard array subclasses", "text": "\nattribute\n\nThe transposed array.\n\nSame as `self.transpose()`.\n\nSee also\n\n"}, {"name": "recarray.take()", "path": "reference/generated/numpy.recarray.take", "type": "numpy.recarray.take", "text": "\nmethod\n\nReturn an array formed from the elements of `a` at the given indices.\n\nRefer to `numpy.take` for full documentation.\n\nSee also\n\nequivalent function\n\n"}, {"name": "recarray.tobytes()", "path": "reference/generated/numpy.recarray.tobytes", "type": "numpy.recarray.tobytes", "text": "\nmethod\n\nConstruct Python bytes containing the raw data bytes in the array.\n\nConstructs Python bytes showing a copy of the raw contents of data memory. The\nbytes object is produced in C-order by default. This behavior is controlled by\nthe `order` parameter.\n\nNew in version 1.9.0.\n\nControls the memory layout of the bytes object. \u2018C\u2019 means C-order, \u2018F\u2019 means\nF-order, \u2018A\u2019 (short for Any) means \u2018F\u2019 if `a` is Fortran contiguous, \u2018C\u2019\notherwise. Default is \u2018C\u2019.\n\nPython bytes exhibiting a copy of `a`\u2019s raw data.\n\n"}, {"name": "recarray.tofile()", "path": "reference/generated/numpy.recarray.tofile", "type": "numpy.recarray.tofile", "text": "\nmethod\n\nWrite array to a file as text or binary (default).\n\nData is always written in \u2018C\u2019 order, independent of the order of `a`. The data\nproduced by this method can be recovered using the function fromfile().\n\nAn open file object, or a string containing a filename.\n\nChanged in version 1.17.0: `pathlib.Path` objects are now accepted.\n\nSeparator between array items for text output. If \u201c\u201d (empty), a binary file is\nwritten, equivalent to `file.write(a.tobytes())`.\n\nFormat string for text file output. Each entry in the array is formatted to\ntext by first converting it to the closest Python type, and then using\n\u201cformat\u201d % item.\n\nThis is a convenience function for quick storage of array data. Information on\nendianness and precision is lost, so this method is not a good choice for\nfiles intended to archive data or transport data between machines with\ndifferent endianness. Some of these problems can be overcome by outputting the\ndata as text files, at the expense of speed and file size.\n\nWhen fid is a file object, array contents are directly written to the file,\nbypassing the file object\u2019s `write` method. As a result, tofile cannot be used\nwith files objects supporting compression (e.g., GzipFile) or file-like\nobjects that do not support `fileno()` (e.g., BytesIO).\n\n"}, {"name": "recarray.tolist()", "path": "reference/generated/numpy.recarray.tolist", "type": "numpy.recarray.tolist", "text": "\nmethod\n\nReturn the array as an `a.ndim`-levels deep nested list of Python scalars.\n\nReturn a copy of the array data as a (nested) Python list. Data items are\nconverted to the nearest compatible builtin Python type, via the `item`\nfunction.\n\nIf `a.ndim` is 0, then since the depth of the nested list is 0, it will not be\na list at all, but a simple Python scalar.\n\nThe possibly nested list of array elements.\n\nThe array may be recreated via `a = np.array(a.tolist())`, although this may\nsometimes lose precision.\n\nFor a 1D array, `a.tolist()` is almost the same as `list(a)`, except that\n`tolist` changes numpy scalars to Python scalars:\n\nAdditionally, for a 2D array, `tolist` applies recursively:\n\nThe base case for this recursion is a 0D array:\n\n"}, {"name": "recarray.tostring()", "path": "reference/generated/numpy.recarray.tostring", "type": "numpy.recarray.tostring", "text": "\nmethod\n\nA compatibility alias for `tobytes`, with exactly the same behavior.\n\nDespite its name, it returns `bytes` not `str`s.\n\nDeprecated since version 1.19.0.\n\n"}, {"name": "recarray.trace()", "path": "reference/generated/numpy.recarray.trace", "type": "numpy.recarray.trace", "text": "\nmethod\n\nReturn the sum along diagonals of the array.\n\nRefer to `numpy.trace` for full documentation.\n\nSee also\n\nequivalent function\n\n"}, {"name": "recarray.transpose()", "path": "reference/generated/numpy.recarray.transpose", "type": "numpy.recarray.transpose", "text": "\nmethod\n\nReturns a view of the array with axes transposed.\n\nFor a 1-D array this has no effect, as a transposed vector is simply the same\nvector. To convert a 1-D array into a 2D column vector, an additional\ndimension must be added. `np.atleast2d(a).T` achieves this, as does `a[:,\nnp.newaxis]`. For a 2-D array, this is a standard matrix transpose. For an n-D\narray, if axes are given, their order indicates how the axes are permuted (see\nExamples). If axes are not provided and `a.shape = (i[0], i[1], ... i[n-2],\ni[n-1])`, then `a.transpose().shape = (i[n-1], i[n-2], ... i[1], i[0])`.\n\nView of `a`, with axes suitably permuted.\n\nSee also\n\nEquivalent function\n\nArray property returning the array transposed.\n\nGive a new shape to an array without changing its data.\n\n"}, {"name": "recarray.var()", "path": "reference/generated/numpy.recarray.var", "type": "numpy.recarray.var", "text": "\nmethod\n\nReturns the variance of the array elements, along given axis.\n\nRefer to `numpy.var` for full documentation.\n\nSee also\n\nequivalent function\n\n"}, {"name": "recarray.view()", "path": "reference/generated/numpy.recarray.view", "type": "numpy.recarray.view", "text": "\nmethod\n\nNew view of array with the same data.\n\nNote\n\nPassing None for `dtype` is different from omitting the parameter, since the\nformer invokes `dtype(None)` which is an alias for `dtype('float_')`.\n\nData-type descriptor of the returned view, e.g., float32 or int16. Omitting it\nresults in the view having the same data-type as `a`. This argument can also\nbe specified as an ndarray sub-class, which then specifies the type of the\nreturned object (this is equivalent to setting the `type` parameter).\n\nType of the returned view, e.g., ndarray or matrix. Again, omission of the\nparameter results in type preservation.\n\n`a.view()` is used two different ways:\n\n`a.view(some_dtype)` or `a.view(dtype=some_dtype)` constructs a view of the\narray\u2019s memory with a different data-type. This can cause a reinterpretation\nof the bytes of memory.\n\n`a.view(ndarray_subclass)` or `a.view(type=ndarray_subclass)` just returns an\ninstance of `ndarray_subclass` that looks at the same array (same shape,\ndtype, etc.) This does not cause a reinterpretation of the memory.\n\nFor `a.view(some_dtype)`, if `some_dtype` has a different number of bytes per\nentry than the previous dtype (for example, converting a regular array to a\nstructured array), then the behavior of the view cannot be predicted just from\nthe superficial appearance of `a` (shown by `print(a)`). It also depends on\nexactly how `a` is stored in memory. Therefore if `a` is C-ordered versus\nfortran-ordered, versus defined as a slice or transpose, etc., the view may\ngive different results.\n\nViewing array data using a different type and dtype:\n\nCreating a view on a structured array so it can be used in calculations\n\nMaking changes to the view changes the underlying array\n\nUsing a view to convert an array to a recarray:\n\nViews share data:\n\nViews that change the dtype size (bytes per entry) should normally be avoided\non arrays defined by slices, transposes, fortran-ordering, etc.:\n\n"}, {"name": "record.all()", "path": "reference/generated/numpy.record.all", "type": "numpy.record.all", "text": "\nmethod\n\nScalar method identical to the corresponding array attribute.\n\nPlease see `ndarray.all`.\n\n"}, {"name": "record.any()", "path": "reference/generated/numpy.record.any", "type": "numpy.record.any", "text": "\nmethod\n\nScalar method identical to the corresponding array attribute.\n\nPlease see `ndarray.any`.\n\n"}, {"name": "record.argmax()", "path": "reference/generated/numpy.record.argmax", "type": "numpy.record.argmax", "text": "\nmethod\n\nScalar method identical to the corresponding array attribute.\n\nPlease see `ndarray.argmax`.\n\n"}, {"name": "record.argmin()", "path": "reference/generated/numpy.record.argmin", "type": "numpy.record.argmin", "text": "\nmethod\n\nScalar method identical to the corresponding array attribute.\n\nPlease see `ndarray.argmin`.\n\n"}, {"name": "record.argsort()", "path": "reference/generated/numpy.record.argsort", "type": "numpy.record.argsort", "text": "\nmethod\n\nScalar method identical to the corresponding array attribute.\n\nPlease see `ndarray.argsort`.\n\n"}, {"name": "record.astype()", "path": "reference/generated/numpy.record.astype", "type": "numpy.record.astype", "text": "\nmethod\n\nScalar method identical to the corresponding array attribute.\n\nPlease see `ndarray.astype`.\n\n"}, {"name": "record.base", "path": "reference/generated/numpy.record.base", "type": "Standard array subclasses", "text": "\nattribute\n\nbase object\n\n"}, {"name": "record.byteswap()", "path": "reference/generated/numpy.record.byteswap", "type": "numpy.record.byteswap", "text": "\nmethod\n\nScalar method identical to the corresponding array attribute.\n\nPlease see `ndarray.byteswap`.\n\n"}, {"name": "record.choose()", "path": "reference/generated/numpy.record.choose", "type": "numpy.record.choose", "text": "\nmethod\n\nScalar method identical to the corresponding array attribute.\n\nPlease see `ndarray.choose`.\n\n"}, {"name": "record.clip()", "path": "reference/generated/numpy.record.clip", "type": "numpy.record.clip", "text": "\nmethod\n\nScalar method identical to the corresponding array attribute.\n\nPlease see `ndarray.clip`.\n\n"}, {"name": "record.compress()", "path": "reference/generated/numpy.record.compress", "type": "numpy.record.compress", "text": "\nmethod\n\nScalar method identical to the corresponding array attribute.\n\nPlease see `ndarray.compress`.\n\n"}, {"name": "record.conjugate()", "path": "reference/generated/numpy.record.conjugate", "type": "numpy.record.conjugate", "text": "\nmethod\n\nScalar method identical to the corresponding array attribute.\n\nPlease see `ndarray.conjugate`.\n\n"}, {"name": "record.copy()", "path": "reference/generated/numpy.record.copy", "type": "numpy.record.copy", "text": "\nmethod\n\nScalar method identical to the corresponding array attribute.\n\nPlease see `ndarray.copy`.\n\n"}, {"name": "record.cumprod()", "path": "reference/generated/numpy.record.cumprod", "type": "numpy.record.cumprod", "text": "\nmethod\n\nScalar method identical to the corresponding array attribute.\n\nPlease see `ndarray.cumprod`.\n\n"}, {"name": "record.cumsum()", "path": "reference/generated/numpy.record.cumsum", "type": "numpy.record.cumsum", "text": "\nmethod\n\nScalar method identical to the corresponding array attribute.\n\nPlease see `ndarray.cumsum`.\n\n"}, {"name": "record.data", "path": "reference/generated/numpy.record.data", "type": "Standard array subclasses", "text": "\nattribute\n\nPointer to start of data.\n\n"}, {"name": "record.diagonal()", "path": "reference/generated/numpy.record.diagonal", "type": "numpy.record.diagonal", "text": "\nmethod\n\nScalar method identical to the corresponding array attribute.\n\nPlease see `ndarray.diagonal`.\n\n"}, {"name": "record.dump()", "path": "reference/generated/numpy.record.dump", "type": "numpy.record.dump", "text": "\nmethod\n\nScalar method identical to the corresponding array attribute.\n\nPlease see `ndarray.dump`.\n\n"}, {"name": "record.dumps()", "path": "reference/generated/numpy.record.dumps", "type": "numpy.record.dumps", "text": "\nmethod\n\nScalar method identical to the corresponding array attribute.\n\nPlease see `ndarray.dumps`.\n\n"}, {"name": "record.fill()", "path": "reference/generated/numpy.record.fill", "type": "numpy.record.fill", "text": "\nmethod\n\nScalar method identical to the corresponding array attribute.\n\nPlease see `ndarray.fill`.\n\n"}, {"name": "record.flags", "path": "reference/generated/numpy.record.flags", "type": "Standard array subclasses", "text": "\nattribute\n\ninteger value of flags\n\n"}, {"name": "record.flat", "path": "reference/generated/numpy.record.flat", "type": "Standard array subclasses", "text": "\nattribute\n\nA 1-D view of the scalar.\n\n"}, {"name": "record.flatten()", "path": "reference/generated/numpy.record.flatten", "type": "numpy.record.flatten", "text": "\nmethod\n\nScalar method identical to the corresponding array attribute.\n\nPlease see `ndarray.flatten`.\n\n"}, {"name": "record.getfield()", "path": "reference/generated/numpy.record.getfield", "type": "numpy.record.getfield", "text": "\nmethod\n\nScalar method identical to the corresponding array attribute.\n\nPlease see `ndarray.getfield`.\n\n"}, {"name": "record.item()", "path": "reference/generated/numpy.record.item", "type": "numpy.record.item", "text": "\nmethod\n\nScalar method identical to the corresponding array attribute.\n\nPlease see `ndarray.item`.\n\n"}, {"name": "record.itemset()", "path": "reference/generated/numpy.record.itemset", "type": "numpy.record.itemset", "text": "\nmethod\n\nScalar method identical to the corresponding array attribute.\n\nPlease see `ndarray.itemset`.\n\n"}, {"name": "record.itemsize", "path": "reference/generated/numpy.record.itemsize", "type": "Standard array subclasses", "text": "\nattribute\n\nThe length of one element in bytes.\n\n"}, {"name": "record.max()", "path": "reference/generated/numpy.record.max", "type": "numpy.record.max", "text": "\nmethod\n\nScalar method identical to the corresponding array attribute.\n\nPlease see `ndarray.max`.\n\n"}, {"name": "record.mean()", "path": "reference/generated/numpy.record.mean", "type": "numpy.record.mean", "text": "\nmethod\n\nScalar method identical to the corresponding array attribute.\n\nPlease see `ndarray.mean`.\n\n"}, {"name": "record.min()", "path": "reference/generated/numpy.record.min", "type": "numpy.record.min", "text": "\nmethod\n\nScalar method identical to the corresponding array attribute.\n\nPlease see `ndarray.min`.\n\n"}, {"name": "record.nbytes", "path": "reference/generated/numpy.record.nbytes", "type": "Standard array subclasses", "text": "\nattribute\n\nThe length of the scalar in bytes.\n\n"}, {"name": "record.ndim", "path": "reference/generated/numpy.record.ndim", "type": "Standard array subclasses", "text": "\nattribute\n\nThe number of array dimensions.\n\n"}, {"name": "record.newbyteorder()", "path": "reference/generated/numpy.record.newbyteorder", "type": "numpy.record.newbyteorder", "text": "\nmethod\n\nReturn a new `dtype` with a different byte order.\n\nChanges are also made in all fields and sub-arrays of the data type.\n\nThe `new_order` code can be any from the following:\n\nByte order to force; a value from the byte order specifications above. The\ndefault value (\u2018S\u2019) results in swapping the current byte order.\n\nNew `dtype` object with the given change to the byte order.\n\n"}, {"name": "record.nonzero()", "path": "reference/generated/numpy.record.nonzero", "type": "numpy.record.nonzero", "text": "\nmethod\n\nScalar method identical to the corresponding array attribute.\n\nPlease see `ndarray.nonzero`.\n\n"}, {"name": "record.pprint()", "path": "reference/generated/numpy.record.pprint", "type": "numpy.record.pprint", "text": "\nmethod\n\nPretty-print all fields.\n\n"}, {"name": "record.prod()", "path": "reference/generated/numpy.record.prod", "type": "numpy.record.prod", "text": "\nmethod\n\nScalar method identical to the corresponding array attribute.\n\nPlease see `ndarray.prod`.\n\n"}, {"name": "record.ptp()", "path": "reference/generated/numpy.record.ptp", "type": "numpy.record.ptp", "text": "\nmethod\n\nScalar method identical to the corresponding array attribute.\n\nPlease see `ndarray.ptp`.\n\n"}, {"name": "record.put()", "path": "reference/generated/numpy.record.put", "type": "numpy.record.put", "text": "\nmethod\n\nScalar method identical to the corresponding array attribute.\n\nPlease see `ndarray.put`.\n\n"}, {"name": "record.ravel()", "path": "reference/generated/numpy.record.ravel", "type": "numpy.record.ravel", "text": "\nmethod\n\nScalar method identical to the corresponding array attribute.\n\nPlease see `ndarray.ravel`.\n\n"}, {"name": "record.repeat()", "path": "reference/generated/numpy.record.repeat", "type": "numpy.record.repeat", "text": "\nmethod\n\nScalar method identical to the corresponding array attribute.\n\nPlease see `ndarray.repeat`.\n\n"}, {"name": "record.reshape()", "path": "reference/generated/numpy.record.reshape", "type": "numpy.record.reshape", "text": "\nmethod\n\nScalar method identical to the corresponding array attribute.\n\nPlease see `ndarray.reshape`.\n\n"}, {"name": "record.resize()", "path": "reference/generated/numpy.record.resize", "type": "numpy.record.resize", "text": "\nmethod\n\nScalar method identical to the corresponding array attribute.\n\nPlease see `ndarray.resize`.\n\n"}, {"name": "record.round()", "path": "reference/generated/numpy.record.round", "type": "numpy.record.round", "text": "\nmethod\n\nScalar method identical to the corresponding array attribute.\n\nPlease see `ndarray.round`.\n\n"}, {"name": "record.searchsorted()", "path": "reference/generated/numpy.record.searchsorted", "type": "numpy.record.searchsorted", "text": "\nmethod\n\nScalar method identical to the corresponding array attribute.\n\nPlease see `ndarray.searchsorted`.\n\n"}, {"name": "record.setfield()", "path": "reference/generated/numpy.record.setfield", "type": "numpy.record.setfield", "text": "\nmethod\n\nScalar method identical to the corresponding array attribute.\n\nPlease see `ndarray.setfield`.\n\n"}, {"name": "record.setflags()", "path": "reference/generated/numpy.record.setflags", "type": "numpy.record.setflags", "text": "\nmethod\n\nScalar method identical to the corresponding array attribute.\n\nPlease see `ndarray.setflags`.\n\n"}, {"name": "record.size", "path": "reference/generated/numpy.record.size", "type": "Standard array subclasses", "text": "\nattribute\n\nThe number of elements in the gentype.\n\n"}, {"name": "record.sort()", "path": "reference/generated/numpy.record.sort", "type": "numpy.record.sort", "text": "\nmethod\n\nScalar method identical to the corresponding array attribute.\n\nPlease see `ndarray.sort`.\n\n"}, {"name": "record.squeeze()", "path": "reference/generated/numpy.record.squeeze", "type": "numpy.record.squeeze", "text": "\nmethod\n\nScalar method identical to the corresponding array attribute.\n\nPlease see `ndarray.squeeze`.\n\n"}, {"name": "record.std()", "path": "reference/generated/numpy.record.std", "type": "numpy.record.std", "text": "\nmethod\n\nScalar method identical to the corresponding array attribute.\n\nPlease see `ndarray.std`.\n\n"}, {"name": "record.strides", "path": "reference/generated/numpy.record.strides", "type": "Standard array subclasses", "text": "\nattribute\n\nTuple of bytes steps in each dimension.\n\n"}, {"name": "record.sum()", "path": "reference/generated/numpy.record.sum", "type": "numpy.record.sum", "text": "\nmethod\n\nScalar method identical to the corresponding array attribute.\n\nPlease see `ndarray.sum`.\n\n"}, {"name": "record.swapaxes()", "path": "reference/generated/numpy.record.swapaxes", "type": "numpy.record.swapaxes", "text": "\nmethod\n\nScalar method identical to the corresponding array attribute.\n\nPlease see `ndarray.swapaxes`.\n\n"}, {"name": "record.T", "path": "reference/generated/numpy.record.t", "type": "Standard array subclasses", "text": "\nattribute\n\nScalar attribute identical to the corresponding array attribute.\n\nPlease see `ndarray.T`.\n\n"}, {"name": "record.take()", "path": "reference/generated/numpy.record.take", "type": "numpy.record.take", "text": "\nmethod\n\nScalar method identical to the corresponding array attribute.\n\nPlease see `ndarray.take`.\n\n"}, {"name": "record.tofile()", "path": "reference/generated/numpy.record.tofile", "type": "numpy.record.tofile", "text": "\nmethod\n\nScalar method identical to the corresponding array attribute.\n\nPlease see `ndarray.tofile`.\n\n"}, {"name": "record.tolist()", "path": "reference/generated/numpy.record.tolist", "type": "numpy.record.tolist", "text": "\nmethod\n\nScalar method identical to the corresponding array attribute.\n\nPlease see `ndarray.tolist`.\n\n"}, {"name": "record.tostring()", "path": "reference/generated/numpy.record.tostring", "type": "numpy.record.tostring", "text": "\nmethod\n\nScalar method identical to the corresponding array attribute.\n\nPlease see `ndarray.tostring`.\n\n"}, {"name": "record.trace()", "path": "reference/generated/numpy.record.trace", "type": "numpy.record.trace", "text": "\nmethod\n\nScalar method identical to the corresponding array attribute.\n\nPlease see `ndarray.trace`.\n\n"}, {"name": "record.transpose()", "path": "reference/generated/numpy.record.transpose", "type": "numpy.record.transpose", "text": "\nmethod\n\nScalar method identical to the corresponding array attribute.\n\nPlease see `ndarray.transpose`.\n\n"}, {"name": "record.var()", "path": "reference/generated/numpy.record.var", "type": "numpy.record.var", "text": "\nmethod\n\nScalar method identical to the corresponding array attribute.\n\nPlease see `ndarray.var`.\n\n"}, {"name": "record.view()", "path": "reference/generated/numpy.record.view", "type": "numpy.record.view", "text": "\nmethod\n\nScalar method identical to the corresponding array attribute.\n\nPlease see `ndarray.view`.\n\n"}, {"name": "Release", "path": "reference/index", "type": "API reference", "text": "\n1.22\n\nDecember 31, 2021\n\nThis reference manual details functions, modules, and objects included in\nNumPy, describing what they are and what they do. For learning how to use\nNumPy, see the complete documentation.\n\nLarge parts of this manual originate from Travis E. Oliphant\u2019s book Guide to\nNumPy (which generously entered Public Domain in August 2008). The reference\ndocumentation for many of the functions are written by numerous contributors\nand developers of NumPy.\n\n"}, {"name": "Release notes", "path": "release", "type": "Release notes", "text": "\n\n"}, {"name": "Releasing a version", "path": "dev/releasing", "type": "Development", "text": "\nThis file gives an overview of what is necessary to build binary releases for\nNumPy.\n\nThe current info on building and releasing NumPy and SciPy is scattered in\nseveral places. It should be summarized in one place, updated, and where\nnecessary described in more detail. The sections below list all places where\nuseful info can be found.\n\nNEP 29 outlines which Python versions are supported; For the first half of\n2020, this will be Python >= 3.6. We test NumPy against all these versions\nevery time we merge code to main. Binary installers may be available for a\nsubset of these versions (see below).\n\nOS X versions >= 10.9 are supported, for Python version support see NEP 29. We\nbuild binary wheels for OSX that are compatible with Python.org Python, system\nPython, homebrew and macports - see this OSX wheel building summary for\ndetails.\n\nWe build 32- and 64-bit wheels on Windows. Windows 7, 8 and 10 are supported.\nWe build NumPy using the mingw-w64 toolchain on Appveyor.\n\nWe build and ship manylinux1 wheels for NumPy. Many Linux distributions\ninclude their own binary builds of NumPy.\n\nNo binaries are provided, but successful builds on Solaris and BSD have been\nreported.\n\nWe build all our wheels on cloud infrastructure - so this list of compilers is\nfor information and debugging builds locally. See the `.travis.yml` script in\nthe numpy wheels repo for the definitive source of the build recipes. Packages\nthat are available using pip are noted.\n\nThe same gcc version is used as the one with which Python itself is built on\neach platform. At the moment this means:\n\nYou will need Cython for building the binaries. Cython compiles the `.pyx`\nfiles in the NumPy distribution to `.c` files.\n\nAll the wheels link to a version of OpenBLAS supplied via the openblas-libs\nrepo. The shared object (or DLL) is shipped with in the wheel, renamed to\nprevent name collisions with other OpenBLAS shared objects that may exist in\nthe filesystem.\n\nYou will need write permission for numpy-wheels in order to trigger wheel\nbuilds.\n\nBuilding the documents requires a number of latex `.sty` files. Install them\nall to avoid aggravation.\n\nYou will need a personal access token\nhttps://help.github.com/articles/creating-a-personal-access-token-for-the-\ncommand-line/ so that scripts can access the github NumPy repository.\n\nVirtualenv is a very useful tool to keep several versions of packages around.\nIt is also used in the Paver script to build the docs.\n\nWe currently support Python 3.6-3.8 on Windows, OSX, and Linux\n\nSee the numpy wheels building repository for more detail.\n\nWe build source releases in both .zip and .tar.gz formats.\n\nA typical release schedule is one beta, two release candidates and a final\nrelease. It\u2019s best to discuss the timing on the mailing list first, in order\nfor people to get their commits in on time, get doc wiki edits merged, etc.\nAfter a date is set, create a new maintenance/x.y.z branch, add new empty\nrelease notes for the next version in the main branch and update the Trac\nMilestones.\n\nFor details of the build process itself, it is best to read the pavement.py\nscript.\n\nNote\n\nThe following steps are repeated for the beta(s), release candidates(s) and\nthe final release.\n\nBefore the release branch is made, it should be checked that all deprecated\ncode that should be removed is actually removed, and all new deprecations say\nin the docstring or deprecation warning at what version the code will be\nremoved.\n\nThe C API version needs to be tracked in three places\n\nThere are three steps to the process.\n\nIf the C_API_VERSION in the first step has changed, or if the hash of the API\nhas changed, the cversions.txt file needs to be updated. To check the hash,\nrun the script numpy/core/cversions.py and note the API hash that is printed.\nIf that hash does not match the last hash in\nnumpy/core/code_generators/cversions.txt the hash has changed. Using both the\nappropriate C_API_VERSION and hash, add a new entry to cversions.txt. If the\nAPI version was not changed, but the hash differs, you will need to comment\nout the previous entry for that API version. For instance, in NumPy 1.9\nannotations were added, which changed the hash, but the API was the same as in\n1.8. The hash serves as a check for API changes, but it is not definitive.\n\nIf steps 1 and 2 are done correctly, compiling the release should not give a\nwarning \u201cAPI mismatch detect at the beginning of the build\u201d.\n\nThe C ABI version number in numpy/core/setup_common.py should only be updated\nfor a major release.\n\nUse towncrier to build the release note and commit the changes. This will\nremove all the fragments from `doc/release/upcoming_changes` and add\n`doc/release/<version>-note.rst`.\n\ntowncrier build \u2013version \u201c<version>\u201d git commit -m\u201dCreate release note\u201d\n\nCheck that the release notes are up-to-date.\n\nUpdate the release notes with a Highlights section. Mention some of the\nfollowing:\n\nIdentify the commit hash of the release, e.g. 1b2e1d63ff:\n\nFirst, change/check the following variables in `pavement.py` depending on the\nrelease version:\n\nDo any other changes. When you are ready to release, do the following changes:\n\nAnd make sure the `VERSION` variable is set properly.\n\nNow you can make the release commit and tag. We recommend you don\u2019t push the\ncommit or tag immediately, just in case you need to do more cleanup. We prefer\nto defer the push of the tag until we\u2019re confident this is the exact form of\nthe released code (see: Push the release tag and commit):\n\ngit commit -s -m \u201cREL: Release.\u201d setup.py git tag -s <version>\n\nThe `-s` flag makes a PGP (usually GPG) signed tag. Please do sign the release\ntags.\n\nThe release tag should have the release number in the annotation (tag\nmessage). Unfortunately, the name of a tag can be changed without breaking the\nsignature, the contents of the message cannot.\n\nSee: https://github.com/scipy/scipy/issues/4919 for a discussion of signing\nrelease tags, and https://keyring.debian.org/creating-key.html for\ninstructions on creating a GPG key if you do not have one.\n\nTo make your key more readily identifiable as you, consider sending your key\nto public keyservers, with a command such as:\n\nIncrement the release number in setup.py. Release candidates should have \u201crc1\u201d\n(or \u201crc2\u201d, \u201crcN\u201d) appended to the X.Y.Z format.\n\nAlso create a new version hash in cversions.txt and a corresponding version\ndefine NPY_x_y_API_VERSION in numpyconfig.h\n\nSee the numpy wheels repository.\n\nIn that repository edit the files:\n\nIn both cases, set the `BUILD_COMMIT` variable to the current release tag -\ne.g. `v1.19.0`:\n\nMake sure that the release tag has been pushed.\n\nTrigger a build by pushing a commit of your edits to the repository. Note that\nyou can do this on a branch, but it must be pushed upstream to the\n`MacPython/numpy-wheels` repository to trigger uploads since only that repo\nhas the appropriate tokens to allow uploads.\n\nThe wheels, once built, appear at https://anaconda.org/multibuild-wheels-\nstaging/numpy\n\nBuild the changelog and notes for upload with:\n\nDo:\n\nto check that the documentation is in a buildable state. Then, after tagging,\ncreate an archive of the documentation in the numpy/doc repo:\n\nThe wheels and source should be uploaded to PyPI.\n\nYou should upload the wheels first, and the source formats last, to make sure\nthat pip users don\u2019t accidentally get a source install when they were\nexpecting a binary wheel.\n\nYou can do this automatically using the `wheel-uploader` script from\nhttps://github.com/MacPython/terryfy. Here is the recommended incantation for\ndownloading all the Windows, Manylinux, OSX wheels and uploading to PyPI.\n\nThe `-v` flag gives verbose feedback, `-s` causes the script to sign the\nwheels with your GPG key before upload. Don\u2019t forget to upload the wheels\nbefore the source tarball, so there is no period for which people switch from\nan expected binary install to a source install from PyPI.\n\nThere are two ways to update the source release on PyPI, the first one is:\n\nThis will ask for your key PGP passphrase, in order to sign the built source\npackages.\n\nThe second way is to upload the PKG_INFO file inside the sdist dir in the web\ninterface of PyPI. The source tarball can also be uploaded through this\ninterface.\n\nFinally, now you are confident this tag correctly defines the source code that\nyou released you can push the tag and release commit up to github:\n\nwhere `upstream` points to the main https://github.com/numpy/numpy.git\nrepository.\n\nA release announcement with a link to the download site should be placed in\nthe sidebar of the front page of scipy.org.\n\nThe scipy.org should be a PR at https://github.com/scipy/scipy.org. The file\nthat needs modification is `www/index.rst`. Search for `News`.\n\nIf this release is the first one to support a new Python version, or the first\nto provide wheels for a new platform or PyPy version, the version pinnings in\nhttps://github.com/scipy/oldest-supported-numpy should be updated. Either\nsubmit a PR with changes to `setup.cfg` there, or open an issue with info on\nneeded changes.\n\nThe release should be announced on the mailing lists of NumPy and SciPy, to\npython-announce, and possibly also those of Matplotlib, IPython and/or Pygame.\n\nDuring the beta/RC phase, an explicit request for testing the binaries with\nseveral other libraries (SciPy/Matplotlib/Pygame) should be posted on the\nmailing list.\n\nEmail the editor of LWN to let them know of the release. Directions at:\nhttps://lwn.net/op/FAQ.lwn#contact\n\nAfter the final release is announced, a few administrative tasks are left to\nbe done:\n\nThis file contains a walkthrough of the NumPy 1.21.0 release on Linux,\nmodified for building on azure and uploading to anaconda.org The commands can\nbe copied into the command line, but be sure to replace 1.21.0 by the correct\nversion.\n\nThis should be read together with the general directions in `releasing`.\n\nChanges that have been marked for this release must be backported to the\nmaintenance/1.21.x branch.\n\nFour documents usually need to be updated or created before making a release:\n\nThese changes should be made as an ordinary PR against the maintenance branch.\nAfter release all files except `doc/source/release.rst` will need to be\nforward ported to the main branch.\n\nThe changelog is generated using the changelog tool:\n\nwhere `GITHUB` contains your GitHub access token. The text will need to be\nchecked for non-standard contributor names and dependabot entries removed. It\nis also a good idea to remove any links that may be present in the PR titles\nas they don\u2019t translate well to markdown, replace them with monospaced text.\nThe non-standard contributor names should be fixed by updating the `.mailmap`\nfile, which is a lot of work. It is best to make several trial runs before\nreaching this point and ping the malefactors using a GitHub issue to get the\nneeded information.\n\nIf this is the first release in a series the release note is generated, see\nthe release note in `doc/release/upcoming_changes/README.rst` to see how to do\nthis. Generating the release notes will also delete all the news fragment\nfiles in `doc/release/upcoming_changes/`.\n\nThe generated release note will always need some fixups, the introduction will\nneed to be written, and significant changes should be called out. For patch\nreleases the changelog text may also be appended, but not for the initial\nrelease as it is too long. Check previous release notes to see how this is\ndone. Note that the `:orphan:` markup at the top, if present, will need\nchanging to `.. currentmodule:: numpy` and the `doc/source/release.rst` index\nfile will need updating.\n\nCheck that the pavement.py file points to the correct release notes. It should\nhave been updated after the last release, but if not, fix it now:\n\nNote that in the code snippets below, `upstream` refers to the root repository\non GitHub and `origin` to its fork in your personal GitHub repositories. You\nmay need to make adjustments if you have not forked the repository but simply\ncloned it locally. You can also edit `.git/config` and add `upstream` if it\nisn\u2019t already present.\n\nCheckout the branch for the release, make sure it is up to date, and clean the\nrepository:\n\nSanity check:\n\nTag the release and push the tag. This requires write permission for the numpy\nrepository:\n\nPaver is used to build the source releases. It will create the `release` and\n`release/installers` directories and put the `*.zip` and `*.tar.gz` source\nreleases in the latter.\n\nTrigger the wheels build by pointing the numpy-wheels repository at this\ncommit. This can take up to an hour. The numpy-wheels repository is cloned\nfrom https://github.com/MacPython/numpy-wheels. If this is the first release\nin a series, start with a pull as the repo may have been accessed and changed\nby someone else, then create a new branch for the series. If the branch\nalready exists skip this:\n\nCheckout the new branch and edit the `azure-pipelines.yml` and `.travis.yml`\nfiles to make sure they have the correct version, and put in the commit hash\nfor the `REL` commit created above for `BUILD_COMMIT` variable. The\n`azure/posix.yml` and `.travis.yml` files may also need the Cython versions\nupdated to keep up with Python releases, but generally just do:\n\nNow wait. If you get nervous at the amount of time taken \u2013 the builds can take\na while \u2013 you can check the build progress by following the links provided at\nhttps://github.com/MacPython/numpy-wheels to check the build status. Check if\nall the needed wheels have been built and uploaded to the staging repository\nbefore proceeding.\n\nNote that sometimes builds, like tests, fail for unrelated reasons and you\nwill need to rerun them. You will need to be logged in under \u2018numpy\u2019 to do\nthis on azure.\n\nWhen the wheels have all been successfully built and staged, download them\nfrom the Anaconda staging directory using the `tools/download-wheels.py`\nscript:\n\nThis needs to be done after all installers are downloaded, but before the\npavement file is updated for continued development:\n\nCreate release notes for next release and edit them to set the version. These\nnotes will be a skeleton and have little content:\n\nAdd new release notes to the documentation release list and update the\n`RELEASE_NOTES` variable in `pavement.py`.\n\n$ gvim doc/source/release.rst pavement.py\n\nCommit the result:\n\nUpload to PyPI using `twine`. A recent version of `twine` of is needed after\nrecent PyPI changes, version `3.4.1` was used here:\n\nIf one of the commands breaks in the middle, you may need to selectively\nupload the remaining files because PyPI does not allow the same file to be\nuploaded twice. The source file should be uploaded last to avoid\nsynchronization problems that might occur if pip users access the files while\nthis is in process, causing pip to build from source rather than downloading a\nbinary wheel. PyPI only allows a single source distribution, here we have\nchosen the zip archive.\n\nGo to https://github.com/numpy/numpy/releases, there should be a `v1.21.0\ntag`, click on it and hit the edit button for that tag. There are two ways to\nadd files, using an editable text window and as binary uploads. Start by\nediting the `release/README.md` that is translated from the rst version using\npandoc. Things that will need fixing: PR lines from the changelog, if\nincluded, are wrapped and need unwrapping, links should be changed to\nmonospaced text. Then copy the contents to the clipboard and paste them into\nthe text window. It may take several tries to get it look right. Then\n\nThis step is only needed for final releases and can be skipped for pre-\nreleases and most patch releases. `make merge-doc` clones the `numpy/doc` repo\ninto `doc/build/merge` and updates it with the new documentation:: Note that\nif you have a `local` numpy install, you should either remove it or install\nthe current version for the docs to pick up the correct NumPy version.\n\n$ pushd doc $ make dist $ make merge-doc $ popd\n\nIf the release series is a new one, you will need to add a new section to the\n`doc/build/merge/index.html` front page just after the \u201cinsert here\u201d comment:\n\nOtherwise, only the `zip` and `pdf` links should be updated with the new tag\nname:\n\nYou can \u201ctest run\u201d the new documentation in a browser to make sure the links\nwork:\n\nUpdate the stable link:\n\nOnce everything seems satisfactory, commit and upload the changes:\n\nThis assumes that you have forked https://github.com/scipy/scipy.org:\n\nNow go to your fork and make a pull request for the branch.\n\nThe release should be announced on the numpy-discussion, scipy-devel, scipy-\nuser, and python-announce-list mailing lists. Look at previous announcements\nfor the basic template. The contributor and PR lists are the same as generated\nfor the release notes above. If you crosspost, make sure that python-announce-\nlist is BCC so that replies will not be sent to that list.\n\nCheckout main and forward port the documentation changes:\n\nGo to GitHub and make a PR.\n\n"}, {"name": "Reporting bugs", "path": "bugs", "type": "Reporting bugs", "text": "\nFile bug reports or feature requests, and make contributions (e.g. code\npatches), by opening a \u201cnew issue\u201d on GitHub:\n\nPlease give as much information as you can in the ticket. It is extremely\nuseful if you can supply a small self-contained code snippet that reproduces\nthe problem. Also specify the component, the version you are referring to and\nthe milestone.\n\nReport bugs to the appropriate GitHub project (there is one for NumPy and a\ndifferent one for SciPy).\n\nMore information can be found on the https://www.scipy.org/scipylib/dev-\nzone.html website.\n\n"}, {"name": "Routines", "path": "reference/routines", "type": "Routines", "text": "\nIn this chapter routine docstrings are presented, grouped by functionality.\nMany docstrings contain example code, which demonstrates basic usage of the\nroutine. The examples assume that NumPy is imported with:\n\nA convenient way to execute examples is the `%doctest_mode` mode of IPython,\nwhich allows for pasting of multi-line examples and preserves indentation.\n\n"}, {"name": "self.typeStr", "path": "reference/swig.testing", "type": "Testing the numpy.i Typemaps", "text": "\nWriting tests for the `numpy.i` SWIG interface file is a combinatorial\nheadache. At present, 12 different data types are supported, each with 74\ndifferent argument signatures, for a total of 888 typemaps supported \u201cout of\nthe box\u201d. Each of these typemaps, in turn, might require several unit tests in\norder to verify expected behavior for both proper and improper inputs.\nCurrently, this results in more than 1,000 individual unit tests executed when\n`make test` is run in the `numpy/tools/swig` subdirectory.\n\nTo facilitate this many similar unit tests, some high-level programming\ntechniques are employed, including C and SWIG macros, as well as Python\ninheritance. The purpose of this document is to describe the testing\ninfrastructure employed to verify that the `numpy.i` typemaps are working as\nexpected.\n\nThere are three independent testing frameworks supported, for one-, two-, and\nthree-dimensional arrays respectively. For one-dimensional arrays, there are\ntwo C++ files, a header and a source, named:\n\nthat contain prototypes and code for a variety of functions that have one-\ndimensional arrays as function arguments. The file:\n\nis a SWIG interface file that defines a python module `Vector` that wraps the\nfunctions in `Vector.h` while utilizing the typemaps in `numpy.i` to correctly\nhandle the C arrays.\n\nThe `Makefile` calls `swig` to generate `Vector.py` and `Vector_wrap.cxx`, and\nalso executes the `setup.py` script that compiles `Vector_wrap.cxx` and links\ntogether the extension module `_Vector.so` or `_Vector.dylib`, depending on\nthe platform. This extension module and the proxy file `Vector.py` are both\nplaced in a subdirectory under the `build` directory.\n\nThe actual testing takes place with a Python script named:\n\nthat uses the standard Python library module `unittest`, which performs\nseveral tests of each function defined in `Vector.h` for each data type\nsupported.\n\nTwo-dimensional arrays are tested in exactly the same manner. The above\ndescription applies, but with `Matrix` substituted for `Vector`. For three-\ndimensional tests, substitute `Tensor` for `Vector`. For four-dimensional\ntests, substitute `SuperTensor` for `Vector`. For flat in-place array tests,\nsubstitute `Flat` for `Vector`. For the descriptions that follow, we will\nreference the `Vector` tests, but the same information applies to `Matrix`,\n`Tensor` and `SuperTensor` tests.\n\nThe command `make test` will ensure that all of the test software is built and\nthen run all three test scripts.\n\n`Vector.h` is a C++ header file that defines a C macro called\n`TEST_FUNC_PROTOS` that takes two arguments: `TYPE`, which is a data type name\nsuch as `unsigned int`; and `SNAME`, which is a short name for the same data\ntype with no spaces, e.g. `uint`. This macro defines several function\nprototypes that have the prefix `SNAME` and have at least one argument that is\nan array of type `TYPE`. Those functions that have return arguments return a\n`TYPE` value.\n\n`TEST_FUNC_PROTOS` is then implemented for all of the data types supported by\n`numpy.i`:\n\n`Vector.cxx` is a C++ source file that implements compilable code for each of\nthe function prototypes specified in `Vector.h`. It defines a C macro\n`TEST_FUNCS` that has the same arguments and works in the same way as\n`TEST_FUNC_PROTOS` does in `Vector.h`. `TEST_FUNCS` is implemented for each of\nthe 12 data types as above.\n\n`Vector.i` is a SWIG interface file that defines python module `Vector`. It\nfollows the conventions for using `numpy.i` as described in this chapter. It\ndefines a SWIG macro `%apply_numpy_typemaps` that has a single argument\n`TYPE`. It uses the SWIG directive `%apply` to apply the provided typemaps to\nthe argument signatures found in `Vector.h`. This macro is then implemented\nfor all of the data types supported by `numpy.i`. It then does a `%include\n\"Vector.h\"` to wrap all of the function prototypes in `Vector.h` using the\ntypemaps in `numpy.i`.\n\nAfter `make` is used to build the testing extension modules, `testVector.py`\ncan be run to execute the tests. As with other scripts that use `unittest` to\nfacilitate unit testing, `testVector.py` defines a class that inherits from\n`unittest.TestCase`:\n\nHowever, this class is not run directly. Rather, it serves as a base class to\nseveral other python classes, each one specific to a particular data type. The\n`VectorTestCase` class stores two strings for typing information:\n\nA string that matches one of the `SNAME` prefixes used in `Vector.h` and\n`Vector.cxx`. For example, `\"double\"`.\n\nA short (typically single-character) string that represents a data type in\nnumpy and corresponds to `self.typeStr`. For example, if `self.typeStr` is\n`\"double\"`, then `self.typeCode` should be `\"d\"`.\n\nEach test defined by the `VectorTestCase` class extracts the python function\nit is trying to test by accessing the `Vector` module\u2019s dictionary:\n\nIn the case of double precision tests, this will return the python function\n`Vector.doubleLength`.\n\nWe then define a new test case class for each supported data type with a short\ndefinition such as:\n\nEach of these 12 classes is collected into a `unittest.TestSuite`, which is\nthen executed. Errors and failures are summed together and returned as the\nexit argument. Any non-zero result indicates that at least one test did not\npass.\n\n"}, {"name": "Set routines", "path": "reference/routines.set", "type": "Set routines", "text": "\n`lib.arraysetops`\n\nSet operations for arrays based on sorting.\n\n`unique`(ar[, return_index, return_inverse, ...])\n\nFind the unique elements of an array.\n\n`in1d`(ar1, ar2[, assume_unique, invert])\n\nTest whether each element of a 1-D array is also present in a second array.\n\n`intersect1d`(ar1, ar2[, assume_unique, ...])\n\nFind the intersection of two arrays.\n\n`isin`(element, test_elements[, ...])\n\nCalculates `element in test_elements`, broadcasting over `element` only.\n\n`setdiff1d`(ar1, ar2[, assume_unique])\n\nFind the set difference of two arrays.\n\n`setxor1d`(ar1, ar2[, assume_unique])\n\nFind the set exclusive-or of two arrays.\n\n`union1d`(ar1, ar2)\n\nFind the union of two arrays.\n\n"}, {"name": "Setting up and using your development environment", "path": "dev/development_environment", "type": "Development", "text": "\nSince NumPy contains parts written in C and Cython that need to be compiled\nbefore use, make sure you have the necessary compilers and Python development\nheaders installed - see Building from source. Building NumPy as of version\n`1.17` requires a C99 compliant compiler.\n\nHaving compiled code also means that importing NumPy from the development\nsources needs some additional steps, which are explained below. For the rest\nof this chapter we assume that you have set up your git repo as described in\nGit for development.\n\nTo build the development version of NumPy and run tests, spawn interactive\nshells with the Python import paths properly set up etc., do one of:\n\nThis builds NumPy first, so the first time it may take a few minutes. If you\nspecify `-n`, the tests are run against the version of NumPy (if any) found on\ncurrent PYTHONPATH.\n\nWhen specifying a target using `-s`, `-t`, or `--python`, additional arguments\nmay be forwarded to the target embedded by `runtests.py` by passing the extra\narguments after a bare `--`. For example, to run a test method with the\n`--pdb` flag forwarded to the target, run the following:\n\nWhen using pytest as a target (the default), you can match test names using\npython operators by passing the `-k` argument to pytest:\n\nNote\n\nRemember that all tests of NumPy should pass before committing your changes.\n\nUsing `runtests.py` is the recommended approach to running tests. There are\nalso a number of alternatives to it, for example in-place build or installing\nto a virtualenv or a conda environment. See the FAQ below for details.\n\nNote\n\nSome of the tests in the test suite require a large amount of memory, and are\nskipped if your system does not have enough.\n\nTo override the automatic detection of available memory, set the environment\nvariable `NPY_AVAILABLE_MEM`, for example `NPY_AVAILABLE_MEM=32GB`, or using\npytest `--available-memory=32GB` target option.\n\nFor development, you can set up an in-place build so that changes made to\n`.py` files have effect without rebuild. First, run:\n\nThis allows you to import the in-place built NumPy from the repo base\ndirectory only. If you want the in-place build to be visible outside that base\ndir, you need to point your `PYTHONPATH` environment variable to this\ndirectory. Some IDEs (Spyder for example) have utilities to manage\n`PYTHONPATH`. On Linux and OSX, you can run the command:\n\nand on Windows:\n\nNow editing a Python source file in NumPy allows you to immediately test and\nuse your changes (in `.py` files), by simply restarting the interpreter.\n\nNote that another way to do an inplace build visible outside the repo base dir\nis with `python setup.py develop`. Instead of adjusting `PYTHONPATH`, this\ninstalls a `.egg-link` file into your site-packages as well as adjusts the\n`easy-install.pth` there, so its a more permanent (and magical) operation.\n\nBuild options can be discovered by running any of:\n\nIt\u2019s possible to do a parallel build with `numpy.distutils` with the `-j`\noption; see Parallel builds for more details.\n\nA similar approach to in-place builds and use of `PYTHONPATH` but outside the\nsource tree is to use:\n\nNumPy uses a series of tests to probe the compiler and libc libraries for\nfunctions. The results are stored in `_numpyconfig.h` and `config.h` files\nusing `HAVE_XXX` definitions. These tests are run during the `build_src` phase\nof the `_multiarray_umath` module in the `generate_config_h` and\n`generate_numpyconfig_h` functions. Since the output of these calls includes\nmany compiler warnings and errors, by default it is run quietly. If you wish\nto see this output, you can run the `build_src` stage verbosely:\n\nA frequently asked question is \u201cHow do I set up a development version of NumPy\nin parallel to a released version that I use to do my job/research?\u201d.\n\nOne simple way to achieve this is to install the released version in site-\npackages, by using pip or conda for example, and set up the development\nversion in a virtual environment.\n\nIf you use conda, we recommend creating a separate virtual environment for\nnumpy development using the `environment.yml` file in the root of the repo\n(this will create the environment and install all development dependencies at\nonce):\n\nIf you installed Python some other way than conda, first install virtualenv\n(optionally use virtualenvwrapper), then create your virtualenv (named `numpy-\ndev` here) with:\n\nNow, whenever you want to switch to the virtual environment, you can use the\ncommand `source numpy-dev/bin/activate`, and `deactivate` to exit from the\nvirtual environment and back to your previous shell.\n\nBesides using `runtests.py`, there are various ways to run the tests. Inside\nthe interpreter, tests can be run like this:\n\nOr a similar way from the command line:\n\nTests can also be run with `pytest numpy`, however then the NumPy-specific\nplugin is not found which causes strange side effects\n\nRunning individual test files can be useful; it\u2019s much faster than running the\nwhole test suite or that of a whole module (example: `np.random.test()`). This\ncan be done with:\n\nThat also takes extra arguments, like `--pdb` which drops you into the Python\ndebugger when a test fails or an exception is raised.\n\nRunning tests with tox is also supported. For example, to build NumPy and run\nthe test suite with Python 3.7, use:\n\nFor more extensive information, see Testing Guidelines\n\nNote: do not run the tests from the root directory of your numpy git repo\nwithout ``runtests.py``, that will result in strange test errors.\n\nLint checks can be performed on newly added lines of Python code.\n\nInstall all dependent packages using pip:\n\nTo run lint checks before committing new code, run:\n\nTo check all changes in newly added Python code of current branch with target\nbranch, run:\n\nIf there are no errors, the script exits with no message. In case of errors:\n\nIt is advisable to run lint checks before pushing commits to a remote branch\nsince the linter runs as part of the CI pipeline.\n\nFor more details on Style Guidelines:\n\nRebuilding NumPy after making changes to compiled code can be done with the\nsame build command as you used previously - only the changed files will be re-\nbuilt. Doing a full build, which sometimes is necessary, requires cleaning the\nworkspace first. The standard way of doing this is (note: deletes any\nuncommitted files!):\n\nWhen you want to discard all changes and go back to the last commit in the\nrepo, use one of:\n\nAnother frequently asked question is \u201cHow do I debug C code inside NumPy?\u201d.\nFirst, ensure that you have gdb installed on your system with the Python\nextensions (often the default on Linux). You can see which version of Python\nis running inside gdb to verify your setup:\n\nNext you need to write a Python script that invokes the C code whose execution\nyou want to debug. For instance `mytest.py`:\n\nNow, you can run:\n\nAnd then in the debugger:\n\nThe execution will now stop at the corresponding C function and you can step\nthrough it as usual. A number of useful Python-specific commands are\navailable. For example to see where in the Python code you are, use `py-list`.\nFor more details, see DebuggingWithGdb. Here are some commonly used commands:\n\nInstead of plain `gdb` you can of course use your favourite alternative\ndebugger; run it on the python binary with arguments `runtests.py -g --python\nmytest.py`.\n\nBuilding NumPy with a Python built with debug support (on Linux distributions\ntypically packaged as `python-dbg`) is highly recommended.\n\nThe best strategy to better understand the code base is to pick something you\nwant to change and start reading the code to figure out how it works. When in\ndoubt, you can ask questions on the mailing list. It is perfectly okay if your\npull requests aren\u2019t perfect, the community is always happy to help. As a\nvolunteer project, things do sometimes get dropped and it\u2019s totally fine to\nping us if something has sat without a response for about two to four weeks.\n\nSo go ahead and pick something that annoys or confuses you about NumPy,\nexperiment with the code, hang around for discussions or go through the\nreference documents to try to fix it. Things will fall in place and soon\nyou\u2019ll have a pretty good understanding of the project as a whole. Good Luck!\n\n"}, {"name": "Setting up git for NumPy development", "path": "dev/gitwash/development_setup", "type": "Development", "text": "\nTo contribute code or documentation, you first need\n\nYou may already have git; check by typing `git --version`. If it\u2019s installed\nyou\u2019ll see some variation of `git version 2.11.0`. If instead you see `command\nis not recognized`, `command not found`, etc., install git.\n\nThen set your name and email:\n\nIf you don\u2019t have a GitHub account, visit https://github.com/join to create\none.\n\n`Forking` has two steps \u2013 visit GitHub to create a fork repo in your account,\nthen make a copy of it on your own machine.\n\nAt the upper right of the page, click `Fork`:\n\nYou\u2019ll see\n\nand then you\u2019ll be taken to the home page of your forked copy:\n\nIn the directory where you want the copy created, run\n\nYou\u2019ll see something like:\n\nA directory `numpy` is created on your machine. (If you already have a numpy\ndirectory, GitHub will choose a different name like `numpy-1`.)\n\nGive the name `upstream` to the main NumPy repo:\n\nSet up your repository so `git pull` pulls from `upstream` by default:\n\nThe branches shown by `git branch -a` will include\n\nIf `upstream` isn\u2019t there, it will be added after you access the NumPy repo\nwith a command like `git fetch` or `git pull`.\n\nThe repos shown by `git remote -v show` will include your fork on GitHub and\nthe main repo:\n\n`git config --list` will include\n\nCloning your NumPy fork repo required no password, because it read the remote\nrepo without changing it. Later, though, submitting your pull requests will\nwrite to it, and GitHub will ask for your username and password \u2013 even though\nit\u2019s your own repo. You can eliminate this authentication without compromising\nsecurity by setting up SSH keys .\n\nIf you set up the keys before cloning, the instructions above change slightly.\nInstead of\n\nrun\n\nand instead of showing an `https` URL, `git remote -v` will show\n\nIf you have cloned already and want to start using SSH, see Switching remote\nURLs from HTTPS to SSH .\n\n"}, {"name": "setup.py", "path": "reference/random/examples/cython/setup.py", "type": "Cython", "text": "\n\n"}, {"name": "Some cases where uint and true alignment are different ()", "path": "dev/alignment", "type": "Development", "text": "\nThere are three use-cases related to memory alignment in NumPy (as of 1.14):\n\nNumPy uses two different forms of alignment to achieve these goals: \u201cTrue\nalignment\u201d and \u201cUint alignment\u201d.\n\n\u201cTrue\u201d alignment refers to the architecture-dependent alignment of an\nequivalent C-type in C. For example, in x64 systems `float64` is equivalent to\n`double` in C. On most systems, this has either an alignment of 4 or 8 bytes\n(and this can be controlled in GCC by the option `malign-double`). A variable\nis aligned in memory if its memory offset is a multiple of its alignment. On\nsome systems (eg. sparc) memory alignment is required; on others, it gives a\nspeedup.\n\n\u201cUint\u201d alignment depends on the size of a datatype. It is defined to be the\n\u201cTrue alignment\u201d of the uint used by NumPy\u2019s copy-code to copy the datatype,\nor undefined/unaligned if there is no equivalent uint. Currently, NumPy uses\n`uint8`, `uint16`, `uint32`, `uint64`, and `uint64` to copy data of size 1, 2,\n4, 8, 16 bytes respectively, and all other sized datatypes cannot be uint-\naligned.\n\nFor example, on a (typical Linux x64 GCC) system, the NumPy `complex64`\ndatatype is implemented as `struct { float real, imag; }`. This has \u201ctrue\u201d\nalignment of 4 and \u201cuint\u201d alignment of 8 (equal to the true alignment of\n`uint64`).\n\narch\n\ntype\n\ntrue-aln\n\nuint-aln\n\nx86_64\n\ncomplex64\n\n4\n\n8\n\nx86_64\n\nfloat128\n\n16\n\n8\n\nx86\n\nfloat96\n\n4\n\n-\nThere are 4 relevant uses of the word `align` used in NumPy:\n\nHere is how the variables above are used:\n\nNote that the strided-copy and strided-cast code are deeply intertwined and so\nany arrays being processed by them must be both uint and true aligned, even\nthough the copy-code only needs uint alignment and the cast code only true\nalignment. If there is ever a big rewrite of this code it would be good to\nallow them to use different alignments.\n\n"}, {"name": "Sorting, searching, and counting", "path": "reference/routines.sort", "type": "Sorting, searching, and counting", "text": "\n`sort`(a[, axis, kind, order])\n\nReturn a sorted copy of an array.\n\n`lexsort`(keys[, axis])\n\nPerform an indirect stable sort using a sequence of keys.\n\n`argsort`(a[, axis, kind, order])\n\nReturns the indices that would sort an array.\n\n`ndarray.sort`([axis, kind, order])\n\nSort an array in-place.\n\n`msort`(a)\n\nReturn a copy of an array sorted along the first axis.\n\n`sort_complex`(a)\n\nSort a complex array using the real part first, then the imaginary part.\n\n`partition`(a, kth[, axis, kind, order])\n\nReturn a partitioned copy of an array.\n\n`argpartition`(a, kth[, axis, kind, order])\n\nPerform an indirect partition along the given axis using the algorithm\nspecified by the `kind` keyword.\n\n`argmax`(a[, axis, out, keepdims])\n\nReturns the indices of the maximum values along an axis.\n\n`nanargmax`(a[, axis, out, keepdims])\n\nReturn the indices of the maximum values in the specified axis ignoring NaNs.\n\n`argmin`(a[, axis, out, keepdims])\n\nReturns the indices of the minimum values along an axis.\n\n`nanargmin`(a[, axis, out, keepdims])\n\nReturn the indices of the minimum values in the specified axis ignoring NaNs.\n\n`argwhere`(a)\n\nFind the indices of array elements that are non-zero, grouped by element.\n\n`nonzero`(a)\n\nReturn the indices of the elements that are non-zero.\n\n`flatnonzero`(a)\n\nReturn indices that are non-zero in the flattened version of a.\n\n`where`(condition, [x, y], /)\n\nReturn elements chosen from `x` or `y` depending on `condition`.\n\n`searchsorted`(a, v[, side, sorter])\n\nFind indices where elements should be inserted to maintain order.\n\n`extract`(condition, arr)\n\nReturn the elements of an array that satisfy some condition.\n\n`count_nonzero`(a[, axis, keepdims])\n\nCounts the number of non-zero values in the array `a`.\n\n"}, {"name": "static distutils.ccompiler_opt.CCompilerOpt.dist_error()", "path": "reference/generated/numpy.distutils.ccompiler_opt.ccompileropt.dist_error", "type": "numpy.distutils.ccompiler_opt.CCompilerOpt.dist_error", "text": "\nmethod\n\nRaise a compiler error\n\n"}, {"name": "static distutils.ccompiler_opt.CCompilerOpt.dist_fatal()", "path": "reference/generated/numpy.distutils.ccompiler_opt.ccompileropt.dist_fatal", "type": "numpy.distutils.ccompiler_opt.CCompilerOpt.dist_fatal", "text": "\nmethod\n\nRaise a distutils error\n\n"}, {"name": "static distutils.ccompiler_opt.CCompilerOpt.dist_load_module()", "path": "reference/generated/numpy.distutils.ccompiler_opt.ccompileropt.dist_load_module", "type": "numpy.distutils.ccompiler_opt.CCompilerOpt.dist_load_module", "text": "\nmethod\n\nLoad a module from file, required by the abstract class \u2018_Cache\u2019.\n\n"}, {"name": "static distutils.ccompiler_opt.CCompilerOpt.dist_log()", "path": "reference/generated/numpy.distutils.ccompiler_opt.ccompileropt.dist_log", "type": "numpy.distutils.ccompiler_opt.CCompilerOpt.dist_log", "text": "\nmethod\n\nPrint a console message\n\n"}, {"name": "static distutils.ccompiler_opt.CCompilerOpt.me()", "path": "reference/generated/numpy.distutils.ccompiler_opt.ccompileropt.me", "type": "numpy.distutils.ccompiler_opt.CCompilerOpt.me", "text": "\nmethod\n\nA static method that can be treated as a decorator to dynamically cache\ncertain methods.\n\n"}, {"name": "static ma.MaskedArray.__new__()", "path": "reference/generated/numpy.ma.maskedarray.__new__", "type": "Masked arrays", "text": "\nmethod\n\nCreate a new masked array from scratch.\n\nA masked array can also be created by taking a .view(MaskedArray).\n\n"}, {"name": "Statistics", "path": "reference/routines.statistics", "type": "Statistics", "text": "\n`ptp`(a[, axis, out, keepdims])\n\nRange of values (maximum - minimum) along an axis.\n\n`percentile`(a, q[, axis, out, ...])\n\nCompute the q-th percentile of the data along the specified axis.\n\n`nanpercentile`(a, q[, axis, out, ...])\n\nCompute the qth percentile of the data along the specified axis, while\nignoring nan values.\n\n`quantile`(a, q[, axis, out, overwrite_input, ...])\n\nCompute the q-th quantile of the data along the specified axis.\n\n`nanquantile`(a, q[, axis, out, ...])\n\nCompute the qth quantile of the data along the specified axis, while ignoring\nnan values.\n\n`median`(a[, axis, out, overwrite_input, keepdims])\n\nCompute the median along the specified axis.\n\n`average`(a[, axis, weights, returned])\n\nCompute the weighted average along the specified axis.\n\n`mean`(a[, axis, dtype, out, keepdims, where])\n\nCompute the arithmetic mean along the specified axis.\n\n`std`(a[, axis, dtype, out, ddof, keepdims, where])\n\nCompute the standard deviation along the specified axis.\n\n`var`(a[, axis, dtype, out, ddof, keepdims, where])\n\nCompute the variance along the specified axis.\n\n`nanmedian`(a[, axis, out, overwrite_input, ...])\n\nCompute the median along the specified axis, while ignoring NaNs.\n\n`nanmean`(a[, axis, dtype, out, keepdims, where])\n\nCompute the arithmetic mean along the specified axis, ignoring NaNs.\n\n`nanstd`(a[, axis, dtype, out, ddof, ...])\n\nCompute the standard deviation along the specified axis, while ignoring NaNs.\n\n`nanvar`(a[, axis, dtype, out, ddof, ...])\n\nCompute the variance along the specified axis, while ignoring NaNs.\n\n`corrcoef`(x[, y, rowvar, bias, ddof, dtype])\n\nReturn Pearson product-moment correlation coefficients.\n\n`correlate`(a, v[, mode])\n\nCross-correlation of two 1-dimensional sequences.\n\n`cov`(m[, y, rowvar, bias, ddof, fweights, ...])\n\nEstimate a covariance matrix, given data and weights.\n\n`histogram`(a[, bins, range, normed, weights, ...])\n\nCompute the histogram of a dataset.\n\n`histogram2d`(x, y[, bins, range, normed, ...])\n\nCompute the bi-dimensional histogram of two data samples.\n\n`histogramdd`(sample[, bins, range, normed, ...])\n\nCompute the multidimensional histogram of some data.\n\n`bincount`(x, /[, weights, minlength])\n\nCount number of occurrences of each value in array of non-negative ints.\n\n`histogram_bin_edges`(a[, bins, range, weights])\n\nFunction to calculate only the edges of the bins used by the `histogram`\nfunction.\n\n`digitize`(x, bins[, right])\n\nReturn the indices of the bins to which each value in input array belongs.\n\n"}, {"name": "String operations", "path": "reference/routines.char", "type": "String operations", "text": "\nThe `numpy.char` module provides a set of vectorized string operations for\narrays of type `numpy.str_` or `numpy.bytes_`. All of them are based on the\nstring methods in the Python standard library.\n\n`add`(x1, x2)\n\nReturn element-wise string concatenation for two arrays of str or unicode.\n\n`multiply`(a, i)\n\nReturn (a * i), that is string multiple concatenation, element-wise.\n\n`mod`(a, values)\n\nReturn (a % i), that is pre-Python 2.6 string formatting (interpolation),\nelement-wise for a pair of array_likes of str or unicode.\n\n`capitalize`(a)\n\nReturn a copy of `a` with only the first character of each element\ncapitalized.\n\n`center`(a, width[, fillchar])\n\nReturn a copy of `a` with its elements centered in a string of length `width`.\n\n`decode`(a[, encoding, errors])\n\nCalls `str.decode` element-wise.\n\n`encode`(a[, encoding, errors])\n\nCalls `str.encode` element-wise.\n\n`expandtabs`(a[, tabsize])\n\nReturn a copy of each string element where all tab characters are replaced by\none or more spaces.\n\n`join`(sep, seq)\n\nReturn a string which is the concatenation of the strings in the sequence\n`seq`.\n\n`ljust`(a, width[, fillchar])\n\nReturn an array with the elements of `a` left-justified in a string of length\n`width`.\n\n`lower`(a)\n\nReturn an array with the elements converted to lowercase.\n\n`lstrip`(a[, chars])\n\nFor each element in `a`, return a copy with the leading characters removed.\n\n`partition`(a, sep)\n\nPartition each element in `a` around `sep`.\n\n`replace`(a, old, new[, count])\n\nFor each element in `a`, return a copy of the string with all occurrences of\nsubstring `old` replaced by `new`.\n\n`rjust`(a, width[, fillchar])\n\nReturn an array with the elements of `a` right-justified in a string of length\n`width`.\n\n`rpartition`(a, sep)\n\nPartition (split) each element around the right-most separator.\n\n`rsplit`(a[, sep, maxsplit])\n\nFor each element in `a`, return a list of the words in the string, using `sep`\nas the delimiter string.\n\n`rstrip`(a[, chars])\n\nFor each element in `a`, return a copy with the trailing characters removed.\n\n`split`(a[, sep, maxsplit])\n\nFor each element in `a`, return a list of the words in the string, using `sep`\nas the delimiter string.\n\n`splitlines`(a[, keepends])\n\nFor each element in `a`, return a list of the lines in the element, breaking\nat line boundaries.\n\n`strip`(a[, chars])\n\nFor each element in `a`, return a copy with the leading and trailing\ncharacters removed.\n\n`swapcase`(a)\n\nReturn element-wise a copy of the string with uppercase characters converted\nto lowercase and vice versa.\n\n`title`(a)\n\nReturn element-wise title cased version of string or unicode.\n\n`translate`(a, table[, deletechars])\n\nFor each element in `a`, return a copy of the string where all characters\noccurring in the optional argument `deletechars` are removed, and the\nremaining characters have been mapped through the given translation table.\n\n`upper`(a)\n\nReturn an array with the elements converted to uppercase.\n\n`zfill`(a, width)\n\nReturn the numeric string left-filled with zeros\n\nUnlike the standard numpy comparison operators, the ones in the `char` module\nstrip trailing whitespace characters before performing the comparison.\n\n`equal`(x1, x2)\n\nReturn (x1 == x2) element-wise.\n\n`not_equal`(x1, x2)\n\nReturn (x1 != x2) element-wise.\n\n`greater_equal`(x1, x2)\n\nReturn (x1 >= x2) element-wise.\n\n`less_equal`(x1, x2)\n\nReturn (x1 <= x2) element-wise.\n\n`greater`(x1, x2)\n\nReturn (x1 > x2) element-wise.\n\n`less`(x1, x2)\n\nReturn (x1 < x2) element-wise.\n\n`compare_chararrays`(a1, a2, cmp, rstrip)\n\nPerforms element-wise comparison of two string arrays using the comparison\noperator specified by `cmp_op`.\n\n`count`(a, sub[, start, end])\n\nReturns an array with the number of non-overlapping occurrences of substring\n`sub` in the range [`start`, `end`].\n\n`endswith`(a, suffix[, start, end])\n\nReturns a boolean array which is `True` where the string element in `a` ends\nwith `suffix`, otherwise `False`.\n\n`find`(a, sub[, start, end])\n\nFor each element, return the lowest index in the string where substring `sub`\nis found.\n\n`index`(a, sub[, start, end])\n\nLike `find`, but raises `ValueError` when the substring is not found.\n\n`isalpha`(a)\n\nReturns true for each element if all characters in the string are alphabetic\nand there is at least one character, false otherwise.\n\n`isalnum`(a)\n\nReturns true for each element if all characters in the string are alphanumeric\nand there is at least one character, false otherwise.\n\n`isdecimal`(a)\n\nFor each element, return True if there are only decimal characters in the\nelement.\n\n`isdigit`(a)\n\nReturns true for each element if all characters in the string are digits and\nthere is at least one character, false otherwise.\n\n`islower`(a)\n\nReturns true for each element if all cased characters in the string are\nlowercase and there is at least one cased character, false otherwise.\n\n`isnumeric`(a)\n\nFor each element, return True if there are only numeric characters in the\nelement.\n\n`isspace`(a)\n\nReturns true for each element if there are only whitespace characters in the\nstring and there is at least one character, false otherwise.\n\n`istitle`(a)\n\nReturns true for each element if the element is a titlecased string and there\nis at least one character, false otherwise.\n\n`isupper`(a)\n\nReturns true for each element if all cased characters in the string are\nuppercase and there is at least one character, false otherwise.\n\n`rfind`(a, sub[, start, end])\n\nFor each element in `a`, return the highest index in the string where\nsubstring `sub` is found, such that `sub` is contained within [`start`,\n`end`].\n\n`rindex`(a, sub[, start, end])\n\nLike `rfind`, but raises `ValueError` when the substring `sub` is not found.\n\n`startswith`(a, prefix[, start, end])\n\nReturns a boolean array which is `True` where the string element in `a` starts\nwith `prefix`, otherwise `False`.\n\n`str_len`(a)\n\nReturn len(a) element-wise.\n\n`array`(obj[, itemsize, copy, unicode, order])\n\nCreate a `chararray`.\n\n`asarray`(obj[, itemsize, unicode, order])\n\nConvert the input to a `chararray`, copying the data only if necessary.\n\n`chararray`(shape[, itemsize, unicode, ...])\n\nProvides a convenient view on arrays of string and unicode values.\n\n"}, {"name": "Subclassing ndarray", "path": "user/basics.subclassing", "type": "User Guide", "text": "\nSubclassing ndarray is relatively simple, but it has some complications\ncompared to other Python objects. On this page we explain the machinery that\nallows you to subclass ndarray, and the implications for implementing a\nsubclass.\n\nSubclassing ndarray is complicated by the fact that new instances of ndarray\nclasses can come about in three different ways. These are:\n\nThe last two are characteristics of ndarrays - in order to support things like\narray slicing. The complications of subclassing ndarray are due to the\nmechanisms numpy has to support these latter two routes of instance creation.\n\nView casting is the standard ndarray mechanism by which you take an ndarray of\nany subclass, and return a view of the array as another (specified) subclass:\n\nNew instances of an ndarray subclass can also come about by a very similar\nmechanism to View casting, when numpy finds it needs to create a new instance\nfrom a template instance. The most obvious place this has to happen is when\nyou are taking slices of subclassed arrays. For example:\n\nThe slice is a view onto the original `c_arr` data. So, when we take a view\nfrom the ndarray, we return a new ndarray, of the same class, that points to\nthe data in the original.\n\nThere are other points in the use of ndarrays where we need such views, such\nas copying arrays (`c_arr.copy()`), creating ufunc output arrays (see also\n__array_wrap__ for ufuncs and other functions), and reducing methods (like\n`c_arr.mean()`).\n\nThese paths both use the same machinery. We make the distinction here, because\nthey result in different input to your methods. Specifically, View casting\nmeans you have created a new instance of your array type from any potential\nsubclass of ndarray. Creating new from template means you have created a new\ninstance of your class from a pre-existing instance, allowing you - for\nexample - to copy across attributes that are particular to your subclass.\n\nIf we subclass ndarray, we need to deal not only with explicit construction of\nour array type, but also View casting or Creating new from template. NumPy has\nthe machinery to do this, and it is this machinery that makes subclassing\nslightly non-standard.\n\nThere are two aspects to the machinery that ndarray uses to support views and\nnew-from-template in subclasses.\n\nThe first is the use of the `ndarray.__new__` method for the main work of\nobject initialization, rather then the more usual `__init__` method. The\nsecond is the use of the `__array_finalize__` method to allow subclasses to\nclean up after the creation of views and new instances from templates.\n\n`__new__` is a standard Python method, and, if present, is called before\n`__init__` when we create a class instance. See the python __new__\ndocumentation for more detail.\n\nFor example, consider the following Python code:\n\nmeaning that we get:\n\nWhen we call `C('hello')`, the `__new__` method gets its own class as first\nargument, and the passed argument, which is the string `'hello'`. After python\ncalls `__new__`, it usually (see below) calls our `__init__` method, with the\noutput of `__new__` as the first argument (now a class instance), and the\npassed arguments following.\n\nAs you can see, the object can be initialized in the `__new__` method or the\n`__init__` method, or both, and in fact ndarray does not have an `__init__`\nmethod, because all the initialization is done in the `__new__` method.\n\nWhy use `__new__` rather than just the usual `__init__`? Because in some\ncases, as for ndarray, we want to be able to return an object of some other\nclass. Consider the following:\n\nmeaning that:\n\nThe definition of `C` is the same as before, but for `D`, the `__new__` method\nreturns an instance of class `C` rather than `D`. Note that the `__init__`\nmethod of `D` does not get called. In general, when the `__new__` method\nreturns an object of class other than the class in which it is defined, the\n`__init__` method of that class is not called.\n\nThis is how subclasses of the ndarray class are able to return views that\npreserve the class type. When taking a view, the standard ndarray machinery\ncreates the new ndarray object with something like:\n\nwhere `subdtype` is the subclass. Thus the returned view is of the same class\nas the subclass, rather than being of class `ndarray`.\n\nThat solves the problem of returning views of the same type, but now we have a\nnew problem. The machinery of ndarray can set the class this way, in its\nstandard methods for taking views, but the ndarray `__new__` method knows\nnothing of what we have done in our own `__new__` method in order to set\nattributes, and so on. (Aside - why not call `obj = subdtype.__new__(...`\nthen? Because we may not have a `__new__` method with the same call\nsignature).\n\n`__array_finalize__` is the mechanism that numpy provides to allow subclasses\nto handle the various ways that new instances get created.\n\nRemember that subclass instances can come about in these three ways:\n\nOur `MySubClass.__new__` method only gets called in the case of the explicit\nconstructor call, so we can\u2019t rely on `MySubClass.__new__` or\n`MySubClass.__init__` to deal with the view casting and new-from-template. It\nturns out that `MySubClass.__array_finalize__` does get called for all three\nmethods of object creation, so this is where our object creation housekeeping\nusually goes.\n\nThe arguments that `__array_finalize__` receives differ for the three methods\nof instance creation above.\n\nThe following code allows us to look at the call sequences and arguments:\n\nNow:\n\nThe signature of `__array_finalize__` is:\n\nOne sees that the `super` call, which goes to `ndarray.__new__`, passes\n`__array_finalize__` the new object, of our own class (`self`) as well as the\nobject from which the view has been taken (`obj`). As you can see from the\noutput above, the `self` is always a newly created instance of our subclass,\nand the type of `obj` differs for the three instance creation methods:\n\nBecause `__array_finalize__` is the only method that always sees new instances\nbeing created, it is the sensible place to fill in instance defaults for new\nobject attributes, among other tasks.\n\nThis may be clearer with an example.\n\nUsing the object looks like this:\n\nThis class isn\u2019t very useful, because it has the same constructor as the bare\nndarray object, including passing in buffers and shapes and so on. We would\nprobably prefer the constructor to be able to take an already formed ndarray\nfrom the usual numpy calls to `np.array` and return an object.\n\nHere is a class that takes a standard ndarray that already exists, casts as\nour type, and adds an extra attribute.\n\nSo:\n\nNew in version 1.13.\n\nA subclass can override what happens when executing numpy ufuncs on it by\noverriding the default `ndarray.__array_ufunc__` method. This method is\nexecuted instead of the ufunc and should return either the result of the\noperation, or `NotImplemented` if the operation requested is not implemented.\n\nThe signature of `__array_ufunc__` is:\n\nA typical implementation would convert any inputs or outputs that are\ninstances of one\u2019s own class, pass everything on to a superclass using\n`super()`, and finally return the results after possible back-conversion. An\nexample, taken from the test case `test_ufunc_override_with_super` in\n`core/tests/test_umath.py`, is the following.\n\nSo, this class does not actually do anything interesting: it just converts any\ninstances of its own to regular ndarray (otherwise, we\u2019d get infinite\nrecursion!), and adds an `info` dictionary that tells which inputs and outputs\nit converted. Hence, e.g.,\n\nNote that another approach would be to to use `getattr(ufunc,\nmethods)(*inputs, **kwargs)` instead of the `super` call. For this example,\nthe result would be identical, but there is a difference if another operand\nalso defines `__array_ufunc__`. E.g., lets assume that we evalulate `np.add(a,\nb)`, where `b` is an instance of another class `B` that has an override. If\nyou use `super` as in the example, `ndarray.__array_ufunc__` will notice that\n`b` has an override, which means it cannot evaluate the result itself. Thus,\nit will return `NotImplemented` and so will our class `A`. Then, control will\nbe passed over to `b`, which either knows how to deal with us and produces a\nresult, or does not and returns `NotImplemented`, raising a `TypeError`.\n\nIf instead, we replace our `super` call with `getattr(ufunc, method)`, we\neffectively do `np.add(a.view(np.ndarray), b)`. Again, `B.__array_ufunc__`\nwill be called, but now it sees an `ndarray` as the other argument. Likely, it\nwill know how to handle this, and return a new instance of the `B` class to\nus. Our example class is not set up to handle this, but it might well be the\nbest approach if, e.g., one were to re-implement `MaskedArray` using\n`__array_ufunc__`.\n\nAs a final note: if the `super` route is suited to a given class, an advantage\nof using it is that it helps in constructing class hierarchies. E.g., suppose\nthat our other class `B` also used the `super` in its `__array_ufunc__`\nimplementation, and we created a class `C` that depended on both, i.e., `class\nC(A, B)` (with, for simplicity, not another `__array_ufunc__` override). Then\nany ufunc on an instance of `C` would pass on to `A.__array_ufunc__`, the\n`super` call in `A` would go to `B.__array_ufunc__`, and the `super` call in\n`B` would go to `ndarray.__array_ufunc__`, thus allowing `A` and `B` to\ncollaborate.\n\nPrior to numpy 1.13, the behaviour of ufuncs could only be tuned using\n`__array_wrap__` and `__array_prepare__`. These two allowed one to change the\noutput type of a ufunc, but, in contrast to `__array_ufunc__`, did not allow\none to make any changes to the inputs. It is hoped to eventually deprecate\nthese, but `__array_wrap__` is also used by other numpy functions and methods,\nsuch as `squeeze`, so at the present time is still needed for full\nfunctionality.\n\nConceptually, `__array_wrap__` \u201cwraps up the action\u201d in the sense of allowing\na subclass to set the type of the return value and update attributes and\nmetadata. Let\u2019s show how this works with an example. First we return to the\nsimpler example subclass, but with a different name and some print statements:\n\nWe run a ufunc on an instance of our new array:\n\nNote that the ufunc (`np.add`) has called the `__array_wrap__` method with\narguments `self` as `obj`, and `out_arr` as the (ndarray) result of the\naddition. In turn, the default `__array_wrap__` (`ndarray.__array_wrap__`) has\ncast the result to class `MySubClass`, and called `__array_finalize__` \\-\nhence the copying of the `info` attribute. This has all happened at the C\nlevel.\n\nBut, we could do anything we wanted:\n\nSo, by defining a specific `__array_wrap__` method for our subclass, we can\ntweak the output from ufuncs. The `__array_wrap__` method requires `self`,\nthen an argument - which is the result of the ufunc - and an optional\nparameter context. This parameter is returned by ufuncs as a 3-element tuple:\n(name of the ufunc, arguments of the ufunc, domain of the ufunc), but is not\nset by other numpy functions. Though, as seen above, it is possible to do\notherwise, `__array_wrap__` should return an instance of its containing class.\nSee the masked array subclass for an implementation.\n\nIn addition to `__array_wrap__`, which is called on the way out of the ufunc,\nthere is also an `__array_prepare__` method which is called on the way into\nthe ufunc, after the output arrays are created but before any computation has\nbeen performed. The default implementation does nothing but pass through the\narray. `__array_prepare__` should not attempt to access the array data or\nresize the array, it is intended for setting the output array type, updating\nattributes and metadata, and performing any checks based on the input that may\nbe desired before computation begins. Like `__array_wrap__`,\n`__array_prepare__` must return an ndarray or subclass thereof or raise an\nerror.\n\nOne of the problems that ndarray solves is keeping track of memory ownership\nof ndarrays and their views. Consider the case where we have created an\nndarray, `arr` and have taken a slice with `v = arr[1:]`. The two objects are\nlooking at the same memory. NumPy keeps track of where the data came from for\na particular array or view, with the `base` attribute:\n\nIn general, if the array owns its own memory, as for `arr` in this case, then\n`arr.base` will be None - there are some exceptions to this - see the numpy\nbook for more details.\n\nThe `base` attribute is useful in being able to tell whether we have a view or\nthe original array. This in turn can be useful if we need to know whether or\nnot to do some specific cleanup when the subclassed array is deleted. For\nexample, we may only want to do the cleanup if the original array is deleted,\nbut not the views. For an example of how this can work, have a look at the\n`memmap` class in `numpy.core`.\n\nWhen sub-classing `ndarray` or creating duck-types that mimic the `ndarray`\ninterface, it is your responsibility to decide how aligned your APIs will be\nwith those of numpy. For convenience, many numpy functions that have a\ncorresponding `ndarray` method (e.g., `sum`, `mean`, `take`, `reshape`) work\nby checking if the first argument to a function has a method of the same name.\nIf it exists, the method is called instead of coercing the arguments to a\nnumpy array.\n\nFor example, if you want your sub-class or duck-type to be compatible with\nnumpy\u2019s `sum` function, the method signature for this object\u2019s `sum` method\nshould be the following:\n\nThis is the exact same method signature for `np.sum`, so now if a user calls\n`np.sum` on this object, numpy will call the object\u2019s own `sum` method and\npass in these arguments enumerated above in the signature, and no errors will\nbe raised because the signatures are completely compatible with each other.\n\nIf, however, you decide to deviate from this signature and do something like\nthis:\n\nThis object is no longer compatible with `np.sum` because if you call\n`np.sum`, it will pass in unexpected arguments `out` and `keepdims`, causing a\nTypeError to be raised.\n\nIf you wish to maintain compatibility with numpy and its subsequent versions\n(which might add new keyword arguments) but do not want to surface all of\nnumpy\u2019s arguments, your function\u2019s signature should accept `**kwargs`. For\nexample:\n\nThis object is now compatible with `np.sum` again because any extraneous\narguments (i.e. keywords that are not `axis` or `dtype`) will be hidden away\nin the `**unused_kwargs` parameter.\n\n"}, {"name": "template<typename Tp, std::size_t N>class DoxyLimbo", "path": "dev/howto-docs#_CPPv4I0_NSt6size_tEE9DoxyLimbo", "type": "Development", "text": "\nTemplate to represent limbo numbers.\n\nSpecializations for integer types that are part of nowhere. It doesn\u2019t support\nwith any real types.\n\nType of the integer. Required to be an integer type.\n\nNumber of elements.\n\nDefault constructor. Initialize nothing.\n\nSet Default behavior for copy the limbo.\n\nReturns the raw data for the limbo.\n\nExample for inline comment.\n\n"}, {"name": "Test Support (numpy.testing)", "path": "reference/routines.testing", "type": "Test Support ( \n      \n       numpy.testing\n      \n      )", "text": "\nCommon test support for all numpy test scripts.\n\nThis single module should provide all the common functionality for numpy tests\nin a single location, so that test scripts can just import it and work right\naway. For background, see the Testing Guidelines\n\n`assert_allclose`(actual, desired[, rtol, ...])\n\nRaises an AssertionError if two objects are not equal up to desired tolerance.\n\n`assert_array_almost_equal_nulp`(x, y[, nulp])\n\nCompare two arrays relatively to their spacing.\n\n`assert_array_max_ulp`(a, b[, maxulp, dtype])\n\nCheck that all items of arrays differ in at most N Units in the Last Place.\n\n`assert_array_equal`(x, y[, err_msg, verbose])\n\nRaises an AssertionError if two array_like objects are not equal.\n\n`assert_array_less`(x, y[, err_msg, verbose])\n\nRaises an AssertionError if two array_like objects are not ordered by less\nthan.\n\n`assert_equal`(actual, desired[, err_msg, verbose])\n\nRaises an AssertionError if two objects are not equal.\n\n`assert_raises`(assert_raises)\n\nFail unless an exception of class exception_class is thrown by callable when\ninvoked with arguments args and keyword arguments kwargs.\n\n`assert_raises_regex`(exception_class, ...)\n\nFail unless an exception of class exception_class and with message that\nmatches expected_regexp is thrown by callable when invoked with arguments args\nand keyword arguments kwargs.\n\n`assert_warns`(warning_class, *args, **kwargs)\n\nFail unless the given callable throws the specified warning.\n\n`assert_string_equal`(actual, desired)\n\nTest if two strings are equal.\n\nIt is recommended to use one of `assert_allclose`,\n`assert_array_almost_equal_nulp` or `assert_array_max_ulp` instead of these\nfunctions for more consistent floating point comparisons.\n\n`assert_almost_equal`(actual, desired[, ...])\n\nRaises an AssertionError if two items are not equal up to desired precision.\n\n`assert_approx_equal`(actual, desired[, ...])\n\nRaises an AssertionError if two items are not equal up to significant digits.\n\n`assert_array_almost_equal`(x, y[, decimal, ...])\n\nRaises an AssertionError if two objects are not equal up to desired precision.\n\n`dec.deprecated`([conditional])\n\nDeprecated since version 1.21.\n\n`dec.knownfailureif`(fail_condition[, msg])\n\nDeprecated since version 1.21.\n\n`dec.setastest`([tf])\n\nDeprecated since version 1.21.\n\n`dec.skipif`(skip_condition[, msg])\n\nDeprecated since version 1.21.\n\n`dec.slow`(t)\n\nDeprecated since version 1.21.\n\n`decorate_methods`(cls, decorator[, testmatch])\n\nApply a decorator to all methods in a class matching a regular expression.\n\n`Tester`\n\nalias of `numpy.testing._private.nosetester.NoseTester`\n\n`run_module_suite`([file_to_run, argv])\n\nRun a test module.\n\n`rundocs`([filename, raise_on_error])\n\nRun doctests found in the given file.\n\n`suppress_warnings`([forwarding_rule])\n\nContext manager and decorator doing much the same as\n`warnings.catch_warnings`.\n\n"}, {"name": "testing.assert_allclose()", "path": "reference/generated/numpy.testing.assert_allclose", "type": "numpy.testing.assert_allclose", "text": "\nRaises an AssertionError if two objects are not equal up to desired tolerance.\n\nThe test is equivalent to `allclose(actual, desired, rtol, atol)` (note that\n`allclose` has different default values). It compares the difference between\n`actual` and `desired` to `atol + rtol * abs(desired)`.\n\nNew in version 1.5.0.\n\nArray obtained.\n\nArray desired.\n\nRelative tolerance.\n\nAbsolute tolerance.\n\nIf True, NaNs will compare equal.\n\nThe error message to be printed in case of failure.\n\nIf True, the conflicting values are appended to the error message.\n\nIf actual and desired are not equal up to specified precision.\n\nSee also\n\n"}, {"name": "testing.assert_almost_equal()", "path": "reference/generated/numpy.testing.assert_almost_equal", "type": "numpy.testing.assert_almost_equal", "text": "\nRaises an AssertionError if two items are not equal up to desired precision.\n\nNote\n\nIt is recommended to use one of `assert_allclose`,\n`assert_array_almost_equal_nulp` or `assert_array_max_ulp` instead of this\nfunction for more consistent floating point comparisons.\n\nThe test verifies that the elements of `actual` and `desired` satisfy.\n\n`abs(desired-actual) < 1.5 * 10**(-decimal)`\n\nThat is a looser test than originally documented, but agrees with what the\nactual implementation in `assert_array_almost_equal` did up to rounding\nvagaries. An exception is raised at conflicting values. For ndarrays this\ndelegates to assert_array_almost_equal\n\nThe object to check.\n\nThe expected object.\n\nDesired precision, default is 7.\n\nThe error message to be printed in case of failure.\n\nIf True, the conflicting values are appended to the error message.\n\nIf actual and desired are not equal up to specified precision.\n\nSee also\n\nCompare two array_like objects for equality with desired relative and/or\nabsolute precision.\n\n"}, {"name": "testing.assert_approx_equal()", "path": "reference/generated/numpy.testing.assert_approx_equal", "type": "numpy.testing.assert_approx_equal", "text": "\nRaises an AssertionError if two items are not equal up to significant digits.\n\nNote\n\nIt is recommended to use one of `assert_allclose`,\n`assert_array_almost_equal_nulp` or `assert_array_max_ulp` instead of this\nfunction for more consistent floating point comparisons.\n\nGiven two numbers, check that they are approximately equal. Approximately\nequal is defined as the number of significant digits that agree.\n\nThe object to check.\n\nThe expected object.\n\nDesired precision, default is 7.\n\nThe error message to be printed in case of failure.\n\nIf True, the conflicting values are appended to the error message.\n\nIf actual and desired are not equal up to specified precision.\n\nSee also\n\nCompare two array_like objects for equality with desired relative and/or\nabsolute precision.\n\nthe evaluated condition that raises the exception is\n\n"}, {"name": "testing.assert_array_almost_equal()", "path": "reference/generated/numpy.testing.assert_array_almost_equal", "type": "numpy.testing.assert_array_almost_equal", "text": "\nRaises an AssertionError if two objects are not equal up to desired precision.\n\nNote\n\nIt is recommended to use one of `assert_allclose`,\n`assert_array_almost_equal_nulp` or `assert_array_max_ulp` instead of this\nfunction for more consistent floating point comparisons.\n\nThe test verifies identical shapes and that the elements of `actual` and\n`desired` satisfy.\n\n`abs(desired-actual) < 1.5 * 10**(-decimal)`\n\nThat is a looser test than originally documented, but agrees with what the\nactual implementation did up to rounding vagaries. An exception is raised at\nshape mismatch or conflicting values. In contrast to the standard usage in\nnumpy, NaNs are compared like numbers, no assertion is raised if both objects\nhave NaNs in the same positions.\n\nThe actual object to check.\n\nThe desired, expected object.\n\nDesired precision, default is 6.\n\nThe error message to be printed in case of failure.\n\nIf True, the conflicting values are appended to the error message.\n\nIf actual and desired are not equal up to specified precision.\n\nSee also\n\nCompare two array_like objects for equality with desired relative and/or\nabsolute precision.\n\nthe first assert does not raise an exception\n\n"}, {"name": "testing.assert_array_almost_equal_nulp()", "path": "reference/generated/numpy.testing.assert_array_almost_equal_nulp", "type": "numpy.testing.assert_array_almost_equal_nulp", "text": "\nCompare two arrays relatively to their spacing.\n\nThis is a relatively robust method to compare two arrays whose amplitude is\nvariable.\n\nInput arrays.\n\nThe maximum number of unit in the last place for tolerance (see Notes).\nDefault is 1.\n\nIf the spacing between `x` and `y` for one or more elements is larger than\n`nulp`.\n\nSee also\n\nCheck that all items of arrays differ in at most N Units in the Last Place.\n\nReturn the distance between x and the nearest adjacent number.\n\nAn assertion is raised if the following condition is not met:\n\n"}, {"name": "testing.assert_array_equal()", "path": "reference/generated/numpy.testing.assert_array_equal", "type": "numpy.testing.assert_array_equal", "text": "\nRaises an AssertionError if two array_like objects are not equal.\n\nGiven two array_like objects, check that the shape is equal and all elements\nof these objects are equal (but see the Notes for the special handling of a\nscalar). An exception is raised at shape mismatch or conflicting values. In\ncontrast to the standard usage in numpy, NaNs are compared like numbers, no\nassertion is raised if both objects have NaNs in the same positions.\n\nThe usual caution for verifying equality with floating point numbers is\nadvised.\n\nThe actual object to check.\n\nThe desired, expected object.\n\nThe error message to be printed in case of failure.\n\nIf True, the conflicting values are appended to the error message.\n\nIf actual and desired objects are not equal.\n\nSee also\n\nCompare two array_like objects for equality with desired relative and/or\nabsolute precision.\n\nWhen one of `x` and `y` is a scalar and the other is array_like, the function\nchecks that each element of the array_like object is equal to the scalar.\n\nThe first assert does not raise an exception:\n\nAssert fails with numerical imprecision with floats:\n\nUse `assert_allclose` or one of the nulp (number of floating point values)\nfunctions for these cases instead:\n\nAs mentioned in the Notes section, `assert_array_equal` has special handling\nfor scalars. Here the test checks that each value in `x` is 3:\n\n"}, {"name": "testing.assert_array_less()", "path": "reference/generated/numpy.testing.assert_array_less", "type": "numpy.testing.assert_array_less", "text": "\nRaises an AssertionError if two array_like objects are not ordered by less\nthan.\n\nGiven two array_like objects, check that the shape is equal and all elements\nof the first object are strictly smaller than those of the second object. An\nexception is raised at shape mismatch or incorrectly ordered values. Shape\nmismatch does not raise if an object has zero dimension. In contrast to the\nstandard usage in numpy, NaNs are compared, no assertion is raised if both\nobjects have NaNs in the same positions.\n\nThe smaller object to check.\n\nThe larger object to compare.\n\nThe error message to be printed in case of failure.\n\nIf True, the conflicting values are appended to the error message.\n\nIf actual and desired objects are not equal.\n\nSee also\n\ntests objects for equality\n\ntest objects for equality up to precision\n\n"}, {"name": "testing.assert_array_max_ulp()", "path": "reference/generated/numpy.testing.assert_array_max_ulp", "type": "numpy.testing.assert_array_max_ulp", "text": "\nCheck that all items of arrays differ in at most N Units in the Last Place.\n\nInput arrays to be compared.\n\nThe maximum number of units in the last place that elements of `a` and `b` can\ndiffer. Default is 1.\n\nData-type to convert `a` and `b` to if given. Default is None.\n\nArray containing number of representable floating point numbers between items\nin `a` and `b`.\n\nIf one or more elements differ by more than `maxulp`.\n\nSee also\n\nCompare two arrays relatively to their spacing.\n\nFor computing the ULP difference, this API does not differentiate between\nvarious representations of NAN (ULP difference between 0x7fc00000 and\n0xffc00000 is zero).\n\n"}, {"name": "testing.assert_equal()", "path": "reference/generated/numpy.testing.assert_equal", "type": "numpy.testing.assert_equal", "text": "\nRaises an AssertionError if two objects are not equal.\n\nGiven two objects (scalars, lists, tuples, dictionaries or numpy arrays),\ncheck that all elements of these objects are equal. An exception is raised at\nthe first conflicting values.\n\nWhen one of `actual` and `desired` is a scalar and the other is array_like,\nthe function checks that each element of the array_like object is equal to the\nscalar.\n\nThis function handles NaN comparisons as if NaN was a \u201cnormal\u201d number. That\nis, AssertionError is not raised if both objects have NaNs in the same\npositions. This is in contrast to the IEEE standard on NaNs, which says that\nNaN compared to anything must return False.\n\nThe object to check.\n\nThe expected object.\n\nThe error message to be printed in case of failure.\n\nIf True, the conflicting values are appended to the error message.\n\nIf actual and desired are not equal.\n\nThe following comparison does not raise an exception. There are NaNs in the\ninputs, but they are in the same positions.\n\n"}, {"name": "testing.assert_raises()", "path": "reference/generated/numpy.testing.assert_raises", "type": "numpy.testing.assert_raises", "text": "\nFail unless an exception of class exception_class is thrown by callable when\ninvoked with arguments args and keyword arguments kwargs. If a different type\nof exception is thrown, it will not be caught, and the test case will be\ndeemed to have suffered an error, exactly as for an unexpected exception.\n\nAlternatively, `assert_raises` can be used as a context manager:\n\nis equivalent to\n\n"}, {"name": "testing.assert_raises_regex()", "path": "reference/generated/numpy.testing.assert_raises_regex", "type": "numpy.testing.assert_raises_regex", "text": "\nFail unless an exception of class exception_class and with message that\nmatches expected_regexp is thrown by callable when invoked with arguments args\nand keyword arguments kwargs.\n\nAlternatively, can be used as a context manager like `assert_raises`.\n\nName of this function adheres to Python 3.2+ reference, but should work in all\nversions down to 2.6.\n\nNew in version 1.9.0.\n\n"}, {"name": "testing.assert_string_equal()", "path": "reference/generated/numpy.testing.assert_string_equal", "type": "numpy.testing.assert_string_equal", "text": "\nTest if two strings are equal.\n\nIf the given strings are equal, `assert_string_equal` does nothing. If they\nare not equal, an AssertionError is raised, and the diff between the strings\nis shown.\n\nThe string to test for equality against the expected string.\n\nThe expected string.\n\n"}, {"name": "testing.assert_warns()", "path": "reference/generated/numpy.testing.assert_warns", "type": "numpy.testing.assert_warns", "text": "\nFail unless the given callable throws the specified warning.\n\nA warning of class warning_class should be thrown by the callable when invoked\nwith arguments args and keyword arguments kwargs. If a different type of\nwarning is thrown, it will not be caught.\n\nIf called with all arguments other than the warning class omitted, may be used\nas a context manager:\n\ndo_something()\n\nThe ability to be used as a context manager is new in NumPy v1.11.0.\n\nNew in version 1.4.0.\n\nThe class defining the warning that `func` is expected to throw.\n\nCallable to test\n\nArguments for `func`.\n\nKeyword arguments for `func`.\n\n"}, {"name": "testing.dec.deprecated()", "path": "reference/generated/numpy.testing.dec.deprecated", "type": "numpy.testing.dec.deprecated", "text": "\nDeprecated since version 1.21: This decorator is retained for compatibility\nwith the nose testing framework, which is being phased out. Please use the\nnose2 or pytest frameworks instead.\n\nFilter deprecation warnings while running the test suite.\n\nThis decorator can be used to filter DeprecationWarning\u2019s, to avoid printing\nthem during the test suite run, while checking that the test actually raises a\nDeprecationWarning.\n\nFlag to determine whether to mark test as deprecated or not. If the condition\nis a callable, it is used at runtime to dynamically make the decision. Default\nis True.\n\nThe `deprecated` decorator itself.\n\nNew in version 1.4.0.\n\n"}, {"name": "testing.dec.knownfailureif()", "path": "reference/generated/numpy.testing.dec.knownfailureif", "type": "numpy.testing.dec.knownfailureif", "text": "\nDeprecated since version 1.21: This decorator is retained for compatibility\nwith the nose testing framework, which is being phased out. Please use the\nnose2 or pytest frameworks instead.\n\nMake function raise KnownFailureException exception if given condition is\ntrue.\n\nIf the condition is a callable, it is used at runtime to dynamically make the\ndecision. This is useful for tests that may require costly imports, to delay\nthe cost until the test suite is actually executed.\n\nFlag to determine whether to mark the decorated test as a known failure (if\nTrue) or not (if False).\n\nMessage to give on raising a KnownFailureException exception. Default is None.\n\nDecorator, which, when applied to a function, causes KnownFailureException to\nbe raised when `fail_condition` is True, and the function to be called\nnormally otherwise.\n\nThe decorator itself is decorated with the `nose.tools.make_decorator`\nfunction in order to transmit function name, and various other metadata.\n\n"}, {"name": "testing.dec.setastest()", "path": "reference/generated/numpy.testing.dec.setastest", "type": "numpy.testing.dec.setastest", "text": "\nDeprecated since version 1.21: This decorator is retained for compatibility\nwith the nose testing framework, which is being phased out. Please use the\nnose2 or pytest frameworks instead.\n\nSignals to nose that this function is or is not a test.\n\nIf True, specifies that the decorated callable is a test. If False, specifies\nthat the decorated callable is not a test. Default is True.\n\nThis decorator can\u2019t use the nose namespace, because it can be called from a\nnon-test module. See also `istest` and `nottest` in `nose.tools`.\n\n`setastest` can be used in the following way:\n\n"}, {"name": "testing.dec.skipif()", "path": "reference/generated/numpy.testing.dec.skipif", "type": "numpy.testing.dec.skipif", "text": "\nDeprecated since version 1.21: This decorator is retained for compatibility\nwith the nose testing framework, which is being phased out. Please use the\nnose2 or pytest frameworks instead.\n\nMake function raise SkipTest exception if a given condition is true.\n\nIf the condition is a callable, it is used at runtime to dynamically make the\ndecision. This is useful for tests that may require costly imports, to delay\nthe cost until the test suite is actually executed.\n\nFlag to determine whether to skip the decorated test.\n\nMessage to give on raising a SkipTest exception. Default is None.\n\nDecorator which, when applied to a function, causes SkipTest to be raised when\n`skip_condition` is True, and the function to be called normally otherwise.\n\nThe decorator itself is decorated with the `nose.tools.make_decorator`\nfunction in order to transmit function name, and various other metadata.\n\n"}, {"name": "testing.dec.slow()", "path": "reference/generated/numpy.testing.dec.slow", "type": "numpy.testing.dec.slow", "text": "\nDeprecated since version 1.21: This decorator is retained for compatibility\nwith the nose testing framework, which is being phased out. Please use the\nnose2 or pytest frameworks instead.\n\nLabel a test as \u2018slow\u2019.\n\nThe exact definition of a slow test is obviously both subjective and hardware-\ndependent, but in general any individual test that requires more than a second\nor two should be labeled as slow (the whole suite consists of thousands of\ntests, so even a second is significant).\n\nThe test to label as slow.\n\nThe decorated test `t`.\n\nThe `numpy.testing` module includes `import decorators as dec`. A test can be\ndecorated as slow like this:\n\n"}, {"name": "testing.decorate_methods()", "path": "reference/generated/numpy.testing.decorate_methods", "type": "numpy.testing.decorate_methods", "text": "\nApply a decorator to all methods in a class matching a regular expression.\n\nThe given decorator is applied to all public methods of `cls` that are matched\nby the regular expression `testmatch` (`testmatch.search(methodname)`).\nMethods that are private, i.e. start with an underscore, are ignored.\n\nClass whose methods to decorate.\n\nDecorator to apply to methods\n\nThe regular expression. Default value is None, in which case the nose default\n(`re.compile(r'(?:^|[\\b_\\.%s-])[Tt]est' % os.sep)`) is used. If `testmatch` is\na string, it is compiled to a regular expression first.\n\n"}, {"name": "testing.run_module_suite()", "path": "reference/generated/numpy.testing.run_module_suite", "type": "numpy.testing.run_module_suite", "text": "\nRun a test module.\n\nEquivalent to calling `$ nosetests <argv> <file_to_run>` from the command line\n\nPath to test module, or None. By default, run the module from which this\nfunction is called.\n\nArguments to be passed to the nose test runner. `argv[0]` is ignored. All\ncommand line arguments accepted by `nosetests` will work. If it is the default\nvalue None, sys.argv is used.\n\nNew in version 1.9.0.\n\nAdding the following:\n\nat the end of a test module will run the tests when that module is called in\nthe python interpreter.\n\nAlternatively, calling:\n\nfrom an interpreter will run all the test routine in \u2018test_matlib.py\u2019.\n\n"}, {"name": "testing.rundocs()", "path": "reference/generated/numpy.testing.rundocs", "type": "numpy.testing.rundocs", "text": "\nRun doctests found in the given file.\n\nBy default `rundocs` raises an AssertionError on failure.\n\nThe path to the file for which the doctests are run.\n\nWhether to raise an AssertionError when a doctest fails. Default is True.\n\nThe doctests can be run by the user/developer by adding the `doctests`\nargument to the `test()` call. For example, to run all tests (including\ndoctests) for `numpy.lib`:\n\n"}, {"name": "testing.suppress_warnings.__call__()", "path": "reference/generated/numpy.testing.suppress_warnings.__call__", "type": "numpy.testing.suppress_warnings.__call__", "text": "\nmethod\n\nFunction decorator to apply certain suppressions to a whole function.\n\n"}, {"name": "testing.suppress_warnings.filter()", "path": "reference/generated/numpy.testing.suppress_warnings.filter", "type": "numpy.testing.suppress_warnings.filter", "text": "\nmethod\n\nAdd a new suppressing filter or apply it if the state is entered.\n\nWarning class to filter\n\nRegular expression matching the warning message.\n\nModule to filter for. Note that the module (and its file) must match exactly\nand cannot be a submodule. This may make it unreliable for external modules.\n\nWhen added within a context, filters are only added inside the context and\nwill be forgotten when the context is exited.\n\n"}, {"name": "testing.suppress_warnings.record()", "path": "reference/generated/numpy.testing.suppress_warnings.record", "type": "numpy.testing.suppress_warnings.record", "text": "\nmethod\n\nAppend a new recording filter or apply it if the state is entered.\n\nAll warnings matching will be appended to the `log` attribute.\n\nWarning class to filter\n\nRegular expression matching the warning message.\n\nModule to filter for. Note that the module (and its file) must match exactly\nand cannot be a submodule. This may make it unreliable for external modules.\n\nA list which will be filled with all matched warnings.\n\nWhen added within a context, filters are only added inside the context and\nwill be forgotten when the context is exited.\n\n"}, {"name": "The N-dimensional array (ndarray)", "path": "reference/arrays.ndarray", "type": "The N-dimensional array ( \n      \n       ndarray\n      \n      )", "text": "\nAn `ndarray` is a (usually fixed-size) multidimensional container of items of\nthe same type and size. The number of dimensions and items in an array is\ndefined by its `shape`, which is a `tuple` of N non-negative integers that\nspecify the sizes of each dimension. The type of items in the array is\nspecified by a separate data-type object (dtype), one of which is associated\nwith each ndarray.\n\nAs with other container objects in Python, the contents of an `ndarray` can be\naccessed and modified by indexing or slicing the array (using, for example, N\nintegers), and via the methods and attributes of the `ndarray`.\n\nDifferent `ndarrays` can share the same data, so that changes made in one\n`ndarray` may be visible in another. That is, an ndarray can be a \u201cview\u201d to\nanother ndarray, and the data it is referring to is taken care of by the\n\u201cbase\u201d ndarray. ndarrays can also be views to memory owned by Python `strings`\nor objects implementing the `buffer` or array interfaces.\n\nA 2-dimensional array of size 2 x 3, composed of 4-byte integer elements:\n\nThe array can be indexed using Python container-like syntax:\n\nFor example slicing can produce views of the array:\n\nNew arrays can be constructed using the routines detailed in Array creation\nroutines, and also by using the low-level `ndarray` constructor:\n\n`ndarray`(shape[, dtype, buffer, offset, ...])\n\nAn array object represents a multidimensional, homogeneous array of fixed-size\nitems.\n\nArrays can be indexed using an extended Python slicing syntax,\n`array[selection]`. Similar syntax is also used for accessing fields in a\nstructured data type.\n\nSee also\n\nArray Indexing.\n\nAn instance of class `ndarray` consists of a contiguous one-dimensional\nsegment of computer memory (owned by the array, or by some other object),\ncombined with an indexing scheme that maps N integers into the location of an\nitem in the block. The ranges in which the indices can vary is specified by\nthe `shape` of the array. How many bytes each item takes and how the bytes are\ninterpreted is defined by the data-type object associated with the array.\n\nA segment of memory is inherently 1-dimensional, and there are many different\nschemes for arranging the items of an N-dimensional array in a 1-dimensional\nblock. NumPy is flexible, and `ndarray` objects can accommodate any strided\nindexing scheme. In a strided scheme, the N-dimensional index \\\\((n_0, n_1,\n..., n_{N-1})\\\\) corresponds to the offset (in bytes):\n\nfrom the beginning of the memory block associated with the array. Here,\n\\\\(s_k\\\\) are integers which specify the `strides` of the array. The column-\nmajor order (used, for example, in the Fortran language and in Matlab) and\nrow-major order (used in C) schemes are just specific kinds of strided scheme,\nand correspond to memory that can be addressed by the strides:\n\nwhere \\\\(d_j\\\\) `= self.shape[j]`.\n\nBoth the C and Fortran orders are contiguous, i.e., single-segment, memory\nlayouts, in which every part of the memory block can be accessed by some\ncombination of the indices.\n\nNote\n\n`Contiguous arrays` and `single-segment arrays` are synonymous and are used\ninterchangeably throughout the documentation.\n\nWhile a C-style and Fortran-style contiguous array, which has the\ncorresponding flags set, can be addressed with the above strides, the actual\nstrides may be different. This can happen in two cases:\n\nPoint 1. means that `self` and `self.squeeze()` always have the same\ncontiguity and `aligned` flags value. This also means that even a high\ndimensional array could be C-style and Fortran-style contiguous at the same\ntime.\n\nAn array is considered aligned if the memory offsets for all elements and the\nbase offset itself is a multiple of `self.itemsize`. Understanding `memory-\nalignment` leads to better performance on most hardware.\n\nNote\n\nPoints (1) and (2) can currently be disabled by the compile time environmental\nvariable `NPY_RELAXED_STRIDES_CHECKING=0`, which was the default before NumPy\n1.10. No users should have to do this. `NPY_RELAXED_STRIDES_DEBUG=1` can be\nused to help find errors when incorrectly relying on the strides in\nC-extension code (see below warning).\n\nYou can check whether this option was enabled when your NumPy was built by\nlooking at the value of `np.ones((10,1), order='C').flags.f_contiguous`. If\nthis is `True`, then your NumPy has relaxed strides checking enabled.\n\nWarning\n\nIt does not generally hold that `self.strides[-1] == self.itemsize` for\nC-style contiguous arrays or `self.strides[0] == self.itemsize` for Fortran-\nstyle contiguous arrays is true.\n\nData in new `ndarrays` is in the row-major (C) order, unless otherwise\nspecified, but, for example, basic array slicing often produces views in a\ndifferent scheme.\n\nNote\n\nSeveral algorithms in NumPy work on arbitrarily strided arrays. However, some\nalgorithms require single-segment arrays. When an irregularly strided array is\npassed in to such algorithms, a copy is automatically made.\n\nArray attributes reflect information that is intrinsic to the array itself.\nGenerally, accessing an array through its attributes allows you to get and\nsometimes set intrinsic properties of the array without creating a new array.\nThe exposed attributes are the core parts of an array and only some of them\ncan be reset meaningfully without creating a new array. Information on each\nattribute is given below.\n\nThe following attributes contain information about the memory layout of the\narray:\n\n`ndarray.flags`\n\nInformation about the memory layout of the array.\n\n`ndarray.shape`\n\nTuple of array dimensions.\n\n`ndarray.strides`\n\nTuple of bytes to step in each dimension when traversing an array.\n\n`ndarray.ndim`\n\nNumber of array dimensions.\n\n`ndarray.data`\n\nPython buffer object pointing to the start of the array's data.\n\n`ndarray.size`\n\nNumber of elements in the array.\n\n`ndarray.itemsize`\n\nLength of one array element in bytes.\n\n`ndarray.nbytes`\n\nTotal bytes consumed by the elements of the array.\n\n`ndarray.base`\n\nBase object if memory is from some other object.\n\nSee also\n\nData type objects\n\nThe data type object associated with the array can be found in the `dtype`\nattribute:\n\n`ndarray.dtype`\n\nData-type of the array's elements.\n\n`ndarray.T`\n\nThe transposed array.\n\n`ndarray.real`\n\nThe real part of the array.\n\n`ndarray.imag`\n\nThe imaginary part of the array.\n\n`ndarray.flat`\n\nA 1-D iterator over the array.\n\nSee also\n\nThe Array Interface.\n\n`__array_interface__`\n\nPython-side of the array interface\n\n`__array_struct__`\n\nC-side of the array interface\n\n`ndarray.ctypes`\n\nAn object to simplify the interaction of the array with the ctypes module.\n\nAn `ndarray` object has many methods which operate on or with the array in\nsome fashion, typically returning an array result. These methods are briefly\nexplained below. (Each method\u2019s docstring has a more complete description.)\n\nFor the following methods there are also corresponding functions in `numpy`:\n`all`, `any`, `argmax`, `argmin`, `argpartition`, `argsort`, `choose`, `clip`,\n`compress`, `copy`, `cumprod`, `cumsum`, `diagonal`, `imag`, `max`, `mean`,\n`min`, `nonzero`, `partition`, `prod`, `ptp`, `put`, `ravel`, `real`,\n`repeat`, `reshape`, `round`, `searchsorted`, `sort`, `squeeze`, `std`, `sum`,\n`swapaxes`, `take`, `trace`, `transpose`, `var`.\n\n`ndarray.item`(*args)\n\nCopy an element of an array to a standard Python scalar and return it.\n\n`ndarray.tolist`()\n\nReturn the array as an `a.ndim`-levels deep nested list of Python scalars.\n\n`ndarray.itemset`(*args)\n\nInsert scalar into an array (scalar is cast to array's dtype, if possible)\n\n`ndarray.tostring`([order])\n\nA compatibility alias for `tobytes`, with exactly the same behavior.\n\n`ndarray.tobytes`([order])\n\nConstruct Python bytes containing the raw data bytes in the array.\n\n`ndarray.tofile`(fid[, sep, format])\n\nWrite array to a file as text or binary (default).\n\n`ndarray.dump`(file)\n\nDump a pickle of the array to the specified file.\n\n`ndarray.dumps`()\n\nReturns the pickle of the array as a string.\n\n`ndarray.astype`(dtype[, order, casting, ...])\n\nCopy of the array, cast to a specified type.\n\n`ndarray.byteswap`([inplace])\n\nSwap the bytes of the array elements\n\n`ndarray.copy`([order])\n\nReturn a copy of the array.\n\n`ndarray.view`([dtype][, type])\n\nNew view of array with the same data.\n\n`ndarray.getfield`(dtype[, offset])\n\nReturns a field of the given array as a certain type.\n\n`ndarray.setflags`([write, align, uic])\n\nSet array flags WRITEABLE, ALIGNED, (WRITEBACKIFCOPY and UPDATEIFCOPY),\nrespectively.\n\n`ndarray.fill`(value)\n\nFill the array with a scalar value.\n\nFor reshape, resize, and transpose, the single tuple argument may be replaced\nwith `n` integers which will be interpreted as an n-tuple.\n\n`ndarray.reshape`(shape[, order])\n\nReturns an array containing the same data with a new shape.\n\n`ndarray.resize`(new_shape[, refcheck])\n\nChange shape and size of array in-place.\n\n`ndarray.transpose`(*axes)\n\nReturns a view of the array with axes transposed.\n\n`ndarray.swapaxes`(axis1, axis2)\n\nReturn a view of the array with `axis1` and `axis2` interchanged.\n\n`ndarray.flatten`([order])\n\nReturn a copy of the array collapsed into one dimension.\n\n`ndarray.ravel`([order])\n\nReturn a flattened array.\n\n`ndarray.squeeze`([axis])\n\nRemove axes of length one from `a`.\n\nFor array methods that take an axis keyword, it defaults to None. If axis is\nNone, then the array is treated as a 1-D array. Any other value for axis\nrepresents the dimension along which the operation should proceed.\n\n`ndarray.take`(indices[, axis, out, mode])\n\nReturn an array formed from the elements of `a` at the given indices.\n\n`ndarray.put`(indices, values[, mode])\n\nSet `a.flat[n] = values[n]` for all `n` in indices.\n\n`ndarray.repeat`(repeats[, axis])\n\nRepeat elements of an array.\n\n`ndarray.choose`(choices[, out, mode])\n\nUse an index array to construct a new array from a set of choices.\n\n`ndarray.sort`([axis, kind, order])\n\nSort an array in-place.\n\n`ndarray.argsort`([axis, kind, order])\n\nReturns the indices that would sort this array.\n\n`ndarray.partition`(kth[, axis, kind, order])\n\nRearranges the elements in the array in such a way that the value of the\nelement in kth position is in the position it would be in a sorted array.\n\n`ndarray.argpartition`(kth[, axis, kind, order])\n\nReturns the indices that would partition this array.\n\n`ndarray.searchsorted`(v[, side, sorter])\n\nFind indices where elements of v should be inserted in a to maintain order.\n\n`ndarray.nonzero`()\n\nReturn the indices of the elements that are non-zero.\n\n`ndarray.compress`(condition[, axis, out])\n\nReturn selected slices of this array along given axis.\n\n`ndarray.diagonal`([offset, axis1, axis2])\n\nReturn specified diagonals.\n\nMany of these methods take an argument named axis. In such cases,\n\nExample of the axis argument\n\nA 3-dimensional array of size 3 x 3 x 3, summed over each of its three axes\n\nThe parameter dtype specifies the data type over which a reduction operation\n(like summing) should take place. The default reduce data type is the same as\nthe data type of self. To avoid overflow, it can be useful to perform the\nreduction using a larger data type.\n\nFor several methods, an optional out argument can also be provided and the\nresult will be placed into the output array given. The out argument must be an\n`ndarray` and have the same number of elements. It can have a different data\ntype in which case casting will be performed.\n\n`ndarray.max`([axis, out, keepdims, initial, ...])\n\nReturn the maximum along a given axis.\n\n`ndarray.argmax`([axis, out])\n\nReturn indices of the maximum values along the given axis.\n\n`ndarray.min`([axis, out, keepdims, initial, ...])\n\nReturn the minimum along a given axis.\n\n`ndarray.argmin`([axis, out])\n\nReturn indices of the minimum values along the given axis.\n\n`ndarray.ptp`([axis, out, keepdims])\n\nPeak to peak (maximum - minimum) value along a given axis.\n\n`ndarray.clip`([min, max, out])\n\nReturn an array whose values are limited to `[min, max]`.\n\n`ndarray.conj`()\n\nComplex-conjugate all elements.\n\n`ndarray.round`([decimals, out])\n\nReturn `a` with each element rounded to the given number of decimals.\n\n`ndarray.trace`([offset, axis1, axis2, dtype, out])\n\nReturn the sum along diagonals of the array.\n\n`ndarray.sum`([axis, dtype, out, keepdims, ...])\n\nReturn the sum of the array elements over the given axis.\n\n`ndarray.cumsum`([axis, dtype, out])\n\nReturn the cumulative sum of the elements along the given axis.\n\n`ndarray.mean`([axis, dtype, out, keepdims, where])\n\nReturns the average of the array elements along given axis.\n\n`ndarray.var`([axis, dtype, out, ddof, ...])\n\nReturns the variance of the array elements, along given axis.\n\n`ndarray.std`([axis, dtype, out, ddof, ...])\n\nReturns the standard deviation of the array elements along given axis.\n\n`ndarray.prod`([axis, dtype, out, keepdims, ...])\n\nReturn the product of the array elements over the given axis\n\n`ndarray.cumprod`([axis, dtype, out])\n\nReturn the cumulative product of the elements along the given axis.\n\n`ndarray.all`([axis, out, keepdims, where])\n\nReturns True if all elements evaluate to True.\n\n`ndarray.any`([axis, out, keepdims, where])\n\nReturns True if any of the elements of `a` evaluate to True.\n\nArithmetic and comparison operations on `ndarrays` are defined as element-wise\noperations, and generally yield `ndarray` objects as results.\n\nEach of the arithmetic operations (`+`, `-`, `*`, `/`, `//`, `%`, `divmod()`,\n`**` or `pow()`, `<<`, `>>`, `&`, `^`, `|`, `~`) and the comparisons (`==`,\n`<`, `>`, `<=`, `>=`, `!=`) is equivalent to the corresponding universal\nfunction (or ufunc for short) in NumPy. For more information, see the section\non Universal Functions.\n\nComparison operators:\n\n`ndarray.__lt__`(value, /)\n\nReturn self<value.\n\n`ndarray.__le__`(value, /)\n\nReturn self<=value.\n\n`ndarray.__gt__`(value, /)\n\nReturn self>value.\n\n`ndarray.__ge__`(value, /)\n\nReturn self>=value.\n\n`ndarray.__eq__`(value, /)\n\nReturn self==value.\n\n`ndarray.__ne__`(value, /)\n\nReturn self!=value.\n\nTruth value of an array (`bool()`):\n\n`ndarray.__bool__`(/)\n\nself != 0\n\nNote\n\nTruth-value testing of an array invokes `ndarray.__bool__`, which raises an\nerror if the number of elements in the array is larger than 1, because the\ntruth value of such arrays is ambiguous. Use `.any()` and `.all()` instead to\nbe clear about what is meant in such cases. (If the number of elements is 0,\nthe array evaluates to `False`.)\n\nUnary operations:\n\n`ndarray.__neg__`(/)\n\n-self\n`ndarray.__pos__`(/)\n\n+self\n\n`ndarray.__abs__`(self)\n\n`ndarray.__invert__`(/)\n\n~self\n\nArithmetic:\n\n`ndarray.__add__`(value, /)\n\nReturn self+value.\n\n`ndarray.__sub__`(value, /)\n\nReturn self-value.\n\n`ndarray.__mul__`(value, /)\n\nReturn self*value.\n\n`ndarray.__truediv__`(value, /)\n\nReturn self/value.\n\n`ndarray.__floordiv__`(value, /)\n\nReturn self//value.\n\n`ndarray.__mod__`(value, /)\n\nReturn self%value.\n\n`ndarray.__divmod__`(value, /)\n\nReturn divmod(self, value).\n\n`ndarray.__pow__`(value[, mod])\n\nReturn pow(self, value, mod).\n\n`ndarray.__lshift__`(value, /)\n\nReturn self<<value.\n\n`ndarray.__rshift__`(value, /)\n\nReturn self>>value.\n\n`ndarray.__and__`(value, /)\n\nReturn self&value.\n\n`ndarray.__or__`(value, /)\n\nReturn self|value.\n\n`ndarray.__xor__`(value, /)\n\nReturn self^value.\n\nNote\n\nArithmetic, in-place:\n\n`ndarray.__iadd__`(value, /)\n\nReturn self+=value.\n\n`ndarray.__isub__`(value, /)\n\nReturn self-=value.\n\n`ndarray.__imul__`(value, /)\n\nReturn self*=value.\n\n`ndarray.__itruediv__`(value, /)\n\nReturn self/=value.\n\n`ndarray.__ifloordiv__`(value, /)\n\nReturn self//=value.\n\n`ndarray.__imod__`(value, /)\n\nReturn self%=value.\n\n`ndarray.__ipow__`(value, /)\n\nReturn self**=value.\n\n`ndarray.__ilshift__`(value, /)\n\nReturn self<<=value.\n\n`ndarray.__irshift__`(value, /)\n\nReturn self>>=value.\n\n`ndarray.__iand__`(value, /)\n\nReturn self&=value.\n\n`ndarray.__ior__`(value, /)\n\nReturn self|=value.\n\n`ndarray.__ixor__`(value, /)\n\nReturn self^=value.\n\nWarning\n\nIn place operations will perform the calculation using the precision decided\nby the data type of the two operands, but will silently downcast the result\n(if necessary) so it can fit back into the array. Therefore, for mixed\nprecision calculations, `A {op}= B` can be different than `A = A {op} B`. For\nexample, suppose `a = ones((3,3))`. Then, `a += 3j` is different than `a = a +\n3j`: while they both perform the same computation, `a += 3` casts the result\nto fit back in `a`, whereas `a = a + 3j` re-binds the name `a` to the result.\n\nMatrix Multiplication:\n\n`ndarray.__matmul__`(value, /)\n\nReturn self@value.\n\nNote\n\nMatrix operators `@` and `@=` were introduced in Python 3.5 following PEP 465,\nand the `@` operator has been introduced in NumPy 1.10.0. Further information\ncan be found in the `matmul` documentation.\n\nFor standard library functions:\n\n`ndarray.__copy__`()\n\nUsed if `copy.copy` is called on an array.\n\n`ndarray.__deepcopy__`(memo, /)\n\nUsed if `copy.deepcopy` is called on an array.\n\n`ndarray.__reduce__`()\n\nFor pickling.\n\n`ndarray.__setstate__`(state, /)\n\nFor unpickling.\n\nBasic customization:\n\n`ndarray.__new__`(*args, **kwargs)\n\n`ndarray.__array__`([dtype], /)\n\nReturns either a new reference to self if dtype is not given or a new array of\nprovided data type if dtype is different from the current dtype of the array.\n\n`ndarray.__array_wrap__`(array[, context], /)\n\nReturns a view of `array` with the same type as self.\n\nContainer customization: (see Indexing)\n\n`ndarray.__len__`(/)\n\nReturn len(self).\n\n`ndarray.__getitem__`(key, /)\n\nReturn self[key].\n\n`ndarray.__setitem__`(key, value, /)\n\nSet self[key] to value.\n\n`ndarray.__contains__`(key, /)\n\nReturn key in self.\n\nConversion; the operations `int()`, `float()` and `complex()`. They work only\non arrays that have one element in them and return the appropriate scalar.\n\n`ndarray.__int__`(self)\n\n`ndarray.__float__`(self)\n\n`ndarray.__complex__`\n\nString representations:\n\n`ndarray.__str__`(/)\n\nReturn str(self).\n\n`ndarray.__repr__`(/)\n\nReturn repr(self).\n\nUtility method for typing:\n\n`ndarray.__class_getitem__`(item, /)\n\nReturn a parametrized wrapper around the `ndarray` type.\n\n"}, {"name": "The numpy.ma module", "path": "reference/maskedarray.generic", "type": "The \n        \n         numpy.ma\n        \n        module", "text": "\nMasked arrays are arrays that may have missing or invalid entries. The\n`numpy.ma` module provides a nearly work-alike replacement for numpy that\nsupports data arrays with masks.\n\nIn many circumstances, datasets can be incomplete or tainted by the presence\nof invalid data. For example, a sensor may have failed to record a data, or\nrecorded an invalid value. The `numpy.ma` module provides a convenient way to\naddress this issue, by introducing masked arrays.\n\nA masked array is the combination of a standard `numpy.ndarray` and a mask. A\nmask is either `nomask`, indicating that no value of the associated array is\ninvalid, or an array of booleans that determines for each element of the\nassociated array whether the value is valid or not. When an element of the\nmask is `False`, the corresponding element of the associated array is valid\nand is said to be unmasked. When an element of the mask is `True`, the\ncorresponding element of the associated array is said to be masked (invalid).\n\nThe package ensures that masked entries are not used in computations.\n\nAs an illustration, let\u2019s consider the following dataset:\n\nWe wish to mark the fourth entry as invalid. The easiest is to create a masked\narray:\n\nWe can now compute the mean of the dataset, without taking the invalid data\ninto account:\n\nThe main feature of the `numpy.ma` module is the `MaskedArray` class, which is\na subclass of `numpy.ndarray`. The class, its attributes and methods are\ndescribed in more details in the MaskedArray class section.\n\nThe `numpy.ma` module can be used as an addition to `numpy`:\n\nTo create an array with the second element invalid, we would do:\n\nTo create a masked array where all values close to 1.e20 are invalid, we would\ndo:\n\nFor a complete discussion of creation methods for masked arrays please see\nsection Constructing masked arrays.\n\n"}, {"name": "Three ways to wrap - getting started", "path": "f2py/f2py.getting-started", "type": "Three ways to wrap - getting started", "text": "\nWrapping Fortran or C functions to Python using F2PY consists of the following\nsteps:\n\nCreating the so-called signature file that contains descriptions of wrappers\nto Fortran or C functions, also called the signatures of the functions. For\nFortran routines, F2PY can create an initial signature file by scanning\nFortran source codes and tracking all relevant information needed to create\nwrapper functions.\n\nF2PY compiles all sources and builds an extension module containing the\nwrappers.\n\nDepending on the situation, these steps can be carried out in a single\ncomposite command or step-by-step; in which case some steps can be omitted or\ncombined with others.\n\nBelow, we describe three typical approaches of using F2PY. These can be read\nin order of increasing effort, but also cater to different access levels\ndepending on whether the Fortran code can be freely modified.\n\nThe following example Fortran 77 code will be used for illustration, save it\nas `fib1.f`:\n\nThe quickest way to wrap the Fortran subroutine `FIB` for use in Python is to\nrun\n\nThis command compiles and wraps `fib1.f` (`-c`) to create the extension module\n`fib1.so` (`-m`) in the current directory. A list of command line options can\nbe seen by executing `python -m numpy.f2py`. Now, in Python the Fortran\nsubroutine `FIB` is accessible via `fib1.fib`:\n\nNote\n\nOne can use different values for optional `n`:\n\nbut an exception is raised when it is incompatible with the input array `a`:\n\nF2PY implements basic compatibility checks between related arguments in order\nto avoid unexpected crashes.\n\nWhen a NumPy array, that is Fortran contiguous and has a `dtype` corresponding\nto a presumed Fortran type, is used as an input array argument, then its C\npointer is directly passed to Fortran.\n\nOtherwise F2PY makes a contiguous copy (with the proper `dtype`) of the input\narray and passes a C pointer of the copy to the Fortran subroutine. As a\nresult, any possible changes to the (copy of) input array have no effect to\nthe original argument, as demonstrated below:\n\nClearly, this is unexpected, as Fortran typically passes by reference. That\nthe above example worked with `dtype=float` is considered accidental.\n\nF2PY provides an `intent(inplace)` attribute that modifies the attributes of\nan input array so that any changes made by Fortran routine will be reflected\nin the input argument. For example, if one specifies the `intent(inplace) a`\ndirective (see subsequent sections on how), then the example above would read:\n\nHowever, the recommended way to have changes made by Fortran subroutine\npropagate to Python is to use the `intent(out)` attribute. That approach is\nmore efficient and also cleaner.\n\nThough the approach to wrapping Fortran routines for Python discussed so far\nis very straightforward, it has several drawbacks (see the comments above).\nThe drawbacks are due to the fact that there is no way for F2PY to determine\nthe actual intention of the arguments; that is there is ambiguity in\ndistinguishing between input and output arguments. Consequently, F2PY assumes\nthat all arguments are input arguments by default.\n\nHowever, there are ways (see below) to remove this ambiguity by \u201cteaching\u201d\nF2PY about the true intentions of function arguments, and F2PY is then able to\ngenerate more explicit, easier to use, and less error prone wrappers for\nFortran functions.\n\nLet us apply the steps for wrapping Fortran functions to Python one by one.\n\nFirst, we create a signature file from `fib1.f` by running:\n\nThe signature file is saved to `fib1.pyf` (see the `-h` flag) and its contents\nare shown below.\n\nNext, we\u2019ll teach F2PY that the argument `n` is an input argument (using the\n`intent(in)` attribute) and that the result, i.e., the contents of `a` after\ncalling the Fortran function `FIB`, should be returned to Python (using the\n`intent(out)` attribute). In addition, an array `a` should be created\ndynamically using the size determined by the input argument `n` (using the\n`depend(n)` attribute to indicate this dependence relation).\n\nThe contents of a suitably modified version of `fib1.pyf` (saved as\n`fib2.pyf`) is as follows:\n\nFinally, we build the extension module with `numpy.distutils` by running:\n\nIn Python:\n\nNote\n\nThe \u201csmart way\u201d of wrapping Fortran functions, as explained above, is suitable\nfor wrapping (e.g. third party) Fortran codes for which modifications to their\nsource codes are not desirable nor even possible.\n\nHowever, if editing Fortran codes is acceptable, then the generation of an\nintermediate signature file can be skipped in most cases. F2PY specific\nattributes can be inserted directly into Fortran source codes using F2PY\ndirectives. A F2PY directive consists of special comment lines (starting with\n`Cf2py` or `!f2py`, for example) which are ignored by Fortran compilers but\ninterpreted by F2PY as normal lines.\n\nConsider a modified version of the previous Fortran code with F2PY directives,\nsaved as `fib3.f`:\n\nBuilding the extension module can be now carried out in one command:\n\nNotice that the resulting wrapper to `FIB` is as \u201csmart\u201d (unambiguous) as in\nthe previous case:\n\n"}, {"name": "Two and three dots in difference specs", "path": "dev/gitwash/dot2_dot3", "type": "Development", "text": "\nThanks to Yarik Halchenko for this explanation.\n\nImagine a series of commits A, B, C, D\u2026 Imagine that there are two branches,\ntopic and main. You branched topic off main when main was at commit \u2018E\u2019. The\ngraph of the commits looks like this:\n\nThen:\n\nwill output the difference from G to C (i.e. with effects of F and G), while:\n\nwould output just differences in the topic branch (i.e. only A, B, and C).\n\n"}, {"name": "type binomial_t", "path": "reference/random/c-api#c.binomial_t", "type": "C API for random", "text": "\n\n"}, {"name": "type bitgen_t", "path": "reference/random/c-api", "type": "C API for random", "text": "\nNew in version 1.19.0.\n\nAccess to various distributions below is available via Cython or C-wrapper\nlibraries like CFFI. All the functions accept a `bitgen_t` as their first\nargument. To access these from Cython or C, you must link with the `npyrandom`\nlibrary which is part of the NumPy distribution, located in\n`numpy/random/lib`.\n\nThe `bitgen_t` holds the current state of the BitGenerator and pointers to\nfunctions that return standard C types while advancing the state.\n\nSee Extending for examples of using these functions.\n\nThe functions are named with the following conventions:\n\nGenerate a single integer\n\nGenerate random uint64 numbers in closed interval [off, off + rng].\n\n"}, {"name": "type NPY_AO", "path": "reference/c-api/types-and-structures#c.NPY_AO", "type": "Python Types and C-Structures", "text": "\nThe `PyArrayObject` C-structure contains all of the required information for\nan array. All instances of an ndarray (and its subclasses) will have this\nstructure. For future compatibility, these structure members should normally\nbe accessed using the provided macros. If you need a shorter name, then you\ncan make use of `NPY_AO` (deprecated) which is defined to be equivalent to\n`PyArrayObject`. Direct access to the struct fields are deprecated. Use the\n`PyArray_*(arr)` form instead. As of NumPy 1.20, the size of this struct is\nnot considered part of the NumPy ABI (see note at the end of the member list).\n\nThis is needed by all Python objects. It consists of (at least) a reference\ncount member ( `ob_refcnt` ) and a pointer to the typeobject ( `ob_type` ).\n(Other elements may also be present if Python was compiled with special\noptions see Include/object.h in the Python source tree for more information).\nThe ob_type member points to a Python type object.\n\nAccessible via `PyArray_DATA`, this data member is a pointer to the first\nelement of the array. This pointer can (and normally should) be recast to the\ndata type of the array.\n\nAn integer providing the number of dimensions for this array. When nd is 0,\nthe array is sometimes called a rank-0 array. Such arrays have undefined\ndimensions and strides and cannot be accessed. Macro `PyArray_NDIM` defined in\n`ndarraytypes.h` points to this data member. `NPY_MAXDIMS` is the largest\nnumber of dimensions for any array.\n\nAn array of integers providing the shape in each dimension as long as nd\n\\\\(\\geq\\\\) 1\\. The integer is always large enough to hold a pointer on the\nplatform, so the dimension size is only limited by memory. `PyArray_DIMS` is\nthe macro associated with this data member.\n\nAn array of integers providing for each dimension the number of bytes that\nmust be skipped to get to the next element in that dimension. Associated with\nmacro `PyArray_STRIDES`.\n\nPointed to by `PyArray_BASE`, this member is used to hold a pointer to another\nPython object that is related to this array. There are two use cases:\n\nWhen `PyArray_ResolveWritebackIfCopy` is called, the array pointed to by base\nwill be updated with the contents of this array.\n\nA pointer to a data-type descriptor object (see below). The data-type\ndescriptor object is an instance of a new built-in type which allows a generic\ndescription of memory. There is a descriptor structure for each data type\nsupported. This descriptor structure contains useful information about the\ntype as well as a pointer to a table of function pointers to implement\nspecific functionality. As the name suggests, it is associated with the macro\n`PyArray_DESCR`.\n\nPointed to by the macro `PyArray_FLAGS`, this data member represents the flags\nindicating how the memory pointed to by data is to be interpreted. Possible\nflags are `NPY_ARRAY_C_CONTIGUOUS`, `NPY_ARRAY_F_CONTIGUOUS`,\n`NPY_ARRAY_OWNDATA`, `NPY_ARRAY_ALIGNED`, `NPY_ARRAY_WRITEABLE`,\n`NPY_ARRAY_WRITEBACKIFCOPY`, and `NPY_ARRAY_UPDATEIFCOPY`.\n\nThis member allows array objects to have weak references (using the weakref\nmodule).\n\nNote\n\nFurther members are considered private and version dependent. If the size of\nthe struct is important for your code, special care must be taken. A possible\nuse-case when this is relevant is subclassing in C. If your code relies on\n`sizeof(PyArrayObject)` to be constant, you must add the following check at\nimport time:\n\nTo ensure that your code does not have to be compiled for a specific NumPy\nversion, you may add a constant, leaving room for changes in NumPy. A solution\nguaranteed to be compatible with any future NumPy version requires the use of\na runtime calculate offset and allocation size.\n\n"}, {"name": "type npy_cdouble", "path": "reference/c-api/dtype#c.npy_cdouble", "type": "Data Type API", "text": "\n64-bit complex double\n\n"}, {"name": "type npy_cfloat", "path": "reference/c-api/dtype#c.npy_cfloat", "type": "Data Type API", "text": "\n32-bit complex float\n\n"}, {"name": "type npy_clongdouble", "path": "reference/c-api/dtype#c.npy_clongdouble", "type": "Data Type API", "text": "\nlong complex double\n\n"}, {"name": "type npy_double", "path": "reference/c-api/dtype#c.npy_double", "type": "Data Type API", "text": "\n64-bit double\n\n"}, {"name": "type npy_float", "path": "reference/c-api/dtype#c.npy_float", "type": "Data Type API", "text": "\n32-bit float\n\n"}, {"name": "type npy_hash_t", "path": "reference/c-api/types-and-structures#c.NPY_USE_SETITEM.npy_hash_t", "type": "Python Types and C-Structures", "text": "\n\n"}, {"name": "type npy_int", "path": "reference/c-api/dtype#c.npy_int", "type": "Data Type API", "text": "\nint\n\n"}, {"name": "type npy_int16", "path": "reference/c-api/dtype#c.npy_int16", "type": "Data Type API", "text": "\n16-bit integer\n\n"}, {"name": "type npy_int32", "path": "reference/c-api/dtype#c.npy_int32", "type": "Data Type API", "text": "\n32-bit integer\n\n"}, {"name": "type npy_int64", "path": "reference/c-api/dtype#c.npy_int64", "type": "Data Type API", "text": "\n64-bit integer\n\n"}, {"name": "type npy_intp", "path": "reference/c-api/dtype#c.npy_intp", "type": "Data Type API", "text": "\nPy_intptr_t (an integer that is the size of a pointer on the platform).\n\n"}, {"name": "type npy_long", "path": "reference/c-api/dtype#c.npy_long", "type": "Data Type API", "text": "\nlong int\n\n"}, {"name": "type npy_longdouble", "path": "reference/c-api/dtype#c.npy_longdouble", "type": "Data Type API", "text": "\nlong double\n\n"}, {"name": "type npy_longlong", "path": "reference/c-api/dtype#c.npy_longlong", "type": "Data Type API", "text": "\nlong long int\n\n"}, {"name": "type npy_short", "path": "reference/c-api/dtype#c.npy_short", "type": "Data Type API", "text": "\nshort\n\n"}, {"name": "type npy_ubyte", "path": "reference/c-api/dtype#c.npy_ubyte", "type": "Data Type API", "text": "\nunsigned char\n\n"}, {"name": "type npy_uint", "path": "reference/c-api/dtype#c.npy_uint", "type": "Data Type API", "text": "\nunsigned int\n\n"}, {"name": "type npy_uint16", "path": "reference/c-api/dtype#c.npy_uint16", "type": "Data Type API", "text": "\n16-bit unsigned integer\n\n"}, {"name": "type npy_uint32", "path": "reference/c-api/dtype#c.npy_uint32", "type": "Data Type API", "text": "\n32-bit unsigned integer\n\n"}, {"name": "type npy_uint64", "path": "reference/c-api/dtype#c.npy_uint64", "type": "Data Type API", "text": "\n64-bit unsigned integer\n\n"}, {"name": "type npy_uintp", "path": "reference/c-api/dtype#c.npy_uintp", "type": "Data Type API", "text": "\nunsigned Py_intptr_t (an integer that is the size of a pointer on the\nplatform).\n\n"}, {"name": "type npy_ulong", "path": "reference/c-api/dtype#c.npy_ulong", "type": "Data Type API", "text": "\nunsigned long int\n\n"}, {"name": "type npy_ulonglong", "path": "reference/c-api/dtype#c.npy_ulonglong", "type": "Data Type API", "text": "\nunsigned long long int\n\n"}, {"name": "type npy_ushort", "path": "reference/c-api/dtype#c.npy_ushort", "type": "Data Type API", "text": "\nunsigned short\n\n"}, {"name": "type NpyAuxData_CloneFunc", "path": "reference/c-api/array#c.NpyAuxData_CloneFunc", "type": "Array API", "text": "\nThe function pointer type for NpyAuxData clone functions. These functions\nshould never set the Python exception on error, because they may be called\nfrom a multi-threaded context.\n\n"}, {"name": "type NpyAuxData_FreeFunc", "path": "reference/c-api/array#c.NpyAuxData_FreeFunc", "type": "Array API", "text": "\nThe function pointer type for NpyAuxData free functions.\n\n"}, {"name": "type NpyIter", "path": "reference/c-api/iterator", "type": "Array Iterator API", "text": "\nNew in version 1.6.\n\nThe array iterator encapsulates many of the key features in ufuncs, allowing\nuser code to support features like output parameters, preservation of memory\nlayouts, and buffering of data with the wrong alignment or type, without\nrequiring difficult coding.\n\nThis page documents the API for the iterator. The iterator is named `NpyIter`\nand functions are named `NpyIter_*`.\n\nThere is an introductory guide to array iteration which may be of interest for\nthose using this C API. In many instances, testing out ideas by creating the\niterator in Python is a good idea before writing the C iteration code.\n\nThe best way to become familiar with the iterator is to look at its usage\nwithin the NumPy codebase itself. For example, here is a slightly tweaked\nversion of the code for `PyArray_CountNonzero`, which counts the number of\nnon-zero elements in an array.\n\nHere is a simple copy function using the iterator. The `order` parameter is\nused to control the memory layout of the allocated result, typically\n`NPY_KEEPORDER` is desired.\n\nThe iterator layout is an internal detail, and user code only sees an\nincomplete struct.\n\nThis is an opaque pointer type for the iterator. Access to its contents can\nonly be done through the iterator API.\n\nThis is the type which exposes the iterator to Python. Currently, no API is\nexposed which provides access to the values of a Python-created iterator. If\nan iterator is created in Python, it must be used in Python and vice versa.\nSuch an API will likely be created in a future version.\n\nThis is a function pointer for the iteration loop, returned by\n`NpyIter_GetIterNext`.\n\nThis is a function pointer for getting the current iterator multi-index,\nreturned by `NpyIter_GetGetMultiIndex`.\n\nCreates an iterator for the given numpy array object `op`.\n\nFlags that may be passed in `flags` are any combination of the global and per-\noperand flags documented in `NpyIter_MultiNew`, except for\n`NPY_ITER_ALLOCATE`.\n\nAny of the `NPY_ORDER` enum values may be passed to `order`. For efficient\niteration, `NPY_KEEPORDER` is the best option, and the other orders enforce\nthe particular iteration pattern.\n\nAny of the `NPY_CASTING` enum values may be passed to `casting`. The values\ninclude `NPY_NO_CASTING`, `NPY_EQUIV_CASTING`, `NPY_SAFE_CASTING`,\n`NPY_SAME_KIND_CASTING`, and `NPY_UNSAFE_CASTING`. To allow the casts to\noccur, copying or buffering must also be enabled.\n\nIf `dtype` isn\u2019t `NULL`, then it requires that data type. If copying is\nallowed, it will make a temporary copy if the data is castable. If\n`NPY_ITER_UPDATEIFCOPY` is enabled, it will also copy the data back with\nanother cast upon iterator destruction.\n\nReturns NULL if there is an error, otherwise returns the allocated iterator.\n\nTo make an iterator similar to the old iterator, this should work.\n\nIf you want to edit an array with aligned `double` code, but the order doesn\u2019t\nmatter, you would use this.\n\nCreates an iterator for broadcasting the `nop` array objects provided in `op`,\nusing regular NumPy broadcasting rules.\n\nAny of the `NPY_ORDER` enum values may be passed to `order`. For efficient\niteration, `NPY_KEEPORDER` is the best option, and the other orders enforce\nthe particular iteration pattern. When using `NPY_KEEPORDER`, if you also want\nto ensure that the iteration is not reversed along an axis, you should pass\nthe flag `NPY_ITER_DONT_NEGATE_STRIDES`.\n\nAny of the `NPY_CASTING` enum values may be passed to `casting`. The values\ninclude `NPY_NO_CASTING`, `NPY_EQUIV_CASTING`, `NPY_SAFE_CASTING`,\n`NPY_SAME_KIND_CASTING`, and `NPY_UNSAFE_CASTING`. To allow the casts to\noccur, copying or buffering must also be enabled.\n\nIf `op_dtypes` isn\u2019t `NULL`, it specifies a data type or `NULL` for each\n`op[i]`.\n\nReturns NULL if there is an error, otherwise returns the allocated iterator.\n\nFlags that may be passed in `flags`, applying to the whole iterator, are:\n\nCauses the iterator to track a raveled flat index matching C order. This\noption cannot be used with `NPY_ITER_F_INDEX`.\n\nCauses the iterator to track a raveled flat index matching Fortran order. This\noption cannot be used with `NPY_ITER_C_INDEX`.\n\nCauses the iterator to track a multi-index. This prevents the iterator from\ncoalescing axes to produce bigger inner loops. If the loop is also not\nbuffered and no index is being tracked (`NpyIter_RemoveAxis` can be called),\nthen the iterator size can be `-1` to indicate that the iterator is too large.\nThis can happen due to complex broadcasting and will result in errors being\ncreated when the setting the iterator range, removing the multi index, or\ngetting the next function. However, it is possible to remove axes again and\nuse the iterator normally if the size is small enough after removal.\n\nCauses the iterator to skip iteration of the innermost loop, requiring the\nuser of the iterator to handle it.\n\nThis flag is incompatible with `NPY_ITER_C_INDEX`, `NPY_ITER_F_INDEX`, and\n`NPY_ITER_MULTI_INDEX`.\n\nThis only affects the iterator when `NPY_KEEPORDER` is specified for the order\nparameter. By default with `NPY_KEEPORDER`, the iterator reverses axes which\nhave negative strides, so that memory is traversed in a forward direction.\nThis disables this step. Use this flag if you want to use the underlying\nmemory-ordering of the axes, but don\u2019t want an axis reversed. This is the\nbehavior of `numpy.ravel(a, order='K')`, for instance.\n\nCauses the iterator to convert all the operands to a common data type,\ncalculated based on the ufunc type promotion rules. Copying or buffering must\nbe enabled.\n\nIf the common data type is known ahead of time, don\u2019t use this flag. Instead,\nset the requested dtype for all the operands.\n\nIndicates that arrays with reference types (object arrays or structured arrays\ncontaining an object type) may be accepted and used in the iterator. If this\nflag is enabled, the caller must be sure to check whether\nNpyIter_IterationNeedsAPI(iter) is true, in which case it may not release the\nGIL during iteration.\n\nIndicates that arrays with a size of zero should be permitted. Since the\ntypical iteration loop does not naturally work with zero-sized arrays, you\nmust check that the IterSize is larger than zero before entering the iteration\nloop. Currently only the operands are checked, not a forced shape.\n\nPermits writeable operands with a dimension with zero stride and size greater\nthan one. Note that such operands must be read/write.\n\nWhen buffering is enabled, this also switches to a special buffering mode\nwhich reduces the loop length as necessary to not trample on values being\nreduced.\n\nNote that if you want to do a reduction on an automatically allocated output,\nyou must use `NpyIter_GetOperandArray` to get its reference, then set every\nvalue to the reduction unit before doing the iteration loop. In the case of a\nbuffered reduction, this means you must also specify the flag\n`NPY_ITER_DELAY_BUFALLOC`, then reset the iterator after initializing the\nallocated operand to prepare the buffers.\n\nEnables support for iteration of sub-ranges of the full `iterindex` range `[0,\nNpyIter_IterSize(iter))`. Use the function `NpyIter_ResetToIterIndexRange` to\nspecify a range for iteration.\n\nThis flag can only be used with `NPY_ITER_EXTERNAL_LOOP` when\n`NPY_ITER_BUFFERED` is enabled. This is because without buffering, the inner\nloop is always the size of the innermost iteration dimension, and allowing it\nto get cut up would require special handling, effectively making it more like\nthe buffered version.\n\nCauses the iterator to store buffering data, and use buffering to satisfy data\ntype, alignment, and byte-order requirements. To buffer an operand, do not\nspecify the `NPY_ITER_COPY` or `NPY_ITER_UPDATEIFCOPY` flags, because they\nwill override buffering. Buffering is especially useful for Python code using\nthe iterator, allowing for larger chunks of data at once to amortize the\nPython interpreter overhead.\n\nIf used with `NPY_ITER_EXTERNAL_LOOP`, the inner loop for the caller may get\nlarger chunks than would be possible without buffering, because of how the\nstrides are laid out.\n\nNote that if an operand is given the flag `NPY_ITER_COPY` or\n`NPY_ITER_UPDATEIFCOPY`, a copy will be made in preference to buffering.\nBuffering will still occur when the array was broadcast so elements need to be\nduplicated to get a constant stride.\n\nIn normal buffering, the size of each inner loop is equal to the buffer size,\nor possibly larger if `NPY_ITER_GROWINNER` is specified. If\n`NPY_ITER_REDUCE_OK` is enabled and a reduction occurs, the inner loops may\nbecome smaller depending on the structure of the reduction.\n\nWhen buffering is enabled, this allows the size of the inner loop to grow when\nbuffering isn\u2019t necessary. This option is best used if you\u2019re doing a straight\npass through all the data, rather than anything with small cache-friendly\narrays of temporary values for each inner loop.\n\nWhen buffering is enabled, this delays allocation of the buffers until\n`NpyIter_Reset` or another reset function is called. This flag exists to avoid\nwasteful copying of buffer data when making multiple copies of a buffered\niterator for multi-threaded iteration.\n\nAnother use of this flag is for setting up reduction operations. After the\niterator is created, and a reduction output is allocated automatically by the\niterator (be sure to use READWRITE access), its value may be initialized to\nthe reduction unit. Use `NpyIter_GetOperandArray` to get the object. Then,\ncall `NpyIter_Reset` to allocate and fill the buffers with their initial\nvalues.\n\nIf any write operand has overlap with any read operand, eliminate all overlap\nby making temporary copies (enabling UPDATEIFCOPY for write operands, if\nnecessary). A pair of operands has overlap if there is a memory address that\ncontains data common to both arrays.\n\nBecause exact overlap detection has exponential runtime in the number of\ndimensions, the decision is made based on heuristics, which has false\npositives (needless copies in unusual cases) but has no false negatives.\n\nIf any read/write overlap exists, this flag ensures the result of the\noperation is the same as if all operands were copied. In cases where copies\nwould need to be made, the result of the computation may be undefined without\nthis flag!\n\nFlags that may be passed in `op_flags[i]`, where `0 <= i < nop`:\n\nIndicate how the user of the iterator will read or write to `op[i]`. Exactly\none of these flags must be specified per operand. Using `NPY_ITER_READWRITE`\nor `NPY_ITER_WRITEONLY` for a user-provided operand may trigger\n`WRITEBACKIFCOPY`` semantics. The data will be written back to the original\narray when `NpyIter_Deallocate` is called.\n\nAllow a copy of `op[i]` to be made if it does not meet the data type or\nalignment requirements as specified by the constructor flags and parameters.\n\nTriggers `NPY_ITER_COPY`, and when an array operand is flagged for writing and\nis copied, causes the data in a copy to be copied back to `op[i]` when\n`NpyIter_Deallocate` is called.\n\nIf the operand is flagged as write-only and a copy is needed, an uninitialized\ntemporary array will be created and then copied to back to `op[i]` on calling\n`NpyIter_Deallocate`, instead of doing the unnecessary copy operation.\n\nCauses the iterator to provide data for `op[i]` that is in native byte order,\naligned according to the dtype requirements, contiguous, or any combination.\n\nBy default, the iterator produces pointers into the arrays provided, which may\nbe aligned or unaligned, and with any byte order. If copying or buffering is\nnot enabled and the operand data doesn\u2019t satisfy the constraints, an error\nwill be raised.\n\nThe contiguous constraint applies only to the inner loop, successive inner\nloops may have arbitrary pointer changes.\n\nIf the requested data type is in non-native byte order, the NBO flag overrides\nit and the requested data type is converted to be in native byte order.\n\nThis is for output arrays, and requires that the flag `NPY_ITER_WRITEONLY` or\n`NPY_ITER_READWRITE` be set. If `op[i]` is NULL, creates a new array with the\nfinal broadcast dimensions, and a layout matching the iteration order of the\niterator.\n\nWhen `op[i]` is NULL, the requested data type `op_dtypes[i]` may be NULL as\nwell, in which case it is automatically generated from the dtypes of the\narrays which are flagged as readable. The rules for generating the dtype are\nthe same is for UFuncs. Of special note is handling of byte order in the\nselected dtype. If there is exactly one input, the input\u2019s dtype is used as\nis. Otherwise, if more than one input dtypes are combined together, the output\nwill be in native byte order.\n\nAfter being allocated with this flag, the caller may retrieve the new array by\ncalling `NpyIter_GetOperandArray` and getting the i-th object in the returned\nC array. The caller must call Py_INCREF on it to claim a reference to the\narray.\n\nFor use with `NPY_ITER_ALLOCATE`, this flag disables allocating an array\nsubtype for the output, forcing it to be a straight ndarray.\n\nTODO: Maybe it would be better to introduce a function\n`NpyIter_GetWrappedOutput` and remove this flag?\n\nEnsures that the input or output matches the iteration dimensions exactly.\n\nNew in version 1.7.\n\nIndicates that this operand is the mask to use for selecting elements when\nwriting to operands which have the `NPY_ITER_WRITEMASKED` flag applied to\nthem. Only one operand may have `NPY_ITER_ARRAYMASK` flag applied to it.\n\nThe data type of an operand with this flag should be either `NPY_BOOL`,\n`NPY_MASK`, or a struct dtype whose fields are all valid mask dtypes. In the\nlatter case, it must match up with a struct operand being WRITEMASKED, as it\nis specifying a mask for each field of that array.\n\nThis flag only affects writing from the buffer back to the array. This means\nthat if the operand is also `NPY_ITER_READWRITE` or `NPY_ITER_WRITEONLY`, code\ndoing iteration can write to this operand to control which elements will be\nuntouched and which ones will be modified. This is useful when the mask should\nbe a combination of input masks.\n\nNew in version 1.7.\n\nThis array is the mask for all `writemasked` operands. Code uses the\n`writemasked` flag which indicates that only elements where the chosen\nARRAYMASK operand is True will be written to. In general, the iterator does\nnot enforce this, it is up to the code doing the iteration to follow that\npromise.\n\nWhen `writemasked` flag is used, and this operand is buffered, this changes\nhow data is copied from the buffer into the array. A masked copying routine is\nused, which only copies the elements in the buffer for which `writemasked`\nreturns true from the corresponding element in the ARRAYMASK operand.\n\nIn memory overlap checks, assume that operands with\n`NPY_ITER_OVERLAP_ASSUME_ELEMENTWISE` enabled are accessed only in the\niterator order.\n\nThis enables the iterator to reason about data dependency, possibly avoiding\nunnecessary copies.\n\nThis flag has effect only if `NPY_ITER_COPY_IF_OVERLAP` is enabled on the\niterator.\n\nExtends `NpyIter_MultiNew` with several advanced options providing more\ncontrol over broadcasting and buffering.\n\nIf -1/NULL values are passed to `oa_ndim`, `op_axes`, `itershape`, and\n`buffersize`, it is equivalent to `NpyIter_MultiNew`.\n\nThe parameter `oa_ndim`, when not zero or -1, specifies the number of\ndimensions that will be iterated with customized broadcasting. If it is\nprovided, `op_axes` must and `itershape` can also be provided. The `op_axes`\nparameter let you control in detail how the axes of the operand arrays get\nmatched together and iterated. In `op_axes`, you must provide an array of\n`nop` pointers to `oa_ndim`-sized arrays of type `npy_intp`. If an entry in\n`op_axes` is NULL, normal broadcasting rules will apply. In `op_axes[j][i]` is\nstored either a valid axis of `op[j]`, or -1 which means `newaxis`. Within\neach `op_axes[j]` array, axes may not be repeated. The following example is\nhow normal broadcasting applies to a 3-D array, a 2-D array, a 1-D array and a\nscalar.\n\nNote: Before NumPy 1.8 `oa_ndim == 0` was used for signalling that that\n``op_axes` and `itershape` are unused. This is deprecated and should be\nreplaced with -1. Better backward compatibility may be achieved by using\n`NpyIter_MultiNew` for this case.\n\nThe `itershape` parameter allows you to force the iterator to have a specific\niteration shape. It is an array of length `oa_ndim`. When an entry is\nnegative, its value is determined from the operands. This parameter allows\nautomatically allocated outputs to get additional dimensions which don\u2019t match\nup with any dimension of an input.\n\nIf `buffersize` is zero, a default buffer size is used, otherwise it specifies\nhow big of a buffer to use. Buffers which are powers of 2 such as 4096 or 8192\nare recommended.\n\nReturns NULL if there is an error, otherwise returns the allocated iterator.\n\nMakes a copy of the given iterator. This function is provided primarily to\nenable multi-threaded iteration of the data.\n\nTODO: Move this to a section about multithreaded iteration.\n\nThe recommended approach to multithreaded iteration is to first create an\niterator with the flags `NPY_ITER_EXTERNAL_LOOP`, `NPY_ITER_RANGED`,\n`NPY_ITER_BUFFERED`, `NPY_ITER_DELAY_BUFALLOC`, and possibly\n`NPY_ITER_GROWINNER`. Create a copy of this iterator for each thread (minus\none for the first iterator). Then, take the iteration index range `[0,\nNpyIter_GetIterSize(iter))` and split it up into tasks, for example using a\nTBB parallel_for loop. When a thread gets a task to execute, it then uses its\ncopy of the iterator by calling `NpyIter_ResetToIterIndexRange` and iterating\nover the full range.\n\nWhen using the iterator in multi-threaded code or in code not holding the\nPython GIL, care must be taken to only call functions which are safe in that\ncontext. `NpyIter_Copy` cannot be safely called without the Python GIL,\nbecause it increments Python references. The `Reset*` and some other functions\nmay be safely called by passing in the `errmsg` parameter as non-NULL, so that\nthe functions will pass back errors through it instead of setting a Python\nexception.\n\n`NpyIter_Deallocate` must be called for each copy.\n\nRemoves an axis from iteration. This requires that `NPY_ITER_MULTI_INDEX` was\nset for iterator creation, and does not work if buffering is enabled or an\nindex is being tracked. This function also resets the iterator to its initial\nstate.\n\nThis is useful for setting up an accumulation loop, for example. The iterator\ncan first be created with all the dimensions, including the accumulation axis,\nso that the output gets created correctly. Then, the accumulation axis can be\nremoved, and the calculation done in a nested fashion.\n\nWARNING: This function may change the internal memory layout of the iterator.\nAny cached functions or pointers from the iterator must be retrieved again!\nThe iterator range will be reset as well.\n\nReturns `NPY_SUCCEED` or `NPY_FAIL`.\n\nIf the iterator is tracking a multi-index, this strips support for them, and\ndoes further iterator optimizations that are possible if multi-indices are not\nneeded. This function also resets the iterator to its initial state.\n\nWARNING: This function may change the internal memory layout of the iterator.\nAny cached functions or pointers from the iterator must be retrieved again!\n\nAfter calling this function, NpyIter_HasMultiIndex(iter) will return false.\n\nReturns `NPY_SUCCEED` or `NPY_FAIL`.\n\nIf `NpyIter_RemoveMultiIndex` was called, you may want to enable the flag\n`NPY_ITER_EXTERNAL_LOOP`. This flag is not permitted together with\n`NPY_ITER_MULTI_INDEX`, so this function is provided to enable the feature\nafter `NpyIter_RemoveMultiIndex` is called. This function also resets the\niterator to its initial state.\n\nWARNING: This function changes the internal logic of the iterator. Any cached\nfunctions or pointers from the iterator must be retrieved again!\n\nReturns `NPY_SUCCEED` or `NPY_FAIL`.\n\nDeallocates the iterator object and resolves any needed writebacks.\n\nReturns `NPY_SUCCEED` or `NPY_FAIL`.\n\nResets the iterator back to its initial state, at the beginning of the\niteration range.\n\nReturns `NPY_SUCCEED` or `NPY_FAIL`. If errmsg is non-NULL, no Python\nexception is set when `NPY_FAIL` is returned. Instead, *errmsg is set to an\nerror message. When errmsg is non-NULL, the function may be safely called\nwithout holding the Python GIL.\n\nResets the iterator and restricts it to the `iterindex` range `[istart,\niend)`. See `NpyIter_Copy` for an explanation of how to use this for multi-\nthreaded iteration. This requires that the flag `NPY_ITER_RANGED` was passed\nto the iterator constructor.\n\nIf you want to reset both the `iterindex` range and the base pointers at the\nsame time, you can do the following to avoid extra buffer copying (be sure to\nadd the return code error checks when you copy this code).\n\nReturns `NPY_SUCCEED` or `NPY_FAIL`. If errmsg is non-NULL, no Python\nexception is set when `NPY_FAIL` is returned. Instead, *errmsg is set to an\nerror message. When errmsg is non-NULL, the function may be safely called\nwithout holding the Python GIL.\n\nResets the iterator back to its initial state, but using the values in\n`baseptrs` for the data instead of the pointers from the arrays being\niterated. This functions is intended to be used, together with the `op_axes`\nparameter, by nested iteration code with two or more iterators.\n\nReturns `NPY_SUCCEED` or `NPY_FAIL`. If errmsg is non-NULL, no Python\nexception is set when `NPY_FAIL` is returned. Instead, *errmsg is set to an\nerror message. When errmsg is non-NULL, the function may be safely called\nwithout holding the Python GIL.\n\nTODO: Move the following into a special section on nested iterators.\n\nCreating iterators for nested iteration requires some care. All the iterator\noperands must match exactly, or the calls to `NpyIter_ResetBasePointers` will\nbe invalid. This means that automatic copies and output allocation should not\nbe used haphazardly. It is possible to still use the automatic data conversion\nand casting features of the iterator by creating one of the iterators with all\nthe conversion parameters enabled, then grabbing the allocated operands with\nthe `NpyIter_GetOperandArray` function and passing them into the constructors\nfor the rest of the iterators.\n\nWARNING: When creating iterators for nested iteration, the code must not use a\ndimension more than once in the different iterators. If this is done, nested\niteration will produce out-of-bounds pointers during iteration.\n\nWARNING: When creating iterators for nested iteration, buffering can only be\napplied to the innermost iterator. If a buffered iterator is used as the\nsource for `baseptrs`, it will point into a small buffer instead of the array\nand the inner iteration will be invalid.\n\nThe pattern for using nested iterators is as follows.\n\nAdjusts the iterator to point to the `ndim` indices pointed to by\n`multi_index`. Returns an error if a multi-index is not being tracked, the\nindices are out of bounds, or inner loop iteration is disabled.\n\nReturns `NPY_SUCCEED` or `NPY_FAIL`.\n\nAdjusts the iterator to point to the `index` specified. If the iterator was\nconstructed with the flag `NPY_ITER_C_INDEX`, `index` is the C-order index,\nand if the iterator was constructed with the flag `NPY_ITER_F_INDEX`, `index`\nis the Fortran-order index. Returns an error if there is no index being\ntracked, the index is out of bounds, or inner loop iteration is disabled.\n\nReturns `NPY_SUCCEED` or `NPY_FAIL`.\n\nReturns the number of elements being iterated. This is the product of all the\ndimensions in the shape. When a multi index is being tracked (and\n`NpyIter_RemoveAxis` may be called) the size may be `-1` to indicate an\niterator is too large. Such an iterator is invalid, but may become valid after\n`NpyIter_RemoveAxis` is called. It is not necessary to check for this case.\n\nGets the `iterindex` of the iterator, which is an index matching the iteration\norder of the iterator.\n\nGets the `iterindex` sub-range that is being iterated. If `NPY_ITER_RANGED`\nwas not specified, this always returns the range `[0,\nNpyIter_IterSize(iter))`.\n\nAdjusts the iterator to point to the `iterindex` specified. The IterIndex is\nan index matching the iteration order of the iterator. Returns an error if the\n`iterindex` is out of bounds, buffering is enabled, or inner loop iteration is\ndisabled.\n\nReturns `NPY_SUCCEED` or `NPY_FAIL`.\n\nReturns 1 if the flag `NPY_ITER_DELAY_BUFALLOC` was passed to the iterator\nconstructor, and no call to one of the Reset functions has been done yet, 0\notherwise.\n\nReturns 1 if the caller needs to handle the inner-most 1-dimensional loop, or\n0 if the iterator handles all looping. This is controlled by the constructor\nflag `NPY_ITER_EXTERNAL_LOOP` or `NpyIter_EnableExternalLoop`.\n\nReturns 1 if the iterator was created with the `NPY_ITER_MULTI_INDEX` flag, 0\notherwise.\n\nReturns 1 if the iterator was created with the `NPY_ITER_C_INDEX` or\n`NPY_ITER_F_INDEX` flag, 0 otherwise.\n\nReturns 1 if the iterator requires buffering, which occurs when an operand\nneeds conversion or alignment and so cannot be used directly.\n\nReturns 1 if the iterator was created with the `NPY_ITER_BUFFERED` flag, 0\notherwise.\n\nReturns 1 if the iterator was created with the `NPY_ITER_GROWINNER` flag, 0\notherwise.\n\nIf the iterator is buffered, returns the size of the buffer being used,\notherwise returns 0.\n\nReturns the number of dimensions being iterated. If a multi-index was not\nrequested in the iterator constructor, this value may be smaller than the\nnumber of dimensions in the original objects.\n\nReturns the number of operands in the iterator.\n\nGets the array of strides for the specified axis. Requires that the iterator\nbe tracking a multi-index, and that buffering not be enabled.\n\nThis may be used when you want to match up operand axes in some fashion, then\nremove them with `NpyIter_RemoveAxis` to handle their processing manually. By\ncalling this function before removing the axes, you can get the strides for\nthe manual processing.\n\nReturns `NULL` on error.\n\nReturns the broadcast shape of the iterator in `outshape`. This can only be\ncalled on an iterator which is tracking a multi-index.\n\nReturns `NPY_SUCCEED` or `NPY_FAIL`.\n\nThis gives back a pointer to the `nop` data type Descrs for the objects being\niterated. The result points into `iter`, so the caller does not gain any\nreferences to the Descrs.\n\nThis pointer may be cached before the iteration loop, calling `iternext` will\nnot change it.\n\nThis gives back a pointer to the `nop` operand PyObjects that are being\niterated. The result points into `iter`, so the caller does not gain any\nreferences to the PyObjects.\n\nThis gives back a reference to a new ndarray view, which is a view into the\ni-th object in the array `NpyIter_GetOperandArray`, whose dimensions and\nstrides match the internal optimized iteration pattern. A C-order iteration of\nthis view is equivalent to the iterator\u2019s iteration order.\n\nFor example, if an iterator was created with a single array as its input, and\nit was possible to rearrange all its axes and then collapse it into a single\nstrided iteration, this would return a view that is a one-dimensional array.\n\nFills `nop` flags. Sets `outreadflags[i]` to 1 if `op[i]` can be read from,\nand to 0 if not.\n\nFills `nop` flags. Sets `outwriteflags[i]` to 1 if `op[i]` can be written to,\nand to 0 if not.\n\nBuilds a set of strides which are the same as the strides of an output array\ncreated using the `NPY_ITER_ALLOCATE` flag, where NULL was passed for op_axes.\nThis is for data packed contiguously, but not necessarily in C or Fortran\norder. This should be used together with `NpyIter_GetShape` and\n`NpyIter_GetNDim` with the flag `NPY_ITER_MULTI_INDEX` passed into the\nconstructor.\n\nA use case for this function is to match the shape and layout of the iterator\nand tack on one or more dimensions. For example, in order to generate a vector\nper input value for a numerical gradient, you pass in ndim*itemsize for\nitemsize, then add another dimension to the end with size ndim and stride\nitemsize. To do the Hessian matrix, you do the same thing but add two\ndimensions, or take advantage of the symmetry and pack it into 1 dimension\nwith a particular encoding.\n\nThis function may only be called if the iterator is tracking a multi-index and\nif `NPY_ITER_DONT_NEGATE_STRIDES` was used to prevent an axis from being\niterated in reverse order.\n\nIf an array is created with this method, simply adding \u2018itemsize\u2019 for each\niteration will traverse the new array matching the iterator.\n\nReturns `NPY_SUCCEED` or `NPY_FAIL`.\n\nNew in version 1.7.\n\nChecks to see whether this is the first time the elements of the specified\nreduction operand which the iterator points at are being seen for the first\ntime. The function returns a reasonable answer for reduction operands and when\nbuffering is disabled. The answer may be incorrect for buffered non-reduction\noperands.\n\nThis function is intended to be used in EXTERNAL_LOOP mode only, and will\nproduce some wrong answers when that mode is not enabled.\n\nIf this function returns true, the caller should also check the inner loop\nstride of the operand, because if that stride is 0, then only the first\nelement of the innermost external loop is being visited for the first time.\n\nWARNING: For performance reasons, \u2018iop\u2019 is not bounds-checked, it is not\nconfirmed that \u2018iop\u2019 is actually a reduction operand, and it is not confirmed\nthat EXTERNAL_LOOP mode is enabled. These checks are the responsibility of the\ncaller, and should be done outside of any inner loops.\n\nReturns a function pointer for iteration. A specialized version of the\nfunction pointer may be calculated by this function instead of being stored in\nthe iterator structure. Thus, to get good performance, it is required that the\nfunction pointer be saved in a variable rather than retrieved for each loop\niteration.\n\nReturns NULL if there is an error. If errmsg is non-NULL, no Python exception\nis set when `NPY_FAIL` is returned. Instead, *errmsg is set to an error\nmessage. When errmsg is non-NULL, the function may be safely called without\nholding the Python GIL.\n\nThe typical looping construct is as follows.\n\nWhen `NPY_ITER_EXTERNAL_LOOP` is specified, the typical inner loop construct\nis as follows.\n\nObserve that we are using the dataptr array inside the iterator, not copying\nthe values to a local temporary. This is possible because when `iternext()` is\ncalled, these pointers will be overwritten with fresh values, not\nincrementally updated.\n\nIf a compile-time fixed buffer is being used (both flags `NPY_ITER_BUFFERED`\nand `NPY_ITER_EXTERNAL_LOOP`), the inner size may be used as a signal as well.\nThe size is guaranteed to become zero when `iternext()` returns false,\nenabling the following loop construct. Note that if you use this construct,\nyou should not pass `NPY_ITER_GROWINNER` as a flag, because it will cause\nlarger sizes under some circumstances.\n\nReturns a function pointer for getting the current multi-index of the\niterator. Returns NULL if the iterator is not tracking a multi-index. It is\nrecommended that this function pointer be cached in a local variable before\nthe iteration loop.\n\nReturns NULL if there is an error. If errmsg is non-NULL, no Python exception\nis set when `NPY_FAIL` is returned. Instead, *errmsg is set to an error\nmessage. When errmsg is non-NULL, the function may be safely called without\nholding the Python GIL.\n\nThis gives back a pointer to the `nop` data pointers. If\n`NPY_ITER_EXTERNAL_LOOP` was not specified, each data pointer points to the\ncurrent data item of the iterator. If no inner iteration was specified, it\npoints to the first data item of the inner loop.\n\nThis pointer may be cached before the iteration loop, calling `iternext` will\nnot change it. This function may be safely called without holding the Python\nGIL.\n\nGets the array of data pointers directly into the arrays (never into the\nbuffers), corresponding to iteration index 0.\n\nThese pointers are different from the pointers accepted by\n`NpyIter_ResetBasePointers`, because the direction along some axes may have\nbeen reversed.\n\nThis function may be safely called without holding the Python GIL.\n\nThis gives back a pointer to the index being tracked, or NULL if no index is\nbeing tracked. It is only usable if one of the flags `NPY_ITER_C_INDEX` or\n`NPY_ITER_F_INDEX` were specified during construction.\n\nWhen the flag `NPY_ITER_EXTERNAL_LOOP` is used, the code needs to know the\nparameters for doing the inner loop. These functions provide that information.\n\nReturns a pointer to an array of the `nop` strides, one for each iterated\nobject, to be used by the inner loop.\n\nThis pointer may be cached before the iteration loop, calling `iternext` will\nnot change it. This function may be safely called without holding the Python\nGIL.\n\nWARNING: While the pointer may be cached, its values may change if the\niterator is buffered.\n\nReturns a pointer to the number of iterations the inner loop should execute.\n\nThis address may be cached before the iteration loop, calling `iternext` will\nnot change it. The value itself may change during iteration, in particular if\nbuffering is enabled. This function may be safely called without holding the\nPython GIL.\n\nGets an array of strides which are fixed, or will not change during the entire\niteration. For strides that may change, the value NPY_MAX_INTP is placed in\nthe stride.\n\nOnce the iterator is prepared for iteration (after a reset if\n`NPY_ITER_DELAY_BUFALLOC` was used), call this to get the strides which may be\nused to select a fast inner loop function. For example, if the stride is 0,\nthat means the inner loop can always load its value into a variable once, then\nuse the variable throughout the loop, or if the stride equals the itemsize, a\ncontiguous version for that operand may be used.\n\nThis function may be safely called without holding the Python GIL.\n\nThe old iterator API includes functions like PyArrayIter_Check, PyArray_Iter*\nand PyArray_ITER_*. The multi-iterator array includes PyArray_MultiIter*,\nPyArray_Broadcast, and PyArray_RemoveSmallest. The new iterator design\nreplaces all of this functionality with a single object and associated API.\nOne goal of the new API is that all uses of the existing iterator should be\nreplaceable with the new iterator without significant effort. In 1.6, the\nmajor exception to this is the neighborhood iterator, which does not have\ncorresponding features in this iterator.\n\nHere is a conversion table for which functions to use with the new iterator:\n\nIterator Functions\n\n`PyArray_IterNew`\n\n`NpyIter_New`\n\n`PyArray_IterAllButAxis`\n\n`NpyIter_New` \\+ `axes` parameter or Iterator flag `NPY_ITER_EXTERNAL_LOOP`\n\n`PyArray_BroadcastToShape`\n\nNOT SUPPORTED (Use the support for multiple operands instead.)\n\n`PyArrayIter_Check`\n\nWill need to add this in Python exposure\n\n`PyArray_ITER_RESET`\n\n`NpyIter_Reset`\n\n`PyArray_ITER_NEXT`\n\nFunction pointer from `NpyIter_GetIterNext`\n\n`PyArray_ITER_DATA`\n\n`NpyIter_GetDataPtrArray`\n\n`PyArray_ITER_GOTO`\n\n`NpyIter_GotoMultiIndex`\n\n`PyArray_ITER_GOTO1D`\n\n`NpyIter_GotoIndex` or `NpyIter_GotoIterIndex`\n\n`PyArray_ITER_NOTDONE`\n\nReturn value of `iternext` function pointer\n\nMulti-iterator Functions\n\n`PyArray_MultiIterNew`\n\n`NpyIter_MultiNew`\n\n`PyArray_MultiIter_RESET`\n\n`NpyIter_Reset`\n\n`PyArray_MultiIter_NEXT`\n\nFunction pointer from `NpyIter_GetIterNext`\n\n`PyArray_MultiIter_DATA`\n\n`NpyIter_GetDataPtrArray`\n\n`PyArray_MultiIter_NEXTi`\n\nNOT SUPPORTED (always lock-step iteration)\n\n`PyArray_MultiIter_GOTO`\n\n`NpyIter_GotoMultiIndex`\n\n`PyArray_MultiIter_GOTO1D`\n\n`NpyIter_GotoIndex` or `NpyIter_GotoIterIndex`\n\n`PyArray_MultiIter_NOTDONE`\n\nReturn value of `iternext` function pointer\n\n`PyArray_Broadcast`\n\nHandled by `NpyIter_MultiNew`\n\n`PyArray_RemoveSmallest`\n\nIterator flag `NPY_ITER_EXTERNAL_LOOP`\n\nOther Functions\n\n`PyArray_ConvertToCommonType`\n\nIterator flag `NPY_ITER_COMMON_DTYPE`\n\n"}, {"name": "type NpyIter_GetMultiIndexFunc", "path": "reference/c-api/iterator#c.NpyIter_GetMultiIndexFunc", "type": "Array Iterator API", "text": "\nThis is a function pointer for getting the current iterator multi-index,\nreturned by `NpyIter_GetGetMultiIndex`.\n\n"}, {"name": "type NpyIter_IterNextFunc", "path": "reference/c-api/iterator#c.NpyIter_IterNextFunc", "type": "Array Iterator API", "text": "\nThis is a function pointer for the iteration loop, returned by\n`NpyIter_GetIterNext`.\n\n"}, {"name": "type NpyIter_Type", "path": "reference/c-api/iterator#c.NpyIter_Type", "type": "Array Iterator API", "text": "\nThis is the type which exposes the iterator to Python. Currently, no API is\nexposed which provides access to the values of a Python-created iterator. If\nan iterator is created in Python, it must be used in Python and vice versa.\nSuch an API will likely be created in a future version.\n\n"}, {"name": "type PyArray_ArrFuncs", "path": "reference/c-api/types-and-structures#c.PyArray_ArrFuncs", "type": "Python Types and C-Structures", "text": "\nFunctions implementing internal features. Not all of these function pointers\nmust be defined for a given type. The required members are `nonzero`,\n`copyswap`, `copyswapn`, `setitem`, `getitem`, and `cast`. These are assumed\nto be non- `NULL` and `NULL` entries will cause a program crash. The other\nfunctions may be `NULL` which will just mean reduced functionality for that\ndata-type. (Also, the nonzero function will be filled in with a default\nfunction if it is `NULL` when you register a user-defined data-type).\n\nThe concept of a behaved segment is used in the description of the function\npointers. A behaved segment is one that is aligned and in native machine byte-\norder for the data-type. The `nonzero`, `copyswap`, `copyswapn`, `getitem`,\nand `setitem` functions can (and must) deal with mis-behaved arrays. The other\nfunctions require behaved memory segments.\n\nAn array of function pointers to cast from the current type to all of the\nother builtin types. Each function casts a contiguous, aligned, and notswapped\nbuffer pointed at by from to a contiguous, aligned, and notswapped buffer\npointed at by to The number of items to cast is given by n, and the arguments\nfromarr and toarr are interpreted as PyArrayObjects for flexible arrays to get\nitemsize information.\n\nA pointer to a function that returns a standard Python object from a single\nelement of the array object arr pointed to by data. This function must be able\nto deal with \u201cmisbehaved \u201c(misaligned and/or swapped) arrays correctly.\n\nA pointer to a function that sets the Python object item into the array, arr,\nat the position pointed to by data . This function deals with \u201cmisbehaved\u201d\narrays. If successful, a zero is returned, otherwise, a negative one is\nreturned (and a Python error set).\n\nThese members are both pointers to functions to copy data from src to dest and\nswap if indicated. The value of arr is only used for flexible ( `NPY_STRING`,\n`NPY_UNICODE`, and `NPY_VOID` ) arrays (and is obtained from\n`arr->descr->elsize` ). The second function copies a single value, while the\nfirst loops over n values with the provided strides. These functions can deal\nwith misbehaved src data. If src is NULL then no copy is performed. If swap is\n0, then no byteswapping occurs. It is assumed that dest and src do not\noverlap. If they overlap, then use `memmove` (\u2026) first followed by\n`copyswap(n)` with NULL valued `src`.\n\nA pointer to a function that compares two elements of the array, `arr`,\npointed to by `d1` and `d2`. This function requires behaved (aligned and not\nswapped) arrays. The return value is 1 if * `d1` > * `d2`, 0 if * `d1` == *\n`d2`, and -1 if * `d1` < * `d2`. The array object `arr` is used to retrieve\nitemsize and field information for flexible arrays.\n\nA pointer to a function that retrieves the index of the largest of `n`\nelements in `arr` beginning at the element pointed to by `data`. This function\nrequires that the memory segment be contiguous and behaved. The return value\nis always 0. The index of the largest element is returned in `max_ind`.\n\nA pointer to a function that multiplies two `n` -length sequences together,\nadds them, and places the result in element pointed to by `op` of `arr`. The\nstart of the two sequences are pointed to by `ip1` and `ip2`. To get to the\nnext element in each sequence requires a jump of `is1` and `is2` bytes,\nrespectively. This function requires behaved (though not necessarily\ncontiguous) memory.\n\nA pointer to a function that scans (scanf style) one element of the\ncorresponding type from the file descriptor `fd` into the array memory pointed\nto by `ip`. The array is assumed to be behaved. The last argument `arr` is the\narray to be scanned into. Returns number of receiving arguments successfully\nassigned (which may be zero in case a matching failure occurred before the\nfirst receiving argument was assigned), or EOF if input failure occurs before\nthe first receiving argument was assigned. This function should be called\nwithout holding the Python GIL, and has to grab it for error reporting.\n\nA pointer to a function that converts the string pointed to by `str` to one\nelement of the corresponding type and places it in the memory location pointed\nto by `ip`. After the conversion is completed, `*endptr` points to the rest of\nthe string. The last argument `arr` is the array into which ip points (needed\nfor variable-size data- types). Returns 0 on success or -1 on failure.\nRequires a behaved array. This function should be called without holding the\nPython GIL, and has to grab it for error reporting.\n\nA pointer to a function that returns TRUE if the item of `arr` pointed to by\n`data` is nonzero. This function can deal with misbehaved arrays.\n\nA pointer to a function that fills a contiguous array of given length with\ndata. The first two elements of the array must already be filled- in. From\nthese two values, a delta will be computed and the values from item 3 to the\nend will be computed by repeatedly adding this computed delta. The data buffer\nmust be well-behaved.\n\nA pointer to a function that fills a contiguous `buffer` of the given `length`\nwith a single scalar `value` whose address is given. The final argument is the\narray which is needed to get the itemsize for variable-length arrays.\n\nAn array of function pointers to a particular sorting algorithms. A particular\nsorting algorithm is obtained using a key (so far `NPY_QUICKSORT`,\n`NPY_HEAPSORT`, and `NPY_MERGESORT` are defined). These sorts are done in-\nplace assuming contiguous and aligned data.\n\nAn array of function pointers to sorting algorithms for this data type. The\nsame sorting algorithms as for sort are available. The indices producing the\nsort are returned in `result` (which must be initialized with indices 0 to\n`length-1` inclusive).\n\nEither `NULL` or a dictionary containing low-level casting functions for user-\ndefined data-types. Each function is wrapped in a PyCapsule* and keyed by the\ndata-type number.\n\nA function to determine how scalars of this type should be interpreted. The\nargument is `NULL` or a 0-dimensional array containing the data (if that is\nneeded to determine the kind of scalar). The return value must be of type\n`NPY_SCALARKIND`.\n\nEither `NULL` or an array of `NPY_NSCALARKINDS` pointers. These pointers\nshould each be either `NULL` or a pointer to an array of integers (terminated\nby `NPY_NOTYPE`) indicating data-types that a scalar of this data-type of the\nspecified kind can be cast to safely (this usually means without losing\nprecision).\n\nEither `NULL` or an array of integers (terminated by `NPY_NOTYPE` ) indicated\ndata-types that this data-type can be cast to safely (this usually means\nwithout losing precision).\n\nDeprecated since version 1.17: The use of this function will give a\ndeprecation warning when `np.clip`. Instead of this function, the datatype\nmust instead use `PyUFunc_RegisterLoopForDescr` to attach a custom loop to\n`np.core.umath.clip`, `np.minimum`, and `np.maximum`.\n\nDeprecated since version 1.19: Setting this function is deprecated and should\nalways be `NULL`, if set, it will be ignored.\n\nA function that reads `n_in` items from `in`, and writes to `out` the read\nvalue if it is within the limits pointed to by `min` and `max`, or the\ncorresponding limit if outside. The memory segments must be contiguous and\nbehaved, and either `min` or `max` may be `NULL`, but not both.\n\nDeprecated since version 1.19: Setting this function is deprecated and should\nalways be `NULL`, if set, it will be ignored.\n\nA function that takes a pointer `in` to an array of `n_in` items, a pointer\n`mask` to an array of `n_in` boolean values, and a pointer `vals` to an array\nof `nv` items. Items from `vals` are copied into `in` wherever the value in\n`mask` is non-zero, tiling `vals` as needed if `nv < n_in`. All arrays must be\ncontiguous and behaved.\n\nDeprecated since version 1.19: Setting this function is deprecated and should\nalways be `NULL`, if set, it will be ignored.\n\nA function that takes a pointer `src` to a C contiguous, behaved segment,\ninterpreted as a 3-dimensional array of shape `(n_outer, nindarray, nelem)`, a\npointer `indarray` to a contiguous, behaved segment of `m_middle` integer\nindices, and a pointer `dest` to a C contiguous, behaved segment, interpreted\nas a 3-dimensional array of shape `(n_outer, m_middle, nelem)`. The indices in\n`indarray` are used to index `src` along the second dimension, and copy the\ncorresponding chunks of `nelem` items into `dest`. `clipmode` (which can take\non the values `NPY_RAISE`, `NPY_WRAP` or `NPY_CLIP`) determines how will\nindices smaller than 0 or larger than `nindarray` will be handled.\n\nA pointer to a function that retrieves the index of the smallest of `n`\nelements in `arr` beginning at the element pointed to by `data`. This function\nrequires that the memory segment be contiguous and behaved. The return value\nis always 0. The index of the smallest element is returned in `min_ind`.\n\n"}, {"name": "type PyArray_Descr", "path": "reference/c-api/types-and-structures#c.PyArray_Descr", "type": "Python Types and C-Structures", "text": "\nThe `PyArray_Descr` structure lies at the heart of the `PyArrayDescr_Type`.\nWhile it is described here for completeness, it should be considered internal\nto NumPy and manipulated via `PyArrayDescr_*` or `PyDataType*` functions and\nmacros. The size of this structure is subject to change across versions of\nNumPy. To ensure compatibility:\n\nIt has the following structure:\n\nPointer to a typeobject that is the corresponding Python type for the elements\nof this array. For the builtin types, this points to the corresponding array\nscalar. For user-defined types, this should point to a user-defined\ntypeobject. This typeobject can either inherit from array scalars or not. If\nit does not inherit from array scalars, then the `NPY_USE_GETITEM` and\n`NPY_USE_SETITEM` flags should be set in the `flags` member.\n\nA character code indicating the kind of array (using the array interface\ntypestring notation). A \u2018b\u2019 represents Boolean, a \u2018i\u2019 represents signed\ninteger, a \u2018u\u2019 represents unsigned integer, \u2018f\u2019 represents floating point, \u2018c\u2019\nrepresents complex floating point, \u2018S\u2019 represents 8-bit zero-terminated bytes,\n\u2018U\u2019 represents 32-bit/character unicode string, and \u2018V\u2019 represents arbitrary.\n\nA traditional character code indicating the data type.\n\nA character indicating the byte-order: \u2018>\u2019 (big-endian), \u2018<\u2019 (little- endian),\n\u2018=\u2019 (native), \u2018|\u2019 (irrelevant, ignore). All builtin data- types have byteorder\n\u2018=\u2019.\n\nA data-type bit-flag that determines if the data-type exhibits object- array\nlike behavior. Each bit in this member is a flag which are named as:\n\n"}, {"name": "type PyArrayFlagsObject", "path": "reference/c-api/types-and-structures#c.PyArrayFlagsObject", "type": "Python Types and C-Structures", "text": "\n\n"}, {"name": "type PyArrayIterObject", "path": "reference/c-api/types-and-structures#c.PyArrayIterObject", "type": "Python Types and C-Structures", "text": "\nThe C-structure corresponding to an object of `PyArrayIter_Type` is the\n`PyArrayIterObject`. The `PyArrayIterObject` is used to keep track of a\npointer into an N-dimensional array. It contains associated information used\nto quickly march through the array. The pointer can be adjusted in three basic\nways: 1) advance to the \u201cnext\u201d position in the array in a C-style contiguous\nfashion, 2) advance to an arbitrary N-dimensional coordinate in the array, and\n3) advance to an arbitrary one-dimensional index into the array. The members\nof the `PyArrayIterObject` structure are used in these calculations. Iterator\nobjects keep their own dimension and strides information about an array. This\ncan be adjusted as needed for \u201cbroadcasting,\u201d or to loop over only specific\ndimensions.\n\n\\\\(N-1\\\\) where \\\\(N\\\\) is the number of dimensions in the underlying array.\n\nThe current 1-d index into the array.\n\nThe total size of the underlying array.\n\nAn \\\\(N\\\\) -dimensional index into the array.\n\nThe size of the array minus 1 in each dimension.\n\nThe strides of the array. How many bytes needed to jump to the next element in\neach dimension.\n\nHow many bytes needed to jump from the end of a dimension back to its\nbeginning. Note that `backstrides[k] == strides[k] * dims_m1[k]`, but it is\nstored here as an optimization.\n\nThis array is used in computing an N-d index from a 1-d index. It contains\nneeded products of the dimensions.\n\nA pointer to the underlying ndarray this iterator was created to represent.\n\nThis member points to an element in the ndarray indicated by the index.\n\nThis flag is true if the underlying array is `NPY_ARRAY_C_CONTIGUOUS`. It is\nused to simplify calculations when possible.\n\n"}, {"name": "type PyArrayMultiIterObject", "path": "reference/c-api/types-and-structures#c.PyArrayMultiIterObject", "type": "Python Types and C-Structures", "text": "\nThe number of arrays that need to be broadcast to the same shape.\n\nThe total broadcasted size.\n\nThe current (1-d) index into the broadcasted result.\n\nThe number of dimensions in the broadcasted result.\n\nThe shape of the broadcasted result (only `nd` slots are used).\n\nAn array of iterator objects that holds the iterators for the arrays to be\nbroadcast together. On return, the iterators are adjusted for broadcasting.\n\n"}, {"name": "type PyArrayNeighborhoodIterObject", "path": "reference/c-api/types-and-structures#c.PyArrayNeighborhoodIterObject", "type": "Python Types and C-Structures", "text": "\nThe C-structure corresponding to an object of `PyArrayNeighborhoodIter_Type`\nis the `PyArrayNeighborhoodIterObject`.\n\n"}, {"name": "type PyArrayObject", "path": "reference/c-api/types-and-structures#c.PyArrayObject", "type": "Python Types and C-Structures", "text": "\nThe `PyArrayObject` C-structure contains all of the required information for\nan array. All instances of an ndarray (and its subclasses) will have this\nstructure. For future compatibility, these structure members should normally\nbe accessed using the provided macros. If you need a shorter name, then you\ncan make use of `NPY_AO` (deprecated) which is defined to be equivalent to\n`PyArrayObject`. Direct access to the struct fields are deprecated. Use the\n`PyArray_*(arr)` form instead. As of NumPy 1.20, the size of this struct is\nnot considered part of the NumPy ABI (see note at the end of the member list).\n\nThis is needed by all Python objects. It consists of (at least) a reference\ncount member ( `ob_refcnt` ) and a pointer to the typeobject ( `ob_type` ).\n(Other elements may also be present if Python was compiled with special\noptions see Include/object.h in the Python source tree for more information).\nThe ob_type member points to a Python type object.\n\nAccessible via `PyArray_DATA`, this data member is a pointer to the first\nelement of the array. This pointer can (and normally should) be recast to the\ndata type of the array.\n\nAn integer providing the number of dimensions for this array. When nd is 0,\nthe array is sometimes called a rank-0 array. Such arrays have undefined\ndimensions and strides and cannot be accessed. Macro `PyArray_NDIM` defined in\n`ndarraytypes.h` points to this data member. `NPY_MAXDIMS` is the largest\nnumber of dimensions for any array.\n\nAn array of integers providing the shape in each dimension as long as nd\n\\\\(\\geq\\\\) 1\\. The integer is always large enough to hold a pointer on the\nplatform, so the dimension size is only limited by memory. `PyArray_DIMS` is\nthe macro associated with this data member.\n\nAn array of integers providing for each dimension the number of bytes that\nmust be skipped to get to the next element in that dimension. Associated with\nmacro `PyArray_STRIDES`.\n\nPointed to by `PyArray_BASE`, this member is used to hold a pointer to another\nPython object that is related to this array. There are two use cases:\n\nWhen `PyArray_ResolveWritebackIfCopy` is called, the array pointed to by base\nwill be updated with the contents of this array.\n\nA pointer to a data-type descriptor object (see below). The data-type\ndescriptor object is an instance of a new built-in type which allows a generic\ndescription of memory. There is a descriptor structure for each data type\nsupported. This descriptor structure contains useful information about the\ntype as well as a pointer to a table of function pointers to implement\nspecific functionality. As the name suggests, it is associated with the macro\n`PyArray_DESCR`.\n\nPointed to by the macro `PyArray_FLAGS`, this data member represents the flags\nindicating how the memory pointed to by data is to be interpreted. Possible\nflags are `NPY_ARRAY_C_CONTIGUOUS`, `NPY_ARRAY_F_CONTIGUOUS`,\n`NPY_ARRAY_OWNDATA`, `NPY_ARRAY_ALIGNED`, `NPY_ARRAY_WRITEABLE`,\n`NPY_ARRAY_WRITEBACKIFCOPY`, and `NPY_ARRAY_UPDATEIFCOPY`.\n\nThis member allows array objects to have weak references (using the weakref\nmodule).\n\nNote\n\nFurther members are considered private and version dependent. If the size of\nthe struct is important for your code, special care must be taken. A possible\nuse-case when this is relevant is subclassing in C. If your code relies on\n`sizeof(PyArrayObject)` to be constant, you must add the following check at\nimport time:\n\nTo ensure that your code does not have to be compiled for a specific NumPy\nversion, you may add a constant, leaving room for changes in NumPy. A solution\nguaranteed to be compatible with any future NumPy version requires the use of\na runtime calculate offset and allocation size.\n\n"}, {"name": "type PyDataMem_Handler", "path": "reference/c-api/data_memory", "type": "Memory management in NumPy", "text": "\nThe `numpy.ndarray` is a python class. It requires additional memory\nallocations to hold `numpy.ndarray.strides`, `numpy.ndarray.shape` and\n`numpy.ndarray.data` attributes. These attributes are specially allocated\nafter creating the python object in `__new__`. The `strides` and `shape` are\nstored in a piece of memory allocated internally.\n\nThe `data` allocation used to store the actual array values (which could be\npointers in the case of `object` arrays) can be very large, so NumPy has\nprovided interfaces to manage its allocation and release. This document\ndetails how those interfaces work.\n\nSince version 1.7.0, NumPy has exposed a set of `PyDataMem_*` functions\n(`PyDataMem_NEW`, `PyDataMem_FREE`, `PyDataMem_RENEW`) which are backed by\n`alloc`, `free`, `realloc` respectively. In that version NumPy also exposed\nthe `PyDataMem_EventHook` function described below, which wrap the OS-level\ncalls.\n\nSince those early days, Python also improved its memory management\ncapabilities, and began providing various management policies beginning in\nversion 3.4. These routines are divided into a set of domains, each domain has\na `PyMemAllocatorEx` structure of routines for memory management. Python also\nadded a `tracemalloc` module to trace calls to the various routines. These\ntracking hooks were added to the NumPy `PyDataMem_*` routines.\n\nNumPy added a small cache of allocated memory in its internal\n`npy_alloc_cache`, `npy_alloc_cache_zero`, and `npy_free_cache` functions.\nThese wrap `alloc`, `alloc-and-memset(0)` and `free` respectively, but when\n`npy_free_cache` is called, it adds the pointer to a short list of available\nblocks marked by size. These blocks can be re-used by subsequent calls to\n`npy_alloc*`, avoiding memory thrashing.\n\nUsers may wish to override the internal data memory routines with ones of\ntheir own. Since NumPy does not use the Python domain strategy to manage data\nmemory, it provides an alternative set of C-APIs to change memory routines.\nThere are no Python domain-wide strategies for large chunks of object data, so\nthose are less suited to NumPy\u2019s needs. User who wish to change the NumPy data\nmemory management routines can use `PyDataMem_SetHandler`, which uses a\n`PyDataMem_Handler` structure to hold pointers to functions used to manage the\ndata memory. The calls are still wrapped by internal routines to call\n`PyTraceMalloc_Track`, `PyTraceMalloc_Untrack`, and will use the\n`PyDataMem_EventHookFunc` mechanism. Since the functions may change during the\nlifetime of the process, each `ndarray` carries with it the functions used at\nthe time of its instantiation, and these will be used to reallocate or free\nthe data memory of the instance.\n\nA struct to hold function pointers used to manipulate memory\n\nwhere the allocator structure is\n\nSet a new allocation policy. If the input value is `NULL`, will reset the\npolicy to the default. Return the previous policy, or return `NULL` if an\nerror has occurred. We wrap the user-provided functions so they will still\ncall the python and numpy memory management callback hooks.\n\nReturn the current policy that will be used to allocate data for the next\n`PyArrayObject`. On failure, return `NULL`.\n\nFor an example of setting up and using the PyDataMem_Handler, see the test in\n`numpy/core/tests/test_mem_policy.py`\n\nThis function will be called during data memory manipulation\n\nSets the allocation event hook for numpy array data.\n\nReturns a pointer to the previous hook or `NULL`. If old_data is non-`NULL`,\nthe previous user_data pointer will be copied to it.\n\nIf not `NULL`, hook will be called at the end of each\n`PyDataMem_NEW/FREE/RENEW`:\n\nWhen the hook is called, the GIL will be held by the calling thread. The hook\nshould be written to be reentrant, if it performs operations that might cause\nnew allocation events (such as the creation/destruction numpy objects, or\ncreating/destroying Python objects which might cause a gc)\n\nA rare but useful technique is to allocate a buffer outside NumPy, use\n`PyArray_NewFromDescr` to wrap the buffer in a `ndarray`, then switch the\n`OWNDATA` flag to true. When the `ndarray` is released, the appropriate\nfunction from the `ndarray`\u2019s `PyDataMem_Handler` should be called to free the\nbuffer. But the `PyDataMem_Handler` field was never set, it will be `NULL`.\nFor backward compatibility, NumPy will call `free()` to release the buffer. If\n`NUMPY_WARN_IF_NO_MEM_POLICY` is set to `1`, a warning will be emitted. The\ncurrent default is not to emit a warning, this may change in a future version\nof NumPy.\n\nA better technique would be to use a `PyCapsule` as a base object:\n\n"}, {"name": "type PyUFunc_Loop1d", "path": "reference/c-api/types-and-structures#c.PyUFunc_Loop1d", "type": "Python Types and C-Structures", "text": "\nA simple linked-list of C-structures containing the information needed to\ndefine a 1-d loop for a ufunc for every defined signature of a user-defined\ndata-type.\n\n"}, {"name": "type PyUFuncObject", "path": "reference/c-api/types-and-structures#c.PyUFuncObject", "type": "Python Types and C-Structures", "text": "\nThe core of the ufunc is the `PyUFuncObject` which contains all the\ninformation needed to call the underlying C-code loops that perform the actual\nwork. While it is described here for completeness, it should be considered\ninternal to NumPy and manipulated via `PyUFunc_*` functions. The size of this\nstructure is subject to change across versions of NumPy. To ensure\ncompatibility:\n\nIt has the following structure:\n\nThe number of input arguments.\n\nThe number of output arguments.\n\nThe total number of arguments (nin \\+ nout). This must be less than\n`NPY_MAXARGS`.\n\nEither `PyUFunc_One`, `PyUFunc_Zero`, `PyUFunc_MinusOne`, `PyUFunc_None`,\n`PyUFunc_ReorderableNone`, or `PyUFunc_IdentityValue` to indicate the identity\nfor this operation. It is only used for a reduce-like call on an empty array.\n\nAn array of function pointers \u2014 one for each data type supported by the ufunc.\nThis is the vector loop that is called to implement the underlying function\ndims [0] times. The first argument, args, is an array of nargs pointers to\nbehaved memory. Pointers to the data for the input arguments are first,\nfollowed by the pointers to the data for the output arguments. How many bytes\nmust be skipped to get to the next element in the sequence is specified by the\ncorresponding entry in the steps array. The last argument allows the loop to\nreceive extra information. This is commonly used so that a single, generic\nvector loop can be used for multiple functions. In this case, the actual\nscalar function to call is passed in as extradata. The size of this function\npointer array is ntypes.\n\nExtra data to be passed to the 1-d vector loops or `NULL` if no extra-data is\nneeded. This C-array must be the same size ( i.e. ntypes) as the functions\narray. `NULL` is used if extra_data is not needed. Several C-API calls for\nUFuncs are just 1-d vector loops that make use of this extra data to receive a\npointer to the actual function to call.\n\nThe number of supported data types for the ufunc. This number specifies how\nmany different 1-d loops (of the builtin data types) are available.\n\nUnused.\n\nA string name for the ufunc. This is used dynamically to build the __doc__\nattribute of ufuncs.\n\nAn array of \\\\(nargs \\times ntypes\\\\) 8-bit type_numbers which contains the\ntype signature for the function for each of the supported (builtin) data\ntypes. For each of the ntypes functions, the corresponding set of type numbers\nin this array shows how the args argument should be interpreted in the 1-d\nvector loop. These type numbers do not have to be the same type and mixed-type\nufuncs are supported.\n\nDocumentation for the ufunc. Should not contain the function signature as this\nis generated dynamically when __doc__ is retrieved.\n\nAny dynamically allocated memory. Currently, this is used for dynamic ufuncs\ncreated from a python function to store room for the types, data, and name\nmembers.\n\nFor ufuncs dynamically created from python functions, this member holds a\nreference to the underlying Python function.\n\nA dictionary of user-defined 1-d vector loops (stored as CObject ptrs) for\nuser-defined types. A loop may be registered by the user for any user-defined\ntype. It is retrieved by type number. User defined type numbers are always\nlarger than `NPY_USERDEF`.\n\n0 for scalar ufuncs; 1 for generalized ufuncs\n\nNumber of distinct core dimension names in the signature\n\nNumber of core dimensions of each argument\n\nDimension indices in a flattened form; indices of argument `k` are stored in\n`core_dim_ixs[core_offsets[k] : core_offsets[k] + core_numdims[k]]`\n\nPosition of 1st core dimension of each argument in `core_dim_ixs`, equivalent\nto cumsum(`core_num_dims`)\n\nCore signature string\n\nA function which resolves the types and fills an array with the dtypes for the\ninputs and outputs\n\nDeprecated since version 1.22: Some fallback support for this slot exists, but\nwill be removed eventually. A universal function that relied on this will have\nto be ported eventually. See ref:`NEP 41` and ref:`NEP 43`\n\nFor a possible future loop selector with a different signature.\n\nOverride the default operand flags for each ufunc operand.\n\nOverride the default nditer flags for the ufunc.\n\nAdded in API version 0x0000000D\n\nFor each distinct core dimension, the possible frozen size if\n`UFUNC_CORE_DIM_SIZE_INFERRED` is `0`\n\nFor each distinct core dimension, a set of `UFUNC_CORE_DIM*` flags\n\n"}, {"name": "type PyUFuncReduceObject", "path": "reference/c-api/types-and-structures#c.PyUFuncReduceObject", "type": "Python Types and C-Structures", "text": "\nA loose wrapper for the C-structure that contains the information needed for\nreduce-like methods of ufuncs. This is useful if you are trying to understand\nthe reduce, accumulate, and reduce-at code. The `PyUFuncReduceObject` is the\nassociated C-structure. It is defined in the `ufuncobject.h` header.\n\n"}, {"name": "ufunc.__call__()", "path": "reference/generated/numpy.ufunc.__call__", "type": "numpy.ufunc.__call__", "text": "\nmethod\n\nCall self as a function.\n\n"}, {"name": "ufunc.accumulate()", "path": "reference/generated/numpy.ufunc.accumulate", "type": "numpy.ufunc.accumulate", "text": "\nmethod\n\nAccumulate the result of applying the operator to all elements.\n\nFor a one-dimensional array, accumulate produces results equivalent to:\n\nFor example, add.accumulate() is equivalent to np.cumsum().\n\nFor a multi-dimensional array, accumulate is applied along only one axis (axis\nzero by default; see Examples below) so repeated use is necessary if one wants\nto accumulate over multiple axes.\n\nThe array to act on.\n\nThe axis along which to apply the accumulation; default is zero.\n\nThe data-type used to represent the intermediate results. Defaults to the\ndata-type of the output array if such is provided, or the the data-type of the\ninput array if no output array is provided.\n\nA location into which the result is stored. If not provided or None, a\nfreshly-allocated array is returned. For consistency with `ufunc.__call__`, if\ngiven as a keyword, this may be wrapped in a 1-element tuple.\n\nChanged in version 1.13.0: Tuples are allowed for keyword argument.\n\nThe accumulated values. If `out` was supplied, `r` is a reference to `out`.\n\n1-D array examples:\n\n2-D array examples:\n\nAccumulate along axis 0 (rows), down columns:\n\nAccumulate along axis 1 (columns), through rows:\n\n"}, {"name": "ufunc.at()", "path": "reference/generated/numpy.ufunc.at", "type": "numpy.ufunc.at", "text": "\nmethod\n\nPerforms unbuffered in place operation on operand \u2018a\u2019 for elements specified\nby \u2018indices\u2019. For addition ufunc, this method is equivalent to `a[indices] +=\nb`, except that results are accumulated for elements that are indexed more\nthan once. For example, `a[[0,0]] += 1` will only increment the first element\nonce because of buffering, whereas `add.at(a, [0,0], 1)` will increment the\nfirst element twice.\n\nNew in version 1.8.0.\n\nThe array to perform in place operation on.\n\nArray like index object or slice object for indexing into first operand. If\nfirst operand has multiple dimensions, indices can be a tuple of array like\nindex objects or slice objects.\n\nSecond operand for ufuncs requiring two operands. Operand must be\nbroadcastable over first operand after indexing or slicing.\n\nSet items 0 and 1 to their negative values:\n\nIncrement items 0 and 1, and increment item 2 twice:\n\nAdd items 0 and 1 in first array to second array, and store results in first\narray:\n\n"}, {"name": "ufunc.identity", "path": "reference/generated/numpy.ufunc.identity", "type": "numpy.ufunc.identity", "text": "\nattribute\n\nThe identity value.\n\nData attribute containing the identity element for the ufunc, if it has one.\nIf it does not, the attribute value is None.\n\n"}, {"name": "ufunc.nargs", "path": "reference/generated/numpy.ufunc.nargs", "type": "numpy.ufunc.nargs", "text": "\nattribute\n\nThe number of arguments.\n\nData attribute containing the number of arguments the ufunc takes, including\noptional ones.\n\nTypically this value will be one more than what you might expect because all\nufuncs take the optional \u201cout\u201d argument.\n\n"}, {"name": "ufunc.nin", "path": "reference/generated/numpy.ufunc.nin", "type": "numpy.ufunc.nin", "text": "\nattribute\n\nThe number of inputs.\n\nData attribute containing the number of arguments the ufunc treats as input.\n\n"}, {"name": "ufunc.nout", "path": "reference/generated/numpy.ufunc.nout", "type": "numpy.ufunc.nout", "text": "\nattribute\n\nThe number of outputs.\n\nData attribute containing the number of arguments the ufunc treats as output.\n\nSince all ufuncs can take output arguments, this will always be (at least) 1.\n\n"}, {"name": "ufunc.ntypes", "path": "reference/generated/numpy.ufunc.ntypes", "type": "numpy.ufunc.ntypes", "text": "\nattribute\n\nThe number of types.\n\nThe number of numerical NumPy types - of which there are 18 total - on which\nthe ufunc can operate.\n\nSee also\n\n"}, {"name": "ufunc.outer()", "path": "reference/generated/numpy.ufunc.outer", "type": "numpy.ufunc.outer", "text": "\nmethod\n\nApply the ufunc `op` to all pairs (a, b) with a in `A` and b in `B`.\n\nLet `M = A.ndim`, `N = B.ndim`. Then the result, `C`, of `op.outer(A, B)` is\nan array of dimension M + N such that:\n\nFor `A` and `B` one-dimensional, this is equivalent to:\n\nFirst array\n\nSecond array\n\nArguments to pass on to the ufunc. Typically `dtype` or `out`. See `ufunc` for\na comprehensive overview of all available arguments.\n\nOutput array\n\nSee also\n\nA less powerful version of `np.multiply.outer` that `ravel`s all inputs to 1D.\nThis exists primarily for compatibility with old code.\n\n`np.tensordot(a, b, axes=((), ()))` and `np.multiply.outer(a, b)` behave same\nfor all dimensions of a and b.\n\nA multi-dimensional example:\n\n"}, {"name": "ufunc.reduce()", "path": "reference/generated/numpy.ufunc.reduce", "type": "numpy.ufunc.reduce", "text": "\nmethod\n\nReduces `array`\u2019s dimension by one, by applying ufunc along one axis.\n\nLet \\\\(array.shape = (N_0, ..., N_i, ..., N_{M-1})\\\\). Then\n\\\\(ufunc.reduce(array, axis=i)[k_0, ..,k_{i-1}, k_{i+1}, .., k_{M-1}]\\\\) = the\nresult of iterating `j` over \\\\(range(N_i)\\\\), cumulatively applying ufunc to\neach \\\\(array[k_0, ..,k_{i-1}, j, k_{i+1}, .., k_{M-1}]\\\\). For a one-\ndimensional array, reduce produces results equivalent to:\n\nFor example, add.reduce() is equivalent to sum().\n\nThe array to act on.\n\nAxis or axes along which a reduction is performed. The default (`axis` = 0) is\nperform a reduction over the first dimension of the input array. `axis` may be\nnegative, in which case it counts from the last to the first axis.\n\nNew in version 1.7.0.\n\nIf this is None, a reduction is performed over all the axes. If this is a\ntuple of ints, a reduction is performed on multiple axes, instead of a single\naxis or all the axes as before.\n\nFor operations which are either not commutative or not associative, doing a\nreduction over multiple axes is not well-defined. The ufuncs do not currently\nraise an exception in this case, but will likely do so in the future.\n\nThe type used to represent the intermediate results. Defaults to the data-type\nof the output array if this is provided, or the data-type of the input array\nif no output array is provided.\n\nA location into which the result is stored. If not provided or None, a\nfreshly-allocated array is returned. For consistency with `ufunc.__call__`, if\ngiven as a keyword, this may be wrapped in a 1-element tuple.\n\nChanged in version 1.13.0: Tuples are allowed for keyword argument.\n\nIf this is set to True, the axes which are reduced are left in the result as\ndimensions with size one. With this option, the result will broadcast\ncorrectly against the original `array`.\n\nNew in version 1.7.0.\n\nThe value with which to start the reduction. If the ufunc has no identity or\nthe dtype is object, this defaults to None - otherwise it defaults to\nufunc.identity. If `None` is given, the first element of the reduction is\nused, and an error is thrown if the reduction is empty.\n\nNew in version 1.15.0.\n\nA boolean array which is broadcasted to match the dimensions of `array`, and\nselects elements to include in the reduction. Note that for ufuncs like\n`minimum` that do not have an identity defined, one has to pass in also\n`initial`.\n\nNew in version 1.17.0.\n\nThe reduced array. If `out` was supplied, `r` is a reference to it.\n\nA multi-dimensional array example:\n\nYou can use the `initial` keyword argument to initialize the reduction with a\ndifferent value, and `where` to select specific elements to include:\n\nAllows reductions of empty arrays where they would normally fail, i.e. for\nufuncs without an identity.\n\n"}, {"name": "ufunc.reduceat()", "path": "reference/generated/numpy.ufunc.reduceat", "type": "numpy.ufunc.reduceat", "text": "\nmethod\n\nPerforms a (local) reduce with specified slices over a single axis.\n\nFor i in `range(len(indices))`, `reduceat` computes\n`ufunc.reduce(array[indices[i]:indices[i+1]])`, which becomes the i-th\ngeneralized \u201crow\u201d parallel to `axis` in the final result (i.e., in a 2-D\narray, for example, if `axis = 0`, it becomes the i-th row, but if `axis = 1`,\nit becomes the i-th column). There are three exceptions to this:\n\nThe shape of the output depends on the size of `indices`, and may be larger\nthan `array` (this happens if `len(indices) > array.shape[axis]`).\n\nThe array to act on.\n\nPaired indices, comma separated (not colon), specifying slices to reduce.\n\nThe axis along which to apply the reduceat.\n\nThe type used to represent the intermediate results. Defaults to the data type\nof the output array if this is provided, or the data type of the input array\nif no output array is provided.\n\nA location into which the result is stored. If not provided or None, a\nfreshly-allocated array is returned. For consistency with `ufunc.__call__`, if\ngiven as a keyword, this may be wrapped in a 1-element tuple.\n\nChanged in version 1.13.0: Tuples are allowed for keyword argument.\n\nThe reduced values. If `out` was supplied, `r` is a reference to `out`.\n\nA descriptive example:\n\nIf `array` is 1-D, the function `ufunc.accumulate(array)` is the same as\n`ufunc.reduceat(array, indices)[::2]` where `indices` is `range(len(array) -\n1)` with a zero placed in every other element: `indices = zeros(2 * len(array)\n- 1)`, `indices[1::2] = range(1, len(array))`.\n\nDon\u2019t be fooled by this attribute\u2019s name: `reduceat(array)` is not necessarily\nsmaller than `array`.\n\nTo take the running sum of four successive values:\n\nA 2-D example:\n\n"}, {"name": "ufunc.signature", "path": "reference/generated/numpy.ufunc.signature", "type": "numpy.ufunc.signature", "text": "\nattribute\n\nDefinition of the core elements a generalized ufunc operates on.\n\nThe signature determines how the dimensions of each input/output array are\nsplit into core and loop dimensions:\n\nGeneralized ufuncs are used internally in many linalg functions, and in the\ntesting suite; the examples below are taken from these. For ufuncs that\noperate on scalars, the signature is None, which is equivalent to \u2018()\u2019 for\nevery argument.\n\n"}, {"name": "ufunc.types", "path": "reference/generated/numpy.ufunc.types", "type": "numpy.ufunc.types", "text": "\nattribute\n\nReturns a list with types grouped input->output.\n\nData attribute listing the data-type \u201cDomain-Range\u201d groupings the ufunc can\ndeliver. The data-types are given using the character codes.\n\nSee also\n\n"}, {"name": "UFUNC_CORE_DIM_CAN_IGNORE", "path": "reference/c-api/types-and-structures#c.UFUNC_CORE_DIM_CAN_IGNORE", "type": "Python Types and C-Structures", "text": "\nif the dim name ends in `?`\n\n"}, {"name": "UFUNC_CORE_DIM_SIZE_INFERRED", "path": "reference/c-api/types-and-structures#c.UFUNC_CORE_DIM_SIZE_INFERRED", "type": "Python Types and C-Structures", "text": "\nif the dim size will be determined from the operands and not from a frozen\nsignature\n\nIdentity for reduction, when `PyUFuncObject.identity` is equal to\n`PyUFunc_IdentityValue`.\n\n"}, {"name": "UFUNC_ERR_CALL", "path": "reference/c-api/ufunc#c.UFUNC_ERR_CALL", "type": "UFunc API", "text": "\n\n"}, {"name": "UFUNC_ERR_RAISE", "path": "reference/c-api/ufunc#c.UFUNC_ERR_RAISE", "type": "UFunc API", "text": "\n\n"}, {"name": "UFUNC_ERR_WARN", "path": "reference/c-api/ufunc#c.UFUNC_ERR_WARN", "type": "UFunc API", "text": "\n\n"}, {"name": "UFUNC_ERR_{HANDLER}", "path": "reference/c-api/ufunc", "type": "UFunc API", "text": "\nUsed in universal function code to only release the Python GIL if loop->obj is\nnot true (i.e. this is not an OBJECT array loop). Requires use of\n`NPY_BEGIN_THREADS_DEF` in variable declaration area.\n\nUsed in universal function code to re-acquire the Python GIL if it was\nreleased (because loop->obj was not true).\n\npointers to functions that actually implement the underlying (element-by-\nelement) function \\\\(N\\\\) times with the following signature:\n\nargs\n\nAn array of pointers to the actual data for the input and output arrays. The\ninput arguments are given first followed by the output arguments.\n\ndimensions\n\nA pointer to the size of the dimension over which this function is looping.\n\nsteps\n\nA pointer to the number of bytes to jump to get to the next element in this\ndimension for each of the input and output arguments.\n\ndata\n\nArbitrary data (extra arguments, function names, etc. ) that can be stored\nwith the ufunc and will be passed in when it is called.\n\nThis is an example of a func specialized for addition of doubles returning\ndoubles.\n\nCreate a new broadcasting universal function from required variables. Each\nufunc builds around the notion of an element-by-element operation. Each ufunc\nobject contains pointers to 1-d loops implementing the basic functionality for\neach supported type.\n\nNote\n\nThe func, data, types, name, and doc arguments are not copied by\n`PyUFunc_FromFuncAndData`. The caller must ensure that the memory used by\nthese arrays is not freed as long as the ufunc object is alive.\n\ntypes \u2013\n\nLength `(nin + nout) * ntypes` array of `char` encoding the `numpy.dtype.num`\n(built-in only) that the corresponding function in the `func` array accepts.\nFor instance, for a comparison ufunc with three `ntypes`, two `nin` and one\n`nout`, where the first function accepts `numpy.int32` and the the second\n`numpy.int64`, with both returning `numpy.bool_`, `types` would be `(char[])\n{5, 5, 0, 7, 7, 0}` since `NPY_INT32` is 5, `NPY_INT64` is 7, and `NPY_BOOL`\nis 0.\n\nThe bit-width names can also be used (e.g. `NPY_INT32`, `NPY_COMPLEX128` ) if\ndesired.\n\nType casting rules will be used at runtime to find the first `func` callable\nby the input/output provided.\n\nThis function is very similar to PyUFunc_FromFuncAndData above, but has an\nextra signature argument, to define a generalized universal functions.\nSimilarly to how ufuncs are built around an element-by-element operation,\ngufuncs are around subarray-by-subarray operations, the signature defining the\nsubarrays to operate on.\n\nThis function is very similar to `PyUFunc_FromFuncAndDataAndSignature` above,\nbut has an extra identity_value argument, to define an arbitrary identity for\nthe ufunc when `identity` is passed as `PyUFunc_IdentityValue`.\n\nThis function allows the user to register a 1-d loop with an already- created\nufunc to be used whenever the ufunc is called with any of its input arguments\nas the user-defined data-type. This is needed in order to make ufuncs work\nwith built-in data-types. The data-type must have been previously registered\nwith the numpy system. The loop is passed in as function. This loop can take\narbitrary data which should be passed in as data. The data-types the loop\nrequires are passed in as arg_types which must be a pointer to memory at least\nas large as ufunc->nargs.\n\nThis function behaves like PyUFunc_RegisterLoopForType above, except that it\nallows the user to register a 1-d loop using PyArray_Descr objects instead of\ndtype type num values. This allows a 1-d loop to be registered for structured\narray data-dtypes and custom data-types instead of scalar data-types.\n\nReplace a 1-d loop matching the given signature in the already-created ufunc\nwith the new 1-d loop newfunc. Return the old 1-d loop function in oldfunc.\nReturn 0 on success and -1 on failure. This function works only with built-in\ntypes (use `PyUFunc_RegisterLoopForType` for user-defined types). A signature\nis an array of data-type numbers indicating the inputs followed by the outputs\nassumed by the 1-d loop.\n\nA simple interface to the IEEE error-flag checking support. The errmask\nargument is a mask of `UFUNC_MASK_{ERR}` bitmasks indicating which errors to\ncheck for (and how to check for them). The errobj must be a Python tuple with\ntwo elements: a string containing the name which will be used in any\ncommunication of error and either a callable Python object (call-back\nfunction) or `Py_None`. The callable object will only be used if\n`UFUNC_ERR_CALL` is set as the desired error checking method. This routine\nmanages the GIL and is safe to call even after releasing the GIL. If an error\nin the IEEE-compatible hardware is determined a -1 is returned, otherwise a 0\nis returned.\n\nClear the IEEE error flags.\n\nGet the Python values used for ufunc processing from the thread-local storage\narea unless the defaults have been set in which case the name lookup is\nbypassed. The name is placed as a string in the first element of *errobj. The\nsecond element is the looked-up function to call on error callback. The value\nof the looked-up buffer-size to use is passed into bufsize, and the value of\nthe error mask is placed into errmask.\n\nAt the core of every ufunc is a collection of type-specific functions that\ndefines the basic functionality for each of the supported types. These\nfunctions must evaluate the underlying function \\\\(N\\geq1\\\\) times. Extra-data\nmay be passed in that may be used during the calculation. This feature allows\nsome general functions to be used as these basic looping functions. The\ngeneral function has all the code needed to point variables to the right place\nand set up a function call. The general function assumes that the actual\nfunction to call is passed in as the extra data and calls it with the correct\nvalues. All of these functions are suitable for placing directly in the array\nof functions stored in the functions member of the PyUFuncObject structure.\n\nType specific, core 1-d functions for ufuncs where each calculation is\nobtained by calling a function taking one input argument and returning one\noutput. This function is passed in `func`. The letters correspond to\ndtypechar\u2019s of the supported data types ( `e` \\- half, `f` \\- float, `d` \\-\ndouble, `g` \\- long double, `F` \\- cfloat, `D` \\- cdouble, `G` \\-\nclongdouble). The argument func must support the same signature. The _As_X_X\nvariants assume ndarray\u2019s of one data type but cast the values to use an\nunderlying function that takes a different data type. Thus,\n`PyUFunc_f_f_As_d_d` uses ndarrays of data type `NPY_FLOAT` but calls out to a\nC-function that takes double and returns double.\n\nType specific, core 1-d functions for ufuncs where each calculation is\nobtained by calling a function taking two input arguments and returning one\noutput. The underlying function to call is passed in as func. The letters\ncorrespond to dtypechar\u2019s of the specific data type supported by the general-\npurpose function. The argument `func` must support the corresponding\nsignature. The `_As_XX_X` variants assume ndarrays of one data type but cast\nthe values at each iteration of the loop to use the underlying function that\ntakes a different data type.\n\nOne-input, one-output, and two-input, one-output core 1-d functions for the\n`NPY_OBJECT` data type. These functions handle reference count issues and\nreturn early on error. The actual function to call is func and it must accept\ncalls with the signature `(PyObject*) (PyObject*)` for `PyUFunc_O_O` or\n`(PyObject*)(PyObject *, PyObject *)` for `PyUFunc_OO_O`.\n\nThis general purpose 1-d core function assumes that func is a string\nrepresenting a method of the input object. For each iteration of the loop, the\nPython object is extracted from the array and its func method is called\nreturning the result to the output array.\n\nThis general purpose 1-d core function assumes that func is a string\nrepresenting a method of the input object that takes one argument. The first\nargument in args is the method whose function is called, the second argument\nin args is the argument passed to the function. The output of the function is\nstored in the third entry of args.\n\nThis is the 1-d core function used by the dynamic ufuncs created by\numath.frompyfunc(function, nin, nout). In this case func is a pointer to a\n`PyUFunc_PyFuncData` structure which has definition\n\nAt each iteration of the loop, the nin input objects are extracted from their\nobject arrays and placed into an argument tuple, the Python callable is called\nwith the input arguments, and the nout outputs are placed into their object\narrays.\n\nThese are the constants and functions for accessing the ufunc C-API from\nextension modules in precisely the same way as the array C-API can be\naccessed. The `import_ufunc` () function must always be called (in the\ninitialization subroutine of the extension module). If your extension module\nis in one file then that is all that is required. The other two constants are\nuseful if your extension module makes use of multiple files. In that case,\ndefine `PY_UFUNC_UNIQUE_SYMBOL` to something unique to your code and then in\nsource files that do not contain the module initialization function but still\nneed access to the UFUNC API, define `PY_UFUNC_UNIQUE_SYMBOL` to the same name\nused previously and also define `NO_IMPORT_UFUNC`.\n\nThe C-API is actually an array of function pointers. This array is created\n(and pointed to by a global variable) by import_ufunc. The global variable is\neither statically defined or allowed to be seen by other files depending on\nthe state of `PY_UFUNC_UNIQUE_SYMBOL` and `NO_IMPORT_UFUNC`.\n\n"}, {"name": "UFUNC_FPE_DIVIDEBYZERO", "path": "reference/c-api/ufunc#c.UFUNC_FPE_DIVIDEBYZERO", "type": "UFunc API", "text": "\n\n"}, {"name": "UFUNC_FPE_INVALID", "path": "reference/c-api/ufunc#c.UFUNC_FPE_INVALID", "type": "UFunc API", "text": "\n\n"}, {"name": "UFUNC_FPE_OVERFLOW", "path": "reference/c-api/ufunc#c.UFUNC_FPE_OVERFLOW", "type": "UFunc API", "text": "\n\n"}, {"name": "UFUNC_FPE_UNDERFLOW", "path": "reference/c-api/ufunc#c.UFUNC_FPE_UNDERFLOW", "type": "UFunc API", "text": "\n\n"}, {"name": "UFUNC_MASK_INVALID", "path": "reference/c-api/ufunc#c.UFUNC_MASK_INVALID", "type": "UFunc API", "text": "\n\n"}, {"name": "UFUNC_MASK_OVERFLOW", "path": "reference/c-api/ufunc#c.UFUNC_MASK_OVERFLOW", "type": "UFunc API", "text": "\n\n"}, {"name": "UFUNC_MASK_UNDERFLOW", "path": "reference/c-api/ufunc#c.UFUNC_MASK_UNDERFLOW", "type": "UFunc API", "text": "\n\n"}, {"name": "UFUNC_SHIFT_DIVIDEBYZERO", "path": "reference/c-api/ufunc#c.UFUNC_SHIFT_DIVIDEBYZERO", "type": "UFunc API", "text": "\n\n"}, {"name": "UFUNC_SHIFT_INVALID", "path": "reference/c-api/ufunc#c.UFUNC_SHIFT_INVALID", "type": "UFunc API", "text": "\n\n"}, {"name": "UFUNC_SHIFT_OVERFLOW", "path": "reference/c-api/ufunc#c.UFUNC_SHIFT_OVERFLOW", "type": "UFunc API", "text": "\n\n"}, {"name": "UFUNC_SHIFT_UNDERFLOW", "path": "reference/c-api/ufunc#c.UFUNC_SHIFT_UNDERFLOW", "type": "UFunc API", "text": "\n\n"}, {"name": "Under-the-hood Documentation for developers", "path": "dev/underthehood", "type": "Development", "text": "\nThese documents are intended as a low-level look into NumPy; focused towards\ndevelopers.\n\n"}, {"name": "Universal functions (ufunc)", "path": "reference/ufuncs", "type": "Universal functions ( \n    \n     ufunc\n    \n    )", "text": "\nSee also\n\nUniversal functions (ufunc) basics\n\nA universal function (or ufunc for short) is a function that operates on\n`ndarrays` in an element-by-element fashion, supporting array broadcasting,\ntype casting, and several other standard features. That is, a ufunc is a\n\u201cvectorized\u201d wrapper for a function that takes a fixed number of specific\ninputs and produces a fixed number of specific outputs. For detailed\ninformation on universal functions, see Universal functions (ufunc) basics.\n\n`numpy.ufunc`()\n\nFunctions that operate element by element on whole arrays.\n\nAll ufuncs take optional keyword arguments. Most of these represent advanced\nusage and will not typically be used.\n\nNew in version 1.6.\n\nThe first output can be provided as either a positional or a keyword\nparameter. Keyword \u2018out\u2019 arguments are incompatible with positional ones.\n\nNew in version 1.10.\n\nThe \u2018out\u2019 keyword argument is expected to be a tuple with one entry per output\n(which can be None for arrays to be allocated by the ufunc). For ufuncs with a\nsingle output, passing a single array (instead of a tuple holding a single\narray) is also valid.\n\nPassing a single array in the \u2018out\u2019 keyword argument to a ufunc with multiple\noutputs is deprecated, and will raise a warning in numpy 1.10, and an error in\na future release.\n\nIf \u2018out\u2019 is None (the default), a uninitialized return array is created. The\noutput array is then filled with the results of the ufunc in the places that\nthe broadcast \u2018where\u2019 is True. If \u2018where\u2019 is the scalar True (the default),\nthen this corresponds to the entire output being filled. Note that outputs not\nexplicitly filled are left with their uninitialized values.\n\nNew in version 1.13.\n\nOperations where ufunc input and output operands have memory overlap are\ndefined to be the same as for equivalent operations where there is no memory\noverlap. Operations affected make temporary copies as needed to eliminate data\ndependency. As detecting these cases is computationally expensive, a heuristic\nis used, which may in rare cases result in needless temporary copies. For\noperations where the data dependency is simple enough for the heuristic to\nanalyze, temporary copies will not be made even if the arrays overlap, if it\ncan be deduced copies are not necessary. As an example, `np.add(a, b, out=a)`\nwill not involve copies.\n\nNew in version 1.7.\n\nAccepts a boolean array which is broadcast together with the operands. Values\nof True indicate to calculate the ufunc at that position, values of False\nindicate to leave the value in the output alone. This argument cannot be used\nfor generalized ufuncs as those take non-scalar input.\n\nNote that if an uninitialized return array is created, values of False will\nleave those values uninitialized.\n\nNew in version 1.15.\n\nA list of tuples with indices of axes a generalized ufunc should operate on.\nFor instance, for a signature of `(i,j),(j,k)->(i,k)` appropriate for matrix\nmultiplication, the base elements are two-dimensional matrices and these are\ntaken to be stored in the two last axes of each argument. The corresponding\naxes keyword would be `[(-2, -1), (-2, -1), (-2, -1)]`. For simplicity, for\ngeneralized ufuncs that operate on 1-dimensional arrays (vectors), a single\ninteger is accepted instead of a single-element tuple, and for generalized\nufuncs for which all outputs are scalars, the output tuples can be omitted.\n\nNew in version 1.15.\n\nA single axis over which a generalized ufunc should operate. This is a short-\ncut for ufuncs that operate over a single, shared core dimension, equivalent\nto passing in `axes` with entries of `(axis,)` for each single-core-dimension\nargument and `()` for all others. For instance, for a signature `(i),(i)->()`,\nit is equivalent to passing in `axes=[(axis,), (axis,), ()]`.\n\nNew in version 1.15.\n\nIf this is set to `True`, axes which are reduced over will be left in the\nresult as a dimension with size one, so that the result will broadcast\ncorrectly against the inputs. This option can only be used for generalized\nufuncs that operate on inputs that all have the same number of core dimensions\nand with outputs that have no core dimensions, i.e., with signatures like\n`(i),(i)->()` or `(m,m)->()`. If used, the location of the dimensions in the\noutput can be controlled with `axes` and `axis`.\n\nNew in version 1.6.\n\nMay be \u2018no\u2019, \u2018equiv\u2019, \u2018safe\u2019, \u2018same_kind\u2019, or \u2018unsafe\u2019. See `can_cast` for\nexplanations of the parameter values.\n\nProvides a policy for what kind of casting is permitted. For compatibility\nwith previous versions of NumPy, this defaults to \u2018unsafe\u2019 for numpy < 1.7. In\nnumpy 1.7 a transition to \u2018same_kind\u2019 was begun where ufuncs produce a\nDeprecationWarning for calls which are allowed under the \u2018unsafe\u2019 rules, but\nnot under the \u2018same_kind\u2019 rules. From numpy 1.10 and onwards, the default is\n\u2018same_kind\u2019.\n\nNew in version 1.6.\n\nSpecifies the calculation iteration order/memory layout of the output array.\nDefaults to \u2018K\u2019. \u2018C\u2019 means the output should be C-contiguous, \u2018F\u2019 means\nF-contiguous, \u2018A\u2019 means F-contiguous if the inputs are F-contiguous and not\nalso not C-contiguous, C-contiguous otherwise, and \u2018K\u2019 means to match the\nelement ordering of the inputs as closely as possible.\n\nNew in version 1.6.\n\nOverrides the DType of the output arrays the same way as the signature. This\nshould ensure a matching precision of the calculation. The exact calculation\nDTypes chosen may depend on the ufunc and the inputs may be cast to this DType\nto perform the calculation.\n\nNew in version 1.6.\n\nDefaults to true. If set to false, the output will always be a strict array,\nnot a subtype.\n\nEither a Dtype, a tuple of DTypes, or a special signature string indicating\nthe input and output types of a ufunc.\n\nThis argument allows the user to specify exact DTypes to be used for the\ncalculation. Casting will be used as necessary. The actual DType of the input\narrays is not considered unless `signature` is `None` for that array.\n\nWhen all DTypes are fixed, a specific loop is chosen or an error raised if no\nmatching loop exists. If some DTypes are not specified and left `None`, the\nbehaviour may depend on the ufunc. At this time, a list of available\nsignatures is provided by the types attribute of the ufunc. (This list may be\nmissing DTypes not defined by NumPy.)\n\nThe `signature` only specifies the DType class/type. For example, it can\nspecify that the operation should be `datetime64` or `float64` operation. It\ndoes not specify the `datetime64` time-unit or the `float64` byte-order.\n\nFor backwards compatibility this argument can also be provided as sig,\nalthough the long form is preferred. Note that this should not be confused\nwith the generalized ufunc signature that is stored in the signature attribute\nof the of the ufunc object.\n\nA list of length 3 specifying the ufunc buffer-size, the error mode integer,\nand the error call-back function. Normally, these values are looked up in a\nthread-specific dictionary. Passing them here circumvents that look up and\nuses the low-level specification provided for the error mode. This may be\nuseful, for example, as an optimization for calculations requiring many ufunc\ncalls on small arrays in a loop.\n\nThere are some informational attributes that universal functions possess. None\nof the attributes can be set.\n\n__doc__\n\nA docstring for each ufunc. The first part of the docstring is dynamically\ngenerated from the number of outputs, the name, and the number of inputs. The\nsecond part of the docstring is provided at creation time and stored with the\nufunc.\n\n__name__\n\nThe name of the ufunc.\n\n`ufunc.nin`\n\nThe number of inputs.\n\n`ufunc.nout`\n\nThe number of outputs.\n\n`ufunc.nargs`\n\nThe number of arguments.\n\n`ufunc.ntypes`\n\nThe number of types.\n\n`ufunc.types`\n\nReturns a list with types grouped input->output.\n\n`ufunc.identity`\n\nThe identity value.\n\n`ufunc.signature`\n\nDefinition of the core elements a generalized ufunc operates on.\n\n`ufunc.reduce`(array[, axis, dtype, out, ...])\n\nReduces `array`'s dimension by one, by applying ufunc along one axis.\n\n`ufunc.accumulate`(array[, axis, dtype, out])\n\nAccumulate the result of applying the operator to all elements.\n\n`ufunc.reduceat`(array, indices[, axis, ...])\n\nPerforms a (local) reduce with specified slices over a single axis.\n\n`ufunc.outer`(A, B, /, **kwargs)\n\nApply the ufunc `op` to all pairs (a, b) with a in `A` and b in `B`.\n\n`ufunc.at`(a, indices[, b])\n\nPerforms unbuffered in place operation on operand 'a' for elements specified\nby 'indices'.\n\nWarning\n\nA reduce-like operation on an array with a data-type that has a range \u201ctoo\nsmall\u201d to handle the result will silently wrap. One should use `dtype` to\nincrease the size of the data-type over which reduction takes place.\n\nThere are currently more than 60 universal functions defined in `numpy` on one\nor more types, covering a wide variety of operations. Some of these ufuncs are\ncalled automatically on arrays when the relevant infix notation is used (e.g.,\n`add(a, b)` is called internally when `a + b` is written and a or b is an\n`ndarray`). Nevertheless, you may still want to use the ufunc call in order to\nuse the optional output argument(s) to place the output(s) in an object (or\nobjects) of your choice.\n\nRecall that each ufunc operates element-by-element. Therefore, each scalar\nufunc will be described as if acting on a set of scalar inputs to return a set\nof scalar outputs.\n\nNote\n\nThe ufunc still returns its output(s) even if you use the optional output\nargument(s).\n\n`add`(x1, x2, /[, out, where, casting, order, ...])\n\nAdd arguments element-wise.\n\n`subtract`(x1, x2, /[, out, where, casting, ...])\n\nSubtract arguments, element-wise.\n\n`multiply`(x1, x2, /[, out, where, casting, ...])\n\nMultiply arguments element-wise.\n\n`matmul`(x1, x2, /[, out, casting, order, ...])\n\nMatrix product of two arrays.\n\n`divide`(x1, x2, /[, out, where, casting, ...])\n\nReturns a true division of the inputs, element-wise.\n\n`logaddexp`(x1, x2, /[, out, where, casting, ...])\n\nLogarithm of the sum of exponentiations of the inputs.\n\n`logaddexp2`(x1, x2, /[, out, where, casting, ...])\n\nLogarithm of the sum of exponentiations of the inputs in base-2.\n\n`true_divide`(x1, x2, /[, out, where, ...])\n\nReturns a true division of the inputs, element-wise.\n\n`floor_divide`(x1, x2, /[, out, where, ...])\n\nReturn the largest integer smaller or equal to the division of the inputs.\n\n`negative`(x, /[, out, where, casting, order, ...])\n\nNumerical negative, element-wise.\n\n`positive`(x, /[, out, where, casting, order, ...])\n\nNumerical positive, element-wise.\n\n`power`(x1, x2, /[, out, where, casting, ...])\n\nFirst array elements raised to powers from second array, element-wise.\n\n`float_power`(x1, x2, /[, out, where, ...])\n\nFirst array elements raised to powers from second array, element-wise.\n\n`remainder`(x1, x2, /[, out, where, casting, ...])\n\nReturns the element-wise remainder of division.\n\n`mod`(x1, x2, /[, out, where, casting, order, ...])\n\nReturns the element-wise remainder of division.\n\n`fmod`(x1, x2, /[, out, where, casting, ...])\n\nReturns the element-wise remainder of division.\n\n`divmod`(x1, x2[, out1, out2], / [[, out, ...])\n\nReturn element-wise quotient and remainder simultaneously.\n\n`absolute`(x, /[, out, where, casting, order, ...])\n\nCalculate the absolute value element-wise.\n\n`fabs`(x, /[, out, where, casting, order, ...])\n\nCompute the absolute values element-wise.\n\n`rint`(x, /[, out, where, casting, order, ...])\n\nRound elements of the array to the nearest integer.\n\n`sign`(x, /[, out, where, casting, order, ...])\n\nReturns an element-wise indication of the sign of a number.\n\n`heaviside`(x1, x2, /[, out, where, casting, ...])\n\nCompute the Heaviside step function.\n\n`conj`(x, /[, out, where, casting, order, ...])\n\nReturn the complex conjugate, element-wise.\n\n`conjugate`(x, /[, out, where, casting, ...])\n\nReturn the complex conjugate, element-wise.\n\n`exp`(x, /[, out, where, casting, order, ...])\n\nCalculate the exponential of all elements in the input array.\n\n`exp2`(x, /[, out, where, casting, order, ...])\n\nCalculate `2**p` for all `p` in the input array.\n\n`log`(x, /[, out, where, casting, order, ...])\n\nNatural logarithm, element-wise.\n\n`log2`(x, /[, out, where, casting, order, ...])\n\nBase-2 logarithm of `x`.\n\n`log10`(x, /[, out, where, casting, order, ...])\n\nReturn the base 10 logarithm of the input array, element-wise.\n\n`expm1`(x, /[, out, where, casting, order, ...])\n\nCalculate `exp(x) - 1` for all elements in the array.\n\n`log1p`(x, /[, out, where, casting, order, ...])\n\nReturn the natural logarithm of one plus the input array, element-wise.\n\n`sqrt`(x, /[, out, where, casting, order, ...])\n\nReturn the non-negative square-root of an array, element-wise.\n\n`square`(x, /[, out, where, casting, order, ...])\n\nReturn the element-wise square of the input.\n\n`cbrt`(x, /[, out, where, casting, order, ...])\n\nReturn the cube-root of an array, element-wise.\n\n`reciprocal`(x, /[, out, where, casting, ...])\n\nReturn the reciprocal of the argument, element-wise.\n\n`gcd`(x1, x2, /[, out, where, casting, order, ...])\n\nReturns the greatest common divisor of `|x1|` and `|x2|`\n\n`lcm`(x1, x2, /[, out, where, casting, order, ...])\n\nReturns the lowest common multiple of `|x1|` and `|x2|`\n\nTip\n\nThe optional output arguments can be used to help you save memory for large\ncalculations. If your arrays are large, complicated expressions can take\nlonger than absolutely necessary due to the creation and (later) destruction\nof temporary calculation spaces. For example, the expression `G = A * B + C`\nis equivalent to `T1 = A * B; G = T1 + C; del T1`. It will be more quickly\nexecuted as `G = A * B; add(G, C, G)` which is the same as `G = A * B; G +=\nC`.\n\nAll trigonometric functions use radians when an angle is called for. The ratio\nof degrees to radians is \\\\(180^{\\circ}/\\pi.\\\\)\n\n`sin`(x, /[, out, where, casting, order, ...])\n\nTrigonometric sine, element-wise.\n\n`cos`(x, /[, out, where, casting, order, ...])\n\nCosine element-wise.\n\n`tan`(x, /[, out, where, casting, order, ...])\n\nCompute tangent element-wise.\n\n`arcsin`(x, /[, out, where, casting, order, ...])\n\nInverse sine, element-wise.\n\n`arccos`(x, /[, out, where, casting, order, ...])\n\nTrigonometric inverse cosine, element-wise.\n\n`arctan`(x, /[, out, where, casting, order, ...])\n\nTrigonometric inverse tangent, element-wise.\n\n`arctan2`(x1, x2, /[, out, where, casting, ...])\n\nElement-wise arc tangent of `x1/x2` choosing the quadrant correctly.\n\n`hypot`(x1, x2, /[, out, where, casting, ...])\n\nGiven the \"legs\" of a right triangle, return its hypotenuse.\n\n`sinh`(x, /[, out, where, casting, order, ...])\n\nHyperbolic sine, element-wise.\n\n`cosh`(x, /[, out, where, casting, order, ...])\n\nHyperbolic cosine, element-wise.\n\n`tanh`(x, /[, out, where, casting, order, ...])\n\nCompute hyperbolic tangent element-wise.\n\n`arcsinh`(x, /[, out, where, casting, order, ...])\n\nInverse hyperbolic sine element-wise.\n\n`arccosh`(x, /[, out, where, casting, order, ...])\n\nInverse hyperbolic cosine, element-wise.\n\n`arctanh`(x, /[, out, where, casting, order, ...])\n\nInverse hyperbolic tangent element-wise.\n\n`degrees`(x, /[, out, where, casting, order, ...])\n\nConvert angles from radians to degrees.\n\n`radians`(x, /[, out, where, casting, order, ...])\n\nConvert angles from degrees to radians.\n\n`deg2rad`(x, /[, out, where, casting, order, ...])\n\nConvert angles from degrees to radians.\n\n`rad2deg`(x, /[, out, where, casting, order, ...])\n\nConvert angles from radians to degrees.\n\nThese function all require integer arguments and they manipulate the bit-\npattern of those arguments.\n\n`bitwise_and`(x1, x2, /[, out, where, ...])\n\nCompute the bit-wise AND of two arrays element-wise.\n\n`bitwise_or`(x1, x2, /[, out, where, casting, ...])\n\nCompute the bit-wise OR of two arrays element-wise.\n\n`bitwise_xor`(x1, x2, /[, out, where, ...])\n\nCompute the bit-wise XOR of two arrays element-wise.\n\n`invert`(x, /[, out, where, casting, order, ...])\n\nCompute bit-wise inversion, or bit-wise NOT, element-wise.\n\n`left_shift`(x1, x2, /[, out, where, casting, ...])\n\nShift the bits of an integer to the left.\n\n`right_shift`(x1, x2, /[, out, where, ...])\n\nShift the bits of an integer to the right.\n\n`greater`(x1, x2, /[, out, where, casting, ...])\n\nReturn the truth value of (x1 > x2) element-wise.\n\n`greater_equal`(x1, x2, /[, out, where, ...])\n\nReturn the truth value of (x1 >= x2) element-wise.\n\n`less`(x1, x2, /[, out, where, casting, ...])\n\nReturn the truth value of (x1 < x2) element-wise.\n\n`less_equal`(x1, x2, /[, out, where, casting, ...])\n\nReturn the truth value of (x1 <= x2) element-wise.\n\n`not_equal`(x1, x2, /[, out, where, casting, ...])\n\nReturn (x1 != x2) element-wise.\n\n`equal`(x1, x2, /[, out, where, casting, ...])\n\nReturn (x1 == x2) element-wise.\n\nWarning\n\nDo not use the Python keywords `and` and `or` to combine logical array\nexpressions. These keywords will test the truth value of the entire array (not\nelement-by-element as you might expect). Use the bitwise operators & and |\ninstead.\n\n`logical_and`(x1, x2, /[, out, where, ...])\n\nCompute the truth value of x1 AND x2 element-wise.\n\n`logical_or`(x1, x2, /[, out, where, casting, ...])\n\nCompute the truth value of x1 OR x2 element-wise.\n\n`logical_xor`(x1, x2, /[, out, where, ...])\n\nCompute the truth value of x1 XOR x2, element-wise.\n\n`logical_not`(x, /[, out, where, casting, ...])\n\nCompute the truth value of NOT x element-wise.\n\nWarning\n\nThe bit-wise operators & and | are the proper way to perform element-by-\nelement array comparisons. Be sure you understand the operator precedence: `(a\n> 2) & (a < 5)` is the proper syntax because `a > 2 & a < 5` will result in an\nerror due to the fact that `2 & a` is evaluated first.\n\n`maximum`(x1, x2, /[, out, where, casting, ...])\n\nElement-wise maximum of array elements.\n\nTip\n\nThe Python function `max()` will find the maximum over a one-dimensional\narray, but it will do so using a slower sequence interface. The reduce method\nof the maximum ufunc is much faster. Also, the `max()` method will not give\nanswers you might expect for arrays with greater than one dimension. The\nreduce method of minimum also allows you to compute a total minimum over an\narray.\n\n`minimum`(x1, x2, /[, out, where, casting, ...])\n\nElement-wise minimum of array elements.\n\nWarning\n\nthe behavior of `maximum(a, b)` is different than that of `max(a, b)`. As a\nufunc, `maximum(a, b)` performs an element-by-element comparison of `a` and\n`b` and chooses each element of the result according to which element in the\ntwo arrays is larger. In contrast, `max(a, b)` treats the objects `a` and `b`\nas a whole, looks at the (total) truth value of `a > b` and uses it to return\neither `a` or `b` (as a whole). A similar difference exists between\n`minimum(a, b)` and `min(a, b)`.\n\n`fmax`(x1, x2, /[, out, where, casting, ...])\n\nElement-wise maximum of array elements.\n\n`fmin`(x1, x2, /[, out, where, casting, ...])\n\nElement-wise minimum of array elements.\n\nRecall that all of these functions work element-by-element over an array,\nreturning an array output. The description details only a single operation.\n\n`isfinite`(x, /[, out, where, casting, order, ...])\n\nTest element-wise for finiteness (not infinity and not Not a Number).\n\n`isinf`(x, /[, out, where, casting, order, ...])\n\nTest element-wise for positive or negative infinity.\n\n`isnan`(x, /[, out, where, casting, order, ...])\n\nTest element-wise for NaN and return result as a boolean array.\n\n`isnat`(x, /[, out, where, casting, order, ...])\n\nTest element-wise for NaT (not a time) and return result as a boolean array.\n\n`fabs`(x, /[, out, where, casting, order, ...])\n\nCompute the absolute values element-wise.\n\n`signbit`(x, /[, out, where, casting, order, ...])\n\nReturns element-wise True where signbit is set (less than zero).\n\n`copysign`(x1, x2, /[, out, where, casting, ...])\n\nChange the sign of x1 to that of x2, element-wise.\n\n`nextafter`(x1, x2, /[, out, where, casting, ...])\n\nReturn the next floating-point value after x1 towards x2, element-wise.\n\n`spacing`(x, /[, out, where, casting, order, ...])\n\nReturn the distance between x and the nearest adjacent number.\n\n`modf`(x[, out1, out2], / [[, out, where, ...])\n\nReturn the fractional and integral parts of an array, element-wise.\n\n`ldexp`(x1, x2, /[, out, where, casting, ...])\n\nReturns x1 * 2**x2, element-wise.\n\n`frexp`(x[, out1, out2], / [[, out, where, ...])\n\nDecompose the elements of x into mantissa and twos exponent.\n\n`fmod`(x1, x2, /[, out, where, casting, ...])\n\nReturns the element-wise remainder of division.\n\n`floor`(x, /[, out, where, casting, order, ...])\n\nReturn the floor of the input, element-wise.\n\n`ceil`(x, /[, out, where, casting, order, ...])\n\nReturn the ceiling of the input, element-wise.\n\n`trunc`(x, /[, out, where, casting, order, ...])\n\nReturn the truncated value of the input, element-wise.\n\n"}, {"name": "Universal functions (ufunc) basics", "path": "user/basics.ufuncs", "type": "User Guide", "text": "\nSee also\n\nUniversal functions (ufunc)\n\nA universal function (or ufunc for short) is a function that operates on\n`ndarrays` in an element-by-element fashion, supporting array broadcasting,\ntype casting, and several other standard features. That is, a ufunc is a\n\u201cvectorized\u201d wrapper for a function that takes a fixed number of specific\ninputs and produces a fixed number of specific outputs.\n\nIn NumPy, universal functions are instances of the `numpy.ufunc` class. Many\nof the built-in functions are implemented in compiled C code. The basic ufuncs\noperate on scalars, but there is also a generalized kind for which the basic\nelements are sub-arrays (vectors, matrices, etc.), and broadcasting is done\nover other dimensions. The simplest example is the addition operator:\n\nOne can also produce custom `numpy.ufunc` instances using the\n`numpy.frompyfunc` factory function.\n\nAll ufuncs have four methods. They can be found at Methods. However, these\nmethods only make sense on scalar ufuncs that take two input arguments and\nreturn one output argument. Attempting to call these methods on other ufuncs\nwill cause a `ValueError`.\n\nThe reduce-like methods all take an axis keyword, a dtype keyword, and an out\nkeyword, and the arrays must all have dimension >= 1. The axis keyword\nspecifies the axis of the array over which the reduction will take place (with\nnegative values counting backwards). Generally, it is an integer, though for\n`numpy.ufunc.reduce`, it can also be a tuple of `int` to reduce over several\naxes at once, or `None`, to reduce over all axes. For example:\n\nThe dtype keyword allows you to manage a very common problem that arises when\nnaively using `ufunc.reduce`. Sometimes you may have an array of a certain\ndata type and wish to add up all of its elements, but the result does not fit\ninto the data type of the array. This commonly happens if you have an array of\nsingle-byte integers. The dtype keyword allows you to alter the data type over\nwhich the reduction takes place (and therefore the type of the output). Thus,\nyou can ensure that the output is a data type with precision large enough to\nhandle your output. The responsibility of altering the reduce type is mostly\nup to you. There is one exception: if no dtype is given for a reduction on the\n\u201cadd\u201d or \u201cmultiply\u201d operations, then if the input type is an integer (or\nBoolean) data-type and smaller than the size of the `numpy.int_` data type, it\nwill be internally upcast to the `int_` (or `numpy.uint`) data-type. In the\nprevious example:\n\nFinally, the out keyword allows you to provide an output array (for single-\noutput ufuncs, which are currently the only ones supported; for future\nextension, however, a tuple with a single argument can be passed in). If out\nis given, the dtype argument is ignored. Considering `x` from the previous\nexample:\n\nUfuncs also have a fifth method, `numpy.ufunc.at`, that allows in place\noperations to be performed using advanced indexing. No buffering is used on\nthe dimensions where advanced indexing is used, so the advanced index can list\nan item more than once and the operation will be performed on the result of\nthe previous operation for that item.\n\nThe output of the ufunc (and its methods) is not necessarily an `ndarray`, if\nall input arguments are not `ndarrays`. Indeed, if any input defines an\n`__array_ufunc__` method, control will be passed completely to that function,\ni.e., the ufunc is overridden.\n\nIf none of the inputs overrides the ufunc, then all output arrays will be\npassed to the `__array_prepare__` and `__array_wrap__` methods of the input\n(besides `ndarrays`, and scalars) that defines it and has the highest\n`__array_priority__` of any other input to the universal function. The default\n`__array_priority__` of the ndarray is 0.0, and the default\n`__array_priority__` of a subtype is 0.0. Matrices have `__array_priority__`\nequal to 10.0.\n\nAll ufuncs can also take output arguments. If necessary, output will be cast\nto the data-type(s) of the provided output array(s). If a class with an\n`__array__` method is used for the output, results will be written to the\nobject returned by `__array__`. Then, if the class also has an\n`__array_prepare__` method, it is called so metadata may be determined based\non the context of the ufunc (the context consisting of the ufunc itself, the\narguments passed to the ufunc, and the ufunc domain.) The array object\nreturned by `__array_prepare__` is passed to the ufunc for computation.\nFinally, if the class also has an `__array_wrap__` method, the returned\n`ndarray` result will be passed to that method just before passing control\nback to the caller.\n\nSee also\n\nBroadcasting basics\n\nEach universal function takes array inputs and produces array outputs by\nperforming the core function element-wise on the inputs (where an element is\ngenerally a scalar, but can be a vector or higher-order sub-array for\ngeneralized ufuncs). Standard broadcasting rules are applied so that inputs\nnot sharing exactly the same shapes can still be usefully operated on.\n\nBy these rules, if an input has a dimension size of 1 in its shape, the first\ndata entry in that dimension will be used for all calculations along that\ndimension. In other words, the stepping machinery of the ufunc will simply not\nstep along that dimension (the stride will be 0 for that dimension).\n\nNote\n\nIn NumPy 1.6.0, a type promotion API was created to encapsulate the mechanism\nfor determining output types. See the functions `numpy.result_type`,\n`numpy.promote_types`, and `numpy.min_scalar_type` for more details.\n\nAt the core of every ufunc is a one-dimensional strided loop that implements\nthe actual function for a specific type combination. When a ufunc is created,\nit is given a static list of inner loops and a corresponding list of type\nsignatures over which the ufunc operates. The ufunc machinery uses this list\nto determine which inner loop to use for a particular case. You can inspect\nthe `.types` attribute for a particular ufunc to see which type combinations\nhave a defined inner loop and which output type they produce (character codes\nare used in said output for brevity).\n\nCasting must be done on one or more of the inputs whenever the ufunc does not\nhave a core loop implementation for the input types provided. If an\nimplementation for the input types cannot be found, then the algorithm\nsearches for an implementation with a type signature to which all of the\ninputs can be cast \u201csafely.\u201d The first one it finds in its internal list of\nloops is selected and performed, after all necessary type casting. Recall that\ninternal copies during ufuncs (even for casting) are limited to the size of an\ninternal buffer (which is user settable).\n\nNote\n\nUniversal functions in NumPy are flexible enough to have mixed type\nsignatures. Thus, for example, a universal function could be defined that\nworks with floating-point and integer values. See `numpy.ldexp` for an\nexample.\n\nBy the above description, the casting rules are essentially implemented by the\nquestion of when a data type can be cast \u201csafely\u201d to another data type. The\nanswer to this question can be determined in Python with a function call:\n`can_cast(fromtype, totype)`. The example below shows the results of this call\nfor the 24 internally supported types on the author\u2019s 64-bit system. You can\ngenerate this table for your system with the code given in the example.\n\nCode segment showing the \u201ccan cast safely\u201d table for a 64-bit system.\nGenerally the output depends on the system; your system might result in a\ndifferent table.\n\nYou should note that, while included in the table for completeness, the \u2018S\u2019,\n\u2018U\u2019, and \u2018V\u2019 types cannot be operated on by ufuncs. Also, note that on a\n32-bit system the integer types may have different sizes, resulting in a\nslightly altered table.\n\nMixed scalar-array operations use a different set of casting rules that ensure\nthat a scalar cannot \u201cupcast\u201d an array unless the scalar is of a fundamentally\ndifferent kind of data (i.e., under a different hierarchy in the data-type\nhierarchy) than the array. This rule enables you to use scalar constants in\nyour code (which, as Python types, are interpreted accordingly in ufuncs)\nwithout worrying about whether the precision of the scalar constant will cause\nupcasting on your large (small precision) array.\n\nInternally, buffers are used for misaligned data, swapped data, and data that\nhas to be converted from one data type to another. The size of internal\nbuffers is settable on a per-thread basis. There can be up to \\\\(2\n(n_{\\mathrm{inputs}} + n_{\\mathrm{outputs}})\\\\) buffers of the specified size\ncreated to handle the data from all the inputs and outputs of a ufunc. The\ndefault size of a buffer is 10,000 elements. Whenever buffer-based calculation\nwould be needed, but all input arrays are smaller than the buffer size, those\nmisbehaved or incorrectly-typed arrays will be copied before the calculation\nproceeds. Adjusting the size of the buffer may therefore alter the speed at\nwhich ufunc calculations of various sorts are completed. A simple interface\nfor setting this variable is accessible using the function `numpy.setbufsize`.\n\nUniversal functions can trip special floating-point status registers in your\nhardware (such as divide-by-zero). If available on your platform, these\nregisters will be regularly checked during calculation. Error handling is\ncontrolled on a per-thread basis, and can be configured using the functions\n`numpy.seterr` and `numpy.seterrcall`.\n\nClasses (including ndarray subclasses) can override how ufuncs act on them by\ndefining certain special methods. For details, see Standard array subclasses.\n\n"}, {"name": "unsigned int PyArray_GetNDArrayCFeatureVersion()", "path": "reference/c-api/array#c.PyArray_GetNDArrayCFeatureVersion", "type": "Array API", "text": "\nNew in version 1.4.0.\n\nThis just returns the value `NPY_FEATURE_VERSION`. `NPY_FEATURE_VERSION`\nchanges whenever the API changes (e.g. a function is added). A changed value\ndoes not always require a recompile.\n\n"}, {"name": "unsigned int PyArray_GetNDArrayCVersion()", "path": "reference/c-api/array#c.PyArray_GetNDArrayCVersion", "type": "Array API", "text": "\nThis just returns the value `NPY_VERSION`. `NPY_VERSION` changes whenever a\nbackward incompatible change at the ABI level. Because it is in the C-API,\nhowever, comparing the output of this function from the value defined in the\ncurrent header gives a way to test if the C-API has changed thus requiring a\nre-compilation of extension modules that use the C-API. This is automatically\nchecked in the function `import_array`.\n\n"}, {"name": "Upgrading PCG64 with PCG64DXSM", "path": "reference/random/upgrading-pcg64", "type": "Upgrading PCG64 with PCG64DXSM", "text": "\nUses of the `PCG64` `BitGenerator` in a massively-parallel context have been\nshown to have statistical weaknesses that were not apparent at the first\nrelease in numpy 1.17. Most users will never observe this weakness and are\nsafe to continue to use `PCG64`. We have introduced a new `PCG64DXSM`\n`BitGenerator` that will eventually become the new default `BitGenerator`\nimplementation used by `default_rng` in future releases. `PCG64DXSM` solves\nthe statistical weakness while preserving the performance and the features of\n`PCG64`.\n\nIf you\n\nthen this weakness does not affect you at all. Carry on.\n\nIf you use moderate numbers of parallel streams created with `default_rng` or\n`SeedSequence.spawn`, in the 1000s, then the chance of observing this weakness\nis negligibly small. You can continue to use `PCG64` comfortably.\n\nIf you use very large numbers of parallel streams, in the millions, and draw\nlarge amounts of numbers from each, then the chance of observing this weakness\ncan become non-negligible, if still small. An example of such a use case would\nbe a very large distributed reinforcement learning problem with millions of\nlong Monte Carlo playouts each generating billions of random number draws.\nSuch use cases should consider using `PCG64DXSM` explicitly or another modern\n`BitGenerator` like `SFC64` or `Philox`, but it is unlikely that any old\nresults you may have calculated are invalid. In any case, the weakness is a\nkind of Birthday Paradox collision. That is, a single pair of parallel streams\nout of the millions, considered together, might fail a stringent set of\nstatistical tests of randomness. The remaining millions of streams would all\nbe perfectly fine, and the effect of the bad pair in the whole calculation is\nvery likely to be swamped by the remaining streams in most applications.\n\nLike many PRNG algorithms, `PCG64` is constructed from a transition function,\nwhich advances a 128-bit state, and an output function, that mixes the 128-bit\nstate into a 64-bit integer to be output. One of the guiding design principles\nof the PCG family of PRNGs is to balance the computational cost (and\npseudorandomness strength) between the transition function and the output\nfunction. The transition function is a 128-bit linear congruential generator\n(LCG), which consists of multiplying the 128-bit state with a fixed\nmultiplication constant and then adding a user-chosen increment, in 128-bit\nmodular arithmetic. LCGs are well-analyzed PRNGs with known weaknesses, though\n128-bit LCGs are large enough to pass stringent statistical tests on their\nown, with only the trivial output function. The output function of `PCG64` is\nintended to patch up some of those known weaknesses by doing \u201cjust enough\u201d\nscrambling of the bits to assist in the statistical properties without adding\ntoo much computational cost.\n\nOne of these known weaknesses is that advancing the state of the LCG by steps\nnumbering a power of two (`bg.advance(2**N)`) will leave the lower `N` bits\nidentical to the state that was just left. For a single stream drawn from\nsequentially, this is of little consequence. The remaining \\\\(128-N\\\\) bits\nprovide plenty of pseudorandomness that will be mixed in for any practical `N`\nthat can be observed in a single stream, which is why one does not need to\nworry about this if you only use a single stream in your application.\nSimilarly, the `PCG64.jumped` method uses a carefully chosen number of steps\nto avoid creating these collisions. However, once you start creating\n\u201crandomly-initialized\u201d parallel streams, either using OS entropy by calling\n`default_rng` repeatedly or using `SeedSequence.spawn`, then we need to\nconsider how many lower bits need to \u201ccollide\u201d in order to create a bad pair\nof streams, and then evaluate the probability of creating such a collision.\nEmpirically, it has been determined that if one shares the lower 58 bits of\nstate and shares an increment, then the pair of streams, when interleaved,\nwill fail PractRand in a reasonable amount of time, after drawing a few\ngigabytes of data. Following the standard Birthday Paradox calculations for a\ncollision of 58 bits, we can see that we can create \\\\(2^{29}\\\\), or about\nhalf a billion, streams which is when the probability of such a collision\nbecomes high. Half a billion streams is quite high, and the amount of data\neach stream needs to draw before the statistical correlations become apparent\nto even the strict `PractRand` tests is in the gigabytes. But this is on the\nhorizon for very large applications like distributed reinforcement learning.\nThere are reasons to expect that even in these applications a collision\nprobably will not have a practical effect in the total result, since the\nstatistical problem is constrained to just the colliding pair.\n\nNow, let us consider the case when the increment is not constrained to be the\nsame. Our implementation of `PCG64` seeds both the state and the increment;\nthat is, two calls to `default_rng` (almost certainly) have different states\nand increments. Upon our first release, we believed that having the seeded\nincrement would provide a certain amount of extra protection, that one would\nhave to be \u201cclose\u201d in both the state space and increment space in order to\nobserve correlations (`PractRand` failures) in a pair of streams. If that were\ntrue, then the \u201cbottleneck\u201d for collisions would be the 128-bit entropy pool\nsize inside of `SeedSequence` (and 128-bit collisions are in the\n\u201cpreposterously unlikely\u201d category). Unfortunately, this is not true.\n\nOne of the known properties of an LCG is that different increments create\ndistinct streams, but with a known relationship. Each LCG has an orbit that\ntraverses all \\\\(2^{128}\\\\) different 128-bit states. Two LCGs with different\nincrements are related in that one can \u201crotate\u201d the orbit of the first LCG\n(advance it by a number of steps that we can compute from the two increments)\nsuch that then both LCGs will always then have the same state, up to an\nadditive constant and maybe an inversion of the bits. If you then iterate both\nstreams in lockstep, then the states will always remain related by that same\nadditive constant (and the inversion, if present). Recall that `PCG64` is\nconstructed from both a transition function (the LCG) and an output function.\nIt was expected that the scrambling effect of the output function would have\nbeen strong enough to make the distinct streams practically independent (i.e.\n\u201cpassing the `PractRand` tests\u201d) unless the two increments were pathologically\nrelated to each other (e.g. 1 and 3). The output function XSL-RR of the then-\nstandard PCG algorithm that we implemented in `PCG64` turns out to be too weak\nto cover up for the 58-bit collision of the underlying LCG that we described\nabove. For any given pair of increments, the size of the \u201ccolliding\u201d space of\nstates is the same, so for this weakness, the extra distinctness provided by\nthe increments does not translate into extra protection from statistical\ncorrelations that `PractRand` can detect.\n\nFortunately, strengthening the output function is able to correct this\nweakness and does turn the extra distinctness provided by differing increments\ninto additional protection from these low-bit collisions. To the PCG author\u2019s\ncredit, she had developed a stronger output function in response to related\ndiscussions during the long birth of the new `BitGenerator` system. We NumPy\ndevelopers chose to be \u201cconservative\u201d and use the XSL-RR variant that had\nundergone a longer period of testing at that time. The DXSM output function\nadopts a \u201cxorshift-multiply\u201d construction used in strong integer hashes that\nhas much better avalanche properties than the XSL-RR output function. While\nthere are \u201cpathological\u201d pairs of increments that induce \u201cbad\u201d additive\nconstants that relate the two streams, the vast majority of pairs induce\n\u201cgood\u201d additive constants that make the merely-distinct streams of LCG states\ninto practically-independent output streams. Indeed, now the claim we once\nmade about `PCG64` is actually true of `PCG64DXSM`: collisions are possible,\nbut both streams have to simultaneously be both \u201cclose\u201d in the 128 bit state\nspace and \u201cclose\u201d in the 127-bit increment space, so that would be less likely\nthan the negligible chance of colliding in the 128-bit internal `SeedSequence`\npool. The DXSM output function is more computationally intensive than XSL-RR,\nbut some optimizations in the LCG more than make up for the performance hit on\nmost machines, so `PCG64DXSM` is a good, safe upgrade. There are, of course,\nan infinite number of stronger output functions that one could consider, but\nmost will have a greater computational cost, and the DXSM output function has\nnow received many CPU cycles of testing via `PractRand` at this time.\n\n"}, {"name": "Using F2PY bindings in Python", "path": "f2py/python-usage", "type": "Using F2PY bindings in Python", "text": "\nAll wrappers for Fortran/C routines, common blocks, or for Fortran 90 module\ndata generated by F2PY are exposed to Python as `fortran` type objects.\nRoutine wrappers are callable `fortran` type objects while wrappers to Fortran\ndata have attributes referring to data objects.\n\nAll `fortran` type objects have an attribute `_cpointer` that contains a\n`CObject` referring to the C pointer of the corresponding Fortran/C function\nor variable at the C level. Such `CObjects` can be used as a callback argument\nfor F2PY generated functions to bypass the Python C/API layer for calling\nPython functions from Fortran or C when the computational aspects of such\nfunctions are implemented in C or Fortran and wrapped with F2PY (or any other\ntool capable of providing the `CObject` of a function).\n\nConsider a Fortran 77 file ``ftype.f`:\n\nand a wrapper built using `f2py -c ftype.f -m ftype`.\n\nIn Python:\n\nIn general, a scalar argument for a F2PY generated wrapper function can be an\nordinary Python scalar (integer, float, complex number) as well as an\narbitrary sequence object (list, tuple, array, string) of scalars. In the\nlatter case, the first element of the sequence object is passed to Fortran\nroutine as a scalar argument.\n\nNote\n\nWhen type-casting is required and there is possible loss of information via\nnarrowing e.g. when type-casting float to integer or complex to float, F2PY\ndoes not raise an exception.\n\nConsider the following Fortran 77 code:\n\nand wrap it using `f2py -c -m scalar scalar.f`.\n\nIn Python:\n\nF2PY generated wrapper functions accept almost any Python object as a string\nargument, since `str` is applied for non-string objects. Exceptions are NumPy\narrays that must have type code `'c'` or `'1'` when used as string arguments.\n\nA string can have an arbitrary length when used as a string argument for an\nF2PY generated wrapper function. If the length is greater than expected, the\nstring is truncated silently. If the length is smaller than expected,\nadditional memory is allocated and filled with `\\0`.\n\nBecause Python strings are immutable, an `intent(inout)` argument expects an\narray version of a string in order to have in situ changes be effective.\n\nConsider the following Fortran 77 code:\n\nand wrap it using `f2py -c -m mystring string.f`.\n\nPython session:\n\nIn general, array arguments for F2PY generated wrapper functions accept\narbitrary sequences that can be transformed to NumPy array objects. There are\ntwo notable exceptions:\n\nIn general, if a NumPy array is proper-contiguous and has a proper type then\nit is directly passed to the wrapped Fortran/C function. Otherwise, an\nelement-wise copy of the input array is made and the copy, being proper-\ncontiguous and with proper type, is used as the array argument.\n\nThere are two types of proper-contiguous NumPy arrays:\n\nFor one-dimensional arrays these notions coincide.\n\nFor example, a 2x2 array `A` is Fortran-contiguous if its elements are stored\nin memory in the following order:\n\nand C-contiguous if the order is as follows:\n\nTo test whether an array is C-contiguous, use the `.flags.c_contiguous`\nattribute of NumPy arrays. To test for Fortran contiguity, use the\n`.flags.f_contiguous` attribute.\n\nUsually there is no need to worry about how the arrays are stored in memory\nand whether the wrapped functions, being either Fortran or C functions, assume\none or another storage order. F2PY automatically ensures that wrapped\nfunctions get arguments with the proper storage order; the underlying\nalgorithm is designed to make copies of arrays only when absolutely necessary.\nHowever, when dealing with very large multidimensional input arrays with sizes\nclose to the size of the physical memory in your computer, then care must be\ntaken to ensure the usage of proper-contiguous and proper type arguments.\n\nTo transform input arrays to column major storage order before passing them to\nFortran routines, use the function `numpy.asfortranarray(<array>)`.\n\nConsider the following Fortran 77 code:\n\nand wrap it using `f2py -c -m arr array.f -DF2PY_REPORT_ON_ARRAY_COPY=1`.\n\nIn Python:\n\nF2PY supports calling Python functions from Fortran or C codes.\n\nConsider the following Fortran 77 code:\n\nand wrap it using `f2py -c -m callback callback.f`.\n\nIn Python:\n\nIn the above example F2PY was able to guess accurately the signature of the\ncall-back function. However, sometimes F2PY cannot establish the appropriate\nsignature; in these cases the signature of the call-back function must be\nexplicitly defined in the signature file.\n\nTo facilitate this, signature files may contain special modules (the names of\nthese modules contain the special `__user__` sub-string) that defines the\nvarious signatures for call-back functions. Callback arguments in routine\nsignatures have the `external` attribute (see also the `intent(callback)`\nattribute). To relate a callback argument with its signature in a `__user__`\nmodule block, a `use` statement can be utilized as illustrated below. The same\nsignature for a callback argument can be referred to in different routine\nsignatures.\n\nWe use the same Fortran 77 code as in the previous example but now we will\npretend that F2PY was not able to guess the signatures of call-back arguments\ncorrectly. First, we create an initial signature file `callback2.pyf` using\nF2PY:\n\nThen modify it as follows\n\nFinally, we build the extension module using `f2py -c callback2.pyf\ncallback.f`.\n\nAn example Python session for this snippet would be identical to the previous\nexample except that the argument names would differ.\n\nSometimes a Fortran package may require that users provide routines that the\npackage will use. F2PY can construct an interface to such routines so that\nPython functions can be called from Fortran.\n\nConsider the following Fortran 77 subroutine that takes an array as its input\nand applies a function `func` to its elements.\n\nThe Fortran code expects that the function `func` has been defined externally.\nIn order to use a Python function for `func`, it must have an attribute\n`intent(callback)` and, it must be specified before the `external` statement.\n\nFinally, build an extension module using `f2py -c -m foo calculate.f`\n\nIn Python:\n\nThe function is included as an argument to the python function call to the\nFortran subroutine even though it was not in the Fortran subroutine argument\nlist. The \u201cexternal\u201d keyword refers to the C function generated by f2py, not\nthe python function itself. The python function is essentially being supplied\nto the C function.\n\nThe callback function may also be explicitly set in the module. Then it is not\nnecessary to pass the function in the argument list to the Fortran function.\nThis may be desired if the Fortran function calling the python callback\nfunction is itself called by another Fortran function.\n\nConsider the following Fortran 77 subroutine:\n\nand wrap it using `f2py -c -m pfromf extcallback.f`.\n\nIn Python:\n\nF2PY generated interfaces are very flexible with respect to call-back\narguments. For each call-back argument an additional optional argument\n`<name>_extra_args` is introduced by F2PY. This argument can be used to pass\nextra arguments to user provided call-back functions.\n\nIf a F2PY generated wrapper function expects the following call-back argument:\n\nbut the following Python function\n\nis provided by a user, and in addition,\n\nis used, then the following rules are applied when a Fortran or C function\nevaluates the call-back argument `gun`:\n\nIf the function `gun` may return any number of objects as a tuple; then the\nfollowing rules are applied:\n\nF2PY generates wrappers to `common` blocks defined in a routine signature\nblock. Common blocks are visible to all Fortran codes linked to the current\nextension module, but not to other extension modules (this restriction is due\nto the way Python imports shared libraries). In Python, the F2PY wrappers to\n`common` blocks are `fortran` type objects that have (dynamic) attributes\nrelated to the data members of the common blocks. When accessed, these\nattributes return as NumPy array objects (multidimensional arrays are Fortran-\ncontiguous) which directly link to data members in common blocks. Data members\ncan be changed by direct assignment or by in-place changes to the\ncorresponding array objects.\n\nConsider the following Fortran 77 code:\n\nand wrap it using `f2py -c -m common common.f`.\n\nIn Python:\n\nThe F2PY interface to Fortran 90 module data is similar to the handling of\nFortran 77 common blocks.\n\nConsider the following Fortran 90 code:\n\nand wrap it using `f2py -c -m moddata moddata.f90`.\n\nIn Python:\n\nF2PY has basic support for Fortran 90 module allocatable arrays.\n\nConsider the following Fortran 90 code:\n\nand wrap it using `f2py -c -m allocarr allocarr.f90`.\n\nIn Python:\n\n"}, {"name": "Using Gitpod for NumPy development", "path": "dev/development_gitpod", "type": "Development", "text": "\nThis section of the documentation will guide you through:\n\nGitpod is an open-source platform for automated and ready-to-code development\nenvironments. It enables developers to describe their dev environment as code\nand start instant and fresh development environments for each new task\ndirectly from your browser. This reduces the need to install local development\nenvironments and deal with incompatible dependencies.\n\nTo be able to use Gitpod, you will need to have the Gitpod app installed on\nyour GitHub account, so if you do not have an account yet, you will need to\ncreate one first.\n\nHead over to the Gitpod website and click on the Continue with GitHub button.\nYou will be redirected to the GitHub authentication page. You will then be\nasked to install the Gitpod GitHub app.\n\nMake sure to select All repositories access option to avoid issues with\npermissions later on. Click on the green Install button\n\nThis will install the necessary hooks for the integration.\n\nThe best way to work on NumPy as a contributor is by making a fork of the\nrepository first.\n\nOnce you have authenticated to Gitpod through GitHub, you can install the\nGitpod browser extension which will add a Gitpod button next to the Code\nbutton in the repository:\n\nWhen your workspace is ready, you can test the build by entering:\n\n`runtests.py` is another script in the NumPy root directory. It runs a suite\nof tests that make sure NumPy is working as it should, and `-v` activates the\n`--verbose` option to show all the test output.\n\nGitpod uses VSCode as the editor. If you have not used this editor before, you\ncan check the Getting started VSCode docs to familiarize yourself with it.\n\nYour workspace will look similar to the image below:\n\nNote\n\nBy default, VSCode initializes with a light theme. You can change to a dark\ntheme by with the keyboard shortcut ``Cmd`-`K` `Cmd`-`T`` in Mac or\n``Ctrl`-`K` `Ctrl`-`T`` in Linux and Windows.\n\nWe have marked some important sections in the editor:\n\nWe have also pre-installed a few tools and VSCode extensions to help with the\ndevelopment experience:\n\nThe Development workflow section of this documentation contains information\nregarding the NumPy development workflow. Make sure to check this before\nworking on your contributions.\n\nWhen using Gitpod, git is pre configured for you:\n\nAs you started your workspace from your own NumPy fork, you will by default\nhave both `upstream` and `origin` added as remotes. You can verify this by\ntyping `git remote` on your terminal or by clicking on the branch name on the\nstatus bar (see image below).\n\nYou can find the detailed documentation on how rendering the documentation\nwith Sphinx works in the Building the NumPy API and reference docs section.\n\nThe documentation is pre-built during your workspace initialization. So once\nthis task is completed, you have two main options to render the documentation\nin Gitpod.\n\nTo see the rendered version of a page, you can right-click on the `.html` file\nand click on Open with Live Serve. Alternatively, you can open the file in the\neditor and click on the Go live button on the status bar.\n\nA quick and easy way to see live changes in a `.rst` file as you work on it\nuses the rst extension with docutils.\n\nNote\n\nThis will generate a simple live preview of the document without the `html`\ntheme, and some backlinks might not be added correctly. But it is an easy and\nlightweight way to get instant feedback on your work.\n\nOpen VSCode Command Palette with ``Cmd`-`Shift`-`P`` in Mac or\n``Ctrl`-`Shift`-`P`` in Linux and Windows. Start typing \u201crestructured\u201d and\nchoose either \u201cOpen preview\u201d or \u201cOpen preview to the Side\u201d.\n\nAs you work on the document, you will see a live rendering of it on the\neditor.\n\nIf you want to see the final output with the `html` theme you will need to\nrebuild the docs with `make html` and use Live Serve as described in option 1.\n\nYour stopped workspace will be kept for 14 days and deleted afterwards if you\ndo not use them.\n\nYes, let\u2019s say you stepped away for a while and you want to carry on working\non your NumPy contributions. You need to visit https://gitpod.io/workspaces\nand click on the workspace you want to spin up again. All your changes will be\nthere as you last left them.\n\nAbsolutely! Any extensions you installed will be installed in your own\nworkspace and preserved.\n\nHead to https://gitpod.io/integrations and make sure you are logged in. Hover\nover GitHub and click on the three buttons that appear on the right. Click on\nedit permissions and make sure you have `user:email`, `read:user`, and\n`public_repo` checked. Click on Update Permissions and confirm the changes in\nthe GitHub application page.\n\nIf you keep your workspace open in a browser tab but don\u2019t interact with it,\nit will shut down after 30 minutes. If you close the browser tab, it will shut\ndown after 3 minutes.\n\nUnfortunately this is a known-issue on Gitpod\u2019s side. You can sort this issue\nin two ways:\n\nHead to https://gitpod.io/integrations and make sure you are logged in. Hover\nover GitHub and click on the three buttons that appear on the right. Click on\nedit permissions and make sure you have `public_repo` checked. Click on Update\nPermissions and confirm the changes in the GitHub application page.\n\n"}, {"name": "Using NumPy C-API", "path": "user/c-info", "type": "User Guide", "text": "\n\n"}, {"name": "Using the Convenience Classes", "path": "reference/routines.polynomials.classes", "type": "Using the Convenience Classes", "text": "\nThe convenience classes provided by the polynomial package are:\n\nName\n\nProvides\n\nPolynomial\n\nPower series\n\nChebyshev\n\nChebyshev series\n\nLegendre\n\nLegendre series\n\nLaguerre\n\nLaguerre series\n\nHermite\n\nHermite series\n\nHermiteE\n\nHermiteE series\n\nThe series in this context are finite sums of the corresponding polynomial\nbasis functions multiplied by coefficients. For instance, a power series looks\nlike\n\nand has coefficients \\\\([1, 2, 3]\\\\). The Chebyshev series with the same\ncoefficients looks like\n\nand more generally\n\nwhere in this case the \\\\(T_n\\\\) are the Chebyshev functions of degree\n\\\\(n\\\\), but could just as easily be the basis functions of any of the other\nclasses. The convention for all the classes is that the coefficient \\\\(c[i]\\\\)\ngoes with the basis function of degree i.\n\nAll of the classes are immutable and have the same methods, and especially\nthey implement the Python numeric operators +, -, *, //, %, divmod, **, ==,\nand !=. The last two can be a bit problematic due to floating point roundoff\nerrors. We now give a quick demonstration of the various operations using\nNumPy version 1.7.0.\n\nFirst we need a polynomial class and a polynomial instance to play with. The\nclasses can be imported directly from the polynomial package or from the\nmodule of the relevant type. Here we import from the package and use the\nconventional Polynomial class because of its familiarity:\n\nNote that there are three parts to the long version of the printout. The first\nis the coefficients, the second is the domain, and the third is the window:\n\nPrinting a polynomial yields the polynomial expression in a more familiar\nformat:\n\nNote that the string representation of polynomials uses Unicode characters by\ndefault (except on Windows) to express powers and subscripts. An ASCII-based\nrepresentation is also available (default on Windows). The polynomial string\nformat can be toggled at the package-level with the `set_default_printstyle`\nfunction:\n\nor controlled for individual polynomial instances with string formatting:\n\nWe will deal with the domain and window when we get to fitting, for the moment\nwe ignore them and run through the basic algebraic and arithmetic operations.\n\nAddition and Subtraction:\n\nMultiplication:\n\nPowers:\n\nDivision:\n\nFloor division, \u2018//\u2019, is the division operator for the polynomial classes,\npolynomials are treated like integers in this regard. For Python versions <\n3.x the \u2018/\u2019 operator maps to \u2018//\u2019, as it does for Python, for later versions\nthe \u2018/\u2019 will only work for division by scalars. At some point it will be\ndeprecated:\n\nRemainder:\n\nDivmod:\n\nEvaluation:\n\nSubstitution:\n\nSubstitute a polynomial for x and expand the result. Here we substitute p in\nitself leading to a new polynomial of degree 4 after expansion. If the\npolynomials are regarded as functions this is composition of functions:\n\nRoots:\n\nIt isn\u2019t always convenient to explicitly use Polynomial instances, so tuples,\nlists, arrays, and scalars are automatically cast in the arithmetic\noperations:\n\nPolynomials that differ in domain, window, or class can\u2019t be mixed in\narithmetic:\n\nBut different types can be used for substitution. In fact, this is how\nconversion of Polynomial classes among themselves is done for type, domain,\nand window casting:\n\nWhich gives the polynomial `p` in Chebyshev form. This works because \\\\(T_1(x)\n= x\\\\) and substituting \\\\(x\\\\) for \\\\(x\\\\) doesn\u2019t change the original\npolynomial. However, all the multiplications and divisions will be done using\nChebyshev series, hence the type of the result.\n\nIt is intended that all polynomial instances are immutable, therefore\naugmented operations (`+=`, `-=`, etc.) and any other functionality that would\nviolate the immutablity of a polynomial instance are intentionally\nunimplemented.\n\nPolynomial instances can be integrated and differentiated.:\n\nThe first example integrates `p` once, the second example integrates it twice.\nBy default, the lower bound of the integration and the integration constant\nare 0, but both can be specified.:\n\nIn the first case the lower bound of the integration is set to -1 and the\nintegration constant is 0. In the second the constant of integration is set to\n1 as well. Differentiation is simpler since the only option is the number of\ntimes the polynomial is differentiated:\n\nConstructing polynomials by specifying coefficients is just one way of\nobtaining a polynomial instance, they may also be created by specifying their\nroots, by conversion from other polynomial types, and by least squares fits.\nFitting is discussed in its own section, the other methods are demonstrated\nbelow:\n\nThe convert method can also convert domain and window:\n\nIn numpy versions >= 1.7.0 the `basis` and `cast` class methods are also\navailable. The cast method works like the convert method while the basis\nmethod returns the basis polynomial of given degree:\n\nConversions between types can be useful, but it is not recommended for routine\nuse. The loss of numerical precision in passing from a Chebyshev series of\ndegree 50 to a Polynomial series of the same degree can make the results of\nnumerical evaluation essentially random.\n\nFitting is the reason that the `domain` and `window` attributes are part of\nthe convenience classes. To illustrate the problem, the values of the\nChebyshev polynomials up to degree 5 are plotted below.\n\nIn the range -1 <= `x` <= 1 they are nice, equiripple functions lying between\n+/- 1. The same plots over the range -2 <= `x` <= 2 look very different:\n\nAs can be seen, the \u201cgood\u201d parts have shrunk to insignificance. In using\nChebyshev polynomials for fitting we want to use the region where `x` is\nbetween -1 and 1 and that is what the `window` specifies. However, it is\nunlikely that the data to be fit has all its data points in that interval, so\nwe use `domain` to specify the interval where the data points lie. When the\nfit is done, the domain is first mapped to the window by a linear\ntransformation and the usual least squares fit is done using the mapped data\npoints. The window and domain of the fit are part of the returned series and\nare automatically used when computing values, derivatives, and such. If they\naren\u2019t specified in the call the fitting routine will use the default window\nand the smallest domain that holds all the data points. This is illustrated\nbelow for a fit to a noisy sine curve.\n\n"}, {"name": "Using via cmake", "path": "f2py/buildtools/cmake", "type": "Using via \n        \n         cmake", "text": "\nIn terms of complexity, `cmake` falls between `make` and `meson`. The learning\ncurve is steeper since CMake syntax is not pythonic and is closer to `make`\nwith environment variables.\n\nHowever, the trade-off is enhanced flexibility and support for most\narchitectures and compilers. An introduction to the syntax is out of scope for\nthis document, but this extensive CMake collection of resources is great.\n\nNote\n\n`cmake` is very popular for mixed-language systems, however support for `f2py`\nis not particularly native or pleasant; and a more natural approach is to\nconsider Using via scikit-build\n\nReturning to the `fib` example from Three ways to wrap - getting started\nsection.\n\nWe do not need to explicitly generate the `python -m numpy.f2py fib1.f`\noutput, which is `fib1module.c`, which is beneficial. With this; we can now\ninitialize a `CMakeLists.txt` file as follows:\n\nA key element of the `CMakeLists.txt` file defined above is that the\n`add_custom_command` is used to generate the wrapper `C` files and then added\nas a dependency of the actual shared library target via a `add_custom_target`\ndirective which prevents the command from running every time. Additionally,\nthe method used for obtaining the `fortranobject.c` file can also be used to\ngrab the `numpy` headers on older `cmake` versions.\n\nThis then works in the same manner as the other modules, although the naming\nconventions are different and the output library is not automatically prefixed\nwith the `cython` information.\n\nThis is particularly useful where an existing toolchain already exists and\n`scikit-build` or other additional `python` dependencies are discouraged.\n\n"}, {"name": "Using via meson", "path": "f2py/buildtools/meson", "type": "Using via \n        \n         meson", "text": "\nThe key advantage gained by leveraging `meson` over the techniques described\nin Using via numpy.distutils is that this feeds into existing systems and\nlarger projects with ease. `meson` has a rather pythonic syntax which makes it\nmore comfortable and amenable to extension for `python` users.\n\nNote\n\nMeson needs to be at-least `0.46.0` in order to resolve the `python` include\ndirectories.\n\nWe will need the generated `C` wrapper before we can use a general purpose\nbuild system like `meson`. We will acquire this by:\n\nNow, consider the following `meson.build` file for the `fib` and `scalar`\nexamples from Three ways to wrap - getting started section:\n\nAt this point the build will complete, but the import will fail:\n\nRecall that the original example, as reproduced below, was in SCREAMCASE:\n\nWith the standard approach, the subroutine exposed to `python` is `fib` and\nnot `FIB`. This means we have a few options. One approach (where possible) is\nto lowercase the original Fortran file with say:\n\nHowever this requires the ability to modify the source which is not always\npossible. The easiest way to solve this is to let `f2py` deal with it:\n\nA major pain point in the workflow defined above, is the manual tracking of\ninputs. Although it would require more effort to figure out the actual outputs\nfor reasons discussed in F2PY and Build Systems.\n\nHowever, we can augment our workflow in a straightforward to take into account\nfiles for which the outputs are known when the build system is set up.\n\nThis can be compiled and run as before.\n\nIt is worth keeping in mind the following:\n\n"}, {"name": "Using via scikit-build", "path": "f2py/buildtools/skbuild", "type": "Using via \n        \n         scikit-build", "text": "\n`scikit-build` provides two separate concepts geared towards the users of\nPython extension modules.\n\nNote\n\nIt is possible to use `scikit-build`\u2019s `cmake` modules to bypass the cmake\nsetup mechanism completely, and to write targets which call `f2py -c`. This\nusage is not recommended since the point of these build system documents are\nto move away from the internal `numpy.distutils` methods.\n\nFor situations where no `setuptools` replacements are required or wanted (i.e.\nif `wheels` are not needed), it is recommended to instead use the vanilla\n`cmake` setup described in Using via cmake.\n\nWe will consider the `fib` example from Three ways to wrap - getting started\nsection.\n\nConsider using the following `CMakeLists.txt`.\n\nMuch of the logic is the same as in Using via cmake, however notably here the\nappropriate module suffix is generated via `sysconfig.get_config_var(\"SO\")`.\nThe resulting extension can be built and loaded in the standard workflow.\n\nNote\n\nAs of November 2021\n\nThe behavior described here of driving the `cmake` build of a module is\nconsidered to be legacy behaviour and should not be depended on.\n\nThe utility of `scikit-build` lies in being able to drive the generation of\nmore than extension modules, in particular a common usage pattern is the\ngeneration of Python distributables (for example for PyPI).\n\nThe workflow with `scikit-build` straightforwardly supports such packaging\nrequirements. Consider augmenting the project with a `setup.py` as defined:\n\nAlong with a commensurate `pyproject.toml`\n\nTogether these can build the extension using `cmake` in tandem with other\nstandard `setuptools` outputs. Running `cmake` through `setup.py` is mostly\nused when it is necessary to integrate with extension modules not built with\n`cmake`.\n\nWhere we have modified the path to the module as `--inplace` places the\nextension module in a subfolder.\n\n"}, {"name": "vectorize.__call__()", "path": "reference/generated/numpy.vectorize.__call__", "type": "numpy.vectorize.__call__", "text": "\nmethod\n\nReturn arrays with the results of `pyfunc` broadcast (vectorized) over `args`\nand `kwargs` not in `excluded`.\n\n"}, {"name": "version", "path": "reference/arrays.interface", "type": "The Array Interface", "text": "\nNote\n\nThis page describes the numpy-specific API for accessing the contents of a\nnumpy array from other C extensions. PEP 3118 \u2013 `The Revised Buffer Protocol`\nintroduces similar, standardized API to Python 2.6 and 3.0 for any extension\nmodule to use. Cython\u2019s buffer array support uses the PEP 3118 API; see the\nCython numpy tutorial. Cython provides a way to write code that supports the\nbuffer protocol with Python versions older than 2.6 because it has a backward-\ncompatible implementation utilizing the array interface described here.\n\n3\n\nThe array interface (sometimes called array protocol) was created in 2005 as a\nmeans for array-like Python objects to re-use each other\u2019s data buffers\nintelligently whenever possible. The homogeneous N-dimensional array interface\nis a default mechanism for objects to share N-dimensional array memory and\ninformation. The interface consists of a Python-side and a C-side using two\nattributes. Objects wishing to be considered an N-dimensional array in\napplication code should support at least one of these attributes. Objects\nwishing to support an N-dimensional array in application code should look for\nat least one of these attributes and use the information provided\nappropriately.\n\nThis interface describes homogeneous arrays in the sense that each item of the\narray has the same \u201ctype\u201d. This type can be very simple or it can be a quite\narbitrary and complicated C-like structure.\n\nThere are two ways to use the interface: A Python side and a C-side. Both are\nseparate attributes.\n\nThis approach to the interface consists of the object having an\n`__array_interface__` attribute.\n\nA dictionary of items (3 required and 5 optional). The optional keys in the\ndictionary have implied defaults if they are not provided.\n\nThe keys are:\n\nTuple whose elements are the array size in each dimension. Each entry is an\ninteger (a Python `int`). Note that these integers could be larger than the\nplatform `int` or `long` could hold (a Python `int` is a C `long`). It is up\nto the code using this attribute to handle this appropriately; either by\nraising an error when overflow is possible, or by using `long long` as the C\ntype for the shapes.\n\nA string providing the basic type of the homogeneous array The basic string\nformat consists of 3 parts: a character describing the byteorder of the data\n(`<`: little-endian, `>`: big-endian, `|`: not-relevant), a character code\ngiving the basic type of the array, and an integer providing the number of\nbytes the type uses.\n\nThe basic type character codes are:\n\n`t`\n\nBit field (following integer gives the number of bits in the bit field).\n\n`b`\n\nBoolean (integer type where all values are only True or False)\n\n`i`\n\nInteger\n\n`u`\n\nUnsigned integer\n\n`f`\n\nFloating point\n\n`c`\n\nComplex floating point\n\n`m`\n\nTimedelta\n\n`M`\n\nDatetime\n\n`O`\n\nObject (i.e. the memory contains a pointer to `PyObject`)\n\n`S`\n\nString (fixed-length sequence of char)\n\n`U`\n\nUnicode (fixed-length sequence of `Py_UNICODE`)\n\n`V`\n\nOther (void * \u2013 each item is a fixed-size chunk of memory)\n\nA list of tuples providing a more detailed description of the memory layout\nfor each item in the homogeneous array. Each tuple in the list has two or\nthree elements. Normally, this attribute would be used when typestr is\n`V[0-9]+`, but this is not a requirement. The only requirement is that the\nnumber of bytes represented in the typestr key is the same as the total number\nof bytes represented here. The idea is to support descriptions of C-like\nstructs that make up array elements. The elements of each tuple in the list\nare\n\nDefault: `[('', typestr)]`\n\nA 2-tuple whose first argument is an integer (a long integer if necessary)\nthat points to the data-area storing the array contents. This pointer must\npoint to the first element of data (in other words any offset is always\nignored in this case). The second entry in the tuple is a read-only flag (true\nmeans the data area is read-only).\n\nThis attribute can also be an object exposing the buffer interface which will\nbe used to share the data. If this key is not present (or returns None), then\nmemory sharing will be done through the buffer interface of the object itself.\nIn this case, the offset key can be used to indicate the start of the buffer.\nA reference to the object exposing the array interface must be stored by the\nnew object if the memory area is to be secured.\n\nDefault: None\n\nEither `None` to indicate a C-style contiguous array or a Tuple of strides\nwhich provides the number of bytes needed to jump to the next array element in\nthe corresponding dimension. Each entry must be an integer (a Python `int`).\nAs with shape, the values may be larger than can be represented by a C `int`\nor `long`; the calling code should handle this appropriately, either by\nraising an error, or by using `long long` in C. The default is `None` which\nimplies a C-style contiguous memory buffer. In this model, the last dimension\nof the array varies the fastest. For example, the default strides tuple for an\nobject whose array entries are 8 bytes long and whose shape is `(10, 20, 30)`\nwould be `(4800, 240, 8)`\n\nDefault: `None` (C-style contiguous)\n\nNone or an object exposing the array interface. All elements of the mask array\nshould be interpreted only as true or not true indicating which elements of\nthis array are valid. The shape of this object should be `\u201cbroadcastable\u201d` to\nthe shape of the original array.\n\nDefault: None (All array values are valid)\n\nAn integer offset into the array data region. This can only be used when data\nis `None` or returns a `buffer` object.\n\nDefault: 0.\n\nAn integer showing the version of the interface (i.e. 3 for this version). Be\ncareful not to use this to invalidate objects exposing future versions of the\ninterface.\n\nThis approach to the array interface allows for faster access to an array\nusing only one attribute lookup and a well-defined C-structure.\n\nA `PyCapsule` whose `pointer` member contains a pointer to a filled\n`PyArrayInterface` structure. Memory for the structure is dynamically created\nand the `PyCapsule` is also created with an appropriate destructor so the\nretriever of this attribute simply has to apply `Py_DECREF` to the object\nreturned by this attribute when it is finished. Also, either the data needs to\nbe copied out, or a reference to the object exposing this attribute must be\nheld to ensure the data is not freed. Objects exposing the `__array_struct__`\ninterface must also not reallocate their memory if other objects are\nreferencing them.\n\nThe `PyArrayInterface` structure is defined in `numpy/ndarrayobject.h` as:\n\nThe flags member may consist of 5 bits showing how the data should be\ninterpreted and one bit showing how the Interface should be interpreted. The\ndata-bits are `NPY_ARRAY_C_CONTIGUOUS` (0x1), `NPY_ARRAY_F_CONTIGUOUS` (0x2),\n`NPY_ARRAY_ALIGNED` (0x100), `NPY_ARRAY_NOTSWAPPED` (0x200), and\n`NPY_ARRAY_WRITEABLE` (0x400). A final flag `NPY_ARR_HAS_DESCR` (0x800)\nindicates whether or not this structure has the arrdescr field. The field\nshould not be accessed unless this flag is present.\n\nNew since June 16, 2006:\n\nIn the past most implementations used the `desc` member of the `PyCObject`\n(now `PyCapsule`) itself (do not confuse this with the \u201cdescr\u201d member of the\n`PyArrayInterface` structure above \u2014 they are two separate things) to hold the\npointer to the object exposing the interface. This is now an explicit part of\nthe interface. Be sure to take a reference to the object and call\n`PyCapsule_SetContext` before returning the `PyCapsule`, and configure a\ndestructor to decref this reference.\n\nFor clarity it is useful to provide some examples of the type description and\ncorresponding `__array_interface__` \u2018descr\u2019 entries. Thanks to Scott Gilbert\nfor these examples:\n\nIn every case, the \u2018descr\u2019 key is optional, but of course provides more\ninformation which may be important for various applications:\n\nIt should be clear that any structured type could be described using this\ninterface.\n\nThe version 2 interface was very similar. The differences were largely\naesthetic. In particular:\n\nThe `context` member of the `PyCapsule` (formally the `desc` member of the\n`PyCObject`) returned from `__array_struct__` was not specified. Usually, it\nwas the object exposing the array (so that a reference to it could be kept and\ndestroyed when the C-object was destroyed). It is now an explicit requirement\nthat this field be used in some way to hold a reference to the owning object.\n\nNote\n\nUntil August 2020, this said:\n\nNow it must be a tuple whose first element is a string with \u201cPyArrayInterface\nVersion #\u201d and whose second element is the object exposing the array.\n\nThis design was retracted almost immediately after it was proposed, in\n<https://mail.python.org/pipermail/numpy-discussion/2006-June/020995.html>.\nDespite 14 years of documentation to the contrary, at no point was it valid to\nassume that `__array_interface__` capsules held this tuple content.\n\nThere was no `__array_interface__` attribute instead all of the keys (except\nfor version) in the `__array_interface__` dictionary were their own attribute:\nThus to obtain the Python-side information you had to access separately the\nattributes:\n\n"}, {"name": "void **data", "path": "reference/c-api/types-and-structures#c.PyUFuncObject.data", "type": "Python Types and C-Structures", "text": "\nExtra data to be passed to the 1-d vector loops or `NULL` if no extra-data is\nneeded. This C-array must be the same size ( i.e. ntypes) as the functions\narray. `NULL` is used if extra_data is not needed. Several C-API calls for\nUFuncs are just 1-d vector loops that make use of this extra data to receive a\npointer to the actual function to call.\n\n"}, {"name": "void *data", "path": "reference/c-api/types-and-structures#c.PyArrayInterface.data", "type": "Python Types and C-Structures", "text": "\nA pointer to the first element of the array.\n\n"}, {"name": "void *ptr", "path": "reference/c-api/types-and-structures#c.PyUFuncObject.ptr", "type": "Python Types and C-Structures", "text": "\nAny dynamically allocated memory. Currently, this is used for dynamic ufuncs\ncreated from a python function to store room for the types, data, and name\nmembers.\n\n"}, {"name": "void *ptr", "path": "reference/c-api/types-and-structures#c.PyArray_Chunk.ptr", "type": "Python Types and C-Structures", "text": "\nA pointer to the start of the single-segment chunk of memory.\n\n"}, {"name": "void *PyArray_DATA()", "path": "reference/c-api/array#c.PyArray_DATA", "type": "Array API", "text": "\n\n"}, {"name": "void *PyArray_GETPTR1()", "path": "reference/c-api/array#c.PyArray_GETPTR1", "type": "Array API", "text": "\n\n"}, {"name": "void *PyArray_GETPTR2()", "path": "reference/c-api/array#c.PyArray_GETPTR2", "type": "Array API", "text": "\n\n"}, {"name": "void *PyArray_GETPTR3()", "path": "reference/c-api/array#c.PyArray_GETPTR3", "type": "Array API", "text": "\n\n"}, {"name": "void *PyArray_GETPTR4()", "path": "reference/c-api/array#c.PyArray_GETPTR4", "type": "Array API", "text": "\nQuick, inline access to the element at the given coordinates in the ndarray,\nobj, which must have respectively 1, 2, 3, or 4 dimensions (this is not\nchecked). The corresponding i, j, k, and l coordinates can be any integer but\nwill be interpreted as `npy_intp`. You may want to typecast the returned\npointer to the data type of the ndarray.\n\n"}, {"name": "void *PyArray_ITER_DATA()", "path": "reference/c-api/array#c.PyArray_ITER_DATA", "type": "Array API", "text": "\nA pointer to the current element of the array.\n\n"}, {"name": "void *PyArray_malloc()", "path": "reference/c-api/array#c.PyArray_malloc", "type": "Array API", "text": "\n\n"}, {"name": "void *PyArray_MultiIter_DATA()", "path": "reference/c-api/array#c.PyArray_MultiIter_DATA", "type": "Array API", "text": "\nReturn the data-pointer of the i \\\\(^{\\textrm{th}}\\\\) iterator in a multi-\niterator object.\n\n"}, {"name": "void *PyArray_realloc()", "path": "reference/c-api/array#c.PyArray_realloc", "type": "Array API", "text": "\nThese macros use different memory allocators, depending on the constant\n`NPY_USE_PYMEM`. The system malloc is used when `NPY_USE_PYMEM` is 0, if\n`NPY_USE_PYMEM` is 1, then the Python memory allocator is used.\n\n"}, {"name": "void *reserved2", "path": "reference/c-api/types-and-structures#c.PyUFuncObject.reserved2", "type": "Python Types and C-Structures", "text": "\nFor a possible future loop selector with a different signature.\n\n"}, {"name": "void castfunc()", "path": "user/c-info.beyond-basics", "type": "User Guide", "text": "\nOne common algorithmic requirement is to be able to walk over all elements in\na multidimensional array. The array iterator object makes this easy to do in a\ngeneric way that works for arrays of any dimension. Naturally, if you know the\nnumber of dimensions you will be using, then you can always write nested for\nloops to accomplish the iteration. If, however, you want to write code that\nworks with any number of dimensions, then you can make use of the array\niterator. An array iterator object is returned when accessing the .flat\nattribute of an array.\n\nBasic usage is to call `PyArray_IterNew` ( `array` ) where array is an ndarray\nobject (or one of its sub-classes). The returned object is an array-iterator\nobject (the same object returned by the .flat attribute of the ndarray). This\nobject is usually cast to PyArrayIterObject* so that its members can be\naccessed. The only members that are needed are `iter->size` which contains the\ntotal size of the array, `iter->index`, which contains the current 1-d index\ninto the array, and `iter->dataptr` which is a pointer to the data for the\ncurrent element of the array. Sometimes it is also useful to access `iter->ao`\nwhich is a pointer to the underlying ndarray object.\n\nAfter processing data at the current element of the array, the next element of\nthe array can be obtained using the macro `PyArray_ITER_NEXT` ( `iter` ). The\niteration always proceeds in a C-style contiguous fashion (last index varying\nthe fastest). The `PyArray_ITER_GOTO` ( `iter`, `destination` ) can be used to\njump to a particular point in the array, where `destination` is an array of\nnpy_intp data-type with space to handle at least the number of dimensions in\nthe underlying array. Occasionally it is useful to use `PyArray_ITER_GOTO1D` (\n`iter`, `index` ) which will jump to the 1-d index given by the value of\n`index`. The most common usage, however, is given in the following example.\n\nYou can also use `PyArrayIter_Check` ( `obj` ) to ensure you have an iterator\nobject and `PyArray_ITER_RESET` ( `iter` ) to reset an iterator object back to\nthe beginning of the array.\n\nIt should be emphasized at this point that you may not need the array iterator\nif your array is already contiguous (using an array iterator will work but\nwill be slower than the fastest code you could write). The major purpose of\narray iterators is to encapsulate iteration over N-dimensional arrays with\narbitrary strides. They are used in many, many places in the NumPy source code\nitself. If you already know your array is contiguous (Fortran or C), then\nsimply adding the element- size to a running pointer variable will step you\nthrough the array very efficiently. In other words, code like this will\nprobably be faster for you in the contiguous case (assuming doubles).\n\nA common algorithm is to loop over all elements of an array and perform some\nfunction with each element by issuing a function call. As function calls can\nbe time consuming, one way to speed up this kind of algorithm is to write the\nfunction so it takes a vector of data and then write the iteration so the\nfunction call is performed for an entire dimension of data at a time. This\nincreases the amount of work done per function call, thereby reducing the\nfunction-call over-head to a small(er) fraction of the total time. Even if the\ninterior of the loop is performed without a function call it can be\nadvantageous to perform the inner loop over the dimension with the highest\nnumber of elements to take advantage of speed enhancements available on micro-\nprocessors that use pipelining to enhance fundamental operations.\n\nThe `PyArray_IterAllButAxis` ( `array`, `&dim` ) constructs an iterator object\nthat is modified so that it will not iterate over the dimension indicated by\ndim. The only restriction on this iterator object, is that the\n`PyArray_ITER_GOTO1D` ( `it`, `ind` ) macro cannot be used (thus flat indexing\nwon\u2019t work either if you pass this object back to Python \u2014 so you shouldn\u2019t do\nthis). Note that the returned object from this routine is still usually cast\nto PyArrayIterObject *. All that\u2019s been done is to modify the strides and\ndimensions of the returned iterator to simulate iterating over array[\u2026,0,\u2026]\nwhere 0 is placed on the \\\\(\\textrm{dim}^{\\textrm{th}}\\\\) dimension. If dim is\nnegative, then the dimension with the largest axis is found and used.\n\nVery often, it is desirable to iterate over several arrays at the same time.\nThe universal functions are an example of this kind of behavior. If all you\nwant to do is iterate over arrays with the same shape, then simply creating\nseveral iterator objects is the standard procedure. For example, the following\ncode iterates over two arrays assumed to be the same shape and size (actually\nobj1 just has to have at least as many total elements as does obj2):\n\nWhen multiple arrays are involved in an operation, you may want to use the\nsame broadcasting rules that the math operations (i.e. the ufuncs) use. This\ncan be done easily using the `PyArrayMultiIterObject`. This is the object\nreturned from the Python command numpy.broadcast and it is almost as easy to\nuse from C. The function `PyArray_MultiIterNew` ( `n`, `...` ) is used (with\n`n` input objects in place of `...` ). The input objects can be arrays or\nanything that can be converted into an array. A pointer to a\nPyArrayMultiIterObject is returned. Broadcasting has already been accomplished\nwhich adjusts the iterators so that all that needs to be done to advance to\nthe next element in each array is for PyArray_ITER_NEXT to be called for each\nof the inputs. This incrementing is automatically performed by\n`PyArray_MultiIter_NEXT` ( `obj` ) macro (which can handle a multiterator\n`obj` as either a PyArrayMultiIterObject* or a PyObject*). The data from input\nnumber `i` is available using `PyArray_MultiIter_DATA` ( `obj`, `i` ). An\nexample of using this feature follows.\n\nThe function `PyArray_RemoveSmallest` ( `multi` ) can be used to take a multi-\niterator object and adjust all the iterators so that iteration does not take\nplace over the largest dimension (it makes that dimension of size 1). The code\nbeing looped over that makes use of the pointers will very-likely also need\nthe strides data for each of the iterators. This information is stored in\nmulti->iters[i]->strides.\n\nThere are several examples of using the multi-iterator in the NumPy source\ncode as it makes N-dimensional broadcasting-code very simple to write. Browse\nthe source for more examples.\n\nNumPy comes with 24 builtin data-types. While this covers a large majority of\npossible use cases, it is conceivable that a user may have a need for an\nadditional data-type. There is some support for adding an additional data-type\ninto the NumPy system. This additional data- type will behave much like a\nregular data-type except ufuncs must have 1-d loops registered to handle it\nseparately. Also checking for whether or not other data-types can be cast\n\u201csafely\u201d to and from this new type or not will always return \u201ccan cast\u201d unless\nyou also register which types your new data-type can be cast to and from.\n\nThe NumPy source code includes an example of a custom data-type as part of its\ntest suite. The file `_rational_tests.c.src` in the source code directory\n`numpy/numpy/core/src/umath/` contains an implementation of a data-type that\nrepresents a rational number as the ratio of two 32 bit integers.\n\nTo begin to make use of the new data-type, you need to first define a new\nPython type to hold the scalars of your new data-type. It should be acceptable\nto inherit from one of the array scalars if your new type has a binary\ncompatible layout. This will allow your new data type to have the methods and\nattributes of array scalars. New data- types must have a fixed memory size (if\nyou want to define a data-type that needs a flexible representation, like a\nvariable-precision number, then use a pointer to the object as the data-type).\nThe memory layout of the object structure for the new Python type must be\nPyObject_HEAD followed by the fixed-size memory needed for the data- type. For\nexample, a suitable structure for the new Python type is:\n\nAfter you have defined a new Python type object, you must then define a new\n`PyArray_Descr` structure whose typeobject member will contain a pointer to\nthe data-type you\u2019ve just defined. In addition, the required functions in the\n\u201c.f\u201d member must be defined: nonzero, copyswap, copyswapn, setitem, getitem,\nand cast. The more functions in the \u201c.f\u201d member you define, however, the more\nuseful the new data-type will be. It is very important to initialize unused\nfunctions to NULL. This can be achieved using `PyArray_InitArrFuncs` (f).\n\nOnce a new `PyArray_Descr` structure is created and filled with the needed\ninformation and useful functions you call `PyArray_RegisterDataType`\n(new_descr). The return value from this call is an integer providing you with\na unique type_number that specifies your data-type. This type number should be\nstored and made available by your module so that other modules can use it to\nrecognize your data-type (the other mechanism for finding a user-defined data-\ntype number is to search based on the name of the type-object associated with\nthe data-type using `PyArray_TypeNumFromName` ).\n\nYou may want to allow builtin (and other user-defined) data-types to be cast\nautomatically to your data-type. In order to make this possible, you must\nregister a casting function with the data-type you want to be able to cast\nfrom. This requires writing low-level casting functions for each conversion\nyou want to support and then registering these functions with the data-type\ndescriptor. A low-level casting function has the signature.\n\nCast `n` elements `from` one type `to` another. The data to cast from is in a\ncontiguous, correctly-swapped and aligned chunk of memory pointed to by from.\nThe buffer to cast to is also contiguous, correctly-swapped and aligned. The\nfromarr and toarr arguments should only be used for flexible-element-sized\narrays (string, unicode, void).\n\nAn example castfunc is:\n\nThis could then be registered to convert doubles to floats using the code:\n\nBy default, all user-defined data-types are not presumed to be safely castable\nto any builtin data-types. In addition builtin data-types are not presumed to\nbe safely castable to user-defined data-types. This situation limits the\nability of user-defined data-types to participate in the coercion system used\nby ufuncs and other times when automatic coercion takes place in NumPy. This\ncan be changed by registering data-types as safely castable from a particular\ndata-type object. The function `PyArray_RegisterCanCast` (from_descr,\ntotype_number, scalarkind) should be used to specify that the data-type object\nfrom_descr can be cast to the data-type with type number totype_number. If you\nare not trying to alter scalar coercion rules, then use `NPY_NOSCALAR` for the\nscalarkind argument.\n\nIf you want to allow your new data-type to also be able to share in the scalar\ncoercion rules, then you need to specify the scalarkind function in the data-\ntype object\u2019s \u201c.f\u201d member to return the kind of scalar the new data-type\nshould be seen as (the value of the scalar is available to that function).\nThen, you can register data-types that can be cast to separately for each\nscalar kind that may be returned from your user-defined data-type. If you\ndon\u2019t register scalar coercion handling, then all of your user-defined data-\ntypes will be seen as `NPY_NOSCALAR`.\n\nYou may also want to register low-level ufunc loops for your data-type so that\nan ndarray of your data-type can have math applied to it seamlessly.\nRegistering a new loop with exactly the same arg_types signature, silently\nreplaces any previously registered loops for that data-type.\n\nBefore you can register a 1-d loop for a ufunc, the ufunc must be previously\ncreated. Then you call `PyUFunc_RegisterLoopForType` (\u2026) with the information\nneeded for the loop. The return value of this function is `0` if the process\nwas successful and `-1` with an error condition set if it was not successful.\n\nOne of the lesser-used features that has been lurking in Python since 2.2 is\nthe ability to sub-class types in C. This facility is one of the important\nreasons for basing NumPy off of the Numeric code-base which was already in C.\nA sub-type in C allows much more flexibility with regards to memory\nmanagement. Sub-typing in C is not difficult even if you have only a\nrudimentary understanding of how to create new types for Python. While it is\neasiest to sub-type from a single parent type, sub-typing from multiple parent\ntypes is also possible. Multiple inheritance in C is generally less useful\nthan it is in Python because a restriction on Python sub-types is that they\nhave a binary compatible memory layout. Perhaps for this reason, it is\nsomewhat easier to sub-type from a single parent type.\n\nAll C-structures corresponding to Python objects must begin with\n`PyObject_HEAD` (or `PyObject_VAR_HEAD`). In the same way, any sub-type must\nhave a C-structure that begins with exactly the same memory layout as the\nparent type (or all of the parent types in the case of multiple-inheritance).\nThe reason for this is that Python may attempt to access a member of the sub-\ntype structure as if it had the parent structure ( i.e. it will cast a given\npointer to a pointer to the parent structure and then dereference one of it\u2019s\nmembers). If the memory layouts are not compatible, then this attempt will\ncause unpredictable behavior (eventually leading to a memory violation and\nprogram crash).\n\nOne of the elements in `PyObject_HEAD` is a pointer to a type-object\nstructure. A new Python type is created by creating a new type-object\nstructure and populating it with functions and pointers to describe the\ndesired behavior of the type. Typically, a new C-structure is also created to\ncontain the instance-specific information needed for each object of the type\nas well. For example, `&PyArray_Type` is a pointer to the type-object table\nfor the ndarray while a PyArrayObject* variable is a pointer to a particular\ninstance of an ndarray (one of the members of the ndarray structure is, in\nturn, a pointer to the type- object table `&PyArray_Type`). Finally\n`PyType_Ready` (<pointer_to_type_object>) must be called for every new Python\ntype.\n\nTo create a sub-type, a similar procedure must be followed except only\nbehaviors that are different require new entries in the type- object\nstructure. All other entries can be NULL and will be filled in by\n`PyType_Ready` with appropriate functions from the parent type(s). In\nparticular, to create a sub-type in C follow these steps:\n\nIf needed create a new C-structure to handle each instance of your type. A\ntypical C-structure would be:\n\nNotice that the full PyArrayObject is used as the first entry in order to\nensure that the binary layout of instances of the new type is identical to the\nPyArrayObject.\n\nMore information on creating sub-types in C can be learned by reading PEP 253\n(available at https://www.python.org/dev/peps/pep-0253).\n\nSome special methods and attributes are used by arrays in order to facilitate\nthe interoperation of sub-types with the base ndarray type.\n\nSeveral array-creation functions of the ndarray allow specification of a\nparticular sub-type to be created. This allows sub-types to be handled\nseamlessly in many routines. When a sub-type is created in such a fashion,\nhowever, neither the __new__ method nor the __init__ method gets called.\nInstead, the sub-type is allocated and the appropriate instance-structure\nmembers are filled in. Finally, the `__array_finalize__` attribute is looked-\nup in the object dictionary. If it is present and not None, then it can be\neither a CObject containing a pointer to a `PyArray_FinalizeFunc` or it can be\na method taking a single argument (which could be None)\n\nIf the `__array_finalize__` attribute is a CObject, then the pointer must be a\npointer to a function with the signature:\n\nThe first argument is the newly created sub-type. The second argument (if not\nNULL) is the \u201cparent\u201d array (if the array was created using slicing or some\nother operation where a clearly-distinguishable parent is present). This\nroutine can do anything it wants to. It should return a -1 on error and 0\notherwise.\n\nIf the `__array_finalize__` attribute is not None nor a CObject, then it must\nbe a Python method that takes the parent array as an argument (which could be\nNone if there is no parent), and returns nothing. Errors in this method will\nbe caught and handled.\n\nThis attribute allows simple but flexible determination of which sub- type\nshould be considered \u201cprimary\u201d when an operation involving two or more sub-\ntypes arises. In operations where different sub-types are being used, the sub-\ntype with the largest `__array_priority__` attribute will determine the sub-\ntype of the output(s). If two sub- types have the same `__array_priority__`\nthen the sub-type of the first argument determines the output. The default\n`__array_priority__` attribute returns a value of 0.0 for the base ndarray\ntype and 1.0 for a sub-type. This attribute can also be defined by objects\nthat are not sub-types of the ndarray and can be used to determine which\n`__array_wrap__` method should be called for the return output.\n\nAny class or type can define this method which should take an ndarray argument\nand return an instance of the type. It can be seen as the opposite of the\n`__array__` method. This method is used by the ufuncs (and other NumPy\nfunctions) to allow other objects to pass through. For Python >2.4, it can\nalso be used to write a decorator that converts a function that works only\nwith ndarrays to one that works with any type with `__array__` and\n`__array_wrap__` methods.\n\n"}, {"name": "void copyswap()", "path": "reference/c-api/types-and-structures#c.PyArray_ArrFuncs.copyswap", "type": "Python Types and C-Structures", "text": "\nThese members are both pointers to functions to copy data from src to dest and\nswap if indicated. The value of arr is only used for flexible ( `NPY_STRING`,\n`NPY_UNICODE`, and `NPY_VOID` ) arrays (and is obtained from\n`arr->descr->elsize` ). The second function copies a single value, while the\nfirst loops over n values with the provided strides. These functions can deal\nwith misbehaved src data. If src is NULL then no copy is performed. If swap is\n0, then no byteswapping occurs. It is assumed that dest and src do not\noverlap. If they overlap, then use `memmove` (\u2026) first followed by\n`copyswap(n)` with NULL valued `src`.\n\n"}, {"name": "void copyswapn()", "path": "reference/c-api/types-and-structures#c.PyArray_ArrFuncs.copyswapn", "type": "Python Types and C-Structures", "text": "\n\n"}, {"name": "void dotfunc()", "path": "reference/c-api/types-and-structures#c.PyArray_ArrFuncs.dotfunc", "type": "Python Types and C-Structures", "text": "\nA pointer to a function that multiplies two `n` -length sequences together,\nadds them, and places the result in element pointed to by `op` of `arr`. The\nstart of the two sequences are pointed to by `ip1` and `ip2`. To get to the\nnext element in each sequence requires a jump of `is1` and `is2` bytes,\nrespectively. This function requires behaved (though not necessarily\ncontiguous) memory.\n\n"}, {"name": "void fastclip()", "path": "reference/c-api/types-and-structures#c.PyArray_ArrFuncs.fastclip", "type": "Python Types and C-Structures", "text": "\nDeprecated since version 1.17: The use of this function will give a\ndeprecation warning when `np.clip`. Instead of this function, the datatype\nmust instead use `PyUFunc_RegisterLoopForDescr` to attach a custom loop to\n`np.core.umath.clip`, `np.minimum`, and `np.maximum`.\n\nDeprecated since version 1.19: Setting this function is deprecated and should\nalways be `NULL`, if set, it will be ignored.\n\nA function that reads `n_in` items from `in`, and writes to `out` the read\nvalue if it is within the limits pointed to by `min` and `max`, or the\ncorresponding limit if outside. The memory segments must be contiguous and\nbehaved, and either `min` or `max` may be `NULL`, but not both.\n\n"}, {"name": "void fastputmask()", "path": "reference/c-api/types-and-structures#c.PyArray_ArrFuncs.fastputmask", "type": "Python Types and C-Structures", "text": "\nDeprecated since version 1.19: Setting this function is deprecated and should\nalways be `NULL`, if set, it will be ignored.\n\nA function that takes a pointer `in` to an array of `n_in` items, a pointer\n`mask` to an array of `n_in` boolean values, and a pointer `vals` to an array\nof `nv` items. Items from `vals` are copied into `in` wherever the value in\n`mask` is non-zero, tiling `vals` as needed if `nv < n_in`. All arrays must be\ncontiguous and behaved.\n\n"}, {"name": "void fasttake()", "path": "reference/c-api/types-and-structures#c.PyArray_ArrFuncs.fasttake", "type": "Python Types and C-Structures", "text": "\nDeprecated since version 1.19: Setting this function is deprecated and should\nalways be `NULL`, if set, it will be ignored.\n\nA function that takes a pointer `src` to a C contiguous, behaved segment,\ninterpreted as a 3-dimensional array of shape `(n_outer, nindarray, nelem)`, a\npointer `indarray` to a contiguous, behaved segment of `m_middle` integer\nindices, and a pointer `dest` to a C contiguous, behaved segment, interpreted\nas a 3-dimensional array of shape `(n_outer, m_middle, nelem)`. The indices in\n`indarray` are used to index `src` along the second dimension, and copy the\ncorresponding chunks of `nelem` items into `dest`. `clipmode` (which can take\non the values `NPY_RAISE`, `NPY_WRAP` or `NPY_CLIP`) determines how will\nindices smaller than 0 or larger than `nindarray` will be handled.\n\n"}, {"name": "void fill()", "path": "reference/c-api/types-and-structures#c.PyArray_ArrFuncs.fill", "type": "Python Types and C-Structures", "text": "\nA pointer to a function that fills a contiguous array of given length with\ndata. The first two elements of the array must already be filled- in. From\nthese two values, a delta will be computed and the values from item 3 to the\nend will be computed by repeatedly adding this computed delta. The data buffer\nmust be well-behaved.\n\n"}, {"name": "void fillwithscalar()", "path": "reference/c-api/types-and-structures#c.PyArray_ArrFuncs.fillwithscalar", "type": "Python Types and C-Structures", "text": "\nA pointer to a function that fills a contiguous `buffer` of the given `length`\nwith a single scalar `value` whose address is given. The final argument is the\narray which is needed to get the itemsize for variable-length arrays.\n\n"}, {"name": "void functions()", "path": "reference/c-api/types-and-structures#c.PyUFuncObject.functions", "type": "Python Types and C-Structures", "text": "\nAn array of function pointers \u2014 one for each data type supported by the ufunc.\nThis is the vector loop that is called to implement the underlying function\ndims [0] times. The first argument, args, is an array of nargs pointers to\nbehaved memory. Pointers to the data for the input arguments are first,\nfollowed by the pointers to the data for the output arguments. How many bytes\nmust be skipped to get to the next element in the sequence is specified by the\ncorresponding entry in the steps array. The last argument allows the loop to\nreceive extra information. This is commonly used so that a single, generic\nvector loop can be used for multiple functions. In this case, the actual\nscalar function to call is passed in as extradata. The size of this function\npointer array is ntypes.\n\n"}, {"name": "void import_ufunc()", "path": "reference/c-api/ufunc#c.import_ufunc", "type": "UFunc API", "text": "\nThese are the constants and functions for accessing the ufunc C-API from\nextension modules in precisely the same way as the array C-API can be\naccessed. The `import_ufunc` () function must always be called (in the\ninitialization subroutine of the extension module). If your extension module\nis in one file then that is all that is required. The other two constants are\nuseful if your extension module makes use of multiple files. In that case,\ndefine `PY_UFUNC_UNIQUE_SYMBOL` to something unique to your code and then in\nsource files that do not contain the module initialization function but still\nneed access to the UFUNC API, define `PY_UFUNC_UNIQUE_SYMBOL` to the same name\nused previously and also define `NO_IMPORT_UFUNC`.\n\nThe C-API is actually an array of function pointers. This array is created\n(and pointed to by a global variable) by import_ufunc. The global variable is\neither statically defined or allowed to be seen by other files depending on\nthe state of `PY_UFUNC_UNIQUE_SYMBOL` and `NO_IMPORT_UFUNC`.\n\n"}, {"name": "void NPY_AUXDATA_FREE()", "path": "reference/c-api/array#c.NPY_AUXDATA_FREE", "type": "Array API", "text": "\nA macro which calls the auxdata\u2019s free function appropriately, does nothing if\nauxdata is NULL.\n\n"}, {"name": "void NPY_BEGIN_THREADS_DESCR()", "path": "reference/c-api/array#c.NPY_BEGIN_THREADS_DESCR", "type": "Array API", "text": "\nUseful to release the GIL only if dtype does not contain arbitrary Python\nobjects which may need the Python interpreter during execution of the loop.\n\n"}, {"name": "void NPY_BEGIN_THREADS_THRESHOLDED()", "path": "reference/c-api/array#c.NPY_BEGIN_THREADS_THRESHOLDED", "type": "Array API", "text": "\nUseful to release the GIL only if loop_size exceeds a minimum threshold,\ncurrently set to 500. Should be matched with a `NPY_END_THREADS` to regain the\nGIL.\n\n"}, {"name": "void NPY_END_THREADS_DESCR()", "path": "reference/c-api/array#c.NPY_END_THREADS_DESCR", "type": "Array API", "text": "\nUseful to regain the GIL in situations where it was released using the BEGIN\nform of this macro.\n\n"}, {"name": "void npy_set_floatstatus_divbyzero()", "path": "reference/c-api/coremath#c.npy_set_floatstatus_divbyzero", "type": "NumPy core libraries", "text": "\nSet the divide by zero floating point exception\n\nNew in version 1.6.0.\n\n"}, {"name": "void npy_set_floatstatus_invalid()", "path": "reference/c-api/coremath#c.npy_set_floatstatus_invalid", "type": "NumPy core libraries", "text": "\nSet the invalid floating point exception\n\nNew in version 1.6.0.\n\n"}, {"name": "void npy_set_floatstatus_overflow()", "path": "reference/c-api/coremath#c.npy_set_floatstatus_overflow", "type": "NumPy core libraries", "text": "\nSet the overflow floating point exception\n\nNew in version 1.6.0.\n\n"}, {"name": "void npy_set_floatstatus_underflow()", "path": "reference/c-api/coremath#c.npy_set_floatstatus_underflow", "type": "NumPy core libraries", "text": "\nSet the underflow floating point exception\n\nNew in version 1.6.0.\n\n"}, {"name": "void NpyIter_GetInnerFixedStrideArray()", "path": "reference/c-api/iterator#c.NpyIter_GetInnerFixedStrideArray", "type": "Array Iterator API", "text": "\nGets an array of strides which are fixed, or will not change during the entire\niteration. For strides that may change, the value NPY_MAX_INTP is placed in\nthe stride.\n\nOnce the iterator is prepared for iteration (after a reset if\n`NPY_ITER_DELAY_BUFALLOC` was used), call this to get the strides which may be\nused to select a fast inner loop function. For example, if the stride is 0,\nthat means the inner loop can always load its value into a variable once, then\nuse the variable throughout the loop, or if the stride equals the itemsize, a\ncontiguous version for that operand may be used.\n\nThis function may be safely called without holding the Python GIL.\n\n"}, {"name": "void NpyIter_GetIterIndexRange()", "path": "reference/c-api/iterator#c.NpyIter_GetIterIndexRange", "type": "Array Iterator API", "text": "\nGets the `iterindex` sub-range that is being iterated. If `NPY_ITER_RANGED`\nwas not specified, this always returns the range `[0,\nNpyIter_IterSize(iter))`.\n\n"}, {"name": "void NpyIter_GetReadFlags()", "path": "reference/c-api/iterator#c.NpyIter_GetReadFlags", "type": "Array Iterator API", "text": "\nFills `nop` flags. Sets `outreadflags[i]` to 1 if `op[i]` can be read from,\nand to 0 if not.\n\n"}, {"name": "void NpyIter_GetWriteFlags()", "path": "reference/c-api/iterator#c.NpyIter_GetWriteFlags", "type": "Array Iterator API", "text": "\nFills `nop` flags. Sets `outwriteflags[i]` to 1 if `op[i]` can be written to,\nand to 0 if not.\n\n"}, {"name": "void PyArray_ArrayType()", "path": "reference/c-api/array#c.PyArray_ArrayType", "type": "Array API", "text": "\nThis function is superseded by `PyArray_ResultType`.\n\nThis function works similarly to `PyArray_ObjectType` (\u2026) except it handles\nflexible arrays. The mintype argument can have an itemsize member and the\nouttype argument will have an itemsize member at least as big but perhaps\nbigger depending on the object op.\n\n"}, {"name": "void PyArray_CastScalarToCtype()", "path": "reference/c-api/array#c.PyArray_CastScalarToCtype", "type": "Array API", "text": "\nReturn the data (cast to the data type indicated by outcode) from the array-\nscalar, scalar, into the memory pointed to by ctypeptr (which must be large\nenough to handle the incoming memory).\n\n"}, {"name": "void PyArray_CLEARFLAGS()", "path": "reference/c-api/array#c.PyArray_CLEARFLAGS", "type": "Array API", "text": "\nNew in version 1.7.\n\nClears the specified array flags. This function does no validation, and\nassumes that you know what you\u2019re doing.\n\n"}, {"name": "void PyArray_DiscardWritebackIfCopy()", "path": "reference/c-api/array#c.PyArray_DiscardWritebackIfCopy", "type": "Array API", "text": "\nIf `obj.flags` has `NPY_ARRAY_WRITEBACKIFCOPY` or (deprecated)\n`NPY_ARRAY_UPDATEIFCOPY`, this function clears the flags, `DECREF` s\n`obj->base` and makes it writeable, and sets `obj->base` to NULL. In contrast\nto `PyArray_DiscardWritebackIfCopy` it makes no attempt to copy the data from\n`obj->base` This undoes `PyArray_SetWritebackIfCopyBase`. Usually this is\ncalled after an error when you are finished with `obj`, just before\n`Py_DECREF(obj)`. It may be called multiple times, or with `NULL` input.\n\n"}, {"name": "void PyArray_ENABLEFLAGS()", "path": "reference/c-api/array#c.PyArray_ENABLEFLAGS", "type": "Array API", "text": "\nNew in version 1.7.\n\nEnables the specified array flags. This function does no validation, and\nassumes that you know what you\u2019re doing.\n\n"}, {"name": "void PyArray_FillObjectArray()", "path": "reference/c-api/array#c.PyArray_FillObjectArray", "type": "Array API", "text": "\nFill a newly created array with a single value obj at all locations in the\nstructure with object data-types. No checking is performed but arr must be of\ndata-type `NPY_OBJECT` and be single-segment and uninitialized (no previous\nobjects in position). Use `PyArray_XDECREF` (arr) if you need to decrement all\nthe items in the object array prior to calling this function.\n\n"}, {"name": "void PyArray_FILLWBYTE()", "path": "reference/c-api/array#c.PyArray_FILLWBYTE", "type": "Array API", "text": "\nFill the array pointed to by obj \u2014which must be a (subclass of) ndarray\u2014with\nthe contents of val (evaluated as a byte). This macro calls memset, so obj\nmust be contiguous.\n\n"}, {"name": "void PyArray_free()", "path": "reference/c-api/array#c.PyArray_free", "type": "Array API", "text": "\n\n"}, {"name": "void PyArray_Item_INCREF()", "path": "reference/c-api/array#c.PyArray_Item_INCREF", "type": "Array API", "text": "\nA function to INCREF all the objects at the location ptr according to the\ndata-type dtype. If ptr is the start of a structured type with an object at\nany offset, then this will (recursively) increment the reference count of all\nobject-like items in the structured type.\n\n"}, {"name": "void PyArray_Item_XDECREF()", "path": "reference/c-api/array#c.PyArray_Item_XDECREF", "type": "Array API", "text": "\nA function to XDECREF all the object-like items at the location ptr as\nrecorded in the data-type, dtype. This works recursively so that if `dtype`\nitself has fields with data-types that contain object-like items, all the\nobject-like fields will be XDECREF `'d`.\n\n"}, {"name": "void PyArray_ITER_GOTO()", "path": "reference/c-api/array#c.PyArray_ITER_GOTO", "type": "Array API", "text": "\nSet the iterator index, dataptr, and coordinates members to the location in\nthe array indicated by the N-dimensional c-array, destination, which must have\nsize at least iterator ->nd_m1+1.\n\n"}, {"name": "void PyArray_ITER_GOTO1D()", "path": "reference/c-api/array#c.PyArray_ITER_GOTO1D", "type": "Array API", "text": "\nSet the iterator index and dataptr to the location in the array indicated by\nthe integer index which points to an element in the C-styled flattened array.\n\n"}, {"name": "void PyArray_ITER_NEXT()", "path": "reference/c-api/array#c.PyArray_ITER_NEXT", "type": "Array API", "text": "\nIncremement the index and the dataptr members of the iterator to point to the\nnext element of the array. If the array is not (C-style) contiguous, also\nincrement the N-dimensional coordinates array.\n\n"}, {"name": "void PyArray_ITER_RESET()", "path": "reference/c-api/array#c.PyArray_ITER_RESET", "type": "Array API", "text": "\nReset an iterator to the beginning of the array.\n\n"}, {"name": "void PyArray_MapIterNext()", "path": "reference/c-api/array#c.PyArray_MapIterNext", "type": "Array API", "text": "\nThis function needs to update the state of the map iterator and point\n`mit->dataptr` to the memory-location of the next object.\n\nNote that this function never handles an extra operand but provides\ncompatibility for an old (exposed) API.\n\n"}, {"name": "void PyArray_MapIterSwapAxes()", "path": "reference/c-api/array#c.PyArray_MapIterSwapAxes", "type": "Array API", "text": "\nSwap the axes to or from their inserted form. `MapIter` always puts the\nadvanced (array) indices first in the iteration. But if they are consecutive,\nit will insert/transpose them back before returning. This is stored as\n`mit->consec != 0` (the place where they are inserted). For assignments, the\nopposite happens: the values to be assigned are transposed (`getmap=1` instead\nof `getmap=0`). `getmap=0` and `getmap=1` undo the other operation.\n\n"}, {"name": "void PyArray_MultiIter_GOTO()", "path": "reference/c-api/array#c.PyArray_MultiIter_GOTO", "type": "Array API", "text": "\nAdvance each iterator in a multi-iterator object, multi, to the given \\\\(N\\\\)\n-dimensional destination where \\\\(N\\\\) is the number of dimensions in the\nbroadcasted array.\n\n"}, {"name": "void PyArray_MultiIter_GOTO1D()", "path": "reference/c-api/array#c.PyArray_MultiIter_GOTO1D", "type": "Array API", "text": "\nAdvance each iterator in a multi-iterator object, multi, to the corresponding\nlocation of the index into the flattened broadcasted array.\n\n"}, {"name": "void PyArray_MultiIter_NEXT()", "path": "reference/c-api/array#c.PyArray_MultiIter_NEXT", "type": "Array API", "text": "\nAdvance each iterator in a multi-iterator object, multi, to its next\n(broadcasted) element.\n\n"}, {"name": "void PyArray_MultiIter_NEXTi()", "path": "reference/c-api/array#c.PyArray_MultiIter_NEXTi", "type": "Array API", "text": "\nAdvance the pointer of only the i \\\\(^{\\textrm{th}}\\\\) iterator.\n\n"}, {"name": "void PyArray_MultiIter_RESET()", "path": "reference/c-api/array#c.PyArray_MultiIter_RESET", "type": "Array API", "text": "\nReset all the iterators to the beginning in a multi-iterator object, multi.\n\n"}, {"name": "void PyArray_ScalarAsCtype()", "path": "reference/c-api/array#c.PyArray_ScalarAsCtype", "type": "Array API", "text": "\nReturn in ctypeptr a pointer to the actual value in an array scalar. There is\nno error checking so scalar must be an array-scalar object, and ctypeptr must\nhave enough space to hold the correct type. For flexible-sized types, a\npointer to the data is copied into the memory of ctypeptr, for all other\ntypes, the actual data is copied into the address pointed to by ctypeptr.\n\n"}, {"name": "void PyArray_SetStringFunction()", "path": "reference/c-api/array#c.PyArray_SetStringFunction", "type": "Array API", "text": "\nThis function allows you to alter the tp_str and tp_repr methods of the array\nobject to any Python function. Thus you can alter what happens for all arrays\nwhen str(arr) or repr(arr) is called from Python. The function to be called is\npassed in as op. If repr is non-zero, then this function will be called in\nresponse to repr(arr), otherwise the function will be called in response to\nstr(arr). No check on whether or not op is callable is performed. The callable\npassed in to op should expect an array argument and should return a string to\nbe printed.\n\n"}, {"name": "void PyArray_UpdateFlags()", "path": "reference/c-api/array#c.PyArray_UpdateFlags", "type": "Array API", "text": "\nThe `NPY_ARRAY_C_CONTIGUOUS`, `NPY_ARRAY_ALIGNED`, and\n`NPY_ARRAY_F_CONTIGUOUS` array flags can be \u201ccalculated\u201d from the array object\nitself. This routine updates one or more of these flags of arr as specified in\nflagmask by performing the required calculation.\n\n"}, {"name": "void PyArray_XDECREF_ERR()", "path": "reference/c-api/array#c.PyArray_XDECREF_ERR", "type": "Array API", "text": "\nDeprecated in 1.14, use `PyArray_DiscardWritebackIfCopy` followed by\n`Py_XDECREF`\n\nDECREF\u2019s an array object which may have the (deprecated)\n`NPY_ARRAY_UPDATEIFCOPY` or `NPY_ARRAY_WRITEBACKIFCOPY` flag set without\ncausing the contents to be copied back into the original array. Resets the\n`NPY_ARRAY_WRITEABLE` flag on the base object. This is useful for recovering\nfrom an error condition when writeback semantics are used, but will lead to\nwrong results.\n\n"}, {"name": "void PyDataMem_EventHookFunc()", "path": "reference/c-api/data_memory#c.PyDataMem_EventHookFunc", "type": "Memory management in NumPy", "text": "\nThis function will be called during data memory manipulation\n\n"}, {"name": "void PyDataMem_FREE()", "path": "reference/c-api/array#c.PyDataMem_FREE", "type": "Array API", "text": "\n\n"}, {"name": "void PyDimMem_FREE()", "path": "reference/c-api/array#c.PyDimMem_FREE", "type": "Array API", "text": "\n\n"}, {"name": "void PyUFunc_clearfperr()", "path": "reference/c-api/ufunc#c.PyUFunc_clearfperr", "type": "UFunc API", "text": "\nClear the IEEE error flags.\n\n"}, {"name": "void PyUFunc_d_d()", "path": "reference/c-api/ufunc#c.PyUFunc_d_d", "type": "UFunc API", "text": "\n\n"}, {"name": "void PyUFunc_D_D()", "path": "reference/c-api/ufunc#c.PyUFunc_D_D", "type": "UFunc API", "text": "\n\n"}, {"name": "void PyUFunc_DD_D()", "path": "reference/c-api/ufunc#c.PyUFunc_DD_D", "type": "UFunc API", "text": "\n\n"}, {"name": "void PyUFunc_dd_d()", "path": "reference/c-api/ufunc#c.PyUFunc_dd_d", "type": "UFunc API", "text": "\n\n"}, {"name": "void PyUFunc_e_e()", "path": "reference/c-api/ufunc#c.PyUFunc_e_e", "type": "UFunc API", "text": "\n\n"}, {"name": "void PyUFunc_e_e_As_d_d()", "path": "reference/c-api/ufunc#c.PyUFunc_e_e_As_d_d", "type": "UFunc API", "text": "\nType specific, core 1-d functions for ufuncs where each calculation is\nobtained by calling a function taking one input argument and returning one\noutput. This function is passed in `func`. The letters correspond to\ndtypechar\u2019s of the supported data types ( `e` \\- half, `f` \\- float, `d` \\-\ndouble, `g` \\- long double, `F` \\- cfloat, `D` \\- cdouble, `G` \\-\nclongdouble). The argument func must support the same signature. The _As_X_X\nvariants assume ndarray\u2019s of one data type but cast the values to use an\nunderlying function that takes a different data type. Thus,\n`PyUFunc_f_f_As_d_d` uses ndarrays of data type `NPY_FLOAT` but calls out to a\nC-function that takes double and returns double.\n\n"}, {"name": "void PyUFunc_e_e_As_f_f()", "path": "reference/c-api/ufunc#c.PyUFunc_e_e_As_f_f", "type": "UFunc API", "text": "\n\n"}, {"name": "void PyUFunc_ee_e()", "path": "reference/c-api/ufunc#c.PyUFunc_ee_e", "type": "UFunc API", "text": "\n\n"}, {"name": "void PyUFunc_ee_e_As_dd_d()", "path": "reference/c-api/ufunc#c.PyUFunc_ee_e_As_dd_d", "type": "UFunc API", "text": "\nType specific, core 1-d functions for ufuncs where each calculation is\nobtained by calling a function taking two input arguments and returning one\noutput. The underlying function to call is passed in as func. The letters\ncorrespond to dtypechar\u2019s of the specific data type supported by the general-\npurpose function. The argument `func` must support the corresponding\nsignature. The `_As_XX_X` variants assume ndarrays of one data type but cast\nthe values at each iteration of the loop to use the underlying function that\ntakes a different data type.\n\n"}, {"name": "void PyUFunc_ee_e_As_ff_f()", "path": "reference/c-api/ufunc#c.PyUFunc_ee_e_As_ff_f", "type": "UFunc API", "text": "\n\n"}, {"name": "void PyUFunc_F_F()", "path": "reference/c-api/ufunc#c.PyUFunc_F_F", "type": "UFunc API", "text": "\n\n"}, {"name": "void PyUFunc_f_f()", "path": "reference/c-api/ufunc#c.PyUFunc_f_f", "type": "UFunc API", "text": "\n\n"}, {"name": "void PyUFunc_F_F_As_D_D()", "path": "reference/c-api/ufunc#c.PyUFunc_F_F_As_D_D", "type": "UFunc API", "text": "\n\n"}, {"name": "void PyUFunc_ff_f()", "path": "reference/c-api/ufunc#c.PyUFunc_ff_f", "type": "UFunc API", "text": "\n\n"}, {"name": "void PyUFunc_FF_F()", "path": "reference/c-api/ufunc#c.PyUFunc_FF_F", "type": "UFunc API", "text": "\n\n"}, {"name": "void PyUFunc_ff_f_As_dd_d()", "path": "reference/c-api/ufunc#c.PyUFunc_ff_f_As_dd_d", "type": "UFunc API", "text": "\n\n"}, {"name": "void PyUFunc_FF_F_As_DD_D()", "path": "reference/c-api/ufunc#c.PyUFunc_FF_F_As_DD_D", "type": "UFunc API", "text": "\n\n"}, {"name": "void PyUFunc_g_g()", "path": "reference/c-api/ufunc#c.PyUFunc_g_g", "type": "UFunc API", "text": "\n\n"}, {"name": "void PyUFunc_G_G()", "path": "reference/c-api/ufunc#c.PyUFunc_G_G", "type": "UFunc API", "text": "\n\n"}, {"name": "void PyUFunc_GetPyValues()", "path": "reference/c-api/ufunc#c.PyUFunc_GetPyValues", "type": "UFunc API", "text": "\nGet the Python values used for ufunc processing from the thread-local storage\narea unless the defaults have been set in which case the name lookup is\nbypassed. The name is placed as a string in the first element of *errobj. The\nsecond element is the looked-up function to call on error callback. The value\nof the looked-up buffer-size to use is passed into bufsize, and the value of\nthe error mask is placed into errmask.\n\n"}, {"name": "void PyUFunc_gg_g()", "path": "reference/c-api/ufunc#c.PyUFunc_gg_g", "type": "UFunc API", "text": "\n\n"}, {"name": "void PyUFunc_GG_G()", "path": "reference/c-api/ufunc#c.PyUFunc_GG_G", "type": "UFunc API", "text": "\n\n"}, {"name": "void PyUFunc_O_O()", "path": "reference/c-api/ufunc#c.PyUFunc_O_O", "type": "UFunc API", "text": "\n\n"}, {"name": "void PyUFunc_O_O_method()", "path": "reference/c-api/ufunc#c.PyUFunc_O_O_method", "type": "UFunc API", "text": "\nThis general purpose 1-d core function assumes that func is a string\nrepresenting a method of the input object. For each iteration of the loop, the\nPython object is extracted from the array and its func method is called\nreturning the result to the output array.\n\n"}, {"name": "void PyUFunc_On_Om()", "path": "reference/c-api/ufunc#c.PyUFunc_On_Om", "type": "UFunc API", "text": "\nThis is the 1-d core function used by the dynamic ufuncs created by\numath.frompyfunc(function, nin, nout). In this case func is a pointer to a\n`PyUFunc_PyFuncData` structure which has definition\n\nAt each iteration of the loop, the nin input objects are extracted from their\nobject arrays and placed into an argument tuple, the Python callable is called\nwith the input arguments, and the nout outputs are placed into their object\narrays.\n\n"}, {"name": "void PyUFunc_OO_O()", "path": "reference/c-api/ufunc#c.PyUFunc_OO_O", "type": "UFunc API", "text": "\nOne-input, one-output, and two-input, one-output core 1-d functions for the\n`NPY_OBJECT` data type. These functions handle reference count issues and\nreturn early on error. The actual function to call is func and it must accept\ncalls with the signature `(PyObject*) (PyObject*)` for `PyUFunc_O_O` or\n`(PyObject*)(PyObject *, PyObject *)` for `PyUFunc_OO_O`.\n\n"}, {"name": "void PyUFunc_OO_O_method()", "path": "reference/c-api/ufunc#c.PyUFunc_OO_O_method", "type": "UFunc API", "text": "\nThis general purpose 1-d core function assumes that func is a string\nrepresenting a method of the input object that takes one argument. The first\nargument in args is the method whose function is called, the second argument\nin args is the argument passed to the function. The output of the function is\nstored in the third entry of args.\n\n"}, {"name": "void random_multinomial()", "path": "reference/random/c-api#c.random_multinomial", "type": "C API for random", "text": "\n\n"}, {"name": "void random_multivariate_hypergeometric_marginals()", "path": "reference/random/c-api#c.random_multivariate_hypergeometric_marginals", "type": "C API for random", "text": "\n\n"}, {"name": "void random_standard_exponential_fill()", "path": "reference/random/c-api#c.random_standard_exponential_fill", "type": "C API for random", "text": "\n\n"}, {"name": "void random_standard_exponential_fill_f()", "path": "reference/random/c-api#c.random_standard_exponential_fill_f", "type": "C API for random", "text": "\n\n"}, {"name": "void random_standard_exponential_inv_fill()", "path": "reference/random/c-api#c.random_standard_exponential_inv_fill", "type": "C API for random", "text": "\n\n"}, {"name": "void random_standard_exponential_inv_fill_f()", "path": "reference/random/c-api#c.random_standard_exponential_inv_fill_f", "type": "C API for random", "text": "\n\n"}, {"name": "void random_standard_normal_fill()", "path": "reference/random/c-api#c.random_standard_normal_fill", "type": "C API for random", "text": "\n\n"}, {"name": "void random_standard_normal_fill_f()", "path": "reference/random/c-api#c.random_standard_normal_fill_f", "type": "C API for random", "text": "\n\n"}, {"name": "void random_standard_uniform_fill()", "path": "reference/random/c-api#c.random_standard_uniform_fill", "type": "C API for random", "text": "\n\n"}, {"name": "void random_standard_uniform_fill_f()", "path": "reference/random/c-api#c.random_standard_uniform_fill_f", "type": "C API for random", "text": "\n\n"}, {"name": "What is NumPy?", "path": "user/whatisnumpy", "type": "User Guide", "text": "\nNumPy is the fundamental package for scientific computing in Python. It is a\nPython library that provides a multidimensional array object, various derived\nobjects (such as masked arrays and matrices), and an assortment of routines\nfor fast operations on arrays, including mathematical, logical, shape\nmanipulation, sorting, selecting, I/O, discrete Fourier transforms, basic\nlinear algebra, basic statistical operations, random simulation and much more.\n\nAt the core of the NumPy package, is the `ndarray` object. This encapsulates\nn-dimensional arrays of homogeneous data types, with many operations being\nperformed in compiled code for performance. There are several important\ndifferences between NumPy arrays and the standard Python sequences:\n\nThe points about sequence size and speed are particularly important in\nscientific computing. As a simple example, consider the case of multiplying\neach element in a 1-D sequence with the corresponding element in another\nsequence of the same length. If the data are stored in two Python lists, `a`\nand `b`, we could iterate over each element:\n\nThis produces the correct answer, but if `a` and `b` each contain millions of\nnumbers, we will pay the price for the inefficiencies of looping in Python. We\ncould accomplish the same task much more quickly in C by writing (for clarity\nwe neglect variable declarations and initializations, memory allocation, etc.)\n\nThis saves all the overhead involved in interpreting the Python code and\nmanipulating Python objects, but at the expense of the benefits gained from\ncoding in Python. Furthermore, the coding work required increases with the\ndimensionality of our data. In the case of a 2-D array, for example, the C\ncode (abridged as before) expands to\n\nNumPy gives us the best of both worlds: element-by-element operations are the\n\u201cdefault mode\u201d when an `ndarray` is involved, but the element-by-element\noperation is speedily executed by pre-compiled C code. In NumPy\n\ndoes what the earlier examples do, at near-C speeds, but with the code\nsimplicity we expect from something based on Python. Indeed, the NumPy idiom\nis even simpler! This last example illustrates two of NumPy\u2019s features which\nare the basis of much of its power: vectorization and broadcasting.\n\nVectorization describes the absence of any explicit looping, indexing, etc.,\nin the code - these things are taking place, of course, just \u201cbehind the\nscenes\u201d in optimized, pre-compiled C code. Vectorized code has many\nadvantages, among which are:\n\nBroadcasting is the term used to describe the implicit element-by-element\nbehavior of operations; generally speaking, in NumPy all operations, not just\narithmetic operations, but logical, bit-wise, functional, etc., behave in this\nimplicit element-by-element fashion, i.e., they broadcast. Moreover, in the\nexample above, `a` and `b` could be multidimensional arrays of the same shape,\nor a scalar and an array, or even two arrays of with different shapes,\nprovided that the smaller array is \u201cexpandable\u201d to the shape of the larger in\nsuch a way that the resulting broadcast is unambiguous. For detailed \u201crules\u201d\nof broadcasting see Broadcasting.\n\nNumPy fully supports an object-oriented approach, starting, once again, with\n`ndarray`. For example, `ndarray` is a class, possessing numerous methods and\nattributes. Many of its methods are mirrored by functions in the outer-most\nNumPy namespace, allowing the programmer to code in whichever paradigm they\nprefer. This flexibility has allowed the NumPy array dialect and NumPy\n`ndarray` class to become the de-facto language of multi-dimensional data\ninterchange used in Python.\n\n"}, {"name": "What\u2019s New or Different", "path": "reference/random/new-or-different", "type": "What\u2019s New or Different", "text": "\nWarning\n\nThe Box-Muller method used to produce NumPy\u2019s normals is no longer available\nin `Generator`. It is not possible to reproduce the exact random values using\n`Generator` for the normal distribution or any other distribution that relies\non the normal such as the `Generator.gamma` or `Generator.standard_t`. If you\nrequire bitwise backward compatible streams, use `RandomState`, i.e.,\n`RandomState.gamma` or `RandomState.standard_t`.\n\nQuick comparison of legacy mtrand to the new `Generator`\n\nFeature\n\nOlder Equivalent\n\nNotes\n\n`Generator`\n\n`RandomState`\n\n`Generator` requires a stream source, called a `BitGenerator` A number of\nthese are provided. `RandomState` uses the Mersenne Twister `MT19937` by\ndefault, but can also be instantiated with any BitGenerator.\n\n`random`\n\n`random_sample`, `rand`\n\nAccess the values in a BitGenerator, convert them to `float64` in the interval\n`[0.0.,` `` 1.0)``. In addition to the `size` kwarg, now supports `dtype='d'`\nor `dtype='f'`, and an `out` kwarg to fill a user- supplied array.\n\nMany other distributions are also supported.\n\n`integers`\n\n`randint`, `random_integers`\n\nUse the `endpoint` kwarg to adjust the inclusion or exclution of the `high`\ninterval endpoint\n\nAnd in more detail:\n\nOptional `dtype` argument that accepts `np.float32` or `np.float64` to produce\neither single or double prevision uniform random variables for select\ndistributions\n\nOptional `out` argument that allows existing arrays to be filled for select\ndistributions\n\nThis allows multithreading to fill large arrays in chunks using suitable\nBitGenerators in parallel.\n\n"}, {"name": "Window functions", "path": "reference/routines.window", "type": "Window functions", "text": "\n`bartlett`(M)\n\nReturn the Bartlett window.\n\n`blackman`(M)\n\nReturn the Blackman window.\n\n`hamming`(M)\n\nReturn the Hamming window.\n\n`hanning`(M)\n\nReturn the Hanning window.\n\n`kaiser`(M, beta)\n\nReturn the Kaiser window.\n\n"}, {"name": "WITH_THREADS", "path": "reference/c-api/array#c.WITH_THREADS", "type": "Array API", "text": "\n\n"}, {"name": "Writing custom array containers", "path": "user/basics.dispatch", "type": "User Guide", "text": "\nNumpy\u2019s dispatch mechanism, introduced in numpy version v1.16 is the\nrecommended approach for writing custom N-dimensional array containers that\nare compatible with the numpy API and provide custom implementations of numpy\nfunctionality. Applications include dask arrays, an N-dimensional array\ndistributed across multiple nodes, and cupy arrays, an N-dimensional array on\na GPU.\n\nTo get a feel for writing custom array containers, we\u2019ll begin with a simple\nexample that has rather narrow utility but illustrates the concepts involved.\n\nOur custom array can be instantiated like:\n\nWe can convert to a numpy array using `numpy.array` or `numpy.asarray`, which\nwill call its `__array__` method to obtain a standard `numpy.ndarray`.\n\nIf we operate on `arr` with a numpy function, numpy will again use the\n`__array__` interface to convert it to an array and then apply the function in\nthe usual way.\n\nNotice that the return type is a standard `numpy.ndarray`.\n\nHow can we pass our custom array type through this function? Numpy allows a\nclass to indicate that it would like to handle computations in a custom-\ndefined way through the interfaces `__array_ufunc__` and `__array_function__`.\nLet\u2019s take one at a time, starting with `_array_ufunc__`. This method covers\nUniversal functions (ufunc), a class of functions that includes, for example,\n`numpy.multiply` and `numpy.sin`.\n\nThe `__array_ufunc__` receives:\n\nFor this example we will only handle the method `__call__`\n\nNow our custom array type passes through numpy functions.\n\nAt this point `arr + 3` does not work.\n\nTo support it, we need to define the Python interfaces `__add__`, `__lt__`,\nand so on to dispatch to the corresponding ufunc. We can achieve this\nconveniently by inheriting from the mixin `NDArrayOperatorsMixin`.\n\nNow let\u2019s tackle `__array_function__`. We\u2019ll create dict that maps numpy\nfunctions to our custom variants.\n\nA convenient pattern is to define a decorator `implements` that can be used to\nadd functions to `HANDLED_FUNCTIONS`.\n\nNow we write implementations of numpy functions for `DiagonalArray`. For\ncompleteness, to support the usage `arr.sum()` add a method `sum` that calls\n`numpy.sum(self)`, and the same for `mean`.\n\nIf the user tries to use any numpy functions not included in\n`HANDLED_FUNCTIONS`, a `TypeError` will be raised by numpy, indicating that\nthis operation is not supported. For example, concatenating two\n`DiagonalArrays` does not produce another diagonal array, so it is not\nsupported.\n\nAdditionally, our implementations of `sum` and `mean` do not accept the\noptional arguments that numpy\u2019s implementation does.\n\nThe user always has the option of converting to a normal `numpy.ndarray` with\n`numpy.asarray` and using standard numpy from there.\n\nRefer to the dask source code and cupy source code for more fully-worked\nexamples of custom array containers.\n\nSee also NEP 18.\n\n"}, {"name": "Writing your own ufunc", "path": "user/c-info.ufunc-tutorial", "type": "User Guide", "text": "\nBefore reading this, it may help to familiarize yourself with the basics of C\nextensions for Python by reading/skimming the tutorials in Section 1 of\nExtending and Embedding the Python Interpreter and in How to extend NumPy\n\nThe umath module is a computer-generated C-module that creates many ufuncs. It\nprovides a great many examples of how to create a universal function. Creating\nyour own ufunc that will make use of the ufunc machinery is not difficult\neither. Suppose you have a function that you want to operate element-by-\nelement over its inputs. By creating a new ufunc you will obtain a function\nthat handles\n\nIt is not difficult to create your own ufunc. All that is required is a 1-d\nloop for each data-type you want to support. Each 1-d loop must have a\nspecific signature, and only ufuncs for fixed-size data-types can be used. The\nfunction call used to create a new ufunc to work on built-in data-types is\ngiven below. A different mechanism is used to register ufuncs for user-defined\ndata-types.\n\nIn the next several sections we give example code that can be easily modified\nto create your own ufuncs. The examples are successively more complete or\ncomplicated versions of the logit function, a common function in statistical\nmodeling. Logit is also interesting because, due to the magic of IEEE\nstandards (specifically IEEE 754), all of the logit functions created below\nautomatically have the following behavior.\n\nThis is wonderful because the function writer doesn\u2019t have to manually\npropagate infs or nans.\n\nFor comparison and general edification of the reader we provide a simple\nimplementation of a C extension of logit that uses no numpy.\n\nTo do this we need two files. The first is the C file which contains the\nactual code, and the second is the setup.py file used to create the module.\n\nTo use the setup.py file, place setup.py and spammodule.c in the same folder.\nThen python setup.py build will build the module to import, or setup.py\ninstall will install the module to your site-packages directory.\n\nOnce the spam module is imported into python, you can call logit via\nspam.logit. Note that the function used above cannot be applied as-is to numpy\narrays. To do so we must call numpy.vectorize on it. For example, if a python\ninterpreter is opened in the file containing the spam library or spam has been\ninstalled, one can perform the following commands:\n\nTHE RESULTING LOGIT FUNCTION IS NOT FAST! numpy.vectorize simply loops over\nspam.logit. The loop is done at the C level, but the numpy array is constantly\nbeing parsed and build back up. This is expensive. When the author compared\nnumpy.vectorize(spam.logit) against the logit ufuncs constructed below, the\nlogit ufuncs were almost exactly 4 times faster. Larger or smaller speedups\nare, of course, possible depending on the nature of the function.\n\nFor simplicity we give a ufunc for a single dtype, the \u2018f8\u2019 double. As in the\nprevious section, we first give the .c file and then the setup.py file used to\ncreate the module containing the ufunc.\n\nThe place in the code corresponding to the actual computations for the ufunc\nare marked with /*BEGIN main ufunc computation*/ and /*END main ufunc\ncomputation*/. The code in between those lines is the primary thing that must\nbe changed to create your own ufunc.\n\nThis is a setup.py file for the above code. As before, the module can be build\nvia calling python setup.py build at the command prompt, or installed to site-\npackages via python setup.py install.\n\nAfter the above has been installed, it can be imported and used as follows.\n\nWe finally give an example of a full ufunc, with inner loops for half-floats,\nfloats, doubles, and long doubles. As in the previous sections we first give\nthe .c file and then the corresponding setup.py file.\n\nThe places in the code corresponding to the actual computations for the ufunc\nare marked with /*BEGIN main ufunc computation*/ and /*END main ufunc\ncomputation*/. The code in between those lines is the primary thing that must\nbe changed to create your own ufunc.\n\nThis is a setup.py file for the above code. As before, the module can be build\nvia calling python setup.py build at the command prompt, or installed to site-\npackages via python setup.py install.\n\nAfter the above has been installed, it can be imported and used as follows.\n\nOur final example is a ufunc with multiple arguments. It is a modification of\nthe code for a logit ufunc for data with a single dtype. We compute (A*B,\nlogit(A*B)).\n\nWe only give the C code as the setup.py file is exactly the same as the\nsetup.py file in Example NumPy ufunc for one dtype, except that the line\n\nis replaced with\n\nThe C file is given below. The ufunc generated takes two arguments A and B. It\nreturns a tuple whose first element is A*B and whose second element is\nlogit(A*B). Note that it automatically supports broadcasting, as well as all\nother properties of a ufunc.\n\nThis example shows how to create a ufunc for a structured array dtype. For the\nexample we show a trivial ufunc for adding two arrays with dtype \u2018u8,u8,u8\u2019.\nThe process is a bit different from the other examples since a call to\n`PyUFunc_FromFuncAndData` doesn\u2019t fully register ufuncs for custom dtypes and\nstructured array dtypes. We need to also call `PyUFunc_RegisterLoopForDescr`\nto finish setting up the ufunc.\n\nWe only give the C code as the setup.py file is exactly the same as the\nsetup.py file in Example NumPy ufunc for one dtype, except that the line\n\nis replaced with\n\nThe C file is given below.\n\nThe returned ufunc object is a callable Python object. It should be placed in\na (module) dictionary under the same name as was used in the name argument to\nthe ufunc-creation routine. The following example is adapted from the umath\nmodule\n\n"}, {"name": "\u201cdescr\u201ddtype.descr", "path": "reference/generated/numpy.lib.format", "type": "numpy.lib.format", "text": "\nBinary serialization\n\nA simple format for saving numpy arrays to disk with the full information\nabout them.\n\nThe `.npy` format is the standard binary file format in NumPy for persisting a\nsingle arbitrary NumPy array on disk. The format stores all of the shape and\ndtype information necessary to reconstruct the array correctly even on another\nmachine with a different architecture. The format is designed to be as simple\nas possible while achieving its limited goals.\n\nThe `.npz` format is the standard format for persisting multiple NumPy arrays\non disk. A `.npz` file is a zip file containing multiple `.npy` files, one for\neach array.\n\nWarning\n\nDue to limitations in the interpretation of structured dtypes, dtypes with\nfields with empty names will have the names replaced by \u2018f0\u2019, \u2018f1\u2019, etc. Such\narrays will not round-trip through the format entirely accurately. The data is\nintact; only the field names will differ. We are working on a fix for this.\nThis fix will not require a change in the file format. The arrays with such\nstructures can still be saved and restored, and the correct dtype may be\nrestored by using the `loadedarray.view(correct_dtype)` method.\n\nWe recommend using the `.npy` and `.npz` extensions for files saved in this\nformat. This is by no means a requirement; applications may wish to use these\nfile formats but use an extension specific to the application. In the absence\nof an obvious alternative, however, we suggest using `.npy` and `.npz`.\n\nThe version numbering of these formats is independent of NumPy version\nnumbering. If the format is upgraded, the code in `numpy.io` will still be\nable to read and write Version 1.0 files.\n\nThe first 6 bytes are a magic string: exactly `\\x93NUMPY`.\n\nThe next 1 byte is an unsigned byte: the major version number of the file\nformat, e.g. `\\x01`.\n\nThe next 1 byte is an unsigned byte: the minor version number of the file\nformat, e.g. `\\x00`. Note: the version of the file format is not tied to the\nversion of the numpy package.\n\nThe next 2 bytes form a little-endian unsigned short int: the length of the\nheader data HEADER_LEN.\n\nThe next HEADER_LEN bytes form the header data describing the array\u2019s format.\nIt is an ASCII string which contains a Python literal expression of a\ndictionary. It is terminated by a newline (`\\n`) and padded with spaces\n(`\\x20`) to make the total of `len(magic string) + 2 + len(length) +\nHEADER_LEN` be evenly divisible by 64 for alignment purposes.\n\nThe dictionary contains three keys:\n\nAn object that can be passed as an argument to the `numpy.dtype` constructor\nto create the array\u2019s dtype.\n\nWhether the array data is Fortran-contiguous or not. Since Fortran-contiguous\narrays are a common form of non-C-contiguity, we allow them to be written\ndirectly to disk for efficiency.\n\nThe shape of the array.\n\nFor repeatability and readability, the dictionary keys are sorted in\nalphabetic order. This is for convenience only. A writer SHOULD implement this\nif possible. A reader MUST NOT depend on this.\n\nFollowing the header comes the array data. If the dtype contains Python\nobjects (i.e. `dtype.hasobject is True`), then the data is a Python pickle of\nthe array. Otherwise the data is the contiguous (either C- or Fortran-,\ndepending on `fortran_order`) bytes of the array. Consumers can figure out the\nnumber of bytes by multiplying the number of elements given by the shape\n(noting that `shape=()` means there is 1 element) by `dtype.itemsize`.\n\nThe version 1.0 format only allowed the array header to have a total size of\n65535 bytes. This can be exceeded by structured arrays with a large number of\ncolumns. The version 2.0 format extends the header size to 4 GiB. `numpy.save`\nwill automatically save in 2.0 format if the data requires it, else it will\nalways use the more compatible 1.0 format.\n\nThe description of the fourth element of the header therefore has become: \u201cThe\nnext 4 bytes form a little-endian unsigned int: the length of the header data\nHEADER_LEN.\u201d\n\nThis version replaces the ASCII string (which in practice was latin1) with a\nutf8-encoded string, so supports structured types with any unicode field\nnames.\n\nThe `.npy` format, including motivation for creating it and a comparison of\nalternatives, is described in the \u201cnpy-format\u201d NEP, however details have\nevolved with time and this document is more current.\n\n`descr_to_dtype`(descr)\n\nReturns a dtype based off the given description.\n\n`dtype_to_descr`(dtype)\n\nGet a serializable descriptor from the dtype.\n\n`header_data_from_array_1_0`(array)\n\nGet the dictionary of header metadata from a numpy.ndarray.\n\n`magic`(major, minor)\n\nReturn the magic string for the given file format version.\n\n`open_memmap`(filename[, mode, dtype, shape, ...])\n\nOpen a .npy file as a memory-mapped array.\n\n`read_array`(fp[, allow_pickle, pickle_kwargs])\n\nRead an array from an NPY file.\n\n`read_array_header_1_0`(fp)\n\nRead an array header from a filelike object using the 1.0 file format version.\n\n`read_array_header_2_0`(fp)\n\nRead an array header from a filelike object using the 2.0 file format version.\n\n`read_magic`(fp)\n\nRead the magic string to get the version of the file format.\n\n`write_array`(fp, array[, version, ...])\n\nWrite an array to an NPY file, including a header.\n\n`write_array_header_1_0`(fp, d)\n\nWrite the header for an array using the 1.0 format.\n\n`write_array_header_2_0`(fp, d)\n\nWrite the header for an array using the 2.0 format.\n\n"}]