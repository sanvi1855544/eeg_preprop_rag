{"doc_id": "finetune_evaluator.py", "text": "import numpy as np\nimport torch\nfrom sklearn.metrics import balanced_accuracy_score, f1_score, confusion_matrix, cohen_kappa_score, roc_auc_score, \\\n    precision_recall_curve, auc, r2_score, mean_squared_error\nfrom tqdm import tqdm\n\n\nclass Evaluator:\n    def __init__(self, params, data_loader):\n        self.params = params\n        self.data_loader = data_loader\n\n    def get_metrics_for_multiclass(self, model):\n        model.eval()\n\n        truths = []\n        preds = []\n        for x, y in tqdm(self.data_loader, mininterval=1):\n            x = x.cuda()\n            y = y.cuda()\n\n            pred = model(x)\n            pred_y = torch.max(pred, dim=-1)[1]\n\n            truths += y.cpu().squeeze().numpy().tolist()\n            preds += pred_y.cpu().squeeze().numpy().tolist()\n\n        truths = np.array(truths)\n        preds = np.array(preds)\n        acc = balanced_accuracy_score(truths, preds)\n        f1 = f1_score(truths, preds, average='weighted')\n        kappa = cohen_kappa_score(truths, preds)\n        cm = confusion_matrix(truths, preds)\n        return acc, kappa, f1, cm\n\n    def get_metrics_for_binaryclass(self, model):\n        model.eval()\n\n        truths = []\n        preds = []\n        scores = []\n        for x, y in tqdm(self.data_loader, mininterval=1):\n            x = x.cuda()\n            y = y.cuda()\n            pred = model(x)\n            score_y = torch.sigmoid(pred)\n            pred_y = torch.gt(score_y, 0.5).long()\n            truths += y.long().cpu().squeeze().numpy().tolist()\n            preds += pred_y.cpu().squeeze().numpy().tolist()\n            scores += score_y.cpu().numpy().tolist()\n\n        truths = np.array(truths)\n        preds = np.array(preds)\n        scores = np.array(scores)\n        acc = balanced_accuracy_score(truths, preds)\n        roc_auc = roc_auc_score(truths, scores)\n        precision, recall, thresholds = precision_recall_curve(truths, scores, pos_label=1)\n        pr_auc = auc(recall, precision)\n        cm = confusion_matrix(truths, preds)\n        return acc, pr_auc, roc_auc, cm\n\n    def get_metrics_for_regression(self, model):\n        model.eval()\n\n        truths = []\n        preds = []\n        for x, y in tqdm(self.data_loader, mininterval=1):\n            x = x.cuda()\n            y = y.cuda()\n            pred = model(x)\n            truths += y.cpu().squeeze().numpy().tolist()\n            preds += pred.cpu().squeeze().numpy().tolist()\n\n        truths = np.array(truths)\n        preds = np.array(preds)\n        corrcoef = np.corrcoef(truths, preds)[0, 1]\n        r2 = r2_score(truths, preds)\n        rmse = mean_squared_error(truths, preds) ** 0.5\n        return corrcoef, r2, rmse"}
{"doc_id": "finetune_main.py", "text": "import argparse\nimport random\n\nimport numpy as np\nimport torch\n\nfrom datasets import faced_dataset, seedv_dataset, physio_dataset, shu_dataset, isruc_dataset, chb_dataset, \\\n    speech_dataset, mumtaz_dataset, seedvig_dataset, stress_dataset, tuev_dataset, tuab_dataset, bciciv2a_dataset\nfrom finetune_trainer import Trainer\nfrom models import model_for_faced, model_for_seedv, model_for_physio, model_for_shu, model_for_isruc, model_for_chb, \\\n    model_for_speech, model_for_mumtaz, model_for_seedvig, model_for_stress, model_for_tuev, model_for_tuab, \\\n    model_for_bciciv2a\n\n\ndef main():\n    parser = argparse.ArgumentParser(description='Big model downstream')\n    parser.add_argument('--seed', type=int, default=3407, help='random seed (default: 0)')\n    parser.add_argument('--cuda', type=int, default=0, help='cuda number (default: 1)')\n    parser.add_argument('--epochs', type=int, default=50, help='number of epochs (default: 5)')\n    parser.add_argument('--batch_size', type=int, default=64, help='batch size for training (default: 32)')\n    parser.add_argument('--lr', type=float, default=1e-4, help='learning rate (default: 1e-3)')\n    parser.add_argument('--weight_decay', type=float, default=5e-2, help='weight decay (default: 1e-2)')\n    parser.add_argument('--optimizer', type=str, default='AdamW', help='optimizer (AdamW, SGD)')\n    parser.add_argument('--clip_value', type=float, default=1, help='clip_value')\n    parser.add_argument('--dropout', type=float, default=0.1, help='dropout')\n    parser.add_argument('--classifier', type=str, default='avgpooling_patch_reps',\n                        help='[all_patch_reps, avgpooling_patch_reps]')\n    # avgpooling_patch_reps: use average pooling for patch features; all_patch_reps: use all patch features\n\n    \"\"\"############ Downstream dataset settings ############\"\"\"\n    parser.add_argument('--downstream_dataset', type=str, default='FACED',\n                        help='[FACED, SEED-V, PhysioNet-MI, SHU-MI, ISRUC, CHB-MIT, BCIC2020-3, Mumtaz2016, SEED-VIG, MentalArithmetic, TUEV, TUAB, BCIC-IV-2a]')\n    parser.add_argument('--datasets_dir', type=str,\n                        default='/data/datasets/BigDownstream/Faced/processed',\n                        help='datasets_dir')\n    parser.add_argument('--num_of_classes', type=int, default=9, help='number of classes')\n    parser.add_argument('--model_dir', type=str, default='/data/wjq/models_weights/Big/BigFaced', help='model_dir')\n    \"\"\"############ Downstream dataset settings ############\"\"\"\n\n    parser.add_argument('--num_workers', type=int, default=16, help='num_workers')\n    parser.add_argument('--label_smoothing', type=float, default=0.1, help='label_smoothing')\n    parser.add_argument('--multi_lr', type=bool, default=True,\n                        help='multi_lr')  # set different learning rates for different modules\n    parser.add_argument('--frozen', type=bool,\n                        default=False, help='frozen')\n    parser.add_argument('--use_pretrained_weights', type=bool,\n                        default=True, help='use_pretrained_weights')\n    parser.add_argument('--foundation_dir', type=str,\n                        default='pretrained_weights/pretrained_weights.pth',\n                        help='foundation_dir')\n\n    params = parser.parse_args()\n    print(params)\n\n    setup_seed(params.seed)\n    torch.cuda.set_device(params.cuda)\n    print('The downstream dataset is {}'.format(params.downstream_dataset))\n    if params.downstream_dataset == 'FACED':\n        load_dataset = faced_dataset.LoadDataset(params)\n        data_loader = load_dataset.get_data_loader()\n        model = model_for_faced.Model(params)\n        t = Trainer(params, data_loader, model)\n        t.train_for_multiclass()\n    elif params.downstream_dataset == 'SEED-V':\n        load_dataset = seedv_dataset.LoadDataset(params)\n        data_loader = load_dataset.get_data_loader()\n        model = model_for_seedv.Model(params)\n        t = Trainer(params, data_loader, model)\n        t.train_for_multiclass()\n    elif params.downstream_dataset == 'PhysioNet-MI':\n        load_dataset = physio_dataset.LoadDataset(params)\n        data_loader = load_dataset.get_data_loader()\n        model = model_for_physio.Model(params)\n        t = Trainer(params, data_loader, model)\n        t.train_for_multiclass()\n    elif params.downstream_dataset == 'SHU-MI':\n        load_dataset = shu_dataset.LoadDataset(params)\n        data_loader = load_dataset.get_data_loader()\n        model = model_for_shu.Model(params)\n        t = Trainer(params, data_loader, model)\n        t.train_for_binaryclass()\n    elif params.downstream_dataset == 'ISRUC':\n        load_dataset = isruc_dataset.LoadDataset(params)\n        data_loader = load_dataset.get_data_loader()\n        model = model_for_isruc.Model(params)\n        t = Trainer(params, data_loader, model)\n        t.train_for_multiclass()\n    elif params.downstream_dataset == 'CHB-MIT':\n        load_dataset = chb_dataset.LoadDataset(params)\n        data_loader = load_dataset.get_data_loader()\n        model = model_for_chb.Model(params)\n        t = Trainer(params, data_loader, model)\n        t.train_for_binaryclass()\n    elif params.downstream_dataset == 'BCIC2020-3':\n        load_dataset = speech_dataset.LoadDataset(params)\n        data_loader = load_dataset.get_data_loader()\n        model = model_for_speech.Model(params)\n        t = Trainer(params, data_loader, model)\n        t.train_for_multiclass()\n    elif params.downstream_dataset == 'Mumtaz2016':\n        load_dataset = mumtaz_dataset.LoadDataset(params)\n        data_loader = load_dataset.get_data_loader()\n        model = model_for_mumtaz.Model(params)\n        t = Trainer(params, data_loader, model)\n        t.train_for_binaryclass()\n    elif params.downstream_dataset == 'SEED-VIG':\n        load_dataset = seedvig_dataset.LoadDataset(params)\n        data_loader = load_dataset.get_data_loader()\n        model = model_for_seedvig.Model(params)\n        t = Trainer(params, data_loader, model)\n        t.train_for_regression()\n    elif params.downstream_dataset == 'MentalArithmetic':\n        load_dataset = stress_dataset.LoadDataset(params)\n        data_loader = load_dataset.get_data_loader()\n        model = model_for_stress.Model(params)\n        t = Trainer(params, data_loader, model)\n        t.train_for_binaryclass()\n    elif params.downstream_dataset == 'TUEV':\n        load_dataset = tuev_dataset.LoadDataset(params)\n        data_loader = load_dataset.get_data_loader()\n        model = model_for_tuev.Model(params)\n        t = Trainer(params, data_loader, model)\n        t.train_for_multiclass()\n    elif params.downstream_dataset == 'TUAB':\n        load_dataset = tuab_dataset.LoadDataset(params)\n        data_loader = load_dataset.get_data_loader()\n        model = model_for_tuab.Model(params)\n        t = Trainer(params, data_loader, model)\n        t.train_for_binaryclass()\n    elif params.downstream_dataset == 'BCIC-IV-2a':\n        load_dataset = bciciv2a_dataset.LoadDataset(params)\n        data_loader = load_dataset.get_data_loader()\n        model = model_for_bciciv2a.Model(params)\n        t = Trainer(params, data_loader, model)\n        t.train_for_multiclass()\n    print('Done!!!!!')\n\n\ndef setup_seed(seed):\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    np.random.seed(seed)\n    random.seed(seed)\n    torch.backends.cudnn.deterministic = True\n\n\nif __name__ == '__main__':\n    main()\n"}
{"doc_id": "pretrain_trainer.py", "text": "import numpy as np\nimport torch\nfrom ptflops import get_model_complexity_info\nfrom torch.nn import MSELoss\nfrom torchinfo import summary\nfrom tqdm import tqdm\n\nfrom utils.util import generate_mask\n\n\nclass Trainer(object):\n    def __init__(self, params, data_loader, model):\n        self.params = params\n        self.device = torch.device(f\"cuda:{self.params.cuda}\" if torch.cuda.is_available() else \"cpu\")\n        self.data_loader = data_loader\n        self.model = model.to(self.device)\n        self.criterion = MSELoss(reduction='mean').to(self.device)\n\n        if self.params.parallel:\n            device_ids = [0, 1, 2, 3, 4, 5, 6, 7]\n            self.model = torch.nn.DataParallel(self.model, device_ids=device_ids)\n\n        self.data_length = len(self.data_loader)\n\n        summary(self.model, input_size=(1, 19, 30, 200))\n\n        macs, params = get_model_complexity_info(self.model, (19, 30, 200), as_strings=True,\n                                                 print_per_layer_stat=True, verbose=True)\n        print('{:<30}  {:<8}'.format('Computational complexity: ', macs))\n        print('{:<30}  {:<8}'.format('Number of parameters: ', params))\n\n        self.optimizer = torch.optim.AdamW(self.model.parameters(), lr=self.params.lr,\n                                           weight_decay=self.params.weight_decay)\n\n        if self.params.lr_scheduler=='CosineAnnealingLR':\n            self.optimizer_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n                self.optimizer, T_max=40*self.data_length, eta_min=1e-5\n            )\n        elif self.params.lr_scheduler=='ExponentialLR':\n            self.optimizer_scheduler = torch.optim.lr_scheduler.ExponentialLR(\n                self.optimizer, gamma=0.999999999\n            )\n        elif self.params.lr_scheduler=='StepLR':\n            self.optimizer_scheduler = torch.optim.lr_scheduler.StepLR(\n                self.optimizer, step_size=5*self.data_length, gamma=0.5\n            )\n        elif self.params.lr_scheduler=='MultiStepLR':\n            self.optimizer_scheduler = torch.optim.lr_scheduler.MultiStepLR(\n                self.optimizer, milestones=[10*self.data_length, 20*self.data_length, 30*self.data_length], gamma=0.1\n            )\n        elif self.params.lr_scheduler=='CyclicLR':\n            self.optimizer_scheduler = torch.optim.lr_scheduler.CyclicLR(\n                self.optimizer, base_lr=1e-6, max_lr=0.001, step_size_up=self.data_length*5,\n                step_size_down=self.data_length*2, mode='exp_range', gamma=0.9, cycle_momentum=False\n            )\n\n\n    def train(self):\n        best_loss = 10000\n        for epoch in range(self.params.epochs):\n            losses = []\n            for x in tqdm(self.data_loader, mininterval=10):\n                self.optimizer.zero_grad()\n                x = x.to(self.device)/100\n                if self.params.need_mask:\n                    bz, ch_num, patch_num, patch_size = x.shape\n                    mask = generate_mask(\n                        bz, ch_num, patch_num, mask_ratio=self.params.mask_ratio, device=self.device,\n                    )\n                    y = self.model(x, mask=mask)\n                    masked_x = x[mask == 1]\n                    masked_y = y[mask == 1]\n                    loss = self.criterion(masked_y, masked_x)\n\n                    # non_masked_x = x[mask == 0]\n                    # non_masked_y = y[mask == 0]\n                    # non_masked_loss = self.criterion(non_masked_y, non_masked_x)\n                    # loss = 0.8 * masked_loss + 0.2 * non_masked_loss\n                else:\n                    y = self.model(x)\n                    loss = self.criterion(y, x)\n                loss.backward()\n                if self.params.clip_value > 0:\n                    torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.params.clip_value)\n                self.optimizer.step()\n                self.optimizer_scheduler.step()\n                losses.append(loss.data.cpu().numpy())\n            mean_loss = np.mean(losses)\n            learning_rate = self.optimizer.state_dict()['param_groups'][0]['lr']\n            print(f'Epoch {epoch+1}: Training Loss: {mean_loss:.6f}, Learning Rate: {learning_rate:.6f}')\n            if  mean_loss < best_loss:\n                model_path = rf'{self.params.model_dir}/epoch{epoch+1}_loss{mean_loss}.pth'\n                torch.save(self.model.state_dict(), model_path)\n                print(\"model save in \" + model_path)\n                best_loss = mean_loss"}
{"doc_id": "pretrain_main.py", "text": "import argparse\nimport random\nimport numpy as np\nimport torch\nfrom torch.utils.data import DataLoader\n\nfrom datasets.pretraining_dataset import PretrainingDataset\nfrom models.cbramod import CBraMod\nfrom pretrain_trainer import Trainer\n\n\ndef setup_seed(seed):\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    np.random.seed(seed)\n    random.seed(seed)\n    torch.backends.cudnn.deterministic = True\n\n\ndef main():\n    parser = argparse.ArgumentParser(description='EEG Foundation Model')\n    parser.add_argument('--seed', type=int, default=42, help='random seed (default: 0)')\n    parser.add_argument('--cuda', type=int, default=3, help='cuda number (default: 1)')\n    parser.add_argument('--parallel', type=bool, default=False, help='parallel')\n    parser.add_argument('--epochs', type=int, default=40, help='number of epochs (default: 5)')\n    parser.add_argument('--batch_size', type=int, default=128, help='batch size for training (default: 32)')\n    parser.add_argument('--lr', type=float, default=5e-4, help='learning rate (default: 1e-3)')\n    parser.add_argument('--weight_decay', type=float, default=5e-2, help='weight_decay')\n    parser.add_argument('--clip_value', type=float, default=1, help='clip_value')\n    parser.add_argument('--lr_scheduler', type=str, default='CosineAnnealingLR',\n                        help='lr_scheduler: CosineAnnealingLR, ExponentialLR, StepLR, MultiStepLR, CyclicLR')\n\n    # parser.add_argument('--project_mode', type=str, default='cnn', help='project_mode')\n    parser.add_argument('--dropout', type=float, default=0.1, help='dropout')\n    parser.add_argument('--in_dim', type=int, default=200, help='in_dim')\n    parser.add_argument('--out_dim', type=int, default=200, help='out_dim')\n    parser.add_argument('--d_model', type=int, default=200, help='d_model')\n    parser.add_argument('--dim_feedforward', type=int, default=800, help='dim_feedforward')\n    parser.add_argument('--seq_len', type=int, default=30, help='seq_len')\n    parser.add_argument('--n_layer', type=int, default=12, help='n_layer')\n    parser.add_argument('--nhead', type=int, default=8, help='nhead')\n    parser.add_argument('--need_mask', type=bool, default=True, help='need_mask')\n    parser.add_argument('--mask_ratio', type=float, default=0.5, help='mask_ratio')\n\n    parser.add_argument('--dataset_dir', type=str, default='dataset_dir',\n                        help='dataset_dir')\n    parser.add_argument('--model_dir',   type=str,   default='model_dir', help='model_dir')\n    params = parser.parse_args()\n    print(params)\n    setup_seed(params.seed)\n    pretrained_dataset = PretrainingDataset(dataset_dir=params.dataset_dir)\n    print(len(pretrained_dataset))\n    data_loader = DataLoader(\n        pretrained_dataset,\n        batch_size=params.batch_size,\n        num_workers=8,\n        shuffle=True,\n    )\n    model = CBraMod(\n        params.in_dim, params.out_dim, params.d_model, params.dim_feedforward, params.seq_len, params.n_layer,\n        params.nhead\n    )\n    trainer = Trainer(params, data_loader, model)\n    trainer.train()\n    pretrained_dataset.db.close()\n\n\nif __name__ == '__main__':\n    main()\n"}
{"doc_id": "quick_example.py", "text": "import torch\nimport torch.nn as nn\nfrom models.cbramod import CBraMod\nfrom einops.layers.torch import Rearrange\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nmodel = CBraMod().to(device)\nmodel.load_state_dict(torch.load('pretrained_weights/pretrained_weights.pth', map_location=device))\nmodel.proj_out = nn.Identity()\nclassifier = nn.Sequential(\n  Rearrange('b c s p -> b (c s p)'),\n  nn.Linear(22*4*200, 4*200),\n  nn.ELU(),\n  nn.Dropout(0.1),\n  nn.Linear(4 * 200, 200),\n  nn.ELU(),\n  nn.Dropout(0.1),\n  nn.Linear(200, 4),\n).to(device)\n\n# mock_eeg.shape = (batch_size, num_of_channels, time_segments, points_per_patch)\nmock_eeg = torch.randn((8, 22, 4, 200)).to(device)\n\n# logits.shape = (batch_size, num_of_classes)\nlogits = classifier(model(mock_eeg))\n\nprint(logits.shape)"}
{"doc_id": "finetune_trainer.py", "text": "import torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader\n# from models.model_for_faced import Model\nfrom tqdm import tqdm\nimport torch\nfrom finetune_evaluator import Evaluator\nfrom torch.nn import CrossEntropyLoss, BCEWithLogitsLoss, MSELoss\nfrom timeit import default_timer as timer\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.manifold import TSNE\nimport matplotlib as mpl\nimport umap\nfrom sklearn.decomposition import PCA\nimport copy\nimport os\n\n\nclass Trainer(object):\n    def __init__(self, params, data_loader, model):\n        self.params = params\n        self.data_loader = data_loader\n\n        self.val_eval = Evaluator(params, self.data_loader['val'])\n        self.test_eval = Evaluator(params, self.data_loader['test'])\n\n        self.model = model.cuda()\n        if self.params.downstream_dataset in ['FACED', 'SEED-V', 'PhysioNet-MI', 'ISRUC', 'BCIC2020-3', 'TUEV', 'BCIC-IV-2a']:\n            self.criterion = CrossEntropyLoss(label_smoothing=self.params.label_smoothing).cuda()\n        elif self.params.downstream_dataset in ['SHU-MI', 'CHB-MIT', 'Mumtaz2016', 'MentalArithmetic', 'TUAB']:\n            self.criterion = BCEWithLogitsLoss().cuda()\n        elif self.params.downstream_dataset == 'SEED-VIG':\n            self.criterion = MSELoss().cuda()\n\n        self.best_model_states = None\n\n        backbone_params = []\n        other_params = []\n        for name, param in self.model.named_parameters():\n            if \"backbone\" in name:\n                backbone_params.append(param)\n\n                if params.frozen:\n                    param.requires_grad = False\n                else:\n                    param.requires_grad = True\n            else:\n                other_params.append(param)\n\n        if self.params.optimizer == 'AdamW':\n            if self.params.multi_lr: # set different learning rates for different modules\n                self.optimizer = torch.optim.AdamW([\n                    {'params': backbone_params, 'lr': self.params.lr},\n                    {'params': other_params, 'lr': self.params.lr * 5}\n                ], weight_decay=self.params.weight_decay)\n            else:\n                self.optimizer = torch.optim.AdamW(self.model.parameters(), lr=self.params.lr,\n                                                   weight_decay=self.params.weight_decay)\n        else:\n            if self.params.multi_lr:\n                self.optimizer = torch.optim.SGD([\n                    {'params': backbone_params, 'lr': self.params.lr},\n                    {'params': other_params, 'lr': self.params.lr * 5}\n                ],  momentum=0.9, weight_decay=self.params.weight_decay)\n            else:\n                self.optimizer = torch.optim.SGD(self.model.parameters(), lr=self.params.lr, momentum=0.9,\n                                                 weight_decay=self.params.weight_decay)\n\n        self.data_length = len(self.data_loader['train'])\n        self.optimizer_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n            self.optimizer, T_max=self.params.epochs * self.data_length, eta_min=1e-6\n        )\n        print(self.model)\n\n    def train_for_multiclass(self):\n        f1_best = 0\n        kappa_best = 0\n        acc_best = 0\n        cm_best = None\n        for epoch in range(self.params.epochs):\n            self.model.train()\n            start_time = timer()\n            losses = []\n            for x, y in tqdm(self.data_loader['train'], mininterval=10):\n                self.optimizer.zero_grad()\n                x = x.cuda()\n                y = y.cuda()\n                pred = self.model(x)\n                if self.params.downstream_dataset == 'ISRUC':\n                    loss = self.criterion(pred.transpose(1, 2), y)\n                else:\n                    loss = self.criterion(pred, y)\n\n                loss.backward()\n                losses.append(loss.data.cpu().numpy())\n                if self.params.clip_value > 0:\n                    torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.params.clip_value)\n                    # torch.nn.utils.clip_grad_value_(self.model.parameters(), self.params.clip_value)\n                self.optimizer.step()\n                self.optimizer_scheduler.step()\n\n            optim_state = self.optimizer.state_dict()\n\n            with torch.no_grad():\n                acc, kappa, f1, cm = self.val_eval.get_metrics_for_multiclass(self.model)\n                print(\n                    \"Epoch {} : Training Loss: {:.5f}, acc: {:.5f}, kappa: {:.5f}, f1: {:.5f}, LR: {:.5f}, Time elapsed {:.2f} mins\".format(\n                        epoch + 1,\n                        np.mean(losses),\n                        acc,\n                        kappa,\n                        f1,\n                        optim_state['param_groups'][0]['lr'],\n                        (timer() - start_time) / 60\n                    )\n                )\n                print(cm)\n                if kappa > kappa_best:\n                    print(\"kappa increasing....saving weights !! \")\n                    print(\"Val Evaluation: acc: {:.5f}, kappa: {:.5f}, f1: {:.5f}\".format(\n                        acc,\n                        kappa,\n                        f1,\n                    ))\n                    best_f1_epoch = epoch + 1\n                    acc_best = acc\n                    kappa_best = kappa\n                    f1_best = f1\n                    cm_best = cm\n                    self.best_model_states = copy.deepcopy(self.model.state_dict())\n        self.model.load_state_dict(self.best_model_states)\n        with torch.no_grad():\n            print(\"***************************Test************************\")\n            acc, kappa, f1, cm = self.test_eval.get_metrics_for_multiclass(self.model)\n            print(\"***************************Test results************************\")\n            print(\n                \"Test Evaluation: acc: {:.5f}, kappa: {:.5f}, f1: {:.5f}\".format(\n                    acc,\n                    kappa,\n                    f1,\n                )\n            )\n            print(cm)\n            if not os.path.isdir(self.params.model_dir):\n                os.makedirs(self.params.model_dir)\n            model_path = self.params.model_dir + \"/epoch{}_acc_{:.5f}_kappa_{:.5f}_f1_{:.5f}.pth\".format(best_f1_epoch, acc, kappa, f1)\n            torch.save(self.model.state_dict(), model_path)\n            print(\"model save in \" + model_path)\n\n    def train_for_binaryclass(self):\n        acc_best = 0\n        roc_auc_best = 0\n        pr_auc_best = 0\n        cm_best = None\n        for epoch in range(self.params.epochs):\n            self.model.train()\n            start_time = timer()\n            losses = []\n            for x, y in tqdm(self.data_loader['train'], mininterval=10):\n                self.optimizer.zero_grad()\n                x = x.cuda()\n                y = y.cuda()\n                pred = self.model(x)\n\n                loss = self.criterion(pred, y)\n\n                loss.backward()\n                losses.append(loss.data.cpu().numpy())\n                if self.params.clip_value > 0:\n                    torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.params.clip_value)\n                    # torch.nn.utils.clip_grad_value_(self.model.parameters(), self.params.clip_value)\n                self.optimizer.step()\n                self.optimizer_scheduler.step()\n\n            optim_state = self.optimizer.state_dict()\n\n            with torch.no_grad():\n                acc, pr_auc, roc_auc, cm = self.val_eval.get_metrics_for_binaryclass(self.model)\n                print(\n                    \"Epoch {} : Training Loss: {:.5f}, acc: {:.5f}, pr_auc: {:.5f}, roc_auc: {:.5f}, LR: {:.5f}, Time elapsed {:.2f} mins\".format(\n                        epoch + 1,\n                        np.mean(losses),\n                        acc,\n                        pr_auc,\n                        roc_auc,\n                        optim_state['param_groups'][0]['lr'],\n                        (timer() - start_time) / 60\n                    )\n                )\n                print(cm)\n                if roc_auc > roc_auc_best:\n                    print(\"kappa increasing....saving weights !! \")\n                    print(\"Val Evaluation: acc: {:.5f}, pr_auc: {:.5f}, roc_auc: {:.5f}\".format(\n                        acc,\n                        pr_auc,\n                        roc_auc,\n                    ))\n                    best_f1_epoch = epoch + 1\n                    acc_best = acc\n                    pr_auc_best = pr_auc\n                    roc_auc_best = roc_auc\n                    cm_best = cm\n                    self.best_model_states = copy.deepcopy(self.model.state_dict())\n        self.model.load_state_dict(self.best_model_states)\n        with torch.no_grad():\n            print(\"***************************Test************************\")\n            acc, pr_auc, roc_auc, cm = self.test_eval.get_metrics_for_binaryclass(self.model)\n            print(\"***************************Test results************************\")\n            print(\n                \"Test Evaluation: acc: {:.5f}, pr_auc: {:.5f}, roc_auc: {:.5f}\".format(\n                    acc,\n                    pr_auc,\n                    roc_auc,\n                )\n            )\n            print(cm)\n            if not os.path.isdir(self.params.model_dir):\n                os.makedirs(self.params.model_dir)\n            model_path = self.params.model_dir + \"/epoch{}_acc_{:.5f}_pr_{:.5f}_roc_{:.5f}.pth\".format(best_f1_epoch, acc, pr_auc, roc_auc)\n            torch.save(self.model.state_dict(), model_path)\n            print(\"model save in \" + model_path)\n\n    def train_for_regression(self):\n        corrcoef_best = 0\n        r2_best = 0\n        rmse_best = 0\n        for epoch in range(self.params.epochs):\n            self.model.train()\n            start_time = timer()\n            losses = []\n            for x, y in tqdm(self.data_loader['train'], mininterval=10):\n                self.optimizer.zero_grad()\n                x = x.cuda()\n                y = y.cuda()\n                pred = self.model(x)\n                loss = self.criterion(pred, y)\n\n                loss.backward()\n                losses.append(loss.data.cpu().numpy())\n                if self.params.clip_value > 0:\n                    torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.params.clip_value)\n                    # torch.nn.utils.clip_grad_value_(self.model.parameters(), self.params.clip_value)\n                self.optimizer.step()\n                self.optimizer_scheduler.step()\n\n            optim_state = self.optimizer.state_dict()\n\n            with torch.no_grad():\n                corrcoef, r2, rmse = self.val_eval.get_metrics_for_regression(self.model)\n                print(\n                    \"Epoch {} : Training Loss: {:.5f}, corrcoef: {:.5f}, r2: {:.5f}, rmse: {:.5f}, LR: {:.5f}, Time elapsed {:.2f} mins\".format(\n                        epoch + 1,\n                        np.mean(losses),\n                        corrcoef,\n                        r2,\n                        rmse,\n                        optim_state['param_groups'][0]['lr'],\n                        (timer() - start_time) / 60\n                    )\n                )\n                if r2 > r2_best:\n                    print(\"kappa increasing....saving weights !! \")\n                    print(\"Val Evaluation: corrcoef: {:.5f}, r2: {:.5f}, rmse: {:.5f}\".format(\n                        corrcoef,\n                        r2,\n                        rmse,\n                    ))\n                    best_r2_epoch = epoch + 1\n                    corrcoef_best = corrcoef\n                    r2_best = r2\n                    rmse_best = rmse\n                    self.best_model_states = copy.deepcopy(self.model.state_dict())\n\n        self.model.load_state_dict(self.best_model_states)\n        with torch.no_grad():\n            print(\"***************************Test************************\")\n            corrcoef, r2, rmse = self.test_eval.get_metrics_for_regression(self.model)\n            print(\"***************************Test results************************\")\n            print(\n                \"Test Evaluation: corrcoef: {:.5f}, r2: {:.5f}, rmse: {:.5f}\".format(\n                    corrcoef,\n                    r2,\n                    rmse,\n                )\n            )\n\n            if not os.path.isdir(self.params.model_dir):\n                os.makedirs(self.params.model_dir)\n            model_path = self.params.model_dir + \"/epoch{}_corrcoef_{:.5f}_r2_{:.5f}_rmse_{:.5f}.pth\".format(best_r2_epoch, corrcoef, r2, rmse)\n            torch.save(self.model.state_dict(), model_path)\n            print(\"model save in \" + model_path)"}
{"doc_id": "models/model_for_mumtaz.py", "text": "import torch\nimport torch.nn as nn\nfrom einops.layers.torch import Rearrange\n\nfrom .cbramod import CBraMod\n\n\nclass Model(nn.Module):\n    def __init__(self, param):\n        super(Model, self).__init__()\n        self.backbone = CBraMod(\n            in_dim=200, out_dim=200, d_model=200,\n            dim_feedforward=800, seq_len=30,\n            n_layer=12, nhead=8\n        )\n        if param.use_pretrained_weights:\n            map_location = torch.device(f'cuda:{param.cuda}')\n            self.backbone.load_state_dict(torch.load(param.foundation_dir, map_location=map_location))\n        self.backbone.proj_out = nn.Identity()\n        if param.classifier == 'avgpooling_patch_reps':\n            self.classifier = nn.Sequential(\n                Rearrange('b c s d -> b d c s'),\n                nn.AdaptiveAvgPool2d((1, 1)),\n                nn.Flatten(),\n                nn.Linear(200, 1),\n                Rearrange('b 1 -> (b 1)'),\n            )\n        elif param.classifier == 'all_patch_reps':\n            self.classifier = nn.Sequential(\n                Rearrange('b c s d -> b (c s d)'),\n                nn.Linear(19 * 5 * 200, 5 * 200),\n                nn.ELU(),\n                nn.Dropout(param.dropout),\n                nn.Linear(5 * 200, 200),\n                nn.ELU(),\n                nn.Dropout(param.dropout),\n                nn.Linear(200, 1),\n                Rearrange('b 1 -> (b 1)'),\n            )\n\n    def forward(self, x):\n        bz, ch_num, seq_len, patch_size = x.shape\n        feats = self.backbone(x)\n        out = self.classifier(feats)\n        return out\n"}
{"doc_id": "models/model_for_seedv.py", "text": "import torch\nimport torch.nn as nn\nfrom einops.layers.torch import Rearrange\n\nfrom .cbramod import CBraMod\n\n\nclass Model(nn.Module):\n    def __init__(self, param):\n        super(Model, self).__init__()\n        self.backbone = CBraMod(\n            in_dim=200, out_dim=200, d_model=200,\n            dim_feedforward=800, seq_len=30,\n            n_layer=12, nhead=8\n        )\n        if param.use_pretrained_weights:\n            map_location = torch.device(f'cuda:{param.cuda}')\n            self.backbone.load_state_dict(torch.load(param.foundation_dir, map_location=map_location))\n        self.backbone.proj_out = nn.Identity()\n        if param.classifier == 'avgpooling_patch_reps':\n            self.classifier = nn.Sequential(\n                Rearrange('b c s d -> b d c s'),\n                nn.AdaptiveAvgPool2d((1, 1)),\n                nn.Flatten(),\n                nn.Linear(200, param.num_of_classes),\n            )\n        elif param.classifier == 'all_patch_reps':\n            self.classifier = nn.Sequential(\n                Rearrange('b c s d -> b (c s d)'),\n                nn.Linear(62 * 1 * 200, 4 * 200),\n                nn.ELU(),\n                nn.Dropout(param.dropout),\n                nn.Linear(4 * 200, 200),\n                nn.ELU(),\n                nn.Dropout(param.dropout),\n                nn.Linear(200, param.num_of_classes),\n            )\n\n    def forward(self, x):\n        # x = x / 100\n        bz, ch_num, seq_len, patch_size = x.shape\n        feats = self.backbone(x)\n        feats = feats.contiguous().view(bz, ch_num*seq_len*200)\n        out = self.classifier(feats)\n        return out\n"}
{"doc_id": "models/model_for_faced.py", "text": "import torch\nimport torch.nn as nn\nfrom einops.layers.torch import Rearrange\n\nfrom .cbramod import CBraMod\n\n\nclass Model(nn.Module):\n    def __init__(self, param):\n        super(Model, self).__init__()\n        self.backbone = CBraMod(\n            in_dim=200, out_dim=200, d_model=200,\n            dim_feedforward=800, seq_len=30,\n            n_layer=12, nhead=8\n        )\n\n        if param.use_pretrained_weights:\n            map_location = torch.device(f'cuda:{param.cuda}')\n            self.backbone.load_state_dict(torch.load(param.foundation_dir, map_location=map_location))\n        self.backbone.proj_out = nn.Identity()\n\n        if param.classifier == 'avgpooling_patch_reps':\n            self.classifier = nn.Sequential(\n                Rearrange('b c s d -> b d c s'),\n                nn.AdaptiveAvgPool2d((1, 1)),\n                nn.Flatten(),\n                nn.Linear(200, param.num_of_classes),\n            )\n        elif param.classifier == 'all_patch_reps':\n            self.classifier = nn.Sequential(\n                Rearrange('b c s d -> b (c s d)'),\n                nn.Linear(32 * 10 * 200, 10 * 200),\n                nn.ELU(),\n                nn.Dropout(param.dropout),\n                nn.Linear(10 * 200, 200),\n                nn.ELU(),\n                nn.Dropout(param.dropout),\n                nn.Linear(200, param.num_of_classes),\n            )\n\n    def forward(self, x):\n        bz, ch_num, seq_len, patch_size = x.shape\n        feats = self.backbone(x)\n        out = self.classifier(feats)\n        return out\n\n\n\n"}
{"doc_id": "models/criss_cross_transformer.py", "text": "import copy\nfrom typing import Optional, Any, Union, Callable\n\nimport torch\nimport torch.nn as nn\n# import torch.nn.functional as F\nimport warnings\nfrom torch import Tensor\nfrom torch.nn import functional as F\n\n\nclass TransformerEncoder(nn.Module):\n    def __init__(self, encoder_layer, num_layers, norm=None, enable_nested_tensor=True, mask_check=True):\n        super().__init__()\n        torch._C._log_api_usage_once(f\"torch.nn.modules.{self.__class__.__name__}\")\n        self.layers = _get_clones(encoder_layer, num_layers)\n        self.num_layers = num_layers\n        self.norm = norm\n\n    def forward(\n            self,\n            src: Tensor,\n            mask: Optional[Tensor] = None,\n            src_key_padding_mask: Optional[Tensor] = None,\n            is_causal: Optional[bool] = None) -> Tensor:\n\n        output = src\n        for mod in self.layers:\n            output = mod(output, src_mask=mask)\n        if self.norm is not None:\n            output = self.norm(output)\n        return output\n\n\nclass TransformerEncoderLayer(nn.Module):\n    __constants__ = ['norm_first']\n\n    def __init__(self, d_model: int, nhead: int, dim_feedforward: int = 2048, dropout: float = 0.1,\n                 activation: Union[str, Callable[[Tensor], Tensor]] = F.relu,\n                 layer_norm_eps: float = 1e-5, batch_first: bool = False, norm_first: bool = False,\n                 bias: bool = True, device=None, dtype=None) -> None:\n        factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__()\n        self.self_attn_s = nn.MultiheadAttention(d_model//2, nhead // 2, dropout=dropout,\n                                                 bias=bias, batch_first=batch_first,\n                                                 **factory_kwargs)\n        self.self_attn_t = nn.MultiheadAttention(d_model//2, nhead // 2, dropout=dropout,\n                                                 bias=bias, batch_first=batch_first,\n                                                 **factory_kwargs)\n\n        # Implementation of Feedforward model\n        self.linear1 = nn.Linear(d_model, dim_feedforward, bias=bias, **factory_kwargs)\n        self.dropout = nn.Dropout(dropout)\n        self.linear2 = nn.Linear(dim_feedforward, d_model, bias=bias, **factory_kwargs)\n\n        self.norm_first = norm_first\n        self.norm1 = nn.LayerNorm(d_model, eps=layer_norm_eps, **factory_kwargs)\n        self.norm2 = nn.LayerNorm(d_model, eps=layer_norm_eps, **factory_kwargs)\n        self.dropout1 = nn.Dropout(dropout)\n        self.dropout2 = nn.Dropout(dropout)\n\n        # Legacy string support for activation function.\n        if isinstance(activation, str):\n            activation = _get_activation_fn(activation)\n\n        # We can't test self.activation in forward() in TorchScript,\n        # so stash some information about it instead.\n        if activation is F.relu or isinstance(activation, torch.nn.ReLU):\n            self.activation_relu_or_gelu = 1\n        elif activation is F.gelu or isinstance(activation, torch.nn.GELU):\n            self.activation_relu_or_gelu = 2\n        else:\n            self.activation_relu_or_gelu = 0\n        self.activation = activation\n\n    def __setstate__(self, state):\n        super().__setstate__(state)\n        if not hasattr(self, 'activation'):\n            self.activation = F.relu\n\n\n    def forward(\n            self,\n            src: Tensor,\n            src_mask: Optional[Tensor] = None,\n            src_key_padding_mask: Optional[Tensor] = None,\n            is_causal: bool = False) -> Tensor:\n\n        x = src\n        x = x + self._sa_block(self.norm1(x), src_mask, src_key_padding_mask, is_causal=is_causal)\n        x = x + self._ff_block(self.norm2(x))\n        return x\n\n    # self-attention block\n    def _sa_block(self, x: Tensor,\n                  attn_mask: Optional[Tensor], key_padding_mask: Optional[Tensor], is_causal: bool = False) -> Tensor:\n        bz, ch_num, patch_num, patch_size = x.shape\n        xs = x[:, :, :, :patch_size // 2]\n        xt = x[:, :, :, patch_size // 2:]\n        xs = xs.transpose(1, 2).contiguous().view(bz*patch_num, ch_num, patch_size // 2)\n        xt = xt.contiguous().view(bz*ch_num, patch_num, patch_size // 2)\n        xs = self.self_attn_s(xs, xs, xs,\n                             attn_mask=attn_mask,\n                             key_padding_mask=key_padding_mask,\n                             need_weights=False)[0]\n        xs = xs.contiguous().view(bz, patch_num, ch_num, patch_size//2).transpose(1, 2)\n        xt = self.self_attn_t(xt, xt, xt,\n                              attn_mask=attn_mask,\n                              key_padding_mask=key_padding_mask,\n                              need_weights=False)[0]\n        xt = xt.contiguous().view(bz, ch_num, patch_num, patch_size//2)\n        x = torch.concat((xs, xt), dim=3)\n        return self.dropout1(x)\n\n    # feed forward block\n    def _ff_block(self, x: Tensor) -> Tensor:\n        x = self.linear2(self.dropout(self.activation(self.linear1(x))))\n        return self.dropout2(x)\n\n\n\ndef _get_activation_fn(activation: str) -> Callable[[Tensor], Tensor]:\n    if activation == \"relu\":\n        return F.relu\n    elif activation == \"gelu\":\n        return F.gelu\n\n    raise RuntimeError(f\"activation should be relu/gelu, not {activation}\")\n\ndef _get_clones(module, N):\n    # FIXME: copy.deepcopy() is not defined on nn.module\n    return nn.ModuleList([copy.deepcopy(module) for i in range(N)])\n\n\ndef _get_seq_len(\n        src: Tensor,\n        batch_first: bool\n) -> Optional[int]:\n\n    if src.is_nested:\n        return None\n    else:\n        src_size = src.size()\n        if len(src_size) == 2:\n            # unbatched: S, E\n            return src_size[0]\n        else:\n            # batched: B, S, E if batch_first else S, B, E\n            seq_len_pos = 1 if batch_first else 0\n            return src_size[seq_len_pos]\n\n\ndef _detect_is_causal_mask(\n        mask: Optional[Tensor],\n        is_causal: Optional[bool] = None,\n        size: Optional[int] = None,\n) -> bool:\n    \"\"\"Return whether the given attention mask is causal.\n\n    Warning:\n    If ``is_causal`` is not ``None``, its value will be returned as is.  If a\n    user supplies an incorrect ``is_causal`` hint,\n\n    ``is_causal=False`` when the mask is in fact a causal attention.mask\n       may lead to reduced performance relative to what would be achievable\n       with ``is_causal=True``;\n    ``is_causal=True`` when the mask is in fact not a causal attention.mask\n       may lead to incorrect and unpredictable execution - in some scenarios,\n       a causal mask may be applied based on the hint, in other execution\n       scenarios the specified mask may be used.  The choice may not appear\n       to be deterministic, in that a number of factors like alignment,\n       hardware SKU, etc influence the decision whether to use a mask or\n       rely on the hint.\n    ``size`` if not None, check whether the mask is a causal mask of the provided size\n       Otherwise, checks for any causal mask.\n    \"\"\"\n    # Prevent type refinement\n    make_causal = (is_causal is True)\n\n    if is_causal is None and mask is not None:\n        sz = size if size is not None else mask.size(-2)\n        causal_comparison = _generate_square_subsequent_mask(\n            sz, device=mask.device, dtype=mask.dtype)\n\n        # Do not use `torch.equal` so we handle batched masks by\n        # broadcasting the comparison.\n        if mask.size() == causal_comparison.size():\n            make_causal = bool((mask == causal_comparison).all())\n        else:\n            make_causal = False\n\n    return make_causal\n\n\ndef _generate_square_subsequent_mask(\n        sz: int,\n        device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n        dtype: torch.dtype = torch.get_default_dtype(),\n) -> Tensor:\n    r\"\"\"Generate a square causal mask for the sequence. The masked positions are filled with float('-inf').\n        Unmasked positions are filled with float(0.0).\n    \"\"\"\n    return torch.triu(\n        torch.full((sz, sz), float('-inf'), dtype=dtype, device=device),\n        diagonal=1,\n    )\n\n\nif __name__ == '__main__':\n    encoder_layer = TransformerEncoderLayer(\n        d_model=256, nhead=4, dim_feedforward=1024, batch_first=True, norm_first=True,\n        activation=F.gelu\n    )\n    encoder = TransformerEncoder(encoder_layer, num_layers=2, enable_nested_tensor=False)\n    encoder = encoder.cuda()\n\n    a = torch.randn((4, 19, 30, 256)).cuda()\n    b = encoder(a)\n    print(a.shape, b.shape)"}
{"doc_id": "models/model_for_tuev.py", "text": "import torch\nimport torch.nn as nn\nfrom einops.layers.torch import Rearrange\n\nfrom .cbramod import CBraMod\n\n\nclass Model(nn.Module):\n    def __init__(self, param):\n        super(Model, self).__init__()\n        self.backbone = CBraMod(\n            in_dim=200, out_dim=200, d_model=200,\n            dim_feedforward=800, seq_len=30,\n            n_layer=12, nhead=8\n        )\n        if param.use_pretrained_weights:\n            map_location = torch.device(f'cuda:{param.cuda}')\n            self.backbone.load_state_dict(torch.load(param.foundation_dir, map_location=map_location))\n        self.backbone.proj_out = nn.Identity()\n\n        if param.classifier == 'avgpooling_patch_reps':\n            self.classifier = nn.Sequential(\n                Rearrange('b c s d -> b d c s'),\n                nn.AdaptiveAvgPool2d((1, 1)),\n                nn.Flatten(),\n                nn.Linear(200, param.num_of_classes),\n            )\n        elif param.classifier == 'all_patch_reps':\n            self.classifier = nn.Sequential(\n                Rearrange('b c s d -> b (c s d)'),\n                nn.Linear(16 * 5 * 200, 5 * 200),\n                nn.ELU(),\n                nn.Dropout(param.dropout),\n                nn.Linear(5 * 200, 200),\n                nn.ELU(),\n                nn.Dropout(param.dropout),\n                nn.Linear(200, param.num_of_classes),\n            )\n\n    def forward(self, x):\n        bz, ch_num, seq_len, patch_size = x.shape\n        feats = self.backbone(x)\n        out = self.classifier(feats)\n        return out\n\n"}
{"doc_id": "models/model_for_isruc.py", "text": "import torch\nimport torch.nn as nn\n\nfrom .cbramod import CBraMod\n\n\nclass Model(nn.Module):\n    def __init__(self, param):\n        super().__init__()\n        self.backbone = CBraMod(\n            in_dim=200, out_dim=200, d_model=200,\n            dim_feedforward=800, seq_len=30,\n            n_layer=12, nhead=8\n        )\n        if param.use_pretrained_weights:\n            map_location = torch.device(f'cuda:{param.cuda}')\n            self.backbone.load_state_dict(torch.load(param.foundation_dir, map_location=map_location))\n        self.backbone.proj_out = nn.Identity()\n\n        self.head = nn.Sequential(\n            nn.Linear(6*30*200, 512),\n            nn.GELU(),\n        )\n\n        encoder_layer = nn.TransformerEncoderLayer(\n            d_model=512, nhead=4, dim_feedforward=2048, batch_first=True, activation=F.gelu, norm_first=True\n        )\n        self.sequence_encoder = nn.TransformerEncoder(encoder_layer, num_layers=1, enable_nested_tensor=False)\n        self.classifier = nn.Linear(512, param.num_of_classes)\n\n        # self.apply(_weights_init)\n\n    def forward(self, x):\n        bz, seq_len, ch_num, epoch_size = x.shape\n\n        x = x.contiguous().view(bz * seq_len, ch_num, 30, 200)\n        epoch_features = self.backbone(x)\n        epoch_features = epoch_features.contiguous().view(bz, seq_len, ch_num*30*200)\n        epoch_features = self.head(epoch_features)\n        seq_features = self.sequence_encoder(epoch_features)\n        out = self.classifier(seq_features)\n        return out\n"}
{"doc_id": "models/model_for_speech.py", "text": "import torch\nimport torch.nn as nn\nfrom einops.layers.torch import Rearrange\n\nfrom .cbramod import CBraMod\n\n\nclass Model(nn.Module):\n    def __init__(self, param):\n        super(Model, self).__init__()\n        self.backbone = CBraMod(\n            in_dim=200, out_dim=200, d_model=200,\n            dim_feedforward=800, seq_len=30,\n            n_layer=12, nhead=8\n        )\n        if param.use_pretrained_weights:\n            map_location = torch.device(f'cuda:{param.cuda}')\n            self.backbone.load_state_dict(torch.load(param.foundation_dir, map_location=map_location))\n        self.backbone.proj_out = nn.Identity()\n        if param.classifier == 'avgpooling_patch_reps':\n            self.classifier = nn.Sequential(\n                Rearrange('b c s d -> b d c s'),\n                nn.AdaptiveAvgPool2d((1, 1)),\n                nn.Flatten(),\n                nn.Linear(200, param.num_of_classes)\n            )\n        elif param.classifier == 'all_patch_reps':\n            self.classifier = nn.Sequential(\n                Rearrange('b c s d -> b (c s d)'),\n                nn.Linear(64*3*200, 3*200),\n                nn.ELU(),\n                nn.Dropout(param.dropout),\n                nn.Linear(3*200, 200),\n                nn.ELU(),\n                nn.Dropout(param.dropout),\n                nn.Linear(200, param.num_of_classes),\n            )\n\n    def forward(self, x):\n        bz, ch_num, seq_len, patch_size = x.shape\n        feats = self.backbone(x)\n        out = self.classifier(feats)\n        return out\n\n"}
{"doc_id": "models/model_for_chb.py", "text": "import torch\nimport torch.nn as nn\nfrom einops.layers.torch import Rearrange\nfrom .cbramod import CBraMod\n\n\nclass Model(nn.Module):\n    def __init__(self, param):\n        super(Model, self).__init__()\n        self.backbone = CBraMod(\n            in_dim=200, out_dim=200, d_model=200,\n            dim_feedforward=800, seq_len=30,\n            n_layer=12, nhead=8\n        )\n        if param.use_pretrained_weights:\n            map_location = torch.device(f'cuda:{param.cuda}')\n            self.backbone.load_state_dict(torch.load(param.foundation_dir, map_location=map_location))\n        self.backbone.proj_out = nn.Identity()\n\n        if param.classifier == 'avgpooling_patch_reps':\n            self.classifier = nn.Sequential(\n                Rearrange('b c s d -> b d c s'),\n                nn.AdaptiveAvgPool2d((1, 1)),\n                nn.Flatten(),\n                nn.Linear(200, 1),\n                Rearrange('b 1 -> (b 1)'),\n            )\n        elif param.classifier == 'all_patch_reps':\n            self.classifier = nn.Sequential(\n                Rearrange('b c s d -> b (c s d)'),\n                nn.Linear(16*10*200, 10*200),\n                nn.ELU(),\n                nn.Dropout(param.dropout),\n                nn.Linear(10*200, 200),\n                nn.ELU(),\n                nn.Dropout(param.dropout),\n                nn.Linear(200, 1),\n                Rearrange('b 1 -> (b 1)'),\n            )\n\n    def forward(self, x):\n        bz, ch_num, seq_len, patch_size = x.shape\n        feats = self.backbone(x)\n        out = self.classifier(feats)\n        return out"}
{"doc_id": "models/model_for_bciciv2a.py", "text": "import torch\nimport torch.nn as nn\nfrom einops.layers.torch import Rearrange\nfrom .cbramod import CBraMod\n\n\nclass Model(nn.Module):\n    def __init__(self, param):\n        super(Model, self).__init__()\n        self.backbone = CBraMod(\n            in_dim=200, out_dim=200, d_model=200,\n            dim_feedforward=800, seq_len=30,\n            n_layer=12, nhead=8\n        )\n        if param.use_pretrained_weights:\n            map_location = torch.device(f'cuda:{param.cuda}')\n            self.backbone.load_state_dict(torch.load(param.foundation_dir, map_location=map_location))\n        self.backbone.proj_out = nn.Identity()\n        if param.classifier == 'avgpooling_patch_reps':\n            self.classifier = nn.Sequential(\n                Rearrange('b c s d -> b d c s'),\n                nn.AdaptiveAvgPool2d((1, 1)),\n                nn.Flatten(),\n                nn.Linear(200, param.num_of_classes),\n            )\n        elif param.classifier == 'all_patch_reps':\n            self.classifier = nn.Sequential(\n                Rearrange('b c s d -> b (c s d)'),\n                nn.Linear(22 * 4 * 200, 4 * 200),\n                nn.ELU(),\n                nn.Dropout(param.dropout),\n                nn.Linear(4 * 200, 200),\n                nn.ELU(),\n                nn.Dropout(param.dropout),\n                nn.Linear(200, param.num_of_classes),\n            )\n\n    def forward(self, x):\n        # x = x / 100\n        bz, ch_num, seq_len, patch_size = x.shape\n        feats = self.backbone(x)\n        out = self.classifier(feats)\n        return out\n"}
{"doc_id": "models/model_for_stress.py", "text": "import torch\nimport torch.nn as nn\nfrom einops.layers.torch import Rearrange\n\nfrom .cbramod import CBraMod\n\nclass Model(nn.Module):\n    def __init__(self, param):\n        super(Model, self).__init__()\n        self.backbone = CBraMod(\n            in_dim=200, out_dim=200, d_model=200,\n            dim_feedforward=800, seq_len=30,\n            n_layer=12, nhead=8\n        )\n        if param.use_pretrained_weights:\n            map_location = torch.device(f'cuda:{param.cuda}')\n            self.backbone.load_state_dict(torch.load(param.foundation_dir, map_location=map_location))\n        self.backbone.proj_out = nn.Identity()\n        if param.classifier == 'avgpooling_patch_reps':\n            self.classifier = nn.Sequential(\n                Rearrange('b c s d -> b d c s'),\n                nn.AdaptiveAvgPool2d((1, 1)),\n                nn.Flatten(),\n                nn.Linear(200, 1),\n                Rearrange('b 1 -> (b 1)'),\n            )\n        elif param.classifier == 'all_patch_reps':\n            self.classifier = nn.Sequential(\n                Rearrange('b c s d -> b (c s d)'),\n                nn.Linear(20 * 5 * 200, 5 * 200),\n                nn.ELU(),\n                nn.Dropout(param.dropout),\n                nn.Linear(5 * 200, 200),\n                nn.ELU(),\n                nn.Dropout(param.dropout),\n                nn.Linear(200, 1),\n                Rearrange('b 1 -> (b 1)'),\n            )\n\n    def forward(self, x):\n        bz, ch_num, seq_len, patch_size = x.shape\n        feats = self.backbone(x)\n        out = self.classifier(feats)\n        return out\n\n"}
{"doc_id": "models/cbramod.py", "text": "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nfrom models.criss_cross_transformer import TransformerEncoderLayer, TransformerEncoder\n\n\nclass CBraMod(nn.Module):\n    def __init__(self, in_dim=200, out_dim=200, d_model=200, dim_feedforward=800, seq_len=30, n_layer=12,\n                    nhead=8):\n        super().__init__()\n        self.patch_embedding = PatchEmbedding(in_dim, out_dim, d_model, seq_len)\n        encoder_layer = TransformerEncoderLayer(\n            d_model=d_model, nhead=nhead, dim_feedforward=dim_feedforward, batch_first=True, norm_first=True,\n            activation=F.gelu\n        )\n        self.encoder = TransformerEncoder(encoder_layer, num_layers=n_layer, enable_nested_tensor=False)\n        self.proj_out = nn.Sequential(\n            # nn.Linear(d_model, d_model*2),\n            # nn.GELU(),\n            # nn.Linear(d_model*2, d_model),\n            # nn.GELU(),\n            nn.Linear(d_model, out_dim),\n        )\n        self.apply(_weights_init)\n\n    def forward(self, x, mask=None):\n        patch_emb = self.patch_embedding(x, mask)\n        feats = self.encoder(patch_emb)\n\n        out = self.proj_out(feats)\n\n        return out\n\nclass PatchEmbedding(nn.Module):\n    def __init__(self, in_dim, out_dim, d_model, seq_len):\n        super().__init__()\n        self.d_model = d_model\n        self.positional_encoding = nn.Sequential(\n            nn.Conv2d(in_channels=d_model, out_channels=d_model, kernel_size=(19, 7), stride=(1, 1), padding=(9, 3),\n                      groups=d_model),\n        )\n        self.mask_encoding = nn.Parameter(torch.zeros(in_dim), requires_grad=False)\n        # self.mask_encoding = nn.Parameter(torch.randn(in_dim), requires_grad=True)\n\n        self.proj_in = nn.Sequential(\n            nn.Conv2d(in_channels=1, out_channels=25, kernel_size=(1, 49), stride=(1, 25), padding=(0, 24)),\n            nn.GroupNorm(5, 25),\n            nn.GELU(),\n\n            nn.Conv2d(in_channels=25, out_channels=25, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1)),\n            nn.GroupNorm(5, 25),\n            nn.GELU(),\n\n            nn.Conv2d(in_channels=25, out_channels=25, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1)),\n            nn.GroupNorm(5, 25),\n            nn.GELU(),\n        )\n        self.spectral_proj = nn.Sequential(\n            nn.Linear(101, d_model),\n            nn.Dropout(0.1),\n            # nn.LayerNorm(d_model, eps=1e-5),\n        )\n        # self.norm1 = nn.LayerNorm(d_model, eps=1e-5)\n        # self.norm2 = nn.LayerNorm(d_model, eps=1e-5)\n        # self.proj_in = nn.Sequential(\n        #     nn.Linear(in_dim, d_model, bias=False),\n        # )\n\n\n    def forward(self, x, mask=None):\n        bz, ch_num, patch_num, patch_size = x.shape\n        if mask == None:\n            mask_x = x\n        else:\n            mask_x = x.clone()\n            mask_x[mask == 1] = self.mask_encoding\n\n        mask_x = mask_x.contiguous().view(bz, 1, ch_num * patch_num, patch_size)\n        patch_emb = self.proj_in(mask_x)\n        patch_emb = patch_emb.permute(0, 2, 1, 3).contiguous().view(bz, ch_num, patch_num, self.d_model)\n\n        mask_x = mask_x.contiguous().view(bz*ch_num*patch_num, patch_size)\n        spectral = torch.fft.rfft(mask_x, dim=-1, norm='forward')\n        spectral = torch.abs(spectral).contiguous().view(bz, ch_num, patch_num, 101)\n        spectral_emb = self.spectral_proj(spectral)\n        # print(patch_emb[5, 5, 5, :])\n        # print(spectral_emb[5, 5, 5, :])\n        patch_emb = patch_emb + spectral_emb\n\n        positional_embedding = self.positional_encoding(patch_emb.permute(0, 3, 1, 2))\n        positional_embedding = positional_embedding.permute(0, 2, 3, 1)\n\n        patch_emb = patch_emb + positional_embedding\n\n        return patch_emb\n\n\ndef _weights_init(m):\n    if isinstance(m, nn.Linear):\n        nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n    if isinstance(m, nn.Conv1d):\n        nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n    elif isinstance(m, nn.BatchNorm1d):\n        nn.init.constant_(m.weight, 1)\n        nn.init.constant_(m.bias, 0)\n\n\n\nif __name__ == '__main__':\n\n    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n    model = CBraMod(in_dim=200, out_dim=200, d_model=200, dim_feedforward=800, seq_len=30, n_layer=12,\n                    nhead=8).to(device)\n    model.load_state_dict(torch.load('pretrained_weights/pretrained_weights.pth',\n                                     map_location=device))\n    a = torch.randn((8, 16, 10, 200)).cuda()\n    b = model(a)\n    print(a.shape, b.shape)\n"}
{"doc_id": "models/model_for_seedvig.py", "text": "import torch\nimport torch.nn as nn\nfrom einops.layers.torch import Rearrange\n\nfrom .cbramod import CBraMod\n\n\nclass Model(nn.Module):\n    def __init__(self, param):\n        super(Model, self).__init__()\n        self.backbone = CBraMod(\n            in_dim=200, out_dim=200, d_model=200,\n            dim_feedforward=800, seq_len=30,\n            n_layer=12, nhead=8\n        )\n        if param.use_pretrained_weights:\n            map_location = torch.device(f'cuda:{param.cuda}')\n            self.backbone.load_state_dict(torch.load(param.foundation_dir, map_location=map_location))\n        self.backbone.proj_out = nn.Identity()\n        if param.classifier == 'avgpooling_patch_reps':\n            self.classifier = nn.Sequential(\n                Rearrange('b c s d -> b d c s'),\n                nn.AdaptiveAvgPool2d((1, 1)),\n                nn.Flatten(),\n                nn.Linear(200, 1),\n                Rearrange('b 1 -> (b 1)'),\n            )\n        elif param.classifier == 'all_patch_reps':\n            self.classifier = nn.Sequential(\n                Rearrange('b c s d -> b (c s d)'),\n                nn.Linear(17 * 8 * 200, 8 * 200),\n                nn.ELU(),\n                nn.Dropout(param.dropout),\n                nn.Linear(8 * 200, 200),\n                nn.ELU(),\n                nn.Dropout(param.dropout),\n                nn.Linear(200, 1),\n                Rearrange('b 1 -> (b 1)'),\n            )\n\n    def forward(self, x):\n        bz, ch_num, seq_len, patch_size = x.shape\n        feats = self.backbone(x)\n        out = self.classifier(feats)\n        return out\n\n"}
{"doc_id": "models/model_for_physio.py", "text": "import torch\nimport torch.nn as nn\nfrom einops.layers.torch import Rearrange\n\nfrom .cbramod import CBraMod\n\n\nclass Model(nn.Module):\n    def __init__(self, param):\n        super(Model, self).__init__()\n        self.backbone = CBraMod(\n            in_dim=200, out_dim=200, d_model=200,\n            dim_feedforward=800, seq_len=30,\n            n_layer=12, nhead=8\n        )\n        if param.use_pretrained_weights:\n            map_location = torch.device(f'cuda:{param.cuda}')\n            self.backbone.load_state_dict(torch.load(param.foundation_dir, map_location=map_location))\n        self.backbone.proj_out = nn.Identity()\n        if param.classifier == 'avgpooling_patch_reps':\n            self.classifier = nn.Sequential(\n                Rearrange('b c s d -> b d c s'),\n                nn.AdaptiveAvgPool2d((1, 1)),\n                nn.Flatten(),\n                nn.Linear(200, param.num_of_classes),\n            )\n        elif param.classifier == 'all_patch_reps':\n            self.classifier = nn.Sequential(\n                Rearrange('b c s d -> b (c s d)'),\n                nn.Linear(64 * 4 * 200, 4 * 200),\n                nn.ELU(),\n                nn.Dropout(param.dropout),\n                nn.Linear(4 * 200, 200),\n                nn.ELU(),\n                nn.Dropout(param.dropout),\n                nn.Linear(200, param.num_of_classes),\n            )\n\n\n    def forward(self, x):\n        bz, ch_num, seq_len, patch_size = x.shape\n        feats = self.backbone(x)\n        out = self.classifier(feats)\n        return out\n"}
{"doc_id": "models/model_for_shu.py", "text": "import torch\nimport torch.nn as nn\nfrom einops.layers.torch import Rearrange\n\nfrom .cbramod import CBraMod\n\n\nclass Model(nn.Module):\n    def __init__(self, param):\n        super(Model, self).__init__()\n        self.backbone = CBraMod(\n            in_dim=200, out_dim=200, d_model=200,\n            dim_feedforward=800, seq_len=30,\n            n_layer=12, nhead=8\n        )\n        if param.use_pretrained_weights:\n            map_location = torch.device(f'cuda:{param.cuda}')\n            self.backbone.load_state_dict(torch.load(param.foundation_dir, map_location=map_location))\n        self.backbone.proj_out = nn.Identity()\n        if param.classifier == 'avgpooling_patch_reps':\n            self.classifier = nn.Sequential(\n                Rearrange('b c s d -> b d c s'),\n                nn.AdaptiveAvgPool2d((1, 1)),\n                nn.Flatten(),\n                nn.Linear(200, 1),\n                Rearrange('b 1 -> (b 1)'),\n            )\n        elif param.classifier == 'all_patch_reps':\n            self.classifier = nn.Sequential(\n                Rearrange('b c s d -> b (c s d)'),\n                nn.Linear(32 * 4 * 200, 4 * 200),\n                nn.ELU(),\n                nn.Dropout(param.dropout),\n                nn.Linear(4 * 200, 200),\n                nn.ELU(),\n                nn.Dropout(param.dropout),\n                nn.Linear(200, 1),\n                Rearrange('b 1 -> (b 1)'),\n            )\n    def forward(self, x):\n        bz, ch_num, seq_len, patch_size = x.shape\n        feats = self.backbone(x)\n        out = self.classifier(feats)\n        return out\n\n\n"}
{"doc_id": "models/model_for_tuab.py", "text": "import torch\nimport torch.nn as nn\nfrom einops.layers.torch import Rearrange\n\nfrom .cbramod import CBraMod\n\n\nclass Model(nn.Module):\n    def __init__(self, param):\n        super(Model, self).__init__()\n        self.backbone = CBraMod(\n            in_dim=200, out_dim=200, d_model=200,\n            dim_feedforward=800, seq_len=30,\n            n_layer=12, nhead=8\n        )\n        if param.use_pretrained_weights:\n            map_location = torch.device(f'cuda:{param.cuda}')\n            self.backbone.load_state_dict(torch.load(param.foundation_dir, map_location=map_location))\n        self.backbone.proj_out = nn.Identity()\n        if param.classifier == 'avgpooling_patch_reps':\n            self.classifier = nn.Sequential(\n                Rearrange('b c s d -> b d c s'),\n                nn.AdaptiveAvgPool2d((1, 1)),\n                nn.Flatten(),\n                nn.Linear(200, 1),\n                Rearrange('b 1 -> (b 1)'),\n            )\n        elif param.classifier == 'all_patch_reps':\n            self.classifier = nn.Sequential(\n                Rearrange('b c s d -> b (c s d)'),\n                nn.Linear(16 * 10 * 200, 10 * 200),\n                nn.ELU(),\n                nn.Dropout(param.dropout),\n                nn.Linear(10 * 200, 200),\n                nn.ELU(),\n                nn.Dropout(param.dropout),\n                nn.Linear(200, 1),\n                Rearrange('b 1 -> (b 1)'),\n            )\n\n    def forward(self, x):\n        bz, ch_num, seq_len, patch_size = x.shape\n        feats = self.backbone(x)\n        out = self.classifier(feats)\n        return out\n"}
{"doc_id": "models/__init__.py", "text": ""}
{"doc_id": "datasets/seedvig_dataset.py", "text": "import torch\nfrom torch.utils.data import Dataset, DataLoader\nimport numpy as np\nfrom utils.util import to_tensor\nimport os\nimport random\nimport lmdb\nimport pickle\n\nclass CustomDataset(Dataset):\n    def __init__(\n            self,\n            data_dir,\n            mode='train',\n    ):\n        super(CustomDataset, self).__init__()\n        self.db = lmdb.open(data_dir, readonly=True, lock=False, readahead=True, meminit=False)\n        with self.db.begin(write=False) as txn:\n            self.keys = pickle.loads(txn.get('__keys__'.encode()))[mode]\n\n    def __len__(self):\n        return len((self.keys))\n\n    def __getitem__(self, idx):\n        key = self.keys[idx]\n        with self.db.begin(write=False) as txn:\n            pair = pickle.loads(txn.get(key.encode()))\n        data = pair['sample']\n        label = pair['label']\n        # print(key)\n        # print(data.shape)\n        return data/100, label\n\n    def collate(self, batch):\n        x_data = np.array([x[0] for x in batch])\n        y_label = np.array([x[1] for x in batch])\n        return to_tensor(x_data), to_tensor(y_label)\n\n\nclass LoadDataset(object):\n    def __init__(self, params):\n        self.params = params\n        self.datasets_dir = params.datasets_dir\n\n    def get_data_loader(self):\n        train_set = CustomDataset(self.datasets_dir, mode='train')\n        val_set = CustomDataset(self.datasets_dir, mode='val')\n        test_set = CustomDataset(self.datasets_dir, mode='test')\n        print(len(train_set), len(val_set), len(test_set))\n        data_loader = {\n            'train': DataLoader(\n                train_set,\n                batch_size=self.params.batch_size,\n                collate_fn=train_set.collate,\n                shuffle=True,\n            ),\n            'val': DataLoader(\n                val_set,\n                batch_size=self.params.batch_size,\n                collate_fn=val_set.collate,\n                shuffle=False,\n            ),\n            'test': DataLoader(\n                test_set,\n                batch_size=self.params.batch_size,\n                collate_fn=test_set.collate,\n                shuffle=False,\n            ),\n        }\n        return data_loader\n"}
{"doc_id": "datasets/seedv_dataset.py", "text": "import torch\nfrom torch.utils.data import Dataset, DataLoader\nimport numpy as np\nfrom utils.util import to_tensor\nimport os\nimport random\nimport lmdb\nimport pickle\n\n\nclass CustomDataset(Dataset):\n    def __init__(\n            self,\n            data_dir,\n            mode='train',\n    ):\n        super(CustomDataset, self).__init__()\n        self.db = lmdb.open(data_dir, readonly=True, lock=False, readahead=True, meminit=False)\n        with self.db.begin(write=False) as txn:\n            self.keys = pickle.loads(txn.get('__keys__'.encode()))[mode]\n\n    def __len__(self):\n        return len((self.keys))\n\n    def __getitem__(self, idx):\n        key = self.keys[idx]\n        with self.db.begin(write=False) as txn:\n            pair = pickle.loads(txn.get(key.encode()))\n        data = pair['sample']\n        label = pair['label']\n        # print(key)\n        # print(data)\n        # print(label)\n        return data / 100, label\n\n    def collate(self, batch):\n        x_data = np.array([x[0] for x in batch])\n        y_label = np.array([x[1] for x in batch])\n        return to_tensor(x_data), to_tensor(y_label).long()\n\n\nclass LoadDataset(object):\n    def __init__(self, params):\n        self.params = params\n        self.datasets_dir = params.datasets_dir\n\n    def get_data_loader(self):\n        train_set = CustomDataset(self.datasets_dir, mode='train')\n        val_set = CustomDataset(self.datasets_dir, mode='val')\n        test_set = CustomDataset(self.datasets_dir, mode='test')\n        print(len(train_set), len(val_set), len(test_set))\n        print(len(train_set) + len(val_set) + len(test_set))\n        data_loader = {\n            'train': DataLoader(\n                train_set,\n                batch_size=self.params.batch_size,\n                collate_fn=train_set.collate,\n                shuffle=True,\n            ),\n            'val': DataLoader(\n                val_set,\n                batch_size=self.params.batch_size,\n                collate_fn=val_set.collate,\n                shuffle=False,\n            ),\n            'test': DataLoader(\n                test_set,\n                batch_size=self.params.batch_size,\n                collate_fn=test_set.collate,\n                shuffle=False,\n            ),\n        }\n        return data_loader\n"}
{"doc_id": "datasets/tuev_dataset.py", "text": "import torch\nfrom torch.utils.data import Dataset, DataLoader\nimport numpy as np\nfrom utils.util import to_tensor\nimport os\nimport random\nimport lmdb\nimport pickle\nfrom scipy import signal\n\n\nclass CustomDataset(Dataset):\n    def __init__(\n            self,\n            data_dir,\n            files,\n    ):\n        super(CustomDataset, self).__init__()\n        self.data_dir = data_dir\n        self.files = files\n\n    def __len__(self):\n        return len((self.files))\n\n    def __getitem__(self, idx):\n        file = self.files[idx]\n        data_dict = pickle.load(open(os.path.join(self.data_dir, file), \"rb\"))\n        data = data_dict['signal']\n        label = int(data_dict['label'][0]-1)\n        # data = signal.resample(data, 1000, axis=-1)\n        data = data.reshape(16, 5, 200)\n        return data/100, label\n\n    def collate(self, batch):\n        x_data = np.array([x[0] for x in batch])\n        y_label = np.array([x[1] for x in batch])\n        return to_tensor(x_data), to_tensor(y_label).long()\n\n\nclass LoadDataset(object):\n    def __init__(self, params):\n        self.params = params\n        self.datasets_dir = params.datasets_dir\n\n    def get_data_loader(self):\n        train_files = os.listdir(os.path.join(self.datasets_dir, \"processed_train\"))\n        val_files = os.listdir(os.path.join(self.datasets_dir, \"processed_eval\"))\n        test_files = os.listdir(os.path.join(self.datasets_dir, \"processed_test\"))\n\n        train_set = CustomDataset(os.path.join(self.datasets_dir, \"processed_train\"), train_files)\n        val_set = CustomDataset(os.path.join(self.datasets_dir, \"processed_eval\"), val_files)\n        test_set = CustomDataset(os.path.join(self.datasets_dir, \"processed_test\"), test_files)\n\n        print(len(train_set), len(val_set), len(test_set))\n        print(len(train_set)+len(val_set)+len(test_set))\n\n        data_loader = {\n            'train': DataLoader(\n                train_set,\n                batch_size=self.params.batch_size,\n                collate_fn=train_set.collate,\n                shuffle=True,\n            ),\n            'val': DataLoader(\n                val_set,\n                batch_size=self.params.batch_size,\n                collate_fn=val_set.collate,\n                shuffle=False,\n            ),\n            'test': DataLoader(\n                test_set,\n                batch_size=self.params.batch_size,\n                collate_fn=test_set.collate,\n                shuffle=False,\n            ),\n        }\n        return data_loader\n"}
{"doc_id": "datasets/isruc_dataset.py", "text": "import torch\nfrom torch.utils.data import Dataset, DataLoader\nimport numpy as np\nfrom utils.util import to_tensor\nimport os\nimport random\n\n\n\nclass CustomDataset(Dataset):\n    def __init__(\n            self,\n            seqs_labels_path_pair\n    ):\n        super(CustomDataset, self).__init__()\n        self.seqs_labels_path_pair = seqs_labels_path_pair\n\n    def __len__(self):\n        return len((self.seqs_labels_path_pair))\n\n    def __getitem__(self, idx):\n        seq_path = self.seqs_labels_path_pair[idx][0]\n        label_path = self.seqs_labels_path_pair[idx][1]\n        # print(seq_path)\n        # print(label_path)\n        seq = np.load(seq_path)\n        label = np.load(label_path)\n        return seq, label\n\n    def collate(self, batch):\n        x_seq = np.array([x[0] for x in batch])\n        y_label = np.array([x[1] for x in batch])\n        return to_tensor(x_seq), to_tensor(y_label).long()\n\n\nclass LoadDataset(object):\n    def __init__(self, params):\n        self.params = params\n        self.seqs_dir = os.path.join(params.datasets_dir, 'seq')\n        self.labels_dir = os.path.join(params.datasets_dir, 'labels')\n        self.seqs_labels_path_pair = self.load_path()\n\n    def get_data_loader(self):\n        train_pairs, val_pairs, test_pairs = self.split_dataset(self.seqs_labels_path_pair)\n        train_set = CustomDataset(train_pairs)\n        val_set = CustomDataset(val_pairs)\n        test_set = CustomDataset(test_pairs)\n        print(len(train_set), len(val_set), len(test_set))\n        print(len(train_set) + len(val_set) + len(test_set))\n        data_loader = {\n            'train': DataLoader(\n                train_set,\n                batch_size=self.params.batch_size,\n                collate_fn=train_set.collate,\n                shuffle=True,\n            ),\n            'val': DataLoader(\n                val_set,\n                batch_size=1,\n                collate_fn=val_set.collate,\n                shuffle=False,\n            ),\n            'test': DataLoader(\n                test_set,\n                batch_size=1,\n                collate_fn=test_set.collate,\n                shuffle=False,\n            ),\n        }\n        return data_loader\n\n    def load_path(self):\n        seqs_labels_path_pair = []\n        # subject_nums = os.listdir(self.seqs_dir)\n        # print(subject_nums)\n        subject_dirs_seq = []\n        subject_dirs_labels = []\n        for subject_num in range(1, 101):\n            subject_dirs_seq.append(os.path.join(self.seqs_dir, f'ISRUC-group1-{subject_num}'))\n            subject_dirs_labels.append(os.path.join(self.labels_dir, f'ISRUC-group1-{subject_num}'))\n\n        for subject_seq, subject_label in zip(subject_dirs_seq, subject_dirs_labels):\n            # print(subject_seq, subject_label)\n            subject_pairs = []\n            seq_fnames = os.listdir(subject_seq)\n            label_fnames = os.listdir(subject_label)\n            # print(seq_fnames)\n            for seq_fname, label_fname in zip(seq_fnames, label_fnames):\n                subject_pairs.append((os.path.join(subject_seq, seq_fname), os.path.join(subject_label, label_fname)))\n            seqs_labels_path_pair.append(subject_pairs)\n        # print(seqs_labels_path_pair)\n        return seqs_labels_path_pair\n\n    def split_dataset(self, seqs_labels_path_pair):\n        train_pairs = []\n        val_pairs = []\n        test_pairs = []\n\n        for i in range(100):\n            if i < 80:\n                train_pairs.extend(seqs_labels_path_pair[i])\n            elif i < 90:\n                val_pairs.extend(seqs_labels_path_pair[i])\n            else:\n                test_pairs.extend(seqs_labels_path_pair[i])\n        # print(train_pairs, val_pairs, test_pairs)\n        return train_pairs, val_pairs, test_pairs\n"}
{"doc_id": "datasets/speech_dataset.py", "text": "import torch\nfrom torch.utils.data import Dataset, DataLoader\nimport numpy as np\nfrom utils.util import to_tensor\nimport os\nimport random\nimport lmdb\nimport pickle\n\nclass CustomDataset(Dataset):\n    def __init__(\n            self,\n            data_dir,\n            mode='train',\n    ):\n        super(CustomDataset, self).__init__()\n        self.db = lmdb.open(data_dir, readonly=True, lock=False, readahead=True, meminit=False)\n        with self.db.begin(write=False) as txn:\n            self.keys = pickle.loads(txn.get('__keys__'.encode()))[mode]\n\n    def __len__(self):\n        return len((self.keys))\n\n    def __getitem__(self, idx):\n        key = self.keys[idx]\n        with self.db.begin(write=False) as txn:\n            pair = pickle.loads(txn.get(key.encode()))\n        data = pair['sample']\n        label = pair['label']\n        # print(key)\n        # print(data.shape)\n        # print(label)\n        return data/100, label\n\n    def collate(self, batch):\n        x_data = np.array([x[0] for x in batch])\n        y_label = np.array([x[1] for x in batch])\n        return to_tensor(x_data), to_tensor(y_label).long()\n\n\nclass LoadDataset(object):\n    def __init__(self, params):\n        self.params = params\n        self.datasets_dir = params.datasets_dir\n\n    def get_data_loader(self):\n        train_set = CustomDataset(self.datasets_dir, mode='train')\n        val_set = CustomDataset(self.datasets_dir, mode='val')\n        test_set = CustomDataset(self.datasets_dir, mode='test')\n        print(len(train_set), len(val_set), len(test_set))\n        data_loader = {\n            'train': DataLoader(\n                train_set,\n                batch_size=self.params.batch_size,\n                collate_fn=train_set.collate,\n                shuffle=True,\n            ),\n            'val': DataLoader(\n                val_set,\n                batch_size=self.params.batch_size,\n                collate_fn=val_set.collate,\n                shuffle=False,\n            ),\n            'test': DataLoader(\n                test_set,\n                batch_size=self.params.batch_size,\n                collate_fn=test_set.collate,\n                shuffle=False,\n            ),\n        }\n        return data_loader\n"}
{"doc_id": "datasets/chb_dataset.py", "text": "import torch\nfrom torch.utils.data import Dataset, DataLoader\nimport numpy as np\nfrom utils.util import to_tensor\nimport os\nimport random\nimport lmdb\nimport pickle\nfrom scipy import signal\n\nclass CustomDataset(Dataset):\n    def __init__(\n            self,\n            data_dir,\n            mode='train',\n    ):\n        super(CustomDataset, self).__init__()\n        self.files = [os.path.join(data_dir, mode, file) for file in os.listdir(os.path.join(data_dir, mode))]\n\n\n    def __len__(self):\n        return len((self.files))\n\n    def __getitem__(self, idx):\n        file = self.files[idx]\n        data_dict = pickle.load(open(file, 'rb'))\n        data = data_dict['X']\n        label = data_dict['y']\n        data = signal.resample(data, 2000, axis=1)\n        data = data.reshape(16, 10, 200)\n        return data/100, label\n\n    def collate(self, batch):\n        x_data = np.array([x[0] for x in batch])\n        y_label = np.array([x[1] for x in batch])\n        return to_tensor(x_data), to_tensor(y_label)\n\n\nclass LoadDataset(object):\n    def __init__(self, params):\n        self.params = params\n        self.datasets_dir = params.datasets_dir\n\n    def get_data_loader(self):\n        train_set = CustomDataset(self.datasets_dir, mode='train')\n        val_set = CustomDataset(self.datasets_dir, mode='val')\n        test_set = CustomDataset(self.datasets_dir, mode='test')\n        print(len(train_set), len(val_set), len(test_set))\n        print(len(train_set) + len(val_set) + len(test_set))\n        data_loader = {\n            'train': DataLoader(\n                train_set,\n                batch_size=self.params.batch_size,\n                collate_fn=train_set.collate,\n                shuffle=True,\n            ),\n            'val': DataLoader(\n                val_set,\n                batch_size=self.params.batch_size,\n                collate_fn=val_set.collate,\n                shuffle=False,\n            ),\n            'test': DataLoader(\n                test_set,\n                batch_size=self.params.batch_size,\n                collate_fn=test_set.collate,\n                shuffle=False,\n            ),\n        }\n        return data_loader\n"}
{"doc_id": "datasets/shu_dataset.py", "text": "import torch\nfrom torch.utils.data import Dataset, DataLoader\nimport numpy as np\nfrom utils.util import to_tensor\nimport os\nimport random\nimport lmdb\nimport pickle\n\nclass CustomDataset(Dataset):\n    def __init__(\n            self,\n            data_dir,\n            mode='train',\n    ):\n        super(CustomDataset, self).__init__()\n        self.db = lmdb.open(data_dir, readonly=True, lock=False, readahead=True, meminit=False)\n        with self.db.begin(write=False) as txn:\n            self.keys = pickle.loads(txn.get('__keys__'.encode()))[mode]\n        if mode == 'train':\n            random.shuffle(self.keys)\n            length = len(self.keys)\n            self.keys = self.keys[:int(length * 0.3)]\n\n    def __len__(self):\n        return len((self.keys))\n\n    def __getitem__(self, idx):\n        key = self.keys[idx]\n        with self.db.begin(write=False) as txn:\n            pair = pickle.loads(txn.get(key.encode()))\n        data = pair['sample']\n        label = pair['label']\n        # print(label)\n        return data/100, label\n\n    def collate(self, batch):\n        x_data = np.array([x[0] for x in batch])\n        y_label = np.array([x[1] for x in batch])\n        return to_tensor(x_data), to_tensor(y_label)\n\n\nclass LoadDataset(object):\n    def __init__(self, params):\n        self.params = params\n        self.datasets_dir = params.datasets_dir\n\n    def get_data_loader(self):\n        train_set = CustomDataset(self.datasets_dir, mode='train')\n        val_set = CustomDataset(self.datasets_dir, mode='val')\n        test_set = CustomDataset(self.datasets_dir, mode='test')\n        print(len(train_set), len(val_set), len(test_set))\n        print(len(train_set)+len(val_set)+len(test_set))\n        data_loader = {\n            'train': DataLoader(\n                train_set,\n                batch_size=self.params.batch_size,\n                collate_fn=train_set.collate,\n                shuffle=True,\n            ),\n            'val': DataLoader(\n                val_set,\n                batch_size=self.params.batch_size,\n                collate_fn=val_set.collate,\n                shuffle=True,\n            ),\n            'test': DataLoader(\n                test_set,\n                batch_size=self.params.batch_size,\n                collate_fn=test_set.collate,\n                shuffle=True,\n            ),\n        }\n        return data_loader\n"}
{"doc_id": "datasets/tuab_dataset.py", "text": "import torch\nfrom torch.utils.data import Dataset, DataLoader\nimport numpy as np\nfrom utils.util import to_tensor\nimport os\nimport random\nimport lmdb\nimport pickle\nfrom scipy import signal\n\nclass CustomDataset(Dataset):\n    def __init__(\n            self,\n            data_dir,\n            mode='train',\n    ):\n        super(CustomDataset, self).__init__()\n        self.files = [os.path.join(data_dir, mode, file) for file in os.listdir(os.path.join(data_dir, mode))]\n\n\n    def __len__(self):\n        return len((self.files))\n\n    def __getitem__(self, idx):\n        file = self.files[idx]\n        data_dict = pickle.load(open(file, 'rb'))\n        data = data_dict['X']\n        label = data_dict['y']\n        # data = signal.resample(data, 2000, axis=-1)\n        data = data.reshape(16, 10, 200)\n        return data/100, label\n\n    def collate(self, batch):\n        x_data = np.array([x[0] for x in batch])\n        y_label = np.array([x[1] for x in batch])\n        return to_tensor(x_data), to_tensor(y_label)\n\n\nclass LoadDataset(object):\n    def __init__(self, params):\n        self.params = params\n        self.datasets_dir = params.datasets_dir\n\n    def get_data_loader(self):\n        train_set = CustomDataset(self.datasets_dir, mode='train')\n        val_set = CustomDataset(self.datasets_dir, mode='val')\n        test_set = CustomDataset(self.datasets_dir, mode='test')\n        print(len(train_set), len(val_set), len(test_set))\n        print(len(train_set) + len(val_set) + len(test_set))\n        data_loader = {\n            'train': DataLoader(\n                train_set,\n                batch_size=self.params.batch_size,\n                collate_fn=train_set.collate,\n                shuffle=True,\n            ),\n            'val': DataLoader(\n                val_set,\n                batch_size=self.params.batch_size,\n                collate_fn=val_set.collate,\n                shuffle=False,\n            ),\n            'test': DataLoader(\n                test_set,\n                batch_size=self.params.batch_size,\n                collate_fn=test_set.collate,\n                shuffle=False,\n            ),\n        }\n        return data_loader\n"}
{"doc_id": "datasets/physio_dataset.py", "text": "import torch\nfrom torch.utils.data import Dataset, DataLoader\nimport numpy as np\nfrom utils.util import to_tensor\nimport os\nimport random\nimport lmdb\nimport pickle\n\nclass CustomDataset(Dataset):\n    def __init__(\n            self,\n            data_dir,\n            mode='train',\n    ):\n        super(CustomDataset, self).__init__()\n        self.db = lmdb.open(data_dir, readonly=True, lock=False, readahead=True, meminit=False)\n        with self.db.begin(write=False) as txn:\n            self.keys = pickle.loads(txn.get('__keys__'.encode()))[mode]\n\n    def __len__(self):\n        return len((self.keys))\n\n    def __getitem__(self, idx):\n        key = self.keys[idx]\n        with self.db.begin(write=False) as txn:\n            pair = pickle.loads(txn.get(key.encode()))\n        data = pair['sample']\n        label = pair['label']\n        # print(key)\n        # print(data)\n        # print(label)\n        return data/100, label\n\n    def collate(self, batch):\n        x_data = np.array([x[0] for x in batch])\n        y_label = np.array([x[1] for x in batch])\n        return to_tensor(x_data), to_tensor(y_label).long()\n\n\nclass LoadDataset(object):\n    def __init__(self, params):\n        self.params = params\n        self.datasets_dir = params.datasets_dir\n\n    def get_data_loader(self):\n        train_set = CustomDataset(self.datasets_dir, mode='train')\n        val_set = CustomDataset(self.datasets_dir, mode='val')\n        test_set = CustomDataset(self.datasets_dir, mode='test')\n        print(len(train_set), len(val_set), len(test_set))\n        print(len(train_set)+len(val_set)+len(test_set))\n        data_loader = {\n            'train': DataLoader(\n                train_set,\n                batch_size=self.params.batch_size,\n                collate_fn=train_set.collate,\n                shuffle=True,\n            ),\n            'val': DataLoader(\n                val_set,\n                batch_size=self.params.batch_size,\n                collate_fn=val_set.collate,\n                shuffle=False,\n            ),\n            'test': DataLoader(\n                test_set,\n                batch_size=self.params.batch_size,\n                collate_fn=test_set.collate,\n                shuffle=False,\n            ),\n        }\n        return data_loader\n"}
{"doc_id": "datasets/mumtaz_dataset.py", "text": "import torch\nfrom torch.utils.data import Dataset, DataLoader\nimport numpy as np\nfrom utils.util import to_tensor\nimport os\nimport random\nimport lmdb\nimport pickle\n\nclass CustomDataset(Dataset):\n    def __init__(\n            self,\n            data_dir,\n            mode='train',\n    ):\n        super(CustomDataset, self).__init__()\n        self.db = lmdb.open(data_dir, readonly=True, lock=False, readahead=True, meminit=False)\n        with self.db.begin(write=False) as txn:\n            self.keys = pickle.loads(txn.get('__keys__'.encode()))[mode]\n\n    def __len__(self):\n        return len((self.keys))\n\n    def __getitem__(self, idx):\n        key = self.keys[idx]\n        with self.db.begin(write=False) as txn:\n            pair = pickle.loads(txn.get(key.encode()))\n        data = pair['sample']\n        label = pair['label']\n        # print(label)\n        return data/100, label\n\n    def collate(self, batch):\n        x_data = np.array([x[0] for x in batch])\n        y_label = np.array([x[1] for x in batch])\n        return to_tensor(x_data), to_tensor(y_label)\n\n\nclass LoadDataset(object):\n    def __init__(self, params):\n        self.params = params\n        self.datasets_dir = params.datasets_dir\n\n    def get_data_loader(self):\n        train_set = CustomDataset(self.datasets_dir, mode='train')\n        val_set = CustomDataset(self.datasets_dir, mode='val')\n        test_set = CustomDataset(self.datasets_dir, mode='test')\n        print(len(train_set), len(val_set), len(test_set))\n        print(len(train_set) + len(val_set) + len(test_set))\n        data_loader = {\n            'train': DataLoader(\n                train_set,\n                batch_size=self.params.batch_size,\n                collate_fn=train_set.collate,\n                shuffle=True,\n            ),\n            'val': DataLoader(\n                val_set,\n                batch_size=self.params.batch_size,\n                collate_fn=val_set.collate,\n                shuffle=True,\n            ),\n            'test': DataLoader(\n                test_set,\n                batch_size=self.params.batch_size,\n                collate_fn=test_set.collate,\n                shuffle=True,\n            ),\n        }\n        return data_loader\n"}
{"doc_id": "datasets/faced_dataset.py", "text": "import torch\nfrom torch.utils.data import Dataset, DataLoader\nimport numpy as np\nfrom utils.util import to_tensor\nimport os\nimport random\nimport lmdb\nimport pickle\n\nclass CustomDataset(Dataset):\n    def __init__(\n            self,\n            data_dir,\n            mode='train',\n    ):\n        super(CustomDataset, self).__init__()\n        self.db = lmdb.open(data_dir, readonly=True, lock=False, readahead=True, meminit=False)\n        with self.db.begin(write=False) as txn:\n            self.keys = pickle.loads(txn.get('__keys__'.encode()))[mode]\n\n    def __len__(self):\n        return len((self.keys))\n\n    def __getitem__(self, idx):\n        key = self.keys[idx]\n        with self.db.begin(write=False) as txn:\n            pair = pickle.loads(txn.get(key.encode()))\n        data = pair['sample']\n        label = pair['label']\n        return data/100, label\n\n    def collate(self, batch):\n        x_data = np.array([x[0] for x in batch])\n        y_label = np.array([x[1] for x in batch])\n        return to_tensor(x_data), to_tensor(y_label).long()\n\n\nclass LoadDataset(object):\n    def __init__(self, params):\n        self.params = params\n        self.datasets_dir = params.datasets_dir\n\n    def get_data_loader(self):\n        train_set = CustomDataset(self.datasets_dir, mode='train')\n        val_set = CustomDataset(self.datasets_dir, mode='val')\n        test_set = CustomDataset(self.datasets_dir, mode='test')\n        print(len(train_set), len(val_set), len(test_set))\n        print(len(train_set)+len(val_set)+len(test_set))\n        data_loader = {\n            'train': DataLoader(\n                train_set,\n                batch_size=self.params.batch_size,\n                collate_fn=train_set.collate,\n                shuffle=True,\n            ),\n            'val': DataLoader(\n                val_set,\n                batch_size=self.params.batch_size,\n                collate_fn=val_set.collate,\n                shuffle=False,\n            ),\n            'test': DataLoader(\n                test_set,\n                batch_size=self.params.batch_size,\n                collate_fn=test_set.collate,\n                shuffle=False,\n            ),\n        }\n        return data_loader\n"}
{"doc_id": "datasets/pretraining_dataset.py", "text": "import pickle\n\nimport lmdb\nfrom torch.utils.data import Dataset\n\nfrom utils.util import to_tensor\n\n\nclass PretrainingDataset(Dataset):\n    def __init__(\n            self,\n            dataset_dir\n    ):\n        super(PretrainingDataset, self).__init__()\n        self.db = lmdb.open(dataset_dir, readonly=True, lock=False, readahead=True, meminit=False)\n        with self.db.begin(write=False) as txn:\n            self.keys = pickle.loads(txn.get('__keys__'.encode()))\n        # self.keys = self.keys[:100000]\n\n    def __len__(self):\n        return len(self.keys)\n\n    def __getitem__(self, idx):\n        key = self.keys[idx]\n\n        with self.db.begin(write=False) as txn:\n            patch = pickle.loads(txn.get(key.encode()))\n\n        patch = to_tensor(patch)\n        # print(patch.shape)\n        return patch\n\n\n\n"}
{"doc_id": "datasets/bciciv2a_dataset.py", "text": "import torch\nfrom torch.utils.data import Dataset, DataLoader\nimport numpy as np\nfrom utils.util import to_tensor\nimport os\nimport random\nimport lmdb\nimport pickle\n\nclass CustomDataset(Dataset):\n    def __init__(\n            self,\n            data_dir,\n            mode='train',\n    ):\n        super(CustomDataset, self).__init__()\n        self.db = lmdb.open(data_dir, readonly=True, lock=False, readahead=True, meminit=False)\n        with self.db.begin(write=False) as txn:\n            self.keys = pickle.loads(txn.get('__keys__'.encode()))[mode]\n\n    def __len__(self):\n        return len((self.keys))\n\n    def __getitem__(self, idx):\n        key = self.keys[idx]\n        with self.db.begin(write=False) as txn:\n            pair = pickle.loads(txn.get(key.encode()))\n        data = pair['sample']\n        label = pair['label']\n        return data/100, label\n\n    def collate(self, batch):\n        x_data = np.array([x[0] for x in batch])\n        y_label = np.array([x[1] for x in batch])\n        return to_tensor(x_data), to_tensor(y_label).long()\n\nclass LoadDataset(object):\n    def __init__(self, params):\n        self.params = params\n        self.datasets_dir = params.datasets_dir\n\n    def get_data_loader(self):\n        train_set = CustomDataset(self.datasets_dir, mode='train')\n        val_set = CustomDataset(self.datasets_dir, mode='val')\n        test_set = CustomDataset(self.datasets_dir, mode='test')\n        print(len(train_set), len(val_set), len(test_set))\n        print(len(train_set)+len(val_set)+len(test_set))\n        data_loader = {\n            'train': DataLoader(\n                train_set,\n                batch_size=self.params.batch_size,\n                collate_fn=train_set.collate,\n                shuffle=True,\n            ),\n            'val': DataLoader(\n                test_set,\n                batch_size=self.params.batch_size,\n                collate_fn=test_set.collate,\n                shuffle=False,\n            ),\n            'test': DataLoader(\n                test_set,\n                batch_size=self.params.batch_size,\n                collate_fn=test_set.collate,\n                shuffle=False,\n            ),\n        }\n        return data_loader\n"}
{"doc_id": "datasets/__init__.py", "text": ""}
{"doc_id": "datasets/stress_dataset.py", "text": "import torch\nfrom torch.utils.data import Dataset, DataLoader\nimport numpy as np\nfrom utils.util import to_tensor\nimport os\nimport random\nimport lmdb\nimport pickle\n\nclass CustomDataset(Dataset):\n    def __init__(\n            self,\n            data_dir,\n            mode='train',\n    ):\n        super(CustomDataset, self).__init__()\n        self.db = lmdb.open(data_dir, readonly=True, lock=False, readahead=True, meminit=False)\n        with self.db.begin(write=False) as txn:\n            self.keys = pickle.loads(txn.get('__keys__'.encode()))[mode]\n\n    def __len__(self):\n        return len((self.keys))\n\n    def __getitem__(self, idx):\n        key = self.keys[idx]\n        with self.db.begin(write=False) as txn:\n            pair = pickle.loads(txn.get(key.encode()))\n        data = pair['sample']\n        label = pair['label']\n        # print(label)\n        return data/100, label\n\n    def collate(self, batch):\n        x_data = np.array([x[0] for x in batch])\n        y_label = np.array([x[1] for x in batch])\n        return to_tensor(x_data), to_tensor(y_label)\n\n\nclass LoadDataset(object):\n    def __init__(self, params):\n        self.params = params\n        self.datasets_dir = params.datasets_dir\n\n    def get_data_loader(self):\n        train_set = CustomDataset(self.datasets_dir, mode='train')\n        val_set = CustomDataset(self.datasets_dir, mode='val')\n        test_set = CustomDataset(self.datasets_dir, mode='test')\n        print(len(train_set), len(val_set), len(test_set))\n        print(len(train_set)+len(val_set)+len(test_set))\n        data_loader = {\n            'train': DataLoader(\n                train_set,\n                batch_size=self.params.batch_size,\n                collate_fn=train_set.collate,\n                shuffle=True,\n            ),\n            'val': DataLoader(\n                val_set,\n                batch_size=self.params.batch_size,\n                collate_fn=val_set.collate,\n                shuffle=True,\n            ),\n            'test': DataLoader(\n                test_set,\n                batch_size=self.params.batch_size,\n                collate_fn=test_set.collate,\n                shuffle=True,\n            ),\n        }\n        return data_loader\n"}
{"doc_id": "preprocessing/preprocessing_speech.py", "text": "import h5py\nimport scipy\nfrom scipy import signal\nimport os\nimport lmdb\nimport pickle\nimport numpy as np\nimport pandas as pd\n\n\ntrain_dir = '/data/datasets/BigDownstream/Imagined speech/mat/Training set'\nval_dir = '/data/datasets/BigDownstream/Imagined speech/mat/Validation set'\ntest_dir = '/data/datasets/BigDownstream/Imagined speech/mat/Test set'\n\n\n\nfiles_dict = {\n    'train':sorted([file for file in os.listdir(train_dir)]),\n    'val':sorted([file for file in os.listdir(val_dir)]),\n    'test':sorted([file for file in os.listdir(test_dir)]),\n}\n\nprint(files_dict)\n\ndataset = {\n    'train': list(),\n    'val': list(),\n    'test': list(),\n}\n\ndb = lmdb.open('/data/datasets/BigDownstream/Imagined speech/processed', map_size=3000000000)\n\nfor file in files_dict['train']:\n    data = scipy.io.loadmat(os.path.join(train_dir, file))\n    print(data['epo_train'][0][0][0])\n    eeg = data['epo_train'][0][0][4].transpose(2, 1, 0)\n    labels = data['epo_train'][0][0][5].transpose(1, 0)\n    eeg = eeg[:, :, -768:]\n    labels = np.argmax(labels, axis=1)\n    eeg = signal.resample(eeg, 600, axis=2).reshape(300, 64, 3, 200)\n    print(eeg.shape, labels.shape)\n    for i, (sample, label) in enumerate(zip(eeg, labels)):\n        sample_key = f'train-{file[:-4]}-{i}'\n        data_dict = {\n            'sample': sample, 'label': label,\n        }\n        txn = db.begin(write=True)\n        txn.put(key=sample_key.encode(), value=pickle.dumps(data_dict))\n        txn.commit()\n        print(sample_key)\n        dataset['train'].append(sample_key)\n\n\nfor file in files_dict['val']:\n    data = scipy.io.loadmat(os.path.join(val_dir, file))\n    eeg = data['epo_validation'][0][0][4].transpose(2, 1, 0)\n    labels = data['epo_validation'][0][0][5].transpose(1, 0)\n    eeg = eeg[:, :, -768:]\n    labels = np.argmax(labels, axis=1)\n    eeg = signal.resample(eeg, 600, axis=2).reshape(50, 64, 3, 200)\n    print(eeg.shape, labels.shape)\n    for i, (sample, label) in enumerate(zip(eeg, labels)):\n        sample_key = f'val-{file[:-4]}-{i}'\n        data_dict = {\n            'sample': sample, 'label': label,\n        }\n        txn = db.begin(write=True)\n        txn.put(key=sample_key.encode(), value=pickle.dumps(data_dict))\n        txn.commit()\n        print(sample_key)\n        dataset['val'].append(sample_key)\n\n\ndf = pd.read_excel(\"/data/datasets/BigDownstream/Imagined speech/mat/Track3_Answer Sheet_Test.xlsx\")\ndf_=df.head(53)\nall_labels=df_.values\nprint(all_labels.shape)\nall_labels = all_labels[2:, 1:][:, 1:30:2].transpose(1, 0)\nprint(all_labels.shape)\nprint(all_labels)\n\nfor j, file in enumerate(files_dict['test']):\n    data = h5py.File(os.path.join(test_dir, file))\n    eeg = data['epo_test']['x'][:]\n    labels = all_labels[j]\n    eeg = eeg[:, :, -768:]\n    eeg = signal.resample(eeg, 600, axis=2).reshape(50, 64, 3, 200)\n    print(eeg.shape, labels.shape)\n    for i, (sample, label) in enumerate(zip(eeg, labels)):\n        sample_key = f'test-{file[:-4]}-{i}'\n        data_dict = {\n            'sample': sample, 'label': label-1,\n        }\n        txn = db.begin(write=True)\n        txn.put(key=sample_key.encode(), value=pickle.dumps(data_dict))\n        txn.commit()\n        print(sample_key)\n        dataset['test'].append(sample_key)\n\n\ntxn = db.begin(write=True)\ntxn.put(key='__keys__'.encode(), value=pickle.dumps(dataset))\ntxn.commit()\ndb.close()"}
{"doc_id": "preprocessing/preprocessing_bciciv2a.py", "text": "import numpy as np\nimport scipy\nfrom scipy import signal\nimport os\nimport lmdb\nimport pickle\nfrom scipy.signal import butter, lfilter, resample, filtfilt\n\ndef butter_bandpass(low_cut, high_cut, fs, order=5):\n    nyq = 0.5 * fs\n    low = low_cut / nyq\n    high = high_cut / nyq\n    b, a = butter(order, [low, high], btype='band')\n    return b, a\n\nroot_dir = '/data/datasets/BCICIV2a/data_mat'\nfiles = [file for file in os.listdir(root_dir)]\nfiles = sorted(files)\n\n# files.remove('A04E.mat')\n# files.remove('A04T.mat')\n# files.remove('A06E.mat')\n# files.remove('A06T.mat')\nprint(files)\n\nfiles_dict = {\n    'train': ['A01E.mat', 'A01T.mat', 'A02E.mat', 'A02T.mat', 'A03E.mat', 'A03T.mat',\n              'A04E.mat', 'A04T.mat',\n              'A05E.mat', 'A05T.mat'],\n    'val': [\n        'A06E.mat', 'A06T.mat',\n        'A07E.mat', 'A07T.mat'\n    ],\n    'test': ['A08E.mat', 'A08T.mat', 'A09E.mat', 'A09T.mat'],\n}\n\n\n\ndataset = {\n    'train': list(),\n    'val': list(),\n    'test': list(),\n}\n\n# for file in files:\n#     if 'E' in file:\n#         files_dict['train'].append(file)\n#     else:\n#         files_dict['test'].append(file)\n#\n# print(files_dict)\n\n\ndb = lmdb.open('/data/datasets/BCICIV2a/processed_inde_avg_03_50', map_size=1610612736)\nfor files_key in files_dict.keys():\n    for file in files_dict[files_key]:\n        print(file)\n        data = scipy.io.loadmat(os.path.join(root_dir, file))\n        num = len(data['data'][0])\n        # print(num)\n        # print(data['data'][0, 8][0, 0][0].shape)\n        # print(data['data'][0, 8][0, 0][1].shape)\n        # print(data['data'][0, 8][0, 0][2].shape)\n        for j in range(3, num):\n            raw_data = data['data'][0, j][0, 0][0][:, :22]\n            events = data['data'][0, j][0, 0][1][:, 0]\n            labels = data['data'][0, j][0, 0][2][:, 0]\n            length = raw_data.shape[0]\n            events = events.tolist()\n            events.append(length)\n            # print(events)\n            annos = []\n            for i in range(len(events) - 1):\n                annos.append((events[i], events[i + 1]))\n            for i, (anno, label) in enumerate(zip(annos, labels)):\n                sample = raw_data[anno[0]:anno[1]].transpose(1, 0)\n                sample  = sample - np.mean(sample, axis=0, keepdims=True)\n                # print(samples.shape)\n                b, a = butter_bandpass(0.3, 50, 250)\n                sample = lfilter(b, a, sample, -1)\n                # print(sample.shape)\n                sample = sample[:, 2 * 250:6 * 250]\n                sample = resample(sample, 800, axis=-1)\n                # print(sample.shape)\n                # print(i, sample.shape, label)\n                sample = sample.reshape(22, 4, 200)\n                sample_key = f'{file[:-4]}-{j}-{i}'\n                print(sample_key, label-1)\n                data_dict = {\n                    'sample': sample, 'label': label - 1\n                }\n                # print(label-1)\n                txn = db.begin(write=True)\n                txn.put(key=sample_key.encode(), value=pickle.dumps(data_dict))\n                txn.commit()\n                dataset[files_key].append(sample_key)\n\n\ntxn = db.begin(write=True)\ntxn.put(key='__keys__'.encode(), value=pickle.dumps(dataset))\ntxn.commit()\ndb.close()\n"}
{"doc_id": "preprocessing/preprocessing_tuev.py", "text": "import mne\nimport numpy as np\nimport os\nimport pickle\nfrom tqdm import tqdm\n\n\"\"\"\nhttps://github.com/Abhishaike/EEG_Event_Classification\n\"\"\"\n\n\ndef BuildEvents(signals, times, EventData):\n    [numEvents, z] = EventData.shape  # numEvents is equal to # of rows of the .rec file\n    fs = 200.0\n    [numChan, numPoints] = signals.shape\n    # for i in range(numChan):  # standardize each channel\n    #     if np.std(signals[i, :]) > 0:\n    #         signals[i, :] = (signals[i, :] - np.mean(signals[i, :])) / np.std(signals[i, :])\n    features = np.zeros([numEvents, numChan, int(fs) * 5])\n    offending_channel = np.zeros([numEvents, 1])  # channel that had the detected thing\n    labels = np.zeros([numEvents, 1])\n    offset = signals.shape[1]\n    signals = np.concatenate([signals, signals, signals], axis=1)\n    for i in range(numEvents):  # for each event\n        chan = int(EventData[i, 0])  # chan is channel\n        start = np.where((times) >= EventData[i, 1])[0][0]\n        end = np.where((times) >= EventData[i, 2])[0][0]\n        # print (offset + start - 2 * int(fs), offset + end + 2 * int(fs), signals.shape)\n        features[i, :] = signals[\n            :, offset + start - 2 * int(fs) : offset + end + 2 * int(fs)\n        ]\n        offending_channel[i, :] = int(chan)\n        labels[i, :] = int(EventData[i, 3])\n    return [features, offending_channel, labels]\n\n\ndef convert_signals(signals, Rawdata):\n    signal_names = {\n        k: v\n        for (k, v) in zip(\n            Rawdata.info[\"ch_names\"], list(range(len(Rawdata.info[\"ch_names\"])))\n        )\n    }\n    new_signals = np.vstack(\n        (\n            signals[signal_names[\"EEG FP1-REF\"]]\n            - signals[signal_names[\"EEG F7-REF\"]],  # 0\n            (\n                signals[signal_names[\"EEG F7-REF\"]]\n                - signals[signal_names[\"EEG T3-REF\"]]\n            ),  # 1\n            (\n                signals[signal_names[\"EEG T3-REF\"]]\n                - signals[signal_names[\"EEG T5-REF\"]]\n            ),  # 2\n            (\n                signals[signal_names[\"EEG T5-REF\"]]\n                - signals[signal_names[\"EEG O1-REF\"]]\n            ),  # 3\n            (\n                signals[signal_names[\"EEG FP2-REF\"]]\n                - signals[signal_names[\"EEG F8-REF\"]]\n            ),  # 4\n            (\n                signals[signal_names[\"EEG F8-REF\"]]\n                - signals[signal_names[\"EEG T4-REF\"]]\n            ),  # 5\n            (\n                signals[signal_names[\"EEG T4-REF\"]]\n                - signals[signal_names[\"EEG T6-REF\"]]\n            ),  # 6\n            (\n                signals[signal_names[\"EEG T6-REF\"]]\n                - signals[signal_names[\"EEG O2-REF\"]]\n            ),  # 7\n            (\n                signals[signal_names[\"EEG FP1-REF\"]]\n                - signals[signal_names[\"EEG F3-REF\"]]\n            ),  # 14\n            (\n                signals[signal_names[\"EEG F3-REF\"]]\n                - signals[signal_names[\"EEG C3-REF\"]]\n            ),  # 15\n            (\n                signals[signal_names[\"EEG C3-REF\"]]\n                - signals[signal_names[\"EEG P3-REF\"]]\n            ),  # 16\n            (\n                signals[signal_names[\"EEG P3-REF\"]]\n                - signals[signal_names[\"EEG O1-REF\"]]\n            ),  # 17\n            (\n                signals[signal_names[\"EEG FP2-REF\"]]\n                - signals[signal_names[\"EEG F4-REF\"]]\n            ),  # 18\n            (\n                signals[signal_names[\"EEG F4-REF\"]]\n                - signals[signal_names[\"EEG C4-REF\"]]\n            ),  # 19\n            (\n                signals[signal_names[\"EEG C4-REF\"]]\n                - signals[signal_names[\"EEG P4-REF\"]]\n            ),  # 20\n            (signals[signal_names[\"EEG P4-REF\"]] - signals[signal_names[\"EEG O2-REF\"]]),\n        )\n    )  # 21\n    return new_signals\n\n\ndef readEDF(fileName):\n    Rawdata = mne.io.read_raw_edf(fileName, preload=True)\n    Rawdata.resample(200)\n    Rawdata.filter(l_freq=0.3, h_freq=75)\n    Rawdata.notch_filter((60))\n\n    _, times = Rawdata[:]\n    signals = Rawdata.get_data(units='uV')\n    RecFile = fileName[0:-3] + \"rec\"\n    eventData = np.genfromtxt(RecFile, delimiter=\",\")\n    Rawdata.close()\n    return [signals, times, eventData, Rawdata]\n\n\ndef load_up_objects(BaseDir, Features, OffendingChannels, Labels, OutDir):\n    for dirName, subdirList, fileList in tqdm(os.walk(BaseDir)):\n        print(\"Found directory: %s\" % dirName)\n        for fname in fileList:\n            if fname[-4:] == \".edf\":\n                print(\"\\t%s\" % fname)\n                try:\n                    [signals, times, event, Rawdata] = readEDF(\n                        dirName + \"/\" + fname\n                    )  # event is the .rec file in the form of an array\n                    signals = convert_signals(signals, Rawdata)\n                except (ValueError, KeyError):\n                    print(\"something funky happened in \" + dirName + \"/\" + fname)\n                    continue\n                signals, offending_channels, labels = BuildEvents(signals, times, event)\n\n                for idx, (signal, offending_channel, label) in enumerate(\n                    zip(signals, offending_channels, labels)\n                ):\n                    sample = {\n                        \"signal\": signal,\n                        \"offending_channel\": offending_channel,\n                        \"label\": label,\n                    }\n                    save_pickle(\n                        sample,\n                        os.path.join(\n                            OutDir, fname.split(\".\")[0] + \"-\" + str(idx) + \".pkl\"\n                        ),\n                    )\n\n    return Features, Labels, OffendingChannels\n\n\ndef save_pickle(object, filename):\n    with open(filename, \"wb\") as f:\n        pickle.dump(object, f)\n\n\n\"\"\"\nTUEV dataset is downloaded from https://isip.piconepress.com/projects/tuh_eeg/html/downloads.shtml\n\"\"\"\n\nroot = \"/data/zcb/data/TUEV/edf\"\ntarget = \"/data/datasets/BigDownstream/TUEV_refine\"\n\ntrain_out_dir = os.path.join(target, \"processed_train\")\neval_out_dir = os.path.join(target, \"processed_eval\")\n\nif not os.path.exists(train_out_dir):\n    os.makedirs(train_out_dir)\nif not os.path.exists(eval_out_dir):\n    os.makedirs(eval_out_dir)\n\nBaseDirTrain = os.path.join(root, \"train\")\nfs = 200\nTrainFeatures = np.empty(\n    (0, 16, fs)\n)  # 0 for lack of intialization, 22 for channels, fs for num of points\nTrainLabels = np.empty([0, 1])\nTrainOffendingChannel = np.empty([0, 1])\nload_up_objects(\n    BaseDirTrain, TrainFeatures, TrainLabels, TrainOffendingChannel, train_out_dir\n)\n\nBaseDirEval = os.path.join(root, \"eval\")\nfs = 200\nEvalFeatures = np.empty(\n    (0, 16, fs)\n)  # 0 for lack of intialization, 22 for channels, fs for num of points\nEvalLabels = np.empty([0, 1])\nEvalOffendingChannel = np.empty([0, 1])\nload_up_objects(\n    BaseDirEval, EvalFeatures, EvalLabels, EvalOffendingChannel, eval_out_dir\n)\n\n\n#transfer to train, eval, and test\nroot = \"/data/datasets/BigDownstream/TUEV_refine\"\n# seed = 4523\n# np.random.seed(seed)\n\ntrain_files = os.listdir(os.path.join(root, \"processed_train\"))\ntrain_val_sub = list(set([f.split(\"_\")[0] for f in train_files]))\nprint(\"train val sub:\", train_val_sub)\ntest_files = os.listdir(os.path.join(root, \"processed_eval\"))\n\ntrain_val_sub.sort(key=lambda x: x)\n\ntrain_sub = train_val_sub[: int(len(train_val_sub) * 0.8)]\nval_sub = train_val_sub[int(len(train_val_sub) * 0.8) :]\nprint(\"train sub:\", train_sub)\nprint(\"val sub:\", val_sub)\n\nval_files = [f for f in train_files if f.split(\"_\")[0] in val_sub]\ntrain_files = [f for f in train_files if f.split(\"_\")[0] in train_sub]\n\n\nif not os.path.exists(os.path.join(root, 'processed', 'processed_train')):\n    os.makedirs(os.path.join(root, 'processed', 'processed_train'))\nif not os.path.exists(os.path.join(root, 'processed', 'processed_eval')):\n    os.makedirs(os.path.join(root, 'processed', 'processed_eval'))\nif not os.path.exists(os.path.join(root, 'processed', 'processed_test')):\n    os.makedirs(os.path.join(root, 'processed', 'processed_test'))\n\nfor file in tqdm(train_files):\n    os.system(f\"cp {os.path.join(root, 'processed_train', file)} {os.path.join(root, 'processed', 'processed_train')}\")\nfor file in tqdm(val_files):\n    os.system(f\"cp {os.path.join(root, 'processed_train', file)} {os.path.join(root, 'processed', 'processed_eval')}\")\nfor file in tqdm(test_files):\n    os.system(f\"cp {os.path.join(root, 'processed_eval', file)} {os.path.join(root, 'processed', 'processed_test')}\")\n\nprint('Done!')\n"}
{"doc_id": "preprocessing/preprocessing_physio.py", "text": "import scipy\nfrom scipy import signal\nimport os\nimport lmdb\nimport pickle\nimport numpy as np\nimport mne\n\ntasks = ['04', '06', '08', '10', '12', '14'] # select the data for motor imagery\n\nroot_dir = '/data/datasets/eeg-motor-movementimagery-dataset-1.0.0/files'\nfiles = [file for file in os.listdir(root_dir)]\nfiles = sorted(files)\n\nfiles_dict = {\n    'train': files[:70],\n    'val': files[70:89],\n    'test': files[89:109],\n}\n\nprint(files_dict)\n\ndataset = {\n    'train': list(),\n    'val': list(),\n    'test': list(),\n}\n\n\n\nselected_channels = ['Fc5.', 'Fc3.', 'Fc1.', 'Fcz.', 'Fc2.', 'Fc4.', 'Fc6.', 'C5..', 'C3..', 'C1..', 'Cz..', 'C2..',\n                     'C4..', 'C6..', 'Cp5.', 'Cp3.', 'Cp1.', 'Cpz.', 'Cp2.', 'Cp4.', 'Cp6.', 'Fp1.', 'Fpz.', 'Fp2.',\n                     'Af7.', 'Af3.', 'Afz.', 'Af4.', 'Af8.', 'F7..', 'F5..', 'F3..', 'F1..', 'Fz..', 'F2..', 'F4..',\n                     'F6..', 'F8..', 'Ft7.', 'Ft8.', 'T7..', 'T8..', 'T9..', 'T10.', 'Tp7.', 'Tp8.', 'P7..', 'P5..',\n                     'P3..', 'P1..', 'Pz..', 'P2..', 'P4..', 'P6..', 'P8..', 'Po7.', 'Po3.', 'Poz.', 'Po4.', 'Po8.',\n                     'O1..', 'Oz..', 'O2..', 'Iz..']\n\ndb = lmdb.open('/data/datasets/eeg-motor-movementimagery-dataset-1.0.0/processed_average', map_size=4614542346)\n\nfor files_key in files_dict.keys():\n    for file in files_dict[files_key]:\n        for task in tasks:\n            raw = mne.io.read_raw_edf(os.path.join(root_dir, file, f'{file}R{task}.edf'), preload=True)\n            raw.pick_channels(selected_channels, ordered=True)\n            if len(raw.info['bads']) > 0:\n                print('interpolate_bads')\n                raw.interpolate_bads()\n            raw.set_eeg_reference(ref_channels='average')\n            raw.filter(l_freq=0.3, h_freq=None)\n            raw.notch_filter((60))\n            raw.resample(200)\n            events_from_annot, event_dict = mne.events_from_annotations(raw)\n            epochs = mne.Epochs(raw,\n                                events_from_annot,\n                                event_dict,\n                                tmin=0,\n                                tmax=4. - 1.0 / raw.info['sfreq'],\n                                baseline=None,\n                                preload=True)\n            data = epochs.get_data(units='uV')\n            events = epochs.events[:, 2]\n            print(data.shape, events)\n            data = data[:, :, -800:]\n            bz, ch_nums, _ = data.shape\n            data = data.reshape(bz, ch_nums, 4, 200)\n            print(data.shape)\n            for i, (sample, event) in enumerate(zip(data, events)):\n                if event != 1:\n                    sample_key = f'{file}R{task}-{i}'\n                    data_dict = {\n                        'sample': sample, 'label': event - 2 if task in ['04', '08', '12'] else event\n                    }\n                    txn = db.begin(write=True)\n                    txn.put(key=sample_key.encode(), value=pickle.dumps(data_dict))\n                    txn.commit()\n                    dataset[files_key].append(sample_key)\n\ntxn = db.begin(write=True)\ntxn.put(key='__keys__'.encode(), value=pickle.dumps(dataset))\ntxn.commit()\ndb.close()\n"}
{"doc_id": "preprocessing/preprocessing_faced.py", "text": "import scipy\nfrom scipy import signal\nimport os\nimport lmdb\nimport pickle\nimport numpy as np\n\n\nlabels = np.array([0,0,0,1,1,1,2,2,2,3,3,3,4,4,4,4,5,5,5,6,6,6,7,7,7,8,8,8])\nroot_dir = '/data/cyn/FACED/Processed_data'\nfiles = [file for file in os.listdir(root_dir)]\nfiles = sorted(files)\n\nfiles_dict = {\n    'train':files[:80],\n    'val':files[80:100],\n    'test':files[100:],\n}\n\ndataset = {\n    'train': list(),\n    'val': list(),\n    'test': list(),\n}\n\ndb = lmdb.open('/data/datasets/BigDownstream/Faced/processed', map_size=6612500172)\n\nfor files_key in files_dict.keys():\n    for file in files_dict[files_key]:\n        f = open(os.path.join(root_dir, file), 'rb')\n        array = pickle.load(f)\n        eeg = signal.resample(array, 6000, axis=2)\n        eeg_ = eeg.reshape(28, 32, 30, 200)\n        for i, (samples, label) in enumerate(zip(eeg_, labels)):\n            for j in range(3):\n                sample = samples[:, 10*j:10*(j+1), :]\n                sample_key = f'{file}-{i}-{j}'\n                print(sample_key)\n                data_dict = {\n                    'sample': sample, 'label': label\n                }\n                txn = db.begin(write=True)\n                txn.put(key=sample_key.encode(), value=pickle.dumps(data_dict))\n                txn.commit()\n                dataset[files_key].append(sample_key)\n\n\ntxn = db.begin(write=True)\ntxn.put(key='__keys__'.encode(), value=pickle.dumps(dataset))\ntxn.commit()\ndb.close()"}
{"doc_id": "preprocessing/preprocessing_mumtaz.py", "text": "import os\nimport mne\nimport numpy as np\nimport lmdb\nimport pickle\n\n#\u904d\u5386\u6587\u4ef6\u5939\ndef iter_files(rootDir):\n    #\u904d\u5386\u6839\u76ee\u5f55\n    files_H, files_MDD = [], []\n    for file in os.listdir(rootDir):\n        if 'TASK' not in file:\n            if 'MDD' in file:\n                files_MDD.append(file)\n            else:\n                files_H.append(file)\n    return files_H, files_MDD\n\n\nselected_channels = ['EEG Fp1-LE', 'EEG Fp2-LE', 'EEG F3-LE', 'EEG F4-LE', 'EEG C3-LE', 'EEG C4-LE', 'EEG P3-LE',\n                     'EEG P4-LE', 'EEG O1-LE', 'EEG O2-LE', 'EEG F7-LE', 'EEG F8-LE', 'EEG T3-LE', 'EEG T4-LE',\n                     'EEG T5-LE', 'EEG T6-LE', 'EEG Fz-LE', 'EEG Cz-LE', 'EEG Pz-LE']\nrootDir = '/data/datasets/MDDPHCED/files'\nfiles_H, files_MDD = iter_files(rootDir)\nfiles_H = sorted(files_H)\nfiles_MDD = sorted(files_MDD)\nprint(files_H)\nprint(files_MDD)\nprint(len(files_H), len(files_MDD))\n\n\nfiles_dict = {\n    'train':[],\n    'val':[],\n    'test':[],\n}\n\ndataset = {\n    'train': list(),\n    'val': list(),\n    'test': list(),\n}\n\nfiles_dict['train'].extend(files_H[:40])\nfiles_dict['train'].extend(files_MDD[:42])\nfiles_dict['val'].extend(files_H[40:48])\nfiles_dict['val'].extend(files_MDD[42:52])\nfiles_dict['test'].extend(files_H[48:])\nfiles_dict['test'].extend(files_MDD[52:])\n\nprint(files_dict['train'])\nprint(files_dict['val'])\nprint(files_dict['test'])\n\n\ndb = lmdb.open('/data/datasets/MDDPHCED/processed_lmdb_75hz', map_size=1273741824)\n\nfor files_key in files_dict.keys():\n    for file in files_dict[files_key]:\n        raw = mne.io.read_raw_edf(os.path.join(rootDir, file), preload=True)\n        print(raw.info['ch_names'])\n        raw.pick_channels(selected_channels, ordered=True)\n        print(raw.info['ch_names'])\n        raw.resample(200)\n        raw.filter(l_freq=0.3, h_freq=75)\n        raw.notch_filter((50))\n        # raw.plot_psd(average=True)\n        eeg_array = raw.to_data_frame().values\n        # print(raw.info)\n        eeg_array = eeg_array[:, 1:]\n        points, chs = eeg_array.shape\n        print(eeg_array.shape)\n        a = points % (5 * 200)\n        print(a)\n        if a != 0:\n            eeg_array = eeg_array[:-a, :]\n        eeg_array = eeg_array.reshape(-1, 5, 200, chs)\n        eeg_array = eeg_array.transpose(0, 3, 1, 2)\n        print(eeg_array.shape)\n        label = 1 if 'MDD' in file else 0\n        for i, sample in enumerate(eeg_array):\n            sample_key = f'{file[:-4]}_{i}'\n            data_dict = {\n                'sample': sample, 'label': label\n            }\n            txn = db.begin(write=True)\n            txn.put(key=sample_key.encode(), value=pickle.dumps(data_dict))\n            txn.commit()\n            dataset[files_key].append(sample_key)\n\n\ntxn = db.begin(write=True)\ntxn.put(key='__keys__'.encode(), value=pickle.dumps(dataset))\ntxn.commit()\ndb.close()"}
{"doc_id": "preprocessing/preprocessing_tueg_for_pretraining.py", "text": "import os\nimport random\n\nimport mne\nimport numpy as np\nfrom tqdm import tqdm\nimport pickle\nimport lmdb\n\n\nselected_channels = {\n    '01_tcp_ar': [\n            'EEG FP1-REF', 'EEG FP2-REF', 'EEG F3-REF', 'EEG F4-REF', 'EEG C3-REF', 'EEG C4-REF', 'EEG P3-REF',\n            'EEG P4-REF', 'EEG O1-REF', 'EEG O2-REF', 'EEG F7-REF', 'EEG F8-REF', 'EEG T3-REF', 'EEG T4-REF',\n            'EEG T5-REF', 'EEG T6-REF', 'EEG FZ-REF', 'EEG CZ-REF', 'EEG PZ-REF'\n    ],\n    '02_tcp_le': [\n            'EEG FP1-LE', 'EEG FP2-LE', 'EEG F3-LE', 'EEG F4-LE', 'EEG C3-LE', 'EEG C4-LE', 'EEG P3-LE',\n            'EEG P4-LE', 'EEG O1-LE', 'EEG O2-LE', 'EEG F7-LE', 'EEG F8-LE', 'EEG T3-LE', 'EEG T4-LE',\n            'EEG T5-LE', 'EEG T6-LE', 'EEG FZ-LE', 'EEG CZ-LE', 'EEG PZ-LE'\n    ],\n    '03_tcp_ar_a': [\n            'EEG FP1-REF', 'EEG FP2-REF', 'EEG F3-REF', 'EEG F4-REF', 'EEG C3-REF', 'EEG C4-REF', 'EEG P3-REF',\n            'EEG P4-REF', 'EEG O1-REF', 'EEG O2-REF', 'EEG F7-REF', 'EEG F8-REF', 'EEG T3-REF', 'EEG T4-REF',\n            'EEG T5-REF', 'EEG T6-REF', 'EEG FZ-REF', 'EEG CZ-REF', 'EEG PZ-REF'\n    ]\n}\n\ndef setup_seed(seed):\n    np.random.seed(seed)\n    random.seed(seed)\n\n\n#\u904d\u5386\u6587\u4ef6\u5939\ndef iter_files(rootDir):\n    #\u904d\u5386\u6839\u76ee\u5f55\n    file_path_list = []\n    for root,dirs,files in os.walk(rootDir):\n        for file in files:\n            file_name = os.path.join(root,file)\n            # print(file_name)\n            file_path_list.append(file_name)\n    return file_path_list\n\ndef preprocessing_recording(file_path, file_key_list: list, db: lmdb.open):\n    raw = mne.io.read_raw_edf(file_path, preload=True)\n    if '02_tcp_le' in file_path:\n        for ch in selected_channels['02_tcp_le']:\n            if ch not in raw.info['ch_names']:\n                return\n        raw.pick_channels(selected_channels['02_tcp_le'], ordered=True)\n    elif '01_tcp_ar' in file_path:\n        for ch in selected_channels['01_tcp_ar']:\n            if ch not in raw.info['ch_names']:\n                return\n        raw.pick_channels(selected_channels['01_tcp_ar'], ordered=True)\n    elif '03_tcp_ar_a' in file_path:\n        for ch in selected_channels['03_tcp_ar_a']:\n            if ch not in raw.info['ch_names']:\n                return\n        raw.pick_channels(selected_channels['03_tcp_ar_a'], ordered=True)\n    else:\n        return\n    # print(raw.info)\n    raw.resample(200)\n    raw.filter(l_freq=0.3, h_freq=75)\n    raw.notch_filter((60))\n    eeg_array = raw.to_data_frame().values\n    # print(raw.info)\n    eeg_array = eeg_array[:, 1:]\n    points, chs = eeg_array.shape\n    if points < 300 * 200:\n        return\n    a = points % (30 * 200)\n    eeg_array = eeg_array[60 * 200:-(a+60 * 200), :]\n    # print(eeg_array.shape)\n    eeg_array = eeg_array.reshape(-1, 30, 200, chs)\n    eeg_array = eeg_array.transpose(0, 3, 1, 2)\n    print(eeg_array.shape)\n    file_name = file_path.split('/')[-1][:-4]\n\n    for i, sample in enumerate(eeg_array):\n        # print(i, sample.shape)\n        if np.max(np.abs(sample)) < 100:\n            sample_key = f'{file_name}_{i}'\n            print(sample_key)\n            file_key_list.append(sample_key)\n            txn = db.begin(write=True)\n            txn.put(key=sample_key.encode(), value=pickle.dumps(sample))\n            txn.commit()\n\nif __name__ == '__main__':\n    setup_seed(1)\n    file_path_list = iter_files('path...')\n\n    file_path_list = sorted(file_path_list)\n    random.shuffle(file_path_list)\n    # print(file_path_list)\n    db = lmdb.open(r'path...', map_size=1649267441664)\n    file_key_list = []\n    for file_path in tqdm(file_path_list):\n        preprocessing_recording(file_path, file_key_list, db)\n\n    txn = db.begin(write=True)\n    txn.put(key='__keys__'.encode(), value=pickle.dumps(file_key_list))\n    txn.commit()\n    db.close()\n"}
{"doc_id": "preprocessing/preprocessing_seedvig.py", "text": "import h5py\nimport scipy\nfrom scipy import signal\nimport os\nimport lmdb\nimport pickle\nimport numpy as np\nimport pandas as pd\n\n\ndata_dir = '/data/datasets/BigDownstream/SEED-VIG/mat/Raw_Data'\nlabels_dir = '/data/datasets/BigDownstream/SEED-VIG/mat/perclos_labels'\n\nfiles = [file for file in os.listdir(data_dir)]\nfiles = sorted(files)\n\nfiles_dict = {\n    'train': files[:15],\n    'val': files[15:19],\n    'test': files[19:23],\n}\n\nprint(files_dict)\n\ndataset = {\n    'train': list(),\n    'val': list(),\n    'test': list(),\n}\n\ndb = lmdb.open('/data/datasets/BigDownstream/SEED-VIG/processed', map_size=6000000000)\n\nfor files_key in files_dict.keys():\n    for file in files_dict[files_key]:\n        eeg = scipy.io.loadmat(os.path.join(data_dir, file))['EEG'][0][0][0]\n        labels = scipy.io.loadmat(os.path.join(labels_dir, file))['perclos']\n        print(eeg.shape, labels.shape)\n        eeg = eeg.reshape(885, 8, 200, 17)\n        eeg = eeg.transpose(0, 3, 1, 2)\n        labels = labels[:, 0]\n        print(eeg.shape, labels.shape)\n        for i, (sample, label) in enumerate(zip(eeg, labels)):\n            sample_key = f'{file[:-4]}-{i}'\n            print(sample_key)\n            data_dict = {\n                'sample': sample, 'label': label\n            }\n            txn = db.begin(write=True)\n            txn.put(key=sample_key.encode(), value=pickle.dumps(data_dict))\n            txn.commit()\n            dataset[files_key].append(sample_key)\n\ntxn = db.begin(write=True)\ntxn.put(key='__keys__'.encode(), value=pickle.dumps(dataset))\ntxn.commit()\ndb.close()"}
{"doc_id": "preprocessing/preprocessing_SEEDV.py", "text": "import scipy\nfrom scipy import signal\nimport os\nimport lmdb\nimport pickle\nimport numpy as np\nimport mne\n\nuseless_ch = ['M1', 'M2', 'VEO', 'HEO']\ntrials_of_sessions = {\n    '1': {'start': [30, 132, 287, 555, 773, 982, 1271, 1628, 1730, 2025, 2227, 2435, 2667, 2932, 3204],\n          'end': [102, 228, 524, 742, 920, 1240, 1568, 1697, 1994, 2166, 2401, 2607, 2901, 3172, 3359]},\n\n    '2': {'start': [30, 299, 548, 646, 836, 1000, 1091, 1392, 1657, 1809, 1966, 2186, 2333, 2490, 2741],\n          'end': [267, 488, 614, 773, 967, 1059, 1331, 1622, 1777, 1908, 2153, 2302, 2428, 2709, 2817]},\n\n    '3': {'start': [30, 353, 478, 674, 825, 908, 1200, 1346, 1451, 1711, 2055, 2307, 2457, 2726, 2888],\n          'end': [321, 418, 643, 764, 877, 1147, 1284, 1418, 1679, 1996, 2275, 2425, 2664, 2857, 3066]},\n}\nlabels_of_sessions = {\n    '1': [4, 1, 3, 2, 0, 4, 1, 3, 2, 0, 4, 1, 3, 2, 0, ],\n    '2': [2, 1, 3, 0, 4, 4, 0, 3, 2, 1, 3, 4, 1, 2, 0, ],\n    '3': [2, 1, 3, 0, 4, 4, 0, 3, 2, 1, 3, 4, 1, 2, 0, ],\n}\n\nroot_dir = '/data/datasets/BigDownstream/SEED-V/files'\nfiles = [file for file in os.listdir(root_dir)]\nfiles = sorted(files)\nprint(files)\n\ntrials_split = {\n    'train': range(5),\n    'val': range(5, 10),\n    'test': range(10, 15),\n}\n\ndataset = {\n    'train': list(),\n    'val': list(),\n    'test': list(),\n}\n\ndb = lmdb.open('/data/datasets/BigDownstream/SEED-V/processed', map_size=15614542346)\n\nfor file in files:\n    raw = mne.io.read_raw_cnt(os.path.join(root_dir, file), preload=True)\n    raw.drop_channels(useless_ch)\n    # raw.set_eeg_reference(ref_channels='average')\n    raw.resample(200)\n    raw.filter(l_freq=0.3, h_freq=75)\n    data_matrix = raw.get_data(units='uV')\n    session_index = file.split('_')[1]\n    data_trials = [\n        data_matrix[:,\n        trials_of_sessions[session_index]['start'][j] * 200:trials_of_sessions[session_index]['end'][j] * 200]\n        for j in range(15)]\n    labels = labels_of_sessions[session_index]\n    for mode in trials_split.keys():\n        for index in trials_split[mode]:\n            data = data_trials[index]\n            label = labels[index]\n            print(data.shape)\n            data = data.reshape(62, -1, 1, 200)\n            data = data.transpose(1, 0, 2, 3)\n            print(data.shape)\n            for i, sample in enumerate(data):\n                sample_key = f'{file}-{index}-{i}'\n                data_dict = {\n                    'sample': sample, 'label': label\n                }\n                txn = db.begin(write=True)\n                txn.put(key=sample_key.encode(), value=pickle.dumps(data_dict))\n                txn.commit()\n                dataset[mode].append(sample_key)\n\ntxn = db.begin(write=True)\ntxn.put(key='__keys__'.encode(), value=pickle.dumps(dataset))\ntxn.commit()\ndb.close()\n"}
{"doc_id": "preprocessing/preprocessing_stress.py", "text": "import scipy\nfrom scipy import signal\nimport os\nimport lmdb\nimport pickle\nimport mne\n\nroot_dir = '/data/datasets/BigDownstream/mental-arithmetic/edf'\nfiles = [file for file in os.listdir(root_dir)]\nfiles = sorted(files)\nprint(files)\n\nfiles_dict = {\n    'train':files[:56],\n    'val':files[56:64],\n    'test':files[64:],\n}\nprint(files_dict)\ndataset = {\n    'train': list(),\n    'val': list(),\n    'test': list(),\n}\n\n\nselected_channels = ['EEG Fp1', 'EEG Fp2', 'EEG F3', 'EEG F4', 'EEG F7', 'EEG F8', 'EEG T3', 'EEG T4',\n                     'EEG C3', 'EEG C4', 'EEG T5', 'EEG T6', 'EEG P3', 'EEG P4', 'EEG O1', 'EEG O2',\n                     'EEG Fz', 'EEG Cz', 'EEG Pz', 'EEG A2-A1']\n\n\n\ndb = lmdb.open('/data/datasets/BigDownstream/mental-arithmetic/processed', map_size=1000000000)\nfor files_key in files_dict.keys():\n    for file in files_dict[files_key]:\n        raw = mne.io.read_raw_edf(os.path.join(root_dir, file), preload=True)\n        raw.pick(selected_channels)\n        raw.reorder_channels(selected_channels)\n        raw.resample(200)\n\n        eeg = raw.get_data(units='uV')\n        chs, points = eeg.shape\n        a = points % (5 * 200)\n        if a != 0:\n            eeg = eeg[:, :-a]\n        eeg = eeg.reshape(20, -1, 5, 200).transpose(1, 0, 2, 3)\n        label = int(file[-5])\n\n        for i, sample in enumerate(eeg):\n            sample_key = f'{file[:-4]}-{i}'\n            # print(sample_key)\n            data_dict = {\n                'sample':sample, 'label':label-1\n            }\n            txn = db.begin(write=True)\n            txn.put(key=sample_key.encode(), value=pickle.dumps(data_dict))\n            txn.commit()\n            dataset[files_key].append(sample_key)\n\ntxn = db.begin(write=True)\ntxn.put(key='__keys__'.encode(), value=pickle.dumps(dataset))\ntxn.commit()\ndb.close()"}
{"doc_id": "preprocessing/preprocessing_tuab.py", "text": "import os\nimport pickle\n\nfrom multiprocessing import Pool\nimport numpy as np\nimport mne\n\n# we need these channels\n# (signals[signal_names['EEG FP1-REF']] - signals[signal_names['EEG F7-REF']],  # 0\n# (signals[signal_names['EEG F7-REF']] - signals[signal_names['EEG T3-REF']]),  # 1\n# (signals[signal_names['EEG T3-REF']] - signals[signal_names['EEG T5-REF']]),  # 2\n# (signals[signal_names['EEG T5-REF']] - signals[signal_names['EEG O1-REF']]),  # 3\n# (signals[signal_names['EEG FP2-REF']] - signals[signal_names['EEG F8-REF']]),  # 4\n# (signals[signal_names['EEG F8-REF']] - signals[signal_names['EEG T4-REF']]),  # 5\n# (signals[signal_names['EEG T4-REF']] - signals[signal_names['EEG T6-REF']]),  # 6\n# (signals[signal_names['EEG T6-REF']] - signals[signal_names['EEG O2-REF']]),  # 7\n# (signals[signal_names['EEG FP1-REF']] - signals[signal_names['EEG F3-REF']]),  # 14\n# (signals[signal_names['EEG F3-REF']] - signals[signal_names['EEG C3-REF']]),  # 15\n# (signals[signal_names['EEG C3-REF']] - signals[signal_names['EEG P3-REF']]),  # 16\n# (signals[signal_names['EEG P3-REF']] - signals[signal_names['EEG O1-REF']]),  # 17\n# (signals[signal_names['EEG FP2-REF']] - signals[signal_names['EEG F4-REF']]),  # 18\n# (signals[signal_names['EEG F4-REF']] - signals[signal_names['EEG C4-REF']]),  # 19\n# (signals[signal_names['EEG C4-REF']] - signals[signal_names['EEG P4-REF']]),  # 20\n# (signals[signal_names['EEG P4-REF']] - signals[signal_names['EEG O2-REF']]))) # 21\nstandard_channels = [\n    \"EEG FP1-REF\",\n    \"EEG F7-REF\",\n    \"EEG T3-REF\",\n    \"EEG T5-REF\",\n    \"EEG O1-REF\",\n    \"EEG FP2-REF\",\n    \"EEG F8-REF\",\n    \"EEG T4-REF\",\n    \"EEG T6-REF\",\n    \"EEG O2-REF\",\n    \"EEG FP1-REF\",\n    \"EEG F3-REF\",\n    \"EEG C3-REF\",\n    \"EEG P3-REF\",\n    \"EEG O1-REF\",\n    \"EEG FP2-REF\",\n    \"EEG F4-REF\",\n    \"EEG C4-REF\",\n    \"EEG P4-REF\",\n    \"EEG O2-REF\",\n]\n\n\ndef split_and_dump(params):\n    fetch_folder, sub, dump_folder, label = params\n    for file in os.listdir(fetch_folder):\n        if sub in file:\n            print(\"process\", file)\n            file_path = os.path.join(fetch_folder, file)\n            raw = mne.io.read_raw_edf(file_path, preload=True)\n            raw.resample(200)\n            raw.filter(l_freq=0.3, h_freq=75)\n            raw.notch_filter((60))\n            ch_name = raw.ch_names\n            raw_data = raw.get_data(units='uV')\n            channeled_data = raw_data.copy()[:16]\n            try:\n                channeled_data[0] = (\n                    raw_data[ch_name.index(\"EEG FP1-REF\")]\n                    - raw_data[ch_name.index(\"EEG F7-REF\")]\n                )\n                channeled_data[1] = (\n                    raw_data[ch_name.index(\"EEG F7-REF\")]\n                    - raw_data[ch_name.index(\"EEG T3-REF\")]\n                )\n                channeled_data[2] = (\n                    raw_data[ch_name.index(\"EEG T3-REF\")]\n                    - raw_data[ch_name.index(\"EEG T5-REF\")]\n                )\n                channeled_data[3] = (\n                    raw_data[ch_name.index(\"EEG T5-REF\")]\n                    - raw_data[ch_name.index(\"EEG O1-REF\")]\n                )\n                channeled_data[4] = (\n                    raw_data[ch_name.index(\"EEG FP2-REF\")]\n                    - raw_data[ch_name.index(\"EEG F8-REF\")]\n                )\n                channeled_data[5] = (\n                    raw_data[ch_name.index(\"EEG F8-REF\")]\n                    - raw_data[ch_name.index(\"EEG T4-REF\")]\n                )\n                channeled_data[6] = (\n                    raw_data[ch_name.index(\"EEG T4-REF\")]\n                    - raw_data[ch_name.index(\"EEG T6-REF\")]\n                )\n                channeled_data[7] = (\n                    raw_data[ch_name.index(\"EEG T6-REF\")]\n                    - raw_data[ch_name.index(\"EEG O2-REF\")]\n                )\n                channeled_data[8] = (\n                    raw_data[ch_name.index(\"EEG FP1-REF\")]\n                    - raw_data[ch_name.index(\"EEG F3-REF\")]\n                )\n                channeled_data[9] = (\n                    raw_data[ch_name.index(\"EEG F3-REF\")]\n                    - raw_data[ch_name.index(\"EEG C3-REF\")]\n                )\n                channeled_data[10] = (\n                    raw_data[ch_name.index(\"EEG C3-REF\")]\n                    - raw_data[ch_name.index(\"EEG P3-REF\")]\n                )\n                channeled_data[11] = (\n                    raw_data[ch_name.index(\"EEG P3-REF\")]\n                    - raw_data[ch_name.index(\"EEG O1-REF\")]\n                )\n                channeled_data[12] = (\n                    raw_data[ch_name.index(\"EEG FP2-REF\")]\n                    - raw_data[ch_name.index(\"EEG F4-REF\")]\n                )\n                channeled_data[13] = (\n                    raw_data[ch_name.index(\"EEG F4-REF\")]\n                    - raw_data[ch_name.index(\"EEG C4-REF\")]\n                )\n                channeled_data[14] = (\n                    raw_data[ch_name.index(\"EEG C4-REF\")]\n                    - raw_data[ch_name.index(\"EEG P4-REF\")]\n                )\n                channeled_data[15] = (\n                    raw_data[ch_name.index(\"EEG P4-REF\")]\n                    - raw_data[ch_name.index(\"EEG O2-REF\")]\n                )\n            except:\n                with open(\"tuab-process-error-files.txt\", \"a\") as f:\n                    f.write(file + \"\\n\")\n                continue\n            for i in range(channeled_data.shape[1] // 2000):\n                dump_path = os.path.join(\n                    dump_folder, file.split(\".\")[0] + \"_\" + str(i) + \".pkl\"\n                )\n                pickle.dump(\n                    {\"X\": channeled_data[:, i * 2000 : (i + 1) * 2000], \"y\": label},\n                    open(dump_path, \"wb\"),\n                )\n\n\nif __name__ == \"__main__\":\n    \"\"\"\n    TUAB dataset is downloaded from https://isip.piconepress.com/projects/tuh_eeg/html/downloads.shtml\n    \"\"\"\n    # root to abnormal dataset\n    root = \"/data/datasets/BigDownstream/TUAB/edf\"\n    channel_std = \"01_tcp_ar\"\n\n    # seed = 4523\n    # np.random.seed(seed)\n    # train, val abnormal subjects\n    train_val_abnormal = os.path.join(root, \"train\", \"abnormal\", channel_std)\n    train_val_a_sub = list(\n        set([item.split(\"_\")[0] for item in os.listdir(train_val_abnormal)])\n    )\n    train_val_a_sub.sort(key=lambda x: x)\n\n    train_a_sub, val_a_sub = (\n        train_val_a_sub[: int(len(train_val_a_sub) * 0.8)],\n        train_val_a_sub[int(len(train_val_a_sub) * 0.8) :],\n    )\n    print('train_a_sub:', train_a_sub)\n    print('val_a_sub:', val_a_sub)\n\n    # train, val normal subjects\n    train_val_normal = os.path.join(root, \"train\", \"normal\", channel_std)\n    train_val_n_sub = list(\n        set([item.split(\"_\")[0] for item in os.listdir(train_val_normal)])\n    )\n    train_val_n_sub.sort(key=lambda x: x)\n\n    train_n_sub, val_n_sub = (\n        train_val_n_sub[: int(len(train_val_n_sub) * 0.8)],\n        train_val_n_sub[int(len(train_val_n_sub) * 0.8) :],\n    )\n    print('train_n_sub:', train_n_sub)\n    print('val_n_sub:', val_n_sub)\n\n\n    # test abnormal subjects\n    test_abnormal = os.path.join(root, \"eval\", \"abnormal\", channel_std)\n    test_a_sub = list(set([item.split(\"_\")[0] for item in os.listdir(test_abnormal)]))\n\n    # test normal subjects\n    test_normal = os.path.join(root, \"eval\", \"normal\", channel_std)\n    test_n_sub = list(set([item.split(\"_\")[0] for item in os.listdir(test_normal)]))\n\n    # create the train, val, test sample folder\n    if not os.path.exists(os.path.join(root, \"process_refine\")):\n        os.makedirs(os.path.join(root, \"process_refine\"))\n\n    if not os.path.exists(os.path.join(root, \"process_refine\", \"train\")):\n        os.makedirs(os.path.join(root, \"process_refine\", \"train\"))\n    train_dump_folder = os.path.join(root, \"process_refine\", \"train\")\n\n    if not os.path.exists(os.path.join(root, \"process_refine\", \"val\")):\n        os.makedirs(os.path.join(root, \"process_refine\", \"val\"))\n    val_dump_folder = os.path.join(root, \"process_refine\", \"val\")\n\n    if not os.path.exists(os.path.join(root, \"process_refine\", \"test\")):\n        os.makedirs(os.path.join(root, \"process_refine\", \"test\"))\n    test_dump_folder = os.path.join(root, \"process_refine\", \"test\")\n\n    # fetch_folder, sub, dump_folder, labels\n    parameters = []\n    for train_sub in train_a_sub:\n        parameters.append([train_val_abnormal, train_sub, train_dump_folder, 1])\n    for train_sub in train_n_sub:\n        parameters.append([train_val_normal, train_sub, train_dump_folder, 0])\n    for val_sub in val_a_sub:\n        parameters.append([train_val_abnormal, val_sub, val_dump_folder, 1])\n    for val_sub in val_n_sub:\n        parameters.append([train_val_normal, val_sub, val_dump_folder, 0])\n    for test_sub in test_a_sub:\n        parameters.append([test_abnormal, test_sub, test_dump_folder, 1])\n    for test_sub in test_n_sub:\n        parameters.append([test_normal, test_sub, test_dump_folder, 0])\n\n    # split and dump in parallel\n    with Pool(processes=24) as pool:\n        # Use the pool.map function to apply the square function to each element in the numbers list\n        result = pool.map(split_and_dump, parameters)\n\n    print('Done!')"}
{"doc_id": "preprocessing/preprocessing_shu.py", "text": "import scipy\nfrom scipy import signal\nimport os\nimport lmdb\nimport pickle\n\nroot_dir = '/data/datasets/BigDownstream/MODMA/files'\nfiles = [file for file in os.listdir(root_dir)]\nfiles = sorted(files)\n# print(files)\n\nfiles_dict = {\n    'train':files[:75],\n    'val':files[75:100],\n    'test':files[100:],\n}\n\ndataset = {\n    'train': list(),\n    'val': list(),\n    'test': list(),\n}\ndb = lmdb.open('/data/datasets/shu_datasets/processed', map_size=110612736)\nfor files_key in files_dict.keys():\n    for file in files_dict[files_key]:\n        data = scipy.io.loadmat(os.path.join(root_dir, file))\n        eeg = data['data']\n        labels = data['labels'][0]\n        bz, ch_num, points = eeg.shape\n        print(eeg.shape)\n        eeg_resample = signal.resample(eeg, 800, axis=2)\n        eeg_ = eeg_resample.reshape(bz, ch_num, 4, 200)\n        print(eeg_.shape, labels.shape)\n        for i, (sample, label) in enumerate(zip(eeg_, labels)):\n            sample_key = f'{file[:-4]}-{i}'\n            # print(sample_key)\n            data_dict = {\n                'sample':sample, 'label':label-1\n            }\n            txn = db.begin(write=True)\n            txn.put(key=sample_key.encode(), value=pickle.dumps(data_dict))\n            txn.commit()\n            dataset[files_key].append(sample_key)\n\ntxn = db.begin(write=True)\ntxn.put(key='__keys__'.encode(), value=pickle.dumps(dataset))\ntxn.commit()\ndb.close()"}
{"doc_id": "preprocessing/__init__.py", "text": ""}
{"doc_id": "preprocessing/CHB-MIT/process2.py", "text": "import pickle\nimport os\nimport numpy as np\nfrom tqdm import tqdm\nimport multiprocessing as mp\n\nroot = \"/data/datasets/BigDownstream/chb-mit/processed\"\nout = \"/data/datasets/BigDownstream/chb-mit/processed_seg\"\n\n# root = 'clean_signals'\n# out = 'clean_segments'\n\nif not os.path.exists(out):\n    os.makedirs(out)\n\n# dump chb23 and chb24 to test, ch21 and ch22 to val, and the rest to train\ntest_pats = [\"chb23\", \"chb24\"]\nval_pats = [\"chb21\", \"chb22\"]\ntrain_pats = [\n    \"chb01\",\n    \"chb02\",\n    \"chb03\",\n    \"chb04\",\n    \"chb05\",\n    \"chb06\",\n    \"chb07\",\n    \"chb08\",\n    \"chb09\",\n    \"chb10\",\n    \"chb11\",\n    \"chb12\",\n    \"chb13\",\n    \"chb14\",\n    \"chb15\",\n    \"chb16\",\n    \"chb17\",\n    \"chb18\",\n    \"chb19\",\n    \"chb20\",\n]\nchannels = [\n    \"FP1-F7\",\n    \"F7-T7\",\n    \"T7-P7\",\n    \"P7-O1\",\n    \"FP2-F8\",\n    \"F8-T8\",\n    \"T8-P8\",\n    \"P8-O2\",\n    \"FP1-F3\",\n    \"F3-C3\",\n    \"C3-P3\",\n    \"P3-O1\",\n    \"FP2-F4\",\n    \"F4-C4\",\n    \"C4-P4\",\n    \"P4-O2\",\n]\nSAMPLING_RATE = 256\n\n\ndef sub_to_segments(folder, out_folder):\n    print(f\"Processing {folder}...\")\n    # each recording\n    for f in tqdm(os.listdir(os.path.join(root, folder))):\n        print(f\"Processing {folder}/{f}...\")\n        record = pickle.load(open(os.path.join(root, folder, f), \"rb\"))\n        \"\"\"\n        {'FP1-F7': array([-145.93406593,    0.1953602 ,    0.1953602 , ...,  -11.52625153, -2.93040293,   19.34065934]), \n         'F7-T7': array([-104.51770452,    0.1953602 ,    0.1953602 , ...,   23.63858364, 27.54578755,   30.67155067]), \n         'T7-P7': array([-42.78388278,   0.1953602 ,   0.1953602 , ...,  48.64468864, 45.12820513,  34.57875458]), \n        'P7-O1': array([-33.01587302,   0.1953602 ,   0.1953602 , ..., -17.77777778, -20.51282051, -25.59218559]), \n       'FP1-F3': array([-170.94017094,    0.1953602 ,    0.1953602 , ...,  -34.96947497, -25.98290598,    0.1953602 ]), \n        'F3-C3': array([-110.76923077,    0.1953602 ,    0.1953602 , ...,   38.0952381 , 48.64468864,   50.20757021]), \n         'C3-P3': array([11.91697192,  0.1953602 ,  0.1953602 , ..., 40.04884005, 33.7973138 , 25.98290598]), \n       'P3-O1': array([-56.45909646,   0.1953602 ,   0.1953602 , ...,   0.97680098, -6.44688645, -16.60561661]), \n        'FP2-F4': array([-139.29181929,    0.1953602 ,    0.1953602 , ...,   -2.14896215, -2.14896215,   -0.58608059]), \n         'F4-C4': array([-1.36752137,  0.1953602 ,  0.1953602 , ...,  1.75824176, 2.93040293,  7.22832723]), \n        'C4-P4': array([63.88278388,  0.1953602 ,  0.1953602 , ..., 16.996337  , 23.63858364, 25.59218559]), \n       'P4-O2': array([-14.26129426,   0.1953602 ,   0.1953602 , ..., -13.08913309, -8.00976801, -13.47985348]), \n        'FP2-F8': array([-2.67838828e+02,  1.95360195e-01,  1.95360195e-01, ..., 6.83760684e+00,  6.05616606e+00,  6.44688645e+00]), \n        'F8-T8': array([ 57.24053724,   0.1953602 ,   0.1953602 , ...,  -2.53968254,  -9.96336996, -12.6984127 ]), \n        'T8-P8': array([44.73748474,  0.1953602 ,  0.1953602 , ..., 16.996337  , 22.46642247, 26.37362637]), \n       'P8-O2': array([ 74.82295482,   0.1953602 ,  -0.1953602 , ..., -17.38705739, -1.75824176,  -2.53968254]), \n        'FZ-CZ': array([-106.08058608,    0.1953602 ,    0.1953602 , ...,   24.81074481, 28.71794872,   28.71794872]), \n         'CZ-PZ': array([84.59096459,  0.1953602 ,  0.1953602 , ..., 18.94993895, 20.51282051, 18.16849817]), \n       'P7-T7': array([ 43.17460317,   0.1953602 ,   0.1953602 , ..., -48.25396825, -44.73748474, -34.18803419]), \n       'T7-FT9': array([-57.24053724,   0.1953602 ,   0.1953602 , ..., -11.91697192,  -3.71184371,   2.14896215]), \n        'FT9-FT10': array([-2.64713065e+02,  1.95360195e-01,  5.86080586e-01, ..., 9.76800977e-01, -1.58241758e+01, -2.94993895e+01]), \n        'FT10-T8': array([ 94.74969475,   0.1953602 ,   0.1953602 , ...,  -7.22832723, -10.35409035, -13.47985348]), \n       'T8-P8-2': array([44.73748474,  0.1953602 ,  0.1953602 , ..., 16.996337  , 22.46642247, 26.37362637]), \n       'metadata': {'seizures': 0, 'times': [], 'channels': ['FP1-F7', 'F7-T7', 'T7-P7', 'P7-O1', 'FP1-F3', 'F3-C3', 'C3-P3', 'P3-O1', 'FP2-F4', 'F4-C4', 'C4-P4', 'P4-O2', 'FP2-F8', 'F8-T8', 'T8-P8', 'P8-O2', 'FZ-CZ', 'CZ-PZ', 'P7-T7', 'T7-FT9', 'FT9-FT10', 'FT10-T8', 'T8-P8-2']}}\n        \"\"\"\n        signal = []\n        for channel in channels:\n            if channel in record:\n                signal.append(record[channel])\n            else:\n                raise ValueError(f\"Channel {channel} not found in record {record}\")\n        signal = np.array(signal)\n\n        if \"times\" in record[\"metadata\"]:\n            seizure_times = record[\"metadata\"][\"times\"]\n        else:\n            seizure_times = []\n\n        # split the signal into segments on the second dimension by SAMPLING_RATE * 10 seconds\n        for i in range(0, signal.shape[1], SAMPLING_RATE * 10):\n            segment = signal[:, i : i + 10 * SAMPLING_RATE]\n            if segment.shape[1] == 10 * SAMPLING_RATE:\n                # judge whether the segment contains seizures\n                label = 0\n\n                for seizure_time in seizure_times:\n                    if (\n                        i < seizure_time[0] < i + 10 * SAMPLING_RATE\n                        or i < seizure_time[1] < i + 10 * SAMPLING_RATE\n                    ):\n                        label = 1\n                        break\n\n                # save the segment\n                pickle.dump(\n                    {\"X\": segment, \"y\": label},\n                    open(\n                        os.path.join(out_folder, f\"{f.split('.')[0]}-{i}.pkl\"),\n                        \"wb\",\n                    ),\n                )\n\n        for idx, seizure_time in enumerate(seizure_times):\n            for i in range(\n                max(0, seizure_time[0] - SAMPLING_RATE),\n                min(seizure_time[1] + SAMPLING_RATE, signal.shape[1]),\n                5 * SAMPLING_RATE,\n            ):\n                segment = signal[:, i : i + 10 * SAMPLING_RATE]\n                label = 1\n                # save the segment\n                pickle.dump(\n                    {\"X\": segment, \"y\": label},\n                    open(\n                        os.path.join(\n                            out_folder, f\"{f.split('.')[0]}-s-{idx}-add-{i}.pkl\"\n                        ),\n                        \"wb\",\n                    ),\n                )\n\n\n# parallel parameters\nfolders = os.listdir(root)\nout_folders = []\nfor folder in folders:\n    if folder in test_pats:\n        out_folder = os.path.join(out, \"test\")\n    elif folder in val_pats:\n        out_folder = os.path.join(out, \"val\")\n    else:\n        out_folder = os.path.join(out, \"train\")\n\n    if not os.path.exists(out_folder):\n        os.makedirs(out_folder)\n\n    out_folders.append(out_folder)\n\n# process in parallel\nwith mp.Pool(mp.cpu_count()) as pool:\n    res = pool.starmap(sub_to_segments, zip(folders, out_folders))\n"}
{"doc_id": "preprocessing/CHB-MIT/process1.py", "text": "import os\nfrom collections import defaultdict\nimport pyedflib\nimport pyedflib.highlevel as hl\nimport numpy as np\nimport copy\nimport shutil\nimport bz2\nimport pickle\nimport _pickle as cPickle\nimport multiprocessing as mp\n\n\n# Pickle a file and then compress it into a file with extension\ndef compressed_pickle(title, data):\n    # with bz2.BZ2File(title + '.pbz2', 'w') as f:\n    #     cPickle.dump(data, f)\n    pickle.dump(data, open(title, \"wb\"))\n\n\n# Process metadata\ndef process_metadata(summary, filename):\n    f = open(summary, \"r\")\n\n    metadata = {}\n    lines = f.readlines()\n    times = []\n    for i in range(len(lines)):\n        line = lines[i].split()\n        if len(line) == 3 and line[2] == filename:\n            j = i + 1\n            processed = False\n            while not processed:\n                if lines[j].split()[0] == \"Number\":\n                    seizures = int(lines[j].split()[-1])\n                    processed = True\n                j = j + 1\n\n            # If file has seizures get start and end time\n            if seizures > 0:\n                j = i + 1\n                for s in range(seizures):\n                    # Save start and end time of each seizure\n                    processed = False\n                    while not processed:\n                        l = lines[j].split()\n                        # print(l)\n\n                        if l[0] == \"Seizure\" and \"Start\" in l:\n                            start = int(l[-2]) * 256 - 1  # Index of start time\n                            end = (\n                                int(lines[j + 1].split()[-2]) * 256 - 1\n                            )  # Index of end time\n                            processed = True\n                        j = j + 1\n                    times.append((start, end))\n\n            metadata[\"seizures\"] = seizures\n            metadata[\"times\"] = times\n\n    return metadata\n\n\n# Keep some channels from a .edf and ignore the others\ndef drop_channels(edf_source, edf_target=None, to_keep=None, to_drop=None):\n    signals, signal_headers, header = hl.read_edf(\n        edf_source, ch_nrs=to_keep, digital=False\n    )\n    clean_file = {}\n    for signal, header in zip(signals, signal_headers):\n        channel = header.get(\"label\")\n        if channel in clean_file.keys():\n            channel = channel + \"-2\"\n        clean_file[channel] = signal\n    return clean_file\n\n\n# At first, it permuted the channels of a edf signal\n# Now, only keeps valid channels and compress+save into pkl\ndef move_channels(clean_dict, channels, target):\n    # Keep only valid channels\n    keys_to_delete = []\n    for key in clean_dict:\n        if key != \"metadata\" and key not in channels.keys():\n            keys_to_delete.append(key)\n    for key in keys_to_delete:\n        del clean_dict[key]\n\n    # Get size of the numpy array\n    size = 0\n    for item in clean_dict.keys():\n        if item != \"metadata\":\n            size = len(clean_dict.get(item))\n            break\n\n    for k in channels.keys():\n        if k not in clean_dict.keys():\n            clean_dict[k] = np.zeros(size, dtype=float)\n\n    compressed_pickle(target + \".pkl\", clean_dict)\n\n\n# Process edf files of a pacient from start number to end number\ndef process_files(pacient, valid_channels, channels, start, end):\n    for num in range(start, end + 1):\n        to_keep = []\n\n        num = (\"0\" + str(num))[-2:]\n        filename = \"{path}/chb{p}/chb{p}_{n}.edf\".format(\n            path=signals_path, p=pacient, n=num\n        )\n\n        # Check with (cleaned) reference file  if we have to remove more channels\n        try:\n            signals, signal_headers, header = hl.read_edf(filename, digital=False)\n            n = 0\n            for h in signal_headers:\n                if h.get(\"label\") in valid_channels:\n                    if n not in to_keep:\n                        to_keep.append(n)\n                n = n + 1\n\n        except OSError:\n            print(\"****************************************\")\n            print(\"WARNING - Do not worry\")\n            print(\"File\", filename, \"does not exist.\\nProcessing next file.\")\n            print(\"****************************************\")\n            continue\n\n        if len(to_keep) > 0:\n            try:\n                print(\n                    \"Removing\",\n                    len(signal_headers) - len(to_keep),\n                    \"channels from file \",\n                    \"chb{p}_{n}.edf\".format(p=pacient, n=num),\n                )\n                clean_dict = drop_channels(\n                    filename,\n                    edf_target=\"{path}/chb{p}/chb{p}_{n}.edf\".format(\n                        path=clean_path, p=pacient, n=num\n                    ),\n                    to_keep=to_keep,\n                )\n                print(\"Processing file \", filename)\n            except AssertionError:\n                print(\"****************************************\")\n                print(\"WARNING - Do not worry\")\n                print(\"File\", filename, \"does not exist.\\nProcessing next file.\")\n                print(\"****************************************\")\n                continue\n\n        metadata = process_metadata(\n            \"{path}/chb{p}/chb{p}-summary.txt\".format(path=signals_path, p=pacient),\n            \"chb{p}_{n}.edf\".format(p=pacient, n=num),\n        )\n        metadata[\"channels\"] = valid_channels\n        clean_dict[\"metadata\"] = metadata\n        target = \"{path}/chb{p}/chb{p}_{n}.edf\".format(\n            path=clean_path, p=pacient, n=num\n        )\n        move_channels(clean_dict, channels, target)\n\n\ndef start_process(pacient, num, start, end, sum_ind):\n    # Summary file\n    f = open(\n        \"{path}/chb{p}/chb{p}-summary.txt\".format(path=signals_path, p=pacient), \"r\"\n    )\n\n    channels = defaultdict(list)  # Dict of channels and indices\n    valid_channels = []  # Valid channels\n    to_keep = []  # Indices of channels we want to keep\n\n    channel_index = 1  # Index for each channel\n    summary_index = 0  # Index to choose which channel reference take from summary file\n\n    # Process summary file\n    for line in f:\n        line = line.split()\n        if len(line) == 0:\n            continue\n\n        if line[0] == \"Channels\" and line[1] == \"changed:\":\n            summary_index += 1\n\n        if (\n            line[0] == \"Channel\"\n            and summary_index == sum_ind\n            and (line[2] != \"-\" and line[2] != \".\")\n        ):  # '-' means a void channel\n            if (\n                line[2] in channels.keys()\n            ):  # In case of repeated channel just add '-2' to the label\n                name = line[2] + \"-2\"\n            else:\n                name = line[2]\n\n            # Add channel to dict and update lists\n            channels[name].append(str(channel_index))\n            channel_index += 1\n            valid_channels.append(name)\n            to_keep.append(int(line[1][:-1]) - 1)\n\n    # for item in channels.items(): print(item)\n\n    # Clean reference file\n    filename = \"{path}/chb{p}/chb{p}_{n}.edf\".format(\n        path=signals_path, p=pacient, n=num\n    )\n    target = \"{path}/chb{p}/chb{p}_{n}.edf\".format(path=clean_path, p=pacient, n=num)\n\n    if not os.path.exists(\"{path}/chb{p}\".format(p=pacient, path=clean_path)):\n        os.makedirs(\"{path}/chb{p}\".format(p=pacient, path=clean_path))\n\n    clean_dict = drop_channels(filename, edf_target=target, to_keep=to_keep)\n\n    # Process metadata : Number of seizures and start/end time\n    metadata = process_metadata(\n        \"{path}/chb{p}/chb{p}-summary.txt\".format(path=signals_path, p=pacient),\n        \"chb{p}_{n}.edf\".format(p=pacient, n=num),\n    )\n\n    metadata[\"channels\"] = valid_channels\n    clean_dict[\"metadata\"] = metadata\n\n    compressed_pickle(target + \".pkl\", clean_dict)\n\n    # Process the rest of the files to get same channels as reference file\n    process_files(pacient, valid_channels, channels, start, end)\n\n\n# PARAMETERS\nsignals_path = r\"/data/datasets/chb-mit-scalp-eeg-database-1.0.0\"  # Path to the data main directory\nclean_path = r\"/data/datasets/BigDownstream/chb-mit/processed\"  # Path where to store clean data\n\nif not os.path.exists(clean_path):\n    os.makedirs(clean_path)\n\n# Clean pacients one by one manually with these parameters\npacient = \"04\"\nnum = \"01\"  # Reference file\nsummary_index = 0  # Index of channels summary reference\nstart = 28  # Number of first file to process\nend = 28  # Number of last file to process\n# Start the process\n# start_process(pacient, num, start, end, summary_index)\n\n\n# FULL DATA PROCESS\nparameters = [\n    (\"01\", \"01\", 2, 46, 0),\n    (\"02\", \"01\", 2, 35, 0),\n    (\"03\", \"01\", 2, 38, 0),\n    (\"05\", \"01\", 2, 39, 0),\n    (\"06\", \"01\", 2, 24, 0),\n    (\"07\", \"01\", 2, 19, 0),\n    (\"08\", \"02\", 3, 29, 0),\n    (\"10\", \"01\", 2, 89, 0),\n    (\"11\", \"01\", 2, 99, 0),\n    (\"14\", \"01\", 2, 42, 0),\n    (\"20\", \"01\", 2, 68, 0),\n    (\"21\", \"01\", 2, 33, 0),\n    (\"22\", \"01\", 2, 77, 0),\n    (\"23\", \"06\", 7, 20, 0),\n    (\"24\", \"01\", 3, 21, 0),\n    (\"04\", \"07\", 1, 43, 1),\n    (\"09\", \"02\", 1, 19, 1),\n    (\"15\", \"02\", 1, 63, 1),\n    (\"16\", \"01\", 2, 19, 0),\n    (\"18\", \"02\", 1, 36, 1),\n    (\"19\", \"02\", 1, 30, 1),\n]\n\n# parameters = [\n#     (\"12\", \"\")\n# ]\n\n\n\n\nwith mp.Pool(mp.cpu_count()) as pool:\n    res = pool.starmap(start_process, parameters)\n"}
{"doc_id": "preprocessing/CHB-MIT/__init__.py", "text": ""}
{"doc_id": "preprocessing/ISRUC/edf_.py", "text": "\"\"\"Reading tools from EDF, EDF+, BDF, and GDF.\"\"\"\n\n# Authors: Teon Brooks <teon.brooks@gmail.com>\n#          Martin Billinger <martin.billinger@tugraz.at>\n#          Nicolas Barascud <nicolas.barascud@ens.fr>\n#          Stefan Appelhoff <stefan.appelhoff@mailbox.org>\n#          Joan Massich <mailsik@gmail.com>\n#          Clemens Brunner <clemens.brunner@gmail.com>\n#          Jeroen Van Der Donckt (IDlab - imec) <jeroen.vanderdonckt@ugent.be>\n#\n# License: BSD-3-Clause\n# Copyright the MNE-Python contributors.\n\nimport os\nimport re\nfrom datetime import datetime, timedelta, timezone\n\nimport numpy as np\nfrom scipy.interpolate import interp1d\n\nfrom mne._fiff.constants import FIFF\nfrom mne._fiff.meas_info import _empty_info, _unique_channel_names\nfrom mne._fiff.utils import _blk_read_lims, _mult_cal_one\nfrom mne.annotations import Annotations\nfrom mne.filter import resample\nfrom mne.utils import _validate_type, fill_doc, logger, verbose, warn\nfrom mne.io.base import BaseRaw, _get_scaling\n\n# common channel type names mapped to internal ch types\nCH_TYPE_MAPPING = {\n    \"EEG\": FIFF.FIFFV_EEG_CH,\n    \"SEEG\": FIFF.FIFFV_SEEG_CH,\n    \"ECOG\": FIFF.FIFFV_ECOG_CH,\n    \"DBS\": FIFF.FIFFV_DBS_CH,\n    \"EOG\": FIFF.FIFFV_EOG_CH,\n    \"ECG\": FIFF.FIFFV_ECG_CH,\n    \"EMG\": FIFF.FIFFV_EMG_CH,\n    \"BIO\": FIFF.FIFFV_BIO_CH,\n    \"RESP\": FIFF.FIFFV_RESP_CH,\n    \"TEMP\": FIFF.FIFFV_TEMPERATURE_CH,\n    \"MISC\": FIFF.FIFFV_MISC_CH,\n    \"SAO2\": FIFF.FIFFV_BIO_CH,\n}\n\n\n@fill_doc\nclass RawEDF(BaseRaw):\n    \"\"\"Raw object from EDF, EDF+ or BDF file.\n\n    Parameters\n    ----------\n    input_fname : path-like\n        Path to the EDF, EDF+ or BDF file.\n    eog : list or tuple\n        Names of channels or list of indices that should be designated EOG\n        channels. Values should correspond to the electrodes in the file.\n        Default is None.\n    misc : list or tuple\n        Names of channels or list of indices that should be designated MISC\n        channels. Values should correspond to the electrodes in the file.\n        Default is None.\n    stim_channel : ``'auto'`` | str | list of str | int | list of int\n        Defaults to ``'auto'``, which means that channels named ``'status'`` or\n        ``'trigger'`` (case insensitive) are set to STIM. If str (or list of\n        str), all channels matching the name(s) are set to STIM. If int (or\n        list of ints), the channels corresponding to the indices are set to\n        STIM.\n    exclude : list of str\n        Channel names to exclude. This can help when reading data with\n        different sampling rates to avoid unnecessary resampling.\n    infer_types : bool\n        If True, try to infer channel types from channel labels. If a channel\n        label starts with a known type (such as 'EEG') followed by a space and\n        a name (such as 'Fp1'), the channel type will be set accordingly, and\n        the channel will be renamed to the original label without the prefix.\n        For unknown prefixes, the type will be 'EEG' and the name will not be\n        modified. If False, do not infer types and assume all channels are of\n        type 'EEG'.\n\n        .. versionadded:: 0.24.1\n    include : list of str | str\n        Channel names to be included. A str is interpreted as a regular\n        expression. 'exclude' must be empty if include is assigned.\n\n        .. versionadded:: 1.1\n    %(preload)s\n    %(units_edf_bdf_io)s\n    %(encoding_edf)s\n    %(verbose)s\n\n    See Also\n    --------\n    mne.io.Raw : Documentation of attributes and methods.\n    mne.io.read_raw_edf : Recommended way to read EDF/EDF+ files.\n    mne.io.read_raw_bdf : Recommended way to read BDF files.\n\n    Notes\n    -----\n    %(edf_resamp_note)s\n\n    Biosemi devices trigger codes are encoded in 16-bit format, whereas system\n    codes (CMS in/out-of range, battery low, etc.) are coded in bits 16-23 of\n    the status channel (see http://www.biosemi.com/faq/trigger_signals.htm).\n    To retrieve correct event values (bits 1-16), one could do:\n\n        >>> events = mne.find_events(...)  # doctest:+SKIP\n        >>> events[:, 2] &= (2**16 - 1)  # doctest:+SKIP\n\n    The above operation can be carried out directly in :func:`mne.find_events`\n    using the ``mask`` and ``mask_type`` parameters (see\n    :func:`mne.find_events` for more details).\n\n    It is also possible to retrieve system codes, but no particular effort has\n    been made to decode these in MNE. In case it is necessary, for instance to\n    check the CMS bit, the following operation can be carried out:\n\n        >>> cms_bit = 20  # doctest:+SKIP\n        >>> cms_high = (events[:, 2] & (1 << cms_bit)) != 0  # doctest:+SKIP\n\n    It is worth noting that in some special cases, it may be necessary to shift\n    event values in order to retrieve correct event triggers. This depends on\n    the triggering device used to perform the synchronization. For instance, in\n    some files events need to be shifted by 8 bits:\n\n        >>> events[:, 2] >>= 8  # doctest:+SKIP\n\n    TAL channels called 'EDF Annotations' or 'BDF Annotations' are parsed and\n    extracted annotations are stored in raw.annotations. Use\n    :func:`mne.events_from_annotations` to obtain events from these\n    annotations.\n\n    If channels named 'status' or 'trigger' are present, they are considered as\n    STIM channels by default. Use func:`mne.find_events` to parse events\n    encoded in such analog stim channels.\n    \"\"\"\n\n    @verbose\n    def __init__(\n        self,\n        input_fname,\n        eog=None,\n        misc=None,\n        stim_channel=\"auto\",\n        exclude=(),\n        infer_types=False,\n        preload=False,\n        include=None,\n        units=None,\n        encoding=\"utf8\",\n        *,\n        verbose=None,\n    ):\n        logger.info(\"Extracting EDF parameters from {}...\".format(input_fname))\n        input_fname = os.path.abspath(input_fname)\n        info, edf_info, orig_units = _get_info(\n            input_fname, stim_channel, eog, misc, exclude, infer_types, preload, include\n        )\n        logger.info(\"Creating raw.info structure...\")\n\n        _validate_type(units, (str, None, dict), \"units\")\n        if units is None:\n            units = dict()\n        elif isinstance(units, str):\n            units = {ch_name: units for ch_name in info[\"ch_names\"]}\n\n        for k, (this_ch, this_unit) in enumerate(orig_units.items()):\n            if this_ch not in units:\n                continue\n            if this_unit not in (\"\", units[this_ch]):\n                raise ValueError(\n                    f\"Unit for channel {this_ch} is present in the file as \"\n                    f\"{repr(this_unit)}, cannot overwrite it with the units \"\n                    f\"argument {repr(units[this_ch])}.\"\n                )\n            if this_unit == \"\":\n                orig_units[this_ch] = units[this_ch]\n                ch_type = edf_info[\"ch_types\"][k]\n                scaling = _get_scaling(ch_type.lower(), orig_units[this_ch])\n                edf_info[\"units\"][k] /= scaling\n\n        # Raw attributes\n        last_samps = [edf_info[\"nsamples\"] - 1]\n        super().__init__(\n            info,\n            preload,\n            filenames=[input_fname],\n            raw_extras=[edf_info],\n            last_samps=last_samps,\n            orig_format=\"int\",\n            orig_units=orig_units,\n            verbose=verbose,\n        )\n\n        # Read annotations from file and set it\n        if len(edf_info[\"tal_idx\"]) > 0:\n            # Read TAL data exploiting the header info (no regexp)\n            idx = np.empty(0, int)\n            tal_data = self._read_segment_file(\n                np.empty((0, self.n_times)),\n                idx,\n                0,\n                0,\n                int(self.n_times),\n                np.ones((len(idx), 1)),\n                None,\n            )\n            annotations = _read_annotations_edf(\n                tal_data[0],\n                ch_names=info[\"ch_names\"],\n                encoding=encoding,\n            )\n            self.set_annotations(annotations, on_missing=\"warn\")\n\n    def _read_segment_file(self, data, idx, fi, start, stop, cals, mult):\n        \"\"\"Read a chunk of raw data.\"\"\"\n        return _read_segment_file(\n            data,\n            idx,\n            fi,\n            start,\n            stop,\n            self._raw_extras[fi],\n            self._filenames[fi],\n            cals,\n            mult,\n        )\n\n\n@fill_doc\nclass RawGDF(BaseRaw):\n    \"\"\"Raw object from GDF file.\n\n    Parameters\n    ----------\n    input_fname : path-like\n        Path to the GDF file.\n    eog : list or tuple\n        Names of channels or list of indices that should be designated EOG\n        channels. Values should correspond to the electrodes in the file.\n        Default is None.\n    misc : list or tuple\n        Names of channels or list of indices that should be designated MISC\n        channels. Values should correspond to the electrodes in the file.\n        Default is None.\n    stim_channel : ``'auto'`` | str | list of str | int | list of int\n        Defaults to 'auto', which means that channels named 'status' or\n        'trigger' (case insensitive) are set to STIM. If str (or list of str),\n        all channels matching the name(s) are set to STIM. If int (or list of\n        ints), channels corresponding to the indices are set to STIM.\n    exclude : list of str\n        Channel names to exclude. This can help when reading data with\n        different sampling rates to avoid unnecessary resampling.\n\n        .. versionadded:: 0.24.1\n    include : list of str | str\n        Channel names to be included. A str is interpreted as a regular\n        expression. 'exclude' must be empty if include is assigned.\n\n        .. versionadded:: 1.1\n    %(preload)s\n    %(verbose)s\n\n    See Also\n    --------\n    mne.io.Raw : Documentation of attributes and methods.\n    mne.io.read_raw_gdf : Recommended way to read GDF files.\n\n    Notes\n    -----\n    If channels named 'status' or 'trigger' are present, they are considered as\n    STIM channels by default. Use func:`mne.find_events` to parse events\n    encoded in such analog stim channels.\n    \"\"\"\n\n    @verbose\n    def __init__(\n        self,\n        input_fname,\n        eog=None,\n        misc=None,\n        stim_channel=\"auto\",\n        exclude=(),\n        preload=False,\n        include=None,\n        verbose=None,\n    ):\n        logger.info(\"Extracting EDF parameters from {}...\".format(input_fname))\n        input_fname = os.path.abspath(input_fname)\n        info, edf_info, orig_units = _get_info(\n            input_fname, stim_channel, eog, misc, exclude, True, preload, include\n        )\n        logger.info(\"Creating raw.info structure...\")\n\n        # Raw attributes\n        last_samps = [edf_info[\"nsamples\"] - 1]\n        super().__init__(\n            info,\n            preload,\n            filenames=[input_fname],\n            raw_extras=[edf_info],\n            last_samps=last_samps,\n            orig_format=\"int\",\n            orig_units=orig_units,\n            verbose=verbose,\n        )\n\n        # Read annotations from file and set it\n        onset, duration, desc = _get_annotations_gdf(edf_info, self.info[\"sfreq\"])\n\n        self.set_annotations(\n            Annotations(\n                onset=onset, duration=duration, description=desc, orig_time=None\n            )\n        )\n\n    def _read_segment_file(self, data, idx, fi, start, stop, cals, mult):\n        \"\"\"Read a chunk of raw data.\"\"\"\n        return _read_segment_file(\n            data,\n            idx,\n            fi,\n            start,\n            stop,\n            self._raw_extras[fi],\n            self._filenames[fi],\n            cals,\n            mult,\n        )\n\n\ndef _read_ch(fid, subtype, samp, dtype_byte, dtype=None):\n    \"\"\"Read a number of samples for a single channel.\"\"\"\n    # BDF\n    if subtype == \"bdf\":\n        ch_data = np.fromfile(fid, dtype=dtype, count=samp * dtype_byte)\n        ch_data = ch_data.reshape(-1, 3).astype(INT32)\n        ch_data = (ch_data[:, 0]) + (ch_data[:, 1] << 8) + (ch_data[:, 2] << 16)\n        # 24th bit determines the sign\n        ch_data[ch_data >= (1 << 23)] -= 1 << 24\n\n    # GDF data and EDF data\n    else:\n        ch_data = np.fromfile(fid, dtype=dtype, count=samp)\n\n    return ch_data\n\n\ndef _read_segment_file(data, idx, fi, start, stop, raw_extras, filenames, cals, mult):\n    \"\"\"Read a chunk of raw data.\"\"\"\n    n_samps = raw_extras[\"n_samps\"]\n    buf_len = int(raw_extras[\"max_samp\"])\n    dtype = raw_extras[\"dtype_np\"]\n    dtype_byte = raw_extras[\"dtype_byte\"]\n    data_offset = raw_extras[\"data_offset\"]\n    stim_channel_idxs = raw_extras[\"stim_channel_idxs\"]\n    orig_sel = raw_extras[\"sel\"]\n    tal_idx = raw_extras.get(\"tal_idx\", np.empty(0, int))\n    subtype = raw_extras[\"subtype\"]\n    cal = raw_extras[\"cal\"]\n    offsets = raw_extras[\"offsets\"]\n    gains = raw_extras[\"units\"]\n\n    read_sel = np.concatenate([orig_sel[idx], tal_idx])\n    tal_data = []\n\n    # only try to read the stim channel if it's not None and it's\n    # actually one of the requested channels\n    idx_arr = np.arange(idx.start, idx.stop) if isinstance(idx, slice) else idx\n\n    # We could read this one EDF block at a time, which would be this:\n    ch_offsets = np.cumsum(np.concatenate([[0], n_samps]), dtype=np.int64)\n    block_start_idx, r_lims, d_lims = _blk_read_lims(start, stop, buf_len)\n    # But to speed it up, we really need to read multiple blocks at once,\n    # Otherwise we can end up with e.g. 18,181 chunks for a 20 MB file!\n    # Let's do ~10 MB chunks:\n    n_per = max(10 * 1024 * 1024 // (ch_offsets[-1] * dtype_byte), 1)\n    with open(filenames, \"rb\", buffering=0) as fid:\n        # Extract data\n        start_offset = data_offset + block_start_idx * ch_offsets[-1] * dtype_byte\n\n        # first read everything into the `ones` array. For channels with\n        # lower sampling frequency, there will be zeros left at the end of the\n        # row. Ignore TAL/annotations channel and only store `orig_sel`\n        ones = np.zeros((len(orig_sel), data.shape[-1]), dtype=data.dtype)\n        # save how many samples have already been read per channel\n        n_smp_read = [0 for _ in range(len(orig_sel))]\n\n        # read data in chunks\n        for ai in range(0, len(r_lims), n_per):\n            block_offset = ai * ch_offsets[-1] * dtype_byte\n            n_read = min(len(r_lims) - ai, n_per)\n            fid.seek(start_offset + block_offset, 0)\n            # Read and reshape to (n_chunks_read, ch0_ch1_ch2_ch3...)\n            many_chunk = _read_ch(\n                fid, subtype, ch_offsets[-1] * n_read, dtype_byte, dtype\n            ).reshape(n_read, -1)\n            r_sidx = r_lims[ai][0]\n            r_eidx = buf_len * (n_read - 1) + r_lims[ai + n_read - 1][1]\n\n            # loop over selected channels, ci=channel selection\n            for ii, ci in enumerate(read_sel):\n                # This now has size (n_chunks_read, n_samp[ci])\n                ch_data = many_chunk[:, ch_offsets[ci] : ch_offsets[ci + 1]].copy()\n\n                # annotation channel has to be treated separately\n                if ci in tal_idx:\n                    tal_data.append(ch_data)\n                    continue\n\n                orig_idx = idx_arr[ii]\n                ch_data = ch_data * cal[orig_idx]\n                ch_data += offsets[orig_idx]\n                ch_data *= gains[orig_idx]\n\n                assert ci == orig_sel[orig_idx]\n\n                if n_samps[ci] != buf_len:\n                    if orig_idx in stim_channel_idxs:\n                        # Stim channel will be interpolated\n                        old = np.linspace(0, 1, n_samps[ci] + 1, True)\n                        new = np.linspace(0, 1, buf_len, False)\n                        ch_data = np.append(ch_data, np.zeros((len(ch_data), 1)), -1)\n                        ch_data = interp1d(old, ch_data, kind=\"zero\", axis=-1)(new)\n                elif orig_idx in stim_channel_idxs:\n                    ch_data = np.bitwise_and(ch_data.astype(int), 2**17 - 1)\n\n                one_i = ch_data.ravel()[r_sidx:r_eidx]\n\n                # note how many samples have been read\n                smp_read = n_smp_read[orig_idx]\n                ones[orig_idx, smp_read : smp_read + len(one_i)] = one_i\n                n_smp_read[orig_idx] += len(one_i)\n\n        # skip if no data was requested, ie. only annotations were read\n        if sum(n_smp_read) > 0:\n            # expected number of samples, equals maximum sfreq\n            smp_exp = data.shape[-1]\n            assert max(n_smp_read) == smp_exp\n\n            # resample data after loading all chunks to prevent edge artifacts\n            resampled = False\n            for i, smp_read in enumerate(n_smp_read):\n                # nothing read, nothing to resample\n                if smp_read == 0:\n                    continue\n                # upsample if n_samples is lower than from highest sfreq\n                if smp_read != smp_exp:\n                    assert (ones[i, smp_read:] == 0).all()  # sanity check\n                    ones[i, :] = resample(\n                        ones[i, :smp_read].astype(np.float64),\n                        smp_exp,\n                        smp_read,\n                        npad=0,\n                        axis=-1,\n                    )\n                    resampled = True\n\n            # give warning if we resampled a subselection\n            if resampled and raw_extras[\"nsamples\"] != (stop - start):\n                warn(\n                    \"Loading an EDF with mixed sampling frequencies and \"\n                    \"preload=False will result in edge artifacts. \"\n                    \"It is recommended to use preload=True.\"\n                    \"See also https://github.com/mne-tools/mne-python/issues/10635\"\n                )\n\n            _mult_cal_one(data[:, :], ones, idx, cals, mult)\n\n    if len(tal_data) > 1:\n        tal_data = np.concatenate([tal.ravel() for tal in tal_data])\n        tal_data = tal_data[np.newaxis, :]\n    return tal_data\n\n\ndef _read_header(fname, exclude, infer_types, include=None):\n    \"\"\"Unify EDF, BDF and GDF _read_header call.\n\n    Parameters\n    ----------\n    fname : str\n        Path to the EDF+, BDF, or GDF file.\n    exclude : list of str | str\n        Channel names to exclude. This can help when reading data with\n        different sampling rates to avoid unnecessary resampling. A str is\n        interpreted as a regular expression.\n    infer_types : bool\n        If True, try to infer channel types from channel labels. If a channel\n        label starts with a known type (such as 'EEG') followed by a space and\n        a name (such as 'Fp1'), the channel type will be set accordingly, and\n        the channel will be renamed to the original label without the prefix.\n        For unknown prefixes, the type will be 'EEG' and the name will not be\n        modified. If False, do not infer types and assume all channels are of\n        type 'EEG'.\n    include : list of str | str\n        Channel names to be included. A str is interpreted as a regular\n        expression. 'exclude' must be empty if include is assigned.\n\n    Returns\n    -------\n    (edf_info, orig_units) : tuple\n    \"\"\"\n    ext = os.path.splitext(fname)[1][1:].lower()\n    logger.info(\"%s file detected\" % ext.upper())\n    if ext in (\"bdf\", \"edf\", \"rec\"):\n        return _read_edf_header(fname, exclude, infer_types, include)\n    elif ext == \"gdf\":\n        return _read_gdf_header(fname, exclude, include), None\n    else:\n        raise NotImplementedError(\n            f\"Only GDF, EDF, and BDF files are supported, got {ext}.\"\n        )\n\n\ndef _get_info(\n    fname, stim_channel, eog, misc, exclude, infer_types, preload, include=None\n):\n    \"\"\"Extract information from EDF+, BDF or GDF file.\"\"\"\n    eog = eog if eog is not None else []\n    misc = misc if misc is not None else []\n\n    edf_info, orig_units = _read_header(fname, exclude, infer_types, include)\n\n    # XXX: `tal_ch_names` to pass to `_check_stim_channel` should be computed\n    #      from `edf_info['ch_names']` and `edf_info['tal_idx']` but 'tal_idx'\n    #      contains stim channels that are not TAL.\n    stim_channel_idxs, _ = _check_stim_channel(stim_channel, edf_info[\"ch_names\"])\n\n    sel = edf_info[\"sel\"]  # selection of channels not excluded\n    ch_names = edf_info[\"ch_names\"]  # of length len(sel)\n    if \"ch_types\" in edf_info:\n        ch_types = edf_info[\"ch_types\"]  # of length len(sel)\n    else:\n        ch_types = [None] * len(sel)\n    if len(sel) == 0:  # only want stim channels\n        n_samps = edf_info[\"n_samps\"][[0]]\n    else:\n        n_samps = edf_info[\"n_samps\"][sel]\n    nchan = edf_info[\"nchan\"]\n    physical_ranges = edf_info[\"physical_max\"] - edf_info[\"physical_min\"]\n    cals = edf_info[\"digital_max\"] - edf_info[\"digital_min\"]\n    bad_idx = np.where((~np.isfinite(cals)) | (cals == 0))[0]\n    if len(bad_idx) > 0:\n        warn(\n            \"Scaling factor is not defined in following channels:\\n\"\n            + \", \".join(ch_names[i] for i in bad_idx)\n        )\n        cals[bad_idx] = 1\n    bad_idx = np.where(physical_ranges == 0)[0]\n    if len(bad_idx) > 0:\n        warn(\n            \"Physical range is not defined in following channels:\\n\"\n            + \", \".join(ch_names[i] for i in bad_idx)\n        )\n        physical_ranges[bad_idx] = 1\n\n    # Creates a list of dicts of eeg channels for raw.info\n    logger.info(\"Setting channel info structure...\")\n    chs = list()\n    pick_mask = np.ones(len(ch_names))\n\n    chs_without_types = list()\n\n    for idx, ch_name in enumerate(ch_names):\n        chan_info = {}\n        chan_info[\"cal\"] = 1.0\n        chan_info[\"logno\"] = idx + 1\n        chan_info[\"scanno\"] = idx + 1\n        chan_info[\"range\"] = 1.0\n        chan_info[\"unit_mul\"] = FIFF.FIFF_UNITM_NONE\n        chan_info[\"ch_name\"] = ch_name\n        chan_info[\"unit\"] = FIFF.FIFF_UNIT_V\n        chan_info[\"coord_frame\"] = FIFF.FIFFV_COORD_HEAD\n        chan_info[\"coil_type\"] = FIFF.FIFFV_COIL_EEG\n        chan_info[\"kind\"] = FIFF.FIFFV_EEG_CH\n        # montage can't be stored in EDF so channel locs are unknown:\n        chan_info[\"loc\"] = np.full(12, np.nan)\n\n        # if the edf info contained channel type information\n        # set it now\n        ch_type = ch_types[idx]\n        if ch_type is not None and ch_type in CH_TYPE_MAPPING:\n            chan_info[\"kind\"] = CH_TYPE_MAPPING.get(ch_type)\n            if ch_type not in [\"EEG\", \"ECOG\", \"SEEG\", \"DBS\"]:\n                chan_info[\"coil_type\"] = FIFF.FIFFV_COIL_NONE\n            pick_mask[idx] = False\n        # if user passes in explicit mapping for eog, misc and stim\n        # channels set them here\n        if ch_name in eog or idx in eog or idx - nchan in eog:\n            chan_info[\"coil_type\"] = FIFF.FIFFV_COIL_NONE\n            chan_info[\"kind\"] = FIFF.FIFFV_EOG_CH\n            pick_mask[idx] = False\n        elif ch_name in misc or idx in misc or idx - nchan in misc:\n            chan_info[\"coil_type\"] = FIFF.FIFFV_COIL_NONE\n            chan_info[\"kind\"] = FIFF.FIFFV_MISC_CH\n            pick_mask[idx] = False\n        elif idx in stim_channel_idxs:\n            chan_info[\"coil_type\"] = FIFF.FIFFV_COIL_NONE\n            chan_info[\"unit\"] = FIFF.FIFF_UNIT_NONE\n            chan_info[\"kind\"] = FIFF.FIFFV_STIM_CH\n            pick_mask[idx] = False\n            chan_info[\"ch_name\"] = ch_name\n            ch_names[idx] = chan_info[\"ch_name\"]\n            edf_info[\"units\"][idx] = 1\n        elif ch_type not in CH_TYPE_MAPPING:\n            chs_without_types.append(ch_name)\n        chs.append(chan_info)\n\n    # warn if channel type was not inferable\n    if len(chs_without_types):\n        msg = (\n            \"Could not determine channel type of the following channels, \"\n            f'they will be set as EEG:\\n{\", \".join(chs_without_types)}'\n        )\n        logger.info(msg)\n\n    edf_info[\"stim_channel_idxs\"] = stim_channel_idxs\n    if any(pick_mask):\n        picks = [item for item, mask in zip(range(nchan), pick_mask) if mask]\n        edf_info[\"max_samp\"] = max_samp = n_samps[picks].max()\n    else:\n        edf_info[\"max_samp\"] = max_samp = n_samps.max()\n\n    # Info structure\n    # -------------------------------------------------------------------------\n\n    not_stim_ch = [x for x in range(n_samps.shape[0]) if x not in stim_channel_idxs]\n    if len(not_stim_ch) == 0:  # only loading stim channels\n        not_stim_ch = list(range(len(n_samps)))\n    sfreq = (\n        np.take(n_samps, not_stim_ch).max()\n        * edf_info[\"record_length\"][1]\n        / edf_info[\"record_length\"][0]\n    )\n    del n_samps\n    info = _empty_info(sfreq)\n    info[\"meas_date\"] = edf_info[\"meas_date\"]\n    info[\"chs\"] = chs\n    info[\"ch_names\"] = ch_names\n\n    # Subject information\n    info[\"subject_info\"] = {}\n\n    # String subject identifier\n    if edf_info[\"subject_info\"].get(\"id\") is not None:\n        info[\"subject_info\"][\"his_id\"] = edf_info[\"subject_info\"][\"id\"]\n    # Subject sex (0=unknown, 1=male, 2=female)\n    if edf_info[\"subject_info\"].get(\"sex\") is not None:\n        if edf_info[\"subject_info\"][\"sex\"] == \"M\":\n            info[\"subject_info\"][\"sex\"] = 1\n        elif edf_info[\"subject_info\"][\"sex\"] == \"F\":\n            info[\"subject_info\"][\"sex\"] = 2\n        else:\n            info[\"subject_info\"][\"sex\"] = 0\n    # Subject names (first, middle, last).\n    if edf_info[\"subject_info\"].get(\"name\") is not None:\n        sub_names = edf_info[\"subject_info\"][\"name\"].split(\"_\")\n        if len(sub_names) < 2 or len(sub_names) > 3:\n            info[\"subject_info\"][\"last_name\"] = edf_info[\"subject_info\"][\"name\"]\n        elif len(sub_names) == 2:\n            info[\"subject_info\"][\"first_name\"] = sub_names[0]\n            info[\"subject_info\"][\"last_name\"] = sub_names[1]\n        else:\n            info[\"subject_info\"][\"first_name\"] = sub_names[0]\n            info[\"subject_info\"][\"middle_name\"] = sub_names[1]\n            info[\"subject_info\"][\"last_name\"] = sub_names[2]\n    # Birthday in (year, month, day) format.\n    if isinstance(edf_info[\"subject_info\"].get(\"birthday\"), datetime):\n        info[\"subject_info\"][\"birthday\"] = (\n            edf_info[\"subject_info\"][\"birthday\"].year,\n            edf_info[\"subject_info\"][\"birthday\"].month,\n            edf_info[\"subject_info\"][\"birthday\"].day,\n        )\n    # Handedness (1=right, 2=left, 3=ambidextrous).\n    if edf_info[\"subject_info\"].get(\"hand\") is not None:\n        info[\"subject_info\"][\"hand\"] = int(edf_info[\"subject_info\"][\"hand\"])\n    # Height in meters.\n    if edf_info[\"subject_info\"].get(\"height\") is not None:\n        info[\"subject_info\"][\"height\"] = float(edf_info[\"subject_info\"][\"height\"])\n    # Weight in kilograms.\n    if edf_info[\"subject_info\"].get(\"weight\") is not None:\n        info[\"subject_info\"][\"weight\"] = float(edf_info[\"subject_info\"][\"weight\"])\n\n    # Filter settings\n    highpass = edf_info[\"highpass\"]\n    lowpass = edf_info[\"lowpass\"]\n    if highpass.size == 0:\n        pass\n    elif all(highpass):\n        if highpass[0] == \"NaN\":\n            # Placeholder for future use. Highpass set in _empty_info.\n            pass\n        elif highpass[0] == \"DC\":\n            info[\"highpass\"] = 0.0\n        else:\n            hp = highpass[0]\n            try:\n                hp = float(hp)\n            except Exception:\n                hp = 0.0\n            info[\"highpass\"] = hp\n    else:\n        info[\"highpass\"] = float(np.max(highpass))\n        warn(\n            \"Channels contain different highpass filters. Highest filter \"\n            \"setting will be stored.\"\n        )\n    if np.isnan(info[\"highpass\"]):\n        info[\"highpass\"] = 0.0\n    if lowpass.size == 0:\n        # Placeholder for future use. Lowpass set in _empty_info.\n        pass\n    elif all(lowpass):\n        if lowpass[0] in (\"NaN\", \"0\", \"0.0\"):\n            # Placeholder for future use. Lowpass set in _empty_info.\n            pass\n        else:\n            info[\"lowpass\"] = float(lowpass[0])\n    else:\n        info[\"lowpass\"] = float(np.min(lowpass))\n        warn(\n            \"Channels contain different lowpass filters. Lowest filter \"\n            \"setting will be stored.\"\n        )\n    if np.isnan(info[\"lowpass\"]):\n        info[\"lowpass\"] = info[\"sfreq\"] / 2.0\n\n    if info[\"highpass\"] > info[\"lowpass\"]:\n        warn(\n            f'Highpass cutoff frequency {info[\"highpass\"]} is greater '\n            f'than lowpass cutoff frequency {info[\"lowpass\"]}, '\n            \"setting values to 0 and Nyquist.\"\n        )\n        info[\"highpass\"] = 0.0\n        info[\"lowpass\"] = info[\"sfreq\"] / 2.0\n\n    # Some keys to be consistent with FIF measurement info\n    info[\"description\"] = None\n    edf_info[\"nsamples\"] = int(edf_info[\"n_records\"] * max_samp)\n\n    info._unlocked = False\n    info._update_redundant()\n\n    # Later used for reading\n    edf_info[\"cal\"] = physical_ranges / cals\n\n    # physical dimension in \u00b5V\n    edf_info[\"offsets\"] = (\n        edf_info[\"physical_min\"] - edf_info[\"digital_min\"] * edf_info[\"cal\"]\n    )\n    del edf_info[\"physical_min\"]\n    del edf_info[\"digital_min\"]\n\n    if edf_info[\"subtype\"] == \"bdf\":\n        edf_info[\"cal\"][stim_channel_idxs] = 1\n        edf_info[\"offsets\"][stim_channel_idxs] = 0\n        edf_info[\"units\"][stim_channel_idxs] = 1\n\n    return info, edf_info, orig_units\n\n\ndef _parse_prefilter_string(prefiltering):\n    \"\"\"Parse prefilter string from EDF+ and BDF headers.\"\"\"\n    highpass = np.array(\n        [\n            v\n            for hp in [\n                re.findall(r\"HP:\\s*([0-9]+[.]*[0-9]*)\", filt) for filt in prefiltering\n            ]\n            for v in hp\n        ]\n    )\n    lowpass = np.array(\n        [\n            v\n            for hp in [\n                re.findall(r\"LP:\\s*([0-9]+[.]*[0-9]*)\", filt) for filt in prefiltering\n            ]\n            for v in hp\n        ]\n    )\n    return highpass, lowpass\n\n\ndef _edf_str(x):\n    return x.decode(\"latin-1\").split(\"\\x00\")[0]\n\n\ndef _edf_str_num(x):\n    return _edf_str(x).replace(\",\", \".\")\n\n\ndef _read_edf_header(fname, exclude, infer_types, include=None):\n    \"\"\"Read header information from EDF+ or BDF file.\"\"\"\n    edf_info = {\"events\": []}\n\n    with open(fname, \"rb\") as fid:\n        fid.read(8)  # version (unused here)\n\n        # patient ID\n        patient = {}\n        id_info = fid.read(80).decode(\"latin-1\").rstrip()\n        id_info = id_info.split(\" \")\n        if len(id_info):\n            patient[\"id\"] = id_info[0]\n            if len(id_info) >= 4:\n                try:\n                    birthdate = datetime.strptime(id_info[2], \"%d-%b-%Y\")\n                except ValueError:\n                    birthdate = \"X\"\n                patient[\"sex\"] = id_info[1]\n                patient[\"birthday\"] = birthdate\n                patient[\"name\"] = id_info[3]\n                if len(id_info) > 4:\n                    for info in id_info[4:]:\n                        if \"=\" in info:\n                            key, value = info.split(\"=\")\n                            if key in [\"weight\", \"height\"]:\n                                patient[key] = float(value)\n                            elif key in [\"hand\"]:\n                                patient[key] = int(value)\n                            else:\n                                warn(f\"Invalid patient information {key}\")\n\n        # Recording ID\n        meas_id = {}\n        rec_info = fid.read(80).decode(\"latin-1\").rstrip().split(\" \")\n        valid_startdate = False\n        if len(rec_info) == 5:\n            try:\n                startdate = datetime.strptime(rec_info[1], \"%d-%b-%Y\")\n            except ValueError:\n                startdate = \"X\"\n            else:\n                valid_startdate = True\n            meas_id[\"startdate\"] = startdate\n            meas_id[\"study_id\"] = rec_info[2]\n            meas_id[\"technician\"] = rec_info[3]\n            meas_id[\"equipment\"] = rec_info[4]\n\n        # If startdate available in recording info, use it instead of the\n        # file's meas_date since it contains all 4 digits of the year\n        if valid_startdate:\n            day = meas_id[\"startdate\"].day\n            month = meas_id[\"startdate\"].month\n            year = meas_id[\"startdate\"].year\n            fid.read(8)  # skip file's meas_date\n        else:\n            meas_date = fid.read(8).decode(\"latin-1\")\n            day, month, year = [int(x) for x in meas_date.split(\".\")]\n            year = year + 2000 if year < 85 else year + 1900\n\n        meas_time = fid.read(8).decode(\"latin-1\")\n        hour, minute, sec = [int(x) for x in meas_time.split(\".\")]\n        try:\n            meas_date = datetime(\n                year, month, day, hour, minute, sec, tzinfo=timezone.utc\n            )\n        except ValueError:\n            warn(\n                f\"Invalid date encountered ({year:04d}-{month:02d}-\"\n                f\"{day:02d} {hour:02d}:{minute:02d}:{sec:02d}).\"\n            )\n            meas_date = None\n\n        header_nbytes = int(_edf_str(fid.read(8)))\n\n        # The following 44 bytes sometimes identify the file type, but this is\n        # not guaranteed. Therefore, we skip this field and use the file\n        # extension to determine the subtype (EDF or BDF, which differ in the\n        # number of bytes they use for the data records; EDF uses 2 bytes\n        # whereas BDF uses 3 bytes).\n        fid.read(44)\n        subtype = os.path.splitext(fname)[1][1:].lower()\n\n        n_records = int(_edf_str(fid.read(8)))\n        record_length = float(_edf_str(fid.read(8)))\n        record_length = np.array([record_length, 1.0])  # in seconds\n        if record_length[0] == 0:\n            record_length[0] = 1.0\n            warn(\n                \"Header information is incorrect for record length. Default \"\n                \"record length set to 1.\\nIt is possible that this file only\"\n                \" contains annotations and no signals. In that case, please \"\n                \"use mne.read_annotations() to load these annotations.\"\n            )\n\n        nchan = int(_edf_str(fid.read(4)))\n        channels = list(range(nchan))\n\n        # read in 16 byte labels and strip any extra spaces at the end\n        ch_labels = [fid.read(16).strip().decode(\"latin-1\") for _ in channels]\n\n        # get channel names and optionally channel type\n        # EDF specification contains 16 bytes that encode channel names,\n        # optionally prefixed by a string representing channel type separated\n        # by a space\n        if infer_types:\n            ch_types, ch_names = [], []\n            for ch_label in ch_labels:\n                ch_type, ch_name = \"EEG\", ch_label  # default to EEG\n                parts = ch_label.split(\" \")\n                if len(parts) > 1:\n                    if parts[0].upper() in CH_TYPE_MAPPING:\n                        ch_type = parts[0].upper()\n                        ch_name = \" \".join(parts[1:])\n                        logger.info(\n                            f\"Channel '{ch_label}' recognized as type \"\n                            f\"{ch_type} (renamed to '{ch_name}').\"\n                        )\n                ch_types.append(ch_type)\n                ch_names.append(ch_name)\n        else:\n            ch_types, ch_names = [\"EEG\"] * nchan, ch_labels\n\n        exclude = _find_exclude_idx(ch_names, exclude, include)\n        tal_idx = _find_tal_idx(ch_names)\n        exclude = np.concatenate([exclude, tal_idx])\n        sel = np.setdiff1d(np.arange(len(ch_names)), exclude)\n        for ch in channels:\n            fid.read(80)  # transducer\n        units = [fid.read(8).strip().decode(\"latin-1\") for ch in channels]\n        edf_info[\"units\"] = list()\n        for i, unit in enumerate(units):\n            if i in exclude:\n                continue\n            # allow \u03bc (greek mu), \u00b5 (micro symbol) and \u03bc (sjis mu) codepoints\n            if unit in (\"\\u03BCV\", \"\\u00B5V\", \"\\x83\\xCAV\", \"uV\"):\n                edf_info[\"units\"].append(1e-6)\n            elif unit == \"mV\":\n                edf_info[\"units\"].append(1e-3)\n            else:\n                edf_info[\"units\"].append(1)\n        edf_info[\"units\"] = np.array(edf_info[\"units\"], float)\n\n        ch_names = [ch_names[idx] for idx in sel]\n        units = [units[idx] for idx in sel]\n\n        # make sure channel names are unique\n        ch_names = _unique_channel_names(ch_names)\n        orig_units = dict(zip(ch_names, units))\n\n        physical_min = np.array([float(_edf_str_num(fid.read(8))) for ch in channels])[\n            sel\n        ]\n        physical_max = np.array([float(_edf_str_num(fid.read(8))) for ch in channels])[\n            sel\n        ]\n        digital_min = np.array([float(_edf_str_num(fid.read(8))) for ch in channels])[\n            sel\n        ]\n        digital_max = np.array([float(_edf_str_num(fid.read(8))) for ch in channels])[\n            sel\n        ]\n        prefiltering = [_edf_str(fid.read(80)).strip() for ch in channels][:-1]\n        highpass, lowpass = _parse_prefilter_string(prefiltering)\n\n        # number of samples per record\n        n_samps = np.array([int(_edf_str(fid.read(8))) for ch in channels])\n\n        # Populate edf_info\n        edf_info.update(\n            ch_names=ch_names,\n            ch_types=ch_types,\n            data_offset=header_nbytes,\n            digital_max=digital_max,\n            digital_min=digital_min,\n            highpass=highpass,\n            sel=sel,\n            lowpass=lowpass,\n            meas_date=meas_date,\n            n_records=n_records,\n            n_samps=n_samps,\n            nchan=nchan,\n            subject_info=patient,\n            physical_max=physical_max,\n            physical_min=physical_min,\n            record_length=record_length,\n            subtype=subtype,\n            tal_idx=tal_idx,\n        )\n\n        fid.read(32 * nchan).decode()  # reserved\n        assert fid.tell() == header_nbytes\n\n        fid.seek(0, 2)\n        n_bytes = fid.tell()\n        n_data_bytes = n_bytes - header_nbytes\n        total_samps = n_data_bytes // 3 if subtype == \"bdf\" else n_data_bytes // 2\n        read_records = total_samps // np.sum(n_samps)\n        if n_records != read_records:\n            warn(\n                \"Number of records from the header does not match the file \"\n                \"size (perhaps the recording was not stopped before exiting).\"\n                \" Inferring from the file size.\"\n            )\n            edf_info[\"n_records\"] = read_records\n        del n_records\n\n        if subtype == \"bdf\":\n            edf_info[\"dtype_byte\"] = 3  # 24-bit (3 byte) integers\n            edf_info[\"dtype_np\"] = UINT8\n        else:\n            edf_info[\"dtype_byte\"] = 2  # 16-bit (2 byte) integers\n            edf_info[\"dtype_np\"] = INT16\n\n    return edf_info, orig_units\n\n\nINT8 = \"<i1\"\nUINT8 = \"<u1\"\nINT16 = \"<i2\"\nUINT16 = \"<u2\"\nINT32 = \"<i4\"\nUINT32 = \"<u4\"\nINT64 = \"<i8\"\nUINT64 = \"<u8\"\nFLOAT32 = \"<f4\"\nFLOAT64 = \"<f8\"\nGDFTYPE_NP = (\n    None,\n    INT8,\n    UINT8,\n    INT16,\n    UINT16,\n    INT32,\n    UINT32,\n    INT64,\n    UINT64,\n    None,\n    None,\n    None,\n    None,\n    None,\n    None,\n    None,\n    FLOAT32,\n    FLOAT64,\n)\nGDFTYPE_BYTE = tuple(np.dtype(x).itemsize if x is not None else 0 for x in GDFTYPE_NP)\n\n\ndef _check_dtype_byte(types):\n    assert sum(GDFTYPE_BYTE) == 42\n    dtype_byte = [GDFTYPE_BYTE[t] for t in types]\n    dtype_np = [GDFTYPE_NP[t] for t in types]\n    if len(np.unique(dtype_byte)) > 1:\n        # We will not read it properly, so this should be an error\n        raise RuntimeError(\"Reading multiple data types not supported\")\n    return dtype_np[0], dtype_byte[0]\n\n\ndef _read_gdf_header(fname, exclude, include=None):\n    \"\"\"Read GDF 1.x and GDF 2.x header info.\"\"\"\n    edf_info = dict()\n    events = None\n    with open(fname, \"rb\") as fid:\n        version = fid.read(8).decode()\n        edf_info[\"type\"] = edf_info[\"subtype\"] = version[:3]\n        edf_info[\"number\"] = float(version[4:])\n        meas_date = None\n\n        # GDF 1.x\n        # ---------------------------------------------------------------------\n        if edf_info[\"number\"] < 1.9:\n            # patient ID\n            pid = fid.read(80).decode(\"latin-1\")\n            pid = pid.split(\" \", 2)\n            patient = {}\n            if len(pid) >= 2:\n                patient[\"id\"] = pid[0]\n                patient[\"name\"] = pid[1]\n\n            # Recording ID\n            meas_id = {}\n            meas_id[\"recording_id\"] = _edf_str(fid.read(80)).strip()\n\n            # date\n            tm = _edf_str(fid.read(16)).strip()\n            try:\n                if tm[14:16] == \"  \":\n                    tm = tm[:14] + \"00\" + tm[16:]\n                meas_date = datetime(\n                    int(tm[0:4]),\n                    int(tm[4:6]),\n                    int(tm[6:8]),\n                    int(tm[8:10]),\n                    int(tm[10:12]),\n                    int(tm[12:14]),\n                    int(tm[14:16]) * pow(10, 4),\n                    tzinfo=timezone.utc,\n                )\n            except Exception:\n                pass\n\n            header_nbytes = np.fromfile(fid, INT64, 1)[0]\n            meas_id[\"equipment\"] = np.fromfile(fid, UINT8, 8)[0]\n            meas_id[\"hospital\"] = np.fromfile(fid, UINT8, 8)[0]\n            meas_id[\"technician\"] = np.fromfile(fid, UINT8, 8)[0]\n            fid.seek(20, 1)  # 20bytes reserved\n\n            n_records = np.fromfile(fid, INT64, 1)[0]\n            # record length in seconds\n            record_length = np.fromfile(fid, UINT32, 2)\n            if record_length[0] == 0:\n                record_length[0] = 1.0\n                warn(\n                    \"Header information is incorrect for record length. \"\n                    \"Default record length set to 1.\"\n                )\n            nchan = int(np.fromfile(fid, UINT32, 1)[0])\n            channels = list(range(nchan))\n            ch_names = [_edf_str(fid.read(16)).strip() for ch in channels]\n            exclude = _find_exclude_idx(ch_names, exclude, include)\n            sel = np.setdiff1d(np.arange(len(ch_names)), exclude)\n            fid.seek(80 * len(channels), 1)  # transducer\n            units = [_edf_str(fid.read(8)).strip() for ch in channels]\n            edf_info[\"units\"] = list()\n            for i, unit in enumerate(units):\n                if i in exclude:\n                    continue\n                if unit[:2] == \"uV\":\n                    edf_info[\"units\"].append(1e-6)\n                else:\n                    edf_info[\"units\"].append(1)\n            edf_info[\"units\"] = np.array(edf_info[\"units\"], float)\n\n            ch_names = [ch_names[idx] for idx in sel]\n            physical_min = np.fromfile(fid, FLOAT64, len(channels))\n            physical_max = np.fromfile(fid, FLOAT64, len(channels))\n            digital_min = np.fromfile(fid, INT64, len(channels))\n            digital_max = np.fromfile(fid, INT64, len(channels))\n            prefiltering = [_edf_str(fid.read(80)) for ch in channels][:-1]\n            highpass, lowpass = _parse_prefilter_string(prefiltering)\n\n            # n samples per record\n            n_samps = np.fromfile(fid, INT32, len(channels))\n\n            # channel data type\n            dtype = np.fromfile(fid, INT32, len(channels))\n\n            # total number of bytes for data\n            bytes_tot = np.sum(\n                [GDFTYPE_BYTE[t] * n_samps[i] for i, t in enumerate(dtype)]\n            )\n\n            # Populate edf_info\n            dtype_np, dtype_byte = _check_dtype_byte(dtype)\n            edf_info.update(\n                bytes_tot=bytes_tot,\n                ch_names=ch_names,\n                data_offset=header_nbytes,\n                digital_min=digital_min,\n                digital_max=digital_max,\n                dtype_byte=dtype_byte,\n                dtype_np=dtype_np,\n                exclude=exclude,\n                highpass=highpass,\n                sel=sel,\n                lowpass=lowpass,\n                meas_date=meas_date,\n                meas_id=meas_id,\n                n_records=n_records,\n                n_samps=n_samps,\n                nchan=nchan,\n                subject_info=patient,\n                physical_max=physical_max,\n                physical_min=physical_min,\n                record_length=record_length,\n            )\n\n            fid.seek(32 * edf_info[\"nchan\"], 1)  # reserved\n            assert fid.tell() == header_nbytes\n\n            # Event table\n            # -----------------------------------------------------------------\n            etp = header_nbytes + n_records * edf_info[\"bytes_tot\"]\n            # skip data to go to event table\n            fid.seek(etp)\n            etmode = np.fromfile(fid, UINT8, 1)[0]\n            if etmode in (1, 3):\n                sr = np.fromfile(fid, UINT8, 3).astype(np.uint32)\n                event_sr = sr[0]\n                for i in range(1, len(sr)):\n                    event_sr = event_sr + sr[i] * 2 ** (i * 8)\n                n_events = np.fromfile(fid, UINT32, 1)[0]\n                pos = np.fromfile(fid, UINT32, n_events) - 1  # 1-based inds\n                typ = np.fromfile(fid, UINT16, n_events)\n\n                if etmode == 3:\n                    chn = np.fromfile(fid, UINT16, n_events)\n                    dur = np.fromfile(fid, UINT32, n_events)\n                else:\n                    chn = np.zeros(n_events, dtype=np.int32)\n                    dur = np.ones(n_events, dtype=UINT32)\n                np.maximum(dur, 1, out=dur)\n                events = [n_events, pos, typ, chn, dur]\n\n        # GDF 2.x\n        # ---------------------------------------------------------------------\n        else:\n            # FIXED HEADER\n            handedness = (\"Unknown\", \"Right\", \"Left\", \"Equal\")\n            gender = (\"Unknown\", \"Male\", \"Female\")\n            scale = (\"Unknown\", \"No\", \"Yes\", \"Corrected\")\n\n            # date\n            pid = fid.read(66).decode()\n            pid = pid.split(\" \", 2)\n            patient = {}\n            if len(pid) >= 2:\n                patient[\"id\"] = pid[0]\n                patient[\"name\"] = pid[1]\n            fid.seek(10, 1)  # 10bytes reserved\n\n            # Smoking / Alcohol abuse / drug abuse / medication\n            sadm = np.fromfile(fid, UINT8, 1)[0]\n            patient[\"smoking\"] = scale[sadm % 4]\n            patient[\"alcohol_abuse\"] = scale[(sadm >> 2) % 4]\n            patient[\"drug_abuse\"] = scale[(sadm >> 4) % 4]\n            patient[\"medication\"] = scale[(sadm >> 6) % 4]\n            patient[\"weight\"] = np.fromfile(fid, UINT8, 1)[0]\n            if patient[\"weight\"] == 0 or patient[\"weight\"] == 255:\n                patient[\"weight\"] = None\n            patient[\"height\"] = np.fromfile(fid, UINT8, 1)[0]\n            if patient[\"height\"] == 0 or patient[\"height\"] == 255:\n                patient[\"height\"] = None\n\n            # Gender / Handedness / Visual Impairment\n            ghi = np.fromfile(fid, UINT8, 1)[0]\n            patient[\"sex\"] = gender[ghi % 4]\n            patient[\"handedness\"] = handedness[(ghi >> 2) % 4]\n            patient[\"visual\"] = scale[(ghi >> 4) % 4]\n\n            # Recording identification\n            meas_id = {}\n            meas_id[\"recording_id\"] = _edf_str(fid.read(64)).strip()\n            vhsv = np.fromfile(fid, UINT8, 4)\n            loc = {}\n            if vhsv[3] == 0:\n                loc[\"vertpre\"] = 10 * int(vhsv[0] >> 4) + int(vhsv[0] % 16)\n                loc[\"horzpre\"] = 10 * int(vhsv[1] >> 4) + int(vhsv[1] % 16)\n                loc[\"size\"] = 10 * int(vhsv[2] >> 4) + int(vhsv[2] % 16)\n            else:\n                loc[\"vertpre\"] = 29\n                loc[\"horzpre\"] = 29\n                loc[\"size\"] = 29\n            loc[\"version\"] = 0\n            loc[\"latitude\"] = float(np.fromfile(fid, UINT32, 1)[0]) / 3600000\n            loc[\"longitude\"] = float(np.fromfile(fid, UINT32, 1)[0]) / 3600000\n            loc[\"altitude\"] = float(np.fromfile(fid, INT32, 1)[0]) / 100\n            meas_id[\"loc\"] = loc\n\n            meas_date = np.fromfile(fid, UINT64, 1)[0]\n            if meas_date != 0:\n                meas_date = datetime(1, 1, 1, tzinfo=timezone.utc) + timedelta(\n                    meas_date * pow(2, -32) - 367\n                )\n            else:\n                meas_date = None\n\n            birthday = np.fromfile(fid, UINT64, 1).tolist()[0]\n            if birthday == 0:\n                birthday = datetime(1, 1, 1, tzinfo=timezone.utc)\n            else:\n                birthday = datetime(1, 1, 1, tzinfo=timezone.utc) + timedelta(\n                    birthday * pow(2, -32) - 367\n                )\n            patient[\"birthday\"] = birthday\n            if patient[\"birthday\"] != datetime(1, 1, 1, 0, 0, tzinfo=timezone.utc):\n                today = datetime.now(tz=timezone.utc)\n                patient[\"age\"] = today.year - patient[\"birthday\"].year\n                today = today.replace(year=patient[\"birthday\"].year)\n                if today < patient[\"birthday\"]:\n                    patient[\"age\"] -= 1\n            else:\n                patient[\"age\"] = None\n\n            header_nbytes = np.fromfile(fid, UINT16, 1)[0] * 256\n\n            fid.seek(6, 1)  # 6 bytes reserved\n            meas_id[\"equipment\"] = np.fromfile(fid, UINT8, 8)\n            meas_id[\"ip\"] = np.fromfile(fid, UINT8, 6)\n            patient[\"headsize\"] = np.fromfile(fid, UINT16, 3)\n            patient[\"headsize\"] = np.asarray(patient[\"headsize\"], np.float32)\n            patient[\"headsize\"] = np.ma.masked_array(\n                patient[\"headsize\"], np.equal(patient[\"headsize\"], 0), None\n            ).filled()\n            ref = np.fromfile(fid, FLOAT32, 3)\n            gnd = np.fromfile(fid, FLOAT32, 3)\n            n_records = np.fromfile(fid, INT64, 1)[0]\n\n            # record length in seconds\n            record_length = np.fromfile(fid, UINT32, 2)\n            if record_length[0] == 0:\n                record_length[0] = 1.0\n                warn(\n                    \"Header information is incorrect for record length. \"\n                    \"Default record length set to 1.\"\n                )\n\n            nchan = int(np.fromfile(fid, UINT16, 1)[0])\n            fid.seek(2, 1)  # 2bytes reserved\n\n            # Channels (variable header)\n            channels = list(range(nchan))\n            ch_names = [_edf_str(fid.read(16)).strip() for ch in channels]\n            exclude = _find_exclude_idx(ch_names, exclude, include)\n            sel = np.setdiff1d(np.arange(len(ch_names)), exclude)\n\n            fid.seek(80 * len(channels), 1)  # reserved space\n            fid.seek(6 * len(channels), 1)  # phys_dim, obsolete\n\n            \"\"\"The Physical Dimensions are encoded as int16, according to:\n            - Units codes :\n            https://sourceforge.net/p/biosig/svn/HEAD/tree/trunk/biosig/doc/units.csv\n            - Decimal factors codes:\n            https://sourceforge.net/p/biosig/svn/HEAD/tree/trunk/biosig/doc/DecimalFactors.txt\n            \"\"\"  # noqa\n            units = np.fromfile(fid, UINT16, len(channels)).tolist()\n            unitcodes = np.array(units[:])\n            edf_info[\"units\"] = list()\n            for i, unit in enumerate(units):\n                if i in exclude:\n                    continue\n                if unit == 4275:  # microvolts\n                    edf_info[\"units\"].append(1e-6)\n                elif unit == 4274:  # millivolts\n                    edf_info[\"units\"].append(1e-3)\n                elif unit == 512:  # dimensionless\n                    edf_info[\"units\"].append(1)\n                elif unit == 0:\n                    edf_info[\"units\"].append(1)  # unrecognized\n                else:\n                    warn(\n                        \"Unsupported physical dimension for channel %d \"\n                        \"(assuming dimensionless). Please contact the \"\n                        \"MNE-Python developers for support.\" % i\n                    )\n                    edf_info[\"units\"].append(1)\n            edf_info[\"units\"] = np.array(edf_info[\"units\"], float)\n\n            ch_names = [ch_names[idx] for idx in sel]\n            physical_min = np.fromfile(fid, FLOAT64, len(channels))\n            physical_max = np.fromfile(fid, FLOAT64, len(channels))\n            digital_min = np.fromfile(fid, FLOAT64, len(channels))\n            digital_max = np.fromfile(fid, FLOAT64, len(channels))\n\n            fid.seek(68 * len(channels), 1)  # obsolete\n            lowpass = np.fromfile(fid, FLOAT32, len(channels))\n            highpass = np.fromfile(fid, FLOAT32, len(channels))\n            notch = np.fromfile(fid, FLOAT32, len(channels))\n\n            # number of samples per record\n            n_samps = np.fromfile(fid, INT32, len(channels))\n\n            # data type\n            dtype = np.fromfile(fid, INT32, len(channels))\n\n            channel = {}\n            channel[\"xyz\"] = [np.fromfile(fid, FLOAT32, 3)[0] for ch in channels]\n\n            if edf_info[\"number\"] < 2.19:\n                impedance = np.fromfile(fid, UINT8, len(channels)).astype(float)\n                impedance[impedance == 255] = np.nan\n                channel[\"impedance\"] = pow(2, impedance / 8)\n                fid.seek(19 * len(channels), 1)  # reserved\n            else:\n                tmp = np.fromfile(fid, FLOAT32, 5 * len(channels))\n                tmp = tmp[::5]\n                fZ = tmp[:]\n                impedance = tmp[:]\n                # channels with no voltage (code 4256) data\n                ch = [unitcodes & 65504 != 4256][0]\n                impedance[np.where(ch)] = None\n                # channel with no impedance (code 4288) data\n                ch = [unitcodes & 65504 != 4288][0]\n                fZ[np.where(ch)[0]] = None\n\n            assert fid.tell() == header_nbytes\n\n            # total number of bytes for data\n            bytes_tot = np.sum(\n                [GDFTYPE_BYTE[t] * n_samps[i] for i, t in enumerate(dtype)]\n            )\n\n            # Populate edf_info\n            dtype_np, dtype_byte = _check_dtype_byte(dtype)\n            edf_info.update(\n                bytes_tot=bytes_tot,\n                ch_names=ch_names,\n                data_offset=header_nbytes,\n                dtype_byte=dtype_byte,\n                dtype_np=dtype_np,\n                digital_min=digital_min,\n                digital_max=digital_max,\n                exclude=exclude,\n                gnd=gnd,\n                highpass=highpass,\n                sel=sel,\n                impedance=impedance,\n                lowpass=lowpass,\n                meas_date=meas_date,\n                meas_id=meas_id,\n                n_records=n_records,\n                n_samps=n_samps,\n                nchan=nchan,\n                notch=notch,\n                subject_info=patient,\n                physical_max=physical_max,\n                physical_min=physical_min,\n                record_length=record_length,\n                ref=ref,\n            )\n\n            # EVENT TABLE\n            # -----------------------------------------------------------------\n            etp = (\n                edf_info[\"data_offset\"] + edf_info[\"n_records\"] * edf_info[\"bytes_tot\"]\n            )\n            fid.seek(etp)  # skip data to go to event table\n            etmode = fid.read(1).decode()\n            if etmode != \"\":\n                etmode = np.fromstring(etmode, UINT8).tolist()[0]\n\n                if edf_info[\"number\"] < 1.94:\n                    sr = np.fromfile(fid, UINT8, 3)\n                    event_sr = sr[0]\n                    for i in range(1, len(sr)):\n                        event_sr = event_sr + sr[i] * 2 ** (i * 8)\n                    n_events = np.fromfile(fid, UINT32, 1)[0]\n                else:\n                    ne = np.fromfile(fid, UINT8, 3)\n                    n_events = ne[0]\n                    for i in range(1, len(ne)):\n                        n_events = n_events + ne[i] * 2 ** (i * 8)\n                    event_sr = np.fromfile(fid, FLOAT32, 1)[0]\n\n                pos = np.fromfile(fid, UINT32, n_events) - 1  # 1-based inds\n                typ = np.fromfile(fid, UINT16, n_events)\n\n                if etmode == 3:\n                    chn = np.fromfile(fid, UINT16, n_events)\n                    dur = np.fromfile(fid, UINT32, n_events)\n                else:\n                    chn = np.zeros(n_events, dtype=np.uint32)\n                    dur = np.ones(n_events, dtype=np.uint32)\n                np.maximum(dur, 1, out=dur)\n                events = [n_events, pos, typ, chn, dur]\n                edf_info[\"event_sfreq\"] = event_sr\n\n    edf_info.update(events=events, sel=np.arange(len(edf_info[\"ch_names\"])))\n\n    return edf_info\n\n\ndef _check_stim_channel(\n    stim_channel, ch_names, tal_ch_names=[\"EDF Annotations\", \"BDF Annotations\"]\n):\n    \"\"\"Check that the stimulus channel exists in the current datafile.\"\"\"\n    DEFAULT_STIM_CH_NAMES = [\"status\", \"trigger\"]\n\n    if stim_channel is None or stim_channel is False:\n        return [], []\n\n    if stim_channel is True:  # convenient aliases\n        stim_channel = \"auto\"\n\n    elif isinstance(stim_channel, str):\n        if stim_channel == \"auto\":\n            if \"auto\" in ch_names:\n                warn(\n                    RuntimeWarning,\n                    \"Using `stim_channel='auto'` when auto\"\n                    \" also corresponds to a channel name is ambiguous.\"\n                    \" Please use `stim_channel=['auto']`.\",\n                )\n            else:\n                valid_stim_ch_names = DEFAULT_STIM_CH_NAMES\n        else:\n            valid_stim_ch_names = [stim_channel.lower()]\n\n    elif isinstance(stim_channel, int):\n        valid_stim_ch_names = [ch_names[stim_channel].lower()]\n\n    elif isinstance(stim_channel, list):\n        if all([isinstance(s, str) for s in stim_channel]):\n            valid_stim_ch_names = [s.lower() for s in stim_channel]\n        elif all([isinstance(s, int) for s in stim_channel]):\n            valid_stim_ch_names = [ch_names[s].lower() for s in stim_channel]\n        else:\n            raise ValueError(\"Invalid stim_channel\")\n    else:\n        raise ValueError(\"Invalid stim_channel\")\n\n    # Forbid the synthesis of stim channels from TAL Annotations\n    tal_ch_names_found = [\n        ch for ch in valid_stim_ch_names if ch in [t.lower() for t in tal_ch_names]\n    ]\n    if len(tal_ch_names_found):\n        _msg = (\n            \"The synthesis of the stim channel is not supported\"\n            \" since 0.18. Please remove {} from `stim_channel`\"\n            \" and use `mne.events_from_annotations` instead\"\n        ).format(tal_ch_names_found)\n        raise ValueError(_msg)\n\n    ch_names_low = [ch.lower() for ch in ch_names]\n    found = list(set(valid_stim_ch_names) & set(ch_names_low))\n\n    if not found:\n        return [], []\n    else:\n        stim_channel_idxs = [ch_names_low.index(f) for f in found]\n        names = [ch_names[idx] for idx in stim_channel_idxs]\n        return stim_channel_idxs, names\n\n\ndef _find_exclude_idx(ch_names, exclude, include=None):\n    \"\"\"Find indices of all channels to exclude.\n\n    If there are several channels called \"A\" and we want to exclude \"A\", then\n    add (the index of) all \"A\" channels to the exclusion list.\n    \"\"\"\n    if include:  # find other than include channels\n        if exclude:\n            raise ValueError(\n                \"'exclude' must be empty if 'include' is assigned. \" f\"Got {exclude}.\"\n            )\n        if isinstance(include, str):  # regex for channel names\n            indices_include = []\n            for idx, ch in enumerate(ch_names):\n                if re.match(include, ch):\n                    indices_include.append(idx)\n            indices = np.setdiff1d(np.arange(len(ch_names)), indices_include)\n            return indices\n        # list of channel names\n        return [idx for idx, ch in enumerate(ch_names) if ch not in include]\n\n    if isinstance(exclude, str):  # regex for channel names\n        indices = []\n        for idx, ch in enumerate(ch_names):\n            if re.match(exclude, ch):\n                indices.append(idx)\n        return indices\n    # list of channel names\n    return [idx for idx, ch in enumerate(ch_names) if ch in exclude]\n\n\ndef _find_tal_idx(ch_names):\n    # Annotations / TAL Channels\n    accepted_tal_ch_names = [\"EDF Annotations\", \"BDF Annotations\"]\n    tal_channel_idx = np.where(np.isin(ch_names, accepted_tal_ch_names))[0]\n    return tal_channel_idx\n\n\n@fill_doc\ndef read_raw_edf(\n    input_fname,\n    eog=None,\n    misc=None,\n    stim_channel=\"auto\",\n    exclude=(),\n    infer_types=False,\n    include=None,\n    preload=False,\n    units=None,\n    encoding=\"utf8\",\n    *,\n    verbose=None,\n):\n    \"\"\"Reader function for EDF and EDF+ files.\n\n    Parameters\n    ----------\n    input_fname : path-like\n        Path to the EDF or EDF+ file.\n    eog : list or tuple\n        Names of channels or list of indices that should be designated EOG\n        channels. Values should correspond to the electrodes in the file.\n        Default is None.\n    misc : list or tuple\n        Names of channels or list of indices that should be designated MISC\n        channels. Values should correspond to the electrodes in the file.\n        Default is None.\n    stim_channel : ``'auto'`` | str | list of str | int | list of int\n        Defaults to ``'auto'``, which means that channels named ``'status'`` or\n        ``'trigger'`` (case insensitive) are set to STIM. If str (or list of\n        str), all channels matching the name(s) are set to STIM. If int (or\n        list of ints), channels corresponding to the indices are set to STIM.\n    exclude : list of str | str\n        Channel names to exclude. This can help when reading data with\n        different sampling rates to avoid unnecessary resampling. A str is\n        interpreted as a regular expression.\n    infer_types : bool\n        If True, try to infer channel types from channel labels. If a channel\n        label starts with a known type (such as 'EEG') followed by a space and\n        a name (such as 'Fp1'), the channel type will be set accordingly, and\n        the channel will be renamed to the original label without the prefix.\n        For unknown prefixes, the type will be 'EEG' and the name will not be\n        modified. If False, do not infer types and assume all channels are of\n        type 'EEG'.\n\n        .. versionadded:: 0.24.1\n    include : list of str | str\n        Channel names to be included. A str is interpreted as a regular\n        expression. 'exclude' must be empty if include is assigned.\n\n        .. versionadded:: 1.1\n    %(preload)s\n    %(units_edf_bdf_io)s\n    %(encoding_edf)s\n    %(verbose)s\n\n    Returns\n    -------\n    raw : instance of RawEDF\n        The raw instance.\n        See :class:`mne.io.Raw` for documentation of attributes and methods.\n\n    See Also\n    --------\n    mne.io.read_raw_bdf : Reader function for BDF files.\n    mne.io.read_raw_gdf : Reader function for GDF files.\n    mne.export.export_raw : Export function for EDF files.\n    mne.io.Raw : Documentation of attributes and methods of RawEDF.\n\n    Notes\n    -----\n    %(edf_resamp_note)s\n\n    It is worth noting that in some special cases, it may be necessary to shift\n    event values in order to retrieve correct event triggers. This depends on\n    the triggering device used to perform the synchronization. For instance, in\n    some files events need to be shifted by 8 bits:\n\n        >>> events[:, 2] >>= 8  # doctest:+SKIP\n\n    TAL channels called 'EDF Annotations' are parsed and extracted annotations\n    are stored in raw.annotations. Use :func:`mne.events_from_annotations` to\n    obtain events from these annotations.\n\n    If channels named 'status' or 'trigger' are present, they are considered as\n    STIM channels by default. Use func:`mne.find_events` to parse events\n    encoded in such analog stim channels.\n\n    The EDF specification allows optional storage of channel types in the\n    prefix of the signal label for each channel. For example, ``EEG Fz``\n    implies that ``Fz`` is an EEG channel and ``MISC E`` would imply ``E`` is\n    a MISC channel. However, there is no standard way of specifying all\n    channel types. MNE-Python will try to infer the channel type, when such a\n    string exists, defaulting to EEG, when there is no prefix or the prefix is\n    not recognized.\n\n    The following prefix strings are mapped to MNE internal types:\n\n        - 'EEG': 'eeg'\n        - 'SEEG': 'seeg'\n        - 'ECOG': 'ecog'\n        - 'DBS': 'dbs'\n        - 'EOG': 'eog'\n        - 'ECG': 'ecg'\n        - 'EMG': 'emg'\n        - 'BIO': 'bio'\n        - 'RESP': 'resp'\n        - 'MISC': 'misc'\n        - 'SAO2': 'bio'\n\n    The EDF specification allows storage of subseconds in measurement date.\n    However, this reader currently sets subseconds to 0 by default.\n    \"\"\"\n    input_fname = os.path.abspath(input_fname)\n    ext = os.path.splitext(input_fname)[1][1:].lower()\n    # if ext != \"edf\":\n    #     raise NotImplementedError(f\"Only EDF files are supported, got {ext}.\")\n    return RawEDF(\n        input_fname=input_fname,\n        eog=eog,\n        misc=misc,\n        stim_channel=stim_channel,\n        exclude=exclude,\n        infer_types=infer_types,\n        preload=preload,\n        include=include,\n        units=units,\n        encoding=encoding,\n        verbose=verbose,\n    )\n\n\n@fill_doc\ndef read_raw_bdf(\n    input_fname,\n    eog=None,\n    misc=None,\n    stim_channel=\"auto\",\n    exclude=(),\n    infer_types=False,\n    include=None,\n    preload=False,\n    units=None,\n    encoding=\"utf8\",\n    *,\n    verbose=None,\n):\n    \"\"\"Reader function for BDF files.\n\n    Parameters\n    ----------\n    input_fname : path-like\n        Path to the BDF file.\n    eog : list or tuple\n        Names of channels or list of indices that should be designated EOG\n        channels. Values should correspond to the electrodes in the file.\n        Default is None.\n    misc : list or tuple\n        Names of channels or list of indices that should be designated MISC\n        channels. Values should correspond to the electrodes in the file.\n        Default is None.\n    stim_channel : ``'auto'`` | str | list of str | int | list of int\n        Defaults to ``'auto'``, which means that channels named ``'status'`` or\n        ``'trigger'`` (case insensitive) are set to STIM. If str (or list of\n        str), all channels matching the name(s) are set to STIM. If int (or\n        list of ints), channels corresponding to the indices are set to STIM.\n    exclude : list of str | str\n        Channel names to exclude. This can help when reading data with\n        different sampling rates to avoid unnecessary resampling. A str is\n        interpreted as a regular expression.\n    infer_types : bool\n        If True, try to infer channel types from channel labels. If a channel\n        label starts with a known type (such as 'EEG') followed by a space and\n        a name (such as 'Fp1'), the channel type will be set accordingly, and\n        the channel will be renamed to the original label without the prefix.\n        For unknown prefixes, the type will be 'EEG' and the name will not be\n        modified. If False, do not infer types and assume all channels are of\n        type 'EEG'.\n\n        .. versionadded:: 0.24.1\n    include : list of str | str\n        Channel names to be included. A str is interpreted as a regular\n        expression. 'exclude' must be empty if include is assigned.\n\n        .. versionadded:: 1.1\n    %(preload)s\n    %(units_edf_bdf_io)s\n    %(encoding_edf)s\n    %(verbose)s\n\n    Returns\n    -------\n    raw : instance of RawEDF\n        The raw instance.\n        See :class:`mne.io.Raw` for documentation of attributes and methods.\n\n    See Also\n    --------\n    mne.io.read_raw_edf : Reader function for EDF and EDF+ files.\n    mne.io.read_raw_gdf : Reader function for GDF files.\n    mne.io.Raw : Documentation of attributes and methods of RawEDF.\n\n    Notes\n    -----\n    :class:`mne.io.Raw` only stores signals with matching sampling frequencies.\n    Therefore, if mixed sampling frequency signals are requested, all signals\n    are upsampled to the highest loaded sampling frequency. In this case, using\n    preload=True is recommended, as otherwise, edge artifacts appear when\n    slices of the signal are requested.\n\n    Biosemi devices trigger codes are encoded in 16-bit format, whereas system\n    codes (CMS in/out-of range, battery low, etc.) are coded in bits 16-23 of\n    the status channel (see http://www.biosemi.com/faq/trigger_signals.htm).\n    To retrieve correct event values (bits 1-16), one could do:\n\n        >>> events = mne.find_events(...)  # doctest:+SKIP\n        >>> events[:, 2] &= (2**16 - 1)  # doctest:+SKIP\n\n    The above operation can be carried out directly in :func:`mne.find_events`\n    using the ``mask`` and ``mask_type`` parameters (see\n    :func:`mne.find_events` for more details).\n\n    It is also possible to retrieve system codes, but no particular effort has\n    been made to decode these in MNE. In case it is necessary, for instance to\n    check the CMS bit, the following operation can be carried out:\n\n        >>> cms_bit = 20  # doctest:+SKIP\n        >>> cms_high = (events[:, 2] & (1 << cms_bit)) != 0  # doctest:+SKIP\n\n    It is worth noting that in some special cases, it may be necessary to shift\n    event values in order to retrieve correct event triggers. This depends on\n    the triggering device used to perform the synchronization. For instance, in\n    some files events need to be shifted by 8 bits:\n\n        >>> events[:, 2] >>= 8  # doctest:+SKIP\n\n    TAL channels called 'BDF Annotations' are parsed and extracted annotations\n    are stored in raw.annotations. Use :func:`mne.events_from_annotations` to\n    obtain events from these annotations.\n\n    If channels named 'status' or 'trigger' are present, they are considered as\n    STIM channels by default. Use func:`mne.find_events` to parse events\n    encoded in such analog stim channels.\n    \"\"\"\n    input_fname = os.path.abspath(input_fname)\n    ext = os.path.splitext(input_fname)[1][1:].lower()\n    if ext != \"bdf\":\n        raise NotImplementedError(f\"Only BDF files are supported, got {ext}.\")\n    return RawEDF(\n        input_fname=input_fname,\n        eog=eog,\n        misc=misc,\n        stim_channel=stim_channel,\n        exclude=exclude,\n        infer_types=infer_types,\n        preload=preload,\n        include=include,\n        units=units,\n        encoding=encoding,\n        verbose=verbose,\n    )\n\n\n@fill_doc\ndef read_raw_gdf(\n    input_fname,\n    eog=None,\n    misc=None,\n    stim_channel=\"auto\",\n    exclude=(),\n    include=None,\n    preload=False,\n    verbose=None,\n):\n    \"\"\"Reader function for GDF files.\n\n    Parameters\n    ----------\n    input_fname : path-like\n        Path to the GDF file.\n    eog : list or tuple\n        Names of channels or list of indices that should be designated EOG\n        channels. Values should correspond to the electrodes in the file.\n        Default is None.\n    misc : list or tuple\n        Names of channels or list of indices that should be designated MISC\n        channels. Values should correspond to the electrodes in the file.\n        Default is None.\n    stim_channel : ``'auto'`` | str | list of str | int | list of int\n        Defaults to ``'auto'``, which means that channels named ``'status'`` or\n        ``'trigger'`` (case insensitive) are set to STIM. If str (or list of\n        str), all channels matching the name(s) are set to STIM. If int (or\n        list of ints), channels corresponding to the indices are set to STIM.\n    exclude : list of str | str\n        Channel names to exclude. This can help when reading data with\n        different sampling rates to avoid unnecessary resampling. A str is\n        interpreted as a regular expression.\n    include : list of str | str\n        Channel names to be included. A str is interpreted as a regular\n        expression. 'exclude' must be empty if include is assigned.\n    %(preload)s\n    %(verbose)s\n\n    Returns\n    -------\n    raw : instance of RawGDF\n        The raw instance.\n        See :class:`mne.io.Raw` for documentation of attributes and methods.\n\n    See Also\n    --------\n    mne.io.read_raw_edf : Reader function for EDF and EDF+ files.\n    mne.io.read_raw_bdf : Reader function for BDF files.\n    mne.io.Raw : Documentation of attributes and methods of RawGDF.\n\n    Notes\n    -----\n    If channels named 'status' or 'trigger' are present, they are considered as\n    STIM channels by default. Use func:`mne.find_events` to parse events\n    encoded in such analog stim channels.\n    \"\"\"\n    input_fname = os.path.abspath(input_fname)\n    ext = os.path.splitext(input_fname)[1][1:].lower()\n    if ext != \"gdf\":\n        raise NotImplementedError(f\"Only GDF files are supported, got {ext}.\")\n    return RawGDF(\n        input_fname=input_fname,\n        eog=eog,\n        misc=misc,\n        stim_channel=stim_channel,\n        exclude=exclude,\n        preload=preload,\n        include=include,\n        verbose=verbose,\n    )\n\n\n@fill_doc\ndef _read_annotations_edf(annotations, ch_names=None, encoding=\"utf8\"):\n    \"\"\"Annotation File Reader.\n\n    Parameters\n    ----------\n    annotations : ndarray (n_chans, n_samples) | str\n        Channel data in EDF+ TAL format or path to annotation file.\n    ch_names : list of string\n        List of channels' names.\n    %(encoding_edf)s\n\n    Returns\n    -------\n    annot : instance of Annotations\n        The annotations.\n    \"\"\"\n    pat = \"([+-]\\\\d+\\\\.?\\\\d*)(\\x15(\\\\d+\\\\.?\\\\d*))?(\\x14.*?)\\x14\\x00\"\n    if isinstance(annotations, str):\n        with open(annotations, \"rb\") as annot_file:\n            triggers = re.findall(pat.encode(), annot_file.read())\n            triggers = [tuple(map(lambda x: x.decode(encoding), t)) for t in triggers]\n    else:\n        tals = bytearray()\n        annotations = np.atleast_2d(annotations)\n        for chan in annotations:\n            this_chan = chan.ravel()\n            if this_chan.dtype == INT32:  # BDF\n                this_chan = this_chan.view(dtype=UINT8)\n                this_chan = this_chan.reshape(-1, 4)\n                # Why only keep the first 3 bytes as BDF values\n                # are stored with 24 bits (not 32)\n                this_chan = this_chan[:, :3].ravel()\n                # As ravel() returns a 1D array we can add all values at once\n                tals.extend(this_chan)\n            else:\n                this_chan = chan.astype(np.int64)\n                # Exploit np vectorized processing\n                tals.extend(np.uint8([this_chan % 256, this_chan // 256]).flatten(\"F\"))\n        try:\n            triggers = re.findall(pat, tals.decode(encoding))\n        except UnicodeDecodeError as e:\n            raise Exception(\n                \"Encountered invalid byte in at least one annotations channel.\"\n                \" You might want to try setting \\\"encoding='latin1'\\\".\"\n            ) from e\n\n    events = {}\n    offset = 0.0\n    for k, ev in enumerate(triggers):\n        onset = float(ev[0]) + offset\n        duration = float(ev[2]) if ev[2] else 0\n        for description in ev[3].split(\"\\x14\")[1:]:\n            if description:\n                if (\n                    \"@@\" in description\n                    and ch_names is not None\n                    and description.split(\"@@\")[1] in ch_names\n                ):\n                    description, ch_name = description.split(\"@@\")\n                    key = f\"{onset}_{duration}_{description}\"\n                else:\n                    ch_name = None\n                    key = f\"{onset}_{duration}_{description}\"\n                    if key in events:\n                        key += f\"_{k}\"  # make key unique\n                if key in events and ch_name:\n                    events[key][3] += (ch_name,)\n                else:\n                    events[key] = [\n                        onset,\n                        duration,\n                        description,\n                        (ch_name,) if ch_name else (),\n                    ]\n\n            elif k == 0:\n                # The startdate/time of a file is specified in the EDF+ header\n                # fields 'startdate of recording' and 'starttime of recording'.\n                # These fields must indicate the absolute second in which the\n                # start of the first data record falls. So, the first TAL in\n                # the first data record always starts with +0.X, indicating\n                # that the first data record starts a fraction, X, of a second\n                # after the startdate/time that is specified in the EDF+\n                # header. If X=0, then the .X may be omitted.\n                offset = -onset\n\n    if events:\n        onset, duration, description, annot_ch_names = zip(*events.values())\n    else:\n        onset, duration, description, annot_ch_names = list(), list(), list(), list()\n\n    assert len(onset) == len(duration) == len(description) == len(annot_ch_names)\n\n    return Annotations(\n        onset=onset,\n        duration=duration,\n        description=description,\n        orig_time=None,\n        ch_names=annot_ch_names,\n    )\n\n\ndef _get_annotations_gdf(edf_info, sfreq):\n    onset, duration, desc = list(), list(), list()\n    events = edf_info.get(\"events\", None)\n    # Annotations in GDF: events are stored as the following\n    # list: `events = [n_events, pos, typ, chn, dur]` where pos is the\n    # latency, dur is the duration in samples. They both are\n    # numpy.ndarray\n    if events is not None and events[1].shape[0] > 0:\n        onset = events[1] / sfreq\n        duration = events[4] / sfreq\n        desc = events[2]\n\n    return onset, duration, desc\n"}
{"doc_id": "preprocessing/ISRUC/prepare_ISRUC_1.py", "text": "# %%\nfrom mne.io import concatenate_raws\nfrom edf_ import read_raw_edf\nimport matplotlib.pyplot as plt\nimport mne\nimport os\nimport numpy as np\nfrom tqdm import tqdm\nimport xml.etree.ElementTree as ET\nfrom sklearn.preprocessing import StandardScaler\n\n\ndir_path = r'/data/datasets2/ISRUC_extracted/group1'\n\nseq_dir = r'/data/datasets/BigDownstream/ISRUC/precessed_filter_35/seq'\nlabel_dir = r'/data/datasets/BigDownstream/ISRUC/precessed_filter_35/labels'\n\npsg_f_names = []\nlabel_f_names = []\nfor i in range(1, 101):\n    numstr = str(i)\n    psg_f_names.append(f'{dir_path}/{numstr}/{numstr}.rec')\n    label_f_names.append(f'{dir_path}/{numstr}/{numstr}_1.txt')\n\n# psg_f_names.sort()\n# label_f_names.sort()\n\npsg_label_f_pairs = []\nfor psg_f_name, label_f_name in zip(psg_f_names, label_f_names):\n    if psg_f_name[:-4] == label_f_name[:-6]:\n        psg_label_f_pairs.append((psg_f_name, label_f_name))\nfor item in psg_label_f_pairs:\n    print(item)\n\nlabel2id = {'0': 0,\n            '1': 1,\n            '2': 2,\n            '3': 3,\n            '5': 4,}\nprint(label2id)\n# %%\n# signal_name = ['LOC-A2', 'F4-A1']\nn = 0\nnum_seqs = 0\nnum_labels = 0\nfor psg_f_name, label_f_name in tqdm(psg_label_f_pairs):\n    n += 1\n    labels_list = []\n\n    raw = read_raw_edf(os.path.join(dir_path, psg_f_name), preload=True)\n    # raw.pick_channels(signal_name)\n    # raw.resample(sfreq=200)\n    raw.filter(0.3, 35, fir_design='firwin')\n    raw.notch_filter((50))\n    print(raw.info)\n\n    psg_array = raw.to_data_frame().values\n    # print(psg_array[:10, 0])\n    print(psg_array.shape)\n    psg_array = psg_array[:, 1:]\n    psg_array = psg_array[:, 2:8]\n    print(psg_array.shape)\n\n    # std = StandardScaler()\n    # psg_array = std.fit_transform(psg_array)\n    # print(psg_array[:10, :])\n\n    i = psg_array.shape[0] % (30 * 200)\n    if i > 0:\n        psg_array = psg_array[:-i, :]\n    print(psg_array.shape)\n    psg_array = psg_array.reshape(-1, 30 * 200, 6)\n    print(psg_array.shape)\n\n    a = psg_array.shape[0] % 20\n    if a > 0:\n        psg_array = psg_array[:-a, :, :]\n    print(psg_array.shape)\n    psg_array = psg_array.reshape(-1, 20, 30 * 200, 6)\n    epochs_seq = psg_array.transpose(0, 1, 3, 2)\n    print(epochs_seq.shape)\n    # print(epochs_seq[0, 0, :, 100])\n\n    for line in open(os.path.join(dir_path, label_f_name)).readlines():\n        line_str = line.strip()\n        if line_str != '':\n            labels_list.append(label2id[line_str])\n    labels_array = np.array(labels_list)\n    if a > 0:\n        labels_array = labels_array[:-a]\n    labels_seq = labels_array.reshape(-1, 20)\n    print(labels_seq.shape)\n\n    if not os.path.isdir(rf'{seq_dir}/ISRUC-group1-{str(n)}'):\n        os.makedirs(rf'{seq_dir}/ISRUC-group1-{str(n)}')\n    for seq in epochs_seq:\n        seq_name = rf'{seq_dir}/ISRUC-group1-{str(n)}/ISRUC-group1-{str(n)}-{str(num_seqs)}.npy'\n        with open(seq_name, 'wb') as f:\n            np.save(f, seq)\n        num_seqs += 1\n\n    if not os.path.isdir(rf'{label_dir}/ISRUC-group1-{str(n)}'):\n        os.makedirs(rf'{label_dir}/ISRUC-group1-{str(n)}')\n    for label in labels_seq:\n        label_name = rf'{label_dir}/ISRUC-group1-{str(n)}/ISRUC-group1-{str(n)}-{str(num_labels)}.npy'\n        with open(label_name, 'wb') as f:\n            np.save(f, label)\n        num_labels += 1\n\n\n\n"}
{"doc_id": "preprocessing/ISRUC/__init__.py", "text": ""}
{"doc_id": "utils/signaltools.py", "text": "\"\"\"\nsignaltools.py (Only a few functions) of Scipy's Signal processing package, implimented for PyTorch\nCurrently implimeted: resample\n\n\"\"\"\n\nimport sys\nimport torch\nimport torch.fft\n\n__author__ = \"Soumick Chatterjee\"\n__copyright__ = \"Copyright 2020, Soumick Chatterjee & OvGU:ESF:MEMoRIAL\"\n__credits__ = [\"Soumick Chatterjee\"]\n\n__license__ = \"GPL\"\n__version__ = \"0.0.1\"\n__email__ = \"soumick.chatterjee@ovgu.de\"\n__status__ = \"Only x, num and axis of the resample function have been tested\"\n\n\ndef _isrealobj(x):\n    d = x.dtype\n    if d in (torch.complex32, torch.complex64, torch.complex128):\n        return False\n    else:\n        return True\n\n\ndef resample(x, num, t=None, axis=0, window=None, domain='time'):\n    \"\"\"\n    Resample `x` to `num` samples using Fourier method along the given axis.\n\n    The resampled signal starts at the same value as `x` but is sampled\n    with a spacing of ``len(x) / num * (spacing of x)``.  Because a\n    Fourier method is used, the signal is assumed to be periodic.\n\n    Parameters\n    ----------\n    x : array_like\n        The data to be resampled.\n    num : int or array_like\n        The number of samples in the resampled signal.\n        If array_like is supplied, then the resample function will be\n        called recursively for each element of num.\n    t : array_like, optional\n        If `t` is given, it is assumed to be the equally spaced sample\n        positions associated with the signal data in `x`.\n    axis : (int, optional) or (array_like)\n        The axis of `x` that is resampled.  Default is 0.\n        If num is array_like, then axis has to be supplied and has to be array_like.\n        Each element of axis should have one-on-on mapping wtih num.\n        If num is int but axis is array_like, then num will be repeated and will be\n        made a list with same number of elements as axis. Then will proceed both as array_like.\n    window : array_like, callable, string, float, or tuple, optional\n        Specifies the window applied to the signal in the Fourier\n        domain.  See below for details.\n    domain : string, optional\n        A string indicating the domain of the input `x`:\n        ``time`` Consider the input `x` as time-domain (Default),\n        ``freq`` Consider the input `x` as frequency-domain.\n\n    Returns\n    -------\n    resampled_x or (resampled_x, resampled_t)\n        Either the resampled array, or, if `t` was given, a tuple\n        containing the resampled array and the corresponding resampled\n        positions.\n\n    See Also\n    --------\n    decimate : Downsample the signal after applying an FIR or IIR filter.\n    resample_poly : Resample using polyphase filtering and an FIR filter.\n\n    Notes\n    -----\n    The argument `window` controls a Fourier-domain window that tapers\n    the Fourier spectrum before zero-padding to alleviate ringing in\n    the resampled values for sampled signals you didn't intend to be\n    interpreted as band-limited.\n\n    If `window` is a function, then it is called with a vector of inputs\n    indicating the frequency bins (i.e. fftfreq(x.shape[axis]) ).\n\n    If `window` is an array of the same length as `x.shape[axis]` it is\n    assumed to be the window to be applied directly in the Fourier\n    domain (with dc and low-frequency first).\n\n    For any other type of `window`, the function `scipy.signal.get_window`\n    is called to generate the window.\n\n    The first sample of the returned vector is the same as the first\n    sample of the input vector.  The spacing between samples is changed\n    from ``dx`` to ``dx * len(x) / num``.\n\n    If `t` is not None, then it is used solely to calculate the resampled\n    positions `resampled_t`\n\n    As noted, `resample` uses FFT transformations, which can be very\n    slow if the number of input or output samples is large and prime;\n    see `scipy.fft.fft`.\n\n    Examples\n    --------\n    Note that the end of the resampled data rises to meet the first\n    sample of the next cycle:\n\n    >>> from scipy import signal\n\n    >>> x = np.linspace(0, 10, 20, endpoint=False)\n    >>> y = np.cos(-x**2/6.0)\n    >>> f = signal.resample(y, 100)\n    >>> xnew = np.linspace(0, 10, 100, endpoint=False)\n\n    >>> import matplotlib.pyplot as plt\n    >>> plt.plot(x, y, 'go-', xnew, f, '.-', 10, y[0], 'ro')\n    >>> plt.legend(['data', 'resampled'], loc='best')\n    >>> plt.show()\n    \"\"\"\n\n    if domain not in ('time', 'freq'):\n        raise ValueError(\"Acceptable domain flags are 'time' or\"\n                         \" 'freq', not domain={}\".format(domain))\n\n    if hasattr(axis, \"__len__\") and not hasattr(num, \"__len__\"):\n        num = [num] * len(axis)\n\n    if hasattr(num, \"__len__\"):\n        if hasattr(axis, \"__len__\") and len(num) == len(axis):\n            _temp = x\n            _t_list = []\n            for i in range(len(num)):\n                _num = num[i]\n                _axis = axis[i]\n                if t is None:\n                    _temp = resample(_temp, _num, t, _axis, window, domain)\n                else:\n                    _temp, _t = resample(_temp, _num, t, _axis, window, domain)\n                    _t_list.append(_t)\n            if t is None:\n                return _temp\n            else:\n                return _temp, torch.stack(_t_list)\n        else:\n            raise ValueError(\"if num is array like, then axis also has to be array like and of the same length\")\n\n    Nx = x.shape[axis]\n\n    # Check if we can use faster real FFT\n    real_input = _isrealobj(x)\n\n    if domain == 'time':\n        # Forward transform\n        if real_input:\n            X = torch.fft.rfft(x, dim=axis)\n        else:  # Full complex FFT\n            X = torch.fft.fft(x, dim=axis)\n    else:  # domain == 'freq'\n        X = x\n\n    # Apply window to spectrum\n    if window is not None:\n        if callable(window):\n            W = window(torch.fft.fftfreq(Nx))\n        elif isinstance(window, torch.Tensor):\n            if window.shape != (Nx,):\n                raise ValueError('window must have the same length as data')\n            W = window\n        else:\n            sys.exit(\n                \"Window can only be either a function or Tensor. Window generation with get_window function of scipy.signal hasn't been implimented yet.\")\n            W = torch.fft.ifftshift(get_window(window, Nx))\n\n        newshape_W = [1] * x.ndim\n        newshape_W[axis] = X.shape[axis]\n        if real_input:\n            # Fold the window back on itself to mimic complex behavior\n            W_real = W.clone()\n            W_real[1:] += W_real[-1:0:-1]\n            W_real[1:] *= 0.5\n            X *= W_real[:newshape_W[axis]].reshape(newshape_W)\n        else:\n            X *= W.reshape(newshape_W)\n\n    # Copy each half of the original spectrum to the output spectrum, either\n    # truncating high frequences (downsampling) or zero-padding them\n    # (upsampling)\n\n    # Placeholder array for output spectrum\n    newshape = list(x.shape)\n    if real_input:\n        newshape[axis] = num // 2 + 1\n    else:\n        newshape[axis] = num\n    Y = torch.zeros(newshape, dtype=X.dtype, device=x.device)\n\n    # Copy positive frequency components (and Nyquist, if present)\n    N = min(num, Nx)\n    nyq = N // 2 + 1  # Slice index that includes Nyquist if present\n    sl = [slice(None)] * x.ndim\n    sl[axis] = slice(0, nyq)\n    Y[tuple(sl)] = X[tuple(sl)]\n    if not real_input:\n        # Copy negative frequency components\n        if N > 2:  # (slice expression doesn't collapse to empty array)\n            sl[axis] = slice(nyq - N, None)\n            Y[tuple(sl)] = X[tuple(sl)]\n\n    # Split/join Nyquist component(s) if present\n    # So far we have set Y[+N/2]=X[+N/2]\n    if N % 2 == 0:\n        if num < Nx:  # downsampling\n            if real_input:\n                sl[axis] = slice(N // 2, N // 2 + 1)\n                Y[tuple(sl)] *= 2.\n            else:\n                # select the component of Y at frequency +N/2,\n                # add the component of X at -N/2\n                sl[axis] = slice(-N // 2, -N // 2 + 1)\n                Y[tuple(sl)] += X[tuple(sl)]\n        elif Nx < num:  # upsampling\n            # select the component at frequency +N/2 and halve it\n            sl[axis] = slice(N // 2, N // 2 + 1)\n            Y[tuple(sl)] *= 0.5\n            if not real_input:\n                temp = Y[tuple(sl)]\n                # set the component at -N/2 equal to the component at +N/2\n                sl[axis] = slice(num - N // 2, num - N // 2 + 1)\n                Y[tuple(sl)] = temp\n\n    # Inverse transform\n    if real_input:\n        y = torch.fft.irfft(Y, num, dim=axis)\n    else:\n        y = torch.fft.ifft(Y, dim=axis, overwrite_x=True)\n\n    y *= (float(num) / float(Nx))\n\n    if t is None:\n        return y\n    else:\n        new_t = torch.arange(0, num) * (t[1] - t[0]) * Nx / float(num) + t[0]\n        return y, new_t"}
{"doc_id": "utils/__init__.py", "text": ""}
{"doc_id": "utils/util.py", "text": "import os\nimport random\nimport signal\n\nimport numpy as np\nimport torch\nimport torch.distributed as dist\nfrom tqdm import tqdm\nimport random\n\ndef generate_mask(bz, ch_num, patch_num, mask_ratio, device):\n    mask = torch.zeros((bz, ch_num, patch_num), dtype=torch.long, device=device)\n    mask = mask.bernoulli_(mask_ratio)\n    return mask\n\ndef to_tensor(array):\n    return torch.from_numpy(array).float()\n\n\nif __name__ == '__main__':\n    a = generate_mask(192, 32, 15, mask_ratio=0.5, device=None)\n    print(a)"}
